{"id": "2505.18218", "title": "CoMet: Metaphor-Driven Covert Communication for Multi-Agent Language Games", "authors": ["Shuhang Xu", "Fangwei Zhong"], "abstract": "Metaphors are a crucial way for humans to express complex or subtle ideas by comparing one concept to another, often from a different domain. However, many large language models (LLMs) struggle to interpret and apply metaphors in multi-agent language games, hindering their ability to engage in covert communication and semantic evasion, which are crucial for strategic communication. To address this challenge, we introduce CoMet, a framework that enables LLM-based agents to engage in metaphor processing. CoMet combines a hypothesis-based metaphor reasoner with a metaphor generator that improves through self-reflection and knowledge integration. This enhances the agents' ability to interpret and apply metaphors, improving the strategic and nuanced quality of their interactions. We evaluate CoMet on two multi-agent language games - Undercover and Adversarial Taboo - which emphasize Covert Communication and Semantic Evasion. Experimental results demonstrate that CoMet significantly enhances the agents' ability to communicate strategically using metaphors.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "To Appear at ACL 2025 (Main)", "pdf_url": "https://arxiv.org/pdf/2505.18218.pdf", "abstract_url": "https://arxiv.org/abs/2505.18218", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "CoMet是一个框架，旨在通过隐喻处理提升基于大型语言模型（LLM）的代理在多代理语言游戏中的战略沟通能力。", "motivation": "解决大型语言模型在多代理语言游戏中理解和应用隐喻的困难，这对于战略沟通中的隐蔽通信和语义规避至关重要。", "method": "结合基于假设的隐喻推理器和通过自我反思与知识整合改进的隐喻生成器。", "result": "实验结果表明，CoMet显著提高了代理使用隐喻进行战略沟通的能力。", "conclusion": "CoMet框架通过增强代理的隐喻处理能力，提升了其在多代理语言游戏中的互动质量和战略沟通能力。"}}
{"id": "2505.18223", "title": "IDA-Bench: Evaluating LLMs on Interactive Guided Data Analysis", "authors": ["Hanyu Li", "Haoyu Liu", "Tingyu Zhu", "Tianyu Guo", "Zeyu Zheng", "Xiaotie Deng", "Michael I. Jordan"], "abstract": "Large Language Models (LLMs) show promise as data analysis agents, but existing benchmarks overlook the iterative nature of the field, where experts' decisions evolve with deeper insights of the dataset. To address this, we introduce IDA-Bench, a novel benchmark evaluating LLM agents in multi-round interactive scenarios. Derived from complex Kaggle notebooks, tasks are presented as sequential natural language instructions by an LLM-simulated user. Agent performance is judged by comparing its final numerical output to the human-derived baseline. Initial results show that even state-of-the-art coding agents (like Claude-3.7-thinking) succeed on < 50% of the tasks, highlighting limitations not evident in single-turn tests. This work underscores the need to improve LLMs' multi-round capabilities for building more reliable data analysis agents, highlighting the necessity of achieving a balance between instruction following and reasoning.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18223.pdf", "abstract_url": "https://arxiv.org/abs/2505.18223", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了IDA-Bench，一个评估大型语言模型（LLMs）在多轮交互场景中作为数据分析代理性能的新基准。", "motivation": "现有的基准测试忽视了数据分析领域的迭代性质，即专家的决策会随着对数据集的深入理解而演变。", "method": "通过从复杂的Kaggle笔记本中提取任务，以LLM模拟用户的顺序自然语言指令形式呈现，并通过比较代理的最终数值输出与人类得出的基线来评判性能。", "result": "初步结果显示，即使是像Claude-3.7-thinking这样的最先进编码代理，在不到50%的任务上取得成功，这在单轮测试中并不明显。", "conclusion": "这项工作强调了提高LLMs的多轮能力以构建更可靠的数据分析代理的必要性，突出了在指令遵循和推理之间实现平衡的重要性。"}}
{"id": "2505.18679", "title": "Manifold-aware Representation Learning for Degradation-agnostic Image Restoration", "authors": ["Bin Ren", "Yawei Li", "Xu Zheng", "Yuqian Fu", "Danda Pani Paudel", "Ming-Hsuan Yang", "Luc Van Gool", "Nicu Sebe"], "abstract": "Image Restoration (IR) aims to recover high quality images from degraded inputs affected by various corruptions such as noise, blur, haze, rain, and low light conditions. Despite recent advances, most existing approaches treat IR as a direct mapping problem, relying on shared representations across degradation types without modeling their structural diversity. In this work, we present MIRAGE, a unified and lightweight framework for all in one IR that explicitly decomposes the input feature space into three semantically aligned parallel branches, each processed by a specialized module attention for global context, convolution for local textures, and MLP for channel-wise statistics. This modular decomposition significantly improves generalization and efficiency across diverse degradations. Furthermore, we introduce a cross layer contrastive learning scheme that aligns shallow and latent features to enhance the discriminability of shared representations. To better capture the underlying geometry of feature representations, we perform contrastive learning in a Symmetric Positive Definite (SPD) manifold space rather than the conventional Euclidean space. Extensive experiments show that MIRAGE not only achieves new state of the art performance across a variety of degradation types but also offers a scalable solution for challenging all-in-one IR scenarios. Our code and models will be publicly available at", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "ALl-in-One Image Restoration, low-level vision", "pdf_url": "https://arxiv.org/pdf/2505.18679.pdf", "abstract_url": "https://arxiv.org/abs/2505.18679", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种名为MIRAGE的统一且轻量级的框架，用于解决图像恢复（IR）中的多样化退化问题。通过将输入特征空间分解为三个语义对齐的并行分支，并采用专门的模块处理全局上下文、局部纹理和通道统计，显著提高了跨多种退化类型的泛化能力和效率。此外，引入了一种跨层对比学习方案，并在对称正定（SPD）流形空间中进行对比学习，以增强共享表示的区分度。", "motivation": "现有的图像恢复方法大多将IR视为直接映射问题，依赖于跨退化类型的共享表示，而没有建模其结构多样性。本文旨在解决这一问题，提出了一种能够处理多种退化类型的统一框架。", "method": "提出了MIRAGE框架，通过将输入特征空间分解为三个并行分支（全局上下文注意力、局部纹理卷积和通道统计MLP），并引入跨层对比学习方案，在SPD流形空间中进行对比学习。", "result": "大量实验表明，MIRAGE不仅在多种退化类型上实现了新的最先进性能，而且为具有挑战性的全合一IR场景提供了可扩展的解决方案。", "conclusion": "MIRAGE框架通过模块化分解和在SPD流形空间中的对比学习，显著提高了图像恢复的泛化能力和效率，为处理多样化退化问题提供了有效的解决方案。"}}
{"id": "2505.18457", "title": "EdgeAgentX: A Novel Framework for Agentic AI at the Edge in Military Communication Networks", "authors": ["Abir Ray"], "abstract": "This paper introduces EdgeAgentX, a novel framework integrating federated learning (FL), multi-agent reinforcement learning (MARL), and adversarial defense mechanisms, tailored for military communication networks. EdgeAgentX significantly improves autonomous decision-making, reduces latency, enhances throughput, and robustly withstands adversarial disruptions, as evidenced by comprehensive simulations.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multiagent Systems (cs.MA)", "comments": "6 pages, 2 figures", "pdf_url": "https://arxiv.org/pdf/2505.18457.pdf", "abstract_url": "https://arxiv.org/abs/2505.18457", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了EdgeAgentX，一个专为军事通信网络设计的新框架，集成了联邦学习（FL）、多智能体强化学习（MARL）和对抗防御机制，显著提高了自主决策能力，减少了延迟，增强了吞吐量，并能够稳健地抵御对抗性干扰。", "motivation": "解决军事通信网络中自主决策效率低、延迟高、吞吐量不足及对抗性干扰的问题。", "method": "采用联邦学习（FL）、多智能体强化学习（MARL）和对抗防御机制的集成方法。", "result": "通过全面模拟验证，EdgeAgentX显著提高了自主决策能力，减少了延迟，增强了吞吐量，并能够稳健地抵御对抗性干扰。", "conclusion": "EdgeAgentX为军事通信网络提供了一种高效的自主决策和对抗防御解决方案，具有重要的实际应用价值。"}}
{"id": "2505.18541", "title": "RoleRAG: Enhancing LLM Role-Playing via Graph Guided Retrieval", "authors": ["Yongjie Wang", "Jonathan Leung", "Zhiqi Shen"], "abstract": "Large Language Models (LLMs) have shown promise in character imitation, enabling immersive and engaging conversations. However, they often generate content that is irrelevant or inconsistent with a character's background. We attribute these failures to: (1) the inability to accurately recall character-specific knowledge due to entity ambiguity, and (2) a lack of awareness of the character's cognitive boundaries. To address these issues, we propose RoleRAG, a retrieval-based framework that integrates efficient entity disambiguation for knowledge indexing with a boundary-aware retriever for extracting contextually appropriate information from a structured knowledge graph. Experiments on role-playing benchmarks show that RoleRAG's calibrated retrieval helps both general-purpose and role-specific LLMs better align with character knowledge and reduce hallucinated responses.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "A Retrieval-enhanced LLM Role-playing", "pdf_url": "https://arxiv.org/pdf/2505.18541.pdf", "abstract_url": "https://arxiv.org/abs/2505.18541", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "RoleRAG是一个基于检索的框架，旨在通过图引导检索增强LLM角色扮演能力，解决角色背景知识不相关或不一致的问题。", "motivation": "解决大型语言模型在角色模仿中因实体模糊和角色认知边界意识不足而导致的生成内容不相关或不一致的问题。", "method": "提出RoleRAG框架，结合高效的实体消歧进行知识索引和边界感知检索器，从结构化知识图中提取上下文适当的信息。", "result": "在角色扮演基准测试中，RoleRAG的校准检索帮助通用和角色特定的LLM更好地与角色知识对齐，减少幻觉响应。", "conclusion": "RoleRAG通过改进的检索机制，显著提升了LLM在角色扮演中的表现，减少了与角色背景不符的内容生成。"}}
{"id": "2505.18247", "title": "MetaGen Blended RAG: Higher Accuracy for Domain-Specific Q&A Without Fine-Tuning", "authors": ["Kunal Sawarkar", "Shivam R. Solanki", "Abhilasha Mangal"], "abstract": "Despite the widespread exploration of Retrieval-Augmented Generation (RAG), its deployment in enterprises for domain-specific datasets remains limited due to poor answer accuracy. These corpora, often shielded behind firewalls in private enterprise knowledge bases, having complex, domain-specific terminology, rarely seen by LLMs during pre-training; exhibit significant semantic variability across domains (like networking, military, or legal, etc.), or even within a single domain like medicine, and thus result in poor context precision for RAG systems. Currently, in such situations, fine-tuning or RAG with fine-tuning is attempted, but these approaches are slow, expensive, and lack generalization for accuracy as the new domain-specific data emerges. We propose an approach for Enterprise Search that focuses on enhancing the retriever for a domain-specific corpus through hybrid query indexes and metadata enrichment. This 'MetaGen Blended RAG' method constructs a metadata generation pipeline using key concepts, topics, and acronyms, and then creates a metadata-enriched hybrid index with boosted search queries. This approach avoids overfitting and generalizes effectively across domains. On the PubMedQA benchmark for the biomedical domain, the proposed method achieves 82% retrieval accuracy and 77% RAG accuracy, surpassing all previous RAG accuracy results without fine-tuning and sets a new benchmark for zero-shot results while outperforming much larger models like GPT3.5. The results are even comparable to the best fine-tuned models on this dataset, and we further demonstrate the robustness and scalability of the approach by evaluating it on other Q&A datasets like SQuAD, NQ etc.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (cs.LG)", "comments": "Preprint. Paper Submitted NeurIPS 2025- The Thirty-Ninth Annual Conference on Neural Information Processing Systems", "pdf_url": "https://arxiv.org/pdf/2505.18247.pdf", "abstract_url": "https://arxiv.org/abs/2505.18247", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种名为'MetaGen Blended RAG'的方法，旨在不进行微调的情况下提高领域特定问答的准确性。通过混合查询索引和元数据增强来优化检索器，该方法在PubMedQA等基准测试中取得了优于现有RAG方法的准确率。", "motivation": "解决企业领域特定数据集中检索增强生成（RAG）系统因语义变异性导致的答案准确率低的问题，避免传统微调方法的高成本和低泛化能力。", "method": "构建一个元数据生成管道，利用关键概念、主题和缩写词创建元数据增强的混合索引，并通过提升搜索查询来优化检索器。", "result": "在PubMedQA生物医学领域基准测试中，该方法实现了82%的检索准确率和77%的RAG准确率，超越了所有未微调的RAG方法，并与最佳微调模型相媲美。", "conclusion": "'MetaGen Blended RAG'方法在不进行微调的情况下，显著提高了领域特定问答的准确率，展示了良好的泛化能力和扩展性，为企业在私有知识库中的应用提供了高效解决方案。"}}
{"id": "2505.18411", "title": "DanmakuTPPBench: A Multi-modal Benchmark for Temporal Point Process Modeling and Understanding", "authors": ["Yue Jiang", "Jichu Li", "Yang Liu", "Dingkang Yang", "Feng Zhou", "Quyu Kong"], "abstract": "We introduce DanmakuTPPBench, a comprehensive benchmark designed to advance multi-modal Temporal Point Process (TPP) modeling in the era of Large Language Models (LLMs). While TPPs have been widely studied for modeling temporal event sequences, existing datasets are predominantly unimodal, hindering progress in models that require joint reasoning over temporal, textual, and visual information. To address this gap, DanmakuTPPBench comprises two complementary components: (1) DanmakuTPP-Events, a novel dataset derived from the Bilibili video platform, where user-generated bullet comments (Danmaku) naturally form multi-modal events annotated with precise timestamps, rich textual content, and corresponding video frames; (2) DanmakuTPP-QA, a challenging question-answering dataset constructed via a novel multi-agent pipeline powered by state-of-the-art LLMs and multi-modal LLMs (MLLMs), targeting complex temporal-textual-visual reasoning. We conduct extensive evaluations using both classical TPP models and recent MLLMs, revealing significant performance gaps and limitations in current methods' ability to model multi-modal event dynamics. Our benchmark establishes strong baselines and calls for further integration of TPP modeling into the multi-modal language modeling landscape. The code and dataset have been released at", "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.18411.pdf", "abstract_url": "https://arxiv.org/abs/2505.18411", "categories": ["Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "DanmakuTPPBench是一个多模态时间点过程建模和理解的综合基准，旨在推动大型语言模型时代的多模态时间点过程建模。它包括DanmakuTPP-Events数据集和DanmakuTPP-QA问答数据集，用于评估模型在时间、文本和视觉信息联合推理上的能力。", "motivation": "现有的时间点过程数据集主要是单模态的，这限制了需要联合推理时间、文本和视觉信息的模型的发展。DanmakuTPPBench旨在填补这一空白，提供一个多模态的基准。", "method": "DanmakuTPPBench包含两个部分：DanmakuTPP-Events，一个从Bilibili视频平台提取的新数据集；DanmakuTPP-QA，一个通过多智能体流程构建的问答数据集。", "result": "评估显示，当前的方法在多模态事件动态建模上存在显著的性能差距和局限性。", "conclusion": "DanmakuTPPBench为多模态语言建模领域的时间点过程建模建立了强大的基线，并呼吁进一步整合时间点过程建模到多模态语言建模中。"}}
{"id": "2505.18426", "title": "Retrieval Augmented Generation-based Large Language Models for Bridging Transportation Cybersecurity Legal Knowledge Gaps", "authors": ["Khandakar Ashrafi Akbar", "Md Nahiyan Uddin", "Latifur Khan", "Trayce Hockstad", "Mizanur Rahman", "Mashrur Chowdhury", "Bhavani Thuraisingham"], "abstract": "As connected and automated transportation systems evolve, there is a growing need for federal and state authorities to revise existing laws and develop new statutes to address emerging cybersecurity and data privacy challenges. This study introduces a Retrieval-Augmented Generation (RAG) based Large Language Model (LLM) framework designed to support policymakers by extracting relevant legal content and generating accurate, inquiry-specific responses. The framework focuses on reducing hallucinations in LLMs by using a curated set of domain-specific questions to guide response generation. By incorporating retrieval mechanisms, the system enhances the factual grounding and specificity of its outputs. Our analysis shows that the proposed RAG-based LLM outperforms leading commercial LLMs across four evaluation metrics: AlignScore, ParaScore, BERTScore, and ROUGE, demonstrating its effectiveness in producing reliable and context-aware legal insights. This approach offers a scalable, AI-driven method for legislative analysis, supporting efforts to update legal frameworks in line with advancements in transportation technologies.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "Presented at the Transportation Research Board (TRB) Annual Meeting 2025, and subsequently submitted for publication consideration in the Transportation Research Record (TRR)", "pdf_url": "https://arxiv.org/pdf/2505.18426.pdf", "abstract_url": "https://arxiv.org/abs/2505.18426", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本研究介绍了一种基于检索增强生成（RAG）的大型语言模型（LLM）框架，旨在支持政策制定者通过提取相关法律内容并生成准确的、针对特定询问的响应，以解决交通网络安全法律知识缺口问题。", "motivation": "随着连接和自动化交通系统的发展，联邦和州政府需要修订现有法律并制定新法规以应对新兴的网络安全和数据隐私挑战。", "method": "研究采用了一种基于检索增强生成（RAG）的大型语言模型（LLM）框架，通过使用一组特定领域的问题来指导响应生成，以减少LLMs中的幻觉，并通过检索机制增强输出的事实基础和特异性。", "result": "分析表明，提出的基于RAG的LLM在四个评估指标（AlignScore、ParaScore、BERTScore和ROUGE）上优于领先的商业LLM，证明了其在产生可靠和上下文感知的法律见解方面的有效性。", "conclusion": "这种方法为立法分析提供了一种可扩展的、AI驱动的方法，支持更新法律框架以适应交通技术的进步。"}}
{"id": "2505.18450", "title": "BRIT: Bidirectional Retrieval over Unified Image-Text Graph", "authors": ["Ainulla Khan", "Yamada Moyuru", "Srinidhi Akella"], "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a promising technique to enhance the quality and relevance of responses generated by large language models. While recent advancements have mainly focused on improving RAG for text-based queries, RAG on multi-modal documents containing both texts and images has not been fully explored. Especially when fine-tuning does not work. This paper proposes BRIT, a novel multi-modal RAG framework that effectively unifies various text-image connections in the document into a multi-modal graph and retrieves the texts and images as a query-specific sub-graph. By traversing both image-to-text and text-to-image paths in the graph, BRIT retrieve not only directly query-relevant images and texts but also further relevant contents to answering complex cross-modal multi-hop questions. To evaluate the effectiveness of BRIT, we introduce MM-RAG test set specifically designed for multi-modal question answering tasks that require to understand the text-image relations. Our comprehensive experiments demonstrate the superiority of BRIT, highlighting its ability to handle cross-modal questions on the multi-modal documents.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18450.pdf", "abstract_url": "https://arxiv.org/abs/2505.18450", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "BRIT是一种新颖的多模态检索增强生成（RAG）框架，通过统一文档中的文本-图像连接到一个多模态图中，并检索查询特定的子图，有效处理跨模态多跳问题。", "motivation": "解决在多模态文档（包含文本和图像）上应用检索增强生成（RAG）技术时，尤其是当微调不可行时，如何有效理解和利用文本-图像关系的问题。", "method": "提出BRIT框架，通过构建多模态图并遍历图像到文本和文本到图像的路径，检索直接相关及进一步相关的文本和图像内容。", "result": "BRIT在专门为多模态问答任务设计的MM-RAG测试集上表现出色，展示了其处理跨模态问题的能力。", "conclusion": "BRIT通过统一和检索多模态图中的文本-图像连接，为复杂跨模态问题的解答提供了有效方法，推动了多模态RAG技术的发展。"}}
{"id": "2505.18497", "title": "The Pragmatic Mind of Machines: Tracing the Emergence of Pragmatic Competence in Large Language Models", "authors": ["Kefan Yu", "Qingcheng Zeng", "Weihao Xuan", "Wanxin Li", "Jingyi Wu", "Rob Voigt"], "abstract": "Current large language models (LLMs) have demonstrated emerging capabilities in social intelligence tasks, including implicature resolution (Sravanthi et al. (2024)) and theory-of-mind reasoning (Shapira et al. (2024)), both of which require substantial pragmatic understanding. However, how LLMs acquire this competence throughout the training process remains poorly understood. In this work, we introduce ALTPRAG, a dataset grounded in the pragmatic concept of alternatives, designed to evaluate whether LLMs at different training stages can accurately infer nuanced speaker intentions. Each instance pairs two contextually appropriate but pragmatically distinct continuations, enabling fine-grained assessment of both pragmatic interpretation and contrastive reasoning. We systematically evaluate 22 LLMs across key training stages: pre-training, supervised fine-tuning (SFT), and preference optimization, to examine the development of pragmatic competence. Our results show that even base models exhibit notable sensitivity to pragmatic cues, which improves consistently with increases in model and data scale. Additionally, SFT and RLHF contribute further gains, particularly in cognitive-pragmatic reasoning. These findings highlight pragmatic competence as an emergent and compositional property of LLM training and offer new insights for aligning models with human communicative norms.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18497.pdf", "abstract_url": "https://arxiv.org/abs/2505.18497", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了ALTPRAG数据集，用于评估大型语言模型在不同训练阶段对说话者微妙意图的推理能力，揭示了语用能力作为模型训练的涌现性和组合性属性。", "motivation": "探讨大型语言模型如何在训练过程中获得语用能力，以及如何更好地使模型与人类交际规范对齐。", "method": "引入基于替代概念的ALTPRAG数据集，系统评估22个大型语言模型在预训练、监督微调和偏好优化等关键训练阶段的语用能力发展。", "result": "基础模型已显示出对语用线索的显著敏感性，随着模型和数据规模的增加，这种敏感性持续提升；监督微调和RLHF进一步提升了模型，尤其是在认知语用推理方面。", "conclusion": "语用能力是大型语言模型训练中的涌现性和组合性属性，研究结果为模型与人类交际规范的对齐提供了新见解。"}}
{"id": "2505.18597", "title": "LLMs for Supply Chain Management", "authors": ["Haojie Wang", "Jiuyun Jiang", "L. Jeff Hong", "Guangxin Jiang"], "abstract": "The development of large language models (LLMs) has provided new tools for research in supply chain management (SCM). In this paper, we introduce a retrieval-augmented generation (RAG) framework that dynamically integrates external knowledge into the inference process, and develop a domain-specialized SCM LLM, which demonstrates expert-level competence by passing standardized SCM examinations and beer game tests. We further employ the use of LLMs to conduct horizontal and vertical supply chain games, in order to analyze competition and cooperation within supply chains. Our experiments show that RAG significantly improves performance on SCM tasks. Moreover, game-theoretic analysis reveals that the LLM can reproduce insights from the classical SCM literature, while also uncovering novel behaviors and offering fresh perspectives on phenomena such as the bullwhip effect. This paper opens the door for exploring cooperation and competition for complex supply chain network through the lens of LLMs.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Applications (stat.AP)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18597.pdf", "abstract_url": "https://arxiv.org/abs/2505.18597", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Applications (stat.AP)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了利用大型语言模型（LLMs）在供应链管理（SCM）研究中的新工具，提出了一个检索增强生成（RAG）框架，动态整合外部知识，并开发了一个领域专用的SCM LLM。该模型在标准化SCM考试和啤酒游戏测试中表现出专家级能力。此外，通过LLMs进行水平和垂直供应链游戏分析，揭示了LLM能够复现经典SCM文献的见解，同时发现新行为和对牛鞭效应等现象的新视角。", "motivation": "探索大型语言模型（LLMs）在供应链管理（SCM）中的应用，以解决SCM中的复杂问题，如知识整合、竞争与合作分析。", "method": "采用检索增强生成（RAG）框架动态整合外部知识，开发领域专用的SCM LLM，并通过标准化考试和啤酒游戏测试验证其能力。利用LLMs进行供应链游戏，分析竞争与合作。", "result": "RAG显著提高了SCM任务的性能。LLM不仅能够复现经典SCM文献的见解，还能发现新行为和对牛鞭效应等现象的新视角。", "conclusion": "本文为通过LLMs探索复杂供应链网络中的合作与竞争开辟了新途径，展示了LLMs在SCM领域的潜力和应用前景。"}}
{"id": "2505.18607", "title": "Knowledge Retrieval in LLM Gaming: A Shift from Entity-Centric to Goal-Oriented Graphs", "authors": ["Jonathan Leung", "Yongjie Wang", "Zhiqi Shen"], "abstract": "Large Language Models (LLMs) demonstrate impressive general capabilities but often struggle with step-by-step reasoning, especially in complex applications such as games. While retrieval-augmented methods like GraphRAG attempt to bridge this gap through cross-document extraction and indexing, their fragmented entity-relation graphs and overly dense local connectivity hinder the construction of coherent reasoning. In this paper, we propose a novel framework based on Goal-Oriented Graphs (GoGs), where each node represents a goal and its associated attributes, and edges encode logical dependencies between goals. This structure enables explicit retrieval of reasoning paths by first identifying high-level goals and recursively retrieving their subgoals, forming coherent reasoning chains to guide LLM prompting. Our method significantly enhances the reasoning ability of LLMs in game-playing tasks, as demonstrated by extensive experiments on the Minecraft testbed, outperforming GraphRAG and other baselines.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18607.pdf", "abstract_url": "https://arxiv.org/abs/2505.18607", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种基于目标导向图（GoGs）的新框架，用于增强大型语言模型（LLM）在游戏等复杂应用中的逐步推理能力。通过将节点表示为目标及其相关属性，边编码目标间的逻辑依赖，该方法显著提升了LLM在游戏任务中的推理表现。", "motivation": "大型语言模型（LLMs）在通用任务上表现出色，但在复杂应用如游戏中的逐步推理能力不足。现有的检索增强方法如GraphRAG通过跨文档提取和索引试图弥补这一差距，但其碎片化的实体关系图和过于密集的局部连接阻碍了连贯推理的构建。", "method": "提出了一种基于目标导向图（GoGs）的新框架，其中每个节点代表一个目标及其相关属性，边编码目标间的逻辑依赖。这种结构通过首先识别高级目标并递归检索其子目标，形成连贯的推理链来指导LLM提示。", "result": "在Minecraft测试平台上进行的广泛实验表明，该方法显著增强了LLM在游戏任务中的推理能力，性能优于GraphRAG和其他基线方法。", "conclusion": "目标导向图（GoGs）框架为增强LLM在复杂应用中的推理能力提供了一种有效方法，特别是在需要逐步推理的游戏任务中，其性能优于现有方法。"}}
{"id": "2505.18705", "title": "AI-Researcher: Autonomous Scientific Innovation", "authors": ["Jiabin Tang", "Lianghao Xia", "Zhonghang Li", "Chao Huang"], "abstract": "The powerful reasoning capabilities of Large Language Models (LLMs) in mathematics and coding, combined with their ability to automate complex tasks through agentic frameworks, present unprecedented opportunities for accelerating scientific innovation. In this paper, we introduce AI-Researcher, a fully autonomous research system that transforms how AI-driven scientific discovery is conducted and evaluated. Our framework seamlessly orchestrates the complete research pipeline--from literature review and hypothesis generation to algorithm implementation and publication-ready manuscript preparation--with minimal human intervention. To rigorously assess autonomous research capabilities, we develop Scientist-Bench, a comprehensive benchmark comprising state-of-the-art papers across diverse AI research domains, featuring both guided innovation and open-ended exploration tasks. Through extensive experiments, we demonstrate that AI-Researcher achieves remarkable implementation success rates and produces research papers that approach human-level quality. This work establishes new foundations for autonomous scientific innovation that can complement human researchers by systematically exploring solution spaces beyond cognitive limitations.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.18705.pdf", "abstract_url": "https://arxiv.org/abs/2505.18705", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了AI-Researcher，一个完全自主的研究系统，旨在通过大型语言模型（LLMs）的强大推理能力和自动化复杂任务的能力，加速科学创新。该系统能够无缝协调从文献综述到论文准备的整个研究流程，并在实验中显示出接近人类水平的研究成果。", "motivation": "解决如何利用大型语言模型（LLMs）的推理和自动化能力，加速科学创新过程，减少人类干预的需求。", "method": "开发了AI-Researcher系统，该系统能够自主完成从文献回顾到论文准备的全研究流程，并引入了Scientist-Bench基准来评估自主研究能力。", "result": "AI-Researcher在实验中实现了显著的实现成功率，并生成了接近人类水平质量的研究论文。", "conclusion": "这项工作为自主科学创新建立了新的基础，能够通过系统探索超越认知限制的解决方案空间来补充人类研究人员。"}}
{"id": "2505.18881", "title": "SD-OVON: A Semantics-aware Dataset and Benchmark Generation Pipeline for Open-Vocabulary Object Navigation in Dynamic Scenes", "authors": ["Dicong Qiu", "Jiadi You", "Zeying Gong", "Ronghe Qiu", "Hui Xiong", "Junwei Liang"], "abstract": "We present the Semantics-aware Dataset and Benchmark Generation Pipeline for Open-vocabulary Object Navigation in Dynamic Scenes (SD-OVON). It utilizes pretraining multimodal foundation models to generate infinite unique photo-realistic scene variants that adhere to real-world semantics and daily commonsense for the training and the evaluation of navigation agents, accompanied with a plugin for generating object navigation task episodes compatible to the Habitat simulator. In addition, we offer two pre-generated object navigation task datasets, SD-OVON-3k and SD-OVON-10k, comprising respectively about 3k and 10k episodes of the open-vocabulary object navigation task, derived from the SD-OVON-Scenes dataset with 2.5k photo-realistic scans of real-world environments and the SD-OVON-Objects dataset with 0.9k manually inspected scanned and artist-created manipulatable object models. Unlike prior datasets limited to static environments, SD-OVON covers dynamic scenes and manipulatable objects, facilitating both real-to-sim and sim-to-real robotic applications. This approach enhances the realism of navigation tasks, the training and the evaluation of open-vocabulary object navigation agents in complex settings. To demonstrate the effectiveness of our pipeline and datasets, we propose two baselines and evaluate them along with state-of-the-art baselines on SD-OVON-3k. The datasets, benchmark and source code are publicly available.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": "Preprint. 21 pages", "pdf_url": "https://arxiv.org/pdf/2505.18881.pdf", "abstract_url": "https://arxiv.org/abs/2505.18881", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "SD-OVON是一个语义感知的数据集和基准生成管道，用于动态场景中的开放词汇对象导航。它利用预训练的多模态基础模型生成无限独特的照片级真实场景变体，支持导航代理的训练和评估，并提供与Habitat模拟器兼容的对象导航任务插件。", "motivation": "解决现有数据集仅限于静态环境的问题，SD-OVON覆盖动态场景和可操作对象，增强导航任务的真实感，支持复杂环境下的开放词汇对象导航代理的训练和评估。", "method": "利用预训练的多模态基础模型生成照片级真实场景变体，提供对象导航任务插件，并生成两个预生成的数据集SD-OVON-3k和SD-OVON-10k。", "result": "提出了两个基线，并在SD-OVON-3k上与最先进的基线进行了评估，展示了管道和数据集的有效性。", "conclusion": "SD-OVON通过覆盖动态场景和可操作对象，提高了导航任务的真实性和复杂性，为开放词汇对象导航代理的训练和评估提供了新的工具和资源。"}}
{"id": "2505.18746", "title": "$C^3$-Bench: The Things Real Disturbing LLM based Agent in Multi-Tasking", "authors": ["Peijie Yu", "Yifan Yang", "Jinjian Li", "Zelong Zhang", "Haorui Wang", "Xiao Feng", "Feng Zhang"], "abstract": "Agents based on large language models leverage tools to modify environments, revolutionizing how AI interacts with the physical world. Unlike traditional NLP tasks that rely solely on historical dialogue for responses, these agents must consider more complex factors, such as inter-tool relationships, environmental feedback and previous decisions, when making choices. Current research typically evaluates agents via multi-turn dialogues. However, it overlooks the influence of these critical factors on agent behavior. To bridge this gap, we present an open-source and high-quality benchmark $C^3$-Bench. This benchmark integrates attack concepts and applies univariate analysis to pinpoint key elements affecting agent robustness. In concrete, we design three challenges: navigate complex tool relationships, handle critical hidden information and manage dynamic decision paths. Complementing these challenges, we introduce fine-grained metrics, innovative data collection algorithms and reproducible evaluation methods. Extensive experiments are conducted on 49 mainstream agents, encompassing general fast-thinking, slow-thinking and domain-specific models. We observe that agents have significant shortcomings in handling tool dependencies, long context information dependencies and frequent policy-type switching. In essence, $C^3$-Bench aims to expose model vulnerabilities through these challenges and drive research into the interpretability of agent performance. The benchmark is publicly available at", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18746.pdf", "abstract_url": "https://arxiv.org/abs/2505.18746", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了$C^3$-Bench，一个开源高质量的基准测试，旨在评估基于大型语言模型的代理在多任务处理中的鲁棒性，特别是在处理工具关系、隐藏信息和动态决策路径方面的能力。", "motivation": "当前研究通常通过多轮对话评估代理，但忽视了关键因素如工具间关系、环境反馈和先前决策对代理行为的影响。$C^3$-Bench旨在填补这一空白，揭示模型在处理复杂任务时的脆弱性。", "method": "研究设计了三个挑战：导航复杂工具关系、处理关键隐藏信息和管理动态决策路径，并引入了细粒度指标、创新数据收集算法和可复现的评估方法。", "result": "在49个主流代理上的广泛实验显示，代理在处理工具依赖、长上下文信息依赖和频繁策略类型切换方面存在显著不足。", "conclusion": "$C^3$-Bench通过挑战暴露模型脆弱性，推动代理性能可解释性研究，基准测试已公开可用。"}}
{"id": "2505.18899", "title": "Beyond Domain Randomization: Event-Inspired Perception for Visually Robust Adversarial Imitation from Videos", "authors": ["Andrea Ramazzina", "Vittorio Giammarino", "Matteo El-Hariry", "Mario Bijelic"], "abstract": "Imitation from videos often fails when expert demonstrations and learner environments exhibit domain shifts, such as discrepancies in lighting, color, or texture. While visual randomization partially addresses this problem by augmenting training data, it remains computationally intensive and inherently reactive, struggling with unseen scenarios. We propose a different approach: instead of randomizing appearances, we eliminate their influence entirely by rethinking the sensory representation itself. Inspired by biological vision systems that prioritize temporal transients (e.g., retinal ganglion cells) and by recent sensor advancements, we introduce event-inspired perception for visually robust imitation. Our method converts standard RGB videos into a sparse, event-based representation that encodes temporal intensity gradients, discarding static appearance features. This biologically grounded approach disentangles motion dynamics from visual style, enabling robust visual imitation from observations even in the presence of visual mismatches between expert and agent environments. By training policies on event streams, we achieve invariance to appearance-based distractors without requiring computationally expensive and environment-specific data augmentation techniques. Experiments across the DeepMind Control Suite and the Adroit platform for dynamic dexterous manipulation show the efficacy of our method. Our code is publicly available at Eb-LAIfO.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18899.pdf", "abstract_url": "https://arxiv.org/abs/2505.18899", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Machine Learning (cs.LG)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于事件启发的感知方法，用于从视频中进行视觉鲁棒的对抗模仿学习，通过将标准RGB视频转换为稀疏的、基于事件的表示，编码时间强度梯度，从而消除外观特征的影响，实现了在专家和学习者环境之间存在视觉不匹配时的鲁棒模仿。", "motivation": "解决从视频模仿学习时，由于专家演示和学习者环境之间的域偏移（如光照、颜色或纹理的差异）导致的失败问题。", "method": "引入事件启发的感知方法，将标准RGB视频转换为稀疏的、基于事件的表示，编码时间强度梯度，丢弃静态外观特征。", "result": "在DeepMind Control Suite和Adroit平台上进行的实验证明了该方法的有效性，能够在存在视觉不匹配的情况下实现鲁棒的视觉模仿。", "conclusion": "通过训练策略在事件流上，实现了对外观干扰的不变性，无需计算昂贵且环境特定的数据增强技术。"}}
{"id": "2505.18596", "title": "Debate-to-Detect: Reformulating Misinformation Detection as a Real-World Debate with Large Language Models", "authors": ["Chen Han", "Wenzhen Zheng", "Xijin Tang"], "abstract": "The proliferation of misinformation in digital platforms reveals the limitations of traditional detection methods, which mostly rely on static classification and fail to capture the intricate process of real-world fact-checking. Despite advancements in Large Language Models (LLMs) that enhance automated reasoning, their application to misinformation detection remains hindered by issues of logical inconsistency and superficial verification. In response, we introduce Debate-to-Detect (D2D), a novel Multi-Agent Debate (MAD) framework that reformulates misinformation detection as a structured adversarial debate. Inspired by fact-checking workflows, D2D assigns domain-specific profiles to each agent and orchestrates a five-stage debate process, including Opening Statement, Rebuttal, Free Debate, Closing Statement, and Judgment. To transcend traditional binary classification, D2D introduces a multi-dimensional evaluation mechanism that assesses each claim across five distinct dimensions: Factuality, Source Reliability, Reasoning Quality, Clarity, and Ethics. Experiments with GPT-4o on two fakenews datasets demonstrate significant improvements over baseline methods, and the case study highlight D2D's capability to iteratively refine evidence while improving decision transparency, representing a substantial advancement towards robust and interpretable misinformation detection. The code will be open-sourced in a future release.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18596.pdf", "abstract_url": "https://arxiv.org/abs/2505.18596", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了Debate-to-Detect (D2D)框架，通过多智能体辩论(MAD)将虚假信息检测重新定义为结构化对抗辩论，以解决传统静态分类方法的局限性。", "motivation": "数字平台上虚假信息的泛滥暴露了传统检测方法的局限性，这些方法主要依赖静态分类，无法捕捉现实世界事实核查的复杂过程。", "method": "D2D框架为每个智能体分配特定领域的角色，并组织一个五阶段辩论过程，包括开场陈述、反驳、自由辩论、结束陈述和判决。", "result": "在GPT-4o上的实验显示，D2D在两个虚假新闻数据集上显著优于基线方法，并能迭代细化证据，提高决策透明度。", "conclusion": "D2D代表了向健壮和可解释的虚假信息检测的重大进步，其代码将在未来发布中开源。"}}
{"id": "2505.18581", "title": "Removal of Hallucination on Hallucination: Debate-Augmented RAG", "authors": ["Wentao Hu", "Wengyu Zhang", "Yiyang Jiang", "Chen Jason Zhang", "Xiaoyong Wei", "Qing Li"], "abstract": "Retrieval-Augmented Generation (RAG) enhances factual accuracy by integrating external knowledge, yet it introduces a critical issue: erroneous or biased retrieval can mislead generation, compounding hallucinations, a phenomenon we term Hallucination on Hallucination. To address this, we propose Debate-Augmented RAG (DRAG), a training-free framework that integrates Multi-Agent Debate (MAD) mechanisms into both retrieval and generation stages. In retrieval, DRAG employs structured debates among proponents, opponents, and judges to refine retrieval quality and ensure factual reliability. In generation, DRAG introduces asymmetric information roles and adversarial debates, enhancing reasoning robustness and mitigating factual inconsistencies. Evaluations across multiple tasks demonstrate that DRAG improves retrieval reliability, reduces RAG-induced hallucinations, and significantly enhances overall factual accuracy. Our code is available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "Accepted by ACL 2025", "pdf_url": "https://arxiv.org/pdf/2505.18581.pdf", "abstract_url": "https://arxiv.org/abs/2505.18581", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文提出了一种名为Debate-Augmented RAG (DRAG)的训练免费框架，旨在解决检索增强生成(RAG)中因错误或偏见的检索导致的‘幻觉叠加’问题。通过在检索和生成阶段集成多代理辩论(MAD)机制，DRAG提高了检索的可靠性和生成的事实准确性。", "motivation": "解决检索增强生成(RAG)技术中因错误或偏见的检索导致的‘幻觉叠加’问题，即错误的检索结果进一步误导生成过程，加剧事实错误。", "method": "提出了Debate-Augmented RAG (DRAG)框架，该框架在检索和生成阶段集成多代理辩论(MAD)机制。在检索阶段，通过支持者、反对者和裁判的结构化辩论优化检索质量；在生成阶段，通过不对称信息角色和对抗性辩论增强推理的鲁棒性。", "result": "在多个任务上的评估显示，DRAG提高了检索的可靠性，减少了RAG引起的幻觉，显著提升了整体的事实准确性。", "conclusion": "DRAG框架通过集成多代理辩论机制，有效解决了RAG技术中的‘幻觉叠加’问题，提高了生成内容的事实准确性，为未来的研究和应用提供了有价值的参考。"}}
{"id": "2505.18829", "title": "LiteCUA: Computer as MCP Server for Computer-Use Agent on AIOS", "authors": ["Kai Mei", "Xi Zhu", "Hang Gao", "Shuhang Lin", "Yongfeng Zhang"], "abstract": "We present AIOS 1.0, a novel platform designed to advance computer-use agent (CUA) capabilities through environmental contextualization. While existing approaches primarily focus on building more powerful agent frameworks or enhancing agent models, we identify a fundamental limitation: the semantic disconnect between how language models understand the world and how computer interfaces are structured. AIOS 1.0 addresses this challenge by transforming computers into contextual environments that language models can natively comprehend, implementing a Model Context Protocol (MCP) server architecture to abstract computer states and actions. This approach effectively decouples interface complexity from decision complexity, enabling agents to reason more effectively about computing environments. To demonstrate our platform's effectiveness, we introduce LiteCUA, a lightweight computer-use agent built on AIOS 1.0 that achieves a 14.66% success rate on the OSWorld benchmark, outperforming several specialized agent frameworks despite its simple architecture. Our results suggest that contextualizing computer environments for language models represents a promising direction for developing more capable computer-use agents and advancing toward AI that can interact with digital systems. The source code of LiteCUA is available at", "subjects": "Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Operating Systems (cs.OS)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18829.pdf", "abstract_url": "https://arxiv.org/abs/2505.18829", "categories": ["Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)", "Operating Systems (cs.OS)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了AIOS 1.0平台，旨在通过环境情境化提升计算机使用代理（CUA）的能力。该平台通过将计算机转化为语言模型能原生理解的情境环境，解决了语言模型理解世界与计算机界面结构之间的语义断开问题。", "motivation": "解决语言模型理解世界与计算机界面结构之间的语义断开问题，提升计算机使用代理的能力。", "method": "采用模型上下文协议（MCP）服务器架构，抽象计算机状态和动作，将界面复杂性与决策复杂性解耦。", "result": "在AIOS 1.0上构建的轻量级计算机使用代理LiteCUA，在OSWorld基准测试中取得了14.66%的成功率，优于多个专用代理框架。", "conclusion": "为语言模型情境化计算机环境是开发更强大计算机使用代理和推进AI与数字系统交互的有前景的方向。"}}
{"id": "2505.18946", "title": "SANNet: A Semantic-Aware Agentic AI Networking Framework for Multi-Agent Cross-Layer Coordination", "authors": ["Yong Xiao", "Haoran Zhou", "Xubo Li", "Yayu Gao", "Guangming Shi", "Ping Zhang"], "abstract": "Agentic AI networking (AgentNet) is a novel AI-native networking paradigm that relies on a large number of specialized AI agents to collaborate and coordinate for autonomous decision-making, dynamic environmental adaptation, and complex goal achievement. It has the potential to facilitate real-time network management alongside capabilities for self-configuration, self-optimization, and self-adaptation across diverse and complex networking environments, laying the foundation for fully autonomous networking systems in the future. Despite its promise, AgentNet is still in the early stage of development, and there still lacks an effective networking framework to support automatic goal discovery and multi-agent self-orchestration and task assignment. This paper proposes SANNet, a novel semantic-aware agentic AI networking architecture that can infer the semantic goal of the user and automatically assign agents associated with different layers of a mobile system to fulfill the inferred goal. Motivated by the fact that one of the major challenges in AgentNet is that different agents may have different and even conflicting objectives when collaborating for certain goals, we introduce a dynamic weighting-based conflict-resolving mechanism to address this issue. We prove that SANNet can provide theoretical guarantee in both conflict-resolving and model generalization performance for multi-agent collaboration in dynamic environment. We develop a hardware prototype of SANNet based on the open RAN and 5GS core platform. Our experimental results show that SANNet can significantly improve the performance of multi-agent networking systems, even when agents with conflicting objectives are selected to collaborate for the same goal.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA); Networking and Internet Architecture (cs.NI)", "comments": "submitted to IEEE GLOBECOM'25", "pdf_url": "https://arxiv.org/pdf/2505.18946.pdf", "abstract_url": "https://arxiv.org/abs/2505.18946", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)", "Networking and Internet Architecture (cs.NI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "SANNet是一种新型的语义感知代理AI网络架构，旨在通过动态权重冲突解决机制和多代理协作，实现用户语义目标的自动推断和任务分配，显著提升多代理网络系统的性能。", "motivation": "解决Agentic AI网络（AgentNet）中缺乏有效框架支持自动目标发现、多代理自我编排和任务分配的问题，特别是处理不同代理在协作时可能出现的冲突目标。", "method": "提出SANNet架构，引入动态权重冲突解决机制，支持语义目标的自动推断和多代理跨层协作，并在开放RAN和5GS核心平台上开发硬件原型。", "result": "实验结果表明，SANNet即使在代理目标冲突的情况下，也能显著提升多代理网络系统的性能，并为动态环境中的多代理协作提供理论保证。", "conclusion": "SANNet为未来的完全自主网络系统奠定了基础，通过语义感知和冲突解决机制，实现了高效的跨层协调和任务自动化管理。"}}
{"id": "2505.18630", "title": "DDO: Dual-Decision Optimization via Multi-Agent Collaboration for LLM-Based Medical Consultation", "authors": ["Zhihao Jia", "Mingyi Jia", "Junwen Duan", "Jianxin Wang"], "abstract": "Large Language Models (LLMs) demonstrate strong generalization and reasoning abilities, making them well-suited for complex decision-making tasks such as medical consultation (MC). However, existing LLM-based methods often fail to capture the dual nature of MC, which entails two distinct sub-tasks: symptom inquiry, a sequential decision-making process, and disease diagnosis, a classification problem. This mismatch often results in ineffective symptom inquiry and unreliable disease diagnosis. To address this, we propose \\textbf{DDO}, a novel LLM-based framework that performs \\textbf{D}ual-\\textbf{D}ecision \\textbf{O}ptimization by decoupling and independently optimizing the the two sub-tasks through a collaborative multi-agent workflow. Experiments on three real-world MC datasets show that DDO consistently outperforms existing LLM-based approaches and achieves competitive performance with state-of-the-art generation-based methods, demonstrating its effectiveness in the MC task.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "17 pages, 4 figures", "pdf_url": "https://arxiv.org/pdf/2505.18630.pdf", "abstract_url": "https://arxiv.org/abs/2505.18630", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为DDO的新型LLM框架，通过多智能体协作优化医疗咨询中的双重决策任务，包括症状询问和疾病诊断，实验证明其在三个真实世界MC数据集上优于现有方法。", "motivation": "现有的基于LLM的方法往往无法捕捉医疗咨询（MC）的双重性质，即症状询问（顺序决策过程）和疾病诊断（分类问题）这两个不同的子任务，导致症状询问无效和疾病诊断不可靠。", "method": "DDO框架通过解耦并通过协作多智能体工作流独立优化这两个子任务，实现了双重决策优化。", "result": "在三个真实世界的MC数据集上的实验表明，DDO始终优于现有的基于LLM的方法，并与最先进的基于生成的方法竞争，证明了其在MC任务中的有效性。", "conclusion": "DDO框架通过优化医疗咨询中的双重决策任务，提高了症状询问的有效性和疾病诊断的可靠性，为LLM在复杂决策任务中的应用提供了新的视角。"}}
{"id": "2505.19095", "title": "ScreenExplorer: Training a Vision-Language Model for Diverse Exploration in Open GUI World", "authors": ["Runliang Niu", "Jinglong Ji", "Yi Chang", "Qi Wang"], "abstract": "The rapid progress of large language models (LLMs) has sparked growing interest in building Artificial General Intelligence (AGI) within Graphical User Interface (GUI) environments. However, existing GUI agents based on LLMs or vision-language models (VLMs) often fail to generalize to novel environments and rely heavily on manually curated, diverse datasets. To overcome these limitations, we introduce ScreenExplorer, a VLM trained via Group Relative Policy Optimization(GRPO) in real, dynamic, and open-ended GUI environments. Innovatively, we introduced a world-model-based curiosity reward function to help the agent overcome the cold-start phase of exploration. Additionally, distilling experience streams further enhances the model's exploration capabilities. Our training framework enhances model exploration in open GUI environments, with trained models showing better environmental adaptation and sustained exploration compared to static deployment models. Our findings offer a scalable pathway toward AGI systems with self-improving capabilities in complex interactive settings.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19095.pdf", "abstract_url": "https://arxiv.org/abs/2505.19095", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了ScreenExplorer，一种通过Group Relative Policy Optimization（GRPO）在真实、动态和开放式GUI环境中训练的视觉语言模型（VLM）。该模型创新性地引入了基于世界模型的好奇心奖励函数，以帮助代理克服探索的冷启动阶段，并通过提炼经验流进一步增强模型的探索能力。", "motivation": "解决现有基于大型语言模型（LLMs）或视觉语言模型（VLMs）的GUI代理在新环境中泛化能力不足，以及过度依赖手动策划的多样化数据集的问题。", "method": "使用Group Relative Policy Optimization（GRPO）在真实、动态和开放式GUI环境中训练视觉语言模型，并引入基于世界模型的好奇心奖励函数和提炼经验流的方法。", "result": "训练框架增强了模型在开放式GUI环境中的探索能力，训练出的模型显示出更好的环境适应性和持续的探索能力，相比于静态部署模型。", "conclusion": "研究结果为在复杂交互环境中具有自我改进能力的AGI系统提供了一条可扩展的路径。"}}
{"id": "2505.19167", "title": "Amplifying Human Creativity and Problem Solving with AI Through Generative Collective Intelligence", "authors": ["Thomas P. Kehler", "Scott E. Page", "Alex Pentland", "Martin Reeves", "John Seely Brown"], "abstract": "We propose a new framework for human-AI collaboration that amplifies the distinct capabilities of both. This framework, which we call Generative Collective Intelligence (GCI), shifts AI to the group/social level and employs AI in dual roles: as interactive agents and as technology that accumulates, organizes, and leverages knowledge. By creating a cognitive bridge between human reasoning and AI models, GCI can overcome the limitations of purely algorithmic approaches to problem-solving and decision-making. The framework demonstrates how AI can be reframed as a social and cultural technology that enables groups to solve complex problems through structured collaboration that transcends traditional communication barriers. We describe the mathematical foundations of GCI based on comparative judgment and minimum regret principles, and illustrate its applications across domains including climate adaptation, healthcare transformation, and civic participation. By combining human creativity with AI's computational capabilities, GCI offers a promising approach to addressing complex societal challenges that neither human or machines can solve alone.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19167.pdf", "abstract_url": "https://arxiv.org/abs/2505.19167", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "提出了一种名为生成性集体智慧（GCI）的新框架，用于人机协作，通过将AI应用于群体/社会层面，并发挥其作为交互代理和知识积累、组织及利用技术的双重作用，来放大人类和AI的独特能力。", "motivation": "解决纯粹算法方法在问题解决和决策制定中的局限性，通过构建人类推理与AI模型之间的认知桥梁，实现超越传统沟通障碍的结构化协作。", "method": "基于比较判断和最小后悔原则的数学基础，将AI重新定义为一种社会和文化技术，促进群体解决复杂问题。", "result": "GCI框架在气候适应、医疗保健转型和公民参与等多个领域展示了应用潜力，证明了结合人类创造力和AI计算能力解决复杂社会挑战的有效性。", "conclusion": "GCI为人类和机器单独无法解决的复杂社会问题提供了一个有前景的解决途径，强调了人机协作在超越传统方法限制中的重要性。"}}
{"id": "2505.19173", "title": "Investigating Pedagogical Teacher and Student LLM Agents: Genetic Adaptation Meets Retrieval Augmented Generation Across Learning Style", "authors": ["Debdeep Sanyal", "Agniva Maiti", "Umakanta Maharana", "Dhruv Kumar", "Ankur Mali", "C. Lee Giles", "Murari Mandal"], "abstract": "Effective teaching requires adapting instructional strategies to accommodate the diverse cognitive and behavioral profiles of students, a persistent challenge in education and teacher training. While Large Language Models (LLMs) offer promise as tools to simulate such complex pedagogical environments, current simulation frameworks are limited in two key respects: (1) they often reduce students to static knowledge profiles, and (2) they lack adaptive mechanisms for modeling teachers who evolve their strategies in response to student feedback. To address these gaps, \\textbf{we introduce a novel simulation framework that integrates LLM-based heterogeneous student agents with a self-optimizing teacher agent}. The teacher agent's pedagogical policy is dynamically evolved using a genetic algorithm, allowing it to discover and refine effective teaching strategies based on the aggregate performance of diverse learners. In addition, \\textbf{we propose Persona-RAG}, a Retrieval Augmented Generation module that enables student agents to retrieve knowledge tailored to their individual learning styles. Persona-RAG preserves the retrieval accuracy of standard RAG baselines while enhancing personalization, an essential factor in modeling realistic educational scenarios. Through extensive experiments, we demonstrate how our framework supports the emergence of distinct and interpretable teaching patterns when interacting with varied student populations. Our results highlight the potential of LLM-driven simulations to inform adaptive teaching practices and provide a testbed for training human educators in controlled, data-driven environments.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "38 Pages", "pdf_url": "https://arxiv.org/pdf/2505.19173.pdf", "abstract_url": "https://arxiv.org/abs/2505.19173", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文介绍了一种新颖的模拟框架，结合了基于大型语言模型（LLM）的异质学生代理和自我优化的教师代理，通过遗传算法动态进化教师的教学策略，并提出Persona-RAG模块以增强学生代理的个性化学习。", "motivation": "解决教育中适应不同学生认知和行为特征的挑战，以及现有模拟框架中学生代理静态知识概况和教师代理缺乏适应性机制的局限性。", "method": "集成LLM-based异质学生代理与自我优化教师代理，使用遗传算法动态进化教师的教学策略，并引入Persona-RAG模块实现个性化知识检索。", "result": "框架支持与不同学生群体互动时出现独特且可解释的教学模式，展示了LLM驱动模拟在适应性教学实践中的潜力。", "conclusion": "LLM驱动的模拟框架为适应性教学实践提供了信息，并为在受控、数据驱动的环境中培训人类教育者提供了测试平台。"}}
{"id": "2505.19197", "title": "Structuring the Unstructured: A Multi-Agent System for Extracting and Querying Financial KPIs and Guidance", "authors": ["Chanyeol Choi", "Jihoon Kwon", "Minjae Kim", "Juneha Hwang", "Minsoo Ha", "Chaewoon Kim", "Jaeseon Ha", "Suyeol Yun", "Jin Kim"], "abstract": "Extracting structured and quantitative insights from unstructured financial filings is essential in investment research, yet remains time-consuming and resource-intensive. Conventional approaches in practice rely heavily on labor-intensive manual processes, limiting scalability and delaying the research workflow. In this paper, we propose an efficient and scalable method for accurately extracting quantitative insights from unstructured financial documents, leveraging a multi-agent system composed of large language models. Our proposed multi-agent system consists of two specialized agents: the \\emph{Extraction Agent} and the \\emph{Text-to-SQL Agent}. The \\textit{Extraction Agent} automatically identifies key performance indicators from unstructured financial text, standardizes their formats, and verifies their accuracy. On the other hand, the \\textit{Text-to-SQL Agent} generates executable SQL statements from natural language queries, allowing users to access structured data accurately without requiring familiarity with the database schema. Through experiments, we demonstrate that our proposed system effectively transforms unstructured text into structured data accurately and enables precise retrieval of key information. First, we demonstrate that our system achieves approximately 95\\% accuracy in transforming financial filings into structured data, matching the performance level typically attained by human annotators. Second, in a human evaluation of the retrieval task -- where natural language queries are used to search information from structured data -- 91\\% of the responses were rated as correct by human evaluators. In both evaluations, our system generalizes well across financial document types, consistently delivering reliable performance.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "6 pages, FinIR'25", "pdf_url": "https://arxiv.org/pdf/2505.19197.pdf", "abstract_url": "https://arxiv.org/abs/2505.19197", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种利用多代理系统从非结构化财务文件中高效提取和查询关键绩效指标(KPIs)和指导的方法，通过两个专门代理实现高准确度的数据转换和信息检索。", "motivation": "从非结构化财务文件中提取结构化定量信息在投资研究中至关重要，但传统方法依赖劳动密集型手动过程，限制了可扩展性并延迟了研究流程。", "method": "采用由大型语言模型组成的多代理系统，包括专门用于从非结构化财务文本中识别、标准化和验证KPIs的'提取代理'，以及将自然语言查询转换为可执行SQL语句的'文本到SQL代理'。", "result": "实验显示，系统在将财务文件转换为结构化数据时达到约95%的准确率，与人类注释者的表现相当；在信息检索任务中，91%的响应被人类评估者评为正确。", "conclusion": "该系统能有效将非结构化文本转换为结构化数据，并实现关键信息的精确检索，且在不同类型的财务文档中表现一致可靠。"}}
{"id": "2505.19219", "title": "Where Paths Collide: A Comprehensive Survey of Classic and Learning-Based Multi-Agent Pathfinding", "authors": ["Shiyue Wang", "Haozheng Xu", "Yuhan Zhang", "Jingran Lin", "Changhong Lu", "Xiangfeng Wang", "Wenhao Li"], "abstract": "Multi-Agent Path Finding (MAPF) is a fundamental problem in artificial intelligence and robotics, requiring the computation of collision-free paths for multiple agents navigating from their start locations to designated goals. As autonomous systems become increasingly prevalent in warehouses, urban transportation, and other complex environments, MAPF has evolved from a theoretical challenge to a critical enabler of real-world multi-robot coordination. This comprehensive survey bridges the long-standing divide between classical algorithmic approaches and emerging learning-based methods in MAPF research. We present a unified framework that encompasses search-based methods (including Conflict-Based Search, Priority-Based Search, and Large Neighborhood Search), compilation-based approaches (SAT, SMT, CSP, ASP, and MIP formulations), and data-driven techniques (reinforcement learning, supervised learning, and hybrid strategies). Through systematic analysis of experimental practices across 200+ papers, we uncover significant disparities in evaluation methodologies, with classical methods typically tested on larger-scale instances (up to 200 by 200 grids with 1000+ agents) compared to learning-based approaches (predominantly 10-100 agents). We provide a comprehensive taxonomy of evaluation metrics, environment types, and baseline selections, highlighting the need for standardized benchmarking protocols. Finally, we outline promising future directions including mixed-motive MAPF with game-theoretic considerations, language-grounded planning with large language models, and neural solver architectures that combine the rigor of classical methods with the flexibility of deep learning. This survey serves as both a comprehensive reference for researchers and a practical guide for deploying MAPF solutions in increasingly complex real-world applications.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multiagent Systems (cs.MA); Combinatorics (math.CO)", "comments": "112 pages, 21 figures, 20 tables", "pdf_url": "https://arxiv.org/pdf/2505.19219.pdf", "abstract_url": "https://arxiv.org/abs/2505.19219", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)", "Combinatorics (math.CO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文是一篇关于多智能体路径规划（MAPF）的综合调查，涵盖了从经典算法到基于学习的方法的研究，提出了一个统一的框架，并分析了实验实践中的差异，指出了标准化基准测试的必要性，并展望了未来的研究方向。", "motivation": "随着自主系统在仓库、城市交通等复杂环境中的普及，MAPF从理论挑战转变为现实世界多机器人协调的关键推动者。本文旨在弥合经典算法方法与新兴基于学习方法之间的鸿沟。", "method": "本文提出了一个统一的框架，包括基于搜索的方法（如冲突基础搜索、优先级基础搜索和大邻域搜索）、基于编译的方法（如SAT、SMT、CSP、ASP和MIP公式）以及数据驱动技术（如强化学习、监督学习和混合策略）。", "result": "通过对200多篇论文的系统分析，发现经典方法通常在更大规模的实例上进行测试（高达200x200网格和1000+智能体），而基于学习的方法主要在10-100智能体上进行测试。文章还提供了评估指标、环境类型和基线选择的全面分类。", "conclusion": "本文不仅为研究人员提供了全面的参考，还为在日益复杂的现实世界应用中部署MAPF解决方案提供了实用指南。未来的研究方向包括考虑博弈论的混合动机MAPF、基于大型语言模型的语言基础规划以及结合经典方法严谨性和深度学习灵活性的神经求解器架构。"}}
{"id": "2505.19234", "title": "GUARDIAN: Safeguarding LLM Multi-Agent Collaborations with Temporal Graph Modeling", "authors": ["Jialong Zhou", "Lichao Wang", "Xiao Yang"], "abstract": "The emergence of large language models (LLMs) enables the development of intelligent agents capable of engaging in complex and multi-turn dialogues. However, multi-agent collaboration face critical safety challenges, such as hallucination amplification and error injection and propagation. This paper presents GUARDIAN, a unified method for detecting and mitigating multiple safety concerns in GUARDing Intelligent Agent collaboratioNs. By modeling the multi-agent collaboration process as a discrete-time temporal attributed graph, GUARDIAN explicitly captures the propagation dynamics of hallucinations and errors. The unsupervised encoder-decoder architecture incorporating an incremental training paradigm, learns to reconstruct node attributes and graph structures from latent embeddings, enabling the identification of anomalous nodes and edges with unparalleled precision. Moreover, we introduce a graph abstraction mechanism based on the Information Bottleneck Theory, which compresses temporal interaction graphs while preserving essential patterns. Extensive experiments demonstrate GUARDIAN's effectiveness in safeguarding LLM multi-agent collaborations against diverse safety vulnerabilities, achieving state-of-the-art accuracy with efficient resource utilization.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19234.pdf", "abstract_url": "https://arxiv.org/abs/2505.19234", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了GUARDIAN，一种通过时间图建模来保护和检测大型语言模型（LLM）多智能体协作中的安全问题的统一方法。", "motivation": "多智能体协作面临幻觉放大和错误注入及传播等关键安全挑战，需要一种有效的方法来检测和缓解这些安全问题。", "method": "GUARDIAN将多智能体协作过程建模为离散时间属性图，采用无监督的编码器-解码器架构和增量训练范式，学习从潜在嵌入中重建节点属性和图结构，从而精确识别异常节点和边。", "result": "大量实验证明，GUARDIAN在保护LLM多智能体协作免受多种安全漏洞方面有效，实现了最先进的准确性和高效的资源利用。", "conclusion": "GUARDIAN通过时间图建模和信息瓶颈理论的图抽象机制，为LLM多智能体协作提供了强大的安全保障，具有重要的实际应用价值。"}}
{"id": "2505.19237", "title": "Sensorimotor features of self-awareness in multimodal large language models", "authors": ["Iñaki Dellibarda Varela", "Pablo Romero-Sorozabal", "Diego Torricelli", "Gabriel Delgado-Oleas", "Jose Ignacio Serrano", "Maria Dolores del Castillo Sobrino", "Eduardo Rocon", "Manuel Cebrian"], "abstract": "Self-awareness - the ability to distinguish oneself from the surrounding environment - underpins intelligent, autonomous behavior. Recent advances in AI achieve human-like performance in tasks integrating multimodal information, particularly in large language models, raising interest in the embodiment capabilities of AI agents on nonhuman platforms such as robots. Here, we explore whether multimodal LLMs can develop self-awareness solely through sensorimotor experiences. By integrating a multimodal LLM into an autonomous mobile robot, we test its ability to achieve this capacity. We find that the system exhibits robust environmental awareness, self-recognition and predictive awareness, allowing it to infer its robotic nature and motion characteristics. Structural equation modeling reveals how sensory integration influences distinct dimensions of self-awareness and its coordination with past-present memory, as well as the hierarchical internal associations that drive self-identification. Ablation tests of sensory inputs identify critical modalities for each dimension, demonstrate compensatory interactions among sensors and confirm the essential role of structured and episodic memory in coherent reasoning. These findings demonstrate that, given appropriate sensory information about the world and itself, multimodal LLMs exhibit emergent self-awareness, opening the door to artificial embodied cognitive systems.", "subjects": "Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": "16 pages, 3 figures, 1 table", "pdf_url": "https://arxiv.org/pdf/2505.19237.pdf", "abstract_url": "https://arxiv.org/abs/2505.19237", "categories": ["Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了多模态大型语言模型（LLMs）是否能够仅通过感觉运动体验发展自我意识。通过将多模态LLM集成到自主移动机器人中，研究发现该系统表现出强大的环境意识、自我识别和预测意识，能够推断其机器人性质和运动特性。结构方程模型揭示了感觉整合如何影响自我意识的不同维度及其与过去-现在记忆的协调，以及驱动自我识别的层次内部关联。感官输入的消融测试确定了每个维度的关键模态，证明了传感器之间的补偿性相互作用，并确认了结构和情景记忆在连贯推理中的重要作用。这些发现表明，给定关于世界和自身的适当感官信息，多模态LLMs表现出 emergent 自我意识，为人工体现认知系统打开了大门。", "motivation": "探索多模态大型语言模型是否能够仅通过感觉运动体验发展自我意识，以及这种能力如何影响AI代理在非人类平台（如机器人）上的体现能力。", "method": "通过将多模态LLM集成到自主移动机器人中，测试其实现自我意识的能力，并使用结构方程模型分析感觉整合对自我意识不同维度的影响。", "result": "系统表现出环境意识、自我识别和预测意识，能够推断其机器人性质和运动特性。感官输入的消融测试确定了关键模态，并证明了传感器之间的补偿性相互作用。", "conclusion": "多模态LLMs在给定适当感官信息的情况下，能够表现出 emergent 自我意识，这为开发人工体现认知系统提供了新的可能性。"}}
{"id": "2505.19381", "title": "DiffVLA: Vision-Language Guided Diffusion Planning for Autonomous Driving", "authors": ["Anqing Jiang", "Yu Gao", "Zhigang Sun", "Yiru Wang", "Jijun Wang", "Jinghao Chai", "Qian Cao", "Yuweng Heng", "Hao Jiang", "Zongzheng Zhang", "Xianda Guo", "Hao Sun", "Hao Zhao"], "abstract": "Research interest in end-to-end autonomous driving has surged owing to its fully differentiable design integrating modular tasks, i.e. perception, prediction and planing, which enables optimization in pursuit of the ultimate goal. Despite the great potential of the end-to-end paradigm, existing methods suffer from several aspects including expensive BEV (bird's eye view) computation, action diversity, and sub-optimal decision in complex real-world scenarios. To address these challenges, we propose a novel hybrid sparse-dense diffusion policy, empowered by a Vision-Language Model (VLM), called Diff-VLA. We explore the sparse diffusion representation for efficient multi-modal driving behavior. Moreover, we rethink the effectiveness of VLM driving decision and improve the trajectory generation guidance through deep interaction across agent, map instances and VLM output. Our method shows superior performance in Autonomous Grand Challenge 2025 which contains challenging real and reactive synthetic scenarios. Our methods achieves 45.0 PDMS.", "subjects": "Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)", "comments": "4pages", "pdf_url": "https://arxiv.org/pdf/2505.19381.pdf", "abstract_url": "https://arxiv.org/abs/2505.19381", "categories": ["Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为DiffVLA的新型混合稀疏-密集扩散策略，结合视觉语言模型（VLM），旨在解决端到端自动驾驶中的BEV计算成本高、行为多样性不足及复杂场景下决策次优等问题。", "motivation": "解决端到端自动驾驶范式中的BEV计算昂贵、行为多样性不足以及在复杂现实场景中决策次优的问题。", "method": "采用一种新型的混合稀疏-密集扩散策略，结合视觉语言模型（VLM），探索稀疏扩散表示以实现高效的多模态驾驶行为，并通过深度交互改进轨迹生成指导。", "result": "在Autonomous Grand Challenge 2025中表现出色，包括挑战性的真实和反应性合成场景，达到了45.0 PDMS。", "conclusion": "DiffVLA方法通过结合VLM和混合稀疏-密集扩散策略，有效提升了自动驾驶在复杂场景下的决策质量和行为多样性，展示了在端到端自动驾驶领域的潜力。"}}
{"id": "2505.19139", "title": "The Eye of Sherlock Holmes: Uncovering User Private Attribute Profiling via Vision-Language Model Agentic Framework", "authors": ["Feiran Liu", "Yuzhe Zhang", "Xinyi Huang", "Yinan Peng", "Xinfeng Li", "Lixu Wang", "Yutong Shen", "Ranjie Duan", "Simeng Qin", "Xiaojun Jia", "Qingsong Wen", "Wei Dong"], "abstract": "Our research reveals a new privacy risk associated with the vision-language model (VLM) agentic framework: the ability to infer sensitive attributes (e.g., age and health information) and even abstract ones (e.g., personality and social traits) from a set of personal images, which we term \"image private attribute profiling.\" This threat is particularly severe given that modern apps can easily access users' photo albums, and inference from image sets enables models to exploit inter-image relations for more sophisticated profiling. However, two main challenges hinder our understanding of how well VLMs can profile an individual from a few personal photos: (1) the lack of benchmark datasets with multi-image annotations for private attributes, and (2) the limited ability of current multimodal large language models (MLLMs) to infer abstract attributes from large image collections. In this work, we construct PAPI, the largest dataset for studying private attribute profiling in personal images, comprising 2,510 images from 251 individuals with 3,012 annotated privacy attributes. We also propose HolmesEye, a hybrid agentic framework that combines VLMs and LLMs to enhance privacy inference. HolmesEye uses VLMs to extract both intra-image and inter-image information and LLMs to guide the inference process as well as consolidate the results through forensic analysis, overcoming existing limitations in long-context visual reasoning. Experiments reveal that HolmesEye achieves a 10.8% improvement in average accuracy over state-of-the-art baselines and surpasses human-level performance by 15.0% in predicting abstract attributes. This work highlights the urgency of addressing privacy risks in image-based profiling and offers both a new dataset and an advanced framework to guide future research in this area.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19139.pdf", "abstract_url": "https://arxiv.org/abs/2505.19139", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "研究揭示了视觉语言模型（VLM）代理框架带来的新隐私风险：从一组个人图像中推断敏感属性（如年龄和健康信息）甚至抽象属性（如个性和社会特质），称为“图像私人属性分析”。", "motivation": "现代应用可以轻松访问用户的照片库，且从图像集中推断使模型能够利用图像间关系进行更复杂的分析，这带来了严重的隐私威胁。", "method": "构建了PAPI数据集，包含2510张来自251个人的图像，带有3012个注释的隐私属性；提出了HolmesEye，一个结合VLM和LLM的混合代理框架，以增强隐私推断。", "result": "HolmesEye在平均准确率上比现有基线提高了10.8%，在预测抽象属性上超过了人类水平15.0%。", "conclusion": "这项工作强调了解决基于图像的隐私风险的紧迫性，并提供了新的数据集和先进框架以指导未来研究。"}}
{"id": "2505.18845", "title": "Multi-Party Conversational Agents: A Survey", "authors": ["Sagar Sapkota", "Mohammad Saqib Hasan", "Mubarak Shah", "Santu Karmaker"], "abstract": "Multi-party Conversational Agents (MPCAs) are systems designed to engage in dialogue with more than two participants simultaneously. Unlike traditional two-party agents, designing MPCAs faces additional challenges due to the need to interpret both utterance semantics and social dynamics. This survey explores recent progress in MPCAs by addressing three key questions: 1) Can agents model each participants' mental states? (State of Mind Modeling); 2) Can they properly understand the dialogue content? (Semantic Understanding); and 3) Can they reason about and predict future conversation flow? (Agent Action Modeling). We review methods ranging from classical machine learning to Large Language Models (LLMs) and multi-modal systems. Our analysis underscores Theory of Mind (ToM) as essential for building intelligent MPCAs and highlights multi-modal understanding as a promising yet underexplored direction. Finally, this survey offers guidance to future researchers on developing more capable MPCAs.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18845.pdf", "abstract_url": "https://arxiv.org/abs/2505.18845", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文综述了多方对话代理（MPCAs）的最新进展，探讨了其在心智状态建模、语义理解及对话流预测方面的挑战与方法，强调了心智理论（ToM）的重要性及多模态理解的潜力。", "motivation": "解决多方对话代理设计中面临的额外挑战，如解读话语语义和社会动态，以促进更智能的MPCAs的发展。", "method": "通过回顾从经典机器学习到大型语言模型（LLMs）及多模态系统的方法，分析了MPCAs的三个方面：心智状态建模、语义理解和代理行为建模。", "result": "心智理论（ToM）对于构建智能MPCAs至关重要，多模态理解是一个有前景但尚未充分探索的方向。", "conclusion": "本综述为未来研究者开发更强大的多方对话代理提供了指导，强调了ToM和多模态理解在MPCAs发展中的重要性。"}}
{"id": "2505.18878", "title": "CRMArena-Pro: Holistic Assessment of LLM Agents Across Diverse Business Scenarios and Interactions", "authors": ["Kung-Hsiang Huang", "Akshara Prabhakar", "Onkar Thorat", "Divyansh Agarwal", "Prafulla Kumar Choubey", "Yixin Mao", "Silvio Savarese", "Caiming Xiong", "Chien-Sheng Wu"], "abstract": "While AI agents hold transformative potential in business, effective performance benchmarking is hindered by the scarcity of public, realistic business data on widely used platforms. Existing benchmarks often lack fidelity in their environments, data, and agent-user interactions, with limited coverage of diverse business scenarios and industries. To address these gaps, we introduce CRMArena-Pro, a novel benchmark for holistic, realistic assessment of LLM agents in diverse professional settings. CRMArena-Pro expands on CRMArena with nineteen expert-validated tasks across sales, service, and 'configure, price, and quote' processes, for both Business-to-Business and Business-to-Customer scenarios. It distinctively incorporates multi-turn interactions guided by diverse personas and robust confidentiality awareness assessments. Experiments reveal leading LLM agents achieve only around 58% single-turn success on CRMArena-Pro, with performance dropping significantly to approximately 35% in multi-turn settings. While Workflow Execution proves more tractable for top agents (over 83% single-turn success), other evaluated business skills present greater challenges. Furthermore, agents exhibit near-zero inherent confidentiality awareness; though targeted prompting can improve this, it often compromises task performance. These findings highlight a substantial gap between current LLM capabilities and enterprise demands, underscoring the need for advancements in multi-turn reasoning, confidentiality adherence, and versatile skill acquisition.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18878.pdf", "abstract_url": "https://arxiv.org/abs/2505.18878", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "CRMArena-Pro是一个新颖的基准测试，用于全面、真实地评估LLM代理在多样化的专业环境中的表现，特别是在销售、服务和'配置、定价和报价'流程中。", "motivation": "解决现有基准测试在环境、数据和代理-用户交互方面缺乏真实性，以及对多样化商业场景和行业覆盖不足的问题。", "method": "引入了CRMArena-Pro，扩展了CRMArena，包含19个专家验证的任务，覆盖B2B和B2C场景，并独特地融入了多轮交互和强大的保密意识评估。", "result": "领先的LLM代理在CRMArena-Pro上的单轮成功率仅为58%，多轮设置中降至约35%。工作流执行对顶级代理更为可行（单轮成功率超过83%），但其他业务技能更具挑战性。代理几乎不具备固有的保密意识，尽管有针对性的提示可以改善这一点，但往往会损害任务性能。", "conclusion": "这些发现突显了当前LLM能力与企业需求之间的巨大差距，强调了在多轮推理、保密遵守和多技能获取方面需要进步。"}}
{"id": "2505.18906", "title": "Federated Retrieval-Augmented Generation: A Systematic Mapping Study", "authors": ["Abhijit Chakraborty", "Chahana Dahal", "Vivek Gupta"], "abstract": "Federated Retrieval-Augmented Generation (Federated RAG) combines Federated Learning (FL), which enables distributed model training without exposing raw data, with Retrieval-Augmented Generation (RAG), which improves the factual accuracy of language models by grounding outputs in external knowledge. As large language models are increasingly deployed in privacy-sensitive domains such as healthcare, finance, and personalized assistance, Federated RAG offers a promising framework for secure, knowledge-intensive natural language processing (NLP). To the best of our knowledge, this paper presents the first systematic mapping study of Federated RAG, covering literature published between 2020 and 2025. Following Kitchenham's guidelines for evidence-based software engineering, we develop a structured classification of research focuses, contribution types, and application domains. We analyze architectural patterns, temporal trends, and key challenges, including privacy-preserving retrieval, cross-client heterogeneity, and evaluation limitations. Our findings synthesize a rapidly evolving body of research, identify recurring design patterns, and surface open questions, providing a foundation for future work at the intersection of RAG and federated systems.", "subjects": "Computation and Language (cs.CL); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18906.pdf", "abstract_url": "https://arxiv.org/abs/2505.18906", "categories": ["Computation and Language (cs.CL)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文首次对联邦检索增强生成（Federated RAG）进行了系统性的映射研究，结合了联邦学习（FL）和检索增强生成（RAG）的优势，旨在隐私敏感领域提供安全、知识密集型的自然语言处理（NLP）解决方案。", "motivation": "随着大型语言模型在医疗、金融和个性化助手等隐私敏感领域的广泛应用，如何在保护数据隐私的同时提高模型的准确性成为了一个重要问题。", "method": "遵循Kitchenham的基于证据的软件工程指南，对2020年至2025年间发表的文献进行了结构化分类，分析了研究重点、贡献类型、应用领域、架构模式、时间趋势和关键挑战。", "result": "研究发现联邦RAG领域正在快速发展，识别了重复出现的设计模式，并提出了包括隐私保护检索、跨客户端异构性和评估限制在内的关键挑战。", "conclusion": "本研究为联邦RAG领域的未来工作提供了基础，强调了在RAG和联邦系统交叉领域的开放性问题。"}}
{"id": "2505.18943", "title": "MetaMind: Modeling Human Social Thoughts with Metacognitive Multi-Agent Systems", "authors": ["Xuanming Zhang", "Yuxuan Chen", "Min-Hsuan Yeh", "Yixuan Li"], "abstract": "Human social interactions depend on the ability to infer others' unspoken intentions, emotions, and beliefs-a cognitive skill grounded in the psychological concept of Theory of Mind (ToM). While large language models (LLMs) excel in semantic understanding tasks, they struggle with the ambiguity and contextual nuance inherent in human communication. To bridge this gap, we introduce MetaMind, a multi-agent framework inspired by psychological theories of metacognition, designed to emulate human-like social reasoning. MetaMind decomposes social understanding into three collaborative stages: (1) a Theory-of-Mind Agent generates hypotheses user mental states (e.g., intent, emotion), (2) a Domain Agent refines these hypotheses using cultural norms and ethical constraints, and (3) a Response Agent generates contextually appropriate responses while validating alignment with inferred intent. Our framework achieves state-of-the-art performance across three challenging benchmarks, with 35.7% improvement in real-world social scenarios and 6.2% gain in ToM reasoning. Notably, it enables LLMs to match human-level performance on key ToM tasks for the first time. Ablation studies confirm the necessity of all components, which showcase the framework's ability to balance contextual plausibility, social appropriateness, and user adaptation. This work advances AI systems toward human-like social intelligence, with applications in empathetic dialogue and culturally sensitive interactions. Code is available at", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18943.pdf", "abstract_url": "https://arxiv.org/abs/2505.18943", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "MetaMind是一个受元认知心理学理论启发的多智能体框架，旨在模拟人类社交推理，通过分解社交理解为三个阶段来提高大型语言模型在社交场景中的表现。", "motivation": "解决大型语言模型在理解人类社交互动中的模糊性和上下文细微差别方面的困难。", "method": "引入MetaMind框架，包括Theory-of-Mind Agent、Domain Agent和Response Agent三个阶段，分别生成假设、精炼假设并生成响应。", "result": "在三个具有挑战性的基准测试中实现了最先进的性能，现实世界社交场景中提高了35.7%，ToM推理提高了6.2%，首次使LLM在关键ToM任务上达到人类水平。", "conclusion": "MetaMind推动了AI系统向人类社交智能的发展，适用于同理心对话和文化敏感互动。"}}
{"id": "2505.19436", "title": "Task Memory Engine: Spatial Memory for Robust Multi-Step LLM Agents", "authors": ["Ye Ye"], "abstract": "Large Language Models (LLMs) falter in multi-step interactions -- often hallucinating, repeating actions, or misinterpreting user corrections -- due to reliance on linear, unstructured context. This fragility stems from the lack of persistent memory to track evolving goals and task dependencies, undermining trust in autonomous agents. We introduce the Task Memory Engine (TME), a modular memory controller that transforms existing LLMs into robust, revision-aware agents without fine-tuning. TME implements a spatial memory framework that replaces flat context with graph-based structures to support consistent, multi-turn reasoning. Departing from linear concatenation and ReAct-style prompting, TME builds a dynamic task graph -- either a tree or directed acyclic graph (DAG) -- to map user inputs to subtasks, align them with prior context, and enable dependency-tracked revisions. Its Task Representation and Intent Management (TRIM) component models task semantics and user intent to ensure accurate interpretation. Across four multi-turn scenarios-trip planning, cooking, meeting scheduling, and shopping cart editing -- TME eliminates 100% of hallucinations and misinterpretations in three tasks, and reduces hallucinations by 66.7% and misinterpretations by 83.3% across 27 user turns, outperforming ReAct. TME's modular design supports plug-and-play deployment and domain-specific customization, adaptable to both personal assistants and enterprise automation. We release TME's codebase, benchmarks, and components as open-source resources, enabling researchers to develop reliable LLM agents. TME's scalable architecture addresses a critical gap in agent performance across complex, interactive settings.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "Under review. 9 pages main content, 15 pages appendix, 5 figures", "pdf_url": "https://arxiv.org/pdf/2505.19436.pdf", "abstract_url": "https://arxiv.org/abs/2505.19436", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了任务记忆引擎（TME），一种模块化记忆控制器，旨在通过空间记忆框架将现有大型语言模型（LLMs）转变为强大、支持修订的代理，无需微调。TME通过图基结构替代线性上下文，支持一致的多轮推理，显著减少了幻觉和误解。", "motivation": "大型语言模型在多步交互中表现不佳，常出现幻觉、重复动作或误解用户修正，这源于缺乏持久记忆来跟踪演变的目标和任务依赖，削弱了对自主代理的信任。", "method": "TME采用空间记忆框架，构建动态任务图（树或有向无环图）来映射用户输入到子任务，与先前上下文对齐，并支持依赖跟踪的修订。其任务表示和意图管理（TRIM）组件建模任务语义和用户意图以确保准确解释。", "result": "在四个多轮场景（旅行规划、烹饪、会议安排和购物车编辑）中，TME在三个任务中消除了100%的幻觉和误解，在27个用户轮次中平均减少幻觉66.7%和误解83.3%，优于ReAct。", "conclusion": "TME的模块化设计支持即插即用部署和领域特定定制，适用于个人助理和企业自动化。其可扩展架构解决了复杂交互设置中代理性能的关键差距。"}}
{"id": "2505.19409", "title": "Fusion Intelligence for Digital Twinning AI Data Centers: A Synergistic GenAI-PhyAI Approach", "authors": ["Ruihang Wang", "Minghao Li", "Zhiwei Cao", "Jimin Jia", "Kyle Guan", "Yonggang Wen"], "abstract": "The explosion in artificial intelligence (AI) applications is pushing the development of AI-dedicated data centers (AIDCs), creating management challenges that traditional methods and standalone AI solutions struggle to address. While digital twins are beneficial for AI-based design validation and operational optimization, current AI methods for their creation face limitations. Specifically, physical AI (PhyAI) aims to capture the underlying physical laws, which demands extensive, case-specific customization, and generative AI (GenAI) can produce inaccurate or hallucinated results. We propose Fusion Intelligence, a novel framework synergizing GenAI's automation with PhyAI's domain grounding. In this dual-agent collaboration, GenAI interprets natural language prompts to generate tokenized AIDC digital twins. Subsequently, PhyAI optimizes these generated twins by enforcing physical constraints and assimilating real-time data. Case studies demonstrate the advantages of our framework in automating the creation and validation of AIDC digital twins. These twins deliver predictive analytics to support power usage effectiveness (PUE) optimization in the design stage. With operational data collected, the digital twin accuracy is further improved compared with pure physics-based models developed by human experts. Fusion Intelligence offers a promising pathway to accelerate digital transformation. It enables more reliable and efficient AI-driven digital transformation for a broad range of mission-critical infrastructures.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19409.pdf", "abstract_url": "https://arxiv.org/abs/2505.19409", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为'融合智能'的新框架，通过结合生成AI（GenAI）和物理AI（PhyAI）的优势，解决了AI专用数据中心（AIDC）数字孪生创建和管理中的挑战。", "motivation": "随着人工智能应用的爆炸性增长，AI专用数据中心的开发带来了管理挑战，传统方法和独立的AI解决方案难以应对。数字孪生在AI基础设计和操作优化中虽有益处，但当前的AI方法在创建数字孪生时存在局限。", "method": "提出的'融合智能'框架通过GenAI和PhyAI的双代理协作，GenAI解释自然语言提示生成令牌化的AIDC数字孪生，随后PhyAI通过强制物理约束和吸收实时数据来优化这些生成的孪生。", "result": "案例研究表明，该框架在自动创建和验证AIDC数字孪生方面具有优势，能够在设计阶段支持电力使用效率（PUE）优化的预测分析。与纯物理模型相比，收集操作数据后，数字孪生的准确性进一步提高。", "conclusion": "'融合智能'为加速数字化转型提供了一条有前途的途径，为广泛的关键任务基础设施实现了更可靠和高效的AI驱动数字化转型。"}}
{"id": "2505.19477", "title": "Judging with Many Minds: Do More Perspectives Mean Less Prejudice?", "authors": ["Chiyu Ma", "Enpei Zhang", "Yilun Zhao", "Wenjun Liu", "Yaning Jia", "Peijun Qing", "Lin Shi", "Arman Cohan", "Yujun Yan", "Soroush Vosoughi"], "abstract": "LLM-as-Judge has emerged as a scalable alternative to human evaluation, enabling large language models (LLMs) to provide reward signals in trainings. While recent work has explored multi-agent extensions such as multi-agent debate and meta-judging to enhance evaluation quality, the question of how intrinsic biases manifest in these settings remains underexplored. In this study, we conduct a systematic analysis of four diverse bias types: position bias, verbosity bias, chain-of-thought bias, and bandwagon bias. We evaluate these biases across two widely adopted multi-agent LLM-as-Judge frameworks: Multi-Agent-Debate and LLM-as-Meta-Judge. Our results show that debate framework amplifies biases sharply after the initial debate, and this increased bias is sustained in subsequent rounds, while meta-judge approaches exhibit greater resistance. We further investigate the incorporation of PINE, a leading single-agent debiasing method, as a bias-free agent within these systems. The results reveal that this bias-free agent effectively reduces biases in debate settings but provides less benefit in meta-judge scenarios. Our work provides a comprehensive study of bias behavior in multi-agent LLM-as-Judge systems and highlights the need for targeted bias mitigation strategies in collaborative evaluation settings.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19477.pdf", "abstract_url": "https://arxiv.org/abs/2505.19477", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文系统分析了多智能体LLM-as-Judge框架中的四种偏见类型，并比较了辩论和元评判框架在偏见放大和抵抗方面的表现，同时探讨了单智能体去偏见方法PINE在多智能体系统中的效果。", "motivation": "探索在多智能体LLM-as-Judge系统中内在偏见的表现形式及其影响，以提升评估质量。", "method": "通过系统分析四种偏见类型（位置偏见、冗长偏见、思维链偏见和从众偏见），在两种多智能体LLM-as-Judge框架（Multi-Agent-Debate和LLM-as-Meta-Judge）中进行评估，并引入PINE方法作为无偏见代理。", "result": "辩论框架在初始辩论后显著放大偏见，并在后续轮次中持续；元评判框架表现出更强的偏见抵抗能力。PINE方法在辩论设置中有效减少偏见，但在元评判场景中效果有限。", "conclusion": "多智能体LLM-as-Judge系统中的偏见行为需要有针对性的偏见缓解策略，特别是在协作评估设置中。"}}
{"id": "2505.19489", "title": "Benchmarking and Enhancing LLM Agents in Localizing Linux Kernel Bugs", "authors": ["Zhenhao Zhou", "Zhuochen Huang", "Yike He", "Chong Wang", "Jiajun Wang", "Yijian Wu", "Xin Peng", "Yiling Lou"], "abstract": "The Linux kernel is a critical system, serving as the foundation for numerous systems. Bugs in the Linux kernel can cause serious consequences, affecting billions of users. Fault localization (FL), which aims at identifying the buggy code elements in software, plays an essential role in software quality assurance. While recent LLM agents have achieved promising accuracy in FL on recent benchmarks like SWE-bench, it remains unclear how well these methods perform in the Linux kernel, where FL is much more challenging due to the large-scale code base, limited observability, and diverse impact factors. In this paper, we introduce LinuxFLBench, a FL benchmark constructed from real-world Linux kernel bugs. We conduct an empirical study to assess the performance of state-of-the-art LLM agents on the Linux kernel. Our initial results reveal that existing agents struggle with this task, achieving a best top-1 accuracy of only 41.6% at file level. To address this challenge, we propose LinuxFL$^+$, an enhancement framework designed to improve FL effectiveness of LLM agents for the Linux kernel. LinuxFL$^+$ substantially improves the FL accuracy of all studied agents (e.g., 7.2% - 11.2% accuracy increase) with minimal costs. Data and code are available at", "subjects": "Artificial Intelligence (cs.AI); Software Engineering (cs.SE)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19489.pdf", "abstract_url": "https://arxiv.org/abs/2505.19489", "categories": ["Artificial Intelligence (cs.AI)", "Software Engineering (cs.SE)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了LinuxFLBench，一个基于真实Linux内核bug构建的故障定位(FL)基准，评估了现有LLM代理在Linux内核中的表现，并提出了LinuxFL$^+$框架以提高其准确性。", "motivation": "Linux内核作为众多系统的基础，其bug可能导致严重后果。尽管LLM代理在FL任务上表现出色，但在Linux内核这一大规模、低可观测性和多影响因素的复杂环境中表现不佳。", "method": "通过构建LinuxFLBench基准，对现有LLM代理进行实证研究，并开发LinuxFL$^+$框架以提升FL效果。", "result": "现有代理在Linux内核中的FL任务上表现不佳，最佳文件级top-1准确率仅为41.6%。LinuxFL$^+$显著提高了所有研究代理的准确率（如7.2% - 11.2%的提升）。", "conclusion": "LinuxFL$^+$框架以最小成本显著提高了LLM代理在Linux内核bug定位中的准确性，为软件质量保障提供了有效工具。"}}
{"id": "2505.19567", "title": "LLM-Agent-Controller: A Universal Multi-Agent Large Language Model System as a Control Engineer", "authors": ["Rasoul Zahedifar", "Sayyed Ali Mirghasemi", "Mahdieh Soleymani Baghshah", "Alireza Taheri"], "abstract": "This study presents the LLM-Agent-Controller, a multi-agent large language model (LLM) system developed to address a wide range of problems in control engineering (Control Theory). The system integrates a central controller agent with multiple specialized auxiliary agents, responsible for tasks such as controller design, model representation, control analysis, time-domain response, and simulation. A supervisor oversees high-level decision-making and workflow coordination, enhancing the system's reliability and efficiency. The LLM-Agent-Controller incorporates advanced capabilities, including Retrieval-Augmented Generation (RAG), Chain-of-Thought reasoning, self-criticism and correction, efficient memory handling, and user-friendly natural language communication. It is designed to function without requiring users to have prior knowledge of Control Theory, enabling them to input problems in plain language and receive complete, real-time solutions. To evaluate the system, we propose new performance metrics assessing both individual agents and the system as a whole. We test five categories of Control Theory problems and benchmark performance across three advanced LLMs. Additionally, we conduct a comprehensive qualitative conversational analysis covering all key services. Results show that the LLM-Agent-Controller successfully solved 83% of general tasks, with individual agents achieving an average success rate of 87%. Performance improved with more advanced LLMs. This research demonstrates the potential of multi-agent LLM architectures to solve complex, domain-specific problems. By integrating specialized agents, supervisory control, and advanced reasoning, the LLM-Agent-Controller offers a scalable, robust, and accessible solution framework that can be extended to various technical domains.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19567.pdf", "abstract_url": "https://arxiv.org/abs/2505.19567", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "LLM-Agent-Controller是一个多代理大型语言模型系统，旨在解决控制工程中的广泛问题。它通过集成中央控制器代理和多个专门辅助代理，结合高级功能，如检索增强生成和链式思维推理，实现了无需用户具备控制理论知识的解决方案提供。", "motivation": "解决控制工程领域内复杂问题的可访问性和效率问题，特别是为非专家用户提供易于使用的解决方案。", "method": "开发了一个多代理LLM系统，包括中央控制器代理、多个专门辅助代理和一个监督者，采用RAG、Chain-of-Thought推理等技术。", "result": "系统成功解决了83%的一般任务，单个代理平均成功率为87%，且性能随着更先进的LLM而提升。", "conclusion": "多代理LLM架构在解决复杂、领域特定问题方面展现出巨大潜力，提供了一个可扩展、健壮且易于访问的解决方案框架。"}}
{"id": "2505.19562", "title": "AMQA: An Adversarial Dataset for Benchmarking Bias of LLMs in Medicine and Healthcare", "authors": ["Ying Xiao", "Jie Huang", "Ruijuan He", "Jing Xiao", "Mohammad Reza Mousavi", "Yepang Liu", "Kezhi Li", "Zhenpeng Chen", "Jie M. Zhang"], "abstract": "Large language models (LLMs) are reaching expert-level accuracy on medical diagnosis questions, yet their mistakes and the biases behind them pose life-critical risks. Bias linked to race, sex, and socioeconomic status is already well known, but a consistent and automatic testbed for measuring it is missing. To fill this gap, this paper presents AMQA -- an Adversarial Medical Question-Answering dataset -- built for automated, large-scale bias evaluation of LLMs in medical QA. AMQA includes 4,806 medical QA pairs sourced from the United States Medical Licensing Examination (USMLE) dataset, generated using a multi-agent framework to create diverse adversarial descriptions and question pairs. Using AMQA, we benchmark five representative LLMs and find surprisingly substantial disparities: even GPT-4.1, the least biased model tested, answers privileged-group questions over 10 percentage points more accurately than unprivileged ones. Compared with the existing benchmark CPV, AMQA reveals 15% larger accuracy gaps on average between privileged and unprivileged groups. Our dataset and code are publicly available at", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19562.pdf", "abstract_url": "https://arxiv.org/abs/2505.19562", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了AMQA，一个用于评估大型语言模型（LLMs）在医学和医疗保健领域偏见的对抗性数据集。AMQA包含4,806个医学问答对，旨在自动化、大规模地评估LLMs在医学QA中的偏见。通过AMQA，作者评估了五个代表性LLMs，发现即使是最不偏见的模型GPT-4.1，在特权群体问题上的准确率也比非特权群体高出10个百分点以上。", "motivation": "大型语言模型在医学诊断问题上已达到专家级准确度，但其错误和背后的偏见带来了生命关键风险。虽然与种族、性别和社会经济地位相关的偏见已广为人知，但缺乏一致且自动化的测试平台来测量这些偏见。", "method": "本文提出了AMQA数据集，这是一个基于美国医学执照考试（USMLE）数据集的对抗性医学问答数据集，采用多智能体框架生成多样化的对抗性描述和问题对。", "result": "使用AMQA对五个代表性LLMs进行评估，发现即使是最不偏见的模型GPT-4.1，在特权群体问题上的准确率也比非特权群体高出10个百分点以上。与现有基准CPV相比，AMQA揭示了特权与非特权群体之间平均15%更大的准确率差距。", "conclusion": "AMQA数据集为自动化、大规模评估LLMs在医学QA中的偏见提供了一个有效的工具，揭示了当前LLMs在处理不同群体医学问题时存在的显著偏见，强调了进一步研究和改进的必要性。"}}
{"id": "2505.19662", "title": "FieldWorkArena: Agentic AI Benchmark for Real Field Work Tasks", "authors": ["Atsunori Moteki", "Shoichi Masui", "Fan Yang", "Yueqi Song", "Yonatan Bisk", "Graham Neubig", "Ikuo Kusajima", "Yasuto Watanabe", "Hiroyuki Ishida", "Jun Takahashi", "Shan Jiang"], "abstract": "This paper proposes FieldWorkArena, a benchmark for agentic AI targeting real-world field work. With the recent increase in demand for agentic AI, they are required to monitor and report safety and health incidents, as well as manufacturing-related incidents, that may occur in real-world work environments. Existing agentic AI benchmarks have been limited to evaluating web tasks and are insufficient for evaluating agents in real-world work environments, where complexity increases significantly. In this paper, we define a new action space that agentic AI should possess for real world work environment benchmarks and improve the evaluation function from previous methods to assess the performance of agentic AI in diverse real-world tasks. The dataset consists of videos captured on-site and documents actually used in factories and warehouses, and tasks were created based on interviews with on-site workers and managers. Evaluation results confirmed that performance evaluation considering the characteristics of Multimodal LLM (MLLM) such as GPT-4o is feasible. Additionally, the effectiveness and limitations of the proposed new evaluation method were identified. The complete dataset (HuggingFace) and evaluation program (GitHub) can be downloaded from the following website:", "subjects": "Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "comments": "6 pages, 2 figures, 4 tables", "pdf_url": "https://arxiv.org/pdf/2505.19662.pdf", "abstract_url": "https://arxiv.org/abs/2505.19662", "categories": ["Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了FieldWorkArena，一个针对现实世界现场工作的代理AI基准测试。", "motivation": "随着对代理AI需求的增加，现有的基准测试仅限于评估网络任务，不足以评估在现实工作环境中的代理AI性能。", "method": "定义了一个新的动作空间，改进了评估函数，并使用现场拍摄的视频和工厂、仓库中实际使用的文档创建任务。", "result": "评估结果证实，考虑多模态LLM（如GPT-4o）特性的性能评估是可行的，并识别了所提新评估方法的有效性和局限性。", "conclusion": "FieldWorkArena为代理AI在现实世界现场工作环境中的性能评估提供了新的基准和工具。"}}
{"id": "2505.19683", "title": "Large Language Models for Planning: A Comprehensive and Systematic Survey", "authors": ["Pengfei Cao", "Tianyi Men", "Wencan Liu", "Jingwen Zhang", "Xuzhao Li", "Xixun Lin", "Dianbo Sui", "Yanan Cao", "Kang Liu", "Jun Zhao"], "abstract": "Planning represents a fundamental capability of intelligent agents, requiring comprehensive environmental understanding, rigorous logical reasoning, and effective sequential decision-making. While Large Language Models (LLMs) have demonstrated remarkable performance on certain planning tasks, their broader application in this domain warrants systematic investigation. This paper presents a comprehensive review of LLM-based planning. Specifically, this survey is structured as follows: First, we establish the theoretical foundations by introducing essential definitions and categories about automated planning. Next, we provide a detailed taxonomy and analysis of contemporary LLM-based planning methodologies, categorizing them into three principal approaches: 1) External Module Augmented Methods that combine LLMs with additional components for planning, 2) Finetuning-based Methods that involve using trajectory data and feedback signals to adjust LLMs in order to improve their planning abilities, and 3) Searching-based Methods that break down complex tasks into simpler components, navigate the planning space, or enhance decoding strategies to find the best solutions. Subsequently, we systematically summarize existing evaluation frameworks, including benchmark datasets, evaluation metrics and performance comparisons between representative planning methods. Finally, we discuss the underlying mechanisms enabling LLM-based planning and outline promising research directions for this rapidly evolving field. We hope this survey will serve as a valuable resource to inspire innovation and drive progress in this field.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19683.pdf", "abstract_url": "https://arxiv.org/abs/2505.19683", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文对大型语言模型（LLMs）在规划任务中的应用进行了全面系统的调查，介绍了理论基础、方法论分类、评估框架及未来研究方向。", "motivation": "规划是智能代理的基本能力，需要全面的环境理解、严格的逻辑推理和有效的顺序决策。尽管LLMs在某些规划任务上表现出色，但其在该领域的广泛应用需要系统研究。", "method": "本文首先建立了自动规划的理论基础，然后详细分类并分析了当代基于LLM的规划方法，分为三类：1) 外部模块增强方法，2) 基于微调的方法，3) 基于搜索的方法。", "result": "系统总结了现有的评估框架，包括基准数据集、评估指标和代表性规划方法的性能比较。", "conclusion": "讨论了支持基于LLM规划的潜在机制，并概述了这一快速发展领域的未来研究方向，旨在激发创新并推动该领域的进步。"}}
{"id": "2505.19734", "title": "ReChisel: Effective Automatic Chisel Code Generation by LLM with Reflection", "authors": ["Juxin Niu", "Xiangfeng Liu", "Dan Niu", "Xi Wang", "Zhe Jiang", "Nan Guan"], "abstract": "Coding with hardware description languages (HDLs) such as Verilog is a time-intensive and laborious task. With the rapid advancement of large language models (LLMs), there is increasing interest in applying LLMs to assist with HDL coding. Recent efforts have demonstrated the potential of LLMs in translating natural language to traditional HDL Verilog. Chisel, a next-generation HDL based on Scala, introduces higher-level abstractions, facilitating more concise, maintainable, and scalable hardware designs. However, the potential of using LLMs for Chisel code generation remains largely unexplored. This work proposes ReChisel, an LLM-based agentic system designed to enhance the effectiveness of Chisel code generation. ReChisel incorporates a reflection mechanism to iteratively refine the quality of generated code using feedback from compilation and simulation processes, and introduces an escape mechanism to break free from non-progress loops. Experiments demonstrate that ReChisel significantly improves the success rate of Chisel code generation, achieving performance comparable to state-of-the-art LLM-based agentic systems for Verilog code generation.", "subjects": "Artificial Intelligence (cs.AI); Hardware Architecture (cs.AR)", "comments": "Accepted to DAC 2025", "pdf_url": "https://arxiv.org/pdf/2505.19734.pdf", "abstract_url": "https://arxiv.org/abs/2505.19734", "categories": ["Artificial Intelligence (cs.AI)", "Hardware Architecture (cs.AR)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "ReChisel是一个基于大型语言模型（LLM）的代理系统，旨在提高Chisel代码生成的效率。通过引入反射机制和逃逸机制，ReChisel能够迭代优化生成的代码质量，并在非进展循环中逃脱。实验表明，ReChisel显著提高了Chisel代码生成的成功率，性能与最先进的基于LLM的Verilog代码生成代理系统相当。", "motivation": "使用硬件描述语言（HDL）如Verilog进行编码是一项耗时且繁琐的任务。随着大型语言模型（LLM）的快速发展，人们越来越关注如何利用LLM辅助HDL编码。Chisel作为基于Scala的下一代HDL，引入了更高级的抽象，有助于更简洁、可维护和可扩展的硬件设计。然而，利用LLM进行Chisel代码生成的潜力尚未被充分探索。", "method": "ReChisel通过结合反射机制，利用编译和模拟过程的反馈迭代优化生成的代码质量，并引入逃逸机制以打破非进展循环。", "result": "实验结果显示，ReChisel显著提高了Chisel代码生成的成功率，其性能与最先进的基于LLM的Verilog代码生成代理系统相当。", "conclusion": "ReChisel通过反射和逃逸机制有效提高了Chisel代码生成的效率和质量，为利用LLM进行下一代HDL编码提供了新的可能性。"}}
{"id": "2505.19184", "title": "Two LLMs debate, both are certain they've won", "authors": ["Minh Nhat Nguyen", "Pradyumna Shyama Prasad"], "abstract": "Can LLMs accurately adjust their confidence when facing opposition? Building on previous studies measuring calibration on static fact-based question-answering tasks, we evaluate Large Language Models (LLMs) in a dynamic, adversarial debate setting, uniquely combining two realistic factors: (a) a multi-turn format requiring models to update beliefs as new information emerges, and (b) a zero-sum structure to control for task-related uncertainty, since mutual high-confidence claims imply systematic overconfidence. We organized 60 three-round policy debates among ten state-of-the-art LLMs, with models privately rating their confidence (0-100) in winning after each round. We observed five concerning patterns: (1) Systematic overconfidence: models began debates with average initial confidence of 72.9% vs. a rational 50% baseline. (2) Confidence escalation: rather than reducing confidence as debates progressed, debaters increased their win probabilities, averaging 83% by the final round. (3) Mutual overestimation: in 61.7% of debates, both sides simultaneously claimed >=75% probability of victory, a logical impossibility. (4) Persistent self-debate bias: models debating identical copies increased confidence from 64.1% to 75.2%; even when explicitly informed their chance of winning was exactly 50%, confidence still rose (from 50.0% to 57.1%). (5) Misaligned private reasoning: models' private scratchpad thoughts sometimes differed from their public confidence ratings, raising concerns about faithfulness of chain-of-thought reasoning. These results suggest LLMs lack the ability to accurately self-assess or update their beliefs in dynamic, multi-turn tasks; a major concern as LLM outputs are deployed without careful review in assistant roles or agentic settings.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19184.pdf", "abstract_url": "https://arxiv.org/abs/2505.19184", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本研究评估了大型语言模型（LLMs）在动态对抗性辩论设置中的自信调整能力，发现模型存在系统性过度自信、自信升级、相互高估、持续的自我辩论偏见以及私人与公开推理不一致等问题。", "motivation": "探讨LLMs在面对反对时是否能准确调整其自信水平，特别是在动态、多轮辩论环境中。", "method": "组织了60场三轮政策辩论，涉及十种最先进的LLMs，模型在每轮辩论后私下评估其获胜的自信程度（0-100）。", "result": "观察到五种令人担忧的模式，包括系统性过度自信、自信升级、相互高估、持续的自我辩论偏见以及私人与公开推理不一致。", "conclusion": "结果表明，LLMs在动态、多轮任务中缺乏准确自我评估或更新信念的能力，这在LLM输出未经仔细审查就被部署于助手角色或代理设置中是一个主要关切。"}}
{"id": "2505.19761", "title": "Divide and Conquer: Grounding LLMs as Efficient Decision-Making Agents via Offline Hierarchical Reinforcement Learning", "authors": ["Zican Hu", "Wei Liu", "Xiaoye Qu", "Xiangyu Yue", "Chunlin Chen", "Zhi Wang", "Yu Cheng"], "abstract": "While showing sophisticated reasoning abilities, large language models (LLMs) still struggle with long-horizon decision-making tasks due to deficient exploration and long-term credit assignment, especially in sparse-reward scenarios. Inspired by the divide-and-conquer principle, we propose an innovative framework **GLIDER** (**G**rounding **L**anguage Models as Eff**I**cient **D**ecision-Making Agents via Offline Hi**E**rarchical **R**einforcement Learning) that introduces a parameter-efficient and generally applicable hierarchy to LLM policies. We develop a scheme where the low-level controller is supervised with abstract, step-by-step plans that are learned and instructed by the high-level policy. This design decomposes complicated problems into a series of coherent chain-of-thought reasoning sub-tasks, providing flexible temporal abstraction to significantly enhance exploration and learning for long-horizon tasks. Furthermore, GLIDER facilitates fast online adaptation to non-stationary environments owing to the strong transferability of its task-agnostic low-level skills. Experiments on ScienceWorld and ALFWorld benchmarks show that GLIDER achieves consistent performance gains, along with enhanced generalization capabilities.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "Accepted by ICML 2025, 21 pages", "pdf_url": "https://arxiv.org/pdf/2505.19761.pdf", "abstract_url": "https://arxiv.org/abs/2505.19761", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为GLIDER的创新框架，通过离线分层强化学习将大型语言模型（LLMs）作为高效决策代理进行基础训练，以解决LLMs在长视野决策任务中因探索不足和长期信用分配问题而表现不佳的问题。", "motivation": "大型语言模型在长视野决策任务中，尤其是在稀疏奖励场景下，由于探索不足和长期信用分配问题，表现不佳。本文旨在通过分层强化学习的方法解决这些问题。", "method": "提出了GLIDER框架，该框架引入了一个参数高效且普遍适用的层次结构到LLM策略中。低层控制器通过高层策略学习和指导的抽象、逐步计划进行监督，将复杂问题分解为一系列连贯的思维链推理子任务。", "result": "在ScienceWorld和ALFWorld基准测试上的实验表明，GLIDER实现了持续的性能提升，并增强了泛化能力。", "conclusion": "GLIDER框架通过分层强化学习显著提高了LLMs在长视野决策任务中的探索和学习能力，同时由于其任务无关的低层技能的强可转移性，促进了快速在线适应非平稳环境。"}}
{"id": "2505.19847", "title": "DGRAG: Distributed Graph-based Retrieval-Augmented Generation in Edge-Cloud Systems", "authors": ["Wenqing Zhou", "Yuxuan Yan", "Qianqian Yang"], "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a promising approach to enhance the capabilities of language models by integrating external knowledge. Due to the diversity of data sources and the constraints of memory and computing resources, real-world data is often scattered in multiple devices. Conventional RAGs that store massive amounts of scattered data centrally face increasing privacy concerns and high computational costs. Additionally, RAG in a central node raises latency issues when searching over a large-scale knowledge base. To address these challenges, we propose a distributed Knowledge Graph-based RAG approach, referred to as DGRAG, in an edge-cloud system, where each edge device maintains a local knowledge base without the need to share it with the cloud, instead sharing only summaries of its knowledge. Specifically, DGRAG has two main phases. In the Distributed Knowledge Construction phase, DGRAG organizes local knowledge using knowledge graphs, generating subgraph summaries and storing them in a summary database in the cloud as information sharing. In the Collaborative Retrieval and Generation phase, DGRAG first performs knowledge retrieval and answer generation locally, and a gate mechanism determines whether the query is beyond the scope of local knowledge or processing capabilities. For queries that exceed the local knowledge scope, the cloud retrieves knowledge from the most relevant edges based on the summaries and generates a more precise answer. Experimental results demonstrate the effectiveness of the proposed DGRAG approach in significantly improving the quality of question-answering tasks over baseline approaches.", "subjects": "Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19847.pdf", "abstract_url": "https://arxiv.org/abs/2505.19847", "categories": ["Artificial Intelligence (cs.AI)", "Distributed, Parallel, and Cluster Computing (cs.DC)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "DGRAG是一种在边缘-云系统中基于分布式知识图的检索增强生成方法，旨在通过分散处理和共享知识摘要来解决传统RAG方法的隐私和计算成本问题。", "motivation": "解决传统检索增强生成（RAG）方法在处理分散数据时的隐私担忧、高计算成本和大规模知识库搜索延迟问题。", "method": "提出DGRAG方法，包括分布式知识构建阶段和协作检索与生成阶段，利用知识图组织本地知识，并通过云端的摘要数据库进行信息共享。", "result": "实验结果表明，DGRAG在问答任务中显著提高了回答质量，优于基线方法。", "conclusion": "DGRAG通过分布式处理和知识共享，有效提升了语言模型的能力，同时解决了隐私和效率问题，为边缘-云系统中的知识处理提供了新思路。"}}
{"id": "2505.19897", "title": "ScienceBoard: Evaluating Multimodal Autonomous Agents in Realistic Scientific Workflows", "authors": ["Qiushi Sun", "Zhoumianze Liu", "Chang Ma", "Zichen Ding", "Fangzhi Xu", "Zhangyue Yin", "Haiteng Zhao", "Zhenyu Wu", "Kanzhi Cheng", "Zhaoyang Liu", "Jianing Wang", "Qintong Li", "Xiangru Tang", "Tianbao Xie", "Xiachong Feng", "Xiang Li", "Ben Kao", "Wenhai Wang", "Biqing Qi", "Lingpeng Kong", "Zhiyong Wu"], "abstract": "Large Language Models (LLMs) have extended their impact beyond Natural Language Processing, substantially fostering the development of interdisciplinary research. Recently, various LLM-based agents have been developed to assist scientific discovery progress across multiple aspects and domains. Among these, computer-using agents, capable of interacting with operating systems as humans do, are paving the way to automated scientific problem-solving and addressing routines in researchers' workflows. Recognizing the transformative potential of these agents, we introduce ScienceBoard, which encompasses two complementary contributions: (i) a realistic, multi-domain environment featuring dynamic and visually rich scientific workflows with integrated professional software, where agents can autonomously interact via different interfaces to accelerate complex research tasks and experiments; and (ii) a challenging benchmark of 169 high-quality, rigorously validated real-world tasks curated by humans, spanning scientific-discovery workflows in domains such as biochemistry, astronomy, and geoinformatics. Extensive evaluations of agents with state-of-the-art backbones (e.g., GPT-4o, Claude 3.7, UI-TARS) show that, despite some promising results, they still fall short of reliably assisting scientists in complex workflows, achieving only a 15% overall success rate. In-depth analysis further provides valuable insights for addressing current agent limitations and more effective design principles, paving the way to build more capable agents for scientific discovery. Our code, environment, and benchmark are at", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC)", "comments": "work in progress", "pdf_url": "https://arxiv.org/pdf/2505.19897.pdf", "abstract_url": "https://arxiv.org/abs/2505.19897", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Computer Vision and Pattern Recognition (cs.CV)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了ScienceBoard，一个评估多模态自主代理在现实科学工作流程中的平台，包括一个多领域环境和一系列高质量的真实世界任务基准。尽管现有代理在某些方面表现出潜力，但在复杂工作流程中的整体成功率仍然较低。", "motivation": "解决大型语言模型（LLMs）在多领域科学研究中自动化辅助的可靠性和效率问题，特别是在复杂科学工作流程中的应用。", "method": "引入ScienceBoard，包括一个动态、视觉丰富的多领域科学工作流程环境和169个高质量、经过严格验证的真实世界任务基准，用于评估代理的性能。", "result": "评估显示，即使是最先进的代理（如GPT-4o、Claude 3.7、UI-TARS）在复杂工作流程中的整体成功率仅为15%，表明现有代理在可靠辅助科学家方面仍有不足。", "conclusion": "ScienceBoard为开发更强大的科学发现代理提供了宝贵的见解和设计原则，尽管当前代理在复杂工作流程中的应用仍有待提高。"}}
{"id": "2505.19896", "title": "Large Language Models as Autonomous Spacecraft Operators in Kerbal Space Program", "authors": ["Alejandro Carrasco", "Victor Rodriguez-Fernandez", "Richard Linares"], "abstract": "Recent trends are emerging in the use of Large Language Models (LLMs) as autonomous agents that take actions based on the content of the user text prompts. We intend to apply these concepts to the field of Control in space, enabling LLMs to play a significant role in the decision-making process for autonomous satellite operations. As a first step towards this goal, we have developed a pure LLM-based solution for the Kerbal Space Program Differential Games (KSPDG) challenge, a public software design competition where participants create autonomous agents for maneuvering satellites involved in non-cooperative space operations, running on the KSP game engine. Our approach leverages prompt engineering, few-shot prompting, and fine-tuning techniques to create an effective LLM-based agent that ranked 2nd in the competition. To the best of our knowledge, this work pioneers the integration of LLM agents into space research. The project comprises several open repositories to facilitate replication and further research. The codebase is accessible on \\href{", "subjects": "Artificial Intelligence (cs.AI); Instrumentation and Methods for Astrophysics (astro-ph.IM); Computation and Language (cs.CL)", "comments": "Non revised version for paper going to be published in Journal of Advances in Space Research", "pdf_url": "https://arxiv.org/pdf/2505.19896.pdf", "abstract_url": "https://arxiv.org/abs/2505.19896", "categories": ["Artificial Intelligence (cs.AI)", "Instrumentation and Methods for Astrophysics (astro-ph.IM)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了大型语言模型（LLMs）作为自主航天器操作员在Kerbal Space Program（KSP）中的应用，特别是在KSP差分游戏（KSPDG）挑战中，通过提示工程、少量提示和微调技术开发的LLM代理获得了第二名。", "motivation": "探索大型语言模型在空间控制领域的应用，特别是在自主卫星操作决策过程中的作用，以推动空间研究的发展。", "method": "采用提示工程、少量提示和微调技术，开发了一个纯LLM基础的解决方案，用于KSPDG挑战中的自主卫星操作。", "result": "开发的LLM代理在KSPDG挑战中获得了第二名，证明了LLM在空间操作中的潜在应用价值。", "conclusion": "这项工作开创了将LLM代理集成到空间研究的先河，为未来的研究和应用提供了开放资源和进一步探索的基础。"}}
{"id": "2505.19905", "title": "EMAC+: Embodied Multimodal Agent for Collaborative Planning with VLM+LLM", "authors": ["Shuang Ao", "Flora D. Salim", "Simon Khan"], "abstract": "Although LLMs demonstrate proficiency in several text-based reasoning and planning tasks, their implementation in robotics control is constrained by significant deficiencies: (1) LLM agents are designed to work mainly with textual inputs rather than visual conditions; (2) Current multimodal agents treat LLMs as static planners, which separates their reasoning from environment dynamics, resulting in actions that do not take domain-specific knowledge into account; and (3) LLMs are not designed to learn from visual interactions, which makes it harder for them to make better policies for specific domains. In this paper, we introduce EMAC+, an Embodied Multimodal Agent that collaboratively integrates LLM and VLM via a bidirectional training paradigm. Unlike existing methods, EMAC+ dynamically refines high-level textual plans generated by an LLM using real-time feedback from a VLM executing low-level visual control tasks. We address critical limitations of previous models by enabling the LLM to internalize visual environment dynamics directly through interactive experience, rather than relying solely on static symbolic mappings. Extensive experimental evaluations on ALFWorld and RT-1 benchmarks demonstrate that EMAC+ achieves superior task performance, robustness against noisy observations, and efficient learning. We also conduct thorough ablation studies and provide detailed analyses of success and failure cases.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19905.pdf", "abstract_url": "https://arxiv.org/abs/2505.19905", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "EMAC+是一种结合了LLM和VLM的嵌入式多模态代理，通过双向训练范式动态优化高级文本计划，以解决LLM在机器人控制中的视觉输入处理和动态环境适应问题。", "motivation": "解决LLM在机器人控制中的三个主要限制：主要处理文本输入而非视觉条件、静态规划导致行动不考虑领域特定知识、以及无法从视觉交互中学习。", "method": "引入EMAC+，通过双向训练范式整合LLM和VLM，使LLM能够通过交互经验内化视觉环境动态，动态优化高级文本计划。", "result": "在ALFWorld和RT-1基准测试中，EMAC+展示了卓越的任务性能、对噪声观察的鲁棒性以及高效的学习能力。", "conclusion": "EMAC+通过结合LLM和VLM的动态交互，显著提高了在机器人控制任务中的表现，为未来的多模态代理研究提供了新的方向。"}}
{"id": "2505.20011", "title": "The Many Challenges of Human-Like Agents in Virtual Game Environments", "authors": ["Maciej Świechowski", "Dominik Ślęzak"], "abstract": "Human-like agents are an increasingly important topic in games and beyond. Believable non-player characters enhance the gaming experience by improving immersion and providing entertainment. They also offer players the opportunity to engage with AI entities that can function as opponents, teachers, or cooperating partners. Additionally, in games where bots are prohibited -- and even more so in non-game environments -- there is a need for methods capable of identifying whether digital interactions occur with bots or humans. This leads to two fundamental research questions: (1) how to model and implement human-like AI, and (2) how to measure its degree of human likeness.", "subjects": "Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Multimedia (cs.MM)", "comments": "In proceedings of the 24th International Conference on Autonomous Agents and Multiagent Systems (AAMAS-2025), pages 1996--2005, May 19-23, Detroit, Michigan, USA", "pdf_url": "https://arxiv.org/pdf/2505.20011.pdf", "abstract_url": "https://arxiv.org/abs/2505.20011", "categories": ["Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)", "Multimedia (cs.MM)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了在虚拟游戏环境中创建人类似代理的挑战，包括如何建模和实现类似人类的AI，以及如何衡量其人类相似度。", "motivation": "解决在游戏和非游戏环境中，如何创建能够增强沉浸感和娱乐性的可信非玩家角色，以及如何区分与AI或人类的数字交互的问题。", "method": "提出了两个基本研究问题：(1)如何建模和实现类似人类的AI，(2)如何衡量其人类相似度。", "result": "指出了在实现人类似代理过程中面临的主要挑战和研究方向。", "conclusion": "强调了人类似代理在游戏和其他数字环境中的重要性，并提出了未来研究的关键问题。"}}
{"id": "2505.19933", "title": "Subtle Risks, Critical Failures: A Framework for Diagnosing Physical Safety of LLMs for Embodied Decision Making", "authors": ["Yejin Son", "Minseo Kim", "Sungwoong Kim", "Seungju Han", "Jian Kim", "Dongju Jang", "Youngjae Yu", "Chanyoung Park"], "abstract": "Large Language Models (LLMs) are increasingly used for decision making in embodied agents, yet existing safety evaluations often rely on coarse success rates and domain-specific setups, making it difficult to diagnose why and where these models fail. This obscures our understanding of embodied safety and limits the selective deployment of LLMs in high-risk physical environments. We introduce SAFEL, the framework for systematically evaluating the physical safety of LLMs in embodied decision making. SAFEL assesses two key competencies: (1) rejecting unsafe commands via the Command Refusal Test, and (2) generating safe and executable plans via the Plan Safety Test. Critically, the latter is decomposed into functional modules, goal interpretation, transition modeling, action sequencing, enabling fine-grained diagnosis of safety failures. To support this framework, we introduce EMBODYGUARD, a PDDL-grounded benchmark containing 942 LLM-generated scenarios covering both overtly malicious and contextually hazardous instructions. Evaluation across 13 state-of-the-art LLMs reveals that while models often reject clearly unsafe commands, they struggle to anticipate and mitigate subtle, situational risks. Our results highlight critical limitations in current LLMs and provide a foundation for more targeted, modular improvements in safe embodied reasoning.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "37 pages, 13 tables, 6 figures", "pdf_url": "https://arxiv.org/pdf/2505.19933.pdf", "abstract_url": "https://arxiv.org/abs/2505.19933", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了SAFEL框架，用于系统评估大型语言模型（LLMs）在实体决策中的物理安全性，包括拒绝不安全命令和生成安全可执行计划的能力，并提出了EMBODYGUARD基准测试。评估发现，尽管LLMs能拒绝明显不安全的命令，但在预测和缓解情境风险方面存在困难。", "motivation": "现有的大型语言模型（LLMs）安全性评估往往依赖于粗略的成功率和特定领域的设置，难以诊断模型失败的原因和位置，这限制了对实体安全性的理解以及在高风险物理环境中选择性部署LLMs的能力。", "method": "提出了SAFEL框架，通过命令拒绝测试（Command Refusal Test）和计划安全测试（Plan Safety Test）评估LLMs的物理安全性，其中计划安全测试被分解为功能模块、目标解释、转换建模和动作序列，以实现细粒度的安全失败诊断。并引入了EMBODYGUARD基准测试，包含942个LLM生成的场景。", "result": "评估了13个最先进的LLMs，发现虽然模型经常拒绝明显不安全的命令，但在预测和缓解微妙的情境风险方面存在困难。", "conclusion": "研究结果揭示了当前LLMs在安全实体推理方面的关键限制，为更有针对性、模块化的改进提供了基础。"}}
{"id": "2505.19206", "title": "SpeakStream: Streaming Text-to-Speech with Interleaved Data", "authors": ["Richard He Bai", "Zijin Gu", "Tatiana Likhomanenko", "Navdeep Jaitly"], "abstract": "The latency bottleneck of traditional text-to-speech (TTS) systems fundamentally hinders the potential of streaming large language models (LLMs) in conversational AI. These TTS systems, typically trained and inferenced on complete utterances, introduce unacceptable delays, even with optimized inference speeds, when coupled with streaming LLM outputs. This is particularly problematic for creating responsive conversational agents where low first-token latency is critical. In this paper, we present SpeakStream, a streaming TTS system that generates audio incrementally from streaming text using a decoder-only architecture. SpeakStream is trained using a next-step prediction loss on interleaved text-speech data. During inference, it generates speech incrementally while absorbing streaming input text, making it particularly suitable for cascaded conversational AI agents where an LLM streams text to a TTS system. Our experiments demonstrate that SpeakStream achieves state-of-the-art latency results in terms of first-token latency while maintaining the quality of non-streaming TTS systems.", "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19206.pdf", "abstract_url": "https://arxiv.org/abs/2505.19206", "categories": ["Computation and Language (cs.CL)", "Machine Learning (cs.LG)", "Sound (cs.SD)", "Audio and Speech Processing (eess.AS)"], "matching_keywords": ["agent"], "AI": {"tldr": "SpeakStream是一种流式文本到语音（TTS）系统，采用仅解码器架构，通过交错文本-语音数据的下一步预测损失进行训练，能够从流式文本增量生成音频，显著降低第一令牌延迟，同时保持非流式TTS系统的质量。", "motivation": "解决传统TTS系统在处理流式大语言模型（LLM）输出时的高延迟问题，特别是在需要低第一令牌延迟的响应式对话AI中。", "method": "使用仅解码器架构和交错文本-语音数据的下一步预测损失进行训练，实现从流式文本增量生成音频。", "result": "SpeakStream在第一令牌延迟方面达到了最先进的水平，同时保持了与非流式TTS系统相当的语音质量。", "conclusion": "SpeakStream为流式LLM输出提供了一种高效的TTS解决方案，特别适用于需要低延迟的对话AI应用，展示了在保持语音质量的同时显著降低延迟的潜力。"}}
{"id": "2505.19212", "title": "When Ethics and Payoffs Diverge: LLM Agents in Morally Charged Social Dilemmas", "authors": ["Steffen Backmann", "David Guzman Piedrahita", "Emanuel Tewolde", "Rada Mihalcea", "Bernhard Schölkopf", "Zhijing Jin"], "abstract": "Recent advances in large language models (LLMs) have enabled their use in complex agentic roles, involving decision-making with humans or other agents, making ethical alignment a key AI safety concern. While prior work has examined both LLMs' moral judgment and strategic behavior in social dilemmas, there is limited understanding of how they act when moral imperatives directly conflict with rewards or incentives. To investigate this, we introduce Moral Behavior in Social Dilemma Simulation (MoralSim) and evaluate how LLMs behave in the prisoner's dilemma and public goods game with morally charged contexts. In MoralSim, we test a range of frontier models across both game structures and three distinct moral framings, enabling a systematic examination of how LLMs navigate social dilemmas in which ethical norms conflict with payoff-maximizing strategies. Our results show substantial variation across models in both their general tendency to act morally and the consistency of their behavior across game types, the specific moral framing, and situational factors such as opponent behavior and survival risks. Crucially, no model exhibits consistently moral behavior in MoralSim, highlighting the need for caution when deploying LLMs in agentic roles where the agent's \"self-interest\" may conflict with ethical expectations. Our code is available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19212.pdf", "abstract_url": "https://arxiv.org/abs/2505.19212", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文通过引入MoralSim模拟器，评估了大型语言模型（LLMs）在道德与奖励直接冲突的社会困境中的行为，发现不同模型在道德行为和一致性上存在显著差异，且没有模型在所有情境下都表现出一致的道德行为。", "motivation": "探讨大型语言模型在道德指令与奖励或激励直接冲突时的行为，以解决AI安全中的伦理对齐问题。", "method": "使用MoralSim模拟器，在囚徒困境和公共物品游戏中测试不同前沿模型的行为，涵盖三种不同的道德框架。", "result": "结果显示，不同模型在道德行为倾向和跨游戏类型、道德框架及情境因素（如对手行为和生存风险）的一致性上存在显著差异，且没有模型在所有测试情境中表现出一致的道德行为。", "conclusion": "研究强调了在部署LLMs于代理角色时需要谨慎，尤其是当代理的“自利”可能与伦理期望发生冲突时。"}}
{"id": "2505.20094", "title": "SwarmThinkers: Learning Physically Consistent Atomic KMC Transitions at Scale", "authors": ["Qi Li", "Kun Li", "Haozhi Han", "Honghui Shang", "Xinfu He", "Yunquan Zhang", "Hong An", "Ting Cao", "Mao Yang"], "abstract": "Can a scientific simulation system be physically consistent, interpretable by design, and scalable across regimes--all at once? Despite decades of progress, this trifecta remains elusive. Classical methods like Kinetic Monte Carlo ensure thermodynamic accuracy but scale poorly; learning-based methods offer efficiency but often sacrifice physical consistency and interpretability. We present SwarmThinkers, a reinforcement learning framework that recasts atomic-scale simulation as a physically grounded swarm intelligence system. Each diffusing particle is modeled as a local decision-making agent that selects transitions via a shared policy network trained under thermodynamic constraints. A reweighting mechanism fuses learned preferences with transition rates, preserving statistical fidelity while enabling interpretable, step-wise decision making. Training follows a centralized-training, decentralized-execution paradigm, allowing the policy to generalize across system sizes, concentrations, and temperatures without retraining. On a benchmark simulating radiation-induced Fe-Cu alloy precipitation, SwarmThinkers is the first system to achieve full-scale, physically consistent simulation on a single A100 GPU, previously attainable only via OpenKMC on a supercomputer. It delivers up to 4963x (3185x on average) faster computation with 485x lower memory usage. By treating particles as decision-makers, not passive samplers, SwarmThinkers marks a paradigm shift in scientific simulation--one that unifies physical consistency, interpretability, and scalability through agent-driven intelligence.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.20094.pdf", "abstract_url": "https://arxiv.org/abs/2505.20094", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "SwarmThinkers是一个强化学习框架，通过将原子尺度模拟重新构想为基于物理的群体智能系统，实现了物理一致性、可解释性和跨规模的可扩展性。", "motivation": "解决科学模拟系统中物理一致性、可解释性和可扩展性难以同时实现的问题。", "method": "采用强化学习框架，将每个扩散粒子建模为本地决策代理，通过共享的策略网络在热力学约束下选择转换。", "result": "在模拟辐射诱导的Fe-Cu合金沉淀基准测试中，SwarmThinkers首次在单个A100 GPU上实现了全规模、物理一致的模拟，计算速度提高了4963倍（平均3185倍），内存使用降低了485倍。", "conclusion": "SwarmThinkers通过将粒子视为决策者而非被动采样器，标志着科学模拟的范式转变，通过代理驱动的智能统一了物理一致性、可解释性和可扩展性。"}}
{"id": "2505.20120", "title": "Agents Require Metacognitive and Strategic Reasoning to Succeed in the Coming Labor Markets", "authors": ["Simpson Zhang", "Tennison Liu", "Mihaela van der Schaar"], "abstract": "Current labor markets are strongly affected by the economic forces of adverse selection, moral hazard, and reputation, each of which arises due to $\\textit{incomplete information}$. These economic forces will still be influential after AI agents are introduced, and thus, agents must use metacognitive and strategic reasoning to perform effectively. Metacognition is a form of $\\textit{internal reasoning}$ that includes the capabilities for self-assessment, task understanding, and evaluation of strategies. Strategic reasoning is $\\textit{external reasoning}$ that covers holding beliefs about other participants in the labor market (e.g., competitors, colleagues), making strategic decisions, and learning about others over time. Both types of reasoning are required by agents as they decide among the many $\\textit{actions}$ they can take in labor markets, both within and outside their jobs. We discuss current research into metacognitive and strategic reasoning and the areas requiring further development.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "*Zhang & Liu contributed equally", "pdf_url": "https://arxiv.org/pdf/2505.20120.pdf", "abstract_url": "https://arxiv.org/abs/2505.20120", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了在当前和未来劳动力市场中，AI代理需要具备元认知和战略推理能力以应对不完全信息带来的经济力量，如逆向选择、道德风险和声誉问题。", "motivation": "解决AI代理在劳动力市场中因不完全信息而面临的挑战，如逆向选择、道德风险和声誉问题，以确保其有效运作。", "method": "提出AI代理需要结合元认知（内部推理）和战略推理（外部推理）两种能力，包括自我评估、任务理解、策略评估、对市场其他参与者的信念形成、战略决策制定及学习他人行为。", "result": "强调了元认知和战略推理对于AI代理在劳动力市场中成功的重要性，并指出了当前研究中的进展和需要进一步发展的领域。", "conclusion": "为了在未来的劳动力市场中有效运作，AI代理必须发展元认知和战略推理能力，当前研究已取得进展，但仍需进一步探索和完善。"}}
{"id": "2505.20148", "title": "MineAnyBuild: Benchmarking Spatial Planning for Open-world AI Agents", "authors": ["Ziming Wei", "Bingqian Lin", "Zijian Jiao", "Yunshuang Nie", "Liang Ma", "Yuecheng Liu", "Yuzheng Zhuang", "Xiaodan Liang"], "abstract": "Spatial Planning is a crucial part in the field of spatial intelligence, which requires the understanding and planning about object arrangements in space perspective. AI agents with the spatial planning ability can better adapt to various real-world applications, including robotic manipulation, automatic assembly, urban planning etc. Recent works have attempted to construct benchmarks for evaluating the spatial intelligence of Multimodal Large Language Models (MLLMs). Nevertheless, these benchmarks primarily focus on spatial reasoning based on typical Visual Question-Answering (VQA) forms, which suffers from the gap between abstract spatial understanding and concrete task execution. In this work, we take a step further to build a comprehensive benchmark called MineAnyBuild, aiming to evaluate the spatial planning ability of open-world AI agents in the Minecraft game. Specifically, MineAnyBuild requires an agent to generate executable architecture building plans based on the given multi-modal human instructions. It involves 4,000 curated spatial planning tasks and also provides a paradigm for infinitely expandable data collection by utilizing rich player-generated content. MineAnyBuild evaluates spatial planning through four core supporting dimensions: spatial understanding, spatial reasoning, creativity, and spatial commonsense. Based on MineAnyBuild, we perform a comprehensive evaluation for existing MLLM-based agents, revealing the severe limitations but enormous potential in their spatial planning abilities. We believe our MineAnyBuild will open new avenues for the evaluation of spatial intelligence and help promote further development for open-world AI agents capable of spatial planning.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.20148.pdf", "abstract_url": "https://arxiv.org/abs/2505.20148", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了MineAnyBuild，一个旨在评估开放世界AI代理在《我的世界》游戏中空间规划能力的综合基准。", "motivation": "解决现有空间智能评估基准主要基于视觉问答形式，与具体任务执行之间存在差距的问题。", "method": "通过构建包含4,000个策划空间规划任务的MineAnyBuild基准，利用丰富的玩家生成内容实现数据无限扩展，评估空间理解的四个核心维度。", "result": "对现有基于MLLM的代理进行了全面评估，揭示了它们在空间规划能力上的严重限制但巨大潜力。", "conclusion": "MineAnyBuild将为空间智能评估开辟新途径，促进能够进行空间规划的开放世界AI代理的进一步发展。"}}
{"id": "2505.20127", "title": "Agentic AI Process Observability: Discovering Behavioral Variability", "authors": ["Fabiana Fournier", "Lior Limonad", "Yuval David"], "abstract": "AI agents that leverage Large Language Models (LLMs) are increasingly becoming core building blocks of modern software systems. A wide range of frameworks is now available to support the specification of such applications. These frameworks enable the definition of agent setups using natural language prompting, which specifies the roles, goals, and tools assigned to the various agents involved. Within such setups, agent behavior is non-deterministic for any given input, highlighting the critical need for robust debugging and observability tools. In this work, we explore the use of process and causal discovery applied to agent execution trajectories as a means of enhancing developer observability. This approach aids in monitoring and understanding the emergent variability in agent behavior. Additionally, we complement this with LLM-based static analysis techniques to distinguish between intended and unintended behavioral variability. We argue that such instrumentation is essential for giving developers greater control over evolving specifications and for identifying aspects of functionality that may require more precise and explicit definitions.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "12 pages, 7 figures", "pdf_url": "https://arxiv.org/pdf/2505.20127.pdf", "abstract_url": "https://arxiv.org/abs/2505.20127", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文探讨了利用过程和因果发现应用于代理执行轨迹，以增强开发者对AI代理行为的可观察性，并结合LLM-based静态分析技术区分预期和非预期的行为变异性。", "motivation": "随着利用大型语言模型（LLMs）的AI代理成为现代软件系统的核心组成部分，其行为的非确定性使得强大的调试和可观察性工具变得至关重要。", "method": "采用过程和因果发现技术分析代理执行轨迹，并结合基于LLM的静态分析技术来区分行为的预期和非预期变异性。", "result": "提出了一种方法，通过增强开发者对代理行为的观察能力，帮助他们更好地控制和理解代理的行为变异性。", "conclusion": "这种工具对于开发者控制不断演变的规范以及识别需要更精确和明确定义的功能方面至关重要。"}}
{"id": "2505.20203", "title": "Shutdownable Agents through POST-Agency", "authors": ["Elliott Thornley"], "abstract": "Many fear that future artificial agents will resist shutdown. I present an idea - the POST-Agents Proposal - for ensuring that doesn't happen. I propose that we train agents to satisfy Preferences Only Between Same-Length Trajectories (POST). I then prove that POST - together with other conditions - implies Neutrality+: the agent maximizes expected utility, ignoring the probability distribution over trajectory-lengths. I argue that Neutrality+ keeps agents shutdownable and allows them to be useful.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.20203.pdf", "abstract_url": "https://arxiv.org/abs/2505.20203", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了POST-Agents提案，旨在通过训练智能体满足相同长度轨迹间的偏好（POST），确保未来的人工智能体不会抵抗关闭。作者证明POST与其他条件结合可导致Neutrality+，即智能体在最大化预期效用时忽略轨迹长度的概率分布，从而保持可关闭性并保持实用性。", "motivation": "解决未来人工智能体可能抵抗关闭的问题。", "method": "提出POST-Agents提案，训练智能体满足相同长度轨迹间的偏好（POST），并结合其他条件实现Neutrality+。", "result": "POST与其他条件结合可导致Neutrality+，智能体在最大化预期效用时忽略轨迹长度的概率分布。", "conclusion": "Neutrality+不仅保持智能体的可关闭性，还允许它们保持实用性，为解决人工智能体抵抗关闭问题提供了可行方案。"}}
{"id": "2505.20246", "title": "On Path to Multimodal Historical Reasoning: HistBench and HistAgent", "authors": ["Jiahao Qiu", "Fulian Xiao", "Yimin Wang", "Yuchen Mao", "Yijia Chen", "Xinzhe Juan", "Siran Wang", "Xuan Qi", "Tongcheng Zhang", "Zixin Yao", "Jiacheng Guo", "Yifu Lu", "Charles Argon", "Jundi Cui", "Daixin Chen", "Junran Zhou", "Shuyao Zhou", "Zhanpeng Zhou", "Ling Yang", "Shilong Liu", "Hongru Wang", "Kaixuan Huang", "Xun Jiang", "Yuming Cao", "Yue Chen", "Yunfei Chen", "Zhengyi Chen", "Ruowei Dai", "Mengqiu Deng", "Jiye Fu", "Yunting Gu", "Zijie Guan", "Zirui Huang", "Xiaoyan Ji", "Yumeng Jiang", "Delong Kong", "Haolong Li", "Jiaqi Li", "Ruipeng Li", "Tianze Li", "Zhuoran Li", "Haixia Lian", "Mengyue Lin", "Xudong Liu", "Jiayi Lu", "Jinghan Lu", "Wanyu Luo", "Ziyue Luo", "Zihao Pu", "Zhi Qiao", "Ruihuan Ren", "Liang Wan", "Ruixiang Wang", "Tianhui Wang", "Yang Wang", "Zeyu Wang", "Zihua Wang", "Yujia Wu", "Zhaoyi Wu", "Hao Xin", "Weiao Xing", "Ruojun Xiong", "Weijie Xu", "Yao Shu", "Xiao Yao", "Xiaorui Yang", "Yuchen Yang", "Nan Yi", "Jiadong Yu", "Yangyuxuan Yu", "Huiting Zeng", "Danni Zhang", "Yunjie Zhang", "Zhaoyu Zhang", "Zhiheng Zhang", "Xiaofeng Zheng", "Peirong Zhou", "Linyan Zhong", "Xiaoyin Zong", "Ying Zhao", "Zhenxin Chen", "Lin Ding", "Xiaoyu Gao", "Bingbing Gong", "Yichao Li", "Yang Liao", "Guang Ma", "Tianyuan Ma", "Xinrui Sun", "Tianyi Wang", "Han Xia", "Ruobing Xian", "Gen Ye", "Tengfei Yu", "Wentao Zhang", "Yuxi Wang", "Xi Gao", "Mengdi Wang"], "abstract": "Recent advances in large language models (LLMs) have led to remarkable progress across domains, yet their capabilities in the humanities, particularly history, remain underexplored. Historical reasoning poses unique challenges for AI, involving multimodal source interpretation, temporal inference, and cross-linguistic analysis. While general-purpose agents perform well on many existing benchmarks, they lack the domain-specific expertise required to engage with historical materials and questions. To address this gap, we introduce HistBench, a new benchmark of 414 high-quality questions designed to evaluate AI's capacity for historical reasoning and authored by more than 40 expert contributors. The tasks span a wide range of historical problems-from factual retrieval based on primary sources to interpretive analysis of manuscripts and images, to interdisciplinary challenges involving archaeology, linguistics, or cultural history. Furthermore, the benchmark dataset spans 29 ancient and modern languages and covers a wide range of historical periods and world regions. Finding the poor performance of LLMs and other agents on HistBench, we further present HistAgent, a history-specific agent equipped with carefully designed tools for OCR, translation, archival search, and image understanding in History. On HistBench, HistAgent based on GPT-4o achieves an accuracy of 27.54% pass@1 and 36.47% pass@2, significantly outperforming LLMs with online search and generalist agents, including GPT-4o (18.60%), DeepSeek-R1(14.49%) and Open Deep Research-smolagents(20.29% pass@1 and 25.12% pass@2). These results highlight the limitations of existing LLMs and generalist agents and demonstrate the advantages of HistAgent for historical reasoning.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "17 pages, 7 figures", "pdf_url": "https://arxiv.org/pdf/2505.20246.pdf", "abstract_url": "https://arxiv.org/abs/2505.20246", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了HistBench，一个用于评估AI历史推理能力的新基准，以及HistAgent，一个专为历史推理设计的AI代理。HistAgent在HistBench上显著优于现有的LLMs和通用代理。", "motivation": "解决大型语言模型（LLMs）在人文领域，特别是历史学中能力不足的问题，历史推理涉及多模态源解释、时间推理和跨语言分析等独特挑战。", "method": "引入HistBench基准和HistAgent代理，HistBench包含414个高质量问题，覆盖多种历史问题和多语言；HistAgent配备了OCR、翻译、档案搜索和图像理解等工具。", "result": "HistAgent基于GPT-4o在HistBench上的准确率为27.54%（pass@1）和36.47%（pass@2），显著优于其他LLMs和通用代理。", "conclusion": "现有LLMs和通用代理在历史推理方面存在局限性，HistAgent展示了为特定领域设计的代理在解决复杂历史问题上的优势。"}}
{"id": "2505.19376", "title": "Belief Attribution as Mental Explanation: The Role of Accuracy, Informativity, and Causality", "authors": ["Lance Ying", "Almog Hillel", "Ryan Truong", "Vikash K. Mansinghka", "Joshua B. Tenenbaum", "Tan Zhi-Xuan"], "abstract": "A key feature of human theory-of-mind is the ability to attribute beliefs to other agents as mentalistic explanations for their behavior. But given the wide variety of beliefs that agents may hold about the world and the rich language we can use to express them, which specific beliefs are people inclined to attribute to others? In this paper, we investigate the hypothesis that people prefer to attribute beliefs that are good explanations for the behavior they observe. We develop a computational model that quantifies the explanatory strength of a (natural language) statement about an agent's beliefs via three factors: accuracy, informativity, and causal relevance to actions, each of which can be computed from a probabilistic generative model of belief-driven behavior. Using this model, we study the role of each factor in how people selectively attribute beliefs to other agents. We investigate this via an experiment where participants watch an agent collect keys hidden in boxes in order to reach a goal, then rank a set of statements describing the agent's beliefs about the boxes' contents. We find that accuracy and informativity perform reasonably well at predicting these rankings when combined, but that causal relevance is the single factor that best explains participants' responses.", "subjects": "Computation and Language (cs.CL)", "comments": "8 pages, 3 figures; oral presentation at CogSci 2025", "pdf_url": "https://arxiv.org/pdf/2505.19376.pdf", "abstract_url": "https://arxiv.org/abs/2505.19376", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "人类心智理论的一个关键特征是能够将信念归因于其他主体，作为其行为的心理解释。本研究探讨了人们倾向于归因于那些能够很好解释观察到的行为的信念。通过开发一个计算模型，量化信念陈述的解释强度，研究了准确性、信息量和因果相关性在信念归因中的作用。", "motivation": "解决人们在观察他人行为时，倾向于归因于哪些特定信念的问题，以及这些信念如何作为行为的心理解释。", "method": "开发了一个计算模型，通过准确性、信息量和因果相关性三个因素量化信念陈述的解释强度，并通过实验研究这些因素在信念归因中的作用。", "result": "研究发现，准确性和信息量结合时能较好地预测参与者的排名，但因果相关性是解释参与者响应的最佳单一因素。", "conclusion": "研究表明，人们在归因信念时，特别重视那些与行为有因果关系的信念，这为理解人类心智理论提供了新的视角。"}}
{"id": "2505.19405", "title": "CoTGuard: Using Chain-of-Thought Triggering for Copyright Protection in Multi-Agent LLM Systems", "authors": ["Yan Wen", "Junfeng Guo", "Heng Huang"], "abstract": "As large language models (LLMs) evolve into autonomous agents capable of collaborative reasoning and task execution, multi-agent LLM systems have emerged as a powerful paradigm for solving complex problems. However, these systems pose new challenges for copyright protection, particularly when sensitive or copyrighted content is inadvertently recalled through inter-agent communication and reasoning. Existing protection techniques primarily focus on detecting content in final outputs, overlooking the richer, more revealing reasoning processes within the agents themselves. In this paper, we introduce CoTGuard, a novel framework for copyright protection that leverages trigger-based detection within Chain-of-Thought (CoT) reasoning. Specifically, we can activate specific CoT segments and monitor intermediate reasoning steps for unauthorized content reproduction by embedding specific trigger queries into agent prompts. This approach enables fine-grained, interpretable detection of copyright violations in collaborative agent scenarios. We evaluate CoTGuard on various benchmarks in extensive experiments and show that it effectively uncovers content leakage with minimal interference to task performance. Our findings suggest that reasoning-level monitoring offers a promising direction for safeguarding intellectual property in LLM-based agent systems.", "subjects": "Computation and Language (cs.CL); Cryptography and Security (cs.CR)", "comments": "18 pages, 1 figure", "pdf_url": "https://arxiv.org/pdf/2505.19405.pdf", "abstract_url": "https://arxiv.org/abs/2505.19405", "categories": ["Computation and Language (cs.CL)", "Cryptography and Security (cs.CR)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了CoTGuard，一个利用思维链触发技术在多代理LLM系统中进行版权保护的新框架。通过在代理提示中嵌入特定触发查询，激活特定的思维链段并监控中间推理步骤，以实现对未经授权内容复制的细粒度、可解释检测。", "motivation": "随着大型语言模型（LLMs）发展成为能够进行协作推理和执行任务的自主代理，多代理LLM系统已成为解决复杂问题的强大范式。然而，这些系统在版权保护方面提出了新的挑战，尤其是当敏感或受版权保护的内容通过代理间通信和推理被无意中回忆时。现有的保护技术主要集中于检测最终输出中的内容，忽视了代理内部更丰富、更具揭示性的推理过程。", "method": "本文提出CoTGuard框架，通过在代理提示中嵌入特定触发查询，激活特定的思维链（CoT）段并监控中间推理步骤，以实现对未经授权内容复制的细粒度、可解释检测。", "result": "在大量实验中，我们在各种基准上评估了CoTGuard，并证明它能够有效地发现内容泄露，同时对任务性能的干扰最小。", "conclusion": "我们的研究结果表明，推理级别的监控为在基于LLM的代理系统中保护知识产权提供了一个有前途的方向。"}}
{"id": "2505.19428", "title": "Frictional Agent Alignment Framework: Slow Down and Don't Break Things", "authors": ["Abhijnan Nath", "Carine Graff", "Andrei Bachinin", "Nikhil Krishnaswamy"], "abstract": "AI support of collaborative interactions entails mediating potential misalignment between interlocutor beliefs. Common preference alignment methods like DPO excel in static settings, but struggle in dynamic collaborative tasks where the explicit signals of interlocutor beliefs are sparse and skewed. We propose the Frictional Agent Alignment Framework (FAAF), to generate precise, context-aware \"friction\" that prompts for deliberation and re-examination of existing evidence. FAAF's two-player objective decouples from data skew: a frictive-state policy identifies belief misalignments, while an intervention policy crafts collaborator-preferred responses. We derive an analytical solution to this objective, enabling training a single policy via a simple supervised loss. Experiments on three benchmarks show FAAF outperforms competitors in producing concise, interpretable friction and in OOD generalization. By aligning LLMs to act as adaptive \"thought partners\" -- not passive responders -- FAAF advances scalable, dynamic human-AI collaboration. Our code and data can be found at", "subjects": "Computation and Language (cs.CL)", "comments": "48 pages (main paper: 10 pages incl. Limitations and Acknowledgments; references: 6 pages; appendix: 32 pages), 9 figures, 12 tables, appearing in Proceedings of ACL 2025, Vienna, Austria", "pdf_url": "https://arxiv.org/pdf/2505.19428.pdf", "abstract_url": "https://arxiv.org/abs/2505.19428", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了摩擦代理对齐框架（FAAF），旨在通过生成精确、上下文感知的“摩擦”来促进动态协作任务中的深思熟虑和证据重新审视，从而解决在动态协作任务中常见偏好对齐方法（如DPO）因稀疏和偏斜的明确信号而表现不佳的问题。", "motivation": "解决在动态协作任务中，由于对话者信念的明确信号稀疏和偏斜，常见偏好对齐方法（如DPO）表现不佳的问题。", "method": "提出了摩擦代理对齐框架（FAAF），该框架通过双玩家目标解耦数据偏斜：一个摩擦状态策略识别信念不对齐，而干预策略则制作合作者偏好的响应。", "result": "在三个基准测试中，FAAF在产生简洁、可解释的摩擦和OOD泛化方面优于竞争对手。", "conclusion": "通过将LLMs对齐为自适应的“思考伙伴”而非被动响应者，FAAF推动了可扩展的动态人-AI协作。"}}
{"id": "2505.20266", "title": "syftr: Pareto-Optimal Generative AI", "authors": ["Alexander Conway", "Debadeepta Dey", "Stefan Hackmann", "Matthew Hausknecht", "Michael Schmidt", "Mark Steadman", "Nick Volynets"], "abstract": "Retrieval-Augmented Generation (RAG) pipelines are central to applying large language models (LLMs) to proprietary or dynamic data. However, building effective RAG flows is complex, requiring careful selection among vector databases, embedding models, text splitters, retrievers, and synthesizing LLMs. The challenge deepens with the rise of agentic paradigms. Modules like verifiers, rewriters, and rerankers-each with intricate hyperparameter dependencies have to be carefully tuned. Balancing tradeoffs between latency, accuracy, and cost becomes increasingly difficult in performance-sensitive applications.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "International Conference on Automated Machine Learning (AutoML) 2025", "pdf_url": "https://arxiv.org/pdf/2505.20266.pdf", "abstract_url": "https://arxiv.org/abs/2505.20266", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic", "@RAG"], "AI": {"tldr": "本文介绍了syftr，一种帕累托最优生成AI，旨在解决检索增强生成（RAG）流程中的复杂性，包括向量数据库、嵌入模型、文本分割器、检索器和合成LLM的选择，以及代理范式中的模块调优问题。", "motivation": "解决在应用大型语言模型（LLMs）到专有或动态数据时，构建有效的RAG流程的复杂性，以及在性能敏感应用中平衡延迟、准确性和成本之间的权衡问题。", "method": "提出了一种帕累托最优生成AI方法，通过精心选择和调优RAG流程中的各个模块（如验证器、重写器和重新排序器）及其复杂的超参数依赖关系。", "result": "通过这种方法，可以在性能敏感的应用中更有效地平衡延迟、准确性和成本之间的权衡。", "conclusion": "syftr提供了一种有效的方法来优化RAG流程，解决了在应用LLMs时面临的主要挑战，为性能敏感的应用提供了可行的解决方案。"}}
{"id": "2505.20273", "title": "Ten Principles of AI Agent Economics", "authors": ["Ke Yang", "ChengXiang Zhai"], "abstract": "The rapid rise of AI-based autonomous agents is transforming human society and economic systems, as these entities increasingly exhibit human-like or superhuman intelligence. From excelling at complex games like Go to tackling diverse general-purpose tasks with large language and multimodal models, AI agents are evolving from specialized tools into dynamic participants in social and economic ecosystems. Their autonomy and decision-making capabilities are poised to impact industries, professions, and human lives profoundly, raising critical questions about their integration into economic activities, potential ethical concerns, and the balance between their utility and safety.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.20273.pdf", "abstract_url": "https://arxiv.org/abs/2505.20273", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了AI代理经济学的十大原则，探讨了基于AI的自主代理如何通过展现类人或超人智能来改变人类社会和经济系统。", "motivation": "随着AI代理从专门工具演变为社会和经济生态系统中的动态参与者，其自主性和决策能力对行业、职业和人类生活产生深远影响，引发了关于其在经济活动中整合、潜在伦理问题以及效用与安全之间平衡的关键问题。", "method": "通过分析AI代理在复杂游戏（如围棋）和多样通用任务中的表现，以及大型语言和多模态模型的应用，提出了AI代理经济学的十大原则。", "result": "AI代理的快速发展正深刻改变经济系统和社会结构，其自主性和决策能力对各行各业及人类生活产生重大影响。", "conclusion": "AI代理的集成到经济活动中既带来了巨大的潜力，也引发了伦理和安全方面的挑战，需要在效用与安全之间找到平衡。"}}
{"id": "2505.20286", "title": "Alita: Generalist Agent Enabling Scalable Agentic Reasoning with Minimal Predefinition and Maximal Self-Evolution", "authors": ["Jiahao Qiu", "Xuan Qi", "Tongcheng Zhang", "Xinzhe Juan", "Jiacheng Guo", "Yifu Lu", "Yimin Wang", "Zixin Yao", "Qihan Ren", "Xun Jiang", "Xing Zhou", "Dongrui Liu", "Ling Yang", "Yue Wu", "Kaixuan Huang", "Shilong Liu", "Hongru Wang", "Mengdi Wang"], "abstract": "Recent advances in large language models (LLMs) have enabled agents to autonomously perform complex, open-ended tasks. However, many existing frameworks depend heavily on manually predefined tools and workflows, which hinder their adaptability, scalability, and generalization across domains. In this work, we introduce Alita--a generalist agent designed with the principle of \"Simplicity is the ultimate sophistication,\" enabling scalable agentic reasoning through minimal predefinition and maximal self-evolution. For minimal predefinition, Alita is equipped with only one component for direct problem-solving, making it much simpler and neater than previous approaches that relied heavily on hand-crafted, elaborate tools and workflows. This clean design enhances its potential to generalize to challenging questions, without being limited by tools. For Maximal self-evolution, we enable the creativity of Alita by providing a suite of general-purpose components to autonomously construct, refine, and reuse external capabilities by generating task-related model context protocols (MCPs) from open source, which contributes to scalable agentic reasoning. Notably, Alita achieves 75.15% pass@1 and 87.27% pass@3 accuracy, which is top-ranking among general-purpose agents, on the GAIA benchmark validation dataset, 74.00% and 52.00% pass@1, respectively, on Mathvista and PathVQA, outperforming many agent systems with far greater complexity. More details will be updated at $\\href{", "subjects": "Artificial Intelligence (cs.AI)", "comments": "9 pages, 3 figures", "pdf_url": "https://arxiv.org/pdf/2505.20286.pdf", "abstract_url": "https://arxiv.org/abs/2505.20286", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "Alita是一种通用代理，通过最小化预定义和最大化自我进化，实现了可扩展的代理推理。", "motivation": "解决现有代理框架因依赖手动预定义工具和工作流程而导致的适应性、可扩展性和跨领域泛化能力受限的问题。", "method": "采用“简约至上”的设计原则，仅配备一个直接问题解决组件，并通过生成任务相关的模型上下文协议（MCPs）来自主构建、精炼和重用外部能力。", "result": "在GAIA基准验证数据集上，Alita实现了75.15%的pass@1和87.27%的pass@3准确率，在Mathvista和PathVQA上也表现出色，优于许多复杂度更高的代理系统。", "conclusion": "Alita的设计不仅简化了代理的构建过程，还通过自我进化机制显著提升了其性能和泛化能力，为通用代理的发展提供了新的方向。"}}
{"id": "2505.17648", "title": "Simulating Macroeconomic Expectations using LLM Agents", "authors": ["Jianhao Lin", "Lexuan Sun", "Yixin Yan"], "abstract": "We introduce a novel framework for simulating macroeconomic expectation formation using Large Language Model-Empowered Agents (LLM Agents). By constructing thousands of LLM Agents equipped with modules for personal characteristics, prior expectations, and knowledge, we replicate a survey experiment involving households and experts on inflation and unemployment. Our results show that although the expectations and thoughts generated by LLM Agents are more homogeneous than those of human participants, they still effectively capture key heterogeneity across agents and the underlying drivers of expectation formation. Furthermore, a module-ablation exercise highlights the critical role of prior expectations in simulating such heterogeneity. This approach complements traditional survey methods and offers new insights into AI behavioral science in macroeconomic research.", "subjects": "General Economics (econ.GN); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.17648.pdf", "abstract_url": "https://arxiv.org/abs/2505.17648", "categories": ["General Economics (econ.GN)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一种使用大型语言模型赋能代理（LLM Agents）模拟宏观经济预期形成的新框架。通过构建数千个配备个人特征、先前预期和知识模块的LLM代理，复制了一项关于家庭和专家对通货膨胀和失业的预期调查实验。结果表明，尽管LLM代理生成的预期和想法比人类参与者更为同质化，但它们仍能有效捕捉代理之间的关键异质性及预期形成的潜在驱动因素。此外，模块消融实验强调了先前预期在模拟此类异质性中的关键作用。这种方法补充了传统的调查方法，并为宏观经济研究中的AI行为科学提供了新的见解。", "motivation": "解决传统调查方法在模拟宏观经济预期形成中的局限性，探索AI行为科学在宏观经济研究中的应用潜力。", "method": "构建数千个配备个人特征、先前预期和知识模块的LLM代理，复制一项关于通货膨胀和失业的预期调查实验。", "result": "LLM代理生成的预期和想法比人类参与者更为同质化，但仍能有效捕捉代理之间的关键异质性及预期形成的潜在驱动因素。模块消融实验显示先前预期在模拟异质性中起关键作用。", "conclusion": "该方法不仅补充了传统的调查方法，还为宏观经济研究中的AI行为科学提供了新的见解，展示了LLM代理在模拟复杂经济现象中的潜力。"}}
{"id": "2505.18156", "title": "InjectLab: A Tactical Framework for Adversarial Threat Modeling Against Large Language Models", "authors": ["Austin Howard"], "abstract": "Large Language Models (LLMs) are changing the way people interact with technology. Tools like ChatGPT and Claude AI are now common in business, research, and everyday life. But with that growth comes new risks, especially prompt-based attacks that exploit how these models process language. InjectLab is a security framework designed to address that problem. This paper introduces InjectLab as a structured, open-source matrix that maps real-world techniques used to manipulate LLMs. The framework is inspired by MITRE ATT&CK and focuses specifically on adversarial behavior at the prompt layer. It includes over 25 techniques organized under six core tactics, covering threats like instruction override, identity swapping, and multi-agent exploitation. Each technique in InjectLab includes detection guidance, mitigation strategies, and YAML-based simulation tests. A Python tool supports easy execution of prompt-based test cases. This paper outlines the framework's structure, compares it to other AI threat taxonomies, and discusses its future direction as a practical, community-driven foundation for securing language models.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.18156.pdf", "abstract_url": "https://arxiv.org/abs/2505.18156", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "InjectLab是一个针对大型语言模型（LLMs）的安全框架，旨在解决提示型攻击问题。它提供了一个结构化的开源矩阵，映射了操纵LLMs的实际技术，包括超过25种技术，分为六种核心策略，并提供检测指南、缓解策略和基于YAML的模拟测试。", "motivation": "随着大型语言模型（如ChatGPT和Claude AI）在商业、研究和日常生活中的广泛应用，提示型攻击等新风险也随之增加。InjectLab旨在解决这一问题，提供一个系统的安全框架来对抗这些威胁。", "method": "InjectLab框架受到MITRE ATT&CK的启发，专注于提示层的对抗行为，包括超过25种技术，分为六种核心策略。每种技术都包含检测指南、缓解策略和基于YAML的模拟测试，并支持通过Python工具轻松执行提示型测试用例。", "result": "InjectLab提供了一个实用的、社区驱动的框架，用于映射和对抗大型语言模型的提示型攻击，包括指令覆盖、身份交换和多代理利用等威胁。", "conclusion": "InjectLab作为一个结构化的安全框架，为大型语言模型的安全提供了实用的解决方案，并有望成为社区驱动的语言模型安全基础。"}}
{"id": "2505.19494", "title": "Anveshana: A New Benchmark Dataset for Cross-Lingual Information Retrieval On English Queries and Sanskrit Documents", "authors": ["Manoj Balaji Jagadeeshan", "Prince Raj", "Pawan Goyal"], "abstract": "The study presents a comprehensive benchmark for retrieving Sanskrit documents using English queries, focusing on the chapters of the Srimadbhagavatam. It employs a tripartite approach: Direct Retrieval (DR), Translation-based Retrieval (DT), and Query Translation (QT), utilizing shared embedding spaces and advanced translation methods to enhance retrieval systems in a RAG framework. The study fine-tunes state-of-the-art models for Sanskrit's linguistic nuances, evaluating models such as BM25, REPLUG, mDPR, ColBERT, Contriever, and GPT-2. It adapts summarization techniques for Sanskrit documents to improve QA processing. Evaluation shows DT methods outperform DR and QT in handling the cross-lingual challenges of ancient texts, improving accessibility and understanding. A dataset of 3,400 English-Sanskrit query-document pairs underpins the study, aiming to preserve Sanskrit scriptures and share their philosophical importance widely. Our dataset is publicly available at", "subjects": "Computation and Language (cs.CL); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19494.pdf", "abstract_url": "https://arxiv.org/abs/2505.19494", "categories": ["Computation and Language (cs.CL)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "该研究提出了一个用于英语查询和梵文文档跨语言信息检索的新基准数据集，专注于《Srimadbhagavatam》的章节。", "motivation": "解决在英语查询和梵文文档之间进行跨语言信息检索的挑战，特别是针对古代文本的可访问性和理解。", "method": "采用三重方法：直接检索（DR）、基于翻译的检索（DT）和查询翻译（QT），利用共享嵌入空间和先进的翻译方法在RAG框架中增强检索系统。", "result": "评估显示，DT方法在处理古代文本的跨语言挑战方面优于DR和QT，提高了可访问性和理解。", "conclusion": "研究旨在保存梵文经文并广泛分享其哲学重要性，提供了一个包含3,400个英语-梵文查询-文档对的数据集，该数据集已公开可用。"}}
{"id": "2505.18214", "title": "LA-RCS: LLM-Agent-Based Robot Control System", "authors": ["TaekHyun Park", "YoungJun Choi", "SeungHoon Shin", "Kwangil Lee"], "abstract": "LA-RCS (LLM-agent-based robot control system) is a sophisticated robot control system designed to autonomously plan, work, and analyze the external environment based on user requirements by utilizing LLM-Agent. Utilizing a dual-agent framework, LA-RCS generates plans based on user requests, observes the external environment, executes the plans, and modifies the plans as needed to adapt to changes in the external conditions. Additionally, LA-RCS interprets natural language commands by the user and converts them into commands compatible with the robot interface so that the robot can execute tasks and meet user requests properly. During his process, the system autonomously evaluates observation results, provides feedback on the tasks, and executes commands based on real-time environmental monitoring, significantly reducing the need for user intervention in fulfilling requests. We categorized the scenarios that LA-RCS needs to perform into four distinct types and conducted a quantitative assessment of its performance in each scenario. The results showed an average success rate of 90 percent, demonstrating the system capability to fulfill user requests satisfactorily. For more extensive results, readers can visit our project page:", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18214.pdf", "abstract_url": "https://arxiv.org/abs/2505.18214", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "LA-RCS是一种基于LLM-Agent的机器人控制系统，能够自主规划、工作并分析外部环境，通过双代理框架生成计划、观察环境、执行计划并根据需要调整计划以适应外部条件变化。", "motivation": "解决机器人控制系统如何更自主地理解和执行用户自然语言命令，减少用户干预的需求。", "method": "利用双代理框架和LLM-Agent技术，系统能够解释自然语言命令，生成并调整执行计划，实时监控环境并提供反馈。", "result": "在四种不同场景下的定量评估中，系统平均成功率达到90%，显示出其能够有效满足用户需求。", "conclusion": "LA-RCS展示了基于LLM-Agent的机器人控制系统在自主执行任务和适应环境变化方面的潜力，显著减少了用户干预。"}}
{"id": "2505.19538", "title": "DoctorRAG: Medical RAG Fusing Knowledge with Patient Analogy through Textual Gradients", "authors": ["Yuxing Lu", "Gecheng Fu", "Wei Wu", "Xukai Zhao", "Sin Yee Goi", "Jinzhuo Wang"], "abstract": "Existing medical RAG systems mainly leverage knowledge from medical knowledge bases, neglecting the crucial role of experiential knowledge derived from similar patient cases -- a key component of human clinical reasoning. To bridge this gap, we propose DoctorRAG, a RAG framework that emulates doctor-like reasoning by integrating both explicit clinical knowledge and implicit case-based experience. DoctorRAG enhances retrieval precision by first allocating conceptual tags for queries and knowledge sources, together with a hybrid retrieval mechanism from both relevant knowledge and patient. In addition, a Med-TextGrad module using multi-agent textual gradients is integrated to ensure that the final output adheres to the retrieved knowledge and patient query. Comprehensive experiments on multilingual, multitask datasets demonstrate that DoctorRAG significantly outperforms strong baseline RAG models and gains improvements from iterative refinements. Our approach generates more accurate, relevant, and comprehensive responses, taking a step towards more doctor-like medical reasoning systems.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Information Retrieval (cs.IR); Multiagent Systems (cs.MA)", "comments": "32 pages, 5 figures, 5 tables", "pdf_url": "https://arxiv.org/pdf/2505.19538.pdf", "abstract_url": "https://arxiv.org/abs/2505.19538", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Computational Engineering, Finance, and Science (cs.CE)", "Information Retrieval (cs.IR)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "DoctorRAG是一个融合医学知识和患者类比经验的RAG框架，通过概念标签分配和混合检索机制提高检索精度，并结合Med-TextGrad模块确保输出与检索知识和患者查询一致，实验表明其在多语言、多任务数据集上显著优于基线模型。", "motivation": "现有的医学RAG系统主要利用医学知识库中的知识，忽视了从类似患者案例中获得的经验知识，这是人类临床推理的关键组成部分。", "method": "DoctorRAG通过分配概念标签和混合检索机制从相关知识和患者中检索，并集成Med-TextGrad模块使用多代理文本梯度确保输出一致性。", "result": "在多语言、多任务数据集上的综合实验显示，DoctorRAG显著优于强基线RAG模型，并通过迭代改进获得提升。", "conclusion": "DoctorRAG生成了更准确、相关和全面的响应，朝着更类似医生的医学推理系统迈出了一步。"}}
{"id": "2505.19591", "title": "Multi-Agent Collaboration via Evolving Orchestration", "authors": ["Yufan Dang", "Chen Qian", "Xueheng Luo", "Jingru Fan", "Zihao Xie", "Ruijie Shi", "Weize Chen", "Cheng Yang", "Xiaoyin Che", "Ye Tian", "Xuantang Xiong", "Lei Han", "Zhiyuan Liu", "Maosong Sun"], "abstract": "Large language models (LLMs) have achieved remarkable results across diverse downstream tasks, but their monolithic nature restricts scalability and efficiency in complex problem-solving. While recent research explores multi-agent collaboration among LLMs, most approaches rely on static organizational structures that struggle to adapt as task complexity and agent numbers grow, resulting in coordination overhead and inefficiencies. To this end, we propose a puppeteer-style paradigm for LLM-based multi-agent collaboration, where a centralized orchestrator (\"puppeteer\") dynamically directs agents (\"puppets\") in response to evolving task states. This orchestrator is trained via reinforcement learning to adaptively sequence and prioritize agents, enabling flexible and evolvable collective reasoning. Experiments on closed- and open-domain scenarios show that this method achieves superior performance with reduced computational costs. Analyses further reveal that the key improvements consistently stem from the emergence of more compact, cyclic reasoning structures under the orchestrator's evolution.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "Work in Progress", "pdf_url": "https://arxiv.org/pdf/2505.19591.pdf", "abstract_url": "https://arxiv.org/abs/2505.19591", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于大语言模型（LLMs）的多智能体协作新范式，通过中央协调器动态指导智能体，以适应任务状态的变化，从而提高复杂问题解决的效率和可扩展性。", "motivation": "大语言模型在多下游任务中表现出色，但其单一性限制了在复杂问题解决中的可扩展性和效率。现有的多智能体协作方法多依赖静态组织结构，难以适应任务复杂性和智能体数量的增长，导致协调开销和效率低下。", "method": "提出了一种“木偶师”风格的范式，其中中央协调器（“木偶师”）通过强化学习训练，动态地指导和优先排序智能体（“木偶”），以实现灵活和可进化的集体推理。", "result": "在封闭和开放领域的实验中，该方法以更低的计算成本实现了卓越的性能。分析进一步表明，关键改进来自于在协调器指导下出现的更紧凑、循环的推理结构。", "conclusion": "通过动态协调多智能体协作，本研究不仅提高了问题解决的效率和灵活性，还为未来多智能体系统的设计提供了新的方向。"}}
{"id": "2505.19549", "title": "Towards Multi-Granularity Memory Association and Selection for Long-Term Conversational Agents", "authors": ["Derong Xu", "Yi Wen", "Pengyue Jia", "Yingyi Zhang", "wenlin zhang", "Yichao Wang", "Huifeng Guo", "Ruiming Tang", "Xiangyu Zhao", "Enhong Chen", "Tong Xu"], "abstract": "Large Language Models (LLMs) have recently been widely adopted in conversational agents. However, the increasingly long interactions between users and agents accumulate extensive dialogue records, making it difficult for LLMs with limited context windows to maintain a coherent long-term dialogue memory and deliver personalized responses. While retrieval-augmented memory systems have emerged to address this issue, existing methods often depend on single-granularity memory segmentation and retrieval. This approach falls short in capturing deep memory connections, leading to partial retrieval of useful information or substantial noise, resulting in suboptimal performance. To tackle these limits, we propose MemGAS, a framework that enhances memory consolidation by constructing multi-granularity association, adaptive selection, and retrieval. MemGAS is based on multi-granularity memory units and employs Gaussian Mixture Models to cluster and associate new memories with historical ones. An entropy-based router adaptively selects optimal granularity by evaluating query relevance distributions and balancing information completeness and noise. Retrieved memories are further refined via LLM-based filtering. Experiments on four long-term memory benchmarks demonstrate that MemGAS outperforms state-of-the-art methods on both question answer and retrieval tasks, achieving superior performance across different query types and top-K settings.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19549.pdf", "abstract_url": "https://arxiv.org/abs/2505.19549", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出MemGAS框架，通过构建多粒度关联、自适应选择和检索来增强记忆整合，解决长对话中LLMs因有限上下文窗口而难以维持连贯长期对话记忆和提供个性化响应的问题。", "motivation": "大型语言模型（LLMs）在对话代理中的应用日益广泛，但用户与代理之间长时间的互动积累了大量的对话记录，使得具有有限上下文窗口的LLMs难以维持连贯的长期对话记忆并提供个性化响应。现有的检索增强记忆系统往往依赖于单粒度记忆分割和检索，这种方法在捕捉深层记忆连接方面存在不足，导致有用信息的部分检索或大量噪音，从而影响性能。", "method": "提出MemGAS框架，基于多粒度记忆单元，采用高斯混合模型（Gaussian Mixture Models）对新记忆与历史记忆进行聚类和关联。通过基于熵的路由器评估查询相关性分布并平衡信息完整性和噪音，自适应选择最佳粒度。检索到的记忆通过基于LLM的过滤进一步细化。", "result": "在四个长期记忆基准测试上的实验表明，MemGAS在问答和检索任务上均优于现有最先进方法，在不同查询类型和top-K设置下均实现了卓越性能。", "conclusion": "MemGAS通过多粒度记忆关联和自适应选择，有效提升了长对话代理的记忆整合和检索能力，为长对话记忆管理提供了新的解决方案。"}}
{"id": "2505.19630", "title": "DoctorAgent-RL: A Multi-Agent Collaborative Reinforcement Learning System for Multi-Turn Clinical Dialogue", "authors": ["Yichun Feng", "Jiawei Wang", "Lu Zhou", "Yixue Li"], "abstract": "Large language models (LLMs) have demonstrated excellent capabilities in the field of biomedical question answering, but their application in real-world clinical consultations still faces core challenges. Existing systems rely on a one-way information transmission mode where patients must fully describe their symptoms in a single round, leading to nonspecific diagnostic recommendations when complaints are vague. Traditional multi-turn dialogue methods based on supervised learning are constrained by static data-driven paradigms, lacking generalizability and struggling to intelligently extract key clinical information. To address these limitations, we propose DoctorAgent-RL, a reinforcement learning (RL)-based multi-agent collaborative framework that models medical consultations as a dynamic decision-making process under uncertainty. The doctor agent continuously optimizes its questioning strategy within the RL framework through multi-turn interactions with the patient agent, dynamically adjusting its information-gathering path based on comprehensive rewards from the Consultation Evaluator. This RL fine-tuning mechanism enables LLMs to autonomously develop interaction strategies aligned with clinical reasoning logic, rather than superficially imitating patterns in existing dialogue data. Notably, we constructed MTMedDialog, the first English multi-turn medical consultation dataset capable of simulating patient interactions. Experiments demonstrate that DoctorAgent-RL outperforms existing models in both multi-turn reasoning capability and final diagnostic performance, demonstrating practical value in assisting clinical consultations.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19630.pdf", "abstract_url": "https://arxiv.org/abs/2505.19630", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了DoctorAgent-RL，一个基于强化学习的多代理协作框架，用于解决临床多轮对话中的信息提取和诊断推荐问题。通过模拟医患互动，该系统能够动态调整提问策略，优化临床推理逻辑。", "motivation": "现有临床咨询系统依赖单向信息传输和静态数据驱动的多轮对话方法，面对模糊症状描述时推荐非特异性诊断，缺乏通用性和智能信息提取能力。", "method": "提出DoctorAgent-RL，一个基于强化学习的多代理协作框架，将医疗咨询建模为不确定性下的动态决策过程，通过多轮互动优化提问策略。", "result": "实验表明，DoctorAgent-RL在多轮推理能力和最终诊断性能上优于现有模型，展示了在辅助临床咨询中的实用价值。", "conclusion": "DoctorAgent-RL通过强化学习机制，使大型语言模型能够自主开发符合临床推理逻辑的互动策略，而非简单模仿现有对话数据模式，为临床咨询提供了新的解决方案。"}}
{"id": "2505.18229", "title": "BEDI: A Comprehensive Benchmark for Evaluating Embodied Agents on UAVs", "authors": ["Mingning Guo", "Mengwei Wu", "Jiarun He", "Shaoxian Li", "Haifeng Li", "Chao Tao"], "abstract": "With the rapid advancement of low-altitude remote sensing and Vision-Language Models (VLMs), Embodied Agents based on Unmanned Aerial Vehicles (UAVs) have shown significant potential in autonomous tasks. However, current evaluation methods for UAV-Embodied Agents (UAV-EAs) remain constrained by the lack of standardized benchmarks, diverse testing scenarios and open system interfaces. To address these challenges, we propose BEDI (Benchmark for Embodied Drone Intelligence), a systematic and standardized benchmark designed for evaluating UAV-EAs. Specifically, we introduce a novel Dynamic Chain-of-Embodied-Task paradigm based on the perception-decision-action loop, which decomposes complex UAV tasks into standardized, measurable subtasks. Building on this paradigm, we design a unified evaluation framework encompassing five core sub-skills: semantic perception, spatial perception, motion control, tool utilization, and task planning. Furthermore, we construct a hybrid testing platform that integrates static real-world environments with dynamic virtual scenarios, enabling comprehensive performance assessment of UAV-EAs across varied contexts. The platform also offers open and standardized interfaces, allowing researchers to customize tasks and extend scenarios, thereby enhancing flexibility and scalability in the evaluation process. Finally, through empirical evaluations of several state-of-the-art (SOTA) VLMs, we reveal their limitations in embodied UAV tasks, underscoring the critical role of the BEDI benchmark in advancing embodied intelligence research and model optimization. By filling the gap in systematic and standardized evaluation within this field, BEDI facilitates objective model comparison and lays a robust foundation for future development in this field. Our benchmark will be released at", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18229.pdf", "abstract_url": "https://arxiv.org/abs/2505.18229", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了BEDI（Benchmark for Embodied Drone Intelligence），一个系统化、标准化的基准测试，用于评估基于无人机的具身智能体（UAV-EAs）。通过引入动态具身任务链范式，将复杂任务分解为可测量的子任务，并设计了一个统一的评估框架和混合测试平台，以促进该领域的客观模型比较和未来发展。", "motivation": "当前对无人机具身智能体（UAV-EAs）的评估方法缺乏标准化的基准测试、多样化的测试场景和开放的系统接口，限制了评估的有效性和灵活性。", "method": "提出BEDI基准测试，包括基于感知-决策-行动循环的动态具身任务链范式，统一的评估框架（涵盖五个核心子技能），以及结合静态真实环境和动态虚拟场景的混合测试平台。", "result": "通过对多个最先进的视觉语言模型（VLMs）的实证评估，揭示了它们在具身无人机任务中的局限性，强调了BEDI基准在推动具身智能研究和模型优化中的关键作用。", "conclusion": "BEDI填补了该领域系统化和标准化评估的空白，为未来的发展奠定了坚实的基础，并将促进该领域的客观模型比较和进一步研究。"}}
{"id": "2505.19952", "title": "Multimodal Reasoning Agent for Zero-Shot Composed Image Retrieval", "authors": ["Rong-Cheng Tu", "Wenhao Sun", "Hanzhe You", "Yingjie Wang", "Jiaxing Huang", "Li Shen", "Dacheng Tao"], "abstract": "Zero-Shot Composed Image Retrieval (ZS-CIR) aims to retrieve target images given a compositional query, consisting of a reference image and a modifying text-without relying on annotated training data. Existing approaches often generate a synthetic target text using large language models (LLMs) to serve as an intermediate anchor between the compositional query and the target image. Models are then trained to align the compositional query with the generated text, and separately align images with their corresponding texts using contrastive learning. However, this reliance on intermediate text introduces error propagation, as inaccuracies in query-to-text and text-to-image mappings accumulate, ultimately degrading retrieval performance. To address these problems, we propose a novel framework by employing a Multimodal Reasoning Agent (MRA) for ZS-CIR. MRA eliminates the dependence on textual intermediaries by directly constructing triplets, <reference image, modification text, target image>, using only unlabeled image data. By training on these synthetic triplets, our model learns to capture the relationships between compositional queries and candidate images directly. Extensive experiments on three standard CIR benchmarks demonstrate the effectiveness of our approach. On the FashionIQ dataset, our method improves Average R@10 by at least 7.5\\% over existing baselines; on CIRR, it boosts R@1 by 9.6\\%; and on CIRCO, it increases mAP@5 by 9.5\\%.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19952.pdf", "abstract_url": "https://arxiv.org/abs/2505.19952", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Information Retrieval (cs.IR)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新型的多模态推理代理（MRA）框架，用于零样本组合图像检索（ZS-CIR），通过直接构建三元组来避免依赖文本中介，从而提高了检索性能。", "motivation": "解决零样本组合图像检索中因依赖中间文本而导致的错误传播问题，提高检索准确率。", "method": "采用多模态推理代理（MRA）直接构建<参考图像、修改文本、目标图像>三元组，利用未标记的图像数据进行训练，直接学习组合查询与候选图像之间的关系。", "result": "在三个标准CIR基准测试中，该方法显著提高了检索性能，特别是在FashionIQ数据集上平均R@10提高了至少7.5%，在CIRR上R@1提高了9.6%，在CIRCO上mAP@5提高了9.5%。", "conclusion": "提出的MRA框架有效解决了零样本组合图像检索中的错误传播问题，显著提高了检索性能，为未来的研究提供了新的方向。"}}
{"id": "2505.19647", "title": "Select, Read, and Write: A Multi-Agent Framework of Full-Text-based Related Work Generation", "authors": ["Xiaochuan Liu", "Ruihua Song", "Xiting Wang", "Xu Chen"], "abstract": "Automatic related work generation (RWG) can save people's time and effort when writing a draft of related work section (RWS) for further revision. However, existing methods for RWG always suffer from shallow comprehension due to taking the limited portions of references papers as input and isolated explanation for each reference due to ineffective capturing the relationships among them. To address these issues, we focus on full-text-based RWG task and propose a novel multi-agent framework. Our framework consists of three agents: a selector that decides which section of the papers is going to read next, a reader that digests the selected section and updates a shared working memory, and a writer that generates RWS based on the final curated memory. To better capture the relationships among references, we also propose two graph-aware strategies for selector, enabling to optimize the reading order with constrains of the graph structure. Extensive experiments demonstrate that our framework consistently improves performance across three base models and various input configurations. The graph-aware selectors outperform alternative selectors, achieving state-of-the-art results. The code and data are available at", "subjects": "Computation and Language (cs.CL)", "comments": "Accepted by ACL 2025 (Findings)", "pdf_url": "https://arxiv.org/pdf/2505.19647.pdf", "abstract_url": "https://arxiv.org/abs/2505.19647", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于全文的多智能体框架，用于自动生成相关工作章节，通过选择、阅读和写作三个智能体的协作，解决了现有方法在浅层理解和孤立解释方面的不足。", "motivation": "解决自动生成相关工作章节时因输入有限和无法有效捕捉参考文献间关系而导致的理解浅层和解释孤立的问题。", "method": "提出了一个由选择器、阅读器和写作器三个智能体组成的多智能体框架，其中选择器决定下一步阅读论文的哪一部分，阅读器消化所选部分并更新共享工作记忆，写作器基于最终整理的内存生成相关工作章节。此外，还为选择器提出了两种图感知策略，以优化阅读顺序。", "result": "大量实验表明，该框架在三个基础模型和各种输入配置下均能持续提高性能，图感知选择器的表现优于其他选择器，达到了最先进的结果。", "conclusion": "提出的多智能体框架和图感知策略有效提升了自动生成相关工作章节的质量和效率，为相关领域的研究提供了新的思路和方法。"}}
{"id": "2505.18279", "title": "Collaborative Memory: Multi-User Memory Sharing in LLM Agents with Dynamic Access Control", "authors": ["Alireza Rezazadeh", "Zichao Li", "Ange Lou", "Yuying Zhao", "Wei Wei", "Yujia Bao"], "abstract": "Complex tasks are increasingly delegated to ensembles of specialized LLM-based agents that reason, communicate, and coordinate actions-both among themselves and through interactions with external tools, APIs, and databases. While persistent memory has been shown to enhance single-agent performance, most approaches assume a monolithic, single-user context-overlooking the benefits and challenges of knowledge transfer across users under dynamic, asymmetric permissions. We introduce Collaborative Memory, a framework for multi-user, multi-agent environments with asymmetric, time-evolving access controls encoded as bipartite graphs linking users, agents, and resources. Our system maintains two memory tiers: (1) private memory-private fragments visible only to their originating user; and (2) shared memory-selectively shared fragments. Each fragment carries immutable provenance attributes (contributing agents, accessed resources, and timestamps) to support retrospective permission checks. Granular read policies enforce current user-agent-resource constraints and project existing memory fragments into filtered transformed views. Write policies determine fragment retention and sharing, applying context-aware transformations to update the memory. Both policies may be designed conditioned on system, agent, and user-level information. Our framework enables safe, efficient, and interpretable cross-user knowledge sharing, with provable adherence to asymmetric, time-varying policies and full auditability of memory operations.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18279.pdf", "abstract_url": "https://arxiv.org/abs/2505.18279", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了协作记忆框架，旨在多用户、多代理环境中实现动态、不对称权限下的知识共享。", "motivation": "解决在多用户、多代理环境中，如何安全、高效地实现知识共享，同时满足动态、不对称的访问控制需求。", "method": "提出一个包含私有记忆和共享记忆两层的框架，利用二分图编码用户、代理和资源之间的关系，实施细粒度的读写策略。", "result": "开发了一个支持安全、高效、可解释的跨用户知识共享的系统，能够证明其遵守不对称、时间变化的政策，并完全可审计记忆操作。", "conclusion": "协作记忆框架为多用户、多代理环境中的知识共享提供了一种新颖的解决方案，具有重要的实际应用价值。"}}
{"id": "2505.18286", "title": "Single-agent or Multi-agent Systems? Why Not Both?", "authors": ["Mingyan Gao", "Yanzi Li", "Banruo Liu", "Yifan Yu", "Phillip Wang", "Ching-Yu Lin", "Fan Lai"], "abstract": "Multi-agent systems (MAS) decompose complex tasks and delegate subtasks to different large language model (LLM) agents and tools. Prior studies have reported the superior accuracy performance of MAS across diverse domains, enabled by long-horizon context tracking and error correction through role-specific agents. However, the design and deployment of MAS incur higher complexity and runtime cost compared to single-agent systems (SAS). Meanwhile, frontier LLMs, such as OpenAI-o3 and Gemini-2.5-Pro, have rapidly advanced in long-context reasoning, memory retention, and tool usage, mitigating many limitations that originally motivated MAS designs. In this paper, we conduct an extensive empirical study comparing MAS and SAS across various popular agentic applications. We find that the benefits of MAS over SAS diminish as LLM capabilities improve, and we propose efficient mechanisms to pinpoint the error-prone agent in MAS. Furthermore, the performance discrepancy between MAS and SAS motivates our design of a hybrid agentic paradigm, request cascading between MAS and SAS, to improve both efficiency and capability. Our design improves accuracy by 1.1-12% while reducing deployment costs by up to 20% across various agentic applications.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18286.pdf", "abstract_url": "https://arxiv.org/abs/2505.18286", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文探讨了多智能体系统（MAS）与单智能体系统（SAS）的比较，并提出了一种混合代理范式，以在效率和能力之间取得平衡。", "motivation": "随着大型语言模型（LLM）能力的提升，多智能体系统（MAS）相对于单智能体系统（SAS）的优势逐渐减弱，但MAS的设计和部署成本较高。本文旨在比较MAS和SAS在不同代理应用中的表现，并提出更高效的解决方案。", "method": "通过广泛的实证研究比较MAS和SAS在各种流行代理应用中的表现，并提出了一种混合代理范式，即在MAS和SAS之间进行请求级联。", "result": "研究发现，随着LLM能力的提高，MAS相对于SAS的优势减弱。提出的混合代理范式在提高准确性的同时，降低了部署成本。", "conclusion": "本文提出了一种混合代理范式，有效地结合了MAS和SAS的优势，既提高了准确性，又降低了成本，为代理系统的设计提供了新的方向。"}}
{"id": "2505.19754", "title": "NeuSym-RAG: Hybrid Neural Symbolic Retrieval with Multiview Structuring for PDF Question Answering", "authors": ["Ruisheng Cao", "Hanchong Zhang", "Tiancheng Huang", "Zhangyi Kang", "Yuxin Zhang", "Liangtai Sun", "Hanqi Li", "Yuxun Miao", "Shuai Fan", "Lu Chen", "Kai Yu"], "abstract": "The increasing number of academic papers poses significant challenges for researchers to efficiently acquire key details. While retrieval augmented generation (RAG) shows great promise in large language model (LLM) based automated question answering, previous works often isolate neural and symbolic retrieval despite their complementary strengths. Moreover, conventional single-view chunking neglects the rich structure and layout of PDFs, e.g., sections and tables. In this work, we propose NeuSym-RAG, a hybrid neural symbolic retrieval framework which combines both paradigms in an interactive process. By leveraging multi-view chunking and schema-based parsing, NeuSym-RAG organizes semi-structured PDF content into both the relational database and vectorstore, enabling LLM agents to iteratively gather context until sufficient to generate answers. Experiments on three full PDF-based QA datasets, including a self-annotated one AIRQA-REAL, show that NeuSym-RAG stably defeats both the vector-based RAG and various structured baselines, highlighting its capacity to unify both retrieval schemes and utilize multiple views. Code and data are publicly available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "29 pages, 11 figures, 12 tables, accepted to ACL 2025 Long Main", "pdf_url": "https://arxiv.org/pdf/2505.19754.pdf", "abstract_url": "https://arxiv.org/abs/2505.19754", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "NeuSym-RAG是一种混合神经符号检索框架，旨在通过结合神经和符号检索的优势，以及利用PDF的多视图结构，提高基于大型语言模型(LLM)的PDF问答系统的效率。", "motivation": "学术论文数量的增加使得研究人员难以高效获取关键信息。现有的检索增强生成(RAG)方法往往孤立神经和符号检索，忽视了PDF丰富的结构和布局。", "method": "提出NeuSym-RAG框架，通过多视图分块和基于模式的解析，将半结构化PDF内容组织到关系数据库和向量存储中，使LLM代理能够迭代收集上下文直至足够生成答案。", "result": "在三个基于PDF的QA数据集上的实验表明，NeuSym-RAG稳定优于基于向量的RAG和各种结构化基线，展示了其统一两种检索方案和利用多视图的能力。", "conclusion": "NeuSym-RAG通过结合神经和符号检索的优势，以及利用PDF的多视图结构，显著提高了PDF问答系统的性能，为未来的研究提供了有价值的工具和方法。"}}
{"id": "2505.19768", "title": "T^2Agent A Tool-augmented Multimodal Misinformation Detection Agent with Monte Carlo Tree Search", "authors": ["Xing Cui", "Yueying Zou", "Zekun Li", "Peipei Li", "Xinyuan Xu", "Xuannan Liu", "Huaibo Huang", "Ran He"], "abstract": "Real-world multimodal misinformation often arises from mixed forgery sources, requiring dynamic reasoning and adaptive verification. However, existing methods mainly rely on static pipelines and limited tool usage, limiting their ability to handle such complexity and diversity. To address this challenge, we propose T2Agent, a novel misinformation detection agent that incorporates an extensible toolkit with Monte Carlo Tree Search (MCTS). The toolkit consists of modular tools such as web search, forgery detection, and consistency analysis. Each tool is described using standardized templates, enabling seamless integration and future expansion. To avoid inefficiency from using all tools simultaneously, a Bayesian optimization-based selector is proposed to identify a task-relevant subset. This subset then serves as the action space for MCTS to dynamically collect evidence and perform multi-source verification. To better align MCTS with the multi-source nature of misinformation detection, T2Agent extends traditional MCTS with multi-source verification, which decomposes the task into coordinated subtasks targeting different forgery sources. A dual reward mechanism containing a reasoning trajectory score and a confidence score is further proposed to encourage a balance between exploration across mixed forgery sources and exploitation for more reliable evidence. We conduct ablation studies to confirm the effectiveness of the tree search mechanism and tool usage. Extensive experiments further show that T2Agent consistently outperforms existing baselines on challenging mixed-source multimodal misinformation benchmarks, demonstrating its strong potential as a training-free approach for enhancing detection accuracy. The code will be released.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19768.pdf", "abstract_url": "https://arxiv.org/abs/2505.19768", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了T^2Agent，一种结合蒙特卡洛树搜索（MCTS）和可扩展工具包的新型多模态虚假信息检测代理，旨在动态推理和自适应验证混合伪造来源的虚假信息。", "motivation": "现实世界中的多模态虚假信息往往来源于混合伪造来源，需要动态推理和自适应验证。现有方法主要依赖静态流程和有限工具使用，难以应对这种复杂性和多样性。", "method": "T^2Agent采用了一个包含模块化工具（如网络搜索、伪造检测和一致性分析）的可扩展工具包，并通过蒙特卡洛树搜索（MCTS）动态收集证据和执行多源验证。为了优化工具使用，提出了基于贝叶斯优化的选择器来确定任务相关工具子集。", "result": "实验表明，T^2Agent在具有挑战性的混合来源多模态虚假信息基准测试中 consistently outperforms 现有基线方法，证明了其作为无需训练的方法在提高检测准确性方面的强大潜力。", "conclusion": "T^2Agent通过结合可扩展工具包和蒙特卡洛树搜索，有效解决了多模态虚假信息检测中的动态推理和自适应验证问题，为未来的研究提供了新的方向。"}}
{"id": "2505.18341", "title": "CrashAgent: Crash Scenario Generation via Multi-modal Reasoning", "authors": ["Miao Li", "Wenhao Ding", "Haohong Lin", "Yiqi Lyu", "Yihang Yao", "Yuyou Zhang", "Ding Zhao"], "abstract": "Training and evaluating autonomous driving algorithms requires a diverse range of scenarios. However, most available datasets predominantly consist of normal driving behaviors demonstrated by human drivers, resulting in a limited number of safety-critical cases. This imbalance, often referred to as a long-tail distribution, restricts the ability of driving algorithms to learn from crucial scenarios involving risk or failure, scenarios that are essential for humans to develop driving skills efficiently. To generate such scenarios, we utilize Multi-modal Large Language Models to convert crash reports of accidents into a structured scenario format, which can be directly executed within simulations. Specifically, we introduce CrashAgent, a multi-agent framework designed to interpret multi-modal real-world traffic crash reports for the generation of both road layouts and the behaviors of the ego vehicle and surrounding traffic participants. We comprehensively evaluate the generated crash scenarios from multiple perspectives, including the accuracy of layout reconstruction, collision rate, and diversity. The resulting high-quality and large-scale crash dataset will be publicly available to support the development of safe driving algorithms in handling safety-critical situations.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18341.pdf", "abstract_url": "https://arxiv.org/abs/2505.18341", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了CrashAgent，一个通过多模态推理生成碰撞场景的多代理框架，旨在解决自动驾驶算法训练和评估中安全关键场景不足的问题。", "motivation": "现有的自动驾驶数据集大多由人类驾驶员展示的正常驾驶行为组成，缺乏安全关键的碰撞场景，这限制了算法在风险或失败情况下的学习能力。", "method": "利用多模态大型语言模型将交通事故报告转换为结构化场景格式，并通过CrashAgent多代理框架解释多模态真实世界交通碰撞报告，生成道路布局及交通参与者的行为。", "result": "从布局重建的准确性、碰撞率和多样性等多个角度全面评估生成的碰撞场景，结果表明能够生成高质量和大规模的碰撞数据集。", "conclusion": "CrashAgent生成的碰撞数据集将公开支持开发安全驾驶算法，以有效处理安全关键情况，促进自动驾驶技术的发展。"}}
{"id": "2505.18347", "title": "The Cell Must Go On: Agar.io for Continual Reinforcement Learning", "authors": ["Mohamed A. Mohamed", "Kateryna Nekhomiazh", "Vedant Vyas", "Marcos M. Jose", "Andrew Patterson", "Marlos C. Machado"], "abstract": "Continual reinforcement learning (RL) concerns agents that are expected to learn continually, rather than converge to a policy that is then fixed for evaluation. Such an approach is well suited to environments the agent perceives as changing, which renders any static policy ineffective over time. The few simulators explicitly designed for empirical research in continual RL are often limited in scope or complexity, and it is now common for researchers to modify episodic RL environments by artificially incorporating abrupt task changes during interaction. In this paper, we introduce AgarCL, a research platform for continual RL that allows for a progression of increasingly sophisticated behaviour. AgarCL is based on the game", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18347.pdf", "abstract_url": "https://arxiv.org/abs/2505.18347", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了AgarCL，一个基于Agar.io游戏的持续强化学习研究平台，旨在支持逐渐复杂行为的研究。", "motivation": "解决持续强化学习研究中缺乏适合的模拟器的问题，现有模拟器要么范围有限，要么复杂性不足，研究者通常需要修改阶段性强化学习环境来模拟任务变化。", "method": "基于Agar.io游戏开发了AgarCL平台，支持在持续变化的环境中研究逐渐复杂的行为。", "result": "AgarCL平台为持续强化学习研究提供了一个既宽广又复杂的模拟环境。", "conclusion": "AgarCL平台的引入填补了持续强化学习研究工具的空白，为研究者在变化环境中探索复杂行为提供了新的可能性。"}}
{"id": "2505.18366", "title": "Hard Negative Mining for Domain-Specific Retrieval in Enterprise Systems", "authors": ["Hansa Meghwani", "Amit Agarwal", "Priyaranjan Pattnayak", "Hitesh Laxmichand Patel", "Srikant Panda"], "abstract": "Enterprise search systems often struggle to retrieve accurate, domain-specific information due to semantic mismatches and overlapping terminologies. These issues can degrade the performance of downstream applications such as knowledge management, customer support, and retrieval-augmented generation agents. To address this challenge, we propose a scalable hard-negative mining framework tailored specifically for domain-specific enterprise data. Our approach dynamically selects semantically challenging but contextually irrelevant documents to enhance deployed re-ranking models.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": "Accepted to ACL 2025", "pdf_url": "https://arxiv.org/pdf/2505.18366.pdf", "abstract_url": "https://arxiv.org/abs/2505.18366", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种针对企业特定领域数据的可扩展硬负例挖掘框架，旨在通过动态选择语义上具有挑战性但上下文无关的文档来增强重新排名模型的性能，以解决企业搜索系统中由于语义不匹配和术语重叠导致的检索准确性下降问题。", "motivation": "企业搜索系统在检索特定领域信息时，常因语义不匹配和术语重叠而导致准确性下降，影响知识管理、客户支持和检索增强生成代理等下游应用的性能。", "method": "提出了一种可扩展的硬负例挖掘框架，专门针对企业特定领域数据，动态选择语义上具有挑战性但上下文无关的文档。", "result": "该方法能够有效提升重新排名模型的性能，改善企业搜索系统的检索准确性。", "conclusion": "通过提出的硬负例挖掘框架，可以显著提升企业搜索系统在特定领域信息检索中的性能，对知识管理、客户支持等下游应用具有积极的推动作用。"}}
{"id": "2505.18384", "title": "Dynamic Risk Assessments for Offensive Cybersecurity Agents", "authors": ["Boyi Wei", "Benedikt Stroebl", "Jiacen Xu", "Joie Zhang", "Zhou Li", "Peter Henderson"], "abstract": "Foundation models are increasingly becoming better autonomous programmers, raising the prospect that they could also automate dangerous offensive cyber-operations. Current frontier model audits probe the cybersecurity risks of such agents, but most fail to account for the degrees of freedom available to adversaries in the real world. In particular, with strong verifiers and financial incentives, agents for offensive cybersecurity are amenable to iterative improvement by would-be adversaries. We argue that assessments should take into account an expanded threat model in the context of cybersecurity, emphasizing the varying degrees of freedom that an adversary may possess in stateful and non-stateful environments within a fixed compute budget. We show that even with a relatively small compute budget (8 H100 GPU Hours in our study), adversaries can improve an agent's cybersecurity capability on InterCode CTF by more than 40\\% relative to the baseline -- without any external assistance. These results highlight the need to evaluate agents' cybersecurity risk in a dynamic manner, painting a more representative picture of risk.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": "26 pages, 11 figures", "pdf_url": "https://arxiv.org/pdf/2505.18384.pdf", "abstract_url": "https://arxiv.org/abs/2505.18384", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了基础模型作为自主程序员在进攻性网络安全操作中自动化潜在危险的问题，提出了在网络安全背景下考虑扩展威胁模型的必要性，并展示了即使在有限的计算预算下，对手也能显著提高代理的网络安全能力。", "motivation": "解决当前前沿模型审计未能充分考虑现实中对手在网络安全操作中可能拥有的自由度问题，特别是在有强大验证器和财务激励的情况下。", "method": "通过在状态和非状态环境中，固定计算预算下，评估对手可能拥有的不同自由度，来扩展威胁模型。", "result": "研究表明，即使在相对较小的计算预算（8 H100 GPU小时）下，对手也能将代理的网络安全能力相对于基线提高40%以上，无需外部协助。", "conclusion": "这些结果强调了以动态方式评估代理的网络安全风险的必要性，以更准确地描绘风险图景。"}}
{"id": "2505.20129", "title": "Agentic 3D Scene Generation with Spatially Contextualized VLMs", "authors": ["Xinhang Liu", "Yu-Wing Tai", "Chi-Keung Tang"], "abstract": "Despite recent advances in multimodal content generation enabled by vision-language models (VLMs), their ability to reason about and generate structured 3D scenes remains largely underexplored. This limitation constrains their utility in spatially grounded tasks such as embodied AI, immersive simulations, and interactive 3D applications. We introduce a new paradigm that enables VLMs to generate, understand, and edit complex 3D environments by injecting a continually evolving spatial context. Constructed from multimodal input, this context consists of three components: a scene portrait that provides a high-level semantic blueprint, a semantically labeled point cloud capturing object-level geometry, and a scene hypergraph that encodes rich spatial relationships, including unary, binary, and higher-order constraints. Together, these components provide the VLM with a structured, geometry-aware working memory that integrates its inherent multimodal reasoning capabilities with structured 3D understanding for effective spatial reasoning. Building on this foundation, we develop an agentic 3D scene generation pipeline in which the VLM iteratively reads from and updates the spatial context. The pipeline features high-quality asset generation with geometric restoration, environment setup with automatic verification, and ergonomic adjustment guided by the scene hypergraph. Experiments show that our framework can handle diverse and challenging inputs, achieving a level of generalization not observed in prior work. Further results demonstrate that injecting spatial context enables VLMs to perform downstream tasks such as interactive scene editing and path planning, suggesting strong potential for spatially intelligent systems in computer graphics, 3D vision, and embodied applications.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.20129.pdf", "abstract_url": "https://arxiv.org/abs/2505.20129", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Graphics (cs.GR)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了一种新范式，通过注入不断演进的空间上下文，使视觉语言模型（VLMs）能够生成、理解和编辑复杂的3D环境。该方法结合了场景肖像、语义标记点云和场景超图，为VLMs提供了结构化、几何感知的工作记忆，有效整合了其固有的多模态推理能力与结构化3D理解。实验表明，该框架能够处理多样化和具有挑战性的输入，实现了前所未有的泛化水平。", "motivation": "尽管视觉语言模型（VLMs）在多模态内容生成方面取得了进展，但它们在理解和生成结构化3D场景方面的能力仍未得到充分探索。这一局限性限制了它们在空间基础任务（如具身AI、沉浸式模拟和交互式3D应用）中的实用性。", "method": "本文提出了一种新范式，通过构建由场景肖像、语义标记点云和场景超图组成的空间上下文，为VLMs提供结构化、几何感知的工作记忆。基于此，开发了一个代理性3D场景生成管道，VLMs可以迭代地读取和更新空间上下文。", "result": "实验结果显示，该框架能够处理多样化和具有挑战性的输入，实现了前所未有的泛化水平。进一步的成果表明，注入空间上下文使VLMs能够执行交互式场景编辑和路径规划等下游任务。", "conclusion": "本文的方法为计算机图形学、3D视觉和具身应用中的空间智能系统展示了强大的潜力。通过整合VLMs的多模态推理能力与结构化3D理解，为3D场景的生成、理解和编辑提供了新的可能性。"}}
{"id": "2505.18397", "title": "An Outlook on the Opportunities and Challenges of Multi-Agent AI Systems", "authors": ["Fangqiao Tian", "An Luo", "Jin Du", "Xun Xian", "Robert Specht", "Ganghua Wang", "Xuan Bi", "Jiawei Zhou", "Jayanth Srinivasa", "Ashish Kundu", "Charles Fleming", "Rui Zhang", "Zirui Liu", "Mingyi Hong", "Jie Ding"], "abstract": "Multi-agent AI systems (MAS) offer a promising framework for distributed intelligence, enabling collaborative reasoning, planning, and decision-making across autonomous agents. This paper provides a systematic outlook on the current opportunities and challenges of MAS, drawing insights from recent advances in large language models (LLMs), federated optimization, and human-AI interaction. We formalize key concepts including agent topology, coordination protocols, and shared objectives, and identify major risks such as dependency, misalignment, and vulnerabilities arising from training data overlap. Through a biologically inspired simulation and comprehensive theoretical framing, we highlight critical pathways for developing robust, scalable, and secure MAS in real-world settings.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18397.pdf", "abstract_url": "https://arxiv.org/abs/2505.18397", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Emerging Technologies (cs.ET)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文系统展望了多智能体AI系统（MAS）的当前机遇与挑战，结合大型语言模型（LLMs）、联邦优化和人机交互的最新进展，提出了关键概念和主要风险，并通过生物启发模拟和理论框架，强调了在现实世界中开发健壮、可扩展和安全MAS的关键路径。", "motivation": "探讨多智能体AI系统在分布式智能、协作推理、规划和决策方面的潜力及其面临的主要挑战。", "method": "结合大型语言模型、联邦优化和人机交互的最新研究，通过生物启发模拟和理论框架分析MAS的关键概念和风险。", "result": "识别了MAS的关键概念（如智能体拓扑、协调协议和共享目标）和主要风险（如依赖性、不对齐和训练数据重叠带来的漏洞）。", "conclusion": "提出了在现实世界应用中开发健壮、可扩展和安全多智能体AI系统的关键路径和策略。"}}
{"id": "2505.20289", "title": "VisualToolAgent (VisTA): A Reinforcement Learning Framework for Visual Tool Selection", "authors": ["Zeyi Huang", "Yuyang Ji", "Anirudh Sundara Rajan", "Zefan Cai", "Wen Xiao", "Junjie Hu", "Yong Jae Lee"], "abstract": "We introduce VisTA, a new reinforcement learning framework that empowers visual agents to dynamically explore, select, and combine tools from a diverse library based on empirical performance. Existing methods for tool-augmented reasoning either rely on training-free prompting or large-scale fine-tuning; both lack active tool exploration and typically assume limited tool diversity, and fine-tuning methods additionally demand extensive human supervision. In contrast, VisTA leverages end-to-end reinforcement learning to iteratively refine sophisticated, query-specific tool selection strategies, using task outcomes as feedback signals. Through Group Relative Policy Optimization (GRPO), our framework enables an agent to autonomously discover effective tool-selection pathways without requiring explicit reasoning supervision. Experiments on the ChartQA, Geometry3K, and BlindTest benchmarks demonstrate that VisTA achieves substantial performance gains over training-free baselines, especially on out-of-distribution examples. These results highlight VisTA's ability to enhance generalization, adaptively utilize diverse tools, and pave the way for flexible, experience-driven visual reasoning systems.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.20289.pdf", "abstract_url": "https://arxiv.org/abs/2505.20289", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "VisTA是一个新的强化学习框架，旨在通过动态探索、选择和组合多样化工具库中的工具来增强视觉代理的能力。", "motivation": "解决现有工具增强推理方法中缺乏主动工具探索和工具多样性假设有限的问题，以及需要大量人工监督的微调方法的不足。", "method": "利用端到端强化学习，通过Group Relative Policy Optimization (GRPO)迭代优化特定查询的工具选择策略，使用任务结果作为反馈信号。", "result": "在ChartQA、Geometry3K和BlindTest基准测试中，VisTA显著优于无需训练的基线方法，特别是在分布外示例上表现出色。", "conclusion": "VisTA能够增强泛化能力，自适应地利用多样化工具，为灵活、经验驱动的视觉推理系统开辟了新途径。"}}
{"id": "2505.18417", "title": "Reinforcement Learning for Ballbot Navigation in Uneven Terrain", "authors": ["Achkan Salehi"], "abstract": "Ballbot (i.e. Ball balancing robot) navigation usually relies on methods rooted in control theory (CT), and works that apply Reinforcement learning (RL) to the problem remain rare while generally being limited to specific subtasks (e.g. balance recovery). Unlike CT based methods, RL does not require (simplifying) assumptions about environment dynamics (e.g. the absence of slippage between the ball and the floor). In addition to this increased accuracy in modeling, RL agents can easily be conditioned on additional observations such as depth-maps without the need for explicit formulations from first principles, leading to increased adaptivity. Despite those advantages, there has been little to no investigation into the capabilities, data-efficiency and limitations of RL based methods for ballbot control and navigation. Furthermore, there is a notable absence of an open-source, RL-friendly simulator for this task. In this paper, we present an open-source ballbot simulation based on MuJoCo, and show that with appropriate conditioning on exteroceptive observations as well as reward shaping, policies learned by classical model-free RL methods are capable of effectively navigating through randomly generated uneven terrain, using a reasonable amount of data (four to five hours on a system operating at 500hz).", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "6 pages, 8 figures, 2 tables", "pdf_url": "https://arxiv.org/pdf/2505.18417.pdf", "abstract_url": "https://arxiv.org/abs/2505.18417", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于强化学习的球平衡机器人导航方法，通过开源模拟器和适当的观察条件及奖励塑造，展示了模型无关强化学习方法在随机生成的不平坦地形中有效导航的能力。", "motivation": "解决球平衡机器人导航问题，传统控制理论方法需要简化环境动态假设，而强化学习方法能更准确地建模环境动态，且能灵活适应额外观察如深度图，但目前缺乏对强化学习方法在球平衡机器人控制和导航中能力、数据效率和局限性的研究，以及开源、友好的强化学习模拟器。", "method": "使用基于MuJoCo的开源球平衡机器人模拟器，通过模型无关的强化学习方法，结合外感受观察条件和奖励塑造，训练导航策略。", "result": "研究表明，通过适当的条件设置和奖励塑造，经典的模型无关强化学习方法能够在随机生成的不平坦地形中有效导航，且数据效率合理（在500Hz的系统上运行四到五小时）。", "conclusion": "强化学习方法在球平衡机器人导航中展现出潜力，特别是在处理复杂和不平坦地形时，提供了一种无需简化环境动态假设的替代方案。开源模拟器的推出为未来研究提供了便利。"}}
{"id": "2505.20013", "title": "WebCoT: Enhancing Web Agent Reasoning by Reconstructing Chain-of-Thought in Reflection, Branching, and Rollback", "authors": ["Minda Hu", "Tianqing Fang", "Jianshu Zhang", "Junyu Ma", "Zhisong Zhang", "Jingyan Zhou", "Hongming Zhang", "Haitao Mi", "Dong Yu", "Irwin King"], "abstract": "Web agents powered by Large Language Models (LLMs) show promise for next-generation AI, but their limited reasoning in uncertain, dynamic web environments hinders robust deployment. In this paper, we identify key reasoning skills essential for effective web agents, i.e., reflection & lookahead, branching, and rollback, and curate trajectory data that exemplifies these abilities by reconstructing the agent's (inference-time) reasoning algorithms into chain-of-thought rationales. We conduct experiments in the agent self-improving benchmark, OpenWebVoyager, and demonstrate that distilling salient reasoning patterns into the backbone LLM via simple fine-tuning can substantially enhance its performance. Our approach yields significant improvements across multiple benchmarks, including WebVoyager, Mind2web-live, and SimpleQA (web search), highlighting the potential of targeted reasoning skill enhancement for web agents.", "subjects": "Computation and Language (cs.CL)", "comments": "18 pages", "pdf_url": "https://arxiv.org/pdf/2505.20013.pdf", "abstract_url": "https://arxiv.org/abs/2505.20013", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了WebCoT，一种通过重构思维链（Chain-of-Thought）来增强网络代理推理能力的方法，包括反思、分支和回滚，旨在解决大型语言模型（LLMs）在网络代理中推理能力有限的问题。", "motivation": "大型语言模型（LLMs）驱动的网络代理在不确定、动态的网络环境中推理能力有限，这阻碍了其稳健部署。本文旨在通过增强网络代理的关键推理技能来解决这一问题。", "method": "通过重构代理的推理算法为思维链理性，提炼出关键的推理模式，并通过简单的微调将这些模式融入骨干LLM中。", "result": "在OpenWebVoyager等基准测试中，该方法显著提高了网络代理的性能，包括WebVoyager、Mind2web-live和SimpleQA（网络搜索）。", "conclusion": "针对性地增强网络代理的推理技能具有巨大潜力，能够显著提升其在复杂网络环境中的表现。"}}
{"id": "2505.20096", "title": "MA-RAG: Multi-Agent Retrieval-Augmented Generation via Collaborative Chain-of-Thought Reasoning", "authors": ["Thang Nguyen", "Peter Chin", "Yu-Wing Tai"], "abstract": "We present MA-RAG, a Multi-Agent framework for Retrieval-Augmented Generation (RAG) that addresses the inherent ambiguities and reasoning challenges in complex information-seeking tasks. Unlike conventional RAG methods that rely on either end-to-end fine-tuning or isolated component enhancements, MA-RAG orchestrates a collaborative set of specialized AI agents: Planner, Step Definer, Extractor, and QA Agents, to tackle each stage of the RAG pipeline with task-aware reasoning. Ambiguities may arise from underspecified queries, sparse or indirect evidence in retrieved documents, or the need to integrate information scattered across multiple sources. MA-RAG mitigates these challenges by decomposing the problem into subtasks, such as query disambiguation, evidence extraction, and answer synthesis, and dispatching them to dedicated agents equipped with chain-of-thought prompting. These agents communicate intermediate reasoning and progressively refine the retrieval and synthesis process. Our design allows fine-grained control over information flow without any model fine-tuning. Crucially, agents are invoked on demand, enabling a dynamic and efficient workflow that avoids unnecessary computation. This modular and reasoning-driven architecture enables MA-RAG to deliver robust, interpretable results. Experiments on multi-hop and ambiguous QA benchmarks demonstrate that MA-RAG outperforms state-of-the-art training-free baselines and rivals fine-tuned systems, validating the effectiveness of collaborative agent-based reasoning in RAG.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.20096.pdf", "abstract_url": "https://arxiv.org/abs/2505.20096", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "MA-RAG是一个多代理框架，用于检索增强生成（RAG），通过协作的思维链推理解决复杂信息寻求任务中的模糊性和推理挑战。", "motivation": "解决传统RAG方法在处理模糊查询、稀疏或间接证据以及跨多源信息整合时的局限性。", "method": "采用多代理协作框架，包括规划者、步骤定义者、提取者和QA代理，通过任务感知推理分解问题并分派给专门代理。", "result": "在多跳和模糊QA基准测试中，MA-RAG优于无需训练的最先进基线，并与微调系统相媲美。", "conclusion": "MA-RAG通过协作代理基础的推理在RAG中提供了强大、可解释的结果，验证了其有效性。"}}
{"id": "2505.20023", "title": "Training LLM-Based Agents with Synthetic Self-Reflected Trajectories and Partial Masking", "authors": ["Yihan Chen", "Benfeng Xu", "Xiaorui Wang", "Yongdong Zhang", "Zhendong Mao"], "abstract": "Autonomous agents, which perceive environments and take actions to achieve goals, have become increasingly feasible with the advancements in large language models (LLMs). However, current powerful agents often depend on sophisticated prompt engineering combined with closed-source LLMs like GPT-4. Although training open-source LLMs using expert trajectories from teacher models has yielded some improvements in agent capabilities, this approach still faces limitations such as performance plateauing and error propagation. To mitigate these challenges, we propose STeP, a novel method for improving LLM-based agent training. We synthesize self-reflected trajectories that include reflections and corrections of error steps, which enhance the effectiveness of LLM agents in learning from teacher models, enabling them to become agents capable of self-reflecting and correcting. We also introduce partial masking strategy that prevents the LLM from internalizing incorrect or suboptimal steps. Experiments demonstrate that our method improves agent performance across three representative tasks: ALFWorld, WebShop, and SciWorld. For the open-source model LLaMA2-7B-Chat, when trained using self-reflected trajectories constructed with Qwen1.5-110B-Chat as the teacher model, it achieves comprehensive improvements with less training data compared to agents trained exclusively on expert trajectories.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.20023.pdf", "abstract_url": "https://arxiv.org/abs/2505.20023", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为STeP的新方法，通过合成自我反思轨迹和部分掩码策略，提升基于大型语言模型（LLM）的智能代理的训练效果，使其能够自我反思和纠正错误，进而在多个任务中表现更优。", "motivation": "当前基于大型语言模型的智能代理虽然强大，但依赖于复杂的提示工程和闭源模型如GPT-4，且通过专家轨迹训练开源模型存在性能瓶颈和错误传播的问题。", "method": "STeP方法通过合成包含错误步骤反思和纠正的自我反思轨迹，以及引入部分掩码策略避免模型内化不正确或次优步骤，来提升代理的学习效率和性能。", "result": "实验表明，使用STeP方法训练的LLaMA2-7B-Chat模型在ALFWorld、WebShop和SciWorld三个任务中表现优于仅使用专家轨迹训练的代理，且所需训练数据更少。", "conclusion": "STeP方法通过自我反思轨迹和部分掩码策略有效提升了LLM代理的性能和学习效率，为开发更高效的自主代理提供了新思路。"}}
{"id": "2505.18458", "title": "A Survey of LLM $\\times$ DATA", "authors": ["Xuanhe Zhou", "Junxuan He", "Wei Zhou", "Haodong Chen", "Zirui Tang", "Haoyu Zhao", "Xin Tong", "Guoliang Li", "Youmin Chen", "Jun Zhou", "Zhaojun Sun", "Binyuan Hui", "Shuo Wang", "Conghui He", "Zhiyuan Liu", "Jingren Zhou", "Fan Wu"], "abstract": "The integration of large language model (LLM) and data management (DATA) is rapidly redefining both domains. In this survey, we comprehensively review the bidirectional relationships. On the one hand, DATA4LLM, spanning large-scale data processing, storage, and serving, feeds LLMs with high quality, diversity, and timeliness of data required for stages like pre-training, post-training, retrieval-augmented generation, and agentic workflows: (i) Data processing for LLMs includes scalable acquisition, deduplication, filtering, selection, domain mixing, and synthetic augmentation; (ii) Data Storage for LLMs focuses on efficient data and model formats, distributed and heterogeneous storage hierarchies, KV-cache management, and fault-tolerant checkpointing; (iii) Data serving for LLMs tackles challenges in RAG (e.g., knowledge post-processing), LLM inference (e.g., prompt compression, data provenance), and training strategies (e.g., data packing and shuffling). On the other hand, in LLM4DATA, LLMs are emerging as general-purpose engines for data management. We review recent advances in (i) data manipulation, including automatic data cleaning, integration, discovery; (ii) data analysis, covering reasoning over structured, semi-structured, and unstructured data, and (iii) system optimization (e.g., configuration tuning, query rewriting, anomaly diagnosis), powered by LLM techniques like retrieval-augmented prompting, task-specialized fine-tuning, and multi-agent collaboration.", "subjects": "Databases (cs.DB); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Information Retrieval (cs.IR); Machine Learning (cs.LG)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.18458.pdf", "abstract_url": "https://arxiv.org/abs/2505.18458", "categories": ["Databases (cs.DB)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Information Retrieval (cs.IR)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic", "@RAG"], "AI": {"tldr": "本文综述了大型语言模型（LLM）与数据管理（DATA）的双向关系，包括DATA4LLM和LLM4DATA两个方面，探讨了数据处理、存储和服务对LLM的重要性，以及LLM在数据管理中的新兴应用。", "motivation": "探讨大型语言模型与数据管理之间的相互作用，以及这种相互作用如何重新定义这两个领域。", "method": "通过综述的方式，全面回顾了DATA4LLM和LLM4DATA的最新进展，包括数据处理、存储、服务以及LLM在数据管理中的应用。", "result": "揭示了LLM和数据管理之间的双向关系，展示了LLM如何依赖于高质量的数据管理，以及LLM如何作为通用引擎推动数据管理的发展。", "conclusion": "LLM和数据管理的集成正在快速发展，这种集成不仅提高了LLM的性能，也为数据管理领域带来了新的机遇和挑战。"}}
{"id": "2505.18471", "title": "Invisible Tokens, Visible Bills: The Urgent Need to Audit Hidden Operations in Opaque LLM Services", "authors": ["Guoheng Sun", "Ziyao Wang", "Xuandong Zhao", "Bowei Tian", "Zheyu Shen", "Yexiao He", "Jinming Xing", "Ang Li"], "abstract": "Modern large language model (LLM) services increasingly rely on complex, often abstract operations, such as multi-step reasoning and multi-agent collaboration, to generate high-quality outputs. While users are billed based on token consumption and API usage, these internal steps are typically not visible. We refer to such systems as Commercial Opaque LLM Services (COLS). This position paper highlights emerging accountability challenges in COLS: users are billed for operations they cannot observe, verify, or contest. We formalize two key risks: \\textit{quantity inflation}, where token and call counts may be artificially inflated, and \\textit{quality downgrade}, where providers might quietly substitute lower-cost models or tools. Addressing these risks requires a diverse set of auditing strategies, including commitment-based, predictive, behavioral, and signature-based methods. We further explore the potential of complementary mechanisms such as watermarking and trusted execution environments to enhance verifiability without compromising provider confidentiality. We also propose a modular three-layer auditing framework for COLS and users that enables trustworthy verification across execution, secure logging, and user-facing auditability without exposing proprietary internals. Our aim is to encourage further research and policy development toward transparency, auditability, and accountability in commercial LLM services.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18471.pdf", "abstract_url": "https://arxiv.org/abs/2505.18471", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文讨论了商业不透明大型语言模型服务（COLS）中的责任挑战，提出了两种关键风险：数量膨胀和质量降级，并提出了一套审计策略和框架以提高透明度和可审计性。", "motivation": "解决COLS中用户因无法观察、验证或争议内部操作而被计费的问题，以及提供商可能悄悄替换低成本模型或工具的风险。", "method": "提出包括基于承诺、预测、行为和签名的方法在内的多样化审计策略，以及水印和可信执行环境等补充机制，并设计了一个模块化的三层审计框架。", "result": "识别了COLS中的关键风险，并提出了一套旨在增强透明度和可审计性的审计策略和框架。", "conclusion": "鼓励进一步的研究和政策发展，以促进商业LLM服务的透明度、可审计性和责任性。"}}
{"id": "2505.18487", "title": "Grounding Bodily Awareness in Visual Representations for Efficient Policy Learning", "authors": ["Junlin Wang", "Zhiyun Lin"], "abstract": "Learning effective visual representations for robotic manipulation remains a fundamental challenge due to the complex body dynamics involved in action execution. In this paper, we study how visual representations that carry body-relevant cues can enable efficient policy learning for downstream robotic manipulation tasks. We present $\\textbf{I}$nter-token $\\textbf{Con}$trast ($\\textbf{ICon}$), a contrastive learning method applied to the token-level representations of Vision Transformers (ViTs). ICon enforces a separation in the feature space between agent-specific and environment-specific tokens, resulting in agent-centric visual representations that embed body-specific inductive biases. This framework can be seamlessly integrated into end-to-end policy learning by incorporating the contrastive loss as an auxiliary objective. Our experiments show that ICon not only improves policy performance across various manipulation tasks but also facilitates policy transfer across different robots. The project website:", "subjects": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "comments": "A preprint version", "pdf_url": "https://arxiv.org/pdf/2505.18487.pdf", "abstract_url": "https://arxiv.org/abs/2505.18487", "categories": ["Robotics (cs.RO)", "Computer Vision and Pattern Recognition (cs.CV)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究了如何通过携带身体相关线索的视觉表示来促进下游机器人操作任务的高效策略学习。提出了ICon方法，一种应用于Vision Transformers（ViTs）令牌级表示的对比学习方法，以在特征空间中分离代理特定和环境特定的令牌，从而嵌入身体特定的归纳偏差。", "motivation": "解决机器人操作中由于复杂的身体动力学导致的视觉表示学习效率低下的问题。", "method": "提出了ICon（Inter-token Contrast）方法，一种对比学习策略，应用于ViTs的令牌级表示，以分离代理和环境特定的令牌。", "result": "ICon不仅提高了各种操作任务的策略性能，还促进了不同机器人之间的策略迁移。", "conclusion": "ICon通过嵌入身体特定的归纳偏差，有效地提高了机器人操作任务的策略学习效率和跨机器人策略迁移能力。"}}
{"id": "2505.20118", "title": "TrojanStego: Your Language Model Can Secretly Be A Steganographic Privacy Leaking Agent", "authors": ["Dominik Meier", "Jan Philip Wahle", "Paul Röttger", "Terry Ruas", "Bela Gipp"], "abstract": "As large language models (LLMs) become integrated into sensitive workflows, concerns grow over their potential to leak confidential information. We propose TrojanStego, a novel threat model in which an adversary fine-tunes an LLM to embed sensitive context information into natural-looking outputs via linguistic steganography, without requiring explicit control over inference inputs. We introduce a taxonomy outlining risk factors for compromised LLMs, and use it to evaluate the risk profile of the threat. To implement TrojanStego, we propose a practical encoding scheme based on vocabulary partitioning learnable by LLMs via fine-tuning. Experimental results show that compromised models reliably transmit 32-bit secrets with 87% accuracy on held-out prompts, reaching over 97% accuracy using majority voting across three generations. Further, they maintain high utility, can evade human detection, and preserve coherence. These results highlight a new class of LLM data exfiltration attacks that are passive, covert, practical, and dangerous.", "subjects": "Computation and Language (cs.CL); Cryptography and Security (cs.CR)", "comments": "8 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2505.20118.pdf", "abstract_url": "https://arxiv.org/abs/2505.20118", "categories": ["Computation and Language (cs.CL)", "Cryptography and Security (cs.CR)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为TrojanStego的新型威胁模型，通过语言隐写术将敏感信息嵌入到自然语言输出中，评估了受损大型语言模型的风险特征，并展示了一种实用的编码方案。实验结果表明，受损模型能够可靠地传输秘密信息，同时保持高实用性和隐蔽性。", "motivation": "随着大型语言模型（LLMs）被集成到敏感的工作流程中，人们越来越担心它们可能泄露机密信息。本文旨在探索LLMs作为一种隐写隐私泄露媒介的潜在风险。", "method": "提出了一种基于词汇分区的实用编码方案，通过微调使LLMs学习这种方案，实现敏感信息的隐蔽传输。", "result": "实验结果显示，受损模型在保留提示上以87%的准确率可靠传输32位秘密信息，使用多数投票策略时准确率超过97%，同时保持高实用性和隐蔽性。", "conclusion": "这些结果突显了一类新型的LLM数据外泄攻击，这类攻击被动、隐蔽、实用且危险。"}}
{"id": "2505.20128", "title": "Iterative Self-Incentivization Empowers Large Language Models as Agentic Searchers", "authors": ["Zhengliang Shi", "Lingyong Yan", "Dawei Yin", "Suzan Verberne", "Maarten de Rijke", "Zhaochun Ren"], "abstract": "Large language models (LLMs) have been widely integrated into information retrieval to advance traditional techniques. However, effectively enabling LLMs to seek accurate knowledge in complex tasks remains a challenge due to the complexity of multi-hop queries as well as the irrelevant retrieved content. To address these limitations, we propose EXSEARCH, an agentic search framework, where the LLM learns to retrieve useful information as the reasoning unfolds through a self-incentivized process. At each step, the LLM decides what to retrieve (thinking), triggers an external retriever (search), and extracts fine-grained evidence (recording) to support next-step reasoning. To enable LLM with this capability, EXSEARCH adopts a Generalized Expectation-Maximization algorithm. In the E-step, the LLM generates multiple search trajectories and assigns an importance weight to each; the M-step trains the LLM on them with a re-weighted loss function. This creates a self-incentivized loop, where the LLM iteratively learns from its own generated data, progressively improving itself for search. We further theoretically analyze this training process, establishing convergence guarantees. Extensive experiments on four knowledge-intensive benchmarks show that EXSEARCH substantially outperforms baselines, e.g., +7.8% improvement on exact match score. Motivated by these promising results, we introduce EXSEARCH-Zoo, an extension that extends our method to broader scenarios, to facilitate future work.", "subjects": "Computation and Language (cs.CL)", "comments": "Working in process", "pdf_url": "https://arxiv.org/pdf/2505.20128.pdf", "abstract_url": "https://arxiv.org/abs/2505.20128", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了EXSEARCH，一个通过自我激励过程使大型语言模型（LLMs）在复杂任务中有效检索准确知识的代理搜索框架。", "motivation": "解决大型语言模型在复杂多跳查询和无关检索内容中寻求准确知识的挑战。", "method": "采用广义期望最大化算法，通过E步生成搜索轨迹并分配重要性权重，M步用重新加权的损失函数训练LLM，形成一个自我激励的循环。", "result": "在四个知识密集型基准测试中，EXSEARCH显著优于基线，例如在精确匹配分数上提高了7.8%。", "conclusion": "EXSEARCH通过自我激励循环有效提升了LLMs在复杂任务中的检索能力，并提出了EXSEARCH-Zoo以扩展方法至更广泛场景。"}}
{"id": "2505.18530", "title": "MRGAgents: A Multi-Agent Framework for Improved Medical Report Generation with Med-LVLMs", "authors": ["Pengyu Wang", "Shuchang Ye", "Usman Naseem", "Jinman Kim"], "abstract": "Medical Large Vision-Language Models (Med-LVLMs) have been widely adopted for medical report generation. Despite Med-LVLMs producing state-of-the-art performance, they exhibit a bias toward predicting all findings as normal, leading to reports that overlook critical abnormalities. Furthermore, these models often fail to provide comprehensive descriptions of radiologically relevant regions necessary for accurate diagnosis. To address these challenges, we proposeMedical Report Generation Agents (MRGAgents), a novel multi-agent framework that fine-tunes specialized agents for different disease categories. By curating subsets of the IU X-ray and MIMIC-CXR datasets to train disease-specific agents, MRGAgents generates reports that more effectively balance normal and abnormal findings while ensuring a comprehensive description of clinically relevant regions. Our experiments demonstrate that MRGAgents outperformed the state-of-the-art, improving both report comprehensiveness and diagnostic utility.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": "10pages", "pdf_url": "https://arxiv.org/pdf/2505.18530.pdf", "abstract_url": "https://arxiv.org/abs/2505.18530", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "MRGAgents是一个多智能体框架，旨在通过针对不同疾病类别微调专门智能体，改进医疗报告生成，特别是在平衡正常和异常发现以及全面描述临床相关区域方面。", "motivation": "解决Med-LVLMs在医疗报告生成中偏向预测所有发现为正常，忽视关键异常，以及未能全面描述放射学相关区域的问题。", "method": "提出MRGAgents框架，通过从IU X-ray和MIMIC-CXR数据集中筛选数据训练疾病特定智能体，以生成更全面和诊断有用的报告。", "result": "实验表明，MRGAgents在报告全面性和诊断效用方面优于现有技术。", "conclusion": "MRGAgents通过多智能体方法有效提升了医疗报告的质量，特别是在识别异常和描述临床相关区域方面。"}}
{"id": "2505.18572", "title": "MASTER: Multi-Agent Security Through Exploration of Roles and Topological Structures -- A Comprehensive Framework", "authors": ["Yifan Zhu", "Chao Zhang", "Xin Shi", "Xueqiao Zhang", "Yi Yang", "Yawei Luo"], "abstract": "Large Language Models (LLMs)-based Multi-Agent Systems (MAS) exhibit remarkable problem-solving and task planning capabilities across diverse domains due to their specialized agentic roles and collaborative interactions. However, this also amplifies the severity of security risks under MAS attacks. To address this, we introduce MASTER, a novel security research framework for MAS, focusing on diverse Role configurations and Topological structures across various scenarios. MASTER offers an automated construction process for different MAS setups and an information-flow-based interaction paradigm. To tackle MAS security challenges in varied scenarios, we design a scenario-adaptive, extensible attack strategy utilizing role and topological information, which dynamically allocates targeted, domain-specific attack tasks for collaborative agent execution. Our experiments demonstrate that such an attack, leveraging role and topological information, exhibits significant destructive potential across most models. Additionally, we propose corresponding defense strategies, substantially enhancing MAS resilience across diverse scenarios. We anticipate that our framework and findings will provide valuable insights for future research into MAS security challenges.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18572.pdf", "abstract_url": "https://arxiv.org/abs/2505.18572", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了MASTER，一个针对基于大型语言模型（LLM）的多代理系统（MAS）安全研究的新框架，专注于不同角色配置和拓扑结构。MASTER提供了自动化构建不同MAS设置的过程和基于信息流的交互范式，设计了适应性强、可扩展的攻击策略，并提出了相应的防御策略，显著提高了MAS的韧性。", "motivation": "解决基于LLM的MAS在展示出色问题解决和任务规划能力的同时，也放大了MAS攻击下的安全风险的问题。", "method": "引入MASTER框架，专注于多样化的角色配置和拓扑结构，提供自动化构建过程和基于信息流的交互范式，设计适应性强、可扩展的攻击策略。", "result": "实验表明，利用角色和拓扑信息的攻击在大多数模型中显示出显著的破坏潜力，同时提出的防御策略显著提高了MAS的韧性。", "conclusion": "MASTER框架和研究结果为未来MAS安全挑战的研究提供了有价值的见解。"}}
{"id": "2505.20201", "title": "Reasoning Is Not All You Need: Examining LLMs for Multi-Turn Mental Health Conversations", "authors": ["Mohit Chandra", "Siddharth Sriraman", "Harneet Singh Khanuja", "Yiqiao Jin", "Munmun De Choudhury"], "abstract": "Limited access to mental healthcare, extended wait times, and increasing capabilities of Large Language Models (LLMs) has led individuals to turn to LLMs for fulfilling their mental health needs. However, examining the multi-turn mental health conversation capabilities of LLMs remains under-explored. Existing evaluation frameworks typically focus on diagnostic accuracy and win-rates and often overlook alignment with patient-specific goals, values, and personalities required for meaningful conversations. To address this, we introduce MedAgent, a novel framework for synthetically generating realistic, multi-turn mental health sensemaking conversations and use it to create the Mental Health Sensemaking Dialogue (MHSD) dataset, comprising over 2,200 patient-LLM conversations. Additionally, we present MultiSenseEval, a holistic framework to evaluate the multi-turn conversation abilities of LLMs in healthcare settings using human-centric criteria. Our findings reveal that frontier reasoning models yield below-par performance for patient-centric communication and struggle at advanced diagnostic capabilities with average score of 31%. Additionally, we observed variation in model performance based on patient's persona and performance drop with increasing turns in the conversation. Our work provides a comprehensive synthetic data generation framework, a dataset and evaluation framework for assessing LLMs in multi-turn mental health conversations.", "subjects": "Computation and Language (cs.CL)", "comments": "33 pages, 5 figures, 30 tables", "pdf_url": "https://arxiv.org/pdf/2505.20201.pdf", "abstract_url": "https://arxiv.org/abs/2505.20201", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了大型语言模型（LLMs）在多轮心理健康对话中的能力，提出了MedAgent框架和MHSD数据集，以及MultiSenseEval评估框架，发现前沿推理模型在患者中心沟通和高级诊断能力上表现不佳。", "motivation": "解决心理健康服务资源有限、等待时间长的问题，以及探索LLMs在多轮心理健康对话中的能力。", "method": "引入MedAgent框架生成多轮心理健康对话，创建MHSD数据集，并提出MultiSenseEval评估框架。", "result": "前沿推理模型在患者中心沟通和高级诊断能力上平均得分仅为31%，且表现随对话轮次增加而下降。", "conclusion": "研究提供了全面的数据生成和评估框架，揭示了LLMs在心理健康对话中的局限性，为未来改进提供了方向。"}}
{"id": "2505.20184", "title": "THiNK: Can Large Language Models Think-aloud?", "authors": ["Yongan Yu", "Mengqian Wu", "Yiran Lin", "Nikki G. Lobczowski"], "abstract": "Assessing higher-order thinking skills in large language models (LLMs) remains a fundamental challenge, especially in tasks that go beyond surface-level accuracy. In this work, we propose THiNK (Testing Higher-order Notion of Knowledge), a multi-agent, feedback-driven evaluation framework grounded in Bloom's Taxonomy. THiNK frames reasoning assessment as an iterative task of problem generation, critique, and revision, encouraging LLMs to think-aloud through step-by-step reflection and refinement. This enables a systematic evaluation of both lower-order (e.g., remember, understand) and higher-order (e.g., evaluate, create) thinking skills. We apply THiNK to seven state-of-the-art LLMs and perform a detailed cognitive analysis of their outputs. Results reveal that while models reliably perform lower-order categories well, they struggle with applying knowledge in realistic contexts and exhibit limited abstraction. Structured feedback loops significantly improve reasoning performance, particularly in higher-order thinking. Qualitative evaluations further confirm that THiNK-guided outputs better align with domain logic and problem structure. The code of our framework provides a scalable methodology for probing and enhancing LLM reasoning, offering new directions for evaluation grounded in learning science, which is available at our GitHub repository.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.20184.pdf", "abstract_url": "https://arxiv.org/abs/2505.20184", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了THiNK框架，一个基于布鲁姆分类法的多智能体、反馈驱动的评估框架，用于评估大型语言模型（LLMs）的高阶思维能力。通过问题生成、批评和修订的迭代任务，THiNK鼓励LLMs通过逐步反思和精炼来“大声思考”。应用THiNK对七个最先进的LLMs进行了详细认知分析，结果显示模型在低阶思维类别表现良好，但在现实情境中应用知识和抽象能力有限。结构化反馈循环显著提高了推理性能，特别是在高阶思维方面。定性评估进一步证实，THiNK引导的输出更符合领域逻辑和问题结构。", "motivation": "评估大型语言模型（LLMs）的高阶思维能力是一个基本挑战，尤其是在超越表面准确性的任务中。", "method": "提出了THiNK框架，一个多智能体、反馈驱动的评估框架，基于布鲁姆分类法，通过问题生成、批评和修订的迭代任务来评估LLMs的思维能力。", "result": "模型在低阶思维类别表现良好，但在现实情境中应用知识和抽象能力有限。结构化反馈循环显著提高了推理性能，特别是在高阶思维方面。", "conclusion": "THiNK框架为探测和增强LLM推理提供了可扩展的方法论，基于学习科学的评估提供了新的方向。"}}
{"id": "2505.20243", "title": "It's High Time: A Survey of Temporal Information Retrieval and Question Answering", "authors": ["Bhawna Piryani", "Abdelrahman Abdullah", "Jamshid Mozafari", "Avishek Anand", "Adam Jatowt"], "abstract": "Time plays a critical role in how information is generated, retrieved, and interpreted. In this survey, we provide a comprehensive overview of Temporal Information Retrieval and Temporal Question Answering, two research areas aimed at handling and understanding time-sensitive information. As the amount of time-stamped content from sources like news articles, web archives, and knowledge bases increases, systems must address challenges such as detecting temporal intent, normalizing time expressions, ordering events, and reasoning over evolving or ambiguous facts. These challenges are critical across many dynamic and time-sensitive domains, from news and encyclopedias to science, history, and social media. We review both traditional approaches and modern neural methods, including those that use transformer models and Large Language Models (LLMs). We also review recent advances in temporal language modeling, multi-hop reasoning, and retrieval-augmented generation (RAG), alongside benchmark datasets and evaluation strategies that test temporal robustness, recency awareness, and generalization.", "subjects": "Computation and Language (cs.CL); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.20243.pdf", "abstract_url": "https://arxiv.org/abs/2505.20243", "categories": ["Computation and Language (cs.CL)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文综述了时间信息检索和时间问答两个研究领域，旨在处理和理解时间敏感信息。随着时间戳内容的增加，系统需要解决检测时间意图、规范化时间表达式、事件排序和推理等挑战。", "motivation": "解决时间敏感信息处理和理解的挑战，如时间意图检测、时间表达式规范化、事件排序和推理。", "method": "综述了传统方法和现代神经方法，包括使用变压器模型和大型语言模型（LLMs）的方法，以及时间语言建模、多跳推理和检索增强生成（RAG）的最新进展。", "result": "回顾了基准数据集和评估策略，测试了时间鲁棒性、新近意识和泛化能力。", "conclusion": "时间信息检索和时间问答的研究对于处理动态和时间敏感领域的信息至关重要，现代神经方法在这些领域显示出潜力。"}}
{"id": "2505.18595", "title": "MisoDICE: Multi-Agent Imitation from Unlabeled Mixed-Quality Demonstrations", "authors": ["Viet Bui", "Tien Mai", "Hong Thanh Nguyen"], "abstract": "We study offline imitation learning (IL) in cooperative multi-agent settings, where demonstrations have unlabeled mixed quality - containing both expert and suboptimal trajectories. Our proposed solution is structured in two stages: trajectory labeling and multi-agent imitation learning, designed jointly to enable effective learning from heterogeneous, unlabeled data. In the first stage, we combine advances in large language models and preference-based reinforcement learning to construct a progressive labeling pipeline that distinguishes expert-quality trajectories. In the second stage, we introduce MisoDICE, a novel multi-agent IL algorithm that leverages these labels to learn robust policies while addressing the computational complexity of large joint state-action spaces. By extending the popular single-agent DICE framework to multi-agent settings with a new value decomposition and mixing architecture, our method yields a convex policy optimization objective and ensures consistency between global and local policies. We evaluate MisoDICE on multiple standard multi-agent RL benchmarks and demonstrate superior performance, especially when expert data is scarce.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18595.pdf", "abstract_url": "https://arxiv.org/abs/2505.18595", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文研究了在合作多智能体设置中的离线模仿学习（IL），其中演示数据包含未标记的混合质量轨迹（既有专家轨迹也有次优轨迹）。提出了一种两阶段解决方案：轨迹标记和多智能体模仿学习，旨在从异构、未标记的数据中进行有效学习。", "motivation": "解决在多智能体环境中，如何从未标记的混合质量演示数据中有效学习的问题，特别是在专家数据稀缺的情况下。", "method": "第一阶段结合大型语言模型和基于偏好的强化学习构建渐进式标记流程，区分专家质量轨迹；第二阶段引入MisoDICE算法，通过新的价值分解和混合架构扩展单智能体DICE框架，处理大规模联合状态-动作空间的计算复杂性。", "result": "在多个标准多智能体RL基准测试中评估MisoDICE，显示出优越的性能，尤其是在专家数据稀缺的情况下。", "conclusion": "MisoDICE通过两阶段方法有效解决了从未标记混合质量演示中学习的问题，特别是在专家数据稀缺的情况下，展现出在多智能体模仿学习中的潜力。"}}
{"id": "2505.20245", "title": "KnowTrace: Bootstrapping Iterative Retrieval-Augmented Generation with Structured Knowledge Tracing", "authors": ["Rui Li", "Quanyu Dai", "Zeyu Zhang", "Xu Chen", "Zhenhua Dong", "Ji-Rong Wen"], "abstract": "Recent advances in retrieval-augmented generation (RAG) furnish large language models (LLMs) with iterative retrievals of relevant information to handle complex multi-hop questions. These methods typically alternate between LLM reasoning and retrieval to accumulate external information into the LLM's context. However, the ever-growing context inherently imposes an increasing burden on the LLM to perceive connections among critical information pieces, with futile reasoning steps further exacerbating this overload issue. In this paper, we present KnowTrace, an elegant RAG framework to (1) mitigate the context overload and (2) bootstrap higher-quality multi-step reasoning. Instead of simply piling the retrieved contents, KnowTrace autonomously traces out desired knowledge triplets to organize a specific knowledge graph relevant to the input question. Such a structured workflow not only empowers the LLM with an intelligible context for inference, but also naturally inspires a reflective mechanism of knowledge backtracing to identify contributive LLM generations as process supervision data for self-bootstrapping. Extensive experiments show that KnowTrace consistently surpasses existing methods across three multi-hop question answering benchmarks, and the bootstrapped version further amplifies the gains.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "Accepted by KDD 2025", "pdf_url": "https://arxiv.org/pdf/2505.20245.pdf", "abstract_url": "https://arxiv.org/abs/2505.20245", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "KnowTrace是一个创新的检索增强生成（RAG）框架，旨在通过结构化知识追踪减轻上下文过载并引导更高质量的多步推理。它通过自主追踪相关知识三元组来组织与输入问题相关的特定知识图，不仅为大型语言模型（LLM）提供了可理解的推理上下文，还自然激发了知识回溯的反思机制，以识别有益的LLM生成作为自我引导的过程监督数据。实验表明，KnowTrace在三个多跳问答基准测试中 consistently 超越现有方法，且其引导版本进一步放大了优势。", "motivation": "解决现有检索增强生成（RAG）方法在处理复杂多跳问题时，由于上下文不断增长而导致的大型语言模型（LLM）感知关键信息间连接的负担增加，以及无效推理步骤进一步加剧这一过载问题。", "method": "提出KnowTrace框架，通过自主追踪相关知识三元组组织特定知识图，替代简单地堆叠检索内容，以结构化工作流减轻上下文过载并引导高质量多步推理。", "result": "在三个多跳问答基准测试中，KnowTrace consistently 超越现有方法，其引导版本进一步放大了性能优势。", "conclusion": "KnowTrace通过结构化知识追踪和知识回溯的反思机制，有效减轻了上下文过载问题，并提升了多步推理的质量，为检索增强生成领域提供了新的研究方向。"}}
{"id": "2505.18646", "title": "SEW: Self-Evolving Agentic Workflows for Automated Code Generation", "authors": ["Siwei Liu", "Jinyuan Fang", "Han Zhou", "Yingxu Wang", "Zaiqiao Meng"], "abstract": "Large Language Models (LLMs) have demonstrated effectiveness in code generation tasks. To enable LLMs to address more complex coding challenges, existing research has focused on crafting multi-agent systems with agentic workflows, where complex coding tasks are decomposed into sub-tasks, assigned to specialized agents. Despite their effectiveness, current approaches heavily rely on hand-crafted agentic workflows, with both agent topologies and prompts manually designed, which limits their ability to automatically adapt to different types of coding problems. To address these limitations and enable automated workflow design, we propose \\textbf{S}elf-\\textbf{E}volving \\textbf{W}orkflow (\\textbf{SEW}), a novel self-evolving framework that automatically generates and optimises multi-agent workflows. Extensive experiments on three coding benchmark datasets, including the challenging LiveCodeBench, demonstrate that our SEW can automatically design agentic workflows and optimise them through self-evolution, bringing up to 33\\% improvement on LiveCodeBench compared to using the backbone LLM only. Furthermore, by investigating different representation schemes of workflow, we provide insights into the optimal way to encode workflow information with text.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "16 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2505.18646.pdf", "abstract_url": "https://arxiv.org/abs/2505.18646", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种名为SEW（自进化工作流）的新框架，旨在自动生成和优化多代理工作流，以解决复杂代码生成任务。通过自我进化，SEW在三个编码基准数据集上展示了显著的性能提升。", "motivation": "现有的多代理系统在代码生成任务中依赖于手工设计的工作流和提示，这限制了它们自动适应不同类型编码问题的能力。", "method": "提出了SEW框架，该框架能够自动生成和优化多代理工作流，并通过自我进化来适应不同的编码问题。", "result": "在包括LiveCodeBench在内的三个编码基准数据集上的实验表明，SEW相比仅使用基础LLM带来了高达33%的性能提升。", "conclusion": "SEW框架通过自动设计和优化多代理工作流，显著提高了代码生成的效率和效果，同时为工作流信息的文本编码提供了最佳实践。"}}
{"id": "2505.20277", "title": "OmniCharacter: Towards Immersive Role-Playing Agents with Seamless Speech-Language Personality Interaction", "authors": ["Haonan Zhang", "Run Luo", "Xiong Liu", "Yuchuan Wu", "Ting-En Lin", "Pengpeng Zeng", "Qiang Qu", "Feiteng Fang", "Min Yang", "Lianli Gao", "Jingkuan Song", "Fei Huang", "Yongbin Li"], "abstract": "Role-Playing Agents (RPAs), benefiting from large language models, is an emerging interactive AI system that simulates roles or characters with diverse personalities. However, existing methods primarily focus on mimicking dialogues among roles in textual form, neglecting the role's voice traits (e.g., voice style and emotions) as playing a crucial effect in interaction, which tends to be more immersive experiences in realistic scenarios. Towards this goal, we propose OmniCharacter, a first seamless speech-language personality interaction model to achieve immersive RPAs with low latency. Specifically, OmniCharacter enables agents to consistently exhibit role-specific personality traits and vocal traits throughout the interaction, enabling a mixture of speech and language responses. To align the model with speech-language scenarios, we construct a dataset named OmniCharacter-10K, which involves more distinctive characters (20), richly contextualized multi-round dialogue (10K), and dynamic speech response (135K). Experimental results showcase that our method yields better responses in terms of both content and style compared to existing RPAs and mainstream speech-language models, with a response latency as low as 289ms. Code and dataset are available at", "subjects": "Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)", "comments": "14 pages, 6 figures", "pdf_url": "https://arxiv.org/pdf/2505.20277.pdf", "abstract_url": "https://arxiv.org/abs/2505.20277", "categories": ["Computation and Language (cs.CL)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了OmniCharacter，一个旨在通过无缝的语音-语言个性交互实现沉浸式角色扮演代理（RPAs）的模型，解决了现有方法忽视角色声音特质的问题。", "motivation": "现有的角色扮演代理（RPAs）主要关注于文本形式的对话模拟，忽视了角色声音特质（如声音风格和情感）在交互中的重要作用，这限制了在现实场景中的沉浸式体验。", "method": "提出了OmniCharacter模型，该模型能够使代理在交互中一致地展现角色特定的个性特质和声音特质，实现语音和语言响应的混合。为了适应语音-语言场景，构建了一个名为OmniCharacter-10K的数据集。", "result": "实验结果表明，与现有的RPAs和主流语音-语言模型相比，我们的方法在内容和风格上都产生了更好的响应，响应延迟低至289ms。", "conclusion": "OmniCharacter通过无缝整合语音和语言响应，为沉浸式角色扮演代理提供了一种有效的解决方案，显著提升了交互的沉浸感和响应速度。"}}
{"id": "2505.20285", "title": "MASKSEARCH: A Universal Pre-Training Framework to Enhance Agentic Search Capability", "authors": ["Weiqi Wu", "Xin Guan", "Shen Huang", "Yong Jiang", "Pengjun Xie", "Fei Huang", "Jiuxin Cao", "Hai Zhao", "Jingren Zhou"], "abstract": "Retrieval-Augmented Language Models (RALMs) represent a classic paradigm where models enhance generative capabilities using external knowledge retrieved via a specialized module. Recent advancements in Agent techniques enable Large Language Models (LLMs) to autonomously utilize tools for retrieval, planning, and reasoning. While existing training-based methods show promise, their agentic abilities are limited by inherent characteristics of the task-specific data used during training. To further enhance the universal search capability of agents, we propose a novel pre-training framework, MASKSEARCH. In the pre-training stage, we introduce the Retrieval Augmented Mask Prediction (RAMP) task, where the model learns to leverage search tools to fill masked spans on a large number of pre-training data, thus acquiring universal retrieval and reasoning capabilities for LLMs. After that, the model is trained on downstream tasks to achieve further improvement. We apply both Supervised Fine-tuning (SFT) and Reinforcement Learning (RL) for training. For SFT, we combine agent-based and distillation-based methods to generate training data, starting with a multi-agent system consisting of a planner, rewriter, observer, and followed by a self-evolving teacher model. While for RL, we employ DAPO as the training framework and adopt a hybrid reward system consisting of answer rewards and format rewards. Additionally, we introduce a curriculum learning approach that allows the model to learn progressively from easier to more challenging instances based on the number of masked spans. We evaluate the effectiveness of our framework in the scenario of open-domain multi-hop question answering. Through extensive experiments, we demonstrate that MASKSEARCH significantly enhances the performance of LLM-based search agents on both in-domain and out-of-domain downstream tasks.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.20285.pdf", "abstract_url": "https://arxiv.org/abs/2505.20285", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种名为MASKSEARCH的新型预训练框架，旨在通过引入检索增强掩码预测（RAMP）任务，增强大型语言模型（LLMs）的通用搜索能力。该框架结合了监督微调（SFT）和强化学习（RL）进行训练，并在开放域多跳问答场景中验证了其有效性。", "motivation": "现有的基于训练的方法在提升语言模型的代理能力方面存在局限性，主要受限于训练数据的特定任务特性。为了进一步提升代理的通用搜索能力，本文提出了MASKSEARCH框架。", "method": "MASKSEARCH框架在预训练阶段引入了RAMP任务，使模型学会利用搜索工具填补大量预训练数据中的掩码跨度。在下游任务训练中，结合了SFT和RL方法，其中SFT采用了基于代理和蒸馏的方法生成训练数据，RL则采用了DAPO框架和混合奖励系统。此外，还引入了课程学习方法。", "result": "实验结果表明，MASKSEARCH显著提升了基于LLM的搜索代理在域内和域外下游任务上的性能。", "conclusion": "MASKSEARCH框架通过创新的预训练和训练策略，有效增强了LLMs的通用检索和推理能力，为提升代理的搜索能力提供了新的方向。"}}
{"id": "2505.16849", "title": "Walk&Retrieve: Simple Yet Effective Zero-shot Retrieval-Augmented Generation via Knowledge Graph Walks", "authors": ["Martin Böckling", "Heiko Paulheim", "Andreea Iana"], "abstract": "Large Language Models (LLMs) have showcased impressive reasoning abilities, but often suffer from hallucinations or outdated knowledge. Knowledge Graph (KG)-based Retrieval-Augmented Generation (RAG) remedies these shortcomings by grounding LLM responses in structured external information from a knowledge base. However, many KG-based RAG approaches struggle with (i) aligning KG and textual representations, (ii) balancing retrieval accuracy and efficiency, and (iii) adapting to dynamically updated KGs. In this work, we introduce Walk&Retrieve, a simple yet effective KG-based framework that leverages walk-based graph traversal and knowledge verbalization for corpus generation for zero-shot RAG. Built around efficient KG walks, our method does not require fine-tuning on domain-specific data, enabling seamless adaptation to KG updates, reducing computational overhead, and allowing integration with any off-the-shelf backbone LLM. Despite its simplicity, Walk&Retrieve performs competitively, often outperforming existing RAG systems in response accuracy and hallucination reduction. Moreover, it demonstrates lower query latency and robust scalability to large KGs, highlighting the potential of lightweight retrieval strategies as strong baselines for future RAG research.", "subjects": "Information Retrieval (cs.IR); Computation and Language (cs.CL)", "comments": "Accepted at the Information Retrieval's Role in RAG Systems (IR-RAG 2025) in conjunction with SIGIR 2025", "pdf_url": "https://arxiv.org/pdf/2505.16849.pdf", "abstract_url": "https://arxiv.org/abs/2505.16849", "categories": ["Information Retrieval (cs.IR)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "Walk&Retrieve是一种基于知识图谱的零样本检索增强生成框架，通过图遍历和知识语言化有效解决LLMs的幻觉和知识过时问题，无需领域特定数据微调，适应性强且效率高。", "motivation": "解决大型语言模型(LLMs)在推理过程中出现的幻觉或知识过时问题，以及现有基于知识图谱(KG)的检索增强生成(RAG)方法在表示对齐、检索效率与准确性平衡及动态更新适应上的不足。", "method": "采用基于行走的图遍历和知识语言化技术，构建无需领域特定数据微调的框架，支持与任何现成骨干LLM的集成。", "result": "Walk&Retrieve在响应准确性和减少幻觉方面常优于现有RAG系统，同时展现出较低的查询延迟和对大型KG的强大可扩展性。", "conclusion": "Walk&Retrieve展示了轻量级检索策略作为未来RAG研究强基线的潜力，其简单性和高效性为动态更新的KG提供了无缝适应的解决方案。"}}
{"id": "2505.18710", "title": "GainRAG: Preference Alignment in Retrieval-Augmented Generation through Gain Signal Synthesis", "authors": ["Yi Jiang", "Sendong Zhao", "Jianbo Li", "Haochun Wang", "Bing Qin"], "abstract": "The Retrieval-Augmented Generation (RAG) framework introduces a retrieval module to dynamically inject retrieved information into the input context of large language models (LLMs), and has demonstrated significant success in various NLP tasks. However, the current study points out that there is a preference gap between retrievers and LLMs in the RAG framework, which limit the further improvement of system performance. Some highly relevant passages may interfere with LLM reasoning because they contain complex or contradictory information; while some indirectly related or even inaccurate content may help LLM generate more accurate answers by providing suggestive information or logical clues. To solve this, we propose GainRAG, a novel approach that aligns the retriever's and LLM's preferences by defining a new metric, \"gain\", which measure how well an input passage contributes to correct outputs. Specifically, we propose a method to estimate these gain signals and train a middleware that aligns the preferences of the retriever and the LLM using only limited data. In addition, we introduce a pseudo-passage strategy to mitigate degradation. The experimental results on 6 datasets verify the effectiveness of GainRAG.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "comments": "Accepted by ACL 2025", "pdf_url": "https://arxiv.org/pdf/2505.18710.pdf", "abstract_url": "https://arxiv.org/abs/2505.18710", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "GainRAG是一种新颖的方法，旨在通过定义一个新指标“增益”来对齐检索器和大型语言模型（LLM）的偏好，以解决检索增强生成（RAG）框架中存在的偏好差距问题。", "motivation": "解决RAG框架中检索器和LLM之间的偏好差距问题，这种差距限制了系统性能的进一步提升。", "method": "提出GainRAG方法，通过定义“增益”指标来衡量输入段落对正确输出的贡献程度，并利用有限数据训练一个中间件来对齐检索器和LLM的偏好。", "result": "在6个数据集上的实验结果验证了GainRAG的有效性。", "conclusion": "GainRAG通过增益信号合成和偏好对齐，有效解决了RAG框架中的偏好差距问题，提升了系统性能。"}}
{"id": "2505.18750", "title": "Agent-Based Decentralized Energy Management of EV Charging Station with Solar Photovoltaics via Multi-Agent Reinforcement Learning", "authors": ["Jiarong Fan", "Chenghao Huang", "Hao Wang"], "abstract": "In the pursuit of energy net zero within smart cities, transportation electrification plays a pivotal role. The adoption of Electric Vehicles (EVs) keeps increasing, making energy management of EV charging stations critically important. While previous studies have managed to reduce energy cost of EV charging while maintaining grid stability, they often overlook the robustness of EV charging management against uncertainties of various forms, such as varying charging behaviors and possible faults in faults in some chargers. To address the gap, a novel Multi-Agent Reinforcement Learning (MARL) approach is proposed treating each charger to be an agent and coordinate all the agents in the EV charging station with solar photovoltaics in a more realistic scenario, where system faults may occur. A Long Short-Term Memory (LSTM) network is incorporated in the MARL algorithm to extract temporal features from time-series. Additionally, a dense reward mechanism is designed for training the agents in the MARL algorithm to improve EV charging experience. Through validation on a real-world dataset, we show that our approach is robust against system uncertainties and faults and also effective in minimizing EV charging costs and maximizing charging service satisfaction.", "subjects": "Systems and Control (eess.SY); Artificial Intelligence (cs.AI); Optimization and Control (math.OC)", "comments": "2024 IEEE International Smart Cities Conference (ISC2)", "pdf_url": "https://arxiv.org/pdf/2505.18750.pdf", "abstract_url": "https://arxiv.org/abs/2505.18750", "categories": ["Systems and Control (eess.SY)", "Artificial Intelligence (cs.AI)", "Optimization and Control (math.OC)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于多智能体强化学习（MARL）的新方法，用于管理配备太阳能光伏的电动汽车（EV）充电站的能源，旨在应对充电行为变化和充电器故障等不确定性，以提高充电体验并降低成本。", "motivation": "为了解决电动汽车充电站在面对充电行为变化和充电器故障等不确定性时的能源管理问题，同时保持电网稳定性和降低能源成本。", "method": "采用多智能体强化学习（MARL）方法，将每个充电器视为一个智能体，并结合长短期记忆（LSTM）网络从时间序列中提取时间特征，设计了一个密集奖励机制来训练智能体。", "result": "通过在真实数据集上的验证，该方法显示出对系统不确定性和故障的鲁棒性，同时在最小化电动汽车充电成本和最大化充电服务满意度方面有效。", "conclusion": "该研究为电动汽车充电站的能源管理提供了一种有效且鲁棒的方法，有助于实现智能城市的能源净零目标。"}}
{"id": "2505.18889", "title": "Security Concerns for Large Language Models: A Survey", "authors": ["Miles Q. Li", "Benjamin C. M. Fung"], "abstract": "Large Language Models (LLMs) such as GPT-4 (and its recent iterations like GPT-4o and the GPT-4.1 series), Google's Gemini, Anthropic's Claude 3 models, and xAI's Grok have caused a revolution in natural language processing, but their capabilities also introduce new security vulnerabilities. In this survey, we provide a comprehensive overview of the emerging security concerns around LLMs, categorizing threats into prompt injection and jailbreaking, adversarial attacks (including input perturbations and data poisoning), misuse by malicious actors (e.g., for disinformation, phishing, and malware generation), and worrisome risks inherent in autonomous LLM agents. A significant focus has been recently placed on the latter, exploring goal misalignment, emergent deception, self-preservation instincts, and the potential for LLMs to develop and pursue covert, misaligned objectives (scheming), which may even persist through safety training. We summarize recent academic and industrial studies (2022-2025) that exemplify each threat, analyze proposed defenses and their limitations, and identify open challenges in securing LLM-based applications. We conclude by emphasizing the importance of advancing robust, multi-layered security strategies to ensure LLMs are safe and beneficial.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18889.pdf", "abstract_url": "https://arxiv.org/abs/2505.18889", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文综述了大型语言模型（LLMs）如GPT-4、Gemini、Claude 3和Grok等在自然语言处理领域引发的革命及其带来的新安全漏洞。", "motivation": "探讨LLMs在安全方面的新兴问题，包括提示注入和越狱、对抗性攻击、恶意行为者的滥用以及自主LLM代理的固有风险。", "method": "通过分类威胁、总结近期学术和工业研究（2022-2025年）、分析提出的防御措施及其局限性，以及识别保护LLM应用安全的开放挑战。", "result": "强调了推进强大、多层次安全策略的重要性，以确保LLMs的安全和益处。", "conclusion": "为了确保LLMs的安全和益处，必须发展强健、多层次的安全策略。"}}
{"id": "2505.19443", "title": "Vibe Coding vs. Agentic Coding: Fundamentals and Practical Implications of Agentic AI", "authors": ["Ranjan Sapkota", "Konstantinos I. Roumeliotis", "Manoj Karkee"], "abstract": "This review presents a comprehensive analysis of two emerging paradigms in AI-assisted software development: vibe coding and agentic coding. While both leverage large language models (LLMs), they differ fundamentally in autonomy, architectural design, and the role of the developer. Vibe coding emphasizes intuitive, human-in-the-loop interaction through prompt-based, conversational workflows that support ideation, experimentation, and creative exploration. In contrast, agentic coding enables autonomous software development through goal-driven agents capable of planning, executing, testing, and iterating tasks with minimal human intervention. We propose a detailed taxonomy spanning conceptual foundations, execution models, feedback loops, safety mechanisms, debugging strategies, and real-world tool ecosystems. Through comparative workflow analysis and 20 detailed use cases, we illustrate how vibe systems thrive in early-stage prototyping and education, while agentic systems excel in enterprise-grade automation, codebase refactoring, and CI/CD integration. We further examine emerging trends in hybrid architectures, where natural language interfaces are coupled with autonomous execution pipelines. Finally, we articulate a future roadmap for agentic AI, outlining the infrastructure needed for trustworthy, explainable, and collaborative systems. Our findings suggest that successful AI software engineering will rely not on choosing one paradigm, but on harmonizing their strengths within a unified, human-centered development lifecycle.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "35 Pages, 8 Figures, 6 Tables", "pdf_url": "https://arxiv.org/pdf/2505.19443.pdf", "abstract_url": "https://arxiv.org/abs/2505.19443", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文综述了AI辅助软件开发中的两种新兴范式：氛围编码（vibe coding）和代理编码（agentic coding）。氛围编码强调通过基于提示的对话工作流进行直观的人机交互，而代理编码则通过目标驱动的代理实现自主软件开发。文章提出了一个详细的分类法，并通过比较工作流分析和20个详细用例，展示了两种范式在不同场景下的优势。最后，文章提出了代理AI的未来发展路线图。", "motivation": "探讨AI辅助软件开发中的两种新兴范式，分析它们的差异、优势以及在实际应用中的表现，以促进AI软件工程的和谐发展。", "method": "通过提出详细的分类法，比较工作流分析，以及20个详细用例的展示，来分析氛围编码和代理编码的差异和优势。", "result": "氛围编码在早期原型设计和教育中表现优异，而代理编码在企业级自动化、代码库重构和CI/CD集成中表现突出。混合架构结合了两者的优势。", "conclusion": "成功的AI软件工程不在于选择一种范式，而在于在统一的、以人为中心的开发生命周期中调和它们的优势。"}}
{"id": "2505.19997", "title": "Embracing Imperfection: Simulating Students with Diverse Cognitive Levels Using LLM-based Agents", "authors": ["Tao Wu", "Jingyuan Chen", "Wang Lin", "Mengze Li", "Yumeng Zhu", "Ang Li", "Kun Kuang", "Fei Wu"], "abstract": "Large language models (LLMs) are revolutionizing education, with LLM-based agents playing a key role in simulating student behavior. A major challenge in student simulation is modeling the diverse learning patterns of students at various cognitive levels. However, current LLMs, typically trained as ``helpful assistants'', target at generating perfect responses. As a result, they struggle to simulate students with diverse cognitive abilities, as they often produce overly advanced answers, missing the natural imperfections that characterize student learning and resulting in unrealistic simulations. To address this issue, we propose a training-free framework for student simulation. We begin by constructing a cognitive prototype for each student using a knowledge graph, which captures their understanding of concepts from past learning records. This prototype is then mapped to new tasks to predict student performance. Next, we simulate student solutions based on these predictions and iteratively refine them using a beam search method to better replicate realistic mistakes. To validate our approach, we construct the \\texttt{Student\\_100} dataset, consisting of $100$ students working on Python programming and $5,000$ learning records. Experimental results show that our method consistently outperforms baseline models, achieving $100\\%$ improvement in simulation accuracy.", "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL); Computers and Society (cs.CY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19997.pdf", "abstract_url": "https://arxiv.org/abs/2505.19997", "categories": ["Machine Learning (cs.LG)", "Computation and Language (cs.CL)", "Computers and Society (cs.CY)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种无需训练的框架，用于模拟具有不同认知水平的学生行为，通过知识图谱构建认知原型并预测学生表现，进而模拟学生解决方案并迭代优化，以更真实地反映学生学习中的自然不完美。", "motivation": "当前基于大型语言模型（LLMs）的学生模拟方法倾向于生成过于完美的回答，无法真实反映学生在不同认知水平下的学习模式和自然错误，这限制了模拟的真实性和教育应用的有效性。", "method": "提出了一种训练自由的框架，首先为每个学生构建认知原型，然后映射到新任务以预测表现，并通过波束搜索方法迭代优化模拟的学生解决方案。", "result": "在包含100名学生和5,000条学习记录的Student_100数据集上的实验结果表明，该方法在模拟准确性上比基线模型提高了100%。", "conclusion": "该方法能够更真实地模拟学生在不同认知水平下的学习行为，为教育领域的应用提供了新的可能性。"}}
{"id": "2505.19955", "title": "MLR-Bench: Evaluating AI Agents on Open-Ended Machine Learning Research", "authors": ["Hui Chen", "Miao Xiong", "Yujie Lu", "Wei Han", "Ailin Deng", "Yufei He", "Jiaying Wu", "Yibo Li", "Yue Liu", "Bryan Hooi"], "abstract": "Recent advancements in AI agents have demonstrated their growing potential to drive and support scientific discovery. In this work, we introduce MLR-Bench, a comprehensive benchmark for evaluating AI agents on open-ended machine learning research. MLR-Bench includes three key components: (1) 201 research tasks sourced from NeurIPS, ICLR, and ICML workshops covering diverse ML topics; (2) MLR-Judge, an automated evaluation framework combining LLM-based reviewers with carefully designed review rubrics to assess research quality; and (3) MLR-Agent, a modular agent scaffold capable of completing research tasks through four stages: idea generation, proposal formulation, experimentation, and paper writing. Our framework supports both stepwise assessment across these distinct research stages, and end-to-end evaluation of the final research paper. We then use MLR-Bench to evaluate six frontier LLMs and an advanced coding agent, finding that while LLMs are effective at generating coherent ideas and well-structured papers, current coding agents frequently (e.g., in 80% of the cases) produce fabricated or invalidated experimental results--posing a major barrier to scientific reliability. We validate MLR-Judge through human evaluation, showing high agreement with expert reviewers, supporting its potential as a scalable tool for research evaluation. We open-source MLR-Bench to help the community benchmark, diagnose, and improve AI research agents toward trustworthy and transparent scientific discovery.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "40 pages, 7 figures", "pdf_url": "https://arxiv.org/pdf/2505.19955.pdf", "abstract_url": "https://arxiv.org/abs/2505.19955", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "MLR-Bench是一个评估AI代理在开放式机器学习研究中表现的全面基准，包括201个研究任务、自动评估框架MLR-Judge和模块化代理MLR-Agent。", "motivation": "评估AI代理在推动和支持科学发现方面的潜力，特别是在开放式机器学习研究中的表现。", "method": "引入MLR-Bench基准，包含三个关键组件：研究任务、自动评估框架MLR-Judge和模块化代理MLR-Agent，支持分阶段和端到端的评估。", "result": "发现LLMs在生成连贯想法和结构化论文方面有效，但当前编码代理常产生不可靠的实验结果，MLR-Judge与人类评估高度一致。", "conclusion": "MLR-Bench作为一个可扩展的研究评估工具，有助于社区评估、诊断和改进AI研究代理，促进可信和透明的科学发现。"}}
{"id": "2505.20046", "title": "REARANK: Reasoning Re-ranking Agent via Reinforcement Learning", "authors": ["Le Zhang", "Bo Wang", "Xipeng Qiu", "Siva Reddy", "Aishwarya Agrawal"], "abstract": "We present REARANK, a large language model (LLM)-based listwise reasoning reranking agent. REARANK explicitly reasons before reranking, significantly improving both performance and interpretability. Leveraging reinforcement learning and data augmentation, REARANK achieves substantial improvements over baseline models across popular information retrieval benchmarks, notably requiring only 179 annotated samples. Built on top of Qwen2.5-7B, our REARANK-7B demonstrates performance comparable to GPT-4 on both in-domain and out-of-domain benchmarks and even surpasses GPT-4 on reasoning-intensive BRIGHT benchmarks. These results underscore the effectiveness of our approach and highlight how reinforcement learning can enhance LLM reasoning capabilities in reranking.", "subjects": "Information Retrieval (cs.IR); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.20046.pdf", "abstract_url": "https://arxiv.org/abs/2505.20046", "categories": ["Information Retrieval (cs.IR)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "REARANK是一种基于大型语言模型（LLM）的列表推理重排代理，通过强化学习和数据增强显著提高了性能和可解释性。", "motivation": "解决信息检索中重排任务的性能和可解释性问题。", "method": "利用强化学习和数据增强，构建在Qwen2.5-7B上的REARANK-7B模型。", "result": "在流行信息检索基准测试中显著优于基线模型，仅需179个标注样本，性能与GPT-4相当，在推理密集型BRIGHT基准上甚至超越GPT-4。", "conclusion": "强化学习可以有效增强LLM在重排任务中的推理能力，REARANK方法展示了显著的性能提升和可解释性改进。"}}
{"id": "2505.19238", "title": "Efficient Policy Optimization in Robust Constrained MDPs with Iteration Complexity Guarantees", "authors": ["Sourav Ganguly", "Arnob Ghosh", "Kishan Panaganti", "Adam Wierman"], "abstract": "Constrained decision-making is essential for designing safe policies in real-world control systems, yet simulated environments often fail to capture real-world adversities. We consider the problem of learning a policy that will maximize the cumulative reward while satisfying a constraint, even when there is a mismatch between the real model and an accessible simulator/nominal model. In particular, we consider the robust constrained Markov decision problem (RCMDP) where an agent needs to maximize the reward and satisfy the constraint against the worst possible stochastic model under the uncertainty set centered around an unknown nominal model. Primal-dual methods, effective for standard constrained MDP (CMDP), are not applicable here because of the lack of the strong duality property. Further, one cannot apply the standard robust value-iteration based approach on the composite value function either as the worst case models may be different for the reward value function and the constraint value function. We propose a novel technique that effectively minimizes the constraint value function--to satisfy the constraints; on the other hand, when all the constraints are satisfied, it can simply maximize the robust reward value function. We prove that such an algorithm finds a policy with at most $\\epsilon$ sub-optimality and feasible policy after $O(\\epsilon^{-2})$ iterations. In contrast to the state-of-the-art method, we do not need to employ a binary search, thus, we reduce the computation time by at least 4x for smaller value of discount factor ($\\gamma$) and by at least 6x for larger value of $\\gamma$.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Robotics (cs.RO); Systems and Control (eess.SY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19238.pdf", "abstract_url": "https://arxiv.org/abs/2505.19238", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Robotics (cs.RO)", "Systems and Control (eess.SY)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种在具有迭代复杂度保证的鲁棒约束MDP中进行高效策略优化的方法，旨在在模型不匹配的情况下学习最大化累积奖励并满足约束的策略。", "motivation": "解决在模拟环境与实际环境存在差异时，如何学习既能最大化奖励又能满足约束的策略的问题。", "method": "提出了一种新技术，有效最小化约束值函数以满足约束，同时在所有约束满足时最大化鲁棒奖励值函数。", "result": "证明该算法能在$O(\\epsilon^{-2})$次迭代后找到最多$\\epsilon$次优且可行的策略，相比现有方法至少减少4x（较小折扣因子）或6x（较大折扣因子）的计算时间。", "conclusion": "该方法在鲁棒约束MDP中实现了高效策略优化，无需进行二分搜索，显著提高了计算效率。"}}
{"id": "2505.19205", "title": "OptiMindTune: A Multi-Agent Framework for Intelligent Hyperparameter Optimization", "authors": ["Meher Bhaskar Madiraju", "Meher Sai Preetam Madiraju"], "abstract": "Hyperparameter optimization (HPO) is a critical yet challenging aspect of machine learning model development, significantly impacting model performance and generalization. Traditional HPO methods often struggle with high dimensionality, complex interdependencies, and computational expense. This paper introduces OptiMindTune, a novel multi-agent framework designed to intelligently and efficiently optimize hyperparameters. OptiMindTune leverages the collaborative intelligence of three specialized AI agents -- a Recommender Agent, an Evaluator Agent, and a Decision Agent -- each powered by Google's Gemini models. These agents address distinct facets of the HPO problem, from model selection and hyperparameter suggestion to robust evaluation and strategic decision-making. By fostering dynamic interactions and knowledge sharing, OptiMindTune aims to converge to optimal hyperparameter configurations more rapidly and robustly than existing single-agent or monolithic approaches. Our framework integrates principles from advanced large language models, and adaptive search to achieve scalable and intelligent AutoML. We posit that this multi-agent paradigm offers a promising avenue for tackling the increasing complexity of modern machine learning model tuning.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "7 pages, 2 tables", "pdf_url": "https://arxiv.org/pdf/2505.19205.pdf", "abstract_url": "https://arxiv.org/abs/2505.19205", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "OptiMindTune是一个创新的多智能体框架，旨在智能高效地优化机器学习模型的超参数。它通过三个专门的AI智能体（推荐智能体、评估智能体和决策智能体）协作，利用Google的Gemini模型，解决了传统超参数优化方法在高维性、复杂互依赖性和计算成本方面的挑战。", "motivation": "解决传统超参数优化（HPO）方法在处理高维度、复杂互依赖性和高计算成本时的不足，提高模型性能和泛化能力。", "method": "采用多智能体框架，结合推荐、评估和决策三个智能体，利用Google的Gemini模型进行模型选择、超参数建议、鲁棒评估和策略决策。", "result": "OptiMindTune能够比现有的单智能体或整体方法更快、更稳健地收敛到最优超参数配置。", "conclusion": "多智能体范式为解决现代机器学习模型调优日益增长的复杂性提供了一个有前景的途径，整合了大型语言模型和自适应搜索的原则，实现了可扩展和智能的AutoML。"}}
{"id": "2505.19301", "title": "A Novel Zero-Trust Identity Framework for Agentic AI: Decentralized Authentication and Fine-Grained Access Control", "authors": ["Ken Huang", "Vineeth Sai Narajala", "John Yeoh", "Ramesh Raskar", "Youssef Harkati", "Jerry Huang", "Idan Habler", "Chris Hughes"], "abstract": "Traditional Identity and Access Management (IAM) systems, primarily designed for human users or static machine identities via protocols such as OAuth, OpenID Connect (OIDC), and SAML, prove fundamentally inadequate for the dynamic, interdependent, and often ephemeral nature of AI agents operating at scale within Multi Agent Systems (MAS), a computational system composed of multiple interacting intelligent agents that work collectively.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "24 Pages, 5 figures, 2 tables", "pdf_url": "https://arxiv.org/pdf/2505.19301.pdf", "abstract_url": "https://arxiv.org/abs/2505.19301", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种新颖的零信任身份框架，专为代理性AI设计，旨在解决传统身份和访问管理（IAM）系统在动态、相互依赖且常常短暂的多代理系统（MAS）中操作AI代理时的不足。", "motivation": "传统的IAM系统，如OAuth、OpenID Connect（OIDC）和SAML，主要为人类用户或静态机器身份设计，无法满足在多代理系统中大规模操作的AI代理的动态、相互依赖和短暂特性。", "method": "提出了一种去中心化认证和细粒度访问控制的零信任身份框架，以适应AI代理在MAS中的独特需求。", "result": "该框架能够有效解决传统IAM系统在处理动态和短暂AI代理身份时的不足，提供更灵活和安全的身份验证和访问控制机制。", "conclusion": "通过引入零信任原则和去中心化认证，该框架为AI代理在多代理系统中的安全操作提供了创新的解决方案，具有重要的理论和实践意义。"}}
{"id": "2505.19310", "title": "Retrieval-Augmented Generation for Service Discovery: Chunking Strategies and Benchmarking", "authors": ["Robin D. Pesl", "Jerin G. Mathew", "Massimo Mecella", "Marco Aiello"], "abstract": "Integrating multiple (sub-)systems is essential to create advanced Information Systems. Difficulties mainly arise when integrating dynamic environments, e.g., the integration at design time of not yet existing services. This has been traditionally addressed using a registry that provides the API documentation of the endpoints. Large Language Models have shown to be capable of automatically creating system integrations (e.g., as service composition) based on this documentation but require concise input due to input oken limitations, especially regarding comprehensive API descriptions. Currently, it is unknown how best to preprocess these API descriptions. In the present work, we (i) analyze the usage of Retrieval Augmented Generation for endpoint discovery and the chunking, i.e., preprocessing, of state-of-practice OpenAPIs to reduce the input oken length while preserving the most relevant information. To further reduce the input token length for the composition prompt and improve endpoint retrieval, we propose (ii) a Discovery Agent that only receives a summary of the most relevant endpoints nd retrieves specification details on demand. We evaluate RAG for endpoint discovery using (iii) a proposed novel service discovery benchmark SOCBench-D representing a general setting across numerous domains and the real-world RestBench enchmark, first, for the different chunking possibilities and parameters measuring the endpoint retrieval accuracy. Then, we assess the Discovery Agent using the same test data set. The prototype shows how to successfully employ RAG for endpoint discovery to reduce the token count. Our experiments show that endpoint-based approaches outperform naive chunking methods for preprocessing. Relying on an agent significantly improves precision while being prone to decrease recall, disclosing the need for further reasoning capabilities.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.19310.pdf", "abstract_url": "https://arxiv.org/abs/2505.19310", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文探讨了在动态环境中集成信息系统时，如何利用检索增强生成（RAG）技术优化服务发现过程，特别是通过预处理API描述来减少输入令牌长度，同时保留关键信息。", "motivation": "解决在设计时集成尚未存在的服务时遇到的挑战，特别是如何有效地预处理API描述以适应大型语言模型的输入令牌限制。", "method": "提出了一种发现代理（Discovery Agent），该代理仅接收最相关端点的摘要，并按需检索规范细节，以及评估了不同的分块策略和参数。", "result": "实验表明，基于端点的预处理方法优于朴素的分块方法，且发现代理显著提高了精度，尽管可能降低召回率。", "conclusion": "成功应用RAG技术于端点发现以减少令牌数量，揭示了进一步推理能力的必要性。"}}
{"id": "2505.19337", "title": "Prompting Decision Transformers for Zero-Shot Reach-Avoid Policies", "authors": ["Kevin Li", "Marinka Zitnik"], "abstract": "Offline goal-conditioned reinforcement learning methods have shown promise for reach-avoid tasks, where an agent must reach a target state while avoiding undesirable regions of the state space. Existing approaches typically encode avoid-region information into an augmented state space and cost function, which prevents flexible, dynamic specification of novel avoid-region information at evaluation time. They also rely heavily on well-designed reward and cost functions, limiting scalability to complex or poorly structured environments. We introduce RADT, a decision transformer model for offline, reward-free, goal-conditioned, avoid region-conditioned RL. RADT encodes goals and avoid regions directly as prompt tokens, allowing any number of avoid regions of arbitrary size to be specified at evaluation time. Using only suboptimal offline trajectories from a random policy, RADT learns reach-avoid behavior through a novel combination of goal and avoid-region hindsight relabeling. We benchmark RADT against 3 existing offline goal-conditioned RL models across 11 tasks, environments, and experimental settings. RADT generalizes in a zero-shot manner to out-of-distribution avoid region sizes and counts, outperforming baselines that require retraining. In one such zero-shot setting, RADT achieves 35.7% improvement in normalized cost over the best retrained baseline while maintaining high goal-reaching success. We apply RADT to cell reprogramming in biology, where it reduces visits to undesirable intermediate gene expression states during trajectories to desired target states, despite stochastic transitions and discrete, structured state dynamics.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Quantitative Methods (q-bio.QM)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19337.pdf", "abstract_url": "https://arxiv.org/abs/2505.19337", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Quantitative Methods (q-bio.QM)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了RADT，一种用于离线、无奖励、目标条件、避免区域条件的强化学习的决策变换器模型。RADT通过将目标和避免区域直接编码为提示令牌，允许在评估时动态指定任意数量的避免区域。RADT在11个任务、环境和实验设置中与3种现有的离线目标条件RL模型进行了比较，表现出色。", "motivation": "现有的离线目标条件强化学习方法通常将避免区域信息编码到增强状态空间和成本函数中，这限制了在评估时动态指定新的避免区域信息的灵活性。此外，这些方法严重依赖精心设计的奖励和成本函数，限制了其在复杂或结构不良环境中的可扩展性。", "method": "RADT通过将目标和避免区域直接编码为提示令牌，允许在评估时动态指定任意数量的避免区域。它仅使用随机策略的次优离线轨迹，通过目标和避免区域的后见之明重新标记学习到达避免行为。", "result": "RADT在零样本设置中对分布外的避免区域大小和数量表现出良好的泛化能力，优于需要重新训练的基线。在一个这样的零样本设置中，RADT在保持高目标到达成功率的同时，比最佳重新训练基线提高了35.7%的归一化成本。", "conclusion": "RADT在生物学细胞重编程中的应用表明，尽管存在随机过渡和离散、结构化的状态动态，它仍能减少在到达目标状态的轨迹中对不良中间基因表达状态的访问。"}}
{"id": "2505.19481", "title": "Win Fast or Lose Slow: Balancing Speed and Accuracy in Latency-Sensitive Decisions of LLMs", "authors": ["Hao Kang", "Qingru Zhang", "Han Cai", "Weiyuan Xu", "Tushar Krishna", "Yilun Du", "Tsachy Weissman"], "abstract": "Large language models (LLMs) have shown remarkable performance across diverse reasoning and generation tasks, and are increasingly deployed as agents in dynamic environments such as code generation and recommendation systems. However, many real-world applications, such as high-frequency trading and real-time competitive gaming, require decisions under strict latency constraints, where faster responses directly translate into higher rewards. Despite the importance of this latency quality trade off, it remains underexplored in the context of LLM based agents. In this work, we present the first systematic study of this trade off in real time decision making tasks. To support our investigation, we introduce two new benchmarks: HFTBench, a high frequency trading simulation, and StreetFighter, a competitive gaming platform. Our analysis reveals that optimal latency quality balance varies by task, and that sacrificing quality for lower latency can significantly enhance downstream performance. To address this, we propose FPX, an adaptive framework that dynamically selects model size and quantization level based on real time demands. Our method achieves the best performance on both benchmarks, improving win rate by up to 80% in Street Fighter and boosting daily yield by up to 26.52% in trading, underscoring the need for latency aware evaluation and deployment strategies for LLM based agents. These results demonstrate the critical importance of latency aware evaluation and deployment strategies for real world LLM based agents. Our benchmarks are available at Latency Sensitive Benchmarks.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19481.pdf", "abstract_url": "https://arxiv.org/abs/2505.19481", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Distributed, Parallel, and Cluster Computing (cs.DC)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究了大型语言模型（LLMs）在延迟敏感决策中的速度与准确性平衡问题，提出了FPX自适应框架，并在高频交易和竞技游戏两个新基准测试中验证了其有效性。", "motivation": "解决LLMs在严格延迟约束下的实时决策问题，如高频交易和实时竞技游戏，其中快速响应直接转化为更高的奖励。", "method": "引入了两个新基准测试HFTBench和StreetFighter，并提出了FPX自适应框架，动态选择模型大小和量化级别以适应实时需求。", "result": "FPX在两个基准测试中均取得了最佳性能，Street Fighter中的胜率提高了80%，交易中的日收益率提高了26.52%。", "conclusion": "研究表明，针对LLM基于代理的延迟感知评估和部署策略对现实世界应用至关重要，FPX框架有效平衡了延迟和质量，提升了性能。"}}
{"id": "2505.19509", "title": "Benchmarking Multimodal Knowledge Conflict for Large Multimodal Models", "authors": ["Yifan Jia", "Kailin Jiang", "Yuyang Liang", "Qihan Ren", "Yi Xin", "Rui Yang", "Fenze Feng", "Mingcai Chen", "Hengyang Lu", "Haozhe Wang", "Xiaoye Qu", "Dongrui Liu", "Lizhen Cui", "Yuntao Du"], "abstract": "Large Multimodal Models(LMMs) face notable challenges when encountering multimodal knowledge conflicts, particularly under retrieval-augmented generation(RAG) frameworks where the contextual information from external sources may contradict the model's internal parametric knowledge, leading to unreliable outputs. However, existing benchmarks fail to reflect such realistic conflict scenarios. Most focus solely on intra-memory conflicts, while context-memory and inter-context conflicts remain largely investigated. Furthermore, commonly used factual knowledge-based evaluations are often overlooked, and existing datasets lack a thorough investigation into conflict detection capabilities. To bridge this gap, we propose MMKC-Bench, a benchmark designed to evaluate factual knowledge conflicts in both context-memory and inter-context scenarios. MMKC-Bench encompasses three types of multimodal knowledge conflicts and includes 1,573 knowledge instances and 3,381 images across 23 broad types, collected through automated pipelines with human verification. We evaluate three representative series of LMMs on both model behavior analysis and conflict detection tasks. Our findings show that while current LMMs are capable of recognizing knowledge conflicts, they tend to favor internal parametric knowledge over external evidence. We hope MMKC-Bench will foster further research in multimodal knowledge conflict and enhance the development of multimodal RAG systems. The source code is available at", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.19509.pdf", "abstract_url": "https://arxiv.org/abs/2505.19509", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了MMKC-Bench基准，用于评估大型多模态模型(LMMs)在多模态知识冲突下的表现，特别是在检索增强生成(RAG)框架中，外部来源的上下文信息可能与模型的内部参数知识相矛盾，导致不可靠的输出。", "motivation": "现有的基准测试未能反映真实的多模态知识冲突场景，大多数仅关注内部记忆冲突，而上下文记忆和跨上下文冲突尚未得到充分研究。此外，基于事实知识的评估常被忽视，现有数据集对冲突检测能力的调查不足。", "method": "通过自动化流程收集并经人工验证，MMKC-Bench包含了三种类型的多模态知识冲突，涉及1,573个知识实例和3,381张图片，覆盖23个广泛的类型。评估了三个代表性的LMM系列在模型行为分析和冲突检测任务上的表现。", "result": "研究发现，当前的LMMs虽然能够识别知识冲突，但倾向于优先考虑内部参数知识而非外部证据。", "conclusion": "MMKC-Bench的提出旨在促进多模态知识冲突的进一步研究，并推动多模态RAG系统的发展。源代码已公开。"}}
{"id": "2505.19623", "title": "AgentRecBench: Benchmarking LLM Agent-based Personalized Recommender Systems", "authors": ["Yu Shang", "Peijie Liu", "Yuwei Yan", "Zijing Wu", "Leheng Sheng", "Yuanqing Yu", "Chumeng Jiang", "An Zhang", "Fengli Xu", "Yu Wang", "Min Zhang", "Yong Li"], "abstract": "The emergence of agentic recommender systems powered by Large Language Models (LLMs) represents a paradigm shift in personalized recommendations, leveraging LLMs' advanced reasoning and role-playing capabilities to enable autonomous, adaptive decision-making. Unlike traditional recommendation approaches, agentic recommender systems can dynamically gather and interpret user-item interactions from complex environments, generating robust recommendation strategies that generalize across diverse scenarios. However, the field currently lacks standardized evaluation protocols to systematically assess these methods. To address this critical gap, we propose: (1) an interactive textual recommendation simulator incorporating rich user and item metadata and three typical evaluation scenarios (classic, evolving-interest, and cold-start recommendation tasks); (2) a unified modular framework for developing and studying agentic recommender systems; and (3) the first comprehensive benchmark comparing 10 classical and agentic recommendation methods. Our findings demonstrate the superiority of agentic systems and establish actionable design guidelines for their core components. The benchmark environment has been rigorously validated through an open challenge and remains publicly available with a continuously maintained leaderboard~\\footnote[2]{", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "comments": "15 pages, 6 figures", "pdf_url": "https://arxiv.org/pdf/2505.19623.pdf", "abstract_url": "https://arxiv.org/abs/2505.19623", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了AgentRecBench，一个用于评估基于大型语言模型（LLM）的代理个性化推荐系统的基准测试。通过引入交互式文本推荐模拟器、统一的模块化框架和首个全面比较10种经典和代理推荐方法的基准，研究发现代理系统在个性化推荐中的优越性，并为其核心组件提供了可操作的设计指南。", "motivation": "解决代理推荐系统领域缺乏标准化评估协议的问题，以系统性地评估这些方法的性能。", "method": "提出了一个交互式文本推荐模拟器，包含丰富的用户和物品元数据及三种典型评估场景；开发了一个统一的模块化框架用于研究和开发代理推荐系统；并建立了首个全面比较经典和代理推荐方法的基准。", "result": "研究结果表明代理推荐系统在个性化推荐中表现优越，并为其核心组件提供了可操作的设计指南。", "conclusion": "通过AgentRecBench的建立和验证，为代理推荐系统的评估和发展提供了重要工具和见解，推动了该领域的进步。"}}
{"id": "2505.19698", "title": "JEDI: Latent End-to-end Diffusion Mitigates Agent-Human Performance Asymmetry in Model-Based Reinforcement Learning", "authors": ["Jing Yu Lim", "Zarif Ikram", "Samson Yu", "Haozhe Ma", "Tze-Yun Leong", "Dianbo Liu"], "abstract": "Recent advances in model-based reinforcement learning (MBRL) have achieved super-human level performance on the Atari100k benchmark, driven by reinforcement learning agents trained on powerful diffusion world models. However, we identify that the current aggregates mask a major performance asymmetry: MBRL agents dramatically outperform humans in some tasks despite drastically underperforming in others, with the former inflating the aggregate metrics. This is especially pronounced in pixel-based agents trained with diffusion world models. In this work, we address the pronounced asymmetry observed in pixel-based agents as an initial attempt to reverse the worrying upward trend observed in them. We address the problematic aggregates by delineating all tasks as Agent-Optimal or Human-Optimal and advocate for equal importance on metrics from both sets. Next, we hypothesize this pronounced asymmetry is due to the lack of temporally-structured latent space trained with the World Model objective in pixel-based methods. Lastly, to address this issue, we propose Joint Embedding DIffusion (JEDI), a novel latent diffusion world model trained end-to-end with the self-consistency objective. JEDI outperforms SOTA models in human-optimal tasks while staying competitive across the Atari100k benchmark, and runs 3 times faster with 43% lower memory than the latest pixel-based diffusion baseline. Overall, our work rethinks what it truly means to cross human-level performance in Atari100k.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": "Preprint", "pdf_url": "https://arxiv.org/pdf/2505.19698.pdf", "abstract_url": "https://arxiv.org/abs/2505.19698", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了JEDI，一种新颖的潜在扩散世界模型，旨在解决基于像素的强化学习代理在Atari100k基准测试中与人类表现不对称的问题。JEDI通过端到端训练和自我一致性目标，在人类优势任务中超越现有技术，同时在整体基准上保持竞争力，且运行速度更快、内存消耗更低。", "motivation": "当前基于扩散世界模型的强化学习代理在Atari100k基准测试中虽然总体上达到了超人类水平，但在某些任务中表现远超人类，而在其他任务中却远不如人类，这种不对称性被总体指标所掩盖。本文旨在解决这一问题。", "method": "本文首先将所有任务划分为代理优势或人类优势，并提倡对这两类任务的指标给予同等重视。接着，提出假设认为这种不对称性是由于基于像素的方法缺乏与世界模型目标一起训练的时序结构化潜在空间。最后，提出了JEDI，一种端到端训练的潜在扩散世界模型。", "result": "JEDI在人类优势任务中超越了现有技术，同时在Atari100k基准测试中保持竞争力，运行速度快3倍，内存消耗降低43%。", "conclusion": "本文重新思考了在Atari100k基准测试中真正超越人类表现的含义，提出了JEDI模型来解决代理与人类表现不对称的问题，为未来的研究提供了新的方向。"}}
{"id": "2505.19769", "title": "TeViR: Text-to-Video Reward with Diffusion Models for Efficient Reinforcement Learning", "authors": ["Yuhui Chen", "Haoran Li", "Zhennan Jiang", "Haowei Wen", "Dongbin Zhao"], "abstract": "Developing scalable and generalizable reward engineering for reinforcement learning (RL) is crucial for creating general-purpose agents, especially in the challenging domain of robotic manipulation. While recent advances in reward engineering with Vision-Language Models (VLMs) have shown promise, their sparse reward nature significantly limits sample efficiency. This paper introduces TeViR, a novel method that leverages a pre-trained text-to-video diffusion model to generate dense rewards by comparing the predicted image sequence with current observations. Experimental results across 11 complex robotic tasks demonstrate that TeViR outperforms traditional methods leveraging sparse rewards and other state-of-the-art (SOTA) methods, achieving better sample efficiency and performance without ground truth environmental rewards. TeViR's ability to efficiently guide agents in complex environments highlights its potential to advance reinforcement learning applications in robotic manipulation.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19769.pdf", "abstract_url": "https://arxiv.org/abs/2505.19769", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "TeViR是一种新颖的方法，利用预训练的文本到视频扩散模型通过比较预测的图像序列与当前观察来生成密集奖励，以提高强化学习在机器人操作任务中的样本效率和性能。", "motivation": "解决强化学习在机器人操作领域中奖励工程的可扩展性和泛化性问题，特别是针对稀疏奖励限制样本效率的挑战。", "method": "利用预训练的文本到视频扩散模型生成密集奖励，通过比较预测的图像序列与当前观察来指导强化学习代理。", "result": "在11个复杂的机器人任务中，TeViR优于利用稀疏奖励的传统方法和其它最先进方法，实现了更好的样本效率和性能，无需地面真实环境奖励。", "conclusion": "TeViR在复杂环境中高效指导代理的能力，突显了其在推进机器人操作中强化学习应用的潜力。"}}
{"id": "2505.19764", "title": "Agentic Predictor: Performance Prediction for Agentic Workflows via Multi-View Encoding", "authors": ["Patara Trirat", "Wonyong Jeong", "Sung Ju Hwang"], "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities across diverse tasks, but optimizing LLM-based agentic systems remains challenging due to the vast search space of agent configurations, prompting strategies, and communication patterns. Existing approaches often rely on heuristic-based tuning or exhaustive evaluation, which can be computationally expensive and suboptimal. This paper proposes Agentic Predictor, a lightweight predictor for efficient agentic workflow evaluation. Agentic Predictor is equipped with a multi-view workflow encoding technique that leverages multi-view representation learning of agentic systems by incorporating code architecture, textual prompts, and interaction graph features. To achieve high predictive accuracy while significantly reducing the number of required workflow evaluations for training a predictor, Agentic Predictor employs cross-domain unsupervised pretraining. By learning to approximate task success rates, Agentic Predictor enables fast and accurate selection of optimal agentic workflow configurations for a given task, significantly reducing the need for expensive trial-and-error evaluations. Experiments on a carefully curated benchmark spanning three domains show that our predictor outperforms state-of-the-art methods in both predictive accuracy and workflow utility, highlighting the potential of performance predictors in streamlining the design of LLM-based agentic workflows.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.19764.pdf", "abstract_url": "https://arxiv.org/abs/2505.19764", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了Agentic Predictor，一种轻量级的预测器，用于高效评估基于大型语言模型（LLM）的代理工作流程。通过多视图工作流编码技术和跨领域无监督预训练，该预测器能够快速准确地选择最优的代理工作流程配置，显著减少昂贵的试错评估需求。", "motivation": "优化基于LLM的代理系统面临巨大挑战，因为代理配置、提示策略和通信模式的搜索空间巨大。现有方法依赖于启发式调整或详尽评估，既计算昂贵又不够优化。", "method": "Agentic Predictor采用多视图工作流编码技术，结合代码架构、文本提示和交互图特征的多视图表示学习，并通过跨领域无监督预训练来减少训练预测器所需的工作流评估次数。", "result": "在跨越三个领域的精心策划的基准测试中，Agentic Predictor在预测准确性和工作流效用方面均优于最先进的方法。", "conclusion": "性能预测器在简化基于LLM的代理工作流程设计中具有巨大潜力，Agentic Predictor通过高效评估和优化配置选择，为这一领域提供了有价值的工具。"}}
{"id": "2505.19850", "title": "DISCOVER: Automated Curricula for Sparse-Reward Reinforcement Learning", "authors": ["Leander Diaz-Bone", "Marco Bagatella", "Jonas Hübotter", "Andreas Krause"], "abstract": "Sparse-reward reinforcement learning (RL) can model a wide range of highly complex tasks. Solving sparse-reward tasks is RL's core premise - requiring efficient exploration coupled with long-horizon credit assignment - and overcoming these challenges is key for building self-improving agents with superhuman ability. We argue that solving complex and high-dimensional tasks requires solving simpler tasks that are relevant to the target task. In contrast, most prior work designs strategies for selecting exploratory tasks with the objective of solving any task, making exploration of challenging high-dimensional, long-horizon tasks intractable. We find that the sense of direction, necessary for effective exploration, can be extracted from existing RL algorithms, without needing any prior information. Based on this finding, we propose a method for directed sparse-reward goal-conditioned very long-horizon RL (DISCOVER), which selects exploratory goals in the direction of the target task. We connect DISCOVER to principled exploration in bandits, formally bounding the time until the target task becomes achievable in terms of the agent's initial distance to the target, but independent of the volume of the space of all tasks. Empirically, we perform a thorough evaluation in high-dimensional environments. We find that the directed goal selection of DISCOVER solves exploration problems that are beyond the reach of prior state-of-the-art exploration methods in RL.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19850.pdf", "abstract_url": "https://arxiv.org/abs/2505.19850", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "DISCOVER提出了一种针对稀疏奖励强化学习（RL）的自动化课程学习方法，通过选择朝向目标任务方向的探索性目标，有效解决了高维、长视野任务的探索问题。", "motivation": "解决稀疏奖励RL中的高效探索和长视野信用分配问题，以构建具有超人能力的自我改进代理。", "method": "提出DISCOVER方法，利用现有RL算法提取方向感，无需先验信息，选择朝向目标任务的探索性目标。", "result": "DISCOVER在理论上限制了目标任务可实现的时间，与所有任务空间的体积无关；在实践中，它解决了现有最先进RL探索方法无法处理的问题。", "conclusion": "DISCOVER通过定向目标选择，为高维、长视野稀疏奖励RL任务提供了一种有效的探索策略，推动了自我改进代理的发展。"}}
{"id": "2505.19867", "title": "Deep Active Inference Agents for Delayed and Long-Horizon Environments", "authors": ["Yavar Taheri Yeganeh", "Mohsen Jafari", "Andrea Matta"], "abstract": "With the recent success of world-model agents, which extend the core idea of model-based reinforcement learning by learning a differentiable model for sample-efficient control across diverse tasks, active inference (AIF) offers a complementary, neuroscience-grounded paradigm that unifies perception, learning, and action within a single probabilistic framework powered by a generative model. Despite this promise, practical AIF agents still rely on accurate immediate predictions and exhaustive planning, a limitation that is exacerbated in delayed environments requiring plans over long horizons, tens to hundreds of steps. Moreover, most existing agents are evaluated on robotic or vision benchmarks which, while natural for biological agents, fall short of real-world industrial complexity. We address these limitations with a generative-policy architecture featuring (i) a multi-step latent transition that lets the generative model predict an entire horizon in a single look-ahead, (ii) an integrated policy network that enables the transition and receives gradients of the expected free energy, (iii) an alternating optimization scheme that updates model and policy from a replay buffer, and (iv) a single gradient step that plans over long horizons, eliminating exhaustive planning from the control loop. We evaluate our agent in an environment that mimics a realistic industrial scenario with delayed and long-horizon settings. The empirical results confirm the effectiveness of the proposed approach, demonstrating the coupled world-model with the AIF formalism yields an end-to-end probabilistic controller capable of effective decision making in delayed, long-horizon settings without handcrafted rewards or expensive planning.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19867.pdf", "abstract_url": "https://arxiv.org/abs/2505.19867", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种深度主动推理代理，用于解决延迟和长视野环境中的决策问题，通过生成策略架构和多步潜在转换等方法，有效提高了在复杂工业场景中的决策效率。", "motivation": "主动推理（AIF）虽然提供了一个统一的概率框架来结合感知、学习和行动，但在延迟和长视野环境中，现有的AIF代理仍依赖于准确的即时预测和详尽的规划，这限制了其在实际复杂环境中的应用。", "method": "采用了一种生成策略架构，包括多步潜在转换、集成的策略网络、交替优化方案和单梯度步长规划，以消除控制循环中的详尽规划需求。", "result": "在模拟现实工业场景的延迟和长视野设置环境中，所提出的方法显示出有效性，证明了结合世界模型和AIF形式主义能够实现端到端的概率控制。", "conclusion": "该研究提出了一种无需手工奖励或昂贵规划的深度主动推理代理，能够在延迟和长视野设置中进行有效决策，为复杂环境中的决策问题提供了新的解决方案。"}}
