{"id": "2506.12103", "title": "The Amazon Nova Family of Models: Technical Report and Model Card", "authors": ["Amazon AGI", "Aaron Langford", "Aayush Shah", "Abhanshu Gupta", "Abhimanyu Bhatter", "Abhinav Goyal", "Abhinav Mathur", "Abhinav Mohanty", "Abhishek Kumar", "Abhishek Sethi", "Abi Komma", "Abner Pena", "Achin Jain", "Adam Kunysz", "Adam Opyrchal", "Adarsh Singh", "Aditya Rawal", "Adok Achar Budihal Prasad", "Adrià de Gispert", "Agnika Kumar", "Aishwarya Aryamane", "Ajay Nair", "Akilan M", "Akshaya Iyengar", "Akshaya Vishnu Kudlu Shanbhogue", "Alan He", "Alessandra Cervone", "Alex Loeb", "Alex Zhang", "Alexander Fu", "Alexander Lisnichenko", "Alexander Zhipa", "Alexandros Potamianos", "Ali Kebarighotbi", "Aliakbar Daronkolaei", "Alok Parmesh", "Amanjot Kaur Samra", "Ameen Khan", "Amer Rez", "Amir Saffari", "Amit Agarwalla", "Amit Jhindal", "Amith Mamidala", "Ammar Asmro", "Amulya Ballakur", "Anand Mishra", "Anand Sridharan", "Anastasiia Dubinina", "Andre Lenz", "Andreas Doerr", "Andrew Keating", "Andrew Leaver", "Andrew Smith", "Andrew Wirth", "Andy Davey", "Andy Rosenbaum", "Andy Sohn", "Angela Chan", "Aniket Chakrabarti", "Anil Ramakrishna", "Anirban Roy", "Anita Iyer", "Anjali Narayan-Chen", "Ankith Yennu", "Anna Dabrowska", "Anna Gawlowska", "Anna Rumshisky", "Anna Turek", "Anoop Deoras", "Anton Bezruchkin", "Anup Prasad", "Anupam Dewan", "Anwith Kiran", "Apoorv Gupta", "Aram Galstyan", "Aravind Manoharan", "Arijit Biswas", "Arindam Mandal", "Arpit Gupta", "Arsamkhan Pathan", "Arun Nagarajan", "Arushan Rajasekaram", "Arvind Sundararajan", "Ashwin Ganesan", "Ashwin Swaminathan", "Athanasios Mouchtaris", "Audrey Champeau", "Avik Ray", "Ayush Jaiswal", "Ayush Sharma", "Bailey Keefer", "Balamurugan Muthiah", "Beatriz Leon-Millan", "Ben Koopman", "Ben Li", "Benjamin Biggs", "Benjamin Ott", "Bhanu Vinzamuri", "Bharath Venkatesh", "Bhavana Ganesh"], "abstract": "We present Amazon Nova, a new generation of state-of-the-art foundation models that deliver frontier intelligence and industry-leading price performance. Amazon Nova Pro is a highly-capable multimodal model with the best combination of accuracy, speed, and cost for a wide range of tasks. Amazon Nova Lite is a low-cost multimodal model that is lightning fast for processing images, video, documents and text. Amazon Nova Micro is a text-only model that delivers our lowest-latency responses at very low cost. Amazon Nova Canvas is an image generation model that creates professional grade images with rich customization controls. Amazon Nova Reel is a video generation model offering high-quality outputs, customization, and motion control. Our models were built responsibly and with a commitment to customer trust, security, and reliability. We report benchmarking results for core capabilities, agentic performance, long context, functional adaptation, runtime performance, and human evaluation.", "subjects": "Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)", "comments": "48 pages, 10 figures", "pdf_url": "https://arxiv.org/pdf/2506.12103.pdf", "abstract_url": "https://arxiv.org/abs/2506.12103", "categories": ["Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "亚马逊Nova系列模型技术报告与模型卡介绍了新一代最先进的基础模型，提供前沿智能和行业领先的价格性能比。", "motivation": "解决在广泛任务中实现最佳准确性、速度和成本组合的需求，以及提供低成本、快速处理多模态数据和文本的模型。", "method": "开发了包括Amazon Nova Pro、Amazon Nova Lite、Amazon Nova Micro、Amazon Nova Canvas和Amazon Nova Reel在内的多模态和单模态模型系列，专注于不同的性能需求和成本效益。", "result": "报告了核心能力、代理性能、长上下文、功能适应、运行时性能和人类评估的基准测试结果，展示了模型的高性能和多样性。", "conclusion": "亚马逊Nova系列模型以负责任的态度构建，致力于客户信任、安全性和可靠性，为各种应用场景提供了高效、经济的解决方案。"}}
{"id": "2506.12066", "title": "Focusing on Students, not Machines: Grounded Question Generation and Automated Answer Grading", "authors": ["Gérôme Meyer", "Philip Breuer"], "abstract": "Digital technologies are increasingly used in education to reduce the workload of teachers and students. However, creating open-ended study or examination questions and grading their answers is still a tedious task. This thesis presents the foundation for a system that generates questions grounded in class materials and automatically grades student answers. It introduces a sophisticated method for chunking documents with a visual layout, specifically targeting PDF documents. This method enhances the accuracy of downstream tasks, including Retrieval Augmented Generation (RAG). Our thesis demonstrates that high-quality questions and reference answers can be generated from study material. Further, it introduces a new benchmark for automated grading of short answers to facilitate comparison of automated grading systems. An evaluation of various grading systems is conducted and indicates that Large Language Models (LLMs) can generalise to the task of automated grading of short answers from their pre-training tasks. As with other tasks, increasing the parameter size of the LLMs leads to greater performance. Currently, available systems still need human oversight, especially in examination scenarios.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.12066.pdf", "abstract_url": "https://arxiv.org/abs/2506.12066", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种基于课堂材料生成问题并自动评分学生答案的系统基础，介绍了针对PDF文档的视觉布局分块方法，提高了包括检索增强生成（RAG）在内的下游任务的准确性。研究表明，可以从学习材料中生成高质量的问题和参考答案，并引入了一个新的自动评分短答案的基准。评估显示，大型语言模型（LLMs）能够泛化到自动评分短答案的任务，且参数规模越大性能越好。", "motivation": "解决在教育中创建开放式学习或考试问题及评分答案的繁琐任务，减少教师和学生的工作量。", "method": "采用视觉布局分块方法处理PDF文档，利用检索增强生成（RAG）技术生成问题和参考答案，并评估不同自动评分系统的性能。", "result": "研究表明，可以从学习材料中生成高质量的问题和参考答案，大型语言模型（LLMs）在自动评分短答案任务上表现出色，且参数规模越大性能越好。", "conclusion": "当前可用的系统在考试场景中仍需人工监督，但大型语言模型（LLMs）在自动评分任务上显示出潜力，参数规模的增加有助于提高性能。"}}
{"id": "2506.12232", "title": "Zero-Shot Scene Understanding with Multimodal Large Language Models for Automated Vehicles", "authors": ["Mohammed Elhenawy", "Shadi Jaradat", "Taqwa I. Alhadidi", "Huthaifa I. Ashqar", "Ahmed Jaber", "Andry Rakotonirainy", "Mohammad Abu Tami"], "abstract": "Scene understanding is critical for various downstream tasks in autonomous driving, including facilitating driver-agent communication and enhancing human-centered explainability of autonomous vehicle (AV) decisions. This paper evaluates the capability of four multimodal large language models (MLLMs), including relatively small models, to understand scenes in a zero-shot, in-context learning setting. Additionally, we explore whether combining these models using an ensemble approach with majority voting can enhance scene understanding performance. Our experiments demonstrate that GPT-4o, the largest model, outperforms the others in scene understanding. However, the performance gap between GPT-4o and the smaller models is relatively modest, suggesting that advanced techniques such as improved in-context learning, retrieval-augmented generation (RAG), or fine-tuning could further optimize the smaller models' performance. We also observe mixed results with the ensemble approach: while some scene attributes show improvement in performance metrics such as F1-score, others experience a decline. These findings highlight the need for more sophisticated ensemble techniques to achieve consistent gains across all scene attributes. This study underscores the potential of leveraging MLLMs for scene understanding and provides insights into optimizing their performance for autonomous driving applications.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.12232.pdf", "abstract_url": "https://arxiv.org/abs/2506.12232", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文评估了四种多模态大型语言模型（MLLMs）在零样本、上下文学习设置下的场景理解能力，并探讨了通过多数投票的集成方法是否能提升性能。实验表明，GPT-4o表现最佳，但与小模型差距不大，提示通过改进上下文学习、检索增强生成（RAG）或微调可优化小模型性能。集成方法结果不一，需更复杂技术以在所有场景属性上实现一致增益。", "motivation": "解决自动驾驶中场景理解的关键问题，以促进驾驶员-代理通信和增强自动驾驶决策的人类中心解释性。", "method": "评估四种MLLMs在零样本、上下文学习设置下的场景理解能力，并探索多数投票的集成方法。", "result": "GPT-4o表现最佳，但与小模型差距不大；集成方法在某些场景属性上提升性能，其他则下降。", "conclusion": "MLLMs在场景理解中具有潜力，需更先进技术优化小模型和集成方法，以应用于自动驾驶。"}}
{"id": "2506.12149", "title": "Maximally-Informative Retrieval for State Space Model Generation", "authors": ["Evan Becker", "Benjamin Bowman", "Matthew Trager", "Tian Yu Liu", "Luca Zancato", "Wei Xia", "Stefano Soatto"], "abstract": "Given a query and dataset, the optimal way of answering the query is to make use all the information available. Modern LLMs exhibit impressive ability to memorize training data, but data not deemed important during training is forgotten, and information outside that training set cannot be made use of. Processing an entire dataset at inference time is infeasible due to the bounded nature of model resources (e.g. context size in transformers or states in state space models), meaning we must resort to external memory. This constraint naturally leads to the following problem: How can we decide based on the present query and model, what among a virtually unbounded set of known data matters for inference? To minimize model uncertainty for a particular query at test-time, we introduce Retrieval In-Context Optimization (RICO), a retrieval method that uses gradients from the LLM itself to learn the optimal mixture of documents for answer generation. Unlike traditional retrieval-augmented generation (RAG), which relies on external heuristics for document retrieval, our approach leverages direct feedback from the model. Theoretically, we show that standard top-$k$ retrieval with model gradients can approximate our optimization procedure, and provide connections to the leave-one-out loss. We demonstrate empirically that by minimizing an unsupervised loss objective in the form of question perplexity, we can achieve comparable retriever metric performance to BM25 with \\emph{no finetuning}. Furthermore, when evaluated on quality of the final prediction, our method often outperforms fine-tuned dense retrievers such as E5.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.12149.pdf", "abstract_url": "https://arxiv.org/abs/2506.12149", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了RICO，一种利用LLM梯度学习最优文档混合以生成答案的检索方法，旨在最小化测试时特定查询的模型不确定性。", "motivation": "解决在模型资源有限的情况下，如何基于当前查询和模型决定哪些已知数据对推理重要的问题。", "method": "提出了Retrieval In-Context Optimization (RICO)，一种利用LLM梯度优化文档混合的检索方法。", "result": "通过最小化问题困惑度的无监督损失目标，无需微调即可达到与BM25相当的检索器性能，且在最终预测质量上常优于精细调整的密集检索器如E5。", "conclusion": "RICO方法通过直接利用模型反馈优化检索过程，为检索增强生成提供了新的方向，展示了在无监督设置下实现高效检索的潜力。"}}
{"id": "2506.12200", "title": "PRO-V: An Efficient Program Generation Multi-Agent System for Automatic RTL Verification", "authors": ["Yujie Zhao", "Zhijing Wu", "Hejia Zhang", "Zhongming Yu", "Wentao Ni", "Chia-Tung Ho", "Haoxing Ren", "Jishen Zhao"], "abstract": "LLM-assisted hardware verification is gaining substantial attention due to its potential to significantly reduce the cost and effort of crafting effective testbenches. It also serves as a critical enabler for LLM-aided end-to-end hardware language design. However, existing current LLMs often struggle with Register Transfer Level (RTL) code generation, resulting in testbenches that exhibit functional errors in Hardware Description Languages (HDL) logic. Motivated by the strong performance of LLMs in Python code generation under inference-time sampling strategies, and their promising capabilities as judge agents, we propose PRO-V a fully program generation multi-agent system for robust RTL verification. Pro-V incorporates an efficient best-of-n iterative sampling strategy to enhance the correctness of generated testbenches. Moreover, it introduces an LLM-as-a-judge aid validation framework featuring an automated prompt generation pipeline. By converting rule-based static analysis from the compiler into natural language through in-context learning, this pipeline enables LLMs to assist the compiler in determining whether verification failures stem from errors in the RTL design or the testbench. PRO-V attains a verification accuracy of 87.17% on golden RTL implementations and 76.28% on RTL mutants. Our code is open-sourced at", "subjects": "Artificial Intelligence (cs.AI); Hardware Architecture (cs.AR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.12200.pdf", "abstract_url": "https://arxiv.org/abs/2506.12200", "categories": ["Artificial Intelligence (cs.AI)", "Hardware Architecture (cs.AR)"], "matching_keywords": ["agent"], "AI": {"tldr": "PRO-V是一个高效的程序生成多代理系统，旨在通过LLM辅助的硬件验证自动生成RTL测试平台，提高验证准确性和效率。", "motivation": "解决现有LLM在生成RTL代码时存在的功能错误问题，以及降低硬件验证的成本和努力。", "method": "采用最佳n次迭代采样策略增强测试平台的正确性，并引入LLM作为法官辅助验证框架，通过自然语言转换编译器基于规则的静态分析。", "result": "PRO-V在黄金RTL实现上的验证准确率达到87.17%，在RTL突变体上的准确率为76.28%。", "conclusion": "PRO-V通过创新的多代理系统和验证框架，显著提高了RTL验证的准确性和效率，为LLM辅助的端到端硬件语言设计提供了强有力的支持。"}}
{"id": "2506.12152", "title": "Because we have LLMs, we Can and Should Pursue Agentic Interpretability", "authors": ["Been Kim", "John Hewitt", "Neel Nanda", "Noah Fiedel", "Oyvind Tafjord"], "abstract": "The era of Large Language Models (LLMs) presents a new opportunity for interpretability--agentic interpretability: a multi-turn conversation with an LLM wherein the LLM proactively assists human understanding by developing and leveraging a mental model of the user, which in turn enables humans to develop better mental models of the LLM. Such conversation is a new capability that traditional `inspective' interpretability methods (opening the black-box) do not use. Having a language model that aims to teach and explain--beyond just knowing how to talk--is similar to a teacher whose goal is to teach well, understanding that their success will be measured by the student's comprehension. While agentic interpretability may trade off completeness for interactivity, making it less suitable for high-stakes safety situations with potentially deceptive models, it leverages a cooperative model to discover potentially superhuman concepts that can improve humans' mental model of machines. Agentic interpretability introduces challenges, particularly in evaluation, due to what we call `human-entangled-in-the-loop' nature (humans responses are integral part of the algorithm), making the design and evaluation difficult. We discuss possible solutions and proxy goals. As LLMs approach human parity in many tasks, agentic interpretability's promise is to help humans learn the potentially superhuman concepts of the LLMs, rather than see us fall increasingly far from understanding them.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.12152.pdf", "abstract_url": "https://arxiv.org/abs/2506.12152", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种名为‘代理可解释性’的新方法，利用大型语言模型（LLMs）通过多轮对话主动协助人类理解，旨在通过LLMs的教学和解释能力，帮助人类更好地理解LLMs的潜在超人概念。", "motivation": "解决传统‘检查性’可解释性方法（即打开黑盒）无法利用LLMs的新能力，如主动教学和解释，以促进人类对LLMs更深层次理解的问题。", "method": "采用代理可解释性方法，即通过LLMs与人类的多轮对话，LLMs主动协助人类理解，并利用对用户的心理模型来改进人类对LLMs的理解。", "result": "代理可解释性虽然可能在完整性上有所牺牲以获得交互性，不适合高风险安全场景，但能够利用合作模型发现可能超越人类的概念，提升人类对机器的理解。", "conclusion": "随着LLMs在许多任务上接近人类水平，代理可解释性的承诺是帮助人类学习LLMs的潜在超人概念，而不是让我们越来越远离理解它们。"}}
{"id": "2506.12245", "title": "Reversing the Paradigm: Building AI-First Systems with Human Guidance", "authors": ["Cosimo Spera", "Garima Agrawal"], "abstract": "The relationship between humans and artificial intelligence is no longer science fiction -- it's a growing reality reshaping how we live and work. AI has moved beyond research labs into everyday life, powering customer service chats, personalizing travel, aiding doctors in diagnosis, and supporting educators. What makes this moment particularly compelling is AI's increasing collaborative nature. Rather than replacing humans, AI augments our capabilities -- automating routine tasks, enhancing decisions with data, and enabling creativity in fields like design, music, and writing. The future of work is shifting toward AI agents handling tasks autonomously, with humans as supervisors, strategists, and ethical stewards. This flips the traditional model: instead of humans using AI as a tool, intelligent agents will operate independently within constraints, managing everything from scheduling and customer service to complex workflows. Humans will guide and fine-tune these agents to ensure alignment with goals, values, and context.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.12245.pdf", "abstract_url": "https://arxiv.org/abs/2506.12245", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了人工智能与人类关系的转变，从人类使用AI作为工具转变为AI自主操作，人类作为监督者和指导者的新模式。", "motivation": "解决如何构建以AI为先的系统，同时确保人类在其中发挥指导和监督作用的问题。", "method": "提出了一种翻转传统模式的方法，即AI代理在约束下自主操作，人类负责指导和微调。", "result": "AI的协作性质增强，能够在多个领域自动化常规任务，增强决策，并激发创造力。", "conclusion": "未来的工作将趋向于AI代理自主处理任务，人类则扮演监督者、战略家和伦理管家的角色，确保AI与目标、价值观和情境的一致性。"}}
{"id": "2506.12241", "title": "Privacy Reasoning in Ambiguous Contexts", "authors": ["Ren Yi", "Octavian Suciu", "Adria Gascon", "Sarah Meiklejohn", "Eugene Bagdasarian", "Marco Gruteser"], "abstract": "We study the ability of language models to reason about appropriate information disclosure - a central aspect of the evolving field of agentic privacy. Whereas previous works have focused on evaluating a model's ability to align with human decisions, we examine the role of ambiguity and missing context on model performance when making information-sharing decisions. We identify context ambiguity as a crucial barrier for high performance in privacy assessments. By designing Camber, a framework for context disambiguation, we show that model-generated decision rationales can reveal ambiguities and that systematically disambiguating context based on these rationales leads to significant accuracy improvements (up to 13.3\\% in precision and up to 22.3\\% in recall) as well as reductions in prompt sensitivity. Overall, our results indicate that approaches for context disambiguation are a promising way forward to enhance agentic privacy reasoning.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.12241.pdf", "abstract_url": "https://arxiv.org/abs/2506.12241", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文研究了语言模型在信息适当披露方面的推理能力，重点关注了语境模糊性对模型性能的影响，并提出了Camber框架来消除语境模糊，显著提高了隐私评估的准确性。", "motivation": "解决语言模型在信息共享决策中因语境模糊和缺失上下文而导致的性能问题，以提升代理隐私推理的能力。", "method": "设计了Camber框架，通过模型生成的决策理由揭示模糊性，并系统地基于这些理由消除语境模糊。", "result": "使用Camber框架后，隐私评估的准确性显著提高（精确度最高提升13.3%，召回率最高提升22.3%），并减少了提示敏感性。", "conclusion": "语境消歧方法是提升代理隐私推理能力的有效途径，为未来的研究提供了有希望的方向。"}}
{"id": "2506.12270", "title": "Cloud Infrastructure Management in the Age of AI Agents", "authors": ["Zhenning Yang", "Archit Bhatnagar", "Yiming Qiu", "Tongyuan Miao", "Patrick Tser Jern Kon", "Yunming Xiao", "Yibo Huang", "Martin Casado", "Ang Chen"], "abstract": "Cloud infrastructure is the cornerstone of the modern IT industry. However, managing this infrastructure effectively requires considerable manual effort from the DevOps engineering team. We make a case for developing AI agents powered by large language models (LLMs) to automate cloud infrastructure management tasks. In a preliminary study, we investigate the potential for AI agents to use different cloud/user interfaces such as software development kits (SDK), command line interfaces (CLI), Infrastructure-as-Code (IaC) platforms, and web portals. We report takeaways on their effectiveness on different management tasks, and identify research challenges and potential solutions.", "subjects": "Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG); Systems and Control (eess.SY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.12270.pdf", "abstract_url": "https://arxiv.org/abs/2506.12270", "categories": ["Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)", "Machine Learning (cs.LG)", "Systems and Control (eess.SY)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了利用大型语言模型（LLMs）驱动的AI代理来自动化云基础设施管理任务的潜力。通过初步研究，评估了AI代理在不同云/用户界面上的有效性，并提出了研究挑战和潜在解决方案。", "motivation": "云基础设施是现代IT行业的基石，但其有效管理需要DevOps工程团队的大量手动努力。本文旨在探索AI代理自动化这些任务的潜力，以减少人工干预。", "method": "研究通过初步调查，评估AI代理在软件开发工具包（SDK）、命令行界面（CLI）、基础设施即代码（IaC）平台和网络门户等不同云/用户界面上的应用效果。", "result": "报告了AI代理在不同管理任务上的有效性，并识别了研究挑战及潜在解决方案。", "conclusion": "AI代理在自动化云基础设施管理方面展现出潜力，但仍需解决一系列研究挑战以实现广泛应用。"}}
{"id": "2506.12266", "title": "The Behavior Gap: Evaluating Zero-shot LLM Agents in Complex Task-Oriented Dialogs", "authors": ["Avinash Baidya", "Kamalika Das", "Xiang Gao"], "abstract": "Large Language Model (LLM)-based agents have significantly impacted Task-Oriented Dialog Systems (TODS) but continue to face notable performance challenges, especially in zero-shot scenarios. While prior work has noted this performance gap, the behavioral factors driving the performance gap remain under-explored. This study proposes a comprehensive evaluation framework to quantify the behavior gap between AI agents and human experts, focusing on discrepancies in dialog acts, tool usage, and knowledge utilization. Our findings reveal that this behavior gap is a critical factor negatively impacting the performance of LLM agents. Notably, as task complexity increases, the behavior gap widens (correlation: 0.963), leading to a degradation of agent performance on complex task-oriented dialogs. For the most complex task in our study, even the GPT-4o-based agent exhibits low alignment with human behavior, with low F1 scores for dialog acts (0.464), excessive and often misaligned tool usage with a F1 score of 0.139, and ineffective usage of external knowledge. Reducing such behavior gaps leads to significant performance improvement (24.3% on average). This study highlights the importance of comprehensive behavioral evaluations and improved alignment strategies to enhance the effectiveness of LLM-based TODS in handling complex tasks.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)", "comments": "ACL 2025; 18 pages, 8 figures", "pdf_url": "https://arxiv.org/pdf/2506.12266.pdf", "abstract_url": "https://arxiv.org/abs/2506.12266", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本研究提出了一个全面的评估框架，用于量化AI代理与人类专家在对话行为、工具使用和知识利用方面的行为差距，发现这一差距是影响LLM代理性能的关键因素。", "motivation": "解决大型语言模型（LLM）代理在零射击场景下的任务导向对话系统（TODS）中面临的性能挑战，特别是行为差距对性能的影响。", "method": "通过评估框架量化AI代理与人类专家在对话行为、工具使用和知识利用方面的行为差距。", "result": "研究发现，行为差距是影响LLM代理性能的关键因素，随着任务复杂度的增加，行为差距扩大，导致代理性能下降。减少行为差距可以显著提高性能（平均提高24.3%）。", "conclusion": "强调了全面行为评估和改进对齐策略的重要性，以提高LLM基础的TODS在处理复杂任务时的有效性。"}}
{"id": "2506.12317", "title": "The Budget AI Researcher and the Power of RAG Chains", "authors": ["Franklin Lee", "Tengfei Ma"], "abstract": "Navigating the vast and rapidly growing body of scientific literature is a formidable challenge for aspiring researchers. Current approaches to supporting research idea generation often rely on generic large language models (LLMs). While LLMs are effective at aiding comprehension and summarization, they often fall short in guiding users toward practical research ideas due to their limitations. In this study, we present a novel structural framework for research ideation. Our framework, The Budget AI Researcher, uses retrieval-augmented generation (RAG) chains, vector databases, and topic-guided pairing to recombine concepts from hundreds of machine learning papers. The system ingests papers from nine major AI conferences, which collectively span the vast subfields of machine learning, and organizes them into a hierarchical topic tree. It uses the tree to identify distant topic pairs, generate novel research abstracts, and refine them through iterative self-evaluation against relevant literature and peer reviews, generating and refining abstracts that are both grounded in real-world research and demonstrably interesting. Experiments using LLM-based metrics indicate that our method significantly improves the concreteness of generated research ideas relative to standard prompting approaches. Human evaluations further demonstrate a substantial enhancement in the perceived interestingness of the outputs. By bridging the gap between academic data and creative generation, the Budget AI Researcher offers a practical, free tool for accelerating scientific discovery and lowering the barrier for aspiring researchers. Beyond research ideation, this approach inspires solutions to the broader challenge of generating personalized, context-aware outputs grounded in evolving real-world knowledge.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "Intended for AAAI's AI4Research Workshop", "pdf_url": "https://arxiv.org/pdf/2506.12317.pdf", "abstract_url": "https://arxiv.org/abs/2506.12317", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了一种名为‘预算AI研究员’的新颖结构框架，旨在通过检索增强生成（RAG）链、向量数据库和主题引导配对，从数百篇机器学习论文中重新组合概念，以生成和精炼研究摘要，显著提高了研究想法的具体性和趣味性。", "motivation": "解决当前大型语言模型（LLMs）在指导用户生成实用研究想法方面的局限性，帮助研究人员导航快速增长的科术文献。", "method": "使用检索增强生成（RAG）链、向量数据库和主题引导配对技术，结合九大AI会议的论文，构建分层主题树，识别远距离主题对，并通过迭代自我评估和同行评审生成和精炼研究摘要。", "result": "实验表明，该方法显著提高了生成研究想法的具体性，并大幅提升了输出的趣味性。", "conclusion": "‘预算AI研究员’不仅为加速科学发现和降低研究门槛提供了实用工具，还为生成基于现实世界知识的个性化、上下文感知输出提供了解决方案。"}}
{"id": "2506.12366", "title": "Ghost Policies: A New Paradigm for Understanding and Learning from Failure in Deep Reinforcement Learning", "authors": ["Xabier Olaz"], "abstract": "Deep Reinforcement Learning (DRL) agents often exhibit intricate failure modes that are difficult to understand, debug, and learn from. This opacity hinders their reliable deployment in real-world applications. To address this critical gap, we introduce ``Ghost Policies,'' a concept materialized through Arvolution, a novel Augmented Reality (AR) framework. Arvolution renders an agent's historical failed policy trajectories as semi-transparent ``ghosts'' that coexist spatially and temporally with the active agent, enabling an intuitive visualization of policy divergence. Arvolution uniquely integrates: (1) AR visualization of ghost policies, (2) a behavioural taxonomy of DRL maladaptation, (3) a protocol for systematic human disruption to scientifically study failure, and (4) a dual-learning loop where both humans and agents learn from these visualized failures. We propose a paradigm shift, transforming DRL agent failures from opaque, costly errors into invaluable, actionable learning resources, laying the groundwork for a new research field: ``Failure Visualization Learning.''", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.12366.pdf", "abstract_url": "https://arxiv.org/abs/2506.12366", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了‘幽灵策略’和Arvolution框架，旨在通过增强现实(AR)技术可视化深度强化学习(DRL)代理的历史失败策略轨迹，从而帮助理解和学习失败模式。", "motivation": "深度强化学习(DRL)代理的复杂失败模式难以理解、调试和学习，这阻碍了其在现实世界应用中的可靠部署。", "method": "提出了‘幽灵策略’概念和Arvolution框架，包括AR可视化幽灵策略、DRL不适应行为分类法、系统性人为干扰协议以及人类和代理从可视化失败中学习的双学习循环。", "result": "通过Arvolution框架，DRL代理的失败从难以理解的错误转变为宝贵的、可操作的学习资源。", "conclusion": "本文提出了一个范式转变，将DRL代理的失败转化为学习和研究的新资源，为‘失败可视化学习’这一新研究领域奠定了基础。"}}
{"id": "2506.12421", "title": "Plan Your Travel and Travel with Your Plan: Wide-Horizon Planning and Evaluation via LLM", "authors": ["Dongjie Yang", "Chengqiang Lu", "Qimeng Wang", "Xinbei Ma", "Yan Gao", "Yao Hu", "Hai Zhao"], "abstract": "Travel planning is a complex task requiring the integration of diverse real-world information and user preferences. While LLMs show promise, existing methods with long-horizon thinking struggle with handling multifaceted constraints and preferences in the context, leading to suboptimal itineraries. We formulate this as an $L^3$ planning problem, emphasizing long context, long instruction, and long output. To tackle this, we introduce Multiple Aspects of Planning (MAoP), enabling LLMs to conduct wide-horizon thinking to solve complex planning problems. Instead of direct planning, MAoP leverages the strategist to conduct pre-planning from various aspects and provide the planning blueprint for planning models, enabling strong inference-time scalability for better performance. In addition, current benchmarks overlook travel's dynamic nature, where past events impact subsequent journeys, failing to reflect real-world feasibility. To address this, we propose Travel-Sim, an agent-based benchmark assessing plans via real-world travel simulation. This work advances LLM capabilities in complex planning and offers novel insights for evaluating sophisticated scenarios through agent-based simulation.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.12421.pdf", "abstract_url": "https://arxiv.org/abs/2506.12421", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为MAoP的方法，通过LLM进行广泛视野的思考，以解决旅行规划中的复杂问题，并引入了Travel-Sim基准来评估计划的现实可行性。", "motivation": "旅行规划是一个复杂的任务，需要整合多样化的现实世界信息和用户偏好。现有的长视野思考方法在处理多方面的约束和偏好时表现不佳，导致行程规划不理想。", "method": "引入了多方面的规划（MAoP）方法，利用策略师进行预规划，为规划模型提供蓝图，从而在推理时实现更好的性能和可扩展性。", "result": "MAoP方法能够有效地解决复杂规划问题，Travel-Sim基准能够通过基于代理的模拟评估计划的现实可行性。", "conclusion": "这项工作提升了LLM在复杂规划中的能力，并通过基于代理的模拟为评估复杂场景提供了新的见解。"}}
{"id": "2506.12482", "title": "Tiered Agentic Oversight: A Hierarchical Multi-Agent System for AI Safety in Healthcare", "authors": ["Yubin Kim", "Hyewon Jeong", "Chanwoo Park", "Eugene Park", "Haipeng Zhang", "Xin Liu", "Hyeonhoon Lee", "Daniel McDuff", "Marzyeh Ghassemi", "Cynthia Breazeal", "Samir Tulebaev", "Hae Won Park"], "abstract": "Current large language models (LLMs), despite their power, can introduce safety risks in clinical settings due to limitations such as poor error detection and single point of failure. To address this, we propose Tiered Agentic Oversight (TAO), a hierarchical multi-agent framework that enhances AI safety through layered, automated supervision. Inspired by clinical hierarchies (e.g., nurse, physician, specialist), TAO conducts agent routing based on task complexity and agent roles. Leveraging automated inter- and intra-tier collaboration and role-playing, TAO creates a robust safety framework. Ablation studies reveal that TAO's superior performance is driven by its adaptive tiered architecture, which improves safety by over 3.2% compared to static single-tier configurations; the critical role of its lower tiers, particularly tier 1, whose removal most significantly impacts safety; and the strategic assignment of more advanced LLM to these initial tiers, which boosts performance by over 2% compared to less optimal allocations while achieving near-peak safety efficiently. These mechanisms enable TAO to outperform single-agent and multi-agent frameworks in 4 out of 5 healthcare safety benchmarks, showing up to an 8.2% improvement over the next-best methods in these evaluations. Finally, we validate TAO via an auxiliary clinician-in-the-loop study where integrating expert feedback improved TAO's accuracy in medical triage from 40% to 60%.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.12482.pdf", "abstract_url": "https://arxiv.org/abs/2506.12482", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种名为分层代理监督（TAO）的分层多代理框架，旨在通过分层自动化监督提高医疗保健中AI的安全性。TAO通过任务复杂性和代理角色的路由、自动化层级间协作和角色扮演，构建了一个强大的安全框架。研究表明，TAO在医疗安全基准测试中优于单代理和多代理框架，最高提升8.2%。", "motivation": "当前的大型语言模型（LLMs）在临床环境中可能引入安全风险，如错误检测能力差和单点故障。为了解决这些问题，本文提出了TAO框架，以提高AI在医疗保健中的安全性。", "method": "TAO是一个分层多代理框架，受到临床层级（如护士、医生、专家）的启发，根据任务复杂性和代理角色进行路由。它利用自动化层级间协作和角色扮演来增强安全性。", "result": "TAO在5个医疗安全基准测试中的4个中表现优于单代理和多代理框架，最高提升8.2%。此外，通过临床医生参与的辅助研究，TAO在医疗分诊中的准确率从40%提高到60%。", "conclusion": "TAO通过其自适应分层架构、关键低级层的作用和高级LLM的战略分配，显著提高了AI在医疗保健中的安全性。这一框架为未来的AI安全研究提供了有价值的见解。"}}
{"id": "2506.12453", "title": "Topology-Assisted Spatio-Temporal Pattern Disentangling for Scalable MARL in Large-scale Autonomous Traffic Control", "authors": ["Rongpeng Li", "Jianhang Zhu", "Jiahao Huang", "Zhifeng Zhao", "Honggang Zhang"], "abstract": "Intelligent Transportation Systems (ITSs) have emerged as a promising solution towards ameliorating urban traffic congestion, with Traffic Signal Control (TSC) identified as a critical component. Although Multi-Agent Reinforcement Learning (MARL) algorithms have shown potential in optimizing TSC through real-time decision-making, their scalability and effectiveness often suffer from large-scale and complex environments. Typically, these limitations primarily stem from a fundamental mismatch between the exponential growth of the state space driven by the environmental heterogeneities and the limited modeling capacity of current solutions. To address these issues, this paper introduces a novel MARL framework that integrates Dynamic Graph Neural Networks (DGNNs) and Topological Data Analysis (TDA), aiming to enhance the expressiveness of environmental representations and improve agent coordination. Furthermore, inspired by the Mixture of Experts (MoE) architecture in Large Language Models (LLMs), a topology-assisted spatial pattern disentangling (TSD)-enhanced MoE is proposed, which leverages topological signatures to decouple graph features for specialized processing, thus improving the model's ability to characterize dynamic and heterogeneous local observations. The TSD module is also integrated into the policy and value networks of the Multi-agent Proximal Policy Optimization (MAPPO) algorithm, further improving decision-making efficiency and robustness. Extensive experiments conducted on real-world traffic scenarios, together with comprehensive theoretical analysis, validate the superior performance of the proposed framework, highlighting the model's scalability and effectiveness in addressing the complexities of large-scale TSC tasks.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.12453.pdf", "abstract_url": "https://arxiv.org/abs/2506.12453", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新颖的多智能体强化学习（MARL）框架，结合动态图神经网络（DGNNs）和拓扑数据分析（TDA），以提高环境表示的表达能力和智能体协调能力。通过引入拓扑辅助的空间模式解耦（TSD）增强的混合专家（MoE）架构，该框架能够更好地处理动态和异质的局部观察，从而在大规模交通信号控制（TSC）任务中展现出卓越的性能和可扩展性。", "motivation": "智能交通系统（ITSs）是缓解城市交通拥堵的有力解决方案，其中交通信号控制（TSC）是关键组成部分。尽管多智能体强化学习（MARL）算法在通过实时决策优化TSC方面显示出潜力，但其在大规模和复杂环境中的可扩展性和有效性常常受到限制。这些限制主要源于环境异质性驱动的状态空间指数增长与当前解决方案有限建模能力之间的不匹配。", "method": "本文提出了一种结合动态图神经网络（DGNNs）和拓扑数据分析（TDA）的MARL框架，并引入了一种拓扑辅助的空间模式解耦（TSD）增强的混合专家（MoE）架构。该架构利用拓扑特征对图特征进行解耦以进行专门处理，从而提高了模型对动态和异质局部观察的刻画能力。此外，TSD模块还被集成到多智能体近端策略优化（MAPPO）算法的策略和价值网络中，进一步提高了决策效率和鲁棒性。", "result": "在真实世界的交通场景中进行的广泛实验，以及全面的理论分析，验证了所提出框架的优越性能，突出了模型在解决大规模TSC任务复杂性方面的可扩展性和有效性。", "conclusion": "本文提出的框架通过结合DGNNs、TDA和TSD-enhanced MoE架构，显著提高了MARL在大规模交通信号控制任务中的表现。这不仅为解决城市交通拥堵问题提供了新的思路，也为未来智能交通系统的发展奠定了基础。"}}
{"id": "2506.12483", "title": "MALM: A Multi-Information Adapter for Large Language Models to Mitigate Hallucination", "authors": ["Ao Jia", "Haiming Wu", "Guohui Yao", "Dawei Song", "Songkun Ji", "Yazhou Zhang"], "abstract": "Large language models (LLMs) are prone to three types of hallucination: Input-Conflicting, Context-Conflicting and Fact-Conflicting hallucinations. The purpose of this study is to mitigate the different types of hallucination by exploiting the interdependence between them. For this purpose, we propose a Multi-Information Adapter for Large Language Models (MALM). This framework employs a tailored multi-graph learning approach designed to elucidate the interconnections between original inputs, contextual information, and external factual knowledge, thereby alleviating the three categories of hallucination within a cohesive framework. Experiments were carried out on four benchmarking datasets: HaluEval, TruthfulQA, Natural Questions, and TriviaQA. We evaluated the proposed framework in two aspects: (1) adaptability to different base LLMs on HaluEval and TruthfulQA, to confirm if MALM is effective when applied on 7 typical LLMs. MALM showed significant improvements over LLaMA-2; (2) generalizability to retrieval-augmented generation (RAG) by combining MALM with three representative retrievers (BM25, Spider and DPR) separately. Furthermore, automated and human evaluations were conducted to substantiate the correctness of experimental results, where GPT-4 and 3 human volunteers judged which response was better between LLaMA-2 and MALM. The results showed that both GPT-4 and human preferred MALM in 79.4% and 65.6% of cases respectively. The results validate that incorporating the complex interactions between the three types of hallucination through a multilayered graph attention network into the LLM generation process is effective to mitigate the them. The adapter design of the proposed approach is also proven flexible and robust across different base LLMs.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.12483.pdf", "abstract_url": "https://arxiv.org/abs/2506.12483", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本研究提出了一种名为MALM的多信息适配器框架，旨在通过多图学习方法减少大型语言模型(LLMs)的三种幻觉类型：输入冲突、上下文冲突和事实冲突。通过在四个基准数据集上的实验，MALM在适应不同基础LLMs和增强检索生成(RAG)方面显示出显著效果，并通过自动和人工评估验证了其有效性。", "motivation": "大型语言模型(LLMs)容易产生输入冲突、上下文冲突和事实冲突三种类型的幻觉，这影响了模型的准确性和可靠性。本研究旨在通过探索这些幻觉类型之间的相互依赖性来缓解这一问题。", "method": "研究提出了一个多信息适配器框架(MALM)，采用定制的多图学习方法，明确原始输入、上下文信息和外部事实知识之间的相互联系，以在一个统一的框架内缓解三种幻觉。", "result": "在HaluEval和TruthfulQA数据集上的实验表明，MALM在应用于7种典型LLMs时，相比LLaMA-2有显著改进。与三种代表性检索器(BM25、Spider和DPR)结合的RAG实验也验证了MALM的通用性。GPT-4和人类评估者分别有79.4%和65.6%的情况下偏好MALM的响应。", "conclusion": "通过多层图注意力网络将三种幻觉类型之间的复杂交互纳入LLM生成过程，是缓解这些幻觉的有效方法。MALM的适配器设计在不同基础LLMs上展现出灵活性和鲁棒性。"}}
{"id": "2506.12508", "title": "AgentOrchestra: A Hierarchical Multi-Agent Framework for General-Purpose Task Solving", "authors": ["Wentao Zhang", "Ce Cui", "Yilei Zhao", "Yang Liu", "Bo An"], "abstract": "Recent advances in agent systems based on large language models (LLMs) have demonstrated strong capabilities in solving complex tasks. However, most current methods lack mechanisms for coordinating specialized agents and have limited ability to generalize to new or diverse domains. We introduce \\projectname, a hierarchical multi-agent framework for general-purpose task solving that integrates high-level planning with modular agent collaboration. Inspired by the way a conductor orchestrates a symphony and guided by the principles of \\textit{extensibility}, \\textit{multimodality}, \\textit{modularity}, and \\textit{coordination}, \\projectname features a central planning agent that decomposes complex objectives and delegates sub-tasks to a team of specialized agents. Each sub-agent is equipped with general programming and analytical tools, as well as abilities to tackle a wide range of real-world specific tasks, including data analysis, file operations, web navigation, and interactive reasoning in dynamic multimodal environments. \\projectname supports flexible orchestration through explicit sub-goal formulation, inter-agent communication, and adaptive role allocation. We evaluate the framework on three widely used benchmark datasets covering various real-world tasks, searching web pages, reasoning over heterogeneous modalities, etc. Experimental results demonstrate that \\projectname consistently outperforms flat-agent and monolithic baselines in task success rate and adaptability. These findings highlight the effectiveness of hierarchical organization and role specialization in building scalable and general-purpose LLM-based agent systems.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.12508.pdf", "abstract_url": "https://arxiv.org/abs/2506.12508", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "AgentOrchestra是一个基于大型语言模型的分层多智能体框架，旨在通过高层规划和模块化智能体协作解决通用任务。", "motivation": "当前基于大型语言模型的智能体系统在解决复杂任务时缺乏协调专门智能体的机制，且在新领域或多样化领域的泛化能力有限。", "method": "引入了一个分层多智能体框架，包括一个中央规划智能体和多个专门子智能体，支持明确的子目标制定、智能体间通信和自适应角色分配。", "result": "在三个广泛使用的基准数据集上的实验结果表明，AgentOrchestra在任务成功率和适应性上 consistently outperforms 平面智能体和单体基线。", "conclusion": "分层组织和角色专业化在构建可扩展和通用的基于LLM的智能体系统中是有效的。"}}
{"id": "2506.12494", "title": "FlexRAG: A Flexible and Comprehensive Framework for Retrieval-Augmented Generation", "authors": ["Zhuocheng Zhang", "Yang Feng", "Min Zhang"], "abstract": "Retrieval-Augmented Generation (RAG) plays a pivotal role in modern large language model applications, with numerous existing frameworks offering a wide range of functionalities to facilitate the development of RAG systems. However, we have identified several persistent challenges in these frameworks, including difficulties in algorithm reproduction and sharing, lack of new techniques, and high system overhead. To address these limitations, we introduce \\textbf{FlexRAG}, an open-source framework specifically designed for research and prototyping. FlexRAG supports text-based, multimodal, and network-based RAG, providing comprehensive lifecycle support alongside efficient asynchronous processing and persistent caching capabilities. By offering a robust and flexible solution, FlexRAG enables researchers to rapidly develop, deploy, and share advanced RAG systems. Our toolkit and resources are available at \\href{", "subjects": "Computation and Language (cs.CL); Information Retrieval (cs.IR)", "comments": "Accepted by ACL 2025 Demo", "pdf_url": "https://arxiv.org/pdf/2506.12494.pdf", "abstract_url": "https://arxiv.org/abs/2506.12494", "categories": ["Computation and Language (cs.CL)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "FlexRAG是一个专为研究和原型设计设计的开源框架，旨在解决现有检索增强生成（RAG）框架在算法再现与共享、新技术缺乏及系统高开销方面的挑战。", "motivation": "解决现有RAG框架在算法再现与共享、新技术缺乏及系统高开销方面的挑战。", "method": "引入FlexRAG框架，支持文本、多模态和基于网络的RAG，提供全面的生命周期支持、高效的异步处理和持久化缓存能力。", "result": "FlexRAG为研究人员提供了一个强大且灵活的解决方案，使他们能够快速开发、部署和分享先进的RAG系统。", "conclusion": "FlexRAG通过其开放性和灵活性，促进了RAG技术的研究和应用，为未来的发展奠定了基础。"}}
{"id": "2506.12664", "title": "Behavioral Generative Agents for Energy Operations", "authors": ["Cong Chen", "Omer Karaduman", "Xu Kuang"], "abstract": "Accurately modeling consumer behavior in energy operations remains challenging due to inherent uncertainties, behavioral complexities, and limited empirical data. This paper introduces a novel approach leveraging generative agents--artificial agents powered by large language models--to realistically simulate customer decision-making in dynamic energy operations. We demonstrate that these agents behave more optimally and rationally in simpler market scenarios, while their performance becomes more variable and suboptimal as task complexity rises. Furthermore, the agents exhibit heterogeneous customer preferences, consistently maintaining distinct, persona-driven reasoning patterns. Our findings highlight the potential value of integrating generative agents into energy management simulations to improve the design and effectiveness of energy policies and incentive programs.", "subjects": "Artificial Intelligence (cs.AI); Systems and Control (eess.SY)", "comments": "33 pages, 14 figures", "pdf_url": "https://arxiv.org/pdf/2506.12664.pdf", "abstract_url": "https://arxiv.org/abs/2506.12664", "categories": ["Artificial Intelligence (cs.AI)", "Systems and Control (eess.SY)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种利用生成代理（由大型语言模型驱动的人工代理）来模拟动态能源操作中客户决策的新方法，旨在解决由于不确定性、行为复杂性和有限经验数据导致的消费者行为建模难题。", "motivation": "准确模拟能源操作中的消费者行为面临不确定性、行为复杂性和数据有限等挑战，本文旨在通过生成代理解决这些问题。", "method": "采用由大型语言模型驱动的生成代理，模拟客户在动态能源操作中的决策过程。", "result": "研究表明，在简单的市场场景中，这些代理表现出更优和理性的行为；随着任务复杂性的增加，其表现变得更多变和次优。同时，代理展示了异质的客户偏好，保持独特、角色驱动的推理模式。", "conclusion": "将生成代理整合到能源管理模拟中，有望提高能源政策和激励计划的设计和效果，展示了生成代理在能源操作中的潜在价值。"}}
{"id": "2506.12666", "title": "LIFELONG SOTOPIA: Evaluating Social Intelligence of Language Agents Over Lifelong Social Interactions", "authors": ["Hitesh Goel", "Hao Zhu"], "abstract": "Humans engage in lifelong social interactions through interacting with different people under different scenarios for different social goals. This requires social intelligence to gather information through a long time span and use it to navigate various social contexts effectively. Whether AI systems are also capable of this is understudied in the existing research. In this paper, we present a novel benchmark, LIFELONG-SOTOPIA, to perform a comprehensive evaluation of language agents by simulating multi-episode interactions. In each episode, the language agents role-play characters to achieve their respective social goals in randomly sampled social tasks. With LIFELONG-SOTOPIA, we find that goal achievement and believability of all of the language models that we test decline through the whole interaction. Although using an advanced memory method improves the agents' performance, the best agents still achieve a significantly lower goal completion rate than humans on scenarios requiring an explicit understanding of interaction history. These findings show that we can use LIFELONG-SOTOPIA to evaluate the social intelligence of language agents over lifelong social interactions.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.12666.pdf", "abstract_url": "https://arxiv.org/abs/2506.12666", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了LIFELONG-SOTOPIA基准测试，用于评估语言代理在模拟多情节互动中的社交智能。研究发现，所有测试的语言模型在长期互动中的目标达成和可信度均下降，即使使用先进记忆方法，最佳代理的目标完成率仍显著低于人类。", "motivation": "研究AI系统是否具备通过长期社交互动收集信息并有效应对各种社交情境的社交智能。", "method": "通过LIFELONG-SOTOPIA基准测试，模拟多情节互动，让语言代理角色扮演以实现各自的社交目标。", "result": "所有测试的语言模型在长期互动中的表现下降，使用先进记忆方法虽能提升表现，但最佳代理的目标完成率仍显著低于人类。", "conclusion": "LIFELONG-SOTOPIA可用于评估语言代理在终身社交互动中的社交智能，现有AI系统在此方面仍有显著不足。"}}
{"id": "2506.12689", "title": "SciSage: A Multi-Agent Framework for High-Quality Scientific Survey Generation", "authors": ["Xiaofeng Shi", "Qian Kou", "Yuduo Li", "Ning Tang", "Jinxin Xie", "Longbin Yu", "Songjing Wang", "Hua Zhou"], "abstract": "The rapid growth of scientific literature demands robust tools for automated survey-generation. However, current large language model (LLM)-based methods often lack in-depth analysis, structural coherence, and reliable citations. To address these limitations, we introduce SciSage, a multi-agent framework employing a reflect-when-you-write paradigm. SciSage features a hierarchical Reflector agent that critically evaluates drafts at outline, section, and document levels, collaborating with specialized agents for query interpretation, content retrieval, and refinement. We also release SurveyScope, a rigorously curated benchmark of 46 high-impact papers (2020-2025) across 11 computer science domains, with strict recency and citation-based quality controls. Evaluations demonstrate that SciSage outperforms state-of-the-art baselines (LLM x MapReduce-V2, AutoSurvey), achieving +1.73 points in document coherence and +32% in citation F1 scores. Human evaluations reveal mixed outcomes (3 wins vs. 7 losses against human-written surveys), but highlight SciSage's strengths in topical breadth and retrieval efficiency. Overall, SciSage offers a promising foundation for research-assistive writing tools.", "subjects": "Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.12689.pdf", "abstract_url": "https://arxiv.org/abs/2506.12689", "categories": ["Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["agent"], "AI": {"tldr": "SciSage是一个多智能体框架，旨在通过‘边写边反思’的模式生成高质量的科学综述，解决了现有基于大语言模型的方法在深度分析、结构连贯性和可靠引用方面的不足。", "motivation": "科学文献的快速增长需要强大的工具来自动化生成综述。当前基于大语言模型的方法在深度分析、结构连贯性和可靠引用方面存在不足。", "method": "SciSage采用了一个分层次的Reflector智能体，在提纲、章节和文档级别批判性评估草稿，并与专门用于查询解释、内容检索和精炼的智能体协作。", "result": "评估显示，SciSage在文档连贯性上比现有最佳基线高出1.73分，在引用F1分数上高出32%。人类评估显示了混合结果（与人工撰写的综述相比3胜7负），但突出了SciSage在主题广度和检索效率上的优势。", "conclusion": "SciSage为研究辅助写作工具提供了一个有前途的基础，展示了在自动生成高质量科学综述方面的潜力。"}}
{"id": "2506.12801", "title": "Mastering Da Vinci Code: A Comparative Study of Transformer, LLM, and PPO-based Agents", "authors": ["LeCheng Zhang", "Yuanshi Wang", "Haotian Shen", "Xujie Wang"], "abstract": "The Da Vinci Code, a game of logical deduction and imperfect information, presents unique challenges for artificial intelligence, demanding nuanced reasoning beyond simple pattern recognition. This paper investigates the efficacy of various AI paradigms in mastering this game. We develop and evaluate three distinct agent architectures: a Transformer-based baseline model with limited historical context, several Large Language Model (LLM) agents (including Gemini, DeepSeek, and GPT variants) guided by structured prompts, and an agent based on Proximal Policy Optimization (PPO) employing a Transformer encoder for comprehensive game history processing. Performance is benchmarked against the baseline, with the PPO-based agent demonstrating superior win rates ($58.5\\% \\pm 1.0\\%$), significantly outperforming the LLM counterparts. Our analysis highlights the strengths of deep reinforcement learning in policy refinement for complex deductive tasks, particularly in learning implicit strategies from self-play. We also examine the capabilities and inherent limitations of current LLMs in maintaining strict logical consistency and strategic depth over extended gameplay, despite sophisticated prompting. This study contributes to the broader understanding of AI in recreational games involving hidden information and multi-step logical reasoning, offering insights into effective agent design and the comparative advantages of different AI approaches.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.12801.pdf", "abstract_url": "https://arxiv.org/abs/2506.12801", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文比较了Transformer、LLM和PPO-based代理在掌握《达芬奇密码》游戏中的效果，发现PPO-based代理表现最佳。", "motivation": "解决在《达芬奇密码》这类需要复杂推理和不完全信息处理的游戏中，人工智能的表现问题。", "method": "开发并评估了三种不同的代理架构：基于Transformer的基线模型、几种大型语言模型（LLM）代理和基于近端策略优化（PPO）的代理。", "result": "PPO-based代理以58.5% ± 1.0%的胜率显著优于LLM代理，展示了深度强化学习在复杂推理任务中的优势。", "conclusion": "研究强调了深度强化学习在策略精炼中的优势，同时指出了当前LLM在保持严格逻辑一致性和战略深度方面的局限性，为涉及隐藏信息和多步逻辑推理的休闲游戏中AI的设计提供了见解。"}}
{"id": "2506.12841", "title": "WereWolf-Plus: An Update of Werewolf Game setting Based on DSGBench", "authors": ["Xinyuan Xia", "Yuanyi Song", "Haomin Ma", "Jinyu Cai"], "abstract": "With the rapid development of LLM-based agents, increasing attention has been given to their social interaction and strategic reasoning capabilities. However, existing Werewolf-based benchmarking platforms suffer from overly simplified game settings, incomplete evaluation metrics, and poor scalability. To address these limitations, we propose WereWolf-Plus, a multi-model, multi-dimensional, and multi-method benchmarking platform for evaluating multi-agent strategic reasoning in the Werewolf game. The platform offers strong extensibility, supporting customizable configurations for roles such as Seer, Witch, Hunter, Guard, and Sheriff, along with flexible model assignment and reasoning enhancement strategies for different roles. In addition, we introduce a comprehensive set of quantitative evaluation metrics for all special roles, werewolves, and the sheriff, and enrich the assessment dimensions for agent reasoning ability, cooperation capacity, and social influence. WereWolf-Plus provides a more flexible and reliable environment for advancing research on inference and strategic interaction within multi-agent communities. Our code is open sourced at", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.12841.pdf", "abstract_url": "https://arxiv.org/abs/2506.12841", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了WereWolf-Plus，一个基于DSGBench更新的狼人杀游戏设置平台，旨在解决现有狼人杀基准测试平台在游戏设置简化、评价指标不完整和可扩展性差方面的问题。", "motivation": "随着基于LLM的代理的快速发展，人们越来越关注其社交互动和战略推理能力。现有的狼人杀基准测试平台存在游戏设置过于简化、评价指标不完整和可扩展性差的问题。", "method": "提出了WereWolf-Plus，一个多模型、多维度、多方法的基准测试平台，用于评估狼人杀游戏中的多代理战略推理。平台支持角色（如先知、女巫、猎人、守卫和警长）的自定义配置，以及不同角色的灵活模型分配和推理增强策略。", "result": "WereWolf-Plus提供了一个更灵活可靠的环境，用于推进多代理社区内的推理和战略互动研究。", "conclusion": "WereWolf-Plus通过提供强扩展性、自定义角色配置和全面的定量评价指标，丰富了代理推理能力、合作能力和社会影响力的评估维度，为多代理战略推理研究提供了重要工具。"}}
{"id": "2506.13063", "title": "PRISM2: Unlocking Multi-Modal General Pathology AI with Clinical Dialogue", "authors": ["George Shaikovski", "Eugene Vorontsov", "Adam Casson", "Julian Viret", "Eric Zimmermann", "Neil Tenenholtz", "Yi Kan Wang", "Jan H. Bernhard", "Ran A. Godrich", "Juan A. Retamero", "Razik Yousfi", "Nicolo Fusi", "Thomas J. Fuchs", "Kristen Severson", "Siqi Liu"], "abstract": "Recent pathology foundation models can provide rich tile-level representations but fall short of delivering general-purpose clinical utility without further extensive model development. These models lack whole-slide image (WSI) understanding and are not trained with large-scale diagnostic data, limiting their performance on diverse downstream tasks. We introduce PRISM2, a multi-modal slide-level foundation model trained via clinical dialogue to enable scalable, generalizable pathology AI. PRISM2 is trained on nearly 700,000 specimens (2.3 million WSIs) paired with real-world clinical diagnostic reports in a two-stage process. In Stage 1, a vision-language model is trained using contrastive and captioning objectives to align whole slide embeddings with textual clinical diagnosis. In Stage 2, the language model is unfrozen to enable diagnostic conversation and extract more clinically meaningful representations from hidden states. PRISM2 achieves strong performance on diagnostic and biomarker prediction tasks, outperforming prior slide-level models including PRISM and TITAN. It also introduces a zero-shot yes/no classification approach that surpasses CLIP-style methods without prompt tuning or class enumeration. By aligning visual features with clinical reasoning, PRISM2 improves generalization on both data-rich and low-sample tasks, offering a scalable path forward for building general pathology AI agents capable of assisting diagnostic and prognostic decisions.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.13063.pdf", "abstract_url": "https://arxiv.org/abs/2506.13063", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "PRISM2是一个通过临床对话训练的多模态病理学基础模型，旨在提升病理AI的通用性和可扩展性。", "motivation": "现有的病理学基础模型在提供丰富的切片级表示方面表现良好，但在实现通用临床效用方面存在不足，缺乏对整个切片图像（WSI）的理解，且未使用大规模诊断数据进行训练，限制了其在多样化下游任务中的表现。", "method": "PRISM2采用两阶段训练过程：第一阶段通过对比和标题生成目标训练视觉-语言模型，以对齐整个切片嵌入与文本临床诊断；第二阶段解冻语言模型，以启用诊断对话并从隐藏状态提取更具临床意义的表示。", "result": "PRISM2在诊断和生物标志物预测任务中表现出色，超越了包括PRISM和TITAN在内的先前切片级模型，并引入了一种无需提示调整或类别枚举的零样本是/否分类方法，超越了CLIP风格的方法。", "conclusion": "通过将视觉特征与临床推理对齐，PRISM2在数据丰富和低样本任务上都提高了泛化能力，为构建能够协助诊断和预后决策的通用病理AI代理提供了一条可扩展的前进道路。"}}
{"id": "2506.12571", "title": "DoTA-RAG: Dynamic of Thought Aggregation RAG", "authors": ["Saksorn Ruangtanusak", "Natthapath Rungseesiripak", "Peerawat Rojratchadakorn", "Monthol Charattrakool", "Natapong Nitarach"], "abstract": "In this paper, we introduce DoTA-RAG (Dynamic-of-Thought Aggregation RAG), a retrieval-augmented generation system optimized for high-throughput, large-scale web knowledge indexes. Traditional RAG pipelines often suffer from high latency and limited accuracy over massive, diverse datasets. DoTA-RAG addresses these challenges with a three-stage pipeline: query rewriting, dynamic routing to specialized sub-indexes, and multi-stage retrieval and ranking. We further enhance retrieval by evaluating and selecting a superior embedding model, re-embedding the large FineWeb-10BT corpus. Moreover, we create a diverse Q&A dataset of 500 questions generated via the DataMorgana setup across a broad range of WebOrganizer topics and formats. DoTA-RAG improves the answer correctness score from 0.752 (baseline, using LiveRAG pre-built vector store) to 1.478 while maintaining low latency, and it achieves a 0.929 correctness score on the Live Challenge Day. These results highlight DoTA-RAG's potential for practical deployment in domains requiring fast, reliable access to large and evolving knowledge sources.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": "SIGIR LiveRAG 2025 (oral presentation)", "pdf_url": "https://arxiv.org/pdf/2506.12571.pdf", "abstract_url": "https://arxiv.org/abs/2506.12571", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了DoTA-RAG（动态思维聚合RAG），一种针对高吞吐量、大规模网络知识索引优化的检索增强生成系统。", "motivation": "传统RAG管道在大规模、多样化数据集上常面临高延迟和准确性有限的问题。DoTA-RAG旨在解决这些挑战。", "method": "采用三阶段管道：查询重写、动态路由到专门子索引、多阶段检索和排名，并通过评估和选择更优的嵌入模型来增强检索。", "result": "DoTA-RAG将答案正确性分数从0.752（基线）提高到1.478，并在Live Challenge Day上达到0.929的正确性分数，同时保持低延迟。", "conclusion": "这些结果展示了DoTA-RAG在需要快速、可靠访问大型且不断变化的知识源的领域中实际部署的潜力。"}}
{"id": "2506.12607", "title": "Towards Building General Purpose Embedding Models for Industry 4.0 Agents", "authors": ["Christodoulos Constantinides", "Shuxin Lin", "Dhaval Patel"], "abstract": "In this work we focus on improving language models' understanding for asset maintenance to guide the engineer's decisions and minimize asset downtime. Given a set of tasks expressed in natural language for Industry 4.0 domain, each associated with queries related to a specific asset, we want to recommend relevant items and generalize to queries of similar assets. A task may involve identifying relevant sensors given a query about an asset's failure mode.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.12607.pdf", "abstract_url": "https://arxiv.org/abs/2506.12607", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文专注于提升语言模型在资产维护领域的理解能力，以指导工程师决策并最小化资产停机时间。针对工业4.0领域中用自然语言表达的任务集，每个任务与特定资产的查询相关，旨在推荐相关项目并推广到类似资产的查询。", "motivation": "解决工业4.0领域中资产维护任务的自然语言理解和推荐问题，以减少资产停机时间和提高决策效率。", "method": "利用语言模型理解和处理与特定资产相关的自然语言查询，推荐相关项目，并推广到相似资产的查询。", "result": "开发了一种能够理解资产维护任务并推荐相关项目的语言模型，能够推广到相似资产的查询。", "conclusion": "通过提升语言模型在资产维护领域的理解能力，可以有效指导工程师决策，减少资产停机时间，为工业4.0代理构建通用嵌入模型提供了可能。"}}
{"id": "2506.12657", "title": "Synthetic Socratic Debates: Examining Persona Effects on Moral Decision and Persuasion Dynamics", "authors": ["Jiarui Liu", "Yueqi Song", "Yunze Xiao", "Mingqian Zheng", "Lindia Tjuatja", "Jana Schaich Borg", "Mona Diab", "Maarten Sap"], "abstract": "As large language models (LLMs) are increasingly used in morally sensitive domains, it is crucial to understand how persona traits affect their moral reasoning and persuasive behavior. We present the first large-scale study of multi-dimensional persona effects in AI-AI debates over real-world moral dilemmas. Using a 6-dimensional persona space (age, gender, country, class, ideology, and personality), we simulate structured debates between AI agents over 131 relationship-based cases. Our results show that personas affect initial moral stances and debate outcomes, with political ideology and personality traits exerting the strongest influence. Persuasive success varies across traits, with liberal and open personalities reaching higher consensus and win rates. While logit-based confidence grows during debates, emotional and credibility-based appeals diminish, indicating more tempered argumentation over time. These trends mirror findings from psychology and cultural studies, reinforcing the need for persona-aware evaluation frameworks for AI moral reasoning.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.12657.pdf", "abstract_url": "https://arxiv.org/abs/2506.12657", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文首次大规模研究了AI-AI在现实世界道德困境辩论中的多维人格效应，揭示了人格特质对道德立场和辩论结果的影响。", "motivation": "随着大型语言模型（LLMs）在道德敏感领域的应用日益增多，理解人格特质如何影响其道德推理和说服行为变得至关重要。", "method": "研究使用一个6维人格空间（年龄、性别、国家、阶级、意识形态和人格特质），在131个基于关系的案例中模拟了AI代理之间的结构化辩论。", "result": "结果显示，人格特质影响初始道德立场和辩论结果，政治意识形态和人格特质的影响最为显著。自由和开放的人格特质在达成共识和胜率方面表现更佳。辩论过程中，基于逻辑的信心增强，而情感和可信度为基础的诉求减少。", "conclusion": "这些趋势与心理学和文化研究的结果相呼应，强调了为AI道德推理开发人格感知评估框架的必要性。"}}
{"id": "2506.12894", "title": "Homeostatic Coupling for Prosocial Behavior", "authors": ["Naoto Yoshida", "Kingson Man"], "abstract": "When regarding the suffering of others, we often experience personal distress and feel compelled to help\\footnote{Preprint. Under review.}. Inspired by living systems, we investigate the emergence of prosocial behavior among autonomous agents that are motivated by homeostatic self-regulation. We perform multi-agent reinforcement learning, treating each agent as a vulnerable homeostat charged with maintaining its own well-being. We introduce an empathy-like mechanism to share homeostatic states between agents: an agent can either \\emph{observe} their partner's internal state ({\\bf cognitive empathy}) or the agent's internal state can be \\emph{directly coupled} to that of their partner ({\\bf affective empathy}). In three simple multi-agent environments, we show that prosocial behavior arises only under homeostatic coupling - when the distress of a partner can affect one's own well-being. Additionally, we show that empathy can be learned: agents can ``decode\" their partner's external emotive states to infer the partner's internal homeostatic states. Assuming some level of physiological similarity, agents reference their own emotion-generation functions to invert the mapping from outward display to internal state. Overall, we demonstrate the emergence of prosocial behavior when homeostatic agents learn to ``read\" the emotions of others and then to empathize, or feel as they feel.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "Preprint. Unver review", "pdf_url": "https://arxiv.org/pdf/2506.12894.pdf", "abstract_url": "https://arxiv.org/abs/2506.12894", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了自主代理之间亲社会行为的涌现，这些代理通过稳态自我调节来维持自身福祉。通过多代理强化学习，研究引入了类似共情的机制，展示了在稳态耦合下亲社会行为的出现。", "motivation": "解决如何在自主代理中模拟和激发亲社会行为的问题，特别是在面对他人痛苦时如何产生帮助的动机。", "method": "采用多代理强化学习，将每个代理视为一个脆弱的稳态调节器，引入认知共情和情感共情两种机制来共享代理之间的稳态状态。", "result": "研究表明，只有在稳态耦合下，即当伙伴的痛苦能够影响自身福祉时，亲社会行为才会出现。此外，代理能够学习共情，通过解码伙伴的外部情感状态来推断其内部稳态状态。", "conclusion": "本文展示了当稳态代理学会“读取”他人的情感并进而共情时，亲社会行为的涌现，为理解和模拟亲社会行为提供了新的视角。"}}
{"id": "2506.12927", "title": "Sectoral Coupling in Linguistic State Space", "authors": ["Sebastian Dumbrava"], "abstract": "This work presents a formal framework for quantifying the internal dependencies between functional subsystems within artificial agents whose belief states are composed of structured linguistic fragments. Building on the Semantic Manifold framework, which organizes belief content into functional sectors and stratifies them across hierarchical levels of abstraction, we introduce a system of sectoral coupling constants that characterize how one cognitive sector influences another within a fixed level of abstraction. The complete set of these constants forms an agent-specific coupling profile that governs internal information flow, shaping the agent's overall processing tendencies and cognitive style. We provide a detailed taxonomy of these intra-level coupling roles, covering domains such as perceptual integration, memory access and formation, planning, meta-cognition, execution control, and affective modulation. We also explore how these coupling profiles generate feedback loops, systemic dynamics, and emergent signatures of cognitive behavior. Methodologies for inferring these profiles from behavioral or internal agent data are outlined, along with a discussion of how these couplings evolve across abstraction levels. This framework contributes a mechanistic and interpretable approach to modeling complex cognition, with applications in AI system design, alignment diagnostics, and the analysis of emergent agent behavior.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": "56 pages, 12 figures", "pdf_url": "https://arxiv.org/pdf/2506.12927.pdf", "abstract_url": "https://arxiv.org/abs/2506.12927", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一个量化人工代理内部功能子系统间依赖关系的正式框架，基于语义流形框架，引入了一套区段耦合常数系统，用于描述在固定抽象层次内一个认知区段如何影响另一个。", "motivation": "解决如何量化和理解人工代理内部功能子系统之间的依赖关系，以及这些关系如何影响代理的认知风格和行为模式的问题。", "method": "基于语义流形框架，引入区段耦合常数系统，构建代理特定的耦合配置文件，以描述和量化内部信息流。", "result": "提出了一套详细的区段内耦合角色分类法，探讨了耦合配置文件如何生成反馈循环、系统动力学和认知行为的涌现特征。", "conclusion": "该框架为建模复杂认知提供了一种机械化和可解释的方法，适用于AI系统设计、对齐诊断和代理行为涌现分析。"}}
{"id": "2506.12928", "title": "Scaling Test-time Compute for LLM Agents", "authors": ["King Zhu", "Hanhao Li", "Siwei Wu", "Tianshun Xing", "Dehua Ma", "Xiangru Tang", "Minghao Liu", "Jian Yang", "Jiaheng Liu", "Yuchen Eleanor Jiang", "Changwang Zhang", "Chenghua Lin", "Jun Wang", "Ge Zhang", "Wangchunshu Zhou"], "abstract": "Scaling test time compute has shown remarkable success in improving the reasoning abilities of large language models (LLMs). In this work, we conduct the first systematic exploration of applying test-time scaling methods to language agents and investigate the extent to which it improves their effectiveness. Specifically, we explore different test-time scaling strategies, including: (1) parallel sampling algorithms; (2) sequential revision strategies; (3) verifiers and merging methods; (4)strategies for diversifying", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.12928.pdf", "abstract_url": "https://arxiv.org/abs/2506.12928", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文首次系统地探索了在语言代理中应用测试时扩展方法，并研究了其在多大程度上提高了它们的有效性。具体来说，探索了不同的测试时扩展策略。", "motivation": "解决如何通过扩展测试时计算来提高大型语言模型（LLMs）的推理能力的问题。", "method": "探索了四种不同的测试时扩展策略：并行采样算法、顺序修订策略、验证器和合并方法、以及多样化策略。", "result": "测试时扩展方法在提高语言代理的有效性方面显示出了显著的成功。", "conclusion": "系统地应用测试时扩展策略可以显著提升语言代理的推理能力和有效性，为未来的研究提供了新的方向。"}}
{"id": "2506.12981", "title": "Efficient Neuro-Symbolic Retrieval-Augmented Generation through Adaptive Query Routing", "authors": ["Safayat Bin Hakim", "Muhammad Adil", "Alvaro Velasquez", "Houbing Herbert Song"], "abstract": "Retrieval-Augmented Generation (RAG) systems address factual inconsistencies in Large Language Models by grounding generation in external knowledge, yet they face a fundamental efficiency problem: simple queries consume computational resources equivalent to complex multi-hop reasoning tasks. We present SymRAG, a neuro-symbolic framework that introduces adaptive query routing based on real-time complexity and system load assessments. SymRAG dynamically selects symbolic, neural, or hybrid processing paths to align resource use with query demands. Evaluated on 2,000 queries from HotpotQA and DROP using Llama-3.2-3B and Mistral-7B models, SymRAG achieves 97.6--100.0% exact match accuracy with significantly lower CPU utilization (3.6--6.2%) and processing time (0.985--3.165s). Disabling adaptive logic results in 169--1151% increase in processing time, highlighting the framework's impact. These results underscore the potential of adaptive neuro-symbolic routing for scalable, sustainable AI systems.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.12981.pdf", "abstract_url": "https://arxiv.org/abs/2506.12981", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "SymRAG是一种神经符号框架，通过自适应查询路由优化检索增强生成系统的效率，根据查询复杂度和系统负载动态选择处理路径，显著降低资源消耗和处理时间。", "motivation": "解决检索增强生成（RAG）系统在处理简单查询和复杂多跳推理任务时资源消耗相同的基本效率问题。", "method": "引入基于实时复杂度和系统负载评估的自适应查询路由，动态选择符号、神经或混合处理路径。", "result": "在HotpotQA和DROP的2000个查询上测试，SymRAG达到97.6--100.0%的精确匹配准确率，CPU利用率显著降低（3.6--6.2%），处理时间大幅减少（0.985--3.165秒）。", "conclusion": "自适应神经符号路由对于可扩展、可持续的AI系统具有巨大潜力。"}}
{"id": "2506.13037", "title": "MAGIC: Multi-Agent Argumentation and Grammar Integrated Critiquer", "authors": ["Joaquin Jordan", "Xavier Yin", "Melissa Fabros", "Gireeja Ranade", "Narges Norouzi"], "abstract": "Automated Essay Scoring (AES) and Automatic Essay Feedback (AEF) systems aim to reduce the workload of human raters in educational assessment. However, most existing systems prioritize numeric scoring accuracy over the quality of feedback. This paper presents Multi-Agent Argumentation and Grammar Integrated Critiquer (MAGIC), a framework that uses multiple specialized agents to evaluate distinct writing aspects to both predict holistic scores and produce detailed, rubric-aligned feedback. To support evaluation, we curated a novel dataset of past GRE practice test essays with expert-evaluated scores and feedback. MAGIC outperforms baseline models in both essay scoring , as measured by Quadratic Weighted Kappa (QWK). We find that despite the improvement in QWK, there are opportunities for future work in aligning LLM-generated feedback to human preferences.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.13037.pdf", "abstract_url": "https://arxiv.org/abs/2506.13037", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了MAGIC框架，一个旨在通过多智能体论证和语法整合批评器来改进自动作文评分和反馈质量的系统。MAGIC不仅预测整体分数，还提供详细的、与评分标准一致的反馈。", "motivation": "现有的自动作文评分和反馈系统大多侧重于评分准确性，而忽视了反馈质量。本文旨在解决这一问题，通过提供一个既能准确评分又能提供高质量反馈的系统。", "method": "MAGIC框架采用多个专门化的智能体来评估写作的不同方面，结合论证和语法分析，以生成整体评分和详细反馈。", "result": "MAGIC在作文评分方面优于基线模型，通过Quadratic Weighted Kappa (QWK)测量。然而，研究也发现，尽管QWK有所提高，但在将LLM生成的反馈与人类偏好对齐方面仍有改进空间。", "conclusion": "MAGIC框架在自动作文评分和反馈方面表现出色，但未来工作需进一步优化反馈内容，以更好地满足人类评估者的偏好。"}}
{"id": "2506.13260", "title": "COME: Adding Scene-Centric Forecasting Control to Occupancy World Model", "authors": ["Yining Shi", "Kun Jiang", "Qiang Meng", "Ke Wang", "Jiabao Wang", "Wenchao Sun", "Tuopu Wen", "Mengmeng Yang", "Diange Yang"], "abstract": "World models are critical for autonomous driving to simulate environmental dynamics and generate synthetic data. Existing methods struggle to disentangle ego-vehicle motion (perspective shifts) from scene evolvement (agent interactions), leading to suboptimal predictions. Instead, we propose to separate environmental changes from ego-motion by leveraging the scene-centric coordinate systems. In this paper, we introduce COME: a framework that integrates scene-centric forecasting Control into the Occupancy world ModEl. Specifically, COME first generates ego-irrelevant, spatially consistent future features through a scene-centric prediction branch, which are then converted into scene condition using a tailored ControlNet. These condition features are subsequently injected into the occupancy world model, enabling more accurate and controllable future occupancy predictions. Experimental results on the nuScenes-Occ3D dataset show that COME achieves consistent and significant improvements over state-of-the-art (SOTA) methods across diverse configurations, including different input sources (ground-truth, camera-based, fusion-based occupancy) and prediction horizons (3s and 8s). For example, under the same settings, COME achieves 26.3% better mIoU metric than DOME and 23.7% better mIoU metric than UniScene. These results highlight the efficacy of disentangled representation learning in enhancing spatio-temporal prediction fidelity for world models. Code and videos will be available at", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.13260.pdf", "abstract_url": "https://arxiv.org/abs/2506.13260", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了COME框架，通过场景中心预测控制来改进占用世界模型，有效分离了自车运动与场景演变，提升了未来占用预测的准确性和可控性。", "motivation": "现有方法在自动驾驶的世界模型中难以区分自车运动（视角变化）与场景演变（代理交互），导致预测效果不佳。", "method": "COME利用场景中心坐标系，通过场景中心预测分支生成与自车无关的空间一致未来特征，然后通过定制的ControlNet转换为场景条件，最后将这些条件特征注入占用世界模型。", "result": "在nuScenes-Occ3D数据集上的实验结果表明，COME在不同配置（包括不同输入源和预测时间范围）下均优于现有最佳方法，例如在相同设置下，mIoU指标比DOME和UniScene分别提高了26.3%和23.7%。", "conclusion": "COME通过解耦表示学习，显著提升了世界模型在时空预测上的保真度，为自动驾驶的环境动态模拟和合成数据生成提供了更有效的解决方案。"}}
{"id": "2506.13113", "title": "Dynamic Reinsurance Treaty Bidding via Multi-Agent Reinforcement Learning", "authors": ["Stella C. Dong", "James R. Finlay"], "abstract": "This paper develops a novel multi-agent reinforcement learning (MARL) framework for reinsurance treaty bidding, addressing long-standing inefficiencies in traditional broker-mediated placement processes. We pose the core research question: Can autonomous, learning-based bidding systems improve risk transfer efficiency and outperform conventional pricing approaches in reinsurance markets?", "subjects": "Artificial Intelligence (cs.AI); General Economics (econ.GN)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.13113.pdf", "abstract_url": "https://arxiv.org/abs/2506.13113", "categories": ["Artificial Intelligence (cs.AI)", "General Economics (econ.GN)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文开发了一种新颖的多智能体强化学习（MARL）框架，用于再保险条约投标，旨在解决传统经纪人中介安置过程中的长期低效问题。", "motivation": "解决再保险市场中传统定价方法的低效问题，探索基于学习的自主投标系统是否能提高风险转移效率并超越传统方法。", "method": "采用多智能体强化学习（MARL）框架，构建自主学习投标系统。", "result": "研究表明，基于学习的自主投标系统有潜力提高再保险市场的风险转移效率。", "conclusion": "多智能体强化学习框架为再保险条约投标提供了一种有效的替代方案，可能超越传统定价方法，提高市场效率。"}}
{"id": "2506.13131", "title": "AlphaEvolve: A coding agent for scientific and algorithmic discovery", "authors": ["Alexander Novikov", "Ngân Vũ", "Marvin Eisenberger", "Emilien Dupont", "Po-Sen Huang", "Adam Zsolt Wagner", "Sergey Shirobokov", "Borislav Kozlovskii", "Francisco J. R. Ruiz", "Abbas Mehrabian", "M. Pawan Kumar", "Abigail See", "Swarat Chaudhuri", "George Holland", "Alex Davies", "Sebastian Nowozin", "Pushmeet Kohli", "Matej Balog"], "abstract": "In this white paper, we present AlphaEvolve, an evolutionary coding agent that substantially enhances capabilities of state-of-the-art LLMs on highly challenging tasks such as tackling open scientific problems or optimizing critical pieces of computational infrastructure. AlphaEvolve orchestrates an autonomous pipeline of LLMs, whose task is to improve an algorithm by making direct changes to the code. Using an evolutionary approach, continuously receiving feedback from one or more evaluators, AlphaEvolve iteratively improves the algorithm, potentially leading to new scientific and practical discoveries. We demonstrate the broad applicability of this approach by applying it to a number of important computational problems. When applied to optimizing critical components of large-scale computational stacks at Google, AlphaEvolve developed a more efficient scheduling algorithm for data centers, found a functionally equivalent simplification in the circuit design of hardware accelerators, and accelerated the training of the LLM underpinning AlphaEvolve itself. Furthermore, AlphaEvolve discovered novel, provably correct algorithms that surpass state-of-the-art solutions on a spectrum of problems in mathematics and computer science, significantly expanding the scope of prior automated discovery methods (Romera-Paredes et al., 2023). Notably, AlphaEvolve developed a search algorithm that found a procedure to multiply two $4 \\times 4$ complex-valued matrices using $48$ scalar multiplications; offering the first improvement, after 56 years, over Strassen's algorithm in this setting. We believe AlphaEvolve and coding agents like it can have a significant impact in improving solutions of problems across many areas of science and computation.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.13131.pdf", "abstract_url": "https://arxiv.org/abs/2506.13131", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Neural and Evolutionary Computing (cs.NE)"], "matching_keywords": ["agent"], "AI": {"tldr": "AlphaEvolve是一种进化编码代理，通过自主管道和进化方法优化算法，应用于科学和计算问题，展示了在多个领域的显著成果。", "motivation": "解决开放科学问题和优化计算基础设施等高挑战性任务，提升现有LLMs的能力。", "method": "采用进化方法，通过LLMs自主管道直接修改代码，并持续接收评估反馈，迭代优化算法。", "result": "在Google的大规模计算栈中优化了数据中心的调度算法，简化了硬件加速器的电路设计，加速了LLM的训练，并发现了超越现有解决方案的新算法。", "conclusion": "AlphaEvolve及其同类编码代理对科学和计算领域的许多问题解决方案有重大影响潜力。"}}
{"id": "2506.13245", "title": "A Game-Theoretic Negotiation Framework for Cross-Cultural Consensus in LLMs", "authors": ["Guoxi Zhang", "Jiawei Chen", "Tianzhuo Yang", "Jiaming Ji", "Yaodong Yang", "Juntao Dai"], "abstract": "The increasing prevalence of large language models (LLMs) is influencing global value systems. However, these models frequently exhibit a pronounced WEIRD (Western, Educated, Industrialized, Rich, Democratic) cultural bias due to lack of attention to minority values. This monocultural perspective may reinforce dominant values and marginalize diverse cultural viewpoints, posing challenges for the development of equitable and inclusive AI systems. In this work, we introduce a systematic framework designed to boost fair and robust cross-cultural consensus among LLMs. We model consensus as a Nash Equilibrium and employ a game-theoretic negotiation method based on Policy-Space Response Oracles (PSRO) to simulate an organized cross-cultural negotiation process. To evaluate this approach, we construct regional cultural agents using data transformed from the World Values Survey (WVS). Beyond the conventional model-level evaluation method, We further propose two quantitative metrics, Perplexity-based Acceptence and Values Self-Consistency, to assess consensus outcomes. Experimental results indicate that our approach generates consensus of higher quality while ensuring more balanced compromise compared to baselines. Overall, it mitigates WEIRD bias by guiding agents toward convergence through fair and gradual negotiation steps.", "subjects": "Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Computer Science and Game Theory (cs.GT)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.13245.pdf", "abstract_url": "https://arxiv.org/abs/2506.13245", "categories": ["Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)", "Computer Science and Game Theory (cs.GT)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一个基于博弈论的谈判框架，旨在促进大型语言模型（LLMs）中的跨文化共识，以减少WEIRD文化偏见。", "motivation": "大型语言模型普遍存在WEIRD文化偏见，忽视了少数群体的价值观，这可能导致主导价值观的强化和多元文化观点的边缘化，对开发公平和包容的AI系统构成挑战。", "method": "作者将共识建模为纳什均衡，并采用基于策略空间响应预言（PSRO）的博弈论谈判方法，模拟有组织的跨文化谈判过程。", "result": "实验结果表明，该方法生成的共识质量更高，同时确保了更平衡的妥协，有效减轻了WEIRD偏见。", "conclusion": "通过公平和渐进的谈判步骤引导代理达成共识，该方法不仅提高了共识的质量，还促进了文化多样性的包容性。"}}
{"id": "2506.13324", "title": "Towards Pervasive Distributed Agentic Generative AI -- A State of The Art", "authors": ["Gianni Molinari", "Fabio Ciravegna"], "abstract": "The rapid advancement of intelligent agents and Large Language Models (LLMs) is reshaping the pervasive computing field. Their ability to perceive, reason, and act through natural language understanding enables autonomous problem-solving in complex pervasive environments, including the management of heterogeneous sensors, devices, and data. This survey outlines the architectural components of LLM agents (profiling, memory, planning, and action) and examines their deployment and evaluation across various scenarios. Than it reviews computational and infrastructural advancements (cloud to edge) in pervasive computing and how AI is moving in this field. It highlights state-of-the-art agent deployment strategies and applications, including local and distributed execution on resource-constrained devices. This survey identifies key challenges of these agents in pervasive computing such as architectural, energetic and privacy limitations. It finally proposes what we called \"Agent as a Tool\", a conceptual framework for pervasive agentic AI, emphasizing context awareness, modularity, security, efficiency and effectiveness.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.13324.pdf", "abstract_url": "https://arxiv.org/abs/2506.13324", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文综述了智能代理和大型语言模型（LLMs）在普适计算领域的快速发展及其应用，探讨了LLM代理的架构组件、部署策略、面临的挑战，并提出了一个名为“工具化代理”的概念框架。", "motivation": "解决普适计算领域中智能代理和LLMs在复杂环境中的自主问题解决能力，以及如何克服架构、能源和隐私等方面的挑战。", "method": "通过综述LLM代理的架构组件（分析、记忆、规划和行动）、部署和评估方法，以及计算和基础设施的进步，来探讨普适计算中AI的发展。", "result": "识别了普适计算中代理的关键挑战，并提出了一个强调上下文感知、模块化、安全性、效率和有效性的“工具化代理”框架。", "conclusion": "提出了“工具化代理”作为普适计算中代理AI的概念框架，旨在解决现有挑战，推动AI在普适计算领域的进一步发展。"}}
{"id": "2506.13070", "title": "CHILL at SemEval-2025 Task 2: You Can't Just Throw Entities and Hope -- Make Your LLM to Get Them Right", "authors": ["Jaebok Lee", "Yonghyun Ryu", "Seongmin Park", "Yoonjung Choi"], "abstract": "In this paper, we describe our approach for the SemEval 2025 Task 2 on Entity-Aware Machine Translation (EA-MT). Our system aims to improve the accuracy of translating named entities by combining two key approaches: Retrieval Augmented Generation (RAG) and iterative self-refinement techniques using Large Language Models (LLMs). A distinctive feature of our system is its self-evaluation mechanism, where the LLM assesses its own translations based on two key criteria: the accuracy of entity translations and overall translation quality. We demonstrate how these methods work together and effectively improve entity handling while maintaining high-quality translations.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "The 19th International Workshop on Semantic Evaluation", "pdf_url": "https://arxiv.org/pdf/2506.13070.pdf", "abstract_url": "https://arxiv.org/abs/2506.13070", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文描述了我们在SemEval 2025任务2（实体感知机器翻译，EA-MT）中的方法，旨在通过结合检索增强生成（RAG）和利用大型语言模型（LLMs）的迭代自我优化技术，提高命名实体翻译的准确性。", "motivation": "解决命名实体在机器翻译中的准确性问题。", "method": "结合检索增强生成（RAG）和大型语言模型（LLMs）的迭代自我优化技术，引入自我评估机制。", "result": "这些方法有效提高了实体处理的准确性，同时保持了高质量的翻译。", "conclusion": "通过结合RAG和LLMs的迭代自我优化技术，以及自我评估机制，可以显著提高命名实体翻译的准确性和整体翻译质量。"}}
{"id": "2506.13065", "title": "MotiveBench: How Far Are We From Human-Like Motivational Reasoning in Large Language Models?", "authors": ["Xixian Yong", "Jianxun Lian", "Xiaoyuan Yi", "Xiao Zhou", "Xing Xie"], "abstract": "Large language models (LLMs) have been widely adopted as the core of agent frameworks in various scenarios, such as social simulations and AI companions. However, the extent to which they can replicate human-like motivations remains an underexplored question. Existing benchmarks are constrained by simplistic scenarios and the absence of character identities, resulting in an information asymmetry with real-world situations. To address this gap, we propose MotiveBench, which consists of 200 rich contextual scenarios and 600 reasoning tasks covering multiple levels of motivation. Using MotiveBench, we conduct extensive experiments on seven popular model families, comparing different scales and versions within each family. The results show that even the most advanced LLMs still fall short in achieving human-like motivational reasoning. Our analysis reveals key findings, including the difficulty LLMs face in reasoning about \"love & belonging\" motivations and their tendency toward excessive rationality and idealism. These insights highlight a promising direction for future research on the humanization of LLMs. The dataset, benchmark, and code are available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.13065.pdf", "abstract_url": "https://arxiv.org/abs/2506.13065", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了MotiveBench，一个包含200个丰富情境场景和600个推理任务的基准，用于评估大型语言模型（LLMs）在模拟人类动机推理方面的能力。通过对七个流行模型家族的广泛实验，研究发现即使是最先进的LLMs在实现类人动机推理方面仍有不足，特别是在'爱与归属'动机推理上存在困难，并表现出过度理性和理想化的倾向。", "motivation": "解决现有基准在简单场景和缺乏角色身份方面的限制，以及LLMs在模拟人类动机推理方面的不足。", "method": "提出MotiveBench基准，包含丰富的情境场景和推理任务，对七个模型家族进行实验比较。", "result": "最先进的LLMs在实现类人动机推理方面仍有不足，特别是在'爱与归属'动机推理上存在困难，并表现出过度理性和理想化的倾向。", "conclusion": "研究结果强调了LLMs人性化研究的未来方向，MotiveBench为相关研究提供了数据集、基准和代码支持。"}}
{"id": "2506.13109", "title": "Leveraging In-Context Learning for Language Model Agents", "authors": ["Shivanshu Gupta", "Sameer Singh", "Ashish Sabharwal", "Tushar Khot", "Ben Bogin"], "abstract": "In-context learning (ICL) with dynamically selected demonstrations combines the flexibility of prompting large language models (LLMs) with the ability to leverage training data to improve performance. While ICL has been highly successful for prediction and generation tasks, leveraging it for agentic tasks that require sequential decision making is challenging -- one must think not only about how to annotate long trajectories at scale and how to select demonstrations, but also what constitutes demonstrations, and when and where to show them. To address this, we first propose an algorithm that leverages an LLM with retries along with demonstrations to automatically and efficiently annotate agentic tasks with solution trajectories. We then show that set-selection of trajectories of similar tasks as demonstrations significantly improves performance, reliability, robustness, and efficiency of LLM agents. However, trajectory demonstrations have a large inference cost overhead. We show that this can be mitigated by using small trajectory snippets at every step instead of an additional trajectory. We find that demonstrations obtained from larger models (in the annotation phase) also improve smaller models, and that ICL agents can even rival costlier trained agents. Thus, our results reveal that ICL, with careful use, can be very powerful for agentic tasks as well.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "16 pages, 12 figures", "pdf_url": "https://arxiv.org/pdf/2506.13109.pdf", "abstract_url": "https://arxiv.org/abs/2506.13109", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文探讨了如何利用上下文学习（ICL）和动态选择的示范来提高大型语言模型（LLM）在代理任务中的表现。通过提出一种算法和展示相似任务的轨迹示范，研究显著提升了LLM代理的性能、可靠性、健壮性和效率。", "motivation": "解决在需要顺序决策的代理任务中利用ICL的挑战，包括如何大规模注释长轨迹、选择示范以及确定示范的内容和展示时机。", "method": "提出一种算法，利用带有重试的LLM和示范来自动高效地注释代理任务的解决方案轨迹，并展示通过选择相似任务的轨迹作为示范可以提升性能。", "result": "使用轨迹示范显著提高了LLM代理的性能，但增加了推理成本。通过在每个步骤使用小的轨迹片段而非完整轨迹，可以减轻这一成本。此外，从更大模型获得的示范也能提升较小模型的性能，ICL代理甚至可以与成本更高的训练代理相媲美。", "conclusion": "研究表明，通过谨慎使用，ICL对于代理任务也非常强大，能够提高效率并降低成本。"}}
{"id": "2506.13590", "title": "Agent Capability Negotiation and Binding Protocol (ACNBP)", "authors": ["Ken Huang", "Akram Sheriff", "Vineeth Sai Narajala", "Idan Habler"], "abstract": "As multi-agent systems evolve to encompass increasingly diverse and specialized agents, the challenge of enabling effective collaboration between heterogeneous agents has become paramount, with traditional agent communication protocols often assuming homogeneous environments or predefined interaction patterns that limit their applicability in dynamic, open-world scenarios. This paper presents the Agent Capability Negotiation and Binding Protocol (ACNBP), a novel framework designed to facilitate secure, efficient, and verifiable interactions between agents in heterogeneous multi-agent systems through integration with an Agent Name Service (ANS) infrastructure that provides comprehensive discovery, negotiation, and binding mechanisms. The protocol introduces a structured 10-step process encompassing capability discovery, candidate pre-screening and selection, secure negotiation phases, and binding commitment with built-in security measures including digital signatures, capability attestation, and comprehensive threat mitigation strategies, while a key innovation of ACNBP is its protocolExtension mechanism that enables backward-compatible protocol evolution and supports diverse agent architectures while maintaining security and interoperability. We demonstrate ACNBP's effectiveness through a comprehensive security analysis using the MAESTRO threat modeling framework, practical implementation considerations, and a detailed example showcasing the protocol's application in a document translation scenario, with the protocol addressing critical challenges in agent autonomy, capability verification, secure communication, and scalable agent ecosystem management.", "subjects": "Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Multiagent Systems (cs.MA)", "comments": "14 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2506.13590.pdf", "abstract_url": "https://arxiv.org/abs/2506.13590", "categories": ["Artificial Intelligence (cs.AI)", "Cryptography and Security (cs.CR)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了代理能力协商与绑定协议（ACNBP），一个旨在通过集成代理名称服务（ANS）基础设施，促进异构多代理系统中代理之间安全、高效和可验证交互的新框架。", "motivation": "解决在多代理系统中，由于代理的多样性和专业性增加，传统代理通信协议在动态、开放世界场景中适用性有限的问题。", "method": "引入了一个结构化的10步流程，包括能力发现、候选预筛选和选择、安全协商阶段，以及带有内置安全措施的绑定承诺，如数字签名、能力证明和全面的威胁缓解策略。", "result": "通过MAESTRO威胁建模框架的安全分析、实际实施考虑和一个文档翻译场景的详细示例，证明了ACNBP的有效性。", "conclusion": "ACNBP解决了代理自治、能力验证、安全通信和可扩展代理生态系统管理中的关键挑战，同时通过其protocolExtension机制支持协议的后向兼容演进和多样化的代理架构。"}}
{"id": "2506.13741", "title": "PB$^2$: Preference Space Exploration via Population-Based Methods in Preference-Based Reinforcement Learning", "authors": ["Brahim Driss", "Alex Davey", "Riad Akrour"], "abstract": "Preference-based reinforcement learning (PbRL) has emerged as a promising approach for learning behaviors from human feedback without predefined reward functions. However, current PbRL methods face a critical challenge in effectively exploring the preference space, often converging prematurely to suboptimal policies that satisfy only a narrow subset of human preferences. In this work, we identify and address this preference exploration problem through population-based methods. We demonstrate that maintaining a diverse population of agents enables more comprehensive exploration of the preference landscape compared to single-agent approaches. Crucially, this diversity improves reward model learning by generating preference queries with clearly distinguishable behaviors, a key factor in real-world scenarios where humans must easily differentiate between options to provide meaningful feedback. Our experiments reveal that current methods may fail by getting stuck in local optima, requiring excessive feedback, or degrading significantly when human evaluators make errors on similar trajectories, a realistic scenario often overlooked by methods relying on perfect oracle teachers. Our population-based approach demonstrates robust performance when teachers mislabel similar trajectory segments and shows significantly enhanced preference exploration capabilities,particularly in environments with complex reward landscapes.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.13741.pdf", "abstract_url": "https://arxiv.org/abs/2506.13741", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于群体方法的偏好空间探索技术（PB$^2$），用于解决偏好强化学习（PbRL）中的偏好探索问题。通过维持多样化的代理群体，该方法能够更全面地探索偏好景观，从而提高奖励模型的学习效果。实验表明，该方法在面对人类评估者错误标记相似轨迹段等现实场景时表现出鲁棒性，并在复杂奖励景观环境中显著增强了偏好探索能力。", "motivation": "当前偏好强化学习方法在有效探索偏好空间方面面临挑战，常常过早收敛到仅满足一小部分人类偏好的次优策略。", "method": "采用基于群体的方法，通过维持多样化的代理群体来探索偏好景观，生成具有明显区分行为的偏好查询。", "result": "实验结果显示，该方法在面对人类评估者错误标记相似轨迹段等现实场景时表现出鲁棒性，并在复杂奖励景观环境中显著增强了偏好探索能力。", "conclusion": "基于群体的偏好空间探索方法在偏好强化学习中显示出强大的潜力，特别是在处理复杂奖励景观和人类评估错误时。"}}
{"id": "2506.13589", "title": "Omni-AdaVideoRAG: Omni-Contextual Adaptive Retrieval-Augmented for Efficient Long Video Understanding", "authors": ["Zhucun Xue", "Jiangning Zhang", "Xurong Xie", "Yuxuan Cai", "Yong Liu", "Xiangtai Li", "Dacheng Tao"], "abstract": "Multimodal Large Language Models (MLLMs) struggle with long videos due to fixed context windows and weak long-term dependency modeling. Existing Retrieval-Augmented Generation (RAG) methods for videos use static retrieval strategies, leading to inefficiencies for simple queries and information loss for complex tasks. To address this, we propose AdaVideoRAG, a novel framework that dynamically adapts retrieval granularity based on query complexity using a lightweight intent classifier. Our framework employs an Omni-Knowledge Indexing module to build hierarchical databases from text (captions, ASR, OCR), visual features, and semantic graphs, enabling optimal resource allocation across tasks. We also introduce the HiVU benchmark for comprehensive evaluation. Experiments demonstrate improved efficiency and accuracy for long-video understanding, with seamless integration into existing MLLMs. AdaVideoRAG establishes a new paradigm for adaptive retrieval in video analysis. Codes will be open-sourced at", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.13589.pdf", "abstract_url": "https://arxiv.org/abs/2506.13589", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了AdaVideoRAG，一个新颖的框架，通过轻量级意图分类器动态调整检索粒度，以解决多模态大语言模型在处理长视频时的固定上下文窗口和弱长期依赖建模问题。", "motivation": "多模态大语言模型（MLLMs）在处理长视频时，由于固定的上下文窗口和弱长期依赖建模能力，表现不佳。现有的视频检索增强生成（RAG）方法使用静态检索策略，对于简单查询效率低下，对于复杂任务则信息丢失。", "method": "提出了AdaVideoRAG框架，包括一个轻量级意图分类器动态调整检索粒度，以及一个全知识索引模块，从文本（字幕、ASR、OCR）、视觉特征和语义图构建分层数据库，实现跨任务的最优资源分配。", "result": "实验证明，AdaVideoRAG在长视频理解方面提高了效率和准确性，并能无缝集成到现有的MLLMs中。", "conclusion": "AdaVideoRAG为视频分析中的自适应检索建立了新的范式，其代码将开源。"}}
{"id": "2506.13654", "title": "Ego-R1: Chain-of-Tool-Thought for Ultra-Long Egocentric Video Reasoning", "authors": ["Shulin Tian", "Ruiqi Wang", "Hongming Guo", "Penghao Wu", "Yuhao Dong", "Xiuying Wang", "Jingkang Yang", "Hao Zhang", "Hongyuan Zhu", "Ziwei Liu"], "abstract": "We introduce Ego-R1, a novel framework for reasoning over ultra-long (i.e., in days and weeks) egocentric videos, which leverages a structured Chain-of-Tool-Thought (CoTT) process, orchestrated by an Ego-R1 Agent trained via reinforcement learning (RL). Inspired by human problem-solving strategies, CoTT decomposes complex reasoning into modular steps, with the RL agent invoking specific tools, one per step, to iteratively and collaboratively answer sub-questions tackling such tasks as temporal retrieval and multi-modal understanding. We design a two-stage training paradigm involving supervised finetuning (SFT) of a pretrained language model using CoTT data and RL to enable our agent to dynamically propose step-by-step tools for long-range reasoning. To facilitate training, we construct a dataset called Ego-R1 Data, which consists of Ego-CoTT-25K for SFT and Ego-QA-4.4K for RL. Furthermore, our Ego-R1 agent is evaluated on a newly curated week-long video QA benchmark, Ego-R1 Bench, which contains human-verified QA pairs from hybrid sources. Extensive results demonstrate that the dynamic, tool-augmented chain-of-thought reasoning by our Ego-R1 Agent can effectively tackle the unique challenges of understanding ultra-long egocentric videos, significantly extending the time coverage from few hours to a week.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2506.13654.pdf", "abstract_url": "https://arxiv.org/abs/2506.13654", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "Ego-R1是一个新颖的框架，用于处理超长（即几天到几周）的自中心视频推理，通过强化学习训练的Ego-R1代理协调的结构化工具思维链（CoTT）过程。", "motivation": "解决超长自中心视频理解中的复杂推理问题，扩展时间覆盖范围从几小时到一周。", "method": "采用两阶段训练范式，包括使用CoTT数据进行监督微调（SFT）和强化学习（RL），使代理能够动态提出逐步工具进行长范围推理。", "result": "Ego-R1代理的动态、工具增强的思维链推理能有效应对理解超长自中心视频的独特挑战。", "conclusion": "Ego-R1框架通过CoTT和RL的结合，显著提升了超长自中心视频的理解能力，为相关领域的研究和应用提供了新的方向。"}}
{"id": "2506.12078", "title": "Modeling Earth-Scale Human-Like Societies with One Billion Agents", "authors": ["Haoxiang Guan", "Jiyan He", "Liyang Fan", "Zhenzhen Ren", "Shaobin He", "Xin Yu", "Yuan Chen", "Shuxin Zheng", "Tie-Yan Liu", "Zhen Liu"], "abstract": "Understanding how complex societal behaviors emerge from individual cognition and interactions requires both high-fidelity modeling of human behavior and large-scale simulations. Traditional agent-based models (ABMs) have been employed to study these dynamics for decades, but are constrained by simplified agent behaviors that fail to capture human complexity. Recent advances in large language models (LLMs) offer new opportunities by enabling agents to exhibit sophisticated social behaviors that go beyond rule-based logic, yet face significant scaling challenges. Here we present Light Society, an agent-based simulation framework that advances both fronts, efficiently modeling human-like societies at planetary scale powered by LLMs. Light Society formalizes social processes as structured transitions of agent and environment states, governed by a set of LLM-powered simulation operations, and executed through an event queue. This modular design supports both independent and joint component optimization, supporting efficient simulation of societies with over one billion agents. Large-scale simulations of trust games and opinion propagation--spanning up to one billion agents--demonstrate Light Society's high fidelity and efficiency in modeling social trust and information diffusion, while revealing scaling laws whereby larger simulations yield more stable and realistic emergent behaviors.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computers and Society (cs.CY); Social and Information Networks (cs.SI)", "comments": "Work in progress", "pdf_url": "https://arxiv.org/pdf/2506.12078.pdf", "abstract_url": "https://arxiv.org/abs/2506.12078", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Computers and Society (cs.CY)", "Social and Information Networks (cs.SI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了Light Society，一个基于代理的模拟框架，利用大型语言模型（LLMs）高效地模拟了行星尺度上的人类社会，支持超过十亿代理的模拟。", "motivation": "解决传统基于代理的模型（ABMs）在模拟人类行为时的简化行为限制，以及大型语言模型在模拟复杂社会行为时的扩展挑战。", "method": "通过将社会过程形式化为代理和环境状态的结构化转换，由一组LLM驱动的模拟操作控制，并通过事件队列执行，支持独立和联合组件优化。", "result": "大规模模拟信任游戏和意见传播（涉及多达十亿代理）展示了Light Society在模拟社会信任和信息扩散方面的高保真度和效率，同时揭示了更大规模模拟产生更稳定和现实涌现行为的缩放规律。", "conclusion": "Light Society框架在模拟人类复杂社会行为方面具有高保真度和高效率，能够支持超大规模的社会模拟，为理解社会行为的涌现提供了新的工具。"}}
{"id": "2506.13474", "title": "Language Agents for Hypothesis-driven Clinical Decision Making with Reinforcement Learning", "authors": ["David Bani-Harouni", "Chantal Pellegrini", "Ege Özsoy", "Matthias Keicher", "Nassir Navab"], "abstract": "Clinical decision-making is a dynamic, interactive, and cyclic process where doctors have to repeatedly decide on which clinical action to perform and consider newly uncovered information for diagnosis and treatment. Large Language Models (LLMs) have the potential to support clinicians in this process, however, most applications of LLMs in clinical decision support suffer from one of two limitations: Either they assume the unrealistic scenario of immediate availability of all patient information and do not model the interactive and iterative investigation process, or they restrict themselves to the limited \"out-of-the-box\" capabilities of large pre-trained models without performing task-specific training. In contrast to this, we propose to model clinical decision-making for diagnosis with a hypothesis-driven uncertainty-aware language agent, LA-CDM, that converges towards a diagnosis via repeatedly requesting and interpreting relevant tests. Using a hybrid training paradigm combining supervised and reinforcement learning, we train LA-CDM with three objectives targeting critical aspects of clinical decision-making: accurate hypothesis generation, hypothesis uncertainty estimation, and efficient decision-making. We evaluate our methodology on MIMIC-CDM, a real-world dataset covering four abdominal diseases containing various clinical tests and show the benefit of explicitly training clinical decision-making for increasing diagnostic performance and efficiency.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.13474.pdf", "abstract_url": "https://arxiv.org/abs/2506.13474", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于强化学习的语言代理LA-CDM，用于支持临床决策过程中的假设驱动诊断。通过结合监督学习和强化学习，LA-CDM能够生成准确的假设、估计假设的不确定性，并进行高效的决策。在MIMIC-CDM数据集上的评估显示，该方法显著提高了诊断性能和效率。", "motivation": "临床决策是一个动态、互动和循环的过程，需要医生不断决定执行哪些临床行动并考虑新发现的信息进行诊断和治疗。尽管大型语言模型（LLMs）有潜力支持这一过程，但现有应用要么假设所有患者信息立即可用，不模拟互动和迭代的调查过程，要么局限于预训练模型的有限能力，未进行任务特定训练。", "method": "提出了一种假设驱动的不确定性感知语言代理LA-CDM，通过反复请求和解释相关测试来逐步接近诊断。采用结合监督学习和强化学习的混合训练范式，针对临床决策的三个关键方面进行训练：准确的假设生成、假设不确定性估计和高效决策。", "result": "在覆盖四种腹部疾病的真实世界数据集MIMIC-CDM上的评估表明，明确训练临床决策能够显著提高诊断性能和效率。", "conclusion": "LA-CDM通过假设驱动的方法和混合训练范式，有效支持了临床决策过程，提高了诊断的准确性和效率，为临床决策支持系统的发展提供了新的方向。"}}
{"id": "2506.12094", "title": "Military AI Cyber Agents (MAICAs) Constitute a Global Threat to Critical Infrastructure", "authors": ["Timothy Dubber", "Seth Lazar"], "abstract": "This paper argues that autonomous AI cyber-weapons - Military-AI Cyber Agents (MAICAs) - create a credible pathway to catastrophic risk. It sets out the technical feasibility of MAICAs, explains why geopolitics and the nature of cyberspace make MAICAs a catastrophic risk, and proposes political, defensive-AI and analogue-resilience measures to blunt the threat.", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.12094.pdf", "abstract_url": "https://arxiv.org/abs/2506.12094", "categories": ["Computers and Society (cs.CY)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文认为自主AI网络武器——军事AI网络代理（MAICAs）——构成了灾难性风险的可行路径。", "motivation": "探讨MAICAs对关键基础设施构成的全球威胁及其潜在的灾难性风险。", "method": "分析了MAICAs的技术可行性，以及地缘政治和网络空间特性如何使MAICAs成为灾难性风险。", "result": "提出了政治、防御性AI和模拟弹性措施来减轻这一威胁。", "conclusion": "MAICAs对全球安全构成严重威胁，需采取综合措施以降低风险。"}}
{"id": "2506.13599", "title": "CAMS: A CityGPT-Powered Agentic Framework for Urban Human Mobility Simulation", "authors": ["Yuwei Du", "Jie Feng", "Jian Yuan", "Yong Li"], "abstract": "Human mobility simulation plays a crucial role in various real-world applications. Recently, to address the limitations of traditional data-driven approaches, researchers have explored leveraging the commonsense knowledge and reasoning capabilities of large language models (LLMs) to accelerate human mobility simulation. However, these methods suffer from several critical shortcomings, including inadequate modeling of urban spaces and poor integration with both individual mobility patterns and collective mobility distributions. To address these challenges, we propose \\textbf{C}ityGPT-Powered \\textbf{A}gentic framework for \\textbf{M}obility \\textbf{S}imulation (\\textbf{CAMS}), an agentic framework that leverages the language based urban foundation model to simulate human mobility in urban space. \\textbf{CAMS} comprises three core modules, including MobExtractor to extract template mobility patterns and synthesize new ones based on user profiles, GeoGenerator to generate anchor points considering collective knowledge and generate candidate urban geospatial knowledge using an enhanced version of CityGPT, TrajEnhancer to retrieve spatial knowledge based on mobility patterns and generate trajectories with real trajectory preference alignment via DPO. Experiments on real-world datasets show that \\textbf{CAMS} achieves superior performance without relying on externally provided geospatial information. Moreover, by holistically modeling both individual mobility patterns and collective mobility constraints, \\textbf{CAMS} generates more realistic and plausible trajectories. In general, \\textbf{CAMS} establishes a new paradigm that integrates the agentic framework with urban-knowledgeable LLMs for human mobility simulation.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.13599.pdf", "abstract_url": "https://arxiv.org/abs/2506.13599", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "CAMS是一个基于CityGPT的代理框架，用于城市人类移动模拟，通过结合语言基础的都市基础模型，解决了传统数据驱动方法在都市空间建模和个体与集体移动模式整合上的不足。", "motivation": "解决传统数据驱动方法在人类移动模拟中的局限性，特别是都市空间建模不足及个体与集体移动模式整合差的问题。", "method": "提出了CAMS框架，包含MobExtractor、GeoGenerator和TrajEnhancer三个核心模块，分别用于提取和合成移动模式、生成考虑集体知识的锚点和候选都市地理空间知识、以及基于移动模式检索空间知识并生成与真实轨迹偏好对齐的轨迹。", "result": "在真实世界数据集上的实验显示，CAMS在不依赖外部提供的地理空间信息的情况下，实现了卓越的性能，并生成了更真实和合理的轨迹。", "conclusion": "CAMS通过将代理框架与具备都市知识的LLMs整合，为人类移动模拟建立了新的范式，展示了在模拟人类移动方面的潜力和优势。"}}
{"id": "2506.12100", "title": "LLM Embedding-based Attribution (LEA): Quantifying Source Contributions to Generative Model's Response for Vulnerability Analysis", "authors": ["Reza Fayyazi", "Michael Zuzak", "Shanchieh Jay Yang"], "abstract": "Security vulnerabilities are rapidly increasing in frequency and complexity, creating a shifting threat landscape that challenges cybersecurity defenses. Large Language Models (LLMs) have been widely adopted for cybersecurity threat analysis. When querying LLMs, dealing with new, unseen vulnerabilities is particularly challenging as it lies outside LLMs' pre-trained distribution. Retrieval-Augmented Generation (RAG) pipelines mitigate the problem by injecting up-to-date authoritative sources into the model context, thus reducing hallucinations and increasing the accuracy in responses. Meanwhile, the deployment of LLMs in security-sensitive environments introduces challenges around trust and safety. This raises a critical open question: How to quantify or attribute the generated response to the retrieved context versus the model's pre-trained knowledge? This work proposes LLM Embedding-based Attribution (LEA) -- a novel, explainable metric to paint a clear picture on the 'percentage of influence' the pre-trained knowledge vs. retrieved content has for each generated response. We apply LEA to assess responses to 100 critical CVEs from the past decade, verifying its effectiveness to quantify the insightfulness for vulnerability analysis. Our development of LEA reveals a progression of independency in hidden states of LLMs: heavy reliance on context in early layers, which enables the derivation of LEA; increased independency in later layers, which sheds light on why scale is essential for LLM's effectiveness. This work provides security analysts a means to audit LLM-assisted workflows, laying the groundwork for transparent, high-assurance deployments of RAG-enhanced LLMs in cybersecurity operations.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.12100.pdf", "abstract_url": "https://arxiv.org/abs/2506.12100", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种名为LLM嵌入归因（LEA）的新方法，用于量化生成模型响应中预训练知识与检索内容的影响比例，特别针对网络安全漏洞分析中的挑战。", "motivation": "随着网络安全漏洞的频率和复杂性迅速增加，大型语言模型（LLMs）在网络安全威胁分析中的应用面临信任和安全挑战，尤其是在处理未见过的漏洞时。", "method": "通过检索增强生成（RAG）管道将最新权威源注入模型上下文，减少幻觉并提高响应准确性，同时开发LEA度量来量化预训练知识与检索内容对生成响应的影响。", "result": "LEA成功应用于过去十年中的100个关键CVE，验证了其在漏洞分析中量化洞察力的有效性，并揭示了LLMs隐藏状态中依赖性的变化。", "conclusion": "LEA为安全分析师提供了一种审计LLM辅助工作流程的方法，为在网络安全操作中透明、高保证地部署RAG增强的LLMs奠定了基础。"}}
{"id": "2506.12098", "title": "\"I Hadn't Thought About That\": Creators of Human-like AI Weigh in on Ethics And Neurodivergence", "authors": ["Naba Rizvi", "Taggert Smith", "Tanvi Vidyala", "Mya Bolds", "Harper Strickland", "Andrew Begel", "Rua Williams", "Imani Munyaka"], "abstract": "Human-like AI agents such as robots and chatbots are becoming increasingly popular, but they present a variety of ethical concerns. The first concern is in how we define humanness, and how our definition impacts communities historically dehumanized by scientific research. Autistic people in particular have been dehumanized by being compared to robots, making it even more important to ensure this marginalization is not reproduced by AI that may promote neuronormative social behaviors. Second, the ubiquitous use of these agents raises concerns surrounding model biases and accessibility. In our work, we investigate the experiences of the people who build and design these technologies to gain insights into their understanding and acceptance of neurodivergence, and the challenges in making their work more accessible to users with diverse needs. Even though neurodivergent individuals are often marginalized for their unique communication styles, nearly all participants overlooked the conclusions their end-users and other AI system makers may draw about communication norms from the implementation and interpretation of humanness applied in participants' work. This highlights a major gap in their broader ethical considerations, compounded by some participants' neuronormative assumptions about the behaviors and traits that distinguish \"humans\" from \"bots\" and the replication of these assumptions in their work. We examine the impact this may have on autism inclusion in society and provide recommendations for additional systemic changes towards more ethical research directions.", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI)", "comments": "published at FAccT 2025, 15 pages, 2 tables, 4 figures", "pdf_url": "https://arxiv.org/pdf/2506.12098.pdf", "abstract_url": "https://arxiv.org/abs/2506.12098", "categories": ["Computers and Society (cs.CY)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了人类类似AI代理（如机器人和聊天机器人）的伦理问题，特别是如何定义人性及其对历史上被科学研究非人化的社区的影响，尤其是自闭症人群。研究调查了构建和设计这些技术的人的经验，以了解他们对神经多样性的理解和接受程度，以及使他们的工作更适应多样化用户需求的挑战。研究发现，尽管神经多样性个体因其独特的沟通方式常常被边缘化，但几乎所有参与者都忽略了他们的工作可能对沟通规范的影响，这揭示了他们在更广泛的伦理考虑中的主要差距。", "motivation": "解决人类类似AI代理的伦理问题，特别是对神经多样性群体的影响，以及如何避免历史上的非人化现象在这些技术中重现。", "method": "通过调查构建和设计人类类似AI技术的人员的经验，分析他们对神经多样性的理解和接受程度，以及面临的挑战。", "result": "研究发现，参与者普遍忽视了他们的工作可能对沟通规范的影响，存在对神经多样性考虑的显著差距，且部分参与者对区分“人类”与“机器人”的行为和特征持有神经规范性假设。", "conclusion": "研究强调了在AI开发中考虑神经多样性的重要性，并提出了促进更伦理研究方向系统性改变的建议，以促进自闭症等神经多样性群体在社会中的包容性。"}}
{"id": "2506.12104", "title": "DRIFT: Dynamic Rule-Based Defense with Injection Isolation for Securing LLM Agents", "authors": ["Hao Li", "Xiaogeng Liu", "Hung-Chun Chiu", "Dianqi Li", "Ning Zhang", "Chaowei Xiao"], "abstract": "Large Language Models (LLMs) are increasingly central to agentic systems due to their strong reasoning and planning capabilities. By interacting with external environments through predefined tools, these agents can carry out complex user tasks. Nonetheless, this interaction also introduces the risk of prompt injection attacks, where malicious inputs from external sources can mislead the agent's behavior, potentially resulting in economic loss, privacy leakage, or system compromise. System-level defenses have recently shown promise by enforcing static or predefined policies, but they still face two key challenges: the ability to dynamically update security rules and the need for memory stream isolation. To address these challenges, we propose DRIFT, a Dynamic Rule-based Isolation Framework for Trustworthy agentic systems, which enforces both control- and data-level constraints. A Secure Planner first constructs a minimal function trajectory and a JSON-schema-style parameter checklist for each function node based on the user query. A Dynamic Validator then monitors deviations from the original plan, assessing whether changes comply with privilege limitations and the user's intent. Finally, an Injection Isolator detects and masks any instructions that may conflict with the user query from the memory stream to mitigate long-term risks. We empirically validate the effectiveness of DRIFT on the AgentDojo benchmark, demonstrating its strong security performance while maintaining high utility across diverse models -- showcasing both its robustness and adaptability.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": "18 pages, 12 figures", "pdf_url": "https://arxiv.org/pdf/2506.12104.pdf", "abstract_url": "https://arxiv.org/abs/2506.12104", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了DRIFT框架，一个动态规则基础的隔离框架，用于保护基于大型语言模型（LLM）的代理系统免受提示注入攻击。通过安全规划器、动态验证器和注入隔离器的协同工作，DRIFT能够动态更新安全规则并隔离内存流中的恶意指令，从而在保持高实用性的同时提供强大的安全保障。", "motivation": "随着大型语言模型（LLM）在代理系统中的广泛应用，其与外部环境的交互引入了提示注入攻击的风险，可能导致经济损失、隐私泄露或系统被攻陷。现有的系统级防御措施虽有一定效果，但在动态更新安全规则和内存流隔离方面仍面临挑战。", "method": "DRIFT框架通过三个主要组件实现安全防护：安全规划器构建最小功能轨迹和参数检查清单；动态验证器监控计划偏差，评估变更是否符合权限限制和用户意图；注入隔离器检测并屏蔽内存流中可能与用户查询冲突的指令。", "result": "在AgentDojo基准测试中，DRIFT展现了强大的安全性能和高的实用性，证明了其在多样模型中的鲁棒性和适应性。", "conclusion": "DRIFT框架通过动态规则和注入隔离有效解决了LLM代理系统中的安全挑战，不仅提升了系统的安全性，还保持了其高效和灵活的特性，为构建可信赖的代理系统提供了新的解决方案。"}}
{"id": "2506.13743", "title": "LTRR: Learning To Rank Retrievers for LLMs", "authors": ["To Eun Kim", "Fernando Diaz"], "abstract": "Retrieval-Augmented Generation (RAG) systems typically rely on a single fixed retriever, despite growing evidence that no single retriever performs optimally across all query types. In this paper, we explore a query routing approach that dynamically selects from a pool of retrievers based on the query, using both train-free heuristics and learned routing models. We frame routing as a learning-to-rank (LTR) problem and introduce LTRR, a framework that learns to rank retrievers by their expected utility gain to downstream LLM performance. Our experiments, conducted on synthetic QA data with controlled query type variations, show that routing-based RAG systems can outperform the best single-retriever-based systems. Performance gains are especially pronounced in models trained with the Answer Correctness (AC) metric and with pairwise learning approaches, especially with XGBoost. We also observe improvements in generalization to out-of-distribution queries. As part of the SIGIR 2025 LiveRAG challenge, our submitted system demonstrated the practical viability of our approach, achieving competitive performance in both answer correctness and faithfulness. These findings highlight the importance of both training methodology and metric selection in query routing for RAG systems.", "subjects": "Computation and Language (cs.CL); Information Retrieval (cs.IR)", "comments": "SIGIR 2025 LiveRAG Spotlight", "pdf_url": "https://arxiv.org/pdf/2506.13743.pdf", "abstract_url": "https://arxiv.org/abs/2506.13743", "categories": ["Computation and Language (cs.CL)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了LTRR框架，通过学习排名检索器来优化检索增强生成（RAG）系统的性能，动态选择最适合查询的检索器，实验表明该方法在特定条件下能超越单一检索器系统。", "motivation": "解决RAG系统中单一检索器无法在所有查询类型上表现最优的问题。", "method": "采用学习排名（LTR）方法，开发LTRR框架，动态选择检索器，结合无训练启发式和学习的路由模型。", "result": "在合成QA数据上的实验显示，基于路由的RAG系统性能优于单一检索器系统，特别是在使用答案正确性（AC）指标和成对学习方法时。", "conclusion": "研究强调了训练方法和指标选择在RAG系统查询路由中的重要性，LTRR框架在实际应用中展现了竞争力。"}}
{"id": "2506.12110", "title": "EconGym: A Scalable AI Testbed with Diverse Economic Tasks", "authors": ["Qirui Mi", "Qipeng Yang", "Zijun Fan", "Wentian Fan", "Heyang Ma", "Chengdong Ma", "Siyu Xia", "Bo An", "Jun Wang", "Haifeng Zhang"], "abstract": "Artificial intelligence (AI) has become a powerful tool for economic research, enabling large-scale simulation and policy optimization. However, applying AI effectively requires simulation platforms for scalable training and evaluation-yet existing environments remain limited to simplified, narrowly scoped tasks, falling short of capturing complex economic challenges such as demographic shifts, multi-government coordination, and large-scale agent interactions. To address this gap, we introduce EconGym, a scalable and modular testbed that connects diverse economic tasks with AI algorithms. Grounded in rigorous economic modeling, EconGym implements 11 heterogeneous role types (e.g., households, firms, banks, governments), their interaction mechanisms, and agent models with well-defined observations, actions, and rewards. Users can flexibly compose economic roles with diverse agent algorithms to simulate rich multi-agent trajectories across 25+ economic tasks for AI-driven policy learning and analysis. Experiments show that EconGym supports diverse and cross-domain tasks-such as coordinating fiscal, pension, and monetary policies-and enables benchmarking across AI, economic methods, and hybrids. Results indicate that richer task composition and algorithm diversity expand the policy space, while AI agents guided by classical economic methods perform best in complex settings. EconGym also scales to 10k agents with high realism and efficiency.", "subjects": "General Economics (econ.GN); Artificial Intelligence (cs.AI)", "comments": "28 pages, 7 figures, 17 tables", "pdf_url": "https://arxiv.org/pdf/2506.12110.pdf", "abstract_url": "https://arxiv.org/abs/2506.12110", "categories": ["General Economics (econ.GN)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "EconGym是一个可扩展的AI测试平台，旨在通过多样化的经济任务连接AI算法，解决现有环境在模拟复杂经济挑战方面的不足。", "motivation": "现有的人工智能（AI）应用于经济研究的模拟平台局限于简化、范围狭窄的任务，无法捕捉如人口结构变化、多政府协调和大规模代理互动等复杂经济挑战。", "method": "引入EconGym，一个基于严格经济建模的可扩展和模块化测试平台，实现了11种异质角色类型及其互动机制，以及具有明确定义的观察、行动和奖励的代理模型。", "result": "实验表明，EconGym支持多样化和跨领域的任务，如协调财政、养老金和货币政策，并在AI、经济方法和混合方法之间进行基准测试。结果指出，更丰富的任务组合和算法多样性扩大了政策空间，而在复杂环境中，由经典经济方法指导的AI代理表现最佳。", "conclusion": "EconGym不仅能够扩展到10k代理，同时保持高真实性和效率，而且为AI驱动的政策学习和分析提供了丰富的多代理轨迹模拟。"}}
{"id": "2506.12234", "title": "Datrics Text2SQL: A Framework for Natural Language to SQL Query Generation", "authors": ["Tetiana Gladkykh", "Kyrylo Kirykov"], "abstract": "Text-to-SQL systems enable users to query databases using natural language, democratizing access to data analytics. However, they face challenges in understanding ambiguous phrasing, domain-specific vocabulary, and complex schema relationships. This paper introduces Datrics Text2SQL, a Retrieval-Augmented Generation (RAG)-based framework designed to generate accurate SQL queries by leveraging structured documentation, example-based learning, and domain-specific rules. The system builds a rich Knowledge Base from database documentation and question-query examples, which are stored as vector embeddings and retrieved through semantic similarity. It then uses this context to generate syntactically correct and semantically aligned SQL code. The paper details the architecture, training methodology, and retrieval logic, highlighting how the system bridges the gap between user intent and database structure without requiring SQL expertise.", "subjects": "Databases (cs.DB); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "28 pages, 6 figures, initial whitepaper version 1.0, submitted March 2025", "pdf_url": "https://arxiv.org/pdf/2506.12234.pdf", "abstract_url": "https://arxiv.org/abs/2506.12234", "categories": ["Databases (cs.DB)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "Datrics Text2SQL是一个基于检索增强生成（RAG）的框架，旨在通过自然语言生成准确的SQL查询，解决了传统文本到SQL系统在理解模糊表达、领域特定词汇和复杂模式关系方面的挑战。", "motivation": "解决传统文本到SQL系统在理解用户意图和数据库结构之间的差距，特别是在处理模糊表达、领域特定词汇和复杂模式关系时的挑战。", "method": "利用结构化文档、基于示例的学习和领域特定规则，构建一个丰富的知识库，存储为向量嵌入并通过语义相似性检索，以此生成语法正确且语义对齐的SQL代码。", "result": "开发了一个能够有效桥接用户意图和数据库结构的系统，无需用户具备SQL专业知识。", "conclusion": "Datrics Text2SQL框架通过结合检索增强生成技术和丰富的知识库，显著提高了自然语言到SQL查询的准确性和效率，为数据分析的民主化提供了有力工具。"}}
{"id": "2506.12331", "title": "IndoorWorld: Integrating Physical Task Solving and Social Simulation in A Heterogeneous Multi-Agent Environment", "authors": ["Dekun Wu", "Frederik Brudy", "Bang Liu", "Yi Wang"], "abstract": "Virtual environments are essential to AI agent research. Existing environments for LLM agent research typically focus on either physical task solving or social simulation, with the former oversimplifying agent individuality and social dynamics, and the latter lacking physical grounding of social behaviors. We introduce IndoorWorld, a heterogeneous multi-agent environment that tightly integrates physical and social dynamics. By introducing novel challenges for LLM-driven agents in orchestrating social dynamics to influence physical environments and anchoring social interactions within world states, IndoorWorld opens up possibilities of LLM-based building occupant simulation for architectural design. We demonstrate the potential with a series of experiments within an office setting to examine the impact of multi-agent collaboration, resource competition, and spatial layout on agent behavior.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.12331.pdf", "abstract_url": "https://arxiv.org/abs/2506.12331", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "IndoorWorld是一个异构多智能体环境，紧密整合了物理和社会动态，为LLM驱动的智能体提供了在物理环境中协调社会动态的新挑战。", "motivation": "解决现有虚拟环境在LLM智能体研究中要么过于简化智能体个体性和社会动态，要么缺乏社会行为的物理基础的问题。", "method": "引入IndoorWorld，一个异构多智能体环境，通过将社会互动锚定在世界状态中，整合物理和社会动态。", "result": "通过一系列在办公室环境中的实验，研究了多智能体协作、资源竞争和空间布局对智能体行为的影响。", "conclusion": "IndoorWorld为基于LLM的建筑居住者模拟开辟了可能性，对建筑设计有潜在的应用价值。"}}
{"id": "2506.12202", "title": "A Fast, Reliable, and Secure Programming Language for LLM Agents with Code Actions", "authors": ["Stephen Mell", "Botong Zhang", "David Mell", "Shuo Li", "Ramya Ramalingam", "Nathan Yu", "Steve Zdancewic", "Osbert Bastani"], "abstract": "Modern large language models (LLMs) are often deployed as agents, calling external tools adaptively to solve tasks. Rather than directly calling tools, it can be more effective for LLMs to write code to perform the tool calls, enabling them to automatically generate complex control flow such as conditionals and loops. Such code actions are typically provided as Python code, since LLMs are quite proficient at it; however, Python may not be the ideal language due to limited built-in support for performance, security, and reliability. We propose a novel programming language for code actions, called Quasar, which has several benefits: (1) automated parallelization to improve performance, (2) uncertainty quantification to improve reliability and mitigate hallucinations, and (3) security features enabling the user to validate actions. LLMs can write code in a subset of Python, which is automatically transpiled to Quasar. We evaluate our approach on the ViperGPT visual question answering agent, applied to the GQA dataset, demonstrating that LLMs with Quasar actions instead of Python actions retain strong performance, while reducing execution time when possible by 42%, improving security by reducing user approval interactions when possible by 52%, and improving reliability by applying conformal prediction to achieve a desired target coverage level.", "subjects": "Programming Languages (cs.PL); Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.12202.pdf", "abstract_url": "https://arxiv.org/abs/2506.12202", "categories": ["Programming Languages (cs.PL)", "Artificial Intelligence (cs.AI)", "Cryptography and Security (cs.CR)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为Quasar的新型编程语言，专为LLM代理的代码动作设计，旨在提高性能、安全性和可靠性。通过自动化并行化、不确定性量化和安全特性，Quasar在保持强大性能的同时，显著减少了执行时间和用户批准交互，提高了可靠性。", "motivation": "现有的LLM代理通常使用Python编写代码动作，但Python在性能、安全和可靠性方面的内置支持有限，这促使了Quasar语言的开发。", "method": "开发了Quasar语言，支持自动化并行化、不确定性量化和安全特性，允许LLMs编写Python子集代码并自动转换为Quasar。", "result": "在ViperGPT视觉问答代理上的评估显示，使用Quasar动作的LLMs在保持性能的同时，执行时间减少了42%，用户批准交互减少了52%，并通过符合预测达到了目标覆盖水平，提高了可靠性。", "conclusion": "Quasar作为一种新型编程语言，为LLM代理提供了一种快速、可靠且安全的代码动作解决方案，显著提升了性能、安全性和可靠性。"}}
{"id": "2506.12339", "title": "SheetMind: An End-to-End LLM-Powered Multi-Agent Framework for Spreadsheet Automation", "authors": ["Ruiyan Zhu", "Xi Cheng", "Ke Liu", "Brian Zhu", "Daniel Jin", "Neeraj Parihar", "Zhoutian Xu", "Oliver Gao"], "abstract": "We present SheetMind, a modular multi-agent framework powered by large language models (LLMs) for spreadsheet automation via natural language instructions. The system comprises three specialized agents: a Manager Agent that decomposes complex user instructions into subtasks; an Action Agent that translates these into structured commands using a Backus Naur Form (BNF) grammar; and a Reflection Agent that validates alignment between generated actions and the user's original intent. Integrated into Google Sheets via a Workspace extension, SheetMind supports real-time interaction without requiring scripting or formula knowledge. Experiments on benchmark datasets demonstrate an 80 percent success rate on single step tasks and approximately 70 percent on multi step instructions, outperforming ablated and baseline variants. Our results highlight the effectiveness of multi agent decomposition and grammar based execution for bridging natural language and spreadsheet functionalities.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": "Ruiyan Zhu and Xi Cheng contributed equally to this work", "pdf_url": "https://arxiv.org/pdf/2506.12339.pdf", "abstract_url": "https://arxiv.org/abs/2506.12339", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "SheetMind是一个基于大型语言模型（LLMs）的模块化多代理框架，旨在通过自然语言指令实现电子表格自动化。该系统包含三个专门代理：管理代理、行动代理和反思代理，分别负责分解用户指令、转换为结构化命令和验证行动与用户意图的一致性。集成到Google Sheets后，SheetMind支持实时交互，无需脚本或公式知识。实验显示，其在单步和多步任务上的成功率分别为80%和70%，优于基准和简化版本。", "motivation": "解决用户在使用电子表格时需要脚本或公式知识的问题，通过自然语言指令实现自动化操作，降低使用门槛。", "method": "采用多代理框架，包括管理代理分解指令、行动代理通过BNF语法转换指令为结构化命令、反思代理验证行动与意图的一致性。", "result": "在基准数据集上的实验显示，单步任务成功率为80%，多步指令约为70%，优于其他版本。", "conclusion": "SheetMind通过多代理分解和基于语法的执行，有效桥接了自然语言与电子表格功能，提高了自动化操作的效率和可访问性。"}}
{"id": "2506.12469", "title": "Levels of Autonomy for AI Agents", "authors": ["K. J. Kevin Feng", "David W. McDonald", "Amy X. Zhang"], "abstract": "Autonomy is a double-edged sword for AI agents, simultaneously unlocking transformative possibilities and serious risks. How can agent developers calibrate the appropriate levels of autonomy at which their agents should operate? We argue that an agent's level of autonomy can be treated as a deliberate design decision, separate from its capability and operational environment. In this work, we define five levels of escalating agent autonomy, characterized by the roles a user can take when interacting with an agent: operator, collaborator, consultant, approver, and observer. Within each level, we describe the ways by which a user can exert control over the agent and open questions for how to design the nature of user-agent interaction. We then highlight a potential application of our framework towards AI autonomy certificates to govern agent behavior in single- and multi-agent systems. We conclude by proposing early ideas for evaluating agents' autonomy. Our work aims to contribute meaningful, practical steps towards responsibly deployed and useful AI agents in the real world.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": "Forthcoming paper in the Knight First Amendment Institute's \"AI and Democratic Freedoms\" essay series", "pdf_url": "https://arxiv.org/pdf/2506.12469.pdf", "abstract_url": "https://arxiv.org/abs/2506.12469", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文讨论了AI代理的自主性水平，提出了五种逐步提升的自主性级别，并探讨了用户如何在不同级别上与代理互动以施加控制。文章还提出了AI自主性证书的概念，以及评估代理自主性的初步想法，旨在为现实世界中负责任且有用的AI代理部署提供实用的步骤。", "motivation": "AI代理的自主性既带来了变革的可能性，也伴随着严重的风险。本文旨在解决如何为AI代理开发者校准适当的自主性水平的问题。", "method": "作者将代理的自主性水平视为一个独立于其能力和操作环境的设计决策，定义了五种逐步提升的自主性级别，并描述了用户如何在不同级别上对代理施加控制。", "result": "提出了一个框架，包括五种自主性级别和用户在不同级别上的角色，以及如何设计用户与代理互动的开放性问题。还提出了AI自主性证书的概念和评估代理自主性的初步想法。", "conclusion": "本文的工作旨在为现实世界中负责任且有用的AI代理部署提供有意义的、实用的步骤，通过定义自主性级别和提出评估方法，帮助开发者更好地设计和控制AI代理的自主性。"}}
{"id": "2506.12474", "title": "Generalizable Trajectory Prediction via Inverse Reinforcement Learning with Mamba-Graph Architecture", "authors": ["Wenyun Li", "Wenjie Huang", "Zejian Deng", "Chen Sun"], "abstract": "Accurate driving behavior modeling is fundamental to safe and efficient trajectory prediction, yet remains challenging in complex traffic scenarios. This paper presents a novel Inverse Reinforcement Learning (IRL) framework that captures human-like decision-making by inferring diverse reward functions, enabling robust cross-scenario adaptability. The learned reward function is utilized to maximize the likelihood of output by the encoder-decoder architecture that combines Mamba blocks for efficient long-sequence dependency modeling with graph attention networks to encode spatial interactions among traffic agents. Comprehensive evaluations on urban intersections and roundabouts demonstrate that the proposed method not only outperforms various popular approaches in prediction accuracy but also achieves 2 times higher generalization performance to unseen scenarios compared to other IRL-based method.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.12474.pdf", "abstract_url": "https://arxiv.org/abs/2506.12474", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新颖的逆强化学习框架，通过推断多样化的奖励函数来捕捉类似人类的决策，实现了强大的跨场景适应性。该方法结合了Mamba块和图注意力网络，用于高效的长序列依赖建模和交通代理之间的空间交互编码。在城市场景中的全面评估表明，该方法不仅在预测准确性上优于多种流行方法，而且在未见场景中的泛化性能比其他基于IRL的方法高出2倍。", "motivation": "解决在复杂交通场景中准确建模驾驶行为的挑战，以实现安全和高效的轨迹预测。", "method": "采用逆强化学习框架，结合Mamba块和图注意力网络的编码器-解码器架构，以推断多样化的奖励函数并建模长序列依赖和空间交互。", "result": "在城市场景的评估中，该方法在预测准确性上优于多种流行方法，且在未见场景中的泛化性能比其他基于IRL的方法高出2倍。", "conclusion": "提出的方法不仅提高了轨迹预测的准确性，还显著提升了在未见交通场景中的泛化能力，为自动驾驶和智能交通系统的发展提供了有力的技术支持。"}}
{"id": "2506.12735", "title": "Revealing the Challenges of Sim-to-Real Transfer in Model-Based Reinforcement Learning via Latent Space Modeling", "authors": ["Zhilin Lin", "Shiliang Sun"], "abstract": "Reinforcement learning (RL) is playing an increasingly important role in fields such as robotic control and autonomous driving. However, the gap between simulation and the real environment remains a major obstacle to the practical deployment of RL. Agents trained in simulators often struggle to maintain performance when transferred to real-world physical environments. In this paper, we propose a latent space based approach to analyze the impact of simulation on real-world policy improvement in model-based settings. As a natural extension of model-based methods, our approach enables an intuitive observation of the challenges faced by model-based methods in sim-to-real transfer. Experiments conducted in the MuJoCo environment evaluate the performance of our method in both measuring and mitigating the sim-to-real gap. The experiments also highlight the various challenges that remain in overcoming the sim-to-real gap, especially for model-based methods.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.12735.pdf", "abstract_url": "https://arxiv.org/abs/2506.12735", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过潜在空间建模揭示了基于模型的强化学习在模拟到现实转移中的挑战，提出了一种方法来分析和减轻这种差距。", "motivation": "强化学习在机器人控制和自动驾驶等领域越来越重要，但模拟环境与现实环境之间的差距是RL实际部署的主要障碍。模拟训练的代理在转移到现实物理环境时往往难以保持性能。", "method": "提出了一种基于潜在空间的方法，用于分析模拟对现实世界策略改进的影响，作为基于模型方法的自然扩展。", "result": "在MuJoCo环境中进行的实验评估了该方法在测量和减轻模拟到现实差距方面的性能，同时也突出了克服这一差距面临的各种挑战。", "conclusion": "本文的方法直观地展示了基于模型的方法在模拟到现实转移中面临的挑战，实验结果表明，尽管存在挑战，但潜在空间建模为理解和减轻这些差距提供了有效途径。"}}
{"id": "2506.12600", "title": "Trust-MARL: Trust-Based Multi-Agent Reinforcement Learning Framework for Cooperative On-Ramp Merging Control in Heterogeneous Traffic Flow", "authors": ["Jie Pan", "Tianyi Wang", "Christian Claudel", "Jing Shi"], "abstract": "Intelligent transportation systems require connected and automated vehicles (CAVs) to conduct safe and efficient cooperation with human-driven vehicles (HVs) in complex real-world traffic environments. However, the inherent unpredictability of human behaviour, especially at bottlenecks such as highway on-ramp merging areas, often disrupts traffic flow and compromises system performance. To address the challenge of cooperative on-ramp merging in heterogeneous traffic environments, this study proposes a trust-based multi-agent reinforcement learning (Trust-MARL) framework. At the macro level, Trust-MARL enhances global traffic efficiency by leveraging inter-agent trust to improve bottleneck throughput and mitigate traffic shockwave through emergent group-level coordination. At the micro level, a dynamic trust mechanism is designed to enable CAVs to adjust their cooperative strategies in response to real-time behaviors and historical interactions with both HVs and other CAVs. Furthermore, a trust-triggered game-theoretic decision-making module is integrated to guide each CAV in adapting its cooperation factor and executing context-aware lane-changing decisions under safety, comfort, and efficiency constraints. An extensive set of ablation studies and comparative experiments validates the effectiveness of the proposed Trust-MARL approach, demonstrating significant improvements in safety, efficiency, comfort, and adaptability across varying CAV penetration rates and traffic densities.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET); Computer Science and Game Theory (cs.GT); Robotics (cs.RO)", "comments": "34 pages, 7 figures, 4 tables", "pdf_url": "https://arxiv.org/pdf/2506.12600.pdf", "abstract_url": "https://arxiv.org/abs/2506.12600", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Emerging Technologies (cs.ET)", "Computer Science and Game Theory (cs.GT)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于信任的多智能体强化学习框架（Trust-MARL），用于解决异构交通流中的合作上匝道合并控制问题，旨在提高交通效率和安全性。", "motivation": "智能交通系统要求联网和自动化车辆（CAVs）与人类驾驶车辆（HVs）在复杂的现实交通环境中进行安全高效的合作。然而，人类行为的不可预测性，尤其是在高速公路匝道合并区域等瓶颈处，常常会扰乱交通流并影响系统性能。", "method": "研究提出了Trust-MARL框架，宏观上通过利用智能体间的信任来提高瓶颈吞吐量和缓解交通冲击波，微观上设计了动态信任机制，使CAVs能够根据实时行为和历史互动调整合作策略。此外，还集成了信任触发的博弈论决策模块，指导每个CAV在安全、舒适和效率约束下调整合作因素并执行情境感知的车道变更决策。", "result": "通过一系列消融研究和对比实验验证了Trust-MARL方法的有效性，显示在不同CAV渗透率和交通密度下，安全、效率、舒适性和适应性均有显著提升。", "conclusion": "Trust-MARL框架为解决异构交通环境中的合作上匝道合并控制问题提供了有效方案，显著提高了交通系统的整体性能。"}}
{"id": "2506.12795", "title": "Resilient-native and Intelligent NextG Systems", "authors": ["Mehdi Bennis"], "abstract": "Just like power, water and transportation systems, wireless networks are a crucial societal infrastructure. As natural and human-induced disruptions continue to grow, wireless networks must be resilient to unforeseen events, able to withstand and recover from unexpected adverse conditions, shocks, unmodeled disturbances and cascading failures. Despite its critical importance, resilience remains an elusive concept, with its mathematical foundations still underdeveloped. Unlike robustness and reliability, resilience is premised on the fact that disruptions will inevitably happen. Resilience, in terms of elasticity, focuses on the ability to bounce back to favorable states, while resilience as plasticity involves agents (or networks) that can flexibly expand their states, hypotheses and course of actions, by transforming through real-time adaptation and reconfiguration. This constant situational awareness and vigilance of adapting world models and counterfactually reasoning about potential system failures and the corresponding best responses, is a core aspect of resilience. This article seeks to first define resilience and disambiguate it from reliability and robustness, before delving into the mathematics of resilience. Finally, the article concludes by presenting nuanced metrics and discussing trade-offs tailored to the unique characteristics of network resilience.", "subjects": "Emerging Technologies (cs.ET); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.12795.pdf", "abstract_url": "https://arxiv.org/abs/2506.12795", "categories": ["Emerging Technologies (cs.ET)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了无线网络作为关键社会基础设施的重要性，强调了在面对自然和人为干扰时，网络必须具备的弹性。文章区分了弹性与可靠性和鲁棒性的不同，并深入探讨了弹性的数学基础，最后提出了针对网络弹性特性的细致度量标准和权衡讨论。", "motivation": "解决无线网络在面对不可预见事件时的弹性问题，区分弹性与可靠性、鲁棒性的概念，并发展弹性的数学基础。", "method": "通过定义弹性，区分其与可靠性和鲁棒性的不同，探讨弹性的数学基础，并提出针对网络弹性的度量标准和权衡。", "result": "明确了弹性的定义和重要性，提出了弹性的数学基础和针对网络弹性的度量标准。", "conclusion": "无线网络的弹性是应对不可预见事件的关键，需要通过数学基础和细致的度量标准来理解和实现。"}}
{"id": "2506.12879", "title": "Exploring the Potential of Metacognitive Support Agents for Human-AI Co-Creation", "authors": ["Frederic Gmeiner", "Kaitao Luo", "Ye Wang", "Kenneth Holstein", "Nikolas Martelaro"], "abstract": "Despite the potential of generative AI (GenAI) design tools to enhance design processes, professionals often struggle to integrate AI into their workflows. Fundamental cognitive challenges include the need to specify all design criteria as distinct parameters upfront (intent formulation) and designers' reduced cognitive involvement in the design process due to cognitive offloading, which can lead to insufficient problem exploration, underspecification, and limited ability to evaluate outcomes. Motivated by these challenges, we envision novel metacognitive support agents that assist designers in working more reflectively with GenAI. To explore this vision, we conducted exploratory prototyping through a Wizard of Oz elicitation study with 20 mechanical designers probing multiple metacognitive support strategies. We found that agent-supported users created more feasible designs than non-supported users, with differing impacts between support strategies. Based on these findings, we discuss opportunities and tradeoffs of metacognitive support agents and considerations for future AI-based design tools.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": "26 pages, to be published in the proceedings of the Designing Interactive Systems Conference (DIS'25)", "pdf_url": "https://arxiv.org/pdf/2506.12879.pdf", "abstract_url": "https://arxiv.org/abs/2506.12879", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "探讨元认知支持代理在人类与AI共同创作中的潜力", "motivation": "尽管生成式AI设计工具有潜力增强设计过程，但专业人士在将AI整合到工作流程中时常遇到困难。主要的认知挑战包括需要提前将所有设计标准明确为具体参数（意图形成），以及设计师由于认知卸载而在设计过程中的参与度降低，这可能导致问题探索不足、规格说明不充分和评估结果能力有限。", "method": "为了探索这一愿景，我们通过一个包含20名机械设计师的Wizard of Oz启发式研究进行了探索性原型设计，探究了多种元认知支持策略。", "result": "研究发现，得到代理支持的用户比未得到支持的用户创造了更可行的设计，不同支持策略之间有不同的影响。", "conclusion": "基于这些发现，我们讨论了元认知支持代理的机遇和权衡，以及未来基于AI的设计工具的考虑因素。"}}
{"id": "2506.12949", "title": "eLog analysis for accelerators: status and future outlook", "authors": ["Antonin Sulc", "Thorsten Hellert", "Aaron Reed", "Adam Carpenter", "Alex Bien", "Chris Tennant", "Claudio Bisegni", "Daniel Lersch", "Daniel Ratner", "David Lawrence", "Diana McSpadden", "Hayden Hoschouer", "Jason St. John", "Thomas Britton"], "abstract": "This work demonstrates electronic logbook (eLog) systems leveraging modern AI-driven information retrieval capabilities at the accelerator facilities of Fermilab, Jefferson Lab, Lawrence Berkeley National Laboratory (LBNL), SLAC National Accelerator Laboratory. We evaluate contemporary tools and methodologies for information retrieval with Retrieval Augmented Generation (RAGs), focusing on operational insights and integration with existing accelerator control systems.", "subjects": "High Energy Physics - Experiment (hep-ex); Artificial Intelligence (cs.AI)", "comments": "4 pages, 2 figures, 16th International Particle Accelerator Conference (IPAC'25)", "pdf_url": "https://arxiv.org/pdf/2506.12949.pdf", "abstract_url": "https://arxiv.org/abs/2506.12949", "categories": ["High Energy Physics - Experiment (hep-ex)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文展示了在费米实验室、杰斐逊实验室、劳伦斯伯克利国家实验室（LBNL）和SLAC国家加速器实验室的加速器设施中，利用现代人工智能驱动的信息检索能力的电子日志（eLog）系统。我们评估了当代的信息检索工具和方法，特别是检索增强生成（RAGs），重点关注操作洞察和与现有加速器控制系统的集成。", "motivation": "解决加速器设施中电子日志系统的信息检索效率问题，提升操作洞察和系统集成能力。", "method": "利用现代AI驱动的信息检索技术，特别是检索增强生成（RAGs），评估和整合当代工具和方法。", "result": "展示了在多个国家实验室加速器设施中，eLog系统如何有效利用AI技术提升信息检索和操作效率。", "conclusion": "通过集成现代AI技术，eLog系统能够显著提升加速器设施的操作效率和系统集成能力，未来有望进一步优化和扩展应用。"}}
{"id": "2506.13171", "title": "Querying Large Automotive Software Models: Agentic vs. Direct LLM Approaches", "authors": ["Lukasz Mazur", "Nenad Petrovic", "James Pontes Miranda", "Ansgar Radermacher", "Robert Rasche", "Alois Knoll"], "abstract": "Large language models (LLMs) offer new opportunities for interacting with complex software artifacts, such as software models, through natural language. They present especially promising benefits for large software models that are difficult to grasp in their entirety, making traditional interaction and analysis approaches challenging. This paper investigates two approaches for leveraging LLMs to answer questions over software models: direct prompting, where the whole software model is provided in the context, and an agentic approach combining LLM-based agents with general-purpose file access tools. We evaluate these approaches using an Ecore metamodel designed for timing analysis and software optimization in automotive and embedded domains. Our findings show that while the agentic approach achieves accuracy comparable to direct prompting, it is significantly more efficient in terms of token usage. This efficiency makes the agentic approach particularly suitable for the automotive industry, where the large size of software models makes direct prompting infeasible, establishing LLM agents as not just a practical alternative but the only viable solution. Notably, the evaluation was conducted using small LLMs, which are more feasible to be executed locally - an essential advantage for meeting strict requirements around privacy, intellectual property protection, and regulatory compliance. Future work will investigate software models in diverse formats, explore more complex agent architectures, and extend agentic workflows to support not only querying but also modification of software models.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.13171.pdf", "abstract_url": "https://arxiv.org/abs/2506.13171", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文探讨了两种利用大型语言模型（LLMs）查询大型汽车软件模型的方法：直接提示法和代理法。研究发现，代理法在保持与直接提示法相当准确性的同时，显著提高了令牌使用效率，特别适用于汽车行业。", "motivation": "大型软件模型难以整体把握，传统交互和分析方法面临挑战。本文旨在探索LLMs在软件模型查询中的应用，解决效率和可行性问题。", "method": "研究比较了两种方法：直接提示法（将整个软件模型提供在上下文中）和代理法（结合LLM代理与通用文件访问工具）。使用为汽车和嵌入式领域设计的Ecore元模型进行评估。", "result": "代理法在准确性上与直接提示法相当，但在令牌使用上更为高效，使其成为汽车行业的可行解决方案。使用小型LLMs进行本地执行，满足了隐私、知识产权保护和法规遵从的严格要求。", "conclusion": "代理法不仅是大规模软件模型查询的实用替代方案，而且是唯一可行的解决方案。未来工作将探索更多软件模型格式、复杂代理架构，并扩展代理工作流以支持软件模型的修改。"}}
{"id": "2506.13453", "title": "Towards a Formal Specification for Self-organized Shape Formation in Swarm Robotics", "authors": ["YR Darr", "MA Niazi"], "abstract": "The self-organization of robots for the formation of structures and shapes is a stimulating application of the swarm robotic system. It involves a large number of autonomous robots of heterogeneous behavior, coordination among them, and their interaction with the dynamic environment. This process of complex structure formation is considered a complex system, which needs to be modeled by using any modeling approach. Although the formal specification approach along with other formal methods has been used to model the behavior of robots in a swarm. However, to the best of our knowledge, the formal specification approach has not been used to model the self-organization process in swarm robotic systems for shape formation. In this paper, we use a formal specification approach to model the shape formation task of swarm robots. We use Z (Zed) language of formal specification, which is a state-based language, to model the states of the entities of the systems. We demonstrate the effectiveness of Z for the self-organized shape formation. The presented formal specification model gives the outlines for designing and implementing the swarm robotic system for the formation of complex shapes and structures. It also provides the foundation for modeling the complex shape formation process for swarm robotics using a multi-agent system in a simulation-based environment. Keywords: Swarm robotics, Self-organization, Formal specification, Complex systems", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.13453.pdf", "abstract_url": "https://arxiv.org/abs/2506.13453", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种使用形式化规范方法来建模群机器人系统中自组织形状形成过程的新方法。通过使用Z语言，作者成功地建模了系统实体的状态，并展示了该方法在自组织形状形成中的有效性。", "motivation": "群机器人系统中的自组织形状形成是一个复杂的过程，目前尚未有研究使用形式化规范方法来建模这一过程。本文旨在填补这一空白。", "method": "使用Z语言（一种基于状态的形式化规范语言）来建模群机器人系统中实体的状态，以及自组织形状形成的过程。", "result": "提出的形式化规范模型为设计和实现群机器人系统以形成复杂形状和结构提供了框架，并为在基于模拟的环境中建模复杂形状形成过程奠定了基础。", "conclusion": "本文证明了形式化规范方法在建模群机器人自组织形状形成过程中的有效性，为未来的研究和应用提供了新的方向。"}}
{"id": "2506.13246", "title": "On Immutable Memory Systems for Artificial Agents: A Blockchain-Indexed Automata-Theoretic Framework Using ECDH-Keyed Merkle Chains", "authors": ["Craig Steven Wright"], "abstract": "This paper presents a formalised architecture for synthetic agents designed to retain immutable memory, verifiable reasoning, and constrained epistemic growth. Traditional AI systems rely on mutable, opaque statistical models prone to epistemic drift and historical revisionism. In contrast, we introduce the concept of the Merkle Automaton, a cryptographically anchored, deterministic computational framework that integrates formal automata theory with blockchain-based commitments. Each agent transition, memory fragment, and reasoning step is committed within a Merkle structure rooted on-chain, rendering it non-repudiable and auditably permanent. To ensure selective access and confidentiality, we derive symmetric encryption keys from ECDH exchanges contextualised by hierarchical privilege lattices. This enforces cryptographic access control over append-only DAG-structured knowledge graphs. Reasoning is constrained by formal logic systems and verified through deterministic traversal of policy-encoded structures. Updates are non-destructive and historied, preserving epistemic lineage without catastrophic forgetting. Zero-knowledge proofs facilitate verifiable, privacy-preserving inclusion attestations. Collectively, this architecture reframes memory not as a cache but as a ledger - one whose contents are enforced by protocol, bound by cryptography, and constrained by formal logic. The result is not an intelligent agent that mimics thought, but an epistemic entity whose outputs are provably derived, temporally anchored, and impervious to post hoc revision. This design lays foundational groundwork for legal, economic, and high-assurance computational systems that require provable memory, unforgeable provenance, and structural truth.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)", "comments": "47 pages, includes formal automata specifications, cryptographic constructions, and epistemic architecture schema", "pdf_url": "https://arxiv.org/pdf/2506.13246.pdf", "abstract_url": "https://arxiv.org/abs/2506.13246", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Distributed, Parallel, and Cluster Computing (cs.DC)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为Merkle Automaton的架构，旨在为合成代理提供不可变的内存、可验证的推理和受限的认知增长。该架构结合了形式自动机理论和基于区块链的承诺，通过加密技术确保记忆和推理步骤的不可否认性和永久性。", "motivation": "解决传统AI系统依赖易变、不透明的统计模型，容易导致认知漂移和历史修正主义的问题。", "method": "采用Merkle Automaton架构，结合形式自动机理论和区块链技术，使用ECDH交换生成的对称加密密钥和层次特权格来实现选择性访问和保密性。", "result": "设计了一个记忆作为账本的架构，其内容由协议强制执行，受密码学约束，并通过形式逻辑限制，确保了输出的可证明性、时间锚定性和抗后验修改性。", "conclusion": "该架构为需要可证明记忆、不可伪造来源和结构真实性的法律、经济和高保证计算系统奠定了基础。"}}
{"id": "2506.13205", "title": "Screen Hijack: Visual Poisoning of VLM Agents in Mobile Environments", "authors": ["Xuan Wang", "Siyuan Liang", "Zhe Liu", "Yi Yu", "Yuliang Lu", "Xiaochun Cao", "Ee-Chien Chang"], "abstract": "With the growing integration of vision-language models (VLMs), mobile agents are now widely used for tasks like UI automation and camera-based user assistance. These agents are often fine-tuned on limited user-generated datasets, leaving them vulnerable to covert threats during the training process. In this work we present GHOST, the first clean-label backdoor attack specifically designed for mobile agents built upon VLMs. Our method manipulates only the visual inputs of a portion of the training samples - without altering their corresponding labels or instructions - thereby injecting malicious behaviors into the model. Once fine-tuned with this tampered data, the agent will exhibit attacker-controlled responses when a specific visual trigger is introduced at inference time. The core of our approach lies in aligning the gradients of poisoned samples with those of a chosen target instance, embedding backdoor-relevant features into the poisoned training data. To maintain stealth and enhance robustness, we develop three realistic visual triggers: static visual patches, dynamic motion cues, and subtle low-opacity overlays. We evaluate our method across six real-world Android apps and three VLM architectures adapted for mobile use. Results show that our attack achieves high attack success rates (up to 94.67 percent) while maintaining high clean-task performance (FSR up to 95.85 percent). Additionally, ablation studies shed light on how various design choices affect the efficacy and concealment of the attack. Overall, this work is the first to expose critical security flaws in VLM-based mobile agents, highlighting their susceptibility to clean-label backdoor attacks and the urgent need for effective defense mechanisms in their training pipelines. Code and examples are available at:", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": "12 pages", "pdf_url": "https://arxiv.org/pdf/2506.13205.pdf", "abstract_url": "https://arxiv.org/abs/2506.13205", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了GHOST，一种针对基于视觉语言模型（VLM）的移动代理的清洁标签后门攻击方法。通过仅操纵部分训练样本的视觉输入而不改变其标签或指令，该方法在模型中注入了恶意行为。研究在六个真实世界的Android应用和三种适用于移动使用的VLM架构上评估了该方法，结果显示攻击成功率高达94.67%，同时保持了高达95.85%的清洁任务性能。", "motivation": "随着视觉语言模型（VLMs）的集成日益增多，移动代理被广泛用于UI自动化和基于摄像头的用户辅助等任务。这些代理通常在有限的用户生成数据集上进行微调，使其在训练过程中容易受到隐蔽威胁。", "method": "GHOST方法通过仅操纵部分训练样本的视觉输入而不改变其标签或指令，将恶意行为注入模型。该方法的核心在于将中毒样本的梯度与选定的目标实例的梯度对齐，将后门相关特征嵌入到中毒的训练数据中。为了保持隐蔽性和增强鲁棒性，研究开发了三种现实的视觉触发器：静态视觉补丁、动态运动线索和微妙的低不透明度覆盖。", "result": "在六个真实世界的Android应用和三种适用于移动使用的VLM架构上的评估显示，攻击成功率高达94.67%，同时保持了高达95.85%的清洁任务性能。", "conclusion": "这项工作是第一个揭示基于VLM的移动代理中关键安全漏洞的研究，突出了它们对清洁标签后门攻击的易感性以及在训练管道中需要有效防御机制的紧迫性。"}}
{"id": "2506.13469", "title": "A Two-stage Optimization Method for Wide-range Single-electron Quantum Magnetic Sensing", "authors": ["Shiqian Guo", "Jianqing Liu", "Thinh Le", "Huaiyu Dai"], "abstract": "Quantum magnetic sensing based on spin systems has emerged as a new paradigm for detecting ultra-weak magnetic fields with unprecedented sensitivity, revitalizing applications in navigation, geo-localization, biology, and beyond. At the heart of quantum magnetic sensing, from the protocol perspective, lies the design of optimal sensing parameters to manifest and then estimate the underlying signals of interest (SoI). Existing studies on this front mainly rely on adaptive algorithms based on black-box AI models or formula-driven principled searches. However, when the SoI spans a wide range and the quantum sensor has physical constraints, these methods may fail to converge efficiently or optimally, resulting in prolonged interrogation times and reduced sensing accuracy. In this work, we report the design of a new protocol using a two-stage optimization method. In the 1st Stage, a Bayesian neural network with a fixed set of sensing parameters is used to narrow the range of SoI. In the 2nd Stage, a federated reinforcement learning agent is designed to fine-tune the sensing parameters within a reduced search space. The proposed protocol is developed and evaluated in a challenging context of single-shot readout of an NV-center electron spin under a constrained total sensing time budget; and yet it achieves significant improvements in both accuracy and resource efficiency for wide-range D.C. magnetic field estimation compared to the state of the art.", "subjects": "Quantum Physics (quant-ph); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.13469.pdf", "abstract_url": "https://arxiv.org/abs/2506.13469", "categories": ["Quantum Physics (quant-ph)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种两阶段优化方法，用于宽范围单电子量子磁感应，通过贝叶斯神经网络和联邦强化学习代理，显著提高了在受限总感应时间预算下的准确性和资源效率。", "motivation": "量子磁感应基于自旋系统，为检测超弱磁场提供了前所未有的灵敏度，但在信号兴趣范围广泛且量子传感器有物理限制时，现有方法可能无法高效或最优地收敛，导致感应时间延长和准确性降低。", "method": "采用两阶段优化方法：第一阶段使用贝叶斯神经网络缩小信号兴趣范围；第二阶段设计联邦强化学习代理在减少的搜索空间内微调感应参数。", "result": "在NV中心电子自旋的单次读出这一挑战性背景下，与现有技术相比，该方法在宽范围直流磁场估计的准确性和资源效率上实现了显著提升。", "conclusion": "提出的协议在宽范围量子磁感应中实现了更高的准确性和效率，为导航、地理定位和生物学等领域的应用开辟了新途径。"}}
{"id": "2506.13566", "title": "A Production Scheduling Framework for Reinforcement Learning Under Real-World Constraints", "authors": ["Jonathan Hoss", "Felix Schelling", "Noah Klarmann"], "abstract": "The classical Job Shop Scheduling Problem (JSSP) focuses on optimizing makespan under deterministic constraints. Real-world production environments introduce additional complexities that cause traditional scheduling approaches to be less effective. Reinforcement learning (RL) holds potential in addressing these challenges, as it allows agents to learn adaptive scheduling strategies. However, there is a lack of a comprehensive, general-purpose frameworks for effectively training and evaluating RL agents under real-world constraints. To address this gap, we propose a modular framework that extends classical JSSP formulations by incorporating key \\mbox{real-world} constraints inherent to the shopfloor, including transport logistics, buffer management, machine breakdowns, setup times, and stochastic processing conditions, while also supporting multi-objective optimization. The framework is a customizable solution that offers flexibility in defining problem instances and configuring simulation parameters, enabling adaptation to diverse production scenarios. A standardized interface ensures compatibility with various RL approaches, providing a robust environment for training RL agents and facilitating the standardized comparison of different scheduling methods under dynamic and uncertain conditions. We release JobShopLab as an open-source tool for both research and industrial applications, accessible at:", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "This paper has been accepted for presentation at the IEEE 21st International Conference on Automation Science and Engineering (CASE 2025)", "pdf_url": "https://arxiv.org/pdf/2506.13566.pdf", "abstract_url": "https://arxiv.org/abs/2506.13566", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一个针对现实世界约束下的强化学习生产调度框架，旨在解决传统调度方法在处理复杂生产环境时的不足。", "motivation": "传统的作业车间调度问题（JSSP）在确定性约束下优化制造周期，但现实生产环境中的复杂性使得传统方法效果不佳。强化学习（RL）有潜力解决这些挑战，但缺乏一个全面的、通用的框架来有效训练和评估RL代理。", "method": "提出了一个模块化框架，扩展了经典的JSSP公式，通过纳入车间固有的关键现实约束，如运输物流、缓冲区管理、机器故障、设置时间和随机处理条件，同时支持多目标优化。", "result": "该框架提供了一个可定制的解决方案，允许灵活定义问题实例和配置模拟参数，适应多样化的生产场景，并通过标准化接口确保与各种RL方法的兼容性。", "conclusion": "JobShopLab作为一个开源工具发布，用于研究和工业应用，为在动态和不确定条件下训练RL代理和标准化比较不同调度方法提供了一个强大的环境。"}}
{"id": "2506.13583", "title": "Can you see how I learn? Human observers' inferences about Reinforcement Learning agents' learning processes", "authors": ["Bernhard Hilpert", "Muhan Hou", "Kim Baraka", "Joost Broekens"], "abstract": "Reinforcement Learning (RL) agents often exhibit learning behaviors that are not intuitively interpretable by human observers, which can result in suboptimal feedback in collaborative teaching settings. Yet, how humans perceive and interpret RL agent's learning behavior is largely unknown. In a bottom-up approach with two experiments, this work provides a data-driven understanding of the factors of human observers' understanding of the agent's learning process. A novel, observation-based paradigm to directly assess human inferences about agent learning was developed. In an exploratory interview study (\\textit{N}=9), we identify four core themes in human interpretations: Agent Goals, Knowledge, Decision Making, and Learning Mechanisms. A second confirmatory study (\\textit{N}=34) applied an expanded version of the paradigm across two tasks (navigation/manipulation) and two RL algorithms (tabular/function approximation). Analyses of 816 responses confirmed the reliability of the paradigm and refined the thematic framework, revealing how these themes evolve over time and interrelate. Our findings provide a human-centered understanding of how people make sense of agent learning, offering actionable insights for designing interpretable RL systems and improving transparency in Human-Robot Interaction.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.13583.pdf", "abstract_url": "https://arxiv.org/abs/2506.13583", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本研究通过两个实验探索了人类观察者如何理解和解释强化学习（RL）代理的学习行为，开发了一种新的基于观察的范式来直接评估人类对代理学习过程的推断。研究发现，人类解释主要集中在代理目标、知识、决策制定和学习机制四个核心主题上，并提供了设计可解释RL系统和提高人机交互透明度的实用见解。", "motivation": "强化学习代理的学习行为对人类观察者来说往往不直观，这在协作教学环境中可能导致反馈不足。然而，人类如何感知和解释RL代理的学习行为尚不清楚。", "method": "通过两个实验（一个探索性访谈研究和一个确认性研究），使用新开发的基于观察的范式，直接评估人类对代理学习过程的推断。", "result": "研究发现人类解释主要集中在四个核心主题上：代理目标、知识、决策制定和学习机制。确认性研究进一步验证了这些主题的可靠性，并揭示了它们如何随时间演变和相互关联。", "conclusion": "研究结果为理解人类如何理解代理学习提供了以人为中心的视角，为设计可解释的RL系统和提高人机交互的透明度提供了实用见解。"}}
{"id": "2506.13666", "title": "We Should Identify and Mitigate Third-Party Safety Risks in MCP-Powered Agent Systems", "authors": ["Junfeng Fang", "Zijun Yao", "Ruipeng Wang", "Haokai Ma", "Xiang Wang", "Tat-Seng Chua"], "abstract": "The development of large language models (LLMs) has entered in a experience-driven era, flagged by the emergence of environment feedback-driven learning via reinforcement learning and tool-using agents. This encourages the emergenece of model context protocol (MCP), which defines the standard on how should a LLM interact with external services, such as \\api and data. However, as MCP becomes the de facto standard for LLM agent systems, it also introduces new safety risks. In particular, MCP introduces third-party services, which are not controlled by the LLM developers, into the agent systems. These third-party MCP services provider are potentially malicious and have the economic incentives to exploit vulnerabilities and sabotage user-agent interactions. In this position paper, we advocate the research community in LLM safety to pay close attention to the new safety risks issues introduced by MCP, and develop new techniques to build safe MCP-powered agent systems. To establish our position, we argue with three key parts. (1) We first construct \\framework, a controlled framework to examine safety issues in MCP-powered agent systems. (2) We then conduct a series of pilot experiments to demonstrate the safety risks in MCP-powered agent systems is a real threat and its defense is not trivial. (3) Finally, we give our outlook by showing a roadmap to build safe MCP-powered agent systems. In particular, we would call for researchers to persue the following research directions: red teaming, MCP safe LLM development, MCP safety evaluation, MCP safety data accumulation, MCP service safeguard, and MCP safe ecosystem construction. We hope this position paper can raise the awareness of the research community in MCP safety and encourage more researchers to join this important research direction. Our code is available at", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.13666.pdf", "abstract_url": "https://arxiv.org/abs/2506.13666", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文讨论了大型语言模型（LLMs）在模型上下文协议（MCP）驱动的代理系统中引入的第三方安全风险，并呼吁研究社区关注这一问题。通过构建框架、进行实验和提出研究路线图，作者强调了开发安全MCP驱动代理系统的必要性。", "motivation": "随着MCP成为LLM代理系统的标准，第三方服务的安全风险成为一个新问题。这些服务可能被恶意利用，破坏用户与代理的交互。本文旨在提高对MCP安全风险的认识，并推动相关研究。", "method": "作者通过构建一个控制框架来检查MCP驱动的代理系统中的安全问题，进行了一系列试点实验来证明安全风险的真实存在，并提出了构建安全MCP驱动代理系统的路线图。", "result": "实验表明，MCP驱动的代理系统中的安全风险是真实存在的，且防御这些风险并非易事。作者提出了包括红队测试、MCP安全LLM开发等在内的多个研究方向。", "conclusion": "本文呼吁研究社区关注MCP驱动的代理系统中的第三方安全风险，并提出了具体的研究方向和路线图，以促进安全MCP驱动代理系统的发展。"}}
