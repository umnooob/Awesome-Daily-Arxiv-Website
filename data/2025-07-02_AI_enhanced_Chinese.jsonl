{"id": "2507.00355", "title": "Question Decomposition for Retrieval-Augmented Generation", "authors": ["Paul J. L. Ammann", "Jonas Golde", "Alan Akbik"], "abstract": "Grounding large language models (LLMs) in verifiable external sources is a well-established strategy for generating reliable answers. Retrieval-augmented generation (RAG) is one such approach, particularly effective for tasks like question answering: it retrieves passages that are semantically related to the question and then conditions the model on this evidence. However, multi-hop questions, such as \"Which company among NVIDIA, Apple, and Google made the biggest profit in 2023?,\" challenge RAG because relevant facts are often distributed across multiple documents rather than co-occurring in one source, making it difficult for standard RAG to retrieve sufficient information. To address this, we propose a RAG pipeline that incorporates question decomposition: (i) an LLM decomposes the original query into sub-questions, (ii) passages are retrieved for each sub-question, and (iii) the merged candidate pool is reranked to improve the coverage and precision of the retrieved evidence. We show that question decomposition effectively assembles complementary documents, while reranking reduces noise and promotes the most relevant passages before answer generation. Although reranking itself is standard, we show that pairing an off-the-shelf cross-encoder reranker with LLM-driven question decomposition bridges the retrieval gap on multi-hop questions and provides a practical, drop-in enhancement, without any extra training or specialized indexing. We evaluate our approach on the MultiHop-RAG and HotpotQA, showing gains in retrieval (MRR@10: +36.7%) and answer accuracy (F1: +11.6%) over standard RAG baselines.", "subjects": "Computation and Language (cs.CL)", "comments": "Accepted to ACL SRW 2025. 9 Pages, 2 Figures, 4 Tables", "pdf_url": "https://arxiv.org/pdf/2507.00355.pdf", "abstract_url": "https://arxiv.org/abs/2507.00355", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.00814", "title": "Many LLMs Are More Utilitarian Than One", "authors": ["Anita Keshmirian", "Razan Baltaji", "Babak Hemmatian", "Hadi Asghari", "Lav R. Varshney"], "abstract": "Moral judgment is integral to large language model (LLM) alignment and social reasoning. As multi-agent systems gain prominence, it becomes crucial to understand how LLMs function collectively during collaboration, compared to individual agents. In human moral judgment, group deliberation leads to a utilitarian boost: a tendency to endorse norm violations that maximize benefits for the greatest number of people despite harms. We study whether a similar dynamic emerges in multi-agent LLM systems. We tested six models on well-established sets of moral dilemmas across two conditions: (1) Solo, where models reasoned independently, and (2) Group, where they engaged in multi-turn discussions in pairs or triads. In personal moral dilemmas, where agents must decide to directly harm one individual to maximize the utility for others, all models found moral violations to be more acceptable when part of a group than individually, similar to human experiments. Some models endorsed actions that maximized overall well-being, even if they benefited strangers over familiar individuals. Others became more willing to violate moral norms in groups. However, while human groups show a similar action bias, the mechanism for their utilitarian boost differs from LLMs. Whereas the human shift comes from heightened sensitivity to decision outcomes, LLM groups show either reduced norm sensitivity or enhanced impartiality. This suggests that while the surface behavior of LLM collectives mimics human group reasoning, the underlying drivers differ. We discuss the implications for AI alignment, multi-agent design, and artificial moral reasoning.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "comments": "9 pages, 8 Figures, 7 tables", "pdf_url": "https://arxiv.org/pdf/2507.00814.pdf", "abstract_url": "https://arxiv.org/abs/2507.00814", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)"], "matching_keywords": ["agent"], "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.00509", "title": "TeamCMU at Touché: Adversarial Co-Evolution for Advertisement Integration and Detection in Conversational Search", "authors": ["To Eun Kim", "João Coelho", "Gbemileke Onilude", "Jai Singh"], "abstract": "As conversational search engines increasingly adopt generation-based paradigms powered by Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG), the integration of advertisements into generated responses presents both commercial opportunities and challenges for user experience. Unlike traditional search, where advertisements are clearly delineated, generative systems blur the boundary between informational content and promotional material, raising concerns around transparency and trust. In this work, we propose a modular pipeline for advertisement management in RAG-based conversational systems, consisting of an ad-rewriter for seamless ad integration and a robust ad-classifier for detection. We leverage synthetic data to train high-performing classifiers, which are then used to guide two complementary ad-integration strategies: supervised fine-tuning of the ad-rewriter and a best-of-N sampling approach that selects the least detectable ad-integrated response among multiple candidates. Our evaluation focuses on two core questions: the effectiveness of ad classifiers in detecting diverse ad integration strategies, and the training methods that best support coherent, minimally intrusive ad insertion. Experimental results show that our ad-classifier, trained on synthetic advertisement data inspired by marketing strategies and enhanced through curriculum learning, achieves robust detection performance. Additionally, we demonstrate that classifier-guided optimization, through both fine-tuning and best-of-N sampling, significantly improves ad stealth, enabling more seamless integration. These findings contribute an adversarial co-evolution framework for developing more sophisticated ad-aware generative search systems and robust ad classifiers.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.00509.pdf", "abstract_url": "https://arxiv.org/abs/2507.00509", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.00210", "title": "LineRetriever: Planning-Aware Observation Reduction for Web Agents", "authors": ["Imene Kerboua", "Sahar Omidi Shayegan", "Megh Thakkar", "Xing Han Lù", "Massimo Caccia", "Véronique Eglin", "Alexandre Aussem", "Jérémy Espinas", "Alexandre Lacoste"], "abstract": "While large language models have demonstrated impressive capabilities in web navigation tasks, the extensive context of web pages, often represented as DOM or Accessibility Tree (AxTree) structures, frequently exceeds model context limits. Current approaches like bottom-up truncation or embedding-based retrieval lose critical information about page state and action history. This is particularly problematic for adaptive planning in web agents, where understanding the current state is essential for determining future actions. We hypothesize that embedding models lack sufficient capacity to capture plan-relevant information, especially when retrieving content that supports future action prediction. This raises a fundamental question: how can retrieval methods be optimized for adaptive planning in web navigation tasks? In response, we introduce \\textit{LineRetriever}, a novel approach that leverages a language model to identify and retrieve observation lines most relevant to future navigation steps. Unlike traditional retrieval methods that focus solely on semantic similarity, \\textit{LineRetriever} explicitly considers the planning horizon, prioritizing elements that contribute to action prediction. Our experiments demonstrate that \\textit{LineRetriever} can reduce the size of the observation at each step for the web agent while maintaining consistent performance within the context limitations.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.00210.pdf", "abstract_url": "https://arxiv.org/abs/2507.00210", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2507.00081", "title": "State and Memory is All You Need for Robust and Reliable AI Agents", "authors": ["Matthew Muhoberac", "Atharva Parikh", "Nirvi Vakharia", "Saniya Virani", "Aco Radujevic", "Savannah Wood", "Meghav Verma", "Dimitri Metaxotos", "Jeyaraman Soundararajan", "Thierry Masquelin", "Alexander G. Godfrey", "Sean Gardner", "Dobrila Rudnicki", "Sam Michael", "Gaurav Chopra"], "abstract": "Large language models (LLMs) have enabled powerful advances in natural language understanding and generation. Yet their application to complex, real-world scientific workflows remain limited by challenges in memory, planning, and tool integration. Here, we introduce SciBORG (Scientific Bespoke Artificial Intelligence Agents Optimized for Research Goals), a modular agentic framework that allows LLM-based agents to autonomously plan, reason, and achieve robust and reliable domain-specific task execution. Agents are constructed dynamically from source code documentation and augmented with finite-state automata (FSA) memory, enabling persistent state tracking and context-aware decision-making. This approach eliminates the need for manual prompt engineering and allows for robust, scalable deployment across diverse applications via maintaining context across extended workflows and to recover from tool or execution failures. We validate SciBORG through integration with both physical and virtual hardware, such as microwave synthesizers for executing user-specified reactions, with context-aware decision making and demonstrate its use in autonomous multi-step bioassay retrieval from the PubChem database utilizing multi-step planning, reasoning, agent-to-agent communication and coordination for execution of exploratory tasks. Systematic benchmarking shows that SciBORG agents achieve reliable execution, adaptive planning, and interpretable state transitions. Our results show that memory and state awareness are critical enablers of agentic planning and reliability, offering a generalizable foundation for deploying AI agents in complex environments.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Emerging Technologies (cs.ET); Chemical Physics (physics.chem-ph)", "comments": "5 Main Figures, 10 Extended Data Figures (37 Pages) for Manuscript ; 9 Supplementary Tables, 40 Supplementary Figures (180 Pages) for Supporting Information", "pdf_url": "https://arxiv.org/pdf/2507.00081.pdf", "abstract_url": "https://arxiv.org/abs/2507.00081", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Emerging Technologies (cs.ET)", "Chemical Physics (physics.chem-ph)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了SciBORG，一个模块化的代理框架，旨在通过增强大型语言模型（LLMs）的记忆、规划和工具集成能力，实现复杂科学工作流程中的自主规划和可靠执行。", "motivation": "解决大型语言模型在复杂、真实世界科学工作流程中应用受限的问题，特别是在记忆、规划和工具集成方面的挑战。", "method": "引入SciBORG框架，通过动态构建代理、增强有限状态自动机（FSA）记忆，实现持久状态跟踪和上下文感知决策，无需手动提示工程。", "result": "SciBORG代理在物理和虚拟硬件集成中展示了可靠的执行、自适应规划和可解释的状态转换，特别是在多步生物测定检索等任务中。", "conclusion": "记忆和状态意识是代理规划和可靠性的关键推动因素，为在复杂环境中部署AI代理提供了通用基础。"}}
{"id": "2507.00875", "title": "TransLaw: Benchmarking Large Language Models in Multi-Agent Simulation of the Collaborative Translation", "authors": ["Xi Xuan", "King-kui Sin", "Yufei Zhou", "Chunyu Kit"], "abstract": "Multi-agent systems empowered by large language models (LLMs) have demonstrated remarkable capabilities in a wide range of downstream applications, including machine translation. However, the potential of LLMs in translating Hong Kong legal judgments remains uncertain due to challenges such as intricate legal terminology, culturally embedded nuances, and strict linguistic structures. In this work, we introduce TransLaw, a novel multi-agent framework implemented for real-world Hong Kong case law translation. It employs three specialized agents, namely, Translator, Annotator, and Proofreader, to collaboratively produce translations for high accuracy in legal meaning, appropriateness in style, and adequate coherence and cohesion in structure. This framework supports customizable LLM configurations and achieves tremendous cost reduction compared to professional human translation services. We evaluated its performance using 13 open-source and commercial LLMs as agents and obtained interesting findings, including that it surpasses GPT-4o in legal semantic accuracy, structural coherence, and stylistic fidelity, yet trails human experts in contextualizing complex terminology and stylistic naturalness. Our platform website is available at CityUHK, and our bilingual judgment corpus used for the evaluation is available at Hugging Face.", "subjects": "Computation and Language (cs.CL); Human-Computer Interaction (cs.HC); Multiagent Systems (cs.MA)", "comments": "by other authors", "pdf_url": "https://arxiv.org/pdf/2507.00875.pdf", "abstract_url": "https://arxiv.org/abs/2507.00875", "categories": ["Computation and Language (cs.CL)", "Human-Computer Interaction (cs.HC)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "TransLaw是一个新颖的多智能体框架，专为香港判例法翻译设计，通过三个专业智能体协作，实现高准确性的法律翻译。", "motivation": "解决大型语言模型在香港法律判决翻译中面临的复杂法律术语、文化嵌入细微差别和严格语言结构等挑战。", "method": "采用Translator、Annotator和Proofreader三个专业智能体协作的多智能体框架，支持可定制的LLM配置。", "result": "TransLaw在法律语义准确性、结构连贯性和风格保真度上超越GPT-4o，但在复杂术语的语境化和风格自然度上仍落后于人类专家。", "conclusion": "TransLaw框架在降低成本的同时，提高了翻译质量，为法律翻译领域提供了新的解决方案。"}}
{"id": "2507.00045", "title": "CaughtCheating: Is Your MLLM a Good Cheating Detective? Exploring the Boundary of Visual Perception and Reasoning", "authors": ["Ming Li", "Chenguang Wang", "Yijun Liang", "Xiyao Wang", "Yuhang Zhou", "Xiyang Wu", "Yuqing Zhang", "Ruiyi Zhang", "Tianyi Zhou"], "abstract": "Recent agentic Multi-Modal Large Language Models (MLLMs) such as GPT-o3 have achieved near-ceiling scores on various existing benchmarks, motivating a demand for more challenging test tasks. These MLLMs have been reported to excel in a few expert-level tasks for humans, e.g., GeoGuesser, reflecting their potential as a detective who can notice minuscule cues in an image and weave them into coherent, situational explanations, leading to a reliable answer. But can they match the performance of excellent human detectives? To answer this question, we investigate some hard scenarios where GPT-o3 can still handle, and find a common scenario where o3's performance drops to nearly zero, which we name CaughtCheating. It is inspired by the social media requests that ask others to detect suspicious clues from photos shared by the poster's partner. We conduct extensive experiments and analysis to understand why existing MLLMs lack sufficient capability to solve this kind of task. CaughtCheating provides a class of challenging visual perception and reasoning tasks with great value and practical usage. Success in these tasks paves the way for MLLMs to acquire human-level detective perception and reasoning capabilities.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.00045.pdf", "abstract_url": "https://arxiv.org/abs/2507.00045", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文探讨了多模态大型语言模型（MLLMs）在视觉感知和推理任务中的表现，特别是在名为CaughtCheating的挑战性场景中，发现其性能显著下降。", "motivation": "随着MLLMs在现有基准测试中接近满分，需要更具挑战性的任务来测试其极限。本文旨在探索MLLMs在复杂视觉感知和推理任务中的能力，特别是在模拟社交媒体上请求他人从照片中检测可疑线索的场景中。", "method": "通过设计一个名为CaughtCheating的挑战性场景，进行广泛的实验和分析，以理解现有MLLMs在此类任务中能力不足的原因。", "result": "研究发现，在CaughtCheating场景中，GPT-o3的性能降至几乎为零，揭示了MLLMs在特定视觉感知和推理任务中的局限性。", "conclusion": "CaughtCheating提供了一类具有重大价值和实际用途的挑战性视觉感知和推理任务。成功解决这些任务将为MLLMs获得人类级别的侦探感知和推理能力铺平道路。"}}
{"id": "2507.00432", "title": "Does Math Reasoning Improve General LLM Capabilities? Understanding Transferability of LLM Reasoning", "authors": ["Maggie Huan", "Yuetai Li", "Tuney Zheng", "Xiaoyu Xu", "Seungone Kim", "Minxin Du", "Radha Poovendran", "Graham Neubig", "Xiang Yue"], "abstract": "Math reasoning has become the poster child of progress in large language models (LLMs), with new models rapidly surpassing human-level performance on benchmarks like MATH and AIME. But as math leaderboards improve week by week, it is worth asking: do these gains reflect broader problem-solving ability or just narrow overfitting? To answer this question, we evaluate over 20 open-weight reasoning-tuned models across a broad suite of tasks, including math, scientific QA, agent planning, coding, and standard instruction-following. We surprisingly find that most models that succeed in math fail to transfer their gains to other domains. To rigorously study this phenomenon, we conduct controlled experiments on Qwen3-14B models using math-only data but different tuning methods. We find that reinforcement learning (RL)-tuned models generalize well across domains, while supervised fine-tuning (SFT)-tuned models often forget general capabilities. Latent-space representation and token-space distribution shift analyses reveal that SFT induces substantial representation and output drift, while RL preserves general-domain structure. Our results suggest a need to rethink standard post-training recipes, particularly the reliance on SFT-distilled data for advancing reasoning models.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.00432.pdf", "abstract_url": "https://arxiv.org/abs/2507.00432", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了数学推理能力的提升是否能够普遍提高大型语言模型（LLM）的能力，通过评估20多个开放权重的推理调整模型，发现大多数在数学上成功的模型无法将这种优势转移到其他领域。通过对比实验，发现强化学习调整的模型在跨领域泛化能力上表现更好，而监督微调调整的模型往往会遗忘一般能力。", "motivation": "研究数学推理能力的提升是否能够普遍提高LLM的能力，以及这种提升是否仅仅是对特定领域的过拟合。", "method": "评估了超过20个开放权重的推理调整模型在包括数学、科学问答、代理规划、编码和标准指令跟随等广泛任务上的表现，并对Qwen3-14B模型进行了控制实验，比较了不同调整方法的效果。", "result": "大多数在数学上成功的模型无法将这种优势转移到其他领域。强化学习调整的模型在跨领域泛化能力上表现更好，而监督微调调整的模型往往会遗忘一般能力。潜在空间表示和令牌空间分布偏移分析显示，监督微调导致显著的表示和输出偏移，而强化学习保留了通用领域的结构。", "conclusion": "研究结果表明需要重新思考标准的后训练方法，特别是依赖监督微调蒸馏数据来推进推理模型的进步。"}}
{"id": "2507.00079", "title": "VoyagerVision: Investigating the Role of Multi-modal Information for Open-ended Learning Systems", "authors": ["Ethan Smyth", "Alessandro Suglia"], "abstract": "Open-endedness is an active field of research in the pursuit of capable Artificial General Intelligence (AGI), allowing models to pursue tasks of their own choosing. Simultaneously, recent advancements in Large Language Models (LLMs) such as GPT-4o [9] have allowed such models to be capable of interpreting image inputs. Implementations such as OMNI-EPIC [4] have made use of such features, providing an LLM with pixel data of an agent's POV to parse the environment and allow it to solve tasks. This paper proposes that providing these visual inputs to a model gives it greater ability to interpret spatial environments, and as such, can increase the number of tasks it can successfully perform, extending its open-ended potential. To this aim, this paper proposes VoyagerVision -- a multi-modal model capable of creating structures within Minecraft using screenshots as a form of visual feedback, building on the foundation of Voyager. VoyagerVision was capable of creating an average of 2.75 unique structures within fifty iterations of the system, as Voyager was incapable of this, it is an extension in an entirely new direction. Additionally, in a set of building unit tests VoyagerVision was successful in half of all attempts in flat worlds, with most failures arising in more complex structures. Project website is available at", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2507.00079.pdf", "abstract_url": "https://arxiv.org/abs/2507.00079", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了VoyagerVision，一个多模态模型，旨在通过视觉反馈增强开放学习系统的能力，特别是在Minecraft中创建结构。", "motivation": "研究开放学习系统在追求人工通用智能（AGI）中的作用，特别是如何通过多模态信息（如视觉输入）增强模型的空间理解能力，从而扩展其开放学习潜力。", "method": "提出VoyagerVision模型，该模型基于Voyager，能够利用截图作为视觉反馈，在Minecraft中创建结构。", "result": "VoyagerVision在五十次系统迭代中平均能创建2.75个独特结构，而Voyager无法做到这一点。在平坦世界的构建单元测试中，VoyagerVision的成功率为50%，但在更复杂的结构中失败较多。", "conclusion": "通过引入视觉反馈，VoyagerVision能够扩展开放学习系统的能力，特别是在空间任务中，尽管在复杂结构上仍有改进空间。"}}
{"id": "2507.00180", "title": "BlackBoxToBlueprint: Extracting Interpretable Logic from Legacy Systems using Reinforcement Learning and Counterfactual Analysis", "authors": ["Vidhi Rathore"], "abstract": "Modernizing legacy software systems is a critical but challenging task, often hampered by a lack of documentation and understanding of the original system's intricate decision logic. Traditional approaches like behavioral cloning merely replicate input-output behavior without capturing the underlying intent. This paper proposes a novel pipeline to automatically extract interpretable decision logic from legacy systems treated as black boxes. The approach uses a Reinforcement Learning (RL) agent to explore the input space and identify critical decision boundaries by rewarding actions that cause meaningful changes in the system's output. These counterfactual state transitions, where the output changes, are collected and clustered using K-Means. Decision trees are then trained on these clusters to extract human-readable rules that approximate the system's decision logic near the identified boundaries. I demonstrated the pipeline's effectiveness on three dummy legacy systems with varying complexity, including threshold-based, combined-conditional, and non-linear range logic. Results show that the RL agent successfully focuses exploration on relevant boundary regions, and the extracted rules accurately reflect the core logic of the underlying dummy systems, providing a promising foundation for generating specifications and test cases during legacy migration.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.00180.pdf", "abstract_url": "https://arxiv.org/abs/2507.00180", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新颖的流程，通过强化学习和反事实分析从被视为黑盒的遗留系统中自动提取可解释的决策逻辑。该方法在三个不同复杂度的虚拟遗留系统上展示了其有效性。", "motivation": "遗留软件系统的现代化是一个关键但具有挑战性的任务，常常由于缺乏文档和对原始系统复杂决策逻辑的理解而受阻。传统方法如行为克隆仅复制输入输出行为，而未能捕捉到底层的意图。", "method": "该方法使用强化学习（RL）代理探索输入空间，并通过奖励导致系统输出有意义变化的动作来识别关键决策边界。这些反事实状态转换被收集并使用K-Means进行聚类。然后，在这些聚类上训练决策树，以提取近似系统在识别边界附近决策逻辑的人类可读规则。", "result": "结果表明，RL代理成功地将探索集中在相关的边界区域，提取的规则准确反映了底层虚拟系统的核心逻辑，为在遗留迁移期间生成规范和测试用例提供了有希望的基础。", "conclusion": "本文提出的流程有效地从遗留系统中提取了可解释的决策逻辑，为系统现代化提供了新的工具和方法。"}}
{"id": "2507.00841", "title": "SafeMobile: Chain-level Jailbreak Detection and Automated Evaluation for Multimodal Mobile Agents", "authors": ["Siyuan Liang", "Tianmeng Fang", "Zhe Liu", "Aishan Liu", "Yan Xiao", "Jinyuan He", "Ee-Chien Chang", "Xiaochun Cao"], "abstract": "With the wide application of multimodal foundation models in intelligent agent systems, scenarios such as mobile device control, intelligent assistant interaction, and multimodal task execution are gradually relying on such large model-driven agents. However, the related systems are also increasingly exposed to potential jailbreak risks. Attackers may induce the agents to bypass the original behavioral constraints through specific inputs, and then trigger certain risky and sensitive operations, such as modifying settings, executing unauthorized commands, or impersonating user identities, which brings new challenges to system security. Existing security measures for intelligent agents still have limitations when facing complex interactions, especially in detecting potentially risky behaviors across multiple rounds of conversations or sequences of tasks. In addition, an efficient and consistent automated methodology to assist in assessing and determining the impact of such risks is currently lacking. This work explores the security issues surrounding mobile multimodal agents, attempts to construct a risk discrimination mechanism by incorporating behavioral sequence information, and designs an automated assisted assessment scheme based on a large language model. Through preliminary validation in several representative high-risk tasks, the results show that the method can improve the recognition of risky behaviors to some extent and assist in reducing the probability of agents being jailbroken. We hope that this study can provide some valuable references for the security risk modeling and protection of multimodal intelligent agent systems.", "subjects": "Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)", "comments": "12 pages", "pdf_url": "https://arxiv.org/pdf/2507.00841.pdf", "abstract_url": "https://arxiv.org/abs/2507.00841", "categories": ["Artificial Intelligence (cs.AI)", "Cryptography and Security (cs.CR)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了多模态移动代理的安全问题，提出了一种结合行为序列信息的风险识别机制，并设计了一个基于大型语言模型的自动化辅助评估方案，以提高对风险行为的识别并减少代理被越狱的概率。", "motivation": "随着多模态基础模型在智能代理系统中的广泛应用，相关系统面临越来越多的越狱风险，现有安全措施在复杂交互中仍有限制，缺乏有效的自动化评估方法。", "method": "通过构建结合行为序列信息的风险识别机制，并设计基于大型语言模型的自动化辅助评估方案。", "result": "初步验证表明，该方法能在一定程度上提高对风险行为的识别，并有助于降低代理被越狱的概率。", "conclusion": "本研究为多模态智能代理系统的安全风险建模和保护提供了有价值的参考。"}}
{"id": "2507.00979", "title": "Enhancing LLM Agent Safety via Causal Influence Prompting", "authors": ["Dongyoon Hahm", "Woogyeol Jin", "June Suk Choi", "Sungsoo Ahn", "Kimin Lee"], "abstract": "As autonomous agents powered by large language models (LLMs) continue to demonstrate potential across various assistive tasks, ensuring their safe and reliable behavior is crucial for preventing unintended consequences. In this work, we introduce CIP, a novel technique that leverages causal influence diagrams (CIDs) to identify and mitigate risks arising from agent decision-making. CIDs provide a structured representation of cause-and-effect relationships, enabling agents to anticipate harmful outcomes and make safer decisions. Our approach consists of three key steps: (1) initializing a CID based on task specifications to outline the decision-making process, (2) guiding agent interactions with the environment using the CID, and (3) iteratively refining the CID based on observed behaviors and outcomes. Experimental results demonstrate that our method effectively enhances safety in both code execution and mobile device control tasks.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2507.00979.pdf", "abstract_url": "https://arxiv.org/abs/2507.00979", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一种名为CIP的新技术，利用因果影响图（CIDs）来识别和减轻由大型语言模型（LLM）驱动的自主代理在决策过程中可能产生的风险，以提高其安全性。", "motivation": "随着由大型语言模型驱动的自主代理在各种辅助任务中展现出潜力，确保它们的安全和可靠行为对于防止意外后果至关重要。", "method": "该方法包括三个关键步骤：（1）基于任务规范初始化CID以概述决策过程，（2）使用CID指导代理与环境的交互，（3）根据观察到的行为和结果迭代优化CID。", "result": "实验结果表明，该方法在代码执行和移动设备控制任务中有效提高了安全性。", "conclusion": "通过引入CIP技术，本研究为增强LLM代理的安全性提供了一种有效的方法，有助于预防潜在的危害和意外后果。"}}
{"id": "2507.00951", "title": "Thinking Beyond Tokens: From Brain-Inspired Intelligence to Cognitive Foundations for Artificial General Intelligence and its Societal Impact", "authors": ["Rizwan Qureshi", "Ranjan Sapkota", "Abbas Shah", "Amgad Muneer", "Anas Zafar", "Ashmal Vayani", "Maged Shoman", "Abdelrahman B. M. Eldaly", "Kai Zhang", "Ferhat Sadak", "Shaina Raza", "Xinqi Fan", "Ravid Shwartz-Ziv", "Hong Yan", "Vinjia Jain", "Aman Chadha", "Manoj Karkee", "Jia Wu", "Philip Torr", "Seyedali Mirjalili"], "abstract": "Can machines truly think, reason and act in domains like humans? This enduring question continues to shape the pursuit of Artificial General Intelligence (AGI). Despite the growing capabilities of models such as GPT-4.5, DeepSeek, Claude 3.5 Sonnet, Phi-4, and Grok 3, which exhibit multimodal fluency and partial reasoning, these systems remain fundamentally limited by their reliance on token-level prediction and lack of grounded agency. This paper offers a cross-disciplinary synthesis of AGI development, spanning artificial intelligence, cognitive neuroscience, psychology, generative models, and agent-based systems. We analyze the architectural and cognitive foundations of general intelligence, highlighting the role of modular reasoning, persistent memory, and multi-agent coordination. In particular, we emphasize the rise of Agentic RAG frameworks that combine retrieval, planning, and dynamic tool use to enable more adaptive behavior. We discuss generalization strategies, including information compression, test-time adaptation, and training-free methods, as critical pathways toward flexible, domain-agnostic intelligence. Vision-Language Models (VLMs) are reexamined not just as perception modules but as evolving interfaces for embodied understanding and collaborative task completion. We also argue that true intelligence arises not from scale alone but from the integration of memory and reasoning: an orchestration of modular, interactive, and self-improving components where compression enables adaptive behavior. Drawing on advances in neurosymbolic systems, reinforcement learning, and cognitive scaffolding, we explore how recent architectures begin to bridge the gap between statistical learning and goal-directed cognition. Finally, we identify key scientific, technical, and ethical challenges on the path to AGI.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.00951.pdf", "abstract_url": "https://arxiv.org/abs/2507.00951", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic", "@RAG"], "AI": {"tldr": "本文探讨了人工通用智能（AGI）的发展，分析了当前模型的局限性，并提出了跨学科的合成方法，包括模块化推理、持久记忆和多智能体协调，以实现更灵活、领域无关的智能。", "motivation": "解决当前AI模型在令牌级预测和缺乏基础代理方面的根本限制，推动AGI的发展。", "method": "结合人工智能、认知神经科学、心理学、生成模型和基于代理的系统，分析通用智能的架构和认知基础。", "result": "提出了Agentic RAG框架和视觉语言模型（VLMs）的新视角，强调了记忆与推理的整合对真正智能的重要性。", "conclusion": "通过神经符号系统、强化学习和认知支架的进步，探索了统计学习与目标导向认知之间的桥梁，并指出了AGI路径上的关键科学、技术和伦理挑战。"}}
{"id": "2507.00014", "title": "SWE-Bench-CL: Continual Learning for Coding Agents", "authors": ["Thomas Joshi", "Shayan Chowdhury", "Fatih Uysal"], "abstract": "Large Language Models (LLMs) have achieved impressive results on static code-generation benchmarks, but real-world software development unfolds as a continuous stream of evolving issues, fixes, and feature requests. We introduce SWE-Bench-CL, a novel continual learning benchmark built on the human-verified SWE-Bench Verified dataset introduced by OpenAI and Princeton-NLP in 2024. By organizing GitHub issues into chronologically ordered sequences that reflect natural repository evolution, SWE-Bench-CL enables direct evaluation of an agent's ability to accumulate experience, transfer knowledge across tasks, and resist catastrophic forgetting. We complement the dataset with (i) a preliminary analysis of inter-task structural similarity and contextual sensitivity, (ii) an interactive LangGraph-based evaluation framework augmented with a FAISS-backed semantic memory module, and (iii) a suite of specialized continual learning metrics -- including average accuracy, forgetting, forward/backward transfer, tool-use efficiency, and a generalized Composite Continual Learning Score and CL-F-beta score -- to capture the stability-plasticity trade-off. We outline a rigorous experimental protocol comparing memory-enabled and memory-disabled agents across diverse Python repositories. All code and data are publicly available at", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Software Engineering (cs.SE)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.00014.pdf", "abstract_url": "https://arxiv.org/abs/2507.00014", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Software Engineering (cs.SE)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了SWE-Bench-CL，一个基于OpenAI和Princeton-NLP 2024年引入的人类验证SWE-Bench Verified数据集构建的新型持续学习基准。通过将GitHub问题按时间顺序组织以反映自然仓库演变，SWE-Bench-CL直接评估代理积累经验、跨任务转移知识和抵抗灾难性遗忘的能力。", "motivation": "解决大型语言模型（LLMs）在静态代码生成基准上表现优异，但在现实世界软件开发中作为连续流演变的挑战。", "method": "引入SWE-Bench-CL基准，包括(i)初步分析任务间结构相似性和上下文敏感性，(ii)增强FAISS支持语义记忆模块的交互式LangGraph评估框架，(iii)一套专门的持续学习指标。", "result": "通过比较启用和禁用记忆的代理在不同Python仓库中的表现，提出了一套严格的实验协议。", "conclusion": "SWE-Bench-CL为评估编码代理的持续学习能力提供了全面的框架和工具，所有代码和数据公开可用。"}}
{"id": "2507.00472", "title": "ARIG: Autoregressive Interactive Head Generation for Real-time Conversations", "authors": ["Ying Guo", "Xi Liu", "Cheng Zhen", "Pengfei Yan", "Xiaoming Wei"], "abstract": "Face-to-face communication, as a common human activity, motivates the research on interactive head generation. A virtual agent can generate motion responses with both listening and speaking capabilities based on the audio or motion signals of the other user and itself. However, previous clip-wise generation paradigm or explicit listener/speaker generator-switching methods have limitations in future signal acquisition, contextual behavioral understanding, and switching smoothness, making it challenging to be real-time and realistic. In this paper, we propose an autoregressive (AR) based frame-wise framework called ARIG to realize the real-time generation with better interaction realism. To achieve real-time generation, we model motion prediction as a non-vector-quantized AR process. Unlike discrete codebook-index prediction, we represent motion distribution using diffusion procedure, achieving more accurate predictions in continuous space. To improve interaction realism, we emphasize interactive behavior understanding (IBU) and detailed conversational state understanding (CSU). In IBU, based on dual-track dual-modal signals, we summarize short-range behaviors through bidirectional-integrated learning and perform contextual understanding over long ranges. In CSU, we use voice activity signals and context features of IBU to understand the various states (interruption, feedback, pause, etc.) that exist in actual conversations. These serve as conditions for the final progressive motion prediction. Extensive experiments have verified the effectiveness of our model.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2507.00472.pdf", "abstract_url": "https://arxiv.org/abs/2507.00472", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为ARIG的自回归交互式头部生成框架，旨在实现实时且更具交互真实感的对话。通过非向量量化的自回归过程和扩散程序建模运动预测，以及在交互行为理解和详细对话状态理解上的创新，ARIG在实时生成和交互真实感方面表现出色。", "motivation": "面对面的交流是人类常见的活动，这激发了交互式头部生成的研究。虚拟代理需要基于自身和对方的音频或运动信号，生成具有听和说能力的运动响应。然而，之前的片段式生成范式或显式的听者/说者生成器切换方法在未来信号获取、上下文行为理解和切换平滑度方面存在局限，难以实现实时和真实感。", "method": "本文提出了一个基于自回归（AR）的帧级框架ARIG，通过非向量量化的自回归过程建模运动预测，并在连续空间中使用扩散程序实现更准确的预测。为了提高交互真实感，强调了交互行为理解（IBU）和详细对话状态理解（CSU）。在IBU中，基于双轨双模态信号，通过双向集成学习总结短程行为，并在长程上进行上下文理解。在CSU中，利用语音活动信号和IBU的上下文特征来理解实际对话中存在的各种状态（如打断、反馈、暂停等），这些作为最终渐进式运动预测的条件。", "result": "大量实验验证了我们模型的有效性。", "conclusion": "ARIG框架通过创新的自回归和扩散过程建模，以及在交互行为和对话状态理解上的深入工作，成功实现了实时且更具交互真实感的头部生成，为虚拟代理的交互能力提供了新的研究方向。"}}
{"id": "2507.00096", "title": "AI-Governed Agent Architecture for Web-Trustworthy Tokenization of Alternative Assets", "authors": ["Ailiya Borjigin", "Wei Zhou", "Cong He"], "abstract": "Alternative Assets tokenization is transforming non-traditional financial instruments are represented and traded on the web. However, ensuring trustworthiness in web-based tokenized ecosystems poses significant challenges, from verifying off-chain asset data to enforcing regulatory compliance. This paper proposes an AI-governed agent architecture that integrates intelligent agents with blockchain to achieve web-trustworthy tokenization of alternative assets. In the proposed architecture, autonomous agents orchestrate the tokenization process (asset verification, valuation, compliance checking, and lifecycle management), while an AI-driven governance layer monitors agent behavior and enforces trust through adaptive policies and cryptoeconomic incentives. We demonstrate that this approach enhances transparency, security, and compliance in asset tokenization, addressing key concerns around data authenticity and fraud. A case study on tokenizing real estate assets illustrates how the architecture mitigates risks (e.g., fraudulent listings and money laundering) through real-time AI anomaly detection and on-chain enforcement. Our evaluation and analysis suggest that combining AI governance with multi-agent systems and blockchain can significantly bolster trust in tokenized asset ecosystems. This work offers a novel framework for trustworthy asset tokenization on the web and provides insights for practitioners aiming to deploy secure, compliant tokenization platforms.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": "8 Pages, 1 figure", "pdf_url": "https://arxiv.org/pdf/2507.00096.pdf", "abstract_url": "https://arxiv.org/abs/2507.00096", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种AI治理的代理架构，用于实现网络可信的替代资产代币化，通过智能代理与区块链技术的结合，增强透明度、安全性和合规性。", "motivation": "解决网络基于代币化生态系统中确保可信度的挑战，包括验证链外资产数据和执行监管合规。", "method": "采用AI治理的代理架构，自主代理协调代币化过程，AI驱动的治理层监控代理行为并通过自适应策略和密码经济激励执行信任。", "result": "该方法在资产代币化中提高了透明度、安全性和合规性，有效解决了数据真实性和欺诈等关键问题。", "conclusion": "结合AI治理、多代理系统和区块链技术，可以显著增强代币化资产生态系统的信任，为部署安全、合规的代币化平台提供了新的框架和见解。"}}
{"id": "2507.00980", "title": "RTMap: Real-Time Recursive Mapping with Change Detection and Localization", "authors": ["Yuheng Du", "Sheng Yang", "Lingxuan Wang", "Zhenghua Hou", "Chengying Cai", "Zhitao Tan", "Mingxia Chen", "Shi-Sheng Huang", "Qiang Li"], "abstract": "While recent online HD mapping methods relieve burdened offline pipelines and solve map freshness, they remain limited by perceptual inaccuracies, occlusion in dense traffic, and an inability to fuse multi-agent observations. We propose RTMap to enhance these single-traversal methods by persistently crowdsourcing a multi-traversal HD map as a self-evolutional memory. On onboard agents, RTMap simultaneously addresses three core challenges in an end-to-end fashion: (1) Uncertainty-aware positional modeling for HD map elements, (2) probabilistic-aware localization w.r.t. the crowdsourced prior-map, and (3) real-time detection for possible road structural changes. Experiments on several public autonomous driving datasets demonstrate our solid performance on both the prior-aided map quality and the localization accuracy, demonstrating our effectiveness of robustly serving downstream prediction and planning modules while gradually improving the accuracy and freshness of the crowdsourced prior-map asynchronously. Our source-code will be made publicly available at", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.00980.pdf", "abstract_url": "https://arxiv.org/abs/2507.00980", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "RTMap提出了一种实时递归映射方法，通过多遍历高精地图众包作为自我进化记忆，解决了单次遍历方法在感知不准确、密集交通中的遮挡以及无法融合多智能体观察方面的限制。", "motivation": "解决现有在线高精地图方法在感知不准确、密集交通中的遮挡以及无法融合多智能体观察方面的限制。", "method": "RTMap通过端到端的方式同时解决了三个核心挑战：高精地图元素的不确定性感知位置建模、相对于众包先验地图的概率感知定位以及实时检测可能的道路结构变化。", "result": "在多个公开自动驾驶数据集上的实验表明，RTMap在先验辅助地图质量和定位准确性方面表现优异，有效支持下游预测和规划模块，同时异步提高众包先验地图的准确性和新鲜度。", "conclusion": "RTMap通过实时递归映射和变化检测，提高了高精地图的质量和新鲜度，为自动驾驶提供了更可靠的先验地图支持。"}}
{"id": "2507.01006", "title": "GLM-4.1V-Thinking: Towards Versatile Multimodal Reasoning with Scalable Reinforcement Learning", "authors": ["Wenyi Hong", "Wenmeng Yu", "Xiaotao Gu", "Guo Wang", "Guobing Gan", "Haomiao Tang", "Jiale Cheng", "Ji Qi", "Junhui Ji", "Lihang Pan", "Shuaiqi Duan", "Weihan Wang", "Yan Wang", "Yean Cheng", "Zehai He", "Zhe Su", "Zhen Yang", "Ziyang Pan", "Aohan Zeng", "Baoxu Wang", "Boyan Shi", "Changyu Pang", "Chenhui Zhang", "Da Yin", "Fan Yang", "Guoqing Chen", "Jiazheng Xu", "Jiali Chen", "Jing Chen", "Jinhao Chen", "Jinghao Lin", "Jinjiang Wang", "Junjie Chen", "Leqi Lei", "Leyi Pan", "Mingzhi Zhang", "Qinkai Zheng", "Sheng Yang", "Shi Zhong", "Shiyu Huang", "Shuyuan Zhao", "Siyan Xue", "Shangqin Tu", "Shengbiao Meng", "Tianshu Zhang", "Tianwei Luo", "Tianxiang Hao", "Tianle Gong", "Wenkai Li", "Wei Jia", "Xin Lyu", "Xuancheng Huang", "Yanling Wang", "Yadong Xue", "Yanfeng Wang", "Yifan An", "Yifan Du", "Yiming Shi", "Yiheng Huang", "Yilin Niu", "Yuan Wang", "Yuanchang Yue", "Yuchen Li", "Yutao Zhang", "Yuxuan Zhang", "Zhanxiao Du", "Zhenyu Hou", "Zhao Xue", "Zhengxiao Du", "Zihan Wang", "Peng Zhang", "Debing Liu", "Bin Xu", "Juanzi Li", "Minlie Huang", "Yuxiao Dong", "Jie Tang"], "abstract": "We present GLM-4.1V-Thinking, a vision-language model (VLM) designed to advance general-purpose multimodal reasoning. In this report, we share our key findings in the development of the reasoning-centric training framework. We first develop a capable vision foundation model with significant potential through large-scale pre-training, which arguably sets the upper bound for the final performance. Reinforcement Learning with Curriculum Sampling (RLCS) then unlocks the full potential of the model, leading to comprehensive capability enhancement across a diverse range of tasks, including STEM problem solving, video understanding, content recognition, coding, grounding, GUI-based agents, and long document understanding, among others. To facilitate research in this field, we open-source GLM-4.1V-9B-Thinking, which achieves state-of-the-art performance among models of comparable size. In a comprehensive evaluation across 28 public benchmarks, our model outperforms Qwen2.5-VL-7B on nearly all tasks and achieves comparable or even superior performance on 18 benchmarks relative to the significantly larger Qwen2.5-VL-72B. Notably, GLM-4.1V-9B-Thinking also demonstrates competitive or superior performance compared to closed-source models such as GPT-4o on challenging tasks including long document understanding and STEM reasoning, further underscoring its strong capabilities. Code, models and more information are released at", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.01006.pdf", "abstract_url": "https://arxiv.org/abs/2507.01006", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "GLM-4.1V-Thinking是一种视觉语言模型（VLM），旨在推进通用多模态推理。通过大规模预训练和强化学习课程采样（RLCS）方法，该模型在多种任务上展现出全面的能力提升，并在28个公共基准测试中表现出色。", "motivation": "解决通用多模态推理的挑战，提升视觉语言模型在多样化任务上的性能。", "method": "采用大规模预训练构建视觉基础模型，并通过强化学习课程采样（RLCS）方法进一步优化模型性能。", "result": "GLM-4.1V-9B-Thinking在28个公共基准测试中表现优异，优于同类尺寸模型，并在某些任务上与更大模型或闭源模型如GPT-4o相媲美或更优。", "conclusion": "GLM-4.1V-Thinking通过创新的训练框架和强化学习方法，显著提升了多模态推理能力，为相关研究领域提供了强有力的工具和基准。"}}
{"id": "2507.00268", "title": "Control-Optimized Deep Reinforcement Learning for Artificially Intelligent Autonomous Systems", "authors": ["Oren Fivel", "Matan Rudman", "Kobi Cohen"], "abstract": "Deep reinforcement learning (DRL) has become a powerful tool for complex decision-making in machine learning and AI. However, traditional methods often assume perfect action execution, overlooking the uncertainties and deviations between an agent's selected actions and the actual system response. In real-world applications, such as robotics, mechatronics, and communication networks, execution mismatches arising from system dynamics, hardware constraints, and latency can significantly degrade performance. This work advances AI by developing a novel control-optimized DRL framework that explicitly models and compensates for action execution mismatches, a challenge largely overlooked in existing methods. Our approach establishes a structured two-stage process: determining the desired action and selecting the appropriate control signal to ensure proper execution. It trains the agent while accounting for action mismatches and controller corrections. By incorporating these factors into the training process, the AI agent optimizes the desired action with respect to both the actual control signal and the intended outcome, explicitly considering execution errors. This approach enhances robustness, ensuring that decision-making remains effective under real-world uncertainties. Our approach offers a substantial advancement for engineering practice by bridging the gap between idealized learning and real-world implementation. It equips intelligent agents operating in engineering environments with the ability to anticipate and adjust for actuation errors and system disturbances during training. We evaluate the framework in five widely used open-source mechanical simulation environments we restructured and developed to reflect real-world operating conditions, showcasing its robustness against uncertainties and offering a highly practical and efficient solution for control-oriented applications.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Systems and Control (eess.SY)", "comments": "27 pages, 10 figures", "pdf_url": "https://arxiv.org/pdf/2507.00268.pdf", "abstract_url": "https://arxiv.org/abs/2507.00268", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Systems and Control (eess.SY)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新颖的控制优化深度强化学习框架，旨在解决传统方法中忽视的动作执行不匹配问题，通过两阶段过程优化决策制定，增强在现实世界不确定性下的鲁棒性。", "motivation": "传统深度强化学习方法假设动作执行完美，忽视了实际应用中由于系统动态、硬件限制和延迟导致的动作执行不匹配，这在机器人学、机电一体化和通信网络等领域会显著降低性能。", "method": "开发了一个控制优化的深度强化学习框架，明确建模并补偿动作执行不匹配，包括确定期望动作和选择适当控制信号以确保正确执行的两阶段过程。", "result": "在五个广泛使用的开源机械仿真环境中评估该框架，展示了其对抗不确定性的鲁棒性，为控制导向的应用提供了高效实用的解决方案。", "conclusion": "该方法通过将执行误差和控制器校正纳入训练过程，显著推进了工程实践，弥合了理想化学习与现实世界实施之间的差距，使智能代理能够在训练中预测和调整执行误差和系统干扰。"}}
{"id": "2507.00347", "title": "VTS-Guided AI Interaction Workflow for Business Insights", "authors": ["Sun Ding", "Ude Enebeli", "Atilhan", "Manay", "Ryan Pua", "Kamal Kotak"], "abstract": "Modern firms face a flood of dense, unstructured reports. Turning these documents into usable insights takes heavy effort and is far from agile when quick answers are needed. VTS-AI tackles this gap. It integrates Visual Thinking Strategies, which emphasize evidence-based observation, linking, and thinking, into AI agents, so the agents can extract business insights from unstructured text, tables, and images at scale. The system works in three tiers (micro, meso, macro). It tags issues, links them to source pages, and rolls them into clear action levers stored in a searchable YAML file. In tests on an 18-page business report, VTS-AI matched the speed of a one-shot ChatGPT prompt yet produced richer findings: page locations, verbatim excerpts, severity scores, and causal links. Analysts can accept or adjust these outputs in the same IDE, keeping human judgment in the loop. Early results show VTS-AI spots the direction of key metrics and flags where deeper number-crunching is needed. Next steps include mapping narrative tags to financial ratios, adding finance-tuned language models through a Model-Context Protocol, and building a Risk & Safety Layer to stress-test models and secure data. These upgrades aim to make VTS-AI a production-ready, audit-friendly tool for rapid business analysis.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.00347.pdf", "abstract_url": "https://arxiv.org/abs/2507.00347", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "VTS-AI通过整合视觉思维策略到AI代理中，帮助企业从非结构化文本、表格和图像中提取业务洞察，实现快速分析。", "motivation": "现代企业面临大量密集、非结构化的报告，将这些文档转化为可用的洞察需要大量努力，且在需要快速答案时不够敏捷。", "method": "VTS-AI系统分为三个层次（微观、中观、宏观），标记问题，将其链接到源页面，并将它们汇总为清晰的操作杠杆，存储在可搜索的YAML文件中。", "result": "在18页的商业报告测试中，VTS-AI与一次性ChatGPT提示的速度相匹配，但产生了更丰富的发现：页面位置、逐字摘录、严重性评分和因果链接。", "conclusion": "早期结果显示，VTS-AI能够发现关键指标的方向并标记需要更深入数字分析的地方。下一步包括将叙事标签映射到财务比率，通过模型上下文协议添加金融调优语言模型，并构建风险和安全性层以压力测试模型和保护数据。"}}
{"id": "2507.00352", "title": "An AST-guided LLM Approach for SVRF Code Synthesis", "authors": ["Abanoub E. Abdelmalak", "Mohamed A. Elsayed", "David Abercrombie", "Ilhami Torunoglu"], "abstract": "Standard Verification Rule Format (SVRF) is essential for semiconductor applications like Design Rule Check (DRC), Layout Versus Schematic (LVS), and Optical Proximity Correction (OPC) and it faces challenges as advancing nodes create complex design rules that renders traditional SVRF development ineffective and highlight an expertise gap. This paper introduces a novel methodology integrating Abstract Syntax Tree (AST) embedding and Retrieval-Augmented Generation (RAG) for enhanced SVRF code synthesis, ensuring semantic accuracy and error minimization through structural validation with domain-specific insights for precise code generation.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET)", "comments": "9 Pages, 5 Figures, 2 Tables", "pdf_url": "https://arxiv.org/pdf/2507.00352.pdf", "abstract_url": "https://arxiv.org/abs/2507.00352", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)", "Emerging Technologies (cs.ET)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种结合抽象语法树（AST）嵌入和检索增强生成（RAG）的新方法，用于提高标准验证规则格式（SVRF）代码合成的效率和准确性，特别是在半导体设计规则检查（DRC）、布局与原理图对比（LVS）和光学邻近校正（OPC）等应用中。", "motivation": "随着半导体设计节点的进步，设计规则变得越来越复杂，这使得传统的SVRF开发方法变得低效，并凸显了专业知识缺口。", "method": "采用抽象语法树（AST）嵌入和检索增强生成（RAG）的方法，结合领域特定知识，进行结构验证，以确保代码生成的语义准确性和最小化错误。", "result": "提出的方法能够有效提高SVRF代码合成的准确性和效率，特别是在处理复杂设计规则时。", "conclusion": "通过结合AST和RAG技术，本文的方法为SVRF代码合成提供了一种高效、准确的解决方案，有助于缩小专业知识缺口并应对复杂设计规则的挑战。"}}
{"id": "2507.00378", "title": "iPanda: An Intelligent Protocol Testing and Debugging Agent for Conformance Testing", "authors": ["Xikai Sun", "Fan Dang", "Kebin Liu", "Xin Miao", "Zihao Yang", "Haimo Lu", "Yawen Zheng", "Yunhao Liu"], "abstract": "Conformance testing is essential for ensuring that protocol implementations comply with their specifications. However, traditional testing approaches involve manually creating numerous test cases and scripts, making the process labor-intensive and inefficient. Recently, Large Language Models (LLMs) have demonstrated impressive text comprehension and code generation abilities, providing promising opportunities for automation. In this paper, we propose iPanda, the first end-to-end framework that leverages LLMs to automate protocol conformance testing. Given a protocol specification document and its implementation, iPanda first employs a keyword-based method to automatically generate comprehensive test cases. Then, it utilizes a code-based retrieval-augmented generation approach to effectively interpret the implementation and produce executable test code. To further enhance code quality, iPanda incorporates an iterative self-correction mechanism to refine generated test scripts interactively. Finally, by executing and analyzing the generated tests, iPanda systematically verifies compliance between implementations and protocol specifications. Comprehensive experiments on various protocols show that iPanda significantly outperforms pure LLM-based approaches, improving the success rate (Pass@1) of test-code generation by factors ranging from 4.675 times to 10.751 times.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": "14 pages, 6 figures", "pdf_url": "https://arxiv.org/pdf/2507.00378.pdf", "abstract_url": "https://arxiv.org/abs/2507.00378", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "iPanda是一个利用大型语言模型（LLMs）自动化协议一致性测试的端到端框架，通过自动生成测试用例和可执行测试代码，显著提高了测试代码生成的效率和成功率。", "motivation": "解决传统协议一致性测试方法需要手动创建大量测试用例和脚本，过程劳动密集且效率低下的问题。", "method": "iPanda采用基于关键词的方法自动生成全面的测试用例，并利用基于代码的检索增强生成方法有效解释实现并生成可执行测试代码，同时结合迭代自我校正机制交互式优化生成的测试脚本。", "result": "在各种协议上的综合实验表明，iPanda显著优于纯LLM-based方法，测试代码生成的成功率（Pass@1）提高了4.675倍至10.751倍。", "conclusion": "iPanda通过自动化协议一致性测试，不仅提高了效率，还显著提升了测试代码生成的质量和成功率，为协议测试领域提供了新的解决方案。"}}
{"id": "2507.00443", "title": "Novel Pigeon-inspired 3D Obstacle Detection and Avoidance Maneuver for Multi-UAV Systems", "authors": ["Reza Ahmadvand", "Sarah Safura Sharif", "Yaser Mike Banad"], "abstract": "Recent advances in multi-agent systems manipulation have demonstrated a rising demand for the implementation of multi-UAV systems in urban areas, which are always subjected to the presence of static and dynamic obstacles. Inspired by the collective behavior of tilapia fish and pigeons, the focus of the presented research is on the introduction of a nature-inspired collision-free formation control for a multi-UAV system, considering the obstacle avoidance maneuvers. The developed framework in this study utilizes a semi-distributed control approach, in which, based on a probabilistic Lloyd's algorithm, a centralized guidance algorithm works for optimal positioning of the UAVs, while a distributed control approach has been used for the intervehicle collision and obstacle avoidance. Further, the presented framework has been extended to the 3D space with a novel definition of 3D maneuvers. Finally, the presented framework has been applied to multi-UAV systems in 2D and 3D scenarios, and the obtained results demonstrated the validity of the presented method in dynamic environments with stationary and moving obstacles.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "11 Pages, 11 Pictures, 1 Table, 3 Algorithms", "pdf_url": "https://arxiv.org/pdf/2507.00443.pdf", "abstract_url": "https://arxiv.org/abs/2507.00443", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种受鸽子和罗非鱼集体行为启发的多无人机系统无碰撞编队控制方法，结合半分布式控制策略和3D机动新定义，有效解决了动态环境中的障碍物避让问题。", "motivation": "随着多无人机系统在城市区域应用的增加，静态和动态障碍物的存在成为了一个主要挑战。本文旨在解决多无人机系统在复杂环境中的安全导航问题。", "method": "研究采用了一种半分布式控制方法，结合集中式指导算法（基于概率性Lloyd算法）进行无人机最优定位，以及分布式控制方法处理无人机间碰撞和障碍物避让。此外，还引入了3D机动的新定义。", "result": "在2D和3D场景中的应用结果表明，所提出的框架在包含静止和移动障碍物的动态环境中表现有效。", "conclusion": "本文提出的自然启发式框架为多无人机系统在复杂环境中的安全导航提供了有效的解决方案，特别是在处理3D空间中的障碍物避让方面展现了创新性和实用性。"}}
{"id": "2507.00451", "title": "Best Agent Identification for General Game Playing", "authors": ["Matthew Stephenson", "Alex Newcombe", "Eric Piette", "Dennis Soemers"], "abstract": "We present an efficient and generalised procedure to accurately identify the best performing algorithm for each sub-task in a multi-problem domain. Our approach treats this as a set of best arm identification problems for multi-armed bandits, where each bandit corresponds to a specific task and each arm corresponds to a specific algorithm or agent. We propose an optimistic selection process based on the Wilson score interval (Optimistic-WS) that ranks each arm across all bandits in terms of their potential regret reduction. We evaluate the performance of Optimistic-WS on two of the most popular general game domains, the General Video Game AI (GVGAI) framework and the Ludii general game playing system, with the goal of identifying the highest performing agent for each game within a limited number of trials. Compared to previous best arm identification algorithms for multi-armed bandits, our results demonstrate a substantial performance improvement in terms of average simple regret. This novel approach can be used to significantly improve the quality and accuracy of agent evaluation procedures for general game frameworks, as well as other multi-task domains with high algorithm runtimes.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Data Structures and Algorithms (cs.DS); Information Theory (cs.IT); Machine Learning (stat.ML)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.00451.pdf", "abstract_url": "https://arxiv.org/abs/2507.00451", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Data Structures and Algorithms (cs.DS)", "Information Theory (cs.IT)", "Machine Learning (stat.ML)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种高效且通用的方法，用于在多问题领域中准确识别每个子任务中表现最佳的算法。该方法将问题视为多臂老虎机中的最佳臂识别问题，提出了一种基于Wilson分数区间的乐观选择过程（Optimistic-WS），并在GVGAI和Ludii两个通用游戏领域进行了评估，结果显示在平均简单遗憾方面有显著提升。", "motivation": "解决在多任务领域中准确识别每个子任务中表现最佳算法的问题，以提高通用游戏框架及其他多任务领域中算法评估的质量和准确性。", "method": "将问题视为多臂老虎机中的最佳臂识别问题，提出基于Wilson分数区间的乐观选择过程（Optimistic-WS），对每个臂在所有老虎机中的潜在遗憾减少进行排名。", "result": "在GVGAI和Ludii两个通用游戏领域的评估中，Optimistic-WS相比之前的最佳臂识别算法在平均简单遗憾方面表现出显著的性能提升。", "conclusion": "Optimistic-WS方法可以显著提高通用游戏框架及其他高算法运行时间的多任务领域中算法评估的质量和准确性。"}}
{"id": "2507.00485", "title": "PNAct: Crafting Backdoor Attacks in Safe Reinforcement Learning", "authors": ["Weiran Guo", "Guanjun Liu", "Ziyuan Zhou", "Ling Wang"], "abstract": "Reinforcement Learning (RL) is widely used in tasks where agents interact with an environment to maximize rewards. Building on this foundation, Safe Reinforcement Learning (Safe RL) incorporates a cost metric alongside the reward metric, ensuring that agents adhere to safety constraints during decision-making. In this paper, we identify that Safe RL is vulnerable to backdoor attacks, which can manipulate agents into performing unsafe actions. First, we introduce the relevant concepts and evaluation metrics for backdoor attacks in Safe RL. It is the first attack framework in the Safe RL field that involves both Positive and Negative Action sample (PNAct) is to implant backdoors, where positive action samples provide reference actions and negative action samples indicate actions to be avoided. We theoretically point out the properties of PNAct and design an attack algorithm. Finally, we conduct experiments to evaluate the effectiveness of our proposed backdoor attack framework, evaluating it with the established metrics. This paper highlights the potential risks associated with Safe RL and underscores the feasibility of such attacks. Our code and supplementary material are available at", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.00485.pdf", "abstract_url": "https://arxiv.org/abs/2507.00485", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了Safe Reinforcement Learning（Safe RL）中的后门攻击框架PNAct，首次在该领域引入了正负动作样本的概念，通过理论分析和实验验证了攻击的有效性，揭示了Safe RL潜在的安全风险。", "motivation": "解决Safe RL可能受到的后门攻击问题，即攻击者如何操纵代理执行不安全动作。", "method": "提出PNAct攻击框架，结合正负动作样本植入后门，设计攻击算法，并通过实验评估其有效性。", "result": "实验结果表明，PNAct框架能够有效实施后门攻击，证明了Safe RL存在被操纵的风险。", "conclusion": "本文不仅揭示了Safe RL的安全漏洞，也为未来研究提供了防御此类攻击的方向。"}}
{"id": "2507.00631", "title": "Horus: A Protocol for Trustless Delegation Under Uncertainty", "authors": ["David Shi", "Kevin Joo"], "abstract": "Correctness is an emergent property of systems where exposing error is cheaper than committing it. In dynamic, low-trust environments, autonomous AI agents benefit from delegating work to sub-agents, yet correctness cannot be assured through upfront specification or centralized oversight. We propose a protocol that enforces correctness through collateralized claims in a recursive verification game. Tasks are published as intents, and solvers compete to fulfill them. Selected solvers carry out tasks under risk, with correctness checked post hoc by verifiers. Any challenger can challenge a result by staking against it to trigger the verification process. Incorrect agents are slashed and correct opposition is rewarded, with an escalation path that penalizes erroneous verifiers themselves. When incentives are aligned across solvers, challengers, and verifiers, falsification conditions make correctness the Nash equilibrium.", "subjects": "Computer Science and Game Theory (cs.GT); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "9 pages, 1 figure", "pdf_url": "https://arxiv.org/pdf/2507.00631.pdf", "abstract_url": "https://arxiv.org/abs/2507.00631", "categories": ["Computer Science and Game Theory (cs.GT)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "Horus协议提出了一种在不确定性下无需信任的委托机制，通过抵押声明和递归验证游戏确保正确性。", "motivation": "解决在动态、低信任环境中，自主AI代理委托工作给子代理时无法确保正确性的问题。", "method": "使用抵押声明和递归验证游戏，任务以意图形式发布，解决者在风险下执行任务，事后由验证者检查正确性。", "result": "当激励在解决者、挑战者和验证者之间对齐时，正确性成为纳什均衡。", "conclusion": "Horus协议通过激励机制和验证过程，确保了在不确定性环境中的正确性，为自主AI代理的委托提供了信任less的解决方案。"}}
{"id": "2507.00589", "title": "Quantum Circuit Structure Optimization for Quantum Reinforcement Learning", "authors": ["Seok Bin Son", "Joongheon Kim"], "abstract": "Reinforcement learning (RL) enables agents to learn optimal policies through environmental interaction. However, RL suffers from reduced learning efficiency due to the curse of dimensionality in high-dimensional spaces. Quantum reinforcement learning (QRL) addresses this issue by leveraging superposition and entanglement in quantum computing, allowing efficient handling of high-dimensional problems with fewer resources. QRL combines quantum neural networks (QNNs) with RL, where the parameterized quantum circuit (PQC) acts as the core computational module. The PQC performs linear and nonlinear transformations through gate operations, similar to hidden layers in classical neural networks. Previous QRL studies, however, have used fixed PQC structures based on empirical intuition without verifying their optimality. This paper proposes a QRL-NAS algorithm that integrates quantum neural architecture search (QNAS) to optimize PQC structures within QRL. Experiments demonstrate that QRL-NAS achieves higher rewards than QRL with fixed circuits, validating its effectiveness and practical utility.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.00589.pdf", "abstract_url": "https://arxiv.org/abs/2507.00589", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为QRL-NAS的算法，通过整合量子神经架构搜索（QNAS）来优化量子强化学习（QRL）中的参数化量子电路（PQC）结构，实验证明QRL-NAS比使用固定电路的QRL获得更高的奖励，验证了其有效性和实用性。", "motivation": "强化学习（RL）在高维空间中由于维度诅咒导致学习效率降低，量子强化学习（QRL）通过利用量子计算中的叠加和纠缠特性，能够以更少的资源高效处理高维问题。然而，以往的QRL研究基于经验直觉使用固定的PQC结构，未验证其最优性。", "method": "本文提出QRL-NAS算法，整合量子神经架构搜索（QNAS）来优化QRL中的PQC结构。", "result": "实验结果表明，QRL-NAS比使用固定电路的QRL获得更高的奖励。", "conclusion": "QRL-NAS算法的有效性和实用性得到了验证，为量子强化学习中的PQC结构优化提供了新的方法。"}}
{"id": "2507.00535", "title": "Rethinking Group Recommender Systems in the Era of Generative AI: From One-Shot Recommendations to Agentic Group Decision Support", "authors": ["Dietmar Jannach", "Amra Delić", "Francesco Ricci", "Markus Zanker"], "abstract": "More than twenty-five years ago, first ideas were developed on how to design a system that can provide recommendations to groups of users instead of individual users. Since then, a rich variety of algorithmic proposals were published, e.g., on how to acquire individual preferences, how to aggregate them, and how to generate recommendations for groups of users. However, despite the rich literature on the topic, barely any examples of real-world group recommender systems can be found. This lets us question common assumptions in academic research, in particular regarding communication processes in a group and how recommendation-supported decisions are made. In this essay, we argue that these common assumptions and corresponding system designs often may not match the needs or expectations of users. We thus call for a reorientation in this research area, leveraging the capabilities of modern Generative AI assistants like ChatGPT. Specifically, as one promising future direction, we envision group recommender systems to be systems where human group members interact in a chat and an AI-based group recommendation agent assists the decision-making process in an agentic way. Ultimately, this shall lead to a more natural group decision-making environment and finally to wider adoption of group recommendation systems in practice.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "comments": "Submitted for publication", "pdf_url": "https://arxiv.org/pdf/2507.00535.pdf", "abstract_url": "https://arxiv.org/abs/2507.00535", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文回顾了群体推荐系统25年来的发展，指出尽管学术研究丰富，但实际应用中鲜有成功案例。作者质疑了研究中关于群体沟通和决策过程的常见假设，并提出利用现代生成式AI（如ChatGPT）重新定位研究方向，设想了一种基于AI代理的群体推荐系统，以更自然地支持群体决策，促进实际应用。", "motivation": "解决群体推荐系统在学术研究与实际应用之间的差距，特别是关于群体沟通和决策过程的假设与用户需求和期望不匹配的问题。", "method": "提出利用现代生成式AI技术，如ChatGPT，设计一种新型的群体推荐系统，其中AI代理以更自然的方式协助群体决策过程。", "result": "设想了一种基于AI代理的群体推荐系统，旨在提供更自然的群体决策环境，从而促进这类系统在实践中的广泛应用。", "conclusion": "通过重新定位研究方向，利用生成式AI技术，可以设计出更符合用户需求和期望的群体推荐系统，最终实现其在实践中的广泛应用。"}}
{"id": "2507.00657", "title": "Generative Exaggeration in LLM Social Agents: Consistency, Bias, and Toxicity", "authors": ["Jacopo Nudo", "Mario Edoardo Pandolfo", "Edoardo Loru", "Mattia Samory", "Matteo Cinelli", "Walter Quattrociocchi"], "abstract": "We investigate how Large Language Models (LLMs) behave when simulating political discourse on social media. Leveraging 21 million interactions on X during the 2024 U.S. presidential election, we construct LLM agents based on 1,186 real users, prompting them to reply to politically salient tweets under controlled conditions. Agents are initialized either with minimal ideological cues (Zero Shot) or recent tweet history (Few Shot), allowing one-to-one comparisons with human replies. We evaluate three model families (Gemini, Mistral, and DeepSeek) across linguistic style, ideological consistency, and toxicity. We find that richer contextualization improves internal consistency but also amplifies polarization, stylized signals, and harmful language. We observe an emergent distortion that we call \"generation exaggeration\": a systematic amplification of salient traits beyond empirical baselines. Our analysis shows that LLMs do not emulate users, they reconstruct them. Their outputs, indeed, reflect internal optimization dynamics more than observed behavior, introducing structural biases that compromise their reliability as social proxies. This challenges their use in content moderation, deliberative simulations, and policy modeling.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.00657.pdf", "abstract_url": "https://arxiv.org/abs/2507.00657", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)", "Social and Information Networks (cs.SI)"], "matching_keywords": ["agent"], "AI": {"tldr": "研究探讨了大型语言模型（LLMs）在模拟社交媒体政治讨论时的行为，发现模型在增强内部一致性的同时，也加剧了极化、风格化信号和有害语言的产生，存在一种称为“生成夸张”的系统性放大现象。", "motivation": "解决LLMs在模拟政治话语时可能产生的偏见、毒性和不一致性问题，评估其作为社会代理的可靠性。", "method": "利用2024年美国总统选举期间X平台上的2100万次互动，基于1186名真实用户构建LLM代理，在受控条件下回复政治敏感推文，比较零样本和少样本初始化下的表现。", "result": "发现更丰富的上下文化提高了内部一致性，但也放大了极化、风格化信号和有害语言；LLMs的输出更多反映了内部优化动态而非观察到的行为，引入了结构性偏见。", "conclusion": "LLMs在内容审核、审议模拟和政策建模中的使用受到挑战，因为它们的输出引入了结构性偏见，影响了作为社会代理的可靠性。"}}
{"id": "2507.00938", "title": "WebArXiv: Evaluating Multimodal Agents on Time-Invariant arXiv Tasks", "authors": ["Zihao Sun", "Meng Fang", "Ling Chen"], "abstract": "Recent progress in large language models (LLMs) has enabled the development of autonomous web agents capable of navigating and interacting with real websites. However, evaluating such agents remains challenging due to the instability and inconsistency of existing benchmarks, which often rely on dynamic content or oversimplified simulations. In this work, we introduce WebArXiv, a static and time-invariant benchmark comprising 275 web-based tasks grounded in the arXiv platform. WebArXiv ensures reproducible and reliable evaluation by anchoring tasks in fixed web snapshots with deterministic ground truths and standardized action trajectories. Through behavioral analysis, we identify a common failure mode, Rigid History Reflection, where agents over-rely on fixed interaction histories. To address this, we propose a lightweight dynamic reflection mechanism that allows agents to selectively retrieve relevant past steps during decision-making. We evaluate ten state-of-the-art web agents on WebArXiv. Results demonstrate clear performance differences across agents and validate the effectiveness of our proposed reflection strategy.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI); Databases (cs.DB)", "comments": "10 pages, 9 figures, 4 tables", "pdf_url": "https://arxiv.org/pdf/2507.00938.pdf", "abstract_url": "https://arxiv.org/abs/2507.00938", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)", "Databases (cs.DB)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了WebArXiv，一个基于arXiv平台的静态和时间不变的基准测试，包含275个基于网络的任务，旨在评估多模态代理的性能。通过行为分析，发现了一种常见的失败模式，并提出了一种轻量级的动态反射机制来改善代理的决策过程。", "motivation": "由于现有基准测试的不稳定性和不一致性，评估自主网络代理的性能仍然具有挑战性。这些基准测试往往依赖于动态内容或过于简化的模拟。", "method": "引入了WebArXiv基准测试，该测试基于固定的网络快照和确定性的地面真相，以及标准化的行动轨迹。通过行为分析识别了代理的常见失败模式，并提出了一种动态反射机制来优化代理的决策过程。", "result": "评估了十个最先进的网络代理，结果显示不同代理之间存在明显的性能差异，并验证了所提出的反射策略的有效性。", "conclusion": "WebArXiv提供了一个可重复和可靠的评估框架，有助于识别和解决代理在交互过程中的问题，从而推动多模态代理技术的发展。"}}
{"id": "2507.00914", "title": "Large Language Model Powered Intelligent Urban Agents: Concepts, Capabilities, and Applications", "authors": ["Jindong Han", "Yansong Ning", "Zirui Yuan", "Hang Ni", "Fan Liu", "Tengfei Lyu", "Hao Liu"], "abstract": "The long-standing vision of intelligent cities is to create efficient, livable, and sustainable urban environments using big data and artificial intelligence technologies. Recently, the advent of Large Language Models (LLMs) has opened new ways toward realizing this vision. With powerful semantic understanding and reasoning capabilities, LLMs can be deployed as intelligent agents capable of autonomously solving complex problems across domains. In this article, we focus on Urban LLM Agents, which are LLM-powered agents that are semi-embodied within the hybrid cyber-physical-social space of cities and used for system-level urban decision-making. First, we introduce the concept of urban LLM agents, discussing their unique capabilities and features. Second, we survey the current research landscape from the perspective of agent workflows, encompassing urban sensing, memory management, reasoning, execution, and learning. Third, we categorize the application domains of urban LLM agents into five groups: urban planning, transportation, environment, public safety, and urban society, presenting representative works in each group. Finally, we discuss trustworthiness and evaluation issues that are critical for real-world deployment, and identify several open problems for future research. This survey aims to establish a foundation for the emerging field of urban LLM agents and to provide a roadmap for advancing the intersection of LLMs and urban intelligence. A curated list of relevant papers and open-source resources is maintained and continuously updated at", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.00914.pdf", "abstract_url": "https://arxiv.org/abs/2507.00914", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了大型语言模型（LLMs）作为智能城市代理的概念、能力及应用，旨在通过LLMs提升城市决策的智能化水平。", "motivation": "解决如何利用大型语言模型（LLMs）的语义理解和推理能力，创建高效、宜居、可持续的智能城市环境。", "method": "介绍了城市LLM代理的概念，调查了从代理工作流程（如城市感知、记忆管理、推理等）出发的研究现状，并分类了应用领域。", "result": "提出了城市LLM代理在五个主要领域的应用：城市规划、交通、环境、公共安全和城市社会，并讨论了实际部署中的信任和评估问题。", "conclusion": "本文为城市LLM代理这一新兴领域奠定了基础，并为LLMs与城市智能的交叉研究提供了路线图。"}}
