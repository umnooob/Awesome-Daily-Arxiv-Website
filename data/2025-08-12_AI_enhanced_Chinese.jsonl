{"id": "2508.06600", "title": "BrowseComp-Plus: A More Fair and Transparent Evaluation Benchmark of Deep-Research Agent", "authors": ["Zijian Chen", "Xueguang Ma", "Shengyao Zhuang", "Ping Nie", "Kai Zou", "Andrew Liu", "Joshua Green", "Kshama Patel", "Ruoxi Meng", "Mingyi Su", "Sahel Sharifymoghaddam", "Yanxi Li", "Haoran Hong", "Xinyu Shi", "Xuye Liu", "Nandan Thakur", "Crystina Zhang", "Luyu Gao", "Wenhu Chen", "Jimmy Lin"], "abstract": "Deep-Research agents, which integrate large language models (LLMs) with search tools, have shown success in improving the effectiveness of handling complex queries that require iterative search planning and reasoning over search results. Evaluations on current benchmarks like BrowseComp relies on black-box live web search APIs, have notable limitations in (1) fairness: dynamic and opaque web APIs hinder fair comparisons and reproducibility of deep research methods; (2) transparency: lack of control over the document corpus makes it difficult to isolate retriever contributions. In other words, the current evaluations may compare a complete deep research system at a given time, but they do not foster well-controlled experiments to provide insights into the capability of underlying deep research LLMs. To address these challenges, we introduce BrowseComp-Plus, a benchmark derived from BrowseComp, employing a fixed, carefully curated corpus. Each query in BrowseComp-Plus includes human-verified supporting documents and mined challenging negatives, enabling controlled experimentation. The benchmark is shown to be effective in distinguishing the performance of deep research systems. For instance, the open-source model Search-R1, when paired with the BM25 retriever, achieves 3.86% accuracy, whereas the GPT-5 achieves 55.9%. Integrating the GPT-5 with the Qwen3-Embedding-8B retriever further enhances its accuracy to 70.1% with fewer search calls. This benchmark allows comprehensive evaluation and disentangled analysis of deep research agents and retrieval methods, fostering insights into retrieval effectiveness, citation accuracy, and context engineering in Deep-Research system.", "subjects": "Computation and Language (cs.CL); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.06600.pdf", "abstract_url": "https://arxiv.org/abs/2508.06600", "categories": ["Computation and Language (cs.CL)", "Information Retrieval (cs.IR)"], "matching_keywords": ["agent"], "AI": {"tldr": "BrowseComp-Plus是一个旨在解决当前深度研究代理评估中公平性和透明度问题的基准测试，通过使用固定、精心策划的语料库来促进更公平和透明的比较。", "motivation": "当前基于黑盒实时网络搜索API的评估方法在公平性和透明度方面存在局限，难以进行公平比较和可重复性研究，也无法有效评估底层深度研究LLM的能力。", "method": "引入BrowseComp-Plus基准，采用固定、精心策划的语料库，每个查询包含人工验证的支持文档和挖掘的挑战性负面例子，以支持控制实验。", "result": "BrowseComp-Plus能有效区分深度研究系统的性能，例如，开源模型Search-R1与BM25检索器配对时准确率为3.86%，而GPT-5达到55.9%。结合Qwen3-Embedding-8B检索器后，GPT-5的准确率进一步提升至70.1%，且搜索调用次数减少。", "conclusion": "BrowseComp-Plus基准支持对深度研究代理和检索方法的全面评估和分离分析，促进了对检索效果、引用准确性和上下文工程在深度研究系统中的深入理解。"}}
{"id": "2508.06504", "title": "Retrieval augmented generation based dynamic prompting for few-shot biomedical named entity recognition using large language models", "authors": ["Yao Ge", "Sudeshna Das", "Yuting Guo", "Abeed Sarker"], "abstract": "Biomedical named entity recognition (NER) is a high-utility natural language processing (NLP) task, and large language models (LLMs) show promise particularly in few-shot settings (i.e., limited training data). In this article, we address the performance challenges of LLMs for few-shot biomedical NER by investigating a dynamic prompting strategy involving retrieval-augmented generation (RAG). In our approach, the annotated in-context learning examples are selected based on their similarities with the input texts, and the prompt is dynamically updated for each instance during inference. We implemented and optimized static and dynamic prompt engineering techniques and evaluated them on five biomedical NER datasets. Static prompting with structured components increased average F1-scores by 12% for GPT-4, and 11% for GPT-3.5 and LLaMA 3-70B, relative to basic static prompting. Dynamic prompting further improved performance, with TF-IDF and SBERT retrieval methods yielding the best results, improving average F1-scores by 7.3% and 5.6% in 5-shot and 10-shot settings, respectively. These findings highlight the utility of contextually adaptive prompts via RAG for biomedical NER.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "31 pages, 4 figures, 15 tables", "pdf_url": "https://arxiv.org/pdf/2508.06504.pdf", "abstract_url": "https://arxiv.org/abs/2508.06504", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文探讨了利用检索增强生成（RAG）的动态提示策略，以提高大型语言模型（LLMs）在少量样本生物医学命名实体识别（NER）中的性能。通过根据输入文本的相似性选择注释的上下文学习示例，并在推理过程中动态更新提示，显著提升了模型表现。", "motivation": "解决大型语言模型在少量训练数据（few-shot）设置下进行生物医学命名实体识别时的性能挑战。", "method": "采用检索增强生成（RAG）的动态提示策略，包括基于输入文本相似性选择注释的上下文学习示例，并在推理过程中动态更新提示。同时，实现并优化了静态和动态提示工程技术。", "result": "静态提示与结构化组件相结合，使GPT-4的平均F1分数提高了12%，GPT-3.5和LLaMA 3-70B提高了11%。动态提示进一步提升了性能，TF-IDF和SBERT检索方法在5-shot和10-shot设置下分别使平均F1分数提高了7.3%和5.6%。", "conclusion": "通过检索增强生成实现的情境自适应提示对于生物医学命名实体识别具有显著效用，动态提示策略能有效提升大型语言模型在少量样本设置下的性能。"}}
{"id": "2508.06729", "title": "Large Language Models for Oral History Understanding with Text Classification and Sentiment Analysis", "authors": ["Komala Subramanyam Cherukuri", "Pranav Abishai Moses", "Aisa Sakata", "Jiangping Chen", "Haihua Chen"], "abstract": "Oral histories are vital records of lived experience, particularly within communities affected by systemic injustice and historical erasure. Effective and efficient analysis of their oral history archives can promote access and understanding of the oral histories. However, Large-scale analysis of these archives remains limited due to their unstructured format, emotional complexity, and high annotation costs. This paper presents a scalable framework to automate semantic and sentiment annotation for Japanese American Incarceration Oral History. Using LLMs, we construct a high-quality dataset, evaluate multiple models, and test prompt engineering strategies in historically sensitive contexts. Our multiphase approach combines expert annotation, prompt design, and LLM evaluation with ChatGPT, Llama, and Qwen. We labeled 558 sentences from 15 narrators for sentiment and semantic classification, then evaluated zero-shot, few-shot, and RAG strategies. For semantic classification, ChatGPT achieved the highest F1 score (88.71%), followed by Llama (84.99%) and Qwen (83.72%). For sentiment analysis, Llama slightly outperformed Qwen (82.66%) and ChatGPT (82.29%), with all models showing comparable results. The best prompt configurations were used to annotate 92,191 sentences from 1,002 interviews in the JAIOH collection. Our findings show that LLMs can effectively perform semantic and sentiment annotation across large oral history collections when guided by well-designed prompts. This study provides a reusable annotation pipeline and practical guidance for applying LLMs in culturally sensitive archival analysis. By bridging archival ethics with scalable NLP techniques, this work lays the groundwork for responsible use of artificial intelligence in digital humanities and preservation of collective memory. GitHub:", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.06729.pdf", "abstract_url": "https://arxiv.org/abs/2508.06729", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一个可扩展的框架，利用大型语言模型（LLMs）自动化对日本美国监禁口述历史进行语义和情感注释。通过结合专家注释、提示设计和LLM评估，研究展示了LLMs在大型口述历史集合中有效进行语义和情感注释的能力。", "motivation": "口述历史是记录生活经历的重要资料，尤其是对于受系统性不公正和历史抹除影响的社区。然而，由于其非结构化格式、情感复杂性和高标注成本，这些档案的大规模分析仍然有限。", "method": "研究使用LLMs（包括ChatGPT、Llama和Qwen）构建高质量数据集，评估多种模型，并测试在历史敏感上下文中的提示工程策略。采用多阶段方法，结合专家注释、提示设计和LLM评估。", "result": "在语义分类方面，ChatGPT达到了最高的F1分数（88.71%），其次是Llama（84.99%）和Qwen（83.72%）。在情感分析方面，Llama略优于Qwen（82.66%）和ChatGPT（82.29%）。最佳提示配置用于注释JAIOH集合中1,002次访谈的92,191个句子。", "conclusion": "研究表明，当由设计良好的提示引导时，LLMs可以有效地在大型口述历史集合中执行语义和情感注释。这项工作为在数字人文和集体记忆保护中负责任地使用人工智能奠定了基础。"}}
{"id": "2508.07069", "title": "SEADialogues: A Multilingual Culturally Grounded Multi-turn Dialogue Dataset on Southeast Asian Languages", "authors": ["Muhammad Dehan Al Kautsar", "Aswin Candra", "Muhammad Alif Al Hakim", "Maxalmina Satria Kahfi", "Fajri Koto", "Alham Fikri Aji", "Peerat Limkonchotiwat", "Ekapol Chuangsuwanich", "Genta Indra Winata"], "abstract": "Although numerous datasets have been developed to support dialogue systems, most existing chit-chat datasets overlook the cultural nuances inherent in natural human conversations. To address this gap, we introduce SEADialogues, a culturally grounded dialogue dataset centered on Southeast Asia, a region with over 700 million people and immense cultural diversity. Our dataset features dialogues in eight languages from six Southeast Asian countries, many of which are low-resource despite having sizable speaker populations. To enhance cultural relevance and personalization, each dialogue includes persona attributes and two culturally grounded topics that reflect everyday life in the respective communities. Furthermore, we release a multi-turn dialogue dataset to advance research on culturally aware and human-centric large language models, including conversational dialogue agents.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "Preprint", "pdf_url": "https://arxiv.org/pdf/2508.07069.pdf", "abstract_url": "https://arxiv.org/abs/2508.07069", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "SEADialogues是一个多语言、文化基础的多轮对话数据集，专注于东南亚语言，旨在填补现有闲聊数据集忽视文化细微差别的空白。", "motivation": "解决现有对话数据集在文化细微差别上的不足，特别是针对东南亚这一文化多样性丰富的地区。", "method": "开发了一个包含八种语言、六个东南亚国家的对话数据集，每个对话包含人物属性和两个反映日常生活文化基础的主题。", "result": "发布了SEADialogues数据集，支持文化意识和以人为中心的大型语言模型的研究，包括对话代理。", "conclusion": "SEADialogues为研究文化意识和人类中心的对话系统提供了宝贵的资源，特别是在低资源语言和文化多样性方面。"}}
{"id": "2508.06803", "title": "SEVADE: Self-Evolving Multi-Agent Analysis with Decoupled Evaluation for Hallucination-Resistant Irony Detection", "authors": ["Ziqi Liu", "Yangbin Chen", "Ziyang Zhou", "Yilin Li", "Mingxuan Hu", "Yushan Pan", "Zhijie Xu"], "abstract": "Sarcasm detection is a crucial yet challenging Natural Language Processing task. Existing Large Language Model methods are often limited by single-perspective analysis, static reasoning pathways, and a susceptibility to hallucination when processing complex ironic rhetoric, which impacts their accuracy and reliability. To address these challenges, we propose **SEVADE**, a novel **S**elf-**Ev**olving multi-agent **A**nalysis framework with **D**ecoupled **E**valuation for hallucination-resistant sarcasm detection. The core of our framework is a Dynamic Agentive Reasoning Engine (DARE), which utilizes a team of specialized agents grounded in linguistic theory to perform a multifaceted deconstruction of the text and generate a structured reasoning chain. Subsequently, a separate lightweight rationale adjudicator (RA) performs the final classification based solely on this reasoning chain. This decoupled architecture is designed to mitigate the risk of hallucination by separating complex reasoning from the final judgment. Extensive experiments on four benchmark datasets demonstrate that our framework achieves state-of-the-art performance, with average improvements of **6.75%** in Accuracy and **6.29%** in Macro-F1 score.", "subjects": "Computation and Language (cs.CL); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.06803.pdf", "abstract_url": "https://arxiv.org/abs/2508.06803", "categories": ["Computation and Language (cs.CL)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为SEVADE的新型自我进化多代理分析框架，用于抵抗幻觉的讽刺检测，通过动态代理推理引擎和多角度文本解构，实现了在四个基准数据集上的最先进性能。", "motivation": "解决现有大型语言模型在讽刺检测任务中因单视角分析、静态推理路径和对复杂讽刺修辞的幻觉敏感性而导致的准确性和可靠性问题。", "method": "采用自我进化多代理分析框架（SEVADE），包括动态代理推理引擎（DARE）和轻量级理性裁决器（RA），通过分离复杂推理和最终判断来减少幻觉风险。", "result": "在四个基准数据集上的实验表明，该框架在准确率和Macro-F1分数上平均提高了6.75%和6.29%，达到了最先进的性能。", "conclusion": "SEVADE框架通过其独特的解耦架构和多代理分析方法，有效提高了讽刺检测的准确性和可靠性，为自然语言处理领域提供了新的研究方向。"}}
{"id": "2508.07179", "title": "Schema Lineage Extraction at Scale: Multilingual Pipelines, Composite Evaluation, and Language-Model Benchmarks", "authors": ["Jiaqi Yin", "Yi-Wei Chen", "Meng-Lung Lee", "Xiya Liu"], "abstract": "Enterprise data pipelines, characterized by complex transformations across multiple programming languages, often cause a semantic disconnect between original metadata and downstream data. This \"semantic drift\" compromises data reproducibility and governance, and impairs the utility of services like retrieval-augmented generation (RAG) and text-to-SQL systems. To address this, a novel framework is proposed for the automated extraction of fine-grained schema lineage from multilingual enterprise pipeline scripts. This method identifies four key components: source schemas, source tables, transformation logic, and aggregation operations, creating a standardized representation of data transformations. For the rigorous evaluation of lineage quality, this paper introduces the Schema Lineage Composite Evaluation (SLiCE), a metric that assesses both structural correctness and semantic fidelity. A new benchmark is also presented, comprising 1,700 manually annotated lineages from real-world industrial scripts. Experiments were conducted with 12 language models, from 1.3B to 32B small language models (SLMs) to large language models (LLMs) like GPT-4o and GPT-4.1. The results demonstrate that the performance of schema lineage extraction scales with model size and the sophistication of prompting techniques. Specially, a 32B open-source model, using a single reasoning trace, can achieve performance comparable to the GPT series under standard prompting. This finding suggests a scalable and economical approach for deploying schema-aware agents in practical applications.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Databases (cs.DB)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.07179.pdf", "abstract_url": "https://arxiv.org/abs/2508.07179", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Databases (cs.DB)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "提出了一种新颖的框架，用于从多语言企业管道脚本中自动提取细粒度模式谱系，以解决语义漂移问题，并引入了SLiCE评估指标和新基准。", "motivation": "解决企业数据管道中由于复杂转换导致的语义漂移问题，影响数据可重复性、治理及RAG和text-to-SQL等服务的效用。", "method": "开发了一个自动化框架，识别源模式、源表、转换逻辑和聚合操作，创建数据转换的标准化表示。", "result": "实验表明，模式谱系提取的性能随模型大小和提示技术的复杂程度而提升，32B开源模型在标准提示下性能接近GPT系列。", "conclusion": "研究提出了一种可扩展且经济的方法，用于在实际应用中部署模式感知代理。"}}
{"id": "2508.07185", "title": "DySK-Attn: A Framework for Efficient, Real-Time Knowledge Updating in Large Language Models via Dynamic Sparse Knowledge Attention", "authors": ["Kabir Khan", "Priya Sharma", "Arjun Mehta", "Neha Gupta", "Ravi Narayanan"], "abstract": "Large Language Models (LLMs) suffer from a critical limitation: their knowledge is static and quickly becomes outdated. Retraining these massive models is computationally prohibitive, while existing knowledge editing techniques can be slow and may introduce unforeseen side effects. To address this, we propose DySK-Attn, a novel framework that enables LLMs to efficiently integrate real-time knowledge from a dynamic external source. Our approach synergizes an LLM with a dynamic Knowledge Graph (KG) that can be updated instantaneously. The core of our framework is a sparse knowledge attention mechanism, which allows the LLM to perform a coarse-to-fine grained search, efficiently identifying and focusing on a small, highly relevant subset of facts from the vast KG. This mechanism avoids the high computational cost of dense attention over the entire knowledge base and mitigates noise from irrelevant information. We demonstrate through extensive experiments on time-sensitive question-answering tasks that DySK-Attn significantly outperforms strong baselines, including standard Retrieval-Augmented Generation (RAG) and model editing techniques, in both factual accuracy for updated knowledge and computational efficiency. Our framework offers a scalable and effective solution for building LLMs that can stay current with the ever-changing world.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "Preprint; 7 figures, 3 tables, 1 algorithm; v1. Code and data will be released", "pdf_url": "https://arxiv.org/pdf/2508.07185.pdf", "abstract_url": "https://arxiv.org/abs/2508.07185", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "DySK-Attn是一个新颖的框架，旨在解决大型语言模型(LLMs)知识静态且快速过时的问题，通过动态稀疏知识注意力机制，使LLMs能够高效整合来自动态外部源的实时知识。", "motivation": "大型语言模型(LLMs)的知识是静态的，很快就会过时。重新训练这些庞大的模型计算成本高昂，而现有的知识编辑技术可能速度慢且会引入不可预见的副作用。", "method": "DySK-Attn框架将LLM与可以即时更新的动态知识图(KG)协同工作，其核心是一个稀疏知识注意力机制，允许LLM进行从粗到细的搜索，高效识别并专注于KG中一小部分高度相关的事实。", "result": "在时间敏感的问答任务上的大量实验表明，DySK-Attn在更新知识的事实准确性和计算效率上显著优于包括标准检索增强生成(RAG)和模型编辑技术在内的强基线。", "conclusion": "DySK-Attn提供了一个可扩展且有效的解决方案，用于构建能够与不断变化的世界保持同步的LLMs。"}}
{"id": "2508.07279", "title": "MAQuA: Adaptive Question-Asking for Multidimensional Mental Health Screening using Item Response Theory", "authors": ["Vasudha Varadarajan", "Hui Xu", "Rebecca Astrid Boehme", "Mariam Marlan Mirstrom", "Sverker Sikstrom", "H. Andrew Schwartz"], "abstract": "Recent advances in large language models (LLMs) offer new opportunities for scalable, interactive mental health assessment, but excessive querying by LLMs burdens users and is inefficient for real-world screening across transdiagnostic symptom profiles. We introduce MAQuA, an adaptive question-asking framework for simultaneous, multidimensional mental health screening. Combining multi-outcome modeling on language responses with item response theory (IRT) and factor analysis, MAQuA selects the questions with most informative responses across multiple dimensions at each turn to optimize diagnostic information, improving accuracy and potentially reducing response burden. Empirical results on a novel dataset reveal that MAQuA reduces the number of assessment questions required for score stabilization by 50-87% compared to random ordering (e.g., achieving stable depression scores with 71% fewer questions and eating disorder scores with 85% fewer questions). MAQuA demonstrates robust performance across both internalizing (depression, anxiety) and externalizing (substance use, eating disorder) domains, with early stopping strategies further reducing patient time and burden. These findings position MAQuA as a powerful and efficient tool for scalable, nuanced, and interactive mental health screening, advancing the integration of LLM-based agents into real-world clinical workflows.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.07279.pdf", "abstract_url": "https://arxiv.org/abs/2508.07279", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "MAQuA是一种自适应提问框架，用于多维心理健康筛查，结合多结果建模、项目反应理论和因子分析，优化问题选择以提高诊断效率并减少用户负担。", "motivation": "解决大型语言模型在心理健康评估中因过度查询而给用户带来负担，以及跨诊断症状谱筛查效率低下的问题。", "method": "结合多结果建模、项目反应理论(IRT)和因子分析，MAQuA在每个步骤选择对多个维度最具信息量的问题。", "result": "MAQuA将评估问题数量减少了50-87%，在抑郁和饮食障碍等领域表现出色，早期停止策略进一步减少了患者时间和负担。", "conclusion": "MAQuA作为一种强大且高效的工具，推动了基于LLM的代理在现实世界临床工作流程中的整合，实现了可扩展、细致和交互式的心理健康筛查。"}}
{"id": "2508.06496", "title": "Med-GRIM: Enhanced Zero-Shot Medical VQA using prompt-embedded Multimodal Graph RAG", "authors": ["Rakesh Raj Madavan", "Akshat Kaimal", "Hashim Faisal", "Chandrakala S"], "abstract": "An ensemble of trained multimodal encoders and vision-language models (VLMs) has become a standard approach for visual question answering (VQA) tasks. However, such models often fail to produce responses with the detailed precision necessary for complex, domain-specific applications such as medical VQA. Our representation model, BIND: BLIVA Integrated with Dense Encoding, extends prior multimodal work by refining the joint embedding space through dense, query-token-based encodings inspired by contrastive pretraining techniques. This refined encoder powers Med-GRIM, a model designed for medical VQA tasks that leverages graph-based retrieval and prompt engineering to integrate domain-specific knowledge. Rather than relying on compute-heavy fine-tuning of vision and language models on specific datasets, Med-GRIM applies a low-compute, modular workflow with small language models (SLMs) for efficiency. Med-GRIM employs prompt-based retrieval to dynamically inject relevant knowledge, ensuring both accuracy and robustness in its responses. By assigning distinct roles to each agent within the VQA system, Med-GRIM achieves large language model performance at a fraction of the computational cost. Additionally, to support scalable research in zero-shot multimodal medical applications, we introduce DermaGraph, a novel Graph-RAG dataset comprising diverse dermatological conditions. This dataset facilitates both multimodal and unimodal querying. The code and dataset are available at:", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.06496.pdf", "abstract_url": "https://arxiv.org/abs/2508.06496", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "Med-GRIM是一种增强的零样本医学视觉问答（VQA）模型，通过结合多模态图检索增强生成（RAG）和提示嵌入技术，提高了在复杂医学领域中的精确度。", "motivation": "解决现有视觉问答模型在复杂、领域特定（如医学）应用中缺乏详细精确响应的问题。", "method": "开发了BIND表示模型，通过密集的查询令牌编码细化联合嵌入空间，并利用基于图的检索和提示工程集成领域特定知识。", "result": "Med-GRIM在不依赖计算密集型微调的情况下，实现了与大型语言模型相当的性能，同时显著降低了计算成本。", "conclusion": "Med-GRIM为医学VQA提供了一种高效、模块化的工作流程，同时引入了DermaGraph数据集以支持零样本多模态医学应用的可扩展研究。"}}
{"id": "2508.07308", "title": "HealthBranches: Synthesizing Clinically-Grounded Question Answering Datasets via Decision Pathways", "authors": ["Cristian Cosentino", "Annamaria Defilippo", "Marco Dossena", "Christopher Irwin", "Sara Joubbi", "Pietro Liò"], "abstract": "HealthBranches is a novel benchmark dataset for medical Question-Answering (Q&A), specifically designed to evaluate complex reasoning in Large Language Models (LLMs). This dataset is generated through a semi-automated pipeline that transforms explicit decision pathways from medical source into realistic patient cases with associated questions and answers. Covering 4,063 case studies across 17 healthcare topics, each data point is based on clinically validated reasoning chains. HealthBranches supports both open-ended and multiple-choice question formats and uniquely includes the full reasoning path for each Q&A. Its structured design enables robust evaluation of LLMs' multi-step inference capabilities, including their performance in structured Retrieval-Augmented Generation (RAG) contexts. HealthBranches establishes a foundation for the development of more trustworthy, interpretable, and clinically reliable LLMs in high-stakes domains while also serving as a valuable resource for educational purposes.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.07308.pdf", "abstract_url": "https://arxiv.org/abs/2508.07308", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "HealthBranches是一个新颖的医疗问答基准数据集，专门设计用于评估大型语言模型(LLMs)中的复杂推理能力。", "motivation": "解决在医疗领域缺乏评估LLMs复杂推理能力的基准数据集的问题。", "method": "通过半自动化的流程，将医疗来源的明确决策路径转化为现实的病例研究，包括相关的问题和答案。", "result": "覆盖了17个医疗主题的4,063个病例研究，每个数据点都基于临床验证的推理链，支持开放式和多项选择题格式。", "conclusion": "HealthBranches为开发更可信、可解释且临床可靠的高风险领域LLMs奠定了基础，同时也是教育目的的宝贵资源。"}}
{"id": "2508.06555", "title": "StyleTailor: Towards Personalized Fashion Styling via Hierarchical Negative Feedback", "authors": ["Hongbo Ma", "Fei Shen", "Hongbin Xu", "Xiaoce Wang", "Gang Xu", "Jinkai Zheng", "Liangqiong Qu", "Ming Li"], "abstract": "The advancement of intelligent agents has revolutionized problem-solving across diverse domains, yet solutions for personalized fashion styling remain underexplored, which holds immense promise for promoting shopping experiences. In this work, we present StyleTailor, the first collaborative agent framework that seamlessly unifies personalized apparel design, shopping recommendation, virtual try-on, and systematic evaluation into a cohesive workflow. To this end, StyleTailor pioneers an iterative visual refinement paradigm driven by multi-level negative feedback, enabling adaptive and precise user alignment. Specifically, our framework features two core agents, i.e., Designer for personalized garment selection and Consultant for virtual try-on, whose outputs are progressively refined via hierarchical vision-language model feedback spanning individual items, complete outfits, and try-on efficacy. Counterexamples are aggregated into negative prompts, forming a closed-loop mechanism that enhances recommendation", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Computers and Society (cs.CY); Multiagent Systems (cs.MA)", "comments": "24pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2508.06555.pdf", "abstract_url": "https://arxiv.org/abs/2508.06555", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Computers and Society (cs.CY)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "StyleTailor是一个创新的协作代理框架，旨在通过分层负面反馈实现个性化时尚造型，整合了服装设计、购物推荐、虚拟试穿和系统评估。", "motivation": "解决个性化时尚造型领域尚未充分探索的问题，以提升购物体验。", "method": "采用基于多层次负面反馈的迭代视觉细化范式，通过设计师和顾问两个核心代理，利用视觉语言模型反馈逐步优化推荐。", "result": "开发了一个能够自适应和精确对齐用户需求的框架，通过负面提示形成闭环机制，提高推荐质量。", "conclusion": "StyleTailor框架为个性化时尚造型提供了一种新颖的解决方案，通过整合多种技术和反馈机制，显著提升了用户体验和推荐系统的效能。"}}
{"id": "2508.07592", "title": "IBPS: Indian Bail Prediction System", "authors": ["Puspesh Kumar Srivastava", "Uddeshya Raj", "Praveen Patel", "/Shubham Kumar Nigam", "Noel Shallum", "Arnab Bhattacharya"], "abstract": "Bail decisions are among the most frequently adjudicated matters in Indian courts, yet they remain plagued by subjectivity, delays, and inconsistencies. With over 75% of India's prison population comprising undertrial prisoners, many from socioeconomically disadvantaged backgrounds, the lack of timely and fair bail adjudication exacerbates human rights concerns and contributes to systemic judicial backlog. In this paper, we present the Indian Bail Prediction System (IBPS), an AI-powered framework designed to assist in bail decision-making by predicting outcomes and generating legally sound rationales based solely on factual case attributes and statutory provisions. We curate and release a large-scale dataset of 150,430 High Court bail judgments, enriched with structured annotations such as age, health, criminal history, crime category, custody duration, statutes, and judicial reasoning. We fine-tune a large language model using parameter-efficient techniques and evaluate its performance across multiple configurations, with and without statutory context, and with RAG. Our results demonstrate that models fine-tuned with statutory knowledge significantly outperform baselines, achieving strong accuracy and explanation quality, and generalize well to a test set independently annotated by legal experts. IBPS offers a transparent, scalable, and reproducible solution to support data-driven legal assistance, reduce bail delays, and promote procedural fairness in the Indian judicial system.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.07592.pdf", "abstract_url": "https://arxiv.org/abs/2508.07592", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "印度保释预测系统（IBPS）是一个基于AI的框架，旨在通过预测结果和生成基于事实案件属性和法定条款的法律合理理由来辅助保释决策。", "motivation": "印度法院的保释决策存在主观性、延迟和不一致性问题，尤其是对于社会经济弱势群体的未审判囚犯，这加剧了人权问题和司法积压。", "method": "研究团队收集并注释了一个包含150,430个高等法院保释判决的大规模数据集，并使用参数高效技术对大型语言模型进行微调，评估其在多种配置下的性能。", "result": "结果表明，结合法定知识微调的模型显著优于基线模型，在准确性和解释质量上表现出色，并能很好地泛化到由法律专家独立注释的测试集。", "conclusion": "IBPS提供了一个透明、可扩展和可重复的解决方案，支持数据驱动的法律协助，减少保释延迟，并促进印度司法系统的程序公平。"}}
{"id": "2508.06569", "title": "Operationalizing Serendipity: Multi-Agent AI Workflows for Enhanced Materials Characterization with Theory-in-the-Loop", "authors": ["Lance Yao", "Suman Samantray", "Ayana Ghosh", "Kevin Roccapriore", "Libor Kovarik", "Sarah Allec", "Maxim Ziatdinov"], "abstract": "The history of science is punctuated by serendipitous discoveries, where unexpected observations, rather than targeted hypotheses, opened new fields of inquiry. While modern autonomous laboratories excel at accelerating hypothesis testing, their optimization for efficiency risks overlooking these crucial, unplanned findings. To address this gap, we introduce SciLink, an open-source, multi-agent artificial intelligence framework designed to operationalize serendipity in materials research by creating a direct, automated link between experimental observation, novelty assessment, and theoretical simulations. The framework employs a hybrid AI strategy where specialized machine learning models perform quantitative analysis of experimental data, while large language models handle higher-level reasoning. These agents autonomously convert raw data from materials characterization techniques into falsifiable scientific claims, which are then quantitatively scored for novelty against the published literature. We demonstrate the framework's versatility across diverse research scenarios, showcasing its application to atomic-resolution and hyperspectral data, its capacity to integrate real-time human expert guidance, and its ability to close the research loop by proposing targeted follow-up experiments. By systematically analyzing all observations and contextualizing them, SciLink provides a practical framework for AI-driven materials research that not only enhances efficiency but also actively cultivates an environment ripe for serendipitous discoveries, thereby bridging the gap between automated experimentation and open-ended scientific exploration.", "subjects": "Artificial Intelligence (cs.AI); Materials Science (cond-mat.mtrl-sci)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.06569.pdf", "abstract_url": "https://arxiv.org/abs/2508.06569", "categories": ["Artificial Intelligence (cs.AI)", "Materials Science (cond-mat.mtrl-sci)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了SciLink，一个开源的、多代理人工智能框架，旨在通过实验观察、新颖性评估和理论模拟之间的直接自动化链接，在材料研究中实现偶然发现的操作化。", "motivation": "现代自主实验室在加速假设测试方面表现出色，但其效率优化可能会忽略这些关键的、未计划的发现。为了解决这一问题，本文提出了SciLink框架。", "method": "采用混合AI策略，其中专门的机器学习模型执行实验数据的定量分析，而大型语言模型处理高级推理。这些代理自主地将材料表征技术的原始数据转化为可证伪的科学主张，然后根据已发表的文献对这些主张的新颖性进行定量评分。", "result": "展示了该框架在不同研究场景中的多功能性，包括其在原子分辨率和超光谱数据中的应用、整合实时人类专家指导的能力，以及通过提出有针对性的后续实验来闭合研究循环的能力。", "conclusion": "通过系统地分析所有观察结果并将其情境化，SciLink为AI驱动的材料研究提供了一个实用框架，不仅提高了效率，还积极培育了一个有利于偶然发现的环境，从而弥合了自动化实验和开放式科学探索之间的差距。"}}
{"id": "2508.06836", "title": "Multi-level Advantage Credit Assignment for Cooperative Multi-Agent Reinforcement Learning", "authors": ["Xutong Zhao", "Yaqi Xie"], "abstract": "Cooperative multi-agent reinforcement learning (MARL) aims to coordinate multiple agents to achieve a common goal. A key challenge in MARL is credit assignment, which involves assessing each agent's contribution to the shared reward. Given the diversity of tasks, agents may perform different types of coordination, with rewards attributed to diverse and often overlapping agent subsets. In this work, we formalize the credit assignment level as the number of agents cooperating to obtain a reward, and address scenarios with multiple coexisting levels. We introduce a multi-level advantage formulation that performs explicit counterfactual reasoning to infer credits across distinct levels. Our method, Multi-level Advantage Credit Assignment (MACA), captures agent contributions at multiple levels by integrating advantage functions that reason about individual, joint, and correlated actions. Utilizing an attention-based framework, MACA identifies correlated agent relationships and constructs multi-level advantages to guide policy learning. Comprehensive experiments on challenging Starcraft v1\\&v2 tasks demonstrate MACA's superior performance, underscoring its efficacy in complex credit assignment scenarios.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "Accepted at AISTATS 2025", "pdf_url": "https://arxiv.org/pdf/2508.06836.pdf", "abstract_url": "https://arxiv.org/abs/2508.06836", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种多级优势信用分配方法（MACA），用于解决合作多智能体强化学习中的信用分配问题，通过多级优势公式和注意力机制，有效识别智能体在不同协作层次上的贡献。", "motivation": "合作多智能体强化学习（MARL）中的一个关键挑战是信用分配，即评估每个智能体对共享奖励的贡献。由于任务的多样性，智能体可能进行不同类型的协作，奖励可能归属于不同且经常重叠的智能体子集。", "method": "本文引入了一种多级优势公式，通过显式的反事实推理来推断不同层次的信用。MACA方法通过整合考虑个体、联合和相关动作的优势函数，捕捉智能体在多个层次上的贡献。利用基于注意力的框架，MACA识别相关智能体关系，并构建多级优势以指导策略学习。", "result": "在具有挑战性的Starcraft v1和v2任务上的全面实验表明，MACA在复杂的信用分配场景中表现出卓越的性能。", "conclusion": "MACA方法通过多级优势信用分配，有效解决了合作多智能体强化学习中的信用分配问题，为复杂协作任务提供了高效的解决方案。"}}
{"id": "2508.06851", "title": "MDK12-Bench: A Comprehensive Evaluation of Multimodal Large Language Models on Multidisciplinary Exams", "authors": ["Pengfei Zhou", "Xiaopeng Peng", "Fanrui Zhang", "Zhaopan Xu", "Jiaxin Ai", "Yansheng Qiu", "Chuanhao Li", "Zhen Li", "Ming Li", "Yukang Feng", "Jianwen Sun", "Haoquan Zhang", "Zizhen Li", "Xiaofeng Mao", "Zekai Li", "Wangbo Zhao", "Kai Wang", "Xiaojun Chang", "Wenqi Shao", "Yang You", "Kaipeng Zhang"], "abstract": "Multimodal large language models (MLLMs), which integrate language and visual cues for problem-solving, are crucial for advancing artificial general intelligence (AGI). However, current benchmarks for measuring the intelligence of MLLMs suffer from limited scale, narrow coverage, and unstructured knowledge, offering only static and undifferentiated evaluations. To bridge this gap, we introduce MDK12-Bench, a large-scale multidisciplinary benchmark built from real-world K-12 exams spanning six disciplines with 141K instances and 6,225 knowledge points organized in a six-layer taxonomy. Covering five question formats with difficulty and year annotations, it enables comprehensive evaluation to capture the extent to which MLLMs perform over four dimensions: 1) difficulty levels, 2) temporal (cross-year) shifts, 3) contextual shifts, and 4) knowledge-driven reasoning. We propose a novel dynamic evaluation framework that introduces unfamiliar visual, textual, and question form shifts to challenge model generalization while improving benchmark objectivity and longevity by mitigating data contamination. We further evaluate knowledge-point reference-augmented generation (KP-RAG) to examine the role of knowledge in problem-solving. Key findings reveal limitations in current MLLMs in multiple aspects and provide guidance for enhancing model robustness, interpretability, and AI-assisted education.", "subjects": "Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "comments": "35 pages, 33 figures", "pdf_url": "https://arxiv.org/pdf/2508.06851.pdf", "abstract_url": "https://arxiv.org/abs/2508.06851", "categories": ["Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "MDK12-Bench是一个大规模多学科基准测试，用于评估多模态大语言模型（MLLMs）在真实世界K-12考试中的表现，覆盖六个学科，包含141K实例和6,225个知识点，旨在全面评估MLLMs在难度级别、时间（跨年）变化、上下文变化和知识驱动推理四个维度的表现。", "motivation": "当前用于衡量MLLMs智能的基准测试存在规模有限、覆盖范围狭窄和知识无结构化等问题，只能提供静态和无差异化的评估。为了弥补这一差距，引入了MDK12-Bench。", "method": "提出了一个新颖的动态评估框架，通过引入不熟悉的视觉、文本和问题形式变化来挑战模型的泛化能力，同时通过减轻数据污染来提高基准测试的客观性和长期性。此外，还评估了知识点参考增强生成（KP-RAG）以检查知识在问题解决中的作用。", "result": "关键发现揭示了当前MLLMs在多个方面的局限性，并为增强模型的鲁棒性、可解释性和AI辅助教育提供了指导。", "conclusion": "MDK12-Bench不仅提供了一个全面评估MLLMs的平台，还揭示了当前模型的不足，为未来的研究和发展方向提供了宝贵的见解。"}}
{"id": "2508.07827", "title": "Evaluating Large Language Models as Expert Annotators", "authors": ["Yu-Min Tseng", "Wei-Lin Chen", "Chung-Chi Chen", "Hsin-Hsi Chen"], "abstract": "Textual data annotation, the process of labeling or tagging text with relevant information, is typically costly, time-consuming, and labor-intensive. While large language models (LLMs) have demonstrated their potential as direct alternatives to human annotators for general domains natural language processing (NLP) tasks, their effectiveness on annotation tasks in domains requiring expert knowledge remains underexplored. In this paper, we investigate: whether top-performing LLMs, which might be perceived as having expert-level proficiency in academic and professional benchmarks, can serve as direct alternatives to human expert annotators? To this end, we evaluate both individual LLMs and multi-agent approaches across three highly specialized domains: finance, biomedicine, and law. Specifically, we propose a multi-agent discussion framework to simulate a group of human annotators, where LLMs are tasked to engage in discussions by considering others' annotations and justifications before finalizing their labels. Additionally, we incorporate reasoning models (e.g., o3-mini) to enable a more comprehensive comparison. Our empirical results reveal that: (1) Individual LLMs equipped with inference-time techniques (e.g., chain-of-thought (CoT), self-consistency) show only marginal or even negative performance gains, contrary to prior literature suggesting their broad effectiveness. (2) Overall, reasoning models do not demonstrate statistically significant improvements over non-reasoning models in most settings. This suggests that extended long CoT provides relatively limited benefits for data annotation in specialized domains. (3) Certain model behaviors emerge in the multi-agent discussion environment. For instance, Claude 3.7 Sonnet with thinking rarely changes its initial annotations, even when other agents provide correct annotations or valid reasoning.", "subjects": "Computation and Language (cs.CL)", "comments": "Accepted to COLM 2025", "pdf_url": "https://arxiv.org/pdf/2508.07827.pdf", "abstract_url": "https://arxiv.org/abs/2508.07827", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了大型语言模型（LLMs）在需要专家知识的领域中作为人类专家注释者直接替代品的有效性。通过评估个体LLMs和多代理方法在金融、生物医学和法律三个高度专业化领域的表现，研究发现，配备推理时间技术的个体LLMs仅显示出边际或负面性能提升，而多代理讨论环境中出现了一些模型行为。", "motivation": "解决在需要专家知识的领域中，文本数据注释成本高、耗时且劳动密集型的问题，探索LLMs作为人类专家注释者直接替代品的潜力。", "method": "评估个体LLMs和多代理方法在三个高度专业化领域的表现，提出一个多代理讨论框架来模拟一组人类注释者，并引入推理模型进行更全面的比较。", "result": "研究发现，个体LLMs配备推理时间技术仅显示出边际或负面性能提升；推理模型在大多数设置中未显示出统计上显著的改进；多代理讨论环境中出现特定模型行为。", "conclusion": "研究表明，LLMs在专业化领域作为人类专家注释者的直接替代品效果有限，特别是在需要深入专家知识的任务中。多代理讨论框架揭示了模型行为的特定模式，为未来研究提供了方向。"}}
{"id": "2508.06894", "title": "Pushdown Reward Machines for Reinforcement Learning", "authors": ["Giovanni Varricchione", "Toryn Q. Klassen", "Natasha Alechina", "Mehdi Dastani", "Brian Logan", "Sheila A. McIlraith"], "abstract": "Reward machines (RMs) are automata structures that encode (non-Markovian) reward functions for reinforcement learning (RL). RMs can reward any behaviour representable in regular languages and, when paired with RL algorithms that exploit RM structure, have been shown to significantly improve sample efficiency in many domains. In this work, we present pushdown reward machines (pdRMs), an extension of reward machines based on deterministic pushdown automata. pdRMs can recognize and reward temporally extended behaviours representable in deterministic context-free languages, making them more expressive than reward machines. We introduce two variants of pdRM-based policies, one which has access to the entire stack of the pdRM, and one which can only access the top $k$ symbols (for a given constant $k$) of the stack. We propose a procedure to check when the two kinds of policies (for a given environment, pdRM, and constant $k$) achieve the same optimal expected reward. We then provide theoretical results establishing the expressive power of pdRMs, and space complexity results about the proposed learning problems. Finally, we provide experimental results showing how agents can be trained to perform tasks representable in deterministic context-free languages using pdRMs.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.06894.pdf", "abstract_url": "https://arxiv.org/abs/2508.06894", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了推下奖励机（pdRMs），这是基于确定性下推自动机的奖励机（RMs）的扩展。pdRMs能够识别和奖励确定性上下文无关语言中可表示的时间扩展行为，比RMs更具表达力。", "motivation": "解决强化学习（RL）中奖励函数编码的局限性，特别是对于那些需要识别和奖励更复杂、时间扩展行为的场景。", "method": "提出了两种基于pdRM的策略变体：一种可以访问pdRM的整个堆栈，另一种只能访问堆栈顶部的$k$个符号。并提出了一个程序来检查这两种策略在给定环境、pdRM和常数$k$下是否达到相同的最优预期奖励。", "result": "理论结果确立了pdRMs的表达能力，并提供了关于所提出学习问题的空间复杂性结果。实验结果表明，可以使用pdRMs训练代理执行确定性上下文无关语言中可表示的任务。", "conclusion": "推下奖励机（pdRMs）为强化学习提供了一种更强大的工具，能够处理更复杂的行为模式，从而在样本效率上实现显著提升。"}}
{"id": "2508.06899", "title": "GDBA Revisited: Unleashing the Power of Guided Local Search for Distributed Constraint Optimization", "authors": ["Yanchen Deng", "Xinrun Wang", "Bo An"], "abstract": "Local search is an important class of incomplete algorithms for solving Distributed Constraint Optimization Problems (DCOPs) but it often converges to poor local optima. While GDBA provides a comprehensive rule set to escape premature convergence, its empirical benefits remain marginal on general-valued problems. In this work, we systematically examine GDBA and identify three factors that potentially lead to its inferior performance, i.e., over-aggressive constraint violation conditions, unbounded penalty accumulation, and uncoordinated penalty updates. To address these issues, we propose Distributed Guided Local Search (DGLS), a novel GLS framework for DCOPs that incorporates an adaptive violation condition to selectively penalize constraints with high cost, a penalty evaporation mechanism to control the magnitude of penalization, and a synchronization scheme for coordinated penalty updates. We theoretically show that the penalty values are bounded, and agents play a potential game in our DGLS. Our extensive empirical results on various standard benchmarks demonstrate the great superiority of DGLS over state-of-the-art baselines. Particularly, compared to Damped Max-sum with high damping factors (e.g., 0.7 or 0.9), our DGLS achieves competitive performance on general-valued problems, and outperforms it by significant margins (\\textbf{3.77\\%--66.3\\%}) on structured problems in terms of anytime results.", "subjects": "Artificial Intelligence (cs.AI); Discrete Mathematics (cs.DM)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.06899.pdf", "abstract_url": "https://arxiv.org/abs/2508.06899", "categories": ["Artificial Intelligence (cs.AI)", "Discrete Mathematics (cs.DM)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文重新审视了GDBA，提出了一种新的分布式引导局部搜索（DGLS）框架，用于解决分布式约束优化问题（DCOPs），通过自适应违反条件、惩罚蒸发机制和同步方案显著提升了性能。", "motivation": "局部搜索是解决分布式约束优化问题（DCOPs）的一类重要但不完整的算法，但其常常收敛于较差的局部最优解。GDBA虽然提供了一套全面的规则集以避免过早收敛，但在一般值问题上的实证效益仍然有限。", "method": "提出了分布式引导局部搜索（DGLS）框架，包括自适应违反条件来选择性地惩罚高成本约束、惩罚蒸发机制以控制惩罚幅度，以及同步方案以实现协调的惩罚更新。", "result": "理论证明惩罚值有界，代理在我们的DGLS中扮演潜在游戏。在各种标准基准上的广泛实证结果表明，DGLS在一般值问题上与高阻尼因子的Damped Max-sum竞争，而在结构化问题上以显著优势（3.77%--66.3%）超越。", "conclusion": "DGLS通过解决GDBA的三个潜在问题，显著提升了在分布式约束优化问题中的性能，特别是在结构化问题上表现卓越。"}}
{"id": "2508.06931", "title": "Automated Formalization via Conceptual Retrieval-Augmented LLMs", "authors": ["Wangyue Lu", "Lun Du", "Sirui Li", "Ke Weng", "Haozhe Sun", "Hengyu Liu", "Minghe Yu", "Tiancheng Zhang", "Ge Yu"], "abstract": "Interactive theorem provers (ITPs) require manual formalization, which is labor-intensive and demands expert knowledge. While automated formalization offers a potential solution, it faces two major challenges: model hallucination (e.g., undefined predicates, symbol misuse, and version incompatibility) and the semantic gap caused by ambiguous or missing premises in natural language descriptions. To address these issues, we propose CRAMF, a Concept-driven Retrieval-Augmented Mathematical Formalization framework. CRAMF enhances LLM-based autoformalization by retrieving formal definitions of core mathematical concepts, providing contextual grounding during code generation. However, applying retrieval-augmented generation (RAG) in this setting is non-trivial due to the lack of structured knowledge bases, the polymorphic nature of mathematical concepts, and the high precision required in formal retrieval. We introduce a framework for automatically constructing a concept-definition knowledge base from Mathlib4, the standard mathematical library for the Lean 4 theorem prover, indexing over 26,000 formal definitions and 1,000+ core mathematical concepts. To address conceptual polymorphism, we propose contextual query augmentation with domain- and application-level signals. In addition, we design a dual-channel hybrid retrieval strategy with reranking to ensure accurate and relevant definition retrieval. Experiments on miniF2F, ProofNet, and our newly proposed AdvancedMath benchmark show that CRAMF can be seamlessly integrated into LLM-based autoformalizers, yielding consistent improvements in translation accuracy, achieving up to 62.1% and an average of 29.9% relative improvement.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.06931.pdf", "abstract_url": "https://arxiv.org/abs/2508.06931", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了CRAMF框架，通过概念驱动的检索增强数学形式化方法，解决了自动形式化中的模型幻觉和语义鸿沟问题，显著提高了翻译准确性。", "motivation": "交互式定理证明器(ITPs)需要手动形式化，这不仅劳动密集且需要专业知识。自动形式化虽为潜在解决方案，但面临模型幻觉和自然语言描述中的语义鸿沟两大挑战。", "method": "提出了CRAMF框架，通过从Mathlib4自动构建概念-定义知识库，并采用上下文查询增强和双通道混合检索策略，增强基于LLM的自动形式化。", "result": "在miniF2F、ProofNet和AdvancedMath基准测试中，CRAMF能够无缝集成到基于LLM的自动形式化器中，翻译准确性实现了最高62.1%和平均29.9%的相对提升。", "conclusion": "CRAMF通过检索增强和精确的定义检索，有效解决了自动形式化的核心挑战，为未来的数学形式化研究提供了新的方向。"}}
{"id": "2508.06960", "title": "DatasetResearch: Benchmarking Agent Systems for Demand-Driven Dataset Discovery", "authors": ["Keyu Li", "Mohan Jiang", "Dayuan Fu", "Yunze Wu", "Xiangkun Hu", "Dequan Wang", "Pengfei Liu"], "abstract": "The rapid advancement of large language models has fundamentally shifted the bottleneck in AI development from computational power to data availability-with countless valuable datasets remaining hidden across specialized repositories, research appendices, and domain platforms. As reasoning capabilities and deep research methodologies continue to evolve, a critical question emerges: can AI agents transcend conventional search to systematically discover any dataset that meets specific user requirements, enabling truly autonomous demand-driven data curation? We introduce DatasetResearch, the first comprehensive benchmark evaluating AI agents' ability to discover and synthesize datasets from 208 real-world demands across knowledge-intensive and reasoning-intensive tasks. Our tri-dimensional evaluation framework reveals a stark reality: even advanced deep research systems achieve only 22% score on our challenging DatasetResearch-pro subset, exposing the vast gap between current capabilities and perfect dataset discovery. Our analysis uncovers a fundamental dichotomy-search agents excel at knowledge tasks through retrieval breadth, while synthesis agents dominate reasoning challenges via structured generation-yet both catastrophically fail on \"corner cases\" outside existing distributions. These findings establish the first rigorous baseline for dataset discovery agents and illuminate the path toward AI systems capable of finding any dataset in the digital universe. Our benchmark and comprehensive analysis provide the foundation for the next generation of self-improving AI systems and are publicly available at", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.06960.pdf", "abstract_url": "https://arxiv.org/abs/2508.06960", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了DatasetResearch，第一个全面评估AI代理在知识密集型和推理密集型任务中发现和合成数据集能力的基准。通过三维评估框架，揭示了当前先进深度研究系统在挑战性子集上仅达到22%分数的现实，展示了当前能力与完美数据集发现之间的巨大差距。", "motivation": "随着大型语言模型的快速发展，AI开发的瓶颈已从计算能力转向数据可用性。大量有价值的数据集仍隐藏在专业存储库、研究附录和领域平台中。本文旨在评估AI代理是否能超越传统搜索，系统地发现满足特定用户需求的数据集，实现真正自主的需求驱动数据管理。", "method": "本文引入了DatasetResearch基准，评估AI代理从208个真实世界需求中发现和合成数据集的能力。采用三维评估框架，对知识密集型和推理密集型任务进行了全面分析。", "result": "研究发现，即使是先进的深度研究系统，在具有挑战性的DatasetResearch-pro子集上也仅达到22%的分数。搜索代理在知识任务中通过检索广度表现出色，而合成代理通过结构化生成在推理挑战中占优，但两者在现有分布之外的“角落案例”上都表现不佳。", "conclusion": "这些发现为数据集发现代理建立了第一个严格的基线，并指明了构建能够在数字宇宙中找到任何数据集的AI系统的路径。基准和全面分析为下一代自我改进的AI系统奠定了基础。"}}
{"id": "2508.06963", "title": "MASteer: Multi-Agent Adaptive Steer Strategy for End-to-End LLM Trustworthiness Repair", "authors": ["Changqing Li", "Tianlin Li", "Xiaohan Zhang", "Aishan Liu", "Li Pan"], "abstract": "Large Language Models (LLMs) face persistent and evolving trustworthiness issues, motivating developers to seek automated and flexible repair methods that enable convenient deployment across diverse scenarios. Existing repair methods like supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF) are costly and slow, while prompt engineering lacks robustness and scalability. Representation engineering, which steers model behavior by injecting targeted concept vectors during inference, offers a lightweight, training-free alternative. However, current approaches depend on manually crafted samples and fixed steering strategies, limiting automation and adaptability. To overcome these challenges, we propose MASteer, the first end-to-end framework for trustworthiness repair in LLMs based on representation engineering. MASteer integrates two core components: AutoTester, a multi-agent system that generates diverse, high-quality steer samples tailored to developer needs; and AutoRepairer, which constructs adaptive steering strategies with anchor vectors for automated, context-aware strategy selection during inference. Experiments on standard and customized trustworthiness tasks show MASteer consistently outperforms baselines, improving metrics by 15.36% on LLaMA-3.1-8B-Chat and 4.21% on Qwen-3-8B-Chat, while maintaining general model capabilities. MASteer demonstrates strong robustness, generalization, and practical value for scalable, efficient trustworthiness repair.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.06963.pdf", "abstract_url": "https://arxiv.org/abs/2508.06963", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "MASteer是一个基于表示工程的端到端框架，旨在修复大型语言模型（LLMs）的可信度问题。它通过集成AutoTester和AutoRepairer两个核心组件，自动生成多样化的引导样本并构建自适应的引导策略，以在推理过程中实现自动化、上下文感知的策略选择。实验表明，MASteer在标准及定制可信度任务上均优于基线方法，显著提高了模型的可信度指标，同时保持了模型的通用能力。", "motivation": "大型语言模型（LLMs）面临持续且演变的可信度问题，现有修复方法如监督微调（SFT）和带有人类反馈的强化学习（RLHF）成本高、速度慢，而提示工程缺乏鲁棒性和可扩展性。表示工程作为一种轻量级、无需训练的替代方案，通过注入目标概念向量来引导模型行为，但现有方法依赖手动制作的样本和固定的引导策略，限制了自动化和适应性。", "method": "MASteer框架集成了两个核心组件：AutoTester，一个多智能体系统，用于生成多样化、高质量的引导样本；以及AutoRepairer，用于构建带有锚向量的自适应引导策略，实现推理过程中的自动化、上下文感知的策略选择。", "result": "在标准及定制可信度任务上的实验显示，MASteer在LLaMA-3.1-8B-Chat和Qwen-3-8B-Chat上分别提高了15.36%和4.21%的指标，同时保持了模型的通用能力，展现了强大的鲁棒性、泛化能力和实用价值。", "conclusion": "MASteer为大型语言模型的可信度修复提供了一种可扩展、高效的解决方案，通过自动化和自适应的引导策略，显著提升了模型的可信度，同时保持了其通用能力，具有重要的实践意义。"}}
{"id": "2508.07043", "title": "K-Dense Analyst: Towards Fully Automated Scientific Analysis", "authors": ["Orion Li", "Vinayak Agarwal", "Summer Zhou", "Ashwin Gopinath", "Timothy Kassis"], "abstract": "The complexity of modern bioinformatics analysis has created a critical gap between data generation and developing scientific insights. While large language models (LLMs) have shown promise in scientific reasoning, they remain fundamentally limited when dealing with real-world analytical workflows that demand iterative computation, tool integration and rigorous validation. We introduce K-Dense Analyst, a hierarchical multi-agent system that achieves autonomous bioinformatics analysis through a dual-loop architecture. K-Dense Analyst, part of the broader K-Dense platform, couples planning with validated execution using specialized agents to decompose complex objectives into executable, verifiable tasks within secure computational environments. On BixBench, a comprehensive benchmark for open-ended biological analysis, K-Dense Analyst achieves 29.2% accuracy, surpassing the best-performing language model (GPT-5) by 6.3 percentage points, representing nearly 27% improvement over what is widely considered the most powerful LLM available. Remarkably, K-Dense Analyst achieves this performance using Gemini 2.5 Pro, which attains only 18.3% accuracy when used directly, demonstrating that our architectural innovations unlock capabilities far beyond the underlying model's baseline performance. Our insights demonstrate that autonomous scientific reasoning requires more than enhanced language models, it demands purpose-built systems that can bridge the gap between high-level scientific objectives and low-level computational execution. These results represent a significant advance toward fully autonomous computational biologists capable of accelerating discovery across the life sciences.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA); Genomics (q-bio.GN); Quantitative Methods (q-bio.QM)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.07043.pdf", "abstract_url": "https://arxiv.org/abs/2508.07043", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)", "Genomics (q-bio.GN)", "Quantitative Methods (q-bio.QM)"], "matching_keywords": ["agent"], "AI": {"tldr": "K-Dense Analyst是一个分层多代理系统，通过双环架构实现自主生物信息学分析，显著提高了分析准确性。", "motivation": "解决现代生物信息学分析复杂性与科学洞察开发之间的关键差距。", "method": "采用分层多代理系统和双环架构，将复杂目标分解为可执行、可验证的任务。", "result": "在BixBench上，K-Dense Analyst的准确率达到29.2%，比最佳语言模型（GPT-5）高出6.3个百分点。", "conclusion": "自主科学推理需要专门构建的系统，以弥合高级科学目标与低级计算执行之间的差距。"}}
{"id": "2508.06980", "title": "Simulating Biological Intelligence: Active Inference with Experiment-Informed Generative Model", "authors": ["Aswin Paul", "Moein Khajehnejad", "Forough Habibollahi", "Brett J. Kagan", "Adeel Razi"], "abstract": "With recent and rapid advancements in artificial intelligence (AI), understanding the foundation of purposeful behaviour in autonomous agents is crucial for developing safe and efficient systems. While artificial neural networks have dominated the path to AI, recent studies are exploring the potential of biologically based systems, such as networks of living biological neuronal networks. Along with promises of high power and data efficiency, these systems may also inform more explainable and biologically plausible models. In this work, we propose a framework rooted in active inference, a general theory of behaviour, to model decision-making in embodied agents. Using experiment-informed generative models, we simulate decision-making processes in a simulated game-play environment, mirroring experimental setups that use biological neurons. Our results demonstrate learning in these agents, providing insights into the role of memory-based learning and predictive planning in intelligent decision-making. This work contributes to the growing field of explainable AI by offering a biologically grounded and scalable approach to understanding purposeful behaviour in agents.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "18 pages, 8 figures", "pdf_url": "https://arxiv.org/pdf/2508.06980.pdf", "abstract_url": "https://arxiv.org/abs/2508.06980", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于主动推理的框架，用于模拟具身代理中的决策过程，通过实验信息生成模型在模拟游戏环境中模拟决策，展示了基于记忆的学习和预测规划在智能决策中的作用。", "motivation": "随着人工智能（AI）的快速发展，理解自主代理中有目的行为的基础对于开发安全高效的系统至关重要。尽管人工神经网络在AI发展中占据主导地位，但最近的研究开始探索基于生物的系统，如活体生物神经元网络的潜力。这些系统不仅有望实现高功率和数据效率，还可能提供更可解释和生物学上合理的模型。", "method": "本研究提出了一种基于主动推理的框架，这是一种行为的一般理论，用于模拟具身代理中的决策过程。使用实验信息生成模型，在模拟游戏环境中模拟决策过程，模拟使用生物神经元的实验设置。", "result": "我们的结果表明，这些代理能够学习，为理解基于记忆的学习和预测规划在智能决策中的作用提供了见解。", "conclusion": "这项工作通过提供一种生物学基础和可扩展的方法来理解代理中的有目的行为，为可解释AI的不断发展的领域做出了贡献。"}}
{"id": "2508.07999", "title": "WideSearch: Benchmarking Agentic Broad Info-Seeking", "authors": ["Ryan Wong", "Jiawei Wang", "Junjie Zhao", "Li Chen", "Yan Gao", "Long Zhang", "Xuan Zhou", "Zuo Wang", "Kai Xiang", "Ge Zhang", "Wenhao Huang", "Yang Wang", "Ke Wang"], "abstract": "From professional research to everyday planning, many tasks are bottlenecked by wide-scale information seeking, which is more repetitive than cognitively complex. With the rapid development of Large Language Models (LLMs), automated search agents powered by LLMs offer a promising solution to liberate humans from this tedious work. However, the capability of these agents to perform such \"wide-context\" collection reliably and completely remains largely unevaluated due to a lack of suitable benchmarks. To bridge this gap, we introduce WideSearch, a new benchmark engineered to evaluate agent reliability on these large-scale collection tasks. The benchmark features 200 manually curated questions (100 in English, 100 in Chinese) from over 15 diverse domains, grounded in real user queries. Each task requires agents to collect large-scale atomic information, which could be verified one by one objectively, and arrange it into a well-organized output. A rigorous five-stage quality control pipeline ensures the difficulty, completeness, and verifiability of the dataset. We benchmark over 10 state-of-the-art agentic search systems, including single-agent, multi-agent frameworks, and end-to-end commercial systems. Most systems achieve overall success rates near 0\\%, with the best performer reaching just 5\\%. However, given sufficient time, cross-validation by multiple human testers can achieve a near 100\\% success rate. These results demonstrate that present search agents have critical deficiencies in large-scale information seeking, underscoring urgent areas for future research and development in agentic search. Our dataset, evaluation pipeline, and benchmark results have been publicly released at", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.07999.pdf", "abstract_url": "https://arxiv.org/abs/2508.07999", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了WideSearch，一个旨在评估大型语言模型（LLMs）驱动的搜索代理在大规模信息收集任务中可靠性和完整性的新基准。通过200个手动策划的问题（100英文，100中文）和严格的质量控制流程，研究发现当前搜索代理在此类任务中表现不佳，最高成功率仅为5%，而人类测试者可达近100%。", "motivation": "解决大规模信息搜索任务中自动化搜索代理的可靠性和完整性评估缺乏合适基准的问题。", "method": "引入WideSearch基准，包含200个来自15多个不同领域的问题，采用五阶段质量控制流程确保数据集的难度、完整性和可验证性，并对10多种最先进的搜索代理系统进行基准测试。", "result": "大多数系统的总体成功率接近0%，最佳表现者仅达到5%，而人类测试者在充足时间下可达近100%的成功率。", "conclusion": "当前搜索代理在大规模信息搜索中存在重大缺陷，突出了未来搜索代理研究和开发的紧迫领域。"}}
{"id": "2508.07063", "title": "Towards Safer AI Moderation: Evaluating LLM Moderators Through a Unified Benchmark Dataset and Advocating a Human-First Approach", "authors": ["Naseem Machlovi", "Maryam Saleki", "Innocent Ababio", "Ruhul Amin"], "abstract": "As AI systems become more integrated into daily life, the need for safer and more reliable moderation has never been greater. Large Language Models (LLMs) have demonstrated remarkable capabilities, surpassing earlier models in complexity and performance. Their evaluation across diverse tasks has consistently showcased their potential, enabling the development of adaptive and personalized agents. However, despite these advancements, LLMs remain prone to errors, particularly in areas requiring nuanced moral reasoning. They struggle with detecting implicit hate, offensive language, and gender biases due to the subjective and context-dependent nature of these issues. Moreover, their reliance on training data can inadvertently reinforce societal biases, leading to inconsistencies and ethical concerns in their outputs. To explore the limitations of LLMs in this role, we developed an experimental framework based on state-of-the-art (SOTA) models to assess human emotions and offensive behaviors. The framework introduces a unified benchmark dataset encompassing 49 distinct categories spanning the wide spectrum of human emotions, offensive and hateful text, and gender and racial biases. Furthermore, we introduced SafePhi, a QLoRA fine-tuned version of Phi-4, adapting diverse ethical contexts and outperforming benchmark moderators by achieving a Macro F1 score of 0.89, where OpenAI Moderator and Llama Guard score 0.77 and 0.74, respectively. This research also highlights the critical domains where LLM moderators consistently underperformed, pressing the need to incorporate more heterogeneous and representative data with human-in-the-loop, for better model robustness and explainability.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.07063.pdf", "abstract_url": "https://arxiv.org/abs/2508.07063", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了大型语言模型（LLMs）在内容审核中的应用及其局限性，提出了一个统一的基准数据集和一种名为SafePhi的改进模型，强调了人类参与的重要性以提高模型的鲁棒性和可解释性。", "motivation": "随着AI系统在日常生活中的日益普及，对更安全、更可靠的内容审核的需求日益增长。尽管LLMs在多个任务中表现出色，但在需要细致道德推理的领域仍存在错误，如检测隐含仇恨、冒犯性语言和性别偏见。", "method": "研究开发了一个基于最先进模型的实验框架，用于评估人类情感和冒犯行为，并引入了一个包含49个不同类别的统一基准数据集。此外，提出了SafePhi，一个QLoRA微调的Phi-4版本，以适应多样化的伦理背景。", "result": "SafePhi在Macro F1得分上达到了0.89，优于OpenAI Moderator和Llama Guard的0.77和0.74。研究还指出了LLM审核器在关键领域表现不佳的问题。", "conclusion": "研究表明，为了提高模型的鲁棒性和可解释性，需要纳入更多异质性和代表性的数据，并采用人类参与的方法。SafePhi的成功展示了在AI审核中结合伦理考量和人类监督的潜力。"}}
{"id": "2508.07976", "title": "Beyond Ten Turns: Unlocking Long-Horizon Agentic Search with Large-Scale Asynchronous RL", "authors": ["Jiaxuan Gao", "Wei Fu", "Minyang Xie", "Shusheng Xu", "Chuyi He", "Zhiyu Mei", "Banghua Zhu", "Yi Wu"], "abstract": "Recent advancements in LLM-based agents have demonstrated remarkable capabilities in handling complex, knowledge-intensive tasks by integrating external tools. Among diverse choices of tools, search tools play a pivotal role in accessing vast external knowledge. However, open-source agents still fall short of achieving expert-level Search Intelligence, the ability to resolve ambiguous queries, generate precise searches, analyze results, and conduct thorough exploration. Existing approaches fall short in scalability, efficiency, and data quality. For example, small turn limits in existing online RL methods, e.g. <=10, restrict complex strategy learning. This paper introduces ASearcher, an open-source project for large-scale RL training of search agents. Our key contributions include: (1) Scalable fully asynchronous RL training that enables long-horizon search while maintaining high training efficiency. (2) A prompt-based LLM agent that autonomously synthesizes high-quality and challenging QAs, creating a large-scale QA dataset. Through RL training, our prompt-based QwQ-32B agent achieves substantial improvements, with 46.7% and 20.8% Avg@4 gains on xBench and GAIA, respectively. Notably, our agent exhibits extreme long-horizon search, with tool calls exceeding 40 turns and output tokens exceeding 150k during training time. With a simple agent design and no external LLMs, ASearcher-Web-QwQ achieves Avg@4 scores of 42.1 on xBench and 52.8 on GAIA, surpassing existing open-source 32B agents. We open-source our models, training data, and codes in", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.07976.pdf", "abstract_url": "https://arxiv.org/abs/2508.07976", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了ASearcher，一个开源项目，旨在通过大规模异步强化学习训练搜索代理，以解决现有方法在可扩展性、效率和数据质量上的不足，特别是在长视野搜索方面的限制。", "motivation": "现有的开源代理在实现专家级搜索智能方面存在不足，尤其是在处理模糊查询、生成精确搜索、分析结果和进行彻底探索方面。现有方法在可扩展性、效率和数据质量上也有局限，例如在线强化学习方法的小步数限制（如<=10）限制了复杂策略的学习。", "method": "ASearcher采用了可扩展的完全异步强化学习训练方法，支持长视野搜索同时保持高训练效率，并利用基于提示的大型语言模型代理自主合成高质量且具有挑战性的问答对，创建大规模问答数据集。", "result": "通过强化学习训练，基于提示的QwQ-32B代理在xBench和GAIA上分别实现了46.7%和20.8%的平均@4增益。代理展现出极长的搜索视野，训练时的工具调用超过40步，输出标记超过150k。ASearcher-Web-QwQ在xBench和GAIA上的平均@4分数分别为42.1和52.8，超越了现有的开源32B代理。", "conclusion": "ASearcher通过其简单的代理设计和无需外部大型语言模型的支持，在长视野搜索任务上取得了显著进展，为开源社区提供了模型、训练数据和代码。"}}
{"id": "2508.08139", "title": "Can LLMs Detect Their Confabulations? Estimating Reliability in Uncertainty-Aware Language Models", "authors": ["Tianyi Zhou", "Johanne Medina", "Sanjay Chawla"], "abstract": "Large Language Models (LLMs) are prone to generating fluent but incorrect content, known as confabulation, which poses increasing risks in multi-turn or agentic applications where outputs may be reused as context. In this work, we investigate how in-context information influences model behavior and whether LLMs can identify their unreliable responses. We propose a reliability estimation that leverages token-level uncertainty to guide the aggregation of internal model representations. Specifically, we compute aleatoric and epistemic uncertainty from output logits to identify salient tokens and aggregate their hidden states into compact representations for response-level reliability prediction. Through controlled experiments on open QA benchmarks, we find that correct in-context information improves both answer accuracy and model confidence, while misleading context often induces confidently incorrect responses, revealing a misalignment between uncertainty and correctness. Our probing-based method captures these shifts in model behavior and improves the detection of unreliable outputs across multiple open-source LLMs. These results underscore the limitations of direct uncertainty signals and highlight the potential of uncertainty-guided probing for reliability-aware generation.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.08139.pdf", "abstract_url": "https://arxiv.org/abs/2508.08139", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文研究了大型语言模型（LLMs）在生成内容时的不确定性，提出了一个基于标记级不确定性的可靠性估计方法，以识别和预测模型输出的可靠性。", "motivation": "大型语言模型倾向于生成流畅但不正确的内容（即虚构），这在多轮或代理应用中可能带来风险。本文旨在探索模型如何利用上下文信息以及是否能识别其不可靠的输出。", "method": "提出了一种可靠性估计方法，通过计算输出逻辑的随机和认知不确定性来识别显著标记，并将它们的隐藏状态聚合为紧凑表示，用于响应级别的可靠性预测。", "result": "实验发现，正确的上下文信息提高了答案准确性和模型信心，而误导性上下文则常导致模型自信地生成错误答案，揭示了不确定性与正确性之间的不对齐。", "conclusion": "研究结果强调了直接不确定性信号的局限性，并突出了不确定性引导探测在可靠性感知生成中的潜力。"}}
{"id": "2508.08050", "title": "9th Workshop on Sign Language Translation and Avatar Technologies (SLTAT 2025)", "authors": ["Fabrizio Nunnari", "Cristina Luna Jiménez", "Rosalee Wolfe", "John C. McDonald", "Michael Filhol", "Eleni Efthimiou", "Evita Fotinea", "Thomas Hanke"], "abstract": "The Sign Language Translation and Avatar Technology (SLTAT) workshops continue a series of gatherings to share recent advances in improving deaf / human communication through non-invasive means. This 2025 edition, the 9th since its first appearance in 2011, is hosted by the International Conference on Intelligent Virtual Agents (IVA), giving the opportunity for contamination between two research communities, using digital humans as either virtual interpreters or as interactive conversational agents. As presented in this summary paper, SLTAT sees contributions beyond avatar technologies, with a consistent number of submissions on sign language recognition, and other work on data collection, data analysis, tools, ethics, usability, and affective computing.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.08050.pdf", "abstract_url": "https://arxiv.org/abs/2508.08050", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "SLTAT 2025是第九届手语翻译与虚拟人技术研讨会，旨在通过非侵入性手段改善聋人/人类交流，涵盖手语识别、数据收集与分析、工具、伦理、可用性及情感计算等多个领域。", "motivation": "解决聋人与非聋人之间的沟通障碍，促进手语翻译和虚拟人技术的发展与应用。", "method": "通过研讨会的形式，汇集国际虚拟智能代理会议（IVA）的研究社区，分享手语翻译、虚拟人技术及相关领域的最新进展。", "result": "SLTAT 2025不仅关注虚拟人技术，还收到了大量关于手语识别、数据收集与分析、工具开发、伦理考虑、可用性研究及情感计算等方面的投稿。", "conclusion": "SLTAT 2025通过跨学科交流，推动了手语翻译和虚拟人技术的进步，为改善聋人沟通提供了新的技术支持和研究方向。"}}
{"id": "2508.08149", "title": "REX-RAG: Reasoning Exploration with Policy Correction in Retrieval-Augmented Generation", "authors": ["Wentao Jiang", "Xiang Feng", "Zengmao Wang", "Yong Luo", "Pingbo Xu", "Zhe Chen", "Bo Du", "Jing Zhang"], "abstract": "Reinforcement learning (RL) is emerging as a powerful paradigm for enabling large language models (LLMs) to perform complex reasoning tasks. Recent advances indicate that integrating RL with retrieval-augmented generation (RAG) allows LLMs to dynamically incorporate external knowledge, leading to more informed and robust decision making. However, we identify a critical challenge during policy-driven trajectory sampling: LLMs are frequently trapped in unproductive reasoning paths, which we refer to as \"dead ends\", committing to overconfident yet incorrect conclusions. This severely hampers exploration and undermines effective policy optimization. To address this challenge, we propose REX-RAG (Reasoning Exploration with Policy Correction in Retrieval-Augmented Generation), a novel framework that explores alternative reasoning paths while maintaining rigorous policy learning through principled distributional corrections. Our approach introduces two key innovations: (1) Mixed Sampling Strategy, which combines a novel probe sampling method with exploratory prompts to escape dead ends; and (2) Policy Correction Mechanism, which employs importance sampling to correct distribution shifts induced by mixed sampling, thereby mitigating gradient estimation bias. We evaluate it on seven question-answering benchmarks, and the experimental results show that REX-RAG achieves average performance gains of 5.1% on Qwen2.5-3B and 3.6% on Qwen2.5-7B over strong baselines, demonstrating competitive results across multiple datasets. The code is publicly available at", "subjects": "Computation and Language (cs.CL)", "comments": "17 pages, 4 figures", "pdf_url": "https://arxiv.org/pdf/2508.08149.pdf", "abstract_url": "https://arxiv.org/abs/2508.08149", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "REX-RAG是一个新颖的框架，旨在通过策略校正增强检索增强生成中的推理探索，解决大型语言模型在复杂推理任务中陷入无效路径的问题。", "motivation": "大型语言模型在集成强化学习和检索增强生成进行复杂推理时，常因陷入无效推理路径（即“死胡同”）而影响探索效率和策略优化。", "method": "提出了REX-RAG框架，包含混合采样策略和策略校正机制，前者通过探针采样和探索性提示逃离死胡同，后者使用重要性采样校正分布偏移。", "result": "在七个问答基准测试中，REX-RAG在Qwen2.5-3B和Qwen2.5-7B上分别实现了5.1%和3.6%的平均性能提升。", "conclusion": "REX-RAG通过创新的探索和校正机制，有效提升了大型语言模型在检索增强生成中的推理能力和决策质量。"}}
{"id": "2508.07186", "title": "Multi-Dimensional Summarization Agents with Context-Aware Reasoning over Enterprise Tables", "authors": ["Amit Dhanda"], "abstract": "We propose a novel framework for summarizing structured enterprise data across multiple dimensions using large language model (LLM)-based agents. Traditional table-to-text models often lack the capacity to reason across hierarchical structures and context-aware deltas, which are essential in business reporting tasks. Our method introduces a multi-agent pipeline that extracts, analyzes, and summarizes multi-dimensional data using agents for slicing, variance detection, context construction, and LLM-based generation. Our results show that the proposed framework outperforms traditional approaches, achieving 83\\% faithfulness to underlying data, superior coverage of significant changes, and high relevance scores (4.4/5) for decision-critical insights. The improvements are especially pronounced in categories involving subtle trade-offs, such as increased revenue due to price changes amid declining unit volumes, which competing methods either overlook or address with limited specificity. We evaluate the framework on Kaggle datasets and demonstrate significant improvements in faithfulness, relevance, and insight quality over baseline table summarization approaches.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.07186.pdf", "abstract_url": "https://arxiv.org/abs/2508.07186", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "提出了一种新颖的框架，利用基于大型语言模型（LLM）的代理对结构化企业数据进行多维度总结。", "motivation": "解决传统表格到文本模型在业务报告任务中缺乏跨层次结构和上下文感知差异推理能力的问题。", "method": "引入了一个多代理管道，通过切片、方差检测、上下文构建和基于LLM的生成代理来提取、分析和总结多维数据。", "result": "所提出的框架在忠实度、显著变化覆盖率和决策关键见解的相关性评分上优于传统方法，尤其在涉及微妙权衡的类别中表现突出。", "conclusion": "该框架在Kaggle数据集上的评估显示，在忠实度、相关性和见解质量上比基线表格总结方法有显著改进。"}}
{"id": "2508.07292", "title": "EndoAgent: A Memory-Guided Reflective Agent for Intelligent Endoscopic Vision-to-Decision Reasoning", "authors": ["Yi Tang", "Kaini Wang", "Yang Chen", "Guangquan Zhou"], "abstract": "Developing general artificial intelligence (AI) systems to support endoscopic image diagnosis is an emerging research priority. Existing methods based on large-scale pretraining often lack unified coordination across tasks and struggle to handle the multi-step processes required in complex clinical workflows. While AI agents have shown promise in flexible instruction parsing and tool integration across domains, their potential in endoscopy remains underexplored. To address this gap, we propose EndoAgent, the first memory-guided agent for vision-to-decision endoscopic analysis that integrates iterative reasoning with adaptive tool selection and collaboration. Built on a dual-memory design, it enables sophisticated decision-making by ensuring logical coherence through short-term action tracking and progressively enhancing reasoning acuity through long-term experiential learning. To support diverse clinical tasks, EndoAgent integrates a suite of expert-designed tools within a unified reasoning loop. We further introduce EndoAgentBench, a benchmark of 5,709 visual question-answer pairs that assess visual understanding and language generation capabilities in realistic scenarios. Extensive experiments show that EndoAgent consistently outperforms both general and medical multimodal models, exhibiting its strong flexibility and reasoning capabilities.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.07292.pdf", "abstract_url": "https://arxiv.org/abs/2508.07292", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了EndoAgent，一种记忆引导的内窥镜视觉到决策推理智能代理，通过双记忆设计整合迭代推理与自适应工具选择，提升临床工作流的复杂多步骤处理能力。", "motivation": "现有的基于大规模预训练的方法在内窥镜图像诊断中缺乏任务间的统一协调，难以处理复杂临床工作流中的多步骤过程。", "method": "EndoAgent采用双记忆设计，通过短期行动跟踪确保逻辑一致性，并通过长期经验学习逐步增强推理敏锐度，整合了一套专家设计的工具在统一的推理循环中。", "result": "大量实验表明，EndoAgent在视觉理解和语言生成能力上 consistently outperforms both general and medical multimodal models，展示了其强大的灵活性和推理能力。", "conclusion": "EndoAgent为内窥镜视觉到决策分析提供了首个记忆引导的代理，通过集成迭代推理与自适应工具选择，显著提升了临床任务的执行效率和准确性。"}}
{"id": "2508.07334", "title": "Hallucination as a Computational Boundary: A Hierarchy of Inevitability and the Oracle Escape", "authors": ["Quan Shi", "Wang Xi", "Zenghui Ding", "Jianqing Gao", "Xianjun Yang"], "abstract": "The illusion phenomenon of large language models (LLMs) is the core obstacle to their reliable deployment. This article formalizes the large language model as a probabilistic Turing machine by constructing a \"computational necessity hierarchy\", and for the first time proves the illusions are inevitable on diagonalization, incomputability, and information theory boundaries supported by the new \"learner pump lemma\". However, we propose two \"escape routes\": one is to model Retrieval Enhanced Generations (RAGs) as oracle machines, proving their absolute escape through \"computational jumps\", providing the first formal theory for the effectiveness of RAGs; The second is to formalize continuous learning as an \"internalized oracle\" mechanism and implement this path through a novel neural game theory", "subjects": "Artificial Intelligence (cs.AI)", "comments": "8 pages, 6 figures", "pdf_url": "https://arxiv.org/pdf/2508.07334.pdf", "abstract_url": "https://arxiv.org/abs/2508.07334", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文通过构建‘计算必要性层次’，首次证明了大型语言模型（LLMs）的幻觉现象在不可计算性和信息理论边界上是不可避免的，并提出了两种‘逃脱路径’：一种是将检索增强生成（RAGs）建模为预言机机器，证明其通过‘计算跳跃’绝对逃脱；另一种是通过新颖的神经博弈论实现连续学习作为‘内化预言机’机制。", "motivation": "解决大型语言模型（LLMs）幻觉现象这一核心障碍，以实现其可靠部署。", "method": "通过构建‘计算必要性层次’和‘学习者泵引理’，将大型语言模型形式化为概率图灵机，并探索两种逃脱路径：RAGs作为预言机机器和连续学习作为‘内化预言机’机制。", "result": "证明了幻觉现象在不可计算性和信息理论边界上的不可避免性，并提出了两种有效的逃脱路径。", "conclusion": "本文不仅为大型语言模型的幻觉现象提供了理论基础，还为通过RAGs和连续学习实现可靠部署提供了新的理论和方法。"}}
{"id": "2508.07407", "title": "A Comprehensive Survey of Self-Evolving AI Agents: A New Paradigm Bridging Foundation Models and Lifelong Agentic Systems", "authors": ["Jinyuan Fang", "Yanwen Peng", "Xi Zhang", "Yingxu Wang", "Xinhao Yi", "Guibin Zhang", "Yi Xu", "Bin Wu", "Siwei Liu", "Zihao Li", "Zhaochun Ren", "Nikos Aletras", "Xi Wang", "Han Zhou", "Zaiqiao Meng"], "abstract": "Recent advances in large language models have sparked growing interest in AI agents capable of solving complex, real-world tasks. However, most existing agent systems rely on manually crafted configurations that remain static after deployment, limiting their ability to adapt to dynamic and evolving environments. To this end, recent research has explored agent evolution techniques that aim to automatically enhance agent systems based on interaction data and environmental feedback. This emerging direction lays the foundation for self-evolving AI agents, which bridge the static capabilities of foundation models with the continuous adaptability required by lifelong agentic systems. In this survey, we provide a comprehensive review of existing techniques for self-evolving agentic systems. Specifically, we first introduce a unified conceptual framework that abstracts the feedback loop underlying the design of self-evolving agentic systems. The framework highlights four key components: System Inputs, Agent System, Environment, and Optimisers, serving as a foundation for understanding and comparing different strategies. Based on this framework, we systematically review a wide range of self-evolving techniques that target different components of the agent system. We also investigate domain-specific evolution strategies developed for specialised fields such as biomedicine, programming, and finance, where optimisation objectives are tightly coupled with domain constraints. In addition, we provide a dedicated discussion on the evaluation, safety, and ethical considerations for self-evolving agentic systems, which are critical to ensuring their effectiveness and reliability. This survey aims to provide researchers and practitioners with a systematic understanding of self-evolving AI agents, laying the foundation for the development of more adaptive, autonomous, and lifelong agentic systems.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.07407.pdf", "abstract_url": "https://arxiv.org/abs/2508.07407", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文综述了自进化AI代理的最新研究，探讨了如何通过自动增强技术使代理系统适应动态环境，提出了一个统一的概念框架，并回顾了针对不同组件的自进化技术，以及特定领域的进化策略，同时讨论了评估、安全和伦理问题。", "motivation": "解决现有AI代理系统依赖手动配置、无法适应动态环境的问题，探索自进化AI代理作为基础模型与终身代理系统之间的桥梁。", "method": "提出一个统一的概念框架，抽象出自进化代理系统设计的反馈循环，系统回顾针对代理系统不同组件的自进化技术，以及特定领域的进化策略。", "result": "提供了一个全面的自进化AI代理技术综述，包括统一框架、技术回顾、特定领域策略及伦理安全讨论，为开发更自适应、自主和终身的代理系统奠定基础。", "conclusion": "自进化AI代理代表了连接静态基础模型与终身代理系统的新范式，其发展需要综合考虑技术、评估、安全及伦理因素，以实现更广泛的应用。"}}
{"id": "2508.07466", "title": "Grounding Natural Language for Multi-agent Decision-Making with Multi-agentic LLMs", "authors": ["Dom Huh", "Prasant Mohapatra"], "abstract": "Language is a ubiquitous tool that is foundational to reasoning and collaboration, ranging from everyday interactions to sophisticated problem-solving tasks. The establishment of a common language can serve as a powerful asset in ensuring clear communication and understanding amongst agents, facilitating desired coordination and strategies. In this work, we extend the capabilities of large language models (LLMs) by integrating them with advancements in multi-agent decision-making algorithms. We propose a systematic framework for the design of multi-agentic large language models (LLMs), focusing on key integration practices. These include advanced prompt engineering techniques, the development of effective memory architectures, multi-modal information processing, and alignment strategies through fine-tuning algorithms. We evaluate these design choices through extensive ablation studies on classic game settings with significant underlying social dilemmas and game-theoretic considerations.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.07466.pdf", "abstract_url": "https://arxiv.org/abs/2508.07466", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种多智能体大型语言模型（LLMs）的系统框架，旨在通过整合多智能体决策算法和LLMs的能力，促进智能体间的清晰沟通和协作。", "motivation": "解决多智能体系统中语言理解和协作的问题，通过建立共同语言来优化沟通和策略协调。", "method": "采用先进的提示工程技术、有效的记忆架构设计、多模态信息处理以及通过微调算法实现的对齐策略。", "result": "通过在具有显著社会困境和博弈论考虑的经典游戏设置上进行广泛的消融研究，评估了这些设计选择的有效性。", "conclusion": "提出的框架为多智能体决策中的自然语言理解和使用提供了系统的方法，有望在多智能体协作和复杂问题解决中发挥重要作用。"}}
{"id": "2508.07468", "title": "CP-Agent: Agentic Constraint Programming", "authors": ["Stefan Szeider"], "abstract": "Translating natural language problem descriptions into formal constraint models remains a fundamental challenge in constraint programming, requiring deep expertise in both the problem domain and modeling frameworks. Previous approaches to automating this translation have employed fixed workflows with predetermined modeling steps, failing on a significant number of benchmark problems. We present a new approach using a pure agentic strategy without any fixed pipeline. We developed a general-purpose Python coding agent based on the ReAct (Reason and Act) principle, utilizing a persistent IPython kernel for stateful code execution and iterative development. Rather than embedding constraint programming logic into the agent architecture, domain-specific expertise is injected solely through a carefully crafted project prompt. The agent combines this prompt-encoded knowledge with access to file operations and code execution tools, enabling it to test hypotheses, debug failures, and verify solutions dynamically. Implemented in just a few hundred lines of code, this architecture successfully solves all 101 problems of the CP-Bench constraint programming benchmark set. The results suggest that constraint modeling tasks require the combination of general coding tools and domain expertise encoded in prompts, rather than specialized agent architectures or predefined workflows.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Software Engineering (cs.SE)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.07468.pdf", "abstract_url": "https://arxiv.org/abs/2508.07468", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)", "Software Engineering (cs.SE)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种新的方法CP-Agent，使用纯代理策略，无需固定流程，成功解决了CP-Bench约束编程基准集中的所有101个问题。", "motivation": "将自然语言问题描述转化为正式的约束模型是约束编程中的一个基本挑战，需要深厚的问题领域和建模框架专业知识。以往的方法采用固定流程，无法解决大量基准问题。", "method": "基于ReAct（Reason and Act）原则，开发了一个通用的Python编码代理，利用持久的IPython内核进行有状态的代码执行和迭代开发。领域特定知识通过精心设计的项目提示注入，而非嵌入到代理架构中。", "result": "该架构仅用几百行代码实现，成功解决了CP-Bench约束编程基准集中的所有101个问题。", "conclusion": "结果表明，约束建模任务需要结合通用编码工具和提示中编码的领域专业知识，而非专门的代理架构或预定义的工作流程。"}}
{"id": "2508.07575", "title": "MCPToolBench++: A Large Scale AI Agent Model Context Protocol MCP Tool Use Benchmark", "authors": ["Shiqing Fan", "Xichen Ding", "Liang Zhang", "Linjian Mo"], "abstract": "LLMs' capabilities are enhanced by using function calls to integrate various data sources or API results into the context window. Typical tools include search, web crawlers, maps, financial data, file systems, and browser usage, etc. Integrating these data sources or functions requires a standardized method. The Model Context Protocol (MCP) provides a standardized way to supply context to LLMs. However, the evaluation of LLMs and AI Agents' MCP tool use abilities suffer from several issues. First, there's a lack of comprehensive datasets or benchmarks to evaluate various MCP tools. Second, the diverse formats of response from MCP tool call execution further increase the difficulty of evaluation. Additionally, unlike existing tool-use benchmarks with high success rates in functions like programming and math functions, the success rate of real-world MCP tool is not guaranteed and varies across different MCP servers. Furthermore, the LLMs' context window also limits the number of available tools that can be called in a single run, because the textual descriptions of tool and the parameters have long token length for an LLM to process all at once. To help address the challenges of evaluating LLMs' performance on calling MCP tools, we propose MCPToolBench++, a large-scale, multi-domain AI Agent tool use benchmark. As of July 2025, this benchmark is build upon marketplace of over 4k MCP servers from more than 40 categories, collected from the MCP marketplaces and GitHub communities. The datasets consist of both single-step and multi-step tool calls across different categories. We evaluated SOTA LLMs with agentic abilities on this benchmark and reported the results.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "Benchmarks and Source Code Released", "pdf_url": "https://arxiv.org/pdf/2508.07575.pdf", "abstract_url": "https://arxiv.org/abs/2508.07575", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "MCPToolBench++是一个大规模、多领域的AI代理工具使用基准，旨在解决评估LLMs和AI代理使用MCP工具能力的挑战。", "motivation": "解决评估LLMs和AI代理使用MCP工具能力时缺乏全面数据集或基准、响应格式多样、成功率不保证以及上下文窗口限制等问题。", "method": "提出了MCPToolBench++基准，基于来自MCP市场和GitHub社区的超过4k个MCP服务器和40多个类别的数据集，包括单步和多步工具调用。", "result": "在SOTA LLMs上进行了评估，并报告了结果。", "conclusion": "MCPToolBench++为评估LLMs在调用MCP工具方面的性能提供了一个有效的解决方案，有助于推动相关领域的研究和发展。"}}
{"id": "2508.07586", "title": "Optimization of Private Semantic Communication Performance: An Uncooperative Covert Communication Method", "authors": ["Wenjing Zhang", "Ye Hu", "Tao Luo", "Zhilong Zhang", "Mingzhe Chen"], "abstract": "In this paper, a novel covert semantic communication framework is investigated. Within this framework, a server extracts and transmits the semantic information, i.e., the meaning of image data, to a user over several time slots. An attacker seeks to detect and eavesdrop the semantic transmission to acquire details of the original image. To avoid data meaning being eavesdropped by an attacker, a friendly jammer is deployed to transmit jamming signals to interfere the attacker so as to hide the transmitted semantic information. Meanwhile, the server will strategically select time slots for semantic information transmission. Due to limited energy, the jammer will not communicate with the server and hence the server does not know the transmit power of the jammer. Therefore, the server must jointly optimize the semantic information transmitted at each time slot and the corresponding transmit power to maximize the privacy and the semantic information transmission quality of the user. To solve this problem, we propose a prioritised sampling assisted twin delayed deep deterministic policy gradient algorithm to jointly determine the transmitted semantic information and the transmit power per time slot without the communications between the server and the jammer. Compared to standard reinforcement learning methods, the propose method uses an additional Q network to estimate Q values such that the agent can select the action with a lower Q value from the two Q networks thus avoiding local optimal action selection and estimation bias of Q values. Simulation results show that the proposed algorithm can improve the privacy and the semantic information transmission quality by up to 77.8% and 14.3% compared to the traditional reinforcement learning methods.", "subjects": "Artificial Intelligence (cs.AI); Networking and Internet Architecture (cs.NI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.07586.pdf", "abstract_url": "https://arxiv.org/abs/2508.07586", "categories": ["Artificial Intelligence (cs.AI)", "Networking and Internet Architecture (cs.NI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究了一种新颖的隐蔽语义通信框架，旨在通过友好干扰器和服务器策略性选择时间槽来优化隐私和语义信息传输质量，提出了一种优先采样辅助的双延迟深度确定性策略梯度算法，显著提高了隐私和传输质量。", "motivation": "解决在语义通信中，如何避免攻击者窃取和检测语义信息的问题，特别是在服务器和干扰器之间无通信的情况下，如何联合优化传输的语义信息和发射功率。", "method": "提出了一种优先采样辅助的双延迟深度确定性策略梯度算法，通过额外的Q网络估计Q值，避免局部最优动作选择和Q值估计偏差。", "result": "仿真结果表明，与传统强化学习方法相比，所提算法能将隐私和语义信息传输质量分别提高高达77.8%和14.3%。", "conclusion": "该研究为无协作隐蔽通信提供了一种有效的解决方案，通过算法优化显著提升了通信的隐私和语义信息传输质量。"}}
{"id": "2508.06591", "title": "Generative Artificial Intelligence Extracts Structure-Function Relationships from Plants for New Materials", "authors": ["Rachel K. Luu", "Jingyu Deng", "Mohammed Shahrudin Ibrahim", "Nam-Joon Cho", "Ming Dao", "Subra Suresh", "Markus J. Buehler"], "abstract": "Large language models (LLMs) have reshaped the research landscape by enabling new approaches to knowledge retrieval and creative ideation. Yet their application in discipline-specific experimental science, particularly in highly multi-disciplinary domains like materials science, remains limited. We present a first-of-its-kind framework that integrates generative AI with literature from hitherto-unconnected fields such as plant science, biomimetics, and materials engineering to extract insights and design experiments for materials. We focus on humidity-responsive systems such as pollen-based materials and Rhapis excelsa (broadleaf lady palm) leaves, which exhibit self-actuation and adaptive performance. Using a suite of AI tools, including a fine-tuned model (BioinspiredLLM), Retrieval-Augmented Generation (RAG), agentic systems, and a Hierarchical Sampling strategy, we extract structure-property relationships and translate them into new classes of bioinspired materials. Structured inference protocols generate and evaluate hundreds of hypotheses from a single query, surfacing novel and experimentally tractable ideas. We validate our approach through real-world implementation: LLM-generated procedures, materials designs, and mechanical predictions were tested in the laboratory, culminating in the fabrication of a novel pollen-based adhesive with tunable morphology and measured shear strength, establishing a foundation for future plant-derived adhesive design. This work demonstrates how AI-assisted ideation can drive real-world materials design and enable effective human-AI collaboration.", "subjects": "Machine Learning (cs.LG); Disordered Systems and Neural Networks (cond-mat.dis-nn); Materials Science (cond-mat.mtrl-sci); Other Condensed Matter (cond-mat.other); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.06591.pdf", "abstract_url": "https://arxiv.org/abs/2508.06591", "categories": ["Machine Learning (cs.LG)", "Disordered Systems and Neural Networks (cond-mat.dis-nn)", "Materials Science (cond-mat.mtrl-sci)", "Other Condensed Matter (cond-mat.other)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic", "@RAG"], "AI": {"tldr": "本文介绍了一种首创的框架，结合生成式AI与植物科学、仿生学和材料工程等领域的文献，以提取见解并设计材料实验，特别是在湿度响应系统方面。通过AI工具，包括定制模型、检索增强生成、代理系统和分层采样策略，提取结构-性能关系并将其转化为新型仿生材料。通过实验室测试验证了AI生成的设计和预测，成功制造了一种新型花粉基粘合剂。", "motivation": "探索生成式人工智能在多学科领域如材料科学中的应用，特别是在提取结构-功能关系和设计新型材料方面的潜力。", "method": "集成生成式AI与多学科文献，使用包括BioinspiredLLM、检索增强生成(RAG)、代理系统和分层采样策略在内的AI工具，提取结构-性能关系并转化为新材料设计。", "result": "通过实验室测试验证了AI生成的材料设计和机械预测，成功制造了一种具有可调形态和测量剪切强度的新型花粉基粘合剂。", "conclusion": "这项工作展示了AI辅助构思如何推动现实世界的材料设计，并实现有效的人机协作，为未来植物衍生材料的设计奠定了基础。"}}
{"id": "2508.06905", "title": "MultiRef: Controllable Image Generation with Multiple Visual References", "authors": ["Ruoxi Chen", "Dongping Chen", "Siyuan Wu", "Sinan Wang", "Shiyun Lang", "Petr Sushko", "Gaoyang Jiang", "Yao Wan", "Ranjay Krishna"], "abstract": "Visual designers naturally draw inspiration from multiple visual references, combining diverse elements and aesthetic principles to create artwork. However, current image generative frameworks predominantly rely on single-source inputs -- either text prompts or individual reference images. In this paper, we focus on the task of controllable image generation using multiple visual references. We introduce MultiRef-bench, a rigorous evaluation framework comprising 990 synthetic and 1,000 real-world samples that require incorporating visual content from multiple reference images. The synthetic samples are synthetically generated through our data engine RefBlend, with 10 reference types and 33 reference combinations. Based on RefBlend, we further construct a dataset MultiRef containing 38k high-quality images to facilitate further research. Our experiments across three interleaved image-text models (i.e., OmniGen, ACE, and Show-o) and six agentic frameworks (e.g., ChatDiT and LLM + SD) reveal that even state-of-the-art systems struggle with multi-reference conditioning, with the best model OmniGen achieving only 66.6% in synthetic samples and 79.0% in real-world cases on average compared to the golden answer. These findings provide valuable directions for developing more flexible and human-like creative tools that can effectively integrate multiple sources of visual inspiration. The dataset is publicly available at:", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "Accepted to ACM MM 2025 Datasets", "pdf_url": "https://arxiv.org/pdf/2508.06905.pdf", "abstract_url": "https://arxiv.org/abs/2508.06905", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了MultiRef，一个专注于使用多个视觉参考进行可控图像生成的任务，并提出了MultiRef-bench评估框架和MultiRef数据集，以促进相关研究。", "motivation": "解决当前图像生成框架主要依赖单源输入（如文本提示或单个参考图像）的限制，探索如何从多个视觉参考中获取灵感并生成图像。", "method": "通过RefBlend数据引擎生成合成样本，构建包含38k高质量图像的MultiRef数据集，并在三个交错的图像-文本模型和六个代理框架上进行实验。", "result": "实验显示，即使是先进的系统在多参考条件处理上也存在困难，最佳模型OmniGen在合成样本和真实案例中的平均表现分别为66.6%和79.0%。", "conclusion": "这些发现为开发更灵活、更接近人类创造力的工具提供了宝贵的方向，这些工具能够有效整合多种视觉灵感来源。"}}
{"id": "2508.06916", "title": "Talk2Image: A Multi-Agent System for Multi-Turn Image Generation and Editing", "authors": ["Shichao Ma", "Yunhe Guo", "Jiahao Su", "Qihe Huang", "Zhengyang Zhou", "Yang Wang"], "abstract": "Text-to-image generation tasks have driven remarkable advances in diverse media applications, yet most focus on single-turn scenarios and struggle with iterative, multi-turn creative tasks. Recent dialogue-based systems attempt to bridge this gap, but their single-agent, sequential paradigm often causes intention drift and incoherent edits. To address these limitations, we present Talk2Image, a novel multi-agent system for interactive image generation and editing in multi-turn dialogue scenarios. Our approach integrates three key components: intention parsing from dialogue history, task decomposition and collaborative execution across specialized agents, and feedback-driven refinement based on a multi-view evaluation mechanism. Talk2Image enables step-by-step alignment with user intention and consistent image editing. Experiments demonstrate that Talk2Image outperforms existing baselines in controllability, coherence, and user satisfaction across iterative image generation and editing tasks.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.06916.pdf", "abstract_url": "https://arxiv.org/abs/2508.06916", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了Talk2Image，一个用于多轮对话场景中交互式图像生成和编辑的多代理系统。该系统通过意图解析、任务分解和协作执行以及基于多视图评估机制的反馈驱动细化，实现了与用户意图的逐步对齐和一致的图像编辑。实验表明，Talk2Image在可控性、连贯性和用户满意度方面优于现有基线。", "motivation": "解决文本到图像生成任务中单轮场景的局限性，以及单代理、顺序范式在多轮创意任务中导致的意图漂移和不连贯编辑问题。", "method": "提出Talk2Image，一个多代理系统，集成意图解析、任务分解和协作执行、基于多视图评估机制的反馈驱动细化三个关键组件。", "result": "Talk2Image在迭代图像生成和编辑任务中，在可控性、连贯性和用户满意度方面优于现有基线。", "conclusion": "Talk2Image通过多代理系统和多轮对话机制，有效支持了复杂的图像生成和编辑任务，提高了与用户意图的对齐和编辑的一致性。"}}
{"id": "2508.07642", "title": "Breaking Down and Building Up: Mixture of Skill-Based Vision-and-Language Navigation Agents", "authors": ["Tianyi Ma", "Yue Zhang", "Zehao Wang", "Parisa Kordjamshidi"], "abstract": "Vision-and-Language Navigation (VLN) poses significant challenges in enabling agents to interpret natural language instructions and navigate complex 3D environments. While recent progress has been driven by large-scale pre-training and data augmentation, current methods still struggle to generalize to unseen scenarios, particularly when complex spatial and temporal reasoning is required. In this work, we propose SkillNav, a modular framework that introduces structured, skill-based reasoning into Transformer-based VLN agents. Our method decomposes navigation into a set of interpretable atomic skills (e.g., Vertical Movement, Area and Region Identification, Stop and Pause), each handled by a specialized agent. We then introduce a novel zero-shot Vision-Language Model (VLM)-based router, which dynamically selects the most suitable agent at each time step by aligning sub-goals with visual observations and historical actions. SkillNav achieves a new state-of-the-art performance on the R2R benchmark and demonstrates strong generalization to the GSA-R2R benchmark that includes novel instruction styles and unseen environments.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)", "comments": "18 pages, 5 Figures,", "pdf_url": "https://arxiv.org/pdf/2508.07642.pdf", "abstract_url": "https://arxiv.org/abs/2508.07642", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "提出SkillNav，一个模块化框架，通过基于技能的推理提升Transformer基础的视觉与语言导航（VLN）代理的性能。", "motivation": "解决视觉与语言导航（VLN）中代理在未见场景下泛化能力不足的问题，特别是在需要复杂空间和时间推理时。", "method": "将导航分解为一组可解释的原子技能，每个技能由专门的代理处理，并引入基于零样本视觉语言模型（VLM）的路由器动态选择最适合的代理。", "result": "在R2R基准测试中达到新的最先进性能，并在包含新指令风格和未见环境的GSA-R2R基准测试中表现出强大的泛化能力。", "conclusion": "SkillNav通过模块化和基于技能的方法显著提高了VLN代理的性能和泛化能力，为未来的研究提供了新的方向。"}}
{"id": "2508.07667", "title": "1-2-3 Check: Enhancing Contextual Privacy in LLM via Multi-Agent Reasoning", "authors": ["Wenkai Li", "Liwen Sun", "Zhenxiang Guan", "Xuhui Zhou", "Maarten Sap"], "abstract": "Addressing contextual privacy concerns remains challenging in interactive settings where large language models (LLMs) process information from multiple sources (e.g., summarizing meetings with private and public information). We introduce a multi-agent framework that decomposes privacy reasoning into specialized subtasks (extraction, classification), reducing the information load on any single agent while enabling iterative validation and more reliable adherence to contextual privacy norms. To understand how privacy errors emerge and propagate, we conduct a systematic ablation over information-flow topologies, revealing when and why upstream detection mistakes cascade into downstream leakage. Experiments on the ConfAIde and PrivacyLens benchmark with several open-source and closed-sourced LLMs demonstrate that our best multi-agent configuration substantially reduces private information leakage (\\textbf{18\\%} on ConfAIde and \\textbf{19\\%} on PrivacyLens with GPT-4o) while preserving the fidelity of public content, outperforming single-agent baselines. These results highlight the promise of principled information-flow design in multi-agent systems for contextual privacy with LLMs.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.07667.pdf", "abstract_url": "https://arxiv.org/abs/2508.07667", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种多智能体框架，通过将隐私推理分解为专门子任务（提取、分类）来增强大型语言模型（LLMs）在交互设置中的上下文隐私保护，有效减少了私人信息泄露，同时在公共内容上保持了高保真度。", "motivation": "解决在交互设置中，大型语言模型（LLMs）处理来自多个来源信息（如包含私人和公共信息的会议摘要）时的上下文隐私问题。", "method": "引入一个多智能体框架，将隐私推理分解为专门的子任务（提取、分类），减少单个智能体的信息负载，同时实现迭代验证和更可靠地遵守上下文隐私规范。", "result": "在ConfAIde和PrivacyLens基准测试中，使用GPT-4o的最佳多智能体配置显著减少了私人信息泄露（ConfAIde上18%，PrivacyLens上19%），同时保持了公共内容的保真度，优于单智能体基线。", "conclusion": "这些结果强调了在多智能体系统中进行原则性信息流设计，在LLMs中实现上下文隐私的潜力。"}}
{"id": "2508.07671", "title": "EMPATHIA: Multi-Faceted Human-AI Collaboration for Refugee Integration", "authors": ["Mohamed Rayan Barhdadi", "Mehmet Tuncel", "Erchin Serpedin", "Hasan Kurban"], "abstract": "Current AI approaches to refugee integration optimize narrow objectives such as employment and fail to capture the cultural, emotional, and ethical dimensions critical for long-term success. We introduce EMPATHIA (Enriched Multimodal Pathways for Agentic Thinking in Humanitarian Immigrant Assistance), a multi-agent framework addressing the central Creative AI question: how do we preserve human dignity when machines participate in life-altering decisions? Grounded in Kegan's Constructive Developmental Theory, EMPATHIA decomposes integration into three modules: SEED (Socio-cultural Entry and Embedding Decision) for initial placement, RISE (Rapid Integration and Self-sufficiency Engine) for early independence, and THRIVE (Transcultural Harmony and Resilience through Integrated Values and Engagement) for sustained outcomes. SEED employs a selector-validator architecture with three specialized agents - emotional, cultural, and ethical - that deliberate transparently to produce interpretable recommendations. Experiments on the UN Kakuma dataset (15,026 individuals, 7,960 eligible adults 15+ per ILO/UNHCR standards) and implementation on 6,359 working-age refugees (15+) with 150+ socioeconomic variables achieved 87.4% validation convergence and explainable assessments across five host countries. EMPATHIA's weighted integration of cultural, emotional, and ethical factors balances competing value systems while supporting practitioner-AI collaboration. By augmenting rather than replacing human expertise, EMPATHIA provides a generalizable framework for AI-driven allocation tasks where multiple values must be reconciled.", "subjects": "Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Human-Computer Interaction (cs.HC); Multiagent Systems (cs.MA); Applications (stat.AP)", "comments": "19 pages, 3 figures (plus 6 figures in supplementary), 2 tables, 1 algorithm. Submitted to NeurIPS 2025 Creative AI Track: Humanity", "pdf_url": "https://arxiv.org/pdf/2508.07671.pdf", "abstract_url": "https://arxiv.org/abs/2508.07671", "categories": ["Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)", "Human-Computer Interaction (cs.HC)", "Multiagent Systems (cs.MA)", "Applications (stat.AP)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "EMPATHIA是一个多代理框架，旨在通过考虑文化、情感和伦理维度，改善难民整合过程，保持人类尊严。", "motivation": "解决当前AI在难民整合中仅优化狭窄目标（如就业）而忽视文化、情感和伦理维度的问题。", "method": "基于Kegan的建构发展理论，EMPATHIA将整合过程分解为三个模块：SEED（初始安置）、RISE（早期独立）和THRIVE（持续成果），采用选择器-验证器架构和三个专门代理（情感、文化、伦理）进行透明审议。", "result": "在UN Kakuma数据集上的实验显示，EMPATHIA实现了87.4%的验证收敛，并在五个东道国提供了可解释的评估。", "conclusion": "EMPATHIA通过加权整合文化、情感和伦理因素，平衡了竞争价值系统，支持实践者与AI的协作，为需要调和多种价值的AI驱动分配任务提供了通用框架。"}}
{"id": "2508.07673", "title": "Ethics2vec: aligning automatic agents and human preferences", "authors": ["Gianluca Bontempi"], "abstract": "Though intelligent agents are supposed to improve human experience (or make it more efficient), it is hard from a human perspective to grasp the ethical values which are explicitly or implicitly embedded in an agent behaviour. This is the well-known problem of alignment, which refers to the challenge of designing AI systems that align with human values, goals and preferences. This problem is particularly challenging since most human ethical considerations refer to \\emph{incommensurable} (i.e. non-measurable and/or incomparable) values and criteria. Consider, for instance, a medical agent prescribing a treatment to a cancerous patient. How could it take into account (and/or weigh) incommensurable aspects like the value of a human life and the cost of the treatment? Now, the alignment between human and artificial values is possible only if we define a common space where a metric can be defined and used. This paper proposes to extend to ethics the conventional Anything2vec approach, which has been successful in plenty of similar and hard-to-quantify domains (ranging from natural language processing to recommendation systems and graph analysis). This paper proposes a way to map an automatic agent decision-making (or control law) strategy to a multivariate vector representation, which can be used to compare and assess the alignment with human values. The Ethics2Vec method is first introduced in the case of an automatic agent performing binary decision-making. Then, a vectorisation of an automatic control law (like in the case of a self-driving car) is discussed to show how the approach can be extended to automatic control settings.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.07673.pdf", "abstract_url": "https://arxiv.org/abs/2508.07673", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为Ethics2vec的方法，旨在通过将自动代理的决策或控制策略映射到多元向量表示，来解决AI系统与人类价值观、目标和偏好对齐的问题。", "motivation": "解决智能代理与人类价值观对齐的挑战，特别是在涉及不可通约（即不可测量和/或不可比较）的价值观和标准时。", "method": "扩展了传统的Anything2vec方法，将其应用于伦理学领域，提出了一种将自动代理的决策或控制策略向量化的方法。", "result": "提出了Ethics2Vec方法，首先在自动代理进行二元决策的情况下引入，然后讨论了如何将自动控制律（如自动驾驶汽车的情况）向量化，以展示该方法如何扩展到自动控制设置。", "conclusion": "通过定义一个可以定义和使用度量的共同空间，Ethics2vec方法为实现人工和人类价值观之间的对齐提供了一种可能的途径。"}}
{"id": "2508.07941", "title": "Deep Reinforcement Learning with anticipatory reward in LSTM for Collision Avoidance of Mobile Robots", "authors": ["Olivier Poulet", "Frédéric Guinand", "François Guérin"], "abstract": "This article proposes a collision risk anticipation method based on short-term prediction of the agents position. A Long Short-Term Memory (LSTM) model, trained on past trajectories, is used to estimate the next position of each robot. This prediction allows us to define an anticipated collision risk by dynamically modulating the reward of a Deep Q-Learning Network (DQN) agent. The approach is tested in a constrained environment, where two robots move without communication or identifiers. Despite a limited sampling frequency (1 Hz), the results show a significant decrease of the collisions number and a stability improvement. The proposed method, which is computationally inexpensive, appears particularly attractive for implementation on embedded systems.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.07941.pdf", "abstract_url": "https://arxiv.org/abs/2508.07941", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于短时预测的碰撞风险预判方法，利用LSTM模型预测机器人位置，通过动态调整DQN智能体的奖励来定义预期碰撞风险。在受限环境中测试，结果显示碰撞次数显著减少，稳定性提高。", "motivation": "解决移动机器人在无通信或标识情况下的碰撞避免问题。", "method": "使用LSTM模型预测机器人位置，动态调整DQN智能体的奖励以预判碰撞风险。", "result": "在1 Hz的有限采样频率下，碰撞次数显著减少，稳定性得到改善。", "conclusion": "该方法计算成本低，特别适合嵌入式系统实现，有效提高了移动机器人的碰撞避免能力和稳定性。"}}
{"id": "2508.07950", "title": "FEAT: A Multi-Agent Forensic AI System with Domain-Adapted Large Language Model for Automated Cause-of-Death Analysis", "authors": ["Chen Shen", "Wanqing Zhang", "Kehan Li", "Erwen Huang", "Haitao Bi", "Aiying Fan", "Yiwen Shen", "Hongmei Dong", "Ji Zhang", "Yuming Shao", "Zengjia Liu", "Xinshe Liu", "Tao Li", "Chunxia Yan", "Shuanliang Fan", "Di Wu", "Jianhua Ma", "Bin Cong", "Zhenyuan Wang", "Chunfeng Lian"], "abstract": "Forensic cause-of-death determination faces systemic challenges, including workforce shortages and diagnostic variability, particularly in high-volume systems like China's medicolegal infrastructure. We introduce FEAT (ForEnsic AgenT), a multi-agent AI framework that automates and standardizes death investigations through a domain-adapted large language model. FEAT's application-oriented architecture integrates: (i) a central Planner for task decomposition, (ii) specialized Local Solvers for evidence analysis, (iii) a Memory & Reflection module for iterative refinement, and (iv) a Global Solver for conclusion synthesis. The system employs tool-augmented reasoning, hierarchical retrieval-augmented generation, forensic-tuned LLMs, and human-in-the-loop feedback to ensure legal and medical validity. In evaluations across diverse Chinese case cohorts, FEAT outperformed state-of-the-art AI systems in both long-form autopsy analyses and concise cause-of-death conclusions. It demonstrated robust generalization across six geographic regions and achieved high expert concordance in blinded validations. Senior pathologists validated FEAT's outputs as comparable to those of human experts, with improved detection of subtle evidentiary nuances. To our knowledge, FEAT is the first LLM-based AI agent system dedicated to forensic medicine, offering scalable, consistent death certification while maintaining expert-level rigor. By integrating AI efficiency with human oversight, this work could advance equitable access to reliable medicolegal services while addressing critical capacity constraints in forensic systems.", "subjects": "Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Multiagent Systems (cs.MA)", "comments": "18pages, 6 figures", "pdf_url": "https://arxiv.org/pdf/2508.07950.pdf", "abstract_url": "https://arxiv.org/abs/2508.07950", "categories": ["Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "FEAT是一个多代理AI系统，通过领域适应的大型语言模型自动化并标准化死亡调查，解决了法医死因确定中的挑战。", "motivation": "解决法医死因确定中的系统性挑战，如劳动力短缺和诊断变异性，特别是在中国的高容量法医体系中。", "method": "采用多代理AI框架，包括中央规划器、本地求解器、记忆与反思模块和全局求解器，结合工具增强推理、层次检索增强生成和法医调谐的LLMs。", "result": "FEAT在多样化的中国案例队列中评估，表现优于最先进的AI系统，并在盲法验证中实现了高专家一致性。", "conclusion": "FEAT是首个基于LLM的AI代理系统，致力于法医学，提供可扩展、一致的死亡证明，同时保持专家级别的严谨性。"}}
{"id": "2508.07201", "title": "Propagation Tree Is Not Deep: Adaptive Graph Contrastive Learning Approach for Rumor Detection", "authors": ["Chaoqun Cui", "Caiyan Jia"], "abstract": "Rumor detection on social media has become increasingly important. Most existing graph-based models presume rumor propagation trees (RPTs) have deep structures and learn sequential stance features along branches. However, through statistical analysis on real-world datasets, we find RPTs exhibit wide structures, with most nodes being shallow 1-level replies. To focus learning on intensive substructures, we propose Rumor Adaptive Graph Contrastive Learning (RAGCL) method with adaptive view augmentation guided by node centralities. We summarize three principles for RPT augmentation: 1) exempt root nodes, 2) retain deep reply nodes, 3) preserve lower-level nodes in deep sections. We employ node dropping, attribute masking and edge dropping with probabilities from centrality-based importance scores to generate views. A graph contrastive objective then learns robust rumor representations. Extensive experiments on four benchmark datasets demonstrate RAGCL outperforms state-of-the-art methods. Our work reveals the wide-structure nature of RPTs and contributes an effective graph contrastive learning approach tailored for rumor detection through principled adaptive augmentation. The proposed principles and augmentation techniques can potentially benefit other applications involving tree-structured graphs.", "subjects": "Social and Information Networks (cs.SI); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "This paper is accepted by AAAI2024", "pdf_url": "https://arxiv.org/pdf/2508.07201.pdf", "abstract_url": "https://arxiv.org/abs/2508.07201", "categories": ["Social and Information Networks (cs.SI)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种名为RAGCL的自适应图对比学习方法，用于社交媒体上的谣言检测。通过统计分析真实世界数据集，发现谣言传播树（RPTs）具有广泛的结构，大多数节点为浅层1级回复。RAGCL方法通过节点中心性指导的自适应视图增强，专注于密集子结构的学习，并在四个基准数据集上表现出优于现有方法的性能。", "motivation": "解决现有基于图的模型假设谣言传播树具有深层结构，而实际上大多数节点为浅层回复的问题，提出了一种更有效的谣言检测方法。", "method": "提出了Rumor Adaptive Graph Contrastive Learning (RAGCL)方法，通过节点中心性指导的自适应视图增强（包括节点丢弃、属性掩码和边丢弃）来生成视图，并使用图对比目标学习鲁棒的谣言表示。", "result": "在四个基准数据集上的广泛实验表明，RAGCL方法在谣言检测上优于现有最先进的方法。", "conclusion": "本文揭示了谣言传播树的广泛结构特性，并提出了一种通过原则性自适应增强的图对比学习方法，为谣言检测提供了有效解决方案，其提出的原则和增强技术也可能有益于其他涉及树结构图的应用。"}}
{"id": "2508.07342", "title": "PrLM: Learning Explicit Reasoning for Personalized RAG via Contrastive Reward Optimization", "authors": ["Kepu Zhang", "Teng Shi", "Weijie Yu", "Jun Xu"], "abstract": "Personalized retrieval-augmented generation (RAG) aims to produce user-tailored responses by incorporating retrieved user profiles alongside the input query. Existing methods primarily focus on improving retrieval and rely on large language models (LLMs) to implicitly integrate the retrieved context with the query. However, such models are often sensitive to retrieval quality and may generate responses that are misaligned with user preferences. To address this limitation, we propose PrLM, a reinforcement learning framework that trains LLMs to explicitly reason over retrieved user profiles. Guided by a contrastively trained personalization reward model, PrLM effectively learns from user responses without requiring annotated reasoning paths. Experiments on three personalized text generation datasets show that PrLM outperforms existing methods and remains robust across varying numbers of retrieved profiles and different retrievers.", "subjects": "Information Retrieval (cs.IR); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.07342.pdf", "abstract_url": "https://arxiv.org/abs/2508.07342", "categories": ["Information Retrieval (cs.IR)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了PrLM，一个通过对比奖励优化学习显式推理的个性化RAG框架，旨在通过强化学习训练大型语言模型（LLMs）显式地推理检索到的用户资料，以生成更符合用户偏好的响应。", "motivation": "现有的个性化检索增强生成（RAG）方法主要关注于改进检索过程，并依赖大型语言模型（LLMs）隐式地将检索到的上下文与查询结合，这些模型对检索质量敏感，可能生成与用户偏好不一致的响应。", "method": "提出了PrLM，一个强化学习框架，通过对比训练的个人化奖励模型指导，训练LLMs显式地推理检索到的用户资料，无需标注推理路径。", "result": "在三个个性化文本生成数据集上的实验表明，PrLM优于现有方法，并且在检索到的资料数量和不同检索器下保持鲁棒性。", "conclusion": "PrLM通过显式推理和对比奖励优化，有效地学习用户响应，生成更符合用户偏好的个性化响应，提高了RAG的性能和鲁棒性。"}}
{"id": "2508.07021", "title": "DocRefine: An Intelligent Framework for Scientific Document Understanding and Content Optimization based on Multimodal Large Model Agents", "authors": ["Kun Qian", "Wenjie Li", "Tianyu Sun", "Wenhong Wang", "Wenhan Luo"], "abstract": "The exponential growth of scientific literature in PDF format necessitates advanced tools for efficient and accurate document understanding, summarization, and content optimization. Traditional methods fall short in handling complex layouts and multimodal content, while direct application of Large Language Models (LLMs) and Vision-Language Large Models (LVLMs) lacks precision and control for intricate editing tasks. This paper introduces DocRefine, an innovative framework designed for intelligent understanding, content refinement, and automated summarization of scientific PDF documents, driven by natural language instructions. DocRefine leverages the power of advanced LVLMs (e.g., GPT-4o) by orchestrating a sophisticated multi-agent system comprising six specialized and collaborative agents: Layout & Structure Analysis, Multimodal Content Understanding, Instruction Decomposition, Content Refinement, Summarization & Generation, and Fidelity & Consistency Verification. This closed-loop feedback architecture ensures high semantic accuracy and visual fidelity. Evaluated on the comprehensive DocEditBench dataset, DocRefine consistently outperforms state-of-the-art baselines across various tasks, achieving overall scores of 86.7% for Semantic Consistency Score (SCS), 93.9% for Layout Fidelity Index (LFI), and 85.0% for Instruction Adherence Rate (IAR). These results demonstrate DocRefine's superior capability in handling complex multimodal document editing, preserving semantic integrity, and maintaining visual consistency, marking a significant advancement in automated scientific document processing.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.07021.pdf", "abstract_url": "https://arxiv.org/abs/2508.07021", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "DocRefine是一个基于多模态大型模型代理的智能框架，旨在高效准确地理解、优化和总结科学PDF文档。通过六个专业协作代理的闭环反馈架构，DocRefine在语义一致性和视觉保真度方面表现出色。", "motivation": "科学文献的快速增长需要更先进的工具来处理复杂的布局和多模态内容，传统方法和直接应用大型语言模型在处理复杂编辑任务时缺乏精确性和控制。", "method": "DocRefine利用先进的多模态大型模型（如GPT-4o），通过六个专业协作代理的闭环反馈架构，实现文档的智能理解和内容优化。", "result": "在DocEditBench数据集上的评估显示，DocRefine在语义一致性得分（SCS）、布局保真度指数（LFI）和指令遵循率（IAR）上分别达到了86.7%、93.9%和85.0%，显著优于现有基线。", "conclusion": "DocRefine在自动化科学文档处理方面取得了显著进展，能够有效处理复杂的多模态文档编辑，保持语义完整性和视觉一致性。"}}
{"id": "2508.08053", "title": "AdaptFlow: Adaptive Workflow Optimization via Meta-Learning", "authors": ["Runchuan Zhu", "Bowen Jiang", "Lingrui Mei", "Fangkai Yang", "Lu Wang", "Haoxiang Gao", "Fengshuo Bai", "Pu Zhao", "Qingwei Lin", "Saravan Rajmohan", "Dongmei Zhang"], "abstract": "Recent advances in large language models (LLMs) have sparked growing interest in agentic workflows, which are structured sequences of LLM invocations intended to solve complex tasks. However, existing approaches often rely on static templates or manually designed workflows, which limit adaptability to diverse tasks and hinder scalability. We propose AdaptFlow, a natural language-based meta-learning framework inspired by model-agnostic meta-learning (MAML). AdaptFlow learns a generalizable workflow initialization that enables rapid subtask-level adaptation. It employs a bi-level optimization scheme: the inner loop refines the workflow for a specific subtask using LLM-generated feedback, while the outer loop updates the shared initialization to perform well across tasks. This setup allows AdaptFlow to generalize effectively to unseen tasks by adapting the initialized workflow through language-guided modifications. Evaluated across question answering, code generation, and mathematical reasoning benchmarks, AdaptFlow consistently outperforms both manually crafted and automatically searched baselines, achieving state-of-the-art results with strong generalization across tasks and models. The source code and data are available at", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.08053.pdf", "abstract_url": "https://arxiv.org/abs/2508.08053", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "AdaptFlow是一种基于自然语言的元学习框架，旨在通过元学习优化工作流，提高对多样化任务的适应性和可扩展性。", "motivation": "解决现有方法依赖静态模板或手动设计工作流，限制了对多样化任务的适应性和可扩展性的问题。", "method": "采用受模型无关元学习（MAML）启发的双层优化方案：内循环使用LLM生成的反馈为特定子任务细化工作流，外循环更新共享初始化以跨任务表现良好。", "result": "在问答、代码生成和数学推理基准测试中，AdaptFlow consistently outperforms both manually crafted and automatically searched baselines, achieving state-of-the-art results with strong generalization across tasks and models。", "conclusion": "AdaptFlow通过语言引导的修改，有效地将初始化的工作流适应于未见任务，展示了强大的跨任务和模型泛化能力。"}}
{"id": "2508.08115", "title": "TeamMedAgents: Enhancing Medical Decision-Making of LLMs Through Structured Teamwork", "authors": ["Pranav Pushkar Mishra", "Mohammad Arvan", "Mohan Zalake"], "abstract": "We present TeamMedAgents, a novel multi-agent approach that systematically integrates evidence-based teamwork components from human-human collaboration into medical decision-making with large language models (LLMs). Our approach validates an organizational psychology teamwork model from human collaboration to computational multi-agent medical systems by operationalizing six core teamwork components derived from Salas et al.'s \"Big Five\" model: team leadership, mutual performance monitoring, team orientation, shared mental models, closed-loop communication, and mutual trust. We implement and evaluate these components as modular, configurable mechanisms within an adaptive collaboration architecture while assessing the effect of the number of agents involved based on the task's requirements and domain. Systematic evaluation of computational implementations of teamwork behaviors across eight medical benchmarks (MedQA, MedMCQA, MMLU-Pro Medical, PubMedQA, DDXPlus, MedBullets, Path-VQA, and PMC-VQA) demonstrates consistent improvements across 7 out of 8 evaluated datasets. Controlled ablation studies conducted on 50 questions per configuration across 3 independent runs provide mechanistic insights into individual component contributions, revealing optimal teamwork configurations that vary by reasoning task complexity and domain-specific requirements. Our ablation analyses reveal dataset-specific optimal teamwork configurations, indicating that different medical reasoning modalities benefit from distinct collaborative patterns. TeamMedAgents represents an advancement in collaborative AI by providing a systematic translation of established teamwork theories from human collaboration into agentic collaboration, establishing a foundation for evidence-based multi-agent system design in critical decision-making domains.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "10 pages, 1 figure, 6 tables(2 in main, 4 in appendix)", "pdf_url": "https://arxiv.org/pdf/2508.08115.pdf", "abstract_url": "https://arxiv.org/abs/2508.08115", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "TeamMedAgents是一种新颖的多代理方法，通过将人类协作中的团队合作组件系统性地整合到大型语言模型（LLMs）的医疗决策中，提升了医疗决策的质量。该方法基于Salas等人的“五大”团队合作模型，实现了六项核心团队合作组件，并在八个医疗基准测试中展示了性能的持续提升。", "motivation": "解决大型语言模型在医疗决策中缺乏有效团队合作机制的问题，通过引入人类团队合作的理论和实践，提升AI在医疗领域的决策质量和可靠性。", "method": "采用多代理系统，实现并评估了六项核心团队合作组件（团队领导、相互绩效监控、团队导向、共享心智模型、闭环沟通和相互信任）作为模块化、可配置的机制，在不同的医疗推理任务和领域中进行了系统评估。", "result": "在八个医疗基准测试中，七个数据集上展示了性能的持续提升。通过控制消融研究，揭示了不同医疗推理模态受益于不同的团队合作配置。", "conclusion": "TeamMedAgents通过将人类团队合作理论系统性地转化为代理协作，为关键决策领域的多代理系统设计奠定了基础，代表了协作AI的进步。"}}
{"id": "2508.08127", "title": "BlindGuard: Safeguarding LLM-based Multi-Agent Systems under Unknown Attacks", "authors": ["Rui Miao", "Yixin Liu", "Yili Wang", "Xu Shen", "Yue Tan", "Yiwei Dai", "Shirui Pan", "Xin Wang"], "abstract": "The security of LLM-based multi-agent systems (MAS) is critically threatened by propagation vulnerability, where malicious agents can distort collective decision-making through inter-agent message interactions. While existing supervised defense methods demonstrate promising performance, they may be impractical in real-world scenarios due to their heavy reliance on labeled malicious agents to train a supervised malicious detection model. To enable practical and generalizable MAS defenses, in this paper, we propose BlindGuard, an unsupervised defense method that learns without requiring any attack-specific labels or prior knowledge of malicious behaviors. To this end, we establish a hierarchical agent encoder to capture individual, neighborhood, and global interaction patterns of each agent, providing a comprehensive understanding for malicious agent detection. Meanwhile, we design a corruption-guided detector that consists of directional noise injection and contrastive learning, allowing effective detection model training solely on normal agent behaviors. Extensive experiments show that BlindGuard effectively detects diverse attack types (i.e., prompt injection, memory poisoning, and tool attack) across MAS with various communication patterns while maintaining superior generalizability compared to supervised baselines. The code is available at:", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.08127.pdf", "abstract_url": "https://arxiv.org/abs/2508.08127", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了BlindGuard，一种无监督防御方法，用于保护基于LLM的多代理系统（MAS）免受未知攻击的威胁，无需依赖标记的恶意代理或恶意行为的先验知识。", "motivation": "现有的监督防御方法在实际应用中可能不切实际，因为它们严重依赖标记的恶意代理来训练监督恶意检测模型。为了解决这一问题，本文旨在开发一种无需攻击特定标签或恶意行为先验知识的实用且可推广的MAS防御方法。", "method": "BlindGuard通过建立一个分层的代理编码器来捕捉每个代理的个体、邻居和全局交互模式，为恶意代理检测提供全面的理解。同时，设计了一个基于腐败的检测器，包括定向噪声注入和对比学习，仅需正常代理行为即可有效训练检测模型。", "result": "大量实验表明，BlindGuard能够有效检测MAS中的多种攻击类型（如提示注入、内存污染和工具攻击），并在各种通信模式中保持优于监督基线的泛化能力。", "conclusion": "BlindGuard作为一种无监督防御方法，不仅能够有效保护MAS免受未知攻击的威胁，而且在泛化能力上优于现有的监督方法，为MAS的安全提供了实用的解决方案。"}}
{"id": "2508.08147", "title": "From Natural Language to Solver-Ready Power System Optimization: An LLM-Assisted, Validation-in-the-Loop Framework", "authors": ["Yunkai Hu", "Tianqiao Zhao", "Meng Yue"], "abstract": "This paper introduces a novel Large Language Models (LLMs)-assisted agent that automatically converts natural-language descriptions of power system optimization scenarios into compact, solver-ready formulations and generates corresponding solutions. In contrast to approaches that rely solely on LLM to produce solutions directly, the proposed method focuses on discovering a mathematically compatible formulation that can be efficiently solved by off-the-shelf optimization solvers. Directly using LLMs to produce solutions often leads to infeasible or suboptimal results, as these models lack the numerical precision and constraint-handling capabilities of established optimization solvers. The pipeline integrates a domain-aware prompt and schema with an LLM, enforces feasibility through systematic validation and iterative repair, and returns both solver-ready models and user-facing results. Using the unit commitment problem as a representative case study, the agent produces optimal or near-optimal schedules along with the associated objective costs. Results demonstrate that coupling the solver with task-specific validation significantly enhances solution reliability. This work shows that combining AI with established optimization frameworks bridges high-level problem descriptions and executable mathematical models, enabling more efficient decision-making in energy systems", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.08147.pdf", "abstract_url": "https://arxiv.org/abs/2508.08147", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一种新型的大型语言模型（LLMs）辅助代理，能够自动将电力系统优化场景的自然语言描述转换为紧凑、可直接求解的数学公式，并生成相应的解决方案。与直接依赖LLM生成解决方案的方法不同，该方法专注于发现数学上兼容的公式，这些公式可以通过现成的优化求解器高效求解。通过将领域感知提示和模式与LLM集成，通过系统验证和迭代修复强制执行可行性，并返回可直接求解的模型和面向用户的结果。以机组组合问题为例，代理生成了最优或接近最优的调度方案及相关目标成本。结果表明，将求解器与任务特定验证相结合显著提高了解决方案的可靠性。这项工作表明，将AI与已建立的优化框架相结合，可以桥接高级问题描述和可执行的数学模型，从而在能源系统中实现更高效的决策。", "motivation": "直接使用LLMs生成解决方案往往会导致不可行或次优的结果，因为这些模型缺乏已建立优化求解器的数值精度和约束处理能力。", "method": "该方法通过集成领域感知提示和模式与LLM，通过系统验证和迭代修复强制执行可行性，并返回可直接求解的模型和面向用户的结果。", "result": "以机组组合问题为例，代理生成了最优或接近最优的调度方案及相关目标成本。结果表明，将求解器与任务特定验证相结合显著提高了解决方案的可靠性。", "conclusion": "将AI与已建立的优化框架相结合，可以桥接高级问题描述和可执行的数学模型，从而在能源系统中实现更高效的决策。"}}
{"id": "2508.06497", "title": "Forecasting Commodity Price Shocks Using Temporal and Semantic Fusion of Prices Signals and Agentic Generative AI Extracted Economic News", "authors": ["Mohammed-Khalil Ghali", "Cecil Pang", "Oscar Molina", "Carlos Gershenson-Garcia", "Daehan Won"], "abstract": "Accurate forecasting of commodity price spikes is vital for countries with limited economic buffers, where sudden increases can strain national budgets, disrupt import-reliant sectors, and undermine food and energy security. This paper introduces a hybrid forecasting framework that combines historical commodity price data with semantic signals derived from global economic news, using an agentic generative AI pipeline. The architecture integrates dual-stream Long Short-Term Memory (LSTM) networks with attention mechanisms to fuse structured time-series inputs with semantically embedded, fact-checked news summaries collected from 1960 to 2023. The model is evaluated on a 64-year dataset comprising normalized commodity price series and temporally aligned news embeddings. Results show that the proposed approach achieves a mean AUC of 0.94 and an overall accuracy of 0.91 substantially outperforming traditional baselines such as logistic regression (AUC = 0.34), random forest (AUC = 0.57), and support vector machines (AUC = 0.47). Additional ablation studies reveal that the removal of attention or dimensionality reduction leads to moderate declines in performance, while eliminating the news component causes a steep drop in AUC to 0.46, underscoring the critical value of incorporating real-world context through unstructured text. These findings demonstrate that integrating agentic generative AI with deep learning can meaningfully improve early detection of commodity price shocks, offering a practical tool for economic planning and risk mitigation in volatile market environments while saving the very high costs of operating a full generative AI agents pipeline.", "subjects": "Computational Finance (q-fin.CP); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.06497.pdf", "abstract_url": "https://arxiv.org/abs/2508.06497", "categories": ["Computational Finance (q-fin.CP)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了一种混合预测框架，结合历史商品价格数据和全球经济新闻的语义信号，使用代理生成AI管道，通过双流LSTM网络与注意力机制融合结构化和非结构化数据，显著提高了商品价格冲击的早期检测准确性。", "motivation": "准确预测商品价格波动对于经济缓冲有限的国家至关重要，因为突然的价格上涨可能会对国家预算、依赖进口的行业以及食品和能源安全造成压力。", "method": "采用双流长短期记忆（LSTM）网络与注意力机制相结合的架构，融合结构化时间序列输入和语义嵌入的、经过事实核查的新闻摘要。", "result": "所提出的方法在64年的数据集上实现了0.94的平均AUC和0.91的总体准确率，显著优于逻辑回归（AUC = 0.34）、随机森林（AUC = 0.57）和支持向量机（AUC = 0.47）等传统基线。", "conclusion": "研究表明，将代理生成AI与深度学习相结合，可以显著提高商品价格冲击的早期检测能力，为经济规划和风险缓解提供了实用工具，同时节省了运行完整生成AI代理管道的高成本。"}}
{"id": "2508.06503", "title": "Understanding Human Limits in Pattern Recognition: A Computational Model of Sequential Reasoning in Rock, Paper, Scissors", "authors": ["Logan Cross", "Erik Brockbank", "Tobias Gerstenberg", "Judith E. Fan", "Daniel L. K. Yamins", "Nick Haber"], "abstract": "How do we predict others from patterns in their behavior and what are the computational constraints that limit this ability? We investigate these questions by modeling human behavior over repeated games of rock, paper, scissors from Brockbank & Vul (2024). Against algorithmic opponents that varied in strategic sophistication, people readily exploit simple transition patterns (e.g., consistently playing rock after paper) but struggle to detect more complex sequential dependencies. To understand the cognitive mechanisms underlying these abilities and their limitations, we deploy Hypothetical Minds (HM), a large language model-based agent that generates and tests hypotheses about opponent strategies, as a cognitive model of this behavior (Cross et al., 2024). We show that when applied to the same experimental conditions, HM closely mirrors human performance patterns, succeeding and failing in similar ways. To better understand the source of HM's failures and whether people might face similar cognitive bottlenecks in this context, we performed a series of ablations and augmentations targeting different components of the system. When provided with natural language descriptions of the opponents' strategies, HM successfully exploited 6/7 bot opponents with win rates >80% suggesting that accurate hypothesis generation is the primary cognitive bottleneck in this task. Further, by systematically manipulating the model's hypotheses through pedagogically-inspired interventions, we find that the model substantially updates its causal understanding of opponent behavior, revealing how model-based analyses can produce testable hypotheses about human cognition.", "subjects": "Neurons and Cognition (q-bio.NC); Artificial Intelligence (cs.AI)", "comments": "To be published in Proceedings of the 8th Annual Conference on Cognitive Computational Neuroscience (2025)", "pdf_url": "https://arxiv.org/pdf/2508.06503.pdf", "abstract_url": "https://arxiv.org/abs/2508.06503", "categories": ["Neurons and Cognition (q-bio.NC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "该研究通过建模人类在重复的石头、剪刀、布游戏中的行为，探讨了人类如何从行为模式中预测他人以及限制这种能力的计算约束。研究使用基于大型语言模型的假设思维（HM）作为认知模型，发现HM在相同实验条件下能紧密镜像人类的表现模式。通过一系列消融和增强实验，研究发现准确的假设生成是此任务中的主要认知瓶颈，并通过教学干预显著更新了模型对对手行为的因果理解。", "motivation": "探讨人类如何从行为模式中预测他人以及限制这种能力的计算约束。", "method": "使用基于大型语言模型的假设思维（HM）作为认知模型，模拟人类在重复的石头、剪刀、布游戏中的行为，并进行一系列消融和增强实验。", "result": "HM在相同实验条件下能紧密镜像人类的表现模式；准确的假设生成是此任务中的主要认知瓶颈；通过教学干预可以显著更新模型对对手行为的因果理解。", "conclusion": "模型基于分析可以产生关于人类认知的可测试假设，揭示了人类在模式识别中的认知瓶颈及其可能的克服方法。"}}
{"id": "2508.07662", "title": "GLiClass: Generalist Lightweight Model for Sequence Classification Tasks", "authors": ["Ihor Stepanov", "Mykhailo Shtopko", "Dmytro Vodianytskyi", "Oleksandr Lukashov", "Alexander Yavorskyi", "Mykyta Yaroshenko"], "abstract": "Classification is one of the most widespread tasks in AI applications, serving often as the first step in filtering, sorting, and categorizing data. Since modern AI systems must handle large volumes of input data and early pipeline stages can propagate errors downstream, achieving high efficiency and accuracy is critical. Moreover, classification requirements can change dynamically based on user needs, necessitating models with strong zero-shot capabilities. While generative LLMs have become mainstream for zero-shot classification due to their versatility, they suffer from inconsistent instruction following and computational inefficiency. Cross-encoders, commonly used as rerankers in RAG pipelines, face a different bottleneck: they must process text-label pairs sequentially, significantly reducing efficiency with large label sets. Embedding-based approaches offer good efficiency but struggle with complex scenarios involving logical and semantic constraints. We propose GLiClass, a novel method that adapts the GLiNER architecture for sequence classification tasks. Our approach achieves strong accuracy and efficiency comparable to embedding-based methods, while maintaining the flexibility needed for zero-shot and few-shot learning scenarios. Additionally, we adapted proximal policy optimization (PPO) for multi-label text classification, enabling training classifiers in data-sparse conditions or from human feedback.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "14 pages, 7 tables, 2 figures", "pdf_url": "https://arxiv.org/pdf/2508.07662.pdf", "abstract_url": "https://arxiv.org/abs/2508.07662", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "GLiClass是一种新型的序列分类任务通用轻量级模型，旨在解决现有方法在效率、准确性和零样本学习能力方面的不足。", "motivation": "现代AI系统需要处理大量输入数据，且早期阶段的错误可能影响下游任务，因此实现高效率和高准确性的分类至关重要。此外，分类需求可能根据用户需求动态变化，需要模型具备强大的零样本能力。", "method": "GLiClass通过调整GLiNER架构以适应序列分类任务，并结合了近端策略优化（PPO）进行多标签文本分类，以在数据稀疏或从人类反馈中训练分类器。", "result": "GLiClass在保持与基于嵌入的方法相当的效率和准确性的同时，提供了零样本和小样本学习所需的灵活性。", "conclusion": "GLiClass为序列分类任务提供了一种高效、准确且灵活的新方法，特别适用于需要动态适应和零样本学习的场景。"}}
{"id": "2508.07092", "title": "Communication-Efficient Multi-Agent 3D Detection via Hybrid Collaboration", "authors": ["Yue Hu", "Juntong Peng", "Yunqiao Yang", "Siheng Chen"], "abstract": "Collaborative 3D detection can substantially boost detection performance by allowing agents to exchange complementary information. It inherently results in a fundamental trade-off between detection performance and communication bandwidth. To tackle this bottleneck issue, we propose a novel hybrid collaboration that adaptively integrates two types of communication messages: perceptual outputs, which are compact, and raw observations, which offer richer information. This approach focuses on two key aspects: i) integrating complementary information from two message types and ii) prioritizing the most critical data within each type. By adaptively selecting the most critical set of messages, it ensures optimal perceptual information and adaptability, effectively meeting the demands of diverse communication", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.07092.pdf", "abstract_url": "https://arxiv.org/abs/2508.07092", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "提出了一种新颖的混合协作方法，通过自适应整合两种通信消息（感知输出和原始观察）来提高3D检测性能，同时优化通信带宽使用。", "motivation": "解决协作3D检测中检测性能与通信带宽之间的基本权衡问题。", "method": "采用混合协作方法，自适应整合感知输出和原始观察两种通信消息，并优先考虑每种类型中最关键的数据。", "result": "通过自适应选择最关键的消息集，确保了最佳的感知信息和适应性，有效满足了多样化通信的需求。", "conclusion": "该方法在提高3D检测性能的同时，优化了通信带宽的使用，为协作3D检测提供了一种有效的解决方案。"}}
{"id": "2508.08088", "title": "HierSearch: A Hierarchical Enterprise Deep Search Framework Integrating Local and Web Searches", "authors": ["Jiejun Tan", "Zhicheng Dou", "Yan Yu", "Jiehan Cheng", "Qiang Ju", "Jian Xie", "Ji-Rong Wen"], "abstract": "Recently, large reasoning models have demonstrated strong mathematical and coding abilities, and deep search leverages their reasoning capabilities in challenging information retrieval tasks. Existing deep search works are generally limited to a single knowledge source, either local or the Web. However, enterprises often require private deep search systems that can leverage search tools over both local and the Web corpus. Simply training an agent equipped with multiple search tools using flat reinforcement learning (RL) is a straightforward idea, but it has problems such as low training data efficiency and poor mastery of complex tools. To address the above issue, we propose a hierarchical agentic deep search framework, HierSearch, trained with hierarchical RL. At the low level, a local deep search agent and a Web deep search agent are trained to retrieve evidence from their corresponding domains. At the high level, a planner agent coordinates low-level agents and provides the final answer. Moreover, to prevent direct answer copying and error propagation, we design a knowledge refiner that filters out hallucinations and irrelevant evidence returned by low-level agents. Experiments show that HierSearch achieves better performance compared to flat RL, and outperforms various deep search and multi-source retrieval-augmented generation baselines in six benchmarks across general, finance, and medical domains.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2508.08088.pdf", "abstract_url": "https://arxiv.org/abs/2508.08088", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种名为HierSearch的分层企业深度搜索框架，该框架整合了本地和网络搜索，通过分层强化学习训练，以提高搜索效率和质量。", "motivation": "企业需要能够同时利用本地和网络知识源的私有深度搜索系统，但现有的深度搜索工作通常仅限于单一知识源，且简单的扁平强化学习方法存在训练数据效率低和对复杂工具掌握差的问题。", "method": "提出了一种分层代理深度搜索框架HierSearch，采用分层强化学习训练。低层训练本地和网络深度搜索代理从各自领域检索证据，高层规划代理协调低层代理并提供最终答案。此外，设计了知识提炼器以过滤低层代理返回的幻觉和不相关证据。", "result": "实验表明，HierSearch在六个基准测试中（涵盖通用、金融和医疗领域）相比扁平强化学习和多种深度搜索及多源检索增强生成基线，表现更优。", "conclusion": "HierSearch框架通过分层强化学习和知识提炼，有效提高了企业深度搜索系统的性能和质量，适用于多种领域。"}}
{"id": "2508.07251", "title": "Understanding Dynamic Scenes in Ego Centric 4D Point Clouds", "authors": ["Junsheng Huang", "Shengyu Hao", "Bocheng Hu", "Gaoang Wang"], "abstract": "Understanding dynamic 4D scenes from an egocentric perspective-modeling changes in 3D spatial structure over time-is crucial for human-machine interaction, autonomous navigation, and embodied intelligence. While existing egocentric datasets contain dynamic scenes, they lack unified 4D annotations and task-driven evaluation protocols for fine-grained spatio-temporal reasoning, especially on motion of objects and human, together with their interactions. To address this gap, we introduce EgoDynamic4D, a novel QA benchmark on highly dynamic scenes, comprising RGB-D video, camera poses, globally unique instance masks, and 4D bounding boxes. We construct 927K QA pairs accompanied by explicit Chain-of-Thought (CoT), enabling verifiable, step-by-step spatio-temporal reasoning. We design 12 dynamic QA tasks covering agent motion, human-object interaction, trajectory prediction, relation understanding, and temporal-causal reasoning, with fine-grained, multidimensional metrics. To tackle these tasks, we propose an end-to-end spatio-temporal reasoning framework that unifies dynamic and static scene information, using instance-aware feature encoding, time and camera encoding, and spatially adaptive down-sampling to compress large 4D scenes into token sequences manageable by LLMs. Experiments on EgoDynamic4D show that our method consistently outperforms baselines, validating the effectiveness of multimodal temporal modeling for egocentric dynamic scene understanding.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.07251.pdf", "abstract_url": "https://arxiv.org/abs/2508.07251", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了EgoDynamic4D，一个用于高度动态场景的新型QA基准，包含RGB-D视频、相机姿态、全局唯一实例掩码和4D边界框，旨在通过12个动态QA任务促进细粒度的时空推理。", "motivation": "解决现有自我中心数据集在统一4D注释和任务驱动评估协议方面的不足，特别是在对象和人类运动及其交互的细粒度时空推理上。", "method": "提出一个端到端的时空推理框架，统一动态和静态场景信息，使用实例感知特征编码、时间和相机编码以及空间自适应下采样，将大型4D场景压缩为LLMs可管理的令牌序列。", "result": "在EgoDynamic4D上的实验表明，该方法在多种动态QA任务上 consistently outperforms baselines，验证了多模态时间建模在自我中心动态场景理解中的有效性。", "conclusion": "EgoDynamic4D基准和提出的方法为自我中心动态场景理解提供了新的工具和方向，特别是在促进细粒度时空推理方面。"}}
{"id": "2508.06659", "title": "In-Context Reinforcement Learning via Communicative World Models", "authors": ["Fernando Martinez-Lopez", "Tao Li", "Yingdong Lu", "Juntao Chen"], "abstract": "Reinforcement learning (RL) agents often struggle to generalize to new tasks and contexts without updating their parameters, mainly because their learned representations and policies are overfit to the specifics of their training environments. To boost agents' in-context RL (ICRL) ability, this work formulates ICRL as a two-agent emergent communication problem and introduces CORAL (Communicative Representation for Adaptive RL), a framework that learns a transferable communicative context by decoupling latent representation learning from control. In CORAL, an Information Agent (IA) is pre-trained as a world model on a diverse distribution of tasks. Its objective is not to maximize task reward, but to build a world model and distill its understanding into concise messages. The emergent communication protocol is shaped by a novel Causal Influence Loss, which measures the effect that the message has on the next action. During deployment, the previously trained IA serves as a fixed contextualizer for a new Control Agent (CA), which learns to solve tasks by interpreting the provided communicative context. Our experiments demonstrate that this approach enables the CA to achieve significant gains in sample efficiency and successfully perform zero-shot adaptation with the help of pre-trained IA in entirely unseen sparse-reward environments, validating the efficacy of learning a transferable communicative representation.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.06659.pdf", "abstract_url": "https://arxiv.org/abs/2508.06659", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种通过通信世界模型进行上下文强化学习（ICRL）的方法，名为CORAL框架，旨在通过解耦潜在表示学习和控制来提升代理的ICRL能力。", "motivation": "强化学习（RL）代理在新任务和上下文中的泛化能力不足，主要因为其学习的表示和策略过度拟合于训练环境的具体细节。", "method": "CORAL框架将ICRL制定为一个双代理的紧急通信问题，通过预训练信息代理（IA）作为世界模型，并使用新颖的因果影响损失来塑造紧急通信协议，然后在部署时固定IA作为新控制代理（CA）的上下文提供者。", "result": "实验表明，这种方法使CA在样本效率上取得了显著提升，并在完全未见过的稀疏奖励环境中成功实现了零射击适应。", "conclusion": "学习可转移的通信表示对于提升代理的ICRL能力是有效的，CORAL框架为此提供了一种可行的解决方案。"}}
{"id": "2508.06767", "title": "PANAMA: A Network-Aware MARL Framework for Multi-Agent Path Finding in Digital Twin Ecosystems", "authors": ["Arman Dogru", "R. Irem Bor-Yaliniz", "Nimal Gamini Senarath"], "abstract": "Digital Twins (DTs) are transforming industries through advanced data processing and analysis, positioning the world of DTs, Digital World, as a cornerstone of nextgeneration technologies including embodied AI. As robotics and automated systems scale, efficient data-sharing frameworks and robust algorithms become critical. We explore the pivotal role of data handling in next-gen networks, focusing on dynamics between application and network providers (AP/NP) in DT ecosystems. We introduce PANAMA, a novel algorithm with Priority Asymmetry for Network Aware Multi-agent Reinforcement Learning (MARL) based multi-agent path finding (MAPF). By adopting a Centralized Training with Decentralized Execution (CTDE) framework and asynchronous actor-learner architectures, PANAMA accelerates training while enabling autonomous task execution by embodied AI. Our approach demonstrates superior pathfinding performance in accuracy, speed, and scalability compared to existing benchmarks. Through simulations, we highlight optimized data-sharing strategies for scalable, automated systems, ensuring resilience in complex, real-world environments. PANAMA bridges the gap between network-aware decision-making and robust multi-agent coordination, advancing the synergy between DTs, wireless networks, and AI-driven automation.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Multiagent Systems (cs.MA); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.06767.pdf", "abstract_url": "https://arxiv.org/abs/2508.06767", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Distributed, Parallel, and Cluster Computing (cs.DC)", "Multiagent Systems (cs.MA)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "PANAMA是一种网络感知的多智能体强化学习框架，用于数字孪生生态系统中的多智能体路径规划，通过集中训练与分散执行的架构，提高了路径规划的准确性、速度和可扩展性。", "motivation": "随着机器人和自动化系统的规模扩大，高效的数据共享框架和强大的算法变得至关重要。本文探讨了数据处理在下一代网络中的关键作用，特别是在数字孪生生态系统中应用和网络提供商之间的动态关系。", "method": "PANAMA采用了一种具有优先级不对称性的网络感知多智能体强化学习算法，结合了集中训练与分散执行（CTDE）框架和异步的演员-学习者架构，以加速训练并实现自主任务执行。", "result": "通过模拟，PANAMA在准确性、速度和可扩展性方面表现出优于现有基准的路径规划性能，并展示了针对可扩展自动化系统的优化数据共享策略。", "conclusion": "PANAMA在网络感知决策和强大的多智能体协调之间架起了桥梁，推动了数字孪生、无线网络和AI驱动自动化之间的协同发展。"}}
{"id": "2508.06806", "title": "Offline-to-Online Reinforcement Learning with Classifier-Free Diffusion Generation", "authors": ["Xiao Huang", "Xu Liu", "Enze Zhang", "Tong Yu", "Shuai Li"], "abstract": "Offline-to-online Reinforcement Learning (O2O RL) aims to perform online fine-tuning on an offline pre-trained policy to minimize costly online interactions. Existing work used offline datasets to generate data that conform to the online data distribution for data augmentation. However, generated data still exhibits a gap with the online data, limiting overall performance. To address this, we propose a new data augmentation approach, Classifier-Free Diffusion Generation (CFDG). Without introducing additional classifier training overhead, CFDG leverages classifier-free guidance diffusion to significantly enhance the generation quality of offline and online data with different distributions. Additionally, it employs a reweighting method to enable more generated data to align with the online data, enhancing performance while maintaining the agent's stability. Experimental results show that CFDG outperforms replaying the two data types or using a standard diffusion model to generate new data. Our method is versatile and can be integrated with existing offline-to-online RL algorithms. By implementing CFDG to popular methods IQL, PEX and APL, we achieve a notable 15% average improvement in empirical performance on the D4RL benchmark such as MuJoCo and AntMaze.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "ICML2025", "pdf_url": "https://arxiv.org/pdf/2508.06806.pdf", "abstract_url": "https://arxiv.org/abs/2508.06806", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为无分类器扩散生成（CFDG）的新数据增强方法，用于离线到在线强化学习（O2O RL），旨在通过高质量的数据生成和重新加权方法，缩小离线与在线数据之间的分布差距，从而提升整体性能。", "motivation": "解决离线预训练策略在线微调时，生成数据与在线数据分布存在差距，限制性能提升的问题。", "method": "采用无分类器引导扩散生成技术（CFDG），无需额外分类器训练开销，显著提升不同分布数据的生成质量，并结合重新加权方法使生成数据更符合在线数据分布。", "result": "实验结果表明，CFDG在D4RL基准测试（如MuJoCo和AntMaze）上，比现有方法平均提高了15%的性能。", "conclusion": "CFDG方法不仅提升了离线到在线强化学习的性能，而且具有通用性，可与现有O2O RL算法集成，为强化学习领域提供了新的数据增强解决方案。"}}
{"id": "2508.06871", "title": "Sparsity-Driven Plasticity in Multi-Task Reinforcement Learning", "authors": ["Aleksandar Todorov", "Juan Cardenas-Cartagena", "Rafael F. Cunha", "Marco Zullich", "Matthia Sabatelli"], "abstract": "Plasticity loss, a diminishing capacity to adapt as training progresses, is a critical challenge in deep reinforcement learning. We examine this issue in multi-task reinforcement learning (MTRL), where higher representational flexibility is crucial for managing diverse and potentially conflicting task demands. We systematically explore how sparsification methods, particularly Gradual Magnitude Pruning (GMP) and Sparse Evolutionary Training (SET), enhance plasticity and consequently improve performance in MTRL agents. We evaluate these approaches across distinct MTRL architectures (shared backbone, Mixture of Experts, Mixture of Orthogonal Experts) on standardized MTRL benchmarks, comparing against dense baselines, and a comprehensive range of alternative plasticity-inducing or regularization methods. Our results demonstrate that both GMP and SET effectively mitigate key indicators of plasticity degradation, such as neuron dormancy and representational collapse. These plasticity improvements often correlate with enhanced multi-task performance, with sparse agents frequently outperforming dense counterparts and achieving competitive results against explicit plasticity interventions. Our findings offer insights into the interplay between plasticity, network sparsity, and MTRL designs, highlighting dynamic sparsification as a robust but context-sensitive tool for developing more adaptable MTRL systems.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.06871.pdf", "abstract_url": "https://arxiv.org/abs/2508.06871", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文探讨了在深度强化学习中，特别是在多任务强化学习（MTRL）中，如何通过稀疏化方法（如渐进幅度剪枝和稀疏进化训练）来增强可塑性，从而改善MTRL代理的性能。", "motivation": "解决深度强化学习中的可塑性丧失问题，特别是在多任务强化学习中，如何通过稀疏化方法来增强网络的可塑性，以应对多样化和潜在冲突的任务需求。", "method": "系统地探索了渐进幅度剪枝（GMP）和稀疏进化训练（SET）等稀疏化方法，并在不同的MTRL架构上进行了评估，与密集基线和其他可塑性诱导或正则化方法进行了比较。", "result": "结果表明，GMP和SET都能有效缓解可塑性退化的关键指标，如神经元休眠和表征崩溃。这些可塑性的改善往往与多任务性能的提升相关，稀疏代理经常优于密集代理，并在与显式可塑性干预的比较中取得了竞争性结果。", "conclusion": "研究结果揭示了可塑性、网络稀疏性和MTRL设计之间的相互作用，强调了动态稀疏化作为开发更具适应性MTRL系统的强大但上下文敏感的工具。"}}
{"id": "2508.07001", "title": "Consensus-based Decentralized Multi-agent Reinforcement Learning for Random Access Network Optimization", "authors": ["Myeung Suk Oh", "Zhiyao Zhang", "FNU Hairi", "Alvaro Velasquez", "Jia Liu"], "abstract": "With wireless devices increasingly forming a unified smart network for seamless, user-friendly operations, random access (RA) medium access control (MAC) design is considered a key solution for handling unpredictable data traffic from multiple terminals. However, it remains challenging to design an effective RA-based MAC protocol to minimize collisions and ensure transmission fairness across the devices. While existing multi-agent reinforcement learning (MARL) approaches with centralized training and decentralized execution (CTDE) have been proposed to optimize RA performance, their reliance on centralized training and the significant overhead required for information collection can make real-world applications unrealistic. In this work, we adopt a fully decentralized MARL architecture, where policy learning does not rely on centralized tasks but leverages consensus-based information exchanges across devices. We design our MARL algorithm over an actor-critic (AC) network and propose exchanging only local rewards to minimize communication overhead. Furthermore, we provide a theoretical proof of global convergence for our approach. Numerical experiments show that our proposed MARL algorithm can significantly improve RA network performance compared to other baselines.", "subjects": "Networking and Internet Architecture (cs.NI); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "This paper has been accepted in ACM International Symposium on Theory, Algorithmic Foundations, and Protocol Design for Mobile Networks and Mobile Computing (MobiHoc) 2025", "pdf_url": "https://arxiv.org/pdf/2508.07001.pdf", "abstract_url": "https://arxiv.org/abs/2508.07001", "categories": ["Networking and Internet Architecture (cs.NI)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于共识的分散式多智能体强化学习方法，用于优化随机接入网络性能，通过最小化通信开销和提高传输公平性，显著提升了网络性能。", "motivation": "随着无线设备越来越多地形成一个统一的智能网络，随机接入（RA）媒体访问控制（MAC）设计成为处理来自多个终端的不可预测数据流量的关键解决方案。然而，设计一个有效的基于RA的MAC协议以最小化冲突并确保设备间的传输公平性仍然具有挑战性。", "method": "采用完全分散的多智能体强化学习（MARL）架构，其中策略学习不依赖于集中式任务，而是利用跨设备的基于共识的信息交换。设计了一个基于演员-评论家（AC）网络的MARL算法，并提议仅交换局部奖励以最小化通信开销。", "result": "数值实验表明，与其他基线相比，我们提出的MARL算法可以显著提高RA网络性能。", "conclusion": "本文提出的方法不仅减少了集中式训练的需求和通信开销，还通过理论证明了全局收敛性，为随机接入网络的优化提供了有效的解决方案。"}}
{"id": "2508.07029", "title": "From Imitation to Optimization: A Comparative Study of Offline Learning for Autonomous Driving", "authors": ["Antonio Guillen-Perez"], "abstract": "Learning robust driving policies from large-scale, real-world datasets is a central challenge in autonomous driving, as online data collection is often unsafe and impractical. While Behavioral Cloning (BC) offers a straightforward approach to imitation learning, policies trained with BC are notoriously brittle and suffer from compounding errors in closed-loop execution. This work presents a comprehensive pipeline and a comparative study to address this limitation. We first develop a series of increasingly sophisticated BC baselines, culminating in a Transformer-based model that operates on a structured, entity-centric state representation. While this model achieves low imitation loss, we show that it still fails in long-horizon simulations. We then demonstrate that by applying a state-of-the-art Offline Reinforcement Learning algorithm, Conservative Q-Learning (CQL), to the same data and architecture, we can learn a significantly more robust policy. Using a carefully engineered reward function, the CQL agent learns a conservative value function that enables it to recover from minor errors and avoid out-of-distribution states. In a large-scale evaluation on 1,000 unseen scenarios from the Waymo Open Motion Dataset, our final CQL agent achieves a 3.2x higher success rate and a 7.4x lower collision rate than the strongest BC baseline, proving that an offline RL approach is critical for learning robust, long-horizon driving policies from static expert data.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Robotics (cs.RO); Systems and Control (eess.SY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.07029.pdf", "abstract_url": "https://arxiv.org/abs/2508.07029", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Robotics (cs.RO)", "Systems and Control (eess.SY)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过比较研究，探讨了自动驾驶中从模仿学习到离线强化学习的转变，展示了离线强化学习在提高驾驶策略稳健性方面的优势。", "motivation": "解决自动驾驶中从大规模真实世界数据集学习稳健驾驶策略的挑战，因为在线数据收集通常不安全且不切实际。", "method": "开发了一系列逐步复杂的模仿学习基线模型，最终采用基于Transformer的模型，并应用了最先进的离线强化学习算法Conservative Q-Learning (CQL)。", "result": "在Waymo Open Motion Dataset的1,000个未见过的场景中，CQL代理的成功率比最强的模仿学习基线高3.2倍，碰撞率低7.4倍。", "conclusion": "离线强化学习方法对于从静态专家数据学习稳健、长期视野的驾驶策略至关重要。"}}
{"id": "2508.07126", "title": "Pref-GUIDE: Continual Policy Learning from Real-Time Human Feedback via Preference-Based Learning", "authors": ["Zhengran Ji", "Boyuan Chen"], "abstract": "Training reinforcement learning agents with human feedback is crucial when task objectives are difficult to specify through dense reward functions. While prior methods rely on offline trajectory comparisons to elicit human preferences, such data is unavailable in online learning scenarios where agents must adapt on the fly. Recent approaches address this by collecting real-time scalar feedback to guide agent behavior and train reward models for continued learning after human feedback becomes unavailable. However, scalar feedback is often noisy and inconsistent, limiting the accuracy and generalization of learned rewards. We propose Pref-GUIDE, a framework that transforms real-time scalar feedback into preference-based data to improve reward model learning for continual policy training. Pref-GUIDE Individual mitigates temporal inconsistency by comparing agent behaviors within short windows and filtering ambiguous feedback. Pref-GUIDE Voting further enhances robustness by aggregating reward models across a population of users to form consensus preferences. Across three challenging environments, Pref-GUIDE significantly outperforms scalar-feedback baselines, with the voting variant exceeding even expert-designed dense rewards. By reframing scalar feedback as structured preferences with population feedback, Pref-GUIDE offers a scalable and principled approach for harnessing human input in online reinforcement learning.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.07126.pdf", "abstract_url": "https://arxiv.org/abs/2508.07126", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "Pref-GUIDE是一个通过基于偏好的学习从实时人类反馈中持续学习策略的框架，旨在解决在线学习场景中难以通过密集奖励函数指定任务目标的问题。", "motivation": "解决在线强化学习场景中，由于缺乏离线轨迹比较数据，以及实时标量反馈的噪声和不一致性，导致学习奖励模型的准确性和泛化能力受限的问题。", "method": "Pref-GUIDE将实时标量反馈转化为基于偏好的数据，通过比较短时间窗口内的代理行为并过滤模糊反馈（Pref-GUIDE Individual），以及通过聚合用户群体的奖励模型形成共识偏好（Pref-GUIDE Voting），来改进奖励模型的学习。", "result": "在三个具有挑战性的环境中，Pref-GUIDE显著优于基于标量反馈的基线方法，其投票变体甚至超过了专家设计的密集奖励。", "conclusion": "通过将标量反馈重新构建为具有群体反馈的结构化偏好，Pref-GUIDE为在线强化学习中利用人类输入提供了一种可扩展和原则性的方法。"}}
{"id": "2508.07221", "title": "LLM-based Agents for Automated Confounder Discovery and Subgroup Analysis in Causal Inference", "authors": ["Po-Han Lee", "Yu-Cheng Lin", "Chan-Tung Ku", "Chan Hsu", "Pei-Cing Huang", "Ping-Hsun Wu", "Yihuang Kang"], "abstract": "Estimating individualized treatment effects from observational data presents a persistent challenge due to unmeasured confounding and structural bias. Causal Machine Learning (causal ML) methods, such as causal trees and doubly robust estimators, provide tools for estimating conditional average treatment effects. These methods have limited effectiveness in complex real-world environments due to the presence of latent confounders or those described in unstructured formats. Moreover, reliance on domain experts for confounder identification and rule interpretation introduces high annotation cost and scalability concerns. In this work, we proposed Large Language Model-based agents for automated confounder discovery and subgroup analysis that integrate agents into the causal ML pipeline to simulate domain expertise. Our framework systematically performs subgroup identification and confounding structure discovery by leveraging the reasoning capabilities of LLM-based agents, which reduces human dependency while preserving interpretability. Experiments on real-world medical datasets show that our proposed approach enhances treatment effect estimation robustness by narrowing confidence intervals and uncovering unrecognized confounding biases. Our findings suggest that LLM-based agents offer a promising path toward scalable, trustworthy, and semantically aware causal inference.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA); Applications (stat.AP); Methodology (stat.ME)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.07221.pdf", "abstract_url": "https://arxiv.org/abs/2508.07221", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)", "Applications (stat.AP)", "Methodology (stat.ME)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于大型语言模型（LLM）的代理，用于自动化混杂因素发现和因果推断中的亚组分析，以减少对领域专家的依赖并提高处理复杂现实世界环境的能力。", "motivation": "解决观察数据中由于未测量的混杂因素和结构偏差导致的个体化治疗效果估计难题，特别是在存在潜在混杂因素或非结构化描述的情况下，传统因果机器学习方法效果有限。", "method": "利用基于LLM的代理模拟领域专业知识，集成到因果机器学习流程中，系统执行亚组识别和混杂结构发现。", "result": "在真实世界医疗数据集上的实验表明，该方法通过缩小置信区间和揭示未识别的混杂偏差，增强了治疗效果估计的稳健性。", "conclusion": "基于LLM的代理为可扩展、可信赖且语义感知的因果推断提供了一条有前景的路径。"}}
{"id": "2508.07453", "title": "Noise-Aware Generative Microscopic Traffic Simulation", "authors": ["Vindula Jayawardana", "Catherine Tang", "Junyi Ji", "Jonah Philion", "Xue Bin Peng", "Cathy Wu"], "abstract": "Accurately modeling individual vehicle behavior in microscopic traffic simulation remains a key challenge in intelligent transportation systems, as it requires vehicles to realistically generate and respond to complex traffic phenomena such as phantom traffic jams. While traditional human driver simulation models offer computational tractability, they do so by abstracting away the very complexity that defines human driving. On the other hand, recent advances in infrastructure-mounted camera-based roadway sensing have enabled the extraction of vehicle trajectory data, presenting an opportunity to shift toward generative, agent-based models. Yet, a major bottleneck remains: most existing datasets are either overly sanitized or lack standardization, failing to reflect the noisy, imperfect nature of real-world sensing. Unlike data from vehicle-mounted sensors-which can mitigate sensing artifacts like occlusion through overlapping fields of view and sensor fusion-infrastructure-based sensors surface a messier, more practical view of challenges that traffic engineers encounter. To this end, we present the I-24 MOTION Scenario Dataset (I24-MSD)-a standardized, curated dataset designed to preserve a realistic level of sensor imperfection, embracing these errors as part of the learning problem rather than an obstacle to overcome purely from preprocessing. Drawing from noise-aware learning strategies in computer vision, we further adapt existing generative models in the autonomous driving community for I24-MSD with noise-aware loss functions. Our results show that such models not only outperform traditional baselines in realism but also benefit from explicitly engaging with, rather than suppressing, data imperfection. We view I24-MSD as a stepping stone toward a new generation of microscopic traffic simulation that embraces the real-world challenges and is better aligned with practical needs.", "subjects": "Systems and Control (eess.SY); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.07453.pdf", "abstract_url": "https://arxiv.org/abs/2508.07453", "categories": ["Systems and Control (eess.SY)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种噪声感知的生成性微观交通模拟方法，通过利用基础设施安装的摄像头提取的车辆轨迹数据，开发了I-24 MOTION Scenario Dataset (I24-MSD)，一个保留传感器不完美性的标准化数据集，并采用噪声感知损失函数改进生成模型，以提高模拟的真实性。", "motivation": "微观交通模拟中准确建模个体车辆行为是一个关键挑战，传统的人类驾驶员模拟模型虽然计算上可行，但忽略了人类驾驶的复杂性。同时，现有数据集往往过于净化或缺乏标准化，未能反映真实世界传感的噪声和不完美性。", "method": "利用基础设施安装的摄像头提取的车辆轨迹数据，开发了I24-MSD数据集，并采用噪声感知损失函数改进生成模型，以更好地处理数据中的噪声和不完美性。", "result": "结果显示，这种噪声感知生成模型不仅在真实性上优于传统基线，而且通过明确处理而非抑制数据不完美性，获得了更好的性能。", "conclusion": "I24-MSD被视为迈向新一代微观交通模拟的垫脚石，这种模拟更贴近实际挑战和需求，通过拥抱而非回避现实世界的不完美性，为智能交通系统提供了更实用的解决方案。"}}
{"id": "2508.08170", "title": "ReconDreamer-RL: Enhancing Reinforcement Learning via Diffusion-based Scene Reconstruction", "authors": ["Chaojun Ni", "Guosheng Zhao", "Xiaofeng Wang", "Zheng Zhu", "Wenkang Qin", "Xinze Chen", "Guanghong Jia", "Guan Huang", "Wenjun Mei"], "abstract": "Reinforcement learning for training end-to-end autonomous driving models in closed-loop simulations is gaining growing attention. However, most simulation environments differ significantly from real-world conditions, creating a substantial simulation-to-reality (sim2real) gap. To bridge this gap, some approaches utilize scene reconstruction techniques to create photorealistic environments as a simulator. While this improves realistic sensor simulation, these methods are inherently constrained by the distribution of the training data, making it difficult to render high-quality sensor data for novel trajectories or corner case scenarios. Therefore, we propose ReconDreamer-RL, a framework designed to integrate video diffusion priors into scene reconstruction to aid reinforcement learning, thereby enhancing end-to-end autonomous driving training. Specifically, in ReconDreamer-RL, we introduce ReconSimulator, which combines the video diffusion prior for appearance modeling and incorporates a kinematic model for physical modeling, thereby reconstructing driving scenarios from real-world data. This narrows the sim2real gap for closed-loop evaluation and reinforcement learning. To cover more corner-case scenarios, we introduce the Dynamic Adversary Agent (DAA), which adjusts the trajectories of surrounding vehicles relative to the ego vehicle, autonomously generating corner-case traffic scenarios (e.g., cut-in). Finally, the Cousin Trajectory Generator (CTG) is proposed to address the issue of training data distribution, which is often biased toward simple straight-line movements. Experiments show that ReconDreamer-RL improves end-to-end autonomous driving training, outperforming imitation learning methods with a 5x reduction in the Collision Ratio.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.08170.pdf", "abstract_url": "https://arxiv.org/abs/2508.08170", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "ReconDreamer-RL通过将视频扩散先验集成到场景重建中，以增强强化学习，特别是在端到端自动驾驶训练中。它引入了ReconSimulator结合视频扩散先验和运动学模型，以及动态对手代理（DAA）和表亲轨迹生成器（CTG）来覆盖更多角落案例和改善训练数据分布。实验显示，该方法在减少碰撞率方面优于模仿学习方法。", "motivation": "解决自动驾驶训练中模拟环境与现实世界条件之间的差距（sim2real gap），以及训练数据分布偏差和角落案例场景不足的问题。", "method": "提出ReconDreamer-RL框架，结合视频扩散先验和运动学模型进行场景重建，引入动态对手代理（DAA）生成角落案例交通场景，以及表亲轨迹生成器（CTG）改善训练数据分布。", "result": "实验结果表明，ReconDreamer-RL在端到端自动驾驶训练中优于模仿学习方法，碰撞率降低了5倍。", "conclusion": "ReconDreamer-RL通过创新的场景重建和训练数据增强方法，有效缩小了sim2real差距，提高了自动驾驶训练的效率和安全性。"}}
{"id": "2508.08189", "title": "Reinforcement Learning in Vision: A Survey", "authors": ["Weijia Wu", "Chen Gao", "Joya Chen", "Kevin Qinghong Lin", "Qingwei Meng", "Yiming Zhang", "Yuke Qiu", "Hong Zhou", "Mike Zheng Shou"], "abstract": "Recent advances at the intersection of reinforcement learning (RL) and visual intelligence have enabled agents that not only perceive complex visual scenes but also reason, generate, and act within them. This survey offers a critical and up-to-date synthesis of the field. We first formalize visual RL problems and trace the evolution of policy-optimization strategies from RLHF to verifiable reward paradigms, and from Proximal Policy Optimization to Group Relative Policy Optimization. We then organize more than 200 representative works into four thematic pillars: multi-modal large language models, visual generation, unified model frameworks, and vision-language-action models. For each pillar we examine algorithmic design, reward engineering, benchmark progress, and we distill trends such as curriculum-driven training, preference-aligned diffusion, and unified reward modeling. Finally, we review evaluation protocols spanning set-level fidelity, sample-level preference, and state-level stability, and we identify open challenges that include sample efficiency, generalization, and safe deployment. Our goal is to provide researchers and practitioners with a coherent map of the rapidly expanding landscape of visual RL and to highlight promising directions for future inquiry. Resources are available at:", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "22 pages", "pdf_url": "https://arxiv.org/pdf/2508.08189.pdf", "abstract_url": "https://arxiv.org/abs/2508.08189", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文是一篇关于强化学习在视觉领域应用的综述，总结了从RLHF到可验证奖励范式的策略优化演变，并将200多篇代表性工作分为四大主题支柱进行探讨。", "motivation": "解决强化学习与视觉智能交叉领域的最新进展，为研究者和实践者提供一个连贯的视觉RL领域快速扩展的景观图和未来研究的有希望方向。", "method": "通过组织200多篇代表性工作到四大主题支柱（多模态大型语言模型、视觉生成、统一模型框架和视觉-语言-动作模型），并检查算法设计、奖励工程、基准进展来综合领域现状。", "result": "总结了如课程驱动训练、偏好对齐扩散和统一奖励建模等趋势，并回顾了评估协议，识别了包括样本效率、泛化和安全部署在内的开放挑战。", "conclusion": "本文旨在为研究者和实践者提供视觉RL领域的全面概述，并强调未来研究的有希望方向，相关资源可供进一步探索。"}}
{"id": "2508.07569", "title": "Retrieval-Augmented Multi-Agent System for Rapid Statement of Work Generation", "authors": ["Amulya Suravarjhula", "Rashi Chandrashekhar Agrawal", "Sakshi Jayesh Patel", "Rahul Gupta"], "abstract": "Drafting a Statement of Work (SOW) is a vital part of business and legal projects. It outlines key details like deliverables, timelines, responsibilities, and legal terms. However, creating these documents is often a slow and complex process. It usually involves multiple people, takes several days, and leaves room for errors or outdated content. This paper introduces a new AI-driven automation system that makes the entire SOW drafting process faster, easier, and more accurate. Instead of relying completely on humans, the system uses three intelligent components or 'agents' that each handle a part of the job. One agent writes the first draft, another checks if everything is legally correct, and the third agent formats the document and ensures everything is in order. Unlike basic online tools that just fill in templates, this system understands the meaning behind the content and customizes the SOW to match the needs of the project. It also checks legal compliance and formatting so that users can trust the result. The system was tested using real business examples. It was able to create a full SOW in under three minutes, compared to several hours or days using manual methods. It also performed well in accuracy and quality, showing that it can reduce legal risks and save a lot of time. This solution shows how artificial intelligence can be used to support legal and business professionals by taking care of routine work and helping them focus on more important decisions. It's a step toward making legal processes smarter, faster, and more reliable.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": "7 pages", "pdf_url": "https://arxiv.org/pdf/2508.07569.pdf", "abstract_url": "https://arxiv.org/abs/2508.07569", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一种基于AI的自动化系统，用于快速生成工作说明书（SOW），通过三个智能代理分别负责起草、法律合规检查和文档格式化，显著提高了SOW的起草速度和准确性。", "motivation": "起草工作说明书（SOW）是一个缓慢且复杂的过程，涉及多人协作，耗时数天，且容易出错或包含过时内容。本文旨在解决这一问题。", "method": "系统采用三个智能代理：一个负责起草初稿，一个检查法律合规性，第三个负责文档格式化和最终检查，确保内容的准确性和定制化。", "result": "测试显示，该系统能在三分钟内完成SOW的起草，远快于传统手动方法的数小时或数天，同时在准确性和质量上表现良好。", "conclusion": "该AI系统展示了如何通过自动化常规工作支持法律和商业专业人士，使法律流程更智能、快速和可靠。"}}
{"id": "2508.07560", "title": "Progressive Bird's Eye View Perception for Safety-Critical Autonomous Driving: A Comprehensive Survey", "authors": ["Yan Gong", "Naibang Wang", "Jianli Lu", "Xinyu Zhang", "Yongsheng Gao", "Jie Zhao", "Zifan Huang", "Haozhi Bai", "Nanxin Zeng", "Nayu Su", "Lei Yang", "Ziying Song", "Xiaoxi Hu", "Xinmin Jiang", "Xiaojuan Zhang", "Susanto Rahardja"], "abstract": "Bird's-Eye-View (BEV) perception has become a foundational paradigm in autonomous driving, enabling unified spatial representations that support robust multi-sensor fusion and multi-agent collaboration. As autonomous vehicles transition from controlled environments to real-world deployment, ensuring the safety and reliability of BEV perception in complex scenarios - such as occlusions, adverse weather, and dynamic traffic - remains a critical challenge. This survey provides the first comprehensive review of BEV perception from a safety-critical perspective, systematically analyzing state-of-the-art frameworks and implementation strategies across three progressive stages: single-modality vehicle-side, multimodal vehicle-side, and multi-agent collaborative perception. Furthermore, we examine public datasets encompassing vehicle-side, roadside, and collaborative settings, evaluating their relevance to safety and robustness. We also identify key open-world challenges - including open-set recognition, large-scale unlabeled data, sensor degradation, and inter-agent communication latency - and outline future research directions, such as integration with end-to-end autonomous driving systems, embodied intelligence, and large language models.", "subjects": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.07560.pdf", "abstract_url": "https://arxiv.org/abs/2508.07560", "categories": ["Robotics (cs.RO)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文首次从安全关键角度全面综述了自动驾驶中的鸟瞰图（BEV）感知技术，分析了单模态车载、多模态车载及多智能体协作感知三个阶段的先进框架与实现策略，并探讨了相关公开数据集及未来研究方向。", "motivation": "随着自动驾驶车辆从受控环境转向实际部署，确保BEV感知在复杂场景（如遮挡、恶劣天气和动态交通）中的安全性和可靠性成为一个关键挑战。", "method": "系统分析了BEV感知的三个渐进阶段：单模态车载、多模态车载和多智能体协作感知，并评估了相关公开数据集的安全性和鲁棒性。", "result": "识别了开放世界中的关键挑战，如开放集识别、大规模未标记数据、传感器退化和智能体间通信延迟，并提出了未来研究方向。", "conclusion": "BEV感知技术在自动驾驶中具有重要作用，但面临多项挑战，未来研究应关注与端到端自动驾驶系统、具身智能和大语言模型的整合。"}}
{"id": "2508.07745", "title": "Chimera: Harnessing Multi-Agent LLMs for Automatic Insider Threat Simulation", "authors": ["Jiongchi Yu", "Xiaofei Xie", "Qiang Hu", "Yuhan Ma", "Ziming Zhao"], "abstract": "Insider threats, which can lead to severe losses, remain a major security concern. While machine learning-based insider threat detection (ITD) methods have shown promising results, their progress is hindered by the scarcity of high-quality data. Enterprise data is sensitive and rarely accessible, while publicly available datasets, when limited in scale due to cost, lack sufficient real-world coverage; and when purely synthetic, they fail to capture rich semantics and realistic user behavior. To address this, we propose Chimera, the first large language model (LLM)-based multi-agent framework that automatically simulates both benign and malicious insider activities and collects diverse logs across diverse enterprise environments. Chimera models each employee with agents that have role-specific behavior and integrates modules for group meetings, pairwise interactions, and autonomous scheduling, capturing realistic organizational dynamics. It incorporates 15 types of insider attacks (e.g., IP theft, system sabotage) and has been deployed to simulate activities in three sensitive domains: technology company, finance corporation, and medical institution, producing a new dataset, ChimeraLog. We assess ChimeraLog via human studies and quantitative analysis, confirming its diversity, realism, and presence of explainable threat patterns. Evaluations of existing ITD methods show an average F1-score of 0.83, which is significantly lower than 0.99 on the CERT dataset, demonstrating ChimeraLog's higher difficulty and utility for advancing ITD research.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Software Engineering (cs.SE)", "comments": "23 pages", "pdf_url": "https://arxiv.org/pdf/2508.07745.pdf", "abstract_url": "https://arxiv.org/abs/2508.07745", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Software Engineering (cs.SE)"], "matching_keywords": ["agent"], "AI": {"tldr": "Chimera是一个基于大型语言模型（LLM）的多智能体框架，旨在自动模拟良性和恶意的内部人员活动，以解决内部威胁检测（ITD）研究中高质量数据稀缺的问题。", "motivation": "内部威胁可能导致严重损失，是主要的安全问题。现有的ITD方法因高质量数据的稀缺而进展缓慢，企业数据敏感且难以获取，公开数据集要么规模有限，要么无法捕捉丰富的语义和真实的用户行为。", "method": "Chimera通过为每个员工建模具有角色特定行为的智能体，并整合小组会议、成对互动和自主调度模块，模拟现实的组织动态。它包含15种内部攻击类型，并在三个敏感领域部署模拟活动，生成了新的数据集ChimeraLog。", "result": "通过人类研究和定量分析评估ChimeraLog，确认了其多样性、真实性和可解释的威胁模式的存在。现有ITD方法的评估显示平均F1分数为0.83，显著低于CERT数据集的0.99，证明了ChimeraLog的更高难度和对ITD研究的实用性。", "conclusion": "Chimera通过自动模拟内部人员活动和生成高质量数据集，为内部威胁检测研究提供了新的工具和方法，有助于推动该领域的发展。"}}
{"id": "2508.07966", "title": "Exploring the Challenges and Opportunities of AI-assisted Codebase Generation", "authors": ["Philipp Eibl", "Sadra Sabouri", "Souti Chattopadhyay"], "abstract": "Recent AI code assistants have significantly improved their ability to process more complex contexts and generate entire codebases based on a textual description, compared to the popular snippet-level generation. These codebase AI assistants (CBAs) can also extend or adapt codebases, allowing users to focus on higher-level design and deployment decisions. While prior work has extensively studied the impact of snippet-level code generation, this new class of codebase generation models is relatively unexplored. Despite initial anecdotal reports of excitement about these agents, they remain less frequently adopted compared to snippet-level code assistants. To utilize CBAs better, we need to understand how developers interact with CBAs, and how and why CBAs fall short of developers' needs. In this paper, we explored these gaps through a counterbalanced user study and interview with (n = 16) students and developers working on coding tasks with CBAs. We found that participants varied the information in their prompts, like problem description (48% of prompts), required functionality (98% of prompts), code structure (48% of prompts), and their prompt writing process. Despite various strategies, the overall satisfaction score with generated codebases remained low (mean = 2.8, median = 3, on a scale of one to five). Participants mentioned functionality as the most common factor for dissatisfaction (77% of instances), alongside poor code quality (42% of instances) and communication issues (25% of instances). We delve deeper into participants' dissatisfaction to identify six underlying challenges that participants faced when using CBAs, and extracted five barriers to incorporating CBAs into their workflows. Finally, we surveyed 21 commercial CBAs to compare their capabilities with participant challenges and present design opportunities for more efficient and useful CBAs.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.07966.pdf", "abstract_url": "https://arxiv.org/abs/2508.07966", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了AI辅助代码库生成（CBAs）的挑战与机遇，通过用户研究和访谈揭示了开发者与CBAs互动中的不满及其原因，并提出了改进设计的机会。", "motivation": "研究AI代码库助手（CBAs）在开发者中的使用情况、存在的问题以及为何其采纳率低于片段级代码助手，以促进CBAs的更有效利用。", "method": "通过平衡用户研究和访谈（n = 16）以及调查21个商业CBAs，分析开发者与CBAs的互动方式、不满原因及CBAs的能力。", "result": "研究发现，尽管开发者尝试多种提示策略，但对生成的代码库总体满意度低（平均2.8分，满分5分），主要不满源于功能实现（77%）、代码质量差（42%）和沟通问题（25%）。研究还识别了使用CBAs时的六大挑战和五大工作流程融入障碍。", "conclusion": "研究揭示了CBAs在实际应用中的局限性，并提出了设计更高效、有用CBAs的机会，为未来的AI辅助代码生成工具开发提供了方向。"}}
{"id": "2508.08101", "title": "ChatGPT on the Road: Leveraging Large Language Model-Powered In-vehicle Conversational Agents for Safer and More Enjoyable Driving Experience", "authors": ["Yeana Lee Bond", "Mungyeong Choe", "Baker Kasim Hasan", "Arsh Siddiqui", "Myounghoon Jeon"], "abstract": "Studies on in-vehicle conversational agents have traditionally relied on pre-scripted prompts or limited voice commands, constraining natural driver-agent interaction. To resolve this issue, the present study explored the potential of a ChatGPT-based in-vehicle agent capable of carrying continuous, multi-turn dialogues. Forty drivers participated in our experiment using a motion-based driving simulator, comparing three conditions (No agent, Pre-scripted agent, and ChatGPT-based agent) as a within-subjects variable. Results showed that the ChatGPT-based agent condition led to more stable driving performance across multiple metrics. Participants demonstrated lower variability in longitudinal acceleration, lateral acceleration, and lane deviation compared to the other two conditions. In subjective evaluations, the ChatGPT-based agent also received significantly higher ratings in competence, animacy, affective trust, and preference compared to the Pre-scripted agent. Our thematic analysis of driver-agent conversations revealed diverse interaction patterns in topics, including driving assistance/questions, entertainment requests, and anthropomorphic interactions. Our results highlight the potential of LLM-powered in-vehicle conversational agents to enhance driving safety and user experience through natural, context-rich interactions.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Software Engineering (cs.SE)", "comments": "Submitted to International Journal of Human-Computer Studies. Bond and Choe: Drafting, Review, Editing, Validation, Software, Methodology, Investigation, Data Analysis, Conceptualization, Experiment training. Hasan and Siddiqui: Experimental and Data Analysis Support. Jeon: Supervision, Review, Resources, Project Admin, Methodology, Conceptualization. Total 34 pages", "pdf_url": "https://arxiv.org/pdf/2508.08101.pdf", "abstract_url": "https://arxiv.org/abs/2508.08101", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)", "Software Engineering (cs.SE)"], "matching_keywords": ["agent"], "AI": {"tldr": "本研究探讨了基于ChatGPT的车载对话代理在提升驾驶安全和用户体验方面的潜力，通过实验比较了无代理、预设脚本代理和ChatGPT代理三种条件下的驾驶表现和用户评价。", "motivation": "传统的车载对话代理依赖于预设脚本或有限的语音命令，限制了驾驶员与代理之间的自然互动。本研究旨在解决这一问题，探索基于大型语言模型（如ChatGPT）的车载代理能否通过连续、多轮对话提升交互质量。", "method": "研究采用基于运动的驾驶模拟器，40名驾驶员参与了实验，比较了三种条件（无代理、预设脚本代理和ChatGPT代理）下的驾驶表现和主观评价。", "result": "结果显示，ChatGPT代理条件下的驾驶表现在多个指标上更为稳定，包括纵向加速度、横向加速度和车道偏离的变异性较低。在主观评价方面，ChatGPT代理在能力、生动性、情感信任和偏好方面得分显著高于预设脚本代理。对话分析揭示了多样化的交互模式。", "conclusion": "研究结果表明，基于大型语言模型的车载对话代理通过自然、上下文丰富的交互，有望提升驾驶安全和用户体验。"}}
{"id": "2508.08137", "title": "MuaLLM: A Multimodal Large Language Model Agent for Circuit Design Assistance with Hybrid Contextual Retrieval-Augmented Generation", "authors": ["Pravallika Abbineni", "Saoud Aldowaish", "Colin Liechty", "Soroosh Noorzad", "Ali Ghazizadeh", "Morteza Fayazi"], "abstract": "Conducting a comprehensive literature review is crucial for advancing circuit design methodologies. However, the rapid influx of state-of-the-art research, inconsistent data representation, and the complexity of optimizing circuit design objectives make this task significantly challenging. In this paper, we propose MuaLLM, an open-source multimodal Large Language Model (LLM) agent for circuit design assistance that integrates a hybrid Retrieval-Augmented Generation (RAG) framework with an adaptive vector database of circuit design research papers. Unlike conventional LLMs, the MuaLLM agent employs a Reason + Act (ReAct) workflow for iterative reasoning, goal-setting, and multi-step information retrieval. It functions as a question-answering design assistant, capable of interpreting complex queries and providing reasoned responses grounded in circuit literature. Its multimodal capabilities enable processing of both textual and visual data, facilitating more efficient and comprehensive analysis. The system dynamically adapts using intelligent search tools, automated document retrieval from the internet, and real-time database updates. Unlike conventional approaches constrained by model context limits, MuaLLM decouples retrieval from inference, enabling scalable reasoning over arbitrarily large corpora. At the maximum context length supported by standard LLMs, MuaLLM remains up to 10x less costly and 1.6x faster while maintaining the same accuracy. This allows rapid, no-human-in-the-loop database generation, overcoming the bottleneck of simulation-based dataset creation for circuits. To evaluate MuaLLM, we introduce two custom datasets: RAG-250, targeting retrieval and citation performance, and Reasoning-100 (Reas-100), focused on multistep reasoning in circuit design. MuaLLM achieves 90.1% recall on RAG-250, and 86.8% accuracy on Reas-100.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Systems and Control (eess.SY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.08137.pdf", "abstract_url": "https://arxiv.org/abs/2508.08137", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Systems and Control (eess.SY)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "MuaLLM是一个开源的多模态大型语言模型代理，旨在通过混合上下文检索增强生成技术辅助电路设计，提高文献回顾和设计的效率与准确性。", "motivation": "电路设计方法论的进步需要全面的文献回顾，但最新研究的快速涌入、数据表示的不一致性以及电路设计目标优化的复杂性使得这一任务极具挑战性。", "method": "MuaLLM结合了混合检索增强生成（RAG）框架和自适应电路设计研究论文向量数据库，采用Reason + Act（ReAct）工作流进行迭代推理、目标设定和多步信息检索。", "result": "MuaLLM在RAG-250数据集上实现了90.1%的召回率，在Reas-100数据集上达到了86.8%的准确率，同时比标准LLM成本低10倍，速度快1.6倍。", "conclusion": "MuaLLM通过解耦检索与推理，实现了对任意大规模文献的可扩展推理，克服了基于仿真的电路数据集创建的瓶颈，为电路设计提供了快速、高效的辅助工具。"}}
{"id": "2508.08228", "title": "LL3M: Large Language 3D Modelers", "authors": ["Sining Lu", "Guan Chen", "Nam Anh Dinh", "Itai Lang", "Ari Holtzman", "Rana Hanocka"], "abstract": "We present LL3M, a multi-agent system that leverages pretrained large language models (LLMs) to generate 3D assets by writing interpretable Python code in Blender. We break away from the typical generative approach that learns from a collection of 3D data. Instead, we reformulate shape generation as a code-writing task, enabling greater modularity, editability, and integration with artist workflows. Given a text prompt, LL3M coordinates a team of specialized LLM agents to plan, retrieve, write, debug, and refine Blender scripts that generate and edit geometry and appearance. The generated code works as a high-level, interpretable, human-readable, well-documented representation of scenes and objects, making full use of sophisticated Blender constructs (e.g. B-meshes, geometry modifiers, shader nodes) for diverse, unconstrained shapes, materials, and scenes. This code presents many avenues for further agent and human editing and experimentation via code tweaks or procedural parameters. This medium naturally enables a co-creative loop in our system: agents can automatically self-critique using code and visuals, while iterative user instructions provide an intuitive way to refine assets. A shared code context across agents enables awareness of previous attempts, and a retrieval-augmented generation knowledge base built from Blender API documentation, BlenderRAG, equips agents with examples, types, and functions empowering advanced modeling operations and code correctness. We demonstrate the effectiveness of LL3M across diverse shape categories, style and material edits, and user-driven refinements. Our experiments showcase the power of code as a generative and interpretable medium for 3D asset creation. Our project page is at", "subjects": "Graphics (cs.GR); Artificial Intelligence (cs.AI)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2508.08228.pdf", "abstract_url": "https://arxiv.org/abs/2508.08228", "categories": ["Graphics (cs.GR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "LL3M是一个利用预训练大型语言模型（LLMs）通过编写可解释的Python代码在Blender中生成3D资产的多代理系统。它将形状生成重新定义为代码编写任务，提供了更高的模块化、可编辑性和与艺术家工作流程的集成。", "motivation": "解决传统3D生成方法依赖于3D数据集合学习的问题，提供一种更灵活、可编辑且易于与艺术家工作流程集成的方法。", "method": "LL3M通过协调一组专门的LLM代理来规划、检索、编写、调试和优化Blender脚本，以生成和编辑几何形状和外观。这些脚本作为高级、可解释、人类可读且文档齐全的场景和对象表示。", "result": "LL3M在多样化的形状类别、风格和材质编辑以及用户驱动的优化中展示了其有效性，证明了代码作为3D资产生成的生成和可解释媒介的强大能力。", "conclusion": "LL3M通过代码作为媒介，不仅提高了3D资产生成的效率和灵活性，还促进了代理与人类之间的共创循环，为未来的3D建模和编辑提供了新的可能性。"}}
