{"id": "2507.08520", "title": "Occlusion-Guided Feature Purification Learning via Reinforced Knowledge Distillation for Occluded Person Re-Identification", "authors": ["Yufei Zheng", "Wenjun Wang", "Wenjun Gan", "Jiawei Liu"], "abstract": "Occluded person re-identification aims to retrieve holistic images based on occluded ones. Existing methods often rely on aligning visible body parts, applying occlusion augmentation, or complementing missing semantics using holistic images. However, they face challenges in handling diverse occlusion scenarios not seen during training and the issue of feature contamination from holistic images. To address these limitations, we propose Occlusion-Guided Feature Purification Learning via Reinforced Knowledge Distillation (OGFR), which simultaneously mitigates these challenges. OGFR adopts a teacher-student distillation architecture that effectively incorporates diverse occlusion patterns into feature representation while transferring the purified discriminative holistic knowledge from the holistic to the occluded branch through reinforced knowledge distillation. Specifically, an Occlusion-Aware Vision Transformer is designed to leverage learnable occlusion pattern embeddings to explicitly model such diverse occlusion types, thereby guiding occlusion-aware robust feature representation. Moreover, we devise a Feature Erasing and Purification Module within the holistic branch, in which an agent is employed to identify low-quality patch tokens of holistic images that contain noisy negative information via deep reinforcement learning, and substitute these patch tokens with learnable embedding tokens to avoid feature contamination and further excavate identity-related discriminative clues. Afterward, with the assistance of knowledge distillation, the student branch effectively absorbs the purified holistic knowledge to precisely learn robust representation regardless of the interference of occlusions.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "13 pages, 8 figures", "pdf_url": "https://arxiv.org/pdf/2507.08520.pdf", "abstract_url": "https://arxiv.org/abs/2507.08520", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种通过强化知识蒸馏的遮挡引导特征纯化学习（OGFR）方法，用于解决遮挡人员重新识别中的多样化遮挡场景和特征污染问题。", "motivation": "遮挡人员重新识别旨在基于遮挡图像检索完整图像。现有方法在处理训练中未见的多样化遮挡场景和避免完整图像特征污染方面存在挑战。", "method": "OGFR采用教师-学生蒸馏架构，设计了一个遮挡感知视觉变换器来显式建模多样化遮挡类型，并在完整分支中设计了特征擦除和纯化模块，通过深度强化学习识别并替换低质量补丁令牌。", "result": "OGFR能够有效吸收纯化的完整知识，精确学习鲁棒表示，不受遮挡干扰。", "conclusion": "OGFR通过遮挡引导特征纯化学习和强化知识蒸馏，成功解决了遮挡人员重新识别中的多样化遮挡场景和特征污染问题。"}}
{"id": "2507.08548", "title": "SAM2RL: Towards Reinforcement Learning Memory Control in Segment Anything Model 2", "authors": ["Alen Adamyan", "Tomáš Čížek", "Matej Straka", "Klara Janouskova", "Martin Schmid"], "abstract": "Segment Anything Model 2 (SAM 2) has demonstrated strong performance in object segmentation tasks and has become the state-of-the-art for visual object tracking. The model stores information from previous frames in a memory bank, enabling temporal consistency across video sequences. Recent methods augment SAM 2 with hand-crafted update rules to better handle distractors, occlusions, and object motion. We propose a fundamentally different approach using reinforcement learning for optimizing memory updates in SAM 2 by framing memory control as a sequential decision-making problem. In an overfitting setup with a separate agent per video, our method achieves a relative improvement over SAM 2 that exceeds by more than three times the gains of existing heuristics. These results reveal the untapped potential of the memory bank and highlight reinforcement learning as a powerful alternative to hand-crafted update rules for memory control in visual object tracking.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.08548.pdf", "abstract_url": "https://arxiv.org/abs/2507.08548", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为SAM2RL的新方法，通过强化学习优化Segment Anything Model 2（SAM 2）中的内存更新，将内存控制视为顺序决策问题。在针对每个视频单独训练代理的过拟合设置中，该方法相对于SAM 2的相对改进超过了现有启发式方法的三倍以上。", "motivation": "解决SAM 2在处理视频序列中的干扰物、遮挡和物体运动时，依赖手工制定的更新规则的问题。", "method": "使用强化学习框架，将内存控制建模为顺序决策问题，以优化SAM 2的内存更新策略。", "result": "在过拟合设置下，每个视频使用单独的代理，该方法相对于SAM 2的性能提升超过了现有启发式方法的三倍以上。", "conclusion": "研究结果表明，内存银行具有未被开发的潜力，强化学习是视觉对象跟踪中内存控制的一个强大替代方案，优于手工制定的更新规则。"}}
{"id": "2507.08343", "title": "Towards Imperceptible JPEG Image Hiding: Multi-range Representations-driven Adversarial Stego Generation", "authors": ["Junxue Yang", "Xin Liao", "Weixuan Tang", "Jianhua Yang", "Zheng Qin"], "abstract": "Deep hiding has been exploring the hiding capability of deep learning-based models, aiming to conceal image-level messages into cover images and reveal them from generated stego images. Existing schemes are easily detected by steganalyzers due to their large payloads and their limitation to feature extraction based solely on either pure convolution or pure transformer operators within a single range, as well as pixel-level loss constraints. To address the issue, in this paper, we introduce generation-based adversarial attacks into color JPEG image deep hiding and propose a multi-range representations-driven adversarial stego generation framework called MRAG from a steganalysis perspective. Specifically, we integrate the local-range neighbor reception characteristic of the convolution and the global-range dependency modeling of the transformer to construct MRAG. Meanwhile, we use the transformed images obtained through coarse-grained and fine-grained frequency decomposition as inputs, introducing multi-grained information. Furthermore, a features angle-norm disentanglement loss is designed to constrain the generated stegos closer to covers in the angle and norm space of the steganalyzer's classified features. Consequently, small yet effective adversarial perturbations can be injected into the process of generating stegos, ensuring that stegos maintain favorable secret restorability and imperceptibility. Extensive experiments demonstrate that MRAG can achieve state-of-the-art performance.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.08343.pdf", "abstract_url": "https://arxiv.org/abs/2507.08343", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种名为MRAG的多范围表示驱动的对抗性隐写生成框架，旨在解决现有深度隐藏方案容易被隐写分析器检测到的问题。通过结合卷积的局部范围邻居接收特性和变换器的全局范围依赖建模，以及引入多粒度信息和设计特征角度-范数解缠损失，MRAG能够在生成隐写图像时注入小但有效的对抗性扰动，从而保持隐写图像的良好秘密恢复性和不可感知性。", "motivation": "现有的深度隐藏方案由于大载荷和仅限于单一范围内的纯卷积或纯变换器操作符以及像素级损失约束，容易被隐写分析器检测到。本文旨在解决这一问题。", "method": "本文提出了一个多范围表示驱动的对抗性隐写生成框架MRAG，该框架结合了卷积的局部范围邻居接收特性和变换器的全局范围依赖建模，并通过粗粒度和细粒度频率分解获得的转换图像作为输入，引入多粒度信息。此外，还设计了特征角度-范数解缠损失来约束生成的隐写图像在隐写分析器分类特征的角度和范数空间中更接近封面图像。", "result": "大量实验证明，MRAG能够实现最先进的性能，确保隐写图像保持良好的秘密恢复性和不可感知性。", "conclusion": "MRAG框架通过结合卷积和变换器的特性，以及引入多粒度信息和设计新的损失函数，有效地解决了现有深度隐藏方案容易被检测到的问题，为隐写技术的发展提供了新的方向。"}}
{"id": "2507.08648", "title": "DatasetAgent: A Novel Multi-Agent System for Auto-Constructing Datasets from Real-World Images", "authors": ["Haoran Sun", "Haoyu Bian", "Shaoning Zeng", "Yunbo Rao", "Xu Xu", "Lin Mei", "Jianping Gou"], "abstract": "Common knowledge indicates that the process of constructing image datasets usually depends on the time-intensive and inefficient method of manual collection and annotation. Large models offer a solution via data generation. Nonetheless, real-world data are obviously more valuable comparing to artificially intelligence generated data, particularly in constructing image datasets. For this reason, we propose a novel method for auto-constructing datasets from real-world images by a multiagent collaborative system, named as DatasetAgent. By coordinating four different agents equipped with Multi-modal Large Language Models (MLLMs), as well as a tool package for image optimization, DatasetAgent is able to construct high-quality image datasets according to user-specified requirements. In particular, two types of experiments are conducted, including expanding existing datasets and creating new ones from scratch, on a variety of open-source datasets. In both cases, multiple image datasets constructed by DatasetAgent are used to train various vision models for image classification, object detection, and image segmentation.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.08648.pdf", "abstract_url": "https://arxiv.org/abs/2507.08648", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为DatasetAgent的新型多代理系统，用于从现实世界图像中自动构建数据集，通过协调四个不同的代理和图像优化工具包，能够根据用户指定的需求构建高质量的图像数据集。", "motivation": "解决传统手动收集和注释图像数据集方法的时间密集和效率低下问题，同时强调现实世界数据比人工智能生成的数据更有价值。", "method": "使用多代理协作系统，配备多模态大型语言模型（MLLMs）和图像优化工具包，自动构建高质量图像数据集。", "result": "通过扩展现有数据集和从零开始创建新数据集的实验，证明了DatasetAgent构建的数据集可以用于训练各种视觉模型，如图像分类、对象检测和图像分割。", "conclusion": "DatasetAgent提供了一种高效、自动化的方法来构建高质量的图像数据集，有助于推动计算机视觉领域的研究和应用。"}}
{"id": "2507.08644", "title": "OnlineBEV: Recurrent Temporal Fusion in Bird's Eye View Representations for Multi-Camera 3D Perception", "authors": ["Junho Koh", "Youngwoo Lee", "Jungho Kim", "Dongyoung Lee", "Jun Won Choi"], "abstract": "Multi-view camera-based 3D perception can be conducted using bird's eye view (BEV) features obtained through perspective view-to-BEV transformations. Several studies have shown that the performance of these 3D perception methods can be further enhanced by combining sequential BEV features obtained from multiple camera frames. However, even after compensating for the ego-motion of an autonomous agent, the performance gain from temporal aggregation is limited when combining a large number of image frames. This limitation arises due to dynamic changes in BEV features over time caused by object motion. In this paper, we introduce a novel temporal 3D perception method called OnlineBEV, which combines BEV features over time using a recurrent structure. This structure increases the effective number of combined features with minimal memory usage. However, it is critical to spatially align the features over time to maintain strong performance. OnlineBEV employs the Motion-guided BEV Fusion Network (MBFNet) to achieve temporal feature alignment. MBFNet extracts motion features from consecutive BEV frames and dynamically aligns historical BEV features with current ones using these motion features. To enforce temporal feature alignment explicitly, we use Temporal Consistency Learning Loss, which captures discrepancies between historical and target BEV features. Experiments conducted on the nuScenes benchmark demonstrate that OnlineBEV achieves significant performance gains over the current best method, SOLOFusion. OnlineBEV achieves 63.9% NDS on the nuScenes test set, recording state-of-the-art performance in the camera-only 3D object detection task.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "Accepted to Transactions on Intelligent Transportation Systems", "pdf_url": "https://arxiv.org/pdf/2507.08644.pdf", "abstract_url": "https://arxiv.org/abs/2507.08644", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "OnlineBEV提出了一种新颖的时序3D感知方法，通过递归结构结合鸟瞰图（BEV）特征，利用运动引导的BEV融合网络（MBFNet）实现时序特征对齐，显著提升了多摄像头3D感知性能。", "motivation": "现有的多视角摄像头3D感知方法通过结合多个摄像头帧的时序BEV特征来提升性能，但由于物体运动导致的BEV特征动态变化，时序聚合的性能提升有限。", "method": "OnlineBEV采用递归结构结合BEV特征，使用MBFNet提取连续BEV帧的运动特征，并动态对齐历史与当前BEV特征，同时使用时序一致性学习损失显式强化特征对齐。", "result": "在nuScenes基准测试中，OnlineBEV实现了63.9%的NDS，超过了当前最佳方法SOLOFusion，在仅使用摄像头的3D物体检测任务中达到了最先进的性能。", "conclusion": "OnlineBEV通过递归时序融合和运动引导的特征对齐，有效提升了多摄像头3D感知的性能，为自动驾驶等领域提供了更强大的感知能力。"}}
{"id": "2507.08655", "title": "Generalizable 7T T1-map Synthesis from 1.5T and 3T T1 MRI with an Efficient Transformer Model", "authors": ["Zach Eidex", "Mojtaba Safari", "Tonghe Wang", "Vanessa Wildman", "David S. Yu", "Hui Mao", "Erik Middlebrooks", "Aparna Kesewala", "Xiaofeng Yang"], "abstract": "Purpose: Ultra-high-field 7T MRI offers improved resolution and contrast over standard clinical field strengths (1.5T, 3T). However, 7T scanners are costly, scarce, and introduce additional challenges such as susceptibility artifacts. We propose an efficient transformer-based model (7T-Restormer) to synthesize 7T-quality T1-maps from routine 1.5T or 3T T1-weighted (T1W) images. Methods: Our model was validated on 35 1.5T and 108 3T T1w MRI paired with corresponding 7T T1 maps of patients with confirmed MS. A total of 141 patient cases (32,128 slices) were randomly divided into 105 (25; 80) training cases (19,204 slices), 19 (5; 14) validation cases (3,476 slices), and 17 (5; 14) test cases (3,145 slices) where (X; Y) denotes the patients with 1.5T and 3T T1W scans, respectively. The synthetic 7T T1 maps were compared against the ResViT and ResShift models. Results: The 7T-Restormer model achieved a PSNR of 26.0 +/- 4.6 dB, SSIM of 0.861 +/- 0.072, and NMSE of 0.019 +/- 0.011 for 1.5T inputs, and 25.9 +/- 4.9 dB, and 0.866 +/- 0.077 for 3T inputs, respectively. Using 10.5 M parameters, our model reduced NMSE by 64 % relative to 56.7M parameter ResShift (0.019 vs 0.052, p = <.001 and by 41 % relative to 70.4M parameter ResViT (0.019 vs 0.032, p = <.001) at 1.5T, with similar advantages at 3T (0.021 vs 0.060 and 0.033; p < .001). Training with a mixed 1.5 T + 3 T corpus was superior to single-field strategies. Restricting the model to 1.5T increased the 1.5T NMSE from 0.019 to 0.021 (p = 1.1E-3) while training solely on 3T resulted in lower performance on input 1.5T T1W MRI. Conclusion: We propose a novel method for predicting quantitative 7T MP2RAGE maps from 1.5T and 3T T1W scans with higher quality than existing state-of-the-art methods. Our approach makes the benefits of 7T MRI more accessible to standard clinical workflows.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.08655.pdf", "abstract_url": "https://arxiv.org/abs/2507.08655", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种高效的基于Transformer的模型（7T-Restormer），用于从常规1.5T或3T T1加权图像合成7T质量的T1图，以提高7T MRI的可及性。", "motivation": "7T MRI提供了比标准临床场强（1.5T，3T）更高的分辨率和对比度，但7T扫描仪成本高、稀缺，并引入了如敏感性伪影等额外挑战。", "method": "使用一个高效的基于Transformer的模型（7T-Restormer），在35例1.5T和108例3T T1加权MRI与相应7T T1图的MS患者数据上进行验证。", "result": "7T-Restormer模型在1.5T输入上实现了PSNR为26.0 +/- 4.6 dB，SSIM为0.861 +/- 0.072，NMSE为0.019 +/- 0.011，在3T输入上实现了PSNR为25.9 +/- 4.9 dB，SSIM为0.866 +/- 0.077。", "conclusion": "我们提出了一种新颖的方法，用于从1.5T和3T T1加权扫描预测定量7T MP2RAGE图，其质量优于现有最先进的方法，使7T MRI的好处更易于标准临床工作流程。"}}
{"id": "2507.08297", "title": "KAT-V1: Kwai-AutoThink Technical Report", "authors": ["Zizheng Zhan", "Ken Deng", "Huaixi Tang", "Wen Xiang", "Kun Wu", "Weihao Li", "Wenqiang Zhu", "Jingxuan Xu", "Lecheng Huang", "Zongxian Feng", "Shaojie Wang", "Shangpeng Yan", "Jiaheng Liu", "Zhongyuan Peng", "Zuchen Gao", "Haoyang Huang", "Ziqi Zhan", "Yanan Wu", "Yuanxing Zhang", "Jian Yang", "Guang Chen", "Haotian Zhang", "Bin Chen", "Bing Yu"], "abstract": "We present Kwaipilot-AutoThink (KAT), an open-source 40B large language model developed to address the overthinking problem in reasoning-intensive tasks, where an automatic thinking training paradigm is proposed to dynamically switch between reasoning and non-reasoning modes based on task complexity. Specifically, first, we construct the dual-regime dataset based on a novel tagging pipeline and a multi-agent synthesis strategy, and then we apply Multi-Token Prediction (MTP)-enhanced knowledge distillation, enabling efficient and fine-grained reasoning transfer with minimal pretraining cost. Besides, we implement a cold-start initialization strategy that introduces mode-selection priors using majority-vote signals and intent-aware prompting. Finally, we propose Step-SRPO, a reinforcement learning algorithm that incorporates intermediate supervision into the GRPO framework, offering structured guidance over both reasoning-mode selection and response accuracy. Extensive experiments across multiple benchmarks demonstrate that KAT consistently matches or even outperforms current state-of-the-art models, including DeepSeek-R1-0528 and Qwen3-235B-A22B, across a wide range of reasoning-intensive tasks while reducing token usage by up to approximately 30\\%. Beyond academic evaluation, KAT has been successfully deployed in Kwaipilot (i.e., Kuaishou's internal coding assistant), and improves real-world development workflows with high accuracy, efficiency, and controllable reasoning behaviors. Moreover, we are actively training a 200B Mixture-of-Experts (MoE) with 40B activation parameters, where the early-stage results already demonstrate promising improvements in performance and efficiency, further showing the scalability of the AutoThink paradigm.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.08297.pdf", "abstract_url": "https://arxiv.org/abs/2507.08297", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "KAT-V1是快手开发的40B大型语言模型，旨在解决推理密集型任务中的过度思考问题，通过自动思维训练范式动态切换推理和非推理模式。", "motivation": "解决推理密集型任务中模型过度思考的问题，提高效率和准确性。", "method": "采用双制度数据集构建、多令牌预测增强的知识蒸馏、冷启动初始化策略和Step-SRPO强化学习算法。", "result": "KAT在多个基准测试中匹配或超越当前最先进模型，同时减少约30%的令牌使用，并在快手内部编码助手Kwaipilot中成功部署。", "conclusion": "AutoThink范式在性能和效率上展现出可扩展性，早期200B MoE模型的结果显示进一步改进的潜力。"}}
{"id": "2507.08038", "title": "AblationBench: Evaluating Automated Planning of Ablations in Empirical AI Research", "authors": ["Talor Abramovich", "Gal Chechik"], "abstract": "Autonomous agents built on language models (LMs) are showing increasing popularity in many fields, including scientific research. AI co-scientists aim to support or automate parts of the research process using these agents. A key component of empirical AI research is the design of ablation experiments. To this end, we introduce AblationBench, a benchmark suite for evaluating agents on ablation planning tasks in empirical AI research. It includes two tasks: AuthorAblation, which helps authors propose ablation experiments based on a method section and contains 83 instances, and ReviewerAblation, which helps reviewers find missing ablations in a full paper and contains 350 instances. For both tasks, we develop LM-based judges that serve as an automatic evaluation framework. Our experiments with frontier LMs show that these tasks remain challenging, with the best-performing LM system identifying only 29% of the original ablations on average. Lastly, we analyze the limitations of current LMs on these tasks, and find that chain-of-thought prompting outperforms the currently existing agent-based approach.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.08038.pdf", "abstract_url": "https://arxiv.org/abs/2507.08038", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了AblationBench，一个用于评估在实证AI研究中自动化规划消融实验的基准套件，包含两个任务：AuthorAblation和ReviewerAblation，并开发了基于语言模型的评估框架。实验显示，当前最先进的语言模型在这些任务上仍有挑战，最佳表现的系统平均仅识别出29%的原始消融实验。", "motivation": "随着基于语言模型的自主代理在科学研究中越来越受欢迎，AI共科学家旨在利用这些代理支持或自动化研究过程的某些部分。消融实验的设计是实证AI研究的一个关键组成部分，但目前缺乏评估代理在这一任务上的表现的基准。", "method": "引入了AblationBench基准套件，包含两个任务：AuthorAblation和ReviewerAblation，分别帮助作者基于方法部分提出消融实验和帮助评审者在完整论文中发现缺失的消融实验。开发了基于语言模型的评估框架，用于自动评估。", "result": "实验结果表明，这些任务对当前最先进的语言模型仍然具有挑战性，最佳表现的系统平均仅识别出29%的原始消融实验。此外，思维链提示优于现有的基于代理的方法。", "conclusion": "AblationBench为评估自动化消融实验规划提供了一个有效的基准，揭示了当前语言模型在这一领域的局限性，并指出了未来改进的方向。"}}
{"id": "2507.08207", "title": "A Dynamic Stackelberg Game Framework for Agentic AI Defense Against LLM Jailbreaking", "authors": ["Zhengye Han", "Quanyan Zhu"], "abstract": "As large language models (LLMs) are increasingly deployed in critical applications, the challenge of jailbreaking, where adversaries manipulate the models to bypass safety mechanisms, has become a significant concern. This paper presents a dynamic Stackelberg game framework to model the interactions between attackers and defenders in the context of LLM jailbreaking. The framework treats the prompt-response dynamics as a sequential extensive-form game, where the defender, as the leader, commits to a strategy while anticipating the attacker's optimal responses. We propose a novel agentic AI solution, the \"Purple Agent,\" which integrates adversarial exploration and defensive strategies using Rapidly-exploring Random Trees (RRT). The Purple Agent actively simulates potential attack trajectories and intervenes proactively to prevent harmful outputs. This approach offers a principled method for analyzing adversarial dynamics and provides a foundation for mitigating the risk of jailbreaking.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.08207.pdf", "abstract_url": "https://arxiv.org/abs/2507.08207", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种动态Stackelberg游戏框架，用于模拟大型语言模型（LLMs）越狱攻击中攻击者与防御者之间的互动，并介绍了一种名为“紫色代理”的新型代理AI解决方案，该方案结合了对抗性探索和防御策略，以主动预防有害输出。", "motivation": "随着大型语言模型（LLMs）在关键应用中的部署越来越广泛，越狱攻击（即攻击者操纵模型绕过安全机制）已成为一个重要问题。本文旨在解决这一问题。", "method": "采用动态Stackelberg游戏框架，将提示-响应动态建模为顺序扩展形式游戏，并提出“紫色代理”解决方案，该方案利用快速探索随机树（RRT）集成对抗性探索和防御策略。", "result": "提出的“紫色代理”能够主动模拟潜在攻击轨迹并提前干预，为防止LLM越狱提供了一种有原则的方法。", "conclusion": "本文的动态Stackelberg游戏框架和“紫色代理”解决方案为分析对抗动态和减轻越狱风险提供了理论基础和实践方法。"}}
{"id": "2507.08208", "title": "Reasoning and Behavioral Equilibria in LLM-Nash Games: From Mindsets to Actions", "authors": ["Quanyan Zhu"], "abstract": "We introduce the LLM-Nash framework, a game-theoretic model where agents select reasoning prompts to guide decision-making via Large Language Models (LLMs). Unlike classical games that assume utility-maximizing agents with full rationality, this framework captures bounded rationality by modeling the reasoning process explicitly. Equilibrium is defined over the prompt space, with actions emerging as the behavioral output of LLM inference. This approach enables the study of cognitive constraints, mindset expressiveness, and epistemic learning. Through illustrative examples, we show how reasoning equilibria can diverge from classical Nash outcomes, offering a new foundation for strategic interaction in LLM-enabled systems.", "subjects": "Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.08208.pdf", "abstract_url": "https://arxiv.org/abs/2507.08208", "categories": ["Artificial Intelligence (cs.AI)", "Computer Science and Game Theory (cs.GT)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了LLM-Nash框架，一种游戏理论模型，其中代理选择推理提示通过大型语言模型（LLMs）指导决策。与假设代理具有完全理性的经典游戏不同，该框架通过明确建模推理过程来捕捉有限理性。平衡被定义在提示空间上，行为作为LLM推理的输出出现。这种方法能够研究认知约束、心态表达性和认知学习。通过示例，我们展示了推理平衡如何与经典纳什结果不同，为LLM支持系统中的战略互动提供了新的基础。", "motivation": "解决经典游戏理论中假设代理具有完全理性与现实世界中代理的有限理性之间的差距，特别是在大型语言模型（LLMs）支持的系统中。", "method": "引入LLM-Nash框架，通过建模代理的推理过程来捕捉有限理性，定义在提示空间上的平衡，行为作为LLM推理的输出。", "result": "推理平衡可以与经典纳什结果不同，提供了对认知约束、心态表达性和认知学习的新见解。", "conclusion": "LLM-Nash框架为理解和支持LLM系统中的战略互动提供了新的理论基础，特别是在考虑代理的有限理性和认知过程时。"}}
{"id": "2507.08210", "title": "From Curiosity to Competence: How World Models Interact with the Dynamics of Exploration", "authors": ["Fryderyk Mantiuk", "Hanqi Zhou", "Charley M. Wu"], "abstract": "What drives an agent to explore the world while also maintaining control over the environment? From a child at play to scientists in the lab, intelligent agents must balance curiosity (the drive to seek knowledge) with competence (the drive to master and control the environment). Bridging cognitive theories of intrinsic motivation with reinforcement learning, we ask how evolving internal representations mediate the trade-off between curiosity (novelty or information gain) and competence (empowerment). We compare two model-based agents using handcrafted state abstractions (Tabular) or learning an internal world model (Dreamer). The Tabular agent shows curiosity and competence guide exploration in distinct patterns, while prioritizing both improves exploration. The Dreamer agent reveals a two-way interaction between exploration and representation learning, mirroring the developmental co-evolution of curiosity and competence. Our findings formalize adaptive exploration as a balance between pursuing the unknown and the controllable, offering insights for cognitive theories and efficient reinforcement learning.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.08210.pdf", "abstract_url": "https://arxiv.org/abs/2507.08210", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了智能体如何通过内在动机与强化学习的结合，平衡好奇心（寻求知识）与能力（掌握和控制环境）之间的权衡，比较了两种基于模型的代理，揭示了探索与表示学习之间的双向互动。", "motivation": "解决智能体在探索世界与保持环境控制之间的平衡问题，类似于从儿童玩耍到科学家实验室中的行为。", "method": "比较了使用手工制作状态抽象（Tabular）或学习内部世界模型（Dreamer）的两种基于模型的代理。", "result": "Tabular代理显示好奇心和能力以不同的模式引导探索，而优先考虑两者可以改善探索；Dreamer代理揭示了探索与表示学习之间的双向互动。", "conclusion": "研究结果将适应性探索形式化为追求未知与可控之间的平衡，为认知理论和高效强化学习提供了见解。"}}
{"id": "2507.08249", "title": "Giving AI Agents Access to Cryptocurrency and Smart Contracts Creates New Vectors of AI Harm", "authors": ["Bill Marino", "Ari Juels"], "abstract": "There is growing interest in giving AI agents access to cryptocurrencies as well as to the smart contracts that transact them. But doing so, this position paper argues, could lead to formidable new vectors of AI harm. To support this argument, we first examine the unique properties of cryptocurrencies and smart contracts that could lead to these new vectors of harm. Next, we describe each of these new vectors of harm in detail. Finally, we conclude with a call for more technical research aimed at preventing and mitigating these harms and, thereby making it safer to endow AI agents with cryptocurrencies and smart contracts.", "subjects": "Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.08249.pdf", "abstract_url": "https://arxiv.org/abs/2507.08249", "categories": ["Artificial Intelligence (cs.AI)", "Cryptography and Security (cs.CR)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了赋予AI代理访问加密货币和智能合约的能力可能带来的新危害向量，并呼吁进行更多技术研究以防止和减轻这些危害。", "motivation": "解决赋予AI代理访问加密货币和智能合约能力可能引发的新危害问题。", "method": "分析加密货币和智能合约的独特属性，详细描述这些新危害向量。", "result": "识别了由AI代理访问加密货币和智能合约可能导致的潜在危害向量。", "conclusion": "需要进行更多技术研究以防止和减轻这些危害，使赋予AI代理加密货币和智能合约更加安全。"}}
{"id": "2507.08392", "title": "Multi-Agent LLMs as Ethics Advocates in AI-Based Systems", "authors": ["Asma Yamani", "Malak Baslyman", "Moataz Ahmed"], "abstract": "Incorporating ethics into the requirement elicitation process is essential for creating ethically aligned systems. Although eliciting manual ethics requirements is effective, it requires diverse input from multiple stakeholders, which can be challenging due to time and resource constraints. Moreover, it is often given a low priority in the requirements elicitation process. This study proposes a framework for generating ethics requirements drafts by introducing an ethics advocate agent in a multi-agent LLM setting. This agent critiques and provides input on ethical issues based on the system description. The proposed framework is evaluated through two case studies from different contexts, demonstrating that it captures the majority of ethics requirements identified by researchers during 30-minute interviews and introduces several additional relevant requirements. However, it also highlights reliability issues in generating ethics requirements, emphasizing the need for human feedback in this sensitive domain. We believe this work can facilitate the broader adoption of ethics in the requirements engineering process, ultimately leading to more ethically aligned products.", "subjects": "Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.08392.pdf", "abstract_url": "https://arxiv.org/abs/2507.08392", "categories": ["Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)"], "matching_keywords": ["agent"], "AI": {"tldr": "本研究提出了一种在多代理LLM设置中引入伦理倡导者代理的框架，用于生成伦理要求草案，并通过两个案例研究评估其效果。", "motivation": "在需求获取过程中融入伦理考虑对于创建伦理对齐的系统至关重要，但由于时间和资源限制，这一过程往往被忽视。", "method": "引入伦理倡导者代理在多代理LLM设置中，该代理基于系统描述对伦理问题进行批评和提供输入。", "result": "框架能够捕捉研究人员在30分钟访谈中确定的大多数伦理要求，并引入了一些额外的相关要求，但也揭示了在生成伦理要求时的可靠性问题。", "conclusion": "这项工作可以促进伦理在需求工程过程中的更广泛采用，最终导致更伦理对齐的产品，但强调了在这一敏感领域需要人类反馈。"}}
{"id": "2507.08270", "title": "Agent Safety Alignment via Reinforcement Learning", "authors": ["Zeyang Sha", "Hanling Tian", "Zhuoer Xu", "Shiwen Cui", "Changhua Meng", "Weiqiang Wang"], "abstract": "The emergence of autonomous Large Language Model (LLM) agents capable of tool usage has introduced new safety risks that go beyond traditional conversational misuse. These agents, empowered to execute external functions, are vulnerable to both user-initiated threats (e.g., adversarial prompts) and tool-initiated threats (e.g., malicious outputs from compromised tools). In this paper, we propose the first unified safety-alignment framework for tool-using agents, enabling models to handle both channels of threat via structured reasoning and sandboxed reinforcement learning. We introduce a tri-modal taxonomy, including benign, malicious, and sensitive for both user prompts and tool responses, and define a policy-driven decision model. Our framework employs a custom-designed sandbox environment that simulates real-world tool execution and allows fine-grained reward shaping. Through extensive evaluations on public and self-built benchmarks, including Agent SafetyBench, InjecAgent, and BFCL, we demonstrate that our safety-aligned agents significantly improve resistance to security threats while preserving strong utility on benign tasks. Our results show that safety and effectiveness can be jointly optimized, laying the groundwork for trustworthy deployment of autonomous LLM agents.", "subjects": "Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.08270.pdf", "abstract_url": "https://arxiv.org/abs/2507.08270", "categories": ["Artificial Intelligence (cs.AI)", "Cryptography and Security (cs.CR)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了首个针对使用工具的自主大型语言模型（LLM）代理的统一安全对齐框架，通过结构化推理和沙盒强化学习处理用户和工具引发的安全威胁。", "motivation": "自主LLM代理的工具使用能力引入了超越传统对话滥用的新安全风险，包括用户发起的威胁（如对抗性提示）和工具发起的威胁（如受损工具的恶意输出）。", "method": "提出了一个三模态分类法（良性、恶意、敏感）用于用户提示和工具响应，并定义了一个基于策略的决策模型。框架采用定制设计的沙盒环境，模拟真实世界工具执行并允许细粒度奖励塑造。", "result": "在包括Agent SafetyBench、InjecAgent和BFCL在内的公共和自建基准上的广泛评估表明，安全对齐的代理显著提高了对安全威胁的抵抗能力，同时在良性任务上保持了强大的效用。", "conclusion": "结果表明，安全性和有效性可以共同优化，为自主LLM代理的可信部署奠定了基础。"}}
{"id": "2507.08800", "title": "NeuralOS: Towards Simulating Operating Systems via Neural Generative Models", "authors": ["Luke Rivard", "Sun Sun", "Hongyu Guo", "Wenhu Chen", "Yuntian Deng"], "abstract": "We introduce NeuralOS, a neural framework that simulates graphical user interfaces (GUIs) of operating systems by directly predicting screen frames in response to user inputs such as mouse movements, clicks, and keyboard events. NeuralOS combines a recurrent neural network (RNN), which tracks computer state, with a diffusion-based neural renderer that generates screen images. The model is trained on a large-scale dataset of Ubuntu XFCE recordings, which include both randomly generated interactions and realistic interactions produced by AI agents. Experiments show that NeuralOS successfully renders realistic GUI sequences, accurately captures mouse interactions, and reliably predicts state transitions like application launches. Although modeling fine-grained keyboard interactions precisely remains challenging, NeuralOS offers a step toward creating fully adaptive, generative neural interfaces for future human-computer interaction systems.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.08800.pdf", "abstract_url": "https://arxiv.org/abs/2507.08800", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Human-Computer Interaction (cs.HC)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "NeuralOS是一个通过神经生成模型模拟操作系统图形用户界面（GUI）的框架，能够根据用户输入（如鼠标移动、点击和键盘事件）直接预测屏幕帧。", "motivation": "解决如何通过神经生成模型模拟操作系统GUI的问题，为未来人机交互系统创建完全自适应的生成神经接口。", "method": "结合了用于跟踪计算机状态的循环神经网络（RNN）和基于扩散的神经渲染器，生成屏幕图像。模型在Ubuntu XFCE记录的大规模数据集上进行训练。", "result": "NeuralOS成功渲染了真实的GUI序列，准确捕捉了鼠标交互，并可靠地预测了如应用程序启动等状态转换。", "conclusion": "尽管精确建模细粒度的键盘交互仍具挑战性，但NeuralOS为创建未来人机交互系统的完全自适应、生成神经接口迈出了一步。"}}
{"id": "2507.08325", "title": "CRMAgent: A Multi-Agent LLM System for E-Commerce CRM Message Template Generation", "authors": ["Yinzhu Quan", "Xinrui Li", "Ying Chen"], "abstract": "In e-commerce private-domain channels such as instant messaging and e-mail, merchants engage customers directly as part of their Customer Relationship Management (CRM) programmes to drive retention and conversion. While a few top performers excel at crafting outbound messages, most merchants struggle to write persuasive copy because they lack both expertise and scalable tools. We introduce CRMAgent, a multi-agent system built on large language models (LLMs) that generates high-quality message templates and actionable writing guidance through three complementary modes. First, group-based learning enables the agent to learn from a merchant's own top-performing messages within the same audience segment and rewrite low-performing ones. Second, retrieval-and-adaptation fetches templates that share the same audience segment and exhibit high similarity in voucher type and product category, learns their successful patterns, and adapts them to the current campaign. Third, a rule-based fallback provides a lightweight zero-shot rewrite when no suitable references are available. Extensive experiments show that CRMAgent consistently outperforms merchants' original templates, delivering significant gains in both audience-match and marketing-effectiveness metrics.", "subjects": "Computation and Language (cs.CL); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.08325.pdf", "abstract_url": "https://arxiv.org/abs/2507.08325", "categories": ["Computation and Language (cs.CL)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "CRMAgent是一个基于大型语言模型的多代理系统，旨在为电子商务CRM生成高质量的消息模板和写作指导。", "motivation": "解决电子商务中大多数商家因缺乏专业知识和可扩展工具而难以撰写有说服力的外发消息的问题。", "method": "通过三种互补模式：基于群体的学习、检索与适应以及基于规则的备用方案，生成高质量的消息模板。", "result": "实验显示，CRMAgent在受众匹配和营销效果指标上均显著优于商家原始模板。", "conclusion": "CRMAgent为电子商务CRM提供了一种有效的解决方案，能够显著提升消息模板的质量和营销效果。"}}
{"id": "2507.08339", "title": "What Factors Affect LLMs and RLLMs in Financial Question Answering?", "authors": ["Peng Wang", "Xuesi Hu", "Jiageng Wu", "Yuntao Zou", "Qiancheng Zhang", "Dagang Li"], "abstract": "Recently, the development of large language models (LLMs) and reasoning large language models (RLLMs) have gained considerable attention from many researchers. RLLMs enhance the reasoning capabilities of LLMs through Long Chain-of-Thought (Long CoT) processes, significantly improving the performance of LLMs in addressing complex problems. However, there are few works that systematically explore what methods can fully unlock the performance of LLMs and RLLMs within the financial domain. To investigate the impact of various methods on LLMs and RLLMs, we utilize five LLMs and three RLLMs to assess the effects of prompting methods, agentic frameworks, and multilingual alignment methods on financial question-answering tasks. Our research findings indicate: (1) Current prompting methods and agent frameworks enhance the performance of LLMs in financial question answering by simulating Long CoT; (2) RLLMs possess inherent Long CoT capabilities, which limits the effectiveness of conventional methods in further enhancing their performance; (3) Current advanced multilingual alignment methods primarily improve the multilingual performance of LLMs by extending the reasoning length, which yields minimal benefits for RLLMs. We hope that this study can serve as an important reference for LLMs and RLLMs in the field of financial question answering.", "subjects": "Computation and Language (cs.CL)", "comments": "Preprint", "pdf_url": "https://arxiv.org/pdf/2507.08339.pdf", "abstract_url": "https://arxiv.org/abs/2507.08339", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文探讨了大型语言模型（LLMs）和推理大型语言模型（RLLMs）在金融问答任务中的表现，研究了提示方法、代理框架和多语言对齐方法对它们的影响。", "motivation": "探索在金融领域内，哪些方法能够充分释放LLMs和RLLMs的性能，特别是在处理复杂问题时的表现。", "method": "使用五种LLMs和三种RLLMs，评估了提示方法、代理框架和多语言对齐方法对金融问答任务的影响。", "result": "研究发现：1）当前的提示方法和代理框架通过模拟长链思维（Long CoT）提高了LLMs在金融问答中的表现；2）RLLMs固有的Long CoT能力限制了传统方法进一步提升其性能的效果；3）先进的多语言对齐方法主要通过延长推理长度来提升LLMs的多语言表现，对RLLMs的益处有限。", "conclusion": "本研究为LLMs和RLLMs在金融问答领域的应用提供了重要参考，指出了当前方法的局限性和未来改进的方向。"}}
{"id": "2507.08350", "title": "Exploring Design of Multi-Agent LLM Dialogues for Research Ideation", "authors": ["Keisuke Ueda", "Wataru Hirota", "Takuto Asakura", "Takahiro Omi", "Kosuke Takahashi", "Kosuke Arima", "Tatsuya Ishigaki"], "abstract": "Large language models (LLMs) are increasingly used to support creative tasks such as research idea generation. While recent work has shown that structured dialogues between LLMs can improve the novelty and feasibility of generated ideas, the optimal design of such interactions remains unclear. In this study, we conduct a comprehensive analysis of multi-agent LLM dialogues for scientific ideation. We compare different configurations of agent roles, number of agents, and dialogue depth to understand how these factors influence the novelty and feasibility of generated ideas. Our experimental setup includes settings where one agent generates ideas and another critiques them, enabling iterative improvement. Our results show that enlarging the agent cohort, deepening the interaction depth, and broadening agent persona heterogeneity each enrich the diversity of generated ideas. Moreover, specifically increasing critic-side diversity within the ideation-critique-revision loop further boosts the feasibility of the final proposals. Our findings offer practical guidelines for building effective multi-agent LLM systems for scientific ideation. Our code is available at", "subjects": "Computation and Language (cs.CL); Multiagent Systems (cs.MA)", "comments": "16 pages, 1 figure, appendix. Accepted to SIGDIAL 2025", "pdf_url": "https://arxiv.org/pdf/2507.08350.pdf", "abstract_url": "https://arxiv.org/abs/2507.08350", "categories": ["Computation and Language (cs.CL)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本研究探讨了多智能体大语言模型（LLM）对话在研究构思中的设计，比较了不同智能体角色、数量和对话深度对生成想法新颖性和可行性的影响。", "motivation": "解决如何优化多智能体LLM对话设计以支持科研构思，提高生成想法的新颖性和可行性的问题。", "method": "通过实验比较不同配置的智能体角色、数量和对话深度，包括一个智能体生成想法，另一个进行批评以实现迭代改进的设置。", "result": "扩大智能体群体、加深交互深度和增加智能体角色异质性均能丰富生成想法的多样性；特别地，增加批评端的多样性进一步提升了最终提案的可行性。", "conclusion": "研究结果为构建有效的多智能体LLM系统以支持科学构思提供了实用指南。"}}
{"id": "2507.08425", "title": "A Survey of Large Language Models in Discipline-specific Research: Challenges, Methods and Opportunities", "authors": ["Lu Xiang", "Yang Zhao", "Yaping Zhang", "Chengqing Zong"], "abstract": "Large Language Models (LLMs) have demonstrated their transformative potential across numerous disciplinary studies, reshaping the existing research methodologies and fostering interdisciplinary collaboration. However, a systematic understanding of their integration into diverse disciplines remains underexplored. This survey paper provides a comprehensive overview of the application of LLMs in interdisciplinary studies, categorising research efforts from both a technical perspective and with regard to their applicability. From a technical standpoint, key methodologies such as supervised fine-tuning, retrieval-augmented generation, agent-based approaches, and tool-use integration are examined, which enhance the adaptability and effectiveness of LLMs in discipline-specific contexts. From the perspective of their applicability, this paper explores how LLMs are contributing to various disciplines including mathematics, physics, chemistry, biology, and the humanities and social sciences, demonstrating their role in discipline-specific tasks. The prevailing challenges are critically examined and the promising research directions are highlighted alongside the recent advances in LLMs. By providing a comprehensive overview of the technical developments and applications in this field, this survey aims to serve as an invaluable resource for the researchers who are navigating the complex landscape of LLMs in the context of interdisciplinary studies.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.08425.pdf", "abstract_url": "https://arxiv.org/abs/2507.08425", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文综述了大型语言模型（LLMs）在学科特定研究中的应用、挑战、方法及机遇，旨在为跨学科研究中的LLMs使用提供全面指南。", "motivation": "尽管LLMs在多个学科中展现出变革潜力，但其在跨学科研究中的系统整合仍未被充分探索。本文旨在填补这一空白。", "method": "从技术和应用两个角度分类研究努力，探讨了监督微调、检索增强生成、基于代理的方法和工具使用整合等关键技术。", "result": "LLMs在数学、物理、化学、生物学及人文社会科学等多个学科中发挥作用，同时面临挑战，但也展现出广阔的研究前景。", "conclusion": "本文通过全面概述LLMs的技术发展和应用，旨在成为跨学科研究中导航LLMs复杂景观的宝贵资源。"}}
{"id": "2507.08440", "title": "Finding Common Ground: Using Large Language Models to Detect Agreement in Multi-Agent Decision Conferences", "authors": ["Selina Heller", "Mohamed Ibrahim", "David Antony Selby", "Sebastian Vollmer"], "abstract": "Decision conferences are structured, collaborative meetings that bring together experts from various fields to address complex issues and reach a consensus on recommendations for future actions or policies. These conferences often rely on facilitated discussions to ensure productive dialogue and collective agreement. Recently, Large Language Models (LLMs) have shown significant promise in simulating real-world scenarios, particularly through collaborative multi-agent systems that mimic group interactions. In this work, we present a novel LLM-based multi-agent system designed to simulate decision conferences, specifically focusing on detecting agreement among the participant agents. To achieve this, we evaluate six distinct LLMs on two tasks: stance detection, which identifies the position an agent takes on a given issue, and stance polarity detection, which identifies the sentiment as positive, negative, or neutral. These models are further assessed within the multi-agent system to determine their effectiveness in complex simulations. Our results indicate that LLMs can reliably detect agreement even in dynamic and nuanced debates. Incorporating an agreement-detection agent within the system can also improve the efficiency of group debates and enhance the overall quality and coherence of deliberations, making them comparable to real-world decision conferences regarding outcome and decision-making. These findings demonstrate the potential for LLM-based multi-agent systems to simulate group decision-making processes. They also highlight that such systems could be instrumental in supporting decision-making with expert elicitation workshops across various domains.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.08440.pdf", "abstract_url": "https://arxiv.org/abs/2507.08440", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于大型语言模型（LLM）的多智能体系统，用于模拟决策会议并检测参与者之间的共识。通过评估六种不同的LLM在立场检测和立场极性检测任务上的表现，研究发现LLM能够在动态和微妙的辩论中可靠地检测共识。", "motivation": "决策会议是解决复杂问题并达成共识的重要方式，但依赖于人工促进讨论。本研究旨在探索LLM在多智能体系统中模拟决策会议并检测共识的潜力，以提高讨论效率和决策质量。", "method": "研究评估了六种不同的LLM在立场检测和立场极性检测任务上的表现，并将这些模型集成到多智能体系统中，以评估其在复杂模拟中的有效性。", "result": "结果表明，LLM能够在动态和微妙的辩论中可靠地检测共识。在系统中加入共识检测智能体可以提高小组辩论的效率和讨论的整体质量。", "conclusion": "这项研究展示了基于LLM的多智能体系统在模拟群体决策过程中的潜力，并表明这些系统可以在多个领域的专家研讨中支持决策制定。"}}
{"id": "2507.08468", "title": "Using Large Language Models for Legal Decision-Making in Austrian Value-Added Tax Law: An Experimental Study", "authors": ["Marina Luketina", "Andrea Benkel", "Christoph G. Schuetz"], "abstract": "This paper provides an experimental evaluation of the capability of large language models (LLMs) to assist in legal decision-making within the framework of Austrian and European Union value-added tax (VAT) law. In tax consulting practice, clients often describe cases in natural language, making LLMs a prime candidate for supporting automated decision-making and reducing the workload of tax professionals. Given the requirement for legally grounded and well-justified analyses, the propensity of LLMs to hallucinate presents a considerable challenge. The experiments focus on two common methods for enhancing LLM performance: fine-tuning and retrieval-augmented generation (RAG). In this study, these methods are applied on both textbook cases and real-world cases from a tax consulting firm to systematically determine the best configurations of LLM-based systems and assess the legal-reasoning capabilities of LLMs. The findings highlight the potential of using LLMs to support tax consultants by automating routine tasks and providing initial analyses, although current prototypes are not ready for full automation due to the sensitivity of the legal domain. The findings indicate that LLMs, when properly configured, can effectively support tax professionals in VAT tasks and provide legally grounded justifications for decisions. However, limitations remain regarding the handling of implicit client knowledge and context-specific documentation, underscoring the need for future integration of structured background information.", "subjects": "Computation and Language (cs.CL)", "comments": "26 pages, 5 figures, 6 tables", "pdf_url": "https://arxiv.org/pdf/2507.08468.pdf", "abstract_url": "https://arxiv.org/abs/2507.08468", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文通过实验评估了大型语言模型（LLMs）在奥地利和欧盟增值税（VAT）法律框架内辅助法律决策的能力。研究表明，适当配置的LLMs可以有效支持税务专业人士，并提供法律依据充分的决策理由，尽管当前原型因法律领域的敏感性尚不适合完全自动化。", "motivation": "解决税务咨询实践中客户常以自然语言描述案例，需要自动化决策支持以减少税务专业人员工作量的问题，同时应对LLMs在法律领域中可能产生的幻觉挑战。", "method": "研究采用两种常见方法提升LLM性能：微调（fine-tuning）和检索增强生成（RAG），并将这些方法应用于教科书案例和税务咨询公司的真实案例，以系统确定LLM基于系统的最佳配置并评估其法律推理能力。", "result": "发现LLMs在支持税务顾问自动化例行任务和提供初步分析方面具有潜力，但当前原型因处理隐含客户知识和特定上下文文档的限制，尚不适合完全自动化。", "conclusion": "LLMs在适当配置下可以有效支持税务专业人士完成VAT任务并提供法律依据充分的决策理由，但未来需要整合结构化背景信息以克服现有限制。"}}
{"id": "2507.08603", "title": "Unlocking Speech Instruction Data Potential with Query Rewriting", "authors": ["Yonghua Hei", "Yibo Yan", "Shuliang Liu", "Huiyu Zhou", "Linfeng Zhang", "Xuming Hu"], "abstract": "End-to-end Large Speech Language Models~(\\textbf{LSLMs}) demonstrate strong potential in response latency and speech comprehension capabilities, showcasing general intelligence across speech understanding tasks. However, the ability to follow speech instructions has not been fully realized due to the lack of datasets and heavily biased training tasks. Leveraging the rich ASR datasets, previous approaches have used Large Language Models~(\\textbf{LLMs}) to continue the linguistic information of speech to construct speech instruction datasets. Yet, due to the gap between LLM-generated results and real human responses, the continuation methods further amplify these shortcomings. Given the high costs of collecting and annotating speech instruction datasets by humans, using speech synthesis to construct large-scale speech instruction datasets has become a balanced and robust alternative. Although modern Text-To-Speech~(\\textbf{TTS}) models have achieved near-human-level synthesis quality, it is challenging to appropriately convert out-of-distribution text instruction to speech due to the limitations of the training data distribution in TTS models. To address this issue, we propose a query rewriting framework with multi-LLM knowledge fusion, employing multiple agents to annotate and validate the synthesized speech, making it possible to construct high-quality speech instruction datasets without relying on human annotation. Experiments show that this method can transform text instructions into distributions more suitable for TTS models for speech synthesis through zero-shot rewriting, increasing data usability from 72\\% to 93\\%. It also demonstrates unique advantages in rewriting tasks that require complex knowledge and context-related abilities.", "subjects": "Artificial Intelligence (cs.AI); Sound (cs.SD); Audio and Speech Processing (eess.AS)", "comments": "ACL 2025 Findings", "pdf_url": "https://arxiv.org/pdf/2507.08603.pdf", "abstract_url": "https://arxiv.org/abs/2507.08603", "categories": ["Artificial Intelligence (cs.AI)", "Sound (cs.SD)", "Audio and Speech Processing (eess.AS)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种利用查询重写框架和多LLM知识融合的方法，通过多智能体标注和验证合成语音，无需依赖人工标注即可构建高质量的语音指令数据集。实验表明，该方法能有效提升数据可用性。", "motivation": "解决由于缺乏数据集和训练任务偏差导致的语音指令跟随能力未充分发挥的问题，以及高质量语音指令数据集构建的高成本问题。", "method": "提出一个查询重写框架，结合多LLM知识融合，使用多智能体进行合成语音的标注和验证。", "result": "通过零样本重写将文本指令转换为更适合TTS模型语音合成的分布，数据可用性从72%提高到93%。", "conclusion": "该方法为构建高质量语音指令数据集提供了一种无需人工标注的平衡且稳健的替代方案，尤其在需要复杂知识和上下文相关能力的重写任务中展现出独特优势。"}}
{"id": "2507.08619", "title": "Agentic Large Language Models for Conceptual Systems Engineering and Design", "authors": ["Soheyl Massoudi", "Mark Fuge"], "abstract": "Early-stage engineering design involves complex, iterative reasoning, yet existing large language model (LLM) workflows struggle to maintain task continuity and generate executable models. We evaluate whether a structured multi-agent system (MAS) can more effectively manage requirements extraction, functional decomposition, and simulator code generation than a simpler two-agent system (2AS). The target application is a solar-powered water filtration system as described in a cahier des charges. We introduce the Design-State Graph (DSG), a JSON-serializable representation that bundles requirements, physical embodiments, and Python-based physics models into graph nodes. A nine-role MAS iteratively builds and refines the DSG, while the 2AS collapses the process to a Generator-Reflector loop. Both systems run a total of 60 experiments (2 LLMs - Llama 3.3 70B vs reasoning-distilled DeepSeek R1 70B x 2 agent configurations x 3 temperatures x 5 seeds). We report a JSON validity, requirement coverage, embodiment presence, code compatibility, workflow completion, runtime, and graph size. Across all runs, both MAS and 2AS maintained perfect JSON integrity and embodiment tagging. Requirement coverage remained minimal (less than 20\\%). Code compatibility peaked at 100\\% under specific 2AS settings but averaged below 50\\% for MAS. Only the reasoning-distilled model reliably flagged workflow completion. Powered by DeepSeek R1 70B, the MAS generated more granular DSGs (average 5-6 nodes) whereas 2AS mode-collapsed. Structured multi-agent orchestration enhanced design detail. Reasoning-distilled LLM improved completion rates, yet low requirements and fidelity gaps in coding persisted.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "32 pages, 3 figures", "pdf_url": "https://arxiv.org/pdf/2507.08619.pdf", "abstract_url": "https://arxiv.org/abs/2507.08619", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文评估了结构化多代理系统（MAS）与简单双代理系统（2AS）在早期工程设计中管理需求提取、功能分解和模拟器代码生成的有效性。通过设计状态图（DSG）作为JSON可序列化表示，研究发现MAS在生成更细粒度的DSG方面表现更好，但需求覆盖率和代码兼容性仍有待提高。", "motivation": "解决早期工程设计阶段中大型语言模型（LLM）工作流在保持任务连续性和生成可执行模型方面的困难。", "method": "引入设计状态图（DSG）作为JSON可序列化表示，比较九角色MAS与双代理系统（2AS）在太阳能水过滤系统设计中的表现。", "result": "MAS和2AS均保持了完美的JSON完整性和体现标记，但需求覆盖率低（小于20%）。代码兼容性在特定2AS设置下达到100%，但MAS平均低于50%。推理蒸馏模型可靠地标记了工作流完成。", "conclusion": "结构化多代理协调增强了设计细节，推理蒸馏LLM提高了完成率，但在需求和代码保真度方面仍存在差距。"}}
{"id": "2507.08705", "title": "elsciRL: Integrating Language Solutions into Reinforcement Learning Problem Settings", "authors": ["Philip Osborne", "Danilo S. Carvalho", "André Freitas"], "abstract": "We present elsciRL, an open-source Python library to facilitate the application of language solutions on reinforcement learning problems. We demonstrate the potential of our software by extending the Language Adapter with Self-Completing Instruction framework defined in (Osborne, 2024) with the use of LLMs. Our approach can be re-applied to new applications with minimal setup requirements. We provide a novel GUI that allows a user to provide text input for an LLM to generate instructions which it can then self-complete. Empirical results indicate that these instructions \\textit{can} improve a reinforcement learning agent's performance. Therefore, we present this work to accelerate the evaluation of language solutions on reward based environments to enable new opportunities for scientific discovery.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "6 pages, 1 figure, 3 tables, 11 Appendix pages, submitted to EMNLP 2025 Call for System Demonstrations", "pdf_url": "https://arxiv.org/pdf/2507.08705.pdf", "abstract_url": "https://arxiv.org/abs/2507.08705", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "elsciRL是一个开源的Python库，旨在将语言解决方案应用于强化学习问题。通过扩展Language Adapter with Self-Completing Instruction框架并结合LLMs的使用，展示了其潜力。提供了一个新颖的GUI，允许用户通过文本输入生成指令，进而自我完成。实证结果表明，这些指令可以提升强化学习代理的性能。", "motivation": "解决将语言解决方案有效整合到强化学习问题中的挑战，加速语言解决方案在基于奖励的环境中的评估，为科学发现开辟新机会。", "method": "扩展了Language Adapter with Self-Completing Instruction框架，利用LLMs生成并自我完成指令，提供了一个用户友好的GUI以简化操作。", "result": "实证结果表明，通过LLMs生成的指令能够提升强化学习代理的性能。", "conclusion": "elsciRL库通过简化语言解决方案在强化学习中的应用，为加速相关研究和科学发现提供了新的工具和可能性。"}}
{"id": "2507.08664", "title": "Introspection of Thought Helps AI Agents", "authors": ["Haoran Sun", "Shaoning Zeng"], "abstract": "AI Agents rely on Large Language Models (LLMs) and Multimodal-LLMs (MLLMs) to perform interpretation and inference in text and image tasks without post-training, where LLMs and MLLMs play the most critical role and determine the initial ability and limitations of AI Agents. Usually, AI Agents utilize sophisticated prompt engineering and external reasoning framework to obtain a promising interaction with LLMs, e.g., Chain-of-Thought, Iteration of Thought and Image-of-Thought. However, they are still constrained by the inherent limitations of LLM in understanding natural language, and the iterative reasoning process will generate a large amount of inference cost. To this end, we propose a novel AI Agent Reasoning Framework with Introspection of Thought (INoT) by designing a new LLM-Read code in prompt. It enables LLM to execute programmatic dialogue reasoning processes following the code in prompt. Therefore, self-denial and reflection occur within LLM instead of outside LLM, which can reduce token cost effectively. Through our experiments on six benchmarks for three different tasks, the effectiveness of INoT is verified, with an average improvement of 7.95\\% in performance, exceeding the baselines. Furthermore, the token cost of INoT is lower on average than the best performing method at baseline by 58.3\\%. In addition, we demonstrate the versatility of INoT in image interpretation and inference through verification experiments.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.08664.pdf", "abstract_url": "https://arxiv.org/abs/2507.08664", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新型的AI代理推理框架INoT，通过设计新的LLM-Read代码提示，使LLM能够按照提示中的代码执行程序化对话推理过程，从而在LLM内部实现自我否定和反思，有效降低令牌成本。", "motivation": "AI代理依赖大型语言模型（LLMs）和多模态LLMs（MLLMs）在文本和图像任务中进行解释和推理，但受限于LLMs在理解自然语言方面的固有局限性，且迭代推理过程会产生大量推理成本。", "method": "设计了INoT框架，通过在提示中引入LLM-Read代码，使LLM能够执行程序化对话推理过程，实现内部自我否定和反思。", "result": "在六个基准测试中，INoT的平均性能提高了7.95%，令牌成本比基线最佳方法平均降低了58.3%，并在图像解释和推理中展示了其多功能性。", "conclusion": "INoT框架通过内部反思机制有效提升了AI代理的性能并降低了成本，展示了在多种任务中的广泛应用潜力。"}}
{"id": "2507.08432", "title": "xpSHACL: Explainable SHACL Validation using Retrieval-Augmented Generation and Large Language Models", "authors": ["Gustavo Correa Publio", "José Emilio Labra Gayo"], "abstract": "Shapes Constraint Language (SHACL) is a powerful language for validating RDF data. Given the recent industry attention to Knowledge Graphs (KGs), more users need to validate linked data properly. However, traditional SHACL validation engines often provide terse reports in English that are difficult for non-technical users to interpret and act upon. This paper presents xpSHACL, an explainable SHACL validation system that addresses this issue by combining rule-based justification trees with retrieval-augmented generation (RAG) and large language models (LLMs) to produce detailed, multilanguage, human-readable explanations for constraint violations. A key feature of xpSHACL is its usage of a Violation KG to cache and reuse explanations, improving efficiency and consistency.", "subjects": "Databases (cs.DB); Computation and Language (cs.CL)", "comments": "Accepted for publication in the 2nd LLM+Graph Workshop, colocated at VLDB'25", "pdf_url": "https://arxiv.org/pdf/2507.08432.pdf", "abstract_url": "https://arxiv.org/abs/2507.08432", "categories": ["Databases (cs.DB)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "xpSHACL是一个可解释的SHACL验证系统，通过结合规则基础的证明树、检索增强生成（RAG）和大语言模型（LLMs），为约束违规提供详细、多语言、人类可读的解释。", "motivation": "传统的SHACL验证引擎提供的英文报告简洁，非技术用户难以理解和采取行动。xpSHACL旨在解决这一问题，使链接数据的验证更加易于理解和操作。", "method": "xpSHACL结合了规则基础的证明树、检索增强生成（RAG）和大语言模型（LLMs），并利用违规知识图谱（Violation KG）来缓存和重用解释，以提高效率和一致性。", "result": "xpSHACL能够生成详细、多语言、人类可读的约束违规解释，提高了非技术用户对SHACL验证结果的理解和操作能力。", "conclusion": "xpSHACL通过创新的方法提高了SHACL验证的可解释性和用户体验，为知识图谱的广泛应用提供了支持。"}}
{"id": "2507.08610", "title": "Emergent Natural Language with Communication Games for Improving Image Captioning Capabilities without Additional Data", "authors": ["Parag Dutta", "Ambedkar Dukkipati"], "abstract": "Image captioning is an important problem in developing various AI systems, and these tasks require large volumes of annotated images to train the models. Since all existing labelled datasets are already used for training the large Vision Language Models (VLMs), it becomes challenging to improve the performance of the same. Considering this, it is essential to consider the unsupervised image captioning performance, which remains relatively under-explored. To that end, we propose LoGIC (Lewis Communication Game for Image Captioning), a Multi-agent Reinforcement Learning game. The proposed method consists of two agents, a 'speaker' and a 'listener', with the objective of learning a strategy for communicating in natural language. We train agents in the cooperative common-reward setting using the GRPO algorithm and show that improvement in image captioning performance emerges as a consequence of the agents learning to play the game. We show that using pre-trained VLMs as the 'speaker' and Large Language Model (LLM) for language understanding in the 'listener', we achieved a $46$ BLEU score after fine-tuning using LoGIC without additional labels, a $2$ units advantage in absolute metrics compared to the $44$ BLEU score of the vanilla VLM. Additionally, we replace the VLM from the 'speaker' with lightweight components: (i) a ViT for image perception and (ii) a GPT2 language generation, and train them from scratch using LoGIC, obtaining a $31$ BLEU score in the unsupervised setting, a $10$ points advantage over existing unsupervised image-captioning methods.", "subjects": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.08610.pdf", "abstract_url": "https://arxiv.org/abs/2507.08610", "categories": ["Machine Learning (cs.LG)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为LoGIC的多智能体强化学习游戏，旨在不依赖额外标注数据的情况下提升图像描述生成能力。通过训练‘说话者’和‘听者’两个智能体在合作共同奖励设置下进行自然语言交流，该方法在图像描述任务上取得了显著提升。", "motivation": "图像描述是开发各种AI系统的重要问题，但这些任务需要大量标注图像来训练模型。考虑到所有现有的标注数据集已被用于训练大型视觉语言模型（VLMs），提升这些模型的性能变得具有挑战性。因此，探索无监督图像描述性能变得尤为重要。", "method": "提出了LoGIC（Lewis Communication Game for Image Captioning），一种多智能体强化学习游戏，包括一个‘说话者’和一个‘听者’两个智能体，目的是学习自然语言交流策略。使用GRPO算法在合作共同奖励设置下训练智能体。", "result": "使用预训练的VLMs作为‘说话者’和大型语言模型（LLM）作为‘听者’，在不需要额外标注的情况下，通过LoGIC微调后获得了46 BLEU分数，比原始VLM的44 BLEU分数高出2个单位。此外，用轻量级组件替换‘说话者’中的VLM，在无监督设置下获得了31 BLEU分数，比现有无监督图像描述方法高出10分。", "conclusion": "LoGIC方法在不依赖额外标注数据的情况下，通过多智能体强化学习游戏显著提升了图像描述的性能，为无监督图像描述任务提供了新的解决方案。"}}
{"id": "2507.08164", "title": "KP-A: A Unified Network Knowledge Plane for Catalyzing Agentic Network Intelligence", "authors": ["Yun Tang", "Mengbang Zou", "Zeinab Nezami", "Syed Ali Raza Zaidi", "Weisi Guo"], "abstract": "The emergence of large language models (LLMs) and agentic systems is enabling autonomous 6G networks with advanced intelligence, including self-configuration, self-optimization, and self-healing. However, the current implementation of individual intelligence tasks necessitates isolated knowledge retrieval pipelines, resulting in redundant data flows and inconsistent interpretations. Inspired by the service model unification effort in Open-RAN (to support interoperability and vendor diversity), we propose KP-A: a unified Network Knowledge Plane specifically designed for Agentic network intelligence. By decoupling network knowledge acquisition and management from intelligence logic, KP-A streamlines development and reduces maintenance complexity for intelligence engineers. By offering an intuitive and consistent knowledge interface, KP-A also enhances interoperability for the network intelligence agents. We demonstrate KP-A in two representative intelligence tasks: live network knowledge Q&A and edge AI service orchestration. All implementation artifacts have been open-sourced to support reproducibility and future standardization efforts.", "subjects": "Networking and Internet Architecture (cs.NI); Artificial Intelligence (cs.AI); Software Engineering (cs.SE)", "comments": "7 pages, 5 figures, submitted for possible publication", "pdf_url": "https://arxiv.org/pdf/2507.08164.pdf", "abstract_url": "https://arxiv.org/abs/2507.08164", "categories": ["Networking and Internet Architecture (cs.NI)", "Artificial Intelligence (cs.AI)", "Software Engineering (cs.SE)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了KP-A：一个统一的网络知识平面，旨在为代理网络智能提供支持。通过将网络知识获取和管理与智能逻辑解耦，KP-A简化了开发并降低了智能工程师的维护复杂性。KP-A还通过提供直观且一致的知识接口，增强了网络智能代理的互操作性。", "motivation": "当前，大型语言模型（LLMs）和代理系统的出现使得6G网络能够实现自主网络智能，包括自我配置、自我优化和自我修复。然而，当前个别智能任务的实现需要孤立的知识检索管道，导致数据流冗余和解释不一致。", "method": "受Open-RAN中服务模型统一努力的启发，提出了KP-A：一个专门为代理网络智能设计的统一网络知识平面。通过将网络知识获取和管理与智能逻辑解耦，KP-A简化了开发并降低了维护复杂性。", "result": "KP-A在两个代表性的智能任务中进行了演示：实时网络知识问答和边缘AI服务编排。所有实现工件均已开源，以支持可重复性和未来的标准化工作。", "conclusion": "KP-A通过提供一个统一的网络知识平面，不仅简化了代理网络智能的开发，还通过增强互操作性，为未来的网络智能标准化工作奠定了基础。"}}
{"id": "2507.08445", "title": "CUE-RAG: Towards Accurate and Cost-Efficient Graph-Based RAG via Multi-Partite Graph and Query-Driven Iterative Retrieval", "authors": ["Yaodong Su", "Yixiang Fang", "Yingli Zhou", "Quanqing Xu", "Chuanhui Yang"], "abstract": "Despite the remarkable progress of Large Language Models (LLMs), their performance in question answering (QA) remains limited by the lack of domain-specific and up-to-date knowledge. Retrieval-Augmented Generation (RAG) addresses this limitation by incorporating external information, often from graph-structured data. However, existing graph-based RAG methods suffer from poor graph quality due to incomplete extraction and insufficient utilization of query information during retrieval. To overcome these limitations, we propose CUE-RAG, a novel approach that introduces (1) a multi-partite graph index incorporates text Chunks, knowledge Units, and Entities to capture semantic content at multiple levels of granularity, (2) a hybrid extraction strategy that reduces LLM token usage while still producing accurate and disambiguated knowledge units, and (3) Q-Iter, a query-driven iterative retrieval strategy that enhances relevance through semantic search and constrained graph traversal. Experiments on three QA benchmarks show that CUE-RAG significantly outperforms state-of-the-art baselines, achieving up to 99.33% higher Accuracy and 113.51% higher F1 score while reducing indexing costs by 72.58%. Remarkably, CUE-RAG matches or outperforms baselines even without using an LLM for indexing. These results demonstrate the effectiveness and cost-efficiency of CUE-RAG in advancing graph-based RAG systems.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.08445.pdf", "abstract_url": "https://arxiv.org/abs/2507.08445", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "CUE-RAG是一种新颖的图基RAG方法，通过多部图索引和查询驱动的迭代检索策略，提高了问答系统的准确性和成本效率。", "motivation": "解决大型语言模型在问答任务中因缺乏领域特定和最新知识而表现受限的问题，以及现有图基RAG方法在图质量和查询信息利用上的不足。", "method": "引入多部图索引（包含文本块、知识单元和实体）、混合提取策略减少LLM令牌使用，以及查询驱动的迭代检索策略（Q-Iter）。", "result": "在三个QA基准测试中，CUE-RAG显著优于现有基线，准确率和F1分数分别提高至99.33%和113.51%，同时降低索引成本72.58%。", "conclusion": "CUE-RAG在提高图基RAG系统的有效性和成本效率方面显示出显著优势，即使不使用LLM进行索引也能匹配或超越基线性能。"}}
{"id": "2507.08584", "title": "To Trade or Not to Trade: An Agentic Approach to Estimating Market Risk Improves Trading Decisions", "authors": ["Dimitrios Emmanoulopoulos", "Ollie Olby", "Justin Lyon", "Namid R. Stillman"], "abstract": "Large language models (LLMs) are increasingly deployed in agentic frameworks, in which prompts trigger complex tool-based analysis in pursuit of a goal. While these frameworks have shown promise across multiple domains including in finance, they typically lack a principled model-building step, relying instead on sentiment- or trend-based analysis. We address this gap by developing an agentic system that uses LLMs to iteratively discover stochastic differential equations for financial time series. These models generate risk metrics which inform daily trading decisions. We evaluate our system in both traditional backtests and using a market simulator, which introduces synthetic but causally plausible price paths and news events. We find that model-informed trading strategies outperform standard LLM-based agents, improving Sharpe ratios across multiple equities. Our results show that combining LLMs with agentic model discovery enhances market risk estimation and enables more profitable trading decisions.", "subjects": "Statistical Finance (q-fin.ST); Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Multiagent Systems (cs.MA); Computational Finance (q-fin.CP)", "comments": "31 pages, 7 figures, 3 tables", "pdf_url": "https://arxiv.org/pdf/2507.08584.pdf", "abstract_url": "https://arxiv.org/abs/2507.08584", "categories": ["Statistical Finance (q-fin.ST)", "Artificial Intelligence (cs.AI)", "Computational Engineering, Finance, and Science (cs.CE)", "Multiagent Systems (cs.MA)", "Computational Finance (q-fin.CP)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种基于大型语言模型（LLMs）的代理系统，用于通过迭代发现金融时间序列的随机微分方程来改进交易决策。该系统通过生成风险指标来指导日常交易，并在传统回测和市场模拟器中评估表现，结果显示模型 informed 的交易策略优于标准的基于LLM的代理，提高了多只股票的夏普比率。", "motivation": "解决现有基于大型语言模型的代理框架在金融领域中缺乏原则性模型构建步骤的问题，这些框架通常依赖于情感或趋势分析。", "method": "开发了一个代理系统，该系统使用LLMs迭代发现金融时间序列的随机微分方程，生成风险指标以指导交易决策，并在传统回测和市场模拟器中评估策略表现。", "result": "模型 informed 的交易策略在多个股票中提高了夏普比率，显示出优于标准的基于LLM的代理策略的表现。", "conclusion": "将LLMs与代理模型发现相结合，可以增强市场风险估计，并实现更有利可图的交易决策。"}}
{"id": "2507.08653", "title": "Safe Deep Reinforcement Learning for Resource Allocation with Peak Age of Information Violation Guarantees", "authors": ["Berire Gunes Reyhan", "Sinem Coleri"], "abstract": "In Wireless Networked Control Systems (WNCSs), control and communication systems must be co-designed due to their strong interdependence. This paper presents a novel optimization theory-based safe deep reinforcement learning (DRL) framework for ultra-reliable WNCSs, ensuring constraint satisfaction while optimizing performance, for the first time in the literature. The approach minimizes power consumption under key constraints, including Peak Age of Information (PAoI) violation probability, transmit power, and schedulability in the finite blocklength regime. PAoI violation probability is uniquely derived by combining stochastic maximum allowable transfer interval (MATI) and maximum allowable packet delay (MAD) constraints in a multi-sensor network. The framework consists of two stages: optimization theory and safe DRL. The first stage derives optimality conditions to establish mathematical relationships among variables, simplifying and decomposing the problem. The second stage employs a safe DRL model where a teacher-student framework guides the DRL agent (student). The control mechanism (teacher) evaluates compliance with system constraints and suggests the nearest feasible action when needed. Extensive simulations show that the proposed framework outperforms rule-based and other optimization theory based DRL benchmarks, achieving faster convergence, higher rewards, and greater stability.", "subjects": "Signal Processing (eess.SP); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multiagent Systems (cs.MA)", "comments": "15 Pages, to be published in IEEE Transactions on Communications", "pdf_url": "https://arxiv.org/pdf/2507.08653.pdf", "abstract_url": "https://arxiv.org/abs/2507.08653", "categories": ["Signal Processing (eess.SP)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于优化理论的安全深度强化学习（DRL）框架，用于无线网络控制系统（WNCSs）中的资源分配，首次在文献中确保了约束满足的同时优化性能。", "motivation": "解决无线网络控制系统中控制和通信系统必须共同设计的问题，确保在满足关键约束（如峰值信息年龄（PAoI）违反概率、发射功率和有限块长度制度下的可调度性）的同时优化性能。", "method": "采用两阶段方法：第一阶段利用优化理论推导最优性条件，建立变量间的数学关系，简化和分解问题；第二阶段采用安全DRL模型，其中教师-学生框架指导DRL代理（学生），控制机制（教师）评估系统约束的遵守情况并在需要时建议最近的可行行动。", "result": "广泛的模拟显示，所提出的框架优于基于规则和其他基于优化理论的DRL基准，实现了更快的收敛、更高的奖励和更大的稳定性。", "conclusion": "该框架为超可靠的WNCSs提供了一种新颖的资源分配方法，首次在满足约束的同时优化性能，为未来的研究和应用提供了有价值的参考。"}}
