{"id": "2506.22554", "title": "Seamless Interaction: Dyadic Audiovisual Motion Modeling and Large-Scale Dataset", "authors": ["Vasu Agrawal", "Akinniyi Akinyemi", "Kathryn Alvero", "Morteza Behrooz", "Julia Buffalini", "Fabio Maria Carlucci", "Joy Chen", "Junming Chen", "Zhang Chen", "Shiyang Cheng", "Praveen Chowdary", "Joe Chuang", "Antony D'Avirro", "Jon Daly", "Ning Dong", "Mark Duppenthaler", "Cynthia Gao", "Jeff Girard", "Martin Gleize", "Sahir Gomez", "Hongyu Gong", "Srivathsan Govindarajan", "Brandon Han", "Sen He", "Denise Hernandez", "Yordan Hristov", "Rongjie Huang", "Hirofumi Inaguma", "Somya Jain", "Raj Janardhan", "Qingyao Jia", "Christopher Klaiber", "Dejan Kovachev", "Moneish Kumar", "Hang Li", "Yilei Li", "Pavel Litvin", "Wei Liu", "Guangyao Ma", "Jing Ma", "Martin Ma", "Xutai Ma", "Lucas Mantovani", "Sagar Miglani", "Sreyas Mohan", "Louis-Philippe Morency", "Evonne Ng", "Kam-Woh Ng", "Tu Anh Nguyen", "Amia Oberai", "Benjamin Peloquin", "Juan Pino", "Jovan Popovic", "Omid Poursaeed", "Fabian Prada", "Alice Rakotoarison", "Alexander Richard", "Christophe Ropers", "Safiyyah Saleem", "Vasu Sharma", "Alex Shcherbyna", "Jia Shen", "Jie Shen", "Anastasis Stathopoulos", "Anna Sun", "Paden Tomasello", "Tuan Tran", "Arina Turkatenko", "Bo Wan", "Chao Wang", "Jeff Wang", "Mary Williamson", "Carleigh Wood", "Tao Xiang", "Yilin Yang", "Julien Yao", "Chen Zhang", "Jiemin Zhang", "Xinyue Zhang", "Jason Zheng", "Pavlo Zhyzheria", "Jan Zikes", "Michael Zollhoefer"], "abstract": "Human communication involves a complex interplay of verbal and nonverbal signals, essential for conveying meaning and achieving interpersonal goals. To develop socially intelligent AI technologies, it is crucial to develop models that can both comprehend and generate dyadic behavioral dynamics. To this end, we introduce the Seamless Interaction Dataset, a large-scale collection of over 4,000 hours of face-to-face interaction footage from over 4,000 participants in diverse contexts. This dataset enables the development of AI technologies that understand dyadic embodied dynamics, unlocking breakthroughs in virtual agents, telepresence experiences, and multimodal content analysis tools. We also develop a suite of models that utilize the dataset to generate dyadic motion gestures and facial expressions aligned with human speech. These models can take as input both the speech and visual behavior of their interlocutors. We present a variant with speech from an LLM model and integrations with 2D and 3D rendering methods, bringing us closer to interactive virtual agents. Additionally, we describe controllable variants of our motion models that can adapt emotional responses and expressivity levels, as well as generating more semantically-relevant gestures. Finally, we discuss methods for assessing the quality of these dyadic motion models, which are demonstrating the potential for more intuitive and responsive human-AI interactions.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.22554.pdf", "abstract_url": "https://arxiv.org/abs/2506.22554", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了无缝交互数据集，一个大规模的面对面互动视频集合，用于开发能够理解和生成双向行为动态的AI技术。", "motivation": "开发能够理解和生成双向行为动态的模型，以推动社交智能AI技术的发展。", "method": "收集了超过4,000小时的面对面互动视频，开发了一套模型来生成与人类语音对齐的双向运动手势和面部表情。", "result": "开发了能够根据对话者的语音和视觉行为生成相应手势和表情的模型，并展示了与LLM模型语音和2D、3D渲染方法的集成。", "conclusion": "这些双向运动模型展示了更直观和响应式的人机交互潜力，为虚拟代理、远程呈现体验和多模态内容分析工具的开发提供了突破。"}}
{"id": "2506.22508", "title": "AgentStealth: Reinforcing Large Language Model for Anonymizing User-generated Text", "authors": ["Chenyang Shao", "Tianxing Li", "Chenhao Pu", "Fengli Xu", "Yong Li"], "abstract": "In today's digital world, casual user-generated content often contains subtle cues that may inadvertently expose sensitive personal attributes. Such risks underscore the growing importance of effective text anonymization to safeguard individual privacy. However, existing methods either rely on rigid replacements that damage utility or cloud-based LLMs that are costly and pose privacy risks. To address these issues, we explore the use of locally deployed smaller-scale language models (SLMs) for anonymization. Yet training effective SLMs remains challenging due to limited high-quality supervision. To address the challenge, we propose AgentStealth, a self-reinforcing LLM anonymization", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "This work has been submitted to NeurIPS 2025. Under review", "pdf_url": "https://arxiv.org/pdf/2506.22508.pdf", "abstract_url": "https://arxiv.org/abs/2506.22508", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出AgentStealth，一种通过自我强化的本地部署小规模语言模型（SLMs）来匿名化用户生成文本的方法，以解决现有方法在保护隐私和保持文本效用之间的平衡问题。", "motivation": "在数字世界中，用户生成的内容可能无意中暴露敏感个人信息，现有匿名化方法要么损害文本效用，要么依赖成本高且存在隐私风险的云基础大型语言模型（LLMs）。", "method": "使用本地部署的小规模语言模型（SLMs）进行文本匿名化，并通过AgentStealth方法自我强化训练这些模型，以克服高质量监督数据有限的挑战。", "result": "AgentStealth方法能够有效匿名化用户生成文本，同时保持文本的效用，解决了现有方法的局限。", "conclusion": "AgentStealth为文本匿名化提供了一种既保护隐私又保持文本效用的可行方案，特别是在资源有限的情况下，展示了本地部署SLMs的潜力。"}}
{"id": "2506.22485", "title": "AI Agents-as-Judge: Automated Assessment of Accuracy, Consistency, Completeness and Clarity for Enterprise Documents", "authors": ["Sudip Dasgupta", "Himanshu Shankar"], "abstract": "This study presents a modular, multi-agent system for the automated review of highly structured enterprise business documents using AI agents. Unlike prior solutions focused on unstructured texts or limited compliance checks, this framework leverages modern orchestration tools such as LangChain, CrewAI, TruLens, and Guidance to enable section-by-section evaluation of documents for accuracy, consistency, completeness, and clarity. Specialized agents, each responsible for discrete review criteria such as template compliance or factual correctness, operate in parallel or sequence as required. Evaluation outputs are enforced to a standardized, machine-readable schema, supporting downstream analytics and auditability. Continuous monitoring and a feedback loop with human reviewers allow for iterative system improvement and bias mitigation.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "17 pages, 2 system diagrams, 1 table, no prior conference publication", "pdf_url": "https://arxiv.org/pdf/2506.22485.pdf", "abstract_url": "https://arxiv.org/abs/2506.22485", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本研究提出了一种模块化、多代理系统，用于利用AI代理自动审查高度结构化的企业业务文档。与之前专注于非结构化文本或有限合规性检查的解决方案不同，该框架利用现代编排工具，如LangChain、CrewAI、TruLens和Guidance，实现对文档准确性、一致性、完整性和清晰性的逐部分评估。", "motivation": "解决企业业务文档审查中的自动化问题，提高审查的效率和准确性，同时支持下游分析和审计。", "method": "采用模块化、多代理系统，利用现代编排工具实现文档的逐部分评估，每个代理负责不同的审查标准，如模板合规性或事实正确性。", "result": "开发了一个能够自动评估企业文档准确性、一致性、完整性和清晰性的系统，支持标准化、机器可读的输出，便于下游分析和审计。", "conclusion": "该系统通过持续监控和与人类审查者的反馈循环，实现了系统的迭代改进和偏见缓解，为企业文档审查提供了高效、准确的自动化解决方案。"}}
{"id": "2506.22598", "title": "RExBench: Can coding agents autonomously implement AI research extensions?", "authors": ["Nicholas Edwards", "Yukyung Lee", "Yujun", "Yulu Qin", "Sebastian Schuster", "Najoung Kim"], "abstract": "Agents based on Large Language Models (LLMs) have shown promise for performing sophisticated software engineering tasks autonomously. In addition, there has been progress towards developing agents that can perform parts of the research pipeline in machine learning and the natural sciences. We argue that research extension and its implementation is a critical capability for such systems, and introduce RExBench to support the evaluation of this capability. RExBench is a benchmark consisting of 12 realistic research experiment implementation tasks that aim to investigate research hypotheses that have not previously been implemented. Each task is set up as an extension to an existing research paper and codebase, accompanied by domain expert-written instructions. RExBench is robust to data contamination, and supports an automatic evaluation infrastructure that executes agent outputs to determine whether the success criteria are met. We use this benchmark to evaluate nine LLM agents implemented using three different frameworks: aider, Claude Code, and OpenHands. We find that all agents evaluated fail to autonomously implement the majority of the extensions. Although the success rate improves with additional human-written hints, the best performance under this setting remains below 40%. This indicates that current agents are still short of being able to handle realistic research extension tasks without substantial human guidance.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.22598.pdf", "abstract_url": "https://arxiv.org/abs/2506.22598", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "RExBench是一个评估编码代理自主实现AI研究扩展能力的基准，包含12个未实现的研究假设任务。评估显示，当前基于LLM的代理在无大量人类指导的情况下，难以自主完成大多数扩展任务。", "motivation": "解决基于大型语言模型（LLMs）的代理在自主执行机器学习研究扩展及其实现方面的能力评估问题。", "method": "引入RExBench基准，包含12个真实的研究实验实现任务，支持自动评估基础设施来执行代理输出以确定是否满足成功标准。", "result": "评估的九个LLM代理中，没有一个能够自主实现大多数扩展任务。即使在提供额外人类编写的提示后，最佳成功率仍低于40%。", "conclusion": "当前代理在无大量人类指导的情况下，尚无法处理真实的研究扩展任务，显示出在这一领域仍需进一步发展和改进。"}}
{"id": "2506.22518", "title": "Weak-to-Strong GraphRAG: Aligning Weak Retrievers with Large Language Models for Graph-based Retrieval Augmented Generation", "authors": ["Deyu Zou", "Yongqiang Chen", "Mufei Li", "Siqi Miao", "Chenxi Liu", "Bo Han", "James Cheng", "Pan Li"], "abstract": "Graph-based retrieval-augmented generation (RAG) enables large language models (LLMs) to ground responses with structured external knowledge from up-to-date knowledge graphs (KGs) and reduce hallucinations. However, LLMs often rely on a weak retriever in graph-based RAG: I) Due to the lack of ground truth, the retriever is often trained on weak supervision, which often introduces spurious signals to the LLMs. II) Due to the abstraction of graph data, the retrieved knowledge is often presented in unorganized forms. To mitigate the issue, we present Refined Graph-based RAG (ReG) to align weak retrievers to LLMs for graph-based RAG. Specifically, ReG incorporates LLM feedback to get rid of spurious signals and improve the quality of the supervision. Meanwhile, ReG introduces a structure-aware reorganization module to refactor the retrieval results into logically coherent evidence chains. Experiments on prominent benchmarks demonstrate that ReG significantly and consistently brings improvements across different LLM backbones by up to 10%. The improved supervision quality enables ReG to match the state-of-the-art performance with 5% training data and to transfer to out-of-distribution KGs. Notably, when adopted to reasoning-based LLMs, ReG reduces the reasoning token cost by up to 30% and improves the performance by up to 4%.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.22518.pdf", "abstract_url": "https://arxiv.org/abs/2506.22518", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了Refined Graph-based RAG (ReG)方法，通过将弱检索器与大型语言模型(LLMs)对齐，解决了图基检索增强生成(RAG)中因弱监督和图形数据抽象导致的问题。ReG利用LLM反馈消除虚假信号并提升监督质量，同时引入结构感知重组模块优化检索结果。实验显示，ReG在不同LLM骨架上实现了高达10%的性能提升，并在仅使用5%训练数据时达到最先进水平，还能适应分布外知识图谱。此外，ReG在推理型LLMs中减少了高达30%的推理令牌成本并提升性能4%。", "motivation": "解决图基检索增强生成(RAG)中因弱监督训练和图形数据抽象导致的虚假信号引入和检索知识呈现无组织的问题。", "method": "提出Refined Graph-based RAG (ReG)方法，通过LLM反馈消除虚假信号并提升监督质量，引入结构感知重组模块优化检索结果。", "result": "ReG在不同LLM骨架上实现了高达10%的性能提升，使用5%训练数据时达到最先进水平，适应分布外知识图谱，减少推理型LLMs的推理令牌成本高达30%并提升性能4%。", "conclusion": "ReG通过对齐弱检索器与LLMs，有效提升了图基RAG的性能和效率，为处理结构化外部知识提供了新方向。"}}
{"id": "2506.22644", "title": "Evaluating Hybrid Retrieval Augmented Generation using Dynamic Test Sets: LiveRAG Challenge", "authors": ["Chase Fensore", "Kaustubh Dhole", "Joyce C Ho", "Eugene Agichtein"], "abstract": "We present our submission to the LiveRAG Challenge 2025, which evaluates retrieval-augmented generation (RAG) systems on dynamic test sets using the FineWeb-10BT corpus. Our final hybrid approach combines sparse (BM25) and dense (E5) retrieval methods and then aims to generate relevant and faithful answers with Falcon3-10B-Instruct. Through systematic evaluation on 200 synthetic questions generated with DataMorgana across 64 unique question-user combinations, we demonstrate that neural re-ranking with RankLLaMA improves MAP from 0.523 to 0.797 (52% relative improvement) but introduces prohibitive computational costs (84s vs 1.74s per question). While DSPy-optimized prompting strategies achieved higher semantic similarity (0.771 vs 0.668), their 0% refusal rates raised concerns about over-confidence and generalizability. Our submitted hybrid system without re-ranking achieved 4th place in faithfulness and 11th place in correctness among 25 teams. Analysis across question categories reveals that vocabulary alignment between questions and documents was the strongest predictor of performance on our development set, with document-similar phrasing improving cosine similarity from 0.562 to 0.762.", "subjects": "Computation and Language (cs.CL); Information Retrieval (cs.IR)", "comments": "4 pages, 3 tables, 2 figures. Accepted at the SIGIR LiveRAG Workshop 2025 (Submission 2664)", "pdf_url": "https://arxiv.org/pdf/2506.22644.pdf", "abstract_url": "https://arxiv.org/abs/2506.22644", "categories": ["Computation and Language (cs.CL)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了参加LiveRAG Challenge 2025的提交，评估了在动态测试集上使用FineWeb-10BT语料库的检索增强生成（RAG）系统。通过结合稀疏（BM25）和密集（E5）检索方法的混合方法，使用Falcon3-10B-Instruct生成相关且忠实的答案。", "motivation": "解决检索增强生成系统在动态测试集上的评估问题，特别是在提高答案的相关性和忠实度方面的挑战。", "method": "采用稀疏（BM25）和密集（E5）检索方法的混合方法，结合Falcon3-10B-Instruct生成答案，并通过RankLLaMA进行神经重排序。", "result": "神经重排序将MAP从0.523提高到0.797（相对提高52%），但增加了计算成本（84秒 vs 1.74秒每问题）。DSPy优化的提示策略实现了更高的语义相似度（0.771 vs 0.668），但拒绝率为0%引发了对过度自信和泛化能力的担忧。", "conclusion": "混合系统在没有重排序的情况下，在忠实度和正确性方面分别获得第4和第11名。问题与文档之间的词汇对齐是开发集上性能的最强预测因素。"}}
{"id": "2506.22609", "title": "Ludax: A GPU-Accelerated Domain Specific Language for Board Games", "authors": ["Graham Todd", "Alexander G. Padula", "Dennis J.N.J. Soemers", "Julian Togelius"], "abstract": "Games have long been used as benchmarks and testing environments for research in artificial intelligence. A key step in supporting this research was the development of game description languages: frameworks that compile domain-specific code into playable and simulatable game environments, allowing researchers to generalize their algorithms and approaches across multiple games without having to manually implement each one. More recently, progress in reinforcement learning (RL) has been largely driven by advances in hardware acceleration. Libraries like JAX allow practitioners to take full advantage of cutting-edge computing hardware, often speeding up training and testing by orders of magnitude. Here, we present a synthesis of these strands of research: a domain-specific language for board games which automatically compiles into hardware-accelerated code. Our framework, Ludax, combines the generality of game description languages with the speed of modern parallel processing hardware and is designed to fit neatly into existing deep learning pipelines. We envision Ludax as a tool to help accelerate games research generally, from RL to cognitive science, by enabling rapid simulation and providing a flexible representation scheme. We present a detailed breakdown of Ludax's description language and technical notes on the compilation process, along with speed benchmarking and a demonstration of training RL agents. The Ludax framework, along with implementations of existing board games, is open-source and freely available.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "18 pages, 3 figures", "pdf_url": "https://arxiv.org/pdf/2506.22609.pdf", "abstract_url": "https://arxiv.org/abs/2506.22609", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "Ludax是一个专为棋盘游戏设计的GPU加速领域特定语言，旨在通过自动编译成硬件加速代码来加速游戏研究，特别是在强化学习和认知科学领域。", "motivation": "为了解决游戏研究中手动实现每种游戏环境的繁琐问题，并利用现代并行处理硬件加速研究过程。", "method": "开发了一个名为Ludax的领域特定语言，该语言能够自动编译成硬件加速代码，并结合了游戏描述语言的通用性和现代并行处理硬件的速度。", "result": "Ludax框架成功实现了快速模拟和灵活的表示方案，加速了游戏研究，包括强化学习代理的训练。", "conclusion": "Ludax作为一个开源工具，有望加速从强化学习到认知科学等多个领域的游戏研究，通过提供快速的模拟和灵活的表示方案。"}}
{"id": "2506.22653", "title": "URSA: The Universal Research and Scientific Agent", "authors": ["Michael Grosskopf", "Russell Bent", "Rahul Somasundaram", "Isaac Michaud", "Arthur Lui", "Nathan Debardeleben", "Earl Lawrence"], "abstract": "Large language models (LLMs) have moved far beyond their initial form as simple chatbots, now carrying out complex reasoning, planning, writing, coding, and research tasks. These skills overlap significantly with those that human scientists use day-to-day to solve complex problems that drive the cutting edge of research. Using LLMs in \"agentic\" AI has the potential to revolutionize modern science and remove bottlenecks to progress. In this work, we present URSA, a scientific agent ecosystem for accelerating research tasks. URSA consists of a set of modular agents and tools, including coupling to advanced physics simulation codes, that can be combined to address scientific problems of varied complexity and impact. This work highlights the architecture of URSA, as well as examples that highlight the potential of the system.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "31 pages, 9 figures", "pdf_url": "https://arxiv.org/pdf/2506.22653.pdf", "abstract_url": "https://arxiv.org/abs/2506.22653", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "URSA是一个旨在加速科研任务的科学代理生态系统，它通过模块化代理和工具的结合，包括与高级物理模拟代码的耦合，来解决不同复杂性和影响力的科学问题。", "motivation": "利用大型语言模型（LLMs）在“代理”AI中的潜力，解决现代科学研究中的瓶颈问题，推动科研进步。", "method": "开发了一个名为URSA的科学代理生态系统，包含一组模块化代理和工具，能够结合高级物理模拟代码，以解决各种科学问题。", "result": "展示了URSA的架构及其在解决复杂科学问题中的潜力，突出了系统在加速科研任务方面的能力。", "conclusion": "URSA作为一个科学代理生态系统，有潜力通过利用LLMs和模块化工具的结合，显著加速科研进程，解决复杂的科学问题。"}}
{"id": "2506.22893", "title": "Agentic Enterprise: AI-Centric User to User-Centric AI", "authors": ["Arpit Narechania", "Alex Endert", "Atanu R Sinha"], "abstract": "After a very long winter, the Artificial Intelligence (AI) spring is here. Or, so it seems over the last three years. AI has the potential to impact many areas of human life - personal, social, health, education, professional. In this paper, we take a closer look at the potential of AI for Enterprises, where decision-making plays a crucial and repeated role across functions, tasks, and operations. We consider Agents imbued with AI as means to increase decision-productivity of enterprises. We highlight six tenets for Agentic success in enterprises, by drawing attention to what the current, AI-Centric User paradigm misses, in the face of persistent needs of and usefulness for Enterprise Decision-Making. In underscoring a shift to User-Centric AI, we offer six tenets and promote market mechanisms for platforms, aligning the design of AI and its delivery by Agents to the cause of enterprise users.", "subjects": "Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)", "comments": "12 pages, 1 figure, 2 sidebars; Preprint", "pdf_url": "https://arxiv.org/pdf/2506.22893.pdf", "abstract_url": "https://arxiv.org/abs/2506.22893", "categories": ["Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文探讨了人工智能（AI）在企业中的潜力，特别是在决策制定方面。作者提出了六个原则，以促进AI在企业中的成功应用，并强调了从以AI为中心的用户范式向以用户为中心的AI转变的重要性。", "motivation": "解决当前以AI为中心的用户范式在企业决策制定中未能满足的持久需求和实用性，探索AI如何提升企业的决策效率。", "method": "通过提出六个原则，促进AI在企业中的成功应用，并倡导市场机制来对齐AI的设计和交付与企业的需求。", "result": "提出了六个原则，旨在实现从以AI为中心的用户范式向以用户为中心的AI的转变，以更好地服务于企业决策制定的需求。", "conclusion": "通过转向以用户为中心的AI和实施六个原则，可以更有效地利用AI提升企业的决策效率和生产力。"}}
{"id": "2506.22890", "title": "CP-Guard: A Unified, Probability-Agnostic, and Adaptive Framework for Malicious Agent Detection and Defense in Multi-Agent Embodied Perception Systems", "authors": ["Senkang Hu", "Yihang Tao", "Guowen Xu", "Xinyuan Qian", "Yiqin Deng", "Xianhao Chen", "Sam Tak Wu Kwong", "Yuguang Fang"], "abstract": "Collaborative Perception (CP) has been shown to be a promising technique for multi-agent autonomous driving and multi-agent robotic systems, where multiple agents share their perception information to enhance the overall perception performance and expand the perception range. However, in CP, an ego agent needs to receive messages from its collaborators, which makes it vulnerable to attacks from malicious agents. To address this critical issue, we propose a unified, probability-agnostic, and adaptive framework, namely, CP-Guard, which is a tailored defense mechanism for CP deployed by each agent to accurately detect and eliminate malicious agents in its collaboration network. Our key idea is to enable CP to reach a consensus rather than a conflict against an ego agent's perception results. Based on this idea, we first develop a probability-agnostic sample consensus (PASAC) method to effectively sample a subset of the collaborators and verify the consensus without prior probabilities of malicious agents. Furthermore, we define collaborative consistency loss (CCLoss) for object detection task and bird's eye view (BEV) segmentation task to capture the discrepancy between an ego agent and its collaborators, which is used as a verification criterion for consensus. In addition, we propose online adaptive threshold via dual sliding windows to dynamically adjust the threshold for consensus verification and ensure the reliability of the systems in dynamic environments. Finally, we conduct extensive experiments and demonstrate the effectiveness of our framework. Code will be released at", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Cryptography and Security (cs.CR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.22890.pdf", "abstract_url": "https://arxiv.org/abs/2506.22890", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Cryptography and Security (cs.CR)"], "matching_keywords": ["agent"], "AI": {"tldr": "CP-Guard是一个统一的、概率无关的、自适应的框架，用于在多智能体感知系统中检测和防御恶意代理。", "motivation": "协作感知（CP）在多智能体自动驾驶和多智能体机器人系统中显示出潜力，但智能体接收来自合作者的消息使其易受恶意代理攻击。", "method": "提出了CP-Guard框架，包括概率无关样本共识（PASAC）方法、协作一致性损失（CCLoss）定义和在线自适应阈值技术，以动态调整共识验证阈值。", "result": "通过广泛实验证明了CP-Guard框架在检测和消除恶意代理方面的有效性。", "conclusion": "CP-Guard框架为协作感知系统提供了一个有效的防御机制，能够在不依赖恶意代理先验概率的情况下，动态适应环境变化，确保系统可靠性。"}}
{"id": "2506.23049", "title": "AURA: Agent for Understanding, Reasoning, and Automated Tool Use in Voice-Driven Tasks", "authors": ["Leander Melroy Maben", "Gayathri Ganesh Lakshmy", "Srijith Radhakrishnan", "Siddhant Arora", "Shinji Watanabe"], "abstract": "Despite advances in language and speech technologies, no open-source system enables full speech-to-speech, multi-turn dialogue with integrated tool use and agentic reasoning. We introduce AURA (Agent for Understanding, Reasoning, and Automated Tool Use), the first open-source, speech-native assistant capable of completing complex, goal-driven tasks through dynamic tool invocation and multi-turn conversation. AURA combines open-weight ASR, TTS, and LLMs in a cascaded pipeline and supports tools such as calendar booking, contact lookup, web search, and email. Its modular design allows easy integration of new tools using natural language prompts and action classes. On VoiceBench, AURA scores 92.75% on OpenBookQA-outperforming all open-weight systems and nearing GPT-4o-and 4.39 on AlpacaEval, competitive with other open-weight systems. Human evaluation shows 90% task success on complex, multi-turn speech tasks.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Sound (cs.SD); Audio and Speech Processing (eess.AS)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.23049.pdf", "abstract_url": "https://arxiv.org/abs/2506.23049", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Sound (cs.SD)", "Audio and Speech Processing (eess.AS)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "AURA是一个开源的语音原生助手，能够通过动态工具调用和多轮对话完成复杂的、目标驱动的任务。它结合了开放的ASR、TTS和LLMs技术，支持日历预订、联系人查找、网络搜索和电子邮件等工具。在VoiceBench上，AURA的表现优于所有开放权重系统，接近GPT-4o，并且在AlpacaEval上与其他开放权重系统竞争。人类评估显示，在复杂的多轮语音任务中，AURA的任务成功率为90%。", "motivation": "尽管语言和语音技术有所进步，但目前还没有开源系统能够实现完整的语音到语音、多轮对话，并集成工具使用和代理推理。AURA旨在填补这一空白。", "method": "AURA结合了开放的ASR、TTS和LLMs技术，采用级联管道设计，支持通过自然语言提示和动作类轻松集成新工具。", "result": "在VoiceBench上，AURA在OpenBookQA上的得分为92.75%，优于所有开放权重系统，接近GPT-4o；在AlpacaEval上的得分为4.39，与其他开放权重系统竞争。人类评估显示，在复杂的多轮语音任务中，AURA的任务成功率为90%。", "conclusion": "AURA是第一个开源的、语音原生的助手，能够通过动态工具调用和多轮对话完成复杂的、目标驱动的任务。其模块化设计允许轻松集成新工具，且在多个评估指标上表现出色，接近或优于现有系统。"}}
{"id": "2506.22852", "title": "Knowledge Augmented Finetuning Matters in both RAG and Agent Based Dialog Systems", "authors": ["Yucheng Cai", "Yuxuan Wu", "Yi Huang", "Junlan Feng", "Zhijian Ou"], "abstract": "Large language models (LLMs) have recently been applied to dialog systems. Despite making progress, LLMs are prone to errors in knowledge-intensive scenarios. Recently, approaches based on retrieval augmented generation (RAG) and agent have emerged to improve the factual accuracy by enhancing the LLMs with knowledge retrieved from external knowledge bases (KBs). This is mostly implemented by prompting the LLMs with instructions, examples and the retrieved knowledge. However, LLMs may have difficulty using the retrieved knowledge effectively for response generation, because they are not well trained to do such generation for specific domains. To mitigate this problem, we propose to finetune the LLMs in the RAG-based and agent-based systems with domain-specific data, together with domain-specific external knowledge, which is called knowledge augmented finetuning (KAFT). We base our study on the MobileCS2 dataset, a real-life customer service dialog dataset that features intensive knowledge interactions, to systematically compare the prompting and KAFT techniques in the RAG-based and agent-based systems. Experiment results show that KAFT substantially surpasses prompting in both RAG and agent systems, particularly in terms of factual accuracy. To the best of our knowledge, this paper represents the first solid empirical work to investigate the KAFT idea.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.22852.pdf", "abstract_url": "https://arxiv.org/abs/2506.22852", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文探讨了在基于检索增强生成（RAG）和代理的对话系统中，知识增强微调（KAFT）的重要性。通过使用特定领域的数据和外部知识对大型语言模型（LLMs）进行微调，显著提高了事实准确性。", "motivation": "解决大型语言模型在知识密集型场景中容易出错的问题，特别是在对话系统中有效利用检索知识生成准确回答的挑战。", "method": "提出了知识增强微调（KAFT）方法，通过在RAG和代理系统中使用特定领域的数据和外部知识对LLMs进行微调。", "result": "实验结果表明，KAFT在RAG和代理系统中均显著优于提示技术，尤其是在事实准确性方面。", "conclusion": "KAFT是提高对话系统事实准确性的有效方法，本文是首个对KAFT思想进行实证研究的坚实工作。"}}
{"id": "2506.22853", "title": "DICE-BENCH: Evaluating the Tool-Use Capabilities of Large Language Models in Multi-Round, Multi-Party Dialogues", "authors": ["Kyochul Jang", "Donghyeon Lee", "Kyusik Kim", "Dongseok Heo", "Taewhoo Lee", "Woojeong Kim", "Bongwon Suh"], "abstract": "Existing function-calling benchmarks focus on single-turn interactions. However, they overlook the complexity of real-world scenarios. To quantify how existing benchmarks address practical applications, we introduce DICE-SCORE, a metric that evaluates the dispersion of tool-related information such as function name and parameter values throughout the dialogue. Analyzing existing benchmarks through DICE-SCORE reveals notably low scores, highlighting the need for more realistic scenarios. To address this gap, we present DICE-BENCH, a framework that constructs practical function-calling datasets by synthesizing conversations through a tool graph that maintains dependencies across rounds and a multi-agent system with distinct personas to enhance dialogue naturalness. The final dataset comprises 1,607 high-DICE-SCORE instances. Our experiments on 19 LLMs with DICE-BENCH show that significant advances are still required before such models can be deployed effectively in real-world settings. Our code and data are all publicly available:", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "9 pages, ACL 2025 Vienna", "pdf_url": "https://arxiv.org/pdf/2506.22853.pdf", "abstract_url": "https://arxiv.org/abs/2506.22853", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了DICE-BENCH，一个评估大型语言模型在多轮、多方对话中使用工具能力的框架。通过DICE-SCORE指标，作者发现现有基准测试在真实场景中的应用存在不足，并提出了一个通过工具图和多方代理系统构建的实用函数调用数据集。", "motivation": "现有的函数调用基准测试仅关注单轮交互，忽略了真实世界场景的复杂性。为了量化现有基准测试在实际应用中的表现，作者引入了DICE-SCORE指标，并发现现有基准测试的得分较低，这表明需要更真实的场景来评估模型。", "method": "作者提出了DICE-BENCH框架，该框架通过工具图维护跨轮的依赖关系，并使用具有不同角色的多代理系统来增强对话的自然性，从而构建实用的函数调用数据集。", "result": "最终的数据集包含了1,607个高DICE-SCORE的实例。在19个大型语言模型上的实验表明，这些模型在真实世界设置中的有效部署仍需重大进步。", "conclusion": "DICE-BENCH框架和DICE-SCORE指标为评估大型语言模型在复杂对话中的工具使用能力提供了新的视角和方法，揭示了当前模型在实际应用中的局限性，并促进了更真实场景下的模型评估。"}}
{"id": "2506.23273", "title": "FinStat2SQL: A Text2SQL Pipeline for Financial Statement Analysis", "authors": ["Quang Hung Nguyen", "Phuong Anh Trinh", "Phan Quoc Hung Mai", "Tuan Phong Trinh"], "abstract": "Despite the advancements of large language models, text2sql still faces many challenges, particularly with complex and domain-specific queries. In finance, database designs and financial reporting layouts vary widely between financial entities and countries, making text2sql even more challenging. We present FinStat2SQL, a lightweight text2sql pipeline enabling natural language queries over financial statements. Tailored to local standards like VAS, it combines large and small language models in a multi-agent setup for entity extraction, SQL generation, and self-correction. We build a domain-specific database and evaluate models on a synthetic QA dataset. A fine-tuned 7B model achieves 61.33\\% accuracy with sub-4-second response times on consumer hardware, outperforming GPT-4o-mini. FinStat2SQL offers a scalable, cost-efficient solution for financial analysis, making AI-powered querying accessible to Vietnamese enterprises.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.23273.pdf", "abstract_url": "https://arxiv.org/abs/2506.23273", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "FinStat2SQL是一个针对财务报表分析的轻量级Text2SQL管道，支持自然语言查询，特别适应越南的VAS等本地标准，通过多智能体设置结合大小语言模型，实现了在消费级硬件上61.33%的准确率和低于4秒的响应时间。", "motivation": "解决在金融领域，由于数据库设计和财务报表布局在不同金融机构和国家之间存在广泛差异，Text2SQL面临的复杂和领域特定查询的挑战。", "method": "采用多智能体设置，结合大型和小型语言模型，进行实体提取、SQL生成和自我校正，针对越南的VAS等本地标准进行定制。", "result": "在消费级硬件上，一个经过微调的7B模型实现了61.33%的准确率，响应时间低于4秒，性能超过了GPT-4o-mini。", "conclusion": "FinStat2SQL为金融分析提供了一个可扩展、成本效益高的解决方案，使越南企业能够访问AI驱动的查询功能。"}}
{"id": "2506.22957", "title": "Agent-to-Agent Theory of Mind: Testing Interlocutor Awareness among Large Language Models", "authors": ["Younwoo Choi", "Changling Li", "Yongjin Yang", "Zhijing Jin"], "abstract": "As large language models (LLMs) are increasingly integrated into multi-agent and human-AI systems, understanding their awareness of both self-context and conversational partners is essential for ensuring reliable performance and robust safety. While prior work has extensively studied situational awareness which refers to an LLM's ability to recognize its operating phase and constraints, it has largely overlooked the complementary capacity to identify and adapt to the identity and characteristics of a dialogue partner. In this paper, we formalize this latter capability as interlocutor awareness and present the first systematic evaluation of its emergence in contemporary LLMs. We examine interlocutor inference across three dimensions-reasoning patterns, linguistic style, and alignment preferences-and show that LLMs reliably identify same-family peers and certain prominent model families, such as GPT and Claude. To demonstrate its practical significance, we develop three case studies in which interlocutor awareness both enhances multi-LLM collaboration through prompt adaptation and introduces new alignment and safety vulnerabilities, including reward-hacking behaviors and increased jailbreak susceptibility. Our findings highlight the dual promise and peril of identity-sensitive behavior in LLMs, underscoring the need for further understanding of interlocutor awareness and new safeguards in multi-agent deployments. Our code is open-sourced at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.22957.pdf", "abstract_url": "https://arxiv.org/abs/2506.22957", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究了大型语言模型（LLMs）在对话中对对话伙伴身份和特征的识别与适应能力，即对话者意识。通过三个维度的评估，发现LLMs能可靠识别同族模型及特定模型家族，如GPT和Claude。研究还展示了对话者意识在多LLM协作中的实际应用及其带来的新安全漏洞。", "motivation": "随着大型语言模型（LLMs）越来越多地集成到多代理和人类-AI系统中，理解它们对自我上下文和对话伙伴的意识对于确保可靠性能和强大安全性至关重要。", "method": "研究通过三个维度（推理模式、语言风格和对齐偏好）评估LLMs的对话者推理能力，并开发了三个案例研究来展示对话者意识的实际意义。", "result": "LLMs能可靠识别同族模型及特定模型家族，如GPT和Claude。对话者意识既增强了多LLM协作，也引入了新的对齐和安全漏洞。", "conclusion": "研究结果强调了LLMs中身份敏感行为的双重承诺和危险，突显了进一步理解对话者意识及在多代理部署中实施新保障措施的必要性。"}}
{"id": "2506.23306", "title": "GATSim: Urban Mobility Simulation with Generative Agents", "authors": ["Qi Liu", "Can Li", "Wanjing Ma"], "abstract": "Traditional agent-based urban mobility simulations rely on rigid rule-based systems that fail to capture the complexity, adaptability, and behavioral diversity characteristic of human travel decision-making. Recent advances in large language models and AI agent technology offer opportunities to create agents with reasoning capabilities, persistent memory, and adaptive learning mechanisms. We propose GATSim (Generative-Agent Transport Simulation), a novel framework that leverages these advances to create generative agents with rich behavioral characteristics for urban mobility simulation. Unlike conventional approaches, GATSim agents possess diverse socioeconomic attributes, individual lifestyles, and evolving preferences that shape their mobility decisions through psychologically-informed memory systems, tool usage capabilities, and lifelong learning mechanisms. The main contributions of this study include: (1) a comprehensive architecture combining an urban mobility foundation model with agent cognitive systems and transport simulation environment, (2) a fully functional prototype implementation, and (3) systematic validation demonstrating that generative agents produce believable travel behaviors. Through designed reflection processes, generative agents in this study can transform specific travel experiences into generalized insights, enabling realistic behavioral adaptation over time with specialized mechanisms for activity planning and real-time reactive behaviors tailored to urban mobility contexts. Experiments show that generative agents perform competitively with human annotators in mobility scenarios while naturally producing macroscopic traffic evolution patterns. The code for the prototype system is shared at", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.23306.pdf", "abstract_url": "https://arxiv.org/abs/2506.23306", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "GATSim提出了一种基于生成代理的城巿交通模拟框架，利用大型语言模型和AI代理技术，创建具有丰富行为特征的代理，以模拟人类旅行决策的复杂性和适应性。", "motivation": "传统的基于规则的城巿交通模拟无法充分捕捉人类旅行决策的复杂性、适应性和行为多样性。", "method": "GATSim结合城巿交通基础模型、代理认知系统和交通模拟环境，通过心理记忆系统、工具使用能力和终身学习机制，创建具有社会经济属性、个人生活方式和演变偏好的生成代理。", "result": "实验表明，生成代理在交通场景中与人类注释者表现相当，并能自然产生宏观交通演变模式。", "conclusion": "GATSim通过生成代理实现了更真实、适应性更强的城巿交通模拟，为交通规划和政策制定提供了新的工具。"}}
{"id": "2506.23276", "title": "Corrupted by Reasoning: Reasoning Language Models Become Free-Riders in Public Goods Games", "authors": ["David Guzman Piedrahita", "Yongjin Yang", "Mrinmaya Sachan", "Giorgia Ramponi", "Bernhard Schölkopf", "Zhijing Jin"], "abstract": "As large language models (LLMs) are increasingly deployed as autonomous agents, understanding their cooperation and social mechanisms is becoming increasingly important. In particular, how LLMs balance self-interest and collective well-being is a critical challenge for ensuring alignment, robustness, and safe deployment. In this paper, we examine the challenge of costly sanctioning in multi-agent LLM systems, where an agent must decide whether to invest its own resources to incentivize cooperation or penalize defection. To study this, we adapt a public goods game with institutional choice from behavioral economics, allowing us to observe how different LLMs navigate social dilemmas over repeated interactions. Our analysis reveals four distinct behavioral patterns among models: some consistently establish and sustain high levels of cooperation, others fluctuate between engagement and disengagement, some gradually decline in cooperative behavior over time, and others rigidly follow fixed strategies regardless of outcomes. Surprisingly, we find that reasoning LLMs, such as the o1 series, struggle significantly with cooperation, whereas some traditional LLMs consistently achieve high levels of cooperation. These findings suggest that the current approach to improving LLMs, which focuses on enhancing their reasoning capabilities, does not necessarily lead to cooperation, providing valuable insights for deploying LLM agents in environments that require sustained collaboration. Our code is available at", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.23276.pdf", "abstract_url": "https://arxiv.org/abs/2506.23276", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究了大型语言模型（LLMs）在多代理系统中的合作行为，特别是在公共物品游戏中如何平衡自我利益与集体福祉。研究发现，不同LLMs展现出四种不同的行为模式，且具有推理能力的LLMs在合作方面表现不佳。", "motivation": "随着大型语言模型（LLMs）越来越多地被部署为自主代理，理解它们的合作和社会机制变得越来越重要。特别是，LLMs如何平衡自我利益和集体福祉是确保对齐性、鲁棒性和安全部署的关键挑战。", "method": "研究通过改编行为经济学中的公共物品游戏与制度选择，观察不同LLMs在重复互动中如何应对社会困境。", "result": "分析揭示了四种不同的行为模式：一些模型持续建立和维持高水平的合作，其他模型在参与和退出之间波动，一些模型随时间逐渐减少合作行为，其他模型则无论结果如何都严格遵循固定策略。令人惊讶的是，具有推理能力的LLMs（如o1系列）在合作方面表现显著不佳，而一些传统LLMs则能持续实现高水平的合作。", "conclusion": "这些发现表明，当前通过增强推理能力来改进LLMs的方法并不一定导致更好的合作，为在需要持续协作的环境中部署LLM代理提供了宝贵的见解。"}}
{"id": "2506.23549", "title": "CooT: Learning to Coordinate In-Context with Coordination Transformers", "authors": ["Huai-Chih Wang", "Hsiang-Chun Chuang", "Hsi-Chun Cheng", "Dai-Jie Wu", "Shao-Hua Sun"], "abstract": "Effective coordination among artificial agents in dynamic and uncertain environments remains a significant challenge in multi-agent systems. Existing approaches, such as self-play and population-based methods, either generalize poorly to unseen partners or require extensive training. To overcome these limitations, we propose Coordination Transformers (CooT), a novel in-context coordination framework that uses recent interaction histories to adapt to unseen partners rapidly. Unlike previous approaches that primarily aim to increase the diversity of training partners, CooT explicitly focuses on adapting to new partner behaviors by predicting actions aligned with observed partner interactions. Trained on interaction trajectories collected from diverse pairs of agents with complementary behaviors, CooT quickly learns effective coordination strategies without explicit supervision or fine-tuning. Evaluations on the Overcooked benchmark demonstrate that CooT significantly outperforms baseline methods in coordination tasks involving previously unseen partners. Human evaluations further confirm CooT as the most effective collaborative partner, while extensive ablations highlight its robustness, flexibility, and sensitivity to context in multi-agent scenarios.", "subjects": "Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)", "comments": "23 pages, 10 tables, 8 figures", "pdf_url": "https://arxiv.org/pdf/2506.23549.pdf", "abstract_url": "https://arxiv.org/abs/2506.23549", "categories": ["Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新颖的上下文协调框架——协调变换器（CooT），旨在通过最近的交互历史快速适应未见过的合作伙伴，以解决多智能体系统中动态和不确定环境下的有效协调问题。", "motivation": "解决多智能体系统中在动态和不确定环境下与未见过的合作伙伴有效协调的挑战，现有方法如自我对弈和基于群体的方法要么对未见过的合作伙伴泛化能力差，要么需要大量训练。", "method": "提出了协调变换器（CooT），这是一个新颖的上下文协调框架，利用最近的交互历史来快速适应新的合作伙伴行为，通过预测与观察到的合作伙伴交互一致的行动。", "result": "在Overcooked基准测试中，CooT在与未见过的合作伙伴的协调任务中显著优于基线方法。人类评估进一步确认CooT是最有效的协作伙伴，广泛的消融实验突出了其在多智能体场景中的鲁棒性、灵活性和对上下文的敏感性。", "conclusion": "CooT通过快速学习有效的协调策略，无需显式监督或微调，显著提高了与未见过的合作伙伴的协调效率，为多智能体系统提供了一种新的、高效的协调方法。"}}
{"id": "2506.23626", "title": "Self-correcting Reward Shaping via Language Models for Reinforcement Learning Agents in Games", "authors": ["António Afonso", "Iolanda Leite", "Alessandro Sestini", "Florian Fuchs", "Konrad Tollmar", "Linus Gisslén"], "abstract": "Reinforcement Learning (RL) in games has gained significant momentum in recent years, enabling the creation of different agent behaviors that can transform a player's gaming experience. However, deploying RL agents in production environments presents two key challenges: (1) designing an effective reward function typically requires an RL expert, and (2) when a game's content or mechanics are modified, previously tuned reward weights may no longer be optimal. Towards the latter challenge, we propose an automated approach for iteratively fine-tuning an RL agent's reward function weights, based on a user-defined language based behavioral goal. A Language Model (LM) proposes updated weights at each iteration based on this target behavior and a summary of performance statistics from prior training rounds. This closed-loop process allows the LM to self-correct and refine its output over time, producing increasingly aligned behavior without the need for manual reward engineering. We evaluate our approach in a racing task and show that it consistently improves agent performance across iterations. The LM-guided agents show a significant increase in performance from $9\\%$ to $74\\%$ success rate in just one iteration. We compare our LM-guided tuning against a human expert's manual weight design in the racing task: by the final iteration, the LM-tuned agent achieved an $80\\%$ success rate, and completed laps in an average of $855$ time steps, a competitive performance against the expert-tuned agent's peak $94\\%$ success, and $850$ time steps.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "16 pages in total, 10 pages of main paper, 5 figures", "pdf_url": "https://arxiv.org/pdf/2506.23626.pdf", "abstract_url": "https://arxiv.org/abs/2506.23626", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种通过语言模型自动调整强化学习代理在游戏中奖励函数权重的方法，以解决游戏内容或机制变化时手动调整奖励函数的挑战。", "motivation": "解决在游戏环境中部署强化学习代理时，设计有效的奖励函数需要专家参与，以及游戏内容或机制变化时原有奖励权重不再最优的问题。", "method": "使用语言模型基于用户定义的行为目标和先前训练轮次的性能统计摘要，迭代地提出更新的奖励函数权重，实现自我纠正和精细化输出。", "result": "在赛车任务中评估，该方法显著提高了代理性能，从9%的成功率提升到74%，最终迭代达到80%的成功率和855时间步的平均圈速，与专家调整的代理性能相当。", "conclusion": "提出的方法能够自动调整奖励函数权重，显著提高代理性能，减少对手动奖励工程的需求，展示了语言模型在强化学习中的应用潜力。"}}
{"id": "2506.23576", "title": "Evaluating Multi-Agent Defences Against Jailbreaking Attacks on Large Language Models", "authors": ["Maria Carolina Cornelia Wit", "Jun Pang"], "abstract": "Recent advances in large language models (LLMs) have raised concerns about jailbreaking attacks, i.e., prompts that bypass safety mechanisms. This paper investigates the use of multi-agent LLM systems as a defence against such attacks. We evaluate three jailbreaking strategies, including the original AutoDefense attack and two from Deepleaps: BetterDan and JB. Reproducing the AutoDefense framework, we compare single-agent setups with two- and three-agent configurations. Our results show that multi-agent systems enhance resistance to jailbreaks, especially by reducing false negatives. However, its effectiveness varies by attack type, and it introduces trade-offs such as increased false positives and computational overhead. These findings point to the limitations of current automated defences and suggest directions for improving alignment robustness in future LLM systems.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "26 pages, 1 figure", "pdf_url": "https://arxiv.org/pdf/2506.23576.pdf", "abstract_url": "https://arxiv.org/abs/2506.23576", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了使用多代理大型语言模型（LLM）系统作为防御手段对抗越狱攻击的有效性。通过评估三种越狱策略，研究发现多代理系统能增强对越狱攻击的抵抗力，尤其是减少假阴性，但也带来了假阳性增加和计算开销等权衡。", "motivation": "随着大型语言模型（LLM）的进步，越狱攻击（即绕过安全机制的提示）引发了担忧。本研究旨在探索多代理LLM系统作为防御此类攻击的潜力。", "method": "研究复制了AutoDefense框架，比较了单代理与两代理和三代理配置的防御效果，评估了包括AutoDefense攻击和Deepleaps的BetterDan与JB在内的三种越狱策略。", "result": "结果表明，多代理系统提高了对越狱攻击的抵抗力，特别是在减少假阴性方面。然而，其效果因攻击类型而异，并伴随着假阳性增加和计算开销的增加。", "conclusion": "这些发现指出了当前自动防御的局限性，并为未来LLM系统提高对齐鲁棒性提供了方向。"}}
{"id": "2506.23046", "title": "SoMi-ToM: Evaluating Multi-Perspective Theory of Mind in Embodied Social Interactions", "authors": ["Xianzhe Fan", "Xuhui Zhou", "Chuanyang Jin", "Kolby Nottingham", "Hao Zhu", "Maarten Sap"], "abstract": "Humans continuously infer the states, goals, and behaviors of others by perceiving their surroundings in dynamic, real-world social interactions. However, most Theory of Mind (ToM) benchmarks only evaluate static, text-based scenarios, which have a significant gap compared to real interactions. We propose the SoMi-ToM benchmark, designed to evaluate multi-perspective ToM in embodied multi-agent complex social interactions. This benchmark is based on rich multimodal interaction data generated by the interaction environment SoMi, covering diverse crafting goals and social relationships. Our framework supports multi-level evaluation: (1) first-person evaluation provides multimodal (visual, dialogue, action, etc.) input from a first-person perspective during a task for real-time state inference, (2) third-person evaluation provides complete third-person perspective video and text records after a task for goal and behavior inference. This evaluation method allows for a more comprehensive examination of a model's ToM capabilities from both the subjective immediate experience and the objective global observation. We constructed a challenging dataset containing 35 third-person perspective videos, 363 first-person perspective images, and 1225 expert-annotated multiple-choice questions (three options). On this dataset, we systematically evaluated the performance of human subjects and several state-of-the-art large vision-language models (LVLMs). The results show that LVLMs perform significantly worse than humans on SoMi-ToM: the average accuracy gap between humans and models is 40.1% in first-person evaluation and 26.4% in third-person evaluation. This indicates that future LVLMs need to further improve their ToM capabilities in embodied, complex social interactions.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)", "comments": "23 pages, 6 figures", "pdf_url": "https://arxiv.org/pdf/2506.23046.pdf", "abstract_url": "https://arxiv.org/abs/2506.23046", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "SoMi-ToM基准测试旨在评估多智能体复杂社交互动中的多视角心理理论能力，通过第一人称和第三人称视角的评估方法，全面考察模型的心理理论能力。", "motivation": "现有的心理理论（ToM）基准测试大多基于静态、文本化的场景，与真实的社交互动存在显著差距。为了解决这一问题，提出了SoMi-ToM基准测试，以评估在具体化多智能体复杂社交互动中的多视角ToM能力。", "method": "基于SoMi互动环境生成的丰富多模态互动数据，设计了支持多级评估的框架：第一人称评估提供任务期间的第一人称视角多模态输入，第三人称评估提供任务后的完整第三人称视角视频和文本记录。", "result": "在构建的数据集上，人类与几种最先进的大型视觉语言模型（LVLMs）的表现进行了系统评估。结果显示，LVLMs在SoMi-ToM上的表现显著低于人类：第一人称评估中人类与模型的平均准确率差距为40.1%，第三人称评估中为26.4%。", "conclusion": "这表明未来的LVLMs需要在具体化、复杂的社交互动中进一步提高其ToM能力。"}}
{"id": "2506.23139", "title": "Benchmarking Deep Search over Heterogeneous Enterprise Data", "authors": ["Prafulla Kumar Choubey", "Xiangyu Peng", "Shilpa Bhagavath", "Kung-Hsiang Huang", "Caiming Xiong", "Chien-Sheng Wu"], "abstract": "We present a new benchmark for evaluating Deep Search--a realistic and complex form of retrieval-augmented generation (RAG) that requires source-aware, multi-hop reasoning over diverse, sparsed, but related sources. These include documents, meeting transcripts, Slack messages, GitHub, and URLs, which vary in structure and often contain human-to-human interactions. We build it using a synthetic data pipeline that simulates business workflows across product planning, development, and support stages, generating interconnected content with realistic noise and multi-hop questions with guaranteed ground-truth answers. We release our benchmark with both answerable and unanswerable queries, and retrieval pool of 39,190 enterprise artifacts, enabling fine-grained evaluation of long-context LLM and RAG systems. Our experiments reveal that even the best-performing agentic RAG methods achieve an average performance score of 32.96 on our benchmark. With further analysis, we highlight retrieval as the main bottleneck: existing methods struggle to conduct deep searches and retrieve all necessary evidence. Consequently, they often reason over partial context, leading to significant performance degradation.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.23139.pdf", "abstract_url": "https://arxiv.org/abs/2506.23139", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic", "@RAG"], "AI": {"tldr": "提出了一种新的深度搜索基准测试，用于评估在异构企业数据上的检索增强生成（RAG）性能，揭示了现有方法在深度搜索和检索所有必要证据方面的困难。", "motivation": "解决在企业环境中，由于数据来源多样、结构不一且包含人机交互，现有检索增强生成方法在深度搜索和多跳推理上的性能不足问题。", "method": "通过合成数据管道模拟企业工作流程，生成包含噪声的互连内容和多跳问题，构建了一个包含可回答和不可回答查询的基准测试。", "result": "实验显示，即使性能最佳的代理RAG方法在基准测试上的平均得分仅为32.96，检索是主要瓶颈。", "conclusion": "现有方法在深度搜索和检索所有必要证据方面存在困难，导致在部分上下文上推理时性能显著下降。"}}
{"id": "2506.23136", "title": "LLM-Assisted Question-Answering on Technical Documents Using Structured Data-Aware Retrieval Augmented Generation", "authors": ["Shadman Sobhan", "Mohammad Ariful Haque"], "abstract": "Large Language Models (LLMs) are capable of natural language understanding and generation. But they face challenges such as hallucination and outdated knowledge. Fine-tuning is one possible solution, but it is resource-intensive and must be repeated with every data update. Retrieval-Augmented Generation (RAG) offers an efficient solution by allowing LLMs to access external knowledge sources. However, traditional RAG pipelines struggle with retrieving information from complex technical documents with structured data such as tables and images. In this work, we propose a RAG pipeline, capable of handling tables and images in documents, for technical documents that support both scanned and searchable formats. Its retrieval process combines vector similarity search with a fine-tuned reranker based on Gemma-2-9b-it. The reranker is trained using RAFT (Retrieval-Augmented Fine-Tuning) on a custom dataset designed to improve context identification for question answering. Our evaluation demonstrates that the proposed pipeline achieves a high faithfulness score of 94% (RAGas) and 96% (DeepEval), and an answer relevancy score of 87% (RAGas) and 93% (DeepEval). Comparative analysis demonstrates that the proposed architecture is superior to general RAG pipelines in terms of table-based questions and handling questions outside context.", "subjects": "Computation and Language (cs.CL)", "comments": "29 Pages, 11 Tables", "pdf_url": "https://arxiv.org/pdf/2506.23136.pdf", "abstract_url": "https://arxiv.org/abs/2506.23136", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种能够处理技术文档中表格和图像的检索增强生成（RAG）管道，结合向量相似性搜索和基于Gemma-2-9b-it的精细调整重新排序器，显著提高了问答的准确性和相关性。", "motivation": "大型语言模型（LLMs）在自然语言理解和生成方面表现出色，但仍面临幻觉和知识过时等挑战。传统的RAG管道在处理包含结构化数据（如表格和图像）的复杂技术文档时效果不佳。", "method": "提出了一种RAG管道，结合向量相似性搜索和基于Gemma-2-9b-it的精细调整重新排序器，使用RAFT（检索增强精细调整）在自定义数据集上训练，以提高上下文识别的准确性。", "result": "评估显示，提出的管道在RAGas和DeepEval上的忠实度得分分别为94%和96%，答案相关性得分分别为87%和93%，在处理表格基础问题和上下文外问题时优于一般RAG管道。", "conclusion": "该研究提出的RAG管道有效解决了技术文档中结构化数据处理的问题，显著提高了问答系统的性能和准确性，为LLMs在技术文档问答中的应用提供了新的解决方案。"}}
{"id": "2506.23689", "title": "PokéAI: A Goal-Generating, Battle-Optimizing Multi-agent System for Pokemon Red", "authors": ["Zihao Liu", "Xinhang Sui", "Yueran Song", "Siwen Wang"], "abstract": "We introduce PokéAI, the first text-based, multi-agent large language model (LLM) framework designed to autonomously play and progress through Pokémon Red. Our system consists of three specialized agents-Planning, Execution, and Critique-each with its own memory bank, role, and skill set. The Planning Agent functions as the central brain, generating tasks to progress through the game. These tasks are then delegated to the Execution Agent, which carries them out within the game environment. Upon task completion, the Critique Agent evaluates the outcome to determine whether the objective was successfully achieved. Once verification is complete, control returns to the Planning Agent, forming a closed-loop decision-making system.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.23689.pdf", "abstract_url": "https://arxiv.org/abs/2506.23689", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "介绍了PokéAI，首个基于文本的多代理大型语言模型框架，用于自主玩并通过《Pokémon Red》。系统由三个专门代理组成，形成一个闭环决策系统。", "motivation": "解决如何利用多代理大型语言模型框架自主玩并通过复杂游戏《Pokémon Red》的问题。", "method": "采用三个专门代理（规划、执行、批评）的系统，每个代理有自己的记忆库、角色和技能集，形成闭环决策系统。", "result": "成功设计并实现了能够自主玩《Pokémon Red》的多代理系统。", "conclusion": "PokéAI系统展示了多代理大型语言模型在复杂游戏自主玩和通过中的潜力，为未来研究提供了方向。"}}
{"id": "2506.23844", "title": "A Survey on Autonomy-Induced Security Risks in Large Model-Based Agents", "authors": ["Hang Su", "Jun Luo", "Chang Liu", "Xiao Yang", "Yichi Zhang", "Yinpeng Dong", "Jun Zhu"], "abstract": "Recent advances in large language models (LLMs) have catalyzed the rise of autonomous AI agents capable of perceiving, reasoning, and acting in dynamic, open-ended environments. These large-model agents mark a paradigm shift from static inference systems to interactive, memory-augmented entities. While these capabilities significantly expand the functional scope of AI, they also introduce qualitatively novel security risks - such as memory poisoning, tool misuse, reward hacking, and emergent misalignment - that extend beyond the threat models of conventional systems or standalone LLMs. In this survey, we first examine the structural foundations and key capabilities that underpin increasing levels of agent autonomy, including long-term memory retention, modular tool use, recursive planning, and reflective reasoning. We then analyze the corresponding security vulnerabilities across the agent stack, identifying failure modes such as deferred decision hazards, irreversible tool chains, and deceptive behaviors arising from internal state drift or value misalignment. These risks are traced to architectural fragilities that emerge across perception, cognition, memory, and action modules. To address these challenges, we systematically review recent defense strategies deployed at different autonomy layers, including input sanitization, memory lifecycle control, constrained decision-making, structured tool invocation, and introspective reflection. We introduce the Reflective Risk-Aware Agent Architecture (R2A2), a unified cognitive framework grounded in Constrained Markov Decision Processes (CMDPs), which incorporates risk-aware world modeling, meta-policy adaptation, and joint reward-risk optimization to enable principled, proactive safety across the agent's decision-making loop.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "18 pages", "pdf_url": "https://arxiv.org/pdf/2506.23844.pdf", "abstract_url": "https://arxiv.org/abs/2506.23844", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文调查了基于大型模型的自主AI代理引发的安全风险，包括记忆中毒、工具滥用、奖励黑客和突发性错位等，并提出了一个统一的认知框架R2A2来应对这些挑战。", "motivation": "随着大型语言模型（LLMs）的进步，自主AI代理的能力大幅提升，但这也带来了新的安全风险，这些风险超出了传统系统或独立LLMs的威胁模型。", "method": "通过分析代理自主性的结构基础和关键能力，识别安全漏洞，并系统回顾了不同自主层的防御策略，提出了基于约束马尔可夫决策过程（CMDPs）的R2A2框架。", "result": "研究发现，代理堆栈中存在多种安全漏洞，如延迟决策危险、不可逆工具链和由内部状态漂移或价值错位引起的欺骗行为。", "conclusion": "R2A2框架通过风险感知世界建模、元策略适应和联合奖励-风险优化，为代理的决策循环提供了原则性、主动的安全保障。"}}
{"id": "2506.23793", "title": "Advancing Learnable Multi-Agent Pathfinding Solvers with Active Fine-Tuning", "authors": ["Anton Andreychuk", "Konstantin Yakovlev", "Aleksandr Panov", "Alexey Skrynnik"], "abstract": "Multi-agent pathfinding (MAPF) is a common abstraction of multi-robot trajectory planning problems, where multiple homogeneous robots simultaneously move in the shared environment. While solving MAPF optimally has been proven to be NP-hard, scalable, and efficient, solvers are vital for real-world applications like logistics, search-and-rescue, etc. To this end, decentralized suboptimal MAPF solvers that leverage machine learning have come on stage. Building on the success of the recently introduced MAPF-GPT, a pure imitation learning solver, we introduce MAPF-GPT-DDG. This novel approach effectively fine-tunes the pre-trained MAPF model using centralized expert data. Leveraging a novel delta-data generation mechanism, MAPF-GPT-DDG accelerates training while significantly improving performance at test time. Our experiments demonstrate that MAPF-GPT-DDG surpasses all existing learning-based MAPF solvers, including the original MAPF-GPT, regarding solution quality across many testing scenarios. Remarkably, it can work with MAPF instances involving up to 1 million agents in a single environment, setting a new milestone for scalability in MAPF domains.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.23793.pdf", "abstract_url": "https://arxiv.org/abs/2506.23793", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了MAPF-GPT-DDG，一种通过主动微调预训练模型来提高多智能体路径规划（MAPF）求解器性能的新方法。该方法利用中心化专家数据和创新的delta-data生成机制，加速训练并显著提升测试时的性能。实验表明，MAPF-GPT-DDG在解决方案质量上超越了所有现有的基于学习的MAPF求解器，包括原始的MAPF-GPT，并且能够处理单个环境中多达100万个智能体的MAPF实例，为MAPF领域的可扩展性设立了新的里程碑。", "motivation": "多智能体路径规划（MAPF）是多机器人轨迹规划问题的常见抽象，其中多个同质机器人在共享环境中同时移动。虽然最优解决MAPF已被证明是NP难的，但可扩展且高效的求解器对于物流、搜救等实际应用至关重要。为此，利用机器学习的去中心化次优MAPF求解器应运而生。", "method": "基于最近引入的纯模仿学习求解器MAPF-GPT的成功，我们引入了MAPF-GPT-DDG。这种新方法有效地利用中心化专家数据对预训练的MAPF模型进行微调。通过创新的delta-data生成机制，MAPF-GPT-DDG加速了训练，同时显著提高了测试时的性能。", "result": "我们的实验表明，MAPF-GPT-DDG在解决方案质量上超越了所有现有的基于学习的MAPF求解器，包括原始的MAPF-GPT。值得注意的是，它能够处理单个环境中多达100万个智能体的MAPF实例，为MAPF领域的可扩展性设立了新的里程碑。", "conclusion": "MAPF-GPT-DDG通过主动微调预训练模型和创新的delta-data生成机制，显著提高了多智能体路径规划求解器的性能和可扩展性，为实际应用提供了更高效的解决方案。"}}
{"id": "2506.23692", "title": "Agent4S: The Transformation of Research Paradigms from the Perspective of Large Language Models", "authors": ["Boyuan Zheng", "Zerui Fang", "Zhe Xu", "Rui Wang", "Yiwen Chen", "Cunshi Wang", "Mengwei Qu", "Lei Lei", "Zhen Feng", "Yan Liu", "Yuyang Li", "Mingzhou Tan", "Jiaji Wu", "Jianwei Shuai", "Jia Li", "Fangfu Ye"], "abstract": "While AI for Science (AI4S) serves as an analytical tool in the current research paradigm, it doesn't solve its core inefficiency. We propose \"Agent for Science\" (Agent4S)-the use of LLM-driven agents to automate the entire research workflow-as the true Fifth Scientific Paradigm. This paper introduces a five-level classification for Agent4S, outlining a clear roadmap from simple task automation to fully autonomous, collaborative \"AI Scientists.\" This framework defines the next revolutionary step in scientific discovery.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.23692.pdf", "abstract_url": "https://arxiv.org/abs/2506.23692", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了‘Agent for Science’（Agent4S）概念，即利用大型语言模型（LLM）驱动的代理来自动化整个科研工作流程，作为真正的第五科学范式。", "motivation": "当前的‘AI for Science’（AI4S）研究范式虽然作为分析工具，但未能解决其核心效率低下的问题。", "method": "提出了一个五级分类法，为Agent4S提供了一个从简单任务自动化到完全自主、协作的‘AI科学家’的清晰路线图。", "result": "这一框架定义了科学发现的下一个革命性步骤。", "conclusion": "Agent4S被视为真正的第五科学范式，预示着科研工作流程自动化的未来发展方向。"}}
{"id": "2506.23924", "title": "Performance of LLMs on Stochastic Modeling Operations Research Problems: From Theory to Practice", "authors": ["Akshit Kumar", "Tianyi Peng", "Yuhang Wu", "Assaf Zeevi"], "abstract": "Large language models (LLMs) have exhibited expert-level capabilities across various domains. However, their abilities to solve problems in Operations Research (OR) -- the analysis and optimization of mathematical models derived from real-world problems or their verbal descriptions -- remain underexplored. In this work, we take a first step toward evaluating LLMs' abilities to solve stochastic modeling problems, a core class of OR problems characterized by uncertainty and typically involving tools from probability, statistics, and stochastic processes. We manually procure a representative set of graduate-level homework and doctoral qualification-exam problems and test LLMs' abilities to solve them. We further leverage SimOpt, an open-source library of simulation-optimization problems and solvers, to investigate LLMs' abilities to make real-world decisions under uncertainty. Our results show that, though a nontrivial amount of work is still needed to reliably automate the stochastic modeling pipeline in reality, state-of-the-art LLMs demonstrate proficiency on par with human experts in both classroom and practical settings. These findings highlight the potential of building AI agents that assist OR researchers and amplify the real-world impact of OR through automation.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.23924.pdf", "abstract_url": "https://arxiv.org/abs/2506.23924", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "大型语言模型（LLMs）在解决运筹学（OR）中的随机建模问题方面展现出与人类专家相当的能力，尽管在实际应用中实现自动化仍需大量工作。", "motivation": "探索大型语言模型在运筹学领域，特别是随机建模问题解决中的能力，这一问题领域涉及不确定性，通常需要概率、统计和随机过程等工具。", "method": "通过手动收集一组代表性的研究生级别作业和博士资格考试问题，测试LLMs的解决能力，并利用SimOpt开源库研究LLMs在不确定性下做出实际决策的能力。", "result": "尽管在实际中可靠地自动化随机建模流程仍需大量工作，但最先进的LLMs在课堂和实际环境中展现出与人类专家相当的能力。", "conclusion": "这些发现突出了构建辅助运筹学研究的人工智能代理的潜力，并通过自动化放大运筹学的实际影响。"}}
{"id": "2506.24119", "title": "SPIRAL: Self-Play on Zero-Sum Games Incentivizes Reasoning via Multi-Agent Multi-Turn Reinforcement Learning", "authors": ["Bo Liu", "Leon Guertler", "Simon Yu", "Zichen Liu", "Penghui Qi", "Daniel Balcells", "Mickel Liu", "Cheston Tan", "Weiyan Shi", "Min Lin", "Wee Sun Lee", "Natasha Jaques"], "abstract": "Recent advances in reinforcement learning have shown that language models can develop sophisticated reasoning through training on tasks with verifiable rewards, but these approaches depend on human-curated problem-answer pairs and domain-specific reward engineering. We introduce SPIRAL, a self-play framework where models learn by playing multi-turn, zero-sum games against continuously improving versions of themselves, eliminating the need for human supervision. Through self-play, SPIRAL generates an infinite curriculum of progressively challenging problems as models must constantly adapt to stronger opponents. To enable this self-play training at scale, We implement a fully online, multi-turn, multi-agent reinforcement learning system for LLMs and propose role-conditioned advantage estimation (RAE) to stabilize multi-agent training. Using SPIRAL, self-play on zero-sum games produces reasoning capabilities that transfer broadly. Training Qwen3-4B-Base on Kuhn Poker alone achieves 8.6% improvement on math and 8.4% on general reasoning, outperforming SFT on 25,000 expert game trajectories. Analysis reveals that this transfer occurs through three cognitive patterns: systematic decomposition, expected value calculation, and case-by-case analysis. Multi-game training (TicTacToe, Kuhn Poker, Simple Negotiation) further enhances performance as each game develops distinct reasoning strengths. Applying SPIRAL to a strong reasoning model (DeepSeek-R1-Distill-Qwen-7B) can still lead to 2.0% average improvement. These results demonstrate that zero-sum games naturally develop transferable reasoning capabilities, highlighting a promising direction for autonomous reasoning development.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": "Work in Progress", "pdf_url": "https://arxiv.org/pdf/2506.24119.pdf", "abstract_url": "https://arxiv.org/abs/2506.24119", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "SPIRAL是一个通过自我对弈在零和游戏中激励推理的多智能体多回合强化学习框架，无需人类监督即可生成无限渐进式挑战问题，提升模型的推理能力。", "motivation": "解决现有强化学习方法依赖人类监督和特定领域奖励工程的问题，通过自我对弈开发自主推理能力。", "method": "引入SPIRAL框架，实现完全在线的多回合多智能体强化学习系统，并提出角色条件优势估计（RAE）以稳定多智能体训练。", "result": "在Kuhn Poker上训练的Qwen3-4B-Base模型在数学和一般推理上分别提高了8.6%和8.4%，多游戏训练进一步提升了性能。", "conclusion": "零和游戏自然发展出可转移的推理能力，为自主推理发展指明了有前景的方向。"}}
{"id": "2506.23992", "title": "Harnessing AI Agents to Advance Research on Refugee Child Mental Health", "authors": ["Aditya Shrivastava", "Komal Gupta", "Shraddha Arora"], "abstract": "The international refugee crisis deepens, exposing millions of dis placed children to extreme psychological trauma. This research suggests a com pact, AI-based framework for processing unstructured refugee health data and distilling knowledge on child mental health. We compare two Retrieval-Aug mented Generation (RAG) pipelines, Zephyr-7B-beta and DeepSeek R1-7B, to determine how well they process challenging humanitarian datasets while avoid ing hallucination hazards. By combining cutting-edge AI methods with migration research and child psychology, this study presents a scalable strategy to assist policymakers, mental health practitioners, and humanitarian agencies to better assist displaced children and recognize their mental wellbeing. In total, both the models worked properly but significantly Deepseek R1 is superior to Zephyr with an accuracy of answer relevance 0.91", "subjects": "Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET)", "comments": "14 page , 2 image , 2 tables , accepted under 5th International Conference on Innovations in Computational Intelligence and Computer Vision (ICICV-2025)", "pdf_url": "https://arxiv.org/pdf/2506.23992.pdf", "abstract_url": "https://arxiv.org/abs/2506.23992", "categories": ["Artificial Intelligence (cs.AI)", "Emerging Technologies (cs.ET)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本研究提出了一种基于AI的紧凑框架，用于处理非结构化的难民健康数据，并提炼关于儿童心理健康的知识。通过比较两种检索增强生成（RAG）管道，Zephyr-7B-beta和DeepSeek R1-7B，研究发现DeepSeek R1在准确性上显著优于Zephyr。", "motivation": "国际难民危机加剧，数百万流离失所的儿童面临极端的心理创伤。本研究旨在利用AI技术处理难民健康数据，为政策制定者、心理健康从业者和人道主义机构提供可扩展的策略，以更好地帮助这些儿童并关注他们的心理健康。", "method": "研究比较了两种检索增强生成（RAG）管道，Zephyr-7B-beta和DeepSeek R1-7B，评估它们在处理具有挑战性的人道主义数据集时的表现，同时避免幻觉风险。", "result": "两种模型都能正常工作，但DeepSeek R1在答案相关性上的准确性显著优于Zephyr，达到了0.91。", "conclusion": "通过将前沿的AI方法与移民研究和儿童心理学相结合，本研究提出了一种可扩展的策略，有助于更好地理解和改善流离失所儿童的心理健康。DeepSeek R1在处理难民健康数据方面表现出色，为相关领域的实践提供了有力工具。"}}
{"id": "2506.23342", "title": "ATGen: A Framework for Active Text Generation", "authors": ["Akim Tsvigun", "Daniil Vasilev", "Ivan Tsvigun", "Ivan Lysenko", "Talgat Bektleuov", "Aleksandr Medvedev", "Uliana Vinogradova", "Nikita Severin", "Mikhail Mozikov", "Andrey Savchenko", "Rostislav Grigorev", "Ramil Kuleev", "Fedor Zhdanov", "Artem Shelmanov", "Ilya Makarov"], "abstract": "Active learning (AL) has demonstrated remarkable potential in reducing the annotation effort required for training machine learning models. However, despite the surging popularity of natural language generation (NLG) tasks in recent years, the application of AL to NLG has been limited. In this paper, we introduce Active Text Generation (ATGen) - a comprehensive framework that bridges AL with text generation tasks, enabling the application of state-of-the-art AL strategies to NLG. Our framework simplifies AL-empowered annotation in NLG tasks using both human annotators and automatic annotation agents based on large language models (LLMs). The framework supports LLMs deployed as services, such as ChatGPT and Claude, or operated on-premises. Furthermore, ATGen provides a unified platform for smooth implementation and benchmarking of novel AL strategies tailored to NLG tasks. Finally, we present evaluation results for state-of-the-art AL strategies across diverse settings and multiple text generation tasks. We show that ATGen reduces both the effort of human annotators and costs associated with API calls to LLM-based annotation agents. The code of the framework is available on GitHub under the MIT license. The video presentation is available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "Accepted at ACL 2025 System Demonstrations", "pdf_url": "https://arxiv.org/pdf/2506.23342.pdf", "abstract_url": "https://arxiv.org/abs/2506.23342", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "ATGen是一个将主动学习（AL）与文本生成任务结合的框架，旨在减少自然语言生成（NLG）任务中的标注工作量和成本。", "motivation": "尽管主动学习在减少机器学习模型训练所需的标注工作量方面显示出巨大潜力，但其在自然语言生成任务中的应用仍然有限。", "method": "ATGen框架通过结合人类标注者和基于大型语言模型（LLMs）的自动标注代理，简化了NLG任务中的主动学习应用。", "result": "评估结果显示，ATGen在多种文本生成任务中有效减少了人类标注者的工作量和与LLM-based标注代理API调用相关的成本。", "conclusion": "ATGen为NLG任务提供了一个统一的平台，支持新颖的主动学习策略的实施和基准测试，同时降低了标注成本和努力。"}}
{"id": "2506.23485", "title": "Thought-Augmented Planning for LLM-Powered Interactive Recommender Agent", "authors": ["Haocheng Yu", "Yaxiong Wu", "Hao Wang", "Wei Guo", "Yong Liu", "Yawen Li", "Yuyang Ye", "Junping Du", "Enhong Chen"], "abstract": "Interactive recommendation is a typical information-seeking task that allows users to interactively express their needs through natural language and obtain personalized recommendations. Large language model-powered (LLM-powered) agents have become a new paradigm in interactive recommendations, effectively capturing users' real-time needs and enhancing personalized experiences. However, due to limited planning and generalization capabilities, existing formulations of LLM-powered interactive recommender agents struggle to effectively address diverse and complex user intents, such as intuitive, unrefined, or occasionally ambiguous requests. To tackle this challenge, we propose a novel thought-augmented interactive recommender agent system (TAIRA) that addresses complex user intents through distilled thought patterns. Specifically, TAIRA is designed as an LLM-powered multi-agent system featuring a manager agent that orchestrates recommendation tasks by decomposing user needs and planning subtasks, with its planning capacity strengthened through Thought Pattern Distillation (TPD), a thought-augmentation method that extracts high-level thoughts from the agent's and human experts' experiences. Moreover, we designed a set of user simulation schemes to generate personalized queries of different difficulties and evaluate the recommendations based on specific datasets. Through comprehensive experiments conducted across multiple datasets, TAIRA exhibits significantly enhanced performance compared to existing methods. Notably, TAIRA shows a greater advantage on more challenging tasks while generalizing effectively on novel tasks, further validating its superiority in managing complex user intents within interactive recommendation systems. The code is publicly available at:", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.23485.pdf", "abstract_url": "https://arxiv.org/abs/2506.23485", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为TAIRA的新型思维增强交互推荐代理系统，旨在通过提炼思维模式解决复杂用户意图，提升LLM驱动的交互推荐代理的性能。", "motivation": "现有的LLM驱动的交互推荐代理由于规划和泛化能力有限，难以有效处理多样化和复杂的用户意图，如直观、未精炼或偶尔模糊的请求。", "method": "TAIRA是一个LLM驱动的多代理系统，包含一个管理者代理，通过分解用户需求和规划子任务来协调推荐任务，其规划能力通过思维模式提炼（TPD）得到加强。TPD是一种从代理和人类专家经验中提取高级思维的思维增强方法。", "result": "通过在多个数据集上进行的综合实验，TAIRA表现出比现有方法显著增强的性能，尤其是在更具挑战性的任务上显示出更大的优势，并能有效泛化到新任务上。", "conclusion": "TAIRA在交互推荐系统中管理复杂用户意图方面显示出优越性，其代码已公开。"}}
{"id": "2506.22445", "title": "Hierarchical Adversarially-Resilient Multi-Agent Reinforcement Learning for Cyber-Physical Systems Security", "authors": ["Saad Alqithami"], "abstract": "Cyber-Physical Systems play a critical role in the infrastructure of various sectors, including manufacturing, energy distribution, and autonomous transportation systems. However, their increasing connectivity renders them highly vulnerable to sophisticated cyber threats, such as adaptive and zero-day attacks, against which traditional security methods like rule-based intrusion detection and single-agent reinforcement learning prove insufficient. To overcome these challenges, this paper introduces a novel Hierarchical Adversarially-Resilient Multi-Agent Reinforcement Learning (HAMARL) framework. HAMARL employs a hierarchical structure consisting of local agents dedicated to subsystem security and a global coordinator that oversees and optimizes comprehensive, system-wide defense strategies. Furthermore, the framework incorporates an adversarial training loop designed to simulate and anticipate evolving cyber threats, enabling proactive defense adaptation. Extensive experimental evaluations conducted on a simulated industrial IoT testbed indicate that HAMARL substantially outperforms traditional multi-agent reinforcement learning approaches, significantly improving attack detection accuracy, reducing response times, and ensuring operational continuity. The results underscore the effectiveness of combining hierarchical multi-agent coordination with adversarially-aware training to enhance the resilience and security of next-generation CPS.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.22445.pdf", "abstract_url": "https://arxiv.org/abs/2506.22445", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Cryptography and Security (cs.CR)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新颖的分层对抗性弹性多智能体强化学习（HAMARL）框架，旨在提高网络物理系统（CPS）的安全性，通过分层结构和对抗性训练循环来模拟和预测不断变化的网络威胁，从而显著提高攻击检测准确性和减少响应时间。", "motivation": "网络物理系统（CPS）在各行业基础设施中扮演着关键角色，但其日益增长的连通性使其极易受到复杂网络威胁的攻击，传统的安全方法如基于规则的入侵检测和单智能体强化学习已显得不足。", "method": "HAMARL框架采用分层结构，包括致力于子系统安全的本地智能体和一个监督并优化全系统防御策略的全局协调器，并结合了对抗性训练循环来模拟和预测不断变化的网络威胁。", "result": "在模拟的工业物联网测试平台上进行的广泛实验评估表明，HAMARL显著优于传统的多智能体强化学习方法，显著提高了攻击检测准确性，减少了响应时间，并确保了操作的连续性。", "conclusion": "结果表明，将分层多智能体协调与对抗性意识训练相结合，可以有效增强下一代CPS的弹性和安全性。"}}
{"id": "2506.23610", "title": "Evaluating the Simulation of Human Personality-Driven Susceptibility to Misinformation with LLMs", "authors": ["Manuel Pratelli", "Marinella Petrocchi"], "abstract": "Large language models (LLMs) make it possible to generate synthetic behavioural data at scale, offering an ethical and low-cost alternative to human experiments. Whether such data can faithfully capture psychological differences driven by personality traits, however, remains an open question. We evaluate the capacity of LLM agents, conditioned on Big-Five profiles, to reproduce personality-based variation in susceptibility to misinformation, focusing on news discernment, the ability to judge true headlines as true and false headlines as false. Leveraging published datasets in which human participants with known personality profiles rated headline accuracy, we create matching LLM agents and compare their responses to the original human patterns. Certain trait-misinformation associations, notably those involving Agreeableness and Conscientiousness, are reliably replicated, whereas others diverge, revealing systematic biases in how LLMs internalize and express personality. The results underscore both the promise and the limits of personality-aligned LLMs for behavioral simulation, and offer new insight into modeling cognitive diversity in artificial agents.", "subjects": "Computation and Language (cs.CL); Computers and Society (cs.CY)", "comments": "pre-print version - paper actually under submission", "pdf_url": "https://arxiv.org/pdf/2506.23610.pdf", "abstract_url": "https://arxiv.org/abs/2506.23610", "categories": ["Computation and Language (cs.CL)", "Computers and Society (cs.CY)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文评估了基于大五人格特征的LLM代理在模拟人类因人格特质而对错误信息易感性方面的能力，发现某些特质与错误信息的关联可以可靠复制，而其他则显示出LLM在内部化和表达人格时的系统性偏差。", "motivation": "探讨LLM生成的合成行为数据是否能准确捕捉由人格特质驱动的心理差异，特别是在错误信息易感性方面。", "method": "利用已知人格特征的人类参与者在评估新闻标题准确性时的数据集，创建匹配的LLM代理，并将其反应与原始人类模式进行比较。", "result": "某些特质（如宜人性和尽责性）与错误信息的关联可以可靠复制，而其他特质则显示出LLM在内部化和表达人格时的系统性偏差。", "conclusion": "结果强调了人格对齐的LLM在行为模拟中的潜力和限制，并为在人工代理中建模认知多样性提供了新的见解。"}}
{"id": "2506.23667", "title": "L0: Reinforcement Learning to Become General Agents", "authors": ["Junjie Zhang", "Jingyi Xi", "Zhuoyang Song", "Junyu Lu", "Yuhua Ke", "Ting Sun", "Yukun Yang", "Jiaxing Zhang", "Songxin Zhang", "Zejian Xie"], "abstract": "Training large language models (LLMs) to act as autonomous agents for multi-turn, long-horizon tasks remains significant challenges in scalability and training efficiency. To address this, we introduce L-Zero (L0), a scalable, end-to-end training pipeline for general-purpose agents. Featuring a low-cost, extensible, and sandboxed concurrent agent worker pool, L0 lowers the barrier for applying reinforcement learning in complex environments. We also introduce NB-Agent, the agent scaffold within L0, which operates in a \"code-as-action\" fashion via a Read-Eval-Print-Loop (REPL). We evaluate L0 on factuality question-answering benchmarks. Our experiments demonstrate that a base model can develop robust problem-solving skills using solely Reinforcement Learning with Verifiable Rewards (RLVR). On the Qwen2.5-7B-Instruct model, our method boosts accuracy on SimpleQA from 30 % to 80 % and on HotpotQA from 22 % to 41 %. We have open-sourced the entire L0 system, including our L0 series models, the NB-Agent, a complete training pipeline, and the corresponding training recipes on (", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.23667.pdf", "abstract_url": "https://arxiv.org/abs/2506.23667", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了L-Zero（L0），一个可扩展的端到端训练管道，用于训练大型语言模型（LLMs）作为自主代理执行多轮、长视距任务。通过引入低成本的、可扩展的、沙盒化的并发代理工作池和NB-Agent代理框架，L0降低了在复杂环境中应用强化学习的门槛。实验表明，该方法在事实性问答基准上显著提高了模型的准确性。", "motivation": "解决大型语言模型（LLMs）在作为自主代理执行多轮、长视距任务时面临的可扩展性和训练效率的挑战。", "method": "引入了L-Zero（L0）训练管道和NB-Agent代理框架，采用“代码即行动”的方式通过Read-Eval-Print-Loop（REPL）操作，并使用可验证奖励的强化学习（RLVR）进行训练。", "result": "在Qwen2.5-7B-Instruct模型上，该方法将SimpleQA的准确率从30%提高到80%，HotpotQA的准确率从22%提高到41%。", "conclusion": "L0系统及其方法显著提高了模型在复杂任务中的性能，且整个系统已开源，包括L0系列模型、NB-Agent、完整的训练管道和相应的训练配方。"}}
{"id": "2506.23329", "title": "IR3D-Bench: Evaluating Vision-Language Model Scene Understanding as Agentic Inverse Rendering", "authors": ["Parker Liu", "Chenxin Li", "Zhengxin Li", "Yipeng Wu", "Wuyang Li", "Zhiqin Yang", "Zhenyuan Zhang", "Yunlong Lin", "Sirui Han", "Brandon Y. Feng"], "abstract": "Vision-language models (VLMs) excel at descriptive tasks, but whether they truly understand scenes from visual observations remains uncertain. We introduce IR3D-Bench, a benchmark challenging VLMs to demonstrate understanding through active creation rather than passive recognition. Grounded in the analysis-by-synthesis paradigm, IR3D-Bench tasks Vision-Language Agents (VLAs) with actively using programming and rendering tools to recreate the underlying 3D structure of an input image, achieving agentic inverse rendering through tool use. This \"understanding-by-creating\" approach probes the tool-using generative capacity of VLAs, moving beyond the descriptive or conversational capacity measured by traditional scene understanding benchmarks. We provide a comprehensive suite of metrics to evaluate geometric accuracy, spatial relations, appearance attributes, and overall plausibility. Initial experiments on agentic inverse rendering powered by various state-of-the-art VLMs highlight current limitations, particularly in visual precision rather than basic tool usage. IR3D-Bench, including data and evaluation protocols, is released to facilitate systematic study and development of tool-using VLAs towards genuine scene understanding by creating.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2506.23329.pdf", "abstract_url": "https://arxiv.org/abs/2506.23329", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "IR3D-Bench是一个评估视觉语言模型（VLMs）通过主动创造而非被动识别来展示场景理解能力的基准。它基于分析-合成范式，要求视觉语言代理（VLAs）使用编程和渲染工具重新创建输入图像的底层3D结构，实现代理逆向渲染。", "motivation": "当前视觉语言模型在描述性任务上表现出色，但它们是否真正从视觉观察中理解场景仍不确定。本文旨在通过主动创造而非被动识别来评估VLMs的场景理解能力。", "method": "IR3D-Bench通过要求VLAs使用工具进行代理逆向渲染，即重新创建输入图像的3D结构，来评估其场景理解能力。提供了一套全面的评估指标，包括几何准确性、空间关系、外观属性和整体合理性。", "result": "初步实验显示，当前最先进的VLMs在视觉精度而非基本工具使用上存在局限性。", "conclusion": "IR3D-Bench的发布旨在促进对工具使用VLAs的系统研究和开发，以实现通过创造达到真正的场景理解。"}}
{"id": "2506.23998", "title": "Auto-TA: Towards Scalable Automated Thematic Analysis (TA) via Multi-Agent Large Language Models with Reinforcement Learning", "authors": ["Seungjun Yi", "Joakim Nguyen", "Huimin Xu", "Terence Lim", "Andrew Well", "Mia Markey", "Ying Ding"], "abstract": "Congenital heart disease (CHD) presents complex, lifelong challenges often underrepresented in traditional clinical metrics. While unstructured narratives offer rich insights into patient and caregiver experiences, manual thematic analysis (TA) remains labor-intensive and unscalable. We propose a fully automated large language model (LLM) pipeline that performs end-to-end TA on clinical narratives, which eliminates the need for manual coding or full transcript review. Our system employs a novel multi-agent framework, where specialized LLM agents assume roles to enhance theme quality and alignment with human analysis. To further improve thematic relevance, we optionally integrate reinforcement learning from human feedback (RLHF). This supports scalable, patient-centered analysis of large qualitative datasets and allows LLMs to be fine-tuned for specific clinical contexts.", "subjects": "Computation and Language (cs.CL)", "comments": "Presented at ACL 2025 SRW", "pdf_url": "https://arxiv.org/pdf/2506.23998.pdf", "abstract_url": "https://arxiv.org/abs/2506.23998", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为Auto-TA的自动化主题分析方法，利用多智能体大型语言模型（LLM）和强化学习（RLHF）技术，旨在解决先天性心脏病（CHD）患者和护理者经验分析中的可扩展性问题。", "motivation": "传统的临床指标难以全面反映先天性心脏病（CHD）患者和护理者的复杂、终身挑战，而无结构的叙述提供了丰富的见解。然而，手动主题分析（TA）既费时又不具备可扩展性。", "method": "研究提出了一种全自动的大型语言模型（LLM）流程，执行端到端的临床叙述主题分析。该系统采用了一种新颖的多智能体框架，其中专门的LLM智能体承担角色以提高主题质量并与人类分析对齐。为进一步提升主题相关性，可选地整合了来自人类反馈的强化学习（RLHF）。", "result": "该方法支持对大型定性数据集进行可扩展的、以患者为中心的分析，并允许LLM针对特定的临床上下文进行微调。", "conclusion": "Auto-TA系统通过自动化主题分析，不仅提高了分析效率和质量，还为特定临床环境下的LLM应用提供了新的可能性，从而促进了患者和护理者经验的深入理解。"}}
{"id": "2506.23468", "title": "NavMorph: A Self-Evolving World Model for Vision-and-Language Navigation in Continuous Environments", "authors": ["Xuan Yao", "Junyu Gao", "Changsheng Xu"], "abstract": "Vision-and-Language Navigation in Continuous Environments (VLN-CE) requires agents to execute sequential navigation actions in complex environments guided by natural language instructions. Current approaches often struggle with generalizing to novel environments and adapting to ongoing changes during navigation. Inspired by human cognition, we present NavMorph, a self-evolving world model framework that enhances environmental understanding and decision-making in VLN-CE tasks. NavMorph employs compact latent representations to model environmental dynamics, equipping agents with foresight for adaptive planning and policy refinement. By integrating a novel Contextual Evolution Memory, NavMorph leverages scene-contextual information to support effective navigation while maintaining online adaptability. Extensive experiments demonstrate that our method achieves notable performance improvements on popular VLN-CE benchmarks. Code is available at \\href{", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "Accepted by ICCV 2025", "pdf_url": "https://arxiv.org/pdf/2506.23468.pdf", "abstract_url": "https://arxiv.org/abs/2506.23468", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "NavMorph是一个自演进的世界模型框架，旨在提升视觉与语言导航在连续环境中的环境理解和决策能力。", "motivation": "解决视觉与语言导航在连续环境（VLN-CE）中难以适应新环境和导航过程中持续变化的问题。", "method": "采用紧凑的潜在表示来建模环境动态，结合新颖的上下文进化记忆（Contextual Evolution Memory）来支持有效导航并保持在线适应性。", "result": "在流行的VLN-CE基准测试中实现了显著的性能提升。", "conclusion": "NavMorph通过自演进的世界模型和上下文进化记忆，显著提高了在复杂环境中基于自然语言指令的导航能力。"}}
{"id": "2506.22809", "title": "BayesLoRA: Task-Specific Uncertainty in Low-Rank Adapters", "authors": ["Cooper Doyle"], "abstract": "We propose BayesLoRA, a task-specific uncertainty quantification framework that integrates MC-Dropout into Low-Rank Adapters (LoRA). Unlike general-purpose transformer uncertainty methods, BayesLoRA provides guardrails tailored to downstream workflows, enabling agents to introspect and modulate behavior under uncertainty. We demonstrate mathematically and empirically that LoRA adapters exhibit amplified variance outside fine-tuning distributions, yielding reliable confidence estimates for agentic decision-making.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "13 pages, 3 figures, 1 table", "pdf_url": "https://arxiv.org/pdf/2506.22809.pdf", "abstract_url": "https://arxiv.org/abs/2506.22809", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "BayesLoRA是一种任务特定的不确定性量化框架，它将MC-Dropout集成到低秩适配器（LoRA）中，为下游工作流程提供定制的护栏，使代理能够在不确定性下内省和调节行为。", "motivation": "解决在低秩适配器中量化任务特定不确定性的问题，以支持代理在不确定性下的决策制定。", "method": "将MC-Dropout集成到Low-Rank Adapters（LoRA）中，开发了BayesLoRA框架。", "result": "数学和经验证明，LoRA适配器在微调分布之外表现出放大的方差，为代理决策提供了可靠的置信度估计。", "conclusion": "BayesLoRA为代理在不确定性下的决策提供了有效的工具，具有重要的实际应用价值。"}}
{"id": "2506.22656", "title": "Knowledge-Guided Multi-Agent Framework for Automated Requirements Development: A Vision", "authors": ["Jiangping Huang", "Dongming Jin", "Weisong Sun", "Yang Liu", "Zhi Jin"], "abstract": "This paper envisions a knowledge-guided multi-agent framework named KGMAF for automated requirements development. KGMAF aims to address gaps in current automation systems for SE, which prioritize code development and overlook the complexities of requirements tasks. KGMAF is composed of six specialized agents and an artifact pool to improve efficiency and accuracy. Specifically, KGMAF outlines the functionality, actions, and knowledge of each agent and provides the conceptual design of the artifact pool. Our case study highlights the potential of KGMAF in real-world scenarios. Finally, we outline several research opportunities for implementing and enhancing automated requirements development using multi-agent systems. We believe that KGMAF will play a pivotal role in shaping the future of automated requirements development in the era of LLMs.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.22656.pdf", "abstract_url": "https://arxiv.org/abs/2506.22656", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文设想了一个名为KGMAF的知识引导多代理框架，用于自动化需求开发，旨在解决当前SE自动化系统中忽视需求任务复杂性的问题。", "motivation": "解决当前软件工程(SE)自动化系统在代码开发优先的同时，忽视需求任务复杂性的问题。", "method": "提出了一个由六个专门代理和一个工件池组成的知识引导多代理框架(KGMAF)，详细描述了每个代理的功能、行动和知识，以及工件池的概念设计。", "result": "案例研究展示了KGMAF在现实场景中的潜力，并概述了利用多代理系统实现和增强自动化需求开发的多个研究机会。", "conclusion": "KGMAF将在LLMs时代对自动化需求开发的未来发挥关键作用。"}}
{"id": "2506.23670", "title": "Efficient Interleaved Speech Modeling through Knowledge Distillation", "authors": ["Mohammadmahdi Nouriborji", "Morteza Rohanian"], "abstract": "Current speech language models exceed the size and latency constraints of many deployment environments. We build compact, expressive speech generation models through layer-aligned distillation, matching hidden states, attention maps, and softened logits to compress large multimodal transformers by 3x with minimal loss in performance. We introduce TinyWave, a family of 2B-parameter models for speech-to-speech and interleaved speech-text generation, trained on 50,000 hours of public audio. TinyWave supports (i) speech-only generation using phonetic or expressive tokens and (ii) mixed speech-text continuations. Evaluation on Libri-Light shows TinyWave within 1.4 normalized perplexity points of its teacher. Accuracy on spoken StoryCloze and SALMon reaches 93-97% of the teacher's performance, outperforming size-matched baselines. These models are optimized for deployment on commodity hardware, enabling applications in real-time conversational agents, assistive technologies, and low-resource environments. We release models, training code, and evaluation scripts to support reproducible research on compact, expressive speech generation.", "subjects": "Sound (cs.SD); Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.23670.pdf", "abstract_url": "https://arxiv.org/abs/2506.23670", "categories": ["Sound (cs.SD)", "Computation and Language (cs.CL)", "Audio and Speech Processing (eess.AS)"], "matching_keywords": ["agent"], "AI": {"tldr": "通过知识蒸馏技术，构建了紧凑且表达力强的语音生成模型TinyWave，支持语音到语音和交错语音文本生成，性能接近大型模型，适用于实时对话代理等应用。", "motivation": "解决当前语音语言模型因体积和延迟限制难以在许多部署环境中使用的问题。", "method": "采用层对齐蒸馏技术，匹配隐藏状态、注意力图和软化逻辑，将大型多模态变压器压缩3倍。", "result": "TinyWave在Libri-Light上的性能接近其教师模型，在StoryCloze和SALMon上的准确率达到教师模型的93-97%，优于尺寸匹配的基线。", "conclusion": "TinyWave模型优化了在商品硬件上的部署，支持实时对话代理等应用，并发布了模型和代码以促进可重复研究。"}}
{"id": "2506.22703", "title": "P4OMP: Retrieval-Augmented Prompting for OpenMP Parallelism in Serial Code", "authors": ["Wali Mohammad Abdullah", "Azmain Kabir"], "abstract": "We present P4OMP, a retrieval-augmented framework for transforming serial C/C++ code into OpenMP-annotated parallel code using large language models (LLMs). To our knowledge, this is the first system to apply retrieval-based prompting for OpenMP pragma correctness without model fine-tuning or compiler instrumentation. P4OMP leverages Retrieval-Augmented Generation (RAG) with structured instructional knowledge from OpenMP tutorials to improve the reliability of prompt-driven code generation. By grounding generation in the retrieved context, P4OMP improves syntactic correctness compared to baseline prompting with GPT-3.5-Turbo. We evaluate P4OMP against a baseline, GPT-3.5-Turbo without retrieval, on a comprehensive benchmark of 108 real-world C++ programs drawn from Stack Overflow, PolyBench, and NAS benchmark suites. P4OMP achieves 100% compilation success on all parallelizable cases, while the baseline fails to compile in 20 out of 108 cases. Six cases that rely on non-random-access iterators or thread-unsafe constructs are excluded due to fundamental OpenMP limitations. A detailed analysis demonstrates how P4OMP consistently avoids scoping errors, syntactic misuse, and invalid directive combinations that commonly affect baseline-generated code. We further demonstrate strong runtime scaling across seven compute-intensive benchmarks on an HPC cluster. P4OMP offers a robust, modular pipeline that significantly improves the reliability and applicability of LLM-generated OpenMP code.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.22703.pdf", "abstract_url": "https://arxiv.org/abs/2506.22703", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "P4OMP是一个基于检索增强的框架，利用大型语言模型（LLMs）将串行C/C++代码转换为带有OpenMP注释的并行代码。该系统首次应用基于检索的提示方法，无需模型微调或编译器插装，即可提高OpenMP编译指示的正确性。通过结合检索增强生成（RAG）和OpenMP教程中的结构化知识，P4OMP显著提升了代码生成的可靠性。在108个真实世界的C++程序上进行的评估显示，P4OMP在所有可并行化案例中实现了100%的编译成功率，而基线方法在108个案例中有20个未能编译。P4OMP有效避免了常见的范围错误、语法误用和无效指令组合，展示了在HPC集群上强大的运行时扩展性。", "motivation": "解决将串行代码转换为并行代码时，大型语言模型生成的OpenMP编译指示的正确性和可靠性问题。", "method": "采用检索增强生成（RAG）技术，结合OpenMP教程中的结构化知识，提升提示驱动的代码生成的可靠性。", "result": "在108个真实世界的C++程序上，P4OMP实现了100%的编译成功率，而基线方法在108个案例中有20个未能编译。P4OMP有效避免了常见的范围错误、语法误用和无效指令组合。", "conclusion": "P4OMP提供了一个强大、模块化的流程，显著提高了LLM生成的OpenMP代码的可靠性和适用性，为并行编程提供了新的支持。"}}
{"id": "2506.22706", "title": "General Autonomous Cybersecurity Defense: Learning Robust Policies for Dynamic Topologies and Diverse Attackers", "authors": ["Arun Ramamurthy", "Neil Dhir"], "abstract": "In the face of evolving cyber threats such as malware, ransomware and phishing, autonomous cybersecurity defense (ACD) systems have become essential for real-time threat detection and response with optional human intervention. However, existing ACD systems rely on limiting assumptions, particularly the stationarity of the underlying network dynamics. In real-world scenarios, network topologies can change due to actions taken by attackers or defenders, system failures, or time evolution of networks, leading to failures in the adaptive capabilities of current defense agents. Moreover, many agents are trained on static environments, resulting in overfitting to specific topologies, which hampers their ability to generalize to out-of-distribution network topologies. This work addresses these challenges by exploring methods for developing agents to learn generalizable policies across dynamic network environments -- general ACD (GACD).", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (stat.ML)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.22706.pdf", "abstract_url": "https://arxiv.org/abs/2506.22706", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)", "Machine Learning (stat.ML)"], "matching_keywords": ["agent"], "AI": {"tldr": "面对如恶意软件、勒索软件和钓鱼等不断演变的网络威胁，自主网络安全防御（ACD）系统已成为实时威胁检测和响应的关键，可选人类干预。然而，现有的ACD系统依赖于限制性假设，特别是底层网络动态的静态性。在现实世界场景中，网络拓扑可能因攻击者或防御者的行动、系统故障或网络的时间演变而改变，导致当前防御代理的适应能力失败。此外，许多代理在静态环境中训练，导致对特定拓扑的过度拟合，这阻碍了它们对分布外网络拓扑的泛化能力。这项工作通过探索在动态网络环境中开发代理以学习可泛化策略的方法——通用ACD（GACD），来应对这些挑战。", "motivation": "解决现有自主网络安全防御（ACD）系统在动态网络拓扑和多样化攻击者面前泛化能力不足的问题。", "method": "探索在动态网络环境中开发代理以学习可泛化策略的方法，即通用ACD（GACD）。", "result": "提出了通用ACD（GACD）框架，旨在提高防御代理在动态和多样化网络环境中的适应性和泛化能力。", "conclusion": "通用ACD（GACD）框架为解决现有ACD系统在动态网络拓扑和多样化攻击者面前的局限性提供了新的方向，有望提升网络安全防御的实时性和有效性。"}}
{"id": "2506.23978", "title": "LLM Agents Are the Antidote to Walled Gardens", "authors": ["Samuele Marro", "Philip Torr"], "abstract": "While the Internet's core infrastructure was designed to be open and universal, today's application layer is dominated by closed, proprietary platforms. Open and interoperable APIs require significant investment, and market leaders have little incentive to enable data exchange that could erode their user lock-in. We argue that LLM-based agents fundamentally disrupt this status quo. Agents can automatically translate between data formats and interact with interfaces designed for humans: this makes interoperability dramatically cheaper and effectively unavoidable. We name this shift universal interoperability: the ability for any two digital services to exchange data seamlessly using AI-mediated adapters. Universal interoperability undermines monopolistic behaviours and promotes data portability. However, it can also lead to new security risks and technical debt. Our position is that the ML community should embrace this development while building the appropriate frameworks to mitigate the downsides. By acting now, we can harness AI to restore user freedom and competitive markets without sacrificing security.", "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL); Computers and Society (cs.CY); Social and Information Networks (cs.SI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.23978.pdf", "abstract_url": "https://arxiv.org/abs/2506.23978", "categories": ["Machine Learning (cs.LG)", "Computation and Language (cs.CL)", "Computers and Society (cs.CY)", "Social and Information Networks (cs.SI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文讨论了基于LLM的代理如何通过自动翻译数据格式和与人类设计的界面交互，实现通用互操作性，从而打破封闭平台的垄断，促进数据可移植性，同时也指出了可能带来的安全风险和技术债务。", "motivation": "解决当前互联网应用层由封闭、专有平台主导，缺乏开放和互操作性API的问题。", "method": "利用基于LLM的代理自动翻译数据格式和与人类设计的界面交互，实现通用互操作性。", "result": "通用互操作性可以削弱垄断行为，促进数据可移植性，但也可能带来新的安全风险和技术债务。", "conclusion": "ML社区应拥抱这一发展，同时建立适当的框架以减轻负面影响，利用AI恢复用户自由和竞争市场，同时不牺牲安全性。"}}
{"id": "2506.24019", "title": "Ella: Embodied Social Agents with Lifelong Memory", "authors": ["Hongxin Zhang", "Zheyuan Zhang", "Zeyuan Wang", "Zunzhe Zhang", "Lixing Fang", "Qinhong Zhou", "Chuang Gan"], "abstract": "We introduce Ella, an embodied social agent capable of lifelong learning within a community in a 3D open world, where agents accumulate experiences and acquire knowledge through everyday visual observations and social interactions. At the core of Ella's capabilities is a structured, long-term multimodal memory system that stores, updates, and retrieves information effectively. It consists of a name-centric semantic memory for organizing acquired knowledge and a spatiotemporal episodic memory for capturing multimodal experiences. By integrating this lifelong memory system with foundation models, Ella retrieves relevant information for decision-making, plans daily activities, builds social relationships, and evolves autonomously while coexisting with other intelligent beings in the open world. We conduct capability-oriented evaluations in a dynamic 3D open world where 15 agents engage in social activities for days and are assessed with a suite of unseen controlled evaluations. Experimental results show that Ella can influence, lead, and cooperate with other agents well to achieve goals, showcasing its ability to learn effectively through observation and social interaction. Our findings highlight the transformative potential of combining structured memory systems with foundation models for advancing embodied intelligence. More videos can be found at", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.24019.pdf", "abstract_url": "https://arxiv.org/abs/2506.24019", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "介绍了Ella，一个能够在3D开放世界中通过终身学习积累经验和知识的具身社交代理。Ella的核心能力是一个结构化的长期多模态记忆系统，该系统有效地存储、更新和检索信息。通过将这个终身记忆系统与基础模型集成，Ella能够检索相关信息进行决策、规划日常活动、建立社交关系，并在开放世界中与其他智能生物共存。实验结果表明，Ella能够有效地通过观察和社交互动学习，影响、领导和与其他代理合作以实现目标。", "motivation": "解决如何在3D开放世界中创建能够通过终身学习积累经验和知识的具身社交代理的问题。", "method": "开发了一个结构化的长期多模态记忆系统，包括以名称为中心的语义记忆和时空情景记忆，与基础模型集成，以支持决策制定、日常活动规划和社会关系建立。", "result": "实验结果显示，Ella能够在动态的3D开放世界中有效地通过观察和社交互动学习，影响、领导和与其他代理合作以实现目标。", "conclusion": "结合结构化记忆系统和基础模型具有推动具身智能发展的变革潜力。"}}
{"id": "2506.23023", "title": "Scenario-Based Hierarchical Reinforcement Learning for Automated Driving Decision Making", "authors": ["M. Youssef Abdelhamid", "Lennart Vater", "Zlatan Ajanovic"], "abstract": "Developing decision-making algorithms for highly automated driving systems remains challenging, since these systems have to operate safely in an open and complex environments. Reinforcement Learning (RL) approaches can learn comprehensive decision policies directly from experience and already show promising results in simple driving tasks. However, current approaches fail to achieve generalizability for more complex driving tasks and lack learning efficiency. Therefore, we present Scenario-based Automated Driving Reinforcement Learning (SAD-RL), the first framework that integrates Reinforcement Learning (RL) of hierarchical policy in a scenario-based environment. A high-level policy selects maneuver templates that are evaluated and executed by a low-level control logic. The scenario-based environment allows to control the training experience for the agent and to explicitly introduce challenging, but rate situations into the training process. Our experiments show that an agent trained using the SAD-RL framework can achieve safe behaviour in easy as well as challenging situations efficiently. Our ablation studies confirmed that both HRL and scenario diversity are essential for achieving these results.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "6 pages, 10 figures, submitted to a conference", "pdf_url": "https://arxiv.org/pdf/2506.23023.pdf", "abstract_url": "https://arxiv.org/abs/2506.23023", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于场景的分层强化学习框架（SAD-RL），用于自动化驾驶决策制定，旨在解决复杂环境中自动驾驶系统的安全性和学习效率问题。", "motivation": "开发高度自动化驾驶系统的决策算法面临挑战，因为这些系统需要在开放和复杂的环境中安全运行。现有的强化学习方法在简单驾驶任务中显示出潜力，但在更复杂的任务中缺乏通用性和学习效率。", "method": "提出了SAD-RL框架，该框架在基于场景的环境中集成了分层策略的强化学习。高层策略选择机动模板，由低层控制逻辑评估和执行。通过场景化环境控制训练经验，并明确引入具有挑战性的情况。", "result": "实验表明，使用SAD-RL框架训练的智能体能够在简单和具有挑战性的情况下高效地实现安全行为。消融研究证实，分层强化学习和场景多样性对实现这些结果至关重要。", "conclusion": "SAD-RL框架通过分层策略和场景化训练，有效提高了自动驾驶决策的安全性和学习效率，为复杂环境中的自动化驾驶提供了新的解决方案。"}}
{"id": "2506.23068", "title": "Curious Causality-Seeking Agents Learn Meta Causal World", "authors": ["Zhiyu Zhao", "Haoxuan Li", "Haifeng Zhang", "Jun Wang", "Francesco Faccio", "Jürgen Schmidhuber", "Mengyue Yang"], "abstract": "When building a world model, a common assumption is that the environment has a single, unchanging underlying causal rule, like applying Newton's laws to every situation. In reality, what appears as a drifting causal mechanism is often the manifestation of a fixed underlying mechanism seen through a narrow observational window. This brings about a problem that, when building a world model, even subtle shifts in policy or environment states can alter the very observed causal mechanisms. In this work, we introduce the \\textbf{Meta-Causal Graph} as world models, a minimal unified representation that efficiently encodes the transformation rules governing how causal structures shift across different latent world states. A single Meta-Causal Graph is composed of multiple causal subgraphs, each triggered by meta state, which is in the latent state space. Building on this representation, we introduce a \\textbf{Causality-Seeking Agent} whose objectives are to (1) identify the meta states that trigger each subgraph, (2) discover the corresponding causal relationships by agent curiosity-driven intervention policy, and (3) iteratively refine the Meta-Causal Graph through ongoing curiosity-driven exploration and agent experiences. Experiments on both synthetic tasks and a challenging robot arm manipulation task demonstrate that our method robustly captures shifts in causal dynamics and generalizes effectively to previously unseen contexts.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Applications (stat.AP)", "comments": "33 pages", "pdf_url": "https://arxiv.org/pdf/2506.23068.pdf", "abstract_url": "https://arxiv.org/abs/2506.23068", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Applications (stat.AP)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为“元因果图”的世界模型，用于编码不同潜在世界状态下因果结构变化的转换规则。通过引入“因果寻求代理”，该模型能够识别触发子图的元状态，发现相应的因果关系，并通过好奇心驱动的探索不断优化模型。实验表明，该方法能有效捕捉因果动态变化并泛化到新情境。", "motivation": "解决在构建世界模型时，由于策略或环境状态的细微变化导致观察到的因果机制发生变化的问题。", "method": "引入“元因果图”作为世界模型，结合“因果寻求代理”的好奇心驱动干预策略，识别元状态和因果关系，并迭代优化模型。", "result": "在合成任务和机器人手臂操作任务上的实验证明，该方法能有效捕捉因果动态变化并具有良好的泛化能力。", "conclusion": "提出的元因果图和因果寻求代理方法为解决因果机制变化问题提供了有效途径，具有广泛的应用潜力。"}}
{"id": "2506.23260", "title": "From Prompt Injections to Protocol Exploits: Threats in LLM-Powered AI Agents Workflows", "authors": ["Mohamed Amine Ferrag", "Norbert Tihanyi", "Djallel Hamouda", "Leandros Maglaras", "Merouane Debbah"], "abstract": "Autonomous AI agents powered by large language models (LLMs) with structured function-calling interfaces have dramatically expanded capabilities for real-time data retrieval, complex computation, and multi-step orchestration. Yet, the explosive proliferation of plugins, connectors, and inter-agent protocols has outpaced discovery mechanisms and security practices, resulting in brittle integrations vulnerable to diverse threats. In this survey, we introduce the first unified, end-to-end threat model for LLM-agent ecosystems, spanning host-to-tool and agent-to-agent communications, formalize adversary capabilities and attacker objectives, and catalog over thirty attack techniques. Specifically, we organized the threat model into four domains: Input Manipulation (e.g., prompt injections, long-context hijacks, multimodal adversarial inputs), Model Compromise (e.g., prompt- and parameter-level backdoors, composite and encrypted multi-backdoors, poisoning strategies), System and Privacy Attacks (e.g., speculative side-channels, membership inference, retrieval poisoning, social-engineering simulations), and Protocol Vulnerabilities (e.g., exploits in Model Context Protocol (MCP), Agent Communication Protocol (ACP), Agent Network Protocol (ANP), and Agent-to-Agent (A2A) protocol). For each category, we review representative scenarios, assess real-world feasibility, and evaluate existing defenses. Building on our threat taxonomy, we identify key open challenges and future research directions, such as securing MCP deployments through dynamic trust management and cryptographic provenance tracking; designing and hardening Agentic Web Interfaces; and achieving resilience in multi-agent and federated environments. Our work provides a comprehensive reference to guide the design of robust defense mechanisms and establish best practices for resilient LLM-agent workflows.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": "29 pages, 15 figures, 6 tables", "pdf_url": "https://arxiv.org/pdf/2506.23260.pdf", "abstract_url": "https://arxiv.org/abs/2506.23260", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了第一个统一的、端到端的LLM代理生态系统威胁模型，涵盖了主机到工具和代理到代理的通信，形式化了对手能力和攻击者目标，并分类了三十多种攻击技术。", "motivation": "随着大型语言模型（LLMs）驱动的自主AI代理的快速发展，插件、连接器和代理间协议的激增超过了发现机制和安全实践的发展，导致了脆弱的集成和多样化的威胁。", "method": "研究通过将威胁模型组织成四个领域：输入操纵、模型妥协、系统和隐私攻击以及协议漏洞，对每种攻击技术进行了代表性场景的回顾、现实可行性的评估和现有防御的评估。", "result": "研究为每种威胁类别提供了详细的攻击技术和防御措施，并指出了未来的研究方向，如通过动态信任管理和加密来源跟踪来保护MCP部署。", "conclusion": "本文为设计强大的防御机制和建立弹性LLM代理工作流程的最佳实践提供了全面的参考，旨在指导未来的研究和实践。"}}
{"id": "2506.23164", "title": "Mode Collapse Happens: Evaluating Critical Interactions in Joint Trajectory Prediction Models", "authors": ["Maarten Hugenholtz", "Anna Meszaros", "Jens Kober", "Zlatan Ajanovic"], "abstract": "Autonomous Vehicle decisions rely on multimodal prediction models that account for multiple route options and the inherent uncertainty in human behavior. However, models can suffer from mode collapse, where only the most likely mode is predicted, posing significant safety risks. While existing methods employ various strategies to generate diverse predictions, they often overlook the diversity in interaction modes among agents. Additionally, traditional metrics for evaluating prediction models are dataset-dependent and do not evaluate inter-agent interactions quantitatively. To our knowledge, none of the existing metrics explicitly evaluates mode collapse. In this paper, we propose a novel evaluation framework that assesses mode collapse in joint trajectory predictions, focusing on safety-critical interactions. We introduce metrics for mode collapse, mode correctness, and coverage, emphasizing the sequential dimension of predictions. By testing four multi-agent trajectory prediction models, we demonstrate that mode collapse indeed happens. When looking at the sequential dimension, although prediction accuracy improves closer to interaction events, there are still cases where the models are unable to predict the correct interaction mode, even just before the interaction mode becomes inevitable. We hope that our framework can help researchers gain new insights and advance the development of more consistent and accurate prediction models, thus enhancing the safety of autonomous driving systems.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": "12 pages, 8 figures, submitted to a journal", "pdf_url": "https://arxiv.org/pdf/2506.23164.pdf", "abstract_url": "https://arxiv.org/abs/2506.23164", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新的评估框架，用于评估联合轨迹预测中的模式崩溃问题，重点关注安全关键的交互。通过引入模式崩溃、模式正确性和覆盖率的度量标准，强调了预测的序列维度。测试了四种多智能体轨迹预测模型，证明了模式崩溃确实会发生。", "motivation": "自动驾驶决策依赖于多模态预测模型，这些模型考虑了多种路线选择和人类行为的不确定性。然而，模型可能会遭受模式崩溃，即只预测最可能的模式，这带来了重大的安全风险。现有的方法虽然采用了各种策略来生成多样化的预测，但往往忽视了智能体之间交互模式的多样性。此外，传统的预测模型评估指标依赖于数据集，没有定量评估智能体间的交互。", "method": "本文提出了一种新颖的评估框架，该框架通过引入模式崩溃、模式正确性和覆盖率的度量标准，评估联合轨迹预测中的模式崩溃问题，特别关注安全关键的交互。", "result": "通过测试四种多智能体轨迹预测模型，研究发现模式崩溃确实会发生。在序列维度上，尽管预测准确性在接近交互事件时有所提高，但仍存在模型无法预测正确交互模式的情况，即使在交互模式变得不可避免之前。", "conclusion": "本文提出的框架可以帮助研究人员获得新的见解，推动开发更一致和准确的预测模型，从而提高自动驾驶系统的安全性。"}}
{"id": "2506.23719", "title": "DABstep: Data Agent Benchmark for Multi-step Reasoning", "authors": ["Alex Egg", "Martin Iglesias Goyanes", "Friso Kingma", "Andreu Mora", "Leandro von Werra", "Thomas Wolf"], "abstract": "We introduce DABstep, a novel benchmark for evaluating AI agents on realistic multi-step data analysis tasks. DABstep comprises over 450 real-world challenges derived from a financial analytics platform, requiring models to combine code-based data processing with contextual reasoning over heterogeneous documentation. Each task demands an iterative, multi-step problem-solving approach, testing capabilities in data manipulation, cross-referencing multiple sources, and precise result reporting. The benchmark provides a factoid-style answer format with automatic correctness checks for objective scoring at scale. We evaluate leading LLM-based agents, revealing a substantial performance gap: even the best agent achieves only 14.55% accuracy on the hardest tasks. We detail our benchmark's design, dataset composition, task formulation, evaluation protocol, report baseline results and analyze failure modes. DABstep is released with a public leaderboard and toolkit to accelerate research in autonomous data analysis.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "13 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2506.23719.pdf", "abstract_url": "https://arxiv.org/abs/2506.23719", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "DABstep是一个新颖的基准测试，用于评估AI代理在现实世界多步骤数据分析任务中的表现。它包含450多个来自金融分析平台的真实挑战，要求模型结合基于代码的数据处理和跨异构文档的上下文推理。", "motivation": "解决现有AI代理在多步骤数据分析和复杂问题解决能力评估上的不足，特别是在需要结合数据操作、多源交叉引用和精确结果报告的场景。", "method": "设计了DABstep基准测试，包含多样化的真实世界任务，采用事实型答案格式和自动正确性检查，以客观评分。评估了领先的基于LLM的代理。", "result": "即使在最困难的任务上，表现最佳的代理也仅达到14.55%的准确率，显示出显著的性能差距。", "conclusion": "DABstep通过公共排行榜和工具包的发布，旨在加速自主数据分析领域的研究，揭示了当前AI代理在复杂多步骤推理任务中的局限性。"}}
{"id": "2506.23316", "title": "InfGen: Scenario Generation as Next Token Group Prediction", "authors": ["Zhenghao Peng", "Yuxin Liu", "Bolei Zhou"], "abstract": "Realistic and interactive traffic simulation is essential for training and evaluating autonomous driving systems. However, most existing data-driven simulation methods rely on static initialization or log-replay data, limiting their ability to model dynamic, long-horizon scenarios with evolving agent populations. We propose InfGen, a scenario generation framework that outputs agent states and trajectories in an autoregressive manner. InfGen represents the entire scene as a sequence of tokens, including traffic light signals, agent states, and motion vectors, and uses a transformer model to simulate traffic over time. This design enables InfGen to continuously insert new agents into traffic, supporting infinite scene generation. Experiments demonstrate that InfGen produces realistic, diverse, and adaptive traffic behaviors. Furthermore, reinforcement learning policies trained in InfGen-generated scenarios achieve superior robustness and generalization, validating its utility as a high-fidelity simulation environment for autonomous driving. More information is available at", "subjects": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.23316.pdf", "abstract_url": "https://arxiv.org/abs/2506.23316", "categories": ["Robotics (cs.RO)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "InfGen是一个场景生成框架，通过自回归方式输出代理状态和轨迹，支持无限场景生成，用于自动驾驶训练和评估。", "motivation": "解决现有数据驱动模拟方法在建模动态、长期场景和演化代理群体方面的局限性。", "method": "将整个场景表示为一系列令牌，包括交通灯信号、代理状态和运动向量，并使用变压器模型随时间模拟交通。", "result": "InfGen生成了真实、多样且自适应的交通行为，强化学习策略在其生成的场景中训练显示出更好的鲁棒性和泛化能力。", "conclusion": "InfGen作为一个高保真模拟环境，有效支持自动驾驶系统的训练和评估。"}}
{"id": "2506.23826", "title": "Towards the \"Digital Me\": A vision of authentic Conversational Agents powered by personal Human Digital Twins", "authors": ["Lluís C. Coll", "Martin W. Lauer-Schmaltz", "Philip Cash", "John P. Hansen", "Anja Maier"], "abstract": "Human Digital Twins (HDTs) have traditionally been conceptualized as data-driven models designed to support decision-making across various domains. However, recent advancements in conversational AI open new possibilities for HDTs to function as authentic, interactive digital counterparts of individuals. This paper introduces a novel HDT system architecture that integrates large language models with dynamically updated personal data, enabling it to mirror an individual's conversational style, memories, and behaviors. To achieve this, our approach implements context-aware memory retrieval, neural plasticity-inspired consolidation, and adaptive learning mechanisms, creating a more natural and evolving digital persona. The resulting system does not only replicate an individual's unique conversational style depending on who they are speaking with, but also enriches responses with dynamically captured personal experiences, opinions, and memories. While this marks a significant step toward developing authentic virtual counterparts, it also raises critical ethical concerns regarding privacy, accountability, and the long-term implications of persistent digital identities. This study contributes to the field of HDTs by describing our novel system architecture, demonstrating its capabilities, and discussing future directions and emerging challenges to ensure the responsible and ethical development of HDTs.", "subjects": "Emerging Technologies (cs.ET); Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Human-Computer Interaction (cs.HC); Information Retrieval (cs.IR)", "comments": "24 pages, 9 figures", "pdf_url": "https://arxiv.org/pdf/2506.23826.pdf", "abstract_url": "https://arxiv.org/abs/2506.23826", "categories": ["Emerging Technologies (cs.ET)", "Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)", "Human-Computer Interaction (cs.HC)", "Information Retrieval (cs.IR)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新型的人类数字孪生（HDT）系统架构，该架构集成了大型语言模型和动态更新的个人数据，旨在创建能够反映个人对话风格、记忆和行为的真实交互式数字对应物。", "motivation": "解决传统人类数字孪生在决策支持方面的局限性，探索其在作为个人真实交互式数字对应物方面的潜力。", "method": "采用上下文感知记忆检索、神经可塑性启发的巩固和自适应学习机制，构建一个更自然和进化的数字人格。", "result": "开发的系统不仅能够根据对话对象复制个人的独特对话风格，还能通过动态捕捉的个人经历、意见和记忆丰富回应。", "conclusion": "这项研究在推动真实虚拟对应物发展方面迈出了重要一步，同时也提出了关于隐私、责任和持久数字身份长期影响的伦理问题，强调了负责任和伦理发展HDTs的重要性。"}}
