{"id": "2505.24156", "title": "Towards a Generalizable Bimanual Foundation Policy via Flow-based Video Prediction", "authors": ["Chenyou Fan", "Fangzheng Yan", "Chenjia Bai", "Jiepeng Wang", "Chi Zhang", "Zhen Wang", "Xuelong Li"], "abstract": "Learning a generalizable bimanual manipulation policy is extremely challenging for embodied agents due to the large action space and the need for coordinated arm movements. Existing approaches rely on Vision-Language-Action (VLA) models to acquire bimanual policies. However, transferring knowledge from single-arm datasets or pre-trained VLA models often fails to generalize effectively, primarily due to the scarcity of bimanual data and the fundamental differences between single-arm and bimanual manipulation. In this paper, we propose a novel bimanual foundation policy by fine-tuning the leading text-to-video models to predict robot trajectories and training a lightweight diffusion policy for action generation. Given the lack of embodied knowledge in text-to-video models, we introduce a two-stage paradigm that fine-tunes independent text-to-flow and flow-to-video models derived from a pre-trained text-to-video model. Specifically, optical flow serves as an intermediate variable, providing a concise representation of subtle movements between images. The text-to-flow model predicts optical flow to concretize the intent of language instructions, and the flow-to-video model leverages this flow for fine-grained video prediction. Our method mitigates the ambiguity of language in single-stage text-to-video prediction and significantly reduces the robot-data requirement by avoiding direct use of low-level actions. In experiments, we collect high-quality manipulation data for real dual-arm robot, and the results of simulation and real-world experiments demonstrate the effectiveness of our method.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.24156.pdf", "abstract_url": "https://arxiv.org/abs/2505.24156", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Robotics (cs.RO)"], "matching_keywords": ["agent"]}
{"id": "2505.24238", "title": "MIRAGE: Assessing Hallucination in Multimodal Reasoning Chains of MLLM", "authors": ["Bowen Dong", "Minheng Ni", "Zitong Huang", "Guanglei Yang", "Wangmeng Zuo", "Lei Zhang"], "abstract": "Multimodal hallucination in multimodal large language models (MLLMs) restricts the correctness of MLLMs. However, multimodal hallucinations are multi-sourced and arise from diverse causes. Existing benchmarks fail to adequately distinguish between perception-induced hallucinations and reasoning-induced hallucinations. This failure constitutes a significant issue and hinders the diagnosis of multimodal reasoning failures within MLLMs. To address this, we propose the {\\dataset} benchmark, which isolates reasoning hallucinations by constructing questions where input images are correctly perceived by MLLMs yet reasoning errors persist. {\\dataset} introduces multi-granular evaluation metrics: accuracy, factuality, and LLMs hallucination score for hallucination quantification. Our analysis reveals that (1) the model scale, data scale, and training stages significantly affect the degree of logical, fabrication, and factual hallucinations; (2) current MLLMs show no effective improvement on spatial hallucinations caused by misinterpreted spatial relationships, indicating their limited visual reasoning capabilities; and (3) question types correlate with distinct hallucination patterns, highlighting targeted challenges and potential mitigation strategies. To address these challenges, we propose {\\method}, a method that combines curriculum reinforcement fine-tuning to encourage models to generate logic-consistent reasoning chains by stepwise reducing learning difficulty, and collaborative hint inference to reduce reasoning complexity. {\\method} establishes a baseline on {\\dataset}, and reduces the logical hallucinations in original base models.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.24238.pdf", "abstract_url": "https://arxiv.org/abs/2505.24238", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"]}
{"id": "2505.23885", "title": "OWL: Optimized Workforce Learning for General Multi-Agent Assistance in Real-World Task Automation", "authors": ["Mengkang Hu", "Yuhang Zhou", "Wendong Fan", "Yuzhou Nie", "Bowei Xia", "Tao Sun", "Ziyu Ye", "Zhaoxuan Jin", "Yingru Li", "Qiguang Chen", "Zeyu Zhang", "Yifeng Wang", "Qianshuo Ye", "Bernard Ghanem", "Ping Luo", "Guohao Li"], "abstract": "Large Language Model (LLM)-based multi-agent systems show promise for automating real-world tasks but struggle to transfer across domains due to their domain-specific nature. Current approaches face two critical shortcomings: they require complete architectural redesign and full retraining of all components when applied to new domains. We introduce Workforce, a hierarchical multi-agent framework that decouples strategic planning from specialized execution through a modular architecture comprising: (i) a domain-agnostic Planner for task decomposition, (ii) a Coordinator for subtask management, and (iii) specialized Workers with domain-specific tool-calling capabilities. This decoupling enables cross-domain transferability during both inference and training phases: During inference, Workforce seamlessly adapts to new domains by adding or modifying worker agents; For training, we introduce Optimized Workforce Learning (OWL), which improves generalization across domains by optimizing a domain-agnostic planner with reinforcement learning from real-world feedback. To validate our approach, we evaluate Workforce on the GAIA benchmark, covering various realistic, multi-domain agentic tasks. Experimental results demonstrate Workforce achieves open-source state-of-the-art performance (69.70%), outperforming commercial systems like OpenAI's Deep Research by 2.34%. More notably, our OWL-trained 32B model achieves 52.73% accuracy (+16.37%) and demonstrates performance comparable to GPT-4o on challenging tasks. To summarize, by enabling scalable generalization and modular domain transfer, our work establishes a foundation for the next generation of general-purpose AI assistants.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.23885.pdf", "abstract_url": "https://arxiv.org/abs/2505.23885", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"]}
{"id": "2505.23946", "title": "Lessons Learned: A Multi-Agent Framework for Code LLMs to Learn and Improve", "authors": ["Yuanzhe Liu", "Ryan Deng", "Tim Kaler", "Xuhao Chen", "Charles E. Leiserson", "Yao Ma", "Jie Chen"], "abstract": "Recent studies show that LLMs possess different skills and specialize in different tasks. In fact, we observe that their varied performance occur in several levels of granularity. For example, in the code optimization task, code LLMs excel at different optimization categories and no one dominates others. This observation prompts the question of how one leverages multiple LLM agents to solve a coding problem without knowing their complementary strengths a priori. We argue that a team of agents can learn from each other's successes and failures so as to improve their own performance. Thus, a lesson is the knowledge produced by an agent and passed on to other agents in the collective solution process. We propose a lesson-based collaboration framework, design the lesson solicitation--banking--selection mechanism, and demonstrate that a team of small LLMs with lessons learned can outperform a much larger LLM and other multi-LLM collaboration methods.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multiagent Systems (cs.MA); Software Engineering (cs.SE)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23946.pdf", "abstract_url": "https://arxiv.org/abs/2505.23946", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)", "Software Engineering (cs.SE)"], "matching_keywords": ["agent"]}
{"id": "2505.23950", "title": "InterMT: Multi-Turn Interleaved Preference Alignment with Human Feedback", "authors": ["Boyuan Chen", "Donghai Hong", "Jiaming Ji", "Jiacheng Zheng", "Bowen Dong", "Jiayi Zhou", "Kaile Wang", "Juntao Dai", "Xuyao Wang", "Wenqi Chen", "Qirui Zheng", "Wenxin Li", "Sirui Han", "Yike Guo", "Yaodong Yang"], "abstract": "As multimodal large models (MLLMs) continue to advance across challenging tasks, a key question emerges: What essential capabilities are still missing? A critical aspect of human learning is continuous interaction with the environment -- not limited to language, but also involving multimodal understanding and generation. To move closer to human-level intelligence, models must similarly support multi-turn, multimodal interaction. In particular, they should comprehend interleaved multimodal contexts and respond coherently in ongoing exchanges. In this work, we present an initial exploration through the InterMT -- the first preference dataset for multi-turn multimodal interaction, grounded in real human feedback. In this exploration, we particularly emphasize the importance of human oversight, introducing expert annotations to guide the process, motivated by the fact that current MLLMs lack such complex interactive capabilities. InterMT captures human preferences at both global and local levels into nine sub-dimensions, consists of 15.6k prompts, 52.6k multi-turn dialogue instances, and 32.4k human-labeled preference pairs. To compensate for the lack of capability for multi-modal understanding and generation, we introduce an agentic workflow that leverages tool-augmented MLLMs to construct multi-turn QA instances. To further this goal, we introduce InterMT-Bench to assess the ability of MLLMs in assisting judges with multi-turn, multimodal tasks. We demonstrate the utility of \\InterMT through applications such as judge moderation and further reveal the multi-turn scaling law of judge model. We hope the open-source of our data can help facilitate further research on aligning current MLLMs to the next step. Our project website can be found at", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23950.pdf", "abstract_url": "https://arxiv.org/abs/2505.23950", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"]}
{"id": "2505.23990", "title": "Multi-RAG: A Multimodal Retrieval-Augmented Generation System for Adaptive Video Understanding", "authors": ["Mingyang Mao", "Mariela M. Perez-Cabarcas", "Utteja Kallakuri", "Nicholas R. Waytowich", "Xiaomin Lin", "Tinoosh Mohsenin"], "abstract": "To effectively engage in human society, the ability to adapt, filter information, and make informed decisions in ever-changing situations is critical. As robots and intelligent agents become more integrated into human life, there is a growing opportunity-and need-to offload the cognitive burden on humans to these systems, particularly in dynamic, information-rich scenarios.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23990.pdf", "abstract_url": "https://arxiv.org/abs/2505.23990", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "@RAG"]}
{"id": "2505.24073", "title": "mRAG: Elucidating the Design Space of Multi-modal Retrieval-Augmented Generation", "authors": ["Chan-Wei Hu", "Yueqi Wang", "Shuo Xing", "Chia-Ju Chen", "Zhengzhong Tu"], "abstract": "Large Vision-Language Models (LVLMs) have made remarkable strides in multimodal tasks such as visual question answering, visual grounding, and complex reasoning. However, they remain limited by static training data, susceptibility to hallucinations, and inability to verify claims against up-to-date, external evidence, compromising their performance in dynamic real-world applications. Retrieval-Augmented Generation (RAG) offers a practical solution to mitigate these challenges by allowing the LVLMs to access large-scale knowledge databases via retrieval mechanisms, thereby grounding model outputs in factual, contextually relevant information. Here in this paper, we conduct the first systematic dissection of the multimodal RAG pipeline for LVLMs, explicitly investigating (1) the retrieval phase: on the modality configurations and retrieval strategies, (2) the re-ranking stage: on strategies to mitigate positional biases and improve the relevance of retrieved evidence, and (3) the generation phase: we further investigate how to best integrate retrieved candidates into the final generation process. Finally, we extend to explore a unified agentic framework that integrates re-ranking and generation through self-reflection, enabling LVLMs to select relevant evidence and suppress irrelevant context dynamically. Our full-stack exploration of RAG for LVLMs yields substantial insights, resulting in an average performance boost of 5% without any fine-tuning.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "16 pages, 11 figures", "pdf_url": "https://arxiv.org/pdf/2505.24073.pdf", "abstract_url": "https://arxiv.org/abs/2505.24073", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic", "@RAG"]}
{"id": "2505.24197", "title": "Learning API Functionality from Demonstrations for Tool-based Agents", "authors": ["Bhrij Patel", "Ashish Jagmohan", "Aditya Vempaty"], "abstract": "Digital tool-based agents that invoke external Application Programming Interfaces (APIs) often rely on documentation to understand API functionality. However, such documentation is frequently missing, outdated, privatized, or inconsistent-hindering the development of reliable, general-purpose agents. In this work, we propose learning API functionality directly from demonstrations as a new paradigm applicable in scenarios without documentation. Using existing API benchmarks, we collect demonstrations from both expert API-based agents and from self-exploration. To understand what information demonstrations must convey for successful task completion, we extensively study how the number of demonstrations and the use of LLM-generated summaries and evaluations affect the task success rate of the API-based agent. Our experiments across 3 datasets and 5 models show that learning functionality from demonstrations remains a non-trivial challenge, even for state-of-the-art LLMs. We find that providing explicit function calls and natural language critiques significantly improves the agent's task success rate due to more accurate parameter filling. We analyze failure modes, identify sources of error, and highlight key open challenges for future work in documentation-free, self-improving, API-based agents.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "18 Pages, 13 Figures, 5 Tables", "pdf_url": "https://arxiv.org/pdf/2505.24197.pdf", "abstract_url": "https://arxiv.org/abs/2505.24197", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.24201", "title": "SentinelAgent: Graph-based Anomaly Detection in Multi-Agent Systems", "authors": ["Xu He", "Di Wu", "Yan Zhai", "Kun Sun"], "abstract": "The rise of large language model (LLM)-based multi-agent systems (MAS) introduces new security and reliability challenges. While these systems show great promise in decomposing and coordinating complex tasks, they also face multi-faceted risks across prompt manipulation, unsafe tool usage, and emergent agent miscoordination. Existing guardrail mechanisms offer only partial protection, primarily at the input-output level, and fall short in addressing systemic or multi-point failures in MAS. In this work, we present a system-level anomaly detection framework tailored for MAS, integrating structural modeling with runtime behavioral oversight. Our approach consists of two components. First, we propose a graph-based framework that models agent interactions as dynamic execution graphs, enabling semantic anomaly detection at node, edge, and path levels. Second, we introduce a pluggable SentinelAgent, an LLM-powered oversight agent that observes, analyzes, and intervenes in MAS execution based on security policies and contextual reasoning. By bridging abstract detection logic with actionable enforcement, our method detects not only single-point faults and prompt injections but also multi-agent collusion and latent exploit paths. We validate our framework through two case studies, including an email assistant and Microsoft's Magentic-One system, demonstrating its ability to detect covert risks and provide explainable root-cause attribution. Our work lays the foundation for more trustworthy, monitorable, and secure agent-based AI ecosystems.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.24201.pdf", "abstract_url": "https://arxiv.org/abs/2505.24201", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"]}
{"id": "2505.24226", "title": "E^2GraphRAG: Streamlining Graph-based RAG for High Efficiency and Effectiveness", "authors": ["Yibo Zhao", "Jiapeng Zhu", "Ye Guo", "Kangkang He", "Xiang Li"], "abstract": "Graph-based RAG methods like GraphRAG have shown promising global understanding of the knowledge base by constructing hierarchical entity graphs. However, they often suffer from inefficiency and rely on manually pre-defined query modes, limiting practical use. In this paper, we propose E^2GraphRAG, a streamlined graph-based RAG framework that improves both Efficiency and Effectiveness. During the indexing stage, E^2GraphRAG constructs a summary tree with large language models and an entity graph with SpaCy based on document chunks. We then construct bidirectional indexes between entities and chunks to capture their many-to-many relationships, enabling fast lookup during both local and global retrieval. For the retrieval stage, we design an adaptive retrieval strategy that leverages the graph structure to retrieve and select between local and global modes. Experiments show that E^2GraphRAG achieves up to 10 times faster indexing than GraphRAG and 100 times speedup over LightRAG in retrieval while maintaining competitive QA performance.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "16 pages", "pdf_url": "https://arxiv.org/pdf/2505.24226.pdf", "abstract_url": "https://arxiv.org/abs/2505.24226", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"]}
{"id": "2505.23789", "title": "Conversational Exploration of Literature Landscape with LitChat", "authors": ["Mingyu Huang", "Shasha Zhou", "Yuxuan Chen", "Ke Li"], "abstract": "We are living in an era of \"big literature\", where the volume of digital scientific publications is growing exponentially. While offering new opportunities, this also poses challenges for understanding literature landscapes, as traditional manual reviewing is no longer feasible. Recent large language models (LLMs) have shown strong capabilities for literature comprehension, yet they are incapable of offering \"comprehensive, objective, open and transparent\" views desired by systematic reviews due to their limited context windows and trust issues like hallucinations. Here we present LitChat, an end-to-end, interactive and conversational literature agent that augments LLM agents with data-driven discovery tools to facilitate literature exploration. LitChat automatically interprets user queries, retrieves relevant sources, constructs knowledge graphs, and employs diverse data-mining techniques to generate evidence-based insights addressing user needs. We illustrate the effectiveness of LitChat via a case study on AI4Health, highlighting its capacity to quickly navigate the users through large-scale literature landscape with data-based evidence that is otherwise infeasible with traditional means.", "subjects": "Computation and Language (cs.CL); Information Retrieval (cs.IR); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23789.pdf", "abstract_url": "https://arxiv.org/abs/2505.23789", "categories": ["Computation and Language (cs.CL)", "Information Retrieval (cs.IR)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"]}
{"id": "2505.23794", "title": "R3-RAG: Learning Step-by-Step Reasoning and Retrieval for LLMs via Reinforcement Learning", "authors": ["Yuan Li", "Qi Luo", "Xiaonan Li", "Bufan Li", "Qinyuan Cheng", "Bo Wang", "Yining Zheng", "Yuxin Wang", "Zhangyue Yin", "Xipeng Qiu"], "abstract": "Retrieval-Augmented Generation (RAG) integrates external knowledge with Large Language Models (LLMs) to enhance factual correctness and mitigate hallucination. However, dense retrievers often become the bottleneck of RAG systems due to their limited parameters compared to LLMs and their inability to perform step-by-step reasoning. While prompt-based iterative RAG attempts to address these limitations, it is constrained by human-designed workflows. To address these limitations, we propose $\\textbf{R3-RAG}$, which uses $\\textbf{R}$einforcement learning to make the LLM learn how to $\\textbf{R}$eason and $\\textbf{R}$etrieve step by step, thus retrieving comprehensive external knowledge and leading to correct answers. R3-RAG is divided into two stages. We first use cold start to make the model learn the manner of iteratively interleaving reasoning and retrieval. Then we use reinforcement learning to further harness its ability to better explore the external retrieval environment. Specifically, we propose two rewards for R3-RAG: 1) answer correctness for outcome reward, which judges whether the trajectory leads to a correct answer; 2) relevance-based document verification for process reward, encouraging the model to retrieve documents that are relevant to the user question, through which we can let the model learn how to iteratively reason and retrieve relevant documents to get the correct answer. Experimental results show that R3-RAG significantly outperforms baselines and can transfer well to different retrievers. We release R3-RAG at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23794.pdf", "abstract_url": "https://arxiv.org/abs/2505.23794", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"]}
{"id": "2505.24442", "title": "RMoA: Optimizing Mixture-of-Agents through Diversity Maximization and Residual Compensation", "authors": ["Zhentao Xie", "Chengcheng Han", "Jinxin Shi", "Wenjun Cui", "Xin Zhao", "Xingjiao Wu", "Jiabao Zhao"], "abstract": "Although multi-agent systems based on large language models show strong capabilities on multiple tasks, they are still limited by high computational overhead, information loss, and robustness. Inspired by ResNet's residual learning, we propose Residual Mixture-of-Agents (RMoA), integrating residual connections to optimize efficiency and reliability. To maximize information utilization from model responses while minimizing computational costs, we innovatively design an embedding-based diversity selection mechanism that greedily selects responses via vector similarity. Furthermore, to mitigate iterative information degradation, we introduce a Residual Extraction Agent to preserve cross-layer incremental information by capturing inter-layer response differences, coupled with a Residual Aggregation Agent for hierarchical information integration. Additionally, we propose an adaptive termination mechanism that dynamically halts processing based on residual convergence, further improving inference efficiency. RMoA achieves state-of-the-art performance on the benchmarks of across alignment, mathematical reasoning, code generation, and multitasking understanding, while significantly reducing computational overhead. Code is available at", "subjects": "Artificial Intelligence (cs.AI)", "comments": "Accepted by ACL 2025 (Findings)", "pdf_url": "https://arxiv.org/pdf/2505.24442.pdf", "abstract_url": "https://arxiv.org/abs/2505.24442", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.23815", "title": "Aligning LLMs by Predicting Preferences from User Writing Samples", "authors": ["Stéphane Aroca-Ouellette", "Natalie Mackraz", "Barry-John Theobald", "Katherine Metcalf"], "abstract": "Accommodating human preferences is essential for creating aligned LLM agents that deliver personalized and effective interactions. Recent work has shown the potential for LLMs acting as writing agents to infer a description of user preferences. Agent alignment then comes from conditioning on the inferred preference description. However, existing methods often produce generic preference descriptions that fail to capture the unique and individualized nature of human preferences. This paper introduces PROSE, a method designed to enhance the precision of preference descriptions inferred from user writing samples. PROSE incorporates two key elements: (1) iterative refinement of inferred preferences, and (2) verification of inferred preferences across multiple user writing samples. We evaluate PROSE with several LLMs (i.e., Qwen2.5 7B and 72B Instruct, GPT-mini, and GPT-4o) on a summarization and an email writing task. We find that PROSE more accurately infers nuanced human preferences, improving the quality of the writing agent's generations over CIPHER (a state-of-the-art method for inferring preferences) by 33\\%. Lastly, we demonstrate that ICL and PROSE are complementary methods, and combining them provides up to a 9\\% improvement over ICL alone.", "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.23815.pdf", "abstract_url": "https://arxiv.org/abs/2505.23815", "categories": ["Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"]}
{"id": "2505.23823", "title": "RAGPPI: RAG Benchmark for Protein-Protein Interactions in Drug Discovery", "authors": ["Youngseung Jeon", "Ziwen Li", "Thomas Li", "JiaSyuan Chang", "Morteza Ziyadi", "Xiang 'Anthony' Chen"], "abstract": "Retrieving the biological impacts of protein-protein interactions (PPIs) is essential for target identification (Target ID) in drug development. Given the vast number of proteins involved, this process remains time-consuming and challenging. Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) frameworks have supported Target ID; however, no benchmark currently exists for identifying the biological impacts of PPIs. To bridge this gap, we introduce the RAG Benchmark for PPIs (RAGPPI), a factual question-answer benchmark of 4,420 question-answer pairs that focus on the potential biological impacts of PPIs. Through interviews with experts, we identified criteria for a benchmark dataset, such as a type of QA and source. We built a gold-standard dataset (500 QA pairs) through expert-driven data annotation. We developed an ensemble auto-evaluation LLM that reflected expert labeling characteristics, which facilitates the construction of a silver-standard dataset (3,720 QA pairs). We are committed to maintaining RAGPPI as a resource to support the research community in advancing RAG systems for drug discovery QA solutions.", "subjects": "Computation and Language (cs.CL)", "comments": "17 pages, 4 figures, 8 tables", "pdf_url": "https://arxiv.org/pdf/2505.23823.pdf", "abstract_url": "https://arxiv.org/abs/2505.23823", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"]}
{"id": "2505.24785", "title": "EXP-Bench: Can AI Conduct AI Research Experiments?", "authors": ["Patrick Tser Jern Kon", "Jiachen Liu", "Xinyi Zhu", "Qiuyi Ding", "Jingjia Peng", "Jiarong Xing", "Yibo Huang", "Yiming Qiu", "Jayanth Srinivasa", "Myungjin Lee", "Mosharaf Chowdhury", "Matei Zaharia", "Ang Chen"], "abstract": "Automating AI research holds immense potential for accelerating scientific progress, yet current AI agents struggle with the complexities of rigorous, end-to-end experimentation. We introduce EXP-Bench, a novel benchmark designed to systematically evaluate AI agents on complete research experiments sourced from influential AI publications. Given a research question and incomplete starter code, EXP-Bench challenges AI agents to formulate hypotheses, design and implement experimental procedures, execute them, and analyze results. To enable the creation of such intricate and authentic tasks with high-fidelity, we design a semi-autonomous pipeline to extract and structure crucial experimental details from these research papers and their associated open-source code. With the pipeline, EXP-Bench curated 461 AI research tasks from 51 top-tier AI research papers. Evaluations of leading LLM-based agents, such as OpenHands and IterativeAgent on EXP-Bench demonstrate partial capabilities: while scores on individual experimental aspects such as design or implementation correctness occasionally reach 20-35%, the success rate for complete, executable experiments was a mere 0.5%. By identifying these bottlenecks and providing realistic step-by-step experiment procedures, EXP-Bench serves as a vital tool for future AI agents to improve their ability to conduct AI research experiments. EXP-Bench is open-sourced at", "subjects": "Artificial Intelligence (cs.AI)", "comments": "45 pages, 13 figures", "pdf_url": "https://arxiv.org/pdf/2505.24785.pdf", "abstract_url": "https://arxiv.org/abs/2505.24785", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.24878", "title": "Open CaptchaWorld: A Comprehensive Web-based Platform for Testing and Benchmarking Multimodal LLM Agents", "authors": ["Yaxin Luo", "Zhaoyi Li", "Jiacheng Liu", "Jiacheng Cui", "Xiaohan Zhao", "Zhiqiang Shen"], "abstract": "CAPTCHAs have been a critical bottleneck for deploying web agents in real-world applications, often blocking them from completing end-to-end automation tasks. While modern multimodal LLM agents have demonstrated impressive performance in static perception tasks, their ability to handle interactive, multi-step reasoning challenges like CAPTCHAs is largely untested. To address this gap, we introduce Open CaptchaWorld, the first web-based benchmark and platform specifically designed to evaluate the visual reasoning and interaction capabilities of MLLM-powered agents through diverse and dynamic CAPTCHA puzzles. Our benchmark spans 20 modern CAPTCHA types, totaling 225 CAPTCHAs, annotated with a new metric we propose: CAPTCHA Reasoning Depth, which quantifies the number of cognitive and motor steps required to solve each puzzle. Experimental results show that humans consistently achieve near-perfect scores, state-of-the-art MLLM agents struggle significantly, with success rates at most 40.0% by Browser-Use Openai-o3, far below human-level performance, 93.3%. This highlights Open CaptchaWorld as a vital benchmark for diagnosing the limits of current multimodal agents and guiding the development of more robust multimodal reasoning systems. Code and Data are available at this https URL.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.24878.pdf", "abstract_url": "https://arxiv.org/abs/2505.24878", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Computer Vision and Pattern Recognition (cs.CV)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"]}
{"id": "2505.18334", "title": "Towards Natural Language Communication for Cooperative Autonomous Driving via Self-Play", "authors": ["Jiaxun Cui", "Chen Tang", "Jarrett Holtz", "Janice Nguyen", "Alessandro G. Allievi", "Hang Qiu", "Peter Stone"], "abstract": "Past work has demonstrated that autonomous vehicles can drive more safely if they communicate with one another than if they do not. However, their communication has often not been human-understandable. Using natural language as a vehicle-to-vehicle (V2V) communication protocol offers the potential for autonomous vehicles to drive cooperatively not only with each other but also with human drivers. In this work, we propose a suite of traffic tasks in autonomous driving where vehicles in a traffic scenario need to communicate in natural language to facilitate coordination in order to avoid an imminent collision and/or support efficient traffic flow. To this end, this paper introduces a novel method, LLM+Debrief, to learn a message generation and high-level decision-making policy for autonomous vehicles through multi-agent discussion. To evaluate LLM agents for driving, we developed a gym-like simulation environment that contains a range of driving scenarios. Our experimental results demonstrate that LLM+Debrief is more effective at generating meaningful and human-understandable natural language messages to facilitate cooperation and coordination than a zero-shot LLM agent. Our code and demo videos are available at", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18334.pdf", "abstract_url": "https://arxiv.org/abs/2505.18334", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"]}
{"id": "2505.23780", "title": "More-than-Human Storytelling: Designing Longitudinal Narrative Engagements with Generative AI", "authors": ["Émilie Fabre", "Katie Seaborn", "Shuta Koiwai", "Mizuki Watanabe", "Paul Riesch"], "abstract": "Longitudinal engagement with generative AI (GenAI) storytelling agents is a timely but less charted domain. We explored multi-generational experiences with \"Dreamsmithy,\" a daily dream-crafting app, where participants (N = 28) co-created stories with AI narrator \"Makoto\" every day. Reflections and interactions were captured through a two-week diary study. Reflexive thematic analysis revealed themes likes \"oscillating ambivalence\" and \"socio-chronological bonding,\" highlighting the complex dynamics that emerged between individuals and the AI narrator over time. Findings suggest that while people appreciated the personal notes, opportunities for reflection, and AI creativity, limitations in narrative coherence and control occasionally caused frustration. The results underscore the potential of GenAI for longitudinal storytelling, but also raise critical questions about user agency and ethics. We contribute initial empirical insights and design considerations for developing adaptive, more-than-human storytelling systems.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Sound (cs.SD); Audio and Speech Processing (eess.AS)", "comments": "CHI EA '25", "pdf_url": "https://arxiv.org/pdf/2505.23780.pdf", "abstract_url": "https://arxiv.org/abs/2505.23780", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)", "Sound (cs.SD)", "Audio and Speech Processing (eess.AS)"], "matching_keywords": ["agent"]}
{"id": "2505.23833", "title": "Benchmarking Abstract and Reasoning Abilities Through A Theoretical Perspective", "authors": ["Qingchuan Ma", "Yuhang Wu", "Xiawu Zheng", "Rongrong Ji"], "abstract": "In this paper, we aim to establish a simple, effective, and theoretically grounded benchmark for rigorously probing abstract reasoning in Large Language Models (LLMs). To achieve this, we first develop a mathematic framework that defines abstract reasoning as the ability to: (i) extract essential patterns independent of surface representations, and (ii) apply consistent rules to these abstract patterns. Based on this framework, we introduce two novel complementary metrics: \\(\\scoreGamma\\) measures basic reasoning accuracy, while \\(\\scoreDelta\\) quantifies a model's reliance on specific symbols rather than underlying patterns - a key indicator of true abstraction versus mere memorization. To implement this measurement, we design a benchmark: systematic symbol remapping in rule-based tasks, which forces models to demonstrate genuine pattern recognition beyond superficial token matching. Extensive LLM evaluations using this benchmark (commercial API models, 7B-70B, multi-agent) reveal:1) critical limitations in non-decimal arithmetic and symbolic reasoning; 2) persistent abstraction gaps despite chain-of-thought prompting; and 3) \\(\\scoreDelta\\)'s effectiveness in robustly measuring memory dependence by quantifying performance degradation under symbol remapping, particularly highlighting operand-specific memorization. These findings underscore that current LLMs, despite domain-specific strengths, still lack robust abstract reasoning, highlighting key areas for future improvement.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23833.pdf", "abstract_url": "https://arxiv.org/abs/2505.23833", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2505.23836", "title": "Large Language Models Often Know When They Are Being Evaluated", "authors": ["Joe Needham", "Giles Edkins", "Govind Pimpale", "Henning Bartsch", "Marius Hobbhahn"], "abstract": "If AI models can detect when they are being evaluated, the effectiveness of evaluations might be compromised. For example, models could have systematically different behavior during evaluations, leading to less reliable benchmarks for deployment and governance decisions. We investigate whether frontier language models can accurately classify transcripts based on whether they originate from evaluations or real-world deployment, a capability we call evaluation awareness. To achieve this, we construct a diverse benchmark of 1,000 prompts and transcripts from 61 distinct datasets. These span public benchmarks (e.g., MMLU, SWEBench), real-world deployment interactions, and agent trajectories from scaffolding frameworks (e.g., web-browsing agents). Frontier models clearly demonstrate above-random evaluation awareness (Gemini-2.5-Pro reaches an AUC of $0.83$), but do not yet surpass our simple human baseline (AUC of $0.92$). Furthermore, both AI models and humans are better at identifying evaluations in agentic settings compared to chat settings. Additionally, we test whether models can identify the purpose of the evaluation. Under multiple-choice and open-ended questioning, AI models far outperform random chance in identifying what an evaluation is testing for. Our results indicate that frontier models already exhibit a substantial, though not yet superhuman, level of evaluation-awareness. We recommend tracking this capability in future models.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23836.pdf", "abstract_url": "https://arxiv.org/abs/2505.23836", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"]}
{"id": "2505.23837", "title": "CoMaPOI: A Collaborative Multi-Agent Framework for Next POI Prediction Bridging the Gap Between Trajectory and Language", "authors": ["Lin Zhong", "Lingzhi Wang", "Xu Yang", "Qing Liao"], "abstract": "Large Language Models (LLMs) offer new opportunities for the next Point-Of-Interest (POI) prediction task, leveraging their capabilities in semantic understanding of POI trajectories. However, previous LLM-based methods, which are superficially adapted to next POI prediction, largely overlook critical challenges associated with applying LLMs to this task. Specifically, LLMs encounter two critical challenges: (1) a lack of intrinsic understanding of numeric spatiotemporal data, which hinders accurate modeling of users' spatiotemporal distributions and preferences; and (2) an excessively large and unconstrained candidate POI space, which often results in random or irrelevant predictions. To address these issues, we propose a Collaborative Multi Agent Framework for Next POI Prediction, named CoMaPOI. Through the close interaction of three specialized agents (Profiler, Forecaster, and Predictor), CoMaPOI collaboratively addresses the two critical challenges. The Profiler agent is responsible for converting numeric data into language descriptions, enhancing semantic understanding. The Forecaster agent focuses on dynamically constraining and refining the candidate POI space. The Predictor agent integrates this information to generate high-precision predictions. Extensive experiments on three benchmark datasets (NYC, TKY, and CA) demonstrate that CoMaPOI achieves state of the art performance, improving all metrics by 5% to 10% compared to SOTA baselines. This work pioneers the investigation of challenges associated with applying LLMs to complex spatiotemporal tasks by leveraging tailored collaborative agents.", "subjects": "Computation and Language (cs.CL); Information Retrieval (cs.IR)", "comments": "This paper has been accepted by SIGIR 2025", "pdf_url": "https://arxiv.org/pdf/2505.23837.pdf", "abstract_url": "https://arxiv.org/abs/2505.23837", "categories": ["Computation and Language (cs.CL)", "Information Retrieval (cs.IR)"], "matching_keywords": ["agent"]}
{"id": "2505.23846", "title": "Scalable, Symbiotic, AI and Non-AI Agent Based Parallel Discrete Event Simulations", "authors": ["Atanu Barai", "Stephan Eidenbenz", "Nandakishore Santhi"], "abstract": "To fully leverage the potential of artificial intelligence (AI) systems in a trustworthy manner, it is desirable to couple multiple AI and non-AI systems together seamlessly for constraining and ensuring correctness of the output. This paper introduces a novel parallel discrete event simulation (PDES) based methodology to combine multiple AI and non-AI agents in a causal, rule-based way. Our approach tightly integrates the concept of passage of time, with each agent considered as an entity in the PDES framework and responding to prior requests from other agents. Such coupling mechanism enables the agents to work in a co-operative environment towards a common goal while many tasks run in parallel throughout the simulation. It further enables setting up boundaries to the outputs of the AI agents by applying necessary dynamic constraints using non-AI agents while allowing for scalability through deployment of hundreds of such agents in a larger compute cluster. Distributing smaller AI agents can enable extremely scalable simulations in the future, addressing local memory bottlenecks for model parameter storage. Within a PDES involving both AI and non-AI agents, we break down the problem at hand into structured steps, when necessary, providing a set of multiple choices to the AI agents, and then progressively solve these steps towards a final goal. At each step, the non-AI agents act as unbiased auditors, verifying each action by the AI agents so that certain rules of engagement are followed. We evaluate our approach by solving four problems from four different domains and comparing the results with those from AI models alone. Our results show greater accuracy in solving problems from various domains where the AI models struggle to solve the problems solely by themselves. Results show that overall accuracy of our approach is 68% where as the accuracy of vanilla models is less than 23%.", "subjects": "Computation and Language (cs.CL); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23846.pdf", "abstract_url": "https://arxiv.org/abs/2505.23846", "categories": ["Computation and Language (cs.CL)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"]}
{"id": "2505.23852", "title": "Large Language Model-Based Agents for Automated Research Reproducibility: An Exploratory Study in Alzheimer's Disease", "authors": ["Nic Dobbins", "Christelle Xiong", "Kristine Lan", "Meliha Yetisgen"], "abstract": "Objective: To demonstrate the capabilities of Large Language Models (LLMs) as autonomous agents to reproduce findings of published research studies using the same or similar dataset.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA); Applications (stat.AP)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23852.pdf", "abstract_url": "https://arxiv.org/abs/2505.23852", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)", "Applications (stat.AP)"], "matching_keywords": ["agent"]}
{"id": "2505.24787", "title": "Draw ALL Your Imagine: A Holistic Benchmark and Agent Framework for Complex Instruction-based Image Generation", "authors": ["Yucheng Zhou", "Jiahao Yuan", "Qianning Wang"], "abstract": "Recent advancements in text-to-image (T2I) generation have enabled models to produce high-quality images from textual descriptions. However, these models often struggle with complex instructions involving multiple objects, attributes, and spatial relationships. Existing benchmarks for evaluating T2I models primarily focus on general text-image alignment and fail to capture the nuanced requirements of complex, multi-faceted prompts. Given this gap, we introduce LongBench-T2I, a comprehensive benchmark specifically designed to evaluate T2I models under complex instructions. LongBench-T2I consists of 500 intricately designed prompts spanning nine diverse visual evaluation dimensions, enabling a thorough assessment of a model's ability to follow complex instructions. Beyond benchmarking, we propose an agent framework (Plan2Gen) that facilitates complex instruction-driven image generation without requiring additional model training. This framework integrates seamlessly with existing T2I models, using large language models to interpret and decompose complex prompts, thereby guiding the generation process more effectively. As existing evaluation metrics, such as CLIPScore, fail to adequately capture the nuances of complex instructions, we introduce an evaluation toolkit that automates the quality assessment of generated images using a set of multi-dimensional metrics. The data and code are released at", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.24787.pdf", "abstract_url": "https://arxiv.org/abs/2505.24787", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2505.23803", "title": "MultiPhishGuard: An LLM-based Multi-Agent System for Phishing Email Detection", "authors": ["Yinuo Xue", "Eric Spero", "Yun Sing Koh", "Giovanni Russello"], "abstract": "Phishing email detection faces critical challenges from evolving adversarial tactics and heterogeneous attack patterns. Traditional detection methods, such as rule-based filters and denylists, often struggle to keep pace with these evolving tactics, leading to false negatives and compromised security. While machine learning approaches have improved detection accuracy, they still face challenges adapting to novel phishing strategies. We present MultiPhishGuard, a dynamic LLM-based multi-agent detection system that synergizes specialized expertise with adversarial-aware reinforcement learning. Our framework employs five cooperative agents (text, URL, metadata, explanation simplifier, and adversarial agents) with automatically adjusted decision weights powered by a Proximal Policy Optimization reinforcement learning algorithm. To address emerging threats, we introduce an adversarial training loop featuring an adversarial agent that generates subtle context-aware email variants, creating a self-improving defense ecosystem and enhancing system robustness. Experimental evaluations on public datasets demonstrate that MultiPhishGuard significantly outperforms Chain-of-Thoughts, single-agent baselines and state-of-the-art detectors, as validated by ablation studies and comparative analyses. Experiments demonstrate that MultiPhishGuard achieves high accuracy (97.89\\%) with low false positive (2.73\\%) and false negative rates (0.20\\%). Additionally, we incorporate an explanation simplifier agent, which provides users with clear and easily understandable explanations for why an email is classified as phishing or legitimate. This work advances phishing defense through dynamic multi-agent collaboration and generative adversarial resilience.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23803.pdf", "abstract_url": "https://arxiv.org/abs/2505.23803", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.23805", "title": "ADA: Automated Moving Target Defense for AI Workloads via Ephemeral Infrastructure-Native Rotation in Kubernetes", "authors": ["Akram Sheriff", "Ken Huang", "Zsolt Nemeth", "Madjid Nakhjiri"], "abstract": "This paper introduces the Adaptive Defense Agent (ADA), an innovative Automated Moving Target Defense (AMTD) system designed to fundamentally enhance the security posture of AI workloads. ADA operates by continuously and automatically rotating these workloads at the infrastructure level, leveraging the inherent ephemerality of Kubernetes pods. This constant managed churn systematically invalidates attacker assumptions and disrupts potential kill chains by regularly destroying and respawning AI service instances. This methodology, applying principles of chaos engineering as a continuous, proactive defense, offers a paradigm shift from traditional static defenses that rely on complex and expensive confidential or trusted computing solutions to secure the underlying compute platforms, while at the same time agnostically supporting the latest advancements in agentic and nonagentic AI ecosystems and solutions such as agent-to-agent (A2A) communication frameworks or model context protocols (MCP). This AI-native infrastructure design, relying on the widely proliferated cloud-native Kubernetes technologies, facilitates easier deployment, simplifies maintenance through an inherent zero trust posture achieved by rotation, and promotes faster adoption. We posit that ADA's novel approach to AMTD provides a more robust, agile, and operationally efficient zero-trust model for AI services, achieving security through proactive environmental manipulation rather than reactive patching.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23805.pdf", "abstract_url": "https://arxiv.org/abs/2505.23805", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"]}
{"id": "2505.23923", "title": "ChARM: Character-based Act-adaptive Reward Modeling for Advanced Role-Playing Language Agents", "authors": ["Feiteng Fang", "Ting-En Lin", "Yuchuan Wu", "Xiong Liu", "Xiang Huang", "Dingwei Chen", "Jing Ye", "Haonan Zhang", "Liang Zhu", "Hamid Alinejad-Rokny", "Min Yang", "Fei Huang", "Yongbin Li"], "abstract": "Role-Playing Language Agents (RPLAs) aim to simulate characters for realistic and engaging human-computer interactions. However, traditional reward models often struggle with scalability and adapting to subjective conversational preferences. We propose ChARM, a Character-based Act-adaptive Reward Model, addressing these challenges through two innovations: (1) an act-adaptive margin that significantly enhances learning efficiency and generalizability, and (2) a self-evolution mechanism leveraging large-scale unlabeled data to improve training coverage. Additionally, we introduce RoleplayPref, the first large-scale preference dataset specifically for RPLAs, featuring 1,108 characters, 13 subcategories, and 16,888 bilingual dialogues, alongside RoleplayEval, a dedicated evaluation benchmark. Experimental results show a 13% improvement over the conventional Bradley-Terry model in preference rankings. Furthermore, applying ChARM-generated rewards to preference learning techniques (e.g., direct preference optimization) achieves state-of-the-art results on CharacterEval and RoleplayEval. Code and dataset are available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23923.pdf", "abstract_url": "https://arxiv.org/abs/2505.23923", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.23944", "title": "Retrieval Augmented Generation based Large Language Models for Causality Mining", "authors": ["Thushara Manjari Naduvilakandy", "Hyeju Jang", "Mohammad Al Hasan"], "abstract": "Causality detection and mining are important tasks in information retrieval due to their enormous use in information extraction, and knowledge graph construction. To solve these tasks, in existing literature there exist several solutions -- both unsupervised and supervised. However, the unsupervised methods suffer from poor performance and they often require significant human intervention for causal rule selection, leading to poor generalization across different domains. On the other hand, supervised methods suffer from the lack of large training datasets. Recently, large language models (LLMs) with effective prompt engineering are found to be effective to overcome the issue of unavailability of large training dataset. Yet, in existing literature, there does not exist comprehensive works on causality detection and mining using LLM prompting. In this paper, we present several retrieval-augmented generation (RAG) based dynamic prompting schemes to enhance LLM performance in causality detection and extraction tasks. Extensive experiments over three datasets and five LLMs validate the superiority of our proposed RAG-based dynamic prompting over other static prompting schemes.", "subjects": "Computation and Language (cs.CL)", "comments": "13 pages, 6 figures, published in knowledgeNLP-NAACL2025", "pdf_url": "https://arxiv.org/pdf/2505.23944.pdf", "abstract_url": "https://arxiv.org/abs/2505.23944", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"]}
{"id": "2505.24838", "title": "VideoCAD: A Large-Scale Video Dataset for Learning UI Interactions and 3D Reasoning from CAD Software", "authors": ["Brandon Man", "Ghadi Nehme", "Md Ferdous Alam", "Faez Ahmed"], "abstract": "Computer-Aided Design (CAD) is a time-consuming and complex process, requiring precise, long-horizon user interactions with intricate 3D interfaces. While recent advances in AI-driven user interface (UI) agents show promise, most existing datasets and methods focus on short, low-complexity tasks in mobile or web applications, failing to capture the demands of professional engineering tools. In this work, we introduce VideoCAD, the first attempt at engineering UI interaction learning for precision tasks. Specifically, VideoCAD is a large-scale synthetic dataset consisting of over 41K annotated video recordings of CAD operations, generated using an automated framework for collecting high-fidelity UI action data from human-made CAD designs. Compared to existing datasets, VideoCAD offers an order of magnitude higher complexity in UI interaction learning for real-world engineering tasks, having up to a 20x longer time horizon than other datasets. We show two important downstream applications of VideoCAD: learning UI interactions from professional precision 3D CAD tools and a visual question-answering (VQA) benchmark designed to evaluate multimodal large language models' (LLM) spatial reasoning and video understanding abilities. To learn the UI interactions, we propose VideoCADFormer - a state-of-the-art model in learning CAD interactions directly from video, which outperforms multiple behavior cloning baselines. Both VideoCADFormer and the VQA benchmark derived from VideoCAD reveal key challenges in the current state of video-based UI understanding, including the need for precise action grounding, multi-modal and spatial reasoning, and long-horizon dependencies.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.24838.pdf", "abstract_url": "https://arxiv.org/abs/2505.24838", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.24876", "title": "Agent-X: Evaluating Deep Multimodal Reasoning in Vision-Centric Agentic Tasks", "authors": ["Tajamul Ashraf", "Amal Saqib", "Hanan Ghani", "Muhra AlMahri", "Yuhao Li", "Noor Ahsan", "Umair Nawaz", "Jean Lahoud", "Hisham Cholakkal", "Mubarak Shah", "Philip Torr", "Fahad Shahbaz Khan", "Rao Muhammad Anwer", "Salman Khan"], "abstract": "Deep reasoning is fundamental for solving complex tasks, especially in vision-centric scenarios that demand sequential, multimodal understanding. However, existing benchmarks typically evaluate agents with fully synthetic, single-turn queries, limited visual modalities, and lack a framework to assess reasoning quality over multiple steps as required in real-world settings. To address this, we introduce Agent-X, a large-scale benchmark for evaluating vision-centric agents multi-step and deep reasoning capabilities in real-world, multimodal settings. Agent- X features 828 agentic tasks with authentic visual contexts, including images, multi-image comparisons, videos, and instructional text. These tasks span six major agentic environments: general visual reasoning, web browsing, security and surveillance, autonomous driving, sports, and math reasoning. Our benchmark requires agents to integrate tool use with explicit, stepwise decision-making in these diverse settings. In addition, we propose a fine-grained, step-level evaluation framework that assesses the correctness and logical coherence of each reasoning step and the effectiveness of tool usage throughout the task. Our results reveal that even the best-performing models, including GPT, Gemini, and Qwen families, struggle to solve multi-step vision tasks, achieving less than 50% full-chain success. These findings highlight key bottlenecks in current LMM reasoning and tool-use capabilities and identify future research directions in vision-centric agentic reasoning models. Our data and code are publicly available at", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.24876.pdf", "abstract_url": "https://arxiv.org/abs/2505.24876", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"]}
{"id": "2505.23847", "title": "Seven Security Challenges That Must be Solved in Cross-domain Multi-agent LLM Systems", "authors": ["Ronny Ko", "Jiseong Jeong", "Shuyuan Zheng", "Chuan Xiao", "Taewan Kim", "Makoto Onizuka", "Wonyong Shin"], "abstract": "Large language models (LLMs) are rapidly evolving into autonomous agents that cooperate across organizational boundaries, enabling joint disaster response, supply-chain optimization, and other tasks that demand decentralized expertise without surrendering data ownership. Yet, cross-domain collaboration shatters the unified trust assumptions behind current alignment and containment techniques. An agent benign in isolation may, when receiving messages from an untrusted peer, leak secrets or violate policy, producing risks driven by emergent multi-agent dynamics rather than classical software bugs. This position paper maps the security agenda for cross-domain multi-agent LLM systems. We introduce seven categories of novel security challenges, for each of which we also present plausible attacks, security evaluation metrics, and future research guidelines.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23847.pdf", "abstract_url": "https://arxiv.org/abs/2505.23847", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.23857", "title": "DATD3: Depthwise Attention Twin Delayed Deep Deterministic Policy Gradient For Model Free Reinforcement Learning Under Output Feedback Control", "authors": ["Wuhao Wang", "Zhiyong Chen"], "abstract": "Reinforcement learning in real-world applications often involves output-feedback settings, where the agent receives only partial state information. To address this challenge, we propose the Output-Feedback Markov Decision Process (OPMDP), which extends the standard MDP formulation to accommodate decision-making based on observation histories. Building on this framework, we introduce Depthwise Attention Twin Delayed Deep Deterministic Policy Gradient (DATD3), a novel actor-critic algorithm that employs depthwise separable convolution and multi-head attention to encode historical observations. DATD3 maintains policy expressiveness while avoiding the instability of recurrent models. Extensive experiments on continuous control tasks demonstrate that DATD3 outperforms existing memory-based and recurrent baselines under both partial and full observability.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23857.pdf", "abstract_url": "https://arxiv.org/abs/2505.23857", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.23865", "title": "Combining Deep Architectures for Information Gain estimation and Reinforcement Learning for multiagent field exploration", "authors": ["Emanuele Masiero", "Vito Trianni", "Giuseppe Vizzari", "Dimitri Ognibene"], "abstract": "Precision agriculture requires efficient autonomous systems for crop monitoring, where agents must explore large-scale environments while minimizing resource consumption. This work addresses the problem as an active exploration task in a grid environment representing an agricultural field. Each cell may contain targets (e.g., damaged crops) observable from nine predefined points of view (POVs). Agents must infer the number of targets per cell using partial, sequential observations.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "4 pages, presented at RLDM 2025", "pdf_url": "https://arxiv.org/pdf/2505.23865.pdf", "abstract_url": "https://arxiv.org/abs/2505.23865", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.24251", "title": "Proactive Guidance of Multi-Turn Conversation in Industrial Search", "authors": ["Xiaoyu Li", "Xiao Li", "Li Gao", "Yiding Liu", "Xiaoyang Wang", "Shuaiqiang Wang", "Junfeng Wang", "Dawei Yin"], "abstract": "The evolution of Large Language Models (LLMs) has significantly advanced multi-turn conversation systems, emphasizing the need for proactive guidance to enhance users' interactions. However, these systems face challenges in dynamically adapting to shifts in users' goals and maintaining low latency for real-time interactions. In the Baidu Search AI assistant, an industrial-scale multi-turn search system, we propose a novel two-phase framework to provide proactive guidance. The first phase, Goal-adaptive Supervised Fine-Tuning (G-SFT), employs a goal adaptation agent that dynamically adapts to user goal shifts and provides goal-relevant contextual information. G-SFT also incorporates scalable knowledge transfer to distill insights from LLMs into a lightweight model for real-time interaction. The second phase, Click-oriented Reinforcement Learning (C-RL), adopts a generate-rank paradigm, systematically constructs preference pairs from user click signals, and proactively improves click-through rates through more engaging guidance. This dual-phase architecture achieves complementary objectives: G-SFT ensures accurate goal tracking, while C-RL optimizes interaction quality through click signal-driven reinforcement learning. Extensive experiments demonstrate that our framework achieves 86.10% accuracy in offline evaluation (+23.95% over baseline) and 25.28% CTR in online deployment (149.06% relative improvement), while reducing inference latency by 69.55% through scalable knowledge distillation.", "subjects": "Computation and Language (cs.CL); Information Retrieval (cs.IR)", "comments": "ACL'25 (Industry)", "pdf_url": "https://arxiv.org/pdf/2505.24251.pdf", "abstract_url": "https://arxiv.org/abs/2505.24251", "categories": ["Computation and Language (cs.CL)", "Information Retrieval (cs.IR)"], "matching_keywords": ["agent"]}
{"id": "2505.24255", "title": "Effects of Theory of Mind and Prosocial Beliefs on Steering Human-Aligned Behaviors of LLMs in Ultimatum Games", "authors": ["Neemesh Yadav", "Palakorn Achananuparp", "Jing Jiang", "Ee-Peng Lim"], "abstract": "Large Language Models (LLMs) have shown potential in simulating human behaviors and performing theory-of-mind (ToM) reasoning, a crucial skill for complex social interactions. In this study, we investigate the role of ToM reasoning in aligning agentic behaviors with human norms in negotiation tasks, using the ultimatum game as a controlled environment. We initialized LLM agents with different prosocial beliefs (including Greedy, Fair, and Selfless) and reasoning methods like chain-of-thought (CoT) and varying ToM levels, and examined their decision-making processes across diverse LLMs, including reasoning models like o3-mini and DeepSeek-R1 Distilled Qwen 32B. Results from 2,700 simulations indicated that ToM reasoning enhances behavior alignment, decision-making consistency, and negotiation outcomes. Consistent with previous findings, reasoning models exhibit limited capability compared to models with ToM reasoning, different roles of the game benefits with different orders of ToM reasoning. Our findings contribute to the understanding of ToM's role in enhancing human-AI interaction and cooperative decision-making. The code used for our experiments can be found at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)", "comments": "17 pages, 1 figure, 6 tables", "pdf_url": "https://arxiv.org/pdf/2505.24255.pdf", "abstract_url": "https://arxiv.org/abs/2505.24255", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent", "agentic"]}
{"id": "2505.24654", "title": "Black-box Adversarial Attacks on CNN-based SLAM Algorithms", "authors": ["Maria Rafaela Gkeka", "Bowen Sun", "Evgenia Smirni", "Christos D. Antonopoulos", "Spyros Lalis", "Nikolaos Bellas"], "abstract": "Continuous advancements in deep learning have led to significant progress in feature detection, resulting in enhanced accuracy in tasks like Simultaneous Localization and Mapping (SLAM). Nevertheless, the vulnerability of deep neural networks to adversarial attacks remains a challenge for their reliable deployment in applications, such as navigation of autonomous agents. Even though CNN-based SLAM algorithms are a growing area of research there is a notable absence of a comprehensive presentation and examination of adversarial attacks targeting CNN-based feature detectors, as part of a SLAM system. Our work introduces black-box adversarial perturbations applied to the RGB images fed into the GCN-SLAM algorithm. Our findings on the TUM dataset [30] reveal that even attacks of moderate scale can lead to tracking failure in as many as 76% of the frames. Moreover, our experiments highlight the catastrophic impact of attacking depth instead of RGB input images on the SLAM system.", "subjects": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV)", "comments": "9 pages, 8 figures", "pdf_url": "https://arxiv.org/pdf/2505.24654.pdf", "abstract_url": "https://arxiv.org/abs/2505.24654", "categories": ["Robotics (cs.RO)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"]}
{"id": "2505.23953", "title": "Enhancing LLM-Based Code Generation with Complexity Metrics: A Feedback-Driven Approach", "authors": ["Melika Sepidband", "Hamed Taherkhani", "Song Wang", "Hadi Hemmati"], "abstract": "Automatic code generation has gained significant momentum with the advent of Large Language Models (LLMs) such as GPT-4. Although many studies focus on improving the effectiveness of LLMs for code generation, very limited work tries to understand the generated code's characteristics and leverage that to improve failed cases. In this paper, as the most straightforward characteristic of code, we investigate the relationship between code complexity and the success of LLM generated code. Using a large set of standard complexity metrics, we first conduct an empirical analysis to explore their correlation with LLM's performance on code generation (i.e., Pass@1). Using logistic regression models, we identify which complexity metrics are most predictive of code correctness. Building on these findings, we propose an iterative feedback method, where LLMs are prompted to generate correct code based on complexity metrics from previous failed outputs. We validate our approach across multiple benchmarks (i.e., HumanEval, MBPP, LeetCode, and BigCodeBench) and various LLMs (i.e., GPT-4o, GPT-3.5 Turbo, Llama 3.1, and GPT-o3 mini), comparing the results with two baseline methods: (a) zero-shot generation, and (b) iterative execution-based feedback without our code complexity insights. Experiment results show that our approach makes notable improvements, particularly with a smaller LLM (GPT3.5 Turbo), where, e.g., Pass@1 increased by 35.71% compared to the baseline's improvement of 12.5% on the HumanEval dataset. The study expands experiments to BigCodeBench and integrates the method with the Reflexion code generation agent, leading to Pass@1 improvements of 20% (GPT-4o) and 23.07% (GPT-o3 mini). The results highlight that complexity-aware feedback enhances both direct LLM prompting and agent-based workflows.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": "11 pages, 5 figures. Accepted to COMPSAC 2025", "pdf_url": "https://arxiv.org/pdf/2505.23953.pdf", "abstract_url": "https://arxiv.org/abs/2505.23953", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.24331", "title": "Context-Aware Sentiment Forecasting via LLM-based Multi-Perspective Role-Playing Agents", "authors": ["Fanhang Man", "Huandong Wang", "Jianjie Fang", "Zhaoyi Deng", "Baining Zhao", "Xinlei Chen", "Yong Li"], "abstract": "User sentiment on social media reveals the underlying social trends, crises, and needs. Researchers have analyzed users' past messages to trace the evolution of sentiments and reconstruct sentiment dynamics. However, predicting the imminent sentiment of an ongoing event is rarely studied. In this paper, we address the problem of \\textbf{sentiment forecasting} on social media to predict the user's future sentiment in response to the development of the event. We extract sentiment-related features to enhance the modeling skill and propose a multi-perspective role-playing framework to simulate the process of human response. Our preliminary results show significant improvement in sentiment forecasting on both microscopic and macroscopic levels.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.24331.pdf", "abstract_url": "https://arxiv.org/abs/2505.24331", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2505.24354", "title": "Unifying Language Agent Algorithms with Graph-based Orchestration Engine for Reproducible Agent Research", "authors": ["Qianqian Zhang", "Jiajia Liao", "Heting Ying", "Yibo Ma", "Haozhan Shen", "Jingcheng Li", "Peng Liu", "Lu Zhang", "Chunxin Fang", "Kyusong Lee", "Ruochen Xu", "Tiancheng Zhao"], "abstract": "Language agents powered by large language models (LLMs) have demonstrated remarkable capabilities in understanding, reasoning, and executing complex tasks. However, developing robust agents presents significant challenges: substantial engineering overhead, lack of standardized components, and insufficient evaluation frameworks for fair comparison. We introduce Agent Graph-based Orchestration for Reasoning and Assessment (AGORA), a flexible and extensible framework that addresses these challenges through three key contributions: (1) a modular architecture with a graph-based workflow engine, efficient memory management, and clean component abstraction; (2) a comprehensive suite of reusable agent algorithms implementing state-of-the-art reasoning approaches; and (3) a rigorous evaluation framework enabling systematic comparison across multiple dimensions. Through extensive experiments on mathematical reasoning and multimodal tasks, we evaluate various agent algorithms across different LLMs, revealing important insights about their relative strengths and applicability. Our results demonstrate that while sophisticated reasoning approaches can enhance agent capabilities, simpler methods like Chain-of-Thought often exhibit robust performance with significantly lower computational overhead. AGORA not only simplifies language agent development but also establishes a foundation for reproducible agent research through standardized evaluation protocols.", "subjects": "Computation and Language (cs.CL)", "comments": "Accepted by ACL 2025 Demo", "pdf_url": "https://arxiv.org/pdf/2505.24354.pdf", "abstract_url": "https://arxiv.org/abs/2505.24354", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2505.24388", "title": "ClueAnchor: Clue-Anchored Knowledge Reasoning Exploration and Optimization for Retrieval-Augmented Generation", "authors": ["Hao Chen", "Yukun Yan", "Sen Mei", "Wanxiang Che", "Zhenghao Liu", "Qi Shi", "Xinze Li", "Yuchun Fan", "Pengcheng Huang", "Qiushi Xiong", "Zhiyuan Liu", "Maosong Sun"], "abstract": "Retrieval-Augmented Generation (RAG) augments Large Language Models (LLMs) with external knowledge to improve factuality. However, existing RAG systems frequently underutilize the retrieved documents, failing to extract and integrate the key clues needed to support faithful and interpretable reasoning, especially in cases where relevant evidence is implicit, scattered, or obscured by noise. To address this issue, we propose ClueAnchor, a novel framework for enhancing RAG via clue-anchored reasoning exploration and optimization. ClueAnchor extracts key clues from retrieved content and generates multiple reasoning paths based on different knowledge configurations, optimizing the model by selecting the most effective one through reward-based preference optimization. Experiments show that ClueAnchor significantly outperforms prior RAG baselines in reasoning completeness and robustness. Further analysis confirms its strong resilience to noisy or partially relevant retrieved content, as well as its capability to identify supporting evidence even in the absence of explicit clue supervision during inference.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.24388.pdf", "abstract_url": "https://arxiv.org/abs/2505.24388", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"]}
{"id": "2505.23960", "title": "Information Structure in Mappings: An Approach to Learning, Representation, and Generalisation", "authors": ["Henry Conklin"], "abstract": "Despite the remarkable success of large large-scale neural networks, we still lack unified notation for thinking about and describing their representational spaces. We lack methods to reliably describe how their representations are structured, how that structure emerges over training, and what kinds of structures are desirable. This thesis introduces quantitative methods for identifying systematic structure in a mapping between spaces, and leverages them to understand how deep-learning models learn to represent information, what representational structures drive generalisation, and how design decisions condition the structures that emerge. To do this I identify structural primitives present in a mapping, along with information theoretic quantifications of each. These allow us to analyse learning, structure, and generalisation across multi-agent reinforcement learning models, sequence-to-sequence models trained on a single task, and Large Language Models. I also introduce a novel, performant, approach to estimating the entropy of vector space, that allows this analysis to be applied to models ranging in size from 1 million to 12 billion parameters.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "PhD Thesis, 204 pages; entropy estimation discussed from p.94", "pdf_url": "https://arxiv.org/pdf/2505.23960.pdf", "abstract_url": "https://arxiv.org/abs/2505.23960", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2505.24019", "title": "LLM Agents Should Employ Security Principles", "authors": ["Kaiyuan Zhang", "Zian Su", "Pin-Yu Chen", "Elisa Bertino", "Xiangyu Zhang", "Ninghui Li"], "abstract": "Large Language Model (LLM) agents show considerable promise for automating complex tasks using contextual reasoning; however, interactions involving multiple agents and the system's susceptibility to prompt injection and other forms of context manipulation introduce new vulnerabilities related to privacy leakage and system exploitation. This position paper argues that the well-established design principles in information security, which are commonly referred to as security principles, should be employed when deploying LLM agents at scale. Design principles such as defense-in-depth, least privilege, complete mediation, and psychological acceptability have helped guide the design of mechanisms for securing information systems over the last five decades, and we argue that their explicit and conscientious adoption will help secure agentic systems. To illustrate this approach, we introduce AgentSandbox, a conceptual framework embedding these security principles to provide safeguards throughout an agent's life-cycle. We evaluate with state-of-the-art LLMs along three dimensions: benign utility, attack utility, and attack success rate. AgentSandbox maintains high utility for its intended functions under both benign and adversarial evaluations while substantially mitigating privacy risks. By embedding secure design principles as foundational elements within emerging LLM agent protocols, we aim to promote trustworthy agent ecosystems aligned with user privacy expectations and evolving regulatory requirements.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.24019.pdf", "abstract_url": "https://arxiv.org/abs/2505.24019", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"]}
{"id": "2505.24553", "title": "CREFT: Sequential Multi-Agent LLM for Character Relation Extraction", "authors": ["Ye Eun Chun", "Taeyoon Hwang", "Seung-won Hwang", "Byung-Hak Kim"], "abstract": "Understanding complex character relations is crucial for narrative analysis and efficient script evaluation, yet existing extraction methods often fail to handle long-form narratives with nuanced interactions. To address this challenge, we present CREFT, a novel sequential framework leveraging specialized Large Language Model (LLM) agents. First, CREFT builds a base character graph through knowledge distillation, then iteratively refines character composition, relation extraction, role identification, and group assignments. Experiments on a curated Korean drama dataset demonstrate that CREFT significantly outperforms single-agent LLM baselines in both accuracy and completeness. By systematically visualizing character networks, CREFT streamlines narrative comprehension and accelerates script review -- offering substantial benefits to the entertainment, publishing, and educational sectors.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.24553.pdf", "abstract_url": "https://arxiv.org/abs/2505.24553", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.24575", "title": "NexusSum: Hierarchical LLM Agents for Long-Form Narrative Summarization", "authors": ["Hyuntak Kim", "Byung-Hak Kim"], "abstract": "Summarizing long-form narratives--such as books, movies, and TV scripts--requires capturing intricate plotlines, character interactions, and thematic coherence, a task that remains challenging for existing LLMs. We introduce NexusSum, a multi-agent LLM framework for narrative summarization that processes long-form text through a structured, sequential pipeline--without requiring fine-tuning. Our approach introduces two key innovations: (1) Dialogue-to-Description Transformation: A narrative-specific preprocessing method that standardizes character dialogue and descriptive text into a unified format, improving coherence. (2) Hierarchical Multi-LLM Summarization: A structured summarization pipeline that optimizes chunk processing and controls output length for accurate, high-quality summaries. Our method establishes a new state-of-the-art in narrative summarization, achieving up to a 30.0% improvement in BERTScore (F1) across books, movies, and TV scripts. These results demonstrate the effectiveness of multi-agent LLMs in handling long-form content, offering a scalable approach for structured summarization in diverse storytelling domains.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "Accepted to the main track of ACL 2025", "pdf_url": "https://arxiv.org/pdf/2505.24575.pdf", "abstract_url": "https://arxiv.org/abs/2505.24575", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.24613", "title": "When Harry Meets Superman: The Role of The Interlocutor in Persona-Based Dialogue Generation", "authors": ["Daniela Occhipinti", "Marco Guerini", "Malvina Nissim"], "abstract": "Endowing dialogue agents with persona information has proven to significantly improve the consistency and diversity of their generations. While much focus has been placed on aligning dialogues with provided personas, the adaptation to the interlocutor's profile remains largely underexplored. In this work, we investigate three key aspects: (1) a model's ability to align responses with both the provided persona and the interlocutor's; (2) its robustness when dealing with familiar versus unfamiliar interlocutors and topics, and (3) the impact of additional fine-tuning on specific persona-based dialogues. We evaluate dialogues generated with diverse speaker pairings and topics, framing the evaluation as an author identification task and employing both LLM-as-a-judge and human evaluations. By systematically masking or disclosing information about the interlocutor, we assess its impact on dialogue generation. Results show that access to the interlocutor's persona improves the recognition of the target speaker, while masking it does the opposite. Although models generalise well across topics, they struggle with unfamiliar interlocutors. Finally, we found that in zero-shot settings, LLMs often copy biographical details, facilitating identification but trivialising the task.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.24613.pdf", "abstract_url": "https://arxiv.org/abs/2505.24613", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2505.24157", "title": "Don't Just Follow MLLM Plans: Robust and Efficient Planning for Open-world Agents", "authors": ["Seungjoon Lee", "Suhwan Kim", "Minhyeon Oh", "Youngsik Yoon", "Jungseul Ok"], "abstract": "Developing autonomous agents capable of mastering complex, multi-step tasks in unpredictable, interactive environments presents a significant challenge. While Large Language Models (LLMs) offer promise for planning, existing approaches often rely on problematic internal knowledge or make unrealistic environmental assumptions. Although recent work explores learning planning knowledge, they still retain limitations due to partial reliance on external knowledge or impractical setups. Indeed, prior research has largely overlooked developing agents capable of acquiring planning knowledge from scratch, directly in realistic settings. While realizing this capability is necessary, it presents significant challenges, primarily achieving robustness given the substantial risk of incorporating LLMs' inaccurate knowledge. Moreover, efficiency is crucial for practicality as learning can demand prohibitive exploration. In response, we introduce Robust and Efficient Planning for Open-world Agents (REPOA), a novel framework designed to tackle these issues. REPOA features three key components: adaptive dependency learning and fine-grained failure-aware operation memory to enhance robustness to knowledge inaccuracies, and difficulty-based exploration to improve learning efficiency. Our evaluation in two established open-world testbeds demonstrates REPOA's robust and efficient planning, showcasing its capability to successfully obtain challenging late-game items that were beyond the reach of prior approaches.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.24157.pdf", "abstract_url": "https://arxiv.org/abs/2505.24157", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.24671", "title": "Multiple LLM Agents Debate for Equitable Cultural Alignment", "authors": ["Dayeon Ki", "Rachel Rudinger", "Tianyi Zhou", "Marine Carpuat"], "abstract": "Large Language Models (LLMs) need to adapt their predictions to diverse cultural contexts to benefit diverse communities across the world. While previous efforts have focused on single-LLM, single-turn approaches, we propose to exploit the complementary strengths of multiple LLMs to promote cultural adaptability. We introduce a Multi-Agent Debate framework, where two LLM-based agents debate over a cultural scenario and collaboratively reach a final decision. We propose two variants: one where either LLM agents exclusively debate and another where they dynamically choose between self-reflection and debate during their turns. We evaluate these approaches on 7 open-weight LLMs (and 21 LLM combinations) using the NormAd-ETI benchmark for social etiquette norms in 75 countries. Experiments show that debate improves both overall accuracy and cultural group parity over single-LLM baselines. Notably, multi-agent debate enables relatively small LLMs (7-9B) to achieve accuracies comparable to that of a much larger model (27B parameters).", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "37 pages, 18 figures", "pdf_url": "https://arxiv.org/pdf/2505.24671.pdf", "abstract_url": "https://arxiv.org/abs/2505.24671", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.24239", "title": "An Adversary-Resistant Multi-Agent LLM System via Credibility Scoring", "authors": ["Sana Ebrahimi", "Mohsen Dehghankar", "Abolfazl Asudeh"], "abstract": "While multi-agent LLM systems show strong capabilities in various domains, they are highly vulnerable to adversarial and low-performing agents. To resolve this issue, in this paper, we introduce a general and adversary-resistant multi-agent LLM framework based on credibility scoring. We model the collaborative query-answering process as an iterative game, where the agents communicate and contribute to a final system output. Our system associates a credibility score that is used when aggregating the team outputs. The credibility scores are learned gradually based on the past contributions of each agent in query answering. Our experiments across multiple tasks and settings demonstrate our system's effectiveness in mitigating adversarial influence and enhancing the resilience of multi-agent cooperation, even in the adversary-majority settings.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.24239.pdf", "abstract_url": "https://arxiv.org/abs/2505.24239", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"]}
{"id": "2505.24378", "title": "Mastering Massive Multi-Task Reinforcement Learning via Mixture-of-Expert Decision Transformer", "authors": ["Yilun Kong", "Guozheng Ma", "Qi Zhao", "Haoyu Wang", "Li Shen", "Xueqian Wang", "Dacheng Tao"], "abstract": "Despite recent advancements in offline multi-task reinforcement learning (MTRL) have harnessed the powerful capabilities of the Transformer architecture, most approaches focus on a limited number of tasks, with scaling to extremely massive tasks remaining a formidable challenge. In this paper, we first revisit the key impact of task numbers on current MTRL method, and further reveal that naively expanding the parameters proves insufficient to counteract the performance degradation as the number of tasks escalates. Building upon these insights, we propose M3DT, a novel mixture-of-experts (MoE) framework that tackles task scalability by further unlocking the model's parameter scalability. Specifically, we enhance both the architecture and the optimization of the agent, where we strengthen the Decision Transformer (DT) backbone with MoE to reduce task load on parameter subsets, and introduce a three-stage training mechanism to facilitate efficient training with optimal performance. Experimental results show that, by increasing the number of experts, M3DT not only consistently enhances its performance as model expansion on the fixed task numbers, but also exhibits remarkable task scalability, successfully extending to 160 tasks with superior performance.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "ICML 2025", "pdf_url": "https://arxiv.org/pdf/2505.24378.pdf", "abstract_url": "https://arxiv.org/abs/2505.24378", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.24803", "title": "Guiding Generative Storytelling with Knowledge Graphs", "authors": ["Zhijun Pan", "Antonios Andronis", "Eva Hayek", "Oscar AP Wilkinson", "Ilya Lasy", "Annette Parry", "Guy Gadney", "Tim J. Smith", "Mick Grierson"], "abstract": "Large Language Models (LLMs) have shown great potential in automated story generation, but challenges remain in maintaining long-form coherence and providing users with intuitive and effective control. Retrieval-Augmented Generation (RAG) has proven effective in reducing hallucinations in text generation; however, the use of structured data to support generative storytelling remains underexplored. This paper investigates how knowledge graphs (KGs) can enhance LLM-based storytelling by improving narrative quality and enabling user-driven modifications. We propose a KG-assisted storytelling pipeline and evaluate its effectiveness through a user study with 15 participants. Participants created their own story prompts, generated stories, and edited knowledge graphs to shape their narratives. Through quantitative and qualitative analysis, our findings demonstrate that knowledge graphs significantly enhance story quality in action-oriented and structured narratives within our system settings. Additionally, editing the knowledge graph increases users' sense of control, making storytelling more engaging, interactive, and playful.", "subjects": "Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)", "comments": "This manuscript was submitted for peer review in January 2025", "pdf_url": "https://arxiv.org/pdf/2505.24803.pdf", "abstract_url": "https://arxiv.org/abs/2505.24803", "categories": ["Computation and Language (cs.CL)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["@RAG"]}
{"id": "2505.23841", "title": "SkewRoute: Training-Free LLM Routing for Knowledge Graph Retrieval-Augmented Generation via Score Skewness of Retrieved Context", "authors": ["Hairu Wang", "Yuan Feng", "Yukun Cao", "Xike Xie", "S Kevin Zhou"], "abstract": "Large language models excel at many tasks but often incur high inference costs during deployment. To mitigate hallucination, many systems use a knowledge graph to enhance retrieval-augmented generation (KG-RAG). However, the large amount of retrieved knowledge contexts increase these inference costs further. A promising solution to balance performance and cost is LLM routing, which directs simple queries to smaller LLMs and complex ones to larger LLMs. However, no dedicated routing methods currently exist for RAG, and existing training-based routers face challenges scaling to this domain due to the need for extensive training data. We observe that the score distributions produced by the retrieval scorer strongly correlate with query difficulty. Based on this, we propose a novel, training-free routing framework, the first tailored to KG-RAG that effectively balances performance and cost in a plug-and-play manner. Experiments show our method reduces calls to larger LLMs by up to 50% without sacrificing response quality, demonstrating its potential for efficient and scalable LLM deployment.", "subjects": "Information Retrieval (cs.IR); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23841.pdf", "abstract_url": "https://arxiv.org/abs/2505.23841", "categories": ["Information Retrieval (cs.IR)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"]}
{"id": "2505.24503", "title": "Online Fair Division with Additional Information", "authors": ["Tzeh Yuan Neoh", "Jannik Peters", "Nicholas Teh"], "abstract": "We study the problem of fairly allocating indivisible goods to agents in an online setting, where goods arrive sequentially and must be allocated irrevocably to agents. Focusing on the popular fairness notions of envy-freeness, proportionality, and maximin share fairness (and their approximate variants), we ask how the availability of information on future goods influences the existence and approximability of fair allocations. In the absence of any such information, we establish strong impossibility results, demonstrating the inherent difficulty of achieving even approximate fairness guarantees. In contrast, we demonstrate that knowledge of additional information -- such as aggregate of each agent's total valuations (equivalently, normalized valuations) or the multiset of future goods values (frequency predictions) -- would enable the design of fairer online algorithms. Given normalization information, we propose an algorithm that achieves stronger fairness guarantees than previously known results. Given frequency predictions, we introduce a meta-algorithm that leverages frequency predictions to match the best-known offline guarantees for a broad class of ''share-based'' fairness notions. Our complementary impossibility results in each setting underscore both the limitations imposed by uncertainty about future goods and the potential of leveraging structured information to achieve fairer outcomes in online fair division.", "subjects": "Computer Science and Game Theory (cs.GT); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.24503.pdf", "abstract_url": "https://arxiv.org/abs/2505.24503", "categories": ["Computer Science and Game Theory (cs.GT)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.24584", "title": "AutoChemSchematic AI: A Closed-Loop, Physics-Aware Agentic Framework for Auto-Generating Chemical Process and Instrumentation Diagrams", "authors": ["Sakhinana Sagar Srinivas", "Shivam Gupta", "Venkataramana Runkana"], "abstract": "Recent advancements in generative AI have accelerated the discovery of novel chemicals and materials; however, transitioning these discoveries to industrial-scale production remains a critical bottleneck, as it requires the development of entirely new chemical manufacturing processes. Current AI methods cannot auto-generate PFDs or PIDs, despite their critical role in scaling chemical processes, while adhering to engineering constraints. We present a closed loop, physics aware framework for the automated generation of industrially viable PFDs and PIDs. The framework integrates domain specialized small scale language models (SLMs) (trained for chemical process QA tasks) with first principles simulation, leveraging three key components: (1) a hierarchical knowledge graph of process flow and instrumentation descriptions for 1,020+ chemicals, (2) a multi-stage training pipeline that fine tunes domain specialized SLMs on synthetic datasets via Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and Retrieval-Augmented Instruction Tuning (RAIT), and (3) DWSIM based simulator in the loop validation to ensure feasibility. To improve both runtime efficiency and model compactness, the framework incorporates advanced inference time optimizations including FlashAttention, Lookahead Decoding, PagedAttention with KV-cache quantization, and Test Time Inference Scaling and independently applies structural pruning techniques (width and depth) guided by importance heuristics to reduce model size with minimal accuracy loss. Experiments demonstrate that the framework generates simulator-validated process descriptions with high fidelity, outperforms baseline methods in correctness, and generalizes to unseen chemicals. By bridging AI-driven design with industrial-scale feasibility, this work significantly reduces R&D timelines from lab discovery to plant deployment.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.24584.pdf", "abstract_url": "https://arxiv.org/abs/2505.24584", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["agent", "agentic"]}
{"id": "2505.24710", "title": "Causal-aware Large Language Models: Enhancing Decision-Making Through Learning, Adapting and Acting", "authors": ["Wei Chen", "Jiahao Zhang", "Haipeng Zhu", "Boyan Xu", "Zhifeng Hao", "Keli Zhang", "Junjian Ye", "Ruichu Cai"], "abstract": "Large language models (LLMs) have shown great potential in decision-making due to the vast amount of knowledge stored within the models. However, these pre-trained models are prone to lack reasoning abilities and are difficult to adapt to new environments, further hindering their application to complex real-world tasks. To address these challenges, inspired by the human cognitive process, we propose Causal-aware LLMs, which integrate the structural causal model (SCM) into the decision-making process to model, update, and utilize structured knowledge of the environment in a ``learning-adapting-acting\" paradigm. Specifically, in the learning stage, we first utilize an LLM to extract the environment-specific causal entities and their causal relations to initialize a structured causal model of the environment. Subsequently,in the adapting stage, we update the structured causal model through external feedback about the environment, via an idea of causal intervention. Finally, in the acting stage, Causal-aware LLMs exploit structured causal knowledge for more efficient policy-making through the reinforcement learning agent. The above processes are performed iteratively to learn causal knowledge, ultimately enabling the causal-aware LLMs to achieve a more accurate understanding of the environment and make more efficient decisions. Experimental results across 22 diverse tasks within the open-world game ``Crafter\" validate the effectiveness of our proposed method.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "Accepted by IJCAI 2025", "pdf_url": "https://arxiv.org/pdf/2505.24710.pdf", "abstract_url": "https://arxiv.org/abs/2505.24710", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2505.24715", "title": "CoRet: Improved Retriever for Code Editing", "authors": ["Fabio Fehr", "Prabhu Teja Sivaprasad", "Luca Franceschi", "Giovanni Zappella"], "abstract": "In this paper, we introduce CoRet, a dense retrieval model designed for code-editing tasks that integrates code semantics, repository structure, and call graph dependencies. The model focuses on retrieving relevant portions of a code repository based on natural language queries such as requests to implement new features or fix bugs. These retrieved code chunks can then be presented to a user or to a second code-editing model or agent. To train CoRet, we propose a loss function explicitly designed for repository-level retrieval. On SWE-bench and Long Code Arena's bug localisation datasets, we show that our model substantially improves retrieval recall by at least 15 percentage points over existing models, and ablate the design choices to show their importance in achieving these results.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "ACL 2025", "pdf_url": "https://arxiv.org/pdf/2505.24715.pdf", "abstract_url": "https://arxiv.org/abs/2505.24715", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2505.24808", "title": "RealDrive: Retrieval-Augmented Driving with Diffusion Models", "authors": ["Wenhao Ding", "Sushant Veer", "Yuxiao Chen", "Yulong Cao", "Chaowei Xiao", "Marco Pavone"], "abstract": "Learning-based planners generate natural human-like driving behaviors by learning to reason about nuanced interactions from data, overcoming the rigid behaviors that arise from rule-based planners. Nonetheless, data-driven approaches often struggle with rare, safety-critical scenarios and offer limited controllability over the generated trajectories. To address these challenges, we propose RealDrive, a Retrieval-Augmented Generation (RAG) framework that initializes a diffusion-based planning policy by retrieving the most relevant expert demonstrations from the training dataset. By interpolating between current observations and retrieved examples through a denoising process, our approach enables fine-grained control and safe behavior across diverse scenarios, leveraging the strong prior provided by the retrieved scenario. Another key insight we produce is that a task-relevant retrieval model trained with planning-based objectives results in superior planning performance in our framework compared to a task-agnostic retriever. Experimental results demonstrate improved generalization to long-tail events and enhanced trajectory diversity compared to standard learning-based planners -- we observe a 40% reduction in collision rate on the Waymo Open Motion dataset with RAG.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.24808.pdf", "abstract_url": "https://arxiv.org/abs/2505.24808", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"]}
