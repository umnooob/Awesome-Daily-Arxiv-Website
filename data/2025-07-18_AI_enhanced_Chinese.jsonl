{"id": "2507.12732", "title": "Strategy Adaptation in Large Language Model Werewolf Agents", "authors": ["Fuya Nakamori", "Yin Jou Huang", "Fei Cheng"], "abstract": "This study proposes a method to improve the performance of Werewolf agents by switching between predefined strategies based on the attitudes of other players and the context of conversations. While prior works of Werewolf agents using prompt engineering have employed methods where effective strategies are implicitly defined, they cannot adapt to changing situations. In this research, we propose a method that explicitly selects an appropriate strategy based on the game context and the estimated roles of other players. We compare the strategy adaptation Werewolf agents with baseline agents using implicit or fixed strategies and verify the effectiveness of our proposed method.", "subjects": "Computation and Language (cs.CL)", "comments": "7 pages, 2 figures", "pdf_url": "https://arxiv.org/pdf/2507.12732.pdf", "abstract_url": "https://arxiv.org/abs/2507.12732", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本研究提出了一种通过根据其他玩家的态度和对话上下文切换预定义策略来提高狼人杀代理性能的方法。与之前使用提示工程的狼人杀代理工作不同，我们的方法能够根据游戏上下文和其他玩家的估计角色明确选择适当的策略。", "motivation": "解决现有狼人杀代理无法适应变化情境的问题，通过明确选择策略来提高代理的性能。", "method": "提出了一种基于游戏上下文和其他玩家估计角色明确选择策略的方法。", "result": "与使用隐式或固定策略的基线代理相比，策略适应的狼人杀代理表现出更高的有效性。", "conclusion": "明确选择策略的方法能够有效提高狼人杀代理的性能，适应变化的情境。"}}
{"id": "2507.13152", "title": "SE-VLN: A Self-Evolving Vision-Language Navigation Framework Based on Multimodal Large Language Models", "authors": ["Xiangyu Dong", "Haoran Zhao", "Jiang Gao", "Haozhou Li", "Xiaoguang Ma", "Yaoming Zhou", "Fuhai Chen", "Juan Liu"], "abstract": "Recent advances in vision-language navigation (VLN) were mainly attributed to emerging large language models (LLMs). These methods exhibited excellent generalization capabilities in instruction understanding and task reasoning. However, they were constrained by the fixed knowledge bases and reasoning abilities of LLMs, preventing fully incorporating experiential knowledge and thus resulting in a lack of efficient evolutionary capacity. To address this, we drew inspiration from the evolution capabilities of natural agents, and proposed a self-evolving VLN framework (SE-VLN) to endow VLN agents with the ability to continuously evolve during testing. To the best of our knowledge, it was the first time that an multimodal LLM-powered self-evolving VLN framework was proposed. Specifically, SE-VLN comprised three core modules, i.e., a hierarchical memory module to transfer successful and failure cases into reusable knowledge, a retrieval-augmented thought-based reasoning module to retrieve experience and enable multi-step decision-making, and a reflection module to realize continual evolution. Comprehensive tests illustrated that the SE-VLN achieved navigation success rates of 57% and 35.2% in unseen environments, representing absolute performance improvements of 23.9% and 15.0% over current state-of-the-art methods on R2R and REVERSE datasets, respectively. Moreover, the SE-VLN showed performance improvement with increasing experience repository, elucidating its great potential as a self-evolving agent framework for VLN.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.13152.pdf", "abstract_url": "https://arxiv.org/abs/2507.13152", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于多模态大语言模型的自进化视觉语言导航框架（SE-VLN），旨在解决现有VLN方法因固定知识库和推理能力而无法有效整合经验知识的问题。", "motivation": "解决视觉语言导航（VLN）领域因大型语言模型（LLMs）固定知识库和推理能力限制，导致无法有效整合经验知识，缺乏高效进化能力的问题。", "method": "提出SE-VLN框架，包含三个核心模块：分层记忆模块用于将成功和失败案例转化为可重用知识，检索增强的基于思维的推理模块用于检索经验并实现多步决策，以及反思模块实现持续进化。", "result": "在未见环境中，SE-VLN的导航成功率在R2R和REVERSE数据集上分别达到57%和35.2%，比现有最先进方法绝对性能提高了23.9%和15.0%。", "conclusion": "SE-VLN作为一种自进化代理框架，展示了随着经验库增加而性能提升的潜力，为VLN领域提供了新的研究方向。"}}
{"id": "2507.12795", "title": "City-VLM: Towards Multidomain Perception Scene Understanding via Multimodal Incomplete Learning", "authors": ["Penglei Sun", "Yaoxian Song", "Xiangru Zhu", "Xiang Liu", "Qiang Wang", "Yue Liu", "Changqun Xia", "Tiefeng Li", "Yang Yang", "Xiaowen Chu"], "abstract": "Scene understanding enables intelligent agents to interpret and comprehend their environment. While existing large vision-language models (LVLMs) for scene understanding have primarily focused on indoor household tasks, they face two significant limitations when applied to outdoor large-scale scene understanding. First, outdoor scenarios typically encompass larger-scale environments observed through various sensors from multiple viewpoints (e.g., bird view and terrestrial view), while existing indoor LVLMs mainly analyze single visual modalities within building-scale contexts from humanoid viewpoints. Second, existing LVLMs suffer from missing multidomain perception outdoor data and struggle to effectively integrate 2D and 3D visual information. To address the aforementioned limitations, we build the first multidomain perception outdoor scene understanding dataset, named \\textbf{\\underline{SVM-City}}, deriving from multi\\textbf{\\underline{S}}cale scenarios with multi\\textbf{\\underline{V}}iew and multi\\textbf{\\underline{M}}odal instruction tuning data. It contains $420$k images and $4, 811$M point clouds with $567$k question-answering pairs from vehicles, low-altitude drones, high-altitude aerial planes, and satellite. To effectively fuse the multimodal data in the absence of one modality, we introduce incomplete multimodal learning to model outdoor scene understanding and design the LVLM named \\textbf{\\underline{City-VLM}}. Multimodal fusion is realized by constructing a joint probabilistic distribution space rather than implementing directly explicit fusion operations (e.g., concatenation). Experimental results on three typical outdoor scene understanding tasks show City-VLM achieves $18.14 \\%$ performance surpassing existing LVLMs in question-answering tasks averagely. Our method demonstrates pragmatic and generalization performance across multiple outdoor scenes.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.12795.pdf", "abstract_url": "https://arxiv.org/abs/2507.12795", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "City-VLM是一个针对户外大规模场景理解的多模态不完全学习模型，通过构建首个多领域感知户外场景理解数据集SVM-City，并采用不完全多模态学习方法，有效融合2D和3D视觉信息，显著提升了户外场景理解任务的性能。", "motivation": "解决现有大型视觉语言模型（LVLMs）在户外大规模场景理解中的两个主要限制：一是户外场景通常涉及更大规模的环境和多视角观察，而现有模型主要针对室内单一视觉模态；二是缺乏多领域感知户外数据，难以有效整合2D和3D视觉信息。", "method": "构建了名为SVM-City的多领域感知户外场景理解数据集，包含来自不同视角和模态的420k图像和4,811M点云数据及567k问答对。设计了City-VLM模型，通过构建联合概率分布空间实现多模态融合，而非直接显式融合操作。", "result": "在三个典型的户外场景理解任务中，City-VLM在问答任务上的平均性能比现有LVLMs提升了18.14%，展示了在多个户外场景中的实用性和泛化性能。", "conclusion": "City-VLM通过不完全多模态学习和多领域感知数据集的有效融合，显著提升了户外场景理解的性能，为智能代理在复杂环境中的理解和解释提供了新的解决方案。"}}
{"id": "2507.12484", "title": "AI-Powered Math Tutoring: Platform for Personalized and Adaptive Education", "authors": ["Jarosław A. Chudziak", "Adam Kostka"], "abstract": "The growing ubiquity of artificial intelligence (AI), in particular large language models (LLMs), has profoundly altered the way in which learners gain knowledge and interact with learning material, with many claiming that AI positively influences their learning achievements. Despite this advancement, current AI tutoring systems face limitations associated with their reactive nature, often providing direct answers without encouraging deep reflection or incorporating structured pedagogical tools and strategies. This limitation is most apparent in the field of mathematics, in which AI tutoring systems remain underdeveloped. This research addresses the question: How can AI tutoring systems move beyond providing reactive assistance to enable structured, individualized, and tool-assisted learning experiences? We introduce a novel multi-agent AI tutoring platform that combines adaptive and personalized feedback, structured course generation, and textbook knowledge retrieval to enable modular, tool-assisted learning processes. This system allows students to learn new topics while identifying and targeting their weaknesses, revise for exams effectively, and practice on an unlimited number of personalized exercises. This article contributes to the field of artificial intelligence in education by introducing a novel platform that brings together pedagogical agents and AI-driven components, augmenting the field with modular and effective systems for teaching mathematics.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "8 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2507.12484.pdf", "abstract_url": "https://arxiv.org/abs/2507.12484", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一种新型的多代理AI辅导平台，旨在通过自适应和个性化反馈、结构化课程生成和教科书知识检索，促进模块化、工具辅助的学习过程，特别是在数学教育领域。", "motivation": "当前AI辅导系统在数学教育中存在局限性，主要是反应性援助，缺乏深度反思和结构化教学工具的整合。本研究旨在探索如何使AI辅导系统超越反应性援助，实现结构化、个性化和工具辅助的学习体验。", "method": "引入了一个结合自适应和个性化反馈、结构化课程生成和教科书知识检索的多代理AI辅导平台。", "result": "开发了一个允许学生学习新主题、识别和针对弱点、有效复习考试并在无限数量的个性化练习中练习的系统。", "conclusion": "本文通过引入一个结合教学代理和AI驱动组件的新平台，为人工智能在教育领域的应用贡献了模块化和有效的数学教学系统。"}}
{"id": "2507.12624", "title": "Pathology-Guided Virtual Staining Metric for Evaluation and Training", "authors": ["Qiankai Wang", "James E.D. Tweel", "Parsin Haji Reza", "Anita Layton"], "abstract": "Virtual staining has emerged as a powerful alternative to traditional histopathological staining techniques, enabling rapid, reagent-free image transformations. However, existing evaluation methods predominantly rely on full-reference image quality assessment (FR-IQA) metrics such as structural similarity, which are originally designed for natural images and often fail to capture pathology-relevant features. Expert pathology reviews have also been used, but they are inherently subjective and time-consuming.", "subjects": "Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV); Systems and Control (eess.SY)", "comments": "19 pages, 10 figures. Intended for submission to the Journal of Imaging Informatics in Medicine (JIIM)", "pdf_url": "https://arxiv.org/pdf/2507.12624.pdf", "abstract_url": "https://arxiv.org/abs/2507.12624", "categories": ["Image and Video Processing (eess.IV)", "Computer Vision and Pattern Recognition (cs.CV)", "Systems and Control (eess.SY)"], "matching_keywords": ["agent"], "AI": {"tldr": "虚拟染色技术作为一种强大的传统组织病理学染色技术替代方案，能够实现快速、无需试剂的图像转换。然而，现有的评估方法主要依赖于全参考图像质量评估（FR-IQA）指标，如结构相似性，这些指标最初是为自然图像设计的，往往无法捕捉到病理相关的特征。专家病理学审查也被使用，但它们本质上是主观且耗时的。", "motivation": "解决现有虚拟染色技术评估方法无法准确反映病理相关特征的问题。", "method": "提出了一种基于病理学指导的虚拟染色评估和训练指标。", "result": "该指标能够更准确地评估虚拟染色技术的效果，捕捉到病理相关的特征。", "conclusion": "病理学指导的虚拟染色指标为虚拟染色技术的评估和训练提供了一种更有效的方法，有助于提高虚拟染色技术的准确性和实用性。"}}
{"id": "2507.13190", "title": "GEMMAS: Graph-based Evaluation Metrics for Multi Agent Systems", "authors": ["Jisoo Lee", "Raeyoung Chang", "Dongwook Kwon", "Harmanpreet Singh", "Nikhil Verma"], "abstract": "Multi-agent systems built on language models have shown strong performance on collaborative reasoning tasks. However, existing evaluations focus only on the correctness of the final output, overlooking how inefficient communication and poor coordination contribute to redundant reasoning and higher computational costs. We introduce GEMMAS, a graph-based evaluation framework that analyzes the internal collaboration process by modeling agent interactions as a directed acyclic graph. To capture collaboration quality, we propose two process-level metrics: Information Diversity Score (IDS) to measure semantic variation in inter-agent messages, and Unnecessary Path Ratio (UPR) to quantify redundant reasoning paths. We evaluate GEMMAS across five benchmarks and highlight results on GSM8K, where systems with only a 2.1% difference in accuracy differ by 12.8% in IDS and 80% in UPR, revealing substantial variation in internal collaboration. These findings demonstrate that outcome-only metrics are insufficient for evaluating multi-agent performance and highlight the importance of process-level diagnostics in designing more interpretable and resource-efficient collaborative AI systems.", "subjects": "Computation and Language (cs.CL)", "comments": "4 figures, 1 algorithm, 2 tables, 6 pages, under review at EMNLP Industry track 2025", "pdf_url": "https://arxiv.org/pdf/2507.13190.pdf", "abstract_url": "https://arxiv.org/abs/2507.13190", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "GEMMAS是一个基于图的评估框架，用于分析多代理系统的内部协作过程，通过建模代理交互为有向无环图，提出了两个过程级指标：信息多样性评分（IDS）和不必要路径比率（UPR），以评估协作质量。", "motivation": "现有的多代理系统评估仅关注最终输出的正确性，忽视了低效沟通和不良协调导致的冗余推理和更高计算成本的问题。", "method": "引入GEMMAS框架，通过将代理交互建模为有向无环图，并提出IDS和UPR两个过程级指标来评估协作质量。", "result": "在GSM8K等五个基准测试中，GEMMAS揭示了仅2.1%准确率差异的系统在IDS和UPR上分别有12.8%和80%的差异，表明内部协作存在显著差异。", "conclusion": "仅基于结果的评估指标不足以全面评估多代理性能，过程级诊断在设计更可解释和资源效率更高的协作AI系统中至关重要。"}}
{"id": "2507.13285", "title": "Multi-Agent Synergy-Driven Iterative Visual Narrative Synthesis", "authors": ["Wang Xi", "Quan Shi", "Tian Yu", "Yujie Peng", "Jiayi Sun", "Mengxing Ren", "Zenghui Ding", "Ningguang Yao"], "abstract": "Automated generation of high-quality media presentations is challenging, requiring robust content extraction, narrative planning, visual design, and overall quality optimization. Existing methods often produce presentations with logical inconsistencies and suboptimal layouts, thereby struggling to meet professional standards. To address these challenges, we introduce RCPS (Reflective Coherent Presentation Synthesis), a novel framework integrating three key components: (1) Deep Structured Narrative Planning; (2) Adaptive Layout Generation; (3) an Iterative Optimization Loop. Additionally, we propose PREVAL, a preference-based evaluation framework employing rationale-enhanced multi-dimensional models to assess presentation quality across Content, Coherence, and Design. Experimental results demonstrate that RCPS significantly outperforms baseline methods across all quality dimensions, producing presentations that closely approximate human expert standards. PREVAL shows strong correlation with human judgments, validating it as a reliable automated tool for assessing presentation quality.", "subjects": "Computation and Language (cs.CL)", "comments": "22 pages, 7 figures, 3 tables. Submitted to an ACL-style conference", "pdf_url": "https://arxiv.org/pdf/2507.13285.pdf", "abstract_url": "https://arxiv.org/abs/2507.13285", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了RCPS（反射性连贯演示合成）框架，该框架通过深度结构化叙事规划、自适应布局生成和迭代优化循环，解决了高质量媒体演示自动生成中的挑战。实验证明RCPS在内容、连贯性和设计方面显著优于基线方法。", "motivation": "解决现有方法在自动生成高质量媒体演示时存在的逻辑不一致和布局次优问题，以满足专业标准。", "method": "RCPS框架整合了深度结构化叙事规划、自适应布局生成和迭代优化循环三个关键组件，并提出了基于偏好的评估框架PREVAL。", "result": "RCPS在所有质量维度上显著优于基线方法，生成的演示接近人类专家标准；PREVAL与人类判断有强相关性，验证了其作为评估演示质量的可靠自动化工具的有效性。", "conclusion": "RCPS和PREVAL为高质量媒体演示的自动生成和评估提供了有效解决方案，具有重要的实际应用价值。"}}
{"id": "2507.12494", "title": "MR-LDM -- The Merge-Reactive Longitudinal Decision Model: Game Theoretic Human Decision Modeling for Interactive Sim Agents", "authors": ["Dustin Holley", "Jovin D'sa", "Hossein Nourkhiz Mahjoub", "Gibran Ali"], "abstract": "Enhancing simulation environments to replicate real-world driver behavior, i.e., more humanlike sim agents, is essential for developing autonomous vehicle technology. In the context of highway merging, previous works have studied the operational-level yielding dynamics of lag vehicles in response to a merging car at highway on-ramps. Other works focusing on tactical decision modeling generally consider limited action sets or utilize payoff functions with large parameter sets and limited payoff bounds. In this work, we aim to improve the simulation of the highway merge scenario by targeting a game theoretic model for tactical decision-making with improved payoff functions and lag actions. We couple this with an underlying dynamics model to have a unified decision and dynamics model that can capture merging interactions and simulate more realistic interactions in an explainable and interpretable fashion. The proposed model demonstrated good reproducibility of complex interactions when validated on a real-world dataset. The model was finally integrated into a high fidelity simulation environment and confirmed to have adequate computation time efficiency for use in large-scale simulations to support autonomous vehicle development.", "subjects": "Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT); Multiagent Systems (cs.MA); Robotics (cs.RO)", "comments": "8 pages", "pdf_url": "https://arxiv.org/pdf/2507.12494.pdf", "abstract_url": "https://arxiv.org/abs/2507.12494", "categories": ["Artificial Intelligence (cs.AI)", "Computer Science and Game Theory (cs.GT)", "Multiagent Systems (cs.MA)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "MR-LDM模型是一种用于模拟高速公路合并场景中人类决策行为的游戏理论模型，旨在通过改进的支付函数和滞后动作来增强模拟环境的真实性和可解释性。", "motivation": "为了提高自动驾驶车辆技术开发中模拟环境的真实性，特别是在高速公路合并场景中模拟更接近人类行为的模拟代理。", "method": "采用游戏理论模型进行战术决策建模，结合改进的支付函数和滞后动作，并与底层动力学模型耦合，形成一个统一的决策和动力学模型。", "result": "模型在真实世界数据集上验证了能够良好复现复杂的交互行为，并且在集成到高保真模拟环境中时，显示出足够的计算时间效率。", "conclusion": "MR-LDM模型能够以可解释和可解释的方式模拟更真实的合并交互，支持大规模模拟以促进自动驾驶车辆的发展。"}}
{"id": "2507.12599", "title": "A Survey of Explainable Reinforcement Learning: Targets, Methods and Needs", "authors": ["Léo Saulières"], "abstract": "The success of recent Artificial Intelligence (AI) models has been accompanied by the opacity of their internal mechanisms, due notably to the use of deep neural networks. In order to understand these internal mechanisms and explain the output of these AI models, a set of methods have been proposed, grouped under the domain of eXplainable AI (XAI). This paper focuses on a sub-domain of XAI, called eXplainable Reinforcement Learning (XRL), which aims to explain the actions of an agent that has learned by reinforcement learning. We propose an intuitive taxonomy based on two questions \"What\" and \"How\". The first question focuses on the target that the method explains, while the second relates to the way the explanation is provided. We use this taxonomy to provide a state-of-the-art review of over 250 papers. In addition, we present a set of domains close to XRL, which we believe should get attention from the community. Finally, we identify some needs for the field of XRL.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "69 pages, 19 figures", "pdf_url": "https://arxiv.org/pdf/2507.12599.pdf", "abstract_url": "https://arxiv.org/abs/2507.12599", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文综述了可解释强化学习（XRL）领域，提出了基于'什么'和'如何'问题的直观分类法，并回顾了250多篇论文的现状，同时指出了XRL领域的一些需求和邻近领域。", "motivation": "随着人工智能（AI）模型，特别是深度神经网络的成功，其内部机制的不透明性也随之增加。为了理解这些内部机制并解释AI模型的输出，提出了可解释AI（XAI）领域的一系列方法。本文专注于XAI的一个子领域——可解释强化学习（XRL），旨在解释通过强化学习学习的智能体的行为。", "method": "本文提出了一个基于'什么'和'如何'问题的直观分类法。'什么'问题关注方法解释的目标，而'如何'问题则涉及提供解释的方式。利用这一分类法，作者对250多篇论文进行了现状回顾。", "result": "通过分类法，本文提供了XRL领域的现状综述，并指出了一些需要社区关注的邻近领域。", "conclusion": "本文不仅综述了XRL领域的现状，还识别了该领域的一些需求，为未来的研究提供了方向。"}}
{"id": "2507.12666", "title": "Fly, Fail, Fix: Iterative Game Repair with Reinforcement Learning and Large Multimodal Models", "authors": ["Alex Zook", "Josef Spjut", "Jonathan Tremblay"], "abstract": "Game design hinges on understanding how static rules and content translate into dynamic player behavior - something modern generative systems that inspect only a game's code or assets struggle to capture. We present an automated design iteration framework that closes this gap by pairing a reinforcement learning (RL) agent, which playtests the game, with a large multimodal model (LMM), which revises the game based on what the agent does. In each loop the RL player completes several episodes, producing (i) numerical play metrics and/or (ii) a compact image strip summarising recent video frames. The LMM designer receives a gameplay goal and the current game configuration, analyses the play traces, and edits the configuration to steer future behaviour toward the goal. We demonstrate results that LMMs can reason over behavioral traces supplied by RL agents to iteratively refine game mechanics, pointing toward practical, scalable tools for AI-assisted game design.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2507.12666.pdf", "abstract_url": "https://arxiv.org/abs/2507.12666", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种自动化的游戏设计迭代框架，通过结合强化学习（RL）代理和大型多模态模型（LMM），实现了游戏的自动测试和修改。RL代理负责玩游戏并生成游戏指标和视频摘要，LMM则根据这些信息调整游戏配置，以引导玩家行为达到设计目标。", "motivation": "现代生成系统仅通过检查游戏代码或资源难以捕捉静态规则和内容如何转化为动态玩家行为，这限制了游戏设计的效率和质量。", "method": "框架结合了强化学习代理和大型多模态模型，RL代理进行游戏测试并生成数据和视频摘要，LMM分析这些信息并调整游戏配置。", "result": "研究表明，LMM能够通过分析RL代理提供的行为轨迹来迭代优化游戏机制，为AI辅助游戏设计提供了实用、可扩展的工具。", "conclusion": "该框架为游戏设计提供了一种新的自动化迭代方法，通过结合RL和LMM，能够有效地优化游戏机制，提高设计效率和质量。"}}
{"id": "2507.12801", "title": "Imitating Mistakes in a Learning Companion AI Agent for Online Peer Learning", "authors": ["Sosui Moribe", "Taketoshi Ushiama"], "abstract": "In recent years, peer learning has gained attention as a method that promotes spontaneous thinking among learners, and its effectiveness has been confirmed by numerous studies. This study aims to develop an AI Agent as a learning companion that enables peer learning anytime and anywhere. However, peer learning between humans has various limitations, and it is not always effective. Effective peer learning requires companions at the same proficiency levels. In this study, we assume that a learner's peers with the same proficiency level as the learner make the same mistakes as the learner does and focus on English composition as a specific example to validate this approach.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": ")", "pdf_url": "https://arxiv.org/pdf/2507.12801.pdf", "abstract_url": "https://arxiv.org/abs/2507.12801", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本研究旨在开发一个作为学习伴侣的AI代理，以实现在线同伴学习，特别关注英语作文中学习者与相同熟练水平的同伴犯相同错误的假设。", "motivation": "同伴学习虽有效，但存在限制，如同伴熟练水平不一影响效果。本研究旨在通过AI代理模拟相同熟练水平的同伴，解决这一问题。", "method": "开发一个AI代理作为学习伴侣，模拟与学习者相同熟练水平的同伴，特别是在英语作文中犯相同错误，以验证此方法的有效性。", "result": "未明确提及具体结果，但研究假设模拟相同熟练水平的同伴犯相同错误能有效促进同伴学习。", "conclusion": "通过AI代理模拟相同熟练水平的同伴，可能克服人类同伴学习的限制，为在线同伴学习提供新途径。"}}
{"id": "2507.12806", "title": "MCPEval: Automatic MCP-based Deep Evaluation for AI Agent Models", "authors": ["Zhiwei Liu", "Jielin Qiu", "Shiyu Wang", "Jianguo Zhang", "Zuxin Liu", "Roshan Ram", "Haolin Chen", "Weiran Yao", "Huan Wang", "Shelby Heinecke", "Silvio Savarese", "Caiming Xiong"], "abstract": "The rapid rise of Large Language Models (LLMs)-based intelligent agents underscores the need for robust, scalable evaluation frameworks. Existing methods rely on static benchmarks and labor-intensive data collection, limiting practical assessment. We introduce \\oursystemname, an open-source Model Context Protocol (MCP)-based framework that automates end-to-end task generation and deep evaluation of LLM agents across diverse domains. MCPEval standardizes metrics, seamlessly integrates with native agent tools, and eliminates manual effort in building evaluation pipelines. Empirical results across five real-world domains show its effectiveness in revealing nuanced, domain-specific performance. We publicly release MCPEval", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2507.12806.pdf", "abstract_url": "https://arxiv.org/abs/2507.12806", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了MCPEval，一个基于模型上下文协议（MCP）的开源框架，旨在自动化大型语言模型（LLM）智能代理的端到端任务生成和深度评估。", "motivation": "随着基于大型语言模型（LLM）的智能代理的迅速崛起，现有的评估方法依赖于静态基准和劳动密集型数据收集，限制了实际评估的效率和范围。", "method": "MCPEval通过标准化评估指标、无缝集成原生代理工具，并消除构建评估管道的手动工作，实现了跨多样领域的自动化评估。", "result": "在五个现实世界领域的实证结果表明，MCPEval在揭示领域特定性能的细微差别方面非常有效。", "conclusion": "MCPEval的发布为智能代理的评估提供了一个强大、可扩展的框架，有望推动AI代理模型的进一步发展和应用。"}}
{"id": "2507.12862", "title": "Information-Theoretic Aggregation of Ethical Attributes in Simulated-Command", "authors": ["Hussein Abbass", "Taylan Akay", "Harrison Tolley"], "abstract": "In the age of AI, human commanders need to use the computational powers available in today's environment to simulate a very large number of scenarios. Within each scenario, situations occur where different decision design options could have ethical consequences. Making these decisions reliant on human judgement is both counter-productive to the aim of exploring very large number of scenarios in a timely manner and infeasible when considering the workload needed to involve humans in each of these choices. In this paper, we move human judgement outside the simulation decision cycle. Basically, the human will design the ethical metric space, leaving it to the simulated environment to explore the space. When the simulation completes its testing cycles, the testing environment will come back to the human commander with a few options to select from. The human commander will then exercise human-judgement to select the most appropriate course of action, which will then get executed accordingly. We assume that the problem of designing metrics that are sufficiently granular to assess the ethical implications of decisions is solved. Subsequently, the fundamental problem we look at in this paper is how to weight ethical decisions during the running of these simulations; that is, how to dynamically weight the ethical attributes when agents are faced with decision options with ethical implications during generative simulations. The multi-criteria decision making literature has started to look at nearby problems, where the concept of entropy has been used to determine the weights during aggregation. We draw from that literature different approaches to automatically calculate the weights for ethical attributes during simulation-based testing and evaluation.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.12862.pdf", "abstract_url": "https://arxiv.org/abs/2507.12862", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "在AI时代，本文提出了一种方法，将人类判断从模拟决策循环中移出，设计伦理度量空间由模拟环境探索，最终由人类指挥官选择最合适的行动方案。", "motivation": "解决在大量模拟场景中依赖人类判断进行伦理决策的低效和不可行问题。", "method": "设计伦理度量空间，利用模拟环境探索该空间，并采用多准则决策文献中的熵概念动态加权伦理属性。", "result": "提出了一种自动计算模拟测试中伦理属性权重的方法，减少了人类在决策过程中的直接参与。", "conclusion": "通过将人类判断移出模拟决策循环并自动加权伦理属性，本文方法提高了在大量模拟场景中进行伦理决策的效率和可行性。"}}
{"id": "2507.12821", "title": "Assessing adaptive world models in machines with novel games", "authors": ["Lance Ying", "Katherine M. Collins", "Prafull Sharma", "Cedric Colas", "Kaiya Ivy Zhao", "Adrian Weller", "Zenna Tavares", "Phillip Isola", "Samuel J. Gershman", "Jacob D. Andreas", "Thomas L. Griffiths", "Francois Chollet", "Kelsey R. Allen", "Joshua B. Tenenbaum"], "abstract": "Human intelligence exhibits a remarkable capacity for rapid adaptation and effective problem-solving in novel and unfamiliar contexts. We argue that this profound adaptability is fundamentally linked to the efficient construction and refinement of internal representations of the environment, commonly referred to as world models, and we refer to this adaptation mechanism as world model induction. However, current understanding and evaluation of world models in artificial intelligence (AI) remains narrow, often focusing on static representations learned from training on a massive corpora of data, instead of the efficiency and efficacy of models in learning these representations through interaction and exploration within a novel environment. In this Perspective, we provide a view of world model induction drawing on decades of research in cognitive science on how humans learn and adapt so efficiently; we then call for a new evaluation framework for assessing adaptive world models in AI. Concretely, we propose a new benchmarking paradigm based on suites of carefully designed games with genuine, deep and continually refreshing novelty in the underlying game structures -- we refer to this kind of games as novel games. We detail key desiderata for constructing these games and propose appropriate metrics to explicitly challenge and evaluate the agent's ability for rapid world model induction. We hope that this new evaluation framework will inspire future evaluation efforts on world models in AI and provide a crucial step towards developing AI systems capable of the human-like rapid adaptation and robust generalization -- a critical component of artificial general intelligence.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "17 pages, 4 figures", "pdf_url": "https://arxiv.org/pdf/2507.12821.pdf", "abstract_url": "https://arxiv.org/abs/2507.12821", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了人类智能在快速适应和解决新环境问题方面的能力，提出了世界模型归纳的概念，并呼吁在人工智能中建立一个新的评估框架，以测试和提升AI系统在快速适应和泛化方面的能力。", "motivation": "当前人工智能中对世界模型的理解和评估过于狭窄，主要集中在从大量数据中学习的静态表示上，而不是模型通过在新环境中互动和探索学习这些表示的效率和效果。", "method": "提出了一种新的评估框架，基于一系列精心设计的游戏，这些游戏具有真正的、深层次的和持续更新的新颖性，旨在挑战和评估代理快速归纳世界模型的能力。", "result": "提出了构建这些游戏的关键要求和适当的度量标准，以明确挑战和评估代理的快速世界模型归纳能力。", "conclusion": "希望这一新的评估框架能激励未来对AI世界模型的评估努力，并为开发具有人类-like快速适应和强大泛化能力的人工智能系统迈出关键一步。"}}
{"id": "2507.13334", "title": "A Survey of Context Engineering for Large Language Models", "authors": ["Lingrui Mei", "Jiayu Yao", "Yuyao Ge", "Yiwei Wang", "Baolong Bi", "Yujun Cai", "Jiazhi Liu", "Mingyu Li", "Zhong-Zhi Li", "Duzhen Zhang", "Chenlin Zhou", "Jiayi Mao", "Tianze Xia", "Jiafeng Guo", "Shenghua Liu"], "abstract": "The performance of Large Language Models (LLMs) is fundamentally determined by the contextual information provided during inference. This survey introduces Context Engineering, a formal discipline that transcends simple prompt design to encompass the systematic optimization of information payloads for LLMs. We present a comprehensive taxonomy decomposing Context Engineering into its foundational components and the sophisticated implementations that integrate them into intelligent systems. We first examine the foundational components: context retrieval and generation, context processing and context management. We then explore how these components are architecturally integrated to create sophisticated system implementations: retrieval-augmented generation (RAG), memory systems and tool-integrated reasoning, and multi-agent systems. Through this systematic analysis of over 1300 research papers, our survey not only establishes a technical roadmap for the field but also reveals a critical research gap: a fundamental asymmetry exists between model capabilities. While current models, augmented by advanced context engineering, demonstrate remarkable proficiency in understanding complex contexts, they exhibit pronounced limitations in generating equally sophisticated, long-form outputs. Addressing this gap is a defining priority for future research. Ultimately, this survey provides a unified framework for both researchers and engineers advancing context-aware AI.", "subjects": "Computation and Language (cs.CL)", "comments": "ongoing work; 165 pages, 1401 citations", "pdf_url": "https://arxiv.org/pdf/2507.13334.pdf", "abstract_url": "https://arxiv.org/abs/2507.13334", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文介绍了上下文工程这一新兴学科，旨在系统优化大型语言模型（LLMs）推理过程中的信息负载。通过分析1300多篇研究论文，提出了上下文工程的基础组件和系统实现，并指出了当前模型在理解和生成复杂上下文能力上的不对称性。", "motivation": "解决大型语言模型（LLMs）在推理过程中上下文信息负载的系统优化问题，以及当前模型在理解和生成复杂上下文能力上的不对称性。", "method": "提出了上下文工程的综合分类法，包括基础组件（上下文检索与生成、上下文处理与管理）和系统实现（检索增强生成、记忆系统与工具集成推理、多智能体系统）。", "result": "通过系统分析，建立了该领域的技术路线图，并揭示了模型在理解和生成复杂上下文能力上的显著不对称性。", "conclusion": "上下文工程为研究人员和工程师提供了一个统一的框架，以推动上下文感知AI的发展。解决模型在生成复杂长文本输出方面的限制是未来研究的重点。"}}
{"id": "2507.12774", "title": "A Comprehensive Survey of Electronic Health Record Modeling: From Deep Learning Approaches to Large Language Models", "authors": ["Weijieying Ren", "Jingxi Zhu", "Zehao Liu", "Tianxiang Zhao", "Vasant Honavar"], "abstract": "Artificial intelligence (AI) has demonstrated significant potential in transforming healthcare through the analysis and modeling of electronic health records (EHRs). However, the inherent heterogeneity, temporal irregularity, and domain-specific nature of EHR data present unique challenges that differ fundamentally from those in vision and natural language tasks. This survey offers a comprehensive overview of recent advancements at the intersection of deep learning, large language models (LLMs), and EHR modeling. We introduce a unified taxonomy that spans five key design dimensions: data-centric approaches, neural architecture design, learning-focused strategies, multimodal learning, and LLM-based modeling systems. Within each dimension, we review representative methods addressing data quality enhancement, structural and temporal representation, self-supervised learning, and integration with clinical knowledge. We further highlight emerging trends such as foundation models, LLM-driven clinical agents, and EHR-to-text translation for downstream reasoning. Finally, we discuss open challenges in benchmarking, explainability, clinical alignment, and generalization across diverse clinical settings. This survey aims to provide a structured roadmap for advancing AI-driven EHR modeling and clinical decision support. For a comprehensive list of EHR-related methods, kindly refer to", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.12774.pdf", "abstract_url": "https://arxiv.org/abs/2507.12774", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文综述了电子健康记录（EHR）建模的最新进展，特别是深度学习和大型语言模型（LLMs）在其中的应用。提出了一个统一的分类法，涵盖了五个关键设计维度，并回顾了代表性方法。同时，强调了新兴趋势和开放挑战。", "motivation": "电子健康记录（EHR）数据的异质性、时间不规则性和领域特定性给AI在医疗保健领域的应用带来了独特挑战。本文旨在提供一个结构化的路线图，以推动AI驱动的EHR建模和临床决策支持的发展。", "method": "本文采用综述方法，介绍了一个统一的分类法，涵盖数据为中心的方法、神经架构设计、学习策略、多模态学习和基于LLM的建模系统五个维度，并回顾了代表性方法。", "result": "本文总结了EHR建模的最新进展，包括数据质量增强、结构和时间表示、自监督学习以及与临床知识的整合。同时，指出了基础模型、LLM驱动的临床代理和EHR到文本翻译等新兴趋势。", "conclusion": "本文为AI驱动的EHR建模和临床决策支持提供了结构化的路线图，并讨论了在基准测试、可解释性、临床对齐和跨不同临床环境的泛化等方面的开放挑战。"}}
{"id": "2507.13175", "title": "Black Box Deployed -- Functional Criteria for Artificial Moral Agents in the LLM Era", "authors": ["Matthew E. Brophy"], "abstract": "The advancement of powerful yet opaque large language models (LLMs) necessitates a fundamental revision of the philosophical criteria used to evaluate artificial moral agents (AMAs). Pre-LLM frameworks often relied on the assumption of transparent architectures, which LLMs defy due to their stochastic outputs and opaque internal states. This paper argues that traditional ethical criteria are pragmatically obsolete for LLMs due to this mismatch. Engaging with core themes in the philosophy of technology, this paper proffers a revised set of ten functional criteria to evaluate LLM-based artificial moral agents: moral concordance, context sensitivity, normative integrity, metaethical awareness, system resilience, trustworthiness, corrigibility, partial transparency, functional autonomy, and moral imagination. These guideposts, applied to what we term \"SMA-LLS\" (Simulating Moral Agency through Large Language Systems), aim to steer AMAs toward greater alignment and beneficial societal integration in the coming years. We illustrate these criteria using hypothetical scenarios involving an autonomous public bus (APB) to demonstrate their practical applicability in morally salient contexts.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "42 pages. Supplementary material included at end of article", "pdf_url": "https://arxiv.org/pdf/2507.13175.pdf", "abstract_url": "https://arxiv.org/abs/2507.13175", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一套修订后的功能标准，用于评估基于大型语言模型（LLM）的人工道德代理（AMAs），以应对LLM时代中传统伦理标准的不适用性。", "motivation": "由于大型语言模型（LLMs）的随机输出和不透明的内部状态，传统的伦理标准在评估人工道德代理（AMAs）时显得不切实际，这促使了对评估标准进行根本性修订的需求。", "method": "本文提出了十项功能标准，包括道德一致性、上下文敏感性、规范性完整性、元伦理意识、系统韧性、可信赖性、可纠正性、部分透明性、功能自主性和道德想象力，用于评估LLM-based AMAs。", "result": "通过一个自主公共巴士（APB）的假设场景，这些标准展示了其在道德显著情境中的实际应用性。", "conclusion": "这些标准旨在引导AMAs在未来几年中实现更大的对齐和有益的社会整合，特别是在LLM时代中。"}}
{"id": "2507.12475", "title": "Coarse Addition and the St. Petersburg Paradox: A Heuristic Perspective", "authors": ["Takashi Izumo"], "abstract": "The St. Petersburg paradox presents a longstanding challenge in decision theory. It describes a game whose expected value is infinite, yet for which no rational finite stake can be determined. Traditional solutions introduce auxiliary assumptions, such as diminishing marginal utility, temporal discounting, or extended number systems. These methods often involve mathematical refinements that may not correspond to how people actually perceive or process numerical information. This paper explores an alternative approach based on a modified operation of addition defined over coarse partitions of the outcome space. In this model, exact numerical values are grouped into perceptual categories, and each value is replaced by a representative element of its group before being added. This method allows for a phenomenon where repeated additions eventually cease to affect the outcome, a behavior described as inertial stabilization. Although this is not intended as a definitive resolution of the paradox, the proposed framework offers a plausible way to represent how agents with limited cognitive precision might handle divergent reward structures. We demonstrate that the St. Petersburg series can become inert under this coarse addition for a suitably constructed partition. The approach may also have broader applications in behavioral modeling and the study of machine reasoning under perceptual limitations.", "subjects": "Theoretical Economics (econ.TH); Artificial Intelligence (cs.AI); Optimization and Control (math.OC)", "comments": "16 pages, no figure", "pdf_url": "https://arxiv.org/pdf/2507.12475.pdf", "abstract_url": "https://arxiv.org/abs/2507.12475", "categories": ["Theoretical Economics (econ.TH)", "Artificial Intelligence (cs.AI)", "Optimization and Control (math.OC)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了圣彼得堡悖论，提出了基于粗粒度加法操作的替代解决方案，通过将数值分组并在加法中使用代表元素，模拟有限认知精度下的决策过程。", "motivation": "解决圣彼得堡悖论中无限期望值与有限理性决策之间的矛盾，传统方法依赖额外假设，可能与人类实际数值处理方式不符。", "method": "采用粗粒度加法操作，将数值分组并用代表元素替代原值进行加法，模拟认知限制下的决策过程。", "result": "在适当构建的分区下，圣彼得堡级数在粗粒度加法下可达到惯性稳定，即重复加法不再影响结果。", "conclusion": "提出的框架为有限认知精度代理处理发散奖励结构提供了合理表示，对行为建模和机器在感知限制下的推理研究有广泛适用性。"}}
{"id": "2507.12486", "title": "On multiagent online problems with predictions", "authors": ["Gabriel Istrate", "Cosmin Bonchis", "Victor Bogdan"], "abstract": "We study the power of (competitive) algorithms with predictions in a multiagent setting. We introduce a two predictor framework, that assumes that agents use one predictor for their future (self) behavior, and one for the behavior of the other players. The main problem we are concerned with is understanding what are the best competitive ratios that can be achieved by employing such predictors, under various assumptions on predictor quality.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2507.12486.pdf", "abstract_url": "https://arxiv.org/abs/2507.12486", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Computer Science and Game Theory (cs.GT)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究了在多智能体在线问题中使用预测的（竞争性）算法的能力。作者引入了一个双预测器框架，假设智能体使用一个预测器来预测自身未来行为，另一个预测其他玩家的行为。主要关注的问题是理解在不同预测器质量假设下，使用此类预测器可以实现的最佳竞争比。", "motivation": "解决在多智能体环境中，如何利用预测来提高算法的竞争性能，特别是在预测自身和其他玩家行为时的最佳竞争比问题。", "method": "引入了一个双预测器框架，分别用于预测智能体自身和其他玩家的未来行为，并分析在不同预测质量下的竞争比。", "result": "探讨了在不同预测器质量假设下，使用双预测器框架可以实现的最佳竞争比。", "conclusion": "通过双预测器框架，可以在多智能体在线问题中有效利用预测来提高算法的竞争性能，具体效果取决于预测器的质量。"}}
{"id": "2507.12767", "title": "Autonomy for Older Adult-Agent Interaction", "authors": ["Jiaxin An"], "abstract": "As the global population ages, artificial intelligence (AI)-powered agents have emerged as potential tools to support older adults' caregiving. Prior research has explored agent autonomy by identifying key interaction stages in task processes and defining the agent's role at each stage. However, ensuring that agents align with older adults' autonomy preferences remains a critical challenge. Drawing on interdisciplinary conceptualizations of autonomy, this paper examines four key dimensions of autonomy for older adults: decision-making autonomy, goal-oriented autonomy, control autonomy, and social responsibility autonomy. This paper then proposes the following research directions: (1) Addressing social responsibility autonomy, which concerns the ethical and social implications of agent use in communal settings; (2) Operationalizing agent autonomy from the task perspective; and (3) Developing autonomy measures.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": "7 pages", "pdf_url": "https://arxiv.org/pdf/2507.12767.pdf", "abstract_url": "https://arxiv.org/abs/2507.12767", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了人工智能代理在支持老年人护理中的自主性问题，提出了四个关键自主性维度，并建议了未来研究方向。", "motivation": "随着全球人口老龄化，人工智能代理成为支持老年人护理的潜在工具。然而，如何确保这些代理与老年人的自主性偏好保持一致仍是一个关键挑战。", "method": "本文借鉴了跨学科的自主性概念，分析了老年人自主性的四个关键维度，并提出了三个研究方向。", "result": "提出了四个关键自主性维度：决策自主性、目标导向自主性、控制自主性和社会责任自主性，并建议了未来研究的三个方向。", "conclusion": "本文强调了在开发老年人护理的人工智能代理时考虑其自主性的重要性，并提出了具体的研究方向以解决这一挑战。"}}
{"id": "2507.12496", "title": "FOUNDER: Grounding Foundation Models in World Models for Open-Ended Embodied Decision Making", "authors": ["Yucen Wang", "Rui Yu", "Shenghua Wan", "Le Gan", "De-Chuan Zhan"], "abstract": "Foundation Models (FMs) and World Models (WMs) offer complementary strengths in task generalization at different levels. In this work, we propose FOUNDER, a framework that integrates the generalizable knowledge embedded in FMs with the dynamic modeling capabilities of WMs to enable open-ended task solving in embodied environments in a reward-free manner. We learn a mapping function that grounds FM representations in the WM state space, effectively inferring the agent's physical states in the world simulator from external observations. This mapping enables the learning of a goal-conditioned policy through imagination during behavior learning, with the mapped task serving as the goal state. Our method leverages the predicted temporal distance to the goal state as an informative reward signal. FOUNDER demonstrates superior performance on various multi-task offline visual control benchmarks, excelling in capturing the deep-level semantics of tasks specified by text or videos, particularly in scenarios involving complex observations or domain gaps where prior methods struggle. The consistency of our learned reward function with the ground-truth reward is also empirically validated. Our project website is", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "Accepted by Forty-Second International Conference on Machine Learning (ICML 2025)", "pdf_url": "https://arxiv.org/pdf/2507.12496.pdf", "abstract_url": "https://arxiv.org/abs/2507.12496", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了FOUNDER框架，通过将基础模型（FMs）的通用知识与世界模型（WMs）的动态建模能力相结合，以无奖励的方式在具身环境中实现开放式任务解决。FOUNDER通过学习一个映射函数，将FM表示基础于WM状态空间，从而从外部观察中推断代理在世界模拟器中的物理状态。该方法利用预测到目标状态的时间距离作为信息丰富的奖励信号，在各种多任务离线视觉控制基准测试中表现出色，特别是在涉及复杂观察或领域差距的场景中。", "motivation": "解决在具身环境中实现开放式任务解决的挑战，特别是在复杂观察或领域差距的情况下，现有方法难以捕捉任务深层次语义的问题。", "method": "提出FOUNDER框架，通过集成基础模型（FMs）和世界模型（WMs）的互补优势，学习一个映射函数将FM表示基础于WM状态空间，并利用预测的时间距离作为奖励信号，学习目标条件策略。", "result": "FOUNDER在多任务离线视觉控制基准测试中表现出色，能够有效捕捉由文本或视频指定的任务的深层次语义，特别是在复杂观察或领域差距的场景中。", "conclusion": "FOUNDER框架通过结合FMs和WMs的优势，为开放式具身决策提供了有效的解决方案，特别是在处理复杂观察和领域差距方面显示出强大的能力。"}}
{"id": "2507.12846", "title": "Enter the Mind Palace: Reasoning and Planning for Long-term Active Embodied Question Answering", "authors": ["Muhammad Fadhil Ginting", "Dong-Ki Kim", "Xiangyun Meng", "Andrzej Reinke", "Bandi Jai Krishna", "Navid Kayhani", "Oriana Peltzer", "David D. Fan", "Amirreza Shaban", "Sung-Kyun Kim", "Mykel J. Kochenderfer", "Ali-akbar Agha-mohammadi", "Shayegan Omidshafiei"], "abstract": "As robots become increasingly capable of operating over extended periods -- spanning days, weeks, and even months -- they are expected to accumulate knowledge of their environments and leverage this experience to assist humans more effectively. This paper studies the problem of Long-term Active Embodied Question Answering (LA-EQA), a new task in which a robot must both recall past experiences and actively explore its environment to answer complex, temporally-grounded questions. Unlike traditional EQA settings, which typically focus either on understanding the present environment alone or on recalling a single past observation, LA-EQA challenges an agent to reason over past, present, and possible future states, deciding when to explore, when to consult its memory, and when to stop gathering observations and provide a final answer. Standard EQA approaches based on large models struggle in this setting due to limited context windows, absence of persistent memory, and an inability to combine memory recall with active exploration. To address this, we propose a structured memory system for robots, inspired by the mind palace method from cognitive science. Our method encodes episodic experiences as scene-graph-based world instances, forming a reasoning and planning algorithm that enables targeted memory retrieval and guided navigation. To balance the exploration-recall trade-off, we introduce value-of-information-based stopping criteria that determines when the agent has gathered sufficient information. We evaluate our method on real-world experiments and introduce a new benchmark that spans popular simulation environments and actual industrial sites. Our approach significantly outperforms state-of-the-art baselines, yielding substantial gains in both answer accuracy and exploration efficiency.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.12846.pdf", "abstract_url": "https://arxiv.org/abs/2507.12846", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究了长期主动具身问答（LA-EQA）问题，提出了一种受认知科学中“记忆宫殿”方法启发的结构化记忆系统，用于机器人在长时间操作中积累知识并有效回答复杂问题。", "motivation": "解决机器人在长时间操作中如何有效积累和利用环境知识，以回答复杂、时间基础的问题，克服传统EQA方法在上下文窗口有限、缺乏持久记忆以及无法结合记忆检索与主动探索方面的不足。", "method": "提出了一种基于场景图的世界实例编码的叙事体验的结构化记忆系统，结合推理和规划算法，实现了有针对性的记忆检索和引导导航，并引入了基于信息价值的停止标准来平衡探索与回忆的权衡。", "result": "在真实世界实验和新基准测试中，该方法在回答准确性和探索效率方面显著优于现有最先进的基线方法。", "conclusion": "通过结构化记忆系统和信息价值评估，机器人能够在长期操作中更有效地积累和利用知识，显著提高了回答复杂问题的能力和探索效率。"}}
{"id": "2507.13169", "title": "Prompt Injection 2.0: Hybrid AI Threats", "authors": ["Jeremy McHugh", "Kristina Šekrst", "Jon Cefalu"], "abstract": "Prompt injection attacks, where malicious input is designed to manipulate AI systems into ignoring their original instructions and following unauthorized commands instead, were first discovered by Preamble, Inc. in May 2022 and responsibly disclosed to OpenAI. Over the last three years, these attacks have continued to pose a critical security threat to LLM-integrated systems. The emergence of agentic AI systems, where LLMs autonomously perform multistep tasks through tools and coordination with other agents, has fundamentally transformed the threat landscape. Modern prompt injection attacks can now combine with traditional cybersecurity exploits to create hybrid threats that systematically evade traditional security controls. This paper presents a comprehensive analysis of Prompt Injection 2.0, examining how prompt injections integrate with Cross-Site Scripting (XSS), Cross-Site Request Forgery (CSRF), and other web security vulnerabilities to bypass traditional security measures. We build upon Preamble's foundational research and mitigation technologies, evaluating them against contemporary threats, including AI worms, multi-agent infections, and hybrid cyber-AI attacks. Our analysis incorporates recent benchmarks that demonstrate how traditional web application firewalls, XSS filters, and CSRF tokens fail against AI-enhanced attacks. We also present architectural solutions that combine prompt isolation, runtime security, and privilege separation with novel threat detection capabilities.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.13169.pdf", "abstract_url": "https://arxiv.org/abs/2507.13169", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文分析了Prompt Injection 2.0，探讨了如何将提示注入与XSS、CSRF等网络安全漏洞结合，以绕过传统安全措施。", "motivation": "解决AI系统，特别是LLM集成系统面临的新型安全威胁，即提示注入攻击与传统网络安全漏洞结合的混合威胁。", "method": "基于Preamble的基础研究和缓解技术，评估了当代威胁，包括AI蠕虫、多代理感染和混合网络-AI攻击，并提出了结合提示隔离、运行时安全和权限分离的架构解决方案。", "result": "传统网络应用防火墙、XSS过滤器和CSRF令牌对AI增强的攻击无效，需要新的安全架构来应对这些威胁。", "conclusion": "Prompt Injection 2.0代表了AI安全领域的新挑战，需要结合传统网络安全措施和新型威胁检测能力来有效防御。"}}
{"id": "2507.13171", "title": "Aligning Humans and Robots via Reinforcement Learning from Implicit Human Feedback", "authors": ["Suzie Kim", "Hye-Bin Shin", "Seong-Whan Lee"], "abstract": "Conventional reinforcement learning (RL) ap proaches often struggle to learn effective policies under sparse reward conditions, necessitating the manual design of complex, task-specific reward functions. To address this limitation, rein forcement learning from human feedback (RLHF) has emerged as a promising strategy that complements hand-crafted rewards with human-derived evaluation signals. However, most existing RLHF methods depend on explicit feedback mechanisms such as button presses or preference labels, which disrupt the natural interaction process and impose a substantial cognitive load on the user. We propose a novel reinforcement learning from implicit human feedback (RLIHF) framework that utilizes non-invasive electroencephalography (EEG) signals, specifically error-related potentials (ErrPs), to provide continuous, implicit feedback without requiring explicit user intervention. The proposed method adopts a pre-trained decoder to transform raw EEG signals into probabilistic reward components, en abling effective policy learning even in the presence of sparse external rewards. We evaluate our approach in a simulation environment built on the MuJoCo physics engine, using a Kinova Gen2 robotic arm to perform a complex pick-and-place task that requires avoiding obstacles while manipulating target objects. The results show that agents trained with decoded EEG feedback achieve performance comparable to those trained with dense, manually designed rewards. These findings validate the potential of using implicit neural feedback for scalable and human-aligned reinforcement learning in interactive robotics.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.13171.pdf", "abstract_url": "https://arxiv.org/abs/2507.13171", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新颖的基于隐式人类反馈的强化学习（RLIHF）框架，利用非侵入性脑电图（EEG）信号，特别是错误相关电位（ErrPs），在不需用户显式干预的情况下提供连续的隐式反馈。该方法在稀疏外部奖励的情况下也能有效学习策略，并在模拟环境中验证了其有效性。", "motivation": "传统的强化学习方法在稀疏奖励条件下往往难以学习有效策略，需要手动设计复杂、任务特定的奖励函数。现有的基于人类反馈的强化学习（RLHF）方法大多依赖于显式反馈机制，如按钮按压或偏好标签，这不仅打断了自然交互过程，还给用户带来了巨大的认知负担。", "method": "提出的RLIHF框架利用非侵入性脑电图（EEG）信号，特别是错误相关电位（ErrPs），通过预训练的解码器将原始EEG信号转换为概率奖励组件，从而在不需显式用户干预的情况下提供连续的隐式反馈。", "result": "在基于MuJoCo物理引擎构建的模拟环境中，使用Kinova Gen2机械臂执行需要避开障碍物同时操纵目标物体的复杂拾放任务时，使用解码EEG反馈训练的代理实现了与使用密集、手动设计奖励训练的代理相当的性能。", "conclusion": "这些发现验证了在交互式机器人中使用隐式神经反馈进行可扩展和人类对齐的强化学习的潜力。"}}
