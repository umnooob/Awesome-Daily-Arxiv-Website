{"id": "2504.17207", "title": "Perspective-Aware Reasoning in Vision-Language Models via Mental Imagery Simulation", "authors": ["Phillip Y. Lee", "Jihyeon Je", "Chanho Park", "Mikaela Angelina Uy", "Leonidas Guibas", "Minhyuk Sung"], "abstract": "We present a framework for perspective-aware reasoning in vision-language models (VLMs) through mental imagery simulation. Perspective-taking, the ability to perceive an environment or situation from an alternative viewpoint, is a key benchmark for human-level visual understanding, essential for environmental interaction and collaboration with autonomous agents. Despite advancements in spatial reasoning within VLMs, recent research has shown that modern VLMs significantly lack perspective-aware reasoning capabilities and exhibit a strong bias toward egocentric interpretations. To bridge the gap between VLMs and human perception, we focus on the role of mental imagery, where humans perceive the world through abstracted representations that facilitate perspective shifts. Motivated by this, we propose a framework for perspective-aware reasoning, named Abstract Perspective Change (APC), that effectively leverages vision foundation models, such as object detection, segmentation, and orientation estimation, to construct scene abstractions and enable perspective transformations. Our experiments on synthetic and real-image benchmarks, compared with various VLMs, demonstrate significant improvements in perspective-aware reasoning with our framework, further outperforming fine-tuned spatial reasoning models and novel-view-synthesis-based approaches.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2504.17207.pdf", "abstract_url": "https://arxiv.org/abs/2504.17207", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一个通过心理意象模拟在视觉语言模型（VLMs）中进行视角感知推理的框架，旨在解决VLMs在视角感知推理能力上的不足。", "motivation": "视角感知是人类视觉理解的关键能力，对于环境交互和与自主代理的合作至关重要。然而，现代VLMs在这方面存在显著不足，表现出强烈的自我中心解释偏见。", "method": "作者提出了一个名为抽象视角变化（APC）的框架，利用视觉基础模型（如物体检测、分割和方向估计）构建场景抽象并实现视角转换。", "result": "在合成和真实图像基准上的实验表明，该框架在视角感知推理方面显著优于现有的VLMs，甚至超过了经过微调的空间推理模型和基于新视角合成的方法。", "conclusion": "通过模拟人类心理意象，APC框架有效地提升了VLMs的视角感知推理能力，为更接近人类水平的视觉理解迈出了重要一步。"}}
{"id": "2504.17371", "title": "Highly Accurate and Diverse Traffic Data: The DeepScenario Open 3D Dataset", "authors": ["Oussema Dhaouadi", "Johannes Meier", "Luca Wahl", "Jacques Kaiser", "Luca Scalerandi", "Nick Wandelburg", "Zhuolun Zhou", "Nijanthan Berinpanathan", "Holger Banzhaf", "Daniel Cremers"], "abstract": "Accurate 3D trajectory data is crucial for advancing autonomous driving. Yet, traditional datasets are usually captured by fixed sensors mounted on a car and are susceptible to occlusion. Additionally, such an approach can precisely reconstruct the dynamic environment in the close vicinity of the measurement vehicle only, while neglecting objects that are further away. In this paper, we introduce the DeepScenario Open 3D Dataset (DSC3D), a high-quality, occlusion-free dataset of 6 degrees of freedom bounding box trajectories acquired through a novel monocular camera drone tracking pipeline. Our dataset includes more than 175,000 trajectories of 14 types of traffic participants and significantly exceeds existing datasets in terms of diversity and scale, containing many unprecedented scenarios such as complex vehicle-pedestrian interaction on highly populated urban streets and comprehensive parking maneuvers from entry to exit. DSC3D dataset was captured in five various locations in Europe and the United States and include: a parking lot, a crowded inner-city, a steep urban intersection, a federal highway, and a suburban intersection. Our 3D trajectory dataset aims to enhance autonomous driving systems by providing detailed environmental 3D representations, which could lead to improved obstacle interactions and safety. We demonstrate its utility across multiple applications including motion prediction, motion planning, scenario mining, and generative reactive traffic agents. Our interactive online visualization platform and the complete dataset are publicly available at", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.17371.pdf", "abstract_url": "https://arxiv.org/abs/2504.17371", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了DeepScenario Open 3D数据集（DSC3D），这是一个高质量、无遮挡的6自由度边界框轨迹数据集，通过新型单眼相机无人机跟踪流程获取，旨在提升自动驾驶系统的环境3D表示能力。", "motivation": "传统数据集通常由固定在车上的传感器捕获，容易受到遮挡，且仅能精确重建测量车辆附近的动态环境，忽略了远处的物体。", "method": "使用单眼相机无人机跟踪流程，捕获了超过175,000条14种交通参与者的轨迹，数据集在多样性和规模上显著超过现有数据集。", "result": "DSC3D数据集包含了前所未有的场景，如高度城市化街道上的复杂车辆-行人互动和从进入到退出的全面停车操作，覆盖了欧洲和美国的五个不同地点。", "conclusion": "DSC3D数据集通过提供详细的环境3D表示，有望改善自动驾驶系统中的障碍物互动和安全性，适用于运动预测、运动规划、场景挖掘和生成反应性交通代理等多种应用。"}}
{"id": "2504.17213", "title": "MCAF: Efficient Agent-based Video Understanding Framework through Multimodal Coarse-to-Fine Attention Focusing", "authors": ["Shiwen Cao", "Zhaoxing Zhang", "Junming Jiao", "Juyi Qiao", "Guowen Song", "Rong Shen"], "abstract": "Even in the era of rapid advances in large models, video understanding, particularly long videos, remains highly challenging. Compared with textual or image-based information, videos commonly contain more information with redundancy, requiring large models to strategically allocate attention at a global level for accurate comprehension. To address this, we propose MCAF, an agent-based, training-free framework perform video understanding through Multimodal Coarse-to-fine Attention Focusing. The key innovation lies in its ability to sense and prioritize segments of the video that are highly relevant to the understanding task. First, MCAF hierarchically concentrates on highly relevant frames through multimodal information, enhancing the correlation between the acquired contextual information and the query. Second, it employs a dilated temporal expansion mechanism to mitigate the risk of missing crucial details when extracting information from these concentrated frames. In addition, our framework incorporates a self-reflection mechanism utilizing the confidence level of the model's responses as feedback. By iteratively applying these two creative focusing strategies, it adaptively adjusts attention to capture highly query-connected context and thus improves response accuracy. MCAF outperforms comparable state-of-the-art methods on average. On the EgoSchema dataset, it achieves a remarkable 5% performance gain over the leading approach. Meanwhile, on Next-QA and IntentQA datasets, it outperforms the current state-of-the-art standard by 0.2% and 0.3% respectively. On the Video-MME dataset, which features videos averaging nearly an hour in length, MCAF also outperforms other agent-based methods.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.17213.pdf", "abstract_url": "https://arxiv.org/abs/2504.17213", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "MCAF是一种基于代理的、无需训练的视频理解框架，通过多模态从粗到细的注意力聚焦来提高长视频理解的效率和准确性。", "motivation": "解决长视频理解中的信息冗余和注意力分配问题，提高模型对视频内容的理解准确率。", "method": "采用多模态从粗到细的注意力聚焦策略，包括层次化聚焦相关帧和使用扩张时间扩展机制，以及自我反思机制来调整注意力。", "result": "在EgoSchema数据集上表现优于领先方法5%，在Next-QA和IntentQA数据集上分别优于当前最先进标准0.2%和0.3%，在Video-MME数据集上也优于其他基于代理的方法。", "conclusion": "MCAF通过创新的注意力聚焦策略，有效提高了长视频理解的准确性和效率，为视频理解领域提供了新的解决方案。"}}
{"id": "2504.17137", "title": "MIRAGE: A Metric-Intensive Benchmark for Retrieval-Augmented Generation Evaluation", "authors": ["Chanhee Park", "Hyeonseok Moon", "Chanjun Park", "Heuiseok Lim"], "abstract": "Retrieval-Augmented Generation (RAG) has gained prominence as an effective method for enhancing the generative capabilities of Large Language Models (LLMs) through the incorporation of external knowledge. However, the evaluation of RAG systems remains a challenge, due to the intricate interplay between retrieval and generation components. This limitation has resulted in a scarcity of benchmarks that facilitate a detailed, component-specific assessment. In this work, we present MIRAGE, a Question Answering dataset specifically designed for RAG evaluation. MIRAGE consists of 7,560 curated instances mapped to a retrieval pool of 37,800 entries, enabling an efficient and precise evaluation of both retrieval and generation tasks. We also introduce novel evaluation metrics aimed at measuring RAG adaptability, encompassing dimensions such as noise vulnerability, context acceptability, context insensitivity, and context misinterpretation. Through comprehensive experiments across various retriever-LLM configurations, we provide new insights into the optimal alignment of model pairs and the nuanced dynamics within RAG systems. The dataset and evaluation code are publicly available, allowing for seamless integration and customization in diverse research settings\\footnote{The MIRAGE code and data are available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "Accepted to NAACL2025 Findings", "pdf_url": "https://arxiv.org/pdf/2504.17137.pdf", "abstract_url": "https://arxiv.org/abs/2504.17137", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "MIRAGE是一个专为检索增强生成（RAG）评估设计的问答数据集，包含7,560个实例和37,800个检索条目，旨在通过新颖的评估指标全面评估RAG系统的检索和生成能力。", "motivation": "当前RAG系统的评估面临挑战，缺乏能够详细评估检索和生成组件的基准，这限制了RAG系统的深入研究和优化。", "method": "提出了MIRAGE数据集，包含大量精心挑选的实例和检索条目，并引入新的评估指标来衡量RAG的适应性，包括噪声脆弱性、上下文可接受性、上下文不敏感性和上下文误解等维度。", "result": "通过在不同检索器-LLM配置上的全面实验，提供了关于模型对最优对齐和RAG系统内部细微动态的新见解。", "conclusion": "MIRAGE数据集和评估代码的公开可用性，为多样化研究环境中的集成和定制提供了便利，推动了RAG系统的评估和研究进展。"}}
{"id": "2504.17447", "title": "FRAG: Frame Selection Augmented Generation for Long Video and Long Document Understanding", "authors": ["De-An Huang", "Subhashree Radhakrishnan", "Zhiding Yu", "Jan Kautz"], "abstract": "There has been impressive progress in Large Multimodal Models (LMMs). Recent works extend these models to long inputs, including multi-page documents and long videos. However, the model size and performance of these long context models are still limited due to the computational cost in both training and inference. In this work, we explore an orthogonal direction and process long inputs without long context LMMs. We propose Frame Selection Augmented Generation (FRAG), where the model first selects relevant frames within the input, and then only generates the final outputs based on the selected frames. The core of the selection process is done by scoring each frame independently, which does not require long context processing. The frames with the highest scores are then selected by a simple Top-K selection. We show that this frustratingly simple framework is applicable to both long videos and multi-page documents using existing LMMs without any fine-tuning. We consider two models, LLaVA-OneVision and InternVL2, in our experiments and show that FRAG consistently improves the performance and achieves state-of-the-art performances for both long video and long document understanding. For videos, FRAG substantially improves InternVL2-76B by 5.8% on MLVU and 3.7% on Video-MME. For documents, FRAG achieves over 20% improvements on MP-DocVQA compared with recent LMMs specialized in long document understanding. Code is available at:", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.17447.pdf", "abstract_url": "https://arxiv.org/abs/2504.17447", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种名为FRAG的框架，通过选择输入中的相关帧来增强长视频和多页文档的理解，无需长上下文处理，显著提高了现有大型多模态模型的性能。", "motivation": "解决长输入（如长视频和多页文档）理解中由于计算成本限制模型规模和性能的问题。", "method": "提出Frame Selection Augmented Generation (FRAG)框架，通过独立评分选择相关帧，然后基于所选帧生成最终输出。", "result": "FRAG在长视频和文档理解任务中显著提升性能，如在MLVU和Video-MME上分别提升5.8%和3.7%，在MP-DocVQA上提升超过20%。", "conclusion": "FRAG框架简单有效，无需微调即可应用于现有大型多模态模型，显著提升长视频和文档理解的性能。"}}
{"id": "2504.17192", "title": "Paper2Code: Automating Code Generation from Scientific Papers in Machine Learning", "authors": ["Minju Seo", "Jinheon Baek", "Seongyun Lee", "Sung Ju Hwang"], "abstract": "Despite the rapid growth of machine learning research, corresponding code implementations are often unavailable, making it slow and labor-intensive for researchers to reproduce results and build upon prior work. In the meantime, recent Large Language Models (LLMs) excel at understanding scientific documents and generating high-quality code. Inspired by this, we introduce PaperCoder, a multi-agent LLM framework that transforms machine learning papers into functional code repositories. PaperCoder operates in three stages: planning, where it constructs a high-level roadmap, designs the system architecture with diagrams, identifies file dependencies, and generates configuration files; analysis, which focuses on interpreting implementation-specific details; and generation, where modular, dependency-aware code is produced. Moreover, each phase is instantiated through a set of specialized agents designed to collaborate effectively across the pipeline. We then evaluate PaperCoder on generating code implementations from machine learning papers based on both model-based and human evaluations, specifically from the original paper authors, with author-released repositories as ground truth if available. Our results demonstrate the effectiveness of PaperCoder in creating high-quality, faithful implementations. Furthermore, it consistently shows strengths in the recently released PaperBench benchmark, surpassing strong baselines by substantial margins.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.17192.pdf", "abstract_url": "https://arxiv.org/abs/2504.17192", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "PaperCoder是一个多代理大型语言模型框架，旨在将机器学习论文转化为功能性代码库，通过规划、分析和生成三个阶段实现，并在模型和人类评估中显示出高效和高质量的实现能力。", "motivation": "机器学习研究的快速增长往往缺乏相应的代码实现，这使得研究人员在复现结果和基于先前工作构建时既慢又费力。", "method": "PaperCoder采用多代理大型语言模型框架，通过规划、分析和生成三个阶段，将科学论文转化为功能性代码库。每个阶段由专门设计的代理实例化，以在管道中有效协作。", "result": "PaperCoder在从机器学习论文生成代码实现方面显示出高效和高质量的能力，在PaperBench基准测试中超越了强基线。", "conclusion": "PaperCoder通过自动化代码生成，显著提高了机器学习研究的可复现性和效率，为研究人员提供了强大的工具。"}}
{"id": "2504.16939", "title": "A Desideratum for Conversational Agents: Capabilities, Challenges, and Future Directions", "authors": ["Emre Can Acikgoz", "Cheng Qian", "Hongru Wang", "Vardhan Dongre", "Xiusi Chen", "Heng Ji", "Dilek Hakkani-Tür", "Gokhan Tur"], "abstract": "Recent advances in Large Language Models (LLMs) have propelled conversational AI from traditional dialogue systems into sophisticated agents capable of autonomous actions, contextual awareness, and multi-turn interactions with users. Yet, fundamental questions about their capabilities, limitations, and paths forward remain open. This survey paper presents a desideratum for next-generation Conversational Agents - what has been achieved, what challenges persist, and what must be done for more scalable systems that approach human-level intelligence. To that end, we systematically analyze LLM-driven Conversational Agents by organizing their capabilities into three primary dimensions: (i) Reasoning - logical, systematic thinking inspired by human intelligence for decision making, (ii) Monitor - encompassing self-awareness and user interaction monitoring, and (iii) Control - focusing on tool utilization and policy following. Building upon this, we introduce a novel taxonomy by classifying recent work on Conversational Agents around our proposed desideratum. We identify critical research gaps and outline key directions, including realistic evaluations, long-term multi-turn reasoning skills, self-evolution capabilities, collaborative and multi-agent task completion, personalization, and proactivity. This work aims to provide a structured foundation, highlight existing limitations, and offer insights into potential future research directions for Conversational Agents, ultimately advancing progress toward Artificial General Intelligence (AGI). We maintain a curated repository of papers at:", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.16939.pdf", "abstract_url": "https://arxiv.org/abs/2504.16939", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文综述了大型语言模型（LLMs）驱动的对话代理的最新进展，提出了一个期望清单，包括已实现的成就、存在的挑战以及未来发展方向。", "motivation": "探讨对话代理的能力、局限性和未来发展路径，以推动其向更接近人类智能的水平发展。", "method": "系统分析对话代理的能力，将其分为三个主要维度：推理、监控和控制，并围绕这一期望清单对近期工作进行分类。", "result": "提出了一个新的分类法，识别了关键的研究空白，并概述了包括现实评估、长期多轮推理技能、自我进化能力等在内的关键方向。", "conclusion": "本文旨在为对话代理提供一个结构化的基础，突出现有局限性，并为未来研究方向提供见解，最终推动人工通用智能（AGI）的进步。"}}
{"id": "2504.17200", "title": "A RAG-Based Multi-Agent LLM System for Natural Hazard Resilience and Adaptation", "authors": ["Yangxinyu Xie", "Bowen Jiang", "Tanwi Mallick", "Joshua David Bergerson", "John K. Hutchison", "Duane R. Verner", "Jordan Branham", "M. Ross Alexander", "Robert B. Ross", "Yan Feng", "Leslie-Anne Levy", "Weijie Su", "Camillo J. Taylor"], "abstract": "Large language models (LLMs) are a transformational capability at the frontier of artificial intelligence and machine learning that can support decision-makers in addressing pressing societal challenges such as extreme natural hazard events. As generalized models, LLMs often struggle to provide context-specific information, particularly in areas requiring specialized knowledge. In this work we propose a retrieval-augmented generation (RAG)-based multi-agent LLM system to support analysis and decision-making in the context of natural hazards and extreme weather events. As a proof of concept, we present WildfireGPT, a specialized system focused on wildfire hazards. The architecture employs a user-centered, multi-agent design to deliver tailored risk insights across diverse stakeholder groups. By integrating natural hazard and extreme weather projection data, observational datasets, and scientific literature through an RAG framework, the system ensures both the accuracy and contextual relevance of the information it provides. Evaluation across ten expert-led case studies demonstrates that WildfireGPT significantly outperforms existing LLM-based solutions for decision support.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.17200.pdf", "abstract_url": "https://arxiv.org/abs/2504.17200", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文提出了一种基于检索增强生成（RAG）的多代理大型语言模型（LLM）系统，旨在支持自然灾害和极端天气事件的分析与决策。通过WildfireGPT这一专注于野火灾害的专门系统作为概念验证，展示了该系统如何通过整合自然灾害和极端天气预测数据、观测数据集及科学文献，提供准确且上下文相关的信息。", "motivation": "大型语言模型（LLMs）作为人工智能和机器学习领域的前沿技术，能够支持决策者应对极端自然灾害等紧迫社会挑战。然而，作为通用模型，LLMs在需要专业知识的领域往往难以提供特定上下文的信息。", "method": "本研究采用了一种基于检索增强生成（RAG）的多代理LLM系统架构，通过整合自然灾害和极端天气的预测数据、观测数据集及科学文献，确保所提供信息的准确性和上下文相关性。", "result": "通过十个专家主导的案例研究评估，WildfireGPT在决策支持方面显著优于现有的基于LLM的解决方案。", "conclusion": "本研究提出的RAG-based多代理LLM系统为自然灾害和极端天气事件的分析与决策提供了有效的支持，特别是在需要专业知识和上下文相关信息的领域。WildfireGPT的成功验证了该方法的实用性和有效性。"}}
{"id": "2504.17087", "title": "Leveraging LLMs as Meta-Judges: A Multi-Agent Framework for Evaluating LLM Judgments", "authors": ["Yuran Li", "Jama Hussein Mohamud", "Chongren Sun", "Di Wu", "Benoit Boulet"], "abstract": "Large language models (LLMs) are being widely applied across various fields, but as tasks become more complex, evaluating their responses is increasingly challenging. Compared to human evaluators, the use of LLMs to support performance evaluation offers a more efficient alternative. However, most studies focus mainly on aligning LLMs' judgments with human preferences, overlooking the existence of biases and mistakes in human judgment. Furthermore, how to select suitable LLM judgments given multiple potential LLM responses remains underexplored. To address these two aforementioned issues, we propose a three-stage meta-judge selection pipeline: 1) developing a comprehensive rubric with GPT-4 and human experts, 2) using three advanced LLM agents to score judgments, and 3) applying a threshold to filter out low-scoring judgments. Compared to methods using a single LLM as both judge and meta-judge, our pipeline introduces multi-agent collaboration and a more comprehensive rubric. Experimental results on the JudgeBench dataset show about 15.55\\% improvement compared to raw judgments and about 8.37\\% improvement over the single-agent baseline. Our work demonstrates the potential of LLMs as meta-judges and lays the foundation for future research on constructing preference datasets for LLM-as-a-judge reinforcement learning.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "12 pages, 5 figures, 6 tables", "pdf_url": "https://arxiv.org/pdf/2504.17087.pdf", "abstract_url": "https://arxiv.org/abs/2504.17087", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种利用大型语言模型（LLMs）作为元评判者的三阶段选择流程，通过多智能体协作和综合评分标准，提高了LLM判断的准确性和效率。", "motivation": "随着任务复杂度的增加，评估LLMs的响应变得越来越困难。现有研究主要关注将LLMs的判断与人类偏好对齐，忽视了人类判断中的偏见和错误，以及如何从多个潜在的LLM响应中选择合适的判断。", "method": "提出了一个三阶段的元评判选择流程：1) 与GPT-4和人类专家共同开发综合评分标准；2) 使用三个先进的LLM智能体对判断进行评分；3) 应用阈值过滤低分判断。", "result": "在JudgeBench数据集上的实验结果显示，与原始判断相比提高了约15.55%，与单智能体基线相比提高了约8.37%。", "conclusion": "我们的工作展示了LLMs作为元评判者的潜力，并为未来构建用于LLM作为评判者的强化学习偏好数据集的研究奠定了基础。"}}
{"id": "2504.17282", "title": "Cracking the Code of Action: a Generative Approach to Affordances for Reinforcement Learning", "authors": ["Lynn Cherif", "Flemming Kondrup", "David Venuto", "Ankit Anand", "Doina Precup", "Khimya Khetarpal"], "abstract": "Agents that can autonomously navigate the web through a graphical user interface (GUI) using a unified action space (e.g., mouse and keyboard actions) can require very large amounts of domain-specific expert demonstrations to achieve good performance. Low sample efficiency is often exacerbated in sparse-reward and large-action-space environments, such as a web GUI, where only a few actions are relevant in any given situation. In this work, we consider the low-data regime, with limited or no access to expert behavior. To enable sample-efficient learning, we explore the effect of constraining the action space through $\\textit{intent-based affordances}$ -- i.e., considering in any situation only the subset of actions that achieve a desired outcome. We propose $\\textbf{Code as Generative Affordances}$ $(\\textbf{$\\texttt{CoGA}$})$, a method that leverages pre-trained vision-language models (VLMs) to generate code that determines affordable actions through implicit intent-completion functions and using a fully-automated program generation and verification pipeline. These programs are then used in-the-loop of a reinforcement learning agent to return a set of affordances given a pixel observation. By greatly reducing the number of actions that an agent must consider, we demonstrate on a wide range of tasks in the MiniWob++ benchmark that: $\\textbf{1)}$ $\\texttt{CoGA}$ is orders of magnitude more sample efficient than its RL agent, $\\textbf{2)}$ $\\texttt{CoGA}$'s programs can generalize within a family of tasks, and $\\textbf{3)}$ $\\texttt{CoGA}$ performs better or on par compared with behavior cloning when a small number of expert demonstrations is available.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.17282.pdf", "abstract_url": "https://arxiv.org/abs/2504.17282", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为CoGA的方法，通过预训练的视觉语言模型生成代码，以限制强化学习中的动作空间，从而提高样本效率。", "motivation": "解决在图形用户界面（GUI）中通过统一动作空间（如鼠标和键盘动作）自主导航的代理需要大量领域特定专家演示才能达到良好性能的问题。", "method": "利用预训练的视觉语言模型（VLMs）生成代码，通过隐式意图完成函数和全自动程序生成及验证流程，确定可负担的动作。", "result": "在MiniWob++基准测试中，CoGA显示出比其RL代理更高的样本效率，其程序能够在任务家族内泛化，并且在少量专家演示可用时，表现优于或与行为克隆相当。", "conclusion": "CoGA通过限制代理必须考虑的动作数量，显著提高了样本效率，为在低数据环境下进行高效学习提供了可能。"}}
{"id": "2504.17356", "title": "Comprehend, Divide, and Conquer: Feature Subspace Exploration via Multi-Agent Hierarchical Reinforcement Learning", "authors": ["Weiliang Zhang", "Xiaohan Huang", "Yi Du", "Ziyue Qiao", "Qingqing Long", "Zhen Meng", "Yuanchun Zhou", "Meng Xiao"], "abstract": "Feature selection aims to preprocess the target dataset, find an optimal and most streamlined feature subset, and enhance the downstream machine learning task. Among filter, wrapper, and embedded-based approaches, the reinforcement learning (RL)-based subspace exploration strategy provides a novel objective optimization-directed perspective and promising performance. Nevertheless, even with improved performance, current reinforcement learning approaches face challenges similar to conventional methods when dealing with complex datasets. These challenges stem from the inefficient paradigm of using one agent per feature and the inherent complexities present in the datasets. This observation motivates us to investigate and address the above issue and propose a novel approach, namely HRLFS. Our methodology initially employs a Large Language Model (LLM)-based hybrid state extractor to capture each feature's mathematical and semantic characteristics. Based on this information, features are clustered, facilitating the construction of hierarchical agents for each cluster and sub-cluster. Extensive experiments demonstrate the efficiency, scalability, and robustness of our approach. Compared to contemporary or the one-feature-one-agent RL-based approaches, HRLFS improves the downstream ML performance with iterative feature subspace exploration while accelerating total run time by reducing the number of agents involved.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "20 pages, keywords: Automated Feature Engineering, Tabular Dataset, Multi-Agent Reinforcement Learning, Feature Selection", "pdf_url": "https://arxiv.org/pdf/2504.17356.pdf", "abstract_url": "https://arxiv.org/abs/2504.17356", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为HRLFS的新方法，通过多智能体分层强化学习进行特征子空间探索，旨在优化特征选择过程并提升下游机器学习任务的性能。", "motivation": "当前基于强化学习的特征选择方法在处理复杂数据集时面临效率低下和复杂性高的挑战，这促使研究者探索更高效的方法。", "method": "HRLFS方法首先使用基于大型语言模型（LLM）的混合状态提取器捕获每个特征的数学和语义特性，然后根据这些信息对特征进行聚类，进而为每个聚类和子聚类构建分层智能体。", "result": "大量实验证明，HRLFS方法在效率、可扩展性和鲁棒性方面表现出色，与现有的一特征一智能体RL方法相比，HRLFS通过减少参与的智能体数量，不仅加速了总运行时间，还通过迭代特征子空间探索提高了下游ML性能。", "conclusion": "HRLFS为特征选择提供了一种高效、可扩展且鲁棒的新方法，显著提升了处理复杂数据集时的性能和效率。"}}
{"id": "2504.17574", "title": "RAGAT-Mind: A Multi-Granular Modeling Approach for Rumor Detection Based on MindSpore", "authors": ["Zhenkai Qin", "Guifang Yang", "Dongze Wu"], "abstract": "As false information continues to proliferate across social media platforms, effective rumor detection has emerged as a pressing challenge in natural language processing. This paper proposes RAGAT-Mind, a multi-granular modeling approach for Chinese rumor detection, built upon the MindSpore deep learning framework. The model integrates TextCNN for local semantic extraction, bidirectional GRU for sequential context learning, Multi-Head Self-Attention for global dependency focusing, and Bidirectional Graph Convolutional Networks (BiGCN) for structural representation of word co-occurrence graphs. Experiments on the Weibo1-Rumor dataset demonstrate that RAGAT-Mind achieves superior classification performance, attaining 99.2% accuracy and a macro-F1 score of 0.9919. The results validate the effectiveness of combining hierarchical linguistic features with graph-based semantic structures. Furthermore, the model exhibits strong generalization and interpretability, highlighting its practical value for real-world rumor detection applications.", "subjects": "Computation and Language (cs.CL); Computers and Society (cs.CY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.17574.pdf", "abstract_url": "https://arxiv.org/abs/2504.17574", "categories": ["Computation and Language (cs.CL)", "Computers and Society (cs.CY)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种基于MindSpore深度学习框架的多粒度建模方法RAGAT-Mind，用于中文谣言检测。该方法结合了TextCNN、双向GRU、多头自注意力和双向图卷积网络，有效整合了层次化语言特征和基于图的语义结构。在微博谣言数据集上的实验表明，RAGAT-Mind达到了99.2%的准确率和0.9919的宏F1分数，验证了其高效性和实用性。", "motivation": "随着虚假信息在社交媒体平台上的不断扩散，有效的谣言检测成为自然语言处理领域的一个紧迫挑战。", "method": "RAGAT-Mind模型整合了TextCNN用于局部语义提取，双向GRU用于序列上下文学习，多头自注意力用于全局依赖关注，以及双向图卷积网络(BiGCN)用于词共现图的结构表示。", "result": "在Weibo1-Rumor数据集上的实验显示，RAGAT-Mind实现了99.2%的准确率和0.9919的宏F1分数。", "conclusion": "结果验证了将层次化语言特征与基于图的语义结构结合的有效性。此外，该模型展现出强大的泛化能力和可解释性，突出了其在现实世界谣言检测应用中的实用价值。"}}
{"id": "2504.16946", "title": "MobileCity: An Efficient Framework for Large-Scale Urban Behavior Simulation", "authors": ["Xiaotong Ye", "Nicolas Bougie", "Toshihiko Yamasaki", "Narimasa Watanabe"], "abstract": "Generative agents offer promising capabilities for simulating realistic urban behaviors. However, existing methods oversimplify transportation choices in modern cities, and require prohibitive computational resources for large-scale population simulation. To address these limitations, we first present a virtual city that features multiple functional buildings and transportation modes. Then, we conduct extensive surveys to model behavioral choices and mobility preferences among population groups. Building on these insights, we introduce a simulation framework that captures the complexity of urban mobility while remaining scalable, enabling the simulation of over 4,000 agents. To assess the realism of the generated behaviors, we perform a series of micro and macro-level analyses. Beyond mere performance comparison, we explore insightful experiments, such as predicting crowd density from movement patterns and identifying trends in vehicle preferences across agent demographics.", "subjects": "Social and Information Networks (cs.SI); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.16946.pdf", "abstract_url": "https://arxiv.org/abs/2504.16946", "categories": ["Social and Information Networks (cs.SI)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为MobileCity的高效框架，用于大规模城市行为模拟，解决了现有方法在模拟现代城市交通选择时的过度简化问题，并实现了对超过4000个代理的模拟。", "motivation": "现有生成代理在模拟现实城市行为时，对现代城市交通选择过度简化，且在大规模人口模拟中需要过多的计算资源。", "method": "首先构建了一个具有多种功能建筑和交通模式的虚拟城市，然后通过广泛调查模拟人口群体的行为选择和移动偏好，并在此基础上引入了一个既捕捉城市移动复杂性又可扩展的模拟框架。", "result": "通过一系列微观和宏观层面的分析评估了生成行为的真实性，并进行了如从移动模式预测人群密度和识别不同代理人口统计中车辆偏好趋势等有洞察力的实验。", "conclusion": "MobileCity框架能够有效模拟大规模城市行为，同时捕捉城市移动的复杂性，为城市规划和行为研究提供了有价值的工具。"}}
{"id": "2504.16947", "title": "SCRAG: Social Computing-Based Retrieval Augmented Generation for Community Response Forecasting in Social Media Environments", "authors": ["Dachun Sun", "You Lyu", "Jinning Li", "Yizhuo Chen", "Tianshi Wang", "Tomoyoshi Kimura", "Tarek Abdelzaher"], "abstract": "This paper introduces SCRAG, a prediction framework inspired by social computing, designed to forecast community responses to real or hypothetical social media posts. SCRAG can be used by public relations specialists (e.g., to craft messaging in ways that avoid unintended misinterpretations) or public figures and influencers (e.g., to anticipate social responses), among other applications related to public sentiment prediction, crisis management, and social what-if analysis. While large language models (LLMs) have achieved remarkable success in generating coherent and contextually rich text, their reliance on static training data and susceptibility to hallucinations limit their effectiveness at response forecasting in dynamic social media environments. SCRAG overcomes these challenges by integrating LLMs with a Retrieval-Augmented Generation (RAG) technique rooted in social computing. Specifically, our framework retrieves (i) historical responses from the target community to capture their ideological, semantic, and emotional makeup, and (ii) external knowledge from sources such as news articles to inject time-sensitive context. This information is then jointly used to forecast the responses of the target community to new posts or narratives. Extensive experiments across six scenarios on the X platform (formerly Twitter), tested with various embedding models and LLMs, demonstrate over 10% improvements on average in key evaluation metrics. A concrete example further shows its effectiveness in capturing diverse ideologies and nuances. Our work provides a social computing tool for applications where accurate and concrete insights into community responses are crucial.", "subjects": "Social and Information Networks (cs.SI); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.16947.pdf", "abstract_url": "https://arxiv.org/abs/2504.16947", "categories": ["Social and Information Networks (cs.SI)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "SCRAG是一个基于社交计算的预测框架，旨在预测社交媒体环境中社区对真实或假设帖子的反应。它通过结合大型语言模型和检索增强生成技术，提高了预测的准确性和时效性。", "motivation": "解决大型语言模型在动态社交媒体环境中因依赖静态训练数据和易产生幻觉而限制其反应预测有效性的问题。", "method": "整合大型语言模型与基于社交计算的检索增强生成技术，检索目标社区的历史反应和外部知识，以预测社区对新帖子或叙述的反应。", "result": "在X平台（原Twitter）上的六种场景测试中，使用不同嵌入模型和大型语言模型，关键评估指标平均提高了10%以上。", "conclusion": "SCRAG为需要准确和具体洞察社区反应的应用提供了一个社交计算工具，尤其在公共情感预测、危机管理和社交假设分析等领域具有重要应用价值。"}}
{"id": "2504.17129", "title": "Peer-Aware Cost Estimation in Nonlinear General-Sum Dynamic Games for Mutual Learning and Intent Inference", "authors": ["Seyed Yousef Soltanian", "Wenlong Zhang"], "abstract": "Human-robot interactions can be modeled as incomplete-information general-sum dynamic games since the objective functions of both agents are not explicitly known to each other. However, solving for equilibrium policies for such games presents a major challenge, especially if the games involve nonlinear underlying dynamics. To simplify the problem, existing work often assumes that one agent is an expert with complete information about its peer, which can lead to biased estimates and failures in coordination. To address this challenge, we propose a nonlinear peer-aware cost estimation (N-PACE) algorithm for general-sum dynamic games. In N-PACE, using iterative linear quadratic (LQ) approximation of the nonlinear general-sum game, each agent explicitly models the learning dynamics of its peer agent while inferring their objective functions, leading to unbiased fast learning in inferring the unknown objective function of the peer agent, which is critical for task completion and safety assurance. Additionally, we demonstrate how N-PACE enables \\textbf{intent communication} in such multi-agent systems by explicitly modeling the peer's learning dynamics.", "subjects": "Systems and Control (eess.SY); Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.17129.pdf", "abstract_url": "https://arxiv.org/abs/2504.17129", "categories": ["Systems and Control (eess.SY)", "Artificial Intelligence (cs.AI)", "Computer Science and Game Theory (cs.GT)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种非线性同伴感知成本估计（N-PACE）算法，用于解决非线性一般和动态游戏中的人类-机器人交互问题，通过迭代线性二次近似和显式建模同伴的学习动态，实现了对同伴未知目标函数的无偏快速学习。", "motivation": "解决在非线性一般和动态游戏中，由于不完全信息导致的均衡策略求解难题，以及现有方法假设一个代理为专家可能导致的有偏估计和协调失败问题。", "method": "使用迭代线性二次（LQ）近似非线性一般和游戏，每个代理显式建模其同伴代理的学习动态，同时推断其目标函数。", "result": "N-PACE算法能够实现对同伴未知目标函数的无偏快速学习，这对于任务完成和安全保证至关重要，并且能够在多代理系统中实现意图通信。", "conclusion": "N-PACE算法通过显式建模同伴的学习动态，不仅解决了非线性一般和动态游戏中的学习与意图推断问题，还提高了多代理系统的协调效率和安全性。"}}
{"id": "2504.17355", "title": "Collaborative Multi-Agent Reinforcement Learning for Automated Feature Transformation with Graph-Driven Path Optimization", "authors": ["Xiaohan Huang", "Dongjie Wang", "Zhiyuan Ning", "Ziyue Qiao", "Qingqing Long", "Haowei Zhu", "Yi Du", "Min Wu", "Yuanchun Zhou", "Meng Xiao"], "abstract": "Feature transformation methods aim to find an optimal mathematical feature-feature crossing process that generates high-value features and improves the performance of downstream machine learning tasks. Existing frameworks, though designed to mitigate manual costs, often treat feature transformations as isolated operations, ignoring dynamic dependencies between transformation steps. To address the limitations, we propose TCTO, a collaborative multi-agent reinforcement learning framework that automates feature engineering through graph-driven path optimization. The framework's core innovation lies in an evolving interaction graph that models features as nodes and transformations as edges. Through graph pruning and backtracking, it dynamically eliminates low-impact edges, reduces redundant operations, and enhances exploration stability. This graph also provides full traceability to empower TCTO to reuse high-utility subgraphs from historical transformations. To demonstrate the efficacy and adaptability of our approach, we conduct comprehensive experiments and case studies, which show superior performance across a range of datasets.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "13 pages, Keywords: Automated Feature Transformation, Tabular Dataset, Reinforcement Learning", "pdf_url": "https://arxiv.org/pdf/2504.17355.pdf", "abstract_url": "https://arxiv.org/abs/2504.17355", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为TCTO的协作多智能体强化学习框架，通过图驱动的路径优化自动化特征工程，旨在解决现有特征转换方法忽略转换步骤间动态依赖关系的问题。", "motivation": "现有的特征转换框架虽然旨在减少人工成本，但往往将特征转换视为孤立操作，忽略了转换步骤之间的动态依赖关系。", "method": "提出TCTO框架，利用协作多智能体强化学习和图驱动的路径优化，通过演化交互图建模特征和转换，动态剪枝和回溯以减少冗余操作并增强探索稳定性。", "result": "通过全面的实验和案例研究，证明了TCTO框架在多种数据集上的优越性能和适应性。", "conclusion": "TCTO框架通过图驱动的路径优化和协作多智能体强化学习，有效地自动化了特征工程，提高了下游机器学习任务的性能，并提供了历史转换的高效用子图的可重用性。"}}
{"id": "2504.17490", "title": "Plasticine: Accelerating Research in Plasticity-Motivated Deep Reinforcement Learning", "authors": ["Mingqi Yuan", "Qi Wang", "Guozheng Ma", "Bo Li", "Xin Jin", "Yunbo Wang", "Xiaokang Yang", "Wenjun Zeng", "Dacheng Tao"], "abstract": "Developing lifelong learning agents is crucial for artificial general intelligence. However, deep reinforcement learning (RL) systems often suffer from plasticity loss, where neural networks gradually lose their ability to adapt during training. Despite its significance, this field lacks unified benchmarks and evaluation protocols. We introduce Plasticine, the first open-source framework for benchmarking plasticity optimization in deep RL. Plasticine provides single-file implementations of over 13 mitigation methods, 10 evaluation metrics, and learning scenarios with increasing non-stationarity levels from standard to open-ended environments. This framework enables researchers to systematically quantify plasticity loss, evaluate mitigation strategies, and analyze plasticity dynamics across different contexts. Our documentation, examples, and source code are available at", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "23 pages", "pdf_url": "https://arxiv.org/pdf/2504.17490.pdf", "abstract_url": "https://arxiv.org/abs/2504.17490", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "Plasticine是一个开源的深度学习强化学习框架，旨在解决神经网络在训练过程中逐渐失去适应能力（可塑性丧失）的问题，为研究者提供了统一的基准和评估协议。", "motivation": "开发终身学习代理对于人工智能的通用智能至关重要，但深度强化学习系统经常面临可塑性丧失的问题，即神经网络在训练过程中逐渐失去适应能力。这一领域缺乏统一的基准和评估协议。", "method": "引入了Plasticine，这是第一个用于深度强化学习中可塑性优化基准测试的开源框架。Plasticine提供了超过13种缓解方法的单文件实现、10种评估指标，以及从标准到开放式环境的不同非平稳性水平的学习场景。", "result": "Plasticine框架使研究者能够系统地量化可塑性丧失，评估缓解策略，并分析不同背景下的可塑性动态。", "conclusion": "Plasticine为深度强化学习中的可塑性研究提供了一个系统化的工具，有助于推动终身学习代理的发展，为人工通用智能的实现提供了支持。"}}
{"id": "2504.17669", "title": "Towards a HIPAA Compliant Agentic AI System in Healthcare", "authors": ["Subash Neupane", "Shaswata Mitra", "Sudip Mittal", "Shahram Rahimi"], "abstract": "Agentic AI systems powered by Large Language Models (LLMs) as their foundational reasoning engine, are transforming clinical workflows such as medical report generation and clinical summarization by autonomously analyzing sensitive healthcare data and executing decisions with minimal human oversight. However, their adoption demands strict compliance with regulatory frameworks such as Health Insurance Portability and Accountability Act (HIPAA), particularly when handling Protected Health Information (PHI). This work-in-progress paper introduces a HIPAA-compliant Agentic AI framework that enforces regulatory compliance through dynamic, context-aware policy enforcement. Our framework integrates three core mechanisms: (1) Attribute-Based Access Control (ABAC) for granular PHI governance, (2) a hybrid PHI sanitization pipeline combining regex patterns and BERT-based model to minimize leakage, and (3) immutable audit trails for compliance verification.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.17669.pdf", "abstract_url": "https://arxiv.org/abs/2504.17669", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Emerging Technologies (cs.ET)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了一个符合HIPAA标准的Agentic AI框架，旨在通过动态、上下文感知的策略执行来确保在处理敏感医疗信息时的合规性。", "motivation": "解决在医疗保健领域中使用基于大型语言模型（LLMs）的Agentic AI系统时，如何确保遵守健康保险可携性和责任法案（HIPAA）等监管框架的问题。", "method": "提出了一个框架，整合了三种核心机制：基于属性的访问控制（ABAC）用于细粒度的PHI治理，结合正则表达式模式和基于BERT模型的混合PHI清理管道以减少信息泄露，以及不可变的审计跟踪用于合规性验证。", "result": "开发了一个工作进展中的框架，旨在实现HIPAA合规性，同时支持Agentic AI系统在医疗保健领域的应用。", "conclusion": "该框架为在医疗保健领域安全、合规地部署Agentic AI系统提供了初步解决方案，但仍需进一步发展和完善。"}}
