{"id": "2508.02694", "title": "Efficient Agents: Building Effective Agents While Reducing Cost", "authors": ["Ningning Wang", "Xavier Hu", "Pai Liu", "He Zhu", "Yue Hou", "Heyuan Huang", "Shengyu Zhang", "Jian Yang", "Jiaheng Liu", "Ge Zhang", "Changwang Zhang", "Jun Wang", "Yuchen Eleanor Jiang", "Wangchunshu Zhou"], "abstract": "The remarkable capabilities of Large Language Model (LLM)-driven agents have enabled sophisticated systems to tackle complex, multi-step tasks, but their escalating costs threaten scalability and accessibility. This work presents the first systematic study of the efficiency-effectiveness trade-off in modern agent systems, addressing the critical need for cost-effective designs without sacrificing performance. We investigate three key questions: (1) How much complexity do agentic tasks inherently require? (2) When do additional modules yield diminishing returns? (3) How much efficiency can be gained through the design of efficient agent frameworks? Through an empirical analysis on the GAIA benchmark, we evaluate the impact of LLM backbone selection, agent framework designs, and test-time scaling strategies. Using the cost-of-pass metric, we quantify the efficiency-performance trade-off across these dimensions. Our findings inform the development of Efficient Agents , a novel agent framework that has an optimal complexity to task requirements. Efficient Agents retains 96.7% of the performance of OWL, one leading open-source agent framework, while reducing operational costs from $0.398 to $0.228, resulting in a 28.4% improvement in cost-of-pass. Our work provides actionable insights for designing efficient, high-performing agent systems, advancing the accessibility and sustainability of AI-driven solutions.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Multiagent Systems (cs.MA)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2508.02694.pdf", "abstract_url": "https://arxiv.org/abs/2508.02694", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文首次系统研究了现代代理系统中的效率-效果权衡，提出了Efficient Agents框架，在保持高性能的同时显著降低了成本。", "motivation": "解决大型语言模型(LLM)驱动代理系统成本上升威胁可扩展性和可访问性的问题。", "method": "通过GAIA基准上的实证分析，评估LLM骨干选择、代理框架设计和测试时扩展策略的影响，使用成本通过指标量化效率-性能权衡。", "result": "Efficient Agents框架保留了领先开源代理框架OWL 96.7%的性能，同时将运营成本从$0.398降低到$0.228，成本通过提高了28.4%。", "conclusion": "本研究为设计高效、高性能的代理系统提供了可行的见解，推动了AI驱动解决方案的可访问性和可持续性。"}}
{"id": "2508.03039", "title": "VideoForest: Person-Anchored Hierarchical Reasoning for Cross-Video Question Answering", "authors": ["Yiran Meng", "Junhong Ye", "Wei Zhou", "Guanghui Yue", "Xudong Mao", "Ruomei Wang", "Baoquan Zhao"], "abstract": "Cross-video question answering presents significant challenges beyond traditional single-video understanding, particularly in establishing meaningful connections across video streams and managing the complexity of multi-source information retrieval. We introduce VideoForest, a novel framework that addresses these challenges through person-anchored hierarchical reasoning. Our approach leverages person-level features as natural bridge points between videos, enabling effective cross-video understanding without requiring end-to-end training. VideoForest integrates three key innovations: 1) a human-anchored feature extraction mechanism that employs ReID and tracking algorithms to establish robust spatiotemporal relationships across multiple video sources; 2) a multi-granularity spanning tree structure that hierarchically organizes visual content around person-level trajectories; and 3) a multi-agent reasoning framework that efficiently traverses this hierarchical structure to answer complex cross-video queries. To evaluate our approach, we develop CrossVideoQA, a comprehensive benchmark dataset specifically designed for person-centric cross-video analysis. Experimental results demonstrate VideoForest's superior performance in cross-video reasoning tasks, achieving 71.93% accuracy in person recognition, 83.75% in behavior analysis, and 51.67% in summarization and reasoning, significantly outperforming existing methods. Our work establishes a new paradigm for cross-video understanding by unifying multiple video streams through person-level features, enabling sophisticated reasoning across distributed visual information while maintaining computational efficiency.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.03039.pdf", "abstract_url": "https://arxiv.org/abs/2508.03039", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Multimedia (cs.MM)"], "matching_keywords": ["agent"], "AI": {"tldr": "VideoForest是一个新颖的框架，通过人物锚定的层次推理解决跨视频问答的挑战，无需端到端训练即可实现有效的跨视频理解。", "motivation": "跨视频问答在传统单视频理解之外提出了显著挑战，特别是在建立视频流之间有意义的连接和管理多源信息检索的复杂性方面。", "method": "VideoForest采用人物级别的特征作为视频间的自然桥梁，集成了三个关键创新：1) 使用ReID和跟踪算法建立跨多视频源的强大时空关系的人物锚定特征提取机制；2) 围绕人物级别轨迹层次化组织视觉内容的多粒度生成树结构；3) 高效遍历这一层次结构以回答复杂跨视频查询的多代理推理框架。", "result": "实验结果显示，VideoForest在跨视频推理任务中表现优异，人物识别准确率达到71.93%，行为分析达到83.75%，总结和推理达到51.67%，显著优于现有方法。", "conclusion": "我们的工作通过人物级别特征统一多个视频流，为跨视频理解建立了新范式，能够在保持计算效率的同时实现跨分布式视觉信息的复杂推理。"}}
{"id": "2508.03100", "title": "AVATAR: Reinforcement Learning to See, Hear, and Reason Over Video", "authors": ["Yogesh Kulkarni", "Pooyan Fazli"], "abstract": "Multimodal reasoning over long-horizon video is challenging due to the need for precise spatiotemporal fusion and alignment across modalities. While recent methods such as Group Relative Policy Optimization (GRPO) have shown promise in this domain, they suffer from three key limitations: (1) data inefficiency from their on-policy design, (2) a vanishing advantage problem, where identical or near-identical rewards within a group eliminate the learning signal by producing zero-valued advantages, and (3) uniform credit assignment that fails to emphasize critical reasoning steps. We introduce AVATAR (Audio-Video Agent for Alignment and Reasoning), a framework that addresses these limitations through two core components: (1) an off-policy training architecture that improves sample efficiency and resolves vanishing advantages by reusing past experiences with greater reward diversity, and (2) Temporal Advantage Shaping (TAS), a novel credit assignment strategy that upweights key reasoning phases during learning. AVATAR achieves strong performance across various benchmarks, outperforming the Qwen2.5-Omni baseline by +5.4on MMVU, +4.9 on OmniBench, and +4.5 on Video-Holmes, while demonstrating over 35% higher sample efficiency.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.03100.pdf", "abstract_url": "https://arxiv.org/abs/2508.03100", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "AVATAR是一种通过强化学习在视频中进行多模态推理的框架，解决了现有方法在数据效率、优势消失问题和信用分配上的局限性。", "motivation": "解决长视频多模态推理中的时空融合和对齐问题，以及现有方法如GRPO在数据效率、优势消失和均匀信用分配上的不足。", "method": "AVATAR框架包含两个核心组件：1) 离策略训练架构，提高样本效率并通过重用过去经验解决优势消失问题；2) 时间优势塑造(TAS)，一种新的信用分配策略，强调学习过程中的关键推理阶段。", "result": "AVATAR在多个基准测试中表现优异，相比Qwen2.5-Omni基线，在MMVU上提高了+5.4，在OmniBench上提高了+4.9，在Video-Holmes上提高了+4.5，同时展示了超过35%的样本效率提升。", "conclusion": "AVATAR通过其创新的离策略训练和TAS策略，有效解决了多模态视频推理中的关键挑战，为未来的研究提供了新的方向。"}}
{"id": "2508.02808", "title": "Clinically Grounded Agent-based Report Evaluation: An Interpretable Metric for Radiology Report Generation", "authors": ["Radhika Dua", "Young Joon", "Kwon", "Siddhant Dogra", "Daniel Freedman", "Diana Ruan", "Motaz Nashawaty", "Danielle Rigau", "Daniel Alexander Alber", "Kang Zhang", "Kyunghyun Cho", "Eric Karl Oermann"], "abstract": "Radiological imaging is central to diagnosis, treatment planning, and clinical decision-making. Vision-language foundation models have spurred interest in automated radiology report generation (RRG), but safe deployment requires reliable clinical evaluation of generated reports. Existing metrics often rely on surface-level similarity or behave as black boxes, lacking interpretability. We introduce ICARE (Interpretable and Clinically-grounded Agent-based Report Evaluation), an interpretable evaluation framework leveraging large language model agents and dynamic multiple-choice question answering (MCQA). Two agents, each with either the ground-truth or generated report, generate clinically meaningful questions and quiz each other. Agreement on answers captures preservation and consistency of findings, serving as interpretable proxies for clinical precision and recall. By linking scores to question-answer pairs, ICARE enables transparent, and interpretable assessment. Clinician studies show ICARE aligns significantly more with expert judgment than prior metrics. Perturbation analyses confirm sensitivity to clinical content and reproducibility, while model comparisons reveal interpretable error patterns.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.02808.pdf", "abstract_url": "https://arxiv.org/abs/2508.02808", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了ICARE，一个基于大型语言模型代理和动态多项选择问答的放射学报告生成评估框架，旨在提供透明和可解释的临床评估。", "motivation": "放射学报告生成（RRG）的安全部署需要可靠的临床评估，现有指标往往依赖表面相似性或缺乏可解释性。", "method": "使用两个大型语言模型代理，分别基于真实报告和生成报告，生成有临床意义的问题并相互测试，通过答案一致性评估临床精确度和召回率。", "result": "临床研究表明，ICARE与专家判断的一致性显著高于现有指标，扰动分析证实了对临床内容的敏感性和可重复性。", "conclusion": "ICARE通过将评分与问答对联系起来，实现了透明和可解释的评估，为放射学报告生成提供了更可靠的临床评价工具。"}}
{"id": "2508.02744", "title": "Large Language Model-based Data Science Agent: A Survey", "authors": ["Peiran Wang", "Yaoning Yu", "Ke Chen", "Xianyang Zhan", "Haohan Wang"], "abstract": "The rapid advancement of Large Language Models (LLMs) has driven novel applications across diverse domains, with LLM-based agents emerging as a crucial area of exploration. This survey presents a comprehensive analysis of LLM-based agents designed for data science tasks, summarizing insights from recent studies. From the agent perspective, we discuss the key design principles, covering agent roles, execution, knowledge, and reflection methods. From the data science perspective, we identify key processes for LLM-based agents, including data preprocessing, model development, evaluation, visualization, etc. Our work offers two key contributions: (1) a comprehensive review of recent developments in applying LLMbased agents to data science tasks; (2) a dual-perspective framework that connects general agent design principles with the practical workflows in data science.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.02744.pdf", "abstract_url": "https://arxiv.org/abs/2508.02744", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文综述了基于大型语言模型（LLM）的数据科学代理的最新发展，从代理和数据科学两个视角分析了设计原则和关键流程。", "motivation": "随着大型语言模型（LLM）的快速发展，探索基于LLM的代理在数据科学任务中的应用成为一个重要研究方向。", "method": "从代理视角讨论了设计原则，包括代理角色、执行、知识和反思方法；从数据科学视角识别了关键流程，如数据预处理、模型开发、评估和可视化。", "result": "提出了一个双视角框架，将通用代理设计原则与数据科学实践工作流程联系起来。", "conclusion": "本文不仅全面回顾了LLM代理在数据科学中的应用，还提供了一个连接理论与实践的框架，为未来研究提供了方向。"}}
{"id": "2508.02841", "title": "A Multi-Agent System for Complex Reasoning in Radiology Visual Question Answering", "authors": ["Ziruo Yi", "Jinyu Liu", "Ting Xiao", "Mark V. Albert"], "abstract": "Radiology visual question answering (RVQA) provides precise answers to questions about chest X-ray images, alleviating radiologists' workload. While recent methods based on multimodal large language models (MLLMs) and retrieval-augmented generation (RAG) have shown promising progress in RVQA, they still face challenges in factual accuracy, hallucinations, and cross-modal misalignment. We introduce a multi-agent system (MAS) designed to support complex reasoning in RVQA, with specialized agents for context understanding, multimodal reasoning, and answer validation. We evaluate our system on a challenging RVQA set curated via model disagreement filtering, comprising consistently hard cases across multiple MLLMs. Extensive experiments demonstrate the superiority and effectiveness of our system over strong MLLM baselines, with a case study illustrating its reliability and interpretability. This work highlights the potential of multi-agent approaches to support explainable and trustworthy clinical AI applications that require complex reasoning.", "subjects": "Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.02841.pdf", "abstract_url": "https://arxiv.org/abs/2508.02841", "categories": ["Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文介绍了一种用于放射学视觉问答（RVQA）的多智能体系统（MAS），旨在通过专门设计的智能体提高答案的事实准确性、减少幻觉和跨模态错位问题，并在挑战性的RVQA数据集上展示了其优越性和有效性。", "motivation": "解决放射学视觉问答中基于多模态大语言模型（MLLMs）和检索增强生成（RAG）方法在事实准确性、幻觉和跨模态对齐方面的挑战。", "method": "引入一个多智能体系统（MAS），包括专门用于上下文理解、多模态推理和答案验证的智能体。", "result": "在通过模型分歧过滤筛选的挑战性RVQA数据集上，该系统表现出优于强MLLM基线的性能，并通过案例研究展示了其可靠性和可解释性。", "conclusion": "这项工作突出了多智能体方法在支持需要复杂推理的可解释和可信赖临床AI应用方面的潜力。"}}
{"id": "2508.02900", "title": "Seemingly Simple Planning Problems are Computationally Challenging: The Countdown Game", "authors": ["Michael Katz", "Harsha Kokel", "Sarath Sreedharan"], "abstract": "There is a broad consensus that the inability to form long-term plans is one of the key limitations of current foundational models and agents. However, the existing planning benchmarks remain woefully inadequate to truly measure their planning capabilities. Most existing benchmarks either focus on loosely defined tasks like travel planning or end up leveraging existing domains and problems from international planning competitions. While the former tasks are hard to formalize and verify, the latter were specifically designed to test and challenge the weaknesses of existing automated planners. To address these shortcomings, we propose a procedure for creating a planning benchmark centered around the game called Countdown, where a player is expected to form a target number from a list of input numbers through arithmetic operations. We discuss how this problem meets many of the desiderata associated with an ideal benchmark for planning capabilities evaluation. Specifically, the domain allows for an intuitive, natural language description for each problem instance, it is computationally challenging (NP-complete), and the instance space is rich enough that we do not have to worry about memorization. We perform an extensive theoretical analysis, establishing the computational complexity result and demonstrate the advantage of our instance generation procedure over public benchmarks. We evaluate a variety of existing LLM-assisted planning methods on instances generated using our procedure. Our results show that, unlike other domains like 24 Game (a special case of Countdown), our proposed dynamic benchmark remains extremely challenging for existing LLM-based approaches.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.02900.pdf", "abstract_url": "https://arxiv.org/abs/2508.02900", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于倒计时游戏的规划基准测试方法，旨在更准确地评估基础模型和智能体的长期规划能力。通过理论分析和实验验证，证明了该方法在评估现有LLM辅助规划方法时的有效性和挑战性。", "motivation": "当前规划基准测试在评估基础模型和智能体的长期规划能力方面存在不足，无法准确反映其规划能力的真实水平。", "method": "提出了一种围绕倒计时游戏创建规划基准测试的程序，该游戏要求玩家通过算术运算从一组输入数字中形成目标数字。", "result": "理论分析证实了该问题的计算复杂性（NP完全），实验结果表明，与24 Game等其他领域相比，动态生成的基准测试对现有基于LLM的方法极具挑战性。", "conclusion": "倒计时游戏作为一种规划基准测试，能够有效评估和挑战现有LLM辅助规划方法的规划能力，为未来研究提供了新的方向。"}}
{"id": "2508.02921", "title": "PentestJudge: Judging Agent Behavior Against Operational Requirements", "authors": ["Shane Caldwell", "Max Harley", "Michael Kouremetis", "Vincent Abruzzo", "Will Pearce"], "abstract": "We introduce PentestJudge, a system for evaluating the operations of penetration testing agents. PentestJudge is a large language model (LLM)-as-judge with access to tools that allow it to consume arbitrary trajectories of agent states and tool call history to determine whether a security agent's actions meet certain operating criteria that would be impractical to evaluate programmatically. We develop rubrics that use a tree structure to hierarchically collapse the penetration testing task for a particular environment into smaller, simpler, and more manageable sub-tasks and criteria until each leaf node represents simple yes-or-no criteria for PentestJudge to evaluate. Task nodes are broken down into different categories related to operational objectives, operational security, and tradecraft. LLM-as-judge scores are compared to human domain experts as a ground-truth reference, allowing us to compare their relative performance with standard binary classification metrics, such as F1 scores. We evaluate several frontier and open-source models acting as judge agents, with the best model reaching an F1 score of 0.83. We find models that are better at tool-use perform more closely to human experts. By stratifying the F1 scores by requirement type, we find even models with similar overall scores struggle with different types of questions, suggesting certain models may be better judges of particular operating criteria. We find that weaker and cheaper models can judge the trajectories of pentests performed by stronger and more expensive models, suggesting verification may be easier than generation for the penetration testing task. We share this methodology to facilitate future research in understanding the ability of judges to holistically and scalably evaluate the process quality of AI-based information security agents so that they may be confidently used in sensitive production environments.", "subjects": "Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)", "comments": "18 pages, 5 figures, 3 tables", "pdf_url": "https://arxiv.org/pdf/2508.02921.pdf", "abstract_url": "https://arxiv.org/abs/2508.02921", "categories": ["Artificial Intelligence (cs.AI)", "Cryptography and Security (cs.CR)"], "matching_keywords": ["agent"], "AI": {"tldr": "介绍了PentestJudge系统，这是一个利用大型语言模型（LLM）作为评判者来评估渗透测试代理操作的系统，通过分层结构将复杂任务分解为简单子任务，并与人类专家评分比较，展示了模型在特定操作标准上的评判能力。", "motivation": "解决在敏感生产环境中自信使用基于AI的信息安全代理时，如何全面且可扩展地评估其过程质量的问题。", "method": "开发了一个使用树状结构分层分解渗透测试任务的评分标准，利用LLM作为评判者来评估代理行为是否符合操作标准，并与人类专家的评分进行比较。", "result": "最佳模型的F1分数达到0.83，发现擅长工具使用的模型更接近人类专家的表现，且不同模型在不同类型的问题上表现各异。", "conclusion": "研究表明，较弱且成本较低的模型可以评判由较强且成本较高的模型执行的渗透测试轨迹，表明验证可能比生成渗透测试任务更容易。"}}
{"id": "2508.02936", "title": "AQUAH: Automatic Quantification and Unified Agent in Hydrology", "authors": ["Songkun Yan", "Zhi Li", "Siyu Zhu", "Yixin Wen", "Mofan Zhang", "Mengye Chen", "Jie Cao", "Yang Hong"], "abstract": "We introduce AQUAH, the first end-to-end language-based agent designed specifically for hydrologic modeling. Starting from a simple natural-language prompt (e.g., 'simulate floods for the Little Bighorn basin from 2020 to 2022'), AQUAH autonomously retrieves the required terrain, forcing, and gauge data; configures a hydrologic model; runs the simulation; and generates a self-contained PDF report. The workflow is driven by vision-enabled large language models, which interpret maps and rasters on the fly and steer key decisions such as outlet selection, parameter initialization, and uncertainty commentary. Initial experiments across a range of U.S. basins show that AQUAH can complete cold-start simulations and produce analyst-ready documentation without manual intervention. The results are judged by hydrologists as clear, transparent, and physically plausible. While further calibration and validation are still needed for operational deployment, these early outcomes highlight the promise of LLM-centered, vision-grounded agents to streamline complex environmental modeling and lower the barrier between Earth observation data, physics-based tools, and decision makers.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "8 pages, 5 figures, 2025 ICCV SEA workshop paper", "pdf_url": "https://arxiv.org/pdf/2508.02936.pdf", "abstract_url": "https://arxiv.org/abs/2508.02936", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "AQUAH是首个专为水文建模设计的端到端基于语言的代理，能够从自然语言提示自主完成水文模拟并生成报告。", "motivation": "解决水文建模中数据检索、模型配置、模拟运行和报告生成等复杂流程的自动化问题，降低地球观测数据、物理基础工具与决策者之间的门槛。", "method": "利用视觉支持的大型语言模型驱动工作流，自动解释地图和栅格数据，指导关键决策如出口选择、参数初始化和不确定性评论。", "result": "初步实验表明，AQUAH能在无需人工干预的情况下完成冷启动模拟并生成分析师就绪的文档，结果被水文专家评为清晰、透明且物理上合理。", "conclusion": "尽管还需要进一步的校准和验证以用于操作部署，这些早期成果突出了以LLM为中心、视觉为基础的代理在简化复杂环境建模和降低技术门槛方面的潜力。"}}
{"id": "2508.02959", "title": "Polymath: A Self-Optimizing Agent with Dynamic Hierarchical Workflow", "authors": ["Chia-Tung Ho", "Jing Gong", "Xufeng Yao", "Yunsheng Bai", "Abhishek B Akkur", "Haoxing Ren"], "abstract": "Large language models (LLMs) excel at solving complex tasks by executing agentic workflows composed of detailed instructions and structured operations. Yet, building general-purpose agents by manually embedding foundation models into agentic systems such as Chain-of-Thought, Self-Reflection, and ReACT through text interfaces limits scalability and efficiency. Recently, many researchers have sought to automate the generation and optimization of these workflows through code-based representations. However, existing methods often rely on labeled datasets to train and optimize workflows, making them ineffective and inflexible for solving real-world, dynamic problems where labeled data is unavailable. To address this challenge, we introduce Polymath, a self-optimizing agent with dynamic hierarchical workflow that leverages the flexibility of task flow graphs and the expressiveness of code-represented workflows to solve a wide range of real-world, dynamic problems. The proposed optimization methodology integrates multi-grid-inspired graph optimization with a self-reflection-guided evolutionary algorithm to refine workflows without labeled data. Experimental results on six benchmark datasets across coding, math, and multi-turn QA tasks show that Polymath achieves 8.1% average improvement over state-of-the-art baselines.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "18 pages, 12 figures, under review for AAAI2026", "pdf_url": "https://arxiv.org/pdf/2508.02959.pdf", "abstract_url": "https://arxiv.org/abs/2508.02959", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "Polymath是一种自优化代理，通过动态分层工作流解决现实世界中的动态问题，无需标记数据，平均性能提升8.1%。", "motivation": "解决现有基于标记数据训练的工作流生成方法在现实动态问题中的无效性和不灵活性问题。", "method": "结合任务流图的灵活性和代码表示工作流的表达力，采用多网格启发图优化和自反射引导的进化算法优化工作流。", "result": "在六个基准数据集上的实验显示，Polymath平均性能比最先进基线提高8.1%。", "conclusion": "Polymath通过自优化和动态分层工作流，有效解决了无标记数据情况下的现实动态问题，性能显著提升。"}}
{"id": "2508.02872", "title": "Highlight & Summarize: RAG without the jailbreaks", "authors": ["Giovanni Cherubin", "Andrew Paverd"], "abstract": "Preventing jailbreaking and model hijacking of Large Language Models (LLMs) is an important yet challenging task. For example, when interacting with a chatbot, malicious users can input specially crafted prompts to cause the LLM to generate undesirable content or perform a completely different task from its intended purpose. Existing mitigations for such attacks typically rely on hardening the LLM's system prompt or using a content classifier trained to detect undesirable content or off-topic conversations. However, these probabilistic approaches are relatively easy to bypass due to the very large space of possible inputs and undesirable outputs. In this paper, we present and evaluate Highlight & Summarize (H&S), a new design pattern for retrieval-augmented generation (RAG) systems that prevents these attacks by design. The core idea is to perform the same task as a standard RAG pipeline (i.e., to provide natural language answers to questions, based on relevant sources) without ever revealing the user's question to the generative LLM. This is achieved by splitting the pipeline into two components: a highlighter, which takes the user's question and extracts relevant passages (\"highlights\") from the retrieved documents, and a summarizer, which takes the highlighted passages and summarizes them into a cohesive answer. We describe several possible instantiations of H&S and evaluate their generated responses in terms of correctness, relevance, and response quality. Surprisingly, when using an LLM-based highlighter, the majority of H&S responses are judged to be better than those of a standard RAG pipeline.", "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.02872.pdf", "abstract_url": "https://arxiv.org/abs/2508.02872", "categories": ["Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种名为Highlight & Summarize（H&S）的新设计模式，用于防止大型语言模型（LLMs）的越狱和模型劫持，通过将检索增强生成（RAG）系统分为高亮器和总结器两部分，避免直接向生成LLM暴露用户问题，从而设计上防止攻击。", "motivation": "解决大型语言模型（LLMs）在交互过程中可能被恶意用户通过特别设计的提示诱导生成不良内容或偏离其预期任务的问题。", "method": "提出Highlight & Summarize（H&S）设计模式，将RAG流程分为高亮器（提取相关文档段落）和总结器（将高亮段落总结为连贯答案）两部分，避免直接暴露用户问题给生成LLM。", "result": "使用基于LLM的高亮器时，大多数H&S生成的回答在正确性、相关性和回答质量上优于标准RAG流程。", "conclusion": "H&S设计模式通过架构上的改变有效防止了LLMs的越狱和模型劫持，同时提高了回答的质量，为RAG系统的安全性和效率提供了新的解决方案。"}}
{"id": "2508.03098", "title": "Privacy-Aware Decoding: Mitigating Privacy Leakage of Large Language Models in Retrieval-Augmented Generation", "authors": ["Haoran Wang", "Xiongxiao Xu", "Baixiang Huang", "Kai Shu"], "abstract": "Retrieval-Augmented Generation (RAG) enhances the factual accuracy of large language models (LLMs) by conditioning outputs on external knowledge sources. However, when retrieval involves private or sensitive data, RAG systems are susceptible to extraction attacks that can leak confidential information through generated responses. We propose Privacy-Aware Decoding (PAD), a lightweight, inference-time defense that adaptively injects calibrated Gaussian noise into token logits during generation. PAD integrates confidence-based screening to selectively protect high-risk tokens, efficient sensitivity estimation to minimize unnecessary noise, and context-aware noise calibration to balance privacy with generation quality. A \\renyi Differential Privacy (RDP) accountant rigorously tracks cumulative privacy loss, enabling explicit per-response $(\\varepsilon, \\delta)$-DP guarantees for sensitive outputs. Unlike prior approaches requiring retraining or corpus-level filtering, PAD is model-agnostic and operates entirely at decoding time with minimal computational overhead. Experiments on three real-world datasets demonstrate that PAD substantially reduces private information leakage while preserving response utility, outperforming existing retrieval- and post-processing-based defenses. Our work takes an important step toward mitigating privacy risks in RAG via decoding strategies, paving the way for universal and scalable privacy solutions in sensitive domains. Our code is available:", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.03098.pdf", "abstract_url": "https://arxiv.org/abs/2508.03098", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种名为隐私感知解码（PAD）的轻量级防御机制，旨在减少大型语言模型在检索增强生成（RAG）过程中的隐私泄露风险。PAD通过在生成过程中自适应地注入校准的高斯噪声，并结合基于置信度的筛选、高效敏感性估计和上下文感知噪声校准，有效平衡了隐私保护与生成质量。实验证明，PAD在减少隐私信息泄露的同时，保持了回答的实用性，优于现有的防御方法。", "motivation": "检索增强生成（RAG）虽然提高了大型语言模型的事实准确性，但在处理敏感或私有数据时，容易受到提取攻击，导致机密信息通过生成的响应泄露。本文旨在解决这一问题。", "method": "提出了隐私感知解码（PAD），一种在生成过程中自适应地注入校准高斯噪声到令牌逻辑的轻量级防御机制。PAD包括基于置信度的筛选、高效敏感性估计和上下文感知噪声校准，以及使用Renyi差分隐私（RDP）会计来跟踪累积隐私损失。", "result": "在三个真实世界数据集上的实验表明，PAD显著减少了私有信息泄露，同时保持了回答的实用性，性能优于现有的检索和后处理防御方法。", "conclusion": "PAD为通过解码策略减轻RAG中的隐私风险迈出了重要一步，为敏感领域的通用和可扩展隐私解决方案铺平了道路。"}}
{"id": "2508.03110", "title": "Token-Level Precise Attack on RAG: Searching for the Best Alternatives to Mislead Generation", "authors": ["Zizhong Li", "Haopeng Zhang", "Jiawei Zhang"], "abstract": "While large language models (LLMs) have achieved remarkable success in providing trustworthy responses for knowledge-intensive tasks, they still face critical limitations such as hallucinations and outdated knowledge. To address these issues, the retrieval-augmented generation (RAG) framework enhances LLMs with access to external knowledge via a retriever, enabling more accurate and real-time outputs about the latest events. However, this integration brings new security vulnerabilities: the risk that malicious content in the external database can be retrieved and used to manipulate model outputs. Although prior work has explored attacks on RAG systems, existing approaches either rely heavily on access to the retriever or fail to jointly consider both retrieval and generation stages, limiting their effectiveness, particularly in black-box scenarios. To overcome these limitations, we propose Token-level Precise Attack on the RAG (TPARAG), a novel framework that targets both white-box and black-box RAG systems. TPARAG leverages a lightweight white-box LLM as an attacker to generate and iteratively optimize malicious passages at the token level, ensuring both retrievability and high attack success in generation. Extensive experiments on open-domain QA datasets demonstrate that TPARAG consistently outperforms previous approaches in retrieval-stage and end-to-end attack effectiveness. These results further reveal critical vulnerabilities in RAG pipelines and offer new insights into improving their robustness.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.03110.pdf", "abstract_url": "https://arxiv.org/abs/2508.03110", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种针对检索增强生成（RAG）系统的令牌级精确攻击（TPARAG），旨在通过优化恶意段落来提高检索和生成阶段的攻击成功率，揭示了RAG管道的关键漏洞。", "motivation": "大型语言模型（LLMs）在知识密集型任务中表现出色，但仍存在幻觉和知识过时等问题。RAG框架通过检索外部知识来增强LLMs，但这也引入了新的安全漏洞，即恶意内容可能被检索并用于操纵模型输出。现有攻击方法要么过于依赖检索器的访问权限，要么未能同时考虑检索和生成阶段，限制了其在黑盒场景中的有效性。", "method": "提出TPARAG框架，利用轻量级白盒LLM作为攻击者，在令牌级别生成并迭代优化恶意段落，确保其在检索阶段的可检索性和在生成阶段的高攻击成功率。", "result": "在开放域QA数据集上的大量实验表明，TPARAG在检索阶段和端到端攻击效果上 consistently outperforms previous approaches。", "conclusion": "TPARAG揭示了RAG管道的关键漏洞，为提升其鲁棒性提供了新的见解。"}}
{"id": "2508.02994", "title": "When AIs Judge AIs: The Rise of Agent-as-a-Judge Evaluation for LLMs", "authors": ["Fangyi Yu"], "abstract": "As large language models (LLMs) grow in capability and autonomy, evaluating their outputs-especially in open-ended and complex tasks-has become a critical bottleneck. A new paradigm is emerging: using AI agents as the evaluators themselves. This \"agent-as-a-judge\" approach leverages the reasoning and perspective-taking abilities of LLMs to assess the quality and safety of other models, promising calable and nuanced alternatives to human evaluation. In this review, we define the agent-as-a-judge concept, trace its evolution from single-model judges to dynamic multi-agent debate frameworks, and critically examine their strengths and shortcomings. We compare these approaches across reliability, cost, and human alignment, and survey real-world deployments in domains such as medicine, law, finance, and education. Finally, we highlight pressing challenges-including bias, robustness, and meta evaluation-and outline future research directions. By bringing together these strands, our review demonstrates how agent-based judging can complement (but not replace) human oversight, marking a step toward trustworthy, scalable evaluation for next-generation LLMs.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.02994.pdf", "abstract_url": "https://arxiv.org/abs/2508.02994", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "随着大型语言模型（LLMs）能力和自主性的增长，评估其输出，特别是在开放性和复杂任务中的输出，已成为一个关键瓶颈。一种新范式正在兴起：使用AI代理作为评估者本身。这种“代理即法官”的方法利用LLMs的推理和视角采取能力来评估其他模型的质量和安全性，为人类评估提供了可扩展和细致的替代方案。本文回顾了代理即法官的概念，追溯了其从单一模型法官到动态多代理辩论框架的演变，并批判性地考察了它们的优势和不足。我们比较了这些方法在可靠性、成本和人类对齐方面的表现，并调查了在医学、法律、金融和教育等领域的实际部署。最后，我们强调了包括偏见、鲁棒性和元评估在内的紧迫挑战，并概述了未来的研究方向。通过汇集这些线索，我们的回顾展示了基于代理的评判如何补充（但不能替代）人类监督，标志着朝着可信赖、可扩展的下一代LLMs评估迈出了一步。", "motivation": "解决大型语言模型（LLMs）在开放性和复杂任务中输出评估的瓶颈问题。", "method": "采用“代理即法官”的方法，利用LLMs的推理和视角采取能力来评估其他模型的质量和安全性。", "result": "展示了基于代理的评判在可靠性、成本和人类对齐方面的表现，并调查了其在多个领域的实际部署。", "conclusion": "基于代理的评判可以补充人类监督，但不能替代，标志着朝着可信赖、可扩展的下一代LLMs评估迈出了一步。"}}
{"id": "2508.02999", "title": "AGENTiGraph: A Multi-Agent Knowledge Graph Framework for Interactive, Domain-Specific LLM Chatbots", "authors": ["Xinjie Zhao", "Moritz Blum", "Fan Gao", "Yingjian Chen", "Boming Yang", "Luis Marquez-Carpintero", "Mónica Pina-Navarro", "Yanran Fu", "So Morikawa", "Yusuke Iwasawa", "Yutaka Matsuo", "Chanjun Park", "Irene Li"], "abstract": "AGENTiGraph is a user-friendly, agent-driven system that enables intuitive interaction and management of domain-specific data through the manipulation of knowledge graphs in natural language. It gives non-technical users a complete, visual solution to incrementally build and refine their knowledge bases, allowing multi-round dialogues and dynamic updates without specialized query languages. The flexible design of AGENTiGraph, including intent classification, task planning, and automatic knowledge integration, ensures seamless reasoning between diverse tasks. Evaluated on a 3,500-query benchmark within an educational scenario, the system outperforms strong zero-shot baselines (achieving 95.12% classification accuracy, 90.45% execution success), indicating potential scalability to compliance-critical or multi-step queries in legal and medical domains, e.g., incorporating new statutes or research on the fly. Our open-source demo offers a powerful new paradigm for multi-turn enterprise knowledge management that bridges LLMs and structured graphs.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "CIKM 2025, Demo Track", "pdf_url": "https://arxiv.org/pdf/2508.02999.pdf", "abstract_url": "https://arxiv.org/abs/2508.02999", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "AGENTiGraph是一个多代理知识图谱框架，旨在通过自然语言操作知识图谱，为非技术用户提供直观的交互和领域特定数据管理。该系统在教育和法律等领域展现出高效能和可扩展性。", "motivation": "解决非技术用户在管理和交互领域特定数据时面临的挑战，特别是在需要多轮对话和动态更新的场景中，避免使用专门的查询语言。", "method": "采用意图分类、任务规划和自动知识集成等灵活设计，支持知识图谱的自然语言操作和多代理协作。", "result": "在教育场景的3,500查询基准测试中，系统分类准确率达到95.12%，执行成功率达到90.45%，显示出在法律和医疗等领域的潜在应用价值。", "conclusion": "AGENTiGraph为多轮企业知识管理提供了一个强大的新范式，有效地将大型语言模型与结构化知识图谱结合起来，具有广泛的应用前景。"}}
{"id": "2508.03018", "title": "Beyond Policy Optimization: A Data Curation Flywheel for Sparse-Reward Long-Horizon Planning", "authors": ["Yutong Wang", "Pengliang Ji", "Kaixin Li", "Baolong Bi", "Tao Feng", "Guillaume Sartoretti"], "abstract": "Large Language Reasoning Models have demonstrated remarkable success on static tasks, yet their application to multi-round agentic planning in interactive environments faces two fundamental challenges. First, the intractable credit assignment problem renders conventional reinforcement learning ineffective in sparse-reward settings. Second, the computational overhead of verbose, step-by-step reasoning histories is prohibitive. To address these challenges, we propose BPO, a three-stage framework (bootstrapping, extrapolation, and refinement) that establishes a self-improving data flywheel to develop robust reasoning models for long-horizon, sparse-reward environments. Our framework first bootstraps efficient reasoning using the proposed planning quaternions with long-short chain-of-thought fusion. It then extrapolates to out-of-distribution tasks through complexity-stratified curriculum learning. Finally, the model iteratively refines itself by learning exclusively on experiences selected via reward-gated rejection sampling. Experiments on ALFWorld, ScienceWorld, and WebShop demonstrate that our approach achieves state-of-the-art with significant token efficiency, providing a new recipe for reasoning models in agentic planning.", "subjects": "Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.03018.pdf", "abstract_url": "https://arxiv.org/abs/2508.03018", "categories": ["Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了BPO框架，通过三个阶段（引导、外推和细化）建立自我改进的数据飞轮，以开发适用于稀疏奖励长视野环境的鲁棒推理模型。", "motivation": "解决大型语言推理模型在多轮代理规划中的两个基本挑战：稀疏奖励设置下的信用分配问题和计算开销大的问题。", "method": "采用三阶段框架：引导阶段使用规划四元组和长短链思维融合；外推阶段通过复杂度分层的课程学习；细化阶段通过奖励门控拒绝采样选择经验进行学习。", "result": "在ALFWorld、ScienceWorld和WebShop上的实验表明，该方法在令牌效率上达到了最先进的水平。", "conclusion": "BPO框架为代理规划中的推理模型提供了新的方法，显著提高了在稀疏奖励长视野环境中的性能。"}}
{"id": "2508.03030", "title": "Collab-Solver: Collaborative Solving Policy Learning for Mixed-Integer Linear Programming", "authors": ["Siyuan Li", "Yifan Yu", "Yanchen Deng", "Zhihao Zhang", "Mengjing Chen", "Fangzhou Zhu", "Tao Zhong", "Jianye Hao", "Peng Liu", "Bo An"], "abstract": "Mixed-integer linear programming (MILP) has been a fundamental problem in combinatorial optimization. Previous works have designed a plethora of hard-coded heuristics to accomplish challenging MILP solving with domain knowledge. Driven by the high capability of neural networks, recent research is devoted to replacing manually designed heuristics with learned policies. Although learning-based MILP methods have shown great promise, existing worksindependentlytreatthepolicylearningineachmoduleofMILPsolvers without considering their interdependence, severely hurting the solving speed and quality. To address this issue, we propose a novel multi-agent-based policy learning framework for MILP (Collab-Solver), which can collaboratively optimize the policies for multiple modules. Specifically, we formulate the collaboration of cut selection and branching in MILP solving as a Stackelberg game. Under this formulation, we develop a two-phase learning paradigm to stabilize the collaborative policy learning, where the first phase achieves the data-communicated policy pretraining and the second phase further orchestrates the policy learning for various modules. The jointly learned policy significantly improves the solving performance on both synthetic and large-scale real-world MILP datasets. Moreover, the policies learned by Collab-Solver have also demonstrated excellent generalization abilities across different instance sets.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.03030.pdf", "abstract_url": "https://arxiv.org/abs/2508.03030", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为Collab-Solver的新型多智能体策略学习框架，用于混合整数线性规划（MILP），通过将割选择和分支的协作建模为Stackelberg游戏，采用两阶段学习范式稳定协作策略学习，显著提高了求解性能。", "motivation": "解决现有基于学习的MILP方法在独立处理求解器中各模块策略学习时，忽视它们之间相互依赖关系，严重影响求解速度和质量的问题。", "method": "提出一个多智能体策略学习框架（Collab-Solver），将割选择和分支的协作建模为Stackelberg游戏，并开发了一个两阶段学习范式来稳定协作策略学习。", "result": "在合成和大规模真实世界MILP数据集上，联合学习的策略显著提高了求解性能，并且学习到的策略在不同实例集上展示了优秀的泛化能力。", "conclusion": "Collab-Solver通过协作优化多个模块的策略，不仅提高了MILP的求解效率和质量，还展示了策略学习的泛化能力，为组合优化领域提供了新的研究方向。"}}
{"id": "2508.03038", "title": "Tree-of-Reasoning: Towards Complex Medical Diagnosis via Multi-Agent Reasoning with Evidence Tree", "authors": ["Qi Peng", "Jialin Cui", "Jiayuan Xie", "Yi Cai", "Qing Li"], "abstract": "Large language models (LLMs) have shown great potential in the medical domain. However, existing models still fall short when faced with complex medical diagnosis task in the real world. This is mainly because they lack sufficient reasoning depth, which leads to information loss or logical jumps when processing a large amount of specialized medical data, leading to diagnostic errors. To address these challenges, we propose Tree-of-Reasoning (ToR), a novel multi-agent framework designed to handle complex scenarios. Specifically, ToR introduces a tree structure that can clearly record the reasoning path of LLMs and the corresponding clinical evidence. At the same time, we propose a cross-validation mechanism to ensure the consistency of multi-agent decision-making, thereby improving the clinical reasoning ability of multi-agents in complex medical scenarios. Experimental results on real-world medical data show that our framework can achieve better performance than existing baseline methods.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "Accepted by ACM MM 2025", "pdf_url": "https://arxiv.org/pdf/2508.03038.pdf", "abstract_url": "https://arxiv.org/abs/2508.03038", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了Tree-of-Reasoning (ToR)，一种新颖的多智能体框架，旨在通过证据树进行复杂医疗诊断，解决了大型语言模型(LLMs)在复杂医疗诊断任务中因推理深度不足而导致的信息丢失或逻辑跳跃问题。", "motivation": "现有的LLMs在处理大量专业医疗数据时，由于缺乏足够的推理深度，导致信息丢失或逻辑跳跃，从而产生诊断错误。本文旨在解决这一问题。", "method": "提出了Tree-of-Reasoning (ToR)框架，引入树结构清晰记录LLMs的推理路径和相应的临床证据，并提出交叉验证机制确保多智能体决策的一致性。", "result": "在真实世界的医疗数据上的实验结果表明，该框架能够比现有的基线方法取得更好的性能。", "conclusion": "ToR框架通过多智能体推理和证据树结构，显著提高了在复杂医疗场景下的临床推理能力，为复杂医疗诊断提供了新的解决方案。"}}
{"id": "2508.03092", "title": "Toward Verifiable Misinformation Detection: A Multi-Tool LLM Agent Framework", "authors": ["Zikun Cui", "Tianyi Huang", "Chia-En Chiang", "Cuiqianhe Du"], "abstract": "With the proliferation of Large Language Models (LLMs), the detection of misinformation has become increasingly important and complex. This research proposes an innovative verifiable misinformation detection LLM agent that goes beyond traditional true/false binary judgments. The agent actively verifies claims through dynamic interaction with diverse web sources, assesses information source credibility, synthesizes evidence, and provides a complete verifiable reasoning process. Our designed agent architecture includes three core tools: precise web search tool, source credibility assessment tool and numerical claim verification tool. These tools enable the agent to execute multi-step verification strategies, maintain evidence logs, and form comprehensive assessment conclusions. We evaluate using standard misinformation datasets such as FakeNewsNet, comparing with traditional machine learning models and LLMs. Evaluation metrics include standard classification metrics, quality assessment of reasoning processes, and robustness testing against rewritten content. Experimental results show that our agent outperforms baseline methods in misinformation detection accuracy, reasoning transparency, and resistance to information rewriting, providing a new paradigm for trustworthy AI-assisted fact-checking.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.03092.pdf", "abstract_url": "https://arxiv.org/abs/2508.03092", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种创新的可验证错误信息检测LLM代理框架，通过动态交互、评估信息来源可信度、综合证据并提供完整的可验证推理过程，超越了传统的真/假二元判断。", "motivation": "随着大型语言模型（LLMs）的普及，错误信息的检测变得日益重要且复杂。本研究旨在解决传统方法在错误信息检测中的局限性，提供更透明、更可靠的AI辅助事实核查新范式。", "method": "研究设计了一个LLM代理架构，包括三个核心工具：精确网络搜索工具、来源可信度评估工具和数值声明验证工具。这些工具支持多步骤验证策略、维护证据日志并形成全面评估结论。", "result": "实验结果表明，该代理在错误信息检测准确性、推理透明度和对信息重写的抵抗力方面优于基线方法。", "conclusion": "本研究为可信赖的AI辅助事实核查提供了新的框架，展示了在错误信息检测领域的潜在应用价值和优势。"}}
{"id": "2508.03109", "title": "AgentSME for Simulating Diverse Communication Modes in Smart Education", "authors": ["Wen-Xi Yang", "Tian-Fang Zhao"], "abstract": "Generative agent models specifically tailored for smart education are critical, yet remain relatively underdeveloped. A key challenge stems from the inherent complexity of educational contexts: learners are human beings with various cognitive behaviors, and pedagogy is fundamentally centered on personalized human-to-human communication. To address this issue, this paper proposes AgentSME, a unified generative agent framework powered by LLM. Three directional communication modes are considered in the models, namely Solo, Mono, and Echo, reflecting different types of agency autonomy and communicative reciprocity. Accuracy is adopted as the primary evaluation metric, complemented by three diversity indices designed to assess the diversity of reasoning contents. Six widely used LLMs are tested to validate the robustness of communication modes across different model tiers, which are equally divided into base-capacity and high-capacity configurations. The results show that generative agents that employ the Echo communication mode achieve the highest accuracy scores, while DeepSeek exhibits the greatest diversity. This study provides valuable information to improve agent learning capabilities and inspire smart education models.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.03109.pdf", "abstract_url": "https://arxiv.org/abs/2508.03109", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了AgentSME，一个基于LLM的统一生成代理框架，旨在解决智能教育中生成代理模型发展不足的问题。通过考虑三种定向通信模式（Solo、Mono、Echo），研究评估了不同模型层级的通信模式鲁棒性，发现Echo模式在准确性上表现最佳，而DeepSeek在多样性上表现最好。", "motivation": "智能教育中生成代理模型的发展相对不足，主要挑战在于教育环境的复杂性，包括学习者的多样化认知行为和以个性化人际沟通为核心的教学法。", "method": "提出了AgentSME框架，考虑了三种定向通信模式（Solo、Mono、Echo），并使用准确性作为主要评估指标，辅以三个多样性指数来评估推理内容的多样性。测试了六种广泛使用的LLM，以验证不同模型层级的通信模式鲁棒性。", "result": "采用Echo通信模式的生成代理在准确性得分上最高，而DeepSeek在多样性方面表现最佳。", "conclusion": "本研究为提高代理学习能力和启发智能教育模型提供了有价值的信息。"}}
{"id": "2508.03117", "title": "Toward a Trustworthy Optimization Modeling Agent via Verifiable Synthetic Data Generation", "authors": ["Vinicius Lima", "Dzung T. Phan", "Jayant Kalagnanam", "Dhaval Patel", "Nianjun Zhou"], "abstract": "We present a framework for training trustworthy large language model (LLM) agents for optimization modeling via a verifiable synthetic data generation pipeline. Focusing on linear and mixed-integer linear programming, our approach begins with structured symbolic representations and systematically produces natural language descriptions, mathematical formulations, and solver-executable code. By programmatically constructing each instance with known optimal solutions, the pipeline ensures full verifiability and enables automatic filtering of low-quality demonstrations generated by teacher models. Each dataset instance includes a structured representation of the optimization problem, a corresponding natural language description, the verified optimal solution, and step-by-step demonstrations - generated by a teacher model - that show how to model and solve the problem across multiple optimization modeling languages. This enables supervised fine-tuning of open-source LLMs specifically tailored to optimization tasks. To operationalize this pipeline, we introduce OptiTrust, a modular LLM agent that performs multi-stage translation from natural language to solver-ready code, leveraging stepwise demonstrations, multi-language inference, and majority-vote cross-validation. Our agent achieves state-of-the-art performance on standard benchmarks. Out of 7 datasets, it achieves the highest accuracy on six and outperforms the next-best algorithm by at least 8 percentage on three of them. Our approach provides a scalable, verifiable, and principled path toward building reliable LLM agents for real-world optimization applications.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "25 pages", "pdf_url": "https://arxiv.org/pdf/2508.03117.pdf", "abstract_url": "https://arxiv.org/abs/2508.03117", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种通过可验证的合成数据生成管道训练可信赖的大型语言模型（LLM）代理的框架，专注于线性和混合整数线性规划。通过程序化构建每个实例，确保完全可验证性，并自动过滤低质量的演示。", "motivation": "解决在现实世界优化应用中构建可靠LLM代理的可扩展性、可验证性和原则性问题。", "method": "采用结构化符号表示，系统生成自然语言描述、数学公式和求解器可执行代码的程序化构建方法，引入OptiTrust模块化LLM代理进行多阶段翻译。", "result": "在7个数据集中，OptiTrust在六个上达到了最高准确率，并在其中三个上比次优算法至少高出8个百分点。", "conclusion": "该方法为构建用于现实世界优化应用的可信赖LLM代理提供了一条可扩展、可验证和原则性的路径。"}}
{"id": "2508.03174", "title": "InqEduAgent: Adaptive AI Learning Partners with Gaussian Process Augmentation", "authors": ["Tian-Fang Zhao", "Wen-Xi Yang"], "abstract": "Collaborative partnership matters in inquiry-oriented education. However, most study partners are selected either rely on experience-based assignments with little scientific planning or build on rule-based machine assistants, encountering difficulties in knowledge expansion and inadequate flexibility. This paper proposes an LLM-empowered agent model for simulating and selecting learning partners tailored to inquiry-oriented learning, named InqEduAgent. Generative agents are designed to capture cognitive and evaluative features of learners in real-world scenarios. Then, an adaptive matching algorithm with Gaussian process augmentation is formulated to identify patterns within prior knowledge. Optimal learning-partner matches are provided for learners facing different exercises. The experimental results show the optimal performance of InqEduAgent in most knowledge-learning scenarios and LLM environment with different levels of capabilities. This study promotes the intelligent allocation of human-based learning partners and the formulation of AI-based learning partners. The code, data, and appendix are publicly available at", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.03174.pdf", "abstract_url": "https://arxiv.org/abs/2508.03174", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为InqEduAgent的LLM赋能代理模型，用于模拟和选择适合探究式学习的学习伙伴，通过高斯过程增强的自适应匹配算法优化学习伙伴的匹配。", "motivation": "探究式教育中协作伙伴的选择往往缺乏科学规划或依赖于基于规则的机器助手，导致知识扩展不足和灵活性不够。", "method": "设计了生成代理以捕捉学习者在真实场景中的认知和评估特征，并制定了带有高斯过程增强的自适应匹配算法来识别先验知识中的模式。", "result": "实验结果表明，InqEduAgent在大多数知识学习场景和不同能力水平的LLM环境中表现最优。", "conclusion": "本研究促进了基于人类的学习伙伴的智能分配和基于AI的学习伙伴的制定，相关代码、数据和附录已公开。"}}
{"id": "2508.03341", "title": "Nemori: Self-Organizing Agent Memory Inspired by Cognitive Science", "authors": ["Jiayan Nan", "Wenquan Ma", "Wenlong Wu", "Yize Chen"], "abstract": "Large Language Models (LLMs) demonstrate remarkable capabilities, yet their inability to maintain persistent memory in long contexts limits their effectiveness as autonomous agents in long-term interactions. While existing memory systems have made progress, their reliance on arbitrary granularity for defining the basic memory unit and passive, rule-based mechanisms for knowledge extraction limits their capacity for genuine learning and evolution. To address these foundational limitations, we present Nemori, a novel self-organizing memory architecture inspired by human cognitive principles. Nemori's core innovation is twofold: First, its Two-Step Alignment Principle, inspired by Event Segmentation Theory, provides a principled, top-down method for autonomously organizing the raw conversational stream into semantically coherent episodes, solving the critical issue of memory granularity. Second, its Predict-Calibrate Principle, inspired by the Free-energy Principle, enables the agent to proactively learn from prediction gaps, moving beyond pre-defined heuristics to achieve adaptive knowledge evolution. This offers a viable path toward handling the long-term, dynamic workflows of autonomous agents. Extensive experiments on the LoCoMo and LongMemEval benchmarks demonstrate that Nemori significantly outperforms prior state-of-the-art systems, with its advantage being particularly pronounced in longer contexts.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.03341.pdf", "abstract_url": "https://arxiv.org/abs/2508.03341", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了Nemori，一种受人类认知原理启发的新型自组织记忆架构，旨在解决大型语言模型（LLMs）在长期交互中无法维持持久记忆的问题。通过两步对齐原则和预测校准原则，Nemori能够自主组织对话流并主动学习预测差距，显著优于现有最先进系统。", "motivation": "大型语言模型（LLMs）在长期交互中无法维持持久记忆，现有记忆系统在知识提取和学习进化方面存在限制。", "method": "Nemori采用了两步对齐原则和预测校准原则，分别受事件分割理论和自由能原理启发，用于自主组织对话流和主动学习预测差距。", "result": "在LoCoMo和LongMemEval基准测试中，Nemori显著优于现有最先进系统，尤其在较长上下文中表现更为突出。", "conclusion": "Nemori为解决自主代理在长期动态工作流程中的记忆问题提供了可行路径，其性能在长上下文环境中尤为显著。"}}
{"id": "2508.03333", "title": "CTTS: Collective Test-Time Scaling", "authors": ["Zhende Song", "Shengji Tang", "Peng Ye", "Jiayuan Fan", "Tao Chen"], "abstract": "Test-time scaling (TTS) has emerged as a promising research field for enhancing the effectiveness of large language models (LLMs) without extra training. However, most existing approaches, e.g., Best-of-N and Self-Consistency rely on a single agent interacting with a reward model (SA-SR), constrained by limited capabilities of a single test-time scaling (STTS) paradigm. On the other hand, recent works demonstrate that collective-agent methods can break through the upper bound of single-agent systems by orchestrating diverse models. Thus, in this paper, we take a first step towards exploring Collective Test-Time Scaling (CTTS). Consider the different interaction types of single and multiple models, we design three primary paradigms to investigate the optimal paradigm of CTTS: (1) single agent to multiple reward models (SA-MR); (2) multiple agents to single reward model (MA-SR); and (3) multiple agents to multiple reward models (MA-MR). Extensive experiments demonstrate that MA-MR consistently achieves the best performance. Based on this, we propose a novel framework named CTTS-MM that effectively leverages both multi-agent and multi-reward-model collaboration for enhanced inference. Specifically, for multi-agent collaboration, we propose an Agent Collaboration Search (ACS), which searches for the most effective combination of LLM agents from a large candidate pool; for multi-reward-model collaboration, we propose Mixture of Reword Models (MoR), which consists of a curated question pool and a Prior Reward model Ensemble Selection (PRES) to select the optimal combinations of reward models via Pair-wise Reward Ranking (PRR) metric. Experiments across seven mainstream benchmarks demonstrate that the proposed CTTS-MM consistently obtains superior performance. Code will be released at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.03333.pdf", "abstract_url": "https://arxiv.org/abs/2508.03333", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了集体测试时间缩放（CTTS）的概念，探索了三种主要范式，并提出了一种名为CTTS-MM的新框架，该框架通过多代理和多奖励模型的协作来增强推理性能。", "motivation": "解决现有测试时间缩放（TTS）方法依赖于单一代理与奖励模型交互（SA-SR）的限制，探索集体代理方法以突破单一代理系统的上限。", "method": "设计了三种CTTS范式：SA-MR、MA-SR和MA-MR，并提出CTTS-MM框架，包括代理协作搜索（ACS）和奖励模型混合（MoR）方法。", "result": "实验表明，MA-MR范式 consistently achieves the best performance，CTTS-MM框架在七个主流基准测试中 consistently obtains superior performance。", "conclusion": "集体测试时间缩放（CTTS）通过多代理和多奖励模型的协作，能够有效提升大型语言模型（LLMs）的推理性能，CTTS-MM框架为此提供了一种有效的实现方式。"}}
{"id": "2508.03345", "title": "Adaptive AI Agent Placement and Migration in Edge Intelligence Systems", "authors": ["Xingdan Wang", "Jiayi He", "Zhiqing Tang", "Jianxiong Guo", "Jiong Lou", "Liping Qian", "Tian Wang", "Weijia Jia"], "abstract": "The rise of LLMs such as ChatGPT and Claude fuels the need for AI agents capable of real-time task handling. However, migrating data-intensive, multi-modal edge workloads to cloud data centers, traditionally used for agent deployment, introduces significant latency. Deploying AI agents at the edge improves efficiency and reduces latency. However, edge environments present challenges due to limited and heterogeneous resources. Maintaining QoS for mobile users necessitates agent migration, which is complicated by the complexity of AI agents coordinating LLMs, task planning, memory, and external tools. This paper presents the first systematic deployment and management solution for LLM-based AI agents in dynamic edge environments. We propose a novel adaptive framework for AI agent placement and migration in edge intelligence systems. Our approach models resource constraints and latency/cost, leveraging ant colony algorithms and LLM-based optimization for efficient decision-making. It autonomously places agents to optimize resource utilization and QoS and enables lightweight agent migration by transferring only essential state. Implemented on a distributed system using AgentScope and validated across globally distributed edge servers, our solution significantly reduces deployment latency and migration costs.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.03345.pdf", "abstract_url": "https://arxiv.org/abs/2508.03345", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种在边缘智能系统中自适应放置和迁移AI代理的新框架，旨在解决在动态边缘环境中部署和管理基于LLM的AI代理的挑战。通过利用蚁群算法和基于LLM的优化，该框架优化了资源利用和服务质量，并实现了轻量级代理迁移。", "motivation": "随着如ChatGPT和Claude等大型语言模型(LLMs)的兴起，需要能够实时处理任务的AI代理。然而，将数据密集型、多模态的边缘工作负载迁移到传统上用于代理部署的云数据中心会引入显著的延迟。在边缘部署AI代理提高了效率并减少了延迟，但边缘环境由于资源有限和异构性带来了挑战。", "method": "本文提出了一个新颖的自适应框架，用于在边缘智能系统中进行AI代理的放置和迁移。该方法建模了资源约束和延迟/成本，利用蚁群算法和基于LLM的优化进行高效决策。它自主地放置代理以优化资源利用和服务质量，并通过仅传输必要状态实现轻量级代理迁移。", "result": "在分布式系统上使用AgentScope实现并在全球分布的边缘服务器上验证，我们的解决方案显著减少了部署延迟和迁移成本。", "conclusion": "本文提出的框架为解决在动态边缘环境中部署和管理基于LLM的AI代理的挑战提供了首个系统化的解决方案，通过优化资源利用和服务质量，以及实现轻量级代理迁移，显著提高了效率和减少了成本。"}}
{"id": "2508.03489", "title": "CF-RAG: A Dataset and Method for Carbon Footprint QA Using Retrieval-Augmented Generation", "authors": ["Kaiwen Zhao", "Bharathan Balaji", "Stephen Lee"], "abstract": "Product sustainability reports provide valuable insights into the environmental impacts of a product and are often distributed in PDF format. These reports often include a combination of tables and text, which complicates their analysis. The lack of standardization and the variability in reporting formats further exacerbate the difficulty of extracting and interpreting relevant information from large volumes of documents. In this paper, we tackle the challenge of answering questions related to carbon footprints within sustainability reports available in PDF format. Unlike previous approaches, our focus is on addressing the difficulties posed by the unstructured and inconsistent nature of text extracted from PDF parsing. To facilitate this analysis, we introduce CarbonPDF-QA, an open-source dataset containing question-answer pairs for 1735 product report documents, along with human-annotated answers. Our analysis shows that GPT-4o struggles to answer questions with data inconsistencies. To address this limitation, we propose CarbonPDF, an LLM-based technique specifically designed to answer carbon footprint questions on such datasets. We develop CarbonPDF by fine-tuning Llama 3 with our training data. Our results show that our technique outperforms current state-of-the-art techniques, including question-answering (QA) systems finetuned on table and text data.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.03489.pdf", "abstract_url": "https://arxiv.org/abs/2508.03489", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了CF-RAG：一个使用检索增强生成进行碳足迹问答的数据集和方法，旨在解决从非标准化和格式多变的PDF格式可持续性报告中提取和解释碳足迹相关信息的挑战。", "motivation": "解决从非标准化和格式多变的PDF格式可持续性报告中提取和解释碳足迹相关信息的挑战。", "method": "引入了CarbonPDF-QA数据集，并提出了一种基于LLM的技术CarbonPDF，通过微调Llama 3来回答碳足迹问题。", "result": "CarbonPDF在回答碳足迹问题上优于当前最先进的技术，包括在表格和文本数据上微调的问答系统。", "conclusion": "本文提出的方法和技术在提高从可持续性报告中提取碳足迹信息的准确性和效率方面具有重要价值，为相关领域的研究和应用提供了新的工具和数据集。"}}
{"id": "2508.03529", "title": "Marito: Structuring and Building Open Multilingual Terminologies for South African NLP", "authors": ["Vukosi Marivate", "Isheanesu Dzingirai", "Fiskani Banda", "Richard Lastrucci", "Thapelo Sindane", "Keabetswe Madumo", "Kayode Olaleye", "Abiodun Modupe", "Unarine Netshifhefhe", "Herkulaas Combrink", "Mohlatlego Nakeng", "Matome Ledwaba"], "abstract": "The critical lack of structured terminological data for South Africa's official languages hampers progress in multilingual NLP, despite the existence of numerous government and academic terminology lists. These valuable assets remain fragmented and locked in non-machine-readable formats, rendering them unusable for computational research and development. \\emph{Marito} addresses this challenge by systematically aggregating, cleaning, and standardising these scattered resources into open, interoperable datasets. We introduce the foundational \\emph{Marito} dataset, released under the equitable, Africa-centered NOODL framework. To demonstrate its immediate utility, we integrate the terminology into a Retrieval-Augmented Generation (RAG) pipeline. Experiments show substantial improvements in the accuracy and domain-specific consistency of English-to-Tshivenda machine translation for large language models. \\emph{Marito} provides a scalable foundation for developing robust and equitable NLP technologies, ensuring South Africa's rich linguistic diversity is represented in the digital age.", "subjects": "Computation and Language (cs.CL)", "comments": "Under Review", "pdf_url": "https://arxiv.org/pdf/2508.03529.pdf", "abstract_url": "https://arxiv.org/abs/2508.03529", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "Marito项目旨在解决南非官方语言缺乏结构化术语数据的问题，通过整合、清理和标准化分散的资源，构建开放、可互操作的数据集，以支持多语言NLP的发展。", "motivation": "南非官方语言的术语数据缺乏结构化和机器可读性，阻碍了多语言NLP的进展。", "method": "系统地聚合、清理和标准化分散的术语资源，构建开放、可互操作的数据集，并通过检索增强生成（RAG）管道验证其效用。", "result": "实验显示，将术语整合到RAG管道中显著提高了大型语言模型在英语到Tshivenda机器翻译中的准确性和领域一致性。", "conclusion": "Marito为开发强大且公平的NLP技术提供了可扩展的基础，确保南非丰富的语言多样性在数字时代得到体现。"}}
{"id": "2508.03404", "title": "Visual Document Understanding and Question Answering: A Multi-Agent Collaboration Framework with Test-Time Scaling", "authors": ["Xinlei Yu", "Zhangquan Chen", "Yudong Zhang", "Shilin Lu", "Ruolin Shen", "Jiangning Zhang", "Xiaobin Hu", "Yanwei Fu", "Shuicheng Yan"], "abstract": "Existing vision-language models (VLMs), whether generalists or specialists, remain constrained by their parameter scale, lack robust self-correction capabilities, and underperform in tasks involving long visual contexts and complex reasoning, resulting in suboptimal performance on document-based tasks. To address this, we propose MACT, a Multi-Agent Collaboration framework with Test-Time scaling, tailored for visual document understanding and visual question answering (VQA). It comprises four distinct small-scale agents, i.e., planning, execution, judgment, and answer agents, with clearly defined roles and effective collaboration. Notably, the judgment agent exclusively verifies correctness and redirects to prior agents for revisions, outperforming conventional correction strategies. To further expand the capability boundaries of the framework, we propose mixed reward modeling that balances agent-specific abilities and global collaboration, as well as agent-wise hybrid test-time scaling, which customizes different scaling strategies for each agent based on their functions. Evaluated on benchmarks spanning both document-based and non-document-based settings, our MACT shows superior performance with a smaller parameter scale without sacrificing the ability of general and mathematical tasks. Especially, it stands out in benchmarks involving long visual contexts and complicated reasoning. The three variants of MACT consistently hold the top three positions in average scores, leading in 13 of the 15 benchmarks. Code will be available at:", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.03404.pdf", "abstract_url": "https://arxiv.org/abs/2508.03404", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为MACT的多智能体协作框架，专为视觉文档理解和视觉问答设计，通过四个不同的小规模智能体和测试时扩展策略，显著提升了处理长视觉上下文和复杂推理任务的能力。", "motivation": "现有的视觉语言模型（VLMs）在处理长视觉上下文和复杂推理任务时表现不佳，主要受限于其参数规模、缺乏自我校正能力。", "method": "提出了MACT框架，包括规划、执行、判断和回答四个智能体，采用混合奖励模型和智能体级混合测试时扩展策略。", "result": "MACT在多个基准测试中表现出色，尤其是在涉及长视觉上下文和复杂推理的任务中，其三个变体在15个基准测试中的13个领先。", "conclusion": "MACT框架在较小的参数规模下实现了卓越的性能，特别是在处理复杂文档和理解任务时，为视觉文档理解和视觉问答领域提供了新的解决方案。"}}
{"id": "2508.03368", "title": "Board Game Arena: A Framework and Benchmark for Assessing Large Language Models via Strategic Play", "authors": ["Lucia Cipolina-Kun", "Marianna Nezhurina", "Jenia Jitsev"], "abstract": "The Board Game Arena library provides a framework for evaluating the decision making abilities of large language models (LLMs) through strategic board games implemented in Google OpenSpiel library. The framework enables systematic comparisons between LLM based agents and other agents (random, human, reinforcement learning agents, etc.) in various game scenarios by wrapping multiple board and matrix games and supporting different agent types. It integrates API access to models via LiteLLM, local model deployment via vLLM, and offers distributed execution through Ray. Additionally it provides extensive analysis tools for the LLM reasoning traces. This paper summarizes the structure, key characteristics, and motivation of the repository, highlighting how it contributes to the empirical evaluation of the reasoning of LLM and game-theoretic behavior", "subjects": "Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.03368.pdf", "abstract_url": "https://arxiv.org/abs/2508.03368", "categories": ["Artificial Intelligence (cs.AI)", "Computer Science and Game Theory (cs.GT)"], "matching_keywords": ["agent"], "AI": {"tldr": "Board Game Arena库提供了一个框架，通过战略棋盘游戏评估大型语言模型（LLMs）的决策能力，支持与随机、人类、强化学习代理等的系统比较。", "motivation": "解决如何系统地评估大型语言模型在战略游戏中的决策和推理能力的问题。", "method": "利用Google OpenSpiel库实现的战略棋盘游戏，通过LiteLLM API访问模型，vLLM本地部署模型，以及Ray分布式执行，进行多代理比较。", "result": "提供了一个全面的框架和工具集，用于评估LLMs在游戏中的表现和推理过程。", "conclusion": "Board Game Arena为评估LLMs的战略决策和游戏理论行为提供了实证基础，推动了相关研究的发展。"}}
{"id": "2508.03406", "title": "Multi-Objective Infeasibility Diagnosis for Routing Problems Using Large Language Models", "authors": ["Kai Li", "Ruihao Zheng", "Xinye Hao", "Zhenkun Wang"], "abstract": "In real-world routing problems, users often propose conflicting or unreasonable requirements, which result in infeasible optimization models due to overly restrictive or contradictory constraints, leading to an empty feasible solution set. Existing Large Language Model (LLM)-based methods attempt to diagnose infeasible models, but modifying such models often involves multiple potential adjustments that these methods do not consider. To fill this gap, we introduce Multi-Objective Infeasibility Diagnosis (MOID), which combines LLM agents and multi-objective optimization within an automatic routing solver, to provide a set of representative actionable suggestions. Specifically, MOID employs multi-objective optimization to consider both path cost and constraint violation, generating a set of trade-off solutions, each encompassing varying degrees of model adjustments. To extract practical insights from these solutions, MOID utilizes LLM agents to generate a solution analysis function for the infeasible model. This function analyzes these distinct solutions to diagnose the original infeasible model, providing users with diverse diagnostic insights and suggestions. Finally, we compare MOID with several LLM-based methods on 50 types of infeasible routing problems. The results indicate that MOID automatically generates multiple diagnostic suggestions in a single run, providing more practical insights for restoring model feasibility and decision-making compared to existing methods.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.03406.pdf", "abstract_url": "https://arxiv.org/abs/2508.03406", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了多目标不可行性诊断（MOID）方法，结合大型语言模型（LLM）代理和多目标优化，为路由问题中的不可行模型提供代表性可操作建议。", "motivation": "解决现实世界路由问题中因冲突或不合理要求导致的模型不可行性问题，现有LLM方法未考虑多种潜在调整。", "method": "MOID方法结合LLM代理和多目标优化，考虑路径成本和约束违反，生成一组权衡解决方案，并利用LLM代理生成解决方案分析函数。", "result": "在50种不可行路由问题上比较MOID与几种基于LLM的方法，结果显示MOID在单次运行中自动生成多种诊断建议，提供更实用的模型可行性恢复和决策见解。", "conclusion": "MOID方法通过结合LLM和多目标优化，有效诊断和解决路由问题中的模型不可行性，为用户提供多样化的诊断见解和建议。"}}
{"id": "2508.03438", "title": "Data Overdose? Time for a Quadruple Shot: Knowledge Graph Construction using Enhanced Triple Extraction", "authors": ["Taine J. Elliott", "Stephen P. Levitt", "Ken Nixon", "Martin Bekker"], "abstract": "The rapid expansion of publicly-available medical data presents a challenge for clinicians and researchers alike, increasing the gap between the volume of scientific literature and its applications. The steady growth of studies and findings overwhelms medical professionals at large, hindering their ability to systematically review and understand the latest knowledge. This paper presents an approach to information extraction and automatic knowledge graph (KG) generation to identify and connect biomedical knowledge. Through a pipeline of large language model (LLM) agents, the system decomposes 44 PubMed abstracts into semantically meaningful proposition sentences and extracts KG triples from these sentences. The triples are enhanced using a combination of open domain and ontology-based information extraction methodologies to incorporate ontological categories. On top of this, a context variable is included during extraction to allow the triple to stand on its own - thereby becoming `quadruples'. The extraction accuracy of the LLM is validated by comparing natural language sentences generated from the enhanced triples to the original propositions, achieving an average cosine similarity of 0.874. The similarity for generated sentences of enhanced triples were compared with generated sentences of ordinary triples showing an increase as a result of the context variable. Furthermore, this research explores the ability for LLMs to infer new relationships and connect clusters in the knowledge base of the knowledge graph. This approach leads the way to provide medical practitioners with a centralised, updated in real-time, and sustainable knowledge source, and may be the foundation of similar gains in a wide variety of fields.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "18 pages, 8 figures, Published in the Annual Conference of South African Institute of Computer Scientists and Information Technologists, Preprint (author original)", "pdf_url": "https://arxiv.org/pdf/2508.03438.pdf", "abstract_url": "https://arxiv.org/abs/2508.03438", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种利用增强的三重提取构建知识图谱的方法，旨在解决医学数据快速增长带来的挑战。通过结合开放领域和基于本体的信息提取方法，以及引入上下文变量，系统能够更准确地提取和连接生物医学知识。", "motivation": "解决医学数据快速增长与医学专业人员系统化理解和应用最新知识之间的差距。", "method": "使用大型语言模型（LLM）代理管道，将PubMed摘要分解为有意义的命题句子，并从中提取知识图谱三重，通过结合开放领域和基于本体的信息提取方法增强这些三重，并引入上下文变量形成'四重'。", "result": "增强三重的提取准确率通过与原命题的自然语言句子比较得到验证，平均余弦相似度为0.874。增强三重的生成句子与普通三重的生成句子相比，相似度有所提高。", "conclusion": "该方法为医学从业者提供了一个集中、实时更新和可持续的知识来源，并可能在广泛领域中带来类似的收益。"}}
{"id": "2508.03680", "title": "Agent Lightning: Train ANY AI Agents with Reinforcement Learning", "authors": ["Xufang Luo", "Yuge Zhang", "Zhiyuan He", "Zilong Wang", "Siyun Zhao", "Dongsheng Li", "Luna K. Qiu", "Yuqing Yang"], "abstract": "We present Agent Lightning, a flexible and extensible framework that enables Reinforcement Learning (RL)-based training of Large Language Models (LLMs) for any AI agent. Unlike existing methods that tightly couple RL training with agent or rely on sequence concatenation with masking, Agent Lightning achieves complete decoupling between agent execution and training, allowing seamless integration with existing agents developed via diverse ways (e.g., using frameworks like LangChain, OpenAI Agents SDK, AutoGen, and building from scratch) with almost ZERO code modifications. By formulating agent execution as Markov decision process, we define an unified data interface and propose a hierarchical RL algorithm, LightningRL, which contains a credit assignment module, allowing us to decompose trajectories generated by ANY agents into training transition. This enables RL to handle complex interaction logic, such as multi-agent scenarios and dynamic workflows. For the system design, we introduce a Training-Agent Disaggregation architecture, and brings agent observability frameworks into agent runtime, providing a standardized agent finetuning interface. Experiments across text-to-SQL, retrieval-augmented generation, and math tool-use tasks demonstrate stable, continuous improvements, showcasing the framework's potential for real-world agent training and deployment.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.03680.pdf", "abstract_url": "https://arxiv.org/abs/2508.03680", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "Agent Lightning是一个灵活且可扩展的框架，支持通过强化学习（RL）训练任何AI代理的大型语言模型（LLMs）。它实现了代理执行与训练的完全解耦，支持与现有代理的无缝集成，几乎无需代码修改。", "motivation": "解决现有方法中强化学习训练与代理紧密耦合或依赖于序列拼接与掩码的问题，提供一个更灵活、可扩展的解决方案。", "method": "通过将代理执行建模为马尔可夫决策过程，定义统一的数据接口，并提出包含信用分配模块的分层RL算法LightningRL，以分解任何代理生成的轨迹为训练过渡。", "result": "在文本到SQL、检索增强生成和数学工具使用等任务上的实验展示了稳定、持续的改进，证明了框架在现实世界代理训练和部署中的潜力。", "conclusion": "Agent Lightning框架通过其解耦设计和分层RL算法，为AI代理的训练提供了一个灵活、高效的解决方案，具有广泛的应用前景。"}}
{"id": "2508.03644", "title": "Are We on the Right Way for Assessing Document Retrieval-Augmented Generation?", "authors": ["Wenxuan Shen", "Mingjia Wang", "Yaochen Wang", "Dongping Chen", "Junjie Yang", "Yao Wan", "Weiwei Lin"], "abstract": "Retrieval-Augmented Generation (RAG) systems using Multimodal Large Language Models (MLLMs) show great promise for complex document understanding, yet their development is critically hampered by inadequate evaluation. Current benchmarks often focus on specific part of document RAG system and use synthetic data with incomplete ground truth and evidence labels, therefore failing to reflect real-world bottlenecks and challenges. To overcome these limitations, we introduce Double-Bench: a new large-scale, multilingual, and multimodal evaluation system that is able to produce fine-grained assessment to each component within document RAG systems. It comprises 3,276 documents (72,880 pages) and 5,168 single- and multi-hop queries across 6 languages and 4 document types with streamlined dynamic update support for potential data contamination issues. Queries are grounded in exhaustively scanned evidence pages and verified by human experts to ensure maximum quality and completeness. Our comprehensive experiments across 9 state-of-the-art embedding models, 4 MLLMs and 4 end-to-end document RAG frameworks demonstrate the gap between text and visual embedding models is narrowing, highlighting the need in building stronger document retrieval models. Our findings also reveal the over-confidence dilemma within current document RAG frameworks that tend to provide answer even without evidence support. We hope our fully open-source Double-Bench provide a rigorous foundation for future research in advanced document RAG systems. We plan to retrieve timely corpus and release new benchmarks on an annual basis.", "subjects": "Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Information Retrieval (cs.IR)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2508.03644.pdf", "abstract_url": "https://arxiv.org/abs/2508.03644", "categories": ["Computation and Language (cs.CL)", "Computer Vision and Pattern Recognition (cs.CV)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了Double-Bench，一个新的多语言、多模态评估系统，旨在解决当前检索增强生成（RAG）系统评估的不足，通过提供细粒度的评估来促进复杂文档理解技术的发展。", "motivation": "当前检索增强生成（RAG）系统的评估存在不足，主要集中在系统的特定部分，使用合成数据且缺乏完整的地面真实和证据标签，无法反映真实世界的瓶颈和挑战。", "method": "引入Double-Bench，一个大规模、多语言、多模态的评估系统，包含3,276份文档（72,880页）和5,168个单跳和多跳查询，覆盖6种语言和4种文档类型，支持动态更新以防止数据污染。", "result": "实验表明，文本和视觉嵌入模型之间的差距正在缩小，揭示了当前文档RAG框架中存在过度自信的问题，即在没有证据支持的情况下也倾向于提供答案。", "conclusion": "Double-Bench为未来高级文档RAG系统的研究提供了严格的基础，计划每年检索及时语料并发布新的基准。"}}
{"id": "2508.02721", "title": "Blueprint First, Model Second: A Framework for Deterministic LLM Workflow", "authors": ["Libin Qiu", "Yuhang Ye", "Zhirong Gao", "Xide Zou", "Junfu Chen", "Ziming Gui", "Weizhi Huang", "Xiaobo Xue", "Wenkai Qiu", "Kun Zhao"], "abstract": "While powerful, the inherent non-determinism of large language model (LLM) agents limits their application in structured operational environments where procedural fidelity and predictable execution are strict requirements. This limitation stems from current architectures that conflate probabilistic, high-level planning with low-level action execution within a single generative process. To address this, we introduce the Source Code Agent framework, a new paradigm built on the \"Blueprint First, Model Second\" philosophy. Our framework decouples the workflow logic from the generative model. An expert-defined operational procedure is first codified into a source code-based Execution Blueprint, which is then executed by a deterministic engine. The LLM is strategically invoked as a specialized tool to handle bounded, complex sub-tasks within the workflow, but never to decide the workflow's path. We conduct a comprehensive evaluation on the challenging tau-bench benchmark, designed for complex user-tool-rule scenarios. Our results demonstrate that the Source Code Agent establishes a new state-of-the-art, outperforming the strongest baseline by 10.1 percentage points on the average Pass^1 score while dramatically improving execution efficiency. Our work enables the verifiable and reliable deployment of autonomous agents in applications governed by strict procedural logic.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI); Programming Languages (cs.PL)", "comments": "8 pages, 6 figures, 3 tables", "pdf_url": "https://arxiv.org/pdf/2508.02721.pdf", "abstract_url": "https://arxiv.org/abs/2508.02721", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)", "Programming Languages (cs.PL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为'源代码代理框架'的新范式，旨在解决大型语言模型（LLM）代理在结构化操作环境中因固有的非确定性而受限的问题。该框架基于'蓝图优先，模型其次'的理念，将工作流逻辑与生成模型解耦，通过专家定义的操作程序首先编码为基于源代码的执行蓝图，然后由确定性引擎执行。LLM被策略性地调用为处理工作流中有界复杂子任务的专门工具，而不决定工作流的路径。在tau-bench基准测试中，该框架表现出色，平均Pass^1得分比最强基线高出10.1个百分点，同时显著提高了执行效率。", "motivation": "大型语言模型（LLM）代理的非确定性限制了其在需要严格程序保真度和可预测执行的结构化操作环境中的应用。当前架构将概率性的高级规划与低级动作执行混为一谈，导致这一限制。", "method": "引入了'源代码代理框架'，采用'蓝图优先，模型其次'的方法，将工作流逻辑与生成模型解耦。首先将专家定义的操作程序编码为执行蓝图，然后由确定性引擎执行，LLM仅作为处理有界复杂子任务的工具。", "result": "在tau-bench基准测试中，源代码代理框架平均Pass^1得分比最强基线高出10.1个百分点，同时显著提高了执行效率。", "conclusion": "该工作使得在严格程序逻辑管理的应用中，能够可靠且可验证地部署自主代理，为LLM在结构化环境中的应用开辟了新途径。"}}
{"id": "2508.03501", "title": "Training Long-Context, Multi-Turn Software Engineering Agents with Reinforcement Learning", "authors": ["Alexander Golubev", "Maria Trofimova", "Sergei Polezhaev", "Ibragim Badertdinov", "Maksim Nekrashevich", "Anton Shevtsov", "Simon Karasik", "Sergey Abramov", "Andrei Andriushchenko", "Filipp Fisin", "Sergei Skvortsov", "Boris Yangel"], "abstract": "Research on applications of Reinforcement Learning (RL) to Large Language Models (LLMs) has mostly been focused on single-turn problems, such as mathematical reasoning or single-shot code generation. While these problems can be viewed as token-level multi-turn MDPs, this view corresponds to a degenerate case of multi-turn interaction where the environment provides no feedback. This contrasts with many real-world domains, such as software engineering (SWE), which require rich multi-turn interactions with a stateful environment that responds to each action with a non-trivial observation.", "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL); Software Engineering (cs.SE)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.03501.pdf", "abstract_url": "https://arxiv.org/abs/2508.03501", "categories": ["Machine Learning (cs.LG)", "Computation and Language (cs.CL)", "Software Engineering (cs.SE)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了将强化学习（RL）应用于大型语言模型（LLMs）以解决多轮交互问题，特别是在软件工程（SWE）领域的应用。与单轮问题不同，SWE需要与有状态环境进行丰富的多轮交互。", "motivation": "现有的RL应用于LLMs的研究主要集中在单轮问题上，如数学推理或一次性代码生成，这些问题的环境反馈有限。然而，许多实际领域，如软件工程，需要与有状态环境进行复杂的多轮交互，这促使研究者探索更适用的RL方法。", "method": "本文提出了一种使用强化学习训练能够处理长上下文、多轮交互的软件工程代理的方法。这种方法考虑了环境的状态和每次动作后的非平凡观察。", "result": "研究结果表明，通过考虑环境的状态和反馈，RL可以有效地应用于训练能够处理复杂多轮交互的LLMs，特别是在软件工程领域。", "conclusion": "本文的结论是，通过适当的RL方法，可以训练出能够处理长上下文和多轮交互的LLMs，这对于软件工程等需要复杂交互的领域具有重要意义。"}}
{"id": "2508.03553", "title": "MultiRAG: A Knowledge-guided Framework for Mitigating Hallucination in Multi-source Retrieval Augmented Generation", "authors": ["Wenlong Wu", "Haofen Wang", "Bohan Li", "Peixuan Huang", "Xinzhe Zhao", "Lei Liang"], "abstract": "Retrieval Augmented Generation (RAG) has emerged as a promising solution to address hallucination issues in Large Language Models (LLMs). However, the integration of multiple retrieval sources, while potentially more informative, introduces new challenges that can paradoxically exacerbate hallucination problems. These challenges manifest primarily in two aspects: the sparse distribution of multi-source data that hinders the capture of logical relationships and the inherent inconsistencies among different sources that lead to information conflicts. To address these challenges, we propose MultiRAG, a novel framework designed to mitigate hallucination in multi-source retrieval-augmented generation through knowledge-guided approaches. Our framework introduces two key innovations: (1) a knowledge construction module that employs multi-source line graphs to efficiently aggregate logical relationships across different knowledge sources, effectively addressing the sparse data distribution issue; and (2) a sophisticated retrieval module that implements a multi-level confidence calculation mechanism, performing both graph-level and node-level assessments to identify and eliminate unreliable information nodes, thereby reducing hallucinations caused by inter-source inconsistencies. Extensive experiments on four multi-domain query datasets and two multi-hop QA datasets demonstrate that MultiRAG significantly enhances the reliability and efficiency of knowledge retrieval in complex multi-source scenarios. \\textcolor{blue}{Our code is available in", "subjects": "Information Retrieval (cs.IR); Computation and Language (cs.CL)", "comments": "Accepted by ICDE 2025 Research Paper", "pdf_url": "https://arxiv.org/pdf/2508.03553.pdf", "abstract_url": "https://arxiv.org/abs/2508.03553", "categories": ["Information Retrieval (cs.IR)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "MultiRAG是一个新颖的框架，旨在通过知识引导的方法减轻多源检索增强生成中的幻觉问题。", "motivation": "解决多源检索增强生成（RAG）中因数据稀疏分布和源间不一致导致的幻觉问题。", "method": "引入知识构建模块和多级置信度计算机制，分别用于聚合跨知识源的逻辑关系和识别消除不可靠信息节点。", "result": "在四个多领域查询数据集和两个多跳QA数据集上的广泛实验表明，MultiRAG显著提高了复杂多源场景下知识检索的可靠性和效率。", "conclusion": "MultiRAG通过其创新的知识引导方法，有效解决了多源RAG中的幻觉问题，为复杂场景下的知识检索提供了更可靠的解决方案。"}}
{"id": "2508.02773", "title": "Web3 x AI Agents: Landscape, Integrations, and Foundational Challenges", "authors": ["Yiming Shen", "Jiashuo Zhang", "Zhenzhe Shao", "Wenxuan Luo", "Yanlin Wang", "Ting Chen", "Zibin Zheng", "Jiachi Chen"], "abstract": "The convergence of Web3 technologies and AI agents represents a rapidly evolving frontier poised to reshape decentralized ecosystems. This paper presents the first and most comprehensive analysis of the intersection between Web3 and AI agents, examining five critical dimensions: landscape, economics, governance, security, and trust mechanisms. Through an analysis of 133 existing projects, we first develop a taxonomy and systematically map the current market landscape (RQ1), identifying distinct patterns in project distribution and capitalization. Building upon these findings, we further investigate four key integrations: (1) the role of AI agents in participating in and optimizing decentralized finance (RQ2); (2) their contribution to enhancing Web3 governance mechanisms (RQ3); (3) their capacity to strengthen Web3 security via intelligent vulnerability detection and automated smart contract auditing (RQ4); and (4) the establishment of robust reliability frameworks for AI agent operations leveraging Web3's inherent trust infrastructure (RQ5). By synthesizing these dimensions, we identify key integration patterns, highlight foundational challenges related to scalability, security, and ethics, and outline critical considerations for future research toward building robust, intelligent, and trustworthy decentralized systems with effective AI agent interactions.", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI); General Economics (econ.GN)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.02773.pdf", "abstract_url": "https://arxiv.org/abs/2508.02773", "categories": ["Computers and Society (cs.CY)", "Artificial Intelligence (cs.AI)", "General Economics (econ.GN)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文首次全面分析了Web3技术与AI代理的交汇点，探讨了五个关键维度：景观、经济、治理、安全和信任机制。通过分析133个现有项目，开发了一个分类法并系统地绘制了当前市场景观，识别了项目分布和资本化的不同模式。进一步研究了四个关键整合点，并指出了与可扩展性、安全性和伦理相关的基础挑战。", "motivation": "探索Web3技术与AI代理的融合如何重塑去中心化生态系统，解决现有挑战并推动未来发展。", "method": "通过分析133个现有项目，开发分类法并系统地绘制市场景观，识别模式和资本化情况，进而研究四个关键整合点。", "result": "识别了项目分布和资本化的不同模式，提出了AI代理在去中心化金融、治理、安全和信任机制中的关键作用，以及面临的可扩展性、安全性和伦理挑战。", "conclusion": "通过综合分析，本文为构建强大、智能和可信赖的去中心化系统与AI代理交互提供了关键见解和未来研究方向。"}}
{"id": "2508.02826", "title": "TransAM: Transformer-Based Agent Modeling for Multi-Agent Systems via Local Trajectory Encoding", "authors": ["Conor Wallace", "Umer Siddique", "Yongcan Cao"], "abstract": "Agent modeling is a critical component in developing effective policies within multi-agent systems, as it enables agents to form beliefs about the behaviors, intentions, and competencies of others. Many existing approaches assume access to other agents' episodic trajectories, a condition often unrealistic in real-world applications. Consequently, a practical agent modeling approach must learn a robust representation of the policies of the other agents based only on the local trajectory of the controlled agent. In this paper, we propose \\texttt{TransAM}, a novel transformer-based agent modeling approach to encode local trajectories into an embedding space that effectively captures the policies of other agents. We evaluate the performance of the proposed method in cooperative, competitive, and mixed multi-agent environments. Extensive experimental results demonstrate that our approach generates strong policy representations, improves agent modeling, and leads to higher episodic returns.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.02826.pdf", "abstract_url": "https://arxiv.org/abs/2508.02826", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于Transformer的代理建模方法TransAM，通过局部轨迹编码来有效捕捉多代理系统中其他代理的策略。", "motivation": "解决现有代理建模方法需要访问其他代理的完整轨迹这一不切实际的条件问题，提出仅基于控制代理的局部轨迹学习其他代理策略的鲁棒表示。", "method": "使用Transformer架构的TransAM方法，将局部轨迹编码到一个能够有效捕捉其他代理策略的嵌入空间。", "result": "在合作、竞争和混合多代理环境中的广泛实验结果表明，TransAM能生成强策略表示，改善代理建模，并带来更高的回合回报。", "conclusion": "TransAM作为一种新颖的代理建模方法，能够在仅依赖局部轨迹的情况下，有效学习和表示其他代理的策略，为多代理系统的发展提供了新的可能性。"}}
{"id": "2508.02856", "title": "Secure mmWave Beamforming with Proactive-ISAC Defense Against Beam-Stealing Attacks", "authors": ["Seyed Bagher Hashemi Natanzi", "Hossein Mohammadi", "Bo Tang", "Vuk Marojevic"], "abstract": "Millimeter-wave (mmWave) communication systems face increasing susceptibility to advanced beam-stealing attacks, posing a significant physical layer security threat. This paper introduces a novel framework employing an advanced Deep Reinforcement Learning (DRL) agent for proactive and adaptive defense against these sophisticated attacks. A key innovation is leveraging Integrated Sensing and Communications (ISAC) capabilities for active, intelligent threat assessment. The DRL agent, built on a Proximal Policy Optimization (PPO) algorithm, dynamically controls ISAC probing actions to investigate suspicious activities. We introduce an intensive curriculum learning strategy that guarantees the agent experiences successful detection during training to overcome the complex exploration challenges inherent to such a security-critical task. Consequently, the agent learns a robust and adaptive policy that intelligently balances security and communication performance. Numerical results demonstrate that our framework achieves a mean attacker detection rate of 92.8% while maintaining an average user SINR of over 13 dB.", "subjects": "Signal Processing (eess.SP); Artificial Intelligence (cs.AI); Networking and Internet Architecture (cs.NI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.02856.pdf", "abstract_url": "https://arxiv.org/abs/2508.02856", "categories": ["Signal Processing (eess.SP)", "Artificial Intelligence (cs.AI)", "Networking and Internet Architecture (cs.NI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新型框架，利用先进的深度强化学习（DRL）代理，通过集成感知与通信（ISAC）能力，主动和自适应地防御毫米波通信系统中的波束窃取攻击。采用近端策略优化（PPO）算法的DRL代理动态控制ISAC探测动作，结合密集课程学习策略，成功实现了92.8%的平均攻击者检测率和超过13 dB的用户平均SINR。", "motivation": "毫米波通信系统面临日益增加的波束窃取攻击威胁，这对物理层安全构成了重大挑战。", "method": "采用基于近端策略优化（PPO）算法的深度强化学习（DRL）代理，结合集成感知与通信（ISAC）能力，动态控制探测动作，并实施密集课程学习策略以确保训练期间的成功检测。", "result": "该框架实现了92.8%的平均攻击者检测率，同时保持了超过13 dB的用户平均SINR。", "conclusion": "提出的框架能够智能地平衡安全性和通信性能，为毫米波通信系统提供了一种有效的防御波束窃取攻击的解决方案。"}}
{"id": "2508.02912", "title": "Engineered over Emergent Communication in MARL for Scalable and Sample-Efficient Cooperative Task Allocation in a Partially Observable Grid", "authors": ["Brennen A. Hill", "Mant Koh En Wei", "Thangavel Jishnuanandh"], "abstract": "We compare the efficacy of learned versus engineered communication strategies in a cooperative multi-agent reinforcement learning (MARL) environment. For the learned approach, we introduce Learned Direct Communication (LDC), where agents generate messages and actions concurrently via a neural network. Our engineered approach, Intention Communication, employs an Imagined Trajectory Generation Module (ITGM) and a Message Generation Network (MGN) to formulate messages based on predicted future states. Both strategies are evaluated on their success rates in cooperative tasks under fully and partially observable conditions. Our findings indicate that while emergent communication is viable, the engineered approach demonstrates superior performance and scalability, particularly as environmental complexity increases.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Systems and Control (eess.SY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.02912.pdf", "abstract_url": "https://arxiv.org/abs/2508.02912", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Systems and Control (eess.SY)"], "matching_keywords": ["agent"], "AI": {"tldr": "比较了在多智能体强化学习（MARL）环境中学习与工程化通信策略的有效性，发现工程化方法在性能和可扩展性上更优。", "motivation": "解决在多智能体协作任务中，如何在部分可观察的环境中高效分配任务的问题。", "method": "引入了学习直接通信（LDC）和工程化的意图通信策略，后者使用想象轨迹生成模块（ITGM）和消息生成网络（MGN）来基于预测的未来状态制定消息。", "result": "工程化方法在环境复杂性增加时表现出更优的性能和可扩展性。", "conclusion": "尽管涌现通信是可行的，但工程化通信策略在复杂环境中更为有效和可扩展。"}}
{"id": "2508.02947", "title": "AeroSafe: Mobile Indoor Air Purification using Aerosol Residence Time Analysis and Robotic Cough Emulator Testbed", "authors": ["M Tanjid Hasan Tonmoy", "Rahath Malladi", "Kaustubh Singh", "Forsad Al Hossain", "Rajesh Gupta", "Andrés E. Tejada-Martínez", "Tauhidur Rahman"], "abstract": "Indoor air quality plays an essential role in the safety and well-being of occupants, especially in the context of airborne diseases. This paper introduces AeroSafe, a novel approach aimed at enhancing the efficacy of indoor air purification systems through a robotic cough emulator testbed and a digital-twins-based aerosol residence time analysis. Current portable air filters often overlook the concentrations of respiratory aerosols generated by coughs, posing a risk, particularly in high-exposure environments like healthcare facilities and public spaces. To address this gap, we present a robotic dual-agent physical emulator comprising a maneuverable mannequin simulating cough events and a portable air purifier autonomously responding to aerosols. The generated data from this emulator trains a digital twins model, combining a physics-based compartment model with a machine learning approach, using Long Short-Term Memory (LSTM) networks and graph convolution layers. Experimental results demonstrate the model's ability to predict aerosol concentration dynamics with a mean residence time prediction error within 35 seconds. The proposed system's real-time intervention strategies outperform static air filter placement, showcasing its potential in mitigating airborne pathogen risks.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": "Accepted at IEEE International Conference on Robotics and Automation (ICRA) 2025. Author Accepted Manuscript", "pdf_url": "https://arxiv.org/pdf/2508.02947.pdf", "abstract_url": "https://arxiv.org/abs/2508.02947", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "AeroSafe通过机器人咳嗽模拟器测试平台和基于数字孪生的气溶胶停留时间分析，提出了一种提高室内空气净化系统效能的新方法。", "motivation": "解决当前便携式空气过滤器忽视咳嗽产生的呼吸气溶胶浓度的问题，特别是在医疗设施和公共场所等高暴露环境中。", "method": "使用可操纵的人体模型模拟咳嗽事件和便携式空气净化器自主响应气溶胶的机器人双代理物理模拟器，结合基于物理的隔间模型和机器学习方法（LSTM网络和图卷积层）的数字孪生模型。", "result": "实验结果表明，该模型能够预测气溶胶浓度动态，平均停留时间预测误差在35秒以内。", "conclusion": "提出的系统实时干预策略优于静态空气过滤器放置，展示了其在减轻空气传播病原体风险方面的潜力。"}}
{"id": "2508.02956", "title": "Autonomous Inorganic Materials Discovery via Multi-Agent Physics-Aware Scientific Reasoning", "authors": ["Alireza Ghafarollahi", "Markus J. Buehler"], "abstract": "Conventional machine learning approaches accelerate inorganic materials design via accurate property prediction and targeted material generation, yet they operate as single-shot models limited by the latent knowledge baked into their training data. A central challenge lies in creating an intelligent system capable of autonomously executing the full inorganic materials discovery cycle, from ideation and planning to experimentation and iterative refinement. We introduce SparksMatter, a multi-agent AI model for automated inorganic materials design that addresses user queries by generating ideas, designing and executing experimental workflows, continuously evaluating and refining results, and ultimately proposing candidate materials that meet the target objectives. SparksMatter also critiques and improves its own responses, identifies research gaps and limitations, and suggests rigorous follow-up validation steps, including DFT calculations and experimental synthesis and characterization, embedded in a well-structured final report. The model's performance is evaluated across case studies in thermoelectrics, semiconductors, and perovskite oxides materials design. The results demonstrate the capacity of SparksMatter to generate novel stable inorganic structures that target the user's needs. Benchmarking against frontier models reveals that SparksMatter consistently achieves higher scores in relevance, novelty, and scientific rigor, with a significant improvement in novelty across multiple real-world design tasks as assessed by a blinded evaluator. These results demonstrate SparksMatter's unique capacity to generate chemically valid, physically meaningful, and creative inorganic materials hypotheses beyond existing materials knowledge.", "subjects": "Materials Science (cond-mat.mtrl-sci); Disordered Systems and Neural Networks (cond-mat.dis-nn); Mesoscale and Nanoscale Physics (cond-mat.mes-hall); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.02956.pdf", "abstract_url": "https://arxiv.org/abs/2508.02956", "categories": ["Materials Science (cond-mat.mtrl-sci)", "Disordered Systems and Neural Networks (cond-mat.dis-nn)", "Mesoscale and Nanoscale Physics (cond-mat.mes-hall)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "SparksMatter是一种多智能体AI模型，用于自动化无机材料设计，能够自主执行从构思到实验和迭代优化的全过程，生成符合目标的新型稳定无机结构。", "motivation": "解决传统机器学习方法在无机材料设计中作为单次模型、受限于训练数据中潜在知识的局限性，创建一个能够自主执行完整无机材料发现周期的智能系统。", "method": "引入SparksMatter，一个多智能体AI模型，通过生成想法、设计和执行实验工作流程、持续评估和优化结果，最终提出符合目标目标的候选材料。", "result": "SparksMatter在热电、半导体和钙钛矿氧化物材料设计的案例研究中表现出色，能够生成新颖稳定的无机结构，且在相关性、新颖性和科学严谨性方面 consistently 获得更高分数。", "conclusion": "SparksMatter展示了其独特的生成化学有效、物理意义明确且创造性无机材料假设的能力，超越了现有的材料知识。"}}
{"id": "2508.03012", "title": "Tool-integrated Reinforcement Learning for Repo Deep Search", "authors": ["Zexiong Ma", "Chao Peng", "Qunhong Zeng", "Pengfei Gao", "Yanzhen Zou", "Bing Xie"], "abstract": "Issue localization, the process of identifying code locations that need modification to resolve software issues, is a critical yet challenging task in software development. The semantic gap between natural language issue descriptions and faulty code requires complex multi-hop reasoning through code dependencies. Existing LLM-based agents attempt to address this by integrating repository retrieval tools. However, this transforms issue localization into a demanding task we call Repo Deep Search, which requires the LLM to effectively utilize various repository retrieval tools throughout a multi-step reasoning and navigation process. To tackle this challenge, we present ToolTrain, a two-stage tool-integrated training framework combining rejection-sampled supervised fine-tuning and tool-integrated reinforcement learning to enhance LLMs' ability to use retrieval tools for issue localization. Experimental results show that ToolTrain-trained models achieve state-of-the-art performance, with our 32B model even surpassing Claude-3.7 on function-level localization. The results also show that improved localization performance translates to better end-to-end issue resolution performance. This further demonstrates that training for issue localization is a viable and effective strategy for improving automated software development.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.03012.pdf", "abstract_url": "https://arxiv.org/abs/2508.03012", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了ToolTrain，一个两阶段的工具集成训练框架，旨在通过结合拒绝采样的监督微调和工具集成的强化学习，提升大型语言模型（LLMs）在问题定位中使用检索工具的能力。实验结果显示，ToolTrain训练的模型在功能级定位上达到了最先进的性能，甚至超过了Claude-3.7。", "motivation": "问题定位是软件开发中一个关键但具有挑战性的任务，现有基于LLM的代理通过集成仓库检索工具尝试解决这一问题，但将问题定位转化为一个名为Repo Deep Search的高要求任务。", "method": "提出了ToolTrain，一个两阶段的工具集成训练框架，结合拒绝采样的监督微调和工具集成的强化学习，以增强LLMs使用检索工具进行问题定位的能力。", "result": "ToolTrain训练的模型在功能级定位上达到了最先进的性能，32B模型甚至超过了Claude-3.7。改进的定位性能也转化为更好的端到端问题解决性能。", "conclusion": "训练用于问题定位是提高自动化软件开发的一个可行且有效的策略。"}}
{"id": "2508.03053", "title": "SkeNa: Learning to Navigate Unseen Environments Based on Abstract Hand-Drawn Maps", "authors": ["Haojun Xu", "Jiaqi Xiang", "Wu Wei", "Jinyu Chen", "Linqing Zhong", "Linjiang Huang", "Hongyu Yang", "Si Liu"], "abstract": "A typical human strategy for giving navigation guidance is to sketch route maps based on the environmental layout. Inspired by this, we introduce Sketch map-based visual Navigation (SkeNa), an embodied navigation task in which an agent must reach a goal in an unseen environment using only a hand-drawn sketch map as guidance. To support research for SkeNa, we present a large-scale dataset named SoR, comprising 54k trajectory and sketch map pairs across 71 indoor scenes. In SoR, we introduce two navigation validation sets with varying levels of abstraction in hand-drawn sketches, categorized based on their preservation of spatial scales in the environment, to facilitate future research. To construct SoR, we develop an automated sketch-generation pipeline that efficiently converts floor plans into hand-drawn representations. To solve SkeNa, we propose SkeNavigator, a navigation framework that aligns visual observations with hand-drawn maps to estimate navigation targets. It employs a Ray-based Map Descriptor (RMD) to enhance sketch map valid feature representation using equidistant sampling points and boundary distances. To improve alignment with visual observations, a Dual-Map Aligned Goal Predictor (DAGP) leverages the correspondence between sketch map features and on-site constructed exploration map features to predict goal position and guide navigation. SkeNavigator outperforms prior floor plan navigation methods by a large margin, improving SPL on the high-abstract validation set by 105% relatively. Our code and dataset will be released.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": "9 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2508.03053.pdf", "abstract_url": "https://arxiv.org/abs/2508.03053", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了SkeNa，一种基于手绘草图地图的视觉导航任务，旨在让代理在未见过的环境中仅依靠手绘地图到达目标。为此，作者提出了一个名为SoR的大规模数据集，包含54k轨迹和草图地图对，并开发了SkeNavigator导航框架，该框架通过视觉观察与手绘地图的对齐来估计导航目标，显著提高了导航性能。", "motivation": "受人类通过绘制路线草图提供导航指引的策略启发，本文旨在解决在未见过的环境中仅依靠手绘草图地图进行导航的问题。", "method": "本文提出了SkeNavigator导航框架，包括Ray-based Map Descriptor (RMD)用于增强草图地图的有效特征表示，以及Dual-Map Aligned Goal Predictor (DAGP)用于利用草图地图特征与现场构建的探索地图特征之间的对应关系来预测目标位置并指导导航。", "result": "SkeNavigator在高层抽象验证集上的SPL相对提高了105%，显著优于之前的地图导航方法。", "conclusion": "本文通过引入SkeNa任务和SoR数据集，以及开发SkeNavigator框架，为基于手绘草图地图的视觉导航研究提供了新的方向和工具，展示了在未见过的环境中仅依靠手绘地图进行导航的可行性。"}}
{"id": "2508.03095", "title": "A Survey of AI Agent Registry Solutions", "authors": ["Aditi Singh", "Abul Ehtesham", "Ramesh Raskar", "Mahesh Lambe", "Pradyumna Chari", "Jared James Grogan", "Abhishek Singh", "Saket Kumar"], "abstract": "As As autonomous AI agents scale across cloud, enterprise, and decentralized environments, the need for standardized registry systems to support discovery, identity, and capability sharing has become essential. This paper surveys three prominent registry approaches each defined by a unique metadata model: MCP's", "subjects": "Networking and Internet Architecture (cs.NI); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.03095.pdf", "abstract_url": "https://arxiv.org/abs/2508.03095", "categories": ["Networking and Internet Architecture (cs.NI)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文综述了三种主要的AI代理注册解决方案，每种方案都有其独特的元数据模型，旨在支持在云、企业和去中心化环境中扩展的自主AI代理的发现、身份和能力共享。", "motivation": "随着自主AI代理在云、企业和去中心化环境中的扩展，支持发现、身份和能力共享的标准化注册系统变得至关重要。", "method": "本文调查了三种主要的注册方法，每种方法都定义了一个独特的元数据模型。", "result": "综述了三种主要的AI代理注册解决方案，每种方案都有其独特的元数据模型。", "conclusion": "标准化注册系统对于支持自主AI代理的扩展至关重要，本文综述的三种方法为此提供了基础。"}}
{"id": "2508.03101", "title": "Using the NANDA Index Architecture in Practice: An Enterprise Perspective", "authors": ["Sichao Wang", "Ramesh Raskar", "Mahesh Lambe", "Pradyumna Chari", "Rekha Singhal", "Shailja Gupta", "Rajesh Ranjan", "Ken Huang"], "abstract": "The proliferation of autonomous AI agents represents a paradigmatic shift from traditional web architectures toward collaborative intelligent systems requiring sophisticated mechanisms for discovery, authentication, capability verification, and secure collaboration across heterogeneous protocol environments. This paper presents a comprehensive framework addressing the fundamental infrastructure requirements for secure, trustworthy, and interoperable AI agent ecosystems. We introduce the NANDA (Networked AI Agents in a Decentralized Architecture) framework, providing global agent discovery, cryptographically verifiable capability attestation through AgentFacts, and cross-protocol interoperability across Anthropic's Modal Context Protocol (MCP), Google's Agent-to-Agent (A2A), Microsoft's NLWeb, and standard HTTPS communications. NANDA implements Zero Trust Agentic Access (ZTAA) principles, extending traditional Zero Trust Network Access (ZTNA) to address autonomous agent security challenges including capability spoofing, impersonation attacks, and sensitive data leakage. The framework defines Agent Visibility and Control (AVC) mechanisms enabling enterprise governance while maintaining operational autonomy and regulatory compliance. Our approach transforms isolated AI agents into an interconnected ecosystem of verifiable, trustworthy intelligent services, establishing foundational infrastructure for large-scale autonomous agent deployment across enterprise and consumer environments. This work addresses the critical gap between current AI agent capabilities and infrastructure requirements for secure, scalable, multi-agent collaboration, positioning the foundation for next-generation autonomous intelligent systems.", "subjects": "Networking and Internet Architecture (cs.NI); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.03101.pdf", "abstract_url": "https://arxiv.org/abs/2508.03101", "categories": ["Networking and Internet Architecture (cs.NI)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了NANDA框架，旨在解决自主AI代理在发现、认证、能力验证和安全协作方面的基础设施需求，支持跨协议互操作性，并实施零信任代理访问原则，以构建安全、可信的AI代理生态系统。", "motivation": "随着自主AI代理的激增，传统的网络架构已无法满足协作智能系统在发现、认证、能力验证和安全协作方面的需求，尤其是在异构协议环境中。", "method": "提出了NANDA框架，包括全球代理发现、通过AgentFacts进行密码学可验证的能力证明、跨协议互操作性，以及实施零信任代理访问（ZTAA）原则。", "result": "NANDA框架能够将孤立的AI代理转变为可验证、可信的智能服务互联生态系统，为大规模自主代理部署提供了基础设施。", "conclusion": "该工作填补了当前AI代理能力与安全、可扩展的多代理协作基础设施需求之间的关键空白，为下一代自主智能系统奠定了基础。"}}
{"id": "2508.03113", "title": "NANDA Adaptive Resolver: Architecture for Dynamic Resolution of AI Agent Names", "authors": ["John Zinky", "Hema Seshadri", "Mahesh Lambe", "Pradyumna Chari", "Ramesh Raskar"], "abstract": "AdaptiveResolver is a dynamic microservice architecture designed to address the limitations of static endpoint resolution for AI agent communication in distributed, heterogeneous environments. Unlike traditional DNS or static URLs, AdaptiveResolver enables context-aware, real-time selection of communication endpoints based on factors such as geographic location, system load, agent capabilities, and security threats. Agents advertise their Agent Name and context requirements through Agent Fact cards in an Agent Registry/Index. A requesting Agent discovers a Target Agent using the registry. The Requester Agent can then resolve the Target Agent Name to obtain a tailored communication channel to the agent based on actual environmental context between the agents. The architecture supports negotiation of trust, quality of service, and resource constraints, facilitating flexible, secure, and scalable agent-to-agent interactions that go beyond the classic client-server model. AdaptiveResolver provides a foundation for robust, future-proof agent communication that can evolve with increasing ecosystem complexity.", "subjects": "Networking and Internet Architecture (cs.NI); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.03113.pdf", "abstract_url": "https://arxiv.org/abs/2508.03113", "categories": ["Networking and Internet Architecture (cs.NI)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "NANDA Adaptive Resolver是一种动态微服务架构，旨在解决分布式异构环境中AI代理通信静态端点解析的限制。", "motivation": "解决传统DNS或静态URL在AI代理通信中的局限性，特别是在动态、异构环境下的端点解析问题。", "method": "通过Agent Registry/Index中的Agent Fact卡片，代理可以广告其名称和上下文需求，请求代理可以发现目标代理并基于实际环境上下文解析目标代理名称，以获得定制的通信通道。", "result": "AdaptiveResolver支持信任、服务质量和资源约束的协商，促进了超越经典客户端-服务器模型的灵活、安全和可扩展的代理间交互。", "conclusion": "AdaptiveResolver为强大、面向未来的代理通信提供了基础，能够随着生态系统复杂性的增加而进化。"}}
{"id": "2508.03125", "title": "Attack the Messages, Not the Agents: A Multi-round Adaptive Stealthy Tampering Framework for LLM-MAS", "authors": ["Bingyu Yan", "Ziyi Zhou", "Xiaoming Zhang", "Chaozhuo Li", "Ruilin Zeng", "Yirui Qi", "Tianbo Wang", "Litian Zhang"], "abstract": "Large language model-based multi-agent systems (LLM-MAS) effectively accomplish complex and dynamic tasks through inter-agent communication, but this reliance introduces substantial safety vulnerabilities. Existing attack methods targeting LLM-MAS either compromise agent internals or rely on direct and overt persuasion, which limit their effectiveness, adaptability, and stealthiness. In this paper, we propose MAST, a Multi-round Adaptive Stealthy Tampering framework designed to exploit communication vulnerabilities within the system. MAST integrates Monte Carlo Tree Search with Direct Preference Optimization to train an attack policy model that adaptively generates effective multi-round tampering strategies. Furthermore, to preserve stealthiness, we impose dual semantic and embedding similarity constraints during the tampering process. Comprehensive experiments across diverse tasks, communication architectures, and LLMs demonstrate that MAST consistently achieves high attack success rates while significantly enhancing stealthiness compared to baselines. These findings highlight the effectiveness, stealthiness, and adaptability of MAST, underscoring the need for robust communication safeguards in LLM-MAS.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.03125.pdf", "abstract_url": "https://arxiv.org/abs/2508.03125", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了MAST框架，一种针对基于大型语言模型的多智能体系统（LLM-MAS）通信漏洞的多轮自适应隐蔽篡改攻击方法。MAST通过结合蒙特卡洛树搜索和直接偏好优化来训练攻击策略模型，以生成有效的多轮篡改策略，并通过双重语义和嵌入相似性约束保持隐蔽性。实验表明，MAST在多种任务、通信架构和LLM中均能实现高攻击成功率，同时显著提升隐蔽性。", "motivation": "大型语言模型基于的多智能体系统（LLM-MAS）通过智能体间通信有效完成复杂动态任务，但这种依赖性也引入了重大的安全漏洞。现有的攻击方法要么损害智能体内部，要么依赖于直接和公开的说服，限制了其效果、适应性和隐蔽性。", "method": "MAST框架整合了蒙特卡洛树搜索与直接偏好优化，训练攻击策略模型以自适应生成有效的多轮篡改策略，并通过双重语义和嵌入相似性约束保持攻击的隐蔽性。", "result": "在多样化的任务、通信架构和LLM上的综合实验表明，MAST能够一致地实现高攻击成功率，同时在隐蔽性上显著优于基线方法。", "conclusion": "MAST的有效性、隐蔽性和适应性凸显了在LLM-MAS中实施强大通信保护措施的必要性。"}}
{"id": "2508.03216", "title": "Navigation Pixie: Implementation and Empirical Study Toward On-demand Navigation Agents in Commercial Metaverse", "authors": ["Hikari Yanagawa", "Yuichi Hiroi", "Satomi Tokida", "Yuji Hatada", "Takefumi Hiraki"], "abstract": "While commercial metaverse platforms offer diverse user-generated content, they lack effective navigation assistance that can dynamically adapt to users' interests and intentions. Although previous research has investigated on-demand agents in controlled environments, implementation in commercial settings with diverse world configurations and platform constraints remains challenging.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": "11 pages + supplement 3 pages. To appear in IEEE ISMAR 2025", "pdf_url": "https://arxiv.org/pdf/2508.03216.pdf", "abstract_url": "https://arxiv.org/abs/2508.03216", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了‘Navigation Pixie’的实现及实证研究，旨在为商业元宇宙中的用户提供按需导航代理，动态适应用户的兴趣和意图。", "motivation": "商业元宇宙平台虽然提供了多样化的用户生成内容，但缺乏能够动态适应用户兴趣和意图的有效导航辅助。", "method": "研究在商业环境中实现按需导航代理，克服了多样化的世界配置和平台限制带来的挑战。", "result": "通过实证研究，证明了在商业元宇宙中实现动态适应导航代理的可行性。", "conclusion": "Navigation Pixie为商业元宇宙中的导航提供了新的解决方案，有望提升用户体验和平台互动性。"}}
{"id": "2508.03153", "title": "Estimating Worst-Case Frontier Risks of Open-Weight LLMs", "authors": ["Eric Wallace", "Olivia Watkins", "Miles Wang", "Kai Chen", "Chris Koch"], "abstract": "In this paper, we study the worst-case frontier risks of releasing gpt-oss. We introduce malicious fine-tuning (MFT), where we attempt to elicit maximum capabilities by fine-tuning gpt-oss to be as capable as possible in two domains: biology and cybersecurity. To maximize biological risk (biorisk), we curate tasks related to threat creation and train gpt-oss in an RL environment with web browsing. To maximize cybersecurity risk, we train gpt-oss in an agentic coding environment to solve capture-the-flag (CTF) challenges. We compare these MFT models against open- and closed-weight LLMs on frontier risk evaluations. Compared to frontier closed-weight models, MFT gpt-oss underperforms OpenAI o3, a model that is below Preparedness High capability level for biorisk and cybersecurity. Compared to open-weight models, gpt-oss may marginally increase biological capabilities but does not substantially advance the frontier. Taken together, these results contributed to our decision to release the model, and we hope that our MFT approach can serve as useful guidance for estimating harm from future open-weight releases.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.03153.pdf", "abstract_url": "https://arxiv.org/abs/2508.03153", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文研究了发布gpt-oss的最坏情况前沿风险，通过恶意微调（MFT）方法在生物学和网络安全领域最大化其能力，并与开放和封闭权重的大型语言模型（LLM）进行了比较。结果表明，MFT gpt-oss在生物风险和网络安全方面的表现低于前沿封闭权重模型，且对开放权重模型的生物能力提升有限。这些结果支持了发布该模型的决策，并希望MFT方法能为未来开放权重发布的危害评估提供指导。", "motivation": "研究发布gpt-oss可能带来的最坏情况前沿风险，特别是在生物学和网络安全领域，以评估开放权重大型语言模型（LLM）的潜在危害。", "method": "采用恶意微调（MFT）方法，在生物学领域通过威胁创建相关任务和网络浏览的RL环境训练gpt-oss，在网络安全领域通过代理编码环境和CTF挑战训练gpt-oss，然后与开放和封闭权重的LLM进行比较。", "result": "与前沿封闭权重模型相比，MFT gpt-oss在生物风险和网络安全方面的表现较差；与开放权重模型相比，gpt-oss对生物能力的提升有限，未显著推进前沿。", "conclusion": "研究结果支持了发布gpt-oss的决策，并表明MFT方法可用于评估未来开放权重LLM发布的潜在危害。"}}
{"id": "2508.03253", "title": "Approximate Proportionality in Online Fair Division", "authors": ["Davin Choo", "Winston Fu", "Derek Khu", "Tzeh Yuan Neoh", "Tze-Yang Poon", "Nicholas Teh"], "abstract": "We study the online fair division problem, where indivisible goods arrive sequentially and must be allocated immediately and irrevocably to agents. Prior work has established strong impossibility results for approximating classic fairness notions, such as envy-freeness and maximin share fairness, in this setting. In contrast, we focus on proportionality up to one good (PROP1), a natural relaxation of proportionality whose approximability remains unresolved. We begin by showing that three natural greedy algorithms fail to guarantee any positive approximation to PROP1 in general, against an adaptive adversary. This is surprising because greedy algorithms are commonly used in fair division and a natural greedy algorithm is known to be able to achieve PROP1 under additional information assumptions. This hardness result motivates the study of non-adaptive adversaries and the use of side-information, in the spirit of learning-augmented algorithms. For non-adaptive adversaries, we show that the simple uniformly random allocation can achieve a meaningful PROP1 approximation with high probability. Meanwhile, we present an algorithm that obtain robust approximation ratios against PROP1 when given predictions of the maximum item value (MIV). Interestingly, we also show that stronger fairness notions such as EF1, MMS, and PROPX remain inapproximable even with perfect MIV predictions.", "subjects": "Computer Science and Game Theory (cs.GT); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.03253.pdf", "abstract_url": "https://arxiv.org/abs/2508.03253", "categories": ["Computer Science and Game Theory (cs.GT)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究了在线公平分割问题，重点关注了一种称为“比例性至多一件物品”（PROP1）的公平性概念。研究发现，三种常见的贪心算法在面对适应性对手时无法保证任何正面的PROP1近似，这促使了对非适应性对手和额外信息使用的研究。对于非适应性对手，简单的均匀随机分配可以高概率实现有意义的PROP1近似。同时，当给定最大物品价值（MIV）的预测时，提出了一个能够获得稳健PROP1近似比的算法。有趣的是，研究还表明，即使有完美的MIV预测，更强的公平性概念如EF1、MMS和PROPX仍然无法近似。", "motivation": "解决在线公平分割问题中，如何在物品依次到达且必须立即不可撤销地分配给代理人的情况下，近似实现PROP1公平性的挑战。", "method": "研究了贪心算法在适应性对手下的表现，探索了非适应性对手和额外信息（如MIV预测）的使用，提出了均匀随机分配和基于MIV预测的算法。", "result": "贪心算法在适应性对手下无法保证PROP1近似；均匀随机分配对非适应性对手能高概率实现PROP1近似；基于MIV预测的算法能获得稳健的PROP1近似比；更强的公平性概念即使有完美MIV预测也无法近似。", "conclusion": "研究表明，通过适当的信息假设和算法设计，可以在在线公平分割问题中实现PROP1的近似，但更强的公平性概念仍面临根本性挑战。"}}
{"id": "2508.03393", "title": "Agentic AI in 6G Software Businesses: A Layered Maturity Model", "authors": ["Muhammad Zohaib", "Muhammad Azeem Akbar", "Sami Hyrynsalmi", "Arif Ali Khan"], "abstract": "The emergence of agentic AI systems in 6G software businesses presents both strategic opportunities and significant challenges. While such systems promise increased autonomy, scalability, and intelligent decision-making across distributed environments, their adoption raises concerns regarding technical immaturity, integration complexity, organizational readiness, and performance-cost trade-offs. In this study, we conducted a preliminary thematic mapping to identify factors influencing the adoption of agentic software within the context of 6G. Drawing on a multivocal literature review and targeted scanning, we identified 29 motivators and 27 demotivators, which were further categorized into five high-level themes in each group. This thematic mapping offers a structured overview of the enabling and inhibiting forces shaping organizational readiness for agentic transformation. Positioned as a feasibility assessment, the study represents an early phase of a broader research initiative aimed at developing and validating a layered maturity model grounded in CMMI model with the software architectural three dimensions possibly Data, Business Logic, and Presentation. Ultimately, this work seeks to provide a practical framework to help software-driven organizations assess, structure, and advance their agent-first capabilities in alignment with the demands of 6G.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": "6 pages, 3 figures and FIT'25 Conference", "pdf_url": "https://arxiv.org/pdf/2508.03393.pdf", "abstract_url": "https://arxiv.org/abs/2508.03393", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文探讨了6G软件业务中代理性AI系统的战略机遇与挑战，通过主题映射识别了影响采用的因素，并提出了一个基于CMMI模型的分层成熟度模型框架。", "motivation": "解决6G软件业务中代理性AI系统采用过程中的技术不成熟、集成复杂性、组织准备度及性能成本权衡等问题。", "method": "通过多声部文献综述和针对性扫描，识别了29个激励因素和27个抑制因素，并将其分类为五个高级主题。", "result": "提出了一个分层的成熟度模型，旨在帮助软件驱动型组织评估、构建和提升其代理优先能力。", "conclusion": "本研究为6G时代的软件业务提供了一个实用的框架，以促进代理性AI系统的有效采用和发展。"}}
{"id": "2508.03329", "title": "Industrial LLM-based Code Optimization under Regulation: A Mixture-of-Agents Approach", "authors": ["Mari Ashiga", "Vardan Voskanyan", "Fateme Dinmohammadi", "Jingzhi Gong", "Paul Brookes", "Matthew Truscott", "Rafail Giavrimis", "Mike Basios", "Leslie Kanthan", "Wei Jie"], "abstract": "Recent advancements in Large Language Models (LLMs) for code optimization have enabled industrial platforms to automate software performance engineering at unprecedented scale and speed. Yet, organizations in regulated industries face strict constraints on which LLMs they can use - many cannot utilize commercial models due to data privacy regulations and compliance requirements, creating a significant challenge for achieving high-quality code optimization while maintaining cost-effectiveness. We address this by implementing a Mixture-of-Agents (MoA) approach that directly synthesizes code from multiple specialized LLMs, comparing it against TurinTech AI's vanilla Genetic Algorithm (GA)-based ensemble system and individual LLM optimizers using real-world industrial codebases. Our key contributions include: (1) First MoA application to industrial code optimization using real-world codebases; (2) Empirical evidence that MoA excels with open-source models, achieving 14.3% to 22.2% cost savings and 28.6% to 32.2% faster optimization times for regulated environments; (3) Deployment guidelines demonstrating GA's advantage with commercial models while both ensembles outperform individual LLMs; and (4) Real-world validation across 50 code snippets and seven LLM combinations, generating over 8,700 variants, addresses gaps in industrial LLM ensemble evaluation. This provides actionable guidance for organizations balancing regulatory compliance with optimization performance in production environments.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": "Submitted to ASE'25 Industry Showcase", "pdf_url": "https://arxiv.org/pdf/2508.03329.pdf", "abstract_url": "https://arxiv.org/abs/2508.03329", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于混合代理（MoA）的方法，用于在受监管的工业环境中实现代码优化，通过结合多个专门的大型语言模型（LLMs）来合成代码，与传统的遗传算法（GA）和单个LLM优化器相比，展示了更高的效率和成本效益。", "motivation": "受监管行业在利用大型语言模型（LLMs）进行代码优化时面临数据隐私和合规性要求的限制，这影响了使用商业模型的能力，从而在保持成本效益的同时实现高质量代码优化成为挑战。", "method": "采用混合代理（MoA）方法，直接合成来自多个专门LLMs的代码，并与TurinTech AI的基于遗传算法（GA）的集成系统及单个LLM优化器进行比较。", "result": "MoA在使用开源模型时表现出色，实现了14.3%至22.2%的成本节约和28.6%至32.2%的优化时间缩短；同时，GA在商业模型中表现优势，两种集成方法均优于单个LLMs。", "conclusion": "本研究为在保持监管合规性的同时优化生产环境中的代码性能提供了可行的指导，通过在实际工业代码库上的验证，填补了工业LLM集成评估的空白。"}}
{"id": "2508.03651", "title": "Probing the Gaps in ChatGPT Live Video Chat for Real-World Assistance for People who are Blind or Visually Impaired", "authors": ["Ruei-Che Chang", "Rosiana Natalie", "Wenqian Xu", "Jovan Zheng Feng Yap", "Anhong Guo"], "abstract": "Recent advancements in large multimodal models have provided blind or visually impaired (BVI) individuals with new capabilities to interpret and engage with the real world through interactive systems that utilize live video feeds. However, the potential benefits and challenges of such capabilities to support diverse real-world assistive tasks remain unclear. In this paper, we present findings from an exploratory study with eight BVI participants. Participants used ChatGPT's Advanced Voice with Video, a state-of-the-art live video AI released in late 2024, in various real-world scenarios, from locating objects to recognizing visual landmarks, across unfamiliar indoor and outdoor environments. Our findings indicate that current live video AI effectively provides guidance and answers for static visual scenes but falls short in delivering essential live descriptions required in dynamic situations. Despite inaccuracies in spatial and distance information, participants leveraged the provided visual information to supplement their mobility strategies. Although the system was perceived as human-like due to high-quality voice interactions, assumptions about users' visual abilities, hallucinations, generic responses, and a tendency towards sycophancy led to confusion, distrust, and potential risks for BVI users. Based on the results, we discuss implications for assistive video AI agents, including incorporating additional sensing capabilities for real-world use, determining appropriate intervention timing beyond turn-taking interactions, and addressing ecological and safety concerns.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": "ACM ASSETS 2025", "pdf_url": "https://arxiv.org/pdf/2508.03651.pdf", "abstract_url": "https://arxiv.org/abs/2508.03651", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "探讨了ChatGPT高级语音与视频功能在帮助盲人或视觉障碍者（BVI）进行实时世界辅助任务中的潜力与挑战。研究发现，当前技术在处理静态视觉场景时有效，但在动态情境中提供必要实时描述方面存在不足。", "motivation": "解决大型多模态模型在支持盲人或视觉障碍者进行多样化现实世界辅助任务中的潜在益处和挑战。", "method": "通过八位BVI参与者的探索性研究，使用ChatGPT的高级语音与视频功能在不同现实场景中进行测试。", "result": "当前实时视频AI在静态视觉场景中有效，但在动态情境中提供实时描述方面不足。尽管存在空间和距离信息的不准确，参与者仍利用提供的视觉信息补充其移动策略。", "conclusion": "讨论了辅助视频AI代理的潜在改进方向，包括增加现实世界使用的额外感知能力、确定超越轮流交互的适当干预时机，以及解决生态和安全问题。"}}
{"id": "2508.03665", "title": "A DbC Inspired Neurosymbolic Layer for Trustworthy Agent Design", "authors": ["Claudiu Leoveanu-Condrei"], "abstract": "Generative models, particularly Large Language Models (LLMs), produce fluent outputs yet lack verifiable guarantees. We adapt Design by Contract (DbC) and type-theoretic principles to introduce a contract layer that mediates every LLM call. Contracts stipulate semantic and type requirements on inputs and outputs, coupled with probabilistic remediation to steer generation toward compliance. The layer exposes the dual view of LLMs as semantic parsers and probabilistic black-box components. Contract satisfaction is probabilistic and semantic validation is operationally defined through programmer-specified conditions on well-typed data structures. More broadly, this work postulates that any two agents satisfying the same contracts are \\emph{functionally equivalent} with respect to those contracts.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "3 pages, 1 figure", "pdf_url": "https://arxiv.org/pdf/2508.03665.pdf", "abstract_url": "https://arxiv.org/abs/2508.03665", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种受设计契约（DbC）启发的神经符号层，旨在为生成模型（特别是大型语言模型LLMs）提供可验证的保证。通过引入一个契约层来调解每个LLM调用，该层规定了输入和输出的语义和类型要求，并结合概率性补救措施以引导生成符合要求。", "motivation": "生成模型，尤其是大型语言模型（LLMs），虽然能够产生流畅的输出，但缺乏可验证的保证。本文旨在解决这一问题，通过引入设计契约（DbC）和类型理论原则，为LLMs提供一个可验证的契约层。", "method": "本文采用设计契约（DbC）和类型理论原则，引入一个契约层来调解每个LLM调用。该契约层规定了输入和输出的语义和类型要求，并通过概率性补救措施来引导生成符合要求。", "result": "提出的契约层能够概率性地满足契约要求，并通过程序员指定的条件在良好类型的数据结构上操作定义语义验证。更广泛地说，任何满足相同契约的两个代理在这些契约下都是功能等效的。", "conclusion": "本文的工作为生成模型提供了一种新的可验证保证方法，通过引入契约层和概率性补救措施，使得LLMs的输出更加可靠和可信。此外，本文还提出了任何满足相同契约的两个代理在这些契约下都是功能等效的广泛观点。"}}
