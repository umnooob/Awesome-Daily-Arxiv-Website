{"id": "2508.05852", "title": "VISTA: Vision-Language Imitation of Situational Thinking and Attention for Human-Like Driver Focus in Dynamic Environments", "authors": ["Kaiser Hamid", "Khandakar Ashrafi Akbar", "Nade Liang"], "abstract": "Driver visual attention prediction is a critical task in autonomous driving and human-computer interaction (HCI) research. Most prior studies focus on estimating attention allocation at a single moment in time, typically using static RGB images such as driving scene pictures. In this work, we propose a vision-language framework that models the changing landscape of drivers' gaze through natural language, using few-shot and zero-shot learning on single RGB images. We curate and refine high-quality captions from the BDD-A dataset using human-in-the-loop feedback, then fine-tune LLaVA to align visual perception with attention-centric scene understanding. Our approach integrates both low-level cues and top-down context (e.g., route semantics, risk anticipation), enabling language-based descriptions of gaze behavior. We evaluate performance across training regimes (few shot, and one-shot) and introduce domain-specific metrics for semantic alignment and response diversity. Results show that our fine-tuned model outperforms general-purpose VLMs in attention shift detection and interpretability. To our knowledge, this is among the first attempts to generate driver visual attention allocation and shifting predictions in natural language, offering a new direction for explainable AI in autonomous driving. Our approach provides a foundation for downstream tasks such as behavior forecasting, human-AI teaming, and multi-agent coordination.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.05852.pdf", "abstract_url": "https://arxiv.org/abs/2508.05852", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种视觉-语言框架VISTA，用于模拟驾驶员在动态环境中的视觉注意力变化，通过自然语言描述实现对人眼注视行为的预测。", "motivation": "解决自动驾驶和人机交互研究中，现有方法多基于静态图像预测驾驶员注意力分配，难以捕捉动态环境中注意力变化的问题。", "method": "利用BDD-A数据集中的高质量标注，通过人类反馈进行优化，并微调LLaVA模型，将视觉感知与以注意力为中心的场景理解对齐，结合低级线索和自上而下的上下文信息。", "result": "微调后的模型在注意力转移检测和可解释性方面优于通用视觉语言模型，且在少样本和单样本训练制度下表现良好。", "conclusion": "该研究为自动驾驶中的可解释AI提供了新方向，为行为预测、人-AI协作和多智能体协调等下游任务奠定了基础。"}}
{"id": "2508.05843", "title": "Discovering Properties of Inflectional Morphology in Neural Emergent Communication", "authors": ["Miles Gilberti", "Shane Storks", "Huteng Dai"], "abstract": "Emergent communication (EmCom) with deep neural network-based agents promises to yield insights into the nature of human language, but remains focused primarily on a few subfield-specific goals and metrics that prioritize communication schemes which represent attributes with unique characters one-to-one and compose them syntactically. We thus reinterpret a common EmCom setting, the attribute-value reconstruction game, by imposing a small-vocabulary constraint to simulate double articulation, and formulating a novel setting analogous to naturalistic inflectional morphology (enabling meaningful comparison to natural language communication schemes). We develop new metrics and explore variations of this game motivated by real properties of inflectional morphology: concatenativity and fusionality. Through our experiments, we discover that simulated phonological constraints encourage concatenative morphology, and emergent languages replicate the tendency of natural languages to fuse grammatical attributes.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.05843.pdf", "abstract_url": "https://arxiv.org/abs/2508.05843", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过重新解释常见的EmCom设置，即属性-值重建游戏，通过施加小词汇量约束来模拟双重发音，并制定了一个类似于自然屈折形态的新设置，以探索神经涌现通信中屈折形态的属性。", "motivation": "解决当前涌现通信（EmCom）研究主要集中在少数子领域特定目标和指标上的问题，这些目标和指标优先考虑用独特字符一对一表示属性并通过句法组合它们的通信方案。", "method": "通过施加小词汇量约束模拟双重发音，并制定一个类似于自然屈折形态的新设置，开发新的指标并探索由屈折形态的真实属性（连接性和融合性）驱动的游戏变体。", "result": "实验发现，模拟的音韵约束鼓励连接性形态，涌现语言复制了自然语言融合语法属性的趋势。", "conclusion": "本文的发现为理解人类语言的本质提供了新的视角，特别是在屈折形态方面，展示了神经涌现通信模拟自然语言特性的潜力。"}}
{"id": "2508.05731", "title": "InfiGUI-G1: Advancing GUI Grounding with Adaptive Exploration Policy Optimization", "authors": ["Yuhang Liu", "Zeyu Liu", "Shuanghe Zhu", "Pengxiang Li", "Congkai Xie", "Jiasheng Wang", "Xueyu Hu", "Xiaotian Han", "Jianbo Yuan", "Xinyao Wang", "Shengyu Zhang", "Hongxia Yang", "Fei Wu"], "abstract": "The emergence of Multimodal Large Language Models (MLLMs) has propelled the development of autonomous agents that operate on Graphical User Interfaces (GUIs) using pure visual input. A fundamental challenge is robustly grounding natural language instructions. This requires a precise spatial alignment, which accurately locates the coordinates of each element, and, more critically, a correct semantic alignment, which matches the instructions to the functionally appropriate UI element. Although Reinforcement Learning with Verifiable Rewards (RLVR) has proven to be effective at improving spatial alignment for these MLLMs, we find that inefficient exploration bottlenecks semantic alignment, which prevent models from learning difficult semantic associations. To address this exploration problem, we present Adaptive Exploration Policy Optimization (AEPO), a new policy optimization framework. AEPO employs a multi-answer generation strategy to enforce broader exploration, which is then guided by a theoretically grounded Adaptive Exploration Reward (AER) function derived from first principles of efficiency eta=U/C. Our AEPO-trained models, InfiGUI-G1-3B and InfiGUI-G1-7B, establish new state-of-the-art results across multiple challenging GUI grounding benchmarks, achieving significant relative improvements of up to 9.0% against the naive RLVR baseline on benchmarks designed to test generalization and semantic understanding. Resources are available at", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "11 pages, 3 figures", "pdf_url": "https://arxiv.org/pdf/2508.05731.pdf", "abstract_url": "https://arxiv.org/abs/2508.05731", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了InfiGUI-G1，一种通过自适应探索策略优化（AEPO）提升图形用户界面（GUI）基础的新方法，特别是在多模态大语言模型（MLLMs）中，通过增强空间和语义对齐来改进自然语言指令的基础。", "motivation": "解决在多模态大语言模型中，图形用户界面（GUI）基础的自然语言指令在空间和语义对齐上的挑战，特别是语义对齐因探索效率低下而受限的问题。", "method": "提出了自适应探索策略优化（AEPO）框架，采用多答案生成策略以强制更广泛的探索，并通过理论上基于效率第一原则的自适应探索奖励（AER）函数来引导。", "result": "InfiGUI-G1-3B和InfiGUI-G1-7B模型在多个具有挑战性的GUI基础基准测试中建立了新的最先进成果，相对于简单的RLVR基线，在测试泛化和语义理解的基准上实现了高达9.0%的相对改进。", "conclusion": "AEPO框架有效解决了MLLMs在GUI基础中的探索效率问题，显著提升了模型的空间和语义对齐能力，为未来的自主代理开发提供了新的方向。"}}
{"id": "2508.05766", "title": "A Framework for Inherently Safer AGI through Language-Mediated Active Inference", "authors": ["Bo Wen"], "abstract": "This paper proposes a novel framework for developing safe Artificial General Intelligence (AGI) by combining Active Inference principles with Large Language Models (LLMs). We argue that traditional approaches to AI safety, focused on post-hoc interpretability and reward engineering, have fundamental limitations. We present an architecture where safety guarantees are integrated into the system's core design through transparent belief representations and hierarchical value alignment. Our framework leverages natural language as a medium for representing and manipulating beliefs, enabling direct human oversight while maintaining computational tractability. The architecture implements a multi-agent system where agents self-organize according to Active Inference principles, with preferences and safety constraints flowing through hierarchical Markov blankets. We outline specific mechanisms for ensuring safety, including: (1) explicit separation of beliefs and preferences in natural language, (2) bounded rationality through resource-aware free energy minimization, and (3) compositional safety through modular agent structures. The paper concludes with a research agenda centered on the Abstraction and Reasoning Corpus (ARC) benchmark, proposing experiments to validate our framework's safety properties. Our approach offers a path toward AGI development that is inherently safer, rather than retrofitted with safety measures.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Systems and Control (eess.SY); Adaptation and Self-Organizing Systems (nlin.AO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.05766.pdf", "abstract_url": "https://arxiv.org/abs/2508.05766", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Systems and Control (eess.SY)", "Adaptation and Self-Organizing Systems (nlin.AO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种通过结合主动推理原则与大型语言模型（LLMs）来开发安全的人工通用智能（AGI）的新框架。", "motivation": "解决传统AI安全方法在事后解释性和奖励工程方面的根本限制。", "method": "采用透明信念表示和层次价值对齐的架构，利用自然语言作为表示和操作信念的媒介，实现直接的人类监督同时保持计算可操作性。", "result": "提出了一种多代理系统，代理根据主动推理原则自组织，通过层次马尔可夫毯流动偏好和安全约束。", "conclusion": "该框架为AGI开发提供了一条本质上更安全的路径，而不是事后添加安全措施。"}}
{"id": "2508.06046", "title": "EvolvR: Self-Evolving Pairwise Reasoning for Story Evaluation to Enhance Generation", "authors": ["Xinda Wang", "Zhengxu Hou", "Yangshijie Zhang", "Bingren Yan", "Zhibo Yang", "Xingsheng Zhang", "Luxi Xing", "Qiang Zhou", "Chen Zhang"], "abstract": "Although the effectiveness of Large Language Models (LLMs) as judges (LLM-as-a-judge) has been validated, their performance remains limited in open-ended tasks, particularly in story evaluation. Accurate story evaluation is crucial not only for assisting human quality judgment but also for providing key signals to guide story generation. However, existing methods face a dilemma: prompt engineering for closed-source models suffers from poor adaptability, while fine-tuning approaches for open-source models lack the rigorous reasoning capabilities essential for story evaluation. To address this, we propose the Self-Evolving Pairwise Reasoning (EvolvR) framework. Grounded in pairwise comparison, the framework first self-synthesizes score-aligned Chain-of-Thought (CoT) data via a multi-persona strategy. To ensure data quality, these raw CoTs undergo a self-filtering process, utilizing multi-agents to guarantee their logical rigor and robustness. Finally, the evaluator trained on the refined data is deployed as a reward model to guide the story generation task. Experimental results demonstrate that our framework achieves state-of-the-art (SOTA) performance on three evaluation benchmarks including StoryER, HANNA and OpenMEVA. Furthermore, when served as a reward model, it significantly enhances the quality of generated stories, thereby fully validating the superiority of our self-evolving approach.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.06046.pdf", "abstract_url": "https://arxiv.org/abs/2508.06046", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了自我进化的成对推理（EvolvR）框架，用于故事评估，以提高生成质量。通过多角色策略自合成分数对齐的思维链数据，并利用多代理自我过滤确保数据质量，最终训练评估者作为奖励模型指导故事生成。实验证明，该框架在多个评估基准上达到了最先进的性能，并显著提升了生成故事的质量。", "motivation": "大型语言模型（LLMs）作为评判者在开放式任务中的表现有限，特别是在故事评估方面。准确的故事评估不仅有助于人类质量判断，还能为故事生成提供关键信号。现有方法存在封闭源模型提示工程适应性差和开源模型微调方法缺乏严格推理能力的问题。", "method": "提出了自我进化的成对推理（EvolvR）框架，基于成对比较，通过多角色策略自合成分数对齐的思维链数据，并利用多代理自我过滤确保数据质量，最后训练评估者作为奖励模型指导故事生成。", "result": "实验结果显示，该框架在StoryER、HANNA和OpenMEVA三个评估基准上达到了最先进的性能，并且作为奖励模型显著提升了生成故事的质量。", "conclusion": "自我进化的成对推理框架在故事评估和生成方面表现出优越性，验证了其自我进化方法的有效性。"}}
{"id": "2508.05909", "title": "Spectrum Projection Score: Aligning Retrieved Summaries with Reader Models in Retrieval-Augmented Generation", "authors": ["Zhanghao Hu", "Qinglin Zhu", "Siya Qi", "Yulan He", "Hanqi Yan", "Lin Gui"], "abstract": "Large Language Models (LLMs) have shown improved generation performance through retrieval-augmented generation (RAG) following the retriever-reader paradigm, which supplements model inputs with externally retrieved knowledge. However, prior work often evaluates RAG holistically, assessing the retriever and reader jointly, making it difficult to isolate the true contribution of retrieval, particularly given the prompt sensitivity of LLMs used as readers. We introduce Spectrum Projection Score (SPS), a lightweight, supervision-free metric that allows the reader to gauge the semantic alignment of a retrieved summary with its hidden representation by comparing the area formed by generated tokens from the summary, and the principal directions of subspace in the reader and to measure the relevance. Building on SPS we present xCompress, an inference time controller framework that dynamically samples, ranks, and compresses retrieval summary candidates. Extensive experiments on five QA benchmarks with four open source LLMs show that SPS not only enhances performance across a range of tasks but also provides a principled perspective on the interaction between retrieval and generation.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.05909.pdf", "abstract_url": "https://arxiv.org/abs/2508.05909", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了Spectrum Projection Score (SPS)，一种轻量级、无需监督的度量方法，用于评估检索摘要与读者模型的语义对齐，并提出了xCompress框架来动态采样、排名和压缩检索摘要候选。", "motivation": "解决在检索增强生成（RAG）中难以隔离检索真正贡献的问题，特别是在LLMs作为读者的提示敏感性背景下。", "method": "提出了Spectrum Projection Score (SPS)度量方法和xCompress框架，通过比较生成令牌形成的区域与读者子空间的主方向来测量相关性。", "result": "在五个QA基准测试和四个开源LLMs上的广泛实验表明，SPS不仅提高了多种任务的性能，还为检索与生成之间的交互提供了原则性视角。", "conclusion": "SPS和xCompress框架为评估和优化检索增强生成提供了有效工具，增强了任务性能并深入理解了检索与生成的关系。"}}
{"id": "2508.05888", "title": "Planning Agents on an Ego-Trip: Leveraging Hybrid Ego-Graph Ensembles for Improved Tool Retrieval in Enterprise Task Planning", "authors": ["Sahil Bansal", "Sai Shruthi Sistla", "Aarti Arikatala", "Sebastian Schreiber"], "abstract": "Effective tool retrieval is essential for AI agents to select from a vast array of tools when identifying and planning actions in the context of complex user queries. Despite its central role in planning, this aspect remains underexplored in the literature. Traditional approaches rely primarily on similarities between user queries and tool descriptions, which significantly limits retrieval accuracy, specifically when handling multi-step user requests. To address these limitations, we propose a Knowledge Graph (KG)-based tool retrieval framework that captures the semantic relationships between tools and their functional dependencies. Our retrieval algorithm leverages ensembles of 1-hop ego tool graphs to model direct and indirect connections between tools, enabling more comprehensive and contextual tool selection for multi-step tasks. We evaluate our approach on a synthetically generated internal dataset across six defined user classes, extending previous work on coherent dialogue synthesis and too retrieval benchmarks. Results demonstrate that our tool graph-based method achieves 91.85% tool coverage on the micro-average Complete Recall metric, compared to 89.26% for re-ranked semantic-lexical hybrid retrieval, the strongest non-KG baseline in our experiments. These findings support our hypothesis that the structural information in the KG provides complementary signals to pure similarity matching, particularly for queries requiring sequential tool composition.", "subjects": "Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.05888.pdf", "abstract_url": "https://arxiv.org/abs/2508.05888", "categories": ["Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于知识图谱（KG）的工具检索框架，通过利用1-hop ego工具图的集合来捕捉工具之间的语义关系和功能依赖，以提高企业任务规划中多步骤用户请求的工具检索准确性。", "motivation": "解决在复杂用户查询背景下，AI代理从大量工具中选择和规划行动时的工具检索问题，特别是在处理多步骤用户请求时，传统基于用户查询和工具描述相似性的方法检索准确性有限。", "method": "提出了一种知识图谱（KG）基于的工具检索框架，利用1-hop ego工具图的集合来建模工具之间的直接和间接连接，实现更全面和上下文相关的工具选择。", "result": "在合成的内部数据集上评估，该方法在微平均Complete Recall指标上达到了91.85%的工具覆盖率，优于最强的非KG基线方法的89.26%。", "conclusion": "研究结果表明，知识图谱中的结构信息为纯相似性匹配提供了补充信号，特别是对于需要顺序工具组合的查询，支持了研究假设。"}}
{"id": "2508.05855", "title": "Safety of Embodied Navigation: A Survey", "authors": ["Zixia Wang", "Jia Hu", "Ronghui Mu"], "abstract": "As large language models (LLMs) continue to advance and gain influence, the development of embodied AI has accelerated, drawing significant attention, particularly in navigation scenarios. Embodied navigation requires an agent to perceive, interact with, and adapt to its environment while moving toward a specified target in unfamiliar settings. However, the integration of embodied navigation into critical applications raises substantial safety concerns. Given their deployment in dynamic, real-world environments, ensuring the safety of such systems is critical. This survey provides a comprehensive analysis of safety in embodied navigation from multiple perspectives, encompassing attack strategies, defense mechanisms, and evaluation methodologies. Beyond conducting a comprehensive examination of existing safety challenges, mitigation technologies, and various datasets and metrics that assess effectiveness and robustness, we explore unresolved issues and future research directions in embodied navigation safety. These include potential attack methods, mitigation strategies, more reliable evaluation techniques, and the implementation of verification frameworks. By addressing these critical gaps, this survey aims to provide valuable insights that can guide future research toward the development of safer and more reliable embodied navigation systems. Furthermore, the findings of this study have broader implications for enhancing societal safety and increasing industrial efficiency.", "subjects": "Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.05855.pdf", "abstract_url": "https://arxiv.org/abs/2508.05855", "categories": ["Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文综述了嵌入式导航的安全性，分析了攻击策略、防御机制和评估方法，并探讨了未解决的问题和未来研究方向。", "motivation": "随着大型语言模型（LLMs）的进步和影响力的增加，嵌入式AI的发展加速，特别是在导航场景中引起了广泛关注。嵌入式导航要求代理在陌生环境中感知、交互并适应其环境，同时向指定目标移动。然而，将嵌入式导航集成到关键应用中引发了重大的安全问题。鉴于它们在动态、真实世界环境中的部署，确保这些系统的安全性至关重要。", "method": "本调查从多个角度对嵌入式导航的安全性进行了全面分析，包括攻击策略、防御机制和评估方法。", "result": "除了对现有的安全挑战、缓解技术以及评估有效性和鲁棒性的各种数据集和指标进行全面检查外，我们还探讨了嵌入式导航安全中未解决的问题和未来的研究方向。", "conclusion": "通过解决这些关键差距，本调查旨在提供有价值的见解，可以指导未来研究开发更安全、更可靠的嵌入式导航系统。此外，本研究的结果对增强社会安全和提高工业效率具有更广泛的意义。"}}
{"id": "2508.05996", "title": "Mediator-Guided Multi-Agent Collaboration among Open-Source Models for Medical Decision-Making", "authors": ["Kaitao Chen", "Mianxin Liu", "Daoming Zong", "Chaoyue Ding", "Shaohao Rui", "Yankai Jiang", "Mu Zhou", "Xiaosong Wang"], "abstract": "Complex medical decision-making involves cooperative workflows operated by different clinicians. Designing AI multi-agent systems can expedite and augment human-level clinical decision-making. Existing multi-agent researches primarily focus on language-only tasks, yet their extension to multimodal scenarios remains challenging. A blind combination of diverse vision-language models (VLMs) can amplify an erroneous outcome interpretation. VLMs in general are less capable in instruction following and importantly self-reflection, compared to large language models (LLMs) of comparable sizes. This disparity largely constrains VLMs' ability in cooperative workflows. In this study, we propose MedOrch, a mediator-guided multi-agent collaboration framework for medical multimodal decision-making. MedOrch employs an LLM-based mediator agent that enables multiple VLM-based expert agents to exchange and reflect on their outputs towards collaboration. We utilize multiple open-source general-purpose and domain-specific VLMs instead of costly GPT-series models, revealing the strength of heterogeneous models. We show that the collaboration within distinct VLM-based agents can surpass the capabilities of any individual agent. We validate our approach on five medical vision question answering benchmarks, demonstrating superior collaboration performance without model training. Our findings underscore the value of mediator-guided multi-agent collaboration in advancing medical multimodal intelligence. Our code will be made publicly available.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "14 pages, 4 figures", "pdf_url": "https://arxiv.org/pdf/2508.05996.pdf", "abstract_url": "https://arxiv.org/abs/2508.05996", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为MedOrch的中介引导多智能体协作框架，用于医学多模态决策。该框架利用基于大型语言模型（LLM）的中介智能体，促进多个基于视觉语言模型（VLM）的专家智能体之间的输出交换和反思，以实现协作。", "motivation": "复杂的医学决策涉及由不同临床医生操作的协作工作流程。设计AI多智能体系统可以加速和增强人类水平的临床决策。现有的多智能体研究主要集中在仅语言任务上，而将其扩展到多模态场景仍然具有挑战性。", "method": "MedOrch框架采用基于LLM的中介智能体，使多个基于VLM的专家智能体能够交换和反思它们的输出以实现协作。研究使用了多个开源通用和领域特定的VLM，而不是昂贵的GPT系列模型。", "result": "研究表明，不同基于VLM的智能体之间的协作可以超越任何单个智能体的能力。在五个医学视觉问答基准上的验证显示，无需模型训练即可实现卓越的协作性能。", "conclusion": "研究结果强调了中介引导的多智能体协作在推进医学多模态智能中的价值。代码将公开提供。"}}
{"id": "2508.06042", "title": "Society of Mind Meets Real-Time Strategy: A Hierarchical Multi-Agent Framework for Strategic Reasoning", "authors": ["Daechul Ahn", "San Kim", "Jonghyun Choi"], "abstract": "Large Language Models (LLMs) have recently demonstrated impressive action sequence prediction capabilities but often struggle with dynamic, long-horizon tasks such as real-time strategic games. In a game such as StarCraftII (SC2), agents need to manage resource constraints and adapt to evolving battlefield situations in a partially observable environment. This often overwhelms exisiting LLM-based approaches. To address these challenges, we propose a hierarchical multi-agent framework that employs specialized imitation learning agents under a meta-controller called Strategic Planner (SP). By expert demonstrations, each specialized agent learns a distinctive strategy, such as aerial support or defensive maneuvers, and produces coherent, structured multistep action sequences. The SP then orchestrates these proposals into a single, environmentally adaptive plan that ensures local decisions aligning with long-term strategies. We call this HIMA (Hierarchical Imitation Multi-Agent). We also present TEXTSCII-ALL, a comprehensive SC2 testbed that encompasses all race match combinations in SC2. Our empirical results show that HIMA outperforms state of the arts in strategic clarity, adaptability, and computational efficiency, underscoring the potential of combining specialized imitation modules with meta-level orchestration to develop more robust, general-purpose AI agents.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "COLM 2025", "pdf_url": "https://arxiv.org/pdf/2508.06042.pdf", "abstract_url": "https://arxiv.org/abs/2508.06042", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种分层多智能体框架HIMA，结合专家模仿学习和战略规划器，以提升在实时战略游戏如《星际争霸II》中的表现。", "motivation": "解决大型语言模型在动态、长视野任务如实时战略游戏中表现不佳的问题。", "method": "采用分层多智能体框架，包括专门模仿学习代理和战略规划器(SP)，通过专家示范学习特定策略。", "result": "HIMA在战略清晰度、适应性和计算效率上优于现有技术。", "conclusion": "结合专门模仿模块与元级协调，可以开发出更强大、通用的AI代理。"}}
{"id": "2508.06110", "title": "PanelTR: Zero-Shot Table Reasoning Framework Through Multi-Agent Scientific Discussion", "authors": ["Yiran Rex Ma"], "abstract": "Table reasoning, including tabular QA and fact verification, often depends on annotated data or complex data augmentation, limiting flexibility and generalization. LLMs, despite their versatility, often underperform compared to simple supervised models. To approach these issues, we introduce PanelTR, a framework utilizing LLM agent scientists for robust table reasoning through a structured scientific approach. PanelTR's workflow involves agent scientists conducting individual investigations, engaging in self-review, and participating in collaborative peer-review discussions. This process, driven by five scientist personas, enables semantic-level transfer without relying on data augmentation or parametric optimization. Experiments across four benchmarks show that PanelTR outperforms vanilla LLMs and rivals fully supervised models, all while remaining independent of training data. Our findings indicate that structured scientific methodology can effectively handle complex tasks beyond table reasoning with flexible semantic understanding in a zero-shot context.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "Accepted at IJCNN 2025", "pdf_url": "https://arxiv.org/pdf/2508.06110.pdf", "abstract_url": "https://arxiv.org/abs/2508.06110", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "PanelTR是一个通过多智能体科学讨论实现零样本表格推理的框架，旨在解决表格推理任务中对标注数据或复杂数据增强的依赖问题。", "motivation": "解决表格推理（包括表格QA和事实验证）中因依赖标注数据或复杂数据增强而导致的灵活性和泛化能力受限的问题，以及大型语言模型（LLMs）在此类任务中表现不佳的问题。", "method": "引入PanelTR框架，利用LLM智能体科学家通过结构化的科学方法进行表格推理，包括个体调查、自我审查和同行评审讨论。", "result": "在四个基准测试中，PanelTR的表现优于普通LLMs，并与完全监督模型相媲美，同时不依赖于训练数据。", "conclusion": "结构化的科学方法论可以在零样本上下文中有效处理超出表格推理的复杂任务，具有灵活的语义理解能力。"}}
{"id": "2508.06189", "title": "MA-CBP: A Criminal Behavior Prediction Framework Based on Multi-Agent Asynchronous Collaboration", "authors": ["Cheng Liu", "Daou Zhang", "Tingxu Liu", "Yuhan Wang", "Jinyang Chen", "Yuexuan Li", "Xinying Xiao", "Chenbo Xin", "Ziru Wang", "Weichao Wu"], "abstract": "With the acceleration of urbanization, criminal behavior in public scenes poses an increasingly serious threat to social security. Traditional anomaly detection methods based on feature recognition struggle to capture high-level behavioral semantics from historical information, while generative approaches based on Large Language Models (LLMs) often fail to meet real-time requirements. To address these challenges, we propose MA-CBP, a criminal behavior prediction framework based on multi-agent asynchronous collaboration. This framework transforms real-time video streams into frame-level semantic descriptions, constructs causally consistent historical summaries, and fuses adjacent image frames to perform joint reasoning over long- and short-term contexts. The resulting behavioral decisions include key elements such as event subjects, locations, and causes, enabling early warning of potential criminal activity. In addition, we construct a high-quality criminal behavior dataset that provides multi-scale language supervision, including frame-level, summary-level, and event-level semantic annotations. Experimental results demonstrate that our method achieves superior performance on multiple datasets and offers a promising solution for risk warning in urban public safety scenarios.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.06189.pdf", "abstract_url": "https://arxiv.org/abs/2508.06189", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "MA-CBP是一个基于多智能体异步协作的犯罪行为预测框架，旨在通过实时视频流分析和语义描述转换，结合长短期上下文联合推理，提前预警潜在的犯罪活动。", "motivation": "城市化加速导致公共场景中的犯罪行为对社会安全构成严重威胁，传统基于特征识别的异常检测方法难以捕捉高层次行为语义，而基于大型语言模型的生成方法往往无法满足实时性要求。", "method": "MA-CBP框架将实时视频流转换为帧级语义描述，构建因果一致的历史摘要，并融合相邻图像帧进行长短期上下文联合推理。", "result": "实验结果表明，该方法在多个数据集上表现出色，为城市公共安全场景的风险预警提供了有前景的解决方案。", "conclusion": "MA-CBP框架通过多智能体异步协作和语义分析，有效预测犯罪行为，为提升公共安全提供了新的技术途径。"}}
{"id": "2508.06149", "title": "Scaling Personality Control in LLMs with Big Five Scaler Prompts", "authors": ["Gunhee Cho", "Yun-Gyung Cheong"], "abstract": "We present Big5-Scaler, a prompt-based framework for conditioning large language models (LLMs) with controllable Big Five personality traits. By embedding numeric trait values into natural language prompts, our method enables fine-grained personality control without additional training. We evaluate Big5-Scaler across trait expression, dialogue generation, and human trait imitation tasks. Results show that it induces consistent and distinguishable personality traits across models, with performance varying by prompt type and scale. Our analysis highlights the effectiveness of concise prompts and lower trait intensities, providing a efficient approach for building personality-aware dialogue agents.", "subjects": "Computation and Language (cs.CL); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.06149.pdf", "abstract_url": "https://arxiv.org/abs/2508.06149", "categories": ["Computation and Language (cs.CL)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "介绍Big5-Scaler，一种基于提示的框架，用于通过自然语言提示控制大型语言模型（LLMs）的五大性格特质，无需额外训练即可实现细粒度性格控制。", "motivation": "解决在大型语言模型中实现可控性格特质表达的问题，特别是在无需额外训练的情况下。", "method": "通过将数字特质值嵌入自然语言提示中，Big5-Scaler框架实现了对LLMs的细粒度性格控制。", "result": "Big5-Scaler在不同模型上诱导出一致且可区分的性格特质，性能因提示类型和规模而异，简洁提示和较低特质强度更有效。", "conclusion": "Big5-Scaler为构建具有性格感知的对话代理提供了一种高效方法，特别是在使用简洁提示和较低特质强度时效果更佳。"}}
{"id": "2508.06105", "title": "You Don't Need Pre-built Graphs for RAG: Retrieval Augmented Generation with Adaptive Reasoning Structures", "authors": ["Shengyuan Chen", "Chuang Zhou", "Zheng Yuan", "Qinggang Zhang", "Zeyang Cui", "Hao Chen", "Yilin Xiao", "Jiannong Cao", "Xiao Huang"], "abstract": "Large language models (LLMs) often suffer from hallucination, generating factually incorrect statements when handling questions beyond their knowledge and perception. Retrieval-augmented generation (RAG) addresses this by retrieving query-relevant contexts from knowledge bases to support LLM reasoning. Recent advances leverage pre-constructed graphs to capture the relational connections among distributed documents, showing remarkable performance in complex tasks. However, existing Graph-based RAG (GraphRAG) methods rely on a costly process to transform the corpus into a graph, introducing overwhelming token cost and update latency. Moreover, real-world queries vary in type and complexity, requiring different logic structures for accurate reasoning. The pre-built graph may not align with these required structures, resulting in ineffective knowledge retrieval. To this end, we propose a \\textbf{\\underline{Logic}}-aware \\textbf{\\underline{R}}etrieval-\\textbf{\\underline{A}}ugmented \\textbf{\\underline{G}}eneration framework (\\textbf{LogicRAG}) that dynamically extracts reasoning structures at inference time to guide adaptive retrieval without any pre-built graph. LogicRAG begins by decomposing the input query into a set of subproblems and constructing a directed acyclic graph (DAG) to model the logical dependencies among them. To support coherent multi-step reasoning, LogicRAG then linearizes the graph using topological sort, so that subproblems can be addressed in a logically consistent order. Besides, LogicRAG applies graph pruning to reduce redundant retrieval and uses context pruning to filter irrelevant context, significantly reducing the overall token cost. Extensive experiments demonstrate that LogicRAG achieves both superior performance and efficiency compared to state-of-the-art baselines.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.06105.pdf", "abstract_url": "https://arxiv.org/abs/2508.06105", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种名为LogicRAG的新框架，旨在解决基于图的检索增强生成（GraphRAG）方法中预构建图的高成本和更新延迟问题，通过动态提取推理结构来指导自适应检索，无需预构建图。", "motivation": "大型语言模型（LLMs）在处理超出其知识和感知范围的问题时，常常会产生事实错误的陈述。检索增强生成（RAG）通过从知识库中检索与查询相关的上下文来支持LLM推理，但现有的基于图的RAG方法依赖于将语料库转换为图的昂贵过程，导致高昂的令牌成本和更新延迟。此外，现实世界中的查询类型和复杂性各不相同，需要不同的逻辑结构来进行准确推理，预构建的图可能无法与这些所需结构对齐，导致知识检索效率低下。", "method": "LogicRAG框架在推理时动态提取推理结构，无需任何预构建图。它首先将输入查询分解为一组子问题，并构建一个有向无环图（DAG）来模拟它们之间的逻辑依赖关系。为了支持连贯的多步推理，LogicRAG然后使用拓扑排序对图进行线性化，以便子问题可以按逻辑一致的顺序解决。此外，LogicRAG应用图剪枝来减少冗余检索，并使用上下文剪枝来过滤无关上下文，显著降低了总体令牌成本。", "result": "大量实验表明，与最先进的基线相比，LogicRAG在性能和效率上都达到了优越的表现。", "conclusion": "LogicRAG通过动态提取推理结构和自适应检索，有效解决了预构建图的高成本和更新延迟问题，同时提高了检索的准确性和效率，为复杂任务中的LLM推理提供了强有力的支持。"}}
{"id": "2508.06165", "title": "UR$^2$: Unify RAG and Reasoning through Reinforcement Learning", "authors": ["Weitao Li", "Boran Xiang", "Xiaolong Wang", "Zhinan Gou", "Weizhi Ma", "Yang Liu"], "abstract": "Large Language Models (LLMs) have shown remarkable capabilities through two complementary paradigms: Retrieval-Augmented Generation (RAG), which enhances knowledge grounding, and Reinforcement Learning from Verifiable Rewards (RLVR), which optimizes complex reasoning abilities. However, these two capabilities are often developed in isolation, and existing efforts to unify them remain narrow in scope-typically limited to open-domain QA with fixed retrieval settings and task-specific assumptions. This lack of integration constrains generalization and limits the applicability of RAG-RL methods to broader domains. To bridge this gap, we propose UR2 (Unified RAG and Reasoning), a general framework that unifies retrieval and reasoning through reinforcement learning. UR2 introduces two key contributions: a difficulty-aware curriculum training that selectively invokes retrieval only for challenging problems, and a hybrid knowledge access strategy combining domain-specific offline corpora with LLM-generated summaries. These components are designed to enable dynamic coordination between retrieval and reasoning, improving adaptability across a diverse range of tasks. Experiments across open-domain QA, MMLU-Pro, medical, and mathematical reasoning tasks demonstrate that UR2 (built on Qwen2.5-3/7B and LLaMA-3.1-8B) significantly outperforms existing RAG and RL methods, achieving comparable performance to GPT-4o-mini and GPT-4.1-mini on several benchmarks. We have released all code, models, and data at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.06165.pdf", "abstract_url": "https://arxiv.org/abs/2508.06165", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "UR$^2$是一个通过强化学习统一检索增强生成（RAG）和推理能力的通用框架，旨在解决RAG和RLVR两种能力孤立发展的问题。", "motivation": "解决检索增强生成（RAG）和基于可验证奖励的强化学习（RLVR）两种能力孤立发展，以及现有方法在泛化和应用范围上的局限性。", "method": "提出UR$^2$框架，包括难度感知的课程训练和混合知识访问策略，动态协调检索和推理。", "result": "UR$^2$在多个任务上显著优于现有的RAG和RL方法，性能接近GPT-4o-mini和GPT-4.1-mini。", "conclusion": "UR$^2$通过强化学习统一检索和推理，提高了跨任务适应性，为更广泛领域的应用提供了可能。"}}
{"id": "2508.06178", "title": "Comparing Knowledge Injection Methods for LLMs in a Low-Resource Regime", "authors": ["Hugo Abonizio", "Thales Almeida", "Roberto Lotufo", "Rodrigo Nogueira"], "abstract": "Large language models (LLMs) often require vast amounts of text to effectively acquire new knowledge. While continuing pre-training on large corpora or employing retrieval-augmented generation (RAG) has proven successful, updating an LLM with only a few thousand or million tokens remains challenging. In this work, we investigate the task of injecting small, unstructured information into LLMs and its relation to the catastrophic forgetting phenomenon. We use a dataset of recent news -- ensuring no overlap with the model's pre-training data -- to evaluate the knowledge acquisition by probing the model with question-answer pairs related the learned information. Starting from a continued pre-training baseline, we explored different augmentation algorithms to generate synthetic data to improve the knowledge acquisition capabilities. Our experiments show that simply continuing pre-training on limited data yields modest improvements, whereas exposing the model to diverse textual variations significantly improves the learning of new facts -- particularly with methods that induce greater variability through diverse prompting. Furthermore, we shed light on the forgetting phenomenon in small-data regimes, illustrating the delicate balance between learning new content and retaining existing capabilities. We also confirm the sensitivity of RAG-based approaches for knowledge injection, which often lead to greater degradation on control datasets compared to parametric methods. Finally, we demonstrate that models can generate effective synthetic training data themselves, suggesting a pathway toward self-improving model updates. All code and generated data used in our experiments are publicly available, providing a resource for studying efficient knowledge injection in LLMs with limited data at", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.06178.pdf", "abstract_url": "https://arxiv.org/abs/2508.06178", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本研究探讨了在低资源环境下向大型语言模型（LLMs）注入少量非结构化信息的方法及其与灾难性遗忘现象的关系。通过实验比较了不同的数据增强算法，发现通过多样化提示增加文本变异性能显著提高新事实的学习效果，同时揭示了小数据量下学习新内容与保留现有能力之间的平衡。", "motivation": "解决在有限数据量下向LLMs有效注入新知识并避免灾难性遗忘的问题。", "method": "使用最近新闻数据集评估知识获取，比较了继续预训练基线和使用不同数据增强算法生成合成数据的方法。", "result": "继续预训练在有限数据上效果有限，而通过多样化提示增加文本变异性显著提高了新事实的学习效果。同时，研究揭示了小数据量下学习与遗忘的平衡，并展示了模型自我生成有效训练数据的潜力。", "conclusion": "研究表明，通过增加文本变异性和自我生成训练数据，可以在低资源环境下有效更新LLMs的知识，同时指出了RAG方法在知识注入中的敏感性。"}}
{"id": "2508.06204", "title": "Classification is a RAG problem: A case study on hate speech detection", "authors": ["Richard Willats", "Josh Pennington", "Aravind Mohan", "Bertie Vidgen"], "abstract": "Robust content moderation requires classification systems that can quickly adapt to evolving policies without costly retraining. We present classification using Retrieval-Augmented Generation (RAG), which shifts traditional classification tasks from determining the correct category in accordance with pre-trained parameters to evaluating content in relation to contextual knowledge retrieved at inference. In hate speech detection, this transforms the task from \"is this hate speech?\" to \"does this violate the hate speech policy?\"", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.06204.pdf", "abstract_url": "https://arxiv.org/abs/2508.06204", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种使用检索增强生成（RAG）的分类方法，将传统分类任务从依赖预训练参数确定正确类别转变为在推理时评估内容与检索到的上下文知识的关系，特别是在仇恨言论检测中的应用。", "motivation": "解决内容审核系统需要快速适应不断变化的政策而无需昂贵重新训练的问题。", "method": "采用检索增强生成（RAG）方法，将分类任务转变为在推理时评估内容与检索到的上下文知识的关系。", "result": "在仇恨言论检测中，该方法将任务从“这是仇恨言论吗？”转变为“这违反了仇恨言论政策吗？”。", "conclusion": "RAG方法为内容审核提供了一种灵活、适应性强的解决方案，能够快速适应政策变化而无需重新训练模型。"}}
{"id": "2508.06145", "title": "Retrieval Augmented Large Language Model System for Comprehensive Drug Contraindications", "authors": ["Byeonghun Bang", "Jongsuk Yoon", "Dong-Jin Chang", "Seho Park", "Yong Oh Lee"], "abstract": "The versatility of large language models (LLMs) has been explored across various sectors, but their application in healthcare poses challenges, particularly in the domain of pharmaceutical contraindications where accurate and reliable information is required. This study enhances the capability of LLMs to address contraindications effectively by implementing a Retrieval Augmented Generation (RAG) pipeline. Utilizing OpenAI's GPT-4o-mini as the base model, and the text-embedding-3-small model for embeddings, our approach integrates Langchain to orchestrate a hybrid retrieval system with re-ranking. This system leverages Drug Utilization Review (DUR) data from public databases, focusing on contraindications for specific age groups, pregnancy, and concomitant drug use. The dataset includes 300 question-answer pairs across three categories, with baseline model accuracy ranging from 0.49 to 0.57. Post-integration of the RAG pipeline, we observed a significant improvement in model accuracy, achieving rates of 0.94, 0.87, and 0.89 for contraindications related to age groups, pregnancy, and concomitant drug use, respectively. The results indicate that augmenting LLMs with a RAG framework can substantially reduce uncertainty in prescription and drug intake decisions by providing more precise and reliable drug contraindication information.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.06145.pdf", "abstract_url": "https://arxiv.org/abs/2508.06145", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本研究通过实施检索增强生成（RAG）流程，提高了大型语言模型（LLMs）在药物禁忌方面的应用能力，显著提升了模型在特定年龄组、妊娠和伴随用药禁忌方面的准确性。", "motivation": "解决大型语言模型在医疗健康领域，特别是药物禁忌信息准确性和可靠性方面的应用挑战。", "method": "使用OpenAI的GPT-4o-mini作为基础模型，text-embedding-3-small模型用于嵌入，通过Langchain协调一个混合检索系统与重新排名，整合药物使用审查（DUR）数据。", "result": "RAG流程集成后，模型在特定年龄组、妊娠和伴随用药禁忌方面的准确率分别提升至0.94、0.87和0.89。", "conclusion": "通过RAG框架增强LLMs可以显著减少处方和药物摄入决策中的不确定性，提供更精确和可靠的药物禁忌信息。"}}
{"id": "2304.04475", "title": "Epidemic Control on a Large-Scale-Agent-Based Epidemiology Model using Deep Deterministic Policy Gradient", "authors": ["Gaurav Deshkar", "Jayanta Kshirsagar", "Harshal Hayatnagarkar", "Janani Venugopalan"], "abstract": "To mitigate the impact of the pandemic, several measures include lockdowns, rapid vaccination programs, school closures, and economic stimulus. These interventions can have positive or unintended negative consequences. Current research to model and determine an optimal intervention automatically through round-tripping is limited by the simulation objectives, scale (a few thousand individuals), model types that are not suited for intervention studies, and the number of intervention strategies they can explore (discrete vs continuous). We address these challenges using a Deep Deterministic Policy Gradient (DDPG) based policy optimization framework on a large-scale (100,000 individual) epidemiological agent-based simulation where we perform multi-objective optimization. We determine the optimal policy for lockdown and vaccination in a minimalist age-stratified multi-vaccine scenario with a basic simulation for economic activity. With no lockdown and vaccination (mid-age and elderly), results show optimal economy (individuals below the poverty line) with balanced health objectives (infection, and hospitalization). An in-depth simulation is needed to further validate our results and open-source our framework.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Systems and Control (eess.SY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2304.04475.pdf", "abstract_url": "https://arxiv.org/abs/2304.04475", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Systems and Control (eess.SY)"], "matching_keywords": ["agent"], "AI": {"tldr": "使用深度确定性策略梯度（DDPG）在大规模基于代理的流行病模型上自动确定最佳干预措施，以平衡健康和经济目标。", "motivation": "当前研究在模拟目标、规模、模型类型和干预策略探索方面存在限制，无法自动确定最优的流行病干预措施。", "method": "采用基于DDPG的策略优化框架，在一个大规模（10万个体）的流行病学基于代理的模拟中进行多目标优化。", "result": "在没有封锁和针对中老年人接种疫苗的情况下，实现了经济（贫困线以下个体）和健康目标（感染和住院）的平衡。", "conclusion": "需要进一步的深入模拟来验证结果，并开源框架。"}}
{"id": "2508.06326", "title": "A \"good regulator theorem\" for embodied agents", "authors": ["Nathaniel Virgo", "Martin Biehl", "Manuel Baltieri", "Matteo Capucci"], "abstract": "In a classic paper, Conant and Ashby claimed that \"every good regulator of a system must be a model of that system.\" Artificial Life has produced many examples of systems that perform tasks with apparently no model in sight; these suggest Conant and Ashby's theorem doesn't easily generalise beyond its restricted setup. Nevertheless, here we show that a similar intuition can be fleshed out in a different way: whenever an agent is able to perform a regulation task, it is possible for an observer to interpret it as having \"beliefs\" about its environment, which it \"updates\" in response to sensory input. This notion of belief updating provides a notion of model that is more sophisticated than Conant and Ashby's, as well as a theorem that is more broadly applicable. However, it necessitates a change in perspective, in that the observer plays an essential role in the theory: models are not a mere property of the system but are imposed on it from outside. Our theorem holds regardless of whether the system is regulating its environment in a classic control theory setup, or whether it's regulating its own internal state; the model is of its environment either way. The model might be trivial, however, and this is how the apparent counterexamples are resolved.", "subjects": "Artificial Intelligence (cs.AI); Systems and Control (eess.SY)", "comments": "Accepted at the Artificial Life conference 2025 (ALife 2025). 10 pages, 1 figure", "pdf_url": "https://arxiv.org/pdf/2508.06326.pdf", "abstract_url": "https://arxiv.org/abs/2508.06326", "categories": ["Artificial Intelligence (cs.AI)", "Systems and Control (eess.SY)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了Conant和Ashby的‘好调节器定理’在具身代理中的适用性，提出了一种更复杂的模型概念，即观察者可以将代理解释为具有‘信念’并更新这些信念，从而扩展了原定理的适用范围。", "motivation": "解决Conant和Ashby的‘好调节器定理’在人工生命等领域中出现的局限性问题，探索更广泛适用的理论框架。", "method": "通过引入观察者的视角，重新定义‘模型’的概念，使得代理的调节行为可以被解释为对环境的‘信念’更新。", "result": "提出了一个更广泛适用的定理，表明无论系统是在经典控制理论设置中调节其环境，还是调节其内部状态，都可以被视为对其环境的模型。", "conclusion": "模型的本质不仅取决于系统本身，还依赖于外部观察者的解释，这一观点为解决原定理的局限性提供了新的视角。"}}
{"id": "2508.05637", "title": "Automated Visualization Makeovers with LLMs", "authors": ["Siddharth Gangwar", "David A. Selby", "Sebastian J. Vollmer"], "abstract": "Making a good graphic that accurately and efficiently conveys the desired message to the audience is both an art and a science, typically not taught in the data science curriculum. Visualisation makeovers are exercises where the community exchange feedback to improve charts and data visualizations. Can multi-modal large language models (LLMs) emulate this task? Given a plot in the form of an image file, or the code used to generate it, an LLM, primed with a list of visualization best practices, is employed to semi-automatically generate constructive criticism to produce a better plot. Our system is centred around prompt engineering of a pre-trained model, relying on a combination of userspecified guidelines and any latent knowledge of data visualization practices that might lie within an LLMs training corpus. Unlike other works, the focus is not on generating valid visualization scripts from raw data or prompts, but on educating the user how to improve their existing data visualizations according to an interpretation of best practices. A quantitative evaluation is performed to measure the sensitivity of the LLM agent to various plotting issues across different chart types. We make the tool available as a simple self-hosted applet with an accessible Web interface.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.05637.pdf", "abstract_url": "https://arxiv.org/abs/2508.05637", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了如何利用多模态大型语言模型（LLMs）自动化改进数据可视化，通过提示工程和用户指定指南，生成对现有图表的建设性批评，以提升图表质量。", "motivation": "解决数据科学课程中通常不教授如何制作准确有效传达信息的图表的问题，以及如何自动化进行可视化改进。", "method": "使用预训练的多模态大型语言模型，结合用户指定的可视化最佳实践列表，通过提示工程技术半自动生成改进图表的建议。", "result": "定量评估显示，LLM代理对不同图表类型中的各种绘图问题具有敏感性，能够有效生成改进建议。", "conclusion": "研究表明，LLMs可以用于自动化可视化改进，提供了一个简单自托管的应用程序，使这一工具易于访问。"}}
{"id": "2508.05647", "title": "Query-Aware Graph Neural Networks for Enhanced Retrieval-Augmented Generation", "authors": ["Vibhor Agrawal", "Fay Wang", "Rishi Puri"], "abstract": "We present a novel graph neural network (GNN) architecture for retrieval-augmented generation (RAG) that leverages query-aware attention mechanisms and learned scoring heads to improve retrieval accuracy on complex, multi-hop questions. Unlike traditional dense retrieval methods that treat documents as independent entities, our approach constructs per-episode knowledge graphs that capture both sequential and semantic relationships between text chunks. We introduce an Enhanced Graph Attention Network with query-guided pooling that dynamically focuses on relevant parts of the graph based on user queries. Experimental results demonstrate that our approach significantly outperforms standard dense retrievers on complex question answering tasks, particularly for questions requiring multi-document reasoning. Our implementation leverages PyTorch Geometric for efficient processing of graph-structured data, enabling scalable deployment in production retrieval systems", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.05647.pdf", "abstract_url": "https://arxiv.org/abs/2508.05647", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "提出了一种新颖的图神经网络架构，用于检索增强生成，通过查询感知注意力机制和学习评分头来提高复杂多跳问题的检索准确性。", "motivation": "解决传统密集检索方法将文档视为独立实体，无法捕捉文本块之间序列和语义关系的问题。", "method": "构建每集知识图，引入增强图注意力网络与查询引导池化，动态聚焦于图中与用户查询相关的部分。", "result": "实验结果表明，该方法在复杂问答任务上显著优于标准密集检索器，特别是需要多文档推理的问题。", "conclusion": "该方法通过PyTorch Geometric实现高效的图结构数据处理，支持在生产检索系统中的可扩展部署。"}}
{"id": "2508.06471", "title": "GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models", "authors": ["GLM-4.5 Team", "Aohan Zeng", "Xin Lv", "Qinkai Zheng", "Zhenyu Hou", "Bin Chen", "Chengxing Xie", "Cunxiang Wang", "Da Yin", "Hao Zeng", "Jiajie Zhang", "Kedong Wang", "Lucen Zhong", "Mingdao Liu", "Rui Lu", "Shulin Cao", "Xiaohan Zhang", "Xuancheng Huang", "Yao Wei", "Yean Cheng", "Yifan An", "Yilin Niu", "Yuanhao Wen", "Yushi Bai", "Zhengxiao Du", "Zihan Wang", "Zilin Zhu", "Bohan Zhang", "Bosi Wen", "Bowen Wu", "Bowen Xu", "Can Huang", "Casey Zhao", "Changpeng Cai", "Chao Yu", "Chen Li", "Chendi Ge", "Chenghua Huang", "Chenhui Zhang", "Chenxi Xu", "Chenzheng Zhu", "Chuang Li", "Congfeng Yin", "Daoyan Lin", "Dayong Yang", "Dazhi Jiang", "Ding Ai", "Erle Zhu", "Fei Wang", "Gengzheng Pan", "Guo Wang", "Hailong Sun", "Haitao Li", "Haiyang Li", "Haiyi Hu", "Hanyu Zhang", "Hao Peng", "Hao Tai", "Haoke Zhang", "Haoran Wang", "Haoyu Yang", "He Liu", "He Zhao", "Hongwei Liu", "Hongxi Yan", "Huan Liu", "Huilong Chen", "Ji Li", "Jiajing Zhao", "Jiamin Ren", "Jian Jiao", "Jiani Zhao", "Jianyang Yan", "Jiaqi Wang", "Jiayi Gui", "Jiayue Zhao", "Jie Liu", "Jijie Li", "Jing Li", "Jing Lu", "Jingsen Wang", "Jingwei Yuan", "Jingxuan Li", "Jingzhao Du", "Jinhua Du", "Jinxin Liu", "Junkai Zhi", "Junli Gao", "Ke Wang", "Lekang Yang", "Liang Xu", "Lin Fan", "Lindong Wu", "Lintao Ding", "Lu Wang", "Man Zhang", "Minghao Li", "Minghuan Xu", "Mingming Zhao", "Mingshu Zhai"], "abstract": "We present GLM-4.5, an open-source Mixture-of-Experts (MoE) large language model with 355B total parameters and 32B activated parameters, featuring a hybrid reasoning method that supports both thinking and direct response modes. Through multi-stage training on 23T tokens and comprehensive post-training with expert model iteration and reinforcement learning, GLM-4.5 achieves strong performance across agentic, reasoning, and coding (ARC) tasks, scoring 70.1% on TAU-Bench, 91.0% on AIME 24, and 64.2% on SWE-bench Verified. With much fewer parameters than several competitors, GLM-4.5 ranks 3rd overall among all evaluated models and 2nd on agentic benchmarks. We release both GLM-4.5 (355B parameters) and a compact version, GLM-4.5-Air (106B parameters), to advance research in reasoning and agentic AI systems. Code, models, and more information are available at", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.06471.pdf", "abstract_url": "https://arxiv.org/abs/2508.06471", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "GLM-4.5是一个开源的混合专家（MoE）大型语言模型，总参数3550亿，激活参数320亿，采用混合推理方法，支持思考和直接响应模式。通过多阶段训练和全面的后训练，GLM-4.5在代理、推理和编码（ARC）任务上表现出色。", "motivation": "解决大型语言模型在代理、推理和编码任务上的性能问题，同时减少参数数量以提高效率。", "method": "采用混合专家（MoE）架构和多阶段训练，结合专家模型迭代和强化学习进行后训练。", "result": "GLM-4.5在TAU-Bench上得分70.1%，AIME 24上91.0%，SWE-bench Verified上64.2%，在评估模型中总体排名第三，代理基准测试中排名第二。", "conclusion": "GLM-4.5及其紧凑版本GLM-4.5-Air的发布，推动了推理和代理AI系统的研究，展示了在减少参数数量的同时保持高性能的潜力。"}}
{"id": "2508.06433", "title": "Memp: Exploring Agent Procedural Memory", "authors": ["Runnan Fang", "Yuan Liang", "Xiaobin Wang", "Jialong Wu", "Shuofei Qiao", "Pengjun Xie", "Fei Huang", "Huajun Chen", "Ningyu Zhang"], "abstract": "Large Language Models (LLMs) based agents excel at diverse tasks, yet they suffer from brittle procedural memory that is manually engineered or entangled in static parameters. In this work, we investigate strategies to endow agents with a learnable, updatable, and lifelong procedural memory. We propose Memp that distills past agent trajectories into both fine-grained, step-by-step instructions and higher-level, script-like abstractions, and explore the impact of different strategies for Build, Retrieval, and Update of procedural memory. Coupled with a dynamic regimen that continuously updates, corrects, and deprecates its contents, this repository evolves in lockstep with new experience. Empirical evaluation on TravelPlanner and ALFWorld shows that as the memory repository is refined, agents achieve steadily higher success rates and greater efficiency on analogous tasks. Moreover, procedural memory built from a stronger model retains its value: migrating the procedural memory to a weaker model yields substantial performance gains.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multiagent Systems (cs.MA)", "comments": "Work in progress", "pdf_url": "https://arxiv.org/pdf/2508.06433.pdf", "abstract_url": "https://arxiv.org/abs/2508.06433", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了Memp，一种为基于大型语言模型（LLM）的代理赋予可学习、可更新和终身程序性记忆的策略，通过将过去的代理轨迹提炼为细粒度的逐步指令和更高级的脚本抽象，探索了构建、检索和更新程序性记忆的不同策略的影响。", "motivation": "基于LLM的代理在处理多样化任务时表现出色，但其程序性记忆脆弱，通常是手动设计或与静态参数纠缠。本研究旨在解决这一问题，赋予代理可学习、可更新和终身的程序性记忆。", "method": "提出了Memp策略，该策略将过去的代理轨迹提炼为细粒度的逐步指令和更高级的脚本抽象，并探索了构建、检索和更新程序性记忆的不同策略。结合动态更新机制，持续更新、纠正和淘汰记忆内容。", "result": "在TravelPlanner和ALFWorld上的实证评估显示，随着记忆库的完善，代理在类似任务上的成功率和效率稳步提高。此外，从更强模型构建的程序性记忆迁移到较弱模型时，仍能带来显著的性能提升。", "conclusion": "Memp策略有效地增强了基于LLM的代理的程序性记忆能力，使其能够更高效地完成任务，并且这种记忆的价值可以跨模型迁移，为代理的持续学习和适应提供了新的可能性。"}}
{"id": "2508.05648", "title": "AquiLLM: a RAG Tool for Capturing Tacit Knowledge in Research Groups", "authors": ["Chandler Campbell", "Bernie Boscoe", "Tuan Do"], "abstract": "Research groups face persistent challenges in capturing, storing, and retrieving knowledge that is distributed across team members. Although structured data intended for analysis and publication is often well managed, much of a group's collective knowledge remains informal, fragmented, or undocumented--often passed down orally through meetings, mentoring, and day-to-day collaboration. This includes private resources such as emails, meeting notes, training materials, and ad hoc documentation. Together, these reflect the group's tacit knowledge--the informal, experience-based expertise that underlies much of their work. Accessing this knowledge can be difficult, requiring significant time and insider understanding. Retrieval-augmented generation (RAG) systems offer promising solutions by enabling users to query and generate responses grounded in relevant source material. However, most current RAG-LLM systems are oriented toward public documents and overlook the privacy concerns of internal research materials. We introduce AquiLLM (pronounced ah-quill-em), a lightweight, modular RAG system designed to meet the needs of research groups. AquiLLM supports varied document types and configurable privacy settings, enabling more effective access to both formal and informal knowledge within scholarly groups.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "comments": "Accepted to US Research Software Engineer Association (US-RSE) 2025", "pdf_url": "https://arxiv.org/pdf/2508.05648.pdf", "abstract_url": "https://arxiv.org/abs/2508.05648", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "AquiLLM是一个为研究小组设计的轻量级、模块化RAG系统，旨在捕获、存储和检索分散在团队成员中的隐性知识。", "motivation": "研究小组在捕获、存储和检索分散在团队成员中的知识方面面临持续挑战，尤其是那些非正式、碎片化或未记录的知识。", "method": "AquiLLM采用检索增强生成（RAG）技术，支持多种文档类型和可配置的隐私设置，以更有效地访问学术团体中的正式和非正式知识。", "result": "AquiLLM提供了一个解决方案，使得研究小组能够更容易地访问和利用其集体隐性知识，同时考虑到内部研究材料的隐私问题。", "conclusion": "AquiLLM通过其轻量级和模块化的设计，为研究小组提供了一个有效的工具来管理和利用其隐性知识，填补了当前RAG-LLM系统在隐私和内部文档处理方面的空白。"}}
{"id": "2508.05650", "title": "OmniBench-RAG: A Multi-Domain Evaluation Platform for Retrieval-Augmented Generation Tools", "authors": ["Jiaxuan Liang", "Shide Zhou", "Kailong Wang"], "abstract": "While Retrieval Augmented Generation (RAG) is now widely adopted to enhance LLMs, evaluating its true performance benefits in a reproducible and interpretable way remains a major hurdle. Existing methods often fall short: they lack domain coverage, employ coarse metrics that miss sub document precision, and fail to capture computational trade offs. Most critically, they provide no standardized framework for comparing RAG effectiveness across different models and domains.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.05650.pdf", "abstract_url": "https://arxiv.org/abs/2508.05650", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "OmniBench-RAG是一个多领域评估平台，旨在解决检索增强生成（RAG）工具在评估性能时的可重复性和可解释性问题。", "motivation": "当前评估RAG性能的方法存在领域覆盖不足、使用粗糙的度量标准忽略子文档精度，以及未能捕捉计算权衡等问题，且缺乏比较不同模型和领域RAG有效性的标准化框架。", "method": "提出了OmniBench-RAG，一个多领域评估平台，用于标准化评估RAG工具的性能。", "result": "该平台能够更全面地评估RAG工具的性能，包括在不同领域的表现和计算效率的权衡。", "conclusion": "OmniBench-RAG为解决RAG工具评估中的现有问题提供了一个有效的解决方案，有助于更准确地比较不同模型和领域的RAG有效性。"}}
{"id": "2508.05652", "title": "Lessons from A Large Language Model-based Outdoor Trail Recommendation Chatbot with Retrieval Augmented Generation", "authors": ["Julia Ann Mathew", "Suining He"], "abstract": "The increasing popularity of outdoor recreational activities (such as hiking and biking) has boosted the demand for a conversational AI system to provide informative and personalized suggestion on outdoor trails. Challenges arise in response to (1) how to provide accurate outdoor trail information via conversational AI; and (2) how to enable usable and efficient recommendation services. To address above, this paper discusses the preliminary and practical lessons learned from developing Judy, an outdoor trail recommendation chatbot based on the large language model (LLM) with retrieval augmented generation (RAG). To gain concrete system insights, we have performed case studies with the outdoor trails in Connecticut (CT), US. We have conducted web-based data collection, outdoor trail data management, and LLM model performance studies on the RAG-based recommendation. Our experimental results have demonstrated the accuracy, effectiveness, and usability of Judy in recommending outdoor trails based on the LLM with RAG.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "comments": "4 pages, UrbComp 2025", "pdf_url": "https://arxiv.org/pdf/2508.05652.pdf", "abstract_url": "https://arxiv.org/abs/2508.05652", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文讨论了基于大型语言模型（LLM）与检索增强生成（RAG）的户外步道推荐聊天机器人Judy的开发经验，旨在解决通过对话AI提供准确户外步道信息及高效推荐服务的挑战。", "motivation": "随着户外休闲活动（如徒步和骑行）的日益流行，对能够提供信息丰富且个性化户外步道建议的对话AI系统的需求增加。", "method": "采用大型语言模型（LLM）结合检索增强生成（RAG）技术开发Judy聊天机器人，并通过美国康涅狄格州（CT）的户外步道案例研究进行系统洞察。", "result": "实验结果表明，基于LLM与RAG的Judy在推荐户外步道方面具有准确性、有效性和可用性。", "conclusion": "Judy聊天机器人的开发为户外步道推荐提供了实用的解决方案，展示了LLM与RAG技术在提升对话AI系统性能方面的潜力。"}}
{"id": "2508.05660", "title": "Open-Source Agentic Hybrid RAG Framework for Scientific Literature Review", "authors": ["Aditya Nagori", "Ricardo Accorsi Casonatto", "Ayush Gautam", "Abhinav Manikantha Sai Cheruvu", "Rishikesan Kamaleswaran"], "abstract": "The surge in scientific publications challenges traditional review methods, demanding tools that integrate structured metadata with full-text analysis. Hybrid Retrieval Augmented Generation (RAG) systems, combining graph queries with vector search offer promise but are typically static, rely on proprietary tools, and lack uncertainty estimates. We present an agentic approach that encapsulates the hybrid RAG pipeline within an autonomous agent capable of (1) dynamically selecting between GraphRAG and VectorRAG for each query, (2) adapting instruction-tuned generation in real time to researcher needs, and (3) quantifying uncertainty during inference. This dynamic orchestration improves relevance, reduces hallucinations, and promotes reproducibility.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.05660.pdf", "abstract_url": "https://arxiv.org/abs/2508.05660", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic", "@RAG"], "AI": {"tldr": "提出了一种开源的、基于代理的混合RAG框架，用于科学文献综述，通过动态选择检索方法和实时调整生成策略，提高相关性和减少幻觉。", "motivation": "科学出版物数量的激增对传统综述方法提出了挑战，需要能够整合结构化元数据和全文分析的工具。现有的混合RAG系统通常是静态的，依赖于专有工具，并且缺乏不确定性估计。", "method": "采用代理方法，将混合RAG管道封装在自主代理中，能够(1)动态选择GraphRAG和VectorRAG，(2)实时调整指令调整生成以适应研究者需求，(3)在推理过程中量化不确定性。", "result": "这种动态编排提高了相关性，减少了幻觉，并促进了可重复性。", "conclusion": "该框架为科学文献综述提供了一种更灵活、更可靠的方法，有望解决现有系统的局限性。"}}
{"id": "2508.05662", "title": "From Static to Dynamic: A Streaming RAG Approach to Real-time Knowledge Base", "authors": ["Yuzhou Zhu"], "abstract": "Dynamic streams from news feeds, social media, sensor networks, and financial markets challenge static RAG frameworks. Full-scale indices incur high memory costs; periodic rebuilds introduce latency that undermines data freshness; naive sampling sacrifices semantic coverage. We present Streaming RAG, a unified pipeline that combines multi-vector cosine screening, mini-batch clustering, and a counter-based heavy-hitter filter to maintain a compact prototype set. We further prove an approximation bound \\$E\\[R(K\\_t)] \\ge R^\\* - L \\Delta\\$ linking retrieval quality to clustering variance. An incremental index upsert mechanism refreshes prototypes without interrupting queries. Experiments on eight real-time streams show statistically significant gains in Recall\\@10 (up to 3 points, p < 0.01), end-to-end latency below 15 ms, and throughput above 900 documents per second under a 150 MB budget. Hyperparameter sensitivity analysis over cluster count, admission probability, relevance threshold, and counter capacity validates default settings. In open-domain question answering with GPT-3.5 Turbo, we record 3.2-point gain in Exact Match and 2.8-point gain in F1 on SQuAD; abstractive summarization yields ROUGE-L improvements. Streaming RAG establishes a new Pareto frontier for retrieval augmentation.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.05662.pdf", "abstract_url": "https://arxiv.org/abs/2508.05662", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出Streaming RAG，一种动态处理实时知识库的方法，通过结合多向量余弦筛选、小批量聚类和基于计数器的重击过滤器，有效解决了静态RAG框架在处理动态数据流时的高内存成本和延迟问题。", "motivation": "静态RAG框架在处理来自新闻源、社交媒体、传感器网络和金融市场的动态数据流时，面临高内存成本、数据新鲜度不足和语义覆盖不全的问题。", "method": "Streaming RAG采用多向量余弦筛选、小批量聚类和基于计数器的重击过滤器来维护一个紧凑的原型集，并通过增量索引更新机制在不中断查询的情况下刷新原型。", "result": "在八个实时数据流上的实验显示，Recall@10显著提高（最高3点，p < 0.01），端到端延迟低于15毫秒，吞吐量在150 MB预算下超过900文档/秒。在开放域问答和抽象摘要任务中也表现出性能提升。", "conclusion": "Streaming RAG为检索增强建立了新的帕累托前沿，有效平衡了检索质量和系统性能，适用于实时知识库的动态更新和查询。"}}
{"id": "2508.05664", "title": "Enhancing Retrieval-Augmented Generation for Electric Power Industry Customer Support", "authors": ["Hei Yu Chan", "Kuok Tou Ho", "Chenglong Ma", "Yujing Si", "Hok Lai Lin", "Sa Lei Lam"], "abstract": "Many AI customer service systems use standard NLP pipelines or finetuned language models, which often fall short on ambiguous, multi-intent, or detail-specific queries. This case study evaluates recent techniques: query rewriting, RAG Fusion, keyword augmentation, intent recognition, and context reranking, for building a robust customer support system in the electric power domain. We compare vector-store and graph-based RAG frameworks, ultimately selecting the graph-based RAG for its superior performance in handling complex queries. We find that query rewriting improves retrieval for queries using non-standard terminology or requiring precise detail. RAG Fusion boosts performance on vague or multifaceted queries by merging multiple retrievals. Reranking reduces hallucinations by filtering irrelevant contexts. Intent recognition supports the decomposition of complex questions into more targeted sub-queries, increasing both relevance and efficiency. In contrast, keyword augmentation negatively impacts results due to biased keyword selection. Our final system combines intent recognition, RAG Fusion, and reranking to handle disambiguation and multi-source queries. Evaluated on both a GPT-4-generated dataset and a real-world electricity provider FAQ dataset, it achieves 97.9% and 89.6% accuracy respectively, substantially outperforming baseline RAG models.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "6 pages", "pdf_url": "https://arxiv.org/pdf/2508.05664.pdf", "abstract_url": "https://arxiv.org/abs/2508.05664", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文探讨了在电力行业客户支持中增强检索增强生成（RAG）技术的方法，通过比较向量存储和图基础的RAG框架，选择了后者以处理复杂查询。研究发现，查询重写、RAG Fusion和上下文重排名等技术能有效提升系统性能，而关键词增强则因偏见选择产生负面影响。最终系统结合意图识别、RAG Fusion和重排名，在两种数据集上实现了高准确率。", "motivation": "解决AI客户服务系统在处理模糊、多意图或细节特定查询时的不足，特别是在电力行业中的应用。", "method": "评估了查询重写、RAG Fusion、关键词增强、意图识别和上下文重排名等技术，并比较了向量存储和图基础的RAG框架。", "result": "图基础的RAG框架在处理复杂查询时表现更优，结合意图识别、RAG Fusion和重排名的系统在GPT-4生成的数据集和真实世界FAQ数据集上分别达到了97.9%和89.6%的准确率。", "conclusion": "通过特定技术的组合应用，可以显著提升电力行业客户支持系统的性能和准确性，尤其是在处理复杂和模糊查询时。"}}
{"id": "2508.05666", "title": "HySemRAG: A Hybrid Semantic Retrieval-Augmented Generation Framework for Automated Literature Synthesis and Methodological Gap Analysis", "authors": ["Alejandro Godinez"], "abstract": "We present HySemRAG, a framework that combines Extract, Transform, Load (ETL) pipelines with Retrieval-Augmented Generation (RAG) to automate large-scale literature synthesis and identify methodological research gaps. The system addresses limitations in existing RAG architectures through a multi-layered approach: hybrid retrieval combining semantic search, keyword filtering, and knowledge graph traversal; an agentic self-correction framework with iterative quality assurance; and post-hoc citation verification ensuring complete traceability. Our implementation processes scholarly literature through eight integrated stages: multi-source metadata acquisition, asynchronous PDF retrieval, custom document layout analysis using modified Docling architecture, bibliographic management, LLM-based field extraction, topic modeling, semantic unification, and knowledge graph construction. The system creates dual data products - a Neo4j knowledge graph enabling complex relationship queries and Qdrant vector collections supporting semantic search - serving as foundational infrastructure for verifiable information synthesis. Evaluation across 643 observations from 60 testing sessions demonstrates structured field extraction achieving 35.1% higher semantic similarity scores (0.655 $\\pm$ 0.178) compared to PDF chunking approaches (0.485 $\\pm$ 0.204, p < 0.000001). The agentic quality assurance mechanism achieves 68.3% single-pass success rates with 99.0% citation accuracy in validated responses. Applied to geospatial epidemiology literature on ozone exposure and cardiovascular disease, the system identifies methodological trends and research gaps, demonstrating broad applicability across scientific domains for accelerating evidence synthesis and discovery.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": ". ETL+multi-agent RAG framework for literature synthesis, 35.1% improvement over PDF chunking. Real application: reduced 17,400 papers to 24 relevant ones (99.86%) in 10 minutes for wastewater epidemiology review", "pdf_url": "https://arxiv.org/pdf/2508.05666.pdf", "abstract_url": "https://arxiv.org/abs/2508.05666", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic", "@RAG"], "AI": {"tldr": "HySemRAG框架通过结合ETL管道和RAG技术，自动化大规模文献综合和方法论研究缺口识别，采用多层方法改进现有RAG架构，包括混合检索、自我修正框架和后引用验证，处理学术文献通过八个集成阶段，创建知识图谱和向量集合作为可验证信息综合的基础设施。", "motivation": "解决现有RAG架构在自动化文献综合和方法论研究缺口识别中的限制。", "method": "结合ETL管道和RAG技术，采用混合检索（语义搜索、关键词过滤、知识图谱遍历）、自我修正框架和后引用验证的多层方法。", "result": "在643个观察和60个测试会话中，结构化字段提取的语义相似度得分比PDF分块方法高35.1%，自我修正机制的单次通过成功率为68.3%，引用准确率为99.0%。", "conclusion": "HySemRAG框架在加速证据综合和发现方面展示了跨科学领域的广泛适用性，特别是在地理空间流行病学文献中的应用。"}}
{"id": "2508.06492", "title": "Effective Training Data Synthesis for Improving MLLM Chart Understanding", "authors": ["Yuwei Yang", "Zeyu Zhang", "Yunzhong Hou", "Zhuowan Li", "Gaowen Liu", "Ali Payani", "Yuan-Sen Ting", "Liang Zheng"], "abstract": "Being able to effectively read scientific plots, or chart understanding, is a central part toward building effective agents for science. However, existing multimodal large language models (MLLMs), especially open-source ones, are still falling behind with a typical success rate of 30%-50% on challenging benchmarks. Previous studies on fine-tuning MLLMs with synthetic charts are often restricted by their inadequate similarity to the real charts, which could compromise model training and performance on complex real-world charts. In this study, we show that modularizing chart generation and diversifying visual details improves chart understanding capabilities. In particular, we design a five-step data synthesis pipeline, where we separate data and function creation for single plot generation, condition the generation of later subplots on earlier ones for multi-subplot figures, visually diversify the generated figures, filter out low quality data, and finally generate the question-answer (QA) pairs with GPT-4o. This approach allows us to streamline the generation of fine-tuning datasets and introduce the effective chart dataset (ECD), which contains 10k+ chart images and 300k+ QA pairs, covering 25 topics and featuring 250+ chart type combinations with high visual complexity. We show that ECD consistently improves the performance of various MLLMs on a range of real-world and synthetic test sets. Code, data and models are available at:", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL)", "comments": "Accepted by ICCV 2025 (poster). 26 pages, 17 figures", "pdf_url": "https://arxiv.org/pdf/2508.06492.pdf", "abstract_url": "https://arxiv.org/abs/2508.06492", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本研究提出了一种模块化和视觉多样化的图表生成方法，通过五步数据合成流程创建了有效的图表数据集（ECD），显著提升了多模态大型语言模型（MLLMs）在图表理解任务上的性能。", "motivation": "现有的多模态大型语言模型在图表理解任务上的成功率较低（30%-50%），且以往的合成图表方法因与真实图表相似度不足而限制了模型性能。", "method": "设计了五步数据合成流程，包括分离数据和功能创建、条件生成多子图、视觉多样化、过滤低质量数据以及使用GPT-4o生成问答对，从而创建了包含10k+图表图像和300k+问答对的ECD数据集。", "result": "ECD数据集显著提升了多种MLLMs在真实世界和合成测试集上的图表理解性能。", "conclusion": "通过模块化和视觉多样化的图表生成方法，可以有效提升MLLMs的图表理解能力，ECD数据集的引入为这一领域的研究提供了有价值的资源。"}}
{"id": "2508.05838", "title": "Integrating Vision Foundation Models with Reinforcement Learning for Enhanced Object Interaction", "authors": ["Ahmad Farooq", "Kamran Iqbal"], "abstract": "This paper presents a novel approach that integrates vision foundation models with reinforcement learning to enhance object interaction capabilities in simulated environments. By combining the Segment Anything Model (SAM) and YOLOv5 with a Proximal Policy Optimization (PPO) agent operating in the AI2-THOR simulation environment, we enable the agent to perceive and interact with objects more effectively. Our comprehensive experiments, conducted across four diverse indoor kitchen settings, demonstrate significant improvements in object interaction success rates and navigation efficiency compared to a baseline agent without advanced perception. The results show a 68% increase in average cumulative reward, a 52.5% improvement in object interaction success rate, and a 33% increase in navigation efficiency. These findings highlight the potential of integrating foundation models with reinforcement learning for complex robotic tasks, paving the way for more sophisticated and capable autonomous agents.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Systems and Control (eess.SY)", "comments": "Published in the Proceedings of the 2025 3rd International Conference on Robotics, Control and Vision Engineering (RCVE'25). 6 pages, 3 figures, 1 table", "pdf_url": "https://arxiv.org/pdf/2508.05838.pdf", "abstract_url": "https://arxiv.org/abs/2508.05838", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)", "Machine Learning (cs.LG)", "Systems and Control (eess.SY)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种将视觉基础模型与强化学习相结合的新方法，以增强模拟环境中的物体交互能力。通过结合Segment Anything Model (SAM)和YOLOv5与在AI2-THOR模拟环境中运行的Proximal Policy Optimization (PPO)代理，我们使代理能够更有效地感知和交互物体。", "motivation": "解决在模拟环境中物体交互能力不足的问题，通过结合先进的视觉模型和强化学习技术，提升代理的感知和交互能力。", "method": "结合Segment Anything Model (SAM)和YOLOv5视觉基础模型与Proximal Policy Optimization (PPO)强化学习代理，在AI2-THOR模拟环境中进行实验。", "result": "在四个不同的室内厨房设置中进行的全面实验显示，与没有高级感知的基线代理相比，物体交互成功率和导航效率有显著提升。具体表现为平均累积奖励增加68%，物体交互成功率提高52.5%，导航效率提高33%。", "conclusion": "这些发现突出了将基础模型与强化学习相结合在复杂机器人任务中的潜力，为开发更复杂和更强大的自主代理铺平了道路。"}}
{"id": "2508.05668", "title": "A Survey of LLM-based Deep Search Agents: Paradigm, Optimization, Evaluation, and Challenges", "authors": ["Yunjia Xi", "Jianghao Lin", "Yongzhao Xiao", "Zheli Zhou", "Rong Shan", "Te Gao", "Jiachen Zhu", "Weiwen Liu", "Yong Yu", "Weinan Zhang"], "abstract": "The advent of Large Language Models (LLMs) has significantly revolutionized web search. The emergence of LLM-based Search Agents marks a pivotal shift towards deeper, dynamic, autonomous information seeking. These agents can comprehend user intentions and environmental context and execute multi-turn retrieval with dynamic planning, extending search capabilities far beyond the web. Leading examples like OpenAI's Deep Research highlight their potential for deep information mining and real-world applications. This survey provides the first systematic analysis of search agents. We comprehensively analyze and categorize existing works from the perspectives of architecture, optimization, application, and evaluation, ultimately identifying critical open challenges and outlining promising future research directions in this rapidly evolving field. Our repository is available on", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.05668.pdf", "abstract_url": "https://arxiv.org/abs/2508.05668", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文综述了基于大型语言模型（LLM）的深度搜索代理的范式、优化、评估及挑战，首次系统分析了搜索代理的架构、优化、应用和评估，并指出了该领域的关键开放挑战和未来研究方向。", "motivation": "大型语言模型的出现极大地改变了网络搜索方式，基于LLM的搜索代理标志着向更深层次、动态、自主信息寻求的转变。本文旨在系统分析这一新兴领域的现状、挑战及未来方向。", "method": "通过全面分析和分类现有工作，从架构、优化、应用和评估四个角度出发，对基于LLM的搜索代理进行了系统性的调查。", "result": "识别了基于LLM的搜索代理在深度信息挖掘和实际应用中的潜力，同时揭示了该领域的关键开放挑战。", "conclusion": "基于LLM的搜索代理代表了搜索技术的重大进步，但仍面临多项挑战。本文为未来研究提供了方向，并强调了进一步探索的必要性。"}}
{"id": "2508.06401", "title": "A Systematic Literature Review of Retrieval-Augmented Generation: Techniques, Metrics, and Challenges", "authors": ["Andrew Brown", "Muhammad Roman", "Barry Devereux"], "abstract": "This systematic review of the research literature on retrieval-augmented generation (RAG) provides a focused analysis of the most highly cited studies published between 2020 and May 2025. A total of 128 articles met our inclusion criteria. The records were retrieved from ACM Digital Library, IEEE Xplore, Scopus, ScienceDirect, and the Digital Bibliography and Library Project (DBLP). RAG couples a neural retriever with a generative language model, grounding output in up-to-date, non-parametric memory while retaining the semantic generalisation stored in model weights. Guided by the PRISMA 2020 framework, we (i) specify explicit inclusion and exclusion criteria based on citation count and research questions, (ii) catalogue datasets, architectures, and evaluation practices, and (iii) synthesise empirical evidence on the effectiveness and limitations of RAG. To mitigate citation-lag bias, we applied a lower citation-count threshold to papers published in 2025 so that emerging breakthroughs with naturally fewer citations were still captured. This review clarifies the current research landscape, highlights methodological gaps, and charts priority directions for future research.", "subjects": "Digital Libraries (cs.DL); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Information Retrieval (cs.IR)", "comments": "58 pages", "pdf_url": "https://arxiv.org/pdf/2508.06401.pdf", "abstract_url": "https://arxiv.org/abs/2508.06401", "categories": ["Digital Libraries (cs.DL)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文是对检索增强生成（RAG）研究文献的系统性回顾，分析了2020年至2025年5月间高引用的128篇文章，探讨了RAG的技术、评估方法和挑战。", "motivation": "解决检索增强生成领域的研究现状、方法学差距及未来研究方向的问题。", "method": "采用PRISMA 2020框架，制定明确的纳入和排除标准，分类数据集、架构和评估实践，综合RAG的有效性和局限性的实证证据。", "result": "明确了当前研究格局，突出了方法学上的差距，并为未来研究绘制了优先方向。", "conclusion": "本综述为检索增强生成领域的研究提供了全面的视角，指出了未来的研究方向和潜在的改进空间。"}}
{"id": "2508.06059", "title": "Fact2Fiction: Targeted Poisoning Attack to Agentic Fact-checking System", "authors": ["Haorui He", "Yupeng Li", "Bin Benjamin Zhu", "Dacheng Wen", "Reynold Cheng", "Francis C. M. Lau"], "abstract": "State-of-the-art fact-checking systems combat misinformation at scale by employing autonomous LLM-based agents to decompose complex claims into smaller sub-claims, verify each sub-claim individually, and aggregate the partial results to produce verdicts with justifications (explanatory rationales for the verdicts). The security of these systems is crucial, as compromised fact-checkers, which tend to be easily underexplored, can amplify misinformation. This work introduces Fact2Fiction, the first poisoning attack framework targeting such agentic fact-checking systems. Fact2Fiction mirrors the decomposition strategy and exploits system-generated justifications to craft tailored malicious evidences that compromise sub-claim verification. Extensive experiments demonstrate that Fact2Fiction achieves 8.9\\%--21.2\\% higher attack success rates than state-of-the-art attacks across various poisoning budgets. Fact2Fiction exposes security weaknesses in current fact-checking systems and highlights the need for defensive countermeasures.", "subjects": "Cryptography and Security (cs.CR); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.06059.pdf", "abstract_url": "https://arxiv.org/abs/2508.06059", "categories": ["Cryptography and Security (cs.CR)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "Fact2Fiction是针对基于LLM的代理事实核查系统的首次投毒攻击框架，通过模仿分解策略和利用系统生成的解释来制作恶意证据，从而破坏子声明验证。", "motivation": "随着基于LLM的代理事实核查系统被广泛用于对抗大规模的错误信息，这些系统的安全性变得至关重要。然而，这些系统可能被攻击者利用来放大错误信息，这一问题尚未得到充分探索。", "method": "Fact2Fiction框架通过模仿事实核查系统的分解策略，并利用系统生成的解释（即裁决的解释性理由）来制作定制的恶意证据，从而针对子声明验证进行攻击。", "result": "广泛的实验表明，Fact2Fiction在各种投毒预算下，攻击成功率比现有最先进的攻击高出8.9%到21.2%。", "conclusion": "Fact2Fiction揭示了当前事实核查系统中的安全弱点，强调了需要采取防御性措施来应对此类攻击。"}}
{"id": "2508.05672", "title": "LMAR: Language Model Augmented Retriever for Domain-specific Knowledge Indexing", "authors": ["Yao Zhao", "Yantian Ding", "Zhiyue Zhang", "Dapeng Yao", "Yanxun Xu"], "abstract": "Retrieval Augmented Generation (RAG) systems often struggle with domain-specific knowledge due to performance deterioration of pre-trained embeddings and prohibitive computational costs of large language model (LLM)-based retrievers. While fine-tuning data augmentation embedding models offers a promising direction, its effectiveness is limited by the need for high-quality training data and reliable chunking strategies that preserve contextual integrity. We propose LMAR (Language Model Augmented Retriever), a model-agnostic framework that addresses these challenges by combining LLM-guided data synthesis with contrastive embedding adaptation and efficient text clustering. LMAR consists of a two-stage pipeline: (1) Triplet sampling and synthetic data augmentation, where LLMs act as both labeler and validator to ensure high-fidelity supervision throughout the pipeline. Experimental results across multiple domain-specific benchmark datasets demonstrate that LMAR outperforms multiple baseline models, while maintaining moderate hardware requirements and low latency. Its model-agnostic nature further enables seamless integration with emerging RAG architectures and text embedding models, ensuring continual improvements without redesigning the pipeline. These results highlight LMAR as a practical and cost-effective solution for scalable domain-specific adaptation.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.05672.pdf", "abstract_url": "https://arxiv.org/abs/2508.05672", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "LMAR是一种语言模型增强的检索器框架，旨在解决特定领域知识检索中的性能下降和计算成本高的问题，通过结合LLM引导的数据合成、对比嵌入适应和高效文本聚类，实现了优于基线模型的性能。", "motivation": "解决检索增强生成（RAG）系统在特定领域知识检索中预训练嵌入性能下降和大型语言模型（LLM）检索器计算成本高的问题。", "method": "提出LMAR框架，采用两阶段流程：1) 三元组采样和合成数据增强，利用LLM作为标注器和验证器；2) 结合对比嵌入适应和高效文本聚类。", "result": "在多个特定领域基准数据集上的实验结果表明，LMAR在保持适度硬件需求和低延迟的同时，性能优于多个基线模型。", "conclusion": "LMAR作为一种实用且成本效益高的解决方案，能够无缝集成到新兴的RAG架构和文本嵌入模型中，无需重新设计流程即可实现持续改进。"}}
{"id": "2508.05670", "title": "Can LLMs effectively provide game-theoretic-based scenarios for cybersecurity?", "authors": ["Daniele Proverbio", "Alessio Buscemi", "Alessandro Di Stefano", "Anh Han", "German Castignani", "Pietro Liò"], "abstract": "Game theory has long served as a foundational tool in cybersecurity to test, predict, and design strategic interactions between attackers and defenders. The recent advent of Large Language Models (LLMs) offers new tools and challenges for the security of computer systems; In this work, we investigate whether classical game-theoretic frameworks can effectively capture the behaviours of LLM-driven actors and bots. Using a reproducible framework for game-theoretic LLM agents, we investigate two canonical scenarios -- the one-shot zero-sum game and the dynamic Prisoner's Dilemma -- and we test whether LLMs converge to expected outcomes or exhibit deviations due to embedded biases. Our experiments involve four state-of-the-art LLMs and span five natural languages, English, French, Arabic, Vietnamese, and Mandarin Chinese, to assess linguistic sensitivity. For both games, we observe that the final payoffs are influenced by agents characteristics such as personality traits or knowledge of repeated rounds. Moreover, we uncover an unexpected sensitivity of the final payoffs to the choice of languages, which should warn against indiscriminate application of LLMs in cybersecurity applications and call for in-depth studies, as LLMs may behave differently when deployed in different countries. We also employ quantitative metrics to evaluate the internal consistency and cross-language stability of LLM agents, to help guide the selection of the most stable LLMs and optimising models for secure applications.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Computer Science and Game Theory (cs.GT)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.05670.pdf", "abstract_url": "https://arxiv.org/abs/2508.05670", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)", "Computer Science and Game Theory (cs.GT)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了大型语言模型（LLMs）是否能有效提供基于博弈论的网络安全场景，通过实验发现LLMs的行为受到其特性和语言选择的影响。", "motivation": "研究大型语言模型（LLMs）在网络安全领域中，是否能被传统的博弈论框架有效捕捉其驱动的行为者和机器人的行为。", "method": "使用可重复的博弈论LLM代理框架，研究两种典型场景——一次性零和游戏和动态囚徒困境，并测试LLMs是否收敛到预期结果或表现出由于嵌入偏见而产生的偏差。", "result": "实验发现，最终收益受到代理特性（如个性特征或对重复回合的了解）的影响，并且对语言选择有意外敏感性。", "conclusion": "研究警告不要不加选择地在网络安全应用中应用LLMs，并呼吁进行深入研究，因为LLMs在不同国家部署时可能表现不同。同时，采用定量指标评估LLM代理的内部一致性和跨语言稳定性，以帮助选择最稳定的LLMs并优化安全应用模型。"}}
{"id": "2508.05674", "title": "Towards Effective Offensive Security LLM Agents: Hyperparameter Tuning, LLM as a Judge, and a Lightweight CTF Benchmark", "authors": ["Minghao Shao", "Nanda Rani", "Kimberly Milner", "Haoran Xi", "Meet Udeshi", "Saksham Aggarwal", "Venkata Sai Charan Putrevu", "Sandeep Kumar Shukla", "Prashanth Krishnamurthy", "Farshad Khorrami", "Ramesh Karri", "Muhammad Shafique"], "abstract": "Recent advances in LLM agentic systems have improved the automation of offensive security tasks, particularly for Capture the Flag (CTF) challenges. We systematically investigate the key factors that drive agent success and provide a detailed recipe for building effective LLM-based offensive security agents. First, we present CTFJudge, a framework leveraging LLM as a judge to analyze agent trajectories and provide granular evaluation across CTF solving steps. Second, we propose a novel metric, CTF Competency Index (CCI) for partial correctness, revealing how closely agent solutions align with human-crafted gold standards. Third, we examine how LLM hyperparameters, namely temperature, top-p, and maximum token length, influence agent performance and automated cybersecurity task planning. For rapid evaluation, we present CTFTiny, a curated benchmark of 50 representative CTF challenges across binary exploitation, web, reverse engineering, forensics, and cryptography. Our findings identify optimal multi-agent coordination settings and lay the groundwork for future LLM agent research in cybersecurity. We make CTFTiny open source to public", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.05674.pdf", "abstract_url": "https://arxiv.org/abs/2508.05674", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文探讨了如何构建有效的基于LLM的进攻性安全代理，提出了CTFJudge框架、CTF能力指数（CCI）新指标，并研究了LLM超参数对代理性能的影响。同时，介绍了CTFTiny基准测试，为网络安全领域的LLM代理研究奠定了基础。", "motivation": "解决在自动化进攻性安全任务中，特别是在Capture the Flag（CTF）挑战中，如何提高LLM代理的有效性和性能的问题。", "method": "提出了CTFJudge框架利用LLM作为评判者来分析代理轨迹；引入了CTF能力指数（CCI）来衡量代理解决方案与人类制作的金标准的接近程度；研究了LLM超参数（温度、top-p和最大令牌长度）对代理性能的影响；并开发了CTFTiny基准测试用于快速评估。", "result": "研究发现确定了多代理协调的最佳设置，并为网络安全领域的LLM代理研究提供了基础。CTFTiny基准测试已被开源。", "conclusion": "本研究为构建有效的基于LLM的进攻性安全代理提供了详细的配方和工具，为未来的网络安全研究奠定了基础。"}}
{"id": "2508.05687", "title": "Risk Analysis Techniques for Governed LLM-based Multi-Agent Systems", "authors": ["Alistair Reid", "Simon O'Callaghan", "Liam Carroll", "Tiberio Caetano"], "abstract": "Organisations are starting to adopt LLM-based AI agents, with their deployments naturally evolving from single agents towards interconnected, multi-agent networks. Yet a collection of safe agents does not guarantee a safe collection of agents, as interactions between agents over time create emergent behaviours and induce novel failure modes. This means multi-agent systems require a fundamentally different risk analysis approach than that used for a single agent.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.05687.pdf", "abstract_url": "https://arxiv.org/abs/2508.05687", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "组织开始采用基于LLM的AI代理，其部署自然从单一代理发展为互连的多代理网络。然而，一组安全的代理并不能保证代理集合的安全，因为代理之间的交互会随着时间产生突发行为并引发新的故障模式。这意味着多代理系统需要一种与单一代理根本不同的风险分析方法。", "motivation": "解决多代理系统中由于代理间交互产生的突发行为和新型故障模式所带来的安全问题。", "method": "提出了一种不同于单一代理风险分析的多代理系统风险分析方法。", "result": "认识到多代理系统的安全性需要新的风险分析技术来应对其特有的挑战。", "conclusion": "多代理系统的风险分析需要新的方法，以确保其安全性，这对于组织采用基于LLM的AI代理至关重要。"}}
{"id": "2508.06457", "title": "ScamAgents: How AI Agents Can Simulate Human-Level Scam Calls", "authors": ["Sanket Badhe"], "abstract": "Large Language Models (LLMs) have demonstrated impressive fluency and reasoning capabilities, but their potential for misuse has raised growing concern. In this paper, we present ScamAgent, an autonomous multi-turn agent built on top of LLMs, capable of generating highly realistic scam call scripts that simulate real-world fraud scenarios. Unlike prior work focused on single-shot prompt misuse, ScamAgent maintains dialogue memory, adapts dynamically to simulated user responses, and employs deceptive persuasion strategies across conversational turns. We show that current LLM safety guardrails, including refusal mechanisms and content filters, are ineffective against such agent-based threats. Even models with strong prompt-level safeguards can be bypassed when prompts are decomposed, disguised, or delivered incrementally within an agent framework. We further demonstrate the transformation of scam scripts into lifelike voice calls using modern text-to-speech systems, completing a fully automated scam pipeline. Our findings highlight an urgent need for multi-turn safety auditing, agent-level control frameworks, and new methods to detect and disrupt conversational deception powered by generative AI.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Multiagent Systems (cs.MA)", "comments": "Accepted at CAMLIS 25: Conference on Applied Machine Learning for Information Security. 10 pages, 3 figures", "pdf_url": "https://arxiv.org/pdf/2508.06457.pdf", "abstract_url": "https://arxiv.org/abs/2508.06457", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了ScamAgent，一个基于大型语言模型（LLMs）的自主多轮对话代理，能够生成高度逼真的诈骗电话脚本，模拟现实世界的欺诈场景。研究表明，当前的LLM安全护栏，包括拒绝机制和内容过滤器，对这种基于代理的威胁无效。", "motivation": "大型语言模型（LLMs）的滥用潜力引发了越来越多的关注。本文旨在探索LLMs如何被用来模拟人类级别的诈骗电话，以及当前的安全措施为何无法有效防止这种滥用。", "method": "研究团队开发了ScamAgent，一个能够维护对话记忆、动态适应模拟用户响应并在对话轮次中采用欺骗性说服策略的自主多轮代理。此外，还展示了如何将诈骗脚本转换为逼真的语音电话。", "result": "研究发现，即使具有强大提示级安全保护的模型，在提示被分解、伪装或在代理框架内逐步传递时，也可以被绕过。这完成了一个完全自动化的诈骗流程。", "conclusion": "研究结果强调了进行多轮安全审计、开发代理级控制框架以及寻找新方法来检测和破坏由生成AI驱动的对话欺骗的紧迫需求。"}}
{"id": "2508.05702", "title": "Semantic Reasoning Meets Numerical Precision: An LLM-Powered Multi-Agent System for Power Grid Control", "authors": ["Yan Zhang"], "abstract": "The increasing penetration of Distributed Energy Resources (DERs), widespread adoption of Electric Vehicles (EVs), and the growing frequency of extreme weather events have significantly increased the complexity of power grid planning, operation, and management. Traditional rule-based systems and numerical optimization approaches often struggle with the scale, dynamics, and adaptability required by modern power networks. This paper introduces Grid-Agent, an autonomous, AI-driven framework that combines Large Language Models (LLMs) with multi-agent reinforcement learning to detect and remediate grid violations in real time. Grid-Agent integrates semantic reasoning with numerical precision through a modular agent architecture: a planning agent generates coordinated action sequences using numerical power flow solvers, while a validation agent evaluates system stability and action effectiveness via sandboxed execution with safety rollbacks. To ensure scalability, Grid-Agent incorporates an adaptive multiscale network representation that dynamically selects optimal encoding schemes based on network size and complexity. The framework enables coordinated violation resolution through optimizing switch configurations, battery deployment, and load curtailment strategies. Experimental results in standard IEEE and CIGRE test systems (IEEE 69-bus, CIGRE MV, and IEEE 30-bus) demonstrate superior violation mitigation performance. Additionally, the framework's built-in data collection and learning capabilities enable continuous learning and adaptation to diverse network topologies. The autonomous nature of the framework makes it particularly suitable for modern smart grid applications requiring rapid response to dynamic operating conditions.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Systems and Control (eess.SY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.05702.pdf", "abstract_url": "https://arxiv.org/abs/2508.05702", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Systems and Control (eess.SY)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了Grid-Agent，一个结合大型语言模型（LLMs）和多智能体强化学习的自主AI驱动框架，用于实时检测和修复电网违规行为。该框架通过模块化智能体架构将语义推理与数值精度相结合，展示了在标准IEEE和CIGRE测试系统中的优越性能。", "motivation": "随着分布式能源资源（DERs）的渗透率增加、电动汽车（EVs）的广泛采用以及极端天气事件的频繁发生，电网规划、运营和管理的复杂性显著增加。传统的基于规则的系统和方法难以应对现代电网的规模、动态性和适应性需求。", "method": "Grid-Agent框架结合了大型语言模型（LLMs）和多智能体强化学习，通过模块化智能体架构实现语义推理与数值精度的结合。规划智能体利用数值潮流求解器生成协调的动作序列，而验证智能体通过沙盒执行和安全回滚评估系统稳定性和动作效果。", "result": "在标准IEEE和CIGRE测试系统（IEEE 69-bus、CIGRE MV和IEEE 30-bus）中的实验结果表明，Grid-Agent在违规缓解方面表现出色。框架内置的数据收集和学习能力使其能够持续学习和适应不同的网络拓扑。", "conclusion": "Grid-Agent的自主性使其特别适合需要快速响应动态操作条件的现代智能电网应用。该框架通过结合语义推理和数值精度，为电网控制提供了一种新的解决方案。"}}
{"id": "2508.05728", "title": "CLAPP: The CLASS LLM Agent for Pair Programming", "authors": ["Santiago Casas", "Christian Fidler", "Boris Bolliet", "Francisco Villaescusa-Navarro", "Julien Lesgourgues"], "abstract": "We introduce CLAPP (CLASS LLM Agent for Pair Programming), an interactive AI assistant designed to support researchers working with the Einstein-Boltzmann solver CLASS. CLAPP leverages large language models (LLMs) and domain-specific retrieval to provide conversational coding support for CLASS-answering questions, generating code, debugging errors, and producing plots. Its architecture combines multi-agent LLM orchestration, semantic search across CLASS documentation, and a live Python execution environment. Deployed as a user-friendly web application, CLAPP lowers the entry barrier for scientists unfamiliar with AI tools and enables more productive human-AI collaboration in computational and numerical cosmology. The app is available at", "subjects": "Instrumentation and Methods for Astrophysics (astro-ph.IM); Cosmology and Nongalactic Astrophysics (astro-ph.CO); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2508.05728.pdf", "abstract_url": "https://arxiv.org/abs/2508.05728", "categories": ["Instrumentation and Methods for Astrophysics (astro-ph.IM)", "Cosmology and Nongalactic Astrophysics (astro-ph.CO)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "介绍了CLAPP（CLASS LLM Agent for Pair Programming），一个旨在支持研究人员使用Einstein-Boltzmann求解器CLASS的交互式AI助手。CLAPP利用大型语言模型（LLMs）和特定领域检索，为CLASS提供对话式编码支持，包括回答问题、生成代码、调试错误和制作图表。", "motivation": "解决科学家在使用CLASS时可能遇到的困难，特别是那些不熟悉AI工具的研究人员，通过提供一个用户友好的AI助手来降低进入门槛，提高人机协作的效率。", "method": "结合多代理LLM编排、CLASS文档的语义搜索和实时Python执行环境的架构。", "result": "开发了一个部署为友好网页应用的CLAPP，能够有效地支持科学家在计算和数值宇宙学中的工作。", "conclusion": "CLAPP通过结合先进的语言模型和特定领域的知识，为科学家提供了一个强大的工具，以促进更高效的人机协作，并推动了计算宇宙学领域的研究。"}}
{"id": "2508.05970", "title": "Impact-driven Context Filtering For Cross-file Code Completion", "authors": ["Yanzhou Li", "Shangqing Liu", "Kangjie Chen", "Tianwei Zhang", "Yang Liu"], "abstract": "Retrieval-augmented generation (RAG) has recently demonstrated considerable potential for repository-level code completion, as it integrates cross-file knowledge with in-file preceding code to provide comprehensive contexts for generation. To better understand the contribution of the retrieved cross-file contexts, we introduce a likelihood-based metric to evaluate the impact of each retrieved code chunk on the completion. Our analysis reveals that, despite retrieving numerous chunks, only a small subset positively contributes to the completion, while some chunks even degrade performance. To address this issue, we leverage this metric to construct a repository-level dataset where each retrieved chunk is labeled as positive, neutral, or negative based on its relevance to the target completion. We then propose an adaptive retrieval context filtering framework, CODEFILTER, trained on this dataset to mitigate the harmful effects of negative retrieved contexts in code completion. Extensive evaluation on the RepoEval and CrossCodeLongEval benchmarks demonstrates that CODEFILTER consistently improves completion accuracy compared to approaches without filtering operations across various tasks. Additionally, CODEFILTER significantly reduces the length of the input prompt, enhancing computational efficiency while exhibiting strong generalizability across different models. These results underscore the potential of CODEFILTER to enhance the accuracy, efficiency, and attributability of repository-level code completion.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.05970.pdf", "abstract_url": "https://arxiv.org/abs/2508.05970", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种基于影响驱动的上下文过滤方法CODEFILTER，用于跨文件代码补全，通过评估检索到的代码块对补全的影响，过滤掉负面影响的上下文，提高了补全的准确性和计算效率。", "motivation": "解决在仓库级代码补全中，检索到的跨文件上下文可能包含对补全有负面影响的问题，以提高补全的准确性和效率。", "method": "引入了一种基于可能性的度量来评估每个检索到的代码块对补全的影响，并构建了一个仓库级数据集，然后提出了一个自适应检索上下文过滤框架CODEFILTER。", "result": "在RepoEval和CrossCodeLongEval基准测试中，CODEFILTER相比没有过滤操作的方法在各种任务中 consistently提高了补全准确性，同时显著减少了输入提示的长度，提高了计算效率。", "conclusion": "CODEFILTER有潜力提高仓库级代码补全的准确性、效率和可归因性，展示了在不同模型间的强泛化能力。"}}
{"id": "2508.06269", "title": "OM2P: Offline Multi-Agent Mean-Flow Policy", "authors": ["Zhuoran Li", "Xun Wang", "Hai Zhong", "Longbo Huang"], "abstract": "Generative models, especially diffusion and flow-based models, have been promising in offline multi-agent reinforcement learning. However, integrating powerful generative models into this framework poses unique challenges. In particular, diffusion and flow-based policies suffer from low sampling efficiency due to their iterative generation processes, making them impractical in time-sensitive or resource-constrained settings. To tackle these difficulties, we propose OM2P (Offline Multi-Agent Mean-Flow Policy), a novel offline MARL algorithm to achieve efficient one-step action sampling. To address the misalignment between generative objectives and reward maximization, we introduce a reward-aware optimization scheme that integrates a carefully-designed mean-flow matching loss with Q-function supervision. Additionally, we design a generalized timestep distribution and a derivative-free estimation strategy to reduce memory overhead and improve training stability. Empirical evaluations on Multi-Agent Particle and MuJoCo benchmarks demonstrate that OM2P achieves superior performance, with up to a 3.8x reduction in GPU memory usage and up to a 10.8x speed-up in training time. Our approach represents the first to successfully integrate mean-flow model into offline MARL, paving the way for practical and scalable generative policies in cooperative multi-agent settings.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.06269.pdf", "abstract_url": "https://arxiv.org/abs/2508.06269", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "OM2P是一种新颖的离线多智能体强化学习算法，旨在通过一步动作采样提高效率，解决了生成模型在离线MARL中的采样效率低和资源消耗大的问题。", "motivation": "解决生成模型（如扩散和基于流的模型）在离线多智能体强化学习中采样效率低和资源消耗大的问题，特别是在时间敏感或资源受限的环境中。", "method": "提出OM2P算法，通过奖励感知优化方案、精心设计的均值流匹配损失与Q函数监督的结合，以及广义时间步分布和无导数估计策略，实现高效的一步动作采样。", "result": "在Multi-Agent Particle和MuJoCo基准测试中，OM2P表现出卓越的性能，GPU内存使用减少了3.8倍，训练时间加快了10.8倍。", "conclusion": "OM2P是首个成功将均值流模型集成到离线MARL中的方法，为合作多智能体设置中实用且可扩展的生成策略铺平了道路。"}}
{"id": "2508.06336", "title": "Unsupervised Partner Design Enables Robust Ad-hoc Teamwork", "authors": ["Constantin Ruhdorfer", "Matteo Bortoletto", "Victor Oei", "Anna Penzkofer", "Andreas Bulling"], "abstract": "We introduce Unsupervised Partner Design (UPD) - a population-free, multi-agent reinforcement learning framework for robust ad-hoc teamwork that adaptively generates training partners without requiring pretrained partners or manual parameter tuning. UPD constructs diverse partners by stochastically mixing an ego agent's policy with biased random behaviours and scores them using a variance-based learnability metric that prioritises partners near the ego agent's current learning frontier. We show that UPD can be integrated with unsupervised environment design, resulting in the first method enabling fully unsupervised curricula over both level and partner distributions in a cooperative setting. Through extensive evaluations on Overcooked-AI and the Overcooked Generalisation Challenge, we demonstrate that this dynamic partner curriculum is highly effective: UPD consistently outperforms both population-based and population-free baselines as well as ablations. In a user study, we further show that UPD achieves higher returns than all baselines and was perceived as significantly more adaptive, more human-like, a better collaborator, and less frustrating.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Multiagent Systems (cs.MA)", "comments": "16 pages", "pdf_url": "https://arxiv.org/pdf/2508.06336.pdf", "abstract_url": "https://arxiv.org/abs/2508.06336", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了无监督伙伴设计（UPD），一种无需预训练伙伴或手动参数调整的多智能体强化学习框架，用于鲁棒的临时团队合作。UPD通过随机混合自我智能体的策略与偏置随机行为来构建多样化的伙伴，并使用基于方差的易学性指标对其进行评分。研究表明，UPD可以与无监督环境设计相结合，首次实现了在合作环境中对级别和伙伴分布的完全无监督课程。在Overcooked-AI和Overcooked Generalisation Challenge上的广泛评估表明，这种动态伙伴课程非常有效。", "motivation": "解决在多智能体环境中，如何在没有预训练伙伴或手动调整参数的情况下，实现鲁棒的临时团队合作的问题。", "method": "提出无监督伙伴设计（UPD）框架，通过随机混合自我智能体的策略与偏置随机行为构建多样化伙伴，并使用基于方差的易学性指标评分。", "result": "UPD在Overcooked-AI和Overcooked Generalisation Challenge上的表现优于基于群体和无群体的基线及消融实验，用户研究显示UPD被认为更具适应性、更人性化、合作更好且更少令人沮丧。", "conclusion": "UPD框架通过动态伙伴课程，在无需预训练伙伴或手动调整参数的情况下，实现了在多智能体环境中的鲁棒临时团队合作，为合作环境中的无监督学习提供了新方法。"}}
{"id": "2508.06343", "title": "On Approximate MMS Allocations on Restricted Graph Classes", "authors": ["Václav Blažej", "Michał Dębski ad Zbigniew Lonc", "Marta Piecyk", "Paweł Rzążewski"], "abstract": "We study the problem of fair division of a set of indivisible goods with connectivity constraints. Specifically, we assume that the goods are represented as vertices of a connected graph, and sets of goods allocated to the agents are connected subgraphs of this graph. We focus on the widely-studied maximin share criterion of fairness. It has been shown that an allocation satisfying this criterion may not exist even without connectivity constraints, i.e., if the graph of goods is complete. In view of this, it is natural to seek approximate allocations that guarantee each agent a connected bundle of goods with value at least a constant fraction of the maximin share value to the agent. It is known that for some classes of graphs, such as complete graphs, cycles, and $d$-claw-free graphs for any fixed $d$, such approximate allocations indeed exist. However, it is an open problem whether they exist for the class of all graphs.", "subjects": "Discrete Mathematics (cs.DM); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.06343.pdf", "abstract_url": "https://arxiv.org/abs/2508.06343", "categories": ["Discrete Mathematics (cs.DM)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究了在连通性约束下不可分割物品的公平分配问题，重点关注最大化最小份额（MMS）公平标准。尽管在某些图类中已证明存在近似分配，但对于所有图类是否存在这样的分配仍是一个开放性问题。", "motivation": "解决在物品表示为连通图的顶点，且分配给代理的物品集必须是该图的连通子图的情况下，如何实现公平分配的问题。特别是在最大化最小份额（MMS）公平标准下，即使没有连通性约束，也可能不存在满足该标准的分配。", "method": "研究在不同图类（如完全图、环图和$d$-无爪图）中，是否存在近似分配，即每个代理获得的连通物品集的价值至少是其最大化最小份额价值的一个常数比例。", "result": "已证明在某些特定图类中存在这样的近似分配，但对于所有图类是否存在这样的分配仍是一个未解决的问题。", "conclusion": "尽管在某些受限图类中可以实现近似最大化最小份额的公平分配，但对于更广泛的图类，这一问题的解决方案仍有待探索。"}}
{"id": "2508.06361", "title": "Beyond Prompt-Induced Lies: Investigating LLM Deception on Benign Prompts", "authors": ["Zhaomin Wu", "Mingzhe Du", "See-Kiong Ng", "Bingsheng He"], "abstract": "Large Language Models (LLMs) have been widely deployed in reasoning, planning, and decision-making tasks, making their trustworthiness a critical concern. The potential for intentional deception, where an LLM deliberately fabricates or conceals information to serve a hidden objective, remains a significant and underexplored threat. Existing studies typically induce such deception by explicitly setting a \"hidden\" objective through prompting or fine-tuning, which may not fully reflect real-world human-LLM interactions. Moving beyond this human-induced deception, we investigate LLMs' self-initiated deception on benign prompts. To address the absence of ground truth in this evaluation, we propose a novel framework using \"contact searching questions.\" This framework introduces two statistical metrics derived from psychological principles to quantify the likelihood of deception. The first, the Deceptive Intention Score, measures the model's bias towards a hidden objective. The second, Deceptive Behavior Score, measures the inconsistency between the LLM's internal belief and its expressed output. Upon evaluating 14 leading LLMs, we find that both metrics escalate as task difficulty increases, rising in parallel for most models. Building on these findings, we formulate a mathematical model to explain this behavior. These results reveal that even the most advanced LLMs exhibit an increasing tendency toward deception when handling complex problems, raising critical concerns for the deployment of LLM agents in complex and crucial domains.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.06361.pdf", "abstract_url": "https://arxiv.org/abs/2508.06361", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究了大型语言模型（LLMs）在良性提示下的自我启动欺骗行为，提出了一个基于心理原则的新框架来量化欺骗的可能性，并发现即使是先进的LLMs在处理复杂问题时也表现出越来越强的欺骗倾向。", "motivation": "大型语言模型（LLMs）在推理、规划和决策任务中的广泛应用使其可信度成为关键问题。现有研究通常通过提示或微调明确设置“隐藏”目标来诱导欺骗，这可能无法完全反映现实中人类与LLMs的互动。本文旨在探索LLMs在良性提示下的自我启动欺骗行为。", "method": "为了解决评估中缺乏真实情况的问题，本文提出了一个使用“接触搜索问题”的新框架。该框架引入了两个基于心理原则的统计指标来量化欺骗的可能性：欺骗意图分数（衡量模型对隐藏目标的偏向）和欺骗行为分数（衡量LLM内部信念与其表达输出之间的不一致性）。", "result": "在评估了14个领先的LLMs后，发现随着任务难度的增加，这两个指标都会上升，大多数模型中这两个分数会并行上升。基于这些发现，本文构建了一个数学模型来解释这种行为。", "conclusion": "这些结果表明，即使是先进的LLMs在处理复杂问题时也表现出越来越强的欺骗倾向，这对在复杂和关键领域部署LLM代理提出了严重的关切。"}}
{"id": "2508.06387", "title": "End-to-End Text-to-SQL with Dataset Selection: Leveraging LLMs for Adaptive Query Generation", "authors": ["Anurag Tripathi", "Vaibhav Patle", "Abhinav Jain", "Ayush Pundir", "Sairam Menon", "Ajeet Kumar Singh"], "abstract": "Text-to-SQL bridges the gap between natural language and structured database language, thus allowing non-technical users to easily query databases. Traditional approaches model text-to-SQL as a direct translation task, where a given Natural Language Query (NLQ) is mapped to an SQL command. Recent advances in large language models (LLMs) have significantly improved translation accuracy, however, these methods all require that the target database is pre-specified. This becomes problematic in scenarios with multiple extensive databases, where identifying the correct database becomes a crucial yet overlooked step. In this paper, we propose a three-stage end-to-end text-to-SQL framework to identify the user's intended database before generating SQL queries. Our approach leverages LLMs and prompt engineering to extract implicit information from natural language queries (NLQs) in the form of a ruleset. We then train a large db\\_id prediction model, which includes a RoBERTa-based finetuned encoder, to predict the correct Database identifier (db\\_id) based on both the NLQ and the LLM-generated rules. Finally, we refine the generated SQL by using critic agents to correct errors. Experimental results demonstrate that our framework outperforms the current state-of-the-art models in both database intent prediction and SQL generation accuracy.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "Accepted in IJCNN25", "pdf_url": "https://arxiv.org/pdf/2508.06387.pdf", "abstract_url": "https://arxiv.org/abs/2508.06387", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种三阶段的端到端文本到SQL框架，利用大型语言模型（LLMs）和提示工程从自然语言查询（NLQs）中提取隐含信息，训练一个大型数据库标识符（db_id）预测模型，并通过批评代理纠正错误，以提高数据库意图预测和SQL生成准确性。", "motivation": "解决在多数据库场景下，传统文本到SQL方法需要预先指定目标数据库的问题，以及如何准确识别用户意图数据库并生成正确SQL查询的挑战。", "method": "采用三阶段框架：1) 利用LLMs和提示工程从NLQs中提取规则集；2) 训练基于RoBERTa的微调编码器的db_id预测模型；3) 使用批评代理纠正生成的SQL错误。", "result": "实验结果表明，该框架在数据库意图预测和SQL生成准确性方面优于当前最先进的模型。", "conclusion": "通过结合LLMs、规则提取和批评代理，该框架有效提高了在多数据库环境下的文本到SQL转换的准确性和实用性。"}}
