{"id": "2509.03536", "title": "PG-Agent: An Agent Powered by Page Graph", "authors": ["Weizhi Chen", "Ziwei Wang", "Leyang Yang", "Sheng Zhou", "Xiaoxuan Tang", "Jiajun Bu", "Yong Li", "Wei Jiang"], "abstract": "Graphical User Interface (GUI) agents possess significant commercial and social value, and GUI agents powered by advanced multimodal large language models (MLLMs) have demonstrated remarkable potential. Currently, existing GUI agents usually utilize sequential episodes of multi-step operations across pages as the prior GUI knowledge, which fails to capture the complex transition relationship between pages, making it challenging for the agents to deeply perceive the GUI environment and generalize to new scenarios. Therefore, we design an automated pipeline to transform the sequential episodes into page graphs, which explicitly model the graph structure of the pages that are naturally connected by actions. To fully utilize the page graphs, we further introduce Retrieval-Augmented Generation (RAG) technology to effectively retrieve reliable perception guidelines of GUI from them, and a tailored multi-agent framework PG-Agent with task decomposition strategy is proposed to be injected with the guidelines so that it can generalize to unseen scenarios. Extensive experiments on various benchmarks demonstrate the effectiveness of PG-Agent, even with limited episodes for page graph construction.", "subjects": "Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)", "comments": "Paper accepted to ACM MM 2025", "pdf_url": "https://arxiv.org/pdf/2509.03536.pdf", "abstract_url": "https://arxiv.org/abs/2509.03536", "categories": ["Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "PG-Agent是一种基于页面图的GUI代理，通过将序列操作转换为图结构，并利用RAG技术和多代理框架，提高了在未见场景中的泛化能力。", "motivation": "现有GUI代理依赖序列操作作为先验知识，无法捕捉页面间复杂转换关系，导致难以深度感知环境和泛化到新场景。", "method": "设计自动化管道将序列操作转换为页面图，引入RAG技术检索可靠感知指南，并开发多代理框架PG-Agent进行任务分解。", "result": "在多个基准测试中，PG-Agent表现出高效性，即使使用有限序列构建页面图。", "conclusion": "页面图和RAG技术能显著提升GUI代理的感知和泛化能力，具有实际应用价值。"}}
{"id": "2509.03704", "title": "QuantV2X: A Fully Quantized Multi-Agent System for Cooperative Perception", "authors": ["Seth Z. Zhao", "Huizhi Zhang", "Zhaowei Li", "Juntong Peng", "Anthony Chui", "Zewei Zhou", "Zonglin Meng", "Hao Xiang", "Zhiyu Huang", "Fujia Wang", "Ran Tian", "Chenfeng Xu", "Bolei Zhou", "Jiaqi Ma"], "abstract": "Cooperative perception through Vehicle-to-Everything (V2X) communication offers significant potential for enhancing vehicle perception by mitigating occlusions and expanding the field of view. However, past research has predominantly focused on improving accuracy metrics without addressing the crucial system-level considerations of efficiency, latency, and real-world deployability. Noticeably, most existing systems rely on full-precision models, which incur high computational and transmission costs, making them impractical for real-time operation in resource-constrained environments. In this paper, we introduce \\textbf{QuantV2X}, the first fully quantized multi-agent system designed specifically for efficient and scalable deployment of multi-modal, multi-agent V2X cooperative perception. QuantV2X introduces a unified end-to-end quantization strategy across both neural network models and transmitted message representations that simultaneously reduces computational load and transmission bandwidth. Remarkably, despite operating under low-bit constraints, QuantV2X achieves accuracy comparable to full-precision systems. More importantly, when evaluated under deployment-oriented metrics, QuantV2X reduces system-level latency by 3.2$\\times$ and achieves a +9.5 improvement in mAP30 over full-precision baselines. Furthermore, QuantV2X scales more effectively, enabling larger and more capable models to fit within strict memory budgets. These results highlight the viability of a fully quantized multi-agent intermediate fusion system for real-world deployment. The system will be publicly released to promote research in this field:", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03704.pdf", "abstract_url": "https://arxiv.org/abs/2509.03704", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "QuantV2X是首个全量化多智能体系统，用于高效可扩展的多模态V2X协同感知部署，在低比特约束下实现与全精度系统相当的准确性，并显著降低延迟和带宽。", "motivation": "解决V2X协同感知中现有系统因依赖全精度模型导致的高计算和传输成本问题，提高效率、延迟和实际部署可行性。", "method": "采用端到端统一量化策略，对神经网络模型和传输消息表示进行量化，以减少计算负载和传输带宽。", "result": "系统级延迟降低3.2倍，mAP30提高9.5，在低比特下保持准确性，并更有效地扩展以适应内存限制。", "conclusion": "全量化多智能体中间融合系统在实际部署中可行，将公开发布以推动相关研究。"}}
{"id": "2509.03550", "title": "Diffusion-RL Based Air Traffic Conflict Detection and Resolution Method", "authors": ["Tonghe Li", "Jixin Liu", "Weili Zeng", "Hao Jiang"], "abstract": "In the context of continuously rising global air traffic, efficient and safe Conflict Detection and Resolution (CD&R) is paramount for air traffic management. Although Deep Reinforcement Learning (DRL) offers a promising pathway for CD&R automation, existing approaches commonly suffer from a \"unimodal bias\" in their policies. This leads to a critical lack of decision-making flexibility when confronted with complex and dynamic constraints, often resulting in \"decision deadlocks.\" To overcome this limitation, this paper pioneers the integration of diffusion probabilistic models into the safety-critical task of CD&R, proposing a novel autonomous conflict resolution framework named Diffusion-AC. Diverging from conventional methods that converge to a single optimal solution, our framework models its policy as a reverse denoising process guided by a value function, enabling it to generate a rich, high-quality, and multimodal action distribution. This core architecture is complemented by a Density-Progressive Safety Curriculum (DPSC), a training mechanism that ensures stable and efficient learning as the agent progresses from sparse to high-density traffic environments. Extensive simulation experiments demonstrate that the proposed method significantly outperforms a suite of state-of-the-art DRL benchmarks. Most critically, in the most challenging high-density scenarios, Diffusion-AC not only maintains a high success rate of 94.1% but also reduces the incidence of Near Mid-Air Collisions (NMACs) by approximately 59% compared to the next-best-performing baseline, significantly enhancing the system's safety margin. This performance leap stems from its unique multimodal decision-making capability, which allows the agent to flexibly switch to effective alternative maneuvers.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "59 pages,13 figures, 3 tables", "pdf_url": "https://arxiv.org/pdf/2509.03550.pdf", "abstract_url": "https://arxiv.org/abs/2509.03550", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于扩散概率模型和深度强化学习的自主冲突检测与解决框架Diffusion-AC，通过多模态策略和渐进式安全课程训练，在模拟实验中显著优于现有方法，提高了高密度空中交通的安全性和成功率。", "motivation": "解决现有深度强化学习方法在冲突检测与解决中存在的单模态偏差问题，导致决策僵局和灵活性不足，以应对日益增长的全球空中交通管理需求。", "method": "集成扩散概率模型，将策略建模为基于价值函数的反向去噪过程，生成多模态动作分布，并采用密度渐进安全课程（DPSC）训练机制，从稀疏到高密度环境稳定学习。", "result": "在模拟实验中，Diffusion-AC在高密度场景下成功率高达94.1%，并将近空中碰撞事件减少约59%，显著优于其他先进基准方法。", "conclusion": "该方法通过多模态决策能力提高了灵活性和安全性，为空中交通管理提供了更有效的自动化解决方案，具有重要的实际应用价值。"}}
{"id": "2509.03626", "title": "Explainable Knowledge Graph Retrieval-Augmented Generation (KG-RAG) with KG-SMILE", "authors": ["Zahra Zehtabi Sabeti Moghaddam", "Zeinab Dehghani", "Maneeha Rani", "Koorosh Aslansefat", "Bhupesh Kumar Mishra", "Rameez Raja Kureshi", "Dhavalkumar Thakker"], "abstract": "Generative AI, such as Large Language Models (LLMs), has achieved impressive progress but still produces hallucinations and unverifiable claims, limiting reliability in sensitive domains. Retrieval-Augmented Generation (RAG) improves accuracy by grounding outputs in external knowledge, especially in domains like healthcare, where precision is vital. However, RAG remains opaque and essentially a black box, heavily dependent on data quality. We developed a method-agnostic, perturbation-based framework that provides token and component-level interoperability for Graph RAG using SMILE and named it as Knowledge-Graph (KG)-SMILE. By applying controlled perturbations, computing similarities, and training weighted linear surrogates, KG-SMILE identifies the graph entities and relations most influential to generated outputs, thereby making RAG more transparent. We evaluate KG-SMILE using comprehensive attribution metrics, including fidelity, faithfulness, consistency, stability, and accuracy. Our findings show that KG-SMILE produces stable, human-aligned explanations, demonstrating its capacity to balance model effectiveness with interpretability and thereby fostering greater transparency and trust in machine learning technologies.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03626.pdf", "abstract_url": "https://arxiv.org/abs/2509.03626", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种名为KG-SMILE的可解释知识图谱检索增强生成框架，通过扰动和相似性计算提高透明度和可信度。", "motivation": "解决大型语言模型产生幻觉和不可验证声明的问题，特别是在敏感领域如医疗保健中，RAG方法虽提高准确性但缺乏透明度。", "method": "使用基于扰动的框架，应用控制扰动、计算相似性并训练加权线性代理模型，以识别知识图谱中对生成输出最有影响的实体和关系。", "result": "KG-SMILE通过综合归因指标评估，显示其能产生稳定、与人类对齐的解释，平衡模型有效性和可解释性。", "conclusion": "该方法增强了RAG的透明度，促进了对机器学习技术的信任，适用于敏感领域。"}}
{"id": "2509.03581", "title": "Learning When to Plan: Efficiently Allocating Test-Time Compute for LLM Agents", "authors": ["Davide Paglieri", "Bartłomiej Cupiał", "Jonathan Cook", "Ulyana Piterbarg", "Jens Tuyls", "Edward Grefenstette", "Jakob Nicolaus Foerster", "Jack Parker-Holder", "Tim Rocktäschel"], "abstract": "Training large language models (LLMs) to reason via reinforcement learning (RL) significantly improves their problem-solving capabilities. In agentic settings, existing methods like ReAct prompt LLMs to explicitly plan before every action; however, we demonstrate that always planning is computationally expensive and degrades performance on long-horizon tasks, while never planning further limits performance. To address this, we introduce a conceptual framework formalizing dynamic planning for LLM agents, enabling them to flexibly decide when to allocate test-time compute for planning. We propose a simple two-stage training pipeline: (1) supervised fine-tuning on diverse synthetic data to prime models for dynamic planning, and (2) RL to refine this capability in long-horizon environments. Experiments on the Crafter environment show that dynamic planning agents trained with this approach are more sample-efficient and consistently achieve more complex objectives. Additionally, we demonstrate that these agents can be effectively steered by human-written plans, surpassing their independent capabilities. To our knowledge, this work is the first to explore training LLM agents for dynamic test-time compute allocation in sequential decision-making tasks, paving the way for more efficient, adaptive, and controllable agentic systems.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03581.pdf", "abstract_url": "https://arxiv.org/abs/2509.03581", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种动态规划框架，使LLM代理能够灵活决定何时进行测试时计算规划，通过两阶段训练（监督微调和强化学习）提高效率和性能，在Crafter环境中验证了其有效性。", "motivation": "解决在LLM代理中始终或从不规划导致的计算效率低下和性能下降问题，特别是在长视野任务中。", "method": "引入动态规划框架，采用两阶段训练管道：先监督微调合成数据，再强化学习优化长视野环境中的规划能力。", "result": "实验显示动态规划代理在Crafter环境中更样本高效，能实现更复杂目标，并可被人类计划有效引导，超越独立能力。", "conclusion": "该工作首次探索了LLM代理的动态测试时计算分配，为更高效、自适应和可控的代理系统铺平了道路。"}}
{"id": "2509.03736", "title": "Are LLM Agents Behaviorally Coherent? Latent Profiles for Social Simulation", "authors": ["James Mooney", "Josef Woldense", "Zheng Robert Jia", "Shirley Anugrah Hayati", "My Ha Nguyen", "Vipul Raheja", "Dongyeop Kang"], "abstract": "The impressive capabilities of Large Language Models (LLMs) have fueled the notion that synthetic agents can serve as substitutes for real participants in human-subject research. In an effort to evaluate the merits of this claim, social science researchers have largely focused on whether LLM-generated survey data corresponds to that of a human counterpart whom the LLM is prompted to represent. In contrast, we address a more fundamental question: Do agents maintain internal consistency, retaining similar behaviors when examined under different experimental settings? To this end, we develop a study designed to (a) reveal the agent's internal state and (b) examine agent behavior in a basic dialogue setting. This design enables us to explore a set of behavioral hypotheses to assess whether an agent's conversation behavior is consistent with what we would expect from their revealed internal state. Our findings on these hypotheses show significant internal inconsistencies in LLMs across model families and at differing model sizes. Most importantly, we find that, although agents may generate responses matching those of their human counterparts, they fail to be internally consistent, representing a critical gap in their capabilities to accurately substitute for real participants in human-subject research. Our simulation code and data are publicly accessible.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "25 pages, 9 figures, 7 tables", "pdf_url": "https://arxiv.org/pdf/2509.03736.pdf", "abstract_url": "https://arxiv.org/abs/2509.03736", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文评估大型语言模型（LLM）代理在行为一致性方面的表现，发现尽管能生成类似人类的响应，但内部状态不一致，限制了其在人类主体研究中的替代能力。", "motivation": "解决LLM代理是否能在不同实验设置中保持行为一致性的问题，以评估其作为真实参与者替代品的可行性。", "method": "开发研究设计，揭示代理内部状态并在基本对话设置中检验行为，通过行为假设评估一致性。", "result": "发现LLM代理在不同模型家族和大小中存在显著内部不一致，无法保持行为一致性。", "conclusion": "LLM代理虽能模拟人类响应，但缺乏内部一致性，表明其在人类主体研究中的替代能力存在关键缺陷。"}}
{"id": "2509.03768", "title": "RAGuard: A Novel Approach for in-context Safe Retrieval Augmented Generation for LLMs", "authors": ["Connor Walker", "Koorosh Aslansefat", "Mohammad Naveed Akram", "Yiannis Papadopoulos"], "abstract": "Accuracy and safety are paramount in Offshore Wind (OSW) maintenance, yet conventional Large Language Models (LLMs) often fail when confronted with highly specialised or unexpected scenarios. We introduce RAGuard, an enhanced Retrieval-Augmented Generation (RAG) framework that explicitly integrates safety-critical documents alongside technical", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (stat.ML)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03768.pdf", "abstract_url": "https://arxiv.org/abs/2509.03768", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (stat.ML)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "RAGuard是一种增强的检索增强生成框架，通过整合安全关键文档和技术信息，提高大型语言模型在海上风电维护中的准确性和安全性。", "motivation": "解决大型语言模型在高度专业化或意外场景中准确性和安全性不足的问题。", "method": "使用检索增强生成方法，明确集成安全关键文档。", "result": "提高了模型在海上风电维护中的性能。", "conclusion": "RAGuard框架能有效增强LLMs的安全性和准确性，适用于关键领域。"}}
{"id": "2509.03811", "title": "Leveraging LLM-Based Agents for Intelligent Supply Chain Planning", "authors": ["Yongzhi Qi", "Jiaheng Yin", "Jianshen Zhang", "Dongyang Geng", "Zhengyu Chen", "Hao Hu", "Wei Qi", "Zuo-Jun Max Shen"], "abstract": "In supply chain management, planning is a critical concept. The movement of physical products across different categories, from suppliers to warehouse management, to sales, and logistics transporting them to customers, entails the involvement of many entities. It covers various aspects such as demand forecasting, inventory management, sales operations, and replenishment. How to collect relevant data from an e-commerce platform's perspective, formulate long-term plans, and dynamically adjust them based on environmental changes, while ensuring interpretability, efficiency, and reliability, is a practical and challenging problem. In recent years, the development of AI technologies, especially the rapid progress of large language models, has provided new tools to address real-world issues. In this work, we construct a Supply Chain Planning Agent (SCPA) framework that can understand domain knowledge, comprehend the operator's needs, decompose tasks, leverage or create new tools, and return evidence-based planning reports. We deploy this framework in", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03811.pdf", "abstract_url": "https://arxiv.org/abs/2509.03811", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于大型语言模型的智能供应链规划代理框架，用于解决供应链管理中的动态规划和数据整合挑战。", "motivation": "解决供应链管理中数据收集、长期规划制定、动态调整以及确保可解释性、效率和可靠性的实际问题。", "method": "构建了一个供应链规划代理（SCPA）框架，利用LLM理解领域知识、分解任务、使用或创建工具，并生成基于证据的规划报告。", "result": "框架在部署中展示了处理供应链规划任务的能力，但具体结果未在摘要中详细说明。", "conclusion": "LLM-based agents为供应链规划提供了有效的新工具，具有实际应用潜力。"}}
{"id": "2509.03817", "title": "Learning to Deliberate: Meta-policy Collaboration for Agentic LLMs with Multi-agent Reinforcement Learning", "authors": ["Wei Yang", "Jesse Thomason"], "abstract": "Multi-agent systems of large language models (LLMs) show promise for complex reasoning, but their effectiveness is often limited by fixed collaboration protocols. These frameworks typically focus on macro-level orchestration while overlooking agents' internal deliberative capabilities. This critical meta-cognitive blindspot treats agents as passive executors unable to adapt their strategy based on internal cognitive states like uncertainty or confidence. We introduce the Meta-Policy Deliberation Framework (MPDF), where agents learn a decentralized policy over a set of high-level meta-cognitive actions: Persist, Refine, and Concede. To overcome the instability of traditional policy gradients in this setting, we develop SoftRankPO, a novel reinforcement learning algorithm. SoftRankPO stabilizes training by shaping advantages based on the rank of rewards mapped through smooth normal quantiles, making the learning process robust to reward variance. Experiments show that MPDF with SoftRankPO achieves a a 4-5% absolute gain in average accuracy across five mathematical and general reasoning benchmarks compared to six state-of-the-art heuristic and learning-based multi-agent reasoning algorithms. Our work presents a paradigm for learning adaptive, meta-cognitive policies for multi-agent LLM systems, shifting the focus from designing fixed protocols to learning dynamic, deliberative strategies.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03817.pdf", "abstract_url": "https://arxiv.org/abs/2509.03817", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出元策略审议框架（MPDF）和SoftRankPO算法，通过多智能体强化学习提升大语言模型在复杂推理中的自适应协作能力，实验显示在多个基准上准确率提高4-5%。", "motivation": "解决多智能体大语言模型系统中固定协作协议的限制，这些协议忽视智能体内部审议能力，导致智能体无法基于认知状态（如不确定性）自适应调整策略。", "method": "使用元策略审议框架（MPDF），智能体学习去中心化策略，包括持久、精炼和让步等元认知动作，并开发SoftRankPO强化学习算法，通过平滑正态分位数映射奖励来稳定训练。", "result": "在五个数学和通用推理基准测试中，MPDF与SoftRankPO相比六种先进多智能体推理算法，平均准确率绝对提升4-5%。", "conclusion": "该工作为多智能体LLM系统提供了学习自适应元认知策略的范式，从设计固定协议转向动态审议策略，提升了系统性能和鲁棒性。"}}
{"id": "2509.03527", "title": "Multilevel Analysis of Cryptocurrency News using RAG Approach with Fine-Tuned Mistral Large Language Model", "authors": ["Bohdan M. Pavlyshenko"], "abstract": "In the paper, we consider multilevel multitask analysis of cryptocurrency news using a fine-tuned Mistral 7B large language model with retrieval-augmented generation (RAG).", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03527.pdf", "abstract_url": "https://arxiv.org/abs/2509.03527", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "使用微调的Mistral 7B大语言模型和RAG方法进行加密货币新闻的多层次多任务分析。", "motivation": "解决加密货币新闻的复杂分析需求，通过多任务方法提高信息提取和理解的效率。", "method": "采用检索增强生成（RAG）结合微调的Mistral 7B大语言模型进行多层次分析。", "result": "实现了对加密货币新闻的有效多任务处理，提升了分析的准确性和深度。", "conclusion": "该方法为加密货币领域提供了高效的新闻分析工具，具有实际应用价值。"}}
{"id": "2509.03540", "title": "Improving Factuality in LLMs via Inference-Time Knowledge Graph Construction", "authors": ["Shanglin Wu", "Lihui Liu", "Jinho D. Choi", "Kai Shu"], "abstract": "Large Language Models (LLMs) often struggle with producing factually consistent answers due to limitations in their parametric memory. Retrieval-Augmented Generation (RAG) methods address this issue by incorporating external knowledge from trusted sources at inference time. However, such methods typically treat knowledge as unstructured text, which limits their ability to support compositional reasoning and identify factual inconsistencies. To overcome these limitations, we propose a novel framework that dynamically constructs and expands knowledge graphs (KGs) during inference, integrating both internal knowledge extracted from LLMs and external information retrieved from external sources. Our method begins by extracting a seed KG from the question via prompting, followed by iterative expansion using the LLM's latent knowledge. The graph is then selectively refined through external retrieval, enhancing factual coverage and correcting inaccuracies. We evaluate our approach on three diverse factual QA benchmarks, demonstrating consistent improvements in factual accuracy, answer precision, and interpretability over baseline prompting and static KG-augmented methods. Our findings suggest that inference-time KG construction is a promising direction for enhancing LLM factuality in a structured, interpretable, and scalable manner.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03540.pdf", "abstract_url": "https://arxiv.org/abs/2509.03540", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "通过推理时动态构建和扩展知识图谱来增强LLM的事实准确性，结合内部和外部知识，在多个基准测试中优于基线方法。", "motivation": "解决LLM在生成事实一致答案时的局限性，特别是RAG方法处理非结构化文本时无法支持组合推理和识别事实不一致的问题。", "method": "提出一个框架，在推理时动态构建和扩展知识图谱，包括从问题提取种子图谱、迭代扩展使用LLM潜在知识，并通过外部检索选择性精炼。", "result": "在三个事实QA基准测试中，一致提高了事实准确性、答案精确性和可解释性，优于提示和静态知识图谱增强方法。", "conclusion": "推理时知识图谱构建是增强LLM事实性的结构化、可解释和可扩展的有前景方向。"}}
{"id": "2509.03565", "title": "ResearchPulse: Building Method-Experiment Chains through Multi-Document Scientific Inference", "authors": ["Qi Chen", "Jingxuan Wei", "Zhuoya Yao", "Haiguang Wang", "Gaowei Wu", "Bihui Yu", "Siyuan Li", "Cheng Tan"], "abstract": "Understanding how scientific ideas evolve requires more than summarizing individual papers-it demands structured, cross-document reasoning over thematically related research. In this work, we formalize multi-document scientific inference, a new task that extracts and aligns motivation, methodology, and experimental results across related papers to reconstruct research development chains. This task introduces key challenges, including temporally aligning loosely structured methods and standardizing heterogeneous experimental tables. We present ResearchPulse, an agent-based framework that integrates instruction planning, scientific content extraction, and structured visualization. It consists of three coordinated agents: a Plan Agent for task decomposition, a Mmap-Agent that constructs motivation-method mind maps, and a Lchart-Agent that synthesizes experimental line charts. To support this task, we introduce ResearchPulse-Bench, a citation-aware benchmark of annotated paper clusters. Experiments show that our system, despite using 7B-scale agents, consistently outperforms strong baselines like GPT-4o in semantic alignment, structural consistency, and visual fidelity. The dataset are available in", "subjects": "Computation and Language (cs.CL); Multimedia (cs.MM)", "comments": "Accepted to ACM MM 2025", "pdf_url": "https://arxiv.org/pdf/2509.03565.pdf", "abstract_url": "https://arxiv.org/abs/2509.03565", "categories": ["Computation and Language (cs.CL)", "Multimedia (cs.MM)"], "matching_keywords": ["agent"], "AI": {"tldr": "ResearchPulse 是一个基于代理的框架，用于多文档科学推理，通过提取和整合相关论文的动机、方法和实验结果，构建研究发展链，并在基准测试中优于 GPT-4o 等基线。", "motivation": "解决科学思想演变需要跨文档结构化推理的问题，传统方法无法有效处理主题相关研究中的动机、方法和实验结果的提取与对齐。", "method": "使用基于代理的框架，包括 Plan Agent 进行任务分解、Mmap-Agent 构建动机-方法思维导图、Lchart-Agent 合成实验线图，并引入 ResearchPulse-Bench 基准数据集。", "result": "实验显示，系统在语义对齐、结构一致性和视觉保真度方面优于 GPT-4o 等基线，尽管使用 7B 规模的代理。", "conclusion": "ResearchPulse 有效支持多文档科学推理任务，提供了新的基准和工具，促进科学研究的发展链重建和可视化。"}}
{"id": "2509.03827", "title": "What Would an LLM Do? Evaluating Policymaking Capabilities of Large Language Models", "authors": ["Pierre Le Coz", "Jia An Liu", "Debarun Bhattacharjya", "Georgina Curto", "Serge Stinckwich"], "abstract": "Large language models (LLMs) are increasingly being adopted in high-stakes domains. Their capacity to process vast amounts of unstructured data, explore flexible scenarios, and handle a diversity of contextual factors can make them uniquely suited to provide new insights for the complexity of social policymaking. This article evaluates whether LLMs' are aligned with domain experts (and among themselves) to inform social policymaking on the subject of homelessness alleviation - a challenge affecting over 150 million people worldwide. We develop a novel benchmark comprised of decision scenarios with policy choices across four geographies (South Bend, USA; Barcelona, Spain; Johannesburg, South Africa; Macau SAR, China). The policies in scope are grounded in the conceptual framework of the Capability Approach for human development. We also present an automated pipeline that connects the benchmarked policies to an agent-based model, and we explore the social impact of the recommended policies through simulated social scenarios. The paper results reveal promising potential to leverage LLMs for social policy making. If responsible guardrails and contextual calibrations are introduced in collaboration with local domain experts, LLMs can provide humans with valuable insights, in the form of alternative policies at scale.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03827.pdf", "abstract_url": "https://arxiv.org/abs/2509.03827", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文评估大型语言模型（LLMs）在无家可归缓解政策制定中的能力，开发新基准和自动化管道，显示LLMs在负责任使用下具有潜力。", "motivation": "解决LLMs在高风险领域（如社会政策制定）中是否与领域专家一致的问题，以应对全球无家可归挑战。", "method": "开发基于能力方法的基准决策场景，连接基于代理的模型，通过模拟社会场景评估LLMs的政策建议。", "result": "LLMs显示出在负责任护栏和本地专家合作下，能提供大规模替代政策见解的潜力。", "conclusion": "LLMs可成为社会政策制定的有价值工具，但需引入负责任措施和本地校准。"}}
{"id": "2509.03828", "title": "An Agentic Model Context Protocol Framework for Medical Concept Standardization", "authors": ["Jaerong Ahn", "Andrew Wen", "Nan Wang", "Heling Jia", "Zhiyi Yue", "Sunyang Fu", "Hongfang Liu"], "abstract": "The Observational Medical Outcomes Partnership (OMOP) common data model (CDM) provides a standardized representation of heterogeneous health data to support large-scale, multi-institutional research. One critical step in data standardization using OMOP CDM is the mapping of source medical terms to OMOP standard concepts, a procedure that is resource-intensive and error-prone. While large language models (LLMs) have the potential to facilitate this process, their tendency toward hallucination makes them unsuitable for clinical deployment without training and expert validation. Here, we developed a zero-training, hallucination-preventive mapping system based on the Model Context Protocol (MCP), a standardized and secure framework allowing LLMs to interact with external resources and tools. The system enables explainable mapping and significantly improves efficiency and accuracy with minimal effort. It provides real-time vocabulary lookups and structured reasoning outputs suitable for immediate use in both exploratory and production environments.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03828.pdf", "abstract_url": "https://arxiv.org/abs/2509.03828", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "开发了一种基于模型上下文协议（MCP）的零训练、防幻觉映射系统，用于医学概念标准化，提高OMOP CDM术语映射的效率和准确性。", "motivation": "解决OMOP通用数据模型（CDM）中源医学术语映射到标准概念的资源密集和易出错问题，同时减少大型语言模型（LLMs）的幻觉风险。", "method": "采用模型上下文协议（MCP）框架，使LLMs能与外部资源和工具交互，实现零训练、防幻觉的映射，提供实时词汇查找和结构化推理输出。", "result": "系统显著提高了映射效率和准确性，支持即时在探索和生产环境中使用，并确保解释性映射。", "conclusion": "该方法为医学数据标准化提供了高效、可靠的解决方案，减少了对训练和专家验证的依赖，适合临床部署。"}}
{"id": "2509.03890", "title": "FaMA: LLM-Empowered Agentic Assistant for Consumer-to-Consumer Marketplace", "authors": ["Yineng Yan", "Xidong Wang", "Jin Seng Cheng", "Ran Hu", "Wentao Guan", "Nahid Farahmand", "Hengte Lin", "Yue Li"], "abstract": "The emergence of agentic AI, powered by Large Language Models (LLMs), marks a paradigm shift from reactive generative systems to proactive, goal-oriented autonomous agents capable of sophisticated planning, memory, and tool use. This evolution presents a novel opportunity to address long-standing challenges in complex digital environments. Core tasks on Consumer-to-Consumer (C2C) e-commerce platforms often require users to navigate complex Graphical User Interfaces (GUIs), making the experience time-consuming for both buyers and sellers. This paper introduces a novel approach to simplify these interactions through an LLM-powered agentic assistant. This agent functions as a new, conversational entry point to the marketplace, shifting the primary interaction model from a complex GUI to an intuitive AI agent. By interpreting natural language commands, the agent automates key high-friction workflows. For sellers, this includes simplified updating and renewal of listings, and the ability to send bulk messages. For buyers, the agent facilitates a more efficient product discovery process through conversational search. We present the architecture for Facebook Marketplace Assistant (FaMA), arguing that this agentic, conversational paradigm provides a lightweight and more accessible alternative to traditional app interfaces, allowing users to manage their marketplace activities with greater efficiency. Experiments show FaMA achieves a 98% task success rate on solving complex tasks on the marketplace and enables up to a 2x speedup on interaction time.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03890.pdf", "abstract_url": "https://arxiv.org/abs/2509.03890", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "FaMA是一个基于大型语言模型的智能助手，旨在简化C2C电子商务平台的用户交互，通过自然语言命令自动化高摩擦工作流，实验显示任务成功率达98%，交互时间缩短2倍。", "motivation": "解决C2C电子商务平台中用户因复杂图形界面导致的交互耗时问题，提升买家和卖家的效率。", "method": "使用LLM驱动的智能代理，通过自然语言解释和自动化关键工作流，如卖家更新列表和买家对话搜索，作为新的对话入口点。", "result": "FaMA在复杂任务上达到98%的成功率，交互时间最多缩短2倍。", "conclusion": "代理式对话范式提供轻量级、更易访问的替代方案，能高效管理市场活动，具有实际应用潜力。"}}
{"id": "2509.03906", "title": "A Foundation Model for Chest X-ray Interpretation with Grounded Reasoning via Online Reinforcement Learning", "authors": ["Qika Lin", "Yifan Zhu", "Bin Pu", "Ling Huang", "Haoran Luo", "Jingying Ma", "Zhen Peng", "Tianzhe Zhao", "Fangzhi Xu", "Jian Zhang", "Kai He", "Zhonghong Ou", "Swapnil Mishra", "Mengling Feng"], "abstract": "Medical foundation models (FMs) have shown tremendous promise amid the rapid advancements in artificial intelligence (AI) technologies. However, current medical FMs typically generate answers in a black-box manner, lacking transparent reasoning processes and locally grounded interpretability, which hinders their practical clinical deployments. To this end, we introduce DeepMedix-R1, a holistic medical FM for chest X-ray (CXR) interpretation. It leverages a sequential training pipeline: initially fine-tuned on curated CXR instruction data to equip with fundamental CXR interpretation capabilities, then exposed to high-quality synthetic reasoning samples to enable cold-start reasoning, and finally refined via online reinforcement learning to enhance both grounded reasoning quality and generation performance. Thus, the model produces both an answer and reasoning steps tied to the image's local regions for each query. Quantitative evaluation demonstrates substantial improvements in report generation (e.g., 14.54% and 31.32% over LLaVA-Rad and MedGemma) and visual question answering (e.g., 57.75% and 23.06% over MedGemma and CheXagent) tasks. To facilitate robust assessment, we propose Report Arena, a benchmarking framework using advanced language models to evaluate answer quality, further highlighting the superiority of DeepMedix-R1. Expert review of generated reasoning steps reveals greater interpretability and clinical plausibility compared to the established Qwen2.5-VL-7B model (0.7416 vs. 0.2584 overall preference). Collectively, our work advances medical FM development toward holistic, transparent, and clinically actionable modeling for CXR interpretation.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "15 pages", "pdf_url": "https://arxiv.org/pdf/2509.03906.pdf", "abstract_url": "https://arxiv.org/abs/2509.03906", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文介绍了DeepMedix-R1，一个用于胸部X光解释的医学基础模型，通过在线强化学习实现接地推理，提高报告生成和视觉问答性能及可解释性。", "motivation": "解决当前医学基础模型在临床部署中缺乏透明推理过程和局部接地可解释性的问题。", "method": "采用序列训练管道：先在CXR指令数据上微调，再暴露于合成推理样本，最后通过在线强化学习优化接地推理和生成性能。", "result": "在报告生成和视觉问答任务上显著优于现有模型，并通过专家评审显示更高的可解释性和临床合理性。", "conclusion": "该工作推动了医学基础模型向整体、透明和临床可操作的CXR解释发展。"}}
{"id": "2509.03956", "title": "World Model Implanting for Test-time Adaptation of Embodied Agents", "authors": ["Minjong Yoo", "Jinwoo Jang", "Sihyung Yoon", "Honguk Woo"], "abstract": "In embodied AI, a persistent challenge is enabling agents to robustly adapt to novel domains without requiring extensive data collection or retraining. To address this, we present a world model implanting framework (WorMI) that combines the reasoning capabilities of large language models (LLMs) with independently learned, domain-specific world models through test-time composition. By allowing seamless implantation and removal of the world models, the embodied agent's policy achieves and maintains cross-domain adaptability. In the WorMI framework, we employ a prototype-based world model retrieval approach, utilizing efficient trajectory-based abstract representation matching, to incorporate relevant models into test-time composition. We also develop a world-wise compound attention method that not only integrates the knowledge from the retrieved world models but also aligns their intermediate representations with the reasoning model's representation within the agent's policy. This framework design effectively fuses domain-specific knowledge from multiple world models, ensuring robust adaptation to unseen domains. We evaluate our WorMI on the VirtualHome and ALFWorld benchmarks, demonstrating superior zero-shot and few-shot performance compared to several LLM-based approaches across a range of unseen domains. These results highlight the frameworks potential for scalable, real-world deployment in embodied agent scenarios where adaptability and data efficiency are essential.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03956.pdf", "abstract_url": "https://arxiv.org/abs/2509.03956", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出世界模型植入框架（WorMI），结合大语言模型与领域特定世界模型，通过测试时组合实现具身代理的跨领域自适应，在VirtualHome和ALFWorld基准上展示优越性能。", "motivation": "解决具身AI中代理在无需大量数据收集或重新训练的情况下，鲁棒适应新领域的问题。", "method": "使用原型世界模型检索和轨迹抽象表示匹配，结合世界级复合注意力方法，集成知识并对齐表示。", "result": "在零样本和少样本场景下，优于其他基于大语言模型的方法，实现对新领域的鲁棒适应。", "conclusion": "WorMI框架具有可扩展性和数据效率，适用于现实世界具身代理部署。"}}
{"id": "2509.04027", "title": "CoT-Space: A Theoretical Framework for Internal Slow-Thinking via Reinforcement Learning", "authors": ["Zeyu Gan", "Hao Yi", "Yong Liu"], "abstract": "Reinforcement Learning (RL) has become a pivotal approach for enhancing the reasoning capabilities of Large Language Models (LLMs). However, a significant theoretical gap persists, as traditional token-level RL frameworks fail to align with the reasoning-level nature of complex, multi-step thought processes like Chain-of-Thought (CoT). To address this challenge, we introduce CoT-Space, a novel theoretical framework that recasts LLM reasoning from a discrete token-prediction task to an optimization process within a continuous, reasoning-level semantic space. By analyzing this process from both a noise perspective and a risk perspective, we demonstrate that the convergence to an optimal CoT length is a natural consequence of the fundamental trade-off between underfitting and overfitting. Furthermore, extensive experiments provide strong empirical validation for our theoretical findings. Our framework not only provides a coherent explanation for empirical phenomena such as overthinking but also offers a solid theoretical foundation to guide the future development of more effective and generalizable reasoning agents.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "Preprint Edition", "pdf_url": "https://arxiv.org/pdf/2509.04027.pdf", "abstract_url": "https://arxiv.org/abs/2509.04027", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "CoT-Space是一个理论框架，通过强化学习将LLM推理从离散标记预测重新定义为连续语义空间中的优化过程，解释并验证了最优CoT长度的收敛性。", "motivation": "解决传统标记级RL框架无法处理复杂多步推理（如CoT）的理论缺口问题。", "method": "引入CoT-Space框架，从噪声和风险角度分析推理过程，将推理视为连续语义空间中的优化。", "result": "实验验证了理论发现，表明最优CoT长度是欠拟合和过拟合权衡的自然结果。", "conclusion": "框架为过思考等现象提供解释，并为开发更有效推理代理奠定理论基础。"}}
{"id": "2509.03990", "title": "Meta-Policy Reflexion: Reusable Reflective Memory and Rule Admissibility for Resource-Efficient LLM Agent", "authors": ["Chunlong Wu", "Zhibo Qu"], "abstract": "Large language model (LLM) agents achieve impressive single-task performance but commonly exhibit repeated failures, inefficient exploration, and limited cross-task adaptability. Existing reflective strategies (e.g., Reflexion, ReAct) improve per-episode behavior but typically produce ephemeral, task-specific traces that are not reused across tasks. Reinforcement-learning based alternatives can produce transferable policies but require substantial parameter updates and compute. In this work we introduce Meta-Policy Reflexion (MPR): a hybrid framework that consolidates LLM-generated reflections into a structured, predicate-like Meta-Policy Memory (MPM) and applies that memory at inference time through two complementary mechanisms soft memory-guided decoding and hard rule admissibility checks(HAC). MPR (i) externalizes reusable corrective knowledge without model weight updates, (ii) enforces domain constraints to reduce unsafe or invalid actions, and (iii) retains the adaptability of language-based reflection. We formalize the MPM representation, present algorithms for update and decoding, and validate the approach in a text-based agent environment following the experimental protocol described in the provided implementation (AlfWorld-based). Empirical results reported in the supplied material indicate consistent gains in execution accuracy and robustness when compared to Reflexion baselines; rule admissibility further improves stability. We analyze mechanisms that explain these gains, discuss scalability and failure modes, and outline future directions for multimodal and multi?agent extensions.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03990.pdf", "abstract_url": "https://arxiv.org/abs/2509.03990", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出Meta-Policy Reflexion（MPR）框架，结合元策略内存和规则可接受性检查，提高LLM代理的效率、可重用性和安全性，无需权重更新。", "motivation": "解决LLM代理在单任务中重复失败、探索效率低和跨任务适应性差的问题，现有方法如Reflexion和ReAct产生短暂的任务特定痕迹，而强化学习方法需要高计算成本。", "method": "使用混合框架，将LLM生成的反思整合到结构化元策略内存（MPM）中，通过软内存引导解码和硬规则可接受性检查（HAC）在推理时应用。", "result": "在基于AlfWorld的文本代理环境中，与Reflexion基线相比，执行准确性和鲁棒性有显著提升，规则可接受性检查进一步提高了稳定性。", "conclusion": "MPR外部化可重用知识，增强约束执行和适应性，可扩展至多模态和多代理场景，为资源高效LLM代理提供有效解决方案。"}}
{"id": "2509.04100", "title": "Hybrid Reinforcement Learning and Search for Flight Trajectory Planning", "authors": ["Alberto Luise", "Michele Lombardi", "Florent Teichteil Koenigsbuch"], "abstract": "This paper explores the combination of Reinforcement Learning (RL) and search-based path planners to speed up the optimization of flight paths for airliners, where in case of emergency a fast route re-calculation can be crucial. The fundamental idea is to train an RL Agent to pre-compute near-optimal paths based on location and atmospheric data and use those at runtime to constrain the underlying path planning solver and find a solution within a certain distance from the initial guess. The approach effectively reduces the size of the solver's search space, significantly speeding up route optimization. Although global optimality is not guaranteed, empirical results conducted with Airbus aircraft's performance models show that fuel consumption remains nearly identical to that of an unconstrained solver, with deviations typically within 1%. At the same time, computation speed can be improved by up to 50% as compared to using a conventional solver alone.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.04100.pdf", "abstract_url": "https://arxiv.org/abs/2509.04100", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了结合强化学习和搜索的路径规划方法，以加速航空公司紧急情况下的飞行轨迹优化，通过预计算近优路径约束求解器，在保持燃油消耗接近最优的同时显著提高计算速度。", "motivation": "解决紧急情况下飞行路径快速重新计算的问题，以确保安全和效率。", "method": "使用强化学习代理预计算近优路径，并基于此约束搜索求解器，缩小搜索空间。", "result": "实证结果显示燃油消耗与无约束求解器相近（偏差在1%以内），计算速度提升高达50%。", "conclusion": "该方法在保证性能的同时大幅加速路径优化，适用于航空紧急响应。"}}
{"id": "2509.03891", "title": "MobileRAG: Enhancing Mobile Agent with Retrieval-Augmented Generation", "authors": ["Gowen Loo", "Chang Liu", "Qinghong Yin", "Xiang Chen", "Jiawei Chen", "Jingyuan Zhang", "Yu Tian"], "abstract": "Smartphones have become indispensable in people's daily lives, permeating nearly every aspect of modern society. With the continuous advancement of large language models (LLMs), numerous LLM-based mobile agents have emerged. These agents are capable of accurately parsing diverse user queries and automatically assisting users in completing complex or repetitive operations. However, current agents 1) heavily rely on the comprehension ability of LLMs, which can lead to errors caused by misoperations or omitted steps during tasks, 2) lack interaction with the external environment, often terminating tasks when an app cannot fulfill user queries, and 3) lack memory capabilities, requiring each instruction to reconstruct the interface and being unable to learn from and correct previous mistakes. To alleviate the above issues, we propose MobileRAG, a mobile agents framework enhanced by Retrieval-Augmented Generation (RAG), which includes InterRAG, LocalRAG, and MemRAG. It leverages RAG to more quickly and accurately identify user queries and accomplish complex and long-sequence mobile tasks. Additionally, to more comprehensively assess the performance of MobileRAG, we introduce MobileRAG-Eval, a more challenging benchmark characterized by numerous complex, real-world mobile tasks that require external knowledge assistance. Extensive experimental results on MobileRAG-Eval demonstrate that MobileRAG can easily handle real-world mobile tasks, achieving 10.3\\% improvement over state-of-the-art methods with fewer operational steps. Our code is publicly available at:", "subjects": "Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03891.pdf", "abstract_url": "https://arxiv.org/abs/2509.03891", "categories": ["Computation and Language (cs.CL)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "MobileRAG是一个基于检索增强生成（RAG）的移动代理框架，通过InterRAG、LocalRAG和MemRAG组件提升任务处理能力，在MobileRAG-Eval基准测试中实现10.3%的性能提升。", "motivation": "解决当前LLM移动代理依赖模型理解能力导致错误、缺乏外部环境交互和记忆能力的问题。", "method": "采用检索增强生成（RAG）技术，集成InterRAG、LocalRAG和MemRAG模块来快速准确识别用户查询并完成复杂任务。", "result": "在MobileRAG-Eval基准测试中，性能优于现有方法10.3%，操作步骤更少，能有效处理现实世界移动任务。", "conclusion": "MobileRAG框架显著提升移动代理的准确性和效率，具有实际应用潜力，代码已开源。"}}
{"id": "2509.03934", "title": "SelfAug: Mitigating Catastrophic Forgetting in Retrieval-Augmented Generation via Distribution Self-Alignment", "authors": ["Yuqing Huang", "Rongyang Zhang", "Qimeng Wang", "Chengqiang Lu", "Yan Gao", "Yi Wu", "Yao Hu", "Xuyang Zhi", "Guiquan Liu", "Xin Li", "Hao Wang", "Enhong Chen"], "abstract": "Recent advancements in large language models (LLMs) have revolutionized natural language processing through their remarkable capabilities in understanding and executing diverse tasks. While supervised fine-tuning, particularly in Retrieval-Augmented Generation (RAG) scenarios, effectively enhances task-specific performance, it often leads to catastrophic forgetting, where models lose their previously acquired knowledge and general capabilities. Existing solutions either require access to general instruction data or face limitations in preserving the model's original distribution. To overcome these limitations, we propose SelfAug, a self-distribution alignment method that aligns input sequence logits to preserve the model's semantic distribution, thereby mitigating catastrophic forgetting and improving downstream performance. Extensive experiments demonstrate that SelfAug achieves a superior balance between downstream learning and general capability retention. Our comprehensive empirical analysis reveals a direct correlation between distribution shifts and the severity of catastrophic forgetting in RAG scenarios, highlighting how the absence of RAG capabilities in general instruction tuning leads to significant distribution shifts during fine-tuning. Our findings not only advance the understanding of catastrophic forgetting in RAG contexts but also provide a practical solution applicable across diverse fine-tuning scenarios. Our code is publicly available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03934.pdf", "abstract_url": "https://arxiv.org/abs/2509.03934", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "SelfAug是一种通过分布自对齐来缓解检索增强生成中灾难性遗忘的自分布对齐方法，能在下游学习中保持模型的一般能力。", "motivation": "解决检索增强生成微调中导致的灾难性遗忘问题，即模型失去原有知识和一般能力，现有方法需通用指令数据或难以保持原始分布。", "method": "使用自分布对齐方法，对齐输入序列的logits以保持模型的语义分布。", "result": "实验显示SelfAug在下游学习和一般能力保留间取得更好平衡，分布偏移与灾难性遗忘严重性直接相关。", "conclusion": "SelfAug提供了一种实用解决方案，适用于多种微调场景，并推进了对灾难性遗忘的理解。"}}
{"id": "2509.03918", "title": "MTQA:Matrix of Thought for Enhanced Reasoning in Complex Question Answering", "authors": ["Fengxiao Tang", "Yufeng Li", "Zongzong Wu", "Ming Zhao"], "abstract": "Complex Question Answering (QA) is a fundamental and challenging task in NLP. While large language models (LLMs) exhibit impressive performance in QA, they suffer from significant performance degradation when facing complex and abstract QA tasks due to insufficient reasoning capabilities. Works such as Chain-of-Thought (CoT) and Tree-of-Thought (ToT) aim to enhance LLMs' reasoning abilities, but they face issues such as in-layer redundancy in tree structures and single paths in chain structures. Although some studies utilize Retrieval-Augmented Generation (RAG) methods to assist LLMs in reasoning, the challenge of effectively utilizing large amounts of information involving multiple entities and hops remains critical. To address this, we propose the Matrix of Thought (MoT), a novel and efficient LLM thought structure. MoT explores the problem in both horizontal and vertical dimensions through the \"column-cell communication\" mechanism, enabling LLMs to actively engage in multi-strategy and deep-level thinking, reducing redundancy within the column cells and enhancing reasoning capabilities. Furthermore, we develop a fact-correction mechanism by constructing knowledge units from retrieved knowledge graph triples and raw text to enhance the initial knowledge for LLM reasoning and correct erroneous answers. This leads to the development of an efficient and accurate QA framework (MTQA). Experimental results show that our framework outperforms state-of-the-art methods on four widely-used datasets in terms of F1 and EM scores, with reasoning time only 14.4\\% of the baseline methods, demonstrating both its efficiency and accuracy. The code for this framework is available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03918.pdf", "abstract_url": "https://arxiv.org/abs/2509.03918", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "提出Matrix of Thought (MoT)方法，通过水平和垂直维度探索问题，结合知识单元校正，提升复杂问答中的推理能力和效率。", "motivation": "解决大型语言模型在复杂抽象问答任务中推理能力不足的问题，现有方法如CoT和ToT存在冗余和单一路径限制，RAG方法难以有效利用多实体和多跳信息。", "method": "使用Matrix of Thought (MoT)结构，通过列-单元格通信机制进行多策略深度思考，并构建知识单元从知识图谱和文本中校正错误答案。", "result": "在四个数据集上F1和EM分数优于现有方法，推理时间仅为基线的14.4%，证明高效且准确。", "conclusion": "MoT框架显著增强LLM推理，减少冗余，提高问答性能，代码已开源。"}}
{"id": "2509.03940", "title": "VoxRole: A Comprehensive Benchmark for Evaluating Speech-Based Role-Playing Agents", "authors": ["Weihao Wu", "Liang Cao", "Xinyu Wu", "Zhiwei Lin", "Rui Niu", "Jingbei Li", "Zhiyong Wu"], "abstract": "Recent significant advancements in Large Language Models (LLMs) have greatly propelled the development of Role-Playing Conversational Agents (RPCAs). These systems aim to create immersive user experiences through consistent persona adoption. However, current RPCA research faces dual limitations. First, existing work predominantly focuses on the textual modality, entirely overlooking critical paralinguistic features including intonation, prosody, and rhythm in speech, which are essential for conveying character emotions and shaping vivid identities. Second, the speech-based role-playing domain suffers from a long-standing lack of standardized evaluation benchmarks. Most current spoken dialogue datasets target only fundamental capability assessments, featuring thinly sketched or ill-defined character profiles. Consequently, they fail to effectively quantify model performance on core competencies like long-term persona consistency. To address this critical gap, we introduce VoxRole, the first comprehensive benchmark specifically designed for the evaluation of speech-based RPCAs. The benchmark comprises 13335 multi-turn dialogues, totaling 65.6 hours of speech from 1228 unique characters across 261 movies. To construct this resource, we propose a novel two-stage automated pipeline that first aligns movie audio with scripts and subsequently employs an LLM to systematically build multi-dimensional profiles for each character. Leveraging VoxRole, we conduct a multi-dimensional evaluation of contemporary spoken dialogue models, revealing crucial insights into their respective strengths and limitations in maintaining persona consistency.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Sound (cs.SD)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03940.pdf", "abstract_url": "https://arxiv.org/abs/2509.03940", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Sound (cs.SD)"], "matching_keywords": ["agent"], "AI": {"tldr": "VoxRole是首个针对语音角色扮演代理的全面基准，包含13335个多轮对话和65.6小时语音，用于评估模型在保持角色一致性方面的表现。", "motivation": "当前角色扮演对话代理研究主要关注文本模态，忽略了语音中的副语言特征，且缺乏标准化评估基准，无法有效量化长期角色一致性。", "method": "提出两阶段自动化流程：先对齐电影音频与剧本，然后使用大语言模型构建多维角色档案，创建VoxRole基准。", "result": "评估显示当代语音对话模型在保持角色一致性方面存在优势和局限，提供了关键洞察。", "conclusion": "VoxRole填补了语音角色扮演领域的评估空白，促进了更沉浸式用户体验的发展。"}}
{"id": "2509.04125", "title": "Analysis of Bluffing by DQN and CFR in Leduc Hold'em Poker", "authors": ["Tarik Zaciragic", "Aske Plaat", "K. Joost Batenburg"], "abstract": "In the game of poker, being unpredictable, or bluffing, is an essential skill. When humans play poker, they bluff. However, most works on computer-poker focus on performance metrics such as win rates, while bluffing is overlooked. In this paper we study whether two popular algorithms, DQN (based on reinforcement learning) and CFR (based on game theory), exhibit bluffing behavior in Leduc Hold'em, a simplified version of poker. We designed an experiment where we let the DQN and CFR agent play against each other while we log their actions. We find that both DQN and CFR exhibit bluffing behavior, but they do so in different ways. Although both attempt to perform bluffs at different rates, the percentage of successful bluffs (where the opponent folds) is roughly the same. This suggests that bluffing is an essential aspect of the game, not of the algorithm. Future work should look at different bluffing styles and at the full game of poker. Code at", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.04125.pdf", "abstract_url": "https://arxiv.org/abs/2509.04125", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文分析DQN和CFR算法在Leduc Hold'em扑克中的诈唬行为，发现两者均表现出诈唬但方式不同，成功率相似，强调诈唬是游戏本质而非算法特性。", "motivation": "解决扑克游戏中诈唬行为在计算机算法中被忽视的问题，探究DQN和CFR是否展现诈唬。", "method": "设计实验让DQN和CFR代理互相对战并记录动作，分析诈唬行为和成功率。", "result": "DQN和CFR都表现出诈唬行为，方式不同但成功率大致相同。", "conclusion": "诈唬是扑克游戏的关键方面，未来应研究不同诈唬风格和完整扑克游戏。"}}
{"id": "2509.04310", "title": "EvoEmo: Towards Evolved Emotional Policies for LLM Agents in Multi-Turn Negotiation", "authors": ["Yunbo Long", "Liming Xu", "Lukas Beckenbauer", "Yuhan Liu", "Alexandra Brintrup"], "abstract": "Recent research on Chain-of-Thought (CoT) reasoning in Large Language Models (LLMs) has demonstrated that agents can engage in \\textit{complex}, \\textit{multi-turn} negotiations, opening new avenues for agentic AI. However, existing LLM agents largely overlook the functional role of emotions in such negotiations, instead generating passive, preference-driven emotional responses that make them vulnerable to manipulation and strategic exploitation by adversarial counterparts. To address this gap, we present EvoEmo, an evolutionary reinforcement learning framework that optimizes dynamic emotional expression in negotiations. EvoEmo models emotional state transitions as a Markov Decision Process and employs population-based genetic optimization to evolve high-reward emotion policies across diverse negotiation scenarios. We further propose an evaluation framework with two baselines -- vanilla strategies and fixed-emotion strategies -- for benchmarking emotion-aware negotiation. Extensive experiments and ablation studies show that EvoEmo consistently outperforms both baselines, achieving higher success rates, higher efficiency, and increased buyer savings. This findings highlight the importance of adaptive emotional expression in enabling more effective LLM agents for multi-turn negotiation.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.04310.pdf", "abstract_url": "https://arxiv.org/abs/2509.04310", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "EvoEmo 是一个进化强化学习框架，用于优化大型语言模型在谈判中的动态情感表达，通过马尔可夫决策过程和遗传优化，在实验中优于基线策略。", "motivation": "解决现有LLM代理在谈判中忽视情感功能，产生被动情感响应，易受对手操纵和利用的问题。", "method": "使用进化强化学习框架，将情感状态转移建模为马尔可夫决策过程，并应用基于种群的遗传优化来演化高奖励情感策略。", "result": "EvoEmo 在实验中一致优于香草策略和固定情感策略基线，实现更高的成功率、效率和买家节省。", "conclusion": "自适应情感表达对于开发更有效的多轮谈判LLM代理至关重要。"}}
{"id": "2509.04317", "title": "Improving Robustness of AlphaZero Algorithms to Test-Time Environment Changes", "authors": ["Isidoro Tamassia", "Wendelin Böhmer"], "abstract": "The AlphaZero framework provides a standard way of combining Monte Carlo planning with prior knowledge provided by a previously trained policy-value neural network. AlphaZero usually assumes that the environment on which the neural network was trained will not change at test time, which constrains its applicability. In this paper, we analyze the problem of deploying AlphaZero agents in potentially changed test environments and demonstrate how the combination of simple modifications to the standard framework can significantly boost performance, even in settings with a low planning budget available. The code is publicly available on GitHub.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.04317.pdf", "abstract_url": "https://arxiv.org/abs/2509.04317", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文分析了AlphaZero算法在测试环境变化时的鲁棒性问题，并通过简单修改标准框架显著提升了性能，特别是在低规划预算设置下。", "motivation": "解决AlphaZero算法在测试时环境可能变化的情况下性能下降的问题，以扩展其应用范围。", "method": "结合蒙特卡洛规划和预训练策略价值神经网络，对标准AlphaZero框架进行简单修改。", "result": "修改后的框架显著提高了在变化测试环境中的性能，即使在低规划预算下也有效。", "conclusion": "通过框架修改，AlphaZero算法在环境变化时更具鲁棒性，代码已公开可用，便于进一步研究和应用。"}}
{"id": "2509.04343", "title": "Psychologically Enhanced AI Agents", "authors": ["Maciej Besta", "Shriram Chandran", "Robert Gerstenberger", "Mathis Lindner", "Marcin Chrapek", "Sebastian Hermann Martschat", "Taraneh Ghandi", "Patrick Iff", "Hubert Niewiadomski", "Piotr Nyczyk", "Jürgen Müller", "Torsten Hoefler"], "abstract": "We introduce MBTI-in-Thoughts, a framework for enhancing the effectiveness of Large Language Model (LLM) agents through psychologically grounded personality conditioning. Drawing on the Myers-Briggs Type Indicator (MBTI), our method primes agents with distinct personality archetypes via prompt engineering, enabling control over behavior along two foundational axes of human psychology, cognition and affect. We show that such personality priming yields consistent, interpretable behavioral biases across diverse tasks: emotionally expressive agents excel in narrative generation, while analytically primed agents adopt more stable strategies in game-theoretic settings. Our framework supports experimenting with structured multi-agent communication protocols and reveals that self-reflection prior to interaction improves cooperation and reasoning quality. To ensure trait persistence, we integrate the official 16Personalities test for automated verification. While our focus is on MBTI, we show that our approach generalizes seamlessly to other psychological frameworks such as Big Five, HEXACO, or Enneagram. By bridging psychological theory and LLM behavior design, we establish a foundation for psychologically enhanced AI agents without any fine-tuning.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computers and Society (cs.CY); Human-Computer Interaction (cs.HC); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.04343.pdf", "abstract_url": "https://arxiv.org/abs/2509.04343", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Computers and Society (cs.CY)", "Human-Computer Interaction (cs.HC)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "介绍MBTI-in-Thoughts框架，通过基于MBTI的人格条件化增强LLM代理，无需微调即可控制行为，提升任务表现和合作。", "motivation": "解决如何使AI代理行为更一致、可解释，并基于心理学理论增强其在多样任务中的有效性。", "method": "使用提示工程对LLM代理进行人格原型条件化，基于MBTI等框架，集成16Personalities测试验证特质持久性。", "result": "人格条件化导致行为偏差：情感表达型在叙事生成中表现优，分析型在博弈论中策略更稳定；自我反思提升合作和推理质量。", "conclusion": "框架为心理增强AI奠定基础，可泛化到其他心理学框架，促进AI行为设计与理论的结合。"}}
{"id": "2509.04104", "title": "Towards Stable and Personalised Profiles for Lexical Alignment in Spoken Human-Agent Dialogue", "authors": ["Keara Schaaij", "Roel Boumans", "Tibor Bosse", "Iris Hendrickx"], "abstract": "Lexical alignment, where speakers start to use similar words across conversation, is known to contribute to successful communication. However, its implementation in conversational agents remains underexplored, particularly considering the recent advancements in large language models (LLMs). As a first step towards enabling lexical alignment in human-agent dialogue, this study draws on strategies for personalising conversational agents and investigates the construction of stable, personalised lexical profiles as a basis for lexical alignment. Specifically, we varied the amounts of transcribed spoken data used for construction as well as the number of items included in the profiles per part-of-speech (POS) category and evaluated profile performance across time using recall, coverage, and cosine similarity metrics. It was shown that smaller and more compact profiles, created after 10 min of transcribed speech containing 5 items for adjectives, 5 items for conjunctions, and 10 items for adverbs, nouns, pronouns, and verbs each, offered the best balance in both performance and data efficiency. In conclusion, this study offers practical insights into constructing stable, personalised lexical profiles, taking into account minimal data requirements, serving as a foundational step toward lexical alignment strategies in conversational agents.", "subjects": "Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)", "comments": "Accepted for TSD 2025", "pdf_url": "https://arxiv.org/pdf/2509.04104.pdf", "abstract_url": "https://arxiv.org/abs/2509.04104", "categories": ["Computation and Language (cs.CL)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "本研究探讨了在口语人机对话中构建稳定且个性化的词汇配置文件，以实现词汇对齐，发现使用少量转录数据（10分钟）和紧凑的配置文件（如每个词类5-10个项目）在性能和效率上表现最佳。", "motivation": "解决在对话代理中实现词汇对齐的问题，尤其是在大型语言模型背景下，该领域尚未充分探索，旨在提升人机沟通的成功率。", "method": "通过变化转录口语数据的量和配置文件中的词类项目数（如形容词、连词等），使用召回率、覆盖率和余弦相似度指标评估配置文件在不同时间的性能。", "result": "结果显示，较小且紧凑的配置文件（基于10分钟数据，每个词类5-10个项目）在性能和数据处理效率上达到最佳平衡。", "conclusion": "本研究提供了构建稳定个性化词汇配置文件的实用见解，考虑了最小数据需求，为对话代理中的词汇对齐策略奠定了基础。"}}
{"id": "2509.04183", "title": "MAGneT: Coordinated Multi-Agent Generation of Synthetic Multi-Turn Mental Health Counseling Sessions", "authors": ["Aishik Mandal", "Tanmoy Chakraborty", "Iryna Gurevych"], "abstract": "The growing demand for scalable psychological counseling highlights the need for fine-tuning open-source Large Language Models (LLMs) with high-quality, privacy-compliant data, yet such data remains scarce. Here we introduce MAGneT, a novel multi-agent framework for synthetic psychological counseling session generation that decomposes counselor response generation into coordinated sub-tasks handled by specialized LLM agents, each modeling a key psychological technique. Unlike prior single-agent approaches, MAGneT better captures the structure and nuance of real counseling. In addition, we address inconsistencies in prior evaluation protocols by proposing a unified evaluation framework integrating diverse automatic and expert metrics. Furthermore, we expand the expert evaluations from four aspects of counseling in previous works to nine aspects, enabling a more thorough and robust assessment of data quality. Empirical results show that MAGneT significantly outperforms existing methods in quality, diversity, and therapeutic alignment of the generated counseling sessions, improving general counseling skills by 3.2% and CBT-specific skills by 4.3% on average on cognitive therapy rating scale (CTRS). Crucially, experts prefer MAGneT-generated sessions in 77.2% of cases on average across all aspects. Moreover, fine-tuning an open-source model on MAGneT-generated sessions shows better performance, with improvements of 6.3% on general counseling skills and 7.3% on CBT-specific skills on average on CTRS over those fine-tuned with sessions generated by baseline methods. We also make our code and data public.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "25 pages, 29 figures", "pdf_url": "https://arxiv.org/pdf/2509.04183.pdf", "abstract_url": "https://arxiv.org/abs/2509.04183", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "MAGneT是一种多智能体框架，用于生成合成心理健康咨询对话，通过分解任务到专门LLM代理，提高质量和多样性，优于现有方法，并公开代码和数据。", "motivation": "解决高质量、隐私合规的心理咨询数据稀缺问题，以微调开源大语言模型。", "method": "使用多智能体框架，将咨询师响应生成分解为子任务，由专门LLM代理处理，并引入统一评估框架。", "result": "MAGneT在质量、多样性和治疗对齐上显著优于基线，专家偏好率77.2%，微调模型性能提升6.3%-7.3%。", "conclusion": "MAGneT有效生成高质量咨询数据，支持模型微调，推动可扩展心理咨询发展。"}}
{"id": "2509.03787", "title": "Evaluating the Robustness of Retrieval-Augmented Generation to Adversarial Evidence in the Health Domain", "authors": ["Shakiba Amirshahi", "Amin Bigdeli", "Charles L. A. Clarke", "Amira Ghenai"], "abstract": "Retrieval augmented generation (RAG) systems provide a method for factually grounding the responses of a Large Language Model (LLM) by providing retrieved evidence, or context, as support. Guided by this context, RAG systems can reduce hallucinations and expand the ability of LLMs to accurately answer questions outside the scope of their training data. Unfortunately, this design introduces a critical vulnerability: LLMs may absorb and reproduce misinformation present in retrieved evidence. This problem is magnified if retrieved evidence contains adversarial material explicitly intended to promulgate misinformation. This paper presents a systematic evaluation of RAG robustness in the health domain and examines alignment between model outputs and ground-truth answers. We focus on the health domain due to the potential for harm caused by incorrect responses, as well as the availability of evidence-based ground truth for many common health-related questions. We conduct controlled experiments using common health questions, varying both the type and composition of the retrieved documents (helpful, harmful, and adversarial) as well as the framing of the question by the user (consistent, neutral, and inconsistent). Our findings reveal that adversarial documents substantially degrade alignment, but robustness can be preserved when helpful evidence is also present in the retrieval pool. These findings offer actionable insights for designing safer RAG systems in high-stakes domains by highlighting the need for retrieval safeguards. To enable reproducibility and facilitate future research, all experimental results are publicly available in our github repository.", "subjects": "Information Retrieval (cs.IR); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03787.pdf", "abstract_url": "https://arxiv.org/abs/2509.03787", "categories": ["Information Retrieval (cs.IR)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "评估检索增强生成在健康领域对对抗性证据的鲁棒性，发现对抗性文档会降低模型输出与真实答案的一致性，但存在有益证据时可保持鲁棒性，强调检索保障措施的必要性。", "motivation": "解决RAG系统中LLM可能吸收和传播检索证据中的错误信息问题，尤其在健康领域可能造成危害。", "method": "使用健康问题进行控制实验，变化检索文档类型（有益、有害、对抗性）和问题框架（一致、中性、不一致），评估模型输出与真实答案的对齐。", "result": "对抗性文档显著降低对齐性，但当检索池中包含有益证据时，鲁棒性得以保持。", "conclusion": "设计更安全的RAG系统需要检索保障措施，特别是在高风险领域，实验结果公开以促进未来研究。"}}
{"id": "2509.03741", "title": "Designing Gaze Analytics for ELA Instruction: A User-Centered Dashboard with Conversational AI Support", "authors": ["Eduardo Davalos", "Yike Zhang", "Shruti Jain", "Namrata Srivastava", "Trieu Truong", "Nafees-ul Haque", "Tristan Van", "Jorge Salas", "Sara McFadden", "Sun-Joo Cho", "Gautam Biswas", "Amanda Goodwin"], "abstract": "Eye-tracking offers rich insights into student cognition and engagement, but remains underutilized in classroom-facing educational technology due to challenges in data interpretation and accessibility. In this paper, we present the iterative design and evaluation of a gaze-based learning analytics dashboard for English Language Arts (ELA), developed through five studies involving teachers and students. Guided by user-centered design and data storytelling principles, we explored how gaze data can support reflection, formative assessment, and instructional decision-making. Our findings demonstrate that gaze analytics can be approachable and pedagogically valuable when supported by familiar visualizations, layered explanations, and narrative scaffolds. We further show how a conversational agent, powered by a large language model (LLM), can lower cognitive barriers to interpreting gaze data by enabling natural language interactions with multimodal learning analytics. We conclude with design implications for future EdTech systems that aim to integrate novel data modalities in classroom contexts.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": "22 pages, 9 figures, 3 tables, submitted to IUI2026", "pdf_url": "https://arxiv.org/pdf/2509.03741.pdf", "abstract_url": "https://arxiv.org/abs/2509.03741", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过用户中心设计，开发并评估了用于英语语言艺术教学的注视分析仪表板，结合对话AI支持，使注视数据更易于解释和教学应用。", "motivation": "解决眼动追踪数据在课堂教育技术中因解释困难和可访问性低而未被充分利用的问题。", "method": "采用迭代设计和用户中心方法，通过五项研究探索注视数据与对话AI（基于大语言模型）的结合，以支持反思和教学决策。", "result": "发现注视分析在熟悉可视化、分层解释和叙事支架支持下具有教学价值，对话AI能通过自然语言交互降低认知障碍。", "conclusion": "为未来教育技术系统整合新数据模态提供了设计启示，强调可访问性和教学实用性。"}}
{"id": "2509.03771", "title": "Learning an Adversarial World Model for Automated Curriculum Generation in MARL", "authors": ["Brennen Hill"], "abstract": "World models that infer and predict environmental dynamics are foundational to embodied intelligence. However, their potential is often limited by the finite complexity and implicit biases of hand-crafted training environments. To develop truly generalizable and robust agents, we need environments that scale in complexity alongside the agents learning within them. In this work, we reframe the challenge of environment generation as the problem of learning a goal-conditioned, generative world model. We propose a system where a generative **Attacker** agent learns an implicit world model to synthesize increasingly difficult challenges for a team of cooperative **Defender** agents. The Attacker's objective is not passive prediction, but active, goal-driven interaction: it models and generates world states (i.e., configurations of enemy units) specifically to exploit the Defenders' weaknesses. Concurrently, the embodied Defender team learns a cooperative policy to overcome these generated worlds. This co-evolutionary dynamic creates a self-scaling curriculum where the world model continuously adapts to challenge the decision-making policy of the agents, providing an effectively infinite stream of novel and relevant training scenarios. We demonstrate that this framework leads to the emergence of complex behaviors, such as the world model learning to generate flanking and shielding formations, and the defenders learning coordinated focus-fire and spreading tactics. Our findings position adversarial co-evolution as a powerful method for learning instrumental world models that drive agents toward greater strategic depth and robustness.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03771.pdf", "abstract_url": "https://arxiv.org/abs/2509.03771", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种通过对抗性共同进化学习目标条件生成世界模型的方法，为多智能体强化学习自动生成难度递增的课程，以提升智能体的泛化性和鲁棒性。", "motivation": "解决手制训练环境的有限复杂性和隐含偏见问题，需要环境能随智能体学习而扩展复杂性，以开发更通用和鲁棒的智能体。", "method": "使用生成性攻击者智能体学习隐式世界模型，合成越来越难的挑战来利用防御者智能体的弱点，同时防御者学习合作策略，形成自扩展课程。", "result": "框架导致复杂行为的涌现，如世界模型生成侧翼和防护阵型，防御者学习协调焦点火和分散战术，证明了对抗性共同进化的有效性。", "conclusion": "对抗性共同进化是学习工具性世界模型的有力方法，能推动智能体实现更深战略和鲁棒性。"}}
{"id": "2509.03793", "title": "SAMVAD: A Multi-Agent System for Simulating Judicial Deliberation Dynamics in India", "authors": ["Prathamesh Devadiga", "Omkaar Jayadev Shetty", "Pooja Agarwal"], "abstract": "Understanding the complexities of judicial deliberation is crucial for assessing the efficacy and fairness of a justice system. However, empirical studies of judicial panels are constrained by significant ethical and practical barriers. This paper introduces SAMVAD, an innovative Multi-Agent System (MAS) designed to simulate the deliberation process within the framework of the Indian justice system.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03793.pdf", "abstract_url": "https://arxiv.org/abs/2509.03793", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "SAMVAD 是一个多智能体系统，模拟印度司法系统中的审议过程，以克服伦理和实践障碍。", "motivation": "解决司法审议研究中的伦理和实践障碍，以评估司法系统的效能和公平性。", "method": "使用多智能体系统（MAS）来模拟印度司法系统中的审议动态。", "result": "开发了 SAMVAD 系统，能够模拟审议过程，提供对司法动态的洞察。", "conclusion": "SAMVAD 有助于更好地理解司法审议，促进司法系统的改进和公平性评估。"}}
{"id": "2509.03780", "title": "Natural Latents: Latent Variables Stable Across Ontologies", "authors": ["John Wentworth", "David Lorell"], "abstract": "Suppose two Bayesian agents each learn a generative model of the same environment. We will assume the two have converged on the predictive distribution, i.e. distribution over some observables in the environment, but may have different generative models containing different latent variables. Under what conditions can one agent guarantee that their latents are a function of the other agents latents?", "subjects": "Probability (math.PR); Artificial Intelligence (cs.AI); Information Theory (cs.IT); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03780.pdf", "abstract_url": "https://arxiv.org/abs/2509.03780", "categories": ["Probability (math.PR)", "Artificial Intelligence (cs.AI)", "Information Theory (cs.IT)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了当两个贝叶斯智能体学习同一环境的生成模型时，在何种条件下一个智能体的潜在变量可以保证是另一个智能体潜在变量的函数，假设它们具有相同的预测分布但可能使用不同的潜在变量。", "motivation": "解决在贝叶斯智能体使用不同潜在变量建模同一环境时，如何确保一个智能体的潜在变量可以从另一个智能体的潜在变量中推导出来的问题，以促进模型间的一致性和可解释性。", "method": "假设两个智能体收敛于相同的预测分布，分析潜在变量的稳定性条件，可能涉及信息论或概率论方法来推导函数依赖关系。", "result": "关键发现是，在特定条件下（如潜在变量是自然潜在变量，即在某些变换下稳定），一个智能体的潜在变量可以是另一个的函数，从而提供跨本体论的稳定性保证。", "conclusion": "结论是识别自然潜在变量有助于确保不同生成模型间的兼容性，对多智能体系统、迁移学习和因果推断具有潜在应用价值。"}}
{"id": "2509.03834", "title": "From Leiden to Pleasure Island: The Constant Potts Model for Community Detection as a Hedonic Game", "authors": ["Lucas Lopes Felipe", "Konstantin Avrachenkov", "Daniel Sadoc Menasche"], "abstract": "Community detection is one of the fundamental problems in data science which consists of partitioning nodes into disjoint communities. We present a game-theoretic perspective on the Constant Potts Model (CPM) for partitioning networks into disjoint communities, emphasizing its efficiency, robustness, and accuracy. Efficiency: We reinterpret CPM as a potential hedonic game by decomposing its global Hamiltonian into local utility functions, where the local utility gain of each agent matches the corresponding increase in global utility. Leveraging this equivalence, we prove that local optimization of the CPM objective via better-response dynamics converges in pseudo-polynomial time to an equilibrium partition. Robustness: We introduce and relate two stability criteria: a strict criterion based on a novel notion of robustness, requiring nodes to simultaneously maximize neighbors and minimize non-neighbors within communities, and a relaxed utility function based on a weighted sum of these objectives, controlled by a resolution parameter. Accuracy: In community tracking scenarios, where initial partitions are used to bootstrap the Leiden algorithm with partial ground-truth information, our experiments reveal that robust partitions yield higher accuracy in recovering ground-truth communities.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT)", "comments": "Manuscript submitted to Physica A: Statistical Mechanics and its Applications", "pdf_url": "https://arxiv.org/pdf/2509.03834.pdf", "abstract_url": "https://arxiv.org/abs/2509.03834", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computer Science and Game Theory (cs.GT)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文从博弈论角度重新解释恒定Potts模型（CPM），将其视为享乐博弈，证明局部优化在伪多项式时间内收敛，并引入鲁棒性标准，实验显示在社区跟踪中提高准确性。", "motivation": "解决社区检测问题，特别是通过博弈论视角提升CPM的效率、鲁棒性和准确性。", "method": "将CPM分解为局部效用函数，使用更好响应动态进行局部优化，并引入基于邻居和非邻居的鲁棒性标准。", "result": "局部优化收敛到均衡分区，鲁棒分区在社区跟踪实验中提高了ground-truth社区的恢复准确性。", "conclusion": "CPM的博弈论重释提供高效、鲁棒的社区检测方法，适用于实际数据科学应用。"}}
{"id": "2509.03845", "title": "Meta-Inverse Reinforcement Learning for Mean Field Games via Probabilistic Context Variables", "authors": ["Yang Chen", "Xiao Lin", "Bo Yan", "Libo Zhang", "Jiamou Liu", "Neset Özkan Tan", "Michael Witbrock"], "abstract": "Designing suitable reward functions for numerous interacting intelligent agents is challenging in real-world applications. Inverse reinforcement learning (IRL) in mean field games (MFGs) offers a practical framework to infer reward functions from expert demonstrations. While promising, the assumption of agent homogeneity limits the capability of existing methods to handle demonstrations with heterogeneous and unknown objectives, which are common in practice. To this end, we propose a deep latent variable MFG model and an associated IRL method. Critically, our method can infer rewards from different yet structurally similar tasks without prior knowledge about underlying contexts or modifying the MFG model itself. Our experiments, conducted on simulated scenarios and a real-world spatial taxi-ride pricing problem, demonstrate the superiority of our approach over state-of-the-art IRL methods in MFGs.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT)", "comments": "Accepted to AAAI 2024", "pdf_url": "https://arxiv.org/pdf/2509.03845.pdf", "abstract_url": "https://arxiv.org/abs/2509.03845", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computer Science and Game Theory (cs.GT)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种通过概率上下文变量的元逆强化学习方法，用于平均场博弈，以从专家演示中推断奖励函数，处理异构和未知目标，并在模拟和真实场景中验证了其优越性。", "motivation": "解决平均场博弈中奖励函数设计困难的问题，特别是当专家演示具有异构和未知目标时，现有方法假设代理同质性，限制了实际应用。", "method": "使用深度潜在变量平均场博弈模型和关联的逆强化学习方法，无需先验知识或修改模型即可推断不同但结构相似任务的奖励。", "result": "在模拟场景和真实世界出租车定价问题中，实验显示该方法优于最先进的平均场博弈逆强化学习方法。", "conclusion": "该方法扩展了平均场博弈逆强化学习的应用范围，能有效处理异构目标，具有实际价值。"}}
{"id": "2509.04139", "title": "Enhancing Technical Documents Retrieval for RAG", "authors": ["Songjiang Lai", "Tsun-Hin Cheung", "Ka-Chun Fung", "Kaiwen Xue", "Kwan-Ho Lin", "Yan-Ming Choi", "Vincent Ng", "Kin-Man Lam"], "abstract": "In this paper, we introduce Technical-Embeddings, a novel framework designed to optimize semantic retrieval in technical documentation, with applications in both hardware and software development. Our approach addresses the challenges of understanding and retrieving complex technical content by leveraging the capabilities of Large Language Models (LLMs). First, we enhance user queries by generating expanded representations that better capture user intent and improve dataset diversity, thereby enriching the fine-tuning process for embedding models. Second, we apply summary extraction techniques to encode essential contextual information, refining the representation of technical documents. To further enhance retrieval performance, we fine-tune a bi-encoder BERT model using soft prompting, incorporating separate learning parameters for queries and document context to capture fine-grained semantic nuances. We evaluate our approach on two public datasets, RAG-EDA and Rust-Docs-QA, demonstrating that Technical-Embeddings significantly outperforms baseline models in both precision and recall. Our findings highlight the effectiveness of integrating query expansion and contextual summarization to enhance information access and comprehension in technical domains. This work advances the state of Retrieval-Augmented Generation (RAG) systems, offering new avenues for efficient and accurate technical document retrieval in engineering and product development workflows.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.04139.pdf", "abstract_url": "https://arxiv.org/abs/2509.04139", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了Technical-Embeddings框架，通过查询扩展、摘要提取和BERT微调优化技术文档检索，在RAG-EDA和Rust-Docs-QA数据集上表现优于基线模型。", "motivation": "解决技术文档中复杂内容理解和检索的挑战，以提升RAG系统在硬件和软件开发中的应用。", "method": "使用LLM增强查询、摘要提取编码上下文，并微调bi-encoder BERT模型，结合软提示和分离学习参数。", "result": "在精度和召回率上显著超越基线模型，验证了查询扩展和上下文摘要的有效性。", "conclusion": "该工作推进了RAG系统，为工程和产品开发提供了高效准确的技术文档检索新途径。"}}
{"id": "2509.04303", "title": "HumAIne-Chatbot: Real-Time Personalized Conversational AI via Reinforcement Learning", "authors": ["Georgios Makridis", "Georgios Fragiadakis", "Jorge Oliveira", "Tomaz Saraiva", "Philip Mavrepis", "Georgios Fatouros", "Dimosthenis Kyriazis"], "abstract": "Current conversational AI systems often provide generic, one-size-fits-all interactions that overlook individual user characteristics and lack adaptive dialogue management. To address this gap, we introduce \\textbf{HumAIne-chatbot}, an AI-driven conversational agent that personalizes responses through a novel user profiling framework. The system is pre-trained on a diverse set of GPT-generated virtual personas to establish a broad prior over user types. During live interactions, an online reinforcement learning agent refines per-user models by combining implicit signals (e.g. typing speed, sentiment, engagement duration) with explicit feedback (e.g., likes and dislikes). This profile dynamically informs the chatbot dialogue policy, enabling real-time adaptation of both content and style. To evaluate the system, we performed controlled experiments with 50 synthetic personas in multiple conversation domains. The results showed consistent improvements in user satisfaction, personalization accuracy, and task achievement when personalization features were enabled. Statistical analysis confirmed significant differences between personalized and nonpersonalized conditions, with large effect sizes across key metrics. These findings highlight the effectiveness of AI-driven user profiling and provide a strong foundation for future real-world validation.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": "11 pages, 4 figures, IEEE conference format", "pdf_url": "https://arxiv.org/pdf/2509.04303.pdf", "abstract_url": "https://arxiv.org/abs/2509.04303", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍HumAIne-chatbot，一种通过强化学习实现实时个性化对话的AI系统，利用用户画像框架提升交互质量。", "motivation": "解决当前对话AI系统通用化、缺乏个性化适应的问题。", "method": "使用预训练的GPT生成虚拟角色建立先验知识，结合在线强化学习整合隐式和显式反馈进行用户建模。", "result": "实验显示个性化功能显著提高用户满意度、个性化准确性和任务完成率，统计差异显著。", "conclusion": "AI驱动的用户画像有效，为实际应用提供基础。"}}
{"id": "2509.04152", "title": "TAGAL: Tabular Data Generation using Agentic LLM Methods", "authors": ["Benoît Ronval", "Pierre Dupont", "Siegfried Nijssen"], "abstract": "The generation of data is a common approach to improve the performance of machine learning tasks, among which is the training of models for classification. In this paper, we present TAGAL, a collection of methods able to generate synthetic tabular data using an agentic workflow. The methods leverage Large Language Models (LLMs) for an automatic and iterative process that uses feedback to improve the generated data without any further LLM training. The use of LLMs also allows for the addition of external knowledge in the generation process. We evaluate TAGAL across diverse datasets and different aspects of quality for the generated data. We look at the utility of downstream ML models, both by training classifiers on synthetic data only and by combining real and synthetic data. Moreover, we compare the similarities between the real and the generated data. We show that TAGAL is able to perform on par with state-of-the-art approaches that require LLM training and generally outperforms other training-free approaches. These findings highlight the potential of agentic workflow and open new directions for LLM-based data generation methods.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.04152.pdf", "abstract_url": "https://arxiv.org/abs/2509.04152", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "TAGAL是一种使用代理工作流和大型语言模型生成合成表格数据的方法，无需额外训练，性能媲美需训练的先进方法，并优于其他免训练方法。", "motivation": "解决机器学习中数据生成问题，特别是提高分类模型性能，通过自动化和迭代过程生成高质量表格数据。", "method": "利用大型语言模型（LLMs）的代理工作流，自动迭代生成数据，并整合外部知识和反馈以改进数据质量。", "result": "在多个数据集上评估，TAGAL生成的数据在实用性和相似性方面与需训练的先进方法相当，并优于其他免训练方法。", "conclusion": "代理工作流和LLMs在数据生成中具有潜力，为基于LLM的方法开辟了新方向。"}}
