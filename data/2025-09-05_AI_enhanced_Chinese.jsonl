{"id": "2509.03527", "title": "Multilevel Analysis of Cryptocurrency News using RAG Approach with Fine-Tuned Mistral Large Language Model", "authors": ["Bohdan M. Pavlyshenko"], "abstract": "In the paper, we consider multilevel multitask analysis of cryptocurrency news using a fine-tuned Mistral 7B large language model with retrieval-augmented generation (RAG).", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03527.pdf", "abstract_url": "https://arxiv.org/abs/2509.03527", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "使用微调的Mistral 7B大语言模型和检索增强生成（RAG）方法对加密货币新闻进行多层次多任务分析。", "motivation": "解决加密货币新闻的复杂分析问题，通过结合检索和生成技术提高分析的准确性和深度。", "method": "采用检索增强生成（RAG）方法，结合微调的Mistral 7B大语言模型进行多层次多任务分析。", "result": "该方法能够有效处理加密货币新闻，提供更精确和全面的分析结果。", "conclusion": "RAG与微调大语言模型的结合为加密货币新闻分析提供了高效工具，具有实际应用价值。"}}
{"id": "2509.03540", "title": "Improving Factuality in LLMs via Inference-Time Knowledge Graph Construction", "authors": ["Shanglin Wu", "Lihui Liu", "Jinho D. Choi", "Kai Shu"], "abstract": "Large Language Models (LLMs) often struggle with producing factually consistent answers due to limitations in their parametric memory. Retrieval-Augmented Generation (RAG) methods address this issue by incorporating external knowledge from trusted sources at inference time. However, such methods typically treat knowledge as unstructured text, which limits their ability to support compositional reasoning and identify factual inconsistencies. To overcome these limitations, we propose a novel framework that dynamically constructs and expands knowledge graphs (KGs) during inference, integrating both internal knowledge extracted from LLMs and external information retrieved from external sources. Our method begins by extracting a seed KG from the question via prompting, followed by iterative expansion using the LLM's latent knowledge. The graph is then selectively refined through external retrieval, enhancing factual coverage and correcting inaccuracies. We evaluate our approach on three diverse factual QA benchmarks, demonstrating consistent improvements in factual accuracy, answer precision, and interpretability over baseline prompting and static KG-augmented methods. Our findings suggest that inference-time KG construction is a promising direction for enhancing LLM factuality in a structured, interpretable, and scalable manner.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03540.pdf", "abstract_url": "https://arxiv.org/abs/2509.03540", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "通过推理时动态构建知识图谱，结合内部和外部知识，提高LLMs的事实准确性。", "motivation": "解决LLMs在生成事实一致答案时的局限性，特别是RAG方法在处理非结构化知识时无法支持组合推理和识别事实不一致的问题。", "method": "提出一个框架，在推理时从问题中提取种子知识图谱，迭代扩展使用LLM的潜在知识，并通过外部检索选择性精炼图谱。", "result": "在三个事实QA基准测试中，相比基线方法，在事实准确性、答案精确性和可解释性上取得一致改进。", "conclusion": "推理时知识图谱构建是增强LLM事实性的有前景方向，具有结构化、可解释和可扩展的优点。"}}
{"id": "2509.03565", "title": "ResearchPulse: Building Method-Experiment Chains through Multi-Document Scientific Inference", "authors": ["Qi Chen", "Jingxuan Wei", "Zhuoya Yao", "Haiguang Wang", "Gaowei Wu", "Bihui Yu", "Siyuan Li", "Cheng Tan"], "abstract": "Understanding how scientific ideas evolve requires more than summarizing individual papers-it demands structured, cross-document reasoning over thematically related research. In this work, we formalize multi-document scientific inference, a new task that extracts and aligns motivation, methodology, and experimental results across related papers to reconstruct research development chains. This task introduces key challenges, including temporally aligning loosely structured methods and standardizing heterogeneous experimental tables. We present ResearchPulse, an agent-based framework that integrates instruction planning, scientific content extraction, and structured visualization. It consists of three coordinated agents: a Plan Agent for task decomposition, a Mmap-Agent that constructs motivation-method mind maps, and a Lchart-Agent that synthesizes experimental line charts. To support this task, we introduce ResearchPulse-Bench, a citation-aware benchmark of annotated paper clusters. Experiments show that our system, despite using 7B-scale agents, consistently outperforms strong baselines like GPT-4o in semantic alignment, structural consistency, and visual fidelity. The dataset are available in", "subjects": "Computation and Language (cs.CL); Multimedia (cs.MM)", "comments": "Accepted to ACM MM 2025", "pdf_url": "https://arxiv.org/pdf/2509.03565.pdf", "abstract_url": "https://arxiv.org/abs/2509.03565", "categories": ["Computation and Language (cs.CL)", "Multimedia (cs.MM)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了ResearchPulse，一个基于代理的框架，用于多文档科学推理，通过提取和整合动机、方法和实验结果来构建研究发展链，并在基准测试中优于GPT-4o等基线。", "motivation": "解决科学思想演变需要跨文档结构化推理的问题，传统方法无法有效对齐和标准化相关论文中的动机、方法和实验数据。", "method": "使用基于代理的框架，包括计划代理、思维导图代理和线图代理，进行任务分解、内容提取和可视化，并引入基准数据集ResearchPulse-Bench。", "result": "系统使用7B规模代理，在语义对齐、结构一致性和视觉保真度上一致优于GPT-4o等基线。", "conclusion": "ResearchPulse框架有效支持多文档科学推理任务，提供了新的方法和基准，促进科学研究的结构化分析和可视化。"}}
{"id": "2509.03918", "title": "MTQA:Matrix of Thought for Enhanced Reasoning in Complex Question Answering", "authors": ["Fengxiao Tang", "Yufeng Li", "Zongzong Wu", "Ming Zhao"], "abstract": "Complex Question Answering (QA) is a fundamental and challenging task in NLP. While large language models (LLMs) exhibit impressive performance in QA, they suffer from significant performance degradation when facing complex and abstract QA tasks due to insufficient reasoning capabilities. Works such as Chain-of-Thought (CoT) and Tree-of-Thought (ToT) aim to enhance LLMs' reasoning abilities, but they face issues such as in-layer redundancy in tree structures and single paths in chain structures. Although some studies utilize Retrieval-Augmented Generation (RAG) methods to assist LLMs in reasoning, the challenge of effectively utilizing large amounts of information involving multiple entities and hops remains critical. To address this, we propose the Matrix of Thought (MoT), a novel and efficient LLM thought structure. MoT explores the problem in both horizontal and vertical dimensions through the \"column-cell communication\" mechanism, enabling LLMs to actively engage in multi-strategy and deep-level thinking, reducing redundancy within the column cells and enhancing reasoning capabilities. Furthermore, we develop a fact-correction mechanism by constructing knowledge units from retrieved knowledge graph triples and raw text to enhance the initial knowledge for LLM reasoning and correct erroneous answers. This leads to the development of an efficient and accurate QA framework (MTQA). Experimental results show that our framework outperforms state-of-the-art methods on four widely-used datasets in terms of F1 and EM scores, with reasoning time only 14.4\\% of the baseline methods, demonstrating both its efficiency and accuracy. The code for this framework is available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03918.pdf", "abstract_url": "https://arxiv.org/abs/2509.03918", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "提出Matrix of Thought (MoT)方法，通过水平和垂直维度推理及事实校正机制，提高复杂问答任务的效率和准确性。", "motivation": "解决大型语言模型在复杂抽象问答中推理能力不足的问题，现有方法如CoT和ToT存在冗余和单一路径限制，且RAG方法难以有效利用多实体和多跳信息。", "method": "使用MoT结构，通过列-单元通信机制进行多策略深度思考，结合知识图谱三元组和原始文本构建知识单元进行事实校正。", "result": "在四个数据集上F1和EM分数优于现有方法，推理时间仅为基线的14.4%，证明高效且准确。", "conclusion": "MoT框架显著提升LLM推理能力，适用于复杂问答，代码已开源，具有实际应用价值。"}}
{"id": "2509.03891", "title": "MobileRAG: Enhancing Mobile Agent with Retrieval-Augmented Generation", "authors": ["Gowen Loo", "Chang Liu", "Qinghong Yin", "Xiang Chen", "Jiawei Chen", "Jingyuan Zhang", "Yu Tian"], "abstract": "Smartphones have become indispensable in people's daily lives, permeating nearly every aspect of modern society. With the continuous advancement of large language models (LLMs), numerous LLM-based mobile agents have emerged. These agents are capable of accurately parsing diverse user queries and automatically assisting users in completing complex or repetitive operations. However, current agents 1) heavily rely on the comprehension ability of LLMs, which can lead to errors caused by misoperations or omitted steps during tasks, 2) lack interaction with the external environment, often terminating tasks when an app cannot fulfill user queries, and 3) lack memory capabilities, requiring each instruction to reconstruct the interface and being unable to learn from and correct previous mistakes. To alleviate the above issues, we propose MobileRAG, a mobile agents framework enhanced by Retrieval-Augmented Generation (RAG), which includes InterRAG, LocalRAG, and MemRAG. It leverages RAG to more quickly and accurately identify user queries and accomplish complex and long-sequence mobile tasks. Additionally, to more comprehensively assess the performance of MobileRAG, we introduce MobileRAG-Eval, a more challenging benchmark characterized by numerous complex, real-world mobile tasks that require external knowledge assistance. Extensive experimental results on MobileRAG-Eval demonstrate that MobileRAG can easily handle real-world mobile tasks, achieving 10.3\\% improvement over state-of-the-art methods with fewer operational steps. Our code is publicly available at:", "subjects": "Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03891.pdf", "abstract_url": "https://arxiv.org/abs/2509.03891", "categories": ["Computation and Language (cs.CL)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "MobileRAG是一个通过检索增强生成（RAG）提升移动代理性能的框架，包括InterRAG、LocalRAG和MemRAG组件，在MobileRAG-Eval基准测试中比现有方法提升10.3%，操作步骤更少。", "motivation": "解决当前基于大语言模型的移动代理存在依赖LLM理解能力导致错误、缺乏外部环境交互和记忆能力的问题。", "method": "采用检索增强生成（RAG）技术，通过InterRAG、LocalRAG和MemRAG组件快速准确识别用户查询并完成复杂任务。", "result": "在MobileRAG-Eval基准测试中，MobileRAG能轻松处理真实世界移动任务，性能提升10.3%，操作步骤减少。", "conclusion": "MobileRAG框架有效增强移动代理能力，提高任务准确性和效率，代码已公开。"}}
{"id": "2509.03934", "title": "SelfAug: Mitigating Catastrophic Forgetting in Retrieval-Augmented Generation via Distribution Self-Alignment", "authors": ["Yuqing Huang", "Rongyang Zhang", "Qimeng Wang", "Chengqiang Lu", "Yan Gao", "Yi Wu", "Yao Hu", "Xuyang Zhi", "Guiquan Liu", "Xin Li", "Hao Wang", "Enhong Chen"], "abstract": "Recent advancements in large language models (LLMs) have revolutionized natural language processing through their remarkable capabilities in understanding and executing diverse tasks. While supervised fine-tuning, particularly in Retrieval-Augmented Generation (RAG) scenarios, effectively enhances task-specific performance, it often leads to catastrophic forgetting, where models lose their previously acquired knowledge and general capabilities. Existing solutions either require access to general instruction data or face limitations in preserving the model's original distribution. To overcome these limitations, we propose SelfAug, a self-distribution alignment method that aligns input sequence logits to preserve the model's semantic distribution, thereby mitigating catastrophic forgetting and improving downstream performance. Extensive experiments demonstrate that SelfAug achieves a superior balance between downstream learning and general capability retention. Our comprehensive empirical analysis reveals a direct correlation between distribution shifts and the severity of catastrophic forgetting in RAG scenarios, highlighting how the absence of RAG capabilities in general instruction tuning leads to significant distribution shifts during fine-tuning. Our findings not only advance the understanding of catastrophic forgetting in RAG contexts but also provide a practical solution applicable across diverse fine-tuning scenarios. Our code is publicly available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03934.pdf", "abstract_url": "https://arxiv.org/abs/2509.03934", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "SelfAug是一种通过分布自对齐来减轻检索增强生成中灾难性遗忘的方法，通过对齐输入序列对数来保持模型语义分布，从而在微调中平衡下游学习和通用能力保留。", "motivation": "解决大型语言模型在检索增强生成微调中导致的灾难性遗忘问题，即模型失去先前知识和通用能力，现有方法需要通用指令数据或无法有效保持原始分布。", "method": "使用自分布对齐方法SelfAug，通过对齐输入序列的对数来保持模型的语义分布，从而减轻遗忘并提升下游性能。", "result": "广泛实验显示SelfAug在下游学习和通用能力保留之间达到优越平衡，实证分析揭示分布偏移与灾难性遗忘严重性直接相关。", "conclusion": "SelfAug不仅推进了对RAG中灾难性遗忘的理解，还提供了一个适用于多种微调场景的实用解决方案，代码已公开。"}}
{"id": "2509.03940", "title": "VoxRole: A Comprehensive Benchmark for Evaluating Speech-Based Role-Playing Agents", "authors": ["Weihao Wu", "Liang Cao", "Xinyu Wu", "Zhiwei Lin", "Rui Niu", "Jingbei Li", "Zhiyong Wu"], "abstract": "Recent significant advancements in Large Language Models (LLMs) have greatly propelled the development of Role-Playing Conversational Agents (RPCAs). These systems aim to create immersive user experiences through consistent persona adoption. However, current RPCA research faces dual limitations. First, existing work predominantly focuses on the textual modality, entirely overlooking critical paralinguistic features including intonation, prosody, and rhythm in speech, which are essential for conveying character emotions and shaping vivid identities. Second, the speech-based role-playing domain suffers from a long-standing lack of standardized evaluation benchmarks. Most current spoken dialogue datasets target only fundamental capability assessments, featuring thinly sketched or ill-defined character profiles. Consequently, they fail to effectively quantify model performance on core competencies like long-term persona consistency. To address this critical gap, we introduce VoxRole, the first comprehensive benchmark specifically designed for the evaluation of speech-based RPCAs. The benchmark comprises 13335 multi-turn dialogues, totaling 65.6 hours of speech from 1228 unique characters across 261 movies. To construct this resource, we propose a novel two-stage automated pipeline that first aligns movie audio with scripts and subsequently employs an LLM to systematically build multi-dimensional profiles for each character. Leveraging VoxRole, we conduct a multi-dimensional evaluation of contemporary spoken dialogue models, revealing crucial insights into their respective strengths and limitations in maintaining persona consistency.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Sound (cs.SD)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03940.pdf", "abstract_url": "https://arxiv.org/abs/2509.03940", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Sound (cs.SD)"], "matching_keywords": ["agent"], "AI": {"tldr": "VoxRole是首个专为评估语音角色扮演代理设计的综合基准，包含大量电影对话数据，通过自动化流程构建角色档案，用于多维评估模型性能。", "motivation": "解决当前角色扮演对话代理研究局限于文本模态、缺乏标准化语音评估基准的问题，以更好地量化模型在保持角色一致性方面的能力。", "method": "提出两阶段自动化流程：先对齐电影音频与剧本，再用LLM系统构建多维角色档案，创建包含13335个多轮对话的VoxRole基准。", "result": "评估显示当代语音对话模型在维持角色一致性方面存在显著优势和局限，提供了关键洞察。", "conclusion": "VoxRole填补了语音角色扮演领域评估空白，为未来研究提供了标准化工具，强调语音特征对沉浸式体验的重要性。"}}
{"id": "2509.04104", "title": "Towards Stable and Personalised Profiles for Lexical Alignment in Spoken Human-Agent Dialogue", "authors": ["Keara Schaaij", "Roel Boumans", "Tibor Bosse", "Iris Hendrickx"], "abstract": "Lexical alignment, where speakers start to use similar words across conversation, is known to contribute to successful communication. However, its implementation in conversational agents remains underexplored, particularly considering the recent advancements in large language models (LLMs). As a first step towards enabling lexical alignment in human-agent dialogue, this study draws on strategies for personalising conversational agents and investigates the construction of stable, personalised lexical profiles as a basis for lexical alignment. Specifically, we varied the amounts of transcribed spoken data used for construction as well as the number of items included in the profiles per part-of-speech (POS) category and evaluated profile performance across time using recall, coverage, and cosine similarity metrics. It was shown that smaller and more compact profiles, created after 10 min of transcribed speech containing 5 items for adjectives, 5 items for conjunctions, and 10 items for adverbs, nouns, pronouns, and verbs each, offered the best balance in both performance and data efficiency. In conclusion, this study offers practical insights into constructing stable, personalised lexical profiles, taking into account minimal data requirements, serving as a foundational step toward lexical alignment strategies in conversational agents.", "subjects": "Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)", "comments": "Accepted for TSD 2025", "pdf_url": "https://arxiv.org/pdf/2509.04104.pdf", "abstract_url": "https://arxiv.org/abs/2509.04104", "categories": ["Computation and Language (cs.CL)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究如何构建稳定且个性化的词汇档案，以支持人机对话中的词汇对齐，发现使用少量转录语音数据创建紧凑档案在性能和效率上最佳。", "motivation": "解决在大型语言模型背景下，如何实现人机对话中的词汇对齐，以提升沟通效果，但当前方法仍不足的问题。", "method": "通过变化转录语音数据量和词性类别中的项目数，构建个性化词汇档案，并使用召回率、覆盖率和余弦相似度指标评估档案性能。", "result": "使用10分钟转录语音，包含5个形容词、5个连词，以及各10个副词、名词、代词和动词的档案，在性能和效率上表现最佳。", "conclusion": "研究提供了构建稳定个性化词汇档案的实用见解，考虑了最小数据需求，为对话代理中的词汇对齐策略奠定了基础。"}}
{"id": "2509.04183", "title": "MAGneT: Coordinated Multi-Agent Generation of Synthetic Multi-Turn Mental Health Counseling Sessions", "authors": ["Aishik Mandal", "Tanmoy Chakraborty", "Iryna Gurevych"], "abstract": "The growing demand for scalable psychological counseling highlights the need for fine-tuning open-source Large Language Models (LLMs) with high-quality, privacy-compliant data, yet such data remains scarce. Here we introduce MAGneT, a novel multi-agent framework for synthetic psychological counseling session generation that decomposes counselor response generation into coordinated sub-tasks handled by specialized LLM agents, each modeling a key psychological technique. Unlike prior single-agent approaches, MAGneT better captures the structure and nuance of real counseling. In addition, we address inconsistencies in prior evaluation protocols by proposing a unified evaluation framework integrating diverse automatic and expert metrics. Furthermore, we expand the expert evaluations from four aspects of counseling in previous works to nine aspects, enabling a more thorough and robust assessment of data quality. Empirical results show that MAGneT significantly outperforms existing methods in quality, diversity, and therapeutic alignment of the generated counseling sessions, improving general counseling skills by 3.2% and CBT-specific skills by 4.3% on average on cognitive therapy rating scale (CTRS). Crucially, experts prefer MAGneT-generated sessions in 77.2% of cases on average across all aspects. Moreover, fine-tuning an open-source model on MAGneT-generated sessions shows better performance, with improvements of 6.3% on general counseling skills and 7.3% on CBT-specific skills on average on CTRS over those fine-tuned with sessions generated by baseline methods. We also make our code and data public.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "25 pages, 29 figures", "pdf_url": "https://arxiv.org/pdf/2509.04183.pdf", "abstract_url": "https://arxiv.org/abs/2509.04183", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "MAGneT是一种多智能体框架，用于生成高质量、隐私合规的心理咨询对话，通过分解任务和专家评估改进现有方法，显著提升会话质量和治疗效果。", "motivation": "解决高质量、隐私合规的心理咨询数据稀缺问题，以微调开源大语言模型。", "method": "使用多智能体框架，将咨询师响应生成分解为子任务，由专门的大语言模型代理处理，并整合自动和专家指标进行评估。", "result": "MAGneT在质量、多样性和治疗对齐方面显著优于现有方法，专家偏好率达77.2%，微调模型性能提升6.3%-7.3%。", "conclusion": "MAGneT提供了一种有效的合成数据生成方法，可促进心理咨询模型的开发，并公开代码和数据以支持进一步研究。"}}
{"id": "2509.03536", "title": "PG-Agent: An Agent Powered by Page Graph", "authors": ["Weizhi Chen", "Ziwei Wang", "Leyang Yang", "Sheng Zhou", "Xiaoxuan Tang", "Jiajun Bu", "Yong Li", "Wei Jiang"], "abstract": "Graphical User Interface (GUI) agents possess significant commercial and social value, and GUI agents powered by advanced multimodal large language models (MLLMs) have demonstrated remarkable potential. Currently, existing GUI agents usually utilize sequential episodes of multi-step operations across pages as the prior GUI knowledge, which fails to capture the complex transition relationship between pages, making it challenging for the agents to deeply perceive the GUI environment and generalize to new scenarios. Therefore, we design an automated pipeline to transform the sequential episodes into page graphs, which explicitly model the graph structure of the pages that are naturally connected by actions. To fully utilize the page graphs, we further introduce Retrieval-Augmented Generation (RAG) technology to effectively retrieve reliable perception guidelines of GUI from them, and a tailored multi-agent framework PG-Agent with task decomposition strategy is proposed to be injected with the guidelines so that it can generalize to unseen scenarios. Extensive experiments on various benchmarks demonstrate the effectiveness of PG-Agent, even with limited episodes for page graph construction.", "subjects": "Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)", "comments": "Paper accepted to ACM MM 2025", "pdf_url": "https://arxiv.org/pdf/2509.03536.pdf", "abstract_url": "https://arxiv.org/abs/2509.03536", "categories": ["Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "PG-Agent 是一种基于页面图的 GUI 代理，通过将序列事件转换为图结构并利用 RAG 技术，提高了在未见场景中的泛化能力。", "motivation": "现有 GUI 代理依赖序列操作，难以捕捉页面间的复杂转换关系，导致环境感知不足和泛化困难。", "method": "设计自动化管道将序列事件转换为页面图，结合 RAG 技术检索感知指南，并采用多代理框架和任务分解策略。", "result": "在多个基准测试中，即使使用有限事件构建页面图，PG-Agent 也显示出有效性。", "conclusion": "页面图和 RAG 技术能显著提升 GUI 代理的感知和泛化能力，适用于新场景。"}}
{"id": "2509.03787", "title": "Evaluating the Robustness of Retrieval-Augmented Generation to Adversarial Evidence in the Health Domain", "authors": ["Shakiba Amirshahi", "Amin Bigdeli", "Charles L. A. Clarke", "Amira Ghenai"], "abstract": "Retrieval augmented generation (RAG) systems provide a method for factually grounding the responses of a Large Language Model (LLM) by providing retrieved evidence, or context, as support. Guided by this context, RAG systems can reduce hallucinations and expand the ability of LLMs to accurately answer questions outside the scope of their training data. Unfortunately, this design introduces a critical vulnerability: LLMs may absorb and reproduce misinformation present in retrieved evidence. This problem is magnified if retrieved evidence contains adversarial material explicitly intended to promulgate misinformation. This paper presents a systematic evaluation of RAG robustness in the health domain and examines alignment between model outputs and ground-truth answers. We focus on the health domain due to the potential for harm caused by incorrect responses, as well as the availability of evidence-based ground truth for many common health-related questions. We conduct controlled experiments using common health questions, varying both the type and composition of the retrieved documents (helpful, harmful, and adversarial) as well as the framing of the question by the user (consistent, neutral, and inconsistent). Our findings reveal that adversarial documents substantially degrade alignment, but robustness can be preserved when helpful evidence is also present in the retrieval pool. These findings offer actionable insights for designing safer RAG systems in high-stakes domains by highlighting the need for retrieval safeguards. To enable reproducibility and facilitate future research, all experimental results are publicly available in our github repository.", "subjects": "Information Retrieval (cs.IR); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03787.pdf", "abstract_url": "https://arxiv.org/abs/2509.03787", "categories": ["Information Retrieval (cs.IR)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "评估检索增强生成在健康领域对对抗性证据的鲁棒性，发现对抗性文档降低对齐，但存在有益证据时可保持鲁棒性。", "motivation": "解决RAG系统中LLM可能吸收和传播检索证据中错误信息的问题，尤其在健康领域可能造成危害。", "method": "使用健康问题进行控制实验，变化检索文档类型（有益、有害、对抗性）和问题框架（一致、中性、不一致），评估模型输出与真实答案的对齐。", "result": "对抗性文档显著降低对齐，但当检索池中包含有益证据时，鲁棒性得以保持。", "conclusion": "强调在高风险领域设计更安全的RAG系统需要检索保护措施，并提供可复现的实验结果以促进未来研究。"}}
{"id": "2509.03550", "title": "Diffusion-RL Based Air Traffic Conflict Detection and Resolution Method", "authors": ["Tonghe Li", "Jixin Liu", "Weili Zeng", "Hao Jiang"], "abstract": "In the context of continuously rising global air traffic, efficient and safe Conflict Detection and Resolution (CD&R) is paramount for air traffic management. Although Deep Reinforcement Learning (DRL) offers a promising pathway for CD&R automation, existing approaches commonly suffer from a \"unimodal bias\" in their policies. This leads to a critical lack of decision-making flexibility when confronted with complex and dynamic constraints, often resulting in \"decision deadlocks.\" To overcome this limitation, this paper pioneers the integration of diffusion probabilistic models into the safety-critical task of CD&R, proposing a novel autonomous conflict resolution framework named Diffusion-AC. Diverging from conventional methods that converge to a single optimal solution, our framework models its policy as a reverse denoising process guided by a value function, enabling it to generate a rich, high-quality, and multimodal action distribution. This core architecture is complemented by a Density-Progressive Safety Curriculum (DPSC), a training mechanism that ensures stable and efficient learning as the agent progresses from sparse to high-density traffic environments. Extensive simulation experiments demonstrate that the proposed method significantly outperforms a suite of state-of-the-art DRL benchmarks. Most critically, in the most challenging high-density scenarios, Diffusion-AC not only maintains a high success rate of 94.1% but also reduces the incidence of Near Mid-Air Collisions (NMACs) by approximately 59% compared to the next-best-performing baseline, significantly enhancing the system's safety margin. This performance leap stems from its unique multimodal decision-making capability, which allows the agent to flexibly switch to effective alternative maneuvers.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "59 pages,13 figures, 3 tables", "pdf_url": "https://arxiv.org/pdf/2509.03550.pdf", "abstract_url": "https://arxiv.org/abs/2509.03550", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出一种基于扩散概率模型和深度强化学习的自主冲突检测与解决框架Diffusion-AC，通过多模态决策和密度渐进安全课程，在高密度空管场景中显著提升成功率和安全性。", "motivation": "解决现有深度强化学习方法在空管冲突检测与解决中因单模态策略导致的决策僵化和灵活性不足问题。", "method": "集成扩散概率模型，通过反向去噪过程和价值函数引导生成多模态动作分布，并结合密度渐进安全课程进行训练。", "result": "在模拟实验中，Diffusion-AC在高密度场景下达到94.1%的成功率，并将近空中碰撞发生率降低约59%，优于现有基准方法。", "conclusion": "该方法通过多模态决策能力增强了系统的灵活性和安全性，为空管自动化提供了有效解决方案。"}}
{"id": "2509.03626", "title": "Explainable Knowledge Graph Retrieval-Augmented Generation (KG-RAG) with KG-SMILE", "authors": ["Zahra Zehtabi Sabeti Moghaddam", "Zeinab Dehghani", "Maneeha Rani", "Koorosh Aslansefat", "Bhupesh Kumar Mishra", "Rameez Raja Kureshi", "Dhavalkumar Thakker"], "abstract": "Generative AI, such as Large Language Models (LLMs), has achieved impressive progress but still produces hallucinations and unverifiable claims, limiting reliability in sensitive domains. Retrieval-Augmented Generation (RAG) improves accuracy by grounding outputs in external knowledge, especially in domains like healthcare, where precision is vital. However, RAG remains opaque and essentially a black box, heavily dependent on data quality. We developed a method-agnostic, perturbation-based framework that provides token and component-level interoperability for Graph RAG using SMILE and named it as Knowledge-Graph (KG)-SMILE. By applying controlled perturbations, computing similarities, and training weighted linear surrogates, KG-SMILE identifies the graph entities and relations most influential to generated outputs, thereby making RAG more transparent. We evaluate KG-SMILE using comprehensive attribution metrics, including fidelity, faithfulness, consistency, stability, and accuracy. Our findings show that KG-SMILE produces stable, human-aligned explanations, demonstrating its capacity to balance model effectiveness with interpretability and thereby fostering greater transparency and trust in machine learning technologies.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03626.pdf", "abstract_url": "https://arxiv.org/abs/2509.03626", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种基于扰动的方法KG-SMILE，用于增强知识图谱检索增强生成的解释性，通过识别关键图实体和关系来提高透明度和信任。", "motivation": "解决大型语言模型在敏感领域（如医疗）中产生幻觉和不可验证声明的问题，以及RAG方法的不透明性。", "method": "开发了方法无关的扰动框架KG-SMILE，应用受控扰动、计算相似性并训练加权线性代理模型，以提供令牌和组件级可解释性。", "result": "评估显示KG-SMILE在保真度、忠实度、一致性、稳定性和准确性方面表现良好，产生稳定且与人类对齐的解释。", "conclusion": "KG-SMILE能平衡模型有效性和可解释性，促进机器学习技术的透明度和信任。"}}
{"id": "2509.03581", "title": "Learning When to Plan: Efficiently Allocating Test-Time Compute for LLM Agents", "authors": ["Davide Paglieri", "Bartłomiej Cupiał", "Jonathan Cook", "Ulyana Piterbarg", "Jens Tuyls", "Edward Grefenstette", "Jakob Nicolaus Foerster", "Jack Parker-Holder", "Tim Rocktäschel"], "abstract": "Training large language models (LLMs) to reason via reinforcement learning (RL) significantly improves their problem-solving capabilities. In agentic settings, existing methods like ReAct prompt LLMs to explicitly plan before every action; however, we demonstrate that always planning is computationally expensive and degrades performance on long-horizon tasks, while never planning further limits performance. To address this, we introduce a conceptual framework formalizing dynamic planning for LLM agents, enabling them to flexibly decide when to allocate test-time compute for planning. We propose a simple two-stage training pipeline: (1) supervised fine-tuning on diverse synthetic data to prime models for dynamic planning, and (2) RL to refine this capability in long-horizon environments. Experiments on the Crafter environment show that dynamic planning agents trained with this approach are more sample-efficient and consistently achieve more complex objectives. Additionally, we demonstrate that these agents can be effectively steered by human-written plans, surpassing their independent capabilities. To our knowledge, this work is the first to explore training LLM agents for dynamic test-time compute allocation in sequential decision-making tasks, paving the way for more efficient, adaptive, and controllable agentic systems.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03581.pdf", "abstract_url": "https://arxiv.org/abs/2509.03581", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种动态规划框架，让LLM代理在测试时灵活决定何时进行规划，通过两阶段训练（监督微调和强化学习）提高效率和性能，在Crafter环境中验证了其优越性。", "motivation": "解决现有方法如ReAct中总是规划导致计算成本高和性能下降的问题，以及从不规划限制性能的问题，旨在优化LLM代理在序列决策任务中的计算分配。", "method": "引入动态规划框架，采用两阶段训练管道：先监督微调在合成数据上，后强化学习在长视界环境中，以训练代理动态决定何时规划。", "result": "在Crafter环境实验中，动态规划代理更样本高效，能更一致地完成复杂目标，并可被人类编写的计划有效引导，超越独立能力。", "conclusion": "这是首个探索LLM代理动态测试时计算分配的工作，为更高效、自适应和可控的代理系统铺平了道路。"}}
{"id": "2509.03736", "title": "Are LLM Agents Behaviorally Coherent? Latent Profiles for Social Simulation", "authors": ["James Mooney", "Josef Woldense", "Zheng Robert Jia", "Shirley Anugrah Hayati", "My Ha Nguyen", "Vipul Raheja", "Dongyeop Kang"], "abstract": "The impressive capabilities of Large Language Models (LLMs) have fueled the notion that synthetic agents can serve as substitutes for real participants in human-subject research. In an effort to evaluate the merits of this claim, social science researchers have largely focused on whether LLM-generated survey data corresponds to that of a human counterpart whom the LLM is prompted to represent. In contrast, we address a more fundamental question: Do agents maintain internal consistency, retaining similar behaviors when examined under different experimental settings? To this end, we develop a study designed to (a) reveal the agent's internal state and (b) examine agent behavior in a basic dialogue setting. This design enables us to explore a set of behavioral hypotheses to assess whether an agent's conversation behavior is consistent with what we would expect from their revealed internal state. Our findings on these hypotheses show significant internal inconsistencies in LLMs across model families and at differing model sizes. Most importantly, we find that, although agents may generate responses matching those of their human counterparts, they fail to be internally consistent, representing a critical gap in their capabilities to accurately substitute for real participants in human-subject research. Our simulation code and data are publicly accessible.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "25 pages, 9 figures, 7 tables", "pdf_url": "https://arxiv.org/pdf/2509.03736.pdf", "abstract_url": "https://arxiv.org/abs/2509.03736", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文评估大型语言模型（LLM）代理在人类主题研究中作为真实参与者替代品的可行性，发现尽管LLM能生成类似人类的响应，但内部行为不一致，存在关键能力差距。", "motivation": "解决LLM代理是否能在不同实验设置中保持内部一致性的问题，以评估其作为人类参与者替代品的可靠性。", "method": "开发研究设计，揭示代理内部状态并检查其在基本对话设置中的行为，通过行为假设评估一致性。", "result": "发现LLM在模型家族和不同大小中存在显著内部不一致，无法保持行为一致性。", "conclusion": "LLM代理不能准确替代真实参与者，因为缺乏内部一致性，这对人类主题研究有重要影响。"}}
{"id": "2509.03768", "title": "RAGuard: A Novel Approach for in-context Safe Retrieval Augmented Generation for LLMs", "authors": ["Connor Walker", "Koorosh Aslansefat", "Mohammad Naveed Akram", "Yiannis Papadopoulos"], "abstract": "Accuracy and safety are paramount in Offshore Wind (OSW) maintenance, yet conventional Large Language Models (LLMs) often fail when confronted with highly specialised or unexpected scenarios. We introduce RAGuard, an enhanced Retrieval-Augmented Generation (RAG) framework that explicitly integrates safety-critical documents alongside technical", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (stat.ML)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03768.pdf", "abstract_url": "https://arxiv.org/abs/2509.03768", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (stat.ML)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "RAGuard是一种增强的检索增强生成框架，通过整合安全关键文档和技术信息，提高大型语言模型在海上风电维护中的准确性和安全性。", "motivation": "解决大型语言模型在高度专业化或意外场景中准确性和安全性不足的问题，特别是在海上风电维护领域。", "method": "使用检索增强生成（RAG）方法，明确集成安全关键文档和技术内容。", "result": "关键发现包括框架的潜在有效性，但具体结果未在摘要中提供。", "conclusion": "RAGuard框架旨在提升LLMs在关键应用中的可靠性，具有实际应用价值。"}}
{"id": "2509.03811", "title": "Leveraging LLM-Based Agents for Intelligent Supply Chain Planning", "authors": ["Yongzhi Qi", "Jiaheng Yin", "Jianshen Zhang", "Dongyang Geng", "Zhengyu Chen", "Hao Hu", "Wei Qi", "Zuo-Jun Max Shen"], "abstract": "In supply chain management, planning is a critical concept. The movement of physical products across different categories, from suppliers to warehouse management, to sales, and logistics transporting them to customers, entails the involvement of many entities. It covers various aspects such as demand forecasting, inventory management, sales operations, and replenishment. How to collect relevant data from an e-commerce platform's perspective, formulate long-term plans, and dynamically adjust them based on environmental changes, while ensuring interpretability, efficiency, and reliability, is a practical and challenging problem. In recent years, the development of AI technologies, especially the rapid progress of large language models, has provided new tools to address real-world issues. In this work, we construct a Supply Chain Planning Agent (SCPA) framework that can understand domain knowledge, comprehend the operator's needs, decompose tasks, leverage or create new tools, and return evidence-based planning reports. We deploy this framework in", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03811.pdf", "abstract_url": "https://arxiv.org/abs/2509.03811", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于大型语言模型的供应链规划代理框架，用于智能处理电子商务平台中的需求预测、库存管理等任务，提高可解释性和效率。", "motivation": "解决供应链管理中数据收集、长期计划制定和动态调整的挑战，确保可解释性、效率和可靠性。", "method": "构建供应链规划代理（SCPA）框架，利用大型语言模型理解领域知识、分解任务、使用或创建工具，并生成基于证据的规划报告。", "result": "框架能够部署并处理供应链规划问题，具体结果未在摘要中详细说明。", "conclusion": "该框架为供应链管理提供了新的AI驱动方法，有望提升实际应用的智能化和适应性。"}}
{"id": "2509.03817", "title": "Learning to Deliberate: Meta-policy Collaboration for Agentic LLMs with Multi-agent Reinforcement Learning", "authors": ["Wei Yang", "Jesse Thomason"], "abstract": "Multi-agent systems of large language models (LLMs) show promise for complex reasoning, but their effectiveness is often limited by fixed collaboration protocols. These frameworks typically focus on macro-level orchestration while overlooking agents' internal deliberative capabilities. This critical meta-cognitive blindspot treats agents as passive executors unable to adapt their strategy based on internal cognitive states like uncertainty or confidence. We introduce the Meta-Policy Deliberation Framework (MPDF), where agents learn a decentralized policy over a set of high-level meta-cognitive actions: Persist, Refine, and Concede. To overcome the instability of traditional policy gradients in this setting, we develop SoftRankPO, a novel reinforcement learning algorithm. SoftRankPO stabilizes training by shaping advantages based on the rank of rewards mapped through smooth normal quantiles, making the learning process robust to reward variance. Experiments show that MPDF with SoftRankPO achieves a a 4-5% absolute gain in average accuracy across five mathematical and general reasoning benchmarks compared to six state-of-the-art heuristic and learning-based multi-agent reasoning algorithms. Our work presents a paradigm for learning adaptive, meta-cognitive policies for multi-agent LLM systems, shifting the focus from designing fixed protocols to learning dynamic, deliberative strategies.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03817.pdf", "abstract_url": "https://arxiv.org/abs/2509.03817", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了元策略审议框架（MPDF）和SoftRankPO算法，通过多智能体强化学习提升LLM的元认知能力，在多个推理基准上实现4-5%的准确率提升。", "motivation": "解决多智能体LLM系统中固定协作协议导致的元认知盲点问题，智能体无法基于内部认知状态自适应调整策略。", "method": "使用MPDF框架，智能体学习去中心化策略，包括Persist、Refine和Concede等元认知动作，并开发SoftRankPO算法稳定训练过程。", "result": "在五个数学和通用推理基准上，MPDF与SoftRankPO相比六种先进方法，平均准确率绝对提升4-5%。", "conclusion": "工作展示了学习动态、审议策略的范式，从固定协议设计转向自适应元认知策略，提升多智能体LLM系统的推理能力。"}}
{"id": "2509.04027", "title": "CoT-Space: A Theoretical Framework for Internal Slow-Thinking via Reinforcement Learning", "authors": ["Zeyu Gan", "Hao Yi", "Yong Liu"], "abstract": "Reinforcement Learning (RL) has become a pivotal approach for enhancing the reasoning capabilities of Large Language Models (LLMs). However, a significant theoretical gap persists, as traditional token-level RL frameworks fail to align with the reasoning-level nature of complex, multi-step thought processes like Chain-of-Thought (CoT). To address this challenge, we introduce CoT-Space, a novel theoretical framework that recasts LLM reasoning from a discrete token-prediction task to an optimization process within a continuous, reasoning-level semantic space. By analyzing this process from both a noise perspective and a risk perspective, we demonstrate that the convergence to an optimal CoT length is a natural consequence of the fundamental trade-off between underfitting and overfitting. Furthermore, extensive experiments provide strong empirical validation for our theoretical findings. Our framework not only provides a coherent explanation for empirical phenomena such as overthinking but also offers a solid theoretical foundation to guide the future development of more effective and generalizable reasoning agents.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "Preprint Edition", "pdf_url": "https://arxiv.org/pdf/2509.04027.pdf", "abstract_url": "https://arxiv.org/abs/2509.04027", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "CoT-Space是一个理论框架，通过强化学习将LLM推理从离散标记预测重构为连续语义空间优化，解释并验证了最优CoT长度的收敛性。", "motivation": "解决传统RL框架在token级别无法处理多步推理如CoT的理论缺陷。", "method": "引入CoT-Space框架，从噪声和风险角度分析推理过程，优化语义空间。", "result": "实验验证了理论，显示最优CoT长度源于欠拟合和过拟合的权衡。", "conclusion": "框架为过度思考等现象提供解释，并为开发更有效推理代理奠定理论基础。"}}
{"id": "2509.03704", "title": "QuantV2X: A Fully Quantized Multi-Agent System for Cooperative Perception", "authors": ["Seth Z. Zhao", "Huizhi Zhang", "Zhaowei Li", "Juntong Peng", "Anthony Chui", "Zewei Zhou", "Zonglin Meng", "Hao Xiang", "Zhiyu Huang", "Fujia Wang", "Ran Tian", "Chenfeng Xu", "Bolei Zhou", "Jiaqi Ma"], "abstract": "Cooperative perception through Vehicle-to-Everything (V2X) communication offers significant potential for enhancing vehicle perception by mitigating occlusions and expanding the field of view. However, past research has predominantly focused on improving accuracy metrics without addressing the crucial system-level considerations of efficiency, latency, and real-world deployability. Noticeably, most existing systems rely on full-precision models, which incur high computational and transmission costs, making them impractical for real-time operation in resource-constrained environments. In this paper, we introduce \\textbf{QuantV2X}, the first fully quantized multi-agent system designed specifically for efficient and scalable deployment of multi-modal, multi-agent V2X cooperative perception. QuantV2X introduces a unified end-to-end quantization strategy across both neural network models and transmitted message representations that simultaneously reduces computational load and transmission bandwidth. Remarkably, despite operating under low-bit constraints, QuantV2X achieves accuracy comparable to full-precision systems. More importantly, when evaluated under deployment-oriented metrics, QuantV2X reduces system-level latency by 3.2$\\times$ and achieves a +9.5 improvement in mAP30 over full-precision baselines. Furthermore, QuantV2X scales more effectively, enabling larger and more capable models to fit within strict memory budgets. These results highlight the viability of a fully quantized multi-agent intermediate fusion system for real-world deployment. The system will be publicly released to promote research in this field:", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03704.pdf", "abstract_url": "https://arxiv.org/abs/2509.03704", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "QuantV2X是首个全量化多智能体系统，用于高效可扩展的多模态V2X协同感知部署，通过统一量化策略减少计算和传输成本，在低比特约束下保持精度，并显著降低延迟和提升性能。", "motivation": "解决V2X协同感知中现有系统因使用全精度模型导致的高计算和传输成本问题，提升效率、延迟和实际部署可行性。", "method": "采用端到端统一量化策略，对神经网络模型和传输消息表示进行量化，以减少计算负载和传输带宽。", "result": "在低比特约束下实现与全精度系统相当的精度，系统级延迟降低3.2倍，mAP30提升9.5，并更有效地扩展以适应严格内存预算。", "conclusion": "全量化多智能体中间融合系统在实际部署中可行，将公开发布以促进该领域研究。"}}
{"id": "2509.04343", "title": "Psychologically Enhanced AI Agents", "authors": ["Maciej Besta", "Shriram Chandran", "Robert Gerstenberger", "Mathis Lindner", "Marcin Chrapek", "Sebastian Hermann Martschat", "Taraneh Ghandi", "Patrick Iff", "Hubert Niewiadomski", "Piotr Nyczyk", "Jürgen Müller", "Torsten Hoefler"], "abstract": "We introduce MBTI-in-Thoughts, a framework for enhancing the effectiveness of Large Language Model (LLM) agents through psychologically grounded personality conditioning. Drawing on the Myers-Briggs Type Indicator (MBTI), our method primes agents with distinct personality archetypes via prompt engineering, enabling control over behavior along two foundational axes of human psychology, cognition and affect. We show that such personality priming yields consistent, interpretable behavioral biases across diverse tasks: emotionally expressive agents excel in narrative generation, while analytically primed agents adopt more stable strategies in game-theoretic settings. Our framework supports experimenting with structured multi-agent communication protocols and reveals that self-reflection prior to interaction improves cooperation and reasoning quality. To ensure trait persistence, we integrate the official 16Personalities test for automated verification. While our focus is on MBTI, we show that our approach generalizes seamlessly to other psychological frameworks such as Big Five, HEXACO, or Enneagram. By bridging psychological theory and LLM behavior design, we establish a foundation for psychologically enhanced AI agents without any fine-tuning.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computers and Society (cs.CY); Human-Computer Interaction (cs.HC); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.04343.pdf", "abstract_url": "https://arxiv.org/abs/2509.04343", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Computers and Society (cs.CY)", "Human-Computer Interaction (cs.HC)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "MBTI-in-Thoughts框架通过基于MBTI的人格条件化，增强LLM代理的有效性，无需微调即可控制行为，适用于多种心理框架。", "motivation": "解决如何通过心理学理论增强AI代理行为的一致性和可解释性，以提升在多样化任务中的表现。", "method": "使用提示工程将MBTI人格原型融入LLM代理，控制认知和情感轴，并通过16Personalities测试自动验证特质持久性。", "result": "人格条件化导致一致的行为偏差：情感表达型在叙述生成中表现优异，分析型在博弈论设置中采用更稳定策略，自我反思提高合作和推理质量。", "conclusion": "该框架为心理学增强的AI代理奠定了基础，可泛化到其他心理框架，促进AI行为设计的理论应用。"}}
{"id": "2509.03827", "title": "What Would an LLM Do? Evaluating Policymaking Capabilities of Large Language Models", "authors": ["Pierre Le Coz", "Jia An Liu", "Debarun Bhattacharjya", "Georgina Curto", "Serge Stinckwich"], "abstract": "Large language models (LLMs) are increasingly being adopted in high-stakes domains. Their capacity to process vast amounts of unstructured data, explore flexible scenarios, and handle a diversity of contextual factors can make them uniquely suited to provide new insights for the complexity of social policymaking. This article evaluates whether LLMs' are aligned with domain experts (and among themselves) to inform social policymaking on the subject of homelessness alleviation - a challenge affecting over 150 million people worldwide. We develop a novel benchmark comprised of decision scenarios with policy choices across four geographies (South Bend, USA; Barcelona, Spain; Johannesburg, South Africa; Macau SAR, China). The policies in scope are grounded in the conceptual framework of the Capability Approach for human development. We also present an automated pipeline that connects the benchmarked policies to an agent-based model, and we explore the social impact of the recommended policies through simulated social scenarios. The paper results reveal promising potential to leverage LLMs for social policy making. If responsible guardrails and contextual calibrations are introduced in collaboration with local domain experts, LLMs can provide humans with valuable insights, in the form of alternative policies at scale.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03827.pdf", "abstract_url": "https://arxiv.org/abs/2509.03827", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文评估大型语言模型（LLMs）在无家可归缓解政策制定中的能力，通过多地理基准测试和模拟，显示LLMs在负责任使用下可提供有价值的政策见解。", "motivation": "解决LLMs在高风险领域（如社会政策制定）中的对齐问题，评估其与专家一致性和对复杂社会挑战（如全球1.5亿人无家可归）的适用性。", "method": "开发基于能力概念框架的新基准，包括四个地理区域的决策场景，并使用自动化管道连接代理模型进行社会影响模拟。", "result": "LLMs显示出在政策制定中的潜力，通过负责任护栏和本地专家协作，能大规模提供替代政策见解。", "conclusion": "LLMs可作为社会政策制定的辅助工具，但需结合专家指导和上下文校准以确保负责任应用。"}}
{"id": "2509.03828", "title": "An Agentic Model Context Protocol Framework for Medical Concept Standardization", "authors": ["Jaerong Ahn", "Andrew Wen", "Nan Wang", "Heling Jia", "Zhiyi Yue", "Sunyang Fu", "Hongfang Liu"], "abstract": "The Observational Medical Outcomes Partnership (OMOP) common data model (CDM) provides a standardized representation of heterogeneous health data to support large-scale, multi-institutional research. One critical step in data standardization using OMOP CDM is the mapping of source medical terms to OMOP standard concepts, a procedure that is resource-intensive and error-prone. While large language models (LLMs) have the potential to facilitate this process, their tendency toward hallucination makes them unsuitable for clinical deployment without training and expert validation. Here, we developed a zero-training, hallucination-preventive mapping system based on the Model Context Protocol (MCP), a standardized and secure framework allowing LLMs to interact with external resources and tools. The system enables explainable mapping and significantly improves efficiency and accuracy with minimal effort. It provides real-time vocabulary lookups and structured reasoning outputs suitable for immediate use in both exploratory and production environments.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03828.pdf", "abstract_url": "https://arxiv.org/abs/2509.03828", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文开发了一种基于模型上下文协议（MCP）的零训练、防幻觉映射系统，用于医学概念标准化，提高OMOP CDM数据映射的效率和准确性。", "motivation": "解决OMOP CDM中源医学术语映射到标准概念的资源密集和易出错问题，以及大型语言模型（LLMs）在临床部署中因幻觉而不适用的问题。", "method": "使用模型上下文协议（MCP）框架，允许LLMs与外部资源和工具交互，实现零训练、防幻觉的映射系统，包括实时词汇查找和结构化推理输出。", "result": "系统显著提高了映射效率和准确性，提供可解释的映射，适用于探索和生产环境，无需专家验证。", "conclusion": "该系统为医学数据标准化提供了一种高效、安全的解决方案，支持大规模多机构研究，具有直接应用价值。"}}
{"id": "2509.03890", "title": "FaMA: LLM-Empowered Agentic Assistant for Consumer-to-Consumer Marketplace", "authors": ["Yineng Yan", "Xidong Wang", "Jin Seng Cheng", "Ran Hu", "Wentao Guan", "Nahid Farahmand", "Hengte Lin", "Yue Li"], "abstract": "The emergence of agentic AI, powered by Large Language Models (LLMs), marks a paradigm shift from reactive generative systems to proactive, goal-oriented autonomous agents capable of sophisticated planning, memory, and tool use. This evolution presents a novel opportunity to address long-standing challenges in complex digital environments. Core tasks on Consumer-to-Consumer (C2C) e-commerce platforms often require users to navigate complex Graphical User Interfaces (GUIs), making the experience time-consuming for both buyers and sellers. This paper introduces a novel approach to simplify these interactions through an LLM-powered agentic assistant. This agent functions as a new, conversational entry point to the marketplace, shifting the primary interaction model from a complex GUI to an intuitive AI agent. By interpreting natural language commands, the agent automates key high-friction workflows. For sellers, this includes simplified updating and renewal of listings, and the ability to send bulk messages. For buyers, the agent facilitates a more efficient product discovery process through conversational search. We present the architecture for Facebook Marketplace Assistant (FaMA), arguing that this agentic, conversational paradigm provides a lightweight and more accessible alternative to traditional app interfaces, allowing users to manage their marketplace activities with greater efficiency. Experiments show FaMA achieves a 98% task success rate on solving complex tasks on the marketplace and enables up to a 2x speedup on interaction time.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03890.pdf", "abstract_url": "https://arxiv.org/abs/2509.03890", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "论文介绍FaMA，一个基于LLM的智能助手，用于简化C2C电子商务平台的用户交互，通过自然语言命令自动化任务，提高效率和可访问性。", "motivation": "解决C2C平台中复杂GUI导致的用户交互耗时问题，利用AI代理技术简化买卖双方的流程。", "method": "使用LLM驱动的代理助手，通过自然语言处理实现任务自动化，包括列表更新、批量消息发送和对话式搜索。", "result": "FaMA在复杂任务上达到98%的成功率，交互时间缩短高达2倍。", "conclusion": "代理对话范式提供轻量级、高效的替代方案，提升市场活动管理效率。"}}
{"id": "2509.03906", "title": "A Foundation Model for Chest X-ray Interpretation with Grounded Reasoning via Online Reinforcement Learning", "authors": ["Qika Lin", "Yifan Zhu", "Bin Pu", "Ling Huang", "Haoran Luo", "Jingying Ma", "Zhen Peng", "Tianzhe Zhao", "Fangzhi Xu", "Jian Zhang", "Kai He", "Zhonghong Ou", "Swapnil Mishra", "Mengling Feng"], "abstract": "Medical foundation models (FMs) have shown tremendous promise amid the rapid advancements in artificial intelligence (AI) technologies. However, current medical FMs typically generate answers in a black-box manner, lacking transparent reasoning processes and locally grounded interpretability, which hinders their practical clinical deployments. To this end, we introduce DeepMedix-R1, a holistic medical FM for chest X-ray (CXR) interpretation. It leverages a sequential training pipeline: initially fine-tuned on curated CXR instruction data to equip with fundamental CXR interpretation capabilities, then exposed to high-quality synthetic reasoning samples to enable cold-start reasoning, and finally refined via online reinforcement learning to enhance both grounded reasoning quality and generation performance. Thus, the model produces both an answer and reasoning steps tied to the image's local regions for each query. Quantitative evaluation demonstrates substantial improvements in report generation (e.g., 14.54% and 31.32% over LLaVA-Rad and MedGemma) and visual question answering (e.g., 57.75% and 23.06% over MedGemma and CheXagent) tasks. To facilitate robust assessment, we propose Report Arena, a benchmarking framework using advanced language models to evaluate answer quality, further highlighting the superiority of DeepMedix-R1. Expert review of generated reasoning steps reveals greater interpretability and clinical plausibility compared to the established Qwen2.5-VL-7B model (0.7416 vs. 0.2584 overall preference). Collectively, our work advances medical FM development toward holistic, transparent, and clinically actionable modeling for CXR interpretation.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "15 pages", "pdf_url": "https://arxiv.org/pdf/2509.03906.pdf", "abstract_url": "https://arxiv.org/abs/2509.03906", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了DeepMedix-R1，一种用于胸部X光解释的医学基础模型，通过在线强化学习实现基于图像区域的透明推理，在报告生成和视觉问答任务中表现优异，提高了可解释性和临床实用性。", "motivation": "解决当前医学基础模型在临床部署中因黑盒推理和缺乏局部可解释性而受限的问题。", "method": "采用顺序训练管道：先在CXR指令数据上微调，再通过合成推理样本启动推理，最后通过在线强化学习优化推理质量和生成性能。", "result": "在报告生成任务中提升14.54%和31.32%，在视觉问答任务中提升57.75%和23.06%，专家评审显示可解释性优于Qwen2.5-VL-7B模型（0.7416 vs. 0.2584偏好）。", "conclusion": "该工作推动了医学基础模型向整体、透明和临床可操作的CXR解释发展，并提出了Report Arena基准框架用于评估。"}}
{"id": "2509.03956", "title": "World Model Implanting for Test-time Adaptation of Embodied Agents", "authors": ["Minjong Yoo", "Jinwoo Jang", "Sihyung Yoon", "Honguk Woo"], "abstract": "In embodied AI, a persistent challenge is enabling agents to robustly adapt to novel domains without requiring extensive data collection or retraining. To address this, we present a world model implanting framework (WorMI) that combines the reasoning capabilities of large language models (LLMs) with independently learned, domain-specific world models through test-time composition. By allowing seamless implantation and removal of the world models, the embodied agent's policy achieves and maintains cross-domain adaptability. In the WorMI framework, we employ a prototype-based world model retrieval approach, utilizing efficient trajectory-based abstract representation matching, to incorporate relevant models into test-time composition. We also develop a world-wise compound attention method that not only integrates the knowledge from the retrieved world models but also aligns their intermediate representations with the reasoning model's representation within the agent's policy. This framework design effectively fuses domain-specific knowledge from multiple world models, ensuring robust adaptation to unseen domains. We evaluate our WorMI on the VirtualHome and ALFWorld benchmarks, demonstrating superior zero-shot and few-shot performance compared to several LLM-based approaches across a range of unseen domains. These results highlight the frameworks potential for scalable, real-world deployment in embodied agent scenarios where adaptability and data efficiency are essential.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03956.pdf", "abstract_url": "https://arxiv.org/abs/2509.03956", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出WorMI框架，结合大型语言模型与领域特定世界模型，通过测试时组合实现具身代理的零样本和少样本跨域自适应，在VirtualHome和ALFWorld基准上表现优异。", "motivation": "解决具身AI中代理在无需大量数据或重训练的情况下，鲁棒适应新领域的问题。", "method": "使用原型世界模型检索和轨迹抽象表示匹配，结合世界级复合注意力方法，集成多个世界模型知识并对其齐中间表示。", "result": "在VirtualHome和ALFWorld基准上，零样本和少样本性能优于其他基于LLM的方法。", "conclusion": "WorMI框架具有可扩展性和数据效率，适用于现实世界具身代理部署，强调适应性和知识融合的重要性。"}}
{"id": "2509.03990", "title": "Meta-Policy Reflexion: Reusable Reflective Memory and Rule Admissibility for Resource-Efficient LLM Agent", "authors": ["Chunlong Wu", "Zhibo Qu"], "abstract": "Large language model (LLM) agents achieve impressive single-task performance but commonly exhibit repeated failures, inefficient exploration, and limited cross-task adaptability. Existing reflective strategies (e.g., Reflexion, ReAct) improve per-episode behavior but typically produce ephemeral, task-specific traces that are not reused across tasks. Reinforcement-learning based alternatives can produce transferable policies but require substantial parameter updates and compute. In this work we introduce Meta-Policy Reflexion (MPR): a hybrid framework that consolidates LLM-generated reflections into a structured, predicate-like Meta-Policy Memory (MPM) and applies that memory at inference time through two complementary mechanisms soft memory-guided decoding and hard rule admissibility checks(HAC). MPR (i) externalizes reusable corrective knowledge without model weight updates, (ii) enforces domain constraints to reduce unsafe or invalid actions, and (iii) retains the adaptability of language-based reflection. We formalize the MPM representation, present algorithms for update and decoding, and validate the approach in a text-based agent environment following the experimental protocol described in the provided implementation (AlfWorld-based). Empirical results reported in the supplied material indicate consistent gains in execution accuracy and robustness when compared to Reflexion baselines; rule admissibility further improves stability. We analyze mechanisms that explain these gains, discuss scalability and failure modes, and outline future directions for multimodal and multi?agent extensions.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03990.pdf", "abstract_url": "https://arxiv.org/abs/2509.03990", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了Meta-Policy Reflexion（MPR）框架，通过结构化元策略内存和规则可接受性检查，提高LLM代理的效率和跨任务适应性，无需模型权重更新。", "motivation": "解决LLM代理在单任务中重复失败、探索效率低和跨任务适应性有限的问题，现有方法如Reflexion和ReAct产生临时性、任务特定的痕迹，而强化学习方法计算成本高。", "method": "使用混合框架MPR，整合LLM生成的反思到结构化元策略内存（MPM），并通过软内存引导解码和硬规则可接受性检查（HAC）在推理时应用。", "result": "在基于AlfWorld的文本代理环境中，实验结果显示执行准确性和鲁棒性相比Reflexion基线有持续提升，规则可接受性进一步提高了稳定性。", "conclusion": "MPR外部化可重用知识，增强领域约束，保持基于语言的反思适应性，未来可扩展到多模态和多代理场景。"}}
{"id": "2509.04100", "title": "Hybrid Reinforcement Learning and Search for Flight Trajectory Planning", "authors": ["Alberto Luise", "Michele Lombardi", "Florent Teichteil Koenigsbuch"], "abstract": "This paper explores the combination of Reinforcement Learning (RL) and search-based path planners to speed up the optimization of flight paths for airliners, where in case of emergency a fast route re-calculation can be crucial. The fundamental idea is to train an RL Agent to pre-compute near-optimal paths based on location and atmospheric data and use those at runtime to constrain the underlying path planning solver and find a solution within a certain distance from the initial guess. The approach effectively reduces the size of the solver's search space, significantly speeding up route optimization. Although global optimality is not guaranteed, empirical results conducted with Airbus aircraft's performance models show that fuel consumption remains nearly identical to that of an unconstrained solver, with deviations typically within 1%. At the same time, computation speed can be improved by up to 50% as compared to using a conventional solver alone.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.04100.pdf", "abstract_url": "https://arxiv.org/abs/2509.04100", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了结合强化学习和搜索的路径规划方法，以加速航空公司紧急情况下的飞行路径优化，通过预计算近最优路径来约束求解器，提高计算速度50%，同时燃料消耗偏差在1%以内。", "motivation": "解决在紧急情况下快速重新计算飞行路径的问题，以提升航空安全性和效率。", "method": "使用强化学习代理预计算路径，并基于此约束路径规划求解器，缩小搜索空间。", "result": "实证结果显示，燃料消耗与无约束求解器几乎相同（偏差约1%），计算速度提升高达50%。", "conclusion": "该方法在保持路径质量的同时显著加速优化过程，适用于实时应用，但可能不保证全局最优。"}}
{"id": "2509.04125", "title": "Analysis of Bluffing by DQN and CFR in Leduc Hold'em Poker", "authors": ["Tarik Zaciragic", "Aske Plaat", "K. Joost Batenburg"], "abstract": "In the game of poker, being unpredictable, or bluffing, is an essential skill. When humans play poker, they bluff. However, most works on computer-poker focus on performance metrics such as win rates, while bluffing is overlooked. In this paper we study whether two popular algorithms, DQN (based on reinforcement learning) and CFR (based on game theory), exhibit bluffing behavior in Leduc Hold'em, a simplified version of poker. We designed an experiment where we let the DQN and CFR agent play against each other while we log their actions. We find that both DQN and CFR exhibit bluffing behavior, but they do so in different ways. Although both attempt to perform bluffs at different rates, the percentage of successful bluffs (where the opponent folds) is roughly the same. This suggests that bluffing is an essential aspect of the game, not of the algorithm. Future work should look at different bluffing styles and at the full game of poker. Code at", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.04125.pdf", "abstract_url": "https://arxiv.org/abs/2509.04125", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "分析DQN和CFR在Leduc Hold'em扑克中的诈唬行为，发现两者均表现出诈唬但方式不同，成功率相似，表明诈唬是游戏而非算法的本质。", "motivation": "解决扑克中诈唬行为在计算机算法研究中被忽视的问题，探讨DQN和CFR是否展现诈唬。", "method": "设计实验让DQN和CFR代理互相对战，记录并分析其行动以评估诈唬行为。", "result": "DQN和CFR都表现出诈唬，但方式不同；诈唬成功率大致相同。", "conclusion": "诈唬是扑克游戏的关键方面，未来应研究不同诈唬风格和完整扑克游戏。"}}
{"id": "2509.04310", "title": "EvoEmo: Towards Evolved Emotional Policies for LLM Agents in Multi-Turn Negotiation", "authors": ["Yunbo Long", "Liming Xu", "Lukas Beckenbauer", "Yuhan Liu", "Alexandra Brintrup"], "abstract": "Recent research on Chain-of-Thought (CoT) reasoning in Large Language Models (LLMs) has demonstrated that agents can engage in \\textit{complex}, \\textit{multi-turn} negotiations, opening new avenues for agentic AI. However, existing LLM agents largely overlook the functional role of emotions in such negotiations, instead generating passive, preference-driven emotional responses that make them vulnerable to manipulation and strategic exploitation by adversarial counterparts. To address this gap, we present EvoEmo, an evolutionary reinforcement learning framework that optimizes dynamic emotional expression in negotiations. EvoEmo models emotional state transitions as a Markov Decision Process and employs population-based genetic optimization to evolve high-reward emotion policies across diverse negotiation scenarios. We further propose an evaluation framework with two baselines -- vanilla strategies and fixed-emotion strategies -- for benchmarking emotion-aware negotiation. Extensive experiments and ablation studies show that EvoEmo consistently outperforms both baselines, achieving higher success rates, higher efficiency, and increased buyer savings. This findings highlight the importance of adaptive emotional expression in enabling more effective LLM agents for multi-turn negotiation.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.04310.pdf", "abstract_url": "https://arxiv.org/abs/2509.04310", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "EvoEmo 是一个进化强化学习框架，通过优化动态情感表达来提升 LLM 代理在多方谈判中的性能，超越基线方法。", "motivation": "现有 LLM 代理在多方谈判中忽视情感功能，产生被动情感响应，易受对手操纵和利用，需要解决这一问题。", "method": "使用马尔可夫决策过程建模情感状态转移，并采用基于种群的遗传优化来进化高奖励情感策略。", "result": "EvoEmo 在实验中 consistently 超越香草策略和固定情感策略基线，实现更高的成功率、效率和买家节省。", "conclusion": "自适应情感表达对提升 LLM 代理在多方谈判中的有效性至关重要，EvoEmo 框架展示了其潜力。"}}
{"id": "2509.04317", "title": "Improving Robustness of AlphaZero Algorithms to Test-Time Environment Changes", "authors": ["Isidoro Tamassia", "Wendelin Böhmer"], "abstract": "The AlphaZero framework provides a standard way of combining Monte Carlo planning with prior knowledge provided by a previously trained policy-value neural network. AlphaZero usually assumes that the environment on which the neural network was trained will not change at test time, which constrains its applicability. In this paper, we analyze the problem of deploying AlphaZero agents in potentially changed test environments and demonstrate how the combination of simple modifications to the standard framework can significantly boost performance, even in settings with a low planning budget available. The code is publicly available on GitHub.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.04317.pdf", "abstract_url": "https://arxiv.org/abs/2509.04317", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "分析AlphaZero框架在测试环境变化时的鲁棒性问题，提出简单修改以提升性能，代码已开源。", "motivation": "解决AlphaZero算法在测试时环境变化下的适用性受限问题。", "method": "结合蒙特卡洛规划和策略-价值神经网络，对标准框架进行简单修改。", "result": "显著提升性能，即使在低规划预算设置下也有效。", "conclusion": "改进方法增强了AlphaZero在变化环境中的部署能力，具有实际应用价值。"}}
{"id": "2509.03741", "title": "Designing Gaze Analytics for ELA Instruction: A User-Centered Dashboard with Conversational AI Support", "authors": ["Eduardo Davalos", "Yike Zhang", "Shruti Jain", "Namrata Srivastava", "Trieu Truong", "Nafees-ul Haque", "Tristan Van", "Jorge Salas", "Sara McFadden", "Sun-Joo Cho", "Gautam Biswas", "Amanda Goodwin"], "abstract": "Eye-tracking offers rich insights into student cognition and engagement, but remains underutilized in classroom-facing educational technology due to challenges in data interpretation and accessibility. In this paper, we present the iterative design and evaluation of a gaze-based learning analytics dashboard for English Language Arts (ELA), developed through five studies involving teachers and students. Guided by user-centered design and data storytelling principles, we explored how gaze data can support reflection, formative assessment, and instructional decision-making. Our findings demonstrate that gaze analytics can be approachable and pedagogically valuable when supported by familiar visualizations, layered explanations, and narrative scaffolds. We further show how a conversational agent, powered by a large language model (LLM), can lower cognitive barriers to interpreting gaze data by enabling natural language interactions with multimodal learning analytics. We conclude with design implications for future EdTech systems that aim to integrate novel data modalities in classroom contexts.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": "22 pages, 9 figures, 3 tables, submitted to IUI2026", "pdf_url": "https://arxiv.org/pdf/2509.03741.pdf", "abstract_url": "https://arxiv.org/abs/2509.03741", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过用户中心设计和数据叙事原则，迭代开发并评估了用于英语语言艺术教学的基于凝视的分析仪表板，结合对话AI降低数据解释障碍，提升教学价值。", "motivation": "解决眼动追踪数据在课堂教育技术中因解释困难和可访问性低而未被充分利用的问题。", "method": "采用用户中心设计和数据叙事原则，通过五项涉及教师和学生的研究进行迭代设计和评估，并集成大型语言模型驱动的对话代理。", "result": "发现凝视分析在熟悉可视化、分层解释和叙事支架支持下易于接受且具有教学价值，对话代理通过自然语言交互降低认知障碍。", "conclusion": "为未来教育技术系统整合新数据模态提供设计启示，强调可访问性和教学支持的重要性。"}}
{"id": "2509.03771", "title": "Learning an Adversarial World Model for Automated Curriculum Generation in MARL", "authors": ["Brennen Hill"], "abstract": "World models that infer and predict environmental dynamics are foundational to embodied intelligence. However, their potential is often limited by the finite complexity and implicit biases of hand-crafted training environments. To develop truly generalizable and robust agents, we need environments that scale in complexity alongside the agents learning within them. In this work, we reframe the challenge of environment generation as the problem of learning a goal-conditioned, generative world model. We propose a system where a generative **Attacker** agent learns an implicit world model to synthesize increasingly difficult challenges for a team of cooperative **Defender** agents. The Attacker's objective is not passive prediction, but active, goal-driven interaction: it models and generates world states (i.e., configurations of enemy units) specifically to exploit the Defenders' weaknesses. Concurrently, the embodied Defender team learns a cooperative policy to overcome these generated worlds. This co-evolutionary dynamic creates a self-scaling curriculum where the world model continuously adapts to challenge the decision-making policy of the agents, providing an effectively infinite stream of novel and relevant training scenarios. We demonstrate that this framework leads to the emergence of complex behaviors, such as the world model learning to generate flanking and shielding formations, and the defenders learning coordinated focus-fire and spreading tactics. Our findings position adversarial co-evolution as a powerful method for learning instrumental world models that drive agents toward greater strategic depth and robustness.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03771.pdf", "abstract_url": "https://arxiv.org/abs/2509.03771", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种通过对抗性共同进化学习目标条件生成世界模型的方法，用于多智能体强化学习中自动生成课程，以提升智能体的泛化性和鲁棒性。", "motivation": "解决手工设计训练环境有限复杂性和隐含偏见的问题，需要可扩展复杂性的环境来发展通用和鲁棒的智能体。", "method": "使用生成性攻击者智能体学习隐式世界模型，合成日益困难的挑战，与防御者智能体共同进化，创建自扩展课程。", "result": "框架促成了复杂行为的涌现，如世界模型生成侧翼和盾牌阵型，防御者学习协调集火和分散战术。", "conclusion": "对抗性共同进化是学习工具性世界模型的有效方法，可推动智能体实现更深战略和鲁棒性。"}}
{"id": "2509.03793", "title": "SAMVAD: A Multi-Agent System for Simulating Judicial Deliberation Dynamics in India", "authors": ["Prathamesh Devadiga", "Omkaar Jayadev Shetty", "Pooja Agarwal"], "abstract": "Understanding the complexities of judicial deliberation is crucial for assessing the efficacy and fairness of a justice system. However, empirical studies of judicial panels are constrained by significant ethical and practical barriers. This paper introduces SAMVAD, an innovative Multi-Agent System (MAS) designed to simulate the deliberation process within the framework of the Indian justice system.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03793.pdf", "abstract_url": "https://arxiv.org/abs/2509.03793", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "SAMVAD是一个多代理系统，用于模拟印度司法系统中的审议过程，以克服实证研究的伦理和实践障碍。", "motivation": "解决司法审议复杂性评估中的伦理和实践限制问题。", "method": "使用多代理系统（MAS）来模拟印度司法系统中的审议动态。", "result": "引入了SAMVAD系统，能够模拟审议过程，但具体结果未在摘要中详述。", "conclusion": "SAMVAD有助于更好地理解司法审议，提升司法系统的效能和公平性评估。"}}
{"id": "2509.03780", "title": "Natural Latents: Latent Variables Stable Across Ontologies", "authors": ["John Wentworth", "David Lorell"], "abstract": "Suppose two Bayesian agents each learn a generative model of the same environment. We will assume the two have converged on the predictive distribution, i.e. distribution over some observables in the environment, but may have different generative models containing different latent variables. Under what conditions can one agent guarantee that their latents are a function of the other agents latents?", "subjects": "Probability (math.PR); Artificial Intelligence (cs.AI); Information Theory (cs.IT); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03780.pdf", "abstract_url": "https://arxiv.org/abs/2509.03780", "categories": ["Probability (math.PR)", "Artificial Intelligence (cs.AI)", "Information Theory (cs.IT)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了在贝叶斯代理学习相同环境生成模型时，潜在变量在不同本体论下保持稳定的条件，以确保一个代理的潜在变量是另一个代理潜在变量的函数。", "motivation": "解决当两个贝叶斯代理学习相同环境的生成模型并收敛到相同的预测分布时，但可能使用不同潜在变量，如何保证一个代理的潜在变量是另一个代理潜在变量的函数的问题。", "method": "假设两个代理收敛到相同的预测分布，分析潜在变量在不同本体论下的稳定性条件，以推导出函数依赖关系。", "result": "确定了在特定条件下，一个代理的潜在变量可以保证是另一个代理潜在变量的函数，从而确保潜在变量的跨本体论稳定性。", "conclusion": "结论是存在条件使得潜在变量在不同生成模型中保持稳定，这对多代理系统中的模型一致性和可解释性有重要意义。"}}
{"id": "2509.03834", "title": "From Leiden to Pleasure Island: The Constant Potts Model for Community Detection as a Hedonic Game", "authors": ["Lucas Lopes Felipe", "Konstantin Avrachenkov", "Daniel Sadoc Menasche"], "abstract": "Community detection is one of the fundamental problems in data science which consists of partitioning nodes into disjoint communities. We present a game-theoretic perspective on the Constant Potts Model (CPM) for partitioning networks into disjoint communities, emphasizing its efficiency, robustness, and accuracy. Efficiency: We reinterpret CPM as a potential hedonic game by decomposing its global Hamiltonian into local utility functions, where the local utility gain of each agent matches the corresponding increase in global utility. Leveraging this equivalence, we prove that local optimization of the CPM objective via better-response dynamics converges in pseudo-polynomial time to an equilibrium partition. Robustness: We introduce and relate two stability criteria: a strict criterion based on a novel notion of robustness, requiring nodes to simultaneously maximize neighbors and minimize non-neighbors within communities, and a relaxed utility function based on a weighted sum of these objectives, controlled by a resolution parameter. Accuracy: In community tracking scenarios, where initial partitions are used to bootstrap the Leiden algorithm with partial ground-truth information, our experiments reveal that robust partitions yield higher accuracy in recovering ground-truth communities.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT)", "comments": "Manuscript submitted to Physica A: Statistical Mechanics and its Applications", "pdf_url": "https://arxiv.org/pdf/2509.03834.pdf", "abstract_url": "https://arxiv.org/abs/2509.03834", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computer Science and Game Theory (cs.GT)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文从博弈论角度重新解释恒定Potts模型（CPM），将其视为享乐博弈，证明局部优化在伪多项式时间内收敛，并引入稳定性标准，实验显示在社区追踪中提高准确性。", "motivation": "解决社区检测问题，特别是提高CPM的效率、鲁棒性和准确性，以更好地分区网络节点。", "method": "将CPM分解为局部效用函数，使用更好响应动态进行局部优化，并引入基于邻居和非邻居的稳定性标准。", "result": "局部优化快速收敛到均衡分区，鲁棒分区在社区追踪实验中提高地面真值恢复的准确性。", "conclusion": "CPM的博弈论视角提供高效、鲁棒和准确的社区检测方法，适用于实际应用。"}}
{"id": "2509.04139", "title": "Enhancing Technical Documents Retrieval for RAG", "authors": ["Songjiang Lai", "Tsun-Hin Cheung", "Ka-Chun Fung", "Kaiwen Xue", "Kwan-Ho Lin", "Yan-Ming Choi", "Vincent Ng", "Kin-Man Lam"], "abstract": "In this paper, we introduce Technical-Embeddings, a novel framework designed to optimize semantic retrieval in technical documentation, with applications in both hardware and software development. Our approach addresses the challenges of understanding and retrieving complex technical content by leveraging the capabilities of Large Language Models (LLMs). First, we enhance user queries by generating expanded representations that better capture user intent and improve dataset diversity, thereby enriching the fine-tuning process for embedding models. Second, we apply summary extraction techniques to encode essential contextual information, refining the representation of technical documents. To further enhance retrieval performance, we fine-tune a bi-encoder BERT model using soft prompting, incorporating separate learning parameters for queries and document context to capture fine-grained semantic nuances. We evaluate our approach on two public datasets, RAG-EDA and Rust-Docs-QA, demonstrating that Technical-Embeddings significantly outperforms baseline models in both precision and recall. Our findings highlight the effectiveness of integrating query expansion and contextual summarization to enhance information access and comprehension in technical domains. This work advances the state of Retrieval-Augmented Generation (RAG) systems, offering new avenues for efficient and accurate technical document retrieval in engineering and product development workflows.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.04139.pdf", "abstract_url": "https://arxiv.org/abs/2509.04139", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "提出Technical-Embeddings框架，通过查询扩展和上下文摘要优化技术文档检索，在RAG-EDA和Rust-Docs-QA数据集上超越基线模型。", "motivation": "解决技术文档中复杂内容理解和检索的挑战，以改进RAG系统在硬件和软件开发中的应用。", "method": "利用LLM增强查询、应用摘要提取技术，并使用软提示微调双编码器BERT模型，分别学习查询和文档参数。", "result": "在精度和召回率上显著优于基线模型，验证了方法的有效性。", "conclusion": "集成查询扩展和上下文摘要可提升技术领域的信息访问和理解，推动RAG系统发展，为工程和产品开发提供高效检索途径。"}}
{"id": "2509.03845", "title": "Meta-Inverse Reinforcement Learning for Mean Field Games via Probabilistic Context Variables", "authors": ["Yang Chen", "Xiao Lin", "Bo Yan", "Libo Zhang", "Jiamou Liu", "Neset Özkan Tan", "Michael Witbrock"], "abstract": "Designing suitable reward functions for numerous interacting intelligent agents is challenging in real-world applications. Inverse reinforcement learning (IRL) in mean field games (MFGs) offers a practical framework to infer reward functions from expert demonstrations. While promising, the assumption of agent homogeneity limits the capability of existing methods to handle demonstrations with heterogeneous and unknown objectives, which are common in practice. To this end, we propose a deep latent variable MFG model and an associated IRL method. Critically, our method can infer rewards from different yet structurally similar tasks without prior knowledge about underlying contexts or modifying the MFG model itself. Our experiments, conducted on simulated scenarios and a real-world spatial taxi-ride pricing problem, demonstrate the superiority of our approach over state-of-the-art IRL methods in MFGs.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT)", "comments": "Accepted to AAAI 2024", "pdf_url": "https://arxiv.org/pdf/2509.03845.pdf", "abstract_url": "https://arxiv.org/abs/2509.03845", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computer Science and Game Theory (cs.GT)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种通过概率上下文变量的元逆强化学习方法，用于平均场博弈，以从专家演示中推断奖励函数，处理异构和未知目标，并在模拟和真实世界场景中验证了其优越性。", "motivation": "解决在平均场博弈中，现有逆强化学习方法假设代理同质性，无法处理实践中常见的异构和未知目标的问题。", "method": "提出了一种深度潜在变量平均场博弈模型和相关的逆强化学习方法，利用概率上下文变量推断奖励函数，无需先验知识或修改模型。", "result": "在模拟场景和真实世界出租车定价问题中，该方法优于最先进的平均场博弈逆强化学习方法。", "conclusion": "该方法能有效处理异构目标，提升逆强化学习在平均场博弈中的实用性，具有广泛的应用潜力。"}}
{"id": "2509.04152", "title": "TAGAL: Tabular Data Generation using Agentic LLM Methods", "authors": ["Benoît Ronval", "Pierre Dupont", "Siegfried Nijssen"], "abstract": "The generation of data is a common approach to improve the performance of machine learning tasks, among which is the training of models for classification. In this paper, we present TAGAL, a collection of methods able to generate synthetic tabular data using an agentic workflow. The methods leverage Large Language Models (LLMs) for an automatic and iterative process that uses feedback to improve the generated data without any further LLM training. The use of LLMs also allows for the addition of external knowledge in the generation process. We evaluate TAGAL across diverse datasets and different aspects of quality for the generated data. We look at the utility of downstream ML models, both by training classifiers on synthetic data only and by combining real and synthetic data. Moreover, we compare the similarities between the real and the generated data. We show that TAGAL is able to perform on par with state-of-the-art approaches that require LLM training and generally outperforms other training-free approaches. These findings highlight the potential of agentic workflow and open new directions for LLM-based data generation methods.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.04152.pdf", "abstract_url": "https://arxiv.org/abs/2509.04152", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "TAGAL 是一种使用代理工作流生成合成表格数据的方法，无需额外 LLM 训练，性能媲美或优于现有方法。", "motivation": "解决通过数据生成提升机器学习任务性能的问题，特别是分类模型的训练。", "method": "利用大型语言模型（LLMs）进行自动迭代过程，使用反馈改进生成数据，并可整合外部知识。", "result": "在多个数据集上评估，TAGAL 在生成数据质量、下游模型效用和与真实数据相似性方面表现优异，与需要 LLM 训练的方法相当，并优于其他免训练方法。", "conclusion": "代理工作流和 LLM 在数据生成中具有潜力，为未来方法开辟了新方向。"}}
{"id": "2509.04303", "title": "HumAIne-Chatbot: Real-Time Personalized Conversational AI via Reinforcement Learning", "authors": ["Georgios Makridis", "Georgios Fragiadakis", "Jorge Oliveira", "Tomaz Saraiva", "Philip Mavrepis", "Georgios Fatouros", "Dimosthenis Kyriazis"], "abstract": "Current conversational AI systems often provide generic, one-size-fits-all interactions that overlook individual user characteristics and lack adaptive dialogue management. To address this gap, we introduce \\textbf{HumAIne-chatbot}, an AI-driven conversational agent that personalizes responses through a novel user profiling framework. The system is pre-trained on a diverse set of GPT-generated virtual personas to establish a broad prior over user types. During live interactions, an online reinforcement learning agent refines per-user models by combining implicit signals (e.g. typing speed, sentiment, engagement duration) with explicit feedback (e.g., likes and dislikes). This profile dynamically informs the chatbot dialogue policy, enabling real-time adaptation of both content and style. To evaluate the system, we performed controlled experiments with 50 synthetic personas in multiple conversation domains. The results showed consistent improvements in user satisfaction, personalization accuracy, and task achievement when personalization features were enabled. Statistical analysis confirmed significant differences between personalized and nonpersonalized conditions, with large effect sizes across key metrics. These findings highlight the effectiveness of AI-driven user profiling and provide a strong foundation for future real-world validation.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": "11 pages, 4 figures, IEEE conference format", "pdf_url": "https://arxiv.org/pdf/2509.04303.pdf", "abstract_url": "https://arxiv.org/abs/2509.04303", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "HumAIne-Chatbot 是一个通过强化学习实现实时个性化对话的 AI 系统，结合用户画像框架提升用户满意度和任务完成率。", "motivation": "解决当前对话 AI 系统提供通用、非个性化交互的问题，缺乏对用户特征的适应性和动态对话管理。", "method": "使用预训练的 GPT 生成虚拟人物建立用户类型先验，在线强化学习结合隐式和显式反馈优化用户模型，动态调整对话策略。", "result": "实验显示个性化功能显著提高用户满意度、个性化准确性和任务成就，统计分析确认大效应量差异。", "conclusion": "AI 驱动的用户画像有效，为现实世界应用提供基础，强调个性化在对话 AI 中的重要性。"}}
