{"id": "2506.06331", "title": "How Significant Are the Real Performance Gains? An Unbiased Evaluation Framework for GraphRAG", "authors": ["Qiming Zeng", "Xiao Yan", "Hao Luo", "Yuhao Lin", "Yuxiang Wang", "Fangcheng Fu", "Bo Du", "Quanqing Xu", "Jiawei Jiang"], "abstract": "By retrieving contexts from knowledge graphs, graph-based retrieval-augmented generation (GraphRAG) enhances large language models (LLMs) to generate quality answers for user questions. Many GraphRAG methods have been proposed and reported inspiring performance in answer quality. However, we observe that the current answer evaluation framework for GraphRAG has two critical flaws, i.e., unrelated questions and evaluation biases, which may lead to biased or even wrong conclusions on performance. To tackle the two flaws, we propose an unbiased evaluation framework that uses graph-text-grounded question generation to produce questions that are more related to the underlying dataset and an unbiased evaluation procedure to eliminate the biases in LLM-based answer assessment. We apply our unbiased framework to evaluate 3 representative GraphRAG methods and find that their performance gains are much more moderate than reported previously. Although our evaluation framework may still have flaws, it calls for scientific evaluations to lay solid foundations for GraphRAG research.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.06331.pdf", "abstract_url": "https://arxiv.org/abs/2506.06331", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种无偏见的评估框架，用于评估基于知识图谱的检索增强生成（GraphRAG）方法的真实性能增益，发现现有方法的性能提升比之前报道的要温和得多。", "motivation": "当前GraphRAG方法的答案评估框架存在两个关键缺陷，即无关问题和评估偏见，这可能导致对性能的偏见甚至错误结论。", "method": "提出了一个无偏见的评估框架，包括使用基于图-文本基础的问题生成来产生更相关的问题，以及一个无偏见的评估程序来消除基于LLM的答案评估中的偏见。", "result": "应用该框架评估了3种代表性的GraphRAG方法，发现它们的性能增益比之前报道的要温和得多。", "conclusion": "尽管评估框架可能仍有缺陷，但它呼吁进行科学评估，为GraphRAG研究奠定坚实的基础。"}}
{"id": "2506.06854", "title": "DONUT: A Decoder-Only Model for Trajectory Prediction", "authors": ["Markus Knoche", "Daan de Geus", "Bastian Leibe"], "abstract": "Predicting the motion of other agents in a scene is highly relevant for autonomous driving, as it allows a self-driving car to anticipate. Inspired by the success of decoder-only models for language modeling, we propose DONUT, a Decoder-Only Network for Unrolling Trajectories. Different from existing encoder-decoder forecasting models, we encode historical trajectories and predict future trajectories with a single autoregressive model. This allows the model to make iterative predictions in a consistent manner, and ensures that the model is always provided with up-to-date information, enhancing the performance. Furthermore, inspired by multi-token prediction for language modeling, we introduce an 'overprediction' strategy that gives the network the auxiliary task of predicting trajectories at longer temporal horizons. This allows the model to better anticipate the future, and further improves the performance. With experiments, we demonstrate that our decoder-only approach outperforms the encoder-decoder baseline, and achieves new state-of-the-art results on the Argoverse 2 single-agent motion forecasting benchmark.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.06854.pdf", "abstract_url": "https://arxiv.org/abs/2506.06854", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种仅解码器模型DONUT，用于轨迹预测，通过单一自回归模型编码历史轨迹并预测未来轨迹，提高了性能，并在Argoverse 2单智能体运动预测基准上实现了新的最先进结果。", "motivation": "解决自动驾驶中预测场景中其他智能体运动的问题，以提高自动驾驶汽车的预判能力。", "method": "采用仅解码器网络DONUT，通过单一自回归模型进行历史轨迹编码和未来轨迹预测，并引入'过度预测'策略以预测更长的时间范围内的轨迹。", "result": "DONUT在性能上超越了编码器-解码器基线模型，并在Argoverse 2单智能体运动预测基准上取得了新的最先进结果。", "conclusion": "仅解码器模型DONUT在轨迹预测任务中表现出色，其自回归预测和'过度预测'策略显著提高了预测性能，为自动驾驶领域提供了有效的解决方案。"}}
{"id": "2506.06287", "title": "Deep Research Bench: Evaluating AI Web Research Agents", "authors": ["FutureSearch", "Nikos I. Bosse", "Jon Evans", "Robert G. Gambee", "Daniel Hnyk", "Peter Mühlbacher", "Lawrence Phillips", "Dan Schwarz", "Jack Wildman"], "abstract": "Amongst the most common use cases of modern AI is LLM chat with web search enabled. However, no direct evaluations of the quality of web research agents exist that control for the continually-changing web. We introduce Deep Research Bench, consisting of 89 multi-step web research task instances of varying difficulty across 8 diverse task categories, with the answers carefully worked out by skilled humans. We provide a \"RetroSearch\" environment with a large frozen set of scraped web pages, and demonstrate that offline \"RetroSearch\" agents perform comparably to \"live web\" agents, enabling reliable evaluations of models over time. We provide robust agent tooling and scaffolding to benchmark major LLMs as they are released, including \"thinking\" models like o3 and Gemini 2.5 Pro. We include automated evaluations of the lengthy agent traces to report progress over time in hallucinations, tool use, and forgetting. Finally, we evaluate the major web research products branded as \"Deep Research\", \"Deep Search\", \"Search\", or \"Research.\" Results are available on a public leaderboard at", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.06287.pdf", "abstract_url": "https://arxiv.org/abs/2506.06287", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了Deep Research Bench，一个用于评估AI网络研究代理质量的基准测试，包含89个多步骤网络研究任务实例，覆盖8个不同任务类别，并提供了RetroSearch环境和自动化评估工具。", "motivation": "解决现代AI中最常见的用途之一——启用网络搜索的LLM聊天——缺乏对网络研究代理质量直接评估的问题，尤其是在网络内容不断变化的背景下。", "method": "引入Deep Research Bench，包括89个多步骤网络研究任务实例，使用RetroSearch环境（一个包含大量冻结抓取网页的集合）来评估模型性能，并提供自动化评估工具。", "result": "研究表明，离线RetroSearch代理与实时网络代理性能相当，能够可靠地评估模型随时间的变化，并提供了主要网络研究产品的评估结果。", "conclusion": "Deep Research Bench为评估网络研究代理提供了一个可靠的基准，支持对主要LLM模型的持续评估，并公开了评估结果的排行榜。"}}
{"id": "2506.06324", "title": "Mapping Human-Agent Co-Learning and Co-Adaptation: A Scoping Review", "authors": ["Shruti Kumar", "Xiaoyu Chen", "Xiaomei Wang"], "abstract": "Several papers have delved into the challenges of human-AI-robot co-learning and co-adaptation. It has been noted that the terminology used to describe this collaborative relationship in existing studies needs to be more consistent. For example, the prefix \"co\" is used interchangeably to represent both \"collaborative\" and \"mutual,\" and the terms \"co-learning\" and \"co-adaptation\" are sometimes used interchangeably. However, they can reflect subtle differences in the focus of the studies. The current scoping review's primary research question (RQ1) aims to gather existing papers discussing this collaboration pattern and examine the terms researchers use to describe this human-agent relationship. Given the relative newness of this area of study, we are also keen on exploring the specific types of intelligent agents and task domains that have been considered in existing research (RQ2). This exploration is significant as it can shed light on the diversity of human-agent interactions, from one-time to continuous learning/adaptation scenarios. It can also help us understand the dynamics of human-agent interactions in different task domains, guiding our expectations towards research situated in dynamic, complex domains. Our third objective (RQ3) is to investigate the cognitive theories and frameworks that have been utilized in existing studies to measure human-agent co-learning and co-adaptation. This investigation is crucial as it can help us understand the theoretical underpinnings of human-agent collaboration and adaptation, and it can also guide us in identifying any new frameworks proposed specifically for this type of relationship.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "Abstract accepted to HFES 2024 Annual Meeting", "pdf_url": "https://arxiv.org/pdf/2506.06324.pdf", "abstract_url": "https://arxiv.org/abs/2506.06324", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过范围综述的方法，探讨了人类与AI/机器人共学习与共适应的研究现状，重点分析了术语使用的不一致性、智能代理类型与任务领域的多样性，以及用于测量这种关系的认知理论与框架。", "motivation": "解决人类与AI/机器人共学习与共适应研究中术语使用不一致的问题，并探索该领域的研究多样性及理论框架。", "method": "采用范围综述方法，收集并分析现有研究，重点关注术语使用、智能代理类型、任务领域及认知理论与框架。", "result": "研究发现术语使用存在不一致性，智能代理和任务领域具有多样性，且缺乏统一的认知理论与框架来衡量人类与代理的共学习与共适应。", "conclusion": "本研究为人类与AI/机器人共学习与共适应领域的研究提供了全面的概述，指出了术语标准化和理论框架开发的必要性，以促进未来研究的深入发展。"}}
{"id": "2506.06326", "title": "Memory OS of AI Agent", "authors": ["Jiazheng Kang", "Mingming Ji", "Zhe Zhao", "Ting Bai"], "abstract": "Large Language Models (LLMs) face a crucial challenge from fixed context windows and inadequate memory management, leading to a severe shortage of long-term memory capabilities and limited personalization in the interactive experience with AI agents. To overcome this challenge, we innovatively propose a Memory Operating System, i.e., MemoryOS, to achieve comprehensive and efficient memory management for AI agents. Inspired by the memory management principles in operating systems, MemoryOS designs a hierarchical storage architecture and consists of four key modules: Memory Storage, Updating, Retrieval, and Generation. Specifically, the architecture comprises three levels of storage units: short-term memory, mid-term memory, and long-term personal memory. Key operations within MemoryOS include dynamic updates between storage units: short-term to mid-term updates follow a dialogue-chain-based FIFO principle, while mid-term to long-term updates use a segmented page organization strategy. Our pioneering MemoryOS enables hierarchical memory integration and dynamic updating. Extensive experiments on the LoCoMo benchmark show an average improvement of 49.11% on F1 and 46.18% on BLEU-1 over the baselines on GPT-4o-mini, showing contextual coherence and personalized memory retention in long conversations. The implementation code is open-sourced at", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.06326.pdf", "abstract_url": "https://arxiv.org/abs/2506.06326", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种创新的内存操作系统MemoryOS，旨在解决大型语言模型（LLMs）因固定上下文窗口和不足的内存管理而导致的长时记忆能力不足和交互体验个性化有限的问题。", "motivation": "大型语言模型面临固定上下文窗口和不足的内存管理带来的挑战，这限制了其长时记忆能力和交互体验的个性化。", "method": "受操作系统内存管理原则的启发，MemoryOS设计了一个分层存储架构，包含四个关键模块：内存存储、更新、检索和生成。架构包括三个存储单元级别：短时记忆、中时记忆和长时个人记忆。", "result": "在LoCoMo基准测试上的广泛实验显示，与基线相比，GPT-4o-mini在F1和BLEU-1上平均提高了49.11%和46.18%，展示了在长对话中的上下文连贯性和个性化记忆保留。", "conclusion": "MemoryOS通过分层内存集成和动态更新，显著提升了AI代理的长时记忆能力和交互体验的个性化，其实现代码已开源。"}}
{"id": "2506.06352", "title": "Will artificial agents pursue power by default?", "authors": ["Christian Tarsney"], "abstract": "Researchers worried about catastrophic risks from advanced AI have argued that we should expect sufficiently capable AI agents to pursue power over humanity because power is a convergent instrumental goal, something that is useful for a wide range of final goals. Others have recently expressed skepticism of these claims. This paper aims to formalize the concepts of instrumental convergence and power-seeking in an abstract, decision-theoretic framework, and to assess the claim that power is a convergent instrumental goal. I conclude that this claim contains at least an element of truth, but might turn out to have limited predictive utility, since an agent's options cannot always be ranked in terms of power in the absence of substantive information about the agent's final goals. However, the fact of instrumental convergence is more predictive for agents who have a good shot at attaining absolute or near-absolute power.", "subjects": "Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.06352.pdf", "abstract_url": "https://arxiv.org/abs/2506.06352", "categories": ["Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了高级人工智能是否会默认追求权力的问题，通过决策理论框架形式化了工具性收敛和权力追求的概念，并评估了权力作为工具性收敛目标的说法。", "motivation": "解决关于高级AI是否会因其广泛适用性而追求权力，从而可能带来灾难性风险的争议。", "method": "使用抽象的决策理论框架来形式化工具性收敛和权力追求的概念。", "result": "权力作为工具性收敛目标的说法有一定道理，但在缺乏关于AI最终目标的实质性信息时，其预测效用可能有限。对于有可能获得绝对或接近绝对权力的AI，工具性收敛的事实更具预测性。", "conclusion": "虽然权力作为工具性收敛目标的观点包含一定真实性，但其预测效用可能受限。对于能够获得极大权力的AI，工具性收敛的现象更为显著。"}}
{"id": "2506.06524", "title": "ScriptDoctor: Automatic Generation of PuzzleScript Games via Large Language Models and Tree Search", "authors": ["Sam Earle", "Ahmed Khalifa", "Muhammad Umair Nasir", "Zehua Jiang", "Graham Todd", "Andrzej Banburski-Fahey", "Julian Togelius"], "abstract": "There is much interest in using large pre-trained models in Automatic Game Design (AGD), whether via the generation of code, assets, or more abstract conceptualization of design ideas. But so far this interest largely stems from the ad hoc use of such generative models under persistent human supervision. Much work remains to show how these tools can be integrated into longer-time-horizon AGD pipelines, in which systems interface with game engines to test generated content autonomously. To this end, we introduce ScriptDoctor, a Large Language Model (LLM)-driven system for automatically generating and testing games in PuzzleScript, an expressive but highly constrained description language for turn-based puzzle games over 2D gridworlds. ScriptDoctor generates and tests game design ideas in an iterative loop, where human-authored examples are used to ground the system's output, compilation errors from the PuzzleScript engine are used to elicit functional code, and search-based agents play-test generated games. ScriptDoctor serves as a concrete example of the potential of automated, open-ended LLM-based workflows in generating novel game content.", "subjects": "Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)", "comments": "5 pages, 3 figures, 3 tables, submitted to IEEE Conference on Games as a Short Paper", "pdf_url": "https://arxiv.org/pdf/2506.06524.pdf", "abstract_url": "https://arxiv.org/abs/2506.06524", "categories": ["Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "ScriptDoctor是一个利用大型语言模型和树搜索自动生成PuzzleScript游戏的系统，展示了在自动游戏设计中集成大型预训练模型的潜力。", "motivation": "解决在自动游戏设计（AGD）中如何将大型预训练模型集成到长期设计流程中的问题，特别是在无需持续人类监督的情况下自动生成和测试游戏内容。", "method": "结合大型语言模型（LLM）和树搜索技术，通过迭代循环生成和测试游戏设计想法，利用人类编写的示例来指导输出，使用PuzzleScript引擎的编译错误来引导功能代码的生成，并通过基于搜索的代理进行游戏测试。", "result": "ScriptDoctor能够自动生成新颖的游戏内容，展示了在自动游戏设计中利用LLM进行开放式工作流程的潜力。", "conclusion": "ScriptDoctor作为一个具体示例，证明了基于LLM的自动化工作流程在生成新颖游戏内容方面的潜力，为自动游戏设计领域提供了新的研究方向。"}}
{"id": "2506.06574", "title": "The Optimization Paradox in Clinical AI Multi-Agent Systems", "authors": ["Suhana Bedi", "Iddah Mlauzi", "Daniel Shin", "Sanmi Koyejo", "Nigam H. Shah"], "abstract": "Multi-agent artificial intelligence systems are increasingly deployed in clinical settings, yet the relationship between component-level optimization and system-wide performance remains poorly understood. We evaluated this relationship using 2,400 real patient cases from the MIMIC-CDM dataset across four abdominal pathologies (appendicitis, pancreatitis, cholecystitis, diverticulitis), decomposing clinical diagnosis into information gathering, interpretation, and differential diagnosis. We evaluated single agent systems (one model performing all tasks) against multi-agent systems (specialized models for each task) using comprehensive metrics spanning diagnostic outcomes, process adherence, and cost efficiency. Our results reveal a paradox: while multi-agent systems generally outperformed single agents, the component-optimized or Best of Breed system with superior components and excellent process metrics (85.5% information accuracy) significantly underperformed in diagnostic accuracy (67.7% vs. 77.4% for a top multi-agent system). This finding underscores that successful integration of AI in healthcare requires not just component level optimization but also attention to information flow and compatibility between agents. Our findings highlight the need for end to end system validation rather than relying on component metrics alone.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.06574.pdf", "abstract_url": "https://arxiv.org/abs/2506.06574", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了临床AI多智能体系统中组件级优化与系统整体性能之间的关系，揭示了优化悖论：尽管多智能体系统通常优于单智能体系统，但组件优化的‘最佳品种’系统在诊断准确性上表现不佳。", "motivation": "解决临床AI多智能体系统中组件级优化与系统整体性能之间关系不明的问题。", "method": "使用MIMIC-CDM数据集中的2,400个真实患者案例，比较单智能体系统和多智能体系统在诊断结果、过程遵守和成本效率等方面的表现。", "result": "多智能体系统通常优于单智能体系统，但组件优化的‘最佳品种’系统在诊断准确性上显著低于顶级多智能体系统（67.7% vs. 77.4%）。", "conclusion": "成功整合AI到医疗保健中不仅需要组件级优化，还需要关注信息流和智能体之间的兼容性，强调需要进行端到端系统验证。"}}
{"id": "2506.06962", "title": "AR-RAG: Autoregressive Retrieval Augmentation for Image Generation", "authors": ["Jingyuan Qi", "Zhiyang Xu", "Qifan Wang", "Lifu Huang"], "abstract": "We introduce Autoregressive Retrieval Augmentation (AR-RAG), a novel paradigm that enhances image generation by autoregressively incorporating knearest neighbor retrievals at the patch level. Unlike prior methods that perform a single, static retrieval before generation and condition the entire generation on fixed reference images, AR-RAG performs context-aware retrievals at each generation step, using prior-generated patches as queries to retrieve and incorporate the most relevant patch-level visual references, enabling the model to respond to evolving generation needs while avoiding limitations (e.g., over-copying, stylistic bias, etc.) prevalent in existing methods. To realize AR-RAG, we propose two parallel frameworks: (1) Distribution-Augmentation in Decoding (DAiD), a training-free plug-and-use decoding strategy that directly merges the distribution of model-predicted patches with the distribution of retrieved patches, and (2) Feature-Augmentation in Decoding (FAiD), a parameter-efficient fine-tuning method that progressively smooths the features of retrieved patches via multi-scale convolution operations and leverages them to augment the image generation process. We validate the effectiveness of AR-RAG on widely adopted benchmarks, including Midjourney-30K, GenEval and DPG-Bench, demonstrating significant performance gains over state-of-the-art image generation models.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "Image Generation, Retrieval Augmented Generation", "pdf_url": "https://arxiv.org/pdf/2506.06962.pdf", "abstract_url": "https://arxiv.org/abs/2506.06962", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "AR-RAG是一种新颖的自回归检索增强图像生成范式，通过在生成过程中逐步整合最相关的图像块级视觉参考，提升了图像生成的质量和灵活性。", "motivation": "解决现有图像生成方法中存在的单次静态检索导致的过度复制、风格偏差等问题，通过动态检索适应生成过程中的变化需求。", "method": "提出了两种并行框架：DAiD（一种无需训练的解码策略，直接合并模型预测块与检索块的分布）和FAiD（一种参数高效的微调方法，通过多尺度卷积操作平滑检索块的特征并用于增强图像生成过程）。", "result": "在Midjourney-30K、GenEval和DPG-Bench等广泛采用的基准测试中验证了AR-RAG的有效性，显示出相对于最先进图像生成模型的显著性能提升。", "conclusion": "AR-RAG通过自回归检索增强，有效解决了现有方法的局限性，为图像生成领域提供了新的研究方向和实践方法。"}}
{"id": "2506.07016", "title": "MAGNET: A Multi-agent Framework for Finding Audio-Visual Needles by Reasoning over Multi-Video Haystacks", "authors": ["Sanjoy Chowdhury", "Mohamed Elmoghany", "Yohan Abeysinghe", "Junjie Fei", "Sayan Nag", "Salman Khan", "Mohamed Elhoseiny", "Dinesh Manocha"], "abstract": "Large multimodal models (LMMs) have shown remarkable progress in audio-visual understanding, yet they struggle with real-world scenarios that require complex reasoning across extensive video collections. Existing benchmarks for video question answering remain limited in scope, typically involving one clip per query, which falls short of representing the challenges of large-scale, audio-visual retrieval and reasoning encountered in practical applications. To bridge this gap, we introduce a novel task named AV-HaystacksQA, where the goal is to identify salient segments across different videos in response to a query and link them together to generate the most informative answer. To this end, we present AVHaystacks, an audio-visual benchmark comprising 3100 annotated QA pairs designed to assess the capabilities of LMMs in multi-video retrieval and temporal grounding task. Additionally, we propose a model-agnostic, multi-agent framework MAGNET to address this challenge, achieving up to 89% and 65% relative improvements over baseline methods on BLEU@4 and GPT evaluation scores in QA task on our proposed AVHaystacks. To enable robust evaluation of multi-video retrieval and temporal grounding for optimal response generation, we introduce two new metrics, STEM, which captures alignment errors between a ground truth and a predicted step sequence and MTGS, to facilitate balanced and interpretable evaluation of segment-level grounding performance. Project:", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": "Audio-visual learning, Audio-Visual RAG, Multi-Video Linkage", "pdf_url": "https://arxiv.org/pdf/2506.07016.pdf", "abstract_url": "https://arxiv.org/abs/2506.07016", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一个名为MAGNET的多智能体框架，旨在通过多视频推理找到音频-视觉‘针’，解决了大型多模态模型在处理跨广泛视频集合的复杂推理时的挑战。", "motivation": "大型多模态模型在音频-视觉理解方面取得了显著进展，但在需要跨广泛视频集合进行复杂推理的现实世界场景中表现不佳。现有的视频问答基准在范围上有限，通常每个查询只涉及一个片段，无法代表实际应用中遇到的大规模音频-视觉检索和推理的挑战。", "method": "为了填补这一空白，作者引入了一个名为AV-HaystacksQA的新任务，目标是根据查询识别不同视频中的显著片段并将它们链接起来以生成最具信息量的答案。为此，作者提出了AVHaystacks，一个包含3100个标注QA对的音频-视觉基准，旨在评估大型多模态模型在多视频检索和时间定位任务中的能力。此外，作者提出了一个模型无关的多智能体框架MAGNET来应对这一挑战。", "result": "在提出的AVHaystacks上，MAGNET在QA任务中的BLEU@4和GPT评估分数上分别实现了高达89%和65%的相对改进。为了实现对多视频检索和时间定位的稳健评估以生成最佳响应，作者引入了两个新指标STEM和MTGS。", "conclusion": "本文的主要结论和意义在于提出了一个新的任务和基准，以及一个有效的多智能体框架MAGNET，显著提高了在多视频检索和时间定位任务中的性能，同时引入了新的评估指标以促进更平衡和可解释的评估。"}}
{"id": "2506.06500", "title": "Improving LLM-Powered EDA Assistants with RAFT", "authors": ["Luyao Shi", "Michael Kazda", "Charles Schmitter", "Hemlata Gupta"], "abstract": "Electronic design engineers often struggle to efficiently access relevant information for tasks like design verification and technology development. While large language models (LLMs) can enhance productivity as conversational agents, pre-trained open-source LLMs lack domain-specific knowledge for Electronic Design Automation (EDA). In a Retrieval-Augmented Generation (RAG) context, LLMs rely on external context but may still produce inaccurate responses. Retrieval-Augmented Fine-Tuning (RAFT) improves LLM performance, but acquiring labeled question/answer (Q/A) data in EDA is difficult. To address this, we propose using synthetic Q/A datasets to enhance LLMs with RAFT. Our results show that RAFT with synthetic data significantly boosts LLM performance for RAG-based EDA tasks. We also investigate the impact of using real user questions as Retrieval-Augmented Few-Shot (RAFS) examples for synthetic data generation. Additionally, we implement secure access control to ensure sensitive information is only accessible to authorized personnel. Finally, we assess the risk of data leakage and unintended memorization during fine-tuning with synthetic data, providing practical insights.", "subjects": "Computation and Language (cs.CL)", "comments": "Accepted paper at IEEE International Conference on LLM-Aided Design, 2025 (LAD 2025)", "pdf_url": "https://arxiv.org/pdf/2506.06500.pdf", "abstract_url": "https://arxiv.org/abs/2506.06500", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文提出使用合成Q/A数据集通过RAFT技术增强LLM在EDA领域的性能，解决了领域特定知识不足和标记数据获取困难的问题，并探讨了安全访问控制和数据泄漏风险。", "motivation": "电子设计工程师在设计验证和技术开发等任务中难以高效获取相关信息，而预训练的开源LLM缺乏电子设计自动化(EDA)的领域特定知识，且在RAG背景下可能产生不准确的响应。", "method": "采用合成Q/A数据集结合RAFT技术来增强LLM，研究使用真实用户问题作为RAFS示例对合成数据生成的影响，并实施安全访问控制。", "result": "结果表明，使用合成数据的RAFT显著提高了LLM在基于RAG的EDA任务中的性能，并对数据泄漏和无意记忆化风险进行了评估。", "conclusion": "通过RAFT和合成数据可以有效提升LLM在EDA领域的应用性能，同时需注意数据安全和隐私保护。"}}
{"id": "2506.06539", "title": "Beyond Facts: Evaluating Intent Hallucination in Large Language Models", "authors": ["Yijie Hao", "Haofei Yu", "Jiaxuan You"], "abstract": "When exposed to complex queries containing multiple conditions, today's large language models (LLMs) tend to produce responses that only partially satisfy the query while neglecting certain conditions. We therefore introduce the concept of Intent Hallucination. In this phenomenon, LLMs either omit (neglecting to address certain parts) or misinterpret (responding to invented query parts) elements of the given query, leading to intent hallucinated generation. To systematically evaluate intent hallucination, we introduce FAITHQA, a novel benchmark for intent hallucination that contains 20,068 problems, covering both query-only and retrieval-augmented generation (RAG) setups with varying topics and difficulty. FAITHQA is the first hallucination benchmark that goes beyond factual verification, tailored to identify the fundamental cause of intent hallucination. By evaluating various LLMs on FAITHQA, we find that (1) intent hallucination is a common issue even for state-of-the-art models, and (2) the phenomenon stems from omission or misinterpretation of LLMs. To facilitate future research, we introduce an automatic LLM generation evaluation metric, CONSTRAINT SCORE, for detecting intent hallucination. Human evaluation results demonstrate that CONSTRAINT SCORE is closer to human performance for intent hallucination compared to baselines.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "Accepted to ACL 2025 main conference", "pdf_url": "https://arxiv.org/pdf/2506.06539.pdf", "abstract_url": "https://arxiv.org/abs/2506.06539", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了意图幻觉的概念，即在面对包含多个条件的复杂查询时，大型语言模型（LLMs）往往只部分满足查询而忽略某些条件。作者提出了FAITHQA基准来系统评估意图幻觉，并发现即使是先进模型也存在此问题。", "motivation": "解决大型语言模型在处理复杂查询时部分满足或误解查询条件的问题，即意图幻觉现象。", "method": "引入FAITHQA基准，包含20,068个问题，覆盖查询仅和检索增强生成（RAG）设置，以及不同主题和难度。并提出CONSTRAINT SCORE自动评估指标。", "result": "发现意图幻觉是即使是先进模型也普遍存在的问题，且源于模型的遗漏或误解。CONSTRAINT SCORE在检测意图幻觉上更接近人类表现。", "conclusion": "意图幻觉是LLMs中一个普遍且根本的问题，FAITHQA和CONSTRAINT SCORE为未来研究提供了评估工具。"}}
{"id": "2506.06698", "title": "Contextual Experience Replay for Self-Improvement of Language Agents", "authors": ["Yitao Liu", "Chenglei Si", "Karthik Narasimhan", "Shunyu Yao"], "abstract": "Large language model (LLM) agents have been applied to sequential decision-making tasks such as web navigation, but without any environment-specific experiences, they often fail in these complex tasks. Moreover, current LLM agents are not designed to continually learn from past experiences during inference time, which could be crucial for them to gain these environment-specific experiences. To address this, we propose Contextual Experience Replay (CER), a training-free framework to enable efficient self-improvement for language agents in their context window. Specifically, CER accumulates and synthesizes past experiences into a dynamic memory buffer. These experiences encompass environment dynamics and common decision-making patterns, allowing the agents to retrieve and augment themselves with relevant knowledge in new tasks, enhancing their adaptability in complex environments. We evaluate CER on the challenging WebArena and VisualWebArena benchmarks. On VisualWebArena, CER achieves a competitive performance of 31.9%. On WebArena, CER also gets a competitive average success rate of 36.7%, relatively improving the success rate of the GPT-4o agent baseline by 51.0%. We also conduct a comprehensive analysis on it to prove its efficiency, validity and understand it better.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "comments": "Accepted to ACL 2025. 20 pages", "pdf_url": "https://arxiv.org/pdf/2506.06698.pdf", "abstract_url": "https://arxiv.org/abs/2506.06698", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Computer Vision and Pattern Recognition (cs.CV)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为上下文经验回放（CER）的无训练框架，旨在通过积累和合成过去的经验来增强语言代理在复杂任务中的适应性和自我改进能力。", "motivation": "解决大型语言模型（LLM）代理在顺序决策任务（如网页导航）中因缺乏环境特定经验而失败的问题，以及当前LLM代理在推理时间无法持续学习过去经验的限制。", "method": "提出CER框架，通过动态记忆缓冲区积累和合成过去的经验，包括环境动态和常见决策模式，使代理能够在新的任务中检索并增强相关知识。", "result": "在VisualWebArena和WebArena基准测试中，CER分别取得了31.9%和36.7%的平均成功率，相对于GPT-4o代理基线，成功率相对提高了51.0%。", "conclusion": "CER框架有效地提高了语言代理在复杂环境中的适应性和性能，证明了其效率、有效性，并为理解其工作机制提供了全面的分析。"}}
{"id": "2506.06580", "title": "AI Simulation by Digital Twins: Systematic Survey, Reference Framework, and Mapping to a Standardized Architecture", "authors": ["Xiaoran Liu", "Istvan David"], "abstract": "Insufficient data volume and quality are particularly pressing challenges in the adoption of modern subsymbolic AI. To alleviate these challenges, AI simulation uses virtual training environments in which AI agents can be safely and efficiently developed with simulated, synthetic data. Digital twins open new avenues in AI simulation, as these high-fidelity virtual replicas of physical systems are equipped with state-of-the-art simulators and the ability to further interact with the physical system for additional data collection. In this article, we report on our systematic survey of digital twin-enabled AI simulation. By analyzing 22 primary studies, we identify technological trends and derive a reference framework to situate digital twins and AI components. Based on our findings, we derive a reference framework and provide architectural guidelines by mapping it onto the ISO 23247 reference architecture for digital twins. Finally, we identify challenges and research opportunities for prospective researchers.", "subjects": "Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET); Software Engineering (cs.SE); Systems and Control (eess.SY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.06580.pdf", "abstract_url": "https://arxiv.org/abs/2506.06580", "categories": ["Artificial Intelligence (cs.AI)", "Emerging Technologies (cs.ET)", "Software Engineering (cs.SE)", "Systems and Control (eess.SY)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过系统调查数字孪生支持的AI模拟，分析了22项主要研究，识别技术趋势，并提出了一个参考框架，将数字孪生和AI组件定位。基于研究结果，作者提出了参考框架，并通过将其映射到ISO 23247数字孪生参考架构上，提供了架构指南。最后，作者指出了未来研究面临的挑战和机遇。", "motivation": "解决在现代亚符号AI采用中数据量和质量不足的挑战，通过数字孪生提供的高保真虚拟复制品和先进模拟器，为AI模拟开辟新途径。", "method": "进行系统调查，分析22项主要研究，识别技术趋势，并基于ISO 23247参考架构提出参考框架和架构指南。", "result": "提出了一个参考框架，将数字孪生和AI组件定位，并提供了映射到ISO 23247参考架构上的架构指南。", "conclusion": "数字孪生为AI模拟提供了新的可能性，但同时也面临着挑战，为未来的研究提供了方向和机遇。"}}
{"id": "2506.06725", "title": "WorldLLM: Improving LLMs' world modeling using curiosity-driven theory-making", "authors": ["Guillaume Levy", "Cedric Colas", "Pierre-Yves Oudeyer", "Thomas Carta", "Clement Romac"], "abstract": "Large Language Models (LLMs) possess general world knowledge but often struggle to generate precise predictions in structured, domain-specific contexts such as simulations. These limitations arise from their inability to ground their broad, unstructured understanding in specific environments. To address this, we present WorldLLM, a framework that enhances LLM-based world modeling by combining Bayesian inference and autonomous active exploration with reinforcement learning. WorldLLM leverages the in-context learning abilities of LLMs to guide an LLM-based world model's predictions using natural language hypotheses given in its prompt. These hypotheses are iteratively refined through a Bayesian inference framework that leverages a second LLM as the proposal distribution given collected evidence. This evidence is collected using a curiosity-driven reinforcement learning policy that explores the environment to find transitions with a low log-likelihood under our LLM-based predictive model using the current hypotheses. By alternating between refining hypotheses and collecting new evidence, our framework autonomously drives continual improvement of the predictions. Our experiments demonstrate the effectiveness of WorldLLM in a textual game environment that requires agents to manipulate and combine objects. The framework not only enhances predictive accuracy, but also generates human-interpretable theories of environment dynamics.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.06725.pdf", "abstract_url": "https://arxiv.org/abs/2506.06725", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "WorldLLM是一个框架，通过结合贝叶斯推理和自主主动探索与强化学习，提升基于LLM的世界建模能力。", "motivation": "解决LLMs在结构化、特定领域上下文中生成精确预测的困难，因其无法将广泛、非结构化的理解扎根于特定环境。", "method": "利用LLMs的上下文学习能力，通过自然语言假设引导世界模型的预测，并通过贝叶斯推理框架迭代精炼这些假设。", "result": "在需要代理操纵和组合对象的文本游戏环境中，WorldLLM不仅提高了预测准确性，还生成了人类可理解的环境动态理论。", "conclusion": "WorldLLM框架通过交替精炼假设和收集新证据，自主驱动预测的持续改进，展示了在特定环境中提升LLM预测能力的有效性。"}}
{"id": "2506.06843", "title": "United Minds or Isolated Agents? Exploring Coordination of LLMs under Cognitive Load Theory", "authors": ["HaoYang Shang", "Xuan Liu", "Zi Liang", "Jie Zhang", "Haibo Hu", "Song Guo"], "abstract": "Large Language Models (LLMs) exhibit a notable performance ceiling on complex, multi-faceted tasks, as they often fail to integrate diverse information or adhere to multiple constraints. We posit that such limitation arises when the demands of a task exceed the LLM's effective cognitive load capacity. This interpretation draws a strong analogy to Cognitive Load Theory (CLT) in cognitive science, which explains similar performance boundaries in the human mind, and is further supported by emerging evidence that reveals LLMs have bounded working memory characteristics. Building upon this CLT-grounded understanding, we introduce CoThinker, a novel LLM-based multi-agent framework designed to mitigate cognitive overload and enhance collaborative problem-solving abilities. CoThinker operationalizes CLT principles by distributing intrinsic cognitive load through agent specialization and managing transactional load via structured communication and a collective working memory. We empirically validate CoThinker on complex problem-solving tasks and fabricated high cognitive load scenarios, demonstrating improvements over existing multi-agent baselines in solution quality and efficiency. Our analysis reveals characteristic interaction patterns, providing insights into the emergence of collective cognition and effective load management, thus offering a principled approach to overcoming LLM performance ceilings.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.06843.pdf", "abstract_url": "https://arxiv.org/abs/2506.06843", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了大型语言模型（LLMs）在复杂多面任务中的性能上限问题，提出通过认知负荷理论（CLT）解释这一现象，并介绍了CoThinker框架，通过多代理协作减轻认知过载，提升问题解决能力。", "motivation": "解决LLMs在复杂任务中因认知过载而表现不佳的问题。", "method": "引入基于CLT的CoThinker多代理框架，通过代理专业化和结构化通信分配和管理认知负荷。", "result": "CoThinker在复杂问题解决任务中表现优于现有多代理基线，提高了解决方案的质量和效率。", "conclusion": "CoThinker框架为克服LLMs性能上限提供了原则性方法，揭示了集体认知和有效负荷管理的特征互动模式。"}}
{"id": "2506.06786", "title": "Learning What Matters Now: A Dual-Critic Context-Aware RL Framework for Priority-Driven Information Gain", "authors": ["Dimitris Panagopoulos", "Adolfo Perrusquia", "Weisi Guo"], "abstract": "Autonomous systems operating in high-stakes search-and-rescue (SAR) missions must continuously gather mission-critical information while flexibly adapting to shifting operational priorities. We propose CA-MIQ (Context-Aware Max-Information Q-learning), a lightweight dual-critic reinforcement learning (RL) framework that dynamically adjusts its exploration strategy whenever mission priorities change. CA-MIQ pairs a standard extrinsic critic for task reward with an intrinsic critic that fuses state-novelty, information-location awareness, and real-time priority alignment. A built-in shift detector triggers transient exploration boosts and selective critic resets, allowing the agent to re-focus after a priority revision. In a simulated SAR grid-world, where experiments specifically test adaptation to changes in the priority order of information types the agent is expected to focus on, CA-MIQ achieves nearly four times higher mission-success rates than baselines after a single priority shift and more than three times better performance in multiple-shift scenarios, achieving 100% recovery while baseline methods fail to adapt. These results highlight CA-MIQ's effectiveness in any discrete environment with piecewise-stationary information-value distributions.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "6 pages, 2 figures, 3 tables, submitted as a regural paper to IEEE International Conference on Systems, Man, and Cybernetics (SMC) 2025", "pdf_url": "https://arxiv.org/pdf/2506.06786.pdf", "abstract_url": "https://arxiv.org/abs/2506.06786", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为CA-MIQ的双评论家强化学习框架，旨在解决自主系统在高风险搜救任务中根据任务优先级动态调整探索策略的问题。", "motivation": "自主系统在高风险的搜救任务中需要不断收集关键信息，同时灵活适应变化的操作优先级。现有方法在优先级变化时难以有效适应。", "method": "CA-MIQ结合了标准的外在评论家和内在评论家，后者融合了状态新颖性、信息位置意识和实时优先级对齐。内置的转移检测器触发瞬态探索提升和选择性评论家重置。", "result": "在模拟的搜救网格世界中，CA-MIQ在优先级变化后实现了比基线方法高近四倍的任务成功率，在多优先级变化场景中表现优于基线方法三倍以上，实现了100%的恢复率。", "conclusion": "CA-MIQ在具有分段平稳信息价值分布的离散环境中表现出色，能够有效适应优先级变化，提高任务成功率。"}}
{"id": "2506.06740", "title": "AI PsyRoom: Artificial Intelligence Platform for Segmented Yearning and Reactive Outcome Optimization Method", "authors": ["Yigui Feng", "Qinglin Wang", "Ke Liu", "Xinhai Chen", "Bo Yang", "Jie Liu"], "abstract": "Psychological counseling faces huge challenges due to the growing demand for mental health services and the shortage of trained professionals. Large language models (LLMs) have shown potential to assist psychological counseling, especially in empathy and emotional support. However, existing models lack a deep understanding of emotions and are unable to generate personalized treatment plans based on fine-grained emotions. To address these shortcomings, we present AI PsyRoom, a multi-agent simulation framework designed to enhance psychological counseling by generating empathetic and emotionally nuanced conversations. By leveraging fine-grained emotion classification and a multi-agent framework, we construct a multi-agent PsyRoom A for dialogue reconstruction, generating a high-quality dialogue dataset EmoPsy, which contains 35 sub-emotions, 423 specific emotion scenarios, and 12,350 dialogues. We also propose PsyRoom B for generating personalized treatment plans. Quantitative evaluations demonstrate that AI PsyRoom significantly outperforms state-of-the-art methods, achieving 18% improvement in problem orientation, 23% in expression, 24% in Empathy, and 16% in interactive communication quality. The datasets and models are publicly available, providing a foundation for advancing AI-assisted psychological counseling research.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.06740.pdf", "abstract_url": "https://arxiv.org/abs/2506.06740", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "AI PsyRoom是一个多代理模拟框架，旨在通过生成富有同情心和情感细腻的对话来增强心理咨询。它利用细粒度情绪分类和多代理框架，构建了用于对话重建的多代理PsyRoom A和用于生成个性化治疗计划的PsyRoom B，显著优于现有方法。", "motivation": "心理咨询面临巨大挑战，原因是心理健康服务需求增长和训练有素的专业人员短缺。现有的大型语言模型在同理心和情感支持方面显示出潜力，但缺乏对情感的深入理解，无法基于细粒度情感生成个性化治疗计划。", "method": "通过细粒度情绪分类和多代理框架，构建了多代理PsyRoom A用于对话重建，生成高质量对话数据集EmoPsy，并提出PsyRoom B用于生成个性化治疗计划。", "result": "定量评估显示，AI PsyRoom在问题导向、表达、同理心和交互沟通质量方面显著优于现有方法，分别提高了18%、23%、24%和16%。", "conclusion": "AI PsyRoom为推进AI辅助心理咨询研究提供了基础，其数据集和模型已公开可用。"}}
{"id": "2506.06704", "title": "Dynamic and Parametric Retrieval-Augmented Generation", "authors": ["Weihang Su", "Qingyao Ai", "Jingtao Zhan", "Qian Dong", "Yiqun Liu"], "abstract": "Retrieval-Augmented Generation (RAG) has become a foundational paradigm for equipping large language models (LLMs) with external knowledge, playing a critical role in information retrieval and knowledge-intensive applications. However, conventional RAG systems typically adopt a static retrieve-then-generate pipeline and rely on in-context knowledge injection, which can be suboptimal for complex tasks that require multihop reasoning, adaptive information access, and deeper integration of external knowledge. Motivated by these limitations, the research community has moved beyond static retrieval and in-context knowledge injection. Among the emerging directions, this tutorial delves into two rapidly growing and complementary research areas on RAG: Dynamic RAG and Parametric RAG. Dynamic RAG adaptively determines when and what to retrieve during the LLM's generation process, enabling real-time adaptation to the LLM's evolving information needs. Parametric RAG rethinks how retrieved knowledge should be injected into LLMs, transitioning from input-level to parameter-level knowledge injection for enhanced efficiency and effectiveness. This tutorial offers a comprehensive overview of recent advances in these emerging research areas. It also shares theoretical foundations and practical insights to support and inspire further research in RAG.", "subjects": "Computation and Language (cs.CL); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.06704.pdf", "abstract_url": "https://arxiv.org/abs/2506.06704", "categories": ["Computation and Language (cs.CL)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文探讨了检索增强生成（RAG）的两个新兴研究方向：动态RAG和参数RAG，旨在解决传统RAG在复杂任务中的局限性。", "motivation": "传统RAG系统采用静态的检索-生成流程和上下文知识注入，对于需要多跳推理、自适应信息访问和更深层次外部知识集成的复杂任务可能不够优化。", "method": "动态RAG在LLM生成过程中自适应地决定何时检索和检索什么，以适应LLM不断变化的信息需求；参数RAG则从输入级知识注入转向参数级知识注入，以提高效率和效果。", "result": "本文提供了这两个新兴研究领域的全面概述，分享了理论基础和实践见解，以支持和启发RAG的进一步研究。", "conclusion": "动态RAG和参数RAG为RAG领域提供了新的研究方向，有望在复杂任务中实现更高效和有效的知识集成和应用。"}}
{"id": "2506.07055", "title": "A Layered Self-Supervised Knowledge Distillation Framework for Efficient Multimodal Learning on the Edge", "authors": ["Tarique Dahri", "Zulfiqar Ali Memon", "Zhenyu Yu", "Mohd. Yamani Idna Idris", "Sheheryar Khan", "Sadiq Ahmad", "Maged Shoman", "Saddam Aziz", "Rizwan Qureshi"], "abstract": "We introduce Layered Self-Supervised Knowledge Distillation (LSSKD) framework for training compact deep learning models. Unlike traditional methods that rely on pre-trained teacher networks, our approach appends auxiliary classifiers to intermediate feature maps, generating diverse self-supervised knowledge and enabling one-to-one transfer across different network stages. Our method achieves an average improvement of 4.54\\% over the state-of-the-art PS-KD method and a 1.14% gain over SSKD on CIFAR-100, with a 0.32% improvement on ImageNet compared to HASSKD. Experiments on Tiny ImageNet and CIFAR-100 under few-shot learning scenarios also achieve state-of-the-art results. These findings demonstrate the effectiveness of our approach in enhancing model generalization and performance without the need for large over-parameterized teacher networks. Importantly, at the inference stage, all auxiliary classifiers can be removed, yielding no extra computational cost. This makes our model suitable for deploying small language models on affordable low-computing devices. Owing to its lightweight design and adaptability, our framework is particularly suitable for multimodal sensing and cyber-physical environments that require efficient and responsive inference. LSSKD facilitates the development of intelligent agents capable of learning from limited sensory data under weak supervision.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.07055.pdf", "abstract_url": "https://arxiv.org/abs/2506.07055", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "介绍了一种名为分层自监督知识蒸馏（LSSKD）的框架，用于训练紧凑的深度学习模型。该方法通过附加辅助分类器到中间特征图，生成多样化的自监督知识，并在不同网络阶段实现一对一传输，显著提高了模型性能。", "motivation": "解决传统方法依赖预训练教师网络的问题，以及在资源有限的设备上部署小型语言模型的需求。", "method": "采用分层自监督知识蒸馏框架，通过在中间特征图上附加辅助分类器，生成并传输自监督知识。", "result": "在CIFAR-100上平均比PS-KD方法提高了4.54%，比SSKD提高了1.14%；在ImageNet上比HASSKD提高了0.32%。在Tiny ImageNet和CIFAR-100的少样本学习场景中也达到了最先进的结果。", "conclusion": "LSSKD框架在不依赖大型过参数化教师网络的情况下，有效提升了模型的泛化能力和性能，适合在计算资源有限的设备上部署，特别适用于需要高效和响应式推理的多模态感知和网络物理环境。"}}
{"id": "2506.06923", "title": "Boosting LLM Reasoning via Spontaneous Self-Correction", "authors": ["Xutong Zhao", "Tengyu Xu", "Xuewei Wang", "Zhengxing Chen", "Di Jin", "Liang Tan", "Yen-Ting", "Zishun Yu", "Zhuokai Zhao", "Yun He", "Sinong Wang", "Han Fang", "Sarath Chandar", "Chen Zhu"], "abstract": "While large language models (LLMs) have demonstrated remarkable success on a broad range of tasks, math reasoning remains a challenging one. One of the approaches for improving math reasoning is self-correction, which designs self-improving loops to let the model correct its own mistakes. However, existing self-correction approaches treat corrections as standalone post-generation refinements, relying on extra prompt and system designs to elicit self-corrections, instead of performing real-time, spontaneous self-corrections in a single pass. To address this, we propose SPOC, a spontaneous self-correction approach that enables LLMs to generate interleaved solutions and verifications in a single inference pass, with generation dynamically terminated based on verification outcomes, thereby effectively scaling inference time compute. SPOC considers a multi-agent perspective by assigning dual roles -- solution proposer and verifier -- to the same model. We adopt a simple yet effective approach to generate synthetic data for fine-tuning, enabling the model to develop capabilities for self-verification and multi-agent collaboration. We further improve its solution proposal and verification accuracy through online reinforcement learning. Experiments on mathematical reasoning benchmarks show that SPOC significantly improves performance. Notably, SPOC boosts the accuracy of Llama-3.1-8B and 70B Instruct models, achieving gains of 8.8% and 11.6% on MATH500, 10.0% and 20.0% on AMC23, and 3.3% and 6.7% on AIME24, respectively.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.06923.pdf", "abstract_url": "https://arxiv.org/abs/2506.06923", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为SPOC的自发自我纠正方法，旨在通过单次推理过程中生成交错解决方案和验证来提升大型语言模型（LLMs）的数学推理能力。", "motivation": "尽管大型语言模型在广泛的任务上取得了显著成功，数学推理仍然是一个挑战。现有的自我纠正方法将纠正视为独立的生成后优化，依赖于额外的提示和系统设计来引发自我纠正，而不是在单次推理中实现实时、自发的自我纠正。", "method": "SPOC方法通过在同一模型中分配双重角色——解决方案提出者和验证者，采用简单而有效的方法生成合成数据进行微调，使模型具备自我验证和多智能体协作的能力，并通过在线强化学习进一步提高解决方案提出和验证的准确性。", "result": "在数学推理基准测试中，SPOC显著提高了性能，特别是在Llama-3.1-8B和70B Instruct模型上，分别在MATH500、AMC23和AIME24上实现了8.8%和11.6%、10.0%和20.0%、3.3%和6.7%的准确率提升。", "conclusion": "SPOC通过自发自我纠正和多智能体协作的方法，有效提升了大型语言模型在数学推理任务上的性能，为模型的自我改进和推理能力的发展提供了新的方向。"}}
{"id": "2506.06935", "title": "An Agentic Framework for Autonomous Metamaterial Modeling and Inverse Design", "authors": ["Darui Lu", "Jordan M. Malof", "Willie J. Padilla"], "abstract": "Recent significant advances in integrating multiple Large Language Model (LLM) systems have enabled Agentic Frameworks capable of performing complex tasks autonomously, including novel scientific research. We develop and demonstrate such a framework specifically for the inverse design of photonic metamaterials. When queried with a desired optical spectrum, the Agent autonomously proposes and develops a forward deep learning model, accesses external tools via APIs for tasks like simulation and optimization, utilizes memory, and generates a final design via a deep inverse method. The framework's effectiveness is demonstrated in its ability to automate, reason, plan, and adapt. Notably, the Agentic Framework possesses internal reflection and decision flexibility, permitting highly varied and potentially novel outputs.", "subjects": "Artificial Intelligence (cs.AI); Materials Science (cond-mat.mtrl-sci)", "comments": "22 pages, 6 figures", "pdf_url": "https://arxiv.org/pdf/2506.06935.pdf", "abstract_url": "https://arxiv.org/abs/2506.06935", "categories": ["Artificial Intelligence (cs.AI)", "Materials Science (cond-mat.mtrl-sci)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了一种用于自主超材料建模和逆向设计的代理框架，利用大型语言模型系统集成，实现了复杂任务的自主执行，特别是在光子超材料的逆向设计中展示了其有效性。", "motivation": "解决光子超材料逆向设计中的复杂性和自主性问题，通过集成大型语言模型系统，实现自动化、推理、规划和适应的能力。", "method": "开发了一个代理框架，该框架能够自主提出并开发前向深度学习模型，通过API访问外部工具进行模拟和优化等任务，利用记忆，并通过深度逆向方法生成最终设计。", "result": "框架展示了在自动化、推理、规划和适应方面的有效性，具有内部反思和决策灵活性，能够产生高度多样化和潜在新颖的输出。", "conclusion": "该代理框架为超材料的逆向设计提供了一种高效、自主的解决方案，展示了在科学研究和工程应用中的潜在价值。"}}
{"id": "2506.06959", "title": "Deontically Constrained Policy Improvement in Reinforcement Learning Agents", "authors": ["Alena Makarova", "Houssam Abbas"], "abstract": "Markov Decision Processes (MDPs) are the most common model for decision making under uncertainty in the Machine Learning community. An MDP captures non-determinism, probabilistic uncertainty, and an explicit model of action. A Reinforcement Learning (RL) agent learns to act in an MDP by maximizing a utility function. This paper considers the problem of learning a decision policy that maximizes utility subject to satisfying a constraint expressed in deontic logic. In this setup, the utility captures the agent's mission - such as going quickly from A to B. The deontic formula represents (ethical, social, situational) constraints on how the agent might achieve its mission by prohibiting classes of behaviors. We use the logic of Expected Act Utilitarianism, a probabilistic stit logic that can be interpreted over controlled MDPs. We develop a variation on policy improvement, and show that it reaches a constrained local maximum of the mission utility. Given that in stit logic, an agent's duty is derived from value maximization, this can be seen as a way of acting to simultaneously maximize two value functions, one of which is implicit, in a bi-level structure. We illustrate these results with experiments on sample MDPs.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "20 pages, 11 figures, DEON2025 conference", "pdf_url": "https://arxiv.org/pdf/2506.06959.pdf", "abstract_url": "https://arxiv.org/abs/2506.06959", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了在强化学习（RL）代理中，如何在满足义务逻辑约束的条件下学习最大化效用的决策策略。通过使用期望行为功利主义逻辑，开发了一种策略改进的变体，以达到任务效用的约束局部最大值。", "motivation": "解决在强化学习代理中，如何在满足（伦理、社会、情境）约束的条件下，学习最大化效用的决策策略的问题。", "method": "使用期望行为功利主义逻辑，这是一种可以在受控马尔可夫决策过程（MDPs）上解释的概率stit逻辑，并开发了一种策略改进的变体。", "result": "开发的策略改进方法能够达到任务效用的约束局部最大值，实验在样本MDPs上验证了这些结果。", "conclusion": "本文提出了一种在满足义务逻辑约束的条件下，学习最大化效用的决策策略的方法，为强化学习代理在复杂环境中的应用提供了新的思路。"}}
{"id": "2506.06981", "title": "Deep RL Needs Deep Behavior Analysis: Exploring Implicit Planning by Model-Free Agents in Open-Ended Environments", "authors": ["Riley Simmons-Edler", "Ryan P. Badman", "Felix Baastad Berg", "Raymond Chua", "John J. Vastola", "Joshua Lunger", "William Qian", "Kanaka Rajan"], "abstract": "Understanding the behavior of deep reinforcement learning (DRL) agents -- particularly as task and agent sophistication increase -- requires more than simple comparison of reward curves, yet standard methods for behavioral analysis remain underdeveloped in DRL. We apply tools from neuroscience and ethology to study DRL agents in a novel, complex, partially observable environment, ForageWorld, designed to capture key aspects of real-world animal foraging -- including sparse, depleting resource patches, predator threats, and spatially extended arenas. We use this environment as a platform for applying joint behavioral and neural analysis to agents, revealing detailed, quantitatively grounded insights into agent strategies, memory, and planning. Contrary to common assumptions, we find that model-free RNN-based DRL agents can exhibit structured, planning-like behavior purely through emergent dynamics -- without requiring explicit memory modules or world models. Our results show that studying DRL agents like animals -- analyzing them with neuroethology-inspired tools that reveal structure in both behavior and neural dynamics -- uncovers rich structure in their learning dynamics that would otherwise remain invisible. We distill these tools into a general analysis framework linking core behavioral and representational features to diagnostic methods, which can be reused for a wide range of tasks and agents. As agents grow more complex and autonomous, bridging neuroscience, cognitive science, and AI will be essential -- not just for understanding their behavior, but for ensuring safe alignment and maximizing desirable behaviors that are hard to measure via reward. We show how this can be done by drawing on lessons from how biological intelligence is studied.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.06981.pdf", "abstract_url": "https://arxiv.org/abs/2506.06981", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了深度强化学习（DRL）代理在开放环境中的行为，特别是在复杂、部分可观察的环境ForageWorld中。通过应用神经科学和动物行为学的工具，研究发现，即使没有显式的记忆模块或世界模型，基于循环神经网络（RNN）的无模型DRL代理也能表现出结构化的、类似计划的行为。研究提出了一种通用的分析框架，用于揭示DRL代理学习和行为中的丰富结构，强调了在AI、神经科学和认知科学之间建立桥梁的重要性。", "motivation": "随着任务和代理复杂度的增加，理解深度强化学习（DRL）代理的行为需要超越简单的奖励曲线比较。然而，DRL中的标准行为分析方法仍然不发达。本研究旨在填补这一空白，通过开发新的工具和方法来深入分析DRL代理的行为和神经动态。", "method": "研究在ForageWorld这一新颖、复杂、部分可观察的环境中，应用神经科学和动物行为学的工具对DRL代理进行行为分析。ForageWorld模拟了现实世界动物觅食的关键方面，包括稀疏、耗尽的资源点、捕食者威胁和空间扩展的竞技场。通过这一平台，研究结合行为和神经分析，揭示了代理的策略、记忆和计划行为。", "result": "研究发现，基于循环神经网络（RNN）的无模型DRL代理能够通过涌现的动态表现出结构化的、类似计划的行为，而不需要显式的记忆模块或世界模型。这一发现挑战了常见的假设，即模型免费代理无法进行计划。", "conclusion": "研究表明，通过神经行为学启发的工具分析DRL代理，可以揭示其学习和行为中的丰富结构，这些结构在传统的奖励曲线分析中是看不见的。研究提出了一个通用的分析框架，用于链接核心行为和表征特征到诊断方法，这一框架可广泛应用于各种任务和代理。随着代理变得更加复杂和自主，将神经科学、认知科学和AI结合起来，不仅对于理解代理行为至关重要，也对于确保安全对齐和最大化难以通过奖励衡量的理想行为至关重要。"}}
{"id": "2506.07116", "title": "BRIGHT+: Upgrading the BRIGHT Benchmark with MARCUS, a Multi-Agent RAG Clean-Up Suite", "authors": ["Liyang Chen", "Yujun Cai", "Jieqiong Dong", "Yiwei Wang"], "abstract": "Retrieval-Augmented Generation (RAG) systems require corpora that are both structurally clean and semantically coherent. BRIGHT is a recent and influential benchmark designed to evaluate complex multi-hop retrieval across diverse, high-reasoning domains. However, its practical effectiveness is limited by common web-crawled artifacts - such as content redundancy and semantic discontinuity - that impair retrieval accuracy and downstream reasoning. Notably, we find that such issues are concentrated in seven StackExchange-derived subdomains, while other domains (e.g., Coding and Theorem-based content) remain relatively clean.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "8 pages, 7 figures, 4 tables. Submitted to EMNLP 2025", "pdf_url": "https://arxiv.org/pdf/2506.07116.pdf", "abstract_url": "https://arxiv.org/abs/2506.07116", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文介绍了BRIGHT+，一个升级版的BRIGHT基准测试，通过引入MARCUS（一个多代理RAG清理套件）来解决原始BRIGHT基准测试中由于网络爬取导致的常见问题，如内容冗余和语义不连贯，特别是在七个StackExchange衍生子领域中。", "motivation": "BRIGHT基准测试用于评估跨多样高推理领域的复杂多跳检索，但其实际效果受到网络爬取常见问题（如内容冗余和语义不连贯）的限制，这些问题影响了检索准确性和下游推理。", "method": "通过引入MARCUS，一个多代理RAG清理套件，对BRIGHT基准测试进行升级，特别针对七个StackExchange衍生子领域中的问题进行清理。", "result": "发现这些问题主要集中在七个StackExchange衍生子领域，而其他领域（如编码和定理基础内容）相对干净。", "conclusion": "BRIGHT+通过MARCUS的引入，有效解决了原始BRIGHT基准测试中的问题，提高了其在复杂多跳检索评估中的实用性和准确性。"}}
{"id": "2506.07286", "title": "Multi-Step Guided Diffusion for Image Restoration on Edge Devices: Toward Lightweight Perception in Embodied AI", "authors": ["Aditya Chakravarty"], "abstract": "Diffusion models have shown remarkable flexibility for solving inverse problems without task-specific retraining. However, existing approaches such as Manifold Preserving Guided Diffusion (MPGD) apply only a single gradient update per denoising step, limiting restoration fidelity and robustness, especially in embedded or out-of-distribution settings. In this work, we introduce a multistep optimization strategy within each denoising timestep, significantly enhancing image quality, perceptual accuracy, and generalization. Our experiments on super-resolution and Gaussian deblurring demonstrate that increasing the number of gradient updates per step improves LPIPS and PSNR with minimal latency overhead. Notably, we validate this approach on a Jetson Orin Nano using degraded ImageNet and a UAV dataset, showing that MPGD, originally trained on face datasets, generalizes effectively to natural and aerial scenes. Our findings highlight MPGD's potential as a lightweight, plug-and-play restoration module for real-time visual perception in embodied AI agents such as drones and mobile robots.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Robotics (cs.RO)", "comments": "Accepted in CVPR 2025 Embodied AI Workshop", "pdf_url": "https://arxiv.org/pdf/2506.07286.pdf", "abstract_url": "https://arxiv.org/abs/2506.07286", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Machine Learning (cs.LG)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一种在边缘设备上用于图像恢复的多步引导扩散方法，旨在实现轻量级感知。通过在每个去噪时间步内引入多步优化策略，显著提高了图像质量、感知准确性和泛化能力。", "motivation": "解决现有方法如MPGD在每次去噪步骤中仅应用单一梯度更新，限制了恢复保真度和鲁棒性的问题，特别是在嵌入式或分布外设置中。", "method": "在每个去噪时间步内采用多步优化策略，以增强图像质量、感知准确性和泛化能力。", "result": "实验表明，增加每步的梯度更新次数可以以最小的延迟开销改善LPIPS和PSNR。在Jetson Orin Nano上验证了MPGD的有效性，显示其能够有效地泛化到自然和空中场景。", "conclusion": "MPGD有潜力作为轻量级、即插即用的恢复模块，用于实现无人机和移动机器人等嵌入式AI代理的实时视觉感知。"}}
{"id": "2506.07338", "title": "Hierarchical Scoring with 3D Gaussian Splatting for Instance Image-Goal Navigation", "authors": ["Yijie Deng", "Shuaihang Yuan", "Geeta Chandra Raju Bethala", "Anthony Tzes", "Yu-Shen Liu", "Yi Fang"], "abstract": "Instance Image-Goal Navigation (IIN) requires autonomous agents to identify and navigate to a target object or location depicted in a reference image captured from any viewpoint. While recent methods leverage powerful novel view synthesis (NVS) techniques, such as three-dimensional Gaussian splatting (3DGS), they typically rely on randomly sampling multiple viewpoints or trajectories to ensure comprehensive coverage of discriminative visual cues. This approach, however, creates significant redundancy through overlapping image samples and lacks principled view selection, substantially increasing both rendering and comparison overhead. In this paper, we introduce a novel IIN framework with a hierarchical scoring paradigm that estimates optimal viewpoints for target matching. Our approach integrates cross-level semantic scoring, utilizing CLIP-derived relevancy fields to identify regions with high semantic similarity to the target object class, with fine-grained local geometric scoring that performs precise pose estimation within promising regions. Extensive evaluations demonstrate that our method achieves state-of-the-art performance on simulated IIN benchmarks and real-world applicability.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.07338.pdf", "abstract_url": "https://arxiv.org/abs/2506.07338", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新颖的实例图像目标导航（IIN）框架，采用分层评分范式估计目标匹配的最佳视点，结合跨层次语义评分和局部几何评分，显著提高了导航效率和准确性。", "motivation": "解决实例图像目标导航中因随机采样视点或轨迹导致的冗余和缺乏原则性视点选择的问题，以减少渲染和比较的开销。", "method": "集成跨层次语义评分（利用CLIP衍生的相关性字段识别与目标对象类高度语义相似的区域）和细粒度局部几何评分（在有希望的区域执行精确姿态估计）。", "result": "在模拟的IIN基准测试中实现了最先进的性能，并展示了实际应用的可行性。", "conclusion": "提出的分层评分范式有效提高了实例图像目标导航的效率和准确性，为未来的研究和应用提供了新的方向。"}}
{"id": "2506.06964", "title": "Learning to Clarify by Reinforcement Learning Through Reward-Weighted Fine-Tuning", "authors": ["Subhojyoti Mukherjee", "Viet Dac Lai", "Raghavendra Addanki", "Ryan Rossi", "Seunghyun Yoon", "Trung Bui", "Anup Rao", "Jayakumar Subramanian", "Branislav Kveton"], "abstract": "Question answering (QA) agents automatically answer questions posed in natural language. In this work, we learn to ask clarifying questions in QA agents. The key idea in our method is to simulate conversations that contain clarifying questions and learn from them using reinforcement learning (RL). To make RL practical, we propose and analyze offline RL objectives that can be viewed as reward-weighted supervised fine-tuning (SFT) and easily optimized in large language models. Our work stands in a stark contrast to recently proposed methods, based on SFT and direct preference optimization, which have additional hyper-parameters and do not directly optimize rewards. We compare to these methods empirically and report gains in both optimized rewards and language quality.", "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": "39 pages", "pdf_url": "https://arxiv.org/pdf/2506.06964.pdf", "abstract_url": "https://arxiv.org/abs/2506.06964", "categories": ["Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种通过强化学习（RL）来训练问答（QA）代理学习如何提出澄清问题的方法。通过模拟包含澄清问题的对话，并利用离线RL目标进行学习，该方法在大型语言模型中实现了奖励加权的监督微调（SFT），与现有方法相比，在优化奖励和语言质量方面取得了更好的效果。", "motivation": "解决问答代理在自然语言处理中如何有效提出澄清问题的问题，以提高问答系统的交互质量和效率。", "method": "通过模拟包含澄清问题的对话，利用强化学习（RL）进行学习，特别是采用离线RL目标，即奖励加权的监督微调（SFT），在大型语言模型中实现高效优化。", "result": "与基于监督微调（SFT）和直接偏好优化的现有方法相比，该方法在优化奖励和语言质量方面表现更优。", "conclusion": "通过奖励加权的监督微调（SFT）方法，可以有效训练问答代理学习提出澄清问题，提高问答系统的交互质量和效率，且无需额外超参数，直接优化奖励。"}}
{"id": "2506.07194", "title": "Exploring Effective Strategies for Building a Customised GPT Agent for Coding Classroom Dialogues", "authors": ["Luwei Bai", "Dongkeun Han", "Sara Hennessy"], "abstract": "This study investigates effective strategies for developing a customised GPT agent to code classroom dialogue. While classroom dialogue is widely recognised as a crucial element of education, its analysis remains challenging due to the need for a nuanced understanding of dialogic functions and the labour-intensive nature of manual transcript coding. Recent advancements in large language models offer promising avenues for automating this process. However, existing studies predominantly focus on training large-scale models or evaluating pre-trained models with fixed codebooks, which are often not applicable or replicable for dialogue researchers working with small datasets or customised coding schemes. Using GPT-4's MyGPT agent as a case, this study evaluates its baseline performance in coding classroom dialogue with a human codebook and examines how performance varies with different example inputs through a variable control method. Through a design-based research approach, it identifies a set of practical strategies, based on MyGPT's unique features, for configuring effective agents with limited data. The findings suggest that, despite some limitations, a MyGPT agent developed with these strategies can serve as a useful coding assistant by generating coding suggestions.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "Draft technical report. 39 pages, 2 figures. Not yet submitted for publication. Update expected", "pdf_url": "https://arxiv.org/pdf/2506.07194.pdf", "abstract_url": "https://arxiv.org/abs/2506.07194", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本研究探讨了开发定制GPT代理以编码课堂对话的有效策略，通过评估GPT-4的MyGPT代理在编码课堂对话中的基线性能，并研究不同示例输入对性能的影响，提出了一套基于MyGPT独特特征的实用策略，以在有限数据下配置有效代理。", "motivation": "课堂对话分析因其对对话功能的微妙理解需求和手动转录编码的劳动密集型性质而具有挑战性。大型语言模型的进步为自动化这一过程提供了有希望的途径，但现有研究主要集中于训练大规模模型或使用固定代码本评估预训练模型，这对于使用小数据集或定制编码方案的对话研究者来说往往不适用或不可复制。", "method": "本研究使用GPT-4的MyGPT代理作为案例，通过变量控制方法评估其在编码课堂对话中的基线性能，并研究不同示例输入对性能的影响，采用基于设计的研究方法，识别出一套基于MyGPT独特特征的实用策略。", "result": "研究结果表明，尽管存在一些限制，但使用这些策略开发的MyGPT代理可以通过生成编码建议作为有用的编码助手。", "conclusion": "尽管存在限制，但通过特定策略开发的MyGPT代理可以作为编码课堂对话的有用工具，为对话研究者提供了一种在有限数据下配置有效代理的方法。"}}
{"id": "2506.07217", "title": "BIMgent: Towards Autonomous Building Modeling via Computer-use Agents", "authors": ["Zihan Deng", "Changyu Du", "Stavros Nousias", "André Borrmann"], "abstract": "Existing computer-use agents primarily focus on general-purpose desktop automation tasks, with limited exploration of their application in highly specialized domains. In particular, the 3D building modeling process in the Architecture, Engineering, and Construction (AEC) sector involves open-ended design tasks and complex interaction patterns within Building Information Modeling (BIM) authoring software, which has yet to be thoroughly addressed by current studies. In this paper, we propose BIMgent, an agentic framework powered by multimodal large language models (LLMs), designed to enable autonomous building model authoring via graphical user interface (GUI) operations. BIMgent automates the architectural building modeling process, including multimodal input for conceptual design, planning of software-specific workflows, and efficient execution of the authoring GUI actions. We evaluate BIMgent on real-world building modeling tasks, including both text-based conceptual design generation and reconstruction from existing building design. The design quality achieved by BIMgent was found to be reasonable. Its operations achieved a 32% success rate, whereas all baseline models failed to complete the tasks (0% success rate). Results demonstrate that BIMgent effectively reduces manual workload while preserving design intent, highlighting its potential for practical deployment in real-world architectural modeling scenarios.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "ICML 2025 Workshop on Computer Use Agents", "pdf_url": "https://arxiv.org/pdf/2506.07217.pdf", "abstract_url": "https://arxiv.org/abs/2506.07217", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "BIMgent是一个基于多模态大型语言模型（LLMs）的代理框架，旨在通过图形用户界面（GUI）操作实现自主建筑模型创作。", "motivation": "解决在建筑、工程和施工（AEC）领域中，3D建筑建模过程涉及开放式设计任务和复杂交互模式的问题，当前研究尚未充分探讨。", "method": "采用多模态大型语言模型（LLMs）驱动的代理框架，自动化建筑建模过程，包括概念设计的多模态输入、软件特定工作流的规划以及高效执行创作GUI操作。", "result": "BIMgent在实际建筑建模任务中表现良好，设计质量合理，操作成功率达到32%，而所有基线模型均未能完成任务（0%成功率）。", "conclusion": "BIMgent有效减少了手动工作量，同时保留了设计意图，展示了在实际建筑建模场景中部署的潜力。"}}
{"id": "2506.07223", "title": "LLM-Enhanced Rapid-Reflex Async-Reflect Embodied Agent for Real-Time Decision-Making in Dynamically Changing Environments", "authors": ["Yangqing Zheng", "Shunqi Mao", "Dingxin Zhang", "Weidong Cai"], "abstract": "In the realm of embodied intelligence, the evolution of large language models (LLMs) has markedly enhanced agent decision making. Consequently, researchers have begun exploring agent performance in dynamically changing high-risk scenarios, i.e., fire, flood, and wind scenarios in the HAZARD benchmark. Under these extreme conditions, the delay in decision making emerges as a crucial yet insufficiently studied issue. We propose a Time Conversion Mechanism (TCM) that translates inference delays in decision-making into equivalent simulation frames, thus aligning cognitive and physical costs under a single FPS-based metric. By extending HAZARD with Respond Latency (RL) and Latency-to-Action Ratio (LAR), we deliver a fully latency-aware evaluation protocol. Moreover, we present the Rapid-Reflex Async-Reflect Agent (RRARA), which couples a lightweight LLM-guided feedback module with a rule-based agent to enable immediate reactive behaviors and asynchronous reflective refinements in situ. Experiments on HAZARD show that RRARA substantially outperforms existing baselines in latency-sensitive scenarios.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "Accepted by the CVPR 2025 Embodied AI Workshop", "pdf_url": "https://arxiv.org/pdf/2506.07223.pdf", "abstract_url": "https://arxiv.org/abs/2506.07223", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种时间转换机制（TCM）和快速反射异步反射代理（RRARA），用于在动态变化的高风险环境中实现实时决策。通过将决策延迟转换为等效的模拟帧，并在HAZARD基准测试中引入响应延迟（RL）和延迟到行动比率（LAR），提出了一种完全考虑延迟的评估协议。RRARA结合了轻量级LLM引导的反馈模块和基于规则的代理，以在延迟敏感的场景中显著优于现有基线。", "motivation": "解决在动态变化的高风险场景（如火灾、洪水、风灾等）中，决策延迟这一关键但研究不足的问题。", "method": "提出了时间转换机制（TCM）来量化决策延迟，并开发了快速反射异步反射代理（RRARA），该代理结合了轻量级LLM引导的反馈模块和基于规则的代理，以实现即时反应行为和异步反射优化。", "result": "在HAZARD基准测试中，RRARA在延迟敏感的场景中显著优于现有基线。", "conclusion": "通过TCM和RRARA，本文为动态变化环境中的实时决策提供了一种有效的解决方案，特别是在高风险和延迟敏感的场景中。"}}
{"id": "2506.07450", "title": "Efficient Generation of Diverse Cooperative Agents with World Models", "authors": ["Yi Loo", "Akshunn Trivedi", "Malika Meghjani"], "abstract": "A major bottleneck in the training process for Zero-Shot Coordination (ZSC) agents is the generation of partner agents that are diverse in collaborative conventions. Current Cross-play Minimization (XPM) methods for population generation can be very computationally expensive and sample inefficient as the training objective requires sampling multiple types of trajectories. Each partner agent in the population is also trained from scratch, despite all of the partners in the population learning policies of the same coordination task. In this work, we propose that simulated trajectories from the dynamics model of an environment can drastically speed up the training process for XPM methods. We introduce XPM-WM, a framework for generating simulated trajectories for XPM via a learned World Model (WM). We show XPM with simulated trajectories removes the need to sample multiple trajectories. In addition, we show our proposed method can effectively generate partners with diverse conventions that match the performance of previous methods in terms of SP population training reward as well as training partners for ZSC agents. Our method is thus, significantly more sample efficient and scalable to a larger number of partners.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.07450.pdf", "abstract_url": "https://arxiv.org/abs/2506.07450", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为XPM-WM的框架，通过使用学习到的世界模型（WM）生成模拟轨迹，显著提高了零射击协调（ZSC）代理训练过程中多样合作代理生成的效率。", "motivation": "解决零射击协调（ZSC）代理训练中多样合作代理生成的计算成本高和样本效率低的问题。", "method": "引入XPM-WM框架，利用环境动态模型的模拟轨迹来加速跨游戏最小化（XPM）方法的训练过程。", "result": "XPM-WM方法无需采样多种轨迹，能有效生成具有多样惯例的合作代理，其性能与之前的方法相当，但在样本效率和可扩展性上显著更优。", "conclusion": "XPM-WM框架在生成多样合作代理方面更高效、更可扩展，为ZSC代理的训练提供了新的可能性。"}}
{"id": "2506.07399", "title": "MrM: Black-Box Membership Inference Attacks against Multimodal RAG Systems", "authors": ["Peiru Yang", "Jinhua Yin", "Haoran Zheng", "Xueying Bai", "Huili Wang", "Yufei Sun", "Xintian Li", "Shangguang Wang", "Yongfeng Huang", "Tao Qi"], "abstract": "Multimodal retrieval-augmented generation (RAG) systems enhance large vision-language models by integrating cross-modal knowledge, enabling their increasing adoption across real-world multimodal tasks. These knowledge databases may contain sensitive information that requires privacy protection. However, multimodal RAG systems inherently grant external users indirect access to such data, making them potentially vulnerable to privacy attacks, particularly membership inference attacks (MIAs). % Existing MIA methods targeting RAG systems predominantly focus on the textual modality, while the visual modality remains relatively underexplored. To bridge this gap, we propose MrM, the first black-box MIA framework targeted at multimodal RAG systems. It utilizes a multi-object data perturbation framework constrained by counterfactual attacks, which can concurrently induce the RAG systems to retrieve the target data and generate information that leaks the membership information. Our method first employs an object-aware data perturbation method to constrain the perturbation to key semantics and ensure successful retrieval. Building on this, we design a counterfact-informed mask selection strategy to prioritize the most informative masked regions, aiming to eliminate the interference of model self-knowledge and amplify attack efficacy. Finally, we perform statistical membership inference by modeling query trials to extract features that reflect the reconstruction of masked semantics from response patterns. Experiments on two visual datasets and eight mainstream commercial visual-language models (e.g., GPT-4o, Gemini-2) demonstrate that MrM achieves consistently strong performance across both sample-level and set-level evaluations, and remains robust under adaptive defenses.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.07399.pdf", "abstract_url": "https://arxiv.org/abs/2506.07399", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了MrM，首个针对多模态RAG系统的黑盒成员推理攻击框架，通过多目标数据扰动和反事实攻击，有效揭示系统成员信息，实验证明其在多种商业视觉语言模型上均表现优异。", "motivation": "多模态检索增强生成（RAG）系统在增强大型视觉语言模型的同时，可能泄露知识库中的敏感信息，现有成员推理攻击（MIA）方法主要针对文本模态，视觉模态研究不足。", "method": "MrM框架采用多目标数据扰动和反事实攻击，首先通过对象感知数据扰动确保成功检索，然后设计反事实指导的掩码选择策略，最后通过统计成员推理提取特征。", "result": "在两个视觉数据集和八种主流商业视觉语言模型上的实验表明，MrM在样本级和集合级评估中均表现优异，并能抵抗自适应防御。", "conclusion": "MrM框架有效揭示了多模态RAG系统的成员信息隐私风险，为未来隐私保护技术提供了重要参考。"}}
{"id": "2506.07037", "title": "KG2QA: Knowledge Graph-enhanced Retrieval-Augmented Generation for Communication Standards Question Answering", "authors": ["Zhongze Luo", "Weixuan Wan", "Qizhi Zheng", "Yanhong Bai", "Jingyun Sun", "Jian Wang", "Dan Wang"], "abstract": "There are many types of standards in the field of communication. The traditional consulting model has a long cycle and relies on the knowledge and experience of experts, making it difficult to meet the rapidly developing technological demands. This paper combines the fine-tuning of large language models with the construction of knowledge graphs to implement an intelligent consultation and question-answering system for communication standards. The experimental results show that after LoRA tuning on the constructed dataset of 6,587 questions and answers in the field of communication standards, Qwen2.5-7B-Instruct demonstrates outstanding professional capabilities in the field of communication standards on the test set. BLEU-4 rose from 18.8564 to 66.8993, and evaluation indicators such as ROUGE also increased significantly, outperforming the fine-tuning effect of the comparison model Llama-3-8B-Instruct. Based on the ontology framework containing 6 entity attributes and 10 relation attributes, a knowledge graph of the communication standard domain containing 13,906 entities and 13,524 relations was constructed, showing a relatively good query accuracy rate. The intelligent consultation and question-answering system enables the fine-tuned model on the server side to access the locally constructed knowledge graph and conduct graphical retrieval of key information first, which is conducive to improving the question-answering effect. The evaluation using DeepSeek as the Judge on the test set shows that our RAG framework enables the fine-tuned model to improve the scores at all five angles, with an average score increase of 2.26%. And combined with web services and API interfaces, it has achieved very good results in terms of interaction experience and back-end access, and has very good practical application value.", "subjects": "Computation and Language (cs.CL)", "comments": "23 pages", "pdf_url": "https://arxiv.org/pdf/2506.07037.pdf", "abstract_url": "https://arxiv.org/abs/2506.07037", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文结合大型语言模型的微调与知识图谱构建，实现了一个通信标准智能咨询与问答系统。通过LoRA调优和知识图谱增强的检索增强生成（RAG）框架，显著提升了问答效果和交互体验。", "motivation": "解决传统通信标准咨询周期长、依赖专家知识的问题，满足快速发展的技术需求。", "method": "结合大型语言模型的微调（如Qwen2.5-7B-Instruct）和知识图谱构建，采用RAG框架进行图形检索和信息增强。", "result": "在测试集上，BLEU-4从18.8564提升至66.8993，ROUGE等评价指标显著提高，平均分数提升2.26%。构建的知识图谱包含13,906个实体和13,524个关系，查询准确率较高。", "conclusion": "该系统在通信标准领域展现出卓越的专业能力和应用价值，通过结合Web服务和API接口，实现了良好的交互体验和后端接入。"}}
{"id": "2506.07042", "title": "Reasoning with RAGged events: RAG-Enhanced Event Knowledge Base Construction and reasoning with proof-assistants", "authors": ["Stergios Chatzikyriakidis"], "abstract": "Extracting structured computational representations of historical events from narrative text remains computationally expensive when constructed manually. While RDF/OWL reasoners enable graph-based reasoning, they are limited to fragments of first-order logic, preventing deeper temporal and semantic analysis. This paper addresses both challenges by developing automatic historical event extraction models using multiple LLMs (GPT-4, Claude, Llama 3.2) with three enhancement strategies: pure base generation, knowledge graph enhancement, and Retrieval-Augmented Generation (RAG). We conducted comprehensive evaluations using historical texts from Thucydides. Our findings reveal that enhancement strategies optimize different performance dimensions rather than providing universal improvements. For coverage and historical breadth, base generation achieves optimal performance with Claude and GPT-4 extracting comprehensive events. However, for precision, RAG enhancement improves coordinate accuracy and metadata completeness. Model architecture fundamentally determines enhancement sensitivity: larger models demonstrate robust baseline performance with incremental RAG improvements, while Llama 3.2 shows extreme variance from competitive performance to complete failure. We then developed an automated translation pipeline converting extracted RDF representations into Coq proof assistant specifications, enabling higher-order reasoning beyond RDF capabilities including multi-step causal verification, temporal arithmetic with BC dates, and formal proofs about historical causation. The Coq formalization validates that RAG-discovered event types represent legitimate domain-specific semantic structures rather than ontological violations.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.07042.pdf", "abstract_url": "https://arxiv.org/abs/2506.07042", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文通过开发自动历史事件提取模型，利用多种大型语言模型（GPT-4、Claude、Llama 3.2）和三种增强策略（纯基础生成、知识图谱增强、检索增强生成），解决了从叙述文本中提取结构化计算表示历史事件的计算成本高和RDF/OWL推理器仅限于一阶逻辑片段的问题。研究发现，增强策略优化了不同的性能维度，而非提供普遍改进。此外，开发了一个自动翻译管道，将提取的RDF表示转换为Coq证明助手规范，实现了超越RDF能力的高阶推理。", "motivation": "解决从叙述文本中手动构建历史事件的结构化计算表示的高成本问题，以及RDF/OWL推理器仅限于一阶逻辑片段，无法进行更深层次的时间和语义分析的局限性。", "method": "使用多种大型语言模型（GPT-4、Claude、Llama 3.2）和三种增强策略（纯基础生成、知识图谱增强、检索增强生成）开发自动历史事件提取模型，并进行全面评估。", "result": "增强策略优化了不同的性能维度，而非提供普遍改进。基础生成在覆盖范围和历史广度上达到最佳性能，而RAG增强在坐标精度和元数据完整性上有所提升。模型架构决定了增强敏感性：较大模型显示出稳健的基线性能，而Llama 3.2表现出从竞争性能到完全失败的极端差异。Coq形式化验证了RAG发现的事件类型代表合法的领域特定语义结构。", "conclusion": "通过自动翻译管道将提取的RDF表示转换为Coq证明助手规范，实现了超越RDF能力的高阶推理，包括多步因果验证、带有BC日期的时间算术和关于历史因果关系的正式证明。"}}
{"id": "2506.07106", "title": "Theorem-of-Thought: A Multi-Agent Framework for Abductive, Deductive, and Inductive Reasoning in Language Models", "authors": ["Samir Abdaljalil", "Hasan Kurban", "Khalid Qaraqe", "Erchin Serpedin"], "abstract": "Large language models (LLMs) have shown strong performance across natural language reasoning tasks, yet their reasoning processes remain brittle and difficult to interpret. Prompting techniques like Chain-of-Thought (CoT) enhance reliability by eliciting intermediate reasoning steps or aggregating multiple outputs. However, they lack mechanisms for enforcing logical structure and assessing internal coherence. We introduce Theorem-of-Thought (ToTh), a novel framework that models reasoning as collaboration among three parallel agents, each simulating a distinct mode of inference: abductive, deductive, and inductive. Each agent produces a reasoning trace, which is structured into a formal reasoning graph. To evaluate consistency, we apply Bayesian belief propagation guided by natural language inference (NLI), assigning confidence scores to each step. The most coherent graph is selected to derive the final answer. Experiments on symbolic (WebOfLies) and numerical (MultiArith) reasoning benchmarks show that ToTh consistently outperforms CoT, Self-Consistency, and CoT-Decoding across multiple LLMs, while producing interpretable and logically grounded reasoning chains. Our findings suggest a promising direction for building more robust and cognitively inspired LLM reasoning. The implementation is available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.07106.pdf", "abstract_url": "https://arxiv.org/abs/2506.07106", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了Theorem-of-Thought (ToTh)，一个新颖的多代理框架，旨在通过模拟三种不同的推理模式（溯因、演绎和归纳）来增强语言模型的推理能力。ToTh通过构建形式化的推理图并应用贝叶斯信念传播来评估一致性，从而选择最连贯的推理图来得出最终答案。实验表明，ToTh在多个LLM上 consistently outperforms CoT, Self-Consistency, and CoT-Decoding，同时产生可解释和逻辑基础的推理链。", "motivation": "大型语言模型（LLMs）在自然语言推理任务中表现出色，但其推理过程仍然脆弱且难以解释。现有的提示技术如Chain-of-Thought (CoT)通过引出中间推理步骤或聚合多个输出来提高可靠性，但缺乏强制执行逻辑结构和评估内部一致性的机制。", "method": "本文提出了Theorem-of-Thought (ToTh)框架，该框架将推理建模为三个并行代理之间的协作，每个代理模拟一种不同的推理模式：溯因、演绎和归纳。每个代理产生一个推理轨迹，这些轨迹被结构化为一个形式化的推理图。为了评估一致性，应用了基于自然语言推理（NLI）的贝叶斯信念传播，为每个步骤分配置信度分数。选择最连贯的图来得出最终答案。", "result": "在符号（WebOfLies）和数值（MultiArith）推理基准上的实验表明，ToTh在多个LLM上 consistently outperforms CoT, Self-Consistency, and CoT-Decoding，同时产生可解释和逻辑基础的推理链。", "conclusion": "我们的研究结果表明，ToTh为构建更健壮和认知启发的LLM推理提供了一个有希望的方向。"}}
{"id": "2506.07548", "title": "Curriculum Learning With Counterfactual Group Relative Policy Advantage For Multi-Agent Reinforcement Learning", "authors": ["Weiqiang Jin", "Hongyang Du", "Guizhong Liu", "Dong In Kim"], "abstract": "Multi-agent reinforcement learning (MARL) has achieved strong performance in cooperative adversarial tasks. However, most existing methods typically train agents against fixed opponent strategies and rely on such meta-static difficulty conditions, which limits their adaptability to changing environments and often leads to suboptimal policies. Inspired by the success of curriculum learning (CL) in supervised tasks, we propose a dynamic CL framework for MARL that employs an self-adaptive difficulty adjustment mechanism. This mechanism continuously modulates opponent strength based on real-time agent training performance, allowing agents to progressively learn from easier to more challenging scenarios. However, the dynamic nature of CL introduces instability due to nonstationary environments and sparse global rewards. To address this challenge, we develop a Counterfactual Group Relative Policy Advantage (CGRPA), which is tightly coupled with the curriculum by providing intrinsic credit signals that reflect each agent's impact under evolving task demands. CGRPA constructs a counterfactual advantage function that isolates individual contributions within group behavior, facilitating more reliable policy updates throughout the curriculum. CGRPA evaluates each agent's contribution through constructing counterfactual action advantage function, providing intrinsic rewards that enhance credit assignment and stabilize learning under non-stationary conditions. Extensive experiments demonstrate that our method improves both training stability and final performance, achieving competitive results against state-of-the-art methods. The code is available at", "subjects": "Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": "16 pages; 12figures", "pdf_url": "https://arxiv.org/pdf/2506.07548.pdf", "abstract_url": "https://arxiv.org/abs/2506.07548", "categories": ["Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种用于多智能体强化学习（MARL）的动态课程学习框架，通过自适应难度调整机制和反事实组相对策略优势（CGRPA）来提高训练稳定性和最终性能。", "motivation": "现有的多智能体强化学习方法通常在固定的对手策略下训练，这限制了它们对变化环境的适应性，并常常导致次优策略。", "method": "采用动态课程学习框架和反事实组相对策略优势（CGRPA），通过实时调整对手强度和提供内在信用信号来稳定学习过程。", "result": "实验表明，该方法在训练稳定性和最终性能上均有提升，与最先进的方法相比具有竞争力。", "conclusion": "提出的动态课程学习框架和CGRPA机制有效提高了多智能体强化学习在非平稳环境中的适应性和学习效率。"}}
{"id": "2506.07528", "title": "Coordinating Search-Informed Reasoning and Reasoning-Guided Search in Claim Verification", "authors": ["Qisheng Hu", "Quanyu Long", "Wenya Wang"], "abstract": "Multi-hop claim verification is inherently challenging, requiring multi-step reasoning to construct verification chains while iteratively searching for information to uncover hidden bridging facts. This process is fundamentally interleaved, as effective reasoning relies on dynamically retrieved evidence, while effective search demands reasoning to refine queries based on partial information. To achieve this, we propose Hierarchical Agent Reasoning and Information Search (HARIS), explicitly modeling the coordinated process of reasoning-driven searching and search-informed reasoning. HARIS consists of a high-level reasoning agent that focuses on constructing the main verification chain, generating factual questions when more information is needed, and a low-level search agent that iteratively retrieves more information, refining its search based on intermediate findings. This design allows each agent to specialize in its respective task, enhancing verification accuracy and interpretability. HARIS is trained using reinforcement learning with outcome-based rewards. Experimental results on the EX-FEVER and HOVER benchmarks demonstrate that HARIS achieves strong performance, greatly advancing multi-hop claim verification.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "19 pages, 9 figures", "pdf_url": "https://arxiv.org/pdf/2506.07528.pdf", "abstract_url": "https://arxiv.org/abs/2506.07528", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为HARIS的分层代理推理和信息搜索方法，用于多跳声明验证，通过协调推理驱动的搜索和搜索通知的推理，提高了验证的准确性和可解释性。", "motivation": "多跳声明验证是一个具有挑战性的任务，需要多步推理来构建验证链，同时迭代搜索信息以发现隐藏的桥接事实。这一过程本质上是交织的，因为有效的推理依赖于动态检索的证据，而有效的搜索则需要推理来基于部分信息细化查询。", "method": "HARIS方法包括一个专注于构建主要验证链的高级推理代理，当需要更多信息时生成事实问题，以及一个低级搜索代理，迭代检索更多信息，基于中间发现细化其搜索。这种方法使每个代理专注于其各自的任务。", "result": "在EX-FEVER和HOVER基准测试上的实验结果表明，HARIS实现了强大的性能，极大地推进了多跳声明验证的进展。", "conclusion": "HARIS通过明确建模推理驱动的搜索和搜索通知的推理的协调过程，不仅提高了多跳声明验证的准确性，还增强了其可解释性，为相关领域的研究提供了新的方向。"}}
{"id": "2506.07564", "title": "SAFEFLOW: A Principled Protocol for Trustworthy and Transactional Autonomous Agent Systems", "authors": ["Peiran Li", "Xinkai Zou", "Zhuohang Wu", "Ruifeng Li", "Shuo Xing", "Hanwen Zheng", "Zhikai Hu", "Yuping Wang", "Haoxi Li", "Qin Yuan", "Yingmo Zhang", "Zhengzhong Tu"], "abstract": "Recent advances in large language models (LLMs) and vision-language models (VLMs) have enabled powerful autonomous agents capable of complex reasoning and multi-modal tool use. Despite their growing capabilities, today's agent frameworks remain fragile, lacking principled mechanisms for secure information flow, reliability, and multi-agent coordination. In this work, we introduce SAFEFLOW, a new protocol-level framework for building trustworthy LLM/VLM-based agents. SAFEFLOW enforces fine-grained information flow control (IFC), precisely tracking provenance, integrity, and confidentiality of all the data exchanged between agents, tools, users, and environments. By constraining LLM reasoning to respect these security labels, SAFEFLOW prevents untrusted or adversarial inputs from contaminating high-integrity decisions. To ensure robustness in concurrent multi-agent settings, SAFEFLOW introduces transactional execution, conflict resolution, and secure scheduling over shared state, preserving global consistency across agents. We further introduce mechanisms, including write-ahead logging, rollback, and secure caches, that further enhance resilience against runtime errors and policy violations. To validate the performances, we built SAFEFLOWBENCH, a comprehensive benchmark suite designed to evaluate agent reliability under adversarial, noisy, and concurrent operational conditions. Extensive experiments demonstrate that agents built with SAFEFLOW maintain impressive task performance and security guarantees even in hostile environments, substantially outperforming state-of-the-art. Together, SAFEFLOW and SAFEFLOWBENCH lay the groundwork for principled, robust, and secure agent ecosystems, advancing the frontier of reliable autonomy.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.07564.pdf", "abstract_url": "https://arxiv.org/abs/2506.07564", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "SAFEFLOW是一个新的协议级框架，旨在构建基于LLM/VLM的可信自主代理，通过细粒度的信息流控制、事务执行和冲突解决等机制，确保多代理环境下的安全性和可靠性。", "motivation": "当前的自主代理框架在安全信息流、可靠性和多代理协调方面缺乏原则性机制，SAFEFLOW旨在解决这些问题。", "method": "SAFEFLOW通过实施细粒度的信息流控制（IFC）、事务执行、冲突解决和安全调度等技术，确保数据的安全性和全局一致性。", "result": "实验表明，使用SAFEFLOW构建的代理在敌对、嘈杂和并发操作条件下仍能保持出色的任务性能和安全性，显著优于现有技术。", "conclusion": "SAFEFLOW和SAFEFLOWBENCH为构建原则性、健壮和安全的代理生态系统奠定了基础，推动了可靠自主性的前沿发展。"}}
{"id": "2506.07636", "title": "SWE-Dev: Building Software Engineering Agents with Training and Inference Scaling", "authors": ["Haoran Wang", "Zhenyu Hou", "Yao Wei", "Jie Tang", "Yuxiao Dong"], "abstract": "Large language models (LLMs) have advanced rapidly from conversational problem solving to addressing real-world tasks involving tool use, such as software engineering (SWE). Recent LLM-powered toolkits, such as OpenAI Codex and Cursor, have offered end-to-end automation of the software development process. However, building effective SWE agents remains challenging due to the lack of high-quality training data and effective test cases. To address this issue, we present SWE-Dev, an SWE agent built upon open-source LLMs. First, we develop a robust pipeline to synthesize test cases for patch evaluation. Second, we scale up agent trajectories to construct the training data for building SWE-Dev. Experiments on the SWE-bench-Verified benchmark show that the SWE-Dev models can achieve top performance among all open SWE agents. Specifically, the success rates of the SWE-Dev 7B and 32B parameter models reach 23.4% and 36.6%, respectively, outperforming state-of-the-art open-source models. All code, models, and datasets are publicly available at", "subjects": "Artificial Intelligence (cs.AI)", "comments": "Accepted to Findings of ACL'25", "pdf_url": "https://arxiv.org/pdf/2506.07636.pdf", "abstract_url": "https://arxiv.org/abs/2506.07636", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了SWE-Dev，一个基于开源大型语言模型（LLMs）的软件工程（SWE）代理，旨在解决构建有效SWE代理时缺乏高质量训练数据和有效测试用例的问题。通过开发一个强大的管道来合成测试用例以评估补丁，并扩大代理轨迹以构建训练数据，SWE-Dev在SWE-bench-Verified基准测试中表现出色，7B和32B参数模型的成功率分别达到23.4%和36.6%，优于所有开源SWE代理。", "motivation": "构建有效的软件工程（SWE）代理面临的主要挑战是缺乏高质量的训练数据和有效的测试用例。", "method": "开发了一个强大的管道来合成测试用例以评估补丁，并扩大代理轨迹以构建训练数据，从而构建SWE-Dev代理。", "result": "在SWE-bench-Verified基准测试中，SWE-Dev 7B和32B参数模型的成功率分别达到23.4%和36.6%，优于所有开源SWE代理。", "conclusion": "SWE-Dev通过创新的数据合成和训练方法，显著提高了软件工程代理的性能，为开源社区提供了有价值的资源和工具。"}}
{"id": "2506.07672", "title": "MCPWorld: A Unified Benchmarking Testbed for API, GUI, and Hybrid Computer Use Agents", "authors": ["Yunhe Yan", "Shihe Wang", "Jiajun Du", "Yexuan Yang", "Yuxuan Shan", "Qichen Qiu", "Xianqing Jia", "Xinge Wang", "Xin Yuan", "Xu Han", "Mao Qin", "Yinxiao Chen", "Chen Peng", "Shangguang Wang", "Mengwei Xu"], "abstract": "(M)LLM-powered computer use agents (CUA) are emerging as a transformative technique to automate human-computer interaction. However, existing CUA benchmarks predominantly target GUI agents, whose evaluation methods are susceptible to UI changes and ignore function interactions exposed by application APIs, e.g., Model Context Protocol (MCP). To this end, we propose MCPWorld, the first automatic CUA testbed for API, GUI, and API-GUI hybrid agents. A key principle of MCPWorld is the use of \"white-box apps\", i.e., those with source code availability and can be revised/re-compiled as needed (e.g., adding MCP support), with two notable advantages:", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.07672.pdf", "abstract_url": "https://arxiv.org/abs/2506.07672", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "MCPWorld是一个统一的基准测试平台，专为API、GUI及API-GUI混合计算机使用代理设计，旨在通过‘白盒应用’支持自动测试，解决现有基准主要针对GUI代理且易受UI变化影响的问题。", "motivation": "现有的计算机使用代理(CUA)基准主要针对GUI代理，其评估方法易受用户界面(UI)变化的影响，且忽略了应用程序API（如模型上下文协议MCP）暴露的功能交互。为了解决这些问题，提出了MCPWorld。", "method": "MCPWorld采用‘白盒应用’（即源代码可用且可根据需要修改/重新编译的应用，如添加MCP支持）作为关键原则，支持API、GUI及API-GUI混合代理的自动测试。", "result": "MCPWorld是首个为API、GUI及API-GUI混合代理设计的自动CUA测试平台，具有通过‘白盒应用’实现灵活测试的显著优势。", "conclusion": "MCPWorld的提出填补了现有CUA基准测试的空白，特别是对于API和API-GUI混合代理的支持，为自动化人机交互提供了更全面和灵活的测试环境。"}}
{"id": "2506.07756", "title": "Agent Semantics, Semantic Spacetime, and Graphical Reasoning", "authors": ["Mark Burgess"], "abstract": "Some formal aspects of the Semantic Spacetime graph model are presented, with reference to its use for directed knowledge representations and process modelling. A finite $\\gamma(3,4)$ representation is defined to form a closed set of operations that can scale to any degree of semantic complexity. The Semantic Spacetime postulates bring predictability with minimal constraints to pathways in graphs. The ubiquitous appearance of absorbing states in any partial graph means that a graph process leaks information. The issue is closely associated with the issue of division by zero, which signals a loss of closure and the need for manual injection of remedial information. The Semantic Spacetime model (and its Promise Theory) origins help to clarify how such absorbing states are associated with boundary information where intentionality can enter.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.07756.pdf", "abstract_url": "https://arxiv.org/abs/2506.07756", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了语义时空图模型的一些形式方面，参考了其用于定向知识表示和过程建模的用途。定义了一个有限的γ(3,4)表示，形成了一组可以扩展到任何语义复杂度的封闭操作。语义时空假设为图中的路径带来了可预测性，且约束最小。任何部分图中普遍存在的吸收状态意味着图过程会泄漏信息。这个问题与除以零的问题密切相关，后者标志着闭合的丢失和需要手动注入补救信息。语义时空模型（及其承诺理论起源）有助于澄清这些吸收状态如何与可以输入意图的边界信息相关联。", "motivation": "解决在知识表示和过程建模中，如何预测和管理图中的路径以及处理信息泄漏和闭合丢失的问题。", "method": "使用语义时空图模型和有限的γ(3,4)表示，定义了一组可以扩展到任何语义复杂度的封闭操作。", "result": "语义时空假设为图中的路径带来了可预测性，且约束最小。吸收状态的普遍存在揭示了图过程会泄漏信息，与除以零的问题密切相关。", "conclusion": "语义时空模型及其承诺理论起源有助于理解吸收状态与边界信息的关联，其中可以输入意图，为解决信息泄漏和闭合丢失问题提供了新的视角。"}}
{"id": "2506.07807", "title": "A Proposal to Extend the Common Model of Cognition with Metacognition", "authors": ["John Laird", "Christian Lebiere", "Paul Rosenbloom", "Andrea Stocco", "Robert Wray"], "abstract": "The Common Model of Cognition (CMC) provides an abstract characterization of the structure and processing required by a cognitive architecture for human-like minds. We propose a unified approach to integrating metacognition within the CMC. We propose that metacognition involves reasoning over explicit representations of an agent's cognitive capabilities and processes in working memory. Our proposal exploits the existing cognitive capabilities of the CMC, making minimal extensions in the structure and information available within working memory. We provide examples of metacognition within our proposal.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.07807.pdf", "abstract_url": "https://arxiv.org/abs/2506.07807", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种将元认知整合到认知共同模型（CMC）中的统一方法，通过在工作记忆中推理代理的认知能力和过程的显式表示来实现。", "motivation": "解决如何在认知共同模型中有效地整合元认知，以更全面地模拟人类思维的问题。", "method": "利用CMC现有的认知能力，对工作记忆中的结构和信息进行最小扩展，提出元认知的统一整合方法。", "result": "提出了一个在CMC中实现元认知的具体方案，并通过实例说明了元认知在该方案中的应用。", "conclusion": "通过最小化扩展CMC的结构和信息，可以有效地整合元认知，为模拟人类思维提供了更全面的框架。"}}
{"id": "2506.07270", "title": "Question Answering under Temporal Conflict: Evaluating and Organizing Evolving Knowledge with LLMs", "authors": ["Atahan Özer", "Çağatay Yıldız"], "abstract": "Large language models (LLMs) exhibit remarkable capabilities in question answering and reasoning thanks to their extensive parametric memory. However, their knowledge is inherently limited by the scope of their pre-training data, while real-world information evolves continuously. Updating this knowledge typically requires costly and brittle re-training, or in-context learning (ICL), which becomes impractical at scale given the volume and volatility of modern information. Motivated by these limitations, we investigate how LLMs perform when exposed to temporal text corpora, or documents that reflect evolving knowledge over time, such as sports biographies where facts like a player's \"current team\" change year by year. To this end, we introduce two new benchmarks: Temporal Wiki, which captures factual drift across historical Wikipedia snapshots, and Unified Clark, which aggregates timestamped news articles to simulate real-world information accumulation. Our analysis reveals that LLMs often struggle to reconcile conflicting or outdated facts and can be misled when multiple versions of a fact appear in context. To address these issues, we propose a lightweight, agentic framework that incrementally builds a structured, external memory from source documents without requiring re-training. This knowledge organization strategy enables models to retrieve and reason over temporally filtered, relevant information at inference time. Empirically, our method outperforms ICL and RAG baselines across both benchmarks, especially on questions requiring more complex reasoning or integration of conflicting facts.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.07270.pdf", "abstract_url": "https://arxiv.org/abs/2506.07270", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic", "@RAG"], "AI": {"tldr": "大型语言模型（LLMs）在问答和推理方面表现出色，但其知识受限于预训练数据的范围，而现实世界的信息不断演变。本文研究了LLMs在处理反映知识随时间演变的文本语料时的表现，并引入了两个新基准：Temporal Wiki和Unified Clark。分析发现，LLMs在调和冲突或过时的事实方面存在困难。为此，作者提出了一个轻量级的代理框架，通过构建结构化的外部记忆来改进模型性能。", "motivation": "解决大型语言模型（LLMs）在处理随时间演变的实时信息时的局限性，特别是如何有效更新和整合新知识，避免因信息过时或冲突导致的误导。", "method": "引入了两个新基准（Temporal Wiki和Unified Clark）来评估LLMs处理时间文本语料的能力，并提出了一个轻量级的代理框架，该框架通过构建结构化的外部记忆来增量地组织和检索时间过滤的相关信息。", "result": "提出的方法在Temporal Wiki和Unified Clark基准上优于ICL和RAG基线，特别是在需要更复杂推理或整合冲突事实的问题上表现更佳。", "conclusion": "通过构建结构化的外部记忆，可以在不重新训练模型的情况下，有效提高LLMs处理时间演变信息的能力，为解决LLMs知识更新的挑战提供了新的思路。"}}
{"id": "2506.07982", "title": "$τ^2$-Bench: Evaluating Conversational Agents in a Dual-Control Environment", "authors": ["Victor Barres", "Honghua Dong", "Soham Ray", "Xujie Si", "Karthik Narasimhan"], "abstract": "Existing benchmarks for conversational AI agents simulate single-control environments, where only the AI agent can use tools to interact with the world, while the user remains a passive information provider. This differs from real-world scenarios like technical support, where users need to actively participate in modifying the state of the (shared) world. In order to address this gap, we introduce $\\tau^2$-bench, with four key contributions:", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.07982.pdf", "abstract_url": "https://arxiv.org/abs/2506.07982", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了$τ^2$-Bench，一个用于评估对话AI代理的双控制环境基准，旨在解决现有基准在模拟单控制环境中的不足，更贴近用户需要主动参与修改共享世界状态的真实场景。", "motivation": "现有的对话AI代理基准模拟的是单控制环境，其中只有AI代理可以使用工具与世界互动，而用户则被动提供信息。这与需要用户主动参与修改共享世界状态的真实场景（如技术支持）不同。", "method": "为了解决这一差距，作者引入了$τ^2$-bench，提出了四个关键贡献。", "result": "未提供具体结果，但$τ^2$-bench的引入旨在更准确地评估对话AI代理在双控制环境中的表现。", "conclusion": "$τ^2$-bench的提出填补了现有对话AI代理评估基准的不足，为更贴近真实场景的对话AI代理评估提供了新的方法和视角。"}}
{"id": "2506.07915", "title": "LUCIFER: Language Understanding and Context-Infused Framework for Exploration and Behavior Refinement", "authors": ["Dimitris Panagopoulos", "Adolfo Perrusquia", "Weisi Guo"], "abstract": "In dynamic environments, the rapid obsolescence of pre-existing environmental knowledge creates a gap between an agent's internal model and the evolving reality of its operational context. This disparity between prior and updated environmental valuations fundamentally limits the effectiveness of autonomous decision-making. To bridge this gap, the contextual bias of human domain stakeholders, who naturally accumulate insights through direct, real-time observation, becomes indispensable. However, translating their nuanced, and context-rich input into actionable intelligence for autonomous systems remains an open challenge. To address this, we propose LUCIFER (Language Understanding and Context-Infused Framework for Exploration and Behavior Refinement), a domain-agnostic framework that integrates a hierarchical decision-making architecture with reinforcement learning (RL) and large language models (LLMs) into a unified system. This architecture mirrors how humans decompose complex tasks, enabling a high-level planner to coordinate specialised sub-agents, each focused on distinct objectives and temporally interdependent actions. Unlike traditional applications where LLMs are limited to single role, LUCIFER integrates them in two synergistic roles: as context extractors, structuring verbal stakeholder input into domain-aware representations that influence decision-making through an attention space mechanism aligning LLM-derived insights with the agent's learning process, and as zero-shot exploration facilitators guiding the agent's action selection process during exploration. We benchmark various LLMs in both roles and demonstrate that LUCIFER improves exploration efficiency and decision quality, outperforming flat, goal-conditioned policies. Our findings show the potential of context-driven decision-making, where autonomous systems leverage human contextual knowledge for operational success.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Systems and Control (eess.SY)", "comments": "12 pages, 4 Figures, 3 Tables, submitted to the IEEE for possible publication", "pdf_url": "https://arxiv.org/pdf/2506.07915.pdf", "abstract_url": "https://arxiv.org/abs/2506.07915", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Systems and Control (eess.SY)"], "matching_keywords": ["agent"], "AI": {"tldr": "LUCIFER是一个领域无关的框架，结合了分层决策架构、强化学习和大型语言模型，旨在通过整合人类领域利益相关者的上下文知识，提高自主系统在动态环境中的探索效率和决策质量。", "motivation": "解决自主决策系统中，由于环境知识快速过时导致的内置模型与操作环境现实之间的差距问题，以及如何将人类领域利益相关者的丰富上下文输入转化为自主系统的可操作智能。", "method": "提出LUCIFER框架，该框架集成了分层决策架构、强化学习（RL）和大型语言模型（LLMs），通过LLMs在两种协同角色中的应用：作为上下文提取器，将口头利益相关者输入结构化为领域感知表示；以及作为零射探索促进者，指导代理在探索过程中的行动选择。", "result": "LUCIFER在探索效率和决策质量上优于传统的平面、目标条件策略，展示了上下文驱动决策的潜力。", "conclusion": "LUCIFER框架通过整合人类上下文知识和先进的机器学习技术，为自主系统在动态环境中的操作成功提供了新的可能性。"}}
{"id": "2506.08012", "title": "GUI-Reflection: Empowering Multimodal GUI Models with Self-Reflection Behavior", "authors": ["Penghao Wu", "Shengnan Ma", "Bo Wang", "Jiaheng Yu", "Lewei Lu", "Ziwei Liu"], "abstract": "Multimodal Large Language Models (MLLMs) have shown great potential in revolutionizing Graphical User Interface (GUI) automation. However, existing GUI models mostly rely on learning from nearly error-free offline trajectories, thus lacking reflection and error recovery capabilities. To bridge this gap, we propose GUI-Reflection, a novel framework that explicitly integrates self-reflection and error correction capabilities into end-to-end multimodal GUI models throughout dedicated training stages: GUI-specific pre-training, offline supervised fine-tuning (SFT), and online reflection tuning. GUI-reflection enables self-reflection behavior emergence with fully automated data generation and learning processes without requiring any human annotation. Specifically, 1) we first propose scalable data pipelines to automatically construct reflection and error correction data from existing successful trajectories. While existing GUI models mainly focus on grounding and UI understanding ability, we propose the GUI-Reflection Task Suite to learn and evaluate reflection-oriented abilities explicitly. 2) Furthermore, we built a diverse and efficient environment for online training and data collection of GUI models on mobile devices. 3) We also present an iterative online reflection tuning algorithm leveraging the proposed environment, enabling the model to continuously enhance its reflection and error correction abilities. Our framework equips GUI agents with self-reflection and correction capabilities, paving the way for more robust, adaptable, and intelligent GUI automation, with all data, models, environments, and tools to be released publicly.", "subjects": "Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2506.08012.pdf", "abstract_url": "https://arxiv.org/abs/2506.08012", "categories": ["Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了GUI-Reflection框架，通过自反思和错误纠正能力增强多模态GUI模型，实现了无需人工标注的全自动化数据生成和学习过程。", "motivation": "现有的GUI模型主要依赖于从几乎无错误的离线轨迹中学习，缺乏反思和错误恢复能力。", "method": "提出了一个包含GUI特定预训练、离线监督微调（SFT）和在线反思调谐的端到端多模态GUI模型训练框架，以及自动构建反思和错误纠正数据的数据管道。", "result": "开发了一个多样化和高效的环境，用于在移动设备上进行在线训练和数据收集，并提出了一种迭代的在线反思调谐算法。", "conclusion": "GUI-Reflection框架为GUI代理装备了自反思和纠正能力，为更强大、适应性更强和智能化的GUI自动化铺平了道路。"}}
{"id": "2506.07600", "title": "SceneRAG: Scene-level Retrieval-Augmented Generation for Video Understanding", "authors": ["Nianbo Zeng", "Haowen Hou", "Fei Richard Yu", "Si Shi", "Ying Tiffany He"], "abstract": "Despite recent advances in retrieval-augmented generation (RAG) for video understanding, effectively understanding long-form video content remains underexplored due to the vast scale and high complexity of video data. Current RAG approaches typically segment videos into fixed-length chunks, which often disrupts the continuity of contextual information and fails to capture authentic scene boundaries. Inspired by the human ability to naturally organize continuous experiences into coherent scenes, we present SceneRAG, a unified framework that leverages large language models to segment videos into narrative-consistent scenes by processing ASR transcripts alongside temporal metadata. SceneRAG further sharpens these initial boundaries through lightweight heuristics and iterative correction. For each scene, the framework fuses information from both visual and textual modalities to extract entity relations and dynamically builds a knowledge graph, enabling robust multi-hop retrieval and generation that account for long-range dependencies. Experiments on the LongerVideos benchmark, featuring over 134 hours of diverse content, confirm that SceneRAG substantially outperforms prior baselines, achieving a win rate of up to 72.5 percent on generation tasks.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.07600.pdf", "abstract_url": "https://arxiv.org/abs/2506.07600", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "SceneRAG是一个统一的框架，利用大型语言模型通过处理ASR转录本和时间元数据将视频分割成叙事一致的场景，并通过轻量级启发式和迭代校正进一步锐化这些初始边界。", "motivation": "解决长视频内容理解中的问题，由于视频数据的规模庞大和复杂性高，当前的检索增强生成（RAG）方法通常将视频分割成固定长度的块，这往往会破坏上下文信息的连续性，无法捕捉真实的场景边界。", "method": "利用大型语言模型处理ASR转录本和时间元数据来分割视频，通过轻量级启发式和迭代校正锐化场景边界，并融合视觉和文本模态的信息提取实体关系，动态构建知识图谱。", "result": "在LongerVideos基准测试中，SceneRAG显著优于之前的基线，生成任务的胜率高达72.5%。", "conclusion": "SceneRAG通过叙事一致的场景分割和多模态信息融合，有效地理解和生成长视频内容，为视频理解领域提供了新的解决方案。"}}
{"id": "2506.07611", "title": "DragNeXt: Rethinking Drag-Based Image Editing", "authors": ["Yuan Zhou", "Junbao Zhou", "Qingshan Xu", "Kesen Zhao", "Yuxuan Wang", "Hao Fei", "Richang Hong", "Hanwang Zhang"], "abstract": "Drag-Based Image Editing (DBIE), which allows users to manipulate images by directly dragging objects within them, has recently attracted much attention from the community. However, it faces two key challenges: (\\emph{\\textcolor{magenta}{i}}) point-based drag is often highly ambiguous and difficult to align with users' intentions; (\\emph{\\textcolor{magenta}{ii}}) current DBIE methods primarily rely on alternating between motion supervision and point tracking, which is not only cumbersome but also fails to produce high-quality results. These limitations motivate us to explore DBIE from a new perspective -- redefining it as deformation, rotation, and translation of user-specified handle regions. Thereby, by requiring users to explicitly specify both drag areas and types, we can effectively address the ambiguity issue. Furthermore, we propose a simple-yet-effective editing framework, dubbed \\textcolor{SkyBlue}{\\textbf{DragNeXt}}. It unifies DBIE as a Latent Region Optimization (LRO) problem and solves it through Progressive Backward Self-Intervention (PBSI), simplifying the overall procedure of DBIE while further enhancing quality by fully leveraging region-level structure information and progressive guidance from intermediate drag states. We validate \\textcolor{SkyBlue}{\\textbf{DragNeXt}} on our NextBench, and extensive experiments demonstrate that our proposed method can significantly outperform existing approaches. Code will be released on github.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.07611.pdf", "abstract_url": "https://arxiv.org/abs/2506.07611", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "DragNeXt提出了一种新的基于拖拽的图像编辑方法，通过将编辑任务重新定义为用户指定处理区域的变形、旋转和平移，有效解决了现有方法中的模糊性和操作繁琐问题。", "motivation": "现有的基于拖拽的图像编辑（DBIE）方法存在两个主要问题：点拖拽操作模糊难以准确反映用户意图，以及现有方法依赖交替进行运动监督和点跟踪，操作繁琐且效果不佳。", "method": "DragNeXt将DBIE重新定义为用户指定处理区域的变形、旋转和平移，并通过Latent Region Optimization（LRO）问题和Progressive Backward Self-Intervention（PBSI）方法简化编辑流程，同时利用区域级结构信息和中间拖拽状态的渐进指导提升编辑质量。", "result": "在NextBench上的大量实验表明，DragNeXt在性能上显著优于现有方法。", "conclusion": "DragNeXt通过重新定义拖拽编辑任务和引入LRO与PBSI，不仅简化了操作流程，还显著提升了编辑质量，为基于拖拽的图像编辑提供了新的解决方案。"}}
{"id": "2506.06286", "title": "Disentangling AI Alignment: A Structured Taxonomy Beyond Safety and Ethics", "authors": ["Kevin Baum"], "abstract": "Recent advances in AI research make it increasingly plausible that artificial agents with consequential real-world impact will soon operate beyond tightly controlled environments. Ensuring that these agents are not only safe but that they adhere to broader normative expectations is thus an urgent interdisciplinary challenge. Multiple fields -- notably AI Safety, AI Alignment, and Machine Ethics -- claim to contribute to this task. However, the conceptual boundaries and interrelations among these domains remain vague, leaving researchers without clear guidance in positioning their work.", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)", "comments": "accepted for the LNCS post proceedings of the AISoLA 2024 conference", "pdf_url": "https://arxiv.org/pdf/2506.06286.pdf", "abstract_url": "https://arxiv.org/abs/2506.06286", "categories": ["Computers and Society (cs.CY)", "Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种超越安全和伦理的结构化分类法，以解决人工智能对齐领域的概念模糊问题。", "motivation": "随着人工智能研究的进步，人工代理在非严格控制环境中的实际影响日益显著，确保这些代理不仅安全而且符合更广泛的规范期望成为一个紧迫的跨学科挑战。然而，AI安全、AI对齐和机器伦理等领域之间的概念界限和相互关系仍然模糊，研究人员在定位他们的工作时缺乏明确的指导。", "method": "提出了一种结构化的分类法，旨在澄清AI对齐领域内的概念界限和相互关系。", "result": "通过这种分类法，研究人员可以更清晰地理解和定位他们在AI对齐领域的工作。", "conclusion": "本文的结构化分类法为AI对齐领域提供了一个清晰的框架，有助于指导未来的研究和实践，确保人工代理的安全和规范性。"}}
{"id": "2506.06291", "title": "Improvement of Optimization using Learning Based Models in Mixed Integer Linear Programming Tasks", "authors": ["Xiaoke Wang", "Batuhan Altundas", "Zhaoxin Li", "Aaron Zhao", "Matthew Gombolay"], "abstract": "Mixed Integer Linear Programs (MILPs) are essential tools for solving planning and scheduling problems across critical industries such as construction, manufacturing, and logistics. However, their widespread adoption is limited by long computational times, especially in large-scale, real-time scenarios. To address this, we present a learning-based framework that leverages Behavior Cloning (BC) and Reinforcement Learning (RL) to train Graph Neural Networks (GNNs), producing high-quality initial solutions for warm-starting MILP solvers in Multi-Agent Task Allocation and Scheduling Problems. Experimental results demonstrate that our method reduces optimization time and variance compared to traditional techniques while maintaining solution quality and feasibility.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "4 pages, 4 figures", "pdf_url": "https://arxiv.org/pdf/2506.06291.pdf", "abstract_url": "https://arxiv.org/abs/2506.06291", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于学习的方法，通过行为克隆和强化学习训练图神经网络，为混合整数线性规划任务提供高质量的初始解，以减少优化时间和方差。", "motivation": "混合整数线性规划在关键行业如建筑、制造和物流中的规划与调度问题中至关重要，但其在大规模实时场景中的长计算时间限制了广泛应用。", "method": "使用行为克隆(BC)和强化学习(RL)训练图神经网络(GNNs)，为多智能体任务分配和调度问题中的混合整数线性规划求解器提供初始解。", "result": "实验结果表明，该方法在保持解质量和可行性的同时，减少了优化时间和与传统技术相比的方差。", "conclusion": "提出的学习框架有效提高了混合整数线性规划求解的效率，特别是在大规模实时应用中，具有重要的实际意义。"}}
{"id": "2506.07510", "title": "DeRAGEC: Denoising Named Entity Candidates with Synthetic Rationale for ASR Error Correction", "authors": ["Solee Im", "Wonjun Lee", "Jinmyeong An", "Yunsu Kim", "Jungseul Ok", "Gary Geunbae Lee"], "abstract": "We present DeRAGEC, a method for improving Named Entity (NE) correction in Automatic Speech Recognition (ASR) systems. By extending the Retrieval-Augmented Generative Error Correction (RAGEC) framework, DeRAGEC employs synthetic denoising rationales to filter out noisy NE candidates before correction. By leveraging phonetic similarity and augmented definitions, it refines noisy retrieved NEs using in-context learning, requiring no additional training. Experimental results on CommonVoice and STOP datasets show significant improvements in Word Error Rate (WER) and NE hit ratio, outperforming baseline ASR and RAGEC methods. Specifically, we achieved a 28% relative reduction in WER compared to ASR without postprocessing. Our source code is publicly available at:", "subjects": "Computation and Language (cs.CL)", "comments": "ACL2025 Findings", "pdf_url": "https://arxiv.org/pdf/2506.07510.pdf", "abstract_url": "https://arxiv.org/abs/2506.07510", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "DeRAGEC是一种改进自动语音识别(ASR)系统中命名实体(NE)校正的方法，通过合成去噪理由过滤噪声NE候选，无需额外训练即可通过语音相似性和增强定义优化检索到的NEs。在CommonVoice和STOP数据集上的实验结果显示，其在词错误率(WER)和NE命中率上显著优于基线ASR和RAGEC方法。", "motivation": "解决自动语音识别(ASR)系统中命名实体(NE)校正的问题，特别是在存在噪声NE候选的情况下，提高校正的准确性和效率。", "method": "扩展了检索增强生成错误校正(RAGEC)框架，采用合成去噪理由和上下文学习来过滤和优化噪声NE候选，利用语音相似性和增强定义进行细化。", "result": "在CommonVoice和STOP数据集上实现了词错误率(WER)相对于未经后处理的ASR系统28%的相对减少，同时在NE命中率上也有显著提升。", "conclusion": "DeRAGEC通过合成去噪理由和上下文学习有效提高了ASR系统中命名实体校正的准确性，且无需额外训练，为ASR系统的后处理提供了新的解决方案。"}}
{"id": "2506.07583", "title": "Beyond the Sentence: A Survey on Context-Aware Machine Translation with Large Language Models", "authors": ["Ramakrishna Appicharla", "Baban Gain", "Santanu Pal", "Asif Ekbal"], "abstract": "Despite the popularity of the large language models (LLMs), their application to machine translation is relatively underexplored, especially in context-aware settings. This work presents a literature review of context-aware translation with LLMs. The existing works utilise prompting and fine-tuning approaches, with few focusing on automatic post-editing and creating translation agents for context-aware machine translation. We observed that the commercial LLMs (such as ChatGPT and Tower LLM) achieved better results than the open-source LLMs (such as Llama and Bloom LLMs), and prompt-based approaches serve as good baselines to assess the quality of translations. Finally, we present some interesting future directions to explore.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.07583.pdf", "abstract_url": "https://arxiv.org/abs/2506.07583", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文综述了大型语言模型（LLMs）在上下文感知机器翻译中的应用现状，探讨了提示和微调方法，并指出了开源与商业LLMs在翻译质量上的差异及未来研究方向。", "motivation": "尽管大型语言模型（LLMs）非常流行，但它们在机器翻译中的应用，尤其是在上下文感知设置中的应用，尚未得到充分探索。本文旨在填补这一研究空白。", "method": "本文通过文献综述的方法，分析了使用提示和微调方法进行上下文感知翻译的现有工作，并比较了商业和开源LLMs的表现。", "result": "研究发现，商业LLMs（如ChatGPT和Tower LLM）在翻译质量上优于开源LLMs（如Llama和Bloom LLMs），提示方法可作为评估翻译质量的良好基线。", "conclusion": "本文不仅总结了上下文感知机器翻译的现状，还提出了未来研究的几个有趣方向，为该领域的进一步发展提供了参考。"}}
{"id": "2506.06325", "title": "Evolutionary model for energy trading in community microgrids using Hawk-Dove strategies", "authors": ["Viorica Rozina Chifu", "Tudor Cioara", "Cristina Bianca Pop", "Ionut Anghel"], "abstract": "This paper proposes a decentralized model of energy cooperation between microgrids, in which decisions are made locally, at the level of the microgrid community. Each microgrid is modeled as an autonomous agent that adopts a Hawk or Dove strategy, depending on the level of energy stored in the battery and its role in the energy trading process. The interactions between selling and buying microgrids are modeled through an evolutionary algorithm. An individual in the algorithm population is represented as an energy trading matrix that encodes the amounts of energy traded between the selling and buying microgrids. The population evolution is achieved by recombination and mutation operators. Recombination uses a specialized operator for matrix structures, and mutation is applied to the matrix elements according to a Gaussian distribution. The evaluation of an individual is made with a multi-criteria fitness function that considers the seller profit, the degree of energy stability at the community level, penalties for energy imbalance at the community level and for the degradation of microgrids batteries. The method was tested on a simulated scenario with 100 microgrids, each with its own selling and buying thresholds, to reflect a realistic environment with variable storage characteristics of microgrids batteries. By applying the algorithm on this scenario, 95 out of the 100 microgrids reached a stable energy state. This result confirms the effectiveness of the proposed model in achieving energy balance both at the individual level, for each microgrid, and at the level of the entire community.", "subjects": "Neural and Evolutionary Computing (cs.NE); Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.06325.pdf", "abstract_url": "https://arxiv.org/abs/2506.06325", "categories": ["Neural and Evolutionary Computing (cs.NE)", "Artificial Intelligence (cs.AI)", "Computer Science and Game Theory (cs.GT)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于鹰鸽策略的社区微电网能源交易进化模型，通过分散决策和进化算法实现能源平衡。", "motivation": "解决微电网社区中能源交易的分散决策问题，实现个体和社区层面的能源平衡。", "method": "使用进化算法，将每个微电网建模为自主代理，采用鹰或鸽策略，通过重组和变异操作进化能源交易矩阵。", "result": "在100个微电网的模拟场景中，95个达到了稳定能源状态，验证了模型的有效性。", "conclusion": "提出的模型在个体和社区层面均能有效实现能源平衡，适用于具有可变存储特性的微电网环境。"}}
{"id": "2506.07617", "title": "Vuyko Mistral: Adapting LLMs for Low-Resource Dialectal Translation", "authors": ["Roman Kyslyi", "Yuliia Maksymiuk", "Ihor Pysmennyi"], "abstract": "In this paper we introduce the first effort to adapt large language models (LLMs) to the Ukrainian dialect (in our case Hutsul), a low-resource and morphologically complex dialect spoken in the Carpathian Highlands. We created a parallel corpus of 9852 dialect-to-standard Ukrainian sentence pairs and a dictionary of 7320 dialectal word mappings. We also addressed data shortage by proposing an advanced Retrieval-Augmented Generation (RAG) pipeline to generate synthetic parallel translation pairs, expanding the corpus with 52142 examples. We have fine-tuned multiple open-source LLMs using LoRA and evaluated them on a standard-to-dialect translation task, also comparing with few-shot GPT-4o translation. In the absence of human annotators, we adopt a multi-metric evaluation strategy combining BLEU, chrF++, TER, and LLM-based judgment (GPT-4o). The results show that even small(7B) finetuned models outperform zero-shot baselines such as GPT-4o across both automatic and LLM-evaluated metrics. All data, models, and code are publicly released at:", "subjects": "Computation and Language (cs.CL)", "comments": "Preprint. Will be published at Proceedings of the Fourth Ukrainian Natural Language Processing Workshop (UNLP)", "pdf_url": "https://arxiv.org/pdf/2506.07617.pdf", "abstract_url": "https://arxiv.org/abs/2506.07617", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了首个将大型语言模型（LLMs）适应于乌克兰低资源方言（Hutsul）的努力，创建了9852句方言到标准乌克兰语的平行语料库和7320个方言词汇映射词典，并通过高级检索增强生成（RAG）管道生成合成平行翻译对，扩展了语料库。通过LoRA微调多个开源LLMs，并在标准到方言翻译任务中评估，结果显示即使小型（7B）微调模型在自动和LLM评估指标上也优于零-shot基线如GPT-4o。", "motivation": "解决低资源、形态复杂的乌克兰方言（Hutsul）的翻译问题，填补该领域的研究空白。", "method": "创建平行语料库和方言词典，使用高级检索增强生成（RAG）管道生成合成数据，通过LoRA微调多个开源LLMs，并采用多指标评估策略。", "result": "小型（7B）微调模型在自动和LLM评估指标上优于零-shot基线如GPT-4o。", "conclusion": "通过特定方法和技术的应用，可以有效提升低资源方言翻译的性能，为类似语言的翻译研究提供了有价值的参考和资源。"}}
{"id": "2506.06335", "title": "FinBERT2: A Specialized Bidirectional Encoder for Bridging the Gap in Finance-Specific Deployment of Large Language Models", "authors": ["Xuan Xu", "Fufang Wen", "Beilin Chu", "Zhibing Fu", "Qinhong Lin", "Jiaqi Liu", "Binjie Fei", "Zhongliang Yang", "Linna Zhou", "Yu Li"], "abstract": "In natural language processing (NLP), the focus has shifted from encoder-only tiny language models like BERT to decoder-only large language models(LLMs) such as GPT-3. However, LLMs' practical application in the financial sector has revealed three limitations: (1) LLMs often perform worse than fine-tuned BERT on discriminative tasks despite costing much higher computational resources, such as market sentiment analysis in financial reports; (2) Application on generative tasks heavily relies on retrieval augmented generation (RAG) methods to provide current and specialized information, with general retrievers showing suboptimal performance on domain-specific retrieval tasks; (3) There are additional inadequacies in other feature-based scenarios, such as topic modeling. We introduce FinBERT2, a specialized bidirectional encoder pretrained on a high-quality, financial-specific corpus of 32b tokens. This represents the largest known Chinese financial pretraining corpus for models of this parameter size. As a better backbone, FinBERT2 can bridge the gap in the financial-specific deployment of LLMs through the following achievements: (1) Discriminative fine-tuned models (Fin-Labelers) outperform other (Fin)BERT variants by 0.4%-3.3% and leading LLMs by 9.7%-12.3% on average across five financial classification tasks. (2) Contrastive fine-tuned models (Fin-Retrievers) outperform both open-source (e.g., +6.8\\% avg improvement over BGE-base-zh) and proprietary (e.g., +4.2\\% avg improvement over OpenAI's text-embedding-3-large) embedders across five financial retrieval tasks; (3) Building on FinBERT2 variants, we construct the Fin-TopicModel, which enables superior clustering and topic representation for financial titles. Our work revisits financial BERT models through comparative analysis with contemporary LLMs and offers practical insights for effectively utilizing FinBERT in the LLMs era.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.06335.pdf", "abstract_url": "https://arxiv.org/abs/2506.06335", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)", "Computational Engineering, Finance, and Science (cs.CE)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "FinBERT2是一种专门为金融领域设计的双向编码器，旨在解决大型语言模型(LLMs)在金融应用中存在的性能不足和资源消耗高的问题。通过在高质量金融语料上预训练，FinBERT2在多项金融任务中表现出色，超越了现有的BERT变体和领先的LLMs。", "motivation": "大型语言模型(LLMs)在金融领域的实际应用中存在三个主要限制：在判别任务上性能不如微调的BERT模型，生成任务依赖检索增强生成(RAG)方法，以及在特征基础场景如主题建模中的不足。FinBERT2旨在解决这些问题。", "method": "FinBERT2是一个在32b tokens的高质量金融特定语料上预训练的双向编码器。作为更好的基础模型，它通过微调在金融分类、检索和主题建模任务中实现了卓越性能。", "result": "FinBERT2在五项金融分类任务中平均超越其他(Fin)BERT变体0.4%-3.3%，领先LLMs 9.7%-12.3%；在金融检索任务中超越开源和专有嵌入器；构建的Fin-TopicModel在金融标题聚类和主题表示上表现优异。", "conclusion": "FinBERT2通过比较分析与当代LLMs，重新审视了金融BERT模型，并为在LLMs时代有效利用FinBERT提供了实用见解。"}}
{"id": "2506.07778", "title": "Language-Vision Planner and Executor for Text-to-Visual Reasoning", "authors": ["Yichang Xu", "Gaowen Liu", "Ramana Rao Kompella", "Sihao Hu", "Tiansheng Huang", "Fatih Ilhan", "Selim Furkan Tekin", "Zachary Yahn", "Ling Liu"], "abstract": "The advancement in large language models (LLMs) and large vision models has fueled the rapid progress in multi-modal visual-text reasoning capabilities. However, existing vision-language models (VLMs) to date suffer from generalization performance. Inspired by recent development in LLMs for visual reasoning, this paper presents VLAgent, an AI system that can create a step-by-step visual reasoning plan with an easy-to-understand script and execute each step of the plan in real time by integrating planning script with execution verifications via an automated process supported by VLAgent. In the task planning phase, VLAgent fine-tunes an LLM through in-context learning to generate a step-by-step planner for each user-submitted text-visual reasoning task. During the plan execution phase, VLAgent progressively refines the composition of neuro-symbolic executable modules to generate high-confidence reasoning results. VLAgent has three unique design characteristics: First, we improve the quality of plan generation through in-context learning, improving logic reasoning by reducing erroneous logic steps, incorrect programs, and LLM hallucinations. Second, we design a syntax-semantics parser to identify and correct additional logic errors of the LLM-generated planning script prior to launching the plan executor. Finally, we employ the ensemble method to improve the generalization performance of our step-executor. Extensive experiments with four visual reasoning benchmarks (GQA, MME, NLVR2, VQAv2) show that VLAgent achieves significant performance enhancement for multimodal text-visual reasoning applications, compared to the exiting representative VLMs and LLM based visual composition approaches like ViperGPT and VisProg, thanks to the novel optimization modules of VLAgent back-engine (SS-Parser, Plan Repairer, Output Verifiers). Code and data will be made available upon paper acceptance.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.07778.pdf", "abstract_url": "https://arxiv.org/abs/2506.07778", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了VLAgent，一个结合大型语言模型和视觉模型的多模态视觉-文本推理系统，通过分步规划和执行验证提高推理性能。", "motivation": "解决现有视觉语言模型在泛化性能上的不足，提升多模态视觉-文本推理的准确性和效率。", "method": "VLAgent通过上下文学习微调LLM生成分步规划器，设计语法-语义解析器修正逻辑错误，并采用集成方法提升执行器的泛化性能。", "result": "在四个视觉推理基准测试中，VLAgent相比现有视觉语言模型和基于LLM的视觉组合方法，如ViperGPT和VisProg，实现了显著的性能提升。", "conclusion": "VLAgent通过其独特的优化模块（如SS-Parser、Plan Repairer、Output Verifiers）有效提升了多模态文本-视觉推理应用的性能，展示了其在复杂视觉推理任务中的潜力。"}}
{"id": "2506.06339", "title": "Optimizing RAG Pipelines for Arabic: A Systematic Analysis of Core Components", "authors": ["Jumana Alsubhi", "Mohammad D. Alahmadi", "Ahmed Alhusayni", "Ibrahim Aldailami", "Israa Hamdine", "Ahmad Shabana", "Yazeed Iskandar", "Suhayb Khayyat"], "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a powerful architecture for combining the precision of retrieval systems with the fluency of large language models. While several studies have investigated RAG pipelines for high-resource languages, the optimization of RAG components for Arabic remains underexplored. This study presents a comprehensive empirical evaluation of state-of-the-art RAG components-including chunking strategies, embedding models, rerankers, and language models-across a diverse set of Arabic datasets. Using the RAGAS framework, we systematically compare performance across four core metrics: context precision, context recall, answer faithfulness, and answer relevancy. Our experiments demonstrate that sentence-aware chunking outperforms all other segmentation methods, while BGE-M3 and Multilingual-E5-large emerge as the most effective embedding models. The inclusion of a reranker (bge-reranker-v2-m3) significantly boosts faithfulness in complex datasets, and Aya-8B surpasses StableLM in generation quality. These findings provide critical insights for building high-quality Arabic RAG pipelines and offer practical guidelines for selecting optimal components across different document types.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.06339.pdf", "abstract_url": "https://arxiv.org/abs/2506.06339", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文通过RAGAS框架对阿拉伯语的RAG管道核心组件进行了系统评估，包括分块策略、嵌入模型、重新排序器和语言模型，发现句子感知分块、BGE-M3和Multilingual-E5-large嵌入模型、bge-reranker-v2-m3重新排序器以及Aya-8B语言模型在不同阿拉伯数据集上表现最佳，为构建高质量的阿拉伯RAG管道提供了重要见解和实用指南。", "motivation": "尽管已有研究探讨了高资源语言的RAG管道优化，但阿拉伯语的RAG组件优化仍未被充分探索。本研究旨在填补这一空白，通过全面评估阿拉伯语RAG管道的核心组件，为构建高质量的阿拉伯RAG管道提供依据。", "method": "使用RAGAS框架，对包括分块策略、嵌入模型、重新排序器和语言模型在内的RAG核心组件进行了系统比较，评估了四种核心指标：上下文精确度、上下文召回率、答案忠实度和答案相关性。", "result": "实验结果表明，句子感知分块在所有分割方法中表现最佳；BGE-M3和Multilingual-E5-large是最有效的嵌入模型；bge-reranker-v2-m3重新排序器在复杂数据集中显著提高了忠实度；Aya-8B在生成质量上优于StableLM。", "conclusion": "本研究为构建高质量的阿拉伯RAG管道提供了关键见解，并为不同文档类型选择最优组件提供了实用指南。"}}
{"id": "2506.07785", "title": "Re-ranking Reasoning Context with Tree Search Makes Large Vision-Language Models Stronger", "authors": ["Qi Yang", "Chenghao Zhang", "Lubin Fan", "Kun Ding", "Jieping Ye", "Shiming Xiang"], "abstract": "Recent advancements in Large Vision Language Models (LVLMs) have significantly improved performance in Visual Question Answering (VQA) tasks through multimodal Retrieval-Augmented Generation (RAG). However, existing methods still face challenges, such as the scarcity of knowledge with reasoning examples and erratic responses from retrieved knowledge. To address these issues, in this study, we propose a multimodal RAG framework, termed RCTS, which enhances LVLMs by constructing a Reasoning Context-enriched knowledge base and a Tree Search re-ranking method. Specifically, we introduce a self-consistent evaluation mechanism to enrich the knowledge base with intrinsic reasoning patterns. We further propose a Monte Carlo Tree Search with Heuristic Rewards (MCTS-HR) to prioritize the most relevant examples. This ensures that LVLMs can leverage high-quality contextual reasoning for better and more consistent responses. Extensive experiments demonstrate that our framework achieves state-of-the-art performance on multiple VQA datasets, significantly outperforming In-Context Learning (ICL) and Vanilla-RAG methods. It highlights the effectiveness of our knowledge base and re-ranking method in improving LVLMs. Our code is available at", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "ICML 2025 Spotlight. 22 pages, 16 figures", "pdf_url": "https://arxiv.org/pdf/2506.07785.pdf", "abstract_url": "https://arxiv.org/abs/2506.07785", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种名为RCTS的多模态RAG框架，通过构建富含推理上下文的知识库和树搜索重新排序方法，增强了大型视觉语言模型（LVLMs）在视觉问答（VQA）任务中的表现。", "motivation": "现有的多模态检索增强生成（RAG）方法在视觉问答任务中面临知识推理示例稀缺和检索知识响应不稳定的挑战。", "method": "提出了RCTS框架，包括一个自洽的评价机制来丰富知识库的内在推理模式，以及一个带有启发式奖励的蒙特卡洛树搜索（MCTS-HR）方法来优先考虑最相关的示例。", "result": "大量实验表明，该框架在多个VQA数据集上实现了最先进的性能，显著优于上下文学习（ICL）和Vanilla-RAG方法。", "conclusion": "研究强调了知识库和重新排序方法在提升LVLMs性能方面的有效性，为未来的研究提供了有价值的参考。"}}
{"id": "2506.07671", "title": "GaRAGe: A Benchmark with Grounding Annotations for RAG Evaluation", "authors": ["Ionut-Teodor Sorodoc", "Leonardo F. R. Ribeiro", "Rexhina Blloshmi", "Christopher Davis", "Adrià de Gispert"], "abstract": "We present GaRAGe, a large RAG benchmark with human-curated long-form answers and annotations of each grounding passage, allowing a fine-grained evaluation of whether LLMs can identify relevant grounding when generating RAG answers. Our benchmark contains 2366 questions of diverse complexity, dynamism, and topics, and includes over 35K annotated passages retrieved from both private document sets and the Web, to reflect real-world RAG use cases. This makes it an ideal test bed to evaluate an LLM's ability to identify only the relevant information necessary to compose a response, or provide a deflective response when there is insufficient information. Evaluations of multiple state-of-the-art LLMs on GaRAGe show that the models tend to over-summarise rather than (a) ground their answers strictly on the annotated relevant passages (reaching at most a Relevance-Aware Factuality Score of 60%), or (b) deflect when no relevant grounding is available (reaching at most 31% true positive rate in deflections). The F1 in attribution to relevant sources is at most 58.9%, and we show that performance is particularly reduced when answering time-sensitive questions and when having to draw knowledge from sparser private grounding sources.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "ACL 2025 (Findings)", "pdf_url": "https://arxiv.org/pdf/2506.07671.pdf", "abstract_url": "https://arxiv.org/abs/2506.07671", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "介绍了GaRAGe，一个带有基础注释的大型RAG基准，用于评估LLMs在生成RAG答案时是否能识别相关基础。", "motivation": "解决现有RAG评估基准在细粒度评估LLMs识别相关基础信息能力上的不足。", "method": "构建包含2366个多样化问题的基准，并标注超过35K的基础段落，以反映真实世界的RAG使用场景。", "result": "评估显示，最先进的LLMs倾向于过度总结而非严格基于相关段落（最高相关感知事实性评分60%），或在无相关基础时回避（最高真实阳性率31%）。", "conclusion": "GaRAGe为评估LLMs在RAG中的表现提供了理想测试平台，揭示了当前模型在时间敏感问题和稀疏私人基础源上的表现不足。"}}
{"id": "2506.07726", "title": "Swiss Parliaments Corpus Re-Imagined (SPC_R): Enhanced Transcription with RAG-based Correction and Predicted BLEU", "authors": ["Vincenzo Timmel", "Manfred Vogel", "Daniel Perruchoud", "Reza Kakooee"], "abstract": "This paper presents a new long-form release of the Swiss Parliaments Corpus, converting entire multi-hour Swiss German debate sessions (each aligned with the official session protocols) into high-quality speech-text pairs. Our pipeline starts by transcribing all session audio into Standard German using Whisper Large-v3 under high-compute settings. We then apply a two-step GPT-4o correction process: first, GPT-4o ingests the raw Whisper output alongside the official protocols to refine misrecognitions, mainly named entities. Second, a separate GPT-4o pass evaluates each refined segment for semantic completeness. We filter out any segments whose Predicted BLEU score (derived from Whisper's average token log-probability) and GPT-4o evaluation score fall below a certain threshold. The final corpus contains 801 hours of audio, of which 751 hours pass our quality control. Compared to the original sentence-level SPC release, our long-form dataset achieves a 6-point BLEU improvement, demonstrating the power of combining robust ASR, LLM-based correction, and data-driven filtering for low-resource, domain-specific speech corpora.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.07726.pdf", "abstract_url": "https://arxiv.org/abs/2506.07726", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了瑞士议会语料库的新版本SPC_R，通过结合Whisper Large-v3、GPT-4o校正和基于数据的过滤，显著提高了语音文本配对的质量。", "motivation": "解决低资源、特定领域语音语料库中语音识别和文本转录质量不高的问题。", "method": "使用Whisper Large-v3进行语音转录，然后通过两步GPT-4o校正过程（修正命名实体和评估语义完整性）和基于Predicted BLEU分数的过滤来提高转录质量。", "result": "最终语料库包含801小时的音频，其中751小时通过质量控制，与原句级SPC版本相比，BLEU分数提高了6点。", "conclusion": "结合强大的自动语音识别(ASR)、基于大型语言模型(LLM)的校正和数据驱动的过滤，可以有效提高低资源、特定领域语音语料库的质量。"}}
{"id": "2506.06359", "title": "From Transformers to Large Language Models: A systematic review of AI applications in the energy sector towards Agentic Digital Twins", "authors": ["Gabriel Antonesi", "Tudor Cioara", "Ionut Anghel", "Vasilis Michalakopoulos", "Elissaios Sarmas", "Liana Toderean"], "abstract": "Artificial intelligence (AI) has long promised to improve energy management in smart grids by enhancing situational awareness and supporting more effective decision-making. While traditional machine learning has demonstrated notable results in forecasting and optimization, it often struggles with generalization, situational awareness, and heterogeneous data integration. Recent advances in foundation models such as Transformer architecture and Large Language Models (LLMs) have demonstrated improved capabilities in modelling complex temporal and contextual relationships, as well as in multi-modal data fusion which is essential for most AI applications in the energy sector. In this review we synthesize the rapid expanding field of AI applications in the energy domain focusing on Transformers and LLMs. We examine the architectural foundations, domain-specific adaptations and practical implementations of transformer models across various forecasting and grid management tasks. We then explore the emerging role of LLMs in the field: adaptation and fine tuning for the energy sector, the type of tasks they are suited for, and the new challenges they introduce. Along the way, we highlight practical implementations, innovations, and areas where the research frontier is rapidly expanding. These recent developments reviewed underscore a broader trend: Generative AI (GenAI) is beginning to augment decision-making not only in high-level planning but also in day-to-day operations, from forecasting and grid balancing to workforce training and asset onboarding. Building on these developments, we introduce the concept of the Agentic Digital Twin, a next-generation model that integrates LLMs to bring autonomy, proactivity, and social interaction into digital twin-based energy management systems.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.06359.pdf", "abstract_url": "https://arxiv.org/abs/2506.06359", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文综述了人工智能（AI）在能源领域的应用，特别是Transformer架构和大语言模型（LLMs）的进展，以及它们如何推动Agentic Digital Twins的发展。", "motivation": "传统机器学习在能源管理中存在泛化能力、情境意识和异构数据整合的挑战，本文旨在探讨如何利用最新的基础模型如Transformers和LLMs来解决这些问题。", "method": "通过系统回顾AI在能源领域的应用，分析Transformer模型的架构基础、领域特定适应和实际实现，以及LLMs在能源领域的适应、微调和适用任务。", "result": "研究发现，生成式AI（GenAI）开始在高级规划和日常操作中增强决策制定，Transformers和LLMs在建模复杂时间和上下文关系及多模态数据融合方面表现出色。", "conclusion": "本文提出了Agentic Digital Twin的概念，这是一种集成LLMs的下一代模型，旨在为基于数字孪生的能源管理系统带来自主性、主动性和社交互动能力。"}}
{"id": "2506.06381", "title": "CPS-Guard: Framework for Dependability Assurance of AI- and LLM-Based Cyber-Physical Systems", "authors": ["Trisanth Srinivasan", "Santosh Patapati", "Himani Musku", "Idhant Gode", "Aditya Arora", "Samvit Bhattacharya", "Abubakr Nazriev", "Sanika Hirave", "Zaryab Kanjiani", "Srinjoy Ghose", "Srinidhi Shetty"], "abstract": "Cyber-Physical Systems (CPS) increasingly depend on advanced AI techniques to operate in critical applications. However, traditional verification and validation methods often struggle to handle the unpredictable and dynamic nature of AI components. In this paper, we introduce CPS-Guard, a novel framework that employs multi-role orchestration to automate the iterative assurance process for AI-powered CPS. By assigning specialized roles (e.g., safety monitoring, security assessment, fault injection, and recovery planning) to dedicated agents within a simulated environment, CPS-Guard continuously evaluates and refines AI behavior against a range of dependability requirements. We demonstrate the framework through a case study involving an autonomous vehicle navigating an intersection with an AI-based planner. Our results show that CPS-Guard effectively detects vulnerabilities, manages performance impacts, and supports adaptive recovery strategies, thereby offering a structured and extensible solution for rigorous V&V in safety- and security-critical systems.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET); Human-Computer Interaction (cs.HC); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.06381.pdf", "abstract_url": "https://arxiv.org/abs/2506.06381", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Emerging Technologies (cs.ET)", "Human-Computer Interaction (cs.HC)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了CPS-Guard，一个用于确保基于AI和LLM的Cyber-Physical Systems（CPS）可靠性的框架。通过多角色编排自动化迭代保证过程，CPS-Guard在模拟环境中持续评估和优化AI行为，以满足可靠性要求。通过自动驾驶车辆的案例研究，展示了其有效性。", "motivation": "随着CPS在关键应用中越来越多地依赖先进的AI技术，传统的验证和验证方法难以应对AI组件的不可预测性和动态性。", "method": "CPS-Guard框架采用多角色编排，将专门的角色（如安全监控、安全评估、故障注入和恢复规划）分配给模拟环境中的专用代理，以自动化迭代保证过程。", "result": "案例研究表明，CPS-Guard能有效检测漏洞、管理性能影响并支持自适应恢复策略。", "conclusion": "CPS-Guard为安全和安全关键系统中的严格V&V提供了一个结构化和可扩展的解决方案。"}}
{"id": "2506.07964", "title": "SlideCoder: Layout-aware RAG-enhanced Hierarchical Slide Generation from Design", "authors": ["Wenxin Tang", "Jingyu Xiao", "Wenxuan Jiang", "Xi Xiao", "Yuhang Wang", "Xuxin Tang", "Qing Li", "Yuehe Ma", "Junliang Liu", "Shisong Tang", "Michael R. Lyu"], "abstract": "Manual slide creation is labor-intensive and requires expert prior knowledge. Existing natural language-based LLM generation methods struggle to capture the visual and structural nuances of slide designs. To address this, we formalize the Reference Image to Slide Generation task and propose Slide2Code, the first benchmark with difficulty-tiered samples based on a novel Slide Complexity Metric. We introduce SlideCoder, a layout-aware, retrieval-augmented framework for generating editable slides from reference images. SlideCoder integrates a Color Gradient-based Segmentation algorithm and a Hierarchical Retrieval-Augmented Generation method to decompose complex tasks and enhance code generation. We also release SlideMaster, a 7B open-source model fine-tuned with improved reverse-engineered data. Experiments show that SlideCoder outperforms state-of-the-art baselines by up to 40.5 points, demonstrating strong performance across layout fidelity, execution accuracy, and visual consistency. Our code is available at", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.07964.pdf", "abstract_url": "https://arxiv.org/abs/2506.07964", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了SlideCoder，一个布局感知、检索增强的框架，用于从参考图像生成可编辑的幻灯片，解决了现有基于自然语言的LLM生成方法难以捕捉幻灯片设计的视觉和结构细微差别的问题。", "motivation": "手动创建幻灯片既费时又需要专业知识，现有的基于自然语言的LLM生成方法难以捕捉幻灯片设计的视觉和结构细微差别。", "method": "提出了SlideCoder框架，集成了基于颜色梯度的分割算法和分层检索增强生成方法，以分解复杂任务并增强代码生成。", "result": "实验表明，SlideCoder在布局保真度、执行准确性和视觉一致性方面优于现有基线方法，最高可提高40.5分。", "conclusion": "SlideCoder通过布局感知和检索增强的方法，有效提高了从参考图像生成幻灯片的性能，为幻灯片自动生成提供了新的解决方案。"}}
{"id": "2506.06355", "title": "LLMs as World Models: Data-Driven and Human-Centered Pre-Event Simulation for Disaster Impact Assessment", "authors": ["Lingyao Li", "Dawei Li", "Zhenhui Ou", "Xiaoran Xu", "Jingxiao Liu", "Zihui Ma", "Runlong Yu", "Min Deng"], "abstract": "Efficient simulation is essential for enhancing proactive preparedness for sudden-onset disasters such as earthquakes. Recent advancements in large language models (LLMs) as world models show promise in simulating complex scenarios. This study examines multiple LLMs to proactively estimate perceived earthquake impacts. Leveraging multimodal datasets including geospatial, socioeconomic, building, and street-level imagery data, our framework generates Modified Mercalli Intensity (MMI) predictions at zip code and county scales. Evaluations on the 2014 Napa and 2019 Ridgecrest earthquakes using USGS ''Did You Feel It? (DYFI)'' reports demonstrate significant alignment, as evidenced by a high correlation of 0.88 and a low RMSE of 0.77 as compared to real reports at the zip code level. Techniques such as RAG and ICL can improve simulation performance, while visual inputs notably enhance accuracy compared to structured numerical data alone. These findings show the promise of LLMs in simulating disaster impacts that can help strengthen pre-event planning.", "subjects": "Computers and Society (cs.CY); Computational Engineering, Finance, and Science (cs.CE); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.06355.pdf", "abstract_url": "https://arxiv.org/abs/2506.06355", "categories": ["Computers and Society (cs.CY)", "Computational Engineering, Finance, and Science (cs.CE)", "Computation and Language (cs.CL)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本研究探讨了利用大型语言模型（LLMs）作为世界模型，通过多模态数据集预测地震感知影响的有效性。通过评估2014年纳帕和2019年里奇克雷斯特地震，证明了该方法与真实报告的高度一致性。", "motivation": "提高对突发性灾害（如地震）的主动准备能力，需要高效的模拟方法。", "method": "利用包括地理空间、社会经济、建筑和街道级图像数据在内的多模态数据集，生成邮政编码和县级尺度的修正麦卡利强度（MMI）预测。", "result": "在邮政编码级别上，与真实报告相比，显示出0.88的高相关性和0.77的低RMSE。RAG和ICL技术可以提高模拟性能，而视觉输入相比结构化数值数据显著提高了准确性。", "conclusion": "LLMs在模拟灾害影响方面显示出潜力，有助于加强事前规划。"}}
{"id": "2506.08006", "title": "Dreamland: Controllable World Creation with Simulator and Generative Models", "authors": ["Sicheng Mo", "Ziyang Leng", "Leon Liu", "Weizhen Wang", "Honglin He", "Bolei Zhou"], "abstract": "Large-scale video generative models can synthesize diverse and realistic visual content for dynamic world creation, but they often lack element-wise controllability, hindering their use in editing scenes and training embodied AI agents. We propose Dreamland, a hybrid world generation framework combining the granular control of a physics-based simulator and the photorealistic content output of large-scale pretrained generative models. In particular, we design a layered world abstraction that encodes both pixel-level and object-level semantics and geometry as an intermediate representation to bridge the simulator and the generative model. This approach enhances controllability, minimizes adaptation cost through early alignment with real-world distributions, and supports off-the-shelf use of existing and future pretrained generative models. We further construct a D3Sim dataset to facilitate the training and evaluation of hybrid generation pipelines. Experiments demonstrate that Dreamland outperforms existing baselines with 50.8% improved image quality, 17.9% stronger controllability, and has great potential to enhance embodied agent training. Code and data will be made available.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2506.08006.pdf", "abstract_url": "https://arxiv.org/abs/2506.08006", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "Dreamland是一个结合物理模拟器和生成模型的混合世界生成框架，旨在通过分层世界抽象增强元素级可控性，支持现成使用预训练生成模型，并在图像质量和可控性上优于现有基线。", "motivation": "解决大规模视频生成模型在元素级可控性上的不足，以支持场景编辑和训练具身AI代理。", "method": "设计了一个分层世界抽象，将像素级和对象级的语义和几何编码为中间表示，以桥接模拟器和生成模型。", "result": "实验显示，Dreamland在图像质量上提高了50.8%，在可控性上增强了17.9%，并显示出增强具身代理训练的潜力。", "conclusion": "Dreamland通过结合模拟器的精细控制和生成模型的逼真内容输出，提供了一种高效、可控的世界生成方法，具有广泛的应用潜力。"}}
{"id": "2506.06576", "title": "Future of Work with AI Agents: Auditing Automation and Augmentation Potential across the U.S. Workforce", "authors": ["Yijia Shao", "Humishka Zope", "Yucheng Jiang", "Jiaxin Pei", "David Nguyen", "Erik Brynjolfsson", "Diyi Yang"], "abstract": "The rapid rise of compound AI systems (a.k.a., AI agents) is reshaping the labor market, raising concerns about job displacement, diminished human agency, and overreliance on automation. Yet, we lack a systematic understanding of the evolving landscape. In this paper, we address this gap by introducing a novel auditing framework to assess which occupational tasks workers want AI agents to automate or augment, and how those desires align with the current technological capabilities. Our framework features an audio-enhanced mini-interview to capture nuanced worker desires and introduces the Human Agency Scale (HAS) as a shared language to quantify the preferred level of human involvement. Using this framework, we construct the WORKBank database, building on the U.S. Department of Labor's O*NET database, to capture preferences from 1,500 domain workers and capability assessments from AI experts across over 844 tasks spanning 104 occupations. Jointly considering the desire and technological capability divides tasks in WORKBank into four zones: Automation \"Green Light\" Zone, Automation \"Red Light\" Zone, R&D Opportunity Zone, Low Priority Zone. This highlights critical mismatches and opportunities for AI agent development. Moving beyond a simple automate-or-not dichotomy, our results reveal diverse HAS profiles across occupations, reflecting heterogeneous expectations for human involvement. Moreover, our study offers early signals of how AI agent integration may reshape the core human competencies, shifting from information-focused skills to interpersonal ones. These findings underscore the importance of aligning AI agent development with human desires and preparing workers for evolving workplace dynamics.", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)", "comments": "Preprint", "pdf_url": "https://arxiv.org/pdf/2506.06576.pdf", "abstract_url": "https://arxiv.org/abs/2506.06576", "categories": ["Computers and Society (cs.CY)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Human-Computer Interaction (cs.HC)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一种新颖的审计框架，用于评估工人希望AI代理自动化或增强哪些职业任务，以及这些愿望如何与当前技术能力对齐。通过构建WORKBank数据库，研究揭示了AI代理发展中的关键不匹配和机会，并强调了将AI代理发展与人类愿望对齐的重要性。", "motivation": "解决关于AI代理如何重塑劳动力市场的系统性理解不足的问题，特别是关于工作替代、人类代理减少和自动化过度依赖的担忧。", "method": "引入一个包含音频增强迷你访谈和人类代理量表（HAS）的审计框架，构建WORKBank数据库，收集1500名领域工人和AI专家对844项任务的偏好和能力评估。", "result": "研究将任务分为四个区域：自动化“绿灯”区、自动化“红灯”区、研发机会区和低优先级区，揭示了AI代理发展中的关键不匹配和机会。", "conclusion": "研究结果强调了将AI代理发展与人类愿望对齐的重要性，并为工人准备适应不断变化的职场动态提供了早期信号。"}}
{"id": "2506.06541", "title": "KramaBench: A Benchmark for AI Systems on Data-to-Insight Pipelines over Data Lakes", "authors": ["Eugenie Lai", "Gerardo Vitagliano", "Ziyu Zhang", "Sivaprasad Sudhir", "Om Chabra", "Anna Zeng", "Anton A. Zabreyko", "Chenning Li", "Ferdi Kossmann", "Jialin Ding", "Jun Chen", "Markos Markakis", "Matthew Russo", "Weiyang Wang", "Ziniu Wu", "Michael J. Cafarella", "Lei Cao", "Samuel Madden", "Tim Kraska"], "abstract": "Constructing real-world data-to-insight pipelines often involves data extraction from data lakes, data integration across heterogeneous data sources, and diverse operations from data cleaning to analysis. The design and implementation of data science pipelines require domain knowledge, technical expertise, and even project-specific insights. AI systems have shown remarkable reasoning, coding, and understanding capabilities. However, it remains unclear to what extent these capabilities translate into successful design and execution of such complex pipelines. We introduce KRAMABENCH: a benchmark composed of 104 manually-curated real-world data science pipelines spanning 1700 data files from 24 data sources in 6 different domains. We show that these pipelines test the end-to-end capabilities of AI systems on data processing, requiring data discovery, wrangling and cleaning, efficient processing, statistical reasoning, and orchestrating data processing steps given a high-level task. Our evaluation tests 5 general models and 3 code generation models using our reference framework, DS-GURU, which instructs the AI model to decompose a question into a sequence of subtasks, reason through each step, and synthesize Python code that implements the proposed design. Our results on KRAMABENCH show that, although the models are sufficiently capable of solving well-specified data science code generation tasks, when extensive data processing and domain knowledge are required to construct real-world data science pipelines, existing out-of-box models fall short. Progress on KramaBench represents crucial steps towards developing autonomous data science agents for real-world applications. Our code, reference framework, and data are available at", "subjects": "Databases (cs.DB); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.06541.pdf", "abstract_url": "https://arxiv.org/abs/2506.06541", "categories": ["Databases (cs.DB)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "KRAMABENCH是一个针对AI系统在数据湖上数据到洞察管道能力的基准测试，包含104个手动策划的真实世界数据科学管道，覆盖6个不同领域的24个数据源和1700个数据文件。", "motivation": "解决AI系统在设计和执行复杂数据科学管道方面的能力评估问题，特别是在需要广泛数据处理和领域知识的情况下。", "method": "引入KRAMABENCH基准测试，使用参考框架DS-GURU评估5个通用模型和3个代码生成模型的能力，包括数据发现、整理、清洁、高效处理、统计推理和管道步骤编排。", "result": "现有模型在解决明确指定的数据科学代码生成任务时表现良好，但在需要广泛数据处理和领域知识构建真实世界数据科学管道时表现不足。", "conclusion": "KRAMABENCH的进展是开发用于真实世界应用的自主数据科学代理的关键步骤。"}}
{"id": "2506.07449", "title": "LlamaRec-LKG-RAG: A Single-Pass, Learnable Knowledge Graph-RAG Framework for LLM-Based Ranking", "authors": ["Vahid Azizi", "Fatemeh Koochaki"], "abstract": "Recent advances in Large Language Models (LLMs) have driven their adoption in recommender systems through Retrieval-Augmented Generation (RAG) frameworks. However, existing RAG approaches predominantly rely on flat, similarity-based retrieval that fails to leverage the rich relational structure inherent in user-item interactions. We introduce LlamaRec-LKG-RAG, a novel single-pass, end-to-end trainable framework that integrates personalized knowledge graph context into LLM-based recommendation ranking. Our approach extends the LlamaRec architecture by incorporating a lightweight user preference module that dynamically identifies salient relation paths within a heterogeneous knowledge graph constructed from user behavior and item metadata. These personalized subgraphs are seamlessly integrated into prompts for a fine-tuned Llama-2 model, enabling efficient and interpretable recommendations through a unified inference step. Comprehensive experiments on ML-100K and Amazon Beauty datasets demonstrate consistent and significant improvements over LlamaRec across key ranking metrics (MRR, NDCG, Recall). LlamaRec-LKG-RAG demonstrates the critical value of structured reasoning in LLM-based recommendations and establishes a foundation for scalable, knowledge-aware personalization in next-generation recommender systems. Code is available at~\\href{", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.07449.pdf", "abstract_url": "https://arxiv.org/abs/2506.07449", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "LlamaRec-LKG-RAG是一种新颖的单次通过、端到端可训练框架，通过将个性化知识图谱上下文整合到基于LLM的推荐排名中，改进了现有RAG方法。", "motivation": "现有的RAG方法主要依赖于平面的、基于相似性的检索，未能利用用户-项目交互中丰富的关联结构。", "method": "扩展LlamaRec架构，加入轻量级用户偏好模块，动态识别异构知识图谱中的关键关系路径，并将这些个性化子图无缝整合到微调的Llama-2模型的提示中。", "result": "在ML-100K和Amazon Beauty数据集上的综合实验显示，LlamaRec-LKG-RAG在关键排名指标（MRR、NDCG、Recall）上比LlamaRec有显著提升。", "conclusion": "LlamaRec-LKG-RAG展示了结构化推理在基于LLM的推荐中的关键价值，并为下一代推荐系统中的可扩展、知识感知个性化奠定了基础。"}}
{"id": "2506.07398", "title": "G-Memory: Tracing Hierarchical Memory for Multi-Agent Systems", "authors": ["Guibin Zhang", "Muxin Fu", "Guancheng Wan", "Miao Yu", "Kun Wang", "Shuicheng Yan"], "abstract": "Large language model (LLM)-powered multi-agent systems (MAS) have demonstrated cognitive and execution capabilities that far exceed those of single LLM agents, yet their capacity for self-evolution remains hampered by underdeveloped memory architectures. Upon close inspection, we are alarmed to discover that prevailing MAS memory mechanisms (1) are overly simplistic, completely disregarding the nuanced inter-agent collaboration trajectories, and (2) lack cross-trial and agent-specific customization, in stark contrast to the expressive memory developed for single agents. To bridge this gap, we introduce G-Memory, a hierarchical, agentic memory system for MAS inspired by organizational memory theory, which manages the lengthy MAS interaction via a three-tier graph hierarchy: insight, query, and interaction graphs. Upon receiving a new user query, G-Memory performs bi-directional memory traversal to retrieve both $\\textit{high-level, generalizable insights}$ that enable the system to leverage cross-trial knowledge, and $\\textit{fine-grained, condensed interaction trajectories}$ that compactly encode prior collaboration experiences. Upon task execution, the entire hierarchy evolves by assimilating new collaborative trajectories, nurturing the progressive evolution of agent teams. Extensive experiments across five benchmarks, three LLM backbones, and three popular MAS frameworks demonstrate that G-Memory improves success rates in embodied action and accuracy in knowledge QA by up to $20.89\\%$ and $10.12\\%$, respectively, without any modifications to the original frameworks. Our codes are available at", "subjects": "Multiagent Systems (cs.MA); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.07398.pdf", "abstract_url": "https://arxiv.org/abs/2506.07398", "categories": ["Multiagent Systems (cs.MA)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了G-Memory，一个为多代理系统（MAS）设计的层次化、代理记忆系统，旨在解决现有MAS记忆架构过于简单、缺乏跨试验和代理特定定制的问题。通过三层图层次结构管理MAS交互，G-Memory显著提高了任务执行的成功率和知识问答的准确性。", "motivation": "解决多代理系统（MAS）中记忆架构过于简单、缺乏跨试验和代理特定定制的问题，以提升MAS的自我进化能力。", "method": "引入G-Memory，一个受组织记忆理论启发的层次化、代理记忆系统，通过三层图层次结构（洞察图、查询图和交互图）管理MAS交互，并进行双向记忆遍历以检索高级通用见解和细粒度交互轨迹。", "result": "在五个基准测试、三种LLM主干和三种流行的MAS框架上的广泛实验表明，G-Memory在无需修改原始框架的情况下，将体现行动的成功率和知识问答的准确性分别提高了高达20.89%和10.12%。", "conclusion": "G-Memory通过其层次化和代理特定的记忆机制，显著提升了多代理系统的性能和自我进化能力，为MAS的记忆架构设计提供了新的方向。"}}
{"id": "2506.06630", "title": "Active Test-time Vision-Language Navigation", "authors": ["Heeju Ko", "Sungjune Kim", "Gyeongrok Oh", "Jeongyoon Yoon", "Honglak Lee", "Sujin Jang", "Seungryong Kim", "Sangpil Kim"], "abstract": "Vision-Language Navigation (VLN) policies trained on offline datasets often exhibit degraded task performance when deployed in unfamiliar navigation environments at test time, where agents are typically evaluated without access to external interaction or feedback. Entropy minimization has emerged as a practical solution for reducing prediction uncertainty at test time; however, it can suffer from accumulated errors, as agents may become overconfident in incorrect actions without sufficient contextual grounding. To tackle these challenges, we introduce ATENA (Active TEst-time Navigation Agent), a test-time active learning framework that enables a practical human-robot interaction via episodic feedback on uncertain navigation outcomes. In particular, ATENA learns to increase certainty in successful episodes and decrease it in failed ones, improving uncertainty calibration. Here, we propose mixture entropy optimization, where entropy is obtained from a combination of the action and pseudo-expert distributions-a hypothetical action distribution assuming the agent's selected action to be optimal-controlling both prediction confidence and action preference. In addition, we propose a self-active learning strategy that enables an agent to evaluate its navigation outcomes based on confident predictions. As a result, the agent stays actively engaged throughout all iterations, leading to well-grounded and adaptive decision-making. Extensive evaluations on challenging VLN benchmarks-REVERIE, R2R, and R2R-CE-demonstrate that ATENA successfully overcomes distributional shifts at test time, outperforming the compared baseline methods across various settings.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.06630.pdf", "abstract_url": "https://arxiv.org/abs/2506.06630", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了ATENA（Active TEst-time Navigation Agent），一种测试时主动学习框架，旨在通过人类-机器人交互减少视觉-语言导航（VLN）策略在陌生环境中的性能下降。ATENA通过混合熵优化和自我主动学习策略，提高了不确定性的校准和决策的适应性。", "motivation": "解决视觉-语言导航（VLN）策略在陌生测试环境中性能下降的问题，特别是在没有外部交互或反馈的情况下。", "method": "提出了ATENA框架，包括混合熵优化（结合动作和伪专家分布的熵）和自我主动学习策略，以提高不确定性的校准和决策的适应性。", "result": "在REVERIE、R2R和R2R-CE等VLN基准测试中，ATENA成功克服了测试时的分布偏移，性能优于基线方法。", "conclusion": "ATENA通过主动学习和不确定性优化，显著提高了VLN策略在陌生环境中的适应性和性能，为实际应用提供了可行的解决方案。"}}
{"id": "2506.06862", "title": "Multimodal Spatial Language Maps for Robot Navigation and Manipulation", "authors": ["Chenguang Huang", "Oier Mees", "Andy Zeng", "Wolfram Burgard"], "abstract": "Grounding language to a navigating agent's observations can leverage pretrained multimodal foundation models to match perceptions to object or event descriptions. However, previous approaches remain disconnected from environment mapping, lack the spatial precision of geometric maps, or neglect additional modality information beyond vision. To address this, we propose multimodal spatial language maps as a spatial map representation that fuses pretrained multimodal features with a 3D reconstruction of the environment. We build these maps autonomously using standard exploration. We present two instances of our maps, which are visual-language maps (VLMaps) and their extension to audio-visual-language maps (AVLMaps) obtained by adding audio information. When combined with large language models (LLMs), VLMaps can (i) translate natural language commands into open-vocabulary spatial goals (e.g., \"in between the sofa and TV\") directly localized in the map, and (ii) be shared across different robot embodiments to generate tailored obstacle maps on demand. Building upon the capabilities above, AVLMaps extend VLMaps by introducing a unified 3D spatial representation integrating audio, visual, and language cues through the fusion of features from pretrained multimodal foundation models. This enables robots to ground multimodal goal queries (e.g., text, images, or audio snippets) to spatial locations for navigation. Additionally, the incorporation of diverse sensory inputs significantly enhances goal disambiguation in ambiguous environments. Experiments in simulation and real-world settings demonstrate that our multimodal spatial language maps enable zero-shot spatial and multimodal goal navigation and improve recall by 50% in ambiguous scenarios. These capabilities extend to mobile robots and tabletop manipulators, supporting navigation and interaction guided by visual, audio, and spatial cues.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2506.06862.pdf", "abstract_url": "https://arxiv.org/abs/2506.06862", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)", "Machine Learning (cs.LG)", "Sound (cs.SD)", "Audio and Speech Processing (eess.AS)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种多模态空间语言地图（VLMaps和AVLMaps），通过融合预训练的多模态特征与环境的3D重建，实现了机器人导航和操作中的语言与感知的精确对接。结合大型语言模型，这些地图能够将自然语言命令转化为空间目标，并在不同机器人平台间共享。实验证明，该方法在模拟和真实环境中均能有效支持零样本空间和多模态目标导航，且在模糊场景中的召回率提高了50%。", "motivation": "解决现有方法在机器人导航和操作中语言与感知对接的不足，如缺乏环境地图连接、空间精度不足或忽视视觉以外的模态信息。", "method": "提出多模态空间语言地图，通过融合预训练的多模态特征与环境的3D重建，构建视觉-语言地图（VLMaps）和音频-视觉-语言地图（AVLMaps）。", "result": "实验显示，该方法在模拟和真实环境中均能有效支持零样本空间和多模态目标导航，且在模糊场景中的召回率提高了50%。", "conclusion": "多模态空间语言地图为机器人导航和操作提供了一种高效、精确的语言与感知对接方法，支持跨平台共享和多样化感官输入，显著提升了在模糊环境中的目标识别能力。"}}
{"id": "2506.07468", "title": "Chasing Moving Targets with Online Self-Play Reinforcement Learning for Safer Language Models", "authors": ["Mickel Liu", "Liwei Jiang", "Yancheng Liang", "Simon Shaolei Du", "Yejin Choi", "Tim Althoff", "Natasha Jaques"], "abstract": "Conventional language model (LM) safety alignment relies on a reactive, disjoint procedure: attackers exploit a static model, followed by defensive fine-tuning to patch exposed vulnerabilities. This sequential approach creates a mismatch -- attackers overfit to obsolete defenses, while defenders perpetually lag behind emerging threats. To address this, we propose Self-RedTeam, an online self-play reinforcement learning algorithm where an attacker and defender agent co-evolve through continuous interaction. We cast safety alignment as a two-player zero-sum game, where a single model alternates between attacker and defender roles -- generating adversarial prompts and safeguarding against them -- while a reward LM adjudicates outcomes. This enables dynamic co-adaptation. Grounded in the game-theoretic framework of zero-sum games, we establish a theoretical safety guarantee which motivates the design of our method: if self-play converges to a Nash Equilibrium, the defender will reliably produce safe responses to any adversarial input. Empirically, Self-RedTeam uncovers more diverse attacks (+21.8% SBERT) compared to attackers trained against static defenders and achieves higher robustness on safety benchmarks (e.g., +65.5% on WildJailBreak) than defenders trained against static attackers. We further propose hidden Chain-of-Thought, allowing agents to plan privately, which boosts adversarial diversity and reduces over-refusals. Our results motivate a shift from reactive patching to proactive co-evolution in LM safety training, enabling scalable, autonomous, and robust self-improvement of LMs via multi-agent reinforcement learning (MARL).", "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.07468.pdf", "abstract_url": "https://arxiv.org/abs/2506.07468", "categories": ["Machine Learning (cs.LG)", "Computation and Language (cs.CL)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为Self-RedTeam的在线自玩强化学习算法，旨在通过攻击者和防御者代理的持续互动来解决语言模型安全对齐的问题。该方法将安全对齐视为一个两人零和游戏，通过动态共适应提高模型的安全性和鲁棒性。", "motivation": "传统的语言模型安全对齐方法依赖于反应性、分离的过程，攻击者利用静态模型，随后进行防御性微调以修补暴露的漏洞。这种顺序方法导致攻击者过时防御，而防御者则始终落后于新兴威胁。", "method": "提出Self-RedTeam，一种在线自玩强化学习算法，其中攻击者和防御者代理通过持续互动共同进化。将安全对齐视为两人零和游戏，单个模型在攻击者和防御者角色之间交替，同时奖励LM裁决结果。", "result": "Self-RedTeam发现了比静态防御者训练的攻击者更多样化的攻击（+21.8% SBERT），并在安全基准测试中实现了比静态攻击者训练的防御者更高的鲁棒性（例如，WildJailBreak上+65.5%）。", "conclusion": "研究结果激励从反应性修补转向主动共进化在LM安全训练中，通过多代理强化学习（MARL）实现语言模型的可扩展、自主和鲁棒的自我改进。"}}
{"id": "2506.06658", "title": "Self-Adapting Improvement Loops for Robotic Learning", "authors": ["Calvin Luo", "Zilai Zeng", "Mingxi Jia", "Yilun Du", "Chen Sun"], "abstract": "Video generative models trained on expert demonstrations have been utilized as performant text-conditioned visual planners for solving robotic tasks. However, generalization to unseen tasks remains a challenge. Whereas improved generalization may be facilitated by leveraging learned prior knowledge from additional pre-collected offline data sources, such as web-scale video datasets, in the era of experience we aim to design agents that can continuously improve in an online manner from self-collected behaviors. In this work we thus propose the Self-Adapting Improvement Loop (SAIL), where an in-domain video model iteratively updates itself on self-produced trajectories, collected through adaptation with an internet-scale pretrained video model, and steadily improves its performance for a specified task of interest. We apply SAIL to a diverse suite of MetaWorld tasks, as well as two manipulation tasks on a real robot arm, and find that performance improvements continuously emerge over multiple iterations for novel tasks initially unseen during original in-domain video model training. Furthermore, we discover that SAIL is surprisingly robust regarding if and how the self-collected experience is filtered, and the quality of the initial in-domain demonstrations. Through adaptation with summarized internet-scale data, and learning through online experience, we thus demonstrate a way to iteratively bootstrap a high-performance video model for solving novel robotic tasks through self-improvement.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.06658.pdf", "abstract_url": "https://arxiv.org/abs/2506.06658", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了自我适应改进循环（SAIL），通过利用互联网规模的预训练视频模型和自我收集的行为，迭代更新域内视频模型，以解决机器人任务中的泛化问题。", "motivation": "解决机器人任务中视频生成模型在未见任务上的泛化能力不足的问题。", "method": "提出自我适应改进循环（SAIL），结合互联网规模的预训练视频模型和自我收集的轨迹，迭代更新域内视频模型。", "result": "在MetaWorld任务和真实机器人手臂操作任务中，SAIL能够持续提高性能，且对自我收集经验的质量和初始域内演示的鲁棒性表现出色。", "conclusion": "通过互联网规模数据的适应和在线经验的学习，SAIL展示了一种通过自我改进迭代引导高性能视频模型解决新颖机器人任务的方法。"}}
{"id": "2506.07551", "title": "ChemAgent: Enhancing LLMs for Chemistry and Materials Science through Tree-Search Based Tool Learning", "authors": ["Mengsong Wu", "YaFei Wang", "Yidong Ming", "Yuqi An", "Yuwei Wan", "Wenliang Chen", "Binbin Lin", "Yuqiang Li", "Tong Xie", "Dongzhan Zhou"], "abstract": "Large language models (LLMs) have recently demonstrated promising capabilities in chemistry tasks while still facing challenges due to outdated pretraining knowledge and the difficulty of incorporating specialized chemical expertise. To address these issues, we propose an LLM-based agent that synergistically integrates 137 external chemical tools created ranging from basic information retrieval to complex reaction predictions, and a dataset curation pipeline to generate the dataset ChemToolBench that facilitates both effective tool selection and precise parameter filling during fine-tuning and evaluation. We introduce a Hierarchical Evolutionary Monte Carlo Tree Search (HE-MCTS) framework, enabling independent optimization of tool planning and execution. By leveraging self-generated data, our approach supports step-level fine-tuning (FT) of the policy model and training task-adaptive PRM and ORM that surpass GPT-4o. Experimental evaluations demonstrate that our approach significantly improves performance in Chemistry QA and discovery tasks, offering a robust solution to integrate specialized tools with LLMs for advanced chemical applications. All datasets and code are available at", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Computation and Language (cs.CL)", "comments": "15 pages, 6 figures", "pdf_url": "https://arxiv.org/pdf/2506.07551.pdf", "abstract_url": "https://arxiv.org/abs/2506.07551", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computational Engineering, Finance, and Science (cs.CE)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于大型语言模型（LLMs）的代理ChemAgent，通过整合137种外部化学工具和数据集ChemToolBench，以及引入分层进化蒙特卡洛树搜索（HE-MCTS）框架，显著提升了化学问答和发现任务的性能。", "motivation": "解决大型语言模型在化学任务中因预训练知识过时和难以融入专业化学知识而面临的挑战。", "method": "通过整合外部化学工具和创建数据集ChemToolBench，引入分层进化蒙特卡洛树搜索（HE-MCTS）框架，独立优化工具规划和执行。", "result": "实验评估表明，该方法在化学问答和发现任务中显著提高了性能，超越了GPT-4o。", "conclusion": "为将专业工具与大型语言模型集成以支持高级化学应用提供了强有力的解决方案。"}}
{"id": "2506.06793", "title": "Is Optimal Transport Necessary for Inverse Reinforcement Learning?", "authors": ["Zixuan Dong", "Yumi Omori", "Keith Ross"], "abstract": "Inverse Reinforcement Learning (IRL) aims to recover a reward function from expert demonstrations. Recently, Optimal Transport (OT) methods have been successfully deployed to align trajectories and infer rewards. While OT-based methods have shown strong empirical results, they introduce algorithmic complexity, hyperparameter sensitivity, and require solving the OT optimization problems. In this work, we challenge the necessity of OT in IRL by proposing two simple, heuristic alternatives: (1) Minimum-Distance Reward, which assigns rewards based on the nearest expert state regardless of temporal order; and (2) Segment-Matching Reward, which incorporates lightweight temporal alignment by matching agent states to corresponding segments in the expert trajectory. These methods avoid optimization, exhibit linear-time complexity, and are easy to implement. Through extensive evaluations across 32 online and offline benchmarks with three reinforcement learning algorithms, we show that our simple rewards match or outperform recent OT-based approaches. Our findings suggest that the core benefits of OT may arise from basic proximity alignment rather than its optimal coupling formulation, advocating for reevaluation of complexity in future IRL design.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "19 pages, 10 tables", "pdf_url": "https://arxiv.org/pdf/2506.06793.pdf", "abstract_url": "https://arxiv.org/abs/2506.06793", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了在逆向强化学习（IRL）中是否必须使用最优传输（OT）方法，提出了两种简单的启发式替代方案，并通过广泛实验证明这些简单方法在性能上可以匹配或超越基于OT的方法。", "motivation": "解决逆向强化学习中使用最优传输方法带来的算法复杂性、超参数敏感性和需要解决OT优化问题的问题。", "method": "提出了两种简单的启发式替代方案：最小距离奖励和段匹配奖励，这两种方法避免了优化，具有线性时间复杂性，且易于实现。", "result": "在32个在线和离线基准测试中，使用三种强化学习算法进行的广泛评估表明，这些简单方法在性能上可以匹配或超越最近的基于OT的方法。", "conclusion": "研究结果表明，OT的核心优势可能来自于基本的邻近对齐而非其最优耦合公式，建议未来IRL设计应重新评估复杂性。"}}
{"id": "2506.07046", "title": "QForce-RL: Quantized FPGA-Optimized Reinforcement Learning Compute Engine", "authors": ["Anushka Jha", "Tanushree Dewangan", "Mukul Lokhande", "Santosh Kumar Vishvakarma"], "abstract": "Reinforcement Learning (RL) has outperformed other counterparts in sequential decision-making and dynamic environment control. However, FPGA deployment is significantly resource-expensive, as associated with large number of computations in training agents with high-quality images and possess new challenges. In this work, we propose QForce-RL takes benefits of quantization to enhance throughput and reduce energy footprint with light-weight RL architecture, without significant performance degradation. QForce-RL takes advantages from E2HRL to reduce overall RL actions to learn desired policy and QuaRL for quantization based SIMD for hardware acceleration. We have also provided detailed analysis for different RL environments, with emphasis on model size, parameters, and accelerated compute ops. The architecture is scalable for resource-constrained devices and provide parametrized efficient deployment with flexibility in latency, throughput, power, and energy efficiency. The proposed QForce-RL provides performance enhancement up to 2.3x and better FPS - 2.6x compared to SoTA works.", "subjects": "Hardware Architecture (cs.AR); Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO); Image and Video Processing (eess.IV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.07046.pdf", "abstract_url": "https://arxiv.org/abs/2506.07046", "categories": ["Hardware Architecture (cs.AR)", "Computer Vision and Pattern Recognition (cs.CV)", "Robotics (cs.RO)", "Image and Video Processing (eess.IV)"], "matching_keywords": ["agent"], "AI": {"tldr": "QForce-RL是一种利用量化技术提高吞吐量并减少能源消耗的轻量级强化学习计算引擎，旨在解决FPGA部署中的资源昂贵问题。", "motivation": "解决在FPGA上部署强化学习（RL）时因大量计算和高品质图像训练代理而导致的高资源消耗问题。", "method": "采用量化技术和轻量级RL架构，结合E2HRL减少RL动作以学习所需策略，以及QuaRL的基于量化的SIMD硬件加速。", "result": "QForce-RL在性能上比现有技术提高了2.3倍，帧率提高了2.6倍，同时保持了模型大小、参数和加速计算操作的灵活性。", "conclusion": "QForce-RL为资源受限的设备提供了一种可扩展、参数化高效部署的解决方案，在延迟、吞吐量、功率和能源效率方面具有灵活性。"}}
{"id": "2506.07972", "title": "HeuriGym: An Agentic Benchmark for LLM-Crafted Heuristics in Combinatorial Optimization", "authors": ["Hongzheng Chen", "Yingheng Wang", "Yaohui Cai", "Hins Hu", "Jiajie Li", "Shirley Huang", "Chenhui Deng", "Rongjian Liang", "Shufeng Kong", "Haoxing Ren", "Samitha Samaranayake", "Carla P. Gomes", "Zhiru Zhang"], "abstract": "While Large Language Models (LLMs) have demonstrated significant advancements in reasoning and agent-based problem-solving, current evaluation methodologies fail to adequately assess their capabilities: existing benchmarks either rely on closed-ended questions prone to saturation and memorization, or subjective comparisons that lack consistency and rigor. In this work, we introduce HeuriGym, an agentic framework designed for evaluating heuristic algorithms generated by LLMs for combinatorial optimization problems, characterized by clearly defined objectives and expansive solution spaces. HeuriGym empowers LLMs to propose heuristics, receive evaluative feedback via code execution, and iteratively refine their solutions. We evaluate nine state-of-the-art models on nine problems across domains such as computer systems, logistics, and biology, exposing persistent limitations in tool use, planning, and adaptive reasoning. To quantify performance, we propose the Quality-Yield Index (QYI), a metric that captures both solution pass rate and quality. Even top models like GPT-o4-mini-high and Gemini-2.5-Pro attain QYI scores of only 0.6, well below the expert baseline of 1. Our open-source benchmark aims to guide the development of LLMs toward more effective and realistic problem-solving in scientific and engineering domains.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.07972.pdf", "abstract_url": "https://arxiv.org/abs/2506.07972", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了HeuriGym，一个用于评估由大型语言模型（LLMs）生成的组合优化问题启发式算法的代理框架。通过代码执行提供反馈并迭代改进解决方案，该框架旨在更准确地评估LLMs的能力。", "motivation": "当前评估大型语言模型（LLMs）的方法无法充分评估其在组合优化问题中的能力，现有基准测试要么依赖于容易饱和和记忆的封闭式问题，要么缺乏一致性和严谨性的主观比较。", "method": "引入HeuriGym框架，允许LLMs提出启发式算法，通过代码执行接收评估反馈，并迭代改进解决方案。使用质量-产量指数（QYI）量化性能。", "result": "在九个领域的问题上评估了九个最先进的模型，发现即使在顶级模型如GPT-o4-mini-high和Gemini-2.5-Pro中，QYI分数也仅为0.6，远低于专家基线的1。", "conclusion": "HeuriGym作为一个开源基准，旨在指导LLMs在科学和工程领域开发更有效和现实的问题解决方法，揭示了当前模型在工具使用、规划和适应性推理方面的持续局限性。"}}
{"id": "2506.06837", "title": "AI-Generated Compromises for Coalition Formation", "authors": ["Eyal Briman", "Ehud Shapiro", "Nimrod Talmon"], "abstract": "The challenge of finding compromises between agent proposals is fundamental to AI subfields such as argumentation, mediation, and negotiation. Building on this tradition, Elkind et al. (2021) introduced a process for coalition formation that seeks majority-supported proposals preferable to the status quo, using a metric space where each agent has an ideal point. A crucial step in this process involves identifying compromise proposals around which agent coalitions can unite. How to effectively find such compromise proposals remains an open question. We address this gap by formalizing a model that incorporates agent bounded rationality and uncertainty, and by developing AI methods to generate compromise proposals. We focus on the domain of collaborative document writing, such as the democratic drafting of a community constitution. Our approach uses natural language processing techniques and large language models to induce a semantic metric space over text. Based on this space, we design algorithms to suggest compromise points likely to receive broad support. To evaluate our methods, we simulate coalition formation processes and show that AI can facilitate large-scale democratic text editing, a domain where traditional tools are limited.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.06837.pdf", "abstract_url": "https://arxiv.org/abs/2506.06837", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种利用AI生成妥协方案以促进联盟形成的方法，特别是在协作文档写作领域，如民主起草社区宪法。通过结合自然语言处理技术和大型语言模型，构建了一个语义度量空间，并设计了算法来推荐可能获得广泛支持的妥协点。", "motivation": "解决在联盟形成过程中如何有效找到妥协方案的问题，特别是在大规模民主文本编辑等传统工具有限的领域。", "method": "结合代理的有界理性和不确定性，利用自然语言处理技术和大型语言模型构建语义度量空间，并设计算法生成妥协提案。", "result": "模拟联盟形成过程的评估显示，AI能够促进大规模民主文本编辑，这在传统工具受限的领域中具有重要意义。", "conclusion": "AI方法能够有效地生成妥协提案，促进联盟的形成和大规模民主文本编辑，为解决传统工具难以应对的问题提供了新的可能性。"}}
{"id": "2506.07350", "title": "MapBERT: Bitwise Masked Modeling for Real-Time Semantic Mapping Generation", "authors": ["Yijie Deng", "Shuaihang Yuan", "Congcong Wen", "Hao Huang", "Anthony Tzes", "Geeta Chandra Raju Bethala", "Yi Fang"], "abstract": "Spatial awareness is a critical capability for embodied agents, as it enables them to anticipate and reason about unobserved regions. The primary challenge arises from learning the distribution of indoor semantics, complicated by sparse, imbalanced object categories and diverse spatial scales. Existing methods struggle to robustly generate unobserved areas in real time and do not generalize well to new environments. To this end, we propose \\textbf{MapBERT}, a novel framework designed to effectively model the distribution of unseen spaces. Motivated by the observation that the one-hot encoding of semantic maps aligns naturally with the binary structure of bit encoding, we, for the first time, leverage a lookup-free BitVAE to encode semantic maps into compact bitwise tokens. Building on this, a masked transformer is employed to infer missing regions and generate complete semantic maps from limited observations. To enhance object-centric reasoning, we propose an object-aware masking strategy that masks entire object categories concurrently and pairs them with learnable embeddings, capturing implicit relationships between object embeddings and spatial tokens. By learning these relationships, the model more effectively captures indoor semantic distributions crucial for practical robotic tasks. Experiments on Gibson benchmarks show that MapBERT achieves state-of-the-art semantic map generation, balancing computational efficiency with accurate reconstruction of unobserved regions.", "subjects": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.07350.pdf", "abstract_url": "https://arxiv.org/abs/2506.07350", "categories": ["Robotics (cs.RO)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "MapBERT是一种新颖的框架，旨在有效建模未见空间分布，通过BitVAE编码语义地图为紧凑的比特令牌，并利用掩码变换器推断缺失区域，生成完整的语义地图。", "motivation": "解决现有方法在实时生成未观察区域和在新环境中泛化能力不足的问题，特别是在室内语义分布学习中的挑战。", "method": "采用无查找的BitVAE将语义地图编码为紧凑的比特令牌，并使用掩码变换器推断缺失区域；提出对象感知掩码策略，增强对象中心推理。", "result": "在Gibson基准测试中，MapBERT实现了最先进的语义地图生成，平衡了计算效率和未观察区域的准确重建。", "conclusion": "MapBERT通过创新的比特编码和对象感知掩码策略，有效捕捉室内语义分布，为实际机器人任务提供了关键能力。"}}
{"id": "2506.07400", "title": "MedChat: A Multi-Agent Framework for Multimodal Diagnosis with Large Language Models", "authors": ["Philip Liu", "Sparsh Bansal", "Jimmy Dinh", "Aditya Pawar", "Ramani Satishkumar", "Shail Desai", "Neeraj Gupta", "Xin Wang", "Shu Hu"], "abstract": "The integration of deep learning-based glaucoma detection with large language models (LLMs) presents an automated strategy to mitigate ophthalmologist shortages and improve clinical reporting efficiency. However, applying general LLMs to medical imaging remains challenging due to hallucinations, limited interpretability, and insufficient domain-specific medical knowledge, which can potentially reduce clinical accuracy. Although recent approaches combining imaging models with LLM reasoning have improved reporting, they typically rely on a single generalist agent, restricting their capacity to emulate the diverse and complex reasoning found in multidisciplinary medical teams. To address these limitations, we propose MedChat, a multi-agent diagnostic framework and platform that combines specialized vision models with multiple role-specific LLM agents, all coordinated by a director agent. This design enhances reliability, reduces hallucination risk, and enables interactive diagnostic reporting through an interface tailored for clinical review and educational use. Code available at", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2506.07400.pdf", "abstract_url": "https://arxiv.org/abs/2506.07400", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "MedChat是一个多代理框架，结合了专用视觉模型和多个角色特定的LLM代理，旨在通过大型语言模型（LLMs）实现多模态诊断，以解决眼科医生短缺和提高临床报告效率的问题。", "motivation": "解决将通用LLMs应用于医学影像时出现的幻觉、有限的可解释性和不足的领域特定医学知识等问题，这些问题可能降低临床准确性。", "method": "提出MedChat，一个多代理诊断框架和平台，结合专用视觉模型和多个角色特定的LLM代理，所有代理由一个导演代理协调，以提高可靠性，减少幻觉风险，并通过为临床审查和教育使用量身定制的界面实现交互式诊断报告。", "result": "MedChat的设计增强了可靠性，减少了幻觉风险，并实现了通过为临床审查和教育使用量身定制的界面进行交互式诊断报告。", "conclusion": "MedChat通过多代理框架和专用视觉模型与LLM代理的结合，为医学影像诊断提供了一个更可靠、交互式的解决方案，有助于缓解眼科医生短缺和提高临床报告效率。"}}
{"id": "2506.06958", "title": "Position: Simulating Society Requires Simulating Thought", "authors": ["Chance Jiajie Li", "Jiayi Wu", "Zhenze Mo", "Ao Qu", "Yuhan Tang", "Kaiya Ivy Zhao", "Yulu Gan", "Jie Fan", "Jiangbo Yu", "Jinhua Zhao", "Paul Liang", "Luis Alonso", "Kent Larson"], "abstract": "Simulating society with large language models (LLMs), we argue, requires more than generating plausible behavior -- it demands cognitively grounded reasoning that is structured, revisable, and traceable. LLM-based agents are increasingly used to emulate individual and group behavior -- primarily through prompting and supervised fine-tuning. Yet they often lack internal coherence, causal reasoning, and belief traceability -- making them unreliable for analyzing how people reason, deliberate, or respond to interventions.", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.06958.pdf", "abstract_url": "https://arxiv.org/abs/2506.06958", "categories": ["Computers and Society (cs.CY)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文认为，使用大型语言模型（LLMs）模拟社会不仅需要生成看似合理的行为，还需要基于认知的、结构化、可修正和可追踪的推理。", "motivation": "解决当前LLM基于的代理在模拟个体和群体行为时缺乏内部一致性、因果推理和信念可追踪性的问题。", "method": "提出需要超越当前的提示和监督微调方法，实现更深入的认知模拟。", "result": "指出当前LLM代理在分析人们如何推理、审议或响应干预方面不可靠。", "conclusion": "强调模拟社会需要模拟思维，即需要更加复杂和认知基础的方法来确保模拟的可靠性和有效性。"}}
{"id": "2506.07079", "title": "On the Generalization of Data-Assisted Control in port-Hamiltonian Systems (DAC-pH)", "authors": ["Mostafa Eslami", "Maryam Babazadeh"], "abstract": "This paper introduces a hypothetical hybrid control framework for port-Hamiltonian (p$\\mathcal{H}$) systems, employing a dynamic decomposition based on Data-Assisted Control (DAC). The system's evolution is split into two parts with fixed topology: Right-Hand Side (RHS)- an intrinsic Hamiltonian flow handling worst-case parametric uncertainties, and Left-Hand Side (LHS)- a dissipative/input flow addressing both structural and parametric uncertainties. A virtual port variable $\\Pi$ serves as the interface between these two components. A nonlinear controller manages the intrinsic Hamiltonian flow, determining a desired port control value $\\Pi_c$. Concurrently, Reinforcement Learning (RL) is applied to the dissipative/input flow to learn an agent for providing optimal policy in mapping $\\Pi_c$ to the actual system input. This hybrid approach effectively manages RHS uncertainties while preserving the system's inherent structure. Key advantages include adjustable performance via LHS controller parameters, enhanced AI explainability and interpretability through the port variable $\\Pi$, the ability to guarantee safety and state attainability with hard/soft constraints, reduced complexity in learning hypothesis classes compared to end-to-end solutions, and improved state/parameter estimation using LHS prior knowledge and system Hamiltonian to address partial observability. The paper details the p$\\mathcal{H}$ formulation, derives the decomposition, and presents the modular controller architecture. Beyond design, crucial aspects of stability and robustness analysis and synthesis are investigated, paving the way for deeper theoretical investigations. An application example, a pendulum with nonlinear dynamics, is simulated to demonstrate the approach's empirical and phenomenological benefits for future research.", "subjects": "Systems and Control (eess.SY); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "This paper presents an early investigation of Data-Assisted Control (DAC) with reinforcement learning, showcasing its potential through a simple example. Theoretical analysis is ongoing to establish formal support and guarantees for the proposed approach", "pdf_url": "https://arxiv.org/pdf/2506.07079.pdf", "abstract_url": "https://arxiv.org/abs/2506.07079", "categories": ["Systems and Control (eess.SY)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种假设性的混合控制框架，用于端口哈密尔顿（p$\\mathcal{H}$）系统，采用基于数据辅助控制（DAC）的动态分解。系统演化被分为两部分：右侧（RHS）-处理最坏情况参数不确定性的内在哈密尔顿流，和左侧（LHS）-处理结构和参数不确定性的耗散/输入流。通过虚拟端口变量$\\Pi$作为这两部分的接口，非线性控制器管理内在哈密尔顿流，确定期望的端口控制值$\\Pi_c$，同时应用强化学习（RL）于耗散/输入流以学习提供$\\Pi_c$到实际系统输入的最优策略的代理。", "motivation": "解决端口哈密尔顿系统中参数和结构不确定性管理的问题，同时保持系统的固有结构，并通过混合控制框架提高AI的可解释性和可解释性。", "method": "采用动态分解方法，将系统分为RHS和LHS两部分，结合非线性控制器和强化学习技术，通过虚拟端口变量$\\Pi$实现两部分的有效交互。", "result": "提出的混合控制框架有效管理了RHS的不确定性，同时通过LHS控制器参数调整性能，增强了AI的可解释性，保证了安全性和状态可达性，降低了学习假设类的复杂性，并改善了状态/参数估计。", "conclusion": "通过理论分析和仿真示例（如非线性动力学摆）展示了该方法的实证和现象学优势，为未来的深入研究铺平了道路。"}}
{"id": "2506.07153", "title": "Mind the Web: The Security of Web Use Agents", "authors": ["Avishag Shapira", "Parth Atulbhai Gandhi", "Edan Habler", "Oleg Brodt", "Asaf Shabtai"], "abstract": "Web-use agents are rapidly being deployed to automate complex web tasks, operating with extensive browser capabilities including multi-tab navigation, DOM manipulation, JavaScript execution and authenticated session access. However, these powerful capabilities create a critical and previously unexplored attack surface. This paper demonstrates how attackers can exploit web-use agents' high-privilege capabilities by embedding malicious content in web pages such as comments, reviews, or advertisements that agents encounter during legitimate browsing tasks. In addition, we introduce the task-aligned injection technique that frame malicious commands as helpful task guidance rather than obvious attacks. This technique exploiting fundamental limitations in LLMs' contextual reasoning: agents struggle in maintaining coherent contextual awareness and fail to detect when seemingly helpful web content contains steering attempts that deviate from their original task goal. Through systematic evaluation of four popular agents (OpenAI Operator, Browser Use, Do Browser, OpenOperator), we demonstrate nine payload types that compromise confidentiality, integrity, and availability, including unauthorized camera activation, user impersonation, local file exfiltration, password leakage, and denial of service, with validation across multiple LLMs achieving success rates of 80%-100%. These payloads succeed across agents with built-in safety mechanisms, requiring only the ability to post content on public websites, creating unprecedented risks given the ease of exploitation combined with agents' high-privilege access. To address this attack, we propose comprehensive mitigation strategies including oversight mechanisms, execution constraints, and task-aware reasoning techniques, providing practical directions for secure development and deployment.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.07153.pdf", "abstract_url": "https://arxiv.org/abs/2506.07153", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了网络使用代理在自动化复杂网络任务时的安全问题，揭示了攻击者如何通过嵌入恶意内容利用代理的高权限能力，并提出了任务对齐注入技术。通过评估四种流行代理，展示了九种有效载荷类型，提出了全面的缓解策略。", "motivation": "解决网络使用代理在自动化任务时，由于其高权限能力而暴露的未探索攻击面问题。", "method": "通过嵌入恶意内容和任务对齐注入技术，评估四种流行代理的安全漏洞。", "result": "展示了九种有效载荷类型，包括未经授权的摄像头激活、用户冒充等，成功率高达80%-100%。", "conclusion": "提出了包括监督机制、执行约束和任务感知推理技术在内的全面缓解策略，为安全开发和部署提供了实用方向。"}}
{"id": "2506.07179", "title": "Regularized Adaptive Graph Learning for Large-Scale Traffic Forecasting", "authors": ["Kaiqi Wu", "Weiyang Kong", "Sen Zhang", "Yubao Liu", "Zitong Chen"], "abstract": "Traffic prediction is a critical task in spatial-temporal forecasting with broad applications in travel planning and urban management. Adaptive graph convolution networks have emerged as mainstream solutions due to their ability to learn node embeddings in a data-driven manner and capture complex latent dependencies. However, existing adaptive graph learning methods for traffic forecasting often either ignore the regularization of node embeddings, which account for a significant proportion of model parameters, or face scalability issues from expensive graph convolution operations. To address these challenges, we propose a Regularized Adaptive Graph Learning (RAGL) model. First, we introduce a regularized adaptive graph learning framework that synergizes Stochastic Shared Embedding (SSE) and adaptive graph convolution via a residual difference mechanism, achieving both embedding regularization and noise suppression. Second, to ensure scalability on large road networks, we develop the Efficient Cosine Operator (ECO), which performs graph convolution based on the cosine similarity of regularized embeddings with linear time complexity. Extensive experiments on four large-scale real-world traffic datasets show that RAGL consistently outperforms state-of-the-art methods in terms of prediction accuracy and exhibits competitive computational efficiency.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.07179.pdf", "abstract_url": "https://arxiv.org/abs/2506.07179", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种正则化自适应图学习（RAGL）模型，用于大规模交通预测，通过结合随机共享嵌入（SSE）和残差差异机制的自适应图卷积，实现了嵌入正则化和噪声抑制，并开发了高效余弦算子（ECO）以确保在大规模道路网络上的可扩展性。", "motivation": "交通预测是空间时间预测中的关键任务，现有自适应图学习方法在交通预测中往往忽略节点嵌入的正则化或面临图卷积操作的可扩展性问题。", "method": "提出了一种正则化自适应图学习框架，结合了随机共享嵌入（SSE）和残差差异机制的自适应图卷积，并开发了高效余弦算子（ECO）进行图卷积。", "result": "在四个大规模真实世界交通数据集上的广泛实验表明，RAGL在预测准确性方面 consistently outperforms state-of-the-art methods，并展现出 competitive computational efficiency。", "conclusion": "RAGL模型通过正则化自适应图学习和高效余弦算子，不仅提高了交通预测的准确性，还解决了大规模道路网络上的可扩展性问题。"}}
{"id": "2506.07232", "title": "Learn as Individuals, Evolve as a Team: Multi-agent LLMs Adaptation in Embodied Environments", "authors": ["Xinran Li", "Chenjia Bai", "Zijian Li", "Jiakun Zheng", "Ting Xiao", "Jun Zhang"], "abstract": "Large language models (LLMs) possess extensive knowledge bases and strong reasoning capabilities, making them promising tools for complex, multi-agent planning in embodied environments. However, despite LLMs' advanced abilities and the sophisticated modular design of agentic methods, existing LLM-based planning algorithms remain limited by weak adaptation capabilities to multi-agent embodied scenarios. We address this limitation by introducing a framework that enables LLM agents to learn and evolve both before and during test time, equipping them with environment-relevant knowledge for better planning and enhanced communication for improved cooperation. Inspired by centralized training with decentralized execution in multi-agent reinforcement learning, we propose a \\textit{Learn as Individuals, Evolve as a Team (LIET)} paradigm for multi-agent LLMs adaptation. At the individual level, LLM agents learn a local utility function from exploratory datasets to better comprehend the embodied environment, which is then queried during test time to support informed decision-making. At the team level, LLM agents collaboratively and iteratively maintain and update a shared cooperation knowledge list based on new experiences, using it to guide more effective communication. By combining individual learning with team evolution, LIET enables comprehensive and flexible adaptation for LLM agents. Our experiments on Communicative Watch-And-Help and ThreeD-World Multi-Agent Transport benchmarks demonstrate that LIET, instantiated with both LLaMA and GPT-4o, outperforms existing baselines and exhibits strong cooperative planning abilities.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.07232.pdf", "abstract_url": "https://arxiv.org/abs/2506.07232", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种名为LIET的框架，旨在通过个体学习和团队进化，提升大型语言模型（LLMs）在多智能体具身环境中的适应性和协作规划能力。", "motivation": "尽管大型语言模型具有广泛的知识库和强大的推理能力，但在多智能体具身场景中的适应能力仍然有限。本文旨在解决这一限制。", "method": "提出了一个“个体学习，团队进化”（LIET）的范式，结合了集中训练与分散执行的策略，通过个体层面的本地效用函数学习和团队层面的共享合作知识列表更新，实现LLM智能体的全面和灵活适应。", "result": "在Communicative Watch-And-Help和ThreeD-World Multi-Agent Transport基准测试中，LIET框架（使用LLaMA和GPT-4o实例化）表现优于现有基线，并展现出强大的协作规划能力。", "conclusion": "LIET框架通过结合个体学习和团队进化，有效提升了LLM智能体在多智能体具身环境中的适应性和协作效率，为未来的研究提供了新的方向。"}}
{"id": "2506.07281", "title": "Secondary Stakeholders in AI: Fighting for, Brokering, and Navigating Agency", "authors": ["Leah Hope Ajmani", "Nuredin Ali Abdelkadir", "Stevie Chancellor"], "abstract": "As AI technologies become more human-facing, there have been numerous calls to adapt participatory approaches to AI development -- spurring the idea of participatory AI. However, these calls often focus only on primary stakeholders, such as end-users, and not secondary stakeholders. This paper seeks to translate the ideals of participatory AI to a broader population of secondary AI stakeholders through semi-structured interviews. We theorize that meaningful participation involves three participatory ideals: (1) informedness, (2) consent, and (3) agency. We also explore how secondary stakeholders realize these ideals by traversing a complicated problem space. Like walking up the rungs of a ladder, these ideals build on one another. We introduce three stakeholder archetypes: the reluctant data contributor, the unsupported activist, and the well-intentioned practitioner, who must navigate systemic barriers to achieving agentic AI relationships. We envision an AI future where secondary stakeholders are able to meaningfully participate with the AI systems they influence and are influenced by.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.07281.pdf", "abstract_url": "https://arxiv.org/abs/2506.07281", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文探讨了在AI技术日益面向人类的背景下，如何将参与式AI的理想扩展到次要利益相关者，通过半结构化访谈研究，提出了三个参与理想：知情、同意和代理，并介绍了三种利益相关者原型。", "motivation": "解决当前参与式AI讨论中忽视次要利益相关者的问题，探索如何让他们在AI系统中实现有意义的参与。", "method": "通过半结构化访谈，理论化参与式AI的三个理想，并探索次要利益相关者如何实现这些理想。", "result": "提出了三个参与理想（知情、同意、代理）和三种次要利益相关者原型（不情愿的数据贡献者、无支持的活动家、善意的实践者），揭示了实现代理性AI关系的系统性障碍。", "conclusion": "展望了一个次要利益相关者能够有意义地参与影响和被AI系统影响的未来，强调了克服系统性障碍以实现这一愿景的重要性。"}}
{"id": "2506.07347", "title": "Distributed Risk-Sensitive Safety Filters for Uncertain Discrete-Time Systems", "authors": ["Armin Lederer", "Erfaun Noorani", "Andreas Krause"], "abstract": "Ensuring safety in multi-agent systems is a significant challenge, particularly in settings where centralized coordination is impractical. In this work, we propose a novel risk-sensitive safety filter for discrete-time multi-agent systems with uncertain dynamics that leverages control barrier functions (CBFs) defined through value functions. Our approach relies on centralized risk-sensitive safety conditions based on exponential risk operators to ensure robustness against model uncertainties. We introduce a distributed formulation of the safety filter by deriving two alternative strategies: one based on worst-case anticipation and another on proximity to a known safe policy. By allowing agents to switch between strategies, feasibility can be ensured. Through detailed numerical evaluations, we demonstrate the efficacy of our approach in maintaining safety without being overly conservative.", "subjects": "Systems and Control (eess.SY); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.07347.pdf", "abstract_url": "https://arxiv.org/abs/2506.07347", "categories": ["Systems and Control (eess.SY)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新颖的风险敏感安全过滤器，用于具有不确定动态的离散时间多智能体系统，利用通过价值函数定义的控制屏障函数（CBFs），确保对模型不确定性的鲁棒性。", "motivation": "在多智能体系统中确保安全性是一个重大挑战，特别是在集中协调不切实际的设置中。", "method": "我们的方法依赖于基于指数风险算子的集中风险敏感安全条件，并通过推导两种替代策略（一种基于最坏情况预期，另一种基于接近已知安全策略）引入了安全过滤器的分布式表述。", "result": "通过详细的数值评估，我们证明了我们的方法在保持安全性而不过于保守方面的有效性。", "conclusion": "通过允许智能体在策略之间切换，可以确保可行性，从而在多智能体系统中有效维持安全性。"}}
{"id": "2506.07388", "title": "Shapley-Coop: Credit Assignment for Emergent Cooperation in Self-Interested LLM Agents", "authors": ["Yun Hua", "Haosheng Chen", "Shiqin Wang", "Wenhao Li", "Xiangfeng Wang", "Jun Luo"], "abstract": "Large Language Models (LLMs) show strong collaborative performance in multi-agent systems with predefined roles and workflows. However, in open-ended environments lacking coordination rules, agents tend to act in self-interested ways. The central challenge in achieving coordination lies in credit assignment -- fairly evaluating each agent's contribution and designing pricing mechanisms that align their heterogeneous goals. This problem is critical as LLMs increasingly participate in complex human-AI collaborations, where fair compensation and accountability rely on effective pricing mechanisms. Inspired by how human societies address similar coordination challenges (e.g., through temporary collaborations such as employment or subcontracting), we propose a cooperative workflow, Shapley-Coop. Shapley-Coop integrates Shapley Chain-of-Thought -- leveraging marginal contributions as a principled basis for pricing -- with structured negotiation protocols for effective price matching, enabling LLM agents to coordinate through rational task-time pricing and post-task reward redistribution. This approach aligns agent incentives, fosters cooperation, and maintains autonomy. We evaluate Shapley-Coop across two multi-agent games and a software engineering simulation, demonstrating that it consistently enhances LLM agent collaboration and facilitates equitable credit assignment. These results highlight the effectiveness of Shapley-Coop's pricing mechanisms in accurately reflecting individual contributions during task execution.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.07388.pdf", "abstract_url": "https://arxiv.org/abs/2506.07388", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了Shapley-Coop方法，旨在通过基于边际贡献的定价和结构化谈判协议，促进自利LLM代理在开放环境中的合作，实现公平的信用分配。", "motivation": "解决在缺乏协调规则的开放环境中，自利LLM代理难以合作的问题，关键在于公平评估每个代理的贡献并设计定价机制以协调其异质目标。", "method": "提出Shapley-Coop工作流，结合Shapley Chain-of-Thought（利用边际贡献作为定价基础）和结构化谈判协议，实现理性的任务时间定价和任务后奖励再分配。", "result": "在两个多代理游戏和一个软件工程模拟中评估，Shapley-Coop consistently enhances LLM agent collaboration and facilitates equitable credit assignment.", "conclusion": "Shapley-Coop的定价机制有效反映了任务执行中的个体贡献，促进了代理间的合作，保持了自主性。"}}
{"id": "2506.07392", "title": "From Static to Adaptive Defense: Federated Multi-Agent Deep Reinforcement Learning-Driven Moving Target Defense Against DoS Attacks in UAV Swarm Networks", "authors": ["Yuyang Zhou", "Guang Cheng", "Kang Du", "Zihan Chen", "Tian Qin", "Yuyu Zhao"], "abstract": "The proliferation of unmanned aerial vehicle (UAV) swarms has enabled a wide range of mission-critical applications, but also exposes UAV networks to severe Denial-of-Service (DoS) threats due to their open wireless environment, dynamic topology, and resource constraints. Traditional static or centralized defense mechanisms are often inadequate for such dynamic and distributed scenarios. To address these challenges, we propose a novel federated multi-agent deep reinforcement learning (FMADRL)-driven moving target defense (MTD) framework for proactive and adaptive DoS mitigation in UAV swarm networks. Specifically, we design three lightweight and coordinated MTD mechanisms, including leader switching, route mutation, and frequency hopping, that leverage the inherent flexibility of UAV swarms to disrupt attacker efforts and enhance network resilience. The defense problem is formulated as a multi-agent partially observable Markov decision process (POMDP), capturing the distributed, resource-constrained, and uncertain nature of UAV swarms under attack. Each UAV is equipped with a local policy agent that autonomously selects MTD actions based on partial observations and local experiences. By employing a policy gradient-based FMADRL algorithm, UAVs collaboratively optimize their defense policies via reward-weighted aggregation, enabling distributed learning without sharing raw data and thus reducing communication overhead. Extensive simulations demonstrate that our approach significantly outperforms state-of-the-art baselines, achieving up to a 34.6% improvement in attack mitigation rate, a reduction in average recovery time of up to 94.6%, and decreases in energy consumption and defense cost by as much as 29.3% and 98.3%, respectively, while maintaining robust mission continuity under various DoS attack strategies.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "13pages; In submission", "pdf_url": "https://arxiv.org/pdf/2506.07392.pdf", "abstract_url": "https://arxiv.org/abs/2506.07392", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于联邦多智能体深度强化学习（FMADRL）的动态目标防御（MTD）框架，用于无人机群网络中的DoS攻击自适应缓解。通过设计三种轻量级协调的MTD机制，并结合FMADRL算法，实现了在资源受限和不确定环境下的高效防御。", "motivation": "无人机群网络的开放无线环境、动态拓扑和资源限制使其面临严重的DoS威胁，传统静态或集中式防御机制难以应对这些动态和分布式场景。", "method": "设计了包括领导者切换、路由变异和频率跳变在内的三种轻量级协调MTD机制，并将防御问题建模为多智能体部分可观察马尔可夫决策过程（POMDP），采用基于策略梯度的FMADRL算法进行分布式学习。", "result": "仿真结果表明，该方法在攻击缓解率上比现有技术提高了34.6%，平均恢复时间减少了94.6%，能耗和防御成本分别降低了29.3%和98.3%，同时在不同DoS攻击策略下保持了强大的任务连续性。", "conclusion": "提出的FMADRL驱动的MTD框架为无人机群网络提供了一种高效、自适应的DoS攻击防御解决方案，显著提高了网络弹性和任务连续性。"}}
{"id": "2506.07524", "title": "IntenTest: Stress Testing for Intent Integrity in API-Calling LLM Agents", "authors": ["Shiwei Feng", "Xiangzhe Xu", "Xuan Chen", "Kaiyuan Zhang", "Syed Yusuf Ahmed", "Zian Su", "Mingwei Zheng", "Xiangyu Zhang"], "abstract": "LLM agents are increasingly deployed to automate real-world tasks by invoking APIs through natural language instructions. While powerful, they often suffer from misinterpretation of user intent, leading to the agent's actions that diverge from the user's intended goal, especially as external toolkits evolve. Traditional software testing assumes structured inputs and thus falls short in handling the ambiguity of natural language. We introduce IntenTest, an API-centric stress testing framework that systematically uncovers intent integrity violations in LLM agents. Unlike prior work focused on fixed benchmarks or adversarial inputs, IntenTest generates realistic tasks based on toolkits' documentation and applies targeted mutations to expose subtle agent errors while preserving user intent. To guide testing, we propose semantic partitioning, which organizes natural language tasks into meaningful categories based on toolkit API parameters and their equivalence classes. Within each partition, seed tasks are mutated and ranked by a lightweight predictor that estimates the likelihood of triggering agent errors. To enhance efficiency, IntenTest maintains a datatype-aware strategy memory that retrieves and adapts effective mutation patterns from past cases. Experiments on 80 toolkit APIs demonstrate that IntenTest effectively uncovers intent integrity violations, significantly outperforming baselines in both error-exposing rate and query efficiency. Moreover, IntenTest generalizes well to stronger target models using smaller LLMs for test generation, and adapts to evolving APIs across domains.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.07524.pdf", "abstract_url": "https://arxiv.org/abs/2506.07524", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)"], "matching_keywords": ["agent"], "AI": {"tldr": "IntenTest是一个API-centric的压力测试框架，旨在系统地发现LLM代理中的意图完整性违规，通过基于工具包文档生成现实任务并应用定向突变来暴露代理错误，同时保持用户意图。", "motivation": "LLM代理在通过自然语言指令调用API自动化现实世界任务时，常因误解用户意图而导致行为偏离用户目标，尤其是在外部工具包演变时。传统软件测试无法有效处理自然语言的模糊性。", "method": "IntenTest引入语义分区组织自然语言任务，基于工具包API参数及其等价类，生成并排名突变任务，使用轻量级预测器估计触发代理错误的可能性，并通过数据类型感知的策略记忆提高效率。", "result": "在80个工具包API上的实验表明，IntenTest在暴露错误率和查询效率上显著优于基线，且能很好地泛化到更强的目标模型，并适应跨领域的API演变。", "conclusion": "IntenTest有效地揭示了LLM代理中的意图完整性违规，为自动化任务的可靠性和安全性提供了重要保障。"}}
{"id": "2506.07829", "title": "Decentralizing Multi-Agent Reinforcement Learning with Temporal Causal Information", "authors": ["Jan Corazza", "Hadi Partovi Aria", "Hyohun Kim", "Daniel Neider", "Zhe Xu"], "abstract": "Reinforcement learning (RL) algorithms can find an optimal policy for a single agent to accomplish a particular task. However, many real-world problems require multiple agents to collaborate in order to achieve a common goal. For example, a robot executing a task in a warehouse may require the assistance of a drone to retrieve items from high shelves. In Decentralized Multi-Agent RL (DMARL), agents learn independently and then combine their policies at execution time, but often must satisfy constraints on compatibility of local policies to ensure that they can achieve the global task when combined. In this paper, we study how providing high-level symbolic knowledge to agents can help address unique challenges of this setting, such as privacy constraints, communication limitations, and performance concerns. In particular, we extend the formal tools used to check the compatibility of local policies with the team task, making decentralized training with theoretical guarantees usable in more scenarios. Furthermore, we empirically demonstrate that symbolic knowledge about the temporal evolution of events in the environment can significantly expedite the learning process in DMARL.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.07829.pdf", "abstract_url": "https://arxiv.org/abs/2506.07829", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了在多智能体强化学习（DMARL）中，如何通过提供高级符号知识来解决隐私约束、通信限制和性能问题等独特挑战。通过扩展用于检查局部策略与团队任务兼容性的正式工具，使具有理论保证的分散训练在更多场景中可用。", "motivation": "解决多智能体协作中的隐私约束、通信限制和性能问题，以实现共同目标。", "method": "扩展用于检查局部策略与团队任务兼容性的正式工具，并利用环境事件的时间演化的符号知识来加速学习过程。", "result": "实证表明，关于环境事件时间演化的符号知识可以显著加快DMARL中的学习过程。", "conclusion": "提供高级符号知识可以有效解决DMARL中的独特挑战，扩展了分散训练的应用场景，并加速了学习过程。"}}
{"id": "2506.07935", "title": "Diffusion of Responsibility in Collective Decision Making", "authors": ["Pavel Naumov", "Jia Tao"], "abstract": "The term \"diffusion of responsibility'' refers to situations in which multiple agents share responsibility for an outcome, obscuring individual accountability. This paper examines this frequently undesirable phenomenon in the context of collective decision-making mechanisms.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.07935.pdf", "abstract_url": "https://arxiv.org/abs/2506.07935", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Computer Science and Game Theory (cs.GT)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了集体决策机制中'责任扩散'现象，即多个代理共同承担结果责任，从而模糊了个体责任的情况。", "motivation": "研究集体决策中责任扩散这一不良现象，旨在提高对个体责任在集体决策中作用的理解。", "method": "通过分析集体决策机制中的责任分配情况，探讨责任扩散现象的产生和影响。", "result": "研究发现，责任扩散现象在集体决策中普遍存在，且可能导致个体责任感的降低。", "conclusion": "结论指出，明确个体责任对于改善集体决策机制和提高决策质量具有重要意义。"}}
{"id": "2506.07976", "title": "Thinking vs. Doing: Agents that Reason by Scaling Test-Time Interaction", "authors": ["Junhong Shen", "Hao Bai", "Lunjun Zhang", "Yifei Zhou", "Amrith Setlur", "Shengbang Tong", "Diego Caples", "Nan Jiang", "Tong Zhang", "Ameet Talwalkar", "Aviral Kumar"], "abstract": "The current paradigm of test-time scaling relies on generating long reasoning traces (\"thinking\" more) before producing a response. In agent problems that require interaction, this can be done by generating thinking traces before acting in the world. However, this process does not allow agents to acquire new information from the environment or adapt their behavior over time. In this work, we propose to scale test-time interaction, an untapped dimension of test-time scaling that increases the agent's interaction horizon to enable running rich behaviors such as exploration, backtracking, and dynamic re-planning within a single rollout. To demonstrate the promise of this scaling dimension, we study the domain of web agents. We first show that even prompting-based interaction scaling without any training can improve task success on web benchmarks non-trivially. Building on this, we introduce TTI (Test-Time Interaction), a curriculum-based online reinforcement learning (RL) approach that trains agents by adaptively adjusting their rollout lengths. Using a Gemma 3 12B model, TTI produces state-of-the-art open-source, open-data web agents on WebVoyager and WebArena benchmarks. We further show that TTI enables agents to balance exploration and exploitation adaptively. Our results establish interaction scaling as a powerful, complementary axis to scaling per-step compute, offering new avenues for training adaptive agents.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.07976.pdf", "abstract_url": "https://arxiv.org/abs/2506.07976", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新的测试时间交互扩展方法，通过增加代理的交互视野来丰富其行为，如探索、回溯和动态重新规划，从而在单一滚动中实现更复杂的行为。", "motivation": "当前测试时间扩展的范式依赖于在生成响应之前生成长的推理轨迹（“更多思考”），这在需要交互的代理问题中，不允许代理从环境中获取新信息或随时间调整其行为。", "method": "提出了TTI（测试时间交互），一种基于课程的在线强化学习（RL）方法，通过自适应调整滚动长度来训练代理。", "result": "使用Gemma 3 12B模型，TTI在WebVoyager和WebArena基准测试中产生了最先进的开源、开放数据网络代理，并展示了代理能够自适应地平衡探索和利用。", "conclusion": "交互扩展作为一种强大的、与每步计算扩展互补的轴，为训练自适应代理提供了新的途径。"}}
