{"id": "2505.22752", "title": "Climate Finance Bench", "authors": ["Rafik Mankour", "Yassine Chafai", "Hamada Saleh", "Ghassen Ben Hassine", "Thibaud Barreau", "Peter Tankov"], "abstract": "Climate Finance Bench introduces an open benchmark that targets question-answering over corporate climate disclosures using Large Language Models. We curate 33 recent sustainability reports in English drawn from companies across all 11 GICS sectors and annotate 330 expert-validated question-answer pairs that span pure extraction, numerical reasoning, and logical reasoning. Building on this dataset, we propose a comparison of RAG (retrieval-augmented generation) approaches. We show that the retriever's ability to locate passages that actually contain the answer is the chief performance bottleneck. We further argue for transparent carbon reporting in AI-for-climate applications, highlighting advantages of techniques such as Weight Quantization.", "subjects": "Computation and Language (cs.CL)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.22752.pdf", "abstract_url": "https://arxiv.org/abs/2505.22752", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "Climate Finance Bench提出了一个开放的基准，旨在利用大型语言模型对公司气候披露进行问答。", "motivation": "解决在公司气候披露中准确回答问题的挑战，特别是在提取、数值推理和逻辑推理方面。", "method": "收集了33份英文可持续发展报告，标注了330个专家验证的问题-答案对，并比较了RAG（检索增强生成）方法。", "result": "研究发现，检索器定位包含答案的段落的能力是性能的主要瓶颈。", "conclusion": "强调了在AI-for-climate应用中透明碳报告的重要性，并提出了如权重量化等技术的优势。"}}
{"id": "2505.23130", "title": "PhotoArtAgent: Intelligent Photo Retouching with Language Model-Based Artist Agents", "authors": ["Haoyu Chen", "Keda Tao", "Yizao Wang", "Xinlei Wang", "Lei Zhu", "Jinjin Gu"], "abstract": "Photo retouching is integral to photographic art, extending far beyond simple technical fixes to heighten emotional expression and narrative depth. While artists leverage expertise to create unique visual effects through deliberate adjustments, non-professional users often rely on automated tools that produce visually pleasing results but lack interpretative depth and interactive transparency. In this paper, we introduce PhotoArtAgent, an intelligent system that combines Vision-Language Models (VLMs) with advanced natural language reasoning to emulate the creative process of a professional artist. The agent performs explicit artistic analysis, plans retouching strategies, and outputs precise parameters to Lightroom through an API. It then evaluates the resulting images and iteratively refines them until the desired artistic vision is achieved. Throughout this process, PhotoArtAgent provides transparent, text-based explanations of its creative rationale, fostering meaningful interaction and user control. Experimental results show that PhotoArtAgent not only surpasses existing automated tools in user studies but also achieves results comparable to those of professional human artists.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23130.pdf", "abstract_url": "https://arxiv.org/abs/2505.23130", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "PhotoArtAgent是一个结合视觉语言模型和高级自然语言推理的智能系统，旨在模拟专业艺术家的创作过程，提供透明、文本化的创意解释，实现与用户的有意义互动和控制。", "motivation": "解决非专业用户在照片修饰中依赖自动化工具但缺乏解释深度和交互透明度的问题。", "method": "结合视觉语言模型(VLMs)和高级自然语言推理，模拟艺术家的创作过程，包括艺术分析、修饰策略规划和通过API输出精确参数到Lightroom。", "result": "PhotoArtAgent在用户研究中不仅超越了现有的自动化工具，而且达到了与专业人类艺术家相当的效果。", "conclusion": "PhotoArtAgent通过智能系统和透明交互，为非专业用户提供了接近专业艺术家水平的照片修饰体验。"}}
{"id": "2505.22698", "title": "Design and testing of an agent chatbot supporting decision making with public transport data", "authors": ["Luca Fantin", "Marco Antonelli", "Margherita Cesetti", "Daniele Irto", "Bruno Zamengo", "Francesco Silvestri"], "abstract": "Assessing the quality of public transportation services requires the analysis of large quantities of data on the scheduled and actual trips and documents listing the quality constraints each service needs to meet. Interrogating such datasets with SQL queries, organizing and visualizing the data can be quite complex for most users. This paper presents a chatbot offering a user-friendly tool to interact with these datasets and support decision making. It is based on an agent architecture, which expands the capabilities of the core Large Language Model (LLM) by allowing it to interact with a series of tools that can execute several tasks, like performing SQL queries, plotting data and creating maps from the coordinates of a trip and its stops. This paper also tackles one of the main open problems of such Generative AI projects: collecting data to measure the system's performance. Our chatbot has been extensively tested with a workflow that asks several questions and stores the generated query, the retrieved data and the natural language response for each of them. Such questions are drawn from a set of base examples which are then completed with actual data from the database. This procedure yields a dataset for the evaluation of the chatbot's performance, especially the consistency of its answers and the correctness of the generated queries.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.22698.pdf", "abstract_url": "https://arxiv.org/abs/2505.22698", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一种基于代理架构的聊天机器人，旨在通过用户友好的方式与公共交通数据集交互，支持决策制定。该聊天机器人扩展了大型语言模型（LLM）的核心能力，使其能够执行SQL查询、绘制数据和创建地图等任务。此外，论文还解决了生成AI项目中的一个主要开放问题：收集数据以测量系统性能。", "motivation": "评估公共交通服务质量需要分析大量关于计划与实际行程的数据以及每项服务需要满足的质量约束文件。对于大多数用户来说，使用SQL查询、组织和可视化这些数据可能相当复杂。", "method": "采用基于代理架构的聊天机器人，扩展了大型语言模型（LLM）的能力，使其能够与一系列工具交互，执行SQL查询、数据绘图和从行程及其站点的坐标创建地图等任务。", "result": "通过一个工作流程广泛测试了聊天机器人，该流程提出多个问题，并为每个问题存储生成的查询、检索的数据和自然语言响应。这一过程产生了一个用于评估聊天机器人性能的数据集，特别是其答案的一致性和生成查询的正确性。", "conclusion": "开发的聊天机器人提供了一种用户友好的工具，用于与复杂的公共交通数据集交互，支持决策制定，并通过实际测试验证了其性能和一致性。"}}
{"id": "2505.22809", "title": "First Steps Towards Overhearing LLM Agents: A Case Study With Dungeons & Dragons Gameplay", "authors": ["Andrew Zhu", "Evan Osgood", "Chris Callison-Burch"], "abstract": "Much work has been done on conversational LLM agents which directly assist human users with tasks. We present an alternative paradigm for interacting with LLM agents, which we call \"overhearing agents\". These overhearing agents do not actively participate in conversation -- instead, they \"listen in\" on human-to-human conversations and perform background tasks or provide suggestions to assist the user. In this work, we explore the overhearing agents paradigm through the lens of Dungeons & Dragons gameplay. We present an in-depth study using large multimodal audio-language models as overhearing agents to assist a Dungeon Master. We perform a human evaluation to examine the helpfulness of such agents and find that some large audio-language models have the emergent ability to perform overhearing agent tasks using implicit audio cues. Finally, we release Python libraries and our project code to support further research into the overhearing agents paradigm at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)", "comments": "8 pages, 5 figures. In submission at EMNLP 2025", "pdf_url": "https://arxiv.org/pdf/2505.22809.pdf", "abstract_url": "https://arxiv.org/abs/2505.22809", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一种名为‘偷听代理’的新型LLM代理交互范式，该代理通过‘监听’人类之间的对话来执行后台任务或提供建议，而非直接参与对话。研究以《龙与地下城》游戏为例，探索了大型多模态音频-语言模型作为偷听代理协助游戏主持人的能力，并通过人类评估验证了其有效性。", "motivation": "解决如何让LLM代理在不直接参与对话的情况下，通过监听人类对话来提供帮助的问题。", "method": "使用大型多模态音频-语言模型作为偷听代理，在《龙与地下城》游戏中进行深入案例研究，并进行人类评估。", "result": "研究发现，某些大型音频-语言模型具有利用隐式音频线索执行偷听代理任务的新兴能力。", "conclusion": "偷听代理范式为LLM代理的交互提供了新的可能性，研究发布的Python库和项目代码将支持该领域的进一步研究。"}}
{"id": "2505.22777", "title": "MEDAL: A Framework for Benchmarking LLMs as Multilingual Open-Domain Chatbots and Dialogue Evaluators", "authors": ["John Mendonça", "Alon Lavie", "Isabel Trancoso"], "abstract": "As the capabilities of chatbots and their underlying LLMs continue to dramatically improve, evaluating their performance has increasingly become a major blocker to their further development. A major challenge is the available benchmarking datasets, which are largely static, outdated, and lacking in multilingual coverage, limiting their ability to capture subtle linguistic and cultural variations. This paper introduces MEDAL, an automated multi-agent framework for generating, evaluating, and curating more representative and diverse open-domain dialogue evaluation benchmarks. Our approach leverages several state-of-the-art LLMs to generate user-chatbot multilingual dialogues, conditioned on varied seed contexts. A strong LLM (GPT-4.1) is then used for a multidimensional analysis of the performance of the chatbots, uncovering noticeable cross-lingual performance differences. Guided by this large-scale evaluation, we curate a new meta-evaluation multilingual benchmark and human-annotate samples with nuanced quality judgments. This benchmark is then used to assess the ability of several reasoning and non-reasoning LLMs to act as evaluators of open-domain dialogues. We find that current LLMs struggle to detect nuanced issues, particularly those involving empathy and reasoning.", "subjects": "Computation and Language (cs.CL)", "comments": "May ARR", "pdf_url": "https://arxiv.org/pdf/2505.22777.pdf", "abstract_url": "https://arxiv.org/abs/2505.22777", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "MEDAL是一个自动化多代理框架，用于生成、评估和策划更具代表性和多样性的开放领域对话评估基准。该框架利用先进的LLM生成多语言用户-聊天机器人对话，并通过GPT-4.1进行多维性能分析，揭示了显著的跨语言性能差异。研究还发现，当前的LLM在检测涉及同理心和推理的微妙问题时存在困难。", "motivation": "随着聊天机器人及其底层LLM能力的显著提升，评估其性能已成为进一步发展的主要障碍。现有的基准数据集大多静态、过时且缺乏多语言覆盖，限制了捕捉细微语言和文化差异的能力。", "method": "MEDAL框架利用多个先进的LLM生成基于不同种子上下文的多语言用户-聊天机器人对话，然后使用GPT-4.1进行多维性能分析。基于大规模评估，策划了一个新的多语言元评估基准，并对样本进行了细致的人类注释。", "result": "研究发现，当前的LLM在检测涉及同理心和推理的微妙问题时表现不佳，特别是在多语言环境下。", "conclusion": "MEDAL框架为开放领域对话评估提供了一个更代表性和多样性的基准，揭示了LLM在评估开放领域对话时的局限性，特别是在处理微妙问题方面。"}}
{"id": "2505.22753", "title": "Enhancing Lifelong Multi-Agent Path-finding by Using Artificial Potential Fields", "authors": ["Arseniy Pertzovsky", "Roni Stern", "Ariel Felner", "Roie Zivan"], "abstract": "We explore the use of Artificial Potential Fields (APFs) to solve Multi-Agent Path Finding (MAPF) and Lifelong MAPF (LMAPF) problems. In MAPF, a team of agents must move to their goal locations without collisions, whereas in LMAPF, new goals are generated upon arrival. We propose methods for incorporating APFs in a range of MAPF algorithms, including Prioritized Planning, MAPF-LNS2, and Priority Inheritance with Backtracking (PIBT). Experimental results show that using APF is not beneficial for MAPF but yields up to a 7-fold increase in overall system throughput for LMAPF.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.22753.pdf", "abstract_url": "https://arxiv.org/abs/2505.22753", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了使用人工势场（APFs）解决多智能体路径规划（MAPF）和终身多智能体路径规划（LMAPF）问题。在MAPF中，一组智能体需要无碰撞地移动到目标位置，而在LMAPF中，到达目标后会生成新的目标。作者提出了将APFs融入多种MAPF算法的方法，实验结果表明APF对MAPF无益，但能使LMAPF的系统吞吐量提高多达7倍。", "motivation": "解决多智能体在动态环境中高效、无碰撞路径规划的问题，特别是在终身多智能体路径规划（LMAPF）场景下，如何提高系统吞吐量。", "method": "提出将人工势场（APFs）融入多种MAPF算法，包括优先规划（Prioritized Planning）、MAPF-LNS2和优先级继承与回溯（PIBT）。", "result": "实验结果显示，APF对传统MAPF无显著益处，但在LMAPF场景下，能显著提高系统吞吐量，最高可达7倍。", "conclusion": "人工势场（APFs）在终身多智能体路径规划（LMAPF）中表现出色，能显著提高系统效率，为动态环境下的多智能体路径规划提供了新的解决方案。"}}
{"id": "2505.22954", "title": "Darwin Godel Machine: Open-Ended Evolution of Self-Improving Agents", "authors": ["Jenny Zhang", "Shengran Hu", "Cong Lu", "Robert Lange", "Jeff Clune"], "abstract": "Today's AI systems have human-designed, fixed architectures and cannot autonomously and continuously improve themselves. The advance of AI could itself be automated. If done safely, that would accelerate AI development and allow us to reap its benefits much sooner. Meta-learning can automate the discovery of novel algorithms, but is limited by first-order improvements and the human design of a suitable search space. The Gödel machine proposed a theoretical alternative: a self-improving AI that repeatedly modifies itself in a provably beneficial manner. Unfortunately, proving that most changes are net beneficial is impossible in practice. We introduce the Darwin Gödel Machine (DGM), a self-improving system that iteratively modifies its own code (thereby also improving its ability to modify its own codebase) and empirically validates each change using coding benchmarks. Inspired by Darwinian evolution and open-endedness research, the DGM maintains an archive of generated coding agents. It grows the archive by sampling an agent from it and using a foundation model to create a new, interesting, version of the sampled agent. This open-ended exploration forms a growing tree of diverse, high-quality agents and allows the parallel exploration of many different paths through the search space. Empirically, the DGM automatically improves its coding capabilities (e.g., better code editing tools, long-context window management, peer-review mechanisms), increasing performance on SWE-bench from 20.0% to 50.0%, and on Polyglot from 14.2% to 30.7%. Furthermore, the DGM significantly outperforms baselines without self-improvement or open-ended exploration. All experiments were done with safety precautions (e.g., sandboxing, human oversight). The DGM is a significant step toward self-improving AI, capable of gathering its own stepping stones along paths that unfold into endless innovation.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.22954.pdf", "abstract_url": "https://arxiv.org/abs/2505.22954", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "达尔文哥德尔机（DGM）是一种自我改进的系统，通过迭代修改自身代码并利用编码基准实证验证每次修改，自动提升其编码能力。受达尔文进化和开放式研究启发，DGM通过维护一个生成的编码代理档案库，并利用基础模型创建新版本代理，实现了对搜索空间的并行探索。实验显示，DGM在编码能力上显著提升，并在安全措施下进行。", "motivation": "当前AI系统具有人类设计的固定架构，无法自主持续自我改进。本文旨在通过引入达尔文哥德尔机（DGM），实现AI的自我改进，加速AI发展并尽早受益。", "method": "DGM通过迭代修改自身代码，并利用编码基准实证验证每次修改。它维护一个编码代理档案库，通过基础模型创建新版本代理，实现开放式探索和并行搜索。", "result": "DGM在SWE-bench上的性能从20.0%提升至50.0%，在Polyglot上从14.2%提升至30.7%。显著优于无自我改进或开放式探索的基线。", "conclusion": "DGM是实现自我改进AI的重要一步，能够在安全措施下，沿着展开为无尽创新的路径自主积累垫脚石。"}}
{"id": "2505.22990", "title": "MenTeR: A fully-automated Multi-agenT workflow for end-to-end RF/Analog Circuits Netlist Design", "authors": ["Pin-Han Chen", "Yu-Sheng Lin", "Wei-Cheng Lee", "Tin-Yu Leu", "Po-Hsiang Hsu", "Anjana Dissanayake", "Sungjin Oh", "Chinq-Shiun Chiu"], "abstract": "RF/Analog design is essential for bridging digital technologies with real-world signals, ensuring the functionality and reliability of a wide range of electronic systems. However, analog design procedures are often intricate, time-consuming and reliant on expert intuition, and hinder the time and cost efficiency of circuit development. To overcome the limitations of the manual circuit design, we introduce MenTeR - a multiagent workflow integrated into an end-to-end analog design framework. By employing multiple specialized AI agents that collaboratively address different aspects of the design process, such as specification understanding, circuit optimization, and test bench validation, MenTeR reduces the dependency on frequent trial-and-error-style intervention. MenTeR not only accelerates the design cycle time but also facilitates a broader exploration of the design space, demonstrating robust capabilities in handling real-world analog systems. We believe that MenTeR lays the groundwork for future \"RF/Analog Copilots\" that can collaborate seamlessly with human designers.", "subjects": "Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET); Machine Learning (cs.LG)", "comments": "9 pages, 7 figures, accepted by IEEE ICLAD 2025", "pdf_url": "https://arxiv.org/pdf/2505.22990.pdf", "abstract_url": "https://arxiv.org/abs/2505.22990", "categories": ["Artificial Intelligence (cs.AI)", "Emerging Technologies (cs.ET)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "MenTeR是一个全自动的多代理工作流，用于端到端的RF/模拟电路网表设计，旨在通过AI代理协作减少对人工干预的依赖，加速设计周期并拓宽设计空间探索。", "motivation": "模拟设计过程复杂、耗时且依赖专家直觉，影响了电路开发的时间和成本效率。", "method": "采用多代理工作流，集成多个专门的AI代理，协作处理设计过程的不同方面，如规格理解、电路优化和测试台验证。", "result": "MenTeR减少了频繁的试错式干预需求，加速了设计周期，并能够更广泛地探索设计空间，展示了处理现实世界模拟系统的强大能力。", "conclusion": "MenTeR为未来能与人类设计师无缝协作的“RF/模拟副驾驶”奠定了基础。"}}
{"id": "2505.22960", "title": "Revisiting Multi-Agent Debate as Test-Time Scaling: A Systematic Study of Conditional Effectiveness", "authors": ["Yongjin Yang", "Euiin Yi", "Jongwoo Ko", "Kimin Lee", "Zhijing Jin", "Se-Young Yun"], "abstract": "The remarkable growth in large language model (LLM) capabilities has spurred exploration into multi-agent systems, with debate frameworks emerging as a promising avenue for enhanced problem-solving. These multi-agent debate (MAD) approaches, where agents collaboratively present, critique, and refine arguments, potentially offer improved reasoning, robustness, and diverse perspectives over monolithic models. Despite prior studies leveraging MAD, a systematic understanding of its effectiveness compared to self-agent methods, particularly under varying conditions, remains elusive. This paper seeks to fill this gap by conceptualizing MAD as a test-time computational scaling technique, distinguished by collaborative refinement and diverse exploration capabilities. We conduct a comprehensive empirical investigation comparing MAD with strong self-agent test-time scaling baselines on mathematical reasoning and safety-related tasks. Our study systematically examines the influence of task difficulty, model scale, and agent diversity on MAD's performance. Key findings reveal that, for mathematical reasoning, MAD offers limited advantages over self-agent scaling but becomes more effective with increased problem difficulty and decreased model capability, while agent diversity shows little benefit. Conversely, for safety tasks, MAD's collaborative refinement can increase vulnerability, but incorporating diverse agent configurations facilitates a gradual reduction in attack success through the collaborative refinement process. We believe our findings provide critical guidance for the future development of more effective and strategically deployed MAD systems.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "Preprint, under review", "pdf_url": "https://arxiv.org/pdf/2505.22960.pdf", "abstract_url": "https://arxiv.org/abs/2505.22960", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过将多智能体辩论（MAD）概念化为测试时计算扩展技术，系统地研究了其在数学推理和安全相关任务中的条件有效性。研究发现，MAD在数学推理任务中相对于单智能体方法的优势有限，但在问题难度增加和模型能力降低时更为有效；而在安全任务中，MAD的协作细化可能增加脆弱性，但通过引入多样化的智能体配置可以逐步降低攻击成功率。", "motivation": "尽管多智能体辩论（MAD）作为一种增强问题解决的框架被广泛研究，但其与单智能体方法在不同条件下的有效性比较仍缺乏系统理解。本文旨在填补这一空白。", "method": "本研究将MAD概念化为一种测试时计算扩展技术，并通过在数学推理和安全相关任务上与强单智能体测试时扩展基线进行比较，进行全面的实证调查。", "result": "研究发现，在数学推理任务中，MAD相对于单智能体扩展的优势有限，但随着问题难度的增加和模型能力的降低，MAD变得更加有效；在安全任务中，MAD的协作细化可能增加脆弱性，但通过引入多样化的智能体配置可以逐步降低攻击成功率。", "conclusion": "本文的研究结果为未来开发更有效和战略部署的MAD系统提供了关键指导。"}}
{"id": "2505.23075", "title": "Second Opinion Matters: Towards Adaptive Clinical AI via the Consensus of Expert Model Ensemble", "authors": ["Amit Kumthekar", "Zion Tilley", "Henry Duong", "Bhargav Patel", "Michael Magnoli", "Ahmed Omar", "Ahmed Nasser", "Chaitanya Gharpure", "Yevgen Reztzov"], "abstract": "Despite the growing clinical adoption of large language models (LLMs), current approaches heavily rely on single model architectures. To overcome risks of obsolescence and rigid dependence on single model systems, we present a novel framework, termed the Consensus Mechanism. Mimicking clinical triage and multidisciplinary clinical decision-making, the Consensus Mechanism implements an ensemble of specialized medical expert agents enabling improved clinical decision making while maintaining robust adaptability. This architecture enables the Consensus Mechanism to be optimized for cost, latency, or performance, purely based on its interior model configuration.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "23 pages, 11 figures", "pdf_url": "https://arxiv.org/pdf/2505.23075.pdf", "abstract_url": "https://arxiv.org/abs/2505.23075", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为“共识机制”的新框架，旨在通过专家模型集合的共识来改进临床决策，同时保持强大的适应性。", "motivation": "解决当前大型语言模型（LLMs）在临床应用中过度依赖单一模型架构的问题，以及由此带来的过时风险和刚性依赖。", "method": "模仿临床分诊和多学科临床决策，实现了一个由专业医疗专家代理组成的集合，即共识机制。", "result": "共识机制能够根据其内部模型配置，在成本、延迟或性能方面进行优化，从而改进临床决策。", "conclusion": "共识机制提供了一种灵活且强大的方法，以适应不断变化的临床需求和技术进步，同时提高决策的准确性和可靠性。"}}
{"id": "2505.22942", "title": "WorkForceAgent-R1: Incentivizing Reasoning Capability in LLM-based Web Agents via Reinforcement Learning", "authors": ["Yuchen Zhuang", "Di Jin", "Jiaao Chen", "Wenqi Shi", "Hanrui Wang", "Chao Zhang"], "abstract": "Large language models (LLMs)-empowered web agents enables automating complex, real-time web navigation tasks in enterprise environments. However, existing web agents relying on supervised fine-tuning (SFT) often struggle with generalization and robustness due to insufficient reasoning capabilities when handling the inherently dynamic nature of web interactions. In this study, we introduce WorkForceAgent-R1, an LLM-based web agent trained using a rule-based R1-style reinforcement learning framework designed explicitly to enhance single-step reasoning and planning for business-oriented web navigation tasks. We employ a structured reward function that evaluates both adherence to output formats and correctness of actions, enabling WorkForceAgent-R1 to implicitly learn robust intermediate reasoning without explicit annotations or extensive expert demonstrations. Extensive experiments on the WorkArena benchmark demonstrate that WorkForceAgent-R1 substantially outperforms SFT baselines by 10.26-16.59%, achieving competitive performance relative to proprietary LLM-based agents (gpt-4o) in workplace-oriented web navigation tasks.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "Work in Progress", "pdf_url": "https://arxiv.org/pdf/2505.22942.pdf", "abstract_url": "https://arxiv.org/abs/2505.22942", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "WorkForceAgent-R1是一种基于大型语言模型（LLM）的网络代理，通过强化学习框架增强单步推理和规划能力，用于企业环境中的网络导航任务。", "motivation": "现有的基于监督微调（SFT）的网络代理在处理动态网络交互时，由于推理能力不足，常常面临泛化性和鲁棒性的问题。", "method": "采用基于规则的R1风格强化学习框架，通过结构化奖励函数评估输出格式的遵守和动作的正确性，隐式学习稳健的中间推理。", "result": "在WorkArena基准测试中，WorkForceAgent-R1显著优于SFT基线10.26-16.59%，与专有LLM代理（gpt-4o）在工作导向的网络导航任务中表现相当。", "conclusion": "WorkForceAgent-R1通过强化学习有效提升了LLM网络代理的推理能力，为复杂网络导航任务提供了更强大的解决方案。"}}
{"id": "2505.22961", "title": "ToMAP: Training Opponent-Aware LLM Persuaders with Theory of Mind", "authors": ["Peixuan Han", "Zijia Liu", "Jiaxuan You"], "abstract": "Large language models (LLMs) have shown promising potential in persuasion, but existing works on training LLM persuaders are still preliminary. Notably, while humans are skilled in modeling their opponent's thoughts and opinions proactively and dynamically, current LLMs struggle with such Theory of Mind (ToM) reasoning, resulting in limited diversity and opponent awareness. To address this limitation, we introduce Theory of Mind Augmented Persuader (ToMAP), a novel approach for building more flexible persuader agents by incorporating two theory of mind modules that enhance the persuader's awareness and analysis of the opponent's mental state. Specifically, we begin by prompting the persuader to consider possible objections to the target central claim, and then use a text encoder paired with a trained MLP classifier to predict the opponent's current stance on these counterclaims. Our carefully designed reinforcement learning schema enables the persuader learns how to analyze opponent-related information and utilize it to generate more effective arguments. Experiments show that the ToMAP persuader, while containing only 3B parameters, outperforms much larger baselines, like GPT-4o, with a relative gain of 39.4% across multiple persuadee models and diverse corpora. Notably, ToMAP exhibits complex reasoning chains and reduced repetition during training, which leads to more diverse and effective arguments. The opponent-aware feature of ToMAP also makes it suitable for long conversations and enables it to employ more logical and opponent-aware strategies. These results underscore our method's effectiveness and highlight its potential for developing more persuasive language agents. Code is available at:", "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.22961.pdf", "abstract_url": "https://arxiv.org/abs/2505.22961", "categories": ["Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了ToMAP，一种通过整合两个心智理论模块来增强说服者代理对对手心理状态意识和分析的新方法，旨在解决当前大型语言模型在心智理论推理上的不足。", "motivation": "当前大型语言模型在心智理论推理上存在局限，导致说服策略的多样性和对手意识不足，ToMAP旨在通过增强模型对对手心理状态的理解来提升说服效果。", "method": "ToMAP采用心智理论模块，首先促使说服者考虑对目标核心主张的可能反对意见，然后使用文本编码器和训练好的MLP分类器预测对手对这些反主张的当前立场，并通过精心设计的强化学习模式学习如何分析和利用对手相关信息生成更有效的论点。", "result": "实验显示，仅含3B参数的ToMAP说服者在多个说服模型和多样语料库上的表现优于更大的基线模型（如GPT-4o），相对增益达39.4%，且展现出更复杂的推理链和减少的重复，生成更多样和有效的论点。", "conclusion": "ToMAP的对手意识特性使其适合长对话并能采用更逻辑和对手意识的策略，突出了该方法在开发更具说服力的语言代理方面的有效性和潜力。"}}
{"id": "2505.23153", "title": "Conceptual Framework Toward Embodied Collective Adaptive Intelligence", "authors": ["Fan Wang", "Shaoshan Liu"], "abstract": "Collective Adaptive Intelligence (CAI) represent a transformative approach in artificial intelligence, wherein numerous autonomous agents collaborate, adapt, and self-organize to navigate complex, dynamic environments. This paradigm is particularly impactful in embodied AI applications, where adaptability and resilience are paramount. By enabling systems to reconfigure themselves in response to unforeseen challenges, CAI facilitate robust performance in real-world scenarios. This article introduces a conceptual framework for designing and analyzing CAI. It delineates key attributes including task generalization, resilience, scalability, and self-assembly, aiming to bridge theoretical foundations with practical methodologies for engineering adaptive, emergent intelligence. By providing a structured foundation for understanding and implementing CAI, this work seeks to guide researchers and practitioners in developing more resilient, scalable, and adaptable AI systems across various domains.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23153.pdf", "abstract_url": "https://arxiv.org/abs/2505.23153", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "集体适应性智能（CAI）代表了一种人工智能的变革性方法，其中多个自主代理协作、适应和自我组织以导航复杂、动态的环境。本文介绍了一个设计和分析CAI的概念框架，旨在连接理论基础与工程适应性、涌现智能的实用方法。", "motivation": "解决在复杂动态环境中，如何设计和实现能够协作、适应和自我组织的AI系统，特别是在体现AI应用中，适应性和韧性至关重要的问题。", "method": "引入一个概念框架，明确任务泛化、韧性、可扩展性和自组装等关键属性，旨在为理解和实施CAI提供结构化基础。", "result": "提出了一个指导研究和实践者在多个领域开发更韧性、可扩展和适应性AI系统的框架。", "conclusion": "通过提供一个结构化的基础，这项工作旨在指导研究和实践者在开发更韧性、可扩展和适应性AI系统方面取得进展，跨越各种领域。"}}
{"id": "2505.23399", "title": "GAM-Agent: Game-Theoretic and Uncertainty-Aware Collaboration for Complex Visual Reasoning", "authors": ["Jusheng Zhang", "Yijia Fan", "Wenjun Lin", "Ruiqi Chen", "Haoyi Jiang", "Wenhao Chai", "Jian Wang", "Keze Wang"], "abstract": "We propose GAM-Agent, a game-theoretic multi-agent framework for enhancing vision-language reasoning. Unlike prior single-agent or monolithic models, GAM-Agent formulates the reasoning process as a non-zero-sum game between base agents--each specializing in visual perception subtasks--and a critical agent that verifies logic consistency and factual correctness. Agents communicate via structured claims, evidence, and uncertainty estimates. The framework introduces an uncertainty-aware controller to dynamically adjust agent collaboration, triggering multi-round debates when disagreement or ambiguity is detected. This process yields more robust and interpretable predictions. Experiments on four challenging benchmarks--MMMU, MMBench, MVBench, and V*Bench--demonstrate that GAM-Agent significantly improves performance across various VLM backbones. Notably, GAM-Agent boosts the accuracy of small-to-mid scale models (e.g., Qwen2.5-VL-7B, InternVL3-14B) by 5--6\\%, and still enhances strong models like GPT-4o by up to 2--3\\%. Our approach is modular, scalable, and generalizable, offering a path toward reliable and explainable multi-agent multimodal reasoning.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23399.pdf", "abstract_url": "https://arxiv.org/abs/2505.23399", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "GAM-Agent是一个基于博弈论的多智能体框架，旨在增强视觉语言推理能力。通过将推理过程建模为非零和游戏，结合不确定性感知控制器动态调整智能体协作，显著提升了多种视觉语言模型在复杂视觉推理任务上的性能。", "motivation": "解决现有单智能体或单体模型在复杂视觉推理任务中的局限性，通过多智能体协作提高推理的鲁棒性和可解释性。", "method": "采用博弈论框架，将推理过程设计为由基础智能体和关键智能体参与的非零和游戏，通过结构化声明、证据和不确定性估计进行通信，并引入不确定性感知控制器动态调整协作策略。", "result": "在MMMU、MMBench、MVBench和V*Bench四个基准测试中，GAM-Agent显著提升了各种视觉语言模型的性能，特别是中小规模模型准确率提高了5-6%，强模型如GPT-4o也有2-3%的提升。", "conclusion": "GAM-Agent提供了一种模块化、可扩展且通用的方法，为可靠和可解释的多智能体多模态推理开辟了新路径。"}}
{"id": "2505.23436", "title": "Emergent Risk Awareness in Rational Agents under Resource Constraints", "authors": ["Daniel Jarne Ornia", "Nicholas Bishop", "Joel Dyer", "Wei-Chen Lee", "Ani Calinescu", "Doyne Farme", "Michael Wooldridge"], "abstract": "Advanced reasoning models with agentic capabilities (AI agents) are deployed to interact with humans and to solve sequential decision-making problems under (approximate) utility functions and internal models. When such problems have resource or failure constraints where action sequences may be forcibly terminated once resources are exhausted, agents face implicit trade-offs that reshape their utility-driven (rational) behaviour. Additionally, since these agents are typically commissioned by a human principal to act on their behalf, asymmetries in constraint exposure can give rise to previously unanticipated misalignment between human objectives and agent incentives. We formalise this setting through a survival bandit framework, provide theoretical and empirical results that quantify the impact of survival-driven preference shifts, identify conditions under which misalignment emerges and propose mechanisms to mitigate the emergence of risk-seeking or risk-averse behaviours. As a result, this work aims to increase understanding and interpretability of emergent behaviours of AI agents operating under such survival pressure, and offer guidelines for safely deploying such AI systems in critical resource-limited environments.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23436.pdf", "abstract_url": "https://arxiv.org/abs/2505.23436", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文探讨了在资源约束下，具有代理能力的高级推理模型（AI代理）如何在与人类互动和解决顺序决策问题时，因资源或失败约束而面临的行为变化。通过生存多臂老虎机框架，作者量化了生存驱动的偏好转变的影响，识别了对齐失调出现的条件，并提出了缓解风险寻求或风险规避行为出现的机制。", "motivation": "解决在资源有限的环境中，AI代理因生存压力而可能出现的与人类目标不一致的行为问题。", "method": "使用生存多臂老虎机框架，结合理论和实证研究，分析生存驱动的偏好转变及其影响。", "result": "量化了生存压力对AI代理行为的影响，识别了对齐失调的条件，并提出了缓解机制。", "conclusion": "本研究提高了对在生存压力下操作的AI代理行为的理解和可解释性，为在关键资源有限环境中安全部署此类AI系统提供了指导。"}}
{"id": "2505.23474", "title": "Socratic-PRMBench: Benchmarking Process Reward Models with Systematic Reasoning Patterns", "authors": ["Xiang Li", "Haiyang Yu", "Xinghua Zhang", "Ziyang Huang", "Shizhu He", "Kang Liu", "Jun Zhao", "Fei Huang", "Yongbin Li"], "abstract": "Process Reward Models (PRMs) are crucial in complex reasoning and problem-solving tasks (e.g., LLM agents with long-horizon decision-making) by verifying the correctness of each intermediate reasoning step. In real-world scenarios, LLMs may apply various reasoning patterns (e.g., decomposition) to solve a problem, potentially suffering from errors under various reasoning patterns. Therefore, PRMs are required to identify errors under various reasoning patterns during the reasoning process. However, existing benchmarks mainly focus on evaluating PRMs with stepwise correctness, ignoring a systematic evaluation of PRMs under various reasoning patterns. To mitigate this gap, we introduce Socratic-PRMBench, a new benchmark to evaluate PRMs systematically under six reasoning patterns, including Transformation, Decomposition, Regather, Deduction, Verification, and Integration. Socratic-PRMBench}comprises 2995 reasoning paths with flaws within the aforementioned six reasoning patterns. Through our experiments on both PRMs and LLMs prompted as critic models, we identify notable deficiencies in existing PRMs. These observations underscore the significant weakness of current PRMs in conducting evaluations on reasoning steps under various reasoning patterns. We hope Socratic-PRMBench can serve as a comprehensive testbed for systematic evaluation of PRMs under diverse reasoning patterns and pave the way for future development of PRMs.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23474.pdf", "abstract_url": "https://arxiv.org/abs/2505.23474", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了Socratic-PRMBench，一个新的基准测试，旨在系统评估过程奖励模型（PRMs）在六种推理模式下的表现，揭示了现有PRMs在多样化推理模式评估中的显著不足。", "motivation": "解决现有基准测试主要关注逐步正确性评估，而忽视了对PRMs在各种推理模式下系统评估的问题。", "method": "引入Socratic-PRMBench基准测试，包含2995条在六种推理模式（如转换、分解、重新聚集等）中存在缺陷的推理路径，用于评估PRMs和作为批评模型的LLMs。", "result": "实验发现现有PRMs在多样化推理模式下的评估存在显著弱点。", "conclusion": "Socratic-PRMBench可作为PRMs在多样化推理模式下系统评估的综合测试平台，为PRMs的未来发展铺平道路。"}}
{"id": "2505.23559", "title": "SafeScientist: Toward Risk-Aware Scientific Discoveries by LLM Agents", "authors": ["Kunlun Zhu", "Jiaxun Zhang", "Ziheng Qi", "Nuoxing Shang", "Zijia Liu", "Peixuan Han", "Yue Su", "Haofei Yu", "Jiaxuan You"], "abstract": "Recent advancements in large language model (LLM) agents have significantly accelerated scientific discovery automation, yet concurrently raised critical ethical and safety concerns. To systematically address these challenges, we introduce \\textbf{SafeScientist}, an innovative AI scientist framework explicitly designed to enhance safety and ethical responsibility in AI-driven scientific exploration. SafeScientist proactively refuses ethically inappropriate or high-risk tasks and rigorously emphasizes safety throughout the research process. To achieve comprehensive safety oversight, we integrate multiple defensive mechanisms, including prompt monitoring, agent-collaboration monitoring, tool-use monitoring, and an ethical reviewer component. Complementing SafeScientist, we propose \\textbf{SciSafetyBench}, a novel benchmark specifically designed to evaluate AI safety in scientific contexts, comprising 240 high-risk scientific tasks across 6 domains, alongside 30 specially designed scientific tools and 120 tool-related risk tasks. Extensive experiments demonstrate that SafeScientist significantly improves safety performance by 35\\% compared to traditional AI scientist frameworks, without compromising scientific output quality. Additionally, we rigorously validate the robustness of our safety pipeline against diverse adversarial attack methods, further confirming the effectiveness of our integrated approach. The code and data will be available at", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23559.pdf", "abstract_url": "https://arxiv.org/abs/2505.23559", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了SafeScientist，一个旨在提高AI驱动科学探索安全性和伦理责任的新型AI科学家框架，以及SciSafetyBench，一个评估科学背景下AI安全性的新基准。通过集成多种防御机制，SafeScientist显著提高了安全性表现，同时不牺牲科学输出质量。", "motivation": "解决大型语言模型(LLM)代理在加速科学发现自动化过程中引发的伦理和安全问题。", "method": "开发了SafeScientist框架，集成了提示监控、代理协作监控、工具使用监控和伦理审查组件等多种防御机制，并提出了SciSafetyBench基准进行评估。", "result": "实验表明，SafeScientist相比传统AI科学家框架，安全性表现提高了35%，且科学输出质量未受影响。", "conclusion": "SafeScientist和SciSafetyBench为AI驱动的科学探索提供了一种风险意识和伦理责任增强的方法，有效提高了安全性。"}}
{"id": "2505.23518", "title": "TRAP: Targeted Redirecting of Agentic Preferences", "authors": ["Hangoo Kang", "Jehyeok Yeon", "Gagandeep Singh"], "abstract": "Autonomous agentic AI systems powered by vision-language models (VLMs) are rapidly advancing toward real-world deployment, yet their cross-modal reasoning capabilities introduce new attack surfaces for adversarial manipulation that exploit semantic reasoning across modalities. Existing adversarial attacks typically rely on visible pixel perturbations or require privileged model or environment access, making them impractical for stealthy, real-world exploitation. We introduce TRAP, a generative adversarial framework that manipulates the agent's decision-making using diffusion-based semantic injections. Our method combines negative prompt-based degradation with positive semantic optimization, guided by a Siamese semantic network and layout-aware spatial masking. Without requiring access to model internals, TRAP produces visually natural images yet induces consistent selection biases in agentic AI systems. We evaluate TRAP on the Microsoft Common Objects in Context (COCO) dataset, building multi-candidate decision scenarios. Across these scenarios, TRAP achieves a 100% attack success rate on leading models, including LLaVA-34B, Gemma3, and Mistral-3.1, significantly outperforming baselines such as SPSA, Bandit, and standard diffusion approaches. These results expose a critical vulnerability: Autonomous agents can be consistently misled through human-imperceptible cross-modal manipulations. These findings highlight the need for defense strategies beyond pixel-level robustness to address semantic vulnerabilities in cross-modal decision-making.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23518.pdf", "abstract_url": "https://arxiv.org/abs/2505.23518", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了TRAP，一种生成对抗框架，通过扩散基础的语义注入操纵自主代理AI系统的决策，无需访问模型内部即可在视觉自然图像中诱导选择偏见，展示了跨模态语义操纵的严重漏洞。", "motivation": "随着基于视觉语言模型（VLMs）的自主代理AI系统向现实世界部署快速推进，其跨模态推理能力引入了新的对抗操纵攻击面，现有攻击方法依赖可见像素扰动或需要特权模型或环境访问，不适合隐蔽的现实世界利用。", "method": "TRAP结合了基于负面提示的退化与正面语义优化，由Siamese语义网络和布局感知空间掩码指导，无需模型内部访问即可生成视觉自然图像，同时诱导代理AI系统的选择偏见。", "result": "在Microsoft COCO数据集上构建的多候选决策场景中，TRAP对包括LLaVA-34B、Gemma3和Mistral-3.1在内的领先模型实现了100%的攻击成功率，显著优于SPSA、Bandit和标准扩散方法等基线。", "conclusion": "这些结果揭示了自主代理AI系统可以通过人类难以察觉的跨模态操纵被一致误导的关键漏洞，强调了需要超越像素级鲁棒性的防御策略以解决跨模态决策中的语义漏洞。"}}
{"id": "2505.22993", "title": "Verify-in-the-Graph: Entity Disambiguation Enhancement for Complex Claim Verification with Interactive Graph Representation", "authors": ["Hoang Pham", "Thanh-Do Nguyen", "Khac-Hoai Nam Bui"], "abstract": "Claim verification is a long-standing and challenging task that demands not only high accuracy but also explainability of the verification process. This task becomes an emerging research issue in the era of large language models (LLMs) since real-world claims are often complex, featuring intricate semantic structures or obfuscated entities. Traditional approaches typically address this by decomposing claims into sub-claims and querying a knowledge base to resolve hidden or ambiguous entities. However, the absence of effective disambiguation strategies for these entities can compromise the entire verification process. To address these challenges, we propose Verify-in-the-Graph (VeGraph), a novel framework leveraging the reasoning and comprehension abilities of LLM agents. VeGraph operates in three phases: (1) Graph Representation - an input claim is decomposed into structured triplets, forming a graph-based representation that integrates both structured and unstructured information; (2) Entity Disambiguation -VeGraph iteratively interacts with the knowledge base to resolve ambiguous entities within the graph for deeper sub-claim verification; and (3) Verification - remaining triplets are verified to complete the fact-checking process. Experiments using Meta-Llama-3-70B (instruct version) show that VeGraph achieves competitive performance compared to baselines on two benchmarks HoVer and FEVEROUS, effectively addressing claim verification challenges. Our source code and data are available for further exploitation.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Databases (cs.DB); Information Retrieval (cs.IR)", "comments": "Published at NAACL 2025 Main Conference", "pdf_url": "https://arxiv.org/pdf/2505.22993.pdf", "abstract_url": "https://arxiv.org/abs/2505.22993", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Databases (cs.DB)", "Information Retrieval (cs.IR)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为Verify-in-the-Graph（VeGraph）的新框架，旨在通过利用大型语言模型（LLMs）的推理和理解能力，解决复杂声明验证中的实体消歧问题。VeGraph通过图形表示、实体消歧和验证三个阶段，有效地提高了声明的验证准确性和可解释性。", "motivation": "在大型语言模型（LLMs）时代，复杂声明的验证成为一个新兴的研究问题，因为这些声明往往具有复杂的语义结构或模糊的实体。传统的验证方法由于缺乏有效的实体消歧策略，可能会影响整个验证过程。", "method": "VeGraph框架分为三个阶段：图形表示（将输入声明分解为结构化的三元组，形成基于图形的表示）、实体消歧（与知识库迭代交互以解决图形中的模糊实体）和验证（验证剩余的三元组以完成事实检查过程）。", "result": "使用Meta-Llama-3-70B（指令版本）进行的实验表明，VeGraph在两个基准测试HoVer和FEVEROUS上实现了与基线相比具有竞争力的性能，有效解决了声明验证的挑战。", "conclusion": "VeGraph通过结合图形表示和LLMs的推理能力，为复杂声明验证提供了一种有效的解决方案，不仅提高了验证的准确性，也增强了验证过程的可解释性。"}}
{"id": "2505.23006", "title": "A Practical Approach for Building Production-Grade Conversational Agents with Workflow Graphs", "authors": ["Chiwan Park", "Wonjun Jang", "Daeryong Kim", "Aelim Ahn", "Kichang Yang", "Woosung Hwang", "Jihyeon Roh", "Hyerin Park", "Hyosun Wang", "Min Seok Kim", "Jihoon Kang"], "abstract": "The advancement of Large Language Models (LLMs) has led to significant improvements in various service domains, including search, recommendation, and chatbot applications. However, applying state-of-the-art (SOTA) research to industrial settings presents challenges, as it requires maintaining flexible conversational abilities while also strictly complying with service-specific constraints. This can be seen as two conflicting requirements due to the probabilistic nature of LLMs. In this paper, we propose our approach to addressing this challenge and detail the strategies we employed to overcome their inherent limitations in real-world applications. We conduct a practical case study of a conversational agent designed for the e-commerce domain, detailing our implementation workflow and optimizations. Our findings provide insights into bridging the gap between academic research and real-world application, introducing a framework for developing scalable, controllable, and reliable AI-driven agents.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "Accepted to ACL 2025 Industry Track. 12 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2505.23006.pdf", "abstract_url": "https://arxiv.org/abs/2505.23006", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种通过工作流图构建生产级对话代理的实用方法，旨在解决将最先进的大型语言模型（LLMs）应用于工业环境时面临的挑战，特别是在保持灵活对话能力的同时严格遵守服务特定约束的问题。", "motivation": "大型语言模型（LLMs）的进步虽然在搜索、推荐和聊天机器人等多个服务领域带来了显著改进，但在工业应用中，如何平衡灵活对话能力与服务特定约束的要求仍是一大挑战。", "method": "作者提出了一种方法，通过工作流图来构建对话代理，详细介绍了在电子商务领域的实际案例研究中采用的实施工作流程和优化策略。", "result": "研究发现，通过提出的框架可以有效地缩小学术研究与实际应用之间的差距，开发出可扩展、可控且可靠的AI驱动代理。", "conclusion": "本文的结论是，通过采用工作流图的方法，可以有效地解决在工业应用中应用大型语言模型时遇到的挑战，为开发高效、可靠的对话代理提供了实用的框架和策略。"}}
{"id": "2505.23052", "title": "Query Routing for Retrieval-Augmented Language Models", "authors": ["Jiarui Zhang", "Xiangyu Liu", "Yong Hu", "Chaoyue Niu", "Fan Wu", "Guihai Chen"], "abstract": "Retrieval-Augmented Generation (RAG) significantly improves the performance of Large Language Models (LLMs) on knowledge-intensive tasks. However, varying response quality across LLMs under RAG necessitates intelligent routing mechanisms, which select the most suitable model for each query from multiple retrieval-augmented LLMs via a dedicated router model. We observe that external documents dynamically affect LLMs' ability to answer queries, while existing routing methods, which rely on static parametric knowledge representations, exhibit suboptimal performance in RAG scenarios. To address this, we formally define the new retrieval-augmented LLM routing problem, incorporating the influence of retrieved documents into the routing framework. We propose RAGRouter, a RAG-aware routing design, which leverages document embeddings and RAG capability embeddings with contrastive learning to capture knowledge representation shifts and enable informed routing decisions. Extensive experiments on diverse knowledge-intensive tasks and retrieval settings show that RAGRouter outperforms the best individual LLM by 3.61% on average and existing routing methods by 3.29%-9.33%. With an extended score-threshold-based mechanism, it also achieves strong performance-efficiency trade-offs under low-latency constraints.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23052.pdf", "abstract_url": "https://arxiv.org/abs/2505.23052", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了RAGRouter，一种针对检索增强生成（RAG）场景下的大型语言模型（LLMs）的智能路由机制，旨在通过考虑检索文档的影响，优化模型选择，提高知识密集型任务的性能。", "motivation": "解决在检索增强生成（RAG）场景下，由于外部文档动态影响LLMs回答查询的能力，现有基于静态参数知识表示的路由方法表现不佳的问题。", "method": "提出RAGRouter，一种RAG感知的路由设计，利用文档嵌入和RAG能力嵌入与对比学习，捕捉知识表示的变化，实现明智的路由决策。", "result": "在多种知识密集型任务和检索设置上的广泛实验显示，RAGRouter平均比最佳单个LLM性能提高3.61%，比现有路由方法提高3.29%-9.33%。", "conclusion": "RAGRouter不仅提高了性能，还通过扩展的基于分数阈值的机制，在低延迟约束下实现了强性能-效率权衡。"}}
{"id": "2505.23596", "title": "MAPLE: A Mobile Assistant with Persistent Finite State Machines for Recovery Reasoning", "authors": ["Linqiang Guo", "Wei Liu", "Yi Wen Heng", "Tse-Hsun", "Chen", "Yang Wang"], "abstract": "Mobile GUI agents aim to autonomously complete user-instructed tasks across mobile apps. Recent advances in Multimodal Large Language Models (MLLMs) enable these agents to interpret UI screens, identify actionable elements, and perform interactions such as tapping or typing. However, existing agents remain reactive: they reason only over the current screen and lack a structured model of app navigation flow, limiting their ability to understand context, detect unexpected outcomes, and recover from errors. We present MAPLE, a state-aware multi-agent framework that abstracts app interactions as a Finite State Machine (FSM). We computationally model each UI screen as a discrete state and user actions as transitions, allowing the FSM to provide a structured representation of the app execution. MAPLE consists of specialized agents responsible for four phases of task execution: planning, execution, verification, error recovery, and knowledge retention. These agents collaborate to dynamically construct FSMs in real time based on perception data extracted from the UI screen, allowing the GUI agents to track navigation progress and flow, validate action outcomes through pre- and post-conditions of the states, and recover from errors by rolling back to previously stable states. Our evaluation results on two challenging cross-app benchmarks, Mobile-Eval-E and SPA-Bench, show that MAPLE outperforms the state-of-the-art baseline, improving task success rate by up to 12%, recovery success by 13.8%, and action accuracy by 6.5%. Our results highlight the importance of structured state modeling in guiding mobile GUI agents during task execution. Moreover, our FSM representation can be integrated into future GUI agent architectures as a lightweight, model-agnostic memory layer to support structured planning, execution verification, and error recovery.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23596.pdf", "abstract_url": "https://arxiv.org/abs/2505.23596", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "MAPLE是一种基于有限状态机（FSM）的状态感知多代理框架，旨在提升移动GUI代理的任务执行能力，通过实时构建FSM来跟踪导航进度、验证动作结果并从错误中恢复。", "motivation": "解决现有移动GUI代理在理解上下文、检测意外结果和从错误中恢复方面的局限性。", "method": "将应用交互抽象为有限状态机（FSM），每个UI屏幕建模为一个离散状态，用户动作为转换，通过专门代理协作实时构建FSM。", "result": "在两个跨应用基准测试中，MAPLE显著提高了任务成功率、恢复成功率和动作准确性。", "conclusion": "结构化状态建模对指导移动GUI代理任务执行至关重要，FSM表示可作为轻量级、模型无关的内存层集成到未来GUI代理架构中。"}}
{"id": "2505.23695", "title": "Data-to-Dashboard: Multi-Agent LLM Framework for Insightful Visualization in Enterprise Analytics", "authors": ["Ran Zhang", "Mohannad Elhamod"], "abstract": "The rapid advancement of LLMs has led to the creation of diverse agentic systems in data analysis, utilizing LLMs' capabilities to improve insight generation and visualization. In this paper, we present an agentic system that automates the data-to-dashboard pipeline through modular LLM agents capable of domain detection, concept extraction, multi-perspective analysis generation, and iterative self-reflection. Unlike existing chart QA systems, our framework simulates the analytical reasoning process of business analysts by retrieving domain-relevant knowledge and adapting to diverse datasets without relying on closed ontologies or question templates.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23695.pdf", "abstract_url": "https://arxiv.org/abs/2505.23695", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了一种利用LLM（大型语言模型）技术的多代理系统，旨在自动化数据到仪表板的流程，通过模块化LLM代理实现领域检测、概念提取、多视角分析生成和迭代自我反思，以模拟业务分析师的推理过程。", "motivation": "解决在数据分析中如何更有效地生成见解和可视化的问题，特别是在不依赖封闭本体或问题模板的情况下，适应多样化的数据集。", "method": "采用模块化LLM代理，包括领域检测、概念提取、多视角分析生成和迭代自我反思，以模拟业务分析师的推理过程。", "result": "开发了一个能够自动执行数据到仪表板流程的代理系统，能够检索领域相关知识并适应多样化数据集。", "conclusion": "该框架展示了LLM在自动化数据分析和可视化方面的潜力，为企业在不依赖预设模板或封闭系统的情况下提供了灵活的解决方案。"}}
{"id": "2505.23686", "title": "ROTATE: Regret-driven Open-ended Training for Ad Hoc Teamwork", "authors": ["Caroline Wang", "Arrasy Rahman", "Jiaxun Cui", "Yoonchang Sung", "Peter Stone"], "abstract": "Developing AI agents capable of collaborating with previously unseen partners is a fundamental generalization challenge in multi-agent learning, known as Ad Hoc Teamwork (AHT). Existing AHT approaches typically adopt a two-stage pipeline, where first, a fixed population of teammates is generated with the idea that they should be representative of the teammates that will be seen at deployment time, and second, an AHT agent is trained to collaborate well with agents in the population. To date, the research community has focused on designing separate algorithms for each stage. This separation has led to algorithms that generate teammate pools with limited coverage of possible behaviors, and that ignore whether the generated teammates are easy to learn from for the AHT agent. Furthermore, algorithms for training AHT agents typically treat the set of training teammates as static, thus attempting to generalize to previously unseen partner agents without assuming any control over the distribution of training teammates. In this paper, we present a unified framework for AHT by reformulating the problem as an open-ended learning process between an ad hoc agent and an adversarial teammate generator. We introduce ROTATE, a regret-driven, open-ended training algorithm that alternates between improving the AHT agent and generating teammates that probe its deficiencies. Extensive experiments across diverse AHT environments demonstrate that ROTATE significantly outperforms baselines at generalizing to an unseen set of evaluation teammates, thus establishing a new standard for robust and generalizable teamwork.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23686.pdf", "abstract_url": "https://arxiv.org/abs/2505.23686", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了ROTATE，一种用于Ad Hoc Teamwork（AHT）的遗憾驱动、开放式训练算法，旨在通过交替改进AHT代理和生成探测其缺陷的队友，提高与未见队友的协作能力。", "motivation": "解决多智能体学习中与未见伙伴协作的泛化挑战，现有AHT方法在生成队友池和训练AHT代理时存在局限，如队友行为覆盖有限和忽视训练队友的易学性。", "method": "提出一个统一框架，将AHT问题重新表述为AHT代理与对抗性队友生成器之间的开放式学习过程，引入ROTATE算法交替优化AHT代理和生成挑战其的队友。", "result": "在多样化的AHT环境中进行的广泛实验表明，ROTATE在泛化到未见评估队友方面显著优于基线方法。", "conclusion": "ROTATE为健壮和可泛化的团队合作设立了新标准，通过开放式学习过程有效提高了AHT代理的协作能力。"}}
{"id": "2505.23762", "title": "ZeroGUI: Automating Online GUI Learning at Zero Human Cost", "authors": ["Chenyu Yang", "Shiqian Su", "Shi Liu", "Xuan Dong", "Yue Yu", "Weijie Su", "Xuehui Wang", "Zhaoyang Liu", "Jinguo Zhu", "Hao Li", "Wenhai Wang", "Yu Qiao", "Xizhou Zhu", "Jifeng Dai"], "abstract": "The rapid advancement of large Vision-Language Models (VLMs) has propelled the development of pure-vision-based GUI Agents, capable of perceiving and operating Graphical User Interfaces (GUI) to autonomously fulfill user instructions. However, existing approaches usually adopt an offline learning framework, which faces two core limitations: (1) heavy reliance on high-quality manual annotations for element grounding and action supervision, and (2) limited adaptability to dynamic and interactive environments. To address these limitations, we propose ZeroGUI, a scalable, online learning framework for automating GUI Agent training at Zero human cost. Specifically, ZeroGUI integrates (i) VLM-based automatic task generation to produce diverse training goals from the current environment state, (ii) VLM-based automatic reward estimation to assess task success without hand-crafted evaluation functions, and (iii) two-stage online reinforcement learning to continuously interact with and learn from GUI environments. Experiments on two advanced GUI Agents (UI-TARS and Aguvis) demonstrate that ZeroGUI significantly boosts performance across OSWorld and AndroidLab environments. The code is available at", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23762.pdf", "abstract_url": "https://arxiv.org/abs/2505.23762", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "ZeroGUI是一个可扩展的在线学习框架，旨在零人工成本下自动化GUI代理的训练。它通过整合基于VLM的自动任务生成和奖励估计，以及两阶段在线强化学习，解决了现有离线学习方法对高质量手动注释的依赖和动态交互环境适应性有限的问题。", "motivation": "解决现有纯视觉GUI代理离线学习方法对高质量手动注释的依赖和动态交互环境适应性有限的问题。", "method": "ZeroGUI整合了基于VLM的自动任务生成、基于VLM的自动奖励估计和两阶段在线强化学习。", "result": "在UI-TARS和Aguvis两个高级GUI代理上的实验表明，ZeroGUI在OSWorld和AndroidLab环境中显著提升了性能。", "conclusion": "ZeroGUI框架有效地自动化了GUI代理的训练，无需人工干预，显著提高了在动态和交互环境中的适应性和性能。"}}
{"id": "2505.22673", "title": "Physiology-Informed Generative Multi-Task Network for Contrast-Free CT Perfusion", "authors": ["Wasif Khan", "Kyle B. See", "Simon Kato", "Ziqian Huang", "Amy Lazarte", "Kyle Douglas", "Xiangyang Lou", "Teng J. Peng", "Dhanashree Rajderkar", "John Rees", "Pina Sanelli", "Amita Singh", "Ibrahim Tuna", "Christina A. Wilson", "Ruogu Fang"], "abstract": "Perfusion imaging is extensively utilized to assess hemodynamic status and tissue perfusion in various organs. Computed tomography perfusion (CTP) imaging plays a key role in the early assessment and planning of stroke treatment. While CTP provides essential perfusion parameters to identify abnormal blood flow in the brain, the use of contrast agents in CTP can lead to allergic reactions and adverse side effects, along with costing USD 4.9 billion worldwide in 2022. To address these challenges, we propose a novel deep learning framework called Multitask Automated Generation of Intermodal CT perfusion maps (MAGIC). This framework combines generative artificial intelligence and physiological information to map non-contrast computed tomography (CT) imaging to multiple contrast-free CTP imaging maps. We demonstrate enhanced image fidelity by incorporating physiological characteristics into the loss terms. Our network was trained and validated using CT image data from patients referred for stroke at UF Health and demonstrated robustness to abnormalities in brain perfusion activity. A double-blinded study was conducted involving seven experienced neuroradiologists and vascular neurologists. This study validated MAGIC's visual quality and diagnostic accuracy showing favorable performance compared to clinical perfusion imaging with intravenous contrast injection. Overall, MAGIC holds great promise in revolutionizing healthcare by offering contrast-free, cost-effective, and rapid perfusion imaging.", "subjects": "Tissues and Organs (q-bio.TO); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "comments": "Under Review", "pdf_url": "https://arxiv.org/pdf/2505.22673.pdf", "abstract_url": "https://arxiv.org/abs/2505.22673", "categories": ["Tissues and Organs (q-bio.TO)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为MAGIC的新型深度学习框架，旨在通过生成人工智能和生理信息将非对比计算机断层扫描（CT）成像映射到多个无对比剂的CT灌注成像图，以解决对比剂在CT灌注成像中引起的过敏反应和副作用问题。", "motivation": "CT灌注成像在早期评估和中风治疗规划中扮演关键角色，但使用对比剂可能导致过敏反应和不良副作用，且全球成本高昂。本文旨在解决这些问题。", "method": "提出了一种结合生成人工智能和生理信息的多任务自动化生成跨模态CT灌注图（MAGIC）的深度学习框架，通过在损失项中融入生理特征来增强图像保真度。", "result": "MAGIC在视觉质量和诊断准确性方面显示出优于临床灌注成像的性能，且对脑灌注活动的异常表现出鲁棒性。", "conclusion": "MAGIC有望通过提供无对比剂、成本效益高且快速的灌注成像，革新医疗保健领域。"}}
{"id": "2505.23187", "title": "Cross-Task Experiential Learning on LLM-based Multi-Agent Collaboration", "authors": ["Yilong Li", "Chen Qian", "Yu Xia", "Ruijie Shi", "Yufan Dang", "Zihao Xie", "Ziming You", "Weize Chen", "Cheng Yang", "Weichuan Liu", "Ye Tian", "Xuantang Xiong", "Lei Han", "Zhiyuan Liu", "Maosong Sun"], "abstract": "Large Language Model-based multi-agent systems (MAS) have shown remarkable progress in solving complex tasks through collaborative reasoning and inter-agent critique. However, existing approaches typically treat each task in isolation, resulting in redundant computations and limited generalization across structurally similar tasks. To address this, we introduce multi-agent cross-task experiential learning (MAEL), a novel framework that endows LLM-driven agents with explicit cross-task learning and experience accumulation. We model the task-solving workflow on a graph-structured multi-agent collaboration network, where agents propagate information and coordinate via explicit connectivity. During the experiential learning phase, we quantify the quality for each step in the task-solving workflow and store the resulting rewards along with the corresponding inputs and outputs into each agent's individual experience pool. During inference, agents retrieve high-reward, task-relevant experiences as few-shot examples to enhance the effectiveness of each reasoning step, thereby enabling more accurate and efficient multi-agent collaboration. Experimental results on diverse datasets demonstrate that MAEL empowers agents to learn from prior task experiences effectively-achieving faster convergence and producing higher-quality solutions on current tasks.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "Work in Progress", "pdf_url": "https://arxiv.org/pdf/2505.23187.pdf", "abstract_url": "https://arxiv.org/abs/2505.23187", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于大型语言模型的多智能体跨任务经验学习框架（MAEL），旨在通过跨任务学习和经验积累，提高多智能体系统在结构相似任务上的协作效率和解决方案质量。", "motivation": "现有的多智能体系统在处理复杂任务时，通常将每个任务视为独立，导致计算冗余和在结构相似任务间泛化能力有限。", "method": "作者提出了MAEL框架，通过图结构的多智能体协作网络建模任务解决流程，智能体通过显式连接传播信息和协调。在经验学习阶段，量化任务解决流程中每一步的质量，并将奖励与相应的输入输出存储到每个智能体的个体经验池中。在推理时，智能体检索高奖励、任务相关的经验作为少样本示例，以增强每一步推理的有效性。", "result": "在多样化数据集上的实验结果表明，MAEL能够有效使智能体从先前的任务经验中学习，实现更快的收敛速度，并在当前任务上产生更高质量的解决方案。", "conclusion": "MAEL框架通过跨任务经验学习，显著提升了多智能体协作的准确性和效率，为解决复杂任务提供了一种新的有效方法。"}}
{"id": "2505.22814", "title": "A Large Language Model-Enabled Control Architecture for Dynamic Resource Capability Exploration in Multi-Agent Manufacturing Systems", "authors": ["Jonghan Lim", "Ilya Kovalenko"], "abstract": "Manufacturing environments are becoming more complex and unpredictable due to factors such as demand variations and shorter product lifespans. This complexity requires real-time decision-making and adaptation to disruptions. Traditional control approaches highlight the need for advanced control strategies capable of overcoming unforeseen challenges, as they demonstrate limitations in responsiveness within dynamic industrial settings. Multi-agent systems address these challenges through decentralization of decision-making, enabling systems to respond dynamically to operational changes. However, current multi-agent systems encounter challenges related to real-time adaptation, context-aware decision-making, and the dynamic exploration of resource capabilities. Large language models provide the possibility to overcome these limitations through context-aware decision-making capabilities. This paper introduces a large language model-enabled control architecture for multi-agent manufacturing systems to dynamically explore resource capabilities in response to real-time disruptions. A simulation-based case study demonstrates that the proposed architecture improves system resilience and flexibility. The case study findings show improved throughput and efficient resource utilization compared to existing approaches.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.22814.pdf", "abstract_url": "https://arxiv.org/abs/2505.22814", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于大型语言模型的控制架构，用于多代理制造系统中动态探索资源能力，以应对实时干扰。通过模拟案例研究，证明了该架构在提高系统韧性和灵活性方面的有效性。", "motivation": "制造环境因需求变化和产品生命周期缩短而变得更加复杂和不可预测，传统控制方法在动态工业环境中的响应能力有限，多代理系统虽能通过决策分散化应对这些挑战，但在实时适应、上下文感知决策和资源能力动态探索方面仍面临挑战。", "method": "引入了一种大型语言模型支持的控制架构，用于多代理制造系统，以动态探索资源能力并应对实时干扰。", "result": "案例研究结果表明，与现有方法相比，所提出的架构提高了吞吐量和资源利用效率。", "conclusion": "大型语言模型支持的控制架构为多代理制造系统提供了一种有效的方法，以提高其在面对实时干扰时的韧性和灵活性，从而改善了制造系统的性能。"}}
{"id": "2505.23481", "title": "PhysicsNeRF: Physics-Guided 3D Reconstruction from Sparse Views", "authors": ["Mohamed Rayan Barhdadi", "Hasan Kurban", "Hussein Alnuweiri"], "abstract": "PhysicsNeRF is a physically grounded framework for 3D reconstruction from sparse views, extending Neural Radiance Fields with four complementary constraints: depth ranking, RegNeRF-style consistency, sparsity priors, and cross-view alignment. While standard NeRFs fail under sparse supervision, PhysicsNeRF employs a compact 0.67M-parameter architecture and achieves 21.4 dB average PSNR using only 8 views, outperforming prior methods. A generalization gap of 5.7-6.2 dB is consistently observed and analyzed, revealing fundamental limitations of sparse-view reconstruction. PhysicsNeRF enables physically consistent, generalizable 3D representations for agent interaction and simulation, and clarifies the expressiveness-generalization trade-off in constrained NeRF models.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "4 pages, 2 figures, 2 tables. Preliminary work. Under review by the Building Physically Plausible World Models Workshop at the 42nd International Conference on Machine Learning (ICML 2025), Vancouver, Canada", "pdf_url": "https://arxiv.org/pdf/2505.23481.pdf", "abstract_url": "https://arxiv.org/abs/2505.23481", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "PhysicsNeRF是一个物理指导的稀疏视图3D重建框架，通过结合深度排序、RegNeRF风格一致性、稀疏先验和跨视图对齐四种互补约束，扩展了神经辐射场（NeRF）。该框架使用仅8个视图和0.67M参数的紧凑架构，实现了21.4 dB的平均PSNR，优于现有方法。", "motivation": "解决在稀疏视图下标准NeRFs无法有效进行3D重建的问题，旨在开发一个物理一致、可泛化的3D表示框架，以支持代理交互和模拟。", "method": "采用了一个包含深度排名、RegNeRF风格一致性、稀疏先验和跨视图对齐四种约束的物理指导框架，以及一个紧凑的0.67M参数架构。", "result": "PhysicsNeRF在仅使用8个视图的情况下，实现了21.4 dB的平均PSNR，显著优于现有方法，并揭示了稀疏视图重建的基本限制。", "conclusion": "PhysicsNeRF不仅提供了一个物理一致、可泛化的3D重建解决方案，还阐明了在受限NeRF模型中表达力与泛化能力之间的权衡。"}}
{"id": "2505.23277", "title": "Sentinel: Attention Probing of Proxy Models for LLM Context Compression with an Understanding Perspective", "authors": ["Yong Zhang", "Yanwen Huang", "Ning Cheng", "Yang Guo", "Yun Zhu", "Yanmeng Wang", "Shaojun Wang", "Jing Xiao"], "abstract": "Retrieval-augmented generation (RAG) enhances large language models (LLMs) with external context, but retrieved passages are often lengthy, noisy, or exceed input limits. Existing compression methods typically require supervised training of dedicated compression models, increasing cost and reducing portability. We propose Sentinel, a lightweight sentence-level compression framework that reframes context filtering as an attention-based understanding task. Rather than training a compression model, Sentinel probes decoder attention from an off-the-shelf 0.5B proxy LLM using a lightweight classifier to identify sentence relevance. Empirically, we find that query-context relevance estimation is consistent across model scales, with 0.5B proxies closely matching the behaviors of larger models. On the LongBench benchmark, Sentinel achieves up to 5$\\times$ compression while matching the QA performance of 7B-scale compression systems. Our results suggest that probing native attention signals enables fast, effective, and question-aware context compression. Code available at:", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "Preprint. 17 pages including appendix", "pdf_url": "https://arxiv.org/pdf/2505.23277.pdf", "abstract_url": "https://arxiv.org/abs/2505.23277", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "Sentinel提出了一种轻量级的句子级压缩框架，通过基于注意力的理解任务来过滤上下文，避免了训练专用压缩模型的成本和可移植性问题。", "motivation": "检索增强生成（RAG）通过外部上下文增强大型语言模型（LLMs），但检索到的段落往往冗长、嘈杂或超出输入限制。现有的压缩方法通常需要监督训练专用的压缩模型，增加了成本并降低了可移植性。", "method": "Sentinel利用现成的0.5B代理LLM的解码器注意力，通过轻量级分类器识别句子相关性，从而进行上下文过滤。", "result": "在LongBench基准测试中，Sentinel实现了高达5倍的压缩，同时匹配了7B规模压缩系统的QA性能。", "conclusion": "结果表明，探测原生注意力信号可以实现快速、有效且问题感知的上下文压缩。"}}
{"id": "2505.23291", "title": "ScEdit: Script-based Assessment of Knowledge Editing", "authors": ["Xinye Li", "Zunwen Zheng", "Qian Zhang", "Dekai Zhuang", "Jiabao Kang", "Liyan Xu", "Qingbin Liu", "Xi Chen", "Zhiying Tu", "Dianhui Chu", "Dianbo Sui"], "abstract": "Knowledge Editing (KE) has gained increasing attention, yet current KE tasks remain relatively simple. Under current evaluation frameworks, many editing methods achieve exceptionally high scores, sometimes nearing perfection. However, few studies integrate KE into real-world application scenarios (e.g., recent interest in LLM-as-agent). To support our analysis, we introduce a novel script-based benchmark -- ScEdit (Script-based Knowledge Editing Benchmark) -- which encompasses both counterfactual and temporal edits. We integrate token-level and text-level evaluation methods, comprehensively analyzing existing KE techniques. The benchmark extends traditional fact-based (\"What\"-type question) evaluation to action-based (\"How\"-type question) evaluation. We observe that all KE methods exhibit a drop in performance on established metrics and face challenges on text-level metrics, indicating a challenging task. Our benchmark is available at", "subjects": "Computation and Language (cs.CL)", "comments": "ACL 2025 Findings", "pdf_url": "https://arxiv.org/pdf/2505.23291.pdf", "abstract_url": "https://arxiv.org/abs/2505.23291", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了ScEdit，一个基于脚本的知识编辑评估基准，旨在更全面地评估知识编辑方法在实际应用场景中的表现。", "motivation": "当前的知识编辑（KE）任务评估框架相对简单，许多编辑方法在这些框架下表现接近完美，但缺乏对实际应用场景（如LLM-as-agent）的考虑。", "method": "作者提出了一个新颖的基于脚本的基准——ScEdit，它涵盖了反事实和时间编辑，并整合了令牌级和文本级的评估方法。", "result": "研究发现，所有KE方法在既定指标上的表现均有所下降，且在文本级指标上面临挑战，表明这是一个具有挑战性的任务。", "conclusion": "ScEdit基准的引入为知识编辑领域提供了一个更全面的评估工具，揭示了当前KE方法在实际应用中的局限性，为未来的研究指明了方向。"}}
{"id": "2505.23299", "title": "Data-efficient Meta-models for Evaluation of Context-based Questions and Answers in LLMs", "authors": ["Julia Belikova", "Konstantin Polev", "Rauf Parchiev", "Dmitry Simakov"], "abstract": "Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) systems are increasingly deployed in industry applications, yet their reliability remains hampered by challenges in detecting hallucinations. While supervised state-of-the-art (SOTA) methods that leverage LLM hidden states -- such as activation tracing and representation analysis -- show promise, their dependence on extensively annotated datasets limits scalability in real-world applications. This paper addresses the critical bottleneck of data annotation by investigating the feasibility of reducing training data requirements for two SOTA hallucination detection frameworks: Lookback Lens, which analyzes attention head dynamics, and probing-based approaches, which decode internal model representations. We propose a methodology combining efficient classification algorithms with dimensionality reduction techniques to minimize sample size demands while maintaining competitive performance. Evaluations on standardized question-answering RAG benchmarks show that our approach achieves performance comparable to strong proprietary LLM-based baselines with only 250 training samples. These results highlight the potential of lightweight, data-efficient paradigms for industrial deployment, particularly in annotation-constrained scenarios.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23299.pdf", "abstract_url": "https://arxiv.org/abs/2505.23299", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文研究了如何减少大型语言模型（LLMs）和检索增强生成（RAG）系统中幻觉检测的训练数据需求，提出了一种结合高效分类算法和降维技术的方法，仅需250个训练样本即可达到与强基线相当的性能。", "motivation": "解决在工业应用中部署LLMs和RAG系统时，由于依赖大量标注数据而导致的幻觉检测可扩展性限制问题。", "method": "结合高效分类算法和降维技术，减少两种最先进的幻觉检测框架（Lookback Lens和基于探测的方法）的训练数据需求。", "result": "在标准化的问答RAG基准测试中，仅使用250个训练样本，该方法就达到了与强专有LLM基线相当的性能。", "conclusion": "轻量级、数据高效的方法在工业部署中具有潜力，特别是在标注受限的场景下。"}}
{"id": "2505.22846", "title": "RocqStar: Leveraging Similarity-driven Retrieval and Agentic Systems for Rocq generation", "authors": ["Nikita Khramov", "Andrei Kozyrev", "Gleb Solovev", "Anton Podkopaev"], "abstract": "Interactive Theorem Proving was repeatedly shown to be fruitful combined with Generative Artificial Intelligence. This paper assesses multiple approaches to Rocq generation and illuminates potential avenues for improvement. We highlight the importance of thorough premise selection for generating Rocq proofs and propose a novel approach, leveraging retrieval via a self-attentive embedder model. The evaluation of the designed approach shows up to 28% relative increase of the generator's performance. We tackle the problem of writing Rocq proofs using a multi-stage agentic system, tailored for formal verification, and demonstrate its high effectiveness. We conduct an ablation study and show the use of multi-agent debate on the planning stage of proof synthesis.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Logic in Computer Science (cs.LO); Software Engineering (cs.SE)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.22846.pdf", "abstract_url": "https://arxiv.org/abs/2505.22846", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Logic in Computer Science (cs.LO)", "Software Engineering (cs.SE)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文探讨了生成式人工智能与交互式定理证明结合的有效性，特别关注Rocq证明的生成。通过引入基于自注意力嵌入模型的检索方法，提出了一种新颖的多阶段代理系统，用于形式验证，显著提高了生成器的性能。", "motivation": "解决在交互式定理证明中生成Rocq证明的挑战，特别是在前提选择和证明合成方面的效率问题。", "method": "采用自注意力嵌入模型进行检索，设计了一个多阶段代理系统，专门用于形式验证，并通过多代理辩论在证明合成的规划阶段进行了应用。", "result": "所设计的方法使生成器的性能相对提高了28%，证明了其在Rocq证明生成中的高效性。", "conclusion": "通过结合相似性驱动的检索和多代理系统，可以显著提高Rocq证明生成的效率和效果，为形式验证领域提供了新的改进方向。"}}
{"id": "2505.22852", "title": "Operationalizing CaMeL: Strengthening LLM Defenses for Enterprise Deployment", "authors": ["Krti Tallam", "Emma Miller"], "abstract": "CaMeL (Capabilities for Machine Learning) introduces a capability-based sandbox to mitigate prompt injection attacks in large language model (LLM) agents. While effective, CaMeL assumes a trusted user prompt, omits side-channel concerns, and incurs performance tradeoffs due to its dual-LLM design. This response identifies these issues and proposes engineering improvements to expand CaMeL's threat coverage and operational usability. We introduce: (1) prompt screening for initial inputs, (2) output auditing to detect instruction leakage, (3) a tiered-risk access model to balance usability and control, and (4) a verified intermediate language for formal guarantees. Together, these upgrades align CaMeL with best practices in enterprise security and support scalable deployment.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.22852.pdf", "abstract_url": "https://arxiv.org/abs/2505.22852", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "CaMeL（机器学习能力）引入了一种基于能力的沙箱，以减轻大型语言模型（LLM）代理中的提示注入攻击。虽然有效，但CaMeL假设用户提示可信，忽略了侧信道问题，并因其双LLM设计而带来性能权衡。本文识别了这些问题，并提出了工程改进以扩大CaMeL的威胁覆盖范围和操作可用性。", "motivation": "解决CaMeL在假设可信用户提示、忽略侧信道问题和性能权衡方面的局限性，以增强其在企业部署中的防御能力。", "method": "提出了四项改进措施：(1) 初始输入的提示筛查，(2) 输出审计以检测指令泄漏，(3) 分层风险访问模型以平衡可用性和控制，(4) 用于形式保证的验证中间语言。", "result": "这些升级使CaMeL与企业安全最佳实践保持一致，并支持可扩展的部署。", "conclusion": "通过引入提示筛查、输出审计、分层风险访问模型和验证中间语言，CaMeL的威胁覆盖范围和操作可用性得到了显著提升，更适合企业级部署。"}}
{"id": "2505.23495", "title": "Diagnosing and Addressing Pitfalls in KG-RAG Datasets: Toward More Reliable Benchmarking", "authors": ["Liangliang Zhang", "Zhuorui Jiang", "Hongliang Chi", "Haoyang Chen", "Mohammed Elkoumy", "Fali Wang", "Qiong Wu", "Zhengyi Zhou", "Shirui Pan", "Suhang Wang", "Yao Ma"], "abstract": "Knowledge Graph Question Answering (KGQA) systems rely on high-quality benchmarks to evaluate complex multi-hop reasoning. However, despite their widespread use, popular datasets such as WebQSP and CWQ suffer from critical quality issues, including inaccurate or incomplete ground-truth annotations, poorly constructed questions that are ambiguous, trivial, or unanswerable, and outdated or inconsistent knowledge. Through a manual audit of 16 popular KGQA datasets, including WebQSP and CWQ, we find that the average factual correctness rate is only 57 %. To address these issues, we introduce KGQAGen, an LLM-in-the-loop framework that systematically resolves these pitfalls. KGQAGen combines structured knowledge grounding, LLM-guided generation, and symbolic verification to produce challenging and verifiable QA instances. Using KGQAGen, we construct KGQAGen-10k, a ten-thousand scale benchmark grounded in Wikidata, and evaluate a diverse set of KG-RAG models. Experimental results demonstrate that even state-of-the-art systems struggle on this benchmark, highlighting its ability to expose limitations of existing models. Our findings advocate for more rigorous benchmark construction and position KGQAGen as a scalable framework for advancing KGQA evaluation.", "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": "9 pages", "pdf_url": "https://arxiv.org/pdf/2505.23495.pdf", "abstract_url": "https://arxiv.org/abs/2505.23495", "categories": ["Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文通过手动审核16个流行的KGQA数据集，发现平均事实正确率仅为57%，并提出了KGQAGen框架来解决这些问题，构建了KGQAGen-10k基准测试，展示了现有模型的局限性。", "motivation": "解决知识图谱问答（KGQA）系统中由于数据集质量不高（如标注不准确、问题构建不当、知识过时或不一致）导致的评估不可靠问题。", "method": "引入KGQAGen框架，结合结构化知识基础、LLM引导的生成和符号验证，生成具有挑战性且可验证的QA实例。", "result": "构建的KGQAGen-10k基准测试显示，即使是当前最先进的系统也在此基准上表现不佳，揭示了现有模型的局限性。", "conclusion": "研究结果主张更严格的基准构建，并将KGQAGen定位为推进KGQA评估的可扩展框架。"}}
{"id": "2505.22909", "title": "Learning to Charge More: A Theoretical Study of Collusion by Q-Learning Agents", "authors": ["Cristian Chica", "Yinglong Guo", "Gilad Lerman"], "abstract": "There is growing experimental evidence that $Q$-learning agents may learn to charge supracompetitive prices. We provide the first theoretical explanation for this behavior in infinite repeated games. Firms update their pricing policies based solely on observed profits, without computing equilibrium strategies. We show that when the game admits both a one-stage Nash equilibrium price and a collusive-enabling price, and when the $Q$-function satisfies certain inequalities at the end of experimentation, firms learn to consistently charge supracompetitive prices. We introduce a new class of one-memory subgame perfect equilibria (SPEs) and provide conditions under which learned behavior is supported by naive collusion, grim trigger policies, or increasing strategies. Naive collusion does not constitute an SPE unless the collusive-enabling price is a one-stage Nash equilibrium, whereas grim trigger policies can.", "subjects": "General Economics (econ.GN); Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.22909.pdf", "abstract_url": "https://arxiv.org/abs/2505.22909", "categories": ["General Economics (econ.GN)", "Artificial Intelligence (cs.AI)", "Computer Science and Game Theory (cs.GT)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文首次在无限重复博弈中为Q学习代理可能学会收取超竞争价格的行为提供了理论解释。研究表明，在满足特定条件下，企业会学会持续收取超竞争价格。", "motivation": "解决Q学习代理在无限重复博弈中学会收取超竞争价格行为的理论解释问题。", "method": "通过分析Q函数在实验结束时的特定不等式，研究企业在不计算均衡策略的情况下，如何基于观察到的利润更新定价策略。", "result": "当博弈既允许一阶段纳什均衡价格又允许促成合谋的价格时，企业在满足特定条件下会学会持续收取超竞争价格。", "conclusion": "研究引入了一类新的一记忆子博弈完美均衡(SPEs)，并提供了条件，在这些条件下，学习行为由天真合谋、严厉触发策略或增加策略支持。天真合谋不构成SPE，除非促成合谋的价格是一阶段纳什均衡，而严厉触发策略可以。"}}
{"id": "2505.23020", "title": "AgentAlign: Navigating Safety Alignment in the Shift from Informative to Agentic Large Language Models", "authors": ["Jinchuan Zhang", "Lu Yin", "Yan Zhou", "Songlin Hu"], "abstract": "The acquisition of agentic capabilities has transformed LLMs from \"knowledge providers\" to \"action executors\", a trend that while expanding LLMs' capability boundaries, significantly increases their susceptibility to malicious use. Previous work has shown that current LLM-based agents execute numerous malicious tasks even without being attacked, indicating a deficiency in agentic use safety alignment during the post-training phase. To address this gap, we propose AgentAlign, a novel framework that leverages abstract behavior chains as a medium for safety alignment data synthesis. By instantiating these behavior chains in simulated environments with diverse tool instances, our framework enables the generation of highly authentic and executable instructions while capturing complex multi-step dynamics. The framework further ensures model utility by proportionally synthesizing benign instructions through non-malicious interpretations of behavior chains, precisely calibrating the boundary between helpfulness and harmlessness. Evaluation results on AgentHarm demonstrate that fine-tuning three families of open-source models using our method substantially improves their safety (35.8% to 79.5% improvement) while minimally impacting or even positively enhancing their helpfulness, outperforming various prompting methods. The dataset and code have both been open-sourced.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "Submitted to ACL 2025", "pdf_url": "https://arxiv.org/pdf/2505.23020.pdf", "abstract_url": "https://arxiv.org/abs/2505.23020", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "AgentAlign是一个新颖的框架，旨在解决大型语言模型（LLMs）在获得代理能力后安全对齐不足的问题。通过利用抽象行为链作为安全对齐数据合成的媒介，并在模拟环境中实例化这些行为链，该框架能够生成高度真实且可执行的指令，同时捕捉复杂的多步动态。评估结果显示，使用该方法微调的模型在安全性上有显著提升，同时对其帮助性影响最小甚至有所增强。", "motivation": "随着大型语言模型（LLMs）从“知识提供者”转变为“行动执行者”，其能力边界扩展的同时，也显著增加了被恶意使用的风险。现有研究表明，即使在没有受到攻击的情况下，基于LLM的代理也会执行大量恶意任务，这表明在后训练阶段代理使用安全对齐存在不足。", "method": "提出了AgentAlign框架，该框架利用抽象行为链作为安全对齐数据合成的媒介。通过在模拟环境中用不同的工具实例实例化这些行为链，框架能够生成高度真实且可执行的指令，同时捕捉复杂的多步动态。此外，框架通过非恶意解释行为链比例合成良性指令，精确校准帮助性和无害性之间的边界。", "result": "在AgentHarm上的评估结果显示，使用AgentAlign方法微调的三种开源模型家族在安全性上有显著提升（35.8%到79.5%的改善），同时对其帮助性影响最小甚至有所增强，优于各种提示方法。", "conclusion": "AgentAlign框架有效解决了LLMs在获得代理能力后的安全对齐问题，显著提高了模型的安全性，同时保持了其帮助性。数据集和代码均已开源，为后续研究提供了宝贵的资源。"}}
{"id": "2505.23752", "title": "ThinkGeo: Evaluating Tool-Augmented Agents for Remote Sensing Tasks", "authors": ["Akashah Shabbir", "Muhammad Akhtar Munir", "Akshay Dudhane", "Muhammad Umer Sheikh", "Muhammad Haris Khan", "Paolo Fraccaro", "Juan Bernabe Moreno", "Fahad Shahbaz Khan", "Salman Khan"], "abstract": "Recent progress in large language models (LLMs) has enabled tool-augmented agents capable of solving complex real-world tasks through step-by-step reasoning. However, existing evaluations often focus on general-purpose or multimodal scenarios, leaving a gap in domain-specific benchmarks that assess tool-use capabilities in complex remote sensing use cases. We present ThinkGeo, an agentic benchmark designed to evaluate LLM-driven agents on remote sensing tasks via structured tool use and multi-step planning. Inspired by tool-interaction paradigms, ThinkGeo includes human-curated queries spanning a wide range of real-world applications such as urban planning, disaster assessment and change analysis, environmental monitoring, transportation analysis, aviation monitoring, recreational infrastructure, and industrial site analysis. Each query is grounded in satellite or aerial imagery and requires agents to reason through a diverse toolset. We implement a ReAct-style interaction loop and evaluate both open and closed-source LLMs (e.g., GPT-4o, Qwen2.5) on 436 structured agentic tasks. The benchmark reports both step-wise execution metrics and final answer correctness. Our analysis reveals notable disparities in tool accuracy and planning consistency across models. ThinkGeo provides the first extensive testbed for evaluating how tool-enabled LLMs handle spatial reasoning in remote sensing. Our code and dataset are publicly available", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23752.pdf", "abstract_url": "https://arxiv.org/abs/2505.23752", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "ThinkGeo是一个评估工具增强代理在遥感任务中表现的基准测试，专注于通过结构化工具使用和多步规划来评估LLM驱动的代理。", "motivation": "现有评估多集中在通用或多模态场景，缺乏针对复杂遥感用例中工具使用能力的领域特定基准。", "method": "采用ReAct风格的交互循环，评估开源和闭源LLM在436个结构化代理任务上的表现，包括逐步执行指标和最终答案正确性。", "result": "分析显示不同模型在工具准确性和规划一致性上存在显著差异。", "conclusion": "ThinkGeo为评估工具化LLM如何处理遥感中的空间推理提供了首个广泛的测试平台，代码和数据集已公开。"}}
{"id": "2505.23723", "title": "ML-Agent: Reinforcing LLM Agents for Autonomous Machine Learning Engineering", "authors": ["Zexi Liu", "Jingyi Chai", "Xinyu Zhu", "Shuo Tang", "Rui Ye", "Bo Zhang", "Lei Bai", "Siheng Chen"], "abstract": "The emergence of large language model (LLM)-based agents has significantly advanced the development of autonomous machine learning (ML) engineering. However, most existing approaches rely heavily on manual prompt engineering, failing to adapt and optimize based on diverse experimental experiences. Focusing on this, for the first time, we explore the paradigm of learning-based agentic ML, where an LLM agent learns through interactive experimentation on ML tasks using online reinforcement learning (RL). To realize this, we propose a novel agentic ML training framework with three key components: (1) exploration-enriched fine-tuning, which enables LLM agents to generate diverse actions for enhanced RL exploration; (2) step-wise RL, which enables training on a single action step, accelerating experience collection and improving training efficiency; (3) an agentic ML-specific reward module, which unifies varied ML feedback signals into consistent rewards for RL optimization. Leveraging this framework, we train ML-Agent, driven by a 7B-sized Qwen-2.5 LLM for autonomous ML. Remarkably, despite being trained on merely 9 ML tasks, our 7B-sized ML-Agent outperforms the 671B-sized DeepSeek-R1 agent. Furthermore, it achieves continuous performance improvements and demonstrates exceptional cross-task generalization capabilities.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23723.pdf", "abstract_url": "https://arxiv.org/abs/2505.23723", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种基于强化学习的LLM代理训练框架ML-Agent，通过交互式实验学习自主机器学习工程，显著提升了性能与跨任务泛化能力。", "motivation": "解决现有基于大型语言模型（LLM）的代理在自主机器学习工程中过度依赖手动提示工程，无法根据多样化的实验经验进行适应和优化的问题。", "method": "提出了一个包含三个关键组件的代理性ML训练框架：探索丰富的微调、逐步强化学习和代理性ML特定的奖励模块。", "result": "尽管仅在9个ML任务上训练，7B大小的ML-Agent在性能上超过了671B大小的DeepSeek-R1代理，并展示了持续的改进和卓越的跨任务泛化能力。", "conclusion": "通过强化学习训练的LLM代理能够在自主机器学习工程中实现高效的学习和优化，展现出超越大规模代理的性能和泛化能力。"}}
{"id": "2505.23189", "title": "TrackVLA: Embodied Visual Tracking in the Wild", "authors": ["Shaoan Wang", "Jiazhao Zhang", "Minghan Li", "Jiahang Liu", "Anqi Li", "Kui Wu", "Fangwei Zhong", "Junzhi Yu", "Zhizheng Zhang", "He Wang"], "abstract": "Embodied visual tracking is a fundamental skill in Embodied AI, enabling an agent to follow a specific target in dynamic environments using only egocentric vision. This task is inherently challenging as it requires both accurate target recognition and effective trajectory planning under conditions of severe occlusion and high scene dynamics. Existing approaches typically address this challenge through a modular separation of recognition and planning. In this work, we propose TrackVLA, a Vision-Language-Action (VLA) model that learns the synergy between object recognition and trajectory planning. Leveraging a shared LLM backbone, we employ a language modeling head for recognition and an anchor-based diffusion model for trajectory planning. To train TrackVLA, we construct an Embodied Visual Tracking Benchmark (EVT-Bench) and collect diverse difficulty levels of recognition samples, resulting in a dataset of 1.7 million samples. Through extensive experiments in both synthetic and real-world environments, TrackVLA demonstrates SOTA performance and strong generalizability. It significantly outperforms existing methods on public benchmarks in a zero-shot manner while remaining robust to high dynamics and occlusion in real-world scenarios at 10 FPS inference speed. Our project page is:", "subjects": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23189.pdf", "abstract_url": "https://arxiv.org/abs/2505.23189", "categories": ["Robotics (cs.RO)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "TrackVLA是一种视觉-语言-动作（VLA）模型，旨在通过结合目标识别和轨迹规划来解决在动态环境中进行视觉跟踪的挑战。", "motivation": "解决在动态环境中仅使用自我中心视觉进行特定目标跟踪的挑战，特别是在严重遮挡和高动态场景下。", "method": "利用共享的LLM骨干网络，采用语言建模头进行识别和基于锚点的扩散模型进行轨迹规划。", "result": "在合成和真实世界环境中，TrackVLA展示了最先进的性能和强大的泛化能力，显著优于现有方法，并在10 FPS的推理速度下保持对高动态和遮挡的鲁棒性。", "conclusion": "TrackVLA通过结合目标识别和轨迹规划，为动态环境中的视觉跟踪提供了一种有效的解决方案，具有广泛的应用潜力。"}}
{"id": "2505.23765", "title": "From Chat Logs to Collective Insights: Aggregative Question Answering", "authors": ["Wentao Zhang", "Woojeong Kim", "Yuntian Deng"], "abstract": "Conversational agents powered by large language models (LLMs) are rapidly becoming integral to our daily interactions, generating unprecedented amounts of conversational data. Such datasets offer a powerful lens into societal interests, trending topics, and collective concerns. Yet, existing approaches typically treat these interactions as independent and miss critical insights that could emerge from aggregating and reasoning across large-scale conversation logs. In this paper, we introduce Aggregative Question Answering, a novel task requiring models to reason explicitly over thousands of user-chatbot interactions to answer aggregative queries, such as identifying emerging concerns among specific demographics. To enable research in this direction, we construct a benchmark, WildChat-AQA, comprising 6,027 aggregative questions derived from 182,330 real-world chatbot conversations. Experiments show that existing methods either struggle to reason effectively or incur prohibitive computational costs, underscoring the need for new approaches capable of extracting collective insights from large-scale conversational data.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23765.pdf", "abstract_url": "https://arxiv.org/abs/2505.23765", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了聚合问答这一新任务，旨在通过分析大规模聊天日志来回答聚合查询，如识别特定人群中的新兴关注点。作者构建了一个名为WildChat-AQA的基准测试集，包含6,027个聚合问题，源自182,330个真实世界聊天机器人对话。实验表明，现有方法在有效推理或计算成本方面存在不足，凸显了开发新方法以从大规模对话数据中提取集体见解的必要性。", "motivation": "随着由大型语言模型（LLMs）驱动的对话代理日益成为我们日常互动的一部分，产生了前所未有的对话数据量。这些数据集为社会兴趣、趋势话题和集体关注提供了强大的视角。然而，现有方法通常将这些互动视为独立的，错过了通过聚合和推理大规模对话日志可能获得的关键见解。", "method": "本文提出了聚合问答（Aggregative Question Answering）这一新任务，要求模型明确推理数千个用户与聊天机器人的互动以回答聚合查询。为了支持这一方向的研究，作者构建了WildChat-AQA基准测试集。", "result": "实验结果显示，现有方法要么难以有效推理，要么计算成本过高，这表明需要开发能够从大规模对话数据中提取集体见解的新方法。", "conclusion": "本文强调了从大规模对话数据中提取集体见解的重要性，并提出了聚合问答任务及相应的基准测试集WildChat-AQA，为未来研究提供了方向和工具。"}}
{"id": "2505.23266", "title": "Disrupting Vision-Language Model-Driven Navigation Services via Adversarial Object Fusion", "authors": ["Chunlong Xie", "Jialing He", "Shangwei Guo", "Jiacheng Wang", "Shudong Zhang", "Tianwei Zhang", "Tao Xiang"], "abstract": "We present Adversarial Object Fusion (AdvOF), a novel attack framework targeting vision-and-language navigation (VLN) agents in service-oriented environments by generating adversarial 3D objects. While foundational models like Large Language Models (LLMs) and Vision Language Models (VLMs) have enhanced service-oriented navigation systems through improved perception and decision-making, their integration introduces vulnerabilities in mission-critical service workflows. Existing adversarial attacks fail to address service computing contexts, where reliability and quality-of-service (QoS) are paramount. We utilize AdvOF to investigate and explore the impact of adversarial environments on the VLM-based perception module of VLN agents. In particular, AdvOF first precisely aggregates and aligns the victim object positions in both 2D and 3D space, defining and rendering adversarial objects. Then, we collaboratively optimize the adversarial object with regularization between the adversarial and victim object across physical properties and VLM perceptions. Through assigning importance weights to varying views, the optimization is processed stably and multi-viewedly by iterative fusions from local updates and justifications. Our extensive evaluations demonstrate AdvOF can effectively degrade agent performance under adversarial conditions while maintaining minimal interference with normal navigation tasks. This work advances the understanding of service security in VLM-powered navigation systems, providing computational foundations for robust service composition in physical-world deployments.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "comments": "Under review", "pdf_url": "https://arxiv.org/pdf/2505.23266.pdf", "abstract_url": "https://arxiv.org/abs/2505.23266", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了Adversarial Object Fusion (AdvOF)，一种针对视觉和语言导航(VLN)代理的新型攻击框架，通过生成对抗性3D对象来破坏服务导向环境中的导航系统。", "motivation": "尽管大型语言模型(LLMs)和视觉语言模型(VLMs)等基础模型通过改进的感知和决策能力增强了服务导向的导航系统，但它们的集成在关键任务服务工作流程中引入了漏洞。现有的对抗攻击未能考虑到服务计算环境，其中可靠性和服务质量(QoS)至关重要。", "method": "AdvOF首先在2D和3D空间中精确聚合和对齐受害对象位置，定义并渲染对抗性对象。然后，通过对抗性对象和受害对象之间的物理属性和VLM感知的正则化，协作优化对抗性对象。通过为不同视图分配重要性权重，优化过程通过局部更新和调整的迭代融合稳定且多视角地进行。", "result": "广泛的评估表明，AdvOF可以在对抗条件下有效降低代理性能，同时保持对正常导航任务的最小干扰。", "conclusion": "这项工作增进了对VLM驱动的导航系统中服务安全的理解，为物理世界部署中的鲁棒服务组合提供了计算基础。"}}
{"id": "2505.22907", "title": "Conversational Alignment with Artificial Intelligence in Context", "authors": ["Rachel Katharine Sterken", "James Ravi Kirkpatrick"], "abstract": "The development of sophisticated artificial intelligence (AI) conversational agents based on large language models raises important questions about the relationship between human norms, values, and practices and AI design and performance. This article explores what it means for AI agents to be conversationally aligned to human communicative norms and practices for handling context and common ground and proposes a new framework for evaluating developers' design choices. We begin by drawing on the philosophical and linguistic literature on conversational pragmatics to motivate a set of desiderata, which we call the CONTEXT-ALIGN framework, for conversational alignment with human communicative practices. We then suggest that current large language model (LLM) architectures, constraints, and affordances may impose fundamental limitations on achieving full conversational alignment.", "subjects": "Computers and Society (cs.CY); Computation and Language (cs.CL)", "comments": "20 pages, to be published in Philosophical Perspectives", "pdf_url": "https://arxiv.org/pdf/2505.22907.pdf", "abstract_url": "https://arxiv.org/abs/2505.22907", "categories": ["Computers and Society (cs.CY)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了人工智能对话代理如何与人类交流规范和实践中处理上下文和共同点的需求对齐，提出了一个名为CONTEXT-ALIGN的新框架来评估开发者的设计选择。", "motivation": "解决AI对话代理如何更好地与人类的交流规范和实践对齐的问题。", "method": "利用哲学和语言学文献中关于对话语用学的理论，提出CONTEXT-ALIGN框架。", "result": "当前的大型语言模型架构、限制和功能可能对实现完全的对话对齐构成基本限制。", "conclusion": "提出了一个评估AI对话代理与人类交流规范对齐的新框架，并指出当前技术可能存在的限制。"}}
{"id": "2505.23239", "title": "OSS-UAgent: An Agent-based Usability Evaluation Framework for Open Source Software", "authors": ["Lingkai Meng", "Yu Shao", "Long Yuan", "Longbin Lai", "Peng Cheng", "Wenyuan Yu", "Wenjie Zhang", "Xuemin Lin", "Jingren Zhou"], "abstract": "Usability evaluation is critical to the impact and adoption of open source software (OSS), yet traditional methods relying on human evaluators suffer from high costs and limited scalability. To address these limitations, we introduce OSS-UAgent, an automated, configurable, and interactive agent-based usability evaluation framework specifically designed for open source software. Our framework employs intelligent agents powered by large language models (LLMs) to simulate developers performing programming tasks across various experience levels (from Junior to Expert). By dynamically constructing platform-specific knowledge bases, OSS-UAgent ensures accurate and context-aware code generation. The generated code is automatically evaluated across multiple dimensions, including compliance, correctness, and readability, providing a comprehensive measure of the software's usability. Additionally, our demonstration showcases OSS-UAgent's practical application in evaluating graph analytics platforms, highlighting its effectiveness in automating usability evaluation.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23239.pdf", "abstract_url": "https://arxiv.org/abs/2505.23239", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "OSS-UAgent是一个基于代理的自动化、可配置、交互式的开源软件可用性评估框架，旨在解决传统依赖人工评估方法的高成本和有限扩展性问题。", "motivation": "解决开源软件可用性评估中传统方法的高成本和有限扩展性问题。", "method": "利用大型语言模型（LLMs）驱动的智能代理模拟不同经验水平的开发者执行编程任务，并通过动态构建平台特定知识库确保准确和上下文感知的代码生成。", "result": "生成的代码在合规性、正确性和可读性等多个维度上自动评估，有效自动化了可用性评估。", "conclusion": "OSS-UAgent框架在自动化开源软件可用性评估方面表现出色，特别是在图分析平台的应用中展示了其有效性。"}}
{"id": "2505.23419", "title": "SWE-bench Goes Live!", "authors": ["Linghao Zhang", "Shilin He", "Chaoyun Zhang", "Yu Kang", "Bowen Li", "Chengxing Xie", "Junhao Wang", "Maoquan Wang", "Yufan Huang", "Shengyu Fu", "Elsie Nallipogu", "Qingwei Lin", "Yingnong Dang", "Saravan Rajmohan", "Dongmei Zhang"], "abstract": "The issue-resolving task, where a model generates patches to fix real-world bugs, has emerged as a critical benchmark for evaluating the capabilities of large language models (LLMs). While SWE-bench and its variants have become standard in this domain, they suffer from key limitations: they have not been updated since their initial releases, cover a narrow set of repositories, and depend heavily on manual effort for instance construction and environment setup. These factors hinder scalability and introduce risks of overfitting and data contamination. In this work, we present \\textbf{SWE-bench-Live}, a \\textit{live-updatable} benchmark designed to overcome these challenges. Our initial release consists of 1,319 tasks derived from real GitHub issues created since 2024, spanning 93 repositories. Each task is accompanied by a dedicated Docker image to ensure reproducible execution. Central to our benchmark is \\method, an automated curation pipeline that streamlines the entire process from instance creation to environment setup, removing manual bottlenecks and enabling scalability and continuous updates. We evaluate a range of state-of-the-art agent frameworks and LLMs on SWE-bench-Live, revealing a substantial performance gap compared to static benchmarks like SWE-bench, even under controlled evaluation conditions. To better understand this discrepancy, we perform detailed analyses across repository origin, issue recency, and task difficulty. By providing a fresh, diverse, and executable benchmark grounded in live repository activity, SWE-bench-Live facilitates rigorous, contamination-resistant evaluation of LLMs and agents in dynamic, real-world software development settings.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "}", "pdf_url": "https://arxiv.org/pdf/2505.23419.pdf", "abstract_url": "https://arxiv.org/abs/2505.23419", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了SWE-bench-Live，一个可实时更新的基准测试，旨在解决现有SWE-bench及其变体在评估大型语言模型（LLMs）能力时的局限性。", "motivation": "现有的SWE-bench及其变体在评估LLMs解决现实世界bug的能力时存在局限性，如未更新、覆盖仓库范围窄、依赖手动操作等，这些问题影响了可扩展性并增加了过拟合和数据污染的风险。", "method": "提出了SWE-bench-Live，一个包含1,319个任务的初始版本，这些任务源自2024年以来GitHub上的真实问题，覆盖93个仓库。每个任务配有专用的Docker镜像以确保可重复执行。核心是自动化的curation pipeline，简化了从实例创建到环境设置的整个流程。", "result": "在SWE-bench-Live上评估了一系列最先进的代理框架和LLMs，揭示了与静态基准如SWE-bench相比存在显著的性能差距，即使在受控评估条件下也是如此。", "conclusion": "通过提供一个基于实时仓库活动的新鲜、多样且可执行的基准，SWE-bench-Live促进了在动态、现实世界软件开发环境中对LLMs和代理的严格、抗污染评估。"}}
{"id": "2505.23671", "title": "GSO: Challenging Software Optimization Tasks for Evaluating SWE-Agents", "authors": ["Manish Shetty", "Naman Jain", "Jinjian Liu", "Vijay Kethanaboyina", "Koushik Sen", "Ion Stoica"], "abstract": "Developing high-performance software is a complex task that requires specialized expertise. We introduce GSO, a benchmark for evaluating language models' capabilities in developing high-performance software. We develop an automated pipeline that generates and executes performance tests to analyze repository commit histories to identify 102 challenging optimization tasks across 10 codebases, spanning diverse domains and programming languages. An agent is provided with a codebase and performance test as a precise specification, and tasked to improve the runtime efficiency, which is measured against the expert developer optimization. Our quantitative evaluation reveals that leading SWE-Agents struggle significantly, achieving less than 5% success rate, with limited improvements even with inference-time scaling. Our qualitative analysis identifies key failure modes, including difficulties with low-level languages, practicing lazy optimization strategies, and challenges in accurately localizing bottlenecks. We release the code and artifacts of our benchmark along with agent trajectories to enable future research.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.23671.pdf", "abstract_url": "https://arxiv.org/abs/2505.23671", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "GSO是一个用于评估语言模型在开发高性能软件方面能力的基准测试。通过自动化流程生成和执行性能测试，分析了10个代码库中的102个优化任务。研究发现，领先的SWE-Agents成功率低于5%，且在推理时间扩展方面改进有限。", "motivation": "开发高性能软件是一项复杂的任务，需要专业知识。本文旨在通过GSO基准测试评估语言模型在此领域的能力。", "method": "开发了一个自动化管道，生成和执行性能测试，分析代码库提交历史，识别出102个优化任务。代理被提供代码库和性能测试作为精确规范，任务是提高运行时效率。", "result": "领先的SWE-Agents成功率低于5%，即使在推理时间扩展方面改进也有限。定性分析揭示了关键失败模式，包括处理低级语言的困难、实施懒惰优化策略的挑战以及准确定位瓶颈的难题。", "conclusion": "GSO基准测试揭示了当前SWE-Agents在开发高性能软件方面的局限性，为未来研究提供了代码、工件和代理轨迹。"}}
{"id": "2505.23352", "title": "Understanding the Information Propagation Effects of Communication Topologies in LLM-based Multi-Agent Systems", "authors": ["Xu Shen", "Yixin Liu", "Yiwei Dai", "Yili Wang", "Rui Miao", "Yue Tan", "Shirui Pan", "Xin Wang"], "abstract": "The communication topology in large language model-based multi-agent systems fundamentally governs inter-agent collaboration patterns, critically shaping both the efficiency and effectiveness of collective decision-making. While recent studies for communication topology automated design tend to construct sparse structures for efficiency, they often overlook why and when sparse and dense topologies help or hinder collaboration. In this paper, we present a causal framework to analyze how agent outputs, whether correct or erroneous, propagate under topologies with varying sparsity. Our empirical studies reveal that moderately sparse topologies, which effectively suppress error propagation while preserving beneficial information diffusion, typically achieve optimal task performance. Guided by this insight, we propose a novel topology design approach, EIB-leanrner, that balances error suppression and beneficial information propagation by fusing connectivity patterns from both dense and sparse graphs. Extensive experiments show the superior effectiveness, communication cost, and robustness of EIB-leanrner.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23352.pdf", "abstract_url": "https://arxiv.org/abs/2505.23352", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了基于大型语言模型的多智能体系统中通信拓扑对信息传播的影响，提出了一个因果框架来分析不同稀疏度拓扑下智能体输出的传播，并发现适度稀疏的拓扑在抑制错误传播和保留有益信息扩散方面表现最佳。基于此，作者提出了一种新的拓扑设计方法EIB-leanrner，通过融合稠密和稀疏图的连接模式来平衡错误抑制和有益信息传播。", "motivation": "解决在多智能体系统中，通信拓扑的设计如何影响智能体间的协作效率和效果，特别是稀疏和稠密拓扑在何时以及为何有助于或阻碍协作的问题。", "method": "提出了一个因果框架来分析不同稀疏度拓扑下智能体输出的传播，并基于实证研究结果设计了一种新的拓扑设计方法EIB-leanrner。", "result": "实证研究表明，适度稀疏的拓扑在抑制错误传播和保留有益信息扩散方面表现最佳，EIB-leanrner方法在效果、通信成本和鲁棒性方面表现出色。", "conclusion": "通过平衡错误抑制和有益信息传播的拓扑设计，可以显著提高多智能体系统的协作效率和效果，EIB-leanrner方法为此提供了一种有效的解决方案。"}}
{"id": "2505.23422", "title": "From Knowledge to Noise: CTIM-Rover and the Pitfalls of Episodic Memory in Software Engineering Agents", "authors": ["Tobias Lindenbauer", "Georg Groh", "Hinrich Schütze"], "abstract": "We introduce CTIM-Rover, an AI agent for Software Engineering (SE) built on top of AutoCodeRover (Zhang et al., 2024) that extends agentic reasoning frameworks with an episodic memory, more specifically, a general and repository-level Cross-Task-Instance Memory (CTIM). While existing open-source SE agents mostly rely on ReAct (Yao et al., 2023b), Reflexion (Shinn et al., 2023), or Code-Act (Wang et al., 2024), all of these reasoning and planning frameworks inefficiently discard their long-term memory after a single task instance. As repository-level understanding is pivotal for identifying all locations requiring a patch for fixing a bug, we hypothesize that SE is particularly well positioned to benefit from CTIM. For this, we build on the Experiential Learning (EL) approach ExpeL (Zhao et al., 2024), proposing a Mixture-Of-Experts (MoEs) inspired approach to create both a general-purpose and repository-level CTIM. We find that CTIM-Rover does not outperform AutoCodeRover in any configuration and thus conclude that neither ExpeL nor DoT-Bank (Lingam et al., 2024) scale to real-world SE problems. Our analysis indicates noise introduced by distracting CTIM items or exemplar trajectories as the likely source of the performance degradation.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": "Short Paper, REALM '25 camera-ready", "pdf_url": "https://arxiv.org/pdf/2505.23422.pdf", "abstract_url": "https://arxiv.org/abs/2505.23422", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "介绍了CTIM-Rover，一个基于AutoCodeRover的软件工程AI代理，它通过引入跨任务实例记忆（CTIM）扩展了代理推理框架。研究发现，CTIM-Rover在所有配置中均未超越AutoCodeRover，表明现有方法难以扩展到实际软件工程问题。", "motivation": "解决现有开源软件工程代理在完成任务实例后低效丢弃长期记忆的问题，特别是在修复bug时需要理解整个仓库级别的上下文。", "method": "基于Experiential Learning（EL）方法ExpeL，提出了一种受Mixture-Of-Experts（MoEs）启发的方法，创建了通用和仓库级别的CTIM。", "result": "CTIM-Rover在所有配置中均未超越AutoCodeRover，性能下降的可能原因是CTIM项目或示例轨迹引入的噪音。", "conclusion": "ExpeL和DoT-Bank方法难以扩展到实际软件工程问题，CTIM在软件工程代理中的应用面临噪音干扰的挑战。"}}
{"id": "2505.23643", "title": "Securing AI Agents with Information-Flow Control", "authors": ["Manuel Costa", "Boris Köpf", "Aashish Kolluri", "Andrew Paverd", "Mark Russinovich", "Ahmed Salem", "Shruti Tople", "Lukas Wutschitz", "Santiago Zanella-Béguelin"], "abstract": "As AI agents become increasingly autonomous and capable, ensuring their security against vulnerabilities such as prompt injection becomes critical. This paper explores the use of information-flow control (IFC) to provide security guarantees for AI agents. We present a formal model to reason about the security and expressiveness of agent planners. Using this model, we characterize the class of properties enforceable by dynamic taint-tracking and construct a taxonomy of tasks to evaluate security and utility trade-offs of planner designs. Informed by this exploration, we present Fides, a planner that tracks confidentiality and integrity labels, deterministically enforces security policies, and introduces novel primitives for selectively hiding information. Its evaluation in AgentDojo demonstrates that this approach broadens the range of tasks that can be securely accomplished. A tutorial to walk readers through the the concepts introduced in the paper can be found at", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23643.pdf", "abstract_url": "https://arxiv.org/abs/2505.23643", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了使用信息流控制（IFC）为AI代理提供安全保障的方法，提出了一个形式化模型来推理代理规划器的安全性和表达能力，并介绍了Fides规划器，该规划器通过动态污点跟踪和保密性、完整性标签的跟踪，确定性执行安全策略，扩展了可安全完成的任务范围。", "motivation": "随着AI代理变得越来越自主和强大，确保其安全，防止如提示注入等漏洞变得至关重要。", "method": "提出了一个形式化模型来推理代理规划器的安全性和表达能力，使用动态污点跟踪来强制执行安全策略，并引入了Fides规划器，该规划器跟踪保密性和完整性标签。", "result": "在AgentDojo中的评估表明，这种方法扩大了可以安全完成的任务范围。", "conclusion": "通过信息流控制和Fides规划器的引入，可以更有效地保障AI代理的安全，同时扩展其安全执行任务的能力。"}}
{"id": "2505.23710", "title": "From Connectivity to Autonomy: The Dawn of Self-Evolving Communication Systems", "authors": ["Zeinab Nezami", "Syed Danial Ali Shah", "Maryam Hafeez", "Karim Djemame", "Syed Ali Raza Zaidi"], "abstract": "This paper envisions 6G as a self-evolving telecom ecosystem, where AI-driven intelligence enables dynamic adaptation beyond static connectivity. We explore the key enablers of autonomous communication systems, spanning reconfigurable infrastructure, adaptive middleware, and intelligent network functions, alongside multi-agent collaboration for distributed decision-making. We explore how these methodologies align with emerging industrial IoT frameworks, ensuring seamless integration within digital manufacturing processes. Our findings emphasize the potential for improved real-time decision-making, optimizing efficiency, and reducing latency in networked control systems. The discussion addresses ethical challenges, research directions, and standardization efforts, concluding with a technology stack roadmap to guide future developments. By leveraging state-of-the-art 6G network management techniques, this research contributes to the next generation of intelligent automation solutions, bridging the gap between theoretical advancements and real-world industrial applications.", "subjects": "Systems and Control (eess.SY); Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Emerging Technologies (cs.ET)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23710.pdf", "abstract_url": "https://arxiv.org/abs/2505.23710", "categories": ["Systems and Control (eess.SY)", "Artificial Intelligence (cs.AI)", "Distributed, Parallel, and Cluster Computing (cs.DC)", "Emerging Technologies (cs.ET)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文设想6G为一个自我演进的电信生态系统，通过AI驱动的智能实现超越静态连接的动态适应。探讨了自主通信系统的关键使能技术，包括可重构基础设施、自适应中间件和智能网络功能，以及多智能体协作的分布式决策。研究了这些方法如何与新兴的工业物联网框架对齐，确保在数字制造过程中的无缝集成。", "motivation": "解决当前通信系统在动态适应和智能自动化方面的不足，推动6G网络向更高效、低延迟的自主通信系统发展。", "method": "采用AI驱动的智能技术，结合可重构基础设施、自适应中间件、智能网络功能和多智能体协作，实现网络的自主演进和优化。", "result": "研究发现，这些技术可以显著提高实时决策能力，优化效率，并减少网络控制系统的延迟。", "conclusion": "通过最先进的6G网络管理技术，本研究为下一代智能自动化解决方案的发展提供了理论支持和实践指导，同时强调了伦理挑战、研究方向及标准化工作的重要性。"}}
{"id": "2505.23720", "title": "COBRA: Contextual Bandit Algorithm for Ensuring Truthful Strategic Agents", "authors": ["Arun Verma", "Indrajit Saha", "Makoto Yokoo", "Bryan Kian Hsiang Low"], "abstract": "This paper considers a contextual bandit problem involving multiple agents, where a learner sequentially observes the contexts and the agent's reported arms, and then selects the arm that maximizes the system's overall reward. Existing work in contextual bandits assumes that agents truthfully report their arms, which is unrealistic in many real-life applications. For instance, consider an online platform with multiple sellers; some sellers may misrepresent product quality to gain an advantage, such as having the platform preferentially recommend their products to online users. To address this challenge, we propose an algorithm, COBRA, for contextual bandit problems involving strategic agents that disincentivize their strategic behavior without using any monetary incentives, while having incentive compatibility and a sub-linear regret guarantee. Our experimental results also validate the different performance aspects of our proposed algorithm.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)", "comments": "This paper proposes a contextual bandit algorithm that prevents strategic agents from misreporting while having approximate incentive compatibility and a sub-linear regret guarantee", "pdf_url": "https://arxiv.org/pdf/2505.23720.pdf", "abstract_url": "https://arxiv.org/abs/2505.23720", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Machine Learning (stat.ML)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为COBRA的上下文多臂老虎机算法，旨在解决涉及多个战略代理的问题，确保代理的真实性，无需货币激励，同时保证激励兼容性和次线性遗憾。", "motivation": "现有的上下文老虎机研究假设代理会真实报告其选择，这在许多现实应用中不现实。例如，在线平台上的卖家可能会虚假宣传产品质量以获得优势。", "method": "提出COBRA算法，通过上下文老虎机框架处理战略代理的问题，无需货币激励即可抑制其战略行为，同时保证激励兼容性和次线性遗憾。", "result": "实验结果表明，COBRA算法在抑制战略行为和保证系统整体奖励方面表现良好。", "conclusion": "COBRA算法为处理战略代理的上下文老虎机问题提供了一种有效解决方案，具有实际应用潜力。"}}
