{"id": "2506.21121", "title": "GoIRL: Graph-Oriented Inverse Reinforcement Learning for Multimodal Trajectory Prediction", "authors": ["Muleilan Pei", "Shaoshuai Shi", "Lu Zhang", "Peiliang Li", "Shaojie Shen"], "abstract": "Trajectory prediction for surrounding agents is a challenging task in autonomous driving due to its inherent uncertainty and underlying multimodality. Unlike prevailing data-driven methods that primarily rely on supervised learning, in this paper, we introduce a novel Graph-oriented Inverse Reinforcement Learning (GoIRL) framework, which is an IRL-based predictor equipped with vectorized context representations. We develop a feature adaptor to effectively aggregate lane-graph features into grid space, enabling seamless integration with the maximum entropy IRL paradigm to infer the reward distribution and obtain the policy that can be sampled to induce multiple plausible plans. Furthermore, conditioned on the sampled plans, we implement a hierarchical parameterized trajectory generator with a refinement module to enhance prediction accuracy and a probability fusion strategy to boost prediction confidence. Extensive experimental results showcase our approach not only achieves state-of-the-art performance on the large-scale Argoverse & nuScenes motion forecasting benchmarks but also exhibits superior generalization abilities compared to existing supervised models.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)", "comments": "Accepted by ICML 2025", "pdf_url": "https://arxiv.org/pdf/2506.21121.pdf", "abstract_url": "https://arxiv.org/abs/2506.21121", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新颖的图导向逆强化学习框架（GoIRL），用于自动驾驶中的多模态轨迹预测，通过最大熵逆强化学习范式推断奖励分布，并结合分层参数化轨迹生成器提高预测准确性和置信度。", "motivation": "自动驾驶中周围代理的轨迹预测由于其固有的不确定性和潜在的多模态性而具有挑战性。现有数据驱动方法主要依赖监督学习，难以有效处理这些挑战。", "method": "开发了一个特征适配器，将车道图特征有效聚合到网格空间中，结合最大熵逆强化学习范式推断奖励分布，并实现了一个分层参数化轨迹生成器，带有细化模块和概率融合策略。", "result": "在Argoverse和nuScenes运动预测基准测试中，该方法不仅达到了最先进的性能，而且与现有监督模型相比表现出更优的泛化能力。", "conclusion": "GoIRL框架为自动驾驶中的多模态轨迹预测提供了一种有效的解决方案，通过结合逆强化学习和分层轨迹生成，显著提高了预测的准确性和置信度。"}}
{"id": "2506.20964", "title": "Evidence-based diagnostic reasoning with multi-agent copilot for human pathology", "authors": ["Chengkuan Chen", "Luca L. Weishaupt", "Drew F. K. Williamson", "Richard J. Chen", "Tong Ding", "Bowen Chen", "Anurag Vaidya", "Long Phi Le", "Guillaume Jaume", "Ming Y. Lu", "Faisal Mahmood"], "abstract": "Pathology is experiencing rapid digital transformation driven by whole-slide imaging and artificial intelligence (AI). While deep learning-based computational pathology has achieved notable success, traditional models primarily focus on image analysis without integrating natural language instruction or rich, text-based context. Current multimodal large language models (MLLMs) in computational pathology face limitations, including insufficient training data, inadequate support and evaluation for multi-image understanding, and a lack of autonomous, diagnostic reasoning capabilities. To address these limitations, we introduce PathChat+, a new MLLM specifically designed for human pathology, trained on over 1 million diverse, pathology-specific instruction samples and nearly 5.5 million question answer turns. Extensive evaluations across diverse pathology benchmarks demonstrated that PathChat+ substantially outperforms the prior PathChat copilot, as well as both state-of-the-art (SOTA) general-purpose and other pathology-specific models. Furthermore, we present SlideSeek, a reasoning-enabled multi-agent AI system leveraging PathChat+ to autonomously evaluate gigapixel whole-slide images (WSIs) through iterative, hierarchical diagnostic reasoning, reaching high accuracy on DDxBench, a challenging open-ended differential diagnosis benchmark, while also capable of generating visually grounded, humanly-interpretable summary reports.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.20964.pdf", "abstract_url": "https://arxiv.org/abs/2506.20964", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "PathChat+是一种专为人类病理学设计的新型多模态大型语言模型，通过超过100万种不同的病理学特定指令样本和近550万个问答对的训练，显著优于现有模型，并结合SlideSeek系统实现高精度的自主诊断推理。", "motivation": "解决计算病理学中传统模型缺乏自然语言指令和文本上下文整合，以及多模态大型语言模型在训练数据、多图像理解支持和自主诊断推理能力方面的限制。", "method": "开发PathChat+模型，训练于大量病理学特定指令和问答数据，并结合SlideSeek系统进行迭代、分层的诊断推理。", "result": "PathChat+在多样化的病理学基准测试中显著优于先前模型和其他专业或通用模型，SlideSeek在DDxBench上达到高精度，并能生成视觉基础的人类可理解总结报告。", "conclusion": "PathChat+和SlideSeek系统的结合为病理学提供了强大的自主诊断推理能力，推动了病理学的数字化转型。"}}
{"id": "2506.20911", "title": "FaSTA$^*$: Fast-Slow Toolpath Agent with Subroutine Mining for Efficient Multi-turn Image Editing", "authors": ["Advait Gupta", "Rishie Raj", "Dang Nguyen", "Tianyi Zhou"], "abstract": "We develop a cost-efficient neurosymbolic agent to address challenging multi-turn image editing tasks such as \"Detect the bench in the image while recoloring it to pink. Also, remove the cat for a clearer view and recolor the wall to yellow.'' It combines the fast, high-level subtask planning by large language models (LLMs) with the slow, accurate, tool-use, and local A$^*$ search per subtask to find a cost-efficient toolpath -- a sequence of calls to AI tools. To save the cost of A$^*$ on similar subtasks, we perform inductive reasoning on previously successful toolpaths via LLMs to continuously extract/refine frequently used subroutines and reuse them as new tools for future tasks in an adaptive fast-slow planning, where the higher-level subroutines are explored first, and only when they fail, the low-level A$^*$ search is activated. The reusable symbolic subroutines considerably save exploration cost on the same types of subtasks applied to similar images, yielding a human-like fast-slow toolpath agent \"FaSTA$^*$'': fast subtask planning followed by rule-based subroutine selection per subtask is attempted by LLMs at first, which is expected to cover most tasks, while slow A$^*$ search is only triggered for novel and challenging subtasks. By comparing with recent image editing approaches, we demonstrate FaSTA$^*$ is significantly more computationally efficient while remaining competitive with the state-of-the-art baseline in terms of success rate.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.20911.pdf", "abstract_url": "https://arxiv.org/abs/2506.20911", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "FaSTA$^*$是一种成本高效的神经符号代理，用于处理多轮图像编辑任务，结合了大型语言模型（LLMs）的快速高级子任务规划和慢速、准确的工具使用及局部A$^*$搜索，以找到成本高效的工具路径。通过归纳推理成功工具路径，提取/精炼常用子程序并作为新工具重用，实现了自适应快慢规划，显著提高了计算效率。", "motivation": "解决多轮图像编辑任务中的成本效率问题，如同时进行物体检测、重新着色和移除等操作。", "method": "结合大型语言模型（LLMs）的快速高级子任务规划和慢速、准确的工具使用及局部A$^*$搜索，通过归纳推理提取/精炼常用子程序并重用。", "result": "FaSTA$^*$在计算效率上显著优于最近的图像编辑方法，同时在成功率上与最先进的基线方法保持竞争力。", "conclusion": "FaSTA$^*$通过快慢规划和子程序重用，有效解决了多轮图像编辑任务中的成本效率问题，为未来的图像编辑工具提供了新的思路。"}}
{"id": "2506.20876", "title": "Decide less, communicate more: On the construct validity of end-to-end fact-checking in medicine", "authors": ["Sebastian Joseph", "Lily Chen", "Barry Wei", "Michael Mackert", "Iain J. Marshall", "Paul Pu Liang", "Ramez Kouzy", "Byron C. Wallace", "Junyi Jessy Li"], "abstract": "Technological progress has led to concrete advancements in tasks that were regarded as challenging, such as automatic fact-checking. Interest in adopting these systems for public health and medicine has grown due to the high-stakes nature of medical decisions and challenges in critically appraising a vast and diverse medical literature. Evidence-based medicine connects to every individual, and yet the nature of it is highly technical, rendering the medical literacy of majority users inadequate to sufficiently navigate the domain. Such problems with medical communication ripens the ground for end-to-end fact-checking agents: check a claim against current medical literature and return with an evidence-backed verdict. And yet, such systems remain largely unused. To understand this, we present the first study examining how clinical experts verify real claims from social media by synthesizing medical evidence. In searching for this upper-bound, we reveal fundamental challenges in end-to-end fact-checking when applied to medicine: Difficulties connecting claims in the wild to scientific evidence in the form of clinical trials; ambiguities in underspecified claims mixed with mismatched intentions; and inherently subjective veracity labels. We argue that fact-checking should be approached and evaluated as an interactive communication problem, rather than an end-to-end process.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.20876.pdf", "abstract_url": "https://arxiv.org/abs/2506.20876", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了在医学领域应用端到端事实核查系统的有效性，揭示了将社交媒体上的医学声明与临床试验证据连接起来的挑战，并主张将事实核查视为互动沟通问题而非端到端过程。", "motivation": "解决在医学领域应用自动事实核查系统时遇到的挑战，包括将社交媒体上的声明与科学证据连接、处理不明确的声明以及主观真实性标签的问题。", "method": "通过研究临床专家如何通过综合医学证据验证社交媒体上的真实声明，探索端到端事实核查在医学中的应用上限。", "result": "揭示了在医学领域应用端到端事实核查时的基本挑战，包括证据连接困难、声明不明确和意图不匹配、以及主观真实性标签的问题。", "conclusion": "事实核查应被视为并评估为一个互动沟通问题，而非端到端过程，以更有效地应对医学领域的挑战。"}}
{"id": "2506.20821", "title": "MultiFinRAG: An Optimized Multimodal Retrieval-Augmented Generation (RAG) Framework for Financial Question Answering", "authors": ["Chinmay Gondhalekar", "Urjitkumar Patel", "Fang-Chun Yeh"], "abstract": "Financial documents--such as 10-Ks, 10-Qs, and investor presentations--span hundreds of pages and combine diverse modalities, including dense narrative text, structured tables, and complex figures. Answering questions over such content often requires joint reasoning across modalities, which strains traditional large language models (LLMs) and retrieval-augmented generation (RAG) pipelines due to token limitations, layout loss, and fragmented cross-modal context. We introduce MultiFinRAG, a retrieval-augmented generation framework purpose-built for financial QA. MultiFinRAG first performs multimodal extraction by grouping table and figure images into batches and sending them to a lightweight, quantized open-source multimodal LLM, which produces both structured JSON outputs and concise textual summaries. These outputs, along with narrative text, are embedded and indexed with modality-aware similarity thresholds for precise retrieval. A tiered fallback strategy then dynamically escalates from text-only to text+table+image contexts when necessary, enabling cross-modal reasoning while reducing irrelevant context. Despite running on commodity hardware, MultiFinRAG achieves 19 percentage points higher accuracy than ChatGPT-4o (free-tier) on complex financial QA tasks involving text, tables, images, and combined multimodal reasoning.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE)", "comments": "Preprint Copy", "pdf_url": "https://arxiv.org/pdf/2506.20821.pdf", "abstract_url": "https://arxiv.org/abs/2506.20821", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Computational Engineering, Finance, and Science (cs.CE)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "MultiFinRAG是一个专为金融问答设计的优化多模态检索增强生成框架，通过多模态提取和动态回退策略，提高了跨模态推理的准确性。", "motivation": "解决传统大型语言模型和检索增强生成管道在处理金融文档（如10-Ks、10-Qs和投资者演示）时，由于令牌限制、布局丢失和碎片化的跨模态上下文而面临的挑战。", "method": "MultiFinRAG首先通过将表格和图形图像分组并发送到轻量级、量化的开源多模态LLM进行多模态提取，生成结构化JSON输出和简洁的文本摘要。然后，这些输出与叙述性文本一起嵌入，并使用模态感知相似性阈值进行索引，以实现精确检索。采用分层回退策略，在必要时从仅文本动态升级到文本+表格+图像上下文。", "result": "尽管在商品硬件上运行，MultiFinRAG在涉及文本、表格、图像和组合多模态推理的复杂金融QA任务上，比ChatGPT-4o（免费版）的准确率高出19个百分点。", "conclusion": "MultiFinRAG通过其优化的多模态检索增强生成框架，有效地解决了金融文档问答中的跨模态推理问题，显著提高了准确性和效率。"}}
{"id": "2506.20737", "title": "MAGPIE: A dataset for Multi-AGent contextual PrIvacy Evaluation", "authors": ["Gurusha Juneja", "Alon Albalak", "Wenyue Hua", "William Yang Wang"], "abstract": "The proliferation of LLM-based agents has led to increasing deployment of inter-agent collaboration for tasks like scheduling, negotiation, resource allocation etc. In such systems, privacy is critical, as agents often access proprietary tools and domain-specific databases requiring strict confidentiality. This paper examines whether LLM-based agents demonstrate an understanding of contextual privacy. And, if instructed, do these systems preserve inference time user privacy in non-adversarial multi-turn conversation. Existing benchmarks to evaluate contextual privacy in LLM-agents primarily assess single-turn, low-complexity tasks where private information can be easily excluded. We first present a benchmark - MAGPIE comprising 158 real-life high-stakes scenarios across 15 domains. These scenarios are designed such that complete exclusion of private data impedes task completion yet unrestricted information sharing could lead to substantial losses. We then evaluate the current state-of-the-art LLMs on (a) their understanding of contextually private data and (b) their ability to collaborate without violating user privacy. Empirical experiments demonstrate that current models, including GPT-4o and Claude-2.7-Sonnet, lack robust understanding of contextual privacy, misclassifying private data as shareable 25.2\\% and 43.6\\% of the time. In multi-turn conversations, these models disclose private information in 59.9\\% and 50.5\\% of cases even under explicit privacy instructions. Furthermore, multi-agent systems fail to complete tasks in 71\\% of scenarios. These results underscore that current models are not aligned towards both contextual privacy preservation and collaborative task-solving.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.20737.pdf", "abstract_url": "https://arxiv.org/abs/2506.20737", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了MAGPIE数据集，用于评估多代理系统中的上下文隐私保护能力，发现当前最先进的LLM在理解和保护上下文隐私方面存在不足。", "motivation": "随着基于LLM的代理的增多，代理间的协作任务（如调度、谈判、资源分配等）日益普遍，隐私保护变得至关重要。本文旨在探讨LLM代理是否理解上下文隐私，并在非对抗性多轮对话中保护用户隐私。", "method": "研究首先提出了一个包含158个高风险场景的MAGPIE基准测试，覆盖15个领域，旨在评估LLM在(a)理解上下文隐私数据和(b)在不侵犯用户隐私的情况下协作的能力。", "result": "实验显示，包括GPT-4o和Claude-2.7-Sonnet在内的当前模型对上下文隐私的理解不足，错误地将私有数据分类为可共享的比例分别为25.2%和43.6%。在多轮对话中，即使有明确的隐私指令，这些模型在59.9%和50.5%的情况下仍会泄露私有信息。此外，多代理系统在71%的场景中无法完成任务。", "conclusion": "结果表明，当前模型在上下文隐私保护和协作任务解决方面尚未达到理想的对齐状态。"}}
{"id": "2506.20949", "title": "Beyond Reactive Safety: Risk-Aware LLM Alignment via Long-Horizon Simulation", "authors": ["Chenkai Sun", "Denghui Zhang", "ChengXiang Zhai", "Heng Ji"], "abstract": "Given the growing influence of language model-based agents on high-stakes societal decisions, from public policy to healthcare, ensuring their beneficial impact requires understanding the far-reaching implications of their suggestions. We propose a proof-of-concept framework that projects how model-generated advice could propagate through societal systems on a macroscopic scale over time, enabling more robust alignment. To assess the long-term safety awareness of language models, we also introduce a dataset of 100 indirect harm scenarios, testing models' ability to foresee adverse, non-obvious outcomes from seemingly harmless user prompts. Our approach achieves not only over 20% improvement on the new dataset but also an average win rate exceeding 70% against strong baselines on existing safety benchmarks (AdvBench, SafeRLHF, WildGuardMix), suggesting a promising direction for safer agents.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.20949.pdf", "abstract_url": "https://arxiv.org/abs/2506.20949", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种概念验证框架，用于评估语言模型生成的建议如何在宏观社会系统中传播，并引入了一个包含100个间接伤害场景的数据集，以测试模型预见看似无害用户提示可能导致的不良、非显而易见结果的能力。该方法在新数据集上实现了超过20%的改进，并在现有安全基准测试中平均胜率超过70%，为更安全的智能体指明了方向。", "motivation": "随着基于语言模型的智能体在从公共政策到医疗保健等高风险社会决策中的影响力日益增强，确保其产生有益影响需要理解其建议的深远影响。", "method": "提出了一个概念验证框架，通过宏观社会系统的长期模拟来评估模型生成建议的传播效果，并引入了一个新的数据集来测试模型对间接伤害的预见能力。", "result": "该方法在新数据集上实现了超过20%的改进，并在现有安全基准测试中平均胜率超过70%。", "conclusion": "这项研究为开发更安全的语言模型智能体提供了一个有前景的方向，特别是在预见和减少潜在长期负面影响方面。"}}
{"id": "2506.21506", "title": "Mind2Web 2: Evaluating Agentic Search with Agent-as-a-Judge", "authors": ["Boyu Gou", "Zanming Huang", "Yuting Ning", "Yu Gu", "Michael Lin", "Weijian Qi", "Andrei Kopanev", "Botao Yu", "Bernal Jiménez Gutiérrez", "Yiheng Shu", "Chan Hee Song", "Jiaman Wu", "Shijie Chen", "Hanane Nour Moussa", "Tianshu Zhang", "Jian Xie", "Yifei Li", "Tianci Xue", "Zeyi Liao", "Kai Zhang", "Boyuan Zheng", "Zhaowei Cai", "Viktor Rozgic", "Morteza Ziyadi", "Huan Sun", "Yu Su"], "abstract": "Agentic search such as Deep Research systems, where large language models autonomously browse the web, synthesize information, and return comprehensive citation-backed answers, represents a major shift in how users interact with web-scale information. While promising greater efficiency and cognitive offloading, the growing complexity and open-endedness of agentic search have outpaced existing evaluation benchmarks and methodologies, which largely assume short search horizons and static answers. In this paper, we introduce Mind2Web 2, a benchmark of 130 realistic, high-quality, and long-horizon tasks that require real-time web browsing and extensive information synthesis, constructed with over 1,000 hours of human labor. To address the challenge of evaluating time-varying and complex answers, we propose a novel Agent-as-a-Judge framework. Our method constructs task-specific judge agents based on a tree-structured rubric design to automatically assess both answer correctness and source attribution. We conduct a comprehensive evaluation of nine frontier agentic search systems and human performance, along with a detailed error analysis to draw insights for future development. The best-performing system, OpenAI Deep Research, can already achieve 50-70% of human performance while spending half the time, showing a great potential. Altogether, Mind2Web 2 provides a rigorous foundation for developing and benchmarking the next generation of agentic search systems.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2506.21506.pdf", "abstract_url": "https://arxiv.org/abs/2506.21506", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了Mind2Web 2，一个包含130个现实、高质量、长视野任务的基准测试，用于评估代理搜索系统，并提出了一种新颖的Agent-as-a-Judge框架来自动评估答案正确性和来源归属。", "motivation": "代理搜索系统的复杂性和开放性已经超出了现有评估基准和方法的能力范围，这些基准和方法主要假设搜索视野短和答案静态。", "method": "提出了一个基于树形结构评分设计的任务特定评判代理框架，用于自动评估答案正确性和来源归属。", "result": "对九个前沿代理搜索系统和人类表现进行了全面评估，最佳表现系统OpenAI Deep Research已经能够达到人类表现的50-70%，同时花费的时间仅为一半。", "conclusion": "Mind2Web 2为开发和基准测试下一代代理搜索系统提供了严格的基础，展示了巨大的潜力。"}}
{"id": "2506.21490", "title": "Ad-Hoc Human-AI Coordination Challenge", "authors": ["Tin Dizdarević", "Ravi Hammond", "Tobias Gessler", "Anisoara Calinescu", "Jonathan Cook", "Matteo Gallici", "Andrei Lupu", "Jakob Nicolaus Foerster"], "abstract": "Achieving seamless coordination between AI agents and humans is crucial for real-world applications, yet it remains a significant open challenge. Hanabi is a cooperative card game featuring imperfect information, constrained communication, theory of mind requirements, and coordinated action -- making it an ideal testbed for human-AI coordination. However, its use for human-AI interaction has been limited by the challenges of human evaluation. In this work, we introduce the Ad-Hoc Human-AI Coordination Challenge (AH2AC2) to overcome the constraints of costly and difficult-to-reproduce human evaluations. We develop \\textit{human proxy agents} on a large-scale human dataset that serve as robust, cheap, and reproducible human-like evaluation partners in AH2AC2. To encourage the development of data-efficient methods, we open-source a dataset of 3,079 games, deliberately limiting the amount of available human gameplay data. We present baseline results for both two- and three- player Hanabi scenarios. To ensure fair evaluation, we host the proxy agents through a controlled evaluation system rather than releasing them publicly. The code is available at \\href{", "subjects": "Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Multiagent Systems (cs.MA)", "comments": "Published at ICML 2025", "pdf_url": "https://arxiv.org/pdf/2506.21490.pdf", "abstract_url": "https://arxiv.org/abs/2506.21490", "categories": ["Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了Ad-Hoc Human-AI Coordination Challenge (AH2AC2)，旨在通过开发人类代理代理来解决人类评估成本高和难以复现的问题，以促进AI与人类的无缝协调。", "motivation": "解决AI代理与人类在现实应用中无缝协调的开放挑战，特别是在Hanabi这样的合作卡牌游戏中，由于人类评估的高成本和难以复现性，这一挑战尤为突出。", "method": "开发了基于大规模人类数据的人类代理代理，作为在AH2AC2中 robust、廉价且可复现的人类评估伙伴，并开源了一个包含3,079局游戏的有限数据集。", "result": "为两玩家和三玩家的Hanabi场景提供了基线结果，并通过受控评估系统托管代理代理以确保公平评估。", "conclusion": "AH2AC2和人类代理代理的开发为研究AI与人类协调提供了一个实用、可扩展的框架，同时开源的数据集和代码促进了数据高效方法的发展。"}}
{"id": "2506.21536", "title": "PsyLite Technical Report", "authors": ["Fangjun Ding", "Renyu Zhang", "Xinyu Feng", "Chengye Xie", "Zheng Zhang", "Yanting Zhang"], "abstract": "With the rapid development of digital technology, AI-driven psychological counseling has gradually become an important research direction in the field of mental health. However, existing models still have deficiencies in dialogue safety, detailed scenario handling, and lightweight deployment. To address these issues, this study proposes PsyLite, a lightweight psychological counseling large language model agent developed based on the base model InternLM2.5-7B-chat. Through a two-stage training strategy (hybrid distillation data fine-tuning and ORPO preference optimization), PsyLite enhances the model's deep-reasoning ability, psychological counseling ability, and safe dialogue ability. After deployment using Ollama and Open WebUI, a custom workflow is created with Pipelines. An innovative conditional RAG is designed to introduce crosstalk humor elements at appropriate times during psychological counseling to enhance user experience and decline dangerous requests to strengthen dialogue safety. Evaluations show that PsyLite outperforms the baseline models in the Chinese general evaluation (CEval), psychological counseling professional evaluation (CPsyCounE), and dialogue safety evaluation (SafeDialBench), particularly in psychological counseling professionalism (CPsyCounE score improvement of 47.6\\%) and dialogue safety (\\safe{} score improvement of 2.4\\%). Additionally, the model uses quantization technology (GGUF q4\\_k\\_m) to achieve low hardware deployment (5GB memory is sufficient for operation), providing a feasible solution for psychological counseling applications in resource-constrained environments.", "subjects": "Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.21536.pdf", "abstract_url": "https://arxiv.org/abs/2506.21536", "categories": ["Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本研究提出PsyLite，一个基于InternLM2.5-7B-chat开发的轻量级心理咨询大语言模型代理，通过两阶段训练策略增强模型的深度推理能力、心理咨询能力和安全对话能力，并在资源受限环境中提供可行的心理咨询应用解决方案。", "motivation": "解决现有AI心理咨询模型在对话安全、详细场景处理和轻量级部署方面的不足。", "method": "采用混合蒸馏数据微调和ORPO偏好优化的两阶段训练策略，设计创新的条件RAG引入相声幽默元素，并使用量化技术实现低硬件部署。", "result": "PsyLite在中文通用评估(CEval)、心理咨询专业评估(CPsyCounE)和对话安全评估(SafeDialBench)中优于基线模型，特别是在心理咨询专业性(CPsyCounE分数提高47.6%)和对话安全(安全分数提高2.4%)方面表现突出。", "conclusion": "PsyLite通过技术创新和优化，为资源受限环境中的心理咨询应用提供了高效、安全的解决方案。"}}
{"id": "2504.15217", "title": "DRAGON: Distributional Rewards Optimize Diffusion Generative Models", "authors": ["Yatong Bai", "Jonah Casebeer", "Somayeh Sojoudi", "Nicholas J. Bryan"], "abstract": "We present Distributional RewArds for Generative OptimizatioN (DRAGON), a versatile framework for fine-tuning media generation models towards a desired outcome. Compared with traditional reinforcement learning with human feedback (RLHF) or pairwise preference approaches such as direct preference optimization (DPO), DRAGON is more flexible. It can optimize reward functions that evaluate either individual examples or distributions of them, making it compatible with a broad spectrum of instance-wise, instance-to-distribution, and distribution-to-distribution rewards. Leveraging this versatility, we construct novel reward functions by selecting an encoder and a set of reference examples to create an exemplar distribution. When cross-modality encoders such as CLAP are used, the reference examples may be of a different modality (e.g., text versus audio). Then, DRAGON gathers online and on-policy generations, scores them to construct a positive demonstration set and a negative set, and leverages the contrast between the two sets to maximize the reward. For evaluation, we fine-tune an audio-domain text-to-music diffusion model with 20 different reward functions, including a custom music aesthetics model, CLAP score, Vendi diversity, and Frechet audio distance (FAD). We further compare instance-wise (per-song) and full-dataset FAD settings while ablating multiple FAD encoders and reference sets. Over all 20 target rewards, DRAGON achieves an 81.45% average win rate. Moreover, reward functions based on exemplar sets indeed enhance generations and are comparable to model-based rewards. With an appropriate exemplar set, DRAGON achieves a 60.95% human-voted music quality win rate without training on human preference annotations. As such, DRAGON exhibits a new approach to designing and optimizing reward functions for improving human-perceived quality. Sound examples at", "subjects": "Sound (cs.SD); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multimedia (cs.MM)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.15217.pdf", "abstract_url": "https://arxiv.org/abs/2504.15217", "categories": ["Sound (cs.SD)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Multimedia (cs.MM)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "DRAGON是一个用于微调媒体生成模型的框架，通过分布奖励优化生成模型，比传统方法更灵活，支持多种奖励函数，并在音频领域的文本到音乐扩散模型中展示了其有效性。", "motivation": "解决传统强化学习与人类反馈（RLHF）或直接偏好优化（DPO）等方法在优化生成模型时的局限性，提供更灵活的奖励函数优化方案。", "method": "利用选择的编码器和参考示例创建示范分布，通过对比正负示例集来最大化奖励，支持实例级、实例到分布和分布到分布的奖励函数。", "result": "在20种不同的奖励函数上，DRAGON实现了81.45%的平均胜率，且基于示范集的奖励函数在没有人类偏好注释训练的情况下，实现了60.95%的人类投票音乐质量胜率。", "conclusion": "DRAGON展示了设计和优化奖励函数以提高人类感知质量的新方法，其灵活性和有效性在音频生成任务中得到了验证。"}}
{"id": "2506.21098", "title": "ComRAG: Retrieval-Augmented Generation with Dynamic Vector Stores for Real-time Community Question Answering in Industry", "authors": ["Qinwen Chen", "Wenbiao Tao", "Zhiwei Zhu", "Mingfan Xi", "Liangzhong Guo", "Yuan Wang", "Wei Wang", "Yunshi Lan"], "abstract": "Community Question Answering (CQA) platforms can be deemed as important knowledge bases in community, but effectively leveraging historical interactions and domain knowledge in real-time remains a challenge. Existing methods often underutilize external knowledge, fail to incorporate dynamic historical QA context, or lack memory mechanisms suited for industrial deployment. We propose ComRAG, a retrieval-augmented generation framework for real-time industrial CQA that integrates static knowledge with dynamic historical QA pairs via a centroid-based memory mechanism designed for retrieval, generation, and efficient storage. Evaluated on three industrial CQA datasets, ComRAG consistently outperforms all baselines--achieving up to 25.9% improvement in vector similarity, reducing latency by 8.7% to 23.3%, and lowering chunk growth from 20.23% to 2.06% over iterations.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "7 pages, 4 figures. Accepted at ACL 2025 Industry Track", "pdf_url": "https://arxiv.org/pdf/2506.21098.pdf", "abstract_url": "https://arxiv.org/abs/2506.21098", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "ComRAG是一个针对工业实时社区问答的检索增强生成框架，通过基于质心的记忆机制整合静态知识和动态历史问答对，显著提升了性能。", "motivation": "社区问答平台作为重要的社区知识库，如何有效利用历史交互和领域知识进行实时问答仍是一个挑战。现有方法往往未能充分利用外部知识，或缺乏适合工业部署的记忆机制。", "method": "提出了ComRAG框架，通过基于质心的记忆机制设计，用于检索、生成和高效存储，整合静态知识和动态历史问答对。", "result": "在三个工业CQA数据集上的评估显示，ComRAG在所有基线中表现最佳，向量相似性提高了25.9%，延迟减少了8.7%至23.3%，迭代过程中的块增长从20.23%降至2.06%。", "conclusion": "ComRAG通过其独特的记忆机制和高效的存储策略，为工业实时社区问答提供了一个有效的解决方案，显著提高了问答质量和系统性能。"}}
{"id": "2506.21252", "title": "Agent-RewardBench: Towards a Unified Benchmark for Reward Modeling across Perception, Planning, and Safety in Real-World Multimodal Agents", "authors": ["Tianyi Men", "Zhuoran Jin", "Pengfei Cao", "Yubo Chen", "Kang Liu", "Jun Zhao"], "abstract": "As Multimodal Large Language Models (MLLMs) advance, multimodal agents show promise in real-world tasks like web navigation and embodied intelligence. However, due to limitations in a lack of external feedback, these agents struggle with self-correction and generalization. A promising approach is to use reward models as external feedback, but there is no clear on how to select reward models for agents. Thus, there is an urgent need to build a reward bench targeted at agents. To address these challenges, we propose Agent-RewardBench, a benchmark designed to evaluate reward modeling ability in MLLMs. The benchmark is characterized by three key features: (1) Multiple dimensions and real-world agent scenarios evaluation. It covers perception, planning, and safety with 7 scenarios; (2) Step-level reward evaluation. It allows for the assessment of agent capabilities at the individual steps of a task, providing a more granular view of performance during the planning process; and (3) Appropriately difficulty and high-quality. We carefully sample from 10 diverse models, difficulty control to maintain task challenges, and manual verification to ensure the integrity of the data. Experiments demonstrate that even state-of-the-art multimodal models show limited performance, highlighting the need for specialized training in agent reward modeling. Code is available at github.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "ACL 2025 Main", "pdf_url": "https://arxiv.org/pdf/2506.21252.pdf", "abstract_url": "https://arxiv.org/abs/2506.21252", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "提出了Agent-RewardBench，一个评估多模态大语言模型（MLLMs）奖励建模能力的基准，旨在解决多模态代理在现实世界任务中因缺乏外部反馈而面临的自我纠正和泛化问题。", "motivation": "多模态代理在现实世界任务中表现出潜力，但由于缺乏外部反馈，它们在自我纠正和泛化方面存在困难。奖励模型作为一种外部反馈方法，其选择标准尚不明确，因此迫切需要建立一个针对代理的奖励基准。", "method": "提出了Agent-RewardBench基准，该基准具有三个关键特征：（1）多维度评估和现实世界代理场景，涵盖感知、规划和安全等7个场景；（2）步骤级奖励评估，允许在任务的各个步骤评估代理能力；（3）适当的难度和高质量，通过从10个不同模型中精心采样、难度控制以及手动验证来确保数据的完整性。", "result": "实验表明，即使是先进的多模态模型也表现出有限的性能，这凸显了在代理奖励建模方面进行专门训练的必要性。", "conclusion": "Agent-RewardBench为评估和提升多模态代理在现实世界任务中的奖励建模能力提供了一个统一的基准，揭示了当前模型在这一领域的局限性，并指出了未来研究的方向。"}}
{"id": "2506.21384", "title": "Leveraging LLM-Assisted Query Understanding for Live Retrieval-Augmented Generation", "authors": ["Guanting Dong", "Xiaoxi Li", "Yuyao Zhang", "Mengjie Deng"], "abstract": "Real-world live retrieval-augmented generation (RAG) systems face significant challenges when processing user queries that are often noisy, ambiguous, and contain multiple intents. While RAG enhances large language models (LLMs) with external knowledge, current systems typically struggle with such complex inputs, as they are often trained or evaluated on cleaner data. This paper introduces Omni-RAG, a novel framework designed to improve the robustness and effectiveness of RAG systems in live, open-domain settings. Omni-RAG employs LLM-assisted query understanding to preprocess user inputs through three key modules: (1) Deep Query Understanding and Decomposition, which utilizes LLMs with tailored prompts to denoise queries (e.g., correcting spelling errors) and decompose multi-intent queries into structured sub-queries; (2) Intent-Aware Knowledge Retrieval, which performs retrieval for each sub-query from a corpus (i.e., FineWeb using OpenSearch) and aggregates the results; and (3) Reranking and Generation, where a reranker (i.e., BGE) refines document selection before a final response is generated by an LLM (i.e., Falcon-10B) using a chain-of-thought prompt. Omni-RAG aims to bridge the gap between current RAG capabilities and the demands of real-world applications, such as those highlighted by the SIGIR 2025 LiveRAG Challenge, by robustly handling complex and noisy queries.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": "Accepted at SIGIR 2025 LiveRAG Workshop (Oral Presentation)", "pdf_url": "https://arxiv.org/pdf/2506.21384.pdf", "abstract_url": "https://arxiv.org/abs/2506.21384", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了Omni-RAG框架，旨在通过LLM辅助的查询理解提升实时检索增强生成（RAG）系统在处理嘈杂、模糊及多意图用户查询时的鲁棒性和有效性。", "motivation": "解决实时检索增强生成（RAG）系统在处理复杂、嘈杂查询时的挑战，如用户查询的噪声、模糊性和多意图问题。", "method": "Omni-RAG框架采用LLM辅助的查询理解，包括深度查询理解与分解、意图感知的知识检索以及重新排名与生成三个关键模块。", "result": "通过这三个模块，Omni-RAG能够有效地分解多意图查询、从FineWeb等语料库中检索相关信息，并通过重新排名和生成最终响应。", "conclusion": "Omni-RAG框架旨在弥合当前RAG能力与实时应用需求之间的差距，特别是在处理复杂和嘈杂查询方面，为如SIGIR 2025 LiveRAG Challenge等实际应用场景提供了解决方案。"}}
{"id": "2506.20806", "title": "Poster: Enhancing GNN Robustness for Network Intrusion Detection via Agent-based Analysis", "authors": ["Zhonghao Zhan", "Huichi Zhou", "Hamed Haddadi"], "abstract": "Graph Neural Networks (GNNs) show great promise for Network Intrusion Detection Systems (NIDS), particularly in IoT environments, but suffer performance degradation due to distribution drift and lack robustness against realistic adversarial attacks. Current robustness evaluations often rely on unrealistic synthetic perturbations and lack demonstrations on systematic analysis of different kinds of adversarial attack, which encompass both black-box and white-box scenarios. This work proposes a novel approach to enhance GNN robustness and generalization by employing Large Language Models (LLMs) in an agentic pipeline as simulated cybersecurity expert agents. These agents scrutinize graph structures derived from network flow data, identifying and potentially mitigating suspicious or adversarially perturbed elements before GNN processing. Our experiments, using a framework designed for realistic evaluation and testing with a variety of adversarial attacks including a dataset collected from physical testbed experiments, demonstrate that integrating LLM analysis can significantly improve the resilience of GNN-based NIDS against challenges, showcasing the potential of LLM agent as a complementary layer in intrusion detection architectures.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": "Poster accepted at the 10th IEEE European Symposium on Security and Privacy (Euro S&P 2025)", "pdf_url": "https://arxiv.org/pdf/2506.20806.pdf", "abstract_url": "https://arxiv.org/abs/2506.20806", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种新颖的方法，通过利用大型语言模型（LLMs）作为模拟网络安全专家代理，来增强图神经网络（GNNs）在网络入侵检测系统（NIDS）中的鲁棒性和泛化能力。", "motivation": "图神经网络（GNNs）在网络入侵检测系统（NIDS）中显示出巨大潜力，尤其是在物联网（IoT）环境中，但由于分布漂移和缺乏对现实对抗攻击的鲁棒性，其性能会下降。当前的鲁棒性评估往往依赖于不现实的合成扰动，缺乏对不同种类对抗攻击（包括黑盒和白盒场景）的系统分析演示。", "method": "本研究提出了一种新颖的方法，通过使用大型语言模型（LLMs）在代理管道中作为模拟网络安全专家代理，来增强GNN的鲁棒性和泛化能力。这些代理会审查来自网络流量数据的图结构，识别并可能在GNN处理之前减轻可疑或对抗性扰动的元素。", "result": "我们的实验，使用一个设计用于现实评估和测试的框架，包括从物理测试台实验收集的数据集，展示了整合LLM分析可以显著提高基于GNN的NIDS对挑战的抵抗力，展示了LLM代理作为入侵检测架构中补充层的潜力。", "conclusion": "通过整合大型语言模型（LLMs）的分析，可以显著提高基于图神经网络（GNNs）的网络入侵检测系统（NIDS）对挑战的抵抗力，展示了LLM代理作为入侵检测架构中补充层的潜力。"}}
{"id": "2506.20869", "title": "Engineering RAG Systems for Real-World Applications: Design, Development, and Evaluation", "authors": ["Md Toufique Hasan", "Muhammad Waseem", "Kai-Kristian Kemell", "Ayman Asad Khan", "Mika Saari", "Pekka Abrahamsson"], "abstract": "Retrieval-Augmented Generation (RAG) systems are emerging as a key approach for grounding Large Language Models (LLMs) in external knowledge, addressing limitations in factual accuracy and contextual relevance. However, there is a lack of empirical studies that report on the development of RAG-based implementations grounded in real-world use cases, evaluated through general user involvement, and accompanied by systematic documentation of lessons learned. This paper presents five domain-specific RAG applications developed for real-world scenarios across governance, cybersecurity, agriculture, industrial research, and medical diagnostics. Each system incorporates multilingual OCR, semantic retrieval via vector embeddings, and domain-adapted LLMs, deployed through local servers or cloud APIs to meet distinct user needs. A web-based evaluation involving a total of 100 participants assessed the systems across six dimensions: (i) Ease of Use, (ii) Relevance, (iii) Transparency, (iv) Responsiveness, (v) Accuracy, and (vi) Likelihood of Recommendation. Based on user feedback and our development experience, we documented twelve key lessons learned, highlighting technical, operational, and ethical challenges affecting the reliability and usability of RAG systems in practice.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": "Accepted as a full paper to the 51st Euromicro Conference on Software Engineering and Advanced Applications (SEAA 2025). 9 pages, 4 figures. This is the preprint version and not the final camera ready version", "pdf_url": "https://arxiv.org/pdf/2506.20869.pdf", "abstract_url": "https://arxiv.org/abs/2506.20869", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了五种针对特定领域的RAG（检索增强生成）系统，这些系统应用于治理、网络安全、农业、工业研究和医疗诊断等实际场景。通过多语言OCR、语义检索和领域适应的LLMs技术，系统通过本地服务器或云API部署。通过100名参与者的网络评估，从六个维度评估了系统的性能，并总结了十二个关键经验教训。", "motivation": "解决大型语言模型（LLMs）在事实准确性和上下文相关性方面的限制，缺乏基于真实用例的RAG系统开发经验分享和系统评估的问题。", "method": "开发了五种领域特定的RAG应用，结合多语言OCR、向量嵌入的语义检索和领域适应的LLMs技术，通过用户参与的网络评估进行系统评估。", "result": "用户评估显示系统在易用性、相关性、透明度、响应性、准确性和推荐可能性六个维度上表现良好，总结了影响RAG系统可靠性和实用性的技术、操作和伦理挑战。", "conclusion": "RAG系统在实际应用中展现出潜力，但需克服技术、操作和伦理挑战，以提高其可靠性和用户体验。"}}
{"id": "2506.20883", "title": "Complex Model Transformations by Reinforcement Learning with Uncertain Human Guidance", "authors": ["Kyanna Dagenais", "Istvan David"], "abstract": "Model-driven engineering problems often require complex model transformations (MTs), i.e., MTs that are chained in extensive sequences. Pertinent examples of such problems include model synchronization, automated model repair, and design space exploration. Manually developing complex MTs is an error-prone and often infeasible process. Reinforcement learning (RL) is an apt way to alleviate these issues. In RL, an autonomous agent explores the state space through trial and error to identify beneficial sequences of actions, such as MTs. However, RL methods exhibit performance issues in complex problems. In these situations, human guidance can be of high utility. In this paper, we present an approach and technical framework for developing complex MT sequences through RL, guided by potentially uncertain human advice. Our framework allows user-defined MTs to be mapped onto RL primitives, and executes them as RL programs to find optimal MT sequences. Our evaluation shows that human guidance, even if uncertain, substantially improves RL performance, and results in more efficient development of complex MTs. Through a trade-off between the certainty and timeliness of human advice, our method takes a step towards RL-driven human-in-the-loop engineering methods.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "Accepted for ACM/IEEE MODELS'25", "pdf_url": "https://arxiv.org/pdf/2506.20883.pdf", "abstract_url": "https://arxiv.org/abs/2506.20883", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种通过强化学习（RL）结合不确定的人类指导来开发复杂模型转换（MT）序列的方法和技术框架。该方法允许将用户定义的MT映射到RL原语上，并通过RL程序执行以找到最优的MT序列。评估表明，即使人类指导存在不确定性，也能显著提高RL性能，并更高效地开发复杂MT。", "motivation": "解决模型驱动工程中复杂模型转换（MT）序列开发的问题，这些转换通常需要串联成复杂的序列，手动开发既容易出错又往往不可行。", "method": "提出了一种结合强化学习（RL）和不确定人类指导的方法和技术框架，将用户定义的MT映射到RL原语上，通过RL程序执行以寻找最优MT序列。", "result": "评估结果显示，即使人类指导存在不确定性，也能显著提高RL性能，并更高效地开发复杂MT。", "conclusion": "通过在人类建议的确定性和及时性之间取得平衡，该方法向RL驱动的人类在环工程方法迈进了一步。"}}
{"id": "2506.20921", "title": "LLM-guided Chemical Process Optimization with a Multi-Agent Approach", "authors": ["Tong Zeng", "Srivathsan Badrinarayanan", "Janghoon Ock", "Cheng-Kai Lai", "Amir Barati Farimani"], "abstract": "Chemical process optimization is crucial to maximize production efficiency and economic performance. Traditional methods, including gradient-based solvers, evolutionary algorithms, and parameter grid searches, become impractical when operating constraints are ill-defined or unavailable, requiring engineers to rely on subjective heuristics to estimate feasible parameter ranges. To address this constraint definition bottleneck, we present a multi-agent framework of large language model (LLM) agents that autonomously infer operating constraints from minimal process descriptions, then collaboratively guide optimization using the inferred constraints. Our AutoGen-based agentic framework employs OpenAI's o3 model, with specialized agents for constraint generation, parameter validation, simulation execution, and optimization guidance. Through two phases - autonomous constraint generation using embedded domain knowledge, followed by iterative multi-agent optimization - the framework eliminates the need for predefined operational bounds. Validated on the hydrodealkylation process across cost, yield, and yield-to-cost ratio metrics, the framework demonstrated competitive performance with conventional optimization methods while achieving better computational efficiency, requiring fewer iterations to converge. Our approach converged in under 20 minutes, achieving a 31-fold speedup over grid search. Beyond computational efficiency, the framework's reasoning-guided search demonstrates sophisticated process understanding, correctly identifying utility trade-offs, and applying domain-informed heuristics. This approach shows significant potential for optimization scenarios where operational constraints are poorly characterized or unavailable, particularly for emerging processes and retrofit applications.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE)", "comments": "16 pages (main manuscript without references), 2 figures", "pdf_url": "https://arxiv.org/pdf/2506.20921.pdf", "abstract_url": "https://arxiv.org/abs/2506.20921", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computational Engineering, Finance, and Science (cs.CE)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种基于大型语言模型（LLM）的多智能体框架，用于化学过程优化，通过自主推断操作约束并协作指导优化，解决了传统方法在约束定义不明确时的局限性。", "motivation": "化学过程优化对提高生产效率和经济效益至关重要。传统方法在操作约束不明确或不可用时变得不切实际，工程师需要依赖主观启发式方法来估计可行参数范围。本文旨在解决这一约束定义的瓶颈问题。", "method": "采用基于AutoGen的多智能体框架，利用OpenAI的o3模型，包括约束生成、参数验证、模拟执行和优化指导等专门智能体。通过自主约束生成和迭代多智能体优化两阶段，无需预定义操作界限。", "result": "在氢化脱烷基化过程中，该框架在成本、收率和收率-成本比指标上表现出与传统优化方法相竞争的性能，同时计算效率更高，收敛所需迭代次数更少。框架在20分钟内收敛，比网格搜索快31倍。", "conclusion": "该方法在操作约束不明确或不可用的优化场景中显示出巨大潜力，特别是对于新兴过程和改造应用。其推理引导的搜索展示了复杂的过程理解，正确识别了效用权衡，并应用了领域知识的启发式方法。"}}
{"id": "2506.21552", "title": "Whole-Body Conditioned Egocentric Video Prediction", "authors": ["Yutong Bai", "Danny Tran", "Amir Bar", "Yann LeCun", "Trevor Darrell", "Jitendra Malik"], "abstract": "We train models to Predict Ego-centric Video from human Actions (PEVA), given the past video and an action represented by the relative 3D body pose. By conditioning on kinematic pose trajectories, structured by the joint hierarchy of the body, our model learns to simulate how physical human actions shape the environment from a first-person point of view. We train an auto-regressive conditional diffusion transformer on Nymeria, a large-scale dataset of real-world egocentric video and body pose capture. We further design a hierarchical evaluation protocol with increasingly challenging tasks, enabling a comprehensive analysis of the model's embodied prediction and control abilities. Our work represents an initial attempt to tackle the challenges of modeling complex real-world environments and embodied agent behaviors with video prediction from the perspective of a human.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multimedia (cs.MM); Robotics (cs.RO)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2506.21552.pdf", "abstract_url": "https://arxiv.org/abs/2506.21552", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Multimedia (cs.MM)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文训练了一个模型，通过给定的过去视频和由相对3D身体姿势表示的动作，来预测以自我为中心的视频（PEVA）。通过基于身体关节层次结构的运动姿势轨迹，模型学习模拟物理人类动作如何从第一人称视角塑造环境。", "motivation": "解决从人类动作预测以自我为中心视频的挑战，模拟复杂现实环境和体现代理行为。", "method": "在Nymeria大规模数据集上训练自回归条件扩散变换器，该数据集包含真实世界的以自我为中心的视频和身体姿势捕捉。", "result": "设计了一个分层评估协议，包含越来越具挑战性的任务，全面分析了模型的体现预测和控制能力。", "conclusion": "这项工作是从人类视角解决建模复杂现实环境和体现代理行为的视频预测挑战的初步尝试。"}}
{"id": "2506.21129", "title": "Curriculum-Guided Antifragile Reinforcement Learning for Secure UAV Deconfliction under Observation-Space Attacks", "authors": ["Deepak Kumar Panda", "Adolfo Perrusquia", "Weisi Guo"], "abstract": "Reinforcement learning (RL) policies deployed in safety-critical systems, such as unmanned aerial vehicle (UAV) navigation in dynamic airspace, are vulnerable to out-ofdistribution (OOD) adversarial attacks in the observation space. These attacks induce distributional shifts that significantly degrade value estimation, leading to unsafe or suboptimal decision making rendering the existing policy fragile. To address this vulnerability, we propose an antifragile RL framework designed to adapt against curriculum of incremental adversarial perturbations. The framework introduces a simulated attacker which incrementally increases the strength of observation-space perturbations which enables the RL agent to adapt and generalize across a wider range of OOD observations and anticipate previously unseen attacks. We begin with a theoretical characterization of fragility, formally defining catastrophic forgetting as a monotonic divergence in value function distributions with increasing perturbation strength. Building on this, we define antifragility as the boundedness of such value shifts and derive adaptation conditions under which forgetting is stabilized. Our method enforces these bounds through iterative expert-guided critic alignment using Wasserstein distance minimization across incrementally perturbed observations. We empirically evaluate the approach in a UAV deconfliction scenario involving dynamic 3D obstacles. Results show that the antifragile policy consistently outperforms standard and robust RL baselines when subjected to both projected gradient descent (PGD) and GPS spoofing attacks, achieving up to 15% higher cumulative reward and over 30% fewer conflict events. These findings demonstrate the practical and theoretical viability of antifragile reinforcement learning for secure and resilient decision-making in environments with evolving threat scenarios.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.21129.pdf", "abstract_url": "https://arxiv.org/abs/2506.21129", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种抗脆弱的强化学习框架，旨在通过逐步增加的对抗性扰动课程来适应和抵御观察空间中的攻击，以提高无人机在动态空域中的导航安全性。", "motivation": "安全关键系统中的强化学习策略，如无人机导航，容易受到观察空间中的分布外对抗攻击，这些攻击会导致价值估计显著下降，从而使现有策略变得脆弱。", "method": "提出了一种抗脆弱的强化学习框架，通过引入模拟攻击者逐步增加观察空间的扰动强度，使RL代理能够适应和泛化到更广泛的分布外观察，并预见先前未见过的攻击。", "result": "在无人机冲突避免场景中，抗脆弱策略在受到投影梯度下降和GPS欺骗攻击时， consistently outperforms标准和鲁棒的RL基线，实现了高达15%的更高累积奖励和超过30%的冲突事件减少。", "conclusion": "研究结果表明，抗脆弱强化学习在具有 evolving威胁场景的环境中，对于安全和弹性的决策制定具有实际和理论的可行性。"}}
{"id": "2506.21037", "title": "RL-Selector: Reinforcement Learning-Guided Data Selection via Redundancy Assessment", "authors": ["Suorong Yang", "Peijia Li", "Furao Shen", "Jian Zhao"], "abstract": "Modern deep architectures often rely on large-scale datasets, but training on these datasets incurs high computational and storage overhead. Real-world datasets often contain substantial redundancies, prompting the need for more data-efficient training paradigms. Data selection has shown promise to mitigate redundancy by identifying the most representative samples, thereby reducing training costs without compromising performance. Existing methods typically rely on static scoring metrics or pretrained models, overlooking the combined effect of selected samples and their evolving dynamics during training. We introduce the concept of epsilon-sample cover, which quantifies sample redundancy based on inter-sample relationships, capturing the intrinsic structure of the dataset. Based on this, we reformulate data selection as a reinforcement learning (RL) process and propose RL-Selector, where a lightweight RL agent optimizes the selection policy by leveraging epsilon-sample cover derived from evolving dataset distribution as a reward signal. Extensive experiments across benchmark datasets and diverse architectures demonstrate that our method consistently outperforms existing state-of-the-art baselines. Models trained with our selected datasets show enhanced generalization performance with improved training efficiency.", "subjects": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV)", "comments": "ICCV 2025", "pdf_url": "https://arxiv.org/pdf/2506.21037.pdf", "abstract_url": "https://arxiv.org/abs/2506.21037", "categories": ["Machine Learning (cs.LG)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为RL-Selector的方法，通过强化学习引导的数据选择来减少训练深度学习模型时的冗余数据，提高训练效率而不牺牲性能。", "motivation": "现代深度学习架构通常依赖于大规模数据集，但在这类数据集上训练会产生高计算和存储开销。现实世界的数据集往往包含大量冗余，这促使需要更高效的数据训练范式。", "method": "引入了epsilon-sample cover的概念，量化基于样本间关系的样本冗余，捕捉数据集的内在结构。基于此，将数据选择重新表述为一个强化学习过程，并提出RL-Selector，其中轻量级RL代理通过利用从演化数据集分布中导出的epsilon-sample cover作为奖励信号来优化选择策略。", "result": "在基准数据集和多样化架构上的广泛实验表明，我们的方法 consistently outperforms现有的最先进基线。使用我们选定的数据集训练的模型显示出增强的泛化性能和改进的训练效率。", "conclusion": "RL-Selector通过强化学习引导的数据选择，有效地减少了训练深度学习模型时的冗余数据，提高了训练效率，同时保持了模型的性能。"}}
