{"id": "2506.14831", "title": "Recent Advances in Multi-Agent Human Trajectory Prediction: A Comprehensive Review", "authors": ["Céline Finet", "Stephane Da Silva Martins", "Jean-Bernard Hayet", "Ioannis Karamouzas", "Javad Amirian", "Sylvie Le Hégarat-Mascle", "Julien Pettré", "Emanuel Aldea"], "abstract": "With the emergence of powerful data-driven methods in human trajectory prediction (HTP), gaining a finer understanding of multi-agent interactions lies within hand's reach, with important implications in areas such as autonomous navigation and crowd modeling. This survey reviews some of the most recent advancements in deep learning-based multi-agent trajectory prediction, focusing on studies published between 2020 and 2024. We categorize the existing methods based on their architectural design, their input representations, and their overall prediction strategies, placing a particular emphasis on models evaluated using the ETH/UCY benchmark. Furthermore, we highlight key challenges and future research directions in the field of multi-agent HTP.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Robotics (cs.RO)", "comments": "30 pages", "pdf_url": "https://arxiv.org/pdf/2506.14831.pdf", "abstract_url": "https://arxiv.org/abs/2506.14831", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Machine Learning (cs.LG)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文综述了2020年至2024年间基于深度学习的多智能体人类轨迹预测的最新进展，重点分析了ETH/UCY基准测试中的模型，并探讨了该领域的关键挑战和未来研究方向。", "motivation": "随着数据驱动方法在人类轨迹预测（HTP）中的兴起，深入理解多智能体互动成为可能，这对自主导航和人群建模等领域具有重要意义。", "method": "本文根据架构设计、输入表示和整体预测策略对现有方法进行了分类，特别关注了使用ETH/UCY基准测试评估的模型。", "result": "综述揭示了多智能体HTP领域的最新进展，并指出了当前研究中的关键挑战。", "conclusion": "本文总结了多智能体人类轨迹预测的研究现状，并提出了未来研究的可能方向，为该领域的进一步发展提供了参考。"}}
{"id": "2506.14990", "title": "MEAL: A Benchmark for Continual Multi-Agent Reinforcement Learning", "authors": ["Tristan Tomilin", "Luka van den Boogaard", "Samuel Garcin", "Bram Grooten", "Meng Fang", "Mykola Pechenizkiy"], "abstract": "Benchmarks play a crucial role in the development and analysis of reinforcement learning (RL) algorithms, with environment availability strongly impacting research. One particularly underexplored intersection is continual learning (CL) in cooperative multi-agent settings. To remedy this, we introduce MEAL (Multi-agent Environments for Adaptive Learning), the first benchmark tailored for continual multi-agent reinforcement learning (CMARL). Existing CL benchmarks run environments on the CPU, leading to computational bottlenecks and limiting the length of task sequences. MEAL leverages JAX for GPU acceleration, enabling continual learning across sequences of 100 tasks on a standard desktop PC in a few hours. We show that naively combining popular CL and MARL methods yields strong performance on simple environments, but fails to scale to more complex settings requiring sustained coordination and adaptation. Our ablation study identifies architectural and algorithmic features critical for CMARL on MEAL.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.14990.pdf", "abstract_url": "https://arxiv.org/abs/2506.14990", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了MEAL，一个专为持续多智能体强化学习（CMARL）设计的首个基准测试。MEAL利用JAX进行GPU加速，使得在普通台式电脑上几小时内完成100个任务的持续学习成为可能。研究表明，简单地将流行的持续学习和多智能体强化学习方法结合起来，在简单环境中表现良好，但在需要持续协调和适应的更复杂环境中则难以扩展。", "motivation": "解决在合作多智能体设置中持续学习（CL）研究不足的问题，提供一个高效的基准测试以促进相关算法的发展和评估。", "method": "引入MEAL基准测试，利用JAX实现GPU加速，支持在普通硬件上进行长序列任务的持续学习。", "result": "研究发现，现有的持续学习和多智能体强化学习方法在简单环境中表现良好，但在复杂环境中难以扩展。通过消融研究，确定了在MEAL上进行CMARL的关键架构和算法特征。", "conclusion": "MEAL为持续多智能体强化学习提供了一个高效的基准测试，揭示了现有方法在复杂环境中的局限性，并为未来的研究指明了方向。"}}
{"id": "2506.15131", "title": "Modeling the One-to-Many Property in Open-Domain Dialogue with LLMs", "authors": ["Jing Yang Lee", "Kong-Aik Lee", "Woon-Seng Gan"], "abstract": "Open-domain Dialogue (OD) exhibits a one-to-many (o2m) property, whereby multiple appropriate responses exist for a single dialogue context. Despite prior research showing that modeling this property boosts response diversity, most modern LLM-based dialogue agents do not explicitly do so. In this work, we model the o2m property of OD in LLMs by decomposing OD generation into two key tasks: Multi-Response Generation (MRG) and Preference-based Selection (PS), which entail generating a set of n semantically and lexically diverse high-quality responses for a given dialogue context, followed by selecting a single response based on human preference, respectively. To facilitate MRG and PS, we introduce o2mDial, a dialogue corpus explicitly designed to capture the o2m property by featuring multiple plausible responses for each context. Leveraging o2mDial, we propose new in-context learning and instruction-tuning strategies, as well as novel evaluation metrics for MRG, alongside a model-based approach for PS. Empirical results demonstrate that applying the proposed two-stage framework to smaller LLMs for OD generation enhances overall response diversity while maintaining contextual coherence, improving response quality by up to 90%, bringing them closer to the performance of larger models.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.15131.pdf", "abstract_url": "https://arxiv.org/abs/2506.15131", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种通过分解开放域对话生成任务为多响应生成和基于偏好的选择两阶段框架，以显式建模开放域对话的一对多属性，并引入了o2mDial语料库来支持这一框架，实验结果表明该方法能显著提升响应多样性和质量。", "motivation": "开放域对话存在一对多属性，即单一对话上下文可对应多个合适的响应。尽管先前研究表明建模这一属性能提升响应多样性，但大多数基于大型语言模型的对话代理并未显式地这样做。", "method": "通过将开放域对话生成分解为多响应生成（MRG）和基于偏好的选择（PS）两个关键任务，并引入o2mDial语料库来支持这两项任务。提出了新的上下文学习和指令调整策略，以及MRG的新评估指标和PS的模型基方法。", "result": "实证结果表明，将提出的两阶段框架应用于较小的大型语言模型进行开放域对话生成，能在保持上下文连贯性的同时显著提升响应多样性，响应质量提升高达90%，使其性能接近更大模型。", "conclusion": "通过显式建模开放域对话的一对多属性，并采用两阶段生成和选择框架，可以有效提升对话代理的响应多样性和质量，尤其是在较小模型上的应用显示出接近更大模型的潜力。"}}
{"id": "2506.15207", "title": "Multi-Agent Reinforcement Learning for Autonomous Multi-Satellite Earth Observation: A Realistic Case Study", "authors": ["Mohamad A. Hady", "Siyi Hu", "Mahardhika Pratama", "Jimmy Cao", "Ryszard Kowalczyk"], "abstract": "The exponential growth of Low Earth Orbit (LEO) satellites has revolutionised Earth Observation (EO) missions, addressing challenges in climate monitoring, disaster management, and more. However, autonomous coordination in multi-satellite systems remains a fundamental challenge. Traditional optimisation approaches struggle to handle the real-time decision-making demands of dynamic EO missions, necessitating the use of Reinforcement Learning (RL) and Multi-Agent Reinforcement Learning (MARL). In this paper, we investigate RL-based autonomous EO mission planning by modelling single-satellite operations and extending to multi-satellite constellations using MARL frameworks. We address key challenges, including energy and data storage limitations, uncertainties in satellite observations, and the complexities of decentralised coordination under partial observability. By leveraging a near-realistic satellite simulation environment, we evaluate the training stability and performance of state-of-the-art MARL algorithms, including PPO, IPPO, MAPPO, and HAPPO. Our results demonstrate that MARL can effectively balance imaging and resource management while addressing non-stationarity and reward interdependency in multi-satellite coordination. The insights gained from this study provide a foundation for autonomous satellite operations, offering practical guidelines for improving policy learning in decentralised EO missions.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.15207.pdf", "abstract_url": "https://arxiv.org/abs/2506.15207", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究了基于强化学习（RL）和多智能体强化学习（MARL）的自主地球观测（EO）任务规划，解决了多卫星系统中的自主协调问题。", "motivation": "随着低地球轨道（LEO）卫星数量的指数增长，地球观测任务在气候监测、灾害管理等领域面临挑战。传统优化方法难以满足动态EO任务的实时决策需求，因此需要利用RL和MARL技术。", "method": "通过建模单卫星操作并扩展到多卫星星座，使用MARL框架（包括PPO、IPPO、MAPPO和HAPPO算法）来解决能源和数据存储限制、观测不确定性及部分可观测下的分散协调复杂性。", "result": "研究表明，MARL能有效平衡成像和资源管理，解决多卫星协调中的非平稳性和奖励依赖性问题。", "conclusion": "本研究为自主卫星操作提供了基础，为改进分散EO任务中的策略学习提供了实用指南。"}}
{"id": "2506.15225", "title": "Joint Computation Offloading and Resource Allocation for Uncertain Maritime MEC via Cooperation of UAVs and Vessels", "authors": ["Jiahao You", "Ziye Jia", "Chao Dong", "Qihui Wu", "Zhu Han"], "abstract": "The computation demands from the maritime Internet of Things (MIoT) increase rapidly in recent years, and the unmanned aerial vehicles (UAVs) and vessels based multi-access edge computing (MEC) can fulfill these MIoT requirements. However, the uncertain maritime tasks present significant challenges of inefficient computation offloading and resource allocation. In this paper, we focus on the maritime computation offloading and resource allocation through the cooperation of UAVs and vessels, with consideration of uncertain tasks. Specifically, we propose a cooperative MEC framework for computation offloading and resource allocation, including MIoT devices, UAVs and vessels. Then, we formulate the optimization problem to minimize the total execution time. As for the uncertain MIoT tasks, we leverage Lyapunov optimization to tackle the unpredictable task arrivals and varying computational resource availability. \nBy converting the long-term constraints into short-term constraints, we obtain a set of small-scale optimization problems. Further, considering the heterogeneity of actions and resources of UAVs and vessels, we reformulate the small-scale optimization problem into a Markov game (MG). Moreover, a heterogeneous-agent soft actor-critic is proposed to sequentially update various neural networks and effectively solve the MG problem. \nFinally, simulations are conducted to verify the effectiveness in addressing computational offloading and resource allocation.", "subjects": "Artificial Intelligence (cs.AI); Signal Processing (eess.SP)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.15225.pdf", "abstract_url": "https://arxiv.org/abs/2506.15225", "categories": ["Artificial Intelligence (cs.AI)", "Signal Processing (eess.SP)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种通过无人机和船舶合作的海上多接入边缘计算（MEC）框架，以解决海上物联网（MIoT）任务的不确定性问题，优化计算卸载和资源分配，最小化总执行时间。", "motivation": "海上物联网（MIoT）的计算需求快速增长，但不确定的海上任务给计算卸载和资源分配带来了效率低下的挑战。", "method": "提出了一种合作MEC框架，利用Lyapunov优化处理不确定任务，将长期约束转化为短期约束，并将优化问题重新表述为马尔可夫游戏（MG），采用异构代理软演员-评论家方法解决。", "result": "仿真验证了所提方法在解决计算卸载和资源分配问题上的有效性。", "conclusion": "通过无人机和船舶的合作，可以有效应对海上MEC中的不确定任务，优化计算卸载和资源分配，提高系统性能。"}}
{"id": "2506.15377", "title": "Efficient and Generalizable Environmental Understanding for Visual Navigation", "authors": ["Ruoyu Wang", "Xinshu Li", "Chen Wang", "Lina Yao"], "abstract": "Visual Navigation is a core task in Embodied AI, enabling agents to navigate complex environments toward given objectives. Across diverse settings within Navigation tasks, many necessitate the modelling of sequential data accumulated from preceding time steps. While existing methods perform well, they typically process all historical observations simultaneously, overlooking the internal association structure within the data, which may limit the potential for further improvements in task performance. We address this by examining the unique characteristics of Navigation tasks through the lens of causality, introducing a causal framework to highlight the limitations of conventional sequential methods. Leveraging this insight, we propose Causality-Aware Navigation (CAN), which incorporates a Causal Understanding Module to enhance the agent's environmental understanding capability. Empirical evaluations show that our approach consistently outperforms baselines across various tasks and simulation environments. Extensive ablations studies attribute these gains to the Causal Understanding Module, which generalizes effectively in both Reinforcement and Supervised Learning settings without computational overhead.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.15377.pdf", "abstract_url": "https://arxiv.org/abs/2506.15377", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为因果感知导航（CAN）的新方法，通过引入因果理解模块来增强智能体在视觉导航任务中对环境的理解能力。实验证明，该方法在多种任务和模拟环境中均优于基线方法。", "motivation": "视觉导航是体现AI中的核心任务，但现有方法在处理历史观察数据时忽视了数据内部的关联结构，这可能限制了任务性能的进一步提升。", "method": "通过因果视角分析导航任务的独特特性，提出了因果感知导航（CAN），并引入了一个因果理解模块来增强智能体的环境理解能力。", "result": "实证评估显示，CAN方法在各种任务和模拟环境中 consistently outperforms baselines，且因果理解模块在强化学习和监督学习设置中均能有效泛化，无需额外计算开销。", "conclusion": "CAN方法通过因果理解模块显著提升了视觉导航任务的性能，且具有良好的泛化能力和计算效率，为未来的研究提供了新的方向。"}}
{"id": "2506.15567", "title": "Managing Complex Failure Analysis Workflows with LLM-based Reasoning and Acting Agents", "authors": ["Aline Dobrovsky", "Konstantin Schekotihin", "Christian Burmer"], "abstract": "Failure Analysis (FA) is a highly intricate and knowledge-intensive process. The integration of AI components within the computational infrastructure of FA labs has the potential to automate a variety of tasks, including the detection of non-conformities in images, the retrieval of analogous cases from diverse data sources, and the generation of reports from annotated images. However, as the number of deployed AI models increases, the challenge lies in orchestrating these components into cohesive and efficient workflows that seamlessly integrate with the FA process.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.15567.pdf", "abstract_url": "https://arxiv.org/abs/2506.15567", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了在故障分析（FA）实验室中整合AI组件以自动化任务（如图像非一致性检测、案例检索和报告生成）的潜力，并指出了随着AI模型数量的增加，如何将这些组件协调成高效、连贯的工作流程的挑战。", "motivation": "解决在故障分析过程中，随着部署的AI模型数量增加，如何有效协调这些模型成为连贯且高效的工作流程的挑战。", "method": "提出使用基于LLM的推理和行动代理来管理复杂的故障分析工作流程。", "result": "指出了整合AI组件自动化FA任务的潜力，同时强调了工作流程协调的重要性。", "conclusion": "通过基于LLM的推理和行动代理，可以有效管理和协调FA中的复杂AI工作流程，提高效率和连贯性。"}}
{"id": "2506.15624", "title": "The Effect of State Representation on LLM Agent Behavior in Dynamic Routing Games", "authors": ["Lyle Goodyear", "Rachel Guo", "Ramesh Johari"], "abstract": "Large Language Models (LLMs) have shown promise as decision-makers in dynamic settings, but their stateless nature necessitates creating a natural language representation of history. We present a unifying framework for systematically constructing natural language \"state\" representations for prompting LLM agents in repeated multi-agent games. Previous work on games with LLM agents has taken an ad hoc approach to encoding game history, which not only obscures the impact of state representation on agents' behavior, but also limits comparability between studies. Our framework addresses these gaps by characterizing methods of state representation along three axes: action informativeness (i.e., the extent to which the state representation captures actions played); reward informativeness (i.e., the extent to which the state representation describes rewards obtained); and prompting style (or natural language compression, i.e., the extent to which the full text history is summarized).", "subjects": "Artificial Intelligence (cs.AI)", "comments": "27 pages, 20 figures", "pdf_url": "https://arxiv.org/pdf/2506.15624.pdf", "abstract_url": "https://arxiv.org/abs/2506.15624", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一个统一的框架，用于在重复多智能体游戏中系统地构建自然语言“状态”表示，以提示LLM智能体。该框架通过三个维度来表征状态表示的方法：动作信息量、奖励信息量和提示风格。", "motivation": "解决LLM智能体在动态设置中作为决策者时，其无状态性质需要创建历史自然语言表示的问题，并填补之前工作中对游戏历史编码的临时方法所留下的空白。", "method": "提出一个框架，通过动作信息量、奖励信息量和提示风格（或自然语言压缩）三个维度来系统地构建自然语言状态表示。", "result": "该框架不仅揭示了状态表示对智能体行为的影响，还提高了研究之间的可比性。", "conclusion": "通过系统地构建自然语言状态表示，可以更有效地提示LLM智能体在重复多智能体游戏中的行为，同时增强研究的可比性和一致性。"}}
{"id": "2506.15672", "title": "SwarmAgentic: Towards Fully Automated Agentic System Generation via Swarm Intelligence", "authors": ["Yao Zhang", "Chenyang Lin", "Shijie Tang", "Haokun Chen", "Shijie Zhou", "Yunpu Ma", "Volker Tresp"], "abstract": "The rapid progress of Large Language Models has advanced agentic systems in decision-making, coordination, and task execution. Yet, existing agentic system generation frameworks lack full autonomy, missing from-scratch agent generation, self-optimizing agent functionality, and collaboration, limiting adaptability and scalability. We propose SwarmAgentic, a framework for fully automated agentic system generation that constructs agentic systems from scratch and jointly optimizes agent functionality and collaboration as interdependent components through language-driven exploration. To enable efficient search over system-level structures, SwarmAgentic maintains a population of candidate systems and evolves them via feedback-guided updates, drawing inspiration from Particle Swarm Optimization (PSO). We evaluate our method on six real-world, open-ended, and exploratory tasks involving high-level planning, system-level coordination, and creative reasoning. Given only a task description and an objective function, SwarmAgentic outperforms all baselines, achieving a +261.8% relative improvement over ADAS on the TravelPlanner benchmark, highlighting the effectiveness of full automation in structurally unconstrained tasks. This framework marks a significant step toward scalable and autonomous agentic system design, bridging swarm intelligence with fully automated system multi-agent generation. Our code is publicly released at", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "41 pages", "pdf_url": "https://arxiv.org/pdf/2506.15672.pdf", "abstract_url": "https://arxiv.org/abs/2506.15672", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "SwarmAgentic是一个基于群体智能的全自动化代理系统生成框架，旨在解决现有代理系统生成框架在完全自主性、自我优化代理功能和协作方面的不足。", "motivation": "现有代理系统生成框架缺乏完全自主性，无法实现从零开始的代理生成、自我优化代理功能及协作，限制了系统的适应性和可扩展性。", "method": "SwarmAgentic通过语言驱动的探索，从零开始构建代理系统，并联合优化代理功能和协作作为相互依赖的组件。受粒子群优化（PSO）启发，该框架维护一组候选系统，并通过反馈引导的更新来进化这些系统。", "result": "在六个涉及高级规划、系统级协调和创造性推理的真实世界、开放性和探索性任务中，SwarmAgentic仅给定任务描述和目标函数，就超越了所有基线，在TravelPlanner基准测试中实现了相对于ADAS的+261.8%相对改进。", "conclusion": "SwarmAgentic框架在可扩展和自主代理系统设计方面迈出了重要一步，将群体智能与完全自动化的系统多代理生成相结合。"}}
{"id": "2506.15677", "title": "Embodied Web Agents: Bridging Physical-Digital Realms for Integrated Agent Intelligence", "authors": ["Yining Hong", "Rui Sun", "Bingxuan Li", "Xingcheng Yao", "Maxine Wu", "Alexander Chien", "Da Yin", "Ying Nian Wu", "Zhecan James Wang", "Kai-Wei Chang"], "abstract": "AI agents today are mostly siloed - they either retrieve and reason over vast amount of digital information and knowledge obtained online; or interact with the physical world through embodied perception, planning and action - but rarely both. This separation limits their ability to solve tasks that require integrated physical and digital intelligence, such as cooking from online recipes, navigating with dynamic map data, or interpreting real-world landmarks using web knowledge. We introduce Embodied Web Agents, a novel paradigm for AI agents that fluidly bridge embodiment and web-scale reasoning. To operationalize this concept, we first develop the Embodied Web Agents task environments, a unified simulation platform that tightly integrates realistic 3D indoor and outdoor environments with functional web interfaces. Building upon this platform, we construct and release the Embodied Web Agents Benchmark, which encompasses a diverse suite of tasks including cooking, navigation, shopping, tourism, and geolocation - all requiring coordinated reasoning across physical and digital realms for systematic assessment of cross-domain intelligence. Experimental results reveal significant performance gaps between state-of-the-art AI systems and human capabilities, establishing both challenges and opportunities at the intersection of embodied cognition and web-scale knowledge access. All datasets, codes and websites are publicly available at our project page", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.15677.pdf", "abstract_url": "https://arxiv.org/abs/2506.15677", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Computer Vision and Pattern Recognition (cs.CV)", "Multimedia (cs.MM)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了'具身网络代理'这一新范式，旨在解决AI代理在物理和数字领域之间缺乏整合的问题，通过开发一个统一的模拟平台和基准测试，展示了当前AI系统与人类能力之间的显著差距。", "motivation": "当前AI代理大多局限于单一领域，无法有效整合物理和数字智能，限制了其在需要跨领域智能的任务中的应用。", "method": "开发了'具身网络代理'任务环境和基准测试，包括一个统一的模拟平台，整合了真实的3D环境和功能性网络接口。", "result": "实验结果显示，最先进的AI系统与人类能力之间存在显著差距，揭示了在具身认知和网络规模知识访问交叉领域的挑战和机遇。", "conclusion": "通过'具身网络代理'范式，为AI代理在物理和数字领域的整合提供了新的研究方向和实践平台，所有数据集、代码和网站均已公开。"}}
{"id": "2506.15635", "title": "FindingDory: A Benchmark to Evaluate Memory in Embodied Agents", "authors": ["Karmesh Yadav", "Yusuf Ali", "Gunshi Gupta", "Yarin Gal", "Zsolt Kira"], "abstract": "Large vision-language models have recently demonstrated impressive performance in planning and control tasks, driving interest in their application to real-world robotics. However, deploying these models for reasoning in embodied contexts is limited by their ability to incorporate long-term experience collected across multiple days and represented by vast collections of images. Current VLMs typically struggle to process more than a few hundred images concurrently, highlighting the need for more efficient mechanisms to handle long-term memory in embodied settings. To effectively evaluate these models for long-horizon control, a benchmark must specifically target scenarios where memory is crucial for success. Existing long-video QA benchmarks overlook embodied challenges like object manipulation and navigation, which demand low-level skills and fine-grained reasoning over past interactions. Moreover, effective memory integration in embodied agents involves both recalling relevant historical information and executing actions based on that information, making it essential to study these aspects together rather than in isolation. In this work, we introduce a new benchmark for long-range embodied tasks in the Habitat simulator. This benchmark evaluates memory-based capabilities across 60 tasks requiring sustained engagement and contextual awareness in an environment. The tasks can also be procedurally extended to longer and more challenging versions, enabling scalable evaluation of memory and reasoning. We also present baselines that integrate state-of-the-art VLMs with low level navigation policies, assessing their performance on these memory-intensive tasks and highlight areas for improvement.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2506.15635.pdf", "abstract_url": "https://arxiv.org/abs/2506.15635", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了FindingDory基准测试，旨在评估具身代理中的记忆能力，特别是在需要长期记忆和情境意识的复杂任务中。", "motivation": "大型视觉语言模型在规划和控制任务中表现出色，但在具身环境中处理长期经验和大量图像的能力有限，需要更高效的记忆机制。", "method": "研究团队在Habitat模拟器中引入了一个新的基准测试，包含60个需要持续参与和情境意识的任务，并可程序化扩展为更长更难的版本。", "result": "通过将最先进的视觉语言模型与低级导航策略结合，评估了这些模型在记忆密集型任务上的表现，并指出了改进方向。", "conclusion": "该基准测试为评估具身代理的记忆和推理能力提供了可扩展的方法，有助于推动相关技术的发展。"}}
{"id": "2506.15241", "title": "Research on Graph-Retrieval Augmented Generation Based on Historical Text Knowledge Graphs", "authors": ["Yang Fan", "Zhang Qi", "Xing Wenqian", "Liu Chang", "Liu Liu"], "abstract": "This article addresses domain knowledge gaps in general large language models for historical text analysis in the context of computational humanities and AIGC technology. We propose the Graph RAG framework, combining chain-of-thought prompting, self-instruction generation, and process supervision to create a The First Four Histories character relationship dataset with minimal manual annotation. This dataset supports automated historical knowledge extraction, reducing labor costs. In the graph-augmented generation phase, we introduce a collaborative mechanism between knowledge graphs and retrieval-augmented generation, improving the alignment of general models with historical knowledge. Experiments show that the domain-specific model Xunzi-Qwen1.5-14B, with Simplified Chinese input and chain-of-thought prompting, achieves optimal performance in relation extraction (F1 = 0.68). The DeepSeek model integrated with GraphRAG improves F1 by 11% (0.08-0.19) on the open-domain C-CLUE relation extraction dataset, surpassing the F1 value of Xunzi-Qwen1.5-14B (0.12), effectively alleviating hallucinations phenomenon, and improving interpretability. This framework offers a low-resource solution for classical text knowledge extraction, advancing historical knowledge services and humanities research.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.15241.pdf", "abstract_url": "https://arxiv.org/abs/2506.15241", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出Graph RAG框架，结合思维链提示、自指令生成和过程监督，以最小人工标注创建《前四史》人物关系数据集，支持自动化历史知识提取，降低劳动成本。通过知识图谱与检索增强生成的协作机制，提升通用模型与历史知识的对齐。实验显示，Xunzi-Qwen1.5-14B模型在关系提取上表现最佳（F1=0.68），集成GraphRAG的DeepSeek模型在开放域C-CLUE数据集上F1提升11%，有效缓解幻觉现象，提高可解释性。", "motivation": "解决通用大语言模型在计算人文和AIGC技术背景下历史文本分析中的领域知识缺口问题。", "method": "提出Graph RAG框架，结合思维链提示、自指令生成和过程监督，创建历史人物关系数据集，并引入知识图谱与检索增强生成的协作机制。", "result": "Xunzi-Qwen1.5-14B模型在关系提取上达到F1=0.68；集成GraphRAG的DeepSeek模型在C-CLUE数据集上F1提升11%，有效缓解幻觉现象。", "conclusion": "Graph RAG框架为经典文本知识提取提供了低资源解决方案，推动了历史知识服务和人文研究的进步。"}}
{"id": "2506.15246", "title": "TopClustRAG at SIGIR 2025 LiveRAG Challenge", "authors": ["Juli Bakagianni", "John Pavlopoulos", "Aristidis Likas"], "abstract": "We present TopClustRAG, a retrieval-augmented generation (RAG) system developed for the LiveRAG Challenge, which evaluates end-to-end question answering over large-scale web corpora. Our system employs a hybrid retrieval strategy combining sparse and dense indices, followed by K-Means clustering to group semantically similar passages. Representative passages from each cluster are used to construct cluster-specific prompts for a large language model (LLM), generating intermediate answers that are filtered, reranked, and finally synthesized into a single, comprehensive response. This multi-stage pipeline enhances answer diversity, relevance, and faithfulness to retrieved evidence. Evaluated on the FineWeb Sample-10BT dataset, TopClustRAG ranked 2nd in faithfulness and 7th in correctness on the official leaderboard, demonstrating the effectiveness of clustering-based context filtering and prompt aggregation in large-scale RAG systems.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.15246.pdf", "abstract_url": "https://arxiv.org/abs/2506.15246", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "TopClustRAG是一个为LiveRAG挑战开发的检索增强生成系统，结合了稀疏和密集索引的混合检索策略，通过K-Means聚类和特定集群提示生成中间答案，最终合成全面响应。", "motivation": "解决在大规模网络语料库上进行端到端问答时，如何提高答案的多样性、相关性和对检索证据的忠实度的问题。", "method": "采用混合检索策略结合稀疏和密集索引，使用K-Means聚类对语义相似的段落进行分组，构建集群特定提示给大型语言模型生成中间答案，然后过滤、重新排名并最终合成响应。", "result": "在FineWeb Sample-10BT数据集上评估，TopClustRAG在忠实度上排名第2，在正确性上排名第7，证明了基于聚类的上下文过滤和提示聚合在大规模RAG系统中的有效性。", "conclusion": "TopClustRAG通过聚类和特定集群提示的方法，有效提高了大规模RAG系统中答案的多样性和忠实度，展示了混合检索策略和上下文过滤的潜力。"}}
{"id": "2506.15425", "title": "Understanding GUI Agent Localization Biases through Logit Sharpness", "authors": ["Xingjian Tao", "Yiwei Wang", "Yujun Cai", "Zhicheng Yang", "Jing Tang"], "abstract": "Multimodal large language models (MLLMs) have enabled GUI agents to interact with operating systems by grounding language into spatial actions. Despite their promising performance, these models frequently exhibit hallucinations-systematic localization errors that compromise reliability. We propose a fine-grained evaluation framework that categorizes model predictions into four distinct types, revealing nuanced failure modes beyond traditional accuracy metrics. To better quantify model uncertainty, we introduce the Peak Sharpness Score (PSS), a metric that evaluates the alignment between semantic continuity and logits distribution in coordinate prediction. Building on this insight, we further propose Context-Aware Cropping, a training-free technique that improves model performance by adaptively refining input context. Extensive experiments demonstrate that our framework and methods provide actionable insights and enhance the interpretability and robustness of GUI agent behavior.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.15425.pdf", "abstract_url": "https://arxiv.org/abs/2506.15425", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种细粒度的评估框架和Peak Sharpness Score (PSS)度量，以理解和改善多模态大语言模型(MLLMs)在GUI代理中的定位偏差，并通过Context-Aware Cropping技术提升模型性能。", "motivation": "解决多模态大语言模型在GUI代理中出现的系统性定位错误（幻觉）问题，以提高其可靠性和准确性。", "method": "提出了一个细粒度的评估框架，将模型预测分为四种类型，并引入Peak Sharpness Score (PSS)度量来量化模型不确定性；进一步提出了Context-Aware Cropping技术，无需训练即可通过自适应细化输入上下文来提升模型性能。", "result": "实验证明，所提出的框架和方法能够提供可操作的见解，增强GUI代理行为的可解释性和鲁棒性。", "conclusion": "通过细粒度的评估和Context-Aware Cropping技术，可以有效理解和改善MLLMs在GUI代理中的定位偏差，提升模型的性能和可靠性。"}}
{"id": "2506.15451", "title": "AgentGroupChat-V2: Divide-and-Conquer Is What LLM-Based Multi-Agent System Need", "authors": ["Zhouhong Gu", "Xiaoxuan Zhu", "Yin Cai", "Hao Shen", "Xingzhou Chen", "Qingyi Wang", "Jialin Li", "Xiaoran Shi", "Haoran Guo", "Wenxuan Huang", "Hongwei Feng", "Yanghua Xiao", "Zheyu Ye", "Yao Hu", "Shaosheng Cao"], "abstract": "Large language model based multi-agent systems have demonstrated significant potential in social simulation and complex task resolution domains. However, current frameworks face critical challenges in system architecture design, cross-domain generalizability, and performance guarantees, particularly as task complexity and number of agents increases. We introduces AgentGroupChat-V2, a novel framework addressing these challenges through three core innovations: (1) a divide-and-conquer fully parallel architecture that decomposes user queries into hierarchical task forest structures enabling dependency management and distributed concurrent processing. (2) an adaptive collaboration engine that dynamically selects heterogeneous LLM combinations and interaction modes based on task characteristics. (3) agent organization optimization strategies combining divide-and-conquer approaches for efficient problem decomposition. Extensive experiments demonstrate AgentGroupChat-V2's superior performance across diverse domains, achieving 91.50% accuracy on GSM8K (exceeding the best baseline by 5.6 percentage points), 30.4% accuracy on competition-level AIME (nearly doubling other methods), and 79.20% pass@1 on HumanEval. Performance advantages become increasingly pronounced with higher task difficulty, particularly on Level 5 MATH problems where improvements exceed 11 percentage points compared to state-of-the-art baselines. These results confirm that AgentGroupChat-V2 provides a comprehensive solution for building efficient, general-purpose LLM multi-agent systems with significant advantages in complex reasoning scenarios. Code is available at", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.15451.pdf", "abstract_url": "https://arxiv.org/abs/2506.15451", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "AgentGroupChat-V2是一个基于大型语言模型的多智能体系统框架，通过分而治之的全并行架构、自适应协作引擎和智能体组织优化策略，有效解决了复杂任务处理和跨领域泛化能力的挑战。", "motivation": "当前基于大型语言模型的多智能体系统在系统架构设计、跨领域泛化能力和性能保证方面面临挑战，特别是在任务复杂性和智能体数量增加时。", "method": "提出了三个核心创新：1) 分而治之的全并行架构，将用户查询分解为层次化任务森林结构；2) 自适应协作引擎，根据任务特性动态选择异构LLM组合和交互模式；3) 结合分而治之方法的智能体组织优化策略。", "result": "在多个领域的广泛实验中表现出卓越性能，GSM8K准确率达91.50%，AIME准确率达30.4%，HumanEval pass@1达79.20%，在更高难度的任务中优势更加明显。", "conclusion": "AgentGroupChat-V2为构建高效、通用的LLM多智能体系统提供了全面解决方案，在复杂推理场景中具有显著优势。"}}
{"id": "2506.15522", "title": "Lessons from Training Grounded LLMs with Verifiable Rewards", "authors": ["Shang Hong Sim", "Tej Deep Pala", "Vernon Toh", "Hai Leong Chieu", "Amir Zadeh", "Chuan Li", "Navonil Majumder", "Soujanya Poria"], "abstract": "Generating grounded and trustworthy responses remains a key challenge for large language models (LLMs). While retrieval-augmented generation (RAG) with citation-based grounding holds promise, instruction-tuned models frequently fail even in straightforward scenarios: missing explicitly stated answers, citing incorrectly, or refusing when evidence is available. In this work, we explore how reinforcement learning (RL) and internal reasoning can enhance grounding in LLMs. We use the GRPO (Group Relative Policy Optimization) method to train models using verifiable outcome-based rewards targeting answer correctness, citation sufficiency, and refusal quality, without requiring gold reasoning traces or expensive annotations. Through comprehensive experiments across ASQA, QAMPARI, ELI5, and ExpertQA we show that reasoning-augmented models significantly outperform instruction-only variants, especially in handling unanswerable queries and generating well-cited responses. A two-stage training setup, first optimizing answer and citation behavior and then refusal, further improves grounding by stabilizing the learning signal. Additionally, we revisit instruction tuning via GPT-4 distillation and find that combining it with GRPO enhances performance on long-form, generative QA tasks. Overall, our findings highlight the value of reasoning, stage-wise optimization, and outcome-driven RL for building more verifiable and reliable LLMs.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.15522.pdf", "abstract_url": "https://arxiv.org/abs/2506.15522", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文探讨了如何通过强化学习和内部推理来增强大型语言模型（LLMs）的接地性和可信度，使用GRPO方法训练模型，以目标答案正确性、引用充分性和拒绝质量为可验证的结果奖励，无需黄金推理轨迹或昂贵注释。", "motivation": "解决大型语言模型在生成接地和可信响应方面的关键挑战，特别是在检索增强生成（RAG）和基于引用的接地中，模型经常在简单场景中失败，如遗漏明确陈述的答案、错误引用或在有证据时拒绝回答。", "method": "使用GRPO（Group Relative Policy Optimization）方法，通过可验证的结果奖励训练模型，针对答案正确性、引用充分性和拒绝质量，无需黄金推理轨迹或昂贵注释。", "result": "在ASQA、QAMPARI、ELI5和ExpertQA上的综合实验显示，推理增强模型显著优于仅指令调整的变体，特别是在处理不可回答的查询和生成良好引用的响应方面。两阶段训练设置进一步提高了接地性。", "conclusion": "研究结果强调了推理、分阶段优化和结果驱动的强化学习对于构建更可验证和可靠的大型语言模型的价值，结合GPT-4蒸馏的指令调整和GRPO可以增强长形式生成QA任务的性能。"}}
{"id": "2506.15569", "title": "SciVer: Evaluating Foundation Models for Multimodal Scientific Claim Verification", "authors": ["Chengye Wang", "Yifei Shen", "Zexi Kuang", "Arman Cohan", "Yilun Zhao"], "abstract": "We introduce SciVer, the first benchmark specifically designed to evaluate the ability of foundation models to verify claims within a multimodal scientific context. SciVer consists of 3,000 expert-annotated examples over 1,113 scientific papers, covering four subsets, each representing a common reasoning type in multimodal scientific claim verification. To enable fine-grained evaluation, each example includes expert-annotated supporting evidence. We assess the performance of 21 state-of-the-art multimodal foundation models, including o4-mini, Gemini-2.5-Flash, Llama-3.2-Vision, and Qwen2.5-VL. Our experiment reveals a substantial performance gap between these models and human experts on SciVer. Through an in-depth analysis of retrieval-augmented generation (RAG), and human-conducted error evaluations, we identify critical limitations in current open-source models, offering key insights to advance models' comprehension and reasoning in multimodal scientific literature tasks.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.15569.pdf", "abstract_url": "https://arxiv.org/abs/2506.15569", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "SciVer是首个专门设计用于评估基础模型在多模态科学声明验证中能力的基准，包含3000个专家标注的示例，覆盖四种常见的推理类型。评估了21种最先进的多模态基础模型，发现与人类专家存在显著性能差距，并分析了当前开源模型的关键限制。", "motivation": "解决在多模态科学文献中验证声明的挑战，评估和提升基础模型在此领域的理解和推理能力。", "method": "构建了SciVer基准，包含专家标注的支持证据，评估了21种多模态基础模型，并进行了检索增强生成（RAG）和人工错误评估的深入分析。", "result": "发现当前最先进的多模态基础模型与人类专家在SciVer上的性能存在显著差距，识别了开源模型的关键限制。", "conclusion": "SciVer为提升模型在多模态科学文献任务中的理解和推理能力提供了关键见解，指出了未来研究的改进方向。"}}
{"id": "2506.15674", "title": "Leaky Thoughts: Large Reasoning Models Are Not Private Thinkers", "authors": ["Tommaso Green", "Martin Gubri", "Haritz Puerto", "Sangdoo Yun", "Seong Joon Oh"], "abstract": "We study privacy leakage in the reasoning traces of large reasoning models used as personal agents. Unlike final outputs, reasoning traces are often assumed to be internal and safe. We challenge this assumption by showing that reasoning traces frequently contain sensitive user data, which can be extracted via prompt injections or accidentally leak into outputs. Through probing and agentic evaluations, we demonstrate that test-time compute approaches, particularly increased reasoning steps, amplify such leakage. While increasing the budget of those test-time compute approaches makes models more cautious in their final answers, it also leads them to reason more verbosely and leak more in their own thinking. This reveals a core tension: reasoning improves utility but enlarges the privacy attack surface. We argue that safety efforts must extend to the model's internal thinking, not just its outputs.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.15674.pdf", "abstract_url": "https://arxiv.org/abs/2506.15674", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Cryptography and Security (cs.CR)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "研究大型推理模型在作为个人代理时的隐私泄露问题，特别是推理痕迹中的敏感用户数据泄露。", "motivation": "解决大型推理模型在推理过程中可能泄露敏感用户数据的问题，挑战了推理痕迹内部安全的假设。", "method": "通过探测和代理评估，展示了测试时计算方法（尤其是增加的推理步骤）如何放大隐私泄露。", "result": "增加推理步骤虽然使模型在最终答案上更为谨慎，但也导致其推理更为冗长，增加了隐私泄露的风险。", "conclusion": "安全努力必须扩展到模型的内部思考，而不仅仅是其输出，揭示了推理提高效用但扩大隐私攻击面的核心矛盾。"}}
{"id": "2506.14852", "title": "Cost-Efficient Serving of LLM Agents via Test-Time Plan Caching", "authors": ["Qizheng Zhang", "Michael Wornow", "Kunle Olukotun"], "abstract": "LLM-based agentic applications have shown increasingly remarkable capabilities in complex workflows but incur substantial costs due to extensive planning and reasoning requirements. Existing LLM caching techniques (like context caching and semantic caching), primarily designed for serving chatbots, are insufficient for agentic applications where outputs depend on external data or environmental contexts. We propose agentic plan caching, a novel approach that extracts, stores, adapts, and reuses structured plan templates from planning stages of agentic applications across semantically similar tasks to reduce the cost of serving. Unlike traditional semantic caching, our system extracts plan templates from completed agent executions at test-time, employs keyword extraction to match new requests against cached plans, and utilizes lightweight models to adapt these templates to task-specific plans with contexts. Evaluation across multiple real-world agentic applications shows that our system can reduce costs by 46.62% on average while maintaining performance, offering a more efficient solution for serving LLM-based agents that complements existing LLM serving infrastructures.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Performance (cs.PF)", "comments": "23 pages", "pdf_url": "https://arxiv.org/pdf/2506.14852.pdf", "abstract_url": "https://arxiv.org/abs/2506.14852", "categories": ["Distributed, Parallel, and Cluster Computing (cs.DC)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)", "Performance (cs.PF)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种名为‘代理计划缓存’的新方法，旨在通过提取、存储、调整和重用代理应用中的结构化计划模板，来降低基于LLM的代理应用的服务成本。", "motivation": "现有的LLM缓存技术（如上下文缓存和语义缓存）主要设计用于服务聊天机器人，对于依赖外部数据或环境上下文的代理应用来说效果不佳，导致高昂的服务成本。", "method": "该方法在测试时从完成的代理执行中提取计划模板，使用关键词提取将新请求与缓存计划匹配，并利用轻量级模型将这些模板调整为具有上下文的任务特定计划。", "result": "在多个实际代理应用中的评估显示，该系统平均可降低成本46.62%，同时保持性能，为基于LLM的代理服务提供了更高效的解决方案。", "conclusion": "代理计划缓存是一种有效的成本降低方法，能够补充现有的LLM服务基础设施，为复杂的代理工作流程提供更经济的服务方案。"}}
{"id": "2506.14988", "title": "Fair Algorithms with Probing for Multi-Agent Multi-Armed Bandits", "authors": ["Tianyi Xu", "Jiaxin Liu", "Zizhan Zheng"], "abstract": "We propose a multi-agent multi-armed bandit (MA-MAB) framework aimed at ensuring fair outcomes across agents while maximizing overall system performance. A key challenge in this setting is decision-making under limited information about arm rewards. To address this, we introduce a novel probing framework that strategically gathers information about selected arms before allocation. In the offline setting, where reward distributions are known, we leverage submodular properties to design a greedy probing algorithm with a provable performance bound. For the more complex online setting, we develop an algorithm that achieves sublinear regret while maintaining fairness. Extensive experiments on synthetic and real-world datasets show that our approach outperforms baseline methods, achieving better fairness and efficiency.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.14988.pdf", "abstract_url": "https://arxiv.org/abs/2506.14988", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种多智能体多臂老虎机（MA-MAB）框架，旨在确保智能体间的公平结果同时最大化整体系统性能。通过引入新颖的探测框架，在分配前策略性地收集选定臂的信息，设计了在离线设置中具有可证明性能界的贪婪探测算法，并在在线设置中开发了实现亚线性遗憾同时保持公平的算法。实验表明，该方法在公平性和效率上优于基线方法。", "motivation": "解决在多智能体多臂老虎机设置中，如何在有限信息下做出决策以确保公平结果同时最大化整体性能的问题。", "method": "引入探测框架策略性收集信息，离线设置中利用子模性质设计贪婪探测算法，在线设置中开发实现亚线性遗憾的算法。", "result": "在合成和真实数据集上的广泛实验显示，该方法在公平性和效率上优于基线方法。", "conclusion": "提出的MA-MAB框架和算法能够有效平衡公平性和性能，为多智能体决策问题提供了新的解决方案。"}}
{"id": "2506.15167", "title": "LLM Agent for Hyper-Parameter Optimization", "authors": ["Wanzhe Wang", "Jianqiu Peng", "Menghao Hu", "Weihuang Zhong", "Tong Zhang", "Shuai Wang", "Yixin Zhang", "Mingjie Shao", "Wanli Ni"], "abstract": "Hyper-parameters are essential and critical for the performance of communication algorithms. However, current hyper-parameters tuning methods for warm-start particles swarm optimization with cross and mutation (WS-PSO-CM) algortihm for radio map-enabled unmanned aerial vehicle (UAV) trajectory and communication are primarily heuristic-based, exhibiting low levels of automation and unsatisfactory performance. In this paper, we design an large language model (LLM) agent for automatic hyper-parameters-tuning, where an iterative framework and model context protocol (MCP) are applied. In particular, the LLM agent is first setup via a profile, which specifies the mission, background, and output format. Then, the LLM agent is driven by the prompt requirement, and iteratively invokes WS-PSO-CM algorithm for exploration. Finally, the LLM agent autonomously terminates the loop and returns a set of hyper-parameters. Our experiment results show that the minimal sum-rate achieved by hyper-parameters generated via our LLM agent is significantly higher than those by both human heuristics and random generation methods. This indicates that an LLM agent with PSO knowledge and WS-PSO-CM algorithm background is useful in finding high-performance hyper-parameters.", "subjects": "Information Theory (cs.IT); Artificial Intelligence (cs.AI)", "comments": "6 pages, 6 figures", "pdf_url": "https://arxiv.org/pdf/2506.15167.pdf", "abstract_url": "https://arxiv.org/abs/2506.15167", "categories": ["Information Theory (cs.IT)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文设计了一个基于大型语言模型（LLM）的代理，用于自动调整WS-PSO-CM算法的超参数，以提高无人机轨迹和通信的性能。通过迭代框架和模型上下文协议（MCP），LLM代理能够自主探索并返回一组高性能的超参数。实验结果表明，与人工启发式和随机生成方法相比，LLM代理生成的超参数能显著提高最小和速率。", "motivation": "当前用于WS-PSO-CM算法的超参数调整方法主要是启发式的，自动化水平低且性能不理想。本文旨在解决这一问题，通过LLM代理实现超参数的自动优化。", "method": "设计了一个LLM代理，通过配置文件设定任务、背景和输出格式，然后根据提示要求驱动代理迭代调用WS-PSO-CM算法进行探索，最后自主终止循环并返回超参数。", "result": "实验结果显示，LLM代理生成的超参数在最小和速率上显著优于人工启发式和随机生成方法。", "conclusion": "研究表明，具备PSO知识和WS-PSO-CM算法背景的LLM代理在寻找高性能超参数方面非常有用，为超参数优化提供了新的自动化解决方案。"}}
{"id": "2506.15421", "title": "Reward Models in Deep Reinforcement Learning: A Survey", "authors": ["Rui Yu", "Shenghua Wan", "Yucen Wang", "Chen-Xiao Gao", "Le Gan", "Zongzhang Zhang", "De-Chuan Zhan"], "abstract": "In reinforcement learning (RL), agents continually interact with the environment and use the feedback to refine their behavior. To guide policy optimization, reward models are introduced as proxies of the desired objectives, such that when the agent maximizes the accumulated reward, it also fulfills the task designer's intentions. Recently, significant attention from both academic and industrial researchers has focused on developing reward models that not only align closely with the true objectives but also facilitate policy optimization. In this survey, we provide a comprehensive review of reward modeling techniques within the deep RL literature. We begin by outlining the background and preliminaries in reward modeling. Next, we present an overview of recent reward modeling approaches, categorizing them based on the source, the mechanism, and the learning paradigm. Building on this understanding, we discuss various applications of these reward modeling techniques and review methods for evaluating reward models. Finally, we conclude by highlighting promising research directions in reward modeling. Altogether, this survey includes both established and emerging methods, filling the vacancy of a systematic review of reward models in current literature.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "IJCAI 2025 Survey Track (To Appear)", "pdf_url": "https://arxiv.org/pdf/2506.15421.pdf", "abstract_url": "https://arxiv.org/abs/2506.15421", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文综述了深度强化学习中的奖励模型技术，包括背景、分类、应用及评估方法，并指出了未来研究方向。", "motivation": "解决深度强化学习中奖励模型与真实目标对齐及促进策略优化的问题。", "method": "通过文献综述，分类奖励模型方法，并讨论其应用和评估技术。", "result": "提供了奖励模型技术的全面回顾，填补了现有文献中系统性综述的空白。", "conclusion": "奖励模型在深度强化学习中至关重要，未来研究应关注模型与目标的更紧密对齐及优化策略。"}}
{"id": "2506.15253", "title": "RAS-Eval: A Comprehensive Benchmark for Security Evaluation of LLM Agents in Real-World Environments", "authors": ["Yuchuan Fu", "Xiaohan Yuan", "Dongxia Wang"], "abstract": "The rapid deployment of Large language model (LLM) agents in critical domains like healthcare and finance necessitates robust security frameworks. To address the absence of standardized evaluation benchmarks for these agents in dynamic environments, we introduce RAS-Eval, a comprehensive security benchmark supporting both simulated and real-world tool execution. RAS-Eval comprises 80 test cases and 3,802 attack tasks mapped to 11 Common Weakness Enumeration (CWE) categories, with tools implemented in JSON, LangGraph, and Model Context Protocol (MCP) formats. We evaluate 6 state-of-the-art LLMs across diverse scenarios, revealing significant vulnerabilities: attacks reduced agent task completion rates (TCR) by 36.78% on average and achieved an 85.65% success rate in academic settings. Notably, scaling laws held for security capabilities, with larger models outperforming smaller counterparts. Our findings expose critical risks in real-world agent deployments and provide a foundational framework for future security research. Code and data are available at", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": "12 pages, 8 figures", "pdf_url": "https://arxiv.org/pdf/2506.15253.pdf", "abstract_url": "https://arxiv.org/abs/2506.15253", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了RAS-Eval，一个全面的安全基准测试，用于评估在动态环境中部署的大型语言模型(LLM)代理的安全性。RAS-Eval包含80个测试用例和3,802个攻击任务，覆盖11个CWE类别，支持模拟和真实世界工具执行。通过评估6种最先进的LLM，研究发现攻击显著降低了代理的任务完成率，并揭示了实际部署中的关键风险。", "motivation": "随着大型语言模型(LLM)代理在医疗和金融等关键领域的快速部署，缺乏在动态环境中对这些代理进行标准化安全评估的基准成为了一个问题。", "method": "研究团队开发了RAS-Eval，一个支持模拟和真实世界工具执行的全面安全基准测试，包含80个测试用例和3,802个攻击任务，映射到11个CWE类别。", "result": "评估显示，攻击平均降低了代理任务完成率(TCR)36.78%，在学术环境中成功率高达85.65%。更大的模型在安全能力上表现更好，验证了规模法则。", "conclusion": "研究结果揭示了实际部署LLM代理时的关键风险，并为未来的安全研究提供了一个基础框架。"}}
{"id": "2506.15468", "title": "Co-Creative Learning via Metropolis-Hastings Interaction between Humans and AI", "authors": ["Ryota Okumura", "Tadahiro Taniguchi", "Akira Taniguchi", "Yoshinobu Hagiwara"], "abstract": "We propose co-creative learning as a novel paradigm where humans and AI, i.e., biological and artificial agents, mutually integrate their partial perceptual information and knowledge to construct shared external representations, a process we interpret as symbol emergence. Unlike traditional AI teaching based on unilateral knowledge transfer, this addresses the challenge of integrating information from inherently different modalities. We empirically test this framework using a human-AI interaction model based on the Metropolis-Hastings naming game (MHNG), a decentralized Bayesian inference mechanism. In an online experiment, 69 participants played a joint attention naming game (JA-NG) with one of three computer agent types (MH-based, always-accept, or always-reject) under partial observability. Results show that human-AI pairs with an MH-based agent significantly improved categorization accuracy through interaction and achieved stronger convergence toward a shared sign system. Furthermore, human acceptance behavior aligned closely with the MH-derived acceptance probability. These findings provide the first empirical evidence for co-creative learning emerging in human-AI dyads via MHNG-based interaction. This suggests a promising path toward symbiotic AI systems that learn with humans, rather than from them, by dynamically aligning perceptual experiences, opening a new venue for symbiotic AI alignment.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.15468.pdf", "abstract_url": "https://arxiv.org/abs/2506.15468", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为‘共同创造学习’的新范式，通过Metropolis-Hastings命名游戏（MHNG）实现人类与AI之间的互动，旨在通过整合双方的部分感知信息和知识来构建共享的外部表示，即符号涌现。", "motivation": "解决传统AI教学中单向知识传递无法整合来自不同模态信息的挑战，探索人类与AI如何通过互动实现共同学习和符号系统的共享构建。", "method": "采用基于Metropolis-Hastings命名游戏（MHNG）的人类-AI互动模型，通过在线实验比较三种不同类型的计算机代理（基于MH的、总是接受或总是拒绝）在部分可观察性下的表现。", "result": "实验结果显示，与基于MH的代理互动的人类-AI对通过互动显著提高了分类准确性，并实现了向共享符号系统的更强收敛。此外，人类的接受行为与MH衍生的接受概率高度一致。", "conclusion": "这些发现首次提供了通过MHNG基础互动在人类-AI二元组中涌现共同创造学习的实证证据，为开发能够与人类共同学习而非仅从人类学习的共生AI系统开辟了新途径。"}}
{"id": "2506.15513", "title": "RePCS: Diagnosing Data Memorization in LLM-Powered Retrieval-Augmented Generation", "authors": ["Le Vu Anh", "Nguyen Viet Anh", "Mehmet Dik", "Luong Van Nghia"], "abstract": "Retrieval-augmented generation (RAG) has become a common strategy for updating large language model (LLM) responses with current, external information. However, models may still rely on memorized training data, bypass the retrieved evidence, and produce contaminated outputs. We introduce Retrieval-Path Contamination Scoring (RePCS), a diagnostic method that detects such behavior without requiring model access or retraining. RePCS compares two inference paths: (i) a parametric path using only the query, and (ii) a retrieval-augmented path using both the query and retrieved context by computing the Kullback-Leibler (KL) divergence between their output distributions. A low divergence suggests that the retrieved context had minimal impact, indicating potential memorization. This procedure is model-agnostic, requires no gradient or internal state access, and adds only a single additional forward pass. We further derive PAC-style guarantees that link the KL threshold to user-defined false positive and false negative rates. On the Prompt-WNQA benchmark, RePCS achieves a ROC-AUC of 0.918. This result outperforms the strongest prior method by 6.5 percentage points while keeping latency overhead below 4.7% on an NVIDIA T4 GPU. RePCS offers a lightweight, black-box safeguard to verify whether a RAG system meaningfully leverages retrieval, making it especially valuable in safety-critical applications.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "11 pages, 7 figures, 5 tables", "pdf_url": "https://arxiv.org/pdf/2506.15513.pdf", "abstract_url": "https://arxiv.org/abs/2506.15513", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了RePCS，一种诊断大型语言模型（LLM）驱动的检索增强生成（RAG）中数据记忆化的方法。RePCS通过比较两种推理路径的KL散度来检测模型是否依赖记忆数据而非检索证据，无需模型访问或重新训练。", "motivation": "解决在检索增强生成（RAG）中，大型语言模型可能依赖记忆的训练数据而非检索到的外部信息，导致输出污染的问题。", "method": "提出了检索路径污染评分（RePCS），通过计算仅使用查询的参数路径和使用查询及检索上下文的检索增强路径之间的KL散度，来诊断模型行为。", "result": "在Prompt-WNQA基准测试中，RePCS的ROC-AUC达到0.918，比之前最强方法提高了6.5个百分点，同时延迟开销保持在4.7%以下。", "conclusion": "RePCS提供了一种轻量级的黑盒保护措施，用于验证RAG系统是否有效利用检索，特别适用于安全关键应用。"}}
{"id": "2506.15543", "title": "Learning Algorithms in the Limit", "authors": ["Hristo Papazov", "Nicolas Flammarion"], "abstract": "This paper studies the problem of learning computable functions in the limit by extending Gold's inductive inference framework to incorporate \\textit{computational observations} and \\textit{restricted input sources}. Complimentary to the traditional Input-Output Observations, we introduce Time-Bound Observations, and Policy-Trajectory Observations to study the learnability of general recursive functions under more realistic constraints. While input-output observations do not suffice for learning the class of general recursive functions in the limit, we overcome this learning barrier by imposing computational complexity constraints or supplementing with approximate time-bound observations. Further, we build a formal framework around observations of \\textit{computational agents} and show that learning computable functions from policy trajectories reduces to learning rational functions from input and output, thereby revealing interesting connections to finite-state transducer inference. On the negative side, we show that computable or polynomial-mass characteristic sets cannot exist for the class of linear-time computable functions even for policy-trajectory observations.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Data Structures and Algorithms (cs.DS); Formal Languages and Automata Theory (cs.FL)", "comments": "Accepted at COLT 2025. This version matches the proceedings version", "pdf_url": "https://arxiv.org/pdf/2506.15543.pdf", "abstract_url": "https://arxiv.org/abs/2506.15543", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Data Structures and Algorithms (cs.DS)", "Formal Languages and Automata Theory (cs.FL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过扩展Gold的归纳推理框架，引入计算观察和受限输入源，研究了在极限下学习可计算函数的问题。通过引入时间限制观察和策略轨迹观察，克服了传统输入输出观察在学习一般递归函数时的限制，并建立了围绕计算代理观察的正式框架。", "motivation": "解决在更现实的约束下学习可计算函数的问题，特别是在输入输出观察不足以学习一般递归函数的情况下。", "method": "扩展Gold的归纳推理框架，引入时间限制观察和策略轨迹观察，以及建立计算代理观察的正式框架。", "result": "通过施加计算复杂性约束或补充近似时间限制观察，克服了学习障碍；策略轨迹观察下的学习可简化为从输入和输出学习有理函数。", "conclusion": "即使在策略轨迹观察下，线性时间可计算函数的类也不存在可计算或多项式质量的特征集，揭示了与有限状态转换器推断的有趣联系。"}}
