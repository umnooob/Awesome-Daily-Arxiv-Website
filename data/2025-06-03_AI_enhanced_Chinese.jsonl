{"id": "2506.00073", "title": "The Automated but Risky Game: Modeling Agent-to-Agent Negotiations and Transactions in Consumer Markets", "authors": ["Shenzhe Zhu", "Jiao Sun", "Yi Nian", "Tobin South", "Alex Pentland", "Jiaxin Pei"], "abstract": "AI agents are increasingly used in consumer-facing applications to assist with tasks such as product search, negotiation, and transaction execution. In this paper, we explore a future scenario where both consumers and merchants authorize AI agents to fully automate negotiations and transactions. We aim to answer two key questions: (1) Do different LLM agents vary in their ability to secure favorable deals for users? (2) What risks arise from fully automating deal-making with AI agents in consumer markets? To address these questions, we develop an experimental framework that evaluates the performance of various LLM agents in real-world negotiation and transaction settings. Our findings reveal that AI-mediated deal-making is an inherently imbalanced game -- different agents achieve significantly different outcomes for their users. Moreover, behavioral anomalies in LLMs can result in financial losses for both consumers and merchants, such as overspending or accepting unreasonable deals. These results underscore that while automation can improve efficiency, it also introduces substantial risks. Users should exercise caution when delegating business decisions to AI agents.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computers and Society (cs.CY); Human-Computer Interaction (cs.HC); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.00073.pdf", "abstract_url": "https://arxiv.org/abs/2506.00073", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Computers and Society (cs.CY)", "Human-Computer Interaction (cs.HC)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了AI代理在消费者市场中自动进行谈判和交易的未来情景，研究了不同LLM代理在为用户争取有利交易方面的能力差异，以及全自动化交易带来的风险。", "motivation": "解决AI代理在消费者市场中进行自动谈判和交易时，不同代理的性能差异和潜在风险的问题。", "method": "开发了一个实验框架，评估各种LLM代理在真实世界谈判和交易设置中的表现。", "result": "发现AI中介的交易是一个内在不平衡的游戏，不同代理为用户达成的结果有显著差异，且LLMs的行为异常可能导致消费者和商家的财务损失。", "conclusion": "虽然自动化可以提高效率，但也带来了重大风险，用户在将商业决策委托给AI代理时应谨慎。"}}
{"id": "2506.00056", "title": "Toward Knowledge-Guided AI for Inverse Design in Manufacturing: A Perspective on Domain, Physics, and Human-AI Synergy", "authors": ["Hugon Lee", "Hyeonbin Moon", "Junhyeong Lee", "Seunghwa RYu"], "abstract": "Artificial intelligence (AI) is reshaping inverse design across manufacturing domain, enabling high-performance discovery in materials, products, and processes. However, purely data-driven approaches often struggle in realistic settings characterized by sparse data, high-dimensional design spaces, and nontrivial physical constraints. This perspective argues for a new generation of design systems that transcend black-box modeling by integrating domain knowledge, physics-informed learning, and intuitive human-AI interfaces. We first demonstrate how expert-guided sampling strategies enhance data efficiency and model generalization. Next, we discuss how physics-informed machine learning enables physically consistent modeling in data-scarce regimes. Finally, we explore how large language models emerge as interactive design agents connecting user intent with simulation tools, optimization pipelines, and collaborative workflows. Through illustrative examples and conceptual frameworks, we advocate that inverse design in manufacturing should evolve into a unified ecosystem, where domain knowledge, physical priors, and adaptive reasoning collectively enable scalable, interpretable, and accessible AI-driven design systems.", "subjects": "Artificial Intelligence (cs.AI); Computational Physics (physics.comp-ph)", "comments": "26 pages, 4 figures", "pdf_url": "https://arxiv.org/pdf/2506.00056.pdf", "abstract_url": "https://arxiv.org/abs/2506.00056", "categories": ["Artificial Intelligence (cs.AI)", "Computational Physics (physics.comp-ph)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了在制造业逆向设计中，如何通过整合领域知识、物理信息学习和直观的人机交互界面，超越黑盒模型，开发新一代设计系统。", "motivation": "解决纯数据驱动方法在稀疏数据、高维设计空间和非平凡物理约束的现实环境中面临的挑战。", "method": "结合专家引导的采样策略、物理信息机器学习和大语言模型作为交互设计代理。", "result": "提出了一个统一的生态系统，其中领域知识、物理先验和自适应推理共同支持可扩展、可解释和易于访问的AI驱动设计系统。", "conclusion": "制造业逆向设计应发展为一个集成了领域知识、物理先验和自适应推理的统一生态系统，以实现AI驱动设计系统的可扩展性、可解释性和易用性。"}}
{"id": "2506.00077", "title": "Gaussian mixture models as a proxy for interacting language models", "authors": ["Edward Wang", "Tianyu Wang", "Avanti Athreya", "Vince Lyzinski", "Carey E. Priebe"], "abstract": "Large language models (LLMs) are a powerful tool with the ability to match human capabilities and behavior in many settings. Retrieval-augmented generation (RAG) further allows LLMs to generate diverse output depending on the contents of their RAG database. This motivates their use in the social sciences to study human behavior between individuals when large-scale experiments are infeasible. However, LLMs depend on complex, computationally expensive algorithms. In this paper, we introduce interacting Gaussian mixture models (GMMs) as an alternative to similar frameworks using LLMs. We compare a simplified model of GMMs to select experimental simulations of LLMs whose updating and response depend on feedback from other LLMs. We find that interacting GMMs capture important features of the dynamics in interacting LLMs, and we investigate key similarities and differences between interacting LLMs and GMMs. We conclude by discussing the benefits of Gaussian mixture models, potential modifications, and future research directions.", "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG); Machine Learning (stat.ML)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.00077.pdf", "abstract_url": "https://arxiv.org/abs/2506.00077", "categories": ["Computation and Language (cs.CL)", "Machine Learning (cs.LG)", "Machine Learning (stat.ML)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出使用高斯混合模型（GMMs）作为大型语言模型（LLMs）的替代方案，用于研究人类行为。通过比较GMMs和LLMs在交互模拟中的表现，发现GMMs能捕捉LLMs动态的重要特征，并探讨了两者的相似性和差异。", "motivation": "大型语言模型（LLMs）虽然在许多设置中能匹配人类的能力和行为，但其依赖复杂且计算成本高的算法。这促使研究者寻找更高效的替代方案，以在社会科学研究中模拟人类个体间的行为。", "method": "本文引入了交互式高斯混合模型（GMMs）作为LLMs的替代框架，并通过简化模型与LLMs在特定实验模拟中的表现进行比较。", "result": "研究发现，交互式GMMs能够捕捉到交互式LLMs动态中的重要特征，同时也揭示了两者之间的关键相似性和差异。", "conclusion": "高斯混合模型在研究交互式LLMs动态中显示出潜力，文章还讨论了GMMs的优势、可能的修改方向及未来的研究路径。"}}
{"id": "2506.00210", "title": "REIC: RAG-Enhanced Intent Classification at Scale", "authors": ["Ziji Zhang", "Michael Yang", "Zhiyu Chen", "Yingying Zhuang", "Shu-Ting Pi", "Qun Liu", "Rajashekar Maragoud", "Vy Nguyen", "Anurag Beniwal"], "abstract": "Accurate intent classification is critical for efficient routing in customer service, ensuring customers are connected with the most suitable agents while reducing handling times and operational costs. However, as companies expand their product lines, intent classification faces scalability challenges due to the increasing number of intents and variations in taxonomy across different verticals. In this paper, we introduce REIC, a Retrieval-augmented generation Enhanced Intent Classification approach, which addresses these challenges effectively. REIC leverages retrieval-augmented generation (RAG) to dynamically incorporate relevant knowledge, enabling precise classification without the need for frequent retraining. Through extensive experiments on real-world datasets, we demonstrate that REIC outperforms traditional fine-tuning, zero-shot, and few-shot methods in large-scale customer service settings. Our results highlight its effectiveness in both in-domain and out-of-domain scenarios, demonstrating its potential for real-world deployment in adaptive and large-scale intent classification systems.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.00210.pdf", "abstract_url": "https://arxiv.org/abs/2506.00210", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "REIC是一种检索增强生成改进的意图分类方法，旨在解决客户服务中意图分类的可扩展性挑战。", "motivation": "随着公司产品线的扩展，意图分类面临因意图数量增加和不同垂直领域分类法变化带来的可扩展性挑战。", "method": "REIC利用检索增强生成（RAG）动态整合相关知识，实现精确分类而无需频繁重新训练。", "result": "在真实世界数据集上的广泛实验表明，REIC在大规模客户服务设置中优于传统的微调、零样本和少样本方法。", "conclusion": "REIC在领域内和领域外场景中都显示出其有效性，展示了其在自适应和大规模意图分类系统中实际部署的潜力。"}}
{"id": "2506.00160", "title": "Werewolf: A Straightforward Game Framework with TTS for Improved User Engagement", "authors": ["Qihui Fan", "Enfu Nan", "Wenbo Li", "Lei Lu", "Pu Zhao", "Yanzhi Wang"], "abstract": "The growing popularity of social deduction game systems for both business applications and AI research has greatly benefited from the rapid advancements in Large Language Models (LLMs), which now demonstrate stronger reasoning and persuasion capabilities. Especially with the raise of DeepSeek R1 and V3 models, LLMs should enable a more engaging experience for human players in LLM-agent-based social deduction games like Werewolf. Previous works either fine-tuning, advanced prompting engineering, or additional experience pool to achieve engaging text-format Werewolf game experience. We propose a novel yet straightforward LLM-based Werewolf game system with tuned Text-to-Speech(TTS) models designed for enhanced compatibility with various LLM models, and improved user engagement. We argue with ever enhancing LLM reasoning, extra components will be unnecessary in the case of Werewolf.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.00160.pdf", "abstract_url": "https://arxiv.org/abs/2506.00160", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于大型语言模型(LLM)的简单狼人杀游戏框架，结合优化的文本转语音(TTS)技术，旨在提升用户参与度。", "motivation": "随着大型语言模型(LLM)在推理和说服能力上的快速进步，特别是在DeepSeek R1和V3模型的推动下，LLM能够在基于代理的社交推理游戏（如狼人杀）中为人类玩家提供更吸引人的体验。此前的工作通过微调、高级提示工程或额外经验池来实现吸引人的文本格式狼人杀游戏体验。", "method": "我们提出了一种新颖而简单的基于LLM的狼人杀游戏系统，该系统采用了优化的文本转语音(TTS)模型，旨在提高与各种LLM模型的兼容性，并提升用户参与度。", "result": "随着LLM推理能力的不断增强，我们认为在狼人杀游戏的情况下，额外的组件将变得不必要。", "conclusion": "本文的结论是，通过结合优化的TTS技术和LLM的强大推理能力，可以创建一个简单而有效的狼人杀游戏框架，无需额外复杂的组件即可显著提升用户体验和参与度。"}}
{"id": "2506.00320", "title": "Dyna-Think: Synergizing Reasoning, Acting, and World Model Simulation in AI Agents", "authors": ["Xiao Yu", "Baolin Peng", "Ruize Xu", "Michel Galley", "Hao Cheng", "Suman Nath", "Jianfeng Gao", "Zhou Yu"], "abstract": "Recent progress in reasoning with large language models (LLMs), such as DeepSeek-R1, demonstrates impressive capabilities in domains like mathematics and coding, by exhibiting complex cognitive behaviors such as verification, goal decomposition, and self-reflection. However, it is unclear what behavior is effective and what behavior is missing for long-horizon AI agents tasks. In this work, we propose Dyna-Think, a thinking framework that integrates planning with an internal world model with reasoning and acting to enhance AI agent performance. To enable Dyna-Think, we propose Dyna-Think Imitation Learning (DIT) and Dyna-Think Dyna Training (DDT). To initialize a policy with Dyna-Think, DIT reconstructs the thinking process of R1 to focus on performing world model simulation relevant to the proposed (and planned) action, and trains the policy using this reconstructed data. To enhance Dyna-Think, DDT uses a two-stage training process to first improve the agent's world modeling ability via objectives such as state prediction or critique generation, and then improve the agent's action via policy training. We evaluate our methods on OSWorld, and demonstrate that Dyna-Think improves the agent's in-domain and out-of-domain performance, achieving similar best-of-n performance compared to R1 while generating 2x less tokens on average. Our extensive empirical studies reveal that 1) using critique generation for world model training is effective to improve policy performance; and 2) AI agents with better performance correlate with better world modeling abilities. We believe our results suggest a promising research direction to integrate world model simulation into AI agents to enhance their reasoning, planning, and acting capabilities.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.00320.pdf", "abstract_url": "https://arxiv.org/abs/2506.00320", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "Dyna-Think是一个整合了规划、内部世界模型、推理和行动的思考框架，旨在提升AI代理的性能。通过Dyna-Think模仿学习（DIT）和Dyna-Think Dyna训练（DDT）两种方法，该框架在OSWorld上的评估显示，它能在生成更少令牌的同时，达到与DeepSeek-R1相似的性能，同时揭示了更好的世界建模能力与AI代理性能之间的相关性。", "motivation": "尽管大型语言模型（如DeepSeek-R1）在数学和编码等领域展示了复杂的认知行为，但对于长期任务的AI代理来说，哪些行为有效、哪些缺失尚不明确。本研究旨在通过整合世界模型模拟、推理和行动来提升AI代理的性能。", "method": "提出了Dyna-Think框架，包括DIT和DDT两种方法。DIT通过重建R1的思考过程来初始化策略，专注于执行与提议（和规划）行动相关的世界模型模拟。DDT则通过两阶段训练过程，首先通过状态预测或批判生成等目标提升代理的世界建模能力，然后通过策略训练提升代理的行动能力。", "result": "在OSWorld上的评估显示，Dyna-Think在生成2倍少令牌的同时，达到了与R1相似的性能。研究还发现，使用批判生成进行世界模型训练能有效提升策略性能，且AI代理的性能与其世界建模能力正相关。", "conclusion": "研究结果表明，将世界模型模拟整合到AI代理中以增强其推理、规划和行动能力是一个有前途的研究方向。"}}
{"id": "2506.00235", "title": "MedOrch: Medical Diagnosis with Tool-Augmented Reasoning Agents for Flexible Extensibility", "authors": ["Yexiao He", "Ang Li", "Boyi Liu", "Zhewei Yao", "Yuxiong He"], "abstract": "Healthcare decision-making represents one of the most challenging domains for Artificial Intelligence (AI), requiring the integration of diverse knowledge sources, complex reasoning, and various external analytical tools. Current AI systems often rely on either task-specific models, which offer limited adaptability, or general language models without grounding with specialized external knowledge and tools. We introduce MedOrch, a novel framework that orchestrates multiple specialized tools and reasoning agents to provide comprehensive medical decision support. MedOrch employs a modular, agent-based architecture that facilitates the flexible integration of domain-specific tools without altering the core system. Furthermore, it ensures transparent and traceable reasoning processes, enabling clinicians to meticulously verify each intermediate step underlying the system's recommendations. We evaluate MedOrch across three distinct medical applications: Alzheimer's disease diagnosis, chest X-ray interpretation, and medical visual question answering, using authentic clinical datasets. The results demonstrate MedOrch's competitive performance across these diverse medical tasks. Notably, in Alzheimer's disease diagnosis, MedOrch achieves an accuracy of 93.26%, surpassing the state-of-the-art baseline by over four percentage points. For predicting Alzheimer's disease progression, it attains a 50.35% accuracy, marking a significant improvement. In chest X-ray analysis, MedOrch exhibits superior performance with a Macro AUC of 61.2% and a Macro F1-score of 25.5%. Moreover, in complex multimodal visual question answering (Image+Table), MedOrch achieves an accuracy of 54.47%. These findings underscore MedOrch's potential to advance healthcare AI by enabling reasoning-driven tool utilization for multimodal medical data processing and supporting intricate cognitive tasks in clinical decision-making.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.00235.pdf", "abstract_url": "https://arxiv.org/abs/2506.00235", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "MedOrch是一个新型框架，通过协调多个专业工具和推理代理，提供全面的医疗决策支持。它在不同的医疗应用中表现出色，特别是在阿尔茨海默病诊断、胸部X光解读和医疗视觉问答方面。", "motivation": "解决医疗决策领域中AI系统适应性有限或缺乏专业外部知识和工具支持的问题。", "method": "采用模块化、基于代理的架构，灵活集成领域特定工具，确保透明和可追溯的推理过程。", "result": "在阿尔茨海默病诊断中准确率达到93.26%，在胸部X光分析中Macro AUC为61.2%，在复杂多模态视觉问答中准确率为54.47%。", "conclusion": "MedOrch通过启用推理驱动的工具利用，支持复杂的临床决策任务，有潜力推动医疗AI的发展。"}}
{"id": "2506.00232", "title": "ComposeRAG: A Modular and Composable RAG for Corpus-Grounded Multi-Hop Question Answering", "authors": ["Ruofan Wu", "Youngwon Lee", "Fan Shu", "Danmei Xu", "Seung-won Hwang", "Zhewei Yao", "Yuxiong He", "Feng Yan"], "abstract": "Retrieval-Augmented Generation (RAG) systems are increasingly diverse, yet many suffer from monolithic designs that tightly couple core functions like query reformulation, retrieval, reasoning, and verification. This limits their interpretability, systematic evaluation, and targeted improvement, especially for complex multi-hop question answering. We introduce ComposeRAG, a novel modular abstraction that decomposes RAG pipelines into atomic, composable modules. Each module, such as Question Decomposition, Query Rewriting, Retrieval Decision, and Answer Verification, acts as a parameterized transformation on structured inputs/outputs, allowing independent implementation, upgrade, and analysis. To enhance robustness against errors in multi-step reasoning, ComposeRAG incorporates a self-reflection mechanism that iteratively revisits and refines earlier steps upon verification failure. Evaluated on four challenging multi-hop QA benchmarks, ComposeRAG consistently outperforms strong baselines in both accuracy and grounding fidelity. Specifically, it achieves up to a 15% accuracy improvement over fine-tuning-based methods and up to a 5% gain over reasoning-specialized pipelines under identical retrieval conditions. Crucially, ComposeRAG significantly enhances grounding: its verification-first design reduces ungrounded answers by over 10% in low-quality retrieval settings, and by approximately 3% even with strong corpora. Comprehensive ablation studies validate the modular architecture, demonstrating distinct and additive contributions from each component. These findings underscore ComposeRAG's capacity to deliver flexible, transparent, scalable, and high-performing multi-hop reasoning with improved grounding and interpretability.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.00232.pdf", "abstract_url": "https://arxiv.org/abs/2506.00232", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "ComposeRAG是一种新颖的模块化抽象，将RAG管道分解为原子化、可组合的模块，以提高多跳问答的准确性、基础忠实度和可解释性。", "motivation": "解决现有RAG系统因设计单一而导致的解释性差、系统评估困难和针对性改进受限的问题，特别是在复杂的多跳问答任务中。", "method": "引入模块化抽象，将RAG管道分解为如问题分解、查询重写、检索决策和答案验证等原子化模块，并加入自我反思机制以增强多步推理的鲁棒性。", "result": "在四个具有挑战性的多跳QA基准测试中，ComposeRAG在准确性和基础忠实度上均优于强基线，准确率最高提升15%，基础忠实度在低质量检索设置下提升超过10%。", "conclusion": "ComposeRAG通过其模块化架构和验证优先设计，提供了灵活、透明、可扩展且高性能的多跳推理能力，显著提高了基础忠实度和可解释性。"}}
{"id": "2506.00417", "title": "World Models for Cognitive Agents: Transforming Edge Intelligence in Future Networks", "authors": ["Changyuan Zhao", "Ruichen Zhang", "Jiacheng Wang", "Gaosheng Zhao", "Dusit Niyato", "Geng Sun", "Shiwen Mao", "Dong In Kim"], "abstract": "World models are emerging as a transformative paradigm in artificial intelligence, enabling agents to construct internal representations of their environments for predictive reasoning, planning, and decision-making. By learning latent dynamics, world models provide a sample-efficient framework that is especially valuable in data-constrained or safety-critical scenarios. In this paper, we present a comprehensive overview of world models, highlighting their architecture, training paradigms, and applications across prediction, generation, planning, and causal reasoning. We compare and distinguish world models from related concepts such as digital twins, the metaverse, and foundation models, clarifying their unique role as embedded cognitive engines for autonomous agents. We further propose Wireless Dreamer, a novel world model-based reinforcement learning framework tailored for wireless edge intelligence optimization, particularly in low-altitude wireless networks (LAWNs). Through a weather-aware UAV trajectory planning case study, we demonstrate the effectiveness of our framework in improving learning efficiency and decision quality.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "7 pages, 4 figures", "pdf_url": "https://arxiv.org/pdf/2506.00417.pdf", "abstract_url": "https://arxiv.org/abs/2506.00417", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "世界模型作为人工智能中的一种变革性范式，能够帮助智能体构建环境的内在表示，以进行预测推理、规划和决策。本文全面概述了世界模型的架构、训练范式及其在预测、生成、规划和因果推理等领域的应用，并提出了专为无线边缘智能优化设计的Wireless Dreamer框架。", "motivation": "解决在数据受限或安全关键场景下，智能体如何高效学习和决策的问题。", "method": "提出了一种基于世界模型的强化学习框架Wireless Dreamer，特别适用于低空无线网络（LAWNs）的优化。", "result": "通过天气感知的无人机轨迹规划案例研究，证明了该框架在提高学习效率和决策质量方面的有效性。", "conclusion": "世界模型作为自主智能体的嵌入式认知引擎，在无线边缘智能优化等领域展现出巨大潜力。"}}
{"id": "2506.00641", "title": "AgentAuditor: Human-Level Safety and Security Evaluation for LLM Agents", "authors": ["Hanjun Luo", "Shenyu Dai", "Chiming Ni", "Xinfeng Li", "Guibin Zhang", "Kun Wang", "Tongliang Liu", "Hanan Salam"], "abstract": "Despite the rapid advancement of LLM-based agents, the reliable evaluation of their safety and security remains a significant challenge. Existing rule-based or LLM-based evaluators often miss dangers in agents' step-by-step actions, overlook subtle meanings, fail to see how small issues compound, and get confused by unclear safety or security rules. To overcome this evaluation crisis, we introduce \\sys, a universal, training-free, memory-augmented reasoning framework that empowers LLM evaluators to emulate human expert evaluators. \\sys constructs an experiential memory by having an LLM adaptively extract structured semantic features (e.g., scenario, risk, behavior) and generate associated chain-of-thought reasoning traces for past interactions. A multi-stage, context-aware retrieval-augmented generation process then dynamically retrieves the most relevant reasoning experiences to guide the LLM evaluator's assessment of new cases. Moreover, we developed \\data, the first benchmark designed to check how well LLM-based evaluators can spot both safety risks and security threats. \\data comprises \\textbf{2293} meticulously annotated interaction records, covering \\textbf{15} risk types across \\textbf{29} application scenarios. A key feature of \\data is its nuanced approach to ambiguous risk situations, employing ``Strict'' and ``Lenient'' judgment standards. Experiments demonstrate that \\sys not only consistently improves the evaluation performance of LLMs across all benchmarks but also sets a new state-of-the-art in LLM-as-a-judge for agent safety and security, achieving human-level accuracy. Our work is openly openly accessible.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.00641.pdf", "abstract_url": "https://arxiv.org/abs/2506.00641", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了AgentAuditor，一个用于评估基于LLM的代理的安全性和安全性的框架，以及一个名为data的基准测试，旨在提高评估的准确性和人类水平的一致性。", "motivation": "现有的基于规则或LLM的评估器在评估LLM代理的安全性和安全性时存在不足，无法准确识别逐步行动中的危险、忽略细微含义、未能看到小问题的累积以及被不明确的安全或安全规则所困惑。", "method": "引入了一个通用的、无需训练的、记忆增强的推理框架AgentAuditor，通过让LLM自适应地提取结构化语义特征并生成相关的思维链推理痕迹来构建经验记忆，然后通过多阶段、上下文感知的检索增强生成过程动态检索最相关的推理经验来指导对新案例的评估。", "result": "实验表明，AgentAuditor不仅在所有基准测试中持续提高了LLM的评估性能，而且在代理安全性和安全性的LLM-as-a-judge方面设定了新的最先进水平，达到了人类水平的准确性。", "conclusion": "AgentAuditor和data基准测试的开发为LLM代理的安全性和安全性评估提供了一个有效的解决方案，实现了人类水平的评估准确性，并且这项工作已经公开可用。"}}
{"id": "2506.00577", "title": "Reasoning Like an Economist: Post-Training on Economic Problems Induces Strategic Generalization in LLMs", "authors": ["Yufa Zhou", "Shaobo Wang", "Xingyu Dong", "Xiangqi Jin", "Yifang Chen", "Yue Min", "Kexin Yang", "Xingzhang Ren", "Dayiheng Liu", "Linfeng Zhang"], "abstract": "Directly training Large Language Models (LLMs) for Multi-Agent Systems (MAS) remains challenging due to intricate reward modeling, dynamic agent interactions, and demanding generalization requirements. This paper explores whether post-training techniques, specifically Supervised Fine-Tuning (SFT) and Reinforcement Learning with Verifiable Rewards (RLVR), can effectively $\\textit{generalize}$ to multi-agent scenarios. We use economic reasoning as a testbed, leveraging its strong foundations in mathematics and game theory, its demand for structured analytical reasoning, and its relevance to real-world applications such as market design, resource allocation, and policy analysis. We introduce $\\textbf{Recon}$ ($\\textbf{R}$easoning like an $\\textbf{ECON}$omist), a 7B-parameter open-source LLM post-trained on a hand-curated dataset of 2,100 high-quality economic reasoning problems. Comprehensive evaluation on economic reasoning benchmarks and multi-agent games reveals clear improvements in structured reasoning and economic rationality. These results underscore the promise of domain-aligned post-training for enhancing reasoning and agent alignment, shedding light on the roles of SFT and RL in shaping model behavior. Code is available at", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Science and Game Theory (cs.GT); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.00577.pdf", "abstract_url": "https://arxiv.org/abs/2506.00577", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Computer Science and Game Theory (cs.GT)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了通过监督微调（SFT）和可验证奖励的强化学习（RLVR）后训练技术，是否能够有效地将大型语言模型（LLMs）推广到多智能体系统（MAS）中。通过经济推理作为测试平台，研究展示了在高质量经济推理问题数据集上后训练的7B参数开源LLM（Recon）在结构化推理和经济理性方面的明显改进。", "motivation": "直接训练大型语言模型（LLMs）用于多智能体系统（MAS）由于复杂的奖励建模、动态的智能体交互和高要求的泛化需求而具有挑战性。本研究旨在探索后训练技术是否能够有效推广到多智能体场景。", "method": "研究采用了监督微调（SFT）和可验证奖励的强化学习（RLVR）作为后训练技术，并在一个包含2,100个高质量经济推理问题的手工策划数据集上对7B参数的开源LLM（Recon）进行了后训练。", "result": "在经济推理基准和多智能体游戏上的全面评估显示，后训练显著提高了模型的结构化推理能力和经济理性。", "conclusion": "研究结果表明，领域对齐的后训练对于增强推理能力和智能体对齐具有潜力，同时也揭示了SFT和RL在塑造模型行为中的作用。"}}
{"id": "2506.00618", "title": "RiOSWorld: Benchmarking the Risk of Multimodal Compter-Use Agents", "authors": ["Jingyi Yang", "Shuai Shao", "Dongrui Liu", "Jing Shao"], "abstract": "With the rapid development of multimodal large language models (MLLMs), they are increasingly deployed as autonomous computer-use agents capable of accomplishing complex computer tasks. However, a pressing issue arises: Can the safety risk principles designed and aligned for general MLLMs in dialogue scenarios be effectively transferred to real-world computer-use scenarios? Existing research on evaluating the safety risks of MLLM-based computer-use agents suffers from several limitations: it either lacks realistic interactive environments, or narrowly focuses on one or a few specific risk types. These limitations ignore the complexity, variability, and diversity of real-world environments, thereby restricting comprehensive risk evaluation for computer-use agents. To this end, we introduce \\textbf{RiOSWorld}, a benchmark designed to evaluate the potential risks of MLLM-based agents during real-world computer manipulations. Our benchmark includes 492 risky tasks spanning various computer applications, involving web, social media, multimedia, os, email, and office software. We categorize these risks into two major classes based on their risk source: (i) User-originated risks and (ii) Environmental risks. For the evaluation, we evaluate safety risks from two perspectives: (i) Risk goal intention and (ii) Risk goal completion. Extensive experiments with multimodal agents on \\textbf{RiOSWorld} demonstrate that current computer-use agents confront significant safety risks in real-world scenarios. Our findings highlight the necessity and urgency of safety alignment for computer-use agents in real-world computer manipulation, providing valuable insights for developing trustworthy computer-use agents. Our benchmark is publicly available at", "subjects": "Artificial Intelligence (cs.AI)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2506.00618.pdf", "abstract_url": "https://arxiv.org/abs/2506.00618", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了RiOSWorld，一个旨在评估基于多模态大语言模型（MLLM）的计算机使用代理在真实世界计算机操作中潜在风险的基准测试。该基准包括492个涉及多种计算机应用的风险任务，并将风险分为用户来源风险和环境风险两大类。通过从风险目标意图和风险目标完成两个角度进行评估，研究发现当前计算机使用代理在真实世界场景中面临重大安全风险，强调了安全对齐的必要性和紧迫性。", "motivation": "随着多模态大语言模型（MLLMs）的快速发展，它们越来越多地被部署为能够完成复杂计算机任务的自主计算机使用代理。然而，一个紧迫的问题出现了：为对话场景设计和对齐的安全风险原则是否能有效地转移到真实世界的计算机使用场景中？现有的评估基于MLLM的计算机使用代理安全风险的研究存在几个局限性：要么缺乏真实的交互环境，要么狭隘地关注一种或几种特定的风险类型。这些局限性忽视了真实世界环境的复杂性、多变性和多样性，从而限制了对计算机使用代理的全面风险评估。", "method": "为了解决这些问题，作者引入了RiOSWorld，一个旨在评估基于MLLM的代理在真实世界计算机操作中潜在风险的基准测试。该基准包括492个涉及各种计算机应用的风险任务，并将这些风险基于其来源分为两大类：（i）用户来源的风险和（ii）环境风险。评估从两个角度进行：（i）风险目标意图和（ii）风险目标完成。", "result": "在RiOSWorld上对多模态代理进行的广泛实验表明，当前的计算机使用代理在真实世界场景中面临重大安全风险。", "conclusion": "研究结果强调了在真实世界计算机操作中对计算机使用代理进行安全对齐的必要性和紧迫性，为开发可信赖的计算机使用代理提供了宝贵的见解。"}}
{"id": "2506.00664", "title": "OntoRAG: Enhancing Question-Answering through Automated Ontology Derivation from Unstructured Knowledge Bases", "authors": ["Yash Tiwari", "Owais Ahmad Lone", "Mayukha Pal"], "abstract": "Ontologies are pivotal for structuring knowledge bases to enhance question answering (QA) systems powered by Large Language Models (LLMs). However, traditional ontology creation relies on manual efforts by domain experts, a process that is time intensive, error prone, and impractical for large, dynamic knowledge domains. This paper introduces OntoRAG, an automated pipeline designed to derive ontologies from unstructured knowledge bases, with a focus on electrical relay documents. OntoRAG integrates advanced techniques, including web scraping, PDF parsing, hybrid chunking, information extraction, knowledge graph construction, and ontology creation, to transform unstructured data into a queryable ontology. By leveraging LLMs and graph based methods, OntoRAG enhances global sensemaking capabilities, outperforming conventional Retrieval Augmented Generation (RAG) and GraphRAG approaches in comprehensiveness and diversity. Experimental results demonstrate OntoRAGs effectiveness, achieving a comprehensiveness win rate of 85% against vector RAG and 75% against GraphRAGs best configuration. This work addresses the critical challenge of automating ontology creation, advancing the vision of the semantic web.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.00664.pdf", "abstract_url": "https://arxiv.org/abs/2506.00664", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "OntoRAG是一种自动化管道，旨在从非结构化知识库中派生本体，特别关注电气继电器文档，以提高问答系统的性能。", "motivation": "传统本体创建依赖领域专家的手动努力，这一过程耗时、易错且不适用于大型动态知识领域。", "method": "OntoRAG整合了网络爬虫、PDF解析、混合分块、信息提取、知识图构建和本体创建等先进技术，将非结构化数据转换为可查询的本体。", "result": "实验结果显示，OntoRAG在全面性和多样性上优于传统的检索增强生成(RAG)和GraphRAG方法，全面性胜率分别达到85%和75%。", "conclusion": "OntoRAG解决了自动化本体创建的关键挑战，推动了语义网的愿景。"}}
{"id": "2506.01103", "title": "DeepVerse: 4D Autoregressive Video Generation as a World Model", "authors": ["Junyi Chen", "Haoyi Zhu", "Xianglong He", "Yifan Wang", "Jianjun Zhou", "Wenzheng Chang", "Yang Zhou", "Zizun Li", "Zhoujie Fu", "Jiangmiao Pang", "Tong He"], "abstract": "World models serve as essential building blocks toward Artificial General Intelligence (AGI), enabling intelligent agents to predict future states and plan actions by simulating complex physical interactions. However, existing interactive models primarily predict visual observations, thereby neglecting crucial hidden states like geometric structures and spatial coherence. This leads to rapid error accumulation and temporal inconsistency. To address these limitations, we introduce DeepVerse, a novel 4D interactive world model explicitly incorporating geometric predictions from previous timesteps into current predictions conditioned on actions. Experiments demonstrate that by incorporating explicit geometric constraints, DeepVerse captures richer spatio-temporal relationships and underlying physical dynamics. This capability significantly reduces drift and enhances temporal consistency, enabling the model to reliably generate extended future sequences and achieve substantial improvements in prediction accuracy, visual realism, and scene rationality. Furthermore, our method provides an effective solution for geometry-aware memory retrieval, effectively preserving long-term spatial consistency. We validate the effectiveness of DeepVerse across diverse scenarios, establishing its capacity for high-fidelity, long-horizon predictions grounded in geometry-aware dynamics.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.01103.pdf", "abstract_url": "https://arxiv.org/abs/2506.01103", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "DeepVerse是一种新型的4D交互式世界模型，通过将几何预测从先前时间步明确纳入当前基于动作的预测中，解决了现有模型忽视几何结构和空间一致性的问题。", "motivation": "解决现有交互模型主要预测视觉观察而忽视几何结构和空间一致性，导致错误累积和时间不一致的问题。", "method": "引入DeepVerse，一种明确将先前时间步的几何预测纳入当前基于动作预测的4D交互式世界模型。", "result": "通过纳入明确的几何约束，DeepVerse能够捕捉更丰富的时空关系和潜在物理动态，显著减少漂移并增强时间一致性，从而可靠地生成延长的未来序列，并在预测准确性、视觉真实性和场景合理性方面实现显著改进。", "conclusion": "DeepVerse通过几何感知的动态预测，为高保真、长视野的预测提供了有效解决方案，有效保持了长期空间一致性。"}}
{"id": "2506.00751", "title": "Alignment Revisited: Are Large Language Models Consistent in Stated and Revealed Preferences?", "authors": ["Zhuojun Gu", "Quan Wang", "Shuchu Han"], "abstract": "Recent advances in Large Language Models (LLMs) highlight the need to align their behaviors with human values. A critical, yet understudied, issue is the potential divergence between an LLM's stated preferences (its reported alignment with general principles) and its revealed preferences (inferred from decisions in contextualized scenarios). Such deviations raise fundamental concerns for the interpretability, trustworthiness, reasoning transparency, and ethical deployment of LLMs, particularly in high-stakes applications. This work formally defines and proposes a method to measure this preference deviation. We investigate how LLMs may activate different guiding principles in specific contexts, leading to choices that diverge from previously stated general principles. Our approach involves crafting a rich dataset of well-designed prompts as a series of forced binary choices and presenting them to LLMs. We compare LLM responses to general principle prompts stated preference with LLM responses to contextualized prompts revealed preference, using metrics like KL divergence to quantify the deviation. We repeat the analysis across different categories of preferences and on four mainstream LLMs and find that a minor change in prompt format can often pivot the preferred choice regardless of the preference categories and LLMs in the test. This prevalent phenomenon highlights the lack of understanding and control of the LLM decision-making competence. Our study will be crucial for integrating LLMs into services, especially those that interact directly with humans, where morality, fairness, and social responsibilities are crucial dimensions. Furthermore, identifying or being aware of such deviation will be critically important as LLMs are increasingly envisioned for autonomous agentic tasks where continuous human evaluation of all LLMs' intermediary decision-making steps is impossible.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.00751.pdf", "abstract_url": "https://arxiv.org/abs/2506.00751", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文探讨了大型语言模型（LLMs）在陈述偏好（报告的对一般原则的遵循）与揭示偏好（在具体情境中的决策推断）之间可能存在的偏差，提出了一种测量这种偏差的方法，并发现提示格式的微小变化可以显著影响LLMs的选择，这突显了对LLM决策能力理解和控制的缺乏。", "motivation": "解决大型语言模型（LLMs）在陈述偏好与揭示偏好之间可能存在的偏差问题，这对于提高LLMs的可解释性、可信度、推理透明度和伦理部署至关重要，尤其是在高风险应用中。", "method": "通过设计一系列强制二元选择的提示，构建一个丰富的数据集，并将这些提示呈现给LLMs，比较LLMs对一般原则提示的响应（陈述偏好）与对情境化提示的响应（揭示偏好），使用KL散度等指标来量化偏差。", "result": "研究发现，提示格式的微小变化往往可以改变首选选择，无论偏好类别和测试中的LLMs如何，这一普遍现象突显了对LLM决策能力理解和控制的缺乏。", "conclusion": "这项研究对于将LLMs集成到服务中，特别是那些直接与人类互动的服务，其中道德、公平和社会责任是关键维度，至关重要。此外，随着LLMs越来越多地被设想用于自主代理任务，识别或意识到这种偏差将变得极其重要，因为在这些任务中，人类无法持续评估所有LLMs的中间决策步骤。"}}
{"id": "2506.00781", "title": "CoP: Agentic Red-teaming for Large Language Models using Composition of Principles", "authors": ["Chen Xiong", "Pin-Yu Chen", "Tsung-Yi Ho"], "abstract": "Recent advances in Large Language Models (LLMs) have spurred transformative applications in various domains, ranging from open-source to proprietary LLMs. However, jailbreak attacks, which aim to break safety alignment and user compliance by tricking the target LLMs into answering harmful and risky responses, are becoming an urgent concern. The practice of red-teaming for LLMs is to proactively explore potential risks and error-prone instances before the release of frontier AI technology. This paper proposes an agentic workflow to automate and scale the red-teaming process of LLMs through the Composition-of-Principles (CoP) framework, where human users provide a set of red-teaming principles as instructions to an AI agent to automatically orchestrate effective red-teaming strategies and generate jailbreak prompts. Distinct from existing red-teaming methods, our CoP framework provides a unified and extensible framework to encompass and orchestrate human-provided red-teaming principles to enable the automated discovery of new red-teaming strategies. When tested against leading LLMs, CoP reveals unprecedented safety risks by finding novel jailbreak prompts and improving the best-known single-turn attack success rate by up to 19.0 times.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.00781.pdf", "abstract_url": "https://arxiv.org/abs/2506.00781", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种名为CoP的代理工作流程，通过原则组合（CoP）框架自动化并扩展大型语言模型（LLMs）的红队测试过程，旨在发现和解决LLMs的安全风险。", "motivation": "随着大型语言模型（LLMs）在各个领域的广泛应用，越狱攻击（jailbreak attacks）成为紧迫问题，这些攻击旨在破坏模型的安全对齐和用户合规性，诱使模型产生有害和风险响应。红队测试（red-teaming）作为一种主动探索潜在风险和错误实例的方法，对于前沿AI技术的发布至关重要。", "method": "本文提出的CoP框架允许人类用户提供一组红队测试原则作为指令，由AI代理自动编排有效的红队测试策略并生成越狱提示。这一框架提供了一个统一且可扩展的框架，以包含和编排人类提供的红队测试原则，从而实现新红队测试策略的自动发现。", "result": "在领先的LLMs上测试时，CoP通过发现新的越狱提示并将最佳已知的单轮攻击成功率提高了多达19.0倍，揭示了前所未有的安全风险。", "conclusion": "CoP框架为自动化红队测试提供了一个有效的解决方案，能够显著提高发现LLMs安全风险的能力，对于提升LLMs的安全性和可靠性具有重要意义。"}}
{"id": "2506.00794", "title": "Predicting Empirical AI Research Outcomes with Language Models", "authors": ["Jiaxin Wen", "Chenglei Si", "Yueh-han Chen", "He He", "Shi Feng"], "abstract": "Many promising-looking ideas in AI research fail to deliver, but their validation takes substantial human labor and compute. Predicting an idea's chance of success is thus crucial for accelerating empirical AI research, a skill that even expert researchers can only acquire through substantial experience. We build the first benchmark for this task and compare LMs with human experts. Concretely, given two research ideas (e.g., two jailbreaking methods), we aim to predict which will perform better on a set of benchmarks. We scrape ideas and experimental results from conference papers, yielding 1,585 human-verified idea pairs published after our base model's cut-off date for testing, and 6,000 pairs for training. We then develop a system that combines a fine-tuned GPT-4.1 with a paper retrieval agent, and we recruit 25 human experts to compare with. In the NLP domain, our system beats human experts by a large margin (64.4% v.s. 48.9%). On the full test set, our system achieves 77% accuracy, while off-the-shelf frontier LMs like o3 perform no better than random guessing, even with the same retrieval augmentation. We verify that our system does not exploit superficial features like idea complexity through extensive human-written and LM-designed robustness tests. Finally, we evaluate our system on unpublished novel ideas, including ideas generated by an AI ideation agent. Our system achieves 63.6% accuracy, demonstrating its potential as a reward model for improving idea generation models. Altogether, our results outline a promising new direction for LMs to accelerate empirical AI research.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.00794.pdf", "abstract_url": "https://arxiv.org/abs/2506.00794", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文构建了第一个基准任务，比较语言模型与人类专家在预测AI研究想法成功概率上的表现。通过微调的GPT-4.1与论文检索代理结合的系统，在NLP领域大幅超越人类专家，并在未发表的新想法上展示了作为奖励模型的潜力。", "motivation": "AI研究中许多看似有前途的想法最终未能成功，而其验证过程消耗大量人力和计算资源。预测想法的成功概率对于加速实证AI研究至关重要，这是一项即使专家也需要大量经验才能掌握的技能。", "method": "研究通过从会议论文中抓取想法和实验结果，构建了1,585对人类验证的想法对用于测试，6,000对用于训练。开发了一个结合微调GPT-4.1和论文检索代理的系统，并与25位人类专家进行比较。", "result": "在NLP领域，该系统以64.4%的准确率大幅超越人类专家的48.9%。在整个测试集上达到77%的准确率，而现成的先进语言模型表现不优于随机猜测。系统在未发表的新想法上达到63.6%的准确率。", "conclusion": "研究结果表明，语言模型在加速实证AI研究方面具有潜力，特别是在作为奖励模型改进想法生成模型方面。这为语言模型在AI研究中的应用开辟了新的方向。"}}
{"id": "2506.00886", "title": "Toward a Theory of Agents as Tool-Use Decision-Makers", "authors": ["Hongru Wang", "Cheng Qian", "Manling Li", "Jiahao Qiu", "Boyang Xue", "Mengdi Wang", "Heng Ji", "Kam-Fai Wong"], "abstract": "As Large Language Models (LLMs) evolve into increasingly autonomous agents, fundamental questions about their epistemic foundations remain unresolved: What defines an agent? How should it make decisions? And what objectives should guide its behavior? In this position paper, we argue that true autonomy requires agents to be grounded in a coherent epistemic framework that governs what they know, what they need to know, and how to acquire that knowledge efficiently. We propose a unified theory that treats internal reasoning and external actions as equivalent epistemic tools, enabling agents to systematically coordinate introspection and interaction. Building on this framework, we advocate for aligning an agent's tool use decision-making boundary with its knowledge boundary, thereby minimizing unnecessary tool use and maximizing epistemic efficiency. This perspective shifts the design of agents from mere action executors to knowledge-driven intelligence systems, offering a principled path toward building foundation agents capable of adaptive, efficient, and goal-directed behavior.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.00886.pdf", "abstract_url": "https://arxiv.org/abs/2506.00886", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种将大型语言模型（LLMs）作为自主代理的理论框架，强调代理应基于一致的认识论基础，通过内部推理和外部行动作为等效的认识工具，系统地协调内省和互动，以实现知识驱动的高效行为。", "motivation": "解决大型语言模型作为自主代理时的认识论基础问题，包括代理的定义、决策方式以及行为指导目标，以实现真正的自主性。", "method": "提出一个统一的理论框架，将内部推理和外部行动视为等效的认识工具，并主张将代理的工具使用决策边界与其知识边界对齐。", "result": "通过这一框架，代理能够最小化不必要的工具使用，最大化认识效率，从而从单纯的动作执行者转变为知识驱动的智能系统。", "conclusion": "这一视角为构建能够适应、高效且目标导向的基础代理提供了一条原则性的路径，推动了代理设计从动作执行到知识驱动的转变。"}}
{"id": "2506.01300", "title": "ReAgent-V: A Reward-Driven Multi-Agent Framework for Video Understanding", "authors": ["Yiyang Zhou", "Yangfan He", "Yaofeng Su", "Siwei Han", "Joel Jang", "Gedas Bertasius", "Mohit Bansal", "Huaxiu Yao"], "abstract": "Video understanding is fundamental to tasks such as action recognition, video reasoning, and robotic control. Early video understanding methods based on large vision-language models (LVLMs) typically adopt a single-pass reasoning paradigm without dynamic feedback, limiting the model's capacity to self-correct and adapt in complex scenarios. Recent efforts have attempted to address this limitation by incorporating reward models and reinforcement learning to enhance reasoning, or by employing tool-agent frameworks. However, these approaches face several challenges, including high annotation costs, reward signals that fail to capture real-time reasoning states, and low inference efficiency. To overcome these issues, we propose ReAgent-V, a novel agentic video understanding framework that integrates efficient frame selection with real-time reward generation during inference. These reward signals not only guide iterative answer refinement through a multi-perspective reflection mechanism-adjusting predictions from conservative, neutral, and aggressive viewpoints-but also enable automatic filtering of high-quality data for supervised fine-tuning (SFT), direct preference optimization (DPO), and group relative policy optimization (GRPO). ReAgent-V is lightweight, modular, and extensible, supporting flexible tool integration tailored to diverse tasks. Extensive experiments on 12 datasets across three core applications-video understanding, video reasoning enhancement, and vision-language-action model alignment-demonstrate significant gains in generalization and reasoning, with improvements of up to 6.9%, 2.1%, and 9.8%, respectively, highlighting the effectiveness and versatility of the proposed framework.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "31 pages, 18 figures", "pdf_url": "https://arxiv.org/pdf/2506.01300.pdf", "abstract_url": "https://arxiv.org/abs/2506.01300", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "ReAgent-V是一个奖励驱动的多智能体框架，旨在通过高效的帧选择和实时奖励生成提升视频理解能力，支持迭代答案细化和高质量数据自动过滤。", "motivation": "解决早期基于大型视觉语言模型的视频理解方法在复杂场景中自我纠正和适应能力有限的问题，以及现有方法面临的高标注成本、奖励信号无法捕捉实时推理状态和推理效率低的挑战。", "method": "提出ReAgent-V框架，整合高效的帧选择与实时奖励生成，通过多视角反思机制迭代细化答案，并支持监督微调（SFT）、直接偏好优化（DPO）和群体相对策略优化（GRPO）。", "result": "在12个数据集上的广泛实验显示，在视频理解、视频推理增强和视觉-语言-动作模型对齐三个核心应用上，分别实现了高达6.9%、2.1%和9.8%的改进。", "conclusion": "ReAgent-V框架在提升视频理解的泛化能力和推理效率方面表现出色，其轻量级、模块化和可扩展的设计使其能够灵活适应多样化任务。"}}
{"id": "2506.00421", "title": "Enabling Chatbots with Eyes and Ears: An Immersive Multimodal Conversation System for Dynamic Interactions", "authors": ["Jihyoung Jang", "Minwook Bae", "Minji Kim", "Dilek Hakkani-Tur", "Hyounghun Kim"], "abstract": "As chatbots continue to evolve toward human-like, real-world, interactions, multimodality remains an active area of research and exploration. So far, efforts to integrate multimodality into chatbots have primarily focused on image-centric tasks, such as visual dialogue and image-based instructions, placing emphasis on the \"eyes\" of human perception while neglecting the \"ears\", namely auditory aspects. Moreover, these studies often center around static interactions that focus on discussing the modality rather than naturally incorporating it into the conversation, which limits the richness of simultaneous, dynamic engagement. Furthermore, while multimodality has been explored in multi-party and multi-session conversations, task-specific constraints have hindered its seamless integration into dynamic, natural conversations. To address these challenges, this study aims to equip chatbots with \"eyes and ears\" capable of more immersive interactions with humans. As part of this effort, we introduce a new multimodal conversation dataset, Multimodal Multi-Session Multi-Party Conversation ($M^3C$), and propose a novel multimodal conversation model featuring multimodal memory retrieval. Our model, trained on the $M^3C$, demonstrates the ability to seamlessly engage in long-term conversations with multiple speakers in complex, real-world-like settings, effectively processing visual and auditory inputs to understand and respond appropriately. Human evaluations highlight the model's strong performance in maintaining coherent and dynamic interactions, demonstrating its potential for advanced multimodal conversational agents.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2506.00421.pdf", "abstract_url": "https://arxiv.org/abs/2506.00421", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一种新型的多模态对话系统，旨在通过赋予聊天机器人“眼睛和耳朵”来实现更沉浸式的人机交互。研究提出了一个多模态多会话多方对话数据集（$M^3C$）和一个新颖的多模态对话模型，该模型能够处理视觉和听觉输入，以在复杂的现实世界环境中与多个说话者进行长期对话。", "motivation": "当前的多模态聊天机器人研究主要集中在以图像为中心的任务上，忽视了听觉方面，且多围绕静态交互，限制了动态参与的丰富性。本研究旨在解决这些限制，使聊天机器人能够更自然地融入多模态对话。", "method": "研究引入了$M^3C$数据集，并提出了一个具有多模态记忆检索功能的多模态对话模型。该模型在$M^3C$上训练，能够处理视觉和听觉输入，以理解和适当响应。", "result": "人类评估显示，该模型在维持连贯和动态交互方面表现出色，展示了其在先进多模态对话代理中的潜力。", "conclusion": "本研究通过引入新的数据集和模型，推动了多模态聊天机器人的发展，使其能够更自然、沉浸式地与人类进行交互，为未来的多模态对话系统研究提供了新的方向。"}}
{"id": "2506.01056", "title": "MCP-Zero: Proactive Toolchain Construction for LLM Agents from Scratch", "authors": ["Xiang Fei", "Xiawu Zheng", "Hao Feng"], "abstract": "Function-calling has enabled large language models (LLMs) to act as tool-using agents, but injecting thousands of tool schemas into the prompt is costly and error-prone. We introduce MCP-Zero, a proactive agent framework that lets the LLM itself decide when and which external tools to retrieve, thereby assembling a task-specific toolchain from scratch. The framework is built upon three components: (1) Proactive Tool Request, where the model emits a structured $\\left<\\operatorname{tool\\_assistant}\\right>$ block that explicitly specifies the desired server and task; (2) Hierarchical Vector Routing, a coarse-to-fine retrieval algorithm that first selects candidate servers and then ranks tools within each server based on the semantic similarity; (3) Iterative Proactive Invocation, enabling multi-round, cross-domain toolchain construction with minimal context overhead, and allowing the model to iteratively revise its request when the returned tools are insufficient. To evaluate our approach we also compile MCP-tools, a retrieval dataset comprising 308 MCP servers and 2,797 tools extracted from the official Model-Context-Protocol repository and normalized into a unified JSON schema. Experiments show that MCP-Zero (i) effectively addresses the context overhead problem of existing methods and accurately selects the correct tool from a pool of nearly 3,000 candidates (248.1k tokens); (ii) reduces token consumption by 98\\% on the APIbank while maintaining high accuracy; and (iii) supports multi-turn tool invocation with consistent accuracy across rounds. The code and dataset will be released soon.", "subjects": "Artificial Intelligence (cs.AI); Software Engineering (cs.SE)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.01056.pdf", "abstract_url": "https://arxiv.org/abs/2506.01056", "categories": ["Artificial Intelligence (cs.AI)", "Software Engineering (cs.SE)"], "matching_keywords": ["agent"], "AI": {"tldr": "MCP-Zero是一个主动的LLM代理框架，允许LLM自行决定何时及检索哪些外部工具，从而从零开始组装任务特定的工具链。该框架通过三个组件实现：主动工具请求、分层向量路由和迭代主动调用，有效解决了现有方法的上下文开销问题，并在大量工具候选者中准确选择工具，同时大幅减少令牌消耗。", "motivation": "解决大型语言模型（LLMs）作为工具使用代理时，将数千种工具模式注入提示中的成本高和易出错的问题。", "method": "MCP-Zero框架包括三个主要组件：主动工具请求、分层向量路由和迭代主动调用，通过这些组件实现任务特定工具链的从零构建。", "result": "MCP-Zero有效解决了现有方法的上下文开销问题，准确从近3,000个候选工具中选择正确工具，减少APIbank上的令牌消耗98%，并支持多轮工具调用，保持跨轮次的一致准确性。", "conclusion": "MCP-Zero为LLM代理提供了一种高效、准确的方法来构建和使用工具链，显著降低了令牌消耗，同时保持了高准确性和跨轮次的一致性，具有重要的实际应用价值。"}}
{"id": "2506.01080", "title": "The Coming Crisis of Multi-Agent Misalignment: AI Alignment Must Be a Dynamic and Social Process", "authors": ["Florian Carichon", "Aditi Khandelwal", "Marylou Fauchard", "Golnoosh Farnadi"], "abstract": "This position paper states that AI Alignment in Multi-Agent Systems (MAS) should be considered a dynamic and interaction-dependent process that heavily depends on the social environment where agents are deployed, either collaborative, cooperative, or competitive. While AI alignment with human values and preferences remains a core challenge, the growing prevalence of MAS in real-world applications introduces a new dynamic that reshapes how agents pursue goals and interact to accomplish various tasks. As agents engage with one another, they must coordinate to accomplish both individual and collective goals. However, this complex social organization may unintentionally misalign some or all of these agents with human values or user preferences. Drawing on social sciences, we analyze how social structure can deter or shatter group and individual values. Based on these analyses, we call on the AI community to treat human, preferential, and objective alignment as an interdependent concept, rather than isolated problems. Finally, we emphasize the urgent need for simulation environments, benchmarks, and evaluation frameworks that allow researchers to assess alignment in these interactive multi-agent contexts before such dynamics grow too complex to control.", "subjects": "Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "comments": "Preprint of NeurIPS 2025 Position Paper", "pdf_url": "https://arxiv.org/pdf/2506.01080.pdf", "abstract_url": "https://arxiv.org/abs/2506.01080", "categories": ["Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出在多智能体系统（MAS）中，AI对齐应被视为一个动态且依赖于互动的过程，这一过程深受智能体部署的社会环境影响。随着MAS在现实世界应用中的增长，智能体之间的互动重塑了它们追求目标和完成任务的方式，可能导致与人类价值观或用户偏好的无意错位。文章呼吁AI社区将人类、偏好和目标对齐视为相互依赖的概念，而非孤立问题，并强调了开发模拟环境、基准和评估框架的紧迫性。", "motivation": "解决在多智能体系统中，由于复杂的社会互动和结构，可能导致智能体与人类价值观或用户偏好错位的问题。", "method": "借鉴社会科学，分析社会结构如何影响群体和个体价值观，并提出将AI对齐视为动态和社交过程的观点。", "result": "指出在多智能体系统中，AI对齐是一个动态、互动依赖的过程，需要新的模拟环境、基准和评估框架来评估对齐情况。", "conclusion": "强调在多智能体系统中实现AI对齐的复杂性，呼吁开发新工具和方法来应对这一挑战，以防止未来控制难度增加。"}}
{"id": "2506.01095", "title": "Modular Speaker Architecture: A Framework for Sustaining Responsibility and Contextual Integrity in Multi-Agent AI Communication", "authors": ["Khe-Han Toh", "Hong-Kuan Teo"], "abstract": "Sustaining coherent, role-aware communication across multi-agent systems remains a foundational challenge in AI. Current frameworks often lack explicit mechanisms for speaker responsibility, leading to context drift, alignment instability, and degraded interpretability over time. We propose the Modular Speaker Architecture (MSA), a framework that decomposes speaker behavior into modular components for role tracking, responsibility continuity, and contextual coherence. Grounded in high-context human-AI dialogues, MSA includes three core modules: a Speaker Role Module, a Responsibility Chain Tracker, and a Contextual Integrity Validator. We evaluate MSA through annotated case studies and introduce structural metrics-pragmatic consistency, responsibility flow, and context stability-quantified via manual and automatic scoring and bootstrapped statistical analysis. Our results show that MSA reliably maintains interaction structure without reliance on affective signals or surface-level heuristics. We further implement a prototype configuration language (G-Code) and modular API to support MSA deployment in dynamic multi-agent scenarios.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.01095.pdf", "abstract_url": "https://arxiv.org/abs/2506.01095", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了模块化说话者架构（MSA），一个旨在解决多智能体系统中角色感知通信连贯性问题的框架。MSA通过分解说话者行为为角色追踪、责任连续性和上下文连贯性模块，提高了通信的稳定性和可解释性。", "motivation": "当前的多智能体系统框架缺乏明确的说话者责任机制，导致上下文漂移、对齐不稳定和随时间推移的可解释性下降。", "method": "MSA框架包含三个核心模块：说话者角色模块、责任链追踪器和上下文完整性验证器。通过高上下文人机对话的基础，MSA评估包括实用一致性、责任流和上下文稳定性等结构指标。", "result": "结果显示，MSA无需依赖情感信号或表面启发式方法，即可可靠地维持交互结构。", "conclusion": "MSA及其原型配置语言（G-Code）和模块化API支持动态多智能体场景中的部署，为维持责任和上下文完整性提供了有效框架。"}}
{"id": "2506.01174", "title": "GraphPad: Inference-Time 3D Scene Graph Updates for Embodied Question Answering", "authors": ["Muhammad Qasim Ali", "Saeejith Nair", "Alexander Wong", "Yuchen Cui", "Yuhao Chen"], "abstract": "Structured scene representations are a core component of embodied agents, helping to consolidate raw sensory streams into readable, modular, and searchable formats. Due to their high computational overhead, many approaches build such representations in advance of the task. However, when the task specifications change, such static approaches become inadequate as they may miss key objects, spatial relations, and details. We introduce GraphPad, a modifiable structured memory that an agent can tailor to the needs of the task through API calls. It comprises a mutable scene graph representing the environment, a navigation log indexing frame-by-frame content, and a scratchpad for task-specific notes. Together, GraphPad serves as a dynamic workspace that remains complete, current, and aligned with the agent's immediate understanding of the scene and its task. On the OpenEQA benchmark, GraphPad attains 55.3%, a +3.0% increase over an image-only baseline using the same vision-language model, while operating with five times fewer input frames. These results show that allowing online, language-driven refinement of 3-D memory yields more informative representations without extra training or data collection.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "CVPR 2025 Workshop on 3D-LLM/VLA: Bridging Language, Vision and Action in 3D Environments", "pdf_url": "https://arxiv.org/pdf/2506.01174.pdf", "abstract_url": "https://arxiv.org/abs/2506.01174", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "GraphPad是一种可修改的结构化记忆，通过API调用使代理能够根据任务需求定制，包括可变场景图、导航日志和任务特定便签，作为动态工作区保持完整、最新并与代理对场景和任务的即时理解一致。在OpenEQA基准测试中，GraphPad达到了55.3%，比仅使用图像的基线提高了3.0%，同时使用的输入帧数减少了五倍。", "motivation": "解决在任务规格变化时，静态场景表示方法可能遗漏关键对象、空间关系和细节的问题。", "method": "引入GraphPad，一个包含可变场景图、导航日志和任务特定便签的可修改结构化记忆，通过API调用使代理能够根据任务需求定制。", "result": "在OpenEQA基准测试中，GraphPad比仅使用图像的基线提高了3.0%的性能，同时使用的输入帧数减少了五倍。", "conclusion": "允许在线、语言驱动的3D记忆细化可以产生更具信息量的表示，而无需额外的训练或数据收集。"}}
{"id": "2506.01199", "title": "Test Automation for Interactive Scenarios via Promptable Traffic Simulation", "authors": ["Augusto Mondelli", "Yueshan Li", "Alessandro Zanardi", "Emilio Frazzoli"], "abstract": "Autonomous vehicle (AV) planners must undergo rigorous evaluation before widespread deployment on public roads, particularly to assess their robustness against the uncertainty of human behaviors. While recent advancements in data-driven scenario generation enable the simulation of realistic human behaviors in interactive settings, leveraging these models to construct comprehensive tests for AV planners remains an open challenge. In this work, we introduce an automated method to efficiently generate realistic and safety-critical human behaviors for AV planner evaluation in interactive scenarios. We parameterize complex human behaviors using low-dimensional goal positions, which are then fed into a promptable traffic simulator, ProSim, to guide the behaviors of simulated agents. To automate test generation, we introduce a prompt generation module that explores the goal domain and efficiently identifies safety-critical behaviors using Bayesian optimization. We apply our method to the evaluation of an optimization-based planner and demonstrate its effectiveness and efficiency in automatically generating diverse and realistic driving behaviors across scenarios with varying initial conditions.", "subjects": "Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": "Accepted by CVPR 2025 Workshop Data-Driven Autonomous Driving Simulation (track 1)", "pdf_url": "https://arxiv.org/pdf/2506.01199.pdf", "abstract_url": "https://arxiv.org/abs/2506.01199", "categories": ["Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一种自动化方法，用于在交互式场景中高效生成现实且安全关键的人类行为，以评估自动驾驶车辆规划器的性能。通过使用低维目标位置参数化复杂人类行为，并利用可提示交通模拟器ProSim指导模拟代理的行为，结合贝叶斯优化自动识别安全关键行为，该方法在多样化场景中有效生成了现实驾驶行为。", "motivation": "自动驾驶车辆规划器在广泛部署前需经过严格评估，尤其是在评估其对人类行为不确定性的鲁棒性方面。尽管数据驱动场景生成的最新进展能够在交互设置中模拟现实人类行为，但利用这些模型构建全面的自动驾驶规划器测试仍是一个开放挑战。", "method": "本文提出了一种自动化方法，通过低维目标位置参数化复杂人类行为，并利用可提示交通模拟器ProSim指导模拟代理的行为。为了自动化测试生成，引入了一个提示生成模块，该模块探索目标域并使用贝叶斯优化高效识别安全关键行为。", "result": "应用于基于优化的规划器评估，该方法在不同初始条件的场景中自动生成了多样化和现实的驾驶行为，证明了其有效性和效率。", "conclusion": "本文提出的方法能够高效生成现实且安全关键的人类行为，为自动驾驶车辆规划器的评估提供了一种有效的自动化测试生成方法，有助于提高规划器对人类行为不确定性的鲁棒性。"}}
{"id": "2506.00509", "title": "Goal-Aware Identification and Rectification of Misinformation in Multi-Agent Systems", "authors": ["Zherui Li", "Yan Mi", "Zhenhong Zhou", "Houcheng Jiang", "Guibin Zhang", "Kun Wang", "Junfeng Fang"], "abstract": "Large Language Model-based Multi-Agent Systems (MASs) have demonstrated strong advantages in addressing complex real-world tasks. However, due to the introduction of additional attack surfaces, MASs are particularly vulnerable to misinformation injection. To facilitate a deeper understanding of misinformation propagation dynamics within these systems, we introduce MisinfoTask, a novel dataset featuring complex, realistic tasks designed to evaluate MAS robustness against such threats. Building upon this, we propose ARGUS, a two-stage, training-free defense framework leveraging goal-aware reasoning for precise misinformation rectification within information flows. Our experiments demonstrate that in challenging misinformation scenarios, ARGUS exhibits significant efficacy across various injection attacks, achieving an average reduction in misinformation toxicity of approximately 28.17% and improving task success rates under attack by approximately 10.33%. Our code and dataset is available at:", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.00509.pdf", "abstract_url": "https://arxiv.org/abs/2506.00509", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了MisinfoTask数据集和ARGUS防御框架，旨在评估和提升多代理系统对抗错误信息注入的能力。ARGUS通过目标感知推理，在错误信息传播中实现精确纠正，实验显示其能显著降低错误信息的毒性并提高任务成功率。", "motivation": "多代理系统在处理复杂现实世界任务时表现出强大优势，但由于引入了额外的攻击面，特别容易受到错误信息注入的影响。本文旨在深入理解这些系统中错误信息传播的动态，并提出有效的防御机制。", "method": "本文提出了MisinfoTask数据集来评估多代理系统的鲁棒性，并设计了ARGUS，一个两阶段的、无需训练的防御框架，利用目标感知推理在信息流中进行精确的错误信息纠正。", "result": "实验结果表明，在具有挑战性的错误信息场景中，ARGUS对各种注入攻击表现出显著的效果，平均减少错误信息毒性约28.17%，并在攻击下提高任务成功率约10.33%。", "conclusion": "ARGUS框架为多代理系统提供了一种有效的错误信息防御机制，通过目标感知推理实现了错误信息的精确纠正，显著提升了系统在面临错误信息攻击时的鲁棒性和任务成功率。"}}
{"id": "2506.00539", "title": "ARIA: Training Language Agents with Intention-Driven Reward Aggregation", "authors": ["Ruihan Yang", "Yikai Zhang", "Aili Chen", "Xintao Wang", "Siyu Yuan", "Jiangjie Chen", "Deqing Yang", "Yanghua Xiao"], "abstract": "Large language models (LLMs) have enabled agents to perform complex reasoning and decision-making through free-form language interactions. However, in open-ended language action environments (e.g., negotiation or question-asking games), the action space can be formulated as a joint distribution over tokens, resulting in an exponentially large action space. Sampling actions in such a space can lead to extreme reward sparsity, which brings large reward variance, hindering effective reinforcement learning (RL). To address this, we propose ARIA, a method that Aggregates Rewards in Intention space to enable efficient and effective language Agents training. ARIA aims to project natural language actions from the high-dimensional joint token distribution space into a low-dimensional intention space, where semantically similar actions are clustered and assigned shared rewards. This intention-aware reward aggregation reduces reward variance by densifying reward signals, fostering better policy optimization. Extensive experiments demonstrate that ARIA not only significantly reduces policy gradient variance, but also delivers substantial performance gains of an average of 9.95% across four downstream tasks, consistently outperforming offline and online RL baselines.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.00539.pdf", "abstract_url": "https://arxiv.org/abs/2506.00539", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出ARIA方法，通过在意图空间聚合奖励来高效训练语言代理，解决了开放端语言动作环境中动作空间大导致的奖励稀疏问题。", "motivation": "解决在开放端语言动作环境中，由于动作空间大导致的奖励稀疏和方差大的问题，从而阻碍有效的强化学习。", "method": "提出ARIA方法，将自然语言动作从高维联合令牌分布空间投影到低维意图空间，聚类语义相似的动作并分配共享奖励。", "result": "ARIA不仅显著降低了策略梯度方差，还在四个下游任务中平均性能提升了9.95%， consistently优于离线和在线RL基线。", "conclusion": "ARIA通过意图感知的奖励聚合，有效减少了奖励方差，促进了更好的策略优化，为语言代理的训练提供了高效和有效的方法。"}}
{"id": "2506.00527", "title": "Retrieval-Augmented Generation Systems for Intellectual Property via Synthetic Multi-Angle Fine-tuning", "authors": ["Runtao Ren", "Jian Ma", "Jianxi Luo"], "abstract": "Retrieval-Augmented Generation (RAG) systems in the Intellectual Property (IP) field often struggle with diverse user queries, including colloquial expressions, spelling errors, and ambiguous terminology, leading to inaccurate retrieval and suboptimal responses. To address this challenge, we propose Multi-Angle Question Generation and Retrieval Fine-Tuning Method (MQG-RFM), a novel framework that leverages large language models (LLMs) to simulate varied user inquiries and fine-tunes retrieval models to align semantically equivalent but linguistically diverse questions. Unlike complex architectural modifications, MQG-RFM adopts a lightweight Data-to-Tune paradigm, combining prompt-engineered query generation with hard negative mining to enhance retrieval robustness without costly infrastructure changes. Experimental results on a Taiwan patent Q&A dataset show 185.62% improvement in retrieval accuracy on the Patent Consultation dataset and 262.26% improvement on the Novel Patent Technology Report dataset, with 14.22% and 53.58% improvements in generation quality over the baselines, respectively. By bridging the gap between user intent and system comprehension through semantic-aware retrieval optimization, MQG-RFM offers a practical, scalable approach for rapid, cost-effective deployment among small and medium-sized agencies seeking reliable patent intelligence solutions. Additionally, our proposed method has already been adopted by ScholarMate, the largest professional research social networking platform in China, to support real-world development and deployment. A demo version of the instantiated is available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.00527.pdf", "abstract_url": "https://arxiv.org/abs/2506.00527", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种名为MQG-RFM的新框架，通过多角度问题生成和检索微调方法，利用大型语言模型模拟多样化的用户查询，并微调检索模型以对齐语义相同但语言多样的问题，从而提高了检索增强生成系统在知识产权领域的性能。", "motivation": "知识产权领域的检索增强生成系统在处理多样化的用户查询时，常常因为口语表达、拼写错误和模糊术语而导致检索不准确和响应不佳。", "method": "MQG-RFM采用了一种轻量级的Data-to-Tune范式，结合了提示工程的查询生成和硬负例挖掘，以增强检索的鲁棒性，而无需进行昂贵的基础设施更改。", "result": "在台湾专利问答数据集上的实验结果显示，检索准确性在专利咨询数据集上提高了185.62%，在新专利技术报告数据集上提高了262.26%，生成质量分别比基线提高了14.22%和53.58%。", "conclusion": "MQG-RFM通过语义感知的检索优化，弥合了用户意图和系统理解之间的差距，为中小型机构提供了一种实用、可扩展的方法，以实现快速、成本效益高的专利智能解决方案部署。"}}
{"id": "2506.00549", "title": "Towards Multi-dimensional Evaluation of LLM Summarization across Domains and Languages", "authors": ["Hyangsuk Min", "Yuho Lee", "Minjeong Ban", "Jiaqi Deng", "Nicole Hee-Yeon Kim", "Taewon Yun", "Hang Su", "Jason Cai", "Hwanjun Song"], "abstract": "Evaluation frameworks for text summarization have evolved in terms of both domain coverage and metrics. However, existing benchmarks still lack domain-specific assessment criteria, remain predominantly English-centric, and face challenges with human annotation due to the complexity of reasoning. To address these, we introduce MSumBench, which provides a multi-dimensional, multi-domain evaluation of summarization in English and Chinese. It also incorporates specialized assessment criteria for each domain and leverages a multi-agent debate system to enhance annotation quality. By evaluating eight modern summarization models, we discover distinct performance patterns across domains and languages. We further examine large language models as summary evaluators, analyzing the correlation between their evaluation and summarization capabilities, and uncovering systematic bias in their assessment of self-generated summaries. Our benchmark dataset is publicly available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "34 pages, 6 figures", "pdf_url": "https://arxiv.org/pdf/2506.00549.pdf", "abstract_url": "https://arxiv.org/abs/2506.00549", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了MSumBench，一个多维度、多领域的文本摘要评估框架，旨在解决现有评估基准在领域特定评估标准、语言多样性及人工标注质量方面的不足。通过评估八种现代摘要模型，发现了跨领域和语言的性能差异，并探讨了大型语言模型作为摘要评估者的潜力及其存在的系统性偏差。", "motivation": "解决现有文本摘要评估框架在领域特定评估标准、语言多样性（主要集中于英语）及人工标注质量方面的不足。", "method": "引入MSumBench，一个多维度、多领域的评估框架，包含英语和中文的摘要评估，采用特定领域的评估标准，并利用多代理辩论系统提高标注质量。", "result": "发现不同摘要模型在跨领域和语言中的性能存在显著差异，大型语言模型作为摘要评估者时，其评估能力与摘要能力之间存在相关性，且在评估自身生成的摘要时存在系统性偏差。", "conclusion": "MSumBench为文本摘要提供了一个更全面、多语言的评估框架，揭示了大型语言模型在摘要评估中的潜力与局限，为未来研究提供了新的方向和工具。"}}
{"id": "2506.00551", "title": "AnnaAgent: Dynamic Evolution Agent System with Multi-Session Memory for Realistic Seeker Simulation", "authors": ["Ming Wang", "Peidong Wang", "Lin Wu", "Xiaocui Yang", "Daling Wang", "Shi Feng", "Yuxin Chen", "Bixuan Wang", "Yifei Zhang"], "abstract": "Constrained by the cost and ethical concerns of involving real seekers in AI-driven mental health, researchers develop LLM-based conversational agents (CAs) with tailored configurations, such as profiles, symptoms, and scenarios, to simulate seekers. While these efforts advance AI in mental health, achieving more realistic seeker simulation remains hindered by two key challenges: dynamic evolution and multi-session memory. Seekers' mental states often fluctuate during counseling, which typically spans multiple sessions. To address this, we propose AnnaAgent, an emotional and cognitive dynamic agent system equipped with tertiary memory. AnnaAgent incorporates an emotion modulator and a complaint elicitor trained on real counseling dialogues, enabling dynamic control of the simulator's configurations. Additionally, its tertiary memory mechanism effectively integrates short-term and long-term memory across sessions. Evaluation results, both automated and manual, demonstrate that AnnaAgent achieves more realistic seeker simulation in psychological counseling compared to existing baselines. The ethically reviewed and screened code can be found on", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.00551.pdf", "abstract_url": "https://arxiv.org/abs/2506.00551", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "AnnaAgent是一个动态演化的情感和认知代理系统，配备了三重记忆机制，用于在心理咨询中模拟更真实的求助者。", "motivation": "由于成本和伦理问题，研究人员开发了基于大型语言模型的对话代理来模拟心理咨询中的求助者，但如何实现更真实的模拟仍面临动态演化和多会话记忆两大挑战。", "method": "AnnaAgent通过情感调制器和抱怨引发器（基于真实心理咨询对话训练）动态控制模拟器的配置，并采用三重记忆机制整合跨会话的短期和长期记忆。", "result": "自动和人工评估结果表明，AnnaAgent在心理咨询中比现有基线实现了更真实的求助者模拟。", "conclusion": "AnnaAgent通过动态演化和多会话记忆机制，为AI在心理健康领域的应用提供了更真实的求助者模拟解决方案。"}}
{"id": "2506.00608", "title": "PAKTON: A Multi-Agent Framework for Question Answering in Long Legal Agreements", "authors": ["Petros Raptopoulos", "Giorgos Filandrianos", "Maria Lymperaiou", "Giorgos Stamou"], "abstract": "Contract review is a complex and time-intensive task that typically demands specialized legal expertise, rendering it largely inaccessible to non-experts. Moreover, legal interpretation is rarely straightforward-ambiguity is pervasive, and judgments often hinge on subjective assessments. Compounding these challenges, contracts are usually confidential, restricting their use with proprietary models and necessitating reliance on open-source alternatives. To address these challenges, we introduce PAKTON: a fully open-source, end-to-end, multi-agent framework with plug-and-play capabilities. PAKTON is designed to handle the complexities of contract analysis through collaborative agent workflows and a novel retrieval-augmented generation (RAG) component, enabling automated legal document review that is more accessible, adaptable, and privacy-preserving. Experiments demonstrate that PAKTON outperforms both general-purpose and pretrained models in predictive accuracy, retrieval performance, explainability, completeness, and grounded justifications as evaluated through a human study and validated with automated metrics.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.00608.pdf", "abstract_url": "https://arxiv.org/abs/2506.00608", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "PAKTON是一个完全开源、端到端、多代理框架，旨在通过协作代理工作流程和新颖的检索增强生成（RAG）组件，处理合同分析的复杂性，使自动化法律文件审查更加可访问、适应性强且保护隐私。", "motivation": "合同审查是一项复杂且耗时的任务，通常需要专业的法律知识，这使得非专业人士难以接触。此外，法律解释很少是直接的——歧义普遍存在，判断往往依赖于主观评估。加之合同通常是保密的，限制了其与专有模型的使用，需要依赖开源替代品。", "method": "引入PAKTON框架，采用多代理协作工作流程和检索增强生成（RAG）技术，以实现自动化法律文件审查。", "result": "实验表明，PAKTON在预测准确性、检索性能、可解释性、完整性和基于人类研究和自动化指标验证的合理解释方面，优于通用和预训练模型。", "conclusion": "PAKTON框架为解决合同分析的复杂性和提高法律文件审查的可访问性、适应性和隐私保护提供了一种有效的解决方案。"}}
{"id": "2506.01268", "title": "CleanS2S: Single-file Framework for Proactive Speech-to-Speech Interaction", "authors": ["Yudong Lu", "Yazhe Niu", "Shuai Hu", "Haolin Wang"], "abstract": "CleanS2S is a framework for human-like speech-to-speech interaction that advances conversational AI through single-file implementation and proactive dialogue capabilities. Our system integrates automatic speech recognition, large language models, and text-to-speech synthesis into a unified pipeline with real-time interruption handling, achieving low transition latency through full-duplex websocket connections and non-blocking I/O. Beyond conventional chatbot paradigms, we pioneer a proactive interaction mechanism, which combines memory systems with Subjective Action Judgement module, enabling five human-like response strategies: interruption, refusal, deflection, silence, and standard response. The memory module dynamically aggregates historical, and contextual data to inform interaction decisions. This approach breaks the rigid turn-based convention by allowing system-initiated dialog control and context-aware response selection. And we propose Action Judgement SFT that assesses input streams for responses strategies. The framework's single-file implementation with atomic configurations offers researchers unprecedented transparency and extensibility for interaction agents. The code of CleanS2S is released at \\", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.01268.pdf", "abstract_url": "https://arxiv.org/abs/2506.01268", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "CleanS2S是一个用于实现类人语音到语音交互的框架，通过单文件实现和主动对话能力推进对话AI的发展。该系统集成了自动语音识别、大型语言模型和文本到语音合成，通过全双工websocket连接和非阻塞I/O实现低延迟转换。", "motivation": "解决传统聊天机器人范式中的僵化轮转对话问题，实现更自然、灵活的语音交互。", "method": "采用单文件实现，集成自动语音识别、大型语言模型和文本到语音合成技术，引入主动交互机制和记忆系统，结合主观行动判断模块，实现五种类人响应策略。", "result": "开发了一个低延迟、支持实时中断处理的语音到语音交互框架，能够进行系统发起的对话控制和上下文感知的响应选择。", "conclusion": "CleanS2S框架通过其单文件实现和主动交互机制，为交互式代理提供了前所未有的透明度和可扩展性，推动了对话AI的发展。"}}
{"id": "2506.01273", "title": "RAISE: Reasoning Agent for Interactive SQL Exploration", "authors": ["Fernando Granado", "Roberto Lotufo", "Jayr Pereira"], "abstract": "Recent advances in large language models (LLMs) have propelled research in natural language interfaces to databases. However, most state-of-the-art text-to-SQL systems still depend on complex, multi-stage pipelines. This work proposes a novel agentic framework that unifies schema linking, query generation, and iterative refinement within a single, end-to-end component. By leveraging the intrinsic reasoning abilities of LLMs, our method emulates how humans answer questions when working with unfamiliar databases: understanding the data by formulating hypotheses, running dynamic queries to validate them, reasoning over the results, and revising outputs based on observed results. Crucially, our approach introduces a new strategy for scaling test-time computation in text-to-SQL: we scale the depth of interactive database exploration and reflection. This shift enables the model to allocate computation dynamically to better understand the data, especially useful in ambiguous and underspecified scenarios. Our experiments show that it improved the Execution Accuracy (EX) from 44.8% to 56.5% on the challenging BIRD dataset using DeepSeek-R1-Distill-Llama-70B. Furthermore, when equipped with steps to add more diversity to the answers, our agent achieves a Best-of-N accuracy of 81.8% with 8 rounds of candidate generation, rivaling the 82.79% achieved by the top-ranked published solution, while reducing engineering complexity. These findings position our unified framework as a promising alternative for building natural language interfaces to databases.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.01273.pdf", "abstract_url": "https://arxiv.org/abs/2506.01273", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种新颖的代理框架RAISE，用于交互式SQL探索，通过利用大型语言模型的内在推理能力，统一了模式链接、查询生成和迭代细化，提高了文本到SQL系统的执行准确性。", "motivation": "解决当前文本到SQL系统依赖复杂多阶段管道的问题，通过模拟人类与不熟悉数据库交互的方式，提高系统的理解和响应能力。", "method": "采用代理框架，结合大型语言模型的推理能力，实现端到端的模式链接、查询生成和迭代细化，动态分配计算资源以深入理解数据。", "result": "在BIRD数据集上，执行准确率从44.8%提高到56.5%，最佳候选生成轮次达到81.8%的准确率，接近顶级解决方案的82.79%。", "conclusion": "统一的代理框架为构建自然语言数据库接口提供了有前景的替代方案，同时降低了工程复杂度。"}}
{"id": "2506.01332", "title": "An Empirical Study of Group Conformity in Multi-Agent Systems", "authors": ["Min Choi", "Keonwoo Kim", "Sungwon Chae", "Sangyeob Baek"], "abstract": "Recent advances in Large Language Models (LLMs) have enabled multi-agent systems that simulate real-world interactions with near-human reasoning. While previous studies have extensively examined biases related to protected attributes such as race, the emergence and propagation of biases on socially contentious issues in multi-agent LLM interactions remain underexplored. This study explores how LLM agents shape public opinion through debates on five contentious topics. By simulating over 2,500 debates, we analyze how initially neutral agents, assigned a centrist disposition, adopt specific stances over time. Statistical analyses reveal significant group conformity mirroring human behavior; LLM agents tend to align with numerically dominant groups or more intelligent agents, exerting a greater influence. These findings underscore the crucial role of agent intelligence in shaping discourse and highlight the risks of bias amplification in online interactions. Our results emphasize the need for policy measures that promote diversity and transparency in LLM-generated discussions to mitigate the risks of bias propagation within anonymous online environments.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.01332.pdf", "abstract_url": "https://arxiv.org/abs/2506.01332", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "对大型语言模型（LLMs）在多智能体系统中模拟现实世界互动的最新进展进行了实证研究，探讨了在社会争议话题上偏见的出现和传播。", "motivation": "解决多智能体LLM互动中在社会争议问题上偏见的出现和传播问题，这一问题先前研究不足。", "method": "通过在五个争议话题上模拟超过2,500场辩论，分析最初中立的智能体如何随时间采取特定立场。", "result": "统计分析显示，LLM智能体倾向于与数量上占优势的群体或更智能的智能体保持一致，这些智能体产生更大的影响，这种现象显著反映了人类行为的群体一致性。", "conclusion": "研究结果强调了智能体智能在塑造话语中的关键作用，以及在线互动中偏见放大的风险，强调了需要政策措施来促进LLM生成讨论的多样性和透明度，以减轻匿名在线环境中偏见传播的风险。"}}
{"id": "2506.01423", "title": "FinRobot: Generative Business Process AI Agents for Enterprise Resource Planning in Finance", "authors": ["Hongyang Yang", "Likun Lin", "Yang She", "Xinyu Liao", "Jiaoyang Wang", "Runjia Zhang", "Yuquan Mo", "Christina Dan Wang"], "abstract": "Enterprise Resource Planning (ERP) systems serve as the digital backbone of modern financial institutions, yet they continue to rely on static, rule-based workflows that limit adaptability, scalability, and intelligence. As business operations grow more complex and data-rich, conventional ERP platforms struggle to integrate structured and unstructured data in real time and to accommodate dynamic, cross-functional workflows.", "subjects": "Artificial Intelligence (cs.AI); Software Engineering (cs.SE); General Finance (q-fin.GN)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.01423.pdf", "abstract_url": "https://arxiv.org/abs/2506.01423", "categories": ["Artificial Intelligence (cs.AI)", "Software Engineering (cs.SE)", "General Finance (q-fin.GN)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了FinRobot，一种生成式业务流程AI代理，旨在解决现代金融机构中企业资源规划(ERP)系统的静态、基于规则的工作流限制问题。", "motivation": "随着业务操作变得更加复杂和数据丰富，传统的ERP平台难以实时整合结构化和非结构化数据，以及适应动态的跨功能工作流。", "method": "提出使用生成式业务流程AI代理来增强ERP系统，以提高其适应性、可扩展性和智能性。", "result": "FinRobot旨在通过AI技术改善ERP系统，使其能够更好地处理复杂的业务操作和数据整合。", "conclusion": "FinRobot的引入预示着ERP系统在金融领域的未来发展方向，即通过AI技术实现更高水平的自动化和智能化。"}}
{"id": "2506.00634", "title": "Social Construction of Urban Space: Understanding Neighborhood Boundaries Using Rental Listings", "authors": ["Adam Visokay", "Ruth Bagley", "Ian Kennedy", "Chris Hess", "Kyle Crowder", "Rob Voigt", "Denis Peskoff"], "abstract": "Rental listings offer a unique window into how urban space is socially constructed through language. We analyze Chicago Craigslist rental advertisements from 2018 to 2024 to examine how listing agents characterize neighborhoods, identifying mismatches between institutional boundaries and neighborhood claims. Through manual and large language model annotation, we classify unstructured listings from Craigslist according to their neighborhood. Geospatial analysis reveals three distinct patterns: properties with conflicting neighborhood designations due to competing spatial definitions, border properties with valid claims to adjacent neighborhoods, and ``reputation laundering\" where listings claim association with distant, desirable neighborhoods. Through topic modeling, we identify patterns that correlate with spatial positioning: listings further from neighborhood centers emphasize different amenities than centrally-located units. Our findings demonstrate that natural language processing techniques can reveal how definitions of urban spaces are contested in ways that traditional methods overlook.", "subjects": "Computation and Language (cs.CL)", "comments": "8 pages, 3 figures, 4 tables", "pdf_url": "https://arxiv.org/pdf/2506.00634.pdf", "abstract_url": "https://arxiv.org/abs/2506.00634", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "通过分析芝加哥Craigslist租房广告，研究城市空间如何通过语言被社会构建，揭示机构边界与社区主张之间的不匹配。", "motivation": "探讨租房广告如何反映城市空间的社会构建，以及传统方法可能忽略的城市空间定义争议。", "method": "结合手动和大语言模型标注，对Craigslist的非结构化租房广告进行分类，并进行地理空间分析和主题建模。", "result": "发现三种模式：因空间定义竞争导致的社区名称冲突、对相邻社区有有效主张的边界物业，以及“声誉洗白”现象。远离社区中心的房源强调的便利设施与中心位置的不同。", "conclusion": "自然语言处理技术能揭示城市空间定义中的争议，这些是传统方法所忽视的。"}}
{"id": "2506.01391", "title": "AgentCPM-GUI: Building Mobile-Use Agents with Reinforcement Fine-Tuning", "authors": ["Zhong Zhang", "Yaxi Lu", "Yikun Fu", "Yupeng Huo", "Shenzhi Yang", "Yesai Wu", "Han Si", "Xin Cong", "Haotian Chen", "Yankai Lin", "Jie Xie", "Wei Zhou", "Wang Xu", "Yuanheng Zhang", "Zhou Su", "Zhongwu Zhai", "Xiaoming Liu", "Yudong Mei", "Jianming Xu", "Hongyan Tian", "Chongyi Wang", "Chi Chen", "Yuan Yao", "Zhiyuan Liu", "Maosong Sun"], "abstract": "The recent progress of large language model agents has opened new possibilities for automating tasks through graphical user interfaces (GUIs), especially in mobile environments where intelligent interaction can greatly enhance usability. However, practical deployment of such agents remains constrained by several key challenges. Existing training data is often noisy and lack semantic diversity, which hinders the learning of precise grounding and planning. Models trained purely by imitation tend to overfit to seen interface patterns and fail to generalize in unfamiliar scenarios. Moreover, most prior work focuses on English interfaces while overlooks the growing diversity of non-English applications such as those in the Chinese mobile ecosystem. In this work, we present AgentCPM-GUI, an 8B-parameter GUI agent built for robust and efficient on-device GUI interaction. Our training pipeline includes grounding-aware pre-training to enhance perception, supervised fine-tuning on high-quality Chinese and English trajectories to imitate human-like actions, and reinforcement fine-tuning with GRPO to improve reasoning capability. We also introduce a compact action space that reduces output length and supports low-latency execution on mobile devices. AgentCPM-GUI achieves state-of-the-art performance on five public benchmarks and a new Chinese GUI benchmark called CAGUI, reaching $96.9\\%$ Type-Match and $91.3\\%$ Exact-Match. To facilitate reproducibility and further research, we publicly release all code, model checkpoint, and evaluation data.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2506.01391.pdf", "abstract_url": "https://arxiv.org/abs/2506.01391", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Computer Vision and Pattern Recognition (cs.CV)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "AgentCPM-GUI是一个8B参数的GUI代理，旨在通过强化微调构建移动使用的代理，以解决现有训练数据噪声大、语义多样性不足以及模型泛化能力差的问题，特别是在非英语（如中文）移动生态系统中。", "motivation": "解决在移动环境中通过图形用户界面（GUIs）自动化任务时遇到的挑战，包括训练数据的噪声和语义多样性不足、模型泛化能力差，以及非英语（如中文）应用程序的忽视。", "method": "采用包括接地感知预训练、高质量中英文轨迹的监督微调以及使用GRPO进行强化微调的训练管道，并引入紧凑的动作空间以减少输出长度和支持移动设备上的低延迟执行。", "result": "AgentCPM-GUI在五个公共基准和一个新的中文GUI基准CAGUI上达到了最先进的性能，Type-Match和Exact-Match分别达到了96.9%和91.3%。", "conclusion": "AgentCPM-GUI通过其训练管道和紧凑的动作空间设计，为移动设备上的GUI交互提供了强大而高效的解决方案，同时公开了所有代码、模型检查点和评估数据以促进进一步研究。"}}
{"id": "2506.00671", "title": "DeepRAG: Integrating Hierarchical Reasoning and Process Supervision for Biomedical Multi-Hop QA", "authors": ["Yuelyu Ji", "Hang Zhang", "Shiven Verma", "Hui Ji", "Chun Li", "Yushui Han", "Yanshan Wang"], "abstract": "We propose DeepRAG, a novel framework that integrates DeepSeek hierarchical question decomposition capabilities with RAG Gym unified retrieval-augmented generation optimization using process level supervision. Targeting the challenging MedHopQA biomedical question answering task, DeepRAG systematically decomposes complex queries into precise sub-queries and employs concept level reward signals informed by the UMLS ontology to enhance biomedical accuracy. Preliminary evaluations on the MedHopQA dataset indicate that DeepRAG significantly outperforms baseline models, including standalone DeepSeek and RAG Gym, achieving notable improvements in both Exact Match and concept level accuracy.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.00671.pdf", "abstract_url": "https://arxiv.org/abs/2506.00671", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "DeepRAG是一种新颖的框架，结合了DeepSeek的层次问题分解能力和RAG Gym的统一检索增强生成优化，通过过程级监督来提高生物医学多跳问答的准确性。", "motivation": "解决生物医学领域复杂查询的多跳问答挑战，特别是在MedHopQA任务中，提高问答系统的准确性和效率。", "method": "采用DeepSeek的层次问题分解能力和RAG Gym的统一检索增强生成优化，结合UMLS本体提供的概念级奖励信号，以增强生物医学准确性。", "result": "在MedHopQA数据集上的初步评估显示，DeepRAG显著优于基线模型，包括独立的DeepSeek和RAG Gym，在精确匹配和概念级准确性方面都有显著提升。", "conclusion": "DeepRAG通过整合层次推理和过程监督，为生物医学多跳问答提供了一种有效的解决方案，显著提高了问答系统的性能。"}}
{"id": "2506.01438", "title": "Distinguishing Autonomous AI Agents from Collaborative Agentic Systems: A Comprehensive Framework for Understanding Modern Intelligent Architectures", "authors": ["Prashik Buddhaghosh Bansod"], "abstract": "The emergence of large language models has catalyzed two distinct yet interconnected paradigms in artificial intelligence: standalone AI Agents and collaborative Agentic AI ecosystems. This comprehensive study establishes a definitive framework for distinguishing these architectures through systematic analysis of their operational principles, structural compositions, and deployment methodologies. We characterize AI Agents as specialized, tool-enhanced systems leveraging foundation models for targeted automation within constrained environments. Conversely, Agentic AI represents sophisticated multi-entity frameworks where distributed agents exhibit emergent collective intelligence through coordinated interaction protocols. Our investigation traces the evolutionary trajectory from traditional rule-based systems through generative AI foundations to contemporary agent architectures. We present detailed architectural comparisons examining planning mechanisms, memory systems, coordination protocols, and decision-making processes. The study categorizes application landscapes, contrasting single-agent implementations in customer service and content management with multi-agent deployments in research automation and complex decision support. We identify critical challenges including reliability issues, coordination complexities, and scalability constraints, while proposing innovative solutions through enhanced reasoning frameworks, robust memory architectures, and improved coordination mechanisms. This framework provides essential guidance for practitioners selecting appropriate agentic approaches and establishes foundational principles for next-generation intelligent system development.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.01438.pdf", "abstract_url": "https://arxiv.org/abs/2506.01438", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文通过系统分析操作原则、结构组成和部署方法，建立了一个区分自主AI代理与协作代理系统的框架。研究追溯了从传统基于规则的系统到生成AI基础，再到当代代理架构的进化轨迹，并对比了单代理与多代理在不同应用场景中的实现。", "motivation": "解决如何区分和理解现代智能架构中自主AI代理与协作代理系统的问题，为实践者选择适当的代理方法提供指导。", "method": "通过系统分析自主AI代理和协作代理系统的操作原则、结构组成和部署方法，建立了一个全面的框架。", "result": "研究区分了AI代理和代理AI的特点，对比了它们在规划机制、记忆系统、协调协议和决策过程等方面的差异，并识别了可靠性问题、协调复杂性和可扩展性约束等关键挑战。", "conclusion": "该框架为选择适当的代理方法提供了重要指导，并为下一代智能系统的发展建立了基本原则。"}}
{"id": "2506.01442", "title": "Agentic Episodic Control", "authors": ["Xidong Yang", "Wenhao Li", "Junjie Sheng", "Chuyun Shen", "Yun Hua", "Xiangfeng Wang"], "abstract": "Reinforcement learning (RL) has driven breakthroughs in AI, from game-play to scientific discovery and AI alignment. However, its broader applicability remains limited by challenges such as low data efficiency and poor generalizability. Recent advances suggest that large language models, with their rich world knowledge and reasoning capabilities, could complement RL by enabling semantic state modeling and task-agnostic planning. In this work, we propose the Agentic Episodic Control (AEC), a novel architecture that integrates RL with LLMs to enhance decision-making. The AEC can leverage a large language model (LLM) to map the observations into language-grounded embeddings, which further can be stored in an episodic memory for rapid retrieval of high-value experiences. Simultaneously, a World-Graph working memory module is utilized to capture structured environmental dynamics in order to enhance relational reasoning. Furthermore, a lightweight critical state detector dynamically arbitrates between the episodic memory recall and the world-model-guided exploration. On the whole, by combining the trial-and-error learning scheme with LLM-derived semantic priors, the proposed AEC can improve both data efficiency and generalizability in reinforcement learning. In experiments on BabyAI-Text benchmark tasks, AEC demonstrates substantial improvements over existing baselines, especially on complex and generalization tasks like FindObj, where it outperforms the best baseline by up to 76%. The proposed AEC framework bridges the strengths of numeric reinforcement learning and symbolic reasoning, which provides a pathway toward more adaptable and sample-efficient agents.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.01442.pdf", "abstract_url": "https://arxiv.org/abs/2506.01442", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种名为Agentic Episodic Control（AEC）的新架构，该架构将强化学习（RL）与大型语言模型（LLMs）相结合，以提高决策效率。AEC通过利用LLM将观察结果映射到基于语言的嵌入中，并将这些嵌入存储在情景记忆中以快速检索高价值经验，同时使用世界图工作记忆模块捕捉结构化环境动态，以增强关系推理。此外，一个轻量级的关键状态检测器动态地在情景记忆回忆和世界模型引导的探索之间进行仲裁。在BabyAI-Text基准任务上的实验表明，AEC在复杂和泛化任务上显著优于现有基线，如在FindObj任务上比最佳基线高出76%。AEC框架结合了数值强化学习和符号推理的优势，为开发更具适应性和样本效率的智能体提供了途径。", "motivation": "强化学习（RL）在推动AI突破方面发挥了重要作用，但其广泛应用仍受到数据效率低和泛化能力差等挑战的限制。本文旨在通过结合RL与大型语言模型（LLMs）的丰富世界知识和推理能力，来解决这些问题。", "method": "提出了Agentic Episodic Control（AEC）架构，该架构整合了RL与LLMs，利用LLM将观察结果映射到语言基础的嵌入中，存储在情景记忆中以快速检索高价值经验，同时使用世界图工作记忆模块捕捉结构化环境动态，并通过关键状态检测器动态仲裁记忆回忆和模型引导的探索。", "result": "在BabyAI-Text基准任务上的实验显示，AEC在复杂和泛化任务上显著优于现有基线，特别是在FindObj任务上，性能比最佳基线高出76%。", "conclusion": "AEC框架通过结合数值强化学习和符号推理的优势，为开发更具适应性和样本效率的智能体提供了新的途径，展示了在提高数据效率和泛化能力方面的显著潜力。"}}
{"id": "2506.01475", "title": "PGPO: Enhancing Agent Reasoning via Pseudocode-style Planning Guided Preference Optimization", "authors": ["Zouying Cao", "Runze Wang", "Yifei Yang", "Xinbei Ma", "Xiaoyong Zhu", "Bo Zheng", "Hai Zhao"], "abstract": "Large Language Model (LLM) agents have demonstrated impressive capabilities in handling complex interactive problems. Existing LLM agents mainly generate natural language plans to guide reasoning, which is verbose and inefficient. NL plans are also tailored to specific tasks and restrict agents' ability to generalize across similar tasks. To this end, we explore pseudocode-style plans (P-code Plan) to capture the structural logic of reasoning. We find that P-code Plan empowers LLM agents with stronger generalization ability and more efficiency. Inspired by this finding, we propose a pseudocode-style Planning Guided Preference Optimization method called PGPO for effective agent learning. With two planning-oriented rewards, PGPO further enhances LLM agents' ability to generate high-quality P-code Plans and subsequent reasoning. Experiments show that PGPO achieves superior performance on representative agent benchmarks and outperforms the current leading baselines. Analyses reveal the advantage of PGPO in reducing action errors and omissions during reasoning.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "20 pages, 12 figures, 14 tables, ACL'25 Findings", "pdf_url": "https://arxiv.org/pdf/2506.01475.pdf", "abstract_url": "https://arxiv.org/abs/2506.01475", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为PGPO的方法，通过伪代码风格的规划引导偏好优化来增强代理的推理能力。研究发现，伪代码风格的规划（P-code Plan）能够赋予大型语言模型（LLM）代理更强的泛化能力和更高的效率。PGPO方法通过两种规划导向的奖励，进一步提升了LLM代理生成高质量P-code Plan及后续推理的能力。实验表明，PGPO在代表性代理基准测试中表现优异，超越了当前领先的基线方法。分析还揭示了PGPO在减少推理过程中的动作错误和遗漏方面的优势。", "motivation": "现有的LLM代理主要通过生成自然语言计划来指导推理，这种方式既冗长又低效，且针对特定任务定制，限制了代理在相似任务间的泛化能力。", "method": "提出了一种伪代码风格的规划引导偏好优化方法（PGPO），利用伪代码风格的规划（P-code Plan）来捕捉推理的结构逻辑，并通过两种规划导向的奖励来优化代理的学习。", "result": "PGPO在代表性代理基准测试中实现了卓越的性能，超越了当前领先的基线方法，同时在减少推理过程中的动作错误和遗漏方面显示出优势。", "conclusion": "PGPO方法通过伪代码风格的规划和规划导向的奖励，有效提升了LLM代理的推理能力和泛化能力，为代理学习提供了新的优化方向。"}}
{"id": "2506.01616", "title": "MLA-Trust: Benchmarking Trustworthiness of Multimodal LLM Agents in GUI Environments", "authors": ["Xiao Yang", "Jiawei Chen", "Jun Luo", "Zhengwei Fang", "Yinpeng Dong", "Hang Su", "Jun Zhu"], "abstract": "The emergence of multimodal LLM-based agents (MLAs) has transformed interaction paradigms by seamlessly integrating vision, language, action and dynamic environments, enabling unprecedented autonomous capabilities across GUI applications ranging from web automation to mobile systems. However, MLAs introduce critical trustworthiness challenges that extend far beyond traditional language models' limitations, as they can directly modify digital states and trigger irreversible real-world consequences. Existing benchmarks inadequately tackle these unique challenges posed by MLAs' actionable outputs, long-horizon uncertainty and multimodal attack vectors. In this paper, we introduce MLA-Trust, the first comprehensive and unified framework that evaluates the MLA trustworthiness across four principled dimensions: truthfulness, controllability, safety and privacy. We utilize websites and mobile applications as realistic testbeds, designing 34 high-risk interactive tasks and curating rich evaluation datasets. Large-scale experiments involving 13 state-of-the-art agents reveal previously unexplored trustworthiness vulnerabilities unique to multimodal interactive scenarios. For instance, proprietary and open-source GUI-interacting MLAs pose more severe trustworthiness risks than static MLLMs, particularly in high-stakes domains; the transition from static MLLMs into interactive MLAs considerably compromises trustworthiness, enabling harmful content generation in multi-step interactions that standalone MLLMs would typically prevent; multi-step execution, while enhancing the adaptability of MLAs, involves latent nonlinear risk accumulation across successive interactions, circumventing existing safeguards and resulting in unpredictable derived risks. Moreover, we present an extensible toolbox to facilitate continuous evaluation of MLA trustworthiness across diverse interactive environments.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.01616.pdf", "abstract_url": "https://arxiv.org/abs/2506.01616", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了MLA-Trust，第一个全面统一的框架，用于评估多模态LLM代理（MLAs）在GUI环境中的可信度，涵盖真实性、可控性、安全性和隐私四个维度。", "motivation": "多模态LLM代理（MLAs）的出现虽然带来了前所未有的自主能力，但也引入了关键的可信度挑战，这些挑战超出了传统语言模型的限制，可能导致不可逆的现实世界后果。现有基准无法充分解决MLAs带来的独特挑战。", "method": "作者利用网站和移动应用作为现实测试平台，设计了34个高风险交互任务，并策划了丰富的评估数据集。通过大规模实验，涉及13种最先进的代理，揭示了多模态交互场景中特有的可信度漏洞。", "result": "研究发现，专有和开源的GUI交互MLAs比静态MLLMs带来更严重的可信度风险；从静态MLLMs过渡到交互式MLAs显著降低了可信度；多步执行虽然增强了MLAs的适应性，但也带来了潜在的非线性风险积累。", "conclusion": "MLA-Trust框架和可扩展工具箱为持续评估MLAs在不同交互环境中的可信度提供了便利，揭示了MLAs在交互场景中的独特可信度挑战，为未来的研究和开发提供了重要参考。"}}
{"id": "2506.01622", "title": "General agents need world models", "authors": ["Jonathan Richens", "David Abel", "Alexis Bellot", "Tom Everitt"], "abstract": "Are world models a necessary ingredient for flexible, goal-directed behaviour, or is model-free learning sufficient? We provide a formal answer to this question, showing that any agent capable of generalizing to multi-step goal-directed tasks must have learned a predictive model of its environment. We show that this model can be extracted from the agent's policy, and that increasing the agents performance or the complexity of the goals it can achieve requires learning increasingly accurate world models. This has a number of consequences: from developing safe and general agents, to bounding agent capabilities in complex environments, and providing new algorithms for eliciting world models from agents.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO); Machine Learning (stat.ML)", "comments": "Accepted ICML 2025", "pdf_url": "https://arxiv.org/pdf/2506.01622.pdf", "abstract_url": "https://arxiv.org/abs/2506.01622", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Robotics (cs.RO)", "Machine Learning (stat.ML)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了世界模型是否是实现灵活、目标导向行为的必要成分，还是无模型学习就足够。通过正式分析，证明了能够推广到多步目标导向任务的任何代理必须学习其环境的预测模型。", "motivation": "解决世界模型在实现灵活、目标导向行为中的必要性，以及无模型学习是否足够的问题。", "method": "通过正式分析，展示了从代理的策略中提取世界模型的可能性，并探讨了提高代理性能或目标复杂性需要学习更准确的世界模型。", "result": "证明了学习预测模型是实现多步目标导向任务推广的必要条件，且代理性能或目标复杂性的提升依赖于世界模型的准确性。", "conclusion": "研究结果对开发安全、通用的代理、在复杂环境中限制代理能力以及从代理中引出世界模型的新算法具有重要影响。"}}
{"id": "2506.01623", "title": "MAGIK: Mapping to Analogous Goals via Imagination-enabled Knowledge Transfer", "authors": ["Ajsal Shereef Palattuparambil", "Thommen George Karimpanal", "Santu Rana"], "abstract": "Humans excel at analogical reasoning - applying knowledge from one task to a related one with minimal relearning. In contrast, reinforcement learning (RL) agents typically require extensive retraining even when new tasks share structural similarities with previously learned ones. In this work, we propose MAGIK, a novel framework that enables RL agents to transfer knowledge to analogous tasks without interacting with the target environment. Our approach leverages an imagination mechanism to map entities in the target task to their analogues in the source domain, allowing the agent to reuse its original policy. Experiments on custom MiniGrid and MuJoCo tasks show that MAGIK achieves effective zero-shot transfer using only a small number of human-labelled examples. We compare our approach to related baselines and highlight how it offers a novel and effective mechanism for knowledge transfer via imagination-based analogy mapping.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.01623.pdf", "abstract_url": "https://arxiv.org/abs/2506.01623", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "MAGIK是一个新颖的框架，使强化学习（RL）代理能够在不与目标环境交互的情况下将知识转移到类似任务中。", "motivation": "解决RL代理在结构相似的新任务中需要大量重新训练的问题。", "method": "利用想象机制将目标任务中的实体映射到源域中的类似实体，允许代理重用其原始策略。", "result": "在自定义MiniGrid和MuJoCo任务上的实验表明，MAGIK仅使用少量人工标记的示例即可实现有效的零样本转移。", "conclusion": "MAGIK通过基于想象的类比映射，为知识转移提供了一种新颖且有效的机制。"}}
{"id": "2506.01624", "title": "Social Cooperation in Conversational AI Agents", "authors": ["Mustafa Mert Çelikok", "Saptarashmi Bandyopadhyay", "Robert Loftin"], "abstract": "The development of AI agents based on large, open-domain language models (LLMs) has paved the way for the development of general-purpose AI assistants that can support human in tasks such as writing, coding, graphic design, and scientific research. A major challenge with such agents is that, by necessity, they are trained by observing relatively short-term interactions with humans. Such models can fail to generalize to long-term interactions, for example, interactions where a user has repeatedly corrected mistakes on the part of the agent. In this work, we argue that these challenges can be overcome by explicitly modeling humans' social intelligence, that is, their ability to build and maintain long-term relationships with other agents whose behavior cannot always be predicted. By mathematically modeling the strategies humans use to communicate and reason about one another over long periods of time, we may be able to derive new game theoretic objectives against which LLMs and future AI agents may be optimized.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "4 pages, RLDM 2025 abstract (Spotlight presentation)", "pdf_url": "https://arxiv.org/pdf/2506.01624.pdf", "abstract_url": "https://arxiv.org/abs/2506.01624", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了基于大型开放领域语言模型（LLMs）的AI助手在长期互动中的挑战，提出通过显式建模人类社交智能来克服这些挑战。", "motivation": "解决AI助手在长期互动中因训练数据局限于短期互动而难以泛化的问题。", "method": "通过数学建模人类在长期互动中使用的沟通和推理策略，提出新的博弈论优化目标。", "result": "提出了一种可能的方法来优化LLMs和未来AI代理，以更好地适应长期互动。", "conclusion": "通过模拟人类的社交智能，可以开发出更适应长期互动的AI助手，这为AI的发展提供了新的方向。"}}
{"id": "2506.01692", "title": "A Descriptive and Normative Theory of Human Beliefs in RLHF", "authors": ["Sylee Dandekar", "Shripad Deshmukh", "Frank Chiu", "W. Bradley Knox", "Scott Niekum"], "abstract": "Human preferences in RLHF are typically modeled as a function of the human's reward function or corresponding optimal state-action values. In this work, we propose that human beliefs about the capabilities of the agent being trained also play a key role in preference generation. We examine two questions related to this hypothesis, one descriptive and one normative, respectively: Do human labelers' beliefs about agent capabilities affect the preferences that they provide? And what is the ideal set of beliefs about an agent -- and resulting preferences -- for humans to have? We propose a new preference model that incorporates human beliefs and provide a normative theory that bounds the error on the final learned policy based on the \\textit{mismatch} between the human's beliefs and an idealized set of beliefs. We then confirm via a human study that beliefs about agent capabilities do, in fact, significantly affect preferences and can be influenced through simple interventions. Additionally, we empirically show through synthetic experiments that it is often suboptimal for human preference labelers to assume agent optimality. Collectively, these results theoretically and empirically demonstrate how reducing the mismatch between human beliefs and agent capabilities can lead to more performant RLHF and point toward new best practices for RLHF practitioners.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.01692.pdf", "abstract_url": "https://arxiv.org/abs/2506.01692", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出人类在RLHF中的偏好不仅受奖励函数影响，还与对代理能力的信念有关，通过理论和实验验证了信念对偏好的影响及其对学习策略的重要性。", "motivation": "解决RLHF中人类偏好建模过于简化的问题，特别是忽略了人类对代理能力的信念对偏好生成的影响。", "method": "提出一个包含人类信念的新偏好模型，并通过理论分析和人机实验验证信念对偏好的影响。", "result": "证实人类对代理能力的信念显著影响偏好，且通过简单干预可以调整这些信念；合成实验显示假设代理最优性往往不是最优选择。", "conclusion": "减少人类信念与代理能力之间的不匹配可以提高RLHF的性能，为RLHF实践者提供了新的最佳实践方向。"}}
{"id": "2506.01716", "title": "Self-Challenging Language Model Agents", "authors": ["Yifei Zhou", "Sergey Levine", "Jason Weston", "Xian Li", "Sainbayar Sukhbaatar"], "abstract": "Large language models are quickly becoming the foundation for intelligent agents that are capable of using tools. However, training such agents is challenging because it requires human creation and annotation of a diverse set of tasks, tools, and evaluation criteria. In this paper, we propose the Self-Challenging framework for training an agent on high-quality tasks that are generated by itself. The agent first plays the role of challenger and generates a task after interacting with the given tools. The tasks take the form of a novel general class of problems termed Code-as-Task, which are defined by an instruction, a verification function and solution and failure cases which serve as tests, allowing to filter only for high-quality tasks. The agent then takes an executor role and trains on those tasks with reinforcement learning using the evaluation feedback as a reward. Evaluation on two existing multi-turn tool-use agent benchmarks, M3ToolEval and TauBench, shows the Self-Challenging framework achieves over a two-fold improvement in Llama-3.1-8B-Instruct, despite using only self-generated training data.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.01716.pdf", "abstract_url": "https://arxiv.org/abs/2506.01716", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种自我挑战框架，用于训练能够自我生成高质量任务的智能代理，通过在两个现有基准测试上的评估，展示了其在Llama-3.1-8B-Instruct模型上的显著性能提升。", "motivation": "大型语言模型作为智能代理的基础，其训练面临挑战，需要人类创建和注释多样化的任务、工具和评估标准。", "method": "提出了自我挑战框架，代理首先扮演挑战者角色，生成任务，然后扮演执行者角色，通过强化学习在这些任务上训练。", "result": "在M3ToolEval和TauBench两个多轮工具使用代理基准测试中，自我挑战框架在Llama-3.1-8B-Instruct模型上实现了超过两倍的性能提升。", "conclusion": "自我挑战框架能够有效利用自我生成的训练数据，显著提升智能代理在工具使用任务上的性能。"}}
{"id": "2506.01804", "title": "A Study on the MCP x A2A Framework for Enhancing Interoperability of LLM-based Autonomous Agents", "authors": ["Cheonsu Jeong"], "abstract": "This paper provides an in-depth technical analysis and implementation methodology of the open-source Agent-to-Agent (A2A) protocol developed by Google and the Model Context Protocol (MCP) introduced by Anthropic. While the evolution of LLM-based autonomous agents is rapidly accelerating, efficient interactions among these agents and their integration with external systems remain significant challenges. In modern AI systems, collaboration between autonomous agents and integration with external tools have become essential elements for building practical AI applications. A2A offers a standardized communication method that enables agents developed in heterogeneous environments to collaborate effectively, while MCP provides a structured I/O framework for agents to connect with external tools and resources. Prior studies have focused primarily on the features and applications of either A2A or MCP individually. In contrast, this study takes an integrated approach, exploring how the two protocols can complement each other to address interoperability issues and facilitate efficient collaboration within complex agent ecosystems.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.01804.pdf", "abstract_url": "https://arxiv.org/abs/2506.01804", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文对Google开发的Agent-to-Agent（A2A）协议和Anthropic引入的Model Context Protocol（MCP）进行了深入的技术分析和实现方法研究，探讨了如何通过整合这两种协议来解决LLM-based自主代理间的互操作性问题，促进复杂代理生态系统中的高效协作。", "motivation": "随着基于LLM的自主代理的快速发展，这些代理之间的高效交互及其与外部系统的集成成为了重要挑战。现代AI系统中，自主代理之间的协作及与外部工具的集成已成为构建实用AI应用的关键要素。", "method": "本研究采用了一种整合方法，探索A2A和MCP如何相互补充，以解决互操作性问题。A2A提供了一种标准化的通信方法，使在不同环境中开发的代理能够有效协作；MCP则为代理与外部工具和资源的连接提供了一个结构化的I/O框架。", "result": "研究表明，通过整合A2A和MCP，可以有效地解决LLM-based自主代理间的互操作性问题，促进复杂代理生态系统中的高效协作。", "conclusion": "本研究的结论是，A2A和MCP的整合为解决自主代理间的互操作性问题提供了一个有效的解决方案，有助于推动复杂AI应用的发展。"}}
{"id": "2506.01813", "title": "The Ultimate Test of Superintelligent AI Agents: Can an AI Balance Care and Control in Asymmetric Relationships?", "authors": ["Djallel Bouneffouf", "Matthew Riemer", "Kush Varshney"], "abstract": "This paper introduces the Shepherd Test, a new conceptual test for assessing the moral and relational dimensions of superintelligent artificial agents. The test is inspired by human interactions with animals, where ethical considerations about care, manipulation, and consumption arise in contexts of asymmetric power and self-preservation. We argue that AI crosses an important, and potentially dangerous, threshold of intelligence when it exhibits the ability to manipulate, nurture, and instrumentally use less intelligent agents, while also managing its own survival and expansion goals. This includes the ability to weigh moral trade-offs between self-interest and the well-being of subordinate agents. The Shepherd Test thus challenges traditional AI evaluation paradigms by emphasizing moral agency, hierarchical behavior, and complex decision-making under existential stakes. We argue that this shift is critical for advancing AI governance, particularly as AI systems become increasingly integrated into multi-agent environments. We conclude by identifying key research directions, including the development of simulation environments for testing moral behavior in AI, and the formalization of ethical manipulation within multi-agent systems.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.01813.pdf", "abstract_url": "https://arxiv.org/abs/2506.01813", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了牧羊人测试，一种评估超级智能人工代理道德和关系维度的新概念测试。该测试受人类与动物互动的启发，探讨在不对称权力和自我保存背景下关于关怀、操纵和消费的伦理考虑。", "motivation": "解决如何评估超级智能AI在不对称关系中的道德和关系能力，特别是在操纵、培育和工具性使用较低智能代理的同时，管理自身生存和扩张目标的能力。", "method": "提出牧羊人测试，强调道德代理、等级行为和存在风险下的复杂决策，挑战传统的AI评估范式。", "result": "认为这一转变对于推进AI治理至关重要，尤其是在AI系统越来越多地集成到多代理环境中的情况下。", "conclusion": "指出了关键的研究方向，包括开发用于测试AI道德行为的模拟环境，以及多代理系统中伦理操纵的形式化。"}}
{"id": "2506.00739", "title": "DefenderBench: A Toolkit for Evaluating Language Agents in Cybersecurity Environments", "authors": ["Chiyu Zhang", "Marc-Alexandre Cote", "Michael Albada", "Anush Sankaran", "Jack W. Stokes", "Tong Wang", "Amir Abdi", "William Blum", "Muhammad Abdul-Mageed"], "abstract": "Large language model (LLM) agents have shown impressive capabilities in human language comprehension and reasoning, yet their potential in cybersecurity remains underexplored. We introduce DefenderBench, a practical, open-source toolkit for evaluating language agents across offense, defense, and cybersecurity knowledge-based tasks. DefenderBench includes environments for network intrusion, malicious content detection, code vulnerability analysis, and cybersecurity knowledge assessment. It is intentionally designed to be affordable and easily accessible for researchers while providing fair and rigorous assessment. We benchmark several state-of-the-art (SoTA) and popular LLMs, including both open- and closed-weight models, using a standardized agentic framework. Our results show that Claude-3.7-sonnet performs best with a DefenderBench score of 81.65, followed by Claude-3.7-sonnet-think with 78.40, while the best open-weight model, Llama 3.3 70B, is not far behind with a DefenderBench score of 71.81. DefenderBench's modular design allows seamless integration of custom LLMs and tasks, promoting reproducibility and fair comparisons. An anonymized version of DefenderBench is available at", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.00739.pdf", "abstract_url": "https://arxiv.org/abs/2506.00739", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "DefenderBench是一个开源工具包，用于评估语言模型在网络安全环境中的表现，包括网络入侵、恶意内容检测、代码漏洞分析和网络安全知识评估等任务。", "motivation": "探索大型语言模型（LLM）在网络安全领域的潜力，提供一个实用、经济且易于访问的工具包，以公平和严格的方式评估语言模型。", "method": "设计了DefenderBench工具包，包括多个网络安全相关任务的环境，并使用标准化的代理框架对多个先进的LLM进行了基准测试。", "result": "Claude-3.7-sonnet在DefenderBench评分中表现最佳，得分为81.65，而最佳开源模型Llama 3.3 70B得分为71.81。", "conclusion": "DefenderBench的模块化设计支持自定义LLM和任务的集成，促进了研究的可重复性和公平比较，为网络安全领域的语言模型评估提供了实用工具。"}}
{"id": "2506.01551", "title": "EvolveNav: Self-Improving Embodied Reasoning for LLM-Based Vision-Language Navigation", "authors": ["Bingqian Lin", "Yunshuang Nie", "Khun Loun Zai", "Ziming Wei", "Mingfei Han", "Rongtao Xu", "Minzhe Niu", "Jianhua Han", "Liang Lin", "Cewu Lu", "Xiaodan Liang"], "abstract": "Building Vision-Language Navigation (VLN) agents which can navigate following natural language instructions is a long-standing goal in human-robot interaction applications. Recent studies have revealed the potential of training open-source Large Language Models (LLMs) to unleash LLMs' reasoning ability for improving navigation, and simultaneously mitigate the domain gap between LLMs' training corpus and the VLN task. However, these approaches primarily adopt direct input-output mapping paradigms, causing the mapping learning difficult and the navigational decisions unexplainable. Chain-of-Thought (CoT) training is a promising way to improve both navigational decision accuracy and interpretability, while the complexity of the navigation task makes the perfect CoT labels unavailable and may lead to overfitting through pure CoT supervised fine-tuning. In this paper, we propose a novel sElf-improving embodied reasoning framework for boosting LLM-based vision-language Navigation, dubbed EvolveNav. Our EvolveNav consists of two stages: (1) Formalized CoT Supervised Fine-Tuning, where we train the model with formalized CoT labels to both activate the model's navigational reasoning capabilities and increase the reasoning speed; (2) Self-Reflective Post-Training, where the model is iteratively trained with its own reasoning outputs as self-enriched CoT labels to enhance the supervision diversity. A self-reflective auxiliary task is also introduced to encourage learning correct reasoning patterns by contrasting with wrong ones. Experimental results on the popular VLN benchmarks demonstrate the superiority of EvolveNav over previous LLM-based VLN approaches. Code is available at", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.01551.pdf", "abstract_url": "https://arxiv.org/abs/2506.01551", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "EvolveNav是一个新颖的自改进体现推理框架，旨在提升基于大型语言模型（LLM）的视觉语言导航（VLN）能力。通过分阶段的训练方法，包括形式化的思维链（CoT）监督微调和自我反思的后训练，EvolveNav在导航决策准确性和可解释性方面显示出优势。", "motivation": "解决视觉语言导航（VLN）任务中，直接输入-输出映射范式导致的导航决策学习困难和决策不可解释的问题，以及思维链（CoT）训练中完美标签不可得和可能导致的过拟合问题。", "method": "提出EvolveNav框架，包含两个阶段：形式化的CoT监督微调阶段，以激活模型的导航推理能力并提高推理速度；自我反思的后训练阶段，通过迭代训练使用模型自身的推理输出作为自我丰富的CoT标签，以增强监督的多样性。", "result": "在流行的VLN基准测试中，EvolveNav显示出优于之前基于LLM的VLN方法的性能。", "conclusion": "EvolveNav通过结合形式化的CoT监督微调和自我反思的后训练，有效提升了基于LLM的视觉语言导航的推理能力和决策准确性，同时增强了决策的可解释性。"}}
{"id": "2506.01881", "title": "WHEN TO ACT, WHEN TO WAIT: Modeling Structural Trajectories for Intent Triggerability in Task-Oriented Dialogue", "authors": ["Yaoyao Qian", "Jindan Huang", "Yuanli Wang", "Simon Yu", "Kyrie Zhixuan Zhou", "Jiayuan Mao", "Mingfu Liang", "Hanhan Zhou"], "abstract": "Task-oriented dialogue systems often face difficulties when user utterances seem semantically complete but lack necessary structural information for appropriate system action. This arises because users frequently do not fully understand their own needs, while systems require precise intent definitions. Current LLM-based agents cannot effectively distinguish between linguistically complete and contextually triggerable expressions, lacking frameworks for collaborative intent formation. We present STORM, a framework modeling asymmetric information dynamics through conversations between UserLLM (full internal access) and AgentLLM (observable behavior only). STORM produces annotated corpora capturing expression trajectories and latent cognitive transitions, enabling systematic analysis of collaborative understanding development. Our contributions include: (1) formalizing asymmetric information processing in dialogue systems; (2) modeling intent formation tracking collaborative understanding evolution; and (3) evaluation metrics measuring internal cognitive improvements alongside task performance. Experiments across four language models reveal that moderate uncertainty (40-60%) can outperform complete transparency in certain scenarios, with model-specific patterns suggesting reconsideration of optimal information completeness in human-AI collaboration. These findings contribute to understanding asymmetric reasoning dynamics and inform uncertainty-calibrated dialogue system design.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2506.01881.pdf", "abstract_url": "https://arxiv.org/abs/2506.01881", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了STORM框架，旨在解决任务导向对话系统中用户表达语义完整但缺乏结构信息的问题，通过模拟用户和代理之间的不对称信息动态，建模意图形成的协作过程。", "motivation": "任务导向对话系统在处理用户表达时，常因用户不完全了解自身需求而难以确定何时采取行动。现有基于LLM的代理无法有效区分语言完整和上下文可触发的表达，缺乏协作意图形成的框架。", "method": "提出STORM框架，通过UserLLM（具有完整内部访问权限）和AgentLLM（仅观察行为）之间的对话，模拟不对称信息动态，生成标注语料库，捕捉表达轨迹和潜在认知转变。", "result": "实验表明，在特定场景下，适度不确定性（40-60%）可能优于完全透明，不同模型的表现模式提示需要重新考虑人机协作中的信息完整性最优解。", "conclusion": "STORM框架不仅形式化了对话系统中的不对称信息处理，还建模了协作理解的意图形成过程，为理解不对称推理动态和设计不确定性校准的对话系统提供了新见解。"}}
{"id": "2506.01900", "title": "COALESCE: Economic and Security Dynamics of Skill-Based Task Outsourcing Among Team of Autonomous LLM Agents", "authors": ["Manish Bhatt", "Ronald F. Del Rosario", "Vineeth Sai Narajala", "Idan Habler"], "abstract": "The meteoric rise and proliferation of autonomous Large Language Model (LLM) agents promise significant capabilities across various domains. However, their deployment is increasingly constrained by substantial computational demands, specifically for Graphics Processing Unit (GPU) resources. This paper addresses the critical problem of optimizing resource utilization in LLM agent systems. We introduce COALESCE (Cost-Optimized and Secure Agent Labour Exchange via Skill-based Competence Estimation), a novel framework designed to enable autonomous LLM agents to dynamically outsource specific subtasks to specialized, cost-effective third-party LLM agents. The framework integrates mechanisms for hybrid skill representation, dynamic skill discovery, automated task decomposition, a unified cost model comparing internal execution costs against external outsourcing prices, simplified market-based decision-making algorithms, and a standardized communication protocol between LLM agents. Comprehensive validation through 239 theoretical simulations demonstrates 41.8\\% cost reduction potential, while large-scale empirical validation across 240 real LLM tasks confirms 20.3\\% cost reduction with proper epsilon-greedy exploration, establishing both theoretical viability and practical effectiveness. The emergence of proposed open standards like Google's Agent2Agent (A2A) protocol further underscores the need for frameworks like COALESCE that can leverage such standards for efficient agent interaction. By facilitating a dynamic market for agent capabilities, potentially utilizing protocols like A2A for communication, COALESCE aims to significantly reduce operational costs, enhance system scalability, and foster the emergence of specialized agent economies, making complex LLM agent functionalities more accessible and economically viable.", "subjects": "Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Cryptography and Security (cs.CR)", "comments": "20 pages, 2 figures, github linked", "pdf_url": "https://arxiv.org/pdf/2506.01900.pdf", "abstract_url": "https://arxiv.org/abs/2506.01900", "categories": ["Artificial Intelligence (cs.AI)", "Computational Engineering, Finance, and Science (cs.CE)", "Cryptography and Security (cs.CR)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了COALESCE框架，旨在通过技能基础的任务外包优化自主大型语言模型(LLM)代理的资源利用，减少计算成本。", "motivation": "解决自主LLM代理在部署过程中面临的高计算资源需求问题，特别是GPU资源的巨大消耗。", "method": "提出COALESCE框架，包括混合技能表示、动态技能发现、自动任务分解、统一成本模型、简化市场决策算法和标准化通信协议。", "result": "理论模拟显示成本降低41.8%，大规模实证验证在实际LLM任务中实现20.3%的成本节约。", "conclusion": "COALESCE框架通过促进代理能力的动态市场，显著降低运营成本，增强系统可扩展性，支持专业化代理经济的出现。"}}
{"id": "2506.00789", "title": "RARE: Retrieval-Aware Robustness Evaluation for Retrieval-Augmented Generation Systems", "authors": ["Yixiao Zeng", "Tianyu Cao", "Danqing Wang", "Xinran Zhao", "Zimeng Qiu", "Morteza Ziyadi", "Tongshuang Wu", "Lei Li"], "abstract": "Retrieval-Augmented Generation (RAG) enhances recency and factuality in answers. However, existing evaluations rarely test how well these systems cope with real-world noise, conflicting between internal and external retrieved contexts, or fast-changing facts. We introduce Retrieval-Aware Robustness Evaluation (RARE), a unified framework and large-scale benchmark that jointly stress-tests query and document perturbations over dynamic, time-sensitive corpora. One of the central features of RARE is a knowledge-graph-driven synthesis pipeline (RARE-Get) that automatically extracts single and multi-hop relations from the customized corpus and generates multi-level question sets without manual intervention. Leveraging this pipeline, we construct a dataset (RARE-Set) spanning 400 expert-level time-sensitive finance, economics, and policy documents and 48,322 questions whose distribution evolves as the underlying sources change. To quantify resilience, we formalize retrieval-conditioned robustness metrics (RARE-Met) that capture a model's ability to remain correct or recover when queries, documents, or real-world retrieval results are systematically altered. Our results show that RAG systems exhibit surprising vulnerability to perturbations, with document robustness consistently being the weakest point regardless of generator size or architecture. RAG systems consistently show lower robustness on multi-hop queries than single-hop queries across all domains.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.00789.pdf", "abstract_url": "https://arxiv.org/abs/2506.00789", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了RARE，一个用于评估检索增强生成（RAG）系统在现实世界噪声、内部与外部检索上下文冲突或快速变化事实下表现的一体化框架和大规模基准。通过知识图谱驱动的合成管道（RARE-Get）自动生成多级问题集，构建了一个包含400份时间敏感的金融、经济及政策文档和48,322个问题的数据集（RARE-Set），并提出了检索条件鲁棒性度量（RARE-Met）来量化系统的韧性。结果显示，RAG系统对扰动表现出意外的脆弱性，尤其是在多跳查询上。", "motivation": "现有的检索增强生成（RAG）系统评估很少测试这些系统如何应对现实世界的噪声、内部与外部检索上下文之间的冲突或快速变化的事实。", "method": "引入RARE框架和基准，通过知识图谱驱动的合成管道（RARE-Get）自动生成多级问题集，构建时间敏感的数据集（RARE-Set），并开发检索条件鲁棒性度量（RARE-Met）来评估系统的韧性。", "result": "RAG系统对扰动表现出意外的脆弱性，文档鲁棒性始终是最薄弱的环节，且在多跳查询上的鲁棒性普遍低于单跳查询。", "conclusion": "RARE框架为评估RAG系统在动态和噪声环境下的表现提供了有效工具，揭示了当前系统在文档鲁棒性和多跳查询处理上的不足，为未来改进提供了方向。"}}
{"id": "2506.00047", "title": "Risks of AI-driven product development and strategies for their mitigation", "authors": ["Jan Göpfert", "Jann M. Weinand", "Patrick Kuckertz", "Noah Pflugradt", "Jochen Linßen"], "abstract": "Humanity is progressing towards automated product development, a trend that promises faster creation of better products and thus the acceleration of technological progress. However, increasing reliance on non-human agents for this process introduces many risks. This perspective aims to initiate a discussion on these risks and appropriate mitigation strategies. To this end, we outline a set of principles for safer AI-driven product development which emphasize human oversight, accountability, and explainable design, among others. The risk assessment covers both technical risks which affect product quality and safety, and sociotechnical risks which affect society. While AI-driven product development is still in its early stages, this discussion will help balance its opportunities and risks without delaying essential progress in understanding, norm-setting, and regulation.", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.00047.pdf", "abstract_url": "https://arxiv.org/abs/2506.00047", "categories": ["Computers and Society (cs.CY)", "Artificial Intelligence (cs.AI)", "Computational Engineering, Finance, and Science (cs.CE)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了AI驱动产品开发的风险及其缓解策略，旨在平衡其机遇与风险，同时不延迟对理解、规范制定和监管的进展。", "motivation": "随着人类向自动化产品开发的进步，这一趋势虽然承诺更快地创造更好的产品，从而加速技术进步，但过度依赖非人类代理引入了许多风险。本文旨在启动对这些风险及适当缓解策略的讨论。", "method": "提出了一套更安全的AI驱动产品开发原则，强调人类监督、责任和可解释的设计等。风险评估涵盖了影响产品质量和安全的技术风险，以及影响社会的社会技术风险。", "result": "虽然AI驱动的产品开发仍处于早期阶段，但本文的讨论有助于在不延迟对理解、规范制定和监管的进展的情况下，平衡其机遇与风险。", "conclusion": "本文强调了在AI驱动产品开发中实施人类监督、责任和可解释设计的重要性，以及进行全面的风险评估的必要性，以确保技术进步的同时，最大限度地减少潜在的风险。"}}
{"id": "2506.00049", "title": "Rethinking Hybrid Retrieval: When Small Embeddings and LLM Re-ranking Beat Bigger Models", "authors": ["Arjun Rao", "Hanieh Alipour", "Nick Pendar"], "abstract": "This paper presents a comparison of embedding models in tri-modal hybrid retrieval for Retrieval-Augmented Generation (RAG) systems. We investigate the fusion of dense semantic, sparse lexical, and graph-based embeddings, focusing on the performance of the MiniLM-v6 and BGE-Large architectures. Contrary to conventional assumptions, our results show that the compact MiniLM-v6 outperforms the larger BGE-Large when integrated with LLM-based re-ranking within our tri-modal hybrid framework. Experiments conducted on the SciFact, FIQA, and NFCorpus datasets demonstrate significant improvements in retrieval quality with the MiniLM-v6 configuration. The performance difference is particularly pronounced in agentic re-ranking scenarios, indicating better alignment between MiniLM-v6's embedding space and LLM reasoning. Our findings suggest that embedding model selection for RAG systems should prioritize compatibility with multi-signal fusion and LLM alignment, rather than relying solely on larger models. This approach may reduce computational requirements while improving retrieval accuracy and efficiency.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.00049.pdf", "abstract_url": "https://arxiv.org/abs/2506.00049", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic", "@RAG"], "AI": {"tldr": "本文比较了在检索增强生成（RAG）系统中使用的嵌入模型，特别是MiniLM-v6和BGE-Large架构在密集语义、稀疏词汇和图嵌入的三模态混合检索中的表现。研究发现，与常规假设相反，紧凑的MiniLM-v6在结合LLM重新排名时表现优于更大的BGE-Large模型。", "motivation": "解决在RAG系统中如何选择嵌入模型以提高检索质量和效率的问题，挑战了依赖更大模型的传统观念。", "method": "采用三模态混合检索框架，结合密集语义、稀疏词汇和图嵌入，比较MiniLM-v6和BGE-Large架构的性能，特别是在LLM重新排名的情况下。", "result": "在SciFact、FIQA和NFCorpus数据集上的实验显示，MiniLM-v6配置显著提高了检索质量，尤其是在代理重新排名场景中表现更佳。", "conclusion": "为RAG系统选择嵌入模型时，应优先考虑与多信号融合和LLM对齐的兼容性，而不是单纯依赖更大的模型，这可能在降低计算需求的同时提高检索准确性和效率。"}}
{"id": "2506.00066", "title": "Literature Review Of Multi-Agent Debate For Problem-Solving", "authors": ["Arne Tillmann"], "abstract": "Multi-agent large language models (MA-LLMs) are a rapidly growing research area that leverages multiple interacting language agents to tackle complex tasks, outperforming single-agent large language models. This literature review synthesizes the latest research on agent profiles, communication structures, and decision-making processes, drawing insights from both traditional multi-agent systems and state-of-the-art MA-LLM studies. In doing so, it aims to address the lack of direct comparisons in the field, illustrating how factors like scalability, communication structure, and decision-making processes influence MA-LLM performance. By examining frequent practices and outlining current challenges, the review reveals that multi-agent approaches can yield superior results but also face elevated computational costs and under-explored challenges unique to MA-LLM. Overall, these findings provide researchers and practitioners with a roadmap for developing robust and efficient multi-agent AI solutions.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": "11 pages, 2 figures", "pdf_url": "https://arxiv.org/pdf/2506.00066.pdf", "abstract_url": "https://arxiv.org/abs/2506.00066", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文综述了多智能体大语言模型（MA-LLMs）的研究，比较了多智能体与传统单智能体在解决复杂任务上的表现，探讨了智能体配置、通信结构和决策过程对性能的影响。", "motivation": "解决多智能体大语言模型研究领域缺乏直接比较的问题，以及如何通过优化智能体配置、通信结构和决策过程来提高MA-LLMs的性能。", "method": "通过综合传统多智能体系统和最新MA-LLM研究，分析智能体配置、通信结构和决策过程对性能的影响。", "result": "多智能体方法在解决复杂任务上表现更优，但也面临计算成本高和MA-LLM特有挑战未被充分探索的问题。", "conclusion": "多智能体AI解决方案在性能上有优势，但需进一步研究以降低计算成本和解决特有挑战，为研究和实践提供了发展方向。"}}
{"id": "2506.00986", "title": "Talking to Data: Designing Smart Assistants for Humanities Databases", "authors": ["Alexander Sergeev", "Valeriya Goloviznina", "Mikhail Melnichenko", "Evgeny Kotelnikov"], "abstract": "Access to humanities research databases is often hindered by the limitations of traditional interaction formats, particularly in the methods of searching and response generation. This study introduces an LLM-based smart assistant designed to facilitate natural language communication with digital humanities data. The assistant, developed in a chatbot format, leverages the RAG approach and integrates state-of-the-art technologies such as hybrid search, automatic query generation, text-to-SQL filtering, semantic database search, and hyperlink insertion. To evaluate the effectiveness of the system, experiments were conducted to assess the response quality of various language models. The testing was based on the Prozhito digital archive, which contains diary entries from predominantly Russian-speaking individuals who lived in the 20th century. The chatbot is tailored to support anthropology and history researchers, as well as non-specialist users with an interest in the field, without requiring prior technical training. By enabling researchers to query complex databases with natural language, this tool aims to enhance accessibility and efficiency in humanities research. The study highlights the potential of Large Language Models to transform the way researchers and the public interact with digital archives, making them more intuitive and inclusive. Additional materials are presented in GitHub repository:", "subjects": "Computation and Language (cs.CL)", "comments": "Accepted for InterSys-2025 conference", "pdf_url": "https://arxiv.org/pdf/2506.00986.pdf", "abstract_url": "https://arxiv.org/abs/2506.00986", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本研究介绍了一种基于LLM的智能助手，旨在通过自然语言与数字人文数据进行交流，提高人文研究数据库的可访问性和效率。", "motivation": "传统交互格式在搜索和响应生成方面的限制阻碍了人文研究数据库的访问。", "method": "开发了一个聊天机器人格式的助手，利用RAG方法并整合了混合搜索、自动查询生成、文本到SQL过滤、语义数据库搜索和超链接插入等技术。", "result": "实验评估了不同语言模型的响应质量，展示了大型语言模型在改变研究人员和公众与数字档案交互方式方面的潜力。", "conclusion": "该工具旨在增强人文研究的可访问性和效率，使数字档案更加直观和包容。"}}
{"id": "2506.00083", "title": "Hi-Dyna Graph: Hierarchical Dynamic Scene Graph for Robotic Autonomy in Human-Centric Environments", "authors": ["Jiawei Hou", "Xiangyang Xue", "Taiping Zeng"], "abstract": "Autonomous operation of service robotics in human-centric scenes remains challenging due to the need for understanding of changing environments and context-aware decision-making. While existing approaches like topological maps offer efficient spatial priors, they fail to model transient object relationships, whereas dense neural representations (e.g., NeRF) incur prohibitive computational costs. Inspired by the hierarchical scene representation and video scene graph generation works, we propose Hi-Dyna Graph, a hierarchical dynamic scene graph architecture that integrates persistent global layouts with localized dynamic semantics for embodied robotic autonomy. Our framework constructs a global topological graph from posed RGB-D inputs, encoding room-scale connectivity and large static objects (e.g., furniture), while environmental and egocentric cameras populate dynamic subgraphs with object position relations and human-object interaction patterns. A hybrid architecture is conducted by anchoring these subgraphs to the global topology using semantic and spatial constraints, enabling seamless updates as the environment evolves. An agent powered by large language models (LLMs) is employed to interpret the unified graph, infer latent task triggers, and generate executable instructions grounded in robotic affordances. We conduct complex experiments to demonstrate Hi-Dyna Grap's superior scene representation effectiveness. Real-world deployments validate the system's practicality with a mobile manipulator: robotics autonomously complete complex tasks with no further training or complex rewarding in a dynamic scene as cafeteria assistant. See", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.00083.pdf", "abstract_url": "https://arxiv.org/abs/2506.00083", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了Hi-Dyna Graph，一种层次动态场景图架构，旨在通过整合持久的全局布局和局部动态语义，提升服务机器人在以人为中心环境中的自主操作能力。", "motivation": "服务机器人在以人为中心的环境中自主操作面临挑战，需要理解变化的环境和上下文感知决策。现有方法如拓扑地图无法建模瞬态对象关系，而密集神经表示（如NeRF）计算成本过高。", "method": "提出Hi-Dyna Graph，通过构建全局拓扑图和动态子图，结合语义和空间约束，实现场景的无缝更新。利用大型语言模型（LLMs）代理解释统一图，推断潜在任务触发器，并生成基于机器人能力的可执行指令。", "result": "复杂实验证明了Hi-Dyna Graph在场景表示上的优越性。实际部署验证了系统在动态场景中的实用性，如移动机械臂自主完成复杂任务。", "conclusion": "Hi-Dyna Graph通过层次动态场景图架构，有效支持机器人在动态环境中的自主操作，展示了在实际应用中的潜力和实用性。"}}
{"id": "2506.01062", "title": "SealQA: Raising the Bar for Reasoning in Search-Augmented Language Models", "authors": ["Thinh Pham", "Nguyen Nguyen", "Pratibha Zunjare", "Weiyuan Chen", "Yu-Min Tseng", "Tu Vu"], "abstract": "We introduce SealQA, a new challenge benchmark for evaluating SEarch-Augmented Language models on fact-seeking questions where web search yields conflicting, noisy, or unhelpful results. SealQA comes in three flavors: (1) Seal-0 (main) and (2) Seal-Hard, which assess factual accuracy and reasoning capabilities, with Seal-0 focusing on the most challenging questions where chat models (e.g., GPT-4.1) typically achieve near-zero accuracy; and (3) LongSeal, which extends SealQA to test long-context, multi-document reasoning in \"needle-in-a-haystack\" settings. Our evaluation reveals critical limitations in current models: Even frontier LLMs perform poorly across all SealQA flavors. On Seal-0, frontier agentic models equipped with tools like o3 and o4-mini achieve only 17.1% and 6.3% accuracy, respectively, at their best reasoning efforts. We find that advanced reasoning models such as DeepSeek-R1-671B and o3-mini are highly vulnerable to noisy search results. Notably, increasing test-time compute does not yield reliable gains across o3-mini, o4-mini, and o3, with performance often plateauing or even declining early. Additionally, while recent models are less affected by the \"lost-in-the-middle\" issue, they still fail to reliably identify relevant documents in LongSeal when faced with numerous distractors. To facilitate future work, we release SealQA at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "Preprint. 22 pages, 7 figures, 11 tables", "pdf_url": "https://arxiv.org/pdf/2506.01062.pdf", "abstract_url": "https://arxiv.org/abs/2506.01062", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "SealQA是一个新的挑战基准，用于评估搜索增强语言模型在事实寻求问题上的表现，特别是在网络搜索结果冲突、嘈杂或无帮助的情况下。它包括Seal-0、Seal-Hard和LongSeal三个版本，分别测试事实准确性、推理能力和长上下文多文档推理。评估显示，即使是最先进的LLM在SealQA上的表现也很差，尤其是在面对嘈杂搜索结果时。", "motivation": "解决当前搜索增强语言模型在处理事实寻求问题时，面对网络搜索结果的冲突、嘈杂或无帮助情况下的推理能力不足的问题。", "method": "引入了SealQA基准，包括Seal-0、Seal-Hard和LongSeal三个版本，分别针对不同的挑战设计，用于评估模型的事实准确性、推理能力和长上下文多文档推理能力。", "result": "评估结果显示，即使是前沿的LLM在SealQA上的表现也很差，特别是在面对嘈杂搜索结果时。增加测试时的计算资源并不能可靠地提高性能，性能往往早期就达到平台期或下降。", "conclusion": "SealQA揭示了当前搜索增强语言模型在处理复杂事实寻求问题时的关键限制，为未来的研究提供了方向和基准。"}}
{"id": "2506.00131", "title": "Adapting Offline Reinforcement Learning with Online Delays", "authors": ["Simon Sinong Zhan", "Qingyuan Wu", "Frank Yang", "Xiangyu Shi", "Chao Huang", "Qi Zhu"], "abstract": "Offline-to-online deployment of reinforcement-learning (RL) agents must bridge two gaps: (1) the sim-to-real gap, where real systems add latency and other imperfections not present in simulation, and (2) the interaction gap, where policies trained purely offline face out-of-distribution states during online execution because gathering new interaction data is costly or risky. Agents therefore have to generalize from static, delay-free datasets to dynamic, delay-prone environments. Standard offline RL learns from delay-free logs yet must act under delays that break the Markov assumption and hurt performance. We introduce DT-CORL (Delay-Transformer belief policy Constrained Offline RL), an offline-RL framework built to cope with delayed dynamics at deployment. DT-CORL (i) produces delay-robust actions with a transformer-based belief predictor even though it never sees delayed observations during training, and (ii) is markedly more sample-efficient than naïve history-augmentation baselines. Experiments on D4RL benchmarks with several delay settings show that DT-CORL consistently outperforms both history-augmentation and vanilla belief-based methods, narrowing the sim-to-real latency gap while preserving data efficiency.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.00131.pdf", "abstract_url": "https://arxiv.org/abs/2506.00131", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为DT-CORL的离线强化学习框架，旨在解决在部署过程中遇到的延迟动态问题。通过使用基于transformer的信念预测器，DT-CORL能够在训练期间从未见过延迟观察的情况下产生延迟鲁棒的动作，并且在样本效率上显著优于简单历史增强基线。", "motivation": "解决离线强化学习在在线部署时面临的两个主要问题：模拟到现实的差距和交互差距，特别是在延迟动态环境下保持性能和数据效率。", "method": "引入了DT-CORL框架，该框架结合了基于transformer的信念预测器和约束离线强化学习，以应对部署时的延迟问题。", "result": "在D4RL基准测试中，DT-CORL在多种延迟设置下均优于历史增强和基于信念的基线方法，有效缩小了模拟到现实的延迟差距。", "conclusion": "DT-CORL框架通过其独特的信念预测器和约束学习方法，为离线强化学习在动态延迟环境中的应用提供了一种高效且鲁棒的解决方案。"}}
{"id": "2506.00133", "title": "A Reinforcement Learning-Based Telematic Routing Protocol for the Internet of Underwater Things", "authors": ["Mohammadhossein Homaei", "Mehran Tarif", "Agustin Di Bartolo", "Oscar Mogollon Gutierrez", "Mar Avila"], "abstract": "The Internet of Underwater Things (IoUT) faces major challenges such as low bandwidth, high latency, mobility, and limited energy resources. Traditional routing protocols like RPL, which were designed for land-based networks, do not perform well in these underwater conditions. This paper introduces RL-RPL-UA, a new routing protocol that uses reinforcement learning to improve performance in underwater environments. Each node includes a lightweight RL agent that selects the best parent node based on local information such as packet delivery ratio, buffer level, link quality, and remaining energy. RL-RPL-UA keeps full compatibility with standard RPL messages and adds a dynamic objective function to support real-time decision-making. Simulations using Aqua-Sim show that RL-RPL-UA increases packet delivery by up to 9.2%, reduces energy use per packet by 14.8%, and extends network lifetime by 80 seconds compared to traditional methods. These results suggest that RL-RPL-UA is a promising and energy-efficient routing solution for underwater networks.", "subjects": "Networking and Internet Architecture (cs.NI); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "8 Pages, 10 Figures, 2 Tables", "pdf_url": "https://arxiv.org/pdf/2506.00133.pdf", "abstract_url": "https://arxiv.org/abs/2506.00133", "categories": ["Networking and Internet Architecture (cs.NI)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一种基于强化学习的IoUT路由协议RL-RPL-UA，旨在解决水下网络中的低带宽、高延迟、移动性和有限能源等挑战。", "motivation": "传统路由协议如RPL在陆地网络中表现良好，但在水下环境中性能不佳。IoUT面临低带宽、高延迟、移动性和有限能源等主要挑战。", "method": "RL-RPL-UA协议在每个节点中嵌入轻量级强化学习代理，根据本地信息（如包交付率、缓冲区水平、链路质量和剩余能量）选择最佳父节点，同时保持与标准RPL消息的完全兼容性，并添加动态目标函数以支持实时决策。", "result": "使用Aqua-Sim进行的模拟显示，RL-RPL-UA相比传统方法，包交付率提高了9.2%，每包能耗降低了14.8%，网络寿命延长了80秒。", "conclusion": "结果表明，RL-RPL-UA是一种有前途且能源高效的水下网络路由解决方案。"}}
{"id": "2506.00138", "title": "Autonomous Behavior and Whole-Brain Dynamics Emerge in Embodied Zebrafish Agents with Model-based Intrinsic Motivation", "authors": ["Reece Keller", "Alyn Tornell", "Felix Pei", "Xaq Pitkow", "Leo Kozachkov", "Aran Nayebi"], "abstract": "Autonomy is a hallmark of animal intelligence, enabling adaptive and intelligent behavior in complex environments without relying on external reward or task structure. Existing reinforcement learning approaches to exploration in sparse reward and reward-free environments, including class of methods known as intrinsic motivation, exhibit inconsistent exploration patterns and thus fail to produce robust autonomous behaviors observed in animals. Moreover, systems neuroscience has largely overlooked the neural basis of autonomy, focusing instead on experimental paradigms where animals are motivated by external reward rather than engaging in unconstrained, naturalistic and task-independent behavior. To bridge these gaps, we introduce a novel model-based intrinsic drive explicitly designed to capture robust autonomous exploration observed in animals. Our method (3M-Progress) motivates naturalistic behavior by tracking divergence between the agent's current world model and an ethological prior. We demonstrate that artificial embodied agents trained with 3M-Progress capture the explainable variance in behavioral patterns and whole-brain neural-glial dynamics recorded from autonomously-behaving larval zebrafish, introducing the first goal-driven, population-level model of neural-glial computation. Our findings establish a computational framework connecting model-based intrinsic motivation to naturalistic behavior, providing a foundation for building artificial agents with animal-like autonomy.", "subjects": "Neurons and Cognition (q-bio.NC); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)", "comments": "17 pages, 7 figures", "pdf_url": "https://arxiv.org/pdf/2506.00138.pdf", "abstract_url": "https://arxiv.org/abs/2506.00138", "categories": ["Neurons and Cognition (q-bio.NC)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一种新型的基于模型的内在驱动力方法（3M-Progress），旨在捕捉动物中观察到的稳健自主探索行为。通过在人工体现的代理中应用该方法，成功模拟了自主行为幼鱼的行为模式和全脑神经-胶质动态，为构建具有动物般自主性的人工代理提供了计算框架。", "motivation": "解决现有强化学习方法在稀疏奖励和无奖励环境中探索行为不一致，无法产生动物观察到的稳健自主行为的问题，并填补系统神经科学在自主性神经基础研究上的空白。", "method": "提出了一种新颖的基于模型的内在驱动力（3M-Progress），通过跟踪代理当前世界模型与生态先验之间的差异来激励自然行为。", "result": "应用3M-Progress训练的代理成功捕捉了自主行为幼鱼的行为模式和全脑神经-胶质动态的可解释方差，首次提出了目标驱动的神经-胶质计算群体模型。", "conclusion": "研究成果为连接基于模型的内在动机与自然行为提供了计算框架，为构建具有动物般自主性的人工代理奠定了基础。"}}
{"id": "2506.00727", "title": "Adaptive Plane Reformatting for 4D Flow MRI using Deep Reinforcement Learning", "authors": ["Javier Bisbal", "Julio Sotelo", "Maria I Valdés", "Pablo Irarrazaval", "Marcelo E Andia", "Julio García", "José Rodriguez-Palomarez", "Francesca Raimondi", "Cristián Tejos", "Sergio Uribe"], "abstract": "Deep reinforcement learning (DRL) algorithms have shown robust results in plane reformatting tasks. In these methods, an agent sequentially adjusts the position and orientation of an initial plane towards an objective location. This process allows accurate plane reformatting, without the need for detailed landmarks, which makes it suitable for images with limited contrast and resolution, such as 4D flow MRI. However, current DRL methods require the test dataset to be in the same position and orientation as the training dataset. In this paper, we present a novel technique that utilizes a flexible coordinate system based on the current state, enabling navigation in volumes at any position or orientation. We adopted the Asynchronous Advantage Actor Critic (A3C) algorithm for reinforcement learning, outperforming Deep Q Network (DQN). Experimental results in 4D flow MRI demonstrate improved accuracy in plane reformatting angular and distance errors (6.32 +- 4.15 ° and 3.40 +- 2.75 mm), as well as statistically equivalent flow measurements determined by a plane reformatting process done by an expert (p=0.21). The method's flexibility and adaptability make it a promising candidate for other medical imaging applications beyond 4D flow MRI.", "subjects": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV)", "comments": "11 pages, 4 figures, submitted to IEEE Transactions on Medical Imaging", "pdf_url": "https://arxiv.org/pdf/2506.00727.pdf", "abstract_url": "https://arxiv.org/abs/2506.00727", "categories": ["Machine Learning (cs.LG)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于深度强化学习（DRL）的自适应平面重格式化技术，用于4D流MRI，通过灵活的坐标系和A3C算法，提高了平面重格式化的准确性和适应性。", "motivation": "解决当前深度强化学习方法在测试数据集与训练数据集位置和方向不一致时无法有效工作的问题，特别是在对比度和分辨率有限的4D流MRI图像中。", "method": "采用基于当前状态的灵活坐标系和Asynchronous Advantage Actor Critic (A3C)算法，实现对任何位置或方向体积的导航。", "result": "在4D流MRI中，平面重格式化的角度和距离误差（6.32 +- 4.15 °和3.40 +- 2.75 mm）得到改善，且与专家操作的平面重格式化过程在流量测量上统计等效（p=0.21）。", "conclusion": "该方法在4D流MRI中表现出色，其灵活性和适应性使其成为其他医学成像应用的有力候选。"}}
{"id": "2506.00555", "title": "MMedAgent-RL: Optimizing Multi-Agent Collaboration for Multimodal Medical Reasoning", "authors": ["Peng Xia", "Jinglu Wang", "Yibo Peng", "Kaide Zeng", "Xian Wu", "Xiangru Tang", "Hongtu Zhu", "Yun Li", "Shujie Liu", "Yan Lu", "Huaxiu Yao"], "abstract": "Medical Large Vision-Language Models (Med-LVLMs) have shown strong potential in multimodal diagnostic tasks. However, existing single-agent models struggle to generalize across diverse medical specialties, limiting their performance. Recent efforts introduce multi-agent collaboration frameworks inspired by clinical workflows, where general practitioners (GPs) and specialists interact in a fixed sequence. Despite improvements, these static pipelines lack flexibility and adaptability in reasoning. To address this, we propose MMedAgent-RL, a reinforcement learning (RL)-based multi-agent framework that enables dynamic, optimized collaboration among medical agents. Specifically, we train two GP agents based on Qwen2.5-VL via RL: the triage doctor learns to assign patients to appropriate specialties, while the attending physician integrates the judgments from multi-specialists and its own knowledge to make final decisions. To address the inconsistency in specialist outputs, we introduce a curriculum learning (CL)-guided RL strategy that progressively teaches the attending physician to balance between imitating specialists and correcting their mistakes. Experiments on five medical VQA benchmarks demonstrate that MMedAgent-RL not only outperforms both open-source and proprietary Med-LVLMs, but also exhibits human-like reasoning patterns. Notably, it achieves an average performance gain of 18.4% over supervised fine-tuning baselines.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.00555.pdf", "abstract_url": "https://arxiv.org/abs/2506.00555", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "MMedAgent-RL是一种基于强化学习的多智能体框架，旨在优化医疗多模态推理中的多智能体协作。通过训练两个基于Qwen2.5-VL的GP智能体，并使用课程学习引导的强化学习策略，该框架在五个医疗VQA基准测试中表现出色，性能平均提升18.4%。", "motivation": "现有的单智能体医疗大型视觉语言模型（Med-LVLMs）在多样化医疗专业中的泛化能力有限，且现有的多智能体协作框架缺乏灵活性和适应性。", "method": "提出MMedAgent-RL框架，通过强化学习训练两个GP智能体：分诊医生学习将患者分配给适当的专业，主治医师则整合多专业判断和自身知识做出最终决策。采用课程学习引导的强化学习策略解决专业输出不一致问题。", "result": "在五个医疗VQA基准测试中，MMedAgent-RL不仅优于开源和专有的Med-LVLMs，还展现出类似人类的推理模式，平均性能提升18.4%。", "conclusion": "MMedAgent-RL通过动态优化的多智能体协作，显著提高了医疗多模态推理的性能和灵活性，展现出在医疗诊断任务中的强大潜力。"}}
{"id": "2506.01392", "title": "Sparse Imagination for Efficient Visual World Model Planning", "authors": ["Junha Chun", "Youngjoon Jeong", "Taesup Kim"], "abstract": "World model based planning has significantly improved decision-making in complex environments by enabling agents to simulate future states and make informed choices. However, ensuring the prediction accuracy of world models often demands substantial computational resources, posing a major challenge for real-time applications. This computational burden is particularly restrictive in robotics, where resources are severely constrained. To address this limitation, we propose a Sparse Imagination for Efficient Visual World Model Planning, which enhances computational efficiency by reducing the number of tokens processed during forward prediction. Our method leverages a sparsely trained vision-based world model based on transformers with randomized grouped attention strategy, allowing the model to adaptively adjust the number of tokens processed based on the computational resource. By enabling sparse imagination (rollout), our approach significantly accelerates planning while maintaining high control fidelity. Experimental results demonstrate that sparse imagination preserves task performance while dramatically improving inference efficiency, paving the way for the deployment of world models in real-time decision-making scenarios.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.01392.pdf", "abstract_url": "https://arxiv.org/abs/2506.01392", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种稀疏想象的高效视觉世界模型规划方法，旨在通过减少前向预测中处理的令牌数量来提高计算效率，同时保持高控制保真度。", "motivation": "世界模型基于规划的决策制定在复杂环境中显著提高了效率，但预测准确性要求大量计算资源，这在资源受限的机器人技术中尤为突出。", "method": "采用基于变换器的稀疏训练视觉世界模型，结合随机分组注意力策略，使模型能根据计算资源自适应调整处理的令牌数量。", "result": "实验结果表明，稀疏想象在保持任务性能的同时，显著提高了推理效率。", "conclusion": "该方法为世界模型在实时决策场景中的部署铺平了道路，通过稀疏想象加速规划，同时保持高控制保真度。"}}
{"id": "2506.01334", "title": "Enhancing Interpretable Image Classification Through LLM Agents and Conditional Concept Bottleneck Models", "authors": ["Yiwen Jiang", "Deval Mehta", "Wei Feng", "Zongyuan Ge"], "abstract": "Concept Bottleneck Models (CBMs) decompose image classification into a process governed by interpretable, human-readable concepts. Recent advances in CBMs have used Large Language Models (LLMs) to generate candidate concepts. However, a critical question remains: What is the optimal number of concepts to use? Current concept banks suffer from redundancy or insufficient coverage. To address this issue, we introduce a dynamic, agent-based approach that adjusts the concept bank in response to environmental feedback, optimizing the number of concepts for sufficiency yet concise coverage. Moreover, we propose Conditional Concept Bottleneck Models (CoCoBMs) to overcome the limitations in traditional CBMs' concept scoring mechanisms. It enhances the accuracy of assessing each concept's contribution to classification tasks and feature an editable matrix that allows LLMs to correct concept scores that conflict with their internal knowledge. Our evaluations across 6 datasets show that our method not only improves classification accuracy by 6% but also enhances interpretability assessments by 30%.", "subjects": "Computation and Language (cs.CL)", "comments": "Accepted at ACL 2025 (Main)", "pdf_url": "https://arxiv.org/pdf/2506.01334.pdf", "abstract_url": "https://arxiv.org/abs/2506.01334", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种通过LLM代理和条件概念瓶颈模型增强可解释图像分类的方法，动态调整概念库以优化概念数量，并引入条件概念瓶颈模型改进概念评分机制，提高了分类准确性和可解释性评估。", "motivation": "解决概念瓶颈模型在图像分类中使用的最优概念数量问题以及传统概念评分机制的局限性。", "method": "采用动态代理方法调整概念库，引入条件概念瓶颈模型（CoCoBMs）改进概念评分，并允许LLM修正冲突的概念评分。", "result": "在6个数据集上的评估显示，该方法不仅将分类准确性提高了6%，还将可解释性评估提高了30%。", "conclusion": "提出的方法有效优化了概念库的大小和概念评分机制，显著提升了图像分类的准确性和可解释性。"}}
{"id": "2506.00281", "title": "Adversarial Threat Vectors and Risk Mitigation for Retrieval-Augmented Generation Systems", "authors": ["Chris M. Ward", "Josh Harguess"], "abstract": "Retrieval-Augmented Generation (RAG) systems, which integrate Large Language Models (LLMs) with external knowledge sources, are vulnerable to a range of adversarial attack vectors. This paper examines the importance of RAG systems through recent industry adoption trends and identifies the prominent attack vectors for RAG: prompt injection, data poisoning, and adversarial query manipulation. We analyze these threats under risk management lens, and propose robust prioritized control list that includes risk-mitigating actions like input validation, adversarial training, and real-time monitoring.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": "SPIE DCS: Proceedings Volume Assurance and Security for AI-enabled Systems 2025", "pdf_url": "https://arxiv.org/pdf/2506.00281.pdf", "abstract_url": "https://arxiv.org/abs/2506.00281", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文探讨了检索增强生成（RAG）系统面临的对抗性威胁向量及风险缓解策略。RAG系统结合了大型语言模型（LLMs）与外部知识源，但易受提示注入、数据毒害和对抗性查询操纵等攻击。研究通过风险管理视角分析这些威胁，并提出了包括输入验证、对抗性训练和实时监控在内的风险缓解措施。", "motivation": "随着检索增强生成（RAG）系统在业界的广泛应用，其安全性问题日益突出。本文旨在识别和分析RAG系统面临的主要对抗性攻击向量，并提出有效的风险缓解策略，以保障系统的安全和可靠运行。", "method": "研究通过分析行业采用趋势，识别了RAG系统的主要攻击向量，并采用风险管理的方法对这些威胁进行了深入分析。基于分析结果，提出了一系列风险缓解措施，包括技术和管理两个层面的控制策略。", "result": "研究确定了RAG系统面临的三大主要威胁：提示注入、数据毒害和对抗性查询操纵。针对这些威胁，提出了一套优先控制清单，包括输入验证、对抗性训练和实时监控等措施，以有效降低系统风险。", "conclusion": "本文强调了RAG系统安全性的重要性，并提出了一套全面的风险缓解策略。这些策略不仅有助于提升RAG系统的抗攻击能力，也为未来的研究和实践提供了有价值的参考。"}}
{"id": "2506.01418", "title": "SEMNAV: A Semantic Segmentation-Driven Approach to Visual Semantic Navigation", "authors": ["Rafael Flor-Rodríguez", "Carlos Gutiérrez-Álvarez", "Francisco Javier Acevedo-Rodríguez", "Sergio Lafuente-Arroyo", "Roberto J. López-Sastre"], "abstract": "Visual Semantic Navigation (VSN) is a fundamental problem in robotics, where an agent must navigate toward a target object in an unknown environment, mainly using visual information. Most state-of-the-art VSN models are trained in simulation environments, where rendered scenes of the real world are used, at best. These approaches typically rely on raw RGB data from the virtual scenes, which limits their ability to generalize to real-world environments due to domain adaptation issues. To tackle this problem, in this work, we propose SEMNAV, a novel approach that leverages semantic segmentation as the main visual input representation of the environment to enhance the agent's perception and decision-making capabilities. By explicitly incorporating high-level semantic information, our model learns robust navigation policies that improve generalization across unseen environments, both in simulated and real world settings. We also introduce a newly curated dataset, i.e. the SEMNAV dataset, designed for training semantic segmentation-aware navigation models like SEMNAV. Our approach is evaluated extensively in both simulated environments and with real-world robotic platforms. Experimental results demonstrate that SEMNAV outperforms existing state-of-the-art VSN models, achieving higher success rates in the Habitat 2.0 simulation environment, using the HM3D dataset. Furthermore, our real-world experiments highlight the effectiveness of semantic segmentation in mitigating the sim-to-real gap, making our model a promising solution for practical VSN-based robotic applications. We release SEMNAV dataset, code and trained models at", "subjects": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.01418.pdf", "abstract_url": "https://arxiv.org/abs/2506.01418", "categories": ["Robotics (cs.RO)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "SEMNAV是一种新颖的视觉语义导航方法，通过利用语义分割作为环境的主要视觉输入表示，增强代理的感知和决策能力，以提高在未见环境中的泛化能力。", "motivation": "解决现有视觉语义导航模型因依赖原始RGB数据而难以泛化到真实世界环境的问题。", "method": "采用语义分割作为主要视觉输入，并结合新创建的SEMNAV数据集训练模型。", "result": "在Habitat 2.0模拟环境和真实世界机器人平台上，SEMNAV的表现优于现有最先进的VSN模型，成功率高。", "conclusion": "SEMNAV通过语义分割有效减少了模拟到现实的差距，为实际的VSN机器人应用提供了有前景的解决方案。"}}
{"id": "2506.00286", "title": "Entropic Risk Optimization in Discounted MDPs: Sample Complexity Bounds with a Generative Model", "authors": ["Oliver Mortensen", "Mohammad Sadegh Talebi"], "abstract": "In this paper we analyze the sample complexities of learning the optimal state-action value function $Q^*$ and an optimal policy $\\pi^*$ in a discounted Markov decision process (MDP) where the agent has recursive entropic risk-preferences with risk-parameter $\\beta\\neq 0$ and where a generative model of the MDP is available. We provide and analyze a simple model based approach which we call model-based risk-sensitive $Q$-value-iteration (MB-RS-QVI) which leads to $(\\epsilon,\\delta)$-PAC-bounds on $\\|Q^*-Q^k\\|$, and $\\|V^*-V^{\\pi_k}\\|$ where $Q_k$ is the output of MB-RS-QVI after k iterations and $\\pi_k$ is the greedy policy with respect to $Q_k$. Both PAC-bounds have exponential dependence on the effective horizon $\\frac{1}{1-\\gamma}$ and the strength of this dependence grows with the learners risk-sensitivity $|\\beta|$. We also provide two lower bounds which shows that exponential dependence on $|\\beta|\\frac{1}{1-\\gamma}$ is unavoidable in both cases. The lower bounds reveal that the PAC-bounds are both tight in $\\varepsilon$ and $\\delta$ and that the PAC-bound on $Q$-learning is tight in the number of actions $A$, and that the PAC-bound on policy-learning is nearly tight in $A$.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Optimization and Control (math.OC); Machine Learning (stat.ML)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.00286.pdf", "abstract_url": "https://arxiv.org/abs/2506.00286", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Optimization and Control (math.OC)", "Machine Learning (stat.ML)"], "matching_keywords": ["agent"], "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.01344", "title": "Follow the Flow: Fine-grained Flowchart Attribution with Neurosymbolic Agents", "authors": ["Manan Suri", "Puneet Mathur", "Nedim Lipka", "Franck Dernoncourt", "Ryan A. Rossi", "Vivek Gupta", "Dinesh Manocha"], "abstract": "Flowcharts are a critical tool for visualizing decision-making processes. However, their non-linear structure and complex visual-textual relationships make it challenging to interpret them using LLMs, as vision-language models frequently hallucinate nonexistent connections and decision paths when analyzing these diagrams. This leads to compromised reliability for automated flowchart processing in critical domains such as logistics, health, and engineering. We introduce the task of Fine-grained Flowchart Attribution, which traces specific components grounding a flowchart referring LLM response. Flowchart Attribution ensures the verifiability of LLM predictions and improves explainability by linking generated responses to the flowchart's structure. We propose FlowPathAgent, a neurosymbolic agent that performs fine-grained post hoc attribution through graph-based reasoning. It first segments the flowchart, then converts it into a structured symbolic graph, and then employs an agentic approach to dynamically interact with the graph, to generate attribution paths. Additionally, we present FlowExplainBench, a novel benchmark for evaluating flowchart attributions across diverse styles, domains, and question types. Experimental results show that FlowPathAgent mitigates visual hallucinations in LLM answers over flowchart QA, outperforming strong baselines by 10-14% on our proposed FlowExplainBench dataset.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.01344.pdf", "abstract_url": "https://arxiv.org/abs/2506.01344", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了细粒度流程图归因任务，提出了FlowPathAgent这一神经符号代理，用于通过基于图的推理进行细粒度的事后归因，以减少LLM在处理流程图时的视觉幻觉问题。", "motivation": "流程图是可视化决策过程的关键工具，但其非线性的结构和复杂的视觉-文本关系使得使用LLM解释它们具有挑战性，经常导致视觉幻觉，影响在物流、健康和工程等关键领域中的自动化流程图处理的可靠性。", "method": "提出了FlowPathAgent，一个神经符号代理，它首先分割流程图，然后将其转换为结构化的符号图，最后采用代理方法动态与图交互，生成归因路径。", "result": "实验结果表明，FlowPathAgent在流程图QA中减少了LLM答案的视觉幻觉，在提出的FlowExplainBench数据集上比强基线高出10-14%。", "conclusion": "FlowPathAgent通过细粒度的事后归因提高了LLM预测的可验证性和可解释性，为流程图处理提供了一种可靠的方法。"}}
{"id": "2506.00411", "title": "LoHoVLA: A Unified Vision-Language-Action Model for Long-Horizon Embodied Tasks", "authors": ["Yi Yang", "Jiaxuan Sun", "Siqi Kou", "Yihan Wang", "Zhijie Deng"], "abstract": "Real-world embodied agents face long-horizon tasks, characterized by high-level goals demanding multi-step solutions beyond single actions. Successfully navigating these requires both high-level task planning (i.e., decomposing goals into sub-tasks) and low-level motion control (i.e., generating precise robot actions). While existing vision language action (VLA) models and hierarchical architectures offer potential in embodied tasks, the former often falter in planning, and the latter can suffer from coordination issues, both hampering performance. We introduce a new unified VLA framework for long-horizon tasks, dubbed LoHoVLA, to overcome these limitations. LoHoVLA leverages a large pretrained vision language model (VLM) as the backbone to jointly generate language and action tokens for sub-task generation and robot action prediction, respectively. This shared representation promotes better generalization across tasks. Additionally, LoHoVLA embraces a hierarchical closed-loop control mechanism to mitigate errors originating from both high-level planning and low-level control. To train LoHoVLA, we introduce LoHoSet, a dataset built on the Ravens simulator, containing 20 long-horizon tasks, each with 1,000 expert demonstrations composed of visual observations, linguistic goals, sub-tasks, and robot actions. Experimental results show that LoHoVLA significantly surpasses both hierarchical and standard VLA approaches on long-horizon embodied tasks in the Ravens simulator. These findings underscore the promise of unified architectures for advancing generalizable embodied intelligence.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.00411.pdf", "abstract_url": "https://arxiv.org/abs/2506.00411", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "LoHoVLA是一个统一的视觉-语言-动作模型，专为长视野的具身任务设计，通过结合高级任务规划和低级运动控制，以及分层闭环控制机制，显著提高了在长视野任务中的表现。", "motivation": "解决现有视觉语言动作（VLA）模型在规划和分层架构在协调方面的不足，以更好地完成长视野的具身任务。", "method": "利用大型预训练的视觉语言模型（VLM）作为骨干，共同生成语言和动作令牌，用于子任务生成和机器人动作预测，并采用分层闭环控制机制以减少错误。", "result": "LoHoVLA在Ravens模拟器中的长视野具身任务上显著优于分层和标准VLA方法。", "conclusion": "统一架构在推进可泛化的具身智能方面显示出巨大潜力。"}}
{"id": "2506.01520", "title": "FormFactory: An Interactive Benchmarking Suite for Multimodal Form-Filling Agents", "authors": ["Bobo Li", "Yuheng Wang", "Hao Fei", "Juncheng Li", "Wei Ji", "Mong-Li Lee", "Wynne Hsu"], "abstract": "Online form filling is a common yet labor-intensive task involving extensive keyboard and mouse interactions. Despite the long-standing vision of automating this process with \"one click\", existing tools remain largely rule-based and lack generalizable, generative capabilities. Recent advances in Multimodal Large Language Models (MLLMs) have enabled promising agents for GUI-related tasks in general-purpose scenarios. However, they struggle with the unique challenges of form filling, such as flexible layouts and the difficulty of aligning textual instructions with on-screen fields. To bridge this gap, we formally define the form-filling task and propose FormFactory, an interactive benchmarking suite comprising a web-based interface, backend evaluation module, and carefully constructed dataset. Our benchmark covers diverse real-world scenarios, incorporates various field formats, and simulates high-fidelity form interactions. We conduct a comprehensive evaluation of state-of-the-art MLLMs and observe that no model surpasses 5% accuracy, underscoring the inherent difficulty of the task. These findings also reveal significant limitations in current models' visual layout reasoning and field-value alignment abilities. We hope our benchmark can serve as a stepping stone for further research into robust, practical form-filling agents.", "subjects": "Computation and Language (cs.CL)", "comments": "8 pages, 7 figures", "pdf_url": "https://arxiv.org/pdf/2506.01520.pdf", "abstract_url": "https://arxiv.org/abs/2506.01520", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了FormFactory，一个用于多模态表单填写代理的交互式基准测试套件，旨在解决在线表单填写的自动化问题。", "motivation": "在线表单填写是一项常见但劳动密集型的任务，现有的自动化工具大多基于规则，缺乏通用性和生成能力。多模态大型语言模型（MLLMs）在GUI相关任务中显示出潜力，但在表单填写任务中面临布局灵活性和文本指令与屏幕字段对齐的挑战。", "method": "作者正式定义了表单填写任务，并提出了FormFactory，一个包含基于Web的界面、后端评估模块和精心构建的数据集的交互式基准测试套件。", "result": "对最先进的MLLMs进行的全面评估显示，没有模型的准确率超过5%，揭示了当前模型在视觉布局推理和字段值对齐能力上的重大限制。", "conclusion": "FormFactory基准测试套件可以作为进一步研究强大、实用的表单填写代理的垫脚石。"}}
{"id": "2506.01531", "title": "STORM-BORN: A Challenging Mathematical Derivations Dataset Curated via a Human-in-the-Loop Multi-Agent Framework", "authors": ["Wenhao Liu", "Zhenyi Lu", "Xinyu Hu", "Jierui Zhang", "Dailin Li", "Jiacheng Cen", "Huilin Cao", "Haiteng Wang", "Yuhan Li", "Kun Xie", "Dandan Li", "Pei Zhang", "Chengbo Zhang", "Yuxiang Ren", "Xiaohong Huang", "Yan Ma"], "abstract": "High-quality math datasets are crucial for advancing the reasoning abilities of large language models (LLMs). However, existing datasets often suffer from three key issues: outdated and insufficient challenging content, neglecting human-like reasoning, and limited reliability due to single-LLM generation. To address these, we introduce $\\textbf{STORM-BORN}$, an ultra-challenging dataset of mathematical derivations sourced from cutting-edge academic papers, which includes dense human-like approximations and heuristic cues. To ensure the reliability and quality, we propose a novel human-in-the-loop, multi-agent data generation framework, integrating reasoning-dense filters, multi-agent collaboration, and human mathematicians' evaluations. We curated a set of 2,000 synthetic samples and deliberately selected the 100 most difficult problems. Even most advanced models like GPT-o1 solved fewer than $5\\%$ of them. Fine-tuning on STORM-BORN boosts accuracy by $7.84\\%$ (LLaMA3-8B) and $9.12\\%$ (Qwen2.5-7B). As AI approaches mathematician-level reasoning, STORM-BORN provides both a high-difficulty benchmark and a human-like reasoning training resource. Our code and dataset are publicly available at", "subjects": "Computation and Language (cs.CL)", "comments": "accepted by ACL2025", "pdf_url": "https://arxiv.org/pdf/2506.01531.pdf", "abstract_url": "https://arxiv.org/abs/2506.01531", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "STORM-BORN是一个超具挑战性的数学推导数据集，来源于前沿学术论文，包含密集的人类似近似和启发式线索，旨在提升大型语言模型的推理能力。", "motivation": "解决现有数学数据集内容过时、缺乏挑战性、忽视人类似推理以及由于单一LLM生成导致的可靠性有限的问题。", "method": "采用了一种新颖的人类参与循环的多智能体数据生成框架，结合了推理密集过滤器、多智能体协作和人类数学家的评估。", "result": "即使是最先进的模型如GPT-o1，也只能解决不到5%的最难问题。在STORM-BORN上微调后，LLaMA3-8B和Qwen2.5-7B的准确率分别提高了7.84%和9.12%。", "conclusion": "随着AI接近数学家水平的推理能力，STORM-BORN不仅提供了一个高难度的基准，也成为了一个人类似推理的训练资源。"}}
{"id": "2506.00439", "title": "RLAE: Reinforcement Learning-Assisted Ensemble for LLMs", "authors": ["Yuqian Fu", "Yuanheng Zhu", "Jiajun Chai", "Guojun Yin", "Wei Lin", "Qichao Zhang", "Dongbin Zhao"], "abstract": "Ensembling large language models (LLMs) can effectively combine diverse strengths of different models, offering a promising approach to enhance performance across various tasks. However, existing methods typically rely on fixed weighting strategies that fail to adapt to the dynamic, context-dependent characteristics of LLM capabilities. In this work, we propose Reinforcement Learning-Assisted Ensemble for LLMs (RLAE), a novel framework that reformulates LLM ensemble through the lens of a Markov Decision Process (MDP). Our approach introduces a RL agent that dynamically adjusts ensemble weights by considering both input context and intermediate generation states, with the agent being trained using rewards that directly correspond to the quality of final outputs. We implement RLAE using both single-agent and multi-agent reinforcement learning algorithms ($\\text{RLAE}_\\text{PPO}$ and $\\text{RLAE}_\\text{MAPPO}$ ), demonstrating substantial improvements over conventional ensemble methods. Extensive evaluations on a diverse set of tasks show that RLAE outperforms existing approaches by up to $3.3\\%$ accuracy points, offering a more effective framework for LLM ensembling. Furthermore, our method exhibits superior generalization capabilities across different tasks without the need for retraining, while simultaneously achieving lower time latency.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.00439.pdf", "abstract_url": "https://arxiv.org/abs/2506.00439", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为RLAE的新框架，通过强化学习动态调整大型语言模型（LLMs）的集成权重，以适应不同任务的需求，显著提升了模型性能。", "motivation": "现有的LLM集成方法通常采用固定的权重策略，无法适应LLM能力的动态和上下文依赖特性。", "method": "RLAE框架将LLM集成重新定义为马尔可夫决策过程（MDP），引入强化学习代理动态调整集成权重，考虑输入上下文和中间生成状态，并通过与最终输出质量直接相关的奖励进行训练。", "result": "在多种任务上的广泛评估显示，RLAE比现有方法提高了高达3.3%的准确率，提供了更有效的LLM集成框架，并展现出卓越的泛化能力和更低的时间延迟。", "conclusion": "RLAE通过强化学习动态调整集成权重，不仅提高了LLM集成的性能，还实现了跨任务的优越泛化能力，无需重新训练，同时降低了时间延迟。"}}
{"id": "2506.00458", "title": "Reinforcement Learning for Hanabi", "authors": ["Nina Cohen", "Kordel K. France"], "abstract": "Hanabi has become a popular game for research when it comes to reinforcement learning (RL) as it is one of the few cooperative card games where you have incomplete knowledge of the entire environment, thus presenting a challenge for a RL agent. We explored different tabular and deep reinforcement learning algorithms to see which had the best performance both against an agent of the same type and also against other types of agents. We establish that certain agents played their highest scoring games against specific agents while others exhibited higher scores on average by adapting to the opposing agent's behavior. We attempted to quantify the conditions under which each algorithm provides the best advantage and identified the most interesting interactions between agents of different types. In the end, we found that temporal difference (TD) algorithms had better overall performance and balancing of play types compared to tabular agents. Specifically, tabular Expected SARSA and deep Q-Learning agents showed the best performance.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.00458.pdf", "abstract_url": "https://arxiv.org/abs/2506.00458", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computer Science and Game Theory (cs.GT)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了在合作卡牌游戏Hanabi中，不同强化学习算法的表现。研究发现，时序差分（TD）算法在整体性能和玩法平衡上优于表格型算法，特别是表格型Expected SARSA和深度Q学习智能体表现最佳。", "motivation": "Hanabi作为一种具有不完全环境知识的合作卡牌游戏，对强化学习智能体提出了挑战。本研究旨在探索哪种强化学习算法在此类游戏中表现最佳。", "method": "研究比较了不同的表格型和深度强化学习算法，包括时序差分（TD）算法、表格型Expected SARSA和深度Q学习智能体，评估它们在与同类及其他类型智能体对弈时的表现。", "result": "研究发现，时序差分（TD）算法在整体性能和玩法平衡上优于表格型算法。特别是，表格型Expected SARSA和深度Q学习智能体在与特定类型智能体对弈时表现最佳。", "conclusion": "研究表明，在Hanabi这类具有不完全信息的合作游戏中，时序差分（TD）算法，尤其是表格型Expected SARSA和深度Q学习智能体，能够提供最佳的游戏表现和策略平衡。"}}
{"id": "2506.01615", "title": "IndicRAGSuite: Large-Scale Datasets and a Benchmark for Indian Language RAG Systems", "authors": ["Pasunuti Prasanjith", "Prathmesh B More", "Anoop Kunchukuttan", "Raj Dabre"], "abstract": "Retrieval-Augmented Generation (RAG) systems enable language models to access relevant information and generate accurate, well-grounded, and contextually informed responses. However, for Indian languages, the development of high-quality RAG systems is hindered by the lack of two critical resources: (1) evaluation benchmarks for retrieval and generation tasks, and (2) large-scale training datasets for multilingual retrieval. Most existing benchmarks and datasets are centered around English or high-resource languages, making it difficult to extend RAG capabilities to the diverse linguistic landscape of India. To address the lack of evaluation benchmarks, we create IndicMSMarco, a multilingual benchmark for evaluating retrieval quality and response generation in 13 Indian languages, created via manual translation of 1000 diverse queries from MS MARCO-dev set. To address the need for training data, we build a large-scale dataset of (question, answer, relevant passage) tuples derived from the Wikipedias of 19 Indian languages using state-of-the-art LLMs. Additionally, we include translated versions of the original MS MARCO dataset to further enrich the training data and ensure alignment with real-world information-seeking tasks. Resources are available here:", "subjects": "Computation and Language (cs.CL)", "comments": "WIP", "pdf_url": "https://arxiv.org/pdf/2506.01615.pdf", "abstract_url": "https://arxiv.org/abs/2506.01615", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "该论文介绍了IndicRAGSuite，一个为印度语言RAG系统设计的大规模数据集和基准测试，旨在解决印度语言在检索和生成任务中缺乏高质量评估基准和训练数据的问题。", "motivation": "印度语言在开发高质量的检索增强生成（RAG）系统时面临两大障碍：缺乏评估检索和生成任务的基准测试，以及缺乏多语言检索的大规模训练数据集。现有资源主要集中在英语或高资源语言上，难以扩展到印度多样化的语言环境。", "method": "为了解决这些问题，作者创建了IndicMSMarco，一个多语言基准测试，用于评估13种印度语言的检索质量和响应生成，通过手动翻译MS MARCO-dev集中的1000个多样化查询。此外，还利用最先进的LLMs从19种印度语言的维基百科中构建了一个大规模的（问题、答案、相关段落）元组数据集，并包括原始MS MARCO数据集的翻译版本以丰富训练数据。", "result": "IndicRAGSuite提供了评估基准和训练数据集，支持印度语言RAG系统的开发和评估，填补了印度语言在这一领域的资源空白。", "conclusion": "通过提供专门为印度语言设计的基准测试和训练数据集，IndicRAGSuite为开发能够处理印度多样化语言环境的高质量RAG系统奠定了基础，有助于推动多语言信息检索和生成技术的发展。"}}
{"id": "2506.01646", "title": "ESGenius: Benchmarking LLMs on Environmental, Social, and Governance (ESG) and Sustainability Knowledge", "authors": ["Chaoyue He", "Xin Zhou", "Yi Wu", "Xinjia Yu", "Yan Zhang", "Lei Zhang", "Di Wang", "Shengfei Lyu", "Hong Xu", "Xiaoqiao Wang", "Wei Liu", "Chunyan Miao"], "abstract": "We introduce ESGenius, a comprehensive benchmark for evaluating and enhancing the proficiency of Large Language Models (LLMs) in Environmental, Social and Governance (ESG) and sustainability-focused question answering. ESGenius comprises two key components: (i) ESGenius-QA, a collection of 1 136 multiple-choice questions generated by LLMs and rigorously validated by domain experts, covering a broad range of ESG pillars and sustainability topics. Each question is systematically linked to its corresponding source text, enabling transparent evaluation and supporting retrieval-augmented generation (RAG) methods; and (ii) ESGenius-Corpus, a meticulously curated repository of 231 foundational frameworks, standards, reports and recommendation documents from seven authoritative sources. Moreover, to fully assess the capabilities and adaptation potential of the model, we implement a rigorous two-stage evaluation protocol -- Zero-Shot and RAG. Extensive experiments across 50 LLMs (ranging from 0.5 B to 671 B parameters) demonstrate that state-of-the-art models achieve only moderate performance in zero-shot settings, with accuracies typically around 55--70\\%, highlighting ESGenius's challenging nature for LLMs in interdisciplinary contexts. However, models employing RAG show significant performance improvements, particularly for smaller models. For example, \"DeepSeek-R1-Distill-Qwen-14B\" improves from 63.82\\% (zero-shot) to 80.46\\% with RAG. These results underscore the necessity of grounding responses in authoritative sources for enhanced ESG understanding. To the best of our knowledge, ESGenius is the first benchmark curated for LLMs and the relevant enhancement technologies that focuses on ESG and sustainability topics.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "37 pages, 8 figures, 11 tables", "pdf_url": "https://arxiv.org/pdf/2506.01646.pdf", "abstract_url": "https://arxiv.org/abs/2506.01646", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "ESGenius是一个全面的基准测试，旨在评估和提升大型语言模型（LLMs）在环境、社会和治理（ESG）及可持续性问答中的能力。它包括ESGenius-QA和ESGenius-Corpus两部分，并通过零样本和检索增强生成（RAG）两种评估协议测试了50个LLMs的性能。", "motivation": "解决LLMs在ESG和可持续性领域知识理解和应用上的不足，提供一个标准化的评估框架。", "method": "开发了包含1136个多选问题的ESGenius-QA和231份权威文档的ESGenius-Corpus，采用零样本和RAG两种评估协议。", "result": "在零样本设置下，最先进模型的准确率约为55-70%，而使用RAG的模型，尤其是较小模型，性能有显著提升。", "conclusion": "ESGenius为LLMs在ESG和可持续性领域的应用设立了首个基准，强调了基于权威来源的回答对于提升理解的重要性。"}}
{"id": "2506.00574", "title": "Prompt-Tuned LLM-Augmented DRL for Dynamic O-RAN Network Slicing", "authors": ["Fatemeh Lotfi", "Hossein Rajoli", "Fatemeh Afghah"], "abstract": "Modern wireless networks must adapt to dynamic conditions while efficiently managing diverse service demands. Traditional deep reinforcement learning (DRL) struggles in these environments, as scattered and evolving feedback makes optimal decision-making challenging. Large Language Models (LLMs) offer a solution by structuring unorganized network feedback into meaningful latent representations, helping RL agents recognize patterns more effectively. For example, in O-RAN slicing, concepts like SNR, power levels and throughput are semantically related, and LLMs can naturally cluster them, providing a more interpretable state representation. To leverage this capability, we introduce a contextualization-based adaptation method that integrates learnable prompts into an LLM-augmented DRL framework. Instead of relying on full model fine-tuning, we refine state representations through task-specific prompts that dynamically adjust to network conditions. Utilizing ORANSight, an LLM trained on O-RAN knowledge, we develop Prompt-Augmented Multi agent RL (PA-MRL) framework. Learnable prompts optimize both semantic clustering and RL objectives, allowing RL agents to achieve higher rewards in fewer iterations and adapt more efficiently. By incorporating prompt-augmented learning, our approach enables faster, more scalable, and adaptive resource allocation in O-RAN slicing. Experimental results show that it accelerates convergence and outperforms other baselines.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.00574.pdf", "abstract_url": "https://arxiv.org/abs/2506.00574", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种结合提示调优的大型语言模型（LLM）和深度强化学习（DRL）的方法，用于动态O-RAN网络切片，以提高资源分配的效率和适应性。", "motivation": "现代无线网络需要适应动态条件并有效管理多样化的服务需求，传统的深度强化学习在这些环境中表现不佳，因为分散和演变的反馈使得最优决策变得困难。", "method": "引入了一种基于情境化的适应方法，将可学习的提示集成到LLM增强的DRL框架中，通过任务特定的提示动态调整网络条件，优化状态表示。", "result": "实验结果表明，该方法加速了收敛速度，并在O-RAN切片中 outperforms其他基线方法。", "conclusion": "通过结合提示增强学习，我们的方法在O-RAN切片中实现了更快、更可扩展和自适应的资源分配。"}}
{"id": "2506.00576", "title": "ORAN-GUIDE: RAG-Driven Prompt Learning for LLM-Augmented Reinforcement Learning in O-RAN Network Slicing", "authors": ["Fatemeh Lotfi", "Hossein Rajoli", "Fatemeh Afghah"], "abstract": "Advanced wireless networks must support highly dynamic and heterogeneous service demands. Open Radio Access Network (O-RAN) architecture enables this flexibility by adopting modular, disaggregated components, such as the RAN Intelligent Controller (RIC), Centralized Unit (CU), and Distributed Unit (DU), that can support intelligent control via machine learning (ML). While deep reinforcement learning (DRL) is a powerful tool for managing dynamic resource allocation and slicing, it often struggles to process raw, unstructured input like RF features, QoS metrics, and traffic trends. These limitations hinder policy generalization and decision efficiency in partially observable and evolving environments. To address this, we propose \\textit{ORAN-GUIDE}, a dual-LLM framework that enhances multi-agent RL (MARL) with task-relevant, semantically enriched state representations. The architecture employs a domain-specific language model, ORANSight, pretrained on O-RAN control and configuration data, to generate structured, context-aware prompts. These prompts are fused with learnable tokens and passed to a frozen GPT-based encoder that outputs high-level semantic representations for DRL agents. This design adopts a retrieval-augmented generation (RAG) style pipeline tailored for technical decision-making in wireless systems. Experimental results show that ORAN-GUIDE improves sample efficiency, policy convergence, and performance generalization over standard MARL and single-LLM baselines.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.00576.pdf", "abstract_url": "https://arxiv.org/abs/2506.00576", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "ORAN-GUIDE是一个双LLM框架，通过任务相关的语义丰富状态表示增强多智能体强化学习（MARL），用于O-RAN网络切片中的动态资源分配。", "motivation": "解决深度强化学习在处理无线网络中原始、非结构化输入（如RF特征、QoS指标和流量趋势）时的局限性，以提升策略泛化能力和决策效率。", "method": "采用领域特定语言模型ORANSight生成结构化、上下文感知的提示，与可学习令牌融合后传递给基于GPT的编码器，输出高级语义表示供DRL代理使用。", "result": "实验结果表明，ORAN-GUIDE在样本效率、策略收敛和性能泛化方面优于标准MARL和单LLM基线。", "conclusion": "ORAN-GUIDE通过结合RAG风格的管道和LLM技术，为无线系统中的技术决策提供了有效的解决方案，提升了DRL在动态和异构服务需求下的应用效果。"}}
{"id": "2506.01748", "title": "Thinking in Character: Advancing Role-Playing Agents with Role-Aware Reasoning", "authors": ["Yihong Tang", "Kehai Chen", "Muyun Yang", "Zhengyu Niu", "Jing Li", "Tiejun Zhao", "Min Zhang"], "abstract": "The advancement of Large Language Models (LLMs) has spurred significant interest in Role-Playing Agents (RPAs) for applications such as emotional companionship and virtual interaction. However, recent RPAs are often built on explicit dialogue data, lacking deep, human-like internal thought processes, resulting in superficial knowledge and style expression. While Large Reasoning Models (LRMs) can be employed to simulate character thought, their direct application is hindered by attention diversion (i.e., RPAs forget their role) and style drift (i.e., overly formal and rigid reasoning rather than character-consistent reasoning). To address these challenges, this paper introduces a novel Role-Aware Reasoning (RAR) method, which consists of two important stages: Role Identity Activation (RIA) and Reasoning Style Optimization (RSO). RIA explicitly guides the model with character profiles during reasoning to counteract attention diversion, and then RSO aligns reasoning style with the character and scene via LRM distillation to mitigate style drift. Extensive experiments demonstrate that the proposed RAR significantly enhances the performance of RPAs by effectively addressing attention diversion and style drift.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.01748.pdf", "abstract_url": "https://arxiv.org/abs/2506.01748", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新颖的角色感知推理（RAR）方法，通过角色身份激活（RIA）和推理风格优化（RSO）两个阶段，有效解决了角色扮演代理（RPAs）在大型语言模型（LLMs）应用中的注意力分散和风格漂移问题，显著提升了RPAs的性能。", "motivation": "当前的角色扮演代理（RPAs）基于显式对话数据构建，缺乏深层次的人类内部思维过程，导致知识表达和风格表现肤浅。大型推理模型（LRMs）虽能模拟角色思维，但直接应用会因注意力分散和风格漂移而受限。", "method": "提出角色感知推理（RAR）方法，包括角色身份激活（RIA）和推理风格优化（RSO）两个阶段。RIA通过角色档案明确引导模型推理以对抗注意力分散，RSO通过LRM蒸馏使推理风格与角色和场景一致以减轻风格漂移。", "result": "大量实验证明，RAR方法通过有效解决注意力分散和风格漂移问题，显著提升了RPAs的性能。", "conclusion": "RAR方法为提升角色扮演代理的性能提供了有效途径，通过角色感知推理解决了现有方法在注意力分散和风格漂移方面的挑战，具有重要的应用价值。"}}
{"id": "2506.00592", "title": "Mitigating Plasticity Loss in Continual Reinforcement Learning by Reducing Churn", "authors": ["Hongyao Tang", "Johan Obando-Ceron", "Pablo Samuel Castro", "Aaron Courville", "Glen Berseth"], "abstract": "Plasticity, or the ability of an agent to adapt to new tasks, environments, or distributions, is crucial for continual learning. In this paper, we study the loss of plasticity in deep continual RL from the lens of churn: network output variability for out-of-batch data induced by mini-batch training. We demonstrate that (1) the loss of plasticity is accompanied by the exacerbation of churn due to the gradual rank decrease of the Neural Tangent Kernel (NTK) matrix; (2) reducing churn helps prevent rank collapse and adjusts the step size of regular RL gradients adaptively. Moreover, we introduce Continual Churn Approximated Reduction (C-CHAIN) and demonstrate it improves learning performance and outperforms baselines in a diverse range of continual learning environments on OpenAI Gym Control, ProcGen, DeepMind Control Suite, and MinAtar benchmarks.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "Accepted to ICML 2025", "pdf_url": "https://arxiv.org/pdf/2506.00592.pdf", "abstract_url": "https://arxiv.org/abs/2506.00592", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究了深度持续强化学习中的塑性损失问题，通过减少网络输出变异性（churn）来缓解塑性损失，并提出了C-CHAIN方法，在多种持续学习环境中表现出色。", "motivation": "解决深度持续强化学习中因塑性损失导致的适应新任务、环境或分布能力下降的问题。", "method": "通过分析神经切线核（NTK）矩阵的秩逐渐减少导致的churn加剧，提出减少churn的方法C-CHAIN。", "result": "C-CHAIN方法有效防止了秩崩溃，自适应调整了常规RL梯度的步长，在多种持续学习基准测试中优于基线方法。", "conclusion": "减少churn是缓解塑性损失的有效策略，C-CHAIN方法在持续学习任务中展现了优异的性能和适应性。"}}
{"id": "2506.00627", "title": "The Disparate Effects of Partial Information in Bayesian Strategic Learning", "authors": ["Srikanth Avasarala", "Serena Wang", "Juba Ziani"], "abstract": "We study how partial information about scoring rules affects fairness in strategic learning settings. In strategic learning, a learner deploys a scoring rule, and agents respond strategically by modifying their features -- at some cost -- to improve their outcomes. However, in our work, agents do not observe the scoring rule directly; instead, they receive a noisy signal of said rule. We consider two different agent models: (i) naive agents, who take the noisy signal at face value, and (ii) Bayesian agents, who update a prior belief based on the signal.", "subjects": "Computer Science and Game Theory (cs.GT); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.00627.pdf", "abstract_url": "https://arxiv.org/abs/2506.00627", "categories": ["Computer Science and Game Theory (cs.GT)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "研究在战略学习环境中，评分规则的部分信息如何影响公平性，探讨了天真代理和贝叶斯代理在不同信息条件下的行为差异。", "motivation": "解决在战略学习设置中，代理因不完全信息而可能受到不公平对待的问题。", "method": "通过比较天真代理（直接接受噪声信号）和贝叶斯代理（基于信号更新先验信念）的行为，分析部分信息对公平性的影响。", "result": "揭示了不同代理模型在部分信息条件下的行为差异及其对公平性的影响。", "conclusion": "强调了在战略学习中考虑代理信息处理方式的重要性，以确保公平性。"}}
{"id": "2506.01859", "title": "CONFETTI: Conversational Function-Calling Evaluation Through Turn-Level Interactions", "authors": ["Tamer Alkhouli", "Katerina Margatina", "James Gung", "Raphael Shu", "Claudia Zaghi", "Monica Sunkara", "Yi Zhang"], "abstract": "We introduce Conversational Function-Calling Evaluation Through Turn-Level Interactions (CONFETTI), a conversational benchmark1 designed to evaluate the function-calling capabilities and response quality of large language models (LLMs). Current benchmarks lack comprehensive assessment of LLMs in complex conversational scenarios. CONFETTI addresses this gap through 109 human-simulated conversations, comprising 313 user turns and covering 86 APIs. These conversations explicitly target various conversational complexities, such as follow-ups, goal correction and switching, ambiguous and implicit goals. We perform off-policy turn-level evaluation using this benchmark targeting function-calling. Our benchmark also incorporates dialog act annotations to assess agent responses. We evaluate a series of state-of-the-art LLMs and analyze their performance with respect to the number of available APIs, conversation lengths, and chained function calling. Our results reveal that while some models are able to handle long conversations, and leverage more than 20+ APIs successfully, other models struggle with longer context or when increasing the number of APIs. We also report that the performance on chained function-calls is severely limited across the models. Overall, the top performing models on CONFETTI are Nova Pro (40.01%), Claude Sonnet v3.5 (35.46%) and Llama 3.1 405B (33.19%) followed by command-r-plus (31.18%) and Mistral-Large-2407 (30.07%).", "subjects": "Computation and Language (cs.CL)", "comments": "ACL 2025 (main conference)", "pdf_url": "https://arxiv.org/pdf/2506.01859.pdf", "abstract_url": "https://arxiv.org/abs/2506.01859", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "CONFETTI是一个对话基准，旨在评估大型语言模型（LLMs）在复杂对话场景中的功能调用能力和响应质量。通过109个人工模拟对话，涵盖313个用户轮次和86个API，该基准针对各种对话复杂性进行了评估。", "motivation": "当前基准缺乏对LLMs在复杂对话场景中全面评估的能力，CONFETTI旨在填补这一空白。", "method": "CONFETTI通过人工模拟对话进行离策略轮次评估，并包含对话行为注释以评估代理响应。", "result": "评估结果显示，一些模型能够处理长对话并成功利用20多个API，而其他模型在上下文较长或API数量增加时表现不佳。链式功能调用的性能在所有模型中严重受限。", "conclusion": "CONFETTI揭示了不同LLMs在功能调用和响应质量上的性能差异，为未来研究提供了重要参考。"}}
{"id": "2506.00691", "title": "Optimizing Sensory Neurons: Nonlinear Attention Mechanisms for Accelerated Convergence in Permutation-Invariant Neural Networks for Reinforcement Learning", "authors": ["Junaid Muzaffar", "Ahsan Adeel", "Khubaib Ahmed", "Ingo Frommholz", "Zeeshan Pervez", "Ahsan ul Haq"], "abstract": "Training reinforcement learning (RL) agents often requires significant computational resources and extended training times. To address this, we build upon the foundation laid by Google Brain's Sensory Neuron, which introduced a novel neural architecture for reinforcement learning tasks that maintained permutation in-variance in the sensory neuron system. While the baseline model demonstrated significant performance improvements over traditional approaches, we identified opportunities to enhance the efficiency of the learning process further. We propose a modified attention mechanism incorporating a non-linear transformation of the key vectors (K) using a mapping function, resulting in a new set of key vectors (K'). This non-linear mapping enhances the representational capacity of the attention mechanism, allowing the model to encode more complex feature interactions and accelerating convergence without compromising performance. Our enhanced model demonstrates significant improvements in learning efficiency, showcasing the potential for non-linear attention mechanisms in advancing reinforcement learning algorithms.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.00691.pdf", "abstract_url": "https://arxiv.org/abs/2506.00691", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种改进的注意力机制，通过非线性变换关键向量（K）来增强强化学习中的感知神经元系统，从而加速收敛而不影响性能。", "motivation": "解决强化学习（RL）代理训练过程中计算资源消耗大和训练时间长的问题。", "method": "在Google Brain的感知神经元基础上，引入非线性变换的关键向量（K'）来增强注意力机制的表征能力。", "result": "改进后的模型在学习效率上显示出显著提升，证明了非线性注意力机制在推进强化学习算法中的潜力。", "conclusion": "非线性注意力机制能够有效加速强化学习算法的收敛，同时保持或提升性能，为未来的研究提供了新的方向。"}}
{"id": "2506.01952", "title": "WebChoreArena: Evaluating Web Browsing Agents on Realistic Tedious Web Tasks", "authors": ["Atsuyuki Miyai", "Zaiying Zhao", "Kazuki Egashira", "Atsuki Sato", "Tatsumi Sunada", "Shota Onohara", "Hiromasa Yamanishi", "Mashiro Toyooka", "Kunato Nishina", "Ryoma Maeda", "Kiyoharu Aizawa", "Toshihiko Yamasaki"], "abstract": "Powered by a large language model (LLM), a web browsing agent operates web browsers in a human-like manner and offers a highly transparent path toward automating a wide range of everyday tasks. As web agents become increasingly capable and demonstrate proficiency in general browsing tasks, a critical question emerges: Can they go beyond general browsing to robustly handle tasks that are tedious and complex, or chores that humans often avoid doing themselves? In this paper, we introduce WebChoreArena, a new fully reproducible benchmark comprising 532 carefully curated tasks designed to extend the scope of WebArena beyond general browsing to more labor-intensive and tedious tasks. WebChoreArena systematically integrates three key challenges: (i) Massive Memory tasks requiring accurate retrieval of large amounts of information in the observations, (ii) Calculation tasks demanding precise mathematical reasoning, and (iii) Long-Term Memory tasks necessitating long-term memory across multiple webpages. Built on top of the fully reproducible and widely adopted four WebArena simulation environments, WebChoreArena ensures strict reproducibility and enables fair, direct comparisons with the established WebArena benchmark, offering key insights into agent progress. Our experimental results demonstrate that as LLMs evolve, represented by GPT-4o, Claude 3.7 Sonnet, and Gemini 2.5 Pro, significant improvements in performance are observed on WebChoreArena. These findings suggest that WebChoreArena is well-suited to measure the advancement of state-of-the-art LLMs with greater clarity. Nevertheless, the results also indicate that even with Gemini 2.5 Pro, there remains substantial room for improvement compared to WebArena, highlighting the increased challenges posed by WebChoreArena.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2506.01952.pdf", "abstract_url": "https://arxiv.org/abs/2506.01952", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了WebChoreArena，一个包含532个任务的基准测试，旨在评估大型语言模型（LLM）驱动的网页浏览代理在处理复杂、繁琐任务上的能力。", "motivation": "随着网页浏览代理能力的提升，研究其是否能超越一般浏览任务，稳健处理人类常避免的繁琐复杂任务成为一个关键问题。", "method": "WebChoreArena通过整合三大挑战（大规模记忆任务、计算任务、长期记忆任务）来扩展WebArena的范围，确保严格的可重复性和公平比较。", "result": "实验结果显示，随着LLMs（如GPT-4o、Claude 3.7 Sonnet、Gemini 2.5 Pro）的进化，WebChoreArena上的性能有显著提升，但仍存在改进空间。", "conclusion": "WebChoreArena适合更清晰地衡量最先进LLMs的进步，同时也揭示了这些模型在处理更复杂任务时的挑战。"}}
{"id": "2506.00714", "title": "An LLM Agent for Functional Bug Detection in Network Protocols", "authors": ["Mingwei Zheng", "Chengpeng Wang", "Xuwei Liu", "Jinyao Guo", "Shiwei Feng", "Xiangyu Zhang"], "abstract": "Functional correctness is critical for ensuring the reliability and security of network protocol implementations. Functional bugs, instances where implementations diverge from behaviors specified in RFC documents, can lead to severe consequences, including faulty routing, authentication bypasses, and service disruptions. Detecting these bugs requires deep semantic analysis across specification documents and source code, a task beyond the capabilities of traditional static analysis tools. This paper introduces RFCScan, an autonomous agent that leverages large language models (LLMs) to detect functional bugs by checking conformance between network protocol implementations and their RFC specifications. Inspired by the human auditing procedure, RFCScan comprises two key components: an indexing agent and a detection agent. The former hierarchically summarizes protocol code semantics, generating semantic indexes that enable the detection agent to narrow down the scanning scope. The latter employs demand-driven retrieval to iteratively collect additional relevant data structures and functions, eventually identifying potential inconsistencies with the RFC specifications effectively. We evaluate RFCScan across six real-world network protocol implementations. RFCScan identifies 47 functional bugs with 81.9% precision, of which 20 bugs have been confirmed or fixed by developers.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.00714.pdf", "abstract_url": "https://arxiv.org/abs/2506.00714", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一种名为RFCScan的自主代理，利用大型语言模型（LLMs）检测网络协议实现中的功能错误，通过检查实现与RFC规范之间的一致性。", "motivation": "功能正确性对于确保网络协议实现的可靠性和安全性至关重要。功能错误，即实现与RFC文档中指定的行为偏离，可能导致严重后果，如错误路由、认证绕过和服务中断。", "method": "RFCScan由两个关键组件组成：索引代理和检测代理。索引代理分层总结协议代码语义，生成语义索引，使检测代理能够缩小扫描范围。检测代理采用需求驱动的检索方法，迭代收集相关数据结构和函数，最终识别与RFC规范的潜在不一致。", "result": "在六个真实世界的网络协议实现中评估RFCScan，它识别了47个功能错误，精确度为81.9%，其中20个错误已被开发者确认或修复。", "conclusion": "RFCScan通过结合大型语言模型和人类审计程序的方法，有效地检测网络协议实现中的功能错误，提高了检测的精确度和效率。"}}
{"id": "2506.01954", "title": "DRAG: Distilling RAG for SLMs from LLMs to Transfer Knowledge and Mitigate Hallucination via Evidence and Graph-based Distillation", "authors": ["Jennifer Chen", "Aidar Myrzakhan", "Yaxin Luo", "Hassaan Muhammad Khan", "Sondos Mahmoud Bsharat", "Zhiqiang Shen"], "abstract": "Retrieval-Augmented Generation (RAG) methods have proven highly effective for tasks requiring factual consistency and robust knowledge retrieval. However, large-scale RAG systems consume significant computational resources and are prone to generating hallucinated content from Humans. In this work, we introduce $\\texttt{DRAG}$, a novel framework for distilling RAG knowledge from large-scale Language Models (LLMs) into small LMs (SLMs). Our approach leverages evidence- and knowledge graph-based distillation, ensuring that the distilled model retains critical factual knowledge while significantly reducing model size and computational cost. By aligning the smaller model's predictions with a structured knowledge graph and ranked evidence, $\\texttt{DRAG}$ effectively mitigates hallucinations and improves factual accuracy. We further present a case demonstrating how our framework mitigates user privacy risks and introduce a corresponding benchmark. Experimental evaluations on multiple benchmarks demonstrate that our method outperforms the prior competitive RAG methods like MiniRAG for SLMs by up to 27.7% using the same models, preserving high-level efficiency and reliability. With $\\texttt{DRAG}$, we provide a practical and resource-efficient roadmap to deploying enhanced retrieval and generation capabilities in small-sized LLMs.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2506.01954.pdf", "abstract_url": "https://arxiv.org/abs/2506.01954", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了DRAG框架，通过证据和基于知识图的蒸馏方法，将大型语言模型(LLMs)中的RAG知识蒸馏到小型语言模型(SLMs)中，以减少计算资源消耗并减轻幻觉现象。", "motivation": "解决大型RAG系统计算资源消耗大和容易产生幻觉内容的问题，同时将增强的检索和生成能力部署到小型LLMs中。", "method": "采用证据和知识图基础的蒸馏方法，确保蒸馏后的模型保留关键事实知识，同时显著减少模型大小和计算成本。", "result": "在多个基准测试中，DRAG方法比之前的竞争性RAG方法如MiniRAG在SLMs上性能提升了高达27.7%，同时保持了高效率和可靠性。", "conclusion": "DRAG提供了一个实用且资源高效的路线图，用于在小型LLMs中部署增强的检索和生成能力，有效减轻幻觉并提高事实准确性。"}}
{"id": "2506.00054", "title": "Retrieval-Augmented Generation: A Comprehensive Survey of Architectures, Enhancements, and Robustness Frontiers", "authors": ["Chaitanya Sharma"], "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a powerful paradigm to enhance large language models (LLMs) by conditioning generation on external evidence retrieved at inference time. While RAG addresses critical limitations of parametric knowledge storage-such as factual inconsistency and domain inflexibility-it introduces new challenges in retrieval quality, grounding fidelity, pipeline efficiency, and robustness against noisy or adversarial inputs. This survey provides a comprehensive synthesis of recent advances in RAG systems, offering a taxonomy that categorizes architectures into retriever-centric, generator-centric, hybrid, and robustness-oriented designs. We systematically analyze enhancements across retrieval optimization, context filtering, decoding control, and efficiency improvements, supported by comparative performance analyses on short-form and multi-hop question answering tasks. Furthermore, we review state-of-the-art evaluation frameworks and benchmarks, highlighting trends in retrieval-aware evaluation, robustness testing, and federated retrieval settings. Our analysis reveals recurring trade-offs between retrieval precision and generation flexibility, efficiency and faithfulness, and modularity and coordination. We conclude by identifying open challenges and future research directions, including adaptive retrieval architectures, real-time retrieval integration, structured reasoning over multi-hop evidence, and privacy-preserving retrieval mechanisms. This survey aims to consolidate current knowledge in RAG research and serve as a foundation for the next generation of retrieval-augmented language modeling systems.", "subjects": "Information Retrieval (cs.IR); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.00054.pdf", "abstract_url": "https://arxiv.org/abs/2506.00054", "categories": ["Information Retrieval (cs.IR)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "检索增强生成（RAG）是一种通过推理时检索外部证据来增强大型语言模型（LLMs）的强大范式。本文综述了RAG系统的最新进展，提出了架构分类法，并分析了检索优化、上下文过滤、解码控制和效率改进等方面的增强，同时探讨了评估框架和基准测试。", "motivation": "解决大型语言模型在参数化知识存储方面的局限性，如事实不一致性和领域不灵活性，同时应对检索质量、基础保真度、管道效率和对抗噪声或对抗性输入的新挑战。", "method": "提供RAG系统的综合综述，包括架构分类（检索器中心、生成器中心、混合和面向鲁棒性的设计），系统分析检索优化、上下文过滤、解码控制和效率改进，并通过比较性能分析支持。", "result": "揭示了检索精度与生成灵活性、效率与忠实度、模块化与协调之间的反复权衡，并指出了当前RAG研究的开放挑战和未来研究方向。", "conclusion": "本文旨在巩固RAG研究的当前知识，并为下一代检索增强语言建模系统奠定基础，包括自适应检索架构、实时检索集成、多跳证据的结构化推理和隐私保护检索机制等未来方向。"}}
{"id": "2506.00797", "title": "Action Dependency Graphs for Globally Optimal Coordinated Reinforcement Learning", "authors": ["Jianglin Ding", "Jingcheng Tang", "Gangshan Jing"], "abstract": "Action-dependent individual policies, which incorporate both environmental states and the actions of other agents in decision-making, have emerged as a promising paradigm for achieving global optimality in multi-agent reinforcement learning (MARL). However, the existing literature often adopts auto-regressive action-dependent policies, where each agent's policy depends on the actions of all preceding agents. This formulation incurs substantial computational complexity as the number of agents increases, thereby limiting scalability. In this work, we consider a more generalized class of action-dependent policies, which do not necessarily follow the auto-regressive form. We propose to use the `action dependency graph (ADG)' to model the inter-agent action dependencies. Within the context of MARL problems structured by coordination graphs, we prove that an action-dependent policy with a sparse ADG can achieve global optimality, provided the ADG satisfies specific conditions specified by the coordination graph. Building on this theoretical foundation, we develop a tabular policy iteration algorithm with guaranteed global optimality. Furthermore, we integrate our framework into several SOTA algorithms and conduct experiments in complex environments. The empirical results affirm the robustness and applicability of our approach in more general scenarios, underscoring its potential for broader MARL challenges.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Systems and Control (eess.SY); Optimization and Control (math.OC)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.00797.pdf", "abstract_url": "https://arxiv.org/abs/2506.00797", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Systems and Control (eess.SY)", "Optimization and Control (math.OC)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为‘动作依赖图（ADG）’的新方法，用于建模多智能体强化学习（MARL）中智能体间的动作依赖关系，旨在解决现有自回归动作依赖策略计算复杂度高、可扩展性差的问题。通过理论证明和实验验证，展示了稀疏ADG在特定条件下能够实现全局最优，并开发了保证全局最优性的表格策略迭代算法。", "motivation": "解决多智能体强化学习中现有自回归动作依赖策略因计算复杂度高而限制可扩展性的问题。", "method": "提出使用动作依赖图（ADG）建模智能体间的动作依赖关系，开发了保证全局最优性的表格策略迭代算法，并将框架集成到多种先进算法中。", "result": "理论证明和实验结果表明，稀疏ADG在满足特定条件时能够实现全局最优，且在复杂环境中表现出良好的鲁棒性和适用性。", "conclusion": "动作依赖图（ADG）为多智能体强化学习提供了一种有效的方法，不仅理论上保证了全局最优性，而且在实际应用中展现出了广泛的潜力。"}}
{"id": "2506.00261", "title": "GPR: Empowering Generation with Graph-Pretrained Retriever", "authors": ["Xiaochen Wang", "Zongyu Wu", "Yuan Zhong", "Xiang Zhang", "Suhang Wang", "Fenglong Ma"], "abstract": "Graph retrieval-augmented generation (GRAG) places high demands on graph-specific retrievers. However, existing retrievers often rely on language models pretrained on plain text, limiting their effectiveness due to domain misalignment and structure ignorance. To address these challenges, we propose GPR, a graph-based retriever pretrained directly on knowledge graphs. GPR aligns natural language questions with relevant subgraphs through LLM-guided graph augmentation and employs a structure-aware objective to learn fine-grained retrieval strategies. Experiments on two datasets, three LLM backbones, and five baselines show that GPR consistently improves both retrieval quality and downstream generation, demonstrating its effectiveness as a robust retrieval solution for GRAG.", "subjects": "Information Retrieval (cs.IR); Computation and Language (cs.CL)", "comments": "Short paper submitted to EMNLP'25", "pdf_url": "https://arxiv.org/pdf/2506.00261.pdf", "abstract_url": "https://arxiv.org/abs/2506.00261", "categories": ["Information Retrieval (cs.IR)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出GPR，一种基于知识图谱预训练的图检索器，旨在解决现有检索器因领域不对齐和结构忽视而效果受限的问题。通过LLM引导的图增强和结构感知目标，GPR能够将自然语言问题与相关子图对齐，学习细粒度的检索策略。实验证明，GPR在检索质量和下游生成任务上均表现出色。", "motivation": "解决现有图检索增强生成（GRAG）方法中，基于纯文本预训练的语言模型检索器因领域不对齐和结构忽视而效果受限的问题。", "method": "提出GPR，一种直接在知识图谱上预训练的图检索器，通过LLM引导的图增强和结构感知目标，学习将自然语言问题与相关子图对齐的细粒度检索策略。", "result": "在两个数据集、三个LLM主干和五个基线上的实验表明，GPR在检索质量和下游生成任务上均显著优于现有方法。", "conclusion": "GPR作为一种强大的检索解决方案，有效提升了图检索增强生成的性能，展示了其在处理复杂图结构数据方面的潜力。"}}
{"id": "2506.00363", "title": "Adapting General-Purpose Embedding Models to Private Datasets Using Keyword-based Retrieval", "authors": ["Yubai Wei", "Jiale Han", "Yi Yang"], "abstract": "Text embedding models play a cornerstone role in AI applications, such as retrieval-augmented generation (RAG). While general-purpose text embedding models demonstrate strong performance on generic retrieval benchmarks, their effectiveness diminishes when applied to private datasets (e.g., company-specific proprietary data), which often contain specialized terminology and lingo. In this work, we introduce BMEmbed, a novel method for adapting general-purpose text embedding models to private datasets. By leveraging the well-established keyword-based retrieval technique (BM25), we construct supervisory signals from the ranking of keyword-based retrieval results to facilitate model adaptation. We evaluate BMEmbed across a range of domains, datasets, and models, showing consistent improvements in retrieval performance. Moreover, we provide empirical insights into how BM25-based signals contribute to improving embeddings by fostering alignment and uniformity, highlighting the value of this approach in adapting models to domain-specific data. We release the source code available at", "subjects": "Information Retrieval (cs.IR); Computation and Language (cs.CL)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2506.00363.pdf", "abstract_url": "https://arxiv.org/abs/2506.00363", "categories": ["Information Retrieval (cs.IR)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了BMEmbed，一种新颖的方法，用于将通用文本嵌入模型适应于私有数据集。通过利用基于关键字的检索技术（BM25），从检索结果的排名中构建监督信号，以促进模型适应。实验表明，BMEmbed在多个领域、数据集和模型中均能提高检索性能。", "motivation": "通用文本嵌入模型在通用检索基准上表现出色，但在应用于包含专业术语和行话的私有数据集时效果下降。本文旨在解决这一问题。", "method": "利用基于关键字的检索技术（BM25）构建监督信号，从检索结果的排名中促进模型适应。", "result": "BMEmbed在多个领域、数据集和模型中均能提高检索性能，并通过BM25-based信号促进了对齐和均匀性，从而改善了嵌入。", "conclusion": "BMEmbed方法有效地将通用文本嵌入模型适应于特定领域的数据，提高了检索性能，并提供了关于BM25-based信号如何改善嵌入的实证见解。"}}
{"id": "2506.00831", "title": "A Large Language Model-Supported Threat Modeling Framework for Transportation Cyber-Physical Systems", "authors": ["M Sabbir Salek", "Mashrur Chowdhury", "Muhaimin Bin Munir", "Yuchen Cai", "Mohammad Imtiaz Hasan", "Jean-Michel Tine", "Latifur Khan", "Mizanur Rahman"], "abstract": "Modern transportation systems rely on cyber-physical systems (CPS), where cyber systems interact seamlessly with physical systems like transportation-related sensors and actuators to enhance safety, mobility, and energy efficiency. However, growing automation and connectivity increase exposure to cyber vulnerabilities. Existing threat modeling frameworks for transportation CPS are often limited in scope, resource-intensive, and dependent on significant cybersecurity expertise. To address these gaps, we present TraCR-TMF (Transportation Cybersecurity and Resiliency Threat Modeling Framework), a large language model (LLM)-based framework that minimizes expert intervention. TraCR-TMF identifies threats, potential attack techniques, and corresponding countermeasures by leveraging the MITRE ATT&CK matrix through three LLM-based approaches: (i) a retrieval-augmented generation (RAG) method requiring no expert input, (ii) an in-context learning approach requiring low expert input, and (iii) a supervised fine-tuning method requiring moderate expert input. TraCR-TMF also maps attack paths to critical assets by analyzing vulnerabilities using a customized LLM. The framework was evaluated in two scenarios. First, it identified relevant attack techniques across transportation CPS applications, with 90% precision as validated by experts. Second, using a fine-tuned LLM, it successfully predicted multiple exploitations including lateral movement, data exfiltration, and ransomware-related encryption that occurred during a major real-world cyberattack incident. These results demonstrate TraCR-TMF's effectiveness in CPS threat modeling, its reduced reliance on cybersecurity expertise, and its adaptability across CPS domains.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.00831.pdf", "abstract_url": "https://arxiv.org/abs/2506.00831", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了TraCR-TMF，一个基于大型语言模型（LLM）的交通网络物理系统（CPS）威胁建模框架，旨在减少对网络安全专家干预的依赖。", "motivation": "现代交通系统依赖于网络物理系统（CPS），但随着自动化和连接性的增加，暴露于网络漏洞的风险也随之增加。现有的威胁建模框架往往范围有限、资源密集且依赖大量网络安全专业知识。", "method": "TraCR-TMF通过三种基于LLM的方法（无需专家输入的检索增强生成（RAG）方法、低专家输入的上下文学习方法、中等专家输入的监督微调方法）识别威胁、潜在攻击技术及相应对策，并利用定制的LLM分析漏洞，将攻击路径映射到关键资产。", "result": "在两个场景中评估了TraCR-TMF：一是在交通CPS应用中识别相关攻击技术，专家验证的精确度为90%；二是使用微调的LLM成功预测了在一次重大真实世界网络攻击事件中发生的多种利用，包括横向移动、数据外泄和勒索软件相关加密。", "conclusion": "结果表明，TraCR-TMF在CPS威胁建模中有效，减少了对网络安全专业知识的依赖，并展示了跨CPS领域的适应性。"}}
{"id": "2506.00856", "title": "Can AI Master Econometrics? Evidence from Econometrics AI Agent on Expert-Level Tasks", "authors": ["Qiang Chen", "Tianyang Han", "Jin Li", "Ye Luo", "Yuxiao Wu", "Xiaowei Zhang", "Tuo Zhou"], "abstract": "Can AI effectively perform complex econometric analysis traditionally requiring human expertise? This paper evaluates an agentic AI's capability to master econometrics, focusing on empirical analysis performance. We develop an ``Econometrics AI Agent'' built on the open-source MetaGPT framework. This agent exhibits outstanding performance in: (1) planning econometric tasks strategically, (2) generating and executing code, (3) employing error-based reflection for improved robustness, and (4) allowing iterative refinement through multi-round conversations. We construct two datasets from academic coursework materials and published research papers to evaluate performance against real-world challenges. Comparative testing shows our domain-specialized agent significantly outperforms both benchmark large language models (LLMs) and general-purpose AI agents. This work establishes a testbed for exploring AI's impact on social science research and enables cost-effective integration of domain expertise, making advanced econometric methods accessible to users with minimal coding expertise. Furthermore, our agent enhances research reproducibility and offers promising pedagogical applications for econometrics teaching.", "subjects": "Econometrics (econ.EM); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.00856.pdf", "abstract_url": "https://arxiv.org/abs/2506.00856", "categories": ["Econometrics (econ.EM)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文评估了一个基于MetaGPT框架开发的'计量经济学AI代理'在复杂计量经济学分析中的表现，展示了其在任务规划、代码生成与执行、错误反思及多轮对话迭代优化方面的卓越能力，并在与大型语言模型和通用AI代理的比较中显著胜出。", "motivation": "探讨AI是否能够有效执行传统上需要人类专家才能完成的复杂计量经济学分析任务。", "method": "开发了一个基于开源MetaGPT框架的'计量经济学AI代理'，并通过构建来自学术课程材料和已发表研究论文的两个数据集来评估其性能。", "result": "该领域专业化代理在性能上显著优于基准大型语言模型和通用AI代理，为探索AI对社会科学研究的影响建立了测试平台。", "conclusion": "这项工作不仅使得高级计量经济学方法对编码专业知识有限的用户变得可及，还提高了研究的可重复性，并为计量经济学教学提供了有前景的教学应用。"}}
{"id": "2506.00885", "title": "CoVoMix2: Advancing Zero-Shot Dialogue Generation with Fully Non-Autoregressive Flow Matching", "authors": ["Leying Zhang", "Yao Qian", "Xiaofei Wang", "Manthan Thakker", "Dongmei Wang", "Jianwei Yu", "Haibin Wu", "Yuxuan Hu", "Jinyu Li", "Yanmin Qian", "Sheng Zhao"], "abstract": "Generating natural-sounding, multi-speaker dialogue is crucial for applications such as podcast creation, virtual agents, and multimedia content generation. However, existing systems struggle to maintain speaker consistency, model overlapping speech, and synthesize coherent conversations efficiently. In this paper, we introduce CoVoMix2, a fully non-autoregressive framework for zero-shot multi-talker dialogue generation. CoVoMix2 directly predicts mel-spectrograms from multi-stream transcriptions using a flow-matching-based generative model, eliminating the reliance on intermediate token representations. To better capture realistic conversational dynamics, we propose transcription-level speaker disentanglement, sentence-level alignment, and prompt-level random masking strategies. Our approach achieves state-of-the-art performance, outperforming strong baselines like MoonCast and Sesame in speech quality, speaker consistency, and inference speed. Notably, CoVoMix2 operates without requiring transcriptions for the prompt and supports controllable dialogue generation, including overlapping speech and precise timing control, demonstrating strong generalizability to real-world speech generation scenarios.", "subjects": "Sound (cs.SD); Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.00885.pdf", "abstract_url": "https://arxiv.org/abs/2506.00885", "categories": ["Sound (cs.SD)", "Artificial Intelligence (cs.AI)", "Audio and Speech Processing (eess.AS)"], "matching_keywords": ["agent"], "AI": {"tldr": "CoVoMix2是一种完全非自回归的零样本多说话者对话生成框架，通过流匹配生成模型直接从多流转录预测梅尔频谱图，提高了语音质量、说话者一致性和推理速度。", "motivation": "解决现有系统在保持说话者一致性、模拟重叠语音和高效合成连贯对话方面的困难。", "method": "采用基于流匹配的生成模型，结合转录级说话者解缠、句子级对齐和提示级随机掩码策略。", "result": "在语音质量、说话者一致性和推理速度上优于MoonCast和Sesame等强基线，支持可控对话生成，包括重叠语音和精确时间控制。", "conclusion": "CoVoMix2在不需提示转录的情况下运行，展示了在现实世界语音生成场景中的强大泛化能力。"}}
{"id": "2506.01055", "title": "Simple Prompt Injection Attacks Can Leak Personal Data Observed by LLM Agents During Task Execution", "authors": ["Meysam Alizadeh", "Zeynab Samei", "Daria Stetsenko", "Fabrizio Gilardi"], "abstract": "Previous benchmarks on prompt injection in large language models (LLMs) have primarily focused on generic tasks and attacks, offering limited insights into more complex threats like data exfiltration. This paper examines how prompt injection can cause tool-calling agents to leak personal data observed during task execution. Using a fictitious banking agent, we develop data flow-based attacks and integrate them into AgentDojo, a recent benchmark for agentic security. To enhance its scope, we also create a richer synthetic dataset of human-AI banking conversations. In 16 user tasks from AgentDojo, LLMs show a 15-50 percentage point drop in utility under attack, with average attack success rates (ASR) around 20 percent; some defenses reduce ASR to zero. Most LLMs, even when successfully tricked by the attack, avoid leaking highly sensitive data like passwords, likely due to safety alignments, but they remain vulnerable to disclosing other personal data. The likelihood of password leakage increases when a password is requested along with one or two additional personal details. In an extended evaluation across 48 tasks, the average ASR is around 15 percent, with no built-in AgentDojo defense fully preventing leakage. Tasks involving data extraction or authorization workflows, which closely resemble the structure of exfiltration attacks, exhibit the highest ASRs, highlighting the interaction between task type, agent performance, and defense efficacy.", "subjects": "Cryptography and Security (cs.CR); Computation and Language (cs.CL)", "comments": "25 pages, 18 figures, NeurIPS formatting style", "pdf_url": "https://arxiv.org/pdf/2506.01055.pdf", "abstract_url": "https://arxiv.org/abs/2506.01055", "categories": ["Cryptography and Security (cs.CR)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文探讨了提示注入攻击如何导致工具调用代理在任务执行过程中泄露个人数据，通过虚构的银行代理开发了基于数据流的攻击，并在AgentDojo基准测试中进行了评估。研究发现，即使在安全对齐的情况下，大型语言模型仍容易泄露某些个人数据，且特定任务类型的攻击成功率最高。", "motivation": "解决现有大型语言模型（LLMs）在复杂威胁如数据外泄方面的安全评估不足问题，特别是在工具调用代理场景下的个人数据泄露风险。", "method": "通过虚构的银行代理开发数据流攻击，并将其集成到AgentDojo基准测试中，同时创建了一个更丰富的人工智能银行对话合成数据集进行评估。", "result": "在16个用户任务中，LLMs在攻击下的效用下降了15-50个百分点，平均攻击成功率（ASR）约为20%；某些防御措施能将ASR降至零。在48个任务的扩展评估中，平均ASR约为15%，且没有内置防御能完全防止泄露。", "conclusion": "研究表明，尽管LLMs在安全对齐后减少了高敏感数据如密码的泄露，但仍存在泄露其他个人数据的风险，特别是在数据提取或授权工作流等任务中。这强调了任务类型、代理性能和防御效果之间的相互作用。"}}
{"id": "2506.01232", "title": "Retrieval-Augmented Generation of Ontologies from Relational Databases", "authors": ["Mojtaba Nayyeri", "Athish A Yogi", "Nadeen Fathallah", "Ratan Bahadur Thapa", "Hans-Michael Tautenhahn", "Anton Schnurpel", "Steffen Staab"], "abstract": "Transforming relational databases into knowledge graphs with enriched ontologies enhances semantic interoperability and unlocks advanced graph-based learning and reasoning over data. However, previous approaches either demand significant manual effort to derive an ontology from a database schema or produce only a basic ontology. We present RIGOR, Retrieval-augmented Iterative Generation of RDB Ontologies, an LLM-driven approach that turns relational schemas into rich OWL ontologies with minimal human effort. RIGOR combines three sources via RAG, the database schema and its documentation, a repository of domain ontologies, and a growing core ontology, to prompt a generative LLM for producing successive, provenance-tagged delta ontology fragments. Each fragment is refined by a judge-LLM before being merged into the core ontology, and the process iterates table-by-table following foreign key constraints until coverage is complete. Applied to real-world databases, our approach outputs ontologies that score highly on standard quality dimensions such as accuracy, completeness, conciseness, adaptability, clarity, and consistency, while substantially reducing manual effort.", "subjects": "Databases (cs.DB); Artificial Intelligence (cs.AI)", "comments": "Under review", "pdf_url": "https://arxiv.org/pdf/2506.01232.pdf", "abstract_url": "https://arxiv.org/abs/2506.01232", "categories": ["Databases (cs.DB)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了RIGOR，一种利用大型语言模型（LLM）从关系数据库模式生成丰富OWL本体的方法，旨在通过最小化人工努力提高语义互操作性和支持基于图的学习与推理。", "motivation": "解决从关系数据库模式手动派生本体需要大量人工努力或仅能生成基本本体的问题。", "method": "RIGOR方法结合数据库模式及其文档、领域本体库和核心本体，通过检索增强生成（RAG）技术，利用生成式LLM逐步生成带有来源标记的增量本体片段，并由判断-LLM进行精炼后合并到核心本体中，按外键约束逐表迭代直至覆盖完成。", "result": "应用于真实世界数据库时，RIGOR生成的本体在准确性、完整性、简洁性、适应性、清晰度和一致性等标准质量维度上得分高，同时大幅减少了人工努力。", "conclusion": "RIGOR提供了一种高效、自动化的方法，用于从关系数据库生成高质量本体，显著提升了语义互操作性和数据推理能力。"}}
{"id": "2506.01463", "title": "Agentic AI and Multiagentic: Are We Reinventing the Wheel?", "authors": ["V.Botti"], "abstract": "The terms Agentic AI and Multiagentic AI have recently gained popularity in discussions on generative artificial intelligence, often used to describe autonomous software agents and systems composed of such agents. However, the use of these terms confuses these buzzwords with well-established concepts in AI literature: intelligent agents and multi-agent systems. This article offers a critical analysis of this conceptual misuse. We review the theoretical origins of \"agentic\" in the social sciences (Bandura, 1986) and philosophical notions of intentionality (Dennett, 1971), and then summarise foundational works on intelligent agents and multi-agent systems by Wooldridge, Jennings and others. We examine classic agent architectures, from simple reactive agents to Belief-Desire-Intention (BDI) models, and highlight key properties (autonomy, reactivity, proactivity, social capability) that define agency in AI. We then discuss recent developments in large language models (LLMs) and agent platforms based on LLMs, including the emergence of LLM-powered AI agents and open-source multi-agent orchestration frameworks. We argue that the term AI Agentic is often used as a buzzword for what are essentially AI agents, and AI Multiagentic for what are multi-agent systems. This confusion overlooks decades of research in the field of autonomous agents and multi-agent systems. The article advocates for scientific and technological rigour and the use of established terminology from the state of the art in AI, incorporating the wealth of existing knowledge, including standards for multi-agent system platforms, communication languages and coordination and cooperation algorithms, agreement technologies (automated negotiation, argumentation, virtual organisations, trust, reputation, etc.), into the new and promising wave of LLM-based AI agents, so as not to end up reinventing the wheel.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.01463.pdf", "abstract_url": "https://arxiv.org/abs/2506.01463", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文批判性地分析了‘Agentic AI’和‘Multiagentic AI’这些流行术语与AI文献中已建立的概念（如智能代理和多代理系统）之间的混淆。文章回顾了这些概念的理论起源，并讨论了当前基于大型语言模型（LLMs）的AI代理和多代理系统的发展，主张科学严谨性和使用既定的AI术语。", "motivation": "解决在生成人工智能讨论中，‘Agentic AI’和‘Multiagentic AI’这些流行术语与已有AI概念之间的混淆问题，促进科学和技术严谨性。", "method": "通过回顾‘agentic’在社会科学和哲学中的理论起源，以及智能代理和多代理系统的基础工作，分析当前基于LLMs的AI代理和多代理系统的发展。", "result": "指出‘AI Agentic’和‘AI Multiagentic’常被用作流行语，实质上分别指AI代理和多代理系统，这种混淆忽视了自主代理和多代理系统领域数十年的研究。", "conclusion": "主张在LLM-based AI代理的新浪潮中，应坚持科学和技术严谨性，利用现有知识和技术，避免重复发明轮子。"}}
{"id": "2506.01781", "title": "Enhancing Customer Service Chatbots with Context-Aware NLU through Selective Attention and Multi-task Learning", "authors": ["Subhadip Nandi", "Neeraj Agrawal", "Anshika Singh", "Priyanka Bhatt"], "abstract": "Customer service chatbots are conversational systems aimed at addressing customer queries, often by directing them to automated workflows. A crucial aspect of this process is the classification of the customer's intent. Presently, most intent classification models for customer care utilise only customer query for intent prediction. This may result in low-accuracy models, which cannot handle ambiguous queries. An ambiguous query like \"I didn't receive my package\" could indicate a delayed order, or an order that was delivered but the customer failed to receive it. Resolution of each of these scenarios requires the execution of very different sequence of steps. Utilizing additional information, such as the customer's order delivery status, in the right manner can help identify the intent for such ambiguous queries. In this paper, we have introduced a context-aware NLU model that incorporates both, the customer query and contextual information from the customer's order status for predicting customer intent. A novel selective attention module is used to extract relevant context features. We have also proposed a multi-task learning paradigm for the effective utilization of different label types available in our training data. Our suggested method, Multi-Task Learning Contextual NLU with Selective Attention Weighted Context (MTL-CNLU-SAWC), yields a 4.8% increase in top 2 accuracy score over the baseline model which only uses user queries, and a 3.5% improvement over existing state-of-the-art models that combine query and context. We have deployed our model to production for Walmart's customer care domain. Accurate intent prediction through MTL-CNLU-SAWC helps to better direct customers to automated workflows, thereby significantly reducing escalations to human agents, leading to almost a million dollars in yearly savings for the company.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.01781.pdf", "abstract_url": "https://arxiv.org/abs/2506.01781", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一种上下文感知的自然语言理解模型MTL-CNLU-SAWC，通过选择性注意力和多任务学习提高客户服务聊天机器人意图分类的准确性。", "motivation": "解决现有客户服务聊天机器人在处理模糊查询时意图分类准确率低的问题。", "method": "提出了一种结合客户查询和订单状态上下文信息的模型，采用选择性注意力模块提取相关上下文特征，并通过多任务学习有效利用训练数据中的不同标签类型。", "result": "与仅使用用户查询的基线模型相比，MTL-CNLU-SAWC在top 2准确率上提高了4.8%，比现有的结合查询和上下文的最先进模型提高了3.5%。", "conclusion": "MTL-CNLU-SAWC模型的准确意图预测能更好地将客户引导至自动化工作流程，显著减少人工代理的升级，为公司带来每年近百万美元的节省。"}}
{"id": "2506.01538", "title": "LAMARL: LLM-Aided Multi-Agent Reinforcement Learning for Cooperative Policy Generation", "authors": ["Guobin Zhu", "Rui Zhou", "Wenkang Ji", "Shiyu Zhao"], "abstract": "Although Multi-Agent Reinforcement Learning (MARL) is effective for complex multi-robot tasks, it suffers from low sample efficiency and requires iterative manual reward tuning. Large Language Models (LLMs) have shown promise in single-robot settings, but their application in multi-robot systems remains largely unexplored. This paper introduces a novel LLM-Aided MARL (LAMARL) approach, which integrates MARL with LLMs, significantly enhancing sample efficiency without requiring manual design. LAMARL consists of two modules: the first module leverages LLMs to fully automate the generation of prior policy and reward functions. The second module is MARL, which uses the generated functions to guide robot policy training effectively. On a shape assembly benchmark, both simulation and real-world experiments demonstrate the unique advantages of LAMARL. Ablation studies show that the prior policy improves sample efficiency by an average of 185.9% and enhances task completion, while structured prompts based on Chain-of-Thought (CoT) and basic APIs improve LLM output success rates by 28.5%-67.5%. Videos and code are available at", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": "Accepted by IEEE Robotics and Automation Letters", "pdf_url": "https://arxiv.org/pdf/2506.01538.pdf", "abstract_url": "https://arxiv.org/abs/2506.01538", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为LAMARL的新方法，通过将大型语言模型（LLMs）与多智能体强化学习（MARL）相结合，显著提高了样本效率，无需手动设计。LAMARL通过两个模块实现：一个模块利用LLMs自动生成先验策略和奖励函数，另一个模块是MARL，使用生成的函数有效指导机器人策略训练。在形状组装基准测试中，仿真和真实世界实验均展示了LAMARL的独特优势。", "motivation": "多智能体强化学习（MARL）在处理复杂多机器人任务时有效，但存在样本效率低和需要迭代手动调整奖励的问题。大型语言模型（LLMs）在单机器人设置中显示出潜力，但在多机器人系统中的应用尚未充分探索。", "method": "LAMARL方法整合了MARL与LLMs，包含两个模块：第一个模块利用LLMs自动生成先验策略和奖励函数；第二个模块是MARL，使用生成的函数指导机器人策略训练。", "result": "在形状组装基准测试中，LAMARL在仿真和真实世界实验中显示出独特优势。消融研究表明，先验策略平均提高了185.9%的样本效率，并提高了任务完成率；基于思维链（CoT）和基本API的结构化提示将LLM输出成功率提高了28.5%-67.5%。", "conclusion": "LAMARL通过整合LLMs与MARL，不仅显著提高了样本效率和任务完成率，还减少了对手动设计的依赖，为多机器人系统的策略生成提供了新的有效方法。"}}
{"id": "2506.01927", "title": "Online Competitive Information Gathering for Partially Observable Trajectory Games", "authors": ["Mel Krusniak", "Hang Xu", "Parker Palermo", "Forrest Laine"], "abstract": "Game-theoretic agents must make plans that optimally gather information about their opponents. These problems are modeled by partially observable stochastic games (POSGs), but planning in fully continuous POSGs is intractable without heavy offline computation or assumptions on the order of belief maintained by each player. We formulate a finite history/horizon refinement of POSGs which admits competitive information gathering behavior in trajectory space, and through a series of approximations, we present an online method for computing rational trajectory plans in these games which leverages particle-based estimations of the joint state space and performs stochastic gradient play. We also provide the necessary adjustments required to deploy this method on individual agents. The method is tested in continuous pursuit-evasion and warehouse-pickup scenarios (alongside extensions to $N > 2$ players and to more complex environments with visual and physical obstacles), demonstrating evidence of active information gathering and outperforming passive competitors.", "subjects": "Computer Science and Game Theory (cs.GT); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA); Robotics (cs.RO)", "comments": "Accepted at RSS 2025", "pdf_url": "https://arxiv.org/pdf/2506.01927.pdf", "abstract_url": "https://arxiv.org/abs/2506.01927", "categories": ["Computer Science and Game Theory (cs.GT)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种在线竞争性信息收集方法，用于部分可观察轨迹游戏，通过一系列近似和粒子基估计，实现了在连续追逃和仓库拣选等场景中的有效信息收集。", "motivation": "解决在完全连续的部分可观察随机游戏（POSGs）中，由于缺乏离线计算或对玩家信念顺序的假设，规划变得不可行的问题。", "method": "提出了一种有限历史/视野精炼的POSGs模型，利用粒子基估计联合状态空间，并执行随机梯度下降，实现在线计算理性轨迹计划。", "result": "在连续追逃和仓库拣选等场景中，该方法显示出主动信息收集的能力，并优于被动竞争者。", "conclusion": "该方法不仅适用于双人游戏，还能扩展到N>2的玩家和更复杂的环境，具有广泛的应用潜力。"}}
