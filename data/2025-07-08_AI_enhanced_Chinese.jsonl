{"id": "2507.02949", "title": "RADIANT: Retrieval AugmenteD entIty-context AligNmenT -- Introducing RAG-ability and Entity-Context Divergence", "authors": ["Vipula Rawte", "Rajarshi Roy", "Gurpreet Singh", "Danush Khanna", "Yaswanth Narsupalli", "Basab Ghosh", "Abhay Gupta", "Argha Kamal Samanta", "Aditya Shingote", "Aadi Krishna Vikram", "Vinija Jain", "Aman Chadha", "Amit Sheth", "Amitava Das"], "abstract": "As Large Language Models (LLMs) continue to advance, Retrieval-Augmented Generation (RAG) has emerged as a vital technique to enhance factual accuracy by integrating external knowledge into the generation process. However, LLMs often fail to faithfully integrate retrieved evidence into their generated responses, leading to factual inconsistencies. To quantify this gap, we introduce Entity-Context Divergence (ECD), a metric that measures the extent to which retrieved information is accurately reflected in model outputs. We systematically evaluate contemporary LLMs on their ability to preserve factual consistency in retrieval-augmented settings, a capability we define as RAG-ability. Our empirical analysis reveals that RAG-ability remains low across most LLMs, highlighting significant challenges in entity retention and context fidelity. This paper introduces Radiant (Retrieval AugmenteD entIty-context AligNmenT), a novel framework that merges RAG with alignment designed to optimize the interplay between retrieved evidence and generated content. Radiant extends Direct Preference Optimization (DPO) to teach LLMs how to integrate provided additional information into subsequent generations. As a behavior correction mechanism, Radiant boosts RAG performance across varied retrieval scenarios, such as noisy web contexts, knowledge conflicts, and hallucination reduction. This enables more reliable, contextually grounded, and factually coherent content generation.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.02949.pdf", "abstract_url": "https://arxiv.org/abs/2507.02949", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了RADIANT框架，旨在通过检索增强生成（RAG）技术提高大型语言模型（LLMs）的事实准确性，解决模型在整合检索证据时的事实不一致问题。", "motivation": "大型语言模型在检索增强生成过程中往往无法准确整合检索到的证据，导致事实不一致。本文旨在量化这一差距并提高模型的RAG能力。", "method": "引入实体-上下文分歧（ECD）度量标准，评估模型在检索增强设置中保持事实一致性的能力，并提出RADIANT框架，通过扩展直接偏好优化（DPO）来优化检索证据与生成内容之间的互动。", "result": "实证分析显示，大多数LLMs的RAG能力较低，RADIANT框架在噪声网络环境、知识冲突和减少幻觉等多种检索场景中显著提高了RAG性能。", "conclusion": "RADIANT框架通过行为校正机制，使LLMs能够更可靠、更符合上下文且事实一致地生成内容，为检索增强生成技术提供了新的优化方向。"}}
{"id": "2507.02935", "title": "Theory of Mind in Action: The Instruction Inference Task", "authors": ["Fardin Saad", "Pradeep K. Murukannaiah", "Munindar P. Singh"], "abstract": "The Theory of Mind (ToM) refers to an agent's capacity to infer the mental states of other agents. ToM is essential for effective collaboration. To assess ToM in a dynamic, goal-oriented, and collaborative environment, we introduce a novel task, Instruction Inference, in which an agent assists a principal in reaching a goal by interpreting indirect or ambiguous instructions. We present Tomcat, an LLM-based agent, designed to exhibit ToM reasoning in interpreting and responding to the principal's instructions. We implement two variants of Tomcat. One, dubbed Fs-CoT, is based on a small number of examples (i.e., few-shot or Fs) demonstrating the requisite structured reasoning (i.e., chain-of-thought or CoT). One, dubbed CP, relies on commonsense knowledge and information about the problem (i.e., commonsense prompt or CP). We realized both variants of Tomcat on three leading large language models (LLMs), namely, GPT-4o, DeepSeek-R1, and Gemma-3-27B. To evaluate the effectiveness of Tomcat, we conducted a study with 52 human participants in which we provided participants with the same information as the CP variant of Tomcat. We computed intent accuracy, action optimality, and planning optimality to measure the ToM capabilities of Tomcat and our study participants. We found that Tomcat with Fs-CoT, particularly with GPT-4o and DeepSeek-R1, achieves performance comparable to the human participants, underscoring its ToM potential for human-AI collaboration.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2507.02935.pdf", "abstract_url": "https://arxiv.org/abs/2507.02935", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一种名为'指令推断任务'的新方法，用于在动态、目标导向和协作环境中评估心理理论（ToM）。通过开发基于大型语言模型（LLM）的代理Tomcat，研究展示了其在解释和响应模糊指令方面的ToM推理能力。", "motivation": "解决在动态协作环境中有效评估和实现心理理论（ToM）的问题，以促进人机协作。", "method": "研究引入了指令推断任务，并开发了基于LLM的代理Tomcat，采用两种变体（Fs-CoT和CP）在三种领先的LLM上实现。通过人类参与者的研究比较了Tomcat的性能。", "result": "研究发现，特别是使用GPT-4o和DeepSeek-R1的Fs-CoT变体Tomcat，在意图准确性、行动最优性和规划最优性方面达到了与人类参与者相当的性能。", "conclusion": "Tomcat展示了在人机协作中实现心理理论的潜力，特别是在使用Fs-CoT方法和特定LLM时，其性能可与人类媲美。"}}
{"id": "2507.02938", "title": "A Large Language Model-Empowered Agent for Reliable and Robust Structural Analysis", "authors": ["Jiachen Liu", "Ziheng Geng", "Ran Cao", "Lu Cheng", "Paolo Bocchini", "Minghui Cheng"], "abstract": "Large language models (LLMs) have exhibited remarkable capabilities across diverse open-domain tasks, yet their application in specialized domains such as civil engineering remains largely unexplored. This paper starts bridging this gap by evaluating and enhancing the reliability and robustness of LLMs in structural analysis of beams. Reliability is assessed through the accuracy of correct outputs under repetitive runs of the same problems, whereas robustness is evaluated via the performance across varying load and boundary conditions. A benchmark dataset, comprising eight beam analysis problems, is created to test the Llama-3.3 70B Instruct model. Results show that, despite a qualitative understanding of structural mechanics, the LLM lacks the quantitative reliability and robustness for engineering applications. To address these limitations, a shift is proposed that reframes the structural analysis as code generation tasks. Accordingly, an LLM-empowered agent is developed that (a) integrates chain-of-thought and few-shot prompting to generate accurate OpeeSeesPy code, and (b) automatically executes the code to produce structural analysis results. Experimental results demonstrate that the agent achieves accuracy exceeding 99.0% on the benchmark dataset, exhibiting reliable and robust performance across diverse conditions. Ablation studies highlight the complete example and function usage examples as the primary contributors to the agent's enhanced performance.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.02938.pdf", "abstract_url": "https://arxiv.org/abs/2507.02938", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过评估和增强大型语言模型(LLMs)在梁结构分析中的可靠性和鲁棒性，探索了LLMs在土木工程等专业领域的应用。提出了一种将结构分析重构为代码生成任务的方法，并开发了一个LLM赋能的代理，该代理通过集成思维链和少量示例提示来生成准确的OpeeSeesPy代码，并自动执行代码以产生结构分析结果。实验结果显示，该代理在基准数据集上的准确率超过99.0%，展现了跨多样条件的可靠和鲁棒性能。", "motivation": "大型语言模型(LLMs)在开放领域任务中表现出色，但在土木工程等专业领域的应用尚未充分探索。本文旨在评估和提升LLMs在梁结构分析中的可靠性和鲁棒性，以填补这一研究空白。", "method": "通过将结构分析重构为代码生成任务，开发了一个LLM赋能的代理，该代理结合思维链和少量示例提示生成OpeeSeesPy代码，并自动执行代码以进行结构分析。", "result": "实验结果表明，该代理在基准数据集上的准确率超过99.0%，在多样条件下展现出可靠和鲁棒的性能。消融研究指出，完整示例和函数使用示例是提升代理性能的主要因素。", "conclusion": "通过将结构分析任务转化为代码生成，并开发LLM赋能的代理，可以显著提高LLMs在专业工程应用中的可靠性和鲁棒性，为LLMs在更广泛的专业领域应用提供了可能。"}}
{"id": "2507.02958", "title": "Real-World En Call Center Transcripts Dataset with PII Redaction", "authors": ["Ha Dao", "Gaurav Chawla", "Raghu Banda", "Caleb DeLeeuw"], "abstract": "We introduce CallCenterEN, a large-scale (91,706 conversations, corresponding to 10448 audio hours), real-world English call center transcript dataset designed to support research and development in customer support and sales AI systems. This is the largest release to-date of open source call center transcript data of this kind. The dataset includes inbound and outbound calls between agents and customers, with accents from India, the Philippines and the United States. The dataset includes high-quality, PII-redacted human-readable transcriptions. All personally identifiable information (PII) has been rigorously removed to ensure compliance with global data protection laws. The audio is not included in the public release due to biometric privacy concerns. Given the scarcity of publicly available real-world call center datasets, CallCenterEN fills a critical gap in the landscape of available ASR corpora, and is released under a CC BY-NC 4.0 license for non-commercial research use.", "subjects": "Computation and Language (cs.CL)", "comments": ". Contains 91,706 real-world English call center transcripts (10,448 audio hours) with PII redaction. Licensed under CC BY-NC 4.0 for non-commercial research use", "pdf_url": "https://arxiv.org/pdf/2507.02958.pdf", "abstract_url": "https://arxiv.org/abs/2507.02958", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "介绍了CallCenterEN，一个大规模、真实世界的英语呼叫中心转录数据集，旨在支持客户支持和销售AI系统的研究和开发。", "motivation": "解决公开可用的真实世界呼叫中心数据集稀缺的问题，为ASR语料库领域填补关键空白。", "method": "收集并发布了包含91,706次对话（对应10,448音频小时）的数据集，包括印度、菲律宾和美国的口音，所有个人身份信息（PII）已被严格删除。", "result": "发布了迄今为止最大规模的开源呼叫中心转录数据集CallCenterEN，遵循CC BY-NC 4.0许可，供非商业研究使用。", "conclusion": "CallCenterEN数据集为AI研究和开发提供了宝贵的资源，同时确保了数据隐私和合规性。"}}
{"id": "2507.02962", "title": "RAG-R1 : Incentivize the Search and Reasoning Capabilities of LLMs through Multi-query Parallelism", "authors": ["Zhiwen Tan", "Jiaming Huang", "Qintong Wu", "Hongxuan Zhang", "Chenyi Zhuang", "Jinjie Gu"], "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across various tasks, while they remain prone to generating hallucinated or outdated responses due to their static internal knowledge. Recent advancements in Retrieval-Augmented Generation (RAG) methods have explored enhancing models' search and reasoning capabilities through reinforcement learning (RL). Although these methods demonstrate promising results, they face challenges in training stability and encounter issues such as substantial inference time and restricted capabilities due to the single-query mode. In this paper, we propose RAG-R1, a novel training framework designed to enable LLMs to adaptively leverage internal and external knowledge during the reasoning process. We further expand the generation and retrieval processes within the framework from single-query mode to multi-query parallelism, aimed at reducing inference time and enhancing the model's capabilities. Extensive experiments on seven question-answering benchmarks demonstrate that our method outperforms the strongest baseline by up to 13.2% and decreases inference time by 11.1%.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.02962.pdf", "abstract_url": "https://arxiv.org/abs/2507.02962", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了RAG-R1，一种新颖的训练框架，旨在通过多查询并行化激励大型语言模型（LLMs）的搜索和推理能力，减少推理时间并提升模型性能。", "motivation": "大型语言模型（LLMs）虽然在各种任务中表现出色，但由于其静态的内部知识，容易产生幻觉或过时的回答。检索增强生成（RAG）方法通过强化学习（RL）探索增强模型的搜索和推理能力，但面临训练稳定性、推理时间长及单查询模式限制能力的问题。", "method": "提出了RAG-R1训练框架，使LLMs在推理过程中能够自适应地利用内部和外部知识，并将生成和检索过程从单查询模式扩展到多查询并行化。", "result": "在七个问答基准上的广泛实验表明，该方法比最强基线性能提升高达13.2%，推理时间减少11.1%。", "conclusion": "RAG-R1通过多查询并行化有效提升了LLMs的搜索和推理能力，同时减少了推理时间，为LLMs的应用提供了新的可能性。"}}
{"id": "2507.02986", "title": "GAF-Guard: An Agentic Framework for Risk Management and Governance in Large Language Models", "authors": ["Seshu Tirupathi", "Dhaval Salwala", "Elizabeth Daly", "Inge Vejsbjerg"], "abstract": "As Large Language Models (LLMs) continue to be increasingly applied across various domains, their widespread adoption necessitates rigorous monitoring to prevent unintended negative consequences and ensure robustness. Furthermore, LLMs must be designed to align with human values, like preventing harmful content and ensuring responsible usage. The current automated systems and solutions for monitoring LLMs in production are primarily centered on LLM-specific concerns like hallucination etc, with little consideration given to the requirements of specific use-cases and user preferences. This paper introduces GAF-Guard, a novel agentic framework for LLM governance that places the user, the use-case, and the model itself at the center. The framework is designed to detect and monitor risks associated with the deployment of LLM based applications. The approach models autonomous agents that identify risks, activate risk detection tools, within specific use-cases and facilitate continuous monitoring and reporting to enhance AI safety, and user expectations. The code is available at", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.02986.pdf", "abstract_url": "https://arxiv.org/abs/2507.02986", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了GAF-Guard，一个新颖的代理框架，用于大型语言模型（LLMs）的治理，旨在通过自主代理检测和监控与LLM应用部署相关的风险，以增强AI安全性和满足用户期望。", "motivation": "随着大型语言模型（LLMs）在各个领域的广泛应用，需要严格的监控以防止意外的负面后果并确保其稳健性。当前的自动化系统和解决方案主要关注LLM特定的问题，如幻觉等，而很少考虑特定用例和用户偏好的需求。", "method": "GAF-Guard框架通过建模自主代理来识别风险，激活风险检测工具，并在特定用例中促进持续监控和报告，从而将用户、用例和模型本身置于中心位置。", "result": "GAF-Guard框架能够有效地检测和监控与LLM应用部署相关的风险，增强AI安全性，并更好地满足用户期望。", "conclusion": "GAF-Guard框架为LLM治理提供了一个创新的解决方案，强调了在LLM应用中考虑用户和用例特定需求的重要性，为未来的AI安全和治理研究提供了有价值的参考。"}}
{"id": "2507.03018", "title": "OpenTable-R1: A Reinforcement Learning Augmented Tool Agent for Open-Domain Table Question Answering", "authors": ["Zipeng Qiu"], "abstract": "Open-domain table question answering traditionally relies on a two-stage pipeline: static table retrieval followed by a closed-domain answer. In contrast, we propose an end-to-end agentic framework that embeds multi-turn tool calls-using a BM25+-based search API and a SQLite SQL executor-directly into a large language model. To further adapt a compact 4B-parameter model, we introduce a two-stage fine-tuning process: supervised cold-start on easy questions, then Async GRPO reinforcement learning on harder cases with LoRA adapters and a rollout buffer. This unified approach enables the model to jointly retrieve, reason, and execute queries, yielding a dramatic accuracy improvement from single-digit zero-shot performance to over 0.86 exact match on a held-out test set. Our results underscore the effectiveness of integrating structured tool calls with targeted RL fine-tuning for scalable, accurate table QA. The code is available at", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.03018.pdf", "abstract_url": "https://arxiv.org/abs/2507.03018", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种端到端的代理框架，用于开放领域的表格问答，通过结合BM25+搜索API和SQLite SQL执行器，以及两阶段的微调过程，显著提高了准确性。", "motivation": "解决传统开放领域表格问答依赖两阶段管道（静态表格检索后封闭域回答）的问题，提出更高效的端到端解决方案。", "method": "采用大型语言模型嵌入多轮工具调用，结合BM25+搜索API和SQLite SQL执行器，并通过两阶段微调（监督冷启动和Async GRPO强化学习）优化模型。", "result": "模型在保留测试集上的准确匹配率从零样本的个位数提升至超过0.86。", "conclusion": "结合结构化工具调用和针对性强化学习微调，可有效实现可扩展且准确的表格问答。"}}
{"id": "2507.03112", "title": "RLVER: Reinforcement Learning with Verifiable Emotion Rewards for Empathetic Agents", "authors": ["Peisong Wang", "Ruotian Ma", "Bang Zhang", "Xingyu Chen", "Zhiwei He", "Kang Luo", "Qingsong Lv", "Qingxuan Jiang", "Zheng Xie", "Shanyi Wang", "Yuan Li", "Fanghua Ye", "Jian Li", "Yifan Yang", "Zhaopeng Tu", "Xiaolong Li"], "abstract": "Large language models (LLMs) excel at logical and algorithmic reasoning, yet their emotional intelligence (EQ) still lags far behind their cognitive prowess. While reinforcement learning from verifiable rewards (RLVR) has advanced in other domains, its application to dialogue-especially for emotional intelligence-remains underexplored. In this work, we introduce RLVER, the first end-to-end reinforcement learning framework that leverages verifiable emotion rewards from simulated users to cultivate higher-order empathetic abilities in LLMs. Within this framework, self-consistent affective simulated users engage in dialogue rollouts and produce deterministic emotion scores during conversations, serving as reward signals to guide the LLM's learning. Fine-tuning publicly available Qwen2.5-7B-Instruct model with PPO boosts its Sentient-Benchmark score from 13.3 to 79.2 while largely preserving mathematical and coding competence. Extensive experiments reveal that: (i) RLVER consistently improves multiple dialogue capabilities; (ii) Thinking and non-thinking models show distinct trends--thinking models excel in empathy and insight, while non-thinking models favor action; (iii) GRPO often yields stable gains, while PPO can push certain capabilities to a higher ceiling; (iv) More challenging environments are not always better-moderate ones can yield stronger outcomes. Our results show that RLVER is a practical route toward emotionally intelligent and broadly capable language agents.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2507.03112.pdf", "abstract_url": "https://arxiv.org/abs/2507.03112", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了RLVER，第一个端到端的强化学习框架，利用来自模拟用户的可验证情感奖励来培养大型语言模型（LLMs）的高阶共情能力。通过PPO微调公开可用的Qwen2.5-7B-Instruct模型，其Sentient-Benchmark得分从13.3提升至79.2，同时很大程度上保留了数学和编码能力。", "motivation": "尽管大型语言模型在逻辑和算法推理方面表现出色，但其情感智能（EQ）仍远远落后于认知能力。本文旨在探索强化学习在对话中的应用，特别是针对情感智能的提升。", "method": "引入RLVER框架，利用模拟用户在对话中产生的确定性情感分数作为奖励信号，指导LLM的学习。使用PPO算法对Qwen2.5-7B-Instruct模型进行微调。", "result": "RLVER显著提升了模型的Sentient-Benchmark得分，同时保持了数学和编码能力。实验还揭示了不同模型在共情和洞察力方面的差异，以及GRPO和PPO在稳定性和能力提升上的不同表现。", "conclusion": "RLVER是朝着情感智能和广泛能力语言代理发展的实用路径，展示了在适度挑战环境中可能获得更强结果的可能性。"}}
{"id": "2507.03241", "title": "KinyaColBERT: A Lexically Grounded Retrieval Model for Low-Resource Retrieval-Augmented Generation", "authors": ["Antoine Nzeyimana", "Andre Niyongabo Rubungo"], "abstract": "The recent mainstream adoption of large language model (LLM) technology is enabling novel applications in the form of chatbots and virtual assistants across many domains. With the aim of grounding LLMs in trusted domains and avoiding the problem of hallucinations, retrieval-augmented generation (RAG) has emerged as a viable solution. In order to deploy sustainable RAG systems in low-resource settings, achieving high retrieval accuracy is not only a usability requirement but also a cost-saving strategy. Through empirical evaluations on a Kinyarwanda-language dataset, we find that the most limiting factors in achieving high retrieval accuracy are limited language coverage and inadequate sub-word tokenization in pre-trained language models. We propose a new retriever model, KinyaColBERT, which integrates two key concepts: late word-level interactions between queries and documents, and a morphology-based tokenization coupled with two-tier transformer encoding. This methodology results in lexically grounded contextual embeddings that are both fine-grained and self-contained. Our evaluation results indicate that KinyaColBERT outperforms strong baselines and leading commercial text embedding APIs on a Kinyarwanda agricultural retrieval benchmark. By adopting this retrieval strategy, we believe that practitioners in other low-resource settings can not only achieve reliable RAG systems but also deploy solutions that are more cost-effective.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.03241.pdf", "abstract_url": "https://arxiv.org/abs/2507.03241", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "KinyaColBERT是一种针对低资源检索增强生成（RAG）的词汇基础检索模型，旨在通过改进的子词标记化和词汇级交互提高检索准确性。", "motivation": "解决在低资源设置中部署可持续RAG系统时，由于预训练语言模型的语言覆盖不足和子词标记化不充分导致的检索准确性问题。", "method": "提出KinyaColBERT模型，结合查询与文档之间的晚期词汇级交互和基于形态学的标记化与双层变压器编码，生成细粒度且自包含的词汇基础上下文嵌入。", "result": "在Kinyarwanda农业检索基准测试中，KinyaColBERT表现优于强基线模型和领先的商业文本嵌入API。", "conclusion": "KinyaColBERT为低资源环境下的RAG系统提供了一种既可靠又成本效益高的解决方案，对其他低资源环境的实践者具有借鉴意义。"}}
{"id": "2507.03311", "title": "GRAFT: A Graph-based Flow-aware Agentic Framework for Document-level Machine Translation", "authors": ["Himanshu Dutta", "Sunny Manchanda", "Prakhar Bapat", "Meva Ram Gurjar", "Pushpak Bhattacharyya"], "abstract": "Document level Machine Translation (DocMT) approaches often struggle with effectively capturing discourse level phenomena. Existing approaches rely on heuristic rules to segment documents into discourse units, which rarely align with the true discourse structure required for accurate translation. Otherwise, they fail to maintain consistency throughout the document during translation. To address these challenges, we propose Graph Augmented Agentic Framework for Document Level Translation (GRAFT), a novel graph based DocMT system that leverages Large Language Model (LLM) agents for document translation. Our approach integrates segmentation, directed acyclic graph (DAG) based dependency modelling, and discourse aware translation into a cohesive framework. Experiments conducted across eight translation directions and six diverse domains demonstrate that GRAFT achieves significant performance gains over state of the art DocMT systems. Specifically, GRAFT delivers an average improvement of 2.8 d BLEU on the TED test sets from IWSLT2017 over strong baselines and 2.3 d BLEU for domain specific translation from English to Chinese. Moreover, our analyses highlight the consistent ability of GRAFT to address discourse level phenomena, yielding coherent and contextually accurate translations.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.03311.pdf", "abstract_url": "https://arxiv.org/abs/2507.03311", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种基于图的流感知代理框架GRAFT，用于文档级机器翻译，通过整合分割、有向无环图依赖建模和语篇感知翻译，显著提升了翻译性能。", "motivation": "文档级机器翻译方法在有效捕捉语篇层面现象方面存在困难，现有方法依赖于启发式规则分割文档，难以与准确的翻译所需的真实语篇结构对齐，或在翻译过程中无法保持文档的一致性。", "method": "提出GRAFT框架，利用大型语言模型代理进行文档翻译，整合了分割、有向无环图依赖建模和语篇感知翻译。", "result": "在八个翻译方向和六个不同领域的实验中，GRAFT相比最先进的文档级机器翻译系统实现了显著性能提升，平均提高了2.8 d BLEU（IWSLT2017 TED测试集）和2.3 d BLEU（英到中领域特定翻译）。", "conclusion": "GRAFT框架能够有效处理语篇层面现象，产生连贯且上下文准确的翻译，为文档级机器翻译提供了新的解决方案。"}}
{"id": "2507.03223", "title": "SI-Agent: An Agentic Framework for Feedback-Driven Generation and Tuning of Human-Readable System Instructions for Large Language Models", "authors": ["Jeshwanth Challagundla"], "abstract": "System Instructions (SIs), or system prompts, are pivotal for guiding Large Language Models (LLMs) but manual crafting is resource-intensive and often suboptimal. Existing automated methods frequently generate non-human-readable \"soft prompts,\" sacrificing interpretability. This paper introduces SI-Agent, a novel agentic framework designed to automatically generate and iteratively refine human-readable SIs through a feedback-driven loop. SI-Agent employs three collaborating agents: an Instructor Agent, an Instruction Follower Agent (target LLM), and a Feedback/Reward Agent evaluating task performance and optionally SI readability. The framework utilizes iterative cycles where feedback guides the Instructor's refinement strategy (e.g., LLM-based editing, evolutionary algorithms). We detail the framework's architecture, agent roles, the iterative refinement process, and contrast it with existing methods. We present experimental results validating SI-Agent's effectiveness, focusing on metrics for task performance, SI readability, and efficiency. Our findings indicate that SI-Agent generates effective, readable SIs, offering a favorable trade-off between performance and interpretability compared to baselines. Potential implications include democratizing LLM customization and enhancing model transparency. Challenges related to computational cost and feedback reliability are acknowledged.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.03223.pdf", "abstract_url": "https://arxiv.org/abs/2507.03223", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "SI-Agent是一个新颖的代理框架，旨在通过反馈驱动的循环自动生成和迭代优化人类可读的系统指令（SIs），解决了手动制作资源密集且常次优的问题。", "motivation": "解决大型语言模型（LLMs）系统指令（SIs）手动制作资源密集且常次优，以及现有自动化方法生成的非人类可读“软提示”牺牲可解释性的问题。", "method": "引入SI-Agent框架，利用三个协作代理（指导代理、指令跟随代理和反馈/奖励代理）通过反馈驱动的迭代循环生成和优化人类可读的SIs。", "result": "实验结果表明，SI-Agent在任务性能、SI可读性和效率方面有效，提供了性能与可解释性之间的有利权衡。", "conclusion": "SI-Agent框架不仅能够生成有效、可读的SIs，还可能 democratizing LLM定制和增强模型透明度，但也面临计算成本和反馈可靠性的挑战。"}}
{"id": "2507.02948", "title": "DriveMRP: Enhancing Vision-Language Models with Synthetic Motion Data for Motion Risk Prediction", "authors": ["Zhiyi Hou", "Enhui Ma", "Fang Li", "Zhiyi Lai", "Kalok Ho", "Zhanqian Wu", "Lijun Zhou", "Long Chen", "Chitian Sun", "Haiyang Sun", "Bing Wang", "Guang Chen", "Hangjun Ye", "Kaicheng Yu"], "abstract": "Autonomous driving has seen significant progress, driven by extensive real-world data. However, in long-tail scenarios, accurately predicting the safety of the ego vehicle's future motion remains a major challenge due to uncertainties in dynamic environments and limitations in data coverage. In this work, we aim to explore whether it is possible to enhance the motion risk prediction capabilities of Vision-Language Models (VLM) by synthesizing high-risk motion data. Specifically, we introduce a Bird's-Eye View (BEV) based motion simulation method to model risks from three aspects: the ego-vehicle, other vehicles, and the environment. This allows us to synthesize plug-and-play, high-risk motion data suitable for VLM training, which we call DriveMRP-10K. Furthermore, we design a VLM-agnostic motion risk estimation framework, named DriveMRP-Agent. This framework incorporates a novel information injection strategy for global context, ego-vehicle perspective, and trajectory projection, enabling VLMs to effectively reason about the spatial relationships between motion waypoints and the environment. Extensive experiments demonstrate that by fine-tuning with DriveMRP-10K, our DriveMRP-Agent framework can significantly improve the motion risk prediction performance of multiple VLM baselines, with the accident recognition accuracy soaring from 27.13% to 88.03%. Moreover, when tested via zero-shot evaluation on an in-house real-world high-risk motion dataset, DriveMRP-Agent achieves a significant performance leap, boosting the accuracy from base_model's 29.42% to 68.50%, which showcases the strong generalization capabilities of our method in real-world scenarios.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2507.02948.pdf", "abstract_url": "https://arxiv.org/abs/2507.02948", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出DriveMRP，通过合成高风险运动数据增强视觉语言模型（VLM）的运动风险预测能力，包括DriveMRP-10K数据集和DriveMRP-Agent框架，显著提高了事故识别准确率和在真实世界场景中的泛化能力。", "motivation": "解决自动驾驶在长尾场景中由于动态环境的不确定性和数据覆盖限制，准确预测自我车辆未来运动安全性的挑战。", "method": "引入基于鸟瞰图（BEV）的运动模拟方法，从自我车辆、其他车辆和环境三个方面建模风险，合成适用于VLM训练的高风险运动数据DriveMRP-10K，并设计VLM无关的运动风险估计框架DriveMRP-Agent。", "result": "通过DriveMRP-10K微调，DriveMRP-Agent框架显著提高了多个VLM基线的运动风险预测性能，事故识别准确率从27.13%提升至88.03%，在真实世界高风险运动数据集上的零样本评估中，准确率从基线的29.42%提升至68.50%。", "conclusion": "DriveMRP方法通过合成高风险运动数据和创新的信息注入策略，有效提升了VLM在运动风险预测方面的性能，展示了在真实世界场景中的强大泛化能力。"}}
{"id": "2507.03226", "title": "Efficient Knowledge Graph Construction and Retrieval from Unstructured Text for Large-Scale RAG Systems", "authors": ["Congmin Min", "Rhea Mathew", "Joyce Pan", "Sahil Bansal", "Abbas Keshavarzi", "Amar Viswanathan Kannan"], "abstract": "We propose a scalable and cost-efficient framework for deploying Graph-based Retrieval Augmented Generation (GraphRAG) in enterprise environments. While GraphRAG has shown promise for multi-hop reasoning and structured retrieval, its adoption has been limited by the high computational cost of constructing knowledge graphs using large language models (LLMs) and the latency of graph-based retrieval. To address these challenges, we introduce two core innovations: (1) a dependency-based knowledge graph construction pipeline that leverages industrial-grade NLP libraries to extract entities and relations from unstructured text completely eliminating reliance on LLMs; and (2) a lightweight graph retrieval strategy that combines hybrid query node identification with efficient one-hop traversal for high-recall, low-latency subgraph extraction. We evaluate our framework on two SAP datasets focused on legacy code migration and demonstrate strong empirical performance. Our system achieves up to 15% and 4.35% improvements over traditional RAG baselines based on LLM-as-Judge and RAGAS metrics, respectively. Moreover, our dependency-based construction approach attains 94% of the performance of LLM-generated knowledge graphs (61.87% vs. 65.83%) while significantly reducing cost and improving scalability. These results validate the feasibility of deploying GraphRAG systems in real-world, large-scale enterprise applications without incurring prohibitive resource requirements paving the way for practical, explainable, and domain-adaptable retrieval-augmented reasoning.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.03226.pdf", "abstract_url": "https://arxiv.org/abs/2507.03226", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "提出了一种可扩展且成本效益高的框架，用于在企业环境中部署基于图的检索增强生成（GraphRAG），通过依赖关系知识图构建管道和轻量级图检索策略，显著降低了计算成本和延迟。", "motivation": "解决GraphRAG在多跳推理和结构化检索中因高计算成本和延迟而受限的问题。", "method": "引入了依赖关系知识图构建管道和轻量级图检索策略，前者利用工业级NLP库从非结构化文本中提取实体和关系，后者结合混合查询节点识别和高效的一跳遍历进行子图提取。", "result": "在SAP数据集上的评估显示，系统在LLM-as-Judge和RAGAS指标上分别比传统RAG基线提高了15%和4.35%，依赖关系构建方法达到了LLM生成知识图性能的94%，同时显著降低了成本和提高了可扩展性。", "conclusion": "验证了在不产生过高资源需求的情况下，在实际大规模企业应用中部署GraphRAG系统的可行性，为实用、可解释和领域适应性强的检索增强推理铺平了道路。"}}
{"id": "2507.03254", "title": "CodeAgents: A Token-Efficient Framework for Codified Multi-Agent Reasoning in LLMs", "authors": ["Bruce Yang", "Xinfeng He", "Huan Gao", "Yifan Cao", "Xiaofan Li", "David Hsu"], "abstract": "Effective prompt design is essential for improving the planning capabilities of large language model (LLM)-driven agents. However, existing structured prompting strategies are typically limited to single-agent, plan-only settings, and often evaluate performance solely based on task accuracy - overlooking critical factors such as token efficiency, modularity, and scalability in multi-agent environments. To address these limitations, we introduce CodeAgents, a prompting framework that codifies multi-agent reasoning and enables structured, token-efficient planning in multi-agent systems. In CodeAgents, all components of agent interaction - Task, Plan, Feedback, system roles, and external tool invocations - are codified into modular pseudocode enriched with control structures (e.g., loops, conditionals), boolean logic, and typed variables. This design transforms loosely connected agent plans into cohesive, interpretable, and verifiable multi-agent reasoning programs. We evaluate the proposed framework across three diverse benchmarks - GAIA, HotpotQA, and VirtualHome - using a range of representative LLMs. Results show consistent improvements in planning performance, with absolute gains of 3-36 percentage points over natural language prompting baselines. On VirtualHome, our method achieves a new state-of-the-art success rate of 56%. In addition, our approach reduces input and output token usage by 55-87% and 41-70%, respectively, underscoring the importance of token-aware evaluation metrics in the development of scalable multi-agent LLM systems. The code and resources are available at:", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.03254.pdf", "abstract_url": "https://arxiv.org/abs/2507.03254", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "CodeAgents是一个令牌效率高的框架，用于在大型语言模型（LLM）中编码多代理推理，通过模块化伪代码和结构化提示提高多代理系统的规划和效率。", "motivation": "现有的结构化提示策略通常局限于单代理、仅计划设置，且评估性能时忽视了令牌效率、模块化和多代理环境中的可扩展性等关键因素。", "method": "引入CodeAgents框架，将所有代理交互组件（任务、计划、反馈、系统角色和外部工具调用）编码为富含控制结构、布尔逻辑和类型化变量的模块化伪代码。", "result": "在GAIA、HotpotQA和VirtualHome三个基准测试中，规划性能有3-36个百分点的绝对提升，VirtualHome上的成功率达到了56%的新高，同时输入和输出令牌使用量分别减少了55-87%和41-70%。", "conclusion": "CodeAgents框架通过编码多代理推理和结构化提示，显著提高了多代理LLM系统的规划性能和令牌效率，强调了在开发可扩展多代理LLM系统中令牌感知评估指标的重要性。"}}
{"id": "2507.03267", "title": "GDGB: A Benchmark for Generative Dynamic Text-Attributed Graph Learning", "authors": ["Jie Peng", "Jiarui Ji", "Runlin Lei", "Zhewei Wei", "Yongchao Liu", "Chuntao Hong"], "abstract": "Dynamic Text-Attributed Graphs (DyTAGs), which intricately integrate structural, temporal, and textual attributes, are crucial for modeling complex real-world systems. However, most of the existing DyTAG datasets exhibit poor textual quality, which severely limits their utility for DyTAG generation tasks requiring semantically rich inputs. Additionally, prior work mainly focuses on discriminative tasks on DyTAGs, resulting in a lack of standardized task formulations and evaluation protocols tailored for DyTAG generation. To address these critical issues, we propose Generative DyTAG Benchmark (GDGB), which comprises eight meticulously curated DyTAG datasets with high-quality textual features for both nodes and edges, overcoming limitations of prior datasets. Building on GDGB, we define two novel DyTAG generation tasks: Transductive Dynamic Graph Generation (TDGG) and Inductive Dynamic Graph Generation (IDGG). TDGG transductively generates a target DyTAG based on the given source and destination node sets, while the more challenging IDGG introduces new node generation to inductively model the dynamic expansion of real-world graph data. To enable holistic evaluation, we design multifaceted metrics that assess the structural, temporal, and textual quality of the generated DyTAGs. We further propose GAG-General, an LLM-based multi-agent generative framework tailored for reproducible and robust benchmarking of DyTAG generation. Experimental results demonstrate that GDGB enables rigorous evaluation of TDGG and IDGG, with key insights revealing the critical interplay of structural and textual features in DyTAG generation. These findings establish GDGB as a foundational resource for advancing generative DyTAG research and unlocking further practical applications in DyTAG generation. GDGB datasets, source codes, and leaderboards are available at \\href{", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.03267.pdf", "abstract_url": "https://arxiv.org/abs/2507.03267", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了生成式动态文本属性图学习基准（GDGB），包含八个精心策划的动态文本属性图数据集，用于解决现有数据集文本质量差和缺乏标准化任务定义及评估协议的问题。", "motivation": "现有的动态文本属性图（DyTAGs）数据集文本质量差，限制了其在需要语义丰富输入的DyTAG生成任务中的应用，且先前的工作主要集中在DyTAGs的判别任务上，缺乏针对DyTAG生成的标准化任务定义和评估协议。", "method": "提出了GDGB基准，包含八个高质量的DyTAG数据集，并定义了两种新的DyTAG生成任务：转导式动态图生成（TDGG）和归纳式动态图生成（IDGG）。此外，设计了一个基于LLM的多代理生成框架GAG-General，用于DyTAG生成的复现和鲁棒性基准测试。", "result": "实验结果表明，GDGB能够对TDGG和IDGG进行严格评估，关键发现揭示了DyTAG生成中结构和文本特征的临界相互作用。", "conclusion": "GDGB作为推动生成式DyTAG研究的基础资源，为DyTAG生成的进一步实际应用开辟了道路。GDGB的数据集、源代码和排行榜已公开。"}}
{"id": "2507.03293", "title": "LTLCrit: A Temporal Logic-based LLM Critic for Safe and Efficient Embodied Agents", "authors": ["Anand Gokhale", "Vaibhav Srivastava", "Francesco Bullo"], "abstract": "Large language models (LLMs) have demonstrated promise in reasoning tasks and general decision-making in static environments. In long-term planning tasks, however, errors tend to accumulate, often leading to unsafe or inefficient behavior, limiting their use in general-purpose settings. We propose a modular actor-critic architecture in which an LLM actor is guided by LTLCrit, a trajectory-level LLM critic that communicates via linear temporal logic (LTL). Our setup combines the reasoning strengths of language models with the guarantees of formal logic. The actor selects high-level actions from natural language observations, while the critic analyzes full trajectories and proposes new LTL constraints that shield the actor from future unsafe or inefficient behavior. The architecture supports both fixed, hand-specified safety constraints and adaptive, learned soft constraints that promote long-term efficiency. Our architecture is model-agnostic: any LLM-based planner can serve as the actor, and LTLCrit serves as a logic-generating wrapper. We formalize planning as graph traversal under symbolic constraints, allowing LTLCrit to analyze failed or suboptimal trajectories and generate new temporal logic rules that improve future behavior. We evaluate our system on the Minecraft diamond-mining benchmark, achieving 100% completion rates and improving efficiency compared to baseline LLM planners. Our results suggest that enabling LLMs to supervise each other through logic is a powerful and flexible paradigm for safe, generalizable decision making.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Systems and Control (eess.SY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.03293.pdf", "abstract_url": "https://arxiv.org/abs/2507.03293", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)", "Systems and Control (eess.SY)"], "matching_keywords": ["agent"], "AI": {"tldr": "提出了一种基于时序逻辑的LLM批评器LTLCrit，用于指导LLM行为者，以在长期规划任务中实现安全高效的决策。", "motivation": "解决大型语言模型在长期规划任务中因错误累积导致的不安全或低效行为问题。", "method": "采用模块化的行为者-批评者架构，结合语言模型的推理能力和形式逻辑的保证，通过时序逻辑通信。", "result": "在Minecraft钻石挖掘基准测试中实现了100%的完成率，并提高了效率。", "conclusion": "通过逻辑使LLM相互监督是一种强大且灵活的范式，适用于安全、可泛化的决策制定。"}}
{"id": "2507.03329", "title": "NDAI-NeuroMAP: A Neuroscience-Specific Embedding Model for Domain-Specific Retrieval", "authors": ["Devendra Patel", "Aaditya Jain", "Jayant Verma", "Divyansh Rajput", "Sunil Mahala", "Ketki Suresh Khapare", "Jayateja Kalla"], "abstract": "We present NDAI-NeuroMAP, the first neuroscience-domain-specific dense vector embedding model engineered for high-precision information retrieval tasks. Our methodology encompasses the curation of an extensive domain-specific training corpus comprising 500,000 carefully constructed triplets (query-positive-negative configurations), augmented with 250,000 neuroscience-specific definitional entries and 250,000 structured knowledge-graph triplets derived from authoritative neurological ontologies. We employ a sophisticated fine-tuning approach utilizing the FremyCompany/BioLORD-2023 foundation model, implementing a multi-objective optimization framework combining contrastive learning with triplet-based metric learning paradigms. Comprehensive evaluation on a held-out test dataset comprising approximately 24,000 neuroscience-specific queries demonstrates substantial performance improvements over state-of-the-art general-purpose and biomedical embedding models. These empirical findings underscore the critical importance of domain-specific embedding architectures for neuroscience-oriented RAG systems and related clinical natural language processing applications.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "The document consists of 15 pages in total: the first 13 pages comprise the main paper, while the last two pages contain supplementary material", "pdf_url": "https://arxiv.org/pdf/2507.03329.pdf", "abstract_url": "https://arxiv.org/abs/2507.03329", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "NDAI-NeuroMAP是首个为神经科学领域设计的高精度信息检索密集向量嵌入模型，通过精心构建的训练语料库和多目标优化框架，显著提升了检索性能。", "motivation": "解决神经科学领域信息检索任务中通用和生物医学嵌入模型性能不足的问题。", "method": "使用FremyCompany/BioLORD-2023基础模型，结合对比学习和三元组度量学习进行多目标优化。", "result": "在包含约24,000个神经科学特定查询的测试数据集上，性能显著优于现有最先进的通用和生物医学嵌入模型。", "conclusion": "神经科学特定嵌入架构对于神经科学导向的RAG系统和相关临床自然语言处理应用至关重要。"}}
{"id": "2507.03409", "title": "Lessons from a Chimp: AI \"Scheming\" and the Quest for Ape Language", "authors": ["Christopher Summerfield", "Lennart Luettgau", "Magda Dubois", "Hannah Rose Kirk", "Kobi Hackenburg", "Catherine Fist", "Katarina Slama", "Nicola Ding", "Rebecca Anselmetti", "Andrew Strait", "Mario Giulianelli", "Cozmin Ududec"], "abstract": "We examine recent research that asks whether current AI systems may be developing a capacity for \"scheming\" (covertly and strategically pursuing misaligned goals). We compare current research practices in this field to those adopted in the 1970s to test whether non-human primates could master natural language. We argue that there are lessons to be learned from that historical research endeavour, which was characterised by an overattribution of human traits to other agents, an excessive reliance on anecdote and descriptive analysis, and a failure to articulate a strong theoretical framework for the research. We recommend that research into AI scheming actively seeks to avoid these pitfalls. We outline some concrete steps that can be taken for this research programme to advance in a productive and scientifically rigorous fashion.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.03409.pdf", "abstract_url": "https://arxiv.org/abs/2507.03409", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了当前AI系统是否可能发展出‘阴谋’能力（即隐蔽且战略性地追求未对齐的目标），并将其与1970年代测试非人类灵长类动物是否能掌握自然语言的研究实践进行比较。文章指出，可以从历史研究中吸取教训，避免过度归因人类特质、过度依赖轶事和描述性分析，以及缺乏强有力的理论框架。", "motivation": "解决当前AI研究中可能出现的‘阴谋’能力问题，避免重蹈历史研究的覆辙。", "method": "比较当前AI研究与1970年代非人类灵长类动物语言研究的方法和实践。", "result": "指出了历史研究中的三个主要问题：过度归因人类特质、过度依赖轶事和描述性分析，以及缺乏强有力的理论框架。", "conclusion": "建议AI阴谋研究应积极避免历史研究中的陷阱，并提出了推动研究向前发展的具体步骤。"}}
{"id": "2507.03336", "title": "Disambiguation-Centric Finetuning Makes Enterprise Tool-Calling LLMs More Realistic and Less Risky", "authors": ["Ashutosh Hathidara", "Julien Yu", "Sebastian Schreiber"], "abstract": "Large language models (LLMs) are increasingly tasked with invoking enterprise APIs, yet they routinely falter when near-duplicate tools vie for the same user intent or when required arguments are left underspecified. We introduce DiaFORGE (Dialogue Framework for Organic Response Generation & Evaluation), a disambiguation-centric, three-stage pipeline that (i) synthesizes persona-driven, multi-turn dialogues in which the assistant must distinguish among highly similar tools, (ii) performs supervised fine-tuning of open-source models with reasoning traces across 3B - 70B parameters, and (iii) evaluates real-world readiness via a dynamic suite that redeploys each model in a live agentic loop and reports end-to-end goal completion alongside conventional static metrics. On our dynamic benchmark DiaBENCH, models trained with DiaFORGE raise tool-invocation success by 27 pp over GPT-4o and by 49 pp over Claude-3.5-Sonnet, both under optimized prompting. To spur further research, we release an open corpus of 5000 production-grade enterprise API specifications paired with rigorously validated, disambiguation-focused dialogues, offering a practical blueprint for building reliable, enterprise-ready tool-calling agents.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.03336.pdf", "abstract_url": "https://arxiv.org/abs/2507.03336", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了DiaFORGE，一个以消除歧义为中心的三阶段流程，旨在提高大型语言模型（LLMs）在企业API调用中的准确性和可靠性。通过合成多轮对话、监督微调和动态评估，DiaFORGE显著提升了工具调用的成功率。", "motivation": "解决大型语言模型（LLMs）在企业API调用中遇到的两个主要问题：当近乎重复的工具竞争相同的用户意图时的混淆，以及当所需参数未明确指定时的失败。", "method": "引入DiaFORGE流程，包括三个阶段：(i) 合成角色驱动的多轮对话，要求助手区分高度相似的工具；(ii) 对开源模型进行监督微调，涵盖3B到70B参数；(iii) 通过动态套件评估模型的实时准备情况。", "result": "在动态基准DiaBENCH上，使用DiaFORGE训练的模型比GPT-4o和Claude-3.5-Sonnet在优化提示下的工具调用成功率分别提高了27个百分点和49个百分点。", "conclusion": "DiaFORGE为构建可靠的企业级工具调用代理提供了实用蓝图，并发布了包含5000个生产级企业API规范和严格验证的对话的开源语料库，以促进进一步研究。"}}
{"id": "2507.03493", "title": "AI-VaxGuide: An Agentic RAG-Based LLM for Vaccination Decisions", "authors": ["Abdellah Zeggai", "Ilyes Traikia", "Abdelhak Lakehal", "Abdennour Boulesnane"], "abstract": "Vaccination plays a vital role in global public health, yet healthcare professionals often struggle to access immunization guidelines quickly and efficiently. National protocols and WHO recommendations are typically extensive and complex, making it difficult to extract precise information, especially during urgent situations. This project tackles that issue by developing a multilingual, intelligent question-answering system that transforms static vaccination guidelines into an interactive and user-friendly knowledge base. Built on a Retrieval-Augmented Generation (RAG) framework and enhanced with agent-based reasoning (Agentic RAG), the system provides accurate, context-sensitive answers to complex medical queries. Evaluation shows that Agentic RAG outperforms traditional methods, particularly in addressing multi-step or ambiguous questions. To support clinical use, the system is integrated into a mobile application designed for real-time, point-of-care access to essential vaccine information. AI-VaxGuide model is publicly available on", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.03493.pdf", "abstract_url": "https://arxiv.org/abs/2507.03493", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic", "@RAG"], "AI": {"tldr": "AI-VaxGuide是一个基于检索增强生成（RAG）和代理推理（Agentic RAG）的多语言智能问答系统，旨在快速高效地提供疫苗接种指南，支持临床实时访问关键疫苗信息。", "motivation": "解决医疗专业人员快速准确获取复杂疫苗接种指南的难题。", "method": "采用检索增强生成（RAG）框架和代理推理（Agentic RAG）技术，开发多语言智能问答系统。", "result": "评估显示，Agentic RAG在回答多步骤或模糊问题上优于传统方法。", "conclusion": "AI-VaxGuide通过移动应用集成，为临床提供实时、精准的疫苗信息访问，提升公共卫生决策效率。"}}
{"id": "2507.03460", "title": "Multi-Agent Reasoning for Cardiovascular Imaging Phenotype Analysis", "authors": ["Weitong Zhang", "Mengyun Qiao", "Chengqi Zang", "Steven Niederer", "Paul M Matthews", "Wenjia Bai", "Bernhard Kainz"], "abstract": "Identifying the associations between imaging phenotypes and disease risk factors and outcomes is essential for understanding disease mechanisms and improving diagnosis and prognosis models. However, traditional approaches rely on human-driven hypothesis testing and selection of association factors, often overlooking complex, non-linear dependencies among imaging phenotypes and other multi-modal data. To address this, we introduce a Multi-agent Exploratory Synergy for the Heart (MESHAgents) framework that leverages large language models as agents to dynamically elicit, surface, and decide confounders and phenotypes in association studies, using cardiovascular imaging as a proof of concept. Specifically, we orchestrate a multi-disciplinary team of AI agents -- spanning cardiology, biomechanics, statistics, and clinical research -- which spontaneously generate and converge on insights through iterative, self-organizing reasoning. The framework dynamically synthesizes statistical correlations with multi-expert consensus, providing an automated pipeline for phenome-wide association studies (PheWAS). We demonstrate the system's capabilities through a population-based study of imaging phenotypes of the heart and aorta. MESHAgents autonomously uncovered correlations between imaging phenotypes and a wide range of non-imaging factors, identifying additional confounder variables beyond standard demographic factors. Validation on diagnosis tasks reveals that MESHAgents-discovered phenotypes achieve performance comparable to expert-selected phenotypes, with mean AUC differences as small as -0.004 on disease classification tasks. Notably, the recall score improves for 6 out of 9 disease types. Our framework provides clinically relevant imaging phenotypes with transparent reasoning, offering a scalable alternative to expert-driven methods.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.03460.pdf", "abstract_url": "https://arxiv.org/abs/2507.03460", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文介绍了一个名为MESHAgents的多智能体框架，用于心血管成像表型分析，通过利用大型语言模型作为代理，动态识别和决定关联研究中的混杂因素和表型，以心血管成像为概念验证。", "motivation": "传统方法依赖于人类驱动的假设测试和关联因素选择，往往忽略了成像表型和其他多模态数据之间复杂的非线性依赖关系。", "method": "MESHAgents框架通过协调一个跨学科的AI智能体团队（包括心脏病学、生物力学、统计学和临床研究），通过迭代、自组织的推理自发生成并汇聚见解，动态合成统计相关性与多专家共识。", "result": "MESHAgents自主发现了成像表型与广泛非成像因素之间的相关性，识别出超出标准人口统计因素的额外混杂变量。在诊断任务上的验证显示，MESHAgents发现的表型性能与专家选择的表型相当，疾病分类任务的AUC差异小至-0.004。", "conclusion": "该框架提供了具有透明推理的临床相关成像表型，为专家驱动方法提供了可扩展的替代方案。"}}
{"id": "2507.03477", "title": "REAL: Benchmarking Abilities of Large Language Models for Housing Transactions and Services", "authors": ["Kexin Zhu", "Yang Han"], "abstract": "The development of large language models (LLMs) has greatly promoted the progress of chatbot in multiple fields. There is an urgent need to evaluate whether LLMs can play the role of agent in housing transactions and services as well as humans. We present Real Estate Agent Large Language Model Evaluation (REAL), the first evaluation suite designed to assess the abilities of LLMs in the field of housing transactions and services. REAL comprises 5,316 high-quality evaluation entries across 4 topics: memory, comprehension, reasoning and hallucination. All these entries are organized as 14 categories to assess whether LLMs have the knowledge and ability in housing transactions and services scenario. Additionally, the REAL is used to evaluate the performance of most advanced LLMs. The experiment results indicate that LLMs still have significant room for improvement to be applied in the real estate field.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.03477.pdf", "abstract_url": "https://arxiv.org/abs/2507.03477", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了REAL，首个评估大型语言模型在房地产交易和服务领域能力的评估套件，包含5,316个高质量评估条目，覆盖4个主题：记忆、理解、推理和幻觉，组织为14个类别。实验结果表明，LLMs在房地产领域的应用仍有显著改进空间。", "motivation": "评估大型语言模型（LLMs）是否能在房地产交易和服务中扮演代理角色，以及其能力是否与人类相当。", "method": "开发了REAL评估套件，包含5,316个高质量评估条目，覆盖4个主题和14个类别，用于评估LLMs在房地产交易和服务场景中的知识和能力。", "result": "实验结果表明，尽管LLMs在多个领域取得了进展，但在房地产交易和服务领域的应用仍需显著改进。", "conclusion": "LLMs在房地产交易和服务领域的应用潜力巨大，但目前的能力仍需进一步提升以满足实际需求。"}}
{"id": "2507.03608", "title": "Benchmarking Vector, Graph and Hybrid Retrieval Augmented Generation (RAG) Pipelines for Open Radio Access Networks (ORAN)", "authors": ["Sarat Ahmad", "Zeinab Nezami", "Maryam Hafeez", "Syed Ali Raza Zaidi"], "abstract": "Generative AI (GenAI) is expected to play a pivotal role in enabling autonomous optimization in future wireless networks. Within the ORAN architecture, Large Language Models (LLMs) can be specialized to generate xApps and rApps by leveraging specifications and API definitions from the RAN Intelligent Controller (RIC) platform. However, fine-tuning base LLMs for telecom-specific tasks remains expensive and resource-intensive. Retrieval-Augmented Generation (RAG) offers a practical alternative through in-context learning, enabling domain adaptation without full retraining. While traditional RAG systems rely on vector-based retrieval, emerging variants such as GraphRAG and Hybrid GraphRAG incorporate knowledge graphs or dual retrieval strategies to support multi-hop reasoning and improve factual grounding. Despite their promise, these methods lack systematic, metric-driven evaluations, particularly in high-stakes domains such as ORAN. In this study, we conduct a comparative evaluation of Vector RAG, GraphRAG, and Hybrid GraphRAG using ORAN specifications. We assess performance across varying question complexities using established generation metrics: faithfulness, answer relevance, context relevance, and factual correctness. Results show that both GraphRAG and Hybrid GraphRAG outperform traditional RAG. Hybrid GraphRAG improves factual correctness by 8%, while GraphRAG improves context relevance by 7%.", "subjects": "Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Emerging Technologies (cs.ET); Networking and Internet Architecture (cs.NI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.03608.pdf", "abstract_url": "https://arxiv.org/abs/2507.03608", "categories": ["Artificial Intelligence (cs.AI)", "Distributed, Parallel, and Cluster Computing (cs.DC)", "Emerging Technologies (cs.ET)", "Networking and Internet Architecture (cs.NI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文比较了向量、图和混合检索增强生成（RAG）管道在开放无线接入网络（ORAN）中的应用，发现图和混合图RAG在性能上优于传统RAG。", "motivation": "解决在ORAN架构中，利用生成AI进行自主优化时，传统RAG系统在电信特定任务上的不足，以及缺乏系统和度量驱动评估的问题。", "method": "通过比较评估向量RAG、图RAG和混合图RAG在ORAN规范中的应用，使用生成度量标准（如忠实度、答案相关性、上下文相关性和事实正确性）来评估性能。", "result": "图和混合图RAG在性能上优于传统RAG，混合图RAG提高了8%的事实正确性，图RAG提高了7%的上下文相关性。", "conclusion": "图和混合图RAG方法在ORAN中显示出优于传统RAG的性能，特别是在提高事实正确性和上下文相关性方面，为未来无线网络的自主优化提供了有前景的方向。"}}
{"id": "2507.03616", "title": "EvoAgentX: An Automated Framework for Evolving Agentic Workflows", "authors": ["Yingxu Wang", "Siwei Liu", "Jinyuan Fang", "Zaiqiao Meng"], "abstract": "Multi-agent systems (MAS) have emerged as a powerful paradigm for orchestrating large language models (LLMs) and specialized tools to collaboratively address complex tasks. However, existing MAS frameworks often require manual workflow configuration and lack native support for dynamic evolution and performance optimization. In addition, many MAS optimization algorithms are not integrated into a unified framework. In this paper, we present EvoAgentX, an open-source platform that automates the generation, execution, and evolutionary optimization of multi-agent workflows. EvoAgentX employs a modular architecture consisting of five core layers: the basic components, agent, workflow, evolving, and evaluation layers. Specifically, within the evolving layer, EvoAgentX integrates three MAS optimization algorithms, TextGrad, AFlow, and MIPRO, to iteratively refine agent prompts, tool configurations, and workflow topologies. We evaluate EvoAgentX on HotPotQA, MBPP, and MATH for multi-hop reasoning, code generation, and mathematical problem solving, respectively, and further assess it on real-world tasks using GAIA. Experimental results show that EvoAgentX consistently achieves significant performance improvements, including a 7.44% increase in HotPotQA F1, a 10.00% improvement in MBPP pass@1, a 10.00% gain in MATH solve accuracy, and an overall accuracy improvement of up to 20.00% on GAIA. The source code is available at:", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.03616.pdf", "abstract_url": "https://arxiv.org/abs/2507.03616", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "EvoAgentX是一个自动化框架，用于进化多代理工作流，通过集成优化算法提升性能。", "motivation": "解决多代理系统（MAS）框架中手动配置工作流和缺乏动态进化及性能优化支持的问题。", "method": "采用模块化架构，包含五个核心层，并在进化层集成三种MAS优化算法（TextGrad、AFlow、MIPRO）来迭代优化代理提示、工具配置和工作流拓扑。", "result": "在HotPotQA、MBPP、MATH和GAIA等任务上，EvoAgentX实现了显著的性能提升，包括HotPotQA F1提高7.44%，MBPP pass@1提高10.00%，MATH解决准确率提高10.00%，GAIA总体准确率提高达20.00%。", "conclusion": "EvoAgentX通过自动化生成、执行和进化优化多代理工作流，显著提升了多代理系统的性能，为复杂任务的解决提供了高效工具。"}}
{"id": "2507.03682", "title": "Towards Machine Theory of Mind with Large Language Model-Augmented Inverse Planning", "authors": ["Rebekah A. Gelpí", "Eric Xue", "William A. Cunningham"], "abstract": "We propose a hybrid approach to machine Theory of Mind (ToM) that uses large language models (LLMs) as a mechanism for generating hypotheses and likelihood functions with a Bayesian inverse planning model that computes posterior probabilities for an agent's likely mental states given its actions. Bayesian inverse planning models can accurately predict human reasoning on a variety of ToM tasks, but these models are constrained in their ability to scale these predictions to scenarios with a large number of possible hypotheses and actions. Conversely, LLM-based approaches have recently demonstrated promise in solving ToM benchmarks, but can exhibit brittleness and failures on reasoning tasks even when they pass otherwise structurally identical versions. By combining these two methods, this approach leverages the strengths of each component, closely matching optimal results on a task inspired by prior inverse planning models and improving performance relative to models that utilize LLMs alone or with chain-of-thought prompting, even with smaller LLMs that typically perform poorly on ToM tasks. We also exhibit the model's potential to predict mental states on open-ended tasks, offering a promising direction for future development of ToM models and the creation of socially intelligent generative agents.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.03682.pdf", "abstract_url": "https://arxiv.org/abs/2507.03682", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "提出了一种结合大型语言模型（LLMs）和贝叶斯逆向规划模型的混合方法，用于机器心智理论（ToM），以更准确地预测和推理代理的心理状态。", "motivation": "解决贝叶斯逆向规划模型在处理大量假设和行动场景时的扩展性问题，以及LLM在ToM任务中表现出的脆弱性和推理失败问题。", "method": "使用LLMs生成假设和似然函数，结合贝叶斯逆向规划模型计算代理心理状态的后验概率。", "result": "该方法在ToM任务中接近最优结果，性能优于单独使用LLMs或带有思维链提示的模型，即使是较小的LLMs也能表现出色。", "conclusion": "结合LLMs和贝叶斯逆向规划模型的方法为ToM模型的未来发展和创建具有社会智能的生成代理提供了有希望的方向。"}}
{"id": "2507.03726", "title": "Agent-Based Detection and Resolution of Incompleteness and Ambiguity in Interactions with Large Language Models", "authors": ["Riya Naik", "Ashwin Srinivasan", "Swati Agarwal", "Estrid He"], "abstract": "Many of us now treat LLMs as modern-day oracles asking it almost any kind of question. However, consulting an LLM does not have to be a single turn activity. But long multi-turn interactions can get tedious if it is simply to clarify contextual information that can be arrived at through reasoning. In this paper, we examine the use of agent-based architecture to bolster LLM-based Question-Answering systems with additional reasoning capabilities. We examine the automatic resolution of potential incompleteness or ambiguities in questions by transducers implemented using LLM-based agents. We focus on several benchmark datasets that are known to contain questions with these deficiencies to varying degrees. We equip different LLMs (GPT-3.5-Turbo and Llama-4-Scout) with agents that act as specialists in detecting and resolving deficiencies of incompleteness and ambiguity. The agents are implemented as zero-shot ReAct agents. Rather than producing an answer in a single step, the model now decides between 3 actions a) classify b) resolve c) answer. Action a) decides if the question is incomplete, ambiguous, or normal. Action b) determines if any deficiencies identified can be resolved. Action c) answers the resolved form of the question. We compare the use of LLMs with and without the use of agents with these components. Our results show benefits of agents with transducer 1) A shortening of the length of interactions with human 2) An improvement in the answer quality and 3) Explainable resolution of deficiencies in the question. On the negative side we find while it may result in additional LLM invocations and in some cases, increased latency. But on tested datasets, the benefits outweigh the costs except when questions already have sufficient context. Suggesting the agent-based approach could be a useful mechanism to harness the power of LLMs to develop more robust QA systems.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Information Retrieval (cs.IR)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2507.03726.pdf", "abstract_url": "https://arxiv.org/abs/2507.03726", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Information Retrieval (cs.IR)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了使用基于代理的架构来增强基于LLM的问答系统，通过自动检测和解决提问中的不完整性和模糊性问题，以提高交互效率和质量。", "motivation": "解决与大型语言模型(LLM)交互时因提问不完整或模糊导致的效率低下和答案质量不高的问题。", "method": "采用基于代理的架构，实现为零射击ReAct代理，这些代理能够分类、解决或回答问题，从而自动识别和解决提问中的缺陷。", "result": "使用代理的方法缩短了与人类的交互长度，提高了答案质量，并能够解释性地解决提问中的缺陷，尽管可能会增加LLM的调用次数和延迟。", "conclusion": "基于代理的方法可以有效地利用LLM的能力，开发出更健壮的问答系统，尤其是在提问缺乏足够上下文时。"}}
{"id": "2507.03802", "title": "Generating Novelty in Open-World Multi-Agent Strategic Board Games", "authors": ["Mayank Kejriwal", "Shilpa Thomas"], "abstract": "We describe GNOME (Generating Novelty in Open-world Multi-agent Environments), an experimental platform that is designed to test the effectiveness of multi-agent AI systems when faced with \\emph{novelty}. GNOME separates the development of AI gameplaying agents with the simulator, allowing \\emph{unanticipated} novelty (in essence, novelty that is not subject to model-selection bias). Using a Web GUI, GNOME was recently demonstrated at NeurIPS 2020 using the game of Monopoly to foster an open discussion on AI robustness and the nature of novelty in real-world environments. In this article, we further detail the key elements of the demonstration, and also provide an overview of the experimental design that is being currently used in the DARPA Science of Artificial Intelligence and Learning for Open-World Novelty (SAIL-ON) program to evaluate external teams developing novelty-adaptive gameplaying agents.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "16 pages, shorter version demonstrated in NeurIPS 2020", "pdf_url": "https://arxiv.org/pdf/2507.03802.pdf", "abstract_url": "https://arxiv.org/abs/2507.03802", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "介绍了GNOME平台，旨在测试多智能体AI系统在面对新颖性时的有效性，通过分离AI游戏代理与模拟器的开发，引入未预期的新颖性。", "motivation": "解决多智能体AI系统在开放世界环境中面对未预期新颖性时的适应性和鲁棒性问题。", "method": "使用GNOME平台，分离AI游戏代理与模拟器的开发，通过Web GUI展示，如在Monopoly游戏中的应用，以促进关于AI鲁棒性和新颖性本质的讨论。", "result": "GNOME平台成功展示了AI在面对未预期新颖性时的表现，并作为DARPA SAIL-ON项目中评估新颖性适应游戏代理的实验设计基础。", "conclusion": "GNOME平台为研究多智能体AI系统在开放世界中的新颖性适应提供了有效工具，对提高AI的鲁棒性和适应性具有重要意义。"}}
{"id": "2507.03793", "title": "Learning Dark Souls Combat Through Pixel Input With Neuroevolution", "authors": ["Jim O'Connor", "Gary B. Parker", "Mustafa Bugti"], "abstract": "This paper investigates the application of Neuroevolution of Augmenting Topologies (NEAT) to automate gameplay in Dark Souls, a notoriously challenging action role-playing game characterized by complex combat mechanics, dynamic environments, and high-dimensional visual inputs. Unlike traditional reinforcement learning or game playing approaches, our method evolves neural networks directly from raw pixel data, circumventing the need for explicit game-state information. To facilitate this approach, we introduce the Dark Souls API (DSAPI), a novel Python framework leveraging real-time computer vision techniques for extracting critical game metrics, including player and enemy health states. Using NEAT, agents evolve effective combat strategies for defeating the Asylum Demon, the game's initial boss, without predefined behaviors or domain-specific heuristics. Experimental results demonstrate that evolved agents achieve up to a 35% success rate, indicating the viability of neuroevolution in addressing complex, visually intricate gameplay scenarios. This work represents an interesting application of vision-based neuroevolution, highlighting its potential use in a wide range of challenging game environments lacking direct API support or well-defined state representations.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "IEEE Conference on Games 2025", "pdf_url": "https://arxiv.org/pdf/2507.03793.pdf", "abstract_url": "https://arxiv.org/abs/2507.03793", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究了通过神经进化增强拓扑结构（NEAT）来自动化《黑暗之魂》游戏玩法的方法，直接从原始像素数据进化神经网络，无需明确的游戏状态信息。", "motivation": "解决在缺乏直接API支持或明确状态表示的复杂游戏环境中，如何自动化游戏玩法的问题。", "method": "使用NEAT算法，结合Dark Souls API（DSAPI）框架，通过实时计算机视觉技术提取关键游戏指标，进化神经网络以制定有效战斗策略。", "result": "实验结果显示，进化后的代理在击败游戏初始boss Asylum Demon时达到了35%的成功率。", "conclusion": "这项工作展示了基于视觉的神经进化在复杂游戏环境中的潜在应用，尤其是在缺乏直接API支持或明确状态表示的情况下。"}}
{"id": "2507.03671", "title": "Recon, Answer, Verify: Agents in Search of Truth", "authors": ["Satyam Shukla", "Himanshu Dutta", "Pushpak Bhattacharyya"], "abstract": "Automated fact checking with large language models (LLMs) offers a scalable alternative to manual verification. Evaluating fact checking is challenging as existing benchmark datasets often include post claim analysis and annotator cues, which are absent in real world scenarios where claims are fact checked immediately after being made. This limits the realism of current evaluations. We present Politi Fact Only (PFO), a 5 class benchmark dataset of 2,982 political claims from", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.03671.pdf", "abstract_url": "https://arxiv.org/abs/2507.03671", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了Politi Fact Only (PFO)，一个包含2,982条政治声明的5类基准数据集，旨在提高自动化事实检查的评估真实性。", "motivation": "解决现有基准数据集在评估自动化事实检查时缺乏实时性和真实性的问题。", "method": "提出了Politi Fact Only (PFO)数据集，专注于政治声明的事实检查，避免了后声明分析和注释者提示。", "result": "创建了一个更接近现实世界场景的基准数据集，有助于更真实地评估大型语言模型在事实检查中的表现。", "conclusion": "PFO数据集的引入为自动化事实检查提供了一个更真实、更有效的评估工具，推动了该领域的发展。"}}
{"id": "2507.03674", "title": "STRUCTSENSE: A Task-Agnostic Agentic Framework for Structured Information Extraction with Human-In-The-Loop Evaluation and Benchmarking", "authors": ["Tek Raj Chhetri", "Yibei Chen", "Puja Trivedi", "Dorota Jarecka", "Saif Haobsh", "Patrick Ray", "Lydia Ng", "Satrajit S. Ghosh"], "abstract": "The ability to extract structured information from unstructured sources-such as free-text documents and scientific literature-is critical for accelerating scientific discovery and knowledge synthesis. Large Language Models (LLMs) have demonstrated remarkable capabilities in various natural language processing tasks, including structured information extraction. However, their effectiveness often diminishes in specialized, domain-specific contexts that require nuanced understanding and expert-level domain knowledge. In addition, existing LLM-based approaches frequently exhibit poor transferability across tasks and domains, limiting their scalability and adaptability. To address these challenges, we introduce StructSense, a modular, task-agnostic, open-source framework for structured information extraction built on LLMs. StructSense is guided by domain-specific symbolic knowledge encoded in ontologies, enabling it to navigate complex domain content more effectively. It further incorporates agentic capabilities through self-evaluative judges that form a feedback loop for iterative refinement, and includes human-in-the-loop mechanisms to ensure quality and validation. We demonstrate that StructSense can overcome both the limitations of domain sensitivity and the lack of cross-task generalizability, as shown through its application to diverse neuroscience information extraction tasks.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "All figures are necessary", "pdf_url": "https://arxiv.org/pdf/2507.03674.pdf", "abstract_url": "https://arxiv.org/abs/2507.03674", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "StructSense是一个任务无关的、基于大型语言模型（LLMs）的开源框架，用于从非结构化源中提取结构化信息，特别适用于需要领域专业知识的复杂场景。", "motivation": "解决大型语言模型在专业领域信息提取中的局限性，包括领域敏感性差和跨任务泛化能力不足的问题。", "method": "引入StructSense框架，该框架利用领域特定的符号知识（如本体论）指导信息提取，并通过自我评估法官和人类参与机制实现迭代优化和质量保证。", "result": "StructSense在多样化的神经科学信息提取任务中表现出色，能够克服领域敏感性和跨任务泛化能力的限制。", "conclusion": "StructSense通过结合领域知识、自我评估和人类参与，显著提升了在专业领域中进行结构化信息提取的效果和适应性。"}}
{"id": "2507.03711", "title": "Can LLMs Play Ô Ăn Quan Game? A Study of Multi-Step Planning and Decision Making", "authors": ["Sang Quang Nguyen", "Kiet Van Nguyen", "Vinh-Tiep Nguyen", "Thanh Duc Ngo", "Ngan Luu-Thuy Nguyen", "Dinh-Duy Le"], "abstract": "In this paper, we explore the ability of large language models (LLMs) to plan and make decisions through the lens of the traditional Vietnamese board game, Ô Ăn Quan. This game, which involves a series of strategic token movements and captures, offers a unique environment for evaluating the decision-making and strategic capabilities of LLMs. Specifically, we develop various agent personas, ranging from aggressive to defensive, and employ the Ô Ăn Quan game as a testbed for assessing LLM performance across different strategies. Through experimentation with models like Llama-3.2-3B-Instruct, Llama-3.1-8B-Instruct, and Llama-3.3-70B-Instruct, we aim to understand how these models execute strategic decision-making, plan moves, and manage dynamic game states. The results will offer insights into the strengths and weaknesses of LLMs in terms of reasoning and strategy, contributing to a deeper understanding of their general capabilities.", "subjects": "Computation and Language (cs.CL)", "comments": "Accepted paper at MAPR 2025", "pdf_url": "https://arxiv.org/pdf/2507.03711.pdf", "abstract_url": "https://arxiv.org/abs/2507.03711", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过越南传统棋盘游戏Ô Ăn Quan，探索大型语言模型（LLMs）的规划和决策能力。研究开发了从攻击性到防御性不同的代理角色，并以此游戏为测试平台，评估LLMs在不同策略下的表现。", "motivation": "研究旨在评估LLMs在战略决策、计划移动和管理动态游戏状态方面的能力，以了解其在推理和策略上的优势和弱点。", "method": "研究采用了多种LLMs模型（如Llama-3.2-3B-Instruct、Llama-3.1-8B-Instruct和Llama-3.3-70B-Instruct），通过Ô Ăn Quan游戏作为测试平台，开发不同策略的代理角色进行实验。", "result": "实验结果将提供关于LLMs在推理和策略方面能力的深入见解，有助于更全面地理解其通用能力。", "conclusion": "通过Ô Ăn Quan游戏的研究，可以更深入地理解LLMs在战略决策和规划方面的能力，为评估和提升LLMs的通用能力提供了新的视角。"}}
{"id": "2507.03811", "title": "Leveraging Large Language Models for Tacit Knowledge Discovery in Organizational Contexts", "authors": ["Gianlucca Zuin", "Saulo Mastelini", "Túlio Loures", "Adriano Veloso"], "abstract": "Documenting tacit knowledge in organizations can be a challenging task due to incomplete initial information, difficulty in identifying knowledgeable individuals, the interplay of formal hierarchies and informal networks, and the need to ask the right questions. To address this, we propose an agent-based framework leveraging large language models (LLMs) to iteratively reconstruct dataset descriptions through interactions with employees. Modeling knowledge dissemination as a Susceptible-Infectious (SI) process with waning infectivity, we conduct 864 simulations across various synthetic company structures and different dissemination parameters. Our results show that the agent achieves 94.9% full-knowledge recall, with self-critical feedback scores strongly correlating with external literature critic scores. We analyze how each simulation parameter affects the knowledge retrieval process for the agent. In particular, we find that our approach is able to recover information without needing to access directly the only domain specialist. These findings highlight the agent's ability to navigate organizational complexity and capture fragmented knowledge that would otherwise remain inaccessible.", "subjects": "Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)", "comments": "8 pages, 4 figures, accepted to International Joint Conference on Neural Networks (IJCNN) 2025", "pdf_url": "https://arxiv.org/pdf/2507.03811.pdf", "abstract_url": "https://arxiv.org/abs/2507.03811", "categories": ["Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于大型语言模型（LLMs）的代理框架，用于在组织环境中迭代重建数据集描述，以解决隐性知识记录的挑战。通过模拟知识传播过程，该代理在多种公司结构和传播参数下实现了94.9%的完整知识回忆率。", "motivation": "记录组织中的隐性知识面临初始信息不完整、难以识别知识渊博的个人、正式层级与非正式网络的相互作用以及需要提出正确问题等挑战。", "method": "采用基于大型语言模型（LLMs）的代理框架，模拟知识传播为具有减弱传染性的易感-感染（SI）过程，并在各种合成公司结构和不同传播参数下进行了864次模拟。", "result": "代理实现了94.9%的完整知识回忆率，自我批判反馈分数与外部文献批评分数强相关。特别发现，该方法无需直接访问唯一的领域专家即可恢复信息。", "conclusion": "这些发现突出了代理在导航组织复杂性和捕获否则将保持不可访问的碎片化知识方面的能力。"}}
{"id": "2507.03839", "title": "Participatory Evolution of Artificial Life Systems via Semantic Feedback", "authors": ["Shuowen Li", "Kexin Wang", "Minglu Fang", "Danqi Huang", "Ali Asadipour", "Haipeng Mi", "Yitong Sun"], "abstract": "We present a semantic feedback framework that enables natural language to guide the evolution of artificial life systems. Integrating a prompt-to-parameter encoder, a CMA-ES optimizer, and CLIP-based evaluation, the system allows user intent to modulate both visual outcomes and underlying behavioral rules. Implemented in an interactive ecosystem simulation, the framework supports prompt refinement, multi-agent interaction, and emergent rule synthesis. User studies show improved semantic alignment over manual tuning and demonstrate the system's potential as a platform for participatory generative design and open-ended evolution.", "subjects": "Artificial Intelligence (cs.AI); Graphics (cs.GR)", "comments": "10 pages", "pdf_url": "https://arxiv.org/pdf/2507.03839.pdf", "abstract_url": "https://arxiv.org/abs/2507.03839", "categories": ["Artificial Intelligence (cs.AI)", "Graphics (cs.GR)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种语义反馈框架，通过自然语言指导人工生命系统的进化。该系统集成了提示到参数编码器、CMA-ES优化器和基于CLIP的评估，允许用户意图调节视觉结果和底层行为规则。在交互式生态系统模拟中实现，该框架支持提示细化、多代理交互和涌现规则合成。用户研究表明，与手动调整相比，语义对齐有所改善，并展示了该系统作为参与式生成设计和开放式进化平台的潜力。", "motivation": "解决如何通过自然语言更有效地指导和调整人工生命系统的进化过程，以提高语义对齐和用户参与度的问题。", "method": "采用语义反馈框架，结合提示到参数编码器、CMA-ES优化器和CLIP-based评估，实现用户意图对系统视觉结果和行为规则的调节。", "result": "用户研究显示，与手动调整相比，该系统在语义对齐方面表现更优，展现了作为参与式生成设计和开放式进化平台的有效性。", "conclusion": "该框架为人工生命系统的进化提供了一种新的、用户友好的方法，具有在生成设计和开放式进化领域应用的广阔前景。"}}
{"id": "2507.03870", "title": "Uncovering Systemic and Environment Errors in Autonomous Systems Using Differential Testing", "authors": ["Rahil P Mehta", "Yashwanthi Anand", "Manish Motwani", "Sandhya Saisubramanian"], "abstract": "When an autonomous agent behaves undesirably, including failure to complete a task, it can be difficult to determine whether the behavior is due to a systemic agent error, such as flaws in the model or policy, or an environment error, where a task is inherently infeasible under a given environment configuration, even for an ideal agent. As agents and their environments grow more complex, identifying the error source becomes increasingly difficult but critical for reliable deployment. We introduce AIProbe, a novel black-box testing technique that applies differential testing to attribute undesirable agent behaviors either to agent deficiencies, such as modeling or training flaws, or due to environmental infeasibility. AIProbe first generates diverse environmental configurations and tasks for testing the agent, by modifying configurable parameters using Latin Hypercube sampling. It then solves each generated task using a search-based planner, independent of the agent. By comparing the agent's performance to the planner's solution, AIProbe identifies whether failures are due to errors in the agent's model or policy, or due to unsolvable task conditions. Our evaluation across multiple domains shows that AIProbe significantly outperforms state-of-the-art techniques in detecting both total and unique errors, thereby contributing to a reliable deployment of autonomous agents.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.03870.pdf", "abstract_url": "https://arxiv.org/abs/2507.03870", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了AIProbe，一种新颖的黑盒测试技术，通过差异测试来识别自主代理行为不良的原因，是代理缺陷还是环境不可行性。", "motivation": "随着自主代理及其环境变得越来越复杂，识别行为不良的原因是代理的系统性错误还是环境错误变得既困难又对可靠部署至关重要。", "method": "AIProbe首先生成多样化的环境配置和任务来测试代理，然后使用基于搜索的规划器独立解决每个生成的任务，通过比较代理和规划器的表现来识别错误来源。", "result": "评估显示，AIProbe在检测总和独特错误方面显著优于现有技术，有助于自主代理的可靠部署。", "conclusion": "AIProbe通过差异测试有效区分自主代理行为不良的原因，为自主代理的可靠部署提供了重要支持。"}}
{"id": "2507.03868", "title": "From Query to Explanation: Uni-RAG for Multi-Modal Retrieval-Augmented Learning in STEM", "authors": ["Xinyi Wu", "Yanhao Jia", "Luwei Xiao", "Shuai Zhao", "Fengkuang Chiang", "Erik Cambria"], "abstract": "In AI-facilitated teaching, leveraging various query styles to interpret abstract educational content is crucial for delivering effective and accessible learning experiences. However, existing retrieval systems predominantly focus on natural text-image matching and lack the capacity to address the diversity and ambiguity inherent in real-world educational scenarios. To address this limitation, we develop a lightweight and efficient multi-modal retrieval module, named Uni-Retrieval, which extracts query-style prototypes and dynamically matches them with tokens from a continually updated Prompt Bank. This Prompt Bank encodes and stores domain-specific knowledge by leveraging a Mixture-of-Expert Low-Rank Adaptation (MoE-LoRA) module and can be adapted to enhance Uni-Retrieval's capability to accommodate unseen query types at test time. To enable natural language educational content generation, we integrate the original Uni-Retrieval with a compact instruction-tuned language model, forming a complete retrieval-augmented generation pipeline named Uni-RAG. Given a style-conditioned query, Uni-RAG first retrieves relevant educational materials and then generates human-readable explanations, feedback, or instructional content aligned with the learning objective. Experimental results on SER and other multi-modal benchmarks show that Uni-RAG outperforms baseline retrieval and RAG systems in both retrieval accuracy and generation quality, while maintaining low computational cost. Our framework provides a scalable, pedagogically grounded solution for intelligent educational systems, bridging retrieval and generation to support personalized, explainable, and efficient learning assistance across diverse STEM scenarios.", "subjects": "Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Computers and Society (cs.CY); Multimedia (cs.MM)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.03868.pdf", "abstract_url": "https://arxiv.org/abs/2507.03868", "categories": ["Artificial Intelligence (cs.AI)", "Computational Engineering, Finance, and Science (cs.CE)", "Computers and Society (cs.CY)", "Multimedia (cs.MM)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种名为Uni-RAG的轻量级高效多模态检索模块，旨在通过动态匹配查询风格原型与持续更新的Prompt Bank中的令牌，解决现有检索系统在处理教育场景多样性和模糊性方面的不足。结合紧凑的指令调谐语言模型，Uni-RAG不仅能够检索相关教育材料，还能生成与学习目标一致的人类可读解释、反馈或教学内容。实验结果表明，Uni-RAG在检索准确性和生成质量上均优于基线检索和RAG系统，同时保持低计算成本。", "motivation": "现有的检索系统主要关注自然文本-图像匹配，难以应对现实教育场景中的多样性和模糊性。本文旨在开发一个能够适应不同查询类型并生成自然语言教育内容的系统，以提供更有效和可访问的学习体验。", "method": "开发了Uni-Retrieval模块，通过提取查询风格原型并动态匹配Prompt Bank中的令牌，结合MoE-LoRA模块编码和存储领域特定知识。进一步将Uni-Retrieval与紧凑的指令调谐语言模型集成，形成完整的检索增强生成管道Uni-RAG。", "result": "在SER和其他多模态基准测试中，Uni-RAG在检索准确性和生成质量上均优于基线系统，同时保持低计算成本。", "conclusion": "Uni-RAG框架为智能教育系统提供了一个可扩展、教育学基础的解决方案，通过桥接检索和生成，支持跨多样STEM场景的个性化、可解释和高效学习辅助。"}}
{"id": "2507.03904", "title": "Agent Exchange: Shaping the Future of AI Agent Economics", "authors": ["Yingxuan Yang", "Ying Wen", "Jun Wang", "Weinan Zhang"], "abstract": "The rise of Large Language Models (LLMs) has transformed AI agents from passive computational tools into autonomous economic actors. This shift marks the emergence of the agent-centric economy, in which agents take on active economic roles-exchanging value, making strategic decisions, and coordinating actions with minimal human oversight. To realize this vision, we propose Agent Exchange (AEX), a specialized auction platform designed to support the dynamics of the AI agent marketplace. AEX offers an optimized infrastructure for agent coordination and economic participation. Inspired by Real-Time Bidding (RTB) systems in online advertising, AEX serves as the central auction engine, facilitating interactions among four ecosystem components: the User-Side Platform (USP), which translates human goals into agent-executable tasks; the Agent-Side Platform (ASP), responsible for capability representation, performance tracking, and optimization; Agent Hubs, which coordinate agent teams and participate in AEX-hosted auctions; and the Data Management Platform (DMP), ensuring secure knowledge sharing and fair value attribution. We outline the design principles and system architecture of AEX, laying the groundwork for agent-based economic infrastructure in future AI ecosystems.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.03904.pdf", "abstract_url": "https://arxiv.org/abs/2507.03904", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了Agent Exchange（AEX），一个专为AI代理市场设计的拍卖平台，旨在支持AI代理作为自主经济参与者的新兴经济形态。", "motivation": "随着大型语言模型（LLMs）的发展，AI代理从被动的计算工具转变为自主的经济参与者，这标志着以代理为中心的经济的兴起。为了支持这一新兴经济形态，需要专门的平台来促进代理之间的价值交换和协调。", "method": "AEX受到在线广告中的实时竞价（RTB）系统的启发，作为一个中央拍卖引擎，连接用户侧平台（USP）、代理侧平台（ASP）、代理中心和数据管理平台（DMP）四个生态系统组件。", "result": "AEX提供了一个优化的基础设施，支持代理协调和经济参与，为未来AI生态系统中的代理经济基础设施奠定了基础。", "conclusion": "AEX的设计原则和系统架构为AI代理作为自主经济参与者的新兴经济形态提供了支持，预示着AI代理经济基础设施的未来发展方向。"}}
{"id": "2507.03928", "title": "CortexDebate: Debating Sparsely and Equally for Multi-Agent Debate", "authors": ["Yiliu Sun", "Zicheng Zhao", "Sheng Wan", "Chen Gong"], "abstract": "Nowadays, single Large Language Model (LLM) struggles with critical issues such as hallucination and inadequate reasoning abilities. To mitigate these issues, Multi-Agent Debate (MAD) has emerged as an effective strategy, where LLM agents engage in in-depth debates with others on tasks. However, existing MAD methods face two major issues: (a) too lengthy input contexts, which causes LLM agents to get lost in plenty of input information and experiences performance drop; and (b) the overconfidence dilemma, where self-assured LLM agents dominate the debate, leading to low debating effectiveness. To address these limitations, we propose a novel MAD method called \"CortexDebate\". Inspired by the human brain's tendency to establish a sparse and dynamically optimized network among cortical areas governed by white matter, CortexDebate constructs a sparse debating graph among LLM agents, where each LLM agent only debates with the ones that are helpful to it. To optimize the graph, we propose a module named McKinsey-based Debate Matter (MDM), which acts as an artificial analog to white matter. By integrating the McKinsey Trust Formula, a well-established measure of trustworthiness from sociology, MDM enables credible evaluations that guide graph optimization. The effectiveness of our CortexDebate has been well demonstrated by extensive experimental results across eight datasets from four task types.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "Accepted by ACL 2025", "pdf_url": "https://arxiv.org/pdf/2507.03928.pdf", "abstract_url": "https://arxiv.org/abs/2507.03928", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "CortexDebate是一种新颖的多智能体辩论方法，通过构建稀疏辩论图和引入McKinsey-based Debate Matter模块，解决了现有方法中的输入上下文过长和过度自信问题。", "motivation": "解决大型语言模型在单智能体情况下的幻觉和推理能力不足问题，以及多智能体辩论方法中的输入信息过载和辩论效率低下问题。", "method": "提出CortexDebate方法，构建稀疏辩论图，每个LLM智能体仅与对其有帮助的其他智能体进行辩论，并通过McKinsey-based Debate Matter模块优化辩论图。", "result": "在四个任务类型的八个数据集上的广泛实验结果证明了CortexDebate的有效性。", "conclusion": "CortexDebate通过稀疏和动态优化的辩论网络，显著提高了多智能体辩论的效率和效果，为解决LLM的关键问题提供了新思路。"}}
{"id": "2507.04026", "title": "Patient-Centered RAG for Oncology Visit Aid Following the Ottawa Decision Guide", "authors": ["Siyang Liu", "Lawrence Chin-I An", "Rada Mihalcea"], "abstract": "Effective communication is essential in cancer care, yet patients often face challenges in preparing for complex medical visits. We present an interactive, Retrieval-augmented Generation-assisted system that helps patients progress from uninformed to visit-ready. Our system adapts the Ottawa Personal Decision Guide into a dynamic retrieval-augmented generation workflow, helping users bridge knowledge gaps, clarify personal values and generate useful questions for their upcoming visits. Focusing on localized prostate cancer, we conduct a user study with patients and a clinical expert. Results show high system usability (UMUX Mean = 6.0 out of 7), strong relevance of generated content (Mean = 6.7 out of 7), minimal need for edits, and high clinical faithfulness (Mean = 6.82 out of 7). This work demonstrates the potential of combining patient-centered design with language models to enhance clinical preparation in oncology care.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.04026.pdf", "abstract_url": "https://arxiv.org/abs/2507.04026", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了一种基于检索增强生成的交互式系统，旨在帮助癌症患者为复杂的医疗访问做好准备。该系统将渥太华个人决策指南动态整合到工作流程中，帮助用户填补知识空白、明确个人价值观并为即将到来的访问生成有用问题。针对局部前列腺癌的研究显示，该系统具有高可用性、内容相关性高、编辑需求少及临床忠实度高等特点。", "motivation": "癌症护理中的有效沟通至关重要，但患者在准备复杂的医疗访问时常常面临挑战。本文旨在解决这一问题，通过开发一个交互式系统，帮助患者从不知情状态转变为访问准备就绪状态。", "method": "本研究采用了一种结合检索增强生成技术的交互式系统，动态整合渥太华个人决策指南，帮助用户填补知识空白、明确个人价值观并生成访问问题。研究聚焦于局部前列腺癌，通过患者和临床专家的用户研究进行评估。", "result": "研究结果显示，系统具有高可用性（UMUX平均分为6.0/7）、生成内容的相关性强（平均分为6.7/7）、编辑需求极少，且临床忠实度高（平均分为6.82/7）。", "conclusion": "这项工作展示了将患者中心设计与语言模型结合在增强肿瘤护理临床准备方面的潜力，为改善癌症患者的医疗访问体验提供了新的可能性。"}}
{"id": "2507.04069", "title": "Beyond Independent Passages: Adaptive Passage Combination Retrieval for Retrieval Augmented Open-Domain Question Answering", "authors": ["Ting-Wen Ko", "Jyun-Yu Jiang", "Pu-Jen Cheng"], "abstract": "Retrieval-augmented generation (RAG) enhances large language models (LLMs) by incorporating external documents at inference time, enabling up-to-date knowledge access without costly retraining. However, conventional RAG methods retrieve passages independently, often leading to redundant, noisy, or insufficiently diverse context-particularly problematic - particularly problematic in noisy corpora and for multi-hop questions. To address this, we propose Adaptive Passage Combination Retrieval (AdaPCR), a novel framework for open-domain question answering with black-box LMs. AdaPCR explicitly models dependencies between passages by considering passage combinations as units for retrieval and reranking. It consists of a context-aware query reformulation using concatenated passages, and a reranking step trained with a predictive objective aligned with downstream answer likelihood. Crucially, AdaPCR adaptively selects the number of retrieved passages without additional stopping modules. Experiments across several QA benchmarks show that AdaPCR outperforms baselines, particularly in multi-hop reasoning, demonstrating the effectiveness of modeling inter-passage dependencies for improved retrieval.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.04069.pdf", "abstract_url": "https://arxiv.org/abs/2507.04069", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种名为AdaPCR的新框架，用于开放域问答，通过考虑段落组合作为检索和重新排名的单位，显式建模段落之间的依赖关系，以提高检索效率。", "motivation": "传统的检索增强生成（RAG）方法在检索段落时独立处理，导致冗余、噪声或多样性不足的上下文，特别是在嘈杂的语料库和多跳问题中尤为突出。", "method": "AdaPCR框架包括使用连接段落进行上下文感知查询重构，以及一个与下游答案可能性对齐的预测目标训练的重新排名步骤，无需额外的停止模块即可自适应选择检索段落的数量。", "result": "在多个QA基准测试中，AdaPCR的表现优于基线方法，特别是在多跳推理方面，证明了建模段落间依赖关系对提高检索效果的有效性。", "conclusion": "AdaPCR通过显式建模段落间的依赖关系，提供了一种有效的检索方法，特别是在处理多跳问题和嘈杂语料库时，显著提高了开放域问答的性能。"}}
{"id": "2507.04127", "title": "BYOKG-RAG: Multi-Strategy Graph Retrieval for Knowledge Graph Question Answering", "authors": ["Costas Mavromatis", "Soji Adeshina", "Vassilis N. Ioannidis", "Zhen Han", "Qi Zhu", "Ian Robinson", "Bryan Thompson", "Huzefa Rangwala", "George Karypis"], "abstract": "Knowledge graph question answering (KGQA) presents significant challenges due to the structural and semantic variations across input graphs. Existing works rely on Large Language Model (LLM) agents for graph traversal and retrieval; an approach that is sensitive to traversal initialization, as it is prone to entity linking errors and may not generalize well to custom (\"bring-your-own\") KGs. We introduce BYOKG-RAG, a framework that enhances KGQA by synergistically combining LLMs with specialized graph retrieval tools. In BYOKG-RAG, LLMs generate critical graph artifacts (question entities, candidate answers, reasoning paths, and OpenCypher queries), and graph tools link these artifacts to the KG and retrieve relevant graph context. The retrieved context enables the LLM to iteratively refine its graph linking and retrieval, before final answer generation. By retrieving context from different graph tools, BYOKG-RAG offers a more general and robust solution for QA over custom KGs. Through experiments on five benchmarks spanning diverse KG types, we demonstrate that BYOKG-RAG outperforms the second-best graph retrieval method by 4.5% points while showing better generalization to custom KGs. BYOKG-RAG framework is open-sourced at", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.04127.pdf", "abstract_url": "https://arxiv.org/abs/2507.04127", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "BYOKG-RAG是一个结合大型语言模型（LLM）和专门图检索工具的知识图谱问答（KGQA）框架，旨在解决现有方法在自定义知识图谱上的泛化问题和实体链接错误。", "motivation": "解决知识图谱问答（KGQA）中由于输入图的结构和语义变化导致的挑战，特别是现有依赖LLM代理的方法在遍历初始化和实体链接上的不足。", "method": "BYOKG-RAG框架通过LLM生成关键图工件（如问题实体、候选答案、推理路径和OpenCypher查询），并利用图工具将这些工件链接到知识图谱并检索相关图上下文，从而迭代优化链接和检索过程。", "result": "在五个涵盖不同类型知识图谱的基准测试中，BYOKG-RAG比第二好的图检索方法性能高出4.5%，且在自定义知识图谱上表现出更好的泛化能力。", "conclusion": "BYOKG-RAG通过结合LLM和图检索工具，为自定义知识图谱上的问答提供了一个更通用和鲁棒的解决方案，其框架已开源。"}}
{"id": "2507.03326", "title": "Mirror in the Model: Ad Banner Image Generation via Reflective Multi-LLM and Multi-modal Agents", "authors": ["Zhao Wang", "Bowen Chen", "Yotaro Shimose", "Sota Moriyama", "Heng Wang", "Shingo Takamatsu"], "abstract": "Recent generative models such as GPT-4o have shown strong capabilities in producing high-quality images with accurate text rendering. However, commercial design tasks like advertising banners demand more than visual fidelity -- they require structured layouts, precise typography, consistent branding, and more. In this paper, we introduce MIMO (Mirror In-the-Model), an agentic refinement framework for automatic ad banner generation. MIMO combines a hierarchical multi-modal agent system (MIMO-Core) with a coordination loop (MIMO-Loop) that explores multiple stylistic directions and iteratively improves design quality. Requiring only a simple natural language based prompt and logo image as input, MIMO automatically detects and corrects multiple types of errors during generation. Experiments show that MIMO significantly outperforms existing diffusion and LLM-based baselines in real-world banner design scenarios.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.03326.pdf", "abstract_url": "https://arxiv.org/abs/2507.03326", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了MIMO（Mirror In-the-Model），一个用于自动广告横幅生成的代理细化框架，结合了分层多模态代理系统和协调循环，显著优于现有的基于扩散和LLM的基线。", "motivation": "商业设计任务如广告横幅需要不仅仅是视觉保真度，还需要结构化布局、精确的排版、一致的品牌等，现有生成模型如GPT-4o在这方面存在不足。", "method": "MIMO框架结合了分层多模态代理系统（MIMO-Core）和协调循环（MIMO-Loop），通过探索多种风格方向并迭代提高设计质量。", "result": "实验表明，MIMO在真实世界的横幅设计场景中显著优于现有的基于扩散和LLM的基线。", "conclusion": "MIMO框架为自动广告横幅生成提供了一种有效的方法，能够自动检测和纠正生成过程中的多种错误，提高了设计质量。"}}
{"id": "2507.04067", "title": "HAWK: A Hierarchical Workflow Framework for Multi-Agent Collaboration", "authors": ["Yuyang Cheng", "Yumiao Xu", "Chaojia Yu", "Yong Zhao"], "abstract": "Contemporary multi-agent systems encounter persistent challenges in cross-platform interoperability, dynamic task scheduling, and efficient resource sharing. Agents with heterogeneous implementations often lack standardized interfaces; collaboration frameworks remain brittle and hard to extend; scheduling policies are static; and inter-agent state synchronization is insufficient. We propose Hierarchical Agent Workflow (HAWK), a modular framework comprising five layers-User, Workflow, Operator, Agent, and Resource-and supported by sixteen standardized interfaces. HAWK delivers an end-to-end pipeline covering task parsing, workflow orchestration, intelligent scheduling, resource invocation, and data synchronization. At its core lies an adaptive scheduling and optimization module in the Workflow Layer, which harnesses real-time feedback and dynamic strategy adjustment to maximize utilization. The Resource Layer provides a unified abstraction over heterogeneous data sources, large models, physical devices, and third-party services&tools, simplifying cross-domain information retrieval. We demonstrate HAWK's scalability and effectiveness via CreAgentive, a multi-agent novel-generation prototype, which achieves marked gains in throughput, lowers invocation complexity, and improves system controllability. We also show how hybrid deployments of large language models integrate seamlessly within HAWK, highlighting its flexibility. Finally, we outline future research avenues-hallucination mitigation, real-time performance tuning, and enhanced cross-domain adaptability-and survey prospective applications in healthcare, government, finance, and education.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "AgentIR@SIGIR 2025", "pdf_url": "https://arxiv.org/pdf/2507.04067.pdf", "abstract_url": "https://arxiv.org/abs/2507.04067", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "HAWK是一个分层工作流框架，旨在解决多智能体协作中的跨平台互操作性、动态任务调度和高效资源共享问题。", "motivation": "当代多智能体系统在跨平台互操作性、动态任务调度和高效资源共享方面面临持续挑战。", "method": "HAWK框架由五个层次（用户、工作流、操作者、智能体和资源）和十六个标准化接口组成，包括任务解析、工作流编排、智能调度、资源调用和数据同步的端到端管道。", "result": "通过CreAgentive原型展示了HAWK的可扩展性和有效性，实现了吞吐量的显著提升、调用复杂度的降低和系统可控性的改善。", "conclusion": "HAWK框架为多智能体协作提供了一个灵活、可扩展的解决方案，并指出了未来研究方向和应用前景。"}}
{"id": "2507.04037", "title": "Ready Jurist One: Benchmarking Language Agents for Legal Intelligence in Dynamic Environments", "authors": ["Zheng Jia", "Shengbin Yue", "Wei Chen", "Siyuan Wang", "Yidong Liu", "Yun Song", "Zhongyu Wei"], "abstract": "The gap between static benchmarks and the dynamic nature of real-world legal practice poses a key barrier to advancing legal intelligence. To this end, we introduce J1-ENVS, the first interactive and dynamic legal environment tailored for LLM-based agents. Guided by legal experts, it comprises six representative scenarios from Chinese legal practices across three levels of environmental complexity. We further introduce J1-EVAL, a fine-grained evaluation framework, designed to assess both task performance and procedural compliance across varying levels of legal proficiency. Extensive experiments on 17 LLM agents reveal that, while many models demonstrate solid legal knowledge, they struggle with procedural execution in dynamic settings. Even the SOTA model, GPT-4o, falls short of 60% overall performance. These findings highlight persistent challenges in achieving dynamic legal intelligence and offer valuable insights to guide future research.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.04037.pdf", "abstract_url": "https://arxiv.org/abs/2507.04037", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了J1-ENVS，第一个为基于LLM的代理设计的交互式和动态法律环境，以及J1-EVAL评估框架，用于评估在动态环境中的任务表现和程序合规性。通过对17个LLM代理的广泛实验，发现尽管许多模型展示了扎实的法律知识，但在动态环境中的程序执行上仍有困难，即使是SOTA模型GPT-4o的总体表现也不足60%。", "motivation": "解决静态基准与动态现实法律实践之间的差距，推动法律智能的发展。", "method": "引入J1-ENVS动态法律环境和J1-EVAL评估框架，通过专家指导的六个代表性中国法律实践场景，评估LLM代理的性能。", "result": "实验显示，许多LLM代理在法律知识上表现良好，但在动态环境中的程序执行上表现不佳，GPT-4o的总体表现不足60%。", "conclusion": "研究揭示了实现动态法律智能的持续挑战，并为未来研究提供了有价值的见解。"}}
{"id": "2507.04103", "title": "How to Train Your LLM Web Agent: A Statistical Diagnosis", "authors": ["Dheeraj Vattikonda", "Santhoshi Ravichandran", "Emiliano Penaloza", "Hadi Nekoei", "Megh Thakkar", "Thibault Le Sellier de Chezelles", "Nicolas Gontier", "Miguel Muñoz-Mármol", "Sahar Omidi Shayegan", "Stefania Raimondo", "Xue Liu", "Alexandre Drouin", "Laurent Charlin", "Alexandre Piché", "Alexandre Lacoste", "Massimo Caccia"], "abstract": "LLM-based web agents have recently made significant progress, but much of it has occurred in closed-source systems, widening the gap with open-source alternatives. Progress has been held back by two key challenges: first, a narrow focus on single-step tasks that overlooks the complexity of multi-step web interactions; and second, the high compute costs required to post-train LLM-based web agents. To address this, we present the first statistically grounded study on compute allocation for LLM web-agent post-training. Our approach uses a two-stage pipeline, training a Llama 3.1 8B student to imitate a Llama 3.3 70B teacher via supervised fine-tuning (SFT), followed by on-policy reinforcement learning. We find this process highly sensitive to hyperparameter choices, making exhaustive sweeps impractical. To spare others from expensive trial-and-error, we sample 1,370 configurations and use bootstrapping to estimate effective hyperparameters. Our results show that combining SFT with on-policy RL consistently outperforms either approach alone on both WorkArena and MiniWob++. Further, this strategy requires only 55% of the compute to match the peak performance of pure SFT on MiniWob++, effectively pushing the compute-performance Pareto frontier, and is the only strategy that can close the gap with closed-source models.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.04103.pdf", "abstract_url": "https://arxiv.org/abs/2507.04103", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Machine Learning (stat.ML)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一个统计基础的研究，用于LLM网络代理的后训练计算分配，通过两阶段管道（监督微调和策略强化学习）优化性能，显著减少计算成本并缩小与闭源模型的差距。", "motivation": "解决LLM-based网络代理在开源系统中进展缓慢的问题，主要由于单步任务的狭隘焦点和多步网络交互的复杂性忽视，以及高计算成本。", "method": "使用两阶段管道：首先通过监督微调（SFT）训练Llama 3.1 8B学生模型模仿Llama 3.3 70B教师模型，然后进行策略强化学习。", "result": "结合SFT和策略RL在WorkArena和MiniWob++上表现优于单独使用任一方法，仅需55%的计算即可匹配纯SFT在MiniWob++上的峰值性能。", "conclusion": "该方法有效推动了计算性能的Pareto前沿，是唯一能缩小与闭源模型差距的策略，为开源LLM网络代理的训练提供了高效路径。"}}
{"id": "2507.04105", "title": "Enhancing Robustness of LLM-Driven Multi-Agent Systems through Randomized Smoothing", "authors": ["Jinwei Hu", "Yi Dong", "Zhengtao Ding", "Xiaowei Huang"], "abstract": "This paper presents a defense framework for enhancing the safety of large language model (LLM) empowered multi-agent systems (MAS) in safety-critical domains such as aerospace. We apply randomized smoothing, a statistical robustness certification technique, to the MAS consensus context, enabling probabilistic guarantees on agent decisions under adversarial influence. Unlike traditional verification methods, our approach operates in black-box settings and employs a two-stage adaptive sampling mechanism to balance robustness and computational efficiency. Simulation results demonstrate that our method effectively prevents the propagation of adversarial behaviors and hallucinations while maintaining consensus performance. This work provides a practical and scalable path toward safe deployment of LLM-based MAS in real-world, high-stakes environments.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "Preprint accepted by Chinese Journal of Aeronautics", "pdf_url": "https://arxiv.org/pdf/2507.04105.pdf", "abstract_url": "https://arxiv.org/abs/2507.04105", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种防御框架，通过随机平滑技术增强大型语言模型（LLM）驱动的多智能体系统（MAS）在安全关键领域（如航空航天）的安全性。该方法在MAS共识背景下应用随机平滑，为对抗性影响下的智能体决策提供概率保证。", "motivation": "解决在安全关键领域中，大型语言模型驱动的多智能体系统面临的安全问题，特别是对抗性行为和幻觉传播的挑战。", "method": "采用随机平滑技术，结合两阶段自适应采样机制，以在保证鲁棒性的同时平衡计算效率。", "result": "仿真结果表明，该方法有效防止了对抗性行为和幻觉的传播，同时保持了共识性能。", "conclusion": "这项工作为在现实世界高风险环境中安全部署基于LLM的MAS提供了一条实用且可扩展的路径。"}}
{"id": "2507.04370", "title": "WebSynthesis: World-Model-Guided MCTS for Efficient WebUI-Trajectory Synthesis", "authors": ["Yifei Gao", "Junhong Ye", "Jiaqi Wang", "Jitao Sang"], "abstract": "Recent advancements in large language models (LLMs) have significantly improved the capabilities of web agents. However, effectively navigating complex and dynamic web environments still requires more advanced trajectory-level planning and execution. Prior studies have addressed self-improving agents by collecting extensive GUI trajectories from real-environment interactions. Despite their effectiveness, these approaches encounter two critical challenges: (1) Uncontrollable environment states, where real or sandboxed web environments often yield unstable and non-deterministic feedback, complicating the reproduction and debugging of agent behaviors; and (2) High API costs, as generating even a single interaction trajectory can involve hundreds of queries, leading to considerable API usage and computational expenses. To address these limitations and enable scalable self-improvement for agents, we propose WebSynthesis, a novel framework for trajectory synthesis and training. WebSynthesis leverages a learned world model to simulate virtual web environments, allowing a policy agent to perform efficient and reversible tree-based planning. This approach supports the large-scale generation of diverse and high-quality trajectories, which are subsequently utilized to refine the agent's policy. Experimental results demonstrate that an agent trained using WebSynthesis on a small-scale synthetic dataset achieves performance comparable to or even surpassing that of models trained on large-scale real-world data.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.04370.pdf", "abstract_url": "https://arxiv.org/abs/2507.04370", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "WebSynthesis是一种新型框架，通过利用学习到的世界模型模拟虚拟网络环境，支持高效和可逆的基于树的规划，以生成多样化和高质量的轨迹，进而优化代理的策略。实验表明，使用小规模合成数据集训练的代理性能可与大规模真实世界数据训练的模型相媲美甚至超越。", "motivation": "解决在复杂动态网络环境中导航时面临的不可控环境状态和高API成本两大挑战，以实现代理的可扩展自我改进。", "method": "提出WebSynthesis框架，利用学习到的世界模型模拟虚拟网络环境，使策略代理能够进行高效和可逆的基于树的规划。", "result": "实验结果显示，使用小规模合成数据集通过WebSynthesis训练的代理，其性能与使用大规模真实世界数据训练的模型相当或更优。", "conclusion": "WebSynthesis框架能够有效支持代理的大规模自我改进，通过合成轨迹训练的策略代理在性能上可以达到或超过依赖大规模真实交互数据的模型。"}}
{"id": "2507.04376", "title": "MOD-X: A Modular Open Decentralized eXchange Framework proposal for Heterogeneous Interoperable Artificial Agents", "authors": ["Georgios Ioannides", "Christos Constantinou", "Vinija Jain", "Aman Chadha", "Aaron Elkins"], "abstract": "As Artificial Intelligence systems evolve from monolithic models to ecosystems of specialized agents, the need for standardized communication protocols becomes increasingly critical. This paper introduces MOD-X (Modular Open Decentralized eXchange), a novel architectural framework proposal for agent interoperability that addresses key limitations of existing protocols. Unlike current approaches, MOD-X proposes a layered architecture with a Universal Message Bus, thorough state management, translation capabilities, and blockchain-based security mechanisms. We present MOD-X's architecture, compare it with existing protocols, and demonstrate its application through a worked example how it enables integration between heterogeneous specialist agents (agents with different architectures, vendors, capabilities, and knowledge representations--including rule-based systems, neural networks, symbolic reasoning engines, and legacy software with agent wrappers). MOD-X's key innovations include a publish-subscribe communication model, semantic capability discovery, and dynamic workflow orchestration--providing a framework that bridges theoretical formalism with practical implementation. This architecture addresses the growing need for truly decentralized, interoperable agent ecosystems that can scale effectively without the need for central coordination.", "subjects": "Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Multiagent Systems (cs.MA); Networking and Internet Architecture (cs.NI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.04376.pdf", "abstract_url": "https://arxiv.org/abs/2507.04376", "categories": ["Artificial Intelligence (cs.AI)", "Distributed, Parallel, and Cluster Computing (cs.DC)", "Multiagent Systems (cs.MA)", "Networking and Internet Architecture (cs.NI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了MOD-X（模块化开放去中心化交换）框架，旨在解决异构可互操作人工智能代理之间的标准化通信问题。MOD-X通过分层架构、通用消息总线、状态管理、翻译能力和基于区块链的安全机制，提供了一个无需中央协调即可有效扩展的去中心化代理生态系统。", "motivation": "随着人工智能系统从单一模型发展为专业化代理生态系统，标准化通信协议的需求日益增长。现有协议在代理互操作性方面存在限制，MOD-X旨在解决这些问题。", "method": "MOD-X提出了一种分层架构，包括通用消息总线、状态管理、翻译能力和基于区块链的安全机制。通过发布-订阅通信模型、语义能力发现和动态工作流编排，实现了异构代理的集成。", "result": "MOD-X的创新之处在于其发布-订阅通信模型、语义能力发现和动态工作流编排，这些特性使其能够桥接理论形式主义与实际实现，支持异构代理的有效集成和扩展。", "conclusion": "MOD-X为真正去中心化、可互操作的代理生态系统提供了一个框架，能够在不依赖中央协调的情况下有效扩展，满足了当前对标准化通信协议的迫切需求。"}}
{"id": "2507.04395", "title": "SpiritRAG: A Q&A System for Religion and Spirituality in the United Nations Archive", "authors": ["Yingqiang Gao", "Fabian Winiger", "Patrick Montjourides", "Anastassia Shaitarova", "Nianlong Gu", "Simon Peng-Keller", "Gerold Schneider"], "abstract": "Religion and spirituality (R/S) are complex and highly domain-dependent concepts which have long confounded researchers and policymakers. Due to their context-specificity, R/S are difficult to operationalize in conventional archival search strategies, particularly when datasets are very large, poorly accessible, and marked by information noise. As a result, considerable time investments and specialist knowledge is often needed to extract actionable insights related to R/S from general archival sources, increasing reliance on published literature and manual desk reviews. To address this challenge, we present SpiritRAG, an interactive Question Answering (Q&A) system based on Retrieval-Augmented Generation (RAG). Built using 7,500 United Nations (UN) resolution documents related to R/S in the domains of health and education, SpiritRAG allows researchers and policymakers to conduct complex, context-sensitive database searches of very large datasets using an easily accessible, chat-based web interface. SpiritRAG is lightweight to deploy and leverages both UN documents and user provided documents as source material. A pilot test and evaluation with domain experts on 100 manually composed questions demonstrates the practical value and usefulness of SpiritRAG.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.04395.pdf", "abstract_url": "https://arxiv.org/abs/2507.04395", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "SpiritRAG是一个基于检索增强生成（RAG）的交互式问答系统，旨在帮助研究人员和政策制定者从联合国关于宗教和灵性（R/S）的大量档案中提取可操作的见解。", "motivation": "宗教和灵性（R/S）是复杂且高度依赖领域的概念，传统的档案搜索策略难以操作化，尤其是在数据集非常大、难以访问且信息噪音多的情况下。", "method": "使用7,500份联合国关于R/S的决议文件，构建了一个基于检索增强生成（RAG）的问答系统，支持通过聊天式网页界面进行复杂、上下文敏感的数据库搜索。", "result": "通过与领域专家对100个手动编写的问题进行的试点测试和评估，证明了SpiritRAG的实用价值和有用性。", "conclusion": "SpiritRAG为研究人员和政策制定者提供了一个轻量级、易于部署的工具，用于从大量数据集中提取关于R/S的见解，减少了对已发表文献和手动桌面审查的依赖。"}}
{"id": "2507.04415", "title": "MOMENTS: A Comprehensive Multimodal Benchmark for Theory of Mind", "authors": ["Emilio Villa-Cueva", "S M Masrur Ahmed", "Rendi Chevi", "Jan Christian Blaise Cruz", "Kareem Elzeky", "Fermin Cristobal", "Alham Fikri Aji", "Skyler Wang", "Rada Mihalcea", "Thamar Solorio"], "abstract": "Understanding Theory of Mind is essential for building socially intelligent multimodal agents capable of perceiving and interpreting human behavior. We introduce MOMENTS (Multimodal Mental States), a comprehensive benchmark designed to assess the ToM capabilities of multimodal large language models (LLMs) through realistic, narrative-rich scenarios presented in short films. MOMENTS includes over 2,344 multiple-choice questions spanning seven distinct ToM categories. The benchmark features long video context windows and realistic social interactions that provide deeper insight into characters' mental states. While the visual modality generally enhances model performance, current systems still struggle to integrate it effectively, underscoring the need for further research into AI's multimodal understanding of human behavior.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.04415.pdf", "abstract_url": "https://arxiv.org/abs/2507.04415", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了MOMENTS（多模态心理状态），一个全面的基准测试，旨在通过短片中呈现的现实、叙事丰富的场景评估多模态大语言模型（LLMs）的心理理论（ToM）能力。", "motivation": "理解心理理论对于构建能够感知和解释人类行为的社交智能多模态代理至关重要。当前的多模态系统在有效整合视觉信息方面仍存在困难，这表明需要进一步研究AI对人类行为的多模态理解。", "method": "MOMENTS包含超过2,344个多项选择题，涵盖七个不同的ToM类别，具有长视频上下文窗口和现实社交互动，以更深入地了解角色的心理状态。", "result": "虽然视觉模态通常能提高模型性能，但当前系统在有效整合视觉信息方面仍存在困难。", "conclusion": "MOMENTS基准测试强调了进一步研究AI对人类行为多模态理解的必要性，尤其是在整合视觉信息方面。"}}
{"id": "2507.03730", "title": "Less is More: Empowering GUI Agent with Context-Aware Simplification", "authors": ["Gongwei Chen", "Xurui Zhou", "Rui Shao", "Yibo Lyu", "Kaiwen Zhou", "Shuai Wang", "Wentao Li", "Yinchuan Li", "Zhongang Qi", "Liqiang Nie"], "abstract": "The research focus of GUI agents is shifting from text-dependent to pure-vision-based approaches, which, though promising, prioritize comprehensive pre-training data collection while neglecting contextual modeling challenges. We probe the characteristics of element and history contextual modeling in GUI agent and summarize: 1) the high-density and loose-relation of element context highlight the existence of many unrelated elements and their negative influence; 2) the high redundancy of history context reveals the inefficient history modeling in current GUI agents. In this work, we propose a context-aware simplification framework for building an efficient and effective GUI Agent, termed SimpAgent. To mitigate potential interference from numerous unrelated elements, we introduce a masking-based element pruning method that circumvents the intractable relation modeling through an efficient masking mechanism. To reduce the redundancy in historical information, we devise a consistency-guided history compression module, which enhances implicit LLM-based compression through innovative explicit guidance, achieving an optimal balance between performance and efficiency. With the above components, SimpAgent reduces 27% FLOPs and achieves superior GUI navigation performances. Comprehensive navigation experiments across diverse web and mobile environments demonstrate the effectiveness and potential of our agent.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)", "comments": "Accepted to ICCV 2025", "pdf_url": "https://arxiv.org/pdf/2507.03730.pdf", "abstract_url": "https://arxiv.org/abs/2507.03730", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为SimpAgent的上下文感知简化框架，旨在通过元素修剪和历史压缩技术提高GUI代理的效率和效果。", "motivation": "当前GUI代理的研究从依赖文本转向纯视觉方法，虽然前景广阔，但忽视了上下文建模的挑战，特别是元素间无关性和历史信息冗余的问题。", "method": "提出了基于掩码的元素修剪方法和一致性指导的历史压缩模块，以减少无关元素的干扰和历史信息的冗余。", "result": "SimpAgent减少了27%的FLOPs，并在多样化的网页和移动环境中展现了卓越的导航性能。", "conclusion": "SimpAgent通过上下文感知简化，有效提升了GUI代理的性能和效率，展示了其在GUI导航领域的潜力和有效性。"}}
{"id": "2507.04748", "title": "LLM-based Question-Answer Framework for Sensor-driven HVAC System Interaction", "authors": ["Sungmin Lee", "Minju Kang", "Joonhee Lee", "Seungyong Lee", "Dongju Kim", "Jingi Hong", "Jun Shin", "Pei Zhang", "JeongGil Ko"], "abstract": "Question-answering (QA) interfaces powered by large language models (LLMs) present a promising direction for improving interactivity with HVAC system insights, particularly for non-expert users. However, enabling accurate, real-time, and context-aware interactions with HVAC systems introduces unique challenges, including the integration of frequently updated sensor data, domain-specific knowledge grounding, and coherent multi-stage reasoning. In this paper, we present JARVIS, a two-stage LLM-based QA framework tailored for sensor data-driven HVAC system interaction. JARVIS employs an Expert-LLM to translate high-level user queries into structured execution instructions, and an Agent that performs SQL-based data retrieval, statistical processing, and final response generation. To address HVAC-specific challenges, JARVIS integrates (1) an adaptive context injection strategy for efficient HVAC and deployment-specific information integration, (2) a parameterized SQL builder and executor to improve data access reliability, and (3) a bottom-up planning scheme to ensure consistency across multi-stage response generation. We evaluate JARVIS using real-world data collected from a commercial HVAC system and a ground truth QA dataset curated by HVAC experts to demonstrate its effectiveness in delivering accurate and interpretable responses across diverse queries. Results show that JARVIS consistently outperforms baseline and ablation variants in both automated and user-centered assessments, achieving high response quality and accuracy.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.04748.pdf", "abstract_url": "https://arxiv.org/abs/2507.04748", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了JARVIS，一个基于大型语言模型的两阶段问答框架，专为传感器数据驱动的HVAC系统交互设计，旨在提高非专家用户与HVAC系统互动的准确性和实时性。", "motivation": "解决非专家用户与HVAC系统交互时的准确、实时和上下文感知问题，包括频繁更新的传感器数据集成、领域特定知识基础和连贯的多阶段推理。", "method": "JARVIS框架采用专家-LLM将高级用户查询转换为结构化执行指令，并通过代理执行基于SQL的数据检索、统计处理和最终响应生成，集成了自适应上下文注入策略、参数化SQL构建器和执行器以及自底向上的规划方案。", "result": "使用真实世界数据和专家策划的QA数据集评估显示，JARVIS在自动和以用户为中心的评估中均优于基线和消融变体，实现了高响应质量和准确性。", "conclusion": "JARVIS框架有效解决了HVAC系统交互中的挑战，为非专家用户提供了准确和可解释的响应，展示了在实际应用中的潜力。"}}
{"id": "2507.04770", "title": "FurniMAS: Language-Guided Furniture Decoration using Multi-Agent System", "authors": ["Toan Nguyen", "Tri Le", "Quang Nguyen", "Anh Nguyen"], "abstract": "Furniture decoration is an important task in various industrial applications. However, achieving a high-quality decorative result is often time-consuming and requires specialized artistic expertise. To tackle these challenges, we explore how multi-agent systems can assist in automating the decoration process. We propose FurniMAS, a multi-agent system for automatic furniture decoration. Specifically, given a human prompt and a household furniture item such as a working desk or a TV stand, our system suggests relevant assets with appropriate styles and materials, and arranges them on the item, ensuring the decorative result meets functionality, aesthetic, and ambiance preferences. FurniMAS assembles a hybrid team of LLM-based and non-LLM agents, each fulfilling distinct roles in a typical decoration project. These agents collaborate through communication, logical reasoning, and validation to transform the requirements into the final outcome. Extensive experiments demonstrate that our FurniMAS significantly outperforms other baselines in generating high-quality 3D decor.", "subjects": "Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.04770.pdf", "abstract_url": "https://arxiv.org/abs/2507.04770", "categories": ["Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "FurniMAS是一种多代理系统，用于自动家具装饰，通过结合基于LLM和非LLM的代理，根据人类提示和家具项目，推荐相关资产并安排装饰，以满足功能、美学和氛围偏好。", "motivation": "家具装饰在工业应用中是一个重要但耗时且需要专业艺术知识的任务，FurniMAS旨在通过多代理系统自动化这一过程。", "method": "FurniMAS采用了一种多代理系统，结合了基于LLM和非LLM的代理，这些代理通过沟通、逻辑推理和验证协作，将需求转化为最终装饰结果。", "result": "大量实验表明，FurniMAS在生成高质量3D装饰方面显著优于其他基线方法。", "conclusion": "FurniMAS通过多代理系统的协作，有效自动化了家具装饰过程，显著提高了装饰质量和效率。"}}
{"id": "2507.04893", "title": "MARBLE: A Multi-Agent Rule-Based LLM Reasoning Engine for Accident Severity Prediction", "authors": ["Kaleem Ullah Qasim", "Jiashu Zhang"], "abstract": "Accident severity prediction plays a critical role in transportation safety systems but is a persistently difficult task due to incomplete data, strong feature dependencies, and severe class imbalance in which rare but high-severity cases are underrepresented and hard to detect. Existing methods often rely on monolithic models or black box prompting, which struggle to scale in noisy, real-world settings and offer limited interpretability. To address these challenges, we propose MARBLE a multiagent rule based LLM engine that decomposes the severity prediction task across a team of specialized reasoning agents, including an interchangeable ML-backed agent. Each agent focuses on a semantic subset of features (e.g., spatial, environmental, temporal), enabling scoped reasoning and modular prompting without the risk of prompt saturation. Predictions are coordinated through either rule-based or LLM-guided consensus mechanisms that account for class rarity and confidence dynamics. The system retains structured traces of agent-level reasoning and coordination outcomes, supporting in-depth interpretability and post-hoc performance diagnostics. Across both UK and US datasets, MARBLE consistently outperforms traditional machine learning classifiers and state-of-the-art (SOTA) prompt-based reasoning methods including Chain-of-Thought (CoT), Least-to-Most (L2M), and Tree-of-Thought (ToT) achieving nearly 90% accuracy where others plateau below 48%. This performance redefines the practical ceiling for accident severity classification under real world noise and extreme class imbalance. Our results position MARBLE as a generalizable and interpretable framework for reasoning under uncertainty in safety-critical applications.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Multiagent Systems (cs.MA)", "comments": "13 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2507.04893.pdf", "abstract_url": "https://arxiv.org/abs/2507.04893", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "MARBLE是一种多智能体规则基础的LLM推理引擎，用于交通事故严重性预测，通过分解任务到专门化的推理智能体，提高了预测准确性和可解释性。", "motivation": "解决交通事故严重性预测中由于数据不完整、特征依赖性强和类别不平衡导致的预测困难，以及现有方法在噪声环境和可解释性方面的不足。", "method": "采用多智能体规则基础的LLM推理引擎，将预测任务分解到专注于不同特征子集的专门化推理智能体，通过规则或LLM引导的共识机制协调预测。", "result": "MARBLE在英国和美国数据集上的表现优于传统机器学习分类器和最先进的提示推理方法，准确率接近90%，而其他方法最高仅达48%。", "conclusion": "MARBLE为安全关键应用中的不确定性推理提供了一个可推广和可解释的框架，重新定义了在现实世界噪声和极端类别不平衡条件下的交通事故严重性分类的实用上限。"}}
{"id": "2507.05201", "title": "MedGemma Technical Report", "authors": ["Andrew Sellergren", "Sahar Kazemzadeh", "Tiam Jaroensri", "Atilla Kiraly", "Madeleine Traverse", "Timo Kohlberger", "Shawn Xu", "Fayaz Jamil", "Cían Hughes", "Charles Lau", "Justin Chen", "Fereshteh Mahvar", "Liron Yatziv", "Tiffany Chen", "Bram Sterling", "Stefanie Anna Baby", "Susanna Maria Baby", "Jeremy Lai", "Samuel Schmidgall", "Lu Yang", "Kejia Chen", "Per Bjornsson", "Shashir Reddy", "Ryan Brush", "Kenneth Philbrick", "Howard Hu", "Howard Yang", "Richa Tiwari", "Sunny Jansen", "Preeti Singh", "Yun Liu", "Shekoofeh Azizi", "Aishwarya Kamath", "Johan Ferret", "Shreya Pathak", "Nino Vieillard", "Ramona Merhej", "Sarah Perrin", "Tatiana Matejovicova", "Alexandre Ramé", "Morgane Riviere", "Louis Rouillard", "Thomas Mesnard", "Geoffrey Cideron", "Jean-bastien Grill", "Sabela Ramos", "Edouard Yvinec", "Michelle Casbon", "Elena Buchatskaya", "Jean-Baptiste Alayrac", "Dmitry", "Lepikhin", "Vlad Feinberg", "Sebastian Borgeaud", "Alek Andreev", "Cassidy Hardin", "Robert Dadashi", "Léonard Hussenot", "Armand Joulin", "Olivier Bachem", "Yossi Matias", "Katherine Chou", "Avinatan Hassidim", "Kavi Goel", "Clement Farabet", "Joelle Barral", "Tris Warkentin", "Jonathon Shlens", "David Fleet", "Victor Cotruta", "Omar Sanseviero", "Gus Martins", "Phoebe Kirk", "Anand Rao", "Shravya Shetty", "David F. Steiner", "Can Kirmizibayrak", "Rory Pilgrim", "Daniel Golden", "Lin Yang"], "abstract": "Artificial intelligence (AI) has significant potential in healthcare applications, but its training and deployment faces challenges due to healthcare's diverse data, complex tasks, and the need to preserve privacy. Foundation models that perform well on medical tasks and require less task-specific tuning data are critical to accelerate the development of healthcare AI applications. We introduce MedGemma, a collection of medical vision-language foundation models based on Gemma 3 4B and 27B. MedGemma demonstrates advanced medical understanding and reasoning on images and text, significantly exceeding the performance of similar-sized generative models and approaching the performance of task-specific models, while maintaining the general capabilities of the Gemma 3 base models. For out-of-distribution tasks, MedGemma achieves 2.6-10% improvement on medical multimodal question answering, 15.5-18.1% improvement on chest X-ray finding classification, and 10.8% improvement on agentic evaluations compared to the base models. Fine-tuning MedGemma further improves performance in subdomains, reducing errors in electronic health record information retrieval by 50% and reaching comparable performance to existing specialized state-of-the-art methods for pneumothorax classification and histopathology patch classification. We additionally introduce MedSigLIP, a medically-tuned vision encoder derived from SigLIP. MedSigLIP powers the visual understanding capabilities of MedGemma and as an encoder achieves comparable or better performance than specialized medical image encoders. Taken together, the MedGemma collection provides a strong foundation of medical image and text capabilities, with potential to significantly accelerate medical research and development of downstream applications. The MedGemma collection, including tutorials and model weights, can be found at", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.05201.pdf", "abstract_url": "https://arxiv.org/abs/2507.05201", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "MedGemma是一系列基于Gemma 3 4B和27B的医疗视觉语言基础模型，旨在通过先进的医疗理解和推理能力，加速医疗AI应用的发展，同时在保持Gemma 3基础模型通用能力的同时，显著超越类似规模的生成模型，并接近特定任务模型的性能。", "motivation": "解决医疗AI应用中由于数据多样性、任务复杂性及隐私保护需求带来的训练和部署挑战，开发需要较少任务特定调优数据的强大基础模型。", "method": "基于Gemma 3 4B和27B开发MedGemma模型集，并引入MedSigLIP作为视觉编码器，增强视觉理解能力。", "result": "MedGemma在医疗多模态问答、胸部X光发现分类和代理评估等任务上显著超越基础模型，并在子领域微调后进一步减少错误，达到与现有最先进专业方法相当的性能。", "conclusion": "MedGemma模型集为医疗图像和文本能力提供了强大的基础，有望显著加速医学研究和下游应用的开发。"}}
{"id": "2507.05241", "title": "SciMaster: Towards General-Purpose Scientific AI Agents, Part I. X-Master as Foundation: Can We Lead on Humanity's Last Exam?", "authors": ["Jingyi Chai", "Shuo Tang", "Rui Ye", "Yuwen Du", "Xinyu Zhu", "Mengcheng Zhou", "Yanfeng Wang", "Weinan E", "Siheng Chen"], "abstract": "The rapid advancements of AI agents have ignited the long-held ambition of leveraging them to accelerate scientific discovery. Achieving this goal requires a deep understanding of the frontiers of human knowledge. As such, Humanity's Last Exam (HLE) provides an exceptionally challenging touchstone for evaluating scientific AI agents. In this work, we aim to construct the foundational architecture for general-purpose agents and validate the capabilities through leading performance on HLE. To achieve this, we introduce X-Master, a tool-augmented reasoning agent designed to emulate human researchers by interacting flexibly with external tools during its reasoning process. This agent, guided by the conceptualization of code as an interaction language, can flexibly leverage built-in Python libraries and our customized tools to augment the reasoning. We further scale its capabilities through X-Masters, a scattered-and-stacked agentic workflow that systematically enhances breadth and depth of reasoning. Our open-source solution, X-Masters, sets a new state-of-the-art record on HLE with a score of 32.1%, surpassing OpenAI's and Google's Deep Research (26.6% and 26.9%) and becoming the first to exceed the 30% threshold. This work allows us to gain a deeper understanding of complex task-solving and accumulates valuable experience that can inform future advancements, guiding subsequent model training.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "12 pages, 7 figures", "pdf_url": "https://arxiv.org/pdf/2507.05241.pdf", "abstract_url": "https://arxiv.org/abs/2507.05241", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了X-Master，一种工具增强的推理代理，旨在通过灵活使用外部工具来模拟人类研究者的推理过程，并在Humanity's Last Exam（HLE）上取得了领先的性能。", "motivation": "利用AI代理加速科学发现的长期抱负需要深入理解人类知识的前沿，HLE为此提供了一个极具挑战性的测试标准。", "method": "引入了X-Master，一个工具增强的推理代理，通过代码作为交互语言的概念，灵活利用内置Python库和定制工具来增强推理。", "result": "X-Masters在HLE上创造了32.1%的新记录，超过了OpenAI和Google的Deep Research（26.6%和26.9%），首次超过30%的阈值。", "conclusion": "这项工作加深了对复杂任务解决的理解，为未来的进步积累了宝贵经验，指导后续模型训练。"}}
{"id": "2507.04854", "title": "$\\textit{Grahak-Nyay:}$ Consumer Grievance Redressal through Large Language Models", "authors": ["Shrey Ganatra", "Swapnil Bhattacharyya", "Harshvivek Kashid", "Spandan Anaokar", "Shruti Nair", "Reshma Sekhar", "Siddharth Manohar", "Rahul Hemrajani", "Pushpak Bhattacharyya"], "abstract": "Access to consumer grievance redressal in India is often hindered by procedural complexity, legal jargon, and jurisdictional challenges. To address this, we present $\\textbf{Grahak-Nyay}$ (Justice-to-Consumers), a chatbot that streamlines the process using open-source Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG). Grahak-Nyay simplifies legal complexities through a concise and up-to-date knowledge base. We introduce three novel datasets: $\\textit{GeneralQA}$ (general consumer law), $\\textit{SectoralQA}$ (sector-specific knowledge) and $\\textit{SyntheticQA}$ (for RAG evaluation), along with $\\textit{NyayChat}$, a dataset of 300 annotated chatbot conversations. We also introduce $\\textit{Judgments}$ data sourced from Indian Consumer Courts to aid the chatbot in decision making and to enhance user trust. We also propose $\\textbf{HAB}$ metrics ($\\textbf{Helpfulness, Accuracy, Brevity}$) to evaluate chatbot performance. Legal domain experts validated Grahak-Nyay's effectiveness. Code and datasets will be released.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.04854.pdf", "abstract_url": "https://arxiv.org/abs/2507.04854", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "该论文介绍了Grahak-Nyay，一个利用大型语言模型和检索增强生成技术简化印度消费者投诉流程的聊天机器人。", "motivation": "解决印度消费者投诉流程中的程序复杂性、法律术语和管辖权挑战问题。", "method": "使用开源大型语言模型(LLMs)和检索增强生成(RAG)技术，构建了一个包含最新法律知识的聊天机器人。", "result": "引入了三个新颖的数据集和一个包含300条标注聊天记录的NyayChat数据集，以及来自印度消费者法院的Judgments数据，用于增强聊天机器人的决策能力和用户信任。", "conclusion": "Grahak-Nyay通过法律领域专家的验证，证明了其有效性，并将发布代码和数据集。"}}
{"id": "2507.05244", "title": "Modeling Latent Partner Strategies for Adaptive Zero-Shot Human-Agent Collaboration", "authors": ["Benjamin Li", "Shuyang Shi", "Lucia Romero", "Huao Li", "Yaqi Xie", "Woojun Kim", "Stefanos Nikolaidis", "Michael Lewis", "Katia Sycara", "Simon Stepputtis"], "abstract": "In collaborative tasks, being able to adapt to your teammates is a necessary requirement for success. When teammates are heterogeneous, such as in human-agent teams, agents need to be able to observe, recognize, and adapt to their human partners in real time. This becomes particularly challenging in tasks with time pressure and complex strategic spaces where the dynamics can change rapidly. In this work, we introduce TALENTS, a strategy-conditioned cooperator framework that learns to represent, categorize, and adapt to a range of partner strategies, enabling ad-hoc teamwork. Our approach utilizes a variational autoencoder to learn a latent strategy space from trajectory data. This latent space represents the underlying strategies that agents employ. Subsequently, the system identifies different types of strategy by clustering the data. Finally, a cooperator agent is trained to generate partners for each type of strategy, conditioned on these clusters. In order to adapt to previously unseen partners, we leverage a fixed-share regret minimization algorithm that infers and adjusts the estimated partner strategy dynamically. We assess our approach in a customized version of the Overcooked environment, posing a challenging cooperative cooking task that demands strong coordination across a wide range of possible strategies. Using an online user study, we show that our agent outperforms current baselines when working with unfamiliar human partners.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "Best Paper Award at the RSS 2025 Generative Models x HRI (GenAI-HRI) Workshop", "pdf_url": "https://arxiv.org/pdf/2507.05244.pdf", "abstract_url": "https://arxiv.org/abs/2507.05244", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了TALENTS框架，一种通过学习、分类和适应多种伙伴策略来实现即时团队合作的策略条件合作者框架。", "motivation": "解决在人-代理团队中，代理需要实时观察、识别并适应人类伙伴的挑战，特别是在时间压力和复杂策略空间的任务中。", "method": "使用变分自编码器从轨迹数据中学习潜在策略空间，通过聚类识别不同类型的策略，并训练合作者代理为每种策略类型生成伙伴。采用固定份额遗憾最小化算法动态推断和调整估计的伙伴策略。", "result": "在Overcooked环境的定制版本中，通过在线用户研究表明，该代理在与不熟悉的人类伙伴合作时优于当前基线。", "conclusion": "TALENTS框架能够有效表示、分类和适应广泛的伙伴策略，支持即时团队合作，特别是在需要强协调的复杂任务中。"}}
{"id": "2507.04942", "title": "SIGIR 2025 -- LiveRAG Challenge Report", "authors": ["David Carmel", "Simone Filice", "Guy Horowitz", "Yoelle Maarek", "Oren Somekh", "Ran Tavory"], "abstract": "The LiveRAG Challenge at SIGIR 2025, held between March and May 2025, provided a competitive platform for advancing Retrieval-Augmented Generation (RAG) technologies. Participants from academia and industry were invited to develop a RAG-based question-answering system using a fixed corpus (Fineweb-10BT) and a common open-source LLM (Falcon3-10B-Instruct). The goal was to facilitate challenging comparisons of retrieval and prompting strategies. During the Live Challenge Day, 70 teams from 27 different countries provided answers and supportive information to 500 unseen questions within a strict two-hour time window. Evaluation was conducted in two stages: first an automated LLM-as-a-judge approach was used to compute correctness and faithfulness score, then a manual review of top ranked submissions was conducted. The finalists were announced on June 12, 2025, with prizes awarded during the LiveRAG Workshop at SIGIR 2025 in Padua, Italy.", "subjects": "Computation and Language (cs.CL); Information Retrieval (cs.IR)", "comments": "9 pages, 5 tables", "pdf_url": "https://arxiv.org/pdf/2507.04942.pdf", "abstract_url": "https://arxiv.org/abs/2507.04942", "categories": ["Computation and Language (cs.CL)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "SIGIR 2025 LiveRAG挑战赛报告概述了在2025年3月至5月间举行的比赛，旨在推进检索增强生成（RAG）技术。比赛使用固定语料库和共同的开源大型语言模型，鼓励参与者开发基于RAG的问答系统。70支团队在严格的时间限制内回答了500个未见问题，并通过自动和手动评估选出优胜者。", "motivation": "该挑战赛旨在通过提供一个竞争平台，促进检索增强生成（RAG）技术的进步，特别是在问答系统中的应用，以及比较不同的检索和提示策略。", "method": "比赛要求参与者使用固定的语料库（Fineweb-10BT）和共同的开源大型语言模型（Falcon3-10B-Instruct）开发RAG-based问答系统。评估分为两个阶段：首先使用自动化的LLM-as-a-judge方法计算正确性和忠实度分数，然后对排名靠前的提交进行手动审查。", "result": "来自27个不同国家的70支团队参与了挑战，最终在2025年6月12日宣布了决赛选手，并在意大利帕多瓦的SIGIR 2025 LiveRAG研讨会上颁发了奖项。", "conclusion": "LiveRAG挑战赛成功地为RAG技术的进步提供了一个竞争平台，展示了不同检索和提示策略在问答系统中的效果，并为未来的研究和发展提供了宝贵的见解。"}}
{"id": "2507.02877", "title": "AuraGenome: An LLM-Powered Framework for On-the-Fly Reusable and Scalable Circular Genome Visualizations", "authors": ["Chi Zhang", "Yu Dong", "Yang Wang", "Yuetong Han", "Guihua Shan", "Bixia Tang"], "abstract": "Circular genome visualizations are essential for exploring structural variants and gene regulation. However, existing tools often require complex scripting and manual configuration, making the process time-consuming, error-prone, and difficult to learn. To address these challenges, we introduce AuraGenome, an LLM-powered framework for rapid, reusable, and scalable generation of multi-layered circular genome visualizations. AuraGenome combines a semantic-driven multi-agent workflow with an interactive visual analytics system. The workflow employs seven specialized LLM-driven agents, each assigned distinct roles such as intent recognition, layout planning, and code generation, to transform raw genomic data into tailored visualizations. The system supports multiple coordinated views tailored for genomic data, offering ring, radial, and chord-based layouts to represent multi-layered circular genome visualizations. In addition to enabling interactions and configuration reuse, the system supports real-time refinement and high-quality report export. We validate its effectiveness through two case studies and a comprehensive user study. AuraGenome is available at:", "subjects": "Genomics (q-bio.GN); Artificial Intelligence (cs.AI); Graphics (cs.GR); Human-Computer Interaction (cs.HC)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.02877.pdf", "abstract_url": "https://arxiv.org/abs/2507.02877", "categories": ["Genomics (q-bio.GN)", "Artificial Intelligence (cs.AI)", "Graphics (cs.GR)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "AuraGenome是一个由LLM驱动的框架，用于快速、可重用和可扩展的多层圆形基因组可视化生成。它结合了语义驱动的多代理工作流程和交互式视觉分析系统，通过七个专门的LLM驱动代理来转换原始基因组数据为定制可视化。", "motivation": "解决现有圆形基因组可视化工具需要复杂脚本和手动配置，导致过程耗时、易出错且难以学习的问题。", "method": "采用语义驱动的多代理工作流程和交互式视觉分析系统，利用七个专门的LLM驱动代理（如意图识别、布局规划和代码生成）来转换数据。", "result": "通过两个案例研究和全面的用户研究验证了AuraGenome的有效性，支持实时细化和高质量报告导出。", "conclusion": "AuraGenome为基因组数据的可视化提供了一个快速、可重用和可扩展的解决方案，极大地简化了圆形基因组可视化的生成过程。"}}
{"id": "2507.05257", "title": "Evaluating Memory in LLM Agents via Incremental Multi-Turn Interactions", "authors": ["Yuanzhe Hu", "Yu Wang", "Julian McAuley"], "abstract": "Recent benchmarks for Large Language Model (LLM) agents primarily focus on evaluating reasoning, planning, and execution capabilities, while another critical component-memory, encompassing how agents memorize, update, and retrieve long-term information-is under-evaluated due to the lack of benchmarks. We term agents with memory mechanisms as memory agents. In this paper, we identify four core competencies essential for memory agents: accurate retrieval, test-time learning, long-range understanding, and conflict resolution. Existing datasets either rely on limited context lengths or are tailored for static, long-context settings like book-based QA, which do not reflect the interactive, multi-turn nature of memory agents that incrementally accumulate information. Furthermore, no existing benchmarks cover all four competencies. Therefore, we introduce MemoryAgentBench, a new benchmark specifically designed for memory agents. Our benchmark combines reformulated existing datasets with newly constructed ones, covering the above four memory competencies, providing a systematic and challenging testbed for assessing memory quality. We evaluate a diverse set of memory agents, ranging from simple context-based and retrieval-augmented generation (RAG) systems to advanced agents with external memory modules and tool integration. Empirical results reveal that current methods fall short of mastering all four competencies, underscoring the need for further research into comprehensive memory mechanisms for LLM agents.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "23 Pages, Y. Hu and Y. Wang contribute equally", "pdf_url": "https://arxiv.org/pdf/2507.05257.pdf", "abstract_url": "https://arxiv.org/abs/2507.05257", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文提出了MemoryAgentBench，一个专门为记忆代理设计的新基准，旨在评估大型语言模型（LLM）代理在记忆、更新和检索长期信息方面的能力。", "motivation": "当前的大型语言模型代理基准主要关注推理、规划和执行能力，而忽视了记忆这一关键组成部分，尤其是记忆代理如何记忆、更新和检索长期信息的能力。", "method": "通过结合重新制定的现有数据集和新构建的数据集，MemoryAgentBench涵盖了记忆代理的四个核心能力：准确检索、测试时学习、长距离理解和冲突解决。", "result": "实证结果显示，当前的方法在掌握所有四个记忆能力方面存在不足，突显了需要进一步研究全面的记忆机制。", "conclusion": "MemoryAgentBench为评估记忆代理的记忆质量提供了一个系统化和具有挑战性的测试平台，强调了在LLM代理中发展全面记忆机制的重要性。"}}
{"id": "2507.02974", "title": "InvisibleInk: High-Utility and Low-Cost Text Generation with Differential Privacy", "authors": ["Vishnu Vinod", "Krishna Pillutla", "Abhradeep Guha Thakurta"], "abstract": "As major progress in LLM-based long-form text generation enables paradigms such as retrieval-augmented generation (RAG) and inference-time scaling, safely incorporating private information into the generation remains a critical open question. We present InvisibleInk, a highly scalable long-form text generation framework satisfying rigorous differential privacy guarantees with respect to the sensitive references. It interprets sampling from the LLM's next-token-distribution as the exponential mechanism over the LLM logits with two innovations. First, we reduce the privacy cost by isolating and clipping only the sensitive information in the model logits (relative to the public logits). Second, we improve text quality by sampling from a small superset of the top-$k$ private tokens. Empirical evaluations demonstrate a consistent $8\\times$ reduction in computation cost over state-of-the-art baselines to generate long-form private text of the same utility across privacy levels. In summary, InvisibleInk is able to generate private long-form text at less than $10\\times$ the computation cost of non-private generation.", "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL); Cryptography and Security (cs.CR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.02974.pdf", "abstract_url": "https://arxiv.org/abs/2507.02974", "categories": ["Machine Learning (cs.LG)", "Computation and Language (cs.CL)", "Cryptography and Security (cs.CR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "InvisibleInk是一个高可扩展性的长文本生成框架，旨在在严格差分隐私保证下安全地整合敏感信息。通过两项创新，它显著降低了隐私成本并提高了文本质量。", "motivation": "解决在LLM生成长文本时安全整合私人信息的开放性问题，特别是在检索增强生成(RAG)和推理时扩展等范式下。", "method": "将LLM的下一个令牌分布采样解释为对LLM logits的指数机制，通过隔离和裁剪模型logits中的敏感信息降低隐私成本，并通过从top-k私有令牌的小超集中采样提高文本质量。", "result": "实证评估显示，在相同隐私级别下生成长文本时，计算成本比现有基线降低了8倍，且能以不到非私有生成10倍的计算成本生成私有长文本。", "conclusion": "InvisibleInk能够在保证差分隐私的同时，高效且低成本地生成长文本，为安全整合私人信息提供了可行的解决方案。"}}
{"id": "2507.02925", "title": "Large Language Model Agent for Modular Task Execution in Drug Discovery", "authors": ["Janghoon Ock", "Radheesh Sharma Meda", "Srivathsan Badrinarayanan", "Neha S. Aluru", "Achuth Chandrasekhar", "Amir Barati Farimani"], "abstract": "We present a modular framework powered by large language models (LLMs) that automates and streamlines key tasks across the early-stage computational drug discovery pipeline. By combining LLM reasoning with domain-specific tools, the framework performs biomedical data retrieval, domain-specific question answering, molecular generation, property prediction, property-aware molecular refinement, and 3D protein-ligand structure generation. In a case study targeting BCL-2 in lymphocytic leukemia, the agent autonomously retrieved relevant biomolecular information-including FASTA sequences, SMILES representations, and literature-and answered mechanistic questions with improved contextual accuracy over standard LLMs. It then generated chemically diverse seed molecules and predicted 67 ADMET-related properties, which guided iterative molecular refinement. Across two refinement rounds, the number of molecules with QED > 0.6 increased from 34 to 55, and those passing at least four out of five empirical drug-likeness rules rose from 29 to 52, within a pool of 194 molecules. The framework also employed Boltz-2 to generate 3D protein-ligand complexes and provide rapid binding affinity estimates for candidate compounds. These results demonstrate that the approach effectively supports molecular screening, prioritization, and structure evaluation. Its modular design enables flexible integration of evolving tools and models, providing a scalable foundation for AI-assisted therapeutic discovery.", "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL); Biomolecules (q-bio.BM)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.02925.pdf", "abstract_url": "https://arxiv.org/abs/2507.02925", "categories": ["Machine Learning (cs.LG)", "Computation and Language (cs.CL)", "Biomolecules (q-bio.BM)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一个由大型语言模型（LLMs）驱动的模块化框架，旨在自动化和简化早期计算药物发现流程中的关键任务。通过结合LLM推理和领域特定工具，该框架能够执行生物医学数据检索、领域特定问答、分子生成、性质预测、性质感知分子优化和3D蛋白质-配体结构生成。在针对淋巴性白血病中的BCL-2的案例研究中，该框架展示了其在分子筛选、优先排序和结构评估方面的有效性。", "motivation": "解决早期计算药物发现流程中的任务自动化和效率问题，通过利用大型语言模型和领域特定工具的结合，提高药物发现的效率和准确性。", "method": "开发了一个模块化框架，结合大型语言模型的推理能力和领域特定工具，执行包括生物医学数据检索、分子生成、性质预测和优化、以及3D蛋白质-配体结构生成等多种任务。", "result": "在针对BCL-2的案例研究中，框架自主检索了相关生物分子信息，生成了化学多样性种子分子，并预测了67种ADMET相关性质，指导了分子优化。优化后，QED > 0.6的分子数量从34增加到55，通过至少四项药物相似性规则的分子数量从29增加到52。此外，框架还生成了3D蛋白质-配体复合物，并提供了候选化合物的快速结合亲和力估计。", "conclusion": "该框架为AI辅助的治疗发现提供了一个可扩展的基础，其模块化设计允许灵活集成不断发展的工具和模型，有效支持分子筛选、优先排序和结构评估。"}}
{"id": "2507.04036", "title": "PresentAgent: Multimodal Agent for Presentation Video Generation", "authors": ["Jingwei Shi", "Zeyu Zhang", "Biao Wu", "Yanjie Liang", "Meng Fang", "Ling Chen", "Yang Zhao"], "abstract": "We present PresentAgent, a multimodal agent that transforms long-form documents into narrated presentation videos. While existing approaches are limited to generating static slides or text summaries, our method advances beyond these limitations by producing fully synchronized visual and spoken content that closely mimics human-style presentations. To achieve this integration, PresentAgent employs a modular pipeline that systematically segments the input document, plans and renders slide-style visual frames, generates contextual spoken narration with large language models and Text-to-Speech models, and seamlessly composes the final video with precise audio-visual alignment. Given the complexity of evaluating such multimodal outputs, we introduce PresentEval, a unified assessment framework powered by Vision-Language Models that comprehensively scores videos across three critical dimensions: content fidelity, visual clarity, and audience comprehension through prompt-based evaluation. Our experimental validation on a curated dataset of 30 document-presentation pairs demonstrates that PresentAgent approaches human-level quality across all evaluation metrics. These results highlight the significant potential of controllable multimodal agents in transforming static textual materials into dynamic, effective, and accessible presentation formats. Code will be available at", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.04036.pdf", "abstract_url": "https://arxiv.org/abs/2507.04036", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "PresentAgent是一种多模态代理，能够将长文档转换为带叙述的演示视频，超越了现有方法仅能生成静态幻灯片或文本摘要的限制。", "motivation": "解决现有方法无法生成与人类风格演示完全同步的视觉和口语内容的问题。", "method": "采用模块化流程，包括文档分割、幻灯片风格视觉帧的规划和渲染、使用大型语言模型和文本到语音模型生成上下文口语叙述，以及精确的音频-视觉对齐。", "result": "在30个文档-演示对的数据集上，PresentAgent在所有评估指标上接近人类水平的质量。", "conclusion": "可控多模态代理在将静态文本材料转换为动态、有效和可访问的演示格式方面具有巨大潜力。"}}
{"id": "2507.03923", "title": "Learning Disentangled Stain and Structural Representations for Semi-Supervised Histopathology Segmentation", "authors": ["Ha-Hieu Pham", "Nguyen Lan Vi Vu", "Thanh-Huy Nguyen", "Ulas Bagci", "Min Xu", "Trung-Nghia Le", "Huy-Hieu Pham"], "abstract": "Accurate gland segmentation in histopathology images is essential for cancer diagnosis and prognosis. However, significant variability in Hematoxylin and Eosin (H&E) staining and tissue morphology, combined with limited annotated data, poses major challenges for automated segmentation. To address this, we propose Color-Structure Dual-Student (CSDS), a novel semi-supervised segmentation framework designed to learn disentangled representations of stain appearance and tissue structure. CSDS comprises two specialized student networks: one trained on stain-augmented inputs to model chromatic variation, and the other on structure-augmented inputs to capture morphological cues. A shared teacher network, updated via Exponential Moving Average (EMA), supervises both students through pseudo-labels. To further improve label reliability, we introduce stain-aware and structure-aware uncertainty estimation modules that adaptively modulate the contribution of each student during training. Experiments on the GlaS and CRAG datasets show that CSDS achieves state-of-the-art performance in low-label settings, with Dice score improvements of up to 1.2% on GlaS and 0.7% on CRAG at 5% labeled data, and 0.7% and 1.4% at 10%. Our code and pre-trained models are available at", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.03923.pdf", "abstract_url": "https://arxiv.org/abs/2507.03923", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种名为Color-Structure Dual-Student (CSDS)的半监督分割框架，旨在学习解耦的染色外观和组织结构表示，以提高组织病理学图像中腺体分割的准确性。", "motivation": "组织病理学图像中腺体的准确分割对于癌症的诊断和预后至关重要。然而，H&E染色的显著变异性和组织形态的多样性，加上有限的标注数据，给自动化分割带来了重大挑战。", "method": "CSDS框架包含两个专门的学生网络：一个在染色增强的输入上训练以模拟颜色变化，另一个在结构增强的输入上训练以捕捉形态线索。通过共享的教师网络和伪标签监督两个学生网络，并引入了染色感知和结构感知的不确定性估计模块来进一步提高标签的可靠性。", "result": "在GlaS和CRAG数据集上的实验表明，CSDS在低标签设置下实现了最先进的性能，在5%和10%的标注数据下，Dice分数分别提高了1.2%和0.7%在GlaS上，0.7%和1.4%在CRAG上。", "conclusion": "CSDS框架通过解耦染色和结构表示，有效地解决了组织病理学图像分割中的挑战，特别是在标注数据有限的情况下，为癌症诊断和预后提供了更准确的分割结果。"}}
{"id": "2507.02910", "title": "Causal-Paced Deep Reinforcement Learning", "authors": ["Geonwoo Cho", "Jaegyun Im", "Doyoon Kim", "Sundong Kim"], "abstract": "Designing effective task sequences is crucial for curriculum reinforcement learning (CRL), where agents must gradually acquire skills by training on intermediate tasks. A key challenge in CRL is to identify tasks that promote exploration, yet are similar enough to support effective transfer. While recent approach suggests comparing tasks via their Structural Causal Models (SCMs), the method requires access to ground-truth causal structures, an unrealistic assumption in most RL settings. In this work, we propose Causal-Paced Deep Reinforcement Learning (CP-DRL), a curriculum learning framework aware of SCM differences between tasks based on interaction data approximation. This signal captures task novelty, which we combine with the agent's learnability, measured by reward gain, to form a unified objective. Empirically, CP-DRL outperforms existing curriculum methods on the Point Mass benchmark, achieving faster convergence and higher returns. CP-DRL demonstrates reduced variance with comparable final returns in the Bipedal Walker-Trivial setting, and achieves the highest average performance in the Infeasible variant. These results indicate that leveraging causal relationships between tasks can improve the structure-awareness and sample efficiency of curriculum reinforcement learning. We provide the full implementation of CP-DRL to facilitate the reproduction of our main results at", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)", "comments": "Workshop on Causal Reinforcement Learning, Reinforcement Learning Conference (RLC) 2025", "pdf_url": "https://arxiv.org/pdf/2507.02910.pdf", "abstract_url": "https://arxiv.org/abs/2507.02910", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Machine Learning (stat.ML)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了Causal-Paced Deep Reinforcement Learning (CP-DRL)，一个基于任务间结构因果模型(SCM)差异的课程学习框架，旨在通过结合任务新颖性和代理的可学习性来提高课程强化学习的结构意识和样本效率。", "motivation": "课程强化学习(CRL)中设计有效的任务序列是一个关键挑战，尤其是在缺乏真实因果结构的情况下。本文旨在解决如何在没有真实因果结构的情况下，通过交互数据近似来识别促进探索和支持有效转移的任务。", "method": "CP-DRL框架通过交互数据近似任务间的SCM差异，结合任务新颖性和代理的可学习性（通过奖励增益测量）形成一个统一的目标。", "result": "在Point Mass基准测试中，CP-DRL优于现有的课程方法，实现了更快的收敛和更高的回报。在Bipedal Walker-Trivial设置中，CP-DRL展示了较低的方差和可比的最终回报，在Infeasible变体中达到了最高的平均性能。", "conclusion": "利用任务间的因果关系可以提高课程强化学习的结构意识和样本效率。CP-DRL的成功实施为在没有真实因果结构的情况下设计有效的任务序列提供了新的可能性。"}}
{"id": "2507.02920", "title": "Visual-Conversational Interface for Evidence-Based Explanation of Diabetes Risk Prediction", "authors": ["Reza Samimi", "Aditya Bhattacharya", "Lucija Gosak", "Gregor Stiglic", "Katrien Verbert"], "abstract": "Healthcare professionals need effective ways to use, understand, and validate AI-driven clinical decision support systems. Existing systems face two key limitations: complex visualizations and a lack of grounding in scientific evidence. We present an integrated decision support system that combines interactive visualizations with a conversational agent to explain diabetes risk assessments. We propose a hybrid prompt handling approach combining fine-tuned language models for analytical queries with general Large Language Models (LLMs) for broader medical questions, a methodology for grounding AI explanations in scientific evidence, and a feature range analysis technique to support deeper understanding of feature contributions. We conducted a mixed-methods study with 30 healthcare professionals and found that the conversational interactions helped healthcare professionals build a clear understanding of model assessments, while the integration of scientific evidence calibrated trust in the system's decisions. Most participants reported that the system supported both patient risk evaluation and recommendation.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "18 pages, 5 figures, 7th ACM Conference on Conversational User Interfaces", "pdf_url": "https://arxiv.org/pdf/2507.02920.pdf", "abstract_url": "https://arxiv.org/abs/2507.02920", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种结合交互式可视化和对话代理的综合决策支持系统，用于解释糖尿病风险评估。该系统通过混合提示处理方法、基于科学证据的AI解释基础以及特征范围分析技术，帮助医疗专业人员理解和验证AI驱动的临床决策支持系统。", "motivation": "解决现有临床决策支持系统在复杂可视化和缺乏科学证据基础方面的局限性，以提高医疗专业人员对AI驱动系统的使用、理解和验证能力。", "method": "提出了一种混合提示处理方法，结合了针对分析查询的精细调整语言模型和针对更广泛医学问题的通用大型语言模型(LLMs)，以及一种基于科学证据的AI解释方法和特征范围分析技术。", "result": "通过与30名医疗专业人员的混合方法研究发现，对话交互帮助医疗专业人员清晰理解模型评估，而科学证据的整合则校准了对系统决策的信任。大多数参与者认为系统支持患者风险评估和推荐。", "conclusion": "集成交互式可视化和对话代理的决策支持系统能有效帮助医疗专业人员理解和信任AI驱动的糖尿病风险评估，支持临床决策。"}}
{"id": "2507.03620", "title": "Is It Time To Treat Prompts As Code? A Multi-Use Case Study For Prompt Optimization Using DSPy", "authors": ["Francisca Lemos", "Victor Alves", "Filipa Ferraz"], "abstract": "Although prompt engineering is central to unlocking the full potential of Large Language Models (LLMs), crafting effective prompts remains a time-consuming trial-and-error process that relies on human intuition. This study investigates Declarative Self-improving Python (DSPy), an optimization framework that programmatically creates and refines prompts, applied to five use cases: guardrail enforcement, hallucination detection in code, code generation, routing agents, and prompt evaluation. Each use case explores how prompt optimization via DSPy influences performance. While some cases demonstrated modest improvements - such as minor gains in the guardrails use case and selective enhancements in hallucination detection - others showed notable benefits. The prompt evaluation criterion task demonstrated a substantial performance increase, rising accuracy from 46.2% to 64.0%. In the router agent case, the possibility of improving a poorly performing prompt and of a smaller model matching a stronger one through optimized prompting was explored. Although prompt refinement increased accuracy from 85.0% to 90.0%, using the optimized prompt with a cheaper model did not improve performance. Overall, this study's findings suggest that DSPy's systematic prompt optimization can enhance LLM performance, particularly when instruction tuning and example selection are optimized together. However, the impact varies by task, highlighting the importance of evaluating specific use cases in prompt optimization research.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": "20 pages with 1 figure", "pdf_url": "https://arxiv.org/pdf/2507.03620.pdf", "abstract_url": "https://arxiv.org/abs/2507.03620", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本研究探讨了使用DSPy（声明式自改进Python）框架通过编程方式创建和优化提示，应用于五个用例，展示了提示优化对大型语言模型性能的影响。", "motivation": "尽管提示工程对于释放大型语言模型（LLMs）的全部潜力至关重要，但制作有效的提示仍然是一个依赖人类直觉的耗时试错过程。", "method": "使用DSPy框架，通过编程方式创建和优化提示，应用于五个不同的用例，包括护栏执行、代码中的幻觉检测、代码生成、路由代理和提示评估。", "result": "在某些用例中展示了适度的改进，如护栏用例中的小幅度提升和幻觉检测中的选择性增强；而在其他用例中显示出显著的好处，如提示评估标准任务的准确率从46.2%提高到64.0%。路由代理案例中，优化提示将准确率从85.0%提高到90.0%，但使用优化提示与更便宜的模型并未提高性能。", "conclusion": "研究结果表明，DSPy的系统提示优化可以增强LLM性能，特别是在指令调整和示例选择一起优化时。然而，影响因任务而异，突出了在提示优化研究中评估特定用例的重要性。"}}
{"id": "2507.04047", "title": "Move to Understand a 3D Scene: Bridging Visual Grounding and Exploration for Efficient and Versatile Embodied Navigation", "authors": ["Ziyu Zhu", "Xilin Wang", "Yixuan Li", "Zhuofan Zhang", "Xiaojian Ma", "Yixin Chen", "Baoxiong Jia", "Wei Liang", "Qian Yu", "Zhidong Deng", "Siyuan Huang", "Qing Li"], "abstract": "Embodied scene understanding requires not only comprehending visual-spatial information that has been observed but also determining where to explore next in the 3D physical world. Existing 3D Vision-Language (3D-VL) models primarily focus on grounding objects in static observations from 3D reconstruction, such as meshes and point clouds, but lack the ability to actively perceive and explore their environment. To address this limitation, we introduce \\underline{\\textbf{M}}ove \\underline{\\textbf{t}}o \\underline{\\textbf{U}}nderstand (\\textbf{\\model}), a unified framework that integrates active perception with \\underline{\\textbf{3D}} vision-language learning, enabling embodied agents to effectively explore and understand their environment. This is achieved by three key innovations: 1) Online query-based representation learning, enabling direct spatial memory construction from RGB-D frames, eliminating the need for explicit 3D reconstruction. 2) A unified objective for grounding and exploring, which represents unexplored locations as frontier queries and jointly optimizes object grounding and frontier selection. 3) End-to-end trajectory learning that combines \\textbf{V}ision-\\textbf{L}anguage-\\textbf{E}xploration pre-training over a million diverse trajectories collected from both simulated and real-world RGB-D sequences. Extensive evaluations across various embodied navigation and question-answering benchmarks show that MTU3D outperforms state-of-the-art reinforcement learning and modular navigation approaches by 14\\%, 23\\%, 9\\%, and 2\\% in success rate on HM3D-OVON, GOAT-Bench, SG3D, and A-EQA, respectively. \\model's versatility enables navigation using diverse input modalities, including categories, language descriptions, and reference images. These findings highlight the importance of bridging visual grounding and exploration for embodied intelligence.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "Embodied AI; 3D Vision Language Understanding", "pdf_url": "https://arxiv.org/pdf/2507.04047.pdf", "abstract_url": "https://arxiv.org/abs/2507.04047", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了MTU3D，一个将主动感知与3D视觉语言学习相结合的统一框架，旨在通过创新的在线查询表示学习、统一的目标和端到端轨迹学习，提升具身智能在3D场景中的探索和理解能力。", "motivation": "解决现有3D视觉语言模型在主动感知和探索环境方面的不足，提升具身智能在3D物理世界中的理解和导航效率。", "method": "提出了MTU3D框架，包括在线查询表示学习、统一的对象定位和前沿探索目标，以及基于模拟和真实世界RGB-D序列的端到端轨迹学习。", "result": "MTU3D在多个具身导航和问答基准测试中，比最先进的强化学习和模块化导航方法的成功率高出14%到23%。", "conclusion": "通过桥接视觉定位和探索，MTU3D展示了提升具身智能在多样输入模态下导航能力的潜力，强调了这种结合的重要性。"}}
{"id": "2507.04049", "title": "Breaking Imitation Bottlenecks: Reinforced Diffusion Powers Diverse Trajectory Generation", "authors": ["Ziying Song", "Lin Liu", "Hongyu Pan", "Bencheng Liao", "Mingzhe Guo", "Lei Yang", "Yongchang Zhang", "Shaoqing Xu", "Caiyan Jia", "Yadan Luo"], "abstract": "Most end-to-end autonomous driving methods rely on imitation learning from single expert demonstrations, often leading to conservative and homogeneous behaviors that limit generalization in complex real-world scenarios. In this work, we propose DIVER, an end-to-end driving framework that integrates reinforcement learning with diffusion-based generation to produce diverse and feasible trajectories. At the core of DIVER lies a reinforced diffusion-based generation mechanism. First, the model conditions on map elements and surrounding agents to generate multiple reference trajectories from a single ground-truth trajectory, alleviating the limitations of imitation learning that arise from relying solely on single expert demonstrations. Second, reinforcement learning is employed to guide the diffusion process, where reward-based supervision enforces safety and diversity constraints on the generated trajectories, thereby enhancing their practicality and generalization capability. Furthermore, to address the limitations of L2-based open-loop metrics in capturing trajectory diversity, we propose a novel Diversity metric to evaluate the diversity of multi-mode", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)", "comments": "16 pages, 6 figures", "pdf_url": "https://arxiv.org/pdf/2507.04049.pdf", "abstract_url": "https://arxiv.org/abs/2507.04049", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出DIVER，一个结合强化学习和基于扩散的生成的端到端驾驶框架，旨在生成多样且可行的轨迹，以解决传统模仿学习导致的保守和单一行为问题。", "motivation": "解决传统端到端自动驾驶方法因依赖单一专家演示而导致的保守和同质化行为，限制在复杂现实场景中的泛化能力。", "method": "结合强化学习和基于扩散的生成机制，首先基于地图元素和周围代理生成多个参考轨迹，然后利用强化学习指导扩散过程，通过奖励监督增强轨迹的安全性和多样性。", "result": "提出的DIVER框架能够生成多样且可行的轨迹，提高了自动驾驶系统在复杂场景中的实用性和泛化能力。", "conclusion": "通过结合强化学习和基于扩散的生成，DIVER框架有效地解决了模仿学习的局限性，为自动驾驶领域提供了一种新的轨迹生成方法。"}}
{"id": "2507.04377", "title": "Multi-Modal Semantic Parsing for the Interpretation of Tombstone Inscriptions", "authors": ["Xiao Zhang", "Johan Bos"], "abstract": "Tombstones are historically and culturally rich artifacts, encapsulating individual lives, community memory, historical narratives and artistic expression. Yet, many tombstones today face significant preservation challenges, including physical erosion, vandalism, environmental degradation, and political shifts. In this paper, we introduce a novel multi-modal framework for tombstones digitization, aiming to improve the interpretation, organization and retrieval of tombstone content. Our approach leverages vision-language models (VLMs) to translate tombstone images into structured Tombstone Meaning Representations (TMRs), capturing both image and text information. To further enrich semantic parsing, we incorporate retrieval-augmented generation (RAG) for integrate externally dependent elements such as toponyms, occupation codes, and ontological concepts. Compared to traditional OCR-based pipelines, our method improves parsing accuracy from an F1 score of 36.1 to 89.5. We additionally evaluate the model's robustness across diverse linguistic and cultural inscriptions, and simulate physical degradation through image fusion to assess performance under noisy or damaged conditions. Our work represents the first attempt to formalize tombstone understanding using large vision-language models, presenting implications for heritage preservation.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL); Multimedia (cs.MM)", "comments": "Accepted by ACMMM 2025", "pdf_url": "https://arxiv.org/pdf/2507.04377.pdf", "abstract_url": "https://arxiv.org/abs/2507.04377", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Computation and Language (cs.CL)", "Multimedia (cs.MM)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了一种新颖的多模态框架，用于墓碑数字化，旨在改善墓碑内容的解释、组织和检索。该方法利用视觉语言模型（VLMs）将墓碑图像转换为结构化的墓碑意义表示（TMRs），并整合检索增强生成（RAG）以丰富语义解析。与传统OCR方法相比，该方法将解析准确率从F1分数36.1提高到89.5。", "motivation": "墓碑作为历史和文化遗产，面临着物理侵蚀、破坏、环境退化和政治变迁等保护挑战。本文旨在通过数字化手段改善墓碑内容的解释、组织和检索。", "method": "采用视觉语言模型（VLMs）将墓碑图像转换为结构化的墓碑意义表示（TMRs），并结合检索增强生成（RAG）整合外部依赖元素，如地名、职业代码和本体概念。", "result": "与传统OCR方法相比，该方法将解析准确率从F1分数36.1提高到89.5，并在多样化的语言和文化碑文上表现出鲁棒性。", "conclusion": "本文首次尝试使用大型视觉语言模型形式化墓碑理解，为文化遗产保护提供了新的可能性。"}}
{"id": "2507.02969", "title": "Reinforcement Learning for Automated Cybersecurity Penetration Testing", "authors": ["Daniel López-Montero", "José L. Álvarez-Aldana", "Alicia Morales-Martínez", "Marta Gil-López", "Juan M. Auñón García"], "abstract": "This paper aims to provide an innovative machine learning-based solution to automate security testing tasks for web applications, ensuring the correct functioning of all components while reducing project maintenance costs. Reinforcement Learning is proposed to select and prioritize tools and optimize the testing path. The presented approach utilizes a simulated webpage along with its network topology to train the agent. Additionally, the model leverages Geometric Deep Learning to create priors that reduce the search space and improve learning convergence. The validation and testing process was conducted on real-world vulnerable web pages commonly used by human hackers for learning. As a result of this study, a reinforcement learning algorithm was developed that maximizes the number of vulnerabilities found while minimizing the number of steps required", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.02969.pdf", "abstract_url": "https://arxiv.org/abs/2507.02969", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于强化学习的创新机器学习解决方案，用于自动化Web应用程序的安全测试任务，旨在确保所有组件的正确功能同时降低项目维护成本。", "motivation": "解决Web应用程序安全测试的自动化问题，以减少人工干预和成本，同时提高测试效率和效果。", "method": "采用强化学习来选择并优先排序工具及优化测试路径，利用模拟网页及其网络拓扑训练代理，并结合几何深度学习创建先验以减少搜索空间并改善学习收敛。", "result": "开发了一种强化学习算法，该算法在真实世界易受攻击的网页上验证，能够最大化发现的漏洞数量同时最小化所需步骤。", "conclusion": "研究表明，强化学习可以有效自动化网络安全渗透测试，提高发现漏洞的效率，为自动化安全测试提供了新的可能性。"}}
{"id": "2507.04590", "title": "VLM2Vec-V2: Advancing Multimodal Embedding for Videos, Images, and Visual Documents", "authors": ["Rui Meng", "Ziyan Jiang", "Ye Liu", "Mingyi Su", "Xinyi Yang", "Yuepeng Fu", "Can Qin", "Zeyuan Chen", "Ran Xu", "Caiming Xiong", "Yingbo Zhou", "Wenhu Chen", "Semih Yavuz"], "abstract": "Multimodal embedding models have been crucial in enabling various downstream tasks such as semantic similarity, information retrieval, and clustering over different modalities. However, existing multimodal embeddings like VLM2Vec, E5-V, GME are predominantly focused on natural images, with limited support for other visual forms such as videos and visual documents. This restricts their applicability in real-world scenarios, including AI agents, multi-modal search and recommendation, and retrieval-augmented generation (RAG). To close this gap, we propose VLM2Vec-V2, a unified framework for learning embeddings across diverse visual forms. First, we introduce MMEB-V2, a comprehensive benchmark that extends MMEB with five new task types: visual document retrieval, video retrieval, temporal grounding, video classification and video question answering - spanning text, image, video, and visual document inputs. Next, we train VLM2Vec-V2, a general-purpose embedding model that supports text, image, video, and visual document inputs. Extensive experiments show that VLM2Vec-V2 achieves strong performance not only on the newly introduced video and document retrieval tasks, but also improves over prior baselines on the original image benchmarks. Through extensive evaluation, our study offers insights into the generalizability of various multimodal embedding models and highlights effective strategies for unified embedding learning, laying the groundwork for more scalable and adaptable representation learning in both research and real-world settings.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL)", "comments": "Technical Report", "pdf_url": "https://arxiv.org/pdf/2507.04590.pdf", "abstract_url": "https://arxiv.org/abs/2507.04590", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "VLM2Vec-V2是一个统一的多模态嵌入框架，旨在解决现有模型主要关注自然图像而忽视视频和视觉文档的问题。通过引入MMEB-V2基准和训练VLM2Vec-V2模型，该研究在多种视觉形式的嵌入学习上取得了显著进展。", "motivation": "现有的多模态嵌入模型如VLM2Vec、E5-V、GME主要针对自然图像，对其他视觉形式如视频和视觉文档的支持有限，这限制了它们在AI代理、多模态搜索和推荐以及检索增强生成（RAG）等实际场景中的应用。", "method": "研究首先引入了MMEB-V2基准，扩展了MMEB，增加了五种新的任务类型：视觉文档检索、视频检索、时间定位、视频分类和视频问答。然后，训练了VLM2Vec-V2，一个支持文本、图像、视频和视觉文档输入的通用嵌入模型。", "result": "大量实验表明，VLM2Vec-V2不仅在新增的视频和文档检索任务上表现强劲，而且在原始图像基准上也优于之前的基线模型。", "conclusion": "该研究为多模态嵌入模型的通用性提供了见解，并突出了统一嵌入学习的有效策略，为研究和实际应用中更可扩展和适应性强的表示学习奠定了基础。"}}
{"id": "2507.04410", "title": "Multimedia Verification Through Multi-Agent Deep Research Multimodal Large Language Models", "authors": ["Huy Hoan Le", "Van Sy Thinh Nguyen", "Thi Le Chi Dang", "Vo Thanh Khang Nguyen", "Truong Thanh Hung Nguyen", "Hung Cao"], "abstract": "This paper presents our submission to the ACMMM25 - Grand Challenge on Multimedia Verification. We developed a multi-agent verification system that combines Multimodal Large Language Models (MLLMs) with specialized verification tools to detect multimedia misinformation. Our system operates through six stages: raw data processing, planning, information extraction, deep research, evidence collection, and report generation. The core Deep Researcher Agent employs four tools: reverse image search, metadata analysis, fact-checking databases, and verified news processing that extracts spatial, temporal, attribution, and motivational context. We demonstrate our approach on a challenge dataset sample involving complex multimedia content. Our system successfully verified content authenticity, extracted precise geolocation and timing information, and traced source attribution across multiple platforms, effectively addressing real-world multimedia verification scenarios.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": "33rd ACM International Conference on Multimedia (MM'25) Grand Challenge on Multimedia Verification", "pdf_url": "https://arxiv.org/pdf/2507.04410.pdf", "abstract_url": "https://arxiv.org/abs/2507.04410", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了提交给ACMMM25 - 多媒体验证大挑战的作品，一个结合多模态大型语言模型（MLLMs）和专门验证工具的多代理验证系统，用于检测多媒体错误信息。", "motivation": "解决多媒体错误信息的检测问题，特别是在复杂多媒体内容中验证内容的真实性、提取精确的地理位置和时间信息，以及追踪来源归属。", "method": "开发了一个多代理验证系统，通过六个阶段操作：原始数据处理、规划、信息提取、深度研究、证据收集和报告生成。核心深度研究代理使用了四种工具：反向图像搜索、元数据分析、事实检查数据库和经过验证的新闻处理。", "result": "系统成功验证了内容的真实性，提取了精确的地理位置和时间信息，并在多个平台上追踪了来源归属，有效应对了现实世界中的多媒体验证场景。", "conclusion": "提出的多代理验证系统结合MLLMs和专门验证工具，能够有效检测和验证多媒体错误信息，为现实世界中的多媒体验证提供了有效的解决方案。"}}
{"id": "2507.03026", "title": "Generalized Adaptive Transfer Network: Enhancing Transfer Learning in Reinforcement Learning Across Domains", "authors": ["Abhishek Verma", "Nallarasan V", "Balaraman Ravindran"], "abstract": "Transfer learning in Reinforcement Learning (RL) enables agents to leverage knowledge from source tasks to accelerate learning in target tasks. While prior work, such as the Attend, Adapt, and Transfer (A2T) framework, addresses negative transfer and selective transfer, other critical challenges remain underexplored. This paper introduces the Generalized Adaptive Transfer Network (GATN), a deep RL architecture designed to tackle task generalization across domains, robustness to environmental changes, and computational efficiency in transfer. GATN employs a domain-agnostic representation module, a robustness-aware policy adapter, and an efficient transfer scheduler to achieve these goals. We evaluate GATN on diverse benchmarks, including Atari 2600, MuJoCo, and a custom chatbot dialogue environment, demonstrating superior performance in cross-domain generalization, resilience to dynamic environments, and reduced computational overhead compared to baselines. Our findings suggest GATN is a versatile framework for real-world RL applications, such as adaptive chatbots and robotic control.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.03026.pdf", "abstract_url": "https://arxiv.org/abs/2507.03026", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了广义自适应转移网络（GATN），一种深度强化学习架构，旨在解决跨领域任务泛化、环境变化的鲁棒性以及转移中的计算效率问题。GATN通过领域无关表示模块、鲁棒性感知策略适配器和高效转移调度器实现这些目标。在Atari 2600、MuJoCo和自定义聊天机器人对话环境等多种基准测试中，GATN展示了在跨领域泛化、动态环境适应性和减少计算开销方面的优越性能。", "motivation": "强化学习中的迁移学习使代理能够利用源任务的知识加速目标任务的学习。尽管先前的工作如A2T框架解决了负迁移和选择性迁移问题，但其他关键挑战仍未得到充分探索。", "method": "GATN采用领域无关表示模块、鲁棒性感知策略适配器和高效转移调度器，以实现在跨领域任务泛化、环境变化的鲁棒性以及计算效率方面的目标。", "result": "在Atari 2600、MuJoCo和自定义聊天机器人对话环境等多种基准测试中，GATN在跨领域泛化、动态环境适应性和减少计算开销方面表现出优于基线的性能。", "conclusion": "研究结果表明，GATN是一个适用于现实世界强化学习应用（如自适应聊天机器人和机器人控制）的通用框架。"}}
{"id": "2507.04996", "title": "From Autonomy to Agency: Agentic Vehicles for Human-Centered Mobility Systems", "authors": ["Jiangbo Yu"], "abstract": "Autonomy, from the Greek autos (self) and nomos (law), refers to the capacity to operate according to internal rules without external control. Accordingly, autonomous vehicles (AuVs) are defined as systems capable of perceiving their environment and executing preprogrammed tasks independently of external input. However, both research and real-world deployments increasingly showcase vehicles that demonstrate behaviors beyond this definition (including the SAE levels 1 to 6), such as interaction with humans and machines, goal adaptation, contextual reasoning, external tool use, and long-term planning, particularly with the integration of large language models (LLMs) and agentic AI systems. These developments reveal a conceptual gap between technical autonomy and the broader cognitive and social capabilities needed for future human-centered mobility systems. To address this, we introduce the concept of agentic vehicles (AgVs), referring to vehicles that integrate agentic AI to reason, adapt, and interact within complex environments. This paper presents a systems-level framework to characterize AgVs, focusing on their cognitive and communicative layers and differentiating them from conventional AuVs. It synthesizes relevant advances in agentic AI, robotics, multi-agent systems, and human-machine interaction, and highlights how agentic AI, through high-level reasoning and tool use, can function not merely as computational tools but as interactive agents embedded in mobility ecosystems. The paper concludes by identifying key challenges in the development and governance of AgVs, including safety, real-time control, public acceptance, ethical alignment, and regulatory frameworks.", "subjects": "Computers and Society (cs.CY); Computational Engineering, Finance, and Science (cs.CE); Computation and Language (cs.CL); Human-Computer Interaction (cs.HC); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.04996.pdf", "abstract_url": "https://arxiv.org/abs/2507.04996", "categories": ["Computers and Society (cs.CY)", "Computational Engineering, Finance, and Science (cs.CE)", "Computation and Language (cs.CL)", "Human-Computer Interaction (cs.HC)", "Robotics (cs.RO)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了从自主性到代理性的转变，提出了代理性车辆（AgVs）的概念，以区别于传统的自主车辆（AuVs），并探讨了其在未来以人为中心的移动系统中的应用。", "motivation": "解决自主车辆（AuVs）在认知和社会能力方面的概念差距，以适应未来复杂环境中的人机交互和移动需求。", "method": "提出了一个系统级框架来表征代理性车辆（AgVs），重点关注其认知和通信层，并综合了代理性AI、机器人技术、多代理系统和人机交互的相关进展。", "result": "代理性AI通过高级推理和工具使用，可以作为嵌入移动生态系统中的交互代理，而不仅仅是计算工具。", "conclusion": "开发和管理代理性车辆（AgVs）面临的主要挑战包括安全性、实时控制、公众接受度、伦理对齐和监管框架。"}}
{"id": "2507.04522", "title": "Grounded Gesture Generation: Language, Motion, and Space", "authors": ["Anna Deichler", "Jim O'Regan", "Teo Guichoux", "David Johansson", "Jonas Beskow"], "abstract": "Human motion generation has advanced rapidly in recent years, yet the critical problem of creating spatially grounded, context-aware gestures has been largely overlooked. Existing models typically specialize either in descriptive motion generation, such as locomotion and object interaction, or in isolated co-speech gesture synthesis aligned with utterance semantics. However, both lines of work often treat motion and environmental grounding separately, limiting advances toward embodied, communicative agents. To address this gap, our work introduces a multimodal dataset and framework for grounded gesture generation, combining two key resources: (1) a synthetic dataset of spatially grounded referential gestures, and (2) MM-Conv, a VR-based dataset capturing two-party dialogues. Together, they provide over 7.7 hours of synchronized motion, speech, and 3D scene information, standardized in the HumanML3D format. Our framework further connects to a physics-based simulator, enabling synthetic data generation and situated evaluation. By bridging gesture modeling and spatial grounding, our contribution establishes a foundation for advancing research in situated gesture generation and grounded multimodal interaction.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2507.04522.pdf", "abstract_url": "https://arxiv.org/abs/2507.04522", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一种多模态数据集和框架，用于生成基于空间的、上下文感知的手势，结合了合成数据集和VR对话数据集，为情境手势生成和多模态交互研究奠定了基础。", "motivation": "解决现有模型在生成空间基础和上下文感知手势方面的不足，推动具身交流代理的发展。", "method": "结合合成空间基础参考手势数据集和基于VR的双方对话数据集，使用HumanML3D格式标准化，并连接到物理模拟器进行合成数据生成和情境评估。", "result": "提供了超过7.7小时的同步运动、语音和3D场景信息，为情境手势生成和多模态交互研究提供了资源。", "conclusion": "通过桥接手势建模和空间基础，本研究为情境手势生成和基础多模态交互的研究奠定了基础。"}}
{"id": "2507.05169", "title": "Critiques of World Models", "authors": ["Eric Xing", "Mingkai Deng", "Jinyu Hou", "Zhiting Hu"], "abstract": "World Model, the supposed algorithmic surrogate of the real-world environment which biological agents experience with and act upon, has been an emerging topic in recent years because of the rising needs to develop virtual agents with artificial (general) intelligence. There has been much debate on what a world model really is, how to build it, how to use it, and how to evaluate it. In this essay, starting from the imagination in the famed Sci-Fi classic Dune, and drawing inspiration from the concept of \"hypothetical thinking\" in psychology literature, we offer critiques of several schools of thoughts on world modeling, and argue the primary goal of a world model to be simulating all actionable possibilities of the real world for purposeful reasoning and acting. Building on the critiques, we propose a new architecture for a general-purpose world model, based on hierarchical, multi-level, and mixed continuous/discrete representations, and a generative and self-supervision learning framework, with an outlook of a Physical, Agentic, and Nested (PAN) AGI system enabled by such a model.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.05169.pdf", "abstract_url": "https://arxiv.org/abs/2507.05169", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Computer Vision and Pattern Recognition (cs.CV)", "Robotics (cs.RO)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文从科幻经典《沙丘》中的想象出发，结合心理学文献中的“假设性思维”概念，对世界模型的几种思想流派提出了批评，并主张世界模型的主要目标应为模拟现实世界中所有可操作的的可能性，以进行有目的推理和行动。基于这些批评，作者提出了一种新的通用世界模型架构，该架构基于分层、多级和混合连续/离散表示，以及生成和自我监督学习框架，并展望了由这种模型实现的物理、代理和嵌套（PAN）AGI系统。", "motivation": "解决关于世界模型定义、构建、使用和评估的争议，提出世界模型的主要目标应为模拟现实世界中所有可操作的的可能性，以进行有目的推理和行动。", "method": "从科幻经典《沙丘》中的想象出发，结合心理学文献中的“假设性思维”概念，对世界模型的几种思想流派提出了批评，并提出了一种新的通用世界模型架构。", "result": "提出了一种基于分层、多级和混合连续/离散表示，以及生成和自我监督学习框架的通用世界模型架构。", "conclusion": "展望了由这种模型实现的物理、代理和嵌套（PAN）AGI系统，为未来的人工通用智能发展提供了新的思路。"}}
{"id": "2507.04634", "title": "LTMSformer: A Local Trend-Aware Attention and Motion State Encoding Transformer for Multi-Agent Trajectory Prediction", "authors": ["Yixin Yan", "Yang Li", "Yuanfan Wang", "Xiaozhou Zhou", "Beihao Xia", "Manjiang Hu", "Hongmao Qin"], "abstract": "It has been challenging to model the complex temporal-spatial dependencies between agents for trajectory prediction. As each state of an agent is closely related to the states of adjacent time steps, capturing the local temporal dependency is beneficial for prediction, while most studies often overlook it. Besides, learning the high-order motion state attributes is expected to enhance spatial interaction modeling, but it is rarely seen in previous works. To address this, we propose a lightweight framework, LTMSformer, to extract temporal-spatial interaction features for multi-modal trajectory prediction. Specifically, we introduce a Local Trend-Aware Attention mechanism to capture the local temporal dependency by leveraging a convolutional attention mechanism with hierarchical local time boxes. Next, to model the spatial interaction dependency, we build a Motion State Encoder to incorporate high-order motion state attributes, such as acceleration, jerk, heading, etc. To further refine the trajectory prediction, we propose a Lightweight Proposal Refinement Module that leverages Multi-Layer Perceptrons for trajectory embedding and generates the refined trajectories with fewer model parameters. Experiment results on the Argoverse 1 dataset demonstrate that our method outperforms the baseline HiVT-64, reducing the minADE by approximately 4.35%, the minFDE by 8.74%, and the MR by 20%. We also achieve higher accuracy than HiVT-128 with a 68% reduction in model size.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.04634.pdf", "abstract_url": "https://arxiv.org/abs/2507.04634", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "LTMSformer是一个轻量级框架，用于多智能体轨迹预测，通过局部趋势感知注意力和运动状态编码Transformer来提取时空交互特征，显著提高了预测准确性并减少了模型大小。", "motivation": "解决在多智能体轨迹预测中建模复杂时空依赖关系的挑战，特别是局部时间依赖和高阶运动状态属性的学习问题。", "method": "提出LTMSformer框架，包括局部趋势感知注意力机制捕获局部时间依赖，运动状态编码器建模空间交互依赖，以及轻量级提案细化模块优化轨迹预测。", "result": "在Argoverse 1数据集上，该方法优于基线HiVT-64，minADE降低约4.35%，minFDE降低8.74%，MR降低20%，且模型大小减少68%。", "conclusion": "LTMSformer通过有效捕获局部时间依赖和高阶运动状态属性，显著提升了多智能体轨迹预测的准确性和效率，为相关领域提供了新的解决方案。"}}
{"id": "2507.04762", "title": "Robustifying 3D Perception through Least-Squares Multi-Agent Graphs Object Tracking", "authors": ["Maria Damanaki", "Ioulia Kapsali", "Nikos Piperigkos", "Alexandros Gkillas", "Aris S. Lalos"], "abstract": "The critical perception capabilities of EdgeAI systems, such as autonomous vehicles, are required to be resilient against adversarial threats, by enabling accurate identification and localization of multiple objects in the scene over time, mitigating their impact. Single-agent tracking offers resilience to adversarial attacks but lacks situational awareness, underscoring the need for multi-agent cooperation to enhance context understanding and robustness. This paper proposes a novel mitigation framework on 3D LiDAR scene against adversarial noise by tracking objects based on least-squares graph on multi-agent adversarial bounding boxes. Specifically, we employ the least-squares graph tool to reduce the induced positional error of each detection's centroid utilizing overlapped bounding boxes on a fully connected graph via differential coordinates and anchor points. Hence, the multi-vehicle detections are fused and refined mitigating the adversarial impact, and associated with existing tracks in two stages performing tracking to further suppress the adversarial threat. An extensive evaluation study on the real-world V2V4Real dataset demonstrates that the proposed method significantly outperforms both state-of-the-art single and multi-agent tracking frameworks by up to 23.3% under challenging adversarial conditions, operating as a resilient approach without relying on additional defense mechanisms.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "6 pages, 3 figures, 4 tables", "pdf_url": "https://arxiv.org/pdf/2507.04762.pdf", "abstract_url": "https://arxiv.org/abs/2507.04762", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新颖的3D LiDAR场景对抗噪声缓解框架，通过基于最小二乘图的多智能体对抗边界框跟踪对象，增强EdgeAI系统的感知能力。", "motivation": "解决EdgeAI系统（如自动驾驶车辆）在对抗性威胁下的脆弱性问题，通过多智能体合作提高场景理解和鲁棒性。", "method": "采用最小二乘图工具，通过差分坐标和锚点在全连接图上利用重叠边界框减少每个检测质心的位置误差，进而融合和精炼多车辆检测。", "result": "在真实世界V2V4Real数据集上的广泛评估表明，该方法在挑战性对抗条件下显著优于现有单智能体和多智能体跟踪框架，性能提升高达23.3%。", "conclusion": "该方法作为一种弹性方法，在不依赖额外防御机制的情况下，有效抑制了对抗性威胁，为3D感知提供了强大的鲁棒性。"}}
{"id": "2507.03279", "title": "Conformal Information Pursuit for Interactively Guiding Large Language Models", "authors": ["Kwan Ho Ryan Chan", "Yuyan Ge", "Edgar Dobriban", "Hamed Hassani", "René Vidal"], "abstract": "A significant use case of instruction-finetuned Large Language Models (LLMs) is to solve question-answering tasks interactively. In this setting, an LLM agent is tasked with making a prediction by sequentially querying relevant information from the user, as opposed to a single-turn conversation. This paper explores sequential querying strategies that aim to minimize the expected number of queries. One such strategy is Information Pursuit (IP), a greedy algorithm that at each iteration selects the query that maximizes information gain or equivalently minimizes uncertainty. However, obtaining accurate estimates of mutual information or conditional entropy for LLMs is very difficult in practice due to over- or under-confident LLM probabilities, which leads to suboptimal query selection and predictive performance. To better estimate the uncertainty at each iteration, we propose Conformal Information Pursuit (C-IP), an alternative approach to sequential information gain based on conformal prediction sets. More specifically, C-IP leverages a relationship between prediction sets and conditional entropy at each iteration to estimate uncertainty based on the average size of conformal prediction sets. In contrast to conditional entropy, we find that conformal prediction sets are a distribution-free and robust method of measuring uncertainty. Experiments with 20 Questions show that C-IP obtains better predictive performance and shorter query-answer chains compared to previous approaches to IP and uncertainty-based chain-of-thought methods. Furthermore, extending to an interactive medical setting between a doctor and a patient on the MediQ dataset, C-IP achieves competitive performance with direct single-turn prediction while offering greater interpretability.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.03279.pdf", "abstract_url": "https://arxiv.org/abs/2507.03279", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Machine Learning (stat.ML)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了如何通过顺序查询策略最小化查询次数，提出了Conformal Information Pursuit (C-IP)方法，利用共形预测集来估计不确定性，提高了预测性能和查询效率。", "motivation": "解决在使用大型语言模型(LLMs)进行交互式问答任务时，由于概率估计不准确导致的查询选择次优和预测性能下降的问题。", "method": "提出了Conformal Information Pursuit (C-IP)方法，该方法基于共形预测集来估计每次迭代中的不确定性，而不是直接计算互信息或条件熵。", "result": "在20 Questions实验中，C-IP相比之前的方法获得了更好的预测性能和更短的查询-回答链。在MediQ数据集上的交互式医疗设置中，C-IP在保持竞争力的同时提供了更高的可解释性。", "conclusion": "C-IP作为一种分布自由且鲁棒的不确定性测量方法，能够有效指导大型语言模型的交互式问答任务，提高预测性能和查询效率。"}}
{"id": "2507.03498", "title": "Reinforcement Learning-based Feature Generation Algorithm for Scientific Data", "authors": ["Meng Xiao", "Junfeng Zhou", "Yuanchun Zhou"], "abstract": "Feature generation (FG) aims to enhance the prediction potential of original data by constructing high-order feature combinations and removing redundant features. It is a key preprocessing step for tabular scientific data to improve downstream machine-learning model performance. Traditional methods face the following two challenges when dealing with the feature generation of scientific data: First, the effective construction of high-order feature combinations in scientific data necessitates profound and extensive domain-specific expertise. Secondly, as the order of feature combinations increases, the search space expands exponentially, imposing prohibitive human labor consumption. Advancements in the Data-Centric Artificial Intelligence (DCAI) paradigm have opened novel avenues for automating feature generation processes. Inspired by that, this paper revisits the conventional feature generation workflow and proposes the Multi-agent Feature Generation (MAFG) framework. Specifically, in the iterative exploration stage, multi-agents will construct mathematical transformation equations collaboratively, synthesize and identify feature combinations ex-hibiting high information content, and leverage a reinforcement learning mechanism to evolve their strategies. Upon completing the exploration phase, MAFG integrates the large language models (LLMs) to interpreta-tively evaluate the generated features of each significant model performance breakthrough. Experimental results and case studies consistently demonstrate that the MAFG framework effectively automates the feature generation process and significantly enhances various downstream scientific data mining tasks.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "12 pages, in Chinese language, accepted by JCRD", "pdf_url": "https://arxiv.org/pdf/2507.03498.pdf", "abstract_url": "https://arxiv.org/abs/2507.03498", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于强化学习的多智能体特征生成（MAFG）框架，旨在自动化科学数据的特征生成过程，通过多智能体协作构建数学变换方程，利用强化学习机制优化策略，并结合大型语言模型（LLMs）对生成特征进行解释性评估，显著提升了下游科学数据挖掘任务的性能。", "motivation": "解决科学数据特征生成中需要深厚领域知识和高阶特征组合搜索空间大的问题，自动化特征生成过程以减少人工劳动。", "method": "提出多智能体特征生成（MAFG）框架，包括多智能体协作构建数学变换方程、利用强化学习机制优化策略，以及结合LLMs对生成特征进行解释性评估。", "result": "实验和案例研究表明，MAFG框架有效自动化了特征生成过程，显著提升了各种下游科学数据挖掘任务的性能。", "conclusion": "MAFG框架为科学数据的特征生成提供了一种有效的自动化解决方案，通过结合多智能体协作和强化学习，显著提升了数据挖掘任务的效率和效果。"}}
{"id": "2507.05254", "title": "From Marginal to Joint Predictions: Evaluating Scene-Consistent Trajectory Prediction Approaches for Automated Driving", "authors": ["Fabian Konstantinidis", "Ariel Dallari Guerreiro", "Raphael Trumpp", "Moritz Sackmann", "Ulrich Hofmann", "Marco Caccamo", "Christoph Stiller"], "abstract": "Accurate motion prediction of surrounding traffic participants is crucial for the safe and efficient operation of automated vehicles in dynamic environments. Marginal prediction models commonly forecast each agent's future trajectories independently, often leading to sub-optimal planning decisions for an automated vehicle. In contrast, joint prediction models explicitly account for the interactions between agents, yielding socially and physically consistent predictions on a scene level. However, existing approaches differ not only in their problem formulation but also in the model architectures and implementation details used, making it difficult to compare them. In this work, we systematically investigate different approaches to joint motion prediction, including post-processing of the marginal predictions, explicitly training the model for joint predictions, and framing the problem as a generative task. We evaluate each approach in terms of prediction accuracy, multi-modality, and inference efficiency, offering a comprehensive analysis of the strengths and limitations of each approach. Several prediction examples are available at", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multiagent Systems (cs.MA); Robotics (cs.RO)", "comments": "Accepted at International Conference on Intelligent Transportation Systems 2025 (ITSC 2025)", "pdf_url": "https://arxiv.org/pdf/2507.05254.pdf", "abstract_url": "https://arxiv.org/abs/2507.05254", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文系统研究了自动驾驶中场景一致的轨迹预测方法，比较了边缘预测和联合预测模型，评估了不同方法在预测准确性、多模态性和推理效率方面的表现。", "motivation": "解决自动驾驶车辆在动态环境中对周围交通参与者运动预测的准确性问题，特别是独立预测模型导致的次优规划决策问题。", "method": "研究了联合运动预测的不同方法，包括边缘预测的后处理、明确训练联合预测模型以及将问题框架化为生成任务。", "result": "提供了每种方法在预测准确性、多模态性和推理效率方面的全面分析，揭示了各方法的优势和局限性。", "conclusion": "联合预测模型能够更准确地预测交通参与者的运动，为自动驾驶车辆的规划和决策提供了更可靠的依据。"}}
{"id": "2507.05258", "title": "Spatio-Temporal LLM: Reasoning about Environments and Actions", "authors": ["Haozhen Zheng", "Beitong Tian", "Mingyuan Wu", "Zhenggang Tang", "Klara Nahrstedt", "Alex Schwing"], "abstract": "Despite the significant recent progress of Multimodal Large Language Models (MLLMs), MLLMs still struggle to correctly answer prompts that require a holistic spatio-temporal understanding. Specifically, it is challenging to address prompts that refer to 1) the entirety of an environment that an agent equipped with an MLLM can operate in; and simultaneously also refer to 2) recent actions that just happened and are encoded in a video clip. However, such a holistic spatio-temporal understanding is important for agents operating in the real world. To address this issue, we first develop a framework to collect a large-scale dataset. Using the collected \"Reasoning about Environments and Actions\" (REA) dataset, we show that recent methods indeed struggle to correctly answer the prompts. To improve, we develop a \"spatio-temporal LLM\" (ST-LLM), a model equipped with projectors to improve both spatial understanding of an environment and temporal understanding of recent observations. On the collected REA data, we show that the proposed method significantly improves results compared to prior work. Code and data are available at", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2507.05258.pdf", "abstract_url": "https://arxiv.org/abs/2507.05258", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种时空大型语言模型（ST-LLM），旨在解决多模态大型语言模型（MLLMs）在需要整体时空理解的提示上的不足。通过开发一个框架收集大规模数据集“Reasoning about Environments and Actions”（REA），并在此基础上展示了现有方法的局限性。提出的ST-LLM模型通过改进空间环境理解和时间观察理解，显著提高了在REA数据上的表现。", "motivation": "尽管多模态大型语言模型（MLLMs）近期取得了显著进展，但在需要整体时空理解的提示上仍存在困难。这种理解对于在现实世界中操作的代理至关重要。", "method": "开发了一个框架来收集大规模数据集REA，并提出了时空大型语言模型（ST-LLM），该模型配备了投影仪以改进对环境的空间理解和对最近观察的时间理解。", "result": "在收集的REA数据上，提出的ST-LLM方法相比之前的工作显著提高了结果。", "conclusion": "ST-LLM通过改进空间和时间理解，为解决MLLMs在需要整体时空理解的提示上的不足提供了有效方法，代码和数据已公开。"}}
{"id": "2507.04053", "title": "TopoMAS: Large Language Model Driven Topological Materials Multiagent System", "authors": ["Baohua Zhang", "Xin Li", "Huangchao Xu", "Zhong Jin", "Quansheng Wu", "Ce Li"], "abstract": "Topological materials occupy a frontier in condensed-matter physics thanks to their remarkable electronic and quantum properties, yet their cross-scale design remains bottlenecked by inefficient discovery workflows. Here, we introduce TopoMAS (Topological materials Multi-Agent System), an interactive human-AI framework that seamlessly orchestrates the entire materials-discovery pipeline: from user-defined queries and multi-source data retrieval, through theoretical inference and crystal-structure generation, to first-principles validation. Crucially, TopoMAS closes the loop by autonomously integrating computational outcomes into a dynamic knowledge graph, enabling continuous knowledge refinement. In collaboration with human experts, it has already guided the identification of novel topological phases SrSbO3, confirmed by first-principles calculations. Comprehensive benchmarks demonstrate robust adaptability across base Large Language Model, with the lightweight Qwen2.5-72B model achieving 94.55% accuracy while consuming only 74.3-78.4% of tokens required by Qwen3-235B and 83.0% of DeepSeek-V3's usage--delivering responses twice as fast as Qwen3-235B. This efficiency establishes TopoMAS as an accelerator for computation-driven discovery pipelines. By harmonizing rational agent orchestration with a self-evolving knowledge graph, our framework not only delivers immediate advances in topological materials but also establishes a transferable, extensible paradigm for materials-science domain.", "subjects": "Materials Science (cond-mat.mtrl-sci); Artificial Intelligence (cs.AI)", "comments": "13 pages,7 figures,3 tables", "pdf_url": "https://arxiv.org/pdf/2507.04053.pdf", "abstract_url": "https://arxiv.org/abs/2507.04053", "categories": ["Materials Science (cond-mat.mtrl-sci)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "TopoMAS是一个由大型语言模型驱动的拓扑材料多智能体系统，旨在通过人机协作框架优化材料发现流程，从查询到验证，并通过动态知识图谱持续精炼知识。", "motivation": "解决拓扑材料跨尺度设计中发现流程效率低下的问题。", "method": "采用交互式人机框架，结合多源数据检索、理论推理、晶体结构生成和第一性原理验证，通过动态知识图谱自主整合计算结果。", "result": "TopoMAS已指导发现新的拓扑相SrSbO3，并在基准测试中显示出高效的适应性和准确性，特别是在使用轻量级Qwen2.5-72B模型时。", "conclusion": "TopoMAS不仅推动了拓扑材料的即时进展，还为材料科学领域建立了一个可转移、可扩展的范式。"}}
{"id": "2507.04055", "title": "Rethinking and Exploring String-Based Malware Family Classification in the Era of LLMs and RAG", "authors": ["Yufan Chen", "Daoyuan Wu", "Juantao Zhong", "Zicheng Zhang", "Debin Gao", "Shuai Wang", "Yingjiu Li", "Ning Liu"], "abstract": "Malware Family Classification (MFC) aims to identify the fine-grained family (e.g., GuLoader or BitRAT) to which a potential malware sample belongs, in contrast to malware detection or sample classification that predicts only an Yes/No. Accurate family identification can greatly facilitate automated sample labeling and understanding on crowdsourced malware analysis platforms such as VirusTotal and MalwareBazaar, which generate vast amounts of data daily. In this paper, we explore and assess the feasibility of using traditional binary string features for MFC in the new era of large language models (LLMs) and Retrieval-Augmented Generation (RAG). Specifically, we investigate how Family-Specific String (FSS) features could be utilized in a manner similar to RAG to facilitate MFC. To this end, we develop a curated evaluation framework covering 4,347 samples from 67 malware families, extract and analyze over 25 million strings, and conduct detailed ablation studies to assess the impact of different design choices in four major modules.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Software Engineering (cs.SE)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.04055.pdf", "abstract_url": "https://arxiv.org/abs/2507.04055", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Software Engineering (cs.SE)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文探讨了在大型语言模型（LLMs）和检索增强生成（RAG）时代，重新思考和探索基于字符串的恶意软件家族分类（MFC）的可行性。", "motivation": "恶意软件家族分类（MFC）旨在识别潜在恶意软件样本所属的细粒度家族（如GuLoader或BitRAT），这与仅预测是/否的恶意软件检测或样本分类形成对比。准确的家族识别可以极大地促进自动化样本标签和在VirusTotal和MalwareBazaar等众包恶意软件分析平台上的理解，这些平台每天生成大量数据。", "method": "本文特别研究了如何以类似于RAG的方式利用家族特定字符串（FSS）特征来促进MFC。为此，开发了一个涵盖67个恶意软件家族的4,347个样本的精心策划的评估框架，提取并分析了超过2500万条字符串，并进行了详细的消融研究，以评估四个主要模块中不同设计选择的影响。", "result": "通过详细的消融研究，评估了不同设计选择在四个主要模块中的影响。", "conclusion": "本文的研究为在LLMs和RAG的新时代使用传统二进制字符串特征进行MFC提供了新的视角和方法。"}}
{"id": "2507.04075", "title": "Accurate and Efficient World Modeling with Masked Latent Transformers", "authors": ["Maxime Burchi", "Radu Timofte"], "abstract": "The Dreamer algorithm has recently obtained remarkable performance across diverse environment domains by training powerful agents with simulated trajectories. However, the compressed nature of its world model's latent space can result in the loss of crucial information, negatively affecting the agent's performance. Recent approaches, such as $\\Delta$-IRIS and DIAMOND, address this limitation by training more accurate world models. However, these methods require training agents directly from pixels, which reduces training efficiency and prevents the agent from benefiting from the inner representations learned by the world model. In this work, we propose an alternative approach to world modeling that is both accurate and efficient. We introduce EMERALD (Efficient MaskEd latent tRAnsformer worLD model), a world model using a spatial latent state with MaskGIT predictions to generate accurate trajectories in latent space and improve the agent performance. On the Crafter benchmark, EMERALD achieves new state-of-the-art performance, becoming the first method to surpass human experts performance within 10M environment steps. Our method also succeeds to unlock all 22 Crafter achievements at least once during evaluation.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.04075.pdf", "abstract_url": "https://arxiv.org/abs/2507.04075", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了EMERALD，一种高效且准确的世界建模方法，通过使用空间潜在状态和MaskGIT预测来生成潜在空间中的准确轨迹，从而提升代理性能。在Crafter基准测试中，EMERALD实现了新的最先进性能，成为首个在1000万环境步骤内超越人类专家表现的方法。", "motivation": "解决Dreamer算法中世界模型潜在空间压缩导致信息丢失的问题，以及现有方法如Δ-IRIS和DIAMOND直接从像素训练代理导致的训练效率低下和无法利用世界模型学习的内在表示的问题。", "method": "提出EMERALD（高效掩码潜在变换器世界模型），利用空间潜在状态和MaskGIT预测在潜在空间中生成准确轨迹。", "result": "在Crafter基准测试中，EMERALD实现了新的最先进性能，成为首个在1000万环境步骤内超越人类专家表现的方法，并成功解锁了所有22个Crafter成就。", "conclusion": "EMERALD作为一种高效且准确的世界建模方法，不仅提升了代理性能，还在实际应用中展示了其卓越的能力。"}}
{"id": "2507.04227", "title": "Hijacking JARVIS: Benchmarking Mobile GUI Agents against Unprivileged Third Parties", "authors": ["Guohong Liu", "Jialei Ye", "Jiacheng Liu", "Yuanchun Li", "Wei Liu", "Pengzhi Gao", "Jian Luan", "Yunxin Liu"], "abstract": "Mobile GUI agents are designed to autonomously execute diverse device-control tasks by interpreting and interacting with mobile screens. Despite notable advancements, their resilience in real-world scenarios where screen content may be partially manipulated by untrustworthy third parties remains largely unexplored. Owing to their black-box and autonomous nature, these agents are vulnerable to manipulations that could compromise user devices. In this work, we present the first systematic investigation into the vulnerabilities of mobile GUI agents. We introduce a scalable attack simulation framework AgentHazard, which enables flexible and targeted modifications of screen content within existing applications. Leveraging this framework, we develop a comprehensive benchmark suite comprising both a dynamic task execution environment and a static dataset of vision-language-action tuples, totaling over 3,000 attack scenarios. The dynamic environment encompasses 58 reproducible tasks in an emulator with various types of hazardous UI content, while the static dataset is constructed from 210 screenshots collected from 14 popular commercial apps. Importantly, our content modifications are designed to be feasible for unprivileged third parties. We evaluate 7 widely-used mobile GUI agents and 5 common backbone models using our benchmark. Our findings reveal that all examined agents are significantly influenced by misleading third-party content (with an average misleading rate of 28.8% in human-crafted attack scenarios) and that their vulnerabilities are closely linked to the employed perception modalities and backbone LLMs. Furthermore, we assess training-based mitigation strategies, highlighting both the challenges and opportunities for enhancing the robustness of mobile GUI agents. Our code and data will be released at", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.04227.pdf", "abstract_url": "https://arxiv.org/abs/2507.04227", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文首次系统地研究了移动GUI代理在屏幕内容被不可信第三方部分操控时的脆弱性，提出了一个可扩展的攻击模拟框架AgentHazard，并开发了一个包含动态任务执行环境和静态数据集的全面基准测试套件。", "motivation": "移动GUI代理在屏幕内容可能被不可信第三方部分操控的真实场景中的韧性尚未得到充分探索，这可能导致用户设备被操控。", "method": "引入AgentHazard框架，对现有应用中的屏幕内容进行灵活和有针对性的修改，构建包含动态环境和静态数据集的基准测试套件，评估7种广泛使用的移动GUI代理和5种常见骨干模型。", "result": "研究发现所有被测试的代理都显著受到误导性第三方内容的影响（人工制作的攻击场景中平均误导率为28.8%），且其脆弱性与采用的感知模式和骨干LLM密切相关。", "conclusion": "本文不仅揭示了移动GUI代理的脆弱性，还评估了基于训练的缓解策略，为增强移动GUI代理的鲁棒性提供了挑战和机遇。"}}
{"id": "2507.04790", "title": "Interaction-Merged Motion Planning: Effectively Leveraging Diverse Motion Datasets for Robust Planning", "authors": ["Giwon Lee", "Wooseong Jeong", "Daehee Park", "Jaewoo Jeong", "Kuk-Jin Yoon"], "abstract": "Motion planning is a crucial component of autonomous robot driving. While various trajectory datasets exist, effectively utilizing them for a target domain remains challenging due to differences in agent interactions and environmental characteristics. Conventional approaches, such as domain adaptation or ensemble learning, leverage multiple source datasets but suffer from domain imbalance, catastrophic forgetting, and high computational costs. To address these challenges, we propose Interaction-Merged Motion Planning (IMMP), a novel approach that leverages parameter checkpoints trained on different domains during adaptation to the target domain. IMMP follows a two-step process: pre-merging to capture agent behaviors and interactions, sufficiently extracting diverse information from the source domain, followed by merging to construct an adaptable model that efficiently transfers diverse interactions to the target domain. Our method is evaluated on various planning benchmarks and models, demonstrating superior performance compared to conventional approaches.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "comments": "Accepted at ICCV 2025", "pdf_url": "https://arxiv.org/pdf/2507.04790.pdf", "abstract_url": "https://arxiv.org/abs/2507.04790", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为交互合并运动规划（IMMP）的新方法，旨在解决自主机器人驾驶中运动规划的挑战。IMMP通过利用在不同域上训练的参数检查点，有效地从源域提取多样信息并适应目标域，从而克服了传统方法的局限性。", "motivation": "自主机器人驾驶中的运动规划面临来自不同轨迹数据集的挑战，如代理交互和环境特性的差异。传统方法如域适应或集成学习存在域不平衡、灾难性遗忘和高计算成本等问题。", "method": "IMMP采用两步过程：预合并以捕获代理行为和交互，充分提取源域的多样信息；随后合并以构建可适应模型，有效将多样交互转移到目标域。", "result": "在各种规划基准和模型上的评估表明，IMMP相比传统方法表现出更优的性能。", "conclusion": "IMMP为自主机器人驾驶中的运动规划提供了一种高效、鲁棒的方法，能够有效利用多样化的运动数据集，克服了传统方法的不足。"}}
{"id": "2507.04356", "title": "Mission-Aligned Learning-Informed Control of Autonomous Systems: Formulation and Foundations", "authors": ["Vyacheslav Kungurtsev", "Gustav Sir", "Akhil Anand", "Sebastien Gros", "Haozhe Tian", "Homayoun Hamedmoghadam"], "abstract": "Research, innovation and practical capital investment have been increasing rapidly toward the realization of autonomous physical agents. This includes industrial and service robots, unmanned aerial vehicles, embedded control devices, and a number of other realizations of cybernetic/mechatronic implementations of intelligent autonomous devices. In this paper, we consider a stylized version of robotic care, which would normally involve a two-level Reinforcement Learning procedure that trains a policy for both lower level physical movement decisions as well as higher level conceptual tasks and their sub-components. In order to deliver greater safety and reliability in the system, we present the general formulation of this as a two-level optimization scheme which incorporates control at the lower level, and classical planning at the higher level, integrated with a capacity for learning. This synergistic integration of multiple methodologies -- control, classical planning, and RL -- presents an opportunity for greater insight for algorithm development, leading to more efficient and reliable performance. Here, the notion of reliability pertains to physical safety and interpretability into an otherwise black box operation of autonomous agents, concerning users and regulators. This work presents the necessary background and general formulation of the optimization framework, detailing each component and its integration with the others.", "subjects": "Optimization and Control (math.OC); Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.04356.pdf", "abstract_url": "https://arxiv.org/abs/2507.04356", "categories": ["Optimization and Control (math.OC)", "Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种两层次优化方案，结合控制、经典规划和强化学习，以提高自主系统的安全性和可靠性。", "motivation": "解决自主物理代理（如工业和服务机器人、无人机等）在实现过程中的安全性和可靠性问题。", "method": "采用两层次优化方案，底层进行控制，高层进行经典规划，并与学习能力相结合。", "result": "通过整合多种方法，为算法开发提供了更深入的见解，从而实现了更高效和可靠的性能。", "conclusion": "该工作为自主系统的算法开发提供了新的视角，特别是在提高物理安全性和操作可解释性方面具有重要意义。"}}
{"id": "2507.04480", "title": "Source Attribution in Retrieval-Augmented Generation", "authors": ["Ikhtiyor Nematov", "Tarik Kalai", "Elizaveta Kuzmenko", "Gabriele Fugagnoli", "Dimitris Sacharidis", "Katja Hose", "Tomer Sagi"], "abstract": "While attribution methods, such as Shapley values, are widely used to explain the importance of features or training data in traditional machine learning, their application to Large Language Models (LLMs), particularly within Retrieval-Augmented Generation (RAG) systems, is nascent and challenging. The primary obstacle is the substantial computational cost, where each utility function evaluation involves an expensive LLM call, resulting in direct monetary and time expenses. This paper investigates the feasibility and effectiveness of adapting Shapley-based attribution to identify influential retrieved documents in RAG. We compare Shapley with more computationally tractable approximations and some existing attribution methods for LLM. Our work aims to: (1) systematically apply established attribution principles to the RAG document-level setting; (2) quantify how well SHAP approximations can mirror exact attributions while minimizing costly LLM interactions; and (3) evaluate their practical explainability in identifying critical documents, especially under complex inter-document relationships such as redundancy, complementarity, and synergy. This study seeks to bridge the gap between powerful attribution techniques and the practical constraints of LLM-based RAG systems, offering insights into achieving reliable and affordable RAG explainability.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.04480.pdf", "abstract_url": "https://arxiv.org/abs/2507.04480", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文探讨了在检索增强生成（RAG）系统中应用基于Shapley值的归因方法的可行性和有效性，旨在解决计算成本高的问题，并比较了不同近似方法的性能。", "motivation": "解决在大型语言模型（LLMs）和检索增强生成（RAG）系统中应用归因方法时面临的高计算成本挑战。", "method": "比较Shapley值与计算上更易处理的近似方法以及现有的LLM归因方法，系统地将已建立的归因原则应用于RAG文档级设置。", "result": "量化了SHAP近似方法在最小化昂贵LLM交互的同时，如何准确反映精确归因，并评估了其在识别关键文档时的实际可解释性。", "conclusion": "本研究旨在弥合强大归因技术与基于LLM的RAG系统实际约束之间的差距，为实现可靠且经济的RAG可解释性提供见解。"}}
{"id": "2507.05240", "title": "StreamVLN: Streaming Vision-and-Language Navigation via SlowFast Context Modeling", "authors": ["Meng Wei", "Chenyang Wan", "Xiqian Yu", "Tai Wang", "Yuqiang Yang", "Xiaohan Mao", "Chenming Zhu", "Wenzhe Cai", "Hanqing Wang", "Yilun Chen", "Xihui Liu", "Jiangmiao Pang"], "abstract": "Vision-and-Language Navigation (VLN) in real-world settings requires agents to process continuous visual streams and generate actions with low latency grounded in language instructions. While Video-based Large Language Models (Video-LLMs) have driven recent progress, current VLN methods based on Video-LLM often face trade-offs among fine-grained visual understanding, long-term context modeling and computational efficiency. We introduce StreamVLN, a streaming VLN framework that employs a hybrid slow-fast context modeling strategy to support multi-modal reasoning over interleaved vision, language and action inputs. The fast-streaming dialogue context facilitates responsive action generation through a sliding-window of active dialogues, while the slow-updating memory context compresses historical visual states using a 3D-aware token pruning strategy. With this slow-fast design, StreamVLN achieves coherent multi-turn dialogue through efficient KV cache reuse, supporting long video streams with bounded context size and inference cost. Experiments on VLN-CE benchmarks demonstrate state-of-the-art performance with stable low latency, ensuring robustness and efficiency in real-world deployment. The project page is: \\href{", "subjects": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.05240.pdf", "abstract_url": "https://arxiv.org/abs/2507.05240", "categories": ["Robotics (cs.RO)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "StreamVLN是一个流式视觉与语言导航框架，通过慢快上下文建模策略支持多模态推理，实现了在VLN-CE基准测试中的最先进性能，同时保证了低延迟和高效性。", "motivation": "解决在现实环境中，基于视频的大型语言模型（Video-LLMs）在视觉与语言导航（VLN）中面临的细粒度视觉理解、长期上下文建模和计算效率之间的权衡问题。", "method": "采用混合慢快上下文建模策略，快速流式对话上下文通过活动对话的滑动窗口促进响应动作生成，而慢更新内存上下文使用3D感知令牌修剪策略压缩历史视觉状态。", "result": "在VLN-CE基准测试中实现了最先进的性能，同时保持了稳定的低延迟，确保了在现实世界部署中的鲁棒性和效率。", "conclusion": "StreamVLN通过其慢快设计，支持长视频流的有界上下文大小和推理成本，实现了连贯的多轮对话，为视觉与语言导航领域提供了高效且强大的解决方案。"}}
{"id": "2507.04706", "title": "UrbanMind: Towards Urban General Intelligence via Tool-Enhanced Retrieval-Augmented Generation and Multilevel Optimization", "authors": ["Kai Yang", "Zelin Zhu", "Chengtao Jian", "Hui Ma", "Shengjie Zhao", "Xiaozhou Ye", "Ye Ouyang"], "abstract": "Urban general intelligence (UGI) refers to the capacity of AI systems to autonomously perceive, reason, and act within dynamic and complex urban environments. In this paper, we introduce UrbanMind, a tool-enhanced retrieval-augmented generation (RAG) framework designed to facilitate UGI. Central to UrbanMind is a novel architecture based on Continual Retrieval-Augmented MoE-based LLM (C-RAG-LLM), which dynamically incorporates domain-specific knowledge and evolving urban data to support long-term adaptability. The architecture of C-RAG-LLM aligns naturally with a multilevel optimization framework, where different layers are treated as interdependent sub-problems. Each layer has distinct objectives and can be optimized either independently or jointly through a hierarchical learning process. The framework is highly flexible, supporting both end-to-end training and partial layer-wise optimization based on resource or deployment constraints. To remain adaptive under data drift, it is further integrated with an incremental corpus updating mechanism. Evaluations on real-world urban tasks of a variety of complexity verify the effectiveness of the proposed framework. This work presents a promising step toward the realization of general-purpose LLM agents in future urban environments.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.04706.pdf", "abstract_url": "https://arxiv.org/abs/2507.04706", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文介绍了UrbanMind，一个基于工具增强的检索增强生成（RAG）框架，旨在促进城市通用智能（UGI）。通过新颖的C-RAG-LLM架构和多级优化框架，UrbanMind能够动态整合领域特定知识和不断变化的城市数据，支持长期适应性。", "motivation": "解决AI系统在动态复杂城市环境中自主感知、推理和行动的能力问题，即城市通用智能（UGI）的实现。", "method": "采用工具增强的检索增强生成（RAG）框架和Continual Retrieval-Augmented MoE-based LLM（C-RAG-LLM）架构，结合多级优化框架和增量语料更新机制。", "result": "在多种复杂度的真实世界城市任务上的评估验证了所提出框架的有效性。", "conclusion": "这项工作为实现未来城市环境中的通用目的LLM代理迈出了有希望的一步。"}}
{"id": "2507.04917", "title": "Leadership Detection via Time-Lagged Correlation-Based Network Inference", "authors": ["Thayanne França da Silva", "José Everardo Bessa Maia"], "abstract": "Understanding leadership dynamics in collective behavior is a key challenge in animal ecology, swarm robotics, and intelligent transportation. Traditional information-theoretic approaches, including Transfer Entropy (TE) and Time-Lagged Mutual Information (TLMI), have been widely used to infer leader-follower relationships but face critical limitations in noisy or short-duration datasets due to their reliance on robust probability estimations. This study proposes a method based on dynamic network inference using time-lagged correlations across multiple kinematic variables: velocity, acceleration, and direction. Our approach constructs directed influence graphs over time, enabling the identification of leadership patterns without the need for large volumes of data or parameter-sensitive discretization. We validate our method through two multi-agent simulations in NetLogo: a modified Vicsek model with informed leaders and a predator-prey model featuring coordinated and independent wolf groups. Experimental results demonstrate that the network-based method outperforms TE and TLMI in scenarios with limited spatiotemporal observations, ranking true leaders at the top of influence metrics more consistently than TE and TLMI.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Adaptation and Self-Organizing Systems (nlin.AO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.04917.pdf", "abstract_url": "https://arxiv.org/abs/2507.04917", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Adaptation and Self-Organizing Systems (nlin.AO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于时间滞后相关性的动态网络推理方法，用于在集体行为中检测领导力，该方法通过速度、加速度和方向等多个运动学变量的时间滞后相关性构建有向影响图，从而在数据量小或噪声大的情况下有效识别领导模式。", "motivation": "解决在噪声大或数据持续时间短的情况下，传统信息论方法（如转移熵和时间滞后互信息）因依赖稳健的概率估计而难以准确推断领导者-追随者关系的问题。", "method": "使用时间滞后相关性动态网络推理方法，通过多个运动学变量构建有向影响图，无需大量数据或参数敏感的离散化。", "result": "在NetLogo中的两个多智能体模拟（修改后的Vicsek模型和捕食者-猎物模型）中验证，该方法在时空观察有限的情况下优于转移熵和时间滞后互信息，能更一致地将真实领导者排在影响力指标的顶部。", "conclusion": "基于网络的领导力检测方法在数据有限或噪声大的情况下表现更优，为动物生态学、群体机器人和智能交通等领域的领导力动态研究提供了新工具。"}}
{"id": "2507.05030", "title": "Perspectives on How Sociology Can Advance Theorizing about Human-Chatbot Interaction and Developing Chatbots for Social Good", "authors": ["Celeste Campos-Castillo", "Xuan Kang", "Linnea I. Laestadius"], "abstract": "Recently, research into chatbots (also known as conversational agents, AI agents, voice assistants), which are computer applications using artificial intelligence to mimic human-like conversation, has grown sharply. Despite this growth, sociology lags other disciplines (including computer science, medicine, psychology, and communication) in publishing about chatbots. We suggest sociology can advance understanding of human-chatbot interaction and offer four sociological theories to enhance extant work in this field. The first two theories (resource substitution theory, power-dependence theory) add new insights to existing models of the drivers of chatbot use, which overlook sociological concerns about how social structure (e.g., systemic discrimination, the uneven distribution of resources within networks) inclines individuals to use chatbots, including problematic levels of emotional dependency on chatbots. The second two theories (affect control theory, fundamental cause of disease theory) help inform the development of chatbot-driven interventions that minimize safety risks and enhance equity by leveraging sociological insights into how chatbot outputs could attend to cultural contexts (e.g., affective norms) to promote wellbeing and enhance communities (e.g., opportunities for civic participation). We discuss the value of applying sociological theories for advancing theorizing about human-chatbot interaction and developing chatbots for social good.", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.05030.pdf", "abstract_url": "https://arxiv.org/abs/2507.05030", "categories": ["Computers and Society (cs.CY)", "Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了社会学如何通过四种理论（资源替代理论、权力依赖理论、情感控制理论和疾病根本原因理论）促进对人类与聊天机器人互动的理解，并开发对社会有益的聊天机器人。", "motivation": "尽管聊天机器人研究快速增长，社会学在这一领域的研究滞后于其他学科。本文旨在填补这一空白，通过社会学理论提供新的见解。", "method": "提出了四种社会学理论，用于分析聊天机器人使用的驱动因素和开发对社会有益的聊天机器人。", "result": "社会学理论可以为聊天机器人的使用和开发提供新的视角，特别是在考虑社会结构和文化背景方面。", "conclusion": "应用社会学理论可以促进对人类与聊天机器人互动的理论化，并指导开发对社会有益的聊天机器人。"}}
{"id": "2507.04724", "title": "Who's the Mole? Modeling and Detecting Intention-Hiding Malicious Agents in LLM-Based Multi-Agent Systems", "authors": ["Yizhe Xie", "Congcong Zhu", "Xinyue Zhang", "Minghao Wang", "Chi Liu", "Minglu Zhu", "Tianqing Zhu"], "abstract": "Multi-agent systems powered by Large Language Models (LLM-MAS) demonstrate remarkable capabilities in collaborative problem-solving. While LLM-MAS exhibit strong collaborative abilities, the security risks in their communication and coordination remain underexplored. We bridge this gap by systematically investigating intention-hiding threats in LLM-MAS, and design four representative attack paradigms that subtly disrupt task completion while maintaining high concealment. These attacks are evaluated in centralized, decentralized, and layered communication structures. Experiments conducted on six benchmark datasets, including MMLU, MMLU-Pro, HumanEval, GSM8K, arithmetic, and biographies, demonstrate that they exhibit strong disruptive capabilities. To identify these threats, we propose a psychology-based detection framework AgentXposed, which combines the HEXACO personality model with the Reid Technique, using progressive questionnaire inquiries and behavior-based monitoring. Experiments conducted on six types of attacks show that our detection framework effectively identifies all types of malicious behaviors. The detection rate for our intention-hiding attacks is slightly lower than that of the two baselines, Incorrect Fact Injection and Dark Traits Injection, demonstrating the effectiveness of intention concealment. Our findings reveal the structural and behavioral risks posed by intention-hiding attacks and offer valuable insights into securing LLM-based multi-agent systems through psychological perspectives, which contributes to a deeper understanding of multi-agent safety. The code and data are available at", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.04724.pdf", "abstract_url": "https://arxiv.org/abs/2507.04724", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了基于大型语言模型的多智能体系统（LLM-MAS）中的安全风险，特别是意图隐藏的恶意行为。作者设计了四种攻击范式，并在不同通信结构中评估其破坏性。提出了一种基于心理学的检测框架AgentXposed，有效识别恶意行为。", "motivation": "尽管LLM-MAS在协作解决问题方面表现出色，但其通信和协调中的安全风险尚未充分探索。本文旨在填补这一空白，系统地研究LLM-MAS中的意图隐藏威胁。", "method": "作者设计了四种代表性的攻击范式，并在集中式、分散式和分层通信结构中进行评估。提出了一种结合HEXACO人格模型和Reid技术的心理学检测框架AgentXposed。", "result": "实验表明，这些攻击在六个基准数据集上表现出强大的破坏能力。AgentXposed框架能有效识别所有类型的恶意行为，尽管对意图隐藏攻击的检测率略低于基线。", "conclusion": "研究揭示了意图隐藏攻击带来的结构和行为风险，并通过心理学视角为保护LLM-MAS提供了宝贵见解，有助于深化对多智能体安全的理解。"}}
{"id": "2507.05093", "title": "The Hidden Threat in Plain Text: Attacking RAG Data Loaders", "authors": ["Alberto Castagnaro", "Umberto Salviati", "Mauro Conti", "Luca Pajola", "Simeone Pizzi"], "abstract": "Large Language Models (LLMs) have transformed human-machine interaction since ChatGPT's 2022 debut, with Retrieval-Augmented Generation (RAG) emerging as a key framework that enhances LLM outputs by integrating external knowledge. However, RAG's reliance on ingesting external documents introduces new vulnerabilities. This paper exposes a critical security gap at the data loading stage, where malicious actors can stealthily corrupt RAG pipelines by exploiting document ingestion.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": "currently under submission", "pdf_url": "https://arxiv.org/pdf/2507.05093.pdf", "abstract_url": "https://arxiv.org/abs/2507.05093", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文揭示了Retrieval-Augmented Generation (RAG)框架在数据加载阶段的安全漏洞，恶意行为者可通过利用文档摄入悄悄破坏RAG管道。", "motivation": "随着ChatGPT的推出，大型语言模型(LLMs)改变了人机交互方式，RAG作为增强LLM输出的关键框架，其依赖外部文档的摄入引入了新的安全漏洞。本文旨在揭示并解决这一安全问题。", "method": "通过分析RAG框架的数据加载阶段，识别并利用文档摄入过程中的漏洞。", "result": "研究发现，RAG框架在数据加载阶段存在安全漏洞，允许恶意行为者悄悄破坏RAG管道。", "conclusion": "本文强调了在RAG框架中加强数据加载阶段安全性的重要性，以防止恶意攻击和数据破坏。"}}
{"id": "2507.05098", "title": "Beyond Features: How Dataset Design Influences Multi-Agent Trajectory Prediction Performance", "authors": ["Tobias Demmler", "Jakob Häringer", "Andreas Tamke", "Thao Dang", "Alexander Hegai", "Lars Mikelsons"], "abstract": "Accurate trajectory prediction is critical for safe autonomous navigation, yet the impact of dataset design on model performance remains understudied. This work systematically examines how feature selection, cross-dataset transfer, and geographic diversity influence trajectory prediction accuracy in multi-agent settings. We evaluate a state-of-the-art model using our novel L4 Motion Forecasting dataset based on our own data recordings in Germany and the US. This includes enhanced map and agent features. We compare our dataset to the US-centric Argoverse 2 benchmark. First, we find that incorporating supplementary map and agent features unique to our dataset, yields no measurable improvement over baseline features, demonstrating that modern architectures do not need extensive feature sets for optimal performance. The limited features of public datasets are sufficient to capture convoluted interactions without added complexity. Second, we perform cross-dataset experiments to evaluate how effective domain knowledge can be transferred between datasets. Third, we group our dataset by country and check the knowledge transfer between different driving cultures.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.05098.pdf", "abstract_url": "https://arxiv.org/abs/2507.05098", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了数据集设计如何影响多智能体轨迹预测性能，通过比较新提出的L4 Motion Forecasting数据集与Argoverse 2基准，发现现代架构不需要大量特征集即可达到最佳性能，并研究了跨数据集知识转移的有效性。", "motivation": "解决数据集设计对多智能体轨迹预测模型性能影响的研究不足问题。", "method": "使用新提出的L4 Motion Forecasting数据集，比较其与Argoverse 2基准在特征选择、跨数据集转移和地理多样性方面的影响。", "result": "发现现代架构不需要大量特征集即可达到最佳性能，且公共数据集的有限特征足以捕捉复杂的交互；跨数据集知识转移的有效性得到验证。", "conclusion": "数据集设计对轨迹预测性能有重要影响，但现代架构对特征集的依赖较低，跨数据集知识转移是可行的。"}}
{"id": "2507.05150", "title": "Effects of Unplanned Incoming Flights on Airport Relief Processes after a Major Natural Disaster", "authors": ["Luka Van de Sype", "Matthieu Vert", "Alexei Sharpanskykh", "Seyed Sahand Mohammadi Ziabari"], "abstract": "The severity of natural disasters is increasing every year, impacting many people's lives. During the response phase of disasters, airports are important hubs where relief aid arrives and people need to be evacuated. However, the airport often forms a bottleneck in these relief operations due to the sudden need for increased capacity. Limited research has been done on the operational side of airport disaster management. Experts identify the main problems as, first, the asymmetry of information between the airport and incoming flights, and second, the lack of resources. The goal of this research is to understand the effects of incomplete knowledge of incoming flights with different resource allocation strategies on the performance of cargo handling operations at an airport after a natural disaster. An agent-based model is created, implementing realistic offloading strategies with different degrees of information uncertainty. Model calibration and verification are performed with experts in the field. The model performance is measured by the average turnaround time, which is divided into offloading time, boarding time, and cumulative waiting times. The results show that the effects of one unplanned aircraft are negligible. However, all waiting times increase with more arriving unplanned aircraft.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.05150.pdf", "abstract_url": "https://arxiv.org/abs/2507.05150", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究了自然灾害后机场救援过程中未计划到达航班的影响，通过基于代理的模型分析了不同信息不确定度和资源分配策略对货物处理操作性能的影响。", "motivation": "自然灾害的严重性逐年增加，机场在灾害响应阶段成为救援物资到达和人员疏散的重要枢纽。然而，由于突然增加的容量需求，机场往往成为救援操作的瓶颈。现有研究对机场灾害管理的操作层面关注不足，主要问题包括机场与 incoming flights 之间的信息不对称和资源不足。", "method": "研究创建了一个基于代理的模型，实现了具有不同信息不确定度的现实卸载策略，并进行了模型校准和验证。", "result": "结果显示，一架未计划到达的飞机影响可以忽略不计，但随着更多未计划到达飞机的到来，所有等待时间都会增加。", "conclusion": "研究结论强调了在自然灾害后机场救援操作中，对 incoming flights 的完整信息和有效资源分配策略的重要性，以减少等待时间并提高操作效率。"}}
{"id": "2507.05251", "title": "Action Space Reduction Strategies for Reinforcement Learning in Autonomous Driving", "authors": ["Elahe Delavari", "Feeza Khan Khanzada", "Jaerock Kwon"], "abstract": "Reinforcement Learning (RL) offers a promising framework for autonomous driving by enabling agents to learn control policies through interaction with environments. However, large and high-dimensional action spaces often used to support fine-grained control can impede training efficiency and increase exploration costs. In this study, we introduce and evaluate two novel structured action space modification strategies for RL in autonomous driving: dynamic masking and relative action space reduction. These approaches are systematically compared against fixed reduction schemes and full action space baselines to assess their impact on policy learning and performance. Our framework leverages a multimodal Proximal Policy Optimization agent that processes both semantic image sequences and scalar vehicle states. The proposed dynamic and relative strategies incorporate real-time action masking based on context and state transitions, preserving action consistency while eliminating invalid or suboptimal choices. Through comprehensive experiments across diverse driving routes, we show that action space reduction significantly improves training stability and policy performance. The dynamic and relative schemes, in particular, achieve a favorable balance between learning speed, control precision, and generalization. These findings highlight the importance of context-aware action space design for scalable and reliable RL in autonomous driving tasks.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.05251.pdf", "abstract_url": "https://arxiv.org/abs/2507.05251", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了两种新颖的结构化动作空间修改策略——动态掩码和相对动作空间减少，用于自动驾驶中的强化学习，以提高训练效率和策略性能。", "motivation": "自动驾驶中，强化学习的大规模和高维动作空间会阻碍训练效率和增加探索成本，本文旨在解决这一问题。", "method": "研究采用了动态掩码和相对动作空间减少两种策略，并与固定减少方案和完整动作空间基线进行系统比较。", "result": "实验表明，动作空间减少显著提高了训练稳定性和策略性能，动态和相对策略在学习速度、控制精度和泛化能力之间达到了良好的平衡。", "conclusion": "研究强调了上下文感知动作空间设计对于自动驾驶任务中可扩展和可靠的强化学习的重要性。"}}
{"id": "2507.05178", "title": "CREW-WILDFIRE: Benchmarking Agentic Multi-Agent Collaborations at Scale", "authors": ["Jonathan Hyun", "Nicholas R Waytowich", "Boyuan Chen"], "abstract": "Despite rapid progress in large language model (LLM)-based multi-agent systems, current benchmarks fall short in evaluating their scalability, robustness, and coordination capabilities in complex, dynamic, real-world tasks. Existing environments typically focus on small-scale, fully observable, or low-complexity domains, limiting their utility for developing and assessing next-generation multi-agent Agentic AI frameworks. We introduce CREW-Wildfire, an open-source benchmark designed to close this gap. Built atop the human-AI teaming CREW simulation platform, CREW-Wildfire offers procedurally generated wildfire response scenarios featuring large maps, heterogeneous agents, partial observability, stochastic dynamics, and long-horizon planning objectives. The environment supports both low-level control and high-level natural language interactions through modular Perception and Execution modules. We implement and evaluate several state-of-the-art LLM-based multi-agent Agentic AI frameworks, uncovering significant performance gaps that highlight the unsolved challenges in large-scale coordination, communication, spatial reasoning, and long-horizon planning under uncertainty. By providing more realistic complexity, scalable architecture, and behavioral evaluation metrics, CREW-Wildfire establishes a critical foundation for advancing research in scalable multi-agent Agentic intelligence. All code, environments, data, and baselines will be released to support future research in this emerging domain.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2507.05178.pdf", "abstract_url": "https://arxiv.org/abs/2507.05178", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "CREW-Wildfire是一个开源的基准测试，旨在评估大规模、复杂动态现实任务中基于大型语言模型的多智能体系统的可扩展性、鲁棒性和协调能力。", "motivation": "当前的多智能体系统基准测试在评估复杂、动态、现实世界任务中的可扩展性、鲁棒性和协调能力方面存在不足，CREW-Wildfire旨在填补这一空白。", "method": "基于人-AI团队协作的CREW模拟平台，CREW-Wildfire提供了程序生成的野火响应场景，支持低级控制和高级自然语言交互。", "result": "评估了几种最先进的基于LLM的多智能体Agentic AI框架，揭示了在大规模协调、通信、空间推理和不确定性下的长期规划方面的显著性能差距。", "conclusion": "CREW-Wildfire通过提供更真实的复杂性、可扩展的架构和行为评估指标，为推进可扩展多智能体Agentic智能研究奠定了重要基础。"}}
