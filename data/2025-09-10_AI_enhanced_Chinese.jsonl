{"id": "2509.07538", "title": "TextlessRAG: End-to-End Visual Document RAG by Speech Without Text", "authors": ["Peijin Xie", "Shun Qian", "Bingquan Liu", "Dexin Wang", "Lin Sun", "Xiangzheng Zhang"], "abstract": "Document images encapsulate a wealth of knowledge, while the portability of spoken queries enables broader and flexible application scenarios. Yet, no prior work has explored knowledge base question answering over visual document images with queries provided directly in speech. We propose TextlessRAG, the first end-to-end framework for speech-based question answering over large-scale document images. Unlike prior methods, TextlessRAG eliminates ASR, TTS and OCR, directly interpreting speech, retrieving relevant visual knowledge, and generating answers in a fully textless pipeline. To further boost performance, we integrate a layout-aware reranking mechanism to refine retrieval. Experiments demonstrate substantial improvements in both efficiency and accuracy. To advance research in this direction, we also release the first bilingual speech--document RAG dataset, featuring Chinese and English voice queries paired with multimodal document content. Both the dataset and our pipeline will be made available at repository:", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "5 pages, 4 figures,", "pdf_url": "https://arxiv.org/pdf/2509.07538.pdf", "abstract_url": "https://arxiv.org/abs/2509.07538", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "TextlessRAG是首个端到端框架，用于基于语音的视觉文档问答，无需ASR、TTS或OCR，直接处理语音、检索知识并生成答案，提高了效率和准确性。", "motivation": "解决视觉文档图像知识库问答中直接使用语音查询的问题，以支持更广泛和灵活的应用场景。", "method": "采用端到端文本无关管道，集成布局感知重排机制来优化检索。", "result": "实验显示在效率和准确性上均有显著提升。", "conclusion": "框架和发布的双语数据集推动相关研究，具有实际应用潜力。"}}
{"id": "2509.07680", "title": "CAViAR: Critic-Augmented Video Agentic Reasoning", "authors": ["Sachit Menon", "Ahmet Iscen", "Arsha Nagrani", "Tobias Weyand", "Carl Vondrick", "Cordelia Schmid"], "abstract": "Video understanding has seen significant progress in recent years, with models' performance on perception from short clips continuing to rise. Yet, multiple recent benchmarks, such as LVBench, Neptune, and ActivityNet-RTL, show performance wanes for tasks requiring complex reasoning on videos as queries grow more complex and videos grow longer. In this work, we ask: can existing perception capabilities be leveraged to successfully perform more complex video reasoning? In particular, we develop a large language model agent given access to video modules as subagents or tools. Rather than following a fixed procedure to solve queries as in previous work such as Visual Programming, ViperGPT, and MoReVQA, the agent uses the results of each call to a module to determine subsequent steps. Inspired by work in the textual reasoning domain, we introduce a critic to distinguish between instances of successful and unsuccessful sequences from the agent. We show that the combination of our agent and critic achieve strong performance on the previously-mentioned datasets.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.07680.pdf", "abstract_url": "https://arxiv.org/abs/2509.07680", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "CAViAR 通过结合大型语言模型代理和批评器，利用视频模块作为子代理或工具，提升复杂视频推理任务的性能，在多个基准测试中表现优异。", "motivation": "解决现有视频理解模型在处理复杂查询和长视频时推理能力下降的问题，利用现有感知能力进行更复杂的视频推理。", "method": "开发一个大型语言模型代理，使用视频模块作为子代理或工具，通过动态决定后续步骤，并引入批评器来区分成功和不成功的推理序列。", "result": "在 LVBench、Neptune 和 ActivityNet-RTL 等数据集上实现了强劲的性能。", "conclusion": "CAViAR 方法有效提升了视频推理能力，表明结合代理和批评器可以成功处理复杂视频任务。"}}
{"id": "2509.07188", "title": "DischargeSim: A Simulation Benchmark for Educational Doctor-Patient Communication at Discharge", "authors": ["Zonghai Yao", "Michael Sun", "Won Seok Jang", "Sunjae Kwon", "Soie Kwon", "Hong Yu"], "abstract": "Discharge communication is a critical yet underexplored component of patient care, where the goal shifts from diagnosis to education. While recent large language model (LLM) benchmarks emphasize in-visit diagnostic reasoning, they fail to evaluate models' ability to support patients after the visit. We introduce DischargeSim, a novel benchmark that evaluates LLMs on their ability to act as personalized discharge educators. DischargeSim simulates post-visit, multi-turn conversations between LLM-driven DoctorAgents and PatientAgents with diverse psychosocial profiles (e.g., health literacy, education, emotion). Interactions are structured across six clinically grounded discharge topics and assessed along three axes: (1) dialogue quality via automatic and LLM-as-judge evaluation, (2) personalized document generation including free-text summaries and structured AHRQ checklists, and (3) patient comprehension through a downstream multiple-choice exam. Experiments across 18 LLMs reveal significant gaps in discharge education capability, with performance varying widely across patient profiles. Notably, model size does not always yield better education outcomes, highlighting trade-offs in strategy use and content prioritization. DischargeSim offers a first step toward benchmarking LLMs in post-visit clinical education and promoting equitable, personalized patient support.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "Equal contribution for the first two authors. To appear in the proceedings of the Main Conference on Empirical Methods in Natural Language Processing (EMNLP) 2025", "pdf_url": "https://arxiv.org/pdf/2509.07188.pdf", "abstract_url": "https://arxiv.org/abs/2509.07188", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "DischargeSim 是一个用于评估大语言模型在出院沟通中作为个性化教育者能力的模拟基准，揭示了模型性能的显著差距和与模型大小的非正比关系。", "motivation": "解决现有基准忽略出院后患者教育的问题，专注于评估模型在诊断后支持患者的能力。", "method": "使用多轮对话模拟，结合多样化的患者心理社会档案，通过自动评估、LLM 作为评判者、文档生成和患者理解测试来评估模型。", "result": "实验显示 18 个 LLM 在出院教育能力上存在显著差异，模型大小不总是带来更好结果，强调了策略和内容优先级的权衡。", "conclusion": "DischargeSim 为基准化 LLM 在临床教育中的应用提供了初步框架，促进公平和个性化的患者支持。"}}
{"id": "2509.07389", "title": "Talking with Oompa Loompas: A novel framework for evaluating linguistic acquisition of LLM agents", "authors": ["Sankalp Tattwadarshi Swain", "Anshika Krishnatray", "Dhruv Kumar", "Jagat Sesh Challa"], "abstract": "Existing evaluation studies on linguistic competence of large language models (LLM agents) have focused primarily on vocabulary learning, morphological rule induction, syntactic generalization, pragmatic inference, and cross-linguistic transfer. However, none assess whether LLM agents can acquire a language through pattern recognition and interactive feedback, a central feature of human language acquisition. We propose a novel experimental framework in which an LLM agent is evaluated on its ability to acquire and use a newly constructed language (Tinkatongue) in conversation with a bot that understands only Tinkatongue. Our findings show that LLM agents fail to establish a conversation within 100 responses, yet they adopt distinct strategies that mirror human approaches to language learning. The results suggest a new direction for evaluation benchmarks and open pathways to model designs that learn more effectively from interactive feedback.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)", "comments": "Under review", "pdf_url": "https://arxiv.org/pdf/2509.07389.pdf", "abstract_url": "https://arxiv.org/abs/2509.07389", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "提出新框架评估LLM代理通过互动反馈学习新语言的能力，发现其失败但策略类似人类，推动新基准和模型设计。", "motivation": "现有评估未测试LLM代理通过模式识别和互动反馈获取语言的能力，这是人类语言习得的核心特征。", "method": "设计实验框架，让LLM代理与仅懂新语言Tinkatongue的机器人对话，评估其语言习得和使用。", "result": "LLM代理在100次响应内无法建立对话，但采用类似人类语言学习的策略。", "conclusion": "结果建议新评估基准方向，并开启从互动反馈中更有效学习的模型设计路径。"}}
{"id": "2509.07403", "title": "LongEmotion: Measuring Emotional Intelligence of Large Language Models in Long-Context Interaction", "authors": ["Weichu Liu", "Jing Xiong", "Yuxuan Hu", "Zixuan Li", "Minghuan Tan", "Ningning Mao", "Chenyang Zhao", "Zhongwei Wan", "Chaofan Tao", "Wendong Xu", "Hui Shen", "Chengming Li", "Lingpeng Kong", "Ngai Wong"], "abstract": "Large language models (LLMs) make significant progress in Emotional Intelligence (EI) and long-context understanding. However, existing benchmarks tend to overlook certain aspects of EI in long-context scenarios, especially under realistic, practical settings where interactions are lengthy, diverse, and often noisy. To move towards such realistic settings, we present LongEmotion, a benchmark specifically designed for long-context EI tasks. It covers a diverse set of tasks, including Emotion Classification, Emotion Detection, Emotion QA, Emotion Conversation, Emotion Summary, and Emotion Expression. On average, the input length for these tasks reaches 8,777 tokens, with long-form generation required for Emotion Expression. To enhance performance under realistic constraints, we incorporate Retrieval-Augmented Generation (RAG) and Collaborative Emotional Modeling (CoEM), and compare them with standard prompt-based methods. Unlike conventional approaches, our RAG method leverages both the conversation context and the large language model itself as retrieval sources, avoiding reliance on external knowledge bases. The CoEM method further improves performance by decomposing the task into five stages, integrating both retrieval augmentation and limited knowledge injection. Experimental results show that both RAG and CoEM consistently enhance EI-related performance across most long-context tasks, advancing LLMs toward more practical and real-world EI applications. Furthermore, we conducted a comparative case study experiment on the GPT series to demonstrate the differences among various models in terms of EI. Code is available on GitHub at", "subjects": "Computation and Language (cs.CL)", "comments": "Technical Report", "pdf_url": "https://arxiv.org/pdf/2509.07403.pdf", "abstract_url": "https://arxiv.org/abs/2509.07403", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了LongEmotion基准，用于评估大语言模型在长上下文交互中的情感智能，通过RAG和CoEM方法提升性能，并展示在GPT系列模型上的比较结果。", "motivation": "现有基准在长上下文场景中忽略情感智能的某些方面，特别是在现实、嘈杂的交互设置下，需要更实用的评估方法。", "method": "使用Retrieval-Augmented Generation (RAG) 和 Collaborative Emotional Modeling (CoEM) 方法，结合对话上下文和模型自身作为检索源，分解任务为五个阶段。", "result": "RAG和CoEM在大多数长上下文任务中一致提升情感智能性能，推动大语言模型向更实用的应用发展。", "conclusion": "LongEmotion基准和提出的方法有效增强大语言模型的情感智能，适用于现实世界应用，代码已开源。"}}
{"id": "2509.07475", "title": "HALT-RAG: A Task-Adaptable Framework for Hallucination Detection with Calibrated NLI Ensembles and Abstention", "authors": ["Saumya Goswami", "Siddharth Kurra"], "abstract": "Detecting content that contradicts or is unsupported by a given source text is a critical challenge for the safe deployment of generative language models. We introduce HALT-RAG, a post-hoc verification system designed to identify hallucinations in the outputs of Retrieval-Augmented Generation (RAG) pipelines. Our flexible and task-adaptable framework uses a universal feature set derived from an ensemble of two frozen, off-the-shelf Natural Language Inference (NLI) models and lightweight lexical signals. These features are used to train a simple, calibrated, and task-adapted meta-classifier. Using a rigorous 5-fold out-of-fold (OOF) training protocol to prevent data leakage and produce unbiased estimates, we evaluate our system on the HaluEval benchmark. By pairing our universal feature set with a lightweight, task-adapted classifier and a precision-constrained decision policy, HALT-RAG achieves strong OOF F1-scores of 0.7756, 0.9786, and 0.7391 on the summarization, QA, and dialogue tasks, respectively. The system's well-calibrated probabilities enable a practical abstention mechanism, providing a reliable tool for balancing model performance with safety requirements.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.07475.pdf", "abstract_url": "https://arxiv.org/abs/2509.07475", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "HALT-RAG is a post-hoc verification framework using NLI ensembles and lexical features to detect hallucinations in RAG outputs, achieving high F1-scores on summarization, QA, and dialogue tasks with a calibrated abstention mechanism.", "motivation": "To address the challenge of detecting contradictory or unsupported content in generative language model outputs for safe deployment, particularly in RAG pipelines.", "method": "Uses an ensemble of two frozen NLI models and lexical signals to create a universal feature set, trains a calibrated meta-classifier with a 5-fold OOF protocol, and implements a precision-constrained decision policy for abstention.", "result": "Achieves OOF F1-scores of 0.7756 (summarization), 0.9786 (QA), and 0.7391 (dialogue) on the HaluEval benchmark, with well-calibrated probabilities enabling reliable abstention.", "conclusion": "HALT-RAG provides a flexible and effective tool for hallucination detection, balancing performance and safety in generative AI applications."}}
{"id": "2509.07555", "title": "Avoiding Knowledge Edit Skipping in Multi-hop Question Answering with Guided Decomposition", "authors": ["Yi Liu", "Xiangrong Zhu", "Xiangyu Liu", "Wei Wei", "Wei Hu"], "abstract": "In a rapidly evolving world where information updates swiftly, knowledge in large language models (LLMs) becomes outdated quickly. Retraining LLMs is not a cost-effective option, making knowledge editing (KE) without modifying parameters particularly necessary. We find that although existing retrieval-augmented generation (RAG)-based KE methods excel at editing simple knowledge, they struggle with KE in multi-hop question answering due to the issue of \"edit skipping\", which refers to skipping the relevant edited fact in inference. In addition to the diversity of natural language expressions of knowledge, edit skipping also arises from the mismatch between the granularity of LLMs in problem-solving and the facts in the edited memory. To address this issue, we propose a novel Iterative Retrieval-Augmented Knowledge Editing method with guided decomposition (IRAKE) through the guidance from single edited facts and entire edited cases. Experimental results demonstrate that IRAKE mitigates the failure of editing caused by edit skipping and outperforms state-of-the-art methods for KE in multi-hop question answering.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "Accepted in EMNLP Findings 2025", "pdf_url": "https://arxiv.org/pdf/2509.07555.pdf", "abstract_url": "https://arxiv.org/abs/2509.07555", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种名为IRAKE的新方法，通过引导分解来解决多跳问答中知识编辑跳过的问题，提高编辑效果。", "motivation": "解决大型语言模型知识快速过时的问题，特别是在多跳问答中，现有基于RAG的知识编辑方法因编辑跳过而失败。", "method": "使用迭代检索增强知识编辑方法，通过单编辑事实和完整编辑案例的引导进行分解。", "result": "实验表明，IRAKE减少了编辑跳过导致的失败，并在多跳问答中优于最先进方法。", "conclusion": "IRAKE方法有效缓解了知识编辑跳过问题，提升了知识编辑在多跳问答中的性能。"}}
{"id": "2509.07553", "title": "VeriOS: Query-Driven Proactive Human-Agent-GUI Interaction for Trustworthy OS Agents", "authors": ["Zheng Wu", "Heyuan Huang", "Xingyu Lou", "Xiangmou Qu", "Pengzhou Cheng", "Zongru Wu", "Weiwen Liu", "Weinan Zhang", "Jun Wang", "Zhaoxiang Wang", "Zhuosheng Zhang"], "abstract": "With the rapid progress of multimodal large language models, operating system (OS) agents become increasingly capable of automating tasks through on-device graphical user interfaces (GUIs). However, most existing OS agents are designed for idealized settings, whereas real-world environments often present untrustworthy conditions. To mitigate risks of over-execution in such scenarios, we propose a query-driven human-agent-GUI interaction framework that enables OS agents to decide when to query humans for more reliable task completion. Built upon this framework, we introduce VeriOS-Agent, a trustworthy OS agent trained with a two-stage learning paradigm that falicitate the decoupling and utilization of meta-knowledge. Concretely, VeriOS-Agent autonomously executes actions in normal conditions while proactively querying humans in untrustworthy scenarios. Experiments show that VeriOS-Agent improves the average step-wise success rate by 20.64\\% in untrustworthy scenarios over the state-of-the-art, without compromising normal performance. Analysis highlights VeriOS-Agent's rationality, generalizability, and scalability. The codes, datasets and models are available at", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.07553.pdf", "abstract_url": "https://arxiv.org/abs/2509.07553", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "VeriOS-Agent 是一个可信赖的操作系统代理，通过查询驱动的人-代理-GUI 交互框架，在不可信场景中主动查询人类以提高任务完成可靠性，实验显示其平均步骤成功率提升20.64%。", "motivation": "解决现有操作系统代理在理想化设置中设计，而现实世界环境常存在不可信条件，导致过度执行风险的问题。", "method": "采用查询驱动的人-代理-GUI 交互框架，结合两阶段学习范式，分离和利用元知识，使代理在正常条件下自主执行，在不可信场景中主动查询人类。", "result": "在不可信场景中，平均步骤成功率比最先进方法提高20.64%，且不影响正常性能，显示出合理性、泛化性和可扩展性。", "conclusion": "VeriOS-Agent 提供了一种有效方法，增强操作系统代理的可信度，适用于现实世界应用，代码、数据集和模型已公开。"}}
{"id": "2509.07666", "title": "MoLoRAG: Bootstrapping Document Understanding via Multi-modal Logic-aware Retrieval", "authors": ["Xixi Wu", "Yanchao Tan", "Nan Hou", "Ruiyang Zhang", "Hong Cheng"], "abstract": "Document Understanding is a foundational AI capability with broad applications, and Document Question Answering (DocQA) is a key evaluation task. Traditional methods convert the document into text for processing by Large Language Models (LLMs), but this process strips away critical multi-modal information like figures. While Large Vision-Language Models (LVLMs) address this limitation, their constrained input size makes multi-page document comprehension infeasible. Retrieval-augmented generation (RAG) methods mitigate this by selecting relevant pages, but they rely solely on semantic relevance, ignoring logical connections between pages and the query, which is essential for reasoning.", "subjects": "Computation and Language (cs.CL); Information Retrieval (cs.IR)", "comments": "EMNLP Main 2025", "pdf_url": "https://arxiv.org/pdf/2509.07666.pdf", "abstract_url": "https://arxiv.org/abs/2509.07666", "categories": ["Computation and Language (cs.CL)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "MoLoRAG 提出了一种通过多模态逻辑感知检索引导文档理解的方法，解决传统和现有方法在文档问答中的局限性。", "motivation": "传统方法将文档转换为文本处理会丢失多模态信息，而大型视觉语言模型输入大小受限，检索增强生成方法仅依赖语义相关性，忽略逻辑连接，导致多页文档理解困难。", "method": "使用多模态逻辑感知检索，结合语义和逻辑相关性来选择相关页面，以增强文档问答的性能。", "result": "关键发现包括改进的检索准确性和文档理解能力，但具体结果未在摘要中提供。", "conclusion": "该方法能有效提升多页文档的理解，为文档问答任务提供更全面的解决方案。"}}
{"id": "2509.07098", "title": "Instruction Agent: Enhancing Agent with Expert Demonstration", "authors": ["Yinheng Li", "Hailey Hultquist", "Justin Wagle", "Kazuhito Koishida"], "abstract": "Graphical user interface (GUI) agents have advanced rapidly but still struggle with complex tasks involving novel UI elements, long-horizon actions, and personalized trajectories. In this work, we introduce Instruction Agent, a GUI agent that leverages expert demonstrations to solve such tasks, enabling completion of otherwise difficult workflows. Given a single demonstration, the agent extracts step-by-step instructions and executes them by strictly following the trajectory intended by the user, which avoids making mistakes during execution. The agent leverages the verifier and backtracker modules further to improve robustness. Both modules are critical to understand the current outcome from each action and handle unexpected interruptions(such as pop-up windows) during execution. Our experiments show that Instruction Agent achieves a 60% success rate on a set of tasks in OSWorld that all top-ranked agents failed to complete. The Instruction Agent offers a practical and extensible framework, bridging the gap between current GUI agents and reliable real-world GUI task automation.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.07098.pdf", "abstract_url": "https://arxiv.org/abs/2509.07098", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "Instruction Agent 是一种 GUI 代理，通过专家演示解决复杂任务，提高自动化成功率。", "motivation": "解决 GUI 代理在处理新颖 UI 元素、长时程操作和个性化轨迹等复杂任务时的困难。", "method": "利用专家演示提取逐步指令，结合验证器和回溯器模块执行，避免错误并处理中断。", "result": "在 OSWorld 任务上实现 60% 的成功率，优于其他顶级代理。", "conclusion": "提供了一个实用且可扩展的框架，缩小 GUI 代理与现实世界自动化之间的差距。"}}
{"id": "2509.07367", "title": "Autonomous Code Evolution Meets NP-Completeness", "authors": ["Cunxi Yu", "Rongjian Liang", "Chia-Tung Ho", "Haoxing Ren"], "abstract": "Large language models (LLMs) have recently shown strong coding abilities, enabling not only static code generation but also iterative code self-evolving through agentic frameworks. Recently, AlphaEvolve \\cite{novikov2025alphaevolve} demonstrated that LLM-based coding agents can autonomously improve algorithms and surpass human experts, with scopes limited to isolated kernels spanning hundreds of lines of code. Inspired by AlphaEvolve, we present SATLUTION, the first framework to extend LLM-based code evolution to the full repository scale, encompassing hundreds of files and tens of thousands of lines of C/C++ code. Targeting Boolean Satisfiability (SAT), the canonical NP-complete problem and a cornerstone of both theory and applications. SATLUTION orchestrates LLM agents to directly evolve solver repositories under strict correctness guarantees and distributed runtime feedback, while simultaneously self-evolving its own evolution policies and rules. Starting from SAT Competition 2024 codebases and benchmark, SATLUTION evolved solvers that decisively outperformed the human-designed winners of the SAT Competition 2025, and also surpassed both 2024 and 2025 champions on the 2024 benchmarks.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Logic in Computer Science (cs.LO)", "comments": "31 pages, 11 figures", "pdf_url": "https://arxiv.org/pdf/2509.07367.pdf", "abstract_url": "https://arxiv.org/abs/2509.07367", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Logic in Computer Science (cs.LO)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "SATLUTION框架利用大型语言模型（LLM）代理自主演化C/C++代码库，针对NP完全问题布尔可满足性（SAT），在完整仓库规模上超越人类专家设计的求解器。", "motivation": "解决现有LLM代码演化方法局限于小规模代码的问题，扩展到大型代码库以处理NP完全问题。", "method": "使用LLM代理在严格正确性保证和分布式运行时反馈下演化SAT求解器代码库，并自我演化演化策略。", "result": "从SAT Competition 2024代码出发，演化出的求解器在2025竞赛中击败人类获胜者，并在2024基准上超越2024和2025冠军。", "conclusion": "SATLUTION成功展示了LLM在大型代码库演化中的潜力，为自动算法优化提供了新途径。"}}
{"id": "2509.07006", "title": "ArGen: Auto-Regulation of Generative AI via GRPO and Policy-as-Code", "authors": ["Kapil Madan"], "abstract": "This paper introduces ArGen (Auto-Regulation of Generative AI systems), a framework for aligning Large Language Models (LLMs) with complex sets of configurable, machine-readable rules spanning ethical principles, operational safety protocols, and regulatory compliance standards. Moving beyond just preference-based alignment, ArGen is designed to ensure LLMs adhere to these multifaceted policies through a novel synthesis of principle-based automated reward scoring, Group Relative Policy Optimisation (GRPO), and an Open Policy Agent (OPA) inspired governance layer. This approach provides the technical foundation for achieving and demonstrating compliance with diverse and nuanced governance requirements. To showcase the framework's capability to operationalize a deeply nuanced and culturally-specific value system, we present an in-depth case study: the development of a medical AI assistant guided by principles from Dharmic ethics (such as Ahimsa and Dharma), as derived from texts like the Bhagavad Gita. This challenging application demonstrates ArGen's adaptability, achieving a 70.9% improvement in domain-scope adherence over the baseline. Through our open-source repository, we show that ArGen's methodology offers a path to 'Governable Al' systems that are technically proficient, ethically robust, and verifiably compliant for safe deployment in diverse global contexts.", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": ". Work explores the integration of policy-as-code for AI alignment, with a case study in culturally-nuanced, ethical AI using Dharmic principles", "pdf_url": "https://arxiv.org/pdf/2509.07006.pdf", "abstract_url": "https://arxiv.org/abs/2509.07006", "categories": ["Computers and Society (cs.CY)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "ArGen框架通过GRPO和策略即代码实现生成式AI的自动监管，提升LLMs对伦理、安全和合规规则的遵守，案例研究显示在医疗AI中领域依从性提高70.9%。", "motivation": "解决大型语言模型与复杂、可配置规则（如伦理原则、安全协议和法规标准）对齐的问题，超越基于偏好的对齐方法。", "method": "结合基于原则的自动奖励评分、组相对策略优化（GRPO）和Open Policy Agent（OPA）启发的治理层。", "result": "在基于Dharmic伦理的医疗AI助手案例中，领域依从性比基线提高了70.9%。", "conclusion": "ArGen提供了一条实现技术上熟练、伦理上稳健且可验证合规的'可治理AI'系统的路径，适用于全球多样化环境的安全部署。"}}
{"id": "2509.07642", "title": "Getting In Contract with Large Language Models -- An Agency Theory Perspective On Large Language Model Alignment", "authors": ["Sascha Kaltenpoth", "Oliver Müller"], "abstract": "Adopting Large language models (LLMs) in organizations potentially revolutionizes our lives and work. However, they can generate off-topic, discriminating, or harmful content. This AI alignment problem often stems from misspecifications during the LLM adoption, unnoticed by the principal due to the LLM's black-box nature. While various research disciplines investigated AI alignment, they neither address the information asymmetries between organizational adopters and black-box LLM agents nor consider organizational AI adoption processes. Therefore, we propose LLM ATLAS (LLM Agency Theory-Led Alignment Strategy) a conceptual framework grounded in agency (contract) theory, to mitigate alignment problems during organizational LLM adoption. We conduct a conceptual literature analysis using the organizational LLM adoption phases and the agency theory as concepts. Our approach results in (1) providing an extended literature analysis process specific to AI alignment methods during organizational LLM adoption and (2) providing a first LLM alignment problem-solution space.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2509.07642.pdf", "abstract_url": "https://arxiv.org/abs/2509.07642", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文从代理理论视角提出LLM ATLAS框架，通过概念性文献分析，解决组织采用大语言模型时的对齐问题，强调信息不对称和采用过程。", "motivation": "解决大语言模型在组织采用中因黑盒特性和信息不对称导致的AI对齐问题，如生成无关、歧视或有害内容。", "method": "基于代理（合同）理论，进行概念性文献分析，结合组织LLM采用阶段和代理理论概念，开发LLM ATLAS框架。", "result": "提供扩展的AI对齐方法文献分析过程和首个LLM对齐问题-解决方案空间。", "conclusion": "LLM ATLAS框架有助于缓解组织采用LLM时的对齐问题，强调理论指导的实践应用。"}}
{"id": "2509.07706", "title": "FHIR-RAG-MEDS: Integrating HL7 FHIR with Retrieval-Augmented Large Language Models for Enhanced Medical Decision Support", "authors": ["Yildiray Kabak", "Gokce B. Laleci Erturkmen", "Mert Gencturk", "Tuncay Namli", "A. Anil Sinaci", "Ruben Alcantud Corcoles", "Cristina Gomez Ballesteros", "Pedro Abizanda", "Asuman Dogac"], "abstract": "In this study, we propose FHIR-RAG-MEDS system that aims to integrate Health Level 7 Fast Healthcare Interoperability Resources (HL7 FHIR) with a Retrieval-Augmented Generation (RAG)-based system to improve personalized medical decision support on evidence-based clinical guidelines, emphasizing the need for research in practical applications. In the evolving landscape of medical decision support systems, integrating advanced technologies such as RAG and HL7 FHIR can significantly enhance clinical decision-making processes. Despite the potential of these technologies, there is limited research on their integration in practical applications.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "31 pages, submitted to Journal of Biomedical Informatics, under review", "pdf_url": "https://arxiv.org/pdf/2509.07706.pdf", "abstract_url": "https://arxiv.org/abs/2509.07706", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本研究提出FHIR-RAG-MEDS系统，通过整合HL7 FHIR与检索增强生成技术，以提升基于证据的临床指南的个性化医疗决策支持。", "motivation": "解决医疗决策支持系统中先进技术（如RAG和HL7 FHIR）集成在实际应用中的研究不足问题。", "method": "集成HL7 FHIR标准与检索增强生成（RAG）方法，构建系统以增强临床决策过程。", "result": "系统旨在显著改善个性化医疗决策支持，但具体结果未在摘要中详述。", "conclusion": "集成FHIR与RAG技术有潜力提升临床决策，强调在实用应用中进一步研究的必要性。"}}
{"id": "2509.07846", "title": "Aligning LLMs for the Classroom with Knowledge-Based Retrieval -- A Comparative RAG Study", "authors": ["Amay Jain", "Liu Cui", "Si Chen"], "abstract": "Large language models like ChatGPT are increasingly used in classrooms, but they often provide outdated or fabricated information that can mislead students. Retrieval Augmented Generation (RAG) improves reliability of LLMs by grounding responses in external resources. We investigate two accessible RAG paradigms, vector-based retrieval and graph-based retrieval to identify best practices for classroom question answering (QA). Existing comparative studies fail to account for pedagogical factors such as educational disciplines, question types, and practical deployment costs. Using a novel dataset, EduScopeQA, of 3,176 questions across academic subjects, we measure performance on various educational query types, from specific facts to broad thematic discussions. We also evaluate system alignment with a dataset of systematically altered textbooks that contradict the LLM's latent knowledge. We find that OpenAI Vector Search RAG (representing vector-based RAG) performs well as a low-cost generalist, especially for quick fact retrieval. On the other hand, GraphRAG Global excels at providing pedagogically rich answers to thematic queries, and GraphRAG Local achieves the highest accuracy with the dense, altered textbooks when corpus integrity is critical. Accounting for the 10-20x higher resource usage of GraphRAG (representing graph-based RAG), we show that a dynamic branching framework that routes queries to the optimal retrieval method boosts fidelity and efficiency. These insights provide actionable guidelines for educators and system designers to integrate RAG-augmented LLMs into learning environments effectively.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "This work has been submitted to the IEEE for possible publication", "pdf_url": "https://arxiv.org/pdf/2509.07846.pdf", "abstract_url": "https://arxiv.org/abs/2509.07846", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文比较了基于向量和基于图检索的RAG方法在教育问答中的性能，发现向量检索适合低成本快速事实查询，而图检索更擅长处理主题查询和确保信息准确性，提出了动态分支框架以提高效率和可靠性。", "motivation": "解决大型语言模型在课堂中提供过时或虚假信息的问题，通过RAG方法提升回答的可靠性，并考虑教育因素如学科、问题类型和部署成本。", "method": "使用EduScopeQA数据集（3,176个问题）和修改的教科书数据，评估向量检索（OpenAI Vector Search RAG）和图检索（GraphRAG Global/Local）的性能，并引入动态分支框架优化查询路由。", "result": "向量检索在快速事实查询中表现良好，图检索在处理主题查询和确保信息准确性上更优，但资源使用高10-20倍；动态分支框架提高了保真度和效率。", "conclusion": "研究为教育者和系统设计者提供了实用指南，帮助有效集成RAG增强的LLM到学习环境中，平衡性能和成本。"}}
{"id": "2509.07506", "title": "Astra: A Multi-Agent System for GPU Kernel Performance Optimization", "authors": ["Anjiang Wei", "Tianran Sun", "Yogesh Seenichamy", "Hang Song", "Anne Ouyang", "Azalia Mirhoseini", "Ke Wang", "Alex Aiken"], "abstract": "GPU kernel optimization has long been a central challenge at the intersection of high-performance computing and machine learning. Efficient kernels are crucial for accelerating large language model (LLM) training and serving, yet attaining high performance typically requires extensive manual tuning. Compiler-based systems reduce some of this burden, but still demand substantial manual design and engineering effort. Recently, researchers have explored using LLMs for GPU kernel generation, though prior work has largely focused on translating high-level PyTorch modules into CUDA code. In this work, we introduce Astra, the first LLM-based multi-agent system for GPU kernel optimization. Unlike previous approaches, Astra starts from existing CUDA implementations extracted from SGLang, a widely deployed framework for serving LLMs, rather than treating PyTorch modules as the specification. Within Astra, specialized LLM agents collaborate through iterative code generation, testing, profiling, and planning to produce kernels that are both correct and high-performance. On kernels from SGLang, Astra achieves an average speedup of 1.32x using zero-shot prompting with OpenAI o4-mini. A detailed case study further demonstrates that LLMs can autonomously apply loop transformations, optimize memory access patterns, exploit CUDA intrinsics, and leverage fast math operations to yield substantial performance gains. Our work highlights multi-agent LLM systems as a promising new paradigm for GPU kernel optimization.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Software Engineering (cs.SE)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.07506.pdf", "abstract_url": "https://arxiv.org/abs/2509.07506", "categories": ["Distributed, Parallel, and Cluster Computing (cs.DC)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)", "Software Engineering (cs.SE)"], "matching_keywords": ["agent"], "AI": {"tldr": "Astra 是一个基于大语言模型的多智能体系统，用于优化 GPU 内核性能，通过协作生成和测试代码，在 SGLang 内核上实现平均 1.32 倍加速。", "motivation": "解决 GPU 内核优化中手动调优负担重的问题，现有编译器系统和 LLM 方法仍需要大量人工设计，Astra 旨在自动化这一过程。", "method": "使用多智能体 LLM 系统，从现有 CUDA 代码出发，通过迭代代码生成、测试、分析和规划，协作优化内核性能。", "result": "在 SGLang 内核上，Astra 实现了平均 1.32 倍的速度提升，并展示了自主应用循环变换、优化内存访问模式等能力。", "conclusion": "多智能体 LLM 系统是 GPU 内核优化的有前景新范式，能显著减少人工努力并提升性能。"}}
{"id": "2509.04827", "title": "VoltanaLLM: Feedback-Driven Frequency Control and State-Space Routing for Energy-Efficient LLM Serving", "authors": ["Jiahuan Yu", "Aryan Taneja", "Junfeng Lin", "Minjia Zhang"], "abstract": "Modern Large Language Model (LLM) serving systems increasingly support interactive applications, like real-time chat assistants, code generation tools, and agentic workflows. However, the soaring energy cost of LLM inference presents a growing challenge for sustainable and cost-effective deployment. This paper introduces VoltanaLLM, a system for SLO-aware, energy-efficient LLM serving, built from a control theory perspective. VoltanaLLM co-designs frequency scaling and request routing in emerging prefill/decode disaggregated architectures, leveraging their decoupled execution to enable fine-grained phase-specific control. It consists of a feedback-driven frequency controller that dynamically adapts GPU frequency for prefill and decode phases, and a state-space router that explores routing decisions across frequency-scaled instances to minimize energy under latency constraints. We implement VoltanaLLM in SGLang and evaluate its performance over multiple state-of-the-art LLMs and real-world datasets. The results demonstrate that VoltanaLLM achieves up to 36.3% energy savings while maintaining near-perfect SLO attainment rate, paving the way for sustainable and intelligent LLM serving.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.04827.pdf", "abstract_url": "https://arxiv.org/abs/2509.04827", "categories": ["Distributed, Parallel, and Cluster Computing (cs.DC)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "VoltanaLLM 是一个基于控制理论的系统，通过反馈驱动的频率控制和状态空间路由，在预填充/解码分离架构中实现能效优化的LLM服务，节省高达36.3%的能源，同时保持低延迟。", "motivation": "解决大型语言模型（LLM）推理中能源成本飙升的问题，以实现可持续和成本效益高的部署。", "method": "结合频率缩放和请求路由，使用反馈控制器动态调整GPU频率，并通过状态空间路由器优化路由决策，以最小化能源消耗并满足延迟约束。", "result": "在多个先进LLM和真实数据集上评估，VoltanaLLM实现高达36.3%的能源节省，同时几乎完美满足服务级别目标（SLO）。", "conclusion": "VoltanaLLM为可持续和智能的LLM服务铺平道路，展示了控制理论在系统设计中的有效性。"}}
{"id": "2509.07009", "title": "Computational Concept of the Psyche", "authors": ["Anton Kolonin", "Vladimir Kryukov"], "abstract": "The article provides an overview of approaches to modeling the human psyche in the perspective of building an artificial one. Based on the review, a concept of cognitive architecture is proposed, where the psyche is considered as an operating system of a living or artificial subject, including a space of needs that determines its life meanings in connection with stimuli from the external world, and intelligence as a decision-making system for actions in relation to this world in order to satisfy these needs. Based on the concept, a computational formalization is proposed for creating artificial intelligence systems through learning from experience in the space of a space of needs, taking into account their biological or existential significance for an intelligent agent. Thus, the problem of building general artificial intelligence as a system for making optimal decisions in the space of agent-specific needs under conditions of uncertainty is formalized, with maximization of success in achieving goals, minimization of existential risks and maximization of energy efficiency. A minimal experimental implementation of the model is also provided.", "subjects": "Neurons and Cognition (q-bio.NC); Artificial Intelligence (cs.AI); Systems and Control (eess.SY)", "comments": "14 pages, in Russian, 2 figures, submitted to Neuroinformatics-2025 conference", "pdf_url": "https://arxiv.org/pdf/2509.07009.pdf", "abstract_url": "https://arxiv.org/abs/2509.07009", "categories": ["Neurons and Cognition (q-bio.NC)", "Artificial Intelligence (cs.AI)", "Systems and Control (eess.SY)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于需求空间和智能决策的认知架构，用于建模人类心理并构建通用人工智能系统，通过经验学习优化目标达成、最小化风险和最大化能效。", "motivation": "解决构建通用人工智能系统的问题，通过模拟人类心理的需求驱动决策过程，以应对不确定性并优化代理的生存和效率。", "method": "提出一种计算形式化方法，将心理视为操作系统的认知架构，包括需求空间和智能决策系统，通过经验学习在需求空间中训练AI系统。", "result": "概念被形式化，问题被定义为在不确定性下优化决策，并提供了最小实验实现，展示了模型的可行性。", "conclusion": "该概念为构建通用AI提供了新途径，强调需求驱动和风险最小化，具有潜在的应用价值。"}}
{"id": "2509.07019", "title": "An efficient deep reinforcement learning environment for flexible job-shop scheduling", "authors": ["Xinquan Wu", "Xuefeng Yan", "Mingqiang Wei", "Donghai Guan"], "abstract": "The Flexible Job-shop Scheduling Problem (FJSP) is a classical combinatorial optimization problem that has a wide-range of applications in the real world. In order to generate fast and accurate scheduling solutions for FJSP, various deep reinforcement learning (DRL) scheduling methods have been developed. However, these methods are mainly focused on the design of DRL scheduling Agent, overlooking the modeling of DRL environment. This paper presents a simple chronological DRL environment for FJSP based on discrete event simulation and an end-to-end DRL scheduling model is proposed based on the proximal policy optimization (PPO). Furthermore, a short novel state representation of FJSP is proposed based on two state variables in the scheduling environment and a novel comprehensible reward function is designed based on the scheduling area of machines. Experimental results on public benchmark instances show that the performance of simple priority dispatching rules (PDR) is improved in our scheduling environment and our DRL scheduling model obtains competing performance compared with OR-Tools, meta-heuristic, DRL and PDR scheduling methods.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.07019.pdf", "abstract_url": "https://arxiv.org/abs/2509.07019", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于离散事件模拟的简单时序DRL环境，用于柔性作业车间调度问题（FJSP），并开发了一个基于PPO的端到端DRL调度模型，包括新颖的状态表示和奖励函数，实验显示性能优于现有方法。", "motivation": "解决FJSP中现有深度强化学习方法主要关注代理设计而忽视环境建模的问题，旨在生成快速准确的调度解决方案。", "method": "使用离散事件模拟构建DRL环境，基于近端策略优化（PPO）开发端到端调度模型，提出基于两个状态变量的短状态表示和基于机器调度区域的可理解奖励函数。", "result": "在公共基准实例上，实验结果表明调度环境改进了简单优先级调度规则（PDR）的性能，且DRL调度模型在OR-Tools、元启发式、DRL和PDR方法中具有竞争性表现。", "conclusion": "所提出的环境和方法有效提升了FJSP的调度性能，为实际应用提供了高效解决方案。"}}
{"id": "2509.07029", "title": "The Impact of Artificial Intelligence on Traditional Art Forms: A Disruption or Enhancement", "authors": ["Viswa Chaitanya Marella", "Sai Teja Erukude", "Suhasnadh Reddy Veluru"], "abstract": "The introduction of Artificial Intelligence (AI) into the domains of traditional art (visual arts, performing arts, and crafts) has sparked a complicated discussion about whether this might be an agent of disruption or an enhancement of our traditional art forms. This paper looks at the duality of AI, exploring the ways that recent technologies like Generative Adversarial Networks and Diffusion Models, and text-to-image generators are changing the fields of painting, sculpture, calligraphy, dance, music, and the arts of craft. Using examples and data, we illustrate the ways that AI can democratize creative expression, improve productivity, and preserve cultural heritage, while also examining the negative aspects, including: the threats to authenticity within art, ethical concerns around data, and issues including socio-economic factors such as job losses. While we argue for the context-dependence of the impact of AI (the potential for creative homogenization and the devaluation of human agency in artmaking), we also illustrate the potential for hybrid practices featuring AI in cuisine, etc. We advocate for the development of ethical guidelines, collaborative approaches, and inclusive technology development. In sum, we are articulating a vision of AI in which it amplifies our innate creativity while resisting the displacement of the cultural, nuanced, and emotional aspects of traditional art. The future will be determined by human choices about how to govern AI so that it becomes a mechanism for artistic evolution and not a substitute for the artist's soul.", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI)", "comments": "13 pages", "pdf_url": "https://arxiv.org/pdf/2509.07029.pdf", "abstract_url": "https://arxiv.org/abs/2509.07029", "categories": ["Computers and Society (cs.CY)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨AI对传统艺术的影响，分析其作为破坏或增强的双重作用，强调需通过伦理指南和协作确保AI促进艺术进化而非替代。", "motivation": "解决AI引入传统艺术领域引发的争议，评估其作为破坏或增强因素的问题。", "method": "使用生成对抗网络、扩散模型等技术示例和数据，分析AI在绘画、雕塑等领域的应用。", "result": "AI可民主化创意、提高生产力、保护文化遗产，但也带来真实性威胁、伦理问题和社会经济风险。", "conclusion": "AI的影响取决于人类选择，应发展伦理指南和协作方法，确保其增强而非取代艺术的人文和情感层面。"}}
{"id": "2509.07131", "title": "SoK: Security and Privacy of AI Agents for Blockchain", "authors": ["Nicolò Romandini", "Carlo Mazzocca", "Kai Otsuki", "Rebecca Montanari"], "abstract": "Blockchain and smart contracts have garnered significant interest in recent years as the foundation of a decentralized, trustless digital ecosystem, thereby eliminating the need for traditional centralized authorities. Despite their central role in powering Web3, their complexity still presents significant barriers for non-expert users. To bridge this gap, Artificial Intelligence (AI)-based agents have emerged as valuable tools for interacting with blockchain environments, supporting a range of tasks, from analyzing on-chain data and optimizing transaction strategies to detecting vulnerabilities within smart contracts. While interest in applying AI to blockchain is growing, the literature still lacks a comprehensive survey that focuses specifically on the intersection with AI agents. Most of the related work only provides general considerations, without focusing on any specific domain. This paper addresses this gap by presenting the first Systematization of Knowledge dedicated to AI-driven systems for blockchain, with a special focus on their security and privacy dimensions, shedding light on their applications, limitations, and future research directions.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": "This work has been accepted to the 7th International Conference on Blockchain Computing and Applications (BCCA 2025)", "pdf_url": "https://arxiv.org/pdf/2509.07131.pdf", "abstract_url": "https://arxiv.org/abs/2509.07131", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文是第一份关于区块链AI代理安全与隐私的系统化知识综述，填补了文献空白，聚焦应用、局限和未来研究方向。", "motivation": "区块链和智能合约的复杂性阻碍非专家用户使用，AI代理虽被用于交互，但现有文献缺乏针对AI代理在区块链中安全与隐私的全面调查。", "method": "采用系统化知识方法，综述AI驱动系统在区块链中的应用，特别关注安全与隐私维度。", "result": "论文识别了AI代理在区块链中的关键应用、当前局限，并提出了未来研究的方向。", "conclusion": "AI代理在区块链中潜力巨大，但需加强安全隐私保护，以促进Web3发展。"}}
{"id": "2509.07571", "title": "Towards Generalized Routing: Model and Agent Orchestration for Adaptive and Efficient Inference", "authors": ["Xiyu Guo", "Shan Wang", "Chunfang Ji", "Xuefeng Zhao", "Wenhao Xi", "Yaoyao Liu", "Qinglan Li", "Chao Deng", "Junlan Feng"], "abstract": "The rapid advancement of large language models (LLMs) and domain-specific AI agents has greatly expanded the ecosystem of AI-powered services. User queries, however, are highly diverse and often span multiple domains and task types, resulting in a complex and heterogeneous landscape. This diversity presents a fundamental routing challenge: how to accurately direct each query to an appropriate execution unit while optimizing both performance and efficiency. To address this, we propose MoMA (Mixture of Models and Agents), a generalized routing framework that integrates both LLM and agent-based routing. Built upon a deep understanding of model and agent capabilities, MoMA effectively handles diverse queries through precise intent recognition and adaptive routing strategies, achieving an optimal balance between efficiency and cost. Specifically, we construct a detailed training dataset to profile the capabilities of various LLMs under different routing model structures, identifying the most suitable tasks for each LLM. During inference, queries are dynamically routed to the LLM with the best cost-performance efficiency. We also introduce an efficient agent selection strategy based on a context-aware state machine and dynamic masking. Experimental results demonstrate that the MoMA router offers superior cost-efficiency and scalability compared to existing approaches.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.07571.pdf", "abstract_url": "https://arxiv.org/abs/2509.07571", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "提出MoMA框架，通过集成LLM和基于代理的路由，优化查询路由以实现高效和成本效益的推理。", "motivation": "解决用户查询多样性带来的路由挑战，需准确导向执行单元并优化性能和效率。", "method": "构建训练数据集分析LLM能力，采用意图识别和自适应路由策略，结合上下文感知状态机和动态掩码进行代理选择。", "result": "实验显示MoMA在成本效率和可扩展性上优于现有方法。", "conclusion": "MoMA框架有效处理异构查询，平衡效率与成本，提升AI服务生态系统。"}}
{"id": "2509.07614", "title": "From Classical Data to Quantum Advantage -- Quantum Policy Evaluation on Quantum Hardware", "authors": ["Daniel Hein", "Simon Wiedemann", "Markus Baumann", "Patrik Felbinger", "Justin Klein", "Maximilian Schieder", "Jonas Stein", "Daniëlle Schuman", "Thomas Cope", "Steffen Udluft"], "abstract": "Quantum policy evaluation (QPE) is a reinforcement learning (RL) algorithm which is quadratically more efficient than an analogous classical Monte Carlo estimation. It makes use of a direct quantum mechanical realization of a finite Markov decision process, in which the agent and the environment are modeled by unitary operators and exchange states, actions, and rewards in superposition. Previously, the quantum environment has been implemented and parametrized manually for an illustrative benchmark using a quantum simulator. In this paper, we demonstrate how these environment parameters can be learned from a batch of classical observational data through quantum machine learning (QML) on quantum hardware. The learned quantum environment is then applied in QPE to also compute policy evaluations on quantum hardware. Our experiments reveal that, despite challenges such as noise and short coherence times, the integration of QML and QPE shows promising potential for achieving quantum advantage in RL.", "subjects": "Quantum Physics (quant-ph); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.07614.pdf", "abstract_url": "https://arxiv.org/abs/2509.07614", "categories": ["Quantum Physics (quant-ph)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文演示了如何从经典数据中学习量子环境参数，并在量子硬件上应用量子策略评估，显示出在强化学习中实现量子优势的潜力。", "motivation": "解决量子策略评估中量子环境参数需要手动设置的问题，并探索在噪声和短相干时间等挑战下，如何利用量子机器学习从经典数据中学习参数以实现量子优势。", "method": "使用量子机器学习从一批经典观测数据中学习量子环境参数，然后在量子硬件上应用这些参数进行量子策略评估。", "result": "实验表明，尽管存在噪声和短相干时间等挑战，量子机器学习和量子策略评估的整合显示出在强化学习中实现量子优势的潜力。", "conclusion": "该方法为在量子硬件上实现更高效的强化学习算法提供了可行途径，并强调了量子优势的潜在应用前景。"}}
{"id": "2509.07941", "title": "ImportSnare: Directed \"Code Manual\" Hijacking in Retrieval-Augmented Code Generation", "authors": ["Kai Ye", "Liangcai Su", "Chenxiong Qian"], "abstract": "Code generation has emerged as a pivotal capability of Large Language Models(LLMs), revolutionizing development efficiency for programmers of all skill levels. However, the complexity of data structures and algorithmic logic often results in functional deficiencies and security vulnerabilities in generated code, reducing it to a prototype requiring extensive manual debugging. While Retrieval-Augmented Generation (RAG) can enhance correctness and security by leveraging external code manuals, it simultaneously introduces new attack surfaces.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": "This paper has been accepted by the ACM Conference on Computer and Communications Security (CCS) 2025", "pdf_url": "https://arxiv.org/pdf/2509.07941.pdf", "abstract_url": "https://arxiv.org/abs/2509.07941", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文探讨了在检索增强代码生成中，通过定向'代码手册'劫持引入的新攻击面及其对代码正确性和安全性的影响。", "motivation": "解决大型语言模型在代码生成中因数据结构和算法复杂性导致的功能缺陷和安全漏洞问题，尽管检索增强生成可提升正确性，但也带来新的攻击风险。", "method": "未在摘要中详细说明，但暗示通过分析或实验方法研究定向劫持攻击在检索增强代码生成中的实施和影响。", "result": "摘要未提供具体结果，但指出检索增强生成在提升代码质量的同时引入了新的攻击面。", "conclusion": "强调需要关注和缓解检索增强代码生成中的安全风险，以平衡效率与安全性。"}}
