{"id": "2509.08903", "title": "Noise or Nuance: An Investigation Into Useful Information and Filtering For LLM Driven AKBC", "authors": ["Alex Clay", "Ernesto Jiménez-Ruiz", "Pranava Madhyastha"], "abstract": "RAG and fine-tuning are prevalent strategies for improving the quality of LLM outputs. However, in constrained situations, such as that of the 2025 LM-KBC challenge, such techniques are restricted. In this work we investigate three facets of the triple completion task: generation, quality assurance, and LLM response parsing. Our work finds that in this constrained setting: additional information improves generation quality, LLMs can be effective at filtering poor quality triples, and the tradeoff between flexibility and consistency with LLM response parsing is setting dependent.", "subjects": "Computation and Language (cs.CL)", "comments": "8 pages, 1 figure, accepted to the ISWC 2025 LM-KBC Workshop", "pdf_url": "https://arxiv.org/pdf/2509.08903.pdf", "abstract_url": "https://arxiv.org/abs/2509.08903", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "该论文探讨了在受限环境下（如2025年LM-KBC挑战），通过生成、质量保证和LLM响应解析三个方面，发现额外信息提升生成质量，LLM能有效过滤低质量三元组，解析的灵活性与一致性权衡取决于设置。", "motivation": "解决在约束条件下（如RAG和微调受限时）提高LLM输出质量的问题，特别是在三元组补全任务中。", "method": "研究生成、质量保证和LLM响应解析三个方面的策略，分析信息添加、过滤和解析权衡。", "result": "额外信息改善生成质量，LLM能过滤低质量三元组，解析的灵活性与一致性是设置依赖的。", "conclusion": "在受限AKBC任务中，信息添加和LLM过滤有效，解析策略需根据具体环境调整，为优化LLM应用提供指导。"}}
{"id": "2509.08907", "title": "Automated Evidence Extraction and Scoring for Corporate Climate Policy Engagement: A Multilingual RAG Approach", "authors": ["Imene Kolli", "Ario Saeid Vaghefi", "Chiara Colesanti Senni", "Shantam Raj", "Markus Leippold"], "abstract": "InfluenceMap's LobbyMap Platform monitors the climate policy engagement of over 500 companies and 250 industry associations, assessing each entity's support or opposition to science-based policy pathways for achieving the Paris Agreement's goal of limiting global warming to 1.5°C. Although InfluenceMap has made progress with automating key elements of the analytical workflow, a significant portion of the assessment remains manual, making it time- and labor-intensive and susceptible to human error. We propose an AI-assisted framework to accelerate the monitoring of corporate climate policy engagement by leveraging Retrieval-Augmented Generation to automate the most time-intensive extraction of relevant evidence from large-scale textual data. Our evaluation shows that a combination of layout-aware parsing, the Nomic embedding model, and few-shot prompting strategies yields the best performance in extracting and classifying evidence from multilingual corporate documents. We conclude that while the automated RAG system effectively accelerates evidence extraction, the nuanced nature of the analysis necessitates a human-in-the-loop approach where the technology augments, rather than replaces, expert judgment to ensure accuracy.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.08907.pdf", "abstract_url": "https://arxiv.org/abs/2509.08907", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种基于检索增强生成的多语言AI框架，用于自动提取和评分企业气候政策参与证据，结合布局感知解析和少样本提示，加速分析流程，但强调人机协作以确保准确性。", "motivation": "解决InfluenceMap平台在监控企业气候政策参与时，手动评估部分耗时、易错的问题，以提高效率和减少人为错误。", "method": "采用检索增强生成（RAG）方法，结合布局感知解析、Nomic嵌入模型和少样本提示策略，从多语言文档中自动提取和分类证据。", "result": "评估显示，该方法在证据提取和分类方面表现最佳，有效加速了证据提取过程。", "conclusion": "自动化RAG系统能加速证据提取，但由于分析的复杂性，需要人机协作，技术应辅助而非替代专家判断，以确保准确性。"}}
{"id": "2509.09307", "title": "Can Multimodal LLMs See Materials Clearly? A Multimodal Benchmark on Materials Characterization", "authors": ["Zhengzhao Lai", "Youbin Zheng", "Zhenyang Cai", "Haonan Lyu", "Jinpu Yang", "Hongqing Liang", "Yan Hu", "Benyou Wang"], "abstract": "Materials characterization is fundamental to acquiring materials information, revealing the processing-microstructure-property relationships that guide material design and optimization. While multimodal large language models (MLLMs) have recently shown promise in generative and predictive tasks within materials science, their capacity to understand real-world characterization imaging data remains underexplored. To bridge this gap, we present MatCha, the first benchmark for materials characterization image understanding, comprising 1,500 questions that demand expert-level domain expertise. MatCha encompasses four key stages of materials research comprising 21 distinct tasks, each designed to reflect authentic challenges faced by materials scientists. Our evaluation of state-of-the-art MLLMs on MatCha reveals a significant performance gap compared to human experts. These models exhibit degradation when addressing questions requiring higher-level expertise and sophisticated visual perception. Simple few-shot and chain-of-thought prompting struggle to alleviate these limitations. These findings highlight that existing MLLMs still exhibit limited adaptability to real-world materials characterization scenarios. We hope MatCha will facilitate future research in areas such as new material discovery and autonomous scientific agents. MatCha is available at", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Multimedia (cs.MM)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.09307.pdf", "abstract_url": "https://arxiv.org/abs/2509.09307", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Multimedia (cs.MM)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了MatCha，首个材料表征图像理解基准，包含1500个问题，评估多模态大语言模型在材料科学中的表现，发现其与人类专家存在显著差距。", "motivation": "解决多模态大语言模型在理解真实世界材料表征成像数据方面的能力不足问题，以推动材料科学中的新发现和自主科学代理研究。", "method": "开发MatCha基准，涵盖材料研究的四个关键阶段和21个任务，使用1,500个问题评估现有MLLMs的性能。", "result": "评估显示MLLMs性能显著低于人类专家，在处理需要高级专业知识和视觉感知的问题时表现退化，少样本和思维链提示方法效果有限。", "conclusion": "现有MLLMs对真实世界材料表征场景的适应性有限，MatCha基准有望促进未来研究，如新材料发现和自主科学代理。"}}
{"id": "2509.09071", "title": "Understanding Economic Tradeoffs Between Human and AI Agents in Bargaining Games", "authors": ["Crystal Qian", "Kehang Zhu", "John Horton", "Benjamin S. Manning", "Vivian Tsai", "James Wexler", "Nithum Thain"], "abstract": "Coordination tasks traditionally performed by humans are increasingly being delegated to autonomous agents. As this pattern progresses, it becomes critical to evaluate not only these agents' performance but also the processes through which they negotiate in dynamic, multi-agent environments. Furthermore, different agents exhibit distinct advantages: traditional statistical agents, such as Bayesian models, may excel under well-specified conditions, whereas large language models (LLMs) can generalize across contexts. In this work, we compare humans (N = 216), LLMs (GPT-4o, Gemini 1.5 Pro), and Bayesian agents in a dynamic negotiation setting that enables direct, identical-condition comparisons across populations, capturing both outcomes and behavioral dynamics. Bayesian agents extract the highest surplus through aggressive optimization, at the cost of frequent trade rejections. Humans and LLMs can achieve similar overall surplus, but through distinct behaviors: LLMs favor conservative, concessionary trades with few rejections, while humans employ more strategic, risk-taking, and fairness-oriented behaviors. Thus, we find that performance parity -- a common benchmark in agent evaluation -- can conceal fundamental differences in process and alignment, which are critical for practical deployment in real-world coordination tasks.", "subjects": "Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT); Human-Computer Interaction (cs.HC)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.09071.pdf", "abstract_url": "https://arxiv.org/abs/2509.09071", "categories": ["Artificial Intelligence (cs.AI)", "Computer Science and Game Theory (cs.GT)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文比较了人类、大语言模型（LLM）和贝叶斯代理在动态谈判游戏中的表现，发现性能相似但行为差异显著，强调过程评估对实际部署的重要性。", "motivation": "随着自主代理越来越多地处理协调任务，需要评估其在动态多代理环境中的谈判过程和性能差异，以优化实际应用。", "method": "在相同条件下比较人类（N=216）、LLM（GPT-4o、Gemini 1.5 Pro）和贝叶斯代理在动态谈判游戏中的行为和结果。", "result": "贝叶斯代理通过激进优化获得最高剩余但拒绝率高；人类和LLM剩余相似，但LLM行为保守、让步多，人类行为更战略、冒险和公平导向。", "conclusion": "性能平等可能掩盖过程和一致性差异，这对现实世界协调任务的部署至关重要。"}}
{"id": "2509.08970", "title": "Global Constraint LLM Agents for Text-to-Model Translation", "authors": ["Junyang Cai", "Serdar Kadioglu", "Bistra Dilkina"], "abstract": "Natural language descriptions of optimization or satisfaction problems are challenging to translate into correct MiniZinc models, as this process demands both logical reasoning and constraint programming expertise. We introduce a framework that addresses this challenge with an agentic approach: multiple specialized large language model (LLM) agents decompose the modeling task by global constraint type. Each agent is dedicated to detecting and generating code for a specific class of global constraint, while a final assembler agent integrates these constraint snippets into a complete MiniZinc model. By dividing the problem into smaller, well-defined sub-tasks, each LLM handles a simpler reasoning challenge, potentially reducing overall complexity. We conduct initial experiments with several LLMs and show better performance against baselines such as one-shot prompting and chain-of-thought prompting. Finally, we outline a comprehensive roadmap for future work, highlighting potential enhancements and directions for improvement.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.08970.pdf", "abstract_url": "https://arxiv.org/abs/2509.08970", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种基于多智能体LLM的框架，用于将自然语言描述的优化或满足问题分解并转换为MiniZinc模型，通过专业化代理处理全局约束，实验显示优于基线方法。", "motivation": "解决将自然语言描述的优化或满足问题准确翻译为MiniZinc模型的挑战，该过程需要逻辑推理和约束编程专业知识，但当前方法存在复杂性高的问题。", "method": "采用多智能体方法，多个专业化LLM代理按全局约束类型分解任务，每个代理检测和生成特定约束代码，最后由组装代理整合成完整模型。", "result": "初步实验表明，该框架在多个LLM上表现优于一次性提示和思维链提示等基线方法。", "conclusion": "该方法通过任务分解降低了复杂性，为文本到模型翻译提供了有效途径，并提出了未来改进路线图。"}}
{"id": "2509.09154", "title": "Mind Meets Space: Rethinking Agentic Spatial Intelligence from a Neuroscience-inspired Perspective", "authors": ["Bui Duc Manh", "Soumyaratna Debnath", "Zetong Zhang", "Shriram Damodaran", "Arvind Kumar", "Yueyi Zhang", "Lu Mi", "Erik Cambria", "Lin Wang"], "abstract": "Recent advances in agentic AI have led to systems capable of autonomous task execution and language-based reasoning, yet their spatial reasoning abilities remain limited and underexplored, largely constrained to symbolic and sequential processing. In contrast, human spatial intelligence, rooted in integrated multisensory perception, spatial memory, and cognitive maps, enables flexible, context-aware decision-making in unstructured environments. Therefore, bridging this gap is critical for advancing Agentic Spatial Intelligence toward better interaction with the physical 3D world. To this end, we first start from scrutinizing the spatial neural models as studied in computational neuroscience, and accordingly introduce a novel computational framework grounded in neuroscience principles. This framework maps core biological functions to six essential computation modules: bio-inspired multimodal sensing, multi-sensory integration, egocentric-allocentric conversion, an artificial cognitive map, spatial memory, and spatial reasoning. Together, these modules form a perspective landscape for agentic spatial reasoning capability across both virtual and physical environments. On top, we conduct a framework-guided analysis of recent methods, evaluating their relevance to each module and identifying critical gaps that hinder the development of more neuroscience-grounded spatial reasoning modules. We further examine emerging benchmarks and datasets and explore potential application domains ranging from virtual to embodied systems, such as robotics. Finally, we outline potential research directions, emphasizing the promising roadmap that can generalize spatial reasoning across dynamic or unstructured environments. We hope this work will benefit the research community with a neuroscience-grounded perspective and a structured pathway. Our project page can be found at Github.", "subjects": "Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "comments": "54 pages, journal", "pdf_url": "https://arxiv.org/pdf/2509.09154.pdf", "abstract_url": "https://arxiv.org/abs/2509.09154", "categories": ["Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文从神经科学角度提出一个计算框架，以增强AI代理的空间智能，通过六个模块模拟人类空间认知，分析现有方法、基准和应用，并指出未来研究方向。", "motivation": "解决当前AI代理空间推理能力有限的问题，因其主要依赖符号和序列处理，而人类空间智能基于多感官整合和认知地图，需弥合此差距以提升与物理3D世界的交互。", "method": "基于计算神经科学的空间神经模型，引入一个包含生物启发多模态感知、多感官整合、自我-异我转换、人工认知地图、空间记忆和空间推理的六模块计算框架。", "result": "框架分析揭示了现有方法的不足和关键空白，评估了基准和数据集，并探讨了在虚拟和实体系统（如机器人）中的应用潜力。", "conclusion": "工作提供了一个神经科学基础视角和结构化路径，强调推广空间推理到动态或非结构化环境的路线图，有望推动研究社区发展。"}}
{"id": "2509.09210", "title": "ProgD: Progressive Multi-scale Decoding with Dynamic Graphs for Joint Multi-agent Motion Forecasting", "authors": ["Xing Gao", "Zherui Huang", "Weiyao Lin", "Xiao Sun"], "abstract": "Accurate motion prediction of surrounding agents is crucial for the safe planning of autonomous vehicles. Recent advancements have extended prediction techniques from individual agents to joint predictions of multiple interacting agents, with various strategies to address complex interactions within future motions of agents. However, these methods overlook the evolving nature of these interactions. To address this limitation, we propose a novel progressive multi-scale decoding strategy, termed ProgD, with the help of dynamic heterogeneous graph-based scenario modeling. In particular, to explicitly and comprehensively capture the evolving social interactions in future scenarios, given their inherent uncertainty, we design a progressive modeling of scenarios with dynamic heterogeneous graphs. With the unfolding of such dynamic heterogeneous graphs, a factorized architecture is designed to process the spatio-temporal dependencies within future scenarios and progressively eliminate uncertainty in future motions of multiple agents. Furthermore, a multi-scale decoding procedure is incorporated to improve on the future scenario modeling and consistent prediction of agents' future motion. The proposed ProgD achieves state-of-the-art performance on the INTERACTION multi-agent prediction benchmark, ranking $1^{st}$, and the Argoverse 2 multi-world forecasting benchmark.", "subjects": "Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.09210.pdf", "abstract_url": "https://arxiv.org/abs/2509.09210", "categories": ["Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出ProgD方法，通过动态异构图和渐进多尺度解码，改进多智能体运动预测，在基准测试中达到最先进性能。", "motivation": "解决现有方法忽视智能体间交互动态演变的问题，以提高自动驾驶车辆的安全规划。", "method": "使用动态异构图建模场景，结合渐进多尺度解码处理时空依赖和不确定性。", "result": "在INTERACTION和Argoverse 2基准测试中排名第一，表现优异。", "conclusion": "ProgD方法有效捕捉交互动态，提升预测准确性，对自动驾驶有重要应用价值。"}}
{"id": "2509.09215", "title": "Enabling Regulatory Multi-Agent Collaboration: Architecture, Challenges, and Solutions", "authors": ["Qinnan Hu", "Yuntao Wang", "Yuan Gao", "Zhou Su", "Linkang Du"], "abstract": "Large language models (LLMs)-empowered autonomous agents are transforming both digital and physical environments by enabling adaptive, multi-agent collaboration. While these agents offer significant opportunities across domains such as finance, healthcare, and smart manufacturing, their unpredictable behaviors and heterogeneous capabilities pose substantial governance and accountability challenges. In this paper, we propose a blockchain-enabled layered architecture for regulatory agent collaboration, comprising an agent layer, a blockchain data layer, and a regulatory application layer. Within this framework, we design three key modules: (i) an agent behavior tracing and arbitration module for automated accountability, (ii) a dynamic reputation evaluation module for trust assessment in collaborative scenarios, and (iii) a malicious behavior forecasting module for early detection of adversarial activities. Our approach establishes a systematic foundation for trustworthy, resilient, and scalable regulatory mechanisms in large-scale agent ecosystems. Finally, we discuss the future research directions for blockchain-enabled regulatory frameworks in multi-agent systems.", "subjects": "Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)", "comments": "7 pages, 6 figures", "pdf_url": "https://arxiv.org/pdf/2509.09215.pdf", "abstract_url": "https://arxiv.org/abs/2509.09215", "categories": ["Artificial Intelligence (cs.AI)", "Cryptography and Security (cs.CR)"], "matching_keywords": ["agent"], "AI": {"tldr": "提出基于区块链的分层架构，通过行为追踪、声誉评估和恶意行为预测模块，实现多智能体系统中的可信、弹性和可扩展监管协作。", "motivation": "解决大型语言模型驱动的自主智能体在协作中不可预测行为和异质能力带来的治理与问责挑战。", "method": "设计区块链支持的分层架构，包括智能体层、区块链数据层和监管应用层，并集成行为追踪、声誉评估和恶意行为预测模块。", "result": "建立了系统性基础，支持大规模智能体生态系统中的可信监管机制。", "conclusion": "区块链框架为多智能体系统提供了有效的监管解决方案，并指出了未来研究方向。"}}
{"id": "2509.09245", "title": "Jupiter: Enhancing LLM Data Analysis Capabilities via Notebook and Inference-Time Value-Guided Search", "authors": ["Shuocheng Li", "Yihao Liu", "Silin Du", "Wenxuan Zeng", "Zhe Xu", "Mengyu Zhou", "Yeye He", "Haoyu Dong", "Shi Han", "Dongmei Zhang"], "abstract": "Large language models (LLMs) have shown great promise in automating data science workflows, but existing models still struggle with multi-step reasoning and tool use, which limits their effectiveness on complex data analysis tasks. To address this, we propose a scalable pipeline that extracts high-quality, tool-based data analysis tasks and their executable multi-step solutions from real-world Jupyter notebooks and associated data files. Using this pipeline, we introduce NbQA, a large-scale dataset of standardized task-solution pairs that reflect authentic tool-use patterns in practical data science scenarios. To further enhance multi-step reasoning, we present Jupiter, a framework that formulates data analysis as a search problem and applies Monte Carlo Tree Search (MCTS) to generate diverse solution trajectories for value model learning. During inference, Jupiter combines the value model and node visit counts to efficiently collect executable multi-step plans with minimal search steps. Experimental results show that Qwen2.5-7B and 14B-Instruct models on NbQA solve 77.82% and 86.38% of tasks on InfiAgent-DABench, respectively-matching or surpassing GPT-4o and advanced agent frameworks. Further evaluations demonstrate improved generalization and stronger tool-use reasoning across diverse multi-step reasoning tasks.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.09245.pdf", "abstract_url": "https://arxiv.org/abs/2509.09245", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "Jupiter框架通过从Jupyter笔记本提取高质量任务-解决方案对，并使用MCTS和价值模型增强LLM的多步推理能力，显著提升数据科学任务的解决率。", "motivation": "解决大型语言模型在复杂数据分析任务中多步推理和工具使用方面的不足。", "method": "构建NbQA数据集，应用蒙特卡洛树搜索和价值模型进行推理时搜索，生成可执行的多步计划。", "result": "Qwen2.5-7B和14B-Instruct模型在NbQA上分别解决77.82%和86.38%的任务，性能匹配或超越GPT-4o和先进代理框架。", "conclusion": "Jupiter框架有效提升了LLM的数据分析能力，具有更好的泛化性和工具使用推理。"}}
{"id": "2509.09272", "title": "Fusing Knowledge and Language: A Comparative Study of Knowledge Graph-Based Question Answering with LLMs", "authors": ["Vaibhav Chaudhary", "Neha Soni", "Narotam Singh", "Amita Kapoor"], "abstract": "Knowledge graphs, a powerful tool for structuring information through relational triplets, have recently become the new front-runner in enhancing question-answering systems. While traditional Retrieval Augmented Generation (RAG) approaches are proficient in fact-based and local context-based extraction from concise texts, they encounter limitations when addressing the thematic and holistic understanding of complex, extensive texts, requiring a deeper analysis of both text and context. This paper presents a comprehensive technical comparative study of three different methodologies for constructing knowledge graph triplets and integrating them with Large Language Models (LLMs) for question answering: spaCy, Stanford CoreNLP-OpenIE, and GraphRAG, all leveraging open source technologies. We evaluate the effectiveness, feasibility, and adaptability of these methods by analyzing their capabilities, state of development, and their impact on the performance of LLM-based question answering. Experimental results indicate that while OpenIE provides the most comprehensive coverage of triplets, GraphRAG demonstrates superior reasoning abilities among the three. We conclude with a discussion on the strengths and limitations of each method and provide insights into future directions for improving knowledge graph-based question answering.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "46 pages, 4 figures, 17 tables", "pdf_url": "https://arxiv.org/pdf/2509.09272.pdf", "abstract_url": "https://arxiv.org/abs/2509.09272", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文比较了三种知识图谱构建方法（spaCy、Stanford CoreNLP-OpenIE、GraphRAG）与LLMs结合用于问答的效果，发现OpenIE覆盖最广，GraphRAG推理能力最强。", "motivation": "解决传统RAG方法在处理复杂、长文本时对主题和整体理解不足的问题，通过知识图谱增强问答系统。", "method": "使用spaCy、Stanford CoreNLP-OpenIE和GraphRAG构建知识图谱三元组，并与LLMs集成进行问答，评估其有效性、可行性和适应性。", "result": "实验结果显示，OpenIE提供最全面的三元组覆盖，而GraphRAG在推理能力上表现最优。", "conclusion": "讨论了各方法的优缺点，并提出了未来改进知识图谱问答的方向。"}}
{"id": "2509.09292", "title": "LightAgent: Production-level Open-source Agentic AI Framework", "authors": ["Weige Cai", "Tong Zhu", "Jinyi Niu", "Ruiqi Hu", "Lingyao Li", "Tenglong Wang", "Xiaowu Dai", "Weining Shen", "Liwen Zhang"], "abstract": "With the rapid advancement of large language models (LLMs), Multi-agent Systems (MAS) have achieved significant progress in various application scenarios. However, substantial challenges remain in designing versatile, robust, and efficient platforms for agent deployment. To address these limitations, we propose \\textbf{LightAgent}, a lightweight yet powerful agentic framework, effectively resolving the trade-off between flexibility and simplicity found in existing frameworks. LightAgent integrates core functionalities such as Memory (mem0), Tools, and Tree of Thought (ToT), while maintaining an extremely lightweight structure. As a fully open-source solution, it seamlessly integrates with mainstream chat platforms, enabling developers to easily build self-learning agents. We have released LightAgent at \\href{", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.09292.pdf", "abstract_url": "https://arxiv.org/abs/2509.09292", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "LightAgent是一个轻量级、开源的多代理系统框架，旨在解决现有框架在灵活性与简洁性之间的权衡问题，集成核心功能如内存、工具和思维树，易于与主流聊天平台集成。", "motivation": "随着大语言模型的发展，多代理系统在应用中面临设计通用、鲁棒和高效平台的挑战，现有框架在灵活性与简洁性之间存在不足。", "method": "提出LightAgent框架，集成内存（mem0）、工具和思维树（ToT）等核心功能，保持轻量级结构，并作为开源解决方案与主流聊天平台无缝集成。", "result": "LightAgent有效解决了灵活性与简洁性的权衡，使开发者能轻松构建自学习代理，并已公开发布。", "conclusion": "LightAgent提供了一个强大且易用的代理部署平台，推动了多代理系统的实际应用和发展。"}}
{"id": "2509.09234", "title": "Agentic LLMs for Question Answering over Tabular Data", "authors": ["Rishit Tyagi", "Mohit Gupta", "Rahul Bouri"], "abstract": "Question Answering over Tabular Data (Table QA) presents unique challenges due to the diverse structure, size, and data types of real-world tables. The SemEval 2025 Task 8 (DataBench) introduced a benchmark composed of large-scale, domain-diverse datasets to evaluate the ability of models to accurately answer structured queries. We propose a Natural Language to SQL (NL-to-SQL) approach leveraging large language models (LLMs) such as GPT-4o, GPT-4o-mini, and DeepSeek v2:16b to generate SQL queries dynamically. Our system follows a multi-stage pipeline involving example selection, SQL query generation, answer extraction, verification, and iterative refinement. Experiments demonstrate the effectiveness of our approach, achieving 70.5\\% accuracy on DataBench QA and 71.6\\% on DataBench Lite QA, significantly surpassing baseline scores of 26\\% and 27\\% respectively. This paper details our methodology, experimental results, and alternative approaches, providing insights into the strengths and limitations of LLM-driven Table QA.", "subjects": "Computation and Language (cs.CL)", "comments": "Accepted at ACL workshop SemEval 2025", "pdf_url": "https://arxiv.org/pdf/2509.09234.pdf", "abstract_url": "https://arxiv.org/abs/2509.09234", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种基于大型语言模型（如GPT-4o、GPT-4o-mini和DeepSeek v2:16b）的自然语言到SQL方法，用于表格数据问答，通过多阶段管道实现动态SQL查询生成，在DataBench基准测试中准确率显著超越基线。", "motivation": "解决表格数据问答（Table QA）中由于表格结构、大小和数据类型多样性带来的挑战，提升模型在SemEval 2025 Task 8基准上的表现。", "method": "使用LLMs进行NL-to-SQL转换，采用多阶段管道，包括示例选择、SQL查询生成、答案提取、验证和迭代优化。", "result": "在DataBench QA和DataBench Lite QA上分别达到70.5%和71.6%的准确率，显著高于基线的26%和27%。", "conclusion": "LLM驱动的Table QA方法有效，但存在局限性，论文提供了方法论和实验结果，为未来研究提供见解。"}}
{"id": "2509.09321", "title": "Towards Adaptive ML Benchmarks: Web-Agent-Driven Construction, Domain Expansion, and Metric Optimization", "authors": ["Hangyi Jia", "Yuxi Qian", "Hanwen Tong", "Xinhui Wu", "Lin Chen", "Feng Wei"], "abstract": "Recent advances in large language models (LLMs) have enabled the emergence of general-purpose agents for automating end-to-end machine learning (ML) workflows, including data analysis, feature engineering, model training, and competition solving. However, existing benchmarks remain limited in task coverage, domain diversity, difficulty modeling, and evaluation rigor, failing to capture the full capabilities of such agents in realistic settings. We present TAM Bench, a diverse, realistic, and structured benchmark for evaluating LLM-based agents on end-to-end ML tasks. TAM Bench features three key innovations: (1) A browser automation and LLM-based task acquisition system that automatically collects and structures ML challenges from platforms such as Kaggle, AIcrowd, and Biendata, spanning multiple task types and data modalities (e.g., tabular, text, image, graph, audio); (2) A leaderboard-driven difficulty modeling mechanism that estimates task complexity using participant counts and score dispersion, enabling scalable and objective task calibration; (3) A multi-dimensional evaluation framework incorporating performance, format compliance, constraint adherence, and task generalization. Based on 150 curated AutoML tasks, we construct three benchmark subsets of different sizes -- Lite, Medium, and Full -- designed for varying evaluation scenarios. The Lite version, with 18 tasks and balanced coverage across modalities and difficulty levels, serves as a practical testbed for daily benchmarking and comparative studies.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.09321.pdf", "abstract_url": "https://arxiv.org/abs/2509.09321", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "提出TAM Bench基准，通过自动化系统收集和结构化ML任务，评估LLM代理在端到端ML工作流中的能力，包括任务获取、难度建模和多维评估。", "motivation": "现有基准在任务覆盖、领域多样性、难度建模和评估严谨性方面不足，无法充分评估LLM代理在真实场景中的能力。", "method": "使用浏览器自动化和LLM的任务获取系统收集ML挑战，基于排行榜建模难度，并采用多维评估框架。", "result": "基于150个AutoML任务构建了三个不同规模的基准子集，Lite版本提供18个任务，覆盖多种模态和难度级别。", "conclusion": "TAM Bench提供了一个多样化、真实且结构化的基准，用于评估和比较LLM代理在ML任务中的性能。"}}
{"id": "2509.09360", "title": "MetaRAG: Metamorphic Testing for Hallucination Detection in RAG Systems", "authors": ["Channdeth Sok", "David Luz", "Yacine Haddam"], "abstract": "Large Language Models (LLMs) are increasingly deployed in enterprise applications, yet their reliability remains limited by hallucinations, i.e., confident but factually incorrect information. Existing detection approaches, such as SelfCheckGPT and MetaQA, primarily target standalone LLMs and do not address the unique challenges of Retrieval-Augmented Generation (RAG) systems, where responses must be consistent with retrieved evidence. We therefore present MetaRAG, a metamorphic testing framework for hallucination detection in Retrieval-Augmented Generation (RAG) systems. MetaRAG operates in a real-time, unsupervised, black-box setting, requiring neither ground-truth references nor access to model internals, making it suitable for proprietary and high-stakes domains. The framework proceeds in four stages: (1) decompose answers into atomic factoids, (2) generate controlled mutations of each factoid using synonym and antonym substitutions, (3) verify each variant against the retrieved context (synonyms are expected to be entailed and antonyms contradicted), and (4) aggregate penalties for inconsistencies into a response-level hallucination score. Crucially for identity-aware AI, MetaRAG localizes unsupported claims at the factoid span where they occur (e.g., pregnancy-specific precautions, LGBTQ+ refugee rights, or labor eligibility), allowing users to see flagged spans and enabling system designers to configure thresholds and guardrails for identity-sensitive queries. Experiments on a proprietary enterprise dataset illustrate the effectiveness of MetaRAG for detecting hallucinations and enabling trustworthy deployment of RAG-based conversational agents. We also outline a topic-based deployment design that translates MetaRAG's span-level scores into identity-aware safeguards; this design is discussed but not evaluated in our experiments.", "subjects": "Computation and Language (cs.CL)", "comments": "under review", "pdf_url": "https://arxiv.org/pdf/2509.09360.pdf", "abstract_url": "https://arxiv.org/abs/2509.09360", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "MetaRAG是一个用于检测RAG系统中幻觉的元形态测试框架，通过分解答案、生成变异、验证一致性和聚合分数来操作，无需真实参考或模型内部访问，适用于高风险领域。", "motivation": "解决RAG系统中幻觉检测的挑战，现有方法如SelfCheckGPT和MetaQA主要针对独立LLMs，无法处理RAG的独特需求，即响应必须与检索证据一致。", "method": "使用元形态测试，包括四个阶段：分解答案为原子事实、生成同义词和反义词变异、验证变异与检索上下文的一致性、聚合不一致性分数为幻觉得分。", "result": "在专有企业数据集上的实验显示MetaRAG能有效检测幻觉，支持可信部署，并提出了基于主题的部署设计用于身份感知保障。", "conclusion": "MetaRAG提供了一种无监督、黑盒的幻觉检测方法，适用于RAG系统，能定位不支持的声明并支持身份敏感查询的阈值配置，促进可靠AI部署。"}}
{"id": "2509.09356", "title": "Curriculum-Based Multi-Tier Semantic Exploration via Deep Reinforcement Learning", "authors": ["Abdel Hakim Drid", "Vincenzo Suriani", "Daniele Nardi", "Abderrezzak Debilou"], "abstract": "Navigating and understanding complex and unknown environments autonomously demands more than just basic perception and movement from embodied agents. Truly effective exploration requires agents to possess higher-level cognitive abilities, the ability to reason about their surroundings, and make more informed decisions regarding exploration strategies. However, traditional RL approaches struggle to balance efficient exploration and semantic understanding due to limited cognitive capabilities embedded in the small policies for the agents, leading often to human drivers when dealing with semantic exploration. In this paper, we address this challenge by presenting a novel Deep Reinforcement Learning (DRL) architecture that is specifically designed for resource efficient semantic exploration. A key methodological contribution is the integration of a Vision-Language Model (VLM) common-sense through a layered reward function. The VLM query is modeled as a dedicated action, allowing the agent to strategically query the VLM only when deemed necessary for gaining external guidance, thereby conserving resources. This mechanism is combined with a curriculum learning strategy designed to guide learning at different levels of complexity to ensure robust and stable learning. Our experimental evaluation results convincingly demonstrate that our agent achieves significantly enhanced object discovery rates and develops a learned capability to effectively navigate towards semantically rich regions. Furthermore, it also shows a strategic mastery of when to prompt for external environmental information. By demonstrating a practical and scalable method for embedding common-sense semantic reasoning with autonomous agents, this research provides a novel approach to pursuing a fully intelligent and self-guided exploration in robotics.", "subjects": "Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": "The 19th International Conference on Intelligent Autonomous Systems (IAS 19), 2025, Genoa", "pdf_url": "https://arxiv.org/pdf/2509.09356.pdf", "abstract_url": "https://arxiv.org/abs/2509.09356", "categories": ["Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "提出一种结合课程学习和分层奖励的深度强化学习架构，通过策略性查询视觉语言模型实现高效语义探索，提升对象发现率和导航能力。", "motivation": "解决传统强化学习在平衡高效探索和语义理解方面的不足，由于认知能力有限，常需人工干预。", "method": "集成视觉语言模型的常识推理作为分层奖励，将查询建模为动作，结合课程学习策略指导不同复杂度学习。", "result": "实验显示，代理显著提高对象发现率，有效导航至语义丰富区域，并掌握策略性外部信息查询。", "conclusion": "提供一种实用且可扩展的方法，嵌入常识语义推理，推动机器人全智能自主探索。"}}
{"id": "2509.09467", "title": "Inteligencia Artificial jurídica y el desafío de la veracidad: análisis de alucinaciones, optimización de RAG y principios para una integración responsable", "authors": ["Alex Dantart"], "abstract": "This technical report analyzes the challenge of \"hallucinations\" (false information) in LLMs applied to law. It examines their causes, manifestations, and the effectiveness of the RAG mitigation strategy, highlighting its limitations and proposing holistic optimizations. The paper explores the ethical and regulatory implications, emphasizing human oversight as an irreplaceable role. It concludes that the solution lies not in incrementally improving generative models, but in adopting a \"consultative\" AI paradigm that prioritizes veracity and traceability, acting as a tool to amplify, not replace, professional judgment.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "in Spanish and English languages", "pdf_url": "https://arxiv.org/pdf/2509.09467.pdf", "abstract_url": "https://arxiv.org/abs/2509.09467", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "该技术报告分析了大型语言模型在法律应用中产生'幻觉'（虚假信息）的问题，探讨其原因、表现、RAG缓解策略的有效性及其局限性，并提出整体优化方案。", "motivation": "解决法律领域AI应用中LLMs产生虚假信息的问题，以确保信息的真实性和可靠性。", "method": "分析幻觉的原因和表现，评估RAG策略，并提出优化方法和伦理监管原则，强调人类监督的重要性。", "result": "RAG策略有局限性，需通过整体优化和咨询式AI范式来优先考虑真实性和可追溯性，而非仅改进生成模型。", "conclusion": "解决方案在于采用咨询式AI范式，强调真实性和可追溯性，作为工具增强而非替代专业判断，需要人类监督和伦理整合。"}}
{"id": "2509.09498", "title": "SEDM: Scalable Self-Evolving Distributed Memory for Agents", "authors": ["Haoran Xu", "Jiacong Hu", "Ke Zhang", "Lei Yu", "Yuxin Tang", "Xinyuan Song", "Yiqun Duan", "Lynn Ai", "Bill Shi"], "abstract": "Long-term multi-agent systems inevitably generate vast amounts of trajectories and historical interactions, which makes efficient memory management essential for both performance and scalability. Existing methods typically depend on vector retrieval and hierarchical storage, yet they are prone to noise accumulation, uncontrolled memory expansion, and limited generalization across domains. To address these challenges, we present SEDM, Self-Evolving Distributed Memory, a verifiable and adaptive framework that transforms memory from a passive repository into an active, self-optimizing component. SEDM integrates verifiable write admission based on reproducible replay, a self-scheduling memory controller that dynamically ranks and consolidates entries according to empirical utility, and cross-domain knowledge diffusion that abstracts reusable insights to support transfer across heterogeneous tasks. Evaluations on benchmark datasets demonstrate that SEDM improves reasoning accuracy while reducing token overhead compared with strong memory baselines, and further enables knowledge distilled from fact verification to enhance multi-hop reasoning. The results highlight SEDM as a scalable and sustainable memory mechanism for open-ended multi-agent collaboration. The code will be released in the later stage of this project.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.09498.pdf", "abstract_url": "https://arxiv.org/abs/2509.09498", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "SEDM是一种可扩展的自进化分布式内存框架，用于多智能体系统，通过可验证写入、动态排名和跨域知识扩散，提高推理准确性并减少开销。", "motivation": "解决多智能体系统中轨迹和交互数据量大导致的噪声积累、内存膨胀和跨域泛化受限问题。", "method": "集成可验证写入基于可重现回放、自调度内存控制器动态排名和整合条目、跨域知识扩散抽象可重用见解。", "result": "在基准数据集上，SEDM相比基线提高了推理准确性，减少了token开销，并支持从事实验证中蒸馏知识增强多跳推理。", "conclusion": "SEDM是开放多智能体协作的可扩展和可持续内存机制，代码将发布。"}}
{"id": "2509.09560", "title": "Boosting Embodied AI Agents through Perception-Generation Disaggregation and Asynchronous Pipeline Execution", "authors": ["Shulai Zhang", "Ao Xu", "Quan Chen", "Han Zhao", "Weihao Cui", "Ningxin Zheng", "Haibin Lin", "Xin Liu", "Minyi Guo"], "abstract": "Embodied AI systems operate in dynamic environments, requiring seamless integration of perception and generation modules to process high-frequency input and output demands. Traditional sequential computation patterns, while effective in ensuring accuracy, face significant limitations in achieving the necessary \"thinking\" frequency for real-world applications. In this work, we present Auras, an algorithm-system co-designed inference framework to optimize the inference frequency of embodied AI agents. Auras disaggregates the perception and generation and provides controlled pipeline parallelism for them to achieve high and stable throughput. Faced with the data staleness problem that appears when the parallelism is increased, Auras establishes a public context for perception and generation to share, thereby promising the accuracy of embodied agents. Experimental results show that Auras improves throughput by 2.54x on average while achieving 102.7% of the original accuracy, demonstrating its efficacy in overcoming the constraints of sequential computation and providing high throughput.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.09560.pdf", "abstract_url": "https://arxiv.org/abs/2509.09560", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "Auras框架通过解耦感知与生成模块并采用异步流水线执行，提升具身AI代理的推理频率，实现高吞吐量同时保持准确性。", "motivation": "解决传统顺序计算模式在动态环境中无法满足高频率输入输出需求的问题，优化具身AI系统的实时性能。", "method": "算法-系统协同设计，解耦感知和生成模块，提供受控的流水线并行，并建立共享公共上下文以处理数据过时问题。", "result": "实验显示吞吐量平均提高2.54倍，准确性达到原系统的102.7%，证明其有效性。", "conclusion": "Auras框架成功克服顺序计算限制，提供高吞吐和稳定性能，适用于实时具身AI应用。"}}
{"id": "2509.08835", "title": "Deep opacity and AI: A threat to XAI and to privacy protection mechanisms", "authors": ["Vincent C. Müller"], "abstract": "It is known that big data analytics and AI pose a threat to privacy, and that some of this is due to some kind of \"black box problem\" in AI. I explain how this becomes a problem in the context of justification for judgments and actions. Furthermore, I suggest distinguishing three kinds of opacity: 1) the subjects do not know what the system does (\"shallow opacity\"), 2) the analysts do not know what the system does (\"standard black box opacity\"), or 3) the analysts cannot possibly know what the system might do (\"deep opacity\"). If the agents, data subjects as well as analytics experts, operate under opacity, then these agents cannot provide justifications for judgments that are necessary to protect privacy, e.g., they cannot give \"informed consent\", or guarantee \"anonymity\". It follows from these points that agents in big data analytics and AI often cannot make the judgments needed to protect privacy. So I conclude that big data analytics makes the privacy problems worse and the remedies less effective. As a positive note, I provide a brief outlook on technical ways to handle this situation.", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.08835.pdf", "abstract_url": "https://arxiv.org/abs/2509.08835", "categories": ["Computers and Society (cs.CY)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了大数据分析和AI中的不透明性问题，区分了三种不透明度类型，并指出这加剧了隐私威胁，同时简要展望了技术解决方案。", "motivation": "解决AI和大数据分析中的'黑箱问题'对隐私保护和判断正当性的负面影响。", "method": "通过区分浅层不透明度、标准黑箱不透明度和深度不透明度，分析其对知情同意和匿名性的影响。", "result": "发现不透明性导致代理无法提供必要的隐私保护判断，使隐私问题恶化。", "conclusion": "大数据分析加剧了隐私问题并降低了补救措施的有效性，但技术方法可能提供出路。"}}
{"id": "2509.09677", "title": "The Illusion of Diminishing Returns: Measuring Long Horizon Execution in LLMs", "authors": ["Akshit Sinha", "Arvindh Arun", "Shashwat Goel", "Steffen Staab", "Jonas Geiping"], "abstract": "Does continued scaling of large language models (LLMs) yield diminishing returns? Real-world value often stems from the length of task an agent can complete. We start this work by observing the simple but counterintuitive fact that marginal gains in single-step accuracy can compound into exponential improvements in the length of a task a model can successfully complete. Then, we argue that failures of LLMs when simple tasks are made longer arise from mistakes in execution, rather than an inability to reason. We propose isolating execution capability, by explicitly providing the knowledge and plan needed to solve a long-horizon task. We find that larger models can correctly execute significantly more turns even when small models have 100\\% single-turn accuracy. We observe that the per-step accuracy of models degrades as the number of steps increases. This is not just due to long-context limitations -- curiously, we observe a self-conditioning effect -- models become more likely to make mistakes when the context contains their errors from prior turns. Self-conditioning does not reduce by just scaling the model size. In contrast, recent thinking models do not self-condition, and can also execute much longer tasks in a single turn. We conclude by benchmarking frontier thinking models on the length of task they can execute in a single turn. Overall, by focusing on the ability to execute, we hope to reconcile debates on how LLMs can solve complex reasoning problems yet fail at simple tasks when made longer, and highlight the massive benefits of scaling model size and sequential test-time compute for long-horizon tasks.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.09677.pdf", "abstract_url": "https://arxiv.org/abs/2509.09677", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨大型语言模型（LLM）规模扩展是否带来收益递减，通过隔离执行能力，发现更大模型在长任务中表现更好，但存在自条件错误，而思维模型无此问题。", "motivation": "解决LLM在简单任务变长时失败的问题，强调执行错误而非推理不足，以调和模型在复杂推理与长任务表现间的矛盾。", "method": "通过提供知识和计划隔离执行能力，测试模型在多步任务中的准确率，并比较不同规模模型和思维模型的表现。", "result": "更大模型能执行更多步骤，但准确率随步数增加而下降，自条件错误不随规模扩展减少；思维模型无自条件错误，能执行更长任务。", "conclusion": "聚焦执行能力可解释LLM表现差异，强调规模扩展和序列计算对长任务的重要性，思维模型表现更优。"}}
{"id": "2509.08859", "title": "Multi Robot Coordination in Highly Dynamic Environments: Tackling Asymmetric Obstacles and Limited Communication", "authors": ["Vincenzo Suriani", "Daniele Affinita", "Domenico D. Bloisi", "Daniele Nardi"], "abstract": "Coordinating a fully distributed multi-agent system (MAS) can be challenging when the communication channel has very limited capabilities in terms of sending rate and packet payload. When the MAS has to deal with active obstacles in a highly partially observable environment, the communication channel acquires considerable relevance. In this paper, we present an approach to deal with task assignments in extremely active scenarios, where tasks need to be frequently reallocated among the agents participating in the coordination process. Inspired by market-based task assignments, we introduce a novel distributed coordination method to orchestrate autonomous agents' actions efficiently in low communication scenarios. In particular, our algorithm takes into account asymmetric obstacles. While in the real world, the majority of obstacles are asymmetric, they are usually treated as symmetric ones, thus limiting the applicability of existing methods. To summarize, the presented architecture is designed to tackle scenarios where the obstacles are active and asymmetric, the communication channel is poor and the environment is partially observable. Our approach has been validated in simulation and in the real world, using a team of NAO robots during official RoboCup competitions. Experimental results show a notable reduction in task overlaps in limited communication settings, with a decrease of 52% in the most frequent reallocated task.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": "The 19th International Conference on Intelligent Autonomous Systems (IAS 19), 2025, Genoa", "pdf_url": "https://arxiv.org/pdf/2509.08859.pdf", "abstract_url": "https://arxiv.org/abs/2509.08859", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新颖的分布式协调方法，用于在通信受限、环境部分可观测且存在不对称障碍物的动态环境中高效协调多机器人系统，通过模拟和真实实验验证了任务重叠减少52%。", "motivation": "解决在通信能力有限、环境高度动态且部分可观测的情况下，多智能体系统协调任务分配的挑战，特别是处理不对称障碍物的问题。", "method": "基于市场机制的任务分配启发，开发了一种分布式协调算法，考虑不对称障碍物和低通信场景。", "result": "实验结果显示，在有限通信设置下，任务重叠显著减少，最常见重新分配任务减少了52%。", "conclusion": "该方法有效提升了多机器人系统在动态环境中的协调效率，具有实际应用潜力，如在RoboCup竞赛中验证。"}}
{"id": "2509.09629", "title": "Bridging the Capability Gap: Joint Alignment Tuning for Harmonizing LLM-based Multi-Agent Systems", "authors": ["Minghang Zhu", "Zhengliang Shi", "Zhiwei Xu", "Shiguang Wu", "Lingjie Wang", "Pengjie Ren", "Zhaochun Ren", "Zhumin Chen"], "abstract": "The advancement of large language models (LLMs) has enabled the construction of multi-agent systems to solve complex tasks by dividing responsibilities among specialized agents, such as a planning agent for subgoal generation and a grounding agent for executing tool-use actions. Most existing methods typically fine-tune these agents independently, leading to capability gaps among them with poor coordination. To address this, we propose MOAT, a Multi-Agent Joint Alignment Tuning framework that improves agents collaboration through iterative alignment. MOAT alternates between two key stages: (1) Planning Agent Alignment, which optimizes the planning agent to generate subgoal sequences that better guide the grounding agent; and (2) Grounding Agent Improving, which fine-tunes the grounding agent using diverse subgoal-action pairs generated by the agent itself to enhance its generalization capablity. Theoretical analysis proves that MOAT ensures a non-decreasing and progressively convergent training process. Experiments across six benchmarks demonstrate that MOAT outperforms state-of-the-art baselines, achieving average improvements of 3.1% on held-in tasks and 4.4% on held-out tasks.", "subjects": "Computation and Language (cs.CL)", "comments": "EMNLP 2025 Findings", "pdf_url": "https://arxiv.org/pdf/2509.09629.pdf", "abstract_url": "https://arxiv.org/abs/2509.09629", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文提出MOAT框架，通过联合对齐调优解决多智能体系统中的能力差距问题，提升协作性能，在多个基准测试中优于现有方法。", "motivation": "现有方法独立微调智能体导致能力差距和协调不佳，需要改进多智能体系统的协作。", "method": "使用MOAT框架，包括规划智能体对齐和接地智能体改进两个迭代阶段，通过理论分析确保训练过程收敛。", "result": "在六个基准测试中，MOAT平均提升3.1%（held-in任务）和4.4%（held-out任务），优于最先进基线。", "conclusion": "MOAT有效提升多智能体系统的协调和泛化能力，具有实际应用潜力。"}}
{"id": "2509.09594", "title": "ObjectReact: Learning Object-Relative Control for Visual Navigation", "authors": ["Sourav Garg", "Dustin Craggs", "Vineeth Bhat", "Lachlan Mares", "Stefan Podgorski", "Madhava Krishna", "Feras Dayoub", "Ian Reid"], "abstract": "Visual navigation using only a single camera and a topological map has recently become an appealing alternative to methods that require additional sensors and 3D maps. This is typically achieved through an \"image-relative\" approach to estimating control from a given pair of current observation and subgoal image. However, image-level representations of the world have limitations because images are strictly tied to the agent's pose and embodiment. In contrast, objects, being a property of the map, offer an embodiment- and trajectory-invariant world representation. In this work, we present a new paradigm of learning \"object-relative\" control that exhibits several desirable characteristics: a) new routes can be traversed without strictly requiring to imitate prior experience, b) the control prediction problem can be decoupled from solving the image matching problem, and c) high invariance can be achieved in cross-embodiment deployment for variations across both training-testing and mapping-execution settings. We propose a topometric map representation in the form of a \"relative\" 3D scene graph, which is used to obtain more informative object-level global path planning costs. We train a local controller, dubbed \"ObjectReact\", conditioned directly on a high-level \"WayObject Costmap\" representation that eliminates the need for an explicit RGB input. We demonstrate the advantages of learning object-relative control over its image-relative counterpart across sensor height variations and multiple navigation tasks that challenge the underlying spatial understanding capability, e.g., navigating a map trajectory in the reverse direction. We further show that our sim-only policy is able to generalize well to real-world indoor environments. Code and supplementary material are accessible via project page:", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Systems and Control (eess.SY)", "comments": "CoRL 2025; 23 pages including appendix", "pdf_url": "https://arxiv.org/pdf/2509.09594.pdf", "abstract_url": "https://arxiv.org/abs/2509.09594", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)", "Machine Learning (cs.LG)", "Systems and Control (eess.SY)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出ObjectReact，一种基于对象相对控制的视觉导航方法，使用相对3D场景图进行路径规划，减少对图像匹配的依赖，提高跨环境和跨部署的泛化能力。", "motivation": "解决图像相对控制在视觉导航中因图像与代理姿态绑定而导致的泛化性差问题，寻求更稳健的世界表示方法。", "method": "采用对象相对控制范式，构建相对3D场景图作为拓扑地图，训练本地控制器ObjectReact，基于WayObject Costmap进行控制预测，无需RGB输入。", "result": "在传感器高度变化和反向导航等任务中，ObjectReact优于图像相对方法，仿真策略能泛化到真实室内环境。", "conclusion": "对象相对控制提供更高泛化性和独立性，是视觉导航的有效改进，支持实际应用部署。"}}
{"id": "2509.09265", "title": "Harnessing Uncertainty: Entropy-Modulated Policy Gradients for Long-Horizon LLM Agents", "authors": ["Jiawei Wang", "Jiacai Liu", "Yuqian Fu", "Yingru Li", "Xintao Wang", "Yuan Lin", "Yu Yue", "Lin Zhang", "Yang Wang", "Ke Wang"], "abstract": "In long-horizon tasks, recent agents based on Large Language Models (LLMs) face a significant challenge that sparse, outcome-based rewards make it difficult to assign credit to intermediate steps. Previous methods mainly focus on creating dense reward signals to guide learning, either through traditional reinforcement learning techniques like inverse reinforcement learning or by using Process Reward Models for step-by-step feedback. In this paper, we identify a fundamental problem in the learning dynamics of LLMs: the magnitude of policy gradients is inherently coupled with the entropy, which leads to inefficient small updates for confident correct actions and potentially destabilizes large updates for uncertain ones. To resolve this, we propose Entropy-Modulated Policy Gradients (EMPG), a framework that re-calibrates the learning signal based on step-wise uncertainty and the final task outcome. EMPG amplifies updates for confident correct actions, penalizes confident errors, and attenuates updates from uncertain steps to stabilize exploration. We further introduce a bonus term for future clarity that encourages agents to find more predictable solution paths. Through comprehensive experiments on three challenging agent tasks, WebShop, ALFWorld, and Deep Search, we demonstrate that EMPG achieves substantial performance gains and significantly outperforms strong policy gradient baselines. Project page is at", "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL)", "comments": "ICLR 2026 Under review", "pdf_url": "https://arxiv.org/pdf/2509.09265.pdf", "abstract_url": "https://arxiv.org/abs/2509.09265", "categories": ["Machine Learning (cs.LG)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出熵调制策略梯度（EMPG）框架，通过基于不确定性和任务结果重新校准学习信号，解决长时程任务中LLM代理的信用分配问题，显著提升性能。", "motivation": "解决长时程任务中基于大型语言模型的代理因稀疏奖励导致中间步骤信用分配困难，以及策略梯度大小与熵耦合导致学习效率低和不稳定的问题。", "method": "使用熵调制策略梯度（EMPG）框架，基于步骤不确定性和最终任务结果重新校准学习信号，放大自信正确动作的更新、惩罚自信错误，并衰减不确定步骤的更新，同时引入未来清晰度奖励项。", "result": "在WebShop、ALFWorld和Deep Search等挑战性任务上，EMPG实现了显著的性能提升，并大幅优于强基线策略梯度方法。", "conclusion": "EMPG通过调制策略梯度有效稳定和加速学习，为长时程LLM代理提供了一种高效且稳定的强化学习解决方案。"}}
{"id": "2509.09651", "title": "Retrieval-Augmented Generation for Reliable Interpretation of Radio Regulations", "authors": ["Zakaria El Kassimi", "Fares Fourati", "Mohamed-Slim Alouini"], "abstract": "We study question answering in the domain of radio regulations, a legally sensitive and high-stakes area. We propose a telecom-specific Retrieval-Augmented Generation (RAG) pipeline and introduce, to our knowledge, the first multiple-choice evaluation set for this domain, constructed from authoritative sources using automated filtering and human validation. To assess retrieval quality, we define a domain-specific retrieval metric, under which our retriever achieves approximately 97% accuracy. Beyond retrieval, our approach consistently improves generation accuracy across all tested models. In particular, while naively inserting documents without structured retrieval yields only marginal gains for GPT-4o (less than 1%), applying our pipeline results in nearly a 12% relative improvement. These findings demonstrate that carefully targeted grounding provides a simple yet strong baseline and an effective domain-specific solution for regulatory question answering. All code and evaluation scripts, along with our derived question-answer dataset, are available at", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Signal Processing (eess.SP)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.09651.pdf", "abstract_url": "https://arxiv.org/abs/2509.09651", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)", "Signal Processing (eess.SP)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文研究了无线电法规领域的问答，提出了一个电信特定的检索增强生成（RAG）管道，并创建了首个多选评估集。检索准确率达97%，生成准确率显著提高，尤其在GPT-4o上相对提升近12%。", "motivation": "解决无线电法规这一法律敏感和高风险领域中的可靠问答问题，需要准确和可信的答案。", "method": "使用电信特定的RAG管道，包括自动化过滤和人工验证构建评估集，并定义领域特定检索指标。", "result": "检索准确率约97%，生成准确率在所有测试模型中一致提高，GPT-4o的相对改进近12%。", "conclusion": "针对性的检索增强为法规问答提供了简单而强大的基线解决方案，代码和数据集已公开。"}}
{"id": "2509.09208", "title": "Incentivizing Safer Actions in Policy Optimization for Constrained Reinforcement Learning", "authors": ["Somnath Hazra", "Pallab Dasgupta", "Soumyajit Dey"], "abstract": "Constrained Reinforcement Learning (RL) aims to maximize the return while adhering to predefined constraint limits, which represent domain-specific safety requirements. In continuous control settings, where learning agents govern system actions, balancing the trade-off between reward maximization and constraint satisfaction remains a significant challenge. Policy optimization methods often exhibit instability near constraint boundaries, resulting in suboptimal training performance. To address this issue, we introduce a novel approach that integrates an adaptive incentive mechanism in addition to the reward structure to stay within the constraint bound before approaching the constraint boundary. Building on this insight, we propose Incrementally Penalized Proximal Policy Optimization (IP3O), a practical algorithm that enforces a progressively increasing penalty to stabilize training dynamics. Through empirical evaluation on benchmark environments, we demonstrate the efficacy of IP3O compared to the performance of state-of-the-art Safe RL algorithms. Furthermore, we provide theoretical guarantees by deriving a bound on the worst-case error of the optimality achieved by our algorithm.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "11 pages, Accepted to the 34th International Joint Conference on Artificial Intelligence (IJCAI) 2025, Main Track", "pdf_url": "https://arxiv.org/pdf/2509.09208.pdf", "abstract_url": "https://arxiv.org/abs/2509.09208", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文提出了一种在约束强化学习中激励更安全行动的新方法，通过自适应激励机制和逐步增加的惩罚来稳定训练，实验和理论分析验证了其有效性。", "motivation": "解决在连续控制设置中，策略优化方法在约束边界附近的不稳定性问题，以平衡奖励最大化和约束满足之间的权衡。", "method": "引入了自适应激励机制和增量惩罚近端策略优化（IP3O）算法，通过逐步增加惩罚来稳定训练动态。", "result": "在基准环境上的实证评估显示，IP3O优于最先进的安全强化学习算法，并提供了理论保证，推导了最优性最坏情况误差的界限。", "conclusion": "该方法有效提升了约束强化学习的训练稳定性和性能，具有实际应用潜力。"}}
{"id": "2509.09219", "title": "Vejde: A Framework for Inductive Deep Reinforcement Learning Based on Factor Graph Color Refinement", "authors": ["Jakob Nyberg", "Pontus Johnson"], "abstract": "We present and evaluate Vejde; a framework which combines data abstraction, graph neural networks and reinforcement learning to produce inductive policy functions for decision problems with richly structured states, such as object classes and relations. MDP states are represented as data bases of facts about entities, and Vejde converts each state to a bipartite graph, which is mapped to latent states through neural message passing. The factored representation of both states and actions allows Vejde agents to handle problems of varying size and structure. We tested Vejde agents on eight problem domains defined in RDDL, with ten problem instances each, where policies were trained using both supervised and reinforcement learning. To test policy generalization, we separate problem instances in two sets, one for training and the other solely for testing. Test results on unseen instances for the Vejde agents were compared to MLP agents trained on each problem instance, as well as the online planning algorithm Prost. Our results show that Vejde policies in average generalize to the test instances without a significant loss in score. Additionally, the inductive agents received scores on unseen test instances that on average were close to the instance-specific MLP agents.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.09219.pdf", "abstract_url": "https://arxiv.org/abs/2509.09219", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "Vejde框架结合数据抽象、图神经网络和强化学习，为具有结构化状态的决策问题生成归纳策略函数，在未见实例上实现良好泛化。", "motivation": "解决决策问题中状态结构复杂（如对象类和关系）时，策略难以泛化到不同大小和结构的问题实例。", "method": "将MDP状态表示为实体事实数据库，转换为二分图，通过神经消息传递映射到潜在状态，使用监督和强化学习训练策略。", "result": "在RDDL定义的八个问题域测试中，Vejde策略在未见实例上得分接近实例特定MLP代理，且泛化性能优于在线规划算法Prost。", "conclusion": "Vejde框架有效支持归纳强化学习，提升策略的泛化能力，适用于变化规模的决策问题。"}}
