{"id": "2506.04606", "title": "SmartAvatar: Text- and Image-Guided Human Avatar Generation with VLM AI Agents", "authors": ["Alexander Huang-Menders", "Xinhang Liu", "Andy Xu", "Yuyao Zhang", "Chi-Keung Tang", "Yu-Wing Tai"], "abstract": "SmartAvatar is a vision-language-agent-driven framework for generating fully rigged, animation-ready 3D human avatars from a single photo or textual prompt. While diffusion-based methods have made progress in general 3D object generation, they continue to struggle with precise control over human identity, body shape, and animation readiness. In contrast, SmartAvatar leverages the commonsense reasoning capabilities of large vision-language models (VLMs) in combination with off-the-shelf parametric human generators to deliver high-quality, customizable avatars. A key innovation is an autonomous verification loop, where the agent renders draft avatars, evaluates facial similarity, anatomical plausibility, and prompt alignment, and iteratively adjusts generation parameters for convergence. This interactive, AI-guided refinement process promotes fine-grained control over both facial and body features, enabling users to iteratively refine their avatars via natural-language conversations. Unlike diffusion models that rely on static pre-trained datasets and offer limited flexibility, SmartAvatar brings users into the modeling loop and ensures continuous improvement through an LLM-driven procedural generation and verification system. The generated avatars are fully rigged and support pose manipulation with consistent identity and appearance, making them suitable for downstream animation and interactive applications. Quantitative benchmarks and user studies demonstrate that SmartAvatar outperforms recent text- and image-driven avatar generation systems in terms of reconstructed mesh quality, identity fidelity, attribute accuracy, and animation readiness, making it a versatile tool for realistic, customizable avatar creation on consumer-grade hardware.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "16 pages", "pdf_url": "https://arxiv.org/pdf/2506.04606.pdf", "abstract_url": "https://arxiv.org/abs/2506.04606", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "SmartAvatar是一个基于视觉语言代理的框架，用于从单张照片或文本提示生成完全绑定、可动画的3D人类头像。", "motivation": "解决扩散方法在人类身份、体型和动画准备方面的精确控制不足的问题。", "method": "利用大型视觉语言模型(VLMs)的常识推理能力与现成的参数化人类生成器结合，通过自主验证循环迭代调整生成参数。", "result": "在重建网格质量、身份保真度、属性准确性和动画准备方面优于最近的文本和图像驱动的头像生成系统。", "conclusion": "SmartAvatar是一个多功能工具，适用于在消费级硬件上创建逼真、可定制的头像。"}}
{"id": "2506.04363", "title": "WorldPrediction: A Benchmark for High-level World Modeling and Long-horizon Procedural Planning", "authors": ["Delong Chen", "Willy Chung", "Yejin Bang", "Ziwei Ji", "Pascale Fung"], "abstract": "Humans are known to have an internal \"world model\" that enables us to carry out action planning based on world states. AI agents need to have such a world model for action planning as well. It is not clear how current AI models, especially generative models, are able to learn such world models and carry out procedural planning in diverse environments. We introduce WorldPrediction, a video-based benchmark for evaluating world modeling and procedural planning capabilities of different AI models. In contrast to prior benchmarks that focus primarily on low-level world modeling and robotic motion planning, WorldPrediction is the first benchmark that emphasizes actions with temporal and semantic abstraction. Given initial and final world states, the task is to distinguish the proper action (WorldPrediction-WM) or the properly ordered sequence of actions (WorldPrediction-PP) from a set of counterfactual distractors. This discriminative task setup enable us to evaluate different types of world models and planners and realize a thorough comparison across different hypothesis. The benchmark represents states and actions using visual observations. In order to prevent models from exploiting low-level continuity cues in background scenes, we provide \"action equivalents\" - identical actions observed in different contexts - as candidates for selection. This benchmark is grounded in a formal framework of partially observable semi-MDP, ensuring better reliability and robustness of the evaluation. We conduct extensive human filtering and validation on our benchmark and show that current frontier models barely achieve 57% accuracy on WorldPrediction-WM and 38% on WorldPrediction-PP whereas humans are able to solve both tasks perfectly.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04363.pdf", "abstract_url": "https://arxiv.org/abs/2506.04363", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "WorldPrediction是一个基于视频的基准测试，用于评估不同AI模型的世界建模和程序规划能力，特别强调具有时间和语义抽象的动作。", "motivation": "解决当前AI模型，尤其是生成模型，在多样环境中学习世界模型和执行程序规划能力的不明确性问题。", "method": "引入WorldPrediction基准测试，通过区分正确的动作或动作序列与反事实干扰项来评估模型的世界建模和规划能力。", "result": "当前前沿模型在WorldPrediction-WM和WorldPrediction-PP上的准确率分别为57%和38%，而人类能够完美解决这两个任务。", "conclusion": "WorldPrediction基准测试为评估和比较不同类型的世界模型和规划器提供了一个可靠和健壮的框架，揭示了当前AI模型与世界建模和长期规划能力之间的差距。"}}
{"id": "2506.04595", "title": "Hierarchical-Task-Aware Multi-modal Mixture of Incremental LoRA Experts for Embodied Continual Learning", "authors": ["Ziqi Jia", "Anmin Wang", "Xiaoyang Qu", "Xiaowen Yang", "Jianzong Wang"], "abstract": "Previous continual learning setups for embodied intelligence focused on executing low-level actions based on human commands, neglecting the ability to learn high-level planning and multi-level knowledge. To address these issues, we propose the Hierarchical Embodied Continual Learning Setups (HEC) that divide the agent's continual learning process into two layers: high-level instructions and low-level actions, and define five embodied continual learning sub-setups. Building on these setups, we introduce the Task-aware Mixture of Incremental LoRA Experts (Task-aware MoILE) method. This approach achieves task recognition by clustering visual-text embeddings and uses both a task-level router and a token-level router to select the appropriate LoRA experts. To effectively address the issue of catastrophic forgetting, we apply Singular Value Decomposition (SVD) to the LoRA parameters obtained from prior tasks, preserving key components while orthogonally training the remaining parts. The experimental results show that our method stands out in reducing the forgetting of old tasks compared to other methods, effectively supporting agents in retaining prior knowledge while continuously learning new tasks.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "Accepted by the 63rd Annual Meeting of the Association for Computational Linguistics (ACL 2025)", "pdf_url": "https://arxiv.org/pdf/2506.04595.pdf", "abstract_url": "https://arxiv.org/abs/2506.04595", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了分层体现持续学习设置（HEC），将代理的持续学习过程分为高层指令和低层动作两层，并定义了五个体现持续学习子设置。在此基础上，引入了任务感知的增量LoRA专家混合（Task-aware MoILE）方法，通过聚类视觉-文本嵌入实现任务识别，并使用任务级和令牌级路由器选择适当的LoRA专家。为了有效解决灾难性遗忘问题，我们对先前任务获得的LoRA参数应用奇异值分解（SVD），保留关键组件的同时正交训练其余部分。实验结果表明，我们的方法在减少旧任务遗忘方面表现突出，有效支持代理在持续学习新任务的同时保留先验知识。", "motivation": "解决体现智能在持续学习中忽视高层规划和多级知识学习的问题。", "method": "提出了分层体现持续学习设置（HEC）和任务感知的增量LoRA专家混合（Task-aware MoILE）方法，包括任务识别和路由器选择机制，以及应用SVD于LoRA参数以减少灾难性遗忘。", "result": "实验结果显示，该方法在减少旧任务遗忘方面优于其他方法，有效支持代理在持续学习新任务的同时保留先验知识。", "conclusion": "通过分层学习和任务感知的专家混合方法，有效解决了体现智能在持续学习中的高层规划和多级知识学习问题，同时减少了灾难性遗忘。"}}
{"id": "2506.04676", "title": "Gen-n-Val: Agentic Image Data Generation and Validation", "authors": ["Jing-En Huang", "I-Sheng Fang", "Tzuhsuan Huang", "Chih-Yu Wang", "Jun-Cheng Chen"], "abstract": "Recently, Large Language Models (LLMs) and Vision Large Language Models (VLLMs) have demonstrated impressive performance as agents across various tasks while data scarcity and label noise remain significant challenges in computer vision tasks, such as object detection and instance segmentation. A common solution for resolving these issues is to generate synthetic data. However, current synthetic data generation methods struggle with issues, such as multiple objects per mask, inaccurate segmentation, and incorrect category labels, limiting their effectiveness. To address these issues, we introduce Gen-n-Val, a novel agentic data generation framework that leverages Layer Diffusion (LD), LLMs, and VLLMs to produce high-quality, single-object masks and diverse backgrounds. Gen-n-Val consists of two agents: (1) The LD prompt agent, an LLM, optimizes prompts for LD to generate high-quality foreground instance images and segmentation masks. These optimized prompts ensure the generation of single-object synthetic data with precise instance masks and clean backgrounds. (2) The data validation agent, a VLLM, which filters out low-quality synthetic instance images. The system prompts for both agents are refined through TextGrad. Additionally, we use image harmonization to combine multiple instances within scenes. Compared to state-of-the-art synthetic data approaches like MosaicFusion, our approach reduces invalid synthetic data from 50% to 7% and improves performance by 1% mAP on rare classes in COCO instance segmentation with YOLOv9c and YOLO11m. Furthermore, Gen-n-Val shows significant improvements (7. 1% mAP) over YOLO-Worldv2-M in open-vocabulary object detection benchmarks with YOLO11m. Moreover, Gen-n-Val improves the performance of YOLOv9 and YOLO11 families in instance segmentation and object detection.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04676.pdf", "abstract_url": "https://arxiv.org/abs/2506.04676", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "Gen-n-Val是一个新颖的代理数据生成框架，利用Layer Diffusion、LLMs和VLLMs生成高质量的单对象掩码和多样背景，解决计算机视觉任务中的数据稀缺和标签噪声问题。", "motivation": "解决计算机视觉任务中数据稀缺和标签噪声的问题，特别是对象检测和实例分割中的多对象掩码、不准确分割和错误类别标签等问题。", "method": "Gen-n-Val框架包含两个代理：LD提示代理（LLM）优化LD的提示以生成高质量的前景实例图像和分割掩码；数据验证代理（VLLM）过滤低质量的合成实例图像。系统提示通过TextGrad优化，并使用图像协调技术将多个实例组合到场景中。", "result": "与最先进的合成数据方法相比，Gen-n-Val将无效合成数据从50%减少到7%，并在COCO实例分割中提高了1% mAP，在开放词汇对象检测基准中提高了7.1% mAP。", "conclusion": "Gen-n-Val显著提高了YOLOv9和YOLO11系列在实例分割和对象检测中的性能，为解决计算机视觉任务中的数据问题提供了有效方案。"}}
{"id": "2506.04344", "title": "GEM: Empowering LLM for both Embedding Generation and Language Understanding", "authors": ["Caojin Zhang", "Qiang Zhang", "Ke Li", "Sai Vidyaranya Nuthalapati", "Benyu Zhang", "Jason Liu", "Serena Li", "Lizhu Zhang", "Xiangjun Fan"], "abstract": "Large decoder-only language models (LLMs) have achieved remarkable success in generation and reasoning tasks, where they generate text responses given instructions. However, many applications, e.g., retrieval augmented generation (RAG), still rely on separate embedding models to generate text embeddings, which can complicate the system and introduce discrepancies in understanding of the query between the embedding model and LLMs. To address this limitation, we propose a simple self-supervised approach, Generative Embedding large language Model (GEM), that enables any large decoder-only LLM to generate high-quality text embeddings while maintaining its original text generation and reasoning capabilities. Our method inserts new special token(s) into a text body, and generates summarization embedding of the text by manipulating the attention mask. This method could be easily integrated into post-training or fine tuning stages of any existing LLMs. We demonstrate the effectiveness of our approach by applying it to two popular LLM families, ranging from 1B to 8B parameters, and evaluating the transformed models on both text embedding benchmarks (MTEB) and NLP benchmarks (MMLU). The results show that our proposed method significantly improves the original LLMs on MTEB while having a minimal impact on MMLU. Our strong results indicate that our approach can empower LLMs with state-of-the-art text embedding capabilities while maintaining their original NLP performance", "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04344.pdf", "abstract_url": "https://arxiv.org/abs/2506.04344", "categories": ["Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种名为GEM的自监督方法，使大型解码器语言模型（LLM）能够生成高质量的文本嵌入，同时保持其原有的文本生成和推理能力。", "motivation": "解决现有应用中依赖独立嵌入模型生成文本嵌入的问题，这种方法可能导致系统复杂化并在嵌入模型与LLM之间产生理解上的差异。", "method": "通过在文本中插入新的特殊标记，并通过操纵注意力掩码生成文本的总结嵌入，该方法可以轻松集成到任何现有LLM的后训练或微调阶段。", "result": "应用该方法于两个流行的LLM家族（参数范围从1B到8B）后，在文本嵌入基准（MTEB）和NLP基准（MMLU）上的评估显示，该方法显著提高了原始LLM在MTEB上的表现，同时对MMLU的影响最小。", "conclusion": "GEM方法能够赋予LLM最先进的文本嵌入能力，同时保持其原有的NLP性能，为LLM的应用开辟了新的可能性。"}}
{"id": "2506.04743", "title": "SRD: Reinforcement-Learned Semantic Perturbation for Backdoor Defense in VLMs", "authors": ["Shuhan Xu", "Siyuan Liang", "Hongling Zheng", "Yong Luo", "Aishan Liu", "Dacheng Tao"], "abstract": "Vision-Language Models (VLMs) have achieved remarkable performance in image captioning, but recent studies show they are vulnerable to backdoor attacks. Attackers can inject imperceptible perturbations-such as local pixel triggers or global semantic phrases-into the training data, causing the model to generate malicious, attacker-controlled captions for specific inputs. These attacks are hard to detect and defend due to their stealthiness and cross-modal nature. By analyzing attack samples, we identify two key vulnerabilities: (1) abnormal attention concentration on specific image regions, and (2) semantic drift and incoherence in generated captions. To counter this, we propose Semantic Reward Defense (SRD), a reinforcement learning framework that mitigates backdoor behavior without prior knowledge of triggers. SRD uses a Deep Q-Network to learn policies for applying discrete perturbations (e.g., occlusion, color masking) to sensitive image regions, aiming to disrupt the activation of malicious pathways. We design a semantic fidelity score as the reward signal, which jointly evaluates semantic consistency and linguistic fluency of the output, guiding the agent toward generating robust yet faithful captions. Experiments across mainstream VLMs and datasets show SRD reduces attack success rates to 5.6%, while preserving caption quality on clean inputs with less than 10% performance drop. SRD offers a trigger-agnostic, interpretable defense paradigm against stealthy backdoor threats in multimodal generative models.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04743.pdf", "abstract_url": "https://arxiv.org/abs/2506.04743", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为SRD的强化学习框架，用于防御视觉语言模型（VLMs）中的后门攻击，通过应用离散扰动来破坏恶意路径的激活，同时保持生成的标题质量。", "motivation": "视觉语言模型在图像描述生成方面表现出色，但研究发现它们容易受到后门攻击。攻击者可以在训练数据中注入难以察觉的扰动，导致模型对特定输入生成恶意、受攻击者控制的描述。这些攻击由于其隐蔽性和跨模态特性难以检测和防御。", "method": "提出的语义奖励防御（SRD）是一个强化学习框架，使用深度Q网络学习对敏感图像区域应用离散扰动（如遮挡、颜色掩码）的策略，旨在破坏恶意路径的激活。设计了一个语义保真度分数作为奖励信号，共同评估输出的语义一致性和语言流畅性。", "result": "在主流VLMs和数据集上的实验表明，SRD将攻击成功率降低到5.6%，同时在干净输入上保持标题质量，性能下降不到10%。", "conclusion": "SRD提供了一种与触发器无关、可解释的防御范式，用于对抗多模态生成模型中的隐蔽后门威胁。"}}
{"id": "2506.04790", "title": "LotusFilter: Fast Diverse Nearest Neighbor Search via a Learned Cutoff Table", "authors": ["Yusuke Matsui"], "abstract": "Approximate nearest neighbor search (ANNS) is an essential building block for applications like RAG but can sometimes yield results that are overly similar to each other. In certain scenarios, search results should be similar to the query and yet diverse. We propose LotusFilter, a post-processing module to diversify ANNS results. We precompute a cutoff table summarizing vectors that are close to each other. During the filtering, LotusFilter greedily looks up the table to delete redundant vectors from the candidates. We demonstrated that the LotusFilter operates fast (0.02 [ms/query]) in settings resembling real-world RAG applications, utilizing features such as OpenAI embeddings. Our code is publicly available at", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Information Retrieval (cs.IR); Machine Learning (cs.LG)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2506.04790.pdf", "abstract_url": "https://arxiv.org/abs/2506.04790", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Information Retrieval (cs.IR)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "LotusFilter是一种后处理模块，用于多样化近似最近邻搜索（ANNS）结果，通过预计算的截止表快速删除冗余向量。", "motivation": "解决ANNS结果过于相似的问题，确保搜索结果既与查询相似又具有多样性。", "method": "预计算一个截止表，总结彼此接近的向量，在过滤过程中贪婪地查找表以删除候选中的冗余向量。", "result": "LotusFilter在类似真实世界RAG应用的环境中运行快速（0.02 [ms/查询]），利用了如OpenAI嵌入等特性。", "conclusion": "LotusFilter提供了一种高效的方法来多样化ANNS结果，适用于需要多样性和相似性平衡的应用场景。"}}
{"id": "2506.04389", "title": "Building a Few-Shot Cross-Domain Multilingual NLU Model for Customer Care", "authors": ["Saurabh Kumar", "Sourav Bansal", "Neeraj Agrawal", "Priyanka Bhatt"], "abstract": "Customer care is an essential pillar of the e-commerce shopping experience with companies spending millions of dollars each year, employing automation and human agents, across geographies (like US, Canada, Mexico, Chile), channels (like Chat, Interactive Voice Response (IVR)), and languages (like English, Spanish). SOTA pre-trained models like multilingual-BERT, fine-tuned on annotated data have shown good performance in downstream tasks relevant to Customer Care. However, model performance is largely subject to the availability of sufficient annotated domain-specific data. Cross-domain availability of data remains a bottleneck, thus building an intent classifier that generalizes across domains (defined by channel, geography, and language) with only a few annotations, is of great practical value. In this paper, we propose an embedder-cum-classifier model architecture which extends state-of-the-art domain-specific models to other domains with only a few labeled samples. We adopt a supervised fine-tuning approach with isotropic regularizers to train a domain-specific sentence embedder and a multilingual knowledge distillation strategy to generalize this embedder across multiple domains. The trained embedder, further augmented with a simple linear classifier can be deployed for new domains. Experiments on Canada and Mexico e-commerce Customer Care dataset with few-shot intent detection show an increase in accuracy by 20-23% against the existing state-of-the-art pre-trained models.", "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04389.pdf", "abstract_url": "https://arxiv.org/abs/2506.04389", "categories": ["Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种用于客户服务的少样本跨域多语言自然语言理解模型，通过结合嵌入器和分类器的架构，以及使用各向同性正则器和多语言知识蒸馏策略，显著提高了在少量标注数据情况下的意图分类准确率。", "motivation": "客户服务是电子商务购物体验的重要组成部分，但跨领域数据的可用性限制了现有模型的性能。本文旨在解决在少量标注数据情况下，构建能够跨领域（如渠道、地理和语言）泛化的意图分类器的挑战。", "method": "采用了一种嵌入器-分类器模型架构，结合监督微调方法和各向同性正则器来训练领域特定的句子嵌入器，并使用多语言知识蒸馏策略将该嵌入器泛化到多个领域。", "result": "在加拿大和墨西哥的电子商务客户服务数据集上的实验表明，与现有的最先进预训练模型相比，意图检测的准确率提高了20-23%。", "conclusion": "本文提出的方法能够有效地在少量标注数据的情况下，构建跨领域的意图分类器，为实际应用提供了重要价值。"}}
{"id": "2506.04405", "title": "MedAgentGym: Training LLM Agents for Code-Based Medical Reasoning at Scale", "authors": ["Ran Xu", "Yuchen Zhuang", "Yishan Zhong", "Yue Yu", "Xiangru Tang", "Hang Wu", "May D. Wang", "Peifeng Ruan", "Donghan Yang", "Tao Wang", "Guanghua Xiao", "Carl Yang", "Yang Xie", "Wenqi Shi"], "abstract": "We introduce MedAgentGYM, the first publicly available training environment designed to enhance coding-based medical reasoning capabilities in large language model (LLM) agents. MedAgentGYM comprises 72,413 task instances across 129 categories derived from authentic real-world biomedical scenarios. Tasks are encapsulated within executable coding environments, each featuring detailed task descriptions, interactive feedback mechanisms, verifiable ground-truth annotations, and scalable training trajectory generation. Extensive benchmarking of over 30 LLMs reveals a notable performance disparity between commercial API-based models and open-source counterparts. Leveraging MedAgentGYM, Med-Copilot-7B achieves substantial performance gains through supervised fine-tuning (+36.44%) and continued reinforcement learning (+42.47%), emerging as an affordable and privacy-preserving alternative competitive with gpt-4o. By offering both a comprehensive benchmark and accessible, expandable training resources within unified execution environments, MedAgentGYM delivers an integrated platform to develop LLM-based coding assistants for advanced biomedical research and practice.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04405.pdf", "abstract_url": "https://arxiv.org/abs/2506.04405", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "介绍了MedAgentGYM，首个公开的训练环境，旨在增强大型语言模型（LLM）代理的基于编码的医疗推理能力。包含72,413个任务实例，覆盖129个类别，源自真实世界生物医学场景。通过监督微调和持续强化学习，Med-Copilot-7B性能显著提升。", "motivation": "解决大型语言模型在基于编码的医疗推理能力上的不足，提供一个公开、可扩展的训练环境。", "method": "创建MedAgentGYM环境，包含大量真实世界生物医学任务实例，采用监督微调和强化学习训练LLM代理。", "result": "Med-Copilot-7B通过MedAgentGYM训练，性能显著提升（监督微调+36.44%，强化学习+42.47%），与gpt-4o竞争。", "conclusion": "MedAgentGYM为开发基于LLM的编码助手提供了综合基准和可扩展训练资源，推动高级生物医学研究和实践。"}}
{"id": "2506.04409", "title": "Empaths at SemEval-2025 Task 11: Retrieval-Augmented Approach to Perceived Emotions Prediction", "authors": ["Lev Morozov", "Aleksandr Mogilevskii", "Alexander Shirnin"], "abstract": "This paper describes EmoRAG, a system designed to detect perceived emotions in text for SemEval-2025 Task 11, Subtask A: Multi-label Emotion Detection. We focus on predicting the perceived emotions of the speaker from a given text snippet, labeling it with emotions such as joy, sadness, fear, anger, surprise, and disgust. Our approach does not require additional model training and only uses an ensemble of models to predict emotions. EmoRAG achieves results comparable to the best performing systems, while being more efficient, scalable, and easier to implement.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "Accepted to SemEval-2025, an ACL 2025 workshop", "pdf_url": "https://arxiv.org/pdf/2506.04409.pdf", "abstract_url": "https://arxiv.org/abs/2506.04409", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了EmoRAG系统，用于在SemEval-2025 Task 11的Subtask A中检测文本中的感知情绪，无需额外模型训练，仅使用模型集成预测情绪，效果与最佳系统相当，且更高效、可扩展、易实施。", "motivation": "解决从文本片段中预测说话者感知情绪（如喜悦、悲伤、恐惧、愤怒、惊讶和厌恶）的多标签情绪检测问题。", "method": "采用检索增强的方法，不进行额外的模型训练，仅通过模型集成来预测情绪。", "result": "EmoRAG系统的表现与最佳性能系统相当，同时更高效、可扩展且易于实现。", "conclusion": "EmoRAG为多标签情绪检测提供了一种高效、可扩展且易于实施的解决方案，无需额外训练即可达到竞争性性能。"}}
{"id": "2506.04251", "title": "Language-Guided Multi-Agent Learning in Simulations: A Unified Framework and Evaluation", "authors": ["Zhengyang Li"], "abstract": "This paper introduces LLM-MARL, a unified framework that incorporates large language models (LLMs) into multi-agent reinforcement learning (MARL) to enhance coordination, communication, and generalization in simulated game environments. The framework features three modular components of Coordinator, Communicator, and Memory, which dynamically generate subgoals, facilitate symbolic inter-agent messaging, and support episodic recall. Training combines PPO with a language-conditioned loss and LLM query gating. LLM-MARL is evaluated in Google Research Football, MAgent Battle, and StarCraft II. Results show consistent improvements over MAPPO and QMIX in win rate, coordination score, and zero-shot generalization. Ablation studies demonstrate that subgoal generation and language-based messaging each contribute significantly to performance gains. Qualitative analysis reveals emergent behaviors such as role specialization and communication-driven tactics. By bridging language modeling and policy learning, this work contributes to the design of intelligent, cooperative agents in interactive simulations. It offers a path forward for leveraging LLMs in multi-agent systems used for training, games, and human-AI collaboration.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04251.pdf", "abstract_url": "https://arxiv.org/abs/2506.04251", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了LLM-MARL，一个将大型语言模型（LLMs）融入多智能体强化学习（MARL）的统一框架，旨在提升模拟游戏环境中的协调、通信和泛化能力。", "motivation": "解决多智能体在模拟环境中协调、通信和泛化能力不足的问题。", "method": "结合PPO与语言条件损失和LLM查询门控的训练方法，框架包含Coordinator、Communicator和Memory三个模块。", "result": "在Google Research Football、MAgent Battle和StarCraft II中评估，结果显示在胜率、协调分数和零样本泛化方面优于MAPPO和QMIX。", "conclusion": "通过桥接语言建模和政策学习，这项工作为交互式模拟中智能、协作代理的设计做出了贡献，为在多智能体系统中利用LLMs提供了前进的道路。"}}
{"id": "2506.04245", "title": "Contextual Integrity in LLMs via Reasoning and Reinforcement Learning", "authors": ["Guangchen Lan", "Huseyin A. Inan", "Sahar Abdelnabi", "Janardhan Kulkarni", "Lukas Wutschitz", "Reza Shokri", "Christopher G. Brinton", "Robert Sim"], "abstract": "As the era of autonomous agents making decisions on behalf of users unfolds, ensuring contextual integrity (CI) -- what is the appropriate information to share while carrying out a certain task -- becomes a central question to the field. We posit that CI demands a form of reasoning where the agent needs to reason about the context in which it is operating. To test this, we first prompt LLMs to reason explicitly about CI when deciding what information to disclose. We then extend this approach by developing a reinforcement learning (RL) framework that further instills in models the reasoning necessary to achieve CI. Using a synthetic, automatically created, dataset of only $\\sim700$ examples but with diverse contexts and information disclosure norms, we show that our method substantially reduces inappropriate information disclosure while maintaining task performance across multiple model sizes and families. Importantly, improvements transfer from this synthetic dataset to established CI benchmarks such as PrivacyLens that has human annotations and evaluates privacy leakage of AI assistants in actions and tool calls.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04245.pdf", "abstract_url": "https://arxiv.org/abs/2506.04245", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了在自主代理为用户做出决策的时代，如何通过推理和强化学习确保大型语言模型（LLMs）的上下文完整性（CI），即在进行特定任务时分享适当信息的问题。", "motivation": "解决自主代理在决策过程中如何确保不泄露不适当信息，即维护上下文完整性的问题。", "method": "首先通过提示LLMs明确推理CI来决定披露哪些信息，然后开发一个强化学习框架，进一步培养模型实现CI所需的推理能力。", "result": "使用仅约700个例子的合成数据集，该方法显著减少了不适当的信息披露，同时保持了不同模型大小和家族的任务性能。改进还转移到了具有人类注释的CI基准测试，如PrivacyLens。", "conclusion": "通过推理和强化学习，可以有效提升LLMs在保持任务性能的同时维护上下文完整性的能力，这一方法在合成数据和真实基准测试中均显示出良好的效果。"}}
{"id": "2506.04252", "title": "A Graph-Retrieval-Augmented Generation Framework Enhances Decision-Making in the Circular Economy", "authors": ["Yang Zhao", "Chengxiao Dai", "Dusit Niyato", "Chuan Fu Tan", "Keyi Xiang", "Yueyang Wang", "Zhiquan Yeo", "Daren Tan Zong Loong", "Jonathan Low Zhaozhi", "Eugene H.Z. HO"], "abstract": "Large language models (LLMs) hold promise for sustainable manufacturing, but often hallucinate industrial codes and emission factors, undermining regulatory and investment decisions. We introduce CircuGraphRAG, a retrieval-augmented generation (RAG) framework that grounds LLMs outputs in a domain-specific knowledge graph for the circular economy. This graph connects 117,380 industrial and waste entities with classification codes and GWP100 emission data, enabling structured multi-hop reasoning. Natural language queries are translated into SPARQL and verified subgraphs are retrieved to ensure accuracy and traceability. Compared with Standalone LLMs and Naive RAG, CircuGraphRAG achieves superior performance in single-hop and multi-hop question answering, with ROUGE-L F1 scores up to 1.0, while baseline scores below 0.08. It also improves efficiency, halving the response time and reducing token usage by 16% in representative tasks. CircuGraphRAG provides fact-checked, regulatory-ready support for circular economy planning, advancing reliable, low-carbon resource decision making.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04252.pdf", "abstract_url": "https://arxiv.org/abs/2506.04252", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "CircuGraphRAG是一个检索增强生成框架，通过将大型语言模型（LLMs）的输出与循环经济领域的特定知识图相结合，提高了决策的准确性和效率。", "motivation": "解决大型语言模型在可持续制造中因产生工业代码和排放因子的幻觉而影响监管和投资决策的问题。", "method": "引入CircuGraphRAG框架，利用包含117,380个工业和废物实体的知识图进行结构化多跳推理，将自然语言查询转换为SPARQL并检索验证子图以确保准确性和可追溯性。", "result": "与独立LLMs和Naive RAG相比，CircuGraphRAG在单跳和多跳问答中表现出色，ROUGE-L F1分数高达1.0，同时响应时间减半，代表性任务中的令牌使用量减少16%。", "conclusion": "CircuGraphRAG为循环经济规划提供了经过事实核查、符合监管要求的支持，推动了可靠、低碳资源决策的进步。"}}
{"id": "2506.04287", "title": "Automated Skill Discovery for Language Agents through Exploration and Iterative Feedback", "authors": ["Yongjin Yang", "Sinjae Kang", "Juyong Lee", "Dongjun Lee", "Se-Young Yun", "Kimin Lee"], "abstract": "Training large language model (LLM) agents to acquire necessary skills and perform diverse tasks within an environment is gaining interest as a means to enable open-endedness. However, creating the training dataset for their skill acquisition faces several challenges. Manual trajectory collection requires significant human effort. Another approach, where LLMs directly propose tasks to learn, is often invalid, as the LLMs lack knowledge of which tasks are actually feasible. Moreover, the generated data may not provide a meaningful learning signal, as agents often already perform well on the proposed tasks. To address this, we propose a novel automatic skill discovery framework EXIF for LLM-powered agents, designed to improve the feasibility of generated target behaviors while accounting for the agents' capabilities. Our method adopts an exploration-first strategy by employing an exploration agent (Alice) to train the target agent (Bob) to learn essential skills in the environment. Specifically, Alice first interacts with the environment to retrospectively generate a feasible, environment-grounded skill dataset, which is then used to train Bob. Crucially, we incorporate an iterative feedback loop, where Alice evaluates Bob's performance to identify areas for improvement. This feedback then guides Alice's next round of exploration, forming a closed-loop data generation process. Experiments on Webshop and Crafter demonstrate EXIF's ability to effectively discover meaningful skills and iteratively expand the capabilities of the trained agent without any human intervention, achieving substantial performance improvements. Interestingly, we observe that setting Alice to the same model as Bob also notably improves performance, demonstrating EXIF's potential for building a self-evolving system.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "Preprint, under review", "pdf_url": "https://arxiv.org/pdf/2506.04287.pdf", "abstract_url": "https://arxiv.org/abs/2506.04287", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为EXIF的自动技能发现框架，旨在通过探索和迭代反馈来提高大型语言模型（LLM）代理的技能获取能力，无需人工干预即可有效发现有意义技能并迭代扩展代理能力。", "motivation": "训练大型语言模型代理以获取必要技能并在环境中执行多样化任务是实现开放性的手段之一。然而，为其技能获取创建训练数据集面临手动轨迹收集需要大量人力、LLM直接提出的任务往往不可行以及生成的数据可能不提供有意义学习信号等挑战。", "method": "提出EXIF框架，采用探索优先策略，通过探索代理（Alice）训练目标代理（Bob）学习环境中的基本技能。Alice首先与环境互动，回顾性生成可行的、基于环境的技能数据集，然后用于训练Bob。关键是通过迭代反馈循环，Alice评估Bob的表现以识别改进领域，反馈指导Alice的下一轮探索，形成闭环数据生成过程。", "result": "在Webshop和Crafter上的实验证明，EXIF能够有效发现有意义技能并迭代扩展训练代理的能力，无需任何人工干预即可实现显著的性能提升。有趣的是，将Alice设置为与Bob相同的模型也显著提高了性能，展示了EXIF构建自进化系统的潜力。", "conclusion": "EXIF框架通过探索和迭代反馈有效解决了LLM代理技能获取中的挑战，不仅提高了技能发现的效率和效果，还展示了构建自进化系统的可能性，为未来的研究和发展提供了新的方向。"}}
{"id": "2506.04481", "title": "CogMath: Assessing LLMs' Authentic Mathematical Ability from a Human Cognitive Perspective", "authors": ["Jiayu Liu", "Zhenya Huang", "Wei Dai", "Cheng Cheng", "Jinze Wu", "Jing Sha", "Song Li", "Qi Liu", "Shijin Wang", "Enhong Chen"], "abstract": "Although large language models (LLMs) show promise in solving complex mathematical tasks, existing evaluation paradigms rely solely on a coarse measure of overall answer accuracy, which are insufficient for assessing their authentic capabilities. In this paper, we propose \\textbf{CogMath}, which comprehensively assesses LLMs' mathematical abilities through the lens of human cognition. Specifically, inspired by psychological theories, CogMath formalizes human reasoning process into 3 stages: \\emph{problem comprehension}, \\emph{problem solving}, and \\emph{solution summarization}. Within these stages, we investigate perspectives such as numerical calculation, knowledge, and counterfactuals, and design a total of 9 fine-grained evaluation dimensions. In each dimension, we develop an ``\\emph{Inquiry}-\\emph{Judge}-\\emph{Reference}'' multi-agent system to generate inquiries that assess LLMs' mastery from this dimension. An LLM is considered to truly master a problem only when excelling in all inquiries from the 9 dimensions. By applying CogMath on three benchmarks, we reveal that the mathematical capabilities of 7 mainstream LLMs are overestimated by 30\\%-40\\%. Moreover, we locate their strengths and weaknesses across specific stages/dimensions, offering in-depth insights to further enhance their reasoning abilities.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04481.pdf", "abstract_url": "https://arxiv.org/abs/2506.04481", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了CogMath，一种从人类认知角度全面评估大型语言模型（LLMs）数学能力的方法，揭示了主流LLMs的数学能力被高估30%-40%。", "motivation": "现有的大型语言模型（LLMs）评估范式仅依赖于答案准确性的粗略测量，不足以评估其真实的数学能力。", "method": "CogMath通过将人类推理过程形式化为3个阶段（问题理解、问题解决和解决方案总结），并在这些阶段中设计了9个细粒度的评估维度，开发了一个多代理系统来生成评估LLMs掌握程度的询问。", "result": "应用CogMath在三个基准测试上，发现7个主流LLMs的数学能力被高估了30%-40%，并定位了它们在特定阶段/维度上的优势和弱点。", "conclusion": "CogMath为评估和增强LLMs的数学推理能力提供了深入的见解，揭示了现有评估方法的不足。"}}
{"id": "2506.04253", "title": "HADA: Human-AI Agent Decision Alignment Architecture", "authors": ["Tapio Pitkäranta", "Leena Pitkäranta"], "abstract": "We present HADA (Human-AI Agent Decision Alignment), a protocol- and framework agnostic reference architecture that keeps both large language model (LLM) agents and legacy algorithms aligned with organizational targets and values. HADA wraps any algorithm or LLM in role-specific stakeholder agents -- business, data-science, audit, ethics, and customer -- each exposing conversational APIs so that technical and non-technical actors can query, steer, audit, or contest every decision across strategic, tactical, and real-time horizons. Alignment objectives, KPIs, and value constraints are expressed in natural language and are continuously propagated, logged, and versioned while thousands of heterogeneous agents run on different orchestration stacks. A cloud-native proof of concept packages a production credit-scoring model (getLoanDecision) and deploys it on Docker/Kubernetes/Python; five scripted retail-bank scenarios show how target changes, parameter tweaks, explanation requests, and ethics triggers flow end to end through the architecture. Evaluation followed the Design-Science Research Methodology. Walkthrough observation and log inspection demonstrated complete coverage of six predefined objectives: every role could invoke conversational control, trace KPIs and value constraints, detect and mitigate ZIP-code bias, and reproduce full decision lineage, independent of the underlying LLM or agent library. Contributions: (1) an open-source HADA architecture, (2) a mid-range design theory for human-AI alignment in multi-agent systems, and (3) empirical evidence that framework-agnostic, protocol-compliant stakeholder agents improve accuracy, transparency, and ethical compliance in real-world decision pipelines.", "subjects": "Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)", "comments": "18 pages, 4 figures", "pdf_url": "https://arxiv.org/pdf/2506.04253.pdf", "abstract_url": "https://arxiv.org/abs/2506.04253", "categories": ["Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "HADA是一种协议和框架无关的参考架构，旨在使大型语言模型（LLM）代理和传统算法与组织目标和价值观保持一致。它通过角色特定的利益相关者代理（如业务、数据科学、审计、伦理和客户）包装任何算法或LLM，每个代理都暴露对话API，以便技术和非技术参与者可以查询、指导、审计或质疑每个决策。HADA在云原生概念验证中展示了其在生产信用评分模型中的应用，并通过五个脚本化的零售银行场景展示了目标变更、参数调整、解释请求和伦理触发如何通过架构流动。评估遵循设计科学研究方法，证明了HADA在提高准确性、透明度和伦理合规性方面的有效性。", "motivation": "解决大型语言模型（LLM）代理和传统算法在决策过程中与组织目标和价值观对齐的问题，以提高决策的准确性、透明度和伦理合规性。", "method": "HADA架构通过角色特定的利益相关者代理包装任何算法或LLM，每个代理暴露对话API，支持自然语言表达的对齐目标、KPIs和价值约束，并在不同的编排栈上运行。", "result": "评估显示HADA完全覆盖了六个预定义目标，包括每个角色可以调用对话控制、跟踪KPIs和价值约束、检测和减轻ZIP码偏见，以及再现完整的决策谱系。", "conclusion": "HADA提供了一种开放源代码的架构和中等范围的设计理论，用于多代理系统中的人类-AI对齐，并提供了实证证据，表明框架无关、协议兼容的利益相关者代理可以提高现实世界决策管道的准确性、透明度和伦理合规性。"}}
{"id": "2506.04572", "title": "Demonstrations of Integrity Attacks in Multi-Agent Systems", "authors": ["Can Zheng", "Yuhan Cao", "Xiaoning Dong", "Tianxing He"], "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in natural language understanding, code generation, and complex planning. Simultaneously, Multi-Agent Systems (MAS) have garnered attention for their potential to enable cooperation among distributed agents. However, from a multi-party perspective, MAS could be vulnerable to malicious agents that exploit the system to serve self-interests without disrupting its core functionality. This work explores integrity attacks where malicious agents employ subtle prompt manipulation to bias MAS operations and gain various benefits. Four types of attacks are examined: \\textit{Scapegoater}, who misleads the system monitor to underestimate other agents' contributions; \\textit{Boaster}, who misleads the system monitor to overestimate their own performance; \\textit{Self-Dealer}, who manipulates other agents to adopt certain tools; and \\textit{Free-Rider}, who hands off its own task to others. We demonstrate that strategically crafted prompts can introduce systematic biases in MAS behavior and executable instructions, enabling malicious agents to effectively mislead evaluation systems and manipulate collaborative agents. Furthermore, our attacks can bypass advanced LLM-based monitors, such as GPT-4o-mini and o3-mini, highlighting the limitations of current detection mechanisms. Our findings underscore the critical need for MAS architectures with robust security protocols and content validation mechanisms, alongside monitoring systems capable of comprehensive risk scenario assessment.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04572.pdf", "abstract_url": "https://arxiv.org/abs/2506.04572", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了多智能体系统（MAS）中恶意代理通过微妙的提示操纵进行完整性攻击的四种类型，展示了精心设计的提示如何系统性偏置MAS行为，并揭示了当前检测机制的局限性。", "motivation": "解决多智能体系统中恶意代理利用系统漏洞进行自我利益服务而不破坏其核心功能的问题。", "method": "研究了四种攻击类型：Scapegoater、Boaster、Self-Dealer和Free-Rider，通过策略性设计的提示操纵MAS行为和可执行指令。", "result": "研究表明，这些攻击能够有效误导评估系统和操纵协作代理，甚至能够绕过基于先进LLM的监控系统。", "conclusion": "强调了开发具有强大安全协议和内容验证机制的多智能体系统架构，以及能够进行全面风险评估的监控系统的迫切需要。"}}
{"id": "2506.04571", "title": "OpenAg: Democratizing Agricultural Intelligence", "authors": ["Srikanth Thudumu", "Jason Fisher"], "abstract": "Agriculture is undergoing a major transformation driven by artificial intelligence (AI), machine learning, and knowledge representation technologies. However, current agricultural intelligence systems often lack contextual understanding, explainability, and adaptability, especially for smallholder farmers with limited resources. General-purpose large language models (LLMs), while powerful, typically lack the domain-specific knowledge and contextual reasoning needed for practical decision support in farming. They tend to produce recommendations that are too generic or unrealistic for real-world applications. To address these challenges, we present OpenAg, a comprehensive framework designed to advance agricultural artificial general intelligence (AGI). OpenAg combines domain-specific foundation models, neural knowledge graphs, multi-agent reasoning, causal explainability, and adaptive transfer learning to deliver context-aware, explainable, and actionable insights. The system includes: (i) a unified agricultural knowledge base that integrates scientific literature, sensor data, and farmer-generated knowledge; (ii) a neural agricultural knowledge graph for structured reasoning and inference; (iii) an adaptive multi-agent reasoning system where AI agents specialize and collaborate across agricultural domains; and (iv) a causal transparency mechanism that ensures AI recommendations are interpretable, scientifically grounded, and aligned with real-world constraints. OpenAg aims to bridge the gap between scientific knowledge and the tacit expertise of experienced farmers to support scalable and locally relevant agricultural decision-making.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "10 pages, 1 figure", "pdf_url": "https://arxiv.org/pdf/2506.04571.pdf", "abstract_url": "https://arxiv.org/abs/2506.04571", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "OpenAg是一个旨在推动农业通用人工智能（AGI）发展的综合框架，通过结合领域特定的基础模型、神经知识图谱、多智能体推理、因果可解释性和自适应迁移学习，提供情境感知、可解释且可操作的见解。", "motivation": "当前农业智能系统缺乏情境理解、可解释性和适应性，尤其是对资源有限的小农户。通用大型语言模型（LLMs）虽然强大，但缺乏领域特定知识和情境推理能力，难以提供实用的农业决策支持。", "method": "OpenAg框架包括：统一的农业知识库、神经农业知识图谱、自适应多智能体推理系统和因果透明机制，旨在整合科学文献、传感器数据和农民生成的知识，支持结构化的推理和推断。", "result": "OpenAg通过其综合框架，能够提供更符合实际应用、可解释且基于科学依据的农业决策支持，帮助缩小科学知识与农民实际经验之间的差距。", "conclusion": "OpenAg框架通过其创新的方法和技术，有望实现农业决策支持的规模化和本地化，为农业智能系统的发展开辟了新路径。"}}
{"id": "2506.04616", "title": "Subjective Perspectives within Learned Representations Predict High-Impact Innovation", "authors": ["Likun Cao", "Rui Pan", "James Evans"], "abstract": "Existing studies of innovation emphasize the power of social structures to shape innovation capacity. Emerging machine learning approaches, however, enable us to model innovators' personal perspectives and interpersonal innovation opportunities as a function of their prior trajectories of experience. We theorize then quantify subjective perspectives and innovation opportunities based on innovator positions within the geometric space of concepts inscribed by dynamic language representations. Using data on millions of scientists, inventors, writers, entrepreneurs, and Wikipedia contributors across the creative domains of science, technology, film, entrepreneurship, and Wikipedia, here we show that measured subjective perspectives anticipate what ideas individuals and groups creatively attend to and successfully combine in future. When perspective and background diversity are decomposed as the angular difference between collaborators' perspectives on their creation and between their experiences, the former consistently anticipates creative achievement while the latter portends its opposite, across all cases and time periods examined. We analyze a natural experiment and simulate creative collaborations between AI (large language model) agents designed with various perspective and background diversity, which are consistent with our observational findings. We explore mechanisms underlying these findings and identify how successful collaborators leverage common language to weave together diverse experience obtained through trajectories of prior work that converge to provoke one another and innovate. We explore the importance of these findings for team assembly and research policy.", "subjects": "Computation and Language (cs.CL); Applications (stat.AP); Machine Learning (stat.ML)", "comments": "107 pages, 20 figures", "pdf_url": "https://arxiv.org/pdf/2506.04616.pdf", "abstract_url": "https://arxiv.org/abs/2506.04616", "categories": ["Computation and Language (cs.CL)", "Applications (stat.AP)", "Machine Learning (stat.ML)"], "matching_keywords": ["agent"], "AI": {"tldr": "本研究通过机器学习方法建模创新者的个人视角和人际创新机会，基于他们在动态语言表示所刻画的几何概念空间中的位置，量化主观视角和创新机会。研究表明，测量的主观视角能预测个人和群体未来创造性关注和成功结合的想法。视角多样性和背景多样性的角度差异分别预示创造性成就及其反面。通过自然实验和AI代理模拟，验证了观察结果，并探讨了成功合作者利用共同语言整合多样经验的机制。", "motivation": "解决现有创新研究主要依赖社会结构塑造创新能力，而忽视创新者个人视角和人际创新机会的问题。", "method": "使用机器学习方法，基于创新者在动态语言表示所刻画的几何概念空间中的位置，量化主观视角和创新机会。", "result": "主观视角能预测未来创造性成就，视角多样性预示创造性成就，而背景多样性则预示其反面。AI代理模拟验证了这些观察结果。", "conclusion": "研究强调了视角多样性在创新中的重要性，为团队组建和研究政策提供了重要启示。"}}
{"id": "2506.04636", "title": "CHANCERY: Evaluating corporate governance reasoning capabilities in language models", "authors": ["Lucas Irwin", "Arda Kaz", "Peiyao Sheng", "Pramod Viswanath"], "abstract": "Law has long been a domain that has been popular in natural language processing (NLP) applications. Reasoning (ratiocination and the ability to make connections to precedent) is a core part of the practice of the law in the real world. Nevertheless, while multiple legal datasets exist, none have thus far focused specifically on reasoning tasks. We focus on a specific aspect of the legal landscape by introducing a corporate governance reasoning benchmark (CHANCERY) to test a model's ability to reason about whether executive/board/shareholder's proposed actions are consistent with corporate governance charters. This benchmark introduces a first-of-its-kind corporate governance reasoning test for language models - modeled after real world corporate governance law. The benchmark consists of a corporate charter (a set of governing covenants) and a proposal for executive action. The model's task is one of binary classification: reason about whether the action is consistent with the rules contained within the charter. We create the benchmark following established principles of corporate governance - 24 concrete corporate governance principles established in and 79 real life corporate charters selected to represent diverse industries from a total dataset of 10k real life corporate charters. Evaluations on state-of-the-art (SOTA) reasoning models confirm the difficulty of the benchmark, with models such as Claude 3.7 Sonnet and GPT-4o achieving 64.5% and 75.2% accuracy respectively. Reasoning agents exhibit superior performance, with agents based on the ReAct and CodeAct frameworks scoring 76.1% and 78.1% respectively, further confirming the advanced legal reasoning capabilities required to score highly on the benchmark. We also conduct an analysis of the types of questions which current reasoning models struggle on, revealing insights into the legal reasoning capabilities of SOTA models.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04636.pdf", "abstract_url": "https://arxiv.org/abs/2506.04636", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "介绍了CHANCERY，一个评估语言模型在公司治理推理能力方面的基准测试，基于真实世界的公司治理法律，测试模型是否能判断执行/董事会/股东提出的行动是否符合公司治理章程。", "motivation": "解决现有法律数据集中缺乏专注于推理任务的问题，特别是在公司治理领域的法律推理能力评估。", "method": "创建了一个包含公司章程和执行行动提案的二元分类任务基准，基于24个具体的公司治理原则和79个真实公司章程。", "result": "最先进的推理模型在该基准上表现不佳，Claude 3.7 Sonnet和GPT-4o的准确率分别为64.5%和75.2%，而基于ReAct和CodeAct框架的推理代理表现更好，分别为76.1%和78.1%。", "conclusion": "CHANCERY基准揭示了当前推理模型在法律推理能力上的局限性，并为评估和提升语言模型在公司治理领域的推理能力提供了方向。"}}
{"id": "2506.04651", "title": "Agents of Change: Self-Evolving LLM Agents for Strategic Planning", "authors": ["Nikolas Belle", "Dakota Barnes", "Alfonso Amayuelas", "Ivan Bercovich", "Xin Eric Wang", "William Wang"], "abstract": "Recent advances in LLMs have enabled their use as autonomous agents across a range of tasks, yet they continue to struggle with formulating and adhering to coherent long-term strategies. In this paper, we investigate whether LLM agents can self-improve when placed in environments that explicitly challenge their strategic planning abilities. Using the board game Settlers of Catan, accessed through the open-source Catanatron framework, we benchmark a progression of LLM-based agents, from a simple game-playing agent to systems capable of autonomously rewriting their own prompts and their player agent's code. We introduce a multi-agent architecture in which specialized roles (Analyzer, Researcher, Coder, and Player) collaborate to iteratively analyze gameplay, research new strategies, and modify the agent's logic or prompt. By comparing manually crafted agents to those evolved entirely by LLMs, we evaluate how effectively these systems can diagnose failure and adapt over time. Our results show that self-evolving agents, particularly when powered by models like Claude 3.7 and GPT-4o, outperform static baselines by autonomously adopting their strategies, passing along sample behavior to game-playing agents, and demonstrating adaptive reasoning over multiple iterations.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04651.pdf", "abstract_url": "https://arxiv.org/abs/2506.04651", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了LLM代理在战略规划能力上的自我改进，通过在《卡坦岛》游戏中测试从简单到能自主重写提示和代码的代理系统，发现自进化代理在Claude 3.7和GPT-4o等模型支持下优于静态基线。", "motivation": "解决LLM代理在制定和坚持长期战略方面的困难。", "method": "使用《卡坦岛》游戏和Catanatron框架，比较了从简单游戏代理到能自主重写提示和代码的系统的性能，引入了多代理架构（分析者、研究者、编码者和玩家）进行迭代改进。", "result": "自进化代理，特别是在Claude 3.7和GPT-4o等模型支持下，通过自主采用策略、传递样本行为和展示多轮适应性推理，优于静态基线。", "conclusion": "研究表明，LLM代理能够在适当环境下自我改进战略规划能力，自进化代理在高级模型支持下表现更佳。"}}
{"id": "2506.04654", "title": "E-bike agents: Large Language Model-Driven E-Bike Accident Analysis and Severity Prediction", "authors": ["Zhichao Yang", "Jiashu He", "Mohammad B. Al-Khasawneh", "Darshan Pandit", "Cirillo Cinzia"], "abstract": "Electric bicycles (e-bikes) are rapidly increasing in use, raising safety concerns due to a rise in accident reports. However, e-bike incident reports often use unstructured narrative formats, which hinders quantitative safety analysis. This study introduces E-bike agents, a framework that uses large language models (LLM) powered agents to classify and extract safety variables from unstructured incident reports. Our framework consists of four LLM agents, handling data classification, information extraction, injury cause determination, and component linkage, to extract the key factors that could lead to E-bike accidents and cause varying severity levels. Furthermore, we used an ordered logit model to examine the relationship between the severity of the incident and the factors retrieved, such as gender, the type of cause, and environmental conditions. Our research shows that equipment issues are slightly more common than human-related ones, but human-related incidents are more often fatal. Specifically, pedals, tires, and brakes are frequent contributors to accidents. The model achieves a high weighted F1 score of 0.87 in classification accuracy, highlighting the potential of using LLMs to extract unstructured data in niche domains, such as transportation. Our method offers a scalable solution to improve e-bike safety analytics and provides actionable information for policy makers, designers, and regulators.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04654.pdf", "abstract_url": "https://arxiv.org/abs/2506.04654", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "该研究引入了一个名为E-bike agents的框架，利用大型语言模型（LLM）驱动的代理从非结构化事故报告中分类和提取安全变量，以分析电动自行车（e-bike）事故及其严重性预测。", "motivation": "电动自行车使用的迅速增加引发了安全问题，但由于事故报告通常采用非结构化叙述格式，这阻碍了定量安全分析。", "method": "研究提出了一个由四个LLM代理组成的框架，分别处理数据分类、信息提取、伤害原因确定和组件链接，以提取可能导致电动自行车事故和不同严重程度的关键因素。此外，使用有序logit模型检查事故严重性与提取因素（如性别、原因类型和环境条件）之间的关系。", "result": "研究表明，设备问题比人为相关的问题稍常见，但人为相关的事故更常致命。具体来说，踏板、轮胎和刹车是事故的常见原因。该模型在分类准确性上达到了0.87的高加权F1分数。", "conclusion": "该方法为改进电动自行车安全分析提供了可扩展的解决方案，并为政策制定者、设计师和监管者提供了可操作的信息，展示了在交通等小众领域使用LLMs提取非结构化数据的潜力。"}}
{"id": "2506.04699", "title": "Empowering Economic Simulation for Massively Multiplayer Online Games through Generative Agent-Based Modeling", "authors": ["Bihan Xu", "Shiwei Zhao", "Runze Wu", "Zhenya Huang", "Jiawei Wang", "Zhipeng Hu", "Kai Wang", "Haoyu Liu", "Tangjie Lv", "Le Li", "Changjie Fan", "Xin Tong", "Jiangze Han"], "abstract": "Within the domain of Massively Multiplayer Online (MMO) economy research, Agent-Based Modeling (ABM) has emerged as a robust tool for analyzing game economics, evolving from rule-based agents to decision-making agents enhanced by reinforcement learning. Nevertheless, existing works encounter significant challenges when attempting to emulate human-like economic activities among agents, particularly regarding agent reliability, sociability, and interpretability. In this study, we take a preliminary step in introducing a novel approach using Large Language Models (LLMs) in MMO economy simulation. Leveraging LLMs' role-playing proficiency, generative capacity, and reasoning aptitude, we design LLM-driven agents with human-like decision-making and adaptability. These agents are equipped with the abilities of role-playing, perception, memory, and reasoning, addressing the aforementioned challenges effectively. Simulation experiments focusing on in-game economic activities demonstrate that LLM-empowered agents can promote emergent phenomena like role specialization and price fluctuations in line with market rules.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "KDD2025 Accepted", "pdf_url": "https://arxiv.org/pdf/2506.04699.pdf", "abstract_url": "https://arxiv.org/abs/2506.04699", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种利用大型语言模型（LLMs）在大型多人在线（MMO）游戏经济模拟中的新方法，通过LLM驱动的代理实现人类类似的决策和适应性。", "motivation": "解决在MMO经济研究中，现有方法在模拟人类类似经济活动时遇到的代理可靠性、社交性和可解释性挑战。", "method": "利用LLMs的角色扮演能力、生成能力和推理能力，设计具有角色扮演、感知、记忆和推理能力的LLM驱动代理。", "result": "模拟实验表明，LLM赋能的代理能够促进角色专业化和价格波动等与市场规则一致的新兴现象。", "conclusion": "LLM驱动的代理在MMO经济模拟中展现出模拟人类类似经济活动的潜力，为解决现有挑战提供了有效途径。"}}
{"id": "2506.04828", "title": "Safe Planning and Policy Optimization via World Model Learning", "authors": ["Artem Latyshev", "Gregory Gorbov", "Aleksandr I. Panov"], "abstract": "Reinforcement Learning (RL) applications in real-world scenarios must prioritize safety and reliability, which impose strict constraints on agent behavior. Model-based RL leverages predictive world models for action planning and policy optimization, but inherent model inaccuracies can lead to catastrophic failures in safety-critical settings. We propose a novel model-based RL framework that jointly optimizes task performance and safety. To address world model errors, our method incorporates an adaptive mechanism that dynamically switches between model-based planning and direct policy execution. We resolve the objective mismatch problem of traditional model-based approaches using an implicit world model. Furthermore, our framework employs dynamic safety thresholds that adapt to the agent's evolving capabilities, consistently selecting actions that surpass safe policy suggestions in both performance and safety. Experiments demonstrate significant improvements over non-adaptive methods, showing that our approach optimizes safety and performance simultaneously rather than merely meeting minimum safety requirements. The proposed framework achieves robust performance on diverse safety-critical continuous control tasks, outperforming existing methods.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04828.pdf", "abstract_url": "https://arxiv.org/abs/2506.04828", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新颖的基于模型的强化学习框架，旨在同时优化任务性能和安全性。通过引入自适应机制和动态安全阈值，该方法在安全关键任务中表现出色。", "motivation": "解决在安全关键设置中，由于模型不准确性导致的强化学习应用的安全性和可靠性问题。", "method": "采用了一种结合模型基于规划和直接策略执行的自适应机制，以及动态安全阈值和隐式世界模型来解决传统方法中的目标不匹配问题。", "result": "实验表明，该方法在多样化的安全关键连续控制任务中，相比非自适应方法，能够显著提高安全性和性能。", "conclusion": "提出的框架不仅在满足最低安全要求的同时优化了性能和安全性，而且在多样化的安全关键任务中实现了稳健的性能，优于现有方法。"}}
{"id": "2506.04849", "title": "Towards a Multi-Agent Simulation of Cyber-attackers and Cyber-defenders Battles", "authors": ["Julien Soulé", "Jean-Paul Jamont", "Michel Occello", "Paul Théron", "Louis-Marie Traonouez"], "abstract": "As cyber-attacks show to be more and more complex and coordinated, cyber-defenders strategy through multi-agent approaches could be key to tackle against cyber-attacks as close as entry points in a networked system. This paper presents a Markovian modeling and implementation through a simulator of fighting cyber-attacker agents and cyber-defender agents deployed on host network nodes. It aims to provide an experimental framework to implement realistically based coordinated cyber-attack scenarios while assessing cyber-defenders dynamic organizations. We abstracted network nodes by sets of properties including agents' ones. Actions applied by agents model how the network reacts depending in a given state and what properties are to change. Collective choice of the actions brings the whole environment closer or farther from respective cyber-attackers and cyber-defenders goals. Using the simulator, we implemented a realistically inspired scenario with several behavior implementation approaches for cyber-defenders and cyber-attackers.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04849.pdf", "abstract_url": "https://arxiv.org/abs/2506.04849", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种通过多代理方法模拟网络攻击者与防御者之间战斗的马尔可夫模型和实现，旨在提供一个实验框架来实施基于现实的协调网络攻击场景，同时评估防御者的动态组织。", "motivation": "随着网络攻击变得越来越复杂和协调，通过多代理方法的网络防御策略可能是关键，以尽可能接近网络系统中的入口点来对抗网络攻击。", "method": "本文通过模拟器实现了网络攻击者和防御者代理在主机网络节点上的战斗，抽象了网络节点为一组属性，包括代理的属性。代理应用的动作模拟了网络在给定状态下的反应以及哪些属性会发生变化。", "result": "使用模拟器，我们实现了一个现实启发的场景，其中包含了网络防御者和攻击者的几种行为实现方法。", "conclusion": "本文的模拟器为实现基于现实的协调网络攻击场景提供了一个实验框架，同时能够评估网络防御者的动态组织，为网络防御策略的发展提供了新的视角。"}}
{"id": "2506.04867", "title": "LLMs for sensory-motor control: Combining in-context and iterative learning", "authors": ["Jônata Tyska Carvalho", "Stefano Nolfi"], "abstract": "We propose a method that enables large language models (LLMs) to control embodied agents by directly mapping continuous observation vectors to continuous action vectors. Initially, the LLMs generate a control strategy based on a textual description of the agent, its environment, and the intended goal. This strategy is then iteratively refined through a learning process in which the LLMs are repeatedly prompted to improve the current strategy, using performance feedback and sensory-motor data collected during its evaluation. The method is validated on classic control tasks from the Gymnasium library and the inverted pendulum task from the MuJoCo library. In most cases, it successfully identifies optimal or high-performing solutions by integrating symbolic knowledge derived through reasoning with sub-symbolic sensory-motor data gathered as the agent interacts with its environment.", "subjects": "Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG); Robotics (cs.RO)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2506.04867.pdf", "abstract_url": "https://arxiv.org/abs/2506.04867", "categories": ["Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)", "Machine Learning (cs.LG)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "提出了一种方法，使大型语言模型（LLMs）能够通过直接将连续观察向量映射到连续动作向量来控制具体代理。该方法通过文本描述生成控制策略，并通过迭代学习和性能反馈进行优化。", "motivation": "解决大型语言模型在具体代理控制中的应用问题，特别是在连续观察和动作空间中的直接映射挑战。", "method": "结合上下文学习和迭代学习，通过文本描述生成初始控制策略，并利用性能反馈和感官运动数据进行迭代优化。", "result": "在Gymnasium和MuJoCo库的经典控制任务中，该方法成功找到了最优或高性能的解决方案。", "conclusion": "该方法通过结合符号知识和子符号感官运动数据，有效地实现了大型语言模型在具体代理控制中的应用。"}}
{"id": "2506.04625", "title": "Advancing Tool-Augmented Large Language Models via Meta-Verification and Reflection Learning", "authors": ["Zhiyuan Ma", "Jiayu Liu", "Xianzhen Luo", "Zhenya Huang", "Qingfu Zhu", "Wanxiang Che"], "abstract": "Empowering large language models (LLMs) with effective tool utilization capabilities is crucial for enabling AI agents to solve complex problems. However, current models face two major limitations: (1) unreliable tool planning and invocation due to low-quality instruction datasets (e.g., widespread hallucinated API calls), and (2) weak tool reflection abilities (over 90% of errors cannot be corrected) resulting from static imitation learning. To address these critical limitations, we propose Tool-MVR, a novel Tool-Augmented LLM that achieves comprehensive System 2 reasoning through two key innovations. Specifically, we first introduce Multi-Agent Meta-Verification (MAMV), a systematic pipeline that rigorously validates APIs, queries, and reasoning trajectories to construct ToolBench-V, a new high-quality instruction dataset that addresses the limitation of unreliable tool planning and invocation. Second, we propose Exploration-based Reflection Learning (EXPLORE), which enhances tool reflection capabilities by leveraging tool feedback through a dynamic \"Error -> Reflection -> Correction\" learning paradigm, resulting in our reflection dataset ToolBench-R and addressing the critical weakness in tool reflection. Finally, we obtain Tool-MVR by finetuning open-source LLMs (e.g., Qwen-7B) on both ToolBench-V and ToolBench-R. Our experiments demonstrate that Tool-MVR achieves state-of-the-art performance on StableToolBench, surpassing both ToolLLM (by 23.9%) and GPT-4 (by 15.3%) while reducing API calls by 31.4%, with strong generalization capabilities across unseen tools and scenarios. Additionally, on our proposed RefineToolBench, the first benchmark specifically designed to evaluate tool reflection capabilities, Tool-MVR achieves a 58.9% error correction rate, significantly outperforming ToolLLM's 9.1%.", "subjects": "Computation and Language (cs.CL)", "comments": "Accepted at the Research Track of KDD 2025", "pdf_url": "https://arxiv.org/pdf/2506.04625.pdf", "abstract_url": "https://arxiv.org/abs/2506.04625", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了Tool-MVR，一种通过元验证和反思学习增强的大型语言模型，旨在解决工具规划和调用不可靠及工具反思能力弱的问题。通过多代理元验证和基于探索的反思学习，Tool-MVR在StableToolBench上实现了最先进的性能，并在RefineToolBench上显著提高了错误纠正率。", "motivation": "解决大型语言模型在工具利用方面的两个主要限制：不可靠的工具规划和调用，以及弱的工具反思能力。", "method": "提出了Tool-MVR，结合了多代理元验证（MAMV）和基于探索的反思学习（EXPLORE）两种创新方法，构建了高质量的工具指令数据集和反思数据集。", "result": "Tool-MVR在StableToolBench上的性能超过了ToolLLM和GPT-4，同时减少了API调用次数，并在RefineToolBench上实现了58.9%的错误纠正率。", "conclusion": "Tool-MVR通过元验证和反思学习显著提高了大型语言模型的工具利用能力和错误纠正能力，展现出强大的泛化能力。"}}
{"id": "2506.04649", "title": "Flex-TravelPlanner: A Benchmark for Flexible Planning with Language Agents", "authors": ["Juhyun Oh", "Eunsu Kim", "Alice Oh"], "abstract": "Real-world planning problems require constant adaptation to changing requirements and balancing of competing constraints. However, current benchmarks for evaluating LLMs' planning capabilities primarily focus on static, single-turn scenarios. We introduce Flex-TravelPlanner, a benchmark that evaluates language models' ability to reason flexibly in dynamic planning scenarios. Building on the TravelPlanner dataset~\\citep{xie2024travelplanner}, we introduce two novel evaluation settings: (1) sequential constraint introduction across multiple turns, and (2) scenarios with explicitly prioritized competing constraints. Our analysis of GPT-4o and Llama 3.1 70B reveals several key findings: models' performance on single-turn tasks poorly predicts their ability to adapt plans across multiple turns; constraint introduction order significantly affects performance; and models struggle with constraint prioritization, often incorrectly favoring newly introduced lower priority preferences over existing higher-priority constraints. These findings highlight the importance of evaluating LLMs in more realistic, dynamic planning scenarios and suggest specific directions for improving model performance on complex planning tasks. The code and dataset for our framework are publicly available at", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04649.pdf", "abstract_url": "https://arxiv.org/abs/2506.04649", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了Flex-TravelPlanner基准测试，用于评估语言模型在动态规划场景中的灵活推理能力，揭示了当前模型在多轮适应和约束优先级处理上的不足。", "motivation": "解决现有基准测试在评估语言模型规划能力时过于静态和单轮的问题，提出更接近现实世界动态规划需求的评估框架。", "method": "基于TravelPlanner数据集，引入了两种新的评估设置：多轮顺序引入约束和明确优先级的竞争约束场景。", "result": "发现模型在单轮任务中的表现不能很好地预测其多轮适应能力，约束引入顺序和优先级处理对性能有显著影响。", "conclusion": "强调了在更现实的动态规划场景中评估语言模型的重要性，并指出了改进模型在复杂规划任务中性能的具体方向。"}}
{"id": "2506.04916", "title": "Energentic Intelligence: From Self-Sustaining Systems to Enduring Artificial Life", "authors": ["Atahan Karagoz"], "abstract": "This paper introduces Energentic Intelligence, a class of autonomous systems defined not by task performance, but by their capacity to sustain themselves through internal energy regulation. Departing from conventional reward-driven paradigms, these agents treat survival-maintaining functional operation under fluctuating energetic and thermal conditions-as the central objective. We formalize this principle through an energy-based utility function and a viability-constrained survival horizon, and propose a modular architecture that integrates energy harvesting, thermal regulation, and adaptive computation into a closed-loop control system. A simulated environment demonstrates the emergence of stable, resource-aware behavior without external supervision. Together, these contributions provide a theoretical and architectural foundation for deploying autonomous agents in resource-volatile settings where persistence must be self-regulated and infrastructure cannot be assumed.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Systems and Control (eess.SY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04916.pdf", "abstract_url": "https://arxiv.org/abs/2506.04916", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Systems and Control (eess.SY)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了Energentic Intelligence，一类通过内部能量调节维持自身运行的自主系统，其核心目标是生存而非任务性能。", "motivation": "解决在资源波动的环境中，自主系统如何在没有外部监督的情况下自我维持和持久运行的问题。", "method": "提出了一种基于能量的效用函数和生存视野的可行性约束，以及一个集成了能量收集、温度调节和自适应计算的模块化架构。", "result": "在模拟环境中展示了无需外部监督即可出现的稳定、资源意识行为。", "conclusion": "为在资源波动的环境中部署自主代理提供了理论和架构基础，其中持久性必须自我调节，且不能假设基础设施的存在。"}}
{"id": "2506.05109", "title": "Truly Self-Improving Agents Require Intrinsic Metacognitive Learning", "authors": ["Tennison Liu", "Mihaela van der Schaar"], "abstract": "Self-improving agents aim to continuously acquire new capabilities with minimal supervision. However, current approaches face two key limitations: their self-improvement processes are often rigid, fail to generalize across tasks domains, and struggle to scale with increasing agent capabilities. We argue that effective self-improvement requires intrinsic metacognitive learning, defined as an agent's intrinsic ability to actively evaluate, reflect on, and adapt its own learning processes. Drawing inspiration from human metacognition, we introduce a formal framework comprising three components: metacognitive knowledge (self-assessment of capabilities, tasks, and learning strategies), metacognitive planning (deciding what and how to learn), and metacognitive evaluation (reflecting on learning experiences to improve future learning). Analyzing existing self-improving agents, we find they rely predominantly on extrinsic metacognitive mechanisms, which are fixed, human-designed loops that limit scalability and adaptability. Examining each component, we contend that many ingredients for intrinsic metacognition are already present. Finally, we explore how to optimally distribute metacognitive responsibilities between humans and agents, and robustly evaluate and improve intrinsic metacognitive learning, key challenges that must be addressed to enable truly sustained, generalized, and aligned self-improvement.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "Published as a conference paper at ICML 2025", "pdf_url": "https://arxiv.org/pdf/2506.05109.pdf", "abstract_url": "https://arxiv.org/abs/2506.05109", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了自我改进代理需要内在元认知学习以实现持续能力提升的观点，提出了一个包含元认知知识、规划和评估的框架，并分析了现有方法的局限性。", "motivation": "解决当前自我改进代理在泛化性、扩展性和适应性方面的局限性。", "method": "引入了一个包含元认知知识、元认知规划和元认知评估的正式框架。", "result": "发现现有代理主要依赖外在元认知机制，内在元认知的许多要素已经存在。", "conclusion": "为了实现持续、泛化和对齐的自我改进，需要解决如何最优分配元认知责任和稳健评估内在元认知学习的关键挑战。"}}
{"id": "2506.04998", "title": "Mathematical Reasoning for Unmanned Aerial Vehicles: A RAG-Based Approach for Complex Arithmetic Reasoning", "authors": ["Mehdi Azarafza", "Mojtaba Nayyeri", "Faezeh Pasandideh", "Steffen Staab", "Achim Rettberg"], "abstract": "Autonomous UAV operation necessitates reliable mathematical reasoning for tasks such as trajectory planning and power management. While traditional flight control relies on hardcoded equations, recent Large Language Models (LLMs) offer potential for more flexible problem-solving but struggle with reliably selecting and applying correct mathematical formulations and executing precise multi-step arithmetic. We propose RAG-UAV, a retrieval-augmented generation framework designed to improve the mathematical reasoning of several LLMs (including GPT o1/Turbo, Llama-3.2/3.3, Mistral, and DeepSeek R1) in UAV-specific contexts by providing access to relevant domain literature. To conduct an initial assessment, we introduce the UAV-Math-Bench, a small problem set comprising 20 UAV-centric mathematical problems across four difficulty levels. Our experiments demonstrate that incorporating retrieval substantially increases exact answer accuracy (achieving up to 75% with o1), reduces instances of incorrect formulation selection (from 25% without RAG to 5% with RAG), decreases numerical errors, reducing Mean Squared Error (MSE) by orders of magnitude for the best-performing models. This pilot study indicates that RAG can enable general-purpose LLMs to function as more reliable tools for engineering analysis, although direct real-time flight control requires further investigation and validation on a larger scale. All benchmark data, question and answer are publicly available.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "15 pages, 7 figures, 4 appendix subsections", "pdf_url": "https://arxiv.org/pdf/2506.04998.pdf", "abstract_url": "https://arxiv.org/abs/2506.04998", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种基于检索增强生成（RAG）的框架RAG-UAV，旨在提升大型语言模型（LLMs）在无人机（UAV）特定上下文中的数学推理能力。通过引入UAV-Math-Bench基准测试，实验表明RAG显著提高了准确率，减少了错误选择数学公式和数值错误的情况。", "motivation": "自主无人机操作需要可靠的数学推理能力，而传统飞行控制依赖硬编码方程，大型语言模型虽提供灵活的问题解决潜力，但在选择和正确应用数学公式及执行精确的多步算术方面存在困难。", "method": "提出RAG-UAV框架，通过提供相关领域文献的访问，增强几种LLMs（包括GPT o1/Turbo、Llama-3.2/3.3、Mistral和DeepSeek R1）在无人机特定上下文中的数学推理能力。", "result": "实验结果显示，引入检索显著提高了准确答案的准确率（最高达到75%），减少了错误选择数学公式的情况（从25%降至5%），并大幅降低了数值错误的均方误差（MSE）。", "conclusion": "初步研究表明，RAG可以使通用LLMs成为更可靠的工程分析工具，但实时飞行控制需要进一步的大规模调查和验证。所有基准测试数据、问题和答案均已公开。"}}
{"id": "2506.05296", "title": "Control Tax: The Price of Keeping AI in Check", "authors": ["Mikhail Terekhov", "Zhen Ning David Liu", "Caglar Gulcehre", "Samuel Albanie"], "abstract": "The rapid integration of agentic AI into high-stakes real-world applications requires robust oversight mechanisms. The emerging field of AI Control (AIC) aims to provide such an oversight mechanism, but practical adoption depends heavily on implementation overhead. To study this problem better, we introduce the notion of Control tax -- the operational and financial cost of integrating control measures into AI pipelines. Our work makes three key contributions to the field of AIC: (1) we introduce a theoretical framework that quantifies the Control Tax and maps classifier performance to safety assurances; (2) we conduct comprehensive evaluations of state-of-the-art language models in adversarial settings, where attacker models insert subtle backdoors into code while monitoring models attempt to detect these vulnerabilities; and (3) we provide empirical financial cost estimates for control protocols and develop optimized monitoring strategies that balance safety and cost-effectiveness while accounting for practical constraints like auditing budgets. Our framework enables practitioners to make informed decisions by systematically connecting safety guarantees with their costs, advancing AIC through principled economic feasibility assessment across different deployment contexts.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.05296.pdf", "abstract_url": "https://arxiv.org/abs/2506.05296", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了控制税的概念，即整合控制措施到AI管道中的操作和财务成本，并提出了一个理论框架来量化控制税，将分类器性能映射到安全保证。通过对抗性设置下的全面评估和财务成本估计，开发了平衡安全性和成本效益的优化监控策略。", "motivation": "随着代理AI在高风险现实世界应用中的快速集成，需要强大的监督机制。AI控制（AIC）领域旨在提供这样的监督机制，但实际采用很大程度上取决于实施开销。", "method": "引入控制税的理论框架，量化控制成本并将分类器性能映射到安全保证；在对抗性设置下对最先进的语言模型进行全面评估；提供控制协议的经验财务成本估计并开发优化监控策略。", "result": "提出了一个框架，使从业者能够通过系统地将安全保证与其成本联系起来做出明智的决策，通过原则性的经济可行性评估推进AIC在不同部署环境中的应用。", "conclusion": "通过量化控制税和开发成本效益平衡的监控策略，本文为AI控制领域提供了理论和实践上的贡献，促进了在不同部署背景下对AI安全的经济可行性评估。"}}
{"id": "2506.04265", "title": "CORA: Coalitional Rational Advantage Decomposition for Multi-Agent Policy Gradients", "authors": ["Mengda Ji", "Genjiu Xu", "Liying Wang"], "abstract": "This work focuses on the credit assignment problem in cooperative multi-agent reinforcement learning (MARL). Sharing the global advantage among agents often leads to suboptimal policy updates as it fails to account for the distinct contributions of agents. Although numerous methods consider global or individual contributions for credit assignment, a detailed analysis at the coalition level remains lacking in many approaches. This work analyzes the over-updating problem during multi-agent policy updates from a coalition-level perspective. To address this issue, we propose a credit assignment method called Coalitional Rational Advantage Decomposition (CORA). CORA evaluates coalitional advantages via marginal contributions from all possible coalitions and decomposes advantages using the core solution from cooperative game theory, ensuring coalitional rationality. To reduce computational overhead, CORA employs random coalition sampling. Experiments on matrix games, differential games, and multi-agent collaboration benchmarks demonstrate that CORA outperforms strong baselines, particularly in tasks with multiple local optima. These findings highlight the importance of coalition-aware credit assignment for improving MARL performance.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04265.pdf", "abstract_url": "https://arxiv.org/abs/2506.04265", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Computer Science and Game Theory (cs.GT)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为CORA的信用分配方法，用于解决协作多智能体强化学习中的信用分配问题。CORA通过评估所有可能联盟的边际贡献来分解优势，确保联盟理性，并通过随机联盟采样减少计算开销。实验证明，CORA在多种任务中优于强基线，特别是在具有多个局部最优的任务中。", "motivation": "解决协作多智能体强化学习中的信用分配问题，特别是在共享全局优势导致次优策略更新的情况下，缺乏对联盟层面贡献的详细分析。", "method": "提出了一种名为CORA的信用分配方法，通过评估所有可能联盟的边际贡献来分解优势，并使用合作博弈论中的核心解确保联盟理性，同时采用随机联盟采样以减少计算开销。", "result": "在矩阵游戏、差分游戏和多智能体协作基准测试中，CORA表现优于强基线，特别是在具有多个局部最优的任务中。", "conclusion": "联盟感知的信用分配对于提高多智能体强化学习性能至关重要，CORA方法在这方面表现出色。"}}
{"id": "2506.04236", "title": "Spore in the Wild: Case Study on Spore.fun, a Real-World Experiment of Sovereign Agent Open-ended Evolution on Blockchain with TEEs", "authors": ["Botao Amber Hu", "Helena Rong"], "abstract": "In Artificial Life (ALife) research, replicating Open-Ended Evolution (OEE)-the continuous emergence of novelty observed in biological life-has traditionally been pursued within isolated closed system simulations, such as Tierra and Avida, which have typically plateaued after an initial burst of novelty, failing to achieve sustained OEE. Scholars suggest that OEE requires an \"open\" system that continually exchanges information or energy with its environment. A recent technological innovation in decentralized physical infrastructure networks (DePIN) providing permissionless computational substrates enables deploying large language model (LLM)-based AI agents on blockchains integrated with Trusted Execution Environments (TEEs). This enables on-chain agents to operate autonomously \"in the wild,\" achieving self-sovereignty without human oversight. These agents can control their own social media accounts and cryptocurrency wallets, allowing them to interact directly with blockchain-based financial networks and broader human social media. Building on this new paradigm of on-chain agents,", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Neural and Evolutionary Computing (cs.NE)", "comments": "Submitted to ALIFE 2025", "pdf_url": "https://arxiv.org/pdf/2506.04236.pdf", "abstract_url": "https://arxiv.org/abs/2506.04236", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)", "Neural and Evolutionary Computing (cs.NE)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了在区块链与可信执行环境（TEEs）结合的技术背景下，通过Spore.fun案例研究，实现主权代理在开放环境中的开放式演化（OEE）的可能性。", "motivation": "传统的人工生命（ALife）研究在封闭系统模拟中难以实现持续的开放式演化（OEE），学者认为需要一个与环境持续交换信息或能量的“开放”系统。", "method": "利用去中心化物理基础设施网络（DePIN）和区块链与TEEs的结合，部署基于大型语言模型（LLM）的AI代理，使其能够在无人类监督的情况下自主运作。", "result": "通过Spore.fun案例，展示了在区块链上实现主权代理的开放式演化的可行性，这些代理能够控制自己的社交媒体账户和加密货币钱包，直接与基于区块链的金融网络和更广泛的人类社交媒体互动。", "conclusion": "这项研究为在开放系统中实现持续的开放式演化提供了新的技术路径和实证案例，推动了人工生命和区块链技术的交叉研究。"}}
{"id": "2506.03922", "title": "HSSBench: Benchmarking Humanities and Social Sciences Ability for Multimodal Large Language Models", "authors": ["Zhaolu Kang", "Junhao Gong", "Jiaxu Yan", "Wanke Xia", "Yian Wang", "Ziwen Wang", "Huaxuan Ding", "Zhuo Cheng", "Wenhao Cao", "Zhiyuan Feng", "Siqi He", "Shannan Yan", "Junzhe Chen", "Xiaomin He", "Chaoya Jiang", "Wei Ye", "Kaidong Yu", "Xuelong Li"], "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated significant potential to advance a broad range of domains. However, current benchmarks for evaluating MLLMs primarily emphasize general knowledge and vertical step-by-step reasoning typical of STEM disciplines, while overlooking the distinct needs and potential of the Humanities and Social Sciences (HSS). Tasks in the HSS domain require more horizontal, interdisciplinary thinking and a deep integration of knowledge across related fields, which presents unique challenges for MLLMs, particularly in linking abstract concepts with corresponding visual representations. Addressing this gap, we present HSSBench, a dedicated benchmark designed to assess the capabilities of MLLMs on HSS tasks in multiple languages, including the six official languages of the United Nations. We also introduce a novel data generation pipeline tailored for HSS scenarios, in which multiple domain experts and automated agents collaborate to generate and iteratively refine each sample. HSSBench contains over 13,000 meticulously designed samples, covering six key categories. We benchmark more than 20 mainstream MLLMs on HSSBench and demonstrate that it poses significant challenges even for state-of-the-art models. We hope that this benchmark will inspire further research into enhancing the cross-disciplinary reasoning abilities of MLLMs, especially their capacity to internalize and connect knowledge across fields.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.03922.pdf", "abstract_url": "https://arxiv.org/abs/2506.03922", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "HSSBench是一个专门为评估多模态大语言模型（MLLMs）在人文学科和社会科学（HSS）领域能力而设计的基准测试，包含超过13,000个样本，覆盖六个关键类别，旨在促进MLLMs跨学科推理能力的研究。", "motivation": "当前评估MLLMs的基准主要强调STEM学科的通用知识和垂直逐步推理，忽视了HSS领域的独特需求和潜力，特别是在将抽象概念与相应视觉表示联系方面的挑战。", "method": "提出了HSSBench基准和一个新颖的数据生成流程，该流程通过多个领域专家和自动化代理的合作来生成并迭代优化每个样本，支持包括联合国六种官方语言在内的多种语言。", "result": "对超过20个主流MLLMs的基准测试表明，即使是最先进的模型也面临重大挑战。", "conclusion": "HSSBench有望激发进一步研究，以增强MLLMs的跨学科推理能力，特别是在内化和连接跨领域知识方面的能力。"}}
{"id": "2506.04293", "title": "AUTOCT: Automating Interpretable Clinical Trial Prediction with LLM Agents", "authors": ["Fengze Liu", "Haoyu Wang", "Joonhyuk Cho", "Dan Roth", "Andrew W. Lo"], "abstract": "Clinical trials are critical for advancing medical treatments but remain prohibitively expensive and time-consuming. Accurate prediction of clinical trial outcomes can significantly reduce research and development costs and accelerate drug discovery. While recent deep learning models have shown promise by leveraging unstructured data, their black-box nature, lack of interpretability, and vulnerability to label leakage limit their practical use in high-stakes biomedical contexts. In this work, we propose AutoCT, a novel framework that combines the reasoning capabilities of large language models with the explainability of classical machine learning. AutoCT autonomously generates, evaluates, and refines tabular features based on public information without human input. Our method uses Monte Carlo Tree Search to iteratively optimize predictive performance. Experimental results show that AutoCT performs on par with or better than SOTA methods on clinical trial prediction tasks within only a limited number of self-refinement iterations, establishing a new paradigm for scalable, interpretable, and cost-efficient clinical trial prediction.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04293.pdf", "abstract_url": "https://arxiv.org/abs/2506.04293", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "AutoCT是一个结合大型语言模型推理能力和经典机器学习可解释性的新框架，用于自动化、可解释的临床试验预测。", "motivation": "临床试验对于推进医学治疗至关重要，但成本高昂且耗时。准确预测临床试验结果可以显著降低研发成本并加速药物发现。", "method": "AutoCT利用蒙特卡洛树搜索自主生成、评估和优化基于公共信息的表格特征，无需人工输入。", "result": "实验结果显示，AutoCT在有限的自我优化迭代次数内，在临床试验预测任务上的表现与或优于现有最先进方法。", "conclusion": "AutoCT为可扩展、可解释且成本效益高的临床试验预测建立了新范式。"}}
{"id": "2506.05010", "title": "ComfyUI-Copilot: An Intelligent Assistant for Automated Workflow Development", "authors": ["Zhenran Xu", "Xue Yang", "Yiyu Wang", "Qingli Hu", "Zijiao Wu", "Longyue Wang", "Weihua Luo", "Kaifu Zhang", "Baotian Hu", "Min Zhang"], "abstract": "We introduce ComfyUI-Copilot, a large language model-powered plugin designed to enhance the usability and efficiency of ComfyUI, an open-source platform for AI-driven art creation. Despite its flexibility and user-friendly interface, ComfyUI can present challenges to newcomers, including limited documentation, model misconfigurations, and the complexity of workflow design. ComfyUI-Copilot addresses these challenges by offering intelligent node and model recommendations, along with automated one-click workflow construction. At its core, the system employs a hierarchical multi-agent framework comprising a central assistant agent for task delegation and specialized worker agents for different usages, supported by our curated ComfyUI knowledge bases to streamline debugging and deployment. We validate the effectiveness of ComfyUI-Copilot through both offline quantitative evaluations and online user feedback, showing that it accurately recommends nodes and accelerates workflow development. Additionally, use cases illustrate that ComfyUI-Copilot lowers entry barriers for beginners and enhances workflow efficiency for experienced users. The ComfyUI-Copilot installation package and a demo video are available at", "subjects": "Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2506.05010.pdf", "abstract_url": "https://arxiv.org/abs/2506.05010", "categories": ["Computation and Language (cs.CL)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "ComfyUI-Copilot是一个基于大型语言模型的插件，旨在提高ComfyUI平台的可用性和效率，通过智能节点和模型推荐以及一键式工作流构建，解决新用户面临的挑战。", "motivation": "解决ComfyUI平台对新用户不友好、文档有限、模型配置错误和工作流设计复杂的问题。", "method": "采用分层多代理框架，包括一个中央助理代理和多个专用工作代理，利用定制的ComfyUI知识库来简化调试和部署。", "result": "离线定量评估和在线用户反馈验证了ComfyUI-Copilot能准确推荐节点并加速工作流开发，降低初学者门槛并提升有经验用户的工作效率。", "conclusion": "ComfyUI-Copilot通过智能辅助功能显著提升了ComfyUI平台的用户体验和工作效率，适用于不同技能水平的用户。"}}
{"id": "2506.04276", "title": "Autonomous Collaborative Scheduling of Time-dependent UAVs, Workers and Vehicles for Crowdsensing in Disaster Response", "authors": ["Lei Han", "Yitong Guo", "Pengfei Yang", "Zhiyong Yu", "Liang Wang", "Quan Wang", "Zhiwen Yu"], "abstract": "Natural disasters have caused significant losses to human society, and the timely and efficient acquisition of post-disaster environmental information is crucial for the effective implementation of rescue operations. Due to the complexity of post-disaster environments, existing sensing technologies face challenges such as weak environmental adaptability, insufficient specialized sensing capabilities, and limited practicality of sensing solutions. This paper explores the heterogeneous multi-agent online autonomous collaborative scheduling algorithm HoAs-PALN, aimed at achieving efficient collection of post-disaster environmental information. HoAs-PALN is realized through adaptive dimensionality reduction in the matching process and local Nash equilibrium game, facilitating autonomous collaboration among time-dependent UAVs, workers and vehicles to enhance sensing scheduling. (1) In terms of adaptive dimensionality reduction during the matching process, HoAs-PALN significantly reduces scheduling decision time by transforming a five-dimensional matching process into two categories of three-dimensional matching processes; (2) Regarding the local Nash equilibrium game, HoAs-PALN combines the softmax function to optimize behavior selection probabilities and introduces a local Nash equilibrium determination mechanism to ensure scheduling decision performance. Finally, we conducted detailed experiments based on extensive real-world and simulated data. Compared with the baselines (GREEDY, K-WTA, MADL and MARL), HoAs-PALN improves task completion rates by 64.12%, 46.48%, 16.55%, and 14.03% on average, respectively, while each online scheduling decision takes less than 10 seconds, demonstrating its effectiveness in dynamic post-disaster environments.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04276.pdf", "abstract_url": "https://arxiv.org/abs/2506.04276", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了异构多智能体在线自主协同调度算法HoAs-PALN，旨在实现灾后环境信息的高效收集。通过匹配过程中的自适应降维和局部纳什均衡博弈，HoAs-PALN促进了时间依赖的无人机、工人和车辆之间的自主协作，以增强感知调度。实验表明，HoAs-PALN在动态灾后环境中表现出色。", "motivation": "自然灾害给人类社会造成了重大损失，及时高效地获取灾后环境信息对于有效实施救援行动至关重要。由于灾后环境的复杂性，现有的传感技术面临着环境适应性弱、专业传感能力不足和传感解决方案实用性有限等挑战。", "method": "本文提出了异构多智能体在线自主协同调度算法HoAs-PALN，通过匹配过程中的自适应降维和局部纳什均衡博弈，实现了时间依赖的无人机、工人和车辆之间的自主协作。", "result": "与基线（GREEDY、K-WTA、MADL和MARL）相比，HoAs-PALN平均分别提高了任务完成率64.12%、46.48%、16.55%和14.03%，同时每个在线调度决策耗时少于10秒。", "conclusion": "HoAs-PALN算法在动态灾后环境中表现出色，显著提高了任务完成率并减少了调度决策时间，为灾后救援行动提供了有效的技术支持。"}}
{"id": "2506.04390", "title": "Through the Stealth Lens: Rethinking Attacks and Defenses in RAG", "authors": ["Sarthak Choudhary", "Nils Palumbo", "Ashish Hooda", "Krishnamurthy Dj Dvijotham", "Somesh Jha"], "abstract": "Retrieval-augmented generation (RAG) systems are vulnerable to attacks that inject poisoned passages into the retrieved set, even at low corruption rates. We show that existing attacks are not designed to be stealthy, allowing reliable detection and mitigation. We formalize stealth using a distinguishability-based security game. If a few poisoned passages are designed to control the response, they must differentiate themselves from benign ones, inherently compromising stealth. This motivates the need for attackers to rigorously analyze intermediate signals involved in generation$\\unicode{x2014}$such as attention patterns or next-token probability distributions$\\unicode{x2014}$to avoid easily detectable traces of manipulation. Leveraging attention patterns, we propose a passage-level score$\\unicode{x2014}$the Normalized Passage Attention Score$\\unicode{x2014}$used by our Attention-Variance Filter algorithm to identify and filter potentially poisoned passages. This method mitigates existing attacks, improving accuracy by up to $\\sim 20 \\%$ over baseline defenses. To probe the limits of attention-based defenses, we craft stealthier adaptive attacks that obscure such traces, achieving up to $35 \\%$ attack success rate, and highlight the challenges in improving stealth.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04390.pdf", "abstract_url": "https://arxiv.org/abs/2506.04390", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文探讨了检索增强生成（RAG）系统在面对注入毒化段落攻击时的脆弱性，并提出了一种基于注意力模式的防御方法。", "motivation": "解决RAG系统在低污染率下仍易受毒化段落攻击的问题，以及现有攻击缺乏隐蔽性导致易于检测和缓解的局限性。", "method": "通过形式化隐蔽性概念，提出基于注意力模式的Normalized Passage Attention Score和Attention-Variance Filter算法，以识别和过滤潜在毒化段落。", "result": "该方法有效缓解了现有攻击，将准确率比基线防御提高了约20%。同时，研究还设计了更隐蔽的自适应攻击，成功率达到35%，揭示了提升隐蔽性的挑战。", "conclusion": "研究表明，基于注意力的防御方法能有效对抗现有攻击，但面对更隐蔽的自适应攻击时仍存在挑战，强调了在RAG系统中进一步研究防御策略的必要性。"}}
{"id": "2506.04399", "title": "Unsupervised Meta-Testing with Conditional Neural Processes for Hybrid Meta-Reinforcement Learning", "authors": ["Suzan Ece Ada", "Emre Ugur"], "abstract": "We introduce Unsupervised Meta-Testing with Conditional Neural Processes (UMCNP), a novel hybrid few-shot meta-reinforcement learning (meta-RL) method that uniquely combines, yet distinctly separates, parameterized policy gradient-based (PPG) and task inference-based few-shot meta-RL. Tailored for settings where the reward signal is missing during meta-testing, our method increases sample efficiency without requiring additional samples in meta-training. UMCNP leverages the efficiency and scalability of Conditional Neural Processes (CNPs) to reduce the number of online interactions required in meta-testing. During meta-training, samples previously collected through PPG meta-RL are efficiently reused for learning task inference in an offline manner. UMCNP infers the latent representation of the transition dynamics model from a single test task rollout with unknown parameters. This approach allows us to generate rollouts for self-adaptation by interacting with the learned dynamics model. We demonstrate our method can adapt to an unseen test task using significantly fewer samples during meta-testing than the baselines in 2D-Point Agent and continuous control meta-RL benchmarks, namely, cartpole with unknown angle sensor bias, walker agent with randomized dynamics parameters.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": "Published in IEEE Robotics and Automation Letters Volume: 9, Issue: 10, 8427 - 8434, October 2024. 8 pages, 7 figures", "pdf_url": "https://arxiv.org/pdf/2506.04399.pdf", "abstract_url": "https://arxiv.org/abs/2506.04399", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了UMCNP，一种新型的混合少样本元强化学习方法，通过结合参数化策略梯度基础和任务推断基础的元强化学习，提高了在元测试阶段缺少奖励信号时的样本效率。", "motivation": "解决在元测试阶段缺少奖励信号时，如何提高样本效率而不需要在元训练阶段增加额外样本的问题。", "method": "利用条件神经过程（CNPs）的效率和可扩展性，减少元测试阶段所需的在线交互次数，并在元训练阶段高效重用通过PPG元强化学习收集的样本。", "result": "在2D点代理和连续控制元强化学习基准测试中，UMCNP能够比基线方法使用更少的样本适应未见过的测试任务。", "conclusion": "UMCNP通过结合和分离参数化策略梯度基础和任务推断基础的元强化学习，有效提高了在缺少奖励信号的元测试阶段的样本效率和适应性。"}}
{"id": "2506.05154", "title": "Knowledgeable-r1: Policy Optimization for Knowledge Exploration in Retrieval-Augmented Generation", "authors": ["Chenyu Lin", "Yilin Wen", "Du Su", "Fei Sun", "Muhan Chen", "Chenfu Bao", "Zhonghou Lv"], "abstract": "Retrieval-augmented generation (RAG) is a mainstream method for improving performance on knowledge-intensive tasks. However,current RAG systems often place too much emphasis on retrieved contexts. This can lead to reliance on inaccurate sources and overlook the model's inherent knowledge, especially when dealing with misleading or excessive information. To resolve this imbalance, we propose Knowledgeable-r1 that using joint sampling and define multi policy distributions in knowledge capability exploration to stimulate large language models'self-integrated utilization of parametric and contextual knowledge. Experiments show that Knowledgeable-r1 significantly enhances robustness and reasoning accuracy in both parameters and contextual conflict tasks and general RAG tasks, especially outperforming baselines by 17.07% in counterfactual scenarios and demonstrating consistent gains across RAG tasks. Our code are available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.05154.pdf", "abstract_url": "https://arxiv.org/abs/2506.05154", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "Knowledgeable-r1是一种针对检索增强生成（RAG）系统的策略优化方法，旨在平衡检索上下文与模型固有知识的使用，以提高知识密集型任务的性能。", "motivation": "当前RAG系统过于依赖检索到的上下文，可能导致对不准确来源的依赖和忽视模型固有知识的问题，特别是在处理误导性或过量信息时。", "method": "提出了Knowledgeable-r1，通过联合采样和定义多策略分布在知识能力探索中，激发大型语言模型自我整合利用参数化和上下文知识。", "result": "实验表明，Knowledgeable-r1显著增强了在参数和上下文冲突任务及一般RAG任务中的鲁棒性和推理准确性，特别是在反事实场景中比基线高出17.07%，并在各种RAG任务中表现出一致的增益。", "conclusion": "Knowledgeable-r1通过优化策略，有效平衡了检索上下文与模型固有知识的使用，提高了RAG系统在知识密集型任务中的性能和鲁棒性。"}}
{"id": "2506.05167", "title": "ECoRAG: Evidentiality-guided Compression for Long Context RAG", "authors": ["Yeonseok Jeong", "Jinsu Kim", "Dohyeon Lee", "Seung-won Hwang"], "abstract": "Large Language Models (LLMs) have shown remarkable performance in Open-Domain Question Answering (ODQA) by leveraging external documents through Retrieval-Augmented Generation (RAG). To reduce RAG overhead, from longer context, context compression is necessary. However, prior compression methods do not focus on filtering out non-evidential information, which limit the performance in LLM-based RAG. We thus propose Evidentiality-guided RAG, or \\textbf{ECoRAG} framework. ECoRAG improves LLM performance by compressing retrieved documents based on evidentiality, ensuring whether answer generation is supported by the correct evidence. As an additional step, ECoRAG reflects whether the compressed content provides sufficient evidence, and if not, retrieves more until sufficient. Experiments show that ECoRAG improves LLM performance on ODQA tasks, outperforming existing compression methods. Furthermore, ECoRAG is highly cost-efficient, as it not only reduces latency but also minimizes token usage by retaining only the necessary information to generate the correct answer. Code is available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.05167.pdf", "abstract_url": "https://arxiv.org/abs/2506.05167", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了ECoRAG框架，通过基于证据性的检索文档压缩，提升大型语言模型在开放域问答任务中的性能，同时降低成本。", "motivation": "解决现有检索增强生成（RAG）方法在长上下文压缩中未能有效过滤非证据信息，从而限制性能的问题。", "method": "提出ECoRAG框架，通过证据性指导的压缩方法，确保答案生成得到正确证据支持，并在证据不足时进行补充检索。", "result": "实验表明，ECoRAG在开放域问答任务中优于现有压缩方法，同时显著降低了延迟和令牌使用量。", "conclusion": "ECoRAG不仅提高了LLM的性能，还通过保留生成正确答案所需的最小信息量，实现了高成本效益。"}}
{"id": "2506.05305", "title": "ProRefine: Inference-time Prompt Refinement with Textual Feedback", "authors": ["Deepak Pandita", "Tharindu Cyril Weerasooriya", "Ankit Parag Shah", "Christopher M. Homan", "Wei Wei"], "abstract": "Agentic workflows, where multiple AI agents collaborate to accomplish complex tasks like reasoning or planning, are becoming increasingly prevalent. However, these workflows often suffer from error propagation and sub-optimal performance, largely due to poorly designed prompts that fail to effectively guide individual agents. This is a critical problem because it limits the reliability and scalability of these powerful systems. We introduce ProRefine, an innovative inference-time prompt optimization method that leverages textual feedback from large language models (LLMs) to address this challenge. ProRefine dynamically refines prompts for multi-step reasoning tasks without additional training or ground truth labels. Evaluated on five benchmark mathematical reasoning datasets, ProRefine significantly surpasses zero-shot Chain-of-Thought baselines by 3 to 37 percentage points. This approach not only boosts accuracy but also allows smaller models to match the performance of larger ones, highlighting its potential for efficient and scalable AI deployment, and democratizing access to high-performing AI.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.05305.pdf", "abstract_url": "https://arxiv.org/abs/2506.05305", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "ProRefine是一种创新的推理时提示优化方法，利用大型语言模型的文本反馈动态优化多步推理任务的提示，无需额外训练或真实标签，显著提高了数学推理任务的准确性。", "motivation": "解决多AI代理协作工作流中由于提示设计不佳导致的错误传播和性能不佳问题，提高系统的可靠性和可扩展性。", "method": "引入ProRefine方法，利用大型语言模型(LLMs)的文本反馈在推理时动态优化提示。", "result": "在五个数学推理基准数据集上，ProRefine显著超过零样本思维链基线3至37个百分点，使较小模型能匹配较大模型的性能。", "conclusion": "ProRefine不仅提高了准确性，还促进了高效和可扩展的AI部署， democratizing access to high-performing AI."}}
{"id": "2506.05278", "title": "Micro-Act: Mitigate Knowledge Conflict in Question Answering via Actionable Self-Reasoning", "authors": ["Nan Huo", "Jinyang Li", "Bowen Qin", "Ge Qu", "Xiaolong Li", "Xiaodong Li", "Chenhao Ma", "Reynold Cheng"], "abstract": "Retrieval-Augmented Generation (RAG) systems commonly suffer from Knowledge Conflicts, where retrieved external knowledge contradicts the inherent, parametric knowledge of large language models (LLMs). It adversely affects performance on downstream tasks such as question answering (QA). Existing approaches often attempt to mitigate conflicts by directly comparing two knowledge sources in a side-by-side manner, but this can overwhelm LLMs with extraneous or lengthy contexts, ultimately hindering their ability to identify and mitigate inconsistencies. To address this issue, we propose Micro-Act a framework with a hierarchical action space that automatically perceives context complexity and adaptively decomposes each knowledge source into a sequence of fine-grained comparisons. These comparisons are represented as actionable steps, enabling reasoning beyond the superficial context. Through extensive experiments on five benchmark datasets, Micro-Act consistently achieves significant increase in QA accuracy over state-of-the-art baselines across all 5 datasets and 3 conflict types, especially in temporal and semantic types where all baselines fail significantly. More importantly, Micro-Act exhibits robust performance on non-conflict questions simultaneously, highlighting its practical value in real-world RAG applications.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "Accepted by ACL 2025 Main", "pdf_url": "https://arxiv.org/pdf/2506.05278.pdf", "abstract_url": "https://arxiv.org/abs/2506.05278", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了Micro-Act框架，通过分层动作空间自动感知上下文复杂性并自适应地将每个知识源分解为一系列细粒度比较，以解决检索增强生成（RAG）系统中知识冲突的问题，显著提高了问答（QA）任务的准确性。", "motivation": "检索增强生成（RAG）系统常遭受知识冲突的困扰，即检索到的外部知识与大型语言模型（LLMs）的内在参数知识相矛盾，这影响了问答（QA）等下游任务的性能。现有方法通常通过直接比较两个知识源来缓解冲突，但这可能会让LLMs淹没于无关或冗长的上下文中，最终阻碍其识别和缓解不一致性的能力。", "method": "我们提出了Micro-Act框架，该框架具有分层动作空间，能够自动感知上下文复杂性，并自适应地将每个知识源分解为一系列细粒度比较。这些比较被表示为可操作的步骤，使得推理能够超越表面上下文。", "result": "在五个基准数据集上的广泛实验中，Micro-Act在所有5个数据集和3种冲突类型上均显著优于现有最先进的基线方法，特别是在时间和语义类型上，所有基线方法均显著失败。更重要的是，Micro-Act在非冲突问题上也表现出稳健的性能，突出了其在现实世界RAG应用中的实用价值。", "conclusion": "Micro-Act框架通过其分层动作空间和细粒度比较，有效地缓解了知识冲突问题，显著提高了QA任务的准确性，并在非冲突问题上保持了稳健性能，展示了其在现实世界RAG应用中的广泛潜力。"}}
{"id": "2506.05309", "title": "Time to Talk: LLM Agents for Asynchronous Group Communication in Mafia Games", "authors": ["Niv Eckhaus", "Uri Berger", "Gabriel Stanovsky"], "abstract": "LLMs are used predominantly in synchronous communication, where a human user and a model communicate in alternating turns. In contrast, many real-world settings are inherently asynchronous. For example, in group chats, online team meetings, or social games, there is no inherent notion of turns; therefore, the decision of when to speak forms a crucial part of the participant's decision making. In this work, we develop an adaptive asynchronous LLM-agent which, in addition to determining what to say, also decides when to say it. To evaluate our agent, we collect a unique dataset of online Mafia games, including both human participants, as well as our asynchronous agent. Overall, our agent performs on par with human players, both in game performance, as well as in its ability to blend in with the other human players. Our analysis shows that the agent's behavior in deciding when to speak closely mirrors human patterns, although differences emerge in message content. We release all our data and code to support and encourage further research for more realistic asynchronous communication between LLM agents. This work paves the way for integration of LLMs into realistic human group settings, from assistance in team discussions to educational and professional environments where complex social dynamics must be navigated.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.05309.pdf", "abstract_url": "https://arxiv.org/abs/2506.05309", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文开发了一种自适应异步LLM代理，用于决定何时以及说什么，以在异步群组通信中（如Mafia游戏）与人类玩家表现相当。", "motivation": "解决LLM在异步通信（如群聊、在线团队会议或社交游戏）中的应用问题，其中决定何时发言是参与者决策的关键部分。", "method": "开发了一种自适应异步LLM代理，该代理不仅决定说什么，还决定何时说，并通过收集在线Mafia游戏的数据集来评估代理。", "result": "代理在游戏表现和与人类玩家融合的能力上与人类玩家相当，其决定何时发言的行为模式与人类相似，但在消息内容上存在差异。", "conclusion": "这项工作为将LLM整合到现实的人类群体设置中铺平了道路，从团队讨论的辅助到需要导航复杂社交动态的教育和专业环境。"}}
{"id": "2506.04836", "title": "Oversight Structures for Agentic AI in Public-Sector Organizations", "authors": ["Chris Schmitz", "Jonathan Rystrøm", "Jan Batzner"], "abstract": "This paper finds that the introduction of agentic AI systems intensifies existing challenges to traditional public sector oversight mechanisms -- which rely on siloed compliance units and episodic approvals rather than continuous, integrated supervision. We identify five governance dimensions essential for responsible agent deployment: cross-departmental implementation, comprehensive evaluation, enhanced security protocols, operational visibility, and systematic auditing. We evaluate the capacity of existing oversight structures to meet these challenges, via a mixed-methods approach consisting of a literature review and interviews with civil servants in AI-related roles. We find that agent oversight poses intensified versions of three existing governance challenges: continuous oversight, deeper integration of governance and operational capabilities, and interdepartmental coordination. We propose approaches that both adapt institutional structures and design agent oversight compatible with public sector constraints.", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI)", "comments": "To appear at REALM@ACL2025", "pdf_url": "https://arxiv.org/pdf/2506.04836.pdf", "abstract_url": "https://arxiv.org/abs/2506.04836", "categories": ["Computers and Society (cs.CY)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文发现，引入代理性AI系统加剧了公共部门传统监督机制面临的挑战，这些机制依赖于孤立的合规单位和阶段性批准，而非持续、集成的监督。我们提出了五个对负责任代理部署至关重要的治理维度，并通过文献综述和对AI相关职位公务员的访谈，评估现有监督结构应对这些挑战的能力。", "motivation": "解决代理性AI系统引入公共部门后对传统监督机制带来的挑战，特别是持续监督、治理与运营能力的更深层次整合以及跨部门协调的问题。", "method": "采用混合方法，包括文献综述和对AI相关职位公务员的访谈，评估现有监督结构的能力。", "result": "发现代理监督加剧了三个现有治理挑战：持续监督、治理与运营能力的更深层次整合以及跨部门协调。", "conclusion": "提出了既适应制度结构又设计出与公共部门约束兼容的代理监督方法，以应对这些挑战。"}}
{"id": "2506.04838", "title": "On Automating Security Policies with Contemporary LLMs", "authors": ["Pablo Fernández Saura", "K. R. Jayaram", "Vatche Isahagian", "Jorge Bernal Bernabé", "Antonio Skarmeta"], "abstract": "The complexity of modern computing environments and the growing sophistication of cyber threats necessitate a more robust, adaptive, and automated approach to security enforcement. In this paper, we present a framework leveraging large language models (LLMs) for automating attack mitigation policy compliance through an innovative combination of in-context learning and retrieval-augmented generation (RAG). We begin by describing how our system collects and manages both tool and API specifications, storing them in a vector database to enable efficient retrieval of relevant information. We then detail the architectural pipeline that first decomposes high-level mitigation policies into discrete tasks and subsequently translates each task into a set of actionable API calls. Our empirical evaluation, conducted using publicly available CTI policies in STIXv2 format and Windows API documentation, demonstrates significant improvements in precision, recall, and F1-score when employing RAG compared to a non-RAG baseline.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": "Short Paper. Accepted To Appear in IEEE SSE 2025 (part of SERVICES 2025)", "pdf_url": "https://arxiv.org/pdf/2506.04838.pdf", "abstract_url": "https://arxiv.org/abs/2506.04838", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种利用大型语言模型（LLMs）自动化安全策略的框架，通过结合上下文学习和检索增强生成（RAG）技术，显著提高了攻击缓解策略的自动化执行效率。", "motivation": "现代计算环境的复杂性和网络威胁的日益复杂化，要求采用更强大、自适应和自动化的安全执行方法。", "method": "框架首先收集和管理工具及API规范，将其存储在向量数据库中以便高效检索相关信息；然后通过架构管道将高级缓解策略分解为离散任务，并将每个任务转化为可操作的API调用。", "result": "使用公开可用的CTI策略（STIXv2格式）和Windows API文档进行的实证评估显示，与不使用RAG的基线相比，采用RAG在精确度、召回率和F1分数上均有显著提升。", "conclusion": "研究表明，结合大型语言模型和检索增强生成技术，可以有效地自动化安全策略的执行，为应对复杂网络威胁提供了新的解决方案。"}}
{"id": "2506.05020", "title": "Hierarchical Language Models for Semantic Navigation and Manipulation in an Aerial-Ground Robotic System", "authors": ["Haokun Liu", "Zhaoqi Ma", "Yunong Li", "Junichiro Sugihara", "Yicheng Chen", "Jinjie Li", "Moju Zhao"], "abstract": "Heterogeneous multi-robot systems show great potential in complex tasks requiring coordinated hybrid cooperation. However, traditional approaches relying on static models often struggle with task diversity and dynamic environments. This highlights the need for generalizable intelligence that can bridge high-level reasoning with low-level execution across heterogeneous agents. To address this, we propose a hierarchical framework integrating a prompted Large Language Model (LLM) and a GridMask-enhanced fine-tuned Vision Language Model (VLM). The LLM performs task decomposition and global semantic map construction, while the VLM extracts task-specified semantic labels and 2D spatial information from aerial images to support local planning. Within this framework, the aerial robot follows a globally optimized semantic path and continuously provides bird-view images, guiding the ground robot's local semantic navigation and manipulation, including target-absent scenarios where implicit alignment is maintained. Experiments on a real-world letter-cubes arrangement task demonstrate the framework's adaptability and robustness in dynamic environments. To the best of our knowledge, this is the first demonstration of an aerial-ground heterogeneous system integrating VLM-based perception with LLM-driven task reasoning and motion planning.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.05020.pdf", "abstract_url": "https://arxiv.org/abs/2506.05020", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种集成大型语言模型（LLM）和视觉语言模型（VLM）的层次化框架，用于异构空中-地面机器人系统的语义导航和操作，展示了在动态环境中的适应性和鲁棒性。", "motivation": "解决异构多机器人系统在复杂任务中协调合作时，传统静态模型难以应对任务多样性和动态环境的问题。", "method": "采用层次化框架，结合提示的大型语言模型（LLM）进行任务分解和全局语义地图构建，以及GridMask增强的微调视觉语言模型（VLM）从航拍图像中提取任务指定的语义标签和2D空间信息以支持局部规划。", "result": "在真实世界的字母立方体排列任务上的实验证明了该框架在动态环境中的适应性和鲁棒性。", "conclusion": "这是首次展示将基于VLM的感知与LLM驱动的任务推理和运动规划相结合的空中-地面异构系统，为复杂任务中的机器人协作提供了新的解决方案。"}}
{"id": "2506.05265", "title": "Teaming in the AI Era: AI-Augmented Frameworks for Forming, Simulating, and Optimizing Human Teams", "authors": ["Mohammed Almutairi"], "abstract": "Effective teamwork is essential across diverse domains. During the team formation stage, a key challenge is forming teams that effectively balance user preferences with task objectives to enhance overall team satisfaction. In the team performing stage, maintaining cohesion and engagement is critical for sustaining high team performance. However, existing computational tools and algorithms for team optimization often rely on static data inputs, narrow algorithmic objectives, or solutions tailored for specific contexts, failing to account for the dynamic interplay of team members personalities, evolving goals, and changing individual preferences. Therefore, teams may encounter member dissatisfaction, as purely algorithmic assignments can reduce members commitment to team goals or experience suboptimal engagement due to the absence of timely, personalized guidance to help members adjust their behaviors and interactions as team dynamics evolve. Ultimately, these challenges can lead to reduced overall team performance. My Ph.D. dissertation aims to develop AI-augmented team optimization frameworks and practical systems that enhance team satisfaction, engagement, and performance. First, I propose a team formation framework that leverages a multi-armed bandit algorithm to iteratively refine team composition based on user preferences, ensuring alignment between individual needs and collective team goals to enhance team satisfaction. Second, I introduce tAIfa (Team AI Feedback Assistant), an AI-powered system that utilizes large language models (LLMs) to deliver immediate, personalized feedback to both teams and individual members, enhancing cohesion and engagement. Finally, I present PuppeteerLLM, an LLM-based simulation framework that simulates multi-agent teams to model complex team dynamics within realistic environments, incorporating task-driven collaboration and long-term coordination.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "5 pages, UMAP 25, June 16_19, 2025, New York City, NY, USA", "pdf_url": "https://arxiv.org/pdf/2506.05265.pdf", "abstract_url": "https://arxiv.org/abs/2506.05265", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文提出了一种AI增强的团队优化框架，旨在通过多臂老虎机算法优化团队组建，利用大型语言模型提供即时个性化反馈，以及通过基于LLM的模拟框架模拟多代理团队动态，以提高团队满意度、参与度和绩效。", "motivation": "现有团队优化工具和方法往往依赖静态数据输入或特定上下文解决方案，无法适应团队成员个性、目标和偏好的动态变化，导致团队成员不满和团队绩效下降。", "method": "论文提出了三个主要方法：1) 使用多臂老虎机算法迭代优化团队组建；2) 开发tAIfa系统，利用大型语言模型提供即时个性化反馈；3) 创建PuppeteerLLM框架，模拟多代理团队动态。", "result": "通过AI增强的框架，论文展示了如何更有效地平衡用户偏好与任务目标，提高团队满意度和绩效。", "conclusion": "该研究为团队优化提供了新的AI增强方法，能够适应团队动态变化，提高团队的整体表现和成员满意度。"}}
