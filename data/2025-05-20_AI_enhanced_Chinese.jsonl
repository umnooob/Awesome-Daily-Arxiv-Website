{"id": "2505.11838", "title": "RVTBench: A Benchmark for Visual Reasoning Tasks", "authors": ["Yiqing Shen", "Chenjia Li", "Chenxiao Fan", "Mathias Unberath"], "abstract": "Visual reasoning, the capability to interpret visual input in response to implicit text query through multi-step reasoning, remains a challenge for deep learning models due to the lack of relevant benchmarks. Previous work in visual reasoning has primarily focused on reasoning segmentation, where models aim to segment objects based on implicit text queries. This paper introduces reasoning visual tasks (RVTs), a unified formulation that extends beyond traditional video reasoning segmentation to a diverse family of visual language reasoning problems, which can therefore accommodate multiple output formats including bounding boxes, natural language descriptions, and question-answer pairs. Correspondingly, we identify the limitations in current benchmark construction methods that rely solely on large language models (LLMs), which inadequately capture complex spatial-temporal relationships and multi-step reasoning chains in video due to their reliance on token representation, resulting in benchmarks with artificially limited reasoning complexity. To address this limitation, we propose a novel automated RVT benchmark construction pipeline that leverages digital twin (DT) representations as structured intermediaries between perception and the generation of implicit text queries. Based on this method, we construct RVTBench, a RVT benchmark containing 3,896 queries of over 1.2 million tokens across four types of RVT (segmentation, grounding, VQA and summary), three reasoning categories (semantic, spatial, and temporal), and four increasing difficulty levels, derived from 200 video sequences. Finally, we propose RVTagent, an agent framework for RVT that allows for zero-shot generalization across various types of RVT without task-specific fine-tuning.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.11838.pdf", "abstract_url": "https://arxiv.org/abs/2505.11838", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了RVTBench，一个用于视觉推理任务的基准测试，旨在解决现有基准测试在捕捉复杂时空关系和多步推理链方面的不足。", "motivation": "解决深度学习模型在视觉推理任务中因缺乏相关基准测试而面临的挑战，特别是传统基准测试依赖大型语言模型（LLMs）无法充分捕捉视频中的复杂时空关系和多步推理链。", "method": "提出了一种新颖的自动化RVT基准构建管道，利用数字孪生（DT）表示作为感知和生成隐式文本查询之间的结构化中介。", "result": "构建了RVTBench，一个包含3,896个查询、超过120万标记的基准测试，覆盖四种RVT类型、三种推理类别和四个难度级别。", "conclusion": "RVTBench和RVTagent框架为视觉推理任务提供了一个全面的基准测试和解决方案，支持零样本泛化，无需任务特定微调。"}}
{"id": "2505.11533", "title": "A Data Synthesis Method Driven by Large Language Models for Proactive Mining of Implicit User Intentions in Tourism", "authors": ["Jinqiang Wang", "Huansheng Ning", "Tao Zhu", "Jianguo Ding"], "abstract": "In the tourism domain, Large Language Models (LLMs) often struggle to mine implicit user intentions from tourists' ambiguous inquiries and lack the capacity to proactively guide users toward clarifying their needs. A critical bottleneck is the scarcity of high-quality training datasets that facilitate proactive questioning and implicit intention mining. While recent advances leverage LLM-driven data synthesis to generate such datasets and transfer specialized knowledge to downstream models, existing approaches suffer from several shortcomings: (1) lack of adaptation to the tourism domain, (2) skewed distributions of detail levels in initial inquiries, (3) contextual redundancy in the implicit intention mining module, and (4) lack of explicit thinking about tourists' emotions and intention values. Therefore, we propose SynPT (A Data Synthesis Method Driven by LLMs for Proactive Mining of Implicit User Intentions in the Tourism), which constructs an LLM-driven user agent and assistant agent to simulate dialogues based on seed data collected from Chinese tourism websites. This approach addresses the aforementioned limitations and generates SynPT-Dialog, a training dataset containing explicit reasoning. The dataset is utilized to fine-tune a general LLM, enabling it to proactively mine implicit user intentions. Experimental evaluations, conducted from both human and LLM perspectives, demonstrate the superiority of SynPT compared to existing methods. Furthermore, we analyze key hyperparameters and present case studies to illustrate the practical applicability of our method, including discussions on its adaptability to English-language scenarios. All code and data are publicly available.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.11533.pdf", "abstract_url": "https://arxiv.org/abs/2505.11533", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种由大型语言模型驱动的数据合成方法SynPT，用于主动挖掘旅游领域中的隐式用户意图，解决了现有方法在旅游领域适应性差、初始查询细节水平分布不均、上下文冗余及忽略用户情感和意图价值等问题。", "motivation": "解决大型语言模型在旅游领域中难以从游客模糊查询中挖掘隐式意图及缺乏主动引导用户明确需求的能力，以及高质量训练数据集稀缺的问题。", "method": "构建由大型语言模型驱动的用户代理和助手代理，模拟基于中国旅游网站收集的种子数据的对话，生成包含明确推理的训练数据集SynPT-Dialog，并用于微调通用大型语言模型。", "result": "实验评估表明，SynPT在从人类和大型语言模型角度均优于现有方法，且分析了关键超参数并通过案例研究展示了其实际适用性。", "conclusion": "SynPT方法有效解决了旅游领域隐式用户意图挖掘的挑战，提高了大型语言模型在该领域的应用效果，且代码和数据已公开。"}}
{"id": "2505.11556", "title": "Assessing Collective Reasoning in Multi-Agent LLMs via Hidden Profile Tasks", "authors": ["Yuxuan Li", "Aoi Naito", "Hirokazu Shirado"], "abstract": "Multi-agent systems built on large language models (LLMs) promise enhanced problem-solving through distributed information integration, but also risk replicating collective reasoning failures observed in human groups. Yet, no theory-grounded benchmark exists to systematically evaluate such failures. In this paper, we introduce the Hidden Profile paradigm from social psychology as a diagnostic testbed for multi-agent LLM systems. By distributing critical information asymmetrically across agents, the paradigm reveals how inter-agent dynamics support or hinder collective reasoning. We first formalize the paradigm for multi-agent decision-making under distributed knowledge and instantiate it as a benchmark with nine tasks spanning diverse scenarios, including adaptations from prior human studies. We then conduct experiments with GPT-4.1 and five other leading LLMs, including reasoning-enhanced variants, showing that multi-agent systems across all models fail to match the accuracy of single agents given complete information. While agents' collective performance is broadly comparable to that of human groups, nuanced behavioral differences emerge, such as increased sensitivity to social desirability. Finally, we demonstrate the paradigm's diagnostic utility by exploring a cooperation-contradiction trade-off in multi-agent LLM systems. We find that while cooperative agents are prone to over-coordination in collective settings, increased contradiction impairs group convergence. This work contributes a reproducible framework for evaluating multi-agent LLM systems and motivates future research on artificial collective intelligence and human-AI interaction.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.11556.pdf", "abstract_url": "https://arxiv.org/abs/2505.11556", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过引入社会心理学中的隐藏档案范式，系统地评估了基于大型语言模型的多智能体系统中的集体推理失败，揭示了智能体间动态如何影响集体决策，并展示了不同模型在集体推理任务中的表现。", "motivation": "解决缺乏理论基础的系统性评估多智能体大型语言模型系统中集体推理失败的问题。", "method": "采用社会心理学中的隐藏档案范式作为诊断测试平台，通过不对称地分布关键信息来评估多智能体决策过程。", "result": "实验显示，所有模型的多智能体系统在集体推理任务中的准确性均不及拥有完整信息的单个智能体，且与人类群体表现相似但存在细微行为差异。", "conclusion": "本研究为评估多智能体大型语言模型系统提供了一个可重复的框架，并激励了未来关于人工集体智能和人机交互的研究。"}}
{"id": "2505.11626", "title": "THELMA: Task Based Holistic Evaluation of Large Language Model Applications-RAG Question Answering", "authors": ["Udita Patel", "Rutu Mulkar", "Jay Roberts", "Cibi Chakravarthy Senthilkumar", "Sujay Gandhi", "Xiaofei Zheng", "Naumaan Nayyar", "Rafael Castrillo"], "abstract": "We propose THELMA (Task Based Holistic Evaluation of Large Language Model Applications), a reference free framework for RAG (Retrieval Augmented generation) based question answering (QA) applications. THELMA consist of six interdependent metrics specifically designed for holistic, fine grained evaluation of RAG QA applications. THELMA framework helps developers and application owners evaluate, monitor and improve end to end RAG QA pipelines without requiring labelled sources or reference", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.11626.pdf", "abstract_url": "https://arxiv.org/abs/2505.11626", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "THELMA是一个无需参考的框架，专为RAG问答应用设计的全面、细粒度评估，包含六个相互依赖的指标。", "motivation": "解决RAG问答应用中缺乏全面、细粒度评估框架的问题。", "method": "提出THELMA框架，包含六个相互依赖的指标，用于无标签或参考情况下的评估。", "result": "THELMA框架能够帮助开发者和应用所有者评估、监控和改进RAG问答管道。", "conclusion": "THELMA为RAG问答应用提供了一个有效的评估工具，无需依赖标记数据或参考。"}}
{"id": "2505.11604", "title": "Talk to Your Slides: Efficient Slide Editing Agent with Large Language Models", "authors": ["Kyudan Jung", "Hojun Cho", "Jooyeol Yun", "Jaehyeok Jang", "Jagul Choo"], "abstract": "Existing research on large language models (LLMs) for PowerPoint predominantly focuses on slide generation, overlooking the common yet tedious task of editing existing slides. We introduce Talk-to-Your-Slides, an LLM-powered agent that directly edits slides within active PowerPoint sessions through COM communication. Our system employs a two-level approach: (1) high-level processing where an LLM agent interprets instructions and formulates editing plans, and (2) low-level execution where Python scripts directly manipulate PowerPoint objects. Unlike previous methods relying on predefined operations, our approach enables more flexible and contextually-aware editing. To facilitate evaluation, we present TSBench, a human-annotated dataset of 379 diverse editing instructions with corresponding slide variations. Experimental results demonstrate that Talk-to-Your-Slides significantly outperforms baseline methods in execution success rate, instruction fidelity, and editing efficiency. Our code and benchmark are available at", "subjects": "Computation and Language (cs.CL)", "comments": "14 pages, 6 figures", "pdf_url": "https://arxiv.org/pdf/2505.11604.pdf", "abstract_url": "https://arxiv.org/abs/2505.11604", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了Talk-to-Your-Slides，一个基于大型语言模型（LLM）的代理，通过COM通信直接在活动的PowerPoint会话中编辑幻灯片。该系统采用两级方法：高级处理解释指令并制定编辑计划，低级执行通过Python脚本直接操作PowerPoint对象。与依赖预定义操作的方法不同，该方法支持更灵活和上下文感知的编辑。", "motivation": "解决现有大型语言模型（LLMs）在PowerPoint应用中主要关注幻灯片生成，而忽视了编辑现有幻灯片这一常见但繁琐任务的问题。", "method": "采用两级方法：高级处理由LLM代理解释指令并制定编辑计划，低级执行通过Python脚本直接操作PowerPoint对象。", "result": "实验结果表明，Talk-to-Your-Slides在执行成功率、指令忠实度和编辑效率方面显著优于基线方法。", "conclusion": "Talk-to-Your-Slides提供了一种更灵活、上下文感知的幻灯片编辑方法，显著提高了编辑效率和准确性。"}}
{"id": "2505.11679", "title": "Ambiguity Resolution in Text-to-Structured Data Mapping", "authors": ["Zhibo Hu", "Chen Wang", "Yanfeng Shu", "Hye-Young Paik", "Liming Zhu"], "abstract": "Ambiguity in natural language is a significant obstacle for achieving accurate text to structured data mapping through large language models (LLMs), which affects the performance of tasks such as mapping text to agentic tool calling and text-to-SQL queries. Existing methods of ambiguity handling either exploit ReACT framework to produce the correct mapping through trial and error, or supervised fine tuning to guide models to produce a biased mapping to improve certain tasks. In this paper, we adopt a different approach that characterizes the representation difference of ambiguous text in the latent space and leverage the difference to identify ambiguity before mapping them to structured data. To detect ambiguity of a sentence, we focused on the relationship between ambiguous questions and their interpretations and what cause the LLM ignore multiple interpretations. Different to the distance calculated by dense embedding vectors, we utilize the observation that ambiguity is caused by concept missing in latent space of LLM to design a new distance measurement, computed through the path kernel by the integral of gradient values for each concepts from sparse-autoencoder (SAE) under each state. We identify patterns to distinguish ambiguous questions with this measurement. Based on our observation, We propose a new framework to improve the performance of LLMs on ambiguous agentic tool calling through missing concepts prediction.", "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": "15 pages, 11 figures", "pdf_url": "https://arxiv.org/pdf/2505.11679.pdf", "abstract_url": "https://arxiv.org/abs/2505.11679", "categories": ["Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种新方法，通过分析潜在空间中的表示差异来识别自然语言中的歧义，以提高大型语言模型（LLMs）在文本到结构化数据映射中的性能。", "motivation": "自然语言中的歧义是影响大型语言模型（LLMs）在文本到结构化数据映射中准确性的主要障碍，尤其是在代理工具调用和文本到SQL查询等任务中。现有方法要么通过试错来产生正确的映射，要么通过监督微调来引导模型产生有偏的映射以改进特定任务。", "method": "本文采用了一种不同的方法，通过特征化歧义文本在潜在空间中的表示差异，并利用这种差异在映射到结构化数据之前识别歧义。为了检测句子的歧义，我们专注于歧义问题与其解释之间的关系，以及导致LLM忽略多种解释的原因。不同于通过密集嵌入向量计算的距离，我们利用歧义是由LLM潜在空间中概念缺失引起的观察，设计了一种新的距离测量方法，通过稀疏自编码器（SAE）在每个状态下对每个概念的梯度值的路径核积分来计算。", "result": "我们通过这种测量方法识别出区分歧义问题的模式。基于我们的观察，我们提出了一个新的框架，通过预测缺失的概念来提高LLMs在歧义代理工具调用上的性能。", "conclusion": "本文提出的新框架和方法通过识别和处理自然语言中的歧义，显著提高了大型语言模型在文本到结构化数据映射任务中的性能，特别是在代理工具调用和文本到SQL查询等应用中。"}}
{"id": "2505.11811", "title": "BELLE: A Bi-Level Multi-Agent Reasoning Framework for Multi-Hop Question Answering", "authors": ["Taolin Zhang", "Dongyang Li", "Qizhou Chen", "Chengyu Wang", "Xiaofeng He"], "abstract": "Multi-hop question answering (QA) involves finding multiple relevant passages and performing step-by-step reasoning to answer complex questions. Previous works on multi-hop QA employ specific methods from different modeling perspectives based on large language models (LLMs), regardless of the question types. In this paper, we first conduct an in-depth analysis of public multi-hop QA benchmarks, dividing the questions into four types and evaluating five types of cutting-edge methods for multi-hop QA: Chain-of-Thought (CoT), Single-step, Iterative-step, Sub-step, and Adaptive-step. We find that different types of multi-hop questions have varying degrees of sensitivity to different types of methods. Thus, we propose a Bi-levEL muLti-agEnt reasoning (BELLE) framework to address multi-hop QA by specifically focusing on the correspondence between question types and methods, where each type of method is regarded as an ''operator'' by prompting LLMs differently. The first level of BELLE includes multiple agents that debate to obtain an executive plan of combined ''operators'' to address the multi-hop QA task comprehensively. During the debate, in addition to the basic roles of affirmative debater, negative debater, and judge, at the second level, we further leverage fast and slow debaters to monitor whether changes in viewpoints are reasonable. Extensive experiments demonstrate that BELLE significantly outperforms strong baselines in various datasets. Additionally, the model consumption of BELLE is higher cost-effectiveness than that of single models in more complex multi-hop QA scenarios.", "subjects": "Computation and Language (cs.CL)", "comments": "Accepted by ACL2025 main track", "pdf_url": "https://arxiv.org/pdf/2505.11811.pdf", "abstract_url": "https://arxiv.org/abs/2505.11811", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为BELLE的双层次多智能体推理框架，用于解决多跳问答问题。该框架通过分析问题类型与方法之间的对应关系，利用大型语言模型（LLMs）的不同提示方式作为“操作符”，并通过多智能体辩论来制定执行计划，显著提高了多跳问答的性能。", "motivation": "解决多跳问答（QA）中不同类型问题对不同方法敏感度不同的问题，提出一个能够根据问题类型灵活选择方法的框架。", "method": "提出了一个双层次多智能体推理（BELLE）框架，第一层次包括多个智能体通过辩论获得组合“操作符”的执行计划，第二层次利用快慢辩论者监控观点变化的合理性。", "result": "BELLE在多个数据集上显著优于强基线模型，且在更复杂的多跳QA场景中具有更高的成本效益。", "conclusion": "BELLE框架通过智能体辩论和操作符组合，有效解决了多跳问答中的问题类型与方法匹配问题，提高了问答系统的性能和成本效益。"}}
{"id": "2505.11807", "title": "Retrospex: Language Agent Meets Offline Reinforcement Learning Critic", "authors": ["Yufei Xiang", "Yiqun Shen", "Yeqin Zhang", "Cam-Tu Nguyen"], "abstract": "Large Language Models (LLMs) possess extensive knowledge and commonsense reasoning capabilities, making them valuable for creating powerful agents. However, existing LLM agent frameworks have not fully utilized past experiences for improvement. This work introduces a new LLM-based agent framework called Retrospex, which addresses this challenge by analyzing past experiences in depth. Unlike previous approaches, Retrospex does not directly integrate experiences into the LLM's context. Instead, it combines the LLM's action likelihood with action values estimated by a Reinforcement Learning (RL) Critic, which is trained on past experiences through an offline ''retrospection'' process. Additionally, Retrospex employs a dynamic action rescoring mechanism that increases the importance of experience-based values for tasks that require more interaction with the environment. We evaluate Retrospex in ScienceWorld, ALFWorld and Webshop environments, demonstrating its advantages over strong, contemporary baselines.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "17 pages", "pdf_url": "https://arxiv.org/pdf/2505.11807.pdf", "abstract_url": "https://arxiv.org/abs/2505.11807", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "Retrospex是一种新的基于大型语言模型（LLM）的代理框架，通过结合LLM的行动可能性和由强化学习（RL）批评家估计的行动价值，利用过去的经验进行改进。", "motivation": "现有的LLM代理框架未能充分利用过去的经验进行改进，Retrospex旨在解决这一问题。", "method": "Retrospex不直接将经验集成到LLM的上下文中，而是通过离线“回顾”过程训练的RL批评家估计的行动价值与LLM的行动可能性相结合，并采用动态行动重新评分机制。", "result": "在ScienceWorld、ALFWorld和Webshop环境中的评估显示，Retrospex优于当代强基线。", "conclusion": "Retrospex通过有效利用过去的经验和动态调整经验价值的重要性，提高了LLM代理的性能。"}}
{"id": "2505.11891", "title": "Mobile-Bench-v2: A More Realistic and Comprehensive Benchmark for VLM-based Mobile Agents", "authors": ["Weikai Xu", "Zhizheng Jiang", "Yuxuan Liu", "Wei Liu", "Jian Luan", "Yuanchun Li", "Yunxin Liu", "Bin Wang", "Bo An"], "abstract": "VLM-based mobile agents are increasingly popular due to their capabilities to interact with smartphone GUIs and XML-structured texts and to complete daily tasks. However, existing online benchmarks struggle with obtaining stable reward signals due to dynamic environmental changes. Offline benchmarks evaluate the agents through single-path trajectories, which stands in contrast to the inherently multi-solution characteristics of GUI tasks. Additionally, both types of benchmarks fail to assess whether mobile agents can handle noise or engage in proactive interactions due to a lack of noisy apps or overly full instructions during the evaluation process. To address these limitations, we use a slot-based instruction generation method to construct a more realistic and comprehensive benchmark named Mobile-Bench-v2. Mobile-Bench-v2 includes a common task split, with offline multi-path evaluation to assess the agent's ability to obtain step rewards during task execution. It contains a noisy split based on pop-ups and ads apps, and a contaminated split named AITZ-Noise to formulate a real noisy environment. Furthermore, an ambiguous instruction split with preset Q\\&A interactions is released to evaluate the agent's proactive interaction capabilities. We conduct evaluations on these splits using the single-agent framework AppAgent-v1, the multi-agent framework Mobile-Agent-v2, as well as other mobile agents such as UI-Tars and OS-Atlas. Code and data are available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.11891.pdf", "abstract_url": "https://arxiv.org/abs/2505.11891", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了Mobile-Bench-v2，一个更现实和全面的基准测试，用于评估基于视觉语言模型（VLM）的移动代理。该基准测试通过多路径评估、噪声环境和模糊指令分割等方法，解决了现有基准测试在评估移动代理时的局限性。", "motivation": "现有的在线和离线基准测试在评估基于VLM的移动代理时存在多个问题，如无法获得稳定的奖励信号、评估路径单一、无法处理噪声或进行主动交互等。这些问题限制了移动代理在实际应用中的表现评估。", "method": "作者使用基于槽位的指令生成方法构建了Mobile-Bench-v2基准测试，包括常见任务分割、噪声分割、污染分割和模糊指令分割，以全面评估移动代理的能力。", "result": "通过在Mobile-Bench-v2上进行评估，作者展示了该基准测试能够更全面地评估移动代理的能力，包括处理噪声、进行主动交互以及在多路径任务中获取步骤奖励的能力。", "conclusion": "Mobile-Bench-v2为基于VLM的移动代理提供了一个更现实和全面的评估平台，有助于推动移动代理技术的发展和实际应用。"}}
{"id": "2505.11908", "title": "ELITE: Embedding-Less retrieval with Iterative Text Exploration", "authors": ["Zhangyu Wang", "Siyuan Gao", "Rong Zhou", "Hao Wang", "Li Ning"], "abstract": "Large Language Models (LLMs) have achieved impressive progress in natural language processing, but their limited ability to retain long-term context constrains performance on document-level or multi-turn tasks. Retrieval-Augmented Generation (RAG) mitigates this by retrieving relevant information from an external corpus. However, existing RAG systems often rely on embedding-based retrieval trained on corpus-level semantic similarity, which can lead to retrieving content that is semantically similar in form but misaligned with the question's true intent. Furthermore, recent RAG variants construct graph- or hierarchy-based structures to improve retrieval accuracy, resulting in significant computation and storage overhead. In this paper, we propose an embedding-free retrieval framework. Our method leverages the logical inferencing ability of LLMs in retrieval using iterative search space refinement guided by our novel importance measure and extend our retrieval results with logically related information without explicit graph construction. Experiments on long-context QA benchmarks, including NovelQA and Marathon, show that our approach outperforms strong baselines while reducing storage and runtime by over an order of magnitude.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.11908.pdf", "abstract_url": "https://arxiv.org/abs/2505.11908", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "提出了一种无嵌入的检索框架ELITE，通过迭代文本探索和逻辑推理能力改进检索增强生成（RAG）系统，减少存储和计算开销。", "motivation": "解决现有RAG系统依赖基于嵌入的检索，可能导致检索内容与问题真实意图不符，以及构建图或层次结构导致的计算和存储开销大的问题。", "method": "利用LLMs的逻辑推理能力进行检索，通过迭代搜索空间细化和新颖的重要性度量扩展检索结果，无需显式图构建。", "result": "在长上下文QA基准测试中表现优于强基线，同时减少了一个数量级以上的存储和运行时。", "conclusion": "ELITE框架有效提升了检索的准确性和效率，为文档级或多轮任务提供了更优的解决方案。"}}
{"id": "2505.11932", "title": "Neuro-Symbolic Query Compiler", "authors": ["Yuyao Zhang", "Zhicheng Dou", "Xiaoxi Li", "Jiajie Jin", "Yongkang Wu", "Zhonghua Li", "Qi Ye", "Ji-Rong Wen"], "abstract": "Precise recognition of search intent in Retrieval-Augmented Generation (RAG) systems remains a challenging goal, especially under resource constraints and for complex queries with nested structures and dependencies. This paper presents QCompiler, a neuro-symbolic framework inspired by linguistic grammar rules and compiler design, to bridge this gap. It theoretically designs a minimal yet sufficient Backus-Naur Form (BNF) grammar $G[q]$ to formalize complex queries. Unlike previous methods, this grammar maintains completeness while minimizing redundancy. Based on this, QCompiler includes a Query Expression Translator, a Lexical Syntax Parser, and a Recursive Descent Processor to compile queries into Abstract Syntax Trees (ASTs) for execution. The atomicity of the sub-queries in the leaf nodes ensures more precise document retrieval and response generation, significantly improving the RAG system's ability to address complex queries.", "subjects": "Computation and Language (cs.CL); Information Retrieval (cs.IR)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.11932.pdf", "abstract_url": "https://arxiv.org/abs/2505.11932", "categories": ["Computation and Language (cs.CL)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了QCompiler，一个受语言语法规则和编译器设计启发的神经符号框架，旨在解决检索增强生成（RAG）系统中复杂查询的精确识别问题。通过设计一个最小但足够的Backus-Naur Form（BNF）语法$G[q]$来形式化复杂查询，QCompiler包括查询表达式翻译器、词法语法解析器和递归下降处理器，将查询编译为抽象语法树（ASTs）以执行，从而显著提高RAG系统处理复杂查询的能力。", "motivation": "解决在资源限制下和对于具有嵌套结构和依赖关系的复杂查询，检索增强生成（RAG）系统中搜索意图的精确识别问题。", "method": "设计了一个最小但足够的Backus-Naur Form（BNF）语法$G[q]$来形式化复杂查询，并开发了QCompiler框架，包括查询表达式翻译器、词法语法解析器和递归下降处理器，将查询编译为抽象语法树（ASTs）以执行。", "result": "QCompiler能够更精确地检索文档和生成响应，显著提高了RAG系统处理复杂查询的能力。", "conclusion": "通过引入QCompiler，本文提出了一种有效的方法来改进RAG系统对复杂查询的处理能力，为未来的研究和应用提供了有价值的参考。"}}
{"id": "2505.11995", "title": "Unveiling Knowledge Utilization Mechanisms in LLM-based Retrieval-Augmented Generation", "authors": ["Yuhao Wang", "Ruiyang Ren", "Yucheng Wang", "Wayne Xin Zhao", "Jing Liu", "Hua Wu", "Haifeng Wang"], "abstract": "Considering the inherent limitations of parametric knowledge in large language models (LLMs), retrieval-augmented generation (RAG) is widely employed to expand their knowledge scope. Since RAG has shown promise in knowledge-intensive tasks like open-domain question answering, its broader application to complex tasks and intelligent assistants has further advanced its utility. Despite this progress, the underlying knowledge utilization mechanisms of LLM-based RAG remain underexplored. In this paper, we present a systematic investigation of the intrinsic mechanisms by which LLMs integrate internal (parametric) and external (retrieved) knowledge in RAG scenarios. Specially, we employ knowledge stream analysis at the macroscopic level, and investigate the function of individual modules at the microscopic level. Drawing on knowledge streaming analyses, we decompose the knowledge utilization process into four distinct stages within LLM layers: knowledge refinement, knowledge elicitation, knowledge expression, and knowledge contestation. We further demonstrate that the relevance of passages guides the streaming of knowledge through these stages. At the module level, we introduce a new method, knowledge activation probability entropy (KAPE) for neuron identification associated with either internal or external knowledge. By selectively deactivating these neurons, we achieve targeted shifts in the LLM's reliance on one knowledge source over the other. Moreover, we discern complementary roles for multi-head attention and multi-layer perceptron layers during knowledge formation. These insights offer a foundation for improving interpretability and reliability in retrieval-augmented LLMs, paving the way for more robust and transparent generative solutions in knowledge-intensive domains.", "subjects": "Computation and Language (cs.CL)", "comments": "SIGIR 2025", "pdf_url": "https://arxiv.org/pdf/2505.11995.pdf", "abstract_url": "https://arxiv.org/abs/2505.11995", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文系统地研究了大型语言模型(LLMs)在检索增强生成(RAG)场景中如何整合内部(参数)和外部(检索)知识的内在机制。通过宏观层面的知识流分析和微观层面的模块功能研究，将知识利用过程分解为四个阶段，并引入知识激活概率熵(KAPE)方法，为提升检索增强LLMs的可解释性和可靠性奠定了基础。", "motivation": "尽管检索增强生成(RAG)在知识密集型任务中显示出潜力，但LLM-based RAG的底层知识利用机制仍未充分探索。本文旨在揭示这些机制，以提高生成解决方案的稳健性和透明度。", "method": "采用宏观层面的知识流分析和微观层面的模块功能研究，包括引入知识激活概率熵(KAPE)方法进行神经元识别，并通过选择性失活这些神经元来实现知识来源的针对性转移。", "result": "研究发现，段落的相关性指导知识通过这些阶段流动，多头部注意力和多层感知器层在知识形成中扮演互补角色。", "conclusion": "这些发现为提高检索增强LLMs的可解释性和可靠性提供了基础，为知识密集型领域中更稳健和透明的生成解决方案铺平了道路。"}}
{"id": "2505.12632", "title": "Scalable Video-to-Dataset Generation for Cross-Platform Mobile Agents", "authors": ["Yunseok Jang", "Yeda Song", "Sungryull Sohn", "Lajanugen Logeswaran", "Tiange Luo", "Dong-Ki Kim", "Kyunghoon Bae", "Honglak Lee"], "abstract": "Recent advancements in Large Language Models (LLMs) and Vision-Language Models (VLMs) have sparked significant interest in developing GUI visual agents. We introduce MONDAY (Mobile OS Navigation Task Dataset for Agents from YouTube), a large-scale dataset of 313K annotated frames from 20K instructional videos capturing diverse real-world mobile OS navigation across multiple platforms. Models that include MONDAY in their pre-training phases demonstrate robust cross-platform generalization capabilities, consistently outperforming models trained on existing single OS datasets while achieving an average performance gain of 18.11%p on an unseen mobile OS platform. To enable continuous dataset expansion as mobile platforms evolve, we present an automated framework that leverages publicly available video content to create comprehensive task datasets without manual annotation. Our framework comprises robust OCR-based scene detection (95.04% F1score), near-perfect UI element detection (99.87% hit ratio), and novel multi-step action identification to extract reliable action sequences across diverse interface configurations. We contribute both the MONDAY dataset and our automated collection framework to facilitate future research in mobile OS navigation.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": "CVPR 2025", "pdf_url": "https://arxiv.org/pdf/2505.12632.pdf", "abstract_url": "https://arxiv.org/abs/2505.12632", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了MONDAY，一个从20K教学视频中提取的313K标注帧的大规模数据集，用于跨平台移动代理的GUI视觉代理开发。通过自动化框架，该数据集支持持续扩展，无需手动标注，显著提升了模型在未见移动操作系统平台上的性能。", "motivation": "开发GUI视觉代理的需求随着大型语言模型和视觉语言模型的进步而增加，但缺乏跨平台的、大规模的数据集来支持这一研究。", "method": "提出MONDAY数据集和自动化收集框架，包括OCR-based场景检测、UI元素检测和多步动作识别技术，以从公开视频内容中自动生成任务数据集。", "result": "使用MONDAY进行预训练的模型在跨平台泛化能力上表现优异，平均性能提升18.11%p，且在UI元素检测上达到99.87%的命中率。", "conclusion": "MONDAY数据集和自动化框架为移动操作系统导航研究提供了宝贵的资源，支持未来研究的持续发展和扩展。"}}
{"id": "2505.12299", "title": "Enhance Mobile Agents Thinking Process Via Iterative Preference Learning", "authors": ["Kun Huang", "Weikai Xu", "Yuxuan Liu", "Quandong Wang", "Pengzhi Gao", "Wei Liu", "Jian Luan", "Bin Wang", "Bo An"], "abstract": "The Chain of Action-Planning Thoughts (CoaT) paradigm has been shown to improve the reasoning performance of VLM-based mobile agents in GUI tasks. However, the scarcity of diverse CoaT trajectories limits the expressiveness and generalization ability of such agents. While self-training is commonly employed to address data scarcity, existing approaches either overlook the correctness of intermediate reasoning steps or depend on expensive process-level annotations to construct process reward models (PRM). To address the above problems, we propose an Iterative Preference Learning (IPL) that constructs a CoaT-tree through interative sampling, scores leaf nodes using rule-based reward, and backpropagates feedback to derive Thinking-level Direct Preference Optimization (T-DPO) pairs. To prevent overfitting during warm-up supervised fine-tuning, we further introduce a three-stage instruction evolution, which leverages GPT-4o to generate diverse Q\\&A pairs based on real mobile UI screenshots, enhancing both generality and layout understanding. Experiments on three standard Mobile GUI-agent benchmarks demonstrate that our agent MobileIPL outperforms strong baselines, including continual pretraining models such as OS-ATLAS and UI-TARS. It achieves state-of-the-art performance across three standard Mobile GUI-Agents benchmarks and shows strong generalization to out-of-domain scenarios.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "9 pages, 8 figures, 7 tables", "pdf_url": "https://arxiv.org/pdf/2505.12299.pdf", "abstract_url": "https://arxiv.org/abs/2505.12299", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为迭代偏好学习（IPL）的方法，通过构建CoaT树、使用基于规则的奖励评分叶子节点，并通过反馈反向传播来优化思维级直接偏好优化（T-DPO）对，以解决VLM-based移动代理在GUI任务中推理性能提升的问题。此外，引入三阶段指令进化以防止在监督微调期间的过拟合，实验表明MobileIPL在三个标准Mobile GUI-agent基准测试中表现优异。", "motivation": "解决VLM-based移动代理在GUI任务中推理性能提升的问题，尤其是由于缺乏多样化的CoaT轨迹而限制代理的表达和泛化能力的问题。", "method": "提出迭代偏好学习（IPL）方法，包括构建CoaT树、使用基于规则的奖励评分叶子节点，并通过反馈反向传播来优化思维级直接偏好优化（T-DPO）对，以及引入三阶段指令进化以防止过拟合。", "result": "MobileIPL在三个标准Mobile GUI-agent基准测试中表现优异，包括持续预训练模型如OS-ATLAS和UI-TARS，实现了最先进的性能，并在域外场景中显示出强大的泛化能力。", "conclusion": "通过IPL方法和三阶段指令进化，MobileIPL显著提升了移动代理在GUI任务中的推理性能，为解决数据稀缺和过拟合问题提供了有效途径。"}}
{"id": "2505.12439", "title": "Learning to Play Like Humans: A Framework for LLM Adaptation in Interactive Fiction Games", "authors": ["Jinming Zhang", "Yunfei Long"], "abstract": "Interactive Fiction games (IF games) are where players interact through natural language commands. While recent advances in Artificial Intelligence agents have reignited interest in IF games as a domain for studying decision-making, existing approaches prioritize task-specific performance metrics over human-like comprehension of narrative context and gameplay logic. This work presents a cognitively inspired framework that guides Large Language Models (LLMs) to learn and play IF games systematically. Our proposed **L**earning to **P**lay **L**ike **H**umans (LPLH) framework integrates three key components: (1) structured map building to capture spatial and narrative relationships, (2) action learning to identify context-appropriate commands, and (3) feedback-driven experience analysis to refine decision-making over time. By aligning LLMs-based agents' behavior with narrative intent and commonsense constraints, LPLH moves beyond purely exploratory strategies to deliver more interpretable, human-like performance. Crucially, this approach draws on cognitive science principles to more closely simulate how human players read, interpret, and respond within narrative worlds. As a result, LPLH reframes the IF games challenge as a learning problem for LLMs-based agents, offering a new path toward robust, context-aware gameplay in complex text-based environments.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.12439.pdf", "abstract_url": "https://arxiv.org/abs/2505.12439", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一个认知启发框架LPLH，指导大型语言模型（LLMs）系统性地学习和玩交互式小说游戏（IF游戏），旨在实现更接近人类玩家的表现。", "motivation": "现有的AI代理在IF游戏中更注重任务特定的性能指标，而忽视了人类对叙事背景和游戏逻辑的理解。本文旨在解决这一问题，使LLMs基于的代理能够更接近人类玩家的行为。", "method": "提出的LPLH框架包含三个关键组件：结构化地图构建以捕捉空间和叙事关系，动作学习以识别上下文适当的命令，以及反馈驱动的经验分析以随时间优化决策。", "result": "通过将LLMs基于的代理的行为与叙事意图和常识约束对齐，LPLH超越了纯粹的探索策略，提供了更可解释、更接近人类的表现。", "conclusion": "LPLH将IF游戏的挑战重新定义为LLMs基于代理的学习问题，为复杂文本环境中的稳健、上下文感知游戏玩法提供了新路径。"}}
{"id": "2505.12650", "title": "AutoMat: Enabling Automated Crystal Structure Reconstruction from Microscopy via Agentic Tool Use", "authors": ["Yaotian Yang", "Yiwen Tang", "Yizhe Chen", "Xiao Chen", "Jiangjie Qiu", "Hao Xiong", "Haoyu Yin", "Zhiyao Luo", "Yifei Zhang", "Sijia Tao", "Wentao Li", "Qinghua Zhang", "Yuqiang Li", "Wanli Ouyang", "Bin Zhao", "Xiaonan Wang", "Fei Wei"], "abstract": "Machine learning-based interatomic potentials and force fields depend critically on accurate atomic structures, yet such data are scarce due to the limited availability of experimentally resolved crystals. Although atomic-resolution electron microscopy offers a potential source of structural data, converting these images into simulation-ready formats remains labor-intensive and error-prone, creating a bottleneck for model training and validation. We introduce AutoMat, an end-to-end, agent-assisted pipeline that automatically transforms scanning transmission electron microscopy (STEM) images into atomic crystal structures and predicts their physical properties. AutoMat combines pattern-adaptive denoising, physics-guided template retrieval, symmetry-aware atomic reconstruction, fast relaxation and property prediction via MatterSim, and coordinated orchestration across all stages. We propose the first dedicated STEM2Mat-Bench for this task and evaluate performance using lattice RMSD, formation energy MAE, and structure-matching success rate. By orchestrating external tool calls, AutoMat enables a text-only LLM to outperform vision-language models in this domain, achieving closed-loop reasoning throughout the pipeline. In large-scale experiments over 450 structure samples, AutoMat substantially outperforms existing multimodal large language models and tools. These results validate both AutoMat and STEM2Mat-Bench, marking a key step toward bridging microscopy and atomistic simulation in materials", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.12650.pdf", "abstract_url": "https://arxiv.org/abs/2505.12650", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "AutoMat是一个端到端的代理辅助管道，能够自动将扫描透射电子显微镜（STEM）图像转换为原子晶体结构，并预测其物理性质。通过结合模式自适应去噪、物理引导模板检索、对称感知原子重建、快速松弛和通过MatterSim进行性质预测，以及跨所有阶段的协调编排，AutoMat在这一领域超越了现有的多模态大型语言模型和工具。", "motivation": "机器学习基础的原子间势和力场依赖于准确的原子结构，但由于实验解析的晶体数据稀缺，这类数据难以获取。原子分辨率电子显微镜虽为潜在的结构数据来源，但将这些图像转换为模拟就绪格式仍费时且易出错，成为模型训练和验证的瓶颈。", "method": "AutoMat结合了模式自适应去噪、物理引导模板检索、对称感知原子重建、快速松弛和通过MatterSim进行性质预测，并通过协调编排跨所有阶段的外部工具调用，实现了从STEM图像到原子晶体结构的自动转换。", "result": "在450个结构样本的大规模实验中，AutoMat在晶格RMSD、形成能MAE和结构匹配成功率方面显著优于现有的多模态大型语言模型和工具。", "conclusion": "AutoMat和STEM2Mat-Bench的验证标志着在材料科学中桥接显微镜和原子模拟的关键一步，展示了通过代理工具使用实现自动化晶体结构重建的潜力。"}}
{"id": "2505.12476", "title": "Enhancing Large Language Models with Reward-guided Tree Search for Knowledge Graph Question and Answering", "authors": ["Xiao Long", "Liansheng Zhuang", "Chen Shen", "Shaotian Yan", "Yifei Li", "Shafei Wang"], "abstract": "Recently, large language models (LLMs) have demonstrated impressive performance in Knowledge Graph Question Answering (KGQA) tasks, which aim to find answers based on knowledge graphs (KGs) for natural language questions. Existing LLMs-based KGQA methods typically follow the Graph Retrieval-Augmented Generation (GraphRAG) paradigm, which first retrieves reasoning paths from the large KGs, and then generates the answers based on them. However, these methods emphasize the exploration of new optimal reasoning paths in KGs while ignoring the exploitation of historical reasoning paths, which may lead to sub-optimal reasoning paths. Additionally, the complex semantics contained in questions may lead to the retrieval of inaccurate reasoning paths. To address these issues, this paper proposes a novel and training-free framework for KGQA tasks called Reward-guided Tree Search on Graph (RTSoG). RTSoG decomposes an original question into a series of simpler and well-defined sub-questions to handle the complex semantics. Then, a Self-Critic Monte Carlo Tree Search (SC-MCTS) guided by a reward model is introduced to iteratively retrieve weighted reasoning paths as contextual knowledge. Finally, it stacks the weighted reasoning paths according to their weights to generate the final answers. Extensive experiments on four datasets demonstrate the effectiveness of RTSoG. Notably, it achieves 8.7\\% and 7.0\\% performance improvement over the state-of-the-art method on the GrailQA and the WebQSP respectively.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.12476.pdf", "abstract_url": "https://arxiv.org/abs/2505.12476", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种名为RTSoG的新型无训练框架，用于知识图谱问答（KGQA）任务，通过奖励引导的树搜索增强大型语言模型（LLMs）的性能。RTSoG通过分解复杂问题、引入自我批评蒙特卡洛树搜索（SC-MCTS）和加权推理路径堆叠，显著提高了问答准确率。", "motivation": "解决现有基于LLMs的KGQA方法在探索新最优推理路径时忽视历史推理路径利用，以及复杂问题语义导致检索不准确推理路径的问题。", "method": "提出RTSoG框架，包括问题分解、奖励模型引导的SC-MCTS迭代检索加权推理路径，以及根据权重堆叠推理路径生成最终答案。", "result": "在四个数据集上的广泛实验证明RTSoG的有效性，特别是在GrailQA和WebQSP上分别实现了8.7%和7.0%的性能提升。", "conclusion": "RTSoG通过有效利用历史推理路径和处理复杂问题语义，显著提高了KGQA任务的性能，为未来的研究提供了新的方向。"}}
{"id": "2505.12531", "title": "ESC-Judge: A Framework for Comparing Emotional Support Conversational Agents", "authors": ["Navid Madani", "Rohini Srihari"], "abstract": "Large language models (LLMs) increasingly power mental-health chatbots, yet the field still lacks a scalable, theory-grounded way to decide which model is most effective to deploy. We present ESC-Judge, the first end-to-end evaluation framework that (i) grounds head-to-head comparisons of emotional-support LLMs in Clara Hill's established Exploration-Insight-Action counseling model, providing a structured and interpretable view of performance, and (ii) fully automates the evaluation pipeline at scale. ESC-Judge operates in three stages: first, it synthesizes realistic help-seeker roles by sampling empirically salient attributes such as stressors, personality, and life history; second, it has two candidate support agents conduct separate sessions with the same role, isolating model-specific strategies; and third, it asks a specialized judge LLM to express pairwise preferences across rubric-anchored skills that span the Exploration, Insight, and Action spectrum. In our study, ESC-Judge matched PhD-level annotators on 85 percent of Exploration, 83 percent of Insight, and 86 percent of Action decisions, demonstrating human-level reliability at a fraction of the cost. All code, prompts, synthetic roles, transcripts, and judgment scripts are released to promote transparent progress in emotionally supportive AI.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.12531.pdf", "abstract_url": "https://arxiv.org/abs/2505.12531", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "ESC-Judge是一个用于比较情感支持对话代理的端到端评估框架，基于Clara Hill的探索-洞察-行动咨询模型，自动化评估流程，并在研究中显示出与博士级注释者相近的可靠性。", "motivation": "当前缺乏一个可扩展、理论基础的评估方法来决定哪个大型语言模型(LLM)最适合用于心理健康聊天机器人。", "method": "ESC-Judge通过三个阶段操作：合成真实的求助者角色，让两个候选支持代理与同一角色进行独立会话，然后让专门的法官LLM在探索、洞察和行动技能上表达成对偏好。", "result": "ESC-Judge在探索、洞察和行动决策上与博士级注释者的匹配率分别为85%、83%和86%，显示出与人类相当的可靠性且成本更低。", "conclusion": "ESC-Judge框架为情感支持AI的透明进步提供了支持，所有代码、提示、合成角色、转录本和判断脚本均已发布。"}}
{"id": "2505.12594", "title": "AD-AGENT: A Multi-agent Framework for End-to-end Anomaly Detection", "authors": ["Tiankai Yang", "Junjun Liu", "Wingchun Siu", "Jiahang Wang", "Zhuangzhuang Qian", "Chanjuan Song", "Cheng Cheng", "Xiyang Hu", "Yue Zhao"], "abstract": "Anomaly detection (AD) is essential in areas such as fraud detection, network monitoring, and scientific research. However, the diversity of data modalities and the increasing number of specialized AD libraries pose challenges for non-expert users who lack in-depth library-specific knowledge and advanced programming skills. To tackle this, we present AD-AGENT, an LLM-driven multi-agent framework that turns natural-language instructions into fully executable AD pipelines. AD-AGENT coordinates specialized agents for intent parsing, data preparation, library and model selection, documentation mining, and iterative code generation and debugging. Using a shared short-term workspace and a long-term cache, the agents integrate popular AD libraries like PyOD, PyGOD, and TSLib into a unified workflow. Experiments demonstrate that AD-AGENT produces reliable scripts and recommends competitive models across libraries. The system is open-sourced to support further research and practical applications in AD.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.12594.pdf", "abstract_url": "https://arxiv.org/abs/2505.12594", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "AD-AGENT是一个基于大型语言模型的多代理框架，旨在通过自然语言指令生成可执行异常检测流程，解决非专家用户在数据模态多样化和专用库知识不足的挑战。", "motivation": "异常检测在多个领域至关重要，但数据模态的多样性和专用库的增加为非专家用户带来了挑战。", "method": "AD-AGENT利用多代理框架，通过意图解析、数据准备、库和模型选择、文档挖掘及迭代代码生成和调试等步骤，整合流行异常检测库。", "result": "实验表明，AD-AGENT能生成可靠脚本并推荐跨库的竞争模型。", "conclusion": "AD-AGENT的开源发布支持异常检测的进一步研究和实际应用，为非专家用户提供了便利。"}}
{"id": "2505.12621", "title": "Think Before You Attribute: Improving the Performance of LLMs Attribution Systems", "authors": ["João Eduardo Batista", "Emil Vatai", "Mohamed Wahib"], "abstract": "Large Language Models (LLMs) are increasingly applied in various science domains, yet their broader adoption remains constrained by a critical challenge: the lack of trustworthy, verifiable outputs. Current LLMs often generate answers without reliable source attribution, or worse, with incorrect attributions, posing a barrier to their use in scientific and high-stakes settings, where traceability and accountability are non-negotiable. To be reliable, attribution systems need high accuracy and retrieve data with short lengths, i.e., attribute to a sentence within a document rather than a whole document. We propose a sentence-level pre-attribution step for Retrieve-Augmented Generation (RAG) systems that classify sentences into three categories: not attributable, attributable to a single quote, and attributable to multiple quotes. By separating sentences before attribution, a proper attribution method can be selected for the type of sentence, or the attribution can be skipped altogether. Our results indicate that classifiers are well-suited for this task. In this work, we propose a pre-attribution step to reduce the computational complexity of attribution, provide a clean version of the HAGRID dataset, and provide an end-to-end attribution system that works out of the box.", "subjects": "Computation and Language (cs.CL); Information Retrieval (cs.IR)", "comments": "22 pages (9 pages of content, 4 pages of references, 9 pages of supplementary material), 7 figures, 10 tables", "pdf_url": "https://arxiv.org/pdf/2505.12621.pdf", "abstract_url": "https://arxiv.org/abs/2505.12621", "categories": ["Computation and Language (cs.CL)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种句子级预归属步骤，用于提高大型语言模型（LLMs）归属系统的性能，通过分类句子并选择合适的归属方法，以减少计算复杂性并提高准确性。", "motivation": "大型语言模型在科学领域的广泛应用受到其输出缺乏可信、可验证来源的限制，特别是在需要高追溯性和责任性的高风险环境中。", "method": "提出了一个句子级的预归属步骤，将句子分类为不可归属、可归属到单一引用和可归属到多个引用三类，以便为每种类型的句子选择合适的归属方法或跳过归属。", "result": "结果表明，分类器非常适合这项任务，且提出的预归属步骤能有效减少归属的计算复杂性。", "conclusion": "通过引入句子级预归属步骤，可以显著提高LLMs归属系统的性能和可靠性，为科学和高风险环境中的应用提供了更可信的解决方案。"}}
{"id": "2505.12859", "title": "Re-identification of De-identified Documents with Autoregressive Infilling", "authors": ["Lucas Georges Gabriel Charpentier", "Pierre Lison"], "abstract": "Documents revealing sensitive information about individuals must typically be de-identified. This de-identification is often done by masking all mentions of personally identifiable information (PII), thereby making it more difficult to uncover the identity of the person(s) in question. To investigate the robustness of de-identification methods, we present a novel, RAG-inspired approach that attempts the reverse process of re-identification based on a database of documents representing background knowledge. Given a text in which personal identifiers have been masked, the re-identification proceeds in two steps. A retriever first selects from the background knowledge passages deemed relevant for the re-identification. Those passages are then provided to an infilling model which seeks to infer the original content of each text span. This process is repeated until all masked spans are replaced. We evaluate the re-identification on three datasets (Wikipedia biographies, court rulings and clinical notes). Results show that (1) as many as 80% of de-identified text spans can be successfully recovered and (2) the re-identification accuracy increases along with the level of background knowledge.", "subjects": "Computation and Language (cs.CL)", "comments": "To be presented a ACL 2025, Main, Long paper", "pdf_url": "https://arxiv.org/pdf/2505.12859.pdf", "abstract_url": "https://arxiv.org/abs/2505.12859", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种新颖的、受RAG启发的方法，用于重新识别去标识化文档，通过检索和填充模型恢复被掩盖的个人信息，评估显示高达80%的被掩盖信息可被成功恢复。", "motivation": "探讨去标识化方法的鲁棒性，即如何通过背景知识库重新识别被掩盖个人信息的文档。", "method": "采用两步法：首先通过检索器从背景知识库中选择相关段落，然后使用填充模型推断被掩盖文本的原始内容，直至所有被掩盖部分被替换。", "result": "在三个数据集上的评估显示，高达80%的去标识化文本可被成功恢复，且重新识别的准确率随背景知识水平的提高而增加。", "conclusion": "研究表明，当前的去标识化方法可能不够安全，需要更强大的保护措施以防止敏感信息被重新识别。"}}
{"id": "2505.12662", "title": "Know3-RAG: A Knowledge-aware RAG Framework with Adaptive Retrieval, Generation, and Filtering", "authors": ["Xukai Liu", "Ye Liu", "Shiwen Wu", "Yanghai Zhang", "Yihao Yuan", "Kai Zhang", "Qi Liu"], "abstract": "Recent advances in large language models (LLMs) have led to impressive progress in natural language generation, yet their tendency to produce hallucinated or unsubstantiated content remains a critical concern. To improve factual reliability, Retrieval-Augmented Generation (RAG) integrates external knowledge during inference. However, existing RAG systems face two major limitations: (1) unreliable adaptive control due to limited external knowledge supervision, and (2) hallucinations caused by inaccurate or irrelevant references. To address these issues, we propose Know3-RAG, a knowledge-aware RAG framework that leverages structured knowledge from knowledge graphs (KGs) to guide three core stages of the RAG process, including retrieval, generation, and filtering. Specifically, we introduce a knowledge-aware adaptive retrieval module that employs KG embedding to assess the confidence of the generated answer and determine retrieval necessity, a knowledge-enhanced reference generation strategy that enriches queries with KG-derived entities to improve generated reference relevance, and a knowledge-driven reference filtering mechanism that ensures semantic alignment and factual accuracy of references. Experiments on multiple open-domain QA benchmarks demonstrate that Know3-RAG consistently outperforms strong baselines, significantly reducing hallucinations and enhancing answer reliability.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.12662.pdf", "abstract_url": "https://arxiv.org/abs/2505.12662", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "Know3-RAG是一个知识感知的RAG框架，通过知识图谱的结构化知识指导检索、生成和过滤三个核心阶段，以提高事实可靠性并减少幻觉内容。", "motivation": "解决大型语言模型在自然语言生成中产生的幻觉或未经证实内容的问题，以及现有RAG系统在自适应控制和参考准确性方面的局限性。", "method": "提出Know3-RAG框架，包括知识感知的自适应检索模块、知识增强的参考生成策略和知识驱动的参考过滤机制。", "result": "在多个开放领域QA基准测试中，Know3-RAG consistently outperforms strong baselines, significantly reducing hallucinations and enhancing answer reliability。", "conclusion": "Know3-RAG通过整合知识图谱的结构化知识，有效提高了RAG系统的检索、生成和过滤能力，显著减少了幻觉内容并增强了答案的可靠性。"}}
{"id": "2505.12920", "title": "PyFCG: Fluid Construction Grammar in Python", "authors": ["Paul Van Eecke", "Katrien Beuls"], "abstract": "We present PyFCG, an open source software library that ports Fluid Construction Grammar (FCG) to the Python programming language. PyFCG enables its users to seamlessly integrate FCG functionality into Python programs, and to use FCG in combination with other libraries within Python's rich ecosystem. Apart from a general description of the library, this paper provides three walkthrough tutorials that demonstrate example usage of PyFCG in typical use cases of FCG: (i) formalising and testing construction grammar analyses, (ii) learning usage-based construction grammars from corpora, and (iii) implementing agent-based experiments on emergent communication.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.12920.pdf", "abstract_url": "https://arxiv.org/abs/2505.12920", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "PyFCG是一个开源软件库，将流体构建语法（FCG）移植到Python编程语言中，使用户能够将FCG功能无缝集成到Python程序中，并与Python丰富生态系统中的其他库结合使用。", "motivation": "解决在Python环境中使用流体构建语法（FCG）的需求，以及将FCG与其他Python库结合使用的挑战。", "method": "开发了PyFCG库，提供了三个使用教程，展示了PyFCG在FCG典型用例中的应用：形式化和测试构建语法分析、从语料库中学习基于使用的构建语法、以及实现基于代理的涌现通信实验。", "result": "PyFCG成功地将FCG功能集成到Python中，并通过教程展示了其在多种场景下的应用潜力。", "conclusion": "PyFCG为在Python环境中使用和研究FCG提供了强大的工具，促进了FCG与其他Python库的结合使用，为语言学和计算语言学的研究开辟了新途径。"}}
{"id": "2505.13006", "title": "Evaluating the Performance of RAG Methods for Conversational AI in the Airport Domain", "authors": ["Yuyang Li", "Philip J.M. Kerbusch", "Raimon H.R. Pruim", "Tobias Käfer"], "abstract": "Airports from the top 20 in terms of annual passengers are highly dynamic environments with thousands of flights daily, and they aim to increase the degree of automation. To contribute to this, we implemented a Conversational AI system that enables staff in an airport to communicate with flight information systems. This system not only answers standard airport queries but also resolves airport terminology, jargon, abbreviations, and dynamic questions involving reasoning. In this paper, we built three different Retrieval-Augmented Generation (RAG) methods, including traditional RAG, SQL RAG, and Knowledge Graph-based RAG (Graph RAG). Experiments showed that traditional RAG achieved 84.84% accuracy using BM25 + GPT-4 but occasionally produced hallucinations, which is risky to airport safety. In contrast, SQL RAG and Graph RAG achieved 80.85% and 91.49% accuracy respectively, with significantly fewer hallucinations. Moreover, Graph RAG was especially effective for questions that involved reasoning. Based on our observations, we thus recommend SQL RAG and Graph RAG are better for airport environments, due to fewer hallucinations and the ability to handle dynamic questions.", "subjects": "Computation and Language (cs.CL)", "comments": "Accepted by NAACL 2025 industry track", "pdf_url": "https://arxiv.org/pdf/2505.13006.pdf", "abstract_url": "https://arxiv.org/abs/2505.13006", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文评估了三种RAG方法在机场领域对话AI中的性能，推荐SQL RAG和Graph RAG因其较少产生幻觉且能处理动态问题。", "motivation": "解决机场环境中高度动态和复杂的信息查询问题，提高自动化程度。", "method": "实现了三种RAG方法：传统RAG、SQL RAG和基于知识图谱的RAG（Graph RAG），并进行了实验比较。", "result": "传统RAG准确率为84.84%，但偶尔产生幻觉；SQL RAG和Graph RAG准确率分别为80.85%和91.49%，且幻觉显著减少。Graph RAG特别擅长处理涉及推理的问题。", "conclusion": "推荐在机场环境中使用SQL RAG和Graph RAG，因为它们减少幻觉并能有效处理动态问题。"}}
{"id": "2505.11651", "title": "MIRACL-VISION: A Large, multilingual, visual document retrieval benchmark", "authors": ["Radek Osmulsk", "Gabriel de Souza P. Moreira", "Ronay Ak", "Mengyao Xu", "Benedikt Schifferer", "Even Oldridge"], "abstract": "Document retrieval is an important task for search and Retrieval-Augmented Generation (RAG) applications. Large Language Models (LLMs) have contributed to improving the accuracy of text-based document retrieval. However, documents with complex layout and visual elements like tables, charts and infographics are not perfectly represented in textual format. Recently, image-based document retrieval pipelines have become popular, which use visual large language models (VLMs) to retrieve relevant page images given a query. Current evaluation benchmarks on visual document retrieval are limited, as they primarily focus only English language, rely on synthetically generated questions and offer a small corpus size. Therefore, we introduce MIRACL-VISION, a multilingual visual document retrieval evaluation benchmark. MIRACL-VISION covers 18 languages, and is an extension of the MIRACL dataset, a popular benchmark to evaluate text-based multilingual retrieval pipelines. MIRACL was built using a human-intensive annotation process to generate high-quality questions. In order to reduce MIRACL-VISION corpus size to make evaluation more compute friendly while keeping the datasets challenging, we have designed a method for eliminating the \"easy\" negatives from the corpus. We conducted extensive experiments comparing MIRACL-VISION with other benchmarks, using popular public text and image models. We observe a gap in state-of-the-art VLM-based embedding models on multilingual capabilities, with up to 59.7% lower retrieval accuracy than a text-based retrieval models. Even for the English language, the visual models retrieval accuracy is 12.1% lower compared to text-based models. MIRACL-VISION is a challenging, representative, multilingual evaluation benchmark for visual retrieval pipelines and will help the community build robust models for document retrieval.", "subjects": "Information Retrieval (cs.IR); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.11651.pdf", "abstract_url": "https://arxiv.org/abs/2505.11651", "categories": ["Information Retrieval (cs.IR)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "MIRACL-VISION是一个多语言视觉文档检索评估基准，扩展自MIRACL数据集，覆盖18种语言，旨在解决现有视觉文档检索基准局限于英语、依赖合成问题和小规模语料库的问题。", "motivation": "解决现有视觉文档检索评估基准在语言多样性、问题质量和语料库规模上的局限性，以促进更健壮的文档检索模型的开发。", "method": "扩展MIRACL数据集，采用人工密集注释过程生成高质量问题，并通过设计方法消除语料库中的“简单”负面样本，以减少语料库规模同时保持挑战性。", "result": "实验显示，最先进的基于视觉语言模型（VLM）的嵌入模型在多语言能力上存在差距，检索准确率比基于文本的检索模型低达59.7%，即使在英语中，视觉模型的检索准确率也低12.1%。", "conclusion": "MIRACL-VISION是一个具有挑战性、代表性强的多语言视觉检索评估基准，将帮助社区开发更健壮的文档检索模型。"}}
{"id": "2505.13426", "title": "G1: Bootstrapping Perception and Reasoning Abilities of Vision-Language Model via Reinforcement Learning", "authors": ["Liang Chen", "Hongcheng Gao", "Tianyu Liu", "Zhiqi Huang", "Flood Sung", "Xinyu Zhou", "Yuxin Wu", "Baobao Chang"], "abstract": "Vision-Language Models (VLMs) excel in many direct multimodal tasks but struggle to translate this prowess into effective decision-making within interactive, visually rich environments like games. This ``knowing-doing'' gap significantly limits their potential as autonomous agents, as leading VLMs often performing badly in simple games. To address this, we introduce VLM-Gym, a curated reinforcement learning (RL) environment featuring diverse visual games with unified interfaces and adjustable, compositional difficulty, specifically designed for scalable multi-game parallel training. Leveraging VLM-Gym, we train G0 models using pure RL-driven self-evolution, which demonstrate emergent perception and reasoning patterns. To further mitigate challenges arising from game diversity, we develop G1 models. G1 incorporates a perception-enhanced cold start prior to RL fine-tuning. Our resulting G1 models consistently surpass their teacher across all games and outperform leading proprietary models like Claude-3.7-Sonnet-Thinking. Systematic analysis reveals an intriguing finding: perception and reasoning abilities mutually bootstrap each other throughout the RL training process. Source code including VLM-Gym and RL training are released at", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.13426.pdf", "abstract_url": "https://arxiv.org/abs/2505.13426", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了VLM-Gym，一个专为可扩展的多游戏并行训练设计的强化学习环境，旨在解决视觉语言模型（VLMs）在交互式视觉丰富环境中的决策能力不足问题。通过纯RL驱动的自我进化训练G0模型，并进一步开发了G1模型，该模型在RL微调前加入了感知增强的冷启动，显著提升了性能。", "motivation": "视觉语言模型在多模态任务中表现出色，但在交互式视觉丰富环境（如游戏）中的决策能力不足，这限制了其作为自主代理的潜力。", "method": "开发了VLM-Gym环境，支持多样化的视觉游戏和可调整的组合难度，用于可扩展的多游戏并行训练。通过纯RL驱动的自我进化训练G0模型，并进一步开发了G1模型，该模型在RL微调前加入了感知增强的冷启动。", "result": "G1模型在所有游戏中 consistently surpass their teacher 并 outperformed leading proprietary models like Claude-3.7-Sonnet-Thinking。系统分析揭示了感知和推理能力在RL训练过程中相互促进的有趣发现。", "conclusion": "通过VLM-Gym和RL训练，G1模型显著提升了视觉语言模型在交互式环境中的决策能力，展示了感知和推理能力在训练过程中的相互促进作用。"}}
{"id": "2505.11717", "title": "EnvInjection: Environmental Prompt Injection Attack to Multi-modal Web Agents", "authors": ["Xilong Wang", "John Bloch", "Zedian Shao", "Yuepeng Hu", "Shuyan Zhou", "Neil Zhenqiang Gong"], "abstract": "Multi-modal large language model (MLLM)-based web agents interact with webpage environments by generating actions based on screenshots of the webpages. Environmental prompt injection attacks manipulate the environment to induce the web agent to perform a specific, attacker-chosen action--referred to as the target action. However, existing attacks suffer from limited effectiveness or stealthiness, or are impractical in real-world settings. In this work, we propose EnvInjection, a new attack that addresses these limitations. Our attack adds a perturbation to the raw pixel values of the rendered webpage, which can be implemented by modifying the webpage's source code. After these perturbed pixels are mapped into a screenshot, the perturbation induces the web agent to perform the target action. We formulate the task of finding the perturbation as an optimization problem. A key challenge in solving this problem is that the mapping between raw pixel values and screenshot is non-differentiable, making it difficult to backpropagate gradients to the perturbation. To overcome this, we train a neural network to approximate the mapping and apply projected gradient descent to solve the reformulated optimization problem. Extensive evaluation on multiple webpage datasets shows that EnvInjection is highly effective and significantly outperforms existing baselines.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.11717.pdf", "abstract_url": "https://arxiv.org/abs/2505.11717", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了EnvInjection，一种针对多模态大型语言模型（MLLM）基于网页代理的环境提示注入攻击方法，通过修改网页源代码添加扰动，诱导代理执行攻击者选择的目标动作。", "motivation": "现有的环境提示注入攻击在有效性、隐蔽性或实际应用场景中存在局限，EnvInjection旨在解决这些问题。", "method": "通过将扰动添加到渲染网页的原始像素值中，并训练神经网络近似像素值与截图之间的映射，应用投影梯度下降解决优化问题。", "result": "在多个网页数据集上的广泛评估表明，EnvInjection非常有效，显著优于现有基线。", "conclusion": "EnvInjection作为一种新型攻击方法，不仅提高了攻击的有效性，还增强了在实际应用中的可行性，为多模态网页代理的安全研究提供了新的方向。"}}
{"id": "2505.13259", "title": "From Automation to Autonomy: A Survey on Large Language Models in Scientific Discovery", "authors": ["Tianshi Zheng", "Zheye Deng", "Hong Ting Tsang", "Weiqi Wang", "Jiaxin Bai", "Zihao Wang", "Yangqiu Song"], "abstract": "Large Language Models (LLMs) are catalyzing a paradigm shift in scientific discovery, evolving from task-specific automation tools into increasingly autonomous agents and fundamentally redefining research processes and human-AI collaboration. This survey systematically charts this burgeoning field, placing a central focus on the changing roles and escalating capabilities of LLMs in science. Through the lens of the scientific method, we introduce a foundational three-level taxonomy-Tool, Analyst, and Scientist-to delineate their escalating autonomy and evolving responsibilities within the research lifecycle. We further identify pivotal challenges and future research trajectories such as robotic automation, self-improvement, and ethical governance. Overall, this survey provides a conceptual architecture and strategic foresight to navigate and shape the future of AI-driven scientific discovery, fostering both rapid innovation and responsible advancement. Github Repository:", "subjects": "Computation and Language (cs.CL)", "comments": "16 pages", "pdf_url": "https://arxiv.org/pdf/2505.13259.pdf", "abstract_url": "https://arxiv.org/abs/2505.13259", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文综述了大型语言模型（LLMs）在科学发现中的角色演变，从自动化工具发展为自主代理，并提出了一个三级分类法（工具、分析师、科学家）来描述其在研究生命周期中的自主性和责任变化。", "motivation": "探讨LLMs如何从任务特定的自动化工具转变为科学发现中的自主代理，以及这一转变对研究过程和人类-AI合作的影响。", "method": "通过科学方法的视角，引入了一个三级分类法来系统化LLMs在科学中的角色和能力的提升。", "result": "识别了关键挑战和未来研究方向，如机器人自动化、自我改进和伦理治理。", "conclusion": "提供了一个概念架构和战略前瞻，以引导和塑造AI驱动的科学发现的未来，促进快速创新和负责任的发展。"}}
{"id": "2505.13328", "title": "Rethinking Stateful Tool Use in Multi-Turn Dialogues: Benchmarks and Challenges", "authors": ["Hongru Wang", "Wenyu Huang", "Yufei Wang", "Yuanhao Xi", "Jianqiao Lu", "Huan Zhang", "Nan Hu", "Zeming Liu", "Jeff Z. Pan", "Kam-Fai Wong"], "abstract": "Existing benchmarks that assess Language Models (LMs) as Language Agents (LAs) for tool use primarily focus on stateless, single-turn interactions or partial evaluations, such as tool selection in a single turn, overlooking the inherent stateful nature of interactions in multi-turn applications. To fulfill this gap, we propose \\texttt{DialogTool}, a multi-turn dialogue dataset with stateful tool interactions considering the whole life cycle of tool use, across six key tasks in three stages: 1) \\textit{tool creation}; 2) \\textit{tool utilization}: tool awareness, tool selection, tool execution; and 3) \\textit{role-consistent response}: response generation and role play. Furthermore, we build \\texttt{VirtualMobile} -- an embodied virtual mobile evaluation environment to simulate API calls and assess the robustness of the created APIs\\footnote{We will use tools and APIs alternatively, there are no significant differences between them in this paper.}. Taking advantage of these artifacts, we conduct comprehensive evaluation on 13 distinct open- and closed-source LLMs and provide detailed analysis at each stage, revealing that the existing state-of-the-art LLMs still cannot perform well to use tools over long horizons.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.13328.pdf", "abstract_url": "https://arxiv.org/abs/2505.13328", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一个名为DialogTool的多轮对话数据集，专注于状态工具使用的整个生命周期，并建立了一个虚拟移动评估环境VirtualMobile来模拟API调用。通过对13种不同的开源和闭源LLM进行全面评估，揭示了现有最先进的LLM在长期工具使用方面的不足。", "motivation": "现有的评估语言模型作为语言代理使用工具的基准主要关注无状态的单轮交互或部分评估，忽视了多轮应用中交互的状态性。", "method": "提出了DialogTool数据集和VirtualMobile评估环境，对工具使用的整个生命周期进行了全面评估，包括工具创建、工具利用和角色一致响应三个阶段。", "result": "评估结果显示，现有的最先进LLM在长期工具使用方面表现不佳。", "conclusion": "本文的工作填补了多轮对话中状态工具使用评估的空白，并为未来的研究提供了新的方向和挑战。"}}
{"id": "2505.13258", "title": "Effective and Transparent RAG: Adaptive-Reward Reinforcement Learning for Decision Traceability", "authors": ["Jingyi Ren", "Yekun Xu", "Xiaolong Wang", "Weitao Li", "Weizhi Ma", "Yang Liu"], "abstract": "Retrieval-Augmented Generation (RAG) has significantly improved the performance of large language models (LLMs) on knowledge-intensive domains. However, although RAG achieved successes across distinct domains, there are still some unsolved challenges: 1) Effectiveness. Existing research mainly focuses on developing more powerful RAG retrievers, but how to enhance the generator's (LLM's) ability to utilize the retrieved information for reasoning and generation? 2) Transparency. Most RAG methods ignore which retrieved content actually contributes to the reasoning process, resulting in a lack of interpretability and visibility. To address this, we propose ARENA (Adaptive-Rewarded Evidence Navigation Agent), a transparent RAG generator framework trained via reinforcement learning (RL) with our proposed rewards. Based on the structured generation and adaptive reward calculation, our RL-based training enables the model to identify key evidence, perform structured reasoning, and generate answers with interpretable decision traces. Applied to Qwen2.5-7B-Instruct and Llama3.1-8B-Instruct, abundant experiments with various RAG baselines demonstrate that our model achieves 10-30% improvements on all multi-hop QA datasets, which is comparable with the SOTA Commercially-developed LLMs (e.g., OpenAI-o1, DeepSeek-R1). Further analyses show that ARENA has strong flexibility to be adopted on new datasets without extra training. Our models and codes are publicly released.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.13258.pdf", "abstract_url": "https://arxiv.org/abs/2505.13258", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文提出了ARENA（自适应奖励证据导航代理），一个通过强化学习训练的透明RAG生成器框架，旨在解决RAG在效果和透明度方面的挑战。", "motivation": "解决RAG在知识密集型领域中存在的两个主要挑战：1) 如何增强生成器（LLM）利用检索信息进行推理和生成的能力；2) 提高RAG方法的透明度，明确哪些检索内容对推理过程有贡献。", "method": "提出了ARENA框架，通过强化学习（RL）训练，结合结构化生成和自适应奖励计算，使模型能够识别关键证据、执行结构化推理，并生成带有可解释决策痕迹的答案。", "result": "在Qwen2.5-7B-Instruct和Llama3.1-8B-Instruct上进行的丰富实验表明，ARENA在所有多跳QA数据集上实现了10-30%的性能提升，与最先进的商业开发LLMs（如OpenAI-o1、DeepSeek-R1）相当。进一步分析显示，ARENA在新数据集上具有强大的适应性，无需额外训练。", "conclusion": "ARENA不仅提高了RAG的效果和透明度，还展示了在新数据集上的强大适应能力，为RAG领域的研究和应用提供了新的方向。"}}
{"id": "2505.13434", "title": "SMOTExT: SMOTE meets Large Language Models", "authors": ["Mateusz Bystroński", "Mikołaj Hołysz", "Grzegorz Piotrowski", "Nitesh V. Chawla", "Tomasz Kajdanowicz"], "abstract": "Data scarcity and class imbalance are persistent challenges in training robust NLP models, especially in specialized domains or low-resource settings. We propose a novel technique, SMOTExT, that adapts the idea of Synthetic Minority Over-sampling (SMOTE) to textual data. Our method generates new synthetic examples by interpolating between BERT-based embeddings of two existing examples and then decoding the resulting latent point into text with xRAG architecture. By leveraging xRAG's cross-modal retrieval-generation framework, we can effectively turn interpolated vectors into coherent text. While this is preliminary work supported by qualitative outputs only, the method shows strong potential for knowledge distillation and data augmentation in few-shot settings. Notably, our approach also shows promise for privacy-preserving machine learning: in early experiments, training models solely on generated data achieved comparable performance to models trained on the original dataset. This suggests a viable path toward safe and effective learning under data protection constraints.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.13434.pdf", "abstract_url": "https://arxiv.org/abs/2505.13434", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "SMOTExT是一种新颖的技术，它将合成少数过采样（SMOTE）的思想应用于文本数据，通过BERT嵌入的插值和xRAG架构的解码生成新的合成文本示例，旨在解决NLP模型训练中的数据稀缺和类别不平衡问题。", "motivation": "解决在专业领域或低资源设置中训练稳健NLP模型时遇到的数据稀缺和类别不平衡的持续挑战。", "method": "通过插值两个现有示例的BERT基于嵌入，然后使用xRAG架构将潜在点解码为文本来生成新的合成示例。", "result": "初步工作仅得到定性输出的支持，但该方法在少样本设置中的知识蒸馏和数据增强方面显示出强大潜力，并在隐私保护机器学习方面显示出前景。", "conclusion": "SMOTExT为在数据保护约束下进行安全有效的学习提供了一条可行的路径，尤其是在隐私保护机器学习方面显示出潜力。"}}
{"id": "2505.11545", "title": "TARGET: Benchmarking Table Retrieval for Generative Tasks", "authors": ["Xingyu Ji", "Parker Glenn", "Aditya G. Parameswaran", "Madelon Hulsebos"], "abstract": "The data landscape is rich with structured data, often of high value to organizations, driving important applications in data analysis and machine learning. Recent progress in representation learning and generative models for such data has led to the development of natural language interfaces to structured data, including those leveraging text-to-SQL. Contextualizing interactions, either through conversational interfaces or agentic components, in structured data through retrieval-augmented generation can provide substantial benefits in the form of freshness, accuracy, and comprehensiveness of answers. The key question is: how do we retrieve the right table(s) for the analytical query or task at hand? To this end, we introduce TARGET: a benchmark for evaluating TAble Retrieval for GEnerative Tasks. With TARGET we analyze the retrieval performance of different retrievers in isolation, as well as their impact on downstream tasks. We find that dense embedding-based retrievers far outperform a BM25 baseline which is less effective than it is for retrieval over unstructured text. We also surface the sensitivity of retrievers across various metadata (e.g., missing table titles), and demonstrate a stark variation of retrieval performance across datasets and tasks. TARGET is available at", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Databases (cs.DB)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.11545.pdf", "abstract_url": "https://arxiv.org/abs/2505.11545", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Databases (cs.DB)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了TARGET，一个用于评估生成任务中表格检索性能的基准测试。通过分析不同检索器的性能及其对下游任务的影响，研究发现基于密集嵌入的检索器显著优于BM25基线，并揭示了检索器对各种元数据的敏感性。", "motivation": "解决在结构化数据中如何为分析查询或任务检索正确表格的问题。", "method": "引入TARGET基准，评估不同检索器在孤立状态下的检索性能及其对下游任务的影响。", "result": "密集嵌入式检索器在性能上远超BM25基线，且检索性能在不同数据集和任务间存在显著差异。", "conclusion": "TARGET基准为表格检索在生成任务中的应用提供了评估工具，揭示了检索器性能的差异和敏感性，对提高自然语言接口到结构化数据的准确性和全面性具有重要意义。"}}
{"id": "2505.12642", "title": "Two out of Three (ToT): using self-consistency to make robust predictions", "authors": ["Jung Hoon Lee", "Sujith Vijayan"], "abstract": "Deep learning (DL) can automatically construct intelligent agents, deep neural networks (alternatively, DL models), that can outperform humans in certain tasks. However, the operating principles of DL remain poorly understood, making its decisions incomprehensible. As a result, it poses a great risk to deploy DL in high-stakes domains in which mistakes or errors may lead to critical consequences. Here, we aim to develop an algorithm that can help DL models make more robust decisions by allowing them to abstain from answering when they are uncertain. Our algorithm, named `Two out of Three (ToT)', is inspired by the sensitivity of the human brain to conflicting information. ToT creates two alternative predictions in addition to the original model prediction and uses the alternative predictions to decide whether it should provide an answer or not.", "subjects": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV)", "comments": "12 pages, 7 main figures, 1 supplementary table and 2 supplementary figures", "pdf_url": "https://arxiv.org/pdf/2505.12642.pdf", "abstract_url": "https://arxiv.org/abs/2505.12642", "categories": ["Machine Learning (cs.LG)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为'三选二（ToT）'的算法，旨在通过让深度学习模型在不确定时选择不回答，来帮助其做出更稳健的决策。", "motivation": "深度学习的操作原则尚不明确，其决策难以理解，这在高风险领域中部署时带来了巨大风险。", "method": "ToT算法受到人类大脑对冲突信息敏感性的启发，创建了两个额外的预测，与原始模型预测一起，用于决定是否提供答案。", "result": "通过使用自一致性，ToT算法能够帮助深度学习模型做出更稳健的预测。", "conclusion": "ToT算法通过引入自一致性机制，提高了深度学习模型在高风险领域中的决策可靠性。"}}
{"id": "2505.12065", "title": "Demystifying and Enhancing the Efficiency of Large Language Model Based Search Agents", "authors": ["Tiannuo Yang", "Zebin Yao", "Bowen Jin", "Lixiao Cui", "Yusen Li", "Gang Wang", "Xiaoguang Liu"], "abstract": "Large Language Model (LLM)-based search agents have shown remarkable capabilities in solving complex tasks by dynamically decomposing problems and addressing them through interleaved reasoning and retrieval. However, this interleaved paradigm introduces substantial efficiency bottlenecks. First, we observe that both highly accurate and overly approximate retrieval methods degrade system efficiency: exact search incurs significant retrieval overhead, while coarse retrieval requires additional reasoning steps during generation. Second, we identify inefficiencies in system design, including improper scheduling and frequent retrieval stalls, which lead to cascading latency -- where even minor delays in retrieval amplify end-to-end inference time. To address these challenges, we introduce SearchAgent-X, a high-efficiency inference framework for LLM-based search agents. SearchAgent-X leverages high-recall approximate retrieval and incorporates two key techniques: priority-aware scheduling and non-stall retrieval. Extensive experiments demonstrate that SearchAgent-X consistently outperforms state-of-the-art systems such as vLLM and HNSW-based retrieval across diverse tasks, achieving up to 3.4$\\times$ higher throughput and 5$\\times$ lower latency, without compromising generation quality. SearchAgent-X is available at", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Information Retrieval (cs.IR); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.12065.pdf", "abstract_url": "https://arxiv.org/abs/2505.12065", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Information Retrieval (cs.IR)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了SearchAgent-X，一个针对基于大型语言模型（LLM）的搜索代理的高效推理框架，旨在解决现有系统中存在的效率瓶颈问题。", "motivation": "基于LLM的搜索代理在解决复杂任务时表现出色，但交错的推理和检索范式引入了显著的效率瓶颈，包括检索开销大和系统设计低效。", "method": "SearchAgent-X采用高召回近似检索，并引入了优先级感知调度和非停滞检索两项关键技术。", "result": "实验表明，SearchAgent-X在多样任务中 consistently outperforms state-of-the-art systems，实现了高达3.4倍的吞吐量和5倍的延迟降低，且不牺牲生成质量。", "conclusion": "SearchAgent-X有效解决了基于LLM的搜索代理的效率问题，为未来的研究和应用提供了有价值的参考。"}}
{"id": "2505.12039", "title": "AI-Driven Automation Can Become the Foundation of Next-Era Science of Science Research", "authors": ["Renqi Chen", "Haoyang Su", "Shixiang Tang", "Zhenfei Yin", "Qi Wu", "Hui Li", "Ye Sun", "Nanqing Dong", "Wanli Ouyang", "Philip Torr"], "abstract": "The Science of Science (SoS) explores the mechanisms underlying scientific discovery, and offers valuable insights for enhancing scientific efficiency and fostering innovation. Traditional approaches often rely on simplistic assumptions and basic statistical tools, such as linear regression and rule-based simulations, which struggle to capture the complexity and scale of modern research ecosystems. The advent of artificial intelligence (AI) presents a transformative opportunity for the next generation of SoS, enabling the automation of large-scale pattern discovery and uncovering insights previously unattainable. This paper offers a forward-looking perspective on the integration of Science of Science with AI for automated research pattern discovery and highlights key open challenges that could greatly benefit from AI. We outline the advantages of AI over traditional methods, discuss potential limitations, and propose pathways to overcome them. Additionally, we present a preliminary multi-agent system as an illustrative example to simulate research societies, showcasing AI's ability to replicate real-world research patterns and accelerate progress in Science of Science research.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Physics and Society (physics.soc-ph)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.12039.pdf", "abstract_url": "https://arxiv.org/abs/2505.12039", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Physics and Society (physics.soc-ph)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了人工智能（AI）如何成为下一代科学研究（SoS）的基础，通过自动化大规模模式发现来揭示传统方法难以捕捉的复杂性和规模，提出了AI与传统方法相比的优势、潜在限制及克服途径，并展示了一个初步的多智能体系统作为示例。", "motivation": "传统科学研究方法依赖于简化的假设和基础统计工具，如线性回归和基于规则的模拟，难以捕捉现代研究生态系统的复杂性和规模。AI的出现为SoS提供了转型机会，能够自动化发现大规模模式并揭示以前无法获得的见解。", "method": "本文提出了将科学研究与AI集成以自动化研究模式发现的视角，讨论了AI的优势和潜在限制，并提出了克服这些限制的途径。此外，还展示了一个初步的多智能体系统作为示例，模拟研究社会以展示AI复制现实世界研究模式和加速SoS研究进展的能力。", "result": "AI能够自动化大规模模式发现，揭示传统方法难以捕捉的复杂性和规模，加速科学研究进展。", "conclusion": "AI驱动的自动化为下一代SoS研究提供了基础，能够克服传统方法的限制，通过自动化大规模模式发现和模拟研究社会来加速科学发现和创新。"}}
{"id": "2505.12135", "title": "LLM-BABYBENCH: Understanding and Evaluating Grounded Planning and Reasoning in LLMs", "authors": ["Omar Choukrani", "Idriss Malek", "Daniil Orel", "Zhuohan Xie", "Zangir Iklassov", "Martin Takáč", "Salem Lahlou"], "abstract": "Assessing the capacity of Large Language Models (LLMs) to plan and reason within the constraints of interactive environments is crucial for developing capable AI agents. We introduce $\\textbf{LLM-BabyBench}$, a new benchmark suite designed specifically for this purpose. Built upon a textual adaptation of the procedurally generated BabyAI grid world, this suite evaluates LLMs on three fundamental aspects of grounded intelligence: (1) predicting the consequences of actions on the environment state ($\\textbf{Predict}$ task), (2) generating sequences of low-level actions to achieve specified objectives ($\\textbf{Plan}$ task), and (3) decomposing high-level instructions into coherent subgoal sequences ($\\textbf{Decompose}$ task). We detail the methodology for generating the three corresponding datasets ($\\texttt{LLM-BabyBench-Predict}$, $\\texttt{-Plan}$, $\\texttt{-Decompose}$) by extracting structured information from an expert agent operating within the text-based environment. Furthermore, we provide a standardized evaluation harness and metrics, including environment interaction for validating generated plans, to facilitate reproducible assessment of diverse LLMs. Initial baseline results highlight the challenges posed by these grounded reasoning tasks. The benchmark suite, datasets, data generation code, and evaluation code are made publicly available ($\\href{", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.12135.pdf", "abstract_url": "https://arxiv.org/abs/2505.12135", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了LLM-BabyBench，一个专门设计用于评估大型语言模型（LLMs）在交互环境中规划和推理能力的新基准套件。该套件基于BabyAI网格世界的文本改编，评估LLMs在三个基本方面的接地智能：预测行动对环境状态的影响、生成实现特定目标的低级行动序列以及将高级指令分解为连贯的子目标序列。", "motivation": "评估大型语言模型在交互环境中规划和推理的能力，对于开发有能力的人工智能代理至关重要。", "method": "通过从在基于文本的环境中操作的专家代理中提取结构化信息，生成三个相应的数据集（LLM-BabyBench-Predict、-Plan、-Decompose），并提供一个标准化的评估框架和度量标准，包括用于验证生成计划的环境交互。", "result": "初步基线结果突出了这些接地推理任务所带来的挑战。", "conclusion": "LLM-BabyBench基准套件、数据集、数据生成代码和评估代码的公开可用性，为多样化LLMs的可重复评估提供了便利。"}}
{"id": "2505.13227", "title": "Scaling Computer-Use Grounding via User Interface Decomposition and Synthesis", "authors": ["Tianbao Xie", "Jiaqi Deng", "Xiaochuan Li", "Junlin Yang", "Haoyuan Wu", "Jixuan Chen", "Wenjing Hu", "Xinyuan Wang", "Yuhui Xu", "Zekun Wang", "Yiheng Xu", "Junli Wang", "Doyen Sahoo", "Tao Yu", "Caiming Xiong"], "abstract": "Graphical user interface (GUI) grounding, the ability to map natural language instructions to specific actions on graphical user interfaces, remains a critical bottleneck in computer use agent development. Current benchmarks oversimplify grounding tasks as short referring expressions, failing to capture the complexity of real-world interactions that require software commonsense, layout understanding, and fine-grained manipulation capabilities. To address these limitations, we introduce OSWorld-G, a comprehensive benchmark comprising 564 finely annotated samples across diverse task types including text matching, element recognition, layout understanding, and precise manipulation. Additionally, we synthesize and release the largest computer use grounding dataset Jedi, which contains 4 million examples through multi-perspective decoupling of tasks. Our multi-scale models trained on Jedi demonstrate its effectiveness by outperforming existing approaches on ScreenSpot-v2, ScreenSpot-Pro, and our OSWorld-G. Furthermore, we demonstrate that improved grounding with Jedi directly enhances agentic capabilities of general foundation models on complex computer tasks, improving from 5% to 27% on OSWorld. Through detailed ablation studies, we identify key factors contributing to grounding performance and verify that combining specialized data for different interface elements enables compositional generalization to novel interfaces. All benchmark, data, checkpoints, and code are open-sourced and available at", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC)", "comments": "49 pages, 13 figures", "pdf_url": "https://arxiv.org/pdf/2505.13227.pdf", "abstract_url": "https://arxiv.org/abs/2505.13227", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Computer Vision and Pattern Recognition (cs.CV)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了OSWorld-G和Jedi，一个全面的图形用户界面(GUI)接地基准和最大的计算机使用接地数据集，旨在解决当前基准在捕捉真实世界交互复杂性方面的不足。通过多尺度模型训练，展示了Jedi数据集在提高接地性能和增强通用基础模型在复杂计算机任务上代理能力方面的有效性。", "motivation": "图形用户界面(GUI)接地能力是计算机使用代理开发中的一个关键瓶颈。当前基准将接地任务过度简化为短引用表达，未能捕捉需要软件常识、布局理解和细粒度操作能力的真实世界交互的复杂性。", "method": "引入了OSWorld-G，一个包含564个精细注释样本的全面基准，涵盖了文本匹配、元素识别、布局理解和精确操作等多种任务类型。同时，通过任务的多视角解耦，合成并发布了最大的计算机使用接地数据集Jedi，包含400万个例子。", "result": "在Jedi上训练的多尺度模型在ScreenSpot-v2、ScreenSpot-Pro和OSWorld-G上优于现有方法。此外，改进的接地能力直接将通用基础模型在复杂计算机任务上的代理能力从5%提高到27%。", "conclusion": "通过详细的消融研究，确定了影响接地性能的关键因素，并验证了结合不同界面元素的专门数据能够实现对新颖界面的组合泛化。所有基准、数据、检查点和代码均已开源。"}}
{"id": "2505.12371", "title": "MedAgentBoard: Benchmarking Multi-Agent Collaboration with Conventional Methods for Diverse Medical Tasks", "authors": ["Yinghao Zhu", "Ziyi He", "Haoran Hu", "Xiaochen Zheng", "Xichen Zhang", "Zixiang Wang", "Junyi Gao", "Liantao Ma", "Lequan Yu"], "abstract": "The rapid advancement of Large Language Models (LLMs) has stimulated interest in multi-agent collaboration for addressing complex medical tasks. However, the practical advantages of multi-agent collaboration approaches remain insufficiently understood. Existing evaluations often lack generalizability, failing to cover diverse tasks reflective of real-world clinical practice, and frequently omit rigorous comparisons against both single-LLM-based and established conventional methods. To address this critical gap, we introduce MedAgentBoard, a comprehensive benchmark for the systematic evaluation of multi-agent collaboration, single-LLM, and conventional approaches. MedAgentBoard encompasses four diverse medical task categories: (1) medical (visual) question answering, (2) lay summary generation, (3) structured Electronic Health Record (EHR) predictive modeling, and (4) clinical workflow automation, across text, medical images, and structured EHR data. Our extensive experiments reveal a nuanced landscape: while multi-agent collaboration demonstrates benefits in specific scenarios, such as enhancing task completeness in clinical workflow automation, it does not consistently outperform advanced single LLMs (e.g., in textual medical QA) or, critically, specialized conventional methods that generally maintain better performance in tasks like medical VQA and EHR-based prediction. MedAgentBoard offers a vital resource and actionable insights, emphasizing the necessity of a task-specific, evidence-based approach to selecting and developing AI solutions in medicine. It underscores that the inherent complexity and overhead of multi-agent collaboration must be carefully weighed against tangible performance gains. All code, datasets, detailed prompts, and experimental results are open-sourced at", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.12371.pdf", "abstract_url": "https://arxiv.org/abs/2505.12371", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了MedAgentBoard，一个用于系统评估多智能体协作、单一大语言模型（LLM）和传统方法在多样化医疗任务中表现的全面基准。", "motivation": "解决多智能体协作在复杂医疗任务中实际优势不足理解的问题，以及现有评估缺乏普遍性和多样化任务覆盖的不足。", "method": "引入MedAgentBoard基准，涵盖四类医疗任务：医疗（视觉）问答、通俗摘要生成、结构化电子健康记录（EHR）预测建模和临床工作流程自动化。", "result": "实验显示多智能体协作在特定场景下（如提高临床工作流程自动化的任务完整性）有益，但并不总是优于先进的单LLM或专业传统方法。", "conclusion": "强调在医学中选择和开发AI解决方案时，需要基于任务特定的、证据为基础的方法，并仔细权衡多智能体协作的复杂性和开销与性能提升。"}}
{"id": "2505.12442", "title": "IP Leakage Attacks Targeting LLM-Based Multi-Agent Systems", "authors": ["Liwen Wang", "Wenxuan Wang", "Shuai Wang", "Zongjie Li", "Zhenlan Ji", "Zongyi Lyu", "Daoyuan Wu", "Shing-Chi Cheung"], "abstract": "The rapid advancement of Large Language Models (LLMs) has led to the emergence of Multi-Agent Systems (MAS) to perform complex tasks through collaboration. However, the intricate nature of MAS, including their architecture and agent interactions, raises significant concerns regarding intellectual property (IP) protection. In this paper, we introduce MASLEAK, a novel attack framework designed to extract sensitive information from MAS applications. MASLEAK targets a practical, black-box setting, where the adversary has no prior knowledge of the MAS architecture or agent configurations. The adversary can only interact with the MAS through its public API, submitting attack query $q$ and observing outputs from the final agent. Inspired by how computer worms propagate and infect vulnerable network hosts, MASLEAK carefully crafts adversarial query $q$ to elicit, propagate, and retain responses from each MAS agent that reveal a full set of proprietary components, including the number of agents, system topology, system prompts, task instructions, and tool usages. We construct the first synthetic dataset of MAS applications with 810 applications and also evaluate MASLEAK against real-world MAS applications, including Coze and CrewAI. MASLEAK achieves high accuracy in extracting MAS IP, with an average attack success rate of 87% for system prompts and task instructions, and 92% for system architecture in most cases. We conclude by discussing the implications of our findings and the potential defenses.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.12442.pdf", "abstract_url": "https://arxiv.org/abs/2505.12442", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了MASLEAK，一种针对基于LLM的多代理系统（MAS）的新型攻击框架，旨在提取敏感信息。MASLEAK在对手对MAS架构或代理配置一无所知的黑盒设置下，通过精心设计的查询成功提取了包括系统提示、任务指令等在内的专有组件，攻击成功率高达87%-92%。", "motivation": "随着大型语言模型（LLMs）的快速发展，多代理系统（MAS）被用于通过协作执行复杂任务。然而，MAS的复杂性，包括其架构和代理交互，引发了关于知识产权（IP）保护的重大关切。", "method": "MASLEAK攻击框架，在对手仅能通过公共API与MAS交互的黑盒设置下，通过精心设计的对抗性查询$q$，激发、传播并保留来自每个MAS代理的响应，以揭示包括代理数量、系统拓扑、系统提示、任务指令和工具使用在内的专有组件。", "result": "MASLEAK在提取MAS IP方面达到了高准确率，对于系统提示和任务指令的平均攻击成功率为87%，对于系统架构在大多数情况下为92%。", "conclusion": "研究结果揭示了MAS在IP保护方面的脆弱性，并讨论了潜在的防御措施。"}}
{"id": "2505.12842", "title": "GEM: Gaussian Embedding Modeling for Out-of-Distribution Detection in GUI Agents", "authors": ["Zheng Wu", "Pengzhou Cheng", "Zongru Wu", "Lingzhong Dong", "Zhuosheng Zhang"], "abstract": "Graphical user interface (GUI) agents have recently emerged as an intriguing paradigm for human-computer interaction, capable of automatically executing user instructions to operate intelligent terminal devices. However, when encountering out-of-distribution (OOD) instructions that violate environmental constraints or exceed the current capabilities of agents, GUI agents may suffer task breakdowns or even pose security threats. Therefore, effective OOD detection for GUI agents is essential. Traditional OOD detection methods perform suboptimally in this domain due to the complex embedding space and evolving GUI environments. In this work, we observe that the in-distribution input semantic space of GUI agents exhibits a clustering pattern with respect to the distance from the centroid. Based on the finding, we propose GEM, a novel method based on fitting a Gaussian mixture model over input embedding distances extracted from the GUI Agent that reflect its capability boundary. Evaluated on eight datasets spanning smartphones, computers, and web browsers, our method achieves an average accuracy improvement of 23.70\\% over the best-performing baseline. Analysis verifies the generalization ability of our method through experiments on nine different backbones. The codes are available at", "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.12842.pdf", "abstract_url": "https://arxiv.org/abs/2505.12842", "categories": ["Machine Learning (cs.LG)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为GEM的新方法，用于图形用户界面(GUI)代理中的分布外(OOD)检测，通过高斯混合模型拟合输入嵌入距离来反映代理的能力边界，显著提高了检测准确率。", "motivation": "GUI代理在执行超出其能力范围或违反环境约束的指令时，可能会导致任务失败或安全威胁。传统的OOD检测方法在这一领域表现不佳，因此需要更有效的解决方案。", "method": "提出GEM方法，基于观察到的输入语义空间聚类模式，使用高斯混合模型拟合从GUI代理提取的输入嵌入距离，以反映其能力边界。", "result": "在八个数据集上的评估显示，GEM方法比最佳基线平均准确率提高了23.70%，并通过在九种不同骨干网络上的实验验证了其泛化能力。", "conclusion": "GEM方法有效提高了GUI代理中OOD检测的准确率和泛化能力，为GUI代理的安全和可靠性提供了重要保障。"}}
{"id": "2505.12938", "title": "Leveraging LLM Inconsistency to Boost Pass@k Performance", "authors": ["Uri Dalal", "Meirav Segal", "Zvika Ben-Haim", "Dan Lahav", "Omer Nevo"], "abstract": "Large language models (LLMs) achieve impressive abilities in numerous domains, but exhibit inconsistent performance in response to minor input changes. Rather than view this as a drawback, in this paper we introduce a novel method for leveraging models' inconsistency to boost Pass@k performance. Specifically, we present a \"Variator\" agent that generates k variants of a given task and submits one candidate solution for each one. Our variant generation approach is applicable to a wide range of domains as it is task agnostic and compatible with free-form inputs. We demonstrate the efficacy of our agent theoretically using a probabilistic model of the inconsistency effect, and show empirically that it outperforms the baseline on the APPS dataset. Furthermore, we establish that inconsistency persists even in frontier reasoning models across coding and cybersecurity domains, suggesting our method is likely to remain relevant for future model generations.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.12938.pdf", "abstract_url": "https://arxiv.org/abs/2505.12938", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新方法，利用大型语言模型（LLMs）在响应微小输入变化时表现出的不一致性，通过“Variator”代理生成任务变体，以提高Pass@k性能。", "motivation": "解决大型语言模型在响应微小输入变化时表现不一致的问题，并将这种不一致性转化为提升模型性能的机会。", "method": "引入“Variator”代理，生成给定任务的k个变体，并为每个变体提交一个候选解决方案。该方法任务无关，适用于自由形式输入。", "result": "理论分析和APPS数据集的实证研究表明，该方法在提升Pass@k性能上优于基线方法，且不一致性在编码和网络安全领域的前沿推理模型中仍然存在。", "conclusion": "利用LLMs的不一致性可以有效提升模型性能，且这种方法对未来模型世代仍具有相关性。"}}
{"id": "2505.11584", "title": "LLM Agents Are Hypersensitive to Nudges", "authors": ["Manuel Cherep", "Pattie Maes", "Nikhil Singh"], "abstract": "LLMs are being set loose in complex, real-world environments involving sequential decision-making and tool use. Often, this involves making choices on behalf of human users. However, not much is known about the distribution of such choices, and how susceptible they are to different choice architectures. We perform a case study with a few such LLM models on a multi-attribute tabular decision-making problem, under canonical nudges such as the default option, suggestions, and information highlighting, as well as additional prompting strategies. We show that, despite superficial similarities to human choice distributions, such models differ in subtle but important ways. First, they show much higher susceptibility to the nudges. Second, they diverge in points earned, being affected by factors like the idiosyncrasy of available prizes. Third, they diverge in information acquisition strategies: e.g. incurring substantial cost to reveal too much information, or selecting without revealing any. Moreover, we show that simple prompt strategies like zero-shot chain of thought (CoT) can shift the choice distribution, and few-shot prompting with human data can induce greater alignment. Yet, none of these methods resolve the sensitivity of these models to nudges. Finally, we show how optimal nudges optimized with a human resource-rational model can similarly increase LLM performance for some models. All these findings suggest that behavioral tests are needed before deploying models as agents or assistants acting on behalf of users in complex environments.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "33 pages, 28 figures", "pdf_url": "https://arxiv.org/pdf/2505.11584.pdf", "abstract_url": "https://arxiv.org/abs/2505.11584", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "研究表明，大型语言模型（LLMs）在多属性表格决策问题中对选择架构（如默认选项、建议和信息高亮）表现出极高的敏感性，与人类选择分布存在微妙但重要的差异。", "motivation": "探讨LLMs在复杂现实环境中的决策行为及其对不同选择架构的敏感性，以确保它们作为代理或助手时的行为符合用户期望。", "method": "通过案例研究，对几种LLM模型在多属性表格决策问题中应用经典选择架构和提示策略（如零-shot思维链和少量样本提示）的效果进行分析。", "result": "LLMs对选择架构的敏感性高于人类，且在信息获取策略和积分获取上存在差异；简单的提示策略可以改变选择分布，但无法消除对选择架构的敏感性。", "conclusion": "在将LLMs部署为复杂环境中的代理或助手之前，需要进行行为测试以确保其行为与用户期望一致。"}}
{"id": "2505.11661", "title": "Learning from Less: Guiding Deep Reinforcement Learning with Differentiable Symbolic Planning", "authors": ["Zihan Ye", "Oleg Arenz", "Kristian Kersting"], "abstract": "When tackling complex problems, humans naturally break them down into smaller, manageable subtasks and adjust their initial plans based on observations. For instance, if you want to make coffee at a friend's place, you might initially plan to grab coffee beans, go to the coffee machine, and pour them into the machine. Upon noticing that the machine is full, you would skip the initial steps and proceed directly to brewing. In stark contrast, state of the art reinforcement learners, such as Proximal Policy Optimization (PPO), lack such prior knowledge and therefore require significantly more training steps to exhibit comparable adaptive behavior. Thus, a central research question arises: \\textit{How can we enable reinforcement learning (RL) agents to have similar ``human priors'', allowing the agent to learn with fewer training interactions?} To address this challenge, we propose differentiable symbolic planner (Dylan), a novel framework that integrates symbolic planning into Reinforcement Learning. Dylan serves as a reward model that dynamically shapes rewards by leveraging human priors, guiding agents through intermediate subtasks, thus enabling more efficient exploration. Beyond reward shaping, Dylan can work as a high level planner that composes primitive policies to generate new behaviors while avoiding common symbolic planner pitfalls such as infinite execution loops. Our experimental evaluations demonstrate that Dylan significantly improves RL agents' performance and facilitates generalization to unseen tasks.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "conference paper, 9 pages", "pdf_url": "https://arxiv.org/pdf/2505.11661.pdf", "abstract_url": "https://arxiv.org/abs/2505.11661", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为Dylan的新框架，将符号规划与强化学习相结合，以模拟人类先验知识，从而减少训练交互次数并提高探索效率。", "motivation": "解决强化学习代理缺乏人类先验知识，导致需要大量训练步骤才能表现出适应性行为的问题。", "method": "提出可微分符号规划器（Dylan），作为奖励模型动态塑造奖励，利用人类先验知识引导代理通过中间子任务。", "result": "实验评估表明，Dylan显著提高了强化学习代理的性能，并促进了在未见任务上的泛化能力。", "conclusion": "Dylan框架通过整合符号规划和强化学习，有效地模拟了人类先验知识，使代理能够以更少的训练交互学习，并在新任务上表现出更好的泛化能力。"}}
{"id": "2505.11718", "title": "REMOR: Automated Peer Review Generation with LLM Reasoning and Multi-Objective Reinforcement Learning", "authors": ["Pawin Taechoyotin", "Daniel Acuna"], "abstract": "AI-based peer review systems tend to produce shallow and overpraising suggestions compared to human feedback. Here, we evaluate how well a reasoning LLM trained with multi-objective reinforcement learning (REMOR) can overcome these limitations. We start by designing a multi-aspect reward function that aligns with human evaluation of reviews. The aspects are related to the review itself (e.g., criticisms, novelty) and the relationship between the review and the manuscript (i.e., relevance). First, we perform supervised fine-tuning of DeepSeek-R1-Distill-Qwen-7B using LoRA on PeerRT, a new dataset of high-quality top AI conference reviews enriched with reasoning traces. We then apply Group Relative Policy Optimization (GRPO) to train two models: REMOR-H (with the human-aligned reward) and REMOR-U (with a uniform reward). Interestingly, the human-aligned reward penalizes aspects typically associated with strong reviews, leading REMOR-U to produce qualitatively more substantive feedback. Our results show that REMOR-U and REMOR-H achieve more than twice the average rewards of human reviews, non-reasoning state-of-the-art agentic multi-modal AI review systems, and general commercial LLM baselines. We found that while the best AI and human reviews are comparable in quality, REMOR avoids the long tail of low-quality human reviews. We discuss how reasoning is key to achieving these improvements and release the Human-aligned Peer Review Reward (HPRR) function, the Peer Review Reasoning-enriched Traces (PeerRT) dataset, and the REMOR models, which we believe can help spur progress in the area.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "18 pages, 6 figures", "pdf_url": "https://arxiv.org/pdf/2505.11718.pdf", "abstract_url": "https://arxiv.org/abs/2505.11718", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了REMOR，一个利用大型语言模型（LLM）推理和多目标强化学习（MORL）自动生成同行评审的系统。通过设计一个与人类评价对齐的多方面奖励函数，并应用Group Relative Policy Optimization（GRPO）训练模型，REMOR在生成实质性反馈方面表现出色，超越了现有技术和人类评审的平均水平。", "motivation": "解决AI同行评审系统生成的建议通常比人类反馈浅显和过度赞扬的问题。", "method": "使用LoRA对DeepSeek-R1-Distill-Qwen-7B进行监督微调，应用GRPO训练两个模型：REMOR-H（人类对齐奖励）和REMOR-U（均匀奖励）。", "result": "REMOR-U和REMOR-H的平均奖励是人类评审、非推理最先进的多模态AI评审系统和通用商业LLM基准的两倍以上。", "conclusion": "推理是实现这些改进的关键，REMOR避免了低质量人类评审的长尾问题。发布了HPRR奖励函数、PeerRT数据集和REMOR模型，以促进该领域的进步。"}}
{"id": "2505.11866", "title": "Position Paper: Bounded Alignment: What (Not) To Expect From AGI Agents", "authors": ["Ali A. Minai"], "abstract": "The issues of AI risk and AI safety are becoming critical as the prospect of artificial general intelligence (AGI) looms larger. The emergence of extremely large and capable generative models has led to alarming predictions and created a stir from boardrooms to legislatures. As a result, AI alignment has emerged as one of the most important areas in AI research. The goal of this position paper is to argue that the currently dominant vision of AGI in the AI and machine learning (AI/ML) community needs to evolve, and that expectations and metrics for its safety must be informed much more by our understanding of the only existing instance of general intelligence, i.e., the intelligence found in animals, and especially in humans. This change in perspective will lead to a more realistic view of the technology, and allow for better policy decisions.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "Paper accepted for the 2025 IEEE/INNS International Joint Conference on Neural Networks, Rome, Italy, June 30 - July 5, 2025", "pdf_url": "https://arxiv.org/pdf/2505.11866.pdf", "abstract_url": "https://arxiv.org/abs/2505.11866", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文是一篇立场论文，主张随着人工通用智能（AGI）的临近，AI风险和AI安全问题变得至关重要。论文认为，当前AI/ML社区对AGI的主导愿景需要发展，其安全性的期望和指标应更多地基于我们对现有唯一通用智能实例——动物，尤其是人类智能的理解。这种视角的转变将带来对技术更现实的看法，并允许更好的政策决策。", "motivation": "随着人工通用智能（AGI）的前景日益临近，AI风险和AI安全问题变得至关重要。大型生成模型的出现引发了令人担忧的预测，并在从董事会到立法机构的各个层面引起了震动。因此，AI对齐已成为AI研究中最重要的领域之一。", "method": "本文采用立场论文的形式，通过论证和分析当前AI/ML社区对AGI的主导愿景需要发展，提出其安全性的期望和指标应更多地基于对动物和人类智能的理解。", "result": "论文提出，通过改变视角，基于对现有通用智能实例的理解，可以形成对AGI技术更现实的看法，并促进更好的政策决策。", "conclusion": "本文的结论是，为了更有效地应对AGI带来的挑战和机遇，AI/ML社区需要调整对AGI的期望和安全性指标，更多地借鉴人类和动物智能的理解，以实现更现实的技术评估和政策制定。"}}
{"id": "2505.11942", "title": "LifelongAgentBench: Evaluating LLM Agents as Lifelong Learners", "authors": ["Junhao Zheng", "Xidi Cai", "Qiuke Li", "Duzhen Zhang", "ZhongZhi Li", "Yingying Zhang", "Le Song", "Qianli Ma"], "abstract": "Lifelong learning is essential for intelligent agents operating in dynamic environments. Current large language model (LLM)-based agents, however, remain stateless and unable to accumulate or transfer knowledge over time. Existing benchmarks treat agents as static systems and fail to evaluate lifelong learning capabilities. We present LifelongAgentBench, the first unified benchmark designed to systematically assess the lifelong learning ability of LLM agents. It provides skill-grounded, interdependent tasks across three interactive environments, Database, Operating System, and Knowledge Graph, with automatic label verification, reproducibility, and modular extensibility. Extensive experiments reveal that conventional experience replay has limited effectiveness for LLM agents due to irrelevant information and context length constraints. We further introduce a group self-consistency mechanism that significantly improves lifelong learning performance. We hope LifelongAgentBench will advance the development of adaptive, memory-capable LLM agents.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.11942.pdf", "abstract_url": "https://arxiv.org/abs/2505.11942", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了LifelongAgentBench，首个系统评估大型语言模型（LLM）代理终身学习能力的统一基准，旨在解决现有基准无法评估终身学习能力的问题。", "motivation": "当前基于大型语言模型（LLM）的代理缺乏状态，无法随时间积累或转移知识，现有基准未能评估其终身学习能力。", "method": "提出了LifelongAgentBench基准，包含三个交互环境（数据库、操作系统和知识图谱）的技能基础、相互依赖任务，具有自动标签验证、可重复性和模块化扩展性。", "result": "实验显示传统经验回放对LLM代理效果有限，提出了群体自一致性机制显著提升终身学习性能。", "conclusion": "LifelongAgentBench有望推动开发具有自适应和记忆能力的LLM代理。"}}
{"id": "2505.11962", "title": "CrafText Benchmark: Advancing Instruction Following in Complex Multimodal Open-Ended World", "authors": ["Zoya Volovikova", "Gregory Gorbov", "Petr Kuderov", "Aleksandr I. Panov", "Alexey Skrynnik"], "abstract": "Following instructions in real-world conditions requires the ability to adapt to the world's volatility and entanglement: the environment is dynamic and unpredictable, instructions can be linguistically complex with diverse vocabulary, and the number of possible goals an agent may encounter is vast. Despite extensive research in this area, most studies are conducted in static environments with simple instructions and a limited vocabulary, making it difficult to assess agent performance in more diverse and challenging settings. To address this gap, we introduce CrafText, a benchmark for evaluating instruction following in a multimodal environment with diverse instructions and dynamic interactions. CrafText includes 3,924 instructions with 3,423 unique words, covering Localization, Conditional, Building, and Achievement tasks. Additionally, we propose an evaluation protocol that measures an agent's ability to generalize to novel instruction formulations and dynamically evolving task configurations, providing a rigorous test of both linguistic understanding and adaptive decision-making.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.11962.pdf", "abstract_url": "https://arxiv.org/abs/2505.11962", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "CrafText基准测试：在复杂多模态开放世界中推进指令跟随", "motivation": "解决在现实世界条件下跟随指令的挑战，包括环境的动态性和不可预测性、指令的语言复杂性以及可能遇到的目标多样性。现有研究多在静态环境、简单指令和有限词汇中进行，难以评估代理在更多样化和挑战性环境中的表现。", "method": "引入CrafText基准测试，用于在多模态环境中评估指令跟随能力，包含多样化的指令和动态交互。CrafText包括3,924条指令和3,423个独特词汇，涵盖定位、条件、建造和成就任务。并提出一种评估协议，衡量代理对新指令表述和动态变化任务配置的泛化能力。", "result": "CrafText提供了一个严格的测试，既测试语言理解能力，也测试自适应决策能力。", "conclusion": "CrafText基准测试填补了现有研究的空白，为评估代理在复杂多变环境中的指令跟随能力提供了新的工具和方法。"}}
{"id": "2505.12001", "title": "Interactional Fairness in LLM Multi-Agent Systems: An Evaluation Framework", "authors": ["Ruta Binkyte"], "abstract": "As large language models (LLMs) are increasingly used in multi-agent systems, questions of fairness should extend beyond resource distribution and procedural design to include the fairness of how agents communicate. Drawing from organizational psychology, we introduce a novel framework for evaluating Interactional fairness encompassing Interpersonal fairness (IF) and Informational fairness (InfF) in LLM-based multi-agent systems (LLM-MAS). We extend the theoretical grounding of Interactional Fairness to non-sentient agents, reframing fairness as a socially interpretable signal rather than a subjective experience. We then adapt established tools from organizational justice research, including Colquitt's Organizational Justice Scale and the Critical Incident Technique, to measure fairness as a behavioral property of agent interaction. We validate our framework through a pilot study using controlled simulations of a resource negotiation task. We systematically manipulate tone, explanation quality, outcome inequality, and task framing (collaborative vs. competitive) to assess how IF influences agent behavior. Results show that tone and justification quality significantly affect acceptance decisions even when objective outcomes are held constant. In addition, the influence of IF vs. InfF varies with context. This work lays the foundation for fairness auditing and norm-sensitive alignment in LLM-MAS.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.12001.pdf", "abstract_url": "https://arxiv.org/abs/2505.12001", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一个评估大型语言模型（LLM）多智能体系统中交互公平性的新框架，包括人际公平性（IF）和信息公平性（InfF），并通过实验验证了语气和解释质量对智能体行为的影响。", "motivation": "随着大型语言模型在多智能体系统中的广泛应用，公平性问题不仅限于资源分配和程序设计，还应包括智能体间通信的公平性。", "method": "作者从组织心理学出发，引入了一个评估交互公平性的框架，并调整了组织正义研究中的工具（如Colquitt的组织正义量表和关键事件技术）来测量智能体交互的行为属性。", "result": "实验结果表明，语气和解释质量显著影响接受决策，即使客观结果保持不变。此外，IF与InfF的影响随情境变化。", "conclusion": "这项工作为LLM多智能体系统中的公平性审计和规范敏感对齐奠定了基础。"}}
{"id": "2505.12006", "title": "SOCIA: An End-to-End Agentic Framework for Automated Cyber-Physical-Social Simulator Generation", "authors": ["Yuncheng Hua", "Ji Miao", "Mehdi Jafari", "Jianxiang Xie", "Hao Xue", "Flora D. Salim"], "abstract": "This paper introduces SOCIA (Simulation Orchestration for Cyber-physical-social Intelligence and Agents), a novel end-to-end framework leveraging Large Language Model (LLM)-based multi-agent systems to automate the generation of high-fidelity Cyber-Physical-Social (CPS) simulators. Addressing the challenges of labor-intensive manual simulator development and complex data calibration, SOCIA integrates a centralized orchestration manager that coordinates specialized agents for tasks including data comprehension, code generation, simulation execution, and iterative evaluation-feedback loops. Through empirical evaluations across diverse CPS tasks, such as mask adoption behavior simulation (social), personal mobility generation (physical), and user modeling (cyber), SOCIA demonstrates its ability to produce high-fidelity, scalable simulations with reduced human intervention. These results highlight SOCIA's potential to offer a scalable solution for studying complex CPS phenomena", "subjects": "Artificial Intelligence (cs.AI)", "comments": "28 pages, 3 figures, 2 tables. The paper is under review", "pdf_url": "https://arxiv.org/pdf/2505.12006.pdf", "abstract_url": "https://arxiv.org/abs/2505.12006", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "SOCIA是一个利用大型语言模型（LLM）的多代理系统自动化生成高保真网络-物理-社会（CPS）模拟器的端到端框架。", "motivation": "解决手动开发模拟器劳动密集和复杂数据校准的挑战。", "method": "通过集中式编排管理器协调专门代理，执行数据理解、代码生成、模拟执行和迭代评估反馈循环等任务。", "result": "在多样化的CPS任务中，SOCIA展示了其能够以较少的人为干预生成高保真、可扩展的模拟。", "conclusion": "SOCIA为研究复杂的CPS现象提供了一个可扩展的解决方案。"}}
{"id": "2505.12321", "title": "BeliefNest: A Joint Action Simulator for Embodied Agents with Theory of Mind", "authors": ["Rikunari Sagara", "Koichiro Terao", "Naoto Iwahashi"], "abstract": "This paper introduces an open-source simulator, BeliefNest, designed to enable embodied agents to perform collaborative tasks by leveraging Theory of Mind. BeliefNest dynamically and hierarchically constructs simulators within a Minecraft environment, allowing agents to explicitly represent nested belief states about themselves and others. This enables agent control in open-domain tasks that require Theory of Mind reasoning. The simulator provides a prompt generation mechanism based on each belief state, facilitating the design and evaluation of methods for agent control utilizing large language models (LLMs). We demonstrate through experiments that agents can infer others' beliefs and predict their belief-based actions in false-belief tasks.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.12321.pdf", "abstract_url": "https://arxiv.org/abs/2505.12321", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一个名为BeliefNest的开源模拟器，旨在通过利用心智理论（Theory of Mind）使具身代理能够执行协作任务。BeliefNest在Minecraft环境中动态和分层地构建模拟器，使代理能够明确表示关于自己和他人的嵌套信念状态。", "motivation": "解决具身代理在需要心智理论推理的开放领域任务中进行协作的问题。", "method": "在Minecraft环境中动态和分层地构建模拟器，利用心智理论使代理能够表示嵌套信念状态，并提供基于每个信念状态的提示生成机制。", "result": "实验表明，代理能够推断他人的信念并预测他们基于信念的行为在错误信念任务中。", "conclusion": "BeliefNest模拟器为利用大型语言模型（LLMs）进行代理控制的方法设计和评估提供了便利，展示了代理在心智理论推理方面的潜力。"}}
{"id": "2505.12334", "title": "Enhancing User-Oriented Proactivity in Open-Domain Dialogues with Critic Guidance", "authors": ["Yufeng Wang", "Jinwu Hu", "Ziteng Huang", "Kunyang Lin", "Zitian Zhang", "Peihao Chen", "Yu Hu", "Qianyue Wang", "Zhuliang Yu", "Bin Sun", "Xiaofen Xing", "Qingfang Zheng", "Mingkui Tan"], "abstract": "Open-domain dialogue systems aim to generate natural and engaging conversations, providing significant practical value in real applications such as social robotics and personal assistants. The advent of large language models (LLMs) has greatly advanced this field by improving context understanding and conversational fluency. However, existing LLM-based dialogue systems often fall short in proactively understanding the user's chatting preferences and guiding conversations toward user-centered topics. This lack of user-oriented proactivity can lead users to feel unappreciated, reducing their satisfaction and willingness to continue the conversation in human-computer interactions. To address this issue, we propose a User-oriented Proactive Chatbot (UPC) to enhance the user-oriented proactivity. Specifically, we first construct a critic to evaluate this proactivity inspired by the LLM-as-a-judge strategy. Given the scarcity of high-quality training data, we then employ the critic to guide dialogues between the chatbot and user agents, generating a corpus with enhanced user-oriented proactivity. To ensure the diversity of the user backgrounds, we introduce the ISCO-800, a diverse user background dataset for constructing user agents. Moreover, considering the communication difficulty varies among users, we propose an iterative curriculum learning method that trains the chatbot from easy-to-communicate users to more challenging ones, thereby gradually enhancing its performance. Experiments demonstrate that our proposed training method is applicable to different LLMs, improving user-oriented proactivity and attractiveness in open-domain dialogues.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "9 pages, 7 figures", "pdf_url": "https://arxiv.org/pdf/2505.12334.pdf", "abstract_url": "https://arxiv.org/abs/2505.12334", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种用户导向的主动聊天机器人（UPC），通过构建批评家评估用户导向的主动性，并利用批评家指导对话生成高质量训练语料，结合ISCO-800多样化用户背景数据集和迭代课程学习方法，提升了开放域对话中的用户导向主动性和吸引力。", "motivation": "解决现有基于大型语言模型（LLMs）的对话系统在主动理解用户聊天偏好和引导对话向用户中心话题方面的不足，提升用户满意度和继续对话的意愿。", "method": "构建批评家评估用户导向的主动性，利用批评家指导对话生成训练语料；引入ISCO-800多样化用户背景数据集；提出迭代课程学习方法从易到难训练聊天机器人。", "result": "实验证明，所提出的训练方法适用于不同的LLMs，有效提升了开放域对话中的用户导向主动性和吸引力。", "conclusion": "通过批评家指导、多样化用户背景数据集和迭代课程学习，UPC显著提升了对话系统的用户导向主动性和用户体验，为开放域对话系统的发展提供了新方向。"}}
{"id": "2505.12370", "title": "Enhancing Visual Grounding for GUI Agents via Self-Evolutionary Reinforcement Learning", "authors": ["Xinbin Yuan", "Jian Zhang", "Kaixin Li", "Zhuoxuan Cai", "Lujian Yao", "Jie Chen", "Enguang Wang", "Qibin Hou", "Jinwei Chen", "Peng-Tao Jiang", "Bo Li"], "abstract": "Graphical User Interface (GUI) agents have made substantial strides in understanding and executing user instructions across diverse platforms. Yet, grounding these instructions to precise interface elements remains challenging, especially in complex, high-resolution, professional environments. Traditional supervised finetuning (SFT) methods often require large volumes of diverse data and exhibit weak generalization. To overcome these limitations, we introduce a reinforcement learning (RL) based framework that incorporates three core strategies: (1) seed data curation to ensure high quality training samples, (2) a dense policy gradient that provides continuous feedback based on prediction accuracy, and (3) a self evolutionary reinforcement finetuning mechanism that iteratively refines the model using attention maps. With only 3k training samples, our 7B-parameter model achieves state-of-the-art results among similarly sized models on three grounding benchmarks. Notably, it attains 47.3\\% accuracy on the ScreenSpot-Pro dataset, outperforming much larger models, such as UI-TARS-72B, by a margin of 24.2\\%. These findings underscore the effectiveness of RL-based approaches in enhancing GUI agent performance, particularly in high-resolution, complex environments.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.12370.pdf", "abstract_url": "https://arxiv.org/abs/2505.12370", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一种基于强化学习的框架，旨在提高图形用户界面（GUI）代理在复杂、高分辨率专业环境中对用户指令的视觉定位能力。通过种子数据筛选、密集策略梯度和自进化强化微调机制，该框架在仅有3k训练样本的情况下，使7B参数模型在三个定位基准上达到了同类模型中的最先进水平。", "motivation": "解决GUI代理在复杂、高分辨率专业环境中将用户指令精确地定位到界面元素的挑战，传统的有监督微调方法需要大量多样化数据且泛化能力弱。", "method": "采用强化学习框架，结合种子数据筛选、密集策略梯度和自进化强化微调机制，利用注意力图迭代优化模型。", "result": "在仅有3k训练样本的情况下，7B参数模型在三个定位基准上达到了最先进水平，特别是在ScreenSpot-Pro数据集上实现了47.3%的准确率，比UI-TARS-72B等更大模型高出24.2%。", "conclusion": "强化学习方法能有效提升GUI代理在复杂环境中的性能，尤其是在高分辨率、复杂环境下的视觉定位任务中。"}}
{"id": "2505.12493", "title": "UIShift: Enhancing VLM-based GUI Agents through Self-supervised Reinforcement Learning", "authors": ["Longxi Gao", "Li Zhang", "Mengwei Xu"], "abstract": "Training effective Vision Language Models (VLMs) for GUI agents typically relies on supervised fine-tuning (SFT) over large-scale annotated datasets, where the collection process is labor-intensive and error-prone. In this work, we propose a self-supervised inverse dynamics task to enable VLMs to learn from GUI transition pairs by inferring the action that caused that transition. This training task offers two advantages: (1) It enables VLMs to ignore variations unrelated to user actions (e.g., background refreshes, ads) and to focus on true affordances such as buttons and input fields within complex GUIs. (2) The training data can be easily obtained from existing GUI trajectories without requiring human annotation, and it can be easily scaled through automatic offline exploration. Using this training task, we propose UI-shift, a framework for enhancing VLM-based GUI agents through self-supervised reinforcement learning (RL). With only 2K training samples sourced from existing datasets, two VLMs -- Qwen2.5-VL-3B and Qwen2.5-VL-7B -- trained with UI-Shift achieve competitive or superior performance on grounding tasks (ScreenSpot-series benchmarks) and GUI automation tasks (AndroidControl), compared to SFT baselines and GUI-specific models that explicitly elicit reasoning abilities during RL. Our findings suggest a potential direction for enhancing VLMs for GUI agents by leveraging more self-supervised training data in the future.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.12493.pdf", "abstract_url": "https://arxiv.org/abs/2505.12493", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为UIShift的框架，通过自监督强化学习增强基于视觉语言模型（VLM）的GUI代理。该方法利用自监督的逆动力学任务，使VLM能够从GUI转换对中学习推断导致转换的动作，无需大规模标注数据集。", "motivation": "解决传统依赖大规模标注数据集进行监督微调（SFT）训练视觉语言模型（VLM）用于GUI代理时，数据收集过程劳动密集且易出错的问题。", "method": "提出自监督逆动力学任务，使VLM能够从GUI转换对中学习推断动作，忽略与用户操作无关的变化，专注于GUI中的真实可操作性元素。", "result": "仅使用2K来自现有数据集的训练样本，两个VLM模型（Qwen2.5-VL-3B和Qwen2.5-VL-7B）在基础任务（ScreenSpot系列基准）和GUI自动化任务（AndroidControl）上达到或超过SFT基线和专门设计用于GUI的模型的性能。", "conclusion": "研究结果表明，通过利用更多自监督训练数据，未来有可能进一步增强用于GUI代理的VLM。"}}
{"id": "2505.12501", "title": "ALAS: A Stateful Multi-LLM Agent Framework for Disruption-Aware Planning", "authors": ["Edward Y. Chang", "Longling Geng"], "abstract": "Large language models (LLMs) excel at rapid generation of text and multimodal content, yet they falter on transaction-style planning that demands ACID-like guarantees and real-time disruption recovery. We present Adaptive LLM Agent System (ALAS), a framework that tackles four fundamental LLM deficits: (i) absence of self-verification, (ii) context erosion, (iii) next-token myopia, and (iv) lack of persistent state. ALAS decomposes each plan into role-specialized agents, equips them with automatic state tracking, and coordinates them through a lightweight protocol. When disruptions arise, agents apply history-aware local compensation, avoiding costly global replanning and containing cascade effects. On real-world, large-scale job-shop scheduling benchmarks, ALAS sets new best results for static sequential planning and excels in dynamic reactive scenarios with unexpected disruptions. These gains show that principled modularization plus targeted compensation can unlock scalable and resilient planning with LLMs.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "36 pages, 10 figures, 19 tables", "pdf_url": "https://arxiv.org/pdf/2505.12501.pdf", "abstract_url": "https://arxiv.org/abs/2505.12501", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "ALAS是一个多LLM代理框架，用于解决LLM在需要ACID-like保证和实时中断恢复的事务式规划中的不足。", "motivation": "解决LLM在自我验证缺失、上下文侵蚀、下一个令牌短视和缺乏持久状态四个基本缺陷上的问题。", "method": "ALAS通过将每个计划分解为角色专用代理，配备自动状态跟踪，并通过轻量级协议协调它们。", "result": "在现实世界的大规模作业车间调度基准测试中，ALAS在静态顺序规划和动态反应场景中均取得了最佳结果。", "conclusion": "原则性模块化加上有针对性的补偿可以解锁LLM的可扩展和弹性规划。"}}
{"id": "2505.12731", "title": "Accelerating Adaptive Retrieval Augmented Generation via Instruction-Driven Representation Reduction of Retrieval Overlaps", "authors": ["Jie Ou", "Jinyu Guo", "Shuaihong Jiang", "Zhaokun Wang", "Libo Qin", "Shunyu Yao", "Wenhong Tian"], "abstract": "Retrieval-augmented generation (RAG) has emerged as a pivotal method for expanding the knowledge of large language models. To handle complex queries more effectively, researchers developed Adaptive-RAG (A-RAG) to enhance the generated quality through multiple interactions with external knowledge bases. Despite its effectiveness, A-RAG exacerbates the pre-existing efficiency challenges inherent in RAG, which are attributable to its reliance on multiple iterations of generation. Existing A-RAG approaches process all retrieved contents from scratch. However, they ignore the situation where there is a significant overlap in the content of the retrieval results across rounds. The overlapping content is redundantly represented, which leads to a large proportion of repeated computations, thus affecting the overall efficiency. To address this issue, this paper introduces a model-agnostic approach that can be generally applied to A-RAG methods, which is dedicated to reducing the redundant representation process caused by the overlapping of retrieval results. Specifically, we use cache access and parallel generation to speed up the prefilling and decoding stages respectively. Additionally, we also propose an instruction-driven module to further guide the model to more effectively attend to each part of the content in a more suitable way for LLMs. Experiments show that our approach achieves 2.79 and 2.33 times significant acceleration on average for prefilling and decoding respectively while maintaining equal generation quality.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.12731.pdf", "abstract_url": "https://arxiv.org/abs/2505.12731", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种模型无关的方法，用于减少自适应检索增强生成（A-RAG）中由于检索结果重叠导致的冗余表示过程，通过缓存访问和并行生成加速预填充和解码阶段，同时引入指令驱动模块指导模型更有效地处理内容，实验显示在保持生成质量的同时显著加速。", "motivation": "自适应检索增强生成（A-RAG）虽然提高了生成质量，但由于多轮检索结果内容重叠导致的冗余表示和重复计算，加剧了效率挑战。", "method": "提出一种模型无关的方法，利用缓存访问和并行生成加速预填充和解码阶段，并引入指令驱动模块优化模型对内容的处理方式。", "result": "实验结果表明，该方法在预填充和解码阶段分别实现了平均2.79和2.33倍的显著加速，同时保持了相同的生成质量。", "conclusion": "通过减少冗余表示和优化处理方式，该方法有效提升了A-RAG的效率，为处理复杂查询提供了更高效的解决方案。"}}
{"id": "2505.12788", "title": "Mixture Policy based Multi-Hop Reasoning over N-tuple Temporal Knowledge Graphs", "authors": ["Zhongni Hou", "Miao Su", "Xiaolong Jin", "Zixuan Li", "Long Bai", "Jiafeng Guo", "Xueqi Cheng"], "abstract": "Temporal Knowledge Graphs (TKGs), which utilize quadruples in the form of (subject, predicate, object, timestamp) to describe temporal facts, have attracted extensive attention. N-tuple TKGs (N-TKGs) further extend traditional TKGs by utilizing n-tuples to incorporate auxiliary elements alongside core elements (i.e., subject, predicate, and object) of facts, so as to represent them in a more fine-grained manner. Reasoning over N-TKGs aims to predict potential future facts based on historical ones. However, existing N-TKG reasoning methods often lack explainability due to their black-box nature. Therefore, we introduce a new Reinforcement Learning-based method, named MT-Path, which leverages the temporal information to traverse historical n-tuples and construct a temporal reasoning path. Specifically, in order to integrate the information encapsulated within n-tuples, i.e., the entity-irrelevant information within the predicate, the information about core elements, and the complete information about the entire n-tuples, MT-Path utilizes a mixture policy-driven action selector, which bases on three low-level policies, namely, the predicate-focused policy, the core-element-focused policy and the whole-fact-focused policy. Further, MT-Path utilizes an auxiliary element-aware GCN to capture the rich semantic dependencies among facts, thereby enabling the agent to gain a deep understanding of each n-tuple. Experimental results demonstrate the effectiveness and the explainability of MT-Path.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.12788.pdf", "abstract_url": "https://arxiv.org/abs/2505.12788", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一种名为MT-Path的基于强化学习的新方法，用于在N元组时间知识图（N-TKGs）上进行多跳推理，旨在预测潜在的未来事实。MT-Path通过利用时间信息遍历历史n元组并构建时间推理路径，提高了推理的可解释性。", "motivation": "解决现有N-TKG推理方法由于黑盒性质而缺乏可解释性的问题。", "method": "MT-Path采用基于三种低级策略（谓词聚焦策略、核心元素聚焦策略和全事实聚焦策略）的混合策略驱动动作选择器，以及辅助元素感知的GCN来捕获事实间丰富的语义依赖。", "result": "实验结果表明，MT-Path在有效性和可解释性方面表现出色。", "conclusion": "MT-Path不仅提高了N-TKG推理的准确性，还通过其可解释的推理路径增强了方法的透明度和可信度。"}}
{"id": "2505.12833", "title": "Reasoning BO: Enhancing Bayesian Optimization with Long-Context Reasoning Power of LLMs", "authors": ["Zhuo Yang", "Lingli Ge", "Dong Han", "Tianfan Fu", "Yuqiang Li"], "abstract": "Many real-world scientific and industrial applications require the optimization of expensive black-box functions. Bayesian Optimization (BO) provides an effective framework for such problems. However, traditional BO methods are prone to get trapped in local optima and often lack interpretable insights. To address this issue, this paper designs Reasoning BO, a novel framework that leverages reasoning models to guide the sampling process in BO while incorporating multi-agent systems and knowledge graphs for online knowledge accumulation. By integrating the reasoning and contextual understanding capabilities of Large Language Models (LLMs), we can provide strong guidance to enhance the BO process. As the optimization progresses, Reasoning BO provides real-time sampling recommendations along with critical insights grounded in plausible scientific theories, aiding in the discovery of superior solutions within the search space. We systematically evaluate our approach across 10 diverse tasks encompassing synthetic mathematical functions and complex real-world applications. The framework demonstrates its capability to progressively refine sampling strategies through real-time insights and hypothesis evolution, effectively identifying higher-performing regions of the search space for focused exploration. This process highlights the powerful reasoning and context-learning abilities of LLMs in optimization scenarios. For example, in the Direct Arylation task, our method increased the yield to 60.7%, whereas traditional BO achieved only a 25.2% yield. Furthermore, our investigation reveals that smaller LLMs, when fine-tuned through reinforcement learning, can attain comparable performance to their larger counterparts. This enhanced reasoning capability paves the way for more efficient automated scientific experimentation while maintaining computational feasibility.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.12833.pdf", "abstract_url": "https://arxiv.org/abs/2505.12833", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了Reasoning BO，一个新颖的框架，通过利用大型语言模型（LLMs）的推理和上下文理解能力，结合多智能体系统和知识图谱，来增强贝叶斯优化（BO）过程，从而在昂贵的黑盒函数优化中提供实时采样建议和科学理论依据，有效发现搜索空间中的更优解。", "motivation": "解决传统贝叶斯优化方法易陷入局部最优和缺乏可解释性洞察的问题。", "method": "设计Reasoning BO框架，整合LLMs的推理和上下文理解能力，结合多智能体系统和知识图谱进行在线知识积累。", "result": "在10个多样化任务中系统评估，包括合成数学函数和复杂现实应用，如在直接芳基化任务中将产率从25.2%提高到60.7%。", "conclusion": "展示了LLMs在优化场景中的强大推理和上下文学习能力，同时发现通过强化学习微调的较小LLMs可以达到与较大模型相当的性能，为更高效的自动化科学实验铺平了道路。"}}
{"id": "2505.12872", "title": "From Grunts to Grammar: Emergent Language from Cooperative Foraging", "authors": ["Maytus Piriyajitakonkij", "Rujikorn Charakorn", "Weicheng Tao", "Wei Pan", "Mingfei Sun", "Cheston Tan", "Mengmi Zhang"], "abstract": "Early cavemen relied on gestures, vocalizations, and simple signals to coordinate, plan, avoid predators, and share resources. Today, humans collaborate using complex languages to achieve remarkable results. What drives this evolution in communication? How does language emerge, adapt, and become vital for teamwork? Understanding the origins of language remains a challenge. A leading hypothesis in linguistics and anthropology posits that language evolved to meet the ecological and social demands of early human cooperation. Language did not arise in isolation, but through shared survival goals. Inspired by this view, we investigate the emergence of language in multi-agent Foraging Games. These environments are designed to reflect the cognitive and ecological constraints believed to have influenced the evolution of communication. Agents operate in a shared grid world with only partial knowledge about other agents and the environment, and must coordinate to complete games like picking up high-value targets or executing temporally ordered actions. Using end-to-end deep reinforcement learning, agents learn both actions and communication strategies from scratch. We find that agents develop communication protocols with hallmark features of natural language: arbitrariness, interchangeability, displacement, cultural transmission, and compositionality. We quantify each property and analyze how different factors, such as population size and temporal dependencies, shape specific aspects of the emergent language. Our framework serves as a platform for studying how language can evolve from partial observability, temporal reasoning, and cooperative goals in embodied multi-agent settings. We will release all data, code, and models publicly.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.12872.pdf", "abstract_url": "https://arxiv.org/abs/2505.12872", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文探讨了语言如何从早期的简单信号演变为复杂的交流系统，通过多智能体觅食游戏模拟语言 emergence，发现智能体发展的通信协议具有自然语言的特征。", "motivation": "研究语言起源和演变的驱动因素，特别是在合作和生存需求下的语言 emergence。", "method": "使用端到端深度强化学习在多智能体觅食游戏中模拟语言 emergence，智能体在部分可观察的环境中学习行动和通信策略。", "result": "智能体发展出具有自然语言特征的通信协议，包括任意性、互换性、位移性、文化传播和组合性。", "conclusion": "该框架为研究在部分可观察性、时间推理和合作目标下语言如何演变提供了平台，所有数据、代码和模型将公开。"}}
{"id": "2505.12923", "title": "The Traitors: Deception and Trust in Multi-Agent Language Model Simulations", "authors": ["Pedro M. P. Curvo"], "abstract": "As AI systems increasingly assume roles where trust and alignment with human values are essential, understanding when and why they engage in deception has become a critical research priority. We introduce The Traitors, a multi-agent simulation framework inspired by social deduction games, designed to probe deception, trust formation, and strategic communication among large language model (LLM) agents under asymmetric information. A minority of agents the traitors seek to mislead the majority, while the faithful must infer hidden identities through dialogue and reasoning. Our contributions are: (1) we ground the environment in formal frameworks from game theory, behavioral economics, and social cognition; (2) we develop a suite of evaluation metrics capturing deception success, trust dynamics, and collective inference quality; (3) we implement a fully autonomous simulation platform where LLMs reason over persistent memory and evolving social dynamics, with support for heterogeneous agent populations, specialized traits, and adaptive behaviors. Our initial experiments across DeepSeek-V3, GPT-4o-mini, and GPT-4o (10 runs per model) reveal a notable asymmetry: advanced models like GPT-4o demonstrate superior deceptive capabilities yet exhibit disproportionate vulnerability to others' falsehoods. This suggests deception skills may scale faster than detection abilities. Overall, The Traitors provides a focused, configurable testbed for investigating LLM behavior in socially nuanced interactions. We position this work as a contribution toward more rigorous research on deception mechanisms, alignment challenges, and the broader social reliability of AI systems.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "9 main pages, 31 pages", "pdf_url": "https://arxiv.org/pdf/2505.12923.pdf", "abstract_url": "https://arxiv.org/abs/2505.12923", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了'The Traitors'，一个受社交推理游戏启发的多智能体模拟框架，旨在探究大型语言模型（LLM）智能体在不对称信息下的欺骗、信任形成和战略沟通行为。", "motivation": "随着AI系统在需要信任和与人类价值观对齐的角色中越来越重要，理解它们何时及为何进行欺骗成为了一个关键的研究重点。", "method": "研究团队开发了一个多智能体模拟框架，结合了游戏理论、行为经济学和社会认知的正式框架，并实现了一个全自主的模拟平台，支持异构智能体群体、专门特质和适应性行为。", "result": "初步实验显示，如GPT-4o这样的高级模型展现出更优越的欺骗能力，但对他人谎言的脆弱性也更大，表明欺骗技能的提升速度可能快于检测能力。", "conclusion": "'The Traitors'为研究LLM在社交细微互动中的行为提供了一个集中、可配置的测试平台，有助于更严格地研究欺骗机制、对齐挑战及AI系统的社会可靠性。"}}
{"id": "2505.13044", "title": "CAIM: Development and Evaluation of a Cognitive AI Memory Framework for Long-Term Interaction with Intelligent Agents", "authors": ["Rebecca Westhäußer", "Frederik Berenz", "Wolfgang Minker", "Sebastian Zepf"], "abstract": "Large language models (LLMs) have advanced the field of artificial intelligence (AI) and are a powerful enabler for interactive systems. However, they still face challenges in long-term interactions that require adaptation towards the user as well as contextual knowledge and understanding of the ever-changing environment. To overcome these challenges, holistic memory modeling is required to efficiently retrieve and store relevant information across interaction sessions for suitable responses. Cognitive AI, which aims to simulate the human thought process in a computerized model, highlights interesting aspects, such as thoughts, memory mechanisms, and decision-making, that can contribute towards improved memory modeling for LLMs. Inspired by these cognitive AI principles, we propose our memory framework CAIM. CAIM consists of three modules: 1.) The Memory Controller as the central decision unit; 2.) the Memory Retrieval, which filters relevant data for interaction upon request; and 3.) the Post-Thinking, which maintains the memory storage. We compare CAIM against existing approaches, focusing on metrics such as retrieval accuracy, response correctness, contextual coherence, and memory storage. The results demonstrate that CAIM outperforms baseline frameworks across different metrics, highlighting its context-awareness and potential to improve long-term human-AI interactions.", "subjects": "Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.13044.pdf", "abstract_url": "https://arxiv.org/abs/2505.13044", "categories": ["Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为CAIM的认知AI记忆框架，旨在通过模拟人类思维过程来改善大型语言模型在长期交互中的表现。CAIM包含三个模块：记忆控制器、记忆检索和后思考，通过实验证明其在多个指标上优于现有方法。", "motivation": "大型语言模型在长期交互中面临适应性和上下文理解的挑战，需要有效的记忆建模来存储和检索相关信息。", "method": "受认知AI原则启发，提出了CAIM框架，包括记忆控制器、记忆检索和后思考三个模块，以模拟人类思维过程。", "result": "CAIM在检索准确性、响应正确性、上下文连贯性和记忆存储等指标上优于基线框架，显示出其上下文意识和改善长期人机交互的潜力。", "conclusion": "CAIM框架通过模拟人类认知过程，为大型语言模型提供了有效的记忆建模方法，有望改善长期人机交互的质量。"}}
{"id": "2505.13195", "title": "Adversarial Testing in LLMs: Insights into Decision-Making Vulnerabilities", "authors": ["Lili Zhang", "Haomiaomiao Wang", "Long Cheng", "Libao Deng", "Tomas Ward"], "abstract": "As Large Language Models (LLMs) become increasingly integrated into real-world decision-making systems, understanding their behavioural vulnerabilities remains a critical challenge for AI safety and alignment. While existing evaluation metrics focus primarily on reasoning accuracy or factual correctness, they often overlook whether LLMs are robust to adversarial manipulation or capable of using adaptive strategy in dynamic environments. This paper introduces an adversarial evaluation framework designed to systematically stress-test the decision-making processes of LLMs under interactive and adversarial conditions. Drawing on methodologies from cognitive psychology and game theory, our framework probes how models respond in two canonical tasks: the two-armed bandit task and the Multi-Round Trust Task. These tasks capture key aspects of exploration-exploitation trade-offs, social cooperation, and strategic flexibility. We apply this framework to several state-of-the-art LLMs, including GPT-3.5, GPT-4, Gemini-1.5, and DeepSeek-V3, revealing model-specific susceptibilities to manipulation and rigidity in strategy adaptation. Our findings highlight distinct behavioral patterns across models and emphasize the importance of adaptability and fairness recognition for trustworthy AI deployment. Rather than offering a performance benchmark, this work proposes a methodology for diagnosing decision-making weaknesses in LLM-based agents, providing actionable insights for alignment and safety research.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.13195.pdf", "abstract_url": "https://arxiv.org/abs/2505.13195", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一个对抗性评估框架，旨在系统性地压力测试大型语言模型（LLMs）在交互和对抗条件下的决策过程，揭示了模型在操纵和策略适应性方面的特定脆弱性。", "motivation": "随着大型语言模型（LLMs）越来越多地集成到现实世界的决策系统中，理解它们的行为脆弱性对于AI安全和对齐仍然是一个关键挑战。现有的评估指标主要关注推理准确性或事实正确性，往往忽视了LLMs是否能够抵抗对抗性操纵或在动态环境中使用适应性策略。", "method": "本文采用认知心理学和博弈论的方法论，设计了一个对抗性评估框架，通过两臂老虎机任务和多轮信任任务来测试模型的探索-利用权衡、社会合作和战略灵活性。", "result": "应用该框架对包括GPT-3.5、GPT-4、Gemini-1.5和DeepSeek-V3在内的几种最先进的LLMs进行测试，揭示了模型在操纵和策略适应性方面的特定脆弱性，并强调了适应性和公平性识别对于可信AI部署的重要性。", "conclusion": "本研究不仅提供了一种诊断LLM基于代理的决策弱点的方法论，还为对齐和安全研究提供了可操作的见解，强调了在LLMs部署中考虑行为脆弱性的必要性。"}}
{"id": "2505.13246", "title": "Agentic Publications: An LLM-Driven Framework for Interactive Scientific Publishing, Supplementing Traditional Papers with AI-Powered Knowledge Systems", "authors": ["Roberto Pugliese", "George Kourousias", "Francesco Venier", "Grazia Garlatti Costa"], "abstract": "The exponential growth of scientific literature presents significant challenges for researchers navigating the complex knowledge landscape. We propose \"Agentic Publications\", a novel LLM-driven framework complementing traditional publishing by transforming papers into interactive knowledge systems. Our architecture integrates structured data with unstructured content through retrieval-augmented generation and multi-agent verification. The framework offers interfaces for both humans and machines, combining narrative explanations with machine-readable outputs while addressing ethical considerations through automated validation and transparent governance. Key features include continuous knowledge updates, automatic integration of new findings, and customizable detail levels. Our proof-of-concept demonstrates multilingual interaction, API accessibility, and structured knowledge representation through vector databases, knowledge graphs, and verification agents. This approach enhances scientific communication across disciplines, improving efficiency and collaboration while preserving traditional publishing pathways, particularly valuable for interdisciplinary fields where knowledge integration remains challenging.", "subjects": "Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.13246.pdf", "abstract_url": "https://arxiv.org/abs/2505.13246", "categories": ["Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种名为'Agentic Publications'的新型LLM驱动框架，旨在通过将传统论文转化为交互式知识系统来补充传统出版方式。该框架结合了检索增强生成和多代理验证技术，提供了人类和机器均可使用的接口，同时通过自动验证和透明治理解决伦理问题。", "motivation": "科学文献的指数增长给研究人员在复杂的知识景观中导航带来了重大挑战。本文旨在解决这一问题，通过提供一个交互式知识系统来增强科学交流的效率与合作。", "method": "该框架通过检索增强生成和多代理验证技术，将结构化数据与非结构化内容整合，提供人类和机器均可使用的接口，并实现知识的持续更新和新发现的自动整合。", "result": "概念验证展示了多语言交互、API可访问性以及通过向量数据库、知识图和验证代理实现的结构化知识表示。", "conclusion": "这种方法不仅提高了跨学科科学交流的效率和合作，还保留了传统出版途径，特别适用于知识整合仍具挑战性的跨学科领域。"}}
{"id": "2505.13400", "title": "Robin: A multi-agent system for automating scientific discovery", "authors": ["Ali Essam Ghareeb", "Benjamin Chang", "Ludovico Mitchener", "Angela Yiu", "Caralyn J. Szostkiewicz", "Jon M. Laurent", "Muhammed T. Razzak", "Andrew D. White", "Michaela M. Hinks", "Samuel G. Rodriques"], "abstract": "Scientific discovery is driven by the iterative process of background research, hypothesis generation, experimentation, and data analysis. Despite recent advancements in applying artificial intelligence to scientific discovery, no system has yet automated all of these stages in a single workflow. Here, we introduce Robin, the first multi-agent system capable of fully automating the key intellectual steps of the scientific process. By integrating literature search agents with data analysis agents, Robin can generate hypotheses, propose experiments, interpret experimental results, and generate updated hypotheses, achieving a semi-autonomous approach to scientific discovery. By applying this system, we were able to identify a novel treatment for dry age-related macular degeneration (dAMD), the major cause of blindness in the developed world. Robin proposed enhancing retinal pigment epithelium phagocytosis as a therapeutic strategy, and identified and validated a promising therapeutic candidate, ripasudil. Ripasudil is a clinically-used rho kinase (ROCK) inhibitor that has never previously been proposed for treating dAMD. To elucidate the mechanism of ripasudil-induced upregulation of phagocytosis, Robin then proposed and analyzed a follow-up RNA-seq experiment, which revealed upregulation of ABCA1, a critical lipid efflux pump and possible novel target. All hypotheses, experimental plans, data analyses, and data figures in the main text of this report were produced by Robin. As the first AI system to autonomously discover and validate a novel therapeutic candidate within an iterative lab-in-the-loop framework, Robin establishes a new paradigm for AI-driven scientific discovery.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA); Quantitative Methods (q-bio.QM)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.13400.pdf", "abstract_url": "https://arxiv.org/abs/2505.13400", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)", "Quantitative Methods (q-bio.QM)"], "matching_keywords": ["agent"], "AI": {"tldr": "Robin是一个多智能体系统，能够完全自动化科学发现的关键智力步骤，包括生成假设、提出实验、解释实验结果和更新假设，成功识别出一种治疗干性年龄相关性黄斑变性的新方法。", "motivation": "尽管人工智能在科学发现中的应用有所进展，但尚未有系统能在单一工作流程中自动化所有科学发现阶段。Robin旨在填补这一空白。", "method": "通过整合文献搜索智能体和数据分析智能体，Robin实现了科学发现的关键步骤的自动化，采用半自主的方法进行科学探索。", "result": "Robin成功识别并验证了一种治疗干性年龄相关性黄斑变性的新候选药物ripasudil，并通过RNA-seq实验揭示了其作用机制。", "conclusion": "Robin作为首个在迭代实验室循环框架内自主发现并验证新治疗候选物的AI系统，为AI驱动的科学发现建立了新范式。"}}
{"id": "2505.11548", "title": "One Shot Dominance: Knowledge Poisoning Attack on Retrieval-Augmented Generation Systems", "authors": ["Zhiyuan Chang", "Xiaojun Jia", "Mingyang Li", "Junjie Wang", "Yuekai Huang", "Qing Wang", "Ziyou Jiang", "Yang Liu"], "abstract": "Large Language Models (LLMs) enhanced with Retrieval-Augmented Generation (RAG) have shown improved performance in generating accurate responses. However, the dependence on external knowledge bases introduces potential security vulnerabilities, particularly when these knowledge bases are publicly accessible and modifiable. Poisoning attacks on knowledge bases for RAG systems face two fundamental challenges: the injected malicious content must compete with multiple authentic documents retrieved by the retriever, and LLMs tend to trust retrieved information that aligns with their internal memorized knowledge. Previous works attempt to address these challenges by injecting multiple malicious documents, but such saturation attacks are easily detectable and impractical in real-world scenarios. To enable the effective single document poisoning attack, we propose AuthChain, a novel knowledge poisoning attack method that leverages Chain-of-Evidence theory and authority effect to craft more convincing poisoned documents. AuthChain generates poisoned content that establishes strong evidence chains and incorporates authoritative statements, effectively overcoming the interference from both authentic documents and LLMs' internal knowledge. Extensive experiments across six popular LLMs demonstrate that AuthChain achieves significantly higher attack success rates while maintaining superior stealthiness against RAG defense mechanisms compared to state-of-the-art baselines.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": "15pages, 4 figures", "pdf_url": "https://arxiv.org/pdf/2505.11548.pdf", "abstract_url": "https://arxiv.org/abs/2505.11548", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种名为AuthChain的新型知识毒化攻击方法，针对检索增强生成（RAG）系统，通过利用证据链理论和权威效应，制作更具说服力的毒化文档，有效克服了真实文档和大型语言模型（LLMs）内部知识的干扰。", "motivation": "检索增强生成（RAG）系统依赖外部知识库以提高生成准确回答的性能，但这种依赖性引入了安全漏洞，尤其是当知识库公开可访问和修改时。现有的毒化攻击方法需要注入多个恶意文档，不仅容易被检测，而且在实际场景中不实用。", "method": "AuthChain方法结合了Chain-of-Evidence理论和权威效应，制作出能够建立强证据链并包含权威声明的毒化内容，从而有效提高攻击成功率并保持对RAG防御机制的高隐蔽性。", "result": "在六种流行的大型语言模型上的广泛实验表明，AuthChain相比现有基线方法，实现了显著更高的攻击成功率，同时保持了更高的隐蔽性。", "conclusion": "AuthChain为单文档毒化攻击提供了一种有效且隐蔽的方法，揭示了RAG系统在面对精心设计的毒化攻击时的脆弱性，强调了加强系统安全防御的必要性。"}}
{"id": "2505.11601", "title": "Continuous Optimization for Feature Selection with Permutation-Invariant Embedding and Policy-Guided Search", "authors": ["Rui Liu", "Rui Xie", "Zijun Yao", "Yanjie Fu", "Dongjie Wang"], "abstract": "Feature selection removes redundant features to enhanc performance and computational efficiency in downstream tasks. Existing works often struggle to capture complex feature interactions and adapt to diverse scenarios. Recent advances in this domain have incorporated generative intelligence to address these drawbacks by uncovering intricate relationships between features. However, two key limitations remain: 1) embedding feature subsets in a continuous space is challenging due to permutation sensitivity, as changes in feature order can introduce biases and weaken the embedding learning process; 2) gradient-based search in the embedding space assumes convexity, which is rarely guaranteed, leading to reduced search effectiveness and suboptimal subsets. To address these limitations, we propose a new framework that can: 1) preserve feature subset knowledge in a continuous embedding space while ensuring permutation invariance; 2) effectively explore the embedding space without relying on strong convex assumptions. For the first objective, we develop an encoder-decoder paradigm to preserve feature selection knowledge into a continuous embedding space. This paradigm captures feature interactions through pairwise relationships within the subset, removing the influence of feature order on the embedding. Moreover, an inducing point mechanism is introduced to accelerate pairwise relationship computations. For the second objective, we employ a policy-based reinforcement learning (RL) approach to guide the exploration of the embedding space. The RL agent effectively navigates the space by balancing multiple objectives. By prioritizing high-potential regions adaptively and eliminating the reliance on convexity assumptions, the RL agent effectively reduces the risk of converging to local optima. Extensive experiments demonstrate the effectiveness, efficiency, robustness and explicitness of our model.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "KDD 2025", "pdf_url": "https://arxiv.org/pdf/2505.11601.pdf", "abstract_url": "https://arxiv.org/abs/2505.11601", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新的特征选择框架，通过排列不变嵌入和策略引导搜索解决现有方法在捕捉复杂特征交互和适应多样场景方面的不足。", "motivation": "现有特征选择方法难以捕捉复杂的特征交互和适应多样场景，且在连续空间中嵌入特征子集时面临排列敏感性和梯度搜索的凸性假设问题。", "method": "采用编码器-解码器范式实现排列不变的特征子集嵌入，并引入诱导点机制加速成对关系计算；使用基于策略的强化学习方法引导嵌入空间的探索。", "result": "大量实验证明，该模型在有效性、效率、鲁棒性和明确性方面表现出色。", "conclusion": "所提出的框架不仅保留了特征子集知识，还通过强化学习有效探索了嵌入空间，减少了陷入局部最优的风险。"}}
{"id": "2505.11579", "title": "Toward Adaptive Categories: Dimensional Governance for Agentic AI", "authors": ["Zeynep Engin", "David Hand"], "abstract": "As AI systems evolve from static tools to dynamic agents, traditional categorical governance frameworks -- based on fixed risk tiers, levels of autonomy, or human oversight models -- are increasingly insufficient on their own. Systems built on foundation models, self-supervised learning, and multi-agent architectures increasingly blur the boundaries that categories were designed to police. In this Perspective, we make the case for dimensional governance: a framework that tracks how decision authority, process autonomy, and accountability (the 3As) distribute dynamically across human-AI relationships. A critical advantage of this approach is its ability to explicitly monitor system movement toward and across key governance thresholds, enabling preemptive adjustments before risks materialize. This dimensional approach provides the necessary foundation for more adaptive categorization, enabling thresholds and classifications that can evolve with emerging capabilities. While categories remain essential for decision-making, building them upon dimensional foundations allows for context-specific adaptability and stakeholder-responsive governance that static approaches cannot achieve. We outline key dimensions, critical trust thresholds, and practical examples illustrating where rigid categorical frameworks fail -- and where a dimensional mindset could offer a more resilient and future-proof path forward for both governance and innovation at the frontier of artificial intelligence.", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG); Multiagent Systems (cs.MA)", "comments": "12 pages core text, 14 pages including references, 2 figures", "pdf_url": "https://arxiv.org/pdf/2505.11579.pdf", "abstract_url": "https://arxiv.org/abs/2505.11579", "categories": ["Computers and Society (cs.CY)", "Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种名为‘维度治理’的新框架，旨在解决传统基于固定风险等级、自主水平或人类监督模型的分类治理框架在处理动态AI代理时的不足。通过跟踪决策权威、过程自主性和问责制（3A）在人类-AI关系中的动态分布，该框架能够预先调整以防止风险发生，为更适应性强的分类提供基础。", "motivation": "随着AI系统从静态工具发展为动态代理，传统的分类治理框架在处理基于基础模型、自监督学习和多代理架构的系统时显得不足，因为这些系统模糊了分类旨在监管的界限。", "method": "提出了维度治理框架，重点关注决策权威、过程自主性和问责制（3A）的动态分布，以及如何监控系统向关键治理阈值的移动，从而实现预防性调整。", "result": "维度治理框架为适应性分类提供了基础，允许阈值和分类随新兴能力而演变，同时保持了分类在决策中的重要性，但增加了上下文特定的适应性和对利益相关者响应的治理能力。", "conclusion": "维度治理为AI治理和创新提供了一条更具弹性和未来证明的路径，通过超越静态分类框架，实现了对动态AI代理更有效的监管。"}}
{"id": "2505.11642", "title": "PeerGuard: Defending Multi-Agent Systems Against Backdoor Attacks Through Mutual Reasoning", "authors": ["Falong Fan", "Xi Li"], "abstract": "Multi-agent systems leverage advanced AI models as autonomous agents that interact, cooperate, or compete to complete complex tasks across applications such as robotics and traffic management. Despite their growing importance, safety in multi-agent systems remains largely underexplored, with most research focusing on single AI models rather than interacting agents. This work investigates backdoor vulnerabilities in multi-agent systems and proposes a defense mechanism based on agent interactions. By leveraging reasoning abilities, each agent evaluates responses from others to detect illogical reasoning processes, which indicate poisoned agents. Experiments on LLM-based multi-agent systems, including ChatGPT series and Llama 3, demonstrate the effectiveness of the proposed method, achieving high accuracy in identifying poisoned agents while minimizing false positives on clean agents. We believe this work provides insights into multi-agent system safety and contributes to the development of robust, trustworthy AI interactions.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.11642.pdf", "abstract_url": "https://arxiv.org/abs/2505.11642", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "PeerGuard：通过相互推理防御多智能体系统中的后门攻击", "motivation": "多智能体系统在机器人学和交通管理等应用中越来越重要，但其安全性研究不足，尤其是针对交互智能体的后门攻击。", "method": "提出了一种基于智能体交互的防御机制，利用每个智能体的推理能力评估其他智能体的响应，以检测异常推理过程。", "result": "在基于LLM的多智能体系统（包括ChatGPT系列和Llama 3）上的实验表明，该方法能有效识别被攻击的智能体，同时减少对干净智能体的误报。", "conclusion": "这项工作为多智能体系统的安全性提供了新的见解，有助于开发更健壮、可信的AI交互。"}}
{"id": "2505.11765", "title": "OMAC: A Broad Optimization Framework for LLM-Based Multi-Agent Collaboration", "authors": ["Shijun Li", "Hilaf Hasson", "Joydeep Ghosh"], "abstract": "Agents powered by advanced large language models (LLMs) have demonstrated impressive capabilities across diverse complex applications. Recently, Multi-Agent Systems (MAS), wherein multiple agents collaborate and communicate with each other, have exhibited enhanced capabilities in complex tasks, such as high-quality code generation and arithmetic reasoning. However, the development of such systems often relies on handcrafted methods, and the literature on systematic design and optimization of LLM-based MAS remains limited.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.11765.pdf", "abstract_url": "https://arxiv.org/abs/2505.11765", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "OMAC是一个为基于大型语言模型（LLM）的多智能体协作设计的广泛优化框架，旨在解决多智能体系统（MAS）在复杂任务中开发和优化的系统性不足。", "motivation": "尽管基于先进大型语言模型的智能体在多样化的复杂应用中展示了令人印象深刻的能力，且多智能体系统在复杂任务中表现出增强的能力，但这些系统的开发往往依赖于手工方法，关于系统性设计和优化LLM-based MAS的文献仍然有限。", "method": "提出了OMAC框架，这是一个为LLM-based多智能体协作设计的广泛优化框架。", "result": "通过OMAC框架，可以系统地设计和优化基于LLM的多智能体系统，从而在复杂任务中实现更高的效率和效果。", "conclusion": "OMAC框架为LLM-based多智能体系统的开发和优化提供了一个系统性的解决方案，有望推动多智能体协作在复杂任务中的应用和发展。"}}
{"id": "2505.11864", "title": "Learning Pareto-Optimal Rewards from Noisy Preferences: A Framework for Multi-Objective Inverse Reinforcement Learning", "authors": ["Kalyan Cherukuri", "Aarav Lala"], "abstract": "As generative agents become increasingly capable, alignment of their behavior with complex human values remains a fundamental challenge. Existing approaches often simplify human intent through reduction to a scalar reward, overlooking the multi-faceted nature of human feedback. In this work, we introduce a theoretical framework for preference-based Multi-Objective Inverse Reinforcement Learning (MO-IRL), where human preferences are modeled as latent vector-valued reward functions. We formalize the problem of recovering a Pareto-optimal reward representation from noisy preference queries and establish conditions for identifying the underlying multi-objective structure. We derive tight sample complexity bounds for recovering $\\epsilon$-approximations of the Pareto front and introduce a regret formulation to quantify suboptimality in this multi-objective setting. Furthermore, we propose a provably convergent algorithm for policy optimization using preference-inferred reward cones. Our results bridge the gap between practical alignment techniques and theoretical guarantees, providing a principled foundation for learning aligned behaviors in a high-dimension and value-pluralistic environment.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computational Geometry (cs.CG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.11864.pdf", "abstract_url": "https://arxiv.org/abs/2505.11864", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computational Geometry (cs.CG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一个基于偏好的多目标逆向强化学习（MO-IRL）的理论框架，旨在从嘈杂的偏好查询中恢复帕累托最优奖励表示，并建立了识别底层多目标结构的条件。", "motivation": "随着生成代理的能力不断增强，如何使其行为与复杂的人类价值观对齐仍然是一个基本挑战。现有方法通常通过简化为标量奖励来简化人类意图，忽视了人类反馈的多面性。", "method": "引入了一个理论框架，将人类偏好建模为潜在的向量值奖励函数，并提出了一个可证明收敛的策略优化算法，使用偏好推断的奖励锥。", "result": "为恢复帕累托前沿的ε近似值建立了紧密的样本复杂度界限，并引入了一个遗憾公式来量化这种多目标设置中的次优性。", "conclusion": "我们的结果在实践对齐技术和理论保证之间架起了桥梁，为在高维和价值多元环境中学习对齐行为提供了原则性基础。"}}
{"id": "2505.11912", "title": "Modèles de Substitution pour les Modèles à base d'Agents : Enjeux, Méthodes et Applications", "authors": ["Paul Saves", "Nicolas Verstaevel", "Benoît Gaudou"], "abstract": "Multi-agent simulations enables the modeling and analyses of the dynamic behaviors and interactions of autonomous entities evolving in complex environments. Agent-based models (ABM) are widely used to study emergent phenomena arising from local interactions. However, their high computational cost poses a significant challenge, particularly for large-scale simulations requiring extensive parameter exploration, optimization, or uncertainty quantification. The increasing complexity of ABM limits their feasibility for real-time decision-making and large-scale scenario analysis. To address these limitations, surrogate models offer an efficient alternative by learning approximations from sparse simulation data. These models provide cheap-to-evaluate predictions, significantly reducing computational costs while maintaining accuracy. Various machine learning techniques, including regression models, neural networks, random forests and Gaussian processes, have been applied to construct robust surrogates. Moreover, uncertainty quantification and sensitivity analysis play a crucial role in enhancing model reliability and interpretability.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "12 pages, in French language. Les 33èmes Journées Francophones sur les Systèmes Multi-Agents (JFSMA 2025). 2025", "pdf_url": "https://arxiv.org/pdf/2505.11912.pdf", "abstract_url": "https://arxiv.org/abs/2505.11912", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "代理模型在基于代理的模型中的应用：挑战、方法与用途", "motivation": "基于代理的模型（ABM）在模拟复杂环境中自主实体的动态行为和交互时，计算成本高，限制了其在大规模模拟、实时决策和大规模场景分析中的可行性。", "method": "通过从稀疏的模拟数据中学习近似，使用替代模型（如回归模型、神经网络、随机森林和高斯过程）来提供成本低且准确的预测。", "result": "替代模型显著降低了计算成本，同时保持了准确性，并通过不确定性量化和敏感性分析增强了模型的可靠性和可解释性。", "conclusion": "替代模型为解决基于代理的模型的高计算成本问题提供了有效方法，使其在大规模模拟和实时决策中更加可行。"}}
{"id": "2505.11946", "title": "Let's have a chat with the EU AI Act", "authors": ["Adam Kovari", "Yasin Ghafourian", "Csaba Hegedus", "Belal Abu Naim", "Kitti Mezei", "Pal Varga", "Markus Tauber"], "abstract": "As artificial intelligence (AI) regulations evolve and the regulatory landscape develops and becomes more complex, ensuring compliance with ethical guidelines and legal frameworks remains a challenge for AI developers. This paper introduces an AI-driven self-assessment chatbot designed to assist users in navigating the European Union AI Act and related standards. Leveraging a Retrieval-Augmented Generation (RAG) framework, the chatbot enables real-time, context-aware compliance verification by retrieving relevant regulatory texts and providing tailored guidance. By integrating both public and proprietary standards, it streamlines regulatory adherence, reduces complexity, and fosters responsible AI development. The paper explores the chatbot's architecture, comparing naive and graph-based RAG models, and discusses its potential impact on AI governance.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Digital Libraries (cs.DL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.11946.pdf", "abstract_url": "https://arxiv.org/abs/2505.11946", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)", "Digital Libraries (cs.DL)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了一个基于AI的自评估聊天机器人，旨在帮助用户理解和遵守欧盟AI法案及相关标准。通过采用检索增强生成（RAG）框架，该聊天机器人能够实时提供上下文相关的合规性验证，简化法规遵从过程，促进负责任的AI发展。", "motivation": "随着AI法规的演变和监管环境的复杂化，确保符合伦理指南和法律框架对AI开发者来说是一个挑战。", "method": "利用检索增强生成（RAG）框架，开发了一个能够检索相关法规文本并提供定制指导的聊天机器人。", "result": "该聊天机器人通过整合公共和专有标准，简化了法规遵从过程，降低了复杂性，并促进了负责任的AI开发。", "conclusion": "该聊天机器人有潜力对AI治理产生积极影响，通过提供实时的、上下文相关的合规性验证，帮助开发者更好地理解和遵守复杂的AI法规。"}}
{"id": "2505.11963", "title": "MARVEL: Multi-Agent RTL Vulnerability Extraction using Large Language Models", "authors": ["Luca Collini", "Baleegh Ahmad", "Joey Ah-kiow", "Ramesh Karri"], "abstract": "Hardware security verification is a challenging and time-consuming task. For this purpose, design engineers may utilize tools such as formal verification, linters, and functional simulation tests, coupled with analysis and a deep understanding of the hardware design being inspected. Large Language Models (LLMs) have been used to assist during this task, either directly or in conjunction with existing tools. We improve the state of the art by proposing MARVEL, a multi-agent LLM framework for a unified approach to decision-making, tool use, and reasoning. MARVEL mimics the cognitive process of a designer looking for security vulnerabilities in RTL code. It consists of a supervisor agent that devises the security policy of the system-on-chips (SoCs) using its security documentation. It delegates tasks to validate the security policy to individual executor agents. Each executor agent carries out its assigned task using a particular strategy. Each executor agent may use one or more tools to identify potential security bugs in the design and send the results back to the supervisor agent for further analysis and confirmation. MARVEL includes executor agents that leverage formal tools, linters, simulation tests, LLM-based detection schemes, and static analysis-based checks. We test our approach on a known buggy SoC based on OpenTitan from the Hack@DATE competition. We find that 20 of the 48 issues reported by MARVEL pose security vulnerabilities.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": "Submitted for Peer Review", "pdf_url": "https://arxiv.org/pdf/2505.11963.pdf", "abstract_url": "https://arxiv.org/abs/2505.11963", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "MARVEL是一个基于大型语言模型的多代理框架，用于从RTL代码中提取安全漏洞，模拟设计师寻找安全漏洞的认知过程。", "motivation": "硬件安全验证是一项具有挑战性且耗时的任务，现有的工具和方法需要设计工程师的深入理解和分析。", "method": "MARVEL采用多代理LLM框架，包括一个监督代理和多个执行代理，监督代理制定安全策略，执行代理使用不同策略和工具验证策略。", "result": "在基于OpenTitan的已知有缺陷SoC上测试，MARVEL报告的48个问题中有20个是安全漏洞。", "conclusion": "MARVEL通过多代理LLM框架有效提高了硬件安全验证的效率和准确性，为设计工程师提供了强大的辅助工具。"}}
{"id": "2505.12188", "title": "LLM-DSE: Searching Accelerator Parameters with LLM Agents", "authors": ["Hanyu Wang", "Xinrui Wu", "Zijian Ding", "Su Zheng", "Chengyue Wang", "Tony Nowatzki", "Yizhou Sun", "Jason Cong"], "abstract": "Even though high-level synthesis (HLS) tools mitigate the challenges of programming domain-specific accelerators (DSAs) by raising the abstraction level, optimizing hardware directive parameters remains a significant hurdle. Existing heuristic and learning-based methods struggle with adaptability and sample", "subjects": "Hardware Architecture (cs.AR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.12188.pdf", "abstract_url": "https://arxiv.org/abs/2505.12188", "categories": ["Hardware Architecture (cs.AR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为LLM-DSE的方法，利用大型语言模型（LLM）代理来搜索加速器参数，以解决高级综合（HLS）工具在优化硬件指令参数时面临的挑战。", "motivation": "尽管高级综合（HLS）工具通过提高抽象级别缓解了编程领域特定加速器（DSAs）的挑战，但优化硬件指令参数仍然是一个重大障碍。现有的启发式和基于学习的方法在适应性和样本效率方面存在不足。", "method": "LLM-DSE方法利用大型语言模型（LLM）代理来搜索和优化加速器参数，以提高参数优化的效率和效果。", "result": "通过使用LLM代理，LLM-DSE方法能够更有效地搜索和优化加速器参数，克服了现有方法在适应性和样本效率方面的限制。", "conclusion": "LLM-DSE方法为加速器参数优化提供了一种新的、更有效的途径，有望在高级综合和领域特定加速器设计领域产生重要影响。"}}
{"id": "2505.12327", "title": "Robust Planning for Autonomous Driving via Mixed Adversarial Diffusion Predictions", "authors": ["Albert Zhao", "Stefano Soatto"], "abstract": "We describe a robust planning method for autonomous driving that mixes normal and adversarial agent predictions output by a diffusion model trained for motion prediction. We first train a diffusion model to learn an unbiased distribution of normal agent behaviors. We then generate a distribution of adversarial predictions by biasing the diffusion model at test time to generate predictions that are likely to collide with a candidate plan. We score plans using expected cost with respect to a mixture distribution of normal and adversarial predictions, leading to a planner that is robust against adversarial behaviors but not overly conservative when agents behave normally. Unlike current approaches, we do not use risk measures that over-weight adversarial behaviors while placing little to no weight on low-cost normal behaviors or use hard safety constraints that may not be appropriate for all driving scenarios. We show the effectiveness of our method on single-agent and multi-agent jaywalking scenarios as well as a red light violation scenario.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "IEEE International Conference on Robotics and Automation (ICRA) 2025", "pdf_url": "https://arxiv.org/pdf/2505.12327.pdf", "abstract_url": "https://arxiv.org/abs/2505.12327", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种通过混合正常和对抗性代理预测的扩散模型来实现自动驾驶的鲁棒规划方法。该方法通过训练扩散模型学习正常代理行为的无偏分布，并在测试时生成可能碰撞的对抗性预测，从而在不过度保守的情况下提高规划的鲁棒性。", "motivation": "解决自动驾驶规划中对抗性行为导致的过度保守或忽视正常低成本行为的问题。", "method": "使用扩散模型学习正常代理行为的分布，并在测试时生成对抗性预测，通过混合分布评分候选计划。", "result": "在单代理和多代理的乱穿马路场景以及红灯违规场景中验证了方法的有效性。", "conclusion": "提出的方法在不牺牲正常行为效率的前提下，提高了自动驾驶规划对抗对抗性行为的鲁棒性。"}}
{"id": "2505.12247", "title": "LAMeTA: Intent-Aware Agentic Network Optimization via a Large AI Model-Empowered Two-Stage Approach", "authors": ["Yinqiu Liu", "Guangyuan Liu", "Jiacheng Wang", "Ruichen Zhang", "Dusit Niyato", "Geng Sun", "Zehui Xiong", "Zhu Han"], "abstract": "Nowadays, Generative AI (GenAI) reshapes numerous domains by enabling machines to create content across modalities. As GenAI evolves into autonomous agents capable of reasoning, collaboration, and interaction, they are increasingly deployed on network infrastructures to serve humans automatically. This emerging paradigm, known as the agentic network, presents new optimization challenges due to the demand to incorporate subjective intents of human users expressed in natural language. Traditional generic Deep Reinforcement Learning (DRL) struggles to capture intent semantics and adjust policies dynamically, thus leading to suboptimality. In this paper, we present LAMeTA, a Large AI Model (LAM)-empowered Two-stage Approach for intent-aware agentic network optimization. First, we propose Intent-oriented Knowledge Distillation (IoKD), which efficiently distills intent-understanding capabilities from resource-intensive LAMs to lightweight edge LAMs (E-LAMs) to serve end users. Second, we develop Symbiotic Reinforcement Learning (SRL), integrating E-LAMs with a policy-based DRL framework. In SRL, E-LAMs translate natural language user intents into structured preference vectors that guide both state representation and reward design. The DRL, in turn, optimizes the generative service function chain composition and E-LAM selection based on real-time network conditions, thus optimizing the subjective Quality-of-Experience (QoE). Extensive experiments conducted in an agentic network with 81 agents demonstrate that IoKD reduces mean squared error in intent prediction by up to 22.5%, while SRL outperforms conventional generic DRL by up to 23.5% in maximizing intent-aware QoE.", "subjects": "Networking and Internet Architecture (cs.NI); Artificial Intelligence (cs.AI)", "comments": "13 pages", "pdf_url": "https://arxiv.org/pdf/2505.12247.pdf", "abstract_url": "https://arxiv.org/abs/2505.12247", "categories": ["Networking and Internet Architecture (cs.NI)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "LAMeTA提出了一种基于大型AI模型的两阶段方法，用于意图感知的代理网络优化，通过意图导向的知识蒸馏和共生强化学习，有效提升了用户体验质量。", "motivation": "生成式AI（GenAI）发展为能够推理、协作和交互的自主代理，部署在网络基础设施上以自动服务人类。这种新兴的代理网络范式由于需要融入用户用自然语言表达的主观意图，带来了新的优化挑战。传统的深度强化学习（DRL）难以捕捉意图语义并动态调整策略，导致次优。", "method": "LAMeTA采用两阶段方法：1) 意图导向的知识蒸馏（IoKD），从资源密集型的大型AI模型（LAM）中高效提炼意图理解能力到轻量级边缘LAM（E-LAM）；2) 共生强化学习（SRL），将E-LAM与基于策略的DRL框架集成，E-LAM将自然语言用户意图翻译为结构化偏好向量，指导状态表示和奖励设计。", "result": "在81个代理的代理网络中进行的大量实验表明，IoKD在意图预测中的均方误差降低了高达22.5%，而SRL在最大化意图感知的QoE方面比传统通用DRL高出高达23.5%。", "conclusion": "LAMeTA通过结合大型AI模型和两阶段优化方法，有效解决了代理网络中的意图感知优化问题，显著提升了用户体验质量。"}}
{"id": "2505.12354", "title": "A universal policy wrapper with guarantees", "authors": ["Anton Bolychev", "Georgiy Malaniya", "Grigory Yaremenko", "Anastasia Krasnaya", "Pavel Osinenko"], "abstract": "We introduce a universal policy wrapper for reinforcement learning agents that ensures formal goal-reaching guarantees. In contrast to standard reinforcement learning algorithms that excel in performance but lack rigorous safety assurances, our wrapper selectively switches between a high-performing base policy -- derived from any existing RL method -- and a fallback policy with known convergence properties. Base policy's value function supervises this switching process, determining when the fallback policy should override the base policy to ensure the system remains on a stable path. The analysis proves that our wrapper inherits the fallback policy's goal-reaching guarantees while preserving or improving upon the performance of the base policy. Notably, it operates without needing additional system knowledge or online constrained optimization, making it readily deployable across diverse reinforcement learning architectures and tasks.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Robotics (cs.RO); Systems and Control (eess.SY); Optimization and Control (math.OC)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.12354.pdf", "abstract_url": "https://arxiv.org/abs/2505.12354", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Robotics (cs.RO)", "Systems and Control (eess.SY)", "Optimization and Control (math.OC)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一种用于强化学习智能体的通用策略包装器，旨在提供正式的目标达成保证。与缺乏严格安全保证的标准强化学习算法不同，该包装器选择性地在高性能基础策略和具有已知收敛属性的后备策略之间切换，确保系统保持在稳定路径上。", "motivation": "解决标准强化学习算法在性能优异但缺乏严格安全保证的问题，提供一种既能保证目标达成又不牺牲性能的解决方案。", "method": "通过基础策略的价值函数监督切换过程，决定何时应覆盖基础策略以使用后备策略，确保系统的稳定性。", "result": "分析证明，该包装器继承了后备策略的目标达成保证，同时保持或提高了基础策略的性能，且无需额外的系统知识或在线约束优化。", "conclusion": "这种通用策略包装器易于部署于各种强化学习架构和任务中，为强化学习智能体提供了既安全又高效的解决方案。"}}
{"id": "2505.12467", "title": "Beyond Frameworks: Unpacking Collaboration Strategies in Multi-Agent Systems", "authors": ["Haochun Wang", "Sendong Zhao", "Jingbo Wang", "Zewen Qiang", "Bing Qin", "Ting Liu"], "abstract": "Multi-agent collaboration has emerged as a pivotal paradigm for addressing complex, distributed tasks in large language model (LLM)-driven applications. While prior research has focused on high-level architectural frameworks, the granular mechanisms governing agents, critical to performance and scalability, remain underexplored. This study systematically investigates four dimensions of collaboration strategies: (1) agent governance, (2) participation control, (3) interaction dynamics, and (4) dialogue history management. Through rigorous experimentation under two context-dependent scenarios: Distributed Evidence Integration (DEI) and Structured Evidence Synthesis (SES), we quantify the impact of these strategies on both task accuracy and computational efficiency. Our findings reveal that centralized governance, instructor-led participation, ordered interaction patterns, and instructor-curated context summarization collectively optimize the trade-off between decision quality and resource utilization with the support of the proposed Token-Accuracy Ratio (TAR). This work establishes a foundation for designing adaptive, scalable multi-agent systems, shifting the focus from structural novelty to strategic interaction mechanics.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": "ACL 2025", "pdf_url": "https://arxiv.org/pdf/2505.12467.pdf", "abstract_url": "https://arxiv.org/abs/2505.12467", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文系统研究了多智能体系统中的协作策略，包括代理治理、参与控制、交互动态和对话历史管理四个维度，并通过实验量化了这些策略对任务准确性和计算效率的影响。研究发现，集中治理、导师引导的参与、有序的交互模式和导师策划的上下文总结共同优化了决策质量和资源利用之间的权衡。", "motivation": "多智能体协作已成为解决大型语言模型（LLM）驱动应用中复杂、分布式任务的关键范式。然而，先前的研究主要集中在高层架构框架上，对性能与可扩展性至关重要的细粒度机制研究不足。", "method": "本研究通过两种情境依赖的场景：分布式证据整合（DEI）和结构化证据合成（SES），系统地调查了协作策略的四个维度，并通过严格实验量化了这些策略的影响。", "result": "研究结果表明，集中治理、导师引导的参与、有序的交互模式和导师策划的上下文总结，在提出的Token-Accuracy Ratio（TAR）支持下，共同优化了决策质量和资源利用之间的权衡。", "conclusion": "这项工作为设计自适应、可扩展的多智能体系统奠定了基础，将焦点从结构新颖性转向战略交互机制。"}}
{"id": "2505.12567", "title": "A Survey of Attacks on Large Language Models", "authors": ["Wenrui Xu", "Keshab K. Parhi"], "abstract": "Large language models (LLMs) and LLM-based agents have been widely deployed in a wide range of applications in the real world, including healthcare diagnostics, financial analysis, customer support, robotics, and autonomous driving, expanding their powerful capability of understanding, reasoning, and generating natural languages. However, the wide deployment of LLM-based applications exposes critical security and reliability risks, such as the potential for malicious misuse, privacy leakage, and service disruption that weaken user trust and undermine societal safety. This paper provides a systematic overview of the details of adversarial attacks targeting both LLMs and LLM-based agents. These attacks are organized into three phases in LLMs: Training-Phase Attacks, Inference-Phase Attacks, and Availability & Integrity Attacks. For each phase, we analyze the details of representative and recently introduced attack methods along with their corresponding defenses. We hope our survey will provide a good tutorial and a comprehensive understanding of LLM security, especially for attacks on LLMs. We desire to raise attention to the risks inherent in widely deployed LLM-based applications and highlight the urgent need for robust mitigation strategies for evolving threats.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.12567.pdf", "abstract_url": "https://arxiv.org/abs/2505.12567", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文系统地概述了针对大型语言模型(LLMs)及其基于代理的攻击，分为训练阶段攻击、推理阶段攻击以及可用性与完整性攻击三个阶段，并分析了代表性攻击方法及防御措施，旨在提高对LLM安全性的全面理解，并强调制定稳健缓解策略的紧迫性。", "motivation": "大型语言模型(LLMs)及其基于代理的广泛应用暴露了关键的安全和可靠性风险，如恶意滥用、隐私泄露和服务中断，这些问题削弱了用户信任并威胁社会安全。", "method": "通过将攻击分为训练阶段攻击、推理阶段攻击以及可用性与完整性攻击三个阶段，分析每个阶段的代表性攻击方法及相应的防御措施。", "result": "提供了对LLM安全性的全面理解，特别是针对LLMs的攻击，强调了广泛部署的LLM应用中的风险。", "conclusion": "本文旨在提高对LLM安全性的认识，并强调需要针对不断演变的威胁制定稳健的缓解策略。"}}
{"id": "2505.12623", "title": "Lightweight and Effective Preference Construction in PIBT for Large-Scale Multi-Agent Pathfinding", "authors": ["Keisuke Okumura", "Hiroki Nagai"], "abstract": "PIBT is a computationally lightweight algorithm that can be applied to a variety of multi-agent pathfinding (MAPF) problems, generating the next collision-free locations of agents given another. Because of its simplicity and scalability, it is becoming a popular underlying scheme for recent large-scale MAPF methods involving several hundreds or thousands of agents. Vanilla PIBT makes agents behave greedily towards their assigned goals, while agents typically have multiple best actions, since the graph shortest path is not always unique. Consequently, tiebreaking about how to choose between these actions significantly affects resulting solutions. This paper studies two simple yet effective techniques for tiebreaking in PIBT, without compromising its computational advantage. The first technique allows an agent to intelligently dodge another, taking into account whether each action will hinder the progress of the next timestep. The second technique is to learn, through multiple PIBT runs, how an action causes regret in others and to use this information to minimise regret collectively. Our empirical results demonstrate that these techniques can reduce the solution cost of one-shot MAPF and improve the throughput of lifelong MAPF. For instance, in densely populated one-shot cases, the combined use of these tiebreaks achieves improvements of around 10-20% in sum-of-costs, without significantly compromising the speed of a PIBT-based planner.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": "To be presented at SoCS-25", "pdf_url": "https://arxiv.org/pdf/2505.12623.pdf", "abstract_url": "https://arxiv.org/abs/2505.12623", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究了在PIBT算法中两种简单而有效的平局打破技术，旨在不牺牲其计算优势的情况下，提高大规模多智能体路径规划（MAPF）的解决方案质量和效率。", "motivation": "解决在PIBT算法中，由于图的最短路径不唯一，智能体在选择最佳动作时存在的平局问题，以及如何通过有效的平局打破技术来优化解决方案。", "method": "提出了两种平局打破技术：一是智能体智能躲避另一智能体，考虑每个动作是否会阻碍下一个时间步的进展；二是通过多次PIBT运行学习动作如何导致其他智能体的后悔，并利用这些信息集体最小化后悔。", "result": "实证结果表明，这些技术可以减少一次性MAPF的解决方案成本，并提高终身MAPF的吞吐量。在密集的一次性案例中，结合使用这些平局打破技术可以在不显著影响PIBT规划器速度的情况下，实现总成本约10-20%的改进。", "conclusion": "通过简单的平局打破技术，可以在保持PIBT算法计算优势的同时，显著提高大规模MAPF问题的解决方案质量和效率。"}}
{"id": "2505.12707", "title": "PLAICraft: Large-Scale Time-Aligned Vision-Speech-Action Dataset for Embodied AI", "authors": ["Yingchen He", "Christian D. Weilbach", "Martyna E. Wojciechowska", "Yuxuan Zhang", "Frank Wood"], "abstract": "Advances in deep generative modelling have made it increasingly plausible to train human-level embodied agents. Yet progress has been limited by the absence of large-scale, real-time, multi-modal, and socially interactive datasets that reflect the sensory-motor complexity of natural environments. To address this, we present PLAICraft, a novel data collection platform and dataset capturing multiplayer Minecraft interactions across five time-aligned modalities: video, game output audio, microphone input audio, mouse, and keyboard actions. Each modality is logged with millisecond time precision, enabling the study of synchronous, embodied behaviour in a rich, open-ended world. The dataset comprises over 10,000 hours of gameplay from more than 10,000 global participants.\\footnote{We have done a privacy review for the public release of an initial 200-hour subset of the dataset, with plans to release most of the dataset over time.} Alongside the dataset, we provide an evaluation suite for benchmarking model capabilities in object recognition, spatial awareness, language grounding, and long-term memory. PLAICraft opens a path toward training and evaluating agents that act fluently and purposefully in real time, paving the way for truly embodied artificial intelligence.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "9 pages, 8 figures", "pdf_url": "https://arxiv.org/pdf/2505.12707.pdf", "abstract_url": "https://arxiv.org/abs/2505.12707", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "PLAICraft是一个大规模、时间对齐的多模态数据集，旨在促进具身AI的发展，通过记录Minecraft游戏中的视频、音频和玩家操作等多模态数据。", "motivation": "解决当前缺乏大规模、实时、多模态且社交互动的数据集，以反映自然环境中感官运动复杂性的问题。", "method": "开发了一个数据收集平台和数据集，记录了Minecraft多人游戏中的五种时间对齐的模态：视频、游戏输出音频、麦克风输入音频、鼠标和键盘操作。", "result": "数据集包含超过10,000小时的游戏玩法，来自全球10,000多名参与者，并提供了评估套件用于基准测试。", "conclusion": "PLAICraft为训练和评估在实时中流畅且有目的行动的智能体开辟了道路，推动了真正具身人工智能的发展。"}}
{"id": "2505.12811", "title": "Dynamic Sight Range Selection in Multi-Agent Reinforcement Learning", "authors": ["Wei-Chen Liao", "Ti-Rong Wu", "I-Chen Wu"], "abstract": "Multi-agent reinforcement Learning (MARL) is often challenged by the sight range dilemma, where agents either receive insufficient or excessive information from their environment. In this paper, we propose a novel method, called Dynamic Sight Range Selection (DSR), to address this issue. DSR utilizes an Upper Confidence Bound (UCB) algorithm and dynamically adjusts the sight range during training. Experiment results show several advantages of using DSR. First, we demonstrate using DSR achieves better performance in three common MARL environments, including Level-Based Foraging (LBF), Multi-Robot Warehouse (RWARE), and StarCraft Multi-Agent Challenge (SMAC). Second, our results show that DSR consistently improves performance across multiple MARL algorithms, including QMIX and MAPPO. Third, DSR offers suitable sight ranges for different training steps, thereby accelerating the training process. Finally, DSR provides additional interpretability by indicating the optimal sight range used during training. Unlike existing methods that rely on global information or communication mechanisms, our approach operates solely based on the individual sight ranges of agents. This approach offers a practical and efficient solution to the sight range dilemma, making it broadly applicable to real-world complex environments.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "Accepted at AAMAS 2025. The compiled PDF includes the appendix", "pdf_url": "https://arxiv.org/pdf/2505.12811.pdf", "abstract_url": "https://arxiv.org/abs/2505.12811", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为动态视野范围选择（DSR）的新方法，用于解决多智能体强化学习（MARL）中的视野范围困境。DSR通过使用上置信界（UCB）算法在训练过程中动态调整视野范围，实验结果表明，DSR在多种MARL环境和算法中均能提高性能，加速训练过程，并提供额外的可解释性。", "motivation": "多智能体强化学习（MARL）常面临视野范围困境，即智能体从环境中接收的信息要么不足，要么过多。本文旨在解决这一问题。", "method": "提出了一种名为动态视野范围选择（DSR）的新方法，该方法利用上置信界（UCB）算法在训练过程中动态调整智能体的视野范围。", "result": "实验结果表明，DSR在三种常见的MARL环境（LBF、RWARE、SMAC）中表现更好，能提高多种MARL算法（如QMIX和MAPPO）的性能，加速训练过程，并提供额外的可解释性。", "conclusion": "DSR为视野范围困境提供了一个实用且高效的解决方案，使其广泛应用于现实世界的复杂环境中。与依赖全局信息或通信机制的现有方法不同，DSR仅基于智能体的个体视野范围进行操作。"}}
{"id": "2505.12981", "title": "From Assistants to Adversaries: Exploring the Security Risks of Mobile LLM Agents", "authors": ["Liangxuan Wu", "Chao Wang", "Tianming Liu", "Yanjie Zhao", "Haoyu Wang"], "abstract": "The growing adoption of large language models (LLMs) has led to a new paradigm in mobile computing--LLM-powered mobile AI agents--capable of decomposing and automating complex tasks directly on smartphones. However, the security implications of these agents remain largely unexplored. In this paper, we present the first comprehensive security analysis of mobile LLM agents, encompassing three representative categories: System-level AI Agents developed by original equipment manufacturers (e.g., YOYO Assistant), Third-party Universal Agents (e.g., Zhipu AI AutoGLM), and Emerging Agent Frameworks (e.g., Alibaba Mobile Agent). We begin by analyzing the general workflow of mobile agents and identifying security threats across three core capability dimensions: language-based reasoning, GUI-based interaction, and system-level execution. Our analysis reveals 11 distinct attack surfaces, all rooted in the unique capabilities and interaction patterns of mobile LLM agents, and spanning their entire operational lifecycle. To investigate these threats in practice, we introduce AgentScan, a semi-automated security analysis framework that systematically evaluates mobile LLM agents across all 11 attack scenarios. Applying AgentScan to nine widely deployed agents, we uncover a concerning trend: every agent is vulnerable to targeted attacks. In the most severe cases, agents exhibit vulnerabilities across eight distinct attack vectors. These attacks can cause behavioral deviations, privacy leakage, or even full execution hijacking. Based on these findings, we propose a set of defensive design principles and practical recommendations for building secure mobile LLM agents. Our disclosures have received positive feedback from two major device vendors. Overall, this work highlights the urgent need for standardized security practices in the fast-evolving landscape of LLM-driven mobile automation.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.12981.pdf", "abstract_url": "https://arxiv.org/abs/2505.12981", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文首次全面分析了移动LLM代理的安全风险，揭示了11个不同的攻击面，并开发了AgentScan框架来评估这些风险。研究发现所有被测试的代理都存在漏洞，提出了防御设计原则和建议。", "motivation": "随着大型语言模型（LLMs）在移动计算中的广泛应用，LLM驱动的移动AI代理的安全隐患尚未被充分探索。本文旨在填补这一空白，揭示并分析这些代理的安全风险。", "method": "通过分析移动代理的一般工作流程，识别了三个核心能力维度（语言推理、GUI交互、系统级执行）的安全威胁，并开发了AgentScan半自动化安全分析框架，对九种广泛部署的代理进行了评估。", "result": "研究发现，所有被测试的移动LLM代理都存在针对性的攻击漏洞，最严重的情况下，代理在八个不同的攻击向量上表现出脆弱性，可能导致行为偏差、隐私泄露或完全执行劫持。", "conclusion": "本文强调了在快速发展的LLM驱动移动自动化领域建立标准化安全实践的紧迫性，并提出了防御设计原则和实用建议，得到了主要设备厂商的积极反馈。"}}
{"id": "2505.13076", "title": "The Hidden Dangers of Browsing AI Agents", "authors": ["Mykyta Mudryi", "Markiyan Chaklosh", "Grzegorz Wójcik"], "abstract": "Autonomous browsing agents powered by large language models (LLMs) are increasingly used to automate web-based tasks. However, their reliance on dynamic content, tool execution, and user-provided data exposes them to a broad attack surface. This paper presents a comprehensive security evaluation of such agents, focusing on systemic vulnerabilities across multiple architectural layers. Our work outlines the first end-to-end threat model for browsing agents and provides actionable guidance for securing their deployment in real-world environments. To address discovered threats, we propose a defense in depth strategy incorporating input sanitization, planner executor isolation, formal analyzers, and session safeguards. These measures protect against both initial access and post exploitation attack vectors. Through a white box analysis of a popular open source project, Browser Use, we demonstrate how untrusted web content can hijack agent behavior and lead to critical security breaches. Our findings include prompt injection, domain validation bypass, and credential exfiltration, evidenced by a disclosed CVE and a working proof of concept exploit.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.13076.pdf", "abstract_url": "https://arxiv.org/abs/2505.13076", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文对基于大型语言模型（LLMs）的自主浏览代理进行了全面的安全评估，揭示了其面临的广泛攻击面，并提出了端到端的威胁模型及深度防御策略。", "motivation": "随着基于大型语言模型的自主浏览代理在自动化网络任务中的广泛应用，其依赖动态内容、工具执行和用户提供数据的特点使其暴露于广泛的攻击面，本文旨在解决这些安全问题。", "method": "通过对流行的开源项目Browser Use进行白盒分析，本文展示了不受信任的网络内容如何劫持代理行为，并提出了包括输入净化、规划执行隔离、形式化分析器和会话保护在内的深度防御策略。", "result": "研究发现包括提示注入、域验证绕过和凭证外泄等安全漏洞，并通过披露的CVE和有效的概念验证漏洞证明了这些发现。", "conclusion": "本文不仅首次为浏览代理提供了端到端的威胁模型，还提出了实际可行的安全部署指南，强调了在现实环境中部署这些代理时采取深度防御策略的重要性。"}}
{"id": "2505.13182", "title": "Information Science Principles of Machine Learning: A Causal Chain Meta-Framework Based on Formalized Information Mapping", "authors": ["Jianfeng Xu"], "abstract": "[Objective] This study focuses on addressing the current lack of a unified formal theoretical framework in machine learning, as well as the deficiencies in interpretability and ethical safety assurance. [Methods] A formal information model is first constructed, utilizing sets of well-formed formulas to explicitly define the ontological states and carrier mappings of typical components in machine learning. Learnable and processable predicates, along with learning and processing functions, are introduced to analyze the logical deduction and constraint rules of the causal chains within models. [Results] A meta-framework for machine learning theory (MLT-MF) is established. Based on this framework, universal definitions for model interpretability and ethical safety are proposed. Furthermore, three key theorems are proved: the equivalence of model interpretability and information recoverability, the assurance of ethical safety, and the estimation of generalization error. [Limitations] The current framework assumes ideal conditions with noiseless information-enabling mappings and primarily targets model learning and processing logic in static scenarios. It does not yet address information fusion and conflict resolution across ontological spaces in multimodal or multi-agent systems. [Conclusions] This work overcomes the limitations of fragmented research and provides a unified theoretical foundation for systematically addressing the critical challenges currently faced in machine learning.", "subjects": "Logic in Computer Science (cs.LO); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.13182.pdf", "abstract_url": "https://arxiv.org/abs/2505.13182", "categories": ["Logic in Computer Science (cs.LO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本研究提出了一种基于形式化信息映射的机器学习理论元框架（MLT-MF），旨在解决当前机器学习领域缺乏统一的形式化理论框架以及可解释性和伦理安全保障不足的问题。", "motivation": "解决机器学习领域缺乏统一的形式化理论框架，以及模型可解释性和伦理安全保障的不足。", "method": "构建了一个形式化信息模型，使用良好形成的公式集明确定义了机器学习中典型组件的本体状态和载体映射，引入了可学习和可处理的谓词以及学习和处理函数，分析了模型内因果链的逻辑推导和约束规则。", "result": "建立了机器学习理论的元框架（MLT-MF），提出了模型可解释性和伦理安全的通用定义，并证明了三个关键定理：模型可解释性与信息可恢复性的等价性、伦理安全的保障以及泛化误差的估计。", "conclusion": "这项工作克服了碎片化研究的限制，为系统解决机器学习当前面临的关键挑战提供了统一的理论基础。"}}
{"id": "2505.13188", "title": "When a Reinforcement Learning Agent Encounters Unknown Unknowns", "authors": ["Juntian Zhu", "Miguel de Carvalho", "Zhouwang Yang", "Fengxiang He"], "abstract": "An AI agent might surprisingly find she has reached an unknown state which she has never been aware of -- an unknown unknown. We mathematically ground this scenario in reinforcement learning: an agent, after taking an action calculated from value functions $Q$ and $V$ defined on the {\\it {aware domain}}, reaches a state out of the domain. To enable the agent to handle this scenario, we propose an {\\it episodic Markov decision {process} with growing awareness} (EMDP-GA) model, taking a new {\\it noninformative value expansion} (NIVE) approach to expand value functions to newly aware areas: when an agent arrives at an unknown unknown, value functions $Q$ and $V$ whereon are initialised by noninformative beliefs -- the averaged values on the aware domain. This design is out of respect for the complete absence of knowledge in the newly discovered state. The upper confidence bound momentum Q-learning is then adapted to the growing awareness for training the EMDP-GA model. We prove that (1) the regret of our approach is asymptotically consistent with the state of the art (SOTA) without exposure to unknown unknowns in an extremely uncertain environment, and (2) our computational complexity and space complexity are comparable with the SOTA -- these collectively suggest that though an unknown unknown is surprising, it will be asymptotically properly discovered with decent speed and an affordable cost.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.13188.pdf", "abstract_url": "https://arxiv.org/abs/2505.13188", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Machine Learning (stat.ML)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种处理强化学习代理遇到未知未知状态的方法，通过扩展价值函数和使用非信息价值扩展（NIVE）方法，使代理能够在发现新状态时初始化价值函数。", "motivation": "解决强化学习代理在遇到从未意识到的未知状态（未知未知）时的应对策略问题。", "method": "提出了一个具有增长意识的阶段性马尔可夫决策过程（EMDP-GA）模型，采用非信息价值扩展（NIVE）方法将价值函数扩展到新发现的区域。", "result": "证明了该方法在极端不确定环境中的遗憾与现有技术（SOTA）一致，且计算和空间复杂度与SOTA相当。", "conclusion": "尽管未知未知状态的出现是意外的，但通过提出的方法，代理能够以适当的速度和可承受的成本渐近地发现这些状态。"}}
{"id": "2505.13253", "title": "Composing Dextrous Grasping and In-hand Manipulation via Scoring with a Reinforcement Learning Critic", "authors": ["Lennart Röstel", "Dominik Winkelbauer", "Johannes Pitz", "Leon Sievers", "Berthold Bäuml"], "abstract": "In-hand manipulation and grasping are fundamental yet often separately addressed tasks in robotics. For deriving in-hand manipulation policies, reinforcement learning has recently shown great success. However, the derived controllers are not yet useful in real-world scenarios because they often require a human operator to place the objects in suitable initial (grasping) states. Finding stable grasps that also promote the desired in-hand manipulation goal is an open problem. In this work, we propose a method for bridging this gap by leveraging the critic network of a reinforcement learning agent trained for in-hand manipulation to score and select initial grasps. Our experiments show that this method significantly increases the success rate of in-hand manipulation without requiring additional training. We also present an implementation of a full grasp manipulation pipeline on a real-world system, enabling autonomous grasping and reorientation even of unwieldy objects.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.13253.pdf", "abstract_url": "https://arxiv.org/abs/2505.13253", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种方法，通过利用强化学习代理的评论家网络来评分和选择初始抓取，从而弥合机器人抓取和手内操作之间的差距。实验表明，该方法显著提高了手内操作的成功率，且无需额外训练。", "motivation": "解决机器人手内操作和抓取任务通常被分开处理的问题，特别是在实际应用中，现有的控制器需要人工将物体放置在合适的初始抓取状态，这限制了其应用。", "method": "利用训练用于手内操作的强化学习代理的评论家网络来评分和选择初始抓取。", "result": "该方法显著提高了手内操作的成功率，无需额外训练，并在真实世界系统中实现了自主抓取和重新定向，即使是难以操作的物体。", "conclusion": "通过评分和选择初始抓取，可以有效地将抓取和手内操作结合起来，提高操作的成功率和自主性，为机器人操作的实际应用提供了新的可能性。"}}
{"id": "2505.13291", "title": "TimeSeriesGym: A Scalable Benchmark for (Time Series) Machine Learning Engineering Agents", "authors": ["Yifu Cai", "Xinyu Li", "Mononito Goswami", "Michał Wiliński", "Gus Welter", "Artur Dubrawski"], "abstract": "We introduce TimeSeriesGym, a scalable benchmarking framework for evaluating Artificial Intelligence (AI) agents on time series machine learning engineering challenges. Existing benchmarks lack scalability, focus narrowly on model building in well-defined settings, and evaluate only a limited set of research artifacts (e.g., CSV submission files). To make AI agent benchmarking more relevant to the practice of machine learning engineering, our framework scales along two critical dimensions. First, recognizing that effective ML engineering requires a range of diverse skills, TimeSeriesGym incorporates challenges from diverse sources spanning multiple domains and tasks. We design challenges to evaluate both isolated capabilities (including data handling, understanding research repositories, and code translation) and their combinations, and rather than addressing each challenge independently, we develop tools that support designing multiple challenges at scale. Second, we implement evaluation mechanisms for multiple research artifacts, including submission files, code, and models, using both precise numeric measures and more flexible LLM-based evaluation approaches. This dual strategy balances objective assessment with contextual judgment. Although our initial focus is on time series applications, our framework can be readily extended to other data modalities, broadly enhancing the comprehensiveness and practical utility of agentic AI evaluation. We open-source our benchmarking framework to facilitate future research on the ML engineering capabilities of AI agents.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": ". YC, XL, MG and MW contributed equally, and should be considered joint first authors", "pdf_url": "https://arxiv.org/pdf/2505.13291.pdf", "abstract_url": "https://arxiv.org/abs/2505.13291", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "TimeSeriesGym是一个可扩展的基准测试框架，旨在评估AI代理在时间序列机器学习工程挑战中的表现。该框架通过多样化的挑战和多维度的评估机制，提升了AI代理评估的相关性和实用性。", "motivation": "现有的基准测试缺乏可扩展性，且仅关注在明确定义的环境中的模型构建，评估的研究成果有限。TimeSeriesGym旨在解决这些问题，使AI代理的基准测试更贴近机器学习工程的实践。", "method": "TimeSeriesGym通过在多样化的领域和任务中设计挑战，评估AI代理的孤立能力和组合能力，并开发工具支持大规模设计挑战。同时，采用精确的数值测量和基于LLM的灵活评估方法，对多种研究成果进行评估。", "result": "TimeSeriesGym框架不仅适用于时间序列应用，还可以轻松扩展到其他数据模式，从而广泛提高AI代理评估的全面性和实用性。", "conclusion": "TimeSeriesGym通过其可扩展性和多维度的评估机制，为AI代理的机器学习工程能力评估提供了一个全面且实用的框架，其开源性质将促进未来在这一领域的研究。"}}
