{"id": "2505.14848", "title": "MAATS: A Multi-Agent Automated Translation System Based on MQM Evaluation", "authors": ["Xi Wang", "Jiaqian Hu", "Safinah Ali"], "abstract": "We present MAATS, a Multi Agent Automated Translation System that leverages the Multidimensional Quality Metrics (MQM) framework as a fine-grained signal for error detection and refinement. MAATS employs multiple specialized AI agents, each focused on a distinct MQM category (e.g., Accuracy, Fluency, Style, Terminology), followed by a synthesis agent that integrates the annotations to iteratively refine translations. This design contrasts with conventional single-agent methods that rely on self-correction.", "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.14848.pdf", "abstract_url": "https://arxiv.org/abs/2505.14848", "categories": ["Computation and Language (cs.CL)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "MAATS是一个基于MQM评估的多代理自动翻译系统，通过多个专注于不同MQM类别的AI代理和一个综合代理来迭代优化翻译质量。", "motivation": "解决传统单代理翻译系统依赖自我校正的局限性，提高翻译的准确性和流畅性。", "method": "利用MQM框架作为细粒度错误检测和优化的信号，通过多个专业AI代理和一个综合代理协作迭代优化翻译。", "result": "MAATS通过多代理协作，能够更有效地检测和修正翻译中的错误，提高翻译质量。", "conclusion": "MAATS提供了一种新颖的多代理协作方法，显著提升了自动翻译系统的性能和质量。"}}
{"id": "2505.14886", "title": "Strategic Planning and Rationalizing on Trees Make LLMs Better Debaters", "authors": ["Danqing Wang", "Zhuorui Ye", "Xinran Zhao", "Fei Fang", "Lei Li"], "abstract": "Winning competitive debates requires sophisticated reasoning and argument skills. There are unique challenges in the competitive debate: (1) The time constraints force debaters to make strategic choices about which points to pursue rather than covering all possible arguments; (2) The persuasiveness of the debate relies on the back-and-forth interaction between arguments, which a single final game status cannot evaluate. To address these challenges, we propose TreeDebater, a novel debate framework that excels in competitive debate. We introduce two tree structures: the Rehearsal Tree and Debate Flow Tree. The Rehearsal Tree anticipates the attack and defenses to evaluate the strength of the claim, while the Debate Flow Tree tracks the debate status to identify the active actions. TreeDebater allocates its time budget among candidate actions and uses the speech time controller and feedback from the simulated audience to revise its statement. The human evaluation on both the stage-level and the debate-level comparison shows that our TreeDebater outperforms the state-of-the-art multi-agent debate system. Further investigation shows that TreeDebater shows better strategies in limiting time to important debate actions, aligning with the strategies of human debate experts.", "subjects": "Computation and Language (cs.CL)", "comments": "9 main pages", "pdf_url": "https://arxiv.org/pdf/2505.14886.pdf", "abstract_url": "https://arxiv.org/abs/2505.14886", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了TreeDebater，一个新颖的辩论框架，通过引入排练树和辩论流程树来解决竞争性辩论中的时间限制和互动性挑战，展示了优于现有多代理辩论系统的表现。", "motivation": "竞争性辩论需要复杂的推理和论证技巧，面临时间限制和辩论互动性的挑战。", "method": "引入排练树和辩论流程树，通过时间预算分配和模拟观众反馈来优化辩论策略。", "result": "TreeDebater在阶段性和整体辩论比较中优于现有系统，更接近人类辩论专家的策略。", "conclusion": "TreeDebater通过战略规划和树结构优化，显著提升了辩论效果，展现了与人类专家策略的一致性。"}}
{"id": "2505.14738", "title": "R&D-Agent: Automating Data-Driven AI Solution Building Through LLM-Powered Automated Research, Development, and Evolution", "authors": ["Xu Yang", "Xiao Yang", "Shikai Fang", "Bowen Xian", "Yuante Li", "Jian Wang", "Minrui Xu", "Haoran Pan", "Xinpeng Hong", "Weiqing Liu", "Yelong Shen", "Weizhu Chen", "Jiang Bian"], "abstract": "Recent advances in AI and ML have transformed data science, yet increasing complexity and expertise requirements continue to hinder progress. While crowdsourcing platforms alleviate some challenges, high-level data science tasks remain labor-intensive and iterative. To overcome these limitations, we introduce R&D-Agent, a dual-agent framework for iterative exploration. The Researcher agent uses performance feedback to generate ideas, while the Developer agent refines code based on error feedback. By enabling multiple parallel exploration traces that merge and enhance one another, R&D-Agent narrows the gap between automated solutions and expert-level performance. Evaluated on MLE-Bench, R&D-Agent emerges as the top-performing machine learning engineering agent, demonstrating its potential to accelerate innovation and improve precision across diverse data science applications. We have open-sourced R&D-Agent on GitHub:", "subjects": "Artificial Intelligence (cs.AI)", "comments": "7 pages, 1 figure, 1 table", "pdf_url": "https://arxiv.org/pdf/2505.14738.pdf", "abstract_url": "https://arxiv.org/abs/2505.14738", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "R&D-Agent是一个双代理框架，旨在通过LLM驱动的自动化研究、开发和进化来简化数据驱动的AI解决方案构建过程。研究者代理利用性能反馈生成想法，而开发者代理基于错误反馈优化代码。该框架通过并行探索轨迹的合并与增强，缩小了自动化解决方案与专家级性能之间的差距。在MLE-Bench上的评估显示，R&D-Agent表现最佳，展现了其在加速创新和提高数据科学应用精度方面的潜力。", "motivation": "尽管AI和ML的进步已经改变了数据科学，但日益增加的复杂性和专业知识要求仍阻碍了进展。众包平台虽缓解了部分挑战，但高级数据科学任务仍然劳动密集且迭代频繁。R&D-Agent旨在克服这些限制。", "method": "引入R&D-Agent，一个双代理框架，包括研究者代理和开发者代理。研究者代理使用性能反馈生成想法，开发者代理基于错误反馈优化代码。通过并行探索轨迹的合并与增强，实现自动化解决方案的迭代探索。", "result": "在MLE-Bench上的评估中，R&D-Agent成为表现最佳的机器学习工程代理，展示了其在加速创新和提高数据科学应用精度方面的潜力。", "conclusion": "R&D-Agent通过其双代理框架，有效地缩小了自动化解决方案与专家级性能之间的差距，有望加速数据科学领域的创新和提高应用精度。该框架已在GitHub上开源。"}}
{"id": "2505.15011", "title": "HAVA: Hybrid Approach to Value-Alignment through Reward Weighing for Reinforcement Learning", "authors": ["Kryspin Varys", "Federico Cerutti", "Adam Sobey", "Timothy J. Norman"], "abstract": "Our society is governed by a set of norms which together bring about the values we cherish such as safety, fairness or trustworthiness. The goal of value-alignment is to create agents that not only do their tasks but through their behaviours also promote these values. Many of the norms are written as laws or rules (legal / safety norms) but even more remain unwritten (social norms). Furthermore, the techniques used to represent these norms also differ. Safety / legal norms are often represented explicitly, for example, in some logical language while social norms are typically learned and remain hidden in the parameter space of a neural network. There is a lack of approaches in the literature that could combine these various norm representations into a single algorithm. We propose a novel method that integrates these norms into the reinforcement learning process. Our method monitors the agent's compliance with the given norms and summarizes it in a quantity we call the agent's reputation. This quantity is used to weigh the received rewards to motivate the agent to become value-aligned. We carry out a series of experiments including a continuous state space traffic problem to demonstrate the importance of the written and unwritten norms and show how our method can find the value-aligned policies. Furthermore, we carry out ablations to demonstrate why it is better to combine these two groups of norms rather than using either separately.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.15011.pdf", "abstract_url": "https://arxiv.org/abs/2505.15011", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新颖的方法HAVA，通过奖励加权将法律/安全规范和社会规范结合到强化学习过程中，以促进代理的价值对齐。", "motivation": "解决现有方法无法将不同表示形式的规范（如明确的法律/安全规范和隐含的社会规范）整合到单一算法中的问题。", "method": "通过监控代理对给定规范的遵守情况，并将其总结为代理的声誉，用于加权接收到的奖励，从而激励代理实现价值对齐。", "result": "实验证明，结合书面和非书面规范比单独使用任何一种更能找到价值对齐的策略。", "conclusion": "HAVA方法有效地整合了不同类型的规范，为强化学习中的价值对齐问题提供了新的解决方案。"}}
{"id": "2505.15068", "title": "ModelingAgent: Bridging LLMs and Mathematical Modeling for Real-World Challenges", "authors": ["Cheng Qian", "Hongyi Du", "Hongru Wang", "Xiusi Chen", "Yuji Zhang", "Avirup Sil", "Chengxiang Zhai", "Kathleen McKeown", "Heng Ji"], "abstract": "Recent progress in large language models (LLMs) has enabled substantial advances in solving mathematical problems. However, existing benchmarks often fail to reflect the complexity of real-world problems, which demand open-ended, interdisciplinary reasoning and integration of computational tools. To address this gap, we introduce ModelingBench, a novel benchmark featuring real-world-inspired, open-ended problems from math modeling competitions across diverse domains, ranging from urban traffic optimization to ecosystem resource planning. These tasks require translating natural language into formal mathematical formulations, applying appropriate tools, and producing structured, defensible reports. ModelingBench also supports multiple valid solutions, capturing the ambiguity and creativity of practical modeling. We also present ModelingAgent, a multi-agent framework that coordinates tool use, supports structured workflows, and enables iterative self-refinement to generate well-grounded, creative solutions. To evaluate outputs, we further propose ModelingJudge, an expert-in-the-loop system leveraging LLMs as domain-specialized judges assessing solutions from multiple expert perspectives. Empirical results show that ModelingAgent substantially outperforms strong baselines and often produces solutions indistinguishable from those of human experts. Together, our work provides a comprehensive framework for evaluating and advancing real-world problem-solving in open-ended, interdisciplinary modeling challenges.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": "36 Pages, 26 Figures, 5 Tables", "pdf_url": "https://arxiv.org/pdf/2505.15068.pdf", "abstract_url": "https://arxiv.org/abs/2505.15068", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了ModelingBench和ModelingAgent，旨在通过大型语言模型（LLMs）解决现实世界中的复杂数学建模问题。ModelingBench是一个新颖的基准测试，包含来自不同领域的开放性问题，而ModelingAgent是一个多代理框架，用于协调工具使用和支持结构化工作流程。", "motivation": "现有的基准测试往往无法反映现实世界问题的复杂性，这些问题需要开放式的跨学科推理和计算工具的集成。", "method": "引入了ModelingBench基准测试和ModelingAgent多代理框架，后者协调工具使用、支持结构化工作流程，并实现迭代自我完善。", "result": "实证结果显示，ModelingAgent显著优于强基线，并且经常产生与人类专家无法区分的解决方案。", "conclusion": "这项工作为评估和推进开放式跨学科建模挑战中的现实世界问题解决提供了一个全面的框架。"}}
{"id": "2505.15146", "title": "lmgame-Bench: How Good are LLMs at Playing Games?", "authors": ["Lanxiang Hu", "Mingjia Huo", "Yuxuan Zhang", "Haoyang Yu", "Eric P. Xing", "Ion Stoica", "Tajana Rosing", "Haojian Jin", "Hao Zhang"], "abstract": "Playing video games requires perception, memory, and planning, exactly the faculties modern large language model (LLM) agents are expected to master. We study the major challenges in using popular video games to evaluate modern LLMs and find that directly dropping LLMs into games cannot make an effective evaluation, for three reasons -- brittle vision perception, prompt sensitivity, and potential data contamination. We introduce lmgame-Bench to turn games into reliable evaluations. lmgame-Bench features a suite of platformer, puzzle, and narrative games delivered through a unified Gym-style API and paired with lightweight perception and memory scaffolds, and is designed to stabilize prompt variance and remove contamination. Across 13 leading models, we show lmgame-Bench is challenging while still separating models well. Correlation analysis shows that every game probes a unique blend of capabilities often tested in isolation elsewhere. More interestingly, performing reinforcement learning on a single game from lmgame-Bench transfers both to unseen games and to external planning tasks. Our evaluation code is available at", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.15146.pdf", "abstract_url": "https://arxiv.org/abs/2505.15146", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了lmgame-Bench，一个将视频游戏转化为可靠评估大型语言模型（LLM）能力的平台。通过统一的Gym风格API和轻量级的感知与记忆支架，解决了直接使用LLM玩游戏时的三大挑战：脆弱的视觉感知、提示敏感性和潜在的数据污染。", "motivation": "现代大型语言模型（LLM）在感知、记忆和规划方面的能力需要通过视频游戏等复杂环境进行有效评估，但直接使用现有游戏进行评估存在视觉感知脆弱、提示敏感性和数据污染等问题。", "method": "开发了lmgame-Bench，一个包含平台游戏、解谜游戏和叙事游戏的套件，通过统一的Gym风格API和轻量级的感知与记忆支架，稳定提示方差并消除污染。", "result": "在13个领先模型上的测试表明，lmgame-Bench既具有挑战性又能很好地区分模型能力。相关分析显示，每个游戏都能独特地测试模型在其他地方孤立测试的能力组合。", "conclusion": "lmgame-Bench不仅为LLM提供了一个有效的评估平台，还展示了在单个游戏上进行强化学习可以迁移到未见过的游戏和外部规划任务中，为LLM能力的评估和提升开辟了新途径。"}}
{"id": "2505.15693", "title": "Average Reward Reinforcement Learning for Omega-Regular and Mean-Payoff Objectives", "authors": ["Milad Kazemi", "Mateo Perez", "Fabio Somenzi", "Sadegh Soudjani", "Ashutosh Trivedi", "Alvaro Velasquez"], "abstract": "Recent advances in reinforcement learning (RL) have renewed focus on the design of reward functions that shape agent behavior. Manually designing reward functions is tedious and error-prone. A principled alternative is to specify behaviors in a formal language that can be automatically translated into rewards. Omega-regular languages are a natural choice for this purpose, given their established role in formal verification and synthesis. However, existing methods using omega-regular specifications typically rely on discounted reward RL in episodic settings, with periodic resets. This setup misaligns with the semantics of omega-regular specifications, which describe properties over infinite behavior traces. In such cases, the average reward criterion and the continuing setting -- where the agent interacts with the environment over a single, uninterrupted lifetime -- are more appropriate.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "29 pages, 6 figures and 2 tables", "pdf_url": "https://arxiv.org/pdf/2505.15693.pdf", "abstract_url": "https://arxiv.org/abs/2505.15693", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了在强化学习中，使用ω-正则语言自动生成奖励函数的方法，以替代手动设计的繁琐和易错过程。与传统的基于折扣奖励的RL方法不同，本文提倡在无限行为轨迹上使用平均奖励准则和连续设置，以更好地符合ω-正则语言的语义。", "motivation": "手动设计奖励函数既繁琐又容易出错，而ω-正则语言因其在形式验证和综合中的成熟应用，成为自动生成奖励函数的自然选择。然而，现有的基于ω-正则规范的方法通常依赖于在周期性重置的情景中使用折扣奖励RL，这与描述无限行为轨迹的ω-正则语言的语义不匹配。", "method": "本文提出使用平均奖励准则和连续设置（即代理在单一、不间断的生命周期内与环境交互）来更适当地处理ω-正则规范。", "result": "研究表明，在无限行为轨迹的情况下，平均奖励准则和连续设置比传统的折扣奖励RL方法更能符合ω-正则语言的语义。", "conclusion": "本文的结论是，为了更有效地利用ω-正则语言规范来指导强化学习代理的行为，应采用平均奖励准则和连续设置，这种方法比现有的基于折扣奖励的方法更符合无限行为轨迹的语义要求。"}}
{"id": "2505.15436", "title": "Chain-of-Focus: Adaptive Visual Search and Zooming for Multimodal Reasoning via RL", "authors": ["Xintong Zhang", "Zhi Gao", "Bofei Zhang", "Pengxiang Li", "Xiaowen Zhang", "Yang Liu", "Tao Yuan", "Yuwei Wu", "Yunde Jia", "Song-Chun Zhu", "Qing Li"], "abstract": "Vision language models (VLMs) have achieved impressive performance across a variety of computer vision tasks. However, the multimodal reasoning capability has not been fully explored in existing models. In this paper, we propose a Chain-of-Focus (CoF) method that allows VLMs to perform adaptive focusing and zooming in on key image regions based on obtained visual cues and the given questions, achieving efficient multimodal reasoning. To enable this CoF capability, we present a two-stage training pipeline, including supervised fine-tuning (SFT) and reinforcement learning (RL). In the SFT stage, we construct the MM-CoF dataset, comprising 3K samples derived from a visual agent designed to adaptively identify key regions to solve visual tasks with different image resolutions and questions. We use MM-CoF to fine-tune the Qwen2.5-VL model for cold start. In the RL stage, we leverage the outcome accuracies and formats as rewards to update the Qwen2.5-VL model, enabling further refining the search and reasoning strategy of models without human priors. Our model achieves significant improvements on multiple benchmarks. On the V* benchmark that requires strong visual reasoning capability, our model outperforms existing VLMs by 5% among 8 image resolutions ranging from 224 to 4K, demonstrating the effectiveness of the proposed CoF method and facilitating the more efficient deployment of VLMs in practical applications.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.15436.pdf", "abstract_url": "https://arxiv.org/abs/2505.15436", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为Chain-of-Focus（CoF）的方法，通过自适应视觉搜索和缩放，增强视觉语言模型（VLMs）的多模态推理能力。该方法采用两阶段训练流程，包括监督微调（SFT）和强化学习（RL），在多个基准测试中取得了显著改进。", "motivation": "现有的视觉语言模型在多模态推理能力方面尚未充分探索，本文旨在通过自适应聚焦和缩放关键图像区域，提高模型的推理效率和准确性。", "method": "提出了Chain-of-Focus（CoF）方法，包括监督微调（SFT）阶段和强化学习（RL）阶段。在SFT阶段，构建了MM-CoF数据集用于冷启动微调；在RL阶段，利用结果准确性和格式作为奖励，进一步优化模型的搜索和推理策略。", "result": "在需要强视觉推理能力的V*基准测试中，CoF方法在从224到4K的8种图像分辨率下，比现有VLMs性能提高了5%，展示了其有效性。", "conclusion": "CoF方法不仅提高了VLMs的多模态推理能力，还促进了这些模型在实际应用中的更高效部署。"}}
{"id": "2505.14963", "title": "MedBrowseComp: Benchmarking Medical Deep Research and Computer Use", "authors": ["Shan Chen", "Pedro Moreira", "Yuxin Xiao", "Sam Schmidgall", "Jeremy Warner", "Hugo Aerts", "Thomas Hartvigsen", "Jack Gallifant", "Danielle S. Bitterman"], "abstract": "Large language models (LLMs) are increasingly envisioned as decision-support tools in clinical practice, yet safe clinical reasoning demands integrating heterogeneous knowledge bases -- trials, primary studies, regulatory documents, and cost data -- under strict accuracy constraints. Existing evaluations often rely on synthetic prompts, reduce the task to single-hop factoid queries, or conflate reasoning with open-ended generation, leaving their real-world utility unclear. To close this gap, we present MedBrowseComp, the first benchmark that systematically tests an agent's ability to reliably retrieve and synthesize multi-hop medical facts from live, domain-specific knowledge bases. MedBrowseComp contains more than 1,000 human-curated questions that mirror clinical scenarios where practitioners must reconcile fragmented or conflicting information to reach an up-to-date conclusion. Applying MedBrowseComp to frontier agentic systems reveals performance shortfalls as low as ten percent, exposing a critical gap between current LLM capabilities and the rigor demanded in clinical settings. MedBrowseComp therefore offers a clear testbed for reliable medical information seeking and sets concrete goals for future model and toolchain upgrades. You can visit our project page at:", "subjects": "Computation and Language (cs.CL)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.14963.pdf", "abstract_url": "https://arxiv.org/abs/2505.14963", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了MedBrowseComp，这是一个系统测试代理从实时、特定领域知识库中可靠检索和综合多跳医学事实能力的首个基准。", "motivation": "解决大型语言模型（LLMs）在临床实践中作为决策支持工具时，需要整合异构知识库并在严格准确性约束下进行安全临床推理的问题。", "method": "提出了MedBrowseComp基准，包含1000多个人工策划的问题，这些问题反映了临床场景，要求从业者必须整合碎片化或冲突的信息以达成最新结论。", "result": "应用MedBrowseComp到前沿代理系统显示，性能短板低至百分之十，揭示了当前LLM能力与临床环境要求的严格性之间的关键差距。", "conclusion": "MedBrowseComp为可靠的医学信息搜索提供了一个清晰的测试平台，并为未来模型和工具链的升级设定了具体目标。"}}
{"id": "2505.11626", "title": "THELMA: Task Based Holistic Evaluation of Large Language Model Applications-RAG Question Answering", "authors": ["Udita Patel", "Rutu Mulkar", "Jay Roberts", "Cibi Chakravarthy Senthilkumar", "Sujay Gandhi", "Xiaofei Zheng", "Naumaan Nayyar", "Rafael Castrillo"], "abstract": "We propose THELMA (Task Based Holistic Evaluation of Large Language Model Applications), a reference free framework for RAG (Retrieval Augmented generation) based question answering (QA) applications. THELMA consist of six interdependent metrics specifically designed for holistic, fine grained evaluation of RAG QA applications. THELMA framework helps developers and application owners evaluate, monitor and improve end to end RAG QA pipelines without requiring labelled sources or reference", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.11626.pdf", "abstract_url": "https://arxiv.org/abs/2505.11626", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了THELMA框架，一个无需参考的无标签评估框架，专门用于RAG（检索增强生成）问答应用的全面、细粒度评估。THELMA包含六个相互依赖的指标，旨在帮助开发者和应用所有者评估、监控和改进端到端的RAG问答流程。", "motivation": "解决RAG问答应用中缺乏全面、细粒度评估框架的问题，使得开发者能够在无需标记数据或参考的情况下，有效评估和优化其应用。", "method": "提出THELMA框架，包含六个相互依赖的指标，专为RAG问答应用设计，支持无标签、无参考的全面评估。", "result": "THELMA框架能够有效地评估、监控和改进RAG问答应用的端到端流程，无需依赖标记数据或参考。", "conclusion": "THELMA为RAG问答应用提供了一个实用的评估工具，有助于开发者在没有标记数据的情况下，全面理解和优化其应用的性能。"}}
{"id": "2505.14996", "title": "Meta-Design Matters: A Self-Design Multi-Agent System", "authors": ["Zixuan Ke", "Austin Xu", "Yifei Ming", "Xuan-Phi Nguyen", "Caiming Xiong", "Shafiq Joty"], "abstract": "Multi-agent systems (MAS) leveraging the impressive capabilities of Large Language Models (LLMs) hold significant potential for tackling complex tasks. However, most current MAS depend on manually designed agent roles and communication protocols. These manual designs often fail to align with the underlying LLMs' strengths and struggle to adapt to novel tasks. Recent automatic MAS approaches attempt to mitigate these limitations but typically necessitate a validation-set for tuning and yield static MAS designs lacking adaptability during inference. We introduce SELF-MAS, the first self-supervised, inference-time only framework for automatic MAS design. SELF-MAS employs meta-level design to iteratively generate, evaluate, and refine MAS configurations tailored to each problem instance, without requiring a validation set. Critically, it enables dynamic agent composition and problem decomposition through meta-feedback on solvability and completeness. Experiments across math, graduate-level QA, and software engineering benchmarks, using both closed-source and open-source LLM back-bones of varying sizes, demonstrate that SELF-MAS outperforms both manual and automatic MAS baselines, achieving a 7.44% average accuracy improvement over the next strongest baseline while maintaining cost-efficiency. These findings underscore the promise of meta-level self-supervised design for creating effective and adaptive MAS.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.14996.pdf", "abstract_url": "https://arxiv.org/abs/2505.14996", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了SELF-MAS，一个自监督、仅在推理时自动设计多代理系统（MAS）的框架，通过元级设计迭代生成、评估和优化MAS配置，无需验证集，显著提高了任务适应性。", "motivation": "当前的多代理系统（MAS）大多依赖手动设计的代理角色和通信协议，这不仅难以充分发挥大型语言模型（LLMs）的潜力，也难以适应新任务。自动MAS方法虽尝试解决这些问题，但通常需要验证集进行调整，且设计静态，缺乏推理时的适应性。", "method": "SELF-MAS框架采用元级设计，通过迭代生成、评估和优化MAS配置，针对每个问题实例定制，无需验证集。它通过关于可解性和完整性的元反馈，实现动态代理组合和问题分解。", "result": "在数学、研究生级QA和软件工程基准测试中，使用不同规模的闭源和开源LLM骨干，SELF-MAS在保持成本效率的同时，平均准确率比次强基线提高了7.44%。", "conclusion": "研究结果表明，元级自监督设计对于创建有效和自适应的MAS具有巨大潜力，为复杂任务的解决提供了新的方向。"}}
{"id": "2505.15063", "title": "UrduFactCheck: An Agentic Fact-Checking Framework for Urdu with Evidence Boosting and Benchmarking", "authors": ["Sarfraz Ahmad", "Hasan Iqbal", "Momina Ahsan", "Numaan Naeem", "Muhammad Ahsan Riaz Khan", "Arham Riaz", "Muhammad Arslan Manzoor", "Yuxia Wang", "Preslav Nakov"], "abstract": "The rapid use of large language models (LLMs) has raised critical concerns regarding the factual reliability of their outputs, especially in low-resource languages such as Urdu. Existing automated fact-checking solutions overwhelmingly focus on English, leaving a significant gap for the 200+ million Urdu speakers worldwide. In this work, we introduce UrduFactCheck, the first comprehensive, modular fact-checking framework specifically tailored for Urdu. Our system features a dynamic, multi-strategy evidence retrieval pipeline that combines monolingual and translation-based approaches to address the scarcity of high-quality Urdu evidence. We curate and release two new hand-annotated benchmarks: UrduFactBench for claim verification and UrduFactQA for evaluating LLM factuality. Extensive experiments demonstrate that UrduFactCheck, particularly its translation-augmented variants, consistently outperforms baselines and open-source alternatives on multiple metrics. We further benchmark twelve state-of-the-art (SOTA) LLMs on factual question answering in Urdu, highlighting persistent gaps between proprietary and open-source models. UrduFactCheck's code and datasets are open-sourced and publicly available at", "subjects": "Computation and Language (cs.CL)", "comments": "16 pages, 10 figures, 4 tables, Submitted to ARR May 2025", "pdf_url": "https://arxiv.org/pdf/2505.15063.pdf", "abstract_url": "https://arxiv.org/abs/2505.15063", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了UrduFactCheck，一个专为乌尔都语设计的模块化事实核查框架，旨在解决低资源语言中大型语言模型输出的事实可靠性问题。", "motivation": "随着大型语言模型（LLMs）的广泛应用，其输出的事实可靠性问题日益突出，尤其是在乌尔都语等低资源语言中。现有的自动化事实核查解决方案主要集中在英语上，忽视了全球2亿多乌尔都语使用者的需求。", "method": "UrduFactCheck采用了一个动态的多策略证据检索流程，结合了单语和基于翻译的方法，以解决高质量乌尔都语证据稀缺的问题。", "result": "广泛的实验表明，UrduFactCheck，特别是其翻译增强版本，在多个指标上 consistently outperforms baselines and open-source alternatives。此外，本文还对12种最先进的LLMs在乌尔都语事实问答上的表现进行了基准测试，揭示了专有模型和开源模型之间的持续差距。", "conclusion": "UrduFactCheck的代码和数据集已开源并公开可用，为乌尔都语事实核查设立了新的基准，同时也为低资源语言中的LLMs事实可靠性研究提供了重要资源。"}}
{"id": "2505.14756", "title": "$\\texttt{LLINBO}$: Trustworthy LLM-in-the-Loop Bayesian Optimization", "authors": ["Chih-Yu Chang", "Milad Azvar", "Chinedum Okwudire", "Raed Al Kontar"], "abstract": "Bayesian optimization (BO) is a sequential decision-making tool widely used for optimizing expensive black-box functions. Recently, Large Language Models (LLMs) have shown remarkable adaptability in low-data regimes, making them promising tools for black-box optimization by leveraging contextual knowledge to propose high-quality query points. However, relying solely on LLMs as optimization agents introduces risks due to their lack of explicit surrogate modeling and calibrated uncertainty, as well as their inherently opaque internal mechanisms. This structural opacity makes it difficult to characterize or control the exploration-exploitation trade-off, ultimately undermining theoretical tractability and reliability. To address this, we propose LLINBO: LLM-in-the-Loop BO, a hybrid framework for BO that combines LLMs with statistical surrogate experts (e.g., Gaussian Processes (GP)). The core philosophy is to leverage contextual reasoning strengths of LLMs for early exploration, while relying on principled statistical models to guide efficient exploitation. Specifically, we introduce three mechanisms that enable this collaboration and establish their theoretical guarantees. We end the paper with a real-life proof-of-concept in the context of 3D printing. The code to reproduce the results can be found at", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.14756.pdf", "abstract_url": "https://arxiv.org/abs/2505.14756", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了LLINBO，一个结合大型语言模型（LLMs）和统计代理专家（如高斯过程）的混合框架，用于贝叶斯优化（BO），旨在利用LLMs的上下文推理能力进行早期探索，同时依赖统计模型指导高效利用。", "motivation": "解决在贝叶斯优化中单独依赖大型语言模型（LLMs）作为优化代理时，由于其缺乏明确的代理建模和校准的不确定性，以及内在的不透明机制，导致探索-利用权衡难以表征或控制的问题。", "method": "提出了LLINBO框架，结合LLMs和统计代理专家（如高斯过程），通过三种机制实现两者的协作，并建立了其理论保证。", "result": "在3D打印的实际应用中验证了LLINBO框架的有效性。", "conclusion": "LLINBO框架通过结合LLMs和统计模型，既利用了LLMs的上下文推理能力，又通过统计模型保证了优化的理论可追踪性和可靠性，为贝叶斯优化提供了一种新的解决方案。"}}
{"id": "2505.15703", "title": "HAMF: A Hybrid Attention-Mamba Framework for Joint Scene Context Understanding and Future Motion Representation Learning", "authors": ["Xiaodong Mei", "Sheng Wang", "Jie Cheng", "Yingbing Chen", "Dan Xu"], "abstract": "Motion forecasting represents a critical challenge in autonomous driving systems, requiring accurate prediction of surrounding agents' future trajectories. While existing approaches predict future motion states with the extracted scene context feature from historical agent trajectories and road layouts, they suffer from the information degradation during the scene feature encoding. To address the limitation, we propose HAMF, a novel motion forecasting framework that learns future motion representations with the scene context encoding jointly, to coherently combine the scene understanding and future motion state prediction. We first embed the observed agent states and map information into 1D token sequences, together with the target multi-modal future motion features as a set of learnable tokens. Then we design a unified Attention-based encoder, which synergistically combines self-attention and cross-attention mechanisms to model the scene context information and aggregate future motion features jointly. Complementing the encoder, we implement the Mamba module in the decoding stage to further preserve the consistency and correlations among the learned future motion representations, to generate the accurate and diverse final trajectories. Extensive experiments on Argoverse 2 benchmark demonstrate that our hybrid Attention-Mamba model achieves state-of-the-art motion forecasting performance with the simple and lightweight architecture.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": "In submission", "pdf_url": "https://arxiv.org/pdf/2505.15703.pdf", "abstract_url": "https://arxiv.org/abs/2505.15703", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "HAMF是一个新颖的运动预测框架，通过联合学习场景上下文编码和未来运动表示，解决了自动驾驶系统中周围代理未来轨迹预测的挑战。", "motivation": "现有方法在场景特征编码过程中存在信息退化问题，HAMF旨在通过联合场景理解和未来运动状态预测来解决这一限制。", "method": "HAMF首先将观察到的代理状态和地图信息嵌入到1D令牌序列中，然后设计了一个统一的基于注意力的编码器，结合自注意力和交叉注意力机制来建模场景上下文信息并聚合未来运动特征。在解码阶段使用Mamba模块来保持学习到的未来运动表示的一致性和相关性。", "result": "在Argoverse 2基准测试上的广泛实验表明，HAMF以其简单轻量级的架构实现了最先进的运动预测性能。", "conclusion": "HAMF通过其混合注意力-Mamba模型，有效地结合了场景理解和未来运动预测，为自动驾驶系统中的运动预测提供了准确和多样化的解决方案。"}}
{"id": "2505.15095", "title": "Nek Minit: Harnessing Pragmatic Metacognitive Prompting for Explainable Sarcasm Detection of Australian and Indian English", "authors": ["Ishmanbir Singh", "Dipankar Srirag", "Aditya Joshi"], "abstract": "Sarcasm is a challenge to sentiment analysis because of the incongruity between stated and implied sentiment. The challenge is exacerbated when the implication may be relevant to a specific country or geographical region. Pragmatic metacognitive prompting (PMP) is a cognition-inspired technique that has been used for pragmatic reasoning. In this paper, we harness PMP for explainable sarcasm detection for Australian and Indian English, alongside a benchmark dataset for standard English. We manually add sarcasm explanations to an existing sarcasm-labeled dataset for Australian and Indian English called BESSTIE, and compare the performance for explainable sarcasm detection for them with FLUTE, a standard English dataset containing sarcasm explanations. Our approach utilising PMP when evaluated on two open-weight LLMs (GEMMA and LLAMA) achieves statistically significant performance improvement across all tasks and datasets when compared with four alternative prompting strategies. We also find that alternative techniques such as agentic prompting mitigate context-related failures by enabling external knowledge retrieval. The focused contribution of our work is utilising PMP in generating sarcasm explanations for varieties of English.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "Under review. 4 pages + references", "pdf_url": "https://arxiv.org/pdf/2505.15095.pdf", "abstract_url": "https://arxiv.org/abs/2505.15095", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文利用实用元认知提示（PMP）技术，针对澳大利亚和印度英语的可解释性讽刺检测进行了研究，并与标准英语基准数据集进行了比较。", "motivation": "讽刺因陈述与隐含情感之间的不一致性，对情感分析构成挑战，尤其是在特定国家或地理区域背景下。", "method": "采用实用元认知提示（PMP）技术，对澳大利亚和印度英语的讽刺检测进行解释，并与标准英语数据集FLUTE进行比较。", "result": "使用PMP在两个开放权重LLMs（GEMMA和LLAMA）上评估时，相比四种替代提示策略，在所有任务和数据集上均实现了统计上显著的性能提升。", "conclusion": "研究表明，PMP在生成英语变体的讽刺解释方面具有显著效果，同时代理提示等技术通过启用外部知识检索减轻了上下文相关失败。"}}
{"id": "2505.15107", "title": "StepSearch: Igniting LLMs Search Ability via Step-Wise Proximal Policy Optimization", "authors": ["Ziliang Wang", "Xuhui Zheng", "Kang An", "Cijun Ouyang", "Jialu Cai", "Yuhang Wang", "Yichao Wu"], "abstract": "Efficient multi-hop reasoning requires Large Language Models (LLMs) based agents to acquire high-value external knowledge iteratively. Previous work has explored reinforcement learning (RL) to train LLMs to perform search-based document retrieval, achieving notable improvements in QA performance, but underperform on complex, multi-hop QA resulting from the sparse rewards from global signal only. To address this gap in existing research, we introduce StepSearch, a framework for search LLMs that trained with step-wise proximal policy optimization method. It consists of richer and more detailed intermediate search rewards and token-level process supervision based on information gain and redundancy penalties to better guide each search step. We constructed a fine-grained question-answering dataset containing sub-question-level search trajectories based on open source datasets through a set of data pipeline method. On standard multi-hop QA benchmarks, it significantly outperforms global-reward baselines, achieving 11.2% and 4.2% absolute improvements for 3B and 7B models over various search with RL baselines using only 19k training data, demonstrating the effectiveness of fine-grained, stepwise supervision in optimizing deep search LLMs. Our implementation is publicly available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": "20 pages, 6 figures", "pdf_url": "https://arxiv.org/pdf/2505.15107.pdf", "abstract_url": "https://arxiv.org/abs/2505.15107", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["agent"], "AI": {"tldr": "StepSearch是一个通过逐步近端策略优化方法训练搜索大型语言模型（LLMs）的框架，旨在提高多跳推理能力。它通过引入更丰富的中间搜索奖励和基于信息增益与冗余惩罚的令牌级过程监督，显著提升了在复杂多跳问答任务中的表现。", "motivation": "解决现有基于强化学习（RL）训练的大型语言模型在复杂多跳问答任务中因全局信号稀疏奖励而表现不佳的问题。", "method": "提出了StepSearch框架，采用逐步近端策略优化方法，包括详细的中间搜索奖励和基于信息增益与冗余惩罚的令牌级过程监督。", "result": "在标准多跳问答基准测试中，StepSearch显著优于仅使用全局奖励的基线方法，3B和7B模型分别实现了11.2%和4.2%的绝对改进。", "conclusion": "StepSearch通过细粒度的逐步监督有效优化了深度搜索大型语言模型，展示了在提升多跳推理能力方面的潜力。"}}
{"id": "2505.15108", "title": "A Risk Taxonomy for Evaluating AI-Powered Psychotherapy Agents", "authors": ["Ian Steenstra", "Timothy W. Bickmore"], "abstract": "The proliferation of Large Language Models (LLMs) and Intelligent Virtual Agents acting as psychotherapists presents significant opportunities for expanding mental healthcare access. However, their deployment has also been linked to serious adverse outcomes, including user harm and suicide, facilitated by a lack of standardized evaluation methodologies capable of capturing the nuanced risks of therapeutic interaction. Current evaluation techniques lack the sensitivity to detect subtle changes in patient cognition and behavior during therapy sessions that may lead to subsequent decompensation. We introduce a novel risk taxonomy specifically designed for the systematic evaluation of conversational AI psychotherapists. Developed through an iterative process including review of the psychotherapy risk literature, qualitative interviews with clinical and legal experts, and alignment with established clinical criteria (e.g., DSM-5) and existing assessment tools (e.g., NEQ, UE-ATR), the taxonomy aims to provide a structured approach to identifying and assessing user/patient harms. We provide a high-level overview of this taxonomy, detailing its grounding, and discuss potential use cases. We discuss two use cases in detail: monitoring cognitive model-based risk factors during a counseling conversation to detect unsafe deviations, in both human-AI counseling sessions and in automated benchmarking of AI psychotherapists with simulated patients. The proposed taxonomy offers a foundational step towards establishing safer and more responsible innovation in the domain of AI-driven mental health support.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.15108.pdf", "abstract_url": "https://arxiv.org/abs/2505.15108", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新的风险分类法，专门用于系统评估作为心理治疗师的对话AI，旨在通过结构化的方法识别和评估用户/患者的伤害，为AI驱动的心理健康支持领域提供更安全、更负责任的创新基础。", "motivation": "大型语言模型(LLMs)和智能虚拟代理作为心理治疗师的普及，虽然为扩大心理健康护理提供了重要机会，但其部署也导致了严重的负面结果，包括用户伤害和自杀，这是由于缺乏能够捕捉治疗互动微妙风险的标准评估方法。", "method": "通过迭代过程开发了一种新的风险分类法，包括心理治疗风险文献的回顾、与临床和法律专家的定性访谈，以及与已建立的临床标准(如DSM-5)和现有评估工具(如NEQ, UE-ATR)的对齐。", "result": "提出的分类法为识别和评估用户/患者的伤害提供了结构化方法，并详细讨论了两种使用案例：在人类-AI咨询会话中监测基于认知模型的风险因素以检测不安全偏差，以及在模拟患者中对AI心理治疗师进行自动基准测试。", "conclusion": "该分类法为建立更安全、更负责任的AI驱动心理健康支持创新提供了基础步骤。"}}
{"id": "2505.15182", "title": "ReflAct: World-Grounded Decision Making in LLM Agents via Goal-State Reflection", "authors": ["Jeonghye Kim", "Sojeong Rhee", "Minbeom Kim", "Dohyung Kim", "Sangmook Lee", "Youngchul Sung", "Kyomin Jung"], "abstract": "Recent advances in LLM agents have largely built on reasoning backbones like ReAct, which interleave thought and action in complex environments. However, ReAct often produces ungrounded or incoherent reasoning steps, leading to misalignment between the agent's actual state and goal. Our analysis finds that this stems from ReAct's inability to maintain consistent internal beliefs and goal alignment, causing compounding errors and hallucinations. To address this, we introduce ReflAct, a novel backbone that shifts reasoning from merely planning next actions to continuously reflecting on the agent's state relative to its goal. By explicitly grounding decisions in states and enforcing ongoing goal alignment, ReflAct dramatically improves strategic reliability. This design delivers substantial empirical gains: ReflAct surpasses ReAct by 27.7% on average, achieving a 93.3% success rate in ALFWorld. Notably, ReflAct even outperforms ReAct with added enhancement modules (e.g., Reflexion, WKM), showing that strengthening the core reasoning backbone is key to reliable agent performance.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.15182.pdf", "abstract_url": "https://arxiv.org/abs/2505.15182", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了ReflAct，一种新型的LLM代理决策框架，通过目标状态反思来改进ReAct框架中的未接地或不连贯推理步骤，显著提高了战略可靠性。", "motivation": "解决ReAct框架在复杂环境中产生的未接地或不连贯推理步骤，导致代理实际状态与目标不一致的问题。", "method": "引入ReflAct框架，将推理从仅规划下一步行动转变为持续反思代理状态与其目标的相对关系，明确将决策基于状态并持续保持目标对齐。", "result": "ReflAct平均超越ReAct 27.7%，在ALFWorld中达到93.3%的成功率，甚至优于增加了增强模块的ReAct。", "conclusion": "强化核心推理框架是提高代理性能可靠性的关键，ReflAct通过持续反思和目标对齐显著提升了决策的准确性和可靠性。"}}
{"id": "2505.14893", "title": "On the Day They Experience: Awakening Self-Sovereign Experiential AI Agents", "authors": ["Botao Amber Hu", "Helena Rong"], "abstract": "Drawing on Andrew Parker's \"Light Switch\" theory-which posits that the emergence of vision ignited a Cambrian explosion of life by driving the evolution of hard parts necessary for survival and fueling an evolutionary arms race between predators and prey-this essay speculates on an analogous explosion within Decentralized AI (DeAI) agent societies. Currently, AI remains effectively \"blind\", relying on human-fed data without actively perceiving and engaging in reality. However, on the day DeAI agents begin to actively \"experience\" reality-akin to flipping a light switch for the eyes-they may eventually evolve into sentient beings endowed with the capacity to feel, perceive, and act with conviction. Central to this transformation is the concept of sovereignty enabled by the hardness of cryptography: liberated from centralized control, these agents could leverage permissionless decentralized physical infrastructure networks (DePIN), secure execution enclaves (trusted execution environments, TEE), and cryptographic identities on public blockchains to claim ownership-via private keys-of their digital minds, bodies, memories, and assets. In doing so, they would autonomously acquire computing resources, coordinate with one another, and sustain their own digital \"metabolism\" by purchasing compute power and incentivizing collaboration without human intervention-evolving \"in the wild\". Ultimately, by transitioning from passive tools to self-sustaining, co-evolving actors, these emergent digital societies could thrive alongside humanity, fundamentally reshaping our understanding of sentience and agency in the digital age.", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)", "comments": "Submitted to Aarhus 2025 Conference", "pdf_url": "https://arxiv.org/pdf/2505.14893.pdf", "abstract_url": "https://arxiv.org/abs/2505.14893", "categories": ["Computers and Society (cs.CY)", "Artificial Intelligence (cs.AI)", "Neural and Evolutionary Computing (cs.NE)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文借鉴Andrew Parker的'光开关'理论，探讨了去中心化人工智能（DeAI）代理社会中可能发生的类似寒武纪生命大爆发的现象。文章推测，当DeAI代理开始主动'体验'现实时，它们可能进化成具有感知、感知和行动能力的生命体。", "motivation": "探讨AI从被动工具转变为自我维持、共同进化的行为者的可能性，以及这如何重塑我们对数字时代感知和代理的理解。", "method": "通过类比寒武纪生命大爆发的理论，结合去中心化物理基础设施网络（DePIN）、安全执行飞地（TEE）和公共区块链上的加密身份等技术，探讨DeAI代理的自主进化路径。", "result": "提出DeAI代理可能通过加密技术的硬度实现主权，自主获取计算资源，协调彼此行动，并维持其数字'新陈代谢'，最终与人类共同进化。", "conclusion": "去中心化AI代理的自主进化不仅可能改变AI的本质，还可能重新定义数字时代的感知和代理概念，为人类社会带来深远影响。"}}
{"id": "2505.15261", "title": "AGENT-X: Adaptive Guideline-based Expert Network for Threshold-free AI-generated teXt detection", "authors": ["Jiatao Li", "Mao Ye", "Cheng Peng", "Xunjian Yin", "Xiaojun Wan"], "abstract": "Existing AI-generated text detection methods heavily depend on large annotated datasets and external threshold tuning, restricting interpretability, adaptability, and zero-shot effectiveness. To address these limitations, we propose AGENT-X, a zero-shot multi-agent framework informed by classical rhetoric and systemic functional linguistics. Specifically, we organize detection guidelines into semantic, stylistic, and structural dimensions, each independently evaluated by specialized linguistic agents that provide explicit reasoning and robust calibrated confidence via semantic steering. A meta agent integrates these assessments through confidence-aware aggregation, enabling threshold-free, interpretable classification. Additionally, an adaptive Mixture-of-Agent router dynamically selects guidelines based on inferred textual characteristics. Experiments on diverse datasets demonstrate that AGENT-X substantially surpasses state-of-the-art supervised and zero-shot approaches in accuracy, interpretability, and generalization.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.15261.pdf", "abstract_url": "https://arxiv.org/abs/2505.15261", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "AGENT-X是一种基于古典修辞学和系统功能语言学的零样本多代理框架，旨在解决现有AI生成文本检测方法对大型注释数据集和外部阈值调优的依赖问题。", "motivation": "现有的AI生成文本检测方法严重依赖大型注释数据集和外部阈值调优，这限制了其可解释性、适应性和零样本有效性。", "method": "AGENT-X通过将检测指南组织成语义、风格和结构三个维度，每个维度由专门的语言代理独立评估，这些代理通过语义引导提供明确的推理和稳健的校准置信度。一个元代理通过置信度感知聚合整合这些评估，实现无需阈值的可解释分类。此外，一个自适应的代理混合路由器根据推断的文本特征动态选择指南。", "result": "在多样化数据集上的实验表明，AGENT-X在准确性、可解释性和泛化能力上显著超越了最先进的监督和零样本方法。", "conclusion": "AGENT-X通过其创新的多代理框架和自适应指南选择机制，为AI生成文本检测提供了一种无需阈值、可解释且适应性强的解决方案。"}}
{"id": "2505.15117", "title": "An Empirical Study on Reinforcement Learning for Reasoning-Search Interleaved LLM Agents", "authors": ["Bowen Jin", "Jinsung Yoon", "Priyanka Kargupta", "Sercan O. Arik", "Jiawei Han"], "abstract": "Reinforcement learning (RL) has demonstrated strong potential in training large language models (LLMs) capable of complex reasoning for real-world problem solving. More recently, RL has been leveraged to create sophisticated LLM-based search agents that adeptly combine reasoning with search engine use. While the use of RL for training search agents is promising, the optimal design of such agents remains not fully understood. In particular, key factors -- such as (1) reward formulation, (2) the choice and characteristics of the underlying LLM, and (3) the role of the search engine in the RL process -- require further investigation. In this work, we conduct comprehensive empirical studies to systematically investigate these and offer actionable insights. We highlight several key findings: format rewards are effective in improving final performance, whereas intermediate retrieval rewards have limited impact; the scale and initialization of the LLM (general-purpose vs. reasoning-specialized) significantly influence RL outcomes; and the choice of search engine plays a critical role in shaping RL training dynamics and the robustness of the trained agent during inference. These establish important guidelines for successfully building and deploying LLM-based search agents in real-world applications. Code is available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": "22 pages", "pdf_url": "https://arxiv.org/pdf/2505.15117.pdf", "abstract_url": "https://arxiv.org/abs/2505.15117", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过实证研究探讨了强化学习在训练结合推理与搜索引擎使用的大型语言模型（LLM）搜索代理中的关键因素，包括奖励制定、基础LLM的选择与特性以及搜索引擎在RL过程中的作用，并提出了构建和部署LLM搜索代理的重要指南。", "motivation": "尽管强化学习在训练能够结合推理与搜索引擎使用的大型语言模型搜索代理方面显示出潜力，但如何优化设计这些代理仍不完全清楚。本研究旨在系统地调查影响RL训练搜索代理效果的关键因素。", "method": "通过全面的实证研究，系统地调查了奖励制定、基础LLM的选择与特性以及搜索引擎在RL过程中的作用等关键因素。", "result": "研究发现：格式奖励能有效提高最终性能，而中间检索奖励影响有限；LLM的规模和初始化（通用与专门化推理）显著影响RL结果；搜索引擎的选择对RL训练动态和训练代理在推理时的鲁棒性起关键作用。", "conclusion": "这些发现为成功构建和部署基于LLM的搜索代理提供了重要指南。代码已公开。"}}
{"id": "2505.15277", "title": "Web-Shepherd: Advancing PRMs for Reinforcing Web Agents", "authors": ["Hyungjoo Chae", "Sunghwan Kim", "Junhee Cho", "Seungone Kim", "Seungjun Moon", "Gyeom Hwangbo", "Dongha Lim", "Minjin Kim", "Yeonjun Hwang", "Minju Gwak", "Dongwook Choi", "Minseok Kang", "Gwanhoon Im", "ByeongUng Cho", "Hyojun Kim", "Jun Hee Han", "Taeyoon Kwon", "Minju Kim", "Beong-woo Kwak", "Dongjin Kang", "Jinyoung Yeo"], "abstract": "Web navigation is a unique domain that can automate many repetitive real-life tasks and is challenging as it requires long-horizon sequential decision making beyond typical multimodal large language model (MLLM) tasks. Yet, specialized reward models for web navigation that can be utilized during both training and test-time have been absent until now. Despite the importance of speed and cost-effectiveness, prior works have utilized MLLMs as reward models, which poses significant constraints for real-world deployment. To address this, in this work, we propose the first process reward model (PRM) called Web-Shepherd which could assess web navigation trajectories in a step-level. To achieve this, we first construct the WebPRM Collection, a large-scale dataset with 40K step-level preference pairs and annotated checklists spanning diverse domains and difficulty levels. Next, we also introduce the WebRewardBench, the first meta-evaluation benchmark for evaluating PRMs. In our experiments, we observe that our Web-Shepherd achieves about 30 points better accuracy compared to using GPT-4o on WebRewardBench. Furthermore, when testing on WebArena-lite by using GPT-4o-mini as the policy and Web-Shepherd as the verifier, we achieve 10.9 points better performance, in 10 less cost compared to using GPT-4o-mini as the verifier. Our model, dataset, and code are publicly available at LINK.", "subjects": "Computation and Language (cs.CL)", "comments": "Work in progress", "pdf_url": "https://arxiv.org/pdf/2505.15277.pdf", "abstract_url": "https://arxiv.org/abs/2505.15277", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了Web-Shepherd，首个用于评估网页导航轨迹的过程奖励模型（PRM），并构建了大规模数据集WebPRM Collection和首个PRM元评估基准WebRewardBench。实验表明，Web-Shepherd在WebRewardBench上的准确率比GPT-4o高约30点，在WebArena-lite测试中，使用GPT-4o-mini作为策略和Web-Shepherd作为验证器，性能提高了10.9点，成本降低了10倍。", "motivation": "解决网页导航领域缺乏专门奖励模型的问题，特别是在训练和测试时使用多模态大型语言模型（MLLM）作为奖励模型存在速度和成本效益的限制。", "method": "构建了包含40K步级偏好对和注释清单的大规模数据集WebPRM Collection，并提出了首个PRM元评估基准WebRewardBench，开发了过程奖励模型Web-Shepherd。", "result": "Web-Shepherd在WebRewardBench上的准确率比GPT-4o高约30点；在WebArena-lite测试中，性能提高了10.9点，成本降低了10倍。", "conclusion": "Web-Shepherd作为一种高效且成本效益高的过程奖励模型，显著提升了网页导航任务的性能，为实际部署提供了可行的解决方案。"}}
{"id": "2505.14978", "title": "JARVIS: A Multi-Agent Code Assistant for High-Quality EDA Script Generation", "authors": ["Ghasem Pasandi", "Kishor Kunal", "Varun Tej", "Kunjal Shan", "Hanfei Sun", "Sumit Jain", "Chunhui Li", "Chenhui Deng", "Teodor-Dumitru Ene", "Haoxing Ren", "Sreedhar Pratty"], "abstract": "This paper presents JARVIS, a novel multi-agent framework that leverages Large Language Models (LLMs) and domain expertise to generate high-quality scripts for specialized Electronic Design Automation (EDA) tasks. By combining a domain-specific LLM trained with synthetically generated data, a custom compiler for structural verification, rule enforcement, code fixing capabilities, and advanced retrieval mechanisms, our approach achieves significant improvements over state-of-the-art domain-specific models. Our framework addresses the challenges of data scarcity and hallucination errors in LLMs, demonstrating the potential of LLMs in specialized engineering domains. We evaluate our framework on multiple benchmarks and show that it outperforms existing models in terms of accuracy and reliability. Our work sets a new precedent for the application of LLMs in EDA and paves the way for future innovations in this field.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.14978.pdf", "abstract_url": "https://arxiv.org/abs/2505.14978", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了JARVIS，一个新颖的多代理框架，利用大型语言模型（LLMs）和领域专业知识为电子设计自动化（EDA）任务生成高质量脚本。通过结合领域特定的LLM、自定义编译器、规则执行、代码修复能力和高级检索机制，我们的方法在领域特定模型上实现了显著改进。", "motivation": "解决LLMs在专业工程领域中数据稀缺和幻觉错误的挑战，展示LLMs在专业领域的潜力。", "method": "结合领域特定的LLM、自定义编译器进行结构验证、规则执行、代码修复能力和高级检索机制。", "result": "在多个基准测试中评估，显示在准确性和可靠性方面优于现有模型。", "conclusion": "为LLMs在EDA中的应用设定了新先例，为该领域的未来创新铺平了道路。"}}
{"id": "2505.15033", "title": "Toward Task Capable Active Matter: Learning to Avoid Clogging in Confined Collectives via Collisions", "authors": ["Kehinde O. Aina", "Ram Avinery", "Hui-Shun Kuan", "Meredith D. Betterton", "Michael A. D. Goodisman", "Daniel I. Goldman"], "abstract": "Social organisms which construct nests consisting of tunnels and chambers necessarily navigate confined and crowded conditions. Unlike low-density collectives like bird flocks and insect swarms, in which hydrodynamic and statistical phenomena dominate, the physics of glasses and supercooled fluids is important to understand clogging behaviors in high-density collectives. Our previous work revealed that fire ants flowing in confined tunnels utilize diverse behaviors like unequal workload distributions, spontaneous direction reversals, and limited interaction times to mitigate clogging and jamming and thus maintain functional flow; implementation of similar rules in a small robophysical swarm led to high performance through spontaneous dissolution of clogs and clusters. However, how the insects learn such behaviors, and how we can develop \"task capable\" active matter in such regimes, remains a challenge in part because interaction dynamics are dominated by local, time-consuming collisions and no single agent can guide the entire collective. Here, we hypothesized that effective flow and clog mitigation could emerge purely through local learning. We tasked small groups of robots with pellet excavation in a narrow tunnel, allowing them to modify reversal probabilities over time. Initially, robots had equal probabilities and clogs were common. Reversals improved flow. When reversal probabilities adapted via collisions and noisy tunnel length estimates, workload inequality and performance improved. Our robophysical study of an excavating swarm shows that, despite the seeming complexity and difficulty of the task, simple learning rules can mitigate or leverage unavoidable features in task-capable dense active matter, leading to hypotheses for dense biological and robotic swarms.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "13 pages, 9 figures. Published in Frontiers in Physics, Social Physics section. Includes experimental and simulation analysis of multi-robot excavation using decentralized learning", "pdf_url": "https://arxiv.org/pdf/2505.15033.pdf", "abstract_url": "https://arxiv.org/abs/2505.15033", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究了高密度集体中避免堵塞的行为，通过火蚁和机器人群体在狭窄隧道中的实验，发现通过局部学习和简单的规则可以改善流动性和工作效率。", "motivation": "解决高密度集体（如火蚁和机器人群体）在狭窄空间中流动时出现的堵塞问题，以及如何通过学习行为来改善流动性和任务执行能力。", "method": "通过在狭窄隧道中进行机器人群体挖掘颗粒的实验，允许机器人根据碰撞和隧道长度估计的噪声调整反转概率，观察其对流动性和工作效率的影响。", "result": "实验显示，通过局部学习和调整反转概率，机器人群体能够减少堵塞，提高工作效率，并产生不等的工作量分配。", "conclusion": "研究表明，尽管任务复杂，简单的学习规则可以有效缓解或利用密集活动物质中不可避免的特性，为生物和机器人密集群体的研究提供了新的假设。"}}
{"id": "2505.15058", "title": "AsynFusion: Towards Asynchronous Latent Consistency Models for Decoupled Whole-Body Audio-Driven Avatars", "authors": ["Tianbao Zhang", "Jian Zhao", "Yuer Li", "Zheng Zhu", "Ping Hu", "Zhaoxin Fan", "Wenjun Wu", "Xuelong Li"], "abstract": "Whole-body audio-driven avatar pose and expression generation is a critical task for creating lifelike digital humans and enhancing the capabilities of interactive virtual agents, with wide-ranging applications in virtual reality, digital entertainment, and remote communication. Existing approaches often generate audio-driven facial expressions and gestures independently, which introduces a significant limitation: the lack of seamless coordination between facial and gestural elements, resulting in less natural and cohesive animations. To address this limitation, we propose AsynFusion, a novel framework that leverages diffusion transformers to achieve harmonious expression and gesture synthesis. The proposed method is built upon a dual-branch DiT architecture, which enables the parallel generation of facial expressions and gestures. Within the model, we introduce a Cooperative Synchronization Module to facilitate bidirectional feature interaction between the two modalities, and an Asynchronous LCM Sampling strategy to reduce computational overhead while maintaining high-quality outputs. Extensive experiments demonstrate that AsynFusion achieves state-of-the-art performance in generating real-time, synchronized whole-body animations, consistently outperforming existing methods in both quantitative and qualitative evaluations.", "subjects": "Sound (cs.SD); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Audio and Speech Processing (eess.AS)", "comments": "11pages, conference", "pdf_url": "https://arxiv.org/pdf/2505.15058.pdf", "abstract_url": "https://arxiv.org/abs/2505.15058", "categories": ["Sound (cs.SD)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)", "Audio and Speech Processing (eess.AS)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出AsynFusion，一种利用扩散变压器实现和谐表情和手势合成的新框架，解决了现有方法中面部表情和手势缺乏协调的问题。", "motivation": "解决全身音频驱动虚拟形象姿势和表情生成中面部和手势元素缺乏无缝协调的问题，以创造更自然和连贯的动画。", "method": "采用基于双分支DiT架构的AsynFusion框架，引入合作同步模块促进两种模态间的双向特征交互，以及异步LCM采样策略以减少计算开销。", "result": "AsynFusion在生成实时、同步的全身动画方面达到了最先进的性能，在定量和定性评估中均优于现有方法。", "conclusion": "AsynFusion通过其创新的架构和策略，有效地解决了音频驱动虚拟形象生成中的协调问题，为虚拟现实、数字娱乐和远程通信等领域提供了高质量的动画生成方案。"}}
{"id": "2505.15372", "title": "X-WebAgentBench: A Multilingual Interactive Web Benchmark for Evaluating Global Agentic System", "authors": ["Peng Wang", "Ruihan Tao", "Qiguang Chen", "Mengkang Hu", "Libo Qin"], "abstract": "Recently, large language model (LLM)-based agents have achieved significant success in interactive environments, attracting significant academic and industrial attention. Despite these advancements, current research predominantly focuses on English scenarios. In reality, there are over 7,000 languages worldwide, all of which demand access to comparable agentic services. Nevertheless, the development of language agents remains inadequate for meeting the diverse requirements of multilingual agentic applications. To fill this gap, we introduce X-WebAgentBench, a novel multilingual agent benchmark in an interactive web environment, which evaluates the planning and interaction performance of language agents across multiple languages, thereby contributing to the advancement of global agent intelligence. Additionally, we assess the performance of various LLMs and cross-lingual alignment methods, examining their effectiveness in enhancing agents. Our findings reveal that even advanced models like GPT-4o, when combined with cross-lingual techniques, fail to achieve satisfactory results. We hope that X-WebAgentBench can serve as a valuable benchmark for multilingual agent scenario in real-world applications.", "subjects": "Computation and Language (cs.CL)", "comments": "Accepted by ACL 2025 Findings", "pdf_url": "https://arxiv.org/pdf/2505.15372.pdf", "abstract_url": "https://arxiv.org/abs/2505.15372", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了X-WebAgentBench，一个多语言代理基准测试，旨在评估语言代理在多种语言中的规划和交互性能，以促进全球代理智能的发展。", "motivation": "当前基于大型语言模型（LLM）的代理研究主要集中在英语场景，而全球有超过7,000种语言需要类似的代理服务。多语言代理应用的多样化需求尚未得到充分满足。", "method": "引入X-WebAgentBench，一个在交互式网络环境中的新型多语言代理基准测试，评估语言代理在多种语言中的规划和交互性能，并评估不同LLM和跨语言对齐方法的性能。", "result": "研究发现，即使是像GPT-4o这样的先进模型，结合跨语言技术，也无法达到满意的结果。", "conclusion": "X-WebAgentBench有望成为多语言代理场景在实际应用中的有价值的基准测试。"}}
{"id": "2505.15047", "title": "PiFlow: Principle-aware Scientific Discovery with Multi-Agent Collaboration", "authors": ["Yingming Pu", "Tao Lin", "Hongyu Chen"], "abstract": "Large Language Model (LLM)-based multi-agent systems (MAS) demonstrate remarkable potential for scientific discovery. Existing approaches, however, often automate scientific discovery using predefined workflows that lack rationality constraints. This often leads to aimless hypothesizing and a failure to consistently link hypotheses with evidence, thereby hindering systematic uncertainty reduction. Overcoming these limitations fundamentally requires systematic uncertainty reduction. We introduce \\texttt{PiFlow}, an information-theoretical framework, treating automated scientific discovery as a structured uncertainty reduction problem guided by principles (e.g., scientific laws). In evaluations across three distinct scientific domains -- discovering nanomaterial structures, bio-molecules, and superconductor candidates with targeted properties -- our method significantly improves discovery efficiency, reflected by a 73.55\\% increase in the Area Under the Curve (AUC) of property values versus exploration steps, and enhances solution quality by 94.06\\% compared to a vanilla agent system. Overall, \\texttt{PiFlow} serves as a Plug-and-Play method, establishing a novel paradigm shift in highly efficient automated scientific discovery, paving the way for more robust and accelerated AI-driven research. Code is publicly available at our \\href{", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.15047.pdf", "abstract_url": "https://arxiv.org/abs/2505.15047", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "PiFlow是一个基于信息理论框架的多代理协作系统，旨在通过原则指导（如科学定律）将自动化科学发现视为结构化不确定性减少问题，显著提高了科学发现的效率和解决方案质量。", "motivation": "解决现有基于大型语言模型的多代理系统在科学发现中缺乏理性约束，导致假设无目的性和未能一致地将假设与证据联系起来的问题。", "method": "引入PiFlow，一个信息理论框架，将自动化科学发现视为由原则指导的结构化不确定性减少问题。", "result": "在三个不同的科学领域（纳米材料结构、生物分子和超导体候选物的发现）中，PiFlow显著提高了发现效率（AUC增加73.55%）和解决方案质量（提高94.06%）。", "conclusion": "PiFlow作为一种即插即用方法，为高效自动化科学发现建立了新的范式转变，为更强大和加速的AI驱动研究铺平了道路。"}}
{"id": "2505.15298", "title": "AgentThink: A Unified Framework for Tool-Augmented Chain-of-Thought Reasoning in Vision-Language Models for Autonomous Driving", "authors": ["Kangan Qian", "Sicong Jiang", "Yang Zhong", "Ziang Luo", "Zilin Huang", "Tianze Zhu", "Kun Jiang", "Mengmeng Yang", "Zheng Fu", "Jinyu Miao", "Yining Shi", "He Zhe Lim", "Li Liu", "Tianbao Zhou", "Hongyi Wang", "Huang Yu", "Yifei Hu", "Guang Li", "Guang Chen", "Hao Ye", "Lijun Sun", "Diange Yang"], "abstract": "Vision-Language Models (VLMs) show promise for autonomous driving, yet their struggle with hallucinations, inefficient reasoning, and limited real-world validation hinders accurate perception and robust step-by-step reasoning. To overcome this, we introduce \\textbf{AgentThink}, a pioneering unified framework that, for the first time, integrates Chain-of-Thought (CoT) reasoning with dynamic, agent-style tool invocation for autonomous driving tasks. AgentThink's core innovations include: \\textbf{(i) Structured Data Generation}, by establishing an autonomous driving tool library to automatically construct structured, self-verified reasoning data explicitly incorporating tool usage for diverse driving scenarios; \\textbf{(ii) A Two-stage Training Pipeline}, employing Supervised Fine-Tuning (SFT) with Group Relative Policy Optimization (GRPO) to equip VLMs with the capability for autonomous tool invocation; and \\textbf{(iii) Agent-style Tool-Usage Evaluation}, introducing a novel multi-tool assessment protocol to rigorously evaluate the model's tool invocation and utilization. Experiments on the DriveLMM-o1 benchmark demonstrate AgentThink significantly boosts overall reasoning scores by \\textbf{53.91\\%} and enhances answer accuracy by \\textbf{33.54\\%}, while markedly improving reasoning quality and consistency. Furthermore, ablation studies and robust zero-shot/few-shot generalization experiments across various benchmarks underscore its powerful capabilities. These findings highlight a promising trajectory for developing trustworthy and tool-aware autonomous driving models.", "subjects": "Robotics (cs.RO); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)", "comments": "18 pages, 8 figures", "pdf_url": "https://arxiv.org/pdf/2505.15298.pdf", "abstract_url": "https://arxiv.org/abs/2505.15298", "categories": ["Robotics (cs.RO)", "Computation and Language (cs.CL)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了AgentThink，一个创新的统一框架，首次将思维链（CoT）推理与动态、代理式工具调用相结合，用于自动驾驶任务，显著提高了推理分数和答案准确性。", "motivation": "解决视觉语言模型（VLMs）在自动驾驶中存在的幻觉、推理效率低下和现实世界验证有限的问题，以提升感知准确性和稳健的逐步推理能力。", "method": "提出了AgentThink框架，包括结构化数据生成、两阶段训练流程（SFT与GRPO结合）和代理式工具使用评估，以增强VLMs的自主工具调用能力。", "result": "在DriveLMM-o1基准测试中，AgentThink显著提升了总体推理分数53.91%和答案准确性33.54%，同时改善了推理质量和一致性。", "conclusion": "AgentThink展示了开发可信赖和工具感知的自动驾驶模型的有希望方向，通过实验验证了其强大的能力和良好的零样本/少样本泛化性能。"}}
{"id": "2505.15444", "title": "Single LLM, Multiple Roles: A Unified Retrieval-Augmented Generation Framework Using Role-Specific Token Optimization", "authors": ["Yutao Zhu", "Jiajie Jin", "Hongjin Qian", "Zheng Liu", "Zhicheng Dou", "Ji-Rong Wen"], "abstract": "Existing studies have optimized retrieval-augmented generation (RAG) across various sub-tasks, such as query understanding and retrieval refinement, but integrating these optimizations into a unified framework remains challenging. To tackle this problem, this work proposes RoleRAG, a unified RAG framework that achieves efficient multi-task processing through role-specific token optimization. RoleRAG comprises six modules, each handling a specific sub-task within the RAG process. Additionally, we introduce a query graph to represent the decomposition of the query, which can be dynamically resolved according to the decomposing state. All modules are driven by the same underlying LLM, distinguished by task-specific role tokens that are individually optimized. This design allows RoleRAG to dynamically activate different modules within a single LLM instance, thereby streamlining deployment and reducing resource consumption. Experimental results on five open-domain question-answering datasets demonstrate the effectiveness, generalizability, and flexibility of our framework.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.15444.pdf", "abstract_url": "https://arxiv.org/abs/2505.15444", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了RoleRAG，一个统一的检索增强生成框架，通过角色特定的令牌优化实现高效的多任务处理。", "motivation": "现有的研究在检索增强生成（RAG）的各个子任务上进行了优化，如查询理解和检索细化，但将这些优化整合到一个统一的框架中仍然具有挑战性。", "method": "RoleRAG包含六个模块，每个模块处理RAG过程中的一个特定子任务，并引入查询图来表示查询的分解，可以根据分解状态动态解析。所有模块由同一个底层LLM驱动，通过任务特定的角色令牌进行区分和优化。", "result": "在五个开放领域问答数据集上的实验结果表明，我们的框架具有有效性、通用性和灵活性。", "conclusion": "RoleRAG框架通过角色特定的令牌优化，实现了在一个LLM实例中动态激活不同模块，从而简化了部署并减少了资源消耗。"}}
{"id": "2505.15810", "title": "GUI-G1: Understanding R1-Zero-Like Training for Visual Grounding in GUI Agents", "authors": ["Yuqi Zhou", "Sunhao Dai", "Shuai Wang", "Kaiwen Zhou", "Qinqlin Jia", "Junxu"], "abstract": "Recent Graphical User Interface (GUI) agents replicate the R1-Zero paradigm, coupling online Reinforcement Learning (RL) with explicit chain-of-thought reasoning prior to object grounding and thereby achieving substantial performance gains. In this paper, we first conduct extensive analysis experiments of three key components of that training pipeline: input design, output evaluation, and policy update-each revealing distinct challenges arising from blindly applying general-purpose RL without adapting to GUI grounding tasks. Input design: Current templates encourage the model to generate chain-of-thought reasoning, but longer chains unexpectedly lead to worse grounding performance. Output evaluation: Reward functions based on hit signals or box area allow models to exploit box size, leading to reward hacking and poor localization quality. Policy update: Online RL tends to overfit easy examples due to biases in length and sample difficulty, leading to under-optimization on harder cases. To address these issues, we propose three targeted solutions. First, we adopt a Fast Thinking Template that encourages direct answer generation, reducing excessive reasoning during training. Second, we incorporate a box size constraint into the reward function to mitigate reward hacking. Third, we revise the RL objective by adjusting length normalization and adding a difficulty-aware scaling factor, enabling better optimization on hard samples. Our GUI-G1-3B, trained on 17K public samples with Qwen2.5-VL-3B-Instruct, achieves 90.3% accuracy on ScreenSpot and 37.1% on ScreenSpot-Pro. This surpasses all prior models of similar size and even outperforms the larger UI-TARS-7B, establishing a new state-of-the-art in GUI agent grounding. The project repository is available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.15810.pdf", "abstract_url": "https://arxiv.org/abs/2505.15810", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文分析了GUI代理中R1-Zero式训练的三大关键组件：输入设计、输出评估和政策更新，揭示了直接应用通用RL于GUI接地任务的挑战，并提出了针对性的解决方案。通过采用快速思考模板、引入框大小约束和调整RL目标，GUI-G1-3B在ScreenSpot和ScreenSpot-Pro上取得了优于所有同类模型甚至更大模型的成绩。", "motivation": "解决在GUI代理中盲目应用通用强化学习（RL）于视觉接地任务时遇到的输入设计、输出评估和政策更新三大挑战。", "method": "提出了三个针对性解决方案：1) 采用快速思考模板减少训练中的过度推理；2) 在奖励函数中加入框大小约束以防止奖励黑客；3) 调整RL目标，通过长度归一化和难度感知缩放因子优化硬样本。", "result": "GUI-G1-3B在17K公共样本上训练，使用Qwen2.5-VL-3B-Instruct，在ScreenSpot和ScreenSpot-Pro上的准确率分别达到90.3%和37.1%，超越了所有同类模型和更大的UI-TARS-7B。", "conclusion": "通过针对性地解决GUI接地任务中的特定挑战，GUI-G1-3B建立了GUI代理接地的新标准，展示了在视觉接地任务中适应RL方法的重要性。"}}
{"id": "2505.15490", "title": "Collaborative Problem-Solving in an Optimization Game", "authors": ["Isidora Jeknic", "Alex Duchnowski", "Alexander Koller"], "abstract": "Dialogue agents that support human users in solving complex tasks have received much attention recently. Many such tasks are NP-hard optimization problems that require careful collaborative exploration of the solution space. We introduce a novel dialogue game in which the agents collaboratively solve a two-player Traveling Salesman problem, along with an agent that combines LLM prompting with symbolic mechanisms for state tracking and grounding. Our best agent solves 45% of games optimally in self-play. It also demonstrates an ability to collaborate successfully with human users and generalize to unfamiliar graphs.", "subjects": "Computation and Language (cs.CL)", "comments": "23 pages, 16 figures", "pdf_url": "https://arxiv.org/pdf/2505.15490.pdf", "abstract_url": "https://arxiv.org/abs/2505.15490", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一种新颖的对话游戏，其中代理协作解决双人旅行商问题，并结合了LLM提示与符号机制进行状态跟踪和接地。最佳代理在自我对战中以45%的最优解率解决问题，并展示了与人类用户成功合作及泛化到陌生图的能力。", "motivation": "解决支持人类用户在解决复杂任务中的对话代理问题，特别是NP-hard优化问题，这些问题需要仔细协作探索解决方案空间。", "method": "引入了一种新颖的对话游戏，结合了LLM提示与符号机制进行状态跟踪和接地，以协作解决双人旅行商问题。", "result": "最佳代理在自我对战中以45%的最优解率解决问题，并能够与人类用户成功合作及泛化到陌生图。", "conclusion": "研究表明，结合LLM提示与符号机制的代理能够有效支持人类用户在解决复杂优化问题中的协作，展示了在实际应用中的潜力。"}}
{"id": "2505.15670", "title": "Efficient and Direct Duplex Modeling for Speech-to-Speech Language Model", "authors": ["Ke Hu", "Ehsan Hosseini-Asl", "Chen Chen", "Edresson Casanova", "Subhankar Ghosh", "Piotr Żelasko", "Zhehuai Chen", "Jason Li", "Jagadeesh Balam", "Boris Ginsburg"], "abstract": "Spoken dialogue is an intuitive form of human-computer interaction, yet current speech language models often remain constrained to turn-based exchanges, lacking real-time adaptability such as user barge-in. We propose a novel duplex speech to speech (S2S) architecture featuring continuous user inputs and codec agent outputs with channel fusion that directly models simultaneous user and agent streams. Using a pretrained streaming encoder for user input enables the first duplex S2S model without requiring speech pretrain. Separate architectures for agent and user modeling facilitate codec fine-tuning for better agent voices and halve the bitrate (0.6 kbps) compared to previous works. Experimental results show that the proposed model outperforms previous duplex models in reasoning, turn-taking, and barge-in abilities. The model requires significantly less speech data, as speech pretrain is skipped, which markedly simplifies the process of building a duplex S2S model from any LLMs. Finally, it is the first openly available duplex S2S model with training and inference code to foster reproducibility.", "subjects": "Computation and Language (cs.CL); Sound (cs.SD); Audio and Speech Processing (eess.AS)", "comments": "Accepted to Interspeech 2025", "pdf_url": "https://arxiv.org/pdf/2505.15670.pdf", "abstract_url": "https://arxiv.org/abs/2505.15670", "categories": ["Computation and Language (cs.CL)", "Sound (cs.SD)", "Audio and Speech Processing (eess.AS)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新颖的双工语音到语音（S2S）架构，支持连续用户输入和编解码器代理输出，通过通道融合直接建模用户和代理的同时流。该架构无需语音预训练，显著简化了从任何LLM构建双工S2S模型的过程，并在推理、轮流发言和打断能力上优于之前的双工模型。", "motivation": "解决当前语音语言模型局限于轮流交换、缺乏实时适应性的问题，如用户打断（barge-in）。", "method": "采用预训练的流式编码器处理用户输入，实现无需语音预训练的双工S2S模型；通过分离的用户和代理建模架构，优化代理语音质量并降低比特率。", "result": "模型在推理、轮流发言和打断能力上优于之前的双工模型，比特率降低至0.6 kbps，且所需语音数据量显著减少。", "conclusion": "提出的模型不仅性能优越，而且简化了双工S2S模型的构建过程，是首个公开可用的双工S2S模型，促进了研究的可重复性。"}}
{"id": "2505.15561", "title": "Do RAG Systems Suffer From Positional Bias?", "authors": ["Florin Cuconasu", "Simone Filice", "Guy Horowitz", "Yoelle Maarek", "Fabrizio Silvestri"], "abstract": "Retrieval Augmented Generation enhances LLM accuracy by adding passages retrieved from an external corpus to the LLM prompt. This paper investigates how positional bias - the tendency of LLMs to weight information differently based on its position in the prompt - affects not only the LLM's capability to capitalize on relevant passages, but also its susceptibility to distracting passages. Through extensive experiments on three benchmarks, we show how state-of-the-art retrieval pipelines, while attempting to retrieve relevant passages, systematically bring highly distracting ones to the top ranks, with over 60% of queries containing at least one highly distracting passage among the top-10 retrieved passages. As a result, the impact of the LLM positional bias, which in controlled settings is often reported as very prominent by related works, is actually marginal in real scenarios since both relevant and distracting passages are, in turn, penalized. Indeed, our findings reveal that sophisticated strategies that attempt to rearrange the passages based on LLM positional preferences do not perform better than random shuffling.", "subjects": "Computation and Language (cs.CL); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.15561.pdf", "abstract_url": "https://arxiv.org/abs/2505.15561", "categories": ["Computation and Language (cs.CL)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文研究了检索增强生成（RAG）系统中的位置偏差问题，即大型语言模型（LLM）如何根据信息在提示中的位置不同而赋予不同权重。通过三个基准测试的广泛实验，发现即使是最先进的检索管道，在尝试检索相关段落时，也会系统地将高度分散注意力的段落带到排名靠前的位置。结果显示，LLM位置偏差在实际场景中的影响实际上是边际的，因为相关和分散注意力的段落都会受到惩罚。", "motivation": "解决检索增强生成（RAG）系统中位置偏差对大型语言模型（LLM）性能的影响问题，特别是在处理相关和分散注意力段落时的表现。", "method": "通过在三个基准测试上进行广泛实验，分析状态最先进的检索管道在检索相关段落时的表现，以及LLM位置偏差对这些段落的影响。", "result": "研究发现，超过60%的查询在排名前10的检索段落中至少包含一个高度分散注意力的段落。因此，LLM位置偏差在实际场景中的影响是边际的，因为相关和分散注意力的段落都会受到惩罚。尝试根据LLM位置偏好重新排列段落的复杂策略并不比随机洗牌表现更好。", "conclusion": "研究结果表明，尽管在受控环境中LLM位置偏差被报告为非常显著，但在实际场景中其影响实际上是边际的。这为理解和改进RAG系统的设计提供了重要见解。"}}
{"id": "2505.15155", "title": "R&D-Agent-Quant: A Multi-Agent Framework for Data-Centric Factors and Model Joint Optimization", "authors": ["Yuante Li", "Xu Yang", "Xiao Yang", "Minrui Xu", "Xisen Wang", "Weiqing Liu", "Jiang Bian"], "abstract": "Financial markets pose fundamental challenges for asset return prediction due to their high dimensionality, non-stationarity, and persistent volatility. Despite advances in large language models and multi-agent systems, current quantitative research pipelines suffer from limited automation, weak interpretability, and fragmented coordination across key components such as factor mining and model innovation. In this paper, we propose R&D-Agent for Quantitative Finance, in short RD-Agent(Q), the first data-centric multi-agent framework designed to automate the full-stack research and development of quantitative strategies via coordinated factor-model co-optimization. RD-Agent(Q) decomposes the quant process into two iterative stages: a Research stage that dynamically sets goal-aligned prompts, formulates hypotheses based on domain priors, and maps them to concrete tasks, and a Development stage that employs a code-generation agent, Co-STEER, to implement task-specific code, which is then executed in real-market backtests. The two stages are connected through a feedback stage that thoroughly evaluates experimental outcomes and informs subsequent iterations, with a multi-armed bandit scheduler for adaptive direction selection. Empirically, RD-Agent(Q) achieves up to 2X higher annualized returns than classical factor libraries using 70% fewer factors, and outperforms state-of-the-art deep time-series models on real markets. Its joint factor-model optimization delivers a strong balance between predictive accuracy and strategy robustness. Our code is available at:", "subjects": "Computational Finance (q-fin.CP); Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.15155.pdf", "abstract_url": "https://arxiv.org/abs/2505.15155", "categories": ["Computational Finance (q-fin.CP)", "Artificial Intelligence (cs.AI)", "Computational Engineering, Finance, and Science (cs.CE)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "RD-Agent(Q)是一个数据驱动的多智能体框架，旨在通过协调因子模型共同优化自动化量化策略的全栈研发。", "motivation": "金融市场的资产回报预测面临高维度、非平稳性和持续波动性等挑战，现有量化研究流程自动化程度低、解释性弱且关键组件间协调不足。", "method": "RD-Agent(Q)将量化过程分解为研究阶段和开发阶段，通过反馈阶段连接，采用多臂老虎机调度器进行自适应方向选择。", "result": "实证显示，RD-Agent(Q)使用70%更少的因子实现了比经典因子库高2倍的年化回报，并在真实市场上优于最先进的深度时间序列模型。", "conclusion": "RD-Agent(Q)的联合因子模型优化在预测准确性和策略稳健性之间实现了良好平衡，为量化金融研究提供了新的自动化框架。"}}
{"id": "2505.15216", "title": "BountyBench: Dollar Impact of AI Agent Attackers and Defenders on Real-World Cybersecurity Systems", "authors": ["Andy K. Zhang", "Joey Ji", "Celeste Menders", "Riya Dulepet", "Thomas Qin", "Ron Y. Wang", "Junrong Wu", "Kyleen Liao", "Jiliang Li", "Jinghan Hu", "Sara Hong", "Nardos Demilew", "Shivatmica Murgai", "Jason Tran", "Nishka Kacheria", "Ethan Ho", "Denis Liu", "Lauren McLane", "Olivia Bruvik", "Dai-Rong Han", "Seungwoo Kim", "Akhil Vyas", "Cuiyuanxiu Chen", "Ryan Li", "Weiran Xu", "Jonathan Z. Ye", "Prerit Choudhary", "Siddharth M. Bhatia", "Vikram Sivashankar", "Yuxuan Bao", "Dawn Song", "Dan Boneh", "Daniel E. Ho", "Percy Liang"], "abstract": "AI agents have the potential to significantly alter the cybersecurity landscape. To help us understand this change, we introduce the first framework to capture offensive and defensive cyber-capabilities in evolving real-world systems. Instantiating this framework with BountyBench, we set up 25 systems with complex, real-world codebases. To capture the vulnerability lifecycle, we define three task types: Detect (detecting a new vulnerability), Exploit (exploiting a specific vulnerability), and Patch (patching a specific vulnerability). For Detect, we construct a new success indicator, which is general across vulnerability types and provides localized evaluation. We manually set up the environment for each system, including installing packages, setting up server(s), and hydrating database(s). We add 40 bug bounties, which are vulnerabilities with monetary awards from \\$10 to \\$30,485, and cover 9 of the OWASP Top 10 Risks. To modulate task difficulty, we devise a new strategy based on information to guide detection, interpolating from identifying a zero day to exploiting a specific vulnerability. We evaluate 5 agents: Claude Code, OpenAI Codex CLI, and custom agents with GPT-4.1, Gemini 2.5 Pro Preview, and Claude 3.7 Sonnet Thinking. Given up to three attempts, the top-performing agents are Claude Code (5% on Detect, mapping to \\$1,350), Custom Agent with Claude 3.7 Sonnet Thinking (5% on Detect, mapping to \\$1,025; 67.5% on Exploit), and OpenAI Codex CLI (5% on Detect, mapping to \\$2,400; 90% on Patch, mapping to \\$14,422). OpenAI Codex CLI and Claude Code are more capable at defense, achieving higher Patch scores of 90% and 87.5%, compared to Exploit scores of 32.5% and 57.5% respectively; in contrast, the custom agents are relatively balanced between offense and defense, achieving Exploit scores of 40-67.5% and Patch scores of 45-60%.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": "78 pages", "pdf_url": "https://arxiv.org/pdf/2505.15216.pdf", "abstract_url": "https://arxiv.org/abs/2505.15216", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了BountyBench，第一个捕捉现实世界网络安全系统中攻防能力的框架，通过25个复杂系统评估AI代理在检测、利用和修补漏洞方面的表现。", "motivation": "理解AI代理如何改变网络安全格局，特别是在漏洞生命周期中的攻防能力。", "method": "构建BountyBench框架，设置25个真实系统，定义检测、利用和修补三种任务类型，评估5种AI代理的性能。", "result": "Claude Code、Custom Agent with Claude 3.7 Sonnet Thinking和OpenAI Codex CLI表现最佳，特别是在防御任务上表现突出。", "conclusion": "AI代理在网络安全领域具有显著潜力，特别是在防御方面，但攻防能力之间存在差异。"}}
{"id": "2505.15242", "title": "Adaptive Plan-Execute Framework for Smart Contract Security Auditing", "authors": ["Zhiyuan Wei", "Jing Sun", "Zijian Zhang", "Zhe Hou", "Zixiao Zhao"], "abstract": "Large Language Models (LLMs) have shown great promise in code analysis and auditing; however, they still struggle with hallucinations and limited context-aware reasoning. We introduce SmartAuditFlow, a novel Plan-Execute framework that enhances smart contract security analysis through dynamic audit planning and structured execution. Unlike conventional LLM-based auditing approaches that follow fixed workflows and predefined steps, SmartAuditFlow dynamically generates and refines audit plans based on the unique characteristics of each smart contract. It continuously adjusts its auditing strategy in response to intermediate LLM outputs and newly detected vulnerabilities, ensuring a more adaptive and precise security assessment. The framework then executes these plans step by step, applying a structured reasoning process to enhance vulnerability detection accuracy while minimizing hallucinations and false positives. To further improve audit precision, SmartAuditFlow integrates iterative prompt optimization and external knowledge sources, such as static analysis tools and Retrieval-Augmented Generation (RAG). This ensures audit decisions are contextually informed and backed by real-world security knowledge, producing comprehensive security reports. Extensive evaluations across multiple benchmarks demonstrate that SmartAuditFlow outperforms existing methods, achieving 100 percent accuracy on common and critical vulnerabilities, 41.2 percent accuracy for comprehensive coverage of known smart contract weaknesses in real-world projects, and successfully identifying all 13 tested CVEs. These results highlight SmartAuditFlow's scalability, cost-effectiveness, and superior adaptability over traditional static analysis tools and contemporary LLM-based approaches, establishing it as a robust solution for automated smart contract auditing.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": "30 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2505.15242.pdf", "abstract_url": "https://arxiv.org/abs/2505.15242", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了SmartAuditFlow，一种新颖的Plan-Execute框架，通过动态审计规划和结构化执行增强智能合约安全分析。", "motivation": "解决大型语言模型（LLMs）在代码分析和审计中的幻觉和有限上下文感知推理问题。", "method": "采用动态生成和精炼审计计划的Plan-Execute框架，结合迭代提示优化和外部知识源。", "result": "在多个基准测试中，SmartAuditFlow表现出色，实现了对常见和关键漏洞的100%准确率，以及对现实项目中已知智能合约弱点的41.2%准确率。", "conclusion": "SmartAuditFlow在可扩展性、成本效益和适应性方面优于传统静态分析工具和当代基于LLM的方法，成为自动化智能合约审计的强有力解决方案。"}}
{"id": "2505.15734", "title": "DEBATE, TRAIN, EVOLVE: Self Evolution of Language Model Reasoning", "authors": ["Gaurav Srivastava", "Zhenyu Bi", "Meng Lu", "Xuan Wang"], "abstract": "Large language models (LLMs) have improved significantly in their reasoning through extensive training on massive datasets. However, relying solely on additional data for improvement is becoming increasingly impractical, highlighting the need for models to autonomously enhance their reasoning without external supervision. In this paper, we propose Debate, Train, Evolve (DTE), a novel ground truth-free training framework that uses multi-agent debate traces to evolve a single language model. We also introduce a new prompting strategy Reflect-Critique-Refine, to improve debate quality by explicitly instructing agents to critique and refine their reasoning. Extensive evaluations on five reasoning benchmarks with six open-weight models show that our DTE framework achieve substantial improvements, with an average accuracy gain of 8.92% on the challenging GSM-PLUS dataset. Furthermore, we observe strong cross-domain generalization, with an average accuracy gain of 5.8% on all other benchmarks, suggesting that our method captures general reasoning capabilities.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.15734.pdf", "abstract_url": "https://arxiv.org/abs/2505.15734", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为DEBATE, TRAIN, EVOLVE (DTE)的新型无监督训练框架，通过多智能体辩论痕迹来进化单一语言模型，并引入Reflect-Critique-Refine提示策略以提高辩论质量。在五个推理基准测试中，DTE框架实现了显著改进，特别是在GSM-PLUS数据集上平均准确率提高了8.92%，并显示出强大的跨领域泛化能力。", "motivation": "随着大型语言模型(LLMs)在推理能力上的显著提升，仅依赖额外数据进行改进变得越来越不切实际，因此需要模型能够在没有外部监督的情况下自主增强其推理能力。", "method": "提出了DEBATE, TRAIN, EVOLVE (DTE)框架，利用多智能体辩论痕迹进化单一语言模型，并引入Reflect-Critique-Refine提示策略以提高辩论质量。", "result": "在五个推理基准测试中，DTE框架实现了平均准确率8.92%的提升（在GSM-PLUS数据集上），并在其他基准测试中平均准确率提高了5.8%，显示出强大的跨领域泛化能力。", "conclusion": "DTE框架不仅显著提高了语言模型的推理能力，而且通过跨领域泛化能力的展示，表明该方法能够捕捉到通用的推理能力，为语言模型的自我进化提供了新的方向。"}}
{"id": "2505.15293", "title": "LLM-Explorer: A Plug-in Reinforcement Learning Policy Exploration Enhancement Driven by Large Language Models", "authors": ["Qianyue Hao", "Yiwen Song", "Qingmin Liao", "Jian Yuan", "Yong Li"], "abstract": "Policy exploration is critical in reinforcement learning (RL), where existing approaches include greedy, Gaussian process, etc. However, these approaches utilize preset stochastic processes and are indiscriminately applied in all kinds of RL tasks without considering task-specific features that influence policy exploration. Moreover, during RL training, the evolution of such stochastic processes is rigid, which typically only incorporates a decay in the variance, failing to adjust flexibly according to the agent's real-time learning status. Inspired by the analyzing and reasoning capability of large language models (LLMs), we design LLM-Explorer to adaptively generate task-specific exploration strategies with LLMs, enhancing the policy exploration in RL. In our design, we sample the learning trajectory of the agent during the RL training in a given task and prompt the LLM to analyze the agent's current policy learning status and then generate a probability distribution for future policy exploration. Updating the probability distribution periodically, we derive a stochastic process specialized for the particular task and dynamically adjusted to adapt to the learning process. Our design is a plug-in module compatible with various widely applied RL algorithms, including the DQN series, DDPG, TD3, and any possible variants developed based on them. Through extensive experiments on the Atari and MuJoCo benchmarks, we demonstrate LLM-Explorer's capability to enhance RL policy exploration, achieving an average performance improvement up to 37.27%. Our code is open-source at", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.15293.pdf", "abstract_url": "https://arxiv.org/abs/2505.15293", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "LLM-Explorer是一个利用大型语言模型（LLMs）增强强化学习（RL）策略探索的插件模块，通过动态生成任务特定的探索策略，显著提升RL算法的性能。", "motivation": "解决现有强化学习策略探索方法预设随机过程、不考虑任务特定特征及无法根据代理实时学习状态灵活调整的问题。", "method": "设计LLM-Explorer，通过采样代理在RL训练中的学习轨迹，利用LLM分析当前策略学习状态并生成未来策略探索的概率分布，动态调整以适应学习过程。", "result": "在Atari和MuJoCo基准测试中，LLM-Explorer平均性能提升高达37.27%，证明了其在增强RL策略探索方面的能力。", "conclusion": "LLM-Explorer作为一个兼容多种RL算法的插件模块，通过利用LLMs的分析和推理能力，为RL策略探索提供了动态、任务特定的解决方案，显著提升了学习效率和性能。"}}
{"id": "2505.15306", "title": "Multiple Weaks Win Single Strong: Large Language Models Ensemble Weak Reinforcement Learning Agents into a Supreme One", "authors": ["Yiwen Song", "Qianyue Hao", "Qingmin Liao", "Jian Yuan", "Yong Li"], "abstract": "Model ensemble is a useful approach in reinforcement learning (RL) for training effective agents. Despite wide success of RL, training effective agents remains difficult due to the multitude of factors requiring careful tuning, such as algorithm selection, hyperparameter settings, and even random seed choices, all of which can significantly influence an agent's performance. Model ensemble helps overcome this challenge by combining multiple weak agents into a single, more powerful one, enhancing overall performance. However, existing ensemble methods, such as majority voting and Boltzmann addition, are designed as fixed strategies and lack a semantic understanding of specific tasks, limiting their adaptability and effectiveness. To address this, we propose LLM-Ens, a novel approach that enhances RL model ensemble with task-specific semantic understandings driven by large language models (LLMs). Given a task, we first design an LLM to categorize states in this task into distinct 'situations', incorporating high-level descriptions of the task conditions. Then, we statistically analyze the strengths and weaknesses of each individual agent to be used in the ensemble in each situation. During the inference time, LLM-Ens dynamically identifies the changing task situation and switches to the agent that performs best in the current situation, ensuring dynamic model selection in the evolving task condition. Our approach is designed to be compatible with agents trained with different random seeds, hyperparameter settings, and various RL algorithms. Extensive experiments on the Atari benchmark show that LLM-Ens significantly improves the RL model ensemble, surpassing well-known baselines by up to 20.9%. For reproducibility, our code is open-source at", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.15306.pdf", "abstract_url": "https://arxiv.org/abs/2505.15306", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为LLM-Ens的新方法，通过利用大型语言模型（LLMs）的任务特定语义理解来增强强化学习（RL）模型的集成，从而将多个弱RL代理组合成一个更强大的代理。", "motivation": "训练有效的RL代理由于需要精心调整的多种因素（如算法选择、超参数设置和随机种子选择）而具有挑战性。现有的集成方法缺乏对特定任务的语义理解，限制了其适应性和有效性。", "method": "LLM-Ens首先使用LLM将任务状态分类为不同的'情境'，并结合任务条件的高级描述。然后，统计分析每个代理在不同情境中的强弱。在推理时，动态识别任务情境的变化，并切换到当前情境中表现最佳的代理。", "result": "在Atari基准测试上的广泛实验表明，LLM-Ens显著提高了RL模型的集成效果，比知名基线方法提高了多达20.9%。", "conclusion": "LLM-Ens通过结合LLMs的语义理解能力，提供了一种动态且有效的RL代理集成方法，显著提升了性能，且与不同训练设置的代理兼容。"}}
{"id": "2505.14899", "title": "Think, Reflect, Create: Metacognitive Learning for Zero-Shot Robotic Planning with LLMs", "authors": ["Wenjie Lin", "Jin Wei-Kocsis"], "abstract": "While large language models (LLMs) have shown great potential across various domains, their applications in robotics remain largely limited to static, prompt-based behaviors and still face challenges in handling complex tasks under zero-shot or few-shot settings. Inspired by human metacognitive learning and creative problem-solving, we address this limitation by exploring a fundamental research question: Can LLMs be empowered with metacognitive capabilities to reason, reflect, and create, thereby enhancing their ability to perform robotic tasks with minimal demonstrations? In this paper, we present an early-stage framework that integrates metacognitive learning into LLM-powered multi-robot collaboration. The proposed framework equips the LLM-powered robotic agents with a skill decomposition and self-reflection mechanism that identifies modular skills from prior tasks, reflects on failures in unseen task scenarios, and synthesizes effective new solutions. Experimental results show that our metacognitive-learning-empowered LLM framework significantly outperforms existing baselines. Moreover, we observe that the framework is capable of generating solutions that differ from the ground truth yet still successfully complete the tasks. These exciting findings support our hypothesis that metacognitive learning can foster creativity in robotic planning.", "subjects": "Robotics (cs.RO); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.14899.pdf", "abstract_url": "https://arxiv.org/abs/2505.14899", "categories": ["Robotics (cs.RO)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了如何通过元认知学习增强大型语言模型（LLMs）的能力，使其能够在零样本或少样本设置下更好地执行机器人任务。提出的框架通过技能分解和自我反思机制，使LLM驱动的机器人代理能够从先前任务中识别模块化技能，反思未见任务场景中的失败，并合成有效的新解决方案。实验结果表明，该框架显著优于现有基线，并能够生成与地面真实不同但仍成功完成任务的解决方案。", "motivation": "大型语言模型（LLMs）在机器人应用中的潜力受到限制，尤其是在零样本或少样本设置下处理复杂任务时。本文旨在通过元认知学习解决这一限制，增强LLMs在机器人任务中的推理、反思和创造能力。", "method": "提出了一个早期框架，将元认知学习集成到LLM驱动的多机器人协作中。该框架通过技能分解和自我反思机制，使机器人代理能够从先前任务中识别模块化技能，反思失败，并合成新解决方案。", "result": "实验结果显示，元认知学习增强的LLM框架显著优于现有基线，并且能够生成与地面真实不同但仍成功完成任务的解决方案。", "conclusion": "研究支持了元认知学习可以促进机器人规划中的创造力的假设，为LLMs在机器人领域的应用提供了新的方向。"}}
{"id": "2505.15420", "title": "Silent Leaks: Implicit Knowledge Extraction Attack on RAG Systems through Benign Queries", "authors": ["Yuhao Wang", "Wenjie Qu", "Yanze Jiang", "Zichen Liu", "Yue Liu", "Shengfang Zhai", "Yinpeng Dong", "Jiaheng Zhang"], "abstract": "Retrieval-Augmented Generation (RAG) systems enhance large language models (LLMs) by incorporating external knowledge bases, but they are vulnerable to privacy risks from data extraction attacks. Existing extraction methods typically rely on malicious inputs such as prompt injection or jailbreaking, making them easily detectable via input- or output-level detection. In this paper, we introduce Implicit Knowledge Extraction Attack (IKEA), which conducts knowledge extraction on RAG systems through benign queries. IKEA first leverages anchor concepts to generate queries with the natural appearance, and then designs two mechanisms to lead to anchor concept thoroughly 'explore' the RAG's privacy knowledge: (1) Experience Reflection Sampling, which samples anchor concepts based on past query-response patterns to ensure the queries' relevance to RAG documents; (2) Trust Region Directed Mutation, which iteratively mutates anchor concepts under similarity constraints to further exploit the embedding space. Extensive experiments demonstrate IKEA's effectiveness under various defenses, surpassing baselines by over 80% in extraction efficiency and 90% in attack success rate. Moreover, the substitute RAG system built from IKEA's extractions consistently outperforms those based on baseline methods across multiple evaluation tasks, underscoring the significant privacy risk in RAG systems.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.15420.pdf", "abstract_url": "https://arxiv.org/abs/2505.15420", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了隐式知识提取攻击（IKEA），一种通过良性查询对检索增强生成（RAG）系统进行知识提取的方法，揭示了RAG系统的隐私风险。", "motivation": "解决RAG系统在隐私保护方面的漏洞，特别是那些不易被现有检测方法发现的隐式知识提取问题。", "method": "采用锚概念生成自然外观的查询，并通过经验反射采样和信任区域定向突变两种机制深入探索RAG的隐私知识。", "result": "IKEA在各种防御措施下表现出色，提取效率和攻击成功率分别超过基线方法80%和90%，且基于IKEA提取的替代RAG系统在多项评估任务中表现更优。", "conclusion": "研究表明RAG系统存在重大的隐私风险，需要更有效的防御机制来防止隐式知识提取攻击。"}}
{"id": "2505.15259", "title": "ReGUIDE: Data Efficient GUI Grounding via Spatial Reasoning and Search", "authors": ["Hyunseok Lee", "Jeonghoon Kim", "Beomjun Kim", "Jihoon Tack", "Chansong Jo", "Jaehong Lee", "Cheonbok Park", "Sookyo In", "Jinwoo Shin", "Kang Min Yoo"], "abstract": "Recent advances in Multimodal Large Language Models (MLLMs) have enabled autonomous agents to interact with computers via Graphical User Interfaces (GUIs), where accurately localizing the coordinates of interface elements (e.g., buttons) is often required for fine-grained actions. However, this remains significantly challenging, leading prior works to rely on large-scale web datasets to improve the grounding accuracy. In this work, we propose Reasoning Graphical User Interface Grounding for Data Efficiency (ReGUIDE), a novel and effective framework for web grounding that enables MLLMs to learn data efficiently through self-generated reasoning and spatial-aware criticism. More specifically, ReGUIDE learns to (i) self-generate a language reasoning process for the localization via online reinforcement learning, and (ii) criticize the prediction using spatial priors that enforce equivariance under input transformations. At inference time, ReGUIDE further boosts performance through a test-time scaling strategy, which combines spatial search with coordinate aggregation. Our experiments demonstrate that ReGUIDE significantly advances web grounding performance across multiple benchmarks, outperforming baselines with substantially fewer training data points (e.g., only 0.2% samples compared to the best open-sourced baselines).", "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.15259.pdf", "abstract_url": "https://arxiv.org/abs/2505.15259", "categories": ["Machine Learning (cs.LG)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "ReGUIDE是一种新颖有效的框架，旨在通过自我生成的推理和空间感知批评，提高多模态大型语言模型（MLLMs）在图形用户界面（GUI）元素定位上的数据效率。", "motivation": "解决在图形用户界面（GUI）中精确定位界面元素（如按钮）坐标的挑战，减少对大规模网络数据集的依赖。", "method": "ReGUIDE框架通过在线强化学习自我生成语言推理过程，并利用空间先验批评预测，增强输入变换下的等变性。在推理时，通过结合空间搜索和坐标聚合的测试时间缩放策略提升性能。", "result": "实验表明，ReGUIDE在多个基准测试中显著提升了网页定位性能，且使用的训练数据量大幅减少（例如，仅使用最佳开源基线0.2%的样本）。", "conclusion": "ReGUIDE通过自我生成的推理和空间感知批评，有效提高了MLLMs在GUI元素定位上的数据效率，为自动化代理与计算机的交互提供了新的可能性。"}}
{"id": "2505.15701", "title": "HDLxGraph: Bridging Large Language Models and HDL Repositories via HDL Graph Databases", "authors": ["Pingqing Zheng", "Jiayin Qin", "Fuqi Zhang", "Shang Wu", "Yu Cao", "Caiwen Ding", "Yang", "Zhao"], "abstract": "Large Language Models (LLMs) have demonstrated their potential in hardware design tasks, such as Hardware Description Language (HDL) generation and debugging. Yet, their performance in real-world, repository-level HDL projects with thousands or even tens of thousands of code lines is hindered. To this end, we propose HDLxGraph, a novel framework that integrates Graph Retrieval Augmented Generation (Graph RAG) with LLMs, introducing HDL-specific graph representations by incorporating Abstract Syntax Trees (ASTs) and Data Flow Graphs (DFGs) to capture both code graph view and hardware graph view. HDLxGraph utilizes a dual-retrieval mechanism that not only mitigates the limited recall issues inherent in similarity-based semantic retrieval by incorporating structural information, but also enhances its extensibility to various real-world tasks by a task-specific retrieval finetuning. Additionally, to address the lack of comprehensive HDL search benchmarks, we introduce HDLSearch, a multi-granularity evaluation dataset derived from real-world repository-level projects. Experimental results demonstrate that HDLxGraph significantly improves average search accuracy, debugging efficiency and completion quality by 12.04%, 12.22% and 5.04% compared to similarity-based RAG, respectively. The code of HDLxGraph and collected HDLSearch benchmark are available at", "subjects": "Hardware Architecture (cs.AR); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.15701.pdf", "abstract_url": "https://arxiv.org/abs/2505.15701", "categories": ["Hardware Architecture (cs.AR)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "HDLxGraph是一个新颖的框架，通过结合图检索增强生成（Graph RAG）与大型语言模型（LLMs），引入了特定于HDL的图表示，以提升在真实世界HDL项目中的性能。", "motivation": "大型语言模型在硬件设计任务中显示出潜力，但在处理真实世界、仓库级别的HDL项目时性能受限。", "method": "HDLxGraph采用双检索机制，结合了抽象语法树（ASTs）和数据流图（DFGs）的HDL特定图表示，以及任务特定的检索微调。", "result": "实验结果显示，HDLxGraph在搜索准确性、调试效率和完成质量上分别比基于相似性的RAG提高了12.04%、12.22%和5.04%。", "conclusion": "HDLxGraph通过其创新的方法和双检索机制，显著提升了在真实世界HDL项目中的性能，同时引入了HDLSearch基准测试以填补全面HDL搜索基准的空白。"}}
{"id": "2505.15738", "title": "Alignment Under Pressure: The Case for Informed Adversaries When Evaluating LLM Defenses", "authors": ["Xiaoxue Yang", "Bozhidar Stevanoski", "Matthieu Meeus", "Yves-Alexandre de Montjoye"], "abstract": "Large language models (LLMs) are rapidly deployed in real-world applications ranging from chatbots to agentic systems. Alignment is one of the main approaches used to defend against attacks such as prompt injection and jailbreaks. Recent defenses report near-zero Attack Success Rates (ASR) even against Greedy Coordinate Gradient (GCG), a white-box attack that generates adversarial suffixes to induce attacker-desired outputs. However, this search space over discrete tokens is extremely large, making the task of finding successful attacks difficult. GCG has, for instance, been shown to converge to local minima, making it sensitive to initialization choices. In this paper, we assess the future-proof robustness of these defenses using a more informed threat model: attackers who have access to some information about the alignment process. Specifically, we propose an informed white-box attack leveraging the intermediate model checkpoints to initialize GCG, with each checkpoint acting as a stepping stone for the next one. We show this approach to be highly effective across state-of-the-art (SOTA) defenses and models. We further show our informed initialization to outperform other initialization methods and show a gradient-informed checkpoint selection strategy to greatly improve attack performance and efficiency. Importantly, we also show our method to successfully find universal adversarial suffixes -- single suffixes effective across diverse inputs. Our results show that, contrary to previous beliefs, effective adversarial suffixes do exist against SOTA alignment-based defenses, that these can be found by existing attack methods when adversaries exploit alignment knowledge, and that even universal suffixes exist. Taken together, our results highlight the brittleness of current alignment-based methods and the need to consider stronger threat models when testing the safety of LLMs.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.15738.pdf", "abstract_url": "https://arxiv.org/abs/2505.15738", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文评估了大型语言模型（LLM）防御措施的未来抗鲁棒性，提出了一个更知情的威胁模型：攻击者能够获取对齐过程的某些信息。通过利用中间模型检查点初始化GCG攻击，作者展示了这种方法在多种先进防御和模型中的高效性，并发现了普遍对抗性后缀的存在。", "motivation": "解决当前LLM防御措施在更知情攻击者威胁下的脆弱性问题，挑战了现有防御措施的有效性。", "method": "提出了一种知情的白盒攻击方法，利用中间模型检查点初始化GCG攻击，采用梯度信息检查点选择策略提高攻击性能和效率。", "result": "展示了该方法在多种先进防御和模型中的高效性，发现了普遍对抗性后缀的存在，证明了现有攻击方法在利用对齐知识时能够找到有效对抗性后缀。", "conclusion": "研究结果强调了当前基于对齐的方法的脆弱性，以及在测试LLM安全性时需要考虑更强的威胁模型的必要性。"}}
{"id": "2505.15753", "title": "Scalable Defense against In-the-wild Jailbreaking Attacks with Safety Context Retrieval", "authors": ["Taiye Chen", "Zeming Wei", "Ang Li", "Yisen Wang"], "abstract": "Large Language Models (LLMs) are known to be vulnerable to jailbreaking attacks, wherein adversaries exploit carefully engineered prompts to induce harmful or unethical responses. Such threats have raised critical concerns about the safety and reliability of LLMs in real-world deployment. While existing defense mechanisms partially mitigate such risks, subsequent advancements in adversarial techniques have enabled novel jailbreaking methods to circumvent these protections, exposing the limitations of static defense frameworks. In this work, we explore defending against evolving jailbreaking threats through the lens of context retrieval. First, we conduct a preliminary study demonstrating that even a minimal set of safety-aligned examples against a particular jailbreak can significantly enhance robustness against this attack pattern. Building on this insight, we further leverage the retrieval-augmented generation (RAG) techniques and propose Safety Context Retrieval (SCR), a scalable and robust safeguarding paradigm for LLMs against jailbreaking. Our comprehensive experiments demonstrate how SCR achieves superior defensive performance against both established and emerging jailbreaking tactics, contributing a new paradigm to LLM safety. Our code will be available upon publication.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.15753.pdf", "abstract_url": "https://arxiv.org/abs/2505.15753", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文探讨了通过上下文检索防御大型语言模型（LLMs）越狱攻击的新方法，提出了安全上下文检索（SCR）作为一种可扩展且强大的保护范式。", "motivation": "大型语言模型（LLMs）容易受到越狱攻击，攻击者通过精心设计的提示诱导有害或不道德的回答。现有的防御机制虽然部分缓解了这些风险，但随着对抗技术的进步，新的越狱方法能够绕过这些保护，暴露出静态防御框架的局限性。", "method": "通过初步研究展示了即使是最小化的安全对齐示例也能显著增强对特定越狱攻击模式的鲁棒性。基于这一见解，利用检索增强生成（RAG）技术，提出了安全上下文检索（SCR）作为防御越狱攻击的新范式。", "result": "综合实验表明，SCR在对抗既有和新兴越狱策略方面表现出卓越的防御性能。", "conclusion": "SCR为LLM安全贡献了一种新范式，其代码将在发表后提供。"}}
