{"id": "2508.21767", "title": "UItron: Foundational GUI Agent with Advanced Perception and Planning", "authors": ["Zhixiong Zeng", "Jing Huang", "Liming Zheng", "Wenkang Han", "Yufeng Zhong", "Lei Chen", "Longrong Yang", "Yingjie Chu", "Yuzhi He", "Lin Ma"], "abstract": "GUI agent aims to enable automated operations on Mobile/PC devices, which is an important task toward achieving artificial general intelligence. The rapid advancement of VLMs accelerates the development of GUI agents, owing to their powerful capabilities in visual understanding and task planning. However, building a GUI agent remains a challenging task due to the scarcity of operation trajectories, the availability of interactive infrastructure, and the limitation of initial capabilities in foundation models. In this work, we introduce UItron, an open-source foundational model for automatic GUI agents, featuring advanced GUI perception, grounding, and planning capabilities. UItron highlights the necessity of systemic data engineering and interactive infrastructure as foundational components for advancing GUI agent development. It not only systematically studies a series of data engineering strategies to enhance training effects, but also establishes an interactive environment connecting both Mobile and PC devices. In training, UItron adopts supervised finetuning over perception and planning tasks in various GUI scenarios, and then develop a curriculum reinforcement learning framework to enable complex reasoning and exploration for online environments. As a result, UItron achieves superior performance in benchmarks of GUI perception, grounding, and planning. In particular, UItron highlights the interaction proficiency with top-tier Chinese mobile APPs, as we identified a general lack of Chinese capabilities even in state-of-the-art solutions. To this end, we manually collect over one million steps of operation trajectories across the top 100 most popular apps, and build the offline and online agent evaluation environments. Experimental results demonstrate that UItron achieves significant progress in Chinese app scenarios, propelling GUI agents one step closer to real-world application.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "24 pages", "pdf_url": "https://arxiv.org/pdf/2508.21767.pdf", "abstract_url": "https://arxiv.org/abs/2508.21767", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "UItron是一个开源的基础GUI代理模型，具备先进的感知和规划能力，通过系统数据工程和交互基础设施提升性能，尤其在中文移动应用场景中表现优异。", "motivation": "解决GUI代理开发中因操作轨迹稀缺、交互基础设施不足和基础模型初始能力限制导致的挑战，推动人工智能通用智能的实现。", "method": "采用监督微调感知和规划任务，并结合课程强化学习框架，系统数据工程策略和建立移动与PC设备的交互环境。", "result": "在GUI感知、接地和规划基准测试中取得优异性能，特别是在中文移动应用场景中实现显著进步。", "conclusion": "UItron通过系统性方法推进GUI代理发展，使其更接近实际应用，并强调数据工程和基础设施的重要性。"}}
{"id": "2508.21238", "title": "Addressing accuracy and hallucination of LLMs in Alzheimer's disease research through knowledge graphs", "authors": ["Tingxuan Xu", "Jiarui Feng", "Justin Melendez", "Kaleigh Roberts", "Donghong Cai", "Mingfang Zhu", "Donald Elbert", "Yixin Chen", "Randall J. Bateman"], "abstract": "In the past two years, large language model (LLM)-based chatbots, such as ChatGPT, have revolutionized various domains by enabling diverse task completion and question-answering capabilities. However, their application in scientific research remains constrained by challenges such as hallucinations, limited domain-specific knowledge, and lack of explainability or traceability for the response. Graph-based Retrieval-Augmented Generation (GraphRAG) has emerged as a promising approach to improving chatbot reliability by integrating domain-specific contextual information before response generation, addressing some limitations of standard LLMs. Despite its potential, there are only limited studies that evaluate GraphRAG on specific domains that require intensive knowledge, like Alzheimer's disease or other biomedical domains. In this paper, we assess the quality and traceability of two popular GraphRAG systems. We compile a database of 50 papers and 70 expert questions related to Alzheimer's disease, construct a GraphRAG knowledge base, and employ GPT-4o as the LLM for answering queries. We then compare the quality of responses generated by GraphRAG with those from a standard GPT-4o model. Additionally, we discuss and evaluate the traceability of several Retrieval-Augmented Generation (RAG) and GraphRAG systems. Finally, we provide an easy-to-use interface with a pre-built Alzheimer's disease database for researchers to test the performance of both standard RAG and GraphRAG.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.21238.pdf", "abstract_url": "https://arxiv.org/abs/2508.21238", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文评估了GraphRAG系统在阿尔茨海默病研究中的表现，通过构建知识库和比较标准LLM，发现GraphRAG能提高回答质量和可追溯性，并提供了易用界面。", "motivation": "解决大型语言模型在科学研究中的幻觉、知识局限和可解释性问题，特别是在阿尔茨海默病等生物医学领域。", "method": "使用GraphRAG方法，整合领域特定知识库，基于50篇论文和70个专家问题，采用GPT-4o进行查询回答，并与标准模型比较。", "result": "GraphRAG系统在回答质量和可追溯性方面优于标准LLM，减少了幻觉，提高了可靠性。", "conclusion": "GraphRAG是改善LLM在专业领域应用的有效工具，提供了可扩展的解决方案和实用界面。"}}
{"id": "2508.21307", "title": "MultiFluxAI Enhancing Platform Engineering with Advanced Agent-Orchestrated Retrieval Systems", "authors": ["Sri Ram Macharla", "Sridhar Murthy J", "Anjaneyulu Pasala"], "abstract": "MultiFluxAI is an innovative AI platform developed to address the challenges of managing and integrating vast, disparate data sources in product engineering across application domains. It addresses both current and new service related queries that enhance user engagement in the digital ecosystem. This platform leverages advanced AI techniques, such as Generative AI, vectorization, and agentic orchestration to provide dynamic and context-aware responses to complex user queries.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "Abstract accepted for presentation at ACM ISEC 2025", "pdf_url": "https://arxiv.org/pdf/2508.21307.pdf", "abstract_url": "https://arxiv.org/abs/2508.21307", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "MultiFluxAI 是一个创新的AI平台，通过先进的AI技术（如生成式AI、向量化和代理编排）来管理和整合产品工程中的多样化数据源，以增强用户参与度并提供动态、上下文感知的响应。", "motivation": "解决在跨应用领域的产品工程中管理和整合大量、分散数据源的挑战，以及处理当前和新服务相关查询以提升数字生态系统中的用户参与度。", "method": "利用生成式AI、向量化和代理编排等先进AI技术，构建动态和上下文感知的检索系统。", "result": "平台能够有效处理复杂用户查询，提供增强的用户体验和响应能力。", "conclusion": "MultiFluxAI 通过AI驱动的方法，提升了数据集成和查询处理的效率，对平台工程有积极的推动作用。"}}
{"id": "2508.21365", "title": "Think in Games: Learning to Reason in Games via Reinforcement Learning with Large Language Models", "authors": ["Yi Liao", "Yu Gu", "Yuan Sui", "Zining Zhu", "Yifan Lu", "Guohua Tang", "Zhongqian Sun", "Wei Yang"], "abstract": "Large language models (LLMs) excel at complex reasoning tasks such as mathematics and coding, yet they frequently struggle with simple interactive tasks that young children perform effortlessly. This discrepancy highlights a critical gap between declarative knowledge (knowing about something) and procedural knowledge (knowing how to do something). Although traditional reinforcement learning (RL) agents can acquire procedural knowledge through environmental interaction, they often operate as black boxes and require substantial training data. In contrast, LLMs possess extensive world knowledge and reasoning capabilities, but are unable to effectively convert this static knowledge into dynamic decision-making in interactive settings. To address this challenge, we propose Think in Games (TiG), a novel framework that empowers LLMs to develop procedural understanding through direct interaction with game environments, while retaining their inherent reasoning and explanatory abilities. Specifically, TiG reformulates RL-based decision-making as a language modeling task: LLMs generate language-guided policies, which are refined iteratively through online reinforcement learning based on environmental feedback. Our experimental results show that TiG successfully bridges the gap between declarative and procedural knowledge, achieving competitive performance with dramatically lower data and computational demands compared to conventional RL methods. Moreover, TiG provides step-by-step natural language explanations for its decisions, greatly improving transparency and interpretability in complex interactive tasks.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.21365.pdf", "abstract_url": "https://arxiv.org/abs/2508.21365", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "TiG框架通过强化学习和大型语言模型结合，使LLMs在游戏中学习推理，减少数据需求并提高可解释性。", "motivation": "解决大型语言模型在交互任务中缺乏程序性知识的问题，弥合声明性知识与程序性知识之间的差距。", "method": "将强化学习决策重新表述为语言建模任务，通过环境反馈迭代优化语言引导的策略。", "result": "TiG在性能上与常规RL方法相当，但数据需求和计算成本显著降低，并提供自然语言解释。", "conclusion": "TiG成功整合了LLMs的推理能力和RL的交互学习，提升了交互任务的透明度和效率。"}}
{"id": "2508.21394", "title": "AI Compute Architecture and Evolution Trends", "authors": ["Bor-Sung Liang"], "abstract": "The focus of AI development has shifted from academic research to practical applications. However, AI development faces numerous challenges at various levels. This article will attempt to analyze the opportunities and challenges of AI from several different perspectives using a structured approach. This article proposes a seven-layer model for AI compute architecture, including Physical Layer, Link Layer, Neural Network Layer, Context Layer, Agent Layer, Orchestrator Layer, and Application Layer, from bottom to top. It also explains how AI computing has evolved into this 7-layer architecture through the three-stage evolution on large-scale language models (LLMs). For each layer, we describe the development trajectory and key technologies. In Layers 1 and 2 we discuss AI computing issues and the impact of Scale-Up and Scale-Out strategies on computing architecture. In Layer 3 we explore two different development paths for LLMs. In Layer 4 we discuss the impact of contextual memory on LLMs and compares it to traditional processor memory. In Layers 5 to 7 we discuss the trends of AI agents and explore the issues in evolution from a single AI agent to an AI-based ecosystem, and their impact on the AI industry. Furthermore, AI development involves not only technical challenges but also the economic issues to build self-sustainable ecosystem. This article analyzes the internet industry to provide predictions on the future trajectory of AI development.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "29 pages, 26 figures", "pdf_url": "https://arxiv.org/pdf/2508.21394.pdf", "abstract_url": "https://arxiv.org/abs/2508.21394", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一个七层AI计算架构模型，分析AI从学术研究到实际应用的演变，涵盖技术挑战、经济问题及未来趋势。", "motivation": "解决AI发展从理论到实践中的多层次挑战，包括技术和经济问题。", "method": "使用结构化方法，提出七层架构模型（物理层到应用层），并基于大语言模型的三阶段演变进行分析。", "result": "识别了各层的关键技术和演变轨迹，讨论了Scale-Up/Scale-Out策略、LLM发展路径、上下文记忆影响，以及AI代理和生态系统的趋势。", "conclusion": "AI发展需应对技术和经济挑战，借鉴互联网行业经验，预测未来可持续生态系统的构建。"}}
{"id": "2508.21411", "title": "CARJAN: Agent-Based Generation and Simulation of Traffic Scenarios with AJAN", "authors": ["Leonard Frank Neis", "Andre Antakli", "Matthias Klusch"], "abstract": "User-friendly modeling and virtual simulation of urban traffic scenarios with different types of interacting agents such as pedestrians, cyclists and autonomous vehicles remains a challenge. We present CARJAN, a novel tool for semi-automated generation and simulation of such scenarios based on the multi-agent engineering framework AJAN and the driving simulator CARLA. CARJAN provides a visual user interface for the modeling, storage and maintenance of traffic scenario layouts, and leverages SPARQL Behavior Tree-based decision-making and interactions for agents in dynamic scenario simulations in CARLA. CARJAN provides a first integrated approach for interactive, intelligent agent-based generation and simulation of virtual traffic scenarios in CARLA.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.21411.pdf", "abstract_url": "https://arxiv.org/abs/2508.21411", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "CARJAN是一个基于AJAN和CARLA的工具，用于半自动生成和模拟城市交通场景，支持行人、骑行者、自动驾驶车辆等多智能体交互，提供可视化界面和智能决策。", "motivation": "解决城市交通场景中不同类型智能体交互的建模和虚拟模拟挑战，提升用户友好性和自动化程度。", "method": "使用AJAN多智能体工程框架和CARLA驾驶模拟器，结合SPARQL行为树进行智能体决策和交互，提供可视化界面进行场景布局建模和存储。", "result": "CARJAN实现了在CARLA中交互式、智能化的交通场景生成和模拟，是首个集成方法。", "conclusion": "CARJAN提供了一个有效的工具，促进了虚拟交通场景的智能模拟，具有实际应用潜力。"}}
{"id": "2508.21137", "title": "How Does Cognitive Bias Affect Large Language Models? A Case Study on the Anchoring Effect in Price Negotiation Simulations", "authors": ["Yoshiki Takenami", "Yin Jou Huang", "Yugo Murawaki", "Chenhui Chu"], "abstract": "Cognitive biases, well-studied in humans, can also be observed in LLMs, affecting their reliability in real-world applications. This paper investigates the anchoring effect in LLM-driven price negotiations. To this end, we instructed seller LLM agents to apply the anchoring effect and evaluated negotiations using not only an objective metric but also a subjective metric. Experimental results show that LLMs are influenced by the anchoring effect like humans. Additionally, we investigated the relationship between the anchoring effect and factors such as reasoning and personality. It was shown that reasoning models are less prone to the anchoring effect, suggesting that the long chain of thought mitigates the effect. However, we found no significant correlation between personality traits and susceptibility to the anchoring effect. These findings contribute to a deeper understanding of cognitive biases in LLMs and to the realization of safe and responsible application of LLMs in society.", "subjects": "Computation and Language (cs.CL)", "comments": "work in progress", "pdf_url": "https://arxiv.org/pdf/2508.21137.pdf", "abstract_url": "https://arxiv.org/abs/2508.21137", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究大型语言模型（LLMs）在价格谈判模拟中的锚定效应，发现LLMs像人类一样受其影响，推理模型可减轻效应，但人格特质无显著相关。", "motivation": "解决LLMs中认知偏见（如锚定效应）影响其可靠性和实际应用安全性的问题。", "method": "使用卖家LLM代理应用锚定效应，通过客观和主观指标评估谈判，并分析推理和人格因素的影响。", "result": "LLMs受锚定效应影响；推理模型（长链思维）降低效应；人格特质无显著相关性。", "conclusion": "加深对LLMs认知偏见的理解，促进LLMs的安全和负责任社会应用。"}}
{"id": "2508.21475", "title": "MMSearch-Plus: A Simple Yet Challenging Benchmark for Multimodal Browsing Agents", "authors": ["Xijia Tao", "Yihua Teng", "Xinxing Su", "Xinyu Fu", "Jihao Wu", "Chaofan Tao", "Ziru Liu", "Haoli Bai", "Rui Liu", "Lingpeng Kong"], "abstract": "Large multimodal language models (MLLMs) are increasingly deployed as web agents, yet many multimodal browsing benchmarks can be solved by shallow, fixed workflows that lean on high-recall image search and nearby text-masking the genuinely multimodal challenges of fine-grained visual reasoning, provenance verification, and long-horizon tool use. We introduce MMSearch-Plus, a benchmark of 311 tasks that highly demand multimodal understanding while preserving the difficulty profile of strong text-only browsing suites. Each item is constructed to contain multiple weak, localized visual signals that must be extracted, propagated through iterative text-image search, and cross-validated under retrieval noise before answering. Our curation procedure, Spatial-Temporal Extrapolation, seeds questions whose answers require extrapolating from spatial cues (micro-text, part-level appearance, layouts, signage) and temporal traces (broadcast overlays, seasonal context) to out-of-image facts such as events, dates, and venues. We provide a model-agnostic agent framework with browsing tools and evaluate a range of closed and open MLLMs. The strongest agent (o3) attains 15.1% without search and 36.0% accuracy with rollout under our framework, while a strong open-source model (Qwen-2.5-VL-72B-Instruct) achieves 0.0% without search and 6.9% after 20 rounds of search. Beyond answer accuracy, we assess bounding-box production and cropped-image search, and conduct an error analysis that surfaces failures in source verification, part-based reasoning, and long-horizon planning.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2508.21475.pdf", "abstract_url": "https://arxiv.org/abs/2508.21475", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "MMSearch-Plus 是一个针对多模态浏览代理的基准测试，包含 311 个任务，强调细粒度视觉推理和长时程工具使用，评估模型在噪声检索下的性能。", "motivation": "解决现有多模态浏览基准测试中浅层工作流占主导的问题，突出真正多模态挑战，如视觉推理和来源验证。", "method": "使用空间-时间外推法构建任务，结合迭代文本-图像搜索和交叉验证，提供模型无关的代理框架进行评估。", "result": "最佳代理在无搜索时准确率为 15.1%，有搜索时达 36.0%；开源模型表现较差，无搜索时为 0.0%，搜索后为 6.9%。", "conclusion": "MMSearch-Plus 揭示了模型在来源验证和长时程规划方面的失败，强调了改进多模态代理的必要性。"}}
{"id": "2508.21441", "title": "A General Framework of Epistemic Forgetting and its Instantiation by Ranking Functions", "authors": ["Christoph Beierle", "Alexander Hahn", "Diana Howey", "Gabriele Kern-Isberner", "Kai Sauerwald"], "abstract": "Forgetting as a knowledge management operation deliberately ignores parts of the knowledge and beliefs of an agent, for various reasons. Forgetting has many facets, one may want to forget parts of the syntax, a proposition, or a conditional. In the literature, two main operators suitable for performing forgetting have been proposed and investigated in depth: First, variable elimination is a syntactical method that blends out certain atomic variables to focus on the rest of the language. It has been mainly used in the area of logic programming and answer set programming. Second, contraction in AGM belief revision theory effectively removes propositions from belief sets under logical deduction. Both operations rely mainly on classical logics. In this article, we take an epistemic perspective and study forgetting operations in epistemic states with richer semantic structures, but with clear links to propositional logic. This allows us to investigate what forgetting in the epistemic background means, thereby lifting well-known and novel forgetting operations to the epistemic level. We present five general types of epistemic forgetting and instantiate them with seven concrete forgetting operations for Spohn's ranking functions. We take inspiration from postulates of forgetting both from logic programming and AGM theory to propose a rich landscape of axioms for evaluating forgetting operations. Finally, we evaluate all concrete forgetting operations according to all postulates, leading to a novel comprehensive overview highlighting differences and commonalities among the forgetting operators.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.21441.pdf", "abstract_url": "https://arxiv.org/abs/2508.21441", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一个通用的认知遗忘框架，并将其实例化为排名函数，通过从逻辑编程和AGM理论中汲取灵感，定义了五种认知遗忘类型和七种具体操作，并基于公理进行评估，以揭示遗忘操作符的异同。", "motivation": "解决知识管理中遗忘操作的问题，传统方法如变量消除和AGM收缩主要基于经典逻辑，缺乏在更丰富语义结构（如认知状态）中的系统研究。", "method": "采用认知视角，研究认知状态中的遗忘操作，定义通用框架并实例化为Spohn排名函数，提出公理体系进行评估。", "result": "提出了五种认知遗忘类型和七种具体操作，通过公理评估揭示了操作符之间的差异和共性，提供了全面的概述。", "conclusion": "该框架扩展了遗忘操作到认知层面，为知识管理提供了更丰富的工具，并强调了不同遗忘方法的适用性和局限性。"}}
{"id": "2508.21456", "title": "Morae: Proactively Pausing UI Agents for User Choices", "authors": ["Yi-Hao Peng", "Dingzeyu Li", "Jeffrey P. Bigham", "Amy Pavel"], "abstract": "User interface (UI) agents promise to make inaccessible or complex UIs easier to access for blind and low-vision (BLV) users. However, current UI agents typically perform tasks end-to-end without involving users in critical choices or making them aware of important contextual information, thus reducing user agency. For example, in our field study, a BLV participant asked to buy the cheapest available sparkling water, and the agent automatically chose one from several equally priced options, without mentioning alternative products with different flavors or better ratings. To address this problem, we introduce Morae, a UI agent that automatically identifies decision points during task execution and pauses so that users can make choices. Morae uses large multimodal models to interpret user queries alongside UI code and screenshots, and prompt users for clarification when there is a choice to be made. In a study over real-world web tasks with BLV participants, Morae helped users complete more tasks and select options that better matched their preferences, as compared to baseline agents, including OpenAI Operator. More broadly, this work exemplifies a mixed-initiative approach in which users benefit from the automation of UI agents while being able to express their preferences.", "subjects": "Human-Computer Interaction (cs.HC); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)", "comments": "ACM UIST 2025", "pdf_url": "https://arxiv.org/pdf/2508.21456.pdf", "abstract_url": "https://arxiv.org/abs/2508.21456", "categories": ["Human-Computer Interaction (cs.HC)", "Computation and Language (cs.CL)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "Morae是一种UI代理，通过暂停让用户在决策点做出选择，提高盲人和低视力用户的任务完成率和偏好匹配。", "motivation": "解决当前UI代理在任务执行中不涉及用户选择，减少用户代理权的问题，如自动选择忽略替代选项。", "method": "使用大型多模态模型解释用户查询、UI代码和截图，自动识别决策点并暂停提示用户澄清。", "result": "在真实网络任务研究中，Morae比基线代理（如OpenAI Operator）帮助用户完成更多任务并更好匹配偏好。", "conclusion": "Morae展示了混合主动方法，用户从自动化中受益同时能表达偏好，提升可访问性和用户控制。"}}
{"id": "2508.21184", "title": "BED-LLM: Intelligent Information Gathering with LLMs and Bayesian Experimental Design", "authors": ["Deepro Choudhury", "Sinead Williamson", "Adam Goliński", "Ning Miao", "Freddie Bickford Smith", "Michael Kirchhof", "Yizhe Zhang", "Tom Rainforth"], "abstract": "We propose a general-purpose approach for improving the ability of Large Language Models (LLMs) to intelligently and adaptively gather information from a user or other external source using the framework of sequential Bayesian experimental design (BED). This enables LLMs to act as effective multi-turn conversational agents and interactively interface with external environments. Our approach, which we call BED-LLM (Bayesian Experimental Design with Large Language Models), is based on iteratively choosing questions or queries that maximize the expected information gain (EIG) about the task of interest given the responses gathered previously. We show how this EIG can be formulated in a principled way using a probabilistic model derived from the LLM's belief distribution and provide detailed insights into key decisions in its construction. Further key to the success of BED-LLM are a number of specific innovations, such as a carefully designed estimator for the EIG, not solely relying on in-context updates for conditioning on previous responses, and a targeted strategy for proposing candidate queries. We find that BED-LLM achieves substantial gains in performance across a wide range of tests based on the 20-questions game and using the LLM to actively infer user preferences, compared to direct prompting of the LLM and other adaptive design strategies.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.21184.pdf", "abstract_url": "https://arxiv.org/abs/2508.21184", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (stat.ML)"], "matching_keywords": ["agent"], "AI": {"tldr": "BED-LLM 是一种结合大型语言模型和贝叶斯实验设计的通用方法，用于智能自适应地收集信息，在对话代理和外部环境交互中显著提升性能。", "motivation": "解决大型语言模型在信息收集时缺乏智能和自适应能力的问题，以改善多轮对话和外部接口的有效性。", "method": "使用序列贝叶斯实验设计框架，迭代选择最大化预期信息增益的问题，基于LLM的信念分布构建概率模型，并引入EIG估计器和候选查询策略。", "result": "在20个问题游戏和用户偏好推断测试中，BED-LLM相比直接提示和其他自适应策略，实现了显著的性能提升。", "conclusion": "BED-LLM提供了一种原则性方法，增强LLMs的交互能力，具有广泛的应用潜力。"}}
{"id": "2508.21148", "title": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers", "authors": ["Ming Hu", "Chenglong Ma", "Wei Li", "Wanghan Xu", "Jiamin Wu", "Jucheng Hu", "Tianbin Li", "Guohang Zhuang", "Jiaqi Liu", "Yingzhou Lu", "Ying Chen", "Chaoyang Zhang", "Cheng Tan", "Jie Ying", "Guocheng Wu", "Shujian Gao", "Pengcheng Chen", "Jiashi Lin", "Haitao Wu", "Lulu Chen", "Fengxiang Wang", "Yuanyuan Zhang", "Xiangyu Zhao", "Feilong Tang", "Encheng Su", "Junzhi Ning", "Xinyao Liu", "Ye Du", "Changkai Ji", "Cheng Tang", "Huihui Xu", "Ziyang Chen", "Ziyan Huang", "Jiyao Liu", "Pengfei Jiang", "Yizhou Wang", "Chen Tang", "Jianyu Wu", "Yuchen Ren", "Siyuan Yan", "Zhonghua Wang", "Zhongxing Xu", "Shiyan Su", "Shangquan Sun", "Runkai Zhao", "Zhisheng Zhang", "Yu Liu", "Fudi Wang", "Yuanfeng Ji", "Yanzhou Su", "Hongming Shan", "Chunmei Feng", "Jiahao Xu", "Jiangtao Yan", "Wenhao Tang", "Diping Song", "Lihao Liu", "Yanyan Huang", "Lequan Yu", "Bin Fu", "Shujun Wang", "Xiaomeng Li", "Xiaowei Hu", "Yun Gu", "Ben Fei", "Zhongying Deng", "Benyou Wang", "Yuewen Cao", "Minjie Shen", "Haodong Duan", "Jie Xu", "Yirong Chen", "Fang Yan", "Hongxia Hao", "Jielan Li", "Jiajun Du", "Yanbo Wang", "Imran Razzak", "Chi Zhang", "Lijun Wu", "Conghui He", "Zhaohui Lu", "Jinhai Huang", "Yihao Liu", "Fenghua Ling", "Yuqiang Li", "Aoran Wang", "Qihao Zheng", "Nanqing Dong", "Tianfan Fu", "Dongzhan Zhou", "Yan Lu", "Wenlong Zhang", "Jin Ye", "Jianfei Cai", "Wanli Ouyang", "Yu Qiao", "Zongyuan Ge", "Shixiang Tang", "Junjun He"], "abstract": "Scientific Large Language Models (Sci-LLMs) are transforming how knowledge is represented, integrated, and applied in scientific research, yet their progress is shaped by the complex nature of scientific data. This survey presents a comprehensive, data-centric synthesis that reframes the development of Sci-LLMs as a co-evolution between models and their underlying data substrate. We formulate a unified taxonomy of scientific data and a hierarchical model of scientific knowledge, emphasizing the multimodal, cross-scale, and domain-specific challenges that differentiate scientific corpora from general natural language processing datasets. We systematically review recent Sci-LLMs, from general-purpose foundations to specialized models across diverse scientific disciplines, alongside an extensive analysis of over 270 pre-/post-training datasets, showing why Sci-LLMs pose distinct demands -- heterogeneous, multi-scale, uncertainty-laden corpora that require representations preserving domain invariance and enabling cross-modal reasoning. On evaluation, we examine over 190 benchmark datasets and trace a shift from static exams toward process- and discovery-oriented assessments with advanced evaluation protocols. These data-centric analyses highlight persistent issues in scientific data development and discuss emerging solutions involving semi-automated annotation pipelines and expert validation. Finally, we outline a paradigm shift toward closed-loop systems where autonomous agents based on Sci-LLMs actively experiment, validate, and contribute to a living, evolving knowledge base. Collectively, this work provides a roadmap for building trustworthy, continually evolving artificial intelligence (AI) systems that function as a true partner in accelerating scientific discovery.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.21148.pdf", "abstract_url": "https://arxiv.org/abs/2508.21148", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本调查全面综述了科学大语言模型（Sci-LLMs），从数据基础到代理前沿，强调数据与模型的协同进化，并提出了统一分类法和评估框架，旨在构建可信赖的AI系统以加速科学发现。", "motivation": "解决科学数据复杂性和Sci-LLMs发展中的挑战，如多模态、跨尺度和领域特定问题，以改进科学知识的表示和应用。", "method": "采用数据为中心的综合方法，包括制定科学数据分类法、知识层次模型，并系统回顾Sci-LLMs和相关数据集，使用超过270个数据集和190个基准进行评估。", "result": "分析显示Sci-LLMs需要处理异构、多尺度和不确定性数据，评估从静态测试转向过程导向，并讨论了半自动标注和专家验证等解决方案。", "conclusion": "Sci-LLMs推动向闭环系统范式转变，基于自主代理的实验和验证，可构建持续进化的AI伙伴，加速科学发现。"}}
{"id": "2508.21720", "title": "PosterForest: Hierarchical Multi-Agent Collaboration for Scientific Poster Generation", "authors": ["Jiho Choi", "Seojeong Park", "Seongjong Song", "Hyunjung Shim"], "abstract": "We present a novel training-free framework, \\textit{PosterForest}, for automated scientific poster generation. Unlike prior approaches, which largely neglect the hierarchical structure of scientific documents and the semantic integration of textual and visual elements, our method addresses both challenges directly. We introduce the \\textit{Poster Tree}, a hierarchical intermediate representation that jointly encodes document structure and visual-textual relationships at multiple levels. Our framework employs a multi-agent collaboration strategy, where agents specializing in content summarization and layout planning iteratively coordinate and provide mutual feedback. This approach enables the joint optimization of logical consistency, content fidelity, and visual coherence. Extensive experiments on multiple academic domains show that our method outperforms existing baselines in both qualitative and quantitative evaluations. The resulting posters achieve quality closest to expert-designed ground truth and deliver superior information preservation, structural clarity, and user preference.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.21720.pdf", "abstract_url": "https://arxiv.org/abs/2508.21720", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "PosterForest是一种无需训练的框架，通过多智能体协作和层级树结构，自动生成科学海报，优于现有方法。", "motivation": "解决现有方法忽视科学文档层级结构和文本-视觉元素语义整合的问题。", "method": "使用Poster Tree层级表示和多智能体协作策略，迭代优化内容摘要和布局规划。", "result": "在多个学术领域实验中，方法在定性和定量评估中超越基线，海报质量接近专家设计。", "conclusion": "框架提升了信息保留、结构清晰度和用户偏好，具有实际应用价值。"}}
{"id": "2508.21595", "title": "Scalable Solution Methods for Dec-POMDPs with Deterministic Dynamics", "authors": ["Yang You", "Alex Schutz", "Zhikun Li", "Bruno Lacerda", "Robert Skilton", "Nick Hawes"], "abstract": "Many high-level multi-agent planning problems, including multi-robot navigation and path planning, can be effectively modeled using deterministic actions and observations.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.21595.pdf", "abstract_url": "https://arxiv.org/abs/2508.21595", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文针对具有确定性动态的Dec-POMDPs，提出了可扩展的解决方案方法，以高效处理多智能体规划问题，如多机器人导航和路径规划。", "motivation": "解决多智能体规划问题中确定性动作和观测的建模挑战，以提高可扩展性和效率。", "method": "使用确定性动态的Dec-POMDPs框架，开发可扩展的算法来处理多智能体决策。", "result": "方法在模拟和实际应用中显示出高效性和可扩展性，适用于复杂多智能体场景。", "conclusion": "确定性动态的Dec-POMDPs为多智能体规划提供了有效工具，具有实际应用潜力。"}}
{"id": "2508.21622", "title": "Integrating Large Language Models with Network Optimization for Interactive and Explainable Supply Chain Planning: A Real-World Case Study", "authors": ["Saravanan Venkatachalam"], "abstract": "This paper presents an integrated framework that combines traditional network optimization models with large language models (LLMs) to deliver interactive, explainable, and role-aware decision support for supply chain planning. The proposed system bridges the gap between complex operations research outputs and business stakeholder understanding by generating natural language summaries, contextual visualizations, and tailored key performance indicators (KPIs). The core optimization model addresses tactical inventory redistribution across a network of distribution centers for multi-period and multi-item, using a mixed-integer formulation. The technical architecture incorporates AI agents, RESTful APIs, and a dynamic user interface to support real-time interaction, configuration updates, and simulation-based insights. A case study demonstrates how the system improves planning outcomes by preventing stockouts, reducing costs, and maintaining service levels. Future extensions include integrating private LLMs, transfer learning, reinforcement learning, and Bayesian neural networks to enhance explainability, adaptability, and real-time decision-making.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.21622.pdf", "abstract_url": "https://arxiv.org/abs/2508.21622", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种将大型语言模型与网络优化相结合的框架，用于交互式、可解释的供应链规划，通过案例研究展示了其在减少缺货、降低成本方面的有效性。", "motivation": "解决复杂运筹学输出与业务利益相关者理解之间的差距，提供更易理解和交互的决策支持。", "method": "集成传统网络优化模型（如混合整数规划）与大型语言模型，使用AI代理、API和动态用户界面实现实时交互和模拟。", "result": "系统通过案例研究证明能改善规划结果，防止缺货、减少成本并保持服务水平。", "conclusion": "框架有效提升了供应链规划的可解释性和交互性，未来可扩展以增强适应性和实时决策能力。"}}
{"id": "2508.21803", "title": "Automated Clinical Problem Detection from SOAP Notes using a Collaborative Multi-Agent LLM Architecture", "authors": ["Yeawon Lee", "Xiaoyang Wang", "Christopher C. Yang"], "abstract": "Accurate interpretation of clinical narratives is critical for patient care, but the complexity of these notes makes automation challenging. While Large Language Models (LLMs) show promise, single-model approaches can lack the robustness required for high-stakes clinical tasks. We introduce a collaborative multi-agent system (MAS) that models a clinical consultation team to address this gap. The system is tasked with identifying clinical problems by analyzing only the Subjective (S) and Objective (O) sections of SOAP notes, simulating the diagnostic reasoning process of synthesizing raw data into an assessment. A Manager agent orchestrates a dynamically assigned team of specialist agents who engage in a hierarchical, iterative debate to reach a consensus. We evaluated our MAS against a single-agent baseline on a curated dataset of 420 MIMIC-III notes. The dynamic multi-agent configuration demonstrated consistently improved performance in identifying congestive heart failure, acute kidney injury, and sepsis. Qualitative analysis of the agent debates reveals that this structure effectively surfaces and weighs conflicting evidence, though it can occasionally be susceptible to groupthink. By modeling a clinical team's reasoning process, our system offers a promising path toward more accurate, robust, and interpretable clinical decision support tools.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "Accepted to The 16th ACM Conference on Bioinformatics, Computational Biology, and Health Informatics (ACM-BCB 2025)(Poster Paper)", "pdf_url": "https://arxiv.org/pdf/2508.21803.pdf", "abstract_url": "https://arxiv.org/abs/2508.21803", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "使用协作多智能体LLM架构从SOAP笔记中自动检测临床问题，通过模拟临床团队推理过程，在MIMIC-III数据集上验证了性能提升。", "motivation": "解决临床叙述复杂性导致的自动化挑战，单模型方法在高风险临床任务中缺乏鲁棒性。", "method": "引入协作多智能体系统，由Manager代理协调专家代理进行分层迭代辩论，仅分析SOAP笔记的S和O部分。", "result": "动态多智能体配置在识别充血性心力衰竭、急性肾损伤和败血症方面性能优于单智能体基线，但偶尔易受群体思维影响。", "conclusion": "该系统通过模拟临床团队推理，为更准确、鲁棒和可解释的临床决策支持工具提供了有前景的路径。"}}
{"id": "2508.21097", "title": "Model-Driven Quantum Code Generation Using Large Language Models and Retrieval-Augmented Generation", "authors": ["Nazanin Siavash", "Armin Moin"], "abstract": "This paper introduces a novel research direction for model-to-text/code transformations by leveraging Large Language Models (LLMs) that can be enhanced with Retrieval-Augmented Generation (RAG) pipelines. The focus is on quantum and hybrid quantum-classical software systems, where model-driven approaches can help reduce the costs and mitigate the risks associated with the heterogeneous platform landscape and lack of developers' skills. We validate one of the proposed ideas regarding generating code out of UML model instances of software systems. This Python code uses a well-established library, called Qiskit, to execute on gate-based or circuit-based quantum computers. The RAG pipeline that we deploy incorporates sample Qiskit code from public GitHub repositories. Experimental results show that well-engineered prompts can improve CodeBLEU scores by up to a factor of four, yielding more accurate and consistent quantum code. However, the proposed research direction can go beyond this through further investigation in the future by conducting experiments to address our other research questions and ideas proposed here, such as deploying software system model instances as the source of information in the RAG pipelines, or deploying LLMs for code-to-code transformations, for instance, for transpilation use cases.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": "This paper is accepted to the New Ideas and Emerging Results (NIER) track of the ACM/IEEE 28th International Conference on Model Driven Engineering Languages and Systems (MODELS)", "pdf_url": "https://arxiv.org/pdf/2508.21097.pdf", "abstract_url": "https://arxiv.org/abs/2508.21097", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种利用大型语言模型和检索增强生成进行模型驱动量子代码生成的新方法，通过UML模型实例生成Qiskit代码，实验显示提示工程可将CodeBLEU分数提高四倍。", "motivation": "解决量子软件系统中平台异构和开发者技能不足导致的成本和风险问题。", "method": "使用LLM和RAG管道，从GitHub仓库检索Qiskit代码样本，生成Python代码。", "result": "优化提示后，CodeBLEU分数提升高达四倍，生成代码更准确和一致。", "conclusion": "该方法有效，未来可扩展至模型实例作为RAG信息源或代码到代码转换。"}}
{"id": "2508.21476", "title": "Igniting Creative Writing in Small Language Models: LLM-as-a-Judge versus Multi-Agent Refined Rewards", "authors": ["Xiaolong Wei", "Bo Lu", "Xingyu Zhang", "Zhejun Zhao", "Dongdong Shen", "Long Xia", "Dawei Yin"], "abstract": "Large Language Models (LLMs) have demonstrated remarkable creative writing capabilities, yet their substantial computational demands hinder widespread use. Enhancing Small Language Models (SLMs) offers a promising alternative, but current methods like Supervised Fine-Tuning (SFT) struggle with novelty, and Reinforcement Learning from Human Feedback (RLHF) is costly. This paper explores two distinct AI-driven reward strategies within a Reinforcement Learning from AI Feedback (RLAIF) framework to ignite the creative writing of a 7B-parameter SLM, specifically for generating Chinese greetings. The first strategy employs a RM trained on high-quality preference data curated by a novel multi-agent rejection sampling framework designed for creative tasks. The second, more novel strategy utilizes a principle-guided LLM-as-a-Judge, whose reward function is optimized via an adversarial training scheme with a reflection mechanism, to directly provide reward signals. Comprehensive experiments reveal that while both approaches significantly enhance creative output over baselines, the principle-guided LLM-as-a-Judge demonstrably yields superior generation quality. Furthermore, it offers notable advantages in training efficiency and reduced dependency on human-annotated data, presenting a more scalable and effective path towards creative SLMs. Our automated evaluation methods also exhibit strong alignment with human judgments. Our code and data are publicly available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "EMNLP 2025 Main", "pdf_url": "https://arxiv.org/pdf/2508.21476.pdf", "abstract_url": "https://arxiv.org/abs/2508.21476", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探索了两种AI驱动的奖励策略，在RLAIF框架下提升7B参数小语言模型的创意写作能力，特别是中文问候生成，发现原则引导的LLM-as-a-Judge方法在质量和效率上更优。", "motivation": "解决大型语言模型计算成本高的问题，通过增强小语言模型的创意写作能力，但现有方法如SFT缺乏新颖性，RLHF成本高昂。", "method": "使用RLAIF框架，比较两种奖励策略：一是基于多智能体拒绝采样的奖励模型，二是原则引导的LLM-as-a-Judge通过对抗训练和反思机制提供奖励。", "result": "两种方法均显著提升创意输出，但LLM-as-a-Judge方法在生成质量、训练效率和减少人类数据依赖方面更优，自动评估与人类判断一致。", "conclusion": "原则引导的LLM-as-a-Judge策略为创意小语言模型提供了更可扩展和有效的路径，代码和数据公开可用。"}}
{"id": "2508.21104", "title": "PVPO: Pre-Estimated Value-Based Policy Optimization for Agentic Reasoning", "authors": ["Wenfeng Feng", "Penghong Zhao", "Guochao Jiang", "Chuzhan Hao", "Yuewei Zhang", "Hao Wang"], "abstract": "Critic-free reinforcement learning methods, particularly group policies, have attracted considerable attention for their efficiency in complex tasks. However, these methods rely heavily on multiple sampling and comparisons within the policy to estimate advantage, which may cause the policy to fall into local optimum and increase computational cost. To address these issues, we propose PVPO, an efficient reinforcement learning method enhanced by an advantage reference anchor and data pre-sampling. Specifically, we use the reference model to rollout in advance and employ the calculated reward score as a reference anchor. Our approach effectively corrects the cumulative bias introduced by intra-group comparisons and significantly reduces reliance on the number of rollouts. Meanwhile, the reference model can assess sample difficulty during data pre-sampling, enabling effective selection of high-gain data to improve training efficiency. Experiments conducted on nine datasets across two domains demonstrate that PVPO achieves State-Of-The-Art (SOTA) performance. Our approach not only demonstrates robust generalization across multiple tasks, but also exhibits scalable performance across models of varying scales.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "14 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2508.21104.pdf", "abstract_url": "https://arxiv.org/abs/2508.21104", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "PVPO是一种高效的强化学习方法，通过优势参考锚点和数据预采样减少计算成本并避免局部最优，在多个数据集上实现SOTA性能。", "motivation": "解决无批评强化学习方法依赖多次采样和比较导致局部最优和高计算成本的问题。", "method": "使用参考模型提前滚动计算奖励分数作为优势参考锚点，结合数据预采样选择高增益数据。", "result": "在九个数据集上实现SOTA性能，展示强泛化能力和可扩展性。", "conclusion": "PVPO有效提高训练效率和性能，适用于多种任务和模型规模。"}}
{"id": "2508.21101", "title": "Beyond Prediction: Reinforcement Learning as the Defining Leap in Healthcare AI", "authors": ["Dilruk Perera", "Gousia Habib", "Qianyi Xu", "Daniel J. Tan", "Kai He", "Erik Cambria", "Mengling Feng"], "abstract": "Reinforcement learning (RL) marks a fundamental shift in how artificial intelligence is applied in healthcare. Instead of merely predicting outcomes, RL actively decides interventions with long term goals. Unlike traditional models that operate on fixed associations, RL systems learn through trial, feedback, and long-term reward optimization, introducing transformative possibilities and new risks. From an information fusion lens, healthcare RL typically integrates multi-source signals such as vitals, labs clinical notes, imaging and device telemetry using temporal and decision-level mechanisms. These systems can operate within centralized, federated, or edge architectures to meet real-time clinical constraints, and naturally span data, features and decision fusion levels. This survey explore RL's rise in healthcare as more than a set of tools, rather a shift toward agentive intelligence in clinical environments. We first structure the landscape of RL techniques including model-based and model-free methods, offline and batch-constrained approaches, and emerging strategies for reward specification and uncertainty calibration through the lens of healthcare constraints. We then comprehensively analyze RL applications spanning critical care, chronic disease, mental health, diagnostics, and robotic assistance, identifying their trends, gaps, and translational bottlenecks. In contrast to prior reviews, we critically analyze RL's ethical, deployment, and reward design challenges, and synthesize lessons for safe, human-aligned policy learning. This paper serves as both a a technical roadmap and a critical reflection of RL's emerging transformative role in healthcare AI not as prediction machinery, but as agentive clinical intelligence.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "40 pages in total (including appendix)", "pdf_url": "https://arxiv.org/pdf/2508.21101.pdf", "abstract_url": "https://arxiv.org/abs/2508.21101", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨强化学习在医疗AI中的根本转变，从预测转向主动决策，涵盖技术、应用和伦理挑战。", "motivation": "解决传统AI模型仅预测结果的问题，通过强化学习实现长期目标导向的干预决策。", "method": "使用强化学习技术，包括基于模型和无模型方法、离线学习，并整合多源数据如生命体征和临床笔记。", "result": "强化学习在重症监护、慢性病等领域有应用潜力，但存在伦理和部署挑战。", "conclusion": "强化学习代表医疗AI向代理智能的转变，需关注安全性和人类对齐，以促进临床转化。"}}
{"id": "2508.21111", "title": "Automating the Deep Space Network Data Systems; A Case Study in Adaptive Anomaly Detection through Agentic AI", "authors": ["Evan J. Chou", "Lisa S. Locke", "Harvey M. Soldan"], "abstract": "The Deep Space Network (DSN) is NASA's largest network of antenna facilities that generate a large volume of multivariate time-series data. These facilities contain DSN antennas and transmitters that undergo degradation over long periods of time, which may cause costly disruptions to the data flow and threaten the earth-connection of dozens of spacecraft that rely on the Deep Space Network for their lifeline. The purpose of this study was to experiment with different methods that would be able to assist JPL engineers with directly pinpointing anomalies and equipment degradation through collected data, and continue conducting maintenance and operations of the DSN for future space missions around our universe. As such, we have researched various machine learning techniques that can fully reconstruct data through predictive analysis, and determine anomalous data entries within real-time datasets through statistical computations and thresholds. On top of the fully trained and tested machine learning models, we have also integrated the use of a reinforcement learning subsystem that classifies identified anomalies based on severity level and a Large Language Model that labels an explanation for each anomalous data entry, all of which can be improved and fine-tuned over time through human feedback/input. Specifically, for the DSN transmitters, we have also implemented a full data pipeline system that connects the data extraction, parsing, and processing workflow all together as there was no coherent program or script for performing these tasks before. Using this data pipeline system, we were able to then also connect the models trained from DSN antenna data, completing the data workflow for DSN anomaly detection. This was all wrapped around and further connected by an agentic AI system, where complex reasoning was utilized to determine the classifications and predictions of anomalous data.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.21111.pdf", "abstract_url": "https://arxiv.org/abs/2508.21111", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文通过结合机器学习、强化学习和大型语言模型，开发了一个基于智能AI的异常检测系统，用于自动化NASA深空网络数据系统的异常检测和设备退化监控，以提高维护效率和可靠性。", "motivation": "解决深空网络设备因长期退化导致的昂贵中断和数据流问题，确保航天器连接的可靠性。", "method": "使用机器学习进行预测分析和统计阈值检测，集成强化学习子系统分类异常严重程度，大型语言模型提供解释，并通过人类反馈优化，构建完整的数据管道和智能AI系统。", "result": "成功实现了数据管道的整合和异常检测模型的训练，能够实时识别和分类异常数据。", "conclusion": "该系统可提高深空网络维护的自动化水平，支持未来太空任务，并通过持续学习优化性能。"}}
{"id": "2508.21209", "title": "Designing Smarter Conversational Agents for Kids: Lessons from Cognitive Work and Means-Ends Analyses", "authors": ["Vanessa Figueiredo"], "abstract": "This paper presents two studies on how Brazilian children (ages 9--11) use conversational agents (CAs) for schoolwork, discovery, and entertainment, and how structured scaffolds can enhance these interactions. In Study 1, a seven-week online investigation with 23 participants (children, parents, teachers) employed interviews, observations, and Cognitive Work Analysis to map children's information-processing flows, the role of more knowledgeable others, functional uses, contextual goals, and interaction patterns to inform conversation-tree design. We identified three CA functions: School, Discovery, Entertainment, and derived ``recipe'' scaffolds mirroring parent-child support. In Study 2, we prompted GPT-4o-mini on 1,200 simulated child-CA exchanges, comparing conversation-tree recipes based on structured-prompting to an unstructured baseline. Quantitative evaluation of readability, question count/depth/diversity, and coherence revealed gains for the recipe approach. Building on these findings, we offer design recommendations: scaffolded conversation-trees, child-dedicated profiles for personalized context, and caregiver-curated content. Our contributions include the first CWA application with Brazilian children, an empirical framework of child-CA information flows, and an LLM-scaffolding ``recipe'' (i.e., structured-prompting) for effective, scaffolded learning.", "subjects": "Human-Computer Interaction (cs.HC); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.21209.pdf", "abstract_url": "https://arxiv.org/abs/2508.21209", "categories": ["Human-Computer Interaction (cs.HC)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过两项研究探讨巴西儿童使用对话代理（CAs）的情况，并基于认知工作分析和结构化提示开发了脚手架方法，以提升交互效果，提出了设计建议。", "motivation": "解决儿童在使用对话代理进行学习、探索和娱乐时面临的交互效率和个性化支持不足的问题。", "method": "采用认知工作分析映射信息流，并通过GPT-4o-mini模拟对话，比较结构化提示与无结构基线。", "result": "结构化方法在可读性、问题数量/深度/多样性和连贯性方面优于基线，验证了脚手架的有效性。", "conclusion": "建议使用脚手架对话树、儿童专用配置文件和看护者策划内容，为儿童对话代理设计提供实证框架和实用方法。"}}
{"id": "2508.21246", "title": "HCQA: Hybrid Classical-Quantum Agent for Generating Optimal Quantum Sensor Circuits", "authors": ["Ahmad Alomari", "Sathish A. P. Kumar"], "abstract": "This study proposes an HCQA for designing optimal Quantum Sensor Circuits (QSCs) to address complex quantum physics problems. The HCQA integrates computational intelligence techniques by leveraging a Deep Q-Network (DQN) for learning and policy optimization, enhanced by a quantum-based action selection mechanism based on the Q-values. A quantum circuit encodes the agent current state using Ry gates, and then creates a superposition of possible actions. Measurement of the circuit results in probabilistic action outcomes, allowing the agent to generate optimal QSCs by selecting sequences of gates that maximize the Quantum Fisher Information (QFI) while minimizing the number of gates. This computational intelligence-driven HCQA enables the automated generation of entangled quantum states, specifically the squeezed states, with high QFI sensitivity for quantum state estimation and control. Evaluation of the HCQA on a QSC that consists of two qubits and a sequence of Rx, Ry, and S gates demonstrates its efficiency in generating optimal QSCs with a QFI of 1. This work highlights the synergy between AI-driven learning and quantum computation, illustrating how intelligent agents can autonomously discover optimal quantum circuit designs for enhanced sensing and estimation tasks.", "subjects": "Quantum Physics (quant-ph); Artificial Intelligence (cs.AI)", "comments": "9 pages, 9 figures", "pdf_url": "https://arxiv.org/pdf/2508.21246.pdf", "abstract_url": "https://arxiv.org/abs/2508.21246", "categories": ["Quantum Physics (quant-ph)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本研究提出了一种混合经典-量子代理（HCQA），用于自动生成最优量子传感器电路（QSCs），通过结合深度Q网络和量子机制优化门序列，以提高量子费舍尔信息（QFI）并减少门数，在双量子比特系统上验证了高效性。", "motivation": "解决复杂量子物理问题中设计最优量子传感器电路的挑战，以实现自动化和高灵敏度的量子状态估计与控制。", "method": "使用深度Q网络（DQN）进行学习和策略优化，结合基于Q值的量子动作选择机制，通过Ry门编码状态和创建动作叠加，测量电路以概率性选择动作，最大化QFI并最小化门数。", "result": "在双量子比特和Rx、Ry、S门序列的QSC上评估，HCQA能高效生成最优电路，QFI达到1，成功产生纠缠压缩态。", "conclusion": "HCQA展示了AI驱动学习与量子计算的协同作用，为自动发现最优量子电路设计提供了新途径，提升了量子传感和估计任务的性能。"}}
{"id": "2508.21253", "title": "Reinforcement Learning for Optimizing Large Qubit Array based Quantum Sensor Circuits", "authors": ["Laxmisha Ashok Attisara", "Sathish Kumar"], "abstract": "As the number of qubits in a sensor increases, the complexity of designing and controlling the quantum circuits grows exponentially. Manually optimizing these circuits becomes infeasible. Optimizing entanglement distribution in large-scale quantum circuits is critical for enhancing the sensitivity and efficiency of quantum sensors [5], [6]. This paper presents an engineering integration of reinforcement learning with tensor-network-based simulation (MPS) for scalable circuit optimization for optimizing quantum sensor circuits with up to 60 qubits. To enable efficient simulation and scalability, we adopt tensor network methods, specifically the Matrix Product State (MPS) representation, instead of traditional state vector or density matrix approaches. Our reinforcement learning agent learns to restructure circuits to maximize Quantum Fisher Information (QFI) and entanglement entropy while reducing gate counts and circuit depth. Experimental results show consistent improvements, with QFI values approaching 1, entanglement entropy in the 0.8-1.0 range, and up to 90% reduction in depth and gate count. These results highlight the potential of combining quantum machine learning and tensor networks to optimize complex quantum circuits under realistic constraints.", "subjects": "Quantum Physics (quant-ph); Artificial Intelligence (cs.AI)", "comments": "10 pages, 13 figures, 2 tables", "pdf_url": "https://arxiv.org/pdf/2508.21253.pdf", "abstract_url": "https://arxiv.org/abs/2508.21253", "categories": ["Quantum Physics (quant-ph)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种结合强化学习和张量网络模拟的方法，用于优化多达60量子比特的量子传感器电路，以提高量子费舍尔信息和纠缠熵，同时减少门数和电路深度，实验结果显示显著改进。", "motivation": "随着量子比特数量增加，手动优化量子电路的复杂性呈指数增长，变得不可行，需要自动化方法来优化纠缠分布以提升量子传感器的灵敏度和效率。", "method": "采用强化学习与基于张量网络（MPS）的模拟相结合，代理学习重构电路以最大化量子费舍尔信息和纠缠熵，并减少门数和深度。", "result": "实验结果表明，量子费舍尔信息接近1，纠缠熵在0.8-1.0范围内，深度和门数减少高达90%，显示出一致改进。", "conclusion": "结合量子机器学习和张量网络有潜力在现实约束下优化复杂量子电路，为大规模量子传感器设计提供有效途径。"}}
{"id": "2508.21302", "title": "Locus: Agentic Predicate Synthesis for Directed Fuzzing", "authors": ["Jie Zhu", "Chihao Shen", "Ziyang Li", "Jiahao Yu", "Yizheng Chen", "Kexin Pei"], "abstract": "Directed fuzzing aims to find program inputs that lead to specified target program states. It has broad applications, such as debugging system crashes, confirming reported bugs, and generating exploits for potential vulnerabilities. This task is inherently challenging because target states are often deeply nested in the program, while the search space manifested by numerous possible program inputs is prohibitively large. Existing approaches rely on branch distances or manually-specified constraints to guide the search; however, the branches alone are often insufficient to precisely characterize progress toward reaching the target states, while the manually specified constraints are often tailored for specific bug types and thus difficult to generalize to diverse target states and programs.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Software Engineering (cs.SE)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.21302.pdf", "abstract_url": "https://arxiv.org/abs/2508.21302", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Software Engineering (cs.SE)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出Locus方法，通过自动合成谓词来指导定向模糊测试，以更精确地引导搜索到达目标程序状态，提高效率和通用性。", "motivation": "定向模糊测试在寻找导致特定程序状态的输入时面临挑战，因为目标状态深嵌且搜索空间巨大，现有方法依赖分支距离或手动约束，但不够精确且难以泛化。", "method": "使用代理式谓词合成方法，自动生成谓词来精确指导搜索过程，避免依赖不足的手动或分支信息。", "result": "Locus方法能更有效地引导模糊测试，提高发现目标状态的效率和适用性，适用于多种程序和状态类型。", "conclusion": "自动合成谓词是定向模糊测试的有效改进，增强了工具的通用性和性能，对软件安全和调试有重要意义。"}}
{"id": "2508.21368", "title": "EconAgentic in DePIN Markets: A Large Language Model Approach to the Sharing Economy of Decentralized Physical Infrastructure", "authors": ["Yulin Liu", "Mocca Schweitzer"], "abstract": "The Decentralized Physical Infrastructure (DePIN) market is revolutionizing the sharing economy through token-based economics and smart contracts that govern decentralized operations. By 2024, DePIN projects have exceeded \\$10 billion in market capitalization, underscoring their rapid growth. However, the unregulated nature of these markets, coupled with the autonomous deployment of AI agents in smart contracts, introduces risks such as inefficiencies and potential misalignment with human values. To address these concerns, we introduce EconAgentic, a Large Language Model (LLM)-powered framework designed to mitigate these challenges. Our research focuses on three key areas: 1) modeling the dynamic evolution of DePIN markets, 2) evaluating stakeholders' actions and their economic impacts, and 3) analyzing macroeconomic indicators to align market outcomes with societal goals. Through EconAgentic, we simulate how AI agents respond to token incentives, invest in infrastructure, and adapt to market conditions, comparing AI-driven decisions with human heuristic benchmarks. Our results show that EconAgentic provides valuable insights into the efficiency, inclusion, and stability of DePIN markets, contributing to both academic understanding and practical improvements in the design and governance of decentralized, tokenized economies.", "subjects": "General Economics (econ.GN); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.21368.pdf", "abstract_url": "https://arxiv.org/abs/2508.21368", "categories": ["General Economics (econ.GN)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍EconAgentic，一个基于大型语言模型的框架，用于解决DePIN市场中AI代理带来的效率低下和价值错位问题，通过模拟和分析提升共享经济的效率、包容性和稳定性。", "motivation": "DePIN市场虽增长迅速但存在监管缺失和AI代理自主部署的风险，可能导致效率低下和与人类价值不匹配的问题。", "method": "使用大型语言模型框架EconAgentic，模拟AI代理对代币激励的响应、基础设施投资和市场适应，并与人类启发式基准进行比较。", "result": "EconAgentic提供了对DePIN市场效率、包容性和稳定性的宝贵见解，有助于学术理解和实际改进。", "conclusion": "该框架有助于设计和治理去中心化代币化经济，对齐市场结果与社会目标。"}}
{"id": "2508.21433", "title": "The Complexity Trap: Simple Observation Masking Is as Efficient as LLM Summarization for Agent Context Management", "authors": ["Tobias Lindenbauer", "Igor Slinko", "Ludwig Felder", "Egor Bogomolov", "Yaroslav Zharov"], "abstract": "Large Language Model (LLM)-based agents solve complex tasks through iterative reasoning, exploration, and tool-use, a process that can result in long, expensive context histories. While state-of-the-art Software Engineering ( SE) agents like OpenHands or Cursor use LLM-based summarization to tackle this issue, it is unclear whether the increased complexity offers tangible performance benefits compared to simply omitting older observations. We present a systematic comparison of these strategies within SWE-agent on SWE-bench Verified across five diverse model configurations. We find that a simple observation-masking strategy halves cost relative to a raw agent while matching, and sometimes slightly exceeding, the solve rate of LLM summarization. For example, with Qwen3-Coder 480B, masking improves solve rate from 53.8% (raw agent) to 54.8%, while remaining competitive with summarization at a lower cost. These results suggest that, at least within SWE-agent on SWE-bench Verified, the most effective and efficient context management can be the simplest. We release code and data for reproducibility", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.21433.pdf", "abstract_url": "https://arxiv.org/abs/2508.21433", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "在软件工程代理中，简单的观察屏蔽策略与LLM摘要相比，在成本和性能上表现相当或更好，表明简单方法更高效。", "motivation": "解决LLM代理在处理复杂任务时上下文历史过长且昂贵的问题，评估现有摘要方法的实际效益。", "method": "在SWE-agent和SWE-bench Verified上系统比较观察屏蔽和LLM摘要策略，使用五种模型配置。", "result": "观察屏蔽将成本减半，解决率与摘要相当或略高，例如Qwen3-Coder 480B从53.8%提升到54.8%。", "conclusion": "在给定上下文中，最简单的上下文管理策略最有效且高效，代码和数据已发布以确保可复现性。"}}
