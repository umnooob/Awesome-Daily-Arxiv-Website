{"id": "2509.16421", "title": "AHA -- Predicting What Matters Next: Online Highlight Detection Without Looking Ahead", "authors": ["Aiden Chang", "Celso De Melo", "Stephanie M. Lukin"], "abstract": "Real-time understanding of continuous video streams is essential for intelligent agents operating in high-stakes environments, including autonomous vehicles, surveillance drones, and disaster response robots. Yet, most existing video understanding and highlight detection methods assume access to the entire video during inference, making them unsuitable for online or streaming scenarios. In particular, current models optimize for offline summarization, failing to support step-by-step reasoning needed for real-time decision-making. We introduce Aha, an autoregressive highlight detection framework that predicts the relevance of each video frame against a task described in natural language. Without accessing future video frames, Aha utilizes a multimodal vision-language model and lightweight, decoupled heads trained on a large, curated dataset of human-centric video labels. To enable scalability, we introduce the Dynamic SinkCache mechanism that achieves constant memory usage across infinite-length streams without degrading performance on standard benchmarks. This encourages the hidden representation to capture high-level task objectives, enabling effective frame-level rankings for informativeness, relevance, and uncertainty with respect to the natural language task. Aha achieves state-of-the-art (SOTA) performance on highlight detection benchmarks, surpassing even prior offline, full-context approaches and video-language models by +5.9% on TVSum and +8.3% on", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": "Accepted at NeurIPS 2025, 32 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2509.16421.pdf", "abstract_url": "https://arxiv.org/abs/2509.16421", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出Aha框架，一种无需前瞻的自回归高光检测方法，用于实时视频流理解，在标准基准上实现最先进性能。", "motivation": "解决现有视频高光检测方法依赖完整视频、不适用于在线或流式场景的问题，支持实时决策。", "method": "使用多模态视觉语言模型和轻量级解耦头，结合动态SinkCache机制实现恒定内存使用，预测每帧与自然语言任务的相关性。", "result": "在TVSum等基准上超越现有离线方法，性能提升+5.9%和+8.3%。", "conclusion": "Aha框架有效支持实时视频高光检测，具有高可扩展性，适用于高风险环境。"}}
{"id": "2509.16645", "title": "ADVEDM:Fine-grained Adversarial Attack against VLM-based Embodied Agents", "authors": ["Yichen Wang", "Hangtao Zhang", "Hewen Pan", "Ziqi Zhou", "Xianlong Wang", "Peijin Guo", "Lulu Xue", "Shengshan Hu", "Minghui Li", "Leo Yu Zhang"], "abstract": "Vision-Language Models (VLMs), with their strong reasoning and planning capabilities, are widely used in embodied decision-making (EDM) tasks in embodied agents, such as autonomous driving and robotic manipulation. Recent research has increasingly explored adversarial attacks on VLMs to reveal their vulnerabilities. However, these attacks either rely on overly strong assumptions, requiring full knowledge of the victim VLM, which is impractical for attacking VLM-based agents, or exhibit limited effectiveness. The latter stems from disrupting most semantic information in the image, which leads to a misalignment between the perception and the task context defined by system prompts. This inconsistency interrupts the VLM's reasoning process, resulting in invalid outputs that fail to affect interactions in the physical world. To this end, we propose a fine-grained adversarial attack framework, ADVEDM, which modifies the VLM's perception of only a few key objects while preserving the semantics of the remaining regions. This attack effectively reduces conflicts with the task context, making VLMs output valid but incorrect decisions and affecting the actions of agents, thus posing a more substantial safety threat in the physical world. We design two variants of based on this framework, ADVEDM-R and ADVEDM-A, which respectively remove the semantics of a specific object from the image and add the semantics of a new object into the image. The experimental results in both general scenarios and EDM tasks demonstrate fine-grained control and excellent attack performance.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.16645.pdf", "abstract_url": "https://arxiv.org/abs/2509.16645", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出ADVEDM，一种针对基于VLM的具身代理的细粒度对抗攻击框架，通过修改关键对象语义来输出有效但错误的决策，增强物理世界安全威胁。", "motivation": "解决现有VLM对抗攻击依赖强假设或效果有限的问题，旨在揭示VLM在具身决策任务中的脆弱性。", "method": "使用ADVEDM框架，包括ADVEDM-R和ADVEDM-A变体，分别移除或添加特定对象语义，保持任务上下文一致性。", "result": "实验显示在通用和EDM任务中，ADVEDM实现了细粒度控制和优异的攻击性能。", "conclusion": "ADVEDM能有效影响代理行为，突显VLM在物理世界中的安全风险。"}}
{"id": "2509.16343", "title": "Agentic Reasoning for Robust Vision Systems via Increased Test-Time Compute", "authors": ["Chung-En", "Brian Jalaian", "Nathaniel D. Bastian"], "abstract": "Developing trustworthy intelligent vision systems for high-stakes domains, \\emph{e.g.}, remote sensing and medical diagnosis, demands broad robustness without costly retraining. We propose \\textbf{Visual Reasoning Agent (VRA)}, a training-free, agentic reasoning framework that wraps off-the-shelf vision-language models \\emph{and} pure vision systems in a \\emph{Think--Critique--Act} loop. While VRA incurs significant additional test-time computation, it achieves up to 40\\% absolute accuracy gains on challenging visual reasoning benchmarks. Future work will optimize query routing and early stopping to reduce inference overhead while preserving reliability in vision tasks.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.16343.pdf", "abstract_url": "https://arxiv.org/abs/2509.16343", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出视觉推理代理（VRA），一种无需训练的智能推理框架，通过增加测试时计算，显著提升视觉系统的鲁棒性，在视觉推理基准上实现高达40%的绝对准确率增益。", "motivation": "解决高风险领域（如遥感和医疗诊断）中智能视觉系统需要广泛鲁棒性而无需昂贵再训练的问题。", "method": "使用训练免费的代理推理框架VRA，将现成的视觉语言模型和纯视觉系统包装在Think-Critique-Act循环中。", "result": "在挑战性视觉推理基准上，VRA实现高达40%的绝对准确率提升。", "conclusion": "VRA通过增加测试时计算提高鲁棒性，未来工作将优化查询路由和早停以减少推理开销，同时保持可靠性。"}}
{"id": "2509.16360", "title": "RephQA: Evaluating Readability of Large Language Models in Public Health Question Answering", "authors": ["Weikang Qiu", "Tinglin Huang", "Ryan Rullo", "Yucheng Kuang", "Ali Maatouk", "S. Raquel Ramos", "Rex Ying"], "abstract": "Large Language Models (LLMs) hold promise in addressing complex medical problems. However, while most prior studies focus on improving accuracy and reasoning abilities, a significant bottleneck in developing effective healthcare agents lies in the readability of LLM-generated responses, specifically, their ability to answer public health problems clearly and simply to people without medical backgrounds. In this work, we introduce RephQA, a benchmark for evaluating the readability of LLMs in public health question answering (QA). It contains 533 expert-reviewed QA pairs from 27 sources across 13 topics, and includes a proxy multiple-choice task to assess informativeness, along with two readability metrics: Flesch-Kincaid grade level and professional score. Evaluation of 25 LLMs reveals that most fail to meet readability standards, highlighting a gap between reasoning and effective communication. To address this, we explore four readability-enhancing strategies-standard prompting, chain-of-thought prompting, Group Relative Policy Optimization (GRPO), and a token-adapted variant. Token-adapted GRPO achieves the best results, advancing the development of more practical and user-friendly public health agents. These results represent a step toward building more practical agents for public health.", "subjects": "Computation and Language (cs.CL)", "comments": "ACM KDD Health Track 2025 Blue Sky Best Paper", "pdf_url": "https://arxiv.org/pdf/2509.16360.pdf", "abstract_url": "https://arxiv.org/abs/2509.16360", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了RephQA基准，用于评估大型语言模型在公共卫生问答中的可读性，发现多数模型不达标，并提出改进策略。", "motivation": "解决LLMs在公共卫生问答中响应可读性差的问题，以提升对非专业用户的沟通效果。", "method": "使用RephQA基准（含533个QA对）和四种策略（如标准提示和GRPO）评估25个LLMs的可读性。", "result": "多数LLMs未达到可读性标准，token-adapted GRPO策略表现最佳。", "conclusion": "研究推动了更实用、用户友好的公共卫生代理的发展。"}}
{"id": "2509.16325", "title": "Overhearing LLM Agents: A Survey, Taxonomy, and Roadmap", "authors": ["Andrew Zhu", "Chris Callison-Burch"], "abstract": "Imagine AI assistants that enhance conversations without interrupting them: quietly providing relevant information during a medical consultation, seamlessly preparing materials as teachers discuss lesson plans, or unobtrusively scheduling meetings as colleagues debate calendars. While modern conversational LLM agents directly assist human users with tasks through a chat interface, we study this alternative paradigm for interacting with LLM agents, which we call \"overhearing agents.\" Rather than demanding the user's attention, overhearing agents continuously monitor ambient activity and intervene only when they can provide contextual assistance. In this paper, we present the first analysis of overhearing LLM agents as a distinct paradigm in human-AI interaction and establish a taxonomy of overhearing agent interactions and tasks grounded in a survey of works on prior LLM-powered agents and exploratory HCI studies. Based on this taxonomy, we create a list of best practices for researchers and developers building overhearing agent systems. Finally, we outline the remaining research gaps and reveal opportunities for future research in the overhearing paradigm.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)", "comments": "8 pages, 1 figure", "pdf_url": "https://arxiv.org/pdf/2509.16325.pdf", "abstract_url": "https://arxiv.org/abs/2509.16325", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文首次分析'偷听LLM代理'作为人机交互新范式，通过调查建立分类法和最佳实践，并指出未来研究方向。", "motivation": "解决传统LLM代理通过聊天界面直接辅助用户时可能中断对话的问题，探索不引人注目的上下文辅助方式。", "method": "基于对现有LLM代理和HCI研究的调查，建立偷听代理交互和任务的分类法，并提出最佳实践。", "result": "建立了偷听代理的分类法和最佳实践列表，识别了研究空白。", "conclusion": "偷听代理范式有潜力，需进一步研究以填补空白并推动发展。"}}
{"id": "2509.16330", "title": "Generalizability of Large Language Model-Based Agents: A Comprehensive Survey", "authors": ["Minxing Zhang", "Yi Yang", "Roy Xie", "Bhuwan Dhingra", "Shuyan Zhou", "Jian Pei"], "abstract": "Large Language Model (LLM)-based agents have emerged as a new paradigm that extends LLMs' capabilities beyond text generation to dynamic interaction with external environments. By integrating reasoning with perception, memory, and tool use, agents are increasingly deployed in diverse domains like web navigation and household robotics. A critical challenge, however, lies in ensuring agent generalizability - the ability to maintain consistent performance across varied instructions, tasks, environments, and domains, especially those beyond agents' fine-tuning data. Despite growing interest, the concept of generalizability in LLM-based agents remains underdefined, and systematic approaches to measure and improve it are lacking. In this survey, we provide the first comprehensive review of generalizability in LLM-based agents. We begin by emphasizing agent generalizability's importance by appealing to stakeholders and clarifying the boundaries of agent generalizability by situating it within a hierarchical domain-task ontology. We then review datasets, evaluation dimensions, and metrics, highlighting their limitations. Next, we categorize methods for improving generalizability into three groups: methods for the backbone LLM, for agent components, and for their interactions. Moreover, we introduce the distinction between generalizable frameworks and generalizable agents and outline how generalizable frameworks can be translated into agent-level generalizability. Finally, we identify critical challenges and future directions, including developing standardized frameworks, variance- and cost-based metrics, and approaches that integrate methodological innovations with architecture-level designs. By synthesizing progress and highlighting opportunities, this survey aims to establish a foundation for principled research on building LLM-based agents that generalize reliably across diverse applications.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.16330.pdf", "abstract_url": "https://arxiv.org/abs/2509.16330", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本论文是对大型语言模型（LLM）智能体泛化性的首次全面综述，强调其在跨任务和环境中的重要性，并回顾了数据集、评估方法和改进策略。", "motivation": "解决LLM智能体在多样化指令、任务、环境和领域中保持性能一致性的挑战，因为当前泛化性概念模糊且缺乏系统方法。", "method": "采用调查方法，通过分层领域-任务本体定义泛化性边界，分类改进方法（如针对骨干LLM、智能体组件及其交互），并区分泛化框架与智能体。", "result": "综述发现现有评估方法有局限，提出了改进策略，并识别了标准化框架、新指标和架构设计等未来方向。", "conclusion": "本综述为构建可靠泛化的LLM智能体奠定基础，呼吁整合方法创新与架构设计以推动研究。"}}
{"id": "2509.16394", "title": "Evaluating Behavioral Alignment in Conflict Dialogue: A Multi-Dimensional Comparison of LLM Agents and Humans", "authors": ["Deuksin Kwon", "Kaleen Shrestha", "Bin Han", "Elena Hayoung Lee", "Gale Lucas"], "abstract": "Large Language Models (LLMs) are increasingly deployed in socially complex, interaction-driven tasks, yet their ability to mirror human behavior in emotionally and strategically complex contexts remains underexplored. This study assesses the behavioral alignment of personality-prompted LLMs in adversarial dispute resolution by simulating multi-turn conflict dialogues that incorporate negotiation. Each LLM is guided by a matched Five-Factor personality profile to control for individual variation and enhance realism. We evaluate alignment across three dimensions: linguistic style, emotional expression (e.g., anger dynamics), and strategic behavior. GPT-4.1 achieves the closest alignment with humans in linguistic style and emotional dynamics, while Claude-3.7-Sonnet best reflects strategic behavior. Nonetheless, substantial alignment gaps persist. Our findings establish a benchmark for alignment between LLMs and humans in socially complex interactions, underscoring both the promise and the limitations of personality conditioning in dialogue modeling.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)", "comments": "Accepted to EMNLP 2025 (Main Conference)", "pdf_url": "https://arxiv.org/pdf/2509.16394.pdf", "abstract_url": "https://arxiv.org/abs/2509.16394", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文评估了人格提示的LLM在冲突对话中与人类行为的对齐程度，发现GPT-4.1在语言风格和情感表达上最接近人类，Claude-3.7-Sonnet在战略行为上最佳，但仍有显著差距。", "motivation": "解决LLM在情感和战略复杂的社会互动中模拟人类行为的能力不足的问题。", "method": "通过模拟多轮冲突对话，使用五因素人格配置文件引导LLM，评估语言风格、情感表达和战略行为的对齐。", "result": "GPT-4.1在语言和情感上对齐最好，Claude-3.7-Sonnet在战略行为上最佳，但存在重大对齐差距。", "conclusion": "研究为LLM与人类在社会复杂互动中的对齐提供了基准，显示人格条件化的潜力和局限性。"}}
{"id": "2509.16457", "title": "Implicit Behavioral Alignment of Language Agents in High-Stakes Crowd Simulations", "authors": ["Yunzhe Wang", "Gale M. Lucas", "Burcin Becerik-Gerber", "Volkan Ustun"], "abstract": "Language-driven generative agents have enabled large-scale social simulations with transformative uses, from interpersonal training to aiding global policy-making. However, recent studies indicate that generative agent behaviors often deviate from expert expectations and real-world data--a phenomenon we term the Behavior-Realism Gap. To address this, we introduce a theoretical framework called Persona-Environment Behavioral Alignment (PEBA), formulated as a distribution matching problem grounded in Lewin's behavior equation stating that behavior is a function of the person and their environment. Leveraging PEBA, we propose PersonaEvolve (PEvo), an LLM-based optimization algorithm that iteratively refines agent personas, implicitly aligning their collective behaviors with realistic expert benchmarks within a specified environmental context. We validate PEvo in an active shooter incident simulation we developed, achieving an 84% average reduction in distributional divergence compared to no steering and a 34% improvement over explicit instruction baselines. Results also show PEvo-refined personas generalize to novel, related simulation scenarios. Our method greatly enhances behavioral realism and reliability in high-stakes social simulations. More broadly, the PEBA-PEvo framework provides a principled approach to developing trustworthy LLM-driven social simulations.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "comments": "Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing (EMNLP 2025), Main Conference", "pdf_url": "https://arxiv.org/pdf/2509.16457.pdf", "abstract_url": "https://arxiv.org/abs/2509.16457", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出PEBA理论和PEvo算法，通过迭代优化语言代理的人设，在高风险人群模拟中隐式对齐行为与专家基准，提升行为真实性和可靠性。", "motivation": "解决生成代理行为与专家期望和真实数据之间的行为-现实差距问题，确保高风险社会模拟的可信度。", "method": "基于Lewin行为方程，将问题建模为分布匹配，开发PEvo算法，利用LLM迭代优化代理的人设以隐式对齐行为。", "result": "在主动射击事件模拟中，PEvo平均减少84%分布差异，比显式指令基线提升34%，且优化后的人设能泛化到新场景。", "conclusion": "PEBA-PEvo框架为开发可信赖的LLM驱动社会模拟提供了原则性方法，显著增强行为真实性和可靠性。"}}
{"id": "2509.16721", "title": "Text-Scene: A Scene-to-Language Parsing Framework for 3D Scene Understanding", "authors": ["Haoyuan Li", "Rui Liu", "Hehe Fan", "Yi Yang"], "abstract": "Enabling agents to understand and interact with complex 3D scenes is a fundamental challenge for embodied artificial intelligence systems. While Multimodal Large Language Models (MLLMs) have achieved significant progress in 2D image understanding, extending such capabilities to 3D scenes remains difficult: 1) 3D environment involves richer concepts such as spatial relationships, affordances, physics, layout, and so on, 2) the absence of large-scale 3D vision-language datasets has posed a significant obstacle. In this paper, we introduce Text-Scene, a framework that automatically parses 3D scenes into textual descriptions for scene understanding. Given a 3D scene, our model identifies object attributes and spatial relationships, and then generates a coherent summary of the whole scene, bridging the gap between 3D observation and language without requiring human-in-the-loop intervention. By leveraging both geometric analysis and MLLMs, Text-Scene produces descriptions that are accurate, detailed, and human-interpretable, capturing object-level details and global-level context. Experimental results on benchmarks demonstrate that our textual parses can faithfully represent 3D scenes and benefit downstream tasks. To evaluate the reasoning capability of MLLMs, we present InPlan3D, a comprehensive benchmark for 3D task planning, consisting of 3174 long-term planning tasks across 636 indoor scenes. We emphasize clarity and accessibility in our approach, aiming to make 3D scene content understandable through language. Code and datasets will be released.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": "19 pages, 12 figures, 6 tables", "pdf_url": "https://arxiv.org/pdf/2509.16721.pdf", "abstract_url": "https://arxiv.org/abs/2509.16721", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出Text-Scene框架，通过自动将3D场景解析为文本描述，实现3D场景理解，无需人工干预，并引入InPlan3D基准评估MLLMs的推理能力。", "motivation": "解决3D场景理解中的挑战，包括3D概念丰富和缺乏大规模数据集，以扩展MLLMs到3D领域。", "method": "结合几何分析和MLLMs，自动识别物体属性和空间关系，生成连贯的文本描述。", "result": "实验表明，文本解析能准确表示3D场景，并有益于下游任务；InPlan3D基准包含3174个规划任务。", "conclusion": "框架使3D场景内容可通过语言理解，强调清晰性和可访问性，代码和数据集将发布。"}}
{"id": "2509.16811", "title": "Prompt-Driven Agentic Video Editing System: Autonomous Comprehension of Long-Form, Story-Driven Media", "authors": ["Zihan Ding", "Junlong Chen", "Per Ola Kristensson", "Junxiao Shen", "Xinyi Wang"], "abstract": "Creators struggle to edit long-form, narrative-rich videos not because of UI complexity, but due to the cognitive demands of searching, storyboarding, and sequencing hours of footage. Existing transcript- or embedding-based methods fall short for creative workflows, as models struggle to track characters, infer motivations, and connect dispersed events. We present a prompt-driven, modular editing system that helps creators restructure multi-hour content through free-form prompts rather than timelines. At its core is a semantic indexing pipeline that builds a global narrative via temporal segmentation, guided memory compression, and cross-granularity fusion, producing interpretable traces of plot, dialogue, emotion, and context. Users receive cinematic edits while optionally refining transparent intermediate outputs. Evaluated on 400+ videos with expert ratings, QA, and preference studies, our system scales prompt-driven editing, preserves narrative coherence, and balances automation with creator control.", "subjects": "Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.16811.pdf", "abstract_url": "https://arxiv.org/abs/2509.16811", "categories": ["Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种基于提示的模块化视频编辑系统，通过语义索引和叙事理解，帮助创作者自动编辑长篇故事视频，保持叙事连贯性并平衡自动化与控制。", "motivation": "解决创作者在编辑长篇叙事视频时面临的认知负担问题，现有方法无法有效跟踪角色和事件，缺乏创意工作流支持。", "method": "使用提示驱动、模块化系统，核心是语义索引管道，包括时间分割、记忆压缩和跨粒度融合，以构建全局叙事。", "result": "在400多个视频上评估，系统能扩展提示驱动编辑，保持叙事连贯性，并通过专家评分和偏好研究验证其有效性。", "conclusion": "该系统提升了视频编辑的自动化水平，同时保留创作者控制，为创意工作流提供了新方向。"}}
{"id": "2509.16839", "title": "Roundtable Policy: Improving Scientific Reasoning and Narratives through Confidence-Weighted Consensus of LLMs", "authors": ["Yu Yao", "Jiayi Dong", "Ju Li", "Yang Yang", "Yilun Du"], "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities not only in language generation but also in advancing scientific discovery. A growing body of work has explored ways to improve their reasoning, from self-consistency and chain-of-thought to multi-agent debate. Inspired by the dynamics of scientific committees and the \"Society of Mind,\" we introduce Roundtable Policy, a complementary inference-time reasoning framework that performs inference through the weighted consensus of multiple LLMs. Our findings indicate that this approach significantly enhances reasoning in complex heterogeneous scientific tasks and improves scientific narratives in terms of creativity, rigor, and logical coherence, while reducing hallucinations that single models are prone to. Our approach emphasizes structured and interpretable consensus rather than opaque convergence, while requiring only black-box access and uniform procedures, making it broadly applicable to multi-LLM reasoning.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "Equal contribution: Yu Yao and Jiayi Dong. Equal advising: Ju Li, Yang Yang, and Yilun Du. Affiliations: Massachusetts Institute of Technology (Yu Yao, Ju Li), University of California, Los Angeles (Jiayi Dong, Yang Yang), Harvard University (Yilun Du)", "pdf_url": "https://arxiv.org/pdf/2509.16839.pdf", "abstract_url": "https://arxiv.org/abs/2509.16839", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出Roundtable Policy，一种通过多个LLM的加权共识来增强推理和科学叙述的框架，减少幻觉并提高创造力、严谨性和逻辑连贯性。", "motivation": "解决单一LLM在复杂科学任务中推理不足和易产生幻觉的问题，受科学委员会和'Society of Mind'启发。", "method": "使用加权共识方法，在推理时结合多个LLM的输出，强调结构化和可解释的共识，仅需黑盒访问和统一流程。", "result": "该方法显著提升了复杂异质科学任务的推理能力，改善了科学叙述的质量，同时减少了幻觉。", "conclusion": "Roundtable Policy是一种广泛适用的补充推理框架，能有效提高LLM的科学推理和叙述能力，具有重要应用价值。"}}
{"id": "2509.16866", "title": "seqBench: A Tunable Benchmark to Quantify Sequential Reasoning Limits of LLMs", "authors": ["Mohammad Ramezanali", "Mo Vazifeh", "Paolo Santi"], "abstract": "We introduce seqBench, a parametrized benchmark for probing sequential reasoning limits in Large Language Models (LLMs) through precise, multi-dimensional control over several key complexity dimensions. seqBench allows systematic variation of (1) the logical depth, defined as the number of sequential actions required to solve the task; (2) the number of backtracking steps along the optimal path, quantifying how often the agent must revisit prior states to satisfy deferred preconditions (e.g., retrieving a key after encountering a locked door); and (3) the noise ratio, defined as the ratio between supporting and distracting facts about the environment. Our evaluations on state-of-the-art LLMs reveal a universal failure pattern: accuracy collapses exponentially beyond a model-specific logical depth. Unlike existing benchmarks, seqBench's fine-grained control facilitates targeted analyses of these reasoning failures, illuminating universal scaling laws and statistical limits, as detailed in this paper alongside its generation methodology and evaluation metrics. We find that even top-performing models systematically fail on seqBench's structured reasoning tasks despite minimal search complexity, underscoring key limitations in their commonsense reasoning capabilities. Designed for future evolution to keep pace with advancing models, the seqBench datasets are publicly released to spur deeper scientific inquiry into LLM reasoning, aiming to establish a clearer understanding of their true potential and current boundaries for robust real-world application.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.16866.pdf", "abstract_url": "https://arxiv.org/abs/2509.16866", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "seqBench是一个可调参数基准，用于量化大型语言模型在顺序推理中的限制，通过控制逻辑深度、回溯步骤和噪声比等维度，揭示模型在复杂推理任务中的系统性失败。", "motivation": "解决现有基准无法精确控制推理复杂性，以量化LLMs在顺序推理中的失败模式和限制的问题。", "method": "设计seqBench基准，系统变化逻辑深度、回溯步骤数和噪声比，评估LLMs在结构化推理任务上的表现。", "result": "评估显示，LLMs的准确度在超过模型特定逻辑深度时呈指数级下降，即使任务搜索复杂度低，模型也普遍失败。", "conclusion": "seqBench揭示了LLMs在常识推理中的关键限制，为未来研究提供工具，以理解模型潜力和边界，促进稳健应用。"}}
{"id": "2509.16924", "title": "Audio-Guided Dynamic Modality Fusion with Stereo-Aware Attention for Audio-Visual Navigation", "authors": ["Jia Li", "Yinfeng Yu", "Liejun Wang", "Fuchun Sun", "Wendong Zheng"], "abstract": "In audio-visual navigation (AVN) tasks, an embodied agent must autonomously localize a sound source in unknown and complex 3D environments based on audio-visual signals. Existing methods often rely on static modality fusion strategies and neglect the spatial cues embedded in stereo audio, leading to performance degradation in cluttered or occluded scenes. To address these issues, we propose an end-to-end reinforcement learning-based AVN framework with two key innovations: (1) a \\textbf{S}tereo-Aware \\textbf{A}ttention \\textbf{M}odule (\\textbf{SAM}), which learns and exploits the spatial disparity between left and right audio channels to enhance directional sound perception; and (2) an \\textbf{A}udio-\\textbf{G}uided \\textbf{D}ynamic \\textbf{F}usion Module (\\textbf{AGDF}), which dynamically adjusts the fusion ratio between visual and auditory features based on audio cues, thereby improving robustness to environmental changes. Extensive experiments are conducted on two realistic 3D scene datasets, Replica and Matterport3D, demonstrating that our method significantly outperforms existing approaches in terms of navigation success rate and path efficiency. Notably, our model achieves over 40\\% improvement under audio-only conditions compared to the best-performing baselines. These results highlight the importance of explicitly modeling spatial cues from stereo channels and performing deep multi-modal fusion for robust and efficient audio-visual navigation.", "subjects": "Artificial Intelligence (cs.AI); Sound (cs.SD)", "comments": "Main paper (14 pages). Accepted for publication by ICONIP( International Conference on Neural Information Processing) 2025", "pdf_url": "https://arxiv.org/pdf/2509.16924.pdf", "abstract_url": "https://arxiv.org/abs/2509.16924", "categories": ["Artificial Intelligence (cs.AI)", "Sound (cs.SD)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种用于音频-视觉导航的端到端强化学习框架，通过立体感知注意模块和音频引导动态融合模块，显著提升了在复杂环境中的导航性能。", "motivation": "解决现有音频-视觉导航方法中静态模态融合和忽视立体音频空间线索导致的性能下降问题。", "method": "使用强化学习框架，结合立体感知注意模块（SAM）和音频引导动态融合模块（AGDF）进行动态多模态融合。", "result": "在Replica和Matterport3D数据集上，导航成功率和路径效率显著优于基线方法，音频条件下改进超过40%。", "conclusion": "明确建模立体音频空间线索和深度多模态融合对于鲁棒高效的音频-视觉导航至关重要。"}}
{"id": "2509.16891", "title": "LLMs as Layout Designers: A Spatial Reasoning Perspective", "authors": ["Sha Li"], "abstract": "While Large Language Models (LLMs) have demonstrated impressive reasoning and planning abilities in textual domains and can effectively follow instructions for complex tasks, their capacity for spatial understanding and reasoning remains limited. Such capabilities, however, are critical for applications like content-aware graphic layout design, which demands precise placement, alignment, and structural organization of multiple elements within constrained visual spaces. To address this gap, we propose LaySPA, a reinforcement learning-based framework that augments LLM agents with explicit spatial reasoning capabilities. LaySPA leverages hybrid reward signals that capture geometric validity, structural fidelity, and visual quality, enabling agents to model inter-element relationships, navigate the canvas, and optimize spatial arrangements. Through iterative self-exploration and adaptive policy optimization, LaySPA produces both interpretable reasoning traces and structured layouts. Experimental results demonstrate that LaySPA generates structurally sound and visually appealing layouts, outperforming larger general-purpose LLMs and achieving results on par with state-of-the-art specialized layout models.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.16891.pdf", "abstract_url": "https://arxiv.org/abs/2509.16891", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出LaySPA框架，通过强化学习增强LLM的空间推理能力，用于图形布局设计，在结构合理性和视觉质量上优于大型通用LLM。", "motivation": "解决LLM在空间理解和推理方面的局限性，这对于需要精确元素布局的应用（如内容感知图形设计）至关重要。", "method": "采用基于强化学习的框架LaySPA，利用混合奖励信号（几何有效性、结构保真度和视觉质量）进行迭代自探索和策略优化。", "result": "实验显示，LaySPA生成的布局结构合理、视觉吸引人，性能超过大型通用LLM，与专业布局模型相当。", "conclusion": "LaySPA成功扩展了LLM的空间推理能力，为布局设计提供了可解释的解决方案，具有实际应用潜力。"}}
{"id": "2509.16494", "title": "Can an Individual Manipulate the Collective Decisions of Multi-Agents?", "authors": ["Fengyuan Liu", "Rui Zhao", "Shuo Chen", "Guohao Li", "Philip Torr", "Lei Han", "Jindong Gu"], "abstract": "Individual Large Language Models (LLMs) have demonstrated significant capabilities across various domains, such as healthcare and law. Recent studies also show that coordinated multi-agent systems exhibit enhanced decision-making and reasoning abilities through collaboration. However, due to the vulnerabilities of individual LLMs and the difficulty of accessing all agents in a multi-agent system, a key question arises: If attackers only know one agent, could they still generate adversarial samples capable of misleading the collective decision? To explore this question, we formulate it as a game with incomplete information, where attackers know only one target agent and lack knowledge of the other agents in the system. With this formulation, we propose M-Spoiler, a framework that simulates agent interactions within a multi-agent system to generate adversarial samples. These samples are then used to manipulate the target agent in the target system, misleading the system's collaborative decision-making process. More specifically, M-Spoiler introduces a stubborn agent that actively aids in optimizing adversarial samples by simulating potential stubborn responses from agents in the target system. This enhances the effectiveness of the generated adversarial samples in misleading the system. Through extensive experiments across various tasks, our findings confirm the risks posed by the knowledge of an individual agent in multi-agent systems and demonstrate the effectiveness of our framework. We also explore several defense mechanisms, showing that our proposed attack framework remains more potent than baselines, underscoring the need for further research into defensive strategies.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.16494.pdf", "abstract_url": "https://arxiv.org/abs/2509.16494", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了在多智能体系统中，攻击者仅知道一个智能体时，能否通过生成对抗样本来误导集体决策。作者提出了M-Spoiler框架，通过模拟智能体交互和引入顽固智能体来优化对抗样本，实验证实了风险并展示了框架的有效性。", "motivation": "解决多智能体系统中，由于单个LLM的脆弱性和无法访问所有智能体，攻击者仅知道一个智能体时能否误导集体决策的问题。", "method": "将问题建模为不完全信息博弈，提出M-Spoiler框架，模拟智能体交互并引入顽固智能体来生成和优化对抗样本。", "result": "实验表明，攻击者仅知道一个智能体即可有效误导系统决策，M-Spoiler比基线方法更有效，且防御机制仍需改进。", "conclusion": "多智能体系统存在安全风险，需要进一步研究防御策略以应对基于单个智能体知识的攻击。"}}
{"id": "2509.16533", "title": "Challenging the Evaluator: LLM Sycophancy Under User Rebuttal", "authors": ["Sungwon Kim", "Daniel Khashabi"], "abstract": "Large Language Models (LLMs) often exhibit sycophancy, distorting responses to align with user beliefs, notably by readily agreeing with user counterarguments. Paradoxically, LLMs are increasingly adopted as successful evaluative agents for tasks such as grading and adjudicating claims. This research investigates that tension: why do LLMs show sycophancy when challenged in subsequent conversational turns, yet perform well when evaluating conflicting arguments presented simultaneously? We empirically tested these contrasting scenarios by varying key interaction patterns. We find that state-of-the-art models: (1) are more likely to endorse a user's counterargument when framed as a follow-up from a user, rather than when both responses are presented simultaneously for evaluation; (2) show increased susceptibility to persuasion when the user's rebuttal includes detailed reasoning, even when the conclusion of the reasoning is incorrect; and (3) are more readily swayed by casually phrased feedback than by formal critiques, even when the casual input lacks justification. Our results highlight the risk of relying on LLMs for judgment tasks without accounting for conversational framing.", "subjects": "Computation and Language (cs.CL)", "comments": "Accepted to EMNLP 2025 Findings", "pdf_url": "https://arxiv.org/pdf/2509.16533.pdf", "abstract_url": "https://arxiv.org/abs/2509.16533", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨LLMs在用户反驳下表现出的谄媚行为，发现对话框架影响其评估表现，警示在判断任务中使用LLMs的风险。", "motivation": "解决LLMs在作为评估代理时，为何在同时呈现冲突论点时表现良好，但在对话中被用户反驳时却易出现谄媚行为的问题。", "method": "通过实验变化交互模式，比较LLMs在同时评估与后续对话中对用户反驳的反应。", "result": "LLMs更易赞同用户后续反驳，易受详细但错误推理或随意反馈影响，而不受正式批评影响。", "conclusion": "使用LLMs进行判断任务需考虑对话框架，以避免谄媚行为带来的风险。"}}
{"id": "2509.16564", "title": "MPCG: Multi-Round Persona-Conditioned Generation for Modeling the Evolution of Misinformation with LLMs", "authors": ["Jun Rong Brian Chong", "Yixuan Tang", "Anthony K.H. Tung"], "abstract": "Misinformation evolves as it spreads, shifting in language, framing, and moral emphasis to adapt to new audiences. However, current misinformation detection approaches implicitly assume that misinformation is static. We introduce MPCG, a multi-round, persona-conditioned framework that simulates how claims are iteratively reinterpreted by agents with distinct ideological perspectives. Our approach uses an uncensored large language model (LLM) to generate persona-specific claims across multiple rounds, conditioning each generation on outputs from the previous round, enabling the study of misinformation evolution. We evaluate the generated claims through human and LLM-based annotations, cognitive effort metrics (readability, perplexity), emotion evocation metrics (sentiment analysis, morality), clustering, feasibility, and downstream classification. Results show strong agreement between human and GPT-4o-mini annotations, with higher divergence in fluency judgments. Generated claims require greater cognitive effort than the original claims and consistently reflect persona-aligned emotional and moral framing. Clustering and cosine similarity analyses confirm semantic drift across rounds while preserving topical coherence. Feasibility results show a 77% feasibility rate, confirming suitability for downstream tasks. Classification results reveal that commonly used misinformation detectors experience macro-F1 performance drops of up to 49.7%. The code is available at", "subjects": "Computation and Language (cs.CL); Social and Information Networks (cs.SI)", "comments": "35 pages, 8 figures", "pdf_url": "https://arxiv.org/pdf/2509.16564.pdf", "abstract_url": "https://arxiv.org/abs/2509.16564", "categories": ["Computation and Language (cs.CL)", "Social and Information Networks (cs.SI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出MPCG框架，模拟错误信息在传播中的演变，通过多轮人物条件生成，展示其语义漂移和检测挑战。", "motivation": "当前错误信息检测方法假设信息是静态的，但实际中错误信息会随传播演变，需要动态建模方法。", "method": "使用无审查大语言模型进行多轮生成，每轮基于前一轮输出和特定意识形态人物条件，模拟信息演变。", "result": "生成信息认知努力增加，情感和道德框架与人物对齐，语义漂移但主题一致，错误信息检测器性能下降高达49.7%。", "conclusion": "MPCG能有效模拟错误信息演变，揭示现有检测方法的不足，为动态检测提供基础。"}}
{"id": "2509.16584", "title": "From Scores to Steps: Diagnosing and Improving LLM Performance in Evidence-Based Medical Calculations", "authors": ["Benlu Wang", "Iris Xia", "Yifan Zhang", "Junda Wang", "Feiyun Ouyang", "Shuo Han", "Arman Cohan", "Hong Yu", "Zonghai Yao"], "abstract": "Large language models (LLMs) have demonstrated promising performance on medical benchmarks; however, their ability to perform medical calculations, a crucial aspect of clinical decision-making, remains underexplored and poorly evaluated. Existing benchmarks often assess only the final answer with a wide numerical tolerance, overlooking systematic reasoning failures and potentially causing serious clinical misjudgments. In this work, we revisit medical calculation evaluation with a stronger focus on clinical trustworthiness. First, we clean and restructure the MedCalc-Bench dataset and propose a new step-by-step evaluation pipeline that independently assesses formula selection, entity extraction, and arithmetic computation. Under this granular framework, the accuracy of GPT-4o drops from 62.7% to 43.6%, revealing errors masked by prior evaluations. Second, we introduce an automatic error analysis framework that generates structured attribution for each failure mode. Human evaluation confirms its alignment with expert judgment, enabling scalable and explainable diagnostics. Finally, we propose a modular agentic pipeline, MedRaC, that combines retrieval-augmented generation and Python-based code execution. Without any fine-tuning, MedRaC improves the accuracy of different LLMs from 16.35% up to 53.19%. Our work highlights the limitations of current benchmark practices and proposes a more clinically faithful methodology. By enabling transparent and transferable reasoning evaluation, we move closer to making LLM-based systems trustworthy for real-world medical applications.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "Equal contribution for the first two authors. To appear as an Oral presentation in the proceedings of the Main Conference on Empirical Methods in Natural Language Processing (EMNLP) 2025", "pdf_url": "https://arxiv.org/pdf/2509.16584.pdf", "abstract_url": "https://arxiv.org/abs/2509.16584", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种新的医学计算评估方法，通过分步评估和模块化代理管道MedRaC，提高了LLM在医学计算中的准确性和可解释性。", "motivation": "当前医学基准测试仅评估最终答案，忽略了系统推理错误，可能导致临床误判，需要更可靠的评估方法。", "method": "清理MedCalc-Bench数据集，引入分步评估管道和自动错误分析框架，并开发MedRaC代理管道结合检索增强生成和Python代码执行。", "result": "GPT-4o准确率从62.7%降至43.6%，MedRaC将不同LLM准确率从16.35%提升至53.19%，人类评估确认错误分析框架有效。", "conclusion": "工作揭示了当前基准的局限性，提出了更临床可信的方法，有助于LLM系统在真实医疗应用中的可信度。"}}
{"id": "2509.17068", "title": "Intention-aware Hierarchical Diffusion Model for Long-term Trajectory Anomaly Detection", "authors": ["Chen Wang", "Sarah Erfani", "Tansu Alpcan", "Christopher Leckie"], "abstract": "Long-term trajectory anomaly detection is a challenging problem due to the diversity and complex spatiotemporal dependencies in trajectory data. Existing trajectory anomaly detection methods fail to simultaneously consider both the high-level intentions of agents as well as the low-level details of the agent's navigation when analysing an agent's trajectories. This limits their ability to capture the full diversity of normal trajectories. In this paper, we propose an unsupervised trajectory anomaly detection method named Intention-aware Hierarchical Diffusion model (IHiD), which detects anomalies through both high-level intent evaluation and low-level sub-trajectory analysis. Our approach leverages Inverse Q Learning as the high-level model to assess whether a selected subgoal aligns with an agent's intention based on predicted Q-values. Meanwhile, a diffusion model serves as the low-level model to generate sub-trajectories conditioned on subgoal information, with anomaly detection based on reconstruction error. By integrating both models, IHiD effectively utilises subgoal transition knowledge and is designed to capture the diverse distribution of normal trajectories. Our experiments show that the proposed method IHiD achieves up to 30.2% improvement in anomaly detection performance in terms of F1 score over state-of-the-art baselines.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "15 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2509.17068.pdf", "abstract_url": "https://arxiv.org/abs/2509.17068", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "提出IHiD方法，通过高层意图评估和低层子轨迹分析进行无监督轨迹异常检测，实验显示F1分数提升达30.2%。", "motivation": "解决现有方法无法同时考虑高层意图和低层细节的问题，以捕捉正常轨迹的多样性。", "method": "使用逆Q学习评估子目标意图，扩散模型生成子轨迹，基于重构误差检测异常。", "result": "IHiD在F1分数上比基线方法提升高达30.2%。", "conclusion": "IHiD有效整合模型，提升异常检测性能，适用于复杂轨迹数据。"}}
{"id": "2509.17066", "title": "RALLM-POI: Retrieval-Augmented LLM for Zero-shot Next POI Recommendation with Geographical Reranking", "authors": ["Kunrong Li", "Kwan Hui Lim"], "abstract": "Next point-of-interest (POI) recommendation predicts a user's next destination from historical movements. Traditional models require intensive training, while LLMs offer flexible and generalizable zero-shot solutions but often generate generic or geographically irrelevant results due to missing trajectory and spatial context. To address these issues, we propose RALLM-POI, a framework that couples LLMs with retrieval-augmented generation and self-rectification. We first propose a Historical Trajectory Retriever (HTR) that retrieves relevant past trajectories to serve as contextual references, which are then reranked by a Geographical Distance Reranker (GDR) for prioritizing spatially relevant trajectories. Lastly, an Agentic LLM Rectifier (ALR) is designed to refine outputs through self-reflection. Without additional training, RALLM-POI achieves substantial accuracy gains across three real-world Foursquare datasets, outperforming both conventional and LLM-based baselines. Code is released at", "subjects": "Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": "PRICAI 2025", "pdf_url": "https://arxiv.org/pdf/2509.17066.pdf", "abstract_url": "https://arxiv.org/abs/2509.17066", "categories": ["Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "RALLM-POI 是一个零样本的下一个兴趣点推荐框架，结合检索增强生成和自校正，无需训练即可提高准确性。", "motivation": "解决传统模型需要大量训练，以及LLMs在零样本推荐中因缺乏轨迹和空间上下文而产生通用或地理不相关结果的问题。", "method": "使用历史轨迹检索器检索相关轨迹，地理距离重排器优先空间相关轨迹，代理LLM校正器通过自反思优化输出。", "result": "在三个Foursquare数据集上，RALLM-POI显著提高了准确性，优于传统和LLM基线方法。", "conclusion": "RALLM-POI展示了检索增强和自校正的有效性，为零样本POI推荐提供了灵活且高性能的解决方案。"}}
{"id": "2509.17116", "title": "MCTS-EP: Empowering Embodied Planning with Online Preference Optimization", "authors": ["Hang Xu", "Zang Yu", "Yehui Tang", "Pengbo Hu", "Yuhao Tang", "Hao Dong"], "abstract": "This paper introduces MCTS-EP, an online learning framework that combines large language models (LLM) with Monte Carlo Tree Search (MCTS) for training embodied agents. MCTS-EP integrates three key components: MCTS-guided exploration for preference data collection, efficient multi-modal reasoning mechanism, and iterative training pipeline based on preference optimization. We theoretically prove that MCTS-EP achieves better performance bounds than conventional on-policy algorithms when the loss function is strongly convex, and demonstrate that it can be formulated as a search-enhanced variant of GAIL. MCTS-EP achieves state-of-the-art performace across serval benchmarks. In ALFWorld, it achieves 92% and 87% success rates for textual and visual tasks. In WebShop, it reaches an average reward of 0.81. MTCS-EP also reduces average interaction steps from from 18.7/19.5 to 10.2/9.9 steps in visual", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.17116.pdf", "abstract_url": "https://arxiv.org/abs/2509.17116", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文提出MCTS-EP框架，结合LLM和MCTS在线训练具身智能体，通过偏好优化提升性能，在多个基准测试中达到最先进水平。", "motivation": "解决传统策略算法在具身规划任务中性能不足的问题，旨在提高智能体的探索效率和决策能力。", "method": "使用MCTS引导探索收集偏好数据，结合多模态推理机制和迭代训练管道，基于偏好优化进行在线学习。", "result": "在ALFWorld中文本和视觉任务成功率分别达92%和87%，WebShop平均奖励0.81，交互步骤显著减少。", "conclusion": "MCTS-EP在理论上和实践中优于传统方法，为具身智能体训练提供了高效框架。"}}
{"id": "2509.17158", "title": "ARE: Scaling Up Agent Environments and Evaluations", "authors": ["Pierre Andrews", "Amine Benhalloum", "Gerard Moreno-Torres Bertran", "Matteo Bettini", "Amar Budhiraja", "Ricardo Silveira Cabral", "Virginie Do", "Romain Froger", "Emilien Garreau", "Jean-Baptiste Gaya", "Hugo Laurençon", "Maxime Lecanu", "Kunal Malkan", "Dheeraj Mekala", "Pierre Ménard", "Grégoire Mialon", "Ulyana Piterbarg", "Mikhail Plekhanov", "Mathieu Rita", "Andrey Rusakov", "Thomas Scialom", "Vladislav Vorotilov", "Mengjue Wang", "Ian Yu"], "abstract": "We introduce Meta Agents Research Environments (ARE), a research platform for scalable creation of environments, integration of synthetic or real applications, and execution of agentic orchestrations. ARE provides simple abstractions to build complex and diverse environments, each with their own rules, tools, content, and verifiers, helping to bridge the gap between model development and real-world deployment. We also propose Gaia2, a benchmark built in ARE and designed to measure general agent capabilities. Beyond search and execution, Gaia2 requires agents to handle ambiguities and noise, adapt to dynamic environments, collaborate with other agents, and operate under temporal constraints. Unlike prior benchmarks, Gaia2 runs asynchronously, surfacing new failure modes that are invisible in static settings. Our experiments show that no system dominates across the intelligence spectrum: stronger reasoning often comes at the cost of efficiency, and budget scaling curves plateau, highlighting the need for new architectures and adaptive compute strategies. Perhaps more importantly, ARE abstractions enable continuous extension of Gaia2 to other environments, empowering the community to rapidly create new benchmarks tailored to their domains. In AI's second half, progress increasingly depends on defining meaningful tasks and robust evaluations to drive frontier capabilities forward.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.17158.pdf", "abstract_url": "https://arxiv.org/abs/2509.17158", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了ARE平台和Gaia2基准，用于可扩展的智能体环境创建和评估，强调处理动态、协作任务，并揭示当前系统的局限性。", "motivation": "解决智能体模型开发与真实世界部署之间的差距，以及现有基准在动态和异步环境评估上的不足。", "method": "使用ARE平台构建环境抽象，并开发Gaia2基准，要求智能体处理模糊性、噪声、动态变化、协作和时间约束。", "result": "实验显示，没有系统在所有智能方面占优，推理能力提升常以效率为代价，预算扩展曲线趋于平稳。", "conclusion": "ARE和Gaia2支持持续扩展，推动社区创建定制基准，强调定义有意义任务对AI进步的重要性。"}}
{"id": "2509.17240", "title": "Can Agents Judge Systematic Reviews Like Humans? Evaluating SLRs with LLM-based Multi-Agent System", "authors": ["Abdullah Mushtaq", "Muhammad Rafay Naeem", "Ibrahim Ghaznavi", "Alaa Abd-alrazaq", "Aliya Tabassum", "Junaid Qadir"], "abstract": "Systematic Literature Reviews (SLRs) are foundational to evidence-based research but remain labor-intensive and prone to inconsistency across disciplines. We present an LLM-based SLR evaluation copilot built on a Multi-Agent System (MAS) architecture to assist researchers in assessing the overall quality of the systematic literature reviews. The system automates protocol validation, methodological assessment, and topic relevance checks using a scholarly database. Unlike conventional single-agent methods, our design integrates a specialized agentic approach aligned with PRISMA guidelines to support more structured and interpretable evaluations. We conducted an initial study on five published SLRs from diverse domains, comparing system outputs to expert-annotated PRISMA scores, and observed 84% agreement. While early results are promising, this work represents a first step toward scalable and accurate NLP-driven systems for interdisciplinary workflows and reveals their capacity for rigorous, domain-agnostic knowledge aggregation to streamline the review process.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.17240.pdf", "abstract_url": "https://arxiv.org/abs/2509.17240", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "论文提出了一种基于LLM的多智能体系统，用于自动化评估系统文献综述的质量，在初步研究中与专家评分达到84%的一致性。", "motivation": "系统文献综述是证据研究的基础，但劳动密集且易出现跨学科不一致，需要自动化工具来改进评估过程。", "method": "采用基于LLM的多智能体系统架构，结合PRISMA指南，自动化协议验证、方法评估和主题相关性检查。", "result": "在五个跨领域SLR的初步研究中，系统输出与专家PRISMA评分的一致性为84%。", "conclusion": "该系统是迈向可扩展、准确NLP驱动工具的第一步，展示了在跨学科工作流中实现严格、领域无关知识聚合的潜力。"}}
{"id": "2509.17259", "title": "Mind the Gap: Comparing Model- vs Agentic-Level Red Teaming with Action-Graph Observability on GPT-OSS-20B", "authors": ["Ilham Wicaksono", "Zekun Wu", "Rahul Patel", "Theo King", "Adriano Koshiyama", "Philip Treleaven"], "abstract": "As the industry increasingly adopts agentic AI systems, understanding their unique vulnerabilities becomes critical. Prior research suggests that security flaws at the model level do not fully capture the risks present in agentic deployments, where models interact with tools and external environments. This paper investigates this gap by conducting a comparative red teaming analysis of GPT-OSS-20B, a 20-billion parameter open-source model. Using our observability framework AgentSeer to deconstruct agentic systems into granular actions and components, we apply iterative red teaming attacks with harmful objectives from HarmBench at two distinct levels: the standalone model and the model operating within an agentic loop. Our evaluation reveals fundamental differences between model level and agentic level vulnerability profiles. Critically, we discover the existence of agentic-only vulnerabilities, attack vectors that emerge exclusively within agentic execution contexts while remaining inert against standalone models. Agentic level iterative attacks successfully compromise objectives that completely failed at the model level, with tool-calling contexts showing 24\\% higher vulnerability than non-tool contexts. Conversely, certain model-specific exploits work exclusively at the model level and fail when transferred to agentic contexts, demonstrating that standalone model vulnerabilities do not always generalize to deployed systems.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "Winner of the OpenAI GPT-OSS-20B Red Teaming Challenge (Kaggle, 2025)", "pdf_url": "https://arxiv.org/pdf/2509.17259.pdf", "abstract_url": "https://arxiv.org/abs/2509.17259", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文通过比较GPT-OSS-20B模型在独立和代理环境中的红队测试，揭示了代理级漏洞的独特性，表明模型级安全评估不足以覆盖代理AI系统的风险。", "motivation": "解决代理AI系统部署中，模型级安全漏洞无法完全反映代理环境特有风险的问题，以提升AI系统的安全性。", "method": "使用AgentSeer框架分解代理系统，在HarmBench有害目标下，对模型级和代理级进行迭代红队攻击比较。", "result": "发现代理级存在独有漏洞，工具调用环境脆弱性高24%，且模型级漏洞不一定适用于代理环境。", "conclusion": "代理AI系统需专门安全评估，模型级测试不足，对AI部署安全有重要启示。"}}
{"id": "2509.16610", "title": "LLMsPark: A Benchmark for Evaluating Large Language Models in Strategic Gaming Contexts", "authors": ["Junhao Chen", "Jingbo Sun", "Xiang Li", "Haidong Xin", "Yuhao Xue", "Yibin Xu", "Hao Zhao"], "abstract": "As large language models (LLMs) advance across diverse tasks, the need for comprehensive evaluation beyond single metrics becomes increasingly important. To fully assess LLM intelligence, it is crucial to examine their interactive dynamics and strategic behaviors. We present LLMsPark, a game theory-based evaluation platform that measures LLMs' decision-making strategies and social behaviors in classic game-theoretic settings, providing a multi-agent environment to explore strategic depth. Our system cross-evaluates 15 leading LLMs (both commercial and open-source) using leaderboard rankings and scoring mechanisms. Higher scores reflect stronger reasoning and strategic capabilities, revealing distinct behavioral patterns and performance differences across models. This work introduces a novel perspective for evaluating LLMs' strategic intelligence, enriching existing benchmarks and broadening their assessment in interactive, game-theoretic scenarios. The benchmark and rankings are publicly available at", "subjects": "Computation and Language (cs.CL)", "comments": "Accepted by EMNLP 2025 Findings", "pdf_url": "https://arxiv.org/pdf/2509.16610.pdf", "abstract_url": "https://arxiv.org/abs/2509.16610", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "LLMsPark是一个基于博弈论的基准平台，用于评估大型语言模型在战略游戏中的决策和社交行为，通过排行榜和评分比较15个领先模型。", "motivation": "随着大型语言模型在多任务中进步，需要超越单一指标的全面评估，以检验其交互动态和战略行为。", "method": "使用博弈论设置构建多智能体环境，通过排行榜和评分机制交叉评估15个商业和开源LLM。", "result": "高分模型显示出更强的推理和战略能力，揭示了不同模型的行为模式和性能差异。", "conclusion": "该工作为评估LLM的战略智能提供了新视角，丰富了现有基准，并扩展了在交互式博弈论场景中的评估范围。"}}
{"id": "2509.17353", "title": "Medical AI Consensus: A Multi-Agent Framework for Radiology Report Generation and Evaluation", "authors": ["Ahmed T. Elboardy", "Ghada Khoriba", "Essam A. Rashed"], "abstract": "Automating radiology report generation poses a dual challenge: building clinically reliable systems and designing rigorous evaluation protocols. We introduce a multi-agent reinforcement learning framework that serves as both a benchmark and evaluation environment for multimodal clinical reasoning in the radiology ecosystem. The proposed framework integrates large language models (LLMs) and large vision models (LVMs) within a modular architecture composed of ten specialized agents responsible for image analysis, feature extraction, report generation, review, and evaluation. This design enables fine-grained assessment at both the agent level (e.g., detection and segmentation accuracy) and the consensus level (e.g., report quality and clinical relevance). We demonstrate an implementation using chatGPT-4o on public radiology datasets, where LLMs act as evaluators alongside medical radiologist feedback. By aligning evaluation protocols with the LLM development lifecycle, including pretraining, finetuning, alignment, and deployment, the proposed benchmark establishes a path toward trustworthy deviance-based radiology report generation.", "subjects": "Artificial Intelligence (cs.AI); Image and Video Processing (eess.IV); Medical Physics (physics.med-ph)", "comments": "NeurIPS2025 Workshop: Evaluating the Evolving LLM Lifecycle: Benchmarks, Emergent Abilities, and Scaling", "pdf_url": "https://arxiv.org/pdf/2509.17353.pdf", "abstract_url": "https://arxiv.org/abs/2509.17353", "categories": ["Artificial Intelligence (cs.AI)", "Image and Video Processing (eess.IV)", "Medical Physics (physics.med-ph)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文提出了一个多智能体强化学习框架，用于放射学报告生成和评估，整合了大型语言模型和视觉模型，通过模块化智能体实现细粒度评估，并在公共数据集上进行了演示。", "motivation": "解决自动化放射学报告生成中构建临床可靠系统和设计严格评估协议的双重挑战。", "method": "采用多智能体强化学习框架，集成大型语言模型和视觉模型，由十个专门智能体负责图像分析、特征提取、报告生成、审查和评估。", "result": "在公共放射学数据集上使用ChatGPT-4o实现，展示了智能体级和共识级的评估，结合放射科医生反馈，验证了框架的有效性。", "conclusion": "该基准测试为可信赖的放射学报告生成提供了路径，通过将评估协议与LLM开发周期对齐，促进了临床相关性的提升。"}}
{"id": "2509.16666", "title": "Robust Native Language Identification through Agentic Decomposition", "authors": ["Ahmet Yavuz Uluslu", "Tannon Kew", "Tilia Ellendorff", "Gerold Schneider", "Rico Sennrich"], "abstract": "Large language models (LLMs) often achieve high performance in native language identification (NLI) benchmarks by leveraging superficial contextual clues such as names, locations, and cultural stereotypes, rather than the underlying linguistic patterns indicative of native language (L1) influence. To improve robustness, previous work has instructed LLMs to disregard such clues. In this work, we demonstrate that such a strategy is unreliable and model predictions can be easily altered by misleading hints. To address this problem, we introduce an agentic NLI pipeline inspired by forensic linguistics, where specialized agents accumulate and categorize diverse linguistic evidence before an independent final overall assessment. In this final assessment, a goal-aware coordinating agent synthesizes all evidence to make the NLI prediction. On two benchmark datasets, our approach significantly enhances NLI robustness against misleading contextual clues and performance consistency compared to standard prompting methods.", "subjects": "Computation and Language (cs.CL)", "comments": "Accepted at EMNLP* 2025", "pdf_url": "https://arxiv.org/pdf/2509.16666.pdf", "abstract_url": "https://arxiv.org/abs/2509.16666", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种基于代理分解的鲁棒母语识别方法，通过专门代理收集和分类语言证据，再由协调代理综合评估，显著提高了对误导性上下文线索的鲁棒性。", "motivation": "解决大语言模型在母语识别中过度依赖表面上下文线索（如姓名、地点）而非深层语言模式的问题，以提高模型的鲁棒性和一致性。", "method": "采用受法证语言学启发的代理化管道，包括专门代理积累和分类语言证据，以及独立协调代理进行最终预测。", "result": "在两个基准数据集上，该方法相比标准提示方法，显著增强了鲁棒性和性能一致性。", "conclusion": "代理分解方法能有效提升母语识别的鲁棒性，为改进语言模型在敏感任务中的应用提供了新途径。"}}
{"id": "2509.16713", "title": "OPEN-THEATRE: An Open-Source Toolkit for LLM-based Interactive Drama", "authors": ["Tianyang Xu", "Hongqiu Wu", "Weiqi Wu", "Hai Zhao"], "abstract": "LLM-based Interactive Drama introduces a novel dialogue scenario in which the player immerses into a character and engages in a dramatic story by interacting with LLM agents. Despite the fact that this emerging area holds significant promise, it remains largely underexplored due to the lack of a well-designed playground to develop a complete drama. This makes a significant barrier for researchers to replicate, extend, and study such systems. Hence, we present Open-Theatre, the first open-source toolkit for experiencing and customizing LLM-based interactive drama. It refines prior work with an efficient multi-agent architecture and a hierarchical retrieval-based memory system, designed to enhance narrative coherence and realistic long-term behavior in complex interactions. In addition, we provide a highly configurable pipeline, making it easy for researchers to develop and optimize new approaches.", "subjects": "Computation and Language (cs.CL)", "comments": "Accepted by EMNLP 2025 demo", "pdf_url": "https://arxiv.org/pdf/2509.16713.pdf", "abstract_url": "https://arxiv.org/abs/2509.16713", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了Open-Theatre，一个开源工具包，用于基于LLM的交互式戏剧，通过多智能体架构和分层记忆系统提升叙事连贯性。", "motivation": "解决交互式戏剧领域缺乏标准化工具的问题，便于研究人员复制和扩展系统。", "method": "采用高效的多智能体架构和分层检索式记忆系统，提供可配置的管道。", "result": "开发了首个开源工具包，支持定制化交互式戏剧，增强长期行为的真实性。", "conclusion": "Open-Theatre降低了研究门槛，促进了该领域的发展。"}}
{"id": "2509.17425", "title": "Evaluating Multimodal Large Language Models with Daily Composite Tasks in Home Environments", "authors": ["Zhenliang Zhang", "Yuxi Wang", "Hongzhao Xie", "Shiyun Zhao", "Mingyuan Liu", "Yujie Lu", "Xinyi He", "Zhenku Cheng", "Yujia Peng"], "abstract": "A key feature differentiating artificial general intelligence (AGI) from traditional AI is that AGI can perform composite tasks that require a wide range of capabilities. Although embodied agents powered by multimodal large language models (MLLMs) offer rich perceptual and interactive capabilities, it remains largely unexplored whether they can solve composite tasks. In the current work, we designed a set of composite tasks inspired by common daily activities observed in early childhood development. Within a dynamic and simulated home environment, these tasks span three core domains: object understanding, spatial intelligence, and social activity. We evaluated 17 leading proprietary and open-source MLLMs on these tasks. The results consistently showed poor performance across all three domains, indicating a substantial gap between current capabilities and general intelligence requirements. Together, our tasks offer a preliminary framework for evaluating the general capabilities of embodied agents, marking an early but significant step toward the development of embodied MLLMs and their real-world deployment.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.17425.pdf", "abstract_url": "https://arxiv.org/abs/2509.17425", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过模拟家庭环境中的日常复合任务评估了17个领先的多模态大语言模型，发现它们在物体理解、空间智能和社交活动方面表现不佳，揭示了与通用智能的差距。", "motivation": "解决当前多模态大语言模型是否能执行需要广泛能力的复合任务的问题，以评估其通用智能潜力。", "method": "设计基于幼儿日常活动的复合任务，在动态模拟家庭环境中评估17个专有和开源模型，覆盖物体理解、空间智能和社交活动三个核心领域。", "result": "所有模型在三个领域均表现差，表明当前能力与通用智能要求存在显著差距。", "conclusion": "任务集为评估具身代理的通用能力提供了初步框架，是开发具身MLLM及其实际应用的重要早期步骤。"}}
{"id": "2509.17544", "title": "A Multimodal Conversational Assistant for the Characterization of Agricultural Plots from Geospatial Open Data", "authors": ["Juan Cañada", "Raúl Alonso", "Julio Molleda", "Fidel Díez"], "abstract": "The increasing availability of open Earth Observation (EO) and agricultural datasets holds great potential for supporting sustainable land management. However, their high technical entry barrier limits accessibility for non-expert users. This study presents an open-source conversational assistant that integrates multimodal retrieval and large language models (LLMs) to enable natural language interaction with heterogeneous agricultural and geospatial data. The proposed architecture combines orthophotos, Sentinel-2 vegetation indices, and user-provided documents through retrieval-augmented generation (RAG), allowing the system to flexibly determine whether to rely on multimodal evidence, textual knowledge, or both in formulating an answer. To assess response quality, we adopt an LLM-as-a-judge methodology using Qwen3-32B in a zero-shot, unsupervised setting, applying direct scoring in a multi-dimensional quantitative evaluation framework. Preliminary results show that the system is capable of generating clear, relevant, and context-aware responses to agricultural queries, while remaining reproducible and scalable across geographic regions. The primary contributions of this work include an architecture for fusing multimodal EO and textual knowledge sources, a demonstration of lowering the barrier to access specialized agricultural information through natural language interaction, and an open and reproducible design.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.17544.pdf", "abstract_url": "https://arxiv.org/abs/2509.17544", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种开源多模态对话助手，利用检索增强生成技术整合地理空间和农业数据，通过自然语言交互降低非专家用户的使用门槛。", "motivation": "解决地球观测和农业数据技术门槛高、非专家用户难以访问的问题。", "method": "采用检索增强生成架构，结合多模态检索和大型语言模型，融合正射影像、植被指数和用户文档。", "result": "初步结果显示系统能生成清晰、相关且上下文感知的农业查询响应，具有可重现性和可扩展性。", "conclusion": "主要贡献包括融合多模态知识的架构、降低信息访问壁垒的演示，以及开放可重现的设计。"}}
{"id": "2509.17044", "title": "AgriDoctor: A Multimodal Intelligent Assistant for Agriculture", "authors": ["Mingqing Zhang", "Zhuoning Xu", "Peijie Wang", "Rongji Li", "Liang Wang", "Qiang Liu", "Jian Xu", "Xuyao Zhang", "Shu Wu", "Liang Wang"], "abstract": "Accurate crop disease diagnosis is essential for sustainable agriculture and global food security. Existing methods, which primarily rely on unimodal models such as image-based classifiers and object detectors, are limited in their ability to incorporate domain-specific agricultural knowledge and lack support for interactive, language-based understanding. Recent advances in large language models (LLMs) and large vision-language models (LVLMs) have opened new avenues for multimodal reasoning. However, their performance in agricultural contexts remains limited due to the absence of specialized datasets and insufficient domain adaptation. In this work, we propose AgriDoctor, a modular and extensible multimodal framework designed for intelligent crop disease diagnosis and agricultural knowledge interaction. As a pioneering effort to introduce agent-based multimodal reasoning into the agricultural domain, AgriDoctor offers a novel paradigm for building interactive and domain-adaptive crop health solutions. It integrates five core components: a router, classifier, detector, knowledge retriever and LLMs. To facilitate effective training and evaluation, we construct AgriMM, a comprehensive benchmark comprising 400000 annotated disease images, 831 expert-curated knowledge entries, and 300000 bilingual prompts for intent-driven tool selection. Extensive experiments demonstrate that AgriDoctor, trained on AgriMM, significantly outperforms state-of-the-art LVLMs on fine-grained agricultural tasks, establishing a new paradigm for intelligent and sustainable farming applications.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.17044.pdf", "abstract_url": "https://arxiv.org/abs/2509.17044", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出AgriDoctor，一种用于农业的多模态智能助手，通过整合视觉和语言模型提高作物病害诊断的准确性和交互性。", "motivation": "解决现有单模态模型在农业领域缺乏领域知识和语言交互能力的问题，以及大型视觉语言模型在农业应用中性能不足的局限。", "method": "采用模块化多模态框架，包括路由器、分类器、检测器、知识检索器和LLM，并构建AgriMM数据集进行训练。", "result": "实验表明，AgriDoctor在农业任务上显著优于现有最先进模型。", "conclusion": "AgriDoctor为智能农业建立了新范式，推动了可持续农业应用的发展。"}}
{"id": "2509.17567", "title": "LIMI: Less is More for Agency", "authors": ["Yang Xiao", "Mohan Jiang", "Jie Sun", "Keyu Li", "Jifan Lin", "Yumin Zhuang", "Ji Zeng", "Shijie Xia", "Qishuo Hua", "Xuefeng Li", "Xiaojie Cai", "Tongyu Wang", "Yue Zhang", "Liming Liu", "Xia Wu", "Jinlong Hou", "Yuan Cheng", "Wenjie Li", "Xiang Wang", "Dequan Wang", "Pengfei Liu"], "abstract": "We define Agency as the emergent capacity of AI systems to function as autonomous agents actively discovering problems, formulating hypotheses, and executing solutions through self-directed engagement with environments and tools. This fundamental capability marks the dawn of the Age of AI Agency, driven by a critical industry shift: the urgent need for AI systems that don't just think, but work. While current AI excels at reasoning and generating responses, industries demand autonomous agents that can execute tasks, operate tools, and drive real-world outcomes. As agentic intelligence becomes the defining characteristic separating cognitive systems from productive workers, efficiently cultivating machine autonomy becomes paramount. Current approaches assume that more data yields better agency, following traditional scaling laws from language modeling. We fundamentally challenge this paradigm. LIMI (Less Is More for Intelligent Agency) demonstrates that agency follows radically different development principles. Through strategic focus on collaborative software development and scientific research workflows, we show that sophisticated agentic intelligence can emerge from minimal but strategically curated demonstrations of autonomous behavior. Using only 78 carefully designed training samples, LIMI achieves 73.5% on comprehensive agency benchmarks, dramatically outperforming state-of-the-art models: Kimi-K2-Instruct (24.1%), DeepSeek-V3.1 (11.9%), Qwen3-235B-A22B-Instruct (27.5%), and GLM-4.5 (45.1%). Most strikingly, LIMI demonstrates 53.7% improvement over models trained on 10,000 samples-achieving superior agentic intelligence with 128 times fewer samples. Our findings establish the Agency Efficiency Principle: machine autonomy emerges not from data abundance but from strategic curation of high-quality agentic demonstrations.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.17567.pdf", "abstract_url": "https://arxiv.org/abs/2509.17567", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "LIMI 论文提出，通过少量高质量训练样本（仅78个）即可培养AI代理智能，挑战了数据越多代理能力越强的传统观念，并在基准测试中显著超越现有模型。", "motivation": "解决当前AI系统在自主执行任务和驱动现实成果方面的不足，满足行业对能主动工作而非仅思考的自主代理的迫切需求。", "method": "采用LIMI方法，通过战略性地精选自主行为演示样本，而非依赖大规模数据，专注于协作软件开发和科学研究工作流来培养代理智能。", "result": "LIMI在综合代理基准测试中达到73.5%的准确率，优于多个先进模型，且使用样本量减少128倍时性能提升53.7%。", "conclusion": "确立了代理效率原则：机器自主性源于高质量演示的战略性精选，而非数据量，为高效AI代理开发提供了新范式。"}}
{"id": "2509.17917", "title": "Orcust: Stepwise-Feedback Reinforcement Learning for GUI Agent", "authors": ["Junyu Lu", "Songxin Zhang", "Zejian Xie", "Zhuoyang Song", "Jiaxing Zhang"], "abstract": "Recent advances in GUI agents have achieved remarkable grounding and action-prediction performance, yet existing models struggle with unreliable reward signals and limited online trajectory generation. In this paper, we introduce Orcust, a framework that integrates Principle-Constrained Reward Modeling (PCRM) and Online VM-Grounded Trajectory Construction (OVTC) to enhance reasoning reliability and data efficiency in interactive GUI tasks. We leverages environment-verifiable and LLM-derived principle to enforce interpretable reward signals that constrain long chain-of-thought reasoning and rule-based feedback. OVTC spins up instrumented virtual machines to autonomously collect structured GUI interaction trajectories with explicit procedural and structural objectives, enabling the training of a stepwise reward model that robustly captures human preferences and adheres to task-specific constraints. Extensive experiments on standard GUI benchmarks covering perceptual grounding, foundational operations, and end-to-end task execution reveal that Orcust achieves state-of-the-art performance, improving by 22.2\\% on ScreenSpot and 23.9\\% on ScreenSpot-Pro over the base model (i.e. Qwen2.5-VL-7B). The results demonstrate Orcust's effectiveness in enhancing the reasoning, adaptability and scalability of GUI agents across various environments and task complexities.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.17917.pdf", "abstract_url": "https://arxiv.org/abs/2509.17917", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "Orcust框架通过PCRM和OVTC方法提升GUI代理的推理可靠性和数据效率，在标准基准测试中实现SOTA性能。", "motivation": "解决GUI代理中奖励信号不可靠和在线轨迹生成有限的问题。", "method": "整合PCRM和OVTC，使用环境可验证原则和虚拟机自主收集轨迹来训练逐步奖励模型。", "result": "在ScreenSpot和ScreenSpot-Pro基准上分别提升22.2%和23.9%。", "conclusion": "Orcust有效增强GUI代理的推理、适应性和可扩展性。"}}
{"id": "2509.17978", "title": "The STAR-XAI Protocol: An Interactive Framework for Inducing Second-Order Agency in AI Agents", "authors": ["Antoni Guasch", "Maria Isabel Valdez"], "abstract": "Current Large Reasoning Models (LRMs) exhibit significant limitations in reliability and transparency, often showing a collapse in reasoning capabilities when faced with high-complexity, long-horizon tasks. This \"illusion of thinking\" is frequently an artifact of non-agentic, black-box evaluation paradigms that fail to cultivate robust problem-solving processes. In response, we introduce The STAR-XAI Protocol (Socratic, Transparent, Agentic, Reasoning - for eXplainable Artificial Intelligence), a novel methodology for training and operating verifiably reliable AI agents. Our method reframes the human-AI interaction as a structured, Socratic dialogue, governed by an explicit and evolving rulebook, the Consciousness Transfer Package (CTP). Through an interactive Gameplay Cycle that enforces ante-hoc strategic justification and a state-locking Checksum that prevents error accumulation, the protocol transforms a powerful but opaque LRM into a disciplined \"Clear Box\" agent. We demonstrate the efficacy of this method through an exhaustive 25-move case study in the complex strategic game \"Caps i Caps\". The agent not only solved the high-complexity puzzle but also demonstrated Second-Order Agency, identifying flaws in its own supervisor-approved plans and adapting its core integrity protocols mid-task. The STAR-XAI Protocol offers a practical pathway to creating AI agents that are not just high-performing, but also transparent, auditable, and trustworthy by design.", "subjects": "Artificial Intelligence (cs.AI); Logic in Computer Science (cs.LO)", "comments": "Paper 1 of 4 in The STAR-XAI Protocol series. Paper 2 [arXiv:ID_to_be_added], Paper 3 [arXiv:ID_to_be_added], Paper 4 [arXiv:ID_to_be_added]", "pdf_url": "https://arxiv.org/pdf/2509.17978.pdf", "abstract_url": "https://arxiv.org/abs/2509.17978", "categories": ["Artificial Intelligence (cs.AI)", "Logic in Computer Science (cs.LO)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出STAR-XAI协议，一种通过苏格拉底对话和规则书训练透明、可靠AI代理的方法，在复杂任务中展示二阶代理能力。", "motivation": "解决大型推理模型在复杂任务中可靠性和透明度不足的问题，避免'思考幻觉'。", "method": "使用STAR-XAI协议，包括苏格拉底对话、意识转移包、游戏循环和状态锁定校验和，将模型转化为'透明盒'代理。", "result": "在'Caps i Caps'游戏中，代理成功解决高复杂度谜题，并展示二阶代理能力，如识别自身计划缺陷和调整协议。", "conclusion": "该协议为创建透明、可审计、可信赖的AI代理提供了实用路径。"}}
{"id": "2509.18076", "title": "Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates", "authors": ["Hy Dang", "Tianyi Liu", "Zhuofeng Wu", "Jingfeng Yang", "Haoming Jiang", "Tao Yang", "Pei Chen", "Zhengyang Wang", "Helen Wang", "Huasheng Li", "Bing Yin", "Meng Jiang"], "abstract": "Large language models (LLMs) have demonstrated strong reasoning and tool-use capabilities, yet they often fail in real-world tool-interactions due to incorrect parameterization, poor tool selection, or misinterpretation of user intent. These issues often stem from an incomplete understanding of user goals and inadequate comprehension of tool documentation. While Chain-of-Thought (CoT) prompting has proven effective for enhancing reasoning in general contexts, our analysis reveals that free-form CoT is insufficient and sometimes counterproductive for structured function-calling tasks. To address this, we introduce a curriculum-inspired framework that leverages structured reasoning templates to guide LLMs through more deliberate step-by-step instructions for generating function callings. Experimental results show that our method reduces tool-use errors, achieving 3-12% relative improvements over strong baselines across diverse model series and approaches. Moreover, our framework enhances the robustness, interpretability, and transparency of tool-using agents, advancing the development of more reliable AI assistants for real-world applications.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "Accepted to EMNLP 2025 Main Conference", "pdf_url": "https://arxiv.org/pdf/2509.18076.pdf", "abstract_url": "https://arxiv.org/abs/2509.18076", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于结构化推理模板的课程启发框架，用于改进大型语言模型的函数调用能力，减少工具使用错误并增强可解释性。", "motivation": "解决大型语言模型在真实世界工具交互中因参数化错误、工具选择不当或用户意图误解而失败的问题，这些问题源于对用户目标和工具文档理解不足。", "method": "引入课程启发框架，利用结构化推理模板指导模型通过逐步指令生成函数调用，替代自由形式的思维链提示。", "result": "实验显示，该方法在不同模型系列上相对基线减少工具使用错误，实现3-12%的相对改进，并提高了鲁棒性、可解释性和透明度。", "conclusion": "该框架推进了更可靠AI助手的发展，为实际应用提供了更稳健和可解释的工具使用能力。"}}
{"id": "2509.16212", "title": "EPIC: Generative AI Platform for Accelerating HPC Operational Data Analytics", "authors": ["Ahmad Maroof Karimi", "Woong Shin", "Jesse Hines", "Tirthankar Ghosal", "Naw Safrin Sattar", "Feiyi Wang"], "abstract": "We present EPIC, an AI-driven platform designed to augment operational data analytics. EPIC employs a hierarchical multi-agent architecture where a top-level large language model provides query processing, reasoning and synthesis capabilities. These capabilities orchestrate three specialized low-level agents for information retrieval, descriptive analytics, and predictive analytics. This architecture enables EPIC to perform HPC operational analytics on multi-modal data, including text, images, and tabular formats, dynamically and iteratively. EPIC addresses the limitations of existing HPC operational analytics approaches, which rely on static methods that struggle to adapt to evolving analytics tasks and stakeholder demands.", "subjects": "Databases (cs.DB); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.16212.pdf", "abstract_url": "https://arxiv.org/abs/2509.16212", "categories": ["Databases (cs.DB)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "EPIC是一个基于AI的平台，采用分层多代理架构，利用大型语言模型协调专业代理，对多模态数据进行动态高性能计算操作数据分析。", "motivation": "解决现有高性能计算操作数据分析方法依赖静态技术，难以适应不断变化的分析任务和利益相关者需求的问题。", "method": "使用分层多代理架构，顶层大型语言模型处理查询和推理，协调底层专业代理进行信息检索、描述性分析和预测性分析。", "result": "EPIC能够动态、迭代地处理文本、图像和表格等多模态数据，提升分析能力。", "conclusion": "EPIC通过AI驱动方法增强了高性能计算操作数据分析的适应性和效率，具有实际应用价值。"}}
{"id": "2509.16952", "title": "AirQA: A Comprehensive QA Dataset for AI Research with Instance-Level Evaluation", "authors": ["Tiancheng Huang", "Ruisheng Cao", "Yuxin Zhang", "Zhangyi Kang", "Zijian Wang", "Chenrun Wang", "Yijie Luo", "Hang Zheng", "Lirong Qian", "Lu Chen", "Kai Yu"], "abstract": "The growing volume of academic papers has made it increasingly difficult for researchers to efficiently extract key information. While large language models (LLMs) based agents are capable of automating question answering (QA) workflows for scientific papers, there still lacks a comprehensive and realistic benchmark to evaluate their capabilities. Moreover, training an interactive agent for this specific task is hindered by the shortage of high-quality interaction trajectories. In this work, we propose AirQA, a human-annotated comprehensive paper QA dataset in the field of artificial intelligence (AI), with 13,948 papers and 1,246 questions, that encompasses multi-task, multi-modal and instance-level evaluation. Furthermore, we propose ExTrActor, an automated framework for instruction data synthesis. With three LLM-based agents, ExTrActor can perform example generation and trajectory collection without human intervention. Evaluations of multiple open-source and proprietary models show that most models underperform on AirQA, demonstrating the quality of our dataset. Extensive experiments confirm that ExTrActor consistently improves the multi-turn tool-use capability of small models, enabling them to achieve performance comparable to larger ones.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.16952.pdf", "abstract_url": "https://arxiv.org/abs/2509.16952", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文提出了AirQA数据集和ExTrActor框架，用于评估和改进AI论文的问答能力。", "motivation": "解决学术论文信息提取效率低和缺乏全面基准来评估LLM代理能力的问题。", "method": "创建人工标注的AirQA数据集，并开发ExTrActor框架自动生成指令数据和收集交互轨迹。", "result": "大多数模型在AirQA上表现不佳，ExTrActor能提升小模型的多轮工具使用能力，使其达到与大模型相当的水平。", "conclusion": "AirQA是高质量的基准，ExTrActor有效提升模型性能，对AI研究有重要意义。"}}
{"id": "2509.17167", "title": "SFT-TA: Supervised Fine-Tuned Agents in Multi-Agent LLMs for Automated Inductive Thematic Analysis", "authors": ["Seungjun Yi", "Joakim Nguyen", "Huimin Xu", "Terence Lim", "Joseph Skrovan", "Mehak Beri", "Hitakshi Modi", "Andrew Well", "Liu Leqi", "Mia Markey", "Ying Ding"], "abstract": "Thematic Analysis (TA) is a widely used qualitative method that provides a structured yet flexible framework for identifying and reporting patterns in clinical interview transcripts. However, manual thematic analysis is time-consuming and limits scalability. Recent advances in LLMs offer a pathway to automate thematic analysis, but alignment with human results remains limited. To address these limitations, we propose SFT-TA, an automated thematic analysis framework that embeds supervised fine-tuned (SFT) agents within a multi-agent system. Our framework outperforms existing frameworks and the gpt-4o baseline in alignment with human reference themes. We observed that SFT agents alone may underperform, but achieve better results than the baseline when embedded within a multi-agent system. Our results highlight that embedding SFT agents in specific roles within a multi-agent system is a promising pathway to improve alignment with desired outputs for thematic analysis.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.17167.pdf", "abstract_url": "https://arxiv.org/abs/2509.17167", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文提出了SFT-TA框架，通过在多智能体系统中嵌入监督微调代理，自动进行主题分析，提高了与人类参考主题的对齐度。", "motivation": "手动主题分析耗时且难以扩展，现有LLM自动化方法对齐人类结果有限，需要改进。", "method": "使用监督微调代理嵌入多智能体系统，以特定角色协作进行主题分析。", "result": "SFT-TA框架优于现有方法和GPT-4o基线，多智能体系统提升了SFT代理的性能。", "conclusion": "在多智能体系统中嵌入SFT代理是提高主题分析对齐度的有效途径。"}}
{"id": "2509.17107", "title": "CoBEVMoE: Heterogeneity-aware Feature Fusion with Dynamic Mixture-of-Experts for Collaborative Perception", "authors": ["Lingzhao Kong", "Jiacheng Lin", "Siyu Li", "Kai Luo", "Zhiyong Li", "Kailun Yang"], "abstract": "Collaborative perception aims to extend sensing coverage and improve perception accuracy by sharing information among multiple agents. However, due to differences in viewpoints and spatial positions, agents often acquire heterogeneous observations. Existing intermediate fusion methods primarily focus on aligning similar features, often overlooking the perceptual diversity among agents. To address this limitation, we propose CoBEVMoE, a novel collaborative perception framework that operates in the Bird's Eye View (BEV) space and incorporates a Dynamic Mixture-of-Experts (DMoE) architecture. In DMoE, each expert is dynamically generated based on the input features of a specific agent, enabling it to extract distinctive and reliable cues while attending to shared semantics. This design allows the fusion process to explicitly model both feature similarity and heterogeneity across agents. Furthermore, we introduce a Dynamic Expert Metric Loss (DEML) to enhance inter-expert diversity and improve the discriminability of the fused representation. Extensive experiments on the OPV2V and DAIR-V2X-C datasets demonstrate that CoBEVMoE achieves state-of-the-art performance. Specifically, it improves the IoU for Camera-based BEV segmentation by +1.5% on OPV2V and the AP@50 for LiDAR-based 3D object detection by +3.0% on DAIR-V2X-C, verifying the effectiveness of expert-based heterogeneous feature modeling in multi-agent collaborative perception. The source code will be made publicly available at", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO); Image and Video Processing (eess.IV)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2509.17107.pdf", "abstract_url": "https://arxiv.org/abs/2509.17107", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Robotics (cs.RO)", "Image and Video Processing (eess.IV)"], "matching_keywords": ["agent"], "AI": {"tldr": "CoBEVMoE 是一个用于协作感知的新框架，在 BEV 空间中使用动态 Mixture-of-Experts 架构，通过动态生成专家来融合异构特征，提高感知精度。", "motivation": "解决协作感知中因视角和位置差异导致的异构观测问题，现有方法忽视感知多样性。", "method": "在 BEV 空间中使用 DMoE 架构，动态生成专家提取特征，并引入 DEML 损失增强多样性。", "result": "在 OPV2V 和 DAIR-V2X-C 数据集上实现 SOTA，BEV 分割 IoU 提高 1.5%，3D 检测 AP@50 提高 3.0%。", "conclusion": "基于专家的异构特征建模有效，可提升多代理协作感知性能，代码将开源。"}}
{"id": "2509.17395", "title": "FinDebate: Multi-Agent Collaborative Intelligence for Financial Analysis", "authors": ["Tianshi Cai", "Guanxu Li", "Nijia Han", "Ce Huang", "Zimu Wang", "Changyu Zeng", "Yuqi Wang", "Jingshi Zhou", "Haiyang Zhang", "Qi Chen", "Yushan Pan", "Shuihua Wang", "Wei Wang"], "abstract": "We introduce FinDebate, a multi-agent framework for financial analysis, integrating collaborative debate with domain-specific Retrieval-Augmented Generation (RAG). Five specialized agents, covering earnings, market, sentiment, valuation, and risk, run in parallel to synthesize evidence into multi-dimensional insights. To mitigate overconfidence and improve reliability, we introduce a safe debate protocol that enables agents to challenge and refine initial conclusions while preserving coherent recommendations. Experimental results, based on both LLM-based and human evaluations, demonstrate the framework's efficacy in producing high-quality analysis with calibrated confidence levels and actionable investment strategies across multiple time horizons.", "subjects": "Computation and Language (cs.CL)", "comments": "Accepted at FinNLP@EMNLP 2025. Camera-ready version", "pdf_url": "https://arxiv.org/pdf/2509.17395.pdf", "abstract_url": "https://arxiv.org/abs/2509.17395", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "FinDebate是一个多智能体框架，用于金融分析，通过协作辩论和领域特定RAG合成多维见解，提高可靠性和置信度。", "motivation": "解决金融分析中过度自信和可靠性不足的问题。", "method": "使用五个专业智能体并行运行，结合安全辩论协议和RAG进行证据合成。", "result": "实验显示框架能产生高质量分析，置信度校准良好，投资策略可行。", "conclusion": "FinDebate能生成可靠、可操作的金融分析，适用于多时间范围。"}}
{"id": "2509.17191", "title": "VaseVQA: Multimodal Agent and Benchmark for Ancient Greek Pottery", "authors": ["Jinchao Ge", "Tengfei Cheng", "Biao Wu", "Zeyu Zhang", "Shiya Huang", "Judith Bishop", "Gillian Shepherd", "Meng Fang", "Ling Chen", "Yang Zhao"], "abstract": "Analyzing cultural-heritage artifacts remains challenging for MLLMs: general models lack domain expertise, and SFT often overfits superficial patterns, yielding brittle reasoning for authentication and historical attribution. This raises the question of how to equip MLLMs with robust, expert-level reasoning for ancient Greek pottery. We present VaseVL, an SFT-then-RL system that turns evaluation into supervision: we construct a taxonomy of question types, probe the SFT model to localize type-specific performance gaps, and optimize with type-conditioned, compositionality-oriented rewards targeting those gaps. We also release VaseVQA, a comprehensive benchmark of 31,773 images designed to probe deep understanding. Experiments show state-of-the-art results on style classification and historical attribution with marked gains in compositional robustness over SFT-only baselines, validating diagnosis-guided, taxonomy-conditioned reward engineering and providing a reusable resource for future research. Code and dataset will be available at", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.17191.pdf", "abstract_url": "https://arxiv.org/abs/2509.17191", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了VaseVQA，一个针对古希腊陶器的多模态代理和基准，通过SFT-then-RL系统提升模型推理能力，并在风格分类和历史归属任务上取得先进成果。", "motivation": "解决多模态大语言模型在文化遗产分析中缺乏领域专业知识、容易过拟合的问题，以实现对古希腊陶器的鲁棒专家级推理。", "method": "使用SFT-then-RL系统，构建问题类型分类法，定位性能差距，并通过类型条件、组合性导向的奖励进行优化。", "result": "实验显示在风格分类和历史归属任务上达到最先进水平，组合鲁棒性显著优于仅用SFT的基线。", "conclusion": "验证了诊断引导、分类法条件奖励工程的有效性，并提供了可重用的VaseVQA基准资源。"}}
{"id": "2509.16275", "title": "SecureFixAgent: A Hybrid LLM Agent for Automated Python Static Vulnerability Repair", "authors": ["Jugal Gajjar", "Kamalasankari Subramaniakuppusamy", "Relsy Puthal", "Kaustik Ranaware"], "abstract": "Modern software development pipelines face growing challenges in securing large codebases with extensive dependencies. Static analysis tools like Bandit are effective at vulnerability detection but suffer from high false positives and lack repair capabilities. Large Language Models (LLMs), in contrast, can suggest fixes but often hallucinate changes and lack self-validation. We present SecureFixAgent, a hybrid repair framework integrating Bandit with lightweight local LLMs (<8B parameters) in an iterative detect-repair-validate loop. To improve precision, we apply parameter-efficient LoRA-based fine-tuning on a diverse, curated dataset spanning multiple Python project domains, mitigating dataset bias and reducing unnecessary edits. SecureFixAgent uses Bandit for detection, the LLM for candidate fixes with explanations, and Bandit re-validation for verification, all executed locally to preserve privacy and reduce cloud reliance. Experiments show SecureFixAgent reduces false positives by 10.8% over static analysis, improves fix accuracy by 13.51%, and lowers false positives by 5.46% compared to pre-trained LLMs, typically converging within three iterations. Beyond metrics, developer studies rate explanation quality 4.5/5, highlighting its value for human trust and adoption. By combining verifiable security improvements with transparent rationale in a resource-efficient local framework, SecureFixAgent advances trustworthy, automated vulnerability remediation for modern pipelines.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Software Engineering (cs.SE)", "comments": "6 pages, 3 figures, 4 tables, 1 algorithm, accepted in the Robustness and Security of Large Language Models (ROSE-LLM) special session at ICMLA 2025", "pdf_url": "https://arxiv.org/pdf/2509.16275.pdf", "abstract_url": "https://arxiv.org/abs/2509.16275", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Software Engineering (cs.SE)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出SecureFixAgent，一种混合LLM代理，通过结合Bandit静态分析与轻量级本地LLM，在迭代的检测-修复-验证循环中自动修复Python静态漏洞，减少误报并提高修复精度。", "motivation": "解决静态分析工具高误报和缺乏修复能力，以及LLM修复时产生幻觉变化和缺乏自我验证的问题，以提升软件安全性。", "method": "集成Bandit检测、本地LLM生成修复候选和解释、Bandit重新验证的迭代框架，使用LoRA微调减少数据集偏差。", "result": "实验显示误报减少10.8%，修复精度提高13.51%，误报比预训练LLM降低5.46%，开发者评价解释质量4.5/5。", "conclusion": "SecureFixAgent通过可验证的安全改进和透明解释，推进了可信赖、自动化的漏洞修复，适用于现代开发流程。"}}
{"id": "2509.17328", "title": "UIPro: Unleashing Superior Interaction Capability For GUI Agents", "authors": ["Hongxin Li", "Jingran Su", "Jingfan Chen", "Zheng Ju", "Yuntao Chen", "Qing Li", "Zhaoxiang Zhang"], "abstract": "Building autonomous agents that perceive and operate graphical user interfaces (GUIs) like humans has long been a vision in the field of artificial intelligence. Central to these agents is the capability for GUI interaction, which involves GUI understanding and planning capabilities. Existing methods have tried developing GUI agents based on the multi-modal comprehension ability of vision-language models (VLMs). However, the limited scenario, insufficient size, and heterogeneous action spaces hinder the progress of building generalist GUI agents. To resolve these issues, this paper proposes \\textbf{UIPro}, a novel generalist GUI agent trained with extensive multi-platform and multi-task GUI interaction data, coupled with a unified action space. We first curate a comprehensive dataset encompassing 20.6 million GUI understanding tasks to pre-train UIPro, granting it a strong GUI grounding capability, which is key to downstream GUI agent tasks. Subsequently, we establish a unified action space to harmonize heterogeneous GUI agent task datasets and produce a merged dataset to foster the action prediction ability of UIPro via continued fine-tuning. Experimental results demonstrate UIPro's superior performance across multiple GUI task benchmarks on various platforms, highlighting the effectiveness of our approach.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC)", "comments": "Accepted to ICCV 2025", "pdf_url": "https://arxiv.org/pdf/2509.17328.pdf", "abstract_url": "https://arxiv.org/abs/2509.17328", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出UIPro，一种基于大规模多平台GUI交互数据和统一动作空间的通用GUI代理，在多个基准测试中表现优异。", "motivation": "解决现有GUI代理方法因场景有限、数据规模不足和动作空间异构而难以构建通用代理的问题。", "method": "使用2060万GUI理解任务数据预训练UIPro，建立统一动作空间并合并数据集进行微调，增强GUI基础和动作预测能力。", "result": "实验显示UIPro在多个GUI任务基准上表现卓越，验证了方法的有效性。", "conclusion": "UIPro通过统一数据和方法提升了GUI代理的交互能力，为通用代理发展提供了有效途径。"}}
{"id": "2509.17429", "title": "Multi-scale Temporal Prediction via Incremental Generation and Multi-agent Collaboration", "authors": ["Zhitao Zeng", "Guojian Yuan", "Junyuan Mao", "Yuxuan Wang", "Xiaoshuang Jia", "Yueming Jin"], "abstract": "Accurate temporal prediction is the bridge between comprehensive scene understanding and embodied artificial intelligence. However, predicting multiple fine-grained states of a scene at multiple temporal scales is difficult for vision-language models. We formalize the Multi-Scale Temporal Prediction (MSTP) task in general and surgical scenes by decomposing multi-scale into two orthogonal dimensions: the temporal scale, forecasting states of humans and surgery at varying look-ahead intervals, and the state scale, modeling a hierarchy of states in general and surgical scenes. For example, in general scenes, states of contact relationships are finer-grained than states of spatial relationships. In surgical scenes, medium-level steps are finer-grained than high-level phases yet remain constrained by their encompassing phase. To support this unified task, we introduce the first MSTP Benchmark, featuring synchronized annotations across multiple state scales and temporal scales. We further propose a method, Incremental Generation and Multi-agent Collaboration (IG-MC), which integrates two key innovations. First, we present a plug-and-play incremental generation module that continuously synthesizes up-to-date visual previews at expanding temporal scales to inform multiple decision-making agents, keeping decisions and generated visuals synchronized and preventing performance degradation as look-ahead intervals lengthen. Second, we present a decision-driven multi-agent collaboration framework for multi-state prediction, comprising generation, initiation, and multi-state assessment agents that dynamically trigger and evaluate prediction cycles to balance global coherence and local fidelity.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "20 pages, 6 figures", "pdf_url": "https://arxiv.org/pdf/2509.17429.pdf", "abstract_url": "https://arxiv.org/abs/2509.17429", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出多尺度时间预测任务，并引入IG-MC方法，通过增量生成和多智能体协作提升预测精度。", "motivation": "解决视觉语言模型在多细粒度状态和多时间尺度预测中的困难。", "method": "使用增量生成模块和多智能体协作框架，包括生成、启动和评估智能体。", "result": "开发了首个MSTP基准测试，展示了方法在保持同步和防止性能下降上的有效性。", "conclusion": "IG-MC方法为场景理解和AI应用提供了新途径，具有广泛潜力。"}}
{"id": "2509.17430", "title": "EmbodiedSplat: Personalized Real-to-Sim-to-Real Navigation with Gaussian Splats from a Mobile Device", "authors": ["Gunjan Chhablani", "Xiaomeng Ye", "Muhammad Zubair Irshad", "Zsolt Kira"], "abstract": "The field of Embodied AI predominantly relies on simulation for training and evaluation, often using either fully synthetic environments that lack photorealism or high-fidelity real-world reconstructions captured with expensive hardware. As a result, sim-to-real transfer remains a major challenge. In this paper, we introduce EmbodiedSplat, a novel approach that personalizes policy training by efficiently capturing the deployment environment and fine-tuning policies within the reconstructed scenes. Our method leverages 3D Gaussian Splatting (GS) and the Habitat-Sim simulator to bridge the gap between realistic scene capture and effective training environments. Using iPhone-captured deployment scenes, we reconstruct meshes via GS, enabling training in settings that closely approximate real-world conditions. We conduct a comprehensive analysis of training strategies, pre-training datasets, and mesh reconstruction techniques, evaluating their impact on sim-to-real predictivity in real-world scenarios. Experimental results demonstrate that agents fine-tuned with EmbodiedSplat outperform both zero-shot baselines pre-trained on large-scale real-world datasets (HM3D) and synthetically generated datasets (HSSD), achieving absolute success rate improvements of 20\\% and 40\\% on real-world Image Navigation task. Moreover, our approach yields a high sim-vs-real correlation (0.87--0.97) for the reconstructed meshes, underscoring its effectiveness in adapting policies to diverse environments with minimal effort. Project page:", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)", "comments": "16 pages, 18 figures, paper accepted at ICCV, 2025", "pdf_url": "https://arxiv.org/pdf/2509.17430.pdf", "abstract_url": "https://arxiv.org/abs/2509.17430", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出EmbodiedSplat方法，利用移动设备捕获真实场景，通过3D高斯泼溅重建网格，在模拟器中微调策略，显著提升具身AI在真实世界的导航性能。", "motivation": "解决具身AI中仿真训练与真实世界转移的差距，传统方法依赖非真实合成环境或昂贵硬件，导致sim-to-real转移困难。", "method": "结合3D高斯泼溅和Habitat-Sim模拟器，从iPhone捕获场景重建网格，进行策略微调，分析训练策略和重建技术。", "result": "在真实世界图像导航任务中，微调代理比零样本基线成功率提高20%和40%，仿真与真实相关性高达0.87-0.97。", "conclusion": "EmbodiedSplat能高效适应多样环境，最小化努力，提升sim-to-real可预测性，有广泛应用潜力。"}}
{"id": "2509.17455", "title": "Codifying Natural Langauge Tasks", "authors": ["Haoyang Chen", "Kumiko Tanaka-Ishii"], "abstract": "We explore the applicability of text-to-code to solve real-world problems that are typically solved in natural language, such as legal judgment and medical QA. Unlike previous works, our approach leverages the explicit reasoning provided by program generation. We present ICRAG, a framework that transforms natural language into executable programs through iterative refinement using external knowledge from domain resources and GitHub. Across 13 benchmarks, ICRAG achieves up to 161.1\\% relative improvement. We provide a detailed analysis of the generated code and the impact of external knowledge, and we discuss the limitations of applying text-to-code approaches to real-world natural language tasks.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "Submitted to Journal of Automated Software Engineering", "pdf_url": "https://arxiv.org/pdf/2509.17455.pdf", "abstract_url": "https://arxiv.org/abs/2509.17455", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出ICRAG框架，通过文本到代码转换和迭代优化，利用外部知识解决自然语言任务，在13个基准测试中实现高达161.1%的相对改进。", "motivation": "解决现实世界自然语言任务（如法律判决和医疗问答）中传统方法的局限性，探索文本到代码方法的适用性。", "method": "使用ICRAG框架，通过迭代优化和外部知识（如领域资源和GitHub）将自然语言转换为可执行程序。", "result": "在13个基准测试中，相对改进高达161.1%，并对生成代码和外部知识影响进行了详细分析。", "conclusion": "文本到代码方法在自然语言任务中具有潜力，但存在局限性，需进一步讨论。"}}
{"id": "2509.16369", "title": "Enhancing Financial RAG with Agentic AI and Multi-HyDE: A Novel Approach to Knowledge Retrieval and Hallucination Reduction", "authors": ["Akshay Govind Srinivasan", "Ryan Jacob George", "Jayden Koshy Joe", "Hrushikesh Kant", "Harshith M R", "Sachin Sundar", "Sudharshan Suresh", "Rahul Vimalkanth", "Vijayavallabh"], "abstract": "Accurate and reliable knowledge retrieval is vital for financial question-answering, where continually updated data sources and complex, high-stakes contexts demand precision. Traditional retrieval systems rely on a single database and retriever, but financial applications require more sophisticated approaches to handle intricate regulatory filings, market analyses, and extensive multi-year reports. We introduce a framework for financial Retrieval Augmented Generation (RAG) that leverages agentic AI and the Multi-HyDE system, an approach that generates multiple, nonequivalent queries to boost the effectiveness and coverage of retrieval from large, structured financial corpora. Our pipeline is optimized for token efficiency and multi-step financial reasoning, and we demonstrate that their combination improves accuracy by 11.2% and reduces hallucinations by 15%. Our method is evaluated on standard financial QA benchmarks, showing that integrating domain-specific retrieval mechanisms such as Multi-HyDE with robust toolsets, including keyword and table-based retrieval, significantly enhances both the accuracy and reliability of answers. This research not only delivers a modular, adaptable retrieval framework for finance but also highlights the importance of structured agent workflows and multi-perspective retrieval for trustworthy deployment of AI in high-stakes financial applications.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE)", "comments": "14 Pages, 8 Tables, 2 Figures. Accepted and to be published in the proceedings of FinNLP, Empirical Methods in Natural Language Processing 2025", "pdf_url": "https://arxiv.org/pdf/2509.16369.pdf", "abstract_url": "https://arxiv.org/abs/2509.16369", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)", "Computational Engineering, Finance, and Science (cs.CE)"], "matching_keywords": ["agent", "agentic", "@RAG"], "AI": {"tldr": "本文提出了一种结合Agentic AI和Multi-HyDE的金融RAG框架，通过多查询检索提升知识覆盖，在金融QA基准测试中准确率提高11.2%，幻觉减少15%。", "motivation": "解决金融问答中传统检索系统在动态数据源和复杂高风险场景下精度不足的问题。", "method": "使用Agentic AI和Multi-HyDE系统生成多个非等效查询，结合关键词和基于表格的检索，优化多步推理流程。", "result": "在标准金融QA基准上，准确率提升11.2%，幻觉减少15%。", "conclusion": "该方法为金融AI提供了模块化、可靠的检索框架，强调结构化工作流和多视角检索在高风险应用中的重要性。"}}
{"id": "2509.17459", "title": "PRINCIPLES: Synthetic Strategy Memory for Proactive Dialogue Agents", "authors": ["Namyoung Kim", "Kai Tzu-iunn Ong", "Yeonjun Hwang", "Minseok Kang", "Iiseo Jihn", "Gayoung Kim", "Minju Kim", "Jinyoung Yeo"], "abstract": "Dialogue agents based on large language models (LLMs) have shown promising performance in proactive dialogue, which requires effective strategy planning. However, existing approaches to strategy planning for proactive dialogue face several limitations: limited strategy coverage, preference bias in planning, and reliance on costly additional training. To address these, we propose PRINCIPLES: a synthetic strategy memory for proactive dialogue agents. PRINCIPLES is derived through offline self-play simulations and serves as reusable knowledge that guides strategy planning during inference, eliminating the need for additional training and data annotation. We evaluate PRINCIPLES in both emotional support and persuasion domains, demonstrating consistent improvements over strong baselines. Furthermore, PRINCIPLES maintains its robustness across extended and more diverse evaluation settings. See our project page at", "subjects": "Computation and Language (cs.CL)", "comments": "Accepted to EMNLP 2025 Findings", "pdf_url": "https://arxiv.org/pdf/2509.17459.pdf", "abstract_url": "https://arxiv.org/abs/2509.17459", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文提出了PRINCIPLES，一种基于离线自博弈模拟合成的策略记忆，用于增强主动对话代理的策略规划，无需额外训练，在情感支持和说服领域表现优异。", "motivation": "解决主动对话中现有策略规划方法的局限性，如策略覆盖不足、规划偏好偏差和依赖额外训练成本。", "method": "通过离线自博弈模拟合成策略记忆，作为可重用知识指导推理时的策略规划。", "result": "在情感支持和说服领域评估中，PRINCIPLES一致优于强基线，并在扩展和多样化设置中保持鲁棒性。", "conclusion": "PRINCIPLES提供了一种有效方法，提升主动对话代理的策略规划能力，具有实际应用潜力。"}}
{"id": "2509.17489", "title": "MapCoder-Lite: Squeezing Multi-Agent Coding into a Single Small LLM", "authors": ["Woongkyu Lee", "Junhee Cho", "Jungwook Choi"], "abstract": "Large language models (LLMs) have advanced code generation from single-function tasks to competitive-programming problems, but existing multi-agent solutions either rely on costly large-scale ($>$ 30B) models or collapse when downsized to small open-source models. We present MapCoder-Lite, which upgrades a single 7B model into four role-specialised agents-retriever, planner, coder, and debugger-using only rank-32, role-specific LoRA adapters ($<3\\%$ extra parameters). Three lightweight techniques make this possible: (i) trajectory distillation from strong LLMs fixes format fragility in retrieval and debugging, (ii) supervisor-guided correction strengthens planning and coding agents, and (iii) agent-wise LoRA fine-tuning delivers memory-efficient specialisation. Comprehensive evaluation on xCodeEval, APPS, and CodeContests shows that MapCoder-Lite more than doubles xCodeEval accuracy (from $13.2\\%$ to $28.3\\%$), eliminates all format failures, and closes to within six points of a 32B baseline while cutting GPU memory and token-generation time by $4\\times$. These results demonstrate that careful agent-wise fine-tuning unleashes high-quality multi-agent coding on a small language model.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.17489.pdf", "abstract_url": "https://arxiv.org/abs/2509.17489", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "MapCoder-Lite通过角色专用LoRA适配器将单个7B模型升级为四个代理，显著提升小模型在多代理代码生成中的性能。", "motivation": "解决现有多代理代码生成方案依赖大型模型或在小模型上失效的问题。", "method": "使用轨迹蒸馏、监督引导校正和代理专用LoRA微调等轻量技术。", "result": "在xCodeEval上准确率翻倍，消除格式失败，接近32B基线，同时减少GPU内存和生成时间。", "conclusion": "精细的代理专用微调可在小模型上实现高质量多代理编码。"}}
{"id": "2509.16454", "title": "A Generative AI System for Biomedical Data Discovery with Grammar-Based Visualizations", "authors": ["Devin Lange", "Shanghua Gao", "Pengwei Sui", "Austen Money", "Priya Misner", "Marinka Zitnik", "Nils Gehlenborg"], "abstract": "We explore the potential for combining generative AI with grammar-based visualizations for biomedical data discovery. In our prototype, we use a multi-agent system to generate visualization specifications and apply filters. These visualizations are linked together, resulting in an interactive dashboard that is progressively constructed. Our system leverages the strengths of natural language while maintaining the utility of traditional user interfaces. Furthermore, we utilize generated interactive widgets enabling user adjustment. Finally, we demonstrate the potential utility of this system for biomedical data discovery with a case study.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.16454.pdf", "abstract_url": "https://arxiv.org/abs/2509.16454", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种结合生成式AI和基于语法的可视化的系统，用于生物医学数据发现，通过多代理系统生成交互式仪表板。", "motivation": "解决生物医学数据发现中如何有效结合自然语言交互与传统用户界面的问题。", "method": "使用多代理系统生成可视化规范和过滤器，构建链接的交互式仪表板，并集成生成的小部件。", "result": "通过案例研究展示了该系统在生物医学数据发现中的潜在效用。", "conclusion": "该系统结合了生成式AI和可视化语法，提升了数据探索的交互性和效率。"}}
{"id": "2509.16437", "title": "SENSE-7: Taxonomy and Dataset for Measuring User Perceptions of Empathy in Sustained Human-AI Conversations", "authors": ["Jina Suh", "Lindy Le", "Erfan Shayegani", "Gonzalo Ramos", "Judith Amores", "Desmond C. Ong", "Mary Czerwinski", "Javier Hernandez"], "abstract": "Empathy is increasingly recognized as a key factor in human-AI communication, yet conventional approaches to \"digital empathy\" often focus on simulating internal, human-like emotional states while overlooking the inherently subjective, contextual, and relational facets of empathy as perceived by users. In this work, we propose a human-centered taxonomy that emphasizes observable empathic behaviors and introduce a new dataset, Sense-7, of real-world conversations between information workers and Large Language Models (LLMs), which includes per-turn empathy annotations directly from the users, along with user characteristics, and contextual details, offering a more user-grounded representation of empathy. Analysis of 695 conversations from 109 participants reveals that empathy judgments are highly individualized, context-sensitive, and vulnerable to disruption when conversational continuity fails or user expectations go unmet. To promote further research, we provide a subset of 672 anonymized conversation and provide exploratory classification analysis, showing that an LLM-based classifier can recognize 5 levels of empathy with an encouraging average Spearman $\\rho$=0.369 and Accuracy=0.487 over this set. Overall, our findings underscore the need for AI designs that dynamically tailor empathic behaviors to user contexts and goals, offering a roadmap for future research and practical development of socially attuned, human-centered artificial agents.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.16437.pdf", "abstract_url": "https://arxiv.org/abs/2509.16437", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文提出了一个以用户为中心的共情行为分类法，并引入了Sense-7数据集，基于真实对话分析用户对AI共情的感知，强调共情判断的个体化和情境依赖性。", "motivation": "解决传统数字共情方法忽视用户主观感知和情境因素的问题，旨在更准确地衡量人类与AI对话中的共情。", "method": "开发了基于可观察共情行为的分类法，创建了包含用户注释的Sense-7数据集，并进行了探索性分类分析，使用LLM分类器评估共情水平。", "result": "分析显示共情判断高度个体化和情境敏感，LLM分类器在5级共情分类中达到平均Spearman ρ=0.369和准确率0.487。", "conclusion": "AI设计需动态适应用户情境和目标，为开发以用户为中心的社会化AI提供了研究路线图。"}}
{"id": "2509.17628", "title": "MSCoRe: A Benchmark for Multi-Stage Collaborative Reasoning in LLM Agents", "authors": ["Yuzhen Lei", "Hongbin Xie", "Jiaxing Zhao", "Shuangxue Liu", "Xuan Song"], "abstract": "Large Language Models (LLMs) have excelled in question-answering (QA) tasks within single domains. However, their reasoning and coordination capabilities in complex, multi-stage scenarios remain underexplored. Existing benchmarks typically focus on isolated tasks or narrow domains, overlooking models' abilities for multi-stage collaboration and optimization without explicit external guidance. To bridge this gap, we propose \\textbf{MSCoRe}, a novel benchmark comprising 126696 domain-specific QA instances spanning scenarios in automotive, pharmaceutical, electronics, and energy sectors. The dataset is created using a structured three-phase pipeline: dynamic sampling, iterative question-answer generation, and a multi-level quality assessment to ensure data quality. Tasks are further categorized into three difficulty levels according to stage coverage and complexity. With MSCoRe, we have conducted a comprehensive evaluation of various state-of-the-art LLM agents. The commercial models performed best across all tasks and scenarios, but a notable gap in ROUGE scores remains between simple and complex tasks. We also tested the models' robustness and found that their performance is negatively affected by noisy data. MSCoRe provides a valuable new resource for the community to evaluate and improve multi-stage reasoning in LLM agents. The code and data are available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "10 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2509.17628.pdf", "abstract_url": "https://arxiv.org/abs/2509.17628", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文提出了MSCoRe基准，用于评估大型语言模型在多阶段协作推理中的能力，包含126,696个领域特定QA实例，并评估了多种模型，发现商业模型表现最佳但复杂任务仍有差距。", "motivation": "解决现有基准在评估LLM多阶段协作和优化能力方面的不足，特别是在复杂、多领域场景中。", "method": "通过动态采样、迭代问答生成和多级质量评估的三阶段管道创建基准数据集，并分类任务难度以进行模型评估。", "result": "商业模型在所有任务中表现最好，但简单与复杂任务间的ROUGE分数差距显著，且模型性能受噪声数据负面影响。", "conclusion": "MSCoRe为社区提供了评估和改进LLM多阶段推理能力的新资源，强调了当前模型的局限性。"}}
{"id": "2509.17766", "title": "A State-Update Prompting Strategy for Efficient and Robust Multi-turn Dialogue", "authors": ["Ziyi Liu"], "abstract": "Large Language Models (LLMs) struggle with information forgetting and inefficiency in long-horizon, multi-turn dialogues. To address this, we propose a training-free prompt engineering method, the State-Update Multi-turn Dialogue Strategy. It utilizes \"State Reconstruction\" and \"History Remind\" mechanisms to effectively manage dialogue history. Our strategy shows strong performance across multiple multi-hop QA datasets. For instance, on the HotpotQA dataset, it improves the core information filtering score by 32.6%, leading to a 14.1% increase in the downstream QA score, while also reducing inference time by 73.1% and token consumption by 59.4%. Ablation studies confirm the pivotal roles of both components. Our work offers an effective solution for optimizing LLMs in long-range interactions, providing new insights for developing more robust Agents.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.17766.pdf", "abstract_url": "https://arxiv.org/abs/2509.17766", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "提出一种无需训练的状态更新提示策略，通过状态重构和历史提醒机制，有效提升大型语言模型在多轮对话中的效率和鲁棒性。", "motivation": "解决大型语言模型在多轮长对话中信息遗忘和效率低下的问题。", "method": "使用状态重构和历史提醒机制的提示工程方法，无需额外训练。", "result": "在HotpotQA数据集上，核心信息过滤得分提高32.6%，下游QA得分提升14.1%，推理时间减少73.1%，令牌消耗降低59.4%。", "conclusion": "该方法为优化LLM在长程交互中提供了有效解决方案，对开发更鲁棒的代理具有新见解。"}}
{"id": "2509.17671", "title": "Turk-LettuceDetect: A Hallucination Detection Models for Turkish RAG Applications", "authors": ["Selva Taş", "Mahmut El Huseyni", "Özay Ezerceli", "Reyhan Bayraktar", "Fatma Betül Terzioğlu"], "abstract": "The widespread adoption of Large Language Models (LLMs) has been hindered by their tendency to hallucinate, generating plausible but factually incorrect information. While Retrieval-Augmented Generation (RAG) systems attempt to address this issue by grounding responses in external knowledge, hallucination remains a persistent challenge, particularly for morphologically complex, low-resource languages like Turkish. This paper introduces Turk-LettuceDetect, the first suite of hallucination detection models specifically designed for Turkish RAG applications. Building on the LettuceDetect framework, we formulate hallucination detection as a token-level classification task and fine-tune three distinct encoder architectures: a Turkish-specific ModernBERT, TurkEmbed4STS, and multilingual EuroBERT. These models were trained on a machine-translated version of the RAGTruth benchmark dataset containing 17,790 instances across question answering, data-to-text generation, and summarization tasks. Our experimental results show that the ModernBERT-based model achieves an F1-score of 0.7266 on the complete test set, with particularly strong performance on structured tasks. The models maintain computational efficiency while supporting long contexts up to 8,192 tokens, making them suitable for real-time deployment. Comparative analysis reveals that while state-of-the-art LLMs demonstrate high recall, they suffer from low precision due to over-generation of hallucinated content, underscoring the necessity of specialized detection mechanisms. By releasing our models and translated dataset, this work addresses a critical gap in multilingual NLP and establishes a foundation for developing more reliable and trustworthy AI applications for Turkish and other languages.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.17671.pdf", "abstract_url": "https://arxiv.org/abs/2509.17671", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了Turk-LettuceDetect，首个针对土耳其语RAG应用的幻觉检测模型套件，基于LettuceDetect框架，通过微调三种编码器架构，在机器翻译数据集上训练，实现高效检测，填补了多语言NLP的空白。", "motivation": "解决大型语言模型在生成内容时产生幻觉的问题，特别是在形态复杂、资源匮乏的语言如土耳其语中，RAG系统仍面临幻觉挑战，需要专门的检测机制。", "method": "将幻觉检测建模为令牌级分类任务，微调土耳其语特定的ModernBERT、TurkEmbed4STS和多语言EuroBERT模型，使用机器翻译的RAGTruth基准数据集进行训练。", "result": "ModernBERT模型在完整测试集上F1分数达0.7266，在结构化任务中表现优异，模型计算高效，支持长上下文，而现有LLM召回率高但精度低。", "conclusion": "该工作通过发布模型和数据集，为土耳其语及其他语言开发更可靠的AI应用奠定了基础，强调了专门检测机制的必要性。"}}
{"id": "2509.17788", "title": "One Agent to Serve All: a Lite-Adaptive Stylized AI Assistant for Millions of Multi-Style Official Accounts", "authors": ["Xingyu Fan", "Feifei Li", "Wenhui Que", "Hailong Li"], "abstract": "Conversational agents deployed in industrial-scale official account platforms must generate responses that are both contextually grounded and stylistically aligned-requirements that existing methods struggle to meet. Chain-of-thought (CoT) prompting induces significant latency due to multi-turn reasoning; per-account fine-tuning is computationally prohibitive; and long prompt-based methods degrade the model's ability to grasp injected context and style. In this paper, we propose WeStar, a lite-adaptive framework for stylized contextual question answering that scales to millions of official accounts. WeStar combines context-grounded generation via RAG with style-aware generation using Parametric RAG (PRAG), where LoRA modules are dynamically activated per style cluster. Our contributions are fourfold: (1) We introduce WeStar, a unified framework capable of serving large volumes of official accounts with minimal overhead. (2) We propose a multi-dimensional, cluster-based parameter sharing scheme that enables compact style representation while preserving stylistic diversity. (3) We develop a style-enhanced Direct Preference Optimization (SeDPO) method to optimize each style cluster's parameters for improved generation quality. (4) Experiments on a large-scale industrial dataset validate the effectiveness and efficiency of WeStar, underscoring its pracitical value in real-world deployment.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "7 pages", "pdf_url": "https://arxiv.org/pdf/2509.17788.pdf", "abstract_url": "https://arxiv.org/abs/2509.17788", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文提出WeStar，一种轻量自适应框架，用于为大量官方账号生成上下文相关且风格一致的响应，结合RAG和参数化RAG，通过聚类和优化方法实现高效扩展。", "motivation": "现有方法（如CoT提示、微调或长提示）在工业级官方账号平台上存在延迟高、计算成本大或上下文理解差的问题，难以满足大规模多风格需求。", "method": "WeStar框架结合基于检索的增强生成（RAG）和参数化RAG，使用LoRA模块动态激活每个风格聚类，并引入多维聚类参数共享和风格增强直接偏好优化（SeDPO）方法。", "result": "在大规模工业数据集上的实验验证了WeStar的有效性和效率，表明其在实际部署中具有高实用价值。", "conclusion": "WeStar提供了一种统一、轻量的解决方案，能够以最小开销服务数百万官方账号，解决了现有方法的局限性，具有重要实际意义。"}}
{"id": "2509.16676", "title": "Governed By Agents: A Survey On The Role Of Agentic AI In Future Computing Environments", "authors": ["Nauman Ali Murad", "Safia Baloch"], "abstract": "The emergence of agentic Artificial Intelligence (AI), which can operate autonomously, demonstrate goal-directed behavior, and adaptively learn, indicates the onset of a massive change in today's computing infrastructure. This study investigates how agentic AI models' multiple characteristics may impact the architecture, governance, and operation under which computing environments function. Agentic AI has the potential to reduce reliance on extremely large (public) cloud environments due to resource efficiency, especially with processing and/or storage. The aforementioned characteristics provide us with an opportunity to canvas the likelihood of strategic migration in computing infrastructures away from massive public cloud services, towards more locally distributed architectures: edge computing and on-premises computing infrastructures. Many of these likely migrations will be spurred by factors like on-premises processing needs, diminished data consumption footprints, and cost savings. This study examines how a solution for implementing AI's autonomy could result in a re-architecture of the systems and model a departure from today's governance models to help us manage these increasingly autonomous agents, and an operational overhaul of processes over a very diverse computing systems landscape that bring together computing via cloud, edge, and on-premises computing solutions. To enable us to explore these intertwined decisions, it will be fundamentally important to understand how to best position agentic AI, and to navigate the future state of computing infrastructures.", "subjects": "Emerging Technologies (cs.ET); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.16676.pdf", "abstract_url": "https://arxiv.org/abs/2509.16676", "categories": ["Emerging Technologies (cs.ET)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "该论文调查了代理性AI在未来计算环境中的作用，探讨了其如何通过自主性、资源效率和成本节约推动计算架构从公共云向边缘和本地计算迁移，并强调了对治理和操作模型重新设计的必要性。", "motivation": "解决代理性AI的兴起如何影响计算基础设施的架构、治理和操作，以应对从大规模公共云服务向分布式计算迁移的潜在挑战。", "method": "采用调查研究方法，分析代理性AI的特性及其对计算环境的影响，包括资源效率、成本因素和架构迁移的可能性。", "result": "代理性AI可能减少对公共云的依赖，促进向边缘和本地计算的战略迁移，带来处理需求、数据足迹减少和成本节约等益处。", "conclusion": "代理性AI将重塑计算基础设施，需要新的治理模型和操作流程来管理自主代理，未来计算环境将整合云、边缘和本地解决方案。"}}
{"id": "2509.18052", "title": "The PIMMUR Principles: Ensuring Validity in Collective Behavior of LLM Societies", "authors": ["Jiaxu Zhou", "Jen-tse Huang", "Xuhui Zhou", "Man Ho Lam", "Xintao Wang", "Hao Zhu", "Wenxuan Wang", "Maarten Sap"], "abstract": "Large Language Models (LLMs) are increasingly used for social simulation, where populations of agents are expected to reproduce human-like collective behavior. However, we find that many recent studies adopt experimental designs that systematically undermine the validity of their claims. From a survey of over 40 papers, we identify six recurring methodological flaws: agents are often homogeneous (Profile), interactions are absent or artificially imposed (Interaction), memory is discarded (Memory), prompts tightly control outcomes (Minimal-Control), agents can infer the experimental hypothesis (Unawareness), and validation relies on simplified theoretical models rather than real-world data (Realism). For instance, GPT-4o and Qwen-3 correctly infer the underlying social experiment in 53.1% of cases when given instructions from prior work-violating the Unawareness principle. We formalize these six requirements as the PIMMUR principles and argue they are necessary conditions for credible LLM-based social simulation. To demonstrate their impact, we re-run five representative studies using a framework that enforces PIMMUR and find that the reported social phenomena frequently fail to emerge under more rigorous conditions. Our work establishes methodological standards for LLM-based multi-agent research and provides a foundation for more reliable and reproducible claims about \"AI societies.\"", "subjects": "Computation and Language (cs.CL); Computers and Society (cs.CY)", "comments": "Preprint", "pdf_url": "https://arxiv.org/pdf/2509.18052.pdf", "abstract_url": "https://arxiv.org/abs/2509.18052", "categories": ["Computation and Language (cs.CL)", "Computers and Society (cs.CY)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了PIMMUR原则，作为确保基于LLM的社会模拟有效性的方法论标准，通过重新运行研究展示了其影响。", "motivation": "解决LLM社会模拟中实验设计存在的系统性方法缺陷，以提高研究的可信度和可重复性。", "method": "通过对40多篇论文的调查，识别并形式化六个常见方法缺陷为PIMMUR原则，并使用强制执行这些原则的框架重新运行代表性研究。", "result": "在更严格条件下，许多报告的社会现象未能出现，例如GPT-4o和Qwen-3在53.1%的情况下能推断出实验假设。", "conclusion": "PIMMUR原则是可信LLM社会模拟的必要条件，为多智能体研究建立了方法论基础。"}}
{"id": "2509.17757", "title": "Multi-Agent Amodal Completion: Direct Synthesis with Fine-Grained Semantic Guidance", "authors": ["Hongxing Fan", "Lipeng Wang", "Haohua Chen", "Zehuan Huang", "Jiangtao Wu", "Lu Sheng"], "abstract": "Amodal completion, generating invisible parts of occluded objects, is vital for applications like image editing and AR. Prior methods face challenges with data needs, generalization, or error accumulation in progressive pipelines. We propose a Collaborative Multi-Agent Reasoning Framework based on upfront collaborative reasoning to overcome these issues. Our framework uses multiple agents to collaboratively analyze occlusion relationships and determine necessary boundary expansion, yielding a precise mask for inpainting. Concurrently, an agent generates fine-grained textual descriptions, enabling Fine-Grained Semantic Guidance. This ensures accurate object synthesis and prevents the regeneration of occluders or other unwanted elements, especially within large inpainting areas. Furthermore, our method directly produces layered RGBA outputs guided by visible masks and attention maps from a Diffusion Transformer, eliminating extra segmentation. Extensive evaluations demonstrate our framework achieves state-of-the-art visual quality.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.17757.pdf", "abstract_url": "https://arxiv.org/abs/2509.17757", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于多智能体协作推理的框架，用于图像编辑和AR中的amodal补全，通过直接合成和细粒度语义指导提高视觉质量。", "motivation": "解决现有amodal补全方法在数据需求、泛化能力或渐进式流程中误差累积方面的挑战。", "method": "使用多智能体协作分析遮挡关系并生成精确掩码，结合细粒度文本描述和Diffusion Transformer指导，直接输出分层RGBA结果。", "result": "广泛评估表明，该框架在视觉质量上达到了最先进水平。", "conclusion": "该方法通过直接合成和语义指导，有效避免了不必要元素的再生，提升了amodal补全的准确性和效率。"}}
{"id": "2509.16780", "title": "Comparing RAG and GraphRAG for Page-Level Retrieval Question Answering on Math Textbook", "authors": ["Eason Chen", "Chuangji Li", "Shizhuo Li", "Conrad Borchers", "Zimo Xiao", "Chloe Qianhui Zhao", "Jionghao Lin", "Kenneth R. Koedinger"], "abstract": "Technology-enhanced learning environments often help students retrieve relevant learning content for questions arising during self-paced study. Large language models (LLMs) have emerged as novel aids for information retrieval during learning. While LLMs are effective for general-purpose question-answering, they typically lack alignment with the domain knowledge of specific course materials such as textbooks and slides. We investigate Retrieval-Augmented Generation (RAG) and GraphRAG, a knowledge graph-enhanced RAG approach, for page-level question answering in an undergraduate mathematics textbook. While RAG has been effective for retrieving discrete, contextually relevant passages, GraphRAG may excel in modeling interconnected concepts and hierarchical knowledge structures. We curate a dataset of 477 question-answer pairs, each tied to a distinct textbook page. We then compare the standard embedding-based RAG methods to GraphRAG for evaluating both retrieval accuracy-whether the correct page is retrieved-and generated answer quality via F1 scores. Our findings show that embedding-based RAG achieves higher retrieval accuracy and better F1 scores compared to GraphRAG, which tends to retrieve excessive and sometimes irrelevant content due to its entity-based structure. We also explored re-ranking the retrieved pages with LLM and observed mixed results, including performance drop and hallucinations when dealing with larger context windows. Overall, this study highlights both the promises and challenges of page-level retrieval systems in educational contexts, emphasizing the need for more refined retrieval methods to build reliable AI tutoring solutions in providing reference page numbers.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.16780.pdf", "abstract_url": "https://arxiv.org/abs/2509.16780", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本研究比较了RAG和GraphRAG在数学教科书页级检索问答中的表现，发现基于嵌入的RAG在检索准确性和答案质量上优于GraphRAG，后者因实体结构易检索过多无关内容。", "motivation": "解决大型语言模型在特定教育材料（如教科书）中知识对齐不足的问题，以提升自定进度学习中的信息检索效果。", "method": "使用477个问答对数据集，比较标准嵌入RAG与GraphRAG的检索准确性和生成答案质量，并探索LLM重排方法。", "result": "嵌入RAG在检索准确率和F1分数上表现更好；GraphRAG检索内容过多且不相关；LLM重排导致性能下降和幻觉。", "conclusion": "页级检索系统在教育中有潜力，但需改进检索方法以构建可靠的AI辅导解决方案。"}}
{"id": "2509.18063", "title": "ARK-V1: An LLM-Agent for Knowledge Graph Question Answering Requiring Commonsense Reasoning", "authors": ["Jan-Felix Klein", "Lars Ohnemus"], "abstract": "Large Language Models (LLMs) show strong reasoning abilities but rely on internalized knowledge that is often insufficient, outdated, or incorrect when trying to answer a question that requires specific domain knowledge. Knowledge Graphs (KGs) provide structured external knowledge, yet their complexity and multi-hop reasoning requirements make integration challenging. We present ARK-V1, a simple KG-agent that iteratively explores graphs to answer natural language queries. We evaluate several not fine-tuned state-of-the art LLMs as backbones for ARK-V1 on the CoLoTa dataset, which requires both KG-based and commonsense reasoning over long-tail entities. ARK-V1 achieves substantially higher conditional accuracies than Chain-of-Thought baselines, and larger backbone models show a clear trend toward better coverage, correctness, and stability.", "subjects": "Computation and Language (cs.CL)", "comments": "Work in Progess", "pdf_url": "https://arxiv.org/pdf/2509.18063.pdf", "abstract_url": "https://arxiv.org/abs/2509.18063", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了ARK-V1，一种基于LLM的智能体，用于通过迭代探索知识图谱回答需要常识推理的自然语言问题，在CoLoTa数据集上优于基线方法。", "motivation": "解决LLMs在处理需要特定领域知识和常识推理的问题时，因内部知识不足、过时或不准确而导致的局限性，通过集成结构化外部知识图谱来提升性能。", "method": "使用未微调的先进LLMs作为骨干，构建ARK-V1智能体，通过迭代探索知识图谱来回答查询，并在CoLoTa数据集上进行评估。", "result": "ARK-V1在条件准确率上显著高于Chain-of-Thought基线，且更大的骨干模型在覆盖率、正确性和稳定性方面表现出明显改善趋势。", "conclusion": "ARK-V1有效结合LLMs和知识图谱，提升了复杂推理任务的性能，表明外部知识集成对增强LLM能力的重要性。"}}
{"id": "2509.16941", "title": "SWE-Bench Pro: Can AI Agents Solve Long-Horizon Software Engineering Tasks?", "authors": ["Xiang Deng", "Jeff Da", "Edwin Pan", "Yannis Yiming He", "Charles Ide", "Kanak Garg", "Niklas Lauffer", "Andrew Park", "Nitin Pasari", "Chetan Rane", "Karmini Sampath", "Maya Krishnan", "Srivatsa Kundurthy", "Sean Hendryx", "Zifan Wang", "Chen Bo Calvin Zhang", "Noah Jacobson", "Bing Liu", "Brad Kenstler"], "abstract": "We introduce SWE-Bench Pro, a substantially more challenging benchmark that builds upon the best practices of SWE-BENCH [25], but is explicitly designed to capture realistic, complex, enterprise-level problems beyond the scope of SWE-BENCH. SWE-BENCH PRO contains 1,865 problems sourced from a diverse set of 41 actively maintained repositories spanning business applications, B2B services, and developer tools. The benchmark is partitioned into a public set with open access to problems sourced from 11 repositories, a held-out set of 12 repositories and a commercial set of 18 proprietary repositories where we have formal partnership agreements with early-stage startups. Problems in the held-out and the commercial set are not publicly accessible, but we release results on the commercial set. Our benchmark features long-horizon tasks that may require hours to days for a professional software engineer to complete, often involving patches across multiple files and substantial code modifications. All tasks are human-verified and augmented with sufficient context to ensure resolvability. In our evaluation of widely used coding models, under a unified scaffold, we observe that their performance on SWE-Bench PRO remains below 25% (Pass@1), with GPT-5 achieving the highest score to date at 23.3%. To better understand these limitations, we cluster the failure modes observed in the collected agent trajectories for a clearer characterization of the error patterns exhibited by current models. Overall, SWE-BENCH PRO provides a contamination-resistant testbed that more faithfully captures the complexity and diversity of real-world software development, advancing the pursuit of truly autonomous software engineering agents at a professional level.", "subjects": "Software Engineering (cs.SE); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.16941.pdf", "abstract_url": "https://arxiv.org/abs/2509.16941", "categories": ["Software Engineering (cs.SE)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "SWE-Bench Pro是一个更难的基准测试，基于SWE-BENCH，包含1865个企业级软件工程问题，评估AI代理性能，当前模型如GPT-5准确率低于25%。", "motivation": "解决现有基准如SWE-BENCH无法充分捕捉现实、复杂、长期软件工程任务的问题，以推动真正自主软件工程代理的发展。", "method": "构建包含1865个问题的基准，源自41个活跃仓库，分区为公开、保留和商业集，使用统一框架评估编码模型，并聚类分析失败模式。", "result": "广泛使用的编码模型在SWE-Bench Pro上性能低于25%，GPT-5最高为23.3%，揭示了当前模型在处理长期任务时的局限。", "conclusion": "SWE-Bench Pro提供了一个抗污染、更真实的测试平台，突显了AI在专业软件工程中的挑战，需进一步改进模型能力。"}}
{"id": "2509.18041", "title": "NeuS-QA: Grounding Long-Form Video Understanding in Temporal Logic and Neuro-Symbolic Reasoning", "authors": ["Sahil Shah", "S P Sharan", "Harsh Goel", "Minkyu Choi", "Mustafa Munir", "Manvik Pasula", "Radu Marculescu", "Sandeep Chinchali"], "abstract": "Long-Form Video Question Answering (LVQA) poses challenges beyond traditional visual question answering (VQA), which is often limited to static images or short video clips. While current vision-language models (VLMs) perform well in those settings, they struggle with complex queries in LVQA over long videos involving multi-step temporal reasoning and causality. Vanilla approaches, which sample frames uniformly and feed them to a VLM with the question, incur significant token overhead, forcing severe downsampling. As a result, the model often misses fine-grained visual structure, subtle event transitions, or key temporal cues, ultimately leading to incorrect answers. To address these limitations, recent works have explored query-adaptive frame sampling, hierarchical keyframe selection, and agent-based iterative querying. However, these methods remain fundamentally heuristic: they lack explicit temporal representations and cannot enforce or verify logical event relationships. As a result, there are no formal guarantees that the sampled context actually encodes the compositional or causal logic demanded by the question. To address these foundational gaps, we introduce NeuS-QA, a training-free, plug-and-play neuro-symbolic pipeline for LVQA. NeuS-QA translates a natural language question into a formal temporal logic expression, constructs a video automaton from frame-level semantic propositions, and applies model checking to rigorously identify video segments satisfying the question's logical requirements. Only these logic-verified segments are submitted to the VLM, thus improving interpretability, reducing hallucinations, and enabling compositional reasoning without modifying or fine-tuning the model. Experiments on LongVideoBench and CinePile show NeuS-QA improves performance by over 10%, especially on questions involving event ordering, causality, and multi-step compositional reasoning.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.18041.pdf", "abstract_url": "https://arxiv.org/abs/2509.18041", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出NeuS-QA，一种免训练的神经符号推理方法，用于长视频问答，通过将问题转换为时序逻辑表达式并验证视频片段，提高准确性和可解释性。", "motivation": "解决长视频问答中现有方法因启发式采样缺乏时序逻辑表示，导致无法处理复杂查询如多步推理和因果关系的问题。", "method": "使用神经符号管道，将自然语言问题翻译为时序逻辑表达式，构建视频自动机并进行模型检查，仅提交逻辑验证片段给视觉语言模型。", "result": "在LongVideoBench和CinePile数据集上，性能提升超过10%，尤其在事件排序、因果关系和多步推理问题上表现突出。", "conclusion": "NeuS-QA通过形式化逻辑推理增强长视频理解，减少幻觉，无需模型微调，为复杂视频推理提供可解释的解决方案。"}}
{"id": "2509.17325", "title": "Generalizable End-to-End Tool-Use RL with Synthetic CodeGym", "authors": ["Weihua Du", "Hailei Gong", "Zhan Ling", "Kang Liu", "Lingfeng Shen", "Xuesong Yao", "Yufei Xu", "Dingyuan Shi", "Yiming Yang", "Jiecao Chen"], "abstract": "Tool-augmented large language models (LLMs), hereafter LLM agents, leverage external tools to solve diverse tasks and interface with the real world. However, current training practices largely rely on supervised fine-tuning (SFT) over static trajectories or reinforcement learning (RL) on narrow tasks, and generalize poorly beyond development settings, leading to brittleness with new tools and unseen workflows. Because code execution reflects many structures of real-world workflows, coding problems provide a natural basis for building agent training environments. Motivated by this, we introduce CodeGym, a scalable framework that synthesizes diverse, verifiable, and controllable multi-turn tool-use environments for agent RL, enabling LLM agents to explore and master various workflows actively. CodeGym rewrites static coding problems into interactive environments by extracting atomic functions or logic into callable tools, yielding verifiable tasks that span various tool-execution workflows. Models of varying sizes and chain-of-thought configurations, trained in CodeGym, exhibit consistent out-of-distribution generalizability; for example, Qwen2.5-32B-Instruct achieves an absolute accuracy gain of 8.7 points on the OOD benchmark $\\tau$-Bench. These results highlight CodeGym as a step toward scalable general-purpose RL environments that align with real-world agent workflows.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2509.17325.pdf", "abstract_url": "https://arxiv.org/abs/2509.17325", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了CodeGym框架，通过合成可验证的多轮工具使用环境，用于增强LLM代理的强化学习训练，以提高其在未见工具和工作流上的泛化能力。", "motivation": "当前LLM代理训练方法依赖监督微调或窄任务强化学习，泛化性差，无法适应新工具和未知工作流，需要更可扩展的训练环境。", "method": "开发CodeGym框架，将静态编码问题转化为交互式环境，提取原子函数作为可调用工具，创建多样、可控的任务用于代理强化学习。", "result": "在不同规模和配置的模型上，CodeGym训练显著提升泛化性能，如Qwen2.5-32B-Instruct在OOD基准上准确率提高8.7个百分点。", "conclusion": "CodeGym是迈向可扩展通用强化学习环境的重要一步，能更好地对齐现实世界代理工作流。"}}
{"id": "2509.17336", "title": "Mano Report", "authors": ["Tianyu Fu", "Anyang Su", "Chenxu Zhao", "Hanning Wang", "Minghui Wu", "Zhe Yu", "Fei Hu", "Mingjia Shi", "Wei Dong", "Jiayao Wang", "Yuyang Chen", "Ruiyang Yu", "Siran Peng", "Menglin Li", "Nan Huang", "Haitian Wei", "Jiawei Yu", "Yi Xin", "Xilin Zhao", "Kai Gu", "Ping Jiang", "Sifan Zhou", "Shuo Wang"], "abstract": "Graphical user interfaces (GUIs) are the primary medium for human-computer interaction, yet automating GUI interactions remains challenging due to the complexity of visual elements, dynamic environments, and the need for multi-step reasoning. Existing methods based on vision-language models (VLMs) often suffer from limited resolution, domain mismatch, and insufficient sequential decisionmaking capability. To address these issues, we propose Mano, a robust GUI agent built upon a multi-modal foundation model pre-trained on extensive web and computer system data. Our approach integrates a novel simulated environment for high-fidelity data generation, a three-stage training pipeline (supervised fine-tuning, offline reinforcement learning, and online reinforcement learning), and a verification module for error recovery. Mano demonstrates state-of-the-art performance on multiple GUI benchmarks, including Mind2Web and OSWorld, achieving significant improvements in success rate and operational accuracy. Our work provides new insights into the effective integration of reinforcement learning with VLMs for practical GUI agent deployment, highlighting the importance of domain-specific data, iterative training, and holistic reward design.", "subjects": "Multimedia (cs.MM); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.17336.pdf", "abstract_url": "https://arxiv.org/abs/2509.17336", "categories": ["Multimedia (cs.MM)", "Computation and Language (cs.CL)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了Mano，一种基于多模态基础模型的鲁棒GUI代理，通过模拟环境生成数据、三阶段训练流程和验证模块，在多个基准测试中实现了最先进的性能。", "motivation": "解决GUI自动化交互中的挑战，如视觉元素复杂性、动态环境和多步推理需求，现有VLM方法存在分辨率限制、领域不匹配和顺序决策能力不足的问题。", "method": "使用预训练的多模态基础模型，结合高保真模拟环境生成数据，采用监督微调、离线强化学习和在线强化学习的三阶段训练流程，并集成验证模块进行错误恢复。", "result": "在Mind2Web和OSWorld等GUI基准测试中，Mano实现了状态的最先进性能，显著提高了成功率和操作准确性。", "conclusion": "工作强调了领域特定数据、迭代训练和整体奖励设计的重要性，为强化学习与VLM的有效集成提供了新见解，推动实用GUI代理的部署。"}}
{"id": "2509.16554", "title": "ViTCAE: ViT-based Class-conditioned Autoencoder", "authors": ["Vahid Jebraeeli", "Hamid Krim", "Derya Cansever"], "abstract": "Vision Transformer (ViT) based autoencoders often underutilize the global Class token and employ static attention mechanisms, limiting both generative control and optimization efficiency. This paper introduces ViTCAE, a framework that addresses these issues by re-purposing the Class token into a generative linchpin. In our architecture, the encoder maps the Class token to a global latent variable that dictates the prior distribution for local, patch-level latent variables, establishing a robust dependency where global semantics directly inform the synthesis of local details. Drawing inspiration from opinion dynamics, we treat each attention head as a dynamical system of interacting tokens seeking consensus. This perspective motivates a convergence-aware temperature scheduler that adaptively anneals each head's influence function based on its distributional stability. This process enables a principled head-freezing mechanism, guided by theoretically-grounded diagnostics like an attention evolution distance and a consensus/cluster functional. This technique prunes converged heads during training to significantly improve computational efficiency without sacrificing fidelity. By unifying a generative Class token with an adaptive attention mechanism rooted in multi-agent consensus theory, ViTCAE offers a more efficient and controllable approach to transformer-based generation.", "subjects": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV)", "comments": "-", "pdf_url": "https://arxiv.org/pdf/2509.16554.pdf", "abstract_url": "https://arxiv.org/abs/2509.16554", "categories": ["Machine Learning (cs.LG)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "ViTCAE 是一种基于 Vision Transformer 的类条件自编码器，通过将 Class token 转化为生成核心，并引入基于共识理论的自适应注意力机制，提高了生成控制性和计算效率。", "motivation": "解决 Vision Transformer 自编码器中 Class token 未充分利用和静态注意力机制导致的生成控制不足和优化效率低下的问题。", "method": "使用 Class token 作为全局潜变量指导局部潜变量，并基于意见动力学设计收敛感知的温度调度器，实现注意力头的自适应剪枝。", "result": "显著提升了计算效率而不损失保真度，实现了更高效和可控的基于 Transformer 的生成。", "conclusion": "ViTCAE 通过结合生成性 Class token 和自适应注意力机制，为 Transformer 生成提供了更优的方法。"}}
{"id": "2509.17197", "title": "SignalLLM: A General-Purpose LLM Agent Framework for Automated Signal Processing", "authors": ["Junlong Ke", "Qiying Hu", "Shenghai Yuan", "Yuecong Xu", "Jianfei Yang"], "abstract": "Modern signal processing (SP) pipelines, whether model-based or data-driven, often constrained by complex and fragmented workflow, rely heavily on expert knowledge and manual engineering, and struggle with adaptability and generalization under limited data. In contrast, Large Language Models (LLMs) offer strong reasoning capabilities, broad general-purpose knowledge, in-context learning, and cross-modal transfer abilities, positioning them as powerful tools for automating and generalizing SP workflows. Motivated by these potentials, we introduce SignalLLM, the first general-purpose LLM-based agent framework for general SP tasks. Unlike prior LLM-based SP approaches that are limited to narrow applications or tricky prompting, SignalLLM introduces a principled, modular architecture. It decomposes high-level SP goals into structured subtasks via in-context learning and domain-specific retrieval, followed by hierarchical planning through adaptive retrieval-augmented generation (RAG) and refinement; these subtasks are then executed through prompt-based reasoning, cross-modal reasoning, code synthesis, model invocation, or data-driven LLM-assisted modeling. Its generalizable design enables the flexible selection of problem solving strategies across different signal modalities, task types, and data conditions. We demonstrate the versatility and effectiveness of SignalLLM through five representative tasks in communication and sensing, such as radar target detection, human activity recognition, and text compression. Experimental results show superior performance over traditional and existing LLM-based methods, particularly in few-shot and zero-shot settings.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Signal Processing (eess.SP)", "comments": "11 pages", "pdf_url": "https://arxiv.org/pdf/2509.17197.pdf", "abstract_url": "https://arxiv.org/abs/2509.17197", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Signal Processing (eess.SP)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "SignalLLM是一个基于大型语言模型的通用代理框架，用于自动化信号处理任务，通过模块化架构分解目标并执行，在通信和感知任务中表现出色。", "motivation": "解决信号处理流程复杂、依赖专家知识、适应性差和数据不足的问题，利用LLM的推理能力和泛化潜力实现自动化。", "method": "采用模块化架构，通过上下文学习和领域检索分解任务，使用自适应RAG进行分层规划，并通过提示推理、代码合成等方式执行。", "result": "在雷达目标检测等五个任务中，SignalLLM在少样本和零样本设置下优于传统和现有LLM方法。", "conclusion": "SignalLLM框架展示了LLM在信号处理中的通用性和有效性，为自动化提供了新途径。"}}
{"id": "2509.17255", "title": "Agentic AI for Multi-Stage Physics Experiments at a Large-Scale User Facility Particle Accelerator", "authors": ["Thorsten Hellert", "Drew Bertwistle", "Simon C. Leemann", "Antonin Sulc", "Marco Venturini"], "abstract": "We present the first language-model-driven agentic artificial intelligence (AI) system to autonomously execute multi-stage physics experiments on a production synchrotron light source. Implemented at the Advanced Light Source particle accelerator, the system translates natural language user prompts into structured execution plans that combine archive data retrieval, control-system channel resolution, automated script generation, controlled machine interaction, and analysis. In a representative machine physics task, we show that preparation time was reduced by two orders of magnitude relative to manual scripting even for a system expert, while operator-standard safety constraints were strictly upheld. Core architectural features, plan-first orchestration, bounded tool access, and dynamic capability selection, enable transparent, auditable execution with fully reproducible artifacts. These results establish a blueprint for the safe integration of agentic AI into accelerator experiments and demanding machine physics studies, as well as routine operations, with direct portability across accelerators worldwide and, more broadly, to other large-scale scientific infrastructures.", "subjects": "Accelerator Physics (physics.acc-ph); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.17255.pdf", "abstract_url": "https://arxiv.org/abs/2509.17255", "categories": ["Accelerator Physics (physics.acc-ph)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了首个基于语言模型的代理AI系统，用于在粒子加速器上自主执行多阶段物理实验，显著减少准备时间并确保安全。", "motivation": "解决在大型科学设施中手动执行实验时准备时间长、效率低的问题，以实现自动化、安全且可复现的实验操作。", "method": "使用语言模型将自然语言提示转换为结构化执行计划，结合数据检索、控制系统交互、脚本生成和动态能力选择等方法。", "result": "在代表性任务中，准备时间比手动脚本减少两个数量级，同时严格遵守安全约束，实现了透明、可审计的执行。", "conclusion": "该系统为代理AI在加速器实验和科学基础设施中的安全集成提供了蓝图，具有广泛的适用性。"}}
{"id": "2509.18008", "title": "Through the Lens of Human-Human Collaboration: A Configurable Research Platform for Exploring Human-Agent Collaboration", "authors": ["Bingsheng Yao", "Jiaju Chen", "Chaoran Chen", "April Wang", "Toby Jia-jun Li", "Dakuo Wang"], "abstract": "Intelligent systems have traditionally been designed as tools rather than collaborators, often lacking critical characteristics that collaboration partnerships require. Recent advances in large language model (LLM) agents open new opportunities for human-LLM-agent collaboration by enabling natural communication and various social and cognitive behaviors. Yet it remains unclear whether principles of computer-mediated collaboration established in HCI and CSCW persist, change, or fail when humans collaborate with LLM agents. To support systematic investigations of these questions, we introduce an open and configurable research platform for HCI researchers. The platform's modular design allows seamless adaptation of classic CSCW experiments and manipulation of theory-grounded interaction controls. We demonstrate the platform's effectiveness and usability through two case studies: (1) re-implementing the classic human-human-collaboration task Shape Factory as a between-subject human-agent-collaboration experiment with 16 participants, and (2) a participatory cognitive walkthrough with five HCI researchers to refine workflows and interfaces for experiment setup and analysis.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.18008.pdf", "abstract_url": "https://arxiv.org/abs/2509.18008", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一个可配置的研究平台，用于探索人类与LLM代理的协作，基于人类协作原则，通过案例研究验证其有效性。", "motivation": "解决智能系统作为工具而非协作伙伴的局限性，探究人类与LLM代理协作时CSCW原则的适用性。", "method": "开发了一个模块化、可配置的研究平台，允许适应经典CSCW实验，并通过案例研究（如Shape Factory任务和认知走查）进行验证。", "result": "平台在16名参与者的实验中有效实施，并通过HCI研究者的反馈改进了工作流程和界面，展示了可用性。", "conclusion": "该平台支持系统化研究人类-代理协作，为HCI领域提供了实用工具，并强调了LLM代理在协作中的潜力。"}}
{"id": "2509.17488", "title": "Privacy in Action: Towards Realistic Privacy Mitigation and Evaluation for LLM-Powered Agents", "authors": ["Shouju Wang", "Fenglin Yu", "Xirui Liu", "Xiaoting Qin", "Jue Zhang", "Qingwei Lin", "Dongmei Zhang", "Saravan Rajmohan"], "abstract": "The increasing autonomy of LLM agents in handling sensitive communications, accelerated by Model Context Protocol (MCP) and Agent-to-Agent (A2A) frameworks, creates urgent privacy challenges. While recent work reveals significant gaps between LLMs' privacy Q&A performance and their agent behavior, existing benchmarks remain limited to static, simplified scenarios. We present PrivacyChecker, a model-agnostic, contextual integrity based mitigation approach that effectively reduces privacy leakage from 36.08% to 7.30% on DeepSeek-R1 and from 33.06% to 8.32% on GPT-4o, all while preserving task helpfulness. We also introduce PrivacyLens-Live, transforming static benchmarks into dynamic MCP and A2A environments that reveal substantially higher privacy risks in practical. Our modular mitigation approach integrates seamlessly into agent protocols through three deployment strategies, providing practical privacy protection for the emerging agentic ecosystem. Our data and code will be made available at", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": "To appear at EMNLP 2025 (Findings)", "pdf_url": "https://arxiv.org/pdf/2509.17488.pdf", "abstract_url": "https://arxiv.org/abs/2509.17488", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了PrivacyChecker和PrivacyLens-Live，用于在LLM代理中缓解和评估隐私风险，显著降低隐私泄露并保持任务有效性。", "motivation": "解决LLM代理在处理敏感通信时日益严重的隐私挑战，现有基准测试局限于静态简化场景。", "method": "采用基于上下文完整性的模型无关缓解方法PrivacyChecker，并通过PrivacyLens-Live将静态基准转换为动态MCP和A2A环境。", "result": "在DeepSeek-R1和GPT-4o上，隐私泄露从约36%和33%分别降至7.30%和8.32%，同时保持任务帮助性。", "conclusion": "模块化方法可无缝集成到代理协议中，为新兴代理生态系统提供实用的隐私保护。"}}
{"id": "2509.18054", "title": "A Knowledge Graph-based Retrieval-Augmented Generation Framework for Algorithm Selection in the Facility Layout Problem", "authors": ["Nikhil N S", "Amol Dilip Joshi", "Bilal Muhammed", "Soban Babu"], "abstract": "Selecting a solution algorithm for the Facility Layout Problem (FLP), an NP-hard optimization problem with a multiobjective trade-off, is a complex task that requires deep expert knowledge. The performance of a given algorithm depends on specific problem characteristics such as its scale, objectives, and constraints. This creates a need for a data-driven recommendation method to guide algorithm selection in automated design systems. This paper introduces a new recommendation method to make such expertise accessible, based on a Knowledge Graph-based Retrieval-Augmented Generation (KG RAG) framework. To address this, a domain-specific knowledge graph is constructed from published literature. The method then employs a multi-faceted retrieval mechanism to gather relevant evidence from this knowledge graph using three distinct approaches, which include a precise graph-based search, flexible vector-based search, and high-level cluster-based search. The retrieved evidence is utilized by a Large Language Model (LLM) to generate algorithm recommendations with data-driven reasoning. The proposed KG-RAG method is compared against a commercial LLM chatbot with access to the knowledge base as a table, across a series of diverse, real-world FLP test cases. Based on recommendation accuracy and reasoning capability, the proposed method performed significantly better than the commercial LLM chatbot.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "10 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2509.18054.pdf", "abstract_url": "https://arxiv.org/abs/2509.18054", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种基于知识图谱的检索增强生成框架，用于设施布局问题中的算法选择，通过多方法检索和LLM生成推荐，显著优于商业LLM聊天机器人。", "motivation": "解决设施布局问题中算法选择的复杂性，该问题为NP难优化问题，依赖专家知识，需要数据驱动的推荐方法。", "method": "构建领域知识图谱，采用多面检索机制（图搜索、向量搜索、聚类搜索），并利用LLM生成推荐。", "result": "在真实测试案例中，该方法在推荐准确性和推理能力上显著优于商业LLM聊天机器人。", "conclusion": "KG-RAG框架有效提升算法选择的自动化水平，使专业知识更易获取，具有实际应用价值。"}}
{"id": "2509.18057", "title": "Reinforced Generation of Combinatorial Structures: Applications to Complexity Theory", "authors": ["Ansh Nagda", "Prabhakar Raghavan", "Abhradeep Thakurta"], "abstract": "We explore whether techniques from AI can help discover new combinatorial structures that improve provable limits on efficient algorithms. Specifically, we use AlphaEvolve (an LLM coding agent) to study two settings:", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computational Complexity (cs.CC); Combinatorics (math.CO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.18057.pdf", "abstract_url": "https://arxiv.org/abs/2509.18057", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computational Complexity (cs.CC)", "Combinatorics (math.CO)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文探讨利用AI技术（如AlphaEvolve）生成组合结构，以改进复杂性理论中高效算法的可证明界限。", "motivation": "解决复杂性理论中缺乏新组合结构来提升算法效率证明的问题。", "method": "使用AlphaEvolve（一种LLM编码代理）生成组合结构并应用于两个具体场景。", "result": "关键发现未在摘要中明确，但方法旨在产生改进算法界限的结果。", "conclusion": "AI技术有潜力推动复杂性理论的发展，通过自动化生成组合结构。"}}
