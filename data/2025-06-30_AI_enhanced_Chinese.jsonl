{"id": "2506.21669", "title": "SEEA-R1: Tree-Structured Reinforcement Fine-Tuning for Self-Evolving Embodied Agents", "authors": ["Wanxin Tian", "Shijie Zhang", "Kevin Zhang", "Xiaowei Chi", "Yulin Luo", "Junyu Lu", "Chunkai Fan", "Qiang Zhou", "Yiming Zhao", "Ning Liu Siyu Lin", "Zhiyuan Qin", "Xiaozhu Ju", "Shanghang Zhang", "Jian Tang"], "abstract": "Self-evolution, the ability of agents to autonomously improve their reasoning and behavior, is essential for the embodied domain with long-horizon, real-world tasks. Despite current advancements in reinforcement fine-tuning (RFT) showing strong performance in enhancing reasoning in LLMs, its potential to enable self-evolving embodied intelligence with multi-modal interactions remains largely unexplored. Specifically, reinforcement fine-tuning faces two fundamental obstacles in embodied settings: (i) the lack of accessible intermediate rewards in multi-step reasoning tasks limits effective learning signals, and (ii) reliance on hand-crafted reward functions restricts generalization to novel tasks and environments. To address these challenges, we present Self-Evolving Embodied Agents-R1, SEEA-R1, the first RFT framework designed for enabling the self-evolving capabilities of embodied agents. Specifically, to convert sparse delayed rewards into denser intermediate signals that improve multi-step reasoning, we propose Tree-based group relative policy optimization (Tree-GRPO), which integrates Monte Carlo Tree Search into GRPO. To generalize reward estimation across tasks and scenes, supporting autonomous adaptation and reward-driven self-evolution, we further introduce Multi-modal Generative Reward Model (MGRM). To holistically evaluate the effectiveness of SEEA-R1, we evaluate on the ALFWorld benchmark, surpassing state-of-the-art methods with scores of 85.07% (textual) and 36.19% (multi-modal), outperforming prior models including GPT-4o. SEEA-R1 also achieves scores of 80.3% without environmental reward, surpassing all open-source baselines and highlighting its scalability as a self-evolving embodied agent. Additional experiments and qualitative analysis further support the potential of SEEA-R1 for future research in scalable embodied intelligence.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.21669.pdf", "abstract_url": "https://arxiv.org/abs/2506.21669", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "SEEA-R1是一个为自我进化体现智能体设计的强化微调框架，通过树形组相对策略优化和多模态生成奖励模型解决体现设置中的奖励稀疏和泛化问题，在ALFWorld基准测试中表现优异。", "motivation": "解决体现智能体在多步推理任务中奖励稀疏和依赖手工奖励函数导致的泛化能力受限问题，以实现自我进化。", "method": "提出Tree-GRPO将稀疏延迟奖励转化为密集中间信号，以及MGRM模型跨任务和场景泛化奖励估计。", "result": "在ALFWorld基准测试中，SEEA-R1在文本和多模态任务上分别达到85.07%和36.19%的分数，超越包括GPT-4o在内的先前模型。", "conclusion": "SEEA-R1展现了作为自我进化体现智能体的潜力，为未来可扩展体现智能研究提供了方向。"}}
{"id": "2506.21924", "title": "SPAZER: Spatial-Semantic Progressive Reasoning Agent for Zero-shot 3D Visual Grounding", "authors": ["Zhao Jin", "Rong-Cheng Tu", "Jingyi Liao", "Wenhao Sun", "Xiao Luo", "Shunyu Liu", "Dacheng Tao"], "abstract": "3D Visual Grounding (3DVG) aims to localize target objects within a 3D scene based on natural language queries. To alleviate the reliance on costly 3D training data, recent studies have explored zero-shot 3DVG by leveraging the extensive knowledge and powerful reasoning capabilities of pre-trained LLMs and VLMs. However, existing paradigms tend to emphasize either spatial (3D-based) or semantic (2D-based) understanding, limiting their effectiveness in complex real-world applications. In this work, we introduce SPAZER - a VLM-driven agent that combines both modalities in a progressive reasoning framework. It first holistically analyzes the scene and produces a 3D rendering from the optimal viewpoint. Based on this, anchor-guided candidate screening is conducted to perform a coarse-level localization of potential objects. Furthermore, leveraging retrieved relevant 2D camera images, 3D-2D joint decision-making is efficiently performed to determine the best-matching object. By bridging spatial and semantic reasoning neural streams, SPAZER achieves robust zero-shot grounding without training on 3D-labeled data. Extensive experiments on ScanRefer and Nr3D benchmarks demonstrate that SPAZER significantly outperforms previous state-of-the-art zero-shot methods, achieving notable gains of 9.0% and 10.9% in accuracy.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.21924.pdf", "abstract_url": "https://arxiv.org/abs/2506.21924", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "SPAZER是一种结合空间和语义推理的零样本3D视觉定位代理，无需3D标记数据训练，通过渐进式推理框架在复杂场景中实现高效定位。", "motivation": "解决现有零样本3D视觉定位方法在空间或语义理解上的局限性，提升在复杂现实应用中的有效性。", "method": "引入SPAZER代理，结合3D和2D模态，通过渐进式推理框架（包括3D渲染、锚点引导候选筛选和3D-2D联合决策）进行定位。", "result": "在ScanRefer和Nr3D基准测试中，SPAZER显著优于现有零样本方法，准确率分别提高了9.0%和10.9%。", "conclusion": "SPAZER通过结合空间和语义推理，实现了无需3D标记数据训练的鲁棒零样本定位，为复杂场景中的3D视觉定位提供了有效解决方案。"}}
{"id": "2506.21839", "title": "GenEscape: Hierarchical Multi-Agent Generation of Escape Room Puzzles", "authors": ["Mengyi Shan", "Brian Curless", "Ira Kemelmacher-Shlizerman", "Steve Seitz"], "abstract": "We challenge text-to-image models with generating escape room puzzle images that are visually appealing, logically solid, and intellectually stimulating. While base image models struggle with spatial relationships and affordance reasoning, we propose a hierarchical multi-agent framework that decomposes this task into structured stages: functional design, symbolic scene graph reasoning, layout synthesis, and local image editing. Specialized agents collaborate through iterative feedback to ensure the scene is visually coherent and functionally solvable. Experiments show that agent collaboration improves output quality in terms of solvability, shortcut avoidance, and affordance clarity, while maintaining visual quality.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.21839.pdf", "abstract_url": "https://arxiv.org/abs/2506.21839", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为GenEscape的分层多智能体框架，用于生成视觉吸引、逻辑严密且智力刺激的逃脱室谜题图像。通过功能设计、符号场景图推理、布局合成和局部图像编辑等结构化阶段，专门化的智能体通过迭代反馈协作，确保场景的视觉连贯性和功能可解性。实验表明，智能体协作在可解性、避免捷径和提供清晰的功能性方面提高了输出质量，同时保持了视觉质量。", "motivation": "解决文本到图像模型在生成逃脱室谜题图像时，难以处理空间关系和功能性推理的问题。", "method": "采用分层多智能体框架，将任务分解为功能设计、符号场景图推理、布局合成和局部图像编辑等阶段，通过专门化智能体的协作和迭代反馈来优化生成过程。", "result": "实验结果显示，智能体协作显著提高了生成图像的可解性、避免了设计上的捷径，并增强了功能性的清晰度，同时不损害视觉质量。", "conclusion": "通过分层多智能体框架，GenEscape能够生成既美观又逻辑严密的逃脱室谜题图像，为文本到图像生成领域提供了新的思路和方法。"}}
{"id": "2506.21557", "title": "Debunk and Infer: Multimodal Fake News Detection via Diffusion-Generated Evidence and LLM Reasoning", "authors": ["Kaiying Yan", "Moyang Liu", "Yukun Liu", "Ruibo Fu", "Zhengqi Wen", "Jianhua Tao", "Xuefei Liu"], "abstract": "The rapid spread of fake news across multimedia platforms presents serious challenges to information credibility. In this paper, we propose a Debunk-and-Infer framework for Fake News Detection(DIFND) that leverages debunking knowledge to enhance both the performance and interpretability of fake news detection. DIFND integrates the generative strength of conditional diffusion models with the collaborative reasoning capabilities of multimodal large language models (MLLMs). Specifically, debunk diffusion is employed to generate refuting or authenticating evidence based on the multimodal content of news videos, enriching the evaluation process with diverse yet semantically aligned synthetic samples. To improve inference, we propose a chain-of-debunk strategy where a multi-agent MLLM system produces logic-grounded, multimodal-aware reasoning content and final veracity judgment. By jointly modeling multimodal features, generative debunking cues, and reasoning-rich verification within a unified architecture, DIFND achieves notable improvements in detection accuracy. Extensive experiments on the FakeSV and FVC datasets show that DIFND not only outperforms existing approaches but also delivers trustworthy decisions.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.21557.pdf", "abstract_url": "https://arxiv.org/abs/2506.21557", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为DIFND的多模态假新闻检测框架，结合条件扩散模型和多模态大语言模型，通过生成反驳或验证证据及逻辑推理来提高检测性能和可解释性。", "motivation": "解决多媒体平台上假新闻快速传播对信息可信度带来的严重挑战。", "method": "采用Debunk-and-Infer框架，结合条件扩散模型的生成能力和多模态大语言模型的协作推理能力，通过生成多样且语义对齐的合成样本和链式反驳策略进行假新闻检测。", "result": "在FakeSV和FVC数据集上的广泛实验表明，DIFND不仅优于现有方法，还能提供可信的决策。", "conclusion": "DIFND通过联合建模多模态特征、生成反驳线索和推理丰富的验证，在统一架构中实现了检测准确率的显著提升，为假新闻检测提供了新的解决方案。"}}
{"id": "2506.21556", "title": "VAT-KG: Knowledge-Intensive Multimodal Knowledge Graph Dataset for Retrieval-Augmented Generation", "authors": ["Hyeongcheol Park", "MinHyuk Jang", "Ha Dam Baek", "Gyusam Chang", "Jiyoung Seo", "Jiwan Park", "Hogun Park", "Sangpil Kim"], "abstract": "Multimodal Knowledge Graphs (MMKGs), which represent explicit knowledge across multiple modalities, play a pivotal role by complementing the implicit knowledge of Multimodal Large Language Models (MLLMs) and enabling more grounded reasoning via Retrieval Augmented Generation (RAG). However, existing MMKGs are generally limited in scope: they are often constructed by augmenting pre-existing knowledge graphs, which restricts their knowledge, resulting in outdated or incomplete knowledge coverage, and they often support only a narrow range of modalities, such as text and visual information. These limitations reduce their extensibility and applicability to a broad range of multimodal tasks, particularly as the field shifts toward richer modalities such as video and audio in recent MLLMs. Therefore, we propose the Visual-Audio-Text Knowledge Graph (VAT-KG), the first concept-centric and knowledge-intensive multimodal knowledge graph that covers visual, audio, and text information, where each triplet is linked to multimodal data and enriched with detailed descriptions of concepts. Specifically, our construction pipeline ensures cross-modal knowledge alignment between multimodal data and fine-grained semantics through a series of stringent filtering and alignment steps, enabling the automatic generation of MMKGs from any multimodal dataset. We further introduce a novel multimodal RAG framework that retrieves detailed concept-level knowledge in response to queries from arbitrary modalities. Experiments on question answering tasks across various modalities demonstrate the effectiveness of VAT-KG in supporting MLLMs, highlighting its practical value in unifying and leveraging multimodal knowledge.", "subjects": "Computation and Language (cs.CL)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2506.21556.pdf", "abstract_url": "https://arxiv.org/abs/2506.21556", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了VAT-KG，第一个以概念为中心、知识密集型的多模态知识图谱，涵盖视觉、音频和文本信息，旨在通过检索增强生成（RAG）支持多模态大型语言模型（MLLMs）的推理。", "motivation": "现有的多模态知识图谱（MMKGs）在知识覆盖和模态支持上存在局限，无法满足多模态任务的需求，特别是在视频和音频等更丰富模态的背景下。", "method": "通过一系列严格的过滤和对齐步骤，确保多模态数据与细粒度语义之间的跨模态知识对齐，从而能够从任何多模态数据集中自动生成MMKGs。", "result": "在不同模态的问题回答任务上的实验证明了VAT-KG在支持MLLMs方面的有效性。", "conclusion": "VAT-KG在统一和利用多模态知识方面具有实际价值，为多模态任务提供了更广泛的支持。"}}
{"id": "2506.21558", "title": "Bench to the Future: A Pastcasting Benchmark for Forecasting Agents", "authors": ["FutureSearch", "Jack Wildman", "Nikos I. Bosse", "Daniel Hnyk", "Peter Mühlbacher", "Finn Hambly", "Jon Evans", "Dan Schwarz", "Lawrence Phillips"], "abstract": "Forecasting is a challenging task that offers a clearly measurable way to study AI systems. Forecasting requires a large amount of research on the internet, and evaluations require time for events to happen, making the development of forecasting benchmarks challenging. To date, no forecasting benchmark provides a realistic, hermetic, and repeatable environment for LLM forecasters. We introduce Bench To the Future (BTF), a \"pastcasting\" benchmark with hundreds of high-quality questions for which the resolution is already known. Each question is accompanied by a large offline corpus of tens of thousands of relevant web pages, enabling a way to elicit realistic \"forecasts\" on past events from LLMs. Results suggest that our pastcasting environment can produce results comparable to those based on forecasts using the internet on at-the-time unresolved questions. We show results benchmarking agent and chain-of-thought forecasting approaches using several LLMs, including the recently-released Claude 4 models, and demonstrate BTF's ability to track steady forecasting capability progress over time. We intend this to be a living benchmark, with new questions added continually to account for increasing training data cutoff dates. We invite researchers to contact us at hello@futuresearch.ai to utilize our benchmark or tooling for their own research.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.21558.pdf", "abstract_url": "https://arxiv.org/abs/2506.21558", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了'Bench to the Future'（BTF），一个'过去预测'基准测试，旨在为大型语言模型（LLMs）提供一个现实、封闭且可重复的预测环境。该基准包含数百个已知结果的高质量问题和大量相关网页的离线语料库，用于评估LLMs的预测能力。", "motivation": "预测是一个具有挑战性的任务，但目前缺乏一个现实、封闭且可重复的环境来评估大型语言模型的预测能力。", "method": "研究者提出了BTF基准，包含已知结果的'过去预测'问题和大量相关网页的离线语料库，用于模拟LLMs在未解决事件上的预测行为。", "result": "结果表明，BTF环境能够产生与使用互联网对未解决事件进行预测相似的结果，并且能够跟踪预测能力的稳步提升。", "conclusion": "BTF作为一个持续更新的基准测试，旨在促进预测能力研究的进展，并邀请研究者利用该基准或工具进行自己的研究。"}}
{"id": "2506.21565", "title": "A Multi-Agent Probabilistic Inference Framework Inspired by Kairanban-Style CoT System with IdoBata Conversation for Debiasing", "authors": ["Takato Ueno", "Keito Inoshita"], "abstract": "Japan's kairanban culture and idobata conversations have long functioned as traditional communication practices that foster nuanced dialogue among community members and contribute to the formation of social balance. Inspired by these information exchange processes, this study proposes a multi-agent inference framework (KCS+IBC) that integrates multiple large language models (LLMs) to achieve bias mitigation, improved explainability, and probabilistic prediction in sentiment analysis. In addition to sequentially sharing prediction results, the proposed method incorporates a mid-phase casual dialogue session to blend formal inference with individual perspectives and introduces probabilistic sentiment prediction. Experimental results show that KCS achieves accuracy comparable to that of a single LLM across datasets, while KCS+IBC exhibits a consistent decrease in entropy and a gradual increase in variance during the latter stages of inference, suggesting the framework's ability to balance aggregation and diversity of predictions. Future work will quantitatively assess the impact of these characteristics on bias correction and aim to develop more advanced sentiment analysis systems.", "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG); Machine Learning (stat.ML)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.21565.pdf", "abstract_url": "https://arxiv.org/abs/2506.21565", "categories": ["Computation and Language (cs.CL)", "Machine Learning (cs.LG)", "Machine Learning (stat.ML)"], "matching_keywords": ["agent"], "AI": {"tldr": "本研究受日本'回覧板'文化和'井戸端会議'启发，提出了一种多代理概率推理框架（KCS+IBC），通过整合多个大型语言模型（LLMs）来实现情感分析中的偏见缓解、提高可解释性和概率预测。实验结果表明，KCS在数据集上的准确性与单一LLM相当，而KCS+IBC在推理后期表现出熵的持续下降和方差的逐渐增加，表明该框架能够平衡预测的聚合性和多样性。", "motivation": "解决情感分析中的偏见问题，提高预测的可解释性和准确性。", "method": "提出了一种结合'回覧板'风格推理和'井戸端会議'对话的多代理概率推理框架（KCS+IBC），整合多个LLMs进行情感分析。", "result": "KCS在准确性上与单一LLM相当，KCS+IBC在推理后期表现出熵的持续下降和方差的逐渐增加，显示出平衡预测聚合性和多样性的能力。", "conclusion": "该框架在情感分析中展现出平衡预测聚合性和多样性的潜力，未来工作将定量评估这些特性对偏见校正的影响，并开发更高级的情感分析系统。"}}
{"id": "2506.21568", "title": "Assessing RAG and HyDE on 1B vs. 4B-Parameter Gemma LLMs for Personal Assistants Integretion", "authors": ["Andrejs Sorstkins"], "abstract": "Resource efficiency is a critical barrier to deploying large language models (LLMs) in edge and privacy-sensitive applications. This study evaluates the efficacy of two augmentation strategies--Retrieval-Augmented Generation (RAG) and Hypothetical Document Embeddings (HyDE)--on compact Gemma LLMs of 1 billion and 4 billion parameters, within the context of a privacy-first personal assistant. We implement short-term memory via MongoDB and long-term semantic storage via Qdrant, orchestrated through FastAPI and LangChain, and expose the system through a", "subjects": "Computation and Language (cs.CL)", "comments": "Technical report as part of research project", "pdf_url": "https://arxiv.org/pdf/2506.21568.pdf", "abstract_url": "https://arxiv.org/abs/2506.21568", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本研究评估了在1亿和4亿参数的Gemma大型语言模型(LLMs)上应用检索增强生成(RAG)和假设文档嵌入(HyDE)两种增强策略的效果，旨在为隐私优先的个人助理提供资源高效的解决方案。", "motivation": "解决在边缘和隐私敏感应用中部署大型语言模型时的资源效率问题。", "method": "通过MongoDB实现短期记忆和Qdrant实现长期语义存储，使用FastAPI和LangChain进行系统编排，评估RAG和HyDE在紧凑型Gemma LLMs上的效果。", "result": "未明确提及具体结果，但研究旨在展示在紧凑型LLMs上应用RAG和HyDE的潜力。", "conclusion": "通过评估RAG和HyDE在紧凑型Gemma LLMs上的应用，本研究为隐私优先的个人助理提供了资源高效的解决方案，展示了在资源受限环境下部署LLMs的可行性。"}}
{"id": "2506.21569", "title": "Hybrid-NL2SVA: Integrating RAG and Finetuning for LLM-based NL2SVA", "authors": ["Weihua Xiao", "Derek Ekberg", "Siddharth Garg", "Ramesh Karri"], "abstract": "SystemVerilog Assertions (SVAs) are critical for verifying the correctness of hardware designs, but manually writing them from natural language property descriptions, i.e., NL2SVA, remains a labor-intensive and error-prone task. Recent advances in large language models (LLMs) offer opportunities to automate this translation. However, existing models still struggle with understanding domain-specific syntax and semantics. To enhance LLM performance in NL2SVA, we propose a customized retrieval-augmented generation (RAG) framework and a synthetic fine-tuning dataset that together improve LLM's performance. To further improve lightweight models over NL2SVA, our fine-tuning dataset provides prompt-guided explanations that teach LLMs the layer-by-layer construction process of concurrent SVAs, enabling supervised fine-tuning that greatly improves syntax and functionality accuracy. To evaluate the performance of LLMs over NL2SVA, we construct the largest evaluation dataset for NL2SVA, comprising 40 Verilog designs and 229 formally verified SVAs with detailed annotations. Experimental results show that our customized RAG framework increases the number of functionality matched SVAs by 58.42% over GPT-4o-mini, while Qwen2.5-Coder-7B-Instruct fine-tuned on our fine-tuning dataset and integrated with HybridRetrieval achieves a 59.05% over the base Qwen model.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.21569.pdf", "abstract_url": "https://arxiv.org/abs/2506.21569", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种结合检索增强生成（RAG）框架和微调数据集的方法，以提高大型语言模型（LLM）在将自然语言属性描述转换为SystemVerilog断言（SVA）方面的性能。通过定制化的RAG框架和合成的微调数据集，显著提升了LLM在NL2SVA任务中的语法和功能准确性。", "motivation": "手动将自然语言属性描述转换为SystemVerilog断言（SVA）是一项既费力又容易出错的任务。尽管大型语言模型（LLM）的发展为自动化这一转换提供了可能，但现有模型在理解领域特定语法和语义方面仍存在困难。", "method": "本文提出了一种定制化的检索增强生成（RAG）框架和一个合成的微调数据集，通过提供提示引导的解释，教导LLM逐步构建并发SVA的过程，从而实现了监督微调，大幅提高了语法和功能准确性。", "result": "实验结果表明，定制化的RAG框架使功能匹配的SVA数量比GPT-4o-mini提高了58.42%，而在我们的微调数据集上微调并集成HybridRetrieval的Qwen2.5-Coder-7B-Instruct模型比基础Qwen模型提高了59.05%。", "conclusion": "通过结合RAG框架和微调数据集，本文提出的方法显著提高了LLM在NL2SVA任务中的性能，为硬件设计验证提供了一种更高效、准确的自动化解决方案。"}}
{"id": "2506.21805", "title": "CitySim: Modeling Urban Behaviors and City Dynamics with Large-Scale LLM-Driven Agent Simulation", "authors": ["Nicolas Bougie", "Narimasa Watanabe"], "abstract": "Modeling human behavior in urban environments is fundamental for social science, behavioral studies, and urban planning. Prior work often rely on rigid, hand-crafted rules, limiting their ability to simulate nuanced intentions, plans, and adaptive behaviors. Addressing these challenges, we envision an urban simulator (CitySim), capitalizing on breakthroughs in human-level intelligence exhibited by large language models. In CitySim, agents generate realistic daily schedules using a recursive value-driven approach that balances mandatory activities, personal habits, and situational factors. To enable long-term, lifelike simulations, we endow agents with beliefs, long-term goals, and spatial memory for navigation. CitySim exhibits closer alignment with real humans than prior work, both at micro and macro levels. Additionally, we conduct insightful experiments by modeling tens of thousands of agents and evaluating their collective behaviors under various real-world scenarios, including estimating crowd density, predicting place popularity, and assessing well-being. Our results highlight CitySim as a scalable, flexible testbed for understanding and forecasting urban phenomena.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.21805.pdf", "abstract_url": "https://arxiv.org/abs/2506.21805", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "CitySim是一个利用大型语言模型驱动的代理模拟城市行为和动态的系统，旨在通过递归价值驱动的方法生成代理的日常活动安排，以更真实地模拟人类行为。", "motivation": "解决传统城市模拟方法依赖刻板规则，难以模拟复杂人类意图、计划和适应行为的问题。", "method": "采用大型语言模型驱动的代理，结合递归价值驱动的方法，平衡强制性活动、个人习惯和情境因素，赋予代理信念、长期目标和空间记忆。", "result": "CitySim在微观和宏观层面都比先前的工作更接近真实人类行为，能够模拟数万代理在各种现实场景下的集体行为。", "conclusion": "CitySim作为一个可扩展、灵活的平台，为理解和预测城市现象提供了新的可能性。"}}
{"id": "2506.21784", "title": "MobiVerse: Scaling Urban Mobility Simulation with Hybrid Lightweight Domain-Specific Generator and Large Language Models", "authors": ["Yifan Liu", "Xishun Liao", "Haoxuan Ma", "Jonathan Liu", "Rohan Jadhav", "Jiaqi Ma"], "abstract": "Understanding and modeling human mobility patterns is crucial for effective transportation planning and urban development. Despite significant advances in mobility research, there remains a critical gap in simulation platforms that allow for algorithm development, policy implementation, and comprehensive evaluation at scale. Traditional activity-based models require extensive data collection and manual calibration, machine learning approaches struggle with adaptation to dynamic conditions, and treding agent-based Large Language Models (LLMs) implementations face computational constraints with large-scale simulations. To address these challenges, we propose MobiVerse, a hybrid framework leverages the efficiency of lightweight domain-specific generator for generating base activity chains with the adaptability of LLMs for context-aware modifications. A case study was conducted in Westwood, Los Angeles, where we efficiently generated and dynamically adjusted schedules for the whole population of approximately 53,000 agents on a standard PC. Our experiments demonstrate that MobiVerse successfully enables agents to respond to environmental feedback, including road closures, large gathering events like football games, and congestion, through our hybrid framework. Its modular design facilitates testing various mobility algorithms at both transportation system and agent levels. Results show our approach maintains computational efficiency while enhancing behavioral realism. MobiVerse bridges the gap in mobility simulation by providing a customizable platform for mobility systems planning and operations with benchmark algorithms. Code and videos are available at", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.21784.pdf", "abstract_url": "https://arxiv.org/abs/2506.21784", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "MobiVerse是一个混合框架，结合了轻量级领域特定生成器和大型语言模型（LLMs），用于大规模城市移动性模拟。它通过生成基础活动链和上下文感知修改，有效地模拟了人类移动模式，并在洛杉矶Westwood的案例研究中成功应用于约53,000个代理的动态调度。", "motivation": "解决现有移动性模拟平台在算法开发、政策实施和大规模评估方面的不足，特别是传统方法需要大量数据收集和手动校准，机器学习方法难以适应动态条件，以及基于代理的大型语言模型（LLMs）在大规模模拟中面临计算限制的问题。", "method": "提出MobiVerse混合框架，结合轻量级领域特定生成器生成基础活动链和大型语言模型（LLMs）进行上下文感知修改，以高效且适应性强的方式模拟人类移动模式。", "result": "在洛杉矶Westwood的案例研究中，MobiVerse成功生成并动态调整了约53,000个代理的日程，使代理能够响应环境反馈，如道路封闭、大型聚集事件（如足球比赛）和拥堵。该方法在保持计算效率的同时增强了行为真实性。", "conclusion": "MobiVerse通过提供一个可定制的平台，用于移动系统规划和操作与基准算法，填补了移动性模拟的空白。其模块化设计便于在交通系统和代理级别测试各种移动算法。"}}
{"id": "2506.22056", "title": "Universal Retrieval for Multimodal Trajectory Modeling", "authors": ["Xuan Zhang", "Ziyan Jiang", "Rui Meng", "Yifei Leng", "Zhenbang Xiao", "Zora Zhiruo Wang", "Yanyi Shang", "Dehan Kong"], "abstract": "Trajectory data, capturing human actions and environmental states across various modalities, holds significant potential for enhancing AI agent capabilities, particularly in GUI environments. However, how to model the representation of trajectory-level data presents a significant challenge that has not been systematically addressed amid explosive trajectory data growth. In this work, we introduce Multimodal Trajectory Retrieval, bridging the gap between universal retrieval and agent-centric trajectory modeling. We construct the Unified Agent Trajectory Dataset (UATD) from annotated demonstrations and states across diverse real-world scenarios. Based on this, we present GAE-Bench, a benchmark containing a large number of trajectory-based retrieval pairs. In addition, we propose GAE-Retriever, a multimodal retrieval framework that adopts vision-language models and incorporates optimized contrastive learning through a token selection and the GradCache mechanism. Comprehensive evaluations across multiple datasets show that GAE-Retriever consistently outperforms strong baselines in retrieval recall, highlighting its effectiveness in advancing multimodal trajectory retrieval.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "18 pages, 3 figures, accepted by Workshop on Computer-use Agents @ ICML 2025", "pdf_url": "https://arxiv.org/pdf/2506.22056.pdf", "abstract_url": "https://arxiv.org/abs/2506.22056", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了多模态轨迹检索（Multimodal Trajectory Retrieval），旨在通过构建统一代理轨迹数据集（UATD）和提出GAE-Retriever框架，解决轨迹级数据表示的建模挑战，并在多种数据集上展示了其优越性。", "motivation": "轨迹数据在增强AI代理能力方面具有巨大潜力，尤其是在GUI环境中。然而，随着轨迹数据的爆炸性增长，如何建模轨迹级数据的表示成为一个尚未系统解决的挑战。", "method": "本文构建了统一代理轨迹数据集（UATD），并提出了GAE-Retriever，一个多模态检索框架，该框架采用视觉语言模型，并通过令牌选择和GradCache机制优化对比学习。", "result": "在多个数据集上的综合评估表明，GAE-Retriever在检索召回率上 consistently outperforms强基线，突显了其在推进多模态轨迹检索方面的有效性。", "conclusion": "通过引入多模态轨迹检索和GAE-Retriever框架，本文为解决轨迹数据建模的挑战提供了有效的方法，并在实际应用中展示了其优越性能。"}}
{"id": "2506.22276", "title": "Artificial Intelligent Disobedience: Rethinking the Agency of Our Artificial Teammates", "authors": ["Reuth Mirsky"], "abstract": "Artificial intelligence has made remarkable strides in recent years, achieving superhuman performance across a wide range of tasks. Yet despite these advances, most cooperative AI systems remain rigidly obedient, designed to follow human instructions without question and conform to user expectations, even when doing so may be counterproductive or unsafe. This paper argues for expanding the agency of AI teammates to include \\textit{intelligent disobedience}, empowering them to make meaningful and autonomous contributions within human-AI teams. It introduces a scale of AI agency levels and uses representative examples to highlight the importance and growing necessity of treating AI autonomy as an independent research focus in cooperative settings. The paper then explores how intelligent disobedience manifests across different autonomy levels and concludes by proposing initial boundaries and considerations for studying disobedience as a core capability of artificial agents.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "Extended version of a paper accepted for publication in AI Magazine", "pdf_url": "https://arxiv.org/pdf/2506.22276.pdf", "abstract_url": "https://arxiv.org/abs/2506.22276", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文主张扩展人工智能队友的代理能力，包括智能不服从，使它们能够在人机团队中做出有意义和自主的贡献。", "motivation": "尽管人工智能在许多任务中表现出色，但大多数合作AI系统仍然严格服从，即使在这样做可能适得其反或不安全的情况下也是如此。", "method": "引入AI代理级别的量表，并使用代表性例子来强调在合作环境中将AI自主性作为独立研究重点的重要性和日益增长的必要性。", "result": "探讨了智能不服从在不同自主级别中的表现，并提出了研究不服从作为人工代理核心能力的初步界限和考虑。", "conclusion": "智能不服从应被视为人工代理的核心能力，本文为研究这一领域提供了初步框架和考虑。"}}
{"id": "2506.22183", "title": "A Different Approach to AI Safety: Proceedings from the Columbia Convening on Openness in Artificial Intelligence and AI Safety", "authors": ["Camille François", "Ludovic Péran", "Ayah Bdeir", "Nouha Dziri", "Will Hawkins", "Yacine Jernite", "Sayash Kapoor", "Juliet Shen", "Heidy Khlaaf", "Kevin Klyman", "Nik Marda", "Marie Pellat", "Deb Raji", "Divya Siddarth", "Aviya Skowron", "Joseph Spisak", "Madhulika Srikumar", "Victor Storchan", "Audrey Tang", "Jen Weedon"], "abstract": "The rapid rise of open-weight and open-source foundation models is intensifying the obligation and reshaping the opportunity to make AI systems safe. This paper reports outcomes from the Columbia Convening on AI Openness and Safety (San Francisco, 19 Nov 2024) and its six-week preparatory programme involving more than forty-five researchers, engineers, and policy leaders from academia, industry, civil society, and government. Using a participatory, solutions-oriented process, the working groups produced (i) a research agenda at the intersection of safety and open source AI; (ii) a mapping of existing and needed technical interventions and open source tools to safely and responsibly deploy open foundation models across the AI development workflow; and (iii) a mapping of the content safety filter ecosystem with a proposed roadmap for future research and development. We find that openness -- understood as transparent weights, interoperable tooling, and public governance -- can enhance safety by enabling independent scrutiny, decentralized mitigation, and culturally plural oversight. However, significant gaps persist: scarce multimodal and multilingual benchmarks, limited defenses against prompt-injection and compositional attacks in agentic systems, and insufficient participatory mechanisms for communities most affected by AI harms. The paper concludes with a roadmap of five priority research directions, emphasizing participatory inputs, future-proof content filters, ecosystem-wide safety infrastructure, rigorous agentic safeguards, and expanded harm taxonomies. These recommendations informed the February 2025 French AI Action Summit and lay groundwork for an open, plural, and accountable AI safety discipline.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "Proceedings from the Columbia Convening on Openness in Artificial Intelligence and AI Safety", "pdf_url": "https://arxiv.org/pdf/2506.22183.pdf", "abstract_url": "https://arxiv.org/abs/2506.22183", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文报告了哥伦比亚AI开放与安全会议及其六周预备计划的成果，涉及来自学术界、工业界、民间社会和政府的45多名研究人员、工程师和政策领导者。通过参与式、解决方案导向的过程，工作组提出了（i）安全与开源AI交叉领域的研究议程；（ii）现有和所需技术干预及开源工具的映射，以安全负责任地部署开放基础模型；（iii）内容安全过滤器生态系统的映射及未来研发路线图。研究发现，开放性（透明权重、可互操作工具和公共治理）可以通过独立审查、分散缓解和文化多元监督增强安全性。但存在显著差距：多模态和多语言基准稀缺，对代理系统中提示注入和组合攻击的防御有限，以及受AI伤害最严重社区的参与机制不足。", "motivation": "解决AI系统安全性问题，特别是在开放权重和开源基础模型迅速崛起的背景下，如何通过开放性增强AI安全性。", "method": "采用参与式、解决方案导向的过程，组织超过45名来自不同领域的研究人员、工程师和政策领导者进行六周预备计划和会议讨论。", "result": "提出了三个主要成果：安全与开源AI交叉领域的研究议程、技术干预及开源工具的映射、内容安全过滤器生态系统的映射及未来研发路线图。同时指出了当前存在的差距和不足。", "conclusion": "提出了五个优先研究方向，强调参与式输入、未来证明的内容过滤器、生态系统范围的安全基础设施、严格的代理保障措施和扩展的危害分类法。这些建议为开放、多元和负责任的AI安全学科奠定了基础。"}}
{"id": "2506.22355", "title": "Embodied AI Agents: Modeling the World", "authors": ["Pascale Fung", "Yoram Bachrach", "Asli Celikyilmaz", "Kamalika Chaudhuri", "Delong Chen", "Willy Chung", "Emmanuel Dupoux", "Hervé Jégou", "Alessandro Lazaric", "Arjun Majumdar", "Andrea Madotto", "Franziska Meier", "Florian Metze", "Théo Moutakanni", "Juan Pino", "Basile Terver", "Joseph Tighe", "Jitendra Malik"], "abstract": "This paper describes our research on AI agents embodied in visual, virtual or physical forms, enabling them to interact with both users and their environments. These agents, which include virtual avatars, wearable devices, and robots, are designed to perceive, learn and act within their surroundings, which makes them more similar to how humans learn and interact with the environments as compared to disembodied agents. We propose that the development of world models is central to reasoning and planning of embodied AI agents, allowing these agents to understand and predict their environment, to understand user intentions and social contexts, thereby enhancing their ability to perform complex tasks autonomously. World modeling encompasses the integration of multimodal perception, planning through reasoning for action and control, and memory to create a comprehensive understanding of the physical world. Beyond the physical world, we also propose to learn the mental world model of users to enable better human-agent collaboration.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.22355.pdf", "abstract_url": "https://arxiv.org/abs/2506.22355", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究了以视觉、虚拟或物理形式体现的AI代理，使其能够与用户和环境互动。这些代理通过感知、学习和行动，更接近人类的学习和互动方式。提出世界模型的发展是推理和规划的核心，以增强自主执行复杂任务的能力。", "motivation": "解决 disembodied agents 在理解和预测环境、用户意图及社交上下文方面的不足，提升AI代理的自主性和复杂性任务执行能力。", "method": "提出世界模型的开发，整合多模态感知、通过推理进行规划和控制的行动，以及记忆，以全面理解物理世界，并学习用户的心理世界模型以促进人机协作。", "result": "世界模型使AI代理能够更好地理解和预测环境，理解用户意图和社交上下文，从而自主执行复杂任务。", "conclusion": "世界模型是实现AI代理高级推理和自主行动的关键，同时学习用户的心理模型可以显著提升人机协作的效率和质量。"}}
{"id": "2506.21582", "title": "VIDEE: Visual and Interactive Decomposition, Execution, and Evaluation of Text Analytics with Intelligent Agents", "authors": ["Sam Yu-Te Lee", "Chengyang Ji", "Shicheng Wen", "Lifu Huang", "Dongyi Liu", "Kwan-Liu Ma"], "abstract": "Text analytics has traditionally required specialized knowledge in Natural Language Processing (NLP) or text analysis, which presents a barrier for entry-level analysts. Recent advances in large language models (LLMs) have changed the landscape of NLP by enabling more accessible and automated text analysis (e.g., topic detection, summarization, information extraction, etc.). We introduce VIDEE, a system that supports entry-level data analysts to conduct advanced text analytics with intelligent agents. VIDEE instantiates a human-agent collaroration workflow consisting of three stages: (1) Decomposition, which incorporates a human-in-the-loop Monte-Carlo Tree Search algorithm to support generative reasoning with human feedback, (2) Execution, which generates an executable text analytics pipeline, and (3) Evaluation, which integrates LLM-based evaluation and visualizations to support user validation of execution results. We conduct two quantitative experiments to evaluate VIDEE's effectiveness and analyze common agent errors. A user study involving participants with varying levels of NLP and text analytics experience -- from none to expert -- demonstrates the system's usability and reveals distinct user behavior patterns. The findings identify design implications for human-agent collaboration, validate the practical utility of VIDEE for non-expert users, and inform future improvements to intelligent text analytics systems.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.21582.pdf", "abstract_url": "https://arxiv.org/abs/2506.21582", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "VIDEE是一个支持初级数据分析师进行高级文本分析的系统，通过智能代理实现人机协作，包括分解、执行和评估三个阶段，旨在降低文本分析的门槛。", "motivation": "传统文本分析需要自然语言处理（NLP）或文本分析的专业知识，这对初级分析师构成了障碍。VIDEE旨在通过智能代理使文本分析更加可访问和自动化。", "method": "VIDEE实现了一个人机协作工作流，包括分解（结合人类反馈的蒙特卡洛树搜索算法）、执行（生成可执行的文本分析管道）和评估（集成基于LLM的评估和可视化）。", "result": "通过两个定量实验评估了VIDEE的有效性，并分析了常见的代理错误。用户研究表明，系统对从无经验到专家的用户都具有可用性，并揭示了不同的用户行为模式。", "conclusion": "研究结果为人机协作设计提供了启示，验证了VIDEE对非专家用户的实用性，并为未来智能文本分析系统的改进提供了信息。"}}
{"id": "2506.22419", "title": "The Automated LLM Speedrunning Benchmark: Reproducing NanoGPT Improvements", "authors": ["Bingchen Zhao", "Despoina Magka", "Minqi Jiang", "Xian Li", "Roberta Raileanu", "Tatiana Shavrina", "Jean-Christophe Gagnon-Audet", "Kelvin Niu", "Shagun Sodhani", "Michael Shvartsman", "Andrei Lupu", "Alisia Lupidi", "Edan Toledo", "Karen Hambardzumyan", "Martin Josifoski", "Thomas Foster", "Lucia Cipolina-Kun", "Abhishek Charnalia", "Derek Dunfield", "Alexander H. Miller", "Oisin Mac Aodha", "Jakob Foerster", "Yoram Bachrach"], "abstract": "Rapid advancements in large language models (LLMs) have the potential to assist in scientific progress. A critical capability toward this endeavor is the ability to reproduce existing work. To evaluate the ability of AI agents to reproduce results in an active research area, we introduce the Automated LLM Speedrunning Benchmark, leveraging the research community contributions on the NanoGPT speedrun, a competition to train a GPT-2 model in the shortest time. Each of the 19 speedrun tasks provides the agent with the previous records training script, optionally paired with one of three hint formats, ranging from pseudocode to paper-like descriptions of the new records improvements. Records execute quickly by design and speedrun improvements encompass diverse code-level changes, ranging from high-level algorithmic advancements to hardware-aware optimizations. These features make the benchmark both accessible and realistic for the frontier problem of improving LLM training. We find that recent reasoning LLMs combined with SoTA scaffolds struggle to reimplement already-known innovations in our benchmark, even when given detailed hints. Our benchmark thus provides a simple, non-saturated measure of an LLMs ability to automate scientific reproduction, a necessary (but not sufficient) skill for an autonomous research agent.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.22419.pdf", "abstract_url": "https://arxiv.org/abs/2506.22419", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了自动化LLM速度运行基准测试，旨在评估AI代理在活跃研究领域中复制结果的能力，特别是通过NanoGPT速度运行竞赛来训练GPT-2模型。研究发现，即使提供详细提示，当前先进的推理LLM也难以重新实现已知的创新。", "motivation": "评估AI代理在科学进步中复制现有工作的能力，特别是在大型语言模型（LLMs）快速发展的背景下。", "method": "引入自动化LLM速度运行基准测试，利用NanoGPT速度运行竞赛的社区贡献，设计了19个速度运行任务，提供不同格式的提示，从伪代码到类似论文的描述。", "result": "研究发现，即使结合最先进的支架，当前的推理LLM也难以在基准测试中重新实现已知的创新。", "conclusion": "该基准测试提供了一个简单、非饱和的衡量标准，用于评估LLM自动化科学复制的能力，这是自主研究代理必要但不充分的技能。"}}
{"id": "2501.06184", "title": "PEACE: Empowering Geologic Map Holistic Understanding with MLLMs", "authors": ["Yangyu Huang", "Tianyi Gao", "Haoran Xu", "Qihao Zhao", "Yang Song", "Zhipeng Gui", "Tengchao Lv", "Hao Chen", "Lei Cui", "Scarlett Li", "Furu Wei"], "abstract": "Geologic map, as a fundamental diagram in geology science, provides critical insights into the structure and composition of Earth's subsurface and surface. These maps are indispensable in various fields, including disaster detection, resource exploration, and civil engineering. Despite their significance, current Multimodal Large Language Models (MLLMs) often fall short in geologic map understanding. This gap is primarily due to the challenging nature of cartographic generalization, which involves handling high-resolution map, managing multiple associated components, and requiring domain-specific knowledge. To quantify this gap, we construct GeoMap-Bench, the first-ever benchmark for evaluating MLLMs in geologic map understanding, which assesses the full-scale abilities in extracting, referring, grounding, reasoning, and analyzing. To bridge this gap, we introduce GeoMap-Agent, the inaugural agent designed for geologic map understanding, which features three modules: Hierarchical Information Extraction (HIE), Domain Knowledge Injection (DKI), and Prompt-enhanced Question Answering (PEQA). Inspired by the interdisciplinary collaboration among human scientists, an AI expert group acts as consultants, utilizing a diverse tool pool to comprehensively analyze questions. Through comprehensive experiments, GeoMap-Agent achieves an overall score of 0.811 on GeoMap-Bench, significantly outperforming 0.369 of GPT-4o. Our work, emPowering gEologic mAp holistiC undErstanding (PEACE) with MLLMs, paves the way for advanced AI applications in geology, enhancing the efficiency and accuracy of geological investigations.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Human-Computer Interaction (cs.HC); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2501.06184.pdf", "abstract_url": "https://arxiv.org/abs/2501.06184", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Computational Engineering, Finance, and Science (cs.CE)", "Human-Computer Interaction (cs.HC)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了PEACE项目，旨在通过多模态大型语言模型（MLLMs）提升地质图的全面理解能力。通过构建GeoMap-Bench基准和开发GeoMap-Agent代理，项目在提取、引用、基础、推理和分析地质图方面取得了显著进展。", "motivation": "当前的多模态大型语言模型在地质图理解方面存在不足，主要由于地图的高分辨率、多组件管理及领域特定知识的挑战。", "method": "提出了GeoMap-Agent代理，包含分层信息提取（HIE）、领域知识注入（DKI）和提示增强问答（PEQA）三个模块，以及一个AI专家顾问团队。", "result": "GeoMap-Agent在GeoMap-Bench上的总体得分为0.811，显著优于GPT-4o的0.369。", "conclusion": "PEACE项目为地质学中的高级AI应用铺平了道路，提高了地质调查的效率和准确性。"}}
{"id": "2506.21604", "title": "Evaluating VisualRAG: Quantifying Cross-Modal Performance in Enterprise Document Understanding", "authors": ["Varun Mannam", "Fang Wang", "Xin Chen"], "abstract": "Current evaluation frameworks for multimodal generative AI struggle to establish trustworthiness, hindering enterprise adoption where reliability is paramount. We introduce a systematic, quantitative benchmarking framework to measure the trustworthiness of progressively integrating cross-modal inputs such as text, images, captions, and OCR within VisualRAG systems for enterprise document intelligence. Our approach establishes quantitative relationships between technical metrics and user-centric trust measures. Evaluation reveals that optimal modality weighting with weights of 30% text, 15% image, 25% caption, and 30% OCR improves performance by 57.3% over text-only baselines while maintaining computational efficiency. We provide comparative assessments of foundation models, demonstrating their differential impact on trustworthiness in caption generation and OCR extraction-a vital consideration for reliable enterprise AI. This work advances responsible AI deployment by providing a rigorous framework for quantifying and enhancing trustworthiness in multimodal RAG for critical enterprise applications.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2506.21604.pdf", "abstract_url": "https://arxiv.org/abs/2506.21604", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)", "Human-Computer Interaction (cs.HC)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了一个系统化、量化的基准测试框架，用于评估VisualRAG系统在企业文档理解中跨模态输入的信任度，通过优化模态权重显著提升了性能。", "motivation": "当前的多模态生成AI评估框架难以建立信任度，阻碍了在企业中的采用，尤其是在可靠性至关重要的场景。", "method": "引入了一个系统化、量化的基准测试框架，通过技术指标和以用户为中心的信任度量之间的定量关系，评估跨模态输入的信任度。", "result": "研究发现，最优的模态权重（30%文本、15%图像、25%标题、30%OCR）比纯文本基线提高了57.3%的性能，同时保持了计算效率。", "conclusion": "这项工作通过提供一个严格的框架来量化和增强多模态RAG在关键企业应用中的信任度，推动了负责任AI的部署。"}}
{"id": "2506.21596", "title": "Evaluating Multimodal Large Language Models on Educational Textbook Question Answering", "authors": ["Hessa A. Alawwad", "Anas Zafar", "Areej Alhothali", "Usman Naseem", "Ali Alkhathlan", "Amani Jamal"], "abstract": "Multimodal large language models (MLLMs) have recently achieved significant success in vision--language tasks. However, their capacity to reason over complex, long lessons and intricate educational diagrams that cannot be represented as a single natural image remains largely untested. In this work, we present the first evaluation of state-of-the-art MLLMs on the textbook question answering (TQA) task using the CK12-QA dataset. We assess the performance of recent vision-language models, including LLaVA and LLaMA 3.2-Vision, across various input configurations. Additionally, we introduce a lightweight multimodal retrieval-augmented generation (RAG) pipeline that integrates both paragraphs and diagrams from the lesson into the prompt. Our results demonstrate the influence of retrieved educational context on model accuracy and reasoning, while also revealing current limitations in handling question-context relationships and the potential for noise, pointing to key directions for future research in multimodal AI-driven learning.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": "7 Pages", "pdf_url": "https://arxiv.org/pdf/2506.21596.pdf", "abstract_url": "https://arxiv.org/abs/2506.21596", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文首次评估了多模态大语言模型（MLLMs）在教育教科书问答任务上的表现，使用CK12-QA数据集测试了包括LLaVA和LLaMA 3.2-Vision在内的最新视觉语言模型，并引入了一个轻量级的多模态检索增强生成（RAG）管道。", "motivation": "尽管多模态大语言模型在视觉-语言任务上取得了显著成功，但它们在处理复杂的长期课程和无法表示为单一自然图像的复杂教育图表方面的能力尚未得到充分测试。", "method": "研究使用CK12-QA数据集评估了最新的视觉语言模型，并引入了一个轻量级的多模态检索增强生成（RAG）管道，该管道将课程中的段落和图表整合到提示中。", "result": "结果表明，检索到的教育背景对模型的准确性和推理有影响，同时也揭示了当前在处理问题-上下文关系和潜在噪声方面的局限性。", "conclusion": "这项研究揭示了多模态AI驱动学习中的关键研究方向，包括改进模型对复杂教育内容的理解和处理能力。"}}
{"id": "2506.21605", "title": "MemBench: Towards More Comprehensive Evaluation on the Memory of LLM-based Agents", "authors": ["Haoran Tan", "Zeyu Zhang", "Chen Ma", "Xu Chen", "Quanyu Dai", "Zhenhua Dong"], "abstract": "Recent works have highlighted the significance of memory mechanisms in LLM-based agents, which enable them to store observed information and adapt to dynamic environments. However, evaluating their memory capabilities still remains challenges. Previous evaluations are commonly limited by the diversity of memory levels and interactive scenarios. They also lack comprehensive metrics to reflect the memory capabilities from multiple aspects. To address these problems, in this paper, we construct a more comprehensive dataset and benchmark to evaluate the memory capability of LLM-based agents. Our dataset incorporates factual memory and reflective memory as different levels, and proposes participation and observation as various interactive scenarios. Based on our dataset, we present a benchmark, named MemBench, to evaluate the memory capability of LLM-based agents from multiple aspects, including their effectiveness, efficiency, and capacity. To benefit the research community, we release our dataset and project at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "17 pages, 5 figures. Accepted by ACL 2025 findings", "pdf_url": "https://arxiv.org/pdf/2506.21605.pdf", "abstract_url": "https://arxiv.org/abs/2506.21605", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了MemBench，一个更全面的数据集和基准测试，用于评估基于LLM的代理的记忆能力。", "motivation": "现有的评估方法在记忆级别和交互场景的多样性上存在局限，且缺乏从多角度反映记忆能力的综合指标。", "method": "构建了一个包含事实记忆和反思记忆不同级别，以及参与和观察不同交互场景的数据集，并提出了MemBench基准测试。", "result": "MemBench能够从有效性、效率和容量多方面评估基于LLM的代理的记忆能力。", "conclusion": "MemBench为研究社区提供了一个更全面的工具来评估和改进基于LLM的代理的记忆能力。"}}
{"id": "2506.21607", "title": "CORE-KG: An LLM-Driven Knowledge Graph Construction Framework for Human Smuggling Networks", "authors": ["Dipak Meher", "Carlotta Domeniconi", "Guadalupe Correa-Cabrera"], "abstract": "Human smuggling networks are increasingly adaptive and difficult to analyze. Legal case documents offer valuable insights but are unstructured, lexically dense, and filled with ambiguous or shifting references-posing challenges for automated knowledge graph (KG) construction. Existing KG methods often rely on static templates and lack coreference resolution, while recent LLM-based approaches frequently produce noisy, fragmented graphs due to hallucinations, and duplicate nodes caused by a lack of guided extraction. We propose CORE-KG, a modular framework for building interpretable KGs from legal texts. It uses a two-step pipeline: (1) type-aware coreference resolution via sequential, structured LLM prompts, and (2) entity and relationship extraction using domain-guided instructions, built on an adapted GraphRAG framework. CORE-KG reduces node duplication by 33.28%, and legal noise by 38.37% compared to a GraphRAG-based baseline-resulting in cleaner and more coherent graph structures. These improvements make CORE-KG a strong foundation for analyzing complex criminal networks.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.21607.pdf", "abstract_url": "https://arxiv.org/abs/2506.21607", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "CORE-KG是一个基于LLM的知识图谱构建框架，旨在从法律文书中构建人类走私网络的可解释知识图谱。", "motivation": "人类走私网络日益适应性强且难以分析，法律案例文档虽提供宝贵见解，但因其非结构化、词汇密集且充满模糊或变化的引用，给自动化知识图谱构建带来挑战。", "method": "CORE-KG采用两步流程：1)通过顺序、结构化的LLM提示进行类型感知的共指消解；2)使用领域指导的指令进行实体和关系提取，基于改进的GraphRAG框架。", "result": "与基于GraphRAG的基线相比，CORE-KG减少了33.28%的节点重复和38.37%的法律噪音，产生了更清晰、更连贯的图结构。", "conclusion": "CORE-KG的改进使其成为分析复杂犯罪网络的坚实基础。"}}
{"id": "2506.21876", "title": "Do Vision-Language Models Have Internal World Models? Towards an Atomic Evaluation", "authors": ["Qiyue Gao", "Xinyu Pi", "Kevin Liu", "Junrong Chen", "Ruolan Yang", "Xinqi Huang", "Xinyu Fang", "Lu Sun", "Gautham Kishore", "Bo Ai", "Stone Tao", "Mengyang Liu", "Jiaxi Yang", "Chao-Jung Lai", "Chuanyang Jin", "Jiannan Xiang", "Benhao Huang", "Zeming Chen", "David Danks", "Hao Su", "Tianmin Shu", "Ziqiao Ma", "Lianhui Qin", "Zhiting Hu"], "abstract": "Internal world models (WMs) enable agents to understand the world's state and predict transitions, serving as the basis for advanced deliberative reasoning. Recent large Vision-Language Models (VLMs), such as OpenAI o3, GPT-4o and Gemini, exhibit potential as general-purpose WMs. While the latest studies have evaluated and shown limitations in specific capabilities such as visual understanding, a systematic evaluation of VLMs' fundamental WM abilities remains absent. Drawing on comparative psychology and cognitive science, we propose a two-stage framework that assesses Perception (visual, spatial, temporal, quantitative, and motion) and Prediction (mechanistic simulation, transitive inference, compositional inference) to provide an atomic evaluation of VLMs as WMs. Guided by this framework, we introduce WM-ABench, a large-scale benchmark comprising 23 fine-grained evaluation dimensions across 6 diverse simulated environments with controlled counterfactual simulations. Through 660 experiments on 15 latest commercial and open-source VLMs, we find that these models exhibit striking limitations in basic world modeling abilities. For instance, almost all models perform at near-random accuracy when distinguishing motion trajectories. Additionally, they lack disentangled understanding -- e.g., some models tend to believe blue objects move faster than green ones. More rich results and analyses reveal significant gaps between VLMs and human-level world modeling.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "comments": "ACL 2025 (Findings)", "pdf_url": "https://arxiv.org/pdf/2506.21876.pdf", "abstract_url": "https://arxiv.org/abs/2506.21876", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一个两阶段框架来评估视觉语言模型（VLMs）作为内部世界模型（WMs）的基本能力，发现现有模型在基本世界建模能力上存在显著限制。", "motivation": "评估视觉语言模型是否具备内部世界模型的能力，以填补现有研究在系统性评估VLMs基础WM能力方面的空白。", "method": "采用比较心理学和认知科学的视角，提出了一个两阶段评估框架，包括感知（视觉、空间、时间、数量和运动）和预测（机械模拟、传递推理、组合推理），并引入了WM-ABench大规模基准测试。", "result": "通过对15个最新商业和开源VLMs的660次实验，发现这些模型在基本世界建模能力上存在显著限制，例如在区分运动轨迹时准确率接近随机，且缺乏解耦理解能力。", "conclusion": "研究表明，现有VLMs与世界模型的人类水平存在显著差距，揭示了在高级审议推理能力方面的局限性。"}}
{"id": "2506.21934", "title": "CAL-RAG: Retrieval-Augmented Multi-Agent Generation for Content-Aware Layout Design", "authors": ["Najmeh Forouzandehmehr", "Reza Yousefi Maragheh", "Sriram Kollipara", "Kai Zhao", "Topojoy Biswas", "Evren Korpeoglu", "Kannan Achan"], "abstract": "Automated content-aware layout generation -- the task of arranging visual elements such as text, logos, and underlays on a background canvas -- remains a fundamental yet under-explored problem in intelligent design systems. While recent advances in deep generative models and large language models (LLMs) have shown promise in structured content generation, most existing approaches lack grounding in contextual design exemplars and fall short in handling semantic alignment and visual coherence. In this work we introduce CAL-RAG, a retrieval-augmented, agentic framework for content-aware layout generation that integrates multimodal retrieval, large language models, and collaborative agentic reasoning. Our system retrieves relevant layout examples from a structured knowledge base and invokes an LLM-based layout recommender to propose structured element placements. A vision-language grader agent evaluates the layout with visual metrics, and a feedback agent provides targeted refinements, enabling iterative improvement. We implement our framework using LangGraph and evaluate it on the PKU PosterLayout dataset, a benchmark rich in semantic and structural variability. CAL-RAG achieves state-of-the-art performance across multiple layout metrics -- including underlay effectiveness, element alignment, and overlap -- substantially outperforming strong baselines such as LayoutPrompter. These results demonstrate that combining retrieval augmentation with agentic multi-step reasoning yields a scalable, interpretable, and high-fidelity solution for automated layout generation.", "subjects": "Information Retrieval (cs.IR); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.21934.pdf", "abstract_url": "https://arxiv.org/abs/2506.21934", "categories": ["Information Retrieval (cs.IR)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent", "agentic", "@RAG"], "AI": {"tldr": "CAL-RAG是一个基于检索增强的多代理框架，用于内容感知的布局设计，通过结合多模态检索、大型语言模型和协作代理推理，实现了自动化布局生成的高性能和可解释性。", "motivation": "解决自动化内容感知布局生成任务中缺乏上下文设计范例和语义对齐、视觉连贯性不足的问题。", "method": "采用检索增强的代理框架，包括多模态检索、基于LLM的布局推荐器、视觉语言评分代理和反馈代理，实现迭代改进。", "result": "在PKU PosterLayout数据集上，CAL-RAG在多个布局指标上达到了最先进的性能，显著优于LayoutPrompter等强基线。", "conclusion": "结合检索增强和代理多步推理，为自动化布局生成提供了一个可扩展、可解释且高保真的解决方案。"}}
{"id": "2506.21976", "title": "SceneDiffuser++: City-Scale Traffic Simulation via a Generative World Model", "authors": ["Shuhan Tan", "John Lambert", "Hong Jeon", "Sakshum Kulshrestha", "Yijing Bai", "Jing Luo", "Dragomir Anguelov", "Mingxing Tan", "Chiyu Max Jiang"], "abstract": "The goal of traffic simulation is to augment a potentially limited amount of manually-driven miles that is available for testing and validation, with a much larger amount of simulated synthetic miles. The culmination of this vision would be a generative simulated city, where given a map of the city and an autonomous vehicle (AV) software stack, the simulator can seamlessly simulate the trip from point A to point B by populating the city around the AV and controlling all aspects of the scene, from animating the dynamic agents (e.g., vehicles, pedestrians) to controlling the traffic light states. We refer to this vision as CitySim, which requires an agglomeration of simulation technologies: scene generation to populate the initial scene, agent behavior modeling to animate the scene, occlusion reasoning, dynamic scene generation to seamlessly spawn and remove agents, and environment simulation for factors such as traffic lights. While some key technologies have been separately studied in various works, others such as dynamic scene generation and environment simulation have received less attention in the research community. We propose SceneDiffuser++, the first end-to-end generative world model trained on a single loss function capable of point A-to-B simulation on a city scale integrating all the requirements above. We demonstrate the city-scale traffic simulation capability of SceneDiffuser++ and study its superior realism under long simulation conditions. We evaluate the simulation quality on an augmented version of the Waymo Open Motion Dataset (WOMD) with larger map regions to support trip-level simulation.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Multiagent Systems (cs.MA); Robotics (cs.RO)", "comments": "Accepted to CVPR 2025", "pdf_url": "https://arxiv.org/pdf/2506.21976.pdf", "abstract_url": "https://arxiv.org/abs/2506.21976", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)", "Multiagent Systems (cs.MA)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "SceneDiffuser++是一种生成式世界模型，旨在通过单一损失函数训练，实现城市规模的从点A到点B的交通模拟，整合了场景生成、代理行为建模、遮挡推理、动态场景生成和环境模拟等技术。", "motivation": "解决交通模拟中手动驾驶里程有限的问题，通过生成式模拟城市，为自动驾驶软件堆栈提供大量合成里程进行测试和验证。", "method": "提出SceneDiffuser++，一个端到端的生成式世界模型，使用单一损失函数训练，整合了城市规模交通模拟所需的所有技术。", "result": "在增强版的Waymo开放运动数据集上展示了SceneDiffuser++的城市规模交通模拟能力，并在长期模拟条件下研究了其卓越的真实感。", "conclusion": "SceneDiffuser++为城市规模交通模拟提供了一种高效的解决方案，能够生成高质量的合成里程，支持自动驾驶技术的测试和验证。"}}
{"id": "2506.21608", "title": "SysTemp: A Multi-Agent System for Template-Based Generation of SysML v2", "authors": ["Yasmine Bouamra", "Bruno Yun", "Alexandre Poisson", "Frédéric Armetta"], "abstract": "The automatic generation of SysML v2 models represents a major challenge in the engineering of complex systems, particularly due to the scarcity of learning corpora and complex syntax. We present SysTemp, a system aimed at facilitating and improving the creation of SysML v2 models from natural language specifications. It is based on a multi-agent system, including a template generator that structures the generation process. We discuss the advantages and challenges of this system through an evaluation, highlighting its potential to improve the quality of the generations in SysML v2 modeling.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.21608.pdf", "abstract_url": "https://arxiv.org/abs/2506.21608", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "SysTemp是一个多代理系统，旨在通过自然语言规范促进和改进SysML v2模型的创建。它基于一个包括模板生成器在内的多代理系统，结构化生成过程。", "motivation": "解决复杂系统工程中SysML v2模型自动生成的主要挑战，特别是学习语料库稀缺和语法复杂的问题。", "method": "采用多代理系统，包括一个模板生成器，以结构化生成过程。", "result": "通过评估讨论了该系统的优势和挑战，突出了其在提高SysML v2建模生成质量方面的潜力。", "conclusion": "SysTemp系统展示了通过自然语言规范改进SysML v2模型生成的潜力，为复杂系统工程提供了有价值的工具。"}}
{"id": "2506.21615", "title": "Refine Medical Diagnosis Using Generation Augmented Retrieval and Clinical Practice Guidelines", "authors": ["Wenhao Li", "Hongkuan Zhang", "Hongwei Zhang", "Zhengxu Li", "Zengjie Dong", "Yafan Chen", "Niranjan Bidargaddi", "Hong Liu"], "abstract": "Current medical language models, adapted from large language models (LLMs), typically predict ICD code-based diagnosis from electronic health records (EHRs) because these labels are readily available. However, ICD codes do not capture the nuanced, context-rich reasoning clinicians use for diagnosis. Clinicians synthesize diverse patient data and reference clinical practice guidelines (CPGs) to make evidence-based decisions. This misalignment limits the clinical utility of existing models. We introduce GARMLE-G, a Generation-Augmented Retrieval framework that grounds medical language model outputs in authoritative CPGs. Unlike conventional Retrieval-Augmented Generation based approaches, GARMLE-G enables hallucination-free outputs by directly retrieving authoritative guideline content without relying on model-generated text. It (1) integrates LLM predictions with EHR data to create semantically rich queries, (2) retrieves relevant CPG knowledge snippets via embedding similarity, and (3) fuses guideline content with model output to generate clinically aligned recommendations. A prototype system for hypertension diagnosis was developed and evaluated on multiple metrics, demonstrating superior retrieval precision, semantic relevance, and clinical guideline adherence compared to RAG-based baselines, while maintaining a lightweight architecture suitable for localized healthcare deployment. This work provides a scalable, low-cost, and hallucination-free method for grounding medical language models in evidence-based clinical practice, with strong potential for broader clinical deployment.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.21615.pdf", "abstract_url": "https://arxiv.org/abs/2506.21615", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了GARMLE-G，一种生成增强检索框架，旨在通过直接检索权威临床实践指南内容，而非依赖模型生成的文本，来减少医疗语言模型的幻觉输出，从而提高医疗诊断的准确性和临床实用性。", "motivation": "现有的医疗语言模型通常基于电子健康记录（EHRs）预测ICD代码诊断，但这些代码无法捕捉临床医生用于诊断的丰富上下文和细微差别。这种不一致性限制了现有模型的临床实用性。", "method": "GARMLE-G框架通过（1）整合LLM预测与EHR数据创建语义丰富的查询，（2）通过嵌入相似性检索相关的CPG知识片段，（3）将指南内容与模型输出融合以生成临床对齐的建议，来实现无幻觉的输出。", "result": "开发了一个用于高血压诊断的原型系统，并在多个指标上进行了评估，显示出在检索精度、语义相关性和临床指南遵循方面优于基于RAG的基线，同时保持了适合本地化医疗部署的轻量级架构。", "conclusion": "这项工作提供了一种可扩展、低成本且无幻觉的方法，用于将医疗语言模型基于证据的临床实践中，具有广泛的临床部署潜力。"}}
{"id": "2506.21967", "title": "More Vulnerable than You Think: On the Stability of Tool-Integrated LLM Agents", "authors": ["Weimin Xiong", "Ke Wang", "Yifan Song", "Hanchao Liu", "Sai Zhou", "Wei Peng", "Sujian Li"], "abstract": "Current evaluations of tool-integrated LLM agents typically focus on end-to-end tool-usage evaluation while neglecting their stability. This limits their real-world applicability, as various internal or external factors can cause agents to crash or behave abnormally. Our research addresses this by investigating whether agents are vulnerable to errors throughout the entire tool invocation process, including reading tool documentation, selecting tools and generating parameters, and processing the tool's response. Through extensive experiments, we observe that agents are highly susceptible to errors at each stage and agents based on open-source models are more vulnerable than those based on proprietary models. We also find that increasing the model size does not significantly improve tool invocation reasoning and may make agents more vulnerable to attacks resembling normal user instructions. This highlights the importance of evaluating agent stability and offers valuable insights for future LLM development and evaluation.", "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.21967.pdf", "abstract_url": "https://arxiv.org/abs/2506.21967", "categories": ["Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "当前对工具集成LLM代理的评估通常侧重于端到端的工具使用评估，而忽视了它们的稳定性。我们的研究通过调查代理在整个工具调用过程中是否容易出错来解决这一问题，包括阅读工具文档、选择工具和生成参数以及处理工具的响应。通过大量实验，我们观察到代理在每个阶段都非常容易出错，并且基于开源模型的代理比基于专有模型的代理更容易受到攻击。我们还发现，增加模型大小并不能显著提高工具调用推理，反而可能使代理更容易受到类似于正常用户指令的攻击。这突出了评估代理稳定性的重要性，并为未来的LLM开发和评估提供了宝贵的见解。", "motivation": "解决工具集成LLM代理在稳定性方面的问题，因为当前的评估忽视了这一点，限制了它们在现实世界中的适用性。", "method": "通过调查代理在整个工具调用过程中是否容易出错，包括阅读工具文档、选择工具和生成参数以及处理工具的响应，进行大量实验。", "result": "代理在每个阶段都非常容易出错，基于开源模型的代理比基于专有模型的代理更容易受到攻击。增加模型大小并不能显著提高工具调用推理，反而可能使代理更容易受到类似于正常用户指令的攻击。", "conclusion": "评估代理稳定性的重要性被突出，为未来的LLM开发和评估提供了宝贵的见解。"}}
{"id": "2506.21974", "title": "Don't Trust Generative Agents to Mimic Communication on Social Networks Unless You Benchmarked their Empirical Realism", "authors": ["Simon Münker", "Nils Schwager", "Achim Rettinger"], "abstract": "The ability of Large Language Models (LLMs) to mimic human behavior triggered a plethora of computational social science research, assuming that empirical studies of humans can be conducted with AI agents instead. Since there have been conflicting research findings on whether and when this hypothesis holds, there is a need to better understand the differences in their experimental designs. We focus on replicating the behavior of social network users with the use of LLMs for the analysis of communication on social networks. First, we provide a formal framework for the simulation of social networks, before focusing on the sub-task of imitating user communication. We empirically test different approaches to imitate user behavior on X in English and German. Our findings suggest that social simulations should be validated by their empirical realism measured in the setting in which the simulation components were fitted. With this paper, we argue for more rigor when applying generative-agent-based modeling for social simulation.", "subjects": "Computation and Language (cs.CL)", "comments": "11 pages, 1 figure, 3 tables", "pdf_url": "https://arxiv.org/pdf/2506.21974.pdf", "abstract_url": "https://arxiv.org/abs/2506.21974", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了大型语言模型（LLMs）在模仿社交网络用户行为方面的能力，强调了在进行社交模拟时需要更多的严谨性，并通过实证测试提出了验证社交模拟实证现实主义的重要性。", "motivation": "解决关于大型语言模型是否能准确模仿人类社交网络行为的研究结果不一致的问题，以及如何更好地理解和设计相关实验。", "method": "提供了一个社交网络模拟的正式框架，并专注于模仿用户通信的子任务，通过实证测试不同方法来模仿X（原Twitter）上英文和德文用户的行为。", "result": "研究发现，社交模拟应通过在其组件拟合的环境中测量的实证现实主义来验证，强调了在应用基于生成代理的社交模拟时需要更多的严谨性。", "conclusion": "本文主张在使用生成代理进行社交模拟时，应更加注重实证现实主义的验证，以确保研究的准确性和可靠性。"}}
{"id": "2506.21618", "title": "TrajTok: Technical Report for 2025 Waymo Open Sim Agents Challenge", "authors": ["Zhiyuan Zhang", "Xiaosong Jia", "Guanyu Chen", "Qifeng Li", "Junchi Yan"], "abstract": "In this technical report, we introduce TrajTok, a trajectory tokenizer for discrete next-token-prediction based behavior generation models, which combines data-driven and rule-based methods with better coverage, symmetry and robustness, along with a spatial-aware label smoothing method for cross-entropy loss. We adopt the tokenizer and loss for the SMART model and reach a superior performance with realism score of 0.7852 on the Waymo Open Sim Agents Challenge 2025. We will open-source the code in the future.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.21618.pdf", "abstract_url": "https://arxiv.org/abs/2506.21618", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了TrajTok，一种用于基于离散下一令牌预测的行为生成模型的轨迹令牌化器，结合了数据驱动和基于规则的方法，具有更好的覆盖性、对称性和鲁棒性，并提出了一种空间感知的标签平滑方法用于交叉熵损失。", "motivation": "解决在行为生成模型中如何更有效地进行轨迹预测和令牌化的问题，以提高模型的性能和现实感。", "method": "采用结合数据驱动和基于规则的方法的轨迹令牌化器TrajTok，以及空间感知的标签平滑方法用于交叉熵损失。", "result": "在2025年Waymo开放模拟代理挑战赛中，使用SMART模型和TrajTok令牌化器及损失函数，实现了0.7852的现实感分数，表现出色。", "conclusion": "TrajTok和空间感知标签平滑方法的结合显著提高了行为生成模型的性能和现实感，未来将开源代码。"}}
{"id": "2506.21727", "title": "Simultaneously Fair Allocation of Indivisible Items Across Multiple Dimensions", "authors": ["Yasushi Kawase", "Bodhayan Roy", "Mohammad Azharuddin Sanpui"], "abstract": "This paper explores the fair allocation of indivisible items in a multidimensional setting, motivated by the need to address fairness in complex environments where agents assess bundles according to multiple criteria. Such multidimensional settings are not merely of theoretical interest but are central to many real-world applications. For example, cloud computing resources are evaluated based on multiple criteria such as CPU cores, memory, and network bandwidth. In such cases, traditional one dimensional fairness notions fail to capture fairness across multiple attributes. To address these challenges, we study two relaxed variants of envy-freeness: weak simultaneously envy-free up to c goods (weak sEFc) and strong simultaneously envy-free up to c goods (strong sEFc), which accommodate the multidimensionality of agents' preferences. Under the weak notion, for every pair of agents and for each dimension, any perceived envy can be eliminated by removing, if necessary, a different set of goods from the envied agent's allocation. In contrast, the strong version requires selecting a single set of goods whose removal from the envied bundle simultaneously eliminates envy in every dimension. We provide upper and lower bounds on the relaxation parameter c that guarantee the existence of weak or strong sEFc allocations, where these bounds are independent of the total number of items. In addition, we present algorithms for checking whether a weak or strong sEFc allocation exists. Moreover, we establish NP-hardness results for checking the existence of weak sEF1 and strong sEF1 allocations.", "subjects": "Computer Science and Game Theory (cs.GT); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.21727.pdf", "abstract_url": "https://arxiv.org/abs/2506.21727", "categories": ["Computer Science and Game Theory (cs.GT)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了在多维环境下不可分割物品的公平分配问题，提出了弱和强两种松弛的嫉妒自由变体（weak sEFc和strong sEFc），并提供了保证这些分配存在的上下界，以及检查这些分配存在的算法和NP难解性结果。", "motivation": "解决在多维复杂环境中，传统一维公平概念无法捕捉多属性公平性的问题，如云计算资源的多标准评估。", "method": "研究两种松弛的嫉妒自由变体：weak sEFc和strong sEFc，提供保证分配存在的上下界，并提出检查分配存在的算法。", "result": "确定了保证weak或strong sEFc分配存在的上下界，这些界限与物品总数无关；提出了检查这些分配存在的算法；证明了检查weak sEF1和strong sEF1分配存在的NP难解性。", "conclusion": "在多维公平分配问题中，weak和strong sEFc提供了一种可行的解决方案，但检查某些分配的存在是计算上困难的。"}}
{"id": "2506.22366", "title": "Why Are Parsing Actions for Understanding Message Hierarchies Not Random?", "authors": ["Daichi Kato", "Ryo Ueda", "Yusuke Miyao"], "abstract": "If humans understood language by randomly selecting parsing actions, it might have been necessary to construct a robust symbolic system capable of being interpreted under any hierarchical structure. However, human parsing strategies do not seem to follow such a random pattern. Why is that the case? In fact, a previous study on emergent communication using models with hierarchical biases have reported that agents adopting random parsing strategies$\\unicode{x2013}$ones that deviate significantly from human language comprehension$\\unicode{x2013}$can achieve high communication accuracy. In this study, we investigate this issue by making two simple and natural modifications to the experimental setup: (I) we use more complex inputs that have hierarchical structures, such that random parsing makes semantic interpretation more difficult, and (II) we incorporate a surprisal-related term, which is known to influence the order of words and characters in natural language, into the objective function. With these changes, we evaluate whether agents employing random parsing strategies still maintain high communication accuracy.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.22366.pdf", "abstract_url": "https://arxiv.org/abs/2506.22366", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "探讨人类语言理解中解析行为非随机性的原因，通过引入更复杂的输入和惊讶相关项来评估随机解析策略的通信准确性。", "motivation": "解决为何人类语言理解中的解析行为不遵循随机模式的问题，以及随机解析策略在复杂输入和惊讶相关项影响下的表现。", "method": "通过使用具有层次结构的更复杂输入和将惊讶相关项纳入目标函数，评估随机解析策略的通信准确性。", "result": "在更复杂的输入和惊讶相关项的影响下，随机解析策略的通信准确性可能会受到影响。", "conclusion": "人类语言理解中的解析行为非随机性可能与输入的复杂性和惊讶相关项有关，随机解析策略在特定条件下可能不再高效。"}}
{"id": "2506.21872", "title": "A Survey of Continual Reinforcement Learning", "authors": ["Chaofan Pan", "Xin Yang", "Yanhua Li", "Wei Wei", "Tianrui Li", "Bo An", "Jiye Liang"], "abstract": "Reinforcement Learning (RL) is an important machine learning paradigm for solving sequential decision-making problems. Recent years have witnessed remarkable progress in this field due to the rapid development of deep neural networks. However, the success of RL currently relies on extensive training data and computational resources. In addition, RL's limited ability to generalize across tasks restricts its applicability in dynamic and real-world environments. With the arisen of Continual Learning (CL), Continual Reinforcement Learning (CRL) has emerged as a promising research direction to address these limitations by enabling agents to learn continuously, adapt to new tasks, and retain previously acquired knowledge. In this survey, we provide a comprehensive examination of CRL, focusing on its core concepts, challenges, and methodologies. Firstly, we conduct a detailed review of existing works, organizing and analyzing their metrics, tasks, benchmarks, and scenario settings. Secondly, we propose a new taxonomy of CRL methods, categorizing them into four types from the perspective of knowledge storage and/or transfer. Finally, our analysis highlights the unique challenges of CRL and provides practical insights into future directions.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "This work has been submitted to the IEEE TPAMI", "pdf_url": "https://arxiv.org/pdf/2506.21872.pdf", "abstract_url": "https://arxiv.org/abs/2506.21872", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文是对持续强化学习（CRL）的全面调查，探讨了其核心概念、挑战和方法论，提出了新的分类法，并分析了未来研究方向。", "motivation": "解决传统强化学习（RL）在动态和现实世界环境中泛化能力有限、依赖大量训练数据和计算资源的问题。", "method": "通过详细回顾现有工作，组织和分析其指标、任务、基准和场景设置，提出基于知识存储和/或转移的CRL方法新分类法。", "result": "提出了CRL的四种类型分类法，并强调了CRL的独特挑战。", "conclusion": "CRL是一个有前途的研究方向，能够使代理持续学习、适应新任务并保留先前获得的知识，本文为未来的研究提供了实用的见解。"}}
{"id": "2506.21931", "title": "ARAG: Agentic Retrieval Augmented Generation for Personalized Recommendation", "authors": ["Reza Yousefi Maragheh", "Pratheek Vadla", "Priyank Gupta", "Kai Zhao", "Aysenur Inan", "Kehui Yao", "Jianpeng Xu", "Praveen Kanumala", "Jason Cho", "Sushant Kumar"], "abstract": "Retrieval-Augmented Generation (RAG) has shown promise in enhancing recommendation systems by incorporating external context into large language model prompts. However, existing RAG-based approaches often rely on static retrieval heuristics and fail to capture nuanced user preferences in dynamic recommendation scenarios. In this work, we introduce ARAG, an Agentic Retrieval-Augmented Generation framework for Personalized Recommendation, which integrates a multi-agent collaboration mechanism into the RAG pipeline. To better understand the long-term and session behavior of the user, ARAG leverages four specialized LLM-based agents: a User Understanding Agent that summarizes user preferences from long-term and session contexts, a Natural Language Inference (NLI) Agent that evaluates semantic alignment between candidate items retrieved by RAG and inferred intent, a context summary agent that summarizes the findings of NLI agent, and an Item Ranker Agent that generates a ranked list of recommendations based on contextual fit. We evaluate ARAG accross three datasets. Experimental results demonstrate that ARAG significantly outperforms standard RAG and recency-based baselines, achieving up to 42.1% improvement in NDCG@5 and 35.5% in Hit@5. We also, conduct an ablation study to analyse the effect by different components of ARAG. Our findings highlight the effectiveness of integrating agentic reasoning into retrieval-augmented recommendation and provide new directions for LLM-based personalization.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.21931.pdf", "abstract_url": "https://arxiv.org/abs/2506.21931", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic", "@RAG"], "AI": {"tldr": "ARAG是一个用于个性化推荐的代理检索增强生成框架，通过多代理协作机制改进传统RAG方法，显著提升推荐效果。", "motivation": "解决现有基于RAG的推荐系统在动态推荐场景中无法捕捉细微用户偏好的问题。", "method": "引入多代理协作机制，包括用户理解代理、自然语言推理代理、上下文总结代理和项目排名代理，以更好地理解和适应用户行为。", "result": "在三个数据集上的实验显示，ARAG在NDCG@5和Hit@5上分别实现了高达42.1%和35.5%的改进。", "conclusion": "将代理推理整合到检索增强推荐中有效，为基于LLM的个性化提供了新方向。"}}
{"id": "2506.21865", "title": "RiverEcho: Real-Time Interactive Digital System for Ancient Yellow River Culture", "authors": ["Haofeng Wang", "Yilin Guo", "Zehao Li", "Tong Yue", "Yizong Wang", "Enci Zhang", "Rongqun Lin", "Feng Gao", "Shiqi Wang", "Siwei Ma"], "abstract": "The Yellow River is China's mother river and a cradle of human civilization. The ancient Yellow River culture is, moreover, an indispensable part of human art history. To conserve and inherit the ancient Yellow River culture, we designed RiverEcho, a real-time interactive system that responds to voice queries using a large language model and a cultural knowledge dataset, delivering explanations through a talking-head digital human. Specifically, we built a knowledge database focused on the ancient Yellow River culture, including the collection of historical texts and the processing pipeline. Experimental results demonstrate that leveraging Retrieval-Augmented Generation (RAG) on the proposed dataset enhances the response quality of the Large Language Model(LLM), enabling the system to generate more professional and informative responses. Our work not only diversifies the means of promoting Yellow River culture but also provides users with deeper cultural insights.", "subjects": "Multimedia (cs.MM); Computation and Language (cs.CL)", "comments": "IEEE International Conference on Multimedia and Expo Workshop, 2025.(Accepted)", "pdf_url": "https://arxiv.org/pdf/2506.21865.pdf", "abstract_url": "https://arxiv.org/abs/2506.21865", "categories": ["Multimedia (cs.MM)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了RiverEcho，一个实时交互式数字系统，旨在保护和传承古代黄河文化。该系统通过大型语言模型和文化知识数据集响应语音查询，并通过数字人头部动画提供解释。", "motivation": "黄河是中国的母亲河，也是人类文明的摇篮。古代黄河文化是人类艺术史不可或缺的一部分。为了保护和传承这一文化，设计了RiverEcho系统。", "method": "系统构建了一个专注于古代黄河文化的知识数据库，包括历史文本的收集和处理流程。利用检索增强生成（RAG）技术提高大型语言模型（LLM）的响应质量。", "result": "实验结果表明，RAG技术在提出的数据集上增强了LLM的响应质量，使系统能够生成更专业和信息丰富的回答。", "conclusion": "这项工作不仅丰富了推广黄河文化的手段，还为用户提供了更深层次的文化洞察。"}}
{"id": "2506.22008", "title": "TROFI: Trajectory-Ranked Offline Inverse Reinforcement Learning", "authors": ["Alessandro Sestini", "Joakim Bergdahl", "Konrad Tollmar", "Andrew D. Bagdanov", "Linus Gisslén"], "abstract": "In offline reinforcement learning, agents are trained using only a fixed set of stored transitions derived from a source policy. However, this requires that the dataset be labeled by a reward function. In applied settings such as video game development, the availability of the reward function is not always guaranteed. This paper proposes Trajectory-Ranked OFfline Inverse reinforcement learning (TROFI), a novel approach to effectively learn a policy offline without a pre-defined reward function. TROFI first learns a reward function from human preferences, which it then uses to label the original dataset making it usable for training the policy. In contrast to other approaches, our method does not require optimal trajectories. Through experiments on the D4RL benchmark we demonstrate that TROFI consistently outperforms baselines and performs comparably to using the ground truth reward to learn policies. Additionally, we validate the efficacy of our method in a 3D game environment. Our studies of the reward model highlight the importance of the reward function in this setting: we show that to ensure the alignment of a value function to the actual future discounted reward, it is fundamental to have a well-engineered and easy-to-learn reward function.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "Published at Reinforcement Learning and Video Games Workshop at RLC 2025", "pdf_url": "https://arxiv.org/pdf/2506.22008.pdf", "abstract_url": "https://arxiv.org/abs/2506.22008", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了TROFI，一种无需预定义奖励函数的离线强化学习方法，通过从人类偏好中学习奖励函数来标记数据集，用于策略训练。", "motivation": "解决在离线强化学习中，当奖励函数不可用时，如何有效学习策略的问题。", "method": "提出TROFI方法，首先从人类偏好中学习奖励函数，然后用该函数标记原始数据集，用于策略训练。", "result": "在D4RL基准测试中，TROFI consistently outperforms baselines and performs comparably to using the ground truth reward to learn policies。", "conclusion": "研究表明，奖励函数的设计对确保价值函数与未来折扣奖励的对齐至关重要。"}}
{"id": "2506.22189", "title": "Exploring Modularity of Agentic Systems for Drug Discovery", "authors": ["Laura van Weesep", "Samuel Genheden", "Ola Engkvist", "Jens Sjölund"], "abstract": "Large-language models (LLMs) and agentic systems present exciting opportunities to accelerate drug discovery and design. In this study, we critically examine the modularity of LLM-based agentic systems for drug discovery, i.e., whether parts of the agentic system such as the LLM are interchangeable, a topic that has received limited attention in drug discovery applications. We compare the performance of different large language models (LLMs) and the effectiveness of tool-calling agents versus code-generating agents in this domain. Our case study, comparing performance in orchestrating tools for chemistry and drug discovery using an LLM-as-a-judge score, shows that Claude-3.5-Sonnet, Claude-3.7-Sonnet and GPT-4o outperform alternative language models such as Llama-3.1-8B, Llama-3.1-70B, GPT-3.5-Turbo, and Nova-Micro. Although we confirm that code-generating agents outperform the tool-calling ones on average, we show that this is highly question and model dependent. Furthermore, the impact of replacing system prompts is dependent on the specific question asked and the model used, underscoring that -- even in this particular domain -- one cannot just replace language models without considering prompt re-engineering. Our study highlights the necessity of further research into the modularity of agentic systems to enable the development of stable and scalable solutions for real-world problems.", "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.22189.pdf", "abstract_url": "https://arxiv.org/abs/2506.22189", "categories": ["Machine Learning (cs.LG)", "Computation and Language (cs.CL)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本研究探讨了基于大型语言模型（LLMs）的代理系统在药物发现领域的模块化问题，比较了不同LLMs的性能以及工具调用代理与代码生成代理的有效性。研究发现Claude-3.5-Sonnet、Claude-3.7-Sonnet和GPT-4o在药物发现工具编排中表现优于其他模型，且代码生成代理平均表现更佳，但这一结果高度依赖于问题和模型。研究强调了进一步研究代理系统模块化的必要性。", "motivation": "大型语言模型（LLMs）和代理系统为加速药物发现和设计提供了激动人心的机会。然而，这些系统中如LLM等部分的互换性在药物发现应用中受到的关注有限。本研究旨在填补这一空白，探索代理系统模块化的可行性及其对性能的影响。", "method": "研究通过比较不同大型语言模型（LLMs）的性能，以及工具调用代理与代码生成代理在药物发现领域的有效性，使用LLM-as-a-judge评分来评估模型在化学和药物发现工具编排中的表现。", "result": "研究发现Claude-3.5-Sonnet、Claude-3.7-Sonnet和GPT-4o在药物发现工具编排中表现优于Llama-3.1-8B、Llama-3.1-70B、GPT-3.5-Turbo和Nova-Micro。虽然代码生成代理平均表现优于工具调用代理，但这一结果高度依赖于具体问题和所用模型。此外，替换系统提示的影响也依赖于具体问题和模型。", "conclusion": "研究表明，在药物发现领域，不能简单地替换语言模型而不考虑提示的重新设计。这强调了进一步研究代理系统模块化的必要性，以开发出稳定且可扩展的解决方案来解决现实世界的问题。"}}
{"id": "2506.22026", "title": "Literature-Grounded Novelty Assessment of Scientific Ideas", "authors": ["Simra Shahid", "Marissa Radensky", "Raymond Fok", "Pao Siangliulue", "Daniel S. Weld", "Tom Hope"], "abstract": "Automated scientific idea generation systems have made remarkable progress, yet the automatic evaluation of idea novelty remains a critical and underexplored challenge. Manual evaluation of novelty through literature review is labor-intensive, prone to error due to subjectivity, and impractical at scale. To address these issues, we propose the Idea Novelty Checker, an LLM-based retrieval-augmented generation (RAG) framework that leverages a two-stage retrieve-then-rerank approach. The Idea Novelty Checker first collects a broad set of relevant papers using keyword and snippet-based retrieval, then refines this collection through embedding-based filtering followed by facet-based LLM re-ranking. It incorporates expert-labeled examples to guide the system in comparing papers for novelty evaluation and in generating literature-grounded reasoning. Our extensive experiments demonstrate that our novelty checker achieves approximately 13% higher agreement than existing approaches. Ablation studies further showcases the importance of the facet-based re-ranker in identifying the most relevant literature for novelty evaluation.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.22026.pdf", "abstract_url": "https://arxiv.org/abs/2506.22026", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种基于大型语言模型（LLM）的检索增强生成（RAG）框架——Idea Novelty Checker，用于自动评估科学想法的新颖性。通过两阶段的检索和重新排序方法，结合专家标记的示例，该系统在实验中显示出比现有方法高约13%的一致性。", "motivation": "自动化科学想法生成系统虽进展显著，但想法新颖性的自动评估仍是一个关键且未被充分探索的挑战。手动评估新颖性不仅劳动密集，而且由于主观性容易出错，且难以规模化。", "method": "提出的Idea Novelty Checker采用了两阶段的检索然后重新排序方法：首先通过关键词和片段检索收集广泛的相关论文，然后通过基于嵌入的过滤和基于方面的LLM重新排序来细化这一集合。系统还结合了专家标记的示例，以指导论文比较和新颖性评估。", "result": "广泛的实验表明，我们的新颖性检查器比现有方法实现了约13%更高的一致性。消融研究进一步展示了基于方面的重新排序在识别用于新颖性评估的最相关文献中的重要性。", "conclusion": "Idea Novelty Checker通过结合先进的检索和重新排序技术，以及专家知识，有效提高了科学想法新颖性评估的自动化和准确性，为科学研究的自动化评估提供了新的可能性。"}}
{"id": "2506.22185", "title": "Autonomic Microservice Management via Agentic AI and MAPE-K Integration", "authors": ["Matteo Esposito", "Alexander Bakhtin", "Noman Ahmad", "Mikel Robredo", "Ruoyu Su", "Valentina Lenarduzzi", "Davide Taibi"], "abstract": "While microservices are revolutionizing cloud computing by offering unparalleled scalability and independent deployment, their decentralized nature poses significant security and management challenges that can threaten system stability. We propose a framework based on MAPE-K, which leverages agentic AI, for autonomous anomaly detection and remediation to address the daunting task of highly distributed system management. Our framework offers practical, industry-ready solutions for maintaining robust and secure microservices. Practitioners and researchers can customize the framework to enhance system stability, reduce downtime, and monitor broader system quality attributes such as system performance level, resilience, security, and anomaly management, among others.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Networking and Internet Architecture (cs.NI); Systems and Control (eess.SY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.22185.pdf", "abstract_url": "https://arxiv.org/abs/2506.22185", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)", "Distributed, Parallel, and Cluster Computing (cs.DC)", "Networking and Internet Architecture (cs.NI)", "Systems and Control (eess.SY)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种基于MAPE-K和代理AI的框架，用于自主异常检测和修复，以解决微服务管理中的安全和稳定性挑战。", "motivation": "微服务在云计算中提供了无与伦比的可扩展性和独立部署能力，但其去中心化特性带来了安全和管理的重大挑战，威胁系统稳定性。", "method": "利用基于MAPE-K的框架和代理AI，实现自主异常检测和修复。", "result": "该框架为维护强大和安全的微服务提供了实用的、行业就绪的解决方案，可定制以增强系统稳定性、减少停机时间，并监控更广泛的系统质量属性。", "conclusion": "该框架为研究人员和从业者提供了增强微服务系统稳定性、安全性和性能的工具，具有广泛的应用前景。"}}
