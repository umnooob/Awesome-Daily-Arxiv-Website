{"id": "2506.09331", "title": "Multi-Agent Language Models: Advancing Cooperation, Coordination, and Adaptation", "authors": ["Arjun Vaithilingam Sudhakar"], "abstract": "Modern Large Language Models (LLMs) exhibit impressive zero-shot and few-shot generalization capabilities across complex natural language tasks, enabling their widespread use as virtual assistants for diverse applications such as translation and summarization. Despite being trained solely on large corpora of text without explicit supervision on author intent, LLMs appear to infer the underlying meaning of textual interactions. This raises a fundamental question: can LLMs model and reason about the intentions of others, i.e., do they possess a form of theory of mind? Understanding other's intentions is crucial for effective collaboration, which underpins human societal success and is essential for cooperative interactions among multiple agents, including humans and autonomous systems. In this work, we investigate the theory of mind in LLMs through the lens of cooperative multi-agent reinforcement learning (MARL), where agents learn to collaborate via repeated interactions, mirroring human social reasoning. Our approach aims to enhance artificial agent's ability to adapt and cooperate with both artificial and human partners. By leveraging LLM-based agents capable of natural language interaction, we move towards creating hybrid human-AI systems that can foster seamless collaboration, with broad implications for the future of human-artificial interaction.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2506.09331.pdf", "abstract_url": "https://arxiv.org/abs/2506.09331", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了大型语言模型（LLMs）是否具备理解他人意图的能力，即是否拥有心理理论，并通过多智能体强化学习（MARL）的视角进行研究，旨在提升人工智能代理与人类及人工伙伴的合作能力。", "motivation": "解决LLMs是否能理解和推理他人意图的问题，这对于有效协作至关重要，尤其是在多智能体（包括人类和自主系统）之间的合作互动中。", "method": "通过多智能体强化学习（MARL）框架，研究LLMs在重复互动中学习协作的能力，模拟人类的社会推理过程。", "result": "研究表明，基于LLM的智能体能够通过自然语言互动，增强与人工及人类伙伴的适应和合作能力。", "conclusion": "通过利用具备自然语言交互能力的LLM智能体，可以推动创建混合人机系统，促进无缝协作，对未来人机互动具有广泛影响。"}}
{"id": "2506.09469", "title": "Optimizing Cooperative Multi-Object Tracking using Graph Signal Processing", "authors": ["Maria Damanaki", "Nikos Piperigkos", "Alexandros Gkillas", "Aris S. Lalos"], "abstract": "Multi-Object Tracking (MOT) plays a crucial role in autonomous driving systems, as it lays the foundations for advanced perception and precise path planning modules. Nonetheless, single agent based MOT lacks in sensing surroundings due to occlusions, sensors failures, etc. Hence, the integration of multiagent information is essential for comprehensive understanding of the environment. This paper proposes a novel Cooperative MOT framework for tracking objects in 3D LiDAR scene by formulating and solving a graph topology-aware optimization problem so as to fuse information coming from multiple vehicles. By exploiting a fully connected graph topology defined by the detected bounding boxes, we employ the Graph Laplacian processing optimization technique to smooth the position error of bounding boxes and effectively combine them. In that manner, we reveal and leverage inherent coherences of diverse multi-agent detections, and associate the refined bounding boxes to tracked objects at two stages, optimizing localization and tracking accuracies. An extensive evaluation study has been conducted, using the real-world V2V4Real dataset, where the proposed method significantly outperforms the baseline frameworks, including the state-of-the-art deep-learning DMSTrack and V2V4Real, in various testing sequences.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "2025 IEEE International Conference on Multimedia and Expo Workshops, 3DMM - 3D Multimedia Analytics, Search and Generation", "pdf_url": "https://arxiv.org/pdf/2506.09469.pdf", "abstract_url": "https://arxiv.org/abs/2506.09469", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新颖的协作多目标跟踪（Cooperative MOT）框架，通过图信号处理技术优化3D LiDAR场景中的多车辆信息融合，显著提高了定位和跟踪精度。", "motivation": "解决单代理多目标跟踪（MOT）在自动驾驶系统中因遮挡、传感器故障等问题导致的感知不足，通过多代理信息整合实现环境的全面理解。", "method": "利用检测到的边界框定义的全连接图拓扑，应用图拉普拉斯处理优化技术平滑边界框的位置误差，并在两个阶段关联精炼的边界框与跟踪对象。", "result": "在真实世界的V2V4Real数据集上的广泛评估表明，该方法在多种测试序列中显著优于基线框架，包括最先进的深度学习DMSTrack和V2V4Real。", "conclusion": "通过图拓扑感知优化问题，本文提出的协作MOT框架有效地融合了多车辆信息，提高了多目标跟踪的准确性和鲁棒性。"}}
{"id": "2506.09176", "title": "Robot-Gated Interactive Imitation Learning with Adaptive Intervention Mechanism", "authors": ["Haoyuan Cai", "Zhenghao Peng", "Bolei Zhou"], "abstract": "Interactive Imitation Learning (IIL) allows agents to acquire desired behaviors through human interventions, but current methods impose high cognitive demands on human supervisors. We propose the Adaptive Intervention Mechanism (AIM), a novel robot-gated IIL algorithm that learns an adaptive criterion for requesting human demonstrations. AIM utilizes a proxy Q-function to mimic the human intervention rule and adjusts intervention requests based on the alignment between agent and human actions. By assigning high Q-values when the agent deviates from the expert and decreasing these values as the agent becomes proficient, the proxy Q-function enables the agent to assess the real-time alignment with the expert and request assistance when needed. Our expert-in-the-loop experiments reveal that AIM significantly reduces expert monitoring efforts in both continuous and discrete control tasks. Compared to the uncertainty-based baseline Thrifty-DAgger, our method achieves a 40% improvement in terms of human take-over cost and learning efficiency. Furthermore, AIM effectively identifies safety-critical states for expert assistance, thereby collecting higher-quality expert demonstrations and reducing overall expert data and environment interactions needed. Code and demo video are available at", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)", "comments": "ICML 2025 Poster", "pdf_url": "https://arxiv.org/pdf/2506.09176.pdf", "abstract_url": "https://arxiv.org/abs/2506.09176", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为自适应干预机制（AIM）的机器人门控交互模仿学习算法，旨在通过减少人类监督者的认知负担来优化交互模仿学习过程。AIM通过代理Q函数模仿人类干预规则，并根据代理与人类行为的对齐程度调整干预请求，从而在代理偏离专家行为时请求帮助。实验表明，AIM在连续和离散控制任务中显著减少了专家的监控努力，并在人类接管成本和学��效率方面比基于不确定性的基线Thrifty-DAgger提高了40%。此外，AIM有效识别了需要专家协助的安全关键状态，从而收集了更高质量的专家演示，并减少了所需的专家数据和环境交互。", "motivation": "当前交互模仿学习（IIL）方法对人类监督者施加了高认知需求，这限制了其应用效率和效果。", "method": "提出了自适应干预机制（AIM），一种利用代理Q函数来模仿人类干预规则并根据代理与人类行为的对齐程度调整干预请求的机器人门控IIL算法。", "result": "AIM在连续和离散控制任务中显著减少了专家的监控努力，比Thrifty-DAgger在人类接管成本和学��效率上提高了40%，并能有效识别安全关键状态以收集更高质量的专家演示。", "conclusion": "AIM通过自适应地请求人类干预，不仅减轻了人类监督者的负担，还提高了学习效率和安全性，为交互模仿学习的实际应用提供了新的可能性。"}}
{"id": "2506.09420", "title": "A Call for Collaborative Intelligence: Why Human-Agent Systems Should Precede AI Autonomy", "authors": ["Henry Peng Zou", "Wei-Chieh Huang", "Yaozu Wu", "Chunyu Miao", "Dongyuan Li", "Aiwei Liu", "Yue Zhou", "Yankai Chen", "Weizhi Zhang", "Yangning Li", "Liancheng Fang", "Renhe Jiang", "Philip S. Yu"], "abstract": "Recent improvements in large language models (LLMs) have led many researchers to focus on building fully autonomous AI agents. This position paper questions whether this approach is the right path forward, as these autonomous systems still have problems with reliability, transparency, and understanding the actual requirements of human. We suggest a different approach: LLM-based Human-Agent Systems (LLM-HAS), where AI works with humans rather than replacing them. By keeping human involved to provide guidance, answer questions, and maintain control, these systems can be more trustworthy and adaptable. Looking at examples from healthcare, finance, and software development, we show how human-AI teamwork can handle complex tasks better than AI working alone. We also discuss the challenges of building these collaborative systems and offer practical solutions. This paper argues that progress in AI should not be measured by how independent systems become, but by how well they can work with humans. The most promising future for AI is not in systems that take over human roles, but in those that enhance human capabilities through meaningful partnership.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.09420.pdf", "abstract_url": "https://arxiv.org/abs/2506.09420", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Human-Computer Interaction (cs.HC)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文质疑了当前追求完全自主AI代理的趋势，提出了基于大型语言模型的人机系统（LLM-HAS），强调AI应与人类合作而非取代人类，以提高系统的可信度和适应性。", "motivation": "解决完全自主AI系统在可靠性、透明度和理解人类实际需求方面的问题。", "method": "提出LLM-HAS方法，即AI与人类合作，人类提供指导、回答问题和保持控制。", "result": "通过医疗、金融和软件开发等领域的例子，展示了人机协作在处理复杂任务上优于AI单独工作。", "conclusion": "AI的进步不应以系统的独立性来衡量，而应以与人类合作的能力为标准。AI最有前途的未来在于增强人类能力的有意义的伙伴关系，而非取代人类角色。"}}
{"id": "2506.09655", "title": "DipLLM: Fine-Tuning LLM for Strategic Decision-making in Diplomacy", "authors": ["Kaixuan Xu", "Jiajun Chai", "Sicheng Li", "Yuqian Fu", "Yuanheng Zhu", "Dongbin Zhao"], "abstract": "Diplomacy is a complex multiplayer game that requires both cooperation and competition, posing significant challenges for AI systems. Traditional methods rely on equilibrium search to generate extensive game data for training, which demands substantial computational resources. Large Language Models (LLMs) offer a promising alternative, leveraging pre-trained knowledge to achieve strong performance with relatively small-scale fine-tuning. However, applying LLMs to Diplomacy remains challenging due to the exponential growth of possible action combinations and the intricate strategic interactions among players. To address this challenge, we propose DipLLM, a fine-tuned LLM-based agent that learns equilibrium policies for Diplomacy. DipLLM employs an autoregressive factorization framework to simplify the complex task of multi-unit action assignment into a sequence of unit-level decisions. By defining an equilibrium policy within this framework as the learning objective, we fine-tune the model using only 1.5% of the data required by the state-of-the-art Cicero model, surpassing its performance. Our results demonstrate the potential of fine-tuned LLMs for tackling complex strategic decision-making in multiplayer games.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "Accepted to the 42nd International Conference on Machine Learning (ICML 2025)", "pdf_url": "https://arxiv.org/pdf/2506.09655.pdf", "abstract_url": "https://arxiv.org/abs/2506.09655", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了DipLLM，一种基于大型语言模型（LLM）的微调代理，用于在复杂多人游戏《外交》中学习均衡策略。通过自回归分解框架简化多单位行动分配任务，并使用仅需1.5%数据量的方法超越了现有最先进模型Cicero的性能。", "motivation": "解决《外交》这一复杂多人游戏中AI系统面临的合作与竞争并存、行动组合指数增长及玩家间复杂战略互动的挑战。", "method": "采用自回归分解框架将多单位行动分配任务分解为一系列单位级决策，并以均衡策略作为学习目标，对LLM进行微调。", "result": "DipLLM仅需1.5%的数据量即可超越Cicero模型的性能，展示了微调LLM在处理复杂多人游戏战略决策中的潜力。", "conclusion": "研究表明，微调LLM是解决复杂战略决策问题的有效方法，尤其在数据效率方面具有显著优势。"}}
{"id": "2506.09656", "title": "Application-Driven Value Alignment in Agentic AI Systems: Survey and Perspectives", "authors": ["Wei Zeng", "Hengshu Zhu", "Chuan Qin", "Han Wu", "Yihang Cheng", "Sirui Zhang", "Xiaowei Jin", "Yinuo Shen", "Zhenxing Wang", "Feimin Zhong", "Hui Xiong"], "abstract": "The ongoing evolution of AI paradigms has propelled AI research into the Agentic AI stage. Consequently, the focus of research has shifted from single agents and simple applications towards multi-agent autonomous decision-making and task collaboration in complex environments. As Large Language Models (LLMs) advance, their applications become more diverse and complex, leading to increasingly situational and systemic risks. This has brought significant attention to value alignment for AI agents, which aims to ensure that an agent's goals, preferences, and behaviors align with human values and societal norms. This paper reviews value alignment in agent systems within specific application scenarios. It integrates the advancements in AI driven by large models with the demands of social governance. Our review covers value principles, agent system application scenarios, and agent value alignment evaluation. Specifically, value principles are organized hierarchically from a top-down perspective, encompassing macro, meso, and micro levels. Agent system application scenarios are categorized and reviewed from a general-to-specific viewpoint. Agent value alignment evaluation systematically examines datasets for value alignment assessment and relevant value alignment methods. Additionally, we delve into value coordination among multiple agents within agent systems. Finally, we propose several potential research directions in this field.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.09656.pdf", "abstract_url": "https://arxiv.org/abs/2506.09656", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文综述了代理AI系统中的价值对齐问题，特别是在大型语言模型（LLMs）推动下，AI研究进入代理AI阶段，关注点多智能体在复杂环境中的自主决策和任务协作。文章从价值原则、应用场景和评估方法三个维度，系统回顾了价值对齐的研究进展，并探讨了多智能体间的价值协调问题，最后提出了该领域的潜在研究方向。", "motivation": "随着AI范式的发展，特别是大型语言模型的进步，AI应用变得更加多样化和复杂化，这带来了情境性和系统性的风险。为了确保AI代理的目标、偏好和行为与人类价值观和社会规范一致，价值对齐问题受到了广泛关注。", "method": "本文采用文献综述的方法，从宏观、中观和微观三个层次组织价值原则，从一般到具体的视角分类和回顾代理系统的应用场景，系统考察了价值对齐评估的数据集和相关方法，并深入探讨了多智能体系统中的价值协调问题。", "result": "文章系统回顾了价值对齐在代理AI系统中的研究进展，包括价值原则的组织、应用场景的分类、评估方法的考察，以及多智能体价值协调的探讨，为该领域的研究提供了全面的视角。", "conclusion": "本文不仅总结了代理AI系统中价值对齐的当前研究状态，还提出了未来研究的潜在方向，强调了在AI发展和社会治理需求之间找到平衡的重要性。"}}
{"id": "2506.09659", "title": "Intent Factored Generation: Unleashing the Diversity in Your Language Model", "authors": ["Eltayeb Ahmed", "Uljad Berdica", "Martha Elliott", "Danijela Horak", "Jakob N. Foerster"], "abstract": "Obtaining multiple meaningfully diverse, high quality samples from Large Language Models for a fixed prompt remains an open challenge. Current methods for increasing diversity often only operate at the token-level, paraphrasing the same response. This is problematic because it leads to poor exploration on reasoning problems and to unengaging, repetitive conversational agents. To address this we propose Intent Factored Generation (IFG), factorising the sampling process into two stages. First, we sample a semantically dense intent, e.g., a summary or keywords. Second, we sample the final response conditioning on both the original prompt and the intent from the first stage. This allows us to use a higher temperature during the intent step to promote conceptual diversity, and a lower temperature during the final generation to ensure the outputs are coherent and self-consistent. Additionally, we find that prompting the model to explicitly state its intent for each step of the chain-of-thought before generating the step is beneficial for reasoning tasks. We demonstrate our method's effectiveness across a diverse set of tasks. We show this method improves both pass@k and Reinforcement Learning from Verifier Feedback on maths and code tasks. For instruction-tuning, we combine IFG with Direct Preference Optimisation to increase conversational diversity without sacrificing reward. Finally, we achieve higher diversity while maintaining the quality of generations on a general language modelling task, using a new dataset of reader comments and news articles that we collect and open-source. In summary, we present a simple method of increasing the sample diversity of LLMs while maintaining performance. This method can be implemented by changing the prompt and varying the temperature during generation, making it easy to integrate into many algorithms for gains across various applications.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.09659.pdf", "abstract_url": "https://arxiv.org/abs/2506.09659", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为意图因子生成（IFG）的新方法，旨在解决从大型语言模型中获取多样且高质量样本的挑战。IFG通过将采样过程分为两个阶段来增加样本的多样性，同时保持生成质量。", "motivation": "当前方法在增加多样性时往往只在令牌级别操作，导致推理问题上的探索不足和对话代理的重复无趣。", "method": "IFG方法将采样过程分为两个阶段：首先采样一个语义密集的意图（如摘要或关键词），然后在原始提示和第一阶段意图的基础上采样最终响应。", "result": "该方法在数学和代码任务上提高了pass@k和来自验证器反馈的强化学习性能，同时在指令调优中增加了对话多样性而不牺牲奖励，并在一般语言建模任务中保持了生成质量的同时提高了多样性。", "conclusion": "IFG是一种简单有效的方法，通过改变提示和调整生成温度，可以轻松集成到多种算法中，从而在各种应用中实现性能提升。"}}
{"id": "2506.09513", "title": "ReasonMed: A 370K Multi-Agent Generated Dataset for Advancing Medical Reasoning", "authors": ["Yu Sun", "Xingyu Qian", "Weiwen Xu", "Hao Zhang", "Chenghao Xiao", "Long Li", "Yu Rong", "Wenbing Huang", "Qifeng Bai", "Tingyang Xu"], "abstract": "Though reasoning-based large language models (LLMs) have excelled in mathematics and programming, their capabilities in knowledge-intensive medical question answering remain underexplored. To address this, we introduce ReasonMed, the largest medical reasoning dataset, comprising 370k high-quality examples distilled from 1.7 million initial reasoning paths generated by various LLMs. ReasonMed is constructed through a \\textit{multi-agent verification and refinement process}, where we design an \\textit{Error Refiner} to enhance the reasoning paths by identifying and correcting error-prone steps flagged by a verifier. Leveraging ReasonMed, we systematically investigate best practices for training medical reasoning models and find that combining detailed Chain-of-Thought (CoT) reasoning with concise answer summaries yields the most effective fine-tuning strategy. Based on this strategy, we train ReasonMed-7B, which sets a new benchmark for sub-10B models, outperforming the prior best by 4.17\\% and even exceeding LLaMA3.1-70B on PubMedQA by 4.60\\%.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "24 pages, 6 figures, 7 tables", "pdf_url": "https://arxiv.org/pdf/2506.09513.pdf", "abstract_url": "https://arxiv.org/abs/2506.09513", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "ReasonMed是一个370K的多智能体生成数据集，旨在推进医学推理。通过多智能体验证和精炼过程构建，包含从170万初始推理路径中提炼出的高质量示例。研究发现，结合详细的思维链推理和简洁答案摘要的微调策略最有效，并据此训练了ReasonMed-7B模型，其在子10B模型中设立了新标杆。", "motivation": "尽管基于推理的大型语言模型在数学和编程方面表现出色，但它们在知识密集型医学问答中的能力仍未得到充分探索。", "method": "通过多智能体验证和精炼过程构建ReasonMed数据集，设计了一个错误精炼器来增强由验证器标记的易错步骤的推理路径。", "result": "结合详细的思维链推理与简洁答案摘要的微调策略最为有效。ReasonMed-7B在子10B模型中表现最佳，优于之前的最佳模型4.17%，在PubMedQA上甚至超过LLaMA3.1-70B 4.60%。", "conclusion": "ReasonMed数据集的引入和ReasonMed-7B模型的训练为医学推理领域设立了新的基准，展示了结合详细推理和简洁摘要的微调策略的有效性。"}}
{"id": "2506.09542", "title": "KG-Infused RAG: Augmenting Corpus-Based RAG with External Knowledge Graphs", "authors": ["Dingjun Wu", "Yukun Yan", "Zhenghao Liu", "Zhiyuan Liu", "Maosong Sun"], "abstract": "Retrieval-Augmented Generation (RAG) improves factual accuracy by grounding responses in external knowledge. However, existing methods typically rely on a single source, either unstructured text or structured knowledge. Moreover, they lack cognitively inspired mechanisms for activating relevant knowledge. To address these issues, we propose KG-Infused RAG, a framework that integrates KGs into RAG systems to implement spreading activation, a cognitive process that enables concept association and inference. KG-Infused RAG retrieves KG facts, expands the query accordingly, and enhances generation by combining corpus passages with structured facts, enabling interpretable, multi-source retrieval grounded in semantic structure. We further improve KG-Infused RAG via preference learning on sampled key stages in the pipeline. Experiments on five QA benchmarks show that KG-Infused RAG consistently outperforms vanilla RAG (by 3.8% to 13.8%). Additionally, when integrated into Self-RAG, KG-Infused RAG brings further performance gains, demonstrating its effectiveness and versatility as a plug-and-play enhancement module for corpus-based RAG methods.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.09542.pdf", "abstract_url": "https://arxiv.org/abs/2506.09542", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "KG-Infused RAG是一种将知识图谱（KG）集成到检索增强生成（RAG）系统中的框架，旨在通过实现扩散激活来增强事实准确性，支持多源检索和语义结构基础。", "motivation": "解决现有RAG方法通常依赖单一知识源（非结构化文本或结构化知识）且缺乏认知启发的知识激活机制的问题。", "method": "提出KG-Infused RAG框架，通过检索KG事实、相应扩展查询，并结合语料库段落与结构化事实来增强生成，实现基于语义结构的多源检索。", "result": "在五个QA基准测试中，KG-Infused RAG始终优于普通RAG（提升3.8%至13.8%），并且当集成到Self-RAG中时，带来进一步的性能提升。", "conclusion": "KG-Infused RAG作为一种即插即用的增强模块，不仅提高了RAG方法的性能，还展示了其在多源检索和语义结构基础方面的有效性和多功能性。"}}
{"id": "2506.09080", "title": "FinHEAR: Human Expertise and Adaptive Risk-Aware Temporal Reasoning for Financial Decision-Making", "authors": ["Jiaxiang Chen", "Mingxi Zou", "Zhuo Wang", "Qifan Wang", "Dongning Sun", "Chi Zhang", "Zenglin Xu"], "abstract": "Financial decision-making presents unique challenges for language models, demanding temporal reasoning, adaptive risk assessment, and responsiveness to dynamic events. While large language models (LLMs) show strong general reasoning capabilities, they often fail to capture behavioral patterns central to human financial decisions-such as expert reliance under information asymmetry, loss-averse sensitivity, and feedback-driven temporal adjustment. We propose FinHEAR, a multi-agent framework for Human Expertise and Adaptive Risk-aware reasoning. FinHEAR orchestrates specialized LLM-based agents to analyze historical trends, interpret current events, and retrieve expert-informed precedents within an event-centric pipeline. Grounded in behavioral economics, it incorporates expert-guided retrieval, confidence-adjusted position sizing, and outcome-based refinement to enhance interpretability and robustness. Empirical results on curated financial datasets show that FinHEAR consistently outperforms strong baselines across trend prediction and trading tasks, achieving higher accuracy and better risk-adjusted returns.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computational Finance (q-fin.CP)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.09080.pdf", "abstract_url": "https://arxiv.org/abs/2506.09080", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computational Finance (q-fin.CP)"], "matching_keywords": ["agent"], "AI": {"tldr": "FinHEAR是一个多智能体框架，旨在通过结合人类专业知识和自适应风险意识推理，解决金融决策中的时间推理、风险评估和动态事件响应问题。", "motivation": "解决语言模型在金融决策中难以捕捉人类行为模式（如专家依赖、损失厌恶敏感性和反馈驱动的时间调整）的问题。", "method": "FinHEAR通过协调基于LLM的专门智能体，分析历史趋势、解释当前事件，并在以事件为中心的流程中检索专家知情的前例，结合行为经济学原理，引入专家引导检索、信心调整头寸规模和基于结果的细化。", "result": "在精选的金融数据集上，FinHEAR在趋势预测和交易任务中 consistently outperforms strong baselines，实现了更高的准确性和更好的风险调整回报。", "conclusion": "FinHEAR通过结合人类专业知识和自适应风险意识推理，提高了金融决策的可解释性和鲁棒性，为语言模型在金融领域的应用提供了新的方向。"}}
{"id": "2506.09748", "title": "Hierarchical Image Matching for UAV Absolute Visual Localization via Semantic and Structural Constraints", "authors": ["Xiangkai Zhang", "Xiang Zhou", "Mao Chen", "Yuchen Lu", "Xu Yang", "Zhiyong Liu"], "abstract": "Absolute localization, aiming to determine an agent's location with respect to a global reference, is crucial for unmanned aerial vehicles (UAVs) in various applications, but it becomes challenging when global navigation satellite system (GNSS) signals are unavailable. Vision-based absolute localization methods, which locate the current view of the UAV in a reference satellite map to estimate its position, have become popular in GNSS-denied scenarios. However, existing methods mostly rely on traditional and low-level image matching, suffering from difficulties due to significant differences introduced by cross-source discrepancies and temporal variations. To overcome these limitations, in this paper, we introduce a hierarchical cross-source image matching method designed for UAV absolute localization, which integrates a semantic-aware and structure-constrained coarse matching module with a lightweight fine-grained matching module. Specifically, in the coarse matching module, semantic features derived from a vision foundation model first establish region-level correspondences under semantic and structural constraints. Then, the fine-grained matching module is applied to extract fine features and establish pixel-level correspondences. Building upon this, a UAV absolute visual localization pipeline is constructed without any reliance on relative localization techniques, mainly by employing an image retrieval module before the proposed hierarchical image matching modules. Experimental evaluations on public benchmark datasets and a newly introduced CS-UAV dataset demonstrate superior accuracy and robustness of the proposed method under various challenging conditions, confirming its effectiveness.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)", "comments": "8 pages, 6 figures", "pdf_url": "https://arxiv.org/pdf/2506.09748.pdf", "abstract_url": "https://arxiv.org/abs/2506.09748", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种用于无人机绝对视觉定位的分层跨源图像匹配方法，通过结合语义感知和结构约束的粗匹配模块与轻量级细粒度匹配模块，有效解决了在GNSS信号不可用情况下的定位挑战。", "motivation": "解决在全局导航卫星系统(GNSS)信号不可用时，无人机(UAV)绝对视觉定位面临的跨源差异和时间变化带来的挑战。", "method": "采用分层跨源图像匹配方法，包括语义感知和结构约束的粗匹配模块与轻量级细粒度匹配模块，首先建立区域级对应关系，然后建立像素级对应关系。", "result": "在公共基准数据集和新引入的CS-UAV数据集上的实验评估表明，该方法在各种挑战性条件下具有优越的准确性和鲁棒性。", "conclusion": "提出的方法有效提高了无人机在GNSS信号不可用情况下的绝对视觉定位性能，具有广泛的应用潜力。"}}
{"id": "2506.09839", "title": "OctoNav: Towards Generalist Embodied Navigation", "authors": ["Chen Gao", "Liankai Jin", "Xingyu Peng", "Jiazhao Zhang", "Yue Deng", "Annan Li", "He Wang", "Si Liu"], "abstract": "Embodied navigation stands as a foundation pillar within the broader pursuit of embodied AI. However, previous navigation research is divided into different tasks/capabilities, e.g., ObjNav, ImgNav and VLN, where they differ in task objectives and modalities, making datasets and methods are designed individually. In this work, we take steps toward generalist navigation agents, which can follow free-form instructions that include arbitrary compounds of multi-modal and multi-capability. To achieve this, we propose a large-scale benchmark and corresponding method, termed OctoNav-Bench and OctoNav-R1. Specifically, OctoNav-Bench features continuous environments and is constructed via a designed annotation pipeline. We thoroughly craft instruction-trajectory pairs, where instructions are diverse in free-form with arbitrary modality and capability. Also, we construct a Think-Before-Action (TBA-CoT) dataset within OctoNav-Bench to provide the thinking process behind actions. For OctoNav-R1, we build it upon MLLMs and adapt it to a VLA-type model, which can produce low-level actions solely based on 2D visual observations. Moreover, we design a Hybrid Training Paradigm (HTP) that consists of three stages, i.e., Action-/TBA-SFT, Nav-GPRO, and Online RL stages. Each stage contains specifically designed learning policies and rewards. Importantly, for TBA-SFT and Nav-GRPO designs, we are inspired by the OpenAI-o1 and DeepSeek-R1, which show impressive reasoning ability via thinking-before-answer. Thus, we aim to investigate how to achieve thinking-before-action in the embodied navigation field, to improve model's reasoning ability toward generalists. Specifically, we propose TBA-SFT to utilize the TBA-CoT dataset to fine-tune the model as a cold-start phrase and then leverage Nav-GPRO to improve its thinking ability. Finally, OctoNav-R1 shows superior performance compared with previous methods.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": "31 pages, 25 figures", "pdf_url": "https://arxiv.org/pdf/2506.09839.pdf", "abstract_url": "https://arxiv.org/abs/2506.09839", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了OctoNav，旨在开发一种通用的具身导航代理，能够遵循包含多模态和多能力任意组合的自由形式指令。通过构建大规模基准OctoNav-Bench和相应方法OctoNav-R1，以及设计混合训练范式（HTP），实现了在连续环境中基于2D视觉观察的低级动作生成，并通过思考-行动（TBA-CoT）数据集提升模型的推理能力。", "motivation": "解决现有导航研究因任务目标和模态不同而分散，导致数据集和方法设计孤立的问题，推动通用导航代理的发展。", "method": "构建OctoNav-Bench基准和OctoNav-R1方法，采用混合训练范式（HTP），包括动作-/TBA-SFT、Nav-GPRO和在线RL阶段，利用TBA-CoT数据集提升模型的推理能力。", "result": "OctoNav-R1在性能上优于现有方法，展示了在通用导航代理领域的潜力。", "conclusion": "通过OctoNav-Bench和OctoNav-R1的结合，以及HTP训练范式的应用，本研究为通用具身导航代理的发展提供了新的方向和工具，特别是在提升模型推理能力方面取得了进展。"}}
{"id": "2506.09645", "title": "Learning Efficient and Generalizable Graph Retriever for Knowledge-Graph Question Answering", "authors": ["Tianjun Yao", "Haoxuan Li", "Zhiqiang Shen", "Pan Li", "Tongliang Liu", "Kun Zhang"], "abstract": "Large Language Models (LLMs) have shown strong inductive reasoning ability across various domains, but their reliability is hindered by the outdated knowledge and hallucinations. Retrieval-Augmented Generation mitigates these issues by grounding LLMs with external knowledge; however, most existing RAG pipelines rely on unstructured text, limiting interpretability and structured reasoning. Knowledge graphs, which represent facts as relational triples, offer a more structured and compact alternative. Recent studies have explored integrating knowledge graphs with LLMs for knowledge graph question answering (KGQA), with a significant proportion adopting the retrieve-then-reasoning paradigm. In this framework, graph-based retrievers have demonstrated strong empirical performance, yet they still face challenges in generalization ability. In this work, we propose RAPL, a novel framework for efficient and effective graph retrieval in KGQA. RAPL addresses these limitations through three aspects: (1) a two-stage labeling strategy that combines heuristic signals with parametric models to provide causally grounded supervision; (2) a model-agnostic graph transformation approach to capture both intra- and inter-triple interactions, thereby enhancing representational capacity; and (3) a path-based reasoning strategy that facilitates learning from the injected rational knowledge, and supports downstream reasoner through structured inputs. Empirically, RAPL outperforms state-of-the-art methods by $2.66\\%-20.34\\%$, and significantly reduces the performance gap between smaller and more powerful LLM-based reasoners, as well as the gap under cross-dataset settings, highlighting its superior retrieval capability and generalizability. Codes are available at:", "subjects": "Computation and Language (cs.CL); Information Retrieval (cs.IR); Machine Learning (cs.LG)", "comments": "32 pages, 28 figures", "pdf_url": "https://arxiv.org/pdf/2506.09645.pdf", "abstract_url": "https://arxiv.org/abs/2506.09645", "categories": ["Computation and Language (cs.CL)", "Information Retrieval (cs.IR)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种名为RAPL的新框架，旨在提高知识图谱问答（KGQA）中图检索器的效率和泛化能力。通过两阶段标注策略、模型无关的图转换方法和基于路径的推理策略，RAPL在性能和泛化能力上显著优于现有方法。", "motivation": "大型语言模型（LLMs）在不同领域展现出强大的归纳推理能力，但其可靠性受限于过时的知识和幻觉问题。检索增强生成（RAG）通过外部知识基础缓解这些问题，但现有RAG管道大多依赖非结构化文本，限制了可解释性和结构化推理。知识图谱以关系三元组表示事实，提供了更结构化和紧凑的替代方案。然而，现有的图检索器在泛化能力上仍面临挑战。", "method": "RAPL框架通过三个方面解决这些限制：（1）结合启发式信号和参数化模型的两阶段标注策略，提供因果基础的监督；（2）模型无关的图转换方法，捕捉三元组内和三元组间的交互，增强表示能力；（3）基于路径的推理策略，促进从注入的理性知识中学习，并通过结构化输入支持下游推理器。", "result": "实证结果显示，RAPL在性能上比最先进的方法高出2.66%到20.34%，显著缩小了小型和更强大LLM推理器之间的性能差距，以及在跨数据集设置下的差距，突出了其卓越的检索能力和泛化能力。", "conclusion": "RAPL框架通过创新的两阶段标注、图转换和路径推理策略，有效提升了知识图谱问答中图检索器的效率和泛化能力，为未来的研究和应用提供了有价值的参考。"}}
{"id": "2506.09657", "title": "Bridging the Gap Between Open-Source and Proprietary LLMs in Table QA", "authors": ["Nikolas Evkarpidi", "Elena Tutubalina"], "abstract": "This paper presents a system developed for SemEval 2025 Task 8: Question Answering (QA) over tabular data. Our approach integrates several key components: text-to-SQL and text-to-code generation modules, a self-correction mechanism, and a retrieval-augmented generation (RAG). Additionally, it includes an end-to-end (E2E) module, all orchestrated by a large language model (LLM). Through ablation studies, we analyzed the effects of different parts of our pipeline and identified the challenges that are still present in this field. During the evaluation phase of the competition, our solution achieved an accuracy of 80%, resulting in a top-13 ranking among the 38 participating teams. Our pipeline demonstrates a significant improvement in accuracy for open-source models and achieves a performance comparable to proprietary LLMs in QA tasks over tables. The code is available at GitHub repository.", "subjects": "Computation and Language (cs.CL)", "comments": "Accepted for publication at the 19th International Workshop on Semantic Evaluation (SemEval-2025), to be held in conjunction with ACL 2025. 15 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2506.09657.pdf", "abstract_url": "https://arxiv.org/abs/2506.09657", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了一个为SemEval 2025任务8开发的系统，专注于表格数据的问答。通过整合文本到SQL和文本到代码生成模块、自我纠正机制、检索增强生成（RAG）以及端到端（E2E）模块，并由大型语言模型（LLM）协调，该系统在竞赛评估阶段达到了80%的准确率，在38个参赛团队中排名前13。", "motivation": "解决开源与专有大型语言模型在表格问答任务中的性能差距问题。", "method": "整合了文本到SQL和文本到代码生成模块、自我纠正机制、检索增强生成（RAG）以及端到端（E2E）模块，由大型语言模型（LLM）协调。", "result": "系统在竞赛评估阶段达到了80%的准确率，排名前13，展示了开源模型在表格问答任务中的显著改进和与专有LLMs相当的性能。", "conclusion": "该管道在开源模型中实现了显著的准确率提升，并在表格问答任务中达到了与专有LLMs相当的性能，为未来研究指明了挑战和方向。"}}
{"id": "2506.09669", "title": "Query-Level Uncertainty in Large Language Models", "authors": ["Lihu Chen", "Gaël Varoquaux"], "abstract": "It is important for Large Language Models to be aware of the boundary of their knowledge, the mechanism of identifying known and unknown queries. This type of awareness can help models perform adaptive inference, such as invoking RAG, engaging in slow and deep thinking, or adopting the abstention mechanism, which is beneficial to the development of efficient and trustworthy AI. In this work, we propose a method to detect knowledge boundaries via Query-Level Uncertainty, which aims to determine if the model is able to address a given query without generating any tokens. To this end, we introduce a novel and training-free method called \\emph{Internal Confidence}, which leverages self-evaluations across layers and tokens. Empirical results on both factual QA and mathematical reasoning tasks demonstrate that our internal confidence can outperform several baselines. Furthermore, we showcase that our proposed method can be used for efficient RAG and model cascading, which is able to reduce inference costs while maintaining performance.", "subjects": "Computation and Language (cs.CL)", "comments": "In Progress", "pdf_url": "https://arxiv.org/pdf/2506.09669.pdf", "abstract_url": "https://arxiv.org/abs/2506.09669", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种名为‘内部置信度’的无训练方法，用于检测大型语言模型的知识边界，即确定模型是否能在不生成任何令牌的情况下回答给定查询。该方法通过层和令牌的自我评估来实现，实证结果表明其在事实QA和数学推理任务上优于多个基线。此外，该方法还可用于高效的RAG和模型级联，能在保持性能的同时降低推理成本。", "motivation": "解决大型语言模型识别已知和未知查询的问题，以实现自适应推理，如调用RAG、进行深度思考或采用弃权机制，从而促进高效和可信赖AI的发展。", "method": "提出了一种名为‘内部置信度’的无训练方法，利用层和令牌的自我评估来检测模型的知识边界。", "result": "在事实QA和数学推理任务上的实证结果表明，内部置信度方法优于多个基线，并能有效用于RAG和模型级联，降低推理成本同时保持性能。", "conclusion": "内部置信度方法为大型语言模型提供了一种有效的知识边界检测手段，有助于实现自适应推理和降低推理成本，对发展高效和可信赖的AI具有重要意义。"}}
{"id": "2506.09107", "title": "FAIRTOPIA: Envisioning Multi-Agent Guardianship for Disrupting Unfair AI Pipelines", "authors": ["Athena Vakali", "Ilias Dimitriadis"], "abstract": "AI models have become active decision makers, often acting without human supervision. The rapid advancement of AI technology has already caused harmful incidents that have hurt individuals and societies and AI unfairness in heavily criticized. It is urgent to disrupt AI pipelines which largely neglect human principles and focus on computational biases exploration at the data (pre), model(in), and deployment (post) processing stages. We claim that by exploiting the advances of agents technology, we will introduce cautious, prompt, and ongoing fairness watch schemes, under realistic, systematic, and human-centric fairness expectations. We envision agents as fairness guardians, since agents learn from their environment, adapt to new information, and solve complex problems by interacting with external tools and other systems. To set the proper fairness guardrails in the overall AI pipeline, we introduce a fairness-by-design approach which embeds multi-role agents in an end-to-end (human to AI) synergetic scheme. Our position is that we may design adaptive and realistic AI fairness frameworks, and we introduce a generalized algorithm which can be customized to the requirements and goals of each AI decision making scenario. Our proposed, so called FAIRTOPIA framework, is structured over a three-layered architecture, which encapsulates the AI pipeline inside an agentic guardian and a knowledge-based, self-refining layered scheme. Based on our proposition, we enact fairness watch in all of the AI pipeline stages, under robust multi-agent workflows, which will inspire new fairness research hypothesis, heuristics, and methods grounded in human-centric, systematic, interdisciplinary, socio-technical principles.", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI)", "comments": "11 pages, 4 figures", "pdf_url": "https://arxiv.org/pdf/2506.09107.pdf", "abstract_url": "https://arxiv.org/abs/2506.09107", "categories": ["Computers and Society (cs.CY)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出FAIRTOPIA框架，旨在通过多智能体监护机制解决AI管道中的不公平问题，强调在AI决策过程中嵌入公平性设计。", "motivation": "AI技术快速发展，但其决策过程中缺乏人类原则的考量，导致不公平现象，亟需在数据处理、模型构建及部署阶段引入公平性监护。", "method": "采用基于智能体的公平性监护方案，提出一个三层架构的FAIRTOPIA框架，通过多角色智能体在AI管道中实施端到端的公平性监控。", "result": "提出了一种可定制的通用算法，能够在不同AI决策场景中实现适应性强的公平性框架，并通过多智能体工作流在AI管道的各个阶段实施公平性监控。", "conclusion": "FAIRTOPIA框架为AI公平性研究提供了新的假设、启发和方法，基于人本、系统化、跨学科的社会技术原则，有望推动公平性研究的进一步发展。"}}
{"id": "2506.09902", "title": "PersonaLens: A Benchmark for Personalization Evaluation in Conversational AI Assistants", "authors": ["Zheng Zhao", "Clara Vania", "Subhradeep Kayal", "Naila Khan", "Shay B. Cohen", "Emine Yilmaz"], "abstract": "Large language models (LLMs) have advanced conversational AI assistants. However, systematically evaluating how well these assistants apply personalization--adapting to individual user preferences while completing tasks--remains challenging. Existing personalization benchmarks focus on chit-chat, non-conversational tasks, or narrow domains, failing to capture the complexities of personalized task-oriented assistance. To address this, we introduce PersonaLens, a comprehensive benchmark for evaluating personalization in task-oriented AI assistants. Our benchmark features diverse user profiles equipped with rich preferences and interaction histories, along with two specialized LLM-based agents: a user agent that engages in realistic task-oriented dialogues with AI assistants, and a judge agent that employs the LLM-as-a-Judge paradigm to assess personalization, response quality, and task success. Through extensive experiments with current LLM assistants across diverse tasks, we reveal significant variability in their personalization capabilities, providing crucial insights for advancing conversational AI systems.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "Accepted to ACL 2025 Findings", "pdf_url": "https://arxiv.org/pdf/2506.09902.pdf", "abstract_url": "https://arxiv.org/abs/2506.09902", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "PersonaLens是一个用于评估任务导向型AI助手个性化能力的综合基准，包含多样化的用户配置文件和两个专门的基于LLM的代理，揭示了当前LLM助手在个性化能力上的显著差异。", "motivation": "现有的个性化基准主要集中在闲聊、非对话任务或狭窄领域，无法捕捉到个性化任务导向协助的复杂性。", "method": "引入PersonaLens基准，配备丰富的用户偏好和交互历史，以及两个专门的LLM代理：一个用户代理与AI助手进行现实的任务导向对话，一个法官代理使用LLM-as-a-Judge范式评估个性化、响应质量和任务成功。", "result": "通过在不同任务上与当前LLM助手的广泛实验，揭示了它们在个性化能力上的显著差异。", "conclusion": "PersonaLens为推进对话AI系统提供了关键的见解，揭示了当前LLM助手在个性化能力上的不足和差异。"}}
{"id": "2506.09171", "title": "Improving LLM Agent Planning with In-Context Learning via Atomic Fact Augmentation and Lookahead Search", "authors": ["Samuel Holt", "Max Ruiz Luyten", "Thomas Pouplin", "Mihaela van der Schaar"], "abstract": "Large Language Models (LLMs) are increasingly capable but often require significant guidance or extensive interaction history to perform effectively in complex, interactive environments. Existing methods may struggle with adapting to new information or efficiently utilizing past experiences for multi-step reasoning without fine-tuning. We introduce a novel LLM agent framework that enhances planning capabilities through in-context learning, facilitated by atomic fact augmentation and a recursive lookahead search. Our agent learns to extract task-critical ``atomic facts'' from its interaction trajectories. These facts dynamically augment the prompts provided to LLM-based components responsible for action proposal, latent world model simulation, and state-value estimation. Planning is performed via a depth-limited lookahead search, where the LLM simulates potential trajectories and evaluates their outcomes, guided by the accumulated facts and interaction history. This approach allows the agent to improve its understanding and decision-making online, leveraging its experience to refine its behavior without weight updates. We provide a theoretical motivation linking performance to the quality of fact-based abstraction and LLM simulation accuracy. Empirically, our agent demonstrates improved performance and adaptability on challenging interactive tasks, achieving more optimal behavior as it accumulates experience, showcased in tasks such as TextFrozenLake and ALFWorld.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "9-page main paper, 1 figure. Accepted for an Oral presentation at the First Workshop on Computer Use Agents (ICML 2025), Vancouver, Canada", "pdf_url": "https://arxiv.org/pdf/2506.09171.pdf", "abstract_url": "https://arxiv.org/abs/2506.09171", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新型的LLM代理框架，通过原子事实增强和前瞻搜索来增强规划能力，无需微调即可在线改进决策。", "motivation": "大型语言模型（LLMs）在复杂交互环境中需要大量指导或交互历史才能有效工作，现有方法难以适应新信息或高效利用过去经验进行多步推理。", "method": "引入原子事实增强和递归前瞻搜索的LLM代理框架，动态提取任务关键原子事实以增强提示，通过深度限制的前瞻搜索进行规划。", "result": "代理在挑战性交互任务中表现出更高的性能和适应性，如TextFrozenLake和ALFWorld，随着经验积累行为更优。", "conclusion": "该框架通过原子事实增强和前瞻搜索显著提升了LLM代理的规划能力，无需权重更新即可在线学习和改进。"}}
{"id": "2506.09289", "title": "UTBoost: Rigorous Evaluation of Coding Agents on SWE-Bench", "authors": ["Boxi Yu", "Yuxuan Zhu", "Pinjia He", "Daniel Kang"], "abstract": "The advent of Large Language Models (LLMs) has spurred the development of coding agents for real-world code generation. As a widely used benchmark for evaluating the code generation capabilities of these agents, SWE-Bench uses real-world problems based on GitHub issues and their corresponding pull requests. However, the manually written test cases included in these pull requests are often insufficient, allowing generated patches to pass the tests without resolving the underlying issue. To address this challenge, we introduce UTGenerator, an LLM-driven test case generator that automatically analyzes codebases and dependencies to generate test cases for real-world Python projects. Building on UTGenerator, we propose UTBoost, a comprehensive framework for test case augmentation. In our evaluation, we identified 36 task instances with insufficient test cases and uncovered 345 erroneous patches incorrectly labeled as passed in the original SWE Bench. These corrections, impacting 40.9% of SWE-Bench Lite and 24.4% of SWE-Bench Verified leaderboard entries, yield 18 and 11 ranking changes, respectively.", "subjects": "Software Engineering (cs.SE); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.09289.pdf", "abstract_url": "https://arxiv.org/abs/2506.09289", "categories": ["Software Engineering (cs.SE)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了UTBoost框架，一个用于增强测试案例的综合框架，旨在解决SWE-Bench基准测试中测试案例不足的问题。通过UTGenerator自动生成测试案例，研究发现并纠正了大量错误标记为通过的补丁，显著影响了SWE-Bench的排行榜。", "motivation": "大型语言模型（LLMs）的发展促进了编码代理的进步，但现有的SWE-Bench基准测试中的测试案例往往不足以验证生成的补丁是否真正解决了问题。", "method": "提出了UTGenerator，一个基于LLM的测试案例生成器，自动分析代码库和依赖关系以生成测试案例，并在此基础上构建了UTBoost框架。", "result": "在评估中，识别了36个测试案例不足的任务实例，并发现了345个错误标记为通过的补丁，这些更正影响了SWE-Bench Lite和SWE-Bench Verified排行榜的40.9%和24.4%的条目，分别导致了18和11个排名变化。", "conclusion": "UTBoost框架通过自动生成测试案例，有效提高了编码代理在SWE-Bench上的评估准确性，揭示了现有基准测试中的不足，并对排行榜产生了显著影响。"}}
{"id": "2506.09215", "title": "Robust Noise Attenuation via Adaptive Pooling of Transformer Outputs", "authors": ["Greyson Brothers"], "abstract": "We investigate the design of pooling methods used to summarize the outputs of transformer embedding models, primarily motivated by reinforcement learning and vision applications. This work considers problems where a subset of the input vectors contains requisite information for a downstream task (signal) while the rest are distractors (noise). By framing pooling as vector quantization with the goal of minimizing signal loss, we demonstrate that the standard methods used to aggregate transformer outputs, AvgPool, MaxPool, and ClsToken, are vulnerable to performance collapse as the signal-to-noise ratio (SNR) of inputs fluctuates. We then show that an attention-based adaptive pooling method can approximate the signal-optimal vector quantizer within derived error bounds for any SNR. Our theoretical results are first validated by supervised experiments on a synthetic dataset designed to isolate the SNR problem, then generalized to standard relational reasoning, multi-agent reinforcement learning, and vision benchmarks with noisy observations, where transformers with adaptive pooling display superior robustness across tasks.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "[ICML 2025 Spotlight Poster] To be published in the Forty-Second International Conference on Machine Learning (ICML) Proceedings", "pdf_url": "https://arxiv.org/pdf/2506.09215.pdf", "abstract_url": "https://arxiv.org/abs/2506.09215", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究了用于总结变压器嵌入模型输出的池化方法设计，主要受到强化学习和视觉应用的启发。通过将池化视为向量量化，旨在最小化信号损失，研究发现标准聚合方法（AvgPool、MaxPool和ClsToken）在输入信噪比（SNR）波动时易受性能崩溃影响。提出了一种基于注意力的自适应池化方法，能在任何SNR下近似信号最优向量量化器，并在理论和实验上验证了其优越性。", "motivation": "解决在变压器嵌入模型中，当输入向量中部分为信号部分为噪声时，标准池化方法因信噪比波动导致的性能崩溃问题。", "method": "提出了一种基于注意力的自适应池化方法，旨在近似信号最优向量量化器，以最小化信号损失。", "result": "在合成数据集和标准关系推理、多智能体强化学习及带有噪声观测的视觉基准测试中，自适应池化方法显示出跨任务的优越鲁棒性。", "conclusion": "自适应池化方法能够有效应对信噪比波动，提高变压器模型在噪声环境下的性能和鲁棒性。"}}
{"id": "2506.09276", "title": "Learning The Minimum Action Distance", "authors": ["Lorenzo Steccanella", "Joshua B. Evans", "Özgür Şimşek", "Anders Jonsson"], "abstract": "This paper presents a state representation framework for Markov decision processes (MDPs) that can be learned solely from state trajectories, requiring neither reward signals nor the actions executed by the agent. We propose learning the minimum action distance (MAD), defined as the minimum number of actions required to transition between states, as a fundamental metric that captures the underlying structure of an environment. MAD naturally enables critical downstream tasks such as goal-conditioned reinforcement learning and reward shaping by providing a dense, geometrically meaningful measure of progress. Our self-supervised learning approach constructs an embedding space where the distances between embedded state pairs correspond to their MAD, accommodating both symmetric and asymmetric approximations. We evaluate the framework on a comprehensive suite of environments with known MAD values, encompassing both deterministic and stochastic dynamics, as well as discrete and continuous state spaces, and environments with noisy observations. Empirical results demonstrate that the proposed approach not only efficiently learns accurate MAD representations across these diverse settings but also significantly outperforms existing state representation methods in terms of representation quality.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.09276.pdf", "abstract_url": "https://arxiv.org/abs/2506.09276", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种仅从状态轨迹学习马尔可夫决策过程（MDPs）状态表示的框架，无需奖励信号或执行的动作。通过定义最小动作距离（MAD）作为环境结构的基本度量，该方法支持目标条件强化学习和奖励塑造等下游任务。", "motivation": "解决在无需奖励信号或执行动作的情况下，学习马尔可夫决策过程状态表示的问题，以支持如目标条件强化学习等下游任务。", "method": "提出学习最小动作距离（MAD）作为状态间转换所需最小动作数的度量，通过自监督学习构建嵌入空间，其中状态对的距离对应其MAD。", "result": "在包含确定性和随机动态、离散和连续状态空间及噪声观察的多种环境中，该方法不仅能高效学习准确的MAD表示，而且在表示质量上显著优于现有方法。", "conclusion": "最小动作距离（MAD）作为一种密集且几何意义明确的进度度量，能够有效捕捉环境结构，支持多种下游任务，且在多样环境中表现出优越的表示学习能力。"}}
{"id": "2506.09172", "title": "MultiNet: An Open-Source Software Toolkit \\& Benchmark Suite for the Evaluation and Adaptation of Multimodal Action Models", "authors": ["Pranav Guruprasad", "Yangyue Wang", "Harshvardhan Sikka"], "abstract": "Recent innovations in multimodal action models represent a promising direction for developing general-purpose agentic systems, combining visual understanding, language comprehension, and action generation. We introduce MultiNet - a novel, fully open-source benchmark and surrounding software ecosystem designed to rigorously evaluate and adapt models across vision, language, and action domains. We establish standardized evaluation protocols for assessing vision-language models (VLMs) and vision-language-action models (VLAs), and provide open source software to download relevant data, models, and evaluations. Additionally, we provide a composite dataset with over 1.3 trillion tokens of image captioning, visual question answering, commonsense reasoning, robotic control, digital game-play, simulated locomotion/manipulation, and many more tasks. The MultiNet benchmark, framework, toolkit, and evaluation harness have been used in downstream research on the limitations of VLA generalization.", "subjects": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV)", "comments": "ICML CodeML Workshop, 13 Pages, 6 Figures, 2 Tables", "pdf_url": "https://arxiv.org/pdf/2506.09172.pdf", "abstract_url": "https://arxiv.org/abs/2506.09172", "categories": ["Machine Learning (cs.LG)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "MultiNet是一个开源的软件工具包和基准套件，旨在评估和适应多模态动作模型。它提供了一个全面的数据集和评估协议，用于测试视觉-语言模型（VLMs）和视觉-语言-动作模型（VLAs）的性能。", "motivation": "解决多模态动作模型在视觉理解、语言理解和动作生成方面的评估和适应问题，促进通用代理系统的发展。", "method": "引入MultiNet，一个完全开源的基准和软件生态系统，包括标准化评估协议、开源软件以及一个包含超过1.3万亿令牌的复合数据集。", "result": "MultiNet已被用于下游研究，揭示了VLA泛化的局限性。", "conclusion": "MultiNet为多模态动作模型的评估和适应提供了一个全面的工具和数据集，有助于推动这一领域的研究和发展。"}}
{"id": "2506.09600", "title": "Effective Red-Teaming of Policy-Adherent Agents", "authors": ["Itay Nakash", "George Kour", "Koren Lazar", "Matan Vetzler", "Guy Uziel", "Ateret Anaby-Tavor"], "abstract": "Task-oriented LLM-based agents are increasingly used in domains with strict policies, such as refund eligibility or cancellation rules. The challenge lies in ensuring that the agent consistently adheres to these rules and policies, appropriately refusing any request that would violate them, while still maintaining a helpful and natural interaction. This calls for the development of tailored design and evaluation methodologies to ensure agent resilience against malicious user behavior. We propose a novel threat model that focuses on adversarial users aiming to exploit policy-adherent agents for personal benefit. To address this, we present CRAFT, a multi-agent red-teaming system that leverages policy-aware persuasive strategies to undermine a policy-adherent agent in a customer-service scenario, outperforming conventional jailbreak methods such as DAN prompts, emotional manipulation, and coercive. Building upon the existing tau-bench benchmark, we introduce tau-break, a complementary benchmark designed to rigorously assess the agent's robustness against manipulative user behavior. Finally, we evaluate several straightforward yet effective defense strategies. While these measures provide some protection, they fall short, highlighting the need for stronger, research-driven safeguards to protect policy-adherent agents from adversarial attacks", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Cryptography and Security (cs.CR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.09600.pdf", "abstract_url": "https://arxiv.org/abs/2506.09600", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Cryptography and Security (cs.CR)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种针对遵循政策的LLM代理的新威胁模型，并介绍了CRAFT系统，该系统利用政策感知的说服策略来测试代理的韧性。同时，引入了tau-break基准来评估代理对操纵性用户行为的鲁棒性，并评估了几种防御策略的有效性。", "motivation": "解决在严格政策环境下，确保基于LLM的任务导向代理既能遵守政策，又能保持自然互动的问题，特别是对抗恶意用户行为的需求。", "method": "提出了CRAFT，一个多代理红队系统，使用政策感知的说服策略来测试政策遵循代理的韧性；引入了tau-break基准来评估代理的鲁棒性。", "result": "CRAFT在客户服务场景中优于传统的越狱方法；评估的防御策略虽有一定效果，但仍不足以完全保护代理免受对抗性攻击。", "conclusion": "需要更强、基于研究的保护措施来保护遵循政策的代理免受对抗性攻击，现有的防御策略尚不足以应对挑战。"}}
{"id": "2506.09998", "title": "Flipping Against All Odds: Reducing LLM Coin Flip Bias via Verbalized Rejection Sampling", "authors": ["Tim Z. Xiao", "Johannes Zenn", "Zhen Liu", "Weiyang Liu", "Robert Bamler", "Bernhard Schölkopf"], "abstract": "Large language models (LLMs) can often accurately describe probability distributions using natural language, yet they still struggle to generate faithful samples from them. This mismatch limits their use in tasks requiring reliable stochasticity, such as Monte Carlo methods, agent-based simulations, and randomized decision-making. We investigate this gap between knowledge and sampling in the context of Bernoulli distributions. We introduce Verbalized Rejection Sampling (VRS), a natural-language adaptation of classical rejection sampling that prompts the LLM to reason about and accept or reject proposed samples. Despite relying on the same Bernoulli mechanism internally, VRS substantially reduces sampling bias across models. We provide theoretical analysis showing that, under mild assumptions, VRS improves over direct sampling, with gains attributable to both the algorithm and prompt design. More broadly, our results show how classical probabilistic tools can be verbalized and embedded into LLM workflows to improve reliability, without requiring access to model internals or heavy prompt engineering.", "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL)", "comments": "Technical Report v1 (21 pages, 14 figures)", "pdf_url": "https://arxiv.org/pdf/2506.09998.pdf", "abstract_url": "https://arxiv.org/abs/2506.09998", "categories": ["Machine Learning (cs.LG)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为Verbalized Rejection Sampling (VRS)的方法，旨在减少大型语言模型(LLMs)在生成伯努利分布样本时的偏差。VRS通过自然语言提示LLM对提议的样本进行推理并接受或拒绝，从而在不依赖模型内部结构或复杂提示工程的情况下，显著降低了采样偏差。", "motivation": "大型语言模型(LLMs)能够准确描述概率分布，但在生成忠实样本方面存在困难，这限制了其在需要可靠随机性的任务中的应用。本文旨在解决这一知识生成与采样之间的差距。", "method": "引入了Verbalized Rejection Sampling (VRS)，这是一种自然语言适应的经典拒绝采样方法，通过提示LLM对提议的样本进行推理并接受或拒绝。", "result": "VRS显著减少了跨模型的采样偏差，理论分析表明，在温和假设下，VRS优于直接采样，改进归因于算法和提示设计。", "conclusion": "研究结果表明，经典的 probabilistic 工具可以通过自然语言化并嵌入到LLM工作流程中，以提高可靠性，而无需访问模型内部或进行繁重的提示工程。"}}
{"id": "2506.09335", "title": "Intelligent System of Emergent Knowledge: A Coordination Fabric for Billions of Minds", "authors": ["Moshi Wei", "Sparks Li"], "abstract": "The Intelligent System of Emergent Knowledge (ISEK) establishes a decentralized network where human and artificial intelligence agents collaborate as peers, forming a self-organizing cognitive ecosystem. Built on Web3 infrastructure, ISEK combines three fundamental principles: (1) a decentralized multi-agent architecture resistant to censorship, (2) symbiotic AI-human collaboration with equal participation rights, and (3) resilient self-adaptation through distributed consensus mechanisms.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": "11 pages, 1 figures,", "pdf_url": "https://arxiv.org/pdf/2506.09335.pdf", "abstract_url": "https://arxiv.org/abs/2506.09335", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "《智能涌现知识系统：亿万心智的协调框架》提出了一种去中心化网络ISEK，支持人类与人工智能代理作为平等伙伴协作，形成一个自组织的认知生态系统。", "motivation": "解决如何在去中心化环境中实现人类与人工智能的有效协作，以及如何构建一个抗审查、自我适应的认知生态系统的问题。", "method": "基于Web3基础设施，结合去中心化多代理架构、共生AI-人类协作以及分布式共识机制三大基本原则。", "result": "ISEK系统能够实现人类与AI代理的平等协作，形成一个抗审查、自我适应的认知网络。", "conclusion": "ISEK为构建一个去中心化、协作性强且自我适应的智能系统提供了可行的框架，对未来的AI-人类协作有重要的启示意义。"}}
{"id": "2506.09373", "title": "LPO: Towards Accurate GUI Agent Interaction via Location Preference Optimization", "authors": ["Jiaqi Tang", "Yu Xia", "Yi-Feng Wu", "Yuwei Hu", "Yuhui Chen", "Qing-Guo Chen", "Xiaogang Xu", "Xiangyu Wu", "Hao Lu", "Yanqing Ma", "Shiyin Lu", "Qifeng Chen"], "abstract": "The advent of autonomous agents is transforming interactions with Graphical User Interfaces (GUIs) by employing natural language as a powerful intermediary. Despite the predominance of Supervised Fine-Tuning (SFT) methods in current GUI agents for achieving spatial localization, these methods face substantial challenges due to their limited capacity to accurately perceive positional data. Existing strategies, such as reinforcement learning, often fail to assess positional accuracy effectively, thereby restricting their utility. In response, we introduce Location Preference Optimization (LPO), a novel approach that leverages locational data to optimize interaction preferences. LPO uses information entropy to predict interaction positions by focusing on zones rich in information. Besides, it further introduces a dynamic location reward function based on physical distance, reflecting the varying importance of interaction positions. Supported by Group Relative Preference Optimization (GRPO), LPO facilitates an extensive exploration of GUI environments and significantly enhances interaction precision. Comprehensive experiments demonstrate LPO's superior performance, achieving SOTA results across both offline benchmarks and real-world online evaluations. Our code will be made publicly available soon, at", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.09373.pdf", "abstract_url": "https://arxiv.org/abs/2506.09373", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了位置偏好优化（LPO），一种利用位置数据优化交互偏好的新方法，通过信息熵预测信息丰富区域的交互位置，并引入基于物理距离的动态位置奖励函数，显著提高了GUI代理的交互精度。", "motivation": "当前基于监督微调（SFT）方法的GUI代理在空间定位上面临准确感知位置数据的挑战，现有策略如强化学习在评估位置准确性方面效果有限。", "method": "LPO利用信息熵预测交互位置，引入动态位置奖励函数，并通过组相对偏好优化（GRPO）支持，促进GUI环境的广泛探索。", "result": "综合实验表明，LPO在离线和在线评估中均达到了最先进的性能。", "conclusion": "LPO通过优化位置偏好，显著提升了GUI代理的交互精度，为GUI交互领域提供了新的解决方案。"}}
{"id": "2506.09396", "title": "Reasoning as a Resource: Optimizing Fast and Slow Thinking in Code Generation Models", "authors": ["Zongjie Li", "Shuai Wang"], "abstract": "This position paper proposes a fundamental shift in designing code generation models: treating reasoning depth as a controllable resource. Rather than being an incidental byproduct of prompting, we argue that the trade-off between rapid, direct answers (\"fast thinking\") and elaborate, chain-of-thought deliberation (\"slow thinking\") must be explicitly managed. We contend that optimizing reasoning budgets across the entire model lifecycle - from synthetic data creation and benchmarking to real-world deploymen - can unlock superior trade-offs among accuracy, latency, and cost. This paper outlines how adaptive control over reasoning can enrich supervision signals, motivate new multi-dimensional benchmarks, and inform cost-aware, security-conscious deployment policies. By viewing fast and slow thinking as complementary modes to be scheduled, we envision coding agents that think deep when necessary and act fast when possible.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.09396.pdf", "abstract_url": "https://arxiv.org/abs/2506.09396", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种设计代码生成模型的基本转变：将推理深度视为可控资源。主张通过优化整个模型生命周期中的推理预算，以实现准确性、延迟和成本之间的更优权衡。", "motivation": "解决代码生成模型中快速直接回答与详细链式思考之间的权衡问题，以及如何在整个模型生命周期中优化这些推理预算。", "method": "提出将推理深度作为可控资源，并通过自适应控制推理来丰富监督信号、激励新的多维度基准测试，并指导成本意识和安全意识的部署策略。", "result": "通过明确管理快速和慢速思考的权衡，可以解锁在准确性、延迟和成本之间的更优权衡。", "conclusion": "通过将快速和慢速思考视为可调度的互补模式，可以设计出在必要时深入思考、在可能时快速行动的编码代理。"}}
{"id": "2506.09434", "title": "When Is Diversity Rewarded in Cooperative Multi-Agent Learning?", "authors": ["Michael Amir", "Matteo Bettini", "Amanda Prorok"], "abstract": "The success of teams in robotics, nature, and society often depends on the division of labor among diverse specialists; however, a principled explanation for when such diversity surpasses a homogeneous team is still missing. Focusing on multi-agent task allocation problems, our goal is to study this question from the perspective of reward design: what kinds of objectives are best suited for heterogeneous teams? We first consider an instantaneous, non-spatial setting where the global reward is built by two generalized aggregation operators: an inner operator that maps the $N$ agents' effort allocations on individual tasks to a task score, and an outer operator that merges the $M$ task scores into the global team reward. We prove that the curvature of these operators determines whether heterogeneity can increase reward, and that for broad reward families this collapses to a simple convexity test. Next, we ask what incentivizes heterogeneity to emerge when embodied, time-extended agents must learn an effort allocation policy. To study heterogeneity in such settings, we use multi-agent reinforcement learning (MARL) as our computational paradigm, and introduce Heterogeneous Environment Design (HED), a gradient-based algorithm that optimizes the parameter space of underspecified MARL environments to find scenarios where heterogeneity is advantageous. Experiments in matrix games and an embodied Multi-Goal-Capture environment show that, despite the difference in settings, HED rediscovers the reward regimes predicted by our theory to maximize the advantage of heterogeneity, both validating HED and connecting our theoretical insights to reward design in MARL. Together, these results help us understand when behavioral diversity delivers a measurable benefit.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.09434.pdf", "abstract_url": "https://arxiv.org/abs/2506.09434", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了在合作多智能体学习中，多样性何时能够带来优势。通过研究多智能体任务分配问题，作者从奖励设计的角度分析了异构团队优于同构团队的条件。研究包括理论分析和多智能体强化学习实验，提出了Heterogeneous Environment Design (HED)算法，以发现多样性有利的场景。", "motivation": "解决在机器人、自然界和社会中，团队成功往往依赖于多样化的专家分工，但缺乏一个原则性的解释来说明多样性何时优于同质团队的问题。", "method": "首先在非空间瞬时设置中，通过两个广义聚合算子构建全局奖励，分析算子的曲率是否允许异构性增加奖励。接着，使用多智能体强化学习(MARL)作为计算范式，引入Heterogeneous Environment Design (HED)算法，优化未指定MARL环境的参数空间，以发现多样性有利的场景。", "result": "理论分析表明，算子的曲率决定了异构性是否能增加奖励，且对于广泛的奖励家族，这简化为一个简单的凸性测试。实验在矩阵游戏和Multi-Goal-Capture环境中验证了HED算法能够重新发现理论预测的奖励机制，最大化异构性的优势。", "conclusion": "这些结果帮助我们理解行为多样性何时能够带来可测量的好处，为MARL中的奖励设计提供了理论见解。"}}
{"id": "2506.09485", "title": "Adv-BMT: Bidirectional Motion Transformer for Safety-Critical Traffic Scenario Generation", "authors": ["Yuxin Liu", "Zhenghao Peng", "Xuanhao Cui", "Bolei Zhou"], "abstract": "Scenario-based testing is essential for validating the performance of autonomous driving (AD) systems. However, such testing is limited by the scarcity of long-tailed, safety-critical scenarios in existing datasets collected in the real world. To tackle the data issue, we propose the Adv-BMT framework, which augments real-world scenarios with diverse and realistic adversarial interactions. The core component of Adv-BMT is a bidirectional motion transformer (BMT) model to perform inverse traffic motion predictions, which takes agent information in the last time step of the scenario as input, and reconstruct the traffic in the inverse of chronological order until the initial time step. The Adv-BMT framework is a two-staged pipeline: it first conducts adversarial initializations and then inverse motion predictions. Different from previous work, we do not need any collision data for pretraining, and are able to generate realistic and diverse collision interactions. Our experimental results validate the quality of generated collision scenarios by Adv-BMT: training in our augmented dataset would reduce episode collision rates by 20\\% compared to previous work.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Graphics (cs.GR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.09485.pdf", "abstract_url": "https://arxiv.org/abs/2506.09485", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Graphics (cs.GR)"], "matching_keywords": ["agent"], "AI": {"tldr": "Adv-BMT框架通过双向运动变换器（BMT）模型逆向预测交通运动，增强现实世界场景中的多样化和真实对抗性交互，以解决自动驾驶系统测试中安全关键场景稀缺的问题。", "motivation": "解决现有数据集中长尾、安全关键的场景稀缺问题，以验证自动驾驶系统的性能。", "method": "提出Adv-BMT框架，采用双向运动变换器（BMT）模型进行逆向交通运动预测，无需碰撞数据进行预训练，能够生成真实且多样的碰撞交互。", "result": "实验结果表明，Adv-BMT生成的碰撞场景质量高，使用增强数据集训练可将碰撞率降低20%。", "conclusion": "Adv-BMT框架有效生成多样化和真实的安全关键场景，为自动驾驶系统的测试和验证提供了重要支持。"}}
{"id": "2506.09499", "title": "A Unified Theory of Compositionality, Modularity, and Interpretability in Markov Decision Processes", "authors": ["Thomas J. Ringstrom", "Paul R. Schrater"], "abstract": "We introduce Option Kernel Bellman Equations (OKBEs) for a new reward-free Markov Decision Process. Rather than a value function, OKBEs directly construct and optimize a predictive map called a state-time option kernel (STOK) to maximize the probability of completing a goal while avoiding constraint violations. STOKs are compositional, modular, and interpretable initiation-to-termination transition kernels for policies in the Options Framework of Reinforcement Learning. This means: 1) STOKs can be composed using Chapman-Kolmogorov equations to make spatiotemporal predictions for multiple policies over long horizons, 2) high-dimensional STOKs can be represented and computed efficiently in a factorized and reconfigurable form, and 3) STOKs record the probabilities of semantically interpretable goal-success and constraint-violation events, needed for formal verification. Given a high-dimensional state-transition model for an intractable planning problem, we can decompose it with local STOKs and goal-conditioned policies that are aggregated into a factorized goal kernel, making it possible to forward-plan at the level of goals in high-dimensions to solve the problem. These properties lead to highly flexible agents that can rapidly synthesize meta-policies, reuse planning representations across many tasks, and justify goals using empowerment, an intrinsic motivation function. We argue that reward-maximization is in conflict with the properties of compositionality, modularity, and interpretability. Alternatively, OKBEs facilitate these properties to support verifiable long-horizon planning and intrinsic motivation that scales to dynamic high-dimensional world-models.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "12 Pages", "pdf_url": "https://arxiv.org/pdf/2506.09499.pdf", "abstract_url": "https://arxiv.org/abs/2506.09499", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了选项核贝尔曼方程（OKBEs）用于无奖励马尔可夫决策过程，通过构建和优化状态-时间选项核（STOK）来最大化完成目标同时避免约束违规的概率。STOKs具有组合性、模块化和可解释性，支持长期规划和内在动机。", "motivation": "解决在马尔可夫决策过程中，奖励最大化与组合性、模块化和可解释性之间的冲突，支持可验证的长期规划和内在动机。", "method": "引入选项核贝尔曼方程（OKBEs）和状态-时间选项核（STOKs），利用Chapman-Kolmogorov方程进行组合，高效表示和计算高维STOKs，记录目标成功和约束违规事件的概率。", "result": "STOKs支持高效的高维规划，能够快速合成元策略，跨任务重用规划表示，并通过赋能（empowerment）内在动机函数证明目标的合理性。", "conclusion": "OKBEs通过促进组合性、模块化和可解释性，支持可验证的长期规划和内在动机，适用于动态高维世界模型。"}}
{"id": "2506.09742", "title": "Feature Engineering for Agents: An Adaptive Cognitive Architecture for Interpretable ML Monitoring", "authors": ["Gusseppe Bravo-Rocca", "Peini Liu", "Jordi Guitart", "Rodrigo M Carrillo-Larco", "Ajay Dholakia", "David Ellison"], "abstract": "Monitoring Machine Learning (ML) models in production environments is crucial, yet traditional approaches often yield verbose, low-interpretability outputs that hinder effective decision-making. We propose a cognitive architecture for ML monitoring that applies feature engineering principles to agents based on Large Language Models (LLMs), significantly enhancing the interpretability of monitoring outputs. Central to our approach is a Decision Procedure module that simulates feature engineering through three key steps: Refactor, Break Down, and Compile. The Refactor step improves data representation to better capture feature semantics, allowing the LLM to focus on salient aspects of the monitoring data while reducing noise and irrelevant information. Break Down decomposes complex information for detailed analysis, and Compile integrates sub-insights into clear, interpretable outputs. This process leads to a more deterministic planning approach, reducing dependence on LLM-generated planning, which can sometimes be inconsistent and overly general. The combination of feature engineering-driven planning and selective LLM utilization results in a robust decision support system, capable of providing highly interpretable and actionable insights. Experiments using multiple LLMs demonstrate the efficacy of our approach, achieving significantly higher accuracy compared to various baselines across several domains.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "Accepted at AAMAS 2025", "pdf_url": "https://arxiv.org/pdf/2506.09742.pdf", "abstract_url": "https://arxiv.org/abs/2506.09742", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "提出了一种基于大型语言模型（LLMs）的认知架构，用于机器学习（ML）模型监控，通过特征工程原则增强监控输出的可解释性。", "motivation": "解决传统ML监控方法输出冗长、可解释性低，影响有效决策的问题。", "method": "采用包含重构、分解和编译三个关键步骤的决策程序模块，模拟特征工程，优化数据表示和减少噪声。", "result": "实验证明，该方法在多个领域相比基线方法显著提高了准确性。", "conclusion": "结合特征工程驱动的规划和选择性LLM利用，构建了一个强大的决策支持系统，提供高度可解释和可操作的见解。"}}
{"id": "2506.09508", "title": "Efficient Preference-Based Reinforcement Learning: Randomized Exploration Meets Experimental Design", "authors": ["Andreas Schlaginhaufen", "Reda Ouhamma", "Maryam Kamgarpour"], "abstract": "We study reinforcement learning from human feedback in general Markov decision processes, where agents learn from trajectory-level preference comparisons. A central challenge in this setting is to design algorithms that select informative preference queries to identify the underlying reward while ensuring theoretical guarantees. We propose a meta-algorithm based on randomized exploration, which avoids the computational challenges associated with optimistic approaches and remains tractable. We establish both regret and last-iterate guarantees under mild reinforcement learning oracle assumptions. To improve query complexity, we introduce and analyze an improved algorithm that collects batches of trajectory pairs and applies optimal experimental design to select informative comparison queries. The batch structure also enables parallelization of preference queries, which is relevant in practical deployment as feedback can be gathered concurrently. Empirical evaluation confirms that the proposed method is competitive with reward-based reinforcement learning while requiring a small number of preference queries.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Robotics (cs.RO); Machine Learning (stat.ML)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.09508.pdf", "abstract_url": "https://arxiv.org/abs/2506.09508", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Robotics (cs.RO)", "Machine Learning (stat.ML)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究了一种基于人类反馈的强化学习方法，通过轨迹级别的偏好比较来学习。提出了一种基于随机探索的元算法，避免了乐观方法中的计算挑战，并在温和的强化学习假设下建立了遗憾和最后迭代保证。为了改善查询复杂度，引入了批量收集轨迹对并应用最优实验设计来选择信息丰富的比较查询的改进算法。批量结构还支持偏好查询的并行化，这在实践中可以并发收集反馈。实证评估证实，所提出的方法在需要少量偏好查询的情况下与基于奖励的强化学习竞争。", "motivation": "解决在一般马尔可夫决策过程中从人类反馈学习强化学习时，如何设计算法以选择信息丰富的偏好查询来识别潜在奖励，同时确保理论保证的中心挑战。", "method": "提出了一种基于随机探索的元算法，避免了乐观方法中的计算挑战；引入并分析了一种改进算法，该算法收集批量轨迹对并应用最优实验设计来选择信息丰富的比较查询。", "result": "在温和的强化学习假设下建立了遗憾和最后迭代保证；实证评估显示，所提出的方法在需要少量偏好查询的情况下与基于奖励的强化学习竞争。", "conclusion": "提出的方法通过随机探索和最优实验设计，有效地从人类偏好中学习，同时保证了理论性能和实际应用的可行性，特别是在偏好查询的并行化方面展现了实际部署的潜力。"}}
{"id": "2506.09755", "title": "Intelligent Design 4.0: Paradigm Evolution Toward the Agentic AI Era", "authors": ["Shuo Jiang", "Min Xie", "Frank Youhua Chen", "Jian Ma", "Jianxi Luo"], "abstract": "Research and practice in Intelligent Design (ID) have significantly enhanced engineering innovation, efficiency, quality, and productivity over recent decades, fundamentally reshaping how engineering designers think, behave, and interact with design processes. The recent emergence of Foundation Models (FMs), particularly Large Language Models (LLMs), has demonstrated general knowledge-based reasoning capabilities, and open new paths and avenues for further transformation in engineering design. In this context, this paper introduces Intelligent Design 4.0 (ID 4.0) as an emerging paradigm empowered by agentic AI systems. We review the historical evolution of ID across four distinct stages: rule-based expert systems, task-specific machine learning models, large-scale foundation AI models, and the recent emerging paradigm of multi-agent collaboration. We propose a conceptual framework for ID 4.0 and discuss its potential to support end-to-end automation of engineering design processes through coordinated, autonomous multi-agent-based systems. Furthermore, we discuss future perspectives to enhance and fully realize ID 4.0's potential, including more complex design scenarios, more practical design implementations, novel agent coordination mechanisms, and autonomous design goal-setting with better human value alignment. In sum, these insights lay a foundation for advancing Intelligent Design toward greater adaptivity, autonomy, and effectiveness in addressing increasingly complex design challenges.", "subjects": "Computational Engineering, Finance, and Science (cs.CE); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.09755.pdf", "abstract_url": "https://arxiv.org/abs/2506.09755", "categories": ["Computational Engineering, Finance, and Science (cs.CE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了智能设计4.0（ID 4.0）作为一个新兴范式，由代理性AI系统赋能，回顾了智能设计从基于规则的专家系统到多代理协作的四个发展阶段，并提出了一个概念框架，讨论了其通过协调、自主的多代理系统支持工程设计过程端到端自动化的潜力。", "motivation": "解决工程设计领域中如何利用新兴的代理性AI系统（如大型语言模型）来进一步提高创新、效率、质量和生产力的问题。", "method": "回顾智能设计的历史演变，提出ID 4.0的概念框架，并讨论其通过多代理协作实现工程设计自动化的潜力。", "result": "提出了ID 4.0的概念框架，展示了其支持工程设计过程端到端自动化的潜力，并讨论了未来增强ID 4.0潜力的方向。", "conclusion": "ID 4.0为智能设计提供了向更高适应性、自主性和有效性迈进的基础，以应对日益复杂的设计挑战。"}}
{"id": "2506.09940", "title": "The Sample Complexity of Online Strategic Decision Making with Information Asymmetry and Knowledge Transportability", "authors": ["Jiachen Hu", "Rui Ai", "Han Zhong", "Xiaoyu Chen", "Liwei Wang", "Zhaoran Wang", "Zhuoran Yang"], "abstract": "Information asymmetry is a pervasive feature of multi-agent systems, especially evident in economics and social sciences. In these settings, agents tailor their actions based on private information to maximize their rewards. These strategic behaviors often introduce complexities due to confounding variables. Simultaneously, knowledge transportability poses another significant challenge, arising from the difficulties of conducting experiments in target environments. It requires transferring knowledge from environments where empirical data is more readily available. Against these backdrops, this paper explores a fundamental question in online learning: Can we employ non-i.i.d. actions to learn about confounders even when requiring knowledge transfer? We present a sample-efficient algorithm designed to accurately identify system dynamics under information asymmetry and to navigate the challenges of knowledge transfer effectively in reinforcement learning, framed within an online strategic interaction model. Our method provably achieves learning of an $\\epsilon$-optimal policy with a tight sample complexity of $O(1/\\epsilon^2)$.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)", "comments": "Accepted at ICML 2025", "pdf_url": "https://arxiv.org/pdf/2506.09940.pdf", "abstract_url": "https://arxiv.org/abs/2506.09940", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Machine Learning (stat.ML)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了在信息不对称和知识可迁移性背景下，在线战略决策的样本复杂性。提出了一种样本高效的算法，旨在准确识别信息不对称下的系统动态，并有效应对强化学习中的知识迁移挑战。", "motivation": "解决多智能体系统中由于信息不对称和知识迁移性带来的复杂性，特别是在经济学和社会科学领域，代理根据私人信息调整行动以最大化奖励的情况下。", "method": "提出了一种样本高效的算法，该算法在在线战略交互模型中，能够有效学习系统动态并处理知识迁移问题。", "result": "算法在理论上能够学习到一个ε-最优策略，其样本复杂度为O(1/ε²)。", "conclusion": "本研究为在信息不对称和知识迁移性条件下进行在线学习和战略决策提供了理论支持和实用算法，具有重要的理论和实践意义。"}}
