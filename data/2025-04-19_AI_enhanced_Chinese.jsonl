{"id": "2504.12679", "title": "TongUI: Building Generalized GUI Agents by Learning from Multimodal Web Tutorials", "authors": ["Bofei Zhang", "Zirui Shang", "Zhi Gao", "Wang Zhang", "Rui Xie", "Xiaojian Ma", "Tao Yuan", "Xinxiao Wu", "Song-Chun Zhu", "Qing Li"], "abstract": "Building Graphical User Interface (GUI) agents is a promising research direction, which simulates human interaction with computers or mobile phones to perform diverse GUI tasks. However, a major challenge in developing generalized GUI agents is the lack of sufficient trajectory data across various operating systems and applications, mainly due to the high cost of manual annotations. In this paper, we propose the TongUI framework that builds generalized GUI agents by learning from rich multimodal web tutorials. Concretely, we crawl and process online GUI tutorials (such as videos and articles) into GUI agent trajectory data, through which we produce the GUI-Net dataset containing 143K trajectory data across five operating systems and more than 200 applications. We develop the TongUI agent by fine-tuning Qwen2.5-VL-3B/7B models on GUI-Net, which show remarkable performance improvements on commonly used grounding and navigation benchmarks, outperforming baseline agents about 10\\% on multiple benchmarks, showing the effectiveness of the GUI-Net dataset and underscoring the significance of our TongUI framework. We will fully open-source the code, the GUI-Net dataset, and the trained models soon.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12679.pdf", "abstract_url": "https://arxiv.org/abs/2504.12679", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "TongUI框架通过从多模态网络教程中学习，构建了通用的GUI代理，解决了因手动标注成本高而缺乏跨操作系统和应用程序轨迹数据的问题。", "motivation": "开发通用GUI代理的主要挑战是缺乏跨各种操作系统和应用程序的足够轨迹数据，这主要是由于手动标注的高成本。", "method": "通过爬取和处理在线GUI教程（如视频和文章）为GUI代理轨迹数据，创建了包含143K轨迹数据的GUI-Net数据集，并在该数据集上微调Qwen2.5-VL-3B/7B模型来开发TongUI代理。", "result": "TongUI代理在常用的基础和导航基准测试中表现出显著的性能提升，在多个基准测试中优于基线代理约10%，证明了GUI-Net数据集的有效性和TongUI框架的重要性。", "conclusion": "TongUI框架通过利用多模态网络教程，有效地解决了GUI代理开发中的数据稀缺问题，展示了在构建通用GUI代理方面的潜力。"}}
{"id": "2504.12667", "title": "Two Tasks, One Goal: Uniting Motion and Planning for Excellent End To End Autonomous Driving Performance", "authors": ["Lin Liu", "Ziying Song", "Hongyu Pan", "Lei Yang", "Caiyan Jia"], "abstract": "End-to-end autonomous driving has made impressive progress in recent years. Former end-to-end autonomous driving approaches often decouple planning and motion tasks, treating them as separate modules. This separation overlooks the potential benefits that planning can gain from learning out-of-distribution data encountered in motion tasks. However, unifying these tasks poses significant challenges, such as constructing shared contextual representations and handling the unobservability of other vehicles' states. To address these challenges, we propose TTOG, a novel two-stage trajectory generation framework. In the first stage, a diverse set of trajectory candidates is generated, while the second stage focuses on refining these candidates through vehicle state information. To mitigate the issue of unavailable surrounding vehicle states, TTOG employs a self-vehicle data-trained state estimator, subsequently extended to other vehicles. Furthermore, we introduce ECSA (equivariant context-sharing scene adapter) to enhance the generalization of scene representations across different agents. Experimental results demonstrate that TTOG achieves state-of-the-art performance across both planning and motion tasks. Notably, on the challenging open-loop nuScenes dataset, TTOG reduces the L2 distance by 36.06\\%. Furthermore, on the closed-loop Bench2Drive dataset, our approach achieves a 22\\% improvement in the driving score (DS), significantly outperforming existing baselines.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12667.pdf", "abstract_url": "https://arxiv.org/abs/2504.12667", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新颖的两阶段轨迹生成框架TTOG，旨在统一自动驾驶中的规划和运动任务，通过共享上下文表示和处理其他车辆状态不可观测性的挑战，显著提升了端到端自动驾驶的性能。", "motivation": "传统的端到端自动驾驶方法往往将规划和运动任务解耦，忽视了运动任务中学习到的分布外数据对规划的潜在益处。统一这些任务面临构建共享上下文表示和处理其他车辆状态不可观测性等挑战。", "method": "提出了TTOG框架，包括生成多样化轨迹候选的第一阶段和通过车辆状态信息细化这些候选的第二阶段。为了解决周围车辆状态不可用的问题，TTOG采用了自车数据训练的状态估计器，并引入了ECSA（等变上下文共享场景适配器）来增强不同代理间场景表示的泛化能力。", "result": "实验结果表明，TTOG在规划和运动任务上均达到了最先进的性能。在nuScenes数据集上，L2距离减少了36.06%；在Bench2Drive数据集上，驾驶分数（DS）提高了22%，显著优于现有基线。", "conclusion": "TTOG框架通过统一规划和运动任务，有效解决了共享上下文表示和其他车辆状态不可观测性的挑战，显著提升了自动驾驶的性能，为端到端自动驾驶的发展提供了新的方向。"}}
{"id": "2504.12696", "title": "Collaborative Perception Datasets for Autonomous Driving: A Review", "authors": ["Naibang Wang", "Deyong Shang", "Yan Gong", "Xiaoxi Hu", "Ziying Song", "Lei Yang", "Yuhan Huang", "Xiaoyu Wang", "Jianli Lu"], "abstract": "Collaborative perception has attracted growing interest from academia and industry due to its potential to enhance perception accuracy, safety, and robustness in autonomous driving through multi-agent information fusion. With the advancement of Vehicle-to-Everything (V2X) communication, numerous collaborative perception datasets have emerged, varying in cooperation paradigms, sensor configurations, data sources, and application scenarios. However, the absence of systematic summarization and comparative analysis hinders effective resource utilization and standardization of model evaluation. As the first comprehensive review focused on collaborative perception datasets, this work reviews and compares existing resources from a multi-dimensional perspective. We categorize datasets based on cooperation paradigms, examine their data sources and scenarios, and analyze sensor modalities and supported tasks. A detailed comparative analysis is conducted across multiple dimensions. We also outline key challenges and future directions, including dataset scalability, diversity, domain adaptation, standardization, privacy, and the integration of large language models. To support ongoing research, we provide a continuously updated online repository of collaborative perception datasets and related literature:", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "18pages, 7figures, journal", "pdf_url": "https://arxiv.org/pdf/2504.12696.pdf", "abstract_url": "https://arxiv.org/abs/2504.12696", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文是关于自动驾驶中协作感知数据集的首次全面综述，旨在通过多维度视角回顾和比较现有资源，促进资源的有效利用和模型评估的标准化。", "motivation": "随着车联网（V2X）通信技术的发展，出现了多种协作感知数据集，但由于缺乏系统总结和比较分析，影响了资源的有效利用和模型评估的标准化。", "method": "从多维度视角对现有协作感知数据集进行分类和比较分析，包括合作范式、数据来源和场景、传感器模态及支持的任务等。", "result": "提出了数据集分类框架，并进行了详细的比较分析，同时指出了数据集可扩展性、多样性、领域适应、标准化、隐私保护及大语言模型整合等关键挑战和未来方向。", "conclusion": "本文不仅为自动驾驶协作感知领域的研究提供了宝贵的资源汇总和分析，还提出了未来研究的重点方向，并建立了一个持续更新的在线资源库以支持后续研究。"}}
{"id": "2504.12313", "title": "Exploring the Impact of Personality Traits on Conversational Recommender Systems: A Simulation with Large Language Models", "authors": ["Xiaoyan Zhao", "Yang Deng", "Wenjie Wang", "Hongzhan lin", "Hong Cheng", "Rui Zhang", "See-Kiong Ng", "Tat-Seng Chua"], "abstract": "Conversational Recommender Systems (CRSs) engage users in multi-turn interactions to deliver personalized recommendations. The emergence of large language models (LLMs) further enhances these systems by enabling more natural and dynamic user interactions. However, a key challenge remains in understanding how personality traits shape conversational recommendation outcomes. Psychological evidence highlights the influence of personality traits on user interaction behaviors. To address this, we introduce an LLM-based personality-aware user simulation for CRSs (PerCRS). The user agent induces customizable personality traits and preferences, while the system agent possesses the persuasion capability to simulate realistic interaction in CRSs. We incorporate multi-aspect evaluation to ensure robustness and conduct extensive analysis from both user and system perspectives. Experimental results demonstrate that state-of-the-art LLMs can effectively generate diverse user responses aligned with specified personality traits, thereby prompting CRSs to dynamically adjust their recommendation strategies. Our experimental analysis offers empirical insights into the impact of personality traits on the outcomes of conversational recommender systems.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12313.pdf", "abstract_url": "https://arxiv.org/abs/2504.12313", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了人格特质对会话推荐系统（CRSs）的影响，通过大型语言模型（LLMs）进行模拟，提出了一个基于LLM的人格感知用户模拟（PerCRS），展示了人格特质如何影响推荐结果。", "motivation": "会话推荐系统通过与用户的多轮互动提供个性化推荐，但人格特质如何影响这些互动和推荐结果尚不明确。", "method": "引入了一个基于LLM的人格感知用户模拟（PerCRS），包括可定制的人格特质和偏好的用户代理，以及具有说服能力的系统代理，以模拟真实的CRSs互动。", "result": "实验结果表明，先进的LLMs能有效生成与指定人格特质一致的用户响应，促使CRSs动态调整推荐策略。", "conclusion": "研究为理解人格特质对会话推荐系统结果的影响提供了实证见解，展示了LLMs在模拟和增强CRSs互动中的潜力。"}}
{"id": "2504.12322", "title": "A Strategic Coordination Framework of Small LLMs Matches Large LLMs in Data Synthesis", "authors": ["Xin Gao", "Qizhi Pei", "Zinan Tang", "Yu Li", "Honglin Lin", "Jiang Wu", "Conghui He", "Lijun Wu"], "abstract": "While data synthesis and distillation are promising strategies to enhance small language models, current approaches heavily rely on Large Language Models (LLMs), which suffer from high computational costs, environmental inefficiency, and potential biases inherited from monolithic architectures. In contrast, smaller LLMs are more accessible and sustainable, but their individual capabilities often fall short in generating high-quality, diverse, and reliable data. Inspired by collaborative human processes (e.g., peer review), we propose a multiple small LLMs involved framework, GRA, that aggregates specialized roles across small LLMs to iterative refinement and quality control typically achieved by a single large LLM. In this collaborative framework, multiple small LLMs assume distinct roles-Generator, Reviewer, and Adjudicator-to simulate a peer-review-inspired data synthesis pipeline. The Generator proposes initial data samples, the Reviewer critiques their quality and diversity, and the Adjudicator resolves conflicts to finalize the output. By decomposing the synthesis process into specialized sub-tasks, collaborative small LLMs can achieve data-level parity with large LLM-based distillation. Through experiments across multiple benchmarks, we demonstrate that GRA-produced data matches or exceeds the quality of single large LLM outputs, e.g., Qwen-2.5-72B-Instruct. Our results challenge the necessity of monolithic large models for high-quality data synthesis, advocating instead for strategic coordination of smaller agents. Our datasets, models, and code are publicly available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12322.pdf", "abstract_url": "https://arxiv.org/abs/2504.12322", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为GRA的战略协调框架，通过多个小型语言模型（LLMs）的协作，模拟同行评审过程，以合成高质量数据，挑战了大型语言模型在数据合成中的必要性。", "motivation": "当前数据合成和蒸馏方法过度依赖大型语言模型（LLMs），存在高计算成本、环境效率低下以及可能继承单一架构偏见的缺点。小型LLMs虽更易获取和可持续，但单独使用时在生成高质量、多样化和可靠数据方面能力不足。", "method": "提出了GRA框架，通过分配小型LLMs不同的角色（生成器、评审员和裁决者）来模拟同行评审过程，实现数据的迭代精炼和质量控制。", "result": "实验证明，GRA框架生成的数据在多个基准测试中匹配或超过了单一大型LLM（如Qwen-2.5-72B-Instruct）的输出质量。", "conclusion": "研究结果表明，通过小型代理的战略协调，可以实现与大型模型相当的高质量数据合成，挑战了大型模型在此领域的必要性。"}}
{"id": "2504.12323", "title": "The Other Side of the Coin: Exploring Fairness in Retrieval-Augmented Generation", "authors": ["Zheng Zhang", "Ning Li", "Qi Liu", "Rui Li", "Weibo Gao", "Qingyang Mao", "Zhenya Huang", "Baosheng Yu", "Dacheng Tao"], "abstract": "Retrieval-Augmented Generation (RAG) enhances Large Language Models (LLMs) by retrieving relevant document from external knowledge sources. By referencing this external knowledge, RAG effectively reduces the generation of factually incorrect content and addresses hallucination issues within LLMs. Recently, there has been growing attention to improving the performance and efficiency of RAG systems from various perspectives. While these advancements have yielded significant results, the application of RAG in domains with considerable societal implications raises a critical question about fairness: What impact does the introduction of the RAG paradigm have on the fairness of LLMs? To address this question, we conduct extensive experiments by varying the LLMs, retrievers, and retrieval sources. Our experimental analysis reveals that the scale of the LLMs plays a significant role in influencing fairness outcomes within the RAG framework. When the model scale is smaller than 8B, the integration of retrieval mechanisms often exacerbates unfairness in small-scale LLMs (e.g., LLaMA3.2-1B, Mistral-7B, and LLaMA3-8B). To mitigate the fairness issues introduced by RAG for small-scale LLMs, we propose two approaches, FairFT and FairFilter. Specifically, in FairFT, we align the retriever with the LLM in terms of fairness, enabling it to retrieve documents that facilitate fairer model outputs. In FairFilter, we propose a fairness filtering mechanism to filter out biased content after retrieval. Finally, we validate our proposed approaches on real-world datasets, demonstrating their effectiveness in improving fairness while maintaining performance.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "12 pages", "pdf_url": "https://arxiv.org/pdf/2504.12323.pdf", "abstract_url": "https://arxiv.org/abs/2504.12323", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文探讨了检索增强生成（RAG）在大型语言模型（LLMs）中应用的公平性问题，发现小规模LLMs（小于8B）在集成检索机制时往往会加剧不公平性，并提出了两种方法（FairFT和FairFilter）来缓解这一问题。", "motivation": "随着检索增强生成（RAG）系统在具有重大社会影响的领域中的应用日益增多，研究其对大型语言模型（LLMs）公平性的影响变得尤为重要。", "method": "通过变化LLMs、检索器和检索源进行广泛实验，分析了RAG对LLMs公平性的影响，并提出了FairFT和FairFilter两种方法来缓解小规模LLMs中的不公平性问题。", "result": "实验分析显示，模型规模对RAG框架内的公平性结果有显著影响，小规模LLMs在集成检索机制时往往会加剧不公平性。提出的FairFT和FairFilter方法在真实数据集上验证了其有效性。", "conclusion": "研究强调了在应用RAG技术时考虑公平性的重要性，并提出了有效的解决方案，以在保持性能的同时提高公平性。"}}
{"id": "2504.12477", "title": "Towards Conversational AI for Human-Machine Collaborative MLOps", "authors": ["George Fatouros", "Georgios Makridis", "George Kousiouris", "John Soldatos", "Anargyros Tsadimas", "Dimosthenis Kyriazis"], "abstract": "This paper presents a Large Language Model (LLM) based conversational agent system designed to enhance human-machine collaboration in Machine Learning Operations (MLOps). We introduce the Swarm Agent, an extensible architecture that integrates specialized agents to create and manage ML workflows through natural language interactions. The system leverages a hierarchical, modular design incorporating a KubeFlow Pipelines (KFP) Agent for ML pipeline orchestration, a MinIO Agent for data management, and a Retrieval-Augmented Generation (RAG) Agent for domain-specific knowledge integration. Through iterative reasoning loops and context-aware processing, the system enables users with varying technical backgrounds to discover, execute, and monitor ML pipelines; manage datasets and artifacts; and access relevant documentation, all via intuitive conversational interfaces. Our approach addresses the accessibility gap in complex MLOps platforms like Kubeflow, making advanced ML tools broadly accessible while maintaining the flexibility to extend to other platforms. The paper describes the architecture, implementation details, and demonstrates how this conversational MLOps assistant reduces complexity and lowers barriers to entry for users across diverse technical skill levels.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)", "comments": "8 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2504.12477.pdf", "abstract_url": "https://arxiv.org/abs/2504.12477", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文介绍了一种基于大型语言模型（LLM）的对话代理系统，旨在增强人机协作在机器学习操作（MLOps）中的应用。通过Swarm Agent的可扩展架构，系统整合了专门代理，通过自然语言交互创建和管理ML工作流程。", "motivation": "解决复杂MLOps平台（如Kubeflow）的可访问性问题，使不同技术背景的用户能够通过直观的对话界面使用高级ML工具。", "method": "采用分层模块化设计，整合KubeFlow Pipelines Agent进行ML管道编排，MinIO Agent进行数据管理，以及RAG Agent进行领域特定知识集成。", "result": "通过迭代推理循环和上下文感知处理，系统能够降低复杂性，为不同技术水平的用户降低入门门槛。", "conclusion": "该对话式MLOps助手通过减少复杂性和降低使用门槛，使高级ML工具更广泛地可访问，同时保持扩展到其他平台的灵活性。"}}
{"id": "2504.12482", "title": "Agentic AI Optimisation (AAIO): what it is, how it works, why it matters, and how to deal with it", "authors": ["Luciano Floridi", "Carlotta Buttaboni", "Emmie Hine", "Jessica Morley", "Claudio Novelli", "Tyler Schroder"], "abstract": "The emergence of Agentic Artificial Intelligence (AAI) systems capable of independently initiating digital interactions necessitates a new optimisation paradigm designed explicitly for seamless agent-platform interactions. This article introduces Agentic AI Optimisation (AAIO) as an essential methodology for ensuring effective integration between websites and agentic AI systems. Like how Search Engine Optimisation (SEO) has shaped digital content discoverability, AAIO can define interactions between autonomous AI agents and online platforms. By examining the mutual interdependency between website optimisation and agentic AI success, the article highlights the virtuous cycle that AAIO can create. It further explores the governance, ethical, legal, and social implications (GELSI) of AAIO, emphasising the necessity of proactive regulatory frameworks to mitigate potential negative impacts. The article concludes by affirming AAIO's essential role as part of a fundamental digital infrastructure in the era of autonomous digital agents, advocating for equitable and inclusive access to its benefits.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12482.pdf", "abstract_url": "https://arxiv.org/abs/2504.12482", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了代理性人工智能优化（AAIO）作为一种新方法，旨在确保网站与代理性AI系统之间的有效整合。类似于搜索引擎优化（SEO）对数字内容可发现性的影响，AAIO可以定义自主AI代理与在线平台之间的互动。文章探讨了AAIO在治理、伦理、法律和社会影响（GELSI）方面的意义，并强调了建立积极监管框架的必要性。", "motivation": "随着能够独立发起数字互动的代理性人工智能（AAI）系统的出现，需要一种新的优化范式来专门确保代理与平台之间的无缝互动。", "method": "文章提出了代理性人工智能优化（AAIO）作为一种关键方法，通过分析网站优化与代理性AI成功之间的相互依赖性，突出了AAIO可以创造的良性循环。", "result": "AAIO不仅能够促进代理性AI与在线平台之间的有效互动，还引发了关于治理、伦理、法律和社会影响的广泛讨论。", "conclusion": "文章确认了AAIO在自主数字代理时代作为基本数字基础设施的重要组成部分，并倡导公平和包容地获取其好处。"}}
{"id": "2504.12497", "title": "Heuristic Recognition and Rapid Response to Unfamiliar Events Outside of Agent Design Scope", "authors": ["Robert E. Wray", "Steven J. Jones", "John E. Laird"], "abstract": "Regardless of past learning, an agent in an open world will face unfamiliar situations and events outside of prior experience, existing models, or policies. Further, the agent will sometimes lack relevant knowledge and/or sufficient time to assess the situation, generate and evaluate options, and pursue a robustly considered course of action. How can an agent respond reasonably to situations that are outside of its original design scope? How can it recognize such situations sufficiently quickly and reliably to determine reasonable, adaptive courses of action? We identify key characteristics needed for solutions, evaluate the state-of-the-art by these requirements, and outline a proposed, novel approach that combines domain-general meta-knowledge (in the form of appraisals inspired by human cognition) and metareasoning. It has the potential to provide fast, adaptive responses to unfamiliar situations, more fully meeting the performance characteristics required for open-world, general agents.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "12 pages, 3 figures. Submitted to AGI25 conference", "pdf_url": "https://arxiv.org/pdf/2504.12497.pdf", "abstract_url": "https://arxiv.org/abs/2504.12497", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了开放世界中智能体面对超出其设计范围的不熟悉事件时，如何快速识别并合理响应的问题。通过结合受人类认知启发的领域通用元知识和元推理，提出了一种新颖方法，旨在为开放世界中的通用智能体提供快速、自适应的响应能力。", "motivation": "解决智能体在开放世界中遇到超出其原有设计范围、经验或模型的不熟悉情况时，如何快速识别并采取合理行动的问题。", "method": "提出了一种结合领域通用元知识（受人类认知启发的评估）和元推理的新方法。", "result": "该方法有潜力为开放世界中的通用智能体提供快速、自适应的响应，更全面地满足其性能要求。", "conclusion": "通过结合领域通用元知识和元推理，可以有效地解决智能体在面对不熟悉事件时的快速识别和合理响应问题，这对于开放世界中的通用智能体具有重要意义。"}}
{"id": "2504.12612", "title": "The Chronicles of Foundation AI for Forensics of Multi-Agent Provenance", "authors": ["Ching-Chun Chang", "Isao Echizen"], "abstract": "Provenance is the chronology of things, resonating with the fundamental pursuit to uncover origins, trace connections, and situate entities within the flow of space and time. As artificial intelligence advances towards autonomous agents capable of interactive collaboration on complex tasks, the provenance of generated content becomes entangled in the interplay of collective creation, where contributions are continuously revised, extended or overwritten. In a multi-agent generative chain, content undergoes successive transformations, often leaving little, if any, trace of prior contributions. In this study, we investigates the problem of tracking multi-agent provenance across the temporal dimension of generation. We propose a chronological system for post hoc attribution of generative history from content alone, without reliance on internal memory states or external meta-information. At its core lies the notion of symbolic chronicles, representing signed and time-stamped records, in a form analogous to the chain of custody in forensic science. The system operates through a feedback loop, whereby each generative timestep updates the chronicle of prior interactions and synchronises it with the synthetic content in the very act of generation. This research seeks to develop an accountable form of collaborative artificial intelligence within evolving cyber ecosystems.", "subjects": "Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12612.pdf", "abstract_url": "https://arxiv.org/abs/2504.12612", "categories": ["Artificial Intelligence (cs.AI)", "Cryptography and Security (cs.CR)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究了在多智能体生成链中追踪内容来源的问题，提出了一种基于符号编年史的系统，用于事后归因生成历史，旨在开发一种可追溯的协作人工智能形式。", "motivation": "随着人工智能向能够交互协作完成复杂任务的自主智能体发展，生成内容的来源在多智能体的集体创作中变得复杂，难以追踪。", "method": "研究提出了一种基于符号编年史的系统，通过反馈循环更新交互记录，并与生成内容同步，无需依赖内部记忆状态或外部元信息。", "result": "开发了一种能够从内容本身追溯生成历史的系统，类似于法医学中的保管链，为协作人工智能提供了可追溯性。", "conclusion": "这项研究为在不断发展的网络生态系统中开发可追溯的协作人工智能形式提供了基础，有助于确保生成内容的透明度和可追溯性。"}}
{"id": "2504.12682", "title": "WebLists: Extracting Structured Information From Complex Interactive Websites Using Executable LLM Agents", "authors": ["Arth Bohra", "Manvel Saroyan", "Danil Melkozerov", "Vahe Karufanyan", "Gabriel Maher", "Pascal Weinberger", "Artem Harutyunyan", "Giovanni Campagna"], "abstract": "Most recent web agent research has focused on navigation and transaction tasks, with little emphasis on extracting structured data at scale. We present WebLists, a benchmark of 200 data-extraction tasks across four common business and enterprise use-cases. Each task requires an agent to navigate to a webpage, configure it appropriately, and extract complete datasets with well-defined schemas. We show that both LLMs with search capabilities and SOTA web agents struggle with these tasks, with a recall of 3% and 31%, respectively, despite higher performance on question-answering tasks.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12682.pdf", "abstract_url": "https://arxiv.org/abs/2504.12682", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "WebLists提出了一个包含200个数据提取任务的基准测试，覆盖四种常见的商业和企业用例，展示了当前LLMs和SOTA网络代理在这些任务上的表现不佳。", "motivation": "解决从复杂的交互式网站中大规模提取结构化数据的问题，当前的研究主要集中在导航和交易任务上，而忽视了数据提取。", "method": "通过创建一个包含200个任务的基准测试WebLists，评估LLMs和SOTA网络代理在导航到网页、配置页面和提取完整数据集方面的能力。", "result": "LLMs和SOTA网络代理在数据提取任务上的召回率分别为3%和31%，远低于其在问答任务上的表现。", "conclusion": "研究表明，现有的LLMs和网络代理在处理复杂的结构化数据提取任务时存在显著挑战，需要进一步的研究和改进。"}}
{"id": "2504.13032", "title": "InstructRAG: Leveraging Retrieval-Augmented Generation on Instruction Graphs for LLM-Based Task Planning", "authors": ["Zheng Wang", "Shu Xian Teo", "Jun Jie Chew", "Wei Shi"], "abstract": "Recent advancements in large language models (LLMs) have enabled their use as agents for planning complex tasks. Existing methods typically rely on a thought-action-observation (TAO) process to enhance LLM performance, but these approaches are often constrained by the LLMs' limited knowledge of complex tasks. Retrieval-augmented generation (RAG) offers new opportunities by leveraging external databases to ground generation in retrieved information. In this paper, we identify two key challenges (enlargability and transferability) in applying RAG to task planning. We propose InstructRAG, a novel solution within a multi-agent meta-reinforcement learning framework, to address these challenges. InstructRAG includes a graph to organize past instruction paths (sequences of correct actions), an RL-Agent with Reinforcement Learning to expand graph coverage for enlargability, and an ML-Agent with Meta-Learning to improve task generalization for transferability. The two agents are trained end-to-end to optimize overall planning performance. Our experiments on four widely used task planning datasets demonstrate that InstructRAG significantly enhances performance and adapts efficiently to new tasks, achieving up to a 19.2% improvement over the best existing approach.", "subjects": "Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": "This paper has been accepted by SIGIR 2025", "pdf_url": "https://arxiv.org/pdf/2504.13032.pdf", "abstract_url": "https://arxiv.org/abs/2504.13032", "categories": ["Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文提出了InstructRAG，一种在多智能体元强化学习框架下的新解决方案，旨在通过检索增强生成（RAG）技术解决任务规划中的可扩展性和可转移性挑战。", "motivation": "大型语言模型（LLMs）在规划复杂任务时，受限于其对复杂任务的有限知识，现有的思维-行动-观察（TAO）过程方法存在局限性。", "method": "InstructRAG通过组织过去指令路径的图、使用强化学习的RL-Agent扩展图覆盖以提高可扩展性，以及使用元学习的ML-Agent提高任务泛化以实现可转移性，两智能体端到端训练以优化整体规划性能。", "result": "在四个广泛使用的任务规划数据集上的实验表明，InstructRAG显著提升了性能，并能高效适应新任务，比现有最佳方法提高了19.2%。", "conclusion": "InstructRAG通过结合检索增强生成和多智能体元强化学习，有效解决了任务规划中的关键挑战，为LLM-based任务规划提供了新的解决方案。"}}
{"id": "2504.13145", "title": "Exploring Expert Failures Improves LLM Agent Tuning", "authors": ["Li-Cheng Lan", "Andrew Bai", "Minhao Cheng", "Ruochen Wang", "Cho-Jui Hsieh", "Tianyi Zhou"], "abstract": "Large Language Models (LLMs) have shown tremendous potential as agents, excelling at tasks that require multiple rounds of reasoning and interactions. Rejection Sampling Fine-Tuning (RFT) has emerged as an effective method for finetuning LLMs as agents: it first imitates expert-generated successful trajectories and further improves agentic skills through iterative fine-tuning on successful, self-generated trajectories. However, since the expert (e.g., GPT-4) succeeds primarily on simpler subtasks and RFT inherently favors simpler scenarios, many complex subtasks remain unsolved and persistently out-of-distribution (OOD). Upon investigating these challenging subtasks, we discovered that previously failed expert trajectories can often provide valuable guidance, e.g., plans and key actions, that can significantly improve agent exploration efficiency and acquisition of critical skills. Motivated by these observations, we propose Exploring Expert Failures (EEF), which identifies beneficial actions from failed expert trajectories and integrates them into the training dataset. Potentially harmful actions are meticulously excluded to prevent contamination of the model learning process. By leveraging the beneficial actions in expert failures, EEF successfully solves some previously unsolvable subtasks and improves agent tuning performance. Remarkably, our approach achieved a 62\\% win rate in WebShop, outperforming RFT (53. 6\\%) and GPT-4 (35. 6\\%), and to the best of our knowledge, setting a new state-of-the-art as the first method to surpass a score of 0.81 in WebShop and exceed 81 in SciWorld.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.13145.pdf", "abstract_url": "https://arxiv.org/abs/2504.13145", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种名为探索专家失败（EEF）的新方法，通过分析专家（如GPT-4）在复杂子任务上的失败轨迹，提取有价值的指导和关键动作，以提高大型语言模型（LLM）代理的调优效率和性能。EEF方法在WebShop和SciWorld任务中取得了显著优于现有方法的结果。", "motivation": "尽管拒绝采样微调（RFT）在微调LLM代理方面表现出色，但在处理复杂子任务时，由于专家主要在较简单的子任务上成功，且RFT倾向于简单场景，许多复杂子任务仍无法解决且持续处于分布外（OOD）。本文旨在通过利用专家失败中的有益信息来解决这一问题。", "method": "提出的EEF方法通过识别失败专家轨迹中的有益动作，并将这些动作整合到训练数据集中，同时排除潜在有害动作以避免污染模型学习过程，从而提高代理的探索效率和关键技能的获取。", "result": "EEF方法成功解决了一些之前无法解决的子任务，并在WebShop任务中实现了62%的胜率，显著优于RFT（53.6%）和GPT-4（35.6%），在WebShop和SciWorld任务中创造了新的最先进水平。", "conclusion": "通过探索专家失败中的有益信息，EEF方法不仅提高了LLM代理的性能，还为处理复杂子任务提供了一种新的有效途径，展示了利用失败经验提升模型能力的潜力。"}}
{"id": "2504.13171", "title": "Sleep-time Compute: Beyond Inference Scaling at Test-time", "authors": ["Kevin Lin", "Charlie Snell", "Yu Wang", "Charles Packer", "Sarah Wooders", "Ion Stoica", "Joseph E. Gonzalez"], "abstract": "Scaling test-time compute has emerged as a key ingredient for enabling large language models (LLMs) to solve difficult problems, but comes with high latency and inference cost. We introduce sleep-time compute, which allows models to \"think\" offline about contexts before queries are presented: by anticipating what queries users might ask and pre-computing useful quantities, we can significantly reduce the compute requirements at test-time. To demonstrate the efficacy of our method, we create modified versions of two reasoning tasks - Stateful GSM-Symbolic and Stateful AIME. We find that sleep-time compute can reduce the amount of test-time compute needed to achieve the same accuracy by ~ 5x on Stateful GSM-Symbolic and Stateful AIME and that by scaling sleep-time compute we can further increase accuracy by up to 13% on Stateful GSM-Symbolic and 18% on Stateful AIME. Furthermore, we introduce Multi-Query GSM-Symbolic, which extends GSM-Symbolic by including multiple related queries per context. By amortizing sleep-time compute across related queries about the same context using Multi-Query GSM-Symbolic, we can decrease the average cost per query by 2.5x. We then conduct additional analysis to understand when sleep-time compute is most effective, finding the predictability of the user query to be well correlated with the efficacy of sleep-time compute. Finally, we conduct a case-study of applying sleep-time compute to a realistic agentic SWE task.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2504.13171.pdf", "abstract_url": "https://arxiv.org/abs/2504.13171", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了‘睡眠时间计算’方法，通过在查询前预计算，减少测试时的计算需求，提高大型语言模型的效率和准确性。", "motivation": "解决大型语言模型在测试时高延迟和高计算成本的问题。", "method": "引入‘睡眠时间计算’，预计算用户可能提出的查询和相关量，减少测试时的计算需求。", "result": "在Stateful GSM-Symbolic和Stateful AIME任务中，测试时计算需求减少约5倍，准确性提高13%和18%。通过Multi-Query GSM-Symbolic，每个查询的平均成本降低2.5倍。", "conclusion": "睡眠时间计算能有效减少测试时的计算需求和提高准确性，特别是在用户查询可预测时效果更佳。"}}
{"id": "2504.12330", "title": "HM-RAG: Hierarchical Multi-Agent Multimodal Retrieval Augmented Generation", "authors": ["Pei Liu", "Xin Liu", "Ruoyu Yao", "Junming Liu", "Siyuan Meng", "Ding Wang", "Jun Ma"], "abstract": "While Retrieval-Augmented Generation (RAG) augments Large Language Models (LLMs) with external knowledge, conventional single-agent RAG remains fundamentally limited in resolving complex queries demanding coordinated reasoning across heterogeneous data ecosystems. We present HM-RAG, a novel Hierarchical Multi-agent Multimodal RAG framework that pioneers collaborative intelligence for dynamic knowledge synthesis across structured, unstructured, and graph-based data. The framework is composed of three-tiered architecture with specialized agents: a Decomposition Agent that dissects complex queries into contextually coherent sub-tasks via semantic-aware query rewriting and schema-guided context augmentation; Multi-source Retrieval Agents that carry out parallel, modality-specific retrieval using plug-and-play modules designed for vector, graph, and web-based databases; and a Decision Agent that uses consistency voting to integrate multi-source answers and resolve discrepancies in retrieval results through Expert Model Refinement. This architecture attains comprehensive query understanding by combining textual, graph-relational, and web-derived evidence, resulting in a remarkable 12.95% improvement in answer accuracy and a 3.56% boost in question classification accuracy over baseline RAG systems on the ScienceQA and CrisisMMD benchmarks. Notably, HM-RAG establishes state-of-the-art results in zero-shot settings on both datasets. Its modular architecture ensures seamless integration of new data modalities while maintaining strict data governance, marking a significant advancement in addressing the critical challenges of multimodal reasoning and knowledge synthesis in RAG systems. Code is available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12330.pdf", "abstract_url": "https://arxiv.org/abs/2504.12330", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "HM-RAG是一种新颖的分层多代理多模态检索增强生成框架，通过协作智能动态合成跨结构化、非结构化和基于图的数据的知识，显著提高了答案准确性和问题分类准确性。", "motivation": "解决传统单代理RAG在处理需要跨异构数据生态系统协调推理的复杂查询时的根本限制。", "method": "采用三层架构，包括分解代理、多源检索代理和决策代理，通过语义感知查询重写、模式引导上下文增强、并行多模态特定检索和一致性投票等方法。", "result": "在ScienceQA和CrisisMMD基准测试中，答案准确性提高了12.95%，问题分类准确性提高了3.56%，并在零射击设置中建立了最先进的结果。", "conclusion": "HM-RAG的模块化架构确保了新数据模态的无缝集成，同时保持严格的数据治理，标志着在解决RAG系统中多模态推理和知识合成的关键挑战方面取得了重大进展。"}}
{"id": "2504.12342", "title": "Benchmarking Biopharmaceuticals Retrieval-Augmented Generation Evaluation", "authors": ["Hanmeng Zhong", "Linqing Chen", "Weilei Wang", "Wentao Wu"], "abstract": "Recently, the application of the retrieval-augmented Large Language Models (LLMs) in specific domains has gained significant attention, especially in biopharmaceuticals. However, in this context, there is no benchmark specifically designed for biopharmaceuticals to evaluate LLMs. In this paper, we introduce the Biopharmaceuticals Retrieval-Augmented Generation Evaluation (BRAGE) , the first benchmark tailored for evaluating LLMs' Query and Reference Understanding Capability (QRUC) in the biopharmaceutical domain, available in English, French, German and Chinese. In addition, Traditional Question-Answering (QA) metrics like accuracy and exact match fall short in the open-ended retrieval-augmented QA scenarios. To address this, we propose a citation-based classification method to evaluate the QRUC of LLMs to understand the relationship between queries and references. We apply this method to evaluate the mainstream LLMs on BRAGE. Experimental results show that there is a significant gap in the biopharmaceutical QRUC of mainstream LLMs, and their QRUC needs to be improved.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12342.pdf", "abstract_url": "https://arxiv.org/abs/2504.12342", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了首个针对生物制药领域的检索增强大型语言模型（LLMs）评估基准——BRAGE，旨在评估LLMs在生物制药领域的查询和参考理解能力（QRUC）。", "motivation": "当前缺乏专门针对生物制药领域的基准来评估检索增强的大型语言模型（LLMs），且传统的问答（QA）指标在开放式的检索增强QA场景中表现不足。", "method": "提出了一个基于引用的分类方法，用于评估LLMs的查询和参考理解能力（QRUC），并在BRAGE基准上对主流LLMs进行了评估。", "result": "实验结果显示，主流LLMs在生物制药领域的QRUC存在显著差距，需要进一步改进。", "conclusion": "BRAGE基准的引入和基于引用的分类方法为评估和改进LLMs在生物制药领域的QRUC提供了重要工具和方向。"}}
{"id": "2504.12345", "title": "Reimagining Urban Science: Scaling Causal Inference with Large Language Models", "authors": ["Yutong Xia", "Ao Qu", "Yunhan Zheng", "Yihong Tang", "Dingyi Zhuang", "Yuxuan Liang", "Cathy Wu", "Roger Zimmermann", "Jinhua Zhao"], "abstract": "Urban causal research is essential for understanding the complex dynamics of cities and informing evidence-based policies. However, it is challenged by the inefficiency and bias of hypothesis generation, barriers to multimodal data complexity, and the methodological fragility of causal experimentation. Recent advances in large language models (LLMs) present an opportunity to rethink how urban causal analysis is conducted. This Perspective examines current urban causal research by analyzing taxonomies that categorize research topics, data sources, and methodological approaches to identify structural gaps. We then introduce an LLM-driven conceptual framework, AutoUrbanCI, composed of four distinct modular agents responsible for hypothesis generation, data engineering, experiment design and execution, and results interpretation with policy recommendations. We propose evaluation criteria for rigor and transparency and reflect on implications for human-AI collaboration, equity, and accountability. We call for a new research agenda that embraces AI-augmented workflows not as replacements for human expertise but as tools to broaden participation, improve reproducibility, and unlock more inclusive forms of urban causal reasoning.", "subjects": "Computation and Language (cs.CL); Computers and Society (cs.CY); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12345.pdf", "abstract_url": "https://arxiv.org/abs/2504.12345", "categories": ["Computation and Language (cs.CL)", "Computers and Society (cs.CY)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了利用大型语言模型（LLMs）重新构想城市科学，特别是因果推理的规模化应用。提出了一个名为AutoUrbanCI的LLM驱动框架，旨在解决城市因果研究中的假设生成、数据处理、实验设计和结果解释等挑战。", "motivation": "城市因果研究对于理解城市复杂动态和制定基于证据的政策至关重要，但面临假设生成的低效和偏见、多模态数据复杂性以及因果实验方法脆弱性等挑战。", "method": "引入了一个由四个模块化代理组成的LLM驱动框架AutoUrbanCI，分别负责假设生成、数据工程、实验设计与执行以及结果解释与政策建议。", "result": "提出了评估严谨性和透明度的标准，并反思了人机协作、公平性和责任性的意义。", "conclusion": "呼吁建立一个新研究议程，将AI增强的工作流程视为扩展参与、提高可重复性并实现更包容城市因果推理的工具，而非替代人类专业知识。"}}
{"id": "2504.12516", "title": "BrowseComp: A Simple Yet Challenging Benchmark for Browsing Agents", "authors": ["Jason Wei", "Zhiqing Sun", "Spencer Papay", "Scott McKinney", "Jeffrey Han", "Isa Fulford", "Hyung Won Chung", "Alex Tachard Passos", "William Fedus", "Amelia Glaese"], "abstract": "We present BrowseComp, a simple yet challenging benchmark for measuring the ability for agents to browse the web. BrowseComp comprises 1,266 questions that require persistently navigating the internet in search of hard-to-find, entangled information. Despite the difficulty of the questions, BrowseComp is simple and easy-to-use, as predicted answers are short and easily verifiable against reference answers. BrowseComp for browsing agents can be seen as analogous to how programming competitions are an incomplete but useful benchmark for coding agents. While BrowseComp sidesteps challenges of a true user query distribution, like generating long answers or resolving ambiguity, it measures the important core capability of exercising persistence and creativity in finding information. BrowseComp can be found at", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12516.pdf", "abstract_url": "https://arxiv.org/abs/2504.12516", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "BrowseComp是一个简单但具有挑战性的基准测试，旨在评估网络浏览代理的能力。它包含1,266个需要持续浏览互联网以寻找难以找到、纠缠信息的问题。", "motivation": "解决如何有效测量网络浏览代理在寻找复杂信息时的持久性和创造性的问题。", "method": "通过设计一个包含1,266个问题的基准测试，这些问题需要代理持续浏览互联网以寻找答案，且答案简短易于验证。", "result": "BrowseComp提供了一个简单易用但具有挑战性的测试平台，能够有效评估浏览代理的核心能力。", "conclusion": "BrowseComp作为一个基准测试，虽然不完全模拟真实用户查询分布，但有效测量了浏览代理在寻找信息时的持久性和创造性，为开发更高效的浏览代理提供了重要工具。"}}
{"id": "2504.12560", "title": "CDF-RAG: Causal Dynamic Feedback for Adaptive Retrieval-Augmented Generation", "authors": ["Elahe Khatibi", "Ziyu Wang", "Amir M. Rahmani"], "abstract": "Retrieval-Augmented Generation (RAG) has significantly enhanced large language models (LLMs) in knowledge-intensive tasks by incorporating external knowledge retrieval. However, existing RAG frameworks primarily rely on semantic similarity and correlation-driven retrieval, limiting their ability to distinguish true causal relationships from spurious associations. This results in responses that may be factually grounded but fail to establish cause-and-effect mechanisms, leading to incomplete or misleading insights. To address this issue, we introduce Causal Dynamic Feedback for Adaptive Retrieval-Augmented Generation (CDF-RAG), a framework designed to improve causal consistency, factual accuracy, and explainability in generative reasoning. CDF-RAG iteratively refines queries, retrieves structured causal graphs, and enables multi-hop causal reasoning across interconnected knowledge sources. Additionally, it validates responses against causal pathways, ensuring logically coherent and factually grounded outputs. We evaluate CDF-RAG on four diverse datasets, demonstrating its ability to improve response accuracy and causal correctness over existing RAG-based methods. Our code is publicly available at", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12560.pdf", "abstract_url": "https://arxiv.org/abs/2504.12560", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "CDF-RAG是一个旨在通过因果动态反馈增强检索增强生成（RAG）框架的新方法，以提高生成推理中的因果一致性、事实准确性和可解释性。", "motivation": "现有的RAG框架主要依赖语义相似性和相关性驱动的检索，难以区分真实的因果关系与虚假的关联，导致生成的反应可能基于事实但缺乏因果机制，产生不完整或误导性的见解。", "method": "CDF-RAG通过迭代优化查询、检索结构化因果图，并实现跨互联知识源的多跳因果推理，同时根据因果路径验证反应，确保逻辑一致和事实基础。", "result": "在四个不同数据集上的评估显示，CDF-RAG在提高反应准确性和因果正确性方面优于现有的基于RAG的方法。", "conclusion": "CDF-RAG通过引入因果动态反馈机制，显著提升了RAG框架在知识密集型任务中的表现，特别是在理解和应用因果关系方面。"}}
{"id": "2504.12563", "title": "MetaSynth: Meta-Prompting-Driven Agentic Scaffolds for Diverse Synthetic Data Generation", "authors": ["Haris Riaz", "Sourav Bhabesh", "Vinayak Arannil", "Miguel Ballesteros", "Graham Horwood"], "abstract": "Recent smaller language models such Phi-3.5 and Phi-4 rely on synthetic data generated using larger Language models. Questions remain about leveraging synthetic data for other use cases, such as adapting LLMs to specific domains. A key limitation of synthetic data is low diversity, which negatively impacts its downstream applicability for improving other models. To address this, we propose MetaSynth, a method for generating synthetic data that enhances diversity through meta-prompting, where a language model orchestrates multiple \"expert\" LLM agents to collaboratively generate data. Using only 25 million tokens of synthetic data generated with MetaSynth, we successfully adapt a well-trained LLM (Mistral-7B-v0.3) to two specialized domains-Finance and Biomedicine-without compromising the capabilities of the resulting model in general tasks. In addition, we evaluate the diversity of our synthetic data using seven automated metrics, and find that it approaches the diversity of LLM pre-training corpora.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "33 pages, 17 figures. Preprint", "pdf_url": "https://arxiv.org/pdf/2504.12563.pdf", "abstract_url": "https://arxiv.org/abs/2504.12563", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "MetaSynth提出了一种通过元提示驱动多专家LLM代理协作生成合成数据的方法，以提高数据的多样性，并成功将Mistral-7B-v0.3模型适配到金融和生物医学领域。", "motivation": "解决合成数据多样性低的问题，以增强其在特定领域模型适配中的下游应用效果。", "method": "使用元提示技术，让一个语言模型协调多个“专家”LLM代理协作生成数据。", "result": "仅用2500万 tokens的MetaSynth生成数据，成功将Mistral-7B-v0.3模型适配到金融和生物医学领域，且不损害模型在通用任务上的能力。合成数据的多样性接近LLM预训练语料库。", "conclusion": "MetaSynth方法能有效提高合成数据的多样性，支持特定领域模型的适配，同时保持模型在通用任务上的性能。"}}
{"id": "2504.12673", "title": "ACoRN: Noise-Robust Abstractive Compression in Retrieval-Augmented Language Models", "authors": ["Singon Kim", "Gunho Jung", "Seong-Whan Lee"], "abstract": "Abstractive compression utilizes smaller langauge models to condense query-relevant context, reducing computational costs in retrieval-augmented generation (RAG). However,retrieved documents often include information that is either irrelevant to answering the query or misleading due to factual incorrect content, despite having high relevance scores. This behavior indicates that abstractive compressors are more likely to omit important information essential for the correct answer, especially in long contexts where attention dispersion occurs. To address this issue, we categorize retrieved documents in a more fine-grained manner and propose Abstractive Compression Robust against Noise (ACoRN), which introduces two novel training steps. First, we use offline data augmentation on the training dataset to enhance compressor robustness against two distinct types of retrieval noise. Second, since the language modelbased compressor cannot fully utilize information from multiple retrieved documents and exhibits positional bias, we perform finetuning to generate summaries centered around key information that directly supports the correct answer. Our experiments demonstrate that T5-large, trained with ACoRN as a compressor, improves EM and F1 scores while preserving the answer string, which could serve as direct evidence. ACoRN excels on datasets with many accuracy-reducing documents, making it highly useful in real-world scenarios.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12673.pdf", "abstract_url": "https://arxiv.org/abs/2504.12673", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "ACoRN是一种针对检索增强语言模型的噪声鲁棒性抽象压缩方法，通过细粒度分类检索文档和引入两个新的训练步骤，提高了压缩模型在存在噪声情况下的性能。", "motivation": "解决检索增强生成（RAG）中，由于检索文档包含无关或误导信息，导致抽象压缩模型忽略重要信息的问题。", "method": "提出ACoRN方法，包括对训练数据集进行离线数据增强以提高压缩模型对检索噪声的鲁棒性，以及微调模型以生成围绕关键信息的摘要。", "result": "实验表明，使用ACoRN训练的T5-large模型在保持答案字符串的同时，提高了EM和F1分数，尤其在包含大量降低准确性文档的数据集上表现优异。", "conclusion": "ACoRN在现实世界场景中非常有用，特别是在处理包含大量噪声的检索文档时，能够有效提升抽象压缩模型的性能和准确性。"}}
{"id": "2504.12734", "title": "Pandora: A Code-Driven Large Language Model Agent for Unified Reasoning Across Diverse Structured Knowledge", "authors": ["Yongrui Chen", "Junhao He", "Linbo Fu", "Shenyu Zhang", "Rihui Jin", "Xinbang Dai", "Jiaqi Li", "Dehai Min", "Nan Hu", "Yuxin Zhang", "Guilin Qi", "Yi Huang", "Tongtong Wu"], "abstract": "Unified Structured Knowledge Reasoning (USKR) aims to answer natural language questions (NLQs) by using structured sources such as tables, databases, and knowledge graphs in a unified way. Existing USKR methods either rely on employing task-specific strategies or custom-defined representations, which struggle to leverage the knowledge transfer between different SKR tasks or align with the prior of LLMs, thereby limiting their performance. This paper proposes a novel USKR framework named \\textsc{Pandora}, which takes advantage of \\textsc{Python}'s \\textsc{Pandas} API to construct a unified knowledge representation for alignment with LLM pre-training. It employs an LLM to generate textual reasoning steps and executable Python code for each question. Demonstrations are drawn from a memory of training examples that cover various SKR tasks, facilitating knowledge transfer. Extensive experiments on four benchmarks involving three SKR tasks demonstrate that \\textsc{Pandora} outperforms existing unified frameworks and competes effectively with task-specific methods.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12734.pdf", "abstract_url": "https://arxiv.org/abs/2504.12734", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一个名为Pandora的新框架，用于统一结构化知识推理（USKR），通过利用Python的Pandas API构建统一的知识表示，与LLM预训练对齐，以提高在不同结构化知识推理任务中的表现。", "motivation": "解决现有USKR方法在利用不同SKR任务间的知识转移或与LLMs的先验对齐方面的局限性。", "method": "使用LLM生成文本推理步骤和可执行的Python代码，利用覆盖各种SKR任务的训练示例记忆来促进知识转移。", "result": "在涉及三个SKR任务的四个基准测试中，Pandora的表现优于现有的统一框架，并能与任务特定方法有效竞争。", "conclusion": "Pandora框架通过统一的知识表示和代码驱动的方法，显著提高了在多样化结构化知识推理任务中的性能和适应性。"}}
{"id": "2504.12891", "title": "Are AI agents the new machine translation frontier? Challenges and opportunities of single- and multi-agent systems for multilingual digital communication", "authors": ["Vicent Briva-Iglesias"], "abstract": "The rapid evolution of artificial intelligence (AI) has introduced AI agents as a disruptive paradigm across various industries, yet their application in machine translation (MT) remains underexplored. This paper describes and analyses the potential of single- and multi-agent systems for MT, reflecting on how they could enhance multilingual digital communication. While single-agent systems are well-suited for simpler translation tasks, multi-agent systems, which involve multiple specialized AI agents collaborating in a structured manner, may offer a promising solution for complex scenarios requiring high accuracy, domain-specific knowledge, and contextual awareness. To demonstrate the feasibility of multi-agent workflows in MT, we are conducting a pilot study in legal MT. The study employs a multi-agent system involving four specialized AI agents for (i) translation, (ii) adequacy review, (iii) fluency review, and (iv) final editing. Our findings suggest that multi-agent systems may have the potential to significantly improve domain-adaptability and contextual awareness, with superior translation quality to traditional MT or single-agent systems. This paper also sets the stage for future research into multi-agent applications in MT, integration into professional translation workflows, and shares a demo of the system analyzed in the paper.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET); Human-Computer Interaction (cs.HC)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12891.pdf", "abstract_url": "https://arxiv.org/abs/2504.12891", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Emerging Technologies (cs.ET)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了AI代理在机器翻译(MT)中的应用潜力，特别是单代理和多代理系统如何提升多语言数字通信。通过法律MT的试点研究，展示了多代理系统在提高翻译质量和领域适应性方面的优势。", "motivation": "探索AI代理作为机器翻译新前沿的潜力，解决传统MT在复杂场景下的准确性和上下文意识不足的问题。", "method": "采用单代理和多代理系统进行比较，特别是一个由四个专门AI代理组成的多代理系统，分别负责翻译、充分性审查、流畅性审查和最终编辑。", "result": "研究发现，多代理系统在领域适应性和上下文意识方面表现优异，翻译质量优于传统MT或单代理系统。", "conclusion": "多代理系统为机器翻译提供了新的可能性，尤其是在需要高准确性和专业知识的复杂场景中。本文为未来多代理在MT中的应用和研究奠定了基础。"}}
{"id": "2504.12951", "title": "Are Retrials All You Need? Enhancing Large Language Model Reasoning Without Verbalized Feedback", "authors": ["Nearchos Potamitis", "Akhil Arora"], "abstract": "Recent advancements in large language models (LLMs) have catalyzed the development of general-purpose autonomous agents, demonstrating remarkable performance in complex reasoning tasks across various domains. This surge has spurred the evolution of a plethora of prompt-based reasoning frameworks. A recent focus has been on iterative reasoning strategies that refine outputs through self-evaluation and verbalized feedback. However, these strategies require additional computational complexity to enable models to recognize and correct their mistakes, leading to a significant increase in their cost. In this work, we introduce the concept of ``retrials without feedback'', an embarrassingly simple yet powerful mechanism for enhancing reasoning frameworks by allowing LLMs to retry problem-solving attempts upon identifying incorrect answers. Unlike conventional iterative refinement methods, our method does not require explicit self-reflection or verbalized feedback, simplifying the refinement process. Our findings indicate that simpler retrial-based approaches often outperform more sophisticated reasoning frameworks, suggesting that the benefits of complex methods may not always justify their computational costs. By challenging the prevailing assumption that more intricate reasoning strategies inherently lead to better performance, our work offers new insights into how simpler, more efficient approaches can achieve optimal results. So, are retrials all you need?", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2504.12951.pdf", "abstract_url": "https://arxiv.org/abs/2504.12951", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为“无反馈重试”的简单而强大的机制，通过允许大型语言模型（LLMs）在识别错误答案后重试解决问题，来增强推理框架。与传统的迭代细化方法不同，该方法不需要显式的自我反思或口头反馈，简化了细化过程。研究发现，简单的基于重试的方法往往胜过更复杂的推理框架，表明复杂方法的益处可能并不总是值得其计算成本。", "motivation": "解决大型语言模型在复杂推理任务中通过自我评估和口头反馈细化输出时，所需的额外计算复杂性和成本增加的问题。", "method": "引入“无反馈重试”机制，允许LLMs在识别错误答案后重试解决问题，无需显式的自我反思或口头反馈。", "result": "研究发现，简单的基于重试的方法往往胜过更复杂的推理框架，表明复杂方法的益处可能并不总是值得其计算成本。", "conclusion": "挑战了更复杂的推理策略固有地导致更好性能的普遍假设，提供了关于如何通过更简单、更高效的方法实现最佳结果的新见解。"}}
{"id": "2504.12972", "title": "Estimating Optimal Context Length for Hybrid Retrieval-augmented Multi-document Summarization", "authors": ["Adithya Pratapa", "Teruko Mitamura"], "abstract": "Recent advances in long-context reasoning abilities of language models led to interesting applications in large-scale multi-document summarization. However, prior work has shown that these long-context models are not effective at their claimed context windows. To this end, retrieval-augmented systems provide an efficient and effective alternative. However, their performance can be highly sensitive to the choice of retrieval context length. In this work, we present a hybrid method that combines retrieval-augmented systems with long-context windows supported by recent language models. Our method first estimates the optimal retrieval length as a function of the retriever, summarizer, and dataset. On a randomly sampled subset of the dataset, we use a panel of LLMs to generate a pool of silver references. We use these silver references to estimate the optimal context length for a given RAG system configuration. Our results on the multi-document summarization task showcase the effectiveness of our method across model classes and sizes. We compare against length estimates from strong long-context benchmarks such as RULER and HELMET. Our analysis also highlights the effectiveness of our estimation method for very long-context LMs and its generalization to new classes of LMs.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12972.pdf", "abstract_url": "https://arxiv.org/abs/2504.12972", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种混合方法，结合了检索增强系统和最新语言模型支持的长上下文窗口，用于多文档摘要任务，通过估计最佳检索长度来提高性能。", "motivation": "解决长上下文语言模型在声称的上下文窗口中效率不高的问题，以及检索增强系统对检索上下文长度选择的高度敏感性。", "method": "提出一种混合方法，首先根据检索器、摘要器和数据集估计最佳检索长度，然后使用一组LLM生成银参考池，用于估计给定RAG系统配置的最佳上下文长度。", "result": "在多文档摘要任务上，该方法在不同模型类别和大小上展示了有效性，并与RULER和HELMET等强长上下文基准进行了比较。", "conclusion": "该方法对于非常长上下文的语言模型有效，并且能够推广到新类别的语言模型，为多文档摘要任务提供了一种有效的解决方案。"}}
{"id": "2504.12546", "title": "Anonymous Public Announcements", "authors": ["Thomas Ågotnes", "Rustam Galimullin", "Ken Satoh", "Satoshi Tojo"], "abstract": "We formalise the notion of an \\emph{anonymous public announcement} in the tradition of public announcement logic. Such announcements can be seen as in-between a public announcement from ``the outside\" (an announcement of $\\phi$) and a public announcement by one of the agents (an announcement of $K_a\\phi$): we get more information than just $\\phi$, but not (necessarily) about exactly who made it. Even if such an announcement is prima facie anonymous, depending on the background knowledge of the agents it might reveal the identity of the announcer: if I post something on a message board, the information might reveal who I am even if I don't sign my name. Furthermore, like in the Russian Cards puzzle, if we assume that the announcer's intention was to stay anonymous, that in fact might reveal more information. In this paper we first look at the case when no assumption about intentions are made, in which case the logic with an anonymous public announcement operator is reducible to epistemic logic. We then look at the case when we assume common knowledge of the intention to stay anonymous, which is both more complex and more interesting: in several ways it boils down to the notion of a ``safe\" announcement (again, similarly to Russian Cards). Main results include formal expressivity results and axiomatic completeness for key logical languages.", "subjects": "Logic in Computer Science (cs.LO); Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12546.pdf", "abstract_url": "https://arxiv.org/abs/2504.12546", "categories": ["Logic in Computer Science (cs.LO)", "Artificial Intelligence (cs.AI)", "Cryptography and Security (cs.CR)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文在公共公告逻辑的传统中形式化了匿名公共公告的概念，探讨了在不同假设下匿名公告的逻辑性质和影响。", "motivation": "解决在公共公告中匿名性的形式化问题，以及匿名公告如何在不同的背景知识和意图假设下影响信息的揭示。", "method": "使用公共公告逻辑和认知逻辑的方法，分析匿名公告的逻辑结构，并在不同假设下进行形式化。", "result": "在无意图假设的情况下，匿名公共公告逻辑可简化为认知逻辑；在共同知识意图保持匿名的情况下，逻辑更为复杂，与“安全”公告概念相关。", "conclusion": "匿名公共公告在不同假设下有不同的逻辑性质，特别是在共同知识意图保持匿名的情况下，逻辑更为复杂且有趣，与“安全”公告概念相关。"}}
{"id": "2504.12557", "title": "TraCeS: Trajectory Based Credit Assignment From Sparse Safety Feedback", "authors": ["Siow Meng Low", "Akshat Kumar"], "abstract": "In safe reinforcement learning (RL), auxiliary safety costs are used to align the agent to safe decision making. In practice, safety constraints, including cost functions and budgets, are unknown or hard to specify, as it requires anticipation of all possible unsafe behaviors. We therefore address a general setting where the true safety definition is unknown, and has to be learned from sparsely labeled data. Our key contributions are: first, we design a safety model that performs credit assignment to estimate each decision step's impact on the overall safety using a dataset of diverse trajectories and their corresponding binary safety labels (i.e., whether the corresponding trajectory is safe/unsafe). Second, we illustrate the architecture of our safety model to demonstrate its ability to learn a separate safety score for each timestep. Third, we reformulate the safe RL problem using the proposed safety model and derive an effective algorithm to optimize a safe yet rewarding policy. Finally, our empirical results corroborate our findings and show that this approach is effective in satisfying unknown safety definition, and scalable to various continuous control tasks.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12557.pdf", "abstract_url": "https://arxiv.org/abs/2504.12557", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于轨迹的信用分配方法（TraCeS），用于从稀疏的安全反馈中学习未知的安全定义，并通过安全模型和算法优化，实现安全且有效的强化学习策略。", "motivation": "在安全强化学习中，安全约束（包括成本函数和预算）通常未知或难以指定，因为需要预测所有可能的不安全行为。本文旨在解决安全定义未知且需要从稀疏标记数据中学习的一般设置问题。", "method": "设计了一个安全模型，通过信用分配估计每个决策步骤对整体安全的影响；展示了安全模型的架构，证明其能够为每个时间步学习单独的安全分数；重新制定了安全强化学习问题，并推导出一个有效的算法来优化安全且奖励的策略。", "result": "实证结果证实了该方法的有效性，能够满足未知的安全定义，并适用于各种连续控制任务。", "conclusion": "TraCeS方法通过从稀疏的安全反馈中学习，能够有效地满足未知的安全定义，并在多种连续控制任务中展现出良好的可扩展性。"}}
{"id": "2504.12982", "title": "Accommodate Knowledge Conflicts in Retrieval-augmented LLMs: Towards Reliable Response Generation in the Wild", "authors": ["Jiatai Wang", "Zhiwei Xu", "Di Jin", "Xuewen Yang", "Tao Li"], "abstract": "The proliferation of large language models (LLMs) has significantly advanced information retrieval systems, particularly in response generation (RG). Unfortunately, LLMs often face knowledge conflicts between internal memory and retrievaled external information, arising from misinformation, biases, or outdated knowledge. These conflicts undermine response reliability and introduce uncertainty in decision-making. In this work, we analyze how LLMs navigate knowledge conflicts from an information-theoretic perspective and reveal that when conflicting and supplementary information exhibit significant differences, LLMs confidently resolve their preferences. However, when the distinction is ambiguous, LLMs experience heightened uncertainty. Based on this insight, we propose Swin-VIB, a novel framework that integrates a pipeline of variational information bottleneck models into adaptive augmentation of retrieved information and guiding LLM preference in response generation. Extensive experiments on single-choice, open-ended question-answering (QA), and retrieval augmented generation (RAG) validate our theoretical findings and demonstrate the efficacy of Swin-VIB. Notably, our method improves single-choice task accuracy by at least 7.54\\% over competitive baselines.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12982.pdf", "abstract_url": "https://arxiv.org/abs/2504.12982", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种名为Swin-VIB的新框架，旨在解决大型语言模型（LLMs）在检索增强生成（RAG）中遇到的知识冲突问题，通过变分信息瓶颈模型整合检索信息，提高响应生成的可靠性。", "motivation": "大型语言模型（LLMs）在响应生成（RG）中经常面临内部记忆与检索到的外部信息之间的知识冲突，这些冲突源于错误信息、偏见或过时知识，影响了响应的可靠性和决策的确定性。", "method": "提出Swin-VIB框架，该框架通过一系列变分信息瓶颈模型整合检索到的信息，并指导LLM在响应生成中的偏好，以解决知识冲突问题。", "result": "在单选择、开放式问答（QA）和检索增强生成（RAG）任务上的广泛实验验证了理论发现，并证明了Swin-VIB的有效性，特别是在单选择任务上，准确率至少提高了7.54%。", "conclusion": "Swin-VIB框架能够有效解决LLMs在检索增强生成中的知识冲突问题，提高响应生成的可靠性和准确性，为未来的信息检索系统提供了新的研究方向。"}}
{"id": "2504.13079", "title": "Retrieval-Augmented Generation with Conflicting Evidence", "authors": ["Han Wang", "Archiki Prasad", "Elias Stengel-Eskin", "Mohit Bansal"], "abstract": "Large language model (LLM) agents are increasingly employing retrieval-augmented generation (RAG) to improve the factuality of their responses. However, in practice, these systems often need to handle ambiguous user queries and potentially conflicting information from multiple sources while also suppressing inaccurate information from noisy or irrelevant documents. Prior work has generally studied and addressed these challenges in isolation, considering only one aspect at a time, such as handling ambiguity or robustness to noise and misinformation. We instead consider multiple factors simultaneously, proposing (i) RAMDocs (Retrieval with Ambiguity and Misinformation in Documents), a new dataset that simulates complex and realistic scenarios for conflicting evidence for a user query, including ambiguity, misinformation, and noise; and (ii) MADAM-RAG, a multi-agent approach in which LLM agents debate over the merits of an answer over multiple rounds, allowing an aggregator to collate responses corresponding to disambiguated entities while discarding misinformation and noise, thereby handling diverse sources of conflict jointly. We demonstrate the effectiveness of MADAM-RAG using both closed and open-source models on AmbigDocs -- which requires presenting all valid answers for ambiguous queries -- improving over strong RAG baselines by up to 11.40% and on FaithEval -- which requires suppressing misinformation -- where we improve by up to 15.80% (absolute) with Llama3.3-70B-Instruct. Furthermore, we find that RAMDocs poses a challenge for existing RAG baselines (Llama3.3-70B-Instruct only obtains 32.60 exact match score). While MADAM-RAG begins to address these conflicting factors, our analysis indicates that a substantial gap remains especially when increasing the level of imbalance in supporting evidence and misinformation.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2504.13079.pdf", "abstract_url": "https://arxiv.org/abs/2504.13079", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文提出了一种新的检索增强生成（RAG）方法MADAM-RAG，通过多代理辩论处理用户查询中的歧义、错误信息和噪声，同时介绍了RAMDocs数据集以模拟复杂场景。实验显示，MADAM-RAG在AmbigDocs和FaithEval上优于现有基线，但RAMDocs对现有方法仍构成挑战。", "motivation": "解决大型语言模型（LLM）代理在使用检索增强生成（RAG）时面临的用户查询歧义、多源信息冲突以及噪声和错误信息抑制的问题。", "method": "提出了RAMDocs数据集模拟复杂场景，并开发了MADAM-RAG方法，通过多代理辩论和聚合器整合回答，同时处理歧义、错误信息和噪声。", "result": "MADAM-RAG在AmbigDocs和FaithEval上分别提高了11.40%和15.80%的性能，但RAMDocs对现有RAG基线仍具挑战性（Llama3.3-70B-Instruct仅获得32.60的精确匹配分数）。", "conclusion": "尽管MADAM-RAG在处理冲突因素方面取得了进展，但在支持证据和错误信息不平衡的情况下仍存在显著差距。"}}
{"id": "2504.12408", "title": "A Human-AI Comparative Analysis of Prompt Sensitivity in LLM-Based Relevance Judgment", "authors": ["Negar Arabzadeh", "Charles L. A . Clarke"], "abstract": "Large Language Models (LLMs) are increasingly used to automate relevance judgments for information retrieval (IR) tasks, often demonstrating agreement with human labels that approaches inter-human agreement. To assess the robustness and reliability of LLM-based relevance judgments, we systematically investigate impact of prompt sensitivity on the task. We collected prompts for relevance assessment from 15 human experts and 15 LLMs across three tasks~ -- ~binary, graded, and pairwise~ -- ~yielding 90 prompts in total. After filtering out unusable prompts from three humans and three LLMs, we employed the remaining 72 prompts with three different LLMs as judges to label document/query pairs from two TREC Deep Learning Datasets (2020 and 2021). We compare LLM-generated labels with TREC official human labels using Cohen's $\\kappa$ and pairwise agreement measures. In addition to investigating the impact of prompt variations on agreement with human labels, we compare human- and LLM-generated prompts and analyze differences among different LLMs as judges. We also compare human- and LLM-generated prompts with the standard UMBRELA prompt used for relevance assessment by Bing and TREC 2024 Retrieval Augmented Generation (RAG) Track. To support future research in LLM-based evaluation, we release all data and prompts at", "subjects": "Information Retrieval (cs.IR); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12408.pdf", "abstract_url": "https://arxiv.org/abs/2504.12408", "categories": ["Information Retrieval (cs.IR)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文通过系统研究提示敏感性对基于大型语言模型（LLM）的相关性判断任务的影响，评估了LLM在信息检索（IR）任务中自动化相关性判断的鲁棒性和可靠性。研究收集了人类专家和LLM生成的提示，比较了不同提示下LLM生成标签与人类标签的一致性，并分析了人类与LLM生成提示的差异。", "motivation": "评估大型语言模型（LLMs）在信息检索（IR）任务中自动化相关性判断的鲁棒性和可靠性，特别是提示敏感性对判断结果的影响。", "method": "收集了15位人类专家和15个LLM生成的提示，用于三种任务（二元、分级和成对），共90个提示。使用剩余的72个提示和三个不同的LLM作为评委，对来自两个TREC深度学习数据集（2020和2021）的文档/查询对进行标记。通过Cohen's κ和成对一致性度量比较LLM生成标签与人类标签的一致性。", "result": "研究发现提示变化对与人类标签的一致性有显著影响，并揭示了人类与LLM生成提示之间的差异。同时，比较了不同LLM作为评委时的表现。", "conclusion": "本研究为基于LLM的评估提供了新的见解和数据支持，强调了提示设计在自动化相关性判断中的重要性，并发布了所有数据和提示以支持未来研究。"}}
{"id": "2504.12714", "title": "Cross-environment Cooperation Enables Zero-shot Multi-agent Coordination", "authors": ["Kunal Jha", "Wilka Carvalho", "Yancheng Liang", "Simon S. Du", "Max Kleiman-Weiner", "Natasha Jaques"], "abstract": "Zero-shot coordination (ZSC), the ability to adapt to a new partner in a cooperative task, is a critical component of human-compatible AI. While prior work has focused on training agents to cooperate on a single task, these specialized models do not generalize to new tasks, even if they are highly similar. Here, we study how reinforcement learning on a distribution of environments with a single partner enables learning general cooperative skills that support ZSC with many new partners on many new problems. We introduce two Jax-based, procedural generators that create billions of solvable coordination challenges. We develop a new paradigm called Cross-Environment Cooperation (CEC), and show that it outperforms competitive baselines quantitatively and qualitatively when collaborating with real people. Our findings suggest that learning to collaborate across many unique scenarios encourages agents to develop general norms, which prove effective for collaboration with different partners. Together, our results suggest a new route toward designing generalist cooperative agents capable of interacting with humans without requiring human data.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "Accepted to CogSci 2025, In-review for ICML 2025", "pdf_url": "https://arxiv.org/pdf/2504.12714.pdf", "abstract_url": "https://arxiv.org/abs/2504.12714", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究了如何在多智能体协作任务中实现零样本协调（ZSC），即无需预先训练即可与新伙伴协作的能力。通过在不同环境中与单一伙伴进行强化学习，研究者开发了跨环境协作（CEC）新范式，并展示了其在与人协作时的优越性能。", "motivation": "解决现有AI模型在协作任务中无法泛化到新任务或新伙伴的问题，探索实现更接近人类协作能力的AI。", "method": "使用Jax-based的程序生成器创建数十亿个可解决的协作挑战，开发跨环境协作（CEC）范式，通过在不同环境中训练以学习通用协作技能。", "result": "CEC在与人协作时，在数量和质量上均优于竞争基线，表明通过学习多种独特场景下的协作，智能体能够发展出有效的通用协作规范。", "conclusion": "研究提出了一种新途径，设计能够无需人类数据即可与人类交互的通用协作智能体，为开发更人类兼容的AI提供了方向。"}}
{"id": "2504.12722", "title": "SimUSER: Simulating User Behavior with Large Language Models for Recommender System Evaluation", "authors": ["Nicolas Bougie", "Narimasa Watanabe"], "abstract": "Recommender systems play a central role in numerous real-life applications, yet evaluating their performance remains a significant challenge due to the gap between offline metrics and online behaviors. Given the scarcity and limits (e.g., privacy issues) of real user data, we introduce SimUSER, an agent framework that serves as believable and cost-effective human proxies. SimUSER first identifies self-consistent personas from historical data, enriching user profiles with unique backgrounds and personalities. Then, central to this evaluation are users equipped with persona, memory, perception, and brain modules, engaging in interactions with the recommender system. SimUSER exhibits closer alignment with genuine humans than prior work, both at micro and macro levels. Additionally, we conduct insightful experiments to explore the effects of thumbnails on click rates, the exposure effect, and the impact of reviews on user engagement. Finally, we refine recommender system parameters based on offline A/B test results, resulting in improved user engagement in the real world.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12722.pdf", "abstract_url": "https://arxiv.org/abs/2504.12722", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了SimUSER，一个用于模拟用户行为以评估推荐系统性能的代理框架。通过创建具有个性化背景和性格的用户代理，SimUSER在微观和宏观层面上更接近真实用户行为，为推荐系统的离线评估提供了可信且成本效益高的解决方案。", "motivation": "推荐系统在现实应用中扮演着重要角色，但由于离线指标与在线行为之间的差距，评估其性能仍面临挑战。真实用户数据的稀缺和隐私问题进一步加剧了这一挑战。", "method": "SimUSER框架首先从历史数据中识别自洽的用户角色，丰富用户档案的独特背景和个性。然后，通过配备角色、记忆、感知和大脑模块的用户代理与推荐系统进行交互。", "result": "SimUSER在微观和宏观层面上显示出与真实用户更接近的对齐度。实验还探讨了缩略图对点击率的影响、曝光效应以及评论对用户参与度的影响，并基于离线A/B测试结果优化了推荐系统参数，从而在现实世界中提高了用户参与度。", "conclusion": "SimUSER作为一个可信且成本效益高的用户代理框架，为推荐系统的评估提供了一种新方法，能够更准确地模拟真实用户行为，进而优化推荐系统的性能。"}}
{"id": "2504.12735", "title": "The Athenian Academy: A Seven-Layer Architecture Model for Multi-Agent Systems", "authors": ["Lidong Zhai", "Zhijie Qiu", "Xizhong Guo", "Jiaqi Li"], "abstract": "This paper proposes the \"Academy of Athens\" multi-agent seven-layer framework, aimed at systematically addressing challenges in multi-agent systems (MAS) within artificial intelligence (AI) art creation, such as collaboration efficiency, role allocation, environmental adaptation, and task parallelism. The framework divides MAS into seven layers: multi-agent collaboration, single-agent multi-role playing, single-agent multi-scene traversal, single-agent multi-capability incarnation, different single agents using the same large model to achieve the same target agent, single-agent using different large models to achieve the same target agent, and multi-agent synthesis of the same target agent. Through experimental validation in art creation, the framework demonstrates its unique advantages in task collaboration, cross-scene adaptation, and model fusion. This paper further discusses current challenges such as collaboration mechanism optimization, model stability, and system security, proposing future exploration through technologies like meta-learning and federated learning. The framework provides a structured methodology for multi-agent collaboration in AI art creation and promotes innovative applications in the art field.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12735.pdf", "abstract_url": "https://arxiv.org/abs/2504.12735", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一个名为'雅典学院'的多智能体七层框架，旨在系统解决人工智能艺术创作中多智能体系统面临的协作效率、角色分配、环境适应和任务并行等挑战。", "motivation": "解决多智能体系统在人工智能艺术创作中的协作效率、角色分配、环境适应和任务并行等问题。", "method": "提出一个七层框架，包括多智能体协作、单智能体多角色扮演、单智能体多场景遍历、单智能体多能力体现、不同单智能体使用同一大模型实现同一目标智能体、单智能体使用不同大模型实现同一目标智能体，以及多智能体合成同一目标智能体。", "result": "在艺术创作中的实验验证表明，该框架在任务协作、跨场景适应和模型融合方面具有独特优势。", "conclusion": "该框架为AI艺术创作中的多智能体协作提供了结构化方法，并促进了艺术领域的创新应用。未来可通过元学习和联邦学习等技术进一步探索协作机制优化、模型稳定性和系统安全性等挑战。"}}
{"id": "2504.12757", "title": "MCP Guardian: A Security-First Layer for Safeguarding MCP-Based AI System", "authors": ["Sonu Kumar", "Anubhav Girdhar", "Ritesh Patil", "Divyansh Tripathi"], "abstract": "As Agentic AI gain mainstream adoption, the industry invests heavily in model capabilities, achieving rapid leaps in reasoning and quality. However, these systems remain largely confined to data silos, and each new integration requires custom logic that is difficult to scale. The Model Context Protocol (MCP) addresses this challenge by defining a universal, open standard for securely connecting AI-based applications (MCP clients) to data sources (MCP servers). However, the flexibility of the MCP introduces new risks, including malicious tool servers and compromised data integrity. We present MCP Guardian, a framework that strengthens MCP-based communication with authentication, rate-limiting, logging, tracing, and Web Application Firewall (WAF) scanning. Through real-world scenarios and empirical testing, we demonstrate how MCP Guardian effectively mitigates attacks and ensures robust oversight with minimal overheads. Our approach fosters secure, scalable data access for AI assistants, underscoring the importance of a defense-in-depth approach that enables safer and more transparent innovation in AI-driven environments.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12757.pdf", "abstract_url": "https://arxiv.org/abs/2504.12757", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了MCP Guardian，一个为基于模型上下文协议（MCP）的AI系统设计的安全第一层框架，旨在通过认证、速率限制、日志记录、追踪和Web应用防火墙扫描等措施，加强MCP通信的安全性，有效减轻攻击并确保强健的监管，同时保持低开销。", "motivation": "随着代理AI的普及，行业在模型能力上投入巨大，实现了推理和质量的快速跃升。然而，这些系统大多局限于数据孤岛，每次新集成都需要难以扩展的自定义逻辑。MCP虽解决了这一问题，但其灵活性也带来了新的风险，如恶意工具服务器和数据完整性受损。", "method": "提出了MCP Guardian框架，通过实施认证、速率限制、日志记录、追踪和Web应用防火墙（WAF）扫描等技术，加强MCP通信的安全性。", "result": "通过真实场景和实证测试，证明MCP Guardian能有效减轻攻击，确保强健的监管，同时保持低开销。", "conclusion": "MCP Guardian促进了AI助手的安全、可扩展数据访问，强调了深度防御方法在实现AI驱动环境中更安全、更透明创新的重要性。"}}
{"id": "2504.13128", "title": "FreshStack: Building Realistic Benchmarks for Evaluating Retrieval on Technical Documents", "authors": ["Nandan Thakur", "Jimmy Lin", "Sam Havens", "Michael Carbin", "Omar Khattab", "Andrew Drozdov"], "abstract": "We introduce FreshStack, a reusable framework for automatically building information retrieval (IR) evaluation benchmarks from community-asked questions and answers. FreshStack conducts the following steps: (1) automatic corpus collection from code and technical documentation, (2) nugget generation from community-asked questions and answers, and (3) nugget-level support, retrieving documents using a fusion of retrieval techniques and hybrid architectures. We use FreshStack to build five datasets on fast-growing, recent, and niche topics to ensure the tasks are sufficiently challenging. On FreshStack, existing retrieval models, when applied out-of-the-box, significantly underperform oracle approaches on all five topics, denoting plenty of headroom to improve IR quality. In addition, we identify cases where rerankers do not clearly improve first-stage retrieval accuracy (two out of five topics). We hope that FreshStack will facilitate future work toward constructing realistic, scalable, and uncontaminated IR and RAG evaluation benchmarks. FreshStack datasets are available at:", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.13128.pdf", "abstract_url": "https://arxiv.org/abs/2504.13128", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "FreshStack是一个可重复使用的框架，用于从社区提问和答案中自动构建信息检索(IR)评估基准。它通过自动收集代码和技术文档、从社区问答中生成信息块，以及使用检索技术和混合架构的融合来检索文档，构建了五个数据集。现有检索模型在这些数据集上表现不佳，表明IR质量有提升空间。", "motivation": "解决构建现实、可扩展且未受污染的信息检索(IR)和检索增强生成(RAG)评估基准的问题。", "method": "自动从代码和技术文档收集语料库，从社区问答中生成信息块，使用检索技术和混合架构的融合进行文档检索。", "result": "现有检索模型在五个主题上的表现显著低于oracle方法，且在某些情况下，重新排序器并未明显提高第一阶段的检索准确性。", "conclusion": "FreshStack有助于未来构建现实、可扩展且未受污染的IR和RAG评估基准，现有检索模型在这些基准上有很大的改进空间。"}}
{"id": "2504.12777", "title": "Multi-Agent Reinforcement Learning Simulation for Environmental Policy Synthesis", "authors": ["James Rudd-Jones", "Mirco Musolesi", "María Pérez-Ortiz"], "abstract": "Climate policy development faces significant challenges due to deep uncertainty, complex system dynamics, and competing stakeholder interests. Climate simulation methods, such as Earth System Models, have become valuable tools for policy exploration. However, their typical use is for evaluating potential polices, rather than directly synthesizing them. The problem can be inverted to optimize for policy pathways, but the traditional optimization approaches often struggle with non-linear dynamics, heterogeneous agents, and comprehensive uncertainty quantification. We propose a framework for augmenting climate simulations with Multi-Agent Reinforcement Learning (MARL) to address these limitations. We identify key challenges at the interface between climate simulations and the application of MARL in the context of policy synthesis, including reward definition, scalability with increasing agents and state spaces, uncertainty propagation across linked systems, and solution validation. Additionally, we discuss challenges in making MARL-derived solutions interpretable and useful for policy-makers. Our framework provides a foundation for more sophisticated climate policy exploration while acknowledging important limitations and areas for future research.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": "Published in AAMAS'25 Blue Sky Ideas Track", "pdf_url": "https://arxiv.org/pdf/2504.12777.pdf", "abstract_url": "https://arxiv.org/abs/2504.12777", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种利用多智能体强化学习（MARL）增强气候模拟的框架，以解决气候政策制定中的深层次不确定性、复杂系统动态和利益相关者竞争问题。", "motivation": "气候政策制定面临深层次不确定性、复杂系统动态和利益相关者竞争等挑战，传统的气候模拟方法主要用于评估潜在政策，而非直接合成政策。传统优化方法在处理非线性动态、异质智能体和全面不确定性量化方面存在困难。", "method": "提出了一种框架，通过多智能体强化学习（MARL）增强气候模拟，以优化政策路径。", "result": "识别了气候模拟与MARL在政策合成应用中的关键挑战，包括奖励定义、随着智能体和状态空间增加的可扩展性、跨链接系统的不确定性传播以及解决方案验证。", "conclusion": "该框架为更复杂的气候政策探索提供了基础，同时承认了重要的局限性和未来研究的方向。"}}
{"id": "2504.12961", "title": "QLLM: Do We Really Need a Mixing Network for Credit Assignment in Multi-Agent Reinforcement Learning?", "authors": ["Zhouyang Jiang", "Bin Zhang", "Airong Wei", "Zhiwei Xu"], "abstract": "Credit assignment has remained a fundamental challenge in multi-agent reinforcement learning (MARL). Previous studies have primarily addressed this issue through value decomposition methods under the centralized training with decentralized execution paradigm, where neural networks are utilized to approximate the nonlinear relationship between individual Q-values and the global Q-value. Although these approaches have achieved considerable success in various benchmark tasks, they still suffer from several limitations, including imprecise attribution of contributions, limited interpretability, and poor scalability in high-dimensional state spaces. To address these challenges, we propose a novel algorithm, \\textbf{QLLM}, which facilitates the automatic construction of credit assignment functions using large language models (LLMs). Specifically, the concept of \\textbf{TFCAF} is introduced, wherein the credit allocation process is represented as a direct and expressive nonlinear functional formulation. A custom-designed \\textit{coder-evaluator} framework is further employed to guide the generation, verification, and refinement of executable code by LLMs, significantly mitigating issues such as hallucination and shallow reasoning during inference. Extensive experiments conducted on several standard MARL benchmarks demonstrate that the proposed method consistently outperforms existing state-of-the-art baselines. Moreover, QLLM exhibits strong generalization capability and maintains compatibility with a wide range of MARL algorithms that utilize mixing networks, positioning it as a promising and versatile solution for complex multi-agent scenarios.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": "9 pages, 7 figures", "pdf_url": "https://arxiv.org/pdf/2504.12961.pdf", "abstract_url": "https://arxiv.org/abs/2504.12961", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为QLLM的新算法，利用大型语言模型（LLMs）自动构建信用分配函数，以解决多智能体强化学习（MARL）中的信用分配问题。通过引入TFCAF概念和定制设计的coder-evaluator框架，QLLM在多个标准MARL基准测试中表现优异，展示了强大的泛化能力和广泛的兼容性。", "motivation": "解决多智能体强化学习中的信用分配问题，特别是现有方法在贡献精确归属、可解释性和高维状态空间扩展性方面的局限性。", "method": "提出QLLM算法，利用大型语言模型自动构建信用分配函数，引入TFCAF概念表示信用分配过程，并采用coder-evaluator框架指导LLMs生成、验证和优化可执行代码。", "result": "QLLM在多个标准MARL基准测试中 consistently outperforms现有最先进的基线方法，展示了强大的泛化能力和广泛的算法兼容性。", "conclusion": "QLLM作为一种新颖且通用的解决方案，为复杂多智能体场景中的信用分配问题提供了有效的解决途径，具有广泛的应用前景。"}}
