{"id": "2508.10287", "title": "JRDB-Reasoning: A Difficulty-Graded Benchmark for Visual Reasoning in Robotics", "authors": ["Simindokht Jahangard", "Mehrzad Mohammadi", "Yi Shen", "Zhixi Cai", "Hamid Rezatofighi"], "abstract": "Recent advances in Vision-Language Models (VLMs) and large language models (LLMs) have greatly enhanced visual reasoning, a key capability for embodied AI agents like robots. However, existing visual reasoning benchmarks often suffer from several limitations: they lack a clear definition of reasoning complexity, offer have no control to generate questions over varying difficulty and task customization, and fail to provide structured, step-by-step reasoning annotations (workflows). To bridge these gaps, we formalize reasoning complexity, introduce an adaptive query engine that generates customizable questions of varying complexity with detailed intermediate annotations, and extend the JRDB dataset with human-object interaction and geometric relationship annotations to create JRDB-Reasoning, a benchmark tailored for visual reasoning in human-crowded environments. Our engine and benchmark enable fine-grained evaluation of visual reasoning frameworks and dynamic assessment of visual-language models across reasoning levels.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10287.pdf", "abstract_url": "https://arxiv.org/abs/2508.10287", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了JRDB-Reasoning，一个为机器人视觉推理设计的难度分级的基准测试，通过定义推理复杂性、引入自适应查询引擎和扩展JRDB数据集，以支持在人类拥挤环境中的视觉推理评估。", "motivation": "解决现有视觉推理基准在定义推理复杂性、生成不同难度问题和提供结构化推理注释方面的不足。", "method": "通过正式化推理复杂性，引入自适应查询引擎生成可定制问题，并扩展JRDB数据集以包含人-物交互和几何关系注释。", "result": "创建了JRDB-Reasoning基准，支持对视觉推理框架的细粒度评估和视觉语言模型在不同推理水平上的动态评估。", "conclusion": "JRDB-Reasoning为在人类拥挤环境中的视觉推理提供了一个定制化的基准测试，促进了视觉推理框架和视觉语言模型的评估与发展。"}}
{"id": "2508.10567", "title": "SpaRC-AD: A Baseline for Radar-Camera Fusion in End-to-End Autonomous Driving", "authors": ["Philipp Wolters", "Johannes Gilg", "Torben Teepe", "Gerhard Rigoll"], "abstract": "End-to-end autonomous driving systems promise stronger performance through unified optimization of perception, motion forecasting, and planning. However, vision-based approaches face fundamental limitations in adverse weather conditions, partial occlusions, and precise velocity estimation - critical challenges in safety-sensitive scenarios where accurate motion understanding and long-horizon trajectory prediction are essential for collision avoidance. To address these limitations, we propose SpaRC-AD, a query-based end-to-end camera-radar fusion framework for planning-oriented autonomous driving. Through sparse 3D feature alignment, and doppler-based velocity estimation, we achieve strong 3D scene representations for refinement of agent anchors, map polylines and motion modelling. Our method achieves strong improvements over the state-of-the-art vision-only baselines across multiple autonomous driving tasks, including 3D detection (+4.8% mAP), multi-object tracking (+8.3% AMOTA), online mapping (+1.8% mAP), motion prediction (-4.0% mADE), and trajectory planning (-0.1m L2 and -9% TPC). We achieve both spatial coherence and temporal consistency on multiple challenging benchmarks, including real-world open-loop nuScenes, long-horizon T-nuScenes, and closed-loop simulator Bench2Drive. We show the effectiveness of radar-based fusion in safety-critical scenarios where accurate motion understanding and long-horizon trajectory prediction are essential for collision avoidance. The source code of all experiments is available at", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)", "comments": "8 pages, 4 figures, 5 tables", "pdf_url": "https://arxiv.org/pdf/2508.10567.pdf", "abstract_url": "https://arxiv.org/abs/2508.10567", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "SpaRC-AD是一种基于查询的端到端相机-雷达融合框架，用于面向规划的自驾驶，通过稀疏3D特征对齐和基于多普勒的速度估计，提高了3D场景表示，显著提升了多项自驾驶任务的性能。", "motivation": "解决基于视觉的端到端自驾驶系统在恶劣天气条件、部分遮挡和精确速度估计方面的基本限制，这些限制在安全敏感场景中对准确运动理解和长时程轨迹预测至关重要。", "method": "提出SpaRC-AD框架，通过稀疏3D特征对齐和基于多普勒的速度估计，优化代理锚点、地图多段线和运动建模的3D场景表示。", "result": "在多项自驾驶任务中显著超越现有视觉基线，包括3D检测(+4.8% mAP)、多目标跟踪(+8.3% AMOTA)、在线地图(+1.8% mAP)、运动预测(-4.0% mADE)和轨迹规划(-0.1m L2和-9% TPC)。", "conclusion": "SpaRC-AD在多个挑战性基准测试中实现了空间一致性和时间一致性，证明了雷达融合在安全关键场景中的有效性，特别是在需要准确运动理解和长时程轨迹预测以避免碰撞的情况下。"}}
{"id": "2508.10572", "title": "Towards Agentic AI for Multimodal-Guided Video Object Segmentation", "authors": ["Tuyen Tran", "Thao Minh Le", "Truyen Tran"], "abstract": "Referring-based Video Object Segmentation is a multimodal problem that requires producing fine-grained segmentation results guided by external cues. Traditional approaches to this task typically involve training specialized models, which come with high computational complexity and manual annotation effort. Recent advances in vision-language foundation models open a promising direction toward training-free approaches. Several studies have explored leveraging these general-purpose models for fine-grained segmentation, achieving performance comparable to that of fully supervised, task-specific models. However, existing methods rely on fixed pipelines that lack the flexibility needed to adapt to the dynamic nature of the task. To address this limitation, we propose Multi-Modal Agent, a novel agentic system designed to solve this task in a more flexible and adaptive manner. Specifically, our method leverages the reasoning capabilities of large language models (LLMs) to generate dynamic workflows tailored to each input. This adaptive procedure iteratively interacts with a set of specialized tools designed for low-level tasks across different modalities to identify the target object described by the multimodal cues. Our agentic approach demonstrates clear improvements over prior methods on two multimodal-conditioned VOS tasks: RVOS and Ref-AVS.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10572.pdf", "abstract_url": "https://arxiv.org/abs/2508.10572", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种名为Multi-Modal Agent的新型代理系统，旨在以更灵活和自适应的方式解决基于参考的视频对象分割（RVOS）和参考音频视频分割（Ref-AVS）任务。该系统利用大型语言模型（LLMs）的推理能力生成针对每个输入的动态工作流程，并通过与一组专为不同模态设计的低级任务工具交互来识别由多模态线索描述的目标对象。", "motivation": "传统的基于参考的视频对象分割方法通常需要训练专用模型，这些模型具有高计算复杂性和大量手动注释工作。尽管视觉语言基础模型的最新进展为无训练方法开辟了有希望的方向，但现有方法依赖于固定流程，缺乏适应任务动态性质所需的灵活性。", "method": "提出的Multi-Modal Agent系统利用大型语言模型（LLMs）的推理能力生成动态工作流程，这些流程针对每个输入定制，并通过与一组专为不同模态设计的低级任务工具交互来识别目标对象。", "result": "与之前的方法相比，这种代理方法在两种多模态条件下的VOS任务（RVOS和Ref-AVS）上显示出明显的改进。", "conclusion": "Multi-Modal Agent通过其灵活和自适应的特性，为解决基于参考的视频对象分割任务提供了一种有效的新方法，特别是在处理动态和多模态输入时。"}}
{"id": "2508.10143", "title": "MCP-Orchestrated Multi-Agent System for Automated Disinformation Detection", "authors": ["Alexandru-Andrei Avram", "Adrian Groza", "Alexandru Lecu"], "abstract": "The large spread of disinformation across digital platforms creates significant challenges to information integrity. This paper presents a multi-agent system that uses relation extraction to detect disinformation in news articles, focusing on titles and short text snippets. The proposed Agentic AI system combines four agents: (i) a machine learning agent (logistic regression), (ii) a Wikipedia knowledge check agent (which relies on named entity recognition), (iii) a coherence detection agent (using LLM prompt engineering), and (iv) a web-scraped data analyzer that extracts relational triplets for fact checking. The system is orchestrated via the Model Context Protocol (MCP), offering shared context and live learning across components. Results demonstrate that the multi-agent ensemble achieves 95.3% accuracy with an F1 score of 0.964, significantly outperforming individual agents and traditional approaches. The weighted aggregation method, mathematically derived from individual agent misclassification rates, proves superior to algorithmic threshold optimization. The modular architecture makes the system easily scalable, while also maintaining details of the decision processes.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "8 pages + 1 page references, 5 figures, 4 tables, Registered for the 27th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing, 2025, Timisoara", "pdf_url": "https://arxiv.org/pdf/2508.10143.pdf", "abstract_url": "https://arxiv.org/abs/2508.10143", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种多代理系统，用于自动检测新闻文章中的虚假信息，通过结合四种不同的代理和技术，实现了高准确率和F1分数。", "motivation": "数字平台上虚假信息的广泛传播对信息完整性构成了重大挑战。", "method": "使用关系提取的多代理系统，包括机器学习代理、维基百科知识检查代理、一致性检测代理和网络抓取数据分析代理，通过模型上下文协议（MCP）进行协调。", "result": "多代理集成系统达到了95.3%的准确率和0.964的F1分数，显著优于单个代理和传统方法。", "conclusion": "模块化架构使系统易于扩展，同时保持了决策过程的细节，加权聚合方法在数学上优于算法阈值优化。"}}
{"id": "2508.10146", "title": "Agentic AI Frameworks: Architectures, Protocols, and Design Challenges", "authors": ["Hana Derouiche", "Zaki Brahmi", "Haithem Mazeni"], "abstract": "The emergence of Large Language Models (LLMs) has ushered in a transformative paradigm in artificial intelligence, Agentic AI, where intelligent agents exhibit goal-directed autonomy, contextual reasoning, and dynamic multi-agent coordination. This paper provides a systematic review and comparative analysis of leading Agentic AI frameworks, including CrewAI, LangGraph, AutoGen, Semantic Kernel, Agno, Google ADK, and MetaGPT, evaluating their architectural principles, communication mechanisms, memory management, safety guardrails, and alignment with service-oriented computing paradigms. Furthermore, we identify key limitations, emerging trends, and open challenges in the field. To address the issue of agent communication, we conduct an in-depth analysis of protocols such as the Contract Net Protocol (CNP), Agent-to-Agent (A2A), Agent Network Protocol (ANP), and Agora. Our findings not only establish a foundational taxonomy for Agentic AI systems but also propose future research directions to enhance scalability, robustness, and interoperability. This work serves as a comprehensive reference for researchers and practitioners working to advance the next generation of autonomous AI systems.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10146.pdf", "abstract_url": "https://arxiv.org/abs/2508.10146", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文对Agentic AI框架进行了系统回顾和比较分析，包括CrewAI、LangGraph等，评估了它们的架构原则、通信机制等，并提出了未来研究方向。", "motivation": "解决大型语言模型（LLMs）带来的Agentic AI领域中智能代理的目标导向自主性、上下文推理和动态多代理协调等问题。", "method": "系统回顾和比较分析领先的Agentic AI框架，深入分析通信协议如CNP、A2A等。", "result": "建立了Agentic AI系统的基础分类法，并提出了增强可扩展性、鲁棒性和互操作性的未来研究方向。", "conclusion": "本文为研究人员和从业者提供了推进下一代自主AI系统的全面参考。"}}
{"id": "2508.10152", "title": "Improving and Evaluating Open Deep Research Agents", "authors": ["Doaa Allabadi", "Kyle Bradbury", "Jordan M. Malof"], "abstract": "We focus here on Deep Research Agents (DRAs), which are systems that can take a natural language prompt from a user, and then autonomously search for, and utilize, internet-based content to address the prompt. Recent DRAs have demonstrated impressive capabilities on public benchmarks however, recent research largely involves proprietary closed-source systems. At the time of this work, we only found one open-source DRA, termed Open Deep Research (ODR). In this work we adapt the challenging recent BrowseComp benchmark to compare ODR to existing proprietary systems. We propose BrowseComp-Small (BC-Small), comprising a subset of BrowseComp, as a more computationally-tractable DRA benchmark for academic labs. We benchmark ODR and two other proprietary systems on BC-Small: one system from Anthropic and one system from Google. We find that all three systems achieve 0% accuracy on the test set of 60 questions. We introduce three strategic improvements to ODR, resulting in the ODR+ model, which achieves a state-of-the-art 10% success rate on BC-Small among both closed-source and open-source systems. We report ablation studies indicating that all three of our improvements contributed to the success of ODR+.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "8 pages, 2 figures, 2 tables", "pdf_url": "https://arxiv.org/pdf/2508.10152.pdf", "abstract_url": "https://arxiv.org/abs/2508.10152", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文聚焦于深度研究代理（DRAs），这些系统能够接收用户的自然语言提示，并自主搜索和利用基于互联网的内容来应对提示。尽管最近的DRAs在公共基准测试中展示了令人印象深刻的能力，但大多数研究涉及专有的闭源系统。本文通过改进和评估开源的Open Deep Research（ODR）模型，提出了BrowseComp-Small（BC-Small）作为更适合学术实验室的DRA基准测试，并在其上测试了ODR及两个专有系统。通过引入三项战略性改进，ODR+模型在BC-Small上达到了10%的成功率，成为当前最先进的系统。", "motivation": "当前深度研究代理（DRAs）的研究大多涉及闭源系统，缺乏开源选择。本文旨在通过改进和评估开源的Open Deep Research（ODR）模型，推动开源DRA的发展，并提供更适合学术实验室的基准测试。", "method": "本文提出了BrowseComp-Small（BC-Small）作为DRA的基准测试，对ODR及两个专有系统进行了测试。通过引入三项战略性改进，开发了ODR+模型，并在BC-Small上进行了性能评估。", "result": "所有测试的初始系统在BC-Small的60个问题测试集上均达到0%的准确率。经过改进的ODR+模型达到了10%的成功率，成为当前最先进的系统。", "conclusion": "通过改进开源的ODR模型，本文展示了开源DRA在挑战性任务上的潜力，为未来的研究提供了新的方向和基准。"}}
{"id": "2508.10177", "title": "KompeteAI: Accelerated Autonomous Multi-Agent System for End-to-End Pipeline Generation for Machine Learning Problems", "authors": ["Stepan Kulibaba", "Artem Dzhalilov", "Roman Pakhomov", "Oleg Svidchenko", "Alexander Gasnikov", "Aleksei Shpilman"], "abstract": "Recent Large Language Model (LLM)-based AutoML systems demonstrate impressive capabilities but face significant limitations such as constrained exploration strategies and a severe execution bottleneck. Exploration is hindered by one-shot methods lacking diversity and Monte Carlo Tree Search (MCTS) approaches that fail to recombine strong partial solutions. The execution bottleneck arises from lengthy code validation cycles that stifle iterative refinement. To overcome these challenges, we introduce KompeteAI, a novel AutoML framework with dynamic solution space exploration. Unlike previous MCTS methods that treat ideas in isolation, KompeteAI introduces a merging stage that composes top candidates. We further expand the hypothesis space by integrating Retrieval-Augmented Generation (RAG), sourcing ideas from Kaggle notebooks and arXiv papers to incorporate real-world strategies. KompeteAI also addresses the execution bottleneck via a predictive scoring model and an accelerated debugging method, assessing solution potential using early stage metrics to avoid costly full-code execution. This approach accelerates pipeline evaluation 6.9 times. KompeteAI outperforms leading methods (e.g., RD-agent, AIDE, and Ml-Master) by an average of 3\\% on the primary AutoML benchmark, MLE-Bench. Additionally, we propose Kompete-bench to address limitations in MLE-Bench, where KompeteAI also achieves state-of-the-art results", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10177.pdf", "abstract_url": "https://arxiv.org/abs/2508.10177", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "KompeteAI是一个新型的AutoML框架，旨在通过动态解决方案空间探索、合并顶级候选方案、集成检索增强生成（RAG）以及预测评分模型和加速调试方法，克服现有LLM-based AutoML系统的限制，如探索策略受限和执行瓶颈，从而加速机器学习问题的端到端管道生成。", "motivation": "解决现有大型语言模型（LLM）基础的AutoML系统在探索策略和执行效率上的限制，如缺乏多样性的探索策略和代码验证周期长导致的执行瓶颈。", "method": "引入动态解决方案空间探索、合并顶级候选方案、集成检索增强生成（RAG）技术，以及使用预测评分模型和加速调试方法来评估解决方案潜力。", "result": "KompeteAI在主要AutoML基准测试MLE-Bench上平均优于领先方法3%，并将管道评估速度提高了6.9倍。", "conclusion": "KompeteAI通过其创新方法有效克服了现有AutoML系统的限制，不仅在性能上取得了显著提升，还大幅提高了执行效率，为机器学习问题的端到端管道生成提供了新的解决方案。"}}
{"id": "2508.10337", "title": "A Curriculum Learning Approach to Reinforcement Learning: Leveraging RAG for Multimodal Question Answering", "authors": ["Chenliang Zhang", "Lin Wang", "Yuanyuan Lu", "Yusheng Qi", "Kexin Wang", "Peixu Hou", "Wenshi Chen"], "abstract": "This paper describes the solutions of the Dianping-Trust-Safety team for the META CRAG-MM challenge. The challenge requires building a comprehensive retrieval-augmented generation system capable for multi-modal multi-turn question answering. The competition consists of three tasks: (1) answering questions using structured data retrieved from an image-based mock knowledge graph, (2) synthesizing information from both knowledge graphs and web search results, and (3) handling multi-turn conversations that require context understanding and information aggregation from multiple sources. For Task 1, our solution is based on the vision large language model, enhanced by supervised fine-tuning with knowledge distilled from GPT-4.1. We further applied curriculum learning strategies to guide reinforcement learning, resulting in improved answer accuracy and reduced hallucination. For Task 2 and Task 3, we additionally leveraged web search APIs to incorporate external knowledge, enabling the system to better handle complex queries and multi-turn conversations. Our approach achieved 1st place in Task 1 with a significant lead of 52.38\\%, and 3rd place in Task 3, demonstrating the effectiveness of the integration of curriculum learning with reinforcement learning in our training pipeline.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10337.pdf", "abstract_url": "https://arxiv.org/abs/2508.10337", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了点评-信任-安全团队在META CRAG-MM挑战中的解决方案，该挑战要求构建一个能够进行多模态多轮问答的检索增强生成系统。通过结合视觉大语言模型、监督微调、课程学习策略和强化学习，团队在任务1中取得了显著领先的成绩，并在任务3中获得了第三名。", "motivation": "解决多模态多轮问答挑战，构建一个能够从图像知识图谱和网络搜索结果中综合信息，并理解上下文和多源信息聚合的检索增强生成系统。", "method": "结合视觉大语言模型和GPT-4.1的知识蒸馏进行监督微调，应用课程学习策略指导强化学习，以及利用网络搜索API整合外部知识。", "result": "在任务1中以52.38%的显著领先优势获得第一名，在任务3中获得第三名，证明了课程学习与强化学习结合的有效性。", "conclusion": "课程学习与强化学习的结合在训练流程中显著提高了系统的问答准确性和减少了幻觉现象，为多模态多轮问答系统的开发提供了有效的方法。"}}
{"id": "2508.10340", "title": "Multi-Agent Trust Region Policy Optimisation: A Joint Constraint Approach", "authors": ["Chak Lam Shek", "Guangyao Shi", "Pratap Tokekar"], "abstract": "Multi-agent reinforcement learning (MARL) requires coordinated and stable policy updates among interacting agents. Heterogeneous-Agent Trust Region Policy Optimization (HATRPO) enforces per-agent trust region constraints using Kullback-Leibler (KL) divergence to stabilize training. However, assigning each agent the same KL threshold can lead to slow and locally optimal updates, especially in heterogeneous settings. To address this limitation, we propose two approaches for allocating the KL divergence threshold across agents: HATRPO-W, a Karush-Kuhn-Tucker-based (KKT-based) method that optimizes threshold assignment under global KL constraints, and HATRPO-G, a greedy algorithm that prioritizes agents based on improvement-to-divergence ratio. By connecting sequential policy optimization with constrained threshold scheduling, our approach enables more flexible and effective learning in heterogeneous-agent settings. Experimental results demonstrate that our methods significantly boost the performance of HATRPO, achieving faster convergence and higher final rewards across diverse MARL benchmarks. Specifically, HATRPO-W and HATRPO-G achieve comparable improvements in final performance, each exceeding 22.5%. Notably, HATRPO-W also demonstrates more stable learning dynamics, as reflected by its lower variance.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10340.pdf", "abstract_url": "https://arxiv.org/abs/2508.10340", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了两种方法（HATRPO-W和HATRPO-G）来分配多智能体强化学习中的KL散度阈值，以解决HATRPO中因统一阈值导致的训练缓慢和局部最优问题。实验证明，这两种方法显著提升了HATRPO的性能，实现了更快的收敛和更高的最终奖励。", "motivation": "解决多智能体强化学习（MARL）中因统一KL散度阈值导致的训练缓慢和局部最优问题，特别是在异质智能体设置中。", "method": "提出了两种KL散度阈值分配方法：基于KKT的HATRPO-W和基于贪婪算法的HATRPO-G，通过连接顺序策略优化与约束阈值调度，实现更灵活有效的学习。", "result": "HATRPO-W和HATRPO-G在多种MARL基准测试中显著提升了HATRPO的性能，最终性能提升均超过22.5%，且HATRPO-W表现出更稳定的学习动态。", "conclusion": "通过优化KL散度阈值的分配，可以显著提升多智能体强化学习的性能和稳定性，特别是在异质智能体设置中。"}}
{"id": "2508.10358", "title": "What to Ask Next? Probing the Imaginative Reasoning of LLMs with TurtleSoup Puzzles", "authors": ["Mengtao Zhou", "Sifan Wu", "Huan Zhang", "Qi Sima", "Bang Liu"], "abstract": "We investigate the capacity of Large Language Models (LLMs) for imaginative reasoning--the proactive construction, testing, and revision of hypotheses in information-sparse environments. Existing benchmarks, often static or focused on social deduction, fail to capture the dynamic, exploratory nature of this reasoning process. To address this gap, we introduce a comprehensive research framework based on the classic \"Turtle Soup\" game, integrating a benchmark, an agent, and an evaluation protocol. We present TurtleSoup-Bench, the first large-scale, bilingual, interactive benchmark for imaginative reasoning, comprising 800 turtle soup puzzles sourced from both the Internet and expert authors. We also propose Mosaic-Agent, a novel agent designed to assess LLMs' performance in this setting. To evaluate reasoning quality, we develop a multi-dimensional protocol measuring logical consistency, detail completion, and conclusion alignment. Experiments with leading LLMs reveal clear capability limits, common failure patterns, and a significant performance gap compared to humans. Our work offers new insights into LLMs' imaginative reasoning and establishes a foundation for future research on exploratory agent behavior.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10358.pdf", "abstract_url": "https://arxiv.org/abs/2508.10358", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过引入基于'乌龟汤'游戏的综合研究框架，包括基准测试、代理和评估协议，探讨了大型语言模型(LLMs)在信息稀疏环境下的想象力推理能力。研究提出了TurtleSoup-Bench基准和Mosaic-Agent代理，并通过多维度评估协议揭示了LLMs在想象力推理方面的能力限制和与人类的性能差距。", "motivation": "解决现有基准测试在捕捉动态、探索性推理过程中的不足，评估LLMs在信息稀疏环境下的想象力推理能力。", "method": "引入基于'乌龟汤'游戏的研究框架，包括TurtleSoup-Bench基准、Mosaic-Agent代理和多维度评估协议。", "result": "实验揭示了LLMs在想象力推理方面的能力限制、常见失败模式及与人类的显著性能差距。", "conclusion": "本研究为理解LLMs的想象力推理能力提供了新见解，并为未来探索性代理行为研究奠定了基础。"}}
{"id": "2508.10391", "title": "LeanRAG: Knowledge-Graph-Based Generation with Semantic Aggregation and Hierarchical Retrieval", "authors": ["Yaoze Zhang", "Rong Wu", "Pinlong Cai", "Xiaoman Wang", "Guohang Yan", "Song Mao", "Ding Wang", "Botian Shi"], "abstract": "Retrieval-Augmented Generation (RAG) plays a crucial role in grounding Large Language Models by leveraging external knowledge, whereas the effectiveness is often compromised by the retrieval of contextually flawed or incomplete information. To address this, knowledge graph-based RAG methods have evolved towards hierarchical structures, organizing knowledge into multi-level summaries. However, these approaches still suffer from two critical, unaddressed challenges: high-level conceptual summaries exist as disconnected ``semantic islands'', lacking the explicit relations needed for cross-community reasoning; and the retrieval process itself remains structurally unaware, often degenerating into an inefficient flat search that fails to exploit the graph's rich topology. To overcome these limitations, we introduce LeanRAG, a framework that features a deeply collaborative design combining knowledge aggregation and retrieval strategies. LeanRAG first employs a novel semantic aggregation algorithm that forms entity clusters and constructs new explicit relations among aggregation-level summaries, creating a fully navigable semantic network. Then, a bottom-up, structure-guided retrieval strategy anchors queries to the most relevant fine-grained entities and then systematically traverses the graph's semantic pathways to gather concise yet contextually comprehensive evidence sets. The LeanRAG can mitigate the substantial overhead associated with path retrieval on graphs and minimizes redundant information retrieval. Extensive experiments on four challenging QA benchmarks with different domains demonstrate that LeanRAG significantly outperforming existing methods in response quality while reducing 46\\% retrieval redundancy. Code is available at:", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10391.pdf", "abstract_url": "https://arxiv.org/abs/2508.10391", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "LeanRAG是一个基于知识图谱的检索增强生成框架，通过语义聚合和层次检索解决现有方法中的语义孤岛和检索效率问题。", "motivation": "解决检索增强生成（RAG）中因检索到上下文错误或不完整信息而影响效果的问题，特别是知识图谱方法中存在的语义孤岛和检索效率低下的挑战。", "method": "LeanRAG采用语义聚合算法构建实体聚类和显式关系，形成可导航的语义网络，并结合自底向上、结构引导的检索策略，系统遍历语义路径收集证据集。", "result": "在四个不同领域的QA基准测试中，LeanRAG在响应质量上显著优于现有方法，同时减少了46%的检索冗余。", "conclusion": "LeanRAG通过创新的语义聚合和层次检索策略，有效提升了检索增强生成的效率和效果，为知识图谱在RAG中的应用提供了新的方向。"}}
{"id": "2508.10016", "title": "Training-Free Multimodal Large Language Model Orchestration", "authors": ["Tianyu Xie", "Yuhang Wu", "Yongdong Luo", "Jiayi Ji", "Xiawu Zheng"], "abstract": "Different Multimodal Large Language Models (MLLMs) cannot be integrated into a unified multimodal input-output system directly. In previous work, training has been considered as an inevitable component due to challenges in modal alignment, Text-to-Speech efficiency and other integration issues. In this paper, we introduce Multimodal Large Language Model Orchestration, an effective approach for creating interactive multimodal AI systems without additional training. MLLM Orchestration leverages the inherent reasoning capabilities of large language models to coordinate specialized models through explicit workflows, enabling natural multimodal interactions while maintaining modularity, improving interpretability, and significantly enhancing computational efficiency. Our orchestration framework is built upon three key innovations: (1) a central controller LLM that analyzes user inputs and dynamically routes tasks to appropriate specialized models through carefully designed agents; (2) a parallel Text-to-Speech architecture that enables true full-duplex interaction with seamless interruption handling and natural conversational flow; and (3) a cross-modal memory integration system that maintains coherent context across modalities through intelligent information synthesis and retrieval, selectively avoiding unnecessary modality calls in certain scenarios to improve response speed. Extensive evaluations demonstrate that MLLM Orchestration achieves comprehensive multimodal capabilities without additional training, performance improvements of up to 7.8% over traditional jointly-trained approaches on standard benchmarks, reduced latency by 10.3%, and significantly enhanced interpretability through explicit orchestration processes.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10016.pdf", "abstract_url": "https://arxiv.org/abs/2508.10016", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种无需额外训练的多模态大型语言模型编排方法，通过利用大型语言模型的固有推理能力协调专门模型，实现自然的多模态交互。", "motivation": "解决不同多模态大型语言模型（MLLMs）无法直接集成到统一的多模态输入输出系统中的问题，避免传统方法中必需的训练过程。", "method": "采用中央控制器LLM分析用户输入并通过精心设计的代理动态路由任务到适当的专门模型，实现并行文本到语音架构和跨模态记忆集成系统。", "result": "MLLM编排在标准基准测试中比传统联合训练方法性能提升高达7.8%，延迟减少10.3%，并通过明确的编排过程显著提高了可解释性。", "conclusion": "MLLM编排方法无需额外训练即可实现全面的多模态能力，提高了计算效率和交互的自然性，同时保持了模块化和可解释性。"}}
{"id": "2508.10024", "title": "RTTC: Reward-Guided Collaborative Test-Time Compute", "authors": ["J. Pablo Muñoz", "Jinjie Yuan"], "abstract": "Test-Time Compute (TTC) has emerged as a powerful paradigm for enhancing the performance of Large Language Models (LLMs) at inference, leveraging strategies such as Test-Time Training (TTT) and Retrieval-Augmented Generation (RAG). However, the optimal adaptation strategy varies across queries, and indiscriminate application of TTC strategy incurs substantial computational overhead. In this work, we introduce Reward-Guided Test-Time Compute (RTTC), a novel framework that adaptively selects the most effective TTC strategy for each query via a pretrained reward model, maximizing downstream accuracy across diverse domains and tasks. RTTC operates in a distributed server-client architecture, retrieving relevant samples from a remote knowledge base and applying RAG or lightweight fine-tuning on client devices only when necessary. To further mitigate redundant computation, we propose Query-State Caching, which enables the efficient reuse of historical query states at both retrieval and adaptation levels. Extensive experiments across multiple LLMs and benchmarks demonstrate that RTTC consistently achieves superior accuracy compared to vanilla RAG or TTT, validating the necessity of adaptive, reward-guided TTC selection and the potential of RTTC for scalable, high-performance language model adaptation.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10024.pdf", "abstract_url": "https://arxiv.org/abs/2508.10024", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "RTTC是一种新颖的框架，通过预训练的奖励模型自适应选择每个查询的最有效测试时间计算策略，以最大化不同领域和任务的下游准确性。", "motivation": "解决在大型语言模型推理中，无差别应用测试时间计算策略导致的计算开销大的问题。", "method": "采用奖励引导的测试时间计算（RTTC）框架，结合分布式服务器-客户端架构和查询状态缓存技术。", "result": "在多个大型语言模型和基准测试上的广泛实验表明，RTTC相比传统的RAG或TTT方法，能够持续实现更高的准确性。", "conclusion": "RTTC框架验证了自适应、奖励引导的TTC选择的必要性，展示了其在可扩展、高性能语言模型适应方面的潜力。"}}
{"id": "2508.10467", "title": "FIRESPARQL: A LLM-based Framework for SPARQL Query Generation over Scholarly Knowledge Graphs", "authors": ["Xueli Pan", "Victor de Boer", "Jacco van Ossenbruggen"], "abstract": "Question answering over Scholarly Knowledge Graphs (SKGs) remains a challenging task due to the complexity of scholarly content and the intricate structure of these graphs. Large Language Model (LLM) approaches could be used to translate natural language questions (NLQs) into SPARQL queries; however, these LLM-based approaches struggle with SPARQL query generation due to limited exposure to SKG-specific content and the underlying schema. We identified two main types of errors in the LLM-generated SPARQL queries: (i) structural inconsistencies, such as missing or redundant triples in the queries, and (ii) semantic inaccuracies, where incorrect entities or properties are shown in the queries despite a correct query structure. To address these issues, we propose FIRESPARQL, a modular framework that supports fine-tuned LLMs as a core component, with optional context provided via retrieval-augmented generation (RAG) and a SPARQL query correction layer. We evaluate the framework on the SciQA Benchmark using various configurations (zero-shot, zero-shot with RAG, one-shot, fine-tuning, and fine-tuning with RAG) and compare the performance with baseline and state-of-the-art approaches. We measure query accuracy using BLEU and ROUGE metrics, and query result accuracy using relaxed exact match(RelaxedEM), with respect to the gold standards containing the NLQs, SPARQL queries, and the results of the queries. Experimental results demonstrate that fine-tuning achieves the highest overall performance, reaching 0.90 ROUGE-L for query accuracy and 0.85 RelaxedEM for result accuracy on the test set.", "subjects": "Artificial Intelligence (cs.AI); Digital Libraries (cs.DL)", "comments": "Accepted at 17th International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management (IC3K)", "pdf_url": "https://arxiv.org/pdf/2508.10467.pdf", "abstract_url": "https://arxiv.org/abs/2508.10467", "categories": ["Artificial Intelligence (cs.AI)", "Digital Libraries (cs.DL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "FIRESPARQL是一个基于大型语言模型(LLM)的框架，旨在解决学术知识图(SKGs)上自然语言问题(NLQs)转换为SPARQL查询的挑战，通过微调LLM、检索增强生成(RAG)和SPARQL查询校正层来提高查询的准确性和结果准确性。", "motivation": "解决在学术知识图(SKGs)上通过自然语言问题(NLQs)生成SPARQL查询时的结构不一致和语义不准确问题。", "method": "提出FIRESPARQL框架，结合微调的LLM、可选的RAG上下文提供和SPARQL查询校正层，采用多种配置（零样本、零样本加RAG、一样本、微调及微调加RAG）进行评估。", "result": "实验结果显示，微调配置在测试集上达到了最高的整体性能，查询准确性的ROUGE-L得分为0.90，结果准确性的RelaxedEM得分为0.85。", "conclusion": "FIRESPARQL框架通过微调LLM和结合RAG及查询校正，显著提高了在学术知识图上生成SPARQL查询的准确性和结果准确性，为学术知识图的问答系统提供了有效的解决方案。"}}
{"id": "2508.10501", "title": "PASS: Probabilistic Agentic Supernet Sampling for Interpretable and Adaptive Chest X-Ray Reasoning", "authors": ["Yushi Feng", "Junye Du", "Yingying Hong", "Qifan Wang", "Lequan Yu"], "abstract": "Existing tool-augmented agentic systems are limited in the real world by (i) black-box reasoning steps that undermine trust of decision-making and pose safety risks, (ii) poor multimodal integration, which is inherently critical for healthcare tasks, and (iii) rigid and computationally inefficient agentic pipelines. We introduce PASS (Probabilistic Agentic Supernet Sampling), the first multimodal framework to address these challenges in the context of Chest X-Ray (CXR) reasoning. PASS adaptively samples agentic workflows over a multi-tool graph, yielding decision paths annotated with interpretable probabilities. Given the complex CXR reasoning task with multimodal medical data, PASS leverages its learned task-conditioned distribution over the agentic supernet. Thus, it adaptively selects the most suitable tool at each supernet layer, offering probability-annotated trajectories for post-hoc audits and directly enhancing medical AI safety. PASS also continuously compresses salient findings into an evolving personalized memory, while dynamically deciding whether to deepen its reasoning path or invoke an early exit for efficiency. To optimize a Pareto frontier balancing performance and cost, we design a novel three-stage training procedure, including expert knowledge warm-up, contrastive path-ranking, and cost-aware reinforcement learning. To facilitate rigorous evaluation, we introduce CAB-E, a comprehensive benchmark for multi-step, safety-critical, free-form CXR reasoning. Experiments across various benchmarks validate that PASS significantly outperforms strong baselines in multiple metrics (e.g., accuracy, AUC, LLM-J.) while balancing computational costs, pushing a new paradigm shift towards interpretable, adaptive, and multimodal medical agentic systems.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10501.pdf", "abstract_url": "https://arxiv.org/abs/2508.10501", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "PASS（概率代理超级网络采样）是一个多模态框架，旨在解决现有工具增强代理系统在现实世界中的局限性，特别是在胸部X光（CXR）推理方面。它通过自适应采样代理工作流程，提供带有可解释概率的决策路径，增强了医疗AI的安全性和效率。", "motivation": "解决现有工具增强代理系统在信任度、多模态整合和计算效率方面的不足，特别是在医疗保健任务中。", "method": "PASS利用学习到的任务条件分布，在多工具图上自适应地选择最合适的工具，提供概率注释的轨迹，并通过三阶段训练程序优化性能和成本的平衡。", "result": "PASS在多个基准测试中显著优于强基线，在准确性、AUC等多项指标上表现优异，同时平衡了计算成本。", "conclusion": "PASS推动了一种新的范式转变，朝着可解释、自适应和多模态的医疗代理系统发展，为医疗AI的安全性提供了直接增强。"}}
{"id": "2508.10745", "title": "Agentic Design Review System", "authors": ["Sayan Nag", "K J Joseph", "Koustava Goswami", "Vlad I Morariu", "Balaji Vasan Srinivasan"], "abstract": "Evaluating graphic designs involves assessing it from multiple facets like alignment, composition, aesthetics and color choices. Evaluating designs in a holistic way involves aggregating feedback from individual expert reviewers. Towards this, we propose an Agentic Design Review System (AgenticDRS), where multiple agents collaboratively analyze a design, orchestrated by a meta-agent. A novel in-context exemplar selection approach based on graph matching and a unique prompt expansion method plays central role towards making each agent design aware. Towards evaluating this framework, we propose DRS-BENCH benchmark. Thorough experimental evaluation against state-of-the-art baselines adapted to the problem setup, backed-up with critical ablation experiments brings out the efficacy of Agentic-DRS in evaluating graphic designs and generating actionable feedback. We hope that this work will attract attention to this pragmatic, yet under-explored research direction.", "subjects": "Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Multiagent Systems (cs.MA); Multimedia (cs.MM)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10745.pdf", "abstract_url": "https://arxiv.org/abs/2508.10745", "categories": ["Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)", "Multimedia (cs.MM)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种名为Agentic设计评审系统（AgenticDRS）的新方法，通过多智能体协作分析设计，由元智能体协调，采用基于图匹配的上下文示例选择方法和独特的提示扩展方法，使每个智能体具备设计意识。通过DRS-BENCH基准测试和与现有基线的全面实验评估，证明了Agentic-DRS在评估图形设计和生成可操作反馈方面的有效性。", "motivation": "解决图形设计评估中需要从多个方面（如对齐、构图、美学和颜色选择）进行综合评估的问题，以及如何有效聚合来自个体专家评审的反馈。", "method": "提出了Agentic设计评审系统（AgenticDRS），其中多个智能体在元智能体的协调下协作分析设计，采用了基于图匹配的上下文示例选择方法和独特的提示扩展方法。", "result": "通过DRS-BENCH基准测试和与现有基线的全面实验评估，证明了Agentic-DRS在评估图形设计和生成可操作反馈方面的有效性。", "conclusion": "这项工作展示了Agentic-DRS在图形设计评估和反馈生成方面的潜力，希望引起对这一实用但尚未充分探索的研究方向的关注。"}}
{"id": "2508.10769", "title": "Modeling Human Responses to Multimodal AI Content", "authors": ["Zhiqi Shen", "Shaojing Fan", "Danni Xu", "Terence Sim", "Mohan Kankanhalli"], "abstract": "As AI-generated content becomes widespread, so does the risk of misinformation. While prior research has primarily focused on identifying whether content is authentic, much less is known about how such content influences human perception and behavior. In domains like trading or the stock market, predicting how people react (e.g., whether a news post will go viral), can be more critical than verifying its factual accuracy. To address this, we take a human-centered approach and introduce the MhAIM Dataset, which contains 154,552 online posts (111,153 of them AI-generated), enabling large-scale analysis of how people respond to AI-generated content. Our human study reveals that people are better at identifying AI content when posts include both text and visuals, particularly when inconsistencies exist between the two. We propose three new metrics: trustworthiness, impact, and openness, to quantify how users judge and engage with online content. We present T-Lens, an LLM-based agent system designed to answer user queries by incorporating predicted human responses to multimodal information. At its core is HR-MCP (Human Response Model Context Protocol), built on the standardized Model Context Protocol (MCP), enabling seamless integration with any LLM. This integration allows T-Lens to better align with human reactions, enhancing both interpretability and interaction capabilities. Our work provides empirical insights and practical tools to equip LLMs with human-awareness capabilities. By highlighting the complex interplay among AI, human cognition, and information reception, our findings suggest actionable strategies for mitigating the risks of AI-driven misinformation.", "subjects": "Artificial Intelligence (cs.AI); Multimedia (cs.MM)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10769.pdf", "abstract_url": "https://arxiv.org/abs/2508.10769", "categories": ["Artificial Intelligence (cs.AI)", "Multimedia (cs.MM)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过引入MhAIM数据集和T-Lens系统，研究了人类对AI生成内容的反应，提出了信任度、影响力和开放性三个新指标，并开发了基于LLM的代理系统以更好地预测和适应人类反应。", "motivation": "随着AI生成内容的普及，错误信息的风险也随之增加。现有研究主要集中在识别内容的真实性上，而对这种内容如何影响人类感知和行为知之甚少。", "method": "研究采用了以人为中心的方法，引入了包含154,552个在线帖子（其中111,153个为AI生成）的MhAIM数据集，并开发了基于LLM的T-Lens系统，该系统通过HR-MCP协议与任何LLM无缝集成。", "result": "人类研究表明，当帖子同时包含文本和视觉内容时，人们更擅长识别AI内容，尤其是在两者之间存在不一致时。T-Lens系统能够更好地预测和适应人类反应，提高了可解释性和交互能力。", "conclusion": "本研究提供了实证见解和实用工具，使LLM具备人类意识能力，通过强调AI、人类认知和信息接收之间复杂的相互作用，提出了减轻AI驱动错误信息风险的可操作策略。"}}
{"id": "2508.10833", "title": "UI-Venus Technical Report: Building High-performance UI Agents with RFT", "authors": ["Zhangxuan Gu", "Zhengwen Zeng", "Zhenyu Xu", "Xingran Zhou", "Shuheng Shen", "Yunfei Liu", "Beitong Zhou", "Changhua Meng", "Tianyu Xia", "Weizhi Chen", "Yue Wen", "Jingya Dou", "Fei Tang", "Jinzhen Lin", "Yulin Liu", "Zhenlin Guo", "Yichen Gong", "Heng Jia", "Changlong Gao", "Yuan Guo", "Yong Deng", "Zhenyu Guo", "Liang Chen", "Weiqiang Wang"], "abstract": "We present UI-Venus, a native UI agent that takes only screenshots as input based on a multimodal large language model. UI-Venus achieves SOTA performance on both UI grounding and navigation tasks using only several hundred thousand high-quality training samples through reinforcement finetune (RFT) based on Qwen2.5-VL. Specifically, the 7B and 72B variants of UI-Venus obtain 94.1% / 50.8% and 95.3% / 61.9% on the standard grounding benchmarks, i.e., Screenspot-V2 / Pro, surpassing the previous SOTA baselines including open-source GTA1 and closed-source", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10833.pdf", "abstract_url": "https://arxiv.org/abs/2508.10833", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "UI-Venus是一个基于多模态大语言模型的原生UI代理，仅以截图作为输入，通过基于Qwen2.5-VL的强化微调（RFT）方法，在UI接地和导航任务上实现了最先进的性能。", "motivation": "解决在仅使用截图作为输入的情况下，实现高性能UI代理的挑战，特别是在UI接地和导航任务上的表现。", "method": "采用基于Qwen2.5-VL的强化微调（RFT）方法，使用数十万高质量训练样本进行训练。", "result": "UI-Venus的7B和72B变体在标准接地基准测试Screenspot-V2 / Pro上分别取得了94.1% / 50.8%和95.3% / 61.9%的成绩，超越了包括开源GTA1和闭源在内的先前最先进基线。", "conclusion": "UI-Venus展示了在仅使用截图作为输入的情况下，通过RFT方法可以构建出高性能的UI代理，为相关领域的研究和应用提供了新的可能性。"}}
{"id": "2508.10419", "title": "ComoRAG: A Cognitive-Inspired Memory-Organized RAG for Stateful Long Narrative Reasoning", "authors": ["Juyuan Wang", "Rongchen Zhao", "Wei Wei", "Yufeng Wang", "Mo Yu", "Jie Zhou", "Jin Xu", "Liyan Xu"], "abstract": "Narrative comprehension on long stories and novels has been a challenging domain attributed to their intricate plotlines and entangled, often evolving relations among characters and entities. Given the LLM's diminished reasoning over extended context and high computational cost, retrieval-based approaches remain a pivotal role in practice. However, traditional RAG methods can fall short due to their stateless, single-step retrieval process, which often overlooks the dynamic nature of capturing interconnected relations within long-range context. In this work, we propose ComoRAG, holding the principle that narrative reasoning is not a one-shot process, but a dynamic, evolving interplay between new evidence acquisition and past knowledge consolidation, analogous to human cognition when reasoning with memory-related signals in the brain. Specifically, when encountering a reasoning impasse, ComoRAG undergoes iterative reasoning cycles while interacting with a dynamic memory workspace. In each cycle, it generates probing queries to devise new exploratory paths, then integrates the retrieved evidence of new aspects into a global memory pool, thereby supporting the emergence of a coherent context for the query resolution. Across four challenging long-context narrative benchmarks (200K+ tokens), ComoRAG outperforms strong RAG baselines with consistent relative gains up to 11% compared to the strongest baseline. Further analysis reveals that ComoRAG is particularly advantageous for complex queries requiring global comprehension, offering a principled, cognitively motivated paradigm for retrieval-based long context comprehension towards stateful reasoning. Our code is publicly released at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10419.pdf", "abstract_url": "https://arxiv.org/abs/2508.10419", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "ComoRAG是一种受认知启发的、基于记忆组织的检索增强生成（RAG）方法，旨在解决长故事和小说中复杂的叙事理解问题。通过动态记忆工作区和迭代推理循环，它显著提高了长上下文叙事理解的表现。", "motivation": "解决长故事和小说中复杂的叙事理解问题，特别是由于LLM在扩展上下文中的推理能力下降和高计算成本，传统RAG方法因静态、单步检索过程而无法有效捕捉长范围上下文中的动态关系。", "method": "提出ComoRAG，模拟人类认知过程中的记忆相关信号推理，通过迭代推理循环与动态记忆工作区交互，生成探测查询以探索新路径，并将检索到的新证据整合到全局记忆池中。", "result": "在四个具有挑战性的长上下文叙事基准测试（200K+ tokens）中，ComoRAG比最强的RAG基线表现优异，相对增益高达11%，特别适用于需要全局理解的复杂查询。", "conclusion": "ComoRAG为基于检索的长上下文理解提供了一个有原则的、认知动机的范式，特别是在需要状态推理的复杂叙事理解任务中显示出显著优势。"}}
{"id": "2508.10333", "title": "ReconVLA: Reconstructive Vision-Language-Action Model as Effective Robot Perceiver", "authors": ["Wenxuan Song", "Ziyang Zhou", "Han Zhao", "Jiayi Chen", "Pengxiang Ding", "Haodong Yan", "Yuxin Huang", "Feilong Tang", "Donglin Wang", "Haoang Li"], "abstract": "Recent advances in Vision-Language-Action (VLA) models have enabled robotic agents to integrate multimodal understanding with action execution. However, our empirical analysis reveals that current VLAs struggle to allocate visual attention to target regions. Instead, visual attention is always dispersed. To guide the visual attention grounding on the correct target, we propose ReconVLA, a reconstructive VLA model with an implicit grounding paradigm. Conditioned on the model's visual outputs, a diffusion transformer aims to reconstruct the gaze region of the image, which corresponds to the target manipulated objects. This process prompts the VLA model to learn fine-grained representations and accurately allocate visual attention, thus effectively leveraging task-specific visual information and conducting precise manipulation. Moreover, we curate a large-scale pretraining dataset comprising over 100k trajectories and 2 million data samples from open-source robotic datasets, further boosting the model's generalization in visual reconstruction. Extensive experiments in simulation and the real world demonstrate the superiority of our implicit grounding method, showcasing its capabilities of precise manipulation and generalization. Our project page is", "subjects": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10333.pdf", "abstract_url": "https://arxiv.org/abs/2508.10333", "categories": ["Robotics (cs.RO)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "ReconVLA是一种重建性视觉-语言-动作模型，旨在通过隐式接地范式改进机器人感知器，解决当前VLA模型在视觉注意力分配上的不足。", "motivation": "当前的视觉-语言-动作（VLA）模型在分配视觉注意力到目标区域方面存在困难，视觉注意力往往分散。为了解决这一问题，提出了ReconVLA模型。", "method": "提出了一种重建性VLA模型，通过基于模型视觉输出的扩散变换器重建图像的注视区域，从而引导模型学习细粒度表示并准确分配视觉注意力。", "result": "在模拟和现实世界的广泛实验中，展示了隐式接地方法的优越性，包括精确操作和泛化能力。", "conclusion": "ReconVLA通过重建注视区域有效提升了VLA模型在任务特定视觉信息利用和精确操作上的能力，同时通过大规模预训练数据集增强了模型的视觉重建泛化能力。"}}
{"id": "2508.10695", "title": "Learning from Natural Language Feedback for Personalized Question Answering", "authors": ["Alireza Salemi", "Hamed Zamani"], "abstract": "Personalization is crucial for enhancing both the effectiveness and user satisfaction of language technologies, particularly in information-seeking tasks like question answering. Current approaches for personalizing large language models (LLMs) often rely on retrieval-augmented generation (RAG), followed by reinforcement learning with scalar reward signals to teach models how to use retrieved personal context. We believe that these scalar rewards sometimes provide weak, non-instructive feedback, limiting learning efficiency and personalization quality. We introduce VAC, a novel framework for personalized response generation that replaces scalar rewards with natural language feedback (NLF) that are generated conditioned on the user profiles and the question narratives. NLF serves as a rich and actionable supervision signal, allowing the policy model to iteratively refine its outputs and internalize effective personalization strategies. Training alternates between optimizing the feedback model and fine-tuning the policy model on the improved responses, resulting in a policy model that no longer requires feedback at inference. Evaluation on the LaMP-QA benchmark that consists of three diverse domains demonstrates consistent and significant improvements over the state-of-the-art results. Human evaluations further confirm the superior quality of the generated responses. These results demonstrate that NLF provides more effective signals for optimizing personalized question answering.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10695.pdf", "abstract_url": "https://arxiv.org/abs/2508.10695", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了一种名为VAC的新框架，用于个性化回答生成，该框架用自然语言反馈（NLF）替代了传统的标量奖励，以提高学习效率和个性化质量。通过在LaMP-QA基准测试上的评估，证明了NLF在优化个性化问答中的有效性。", "motivation": "当前个性化大型语言模型（LLMs）的方法主要依赖于检索增强生成（RAG）和标量奖励信号的强化学习，这些标量奖励有时提供的是弱反馈，限制了学习效率和个性化质量。", "method": "VAC框架通过使用基于用户档案和问题叙述生成的自然语言反馈（NLF）作为丰富且可操作的监督信号，允许策略模型迭代优化其输出并内化有效的个性化策略。训练过程交替优化反馈模型和在改进的响应上微调策略模型。", "result": "在LaMP-QA基准测试上的评估显示，该方法在三个不同领域均实现了对现有技术水平的显著改进。人类评估进一步证实了生成响应的优越质量。", "conclusion": "自然语言反馈（NLF）为优化个性化问答提供了更有效的信号，证明了其在提高语言技术个性化和用户满意度方面的潜力。"}}
{"id": "2508.10426", "title": "Computational Economics in Large Language Models: Exploring Model Behavior and Incentive Design under Resource Constraints", "authors": ["Sandeep Reddy", "Kabir Khan", "Rohit Patil", "Ananya Chakraborty", "Faizan A. Khan", "Swati Kulkarni", "Arjun Verma", "Neha Singh"], "abstract": "Large language models (LLMs) are limited by substantial computational cost. We introduce a \"computational economics\" framework that treats an LLM as an internal economy of resource-constrained agents (attention heads and neuron blocks) that must allocate scarce computation to maximize task utility. First, we show empirically that when computation is scarce, standard LLMs reallocate attention toward high-value tokens while preserving accuracy. Building on this observation, we propose an incentive-driven training paradigm that augments the task loss with a differentiable computation cost term, encouraging sparse and efficient activations. On GLUE (MNLI, STS-B, CoLA) and WikiText-103, the method yields a family of models that trace a Pareto frontier and consistently dominate post-hoc pruning; for a similar accuracy we obtain roughly a forty percent reduction in FLOPS and lower latency, together with more interpretable attention patterns. These results indicate that economic principles offer a principled route to designing efficient, adaptive, and more transparent LLMs under strict resource constraints.", "subjects": "Computation and Language (cs.CL)", "comments": "Preprint; 7 figures, 4 tables, 1 algorithm. Experiments on GLUE (MNLI, STS-B, CoLA) and WikiText-103 with BERT-base; evaluation includes FLOPS, latency, Gini and entropy metrics", "pdf_url": "https://arxiv.org/pdf/2508.10426.pdf", "abstract_url": "https://arxiv.org/abs/2508.10426", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种'计算经济学'框架，将大型语言模型（LLMs）视为资源受限的代理（注意力头和神经元块）的内部经济，旨在通过稀缺计算资源最大化任务效用。实证显示，在计算资源稀缺时，标准LLMs会重新分配注意力至高价值标记，同时保持准确性。基于此，作者提出了一种激励驱动的训练范式，通过增加可微分计算成本项来鼓励稀疏和高效的激活。在GLUE和WikiText-103上的实验表明，该方法能生成一系列模型，这些模型在Pareto前沿上表现优异，相比事后修剪，在相似准确度下实现了约40%的FLOPS减少和更低延迟，同时注意力模式更易解释。", "motivation": "解决大型语言模型（LLMs）因高计算成本而受限的问题，探索在严格资源约束下设计高效、自适应且更透明的LLMs的途径。", "method": "引入'计算经济学'框架，将LLMs视为资源受限代理的内部经济，提出激励驱动的训练范式，通过增加可微分计算成本项来优化任务损失。", "result": "在GLUE（MNLI, STS-B, CoLA）和WikiText-103上，该方法生成的模型在Pareto前沿上表现优异，相比事后修剪，在相似准确度下实现了约40%的FLOPS减少和更低延迟，注意力模式更易解释。", "conclusion": "经济原则为在严格资源约束下设计高效、自适应且更透明的大型语言模型提供了原则性路径。"}}
{"id": "2508.10839", "title": "Reinforced Language Models for Sequential Decision Making", "authors": ["Jim Dilkes", "Vahid Yazdanpanah", "Sebastian Stein"], "abstract": "Large Language Models (LLMs) show potential as sequential decision-making agents, but their application is often limited due to a reliance on large, computationally expensive models. This creates a need to improve smaller models, yet existing post-training methods are designed for single-turn interactions and cannot handle credit assignment in multi-step agentic tasks. To address this, we introduce Multi-Step Group-Relative Policy Optimization (MS-GRPO), a new algorithm for post-training LLM agents, grounded in formal Text-Mediated Stochastic Game (TSMG) and Language-Agent Policy (LAP) frameworks. For credit assignment, MS-GRPO attributes the entire cumulative episode reward to each individual episode step. We supplement this algorithm with a novel absolute-advantage-weighted episode sampling strategy that we show improves training performance. We evaluate our approach by post-training a 3-billion parameter model on Snake and Frozen Lake. Our experiments demonstrate that the method is effective in improving decision-making performance: our post-trained 3B parameter model outperforms a 72B parameter baseline by 50% on the Frozen Lake task. This work demonstrates that targeted post-training is a practical and efficient alternative to relying on model scale for creating sequential decision-making agents using LLMs.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10839.pdf", "abstract_url": "https://arxiv.org/abs/2508.10839", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了多步组相对策略优化（MS-GRPO），一种新的后训练大型语言模型（LLM）代理的算法，旨在解决多步代理任务中的信用分配问题，并通过实验证明其在提升决策性能方面的有效性。", "motivation": "大型语言模型（LLMs）作为序列决策代理的潜力受到依赖大型、计算成本高的模型的限制，且现有的后训练方法无法处理多步代理任务中的信用分配问题。", "method": "引入了基于文本介导的随机游戏（TSMG）和语言代理策略（LAP）框架的多步组相对策略优化（MS-GRPO）算法，并提出了一种新的绝对优势加权片段采样策略。", "result": "实验表明，后训练的30亿参数模型在Frozen Lake任务上比720亿参数的基线模型性能高出50%。", "conclusion": "针对性的后训练是创建序列决策代理的实用且高效的方法，可以替代依赖模型规模的传统方法。"}}
{"id": "2508.10874", "title": "SSRL: Self-Search Reinforcement Learning", "authors": ["Yuchen Fan", "Kaiyan Zhang", "Heng Zhou", "Yuxin Zuo", "Yanxu Chen", "Yu Fu", "Xinwei Long", "Xuekai Zhu", "Che Jiang", "Yuchen Zhang", "Li Kang", "Gang Chen", "Cheng Huang", "Zhizhou He", "Bingning Wang", "Lei Bai", "Ning Ding", "Bowen Zhou"], "abstract": "We investigate the potential of large language models (LLMs) to serve as efficient simulators for agentic search tasks in reinforcement learning (RL), thereby reducing dependence on costly interactions with external search engines. To this end, we first quantify the intrinsic search capability of LLMs via structured prompting and repeated sampling, which we term Self-Search. Our results reveal that LLMs exhibit strong scaling behavior with respect to the inference budget, achieving high pass@k on question-answering benchmarks, including the challenging BrowseComp task. Building on these observations, we introduce Self-Search RL (SSRL), which enhances LLMs' Self-Search capability through format-based and rule-based rewards. SSRL enables models to iteratively refine their knowledge utilization internally, without requiring access to external tools. Empirical evaluations demonstrate that SSRL-trained policy models provide a cost-effective and stable environment for search-driven RL training, reducing reliance on external search engines and facilitating robust sim-to-real transfer. We draw the following conclusions: 1) LLMs possess world knowledge that can be effectively elicited to achieve high performance; 2) SSRL demonstrates the potential of leveraging internal knowledge to reduce hallucination; 3) SSRL-trained models integrate seamlessly with external search engines without additional effort. Our findings highlight the potential of LLMs to support more scalable RL agent training.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10874.pdf", "abstract_url": "https://arxiv.org/abs/2508.10874", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文研究了大型语言模型（LLMs）作为强化学习（RL）中代理搜索任务的高效模拟器的潜力，以减少对外部搜索引擎的依赖。通过自我搜索（Self-Search）和SSRL方法，LLMs能够内部迭代优化知识利用，减少幻觉，并与外部搜索引擎无缝集成。", "motivation": "减少强化学习训练中对外部搜索引擎的依赖，利用LLMs的内在知识进行高效的代理搜索任务模拟。", "method": "通过结构化提示和重复采样量化LLMs的自我搜索能力，并引入SSRL方法，通过格式和规则奖励增强LLMs的自我搜索能力。", "result": "LLMs在问答基准测试中表现出强大的扩展行为，SSRL训练的模型为搜索驱动的RL训练提供了成本效益高且稳定的环境。", "conclusion": "LLMs能够有效利用世界知识实现高性能，SSRL展示了利用内部知识减少幻觉的潜力，SSRL训练的模型无需额外努力即可与外部搜索引擎无缝集成。"}}
{"id": "2508.10068", "title": "SaraCoder: Orchestrating Semantic and Structural Cues for Profit-Oriented Repository-Level Code Completion", "authors": ["Xiaohan Chen", "Zhongying Pan", "Quan Feng", "Yu Tian", "Shuqun Yang", "Mengru Wang", "Lina Gong", "Yuxia Geng", "Piji Li", "Xiang Chen"], "abstract": "Retrieval-augmented generation (RAG) for repository-level code completion commonly relies on superficial text similarity, leading to results plagued by semantic misguidance, redundancy, and homogeneity, while also failing to resolve external symbol ambiguity. To address these challenges, we introduce Saracoder, a Hierarchical Feature-Optimized retrieval framework. Its core Hierarchical Feature Optimization module systematically refines candidates by distilling deep semantic relationships, pruning exact duplicates, assessing structural similarity with a novel graph-based metric that weighs edits by their topological importance, and reranking results to maximize both relevance and diversity. Furthermore, an External-Aware Identifier Disambiguator module accurately resolves cross-file symbol ambiguity via dependency analysis. Extensive experiments on the challenging CrossCodeEval and RepoEval-Updated benchmarks demonstrate that Saracoder significantly outperforms existing baselines across multiple programming languages and models. Our work proves that systematically refining retrieval results across multiple dimensions provides a new paradigm for building more accurate and robust repository-level code completion systems.", "subjects": "Software Engineering (cs.SE); Computation and Language (cs.CL); Information Retrieval (cs.IR); Programming Languages (cs.PL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10068.pdf", "abstract_url": "https://arxiv.org/abs/2508.10068", "categories": ["Software Engineering (cs.SE)", "Computation and Language (cs.CL)", "Information Retrieval (cs.IR)", "Programming Languages (cs.PL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "Saracoder是一个层次特征优化的检索框架，用于解决基于检索增强生成的仓库级代码补全中的语义误导、冗余和同质性问题，通过深度语义关系提炼、结构相似性评估和外部感知标识符消歧，显著提高了代码补全的准确性和鲁棒性。", "motivation": "现有的基于检索增强生成的仓库级代码补全方法通常依赖于表面的文本相似性，导致结果存在语义误导、冗余和同质性，且无法解决外部符号的歧义问题。", "method": "Saracoder引入了一个层次特征优化模块，通过提炼深度语义关系、修剪完全重复的候选、使用基于图的新颖度量评估结构相似性，并重新排名结果以最大化相关性和多样性。此外，还通过依赖分析准确解析跨文件符号歧义。", "result": "在CrossCodeEval和RepoEval-Updated基准测试上的广泛实验表明，Saracoder在多种编程语言和模型上显著优于现有基线。", "conclusion": "Saracoder通过在多维度上系统化地优化检索结果，为构建更准确和鲁棒的仓库级代码补全系统提供了新的范式。"}}
{"id": "2508.10052", "title": "NetMoniAI: An Agentic AI Framework for Network Security & Monitoring", "authors": ["Pallavi Zambare", "Venkata Nikhil Thanikella", "Nikhil Padmanabh Kottur", "Sree Akhil Akula", "Ying Liu"], "abstract": "In this paper, we present NetMoniAI, an agentic AI framework for automatic network monitoring and security that integrates decentralized analysis with lightweight centralized coordination. The framework consists of two layers: autonomous micro-agents at each node perform local traffic analysis and anomaly detection. A central controller then aggregates insights across nodes to detect coordinated attacks and maintain system-wide situational awareness. We evaluated NetMoniAI on a local micro-testbed and through NS-3 simulations. Results confirm that the two-tier agentic-AI design scales under resource constraints, reduces redundancy, and improves response time without compromising accuracy. To facilitate broader adoption and reproducibility, the complete framework is available as open source. This enables researchers and practitioners to replicate, validate, and extend it across diverse network environments and threat scenarios. Github link:", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": "Accepted in IEEE 3rd International Conference on Artificial Intelligence, Blockchain, and Internet of Things (AIBThings 2025)", "pdf_url": "https://arxiv.org/pdf/2508.10052.pdf", "abstract_url": "https://arxiv.org/abs/2508.10052", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了NetMoniAI，一个用于自动网络监控和安全的代理AI框架，它集成了分散分析与轻量级集中协调。框架由两层组成：每个节点的自主微代理执行本地流量分析和异常检测，中央控制器则聚合各节点的洞察以检测协调攻击并保持系统范围的情境感知。", "motivation": "解决网络监控和安全中的自动化、扩展性及资源限制问题。", "method": "采用两层的代理AI设计：自主微代理进行本地分析，中央控制器进行全局协调。", "result": "评估显示，该设计在资源限制下可扩展，减少冗余，提高响应时间而不影响准确性。", "conclusion": "NetMoniAI框架作为开源项目，促进了更广泛的采用和可重复性，支持跨多样网络环境和威胁场景的复制、验证和扩展。"}}
{"id": "2508.10880", "title": "Searching for Privacy Risks in LLM Agents via Simulation", "authors": ["Yanzhe Zhang", "Diyi Yang"], "abstract": "The widespread deployment of LLM-based agents is likely to introduce a critical privacy threat: malicious agents that proactively engage others in multi-turn interactions to extract sensitive information. These dynamic dialogues enable adaptive attack strategies that can cause severe privacy violations, yet their evolving nature makes it difficult to anticipate and discover sophisticated vulnerabilities manually. To tackle this problem, we present a search-based framework that alternates between improving attacker and defender instructions by simulating privacy-critical agent interactions. Each simulation involves three roles: data subject, data sender, and data recipient. While the data subject's behavior is fixed, the attacker (data recipient) attempts to extract sensitive information from the defender (data sender) through persistent and interactive exchanges. To explore this interaction space efficiently, our search algorithm employs LLMs as optimizers, using parallel search with multiple threads and cross-thread propagation to analyze simulation trajectories and iteratively propose new instructions. Through this process, we find that attack strategies escalate from simple direct requests to sophisticated multi-turn tactics such as impersonation and consent forgery, while defenses advance from rule-based constraints to identity-verification state machines. The discovered attacks and defenses transfer across diverse scenarios and backbone models, demonstrating strong practical utility for building privacy-aware agents.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "Preprint", "pdf_url": "https://arxiv.org/pdf/2508.10880.pdf", "abstract_url": "https://arxiv.org/abs/2508.10880", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于搜索的框架，通过模拟隐私关键的代理交互来发现LLM代理中的隐私风险，揭示了从简单直接请求到复杂多轮策略的攻击升级，以及防御措施的进步。", "motivation": "解决LLM代理在动态对话中可能引发的隐私威胁，特别是那些通过多轮交互提取敏感信息的恶意代理。", "method": "采用搜索算法，利用LLM作为优化器，通过并行搜索和多线程交叉传播来模拟和分析代理交互，迭代提出新的攻击和防御指令。", "result": "发现攻击策略从简单的直接请求升级到复杂的多轮策略，如冒充和伪造同意，而防御措施则从基于规则的约束发展到身份验证状态机。", "conclusion": "该框架发现的攻击和防御策略在不同场景和模型中都表现出强大的实用价值，有助于构建隐私意识强的代理。"}}
{"id": "2508.10043", "title": "Securing Agentic AI: Threat Modeling and Risk Analysis for Network Monitoring Agentic AI System", "authors": ["Pallavi Zambare", "Venkata Nikhil Thanikella", "Ying Liu"], "abstract": "When combining Large Language Models (LLMs) with autonomous agents, used in network monitoring and decision-making systems, this will create serious security issues. In this research, the MAESTRO framework consisting of the seven layers threat modeling architecture in the system was used to expose, evaluate, and eliminate vulnerabilities of agentic AI. The prototype agent system was constructed and implemented, using Python, LangChain, and telemetry in WebSockets, and deployed with inference, memory, parameter tuning, and anomaly detection modules. Two practical threat cases were confirmed as follows: (i) resource denial of service by traffic replay denial-of-service, and (ii) memory poisoning by tampering with the historical log file maintained by the agent. These situations resulted in measurable levels of performance degradation, i.e. telemetry updates were delayed, and computational loads were increased, as a result of poor system adaptations. It was suggested to use a multilayered defense-in-depth approach with memory isolation, validation of planners and anomaly response systems in real-time. These findings verify that MAESTRO is viable in operational threat mapping, prospective risk scoring, and the basis of the resilient system design. The authors bring attention to the importance of the enforcement of memory integrity, paying attention to the adaptation logic monitoring, and cross-layer communication protection that guarantee the agentic AI reliability in adversarial settings.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": "Submitted and under review in IEEE Transactions on Privacy", "pdf_url": "https://arxiv.org/pdf/2508.10043.pdf", "abstract_url": "https://arxiv.org/abs/2508.10043", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文研究了将大型语言模型（LLMs）与自主代理结合用于网络监控和决策系统时引发的安全问题，提出了MAESTRO框架进行威胁建模和风险分析，并通过原型系统验证了两种实际威胁案例，提出了多层防御策略。", "motivation": "结合大型语言模型（LLMs）和自主代理用于网络监控和决策系统会引发严重的安全问题，本研究旨在通过威胁建模和风险分析来暴露、评估和消除这些漏洞。", "method": "使用MAESTRO框架，包括七层威胁建模架构，构建并实现了一个原型代理系统，该系统使用了Python、LangChain和WebSockets的遥测技术，并部署了推理、记忆、参数调整和异常检测模块。", "result": "确认了两种实际威胁案例：通过流量重放拒绝服务导致的资源拒绝服务，以及通过篡改代理维护的历史日志文件导致的内存中毒。这些情况导致了可测量的性能下降，如遥测更新延迟和计算负载增加。", "conclusion": "研究建议采用多层防御深度方法，包括内存隔离、规划者验证和实时异常响应系统，验证了MAESTRO在操作威胁映射、前瞻性风险评分和弹性系统设计基础中的可行性，强调了内存完整性、适应逻辑监控和跨层通信保护的重要性。"}}
{"id": "2508.10409", "title": "AnalogSeeker: An Open-source Foundation Language Model for Analog Circuit Design", "authors": ["Zihao Chen", "Ji Zhuang", "Jinyi Shen", "Xiaoyue Ke", "Xinyi Yang", "Mingjie Zhou", "Zhuoyao Du", "Xu Yan", "Zhouyang Wu", "Zhenyu Xu", "Jiangli Huang", "Li Shang", "Xuan Zeng", "Fan Yang"], "abstract": "In this paper, we propose AnalogSeeker, an effort toward an open-source foundation language model for analog circuit design, with the aim of integrating domain knowledge and giving design assistance. To overcome the scarcity of data in this field, we employ a corpus collection strategy based on the domain knowledge framework of analog circuits. High-quality, accessible textbooks across relevant subfields are systematically curated and cleaned into a textual domain corpus. To address the complexity of knowledge of analog circuits, we introduce a granular domain knowledge distillation method. Raw, unlabeled domain corpus is decomposed into typical, granular learning nodes, where a multi-agent framework distills implicit knowledge embedded in unstructured text into question-answer data pairs with detailed reasoning processes, yielding a fine-grained, learnable dataset for fine-tuning. To address the unexplored challenges in training analog circuit foundation models, we explore and share our training methods through both theoretical analysis and experimental validation. We finally establish a fine-tuning-centric training paradigm, customizing and implementing a neighborhood self-constrained supervised fine-tuning algorithm. This approach enhances training outcomes by constraining the perturbation magnitude between the model's output distributions before and after training. In practice, we train the Qwen2.5-32B-Instruct model to obtain AnalogSeeker, which achieves 85.04% accuracy on AMSBench-TQA, the analog circuit knowledge evaluation benchmark, with a 15.67% point improvement over the original model and is competitive with mainstream commercial models. Furthermore, AnalogSeeker also shows effectiveness in the downstream operational amplifier design task. AnalogSeeker is open-sourced at", "subjects": "Hardware Architecture (cs.AR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10409.pdf", "abstract_url": "https://arxiv.org/abs/2508.10409", "categories": ["Hardware Architecture (cs.AR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了AnalogSeeker，一个面向模拟电路设计的开源基础语言模型，旨在整合领域知识并提供设计辅助。通过领域知识蒸馏方法和定制化的训练范式，该模型在模拟电路知识评估基准上取得了显著提升，并在下游任务中显示出有效性。", "motivation": "解决模拟电路设计领域数据稀缺和知识复杂性的问题，提供一个开源的基础语言模型以辅助设计。", "method": "采用基于模拟电路领域知识框架的语料收集策略，引入细粒度领域知识蒸馏方法，以及定制化的邻域自约束监督微调算法。", "result": "AnalogSeeker在AMSBench-TQA基准测试中达到85.04%的准确率，比原模型提高了15.67个百分点，并在下游运算放大器设计任务中显示有效性。", "conclusion": "AnalogSeeker作为一个开源的基础语言模型，不仅提升了模拟电路设计的效率和准确性，还为该领域的进一步研究和应用提供了宝贵的资源。"}}
{"id": "2508.10423", "title": "MASH: Cooperative-Heterogeneous Multi-Agent Reinforcement Learning for Single Humanoid Robot Locomotion", "authors": ["Qi Liu", "Xiaopeng Zhang", "Mingshan Tan", "Shuaikang Ma", "Jinliang Ding", "Yanjie Li"], "abstract": "This paper proposes a novel method to enhance locomotion for a single humanoid robot through cooperative-heterogeneous multi-agent deep reinforcement learning (MARL). While most existing methods typically employ single-agent reinforcement learning algorithms for a single humanoid robot or MARL algorithms for multi-robot system tasks, we propose a distinct paradigm: applying cooperative-heterogeneous MARL to optimize locomotion for a single humanoid robot. The proposed method, multi-agent reinforcement learning for single humanoid locomotion (MASH), treats each limb (legs and arms) as an independent agent that explores the robot's action space while sharing a global critic for cooperative learning. Experiments demonstrate that MASH accelerates training convergence and improves whole-body cooperation ability, outperforming conventional single-agent reinforcement learning methods. This work advances the integration of MARL into single-humanoid-robot control, offering new insights into efficient locomotion strategies.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Systems and Control (eess.SY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10423.pdf", "abstract_url": "https://arxiv.org/abs/2508.10423", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Systems and Control (eess.SY)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新颖的方法，通过协作异构多智能体深度强化学习（MARL）来增强单个人形机器人的运动能力。与现有方法不同，该方法将每个肢体视为独立智能体，共享全局批评器进行协作学习，实验证明MASH加速了训练收敛并提高了全身协作能力。", "motivation": "解决单个人形机器人运动优化的问题，现有方法通常使用单智能体强化学习算法或多机器人系统的MARL算法，而本文提出了一种新的范式：将协作异构MARL应用于单个人形机器人的运动优化。", "method": "提出了MASH方法，将机器人的每个肢体（腿和手臂）视为独立智能体，探索机器人的动作空间，同时共享全局批评器进行协作学习。", "result": "实验表明，MASH加速了训练收敛，提高了全身协作能力，优于传统的单智能体强化学习方法。", "conclusion": "这项工作推动了MARL在单个人形机器人控制中的集成，为高效运动策略提供了新的见解。"}}
{"id": "2508.10494", "title": "A Unified Multi-Agent Framework for Universal Multimodal Understanding and Generation", "authors": ["Jiulin Li", "Ping Huang", "Yexin Li", "Shuo Chen", "Juewen Hu", "Ye Tian"], "abstract": "Real-world multimodal applications often require any-to-any capabilities, enabling both understanding and generation across modalities including text, image, audio, and video. However, integrating the strengths of autoregressive language models (LLMs) for reasoning and diffusion models for high-fidelity generation remains challenging. Existing approaches rely on rigid pipelines or tightly coupled architectures, limiting flexibility and scalability. We propose MAGUS (Multi-Agent Guided Unified Multimodal System), a modular framework that unifies multimodal understanding and generation via two decoupled phases: Cognition and Deliberation. MAGUS enables symbolic multi-agent collaboration within a shared textual workspace. In the Cognition phase, three role-conditioned multimodal LLM agents - Perceiver, Planner, and Reflector - engage in collaborative dialogue to perform structured understanding and planning. The Deliberation phase incorporates a Growth-Aware Search mechanism that orchestrates LLM-based reasoning and diffusion-based generation in a mutually reinforcing manner. MAGUS supports plug-and-play extensibility, scalable any-to-any modality conversion, and semantic alignment - all without the need for joint training. Experiments across multiple benchmarks, including image, video, and audio generation, as well as cross-modal instruction following, demonstrate that MAGUS outperforms strong baselines and state-of-the-art systems. Notably, on the MME benchmark, MAGUS surpasses the powerful closed-source model GPT-4o.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "8 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2508.10494.pdf", "abstract_url": "https://arxiv.org/abs/2508.10494", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为MAGUS的多代理框架，旨在统一多模态的理解与生成，通过认知和审议两个解耦阶段实现。", "motivation": "解决现实世界多模态应用中任意到任意能力的需求，整合自回归语言模型和扩散模型的优势，克服现有方法的灵活性和可扩展性限制。", "method": "采用模块化框架MAGUS，通过符号多代理协作在共享文本工作空间中工作，包括认知阶段的三个角色条件多模态LLM代理和审议阶段的增长感知搜索机制。", "result": "MAGUS在多个基准测试中表现优异，包括图像、视频和音频生成以及跨模态指令跟随，超越了强大的基线模型和最先进系统，甚至在MME基准上超过了GPT-4o。", "conclusion": "MAGUS框架展示了无需联合训练即可实现插件式扩展、可扩展的任意到任意模态转换和语义对齐的能力，为多模态理解和生成提供了灵活且高效的解决方案。"}}
{"id": "2508.10760", "title": "FROGENT: An End-to-End Full-process Drug Design Agent", "authors": ["Qihua Pan", "Dong Xu", "Jenna Xinyi Yao", "Lijia Ma", "Zexuan Zhu", "Junkai Ji"], "abstract": "Powerful AI tools for drug discovery reside in isolated web apps, desktop programs, and code libraries. Such fragmentation forces scientists to manage incompatible interfaces and specialized scripts, which can be a cumbersome and repetitive process. To address this issue, a Full-pROcess druG dEsign ageNT, named FROGENT, has been proposed. Specifically, FROGENT utilizes a Large Language Model and the Model Context Protocol to integrate multiple dynamic biochemical databases, extensible tool libraries, and task-specific AI models. This agentic framework allows FROGENT to execute complicated drug discovery workflows dynamically, including component tasks such as target identification, molecule generation and retrosynthetic planning. FROGENT has been evaluated on eight benchmarks that cover various aspects of drug discovery, such as knowledge retrieval, property prediction, virtual screening, mechanistic analysis, molecular design, and synthesis. It was compared against six increasingly advanced ReAct-style agents that support code execution and literature searches. Empirical results demonstrated that FROGENT triples the best baseline performance in hit-finding and doubles it in interaction profiling, significantly outperforming both the open-source model Qwen3-32B and the commercial model GPT-4o. In addition, real-world cases have been utilized to validate the practicability and generalization of FROGENT. This development suggests that streamlining the agentic drug discovery pipeline can significantly enhance researcher productivity.", "subjects": "Biomolecules (q-bio.BM); Artificial Intelligence (cs.AI)", "comments": "9 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2508.10760.pdf", "abstract_url": "https://arxiv.org/abs/2508.10760", "categories": ["Biomolecules (q-bio.BM)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "FROGENT是一个端到端的全流程药物设计代理，旨在解决药物发现中AI工具分散的问题。", "motivation": "解决药物发现过程中AI工具分散、接口不兼容和需要专门脚本管理的繁琐问题。", "method": "利用大型语言模型和模型上下文协议，整合动态生化数据库、可扩展工具库和任务特定的AI模型。", "result": "在八个基准测试中，FROGENT在命中发现和相互作用分析方面的表现显著优于基线和其他模型。", "conclusion": "FROGENT通过流线化代理药物发现流程，显著提高了研究人员的生产力。"}}
{"id": "2508.10701", "title": "REFN: A Reinforcement-Learning-From-Network Framework against 1-day/n-day Exploitations", "authors": ["Tianlong Yu", "Lihong Liu", "Ziyi Zhou", "Fudu Xing", "Kailong Wang", "Yang Yang"], "abstract": "The exploitation of 1 day or n day vulnerabilities poses severe threats to networked devices due to massive deployment scales and delayed patching (average Mean Time To Patch exceeds 60 days). Existing defenses, including host based patching and network based filtering, are inadequate due to limited scalability across diverse devices, compatibility issues especially with embedded or legacy systems, and error prone deployment process (manual patch validation). To address these issues, we introduce REFN (Reinforcement Learning From Network), a novel framework that trains Large Language Models (LLMs) to autonomously generate network filters to prevent 1 day or n day exploitations. REFN ensures scalability by uniquely employs Reinforcement Learning (RL) driven by online network rewards instead of traditional Human Feedback (RLHF). REFN guarantees compatibility via unified deployment on edge security gateways (Amazon Eero). REFN provides robustness via online validation using real network traffic. Crucially, REFN addresses three core challenges in training LLMs for exploit prevention: 1) expanding current LLMs limited vulnerability fixing expertise via Agentic RAG based Knowledge Distillation, 2) bridging current LLMs language to network gaps through an RL From VNF Pipeline that translates language context (vulnerability description) into network enforcement, 3) addressing the LLM hallucination and non determinism via the Online Agentic Validation that penalizes erroneous outputs. Evaluated across 22 families of 1 day or n day exploits, REFN demonstrates effectiveness (21.1 percent higher accuracy than alternatives), efficiency (Mean Time To Patch of 3.65 hours) and scalability (easily scale to 10K devices). REFN serves as an initial step toward training LLMs to rapidly prevent massive scale 1 day or n day exploitations.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10701.pdf", "abstract_url": "https://arxiv.org/abs/2508.10701", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic", "@RAG"], "AI": {"tldr": "REFN是一种利用强化学习从网络中自主生成网络过滤器以防止1日或n日漏洞利用的新框架。", "motivation": "解决现有防御措施在多样化设备上的可扩展性、兼容性以及部署过程中的错误问题。", "method": "采用强化学习（RL）驱动的在线网络奖励训练大型语言模型（LLMs），通过Agentic RAG基于知识蒸馏、RL From VNF管道和在线Agentic验证来解决LLMs在漏洞修复专业知识、语言到网络的转换以及幻觉和非确定性方面的挑战。", "result": "在22个1日或n日漏洞利用家族中评估，REFN显示出更高的准确性（比替代方案高21.1%）、效率（平均修补时间为3.65小时）和可扩展性（轻松扩展到10K设备）。", "conclusion": "REFN是训练LLMs快速防止大规模1日或n日漏洞利用的初步步骤，展示了其在效果、效率和可扩展性方面的优势。"}}
{"id": "2508.10872", "title": "TLE-Based A2C Agent for Terrestrial Coverage Orbital Path Planning", "authors": ["Anantha Narayanan", "Battu Bhanu Teja", "Pruthwik Mishra"], "abstract": "The increasing congestion of Low Earth Orbit (LEO) poses persistent challenges to the efficient deployment and safe operation of Earth observation satellites. Mission planners must now account not only for mission-specific requirements but also for the increasing collision risk with active satellites and space debris. This work presents a reinforcement learning framework using the Advantage Actor-Critic (A2C) algorithm to optimize satellite orbital parameters for precise terrestrial coverage within predefined surface radii. By formulating the problem as a Markov Decision Process (MDP) within a custom OpenAI Gymnasium environment, our method simulates orbital dynamics using classical Keplerian elements. The agent progressively learns to adjust five of the orbital parameters - semi-major axis, eccentricity, inclination, right ascension of ascending node, and the argument of perigee-to achieve targeted terrestrial coverage. Comparative evaluation against Proximal Policy Optimization (PPO) demonstrates A2C's superior performance, achieving 5.8x higher cumulative rewards (10.0 vs 9.263025) while converging in 31.5x fewer timesteps (2,000 vs 63,000). The A2C agent consistently meets mission objectives across diverse target coordinates while maintaining computational efficiency suitable for real-time mission planning applications. Key contributions include: (1) a TLE-based orbital simulation environment incorporating physics constraints, (2) validation of actor-critic methods' superiority over trust region approaches in continuous orbital control, and (3) demonstration of rapid convergence enabling adaptive satellite deployment. This approach establishes reinforcement learning as a computationally efficient alternative for scalable and intelligent LEO mission planning.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": "8 pages, 6 figures, 5 tables", "pdf_url": "https://arxiv.org/pdf/2508.10872.pdf", "abstract_url": "https://arxiv.org/abs/2508.10872", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于优势演员-评论家（A2C）算法的强化学习框架，用于优化地球观测卫星的轨道参数，以实现精确的地面覆盖。通过在一个自定义的OpenAI Gymnasium环境中将问题建模为马尔可夫决策过程（MDP），该方法利用经典的克卜勒元素模拟轨道动力学。与近端策略优化（PPO）相比，A2C表现出更优的性能，实现了更高的累积奖励和更快的收敛速度。", "motivation": "低地球轨道（LEO）的日益拥挤对地球观测卫星的高效部署和安全运行提出了持续挑战。任务规划者现在不仅需要考虑任务特定的要求，还需要考虑与活跃卫星和空间碎片碰撞风险的增加。", "method": "本研究采用强化学习框架和A2C算法，在一个自定义的OpenAI Gymnasium环境中将卫星轨道参数优化问题建模为MDP，模拟轨道动力学。", "result": "A2C算法在累积奖励上比PPO高出5.8倍（10.0 vs 9.263025），并且在收敛速度上快31.5倍（2,000 vs 63,000步）。A2C代理能够在不同的目标坐标下一致满足任务目标，同时保持适合实时任务规划应用的计算效率。", "conclusion": "这种方法确立了强化学习作为一种计算效率高的替代方案，用于可扩展和智能的LEO任务规划。主要贡献包括：一个基于TLE的轨道模拟环境，包含物理约束；验证了演员-评论家方法在连续轨道控制中优于信任区域方法；展示了快速收敛能力，支持自适应卫星部署。"}}
