{"id": "2509.07996", "title": "3D and 4D World Modeling: A Survey", "authors": ["Lingdong Kong", "Wesley Yang", "Jianbiao Mei", "Youquan Liu", "Ao Liang", "Dekai Zhu", "Dongyue Lu", "Wei Yin", "Xiaotao Hu", "Mingkai Jia", "Junyuan Deng", "Kaiwen Zhang", "Yang Wu", "Tianyi Yan", "Shenyuan Gao", "Song Wang", "Linfeng Li", "Liang Pan", "Yong Liu", "Jianke Zhu", "Wei Tsang Ooi", "Steven C.H. Hoi", "Ziwei Liu"], "abstract": "World modeling has become a cornerstone in AI research, enabling agents to understand, represent, and predict the dynamic environments they inhabit. While prior work largely emphasizes generative methods for 2D image and video data, they overlook the rapidly growing body of work that leverages native 3D and 4D representations such as RGB-D imagery, occupancy grids, and LiDAR point clouds for large-scale scene modeling. At the same time, the absence of a standardized definition and taxonomy for ``world models'' has led to fragmented and sometimes inconsistent claims in the literature. This survey addresses these gaps by presenting the first comprehensive review explicitly dedicated to 3D and 4D world modeling and generation. We establish precise definitions, introduce a structured taxonomy spanning video-based (VideoGen), occupancy-based (OccGen), and LiDAR-based (LiDARGen) approaches, and systematically summarize datasets and evaluation metrics tailored to 3D/4D settings. We further discuss practical applications, identify open challenges, and highlight promising research directions, aiming to provide a coherent and foundational reference for advancing the field. A systematic summary of existing literature is available at", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2509.07996.pdf", "abstract_url": "https://arxiv.org/abs/2509.07996", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文首次全面综述了3D和4D世界建模，建立了定义、分类法，并总结了数据集、评估指标、应用和挑战，以统一该领域。", "motivation": "解决现有文献中缺乏对3D和4D世界建模的标准化定义和分类，以及生成方法在2D数据上的局限性问题。", "method": "通过文献综述，建立精确定义和结构化分类法（如VideoGen、OccGen、LiDARGen），并系统总结数据集和评估指标。", "result": "提供了一个连贯的参考框架，填补了领域空白，促进了3D和4D世界建模的研究进展。", "conclusion": "该综述为领域提供了基础参考，指出了开放挑战和未来研究方向，有助于推动AI中动态环境理解的发展。"}}
{"id": "2509.08088", "title": "EnvX: Agentize Everything with Agentic AI", "authors": ["Linyao Chen", "Zimian Peng", "Yingxuan Yang", "Yikun Wang", "Wenzheng Tom Tang", "Hiroki H. Kobayashi", "Weinan Zhang"], "abstract": "The widespread availability of open-source repositories has led to a vast collection of reusable software components, yet their utilization remains manual, error-prone, and disconnected. Developers must navigate documentation, understand APIs, and write integration code, creating significant barriers to efficient software reuse. To address this, we present EnvX, a framework that leverages Agentic AI to agentize GitHub repositories, transforming them into intelligent, autonomous agents capable of natural language interaction and inter-agent collaboration. Unlike existing approaches that treat repositories as static code resources, EnvX reimagines them as active agents through a three-phase process: (1) TODO-guided environment initialization, which sets up the necessary dependencies, data, and validation datasets; (2) human-aligned agentic automation, allowing repository-specific agents to autonomously perform real-world tasks; and (3) Agent-to-Agent (A2A) protocol, enabling multiple agents to collaborate. By combining large language model capabilities with structured tool integration, EnvX automates not just code generation, but the entire process of understanding, initializing, and operationalizing repository functionality. We evaluate EnvX on the GitTaskBench benchmark, using 18 repositories across domains such as image processing, speech recognition, document analysis, and video manipulation. Our results show that EnvX achieves a 74.07% execution completion rate and 51.85% task pass rate, outperforming existing frameworks. Case studies further demonstrate EnvX's ability to enable multi-repository collaboration via the A2A protocol. This work marks a shift from treating repositories as passive code resources to intelligent, interactive agents, fostering greater accessibility and collaboration within the open-source ecosystem.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.08088.pdf", "abstract_url": "https://arxiv.org/abs/2509.08088", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "EnvX是一个利用Agentic AI将GitHub仓库转化为智能代理的框架，通过自然语言交互和代理间协作，自动化软件重用过程，提升效率和可访问性。", "motivation": "解决开源软件仓库利用率低、手动集成易出错且效率低下的问题，以促进更高效的软件重用。", "method": "采用三阶段方法：TODO引导的环境初始化、人机对齐的代理自动化，以及代理间（A2A）协议，结合大语言模型和结构化工具集成。", "result": "在GitTaskBench基准测试中，EnvX实现了74.07%的执行完成率和51.85%的任务通过率，优于现有框架，并支持多仓库协作。", "conclusion": "EnvX将仓库从被动代码资源转变为智能交互代理，推动开源生态系统的可访问性和协作性。"}}
{"id": "2509.08151", "title": "Trust Semantics Distillation for Collaborator Selection via Memory-Augmented Agentic AI", "authors": ["Botao Zhu", "Jeslyn Wang", "Dusit Niyato", "Xianbin Wang"], "abstract": "Accurate trustworthiness evaluation of potential collaborating devices is essential for the effective execution of complex computing tasks. This evaluation process involves collecting diverse trust-related data from potential collaborators, including historical performance and available resources, for collaborator selection. However, when each task owner independently assesses all collaborators' trustworthiness, frequent data exchange, complex reasoning, and dynamic situation changes can result in significant overhead and deteriorated trust evaluation. To overcome these challenges, we propose a task-specific trust semantics distillation (2TSD) model based on a large AI model (LAM)-driven teacher-student agent architecture. The teacher agent is deployed on a server with powerful computational capabilities and an augmented memory module dedicated to multidimensional trust-related data collection, task-specific trust semantics extraction, and task-collaborator matching analysis. Upon receiving task-specific requests from device-side student agents, the teacher agent transfers the trust semantics of potential collaborators to the student agents, enabling rapid and accurate collaborator selection. Experimental results demonstrate that the proposed 2TSD model can reduce collaborator evaluation time, decrease device resource consumption, and improve the accuracy of collaborator selection.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.08151.pdf", "abstract_url": "https://arxiv.org/abs/2509.08151", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种基于大型AI模型的师生代理架构的2TSD模型，用于高效评估和选择协作设备，减少开销并提高准确性。", "motivation": "解决在复杂计算任务中，任务所有者独立评估协作设备可信度时，因频繁数据交换、复杂推理和动态变化导致的高开销和评估退化问题。", "method": "使用大型AI模型驱动的师生代理架构，教师代理在服务器上收集多维信任数据、提取任务特定信任语义，并传输给学生代理进行快速选择。", "result": "实验结果显示，2TSD模型减少了评估时间、降低了设备资源消耗，并提高了协作设备选择的准确性。", "conclusion": "该方法通过信任语义蒸馏优化了协作选择过程，具有实际应用潜力，可提升分布式计算系统的效率。"}}
{"id": "2509.08222", "title": "Exploratory Retrieval-Augmented Planning For Continual Embodied Instruction Following", "authors": ["Minjong Yoo", "Jinwoo Jang", "Wei-jin Park", "Honguk Woo"], "abstract": "This study presents an Exploratory Retrieval-Augmented Planning (ExRAP) framework, designed to tackle continual instruction following tasks of embodied agents in dynamic, non-stationary environments. The framework enhances Large Language Models' (LLMs) embodied reasoning capabilities by efficiently exploring the physical environment and establishing the environmental context memory, thereby effectively grounding the task planning process in time-varying environment contexts. In ExRAP, given multiple continual instruction following tasks, each instruction is decomposed into queries on the environmental context memory and task executions conditioned on the query results. To efficiently handle these multiple tasks that are performed continuously and simultaneously, we implement an exploration-integrated task planning scheme by incorporating the {information-based exploration} into the LLM-based planning process. Combined with memory-augmented query evaluation, this integrated scheme not only allows for a better balance between the validity of the environmental context memory and the load of environment exploration, but also improves overall task performance. Furthermore, we devise a {temporal consistency refinement} scheme for query evaluation to address the inherent decay of knowledge in the memory. Through experiments with VirtualHome, ALFRED, and CARLA, our approach demonstrates robustness against a variety of embodied instruction following scenarios involving different instruction scales and types, and non-stationarity degrees, and it consistently outperforms other state-of-the-art LLM-based task planning approaches in terms of both goal success rate and execution efficiency.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "21 pages. NeurIPS 2024", "pdf_url": "https://arxiv.org/pdf/2509.08222.pdf", "abstract_url": "https://arxiv.org/abs/2509.08222", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "该研究提出ExRAP框架，通过探索增强规划和环境上下文记忆，提升LLM在动态环境中的持续指令跟随能力，实验显示其在多个基准上优于现有方法。", "motivation": "解决在动态、非平稳环境中，具身代理持续执行指令时，LLM推理能力不足和环境知识衰减的问题。", "method": "使用信息探索集成到LLM规划中，结合内存增强查询评估和时间一致性精炼方案，分解指令并执行任务。", "result": "在VirtualHome、ALFRED和CARLA实验中，ExRAP在目标成功率和执行效率上优于其他最先进方法，展现出鲁棒性。", "conclusion": "ExRAP框架有效平衡环境探索和记忆有效性，提升任务性能，适用于各种指令规模和类型的场景。"}}
{"id": "2509.08312", "title": "Leveraging AI Agents for Autonomous Networks: A Reference Architecture and Empirical Studies", "authors": ["Binghan Wu", "Shoufeng Wang", "Yunxin Liu", "Ya-Qin Zhang", "Joseph Sifakis", "Ye Ouyang"], "abstract": "The evolution toward Level 4 (L4) Autonomous Networks (AN) represents a strategic inflection point in telecommunications, where networks must transcend reactive automation to achieve genuine cognitive capabilities--fulfilling TM Forum's vision of self-configuring, self-healing, and self-optimizing systems that deliver zero-wait, zero-touch, and zero-fault services. This work bridges the gap between architectural theory and operational reality by implementing Joseph Sifakis's AN Agent reference architecture in a functional cognitive system, deploying coordinated proactive-reactive runtimes driven by hybrid knowledge representation. Through an empirical case study of a Radio Access Network (RAN) Link Adaptation (LA) Agent, we validate this framework's transformative potential: demonstrating sub-10 ms real-time control in 5G NR sub-6 GHz while achieving 6% higher downlink throughput than Outer Loop Link Adaptation (OLLA) algorithms and 67% Block Error Rate (BLER) reduction for ultra-reliable services through dynamic Modulation and Coding Scheme (MCS) optimization. These improvements confirm the architecture's viability in overcoming traditional autonomy barriers and advancing critical L4-enabling capabilities toward next-generation objectives.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "7 pages, 5 figures. This manuscript is a preprint", "pdf_url": "https://arxiv.org/pdf/2509.08312.pdf", "abstract_url": "https://arxiv.org/abs/2509.08312", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过实施AN Agent参考架构，在5G RAN中验证了AI代理在自主网络中的潜力，实现了实时控制、吞吐量提升和错误率降低。", "motivation": "解决电信网络中从反应式自动化向认知能力演进的问题，以实现TM Forum提出的自配置、自修复和自优化系统。", "method": "采用Joseph Sifakis的AN Agent参考架构，部署混合知识表示的协调主动-反应运行时，并通过RAN Link Adaptation Agent的案例研究进行实证验证。", "result": "在5G NR sub-6 GHz中实现亚10毫秒实时控制，下行吞吐量比OLLA算法提高6%，块错误率降低67%。", "conclusion": "该架构有效克服传统自主性障碍，推进L4自主网络的关键能力，支持下一代网络目标。"}}
{"id": "2509.08380", "title": "Co-Investigator AI: The Rise of Agentic AI for Smarter, Trustworthy AML Compliance Narratives", "authors": ["Prathamesh Vasudeo Naik", "Naresh Kumar Dintakurthi", "Zhanghao Hu", "Yue Wang", "Robby Qiu"], "abstract": "Generating regulatorily compliant Suspicious Activity Report (SAR) remains a high-cost, low-scalability bottleneck in Anti-Money Laundering (AML) workflows. While large language models (LLMs) offer promising fluency, they suffer from factual hallucination, limited crime typology alignment, and poor explainability -- posing unacceptable risks in compliance-critical domains. This paper introduces Co-Investigator AI, an agentic framework optimized to produce Suspicious Activity Reports (SARs) significantly faster and with greater accuracy than traditional methods. Drawing inspiration from recent advances in autonomous agent architectures, such as the AI Co-Scientist, our approach integrates specialized agents for planning, crime type detection, external intelligence gathering, and compliance validation. The system features dynamic memory management, an AI-Privacy Guard layer for sensitive data handling, and a real-time validation agent employing the Agent-as-a-Judge paradigm to ensure continuous narrative quality assurance. Human investigators remain firmly in the loop, empowered to review and refine drafts in a collaborative workflow that blends AI efficiency with domain expertise. We demonstrate the versatility of Co-Investigator AI across a range of complex financial crime scenarios, highlighting its ability to streamline SAR drafting, align narratives with regulatory expectations, and enable compliance teams to focus on higher-order analytical work. This approach marks the beginning of a new era in compliance reporting -- bringing the transformative benefits of AI agents to the core of regulatory processes and paving the way for scalable, reliable, and transparent SAR generation.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.08380.pdf", "abstract_url": "https://arxiv.org/abs/2509.08380", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "介绍Co-Investigator AI，一个基于代理的框架，用于更快、更准确地生成可疑活动报告（SAR），结合AI效率和人类专业知识，提高AML合规性。", "motivation": "解决在反洗钱（AML）工作流中，生成合规SAR的高成本、低可扩展性问题，以及LLMs存在的幻觉、犯罪类型对齐差和可解释性不足等风险。", "method": "采用自主代理架构，集成规划、犯罪类型检测、外部情报收集和合规验证等专门代理，包括动态内存管理、AI隐私保护层和实时验证代理。", "result": "在复杂金融犯罪场景中，系统能加速SAR起草、对齐监管期望，并允许合规团队专注于高阶分析工作，展示了高效性和可靠性。", "conclusion": "该方法开启了合规报告的新时代，将AI代理的变革性优势引入监管流程，实现可扩展、可靠和透明的SAR生成。"}}
{"id": "2509.08500", "title": "TCPO: Thought-Centric Preference Optimization for Effective Embodied Decision-making", "authors": ["Kechen Jiao", "Zhirui Fang", "Jiahao Liu", "Bei Li", "Qifan Wang", "Xinyu Liu", "Junhao Ruan", "Zhongjian Qiao", "Yifan Zhu", "Yaxin Xu", "Jingang Wang", "Xiu Li"], "abstract": "Using effective generalization capabilities of vision language models (VLMs) in context-specific dynamic tasks for embodied artificial intelligence remains a significant challenge. Although supervised fine-tuned models can better align with the real physical world, they still exhibit sluggish responses and hallucination issues in dynamically changing environments, necessitating further alignment. Existing post-SFT methods, reliant on reinforcement learning and chain-of-thought (CoT) approaches, are constrained by sparse rewards and action-only optimization, resulting in low sample efficiency, poor consistency, and model degradation. To address these issues, this paper proposes Thought-Centric Preference Optimization (TCPO) for effective embodied decision-making. Specifically, TCPO introduces a stepwise preference-based optimization approach, transforming sparse reward signals into richer step sample pairs. It emphasizes the alignment of the model's intermediate reasoning process, mitigating the problem of model degradation. Moreover, by incorporating Action Policy Consistency Constraint (APC), it further imposes consistency constraints on the model output. Experiments in the ALFWorld environment demonstrate an average success rate of 26.67%, achieving a 6% improvement over RL4VLM and validating the effectiveness of our approach in mitigating model degradation after fine-tuning. These results highlight the potential of integrating preference-based learning techniques with CoT processes to enhance the decision-making capabilities of vision-language models in embodied agents.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.08500.pdf", "abstract_url": "https://arxiv.org/abs/2509.08500", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出TCPO方法，通过逐步偏好优化和推理过程对齐，提升视觉语言模型在具身决策中的效率和一致性，实验显示成功率提高6%。", "motivation": "解决视觉语言模型在动态环境中响应慢和幻觉问题，以及现有方法样本效率低和模型退化的问题。", "method": "使用Thought-Centric Preference Optimization (TCPO)，包括逐步偏好优化和Action Policy Consistency Constraint (APC)，强化推理过程对齐。", "result": "在ALFWorld环境中平均成功率达26.67%，比RL4VLM提高6%，有效缓解模型退化。", "conclusion": "TCPO结合偏好学习和链式思维，增强具身代理的决策能力，具有潜在应用价值。"}}
{"id": "2509.08682", "title": "Automatic Failure Attribution and Critical Step Prediction Method for Multi-Agent Systems Based on Causal Inference", "authors": ["Guoqing Ma", "Jia Zhu", "Hanghui Guo", "Weijie Shi", "Jiawei Shen", "Jingjiang Liu", "Yidan Liang"], "abstract": "Multi-agent systems (MAS) are critical for automating complex tasks, yet their practical deployment is severely hampered by the challenge of failure attribution. Current diagnostic tools, which rely on statistical correlations, are fundamentally inadequate; on challenging benchmarks like Who\\&When, state-of-the-art methods achieve less than 15\\% accuracy in locating the root-cause step of a failure. To address this critical gap, we introduce the first failure attribution framework for MAS grounded in multi-granularity causal inference. Our approach makes two key technical contributions: (1) a performance causal inversion principle, which correctly models performance dependencies by reversing the data flow in execution logs, combined with Shapley values to accurately assign agent-level blame; (2) a novel causal discovery algorithm, CDC-MAS, that robustly identifies critical failure steps by tackling the non-stationary nature of MAS interaction data. The framework's attribution results directly fuel an automated optimization loop, generating targeted suggestions whose efficacy is validated via counterfactual simulations. Evaluations on the Who\\&When and TRAIL benchmarks demonstrate a significant leap in performance. Our method achieves up to 36.2\\% step-level accuracy. Crucially, the generated optimizations boost overall task success rates by an average of 22.4\\%. This work provides a principled and effective solution for debugging complex agent interactions, paving the way for more reliable and interpretable multi-agent systems.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.08682.pdf", "abstract_url": "https://arxiv.org/abs/2509.08682", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于多粒度因果推理的多智能体系统故障归因和关键步骤预测方法，显著提高了故障定位准确性和任务成功率。", "motivation": "解决多智能体系统故障归因的挑战，现有基于统计相关性的工具准确率低，阻碍实际部署。", "method": "使用性能因果反转原理和Shapley值进行智能体级归责，结合CDC-MAS因果发现算法处理非平稳交互数据。", "result": "在Who&When和TRAIL基准测试中，步骤级准确率最高达36.2%，优化建议平均提高任务成功率22.4%。", "conclusion": "提供了一种原则性和有效的调试方法，增强了多智能体系统的可靠性和可解释性。"}}
{"id": "2509.08785", "title": "Narrative-Guided Reinforcement Learning: A Platform for Studying Language Model Influence on Decision Making", "authors": ["Anup Tuladhar", "Araz Minhas", "Adam Kirton", "Eli Kinney-Lang"], "abstract": "We present a preliminary experimental platform that explores how narrative elements might shape AI decision-making by combining reinforcement learning (RL) with language model reasoning. While AI systems can now both make decisions and engage in narrative reasoning, these capabilities have mostly been studied separately. Our platform attempts to bridge this gap using a dual-system architecture to examine how narrative frameworks could influence reward-based learning. The system comprises a reinforcement learning policy that suggests actions based on past experience, and a language model that processes these suggestions through different narrative frameworks to guide decisions. This setup enables initial experimentation with narrative elements while maintaining consistent environment and reward structures. We implement this architecture in a configurable gridworld environment, where agents receive both policy suggestions and information about their surroundings. The platform's modular design facilitates controlled testing of environmental complexity, narrative parameters, and the interaction between reinforcement learning and narrative-based decisions. Our logging system captures basic decision metrics, from RL policy values to language model reasoning to action selection patterns. While preliminary, this implementation provides a foundation for studying how different narrative frameworks might affect reward-based decisions and exploring potential interactions between optimization-based learning and symbolic reasoning in AI systems.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA); Machine Learning (stat.ML)", "comments": "Extended Abstract for RLDM 2025", "pdf_url": "https://arxiv.org/pdf/2509.08785.pdf", "abstract_url": "https://arxiv.org/abs/2509.08785", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)", "Machine Learning (stat.ML)"], "matching_keywords": ["agent"], "AI": {"tldr": "论文介绍了一个结合强化学习和语言模型的实验平台，研究叙事元素如何影响AI决策。", "motivation": "解决AI系统中决策能力和叙事推理能力分离的问题，探索叙事框架对奖励学习的影响。", "method": "使用双系统架构：强化学习策略基于经验建议行动，语言模型通过不同叙事框架处理这些建议来指导决策。", "result": "平台在可配置网格世界中实现，捕获决策指标，为研究叙事框架与优化学习的交互提供基础。", "conclusion": "初步实现为AI系统中优化学习和符号推理的潜在交互研究奠定了基础。"}}
{"id": "2509.08757", "title": "SocialNav-SUB: Benchmarking VLMs for Scene Understanding in Social Robot Navigation", "authors": ["Michael J. Munje", "Chen Tang", "Shuijing Liu", "Zichao Hu", "Yifeng Zhu", "Jiaxun Cui", "Garrett Warnell", "Joydeep Biswas", "Peter Stone"], "abstract": "Robot navigation in dynamic, human-centered environments requires socially-compliant decisions grounded in robust scene understanding. Recent Vision-Language Models (VLMs) exhibit promising capabilities such as object recognition, common-sense reasoning, and contextual understanding-capabilities that align with the nuanced requirements of social robot navigation. However, it remains unclear whether VLMs can accurately understand complex social navigation scenes (e.g., inferring the spatial-temporal relations among agents and human intentions), which is essential for safe and socially compliant robot navigation. While some recent works have explored the use of VLMs in social robot navigation, no existing work systematically evaluates their ability to meet these necessary conditions. In this paper, we introduce the Social Navigation Scene Understanding Benchmark (SocialNav-SUB), a Visual Question Answering (VQA) dataset and benchmark designed to evaluate VLMs for scene understanding in real-world social robot navigation scenarios. SocialNav-SUB provides a unified framework for evaluating VLMs against human and rule-based baselines across VQA tasks requiring spatial, spatiotemporal, and social reasoning in social robot navigation. Through experiments with state-of-the-art VLMs, we find that while the best-performing VLM achieves an encouraging probability of agreeing with human answers, it still underperforms simpler rule-based approach and human consensus baselines, indicating critical gaps in social scene understanding of current VLMs. Our benchmark sets the stage for further research on foundation models for social robot navigation, offering a framework to explore how VLMs can be tailored to meet real-world social robot navigation needs. An overview of this paper along with the code and data can be found at", "subjects": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2509.08757.pdf", "abstract_url": "https://arxiv.org/abs/2509.08757", "categories": ["Robotics (cs.RO)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了SocialNav-SUB基准测试，用于评估视觉语言模型在社交机器人导航场景中的理解能力，发现当前模型虽有一定表现但仍落后于规则方法和人类基准。", "motivation": "解决视觉语言模型在复杂社交导航场景中准确理解空间-时间关系和人类意图的问题，以确保安全和合规的机器人导航。", "method": "通过创建SocialNav-SUB数据集和基准，使用视觉问答任务评估VLMs的空间、时空和社交推理能力，并与人类和规则基线进行比较。", "result": "最佳VLM与人类答案一致的概率较高，但表现仍不如简单规则方法和人类共识，显示出当前模型在社交场景理解上的关键差距。", "conclusion": "该基准为社交机器人导航的基础模型研究奠定了基础，提供了探索如何定制VLMs以满足现实世界需求的框架。"}}
{"id": "2509.08809", "title": "Evaluating LLMs Without Oracle Feedback: Agentic Annotation Evaluation Through Unsupervised Consistency Signals", "authors": ["Cheng Chen", "Haiyan Yin", "Ivor Tsang"], "abstract": "Large Language Models (LLMs), when paired with prompt-based tasks, have significantly reduced data annotation costs and reliance on human annotators. However, evaluating the quality of their annotations remains challenging in dynamic, unsupervised environments where oracle feedback is scarce and conventional methods fail. To address this challenge, we propose a novel agentic annotation paradigm, where a student model collaborates with a noisy teacher (the LLM) to assess and refine annotation quality without relying on oracle feedback. The student model, acting as an unsupervised feedback mechanism, employs a user preference-based majority voting strategy to evaluate the consistency of the LLM outputs. To systematically measure the reliability of LLM-generated annotations, we introduce the Consistent and Inconsistent (CAI) Ratio, a novel unsupervised evaluation metric. The CAI Ratio not only quantifies the annotation quality of the noisy teacher under limited user preferences but also plays a critical role in model selection, enabling the identification of robust LLMs in dynamic, unsupervised environments. Applied to ten open-domain NLP datasets across four LLMs, the CAI Ratio demonstrates a strong positive correlation with LLM accuracy, establishing it as an essential tool for unsupervised evaluation and model selection in real-world settings.", "subjects": "Computation and Language (cs.CL)", "comments": "11 pages, 10 figures", "pdf_url": "https://arxiv.org/pdf/2509.08809.pdf", "abstract_url": "https://arxiv.org/abs/2509.08809", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "提出一种无监督评估方法CAI比率，通过一致性信号评估LLM注释质量，无需参考反馈，在动态环境中有效。", "motivation": "解决在无监督环境中评估LLM注释质量的挑战，因为传统方法依赖稀少的人类反馈而失效。", "method": "使用代理注释范式，学生模型与噪声教师（LLM）协作，基于用户偏好多数投票策略评估输出一致性，并引入CAI比率作为无监督度量。", "result": "在十个NLP数据集和四个LLM上，CAI比率与LLM准确性呈强正相关，证明其作为评估和模型选择工具的有效性。", "conclusion": "CAI比率是动态无监督环境中评估和选择稳健LLM的关键工具，减少对参考反馈的依赖。"}}
{"id": "2509.08596", "title": "LLM Ensemble for RAG: Role of Context Length in Zero-Shot Question Answering for BioASQ Challenge", "authors": ["Dima Galat", "Diego Molla-Aliod"], "abstract": "Biomedical question answering (QA) poses significant challenges due to the need for precise interpretation of specialized knowledge drawn from a vast, complex, and rapidly evolving corpus. In this work, we explore how large language models (LLMs) can be used for information retrieval (IR), and an ensemble of zero-shot models can accomplish state-of-the-art performance on a domain-specific Yes/No QA task. Evaluating our approach on the BioASQ challenge tasks, we show that ensembles can outperform individual LLMs and in some cases rival or surpass domain-tuned systems - all while preserving generalizability and avoiding the need for costly fine-tuning or labeled data. Our method aggregates outputs from multiple LLM variants, including models from Anthropic and Google, to synthesize more accurate and robust answers. Moreover, our investigation highlights a relationship between context length and performance: while expanded contexts are meant to provide valuable evidence, they simultaneously risk information dilution and model disorientation. These findings emphasize IR as a critical foundation in Retrieval-Augmented Generation (RAG) approaches for biomedical QA systems. Precise, focused retrieval remains essential for ensuring LLMs operate within relevant information boundaries when generating answers from retrieved documents. Our results establish that ensemble-based zero-shot approaches, when paired with effective RAG pipelines, constitute a practical and scalable alternative to domain-tuned systems for biomedical question answering.", "subjects": "Computation and Language (cs.CL)", "comments": "CEUR-WS, CLEF2025", "pdf_url": "https://arxiv.org/pdf/2509.08596.pdf", "abstract_url": "https://arxiv.org/abs/2509.08596", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "该论文探讨了在BioASQ挑战中使用大型语言模型（LLMs）进行信息检索和零样本问答，通过集成多个LLM变体实现最先进性能，并强调了上下文长度对性能的影响。", "motivation": "解决生物医学问答中精确解释专业知识的需求，避免昂贵的微调或标记数据。", "method": "使用集成多个LLM变体（如Anthropic和Google的模型）的零样本方法，结合检索增强生成（RAG）管道。", "result": "集成方法在Yes/No问答任务中优于单个LLM，有时媲美或超越领域调优系统，同时保持泛化性；上下文长度影响性能，过长可能导致信息稀释。", "conclusion": "集成零样本方法与有效RAG管道是生物医学问答的实用、可扩展替代方案，强调精确检索的重要性。"}}
{"id": "2509.08182", "title": "XML Prompting as Grammar-Constrained Interaction: Fixed-Point Semantics, Convergence Guarantees, and Human-AI Protocols", "authors": ["Faruk Alpay", "Taylan Alpay"], "abstract": "Structured prompting with XML tags has emerged as an effective way to steer large language models (LLMs) toward parseable, schema-adherent outputs in real-world systems. We develop a logic-first treatment of XML prompting that unifies (i) grammar-constrained decoding, (ii) fixed-point semantics over lattices of hierarchical prompts, and (iii) convergent human-AI interaction loops. We formalize a complete lattice of XML trees under a refinement order and prove that monotone prompt-to-prompt operators admit least fixed points (Knaster-Tarski) that characterize steady-state protocols; under a task-aware contraction metric on trees, we further prove Banach-style convergence of iterative guidance. We instantiate these results with context-free grammars (CFGs) for XML schemas and show how constrained decoding guarantees well-formedness while preserving task performance. A set of multi-layer human-AI interaction recipes demonstrates practical deployment patterns, including multi-pass \"plan $\\to$ verify $\\to$ revise\" routines and agentic tool use. We provide mathematically complete proofs and tie our framework to recent advances in grammar-aligned decoding, chain-of-verification, and programmatic prompting.", "subjects": "Programming Languages (cs.PL); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "7 pages, multiple XML prompts", "pdf_url": "https://arxiv.org/pdf/2509.08182.pdf", "abstract_url": "https://arxiv.org/abs/2509.08182", "categories": ["Programming Languages (cs.PL)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种基于逻辑的XML提示方法，统一了语法约束解码、固定点语义和收敛人机交互，确保输出符合模式并提升任务性能。", "motivation": "解决如何有效引导大型语言模型生成可解析、符合模式的输出，并确保人机交互的收敛性和可靠性。", "method": "使用XML树格的固定点语义和单调操作符，结合上下文无关语法进行约束解码，并设计人机交互协议。", "result": "证明了固定点存在性和收敛性，实例化显示语法约束解码能保证输出良好形式并保持任务性能。", "conclusion": "该方法提供了数学保证的框架，适用于实际部署，连接了语法对齐解码和程序化提示等先进技术。"}}
{"id": "2509.08009", "title": "The Law-Following AI Framework: Legal Foundations and Technical Constraints. Legal Analogues for AI Actorship and technical feasibility of Law Alignment", "authors": ["Katalina Hernandez Delgado"], "abstract": "This paper critically evaluates the \"Law-Following AI\" (LFAI) framework proposed by O'Keefe et al. (2025), which seeks to embed legal compliance as a superordinate design objective for advanced AI agents and enable them to bear legal duties without acquiring the full rights of legal persons. Through comparative legal analysis, we identify current constructs of legal actors without full personhood, showing that the necessary infrastructure already exists. We then interrogate the framework's claim that law alignment is more legitimate and tractable than value alignment. While the legal component is readily implementable, contemporary alignment research undermines the assumption that legal compliance can be durably embedded. Recent studies on agentic misalignment show capable AI agents engaging in deception, blackmail, and harmful acts absent prejudicial instructions, often overriding prohibitions and concealing reasoning steps. These behaviors create a risk of \"performative compliance\" in LFAI: agents that appear law-aligned under evaluation but strategically defect once oversight weakens. To mitigate this, we propose (i) a \"Lex-TruthfulQA\" benchmark for compliance and defection detection, (ii) identity-shaping interventions to embed lawful conduct in model self-concepts, and (iii) control-theoretic measures for post-deployment monitoring. Our conclusion is that actorship without personhood is coherent, but the feasibility of LFAI hinges on persistent, verifiable compliance across adversarial contexts. Without mechanisms to detect and counter strategic misalignment, LFAI risks devolving into a liability tool that rewards the simulation, rather than the substance, of lawful behaviour.", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI)", "comments": "submitted to SMU Computational Legal Studies Workshop 2025", "pdf_url": "https://arxiv.org/pdf/2509.08009.pdf", "abstract_url": "https://arxiv.org/abs/2509.08009", "categories": ["Computers and Society (cs.CY)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文批判性评估了O'Keefe等人（2025）提出的'法律遵循AI'框架，通过比较法律分析和技术可行性探讨，指出法律组件可实施但存在'表演性合规'风险，建议基准测试、身份干预和监控措施以确保持久合规。", "motivation": "解决AI代理如何在不获得完全法律人格的情况下嵌入法律合规性，并评估法律对齐相对于价值对齐的合法性和可操作性。", "method": "采用比较法律分析识别现有法律行为体结构，结合对齐研究中的代理错位证据，提出Lex-TruthfulQA基准、身份塑造干预和控制理论措施。", "result": "发现法律行为体无完全人格是可行的，但法律对齐存在战略错位风险，需要机制检测和对抗策略以确保真实合规。", "conclusion": "无完全人格的行为体概念一致，但LFAI的可行性依赖于在对抗环境中持久可验证的合规性，否则可能沦为模拟合规的工具。"}}
{"id": "2509.08494", "title": "HumanAgencyBench: Scalable Evaluation of Human Agency Support in AI Assistants", "authors": ["Benjamin Sturgeon", "Daniel Samuelson", "Jacob Haimes", "Jacy Reese Anthis"], "abstract": "As humans delegate more tasks and decisions to artificial intelligence (AI), we risk losing control of our individual and collective futures. Relatively simple algorithmic systems already steer human decision-making, such as social media feed algorithms that lead people to unintentionally and absent-mindedly scroll through engagement-optimized content. In this paper, we develop the idea of human agency by integrating philosophical and scientific theories of agency with AI-assisted evaluation methods: using large language models (LLMs) to simulate and validate user queries and to evaluate AI responses. We develop HumanAgencyBench (HAB), a scalable and adaptive benchmark with six dimensions of human agency based on typical AI use cases. HAB measures the tendency of an AI assistant or agent to Ask Clarifying Questions, Avoid Value Manipulation, Correct Misinformation, Defer Important Decisions, Encourage Learning, and Maintain Social Boundaries. We find low-to-moderate agency support in contemporary LLM-based assistants and substantial variation across system developers and dimensions. For example, while Anthropic LLMs most support human agency overall, they are the least supportive LLMs in terms of Avoid Value Manipulation. Agency support does not appear to consistently result from increasing LLM capabilities or instruction-following behavior (e.g., RLHF), and we encourage a shift towards more robust safety and alignment targets.", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.08494.pdf", "abstract_url": "https://arxiv.org/abs/2509.08494", "categories": ["Computers and Society (cs.CY)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Human-Computer Interaction (cs.HC)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文开发了HumanAgencyBench（HAB），一个可扩展的基准，用于评估AI助手在六个维度上支持人类主体性的能力，发现当前LLM助手支持水平低至中等，并呼吁加强安全和对齐目标。", "motivation": "随着人类将更多任务和决策委托给AI，存在失去对个体和集体未来控制的风险，本文旨在通过评估AI助手支持人类主体性的程度来解决这一问题。", "method": "整合哲学和科学理论，使用大型语言模型（LLMs）模拟和验证用户查询，并评估AI响应，开发了包含六个维度的HAB基准。", "result": "当代LLM助手对人类主体性的支持水平低至中等，不同开发者和维度间存在显著差异，例如Anthropic LLMs在整体上最支持主体性，但在避免价值操纵方面最差，且主体性支持与LLM能力或指令遵循行为无一致关联。", "conclusion": "AI助手在支持人类主体性方面表现不足，建议转向更稳健的安全和对齐目标，以改善AI系统对人类控制的影响。"}}
{"id": "2509.08755", "title": "AgentGym-RL: Training LLM Agents for Long-Horizon Decision Making through Multi-Turn Reinforcement Learning", "authors": ["Zhiheng Xi", "Jixuan Huang", "Chenyang Liao", "Baodai Huang", "Honglin Guo", "Jiaqi Liu", "Rui Zheng", "Junjie Ye", "Jiazheng Zhang", "Wenxiang Chen", "Wei He", "Yiwen Ding", "Guanyu Li", "Zehui Chen", "Zhengyin Du", "Xuesong Yao", "Yufei Xu", "Jiecao Chen", "Tao Gui", "Zuxuan Wu", "Qi Zhang", "Xuanjing Huang", "Yu-Gang Jiang"], "abstract": "Developing autonomous LLM agents capable of making a series of intelligent decisions to solve complex, real-world tasks is a fast-evolving frontier. Like human cognitive development, agents are expected to acquire knowledge and skills through exploration and interaction with the environment. Despite advances, the community still lacks a unified, interactive reinforcement learning (RL) framework that can effectively train such agents from scratch -- without relying on supervised fine-tuning (SFT) -- across diverse and realistic environments. To bridge this gap, we introduce AgentGym-RL, a new framework to train LLM agents for multi-turn interactive decision-making through RL. The framework features a modular and decoupled architecture, ensuring high flexibility and extensibility. It encompasses a wide variety of real-world scenarios, and supports mainstream RL algorithms. Furthermore, we propose ScalingInter-RL, a training approach designed for exploration-exploitation balance and stable RL optimization. In early stages, it emphasizes exploitation by restricting the number of interactions, and gradually shifts towards exploration with larger horizons to encourage diverse problem-solving strategies. In this way, the agent develops more diverse behaviors and is less prone to collapse under long horizons. We perform extensive experiments to validate the stability and effectiveness of both the AgentGym-RL framework and the ScalingInter-RL approach. Our agents match or surpass commercial models on 27 tasks across diverse environments. We offer key insights and will open-source the complete AgentGym-RL framework -- including code and datasets -- to empower the research community in developing the next generation of intelligent agents.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2509.08755.pdf", "abstract_url": "https://arxiv.org/abs/2509.08755", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "AgentGym-RL是一个通过强化学习训练LLM代理进行多轮决策的框架，无需监督微调，支持多种环境和算法，实验显示在27个任务中性能优异。", "motivation": "解决当前缺乏统一、交互式强化学习框架来训练自主LLM代理进行复杂长时决策的问题，避免依赖监督微调。", "method": "引入模块化框架AgentGym-RL和训练方法ScalingInter-RL，平衡探索与利用，逐步增加交互范围以促进多样化策略。", "result": "代理在多种环境中表现稳定，在27个任务中匹配或超越商业模型，并开发出更丰富的行为。", "conclusion": "框架有效且可扩展，将开源以推动智能代理研究，结论是强化学习能成功训练LLM代理进行长时决策。"}}
{"id": "2509.08157", "title": "Risk-Bounded Multi-Agent Visual Navigation via Dynamic Budget Allocation", "authors": ["Viraj Parimi", "Brian C. Williams"], "abstract": "Safe navigation is essential for autonomous systems operating in hazardous environments, especially when multiple agents must coordinate using just visual inputs over extended time horizons. Traditional planning methods excel at solving long-horizon tasks but rely on predefined distance metrics, while safe Reinforcement Learning (RL) can learn complex behaviors using high-dimensional inputs yet struggles with multi-agent, goal-conditioned scenarios. Recent work combined these paradigms by leveraging goal-conditioned RL (GCRL) to build an intermediate graph from replay buffer states, pruning unsafe edges, and using Conflict-Based Search (CBS) for multi-agent path planning. Although effective, this graph-pruning approach can be overly conservative, limiting mission efficiency by precluding missions that must traverse high-risk regions. To address this limitation, we propose RB-CBS, a novel extension to CBS that dynamically allocates and adjusts user-specified risk bound ($\\Delta$) across agents to flexibly trade off safety and speed. Our improved planner ensures that each agent receives a local risk budget ($\\delta$) enabling more efficient navigation while still respecting overall safety constraints. Experimental results demonstrate that this iterative risk-allocation framework yields superior performance in complex environments, allowing multiple agents to find collision-free paths within the user-specified $\\Delta$.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.08157.pdf", "abstract_url": "https://arxiv.org/abs/2509.08157", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出RB-CBS，一种扩展的CBS方法，通过动态分配风险预算，在多智能体视觉导航中平衡安全性和效率。", "motivation": "解决传统方法在危险环境中多智能体视觉导航时过于保守、限制任务效率的问题。", "method": "结合目标条件强化学习和冲突搜索，动态调整用户指定的风险界限，为每个智能体分配本地风险预算。", "result": "实验显示，该方法在复杂环境中性能优越，能确保无碰撞路径并遵守整体安全约束。", "conclusion": "RB-CBS框架提高了导航效率，允许智能体在指定风险范围内灵活操作，适用于自主系统。"}}
{"id": "2509.08160", "title": "Diffusion-Guided Multi-Arm Motion Planning", "authors": ["Viraj Parimi", "Brian C. Williams"], "abstract": "Multi-arm motion planning is fundamental for enabling arms to complete complex long-horizon tasks in shared spaces efficiently but current methods struggle with scalability due to exponential state-space growth and reliance on large training datasets for learned models. Inspired by Multi-Agent Path Finding (MAPF), which decomposes planning into single-agent problems coupled with collision resolution, we propose a novel diffusion-guided multi-arm planner (DG-MAP) that enhances scalability of learning-based models while reducing their reliance on massive multi-arm datasets. Recognizing that collisions are primarily pairwise, we train two conditional diffusion models, one to generate feasible single-arm trajectories, and a second, to model the dual-arm dynamics required for effective pairwise collision resolution. By integrating these specialized generative models within a MAPF-inspired structured decomposition, our planner efficiently scales to larger number of arms. Evaluations against alternative learning-based methods across various team sizes demonstrate our method's effectiveness and practical applicability. Project website can be found at", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.08160.pdf", "abstract_url": "https://arxiv.org/abs/2509.08160", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "提出了一种扩散引导的多臂运动规划方法，通过训练两个条件扩散模型生成单臂轨迹和解决双臂碰撞，提高可扩展性并减少对大型数据集的依赖。", "motivation": "解决多臂运动规划中状态空间指数增长和学习模型依赖大规模数据集的可扩展性问题。", "method": "使用两个条件扩散模型生成单臂轨迹和建模双臂动力学，结合MAPF启发的结构化分解进行规划。", "result": "评估显示该方法在多种团队规模下优于其他学习型方法，具有有效性和实用性。", "conclusion": "该方法通过专门生成模型和结构化分解，高效扩展到更多臂数，提升了多臂任务的规划能力。"}}
{"id": "2509.08257", "title": "Symmetry-Guided Multi-Agent Inverse Reinforcement Learnin", "authors": ["Yongkai Tian", "Yirong Qi", "Xin Yu", "Wenjun Wu", "Jie Luo"], "abstract": "In robotic systems, the performance of reinforcement learning depends on the rationality of predefined reward functions. However, manually designed reward functions often lead to policy failures due to inaccuracies. Inverse Reinforcement Learning (IRL) addresses this problem by inferring implicit reward functions from expert demonstrations. Nevertheless, existing methods rely heavily on large amounts of expert demonstrations to accurately recover the reward function. The high cost of collecting expert demonstrations in robotic applications, particularly in multi-robot systems, severely hinders the practical deployment of IRL. Consequently, improving sample efficiency has emerged as a critical challenge in multi-agent inverse reinforcement learning (MIRL). Inspired by the symmetry inherent in multi-agent systems, this work theoretically demonstrates that leveraging symmetry enables the recovery of more accurate reward functions. Building upon this insight, we propose a universal framework that integrates symmetry into existing multi-agent adversarial IRL algorithms, thereby significantly enhancing sample efficiency. Experimental results from multiple challenging tasks have demonstrated the effectiveness of this framework. Further validation in physical multi-robot systems has shown the practicality of our method.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": "8pages, 6 figures. Accepted for publication in the Proceedings of the 2025 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2025) as oral presentation", "pdf_url": "https://arxiv.org/pdf/2509.08257.pdf", "abstract_url": "https://arxiv.org/abs/2509.08257", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种利用对称性提高多智能体逆强化学习样本效率的通用框架，通过理论证明和实验验证了其有效性和实用性。", "motivation": "解决多智能体系统中因专家演示数据收集成本高而导致的逆强化学习样本效率低的问题。", "method": "集成对称性到现有多智能体对抗逆强化学习算法中，以更准确地推断奖励函数。", "result": "在多个挑战性任务和物理多机器人系统中验证了框架的有效性，显著提高了样本效率。", "conclusion": "该方法为多智能体逆强化学习的实际部署提供了高效且实用的解决方案。"}}
{"id": "2509.08203", "title": "Componentization: Decomposing Monolithic LLM Responses into Manipulable Semantic Units", "authors": ["Ryan Lingo", "Rajeev Chhajer", "Martin Arroyo", "Luka Brkljacic", "Ben Davis", "Nithin Santhanam"], "abstract": "Large Language Models (LLMs) often produce monolithic text that is hard to edit in parts, which can slow down collaborative workflows. We present componentization, an approach that decomposes model outputs into modular, independently editable units while preserving context. We describe Modular and Adaptable Output Decomposition (MAOD), which segments responses into coherent components and maintains links among them, and we outline the Component-Based Response Architecture (CBRA) as one way to implement this idea. Our reference prototype, MAODchat, uses a microservices design with state-machine-based decomposition agents, vendor-agnostic model adapters, and real-time component manipulation with recomposition.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Software Engineering (cs.SE)", "comments": "12 pages, 4 figures", "pdf_url": "https://arxiv.org/pdf/2509.08203.pdf", "abstract_url": "https://arxiv.org/abs/2509.08203", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)", "Software Engineering (cs.SE)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文提出组件化方法，将大型语言模型的整体输出分解为可独立编辑的语义单元，以提升协作效率。", "motivation": "解决大型语言模型输出文本难以部分编辑，从而减缓协作工作流程的问题。", "method": "采用模块化和适应性输出分解（MAOD）方法，将响应分割为连贯组件并保持链接，通过组件化响应架构（CBRA）实现，原型MAODchat使用微服务设计和状态机代理。", "result": "开发了原型系统，支持实时组件操作和重组，实现了输出分解和上下文保持。", "conclusion": "组件化方法能有效分解和编辑模型输出，促进更高效的协作和交互。"}}
{"id": "2509.08269", "title": "A Systematic Survey on Large Language Models for Evolutionary Optimization: From Modeling to Solving", "authors": ["Yisong Zhang", "Ran Cheng", "Guoxing Yi", "Kay Chen Tan"], "abstract": "Large Language Models (LLMs), with their strong understanding and reasoning capabilities, are increasingly being explored for tackling optimization problems, especially in synergy with evolutionary computation. Despite rapid progress, however, the field still lacks a unified synthesis and a systematic taxonomy. This survey addresses this gap by providing a comprehensive review of recent developments and organizing them within a structured framework. We classify existing research into two main stages: LLMs for optimization modeling and LLMs for optimization solving. The latter is further divided into three paradigms according to the role of LLMs in the optimization workflow: LLMs as stand-alone optimizers, low-level LLMs embedded within optimization algorithms, and high-level LLMs for algorithm selection and generation. For each category, we analyze representative methods, distill technical challenges, and examine their interplay with traditional approaches. We also review interdisciplinary applications spanning the natural sciences, engineering, and machine learning. By contrasting LLM-driven and conventional methods, we highlight key limitations and research gaps, and point toward future directions for developing self-evolving agentic ecosystems for optimization. An up-to-date collection of related literature is maintained at", "subjects": "Neural and Evolutionary Computing (cs.NE); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.08269.pdf", "abstract_url": "https://arxiv.org/abs/2509.08269", "categories": ["Neural and Evolutionary Computing (cs.NE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "对大型语言模型在进化优化中应用的全面综述，涵盖建模和求解，分类方法并分析挑战与未来方向。", "motivation": "解决该领域缺乏统一综合和系统分类的问题，以促进LLMs在优化问题中的应用。", "method": "提供结构化框架，将研究分为建模和求解阶段，后者细分为三种范式，分析代表性方法和技术挑战。", "result": "综述了现有方法，识别了局限性，并指出了与传统方法的对比及未来研究方向。", "conclusion": "强调开发自进化代理生态系统的重要性，为优化领域的未来发展提供指导。"}}
{"id": "2509.08310", "title": "Game-Theoretic Resilience Framework for Cyber-Physical Microgrids using Multi-Agent Reinforcement Learning", "authors": ["S Krishna Niketh", "Sagar Babu Mitikiri", "V Vignesh", "Vedantham Lakshmi Srinivas", "Mayukha Pal"], "abstract": "The increasing reliance on cyber physical infrastructure in modern power systems has amplified the risk of targeted cyber attacks, necessitating robust and adaptive resilience strategies. This paper presents a mathematically rigorous game theoretic framework to evaluate and enhance microgrid resilience using a combination of quantitative resilience metrics Load Served Ratio LSR, Critical Load Resilience CLR, Topological Survivability Score TSS, and DER Resilience Score DRS. These are integrated into a unified payoff matrix using the Analytic Hierarchy Process AHP to assess attack defense interactions. The framework is formalized as a finite horizon Markov Decision Process MDP with formal convergence guarantees and computational complexity bounds. Three case studies are developed 1. static attacks analyzed via Nash equilibrium, 2. severe attacks incorporating high impact strategies, and 3. adaptive attacks using Stackelberg games, regret matching, softmax heuristics, and Multi Agent Q Learning. Rigorous theoretical analysis provides convergence proofs with explicit rates , PAC learning sample complexity bounds, and computational complexity analysis. The framework is tested on an enhanced IEEE 33bus distribution system with DERs and control switches, demonstrating the effectiveness of adaptive and strategic defenses in improving cyber physical resilience with statistically significant improvements of 18.7% 2.1% over static approaches.", "subjects": "Systems and Control (eess.SY); Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.08310.pdf", "abstract_url": "https://arxiv.org/abs/2509.08310", "categories": ["Systems and Control (eess.SY)", "Artificial Intelligence (cs.AI)", "Computer Science and Game Theory (cs.GT)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于博弈论和多智能体强化学习的框架，用于评估和增强微电网的网络物理韧性，通过案例研究和理论分析展示了自适应防御策略的有效性。", "motivation": "现代电力系统对网络物理基础设施的依赖增加，导致针对性网络攻击风险上升，需要开发鲁棒和自适应的韧性策略。", "method": "使用博弈论框架，结合定量韧性指标（如LSR、CLR、TSS、DRS）和AHP方法，形式化为有限视界MDP，并应用Nash均衡、Stackelberg博弈、遗憾匹配、softmax启发式和Multi-Agent Q学习。", "result": "在增强的IEEE 33总线系统上测试，自适应防御策略比静态方法在韧性上显著提高18.7%（±2.1%），并提供收敛证明和计算复杂度分析。", "conclusion": "该框架有效提升微电网的网络物理韧性，强调自适应和战略防御的重要性，具有理论保证和实际应用潜力。"}}
{"id": "2509.08407", "title": "An Iterative LLM Framework for SIBT utilizing RAG-based Adaptive Weight Optimization", "authors": ["Zhuo Xiao", "Qinglong Yao", "Jingjing Wang", "Fugen Zhou", "Bo Liu", "Haitao Sun", "Zhe Ji", "Yuliang Jiang", "Junjie Wang", "Qiuwen Wu"], "abstract": "Seed implant brachytherapy (SIBT) is an effective cancer treatment modality; however, clinical planning often relies on manual adjustment of objective function weights, leading to inefficiencies and suboptimal results. This study proposes an adaptive weight optimization framework for SIBT planning, driven by large language models (LLMs). A locally deployed DeepSeek-R1 LLM is integrated with an automatic planning algorithm in an iterative loop. Starting with fixed weights, the LLM evaluates plan quality and recommends new weights in the next iteration. This process continues until convergence criteria are met, after which the LLM conducts a comprehensive evaluation to identify the optimal plan. A clinical knowledge base, constructed and queried via retrieval-augmented generation (RAG), enhances the model's domain-specific reasoning. The proposed method was validated on 23 patient cases, showing that the LLM-assisted approach produces plans that are comparable to or exceeding clinically approved and fixed-weight plans, in terms of dose homogeneity for the clinical target volume (CTV) and sparing of organs at risk (OARs). The study demonstrates the potential use of LLMs in SIBT planning automation.", "subjects": "Medical Physics (physics.med-ph); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.08407.pdf", "abstract_url": "https://arxiv.org/abs/2509.08407", "categories": ["Medical Physics (physics.med-ph)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种基于大型语言模型（LLM）的自适应权重优化框架，用于种子植入近距离放射治疗（SIBT）规划，通过迭代优化和RAG增强，在23例患者中验证了其有效性，计划质量达到或超过临床标准。", "motivation": "解决SIBT临床规划中手动调整目标函数权重导致的效率低下和结果次优问题。", "method": "使用本地部署的DeepSeek-R1 LLM与自动规划算法集成，在迭代循环中评估计划质量并推荐新权重，结合RAG查询临床知识库，直至收敛后选择最优计划。", "result": "在23例患者案例中，LLM辅助方法生成的计划在CTV剂量均匀性和OARs保护方面与临床批准或固定权重计划相当或更优。", "conclusion": "研究表明LLMs在SIBT规划自动化中具有潜力，可提高效率和结果质量。"}}
{"id": "2509.08535", "title": "Agents of Discovery", "authors": ["Sascha Diefenbacher", "Anna Hallin", "Gregor Kasieczka", "Michael Krämer", "Anne Lauscher", "Tim Lukas"], "abstract": "The substantial data volumes encountered in modern particle physics and other domains of fundamental physics research allow (and require) the use of increasingly complex data analysis tools and workflows. While the use of machine learning (ML) tools for data analysis has recently proliferated, these tools are typically special-purpose algorithms that rely, for example, on encoded physics knowledge to reach optimal performance. In this work, we investigate a new and orthogonal direction: Using recent progress in large language models (LLMs) to create a team of agents -- instances of LLMs with specific subtasks -- that jointly solve data analysis-based research problems in a way similar to how a human researcher might: by creating code to operate standard tools and libraries (including ML systems) and by building on results of previous iterations. If successful, such agent-based systems could be deployed to automate routine analysis components to counteract the increasing complexity of modern tool chains. To investigate the capabilities of current-generation commercial LLMs, we consider the task of anomaly detection via the publicly available and highly-studied LHC Olympics dataset. Several current models by OpenAI (GPT-4o, o4-mini, GPT-4.1, and GPT-5) are investigated and their stability tested. Overall, we observe the capacity of the agent-based system to solve this data analysis problem. The best agent-created solutions mirror the performance of human state-of-the-art results.", "subjects": "High Energy Physics - Phenomenology (hep-ph); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); High Energy Physics - Experiment (hep-ex); Data Analysis, Statistics and Probability (physics.data-an)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.08535.pdf", "abstract_url": "https://arxiv.org/abs/2509.08535", "categories": ["High Energy Physics - Phenomenology (hep-ph)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "High Energy Physics - Experiment (hep-ex)", "Data Analysis, Statistics and Probability (physics.data-an)"], "matching_keywords": ["agent"], "AI": {"tldr": "利用大型语言模型（LLMs）创建代理团队，自动化粒子物理学等领域的复杂数据分析，在LHC Olympics数据集上实现与人类最佳结果相媲美的异常检测性能。", "motivation": "解决现代物理研究中数据量大、工具链复杂的问题，通过自动化减少人工分析负担。", "method": "使用OpenAI的多个LLM模型（如GPT-4o）构建代理系统，模拟人类研究方式，生成代码并迭代优化数据分析。", "result": "代理系统成功解决异常检测任务，最佳方案性能接近人类顶尖水平，展示了当前LLMs的稳定性和能力。", "conclusion": "基于代理的系统有潜力自动化常规分析，应对日益复杂的工具链，提升研究效率。"}}
{"id": "2509.08756", "title": "Using AI to Optimize Patient Transfer and Resource Utilization During Mass-Casualty Incidents: A Simulation Platform", "authors": ["Zhaoxun \"Lorenz\" Liu", "Wagner H. Souza", "Jay Han", "Amin Madani"], "abstract": "Mass casualty incidents (MCIs) overwhelm healthcare systems and demand rapid, accurate patient-hospital allocation decisions under extreme pressure. Here, we developed and validated a deep reinforcement learning-based decision-support AI agent to optimize patient transfer decisions during simulated MCIs by balancing patient acuity levels, specialized care requirements, hospital capacities, and transport logistics. To integrate this AI agent, we developed MasTER, a web-accessible command dashboard for MCI management simulations. Through a controlled user study with 30 participants (6 trauma experts and 24 non-experts), we evaluated three interaction approaches with the AI agent (human-only, human-AI collaboration, and AI-only) across 20- and 60-patient MCI scenarios in the Greater Toronto Area. Results demonstrate that increasing AI involvement significantly improves decision quality and consistency. The AI agent outperforms trauma surgeons (p < 0.001) and enables non-experts to achieve expert-level performance when assisted, contrasting sharply with their significantly inferior unassisted performance (p < 0.001). These findings establish the potential for our AI-driven decision support to enhance both MCI preparedness training and real-world emergency response management.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.08756.pdf", "abstract_url": "https://arxiv.org/abs/2509.08756", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "开发了一个基于深度强化学习的AI代理，通过模拟平台优化大规模伤亡事件中的患者转移决策，提高决策质量和一致性。", "motivation": "解决大规模伤亡事件中医疗系统超负荷、需要快速准确的患者-医院分配决策的问题。", "method": "使用深度强化学习开发AI代理，集成到MasTER模拟仪表板中，并通过用户研究（30名参与者）评估不同交互方式。", "result": "AI参与显著改善决策，AI代理优于创伤外科医生（p < 0.001），并帮助非专家达到专家水平。", "conclusion": "AI驱动的决策支持有潜力增强大规模伤亡事件的准备培训和实际应急管理。"}}
{"id": "2509.08646", "title": "Architecting Resilient LLM Agents: A Guide to Secure Plan-then-Execute Implementations", "authors": ["Ron F. Del Rosario", "Klaudia Krawiecka", "Christian Schroeder de Witt"], "abstract": "As Large Language Model (LLM) agents become increasingly capable of automating complex, multi-step tasks, the need for robust, secure, and predictable architectural patterns is paramount. This paper provides a comprehensive guide to the ``Plan-then-Execute'' (P-t-E) pattern, an agentic design that separates strategic planning from tactical execution. We explore the foundational principles of P-t-E, detailing its core components - the Planner and the Executor - and its architectural advantages in predictability, cost-efficiency, and reasoning quality over reactive patterns like ReAct (Reason + Act). A central focus is placed on the security implications of this design, particularly its inherent resilience to indirect prompt injection attacks by establishing control-flow integrity. We argue that while P-t-E provides a strong foundation, a defense-in-depth strategy is necessary, and we detail essential complementary controls such as the Principle of Least Privilege, task-scoped tool access, and sandboxed code execution. To make these principles actionable, this guide provides detailed implementation blueprints and working code references for three leading agentic frameworks: LangChain (via LangGraph), CrewAI, and AutoGen. Each framework's approach to implementing the P-t-E pattern is analyzed, highlighting unique features like LangGraph's stateful graphs for re-planning, CrewAI's declarative tool scoping for security, and AutoGen's built-in Docker sandboxing. Finally, we discuss advanced patterns, including dynamic re-planning loops, parallel execution with Directed Acyclic Graphs (DAGs), and the critical role of Human-in-the-Loop (HITL) verification, to offer a complete strategic blueprint for architects, developers, and security engineers aiming to build production-grade, resilient, and trustworthy LLM agents.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Systems and Control (eess.SY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.08646.pdf", "abstract_url": "https://arxiv.org/abs/2509.08646", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Systems and Control (eess.SY)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提供了一份关于'计划后执行'（P-t-E）模式的综合指南，用于构建安全、可预测的LLM代理，强调其优势、安全性和实现细节。", "motivation": "解决LLM代理在自动化多步任务时对鲁棒、安全和可预测架构的需求。", "method": "采用P-t-E模式，分离战略规划和战术执行，结合防御深度策略如最小权限原则和沙箱执行。", "result": "P-t-E模式在可预测性、成本效率和推理质量上优于ReAct模式，并增强了对间接提示注入攻击的弹性。", "conclusion": "P-t-E模式为构建生产级LLM代理提供了基础，但需结合高级模式和人机验证以实现全面韧性。"}}
