{"id": "2508.10287", "title": "JRDB-Reasoning: A Difficulty-Graded Benchmark for Visual Reasoning in Robotics", "authors": ["Simindokht Jahangard", "Mehrzad Mohammadi", "Yi Shen", "Zhixi Cai", "Hamid Rezatofighi"], "abstract": "Recent advances in Vision-Language Models (VLMs) and large language models (LLMs) have greatly enhanced visual reasoning, a key capability for embodied AI agents like robots. However, existing visual reasoning benchmarks often suffer from several limitations: they lack a clear definition of reasoning complexity, offer have no control to generate questions over varying difficulty and task customization, and fail to provide structured, step-by-step reasoning annotations (workflows). To bridge these gaps, we formalize reasoning complexity, introduce an adaptive query engine that generates customizable questions of varying complexity with detailed intermediate annotations, and extend the JRDB dataset with human-object interaction and geometric relationship annotations to create JRDB-Reasoning, a benchmark tailored for visual reasoning in human-crowded environments. Our engine and benchmark enable fine-grained evaluation of visual reasoning frameworks and dynamic assessment of visual-language models across reasoning levels.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10287.pdf", "abstract_url": "https://arxiv.org/abs/2508.10287", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了JRDB-Reasoning，一个为机器人视觉推理设计的难度分级的基准测试，通过定义推理复杂性、自适应查询引擎和扩展JRDB数据集来解决现有基准的不足。", "motivation": "解决现有视觉推理基准在定义推理复杂性、生成不同难度问题和提供结构化推理注释方面的局限性。", "method": "通过形式化推理复杂性，引入自适应查询引擎生成可定制的问题，并扩展JRDB数据集以包含人-物交互和几何关系注释。", "result": "创建了JRDB-Reasoning基准，支持对视觉推理框架的细粒度评估和视觉语言模型在不同推理级别上的动态评估。", "conclusion": "JRDB-Reasoning为拥挤人类环境中的视觉推理提供了一个有效的评估工具，促进了视觉推理技术的发展。"}}
{"id": "2508.10572", "title": "Towards Agentic AI for Multimodal-Guided Video Object Segmentation", "authors": ["Tuyen Tran", "Thao Minh Le", "Truyen Tran"], "abstract": "Referring-based Video Object Segmentation is a multimodal problem that requires producing fine-grained segmentation results guided by external cues. Traditional approaches to this task typically involve training specialized models, which come with high computational complexity and manual annotation effort. Recent advances in vision-language foundation models open a promising direction toward training-free approaches. Several studies have explored leveraging these general-purpose models for fine-grained segmentation, achieving performance comparable to that of fully supervised, task-specific models. However, existing methods rely on fixed pipelines that lack the flexibility needed to adapt to the dynamic nature of the task. To address this limitation, we propose Multi-Modal Agent, a novel agentic system designed to solve this task in a more flexible and adaptive manner. Specifically, our method leverages the reasoning capabilities of large language models (LLMs) to generate dynamic workflows tailored to each input. This adaptive procedure iteratively interacts with a set of specialized tools designed for low-level tasks across different modalities to identify the target object described by the multimodal cues. Our agentic approach demonstrates clear improvements over prior methods on two multimodal-conditioned VOS tasks: RVOS and Ref-AVS.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10572.pdf", "abstract_url": "https://arxiv.org/abs/2508.10572", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种新型的多模态代理系统（Multi-Modal Agent），用于解决基于参考的视频对象分割（RVOS和Ref-AVS）任务中的灵活性和适应性问题。通过利用大型语言模型（LLMs）的推理能力生成动态工作流程，并与专门设计的工具集交互，该方法在不需要训练的情况下，实现了优于现有方法的性能。", "motivation": "传统的基于参考的视频对象分割方法需要训练专用模型，计算复杂度高且需要大量手动标注。虽然现有的视觉-语言基础模型提供了一种无需训练的解决方案，但这些方法依赖于固定流程，缺乏适应任务动态性的灵活性。", "method": "提出了一种多模态代理系统，该系统利用大型语言模型（LLMs）的推理能力，为每个输入生成动态工作流程，并通过与跨模态设计的专门工具集交互，识别由多模态线索描述的目标对象。", "result": "在多模态条件下的视频对象分割任务（RVOS和Ref-AVS）上，所提出的代理方法明显优于现有方法。", "conclusion": "通过引入动态和自适应的工作流程生成机制，多模态代理系统为解决基于参考的视频对象分割任务提供了一种更灵活、更有效的方法，展示了在无需训练的情况下实现高性能的潜力。"}}
{"id": "2508.10567", "title": "SpaRC-AD: A Baseline for Radar-Camera Fusion in End-to-End Autonomous Driving", "authors": ["Philipp Wolters", "Johannes Gilg", "Torben Teepe", "Gerhard Rigoll"], "abstract": "End-to-end autonomous driving systems promise stronger performance through unified optimization of perception, motion forecasting, and planning. However, vision-based approaches face fundamental limitations in adverse weather conditions, partial occlusions, and precise velocity estimation - critical challenges in safety-sensitive scenarios where accurate motion understanding and long-horizon trajectory prediction are essential for collision avoidance. To address these limitations, we propose SpaRC-AD, a query-based end-to-end camera-radar fusion framework for planning-oriented autonomous driving. Through sparse 3D feature alignment, and doppler-based velocity estimation, we achieve strong 3D scene representations for refinement of agent anchors, map polylines and motion modelling. Our method achieves strong improvements over the state-of-the-art vision-only baselines across multiple autonomous driving tasks, including 3D detection (+4.8% mAP), multi-object tracking (+8.3% AMOTA), online mapping (+1.8% mAP), motion prediction (-4.0% mADE), and trajectory planning (-0.1m L2 and -9% TPC). We achieve both spatial coherence and temporal consistency on multiple challenging benchmarks, including real-world open-loop nuScenes, long-horizon T-nuScenes, and closed-loop simulator Bench2Drive. We show the effectiveness of radar-based fusion in safety-critical scenarios where accurate motion understanding and long-horizon trajectory prediction are essential for collision avoidance. The source code of all experiments is available at", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)", "comments": "8 pages, 4 figures, 5 tables", "pdf_url": "https://arxiv.org/pdf/2508.10567.pdf", "abstract_url": "https://arxiv.org/abs/2508.10567", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "SpaRC-AD是一个基于查询的端到端相机-雷达融合框架，旨在解决自动驾驶中的感知、运动预测和规划问题。通过稀疏3D特征对齐和基于多普勒的速度估计，该方法在多个自动驾驶任务上实现了对纯视觉基线的显著改进。", "motivation": "纯视觉自动驾驶系统在恶劣天气条件、部分遮挡和精确速度估计方面存在根本限制，这些限制在安全敏感场景中尤为关键。SpaRC-AD旨在通过相机和雷达的融合来解决这些限制。", "method": "SpaRC-AD采用稀疏3D特征对齐和基于多普勒的速度估计技术，以增强3D场景表示，优化代理锚点、地图多段线和运动建模。", "result": "在多个自动驾驶任务上，SpaRC-AD相比纯视觉基线实现了显著改进，包括3D检测（+4.8% mAP）、多目标跟踪（+8.3% AMOTA）、在线地图构建（+1.8% mAP）、运动预测（-4.0% mADE）和轨迹规划（-0.1m L2和-9% TPC）。", "conclusion": "SpaRC-AD在多个具有挑战性的基准测试中实现了空间一致性和时间一致性，证明了雷达融合在安全关键场景中的有效性，特别是在需要精确运动理解和长时程轨迹预测以避免碰撞的情况下。"}}
{"id": "2508.10143", "title": "MCP-Orchestrated Multi-Agent System for Automated Disinformation Detection", "authors": ["Alexandru-Andrei Avram", "Adrian Groza", "Alexandru Lecu"], "abstract": "The large spread of disinformation across digital platforms creates significant challenges to information integrity. This paper presents a multi-agent system that uses relation extraction to detect disinformation in news articles, focusing on titles and short text snippets. The proposed Agentic AI system combines four agents: (i) a machine learning agent (logistic regression), (ii) a Wikipedia knowledge check agent (which relies on named entity recognition), (iii) a coherence detection agent (using LLM prompt engineering), and (iv) a web-scraped data analyzer that extracts relational triplets for fact checking. The system is orchestrated via the Model Context Protocol (MCP), offering shared context and live learning across components. Results demonstrate that the multi-agent ensemble achieves 95.3% accuracy with an F1 score of 0.964, significantly outperforming individual agents and traditional approaches. The weighted aggregation method, mathematically derived from individual agent misclassification rates, proves superior to algorithmic threshold optimization. The modular architecture makes the system easily scalable, while also maintaining details of the decision processes.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "8 pages + 1 page references, 5 figures, 4 tables, Registered for the 27th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing, 2025, Timisoara", "pdf_url": "https://arxiv.org/pdf/2508.10143.pdf", "abstract_url": "https://arxiv.org/abs/2508.10143", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种多代理系统，用于自动检测新闻文章中的虚假信息，通过结合四种不同的代理和模型上下文协议（MCP）来实现高准确率。", "motivation": "数字平台上虚假信息的广泛传播对信息完整性构成了重大挑战，需要有效的自动检测方法。", "method": "使用多代理系统，包括机器学习代理、维基百科知识检查代理、一致性检测代理和网络抓取数据分析代理，通过MCP进行协调和共享上下文。", "result": "多代理系统实现了95.3%的准确率和0.964的F1分数，显著优于单个代理和传统方法。", "conclusion": "该系统的模块化架构易于扩展，同时保持了决策过程的透明度，为虚假信息检测提供了一种有效的解决方案。"}}
{"id": "2508.10146", "title": "Agentic AI Frameworks: Architectures, Protocols, and Design Challenges", "authors": ["Hana Derouiche", "Zaki Brahmi", "Haithem Mazeni"], "abstract": "The emergence of Large Language Models (LLMs) has ushered in a transformative paradigm in artificial intelligence, Agentic AI, where intelligent agents exhibit goal-directed autonomy, contextual reasoning, and dynamic multi-agent coordination. This paper provides a systematic review and comparative analysis of leading Agentic AI frameworks, including CrewAI, LangGraph, AutoGen, Semantic Kernel, Agno, Google ADK, and MetaGPT, evaluating their architectural principles, communication mechanisms, memory management, safety guardrails, and alignment with service-oriented computing paradigms. Furthermore, we identify key limitations, emerging trends, and open challenges in the field. To address the issue of agent communication, we conduct an in-depth analysis of protocols such as the Contract Net Protocol (CNP), Agent-to-Agent (A2A), Agent Network Protocol (ANP), and Agora. Our findings not only establish a foundational taxonomy for Agentic AI systems but also propose future research directions to enhance scalability, robustness, and interoperability. This work serves as a comprehensive reference for researchers and practitioners working to advance the next generation of autonomous AI systems.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10146.pdf", "abstract_url": "https://arxiv.org/abs/2508.10146", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文对Agentic AI框架进行了系统回顾和比较分析，评估了其架构原则、通信机制等，并提出了未来研究方向。", "motivation": "解决大型语言模型（LLMs）带来的智能代理在目标导向自主性、上下文推理和动态多代理协调方面的问题。", "method": "系统回顾和比较分析领先的Agentic AI框架，包括CrewAI、LangGraph等，以及深入分析代理通信协议。", "result": "建立了Agentic AI系统的基础分类学，并提出了增强可扩展性、健壮性和互操作性的未来研究方向。", "conclusion": "本文为研究人员和从业者提供了推进下一代自主AI系统的全面参考。"}}
{"id": "2508.10152", "title": "Improving and Evaluating Open Deep Research Agents", "authors": ["Doaa Allabadi", "Kyle Bradbury", "Jordan M. Malof"], "abstract": "We focus here on Deep Research Agents (DRAs), which are systems that can take a natural language prompt from a user, and then autonomously search for, and utilize, internet-based content to address the prompt. Recent DRAs have demonstrated impressive capabilities on public benchmarks however, recent research largely involves proprietary closed-source systems. At the time of this work, we only found one open-source DRA, termed Open Deep Research (ODR). In this work we adapt the challenging recent BrowseComp benchmark to compare ODR to existing proprietary systems. We propose BrowseComp-Small (BC-Small), comprising a subset of BrowseComp, as a more computationally-tractable DRA benchmark for academic labs. We benchmark ODR and two other proprietary systems on BC-Small: one system from Anthropic and one system from Google. We find that all three systems achieve 0% accuracy on the test set of 60 questions. We introduce three strategic improvements to ODR, resulting in the ODR+ model, which achieves a state-of-the-art 10% success rate on BC-Small among both closed-source and open-source systems. We report ablation studies indicating that all three of our improvements contributed to the success of ODR+.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "8 pages, 2 figures, 2 tables", "pdf_url": "https://arxiv.org/pdf/2508.10152.pdf", "abstract_url": "https://arxiv.org/abs/2508.10152", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究了深度研究代理（DRAs），即能够根据用户自然语言提示自主搜索并利用互联网内容来解决问题的系统。尽管现有DRAs在公共基准测试中表现出色，但多数为闭源系统。本文通过改进开源系统ODR，并引入新的基准测试BC-Small，展示了ODR+在性能上的显著提升。", "motivation": "解决深度研究代理（DRAs）领域内开源系统稀缺且性能不足的问题，以及提供一个更适合学术实验室使用的基准测试。", "method": "通过改进现有的开源DRA系统ODR，引入BrowseComp-Small（BC-Small）作为新的基准测试，并对ODR进行三项战略性改进，形成ODR+模型。", "result": "ODR+在BC-Small测试集上达到了10%的成功率，成为当前开源和闭源系统中的最先进水平。", "conclusion": "通过战略性改进，开源DRA系统ODR+在性能上取得了显著提升，为学术研究提供了有价值的工具和基准。"}}
{"id": "2508.10177", "title": "KompeteAI: Accelerated Autonomous Multi-Agent System for End-to-End Pipeline Generation for Machine Learning Problems", "authors": ["Stepan Kulibaba", "Artem Dzhalilov", "Roman Pakhomov", "Oleg Svidchenko", "Alexander Gasnikov", "Aleksei Shpilman"], "abstract": "Recent Large Language Model (LLM)-based AutoML systems demonstrate impressive capabilities but face significant limitations such as constrained exploration strategies and a severe execution bottleneck. Exploration is hindered by one-shot methods lacking diversity and Monte Carlo Tree Search (MCTS) approaches that fail to recombine strong partial solutions. The execution bottleneck arises from lengthy code validation cycles that stifle iterative refinement. To overcome these challenges, we introduce KompeteAI, a novel AutoML framework with dynamic solution space exploration. Unlike previous MCTS methods that treat ideas in isolation, KompeteAI introduces a merging stage that composes top candidates. We further expand the hypothesis space by integrating Retrieval-Augmented Generation (RAG), sourcing ideas from Kaggle notebooks and arXiv papers to incorporate real-world strategies. KompeteAI also addresses the execution bottleneck via a predictive scoring model and an accelerated debugging method, assessing solution potential using early stage metrics to avoid costly full-code execution. This approach accelerates pipeline evaluation 6.9 times. KompeteAI outperforms leading methods (e.g., RD-agent, AIDE, and Ml-Master) by an average of 3\\% on the primary AutoML benchmark, MLE-Bench. Additionally, we propose Kompete-bench to address limitations in MLE-Bench, where KompeteAI also achieves state-of-the-art results", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10177.pdf", "abstract_url": "https://arxiv.org/abs/2508.10177", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "KompeteAI是一个新型的AutoML框架，旨在通过动态解决方案空间探索、合并顶级候选方案、集成检索增强生成（RAG）技术以及预测评分模型和加速调试方法，克服现有LLM-based AutoML系统的限制，如探索策略受限和执行瓶颈，显著提升了管道评估速度和性能。", "motivation": "解决现有大型语言模型（LLM）基础的AutoML系统在探索策略和执行效率上的限制，如缺乏多样性的探索策略和代码验证周期长导致的执行瓶颈。", "method": "引入动态解决方案空间探索、合并顶级候选方案、集成检索增强生成（RAG）技术，以及使用预测评分模型和加速调试方法来评估解决方案潜力。", "result": "KompeteAI将管道评估速度提高了6.9倍，并在主要AutoML基准测试MLE-Bench上平均优于领先方法3%，同时在提出的Kompete-bench上也达到了最先进的成果。", "conclusion": "KompeteAI通过创新的探索和执行策略，显著提高了AutoML系统的性能和效率，为机器学习问题的端到端管道生成提供了加速的自主多代理系统解决方案。"}}
{"id": "2508.10337", "title": "A Curriculum Learning Approach to Reinforcement Learning: Leveraging RAG for Multimodal Question Answering", "authors": ["Chenliang Zhang", "Lin Wang", "Yuanyuan Lu", "Yusheng Qi", "Kexin Wang", "Peixu Hou", "Wenshi Chen"], "abstract": "This paper describes the solutions of the Dianping-Trust-Safety team for the META CRAG-MM challenge. The challenge requires building a comprehensive retrieval-augmented generation system capable for multi-modal multi-turn question answering. The competition consists of three tasks: (1) answering questions using structured data retrieved from an image-based mock knowledge graph, (2) synthesizing information from both knowledge graphs and web search results, and (3) handling multi-turn conversations that require context understanding and information aggregation from multiple sources. For Task 1, our solution is based on the vision large language model, enhanced by supervised fine-tuning with knowledge distilled from GPT-4.1. We further applied curriculum learning strategies to guide reinforcement learning, resulting in improved answer accuracy and reduced hallucination. For Task 2 and Task 3, we additionally leveraged web search APIs to incorporate external knowledge, enabling the system to better handle complex queries and multi-turn conversations. Our approach achieved 1st place in Task 1 with a significant lead of 52.38\\%, and 3rd place in Task 3, demonstrating the effectiveness of the integration of curriculum learning with reinforcement learning in our training pipeline.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10337.pdf", "abstract_url": "https://arxiv.org/abs/2508.10337", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了点评-信任-安全团队在META CRAG-MM挑战中的解决方案，该挑战要求构建一个能够进行多模态多轮问答的检索增强生成系统。团队通过结合视觉大语言模型、监督微调、课程学习策略和强化学习，有效提高了答案准确性并减少了幻觉现象，最终在任务1中获得第一名，在任务3中获得第三名。", "motivation": "解决多模态多轮问答中的信息检索与生成问题，特别是在处理结构化数据、知识图谱和网络搜索结果合成以及多轮对话上下文理解方面的挑战。", "method": "结合视觉大语言模型和GPT-4.1的知识蒸馏进行监督微调，应用课程学习策略指导强化学习，并利用网络搜索API整合外部知识。", "result": "在任务1中以52.38%的显著优势获得第一名，在任务3中获得第三名，证明了课程学习与强化学习结合在训练流程中的有效性。", "conclusion": "通过集成课程学习和强化学习，团队成功构建了一个高效的多模态多轮问答系统，为类似挑战提供了有价值的解决方案。"}}
{"id": "2508.10340", "title": "Multi-Agent Trust Region Policy Optimisation: A Joint Constraint Approach", "authors": ["Chak Lam Shek", "Guangyao Shi", "Pratap Tokekar"], "abstract": "Multi-agent reinforcement learning (MARL) requires coordinated and stable policy updates among interacting agents. Heterogeneous-Agent Trust Region Policy Optimization (HATRPO) enforces per-agent trust region constraints using Kullback-Leibler (KL) divergence to stabilize training. However, assigning each agent the same KL threshold can lead to slow and locally optimal updates, especially in heterogeneous settings. To address this limitation, we propose two approaches for allocating the KL divergence threshold across agents: HATRPO-W, a Karush-Kuhn-Tucker-based (KKT-based) method that optimizes threshold assignment under global KL constraints, and HATRPO-G, a greedy algorithm that prioritizes agents based on improvement-to-divergence ratio. By connecting sequential policy optimization with constrained threshold scheduling, our approach enables more flexible and effective learning in heterogeneous-agent settings. Experimental results demonstrate that our methods significantly boost the performance of HATRPO, achieving faster convergence and higher final rewards across diverse MARL benchmarks. Specifically, HATRPO-W and HATRPO-G achieve comparable improvements in final performance, each exceeding 22.5%. Notably, HATRPO-W also demonstrates more stable learning dynamics, as reflected by its lower variance.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10340.pdf", "abstract_url": "https://arxiv.org/abs/2508.10340", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了两种方法（HATRPO-W和HATRPO-G）来分配多智能体强化学习中的KL散度阈值，以解决HATRPO在异构设置中更新缓慢和局部最优的问题。实验表明，这两种方法显著提高了HATRPO的性能，实现了更快的收敛和更高的最终奖励。", "motivation": "解决多智能体强化学习（MARL）中，由于为每个智能体分配相同的KL散度阈值而导致的训练不稳定、更新缓慢和局部最优问题，特别是在异构智能体设置中。", "method": "提出了两种KL散度阈值分配方法：HATRPO-W（基于KKT的方法，在全局KL约束下优化阈值分配）和HATRPO-G（贪婪算法，根据改进与散度比优先分配智能体）。", "result": "实验结果显示，HATRPO-W和HATRPO-G均显著提升了HATRPO的性能，最终性能提升均超过22.5%。HATRPO-W还表现出更稳定的学习动态，方差更低。", "conclusion": "通过将顺序策略优化与约束阈值调度相结合，本文的方法在异构智能体设置中实现了更灵活和有效的学习，显著提高了多智能体强化学习的性能。"}}
{"id": "2508.10358", "title": "What to Ask Next? Probing the Imaginative Reasoning of LLMs with TurtleSoup Puzzles", "authors": ["Mengtao Zhou", "Sifan Wu", "Huan Zhang", "Qi Sima", "Bang Liu"], "abstract": "We investigate the capacity of Large Language Models (LLMs) for imaginative reasoning--the proactive construction, testing, and revision of hypotheses in information-sparse environments. Existing benchmarks, often static or focused on social deduction, fail to capture the dynamic, exploratory nature of this reasoning process. To address this gap, we introduce a comprehensive research framework based on the classic \"Turtle Soup\" game, integrating a benchmark, an agent, and an evaluation protocol. We present TurtleSoup-Bench, the first large-scale, bilingual, interactive benchmark for imaginative reasoning, comprising 800 turtle soup puzzles sourced from both the Internet and expert authors. We also propose Mosaic-Agent, a novel agent designed to assess LLMs' performance in this setting. To evaluate reasoning quality, we develop a multi-dimensional protocol measuring logical consistency, detail completion, and conclusion alignment. Experiments with leading LLMs reveal clear capability limits, common failure patterns, and a significant performance gap compared to humans. Our work offers new insights into LLMs' imaginative reasoning and establishes a foundation for future research on exploratory agent behavior.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10358.pdf", "abstract_url": "https://arxiv.org/abs/2508.10358", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过‘TurtleSoup’游戏研究大型语言模型（LLMs）的想象力推理能力，提出了一个包含基准、代理和评估协议的框架，揭示了LLMs在此类任务中的局限性。", "motivation": "现有基准大多静态或侧重于社会演绎，未能捕捉想象力推理的动态和探索性，本文旨在填补这一空白。", "method": "引入基于‘TurtleSoup’游戏的综合研究框架，包括TurtleSoup-Bench基准、Mosaic-Agent代理和多维评估协议。", "result": "实验显示，领先的LLMs在想象力推理方面存在明显能力限制和常见失败模式，与人类相比有显著性能差距。", "conclusion": "本研究为LLMs的想象力推理提供了新见解，并为未来探索性代理行为研究奠定了基础。"}}
{"id": "2508.10391", "title": "LeanRAG: Knowledge-Graph-Based Generation with Semantic Aggregation and Hierarchical Retrieval", "authors": ["Yaoze Zhang", "Rong Wu", "Pinlong Cai", "Xiaoman Wang", "Guohang Yan", "Song Mao", "Ding Wang", "Botian Shi"], "abstract": "Retrieval-Augmented Generation (RAG) plays a crucial role in grounding Large Language Models by leveraging external knowledge, whereas the effectiveness is often compromised by the retrieval of contextually flawed or incomplete information. To address this, knowledge graph-based RAG methods have evolved towards hierarchical structures, organizing knowledge into multi-level summaries. However, these approaches still suffer from two critical, unaddressed challenges: high-level conceptual summaries exist as disconnected ``semantic islands'', lacking the explicit relations needed for cross-community reasoning; and the retrieval process itself remains structurally unaware, often degenerating into an inefficient flat search that fails to exploit the graph's rich topology. To overcome these limitations, we introduce LeanRAG, a framework that features a deeply collaborative design combining knowledge aggregation and retrieval strategies. LeanRAG first employs a novel semantic aggregation algorithm that forms entity clusters and constructs new explicit relations among aggregation-level summaries, creating a fully navigable semantic network. Then, a bottom-up, structure-guided retrieval strategy anchors queries to the most relevant fine-grained entities and then systematically traverses the graph's semantic pathways to gather concise yet contextually comprehensive evidence sets. The LeanRAG can mitigate the substantial overhead associated with path retrieval on graphs and minimizes redundant information retrieval. Extensive experiments on four challenging QA benchmarks with different domains demonstrate that LeanRAG significantly outperforming existing methods in response quality while reducing 46\\% retrieval redundancy. Code is available at:", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10391.pdf", "abstract_url": "https://arxiv.org/abs/2508.10391", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "LeanRAG是一个基于知识图谱的检索增强生成框架，通过语义聚合和层次检索解决现有方法中的信息不完整和检索效率低下的问题。", "motivation": "解决检索增强生成（RAG）方法中因检索到上下文错误或不完整信息而影响效果的问题，以及现有知识图谱方法中高级概念摘要缺乏显式关系和检索过程未充分利用图结构的问题。", "method": "LeanRAG采用语义聚合算法形成实体集群并构建聚合级摘要间的新显式关系，创建一个完全可导航的语义网络；然后采用自下而上、结构引导的检索策略，从最相关的细粒度实体开始，系统地遍历图的语义路径以收集简洁但上下文全面的证据集。", "result": "在四个不同领域的QA基准测试中，LeanRAG在响应质量上显著优于现有方法，同时减少了46%的检索冗余。", "conclusion": "LeanRAG通过结合知识聚合和检索策略的深度协作设计，有效解决了现有RAG方法的局限性，提高了生成质量和检索效率。"}}
{"id": "2508.10016", "title": "Training-Free Multimodal Large Language Model Orchestration", "authors": ["Tianyu Xie", "Yuhang Wu", "Yongdong Luo", "Jiayi Ji", "Xiawu Zheng"], "abstract": "Different Multimodal Large Language Models (MLLMs) cannot be integrated into a unified multimodal input-output system directly. In previous work, training has been considered as an inevitable component due to challenges in modal alignment, Text-to-Speech efficiency and other integration issues. In this paper, we introduce Multimodal Large Language Model Orchestration, an effective approach for creating interactive multimodal AI systems without additional training. MLLM Orchestration leverages the inherent reasoning capabilities of large language models to coordinate specialized models through explicit workflows, enabling natural multimodal interactions while maintaining modularity, improving interpretability, and significantly enhancing computational efficiency. Our orchestration framework is built upon three key innovations: (1) a central controller LLM that analyzes user inputs and dynamically routes tasks to appropriate specialized models through carefully designed agents; (2) a parallel Text-to-Speech architecture that enables true full-duplex interaction with seamless interruption handling and natural conversational flow; and (3) a cross-modal memory integration system that maintains coherent context across modalities through intelligent information synthesis and retrieval, selectively avoiding unnecessary modality calls in certain scenarios to improve response speed. Extensive evaluations demonstrate that MLLM Orchestration achieves comprehensive multimodal capabilities without additional training, performance improvements of up to 7.8% over traditional jointly-trained approaches on standard benchmarks, reduced latency by 10.3%, and significantly enhanced interpretability through explicit orchestration processes.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10016.pdf", "abstract_url": "https://arxiv.org/abs/2508.10016", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种无需额外训练的多模态大型语言模型编排方法，通过利用大型语言模型的固有推理能力协调专门模型，实现自然的多模态交互。", "motivation": "解决不同多模态大型语言模型（MLLMs）无法直接集成到统一的多模态输入输出系统中的问题，避免传统方法中必须进行的训练。", "method": "采用中央控制器LLM分析用户输入并通过精心设计的代理动态路由任务到适当的专门模型，实现并行文本到语音架构和跨模态记忆集成系统。", "result": "MLLM编排在不进行额外训练的情况下实现了全面的多模态能力，性能比传统联合训练方法提高了7.8%，延迟减少了10.3%。", "conclusion": "MLLM编排通过显式的工作流程协调专门模型，不仅提高了计算效率和可解释性，还实现了自然的多模态交互。"}}
{"id": "2508.10024", "title": "RTTC: Reward-Guided Collaborative Test-Time Compute", "authors": ["J. Pablo Muñoz", "Jinjie Yuan"], "abstract": "Test-Time Compute (TTC) has emerged as a powerful paradigm for enhancing the performance of Large Language Models (LLMs) at inference, leveraging strategies such as Test-Time Training (TTT) and Retrieval-Augmented Generation (RAG). However, the optimal adaptation strategy varies across queries, and indiscriminate application of TTC strategy incurs substantial computational overhead. In this work, we introduce Reward-Guided Test-Time Compute (RTTC), a novel framework that adaptively selects the most effective TTC strategy for each query via a pretrained reward model, maximizing downstream accuracy across diverse domains and tasks. RTTC operates in a distributed server-client architecture, retrieving relevant samples from a remote knowledge base and applying RAG or lightweight fine-tuning on client devices only when necessary. To further mitigate redundant computation, we propose Query-State Caching, which enables the efficient reuse of historical query states at both retrieval and adaptation levels. Extensive experiments across multiple LLMs and benchmarks demonstrate that RTTC consistently achieves superior accuracy compared to vanilla RAG or TTT, validating the necessity of adaptive, reward-guided TTC selection and the potential of RTTC for scalable, high-performance language model adaptation.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10024.pdf", "abstract_url": "https://arxiv.org/abs/2508.10024", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "RTTC是一个新颖的框架，通过预训练的奖励模型自适应地为每个查询选择最有效的测试时计算策略，以最大化不同领域和任务的下游准确性。", "motivation": "解决在大型语言模型推理中，无差别应用测试时计算策略导致的计算开销大的问题。", "method": "采用分布式服务器-客户端架构，通过奖励模型选择策略，必要时在客户端设备上应用检索增强生成或轻量级微调，并提出查询状态缓存以减少冗余计算。", "result": "在多个大型语言模型和基准测试上的广泛实验表明，RTTC相比传统的RAG或TTT方法，能够持续实现更高的准确性。", "conclusion": "RTTC展示了自适应、奖励引导的测试时计算选择的必要性，以及其在可扩展、高性能语言模型适应中的潜力。"}}
{"id": "2508.10467", "title": "FIRESPARQL: A LLM-based Framework for SPARQL Query Generation over Scholarly Knowledge Graphs", "authors": ["Xueli Pan", "Victor de Boer", "Jacco van Ossenbruggen"], "abstract": "Question answering over Scholarly Knowledge Graphs (SKGs) remains a challenging task due to the complexity of scholarly content and the intricate structure of these graphs. Large Language Model (LLM) approaches could be used to translate natural language questions (NLQs) into SPARQL queries; however, these LLM-based approaches struggle with SPARQL query generation due to limited exposure to SKG-specific content and the underlying schema. We identified two main types of errors in the LLM-generated SPARQL queries: (i) structural inconsistencies, such as missing or redundant triples in the queries, and (ii) semantic inaccuracies, where incorrect entities or properties are shown in the queries despite a correct query structure. To address these issues, we propose FIRESPARQL, a modular framework that supports fine-tuned LLMs as a core component, with optional context provided via retrieval-augmented generation (RAG) and a SPARQL query correction layer. We evaluate the framework on the SciQA Benchmark using various configurations (zero-shot, zero-shot with RAG, one-shot, fine-tuning, and fine-tuning with RAG) and compare the performance with baseline and state-of-the-art approaches. We measure query accuracy using BLEU and ROUGE metrics, and query result accuracy using relaxed exact match(RelaxedEM), with respect to the gold standards containing the NLQs, SPARQL queries, and the results of the queries. Experimental results demonstrate that fine-tuning achieves the highest overall performance, reaching 0.90 ROUGE-L for query accuracy and 0.85 RelaxedEM for result accuracy on the test set.", "subjects": "Artificial Intelligence (cs.AI); Digital Libraries (cs.DL)", "comments": "Accepted at 17th International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management (IC3K)", "pdf_url": "https://arxiv.org/pdf/2508.10467.pdf", "abstract_url": "https://arxiv.org/abs/2508.10467", "categories": ["Artificial Intelligence (cs.AI)", "Digital Libraries (cs.DL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "FIRESPARQL是一个基于大型语言模型(LLM)的框架，旨在通过细调LLM、检索增强生成(RAG)和SPARQL查询校正层，解决从自然语言问题(NLQs)生成SPARQL查询的挑战，特别是在学术知识图谱(SKGs)上的应用。", "motivation": "解决学术知识图谱(SKGs)上问答任务中，由于学术内容的复杂性和图谱结构的复杂性，大型语言模型(LLM)在生成SPARQL查询时遇到的结构不一致和语义不准确的问题。", "method": "提出FIRESPARQL框架，结合细调LLM、检索增强生成(RAG)和SPARQL查询校正层，以改进SPARQL查询的生成。", "result": "在SciQA基准测试中，细调配置达到了最高的整体性能，查询准确度的ROUGE-L得分为0.90，结果准确度的RelaxedEM得分为0.85。", "conclusion": "FIRESPARQL框架通过细调LLM和结合RAG及查询校正，显著提高了在学术知识图谱上生成SPARQL查询的准确性和结果的质量。"}}
{"id": "2508.10501", "title": "PASS: Probabilistic Agentic Supernet Sampling for Interpretable and Adaptive Chest X-Ray Reasoning", "authors": ["Yushi Feng", "Junye Du", "Yingying Hong", "Qifan Wang", "Lequan Yu"], "abstract": "Existing tool-augmented agentic systems are limited in the real world by (i) black-box reasoning steps that undermine trust of decision-making and pose safety risks, (ii) poor multimodal integration, which is inherently critical for healthcare tasks, and (iii) rigid and computationally inefficient agentic pipelines. We introduce PASS (Probabilistic Agentic Supernet Sampling), the first multimodal framework to address these challenges in the context of Chest X-Ray (CXR) reasoning. PASS adaptively samples agentic workflows over a multi-tool graph, yielding decision paths annotated with interpretable probabilities. Given the complex CXR reasoning task with multimodal medical data, PASS leverages its learned task-conditioned distribution over the agentic supernet. Thus, it adaptively selects the most suitable tool at each supernet layer, offering probability-annotated trajectories for post-hoc audits and directly enhancing medical AI safety. PASS also continuously compresses salient findings into an evolving personalized memory, while dynamically deciding whether to deepen its reasoning path or invoke an early exit for efficiency. To optimize a Pareto frontier balancing performance and cost, we design a novel three-stage training procedure, including expert knowledge warm-up, contrastive path-ranking, and cost-aware reinforcement learning. To facilitate rigorous evaluation, we introduce CAB-E, a comprehensive benchmark for multi-step, safety-critical, free-form CXR reasoning. Experiments across various benchmarks validate that PASS significantly outperforms strong baselines in multiple metrics (e.g., accuracy, AUC, LLM-J.) while balancing computational costs, pushing a new paradigm shift towards interpretable, adaptive, and multimodal medical agentic systems.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10501.pdf", "abstract_url": "https://arxiv.org/abs/2508.10501", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "PASS（概率性代理超级网络采样）是一个多模态框架，旨在解决现有工具增强代理系统在现实世界中的局限性，特别是在胸部X光（CXR）推理方面。它通过自适应采样代理工作流程，提供带有可解释概率的决策路径，增强了医疗AI的安全性和效率。", "motivation": "解决现有工具增强代理系统在信任度、多模态整合和计算效率方面的不足，特别是在医疗保健任务中。", "method": "PASS利用学习到的任务条件分布，在多工具图上自适应采样代理工作流程，提供概率注释的决策路径，并通过三阶段训练程序优化性能和成本的平衡。", "result": "PASS在多个基准测试中显著优于强基线，在准确性、AUC等多项指标上表现优异，同时平衡了计算成本。", "conclusion": "PASS推动了向可解释、自适应和多模态医疗代理系统的新范式转变，提高了医疗AI的安全性和效率。"}}
{"id": "2508.10745", "title": "Agentic Design Review System", "authors": ["Sayan Nag", "K J Joseph", "Koustava Goswami", "Vlad I Morariu", "Balaji Vasan Srinivasan"], "abstract": "Evaluating graphic designs involves assessing it from multiple facets like alignment, composition, aesthetics and color choices. Evaluating designs in a holistic way involves aggregating feedback from individual expert reviewers. Towards this, we propose an Agentic Design Review System (AgenticDRS), where multiple agents collaboratively analyze a design, orchestrated by a meta-agent. A novel in-context exemplar selection approach based on graph matching and a unique prompt expansion method plays central role towards making each agent design aware. Towards evaluating this framework, we propose DRS-BENCH benchmark. Thorough experimental evaluation against state-of-the-art baselines adapted to the problem setup, backed-up with critical ablation experiments brings out the efficacy of Agentic-DRS in evaluating graphic designs and generating actionable feedback. We hope that this work will attract attention to this pragmatic, yet under-explored research direction.", "subjects": "Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Multiagent Systems (cs.MA); Multimedia (cs.MM)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10745.pdf", "abstract_url": "https://arxiv.org/abs/2508.10745", "categories": ["Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)", "Multimedia (cs.MM)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种名为Agentic设计评审系统（AgenticDRS）的新方法，通过多个代理协作分析设计，由元代理协调，采用基于图匹配的上下文范例选择方法和独特的提示扩展方法，使每个代理都能意识到设计。通过DRS-BENCH基准评估，实验证明Agentic-DRS在评估图形设计和生成可操作反馈方面的有效性。", "motivation": "解决从多个方面（如对齐、构图、美学和颜色选择）全面评估图形设计的问题，以及如何聚合来自个体专家评审员的反馈。", "method": "提出了Agentic设计评审系统（AgenticDRS），其中多个代理在元代理的协调下协作分析设计，采用了基于图匹配的上下文范例选择方法和独特的提示扩展方法。", "result": "通过DRS-BENCH基准评估，Agentic-DRS在评估图形设计和生成可操作反馈方面表现出色，优于现有的基线方法。", "conclusion": "Agentic-DRS为图形设计的评估和反馈生成提供了一种有效的方法，希望这项工作能引起对这一实用但尚未充分探索的研究方向的关注。"}}
{"id": "2508.10833", "title": "UI-Venus Technical Report: Building High-performance UI Agents with RFT", "authors": ["Zhangxuan Gu", "Zhengwen Zeng", "Zhenyu Xu", "Xingran Zhou", "Shuheng Shen", "Yunfei Liu", "Beitong Zhou", "Changhua Meng", "Tianyu Xia", "Weizhi Chen", "Yue Wen", "Jingya Dou", "Fei Tang", "Jinzhen Lin", "Yulin Liu", "Zhenlin Guo", "Yichen Gong", "Heng Jia", "Changlong Gao", "Yuan Guo", "Yong Deng", "Zhenyu Guo", "Liang Chen", "Weiqiang Wang"], "abstract": "We present UI-Venus, a native UI agent that takes only screenshots as input based on a multimodal large language model. UI-Venus achieves SOTA performance on both UI grounding and navigation tasks using only several hundred thousand high-quality training samples through reinforcement finetune (RFT) based on Qwen2.5-VL. Specifically, the 7B and 72B variants of UI-Venus obtain 94.1% / 50.8% and 95.3% / 61.9% on the standard grounding benchmarks, i.e., Screenspot-V2 / Pro, surpassing the previous SOTA baselines including open-source GTA1 and closed-source", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10833.pdf", "abstract_url": "https://arxiv.org/abs/2508.10833", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "UI-Venus是一种基于多模态大语言模型的原生UI代理，仅以截图作为输入，通过基于Qwen2.5-VL的强化微调（RFT）方法，在UI接地和导航任务上实现了SOTA性能。", "motivation": "解决在仅使用截图作为输入的情况下，提高UI代理在接地和导航任务上的性能问题。", "method": "采用基于Qwen2.5-VL的强化微调（RFT）方法，使用数十万高质量训练样本进行训练。", "result": "UI-Venus的7B和72B变体在标准接地基准测试Screenspot-V2 / Pro上分别取得了94.1% / 50.8%和95.3% / 61.9%的成绩，超越了包括开源GTA1和闭源模型在内的先前SOTA基线。", "conclusion": "UI-Venus展示了通过RFT方法，即使在有限的高质量训练样本下，也能构建出高性能的UI代理，为UI相关任务提供了新的解决方案。"}}
{"id": "2508.10419", "title": "ComoRAG: A Cognitive-Inspired Memory-Organized RAG for Stateful Long Narrative Reasoning", "authors": ["Juyuan Wang", "Rongchen Zhao", "Wei Wei", "Yufeng Wang", "Mo Yu", "Jie Zhou", "Jin Xu", "Liyan Xu"], "abstract": "Narrative comprehension on long stories and novels has been a challenging domain attributed to their intricate plotlines and entangled, often evolving relations among characters and entities. Given the LLM's diminished reasoning over extended context and high computational cost, retrieval-based approaches remain a pivotal role in practice. However, traditional RAG methods can fall short due to their stateless, single-step retrieval process, which often overlooks the dynamic nature of capturing interconnected relations within long-range context. In this work, we propose ComoRAG, holding the principle that narrative reasoning is not a one-shot process, but a dynamic, evolving interplay between new evidence acquisition and past knowledge consolidation, analogous to human cognition when reasoning with memory-related signals in the brain. Specifically, when encountering a reasoning impasse, ComoRAG undergoes iterative reasoning cycles while interacting with a dynamic memory workspace. In each cycle, it generates probing queries to devise new exploratory paths, then integrates the retrieved evidence of new aspects into a global memory pool, thereby supporting the emergence of a coherent context for the query resolution. Across four challenging long-context narrative benchmarks (200K+ tokens), ComoRAG outperforms strong RAG baselines with consistent relative gains up to 11% compared to the strongest baseline. Further analysis reveals that ComoRAG is particularly advantageous for complex queries requiring global comprehension, offering a principled, cognitively motivated paradigm for retrieval-based long context comprehension towards stateful reasoning. Our code is publicly released at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10419.pdf", "abstract_url": "https://arxiv.org/abs/2508.10419", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "ComoRAG是一种受认知启发的记忆组织检索增强生成方法，用于有状态的长叙事推理，通过动态记忆工作空间和迭代推理循环，显著提高了长上下文叙事理解的表现。", "motivation": "解决长故事和小说中复杂的剧情线和角色关系变化带来的叙事理解挑战，以及传统RAG方法在捕捉长范围上下文中动态关系时的不足。", "method": "提出ComoRAG方法，模拟人类认知过程中的记忆相关信号处理，通过迭代推理循环和动态记忆工作空间，生成探测查询并整合新证据到全局记忆池中。", "result": "在四个挑战性的长上下文叙事基准测试（200K+ tokens）中，ComoRAG相比最强的RAG基线有高达11%的相对增益，特别适用于需要全局理解的复杂查询。", "conclusion": "ComoRAG为基于检索的长上下文理解提供了一个有原则、受认知启发的范式，推动了有状态推理的发展。"}}
{"id": "2508.10769", "title": "Modeling Human Responses to Multimodal AI Content", "authors": ["Zhiqi Shen", "Shaojing Fan", "Danni Xu", "Terence Sim", "Mohan Kankanhalli"], "abstract": "As AI-generated content becomes widespread, so does the risk of misinformation. While prior research has primarily focused on identifying whether content is authentic, much less is known about how such content influences human perception and behavior. In domains like trading or the stock market, predicting how people react (e.g., whether a news post will go viral), can be more critical than verifying its factual accuracy. To address this, we take a human-centered approach and introduce the MhAIM Dataset, which contains 154,552 online posts (111,153 of them AI-generated), enabling large-scale analysis of how people respond to AI-generated content. Our human study reveals that people are better at identifying AI content when posts include both text and visuals, particularly when inconsistencies exist between the two. We propose three new metrics: trustworthiness, impact, and openness, to quantify how users judge and engage with online content. We present T-Lens, an LLM-based agent system designed to answer user queries by incorporating predicted human responses to multimodal information. At its core is HR-MCP (Human Response Model Context Protocol), built on the standardized Model Context Protocol (MCP), enabling seamless integration with any LLM. This integration allows T-Lens to better align with human reactions, enhancing both interpretability and interaction capabilities. Our work provides empirical insights and practical tools to equip LLMs with human-awareness capabilities. By highlighting the complex interplay among AI, human cognition, and information reception, our findings suggest actionable strategies for mitigating the risks of AI-driven misinformation.", "subjects": "Artificial Intelligence (cs.AI); Multimedia (cs.MM)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10769.pdf", "abstract_url": "https://arxiv.org/abs/2508.10769", "categories": ["Artificial Intelligence (cs.AI)", "Multimedia (cs.MM)"], "matching_keywords": ["agent"], "AI": {"tldr": "随着AI生成内容的普及，错误信息的风险也随之增加。本文通过引入MhAIM数据集和研究人类对AI生成内容的反应，提出了三个新指标和T-Lens系统，以增强LLMs的人类意识能力。", "motivation": "解决AI生成内容对人类感知和行为影响的研究不足问题，特别是在交易或股票市场等领域，预测人们如何反应比验证事实准确性更为关键。", "method": "采用以人为中心的方法，引入MhAIM数据集，进行大规模分析，并提出三个新指标（可信度、影响力和开放性）来量化用户如何判断和参与在线内容。开发了T-Lens，一个基于LLM的代理系统，通过整合预测的人类对多模态信息的反应来回答用户查询。", "result": "研究发现，当帖子同时包含文本和视觉内容时，人们更擅长识别AI内容，尤其是当两者之间存在不一致时。T-Lens系统通过HR-MCP协议与任何LLM无缝集成，更好地与人类反应对齐，增强了可解释性和互动能力。", "conclusion": "本研究提供了实证见解和实用工具，使LLMs具备人类意识能力。通过强调AI、人类认知和信息接收之间复杂的相互作用，我们的发现提出了减轻AI驱动错误信息风险的可操作策略。"}}
{"id": "2508.10695", "title": "Learning from Natural Language Feedback for Personalized Question Answering", "authors": ["Alireza Salemi", "Hamed Zamani"], "abstract": "Personalization is crucial for enhancing both the effectiveness and user satisfaction of language technologies, particularly in information-seeking tasks like question answering. Current approaches for personalizing large language models (LLMs) often rely on retrieval-augmented generation (RAG), followed by reinforcement learning with scalar reward signals to teach models how to use retrieved personal context. We believe that these scalar rewards sometimes provide weak, non-instructive feedback, limiting learning efficiency and personalization quality. We introduce VAC, a novel framework for personalized response generation that replaces scalar rewards with natural language feedback (NLF) that are generated conditioned on the user profiles and the question narratives. NLF serves as a rich and actionable supervision signal, allowing the policy model to iteratively refine its outputs and internalize effective personalization strategies. Training alternates between optimizing the feedback model and fine-tuning the policy model on the improved responses, resulting in a policy model that no longer requires feedback at inference. Evaluation on the LaMP-QA benchmark that consists of three diverse domains demonstrates consistent and significant improvements over the state-of-the-art results. Human evaluations further confirm the superior quality of the generated responses. These results demonstrate that NLF provides more effective signals for optimizing personalized question answering.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10695.pdf", "abstract_url": "https://arxiv.org/abs/2508.10695", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了VAC框架，通过自然语言反馈（NLF）替代标量奖励，优化个性化问答系统的响应生成，提高了学习效率和个性化质量。", "motivation": "当前基于检索增强生成（RAG）和标量奖励信号的个性化大型语言模型（LLMs）方法，反馈信号弱且非指导性，限制了学习效率和个性化质量。", "method": "提出VAC框架，利用自然语言反馈（NLF）作为丰富且可操作的监督信号，通过交替优化反馈模型和微调策略模型，实现无需推理时反馈的策略模型。", "result": "在LaMP-QA基准测试中，VAC框架在三个不同领域均显示出对现有技术的显著改进，人类评估也证实了生成响应的优越质量。", "conclusion": "自然语言反馈（NLF）为优化个性化问答提供了更有效的信号，显著提升了模型的个性化能力和响应质量。"}}
{"id": "2508.10839", "title": "Reinforced Language Models for Sequential Decision Making", "authors": ["Jim Dilkes", "Vahid Yazdanpanah", "Sebastian Stein"], "abstract": "Large Language Models (LLMs) show potential as sequential decision-making agents, but their application is often limited due to a reliance on large, computationally expensive models. This creates a need to improve smaller models, yet existing post-training methods are designed for single-turn interactions and cannot handle credit assignment in multi-step agentic tasks. To address this, we introduce Multi-Step Group-Relative Policy Optimization (MS-GRPO), a new algorithm for post-training LLM agents, grounded in formal Text-Mediated Stochastic Game (TSMG) and Language-Agent Policy (LAP) frameworks. For credit assignment, MS-GRPO attributes the entire cumulative episode reward to each individual episode step. We supplement this algorithm with a novel absolute-advantage-weighted episode sampling strategy that we show improves training performance. We evaluate our approach by post-training a 3-billion parameter model on Snake and Frozen Lake. Our experiments demonstrate that the method is effective in improving decision-making performance: our post-trained 3B parameter model outperforms a 72B parameter baseline by 50% on the Frozen Lake task. This work demonstrates that targeted post-training is a practical and efficient alternative to relying on model scale for creating sequential decision-making agents using LLMs.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10839.pdf", "abstract_url": "https://arxiv.org/abs/2508.10839", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了MS-GRPO算法，一种用于后训练大型语言模型（LLMs）作为顺序决策代理的新方法，旨在解决小模型在多步代理任务中的信用分配问题。通过在Snake和Frozen Lake任务上的实验，证明了该方法的有效性。", "motivation": "大型语言模型（LLMs）作为顺序决策代理的潜力受到依赖大型、计算昂贵模型的限制，现有后训练方法无法处理多步代理任务中的信用分配问题。", "method": "引入了基于Text-Mediated Stochastic Game (TSMG)和Language-Agent Policy (LAP)框架的Multi-Step Group-Relative Policy Optimization (MS-GRPO)算法，以及一种新的绝对优势加权片段采样策略。", "result": "实验显示，后训练的3B参数模型在Frozen Lake任务上比72B参数的基线模型性能高出50%。", "conclusion": "针对性的后训练是创建顺序决策代理的一种实用且高效的方法，可以替代依赖模型规模的传统方法。"}}
{"id": "2508.10426", "title": "Computational Economics in Large Language Models: Exploring Model Behavior and Incentive Design under Resource Constraints", "authors": ["Sandeep Reddy", "Kabir Khan", "Rohit Patil", "Ananya Chakraborty", "Faizan A. Khan", "Swati Kulkarni", "Arjun Verma", "Neha Singh"], "abstract": "Large language models (LLMs) are limited by substantial computational cost. We introduce a \"computational economics\" framework that treats an LLM as an internal economy of resource-constrained agents (attention heads and neuron blocks) that must allocate scarce computation to maximize task utility. First, we show empirically that when computation is scarce, standard LLMs reallocate attention toward high-value tokens while preserving accuracy. Building on this observation, we propose an incentive-driven training paradigm that augments the task loss with a differentiable computation cost term, encouraging sparse and efficient activations. On GLUE (MNLI, STS-B, CoLA) and WikiText-103, the method yields a family of models that trace a Pareto frontier and consistently dominate post-hoc pruning; for a similar accuracy we obtain roughly a forty percent reduction in FLOPS and lower latency, together with more interpretable attention patterns. These results indicate that economic principles offer a principled route to designing efficient, adaptive, and more transparent LLMs under strict resource constraints.", "subjects": "Computation and Language (cs.CL)", "comments": "Preprint; 7 figures, 4 tables, 1 algorithm. Experiments on GLUE (MNLI, STS-B, CoLA) and WikiText-103 with BERT-base; evaluation includes FLOPS, latency, Gini and entropy metrics", "pdf_url": "https://arxiv.org/pdf/2508.10426.pdf", "abstract_url": "https://arxiv.org/abs/2508.10426", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种‘计算经济学’框架，将大型语言模型（LLMs）视为资源受限的代理（注意力头和神经元块）的内部经济，旨在最大化任务效用。通过实证显示，在计算资源稀缺时，标准LLMs会重新分配注意力至高价值令牌，同时保持准确性。基于此，作者提出了一种激励驱动的训练范式，通过在任务损失中加入可微分的计算成本项，鼓励稀疏和高效的激活。在GLUE和WikiText-103上的实验表明，该方法生成了一系列模型，这些模型在Pareto前沿上表现优异，相比事后修剪，在相似准确度下实现了约40%的FLOPS减少和更低延迟，同时注意力模式更具解释性。", "motivation": "大型语言模型（LLMs）面临高昂的计算成本限制。本研究旨在探索在资源约束下，如何通过经济原则设计高效、自适应且更透明的LLMs。", "method": "引入‘计算经济学’框架，将LLMs视为资源受限代理的内部经济；提出激励驱动的训练范式，通过增加可微分的计算成本项到任务损失中，鼓励稀疏和高效的激活。", "result": "在GLUE（MNLI, STS-B, CoLA）和WikiText-103上，该方法生成的模型在Pareto前沿上表现优异，相比事后修剪，在相似准确度下实现了约40%的FLOPS减少和更低延迟，注意力模式也更易解释。", "conclusion": "经济原则为在严格资源约束下设计高效、自适应且更透明的大型语言模型提供了原则性路径。"}}
{"id": "2508.10874", "title": "SSRL: Self-Search Reinforcement Learning", "authors": ["Yuchen Fan", "Kaiyan Zhang", "Heng Zhou", "Yuxin Zuo", "Yanxu Chen", "Yu Fu", "Xinwei Long", "Xuekai Zhu", "Che Jiang", "Yuchen Zhang", "Li Kang", "Gang Chen", "Cheng Huang", "Zhizhou He", "Bingning Wang", "Lei Bai", "Ning Ding", "Bowen Zhou"], "abstract": "We investigate the potential of large language models (LLMs) to serve as efficient simulators for agentic search tasks in reinforcement learning (RL), thereby reducing dependence on costly interactions with external search engines. To this end, we first quantify the intrinsic search capability of LLMs via structured prompting and repeated sampling, which we term Self-Search. Our results reveal that LLMs exhibit strong scaling behavior with respect to the inference budget, achieving high pass@k on question-answering benchmarks, including the challenging BrowseComp task. Building on these observations, we introduce Self-Search RL (SSRL), which enhances LLMs' Self-Search capability through format-based and rule-based rewards. SSRL enables models to iteratively refine their knowledge utilization internally, without requiring access to external tools. Empirical evaluations demonstrate that SSRL-trained policy models provide a cost-effective and stable environment for search-driven RL training, reducing reliance on external search engines and facilitating robust sim-to-real transfer. We draw the following conclusions: 1) LLMs possess world knowledge that can be effectively elicited to achieve high performance; 2) SSRL demonstrates the potential of leveraging internal knowledge to reduce hallucination; 3) SSRL-trained models integrate seamlessly with external search engines without additional effort. Our findings highlight the potential of LLMs to support more scalable RL agent training.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10874.pdf", "abstract_url": "https://arxiv.org/abs/2508.10874", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文探讨了大型语言模型（LLMs）作为强化学习（RL）中代理搜索任务的高效模拟器的潜力，以减少对外部搜索引擎的依赖。通过结构化提示和重复采样量化LLMs的自我搜索能力，并引入自我搜索强化学习（SSRL）来增强这一能力。", "motivation": "减少强化学习中对外部搜索引擎的依赖，利用LLMs的内部知识提高搜索效率和降低成本。", "method": "通过结构化提示和重复采样量化LLMs的自我搜索能力，并引入SSRL，通过基于格式和基于规则的奖励来增强LLMs的自我搜索能力。", "result": "LLMs在推理预算方面表现出强烈的缩放行为，在问答基准测试中达到高pass@k。SSRL训练的模型为搜索驱动的RL训练提供了成本效益高且稳定的环境，减少了对外部搜索引擎的依赖。", "conclusion": "LLMs的世界知识可以被有效利用以实现高性能；SSRL展示了利用内部知识减少幻觉的潜力；SSRL训练的模型无需额外努力即可与外部搜索引擎无缝集成。这些发现突出了LLMs支持更可扩展的RL代理训练的潜力。"}}
{"id": "2508.10052", "title": "NetMoniAI: An Agentic AI Framework for Network Security & Monitoring", "authors": ["Pallavi Zambare", "Venkata Nikhil Thanikella", "Nikhil Padmanabh Kottur", "Sree Akhil Akula", "Ying Liu"], "abstract": "In this paper, we present NetMoniAI, an agentic AI framework for automatic network monitoring and security that integrates decentralized analysis with lightweight centralized coordination. The framework consists of two layers: autonomous micro-agents at each node perform local traffic analysis and anomaly detection. A central controller then aggregates insights across nodes to detect coordinated attacks and maintain system-wide situational awareness. We evaluated NetMoniAI on a local micro-testbed and through NS-3 simulations. Results confirm that the two-tier agentic-AI design scales under resource constraints, reduces redundancy, and improves response time without compromising accuracy. To facilitate broader adoption and reproducibility, the complete framework is available as open source. This enables researchers and practitioners to replicate, validate, and extend it across diverse network environments and threat scenarios. Github link:", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": "Accepted in IEEE 3rd International Conference on Artificial Intelligence, Blockchain, and Internet of Things (AIBThings 2025)", "pdf_url": "https://arxiv.org/pdf/2508.10052.pdf", "abstract_url": "https://arxiv.org/abs/2508.10052", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了NetMoniAI，一个用于自动网络监控和安全的代理AI框架，结合了分散分析和轻量级集中协调。", "motivation": "解决网络监控和安全中的自动化和可扩展性问题，特别是在资源受限的环境中。", "method": "采用两层级设计：节点上的自主微代理进行本地流量分析和异常检测，中央控制器聚合节点洞察以检测协调攻击。", "result": "评估显示，该设计在资源限制下可扩展，减少冗余，提高响应时间而不影响准确性。", "conclusion": "NetMoniAI作为一个开源框架，促进了更广泛的采用和可重复性，适用于多样化的网络环境和威胁场景。"}}
{"id": "2508.10043", "title": "Securing Agentic AI: Threat Modeling and Risk Analysis for Network Monitoring Agentic AI System", "authors": ["Pallavi Zambare", "Venkata Nikhil Thanikella", "Ying Liu"], "abstract": "When combining Large Language Models (LLMs) with autonomous agents, used in network monitoring and decision-making systems, this will create serious security issues. In this research, the MAESTRO framework consisting of the seven layers threat modeling architecture in the system was used to expose, evaluate, and eliminate vulnerabilities of agentic AI. The prototype agent system was constructed and implemented, using Python, LangChain, and telemetry in WebSockets, and deployed with inference, memory, parameter tuning, and anomaly detection modules. Two practical threat cases were confirmed as follows: (i) resource denial of service by traffic replay denial-of-service, and (ii) memory poisoning by tampering with the historical log file maintained by the agent. These situations resulted in measurable levels of performance degradation, i.e. telemetry updates were delayed, and computational loads were increased, as a result of poor system adaptations. It was suggested to use a multilayered defense-in-depth approach with memory isolation, validation of planners and anomaly response systems in real-time. These findings verify that MAESTRO is viable in operational threat mapping, prospective risk scoring, and the basis of the resilient system design. The authors bring attention to the importance of the enforcement of memory integrity, paying attention to the adaptation logic monitoring, and cross-layer communication protection that guarantee the agentic AI reliability in adversarial settings.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": "Submitted and under review in IEEE Transactions on Privacy", "pdf_url": "https://arxiv.org/pdf/2508.10043.pdf", "abstract_url": "https://arxiv.org/abs/2508.10043", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本研究探讨了将大型语言模型（LLMs）与自主代理结合用于网络监控和决策系统时引发的安全问题，提出了MAESTRO框架进行威胁建模和风险分析，并通过原型系统验证了两种实际威胁案例，提出了多层防御策略以确保代理AI的可靠性。", "motivation": "结合大型语言模型（LLMs）和自主代理用于网络监控和决策系统会引发严重的安全问题，本研究旨在通过MAESTRO框架揭示、评估和消除代理AI的漏洞。", "method": "使用MAESTRO框架的七层威胁建模架构，构建并实现了一个原型代理系统，该系统采用Python、LangChain和WebSockets的遥测技术，部署了推理、内存、参数调整和异常检测模块。", "result": "确认了两种实际威胁案例：通过流量重放拒绝服务导致的资源拒绝服务和通过篡改代理维护的历史日志文件导致的内存中毒。这些情况导致了可测量的性能下降，如遥测更新延迟和计算负载增加。", "conclusion": "研究建议采用多层防御深度方法，包括内存隔离、规划者验证和实时异常响应系统，以确保代理AI在对抗性环境中的可靠性。MAESTRO框架在操作威胁映射、前瞻性风险评分和弹性系统设计基础上被验证为可行。"}}
{"id": "2508.10333", "title": "ReconVLA: Reconstructive Vision-Language-Action Model as Effective Robot Perceiver", "authors": ["Wenxuan Song", "Ziyang Zhou", "Han Zhao", "Jiayi Chen", "Pengxiang Ding", "Haodong Yan", "Yuxin Huang", "Feilong Tang", "Donglin Wang", "Haoang Li"], "abstract": "Recent advances in Vision-Language-Action (VLA) models have enabled robotic agents to integrate multimodal understanding with action execution. However, our empirical analysis reveals that current VLAs struggle to allocate visual attention to target regions. Instead, visual attention is always dispersed. To guide the visual attention grounding on the correct target, we propose ReconVLA, a reconstructive VLA model with an implicit grounding paradigm. Conditioned on the model's visual outputs, a diffusion transformer aims to reconstruct the gaze region of the image, which corresponds to the target manipulated objects. This process prompts the VLA model to learn fine-grained representations and accurately allocate visual attention, thus effectively leveraging task-specific visual information and conducting precise manipulation. Moreover, we curate a large-scale pretraining dataset comprising over 100k trajectories and 2 million data samples from open-source robotic datasets, further boosting the model's generalization in visual reconstruction. Extensive experiments in simulation and the real world demonstrate the superiority of our implicit grounding method, showcasing its capabilities of precise manipulation and generalization. Our project page is", "subjects": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10333.pdf", "abstract_url": "https://arxiv.org/abs/2508.10333", "categories": ["Robotics (cs.RO)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了ReconVLA，一种重建性的视觉-语言-动作（VLA）模型，通过隐式接地范式指导视觉注意力集中在正确的目标区域，以提高机器人感知器的效能。", "motivation": "当前的VLA模型在分配视觉注意力到目标区域方面存在困难，视觉注意力总是分散的，这限制了机器人执行精确操作的能力。", "method": "提出ReconVLA模型，利用扩散变换器基于模型的视觉输出重建图像的注视区域，对应于操作的目标物体，从而学习细粒度表示并准确分配视觉注意力。", "result": "通过在仿真和现实世界中的大量实验，证明了隐式接地方法的优越性，展示了其在精确操作和泛化方面的能力。", "conclusion": "ReconVLA通过重建视觉注视区域，有效提升了机器人对任务特定视觉信息的利用和精确操作的能力，同时通过大规模预训练数据集增强了模型的泛化能力。"}}
{"id": "2508.10068", "title": "SaraCoder: Orchestrating Semantic and Structural Cues for Profit-Oriented Repository-Level Code Completion", "authors": ["Xiaohan Chen", "Zhongying Pan", "Quan Feng", "Yu Tian", "Shuqun Yang", "Mengru Wang", "Lina Gong", "Yuxia Geng", "Piji Li", "Xiang Chen"], "abstract": "Retrieval-augmented generation (RAG) for repository-level code completion commonly relies on superficial text similarity, leading to results plagued by semantic misguidance, redundancy, and homogeneity, while also failing to resolve external symbol ambiguity. To address these challenges, we introduce Saracoder, a Hierarchical Feature-Optimized retrieval framework. Its core Hierarchical Feature Optimization module systematically refines candidates by distilling deep semantic relationships, pruning exact duplicates, assessing structural similarity with a novel graph-based metric that weighs edits by their topological importance, and reranking results to maximize both relevance and diversity. Furthermore, an External-Aware Identifier Disambiguator module accurately resolves cross-file symbol ambiguity via dependency analysis. Extensive experiments on the challenging CrossCodeEval and RepoEval-Updated benchmarks demonstrate that Saracoder significantly outperforms existing baselines across multiple programming languages and models. Our work proves that systematically refining retrieval results across multiple dimensions provides a new paradigm for building more accurate and robust repository-level code completion systems.", "subjects": "Software Engineering (cs.SE); Computation and Language (cs.CL); Information Retrieval (cs.IR); Programming Languages (cs.PL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10068.pdf", "abstract_url": "https://arxiv.org/abs/2508.10068", "categories": ["Software Engineering (cs.SE)", "Computation and Language (cs.CL)", "Information Retrieval (cs.IR)", "Programming Languages (cs.PL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "Saracoder是一个层次特征优化的检索框架，用于解决基于检索增强生成的仓库级代码补全中的语义误导、冗余和同质性问题，通过深度语义关系提炼、结构相似性评估和外部符号消歧，显著提高了代码补全的准确性和鲁棒性。", "motivation": "解决现有基于检索增强生成的仓库级代码补全方法中因依赖表面文本相似性而导致的语义误导、冗余、同质性及外部符号歧义问题。", "method": "引入Saracoder，一个层次特征优化的检索框架，包括层次特征优化模块和外部感知标识符消歧模块，通过深度语义关系提炼、结构相似性评估和依赖分析来优化检索结果。", "result": "在CrossCodeEval和RepoEval-Updated基准测试中，Saracoder在多种编程语言和模型上显著优于现有基线方法。", "conclusion": "系统地从多个维度优化检索结果为构建更准确、更鲁棒的仓库级代码补全系统提供了新范式。"}}
{"id": "2508.10880", "title": "Searching for Privacy Risks in LLM Agents via Simulation", "authors": ["Yanzhe Zhang", "Diyi Yang"], "abstract": "The widespread deployment of LLM-based agents is likely to introduce a critical privacy threat: malicious agents that proactively engage others in multi-turn interactions to extract sensitive information. These dynamic dialogues enable adaptive attack strategies that can cause severe privacy violations, yet their evolving nature makes it difficult to anticipate and discover sophisticated vulnerabilities manually. To tackle this problem, we present a search-based framework that alternates between improving attacker and defender instructions by simulating privacy-critical agent interactions. Each simulation involves three roles: data subject, data sender, and data recipient. While the data subject's behavior is fixed, the attacker (data recipient) attempts to extract sensitive information from the defender (data sender) through persistent and interactive exchanges. To explore this interaction space efficiently, our search algorithm employs LLMs as optimizers, using parallel search with multiple threads and cross-thread propagation to analyze simulation trajectories and iteratively propose new instructions. Through this process, we find that attack strategies escalate from simple direct requests to sophisticated multi-turn tactics such as impersonation and consent forgery, while defenses advance from rule-based constraints to identity-verification state machines. The discovered attacks and defenses transfer across diverse scenarios and backbone models, demonstrating strong practical utility for building privacy-aware agents.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "Preprint", "pdf_url": "https://arxiv.org/pdf/2508.10880.pdf", "abstract_url": "https://arxiv.org/abs/2508.10880", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于搜索的框架，通过模拟隐私关键的代理交互来发现LLM代理中的隐私风险，展示了攻击策略从简单请求升级到复杂多轮战术的演变，以及防御措施的进步。", "motivation": "解决LLM基础代理广泛部署可能带来的隐私威胁，特别是恶意代理通过多轮交互提取敏感信息的风险。", "method": "采用搜索框架，通过模拟涉及数据主体、数据发送者和数据接收者的隐私关键代理交互，利用LLM作为优化器进行并行搜索和多线程传播，迭代提出新指令。", "result": "发现攻击策略从直接请求演变为复杂的多轮战术，如冒充和伪造同意，而防御措施则从基于规则的约束发展到身份验证状态机。", "conclusion": "所发现的攻击和防御策略在多样化的场景和骨干模型中具有转移能力，为构建隐私意识代理提供了强大的实用价值。"}}
{"id": "2508.10409", "title": "AnalogSeeker: An Open-source Foundation Language Model for Analog Circuit Design", "authors": ["Zihao Chen", "Ji Zhuang", "Jinyi Shen", "Xiaoyue Ke", "Xinyi Yang", "Mingjie Zhou", "Zhuoyao Du", "Xu Yan", "Zhouyang Wu", "Zhenyu Xu", "Jiangli Huang", "Li Shang", "Xuan Zeng", "Fan Yang"], "abstract": "In this paper, we propose AnalogSeeker, an effort toward an open-source foundation language model for analog circuit design, with the aim of integrating domain knowledge and giving design assistance. To overcome the scarcity of data in this field, we employ a corpus collection strategy based on the domain knowledge framework of analog circuits. High-quality, accessible textbooks across relevant subfields are systematically curated and cleaned into a textual domain corpus. To address the complexity of knowledge of analog circuits, we introduce a granular domain knowledge distillation method. Raw, unlabeled domain corpus is decomposed into typical, granular learning nodes, where a multi-agent framework distills implicit knowledge embedded in unstructured text into question-answer data pairs with detailed reasoning processes, yielding a fine-grained, learnable dataset for fine-tuning. To address the unexplored challenges in training analog circuit foundation models, we explore and share our training methods through both theoretical analysis and experimental validation. We finally establish a fine-tuning-centric training paradigm, customizing and implementing a neighborhood self-constrained supervised fine-tuning algorithm. This approach enhances training outcomes by constraining the perturbation magnitude between the model's output distributions before and after training. In practice, we train the Qwen2.5-32B-Instruct model to obtain AnalogSeeker, which achieves 85.04% accuracy on AMSBench-TQA, the analog circuit knowledge evaluation benchmark, with a 15.67% point improvement over the original model and is competitive with mainstream commercial models. Furthermore, AnalogSeeker also shows effectiveness in the downstream operational amplifier design task. AnalogSeeker is open-sourced at", "subjects": "Hardware Architecture (cs.AR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10409.pdf", "abstract_url": "https://arxiv.org/abs/2508.10409", "categories": ["Hardware Architecture (cs.AR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了AnalogSeeker，一个面向模拟电路设计的开源基础语言模型，旨在整合领域知识并提供设计辅助。通过领域知识蒸馏方法和创新的训练范式，该模型在模拟电路知识评估基准上取得了显著提升，并在下游应用中显示出有效性。", "motivation": "解决模拟电路设计领域数据稀缺和知识复杂性的问题，提供一个开源的基础语言模型来辅助设计。", "method": "采用基于模拟电路领域知识框架的语料收集策略，引入细粒度领域知识蒸馏方法，以及实施邻域自约束监督微调算法。", "result": "AnalogSeeker在AMSBench-TQA基准测试中达到85.04%的准确率，比原模型提高了15.67个百分点，并在下游应用中表现有效。", "conclusion": "AnalogSeeker作为一个开源模型，不仅提高了模拟电路设计的效率和准确性，还为该领域的进一步研究和应用提供了宝贵的资源。"}}
{"id": "2508.10494", "title": "A Unified Multi-Agent Framework for Universal Multimodal Understanding and Generation", "authors": ["Jiulin Li", "Ping Huang", "Yexin Li", "Shuo Chen", "Juewen Hu", "Ye Tian"], "abstract": "Real-world multimodal applications often require any-to-any capabilities, enabling both understanding and generation across modalities including text, image, audio, and video. However, integrating the strengths of autoregressive language models (LLMs) for reasoning and diffusion models for high-fidelity generation remains challenging. Existing approaches rely on rigid pipelines or tightly coupled architectures, limiting flexibility and scalability. We propose MAGUS (Multi-Agent Guided Unified Multimodal System), a modular framework that unifies multimodal understanding and generation via two decoupled phases: Cognition and Deliberation. MAGUS enables symbolic multi-agent collaboration within a shared textual workspace. In the Cognition phase, three role-conditioned multimodal LLM agents - Perceiver, Planner, and Reflector - engage in collaborative dialogue to perform structured understanding and planning. The Deliberation phase incorporates a Growth-Aware Search mechanism that orchestrates LLM-based reasoning and diffusion-based generation in a mutually reinforcing manner. MAGUS supports plug-and-play extensibility, scalable any-to-any modality conversion, and semantic alignment - all without the need for joint training. Experiments across multiple benchmarks, including image, video, and audio generation, as well as cross-modal instruction following, demonstrate that MAGUS outperforms strong baselines and state-of-the-art systems. Notably, on the MME benchmark, MAGUS surpasses the powerful closed-source model GPT-4o.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "8 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2508.10494.pdf", "abstract_url": "https://arxiv.org/abs/2508.10494", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "MAGUS是一个统一的多模态理解和生成框架，通过解耦的认知和审议阶段实现多模态转换，无需联合训练。", "motivation": "解决现实世界多模态应用中任意到任意模态转换的需求，克服现有方法在灵活性和可扩展性上的限制。", "method": "提出MAGUS框架，采用符号多代理协作和增长感知搜索机制，结合LLM推理和扩散模型生成。", "result": "在多个基准测试中，MAGUS表现优于现有系统和强大的闭源模型GPT-4o。", "conclusion": "MAGUS框架支持即插即用的扩展性，实现了无需联合训练的多模态理解和生成，展示了在多模态任务中的优越性能。"}}
{"id": "2508.10423", "title": "MASH: Cooperative-Heterogeneous Multi-Agent Reinforcement Learning for Single Humanoid Robot Locomotion", "authors": ["Qi Liu", "Xiaopeng Zhang", "Mingshan Tan", "Shuaikang Ma", "Jinliang Ding", "Yanjie Li"], "abstract": "This paper proposes a novel method to enhance locomotion for a single humanoid robot through cooperative-heterogeneous multi-agent deep reinforcement learning (MARL). While most existing methods typically employ single-agent reinforcement learning algorithms for a single humanoid robot or MARL algorithms for multi-robot system tasks, we propose a distinct paradigm: applying cooperative-heterogeneous MARL to optimize locomotion for a single humanoid robot. The proposed method, multi-agent reinforcement learning for single humanoid locomotion (MASH), treats each limb (legs and arms) as an independent agent that explores the robot's action space while sharing a global critic for cooperative learning. Experiments demonstrate that MASH accelerates training convergence and improves whole-body cooperation ability, outperforming conventional single-agent reinforcement learning methods. This work advances the integration of MARL into single-humanoid-robot control, offering new insights into efficient locomotion strategies.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Systems and Control (eess.SY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10423.pdf", "abstract_url": "https://arxiv.org/abs/2508.10423", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Systems and Control (eess.SY)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新颖的方法，通过协作异构多智能体深度强化学习（MARL）来增强单个人形机器人的运动能力。与现有方法通常使用单智能体强化学习算法或MARL算法于多机器人系统任务不同，我们提出了一种独特的范式：应用协作异构MARL来优化单个人形机器人的运动。所提出的方法MASH将每个肢体（腿和手臂）视为独立的智能体，探索机器人的动作空间，同时共享一个全局批评者进行协作学习。实验证明，MASH加速了训练收敛并提高了全身协作能力，优于传统的单智能体强化学习方法。", "motivation": "解决单个人形机器人运动优化的问题，传统方法通常使用单智能体强化学习或MARL于多机器人系统，而忽视了单机器人内部各肢体间的协作潜力。", "method": "提出MASH方法，将人形机器人的每个肢体视为独立的智能体，通过共享全局批评者进行协作学习，以优化机器人的运动。", "result": "实验结果显示，MASH方法在训练收敛速度和全身协作能力方面优于传统的单智能体强化学习方法。", "conclusion": "本研究推动了MARL在单个人形机器人控制中的应用，为高效运动策略提供了新的见解。"}}
{"id": "2508.10701", "title": "REFN: A Reinforcement-Learning-From-Network Framework against 1-day/n-day Exploitations", "authors": ["Tianlong Yu", "Lihong Liu", "Ziyi Zhou", "Fudu Xing", "Kailong Wang", "Yang Yang"], "abstract": "The exploitation of 1 day or n day vulnerabilities poses severe threats to networked devices due to massive deployment scales and delayed patching (average Mean Time To Patch exceeds 60 days). Existing defenses, including host based patching and network based filtering, are inadequate due to limited scalability across diverse devices, compatibility issues especially with embedded or legacy systems, and error prone deployment process (manual patch validation). To address these issues, we introduce REFN (Reinforcement Learning From Network), a novel framework that trains Large Language Models (LLMs) to autonomously generate network filters to prevent 1 day or n day exploitations. REFN ensures scalability by uniquely employs Reinforcement Learning (RL) driven by online network rewards instead of traditional Human Feedback (RLHF). REFN guarantees compatibility via unified deployment on edge security gateways (Amazon Eero). REFN provides robustness via online validation using real network traffic. Crucially, REFN addresses three core challenges in training LLMs for exploit prevention: 1) expanding current LLMs limited vulnerability fixing expertise via Agentic RAG based Knowledge Distillation, 2) bridging current LLMs language to network gaps through an RL From VNF Pipeline that translates language context (vulnerability description) into network enforcement, 3) addressing the LLM hallucination and non determinism via the Online Agentic Validation that penalizes erroneous outputs. Evaluated across 22 families of 1 day or n day exploits, REFN demonstrates effectiveness (21.1 percent higher accuracy than alternatives), efficiency (Mean Time To Patch of 3.65 hours) and scalability (easily scale to 10K devices). REFN serves as an initial step toward training LLMs to rapidly prevent massive scale 1 day or n day exploitations.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10701.pdf", "abstract_url": "https://arxiv.org/abs/2508.10701", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic", "@RAG"], "AI": {"tldr": "REFN是一个利用强化学习从网络中自主生成网络过滤器以防止1天或n天漏洞利用的新框架。", "motivation": "解决现有防御措施在跨设备扩展性、兼容性及部署过程中的不足，特别是针对大规模部署和延迟修补的1天或n天漏洞利用问题。", "method": "采用强化学习（RL）驱动的在线网络奖励训练大型语言模型（LLMs），通过Agentic RAG基于知识蒸馏、RL From VNF管道和在线Agentic验证来解决LLMs在漏洞修复中的核心挑战。", "result": "在22个1天或n天漏洞家族中评估，REFN显示出更高的准确性（比替代方案高21.1%）、效率（平均修补时间为3.65小时）和可扩展性（轻松扩展到10K设备）。", "conclusion": "REFN是训练LLMs快速防止大规模1天或n天漏洞利用的初步步骤，展示了在效果、效率和可扩展性方面的显著优势。"}}
{"id": "2508.10760", "title": "FROGENT: An End-to-End Full-process Drug Design Agent", "authors": ["Qihua Pan", "Dong Xu", "Jenna Xinyi Yao", "Lijia Ma", "Zexuan Zhu", "Junkai Ji"], "abstract": "Powerful AI tools for drug discovery reside in isolated web apps, desktop programs, and code libraries. Such fragmentation forces scientists to manage incompatible interfaces and specialized scripts, which can be a cumbersome and repetitive process. To address this issue, a Full-pROcess druG dEsign ageNT, named FROGENT, has been proposed. Specifically, FROGENT utilizes a Large Language Model and the Model Context Protocol to integrate multiple dynamic biochemical databases, extensible tool libraries, and task-specific AI models. This agentic framework allows FROGENT to execute complicated drug discovery workflows dynamically, including component tasks such as target identification, molecule generation and retrosynthetic planning. FROGENT has been evaluated on eight benchmarks that cover various aspects of drug discovery, such as knowledge retrieval, property prediction, virtual screening, mechanistic analysis, molecular design, and synthesis. It was compared against six increasingly advanced ReAct-style agents that support code execution and literature searches. Empirical results demonstrated that FROGENT triples the best baseline performance in hit-finding and doubles it in interaction profiling, significantly outperforming both the open-source model Qwen3-32B and the commercial model GPT-4o. In addition, real-world cases have been utilized to validate the practicability and generalization of FROGENT. This development suggests that streamlining the agentic drug discovery pipeline can significantly enhance researcher productivity.", "subjects": "Biomolecules (q-bio.BM); Artificial Intelligence (cs.AI)", "comments": "9 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2508.10760.pdf", "abstract_url": "https://arxiv.org/abs/2508.10760", "categories": ["Biomolecules (q-bio.BM)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "FROGENT是一个端到端的全流程药物设计代理，旨在解决药物发现中AI工具分散的问题，通过整合动态生化数据库、可扩展工具库和任务特定AI模型，显著提升研究效率。", "motivation": "解决药物发现中AI工具分散、接口不兼容和需要专门脚本管理的繁琐重复问题。", "method": "利用大型语言模型和模型上下文协议整合多个动态生化数据库、可扩展工具库和任务特定AI模型。", "result": "FROGENT在八个基准测试中显著优于基线性能，特别是在命中发现和相互作用分析方面，表现优于开源模型Qwen3-32B和商业模型GPT-4o。", "conclusion": "FROGENT的开发表明，通过流线化代理药物发现流程可以显著提高研究人员的生产力，其在实际案例中的验证也证明了其实用性和泛化能力。"}}
{"id": "2508.10872", "title": "TLE-Based A2C Agent for Terrestrial Coverage Orbital Path Planning", "authors": ["Anantha Narayanan", "Battu Bhanu Teja", "Pruthwik Mishra"], "abstract": "The increasing congestion of Low Earth Orbit (LEO) poses persistent challenges to the efficient deployment and safe operation of Earth observation satellites. Mission planners must now account not only for mission-specific requirements but also for the increasing collision risk with active satellites and space debris. This work presents a reinforcement learning framework using the Advantage Actor-Critic (A2C) algorithm to optimize satellite orbital parameters for precise terrestrial coverage within predefined surface radii. By formulating the problem as a Markov Decision Process (MDP) within a custom OpenAI Gymnasium environment, our method simulates orbital dynamics using classical Keplerian elements. The agent progressively learns to adjust five of the orbital parameters - semi-major axis, eccentricity, inclination, right ascension of ascending node, and the argument of perigee-to achieve targeted terrestrial coverage. Comparative evaluation against Proximal Policy Optimization (PPO) demonstrates A2C's superior performance, achieving 5.8x higher cumulative rewards (10.0 vs 9.263025) while converging in 31.5x fewer timesteps (2,000 vs 63,000). The A2C agent consistently meets mission objectives across diverse target coordinates while maintaining computational efficiency suitable for real-time mission planning applications. Key contributions include: (1) a TLE-based orbital simulation environment incorporating physics constraints, (2) validation of actor-critic methods' superiority over trust region approaches in continuous orbital control, and (3) demonstration of rapid convergence enabling adaptive satellite deployment. This approach establishes reinforcement learning as a computationally efficient alternative for scalable and intelligent LEO mission planning.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": "8 pages, 6 figures, 5 tables", "pdf_url": "https://arxiv.org/pdf/2508.10872.pdf", "abstract_url": "https://arxiv.org/abs/2508.10872", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于强化学习的框架，使用Advantage Actor-Critic (A2C)算法来优化卫星轨道参数，以实现精确的地面覆盖。通过与Proximal Policy Optimization (PPO)的比较，证明了A2C在累积奖励和收敛速度上的优越性。", "motivation": "低地球轨道(LEO)的日益拥挤给地球观测卫星的高效部署和安全运行带来了持续挑战。任务规划者现在不仅需要考虑任务特定要求，还需要考虑与活跃卫星和空间碎片碰撞风险的增加。", "method": "本研究通过在一个自定义的OpenAI Gymnasium环境中将问题表述为马尔可夫决策过程(MDP)，使用经典的Keplerian元素模拟轨道动力学。A2C算法被用来逐步学习调整五个轨道参数，以实现目标地面覆盖。", "result": "与PPO相比，A2C表现出更优的性能，累积奖励高出5.8倍(10.0 vs 9.263025)，且在31.5倍更少的时间步内收敛(2,000 vs 63,000)。A2C代理在各种目标坐标下一致满足任务目标，同时保持适合实时任务规划应用的计算效率。", "conclusion": "这种方法确立了强化学习作为一种计算效率高的替代方案，用于可扩展和智能的LEO任务规划。主要贡献包括：一个包含物理约束的基于TLE的轨道模拟环境，验证了actor-critic方法在连续轨道控制中优于信任区域方法，以及展示了快速收敛能力，使卫星部署具有适应性。"}}
