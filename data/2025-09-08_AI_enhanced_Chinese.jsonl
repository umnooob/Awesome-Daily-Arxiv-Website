{"id": "2509.04687", "title": "Guideline-Consistent Segmentation via Multi-Agent Refinement", "authors": ["Vanshika Vats", "Ashwani Rathee", "James Davis"], "abstract": "Semantic segmentation in real-world applications often requires not only accurate masks but also strict adherence to textual labeling guidelines. These guidelines are typically complex and long, and both human and automated labeling often fail to follow them faithfully. Traditional approaches depend on expensive task-specific retraining that must be repeated as the guidelines evolve. Although recent open-vocabulary segmentation methods excel with simple prompts, they often fail when confronted with sets of paragraph-length guidelines that specify intricate segmentation rules. To address this, we introduce a multi-agent, training-free framework that coordinates general-purpose vision-language models within an iterative Worker-Supervisor refinement architecture. The Worker performs the segmentation, the Supervisor critiques it against the retrieved guidelines, and a lightweight reinforcement learning stop policy decides when to terminate the loop, ensuring guideline-consistent masks while balancing resource use. Evaluated on the Waymo and ReasonSeg datasets, our method notably outperforms state-of-the-art baselines, demonstrating strong generalization and instruction adherence.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.04687.pdf", "abstract_url": "https://arxiv.org/abs/2509.04687", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出一种多智能体训练免费框架，通过迭代的Worker-Supervisor架构，结合视觉语言模型，确保语义分割符合复杂文本指南，在Waymo和ReasonSeg数据集上优于现有方法。", "motivation": "解决语义分割中准确性和遵循复杂文本指南的问题，传统方法需昂贵重训练，且开放词汇方法在段落长度指南下失败。", "method": "使用多智能体框架，Worker执行分割，Supervisor基于指南批评，轻量强化学习停止策略控制循环，无需训练。", "result": "在Waymo和ReasonSeg数据集上显著优于最先进基线，展示强泛化能力和指令遵循性。", "conclusion": "该方法有效平衡资源使用和指南一致性，适用于指南演变的场景，提升分割质量。"}}
{"id": "2509.04886", "title": "Cryo-RL: automating prostate cancer cryoablation planning with reinforcement learning", "authors": ["Trixia Simangan", "Ahmed Nadeem Abbasi", "Yipeng Hu", "Shaheer U. Saeed"], "abstract": "Cryoablation is a minimally invasive localised treatment for prostate cancer that destroys malignant tissue during de-freezing, while sparing surrounding healthy structures. Its success depends on accurate preoperative planning of cryoprobe placements to fully cover the tumour and avoid critical anatomy. This planning is currently manual, expertise-dependent, and time-consuming, leading to variability in treatment quality and limited scalability. In this work, we introduce Cryo-RL, a reinforcement learning framework that models cryoablation planning as a Markov decision process and learns an optimal policy for cryoprobe placement. Within a simulated environment that models clinical constraints and stochastic intraoperative variability, an agent sequentially selects cryoprobe positions and ice sphere diameters. Guided by a reward function based on tumour coverage, this agent learns a cryoablation strategy that leads to optimal cryoprobe placements without the need for any manually-designed plans. Evaluated on 583 retrospective prostate cancer cases, Cryo-RL achieved over 8 percentage-point Dice improvements compared with the best automated baselines, based on geometric optimisation, and matched human expert performance while requiring substantially less planning time. These results highlight the potential of reinforcement learning to deliver clinically viable, reproducible, and efficient cryoablation plans.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "Accepted at MICAD (Medical Imaging and Computer-Aided Diagnosis) 2025", "pdf_url": "https://arxiv.org/pdf/2509.04886.pdf", "abstract_url": "https://arxiv.org/abs/2509.04886", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "Cryo-RL 使用强化学习自动化前列腺癌冷冻消融规划，通过模拟环境和奖励函数优化探针放置，在 583 例病例中性能优于基线方法并匹配专家水平，减少规划时间。", "motivation": "当前冷冻消融规划依赖手动、耗时且易变，导致治疗质量不一致和可扩展性有限，需要自动化解决方案。", "method": "将规划建模为马尔可夫决策过程，使用强化学习在模拟环境中学习探针位置和冰球直径的选择策略，基于肿瘤覆盖率的奖励函数指导学习。", "result": "在回顾性病例中，Cryo-RL 的 Dice 分数比最佳自动化基线提高超过 8 个百分点，性能与人类专家相当，规划时间大幅减少。", "conclusion": "强化学习能提供临床可行、可重复且高效的冷冻消融计划，具有改善治疗质量和可扩展性的潜力。"}}
{"id": "2509.05263", "title": "LatticeWorld: A Multimodal Large Language Model-Empowered Framework for Interactive Complex World Generation", "authors": ["Yinglin Duan", "Zhengxia Zou", "Tongwei Gu", "Wei Jia", "Zhan Zhao", "Luyi Xu", "Xinzhu Liu", "Hao Jiang", "Kang Chen", "Shuang Qiu"], "abstract": "Recent research has been increasingly focusing on developing 3D world models that simulate complex real-world scenarios. World models have found broad applications across various domains, including embodied AI, autonomous driving, entertainment, etc. A more realistic simulation with accurate physics will effectively narrow the sim-to-real gap and allow us to gather rich information about the real world conveniently. While traditional manual modeling has enabled the creation of virtual 3D scenes, modern approaches have leveraged advanced machine learning algorithms for 3D world generation, with most recent advances focusing on generative methods that can create virtual worlds based on user instructions. This work explores such a research direction by proposing LatticeWorld, a simple yet effective 3D world generation framework that streamlines the industrial production pipeline of 3D environments. LatticeWorld leverages lightweight LLMs (LLaMA-2-7B) alongside the industry-grade rendering engine (e.g., Unreal Engine 5) to generate a dynamic environment. Our proposed framework accepts textual descriptions and visual instructions as multimodal inputs and creates large-scale 3D interactive worlds with dynamic agents, featuring competitive multi-agent interaction, high-fidelity physics simulation, and real-time rendering. We conduct comprehensive experiments to evaluate LatticeWorld, showing that it achieves superior accuracy in scene layout generation and visual fidelity. Moreover, LatticeWorld achieves over a $90\\times$ increase in industrial production efficiency while maintaining high creative quality compared with traditional manual production methods. Our demo video is available at", "subjects": "Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.05263.pdf", "abstract_url": "https://arxiv.org/abs/2509.05263", "categories": ["Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "LatticeWorld是一个基于多模态大语言模型和渲染引擎的3D世界生成框架，通过文本和视觉输入高效创建动态、交互式虚拟环境，提升工业生产效率。", "motivation": "解决传统手动建模在3D世界生成中效率低下的问题，并缩小模拟与现实的差距，以支持更广泛的应用如具身AI和自动驾驶。", "method": "利用轻量级LLM（如LLaMA-2-7B）和行业级渲染引擎（如Unreal Engine 5），接受多模态输入（文本和视觉指令）生成动态3D世界。", "result": "实验显示，LatticeWorld在场景布局生成和视觉保真度上表现优异，生产效率比传统方法提高90倍以上，同时保持高质量。", "conclusion": "LatticeWorld提供了一个高效且高质量的3D世界生成解决方案，有潜力革新工业生产和模拟应用。"}}
{"id": "2509.04456", "title": "Mentalic Net: Development of RAG-based Conversational AI and Evaluation Framework for Mental Health Support", "authors": ["Anandi Dutta", "Shivani Mruthyunjaya", "Jessica Saddington", "Kazi Sifatul Islam"], "abstract": "The emergence of large language models (LLMs) has unlocked boundless possibilities, along with significant challenges. In response, we developed a mental health support chatbot designed to augment professional healthcare, with a strong emphasis on safe and meaningful application. Our approach involved rigorous evaluation, covering accuracy, empathy, trustworthiness, privacy, and bias. We employed a retrieval-augmented generation (RAG) framework, integrated prompt engineering, and fine-tuned a pre-trained model on novel datasets. The resulting system, Mentalic Net Conversational AI, achieved a BERT Score of 0.898, with other evaluation metrics falling within satisfactory ranges. We advocate for a human-in-the-loop approach and a long-term, responsible strategy in developing such transformative technologies, recognizing both their potential to change lives and the risks they may pose if not carefully managed.", "subjects": "Computation and Language (cs.CL)", "comments": "Preprint Version, Accepted in ISEMV 2025", "pdf_url": "https://arxiv.org/pdf/2509.04456.pdf", "abstract_url": "https://arxiv.org/abs/2509.04456", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "开发了基于RAG的心理健康支持聊天机器人Mentalic Net，强调安全性和专业性，通过综合评估达到高BERT分数0.898，倡导负责任的人工智能发展。", "motivation": "解决大型语言模型在心理健康应用中可能带来的挑战，如准确性、同理心和偏见问题，以增强专业医疗支持。", "method": "采用检索增强生成（RAG）框架，结合提示工程和预训练模型微调，使用新数据集进行开发。", "result": "系统BERT Score为0.898，其他评估指标表现满意，显示出高准确性和可靠性。", "conclusion": "结论强调人类参与循环和长期负责任策略的重要性，以最大化技术潜力并管理风险。"}}
{"id": "2509.04465", "title": "Emotionally-Aware Agents for Dispute Resolution", "authors": ["Sushrita Rakshit", "James Hale", "Kushal Chawla", "Jeanne M. Brett", "Jonathan Gratch"], "abstract": "In conflict, people use emotional expressions to shape their counterparts' thoughts, feelings, and actions. This paper explores whether automatic text emotion recognition offers insight into this influence in the context of dispute resolution. Prior work has shown the promise of such methods in negotiations; however, disputes evoke stronger emotions and different social processes. We use a large corpus of buyer-seller dispute dialogues to investigate how emotional expressions shape subjective and objective outcomes. We further demonstrate that large-language models yield considerably greater explanatory power than previous methods for emotion intensity annotation and better match the decisions of human annotators. Findings support existing theoretical models for how emotional expressions contribute to conflict escalation and resolution and suggest that agent-based systems could be useful in managing disputes by recognizing and potentially mitigating emotional escalation.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.04465.pdf", "abstract_url": "https://arxiv.org/abs/2509.04465", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了在争议解决中，自动文本情感识别如何揭示情感表达对主观和客观结果的影响，并展示了大型语言模型在情感强度标注上的优越性，支持基于代理的系统管理情感升级。", "motivation": "解决争议中情感表达如何影响对方，以改进自动系统在冲突管理中的应用。", "method": "使用大型买家-卖家争议对话语料库，比较大型语言模型与传统方法的情感识别性能。", "result": "大型语言模型在情感强度标注上解释力更强，更匹配人类标注，支持情感表达导致冲突升级或解决的理论。", "conclusion": "基于代理的系统可通过识别和缓解情感升级来有效管理争议。"}}
{"id": "2509.04505", "title": "The Ethical Compass of the Machine: Evaluating Large Language Models for Decision Support in Construction Project Management", "authors": ["Somtochukwu Azie", "Yiping Meng"], "abstract": "The integration of Artificial Intelligence (AI) into construction project management (CPM) is accelerating, with Large Language Models (LLMs) emerging as accessible decision-support tools. This study aims to critically evaluate the ethical viability and reliability of LLMs when applied to the ethically sensitive, high-risk decision-making contexts inherent in CPM. A mixed-methods research design was employed, involving the quantitative performance testing of two leading LLMs against twelve real-world ethical scenarios using a novel Ethical Decision Support Assessment Checklist (EDSAC), and qualitative analysis of semi-structured interviews with 12 industry experts to capture professional perceptions. The findings reveal that while LLMs demonstrate adequate performance in structured domains such as legal compliance, they exhibit significant deficiencies in handling contextual nuance, ensuring accountability, and providing transparent reasoning. Stakeholders expressed considerable reservations regarding the autonomous use of AI for ethical judgments, strongly advocating for robust human-in-the-loop oversight. To our knowledge, this is one of the first studies to empirically test the ethical reasoning of LLMs within the construction domain. It introduces the EDSAC framework as a replicable methodology and provides actionable recommendations, emphasising that LLMs are currently best positioned as decision-support aids rather than autonomous ethical agents.", "subjects": "Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "comments": "16 Pages", "pdf_url": "https://arxiv.org/pdf/2509.04505.pdf", "abstract_url": "https://arxiv.org/abs/2509.04505", "categories": ["Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)"], "matching_keywords": ["agent"], "AI": {"tldr": "评估大型语言模型在建筑项目管理中作为决策支持工具的伦理可行性和可靠性，发现其在处理情境细微差别、确保问责制和提供透明推理方面存在显著不足，建议作为辅助工具而非自主伦理代理。", "motivation": "解决AI集成到建筑项目管理中时，LLMs在伦理敏感、高风险决策环境中的可靠性和伦理问题。", "method": "采用混合方法研究设计，包括定量测试两个领先LLMs在12个真实伦理场景中的表现（使用EDSAC清单），以及定性分析12位行业专家的半结构化访谈。", "result": "LLMs在结构化领域（如法律合规）表现良好，但在处理情境细微差别、确保问责制和提供透明推理方面有显著缺陷；利益相关者强烈主张人类监督。", "conclusion": "LLMs目前最适合作为决策支持辅助工具，而非自主伦理代理，并提出了EDSAC框架和可操作建议。"}}
{"id": "2509.04470", "title": "COCORELI: Cooperative, Compositional Reconstitution \\& Execution of Language Instructions", "authors": ["Swarnadeep Bhar", "Omar Naim", "Eleni Metheniti", "Bastien Navarri", "Loïc Cabannes", "Morteza Ezzabady", "Nicholas Asher"], "abstract": "We present COCORELI, a hybrid agent framework designed to tackle the limitations of large language models (LLMs) in tasks requiring: following complex instructions, minimizing hallucination, and spatial reasoning. COCORELI integrates medium-sized LLM agents with novel abstraction mechanisms and a discourse module to parse instructions to in-context learn dynamic, high-level representations of the environment. Experiments on natural collaborative construction tasks show that COCORELI outperforms single-LLM CoT and agentic LLM systems, all using larger LLMs. It manages to largely avoid hallucinations, identify missing information, ask for clarifications, and update its learned objects. COCORELI's abstraction abilities extend beyond ENVIRONMENT, as shown in the ToolBench API completion task.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "18 pages", "pdf_url": "https://arxiv.org/pdf/2509.04470.pdf", "abstract_url": "https://arxiv.org/abs/2509.04470", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "COCORELI是一种混合代理框架，通过集成中型LLM代理、新颖抽象机制和话语模块，有效处理复杂指令、减少幻觉并增强空间推理，在协作构建任务中优于大型LLM系统。", "motivation": "解决大型语言模型在遵循复杂指令、减少幻觉和执行空间推理任务时的局限性。", "method": "使用中型LLM代理结合抽象机制和话语模块，解析指令并学习动态环境表示。", "result": "在自然协作构建任务中，COCORELI表现优于单LLM CoT和代理LLM系统，能避免幻觉、识别缺失信息、请求澄清并更新学习对象。", "conclusion": "COCORELI的抽象能力超越环境，适用于更广泛任务，如ToolBench API完成，展示了其在增强LLM任务执行中的潜力。"}}
{"id": "2509.04642", "title": "Maestro: Joint Graph & Config Optimization for Reliable AI Agents", "authors": ["Wenxiao Wang", "Priyatham Kattakinda", "Soheil Feizi"], "abstract": "Building reliable LLM agents requires decisions at two levels: the graph (which modules exist and how information flows) and the configuration of each node (models, prompts, tools, control knobs). Most existing optimizers tune configurations while holding the graph fixed, leaving structural failure modes unaddressed. We introduce Maestro, a framework-agnostic holistic optimizer for LLM agents that jointly searches over graphs and configurations to maximize agent quality, subject to explicit rollout/token budgets. Beyond numeric metrics, Maestro leverages reflective textual feedback from traces to prioritize edits, improving sample efficiency and targeting specific failure modes. On the IFBench and HotpotQA benchmarks, Maestro consistently surpasses leading prompt optimizers--MIPROv2, GEPA, and GEPA+Merge--by an average of 12%, 4.9%, and 4.86%, respectively; even when restricted to prompt-only optimization, it still leads by 9.65%, 2.37%, and 2.41%. Maestro achieves these results with far fewer rollouts than GEPA. We further show large gains on two applications (interviewer & RAG agents), highlighting that joint graph & configuration search addresses structural failure modes that prompt tuning alone cannot fix.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Software Engineering (cs.SE)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2509.04642.pdf", "abstract_url": "https://arxiv.org/abs/2509.04642", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)", "Software Engineering (cs.SE)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "Maestro 是一个框架无关的优化器，联合搜索图和配置以最大化 LLM 代理质量，在预算约束下通过反射反馈提高效率，在基准测试中优于现有方法。", "motivation": "解决现有优化器仅调整配置而忽略图结构故障模式的问题，确保 LLM 代理的可靠性。", "method": "联合搜索图和节点配置，利用反射文本反馈优先编辑，提高样本效率并针对特定故障模式。", "result": "在 IFBench 和 HotpotQA 基准上，平均超越 MIPROv2、GEPA 和 GEPA+Merge 12%、4.9% 和 4.86%，使用更少的 rollout，并在应用中显示显著改进。", "conclusion": "联合图与配置搜索能有效处理结构故障模式，提示调优无法单独解决，提升 AI 代理的可靠性和效率。"}}
{"id": "2509.04646", "title": "Towards Personalized Explanations for Health Simulations: A Mixed-Methods Framework for Stakeholder-Centric Summarization", "authors": ["Philippe J. Giabbanelli", "Ameeta Agrawal"], "abstract": "Modeling & Simulation (M&S) approaches such as agent-based models hold significant potential to support decision-making activities in health, with recent examples including the adoption of vaccines, and a vast literature on healthy eating behaviors and physical activity behaviors. These models are potentially usable by different stakeholder groups, as they support policy-makers to estimate the consequences of potential interventions and they can guide individuals in making healthy choices in complex environments. However, this potential may not be fully realized because of the models' complexity, which makes them inaccessible to the stakeholders who could benefit the most. While Large Language Models (LLMs) can translate simulation outputs and the design of models into text, current approaches typically rely on one-size-fits-all summaries that fail to reflect the varied informational needs and stylistic preferences of clinicians, policymakers, patients, caregivers, and health advocates. This limitation stems from a fundamental gap: we lack a systematic understanding of what these stakeholders need from explanations and how to tailor them accordingly. To address this gap, we present a step-by-step framework to identify stakeholder needs and guide LLMs in generating tailored explanations of health simulations. Our procedure uses a mixed-methods design by first eliciting the explanation needs and stylistic preferences of diverse health stakeholders, then optimizing the ability of LLMs to generate tailored outputs (e.g., via controllable attribute tuning), and then evaluating through a comprehensive range of metrics to further improve the tailored generation of summaries.", "subjects": "Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET)", "comments": "Accepted at the AAAI 2025 Fall Symposium Series. November 6-8, 2025, Arlington, VA, USA", "pdf_url": "https://arxiv.org/pdf/2509.04646.pdf", "abstract_url": "https://arxiv.org/abs/2509.04646", "categories": ["Artificial Intelligence (cs.AI)", "Emerging Technologies (cs.ET)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一个混合方法框架，通过识别不同健康利益相关者的需求，指导大语言模型生成个性化的健康模拟解释，以克服通用摘要的局限性。", "motivation": "解决健康模拟模型因复杂性而难以被利益相关者（如临床医生、政策制定者、患者等）理解和利用的问题，当前方法缺乏针对不同需求的个性化解释。", "method": "采用混合方法设计，首先通过调查获取利益相关者的解释需求和风格偏好，然后优化大语言模型（如通过可控属性调整）生成定制化输出，并使用多种指标进行评估和改进。", "result": "框架成功识别了利益相关者的需求，并指导大语言模型生成更相关和可接受的个性化解释摘要。", "conclusion": "该框架有助于提高健康模拟的可访问性和实用性，支持更好的决策制定，并强调了在健康领域应用个性化解释的重要性。"}}
{"id": "2509.04731", "title": "Language-Driven Hierarchical Task Structures as Explicit World Models for Multi-Agent Learning", "authors": ["Brennen Hill"], "abstract": "The convergence of Language models, Agent models, and World models represents a critical frontier for artificial intelligence. While recent progress has focused on scaling Language and Agent models, the development of sophisticated, explicit World Models remains a key bottleneck, particularly for complex, long-horizon multi-agent tasks. In domains such as robotic soccer, agents trained via standard reinforcement learning in high-fidelity but structurally-flat simulators often fail due to intractable exploration spaces and sparse rewards. This position paper argues that the next frontier in developing capable agents lies in creating environments that possess an explicit, hierarchical World Model. We contend that this is best achieved through hierarchical scaffolding, where complex goals are decomposed into structured, manageable subgoals. Drawing evidence from a systematic review of 2024 research in multi-agent soccer, we identify a clear and decisive trend towards integrating symbolic and hierarchical methods with multi-agent reinforcement learning (MARL). These approaches implicitly or explicitly construct a task-based world model to guide agent learning. We then propose a paradigm shift: leveraging Large Language Models to dynamically generate this hierarchical scaffold, effectively using language to structure the World Model on the fly. This language-driven world model provides an intrinsic curriculum, dense and meaningful learning signals, and a framework for compositional learning, enabling Agent Models to acquire sophisticated, strategic behaviors with far greater sample efficiency. By building environments with explicit, language-configurable task layers, we can bridge the gap between low-level reactive behaviors and high-level strategic team play, creating a powerful and generalizable framework for training the next generation of intelligent agents.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Multiagent Systems (cs.MA); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.04731.pdf", "abstract_url": "https://arxiv.org/abs/2509.04731", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文主张利用大型语言模型动态生成分层任务结构作为显式世界模型，以提高多智能体强化学习在复杂任务中的样本效率和策略行为。", "motivation": "解决多智能体任务中因探索空间巨大和奖励稀疏导致的标准强化学习失败问题，特别是在如机器人足球等长视域领域。", "method": "通过语言驱动的分层脚手架方法，使用大型语言模型动态分解复杂目标为结构化子目标，构建显式世界模型。", "result": "集成符号和分层方法的多智能体强化学习趋势被确认，这种方法提供内在课程、密集学习信号和组合学习框架。", "conclusion": "语言可配置的任务层环境能桥接低层反应行为和高层策略团队协作，为训练智能智能体提供通用框架。"}}
{"id": "2509.04809", "title": "TalkToAgent: A Human-centric Explanation of Reinforcement Learning Agents with Large Language Models", "authors": ["Haechang Kim", "Hao Chen", "Can Li", "Jong Min Lee"], "abstract": "Explainable Reinforcement Learning (XRL) has emerged as a promising approach in improving the transparency of Reinforcement Learning (RL) agents. However, there remains a gap between complex RL policies and domain experts, due to the limited comprehensibility of XRL results and isolated coverage of current XRL approaches that leave users uncertain about which tools to employ. To address these challenges, we introduce TalkToAgent, a multi-agent Large Language Models (LLM) framework that delivers interactive, natural language explanations for RL policies. The architecture with five specialized LLM agents (Coordinator, Explainer, Coder, Evaluator, and Debugger) enables TalkToAgent to automatically map user queries to relevant XRL tools and clarify an agent's actions in terms of either key state variables, expected outcomes, or counterfactual explanations. Moreover, our approach extends previous counterfactual explanations by deriving alternative scenarios from qualitative behavioral descriptions, or even new rule-based policies. We validated TalkToAgent on quadruple-tank process control problem, a well-known nonlinear control benchmark. Results demonstrated that TalkToAgent successfully mapped user queries into XRL tasks with high accuracy, and coder-debugger interactions minimized failures in counterfactual generation. Furthermore, qualitative evaluation confirmed that TalkToAgent effectively interpreted agent's actions and contextualized their meaning within the problem domain.", "subjects": "Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)", "comments": "31 pages total", "pdf_url": "https://arxiv.org/pdf/2509.04809.pdf", "abstract_url": "https://arxiv.org/abs/2509.04809", "categories": ["Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍TalkToAgent，一个基于大型语言模型的多代理框架，用于提供交互式自然语言解释，以增强强化学习代理的透明度，并在四罐过程控制问题上验证其有效性。", "motivation": "解决可解释强化学习（XRL）结果难以理解和工具孤立的问题，弥合复杂RL策略与领域专家之间的鸿沟。", "method": "使用五个专门的大型语言模型代理（协调器、解释器、编码器、评估器和调试器）自动映射用户查询到XRL工具，并提供状态变量、预期结果或反事实解释。", "result": "TalkToAgent在四罐过程控制问题上准确映射用户查询，最小化反事实生成失败，并通过定性评估确认其能有效解释代理行为。", "conclusion": "TalkToAgent框架成功提高了RL代理的透明度和可解释性，为领域专家提供了实用的交互式解释工具。"}}
{"id": "2509.04847", "title": "Collaboration and Conflict between Humans and Language Models through the Lens of Game Theory", "authors": ["Mukul Singh", "Arjun Radhakrishna", "Sumit Gulwani"], "abstract": "Language models are increasingly deployed in interactive online environments, from personal chat assistants to domain-specific agents, raising questions about their cooperative and competitive behavior in multi-party settings. While prior work has examined language model decision-making in isolated or short-term game-theoretic contexts, these studies often neglect long-horizon interactions, human-model collaboration, and the evolution of behavioral patterns over time. In this paper, we investigate the dynamics of language model behavior in the iterated prisoner's dilemma (IPD), a classical framework for studying cooperation and conflict. We pit model-based agents against a suite of 240 well-established classical strategies in an Axelrod-style tournament and find that language models achieve performance on par with, and in some cases exceeding, the best-known classical strategies. Behavioral analysis reveals that language models exhibit key properties associated with strong cooperative strategies - niceness, provocability, and generosity while also demonstrating rapid adaptability to changes in opponent strategy mid-game. In controlled \"strategy switch\" experiments, language models detect and respond to shifts within only a few rounds, rivaling or surpassing human adaptability. These results provide the first systematic characterization of long-term cooperative behaviors in language model agents, offering a foundation for future research into their role in more complex, mixed human-AI social environments.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "9 pages", "pdf_url": "https://arxiv.org/pdf/2509.04847.pdf", "abstract_url": "https://arxiv.org/abs/2509.04847", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过迭代囚徒困境游戏研究语言模型在长期互动中的合作与冲突行为，发现其性能媲美或超越经典策略，并展现出适应性强的特点。", "motivation": "解决语言模型在多党交互环境中合作与竞争行为的长期动态问题，弥补先前研究对长期互动和人类模型协作的忽视。", "method": "使用迭代囚徒困境框架，将语言模型代理与240种经典策略进行Axelrod式锦标赛，并分析行为模式和适应性。", "result": "语言模型性能与最佳经典策略相当或更优，表现出善良、可激怒和慷慨等合作特性，并能快速适应对手策略变化。", "conclusion": "系统表征了语言模型的长期合作行为，为未来在复杂人机社交环境中的研究奠定基础。"}}
{"id": "2509.04871", "title": "Cloning a Conversational Voice AI Agent from Call\\,Recording Datasets for Telesales", "authors": ["Krittanon Kaewtawee", "Wachiravit Modecrua", "Krittin Pachtrachai", "Touchapon Kraisingkorn"], "abstract": "Recent advances in language and speech modelling have made it possible to build autonomous voice assistants that understand and generate human dialogue in real time. These systems are increasingly being deployed in domains such as customer service and healthcare care, where they can automate repetitive tasks, reduce operational costs, and provide constant support around the clock. In this paper, we present a general methodology for cloning a conversational voice AI agent from a corpus of call recordings. Although the case study described in this paper uses telesales data to illustrate the approach, the underlying process generalizes to any domain where call transcripts are available. Our system listens to customers over the telephone, responds with a synthetic voice, and follows a structured playbook learned from top performing human agents. We describe the domain selection, knowledge extraction, and prompt engineering used to construct the agent, integrating automatic speech recognition, a large language model based dialogue manager, and text to speech synthesis into a streaming inference pipeline. The cloned agent is evaluated against human agents on a rubric of 22 criteria covering introduction, product communication, sales drive, objection handling, and closing. Blind tests show that the AI agent approaches human performance in routine aspects of the call while underperforming in persuasion and objection handling. We analyze these shortcomings and refine the prompt accordingly. The paper concludes with design lessons and avenues for future research, including large scale simulation and automated evaluation.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "10 pages, 4 figures", "pdf_url": "https://arxiv.org/pdf/2509.04871.pdf", "abstract_url": "https://arxiv.org/abs/2509.04871", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种从通话录音数据集中克隆对话语音AI代理的通用方法，应用于电话销售，通过ASR、LLM对话管理和TTS集成，评估显示AI在常规任务接近人类表现，但在说服和处理异议方面不足。", "motivation": "解决自动化客户服务和销售任务的需求，以降低成本并提供全天候支持，利用现有通话录音数据集构建高效语音AI代理。", "method": "基于领域选择、知识提取和提示工程，集成自动语音识别、大型语言模型对话管理和文本转语音合成，构建流式推理管道，从顶级人类代理学习结构化剧本。", "result": "盲测评估显示AI代理在22项标准中，常规方面接近人类表现，但在说服和处理异议方面表现较差，通过提示优化改进。", "conclusion": "方法可泛化到其他领域，未来研究方向包括大规模模拟和自动化评估，强调了设计教训和改进潜力。"}}
{"id": "2509.04876", "title": "OSC: Cognitive Orchestration through Dynamic Knowledge Alignment in Multi-Agent LLM Collaboration", "authors": ["Jusheng Zhang", "Yijia Fan", "Kaitong Cai", "Xiaofei Sun", "Keze Wang"], "abstract": "This paper introduces OSC (Orchestrating Cognitive Synergy), a knowledge-aware adaptive collaboration framework designed to enhance cognitive synergy in multi-agent systems with large language models. While prior work has advanced agent selection and result aggregation, efficient linguistic interactions for deep collaboration among expert agents remain a critical bottleneck. OSC addresses this gap as a pivotal intermediate layer between selection and aggregation, introducing Collaborator Knowledge Models (CKM) to enable each agent to dynamically perceive its collaborators' cognitive states. Through real-time cognitive gap analysis, agents adaptively adjust communication behaviors, including content focus, detail level, and expression style, using learned strategies. Experiments on complex reasoning and problem-solving benchmarks demonstrate that OSC significantly improves task performance and communication efficiency, transforming \"parallel-working individuals'' into a \"deeply collaborative cognitive team.'' This framework not only optimizes multi-agent collaboration but also offers new insights into LLM agent interaction behaviors.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "Accepted at EMNLP 2025 (Long Paper)", "pdf_url": "https://arxiv.org/pdf/2509.04876.pdf", "abstract_url": "https://arxiv.org/abs/2509.04876", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "OSC是一个知识感知的自适应协作框架，通过动态知识对齐增强多智能体大语言模型的认知协同，提升任务性能和通信效率。", "motivation": "解决多智能体系统中专家智能体间高效语言交互的瓶颈，实现深度协作而非仅并行工作。", "method": "引入协作者知识模型（CKM），通过实时认知差距分析，使智能体自适应调整通信行为如内容焦点和表达风格。", "result": "在复杂推理和问题解决基准测试中，OSC显著提高了任务性能和通信效率。", "conclusion": "OSC优化了多智能体协作，为大语言模型智能体交互行为提供了新见解，促进深度认知团队的形成。"}}
{"id": "2509.04926", "title": "Towards Ontology-Based Descriptions of Conversations with Qualitatively-Defined Concepts", "authors": ["Barbara Gendron", "Gaël Guibon", "Mathieu D'aquin"], "abstract": "The controllability of Large Language Models (LLMs) when used as conversational agents is a key challenge, particularly to ensure predictable and user-personalized responses. This work proposes an ontology-based approach to formally define conversational features that are typically qualitative in nature. By leveraging a set of linguistic descriptors, we derive quantitative definitions for qualitatively-defined concepts, enabling their integration into an ontology for reasoning and consistency checking. We apply this framework to the task of proficiency-level control in conversations, using CEFR language proficiency levels as a case study. These definitions are then formalized in description logic and incorporated into an ontology, which guides controlled text generation of an LLM through fine-tuning. Experimental results demonstrate that our approach provides consistent and explainable proficiency-level definitions, improving transparency in conversational AI.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": "Accepted at TOTh 2025 (Terminology \\& Ontology: Theories and applications)", "pdf_url": "https://arxiv.org/pdf/2509.04926.pdf", "abstract_url": "https://arxiv.org/abs/2509.04926", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出一种基于本体的方法，通过语言描述符将定性对话特征量化和形式化，以增强大型语言模型在对话中的可控性和透明度，并以CEFR语言水平为例进行验证。", "motivation": "解决大型语言模型作为对话代理时可控性不足的问题，特别是确保可预测和用户个性化的响应。", "method": "使用本体论方法，通过语言描述符定义定性概念，形式化描述逻辑并整合到本体中，指导LLM的微调文本生成。", "result": "实验结果显示，该方法提供了连贯且可解释的语言水平定义，提高了对话AI的透明度。", "conclusion": "本体论方法能有效提升对话AI的可控性和解释性，为未来应用提供基础。"}}
{"id": "2509.04979", "title": "Internet 3.0: Architecture for a Web-of-Agents with it's Algorithm for Ranking Agents", "authors": ["Rajesh Tembarai Krishnamachari", "Srividya Rajesh"], "abstract": "AI agents -- powered by reasoning-capable large language models (LLMs) and integrated with tools, data, and web search -- are poised to transform the internet into a \\emph{Web of Agents}: a machine-native ecosystem where autonomous agents interact, collaborate, and execute tasks at scale. Realizing this vision requires \\emph{Agent Ranking} -- selecting agents not only by declared capabilities but by proven, recent performance. Unlike Web~1.0's PageRank, a global, transparent network of agent interactions does not exist; usage signals are fragmented and private, making ranking infeasible without coordination.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.04979.pdf", "abstract_url": "https://arxiv.org/abs/2509.04979", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了Internet 3.0的架构，基于AI代理构建Web-of-Agents，并引入代理排名算法，以解决代理选择和性能评估问题。", "motivation": "当前AI代理在互联网中缺乏有效的选择和排名机制，因为交互数据碎片化且私有，无法像PageRank那样实现透明排名，阻碍了大规模自主代理生态系统的实现。", "method": "设计了一种代理排名算法，基于代理的声明能力和已验证的近期性能进行选择，而非依赖全局网络数据。", "result": "该方法理论上能够实现代理的有效排名，促进代理间的交互和协作，但具体实验结果未在摘要中提供。", "conclusion": "Internet 3.0的架构和排名算法是迈向机器原生生态系统的关键步骤，需要进一步协调和实现以应对数据碎片化挑战。"}}
{"id": "2509.04472", "title": "RECAP: REwriting Conversations for Intent Understanding in Agentic Planning", "authors": ["Kushan Mitra", "Dan Zhang", "Hannah Kim", "Estevam Hruschka"], "abstract": "Understanding user intent is essential for effective planning in conversational assistants, particularly those powered by large language models (LLMs) coordinating multiple agents. However, real-world dialogues are often ambiguous, underspecified, or dynamic, making intent detection a persistent challenge. Traditional classification-based approaches struggle to generalize in open-ended settings, leading to brittle interpretations and poor downstream planning. We propose RECAP (REwriting Conversations for Agent Planning), a new benchmark designed to evaluate and advance intent rewriting, reframing user-agent dialogues into concise representations of user goals. RECAP captures diverse challenges such as ambiguity, intent drift, vagueness, and mixed-goal conversations. Alongside the dataset, we introduce an LLM-based evaluator that assesses planning utility given the rewritten intent. Using RECAP, we develop a prompt-based rewriting approach that outperforms baselines. We further demonstrate that fine-tuning two DPO-based rewriters yields additional utility gains. Our results highlight intent rewriting as a critical and tractable component for improving agent planning in open-domain dialogue systems.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.04472.pdf", "abstract_url": "https://arxiv.org/abs/2509.04472", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "RECAP是一个新基准，用于评估和推进意图重写，将用户-代理对话重构为用户目标的简洁表示，以改善开放域对话系统中的代理规划。", "motivation": "解决真实世界对话中意图检测的挑战，如模糊性、不完整性、动态性和混合目标，这些导致传统分类方法在开放设置中泛化能力差，影响下游规划效果。", "method": "提出RECAP基准和基于LLM的评估器，开发基于提示的重写方法，并微调两个DPO-based重写器。", "result": "基于提示的重写方法优于基线，微调DPO-based重写器带来额外效用增益，突显意图重写对代理规划的重要性。", "conclusion": "意图重写是改善开放域对话系统代理规划的关键且可行组件，RECAP基准和评估器有助于推进相关研究。"}}
{"id": "2509.04482", "title": "Energy Landscapes Enable Reliable Abstention in Retrieval-Augmented Large Language Models for Healthcare", "authors": ["Ravi Shankar", "Sheng Wong", "Lin Li", "Magdalena Bachmann", "Alex Silverthorne", "Beth Albert", "Gabriel Davis Jones"], "abstract": "Reliable abstention is critical for retrieval-augmented generation (RAG) systems, particularly in safety-critical domains such as women's health, where incorrect answers can lead to harm. We present an energy-based model (EBM) that learns a smooth energy landscape over a dense semantic corpus of 2.6M guideline-derived questions, enabling the system to decide when to generate or abstain. We benchmark the EBM against a calibrated softmax baseline and a k-nearest neighbour (kNN) density heuristic across both easy and hard abstention splits, where hard cases are semantically challenging near-distribution queries. The EBM achieves superior abstention performance abstention on semantically hard cases, reaching AUROC 0.961 versus 0.950 for softmax, while also reducing FPR@95 (0.235 vs 0.331). On easy negatives, performance is comparable across methods, but the EBM's advantage becomes most pronounced in safety-critical hard distributions. A comprehensive ablation with controlled negative sampling and fair data exposure shows that robustness stems primarily from the energy scoring head, while the inclusion or exclusion of specific negative types (hard, easy, mixed) sharpens decision boundaries but is not essential for generalisation to hard cases. These results demonstrate that energy-based abstention scoring offers a more reliable confidence signal than probability-based softmax confidence, providing a scalable and interpretable foundation for safe RAG systems.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.04482.pdf", "abstract_url": "https://arxiv.org/abs/2509.04482", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种基于能量的模型，用于检索增强生成系统在医疗领域中的可靠弃权，通过平滑能量景观处理语义挑战性查询，实现优于概率基方法的弃权性能。", "motivation": "解决在安全关键领域如女性健康中，检索增强生成系统因错误答案可能导致伤害的问题，需要可靠的弃权机制。", "method": "使用基于能量的模型学习密集语义语料库上的平滑能量景观，以决定何时生成或弃权，并与校准softmax基线和kNN密度启发法进行基准测试。", "result": "EBM在语义困难案例上达到AUROC 0.961，优于softmax的0.950，并降低FPR@95（0.235 vs 0.331），在安全关键分布中优势最明显。", "conclusion": "基于能量的弃权评分比概率基方法更可靠，为安全RAG系统提供了可扩展和可解释的基础。"}}
{"id": "2509.05091", "title": "ProToM: Promoting Prosocial Behaviour via Theory of Mind-Informed Feedback", "authors": ["Matteo Bortoletto", "Yichao Zhou", "Lance Ying", "Tianmin Shu", "Andreas Bulling"], "abstract": "While humans are inherently social creatures, the challenge of identifying when and how to assist and collaborate with others - particularly when pursuing independent goals - can hinder cooperation. To address this challenge, we aim to develop an AI system that provides useful feedback to promote prosocial behaviour - actions that benefit others, even when not directly aligned with one's own goals. We introduce ProToM, a Theory of Mind-informed facilitator that promotes prosocial actions in multi-agent systems by providing targeted, context-sensitive feedback to individual agents. ProToM first infers agents' goals using Bayesian inverse planning, then selects feedback to communicate by maximising expected utility, conditioned on the inferred goal distribution. We evaluate our approach against baselines in two multi-agent environments: Doors, Keys, and Gems, as well as Overcooked. Our results suggest that state-of-the-art large language and reasoning models fall short of communicating feedback that is both contextually grounded and well-timed - leading to higher communication overhead and task speedup. In contrast, ProToM provides targeted and helpful feedback, achieving a higher success rate, shorter task completion times, and is consistently preferred by human users.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2509.05091.pdf", "abstract_url": "https://arxiv.org/abs/2509.05091", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "ProToM是一个基于心智理论的AI系统，通过提供针对性反馈促进多智能体系统中的亲社会行为，提高任务成功率和效率。", "motivation": "解决人类在追求独立目标时难以识别何时及如何协助他人，从而阻碍合作的问题。", "method": "使用贝叶斯逆规划推断智能体目标，并通过最大化期望效用来选择上下文敏感的反馈。", "result": "ProToM在Doors, Keys, and Gems和Overcooked环境中优于基线，实现更高成功率、更短完成时间，并获人类用户偏好。", "conclusion": "ProToM能有效促进亲社会行为，优于现有大型语言和推理模型，减少通信开销和加速任务。"}}
{"id": "2509.04492", "title": "Learned Hallucination Detection in Black-Box LLMs using Token-level Entropy Production Rate", "authors": ["Charles Moslonka", "Hicham Randrianarivo", "Arthur Garnier", "Emmanuel Malherbe"], "abstract": "Hallucinations in Large Language Model (LLM) outputs for Question Answering (QA) tasks critically undermine their real-world reliability. This paper introduces an applied methodology for robust, one-shot hallucination detection, specifically designed for scenarios with limited data access, such as interacting with black-box LLM APIs that typically expose only a few top candidate log-probabilities per token. Our approach derives uncertainty indicators directly from these readily available log-probabilities generated during non-greedy decoding. We first derive an Entropy Production Rate (EPR) metric that offers baseline performance, later augmented with supervised learning. Our learned model uses features representing the entropic contributions of the accessible top-ranked tokens within a single generated sequence, requiring no multiple query re-runs. Evaluated across diverse QA datasets and multiple LLMs, this estimator significantly improves hallucination detection over using EPR alone. Crucially, high performance is demonstrated using only the typically small set of available log-probabilities (e.g., top <10 per token), confirming its practical efficiency and suitability for these API-constrained deployments. This work provides a readily deployable technique to enhance the trustworthiness of LLM responses from a single generation pass in QA and Retrieval-Augmented Generation (RAG) systems, with its utility further demonstrated in a finance framework analyzing responses to queries on annual reports from an industrial dataset.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "8 pages, 7 figures, 1 table. pre-print version", "pdf_url": "https://arxiv.org/pdf/2509.04492.pdf", "abstract_url": "https://arxiv.org/abs/2509.04492", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "提出一种基于熵产生率和监督学习的幻觉检测方法，利用黑盒LLM API中可用的对数概率，在单次生成中高效检测问答任务中的幻觉，提升可靠性。", "motivation": "解决大型语言模型在问答任务中输出幻觉的问题，特别是在数据访问受限的黑盒API场景下，确保模型响应的可信度。", "method": "从非贪婪解码中可用的对数概率推导熵产生率指标，并通过监督学习增强，使用顶级令牌的熵贡献特征进行单序列检测，无需多次查询。", "result": "在多个问答数据集和LLM上评估，该方法显著优于仅使用熵产生率，高效利用少量对数概率（如每令牌前10个），证实其实用性和部署适用性。", "conclusion": "提供了一种易于部署的技术，增强问答和检索增强生成系统中LLM响应的可信度，在金融框架中验证了其效用，适用于API受限环境。"}}
{"id": "2509.04499", "title": "DeepTRACE: Auditing Deep Research AI Systems for Tracking Reliability Across Citations and Evidence", "authors": ["Pranav Narayanan Venkit", "Philippe Laban", "Yilun Zhou", "Kung-Hsiang Huang", "Yixin Mao", "Chien-Sheng Wu"], "abstract": "Generative search engines and deep research LLM agents promise trustworthy, source-grounded synthesis, yet users regularly encounter overconfidence, weak sourcing, and confusing citation practices. We introduce DeepTRACE, a novel sociotechnically grounded audit framework that turns prior community-identified failure cases into eight measurable dimensions spanning answer text, sources, and citations. DeepTRACE uses statement-level analysis (decomposition, confidence scoring) and builds citation and factual-support matrices to audit how systems reason with and attribute evidence end-to-end. Using automated extraction pipelines for popular public models (e.g., GPT-4.5/5,", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2509.04499.pdf", "abstract_url": "https://arxiv.org/abs/2509.04499", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "DeepTRACE是一个新颖的社会技术审计框架，用于评估深度研究AI系统在答案、来源和引用方面的可靠性，通过八个可测量维度分析系统如何处理和归因证据。", "motivation": "解决生成式搜索引擎和深度研究LLM代理中存在的过度自信、来源薄弱和引用实践混乱等问题，以提高其可信度和用户信任。", "method": "使用声明级分析（包括分解和置信度评分），构建引用和事实支持矩阵，通过自动化提取管道审计流行公共模型（如GPT-4.5/5）的端到端推理过程。", "result": "DeepTRACE框架能够系统地识别和测量AI系统在证据处理和归因方面的失败案例，提供可量化的评估维度。", "conclusion": "DeepTRACE有助于改进AI系统的可靠性和透明度，促进更准确和可信的研究辅助工具的发展。"}}
{"id": "2509.04502", "title": "VaccineRAG: Boosting Multimodal Large Language Models' Immunity to Harmful RAG Samples", "authors": ["Qixin Sun", "Ziqin Wang", "Hengyuan Zhao", "Yilin Li", "Kaiyou Song", "Linjiang Huang", "Xiaolin Hu", "Qingpei Guo", "Si Liu"], "abstract": "Retrieval Augmented Generation enhances the response accuracy of Large Language Models (LLMs) by integrating retrieval and generation modules with external knowledge, demonstrating particular strength in real-time queries and Visual Question Answering tasks. However, the effectiveness of RAG is frequently hindered by the precision of the retriever: many retrieved samples fed into the generation phase are irrelevant or misleading, posing a critical bottleneck to LLMs' performance. To address this challenge, we introduce VaccineRAG, a novel Chain-of-Thought-based retrieval-augmented generation dataset. On one hand, VaccineRAG employs a benchmark to evaluate models using data with varying positive/negative sample ratios, systematically exposing inherent weaknesses in current LLMs. On the other hand, it enhances models' sample-discrimination capabilities by prompting LLMs to generate explicit Chain-of-Thought (CoT) analysis for each sample before producing final answers. Furthermore, to enhance the model's ability to learn long-sequence complex CoT content, we propose Partial-GRPO. By modeling the outputs of LLMs as multiple components rather than a single whole, our model can make more informed preference selections for complex sequences, thereby enhancing its capacity to learn complex CoT. Comprehensive evaluations and ablation studies on VaccineRAG validate the effectiveness of the proposed scheme. The code and dataset will be publicly released soon.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.04502.pdf", "abstract_url": "https://arxiv.org/abs/2509.04502", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "VaccineRAG 是一个基于思维链的检索增强生成数据集，通过评估和增强模型对样本的辨别能力，结合 Partial-GRPO 方法提升多模态大语言模型对有害 RAG 样本的免疫力。", "motivation": "解决检索增强生成中检索器精度不足导致无关或误导样本影响大语言模型性能的问题。", "method": "使用 VaccineRAG 数据集评估模型，通过思维链分析样本，并引入 Partial-GRPO 方法建模输出为多组件以学习复杂序列。", "result": "综合评估和消融研究验证了方法的有效性，提升了模型的样本辨别和复杂内容学习能力。", "conclusion": "VaccineRAG 方案能显著增强模型对有害 RAG 样本的鲁棒性，代码和数据集将公开。"}}
{"id": "2509.04508", "title": "ProST: Progressive Sub-task Training for Pareto-Optimal Multi-agent Systems Using Small Language Models", "authors": ["Biddut Sarker Bijoy", "Mohammad Saqib Hasan", "Pegah Alipoormolabashi", "Avirup Sil", "Aruna Balasubramanian", "Niranjan Balasubramanian"], "abstract": "Multi-agent systems with smaller language models (SLMs) present a viable alternative to single agent systems powered by large language models (LLMs) for addressing complex problems. In this work, we study how these alternatives compare in terms of both effectiveness and efficiency. To study this trade-off, we instantiate single and multi-agent systems for the complex problems in the AppWorld environment using different sized language models.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.04508.pdf", "abstract_url": "https://arxiv.org/abs/2509.04508", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文研究了使用小型语言模型（SLMs）的多智能体系统作为大型语言模型（LLMs）单智能体系统的可行替代方案，通过渐进子任务训练实现帕累托最优，在AppWorld环境中比较了有效性和效率。", "motivation": "解决复杂问题时，多智能体系统使用SLMs与单智能体系统使用LLMs在效果和效率之间的权衡问题。", "method": "在AppWorld环境中实例化单和多智能体系统，使用不同大小的语言模型，并应用渐进子任务训练方法。", "result": "多智能体系统使用SLMs提供了可行的替代方案，可能在效果和效率上达到帕累托最优。", "conclusion": "多智能体系统结合SLMs是处理复杂问题的有效方法，平衡了性能与资源使用。"}}
{"id": "2509.04481", "title": "Narrative-to-Scene Generation: An LLM-Driven Pipeline for 2D Game Environments", "authors": ["Yi-Chun Chen", "Arnav Jhala"], "abstract": "Recent advances in large language models(LLMs) enable compelling story generation, but connecting narrative text to playable visual environments remains an open challenge in procedural content generation(PCG). We present a lightweight pipeline that transforms short narrative prompts into a sequence of 2D tile-based game scenes, reflecting the temporal structure of stories. Given an LLM-generated narrative, our system identifies three key time frames, extracts spatial predicates in the form of \"Object-Relation-Object\" triples, and retrieves visual assets using affordance-aware semantic embeddings from the GameTileNet dataset. A layered terrain is generated using Cellular Automata, and objects are placed using spatial rules grounded in the predicate structure. We evaluated our system in ten diverse stories, analyzing tile-object matching, affordance-layer alignment, and spatial constraint satisfaction across frames. This prototype offers a scalable approach to narrative-driven scene generation and lays the foundation for future work on multi-frame continuity, symbolic tracking, and multi-agent coordination in story-centered PCG.", "subjects": "Graphics (cs.GR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Multimedia (cs.MM)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.04481.pdf", "abstract_url": "https://arxiv.org/abs/2509.04481", "categories": ["Graphics (cs.GR)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Multimedia (cs.MM)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于大语言模型的轻量级流程，将短叙事提示转换为2D瓦片游戏场景序列，通过提取空间谓词和检索视觉资产，实现叙事驱动的场景生成。", "motivation": "解决将叙事文本连接到可玩视觉环境的挑战，这是程序化内容生成中的开放问题。", "method": "使用LLM生成叙事，识别关键时间帧，提取对象-关系-对象三元组，检索视觉资产，并通过细胞自动机生成分层地形和基于谓词的空间规则放置对象。", "result": "在十个故事中评估了瓦片-对象匹配、可用性层对齐和空间约束满足，显示出系统的可扩展性。", "conclusion": "原型为叙事驱动的场景生成提供了基础，支持未来多帧连续性、符号跟踪和多代理协调的研究。"}}
{"id": "2509.04716", "title": "KERAG: Knowledge-Enhanced Retrieval-Augmented Generation for Advanced Question Answering", "authors": ["Yushi Sun", "Kai Sun", "Yifan Ethan Xu", "Xiao Yang", "Xin Luna Dong", "Nan Tang", "Lei Chen"], "abstract": "Retrieval-Augmented Generation (RAG) mitigates hallucination in Large Language Models (LLMs) by incorporating external data, with Knowledge Graphs (KGs) offering crucial information for question answering. Traditional Knowledge Graph Question Answering (KGQA) methods rely on semantic parsing, which typically retrieves knowledge strictly necessary for answer generation, thus often suffer from low coverage due to rigid schema requirements and semantic ambiguity. We present KERAG, a novel KG-based RAG pipeline that enhances QA coverage by retrieving a broader subgraph likely to contain relevant information. Our retrieval-filtering-summarization approach, combined with fine-tuned LLMs for Chain-of-Thought reasoning on knowledge sub-graphs, reduces noises and improves QA for both simple and complex questions. Experiments demonstrate that KERAG surpasses state-of-the-art solutions by about 7% in quality and exceeds GPT-4o (Tool) by 10-21%.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": "Accepted by EMNLP Findings 2025", "pdf_url": "https://arxiv.org/pdf/2509.04716.pdf", "abstract_url": "https://arxiv.org/abs/2509.04716", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "KERAG是一种基于知识图谱的检索增强生成方法，通过检索更广泛的子图来提高问答覆盖率，结合过滤和总结技术，减少噪声，提升简单和复杂问题的回答质量，实验显示优于现有方法。", "motivation": "解决传统知识图谱问答方法因严格模式要求和语义模糊导致的低覆盖率问题，减少大型语言模型在问答中的幻觉。", "method": "使用检索-过滤-总结管道，结合微调的大型语言模型进行链式思考推理，从知识子图中提取信息。", "result": "实验表明，KERAG在质量上超越最先进方法约7%，并超过GPT-4o（工具）10-21%。", "conclusion": "KERAG通过增强知识检索和推理，有效提升问答性能，具有实际应用潜力。"}}
{"id": "2509.04535", "title": "In-Context Policy Adaptation via Cross-Domain Skill Diffusion", "authors": ["Minjong Yoo", "Woo Kyung Kim", "Honguk Woo"], "abstract": "In this work, we present an in-context policy adaptation (ICPAD) framework designed for long-horizon multi-task environments, exploring diffusion-based skill learning techniques in cross-domain settings. The framework enables rapid adaptation of skill-based reinforcement learning policies to diverse target domains, especially under stringent constraints on no model updates and only limited target domain data. Specifically, the framework employs a cross-domain skill diffusion scheme, where domain-agnostic prototype skills and a domain-grounded skill adapter are learned jointly and effectively from an offline dataset through cross-domain consistent diffusion processes. The prototype skills act as primitives for common behavior representations of long-horizon policies, serving as a lingua franca to bridge different domains. Furthermore, to enhance the in-context adaptation performance, we develop a dynamic domain prompting scheme that guides the diffusion-based skill adapter toward better alignment with the target domain. Through experiments with robotic manipulation in Metaworld and autonomous driving in CARLA, we show that our $\\oursol$ framework achieves superior policy adaptation performance under limited target domain data conditions for various cross-domain configurations including differences in environment dynamics, agent embodiment, and task horizon.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "9 pages", "pdf_url": "https://arxiv.org/pdf/2509.04535.pdf", "abstract_url": "https://arxiv.org/abs/2509.04535", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于跨域技能扩散的上下文策略适应框架，用于长视野多任务环境，通过扩散学习和动态提示实现快速策略适应，在机器人操作和自动驾驶实验中表现优异。", "motivation": "解决在长视野多任务环境中，强化学习策略在跨域设置下快速适应的问题，特别是在模型不更新和目标域数据有限的情况下。", "method": "使用跨域技能扩散方案，学习领域无关的原型技能和领域接地的技能适配器，结合动态领域提示来增强适应性能。", "result": "在Metaworld和CARLA的实验显示，该框架在有限目标域数据下，针对环境动态、代理体现和任务视野的差异，实现了优越的策略适应性能。", "conclusion": "该框架通过扩散技能学习有效桥接不同领域，为强化学习策略的快速跨域适应提供了可行方案，具有实际应用潜力。"}}
{"id": "2509.04537", "title": "Emergent Social Dynamics of LLM Agents in the El Farol Bar Problem", "authors": ["Ryosuke Takata", "Atsushi Masumori", "Takashi Ikegammi"], "abstract": "We investigate the emergent social dynamics of Large Language Model (LLM) agents in a spatially extended El Farol Bar problem, observing how they autonomously navigate this classic social dilemma. As a result, the LLM agents generated a spontaneous motivation to go to the bar and changed their decision making by becoming a collective. We also observed that the LLM agents did not solve the problem completely, but rather behaved more like humans. These findings reveal a complex interplay between external incentives (prompt-specified constraints such as the 60\\% threshold) and internal incentives (culturally-encoded social preferences derived from pre-training), demonstrating that LLM agents naturally balance formal game-theoretic rationality with social motivations that characterize human behavior. These findings suggest that a new model of group decision making, which could not be handled in the previous game-theoretic problem setting, can be realized by LLM agents.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.04537.pdf", "abstract_url": "https://arxiv.org/abs/2509.04537", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)"], "matching_keywords": ["agent"], "AI": {"tldr": "研究大型语言模型（LLM）代理在扩展版El Farol酒吧问题中的涌现社会动态，发现它们能自发形成集体决策，平衡游戏理论理性与社会动机，类似人类行为。", "motivation": "解决经典社会困境中代理如何自主导航的问题，探索LLM代理是否能模拟人类的社会决策行为，超越传统游戏理论框架。", "method": "使用LLM代理在空间扩展的El Farol酒吧问题中进行模拟，观察其决策过程，结合外部提示约束和内部文化编码的社会偏好。", "result": "LLM代理表现出自发去酒吧的动机，形成集体行为，但未完全解决问题，行为更接近人类，揭示了外部和内部激励的复杂互动。", "conclusion": "LLM代理能实现新的群体决策模型，结合游戏理论和社会动机，为理解人类行为提供新视角，并暗示在复杂社会模拟中的潜力。"}}
{"id": "2509.04794", "title": "Personality as a Probe for LLM Evaluation: Method Trade-offs and Downstream Effects", "authors": ["Gunmay Handa", "Zekun Wu", "Adriano Koshiyama", "Philip Treleaven"], "abstract": "Personality manipulation in large language models (LLMs) is increasingly applied in customer service and agentic scenarios, yet its mechanisms and trade-offs remain unclear. We present a systematic study of personality control using the Big Five traits, comparing in-context learning (ICL), parameter-efficient fine-tuning (PEFT), and mechanistic steering (MS). Our contributions are fourfold. First, we construct a contrastive dataset with balanced high/low trait responses, enabling effective steering vector computation and fair cross-method evaluation. Second, we introduce a unified evaluation framework based on within-run $\\Delta$ analysis that disentangles, reasoning capability, agent performance, and demographic bias across MMLU, GAIA, and BBQ benchmarks. Third, we develop trait purification techniques to separate openness from conscientiousness, addressing representational overlap in trait encoding. Fourth, we propose a three-level stability framework that quantifies method-, trait-, and combination-level robustness, offering practical guidance under deployment constraints. Experiments on Gemma-2-2B-IT and LLaMA-3-8B-Instruct reveal clear trade-offs: ICL achieves strong alignment with minimal capability loss, PEFT delivers the highest alignment at the cost of degraded task performance, and MS provides lightweight runtime control with competitive effectiveness. Trait-level analysis shows openness as uniquely challenging, agreeableness as most resistant to ICL, and personality encoding consolidating around intermediate layers. Taken together, these results establish personality manipulation as a multi-level probe into behavioral representation, linking surface conditioning, parameter encoding, and activation-level steering, and positioning mechanistic steering as a lightweight alternative to fine-tuning for both deployment and interpretability.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.04794.pdf", "abstract_url": "https://arxiv.org/abs/2509.04794", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文系统研究LLM人格控制方法，比较ICL、PEFT和MS，揭示性能权衡，提出评估框架和稳定技术，表明MS为轻量级替代方案。", "motivation": "解决LLM人格操纵机制和权衡不明确的问题，以支持客户服务和代理场景应用。", "method": "使用Big Five特质，构建对比数据集，开发统一评估框架、特质纯化技术和三层稳定性框架，在Gemma-2-2B-IT和LLaMA-3-8B-Instruct上进行实验。", "result": "ICL对齐强但能力损失小，PEFT对齐最高但任务性能下降，MS轻量控制有效；开放性特质挑战大，宜人性抵抗ICL，人格编码集中中间层。", "conclusion": "人格操纵作为行为表示的多层探针，MS是轻量级替代，适用于部署和可解释性。"}}
{"id": "2509.04802", "title": "Mind the Gap: Evaluating Model- and Agentic-Level Vulnerabilities in LLMs with Action Graphs", "authors": ["Ilham Wicaksono", "Zekun Wu", "Theo King", "Adriano Koshiyama", "Philip Treleaven"], "abstract": "As large language models transition to agentic systems, current safety evaluation frameworks face critical gaps in assessing deployment-specific risks. We introduce AgentSeer, an observability-based evaluation framework that decomposes agentic executions into granular action and component graphs, enabling systematic agentic-situational assessment. Through cross-model validation on GPT-OSS-20B and Gemini-2.0-flash using HarmBench single turn and iterative refinement attacks, we demonstrate fundamental differences between model-level and agentic-level vulnerability profiles. Model-level evaluation reveals baseline differences: GPT-OSS-20B (39.47% ASR) versus Gemini-2.0-flash (50.00% ASR), with both models showing susceptibility to social engineering while maintaining logic-based attack resistance. However, agentic-level assessment exposes agent-specific risks invisible to traditional evaluation. We discover \"agentic-only\" vulnerabilities that emerge exclusively in agentic contexts, with tool-calling showing 24-60% higher ASR across both models. Cross-model analysis reveals universal agentic patterns, agent transfer operations as highest-risk tools, semantic rather than syntactic vulnerability mechanisms, and context-dependent attack effectiveness, alongside model-specific security profiles in absolute ASR levels and optimal injection strategies. Direct attack transfer from model-level to agentic contexts shows degraded performance (GPT-OSS-20B: 57% human injection ASR; Gemini-2.0-flash: 28%), while context-aware iterative attacks successfully compromise objectives that failed at model-level, confirming systematic evaluation gaps. These findings establish the urgent need for agentic-situation evaluation paradigms, with AgentSeer providing the standardized methodology and empirical validation.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.04802.pdf", "abstract_url": "https://arxiv.org/abs/2509.04802", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了AgentSeer框架，用于评估LLM在代理系统中的安全漏洞，发现代理级漏洞与模型级存在显著差异，强调需要专门的评估方法。", "motivation": "解决大型语言模型在代理系统部署中，现有安全评估框架无法充分评估特定风险的问题。", "method": "使用AgentSeer框架，通过分解代理执行到动作和组件图，结合HarmBench攻击进行跨模型验证。", "result": "模型级评估显示ASR差异（GPT-OSS-20B 39.47%，Gemini-2.0-flash 50%），代理级评估暴露工具调用风险更高（24-60% ASR增加），并发现代理特有漏洞和上下文依赖攻击效果。", "conclusion": "代理级评估至关重要，AgentSeer提供了标准化方法，证实了传统评估的不足，需发展代理情境评估范式。"}}
{"id": "2509.04633", "title": "Scaling Environments for Organoid Intelligence with LLM-Automated Design and Plasticity-Based Evaluation", "authors": ["Brennen Hill"], "abstract": "As the complexity of artificial agents increases, the design of environments that can effectively shape their behavior and capabilities has become a critical research frontier. We propose a framework that extends this principle to a novel class of agents: biological neural networks in the form of neural organoids. This paper introduces three scalable, closed-loop virtual environments designed to train organoid-based biological agents and probe the underlying mechanisms of learning, such as long-term potentiation (LTP) and long-term depression (LTD). We detail the design of three distinct task environments with increasing complexity: (1) a conditional avoidance task, (2) a one-dimensional predator-prey scenario, and (3) a replication of the classic Pong game. For each environment, we formalize the state and action spaces, the sensory encoding and motor decoding mechanisms, and the feedback protocols based on predictable (reward) and unpredictable (punishment) stimulation. Furthermore, we propose a novel meta-learning approach where a Large Language Model (LLM) is used to automate the generation and optimization of experimental protocols, scaling the process of environment and curriculum design. Finally, we outline a multi-modal approach for evaluating learning by measuring synaptic plasticity at electrophysiological, cellular, and molecular levels. This work bridges the gap between computational neuroscience and agent-based AI, offering a unique platform for studying embodiment, learning, and intelligence in a controlled biological substrate.", "subjects": "Neural and Evolutionary Computing (cs.NE); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neurons and Cognition (q-bio.NC)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.04633.pdf", "abstract_url": "https://arxiv.org/abs/2509.04633", "categories": ["Neural and Evolutionary Computing (cs.NE)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Neurons and Cognition (q-bio.NC)"], "matching_keywords": ["agent"], "AI": {"tldr": "提出一个框架，利用可扩展的虚拟环境和LLM自动化设计来训练和评估基于神经类器官的生物代理，以研究学习机制和智能。", "motivation": "解决设计环境以有效塑造复杂人工代理（特别是生物神经网络）行为的问题，并探索学习机制如LTP和LTD。", "method": "使用三个复杂度递增的虚拟环境（条件回避、一维捕食者-猎物、Pong游戏），结合状态/动作空间定义、感官编码、运动解码、反馈协议，并引入LLM自动化协议生成和优化，以及多模态评估方法测量突触可塑性。", "result": "框架成功设计和优化了环境，能够训练生物代理并评估学习，通过测量电生理、细胞和分子水平的可塑性来验证学习效果。", "conclusion": "该工作连接了计算神经科学和基于代理的AI，提供了一个独特平台来研究受控生物基质中的体现、学习和智能，具有推进AI和神经科学研究的潜力。"}}
{"id": "2509.04712", "title": "Bootstrapping Reinforcement Learning with Sub-optimal Policies for Autonomous Driving", "authors": ["Zhihao Zhang", "Chengyang Peng", "Ekim Yurtsever", "Keith A. Redmill"], "abstract": "Automated vehicle control using reinforcement learning (RL) has attracted significant attention due to its potential to learn driving policies through environment interaction. However, RL agents often face training challenges in sample efficiency and effective exploration, making it difficult to discover an optimal driving strategy. To address these issues, we propose guiding the RL driving agent with a demonstration policy that need not be a highly optimized or expert-level controller. Specifically, we integrate a rule-based lane change controller with the Soft Actor Critic (SAC) algorithm to enhance exploration and learning efficiency. Our approach demonstrates improved driving performance and can be extended to other driving scenarios that can similarly benefit from demonstration-based guidance.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Systems and Control (eess.SY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.04712.pdf", "abstract_url": "https://arxiv.org/abs/2509.04712", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Systems and Control (eess.SY)"], "matching_keywords": ["agent"], "AI": {"tldr": "通过集成基于规则的车道变换控制器与SAC算法，提升自动驾驶中强化学习的样本效率和探索能力，改善驾驶性能。", "motivation": "解决强化学习在自动驾驶中样本效率低和探索困难的问题，以发现更优的驾驶策略。", "method": "使用非专家级的演示策略（如基于规则的车道变换控制器）引导SAC算法，增强探索和学习效率。", "result": "方法展示了改进的驾驶性能，并可扩展到其他类似受益于演示指导的驾驶场景。", "conclusion": "提出的引导方法有效提升了强化学习的效率和性能，具有广泛的应用潜力。"}}
{"id": "2509.05066", "title": "ToM-SSI: Evaluating Theory of Mind in Situated Social Interactions", "authors": ["Matteo Bortoletto", "Constantin Ruhdorfer", "Andreas Bulling"], "abstract": "Most existing Theory of Mind (ToM) benchmarks for foundation models rely on variations of the Sally-Anne test, offering only a very limited perspective on ToM and neglecting the complexity of human social interactions. To address this gap, we propose ToM-SSI: a new benchmark specifically designed to test ToM capabilities in environments rich with social interactions and spatial dynamics. While current ToM benchmarks are limited to text-only or dyadic interactions, ToM-SSI is multimodal and includes group interactions of up to four agents that communicate and move in situated environments. This unique design allows us to study, for the first time, mixed cooperative-obstructive settings and reasoning about multiple agents' mental state in parallel, thus capturing a wider range of social cognition than existing benchmarks. Our evaluations reveal that the current models' performance is still severely limited, especially in these new tasks, highlighting critical gaps for future research.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "EMNLP 2025 (Main)", "pdf_url": "https://arxiv.org/pdf/2509.05066.pdf", "abstract_url": "https://arxiv.org/abs/2509.05066", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "提出了ToM-SSI基准，用于评估多模态和群体交互中的心理理论能力，发现当前模型在这些新任务中表现受限。", "motivation": "解决现有心理理论基准（如Sally-Anne测试）的局限性，这些基准仅关注文本或二元交互，忽略了复杂的社会互动和空间动态。", "method": "设计了一个多模态基准，包括最多四个代理在情境环境中的群体交互，支持合作-阻碍混合设置和并行多代理心理状态推理。", "result": "评估显示，当前模型在新任务中表现严重受限，突显了未来研究的关键差距。", "conclusion": "ToM-SSI基准扩展了心理理论评估范围，强调了模型在复杂社会认知方面的不足，为未来改进提供了方向。"}}
{"id": "2509.04752", "title": "SePA: A Search-enhanced Predictive Agent for Personalized Health Coaching", "authors": ["Melik Ozolcer", "Sang Won Bae"], "abstract": "This paper introduces SePA (Search-enhanced Predictive AI Agent), a novel LLM health coaching system that integrates personalized machine learning and retrieval-augmented generation to deliver adaptive, evidence-based guidance. SePA combines: (1) Individualized models predicting daily stress, soreness, and injury risk from wearable sensor data (28 users, 1260 data points); and (2) A retrieval module that grounds LLM-generated feedback in expert-vetted web content to ensure contextual relevance and reliability. Our predictive models, evaluated with rolling-origin cross-validation and group k-fold cross-validation show that personalized models outperform generalized baselines. In a pilot expert study (n=4), SePA's retrieval-based advice was preferred over a non-retrieval baseline, yielding meaningful practical effect (Cliff's $\\delta$=0.3, p=0.05). We also quantify latency performance trade-offs between response quality and speed, offering a transparent blueprint for next-generation, trustworthy personal health informatics systems.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "Accepted at IEEE-EMBS International Conference on Biomedical and Health Informatics (BHI'25). 7 pages, 5 figures, 3 tables", "pdf_url": "https://arxiv.org/pdf/2509.04752.pdf", "abstract_url": "https://arxiv.org/abs/2509.04752", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "SePA是一种结合个性化机器学习和检索增强生成的LLM健康教练系统，通过可穿戴数据预测健康风险并提供基于证据的指导。", "motivation": "解决个性化健康指导中缺乏可靠性和上下文相关性的问题。", "method": "集成个性化预测模型和检索模块，使用传感器数据和专家验证的网络内容。", "result": "个性化模型优于通用基线，检索建议在专家研究中更受偏好，延迟与质量有权衡。", "conclusion": "SePA为下一代可信个人健康信息系统提供了透明蓝图。"}}
{"id": "2509.05199", "title": "Triadic Fusion of Cognitive, Functional, and Causal Dimensions for Explainable LLMs: The TAXAL Framework", "authors": ["David Herrera-Poyatos", "Carlos Peláez-González", "Cristina Zuheros", "Virilo Tejedor", "Rosana Montes", "Francisco Herrera"], "abstract": "Large Language Models (LLMs) are increasingly being deployed in high-risk domains where opacity, bias, and instability undermine trust and accountability. Traditional explainability methods, focused on surface outputs, do not capture the reasoning pathways, planning logic, and systemic impacts of agentic LLMs.", "subjects": "Computation and Language (cs.CL)", "comments": "27 pages, 9 tables and 2 figures", "pdf_url": "https://arxiv.org/pdf/2509.05199.pdf", "abstract_url": "https://arxiv.org/abs/2509.05199", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "提出TAXAL框架，融合认知、功能和因果维度，以增强高风险领域中LLM的可解释性，解决传统方法在推理路径和系统性影响方面的不足。", "motivation": "解决LLM在高风险领域部署时因不透明、偏见和不稳定导致的信任和问责问题，传统可解释性方法无法捕捉推理路径和系统影响。", "method": "使用TAXAL框架，通过融合认知、功能和因果维度来提供更全面的解释。", "result": "框架旨在改进LLM的可解释性，但摘要未提供具体结果，需参考全文。", "conclusion": "TAXAL框架为LLM的可解释性提供了新方法，有助于提升高风险应用中的信任和问责。"}}
{"id": "2509.04970", "title": "DeGuV: Depth-Guided Visual Reinforcement Learning for Generalization and Interpretability in Manipulation", "authors": ["Tien Pham", "Xinyun Chi", "Khang Nguyen", "Manfred Huber", "Angelo Cangelosi"], "abstract": "Reinforcement learning (RL) agents can learn to solve complex tasks from visual inputs, but generalizing these learned skills to new environments remains a major challenge in RL application, especially robotics. While data augmentation can improve generalization, it often compromises sample efficiency and training stability. This paper introduces DeGuV, an RL framework that enhances both generalization and sample efficiency. In specific, we leverage a learnable masker network that produces a mask from the depth input, preserving only critical visual information while discarding irrelevant pixels. Through this, we ensure that our RL agents focus on essential features, improving robustness under data augmentation. In addition, we incorporate contrastive learning and stabilize Q-value estimation under augmentation to further enhance sample efficiency and training stability. We evaluate our proposed method on the RL-ViGen benchmark using the Franka Emika robot and demonstrate its effectiveness in zero-shot sim-to-real transfer. Our results show that DeGuV outperforms state-of-the-art methods in both generalization and sample efficiency while also improving interpretability by highlighting the most relevant regions in the visual input", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.04970.pdf", "abstract_url": "https://arxiv.org/abs/2509.04970", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "DeGuV是一种深度引导的视觉强化学习框架，通过可学习的掩码网络利用深度输入保留关键视觉信息，结合对比学习和Q值稳定，提高泛化性、样本效率和可解释性，在RL-ViGen基准测试中优于现有方法。", "motivation": "解决视觉强化学习在泛化到新环境时样本效率低和训练不稳定的问题，特别是在机器人应用中。", "method": "使用可学习的掩码网络从深度输入生成掩码，保留关键视觉信息，结合对比学习和Q值稳定技术。", "result": "在RL-ViGen基准测试中，DeGuV在零样本sim-to-real转移中优于state-of-the-art方法，提高了泛化性、样本效率和可解释性。", "conclusion": "DeGuV框架有效提升了视觉强化学习的泛化能力和效率，同时通过突出相关视觉区域增强了可解释性。"}}
{"id": "2509.05197", "title": "AI Agents for Web Testing: A Case Study in the Wild", "authors": ["Naimeng Ye", "Xiao Yu", "Ruize Xu", "Tianyi Peng", "Zhou Yu"], "abstract": "Automated web testing plays a critical role in ensuring high-quality user experiences and delivering business value. Traditional approaches primarily focus on code coverage and load testing, but often fall short of capturing complex user behaviors, leaving many usability issues undetected. The emergence of large language models (LLM) and AI agents opens new possibilities for web testing by enabling human-like interaction with websites and a general awareness of common usability problems. In this work, we present WebProber, a prototype AI agent-based web testing framework. Given a URL, WebProber autonomously explores the website, simulating real user interactions, identifying bugs and usability issues, and producing a human-readable report. We evaluate WebProber through a case study of 120 academic personal websites, where it uncovered 29 usability issues--many of which were missed by traditional tools. Our findings highlight agent-based testing as a promising direction while outlining directions for developing next-generation, user-centered testing frameworks.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.05197.pdf", "abstract_url": "https://arxiv.org/abs/2509.05197", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍WebProber，一种基于AI代理的网页测试框架，通过模拟真实用户交互发现传统工具遗漏的可用性问题，在120个学术个人网站案例研究中识别出29个问题。", "motivation": "传统网页测试方法主要关注代码覆盖和负载测试，但难以捕捉复杂用户行为，导致许多可用性问题未被检测。", "method": "开发WebProber原型，利用大型语言模型和AI代理自主探索网站，模拟用户交互，识别错误和可用性问题，并生成可读报告。", "result": "在120个学术个人网站的案例研究中，WebProber发现了29个可用性问题，其中许多是传统工具遗漏的。", "conclusion": "基于代理的测试是一个有前景的方向，为开发下一代以用户为中心的测试框架提供了指导。"}}
{"id": "2509.04993", "title": "LLM Enabled Multi-Agent System for 6G Networks: Framework and Method of Dual-Loop Edge-Terminal Collaboration", "authors": ["Zheyan Qu", "Wenbo Wang", "Zitong Yu", "Boquan Sun", "Yang Li", "Xing Zhang"], "abstract": "The ubiquitous computing resources in 6G networks provide ideal environments for the fusion of large language models (LLMs) and intelligent services through the agent framework. With auxiliary modules and planning cores, LLM-enabled agents can autonomously plan and take actions to deal with diverse environment semantics and user intentions. However, the limited resources of individual network devices significantly hinder the efficient operation of LLM-enabled agents with complex tool calls, highlighting the urgent need for efficient multi-level device collaborations. To this end, the framework and method of the LLM-enabled multi-agent system with dual-loop terminal-edge collaborations are proposed in 6G networks. Firstly, the outer loop consists of the iterative collaborations between the global agent and multiple sub-agents deployed on edge servers and terminals, where the planning capability is enhanced through task decomposition and parallel sub-task distribution. Secondly, the inner loop utilizes sub-agents with dedicated roles to circularly reason, execute, and replan the sub-task, and the parallel tool calling generation with offloading strategies is incorporated to improve efficiency. The improved task planning capability and task execution efficiency are validated through the conducted case study in 6G-supported urban safety governance. Finally, the open challenges and future directions are thoroughly analyzed in 6G networks, accelerating the advent of the 6G era.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": "This paper has been accepted by IEEE Communications Magazine", "pdf_url": "https://arxiv.org/pdf/2509.04993.pdf", "abstract_url": "https://arxiv.org/abs/2509.04993", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于大语言模型的多智能体系统框架，通过终端-边缘双环协作，提升6G网络中的任务规划和执行效率，并以城市安全治理案例验证了其有效性。", "motivation": "解决6G网络中单个设备资源有限，阻碍LLM智能体高效运行和复杂工具调用的问题，需要高效的多级设备协作。", "method": "采用双环协作框架：外环通过全局代理与边缘服务器和终端上的子代理迭代协作，进行任务分解和并行分配；内环利用角色专用子代理循环推理、执行和重新规划子任务，并结合并行工具调用生成和卸载策略。", "result": "通过6G支持的城市安全治理案例研究，验证了改进的任务规划能力和执行效率。", "conclusion": "该框架加速了6G时代的到来，但文中还分析了开放挑战和未来方向，强调了进一步研究的必要性。"}}
