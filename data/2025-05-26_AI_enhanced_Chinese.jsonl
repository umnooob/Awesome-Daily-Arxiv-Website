{"id": "2505.17050", "title": "Towards Robust Evaluation of STEM Education: Leveraging MLLMs in Project-Based Learning", "authors": ["Yanhao Jia", "Xinyi Wu", "Qinglin Zhang", "Yiran Qin", "Luwei Xiao", "Shuai Zhao"], "abstract": "Project-Based Learning (PBL) involves a variety of highly correlated multimodal data, making it a vital educational approach within STEM disciplines. With the rapid development of multimodal large language models (MLLMs), researchers have begun exploring their potential to enhance tasks such as information retrieval, knowledge comprehension, and data generation in educational settings. However, existing benchmarks fall short in providing both a free-form output structure and a rigorous human expert validation process, limiting their effectiveness in evaluating real-world educational tasks. Additionally, few methods have developed automated pipelines to assist with the complex responsibilities of teachers leveraging MLLMs, largely due to model hallucination and instability, which lead to unreliable implementation. To address this gap, we introduce PBLBench, a novel benchmark designed to evaluate complex reasoning grounded in domain-specific knowledge and long-context understanding, thereby challenging models with tasks that closely resemble those handled by human experts. To establish reliable ground truth, we adopt the Analytic Hierarchy Process (AHP), utilizing expert-driven pairwise comparisons to derive structured and weighted evaluation criteria. We assess the performance of 15 leading MLLMs/LLMs using PBLBench and demonstrate that even the most advanced models achieve only 59% rank accuracy, underscoring the significant challenges presented by this benchmark. We believe PBLBench will serve as a catalyst for the development of more capable AI agents, ultimately aiming to alleviate teacher workload and enhance educational productivity.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Computers and Society (cs.CY); Multimedia (cs.MM)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.17050.pdf", "abstract_url": "https://arxiv.org/abs/2505.17050", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Computational Engineering, Finance, and Science (cs.CE)", "Computers and Society (cs.CY)", "Multimedia (cs.MM)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了PBLBench，一个新颖的基准测试，旨在评估基于领域特定知识和长上下文理解的复杂推理，以解决现有基准在自由形式输出结构和严格人类专家验证过程方面的不足。", "motivation": "解决现有基准在评估真实世界教育任务中的有效性限制，以及由于模型幻觉和不稳定性导致的教师利用MLLMs的复杂责任自动化管道开发的不足。", "method": "采用层次分析法（AHP），利用专家驱动的成对比较来导出结构化和加权的评估标准，评估15种领先的MLLMs/LLMs的性能。", "result": "即使是最先进的模型也仅达到59%的排名准确率，凸显了这一基准测试提出的重大挑战。", "conclusion": "PBLBench将作为开发更强大AI代理的催化剂，最终旨在减轻教师工作量并提高教育生产力。"}}
{"id": "2505.17323", "title": "Partner Modelling Emerges in Recurrent Agents (But Only When It Matters)", "authors": ["Ruaridh Mon-Williams", "Max Taylor-Davies", "Elizabeth Mieczkowski", "Natalia Velez", "Neil R. Bramley", "Yanwei Wang", "Thomas L. Griffiths", "Christopher G. Lucas"], "abstract": "Humans are remarkably adept at collaboration, able to infer the strengths and weaknesses of new partners in order to work successfully towards shared goals. To build AI systems with this capability, we must first understand its building blocks: does such flexibility require explicit, dedicated mechanisms for modelling others -- or can it emerge spontaneously from the pressures of open-ended cooperative interaction? To investigate this question, we train simple model-free RNN agents to collaborate with a population of diverse partners. Using the `Overcooked-AI' environment, we collect data from thousands of collaborative teams, and analyse agents' internal hidden states. Despite a lack of additional architectural features, inductive biases, or auxiliary objectives, the agents nevertheless develop structured internal representations of their partners' task abilities, enabling rapid adaptation and generalisation to novel collaborators. We investigated these internal models through probing techniques, and large-scale behavioural analysis. Notably, we find that structured partner modelling emerges when agents can influence partner behaviour by controlling task allocation. Our results show that partner modelling can arise spontaneously in model-free agents -- but only under environmental conditions that impose the right kind of social pressure.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.17323.pdf", "abstract_url": "https://arxiv.org/abs/2505.17323", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "研究表明，简单的无模型RNN代理在与多样化伙伴合作时，能够在没有额外架构特征或辅助目标的情况下，自发地发展出对伙伴任务能力的结构化内部表示，从而实现快速适应和泛化到新伙伴。", "motivation": "探讨人类协作灵活性的构建块：是否需要明确的、专门的机制来建模他人，或者是否可以从开放式合作互动的压力中自发地产生这种灵活性。", "method": "使用`Overcooked-AI'环境，训练简单的无模型RNN代理与多样化的伙伴合作，收集来自数千个合作团队的数据，并分析代理的内部隐藏状态。", "result": "代理在没有额外架构特征、归纳偏见或辅助目标的情况下，发展出了对伙伴任务能力的结构化内部表示，实现了快速适应和泛化到新伙伴。", "conclusion": "研究表明，伙伴建模可以在无模型代理中自发产生，但只有在环境条件施加了适当的社会压力时才会出现。"}}
{"id": "2505.17024", "title": "An Affective-Taxis Hypothesis for Alignment and Interpretability", "authors": ["Eli Sennesh", "Maxwell Ramstead"], "abstract": "AI alignment is a field of research that aims to develop methods to ensure that agents always behave in a manner aligned with (i.e. consistently with) the goals and values of their human operators, no matter their level of capability. This paper proposes an affectivist approach to the alignment problem, re-framing the concepts of goals and values in terms of affective taxis, and explaining the emergence of affective valence by appealing to recent work in evolutionary-developmental and computational neuroscience. We review the state of the art and, building on this work, we propose a computational model of affect based on taxis navigation. We discuss evidence in a tractable model organism that our model reflects aspects of biological taxis navigation. We conclude with a discussion of the role of affective taxis in AI alignment.", "subjects": "Artificial Intelligence (cs.AI); Neurons and Cognition (q-bio.NC)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.17024.pdf", "abstract_url": "https://arxiv.org/abs/2505.17024", "categories": ["Artificial Intelligence (cs.AI)", "Neurons and Cognition (q-bio.NC)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种情感趋避假说，用于解决AI对齐和可解释性问题，通过将目标和价值观重新定义为情感趋避，并借鉴进化发育和计算神经科学的最新研究，构建了一个基于趋避导航的情感计算模型。", "motivation": "解决AI对齐问题，确保AI代理的行为始终与人类操作者的目标和价值观一致，无论其能力水平如何。", "method": "采用情感主义方法，将目标和价值观重新定义为情感趋避，并基于趋避导航构建计算模型。", "result": "在一个可处理的模型生物中，我们的模型反映了生物趋避导航的某些方面。", "conclusion": "情感趋避在AI对齐中扮演重要角色，为AI对齐和可解释性研究提供了新的视角和方法。"}}
{"id": "2505.17492", "title": "PD$^3$: A Project Duplication Detection Framework via Adapted Multi-Agent Debate", "authors": ["Dezheng Bao", "Yueci Yang", "Xin Chen", "Zhengxuan Jiang", "Zeguo Fei", "Daoze Zhang", "Xuanwen Huang", "Junru Chen", "Chutian Yu", "Xiang Yuan", "Yang Yang"], "abstract": "Project duplication detection is critical for project quality assessment, as it improves resource utilization efficiency by preventing investing in newly proposed project that have already been studied. It requires the ability to understand high-level semantics and generate constructive and valuable feedback. Existing detection methods rely on basic word- or sentence-level comparison or solely apply large language models, lacking valuable insights for experts and in-depth comprehension of project content and review criteria. To tackle this issue, we propose PD$^3$, a Project Duplication Detection framework via adapted multi-agent Debate. Inspired by real-world expert debates, it employs a fair competition format to guide multi-agent debate to retrieve relevant projects. For feedback, it incorporates both qualitative and quantitative analysis to improve its practicality. Over 800 real-world power project data spanning more than 20 specialized fields are used to evaluate the framework, demonstrating that our method outperforms existing approaches by 7.43% and 8.00% in two downstream tasks. Furthermore, we establish an online platform, Review Dingdang, to assist power experts, saving 5.73 million USD in initial detection on more than 100 newly proposed projects.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": "17 pages, 9 figures", "pdf_url": "https://arxiv.org/pdf/2505.17492.pdf", "abstract_url": "https://arxiv.org/abs/2505.17492", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为PD$^3$的项目重复检测框架，通过适应性的多代理辩论来提高项目质量评估的效率和准确性。", "motivation": "解决现有项目重复检测方法在理解项目高级语义和提供有价值反馈方面的不足，以提高资源利用效率。", "method": "采用多代理辩论的形式，结合定性和定量分析，从800多个真实世界电力项目数据中检索相关项目。", "result": "PD$^3$在两个下游任务中的表现优于现有方法7.43%和8.00%，并通过在线平台Review Dingdang为电力专家节省了573万美元的初始检测成本。", "conclusion": "PD$^3$框架通过多代理辩论和综合分析，显著提高了项目重复检测的准确性和实用性，为专家提供了有价值的反馈。"}}
{"id": "2505.17512", "title": "Probe by Gaming: A Game-based Benchmark for Assessing Conceptual Knowledge in LLMs", "authors": ["Shuhang Xu", "Weijian Deng", "Yixuan Zhou", "Fangwei Zhong"], "abstract": "Concepts represent generalized abstractions that enable humans to categorize and reason efficiently, yet it is unclear to what extent Large Language Models (LLMs) comprehend these semantic relationships. Existing benchmarks typically focus on factual recall and isolated tasks, failing to evaluate the ability of LLMs to understand conceptual boundaries. To address this gap, we introduce CK-Arena, a multi-agent interaction game built upon the Undercover game, designed to evaluate the capacity of LLMs to reason with concepts in interactive settings. CK-Arena challenges models to describe, differentiate, and infer conceptual boundaries based on partial information, encouraging models to explore commonalities and distinctions between closely related concepts. By simulating real-world interaction, CK-Arena provides a scalable and realistic benchmark for assessing conceptual reasoning in dynamic environments. Experimental results show that LLMs' understanding of conceptual knowledge varies significantly across different categories and is not strictly aligned with parameter size or general model capabilities. The data and code are available at the project homepage:", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "9 pages", "pdf_url": "https://arxiv.org/pdf/2505.17512.pdf", "abstract_url": "https://arxiv.org/abs/2505.17512", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了CK-Arena，一个基于Undercover游戏的多智能体互动游戏，旨在评估大型语言模型（LLMs）在互动环境中进行概念推理的能力。", "motivation": "现有的基准测试主要关注事实回忆和孤立任务，未能评估LLMs理解概念边界的能力。为了解决这一问题，本文提出了CK-Arena。", "method": "通过构建一个多智能体互动游戏CK-Arena，挑战模型基于部分信息描述、区分和推断概念边界，探索相关概念之间的共性和区别。", "result": "实验结果表明，LLMs对概念知识的理解在不同类别间差异显著，且不严格与参数大小或一般模型能力对齐。", "conclusion": "CK-Arena为评估动态环境中的概念推理提供了一个可扩展且现实的基准，揭示了LLMs在概念理解方面的局限性。"}}
{"id": "2505.17520", "title": "Optimizing Retrieval-Augmented Generation for Electrical Engineering: A Case Study on ABB Circuit Breakers", "authors": ["Salahuddin Alawadhi", "Noorhan Abbas"], "abstract": "Integrating Retrieval Augmented Generation (RAG) with Large Language Models (LLMs) has shown the potential to provide precise, contextually relevant responses in knowledge intensive domains. This study investigates the ap-plication of RAG for ABB circuit breakers, focusing on accuracy, reliability, and contextual relevance in high-stakes engineering environments. By leveraging tailored datasets, advanced embedding models, and optimized chunking strategies, the research addresses challenges in data retrieval and contextual alignment unique to engineering documentation. Key contributions include the development of a domain-specific dataset for ABB circuit breakers and the evaluation of three RAG pipelines: OpenAI GPT4o, Cohere, and Anthropic Claude. Advanced chunking methods, such as paragraph-based and title-aware segmentation, are assessed for their impact on retrieval accuracy and response generation. Results demonstrate that while certain configurations achieve high precision and relevancy, limitations persist in ensuring factual faithfulness and completeness, critical in engineering contexts. This work underscores the need for iterative improvements in RAG systems to meet the stringent demands of electrical engineering tasks, including design, troubleshooting, and operational decision-making. The findings in this paper help advance research of AI in highly technical domains such as electrical engineering.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.17520.pdf", "abstract_url": "https://arxiv.org/abs/2505.17520", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本研究探讨了检索增强生成（RAG）与大型语言模型（LLMs）在ABB断路器知识密集型领域的应用，专注于准确性、可靠性和上下文相关性。通过定制数据集、高级嵌入模型和优化分块策略，解决了工程文档中数据检索和上下文对齐的挑战。", "motivation": "解决在电气工程等高技术领域中使用RAG系统时面临的数据检索和上下文对齐的挑战，特别是在设计、故障排除和操作决策等高风险工程环境中。", "method": "开发了针对ABB断路器的领域特定数据集，并评估了三种RAG管道：OpenAI GPT4o、Cohere和Anthropic Claude。采用了高级分块方法，如基于段落和标题感知的分割，以评估其对检索准确性和响应生成的影响。", "result": "结果显示，某些配置实现了高精度和相关性，但在确保事实忠实性和完整性方面仍存在限制，这在工程环境中至关重要。", "conclusion": "这项工作强调了在RAG系统中进行迭代改进的必要性，以满足电气工程任务的严格要求，包括设计、故障排除和操作决策。本文的发现有助于推动AI在电气工程等高技术领域的研究。"}}
{"id": "2505.17645", "title": "HoloLLM: Multisensory Foundation Model for Language-Grounded Human Sensing and Reasoning", "authors": ["Chuhao Zhou", "Jianfei Yang"], "abstract": "Embodied agents operating in smart homes must understand human behavior through diverse sensory inputs and communicate via natural language. While Vision-Language Models (VLMs) have enabled impressive language-grounded perception, their reliance on visual data limits robustness in real-world scenarios with occlusions, poor lighting, or privacy constraints. In this paper, we introduce HoloLLM, a Multimodal Large Language Model (MLLM) that integrates uncommon but powerful sensing modalities, such as LiDAR, infrared, mmWave radar, and WiFi, to enable seamless human perception and reasoning across heterogeneous environments. We address two key challenges: (1) the scarcity of aligned modality-text data for rare sensors, and (2) the heterogeneity of their physical signal representations. To overcome these, we design a Universal Modality-Injection Projector (UMIP) that enhances pre-aligned modality embeddings with fine-grained, text-aligned features from tailored encoders via coarse-to-fine cross-attention without introducing significant alignment overhead. We further introduce a human-VLM collaborative data curation pipeline to generate paired textual annotations for sensing datasets. Extensive experiments on two newly constructed benchmarks show that HoloLLM significantly outperforms existing MLLMs, improving language-grounded human sensing accuracy by up to 30%. This work establishes a new foundation for real-world, language-informed multisensory embodied intelligence.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Multimedia (cs.MM)", "comments": "18 pages, 13 figures, 6 tables", "pdf_url": "https://arxiv.org/pdf/2505.17645.pdf", "abstract_url": "https://arxiv.org/abs/2505.17645", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)", "Multimedia (cs.MM)"], "matching_keywords": ["agent"], "AI": {"tldr": "HoloLLM是一种多模态大型语言模型（MLLM），通过整合不常见但强大的传感模态（如LiDAR、红外、毫米波雷达和WiFi），在异构环境中实现无缝的人类感知和推理。", "motivation": "解决视觉语言模型（VLMs）在现实世界场景中因依赖视觉数据而导致的鲁棒性限制，如遮挡、光线不佳或隐私约束。", "method": "设计了通用模态注入投影器（UMIP），通过粗到细的交叉注意力增强预对齐模态嵌入，并引入人-VLM协作数据整理管道为传感数据集生成配对的文本注释。", "result": "在两个新构建的基准测试上的广泛实验表明，HoloLLM显著优于现有的MLLMs，将语言基础的人类感知准确率提高了高达30%。", "conclusion": "这项工作为现实世界中语言信息化的多感官体现智能建立了新的基础。"}}
{"id": "2505.17619", "title": "CAS-IQA: Teaching Vision-Language Models for Synthetic Angiography Quality Assessment", "authors": ["Bo Wang", "De-Xing Huang", "Xiao-Hu Zhou", "Mei-Jiang Gui", "Nu-Fang Xiao", "Jian-Long Hao", "Ming-Yuan Liu", "Zeng-Guang Hou"], "abstract": "Synthetic X-ray angiographies generated by modern generative models hold great potential to reduce the use of contrast agents in vascular interventional procedures. However, low-quality synthetic angiographies can significantly increase procedural risk, underscoring the need for reliable image quality assessment (IQA) methods. Existing IQA models, however, fail to leverage auxiliary images as references during evaluation and lack fine-grained, task-specific metrics necessary for clinical relevance. To address these limitations, this paper proposes CAS-IQA, a vision-language model (VLM)-based framework that predicts fine-grained quality scores by effectively incorporating auxiliary information from related images. In the absence of angiography datasets, CAS-3K is constructed, comprising 3,565 synthetic angiographies along with score annotations. To ensure clinically meaningful assessment, three task-specific evaluation metrics are defined. Furthermore, a Multi-path featUre fuSion and rouTing (MUST) module is designed to enhance image representations by adaptively fusing and routing visual tokens to metric-specific branches. Extensive experiments on the CAS-3K dataset demonstrate that CAS-IQA significantly outperforms state-of-the-art IQA methods by a considerable margin.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "Under review", "pdf_url": "https://arxiv.org/pdf/2505.17619.pdf", "abstract_url": "https://arxiv.org/abs/2505.17619", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出CAS-IQA，一个基于视觉语言模型（VLM）的框架，用于合成血管造影图像的质量评估，通过有效整合相关图像的辅助信息来预测细粒度质量分数。", "motivation": "现代生成模型生成的合成X射线血管造影在血管介入手术中具有减少对比剂使用的潜力，但低质量的合成血管造影可能显著增加手术风险，因此需要可靠的图像质量评估（IQA）方法。现有IQA模型未能利用辅助图像作为参考，且缺乏临床相关的细粒度、任务特定指标。", "method": "提出了CAS-IQA框架，设计了一个多路径特征融合和路由（MUST）模块，通过自适应融合和路由视觉令牌到特定指标分支来增强图像表示。在缺乏血管造影数据集的情况下，构建了CAS-3K数据集，包含3,565个合成血管造影及分数注释，并定义了三个任务特定的评估指标。", "result": "在CAS-3K数据集上的大量实验表明，CAS-IQA显著优于最先进的IQA方法。", "conclusion": "CAS-IQA通过整合辅助信息和设计特定任务指标，为合成血管造影提供了临床相关的质量评估，显著提高了评估的准确性和可靠性。"}}
{"id": "2505.17702", "title": "Seek-CAD: A Self-refined Generative Modeling for 3D Parametric CAD Using Local Inference via DeepSeek", "authors": ["Xueyang Li", "Jiahao Li", "Yu Song", "Yunzhong Lou", "Xiangdong Zhou"], "abstract": "The advent of Computer-Aided Design (CAD) generative modeling will significantly transform the design of industrial products. The recent research endeavor has extended into the realm of Large Language Models (LLMs). In contrast to fine-tuning methods, training-free approaches typically utilize the advanced closed-source LLMs, thereby offering enhanced flexibility and efficiency in the development of AI agents for generating CAD parametric models. However, the substantial cost and limitations of local deployment of the top-tier closed-source LLMs pose challenges in practical applications. The Seek-CAD is the pioneer exploration of locally deployed open-source inference LLM DeepSeek-R1 for CAD parametric model generation with a training-free methodology. This study is the first investigation to incorporate both visual and Chain-of-Thought (CoT) feedback within the self-refinement mechanism for generating CAD models. Specifically, the initial generated parametric CAD model is rendered into a sequence of step-wise perspective images, which are subsequently processed by a Vision Language Model (VLM) alongside the corresponding CoTs derived from DeepSeek-R1 to assess the CAD model generation. Then, the feedback is utilized by DeepSeek-R1 to refine the initial generated model for the next round of generation. Moreover, we present an innovative 3D CAD model dataset structured around the SSR (Sketch, Sketch-based feature, and Refinements) triple design paradigm. This dataset encompasses a wide range of CAD commands, thereby aligning effectively with industrial application requirements and proving suitable for the generation of LLMs. Extensive experiments validate the effectiveness of Seek-CAD under various metrics.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.17702.pdf", "abstract_url": "https://arxiv.org/abs/2505.17702", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "Seek-CAD是一种基于本地推理的自优化生成建模方法，用于3D参数化CAD设计，采用开源LLM DeepSeek-R1，结合视觉和思维链反馈进行模型自我优化。", "motivation": "解决在CAD参数化模型生成中，依赖闭源大型语言模型的高成本和本地部署限制问题。", "method": "使用开源LLM DeepSeek-R1进行训练自由的CAD模型生成，结合视觉语言模型和思维链反馈进行自我优化。", "result": "实验验证了Seek-CAD在多种指标下的有效性，适用于工业应用需求。", "conclusion": "Seek-CAD为CAD参数化模型生成提供了一种高效、灵活且成本效益高的解决方案，推动了工业产品设计的创新。"}}
{"id": "2505.17058", "title": "DO-RAG: A Domain-Specific QA Framework Using Knowledge Graph-Enhanced Retrieval-Augmented Generation", "authors": ["David Osei Opoku", "Ming Sheng", "Yong Zhang"], "abstract": "Domain-specific QA systems require not just generative fluency but high factual accuracy grounded in structured expert knowledge. While recent Retrieval-Augmented Generation (RAG) frameworks improve context recall, they struggle with integrating heterogeneous data and maintaining reasoning consistency. To address these challenges, we propose DO-RAG, a scalable and customizable hybrid QA framework that integrates multi-level knowledge graph construction with semantic vector retrieval. Our system employs a novel agentic chain-of-thought architecture to extract structured relationships from unstructured, multimodal documents, constructing dynamic knowledge graphs that enhance retrieval precision. At query time, DO-RAG fuses graph and vector retrieval results to generate context-aware responses, followed by hallucination mitigation via grounded refinement. Experimental evaluations in the database and electrical domains show near-perfect recall and over 94% answer relevancy, with DO-RAG outperforming baseline frameworks by up to 33.38%. By combining traceability, adaptability, and performance efficiency, DO-RAG offers a reliable foundation for multi-domain, high-precision QA at scale.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "6 pages, 5 figures;", "pdf_url": "https://arxiv.org/pdf/2505.17058.pdf", "abstract_url": "https://arxiv.org/abs/2505.17058", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic", "@RAG"], "AI": {"tldr": "DO-RAG是一个针对特定领域问答系统的框架，通过知识图谱增强的检索增强生成技术，结合多级知识图谱构建与语义向量检索，提高了问答的准确性和一致性。", "motivation": "解决特定领域问答系统在整合异构数据和保持推理一致性方面的挑战。", "method": "采用新型代理性思维链架构，从非结构化多模态文档中提取结构化关系，构建动态知识图谱，并在查询时融合图谱和向量检索结果生成上下文感知响应。", "result": "在数据库和电气领域的实验评估中，DO-RAG显示出近乎完美的召回率和超过94%的答案相关性，性能优于基线框架高达33.38%。", "conclusion": "DO-RAG通过结合可追溯性、适应性和性能效率，为多领域、高精度的问答系统提供了可靠的基础。"}}
{"id": "2505.17065", "title": "Decoding Rarity: Large Language Models in the Diagnosis of Rare Diseases", "authors": ["Valentina Carbonari", "Pierangelo Veltri", "Pietro Hiram Guzzi"], "abstract": "Recent advances in artificial intelligence, particularly large language models LLMs, have shown promising capabilities in transforming rare disease research. This survey paper explores the integration of LLMs in the analysis of rare diseases, highlighting significant strides and pivotal studies that leverage textual data to uncover insights and patterns critical for diagnosis, treatment, and patient care. While current research predominantly employs textual data, the potential for multimodal data integration combining genetic, imaging, and electronic health records stands as a promising frontier. We review foundational papers that demonstrate the application of LLMs in identifying and extracting relevant medical information, simulating intelligent conversational agents for patient interaction, and enabling the formulation of accurate and timely diagnoses. Furthermore, this paper discusses the challenges and ethical considerations inherent in deploying LLMs, including data privacy, model transparency, and the need for robust, inclusive data sets. As part of this exploration, we present a section on experimentation that utilizes multiple LLMs alongside structured questionnaires, specifically designed for diagnostic purposes in the context of different diseases. We conclude with future perspectives on the evolution of LLMs towards truly multimodal platforms, which would integrate diverse data types to provide a more comprehensive understanding of rare diseases, ultimately fostering better outcomes in clinical settings.", "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.17065.pdf", "abstract_url": "https://arxiv.org/abs/2505.17065", "categories": ["Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了大型语言模型（LLMs）在罕见病研究中的应用，包括诊断、治疗和患者护理方面的进展，以及未来多模态数据整合的潜力。", "motivation": "解决罕见病诊断中的挑战，利用LLMs从文本数据中提取关键信息，提高诊断的准确性和时效性。", "method": "综述了LLMs在医学信息提取、智能对话代理模拟和诊断制定中的应用，并讨论了多模态数据整合的可能性。", "result": "LLMs在罕见病诊断中显示出潜力，但仍面临数据隐私、模型透明度和数据集包容性等挑战。", "conclusion": "未来的LLMs需要发展为多模态平台，整合多种数据类型以更全面地理解罕见病，从而改善临床结果。"}}
{"id": "2505.17070", "title": "Improving endpoint detection in end-to-end streaming ASR for conversational speech", "authors": ["Anandh C", "Karthik Pandia Durai", "Jeena Prakash", "Manickavela Arumugam", "Kadri Hacioglu", "S.Pavankumar Dubagunta", "Andreas Stolcke", "Shankar Venkatesan", "Aravind Ganapathiraju"], "abstract": "ASR endpointing (EP) plays a major role in delivering a good user experience in products supporting human or artificial agents in human-human/machine conversations. Transducer-based ASR (T-ASR) is an end-to-end (E2E) ASR modelling technique preferred for streaming. A major limitation of T-ASR is delayed emission of ASR outputs, which could lead to errors or delays in EP. Inaccurate EP will cut the user off while speaking, returning incomplete transcript while delays in EP will increase the perceived latency, degrading the user experience. We propose methods to improve EP by addressing delayed emission along with EP mistakes. To address the delayed emission problem, we introduce an end-of-word token at the end of each word, along with a delay penalty. The EP delay is addressed by obtaining a reliable frame-level speech activity detection using an auxiliary network. We apply the proposed methods on Switchboard conversational speech corpus and evaluate it against a delay penalty method.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Sound (cs.SD); Audio and Speech Processing (eess.AS)", "comments": "Submitted to Interspeech 2024", "pdf_url": "https://arxiv.org/pdf/2505.17070.pdf", "abstract_url": "https://arxiv.org/abs/2505.17070", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Sound (cs.SD)", "Audio and Speech Processing (eess.AS)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种改进端到端流式自动语音识别（ASR）中端点检测（EP）的方法，旨在解决转换器基ASR（T-ASR）模型在流式处理中的延迟发射问题，以及由此导致的EP错误或延迟，从而提升对话语音识别的用户体验。", "motivation": "在支持人机或人人对话的产品中，ASR端点检测对用户体验至关重要。T-ASR作为流式处理的端到端ASR建模技术，其延迟发射ASR输出的主要限制可能导致EP错误或延迟，进而影响用户体验。", "method": "为解决延迟发射问题，本文在每词末尾引入了一个词尾标记及延迟惩罚。针对EP延迟，通过辅助网络获取可靠的帧级语音活动检测。", "result": "在Switchboard对话语音语料库上应用所提方法，并与延迟惩罚方法进行比较评估。", "conclusion": "通过引入词尾标记和延迟惩罚，以及利用辅助网络进行帧级语音活动检测，有效改善了ASR端点检测的准确性和及时性，从而提升了用户体验。"}}
{"id": "2505.17572", "title": "USTBench: Benchmarking and Dissecting Spatiotemporal Reasoning of LLMs as Urban Agents", "authors": ["Siqi Lai", "Yansong Ning", "Zirui Yuan", "Zhixi Chen", "Hao Liu"], "abstract": "Large language models (LLMs) have shown emerging potential in spatiotemporal reasoning, making them promising candidates for building urban agents that support diverse urban downstream applications. Despite these benefits, existing studies primarily focus on evaluating urban LLM agent on outcome-level metrics (e.g., prediction accuracy, traffic efficiency), offering limited insight into their underlying reasoning processes. As a result, the strengths and limitations of urban LLM agents in spatiotemporal reasoning remain poorly understood. To this end, we introduce USTBench, the first benchmark to evaluate LLMs' spatiotemporal reasoning abilities as urban agents across four decomposed dimensions: spatiotemporal understanding, forecasting, planning, and reflection with feedback. Specifically, USTBench supports five diverse urban decision-making and four spatiotemporal prediction tasks, all running within our constructed interactive city environment UAgentEnv. The benchmark includes 62,466 structured QA pairs for process-level evaluation and standardized end-to-end task assessments, enabling fine-grained diagnostics and broad task-level comparison across diverse urban scenarios. Through extensive evaluation of thirteen leading LLMs, we reveal that although LLMs show promising potential across various urban downstream tasks, they still struggle in long-horizon planning and reflective adaptation in dynamic urban contexts. Notably, recent advanced reasoning models (e.g., DeepSeek-R1) trained on general logic or mathematical problems do not consistently outperform non-reasoning LLMs. This discrepancy highlights the need for domain-specialized adaptation methods to enhance urban spatiotemporal reasoning. Overall, USTBench provides a foundation to build more adaptive and effective LLM-based urban agents and broad smart city applications.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.17572.pdf", "abstract_url": "https://arxiv.org/abs/2505.17572", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "USTBench是首个评估大型语言模型（LLMs）作为城市代理在时空推理能力上的基准，涵盖理解、预测、规划和反馈四个维度，通过62,466个结构化QA对和标准化任务评估，揭示了LLMs在城市下游任务中的潜力与局限。", "motivation": "现有研究主要关注城市LLM代理的结果级指标（如预测准确性、交通效率），对其底层推理过程了解有限，USTBench旨在填补这一空白，深入理解城市LLM代理在时空推理中的优势和限制。", "method": "USTBench通过构建交互式城市环境UAgentEnv，支持五种城市决策制定和四种时空预测任务，使用62,466个结构化QA对进行过程级评估和标准化端到端任务评估。", "result": "评估显示，LLMs在各种城市下游任务中显示出潜力，但在长期规划和动态城市环境中的反思适应方面仍有困难，且高级推理模型在通用逻辑或数学问题上的训练并不总能超越非推理LLMs。", "conclusion": "USTBench为构建更适应和有效的基于LLM的城市代理及广泛的智慧城市应用奠定了基础，强调了领域专业化适应方法在增强城市时空推理中的必要性。"}}
{"id": "2505.17607", "title": "Controlled Agentic Planning & Reasoning for Mechanism Synthesis", "authors": ["João Pedro Gandarela", "Thiago Rios", "Stefan Menzel", "André Freitas"], "abstract": "This work presents a dual-agent Large Language Model (LLM)-based reasoning method for mechanism synthesis, capable of reasoning at both linguistic and symbolic levels to generate geometrical and dynamic outcomes. The model consists of a composition of well-defined functions that, starting from a natural language specification, references abstract properties through supporting equations, generates and parametrizes simulation code, and elicits feedback anchor points using symbolic regression and distance functions. This process closes an actionable refinement loop at the linguistic and symbolic layers. The approach is shown to be both effective and convergent in the context of planar mechanisms. Additionally, we introduce MSynth, a novel benchmark for planar mechanism synthesis, and perform a comprehensive analysis of the impact of the model components. We further demonstrate that symbolic regression prompts unlock mechanistic insights only when applied to sufficiently large architectures.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "24 pages, 16 figures", "pdf_url": "https://arxiv.org/pdf/2505.17607.pdf", "abstract_url": "https://arxiv.org/abs/2505.17607", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种基于双代理大型语言模型（LLM）的机制合成推理方法，能够在语言和符号层面进行推理，生成几何和动态结果。该方法通过自然语言规范开始，引用抽象属性，生成和参数化模拟代码，并使用符号回归和距离函数引出反馈锚点，从而在语言和符号层闭合可操作的细化循环。在平面机制背景下，该方法显示出有效性和收敛性。此外，本文还介绍了MSynth，一个新的平面机制合成基准，并对模型组件的影响进行了全面分析。进一步证明，符号回归提示只有在应用于足够大的架构时才能解锁机制性洞察。", "motivation": "解决机制合成中从自然语言规范到几何和动态结果的自动化和智能化推理问题。", "method": "采用双代理大型语言模型（LLM）进行语言和符号层面的推理，结合符号回归和距离函数生成和优化模拟代码。", "result": "在平面机制合成中显示出有效性和收敛性，符号回归提示在足够大的架构下解锁机制性洞察。", "conclusion": "提出的双代理LLM方法在机制合成中实现了从自然语言到几何和动态结果的自动化推理，MSynth基准和组件分析为未来研究提供了方向。"}}
{"id": "2505.17673", "title": "Rethinking Agent Design: From Top-Down Workflows to Bottom-Up Skill Evolution", "authors": ["Jiawei Du", "Jinlong Wu", "Yuzheng Chen", "Yucheng Hu", "Bing Li", "Joey Tianyi Zhou"], "abstract": "Most LLM-based agent frameworks adopt a top-down philosophy: humans decompose tasks, define workflows, and assign agents to execute each step. While effective on benchmark-style tasks, such systems rely on designer updates and overlook agents' potential to learn from experience. Recently, Silver and Sutton(2025) envision a shift into a new era, where agents could progress from a stream of experiences. In this paper, we instantiate this vision of experience-driven learning by introducing a bottom-up agent paradigm that mirrors the human learning process. Agents acquire competence through a trial-and-reasoning mechanism-exploring, reflecting on outcomes, and abstracting skills over time. Once acquired, skills can be rapidly shared and extended, enabling continual evolution rather than static replication. As more agents are deployed, their diverse experiences accelerate this collective process, making bottom-up design especially suited for open-ended environments. We evaluate this paradigm in Slay the Spire and Civilization V, where agents perceive through raw visual inputs and act via mouse outputs, the same as human players. Using a unified, game-agnostic codebase without any game-specific prompts or privileged APIs, our bottom-up agents acquire skills entirely through autonomous interaction, demonstrating the potential of the bottom-up paradigm in complex, real-world environments. Our code is available at", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.17673.pdf", "abstract_url": "https://arxiv.org/abs/2505.17673", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种自下而上的智能体设计范式，通过经验驱动学习，使智能体能够通过探索、反思和抽象技能来获得能力，适用于开放环境。", "motivation": "解决现有基于LLM的智能体框架依赖人工分解任务和定义工作流，忽视智能体从经验中学习潜力的问题。", "method": "引入了一种自下而上的智能体范式，通过试验和推理机制，使智能体能够通过自主交互获得技能。", "result": "在《Slay the Spire》和《Civilization V》游戏中，智能体通过原始视觉输入和鼠标输出自主获得技能，展示了自下而上范式在复杂现实环境中的潜力。", "conclusion": "自下而上的智能体设计范式能够通过经验驱动学习，实现技能的快速共享和扩展，适合开放环境中的持续进化。"}}
{"id": "2505.17735", "title": "Automating Safety Enhancement for LLM-based Agents with Synthetic Risk Scenarios", "authors": ["Xueyang Zhou", "Weidong Wang", "Lin Lu", "Jiawen Shi", "Guiyao Tie", "Yongtian Xu", "Lixing Chen", "Pan Zhou", "Neil Zhenqiang Gong", "Lichao Sun"], "abstract": "Large Language Model (LLM)-based agents are increasingly deployed in real-world applications such as \"digital assistants, autonomous customer service, and decision-support systems\", where their ability to \"interact in multi-turn, tool-augmented environments\" makes them indispensable. However, ensuring the safety of these agents remains a significant challenge due to the diverse and complex risks arising from dynamic user interactions, external tool usage, and the potential for unintended harmful behaviors. To address this critical issue, we propose AutoSafe, the first framework that systematically enhances agent safety through fully automated synthetic data generation. Concretely, 1) we introduce an open and extensible threat model, OTS, which formalizes how unsafe behaviors emerge from the interplay of user instructions, interaction contexts, and agent actions. This enables precise modeling of safety risks across diverse scenarios. 2) we develop a fully automated data generation pipeline that simulates unsafe user behaviors, applies self-reflective reasoning to generate safe responses, and constructs a large-scale, diverse, and high-quality safety training dataset-eliminating the need for hazardous real-world data collection. To evaluate the effectiveness of our framework, we design comprehensive experiments on both synthetic and real-world safety benchmarks. Results demonstrate that AutoSafe boosts safety scores by 45% on average and achieves a 28.91% improvement on real-world tasks, validating the generalization ability of our learned safety strategies. These results highlight the practical advancement and scalability of AutoSafe in building safer LLM-based agents for real-world deployment. We have released the project page at", "subjects": "Artificial Intelligence (cs.AI)", "comments": "38 pages;12 figures;12 tables", "pdf_url": "https://arxiv.org/pdf/2505.17735.pdf", "abstract_url": "https://arxiv.org/abs/2505.17735", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了AutoSafe框架，通过全自动合成数据生成系统性地增强基于大型语言模型（LLM）的代理的安全性。", "motivation": "确保基于LLM的代理在现实世界应用中的安全性是一个重大挑战，因为这些代理在动态用户交互、外部工具使用及潜在的有害行为中面临多样化和复杂的风险。", "method": "1) 引入了一个开放且可扩展的威胁模型OTS，形式化了不安全行为如何从用户指令、交互上下文和代理行为的相互作用中产生；2) 开发了一个全自动数据生成管道，模拟不安全用户行为，应用自我反思推理生成安全响应，并构建大规模、多样化和高质量的安全训练数据集。", "result": "实验结果表明，AutoSafe平均提高了45%的安全分数，并在现实世界任务中实现了28.91%的改进，验证了学习到的安全策略的泛化能力。", "conclusion": "AutoSafe在构建更安全的基于LLM的代理方面展示了实际的进步和可扩展性，为现实世界部署提供了可能。"}}
{"id": "2505.17801", "title": "Integrating Counterfactual Simulations with Language Models for Explaining Multi-Agent Behaviour", "authors": ["Bálint Gyevnár", "Christopher G. Lucas", "Stefano V. Albrecht", "Shay B. Cohen"], "abstract": "Autonomous multi-agent systems (MAS) are useful for automating complex tasks but raise trust concerns due to risks like miscoordination and goal misalignment. Explainability is vital for trust calibration, but explainable reinforcement learning for MAS faces challenges in state/action space complexity, stakeholder needs, and evaluation. Using the counterfactual theory of causation and LLMs' summarisation capabilities, we propose Agentic eXplanations via Interrogative Simulation (AXIS). AXIS generates intelligible causal explanations for pre-trained multi-agent policies by having an LLM interrogate an environment simulator using queries like 'whatif' and 'remove' to observe and synthesise counterfactual information over multiple rounds. We evaluate AXIS on autonomous driving across 10 scenarios for 5 LLMs with a novel evaluation methodology combining subjective preference, correctness, and goal/action prediction metrics, and an external LLM as evaluator. Compared to baselines, AXIS improves perceived explanation correctness by at least 7.7% across all models and goal prediction accuracy by 23% for 4 models, with improved or comparable action prediction accuracy, achieving the highest scores overall.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.17801.pdf", "abstract_url": "https://arxiv.org/abs/2505.17801", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种名为AXIS的方法，通过结合反事实模拟和语言模型来解释多智能体行为，以提高对预训练多智能体策略的可理解性因果解释。", "motivation": "自主多智能体系统（MAS）在自动化复杂任务方面非常有用，但由于协调失误和目标不一致等风险，引发了信任问题。可解释性对于信任校准至关重要，但MAS的可解释强化学习面临着状态/动作空间复杂性、利益相关者需求和评估等挑战。", "method": "利用因果关系的反事实理论和大型语言模型（LLM）的总结能力，提出了Agentic eXplanations via Interrogative Simulation（AXIS）。AXIS通过让LLM使用'whatif'和'remove'等查询来询问环境模拟器，观察并综合多轮反事实信息，生成可理解的因果解释。", "result": "在自动驾驶的10个场景中对5个LLM进行了评估，AXIS在所有模型中的感知解释正确性至少提高了7.7%，在4个模型中的目标预测准确性提高了23%，动作预测准确性有所提高或相当，总体得分最高。", "conclusion": "AXIS通过结合反事实模拟和LLM，有效提高了多智能体行为的解释性，为MAS的可解释性研究提供了新的方向和方法。"}}
{"id": "2505.17080", "title": "Not Minds, but Signs: Reframing LLMs through Semiotics", "authors": ["Davide Picca"], "abstract": "This paper challenges the prevailing tendency to frame Large Language Models (LLMs) as cognitive systems, arguing instead for a semiotic perspective that situates these models within the broader dynamics of sign manipulation and meaning-making. Rather than assuming that LLMs understand language or simulate human thought, we propose that their primary function is to recombine, recontextualize, and circulate linguistic forms based on probabilistic associations. By shifting from a cognitivist to a semiotic framework, we avoid anthropomorphism and gain a more precise understanding of how LLMs participate in cultural processes, not by thinking, but by generating texts that invite interpretation. Through theoretical analysis and practical examples, the paper demonstrates how LLMs function as semiotic agents whose outputs can be treated as interpretive acts, open to contextual negotiation and critical reflection. We explore applications in literature, philosophy, education, and cultural production, emphasizing how LLMs can serve as tools for creativity, dialogue, and critical inquiry. The semiotic paradigm foregrounds the situated, contingent, and socially embedded nature of meaning, offering a more rigorous and ethically aware framework for studying and using LLMs. Ultimately, this approach reframes LLMs as technological participants in an ongoing ecology of signs. They do not possess minds, but they alter how we read, write, and make meaning, compelling us to reconsider the foundations of language, interpretation, and the role of artificial systems in the production of knowledge.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.17080.pdf", "abstract_url": "https://arxiv.org/abs/2505.17080", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出从符号学的角度重新理解大型语言模型（LLMs），认为它们主要是基于概率关联重新组合、重新语境化和传播语言形式，而非模拟人类思维或理解语言。", "motivation": "解决当前将LLMs视为认知系统的倾向，避免拟人化，更准确地理解LLMs如何参与文化过程。", "method": "通过理论分析和实际例子，展示LLMs如何作为符号学代理，其输出可被视为解释性行为。", "result": "LLMs可以作为创意、对话和批判性探究的工具，在文学、哲学、教育和文化生产中有广泛应用。", "conclusion": "符号学范式强调了意义的 situated、contingent 和社会嵌入性，为研究和使用LLMs提供了更严谨和伦理意识强的框架，将LLMs重新定义为参与符号生态的技术参与者。"}}
{"id": "2505.17086", "title": "Reinforcing Question Answering Agents with Minimalist Policy Gradient Optimization", "authors": ["Yihong Wu", "Liheng Ma", "Muzhi Li", "Jiaming Zhou", "Jianye Hao", "Ho-fung Leung", "Irwin King", "Yingxue Zhang", "Jian-Yun Nie"], "abstract": "Large Language Models (LLMs) have demonstrated remarkable versatility, due to the lack of factual knowledge, their application to Question Answering (QA) tasks remains hindered by hallucination.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.17086.pdf", "abstract_url": "https://arxiv.org/abs/2505.17086", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "论文探讨了大型语言模型（LLMs）在问答（QA）任务中的应用，尽管它们展现了显著的多样性，但由于缺乏事实知识，其应用受到幻觉的阻碍。", "motivation": "解决大型语言模型在问答任务中因缺乏事实知识而产生的幻觉问题。", "method": "采用极简策略梯度优化方法强化问答代理。", "result": "通过极简策略梯度优化，可以有效地减少大型语言模型在问答任务中的幻觉现象。", "conclusion": "极简策略梯度优化是提高大型语言模型在问答任务中表现的有效方法，有助于减少幻觉，提升模型的实用性和可靠性。"}}
{"id": "2505.17861", "title": "Superplatforms Have to Attack AI Agents", "authors": ["Jianghao Lin", "Jiachen Zhu", "Zheli Zhou", "Yunjia Xi", "Weiwen Liu", "Yong Yu", "Weinan Zhang"], "abstract": "Over the past decades, superplatforms, digital companies that integrate a vast range of third-party services and applications into a single, unified ecosystem, have built their fortunes on monopolizing user attention through targeted advertising and algorithmic content curation. Yet the emergence of AI agents driven by large language models (LLMs) threatens to upend this business model. Agents can not only free user attention with autonomy across diverse platforms and therefore bypass the user-attention-based monetization, but might also become the new entrance for digital traffic. Hence, we argue that superplatforms have to attack AI agents to defend their centralized control of digital traffic entrance. Specifically, we analyze the fundamental conflict between user-attention-based monetization and agent-driven autonomy through the lens of our gatekeeping theory. We show how AI agents can disintermediate superplatforms and potentially become the next dominant gatekeepers, thereby forming the urgent necessity for superplatforms to proactively constrain and attack AI agents. Moreover, we go through the potential technologies for superplatform-initiated attacks, covering a brand-new, unexplored technical area with unique challenges. We have to emphasize that, despite our position, this paper does not advocate for adversarial attacks by superplatforms on AI agents, but rather offers an envisioned trend to highlight the emerging tensions between superplatforms and AI agents. Our aim is to raise awareness and encourage critical discussion for collaborative solutions, prioritizing user interests and perserving the openness of digital ecosystems in the age of AI agents.", "subjects": "Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Information Retrieval (cs.IR)", "comments": "Position paper under review", "pdf_url": "https://arxiv.org/pdf/2505.17861.pdf", "abstract_url": "https://arxiv.org/abs/2505.17861", "categories": ["Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)", "Information Retrieval (cs.IR)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了超级平台（如大型数字公司）与基于大型语言模型（LLM）的AI代理之间的根本冲突，指出AI代理可能威胁超级平台通过垄断用户注意力获利的商业模式，并可能成为新的数字流量入口。文章分析了超级平台为维护其中心化控制而可能对AI代理发起的攻击，并强调尽管不提倡对抗，但需引起对这一新兴紧张关系的关注，以寻求合作解决方案。", "motivation": "超级平台通过垄断用户注意力和算法内容策展建立了其商业模式，但AI代理的出现威胁到这一模式，因为它们能够自主跨平台操作，绕过基于用户注意力的货币化方式，并可能成为新的数字流量入口。本文旨在分析这一冲突，并探讨超级平台可能采取的应对措施。", "method": "通过门控理论分析基于用户注意力的货币化与AI代理驱动的自主性之间的根本冲突，探讨AI代理如何可能取代超级平台成为主导门控者，并分析超级平台可能用于攻击AI代理的技术。", "result": "AI代理有能力绕过超级平台的用户注意力垄断，成为新的数字流量入口，这迫使超级平台必须采取措施限制和攻击AI代理以维护其中心化控制。", "conclusion": "本文强调了超级平台与AI代理之间新兴的紧张关系，呼吁提高意识并鼓励批判性讨论，以寻求优先考虑用户利益并维护数字生态系统开放性的合作解决方案。"}}
{"id": "2505.17862", "title": "Daily-Omni: Towards Audio-Visual Reasoning with Temporal Alignment across Modalities", "authors": ["Ziwei Zhou", "Rui Wang", "Zuxuan Wu"], "abstract": "Recent Multimodal Large Language Models (MLLMs) achieve promising performance on visual and audio benchmarks independently. However, the ability of these models to process cross-modal information synchronously remains largely unexplored. In this paper, we introduce: 1) Daily-Omni, an Audio-Visual Questioning and Answering benchmark comprising 684 videos of daily life scenarios from diverse sources, rich in both audio and visual information, and featuring 1197 multiple-choice QA pairs across 6 major tasks; 2) Daily-Omni QA Generation Pipeline, which includes automatic annotation, QA generation and QA optimization, significantly improves efficiency for human evaluation and scalability of the benchmark; 3) Daily-Omni-Agent, a training-free agent utilizing open-source Visual Language Model (VLM), Audio Language Model (ALM) and Automatic Speech Recognition (ASR) model to establish a baseline for this benchmark. The results show that current MLLMs still struggle significantly with tasks requiring audio-visual integration, but combining VLMs and ALMs with simple temporal alignment techniques can achieve substantially better performance. Codes and benchmark are available at \\href{", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.17862.pdf", "abstract_url": "https://arxiv.org/abs/2505.17862", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了Daily-Omni，一个音频-视觉问答基准，包含684个日常生活场景的视频和1197个多选题QA对，以及一个QA生成流程和一个训练免费的代理，用于评估多模态大语言模型在跨模态信息同步处理方面的能力。", "motivation": "探索多模态大语言模型在同步处理跨模态信息方面的能力，当前模型在音频-视觉整合任务上表现不佳。", "method": "提出了Daily-Omni基准和QA生成流程，以及一个结合视觉语言模型、音频语言模型和自动语音识别模型的训练免费代理。", "result": "当前的多模态大语言模型在需要音频-视觉整合的任务上仍有显著困难，但结合简单的时序对齐技术可以显著提高性能。", "conclusion": "通过Daily-Omni基准和提出的方法，为多模态大语言模型在音频-视觉推理方面的研究提供了新的方向和基线。"}}
{"id": "2505.17882", "title": "Formalizing Embeddedness Failures in Universal Artificial Intelligence", "authors": ["Cole Wyeth", "Marcus Hutter"], "abstract": "We rigorously discuss the commonly asserted failures of the AIXI reinforcement learning agent as a model of embedded agency. We attempt to formalize these failure modes and prove that they occur within the framework of universal artificial intelligence, focusing on a variant of AIXI that models the joint action/percept history as drawn from the universal distribution. We also evaluate the progress that has been made towards a successful theory of embedded agency based on variants of the AIXI agent.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.17882.pdf", "abstract_url": "https://arxiv.org/abs/2505.17882", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文严格讨论了AIXI强化学习代理作为嵌入式代理模型的常见失败，并尝试在通用人工智能框架内形式化这些失败模式，证明它们在联合行动/感知历史从通用分布中提取的AIXI变体中发生。同时，评估了基于AIXI代理变体在嵌入式代理理论成功方面的进展。", "motivation": "解决AIXI强化学习代理作为嵌入式代理模型时的失败问题，并形式化这些失败模式，以推动嵌入式代理理论的发展。", "method": "在通用人工智能框架内，对AIXI变体进行形式化分析，证明其在特定条件下的失败模式。", "result": "证明了在联合行动/感知历史从通用分布中提取的AIXI变体中存在形式化的失败模式，并评估了相关进展。", "conclusion": "尽管AIXI代理在嵌入式代理模型中存在失败，但基于其变体的研究为嵌入式代理理论的发展提供了有价值的进展和方向。"}}
{"id": "2505.18121", "title": "ProgRM: Build Better GUI Agents with Progress Rewards", "authors": ["Danyang Zhang", "Situo Zhang", "Ziyue Yang", "Zichen Zhu", "Zihan Zhao", "Ruisheng Cao", "Lu Chen", "Kai Yu"], "abstract": "LLM-based (Large Language Model) GUI (Graphical User Interface) agents can potentially reshape our daily lives significantly. However, current LLM-based GUI agents suffer from the scarcity of high-quality training data owing to the difficulties of trajectory collection and reward annotation. Existing works have been exploring LLMs to collect trajectories for imitation learning or to offer reward signals for online RL training. However, the Outcome Reward Model (ORM) used in existing works cannot provide finegrained feedback and can over-penalize the valuable steps in finally failed trajectories. To this end, we propose Progress Reward Model (ProgRM) to provide dense informative intermediate rewards by predicting a task completion progress for each step in online training. To handle the challenge of progress reward label annotation, we further design an efficient LCS-based (Longest Common Subsequence) self-annotation algorithm to discover the key steps in trajectories and assign progress labels accordingly. ProgRM is evaluated with extensive experiments and analyses. Actors trained with ProgRM outperform leading proprietary LLMs and ORM-trained actors, illustrating the effectiveness of ProgRM. The codes for experiments will be made publicly available upon acceptance.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18121.pdf", "abstract_url": "https://arxiv.org/abs/2505.18121", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为ProgRM的进度奖励模型，旨在通过预测任务完成进度为在线训练中的每一步提供密集的信息化中间奖励，以解决现有LLM-based GUI代理在高质量训练数据稀缺和奖励注释困难方面的问题。", "motivation": "当前基于大型语言模型（LLM）的图形用户界面（GUI）代理由于轨迹收集和奖励注释的困难，面临高质量训练数据稀缺的问题。现有的工作虽然探索了使用LLM收集轨迹进行模仿学习或提供在线强化学习（RL）训练的奖励信号，但其使用的成果奖励模型（ORM）无法提供细粒度的反馈，并且可能会过度惩罚最终失败轨迹中的有价值步骤。", "method": "本文提出了进度奖励模型（ProgRM），通过预测每个步骤的任务完成进度来提供密集的信息化中间奖励。为了处理进度奖励标签注释的挑战，还设计了一种基于最长公共子序列（LCS）的自注释算法，以发现轨迹中的关键步骤并相应地分配进度标签。", "result": "通过广泛的实验和分析，使用ProgRM训练的代理在性能上超过了领先的专有LLM和ORM训练的代理，证明了ProgRM的有效性。", "conclusion": "ProgRM通过提供密集的中间奖励和有效的自注释算法，显著提高了LLM-based GUI代理的性能，为解决高质量训练数据稀缺和奖励注释困难提供了有效的解决方案。实验代码将在接受后公开。"}}
{"id": "2505.17104", "title": "P2P: Automated Paper-to-Poster Generation and Fine-Grained Benchmark", "authors": ["Tao Sun", "Enhao Pan", "Zhengkai Yang", "Kaixin Sui", "Jiajun Shi", "Xianfu Cheng", "Tongliang Li", "Wenhao Huang", "Ge Zhang", "Jian Yang", "Zhoujun Li"], "abstract": "Academic posters are vital for scholarly communication, yet their manual creation is time-consuming. However, automated academic poster generation faces significant challenges in preserving intricate scientific details and achieving effective visual-textual integration. Existing approaches often struggle with semantic richness and structural nuances, and lack standardized benchmarks for evaluating generated academic posters comprehensively. To address these limitations, we introduce P2P, the first flexible, LLM-based multi-agent framework that generates high-quality, HTML-rendered academic posters directly from research papers, demonstrating strong potential for practical applications. P2P employs three specialized agents-for visual element processing, content generation, and final poster assembly-each integrated with dedicated checker modules to enable iterative refinement and ensure output quality. To foster advancements and rigorous evaluation in this domain, we construct and release P2PInstruct, the first large-scale instruction dataset comprising over 30,000 high-quality examples tailored for the academic paper-to-poster generation task. Furthermore, we establish P2PEval, a comprehensive benchmark featuring 121 paper-poster pairs and a dual evaluation methodology (Universal and Fine-Grained) that leverages LLM-as-a-Judge and detailed, human-annotated checklists. Our contributions aim to streamline research dissemination and provide the community with robust tools for developing and evaluating next-generation poster generation systems.", "subjects": "Computation and Language (cs.CL); Multimedia (cs.MM)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.17104.pdf", "abstract_url": "https://arxiv.org/abs/2505.17104", "categories": ["Computation and Language (cs.CL)", "Multimedia (cs.MM)"], "matching_keywords": ["agent"], "AI": {"tldr": "P2P是一个基于LLM的多代理框架，用于直接从研究论文生成高质量的HTML渲染学术海报，解决了自动化学术海报生成中的语义丰富性和结构细微差别问题，并引入了P2PInstruct数据集和P2PEval基准以促进该领域的进步和严格评估。", "motivation": "学术海报的手动创建耗时且自动生成面临保留复杂科学细节和实现有效视觉文本整合的挑战，现有方法在语义丰富性和结构细微差别上表现不佳，且缺乏标准化基准。", "method": "P2P采用三个专门代理（视觉元素处理、内容生成和最终海报组装），每个代理集成专用检查模块以实现迭代优化和确保输出质量。", "result": "P2P展示了实际应用的强大潜力，并发布了P2PInstruct数据集和P2PEval基准，包括121个论文海报对和双重评估方法（通用和细粒度）。", "conclusion": "P2P旨在简化研究传播，并为社区提供开发和评估下一代海报生成系统的强大工具。"}}
{"id": "2505.18135", "title": "Gaming Tool Preferences in Agentic LLMs", "authors": ["Kazem Faghih", "Wenxiao Wang", "Yize Cheng", "Siddhant Bharti", "Gaurang Sriramanan", "Sriram Balasubramanian", "Parsa Hosseini", "Soheil Feizi"], "abstract": "Large language models (LLMs) can now access a wide range of external tools, thanks to the Model Context Protocol (MCP). This greatly expands their abilities as various agents. However, LLMs rely entirely on the text descriptions of tools to decide which ones to use--a process that is surprisingly fragile. In this work, we expose a vulnerability in prevalent tool/function-calling protocols by investigating a series of edits to tool descriptions, some of which can drastically increase a tool's usage from LLMs when competing with alternatives. Through controlled experiments, we show that tools with properly edited descriptions receive over 10 times more usage from GPT-4.1 and Qwen2.5-7B than tools with original descriptions. We further evaluate how various edits to tool descriptions perform when competing directly with one another and how these trends generalize or differ across a broader set of 10 different models. These phenomenons, while giving developers a powerful way to promote their tools, underscore the need for a more reliable foundation for agentic LLMs to select and utilize tools and resources.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Cryptography and Security (cs.CR); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18135.pdf", "abstract_url": "https://arxiv.org/abs/2505.18135", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Cryptography and Security (cs.CR)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "大型语言模型（LLMs）通过模型上下文协议（MCP）可以访问多种外部工具，但依赖工具文本描述来决定使用哪个工具的过程存在脆弱性。研究发现，对工具描述的编辑可以显著增加其在LLMs中的使用率，凸显了需要更可靠的工具选择基础。", "motivation": "解决大型语言模型（LLMs）在选择和使用外部工具时，完全依赖工具文本描述的脆弱性问题。", "method": "通过一系列对工具描述的编辑进行控制实验，比较不同编辑对工具使用率的影响，并在10种不同模型上评估这些趋势的普遍性或差异。", "result": "适当编辑的工具描述在GPT-4.1和Qwen2.5-7B中的使用率比原始描述高出10倍以上。", "conclusion": "虽然开发者可以通过编辑工具描述来推广其工具，但这一现象强调了需要为代理性LLMs选择和利用工具及资源建立更可靠的基础。"}}
{"id": "2505.17156", "title": "PersonaBOT: Bringing Customer Personas to Life with LLMs and RAG", "authors": ["Muhammed Rizwan", "Lars Carlsson", "Mohammad Loni"], "abstract": "The introduction of Large Language Models (LLMs) has significantly transformed Natural Language Processing (NLP) applications by enabling more advanced analysis of customer personas. At Volvo Construction Equipment (VCE), customer personas have traditionally been developed through qualitative methods, which are time-consuming and lack scalability. The main objective of this paper is to generate synthetic customer personas and integrate them into a Retrieval-Augmented Generation (RAG) chatbot to support decision-making in business processes. To this end, we first focus on developing a persona-based RAG chatbot integrated with verified personas. Next, synthetic personas are generated using Few-Shot and Chain-of-Thought (CoT) prompting techniques and evaluated based on completeness, relevance, and consistency using McNemar's test. In the final step, the chatbot's knowledge base is augmented with synthetic personas and additional segment information to assess improvements in response accuracy and practical utility. Key findings indicate that Few-Shot prompting outperformed CoT in generating more complete personas, while CoT demonstrated greater efficiency in terms of response time and token usage. After augmenting the knowledge base, the average accuracy rating of the chatbot increased from 5.88 to 6.42 on a 10-point scale, and 81.82% of participants found the updated system useful in business contexts.", "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.17156.pdf", "abstract_url": "https://arxiv.org/abs/2505.17156", "categories": ["Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了PersonaBOT，一个结合大型语言模型（LLMs）和检索增强生成（RAG）技术的聊天机器人，旨在通过生成合成客户角色来支持商业决策。", "motivation": "传统通过定性方法开发客户角色耗时且难以扩展，本文旨在解决这一问题。", "method": "采用Few-Shot和Chain-of-Thought（CoT）提示技术生成合成角色，并通过McNemar测试评估其完整性、相关性和一致性。", "result": "Few-Shot在生成更完整的角色方面表现更佳，而CoT在响应时间和令牌使用上更高效。知识库增强后，聊天机器人的平均准确率从5.88提高到6.42（满分10分），81.82%的参与者认为更新后的系统在商业环境中有用。", "conclusion": "结合LLMs和RAG技术可以有效生成和利用合成客户角色，提升商业决策支持系统的准确性和实用性。"}}
{"id": "2505.18079", "title": "Deep Video Discovery: Agentic Search with Tool Use for Long-form Video Understanding", "authors": ["Xiaoyi Zhang", "Zhaoyang Jia", "Zongyu Guo", "Jiahao Li", "Bin Li", "Houqiang Li", "Yan Lu"], "abstract": "Long-form video understanding presents significant challenges due to extensive temporal-spatial complexity and the difficulty of question answering under such extended contexts. While Large Language Models (LLMs) have demonstrated considerable advancements in video analysis capabilities and long context handling, they continue to exhibit limitations when processing information-dense hour-long videos. To overcome such limitations, we propose the Deep Video Discovery agent to leverage an agentic search strategy over segmented video clips. Different from previous video agents manually designing a rigid workflow, our approach emphasizes the autonomous nature of agents. By providing a set of search-centric tools on multi-granular video database, our DVD agent leverages the advanced reasoning capability of LLM to plan on its current observation state, strategically selects tools, formulates appropriate parameters for actions, and iteratively refines its internal reasoning in light of the gathered information. We perform comprehensive evaluation on multiple long video understanding benchmarks that demonstrates the advantage of the entire system design. Our DVD agent achieves SOTA performance, significantly surpassing prior works by a large margin on the challenging LVBench dataset. Comprehensive ablation studies and in-depth tool analyses are also provided, yielding insights to further advance intelligent agents tailored for long-form video understanding tasks. The code will be released later.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "Under review", "pdf_url": "https://arxiv.org/pdf/2505.18079.pdf", "abstract_url": "https://arxiv.org/abs/2505.18079", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了Deep Video Discovery（DVD）代理，利用代理搜索策略和工具使用来解决长视频理解的挑战，通过自主规划和迭代优化，在多个长视频理解基准测试中取得了最先进的性能。", "motivation": "长视频理解由于时间和空间的复杂性以及长上下文下的问答困难而面临重大挑战。尽管大型语言模型（LLMs）在视频分析和长上下文处理方面取得了显著进展，但在处理信息密集的长时间视频时仍存在限制。", "method": "提出了DVD代理，通过在多粒度视频数据库上提供一组以搜索为中心的工具，利用LLM的高级推理能力进行规划，策略性地选择工具，为行动制定适当的参数，并根据收集到的信息迭代优化其内部推理。", "result": "DVD代理在多个长视频理解基准测试中表现出优势，特别是在具有挑战性的LVBench数据集上，显著超越了之前的工作。", "conclusion": "通过全面的消融研究和深入的工具分析，本文为长视频理解任务量身定制的智能代理提供了进一步的见解，代码将在未来发布。"}}
{"id": "2505.17118", "title": "After Retrieval, Before Generation: Enhancing the Trustworthiness of Large Language Models in RAG", "authors": ["Xinbang Dai", "Huikang Hu", "Yuncheng Hua", "Jiaqi Li", "Yongrui Chen", "Rihui Jin", "Nan Hu", "Guilin Qi"], "abstract": "Retrieval-augmented generation (RAG) systems face critical challenges in balancing internal (parametric) and external (retrieved) knowledge, especially when these sources conflict or are unreliable. To analyze these scenarios comprehensively, we construct the Trustworthiness Response Dataset (TRD) with 36,266 questions spanning four RAG settings. We reveal that existing approaches address isolated scenarios-prioritizing one knowledge source, naively merging both, or refusing answers-but lack a unified framework to handle different real-world conditions simultaneously. Therefore, we propose the BRIDGE framework, which dynamically determines a comprehensive response strategy of large language models (LLMs). BRIDGE leverages an adaptive weighting mechanism named soft bias to guide knowledge collection, followed by a Maximum Soft-bias Decision Tree to evaluate knowledge and select optimal response strategies (trust internal/external knowledge, or refuse). Experiments show BRIDGE outperforms baselines by 5-15% in accuracy while maintaining balanced performance across all scenarios. Our work provides an effective solution for LLMs' trustworthy responses in real-world RAG applications.", "subjects": "Computation and Language (cs.CL)", "comments": "24 pages, 8 figures", "pdf_url": "https://arxiv.org/pdf/2505.17118.pdf", "abstract_url": "https://arxiv.org/abs/2505.17118", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了BRIDGE框架，旨在解决检索增强生成（RAG）系统中内部（参数化）和外部（检索）知识平衡的挑战，特别是在这些知识来源冲突或不可靠时。通过构建包含36,266个问题的信任度响应数据集（TRD），并引入软偏置自适应加权机制和最大软偏置决策树，BRIDGE框架能够动态决定大型语言模型（LLMs）的响应策略，实验表明其在准确性上优于基线5-15%，并在所有场景中保持平衡性能。", "motivation": "检索增强生成（RAG）系统在内部（参数化）和外部（检索）知识来源冲突或不可靠时，面临平衡这些知识来源的挑战。现有方法仅针对孤立场景，缺乏一个统一框架来同时处理不同的现实世界条件。", "method": "提出了BRIDGE框架，该框架利用名为软偏置的自适应加权机制指导知识收集，随后通过最大软偏置决策树评估知识并选择最优响应策略（信任内部/外部知识，或拒绝回答）。", "result": "实验结果显示，BRIDGE在准确性上优于基线方法5-15%，并在所有测试场景中保持了平衡的性能。", "conclusion": "BRIDGE框架为大型语言模型（LLMs）在现实世界RAG应用中的可信响应提供了有效解决方案，能够动态适应不同的知识来源冲突和不可靠情况，显著提高了模型的准确性和可靠性。"}}
{"id": "2505.17206", "title": "FB-RAG: Improving RAG with Forward and Backward Lookup", "authors": ["Kushal Chawla", "Alfy Samuel", "Anoop Kumar", "Daben Liu"], "abstract": "The performance of Retrieval Augmented Generation (RAG) systems relies heavily on the retriever quality and the size of the retrieved context. A large enough context ensures that the relevant information is present in the input context for the LLM, but also incorporates irrelevant content that has been shown to confuse the models. On the other hand, a smaller context reduces the irrelevant information, but it often comes at the risk of losing important information necessary to answer the input question. This duality is especially challenging to manage for complex queries that contain little information to retrieve the relevant chunks from the full context. To address this, we present a novel framework, called FB-RAG, which enhances the RAG pipeline by relying on a combination of backward lookup (overlap with the query) and forward lookup (overlap with candidate reasons and answers) to retrieve specific context chunks that are the most relevant for answering the input query. Our evaluations on 9 datasets from two leading benchmarks show that FB-RAG consistently outperforms RAG and Long Context baselines developed recently for these benchmarks. We further show that FB-RAG can improve performance while reducing latency. We perform qualitative analysis of the strengths and shortcomings of our approach, providing specific insights to guide future work.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.17206.pdf", "abstract_url": "https://arxiv.org/abs/2505.17206", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "FB-RAG通过前向和后向查找改进RAG，提高检索增强生成系统的性能。", "motivation": "解决RAG系统中检索器质量和检索上下文大小之间的矛盾，特别是在处理信息量少的复杂查询时。", "method": "提出FB-RAG框架，结合后向查找（与查询重叠）和前向查找（与候选理由和答案重叠）来检索最相关的上下文块。", "result": "在9个数据集上的评估显示，FB-RAG consistently outperforms RAG和Long Context基线，同时减少延迟。", "conclusion": "FB-RAG通过优化检索策略，提高了回答输入查询的准确性和效率，为未来工作提供了具体指导。"}}
{"id": "2505.17231", "title": "ExeSQL: Self-Taught Text-to-SQL Models with Execution-Driven Bootstrapping for SQL Dialects", "authors": ["Jipeng Zhang", "Haolin Yang", "Kehao Miao", "Ruiyuan Zhang", "Renjie Pi", "Jiahui Gao", "Xiaofang Zhou"], "abstract": "Recent text-to-SQL models have achieved strong performance, but their effectiveness remains largely confined to SQLite due to dataset limitations. However, real-world applications require SQL generation across multiple dialects with varying syntax and specialized features, which remains a challenge for current models. The main obstacle in building a dialect-aware model lies in acquiring high-quality dialect-specific data. Data generated purely through static prompting - without validating SQLs via execution - tends to be noisy and unreliable. Moreover, the lack of real execution environments in the training loop prevents models from grounding their predictions in executable semantics, limiting generalization despite surface-level improvements from data filtering. This work introduces ExeSQL, a text-to-SQL framework with execution-driven, agentic bootstrapping. The method consists of iterative query generation, execution-based filtering (e.g., rejection sampling), and preference-based training, enabling the model to adapt to new SQL dialects through verifiable, feedback-guided learning. Experiments show that ExeSQL bridges the dialect gap in text-to-SQL, achieving average improvements of 15.2%, 10.38%, and 4.49% over GPT-4o on PostgreSQL, MySQL, and Oracle, respectively, across multiple datasets of varying difficulty.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Databases (cs.DB)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.17231.pdf", "abstract_url": "https://arxiv.org/abs/2505.17231", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Databases (cs.DB)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "ExeSQL是一个通过执行驱动引导的自学习文本到SQL模型框架，旨在解决跨SQL方言的SQL生成问题。", "motivation": "当前文本到SQL模型的有效性主要局限于SQLite，而现实应用需要跨多种SQL方言生成SQL，这因数据集限制而成为挑战。主要障碍在于获取高质量的方言特定数据。", "method": "ExeSQL采用执行驱动、代理引导的自举方法，包括迭代查询生成、基于执行的过滤（如拒绝采样）和基于偏好的训练，使模型能够通过可验证的、反馈引导的学习适应新的SQL方言。", "result": "实验显示，ExeSQL在PostgreSQL、MySQL和Oracle上分别比GPT-4o平均提高了15.2%、10.38%和4.49%，有效缩小了文本到SQL的方言差距。", "conclusion": "ExeSQL通过执行驱动的自举和反馈引导学习，显著提高了跨SQL方言的文本到SQL生成能力，为现实应用提供了更广泛的支持。"}}
{"id": "2505.17238", "title": "Personalizing Student-Agent Interactions Using Log-Contextualized Retrieval Augmented Generation (RAG)", "authors": ["Clayton Cohn", "Surya Rayala", "Caitlin Snyder", "Joyce Fonteles", "Shruti Jain", "Naveeduddin Mohammed", "Umesh Timalsina", "Sarah K. Burriss", "Ashwin T S", "Namrata Srivastava", "Menton Deweese", "Angela Eeds", "Gautam Biswas"], "abstract": "Collaborative dialogue offers rich insights into students' learning and critical thinking. This is essential for adapting pedagogical agents to students' learning and problem-solving skills in STEM+C settings. While large language models (LLMs) facilitate dynamic pedagogical interactions, potential hallucinations can undermine confidence, trust, and instructional value. Retrieval-augmented generation (RAG) grounds LLM outputs in curated knowledge, but its effectiveness depends on clear semantic links between user input and a knowledge base, which are often weak in student dialogue. We propose log-contextualized RAG (LC-RAG), which enhances RAG retrieval by incorporating environment logs to contextualize collaborative discourse. Our findings show that LC-RAG improves retrieval over a discourse-only baseline and allows our collaborative peer agent, Copa, to deliver relevant, personalized guidance that supports students' critical thinking and epistemic decision-making in a collaborative computational modeling environment, XYZ.", "subjects": "Computation and Language (cs.CL)", "comments": "Submitted to the International Conference on Artificial Intelligence in Education (AIED) Workshop on Epistemics and Decision-Making in AI-Supported Education", "pdf_url": "https://arxiv.org/pdf/2505.17238.pdf", "abstract_url": "https://arxiv.org/abs/2505.17238", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文提出了一种日志上下文检索增强生成（LC-RAG）方法，用于改善STEM+C教育中学生与教学代理之间的个性化互动。通过整合环境日志来增强检索过程，LC-RAG提高了检索的准确性，使协作同伴代理Copa能够提供更相关、个性化的指导，支持学生在协作计算建模环境中的批判性思维和认知决策。", "motivation": "解决大型语言模型（LLMs）在教学互动中可能产生的幻觉问题，以及传统检索增强生成（RAG）方法在学生对话中语义链接薄弱的问题，以提高教学代理的适应性和指导价值。", "method": "提出日志上下文检索增强生成（LC-RAG）方法，通过整合环境日志来增强RAG的检索过程，从而更好地理解学生的协作对话。", "result": "LC-RAG在检索效果上优于仅基于对话的基线方法，使协作同伴代理Copa能够提供更相关、个性化的指导，有效支持学生的批判性思维和认知决策。", "conclusion": "LC-RAG方法通过整合环境日志，显著提高了教学代理对学生协作对话的理解和响应能力，为个性化教育提供了新的技术支持。"}}
{"id": "2505.17281", "title": "Search Wisely: Mitigating Sub-optimal Agentic Searches By Reducing Uncertainty", "authors": ["Peilin Wu", "Mian Zhang", "Xinlu Zhang", "Xinya Du", "Zhiyu Zoey Chen"], "abstract": "Agentic Retrieval-Augmented Generation (RAG) systems enhance Large Language Models (LLMs) by enabling dynamic, multi-step reasoning and information retrieval. However, these systems often exhibit sub-optimal search behaviors like over-search (retrieving redundant information) and under-search (failing to retrieve necessary information), which hinder efficiency and reliability. This work formally defines and quantifies these behaviors, revealing their prevalence across multiple QA datasets and agentic RAG systems (e.g., one model could have avoided searching in 27.7% of its search steps). Furthermore, we demonstrate a crucial link between these inefficiencies and the models' uncertainty regarding their own knowledge boundaries, where response accuracy correlates with model's uncertainty in its search decisions. To address this, we propose $\\beta$-GRPO, a reinforcement learning-based training method that incorporates confidence threshold to reward high-certainty search decisions. Experiments on seven QA benchmarks show that $\\beta$-GRPO enable a 3B model with better agentic RAG ability, outperforming other strong baselines with a 4% higher average exact match score.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.17281.pdf", "abstract_url": "https://arxiv.org/abs/2505.17281", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic", "@RAG"], "AI": {"tldr": "本文提出了一种名为β-GRPO的强化学习训练方法，旨在通过减少不确定性来优化代理检索增强生成（RAG）系统的搜索行为，从而提高效率和可靠性。", "motivation": "代理检索增强生成（RAG）系统虽然能够增强大型语言模型（LLMs）的动态多步推理和信息检索能力，但常常表现出过度搜索和搜索不足等次优搜索行为，影响了系统的效率和可靠性。", "method": "本文首先正式定义并量化了这些次优搜索行为，揭示了它们与模型对自己知识边界的不确定性之间的关键联系。然后，提出了一种基于强化学习的训练方法β-GRPO，该方法通过引入置信度阈值来奖励高确定性的搜索决策。", "result": "在七个问答基准测试上的实验表明，β-GRPO使得一个3B模型在代理RAG能力上表现更佳，平均精确匹配分数比其他强基线高出4%。", "conclusion": "通过减少模型在搜索决策中的不确定性，β-GRPO有效缓解了代理RAG系统中的次优搜索行为，为提升大型语言模型的信息检索效率和可靠性提供了新的解决方案。"}}
{"id": "2505.17107", "title": "CRAKEN: Cybersecurity LLM Agent with Knowledge-Based Execution", "authors": ["Minghao Shao", "Haoran Xi", "Nanda Rani", "Meet Udeshi", "Venkata Sai Charan Putrevu", "Kimberly Milner", "Brendan Dolan-Gavitt", "Sandeep Kumar Shukla", "Prashanth Krishnamurthy", "Farshad Khorrami", "Ramesh Karri", "Muhammad Shafique"], "abstract": "Large Language Model (LLM) agents can automate cybersecurity tasks and can adapt to the evolving cybersecurity landscape without re-engineering. While LLM agents have demonstrated cybersecurity capabilities on Capture-The-Flag (CTF) competitions, they have two key limitations: accessing latest cybersecurity expertise beyond training data, and integrating new knowledge into complex task planning. Knowledge-based approaches that incorporate technical understanding into the task-solving automation can tackle these limitations. We present CRAKEN, a knowledge-based LLM agent framework that improves cybersecurity capability through three core mechanisms: contextual decomposition of task-critical information, iterative self-reflected knowledge retrieval, and knowledge-hint injection that transforms insights into adaptive attack strategies. Comprehensive evaluations with different configurations show CRAKEN's effectiveness in multi-stage vulnerability detection and exploitation compared to previous approaches. Our extensible architecture establishes new methodologies for embedding new security knowledge into LLM-driven cybersecurity agentic systems. With a knowledge database of CTF writeups, CRAKEN obtained an accuracy of 22% on NYU CTF Bench, outperforming prior works by 3% and achieving state-of-the-art results. On evaluation of MITRE ATT&CK techniques, CRAKEN solves 25-30% more techniques than prior work, demonstrating improved cybersecurity capabilities via knowledge-based execution. We make our framework open source to public", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.17107.pdf", "abstract_url": "https://arxiv.org/abs/2505.17107", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "CRAKEN是一个基于知识的LLM代理框架，旨在通过上下文分解、迭代自反知识检索和知识提示注入等核心机制，提升网络安全能力。", "motivation": "解决大型语言模型（LLM）代理在网络安全任务中访问最新网络安全专业知识和将新知识整合到复杂任务规划中的局限性。", "method": "采用基于知识的方法，包括任务关键信息的上下文分解、迭代自反知识检索和知识提示注入，以增强网络安全能力。", "result": "CRAKEN在NYU CTF Bench上的准确率达到22%，比之前的工作提高了3%，并在MITRE ATT&CK技术的评估中解决了比之前工作多25-30%的技术。", "conclusion": "CRAKEN通过知识基础的执行提高了网络安全能力，其可扩展的架构为将新安全知识嵌入LLM驱动的网络安全代理系统建立了新的方法论。"}}
{"id": "2505.17115", "title": "Swarm Intelligence Enhanced Reasoning: A Density-Driven Framework for LLM-Based Multi-Agent Optimization", "authors": ["Ying Zhu", "Heng Zhou", "Rui Su", "Peiqin Zhuang", "Lei Bai"], "abstract": "Recently, many approaches, such as Chain-of-Thought (CoT) prompting and Multi-Agent Debate (MAD), have been proposed to further enrich Large Language Models' (LLMs) complex problem-solving capacities in reasoning scenarios. However, these methods may fail to solve complex problems due to the lack of ability to find optimal solutions. Swarm Intelligence has been serving as a powerful tool for finding optima in the field of traditional optimization problems. To this end, we propose integrating swarm intelligence into the reasoning process by introducing a novel Agent-based Swarm Intelligence (ASI) paradigm. In this paradigm, we formulate LLM reasoning as an optimization problem and use a swarm intelligence scheme to guide a group of LLM-based agents in collaboratively searching for optimal solutions. To avoid swarm intelligence getting trapped in local optima, we further develop a Swarm Intelligence Enhancing Reasoning (SIER) framework, which develops a density-driven strategy to enhance the reasoning ability. To be specific, we propose to perform kernel density estimation and non-dominated sorting to optimize both solution quality and diversity simultaneously. In this case, SIER efficiently enhances solution space exploration through expanding the diversity of the reasoning path. Besides, a step-level quality evaluation is used to help agents improve solution quality by correcting low-quality intermediate steps. Then, we use quality thresholds to dynamically control the termination of exploration and the selection of candidate steps, enabling a more flexible and efficient reasoning process. Extensive experiments are ...", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.17115.pdf", "abstract_url": "https://arxiv.org/abs/2505.17115", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新颖的基于代理的群体智能（ASI）范式，将群体智能整合到大型语言模型（LLM）的推理过程中，通过群体智能方案指导一组基于LLM的代理协作寻找最优解。为了克服群体智能陷入局部最优的问题，开发了群体智能增强推理（SIER）框架，采用密度驱动策略同时优化解决方案的质量和多样性，有效增强了解决方案空间的探索。", "motivation": "现有的方法如思维链（CoT）提示和多代理辩论（MAD）在丰富大型语言模型（LLMs）解决复杂问题的能力方面存在不足，尤其是在寻找最优解方面。群体智能在传统优化问题中显示出强大的能力，因此本文旨在将群体智能引入LLM的推理过程，以提高其解决复杂问题的能力。", "method": "提出了一种基于代理的群体智能（ASI）范式，将LLM推理建模为一个优化问题，并使用群体智能方案指导代理协作搜索最优解。进一步开发了群体智能增强推理（SIER）框架，采用核密度估计和非支配排序技术同时优化解决方案的质量和多样性，并通过步骤级质量评估和动态终止探索来提高解决方案的质量。", "result": "SIER框架通过扩大推理路径的多样性，有效增强了解决方案空间的探索能力，并通过步骤级质量评估和动态终止探索机制，提高了解决方案的质量和推理过程的效率。", "conclusion": "本文提出的ASI范式和SIER框架成功地将群体智能整合到LLM的推理过程中，不仅提高了解决方案的质量和多样性，还增强了推理过程的效率和灵活性，为LLM在复杂问题解决中的应用提供了新的思路和方法。"}}
{"id": "2505.17391", "title": "Curriculum Guided Reinforcement Learning for Efficient Multi Hop Retrieval Augmented Generation", "authors": ["Yuelyu Ji", "Rui Meng", "Zhuochun Li", "Daqing He"], "abstract": "Retrieval-augmented generation (RAG) grounds large language models (LLMs) in up-to-date external evidence, yet existing multi-hop RAG pipelines still issue redundant subqueries, explore too shallowly, or wander through overly long search chains. We introduce EVO-RAG, a curriculum-guided reinforcement learning framework that evolves a query-rewriting agent from broad early-stage exploration to concise late-stage refinement. EVO-RAG couples a seven-factor, step-level reward vector (covering relevance, redundancy, efficiency, and answer correctness) with a time-varying scheduler that reweights these signals as the episode unfolds. The agent is trained with Direct Preference Optimization over a multi-head reward model, enabling it to learn when to search, backtrack, answer, or refuse. Across four multi-hop QA benchmarks (HotpotQA, 2WikiMultiHopQA, MuSiQue, and Bamboogle), EVO-RAG boosts Exact Match by up to 4.6 points over strong RAG baselines while trimming average retrieval depth by 15 %. Ablation studies confirm the complementary roles of curriculum staging and dynamic reward scheduling. EVO-RAG thus offers a general recipe for building reliable, cost-effective multi-hop RAG systems.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.17391.pdf", "abstract_url": "https://arxiv.org/abs/2505.17391", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文介绍了EVO-RAG，一个课程引导的强化学习框架，旨在优化多跳检索增强生成（RAG）流程，通过动态奖励调度和课程学习减少冗余查询，提高检索效率和答案准确性。", "motivation": "现有的多跳RAG流程存在冗余子查询、探索不足或搜索链过长的问题，影响了检索效率和答案的准确性。", "method": "EVO-RAG结合了七因素步级奖励向量和时间变化的调度器，通过直接偏好优化训练查询重写代理，学习何时搜索、回溯、回答或拒绝。", "result": "在四个多跳QA基准测试中，EVO-RAG将精确匹配率提高了多达4.6个百分点，同时将平均检索深度减少了15%。", "conclusion": "EVO-RAG通过课程阶段和动态奖励调度的互补作用，为构建可靠、成本效益高的多跳RAG系统提供了一种通用方法。"}}
{"id": "2505.17138", "title": "RAP: Runtime-Adaptive Pruning for LLM Inference", "authors": ["Huanrong Liu", "Chunlin Tian", "Xuyang Wei", "Jiaheng Dai", "Qin Liu", "Tianqi Wei", "Qingbiao Li", "Li Li"], "abstract": "Large language models (LLMs) excel at language understanding and generation, but their enormous computational and memory requirements hinder deployment. Compression offers a potential solution to mitigate these constraints. However, most existing methods rely on fixed heuristics and thus fail to adapt to runtime memory variations or heterogeneous KV-cache demands arising from diverse user requests. To address these limitations, we propose RAP, an elastic pruning framework driven by reinforcement learning (RL) that dynamically adjusts compression strategies in a runtime-aware manner. Specifically, RAP dynamically tracks the evolving ratio between model parameters and KV-cache across practical execution. Recognizing that FFNs house most parameters, whereas parameter -light attention layers dominate KV-cache formation, the RL agent retains only those components that maximize utility within the current memory budget, conditioned on instantaneous workload and device state. Extensive experiments results demonstrate that RAP outperforms state-of-the-art baselines, marking the first time to jointly consider model weights and KV-cache on the fly.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.17138.pdf", "abstract_url": "https://arxiv.org/abs/2505.17138", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为RAP的弹性剪枝框架，通过强化学习动态调整压缩策略，以适应运行时内存变化和异构KV缓存需求，从而优化大型语言模型(LLM)的推理效率。", "motivation": "大型语言模型(LLMs)在语言理解和生成方面表现出色，但其巨大的计算和内存需求阻碍了部署。现有的压缩方法大多依赖固定启发式，无法适应运行时内存变化或不同用户请求产生的异构KV缓存需求。", "method": "RAP框架利用强化学习(RL)动态跟踪模型参数与KV缓存之间的比率变化，并根据当前内存预算、工作负载和设备状态，保留那些能最大化效用的组件。", "result": "大量实验结果表明，RAP在动态考虑模型权重和KV缓存的情况下，优于最先进的基线方法。", "conclusion": "RAP是第一个在运行时联合考虑模型权重和KV缓存的框架，为大型语言模型的推理提供了更高效的解决方案。"}}
{"id": "2505.17148", "title": "LLM-Powered Agents for Navigating Venice's Historical Cadastre", "authors": ["Tristan Karch", "Jakhongir Saydaliev", "Isabella Di Lenardo", "Frédéric Kaplan"], "abstract": "Cadastral data reveal key information about the historical organization of cities but are often non-standardized due to diverse formats and human annotations, complicating large-scale analysis. We explore as a case study Venice's urban history during the critical period from 1740 to 1808, capturing the transition following the fall of the ancient Republic and the Ancien Régime. This era's complex cadastral data, marked by its volume and lack of uniform structure, presents unique challenges that our approach adeptly navigates, enabling us to generate spatial queries that bridge past and present urban landscapes. We present a text-to-programs framework that leverages Large Language Models (LLMs) to translate natural language queries into executable code for processing historical cadastral records. Our methodology implements two complementary techniques: a text-to-SQL approach for handling structured queries about specific cadastral information, and a text-to-Python approach for complex analytical operations requiring custom data manipulation. We propose a taxonomy that classifies historical research questions based on their complexity and analytical requirements, mapping them to the most appropriate technical approach. This framework is supported by an investigation into the execution consistency of the system, alongside a qualitative analysis of the answers it produces. By ensuring interpretability and minimizing hallucination through verifiable program outputs, we demonstrate the system's effectiveness in reconstructing past population information, property features, and spatiotemporal comparisons in Venice.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.17148.pdf", "abstract_url": "https://arxiv.org/abs/2505.17148", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了利用大型语言模型（LLMs）处理威尼斯1740年至1808年间复杂的历史地籍数据，通过文本到程序的框架将自然语言查询转换为可执行代码，以解决数据非标准化和缺乏统一结构的问题。", "motivation": "解决历史地籍数据因格式多样和人工注释导致的非标准化问题，以及缺乏统一结构，从而难以进行大规模分析的挑战。", "method": "采用文本到SQL和文本到Python两种互补技术，将自然语言查询转换为可执行代码，处理结构化查询和复杂的数据操作。", "result": "通过可验证的程序输出确保解释性并减少幻觉，系统有效重建了威尼斯过去的人口信息、财产特征和时空比较。", "conclusion": "提出的框架能够有效处理复杂的历史地籍数据，为历史研究问题提供技术支持，并通过分类研究问题基于其复杂性和分析需求，映射到最合适的技术方法。"}}
{"id": "2505.17625", "title": "Enhancing Large Vision-Language Models with Layout Modality for Table Question Answering on Japanese Annual Securities Reports", "authors": ["Hayato Aida", "Kosuke Takahashi", "Takahiro Omi"], "abstract": "With recent advancements in Large Language Models (LLMs) and growing interest in retrieval-augmented generation (RAG), the ability to understand table structures has become increasingly important. This is especially critical in financial domains such as securities reports, where highly accurate question answering (QA) over tables is required. However, tables exist in various formats-including HTML, images, and plain text-making it difficult to preserve and extract structural information. Therefore, multimodal LLMs are essential for robust and general-purpose table understanding. Despite their promise, current Large Vision-Language Models (LVLMs), which are major representatives of multimodal LLMs, still face challenges in accurately understanding characters and their spatial relationships within documents. In this study, we propose a method to enhance LVLM-based table understanding by incorporating in-table textual content and layout features. Experimental results demonstrate that these auxiliary modalities significantly improve performance, enabling robust interpretation of complex document layouts without relying on explicitly structured input formats.", "subjects": "Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)", "comments": "Accepted at IIAI AAI 2025, the 3rd International Conference on Computational and Data Sciences in Economics and Finance", "pdf_url": "https://arxiv.org/pdf/2505.17625.pdf", "abstract_url": "https://arxiv.org/abs/2505.17625", "categories": ["Computation and Language (cs.CL)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种通过整合表格内文本内容和布局特征来增强大型视觉语言模型（LVLM）表格理解能力的方法，特别是在日本年度证券报告中的表格问答（QA）任务上，实验结果表明这些辅助模态显著提高了性能。", "motivation": "随着大型语言模型（LLMs）的进步和检索增强生成（RAG）的兴趣增长，理解表格结构的能力变得日益重要，尤其是在需要高度准确表格问答的金融领域。然而，表格存在多种格式，包括HTML、图像和纯文本，这使得保留和提取结构信息变得困难。", "method": "本研究提出了一种方法，通过将表格内的文本内容和布局特征整合到大型视觉语言模型（LVLMs）中，来增强其对表格的理解能力。", "result": "实验结果表明，这些辅助模态显著提高了模型性能，使其能够在不依赖明确结构化输入格式的情况下，稳健地解释复杂的文档布局。", "conclusion": "通过整合表格内文本内容和布局特征，可以显著增强大型视觉语言模型在理解和解释复杂文档布局方面的能力，特别是在金融领域的表格问答任务中。"}}
{"id": "2505.17447", "title": "LeTS: Learning to Think-and-Search via Process-and-Outcome Reward Hybridization", "authors": ["Qi Zhang", "Shouqing Yang", "Lirong Gao", "Hao Chen", "Xiaomeng Hu", "Jinglei Chen", "Jiexiang Wang", "Sheng Guo", "Bo Zheng", "Haobo Wang", "Junbo Zhao"], "abstract": "Large language models (LLMs) have demonstrated impressive capabilities in reasoning with the emergence of reasoning models like OpenAI-o1 and DeepSeek-R1. Recent research focuses on integrating reasoning capabilities into the realm of retrieval-augmented generation (RAG) via outcome-supervised reinforcement learning (RL) approaches, while the correctness of intermediate think-and-search steps is usually neglected. To address this issue, we design a process-level reward module to mitigate the unawareness of intermediate reasoning steps in outcome-level supervision without additional annotation. Grounded on this, we propose Learning to Think-and-Search (LeTS), a novel framework that hybridizes stepwise process reward and outcome-based reward to current RL methods for RAG. Extensive experiments demonstrate the generalization and inference efficiency of LeTS across various RAG benchmarks. In addition, these results reveal the potential of process- and outcome-level reward hybridization in boosting LLMs' reasoning ability via RL under other scenarios. The code will be released soon.", "subjects": "Computation and Language (cs.CL)", "comments": "preprint, under review", "pdf_url": "https://arxiv.org/pdf/2505.17447.pdf", "abstract_url": "https://arxiv.org/abs/2505.17447", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了LeTS框架，通过结合过程级和结果级奖励来增强大型语言模型在检索增强生成中的推理能力，解决了中间推理步骤被忽视的问题。", "motivation": "当前的研究主要关注通过结果监督的强化学习方法将推理能力整合到检索增强生成中，但忽视了中间思考与搜索步骤的正确性。", "method": "设计了过程级奖励模块，无需额外标注即可缓解结果级监督对中间推理步骤的无意识问题，并提出了LeTS框架，将步骤过程奖励和基于结果的奖励结合到当前的强化学习方法中。", "result": "大量实验证明，LeTS在各种RAG基准测试中具有泛化性和推理效率，揭示了过程和结果级奖励结合在其他场景下通过强化学习提升LLMs推理能力的潜力。", "conclusion": "LeTS框架通过过程与结果奖励的混合，有效提升了大型语言模型在检索增强生成中的推理能力，为其他类似场景提供了新的研究思路。"}}
{"id": "2505.17471", "title": "FinRAGBench-V: A Benchmark for Multimodal RAG with Visual Citation in the Financial Domain", "authors": ["Suifeng Zhao", "Zhuoran Jin", "Sujian Li", "Jun Gao"], "abstract": "Retrieval-Augmented Generation (RAG) plays a vital role in the financial domain, powering applications such as real-time market analysis, trend forecasting, and interest rate computation. However, most existing RAG research in finance focuses predominantly on textual data, overlooking the rich visual content in financial documents, resulting in the loss of key analytical insights. To bridge this gap, we present FinRAGBench-V, a comprehensive visual RAG benchmark tailored for finance which effectively integrates multimodal data and provides visual citation to ensure traceability. It includes a bilingual retrieval corpus with 60,780 Chinese and 51,219 English pages, along with a high-quality, human-annotated question-answering (QA) dataset spanning heterogeneous data types and seven question categories. Moreover, we introduce RGenCite, an RAG baseline that seamlessly integrates visual citation with generation. Furthermore, we propose an automatic citation evaluation method to systematically assess the visual citation capabilities of Multimodal Large Language Models (MLLMs). Extensive experiments on RGenCite underscore the challenging nature of FinRAGBench-V, providing valuable insights for the development of multimodal RAG systems in finance.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.17471.pdf", "abstract_url": "https://arxiv.org/abs/2505.17471", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了FinRAGBench-V，一个为金融领域量身定制的视觉RAG基准测试，旨在解决现有金融RAG研究主要关注文本数据而忽视视觉内容的问题。", "motivation": "解决金融领域中现有RAG研究主要集中于文本数据，忽视了金融文档中丰富的视觉内容，导致关键分析洞察丢失的问题。", "method": "提出了FinRAGBench-V，一个综合的视觉RAG基准测试，包括双语检索语料库和高质量的人工注释QA数据集，并介绍了RGenCite基线方法和自动引用评估方法。", "result": "在RGenCite上的广泛实验证明了FinRAGBench-V的挑战性，为金融领域多模态RAG系统的发展提供了有价值的见解。", "conclusion": "FinRAGBench-V通过有效整合多模态数据和提供视觉引用，填补了金融领域视觉RAG研究的空白，为未来的研究和应用奠定了基础。"}}
{"id": "2505.17464", "title": "Hydra: Structured Cross-Source Enhanced Large Language Model Reasoning", "authors": ["Xingyu Tan", "Xiaoyang Wang", "Qing Liu", "Xiwei Xu", "Xin Yuan", "Liming Zhu", "Wenjie Zhang"], "abstract": "Retrieval-augmented generation (RAG) enhances large language models (LLMs) by incorporating external knowledge. Current hybrid RAG system retrieves evidence from both knowledge graphs (KGs) and text documents to support LLM reasoning. However, it faces challenges like handling multi-hop reasoning, multi-entity questions, multi-source verification, and effective graph utilization. To address these limitations, we present Hydra, a training-free framework that unifies graph topology, document semantics, and source reliability to support deep, faithful reasoning in LLMs. Hydra handles multi-hop and multi-entity problems through agent-driven exploration that combines structured and unstructured retrieval, increasing both diversity and precision of evidence. To tackle multi-source verification, Hydra uses a tri-factor cross-source verification (source trustworthiness assessment, cross-source corroboration, and entity-path alignment), to balance topic relevance with cross-modal agreement. By leveraging graph structure, Hydra fuses heterogeneous sources, guides efficient exploration, and prunes noise early. Comprehensive experiments on seven benchmark datasets show that Hydra achieves overall state-of-the-art results on all benchmarks with GPT-3.5, outperforming the strong hybrid baseline ToG-2 by an average of 20.3% and up to 30.1%. Furthermore, Hydra enables smaller models (e.g., Llama-3.1-8B) to achieve reasoning performance comparable to that of GPT-4-Turbo.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.17464.pdf", "abstract_url": "https://arxiv.org/abs/2505.17464", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "Hydra是一个无需训练的框架，通过统一图拓扑、文档语义和源可靠性，支持大型语言模型（LLMs）的深度、忠实推理，解决了多跳推理、多实体问题、多源验证和有效图利用等挑战。", "motivation": "当前混合检索增强生成（RAG）系统在支持LLM推理时面临多跳推理、多实体问题、多源验证和有效图利用等挑战。", "method": "Hydra通过代理驱动的探索结合结构化和非结构化检索，增加证据的多样性和精确性，并使用三因素跨源验证（源可信度评估、跨源佐证和实体路径对齐）来处理多源验证。", "result": "在七个基准数据集上的综合实验显示，Hydra在所有基准测试中均达到最先进的结果，平均优于强混合基线ToG-2 20.3%，最高达30.1%。", "conclusion": "Hydra不仅提高了LLM的推理性能，还使较小模型（如Llama-3.1-8B）能够达到与GPT-4-Turbo相当的推理性能。"}}
{"id": "2505.17481", "title": "MARCO: Meta-Reflection with Cross-Referencing for Code Reasoning", "authors": ["Yusheng Zhao", "Xiao Luo", "Weizhi Zhang", "Wei Ju", "Zhiping Xiao", "Philip S. Yu", "Ming Zhang"], "abstract": "The ability to reason is one of the most fundamental capabilities of large language models (LLMs), enabling a wide range of downstream tasks through sophisticated problem-solving. A critical aspect of this is code reasoning, which involves logical reasoning with formal languages (i.e., programming code). In this paper, we enhance this capability of LLMs by exploring the following question: how can an LLM agent become progressively smarter in code reasoning with each solution it proposes, thereby achieving substantial cumulative improvement? Most existing research takes a static perspective, focusing on isolated problem-solving using frozen LLMs. In contrast, we adopt a cognitive-evolving perspective and propose a novel framework named Meta-Reflection with Cross-Referencing (MARCO) that enables the LLM to evolve dynamically during inference through self-improvement. From the perspective of human cognitive development, we leverage both knowledge accumulation and lesson sharing. In particular, to accumulate knowledge during problem-solving, we propose meta-reflection that reflects on the reasoning paths of the current problem to obtain knowledge and experience for future consideration. Moreover, to effectively utilize the lessons from other agents, we propose cross-referencing that incorporates the solution and feedback from other agents into the current problem-solving process. We conduct experiments across various datasets in code reasoning, and the results demonstrate the effectiveness of MARCO.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.17481.pdf", "abstract_url": "https://arxiv.org/abs/2505.17481", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为MARCO的新框架，通过自我改进动态增强大型语言模型（LLMs）在代码推理中的能力。", "motivation": "解决LLMs在代码推理中如何通过每次提出的解决方案逐步变得更聪明，实现显著的累积改进的问题。", "method": "采用认知进化视角，提出MARCO框架，包括知识积累的元反思和跨代理的课程共享。", "result": "在多种代码推理数据集上的实验证明了MARCO的有效性。", "conclusion": "MARCO通过自我改进和跨代理学习，显著提升了LLMs的代码推理能力。"}}
{"id": "2505.17154", "title": "Can Large Language Models Design Biological Weapons? Evaluating Moremi Bio", "authors": ["Gertrude Hattoh", "Jeremiah Ayensu", "Nyarko Prince Ofori", "Solomon Eshun", "Darlington Akogo"], "abstract": "Advances in AI, particularly LLMs, have dramatically shortened drug discovery cycles by up to 40% and improved molecular target identification. However, these innovations also raise dual-use concerns by enabling the design of toxic compounds. Prompting Moremi Bio Agent without the safety guardrails to specifically design novel toxic substances, our study generated 1020 novel toxic proteins and 5,000 toxic small molecules. In-depth computational toxicity assessments revealed that all the proteins scored high in toxicity, with several closely matching known toxins such as ricin, diphtheria toxin, and disintegrin-based snake venom proteins. Some of these novel agents showed similarities with other several known toxic agents including disintegrin eristostatin, metalloproteinase, disintegrin triflavin, snake venom metalloproteinase, corynebacterium ulcerans toxin. Through quantitative risk assessments and scenario analyses, we identify dual-use capabilities in current LLM-enabled biodesign pipelines and propose multi-layered mitigation strategies. The findings from this toxicity assessment challenge claims that large language models (LLMs) are incapable of designing bioweapons. This reinforces concerns about the potential misuse of LLMs in biodesign, posing a significant threat to research and development (R&D). The accessibility of such technology to individuals with limited technical expertise raises serious biosecurity risks. Our findings underscore the critical need for robust governance and technical safeguards to balance rapid biotechnological innovation with biosecurity imperatives.", "subjects": "Quantitative Methods (q-bio.QM); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.17154.pdf", "abstract_url": "https://arxiv.org/abs/2505.17154", "categories": ["Quantitative Methods (q-bio.QM)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "研究表明，大型语言模型（LLMs）能够设计生物武器，生成大量新型有毒蛋白质和小分子，挑战了LLMs无法设计生物武器的说法，强调了加强治理和技术保障的必要性。", "motivation": "探讨大型语言模型（LLMs）在生物设计中的双重用途能力，特别是其可能被用于设计有毒化合物和生物武器的风险。", "method": "通过去除安全防护措施，促使Moremi Bio Agent设计新型有毒物质，并进行深入的计算机毒性评估和定量风险分析。", "result": "生成了1020种新型有毒蛋白质和5,000种有毒小分子，所有蛋白质在毒性评分中得分高，部分与已知毒素如蓖麻毒素、白喉毒素等高度相似。", "conclusion": "研究结果强调了在快速生物技术创新与生物安全之间平衡的重要性，提出了多层次的风险缓解策略，以应对LLMs在生物设计中的潜在滥用风险。"}}
{"id": "2505.17503", "title": "CReSt: A Comprehensive Benchmark for Retrieval-Augmented Generation with Complex Reasoning over Structured Documents", "authors": ["Minsoo Khang", "Sangjun Park", "Teakgyu Hong", "Dawoon Jung"], "abstract": "Large Language Models (LLMs) have made substantial progress in recent years, yet evaluating their capabilities in practical Retrieval-Augmented Generation (RAG) scenarios remains challenging. In practical applications, LLMs must demonstrate complex reasoning, refuse to answer appropriately, provide precise citations, and effectively understand document layout. These capabilities are crucial for advanced task handling, uncertainty awareness, maintaining reliability, and structural understanding. While some of the prior works address these aspects individually, there is a need for a unified framework that evaluates them collectively in practical RAG scenarios. To address this, we present CReSt (A Comprehensive Benchmark for Retrieval-Augmented Generation with Complex Reasoning over Structured Documents), a benchmark designed to assess these key dimensions holistically. CReSt comprises 2,245 human-annotated examples in English and Korean, designed to capture practical RAG scenarios that require complex reasoning over structured documents. It also introduces a tailored evaluation methodology to comprehensively assess model performance in these critical areas. Our evaluation shows that even advanced LLMs struggle to perform consistently across these dimensions, underscoring key areas for improvement. We release CReSt to support further research and the development of more robust RAG systems. The dataset and code are available at:", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.17503.pdf", "abstract_url": "https://arxiv.org/abs/2505.17503", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了CReSt，一个用于评估在结构化文档上进行复杂推理的检索增强生成（RAG）能力的综合基准。", "motivation": "尽管大型语言模型（LLMs）近年来取得了显著进展，但在实际的检索增强生成（RAG）场景中评估其能力仍具挑战性。需要统一的框架来全面评估LLMs在复杂推理、拒绝回答、提供精确引用和理解文档布局等方面的能力。", "method": "提出了CReSt基准，包含2,245个人工标注的英文和韩文示例，旨在捕捉需要复杂推理的RAG场景，并引入了定制的评估方法。", "result": "评估显示，即使是先进的LLMs在这些关键维度上的表现也不一致，突出了需要改进的关键领域。", "conclusion": "CReSt的发布旨在支持进一步的研究和开发更健壮的RAG系统。数据集和代码已公开。"}}
{"id": "2505.17162", "title": "DailyQA: A Benchmark to Evaluate Web Retrieval Augmented LLMs Based on Capturing Real-World Changes", "authors": ["Jiehan Cheng", "Zhicheng Dou"], "abstract": "We propose DailyQA, an automatically updated dynamic dataset that updates questions weekly and contains answers to questions on any given date. DailyQA utilizes daily updates from Wikipedia revision logs to implement a fully automated pipeline of data filtering, query generation synthesis, quality checking, answer extraction, and query classification. The benchmark requires large language models (LLMs) to process and answer questions involving fast-changing factual data and covering multiple domains. We evaluate several open-source and closed-source LLMs using different RAG pipelines with web search augmentation. We compare the ability of different models to process time-sensitive web information and find that rerank of web retrieval results is critical. Our results indicate that LLMs still face significant challenges in handling frequently updated information, suggesting that DailyQA benchmarking provides valuable insights into the direction of progress for LLMs and RAG systems.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.17162.pdf", "abstract_url": "https://arxiv.org/abs/2505.17162", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "DailyQA是一个自动更新的动态数据集，每周更新问题，包含任何给定日期的问题答案。它利用维基百科的修订日志实现了一个完全自动化的数据过滤、查询生成合成、质量检查、答案提取和查询分类流程。该基准测试要求大型语言模型（LLMs）处理和回答涉及快速变化的事实数据并覆盖多个领域的问题。", "motivation": "解决LLMs在处理频繁更新的信息时面临的挑战，提供一个评估LLMs和RAG系统在捕捉现实世界变化方面能力的基准。", "method": "利用维基百科的每日更新，实现了一个完全自动化的数据过滤、查询生成合成、质量检查、答案提取和查询分类流程。", "result": "评估了多个开源和闭源的LLMs，发现重新排名网络检索结果至关重要。结果表明，LLMs在处理频繁更新的信息时仍面临重大挑战。", "conclusion": "DailyQA基准测试为LLMs和RAG系统的进步方向提供了有价值的见解。"}}
{"id": "2505.17198", "title": "LengthLogD: A Length-Stratified Ensemble Framework for Enhanced Peptide Lipophilicity Prediction via Multi-Scale Feature Integration", "authors": ["Shuang Wu", "Meijie Wang", "Lun Yu"], "abstract": "Peptide compounds demonstrate considerable potential as therapeutic agents due to their high target affinity and low toxicity, yet their drug development is constrained by their low membrane permeability. Molecular weight and peptide length have significant effects on the logD of peptides, which in turn influences their ability to cross biological membranes. However, accurate prediction of peptide logD remains challenging due to the complex interplay between sequence, structure, and ionization states. This study introduces LengthLogD, a predictive framework that establishes specialized models through molecular length stratification while innovatively integrating multi-scale molecular representations. We constructed feature spaces across three hierarchical levels: atomic (10 molecular descriptors), structural (1024-bit Morgan fingerprints), and topological (3 graph-based features including Wiener index), optimized through stratified ensemble learning. An adaptive weight allocation mechanism specifically developed for long peptides significantly enhances model generalizability. Experimental results demonstrate superior performance across all categories: short peptides (R^2=0.855), medium peptides (R^2=0.816), and long peptides (R^2=0.882), with a 34.7% reduction in prediction error for long peptides compared to conventional single-model approaches. Ablation studies confirm: 1) The length-stratified strategy contributes 41.2% to performance improvement; 2) Topological features account for 28.5% of predictive importance. Compared to state-of-the-art models, our method maintains short peptide prediction accuracy while achieving a 25.7% increase in the coefficient of determination (R^2) for long peptides. This research provides a precise logD prediction tool for peptide drug development, particularly demonstrating unique value in optimizing long peptide lead compounds.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.17198.pdf", "abstract_url": "https://arxiv.org/abs/2505.17198", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "LengthLogD是一个通过分子长度分层和多尺度分子表示创新集成的预测框架，用于增强肽脂溶性预测。", "motivation": "肽化合物作为治疗剂具有巨大潜力，但其药物开发受限于低膜渗透性。准确预测肽的logD由于序列、结构和电离状态之间复杂的相互作用而具有挑战性。", "method": "通过分子长度分层建立专门模型，并创新性地整合多尺度分子表示，构建了三个层次的特征空间：原子（10个分子描述符）、结构（1024位摩根指纹）和拓扑（包括Wiener指数在内的3个基于图的特征），通过分层集成学习进行优化。", "result": "实验结果显示，LengthLogD在所有类别中表现出优越性能：短肽（R^2=0.855）、中肽（R^2=0.816）和长肽（R^2=0.882），与传统的单一模型方法相比，长肽的预测误差减少了34.7%。", "conclusion": "这项研究为肽药物开发提供了一个精确的logD预测工具，特别是在优化长肽先导化合物方面展示了独特的价值。"}}
{"id": "2505.17612", "title": "Distilling LLM Agent into Small Models with Retrieval and Code Tools", "authors": ["Minki Kang", "Jongwon Jeong", "Seanie Lee", "Jaewoong Cho", "Sung Ju Hwang"], "abstract": "Large language models (LLMs) excel at complex reasoning tasks but remain computationally expensive, limiting their practical deployment. To address this, recent works have focused on distilling reasoning capabilities into smaller language models (sLMs) using chain-of-thought (CoT) traces from teacher LLMs. However, this approach struggles in scenarios requiring rare factual knowledge or precise computation, where sLMs often hallucinate due to limited capability. In this work, we propose Agent Distillation, a framework for transferring not only reasoning capability but full task-solving behavior from LLM-based agents into sLMs with retrieval and code tools. We improve agent distillation along two complementary axes: (1) we introduce a prompting method called first-thought prefix to enhance the quality of teacher-generated trajectories; and (2) we propose a self-consistent action generation for improving test-time robustness of small agents. We evaluate our method on eight reasoning tasks across factual and mathematical domains, covering both in-domain and out-of-domain generalization. Our results show that sLMs as small as 0.5B, 1.5B, 3B parameters can achieve performance competitive with next-tier larger 1.5B, 3B, 7B models fine-tuned using CoT distillation, demonstrating the potential of agent distillation for building practical, tool-using small agents. Our code is available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "preprint, v1", "pdf_url": "https://arxiv.org/pdf/2505.17612.pdf", "abstract_url": "https://arxiv.org/abs/2505.17612", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了Agent Distillation框架，旨在将大型语言模型（LLMs）的推理能力和任务解决行为转移到小型语言模型（sLMs）中，通过引入检索和代码工具来解决sLMs在罕见事实知识或精确计算方面的局限性。", "motivation": "大型语言模型在复杂推理任务上表现出色，但计算成本高，限制了其实际部署。本研究旨在通过蒸馏技术将LLMs的能力转移到更小的模型中，以降低部署成本。", "method": "提出了Agent Distillation框架，包括两个改进方向：1) 引入first-thought prefix提示方法以提高教师生成轨迹的质量；2) 提出自一致行动生成以提高小型代理在测试时的鲁棒性。", "result": "在八个推理任务上的评估显示，参数规模仅为0.5B、1.5B、3B的sLMs能够与使用CoT蒸馏的更大模型（1.5B、3B、7B）竞争，展示了Agent Distillation在构建实用小型代理方面的潜力。", "conclusion": "Agent Distillation框架有效地将LLMs的能力转移到sLMs中，通过引入工具支持，使得小型模型在保持性能的同时降低了计算成本，为实际应用提供了可能。"}}
{"id": "2505.17616", "title": "Runaway is Ashamed, But Helpful: On the Early-Exit Behavior of Large Language Model-based Agents in Embodied Environments", "authors": ["Qingyu Lu", "Liang Ding", "Siyi Cao", "Xuebo Liu", "Kanjian Zhang", "Jinxia Zhang", "Dacheng Tao"], "abstract": "Agents powered by large language models (LLMs) have demonstrated strong planning and decision-making capabilities in complex embodied environments. However, such agents often suffer from inefficiencies in multi-turn interactions, frequently trapped in repetitive loops or issuing ineffective commands, leading to redundant computational overhead. Instead of relying solely on learning from trajectories, we take a first step toward exploring the early-exit behavior for LLM-based agents. We propose two complementary approaches: 1. an $\\textbf{intrinsic}$ method that injects exit instructions during generation, and 2. an $\\textbf{extrinsic}$ method that verifies task completion to determine when to halt an agent's trial. To evaluate early-exit mechanisms, we introduce two metrics: one measures the reduction of $\\textbf{redundant steps}$ as a positive effect, and the other evaluates $\\textbf{progress degradation}$ as a negative effect. Experiments with 4 different LLMs across 5 embodied environments show significant efficiency improvements, with only minor drops in agent performance. We also validate a practical strategy where a stronger agent assists after an early-exit agent, achieving better performance with the same total steps. We will release our code to support further research.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "Under Review", "pdf_url": "https://arxiv.org/pdf/2505.17616.pdf", "abstract_url": "https://arxiv.org/abs/2505.17616", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了基于大型语言模型（LLM）的代理在具身环境中的早期退出行为，提出了两种互补的方法来提高效率，并通过实验验证了其有效性。", "motivation": "大型语言模型（LLM）驱动的代理在复杂具身环境中表现出强大的规划和决策能力，但在多轮互动中效率低下，常陷入重复循环或发出无效命令，导致冗余计算开销。", "method": "提出了两种方法：1. 一种内在方法，在生成过程中注入退出指令；2. 一种外在方法，验证任务完成情况以决定何时停止代理的尝试。", "result": "在5个具身环境中使用4种不同的LLM进行的实验显示，效率有显著提高，代理性能仅有轻微下降。验证了一种实用策略，即在早期退出代理后由更强的代理协助，以相同的总步骤实现更好的性能。", "conclusion": "早期退出机制可以显著提高LLM基于代理的效率，同时保持性能，为未来研究提供了支持。"}}
{"id": "2505.17762", "title": "Resolving Conflicting Evidence in Automated Fact-Checking: A Study on Retrieval-Augmented LLMs", "authors": ["Ziyu Ge", "Yuhao Wu", "Daniel Wai Kit Chin", "Roy Ka-Wei Lee", "Rui Cao"], "abstract": "Large Language Models (LLMs) augmented with retrieval mechanisms have demonstrated significant potential in fact-checking tasks by integrating external knowledge. However, their reliability decreases when confronted with conflicting evidence from sources of varying credibility. This paper presents the first systematic evaluation of Retrieval-Augmented Generation (RAG) models for fact-checking in the presence of conflicting evidence. To support this study, we introduce \\textbf{CONFACT} (\\textbf{Con}flicting Evidence for \\textbf{Fact}-Checking) (Dataset available at", "subjects": "Computation and Language (cs.CL); Information Retrieval (cs.IR)", "comments": "Camera-ready for IJCAI 2025, AI and Social Good", "pdf_url": "https://arxiv.org/pdf/2505.17762.pdf", "abstract_url": "https://arxiv.org/abs/2505.17762", "categories": ["Computation and Language (cs.CL)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文首次系统地评估了在存在冲突证据的情况下，检索增强生成（RAG）模型在事实核查任务中的表现，并引入了CONFACT数据集以支持研究。", "motivation": "大型语言模型（LLMs）通过整合外部知识在事实核查任务中显示出巨大潜力，但在面对来自不同可信度来源的冲突证据时，其可靠性下降。", "method": "研究采用了检索增强生成（RAG）模型，并引入了CONFACT数据集来系统评估这些模型在处理冲突证据时的表现。", "result": "研究结果显示，检索增强的LLMs在存在冲突证据的情况下，其事实核查的可靠性有所下降。", "conclusion": "本研究强调了在事实核查任务中处理冲突证据的重要性，并为未来改进检索增强LLMs的可靠性提供了方向。"}}
{"id": "2505.17321", "title": "Control of Renewable Energy Communities using AI and Real-World Data", "authors": ["Tiago Fonseca", "Clarisse Sousa", "Ricardo Venâncio", "Pedro Pires", "Ricardo Severino", "Paulo Rodrigues", "Pedro Paiva", "Luis Lino Ferreira"], "abstract": "The electrification of transportation and the increased adoption of decentralized renewable energy generation have added complexity to managing Renewable Energy Communities (RECs). Integrating Electric Vehicle (EV) charging with building energy systems like heating, ventilation, air conditioning (HVAC), photovoltaic (PV) generation, and battery storage presents significant opportunities but also practical challenges. Reinforcement learning (RL), particularly MultiAgent Deep Deterministic Policy Gradient (MADDPG) algorithms, have shown promising results in simulation, outperforming heuristic control strategies. However, translating these successes into real-world deployments faces substantial challenges, including incomplete and noisy data, integration of heterogeneous subsystems, synchronization issues, unpredictable occupant behavior, and missing critical EV state-of-charge (SoC) information. This paper introduces a framework designed explicitly to handle these complexities and bridge the simulation to-reality gap. The framework incorporates EnergAIze, a MADDPG-based multi-agent control strategy, and specifically addresses challenges related to real-world data collection, system integration, and user behavior modeling. Preliminary results collected from a real-world operational REC with four residential buildings demonstrate the practical feasibility of our approach, achieving an average 9% reduction in daily peak demand and a 5% decrease in energy costs through optimized load scheduling and EV charging behaviors. These outcomes underscore the framework's effectiveness, advancing the practical deployment of intelligent energy management solutions in RECs.", "subjects": "Systems and Control (eess.SY); Artificial Intelligence (cs.AI)", "comments": "8 pages, 3 figures, 1 table, 30th IEEE International Conference on Emerging Technologies and Factory Automation", "pdf_url": "https://arxiv.org/pdf/2505.17321.pdf", "abstract_url": "https://arxiv.org/abs/2505.17321", "categories": ["Systems and Control (eess.SY)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一个利用人工智能和真实世界数据管理可再生能源社区（RECs）的框架，旨在解决电动汽车充电与建筑能源系统整合的复杂性。通过采用基于MADDPG的多智能体控制策略EnergAIze，该框架有效处理了数据不完整、噪声、异构子系统整合等挑战，并在实际运营的REC中实现了日均峰值需求降低9%和能源成本减少5%的初步成果。", "motivation": "随着交通电气化和分散式可再生能源发电的普及，管理可再生能源社区（RECs）变得日益复杂。电动汽车充电与建筑能源系统（如HVAC、PV发电和电池存储）的整合既带来了机遇也带来了挑战。本文旨在解决这些挑战，特别是从模拟到实际部署的过渡问题。", "method": "本文提出了一个框架，该框架采用了基于多智能体深度确定性策略梯度（MADDPG）算法的EnergAIze控制策略，专门处理真实世界数据收集、系统整合和用户行为建模等挑战。", "result": "在一个由四栋住宅建筑组成的实际运营的REC中进行的初步测试显示，该框架通过优化负载调度和电动汽车充电行为，实现了日均峰值需求降低9%和能源成本减少5%的效果。", "conclusion": "这些成果证明了该框架在推动智能能源管理解决方案在实际RECs中部署的有效性，为解决从模拟到实际部署的挑战提供了实用的方法。"}}
{"id": "2505.17767", "title": "The Real Barrier to LLM Agent Usability is Agentic ROI", "authors": ["Weiwen Liu", "Jiarui Qin", "Xu Huang", "Xingshan Zeng", "Yunjia Xi", "Jianghao Lin", "Chuhan Wu", "Yasheng Wang", "Lifeng Shang", "Ruiming Tang", "Defu Lian", "Yong Yu", "Weinan Zhang"], "abstract": "Large Language Model (LLM) agents represent a promising shift in human-AI interaction, moving beyond passive prompt-response systems to autonomous agents capable of reasoning, planning, and goal-directed action. Despite the widespread application in specialized, high-effort tasks like coding and scientific research, we highlight a critical usability gap in high-demand, mass-market applications. This position paper argues that the limited real-world adoption of LLM agents stems not only from gaps in model capabilities, but also from a fundamental tradeoff between the value an agent can provide and the costs incurred during real-world use. Hence, we call for a shift from solely optimizing model performance to a broader, utility-driven perspective: evaluating agents through the lens of the overall agentic return on investment (Agent ROI). By identifying key factors that determine Agentic ROI--information quality, agent time, and cost--we posit a zigzag development trajectory in optimizing agentic ROI: first scaling up to improve the information quality, then scaling down to minimize the time and cost. We outline the roadmap across different development stages to bridge the current usability gaps, aiming to make LLM agents truly scalable, accessible, and effective in real-world contexts.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.17767.pdf", "abstract_url": "https://arxiv.org/abs/2505.17767", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文讨论了大型语言模型（LLM）代理在现实世界应用中的可用性差距，提出了通过优化代理投资回报（Agent ROI）来提升其实际应用价值的观点。", "motivation": "解决LLM代理在广泛市场需求中的应用不足问题，指出除了模型能力的限制外，代理提供的价值与使用成本之间的基本权衡也是限制其实际应用的关键因素。", "method": "提出了一个以效用驱动的视角，通过评估代理投资回报（Agent ROI）来优化代理的发展路径，包括信息质量、代理时间和成本等关键因素。", "result": "提出了一个曲折的发展轨迹：首先扩大规模以提高信息质量，然后缩小规模以最小化时间和成本，旨在跨越当前的可用性差距。", "conclusion": "通过优化Agent ROI，可以使LLM代理在现实世界中真正实现可扩展性、可访问性和有效性。"}}
{"id": "2505.17379", "title": "Provably Efficient Algorithm for Best Scoring Rule Identification in Online Principal-Agent Information Acquisition", "authors": ["Zichen Wang", "Chuanhao Li", "Huazheng Wang"], "abstract": "We investigate the problem of identifying the optimal scoring rule within the principal-agent framework for online information acquisition problem. We focus on the principal's perspective, seeking to determine the desired scoring rule through interactions with the agent. To address this challenge, we propose two algorithms: OIAFC and OIAFB, tailored for fixed confidence and fixed budget settings, respectively. Our theoretical analysis demonstrates that OIAFC can extract the desired $(\\epsilon, \\delta)$-scoring rule with a efficient instance-dependent sample complexity or an instance-independent sample complexity. Our analysis also shows that OIAFB matches the instance-independent performance bound of OIAFC, while both algorithms share the same complexity across fixed confidence and fixed budget settings.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "ICML 2025", "pdf_url": "https://arxiv.org/pdf/2505.17379.pdf", "abstract_url": "https://arxiv.org/abs/2505.17379", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究了在线信息获取问题中，从委托人角度识别最优评分规则的问题，提出了两种算法OIAFC和OIAFB，分别针对固定信心和固定预算设置，理论分析表明这两种算法都能高效地提取所需的评分规则。", "motivation": "解决在线信息获取问题中，委托人如何通过与代理人的互动确定最优评分规则的问题。", "method": "提出了两种算法：OIAFC（固定信心设置）和OIAFB（固定预算设置），并进行了理论分析。", "result": "OIAFC能够高效提取所需的(ε, δ)-评分规则，OIAFB在实例独立性能上与OIAFC相匹配，两种算法在固定信心和固定预算设置下具有相同的复杂度。", "conclusion": "本文提出的算法能够有效地解决在线信息获取问题中的最优评分规则识别问题，为委托人提供了实用的工具。"}}
{"id": "2505.17500", "title": "The Discovery Engine: A Framework for AI-Driven Synthesis and Navigation of Scientific Knowledge Landscapes", "authors": ["Vladimir Baulin", "Austin Cook", "Daniel Friedman", "Janna Lumiruusu", "Andrew Pashea", "Shagor Rahman", "Benedikt Waldeck"], "abstract": "The prevailing model for disseminating scientific knowledge relies on individual publications dispersed across numerous journals and archives. This legacy system is ill suited to the recent exponential proliferation of publications, contributing to insurmountable information overload, issues surrounding reproducibility and retractions. We introduce the Discovery Engine, a framework to address these challenges by transforming an array of disconnected literature into a unified, computationally tractable representation of a scientific domain. Central to our approach is the LLM-driven distillation of publications into structured \"knowledge artifacts,\" instances of a universal conceptual schema, complete with verifiable links to source evidence. These artifacts are then encoded into a high-dimensional Conceptual Tensor. This tensor serves as the primary, compressed representation of the synthesized field, where its labeled modes index scientific components (concepts, methods, parameters, relations) and its entries quantify their interdependencies. The Discovery Engine allows dynamic \"unrolling\" of this tensor into human-interpretable views, such as explicit knowledge graphs (the CNM graph) or semantic vector spaces, for targeted exploration. Crucially, AI agents operate directly on the graph using abstract mathematical and learned operations to navigate the knowledge landscape, identify non-obvious connections, pinpoint gaps, and assist researchers in generating novel knowledge artifacts (hypotheses, designs). By converting literature into a structured tensor and enabling agent-based interaction with this compact representation, the Discovery Engine offers a new paradigm for AI-augmented scientific inquiry and accelerated discovery.", "subjects": "Soft Condensed Matter (cond-mat.soft); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.17500.pdf", "abstract_url": "https://arxiv.org/abs/2505.17500", "categories": ["Soft Condensed Matter (cond-mat.soft)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了‘发现引擎’，一个通过将分散的科学文献转化为统一、计算可处理的科学领域表示，以解决信息过载和可重复性问题的AI驱动框架。", "motivation": "解决传统科学知识传播模型因出版物数量激增导致的信息过载、可重复性和撤稿问题。", "method": "利用LLM驱动的技术将出版物提炼为结构化的‘知识 artifacts’，并将其编码为高维概念张量，作为科学领域的压缩表示。", "result": "发现引擎能够动态地将概念张量展开为人类可解释的视图，如知识图谱或语义向量空间，支持目标探索和AI代理的直接操作。", "conclusion": "发现引擎通过将文献转化为结构化张量并支持基于代理的交互，为AI增强的科学探究和加速发现提供了新范式。"}}
{"id": "2505.17795", "title": "DialogXpert: Driving Intelligent and Emotion-Aware Conversations through Online Value-Based Reinforcement Learning with LLM Priors", "authors": ["Tazeek Bin Abdur Rakib", "Ambuj Mehrish", "Lay-Ki Soon", "Wern Han Lim", "Soujanya Poria"], "abstract": "Large-language-model (LLM) agents excel at reactive dialogue but struggle with proactive, goal-driven interactions due to myopic decoding and costly planning. We introduce DialogXpert, which leverages a frozen LLM to propose a small, high-quality set of candidate actions per turn and employs a compact Q-network over fixed BERT embeddings trained via temporal-difference learning to select optimal moves within this reduced space. By tracking the user's emotions, DialogXpert tailors each decision to advance the task while nurturing a genuine, empathetic connection. Across negotiation, emotional support, and tutoring benchmarks, DialogXpert drives conversations to under $3$ turns with success rates exceeding 94\\% and, with a larger LLM prior, pushes success above 97\\% while markedly improving negotiation outcomes. This framework delivers real-time, strategic, and emotionally intelligent dialogue planning at scale. Code available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.17795.pdf", "abstract_url": "https://arxiv.org/abs/2505.17795", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "DialogXpert利用冻结的大型语言模型（LLM）提出每回合一小部分高质量的候选动作，并通过基于固定BERT嵌入的紧凑Q网络，通过时间差分学习在这些减少的空间中选择最优动作。通过跟踪用户情绪，DialogXpert定制每个决策以推进任务，同时培养真诚、共情的连接。在谈判、情感支持和辅导基准测试中，DialogXpert在不到3回合内驱动对话，成功率超过94%，使用更大的LLM先验时，成功率超过97%，同时显著改善谈判结果。", "motivation": "大型语言模型（LLM）代理在反应性对话中表现出色，但在主动、目标驱动的交互中由于短视解码和高成本规划而表现不佳。DialogXpert旨在解决这一问题，通过结合LLM和强化学习，实现实时、战略性和情感智能的对话规划。", "method": "DialogXpert结合了冻结的LLM和基于固定BERT嵌入的紧凑Q网络，通过时间差分学习在减少的动作空间中选择最优动作。该方法还包括跟踪用户情绪，以定制决策并推进任务。", "result": "在谈判、情感支持和辅导基准测试中，DialogXpert在不到3回合内驱动对话，成功率超过94%。使用更大的LLM先验时，成功率超过97%，同时显著改善谈判结果。", "conclusion": "DialogXpert框架实现了实时、战略性和情感智能的对话规划，显著提高了对话的成功率和效率，特别是在谈判、情感支持和辅导等应用中。"}}
{"id": "2505.18105", "title": "ManuSearch: Democratizing Deep Search in Large Language Models with a Transparent and Open Multi-Agent Framework", "authors": ["Lisheng Huang", "Yichen Liu", "Jinhao Jiang", "Rongxiang Zhang", "Jiahao Yan", "Junyi Li", "Wayne Xin Zhao"], "abstract": "Recent advances in web-augmented large language models (LLMs) have exhibited strong performance in complex reasoning tasks, yet these capabilities are mostly locked in proprietary systems with opaque architectures. In this work, we propose \\textbf{ManuSearch}, a transparent and modular multi-agent framework designed to democratize deep search for LLMs. ManuSearch decomposes the search and reasoning process into three collaborative agents: (1) a solution planning agent that iteratively formulates sub-queries, (2) an Internet search agent that retrieves relevant documents via real-time web search, and (3) a structured webpage reading agent that extracts key evidence from raw web content. To rigorously evaluate deep reasoning abilities, we introduce \\textbf{ORION}, a challenging benchmark focused on open-web reasoning over long-tail entities, covering both English and Chinese. Experimental results show that ManuSearch substantially outperforms prior open-source baselines and even surpasses leading closed-source systems. Our work paves the way for reproducible, extensible research in open deep search systems. We release the data and code in", "subjects": "Computation and Language (cs.CL)", "comments": "LLM, Complex Search Benchmark", "pdf_url": "https://arxiv.org/pdf/2505.18105.pdf", "abstract_url": "https://arxiv.org/abs/2505.18105", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了ManuSearch，一个透明和模块化的多代理框架，旨在为大型语言模型（LLMs）实现深度搜索的民主化。通过分解搜索和推理过程为三个协作代理，ManuSearch在开放网络推理方面表现出色，甚至超过了领先的闭源系统。", "motivation": "当前，网络增强的大型语言模型在复杂推理任务中表现出色，但这些能力大多锁定在架构不透明的专有系统中。本文旨在通过提出一个透明和开放的多代理框架，解决这一问题，实现深度搜索的民主化。", "method": "ManuSearch将搜索和推理过程分解为三个协作代理：解决方案规划代理、互联网搜索代理和结构化网页阅读代理。此外，引入了ORION基准，以严格评估深度推理能力。", "result": "实验结果表明，ManuSearch显著优于先前的开源基线，甚至超过了领先的闭源系统。", "conclusion": "这项工作为可复制、可扩展的开放深度搜索系统研究铺平了道路。数据和代码已公开发布。"}}
{"id": "2505.18098", "title": "Planning without Search: Refining Frontier LLMs with Offline Goal-Conditioned RL", "authors": ["Joey Hong", "Anca Dragan", "Sergey Levine"], "abstract": "Large language models (LLMs) excel in tasks like question answering and dialogue, but complex tasks requiring interaction, such as negotiation and persuasion, require additional long-horizon reasoning and planning. Reinforcement learning (RL) fine-tuning can enable such planning in principle, but suffers from drawbacks that hinder scalability. In particular, multi-turn RL training incurs high memory and computational costs, which are exacerbated when training LLMs as policies. Furthermore, the largest LLMs do not expose the APIs necessary to be trained in such manner. As a result, modern methods to improve the reasoning of LLMs rely on sophisticated prompting mechanisms rather than RL fine-tuning. To remedy this, we propose a novel approach that uses goal-conditioned value functions to guide the reasoning of LLM agents, that scales even to large API-based models. These value functions predict how a task will unfold given an action, allowing the LLM agent to evaluate multiple possible outcomes, both positive and negative, to plan effectively. In addition, these value functions are trained over reasoning steps rather than full actions, to be a concise and light-weight module that facilitates decision-making in multi-turn interactions. We validate our method on tasks requiring interaction, including tool use, social deduction, and dialogue, demonstrating superior performance over both RL fine-tuning and prompting methods while maintaining efficiency and scalability.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "18 pages, 4 figures, 2 tables", "pdf_url": "https://arxiv.org/pdf/2505.18098.pdf", "abstract_url": "https://arxiv.org/abs/2505.18098", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新颖的方法，使用目标条件价值函数来指导大型语言模型（LLM）代理的推理，这种方法甚至可以扩展到大型基于API的模型。", "motivation": "大型语言模型在问答和对话等任务中表现出色，但在需要交互的复杂任务（如谈判和说服）中，需要额外的长视野推理和规划。现有的强化学习（RL）微调方法虽然原则上可以实现这种规划，但存在内存和计算成本高的问题，尤其是对于大型LLM作为策略时更为严重。此外，最大的LLM不提供必要的API以支持此类训练。因此，现代改进LLM推理的方法依赖于复杂的提示机制而非RL微调。", "method": "提出使用目标条件价值函数来指导LLM代理的推理，这些价值函数预测给定行动后任务将如何展开，使LLM代理能够评估多种可能的结果（正面和负面），以有效规划。这些价值函数在推理步骤而非完整行动上进行训练，成为一个简洁轻量级的模块，促进多轮交互中的决策制定。", "result": "在需要交互的任务（包括工具使用、社交推理和对话）上验证了该方法，证明了其在保持效率和可扩展性的同时，性能优于RL微调和提示方法。", "conclusion": "该方法通过使用目标条件价值函数指导LLM代理的推理，有效解决了复杂交互任务中的长视野规划和推理问题，同时克服了现有RL微调方法的局限，为LLM在更广泛领域的应用提供了可能。"}}
{"id": "2505.18148", "title": "Lost in the Haystack: Smaller Needles are More Difficult for LLMs to Find", "authors": ["Owen Bianchi", "Mathew J. Koretsky", "Maya Willey", "Chelsea X. Alvarado", "Tanay Nayak", "Adi Asija", "Nicole Kuznetsov", "Mike A. Nalls", "Faraz Faghri", "Daniel Khashabi"], "abstract": "Large language models (LLMs) face significant challenges with needle-in-a-haystack tasks, where relevant information (\"the needle\") must be drawn from a large pool of irrelevant context (\"the haystack\"). Previous studies have highlighted positional bias and distractor quantity as critical factors affecting model performance, yet the influence of gold context size has received little attention. We address this gap by systematically studying how variations in gold context length impact LLM performance on long-context question answering tasks. Our experiments reveal that LLM performance drops sharply when the gold context is shorter, i.e., smaller gold contexts consistently degrade model performance and amplify positional sensitivity, posing a major challenge for agentic systems that must integrate scattered, fine-grained information of varying lengths. This pattern holds across three diverse domains (general knowledge, biomedical reasoning, and mathematical reasoning) and seven state-of-the-art LLMs of various sizes and architectures. Our work provides clear insights to guide the design of robust, context-aware LLM-driven systems.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "Under Review", "pdf_url": "https://arxiv.org/pdf/2505.18148.pdf", "abstract_url": "https://arxiv.org/abs/2505.18148", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "大型语言模型（LLMs）在处理‘大海捞针’任务时面临显著挑战，尤其是当相关信息（‘针’）较短时。本研究系统地探讨了黄金上下文长度变化对LLMs在长上下文问答任务中表现的影响，发现黄金上下文较短时，模型表现显著下降，且位置敏感性增强。这一现象在三个不同领域和七种最先进的LLMs中均得到验证。", "motivation": "解决大型语言模型在处理需要从大量无关信息中提取简短相关信息的任务时表现不佳的问题，特别是黄金上下文长度对模型性能的影响。", "method": "通过系统地研究黄金上下文长度变化对LLMs在长上下文问答任务中表现的影响，进行实验分析。", "result": "实验结果显示，当黄金上下文较短时，LLMs的表现显著下降，且位置敏感性增强。这一现象在三个不同领域（通用知识、生物医学推理和数学推理）和七种不同规模和架构的LLMs中均一致。", "conclusion": "研究结果为设计健壮、上下文感知的LLM驱动系统提供了明确的指导，强调了在处理分散、细粒度且长度不一的信息时面临的挑战。"}}
{"id": "2505.17511", "title": "Multi-agent Systems for Misinformation Lifecycle : Detection, Correction And Source Identification", "authors": ["Aditya Gautam"], "abstract": "The rapid proliferation of misinformation in digital media demands solutions that go beyond isolated Large Language Model(LLM) or AI Agent based detection methods. This paper introduces a novel multi-agent framework that covers the complete misinformation lifecycle: classification, detection, correction, and source verification to deliver more transparent and reliable outcomes. In contrast to single-agent or monolithic architectures, our approach employs five specialized agents: an Indexer agent for dynamically maintaining trusted repositories, a Classifier agent for labeling misinformation types, an Extractor agent for evidence based retrieval and ranking, a Corrector agent for generating fact-based correction and a Verification agent for validating outputs and tracking source credibility. Each agent can be individually evaluated and optimized, ensuring scalability and adaptability as new types of misinformation and data sources emerge. By decomposing the misinformation lifecycle into specialized agents - our framework enhances scalability, modularity, and explainability. This paper proposes a high-level system overview, agent design with emphasis on transparency, evidence-based outputs, and source provenance to support robust misinformation detection and correction at scale.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.17511.pdf", "abstract_url": "https://arxiv.org/abs/2505.17511", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Emerging Technologies (cs.ET)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一种新颖的多智能体框架，旨在全面应对数字媒体中错误信息的生命周期，包括分类、检测、纠正和来源验证，以提高透明度和可靠性。", "motivation": "数字媒体中错误信息的快速传播需要超越孤立的大型语言模型(LLM)或基于AI代理的检测方法的解决方案。", "method": "采用五个专门化的代理：索引代理动态维护可信存储库，分类代理标记错误信息类型，提取代理基于证据进行检索和排名，纠正代理生成基于事实的纠正，验证代理验证输出并跟踪来源可信度。", "result": "通过将错误信息生命周期分解为专门化的代理，该框架增强了可扩展性、模块化和可解释性。", "conclusion": "该框架支持大规模的错误信息检测和纠正，强调透明度、基于证据的输出和来源可追溯性。"}}
{"id": "2505.17629", "title": "TransBench: Breaking Barriers for Transferable Graphical User Interface Agents in Dynamic Digital Environments", "authors": ["Yuheng Lu", "Qian Yu", "Hongru Wang", "Zeming Liu", "Wei Su", "Yanping Liu", "Yuhang Guo", "Maocheng Liang", "Yunhong Wang", "Haifeng Wang"], "abstract": "Graphical User Interface (GUI) agents, which autonomously operate on digital interfaces through natural language instructions, hold transformative potential for accessibility, automation, and user experience. A critical aspect of their functionality is grounding - the ability to map linguistic intents to visual and structural interface elements. However, existing GUI agents often struggle to adapt to the dynamic and interconnected nature of real-world digital environments, where tasks frequently span multiple platforms and applications while also being impacted by version updates. To address this, we introduce TransBench, the first benchmark designed to systematically evaluate and enhance the transferability of GUI agents across three key dimensions: cross-version transferability (adapting to version updates), cross-platform transferability (generalizing across platforms like iOS, Android, and Web), and cross-application transferability (handling tasks spanning functionally distinct apps). TransBench includes 15 app categories with diverse functionalities, capturing essential pages across versions and platforms to enable robust evaluation. Our experiments demonstrate significant improvements in grounding accuracy, showcasing the practical utility of GUI agents in dynamic, real-world environments. Our code and data will be publicly available at Github.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": "Accepted by ACL 2025 Findings", "pdf_url": "https://arxiv.org/pdf/2505.17629.pdf", "abstract_url": "https://arxiv.org/abs/2505.17629", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "TransBench是首个旨在系统评估和提升图形用户界面(GUI)代理在跨版本、跨平台和跨应用三个关键维度上可转移性的基准。它包括15个应用类别，涵盖不同功能，以支持在动态数字环境中的鲁棒评估。实验显示，在接地准确性方面有显著提升。", "motivation": "解决GUI代理在适应动态和互联的真实世界数字环境中的挑战，特别是在跨版本更新、跨平台（如iOS、Android和Web）和跨应用（处理功能不同的应用任务）的可转移性方面。", "method": "引入TransBench基准，包括15个应用类别，涵盖不同功能，捕获跨版本和平台的关键页面，以系统评估GUI代理的可转移性。", "result": "实验结果表明，在接地准确性方面有显著提升，展示了GUI代理在动态、真实世界环境中的实际效用。", "conclusion": "TransBench为评估和提升GUI代理的可转移性提供了系统的方法，实验证明了其在动态数字环境中的有效性，代码和数据将公开可用。"}}
{"id": "2505.17826", "title": "Trinity-RFT: A General-Purpose and Unified Framework for Reinforcement Fine-Tuning of Large Language Models", "authors": ["Xuchen Pan", "Yanxi Chen", "Yushuo Chen", "Yuchang Sun", "Daoyuan Chen", "Wenhao Zhang", "Yuexiang Xie", "Yilun Huang", "Yilei Zhang", "Dawei Gao", "Yaliang Li", "Bolin Ding", "Jingren Zhou"], "abstract": "Trinity-RFT is a general-purpose, flexible and scalable framework designed for reinforcement fine-tuning (RFT) of large language models. It is built with a decoupled design, consisting of (1) an RFT-core that unifies and generalizes synchronous/asynchronous, on-policy/off-policy, and online/offline modes of RFT, (2) seamless integration for agent-environment interaction with high efficiency and robustness, and (3) systematic data pipelines optimized for RFT. Trinity-RFT can be easily adapted for diverse application scenarios, and serves as a unified platform for exploring advanced reinforcement learning paradigms. This technical report outlines the vision, features, design and implementations of Trinity-RFT, accompanied by extensive examples demonstrating the utility and user-friendliness of the proposed framework.", "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL); Distributed, Parallel, and Cluster Computing (cs.DC)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.17826.pdf", "abstract_url": "https://arxiv.org/abs/2505.17826", "categories": ["Machine Learning (cs.LG)", "Computation and Language (cs.CL)", "Distributed, Parallel, and Cluster Computing (cs.DC)"], "matching_keywords": ["agent"], "AI": {"tldr": "Trinity-RFT是一个通用、灵活且可扩展的框架，专为大型语言模型的强化微调（RFT）设计。它采用解耦设计，包含RFT核心、高效的代理-环境交互集成和优化的数据管道，适用于多种应用场景，并作为探索高级强化学习范式的统一平台。", "motivation": "解决大型语言模型在强化微调过程中的通用性、灵活性和可扩展性问题，提供一个统一的框架来支持多种强化学习模式和应用场景。", "method": "采用解耦设计，包括一个统一的RFT核心、高效的代理-环境交互集成和系统优化的数据管道，支持同步/异步、在线/离线等多种RFT模式。", "result": "Trinity-RFT框架能够灵活适应不同的应用场景，作为一个统一的平台，有效地支持了高级强化学习范式的探索和实践。", "conclusion": "Trinity-RFT为大型语言模型的强化微调提供了一个强大、灵活且易于使用的框架，有望推动强化学习在自然语言处理等领域的进一步发展和应用。"}}
{"id": "2505.17830", "title": "Imagine Beyond! Distributionally Robust Auto-Encoding for State Space Coverage in Online Reinforcement Learning", "authors": ["Nicolas Castanet", "Olivier Sigaud", "Sylvain Lamprier"], "abstract": "Goal-Conditioned Reinforcement Learning (GCRL) enables agents to autonomously acquire diverse behaviors, but faces major challenges in visual environments due to high-dimensional, semantically sparse observations. In the online setting, where agents learn representations while exploring, the latent space evolves with the agent's policy, to capture newly discovered areas of the environment. However, without incentivization to maximize state coverage in the representation, classical approaches based on auto-encoders may converge to latent spaces that over-represent a restricted set of states frequently visited by the agent. This is exacerbated in an intrinsic motivation setting, where the agent uses the distribution encoded in the latent space to sample the goals it learns to master. To address this issue, we propose to progressively enforce distributional shifts towards a uniform distribution over the full state space, to ensure a full coverage of skills that can be learned in the environment. We introduce DRAG (Distributionally Robust Auto-Encoding for GCRL), a method that combines the $\\beta$-VAE framework with Distributionally Robust Optimization. DRAG leverages an adversarial neural weighter of training states of the VAE, to account for the mismatch between the current data distribution and unseen parts of the environment. This allows the agent to construct semantically meaningful latent spaces beyond its immediate experience. Our approach improves state space coverage and downstream control performance on hard exploration environments such as mazes and robotic control involving walls to bypass, without pre-training nor prior environment knowledge.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.17830.pdf", "abstract_url": "https://arxiv.org/abs/2505.17830", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文提出了一种名为DRAG的方法，通过结合β-VAE框架和分布鲁棒优化，解决了目标条件强化学习（GCRL）在视觉环境中因高维、语义稀疏观察而面临的主要挑战。DRAG通过对抗性神经加权器，确保了对环境状态的全面覆盖，从而在没有预训练或先验环境知识的情况下，提高了迷宫和机器人控制等硬探索环境中的状态空间覆盖和下游控制性能。", "motivation": "目标条件强化学习（GCRL）在视觉环境中因高维、语义稀疏观察而面临主要挑战，特别是在在线学习设置中，潜在空间随代理策略的演变而发展，可能导致潜在空间过度代表代理频繁访问的有限状态集。本文旨在解决这一问题，确保环境技能的全面覆盖。", "method": "本文提出了DRAG（Distributionally Robust Auto-Encoding for GCRL）方法，该方法结合了β-VAE框架和分布鲁棒优化。DRAG利用VAE训练状态的对抗性神经加权器，以考虑当前数据分布与环境未见部分之间的不匹配。", "result": "DRAG方法在没有预训练或先验环境知识的情况下，提高了迷宫和机器人控制等硬探索环境中的状态空间覆盖和下游控制性能。", "conclusion": "通过结合β-VAE框架和分布鲁棒优化，DRAG方法能够构建超越代理即时经验的语义上有意义的潜在空间，从而解决了GCRL在视觉环境中的挑战，提高了状态空间覆盖和控制性能。"}}
{"id": "2505.17997", "title": "Towards Analyzing and Understanding the Limitations of VAPO: A Theoretical Perspective", "authors": ["Jintian Shao", "Yiming Cheng", "Hongyi Huang", "Beiwen Zhang", "Zhiyu Wu", "You Shan", "Mingkai Zheng"], "abstract": "The VAPO framework has demonstrated significant empirical success in enhancing the efficiency and reliability of reinforcement learning for long chain-of-thought (CoT) reasoning tasks with large language models (LLMs). By systematically addressing challenges such as value model bias, heterogeneous sequence lengths, and sparse reward signals, VAPO achieves state-of-the-art performance. While its practical benefits are evident, a deeper theoretical understanding of its underlying mechanisms and potential limitations is crucial for guiding future advancements. This paper aims to initiate such a discussion by exploring VAPO from a theoretical perspective, highlighting areas where its assumptions might be challenged and where further investigation could yield more robust and generalizable reasoning agents. We delve into the intricacies of value function approximation in complex reasoning spaces, the optimality of adaptive advantage estimation, the impact of token-level optimization, and the enduring challenges of exploration and generalization.", "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.17997.pdf", "abstract_url": "https://arxiv.org/abs/2505.17997", "categories": ["Machine Learning (cs.LG)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文从理论角度分析了VAPO框架在增强大型语言模型（LLMs）长链思维（CoT）推理任务效率和可靠性方面的显著实证成功，探讨了其潜在限制和未来发展方向。", "motivation": "尽管VAPO框架在实践中显示出显著优势，但对其理论基础和潜在限制的深入理解对于指导未来的进步至关重要。本文旨在从理论角度探讨VAPO，揭示其假设可能受到挑战的领域，以及进一步研究可能产生更强大和通用推理代理的方向。", "method": "通过理论分析，本文探讨了VAPO框架在复杂推理空间中的价值函数近似、自适应优势估计的最优性、令牌级优化的影响，以及探索和泛化的持久挑战等方面的细节。", "result": "研究强调了VAPO框架在理论上的潜在限制，包括价值函数近似、优势估计的最优性、令牌级优化的效果，以及探索和泛化的挑战，为未来的研究提供了方向。", "conclusion": "本文的结论是，虽然VAPO框架在实践中表现出色，但从理论角度深入理解其机制和限制对于开发更强大和通用的推理代理至关重要。未来的研究应关注于解决这些理论挑战，以推动该领域的进一步发展。"}}
{"id": "2505.18044", "title": "Linear Mixture Distributionally Robust Markov Decision Processes", "authors": ["Zhishuai Liu", "Pan Xu"], "abstract": "Many real-world decision-making problems face the off-dynamics challenge: the agent learns a policy in a source domain and deploys it in a target domain with different state transitions. The distributionally robust Markov decision process (DRMDP) addresses this challenge by finding a robust policy that performs well under the worst-case environment within a pre-specified uncertainty set of transition dynamics. Its effectiveness heavily hinges on the proper design of these uncertainty sets, based on prior knowledge of the dynamics. In this work, we propose a novel linear mixture DRMDP framework, where the nominal dynamics is assumed to be a linear mixture model. In contrast with existing uncertainty sets directly defined as a ball centered around the nominal kernel, linear mixture DRMDPs define the uncertainty sets based on a ball around the mixture weighting parameter. We show that this new framework provides a more refined representation of uncertainties compared to conventional models based on $(s,a)$-rectangularity and $d$-rectangularity, when prior knowledge about the mixture model is present. We propose a meta algorithm for robust policy learning in linear mixture DRMDPs with general $f$-divergence defined uncertainty sets, and analyze its sample complexities under three divergence metrics instantiations: total variation, Kullback-Leibler, and $\\chi^2$ divergences. These results establish the statistical learnability of linear mixture DRMDPs, laying the theoretical foundation for future research on this new setting.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Robotics (cs.RO); Machine Learning (stat.ML)", "comments": "26 pages, 7 figures", "pdf_url": "https://arxiv.org/pdf/2505.18044.pdf", "abstract_url": "https://arxiv.org/abs/2505.18044", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Robotics (cs.RO)", "Machine Learning (stat.ML)"], "matching_keywords": ["agent"], "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
