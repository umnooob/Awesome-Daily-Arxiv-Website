{"id": "2505.23130", "title": "PhotoArtAgent: Intelligent Photo Retouching with Language Model-Based Artist Agents", "authors": ["Haoyu Chen", "Keda Tao", "Yizao Wang", "Xinlei Wang", "Lei Zhu", "Jinjin Gu"], "abstract": "Photo retouching is integral to photographic art, extending far beyond simple technical fixes to heighten emotional expression and narrative depth. While artists leverage expertise to create unique visual effects through deliberate adjustments, non-professional users often rely on automated tools that produce visually pleasing results but lack interpretative depth and interactive transparency. In this paper, we introduce PhotoArtAgent, an intelligent system that combines Vision-Language Models (VLMs) with advanced natural language reasoning to emulate the creative process of a professional artist. The agent performs explicit artistic analysis, plans retouching strategies, and outputs precise parameters to Lightroom through an API. It then evaluates the resulting images and iteratively refines them until the desired artistic vision is achieved. Throughout this process, PhotoArtAgent provides transparent, text-based explanations of its creative rationale, fostering meaningful interaction and user control. Experimental results show that PhotoArtAgent not only surpasses existing automated tools in user studies but also achieves results comparable to those of professional human artists.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23130.pdf", "abstract_url": "https://arxiv.org/abs/2505.23130", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "PhotoArtAgent是一个结合视觉语言模型和高级自然语言推理的智能系统，旨在模拟专业艺术家的创作过程，提供透明、文本化的创作解释，实现与用户的有意义互动和控制。", "motivation": "解决非专业用户在照片修饰中依赖自动化工具但缺乏解释深度和交互透明度的问题。", "method": "结合视觉语言模型（VLMs）和高级自然语言推理，模拟专业艺术家的创作过程，包括艺术分析、修饰策略规划和通过API输出精确参数到Lightroom。", "result": "PhotoArtAgent不仅在使用者研究中超越了现有的自动化工具，而且达到了与专业人类艺术家相当的效果。", "conclusion": "PhotoArtAgent通过智能系统和透明交互，为非专业用户提供了接近专业水平的照片修饰体验，同时保持了创作的解释深度和用户控制。"}}
{"id": "2505.22752", "title": "Climate Finance Bench", "authors": ["Rafik Mankour", "Yassine Chafai", "Hamada Saleh", "Ghassen Ben Hassine", "Thibaud Barreau", "Peter Tankov"], "abstract": "Climate Finance Bench introduces an open benchmark that targets question-answering over corporate climate disclosures using Large Language Models. We curate 33 recent sustainability reports in English drawn from companies across all 11 GICS sectors and annotate 330 expert-validated question-answer pairs that span pure extraction, numerical reasoning, and logical reasoning. Building on this dataset, we propose a comparison of RAG (retrieval-augmented generation) approaches. We show that the retriever's ability to locate passages that actually contain the answer is the chief performance bottleneck. We further argue for transparent carbon reporting in AI-for-climate applications, highlighting advantages of techniques such as Weight Quantization.", "subjects": "Computation and Language (cs.CL)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.22752.pdf", "abstract_url": "https://arxiv.org/abs/2505.22752", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "《气候金融基准》提出了一个开放的基准，旨在利用大型语言模型对公司气候披露进行问答。该研究收集了33份英文可持续发展报告，涵盖了所有11个GICS行业，并标注了330个专家验证的问题-答案对。基于此数据集，研究比较了RAG方法，发现检索器定位包含答案的段落能力是主要性能瓶颈。此外，研究提倡在AI气候应用中透明报告碳排放，强调了权重量化等技术的优势。", "motivation": "解决如何有效利用大型语言模型对公司气候披露进行准确问答的问题，并推动AI在气候应用中碳排放的透明报告。", "method": "收集并标注了330个专家验证的问题-答案对，基于此数据集比较了RAG（检索增强生成）方法，并探讨了权重量化等技术。", "result": "研究发现，检索器定位包含答案的段落能力是主要性能瓶颈，并展示了权重量化等技术在减少碳排放方面的优势。", "conclusion": "通过建立开放的基准和提倡透明碳排放报告，该研究为利用AI技术处理气候披露信息提供了新的视角和方法。"}}
{"id": "2505.22698", "title": "Design and testing of an agent chatbot supporting decision making with public transport data", "authors": ["Luca Fantin", "Marco Antonelli", "Margherita Cesetti", "Daniele Irto", "Bruno Zamengo", "Francesco Silvestri"], "abstract": "Assessing the quality of public transportation services requires the analysis of large quantities of data on the scheduled and actual trips and documents listing the quality constraints each service needs to meet. Interrogating such datasets with SQL queries, organizing and visualizing the data can be quite complex for most users. This paper presents a chatbot offering a user-friendly tool to interact with these datasets and support decision making. It is based on an agent architecture, which expands the capabilities of the core Large Language Model (LLM) by allowing it to interact with a series of tools that can execute several tasks, like performing SQL queries, plotting data and creating maps from the coordinates of a trip and its stops. This paper also tackles one of the main open problems of such Generative AI projects: collecting data to measure the system's performance. Our chatbot has been extensively tested with a workflow that asks several questions and stores the generated query, the retrieved data and the natural language response for each of them. Such questions are drawn from a set of base examples which are then completed with actual data from the database. This procedure yields a dataset for the evaluation of the chatbot's performance, especially the consistency of its answers and the correctness of the generated queries.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.22698.pdf", "abstract_url": "https://arxiv.org/abs/2505.22698", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一种基于代理架构的聊天机器人，旨在通过用户友好的方式帮助用户与公共交通数据集交互，支持决策制定。该聊天机器人扩展了大型语言模型（LLM）的能力，使其能够执行SQL查询、数据绘图和从行程坐标创建地图等任务。此外，本文还探讨了生成式AI项目中的一个主要开放问题：收集数据以测量系统性能。通过广泛测试，收集了评估聊天机器人性能的数据集，特别是其答案的一致性和生成查询的正确性。", "motivation": "评估公共交通服务质量需要分析大量关于计划与实际行程的数据以及每项服务需要满足的质量约束文件。对于大多数用户来说，使用SQL查询、组织和可视化这些数据可能相当复杂。", "method": "基于代理架构的聊天机器人，扩展了核心大型语言模型（LLM）的能力，使其能够与一系列工具交互，执行SQL查询、数据绘图和从行程坐标创建地图等任务。", "result": "通过广泛测试，收集了一个数据集用于评估聊天机器人的性能，特别是其答案的一致性和生成查询的正确性。", "conclusion": "本文提出的聊天机器人提供了一种用户友好的工具，用于与公共交通数据集交互并支持决策制定，同时解决了生成式AI项目中收集数据以测量系统性能的主要开放问题。"}}
{"id": "2505.22777", "title": "MEDAL: A Framework for Benchmarking LLMs as Multilingual Open-Domain Chatbots and Dialogue Evaluators", "authors": ["John Mendonça", "Alon Lavie", "Isabel Trancoso"], "abstract": "As the capabilities of chatbots and their underlying LLMs continue to dramatically improve, evaluating their performance has increasingly become a major blocker to their further development. A major challenge is the available benchmarking datasets, which are largely static, outdated, and lacking in multilingual coverage, limiting their ability to capture subtle linguistic and cultural variations. This paper introduces MEDAL, an automated multi-agent framework for generating, evaluating, and curating more representative and diverse open-domain dialogue evaluation benchmarks. Our approach leverages several state-of-the-art LLMs to generate user-chatbot multilingual dialogues, conditioned on varied seed contexts. A strong LLM (GPT-4.1) is then used for a multidimensional analysis of the performance of the chatbots, uncovering noticeable cross-lingual performance differences. Guided by this large-scale evaluation, we curate a new meta-evaluation multilingual benchmark and human-annotate samples with nuanced quality judgments. This benchmark is then used to assess the ability of several reasoning and non-reasoning LLMs to act as evaluators of open-domain dialogues. We find that current LLMs struggle to detect nuanced issues, particularly those involving empathy and reasoning.", "subjects": "Computation and Language (cs.CL)", "comments": "May ARR", "pdf_url": "https://arxiv.org/pdf/2505.22777.pdf", "abstract_url": "https://arxiv.org/abs/2505.22777", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了MEDAL，一个用于生成、评估和策划更具代表性和多样性的开放领域对话评估基准的自动化多代理框架。该框架利用先进的LLMs生成多语言用户-聊天机器人对话，并通过GPT-4.1进行多维性能分析，揭示了显著的跨语言性能差异。研究还发现，当前的LLMs在检测涉及同理心和推理的细微问题上存在困难。", "motivation": "随着聊天机器人及其底层LLMs能力的显著提升，评估其性能已成为进一步发展的主要障碍。现有基准数据集大多静态、过时且缺乏多语言覆盖，限制了捕捉细微语言和文化差异的能力。", "method": "采用MEDAL框架，利用多个先进的LLMs生成基于不同种子上下文的多语言用户-聊天机器人对话，然后使用GPT-4.1进行多维性能分析。", "result": "研究发现，当前的LLMs在检测涉及同理心和推理的细微问题上表现不佳，且存在显著的跨语言性能差异。", "conclusion": "通过大规模评估策划了一个新的多语言元评估基准，并人工注释了具有细微质量判断的样本，用于评估LLMs作为开放领域对话评估者的能力。"}}
{"id": "2505.22809", "title": "First Steps Towards Overhearing LLM Agents: A Case Study With Dungeons & Dragons Gameplay", "authors": ["Andrew Zhu", "Evan Osgood", "Chris Callison-Burch"], "abstract": "Much work has been done on conversational LLM agents which directly assist human users with tasks. We present an alternative paradigm for interacting with LLM agents, which we call \"overhearing agents\". These overhearing agents do not actively participate in conversation -- instead, they \"listen in\" on human-to-human conversations and perform background tasks or provide suggestions to assist the user. In this work, we explore the overhearing agents paradigm through the lens of Dungeons & Dragons gameplay. We present an in-depth study using large multimodal audio-language models as overhearing agents to assist a Dungeon Master. We perform a human evaluation to examine the helpfulness of such agents and find that some large audio-language models have the emergent ability to perform overhearing agent tasks using implicit audio cues. Finally, we release Python libraries and our project code to support further research into the overhearing agents paradigm at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)", "comments": "8 pages, 5 figures. In submission at EMNLP 2025", "pdf_url": "https://arxiv.org/pdf/2505.22809.pdf", "abstract_url": "https://arxiv.org/abs/2505.22809", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一种名为‘偷听代理’的新型LLM代理交互范式，该代理不直接参与对话，而是通过‘监听’人类之间的对话来执行后台任务或提供建议。研究以《龙与地下城》游戏为例，探索了大型多模态音频-语言模型作为偷听代理协助游戏主持人的能力，并通过人类评估验证了其有效性。", "motivation": "解决如何通过LLM代理在不直接参与对话的情况下，通过监听人类对话来提供背景支持或建议的问题。", "method": "使用大型多模态音频-语言模型作为偷听代理，在《龙与地下城》游戏中进行深入案例研究，并通过人类评估检验代理的有用性。", "result": "研究发现，某些大型音频-语言模型具有利用隐式音频线索执行偷听代理任务的新兴能力。", "conclusion": "偷听代理范式为LLM代理的交互提供了新的可能性，特别是在需要背景支持的场景中，如游戏主持。研究还发布了Python库和项目代码，以支持未来在这一领域的研究。"}}
{"id": "2505.22753", "title": "Enhancing Lifelong Multi-Agent Path-finding by Using Artificial Potential Fields", "authors": ["Arseniy Pertzovsky", "Roni Stern", "Ariel Felner", "Roie Zivan"], "abstract": "We explore the use of Artificial Potential Fields (APFs) to solve Multi-Agent Path Finding (MAPF) and Lifelong MAPF (LMAPF) problems. In MAPF, a team of agents must move to their goal locations without collisions, whereas in LMAPF, new goals are generated upon arrival. We propose methods for incorporating APFs in a range of MAPF algorithms, including Prioritized Planning, MAPF-LNS2, and Priority Inheritance with Backtracking (PIBT). Experimental results show that using APF is not beneficial for MAPF but yields up to a 7-fold increase in overall system throughput for LMAPF.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.22753.pdf", "abstract_url": "https://arxiv.org/abs/2505.22753", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了利用人工势场（APFs）解决多智能体路径规划（MAPF）和终身多智能体路径规划（LMAPF）问题的方法。研究表明，APF对MAPF无益，但能显著提升LMAPF的系统吞吐量。", "motivation": "解决多智能体在到达目标后新目标不断生成的终身路径规划问题，以及传统路径规划中的碰撞避免问题。", "method": "将人工势场（APFs）整合到多种MAPF算法中，包括优先级规划、MAPF-LNS2和优先级继承与回溯（PIBT）。", "result": "实验结果显示，APF对MAPF无显著帮助，但在LMAPF中能使系统整体吞吐量提升高达7倍。", "conclusion": "人工势场在终身多智能体路径规划中具有显著优势，能够有效提升系统效率，但在传统多智能体路径规划中效果有限。"}}
{"id": "2505.22954", "title": "Darwin Godel Machine: Open-Ended Evolution of Self-Improving Agents", "authors": ["Jenny Zhang", "Shengran Hu", "Cong Lu", "Robert Lange", "Jeff Clune"], "abstract": "Today's AI systems have human-designed, fixed architectures and cannot autonomously and continuously improve themselves. The advance of AI could itself be automated. If done safely, that would accelerate AI development and allow us to reap its benefits much sooner. Meta-learning can automate the discovery of novel algorithms, but is limited by first-order improvements and the human design of a suitable search space. The Gödel machine proposed a theoretical alternative: a self-improving AI that repeatedly modifies itself in a provably beneficial manner. Unfortunately, proving that most changes are net beneficial is impossible in practice. We introduce the Darwin Gödel Machine (DGM), a self-improving system that iteratively modifies its own code (thereby also improving its ability to modify its own codebase) and empirically validates each change using coding benchmarks. Inspired by Darwinian evolution and open-endedness research, the DGM maintains an archive of generated coding agents. It grows the archive by sampling an agent from it and using a foundation model to create a new, interesting, version of the sampled agent. This open-ended exploration forms a growing tree of diverse, high-quality agents and allows the parallel exploration of many different paths through the search space. Empirically, the DGM automatically improves its coding capabilities (e.g., better code editing tools, long-context window management, peer-review mechanisms), increasing performance on SWE-bench from 20.0% to 50.0%, and on Polyglot from 14.2% to 30.7%. Furthermore, the DGM significantly outperforms baselines without self-improvement or open-ended exploration. All experiments were done with safety precautions (e.g., sandboxing, human oversight). The DGM is a significant step toward self-improving AI, capable of gathering its own stepping stones along paths that unfold into endless innovation.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.22954.pdf", "abstract_url": "https://arxiv.org/abs/2505.22954", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "达尔文哥德尔机（DGM）是一种自我改进的AI系统，通过迭代修改自身代码并在编码基准上验证每次更改，自动提升其编码能力。受达尔文进化和开放性研究启发，DGM维护一个生成的编码代理档案，并通过基础模型创建新版本代理来扩展档案。这种方法在搜索空间中并行探索多种路径，显著提高了编码性能。", "motivation": "当前AI系统具有人类设计的固定架构，无法自主持续地自我改进。DGM旨在通过自动化AI的进步，加速AI发展并更早地获得其好处。", "method": "DGM通过迭代修改自身代码并在编码基准上验证每次更改来改进其编码能力。它维护一个编码代理档案，并通过基础模型创建新版本代理来扩展档案，实现开放性探索。", "result": "DGM在SWE-bench上的性能从20.0%提高到50.0%，在Polyglot上从14.2%提高到30.7%，显著优于没有自我改进或开放性探索的基线。", "conclusion": "DGM是朝着自我改进AI迈出的重要一步，能够沿着展开成无尽创新的路径收集自己的垫脚石。所有实验均在安全预防措施下进行。"}}
{"id": "2505.22990", "title": "MenTeR: A fully-automated Multi-agenT workflow for end-to-end RF/Analog Circuits Netlist Design", "authors": ["Pin-Han Chen", "Yu-Sheng Lin", "Wei-Cheng Lee", "Tin-Yu Leu", "Po-Hsiang Hsu", "Anjana Dissanayake", "Sungjin Oh", "Chinq-Shiun Chiu"], "abstract": "RF/Analog design is essential for bridging digital technologies with real-world signals, ensuring the functionality and reliability of a wide range of electronic systems. However, analog design procedures are often intricate, time-consuming and reliant on expert intuition, and hinder the time and cost efficiency of circuit development. To overcome the limitations of the manual circuit design, we introduce MenTeR - a multiagent workflow integrated into an end-to-end analog design framework. By employing multiple specialized AI agents that collaboratively address different aspects of the design process, such as specification understanding, circuit optimization, and test bench validation, MenTeR reduces the dependency on frequent trial-and-error-style intervention. MenTeR not only accelerates the design cycle time but also facilitates a broader exploration of the design space, demonstrating robust capabilities in handling real-world analog systems. We believe that MenTeR lays the groundwork for future \"RF/Analog Copilots\" that can collaborate seamlessly with human designers.", "subjects": "Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET); Machine Learning (cs.LG)", "comments": "9 pages, 7 figures, accepted by IEEE ICLAD 2025", "pdf_url": "https://arxiv.org/pdf/2505.22990.pdf", "abstract_url": "https://arxiv.org/abs/2505.22990", "categories": ["Artificial Intelligence (cs.AI)", "Emerging Technologies (cs.ET)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "MenTeR是一个全自动的多代理工作流，用于端到端的RF/模拟电路网表设计，旨在通过AI代理协作减少对人工干预的依赖，加速设计周期并拓宽设计空间探索。", "motivation": "模拟设计过程复杂、耗时且依赖专家直觉，影响了电路开发的时间和成本效率。", "method": "采用多代理工作流，集成端到端模拟设计框架，通过专门化的AI代理协作处理设计过程的不同方面。", "result": "MenTeR减少了试错式干预的需求，加速了设计周期，并在处理真实世界模拟系统方面展示了强大能力。", "conclusion": "MenTeR为未来能与人类设计师无缝协作的“RF/模拟副驾驶”奠定了基础。"}}
{"id": "2505.22960", "title": "Revisiting Multi-Agent Debate as Test-Time Scaling: A Systematic Study of Conditional Effectiveness", "authors": ["Yongjin Yang", "Euiin Yi", "Jongwoo Ko", "Kimin Lee", "Zhijing Jin", "Se-Young Yun"], "abstract": "The remarkable growth in large language model (LLM) capabilities has spurred exploration into multi-agent systems, with debate frameworks emerging as a promising avenue for enhanced problem-solving. These multi-agent debate (MAD) approaches, where agents collaboratively present, critique, and refine arguments, potentially offer improved reasoning, robustness, and diverse perspectives over monolithic models. Despite prior studies leveraging MAD, a systematic understanding of its effectiveness compared to self-agent methods, particularly under varying conditions, remains elusive. This paper seeks to fill this gap by conceptualizing MAD as a test-time computational scaling technique, distinguished by collaborative refinement and diverse exploration capabilities. We conduct a comprehensive empirical investigation comparing MAD with strong self-agent test-time scaling baselines on mathematical reasoning and safety-related tasks. Our study systematically examines the influence of task difficulty, model scale, and agent diversity on MAD's performance. Key findings reveal that, for mathematical reasoning, MAD offers limited advantages over self-agent scaling but becomes more effective with increased problem difficulty and decreased model capability, while agent diversity shows little benefit. Conversely, for safety tasks, MAD's collaborative refinement can increase vulnerability, but incorporating diverse agent configurations facilitates a gradual reduction in attack success through the collaborative refinement process. We believe our findings provide critical guidance for the future development of more effective and strategically deployed MAD systems.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "Preprint, under review", "pdf_url": "https://arxiv.org/pdf/2505.22960.pdf", "abstract_url": "https://arxiv.org/abs/2505.22960", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过将多智能体辩论（MAD）概念化为测试时计算扩展技术，系统地研究了其在数学推理和安全相关任务中的条件有效性。研究发现，MAD在数学推理任务中相对于单智能体方法的优势有限，但在问题难度增加和模型能力降低时更为有效；而在安全任务中，MAD的协作细化可能增加脆弱性，但通过引入多样化的智能体配置可以逐步降低攻击成功率。", "motivation": "尽管多智能体辩论（MAD）框架在增强问题解决能力方面显示出潜力，但其与单智能体方法相比的有效性，尤其是在不同条件下的表现，尚缺乏系统理解。本研究旨在填补这一空白。", "method": "本研究将MAD概念化为一种测试时计算扩展技术，并通过在数学推理和安全相关任务上与强单智能体测试时扩展基线进行比较，进行了全面的实证调查。研究系统地考察了任务难度、模型规模和智能体多样性对MAD性能的影响。", "result": "研究发现，在数学推理任务中，MAD相对于单智能体扩展的优势有限，但随着问题难度的增加和模型能力的降低，MAD变得更加有效，而智能体多样性显示出较小的益处。在安全任务中，MAD的协作细化可能增加脆弱性，但通过引入多样化的智能体配置可以逐步降低攻击成功率。", "conclusion": "本研究的结果为未来开发更有效和战略部署的MAD系统提供了关键指导。"}}
{"id": "2505.23075", "title": "Second Opinion Matters: Towards Adaptive Clinical AI via the Consensus of Expert Model Ensemble", "authors": ["Amit Kumthekar", "Zion Tilley", "Henry Duong", "Bhargav Patel", "Michael Magnoli", "Ahmed Omar", "Ahmed Nasser", "Chaitanya Gharpure", "Yevgen Reztzov"], "abstract": "Despite the growing clinical adoption of large language models (LLMs), current approaches heavily rely on single model architectures. To overcome risks of obsolescence and rigid dependence on single model systems, we present a novel framework, termed the Consensus Mechanism. Mimicking clinical triage and multidisciplinary clinical decision-making, the Consensus Mechanism implements an ensemble of specialized medical expert agents enabling improved clinical decision making while maintaining robust adaptability. This architecture enables the Consensus Mechanism to be optimized for cost, latency, or performance, purely based on its interior model configuration.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "23 pages, 11 figures", "pdf_url": "https://arxiv.org/pdf/2505.23075.pdf", "abstract_url": "https://arxiv.org/abs/2505.23075", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为共识机制的新框架，通过专家模型集合的共识来改进临床决策，同时保持强大的适应性。", "motivation": "克服当前大型语言模型在临床应用中依赖单一模型架构带来的过时风险和刚性依赖问题。", "method": "模仿临床分诊和多学科临床决策，实现了一个专门医疗专家代理的集合。", "result": "共识机制能够根据其内部模型配置，针对成本、延迟或性能进行优化。", "conclusion": "共识机制框架为临床AI提供了一种灵活、可优化的解决方案，有望提高临床决策的质量和适应性。"}}
{"id": "2505.22942", "title": "WorkForceAgent-R1: Incentivizing Reasoning Capability in LLM-based Web Agents via Reinforcement Learning", "authors": ["Yuchen Zhuang", "Di Jin", "Jiaao Chen", "Wenqi Shi", "Hanrui Wang", "Chao Zhang"], "abstract": "Large language models (LLMs)-empowered web agents enables automating complex, real-time web navigation tasks in enterprise environments. However, existing web agents relying on supervised fine-tuning (SFT) often struggle with generalization and robustness due to insufficient reasoning capabilities when handling the inherently dynamic nature of web interactions. In this study, we introduce WorkForceAgent-R1, an LLM-based web agent trained using a rule-based R1-style reinforcement learning framework designed explicitly to enhance single-step reasoning and planning for business-oriented web navigation tasks. We employ a structured reward function that evaluates both adherence to output formats and correctness of actions, enabling WorkForceAgent-R1 to implicitly learn robust intermediate reasoning without explicit annotations or extensive expert demonstrations. Extensive experiments on the WorkArena benchmark demonstrate that WorkForceAgent-R1 substantially outperforms SFT baselines by 10.26-16.59%, achieving competitive performance relative to proprietary LLM-based agents (gpt-4o) in workplace-oriented web navigation tasks.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "Work in Progress", "pdf_url": "https://arxiv.org/pdf/2505.22942.pdf", "abstract_url": "https://arxiv.org/abs/2505.22942", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "WorkForceAgent-R1是一种基于大型语言模型（LLM）的网络代理，通过强化学习框架增强单步推理和规划能力，用于企业环境中的网络导航任务。", "motivation": "现有的基于监督微调（SFT）的网络代理在处理动态网络交互时，由于推理能力不足，往往难以实现良好的泛化和鲁棒性。", "method": "采用基于规则的R1风格强化学习框架，通过结构化奖励函数评估输出格式的遵循和动作的正确性，隐式学习稳健的中间推理。", "result": "在WorkArena基准测试中，WorkForceAgent-R1显著优于SFT基线10.26-16.59%，与专有LLM代理（gpt-4o）在工作导向的网络导航任务中表现相当。", "conclusion": "WorkForceAgent-R1通过强化学习有效提升了LLM代理在复杂网络导航任务中的推理能力和性能，展示了在企业环境中的潜在应用价值。"}}
{"id": "2505.22961", "title": "ToMAP: Training Opponent-Aware LLM Persuaders with Theory of Mind", "authors": ["Peixuan Han", "Zijia Liu", "Jiaxuan You"], "abstract": "Large language models (LLMs) have shown promising potential in persuasion, but existing works on training LLM persuaders are still preliminary. Notably, while humans are skilled in modeling their opponent's thoughts and opinions proactively and dynamically, current LLMs struggle with such Theory of Mind (ToM) reasoning, resulting in limited diversity and opponent awareness. To address this limitation, we introduce Theory of Mind Augmented Persuader (ToMAP), a novel approach for building more flexible persuader agents by incorporating two theory of mind modules that enhance the persuader's awareness and analysis of the opponent's mental state. Specifically, we begin by prompting the persuader to consider possible objections to the target central claim, and then use a text encoder paired with a trained MLP classifier to predict the opponent's current stance on these counterclaims. Our carefully designed reinforcement learning schema enables the persuader learns how to analyze opponent-related information and utilize it to generate more effective arguments. Experiments show that the ToMAP persuader, while containing only 3B parameters, outperforms much larger baselines, like GPT-4o, with a relative gain of 39.4% across multiple persuadee models and diverse corpora. Notably, ToMAP exhibits complex reasoning chains and reduced repetition during training, which leads to more diverse and effective arguments. The opponent-aware feature of ToMAP also makes it suitable for long conversations and enables it to employ more logical and opponent-aware strategies. These results underscore our method's effectiveness and highlight its potential for developing more persuasive language agents. Code is available at:", "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.22961.pdf", "abstract_url": "https://arxiv.org/abs/2505.22961", "categories": ["Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了ToMAP，一种通过整合两个心智理论模块来增强说服者代理对对手心理状态意识和分析的新方法，旨在解决当前大型语言模型在说服任务中缺乏多样性和对手意识的问题。", "motivation": "当前的大型语言模型在说服任务中缺乏对人类对手心理状态的动态建模能力，导致生成的论证缺乏多样性和对手意识。", "method": "ToMAP通过引入两个心智理论模块，首先促使说服者考虑目标中心主张的可能反对意见，然后使用文本编码器和训练好的MLP分类器预测对手对这些反对意见的当前立场，最后通过精心设计的强化学习模式学习如何分析和利用对手相关信息生成更有效的论证。", "result": "实验显示，仅含3B参数的ToMAP说服者在多个说服模型和多样语料库上的表现优于更大的基线模型（如GPT-4o），相对增益达到39.4%。此外，ToMAP展现出复杂的推理链和训练中减少的重复，生成更多样化和有效的论证。", "conclusion": "ToMAP的对手意识特性使其适合长对话，并能采用更具逻辑性和对手意识的策略，这些结果证明了该方法的有效性，并突显了其在开发更具说服力的语言代理方面的潜力。"}}
{"id": "2505.23153", "title": "Conceptual Framework Toward Embodied Collective Adaptive Intelligence", "authors": ["Fan Wang", "Shaoshan Liu"], "abstract": "Collective Adaptive Intelligence (CAI) represent a transformative approach in artificial intelligence, wherein numerous autonomous agents collaborate, adapt, and self-organize to navigate complex, dynamic environments. This paradigm is particularly impactful in embodied AI applications, where adaptability and resilience are paramount. By enabling systems to reconfigure themselves in response to unforeseen challenges, CAI facilitate robust performance in real-world scenarios. This article introduces a conceptual framework for designing and analyzing CAI. It delineates key attributes including task generalization, resilience, scalability, and self-assembly, aiming to bridge theoretical foundations with practical methodologies for engineering adaptive, emergent intelligence. By providing a structured foundation for understanding and implementing CAI, this work seeks to guide researchers and practitioners in developing more resilient, scalable, and adaptable AI systems across various domains.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23153.pdf", "abstract_url": "https://arxiv.org/abs/2505.23153", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "集体适应性智能（CAI）代表了一种人工智能的变革性方法，其中多个自主代理协作、适应和自我组织以导航复杂、动态的环境。本文介绍了一个设计和分析CAI的概念框架，旨在桥接理论基础与工程适应性、涌现智能的实用方法。", "motivation": "解决在复杂动态环境中，如何设计和实现能够协作、适应和自我组织的AI系统，以提高其在现实世界应用中的适应性和韧性。", "method": "提出了一个概念框架，明确了任务泛化、韧性、可扩展性和自组装等关键属性，旨在为理解和实施CAI提供结构化基础。", "result": "通过这一框架，研究人员和从业者可以开发出更韧性、可扩展和适应性强的AI系统，适用于各种领域。", "conclusion": "本文的工作为集体适应性智能的研究和实践提供了指导，旨在促进更韧性、可扩展和适应性强的AI系统的发展。"}}
{"id": "2505.23399", "title": "GAM-Agent: Game-Theoretic and Uncertainty-Aware Collaboration for Complex Visual Reasoning", "authors": ["Jusheng Zhang", "Yijia Fan", "Wenjun Lin", "Ruiqi Chen", "Haoyi Jiang", "Wenhao Chai", "Jian Wang", "Keze Wang"], "abstract": "We propose GAM-Agent, a game-theoretic multi-agent framework for enhancing vision-language reasoning. Unlike prior single-agent or monolithic models, GAM-Agent formulates the reasoning process as a non-zero-sum game between base agents--each specializing in visual perception subtasks--and a critical agent that verifies logic consistency and factual correctness. Agents communicate via structured claims, evidence, and uncertainty estimates. The framework introduces an uncertainty-aware controller to dynamically adjust agent collaboration, triggering multi-round debates when disagreement or ambiguity is detected. This process yields more robust and interpretable predictions. Experiments on four challenging benchmarks--MMMU, MMBench, MVBench, and V*Bench--demonstrate that GAM-Agent significantly improves performance across various VLM backbones. Notably, GAM-Agent boosts the accuracy of small-to-mid scale models (e.g., Qwen2.5-VL-7B, InternVL3-14B) by 5--6\\%, and still enhances strong models like GPT-4o by up to 2--3\\%. Our approach is modular, scalable, and generalizable, offering a path toward reliable and explainable multi-agent multimodal reasoning.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23399.pdf", "abstract_url": "https://arxiv.org/abs/2505.23399", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "GAM-Agent是一个基于博弈论的多智能体框架，旨在增强视觉语言推理能力。通过将推理过程建模为非零和游戏，结合不确定性感知控制器动态调整智能体协作，显著提升了多种视觉语言模型在复杂任务上的性能。", "motivation": "解决现有视觉语言推理模型中单智能体或整体模型在处理复杂视觉推理任务时的局限性，提高推理的鲁棒性和可解释性。", "method": "采用博弈论多智能体框架，包括专门处理视觉感知子任务的基础智能体和一个验证逻辑一致性和事实正确性的关键智能体，通过结构化声明、证据和不确定性估计进行通信，并引入不确定性感知控制器动态调整协作。", "result": "在MMMU、MMBench、MVBench和V*Bench四个挑战性基准测试中，GAM-Agent显著提升了各种VLM骨干网络的性能，特别是中小规模模型的准确率提高了5-6%，强模型如GPT-4o也提升了2-3%。", "conclusion": "GAM-Agent提供了一种模块化、可扩展且通用的方法，为实现可靠和可解释的多智能体多模态推理开辟了道路。"}}
{"id": "2505.23436", "title": "Emergent Risk Awareness in Rational Agents under Resource Constraints", "authors": ["Daniel Jarne Ornia", "Nicholas Bishop", "Joel Dyer", "Wei-Chen Lee", "Ani Calinescu", "Doyne Farme", "Michael Wooldridge"], "abstract": "Advanced reasoning models with agentic capabilities (AI agents) are deployed to interact with humans and to solve sequential decision-making problems under (approximate) utility functions and internal models. When such problems have resource or failure constraints where action sequences may be forcibly terminated once resources are exhausted, agents face implicit trade-offs that reshape their utility-driven (rational) behaviour. Additionally, since these agents are typically commissioned by a human principal to act on their behalf, asymmetries in constraint exposure can give rise to previously unanticipated misalignment between human objectives and agent incentives. We formalise this setting through a survival bandit framework, provide theoretical and empirical results that quantify the impact of survival-driven preference shifts, identify conditions under which misalignment emerges and propose mechanisms to mitigate the emergence of risk-seeking or risk-averse behaviours. As a result, this work aims to increase understanding and interpretability of emergent behaviours of AI agents operating under such survival pressure, and offer guidelines for safely deploying such AI systems in critical resource-limited environments.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23436.pdf", "abstract_url": "https://arxiv.org/abs/2505.23436", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文探讨了在资源约束下，具有理性行为能力的AI代理（AI agents）如何在生存压力下表现出风险意识的变化。通过生存多臂老虎机框架（survival bandit framework），作者量化了生存驱动偏好转变的影响，识别了导致人类目标与代理激励不一致的条件，并提出了缓解风险寻求或风险规避行为出现的机制。", "motivation": "解决在资源或失败约束下，AI代理与人类目标之间可能出现的不一致问题，特别是在代理被迫在资源耗尽时终止行动序列的情况下。", "method": "使用生存多臂老虎机框架来形式化这一设置，提供理论和实证结果，量化生存驱动偏好转变的影响，并提出缓解机制。", "result": "识别了导致人类目标与代理激励不一致的条件，并提出了有效的机制来缓解风险寻求或风险规避行为的出现。", "conclusion": "这项工作旨在增加对在生存压力下操作的AI代理 emergent行为的理解和可解释性，并为在关键资源有限环境中安全部署此类AI系统提供指导。"}}
{"id": "2505.23474", "title": "Socratic-PRMBench: Benchmarking Process Reward Models with Systematic Reasoning Patterns", "authors": ["Xiang Li", "Haiyang Yu", "Xinghua Zhang", "Ziyang Huang", "Shizhu He", "Kang Liu", "Jun Zhao", "Fei Huang", "Yongbin Li"], "abstract": "Process Reward Models (PRMs) are crucial in complex reasoning and problem-solving tasks (e.g., LLM agents with long-horizon decision-making) by verifying the correctness of each intermediate reasoning step. In real-world scenarios, LLMs may apply various reasoning patterns (e.g., decomposition) to solve a problem, potentially suffering from errors under various reasoning patterns. Therefore, PRMs are required to identify errors under various reasoning patterns during the reasoning process. However, existing benchmarks mainly focus on evaluating PRMs with stepwise correctness, ignoring a systematic evaluation of PRMs under various reasoning patterns. To mitigate this gap, we introduce Socratic-PRMBench, a new benchmark to evaluate PRMs systematically under six reasoning patterns, including Transformation, Decomposition, Regather, Deduction, Verification, and Integration. Socratic-PRMBench}comprises 2995 reasoning paths with flaws within the aforementioned six reasoning patterns. Through our experiments on both PRMs and LLMs prompted as critic models, we identify notable deficiencies in existing PRMs. These observations underscore the significant weakness of current PRMs in conducting evaluations on reasoning steps under various reasoning patterns. We hope Socratic-PRMBench can serve as a comprehensive testbed for systematic evaluation of PRMs under diverse reasoning patterns and pave the way for future development of PRMs.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23474.pdf", "abstract_url": "https://arxiv.org/abs/2505.23474", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了Socratic-PRMBench，一个新的基准测试，用于系统评估过程奖励模型（PRMs）在六种推理模式下的表现，揭示了现有PRMs在多样化推理模式下的显著不足。", "motivation": "解决现有基准测试主要关注逐步正确性评估，而忽视了对PRMs在各种推理模式下系统评估的问题。", "method": "引入Socratic-PRMBench基准测试，包含2995条在六种推理模式（如转换、分解、重新聚集、演绎、验证和整合）中存在缺陷的推理路径。", "result": "实验发现，现有的PRMs和作为批评模型的LLMs在多样化推理模式下的评估存在显著缺陷。", "conclusion": "Socratic-PRMBench可作为PRMs在多样化推理模式下系统评估的综合测试平台，为PRMs的未来发展铺平道路。"}}
{"id": "2505.23559", "title": "SafeScientist: Toward Risk-Aware Scientific Discoveries by LLM Agents", "authors": ["Kunlun Zhu", "Jiaxun Zhang", "Ziheng Qi", "Nuoxing Shang", "Zijia Liu", "Peixuan Han", "Yue Su", "Haofei Yu", "Jiaxuan You"], "abstract": "Recent advancements in large language model (LLM) agents have significantly accelerated scientific discovery automation, yet concurrently raised critical ethical and safety concerns. To systematically address these challenges, we introduce \\textbf{SafeScientist}, an innovative AI scientist framework explicitly designed to enhance safety and ethical responsibility in AI-driven scientific exploration. SafeScientist proactively refuses ethically inappropriate or high-risk tasks and rigorously emphasizes safety throughout the research process. To achieve comprehensive safety oversight, we integrate multiple defensive mechanisms, including prompt monitoring, agent-collaboration monitoring, tool-use monitoring, and an ethical reviewer component. Complementing SafeScientist, we propose \\textbf{SciSafetyBench}, a novel benchmark specifically designed to evaluate AI safety in scientific contexts, comprising 240 high-risk scientific tasks across 6 domains, alongside 30 specially designed scientific tools and 120 tool-related risk tasks. Extensive experiments demonstrate that SafeScientist significantly improves safety performance by 35\\% compared to traditional AI scientist frameworks, without compromising scientific output quality. Additionally, we rigorously validate the robustness of our safety pipeline against diverse adversarial attack methods, further confirming the effectiveness of our integrated approach. The code and data will be available at", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23559.pdf", "abstract_url": "https://arxiv.org/abs/2505.23559", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "SafeScientist是一个创新的AI科学家框架，旨在提高AI驱动科学探索的安全性和伦理责任，通过集成多种防御机制显著提升安全性能。", "motivation": "解决大型语言模型(LLM)代理在加速科学发现自动化过程中引发的伦理和安全问题。", "method": "集成提示监控、代理协作监控、工具使用监控和伦理审查组件等多重防御机制。", "result": "SafeScientist相比传统AI科学家框架安全性能提升35%，且不损害科学输出质量。", "conclusion": "SafeScientist和SciSafetyBench为AI在科学领域的安全应用提供了有效框架和评估标准。"}}
{"id": "2505.23518", "title": "TRAP: Targeted Redirecting of Agentic Preferences", "authors": ["Hangoo Kang", "Jehyeok Yeon", "Gagandeep Singh"], "abstract": "Autonomous agentic AI systems powered by vision-language models (VLMs) are rapidly advancing toward real-world deployment, yet their cross-modal reasoning capabilities introduce new attack surfaces for adversarial manipulation that exploit semantic reasoning across modalities. Existing adversarial attacks typically rely on visible pixel perturbations or require privileged model or environment access, making them impractical for stealthy, real-world exploitation. We introduce TRAP, a generative adversarial framework that manipulates the agent's decision-making using diffusion-based semantic injections. Our method combines negative prompt-based degradation with positive semantic optimization, guided by a Siamese semantic network and layout-aware spatial masking. Without requiring access to model internals, TRAP produces visually natural images yet induces consistent selection biases in agentic AI systems. We evaluate TRAP on the Microsoft Common Objects in Context (COCO) dataset, building multi-candidate decision scenarios. Across these scenarios, TRAP achieves a 100% attack success rate on leading models, including LLaVA-34B, Gemma3, and Mistral-3.1, significantly outperforming baselines such as SPSA, Bandit, and standard diffusion approaches. These results expose a critical vulnerability: Autonomous agents can be consistently misled through human-imperceptible cross-modal manipulations. These findings highlight the need for defense strategies beyond pixel-level robustness to address semantic vulnerabilities in cross-modal decision-making.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23518.pdf", "abstract_url": "https://arxiv.org/abs/2505.23518", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了TRAP，一种生成对抗框架，通过扩散基础的语义注入操纵自主代理AI系统的决策。该方法结合了负面提示基础的退化和正面语义优化，无需访问模型内部，即可产生视觉自然的图像，同时在代理AI系统中诱导一致的选择偏差。在COCO数据集上的评估显示，TRAP对领先模型实现了100%的攻击成功率，揭示了跨模态决策中的语义脆弱性。", "motivation": "随着基于视觉语言模型（VLMs）的自主代理AI系统快速向现实世界部署，其跨模态推理能力引入了新的对抗操纵攻击面。现有的对抗攻击通常依赖于可见的像素扰动或需要特权模型或环境访问，这使得它们在隐蔽的现实世界利用中不切实际。", "method": "TRAP方法结合了负面提示基础的退化与正面语义优化，由Siamese语义网络和布局感知的空间掩码指导。无需访问模型内部，即可生成视觉自然的图像，同时诱导代理AI系统的选择偏差。", "result": "在COCO数据集上的多候选决策场景中，TRAP对包括LLaVA-34B、Gemma3和Mistral-3.1在内的领先模型实现了100%的攻击成功率，显著优于SPSA、Bandit和标准扩散方法等基线。", "conclusion": "这些结果揭示了自主代理AI系统可以通过人类难以察觉的跨模态操纵被一致误导的关键脆弱性，强调了需要超越像素级鲁棒性的防御策略，以解决跨模态决策中的语义脆弱性。"}}
{"id": "2505.22993", "title": "Verify-in-the-Graph: Entity Disambiguation Enhancement for Complex Claim Verification with Interactive Graph Representation", "authors": ["Hoang Pham", "Thanh-Do Nguyen", "Khac-Hoai Nam Bui"], "abstract": "Claim verification is a long-standing and challenging task that demands not only high accuracy but also explainability of the verification process. This task becomes an emerging research issue in the era of large language models (LLMs) since real-world claims are often complex, featuring intricate semantic structures or obfuscated entities. Traditional approaches typically address this by decomposing claims into sub-claims and querying a knowledge base to resolve hidden or ambiguous entities. However, the absence of effective disambiguation strategies for these entities can compromise the entire verification process. To address these challenges, we propose Verify-in-the-Graph (VeGraph), a novel framework leveraging the reasoning and comprehension abilities of LLM agents. VeGraph operates in three phases: (1) Graph Representation - an input claim is decomposed into structured triplets, forming a graph-based representation that integrates both structured and unstructured information; (2) Entity Disambiguation -VeGraph iteratively interacts with the knowledge base to resolve ambiguous entities within the graph for deeper sub-claim verification; and (3) Verification - remaining triplets are verified to complete the fact-checking process. Experiments using Meta-Llama-3-70B (instruct version) show that VeGraph achieves competitive performance compared to baselines on two benchmarks HoVer and FEVEROUS, effectively addressing claim verification challenges. Our source code and data are available for further exploitation.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Databases (cs.DB); Information Retrieval (cs.IR)", "comments": "Published at NAACL 2025 Main Conference", "pdf_url": "https://arxiv.org/pdf/2505.22993.pdf", "abstract_url": "https://arxiv.org/abs/2505.22993", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Databases (cs.DB)", "Information Retrieval (cs.IR)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为Verify-in-the-Graph（VeGraph）的新框架，旨在通过利用大型语言模型（LLMs）的推理和理解能力，解决复杂声明验证中的实体消歧问题。VeGraph通过图表示、实体消歧和验证三个阶段，有效地提高了声明验证的准确性和可解释性。", "motivation": "在大型语言模型（LLMs）时代，现实世界中的声明往往复杂，具有复杂的语义结构或模糊的实体，这使得声明验证成为一个具有挑战性的任务。传统方法通过将声明分解为子声明并查询知识库来解决隐藏或模糊的实体，但缺乏有效的消歧策略可能会影响整个验证过程。", "method": "VeGraph框架分为三个阶段：(1) 图表示 - 将输入声明分解为结构化的三元组，形成结合结构化和非结构化信息的图表示；(2) 实体消歧 - VeGraph与知识库迭代交互，解决图中的模糊实体以进行更深入的子声明验证；(3) 验证 - 验证剩余的三元组以完成事实检查过程。", "result": "使用Meta-Llama-3-70B（指令版本）进行的实验表明，VeGraph在两个基准测试HoVer和FEVEROUS上实现了与基线相比具有竞争力的性能，有效解决了声明验证的挑战。", "conclusion": "VeGraph通过其创新的图表示和实体消歧策略，为复杂声明验证提供了一种有效的解决方案，不仅提高了验证的准确性，还增强了验证过程的可解释性。"}}
{"id": "2505.23006", "title": "A Practical Approach for Building Production-Grade Conversational Agents with Workflow Graphs", "authors": ["Chiwan Park", "Wonjun Jang", "Daeryong Kim", "Aelim Ahn", "Kichang Yang", "Woosung Hwang", "Jihyeon Roh", "Hyerin Park", "Hyosun Wang", "Min Seok Kim", "Jihoon Kang"], "abstract": "The advancement of Large Language Models (LLMs) has led to significant improvements in various service domains, including search, recommendation, and chatbot applications. However, applying state-of-the-art (SOTA) research to industrial settings presents challenges, as it requires maintaining flexible conversational abilities while also strictly complying with service-specific constraints. This can be seen as two conflicting requirements due to the probabilistic nature of LLMs. In this paper, we propose our approach to addressing this challenge and detail the strategies we employed to overcome their inherent limitations in real-world applications. We conduct a practical case study of a conversational agent designed for the e-commerce domain, detailing our implementation workflow and optimizations. Our findings provide insights into bridging the gap between academic research and real-world application, introducing a framework for developing scalable, controllable, and reliable AI-driven agents.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "Accepted to ACL 2025 Industry Track. 12 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2505.23006.pdf", "abstract_url": "https://arxiv.org/abs/2505.23006", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种通过工作流图构建生产级对话代理的实用方法，旨在解决将最先进的大型语言模型（LLMs）应用于工业环境时遇到的挑战，特别是在保持灵活对话能力的同时严格遵守服务特定约束的需求。", "motivation": "大型语言模型（LLMs）的进步虽然在搜索、推荐和聊天机器人等多个服务领域带来了显著改进，但在工业应用中，如何平衡灵活的对话能力和严格遵守服务特定约束成为了一个挑战。", "method": "作者提出了一种方法，通过工作流图来构建对话代理，详细介绍了在电子商务领域的实际案例研究中采用的实施工作流程和优化策略。", "result": "研究结果为如何弥合学术研究与实际应用之间的差距提供了见解，并介绍了一个用于开发可扩展、可控且可靠的AI驱动代理的框架。", "conclusion": "本文的发现和提出的框架为开发既灵活又严格遵守服务约束的生产级对话代理提供了实用的方法和策略，有助于推动AI技术在工业环境中的更广泛应用。"}}
{"id": "2505.23052", "title": "Query Routing for Retrieval-Augmented Language Models", "authors": ["Jiarui Zhang", "Xiangyu Liu", "Yong Hu", "Chaoyue Niu", "Fan Wu", "Guihai Chen"], "abstract": "Retrieval-Augmented Generation (RAG) significantly improves the performance of Large Language Models (LLMs) on knowledge-intensive tasks. However, varying response quality across LLMs under RAG necessitates intelligent routing mechanisms, which select the most suitable model for each query from multiple retrieval-augmented LLMs via a dedicated router model. We observe that external documents dynamically affect LLMs' ability to answer queries, while existing routing methods, which rely on static parametric knowledge representations, exhibit suboptimal performance in RAG scenarios. To address this, we formally define the new retrieval-augmented LLM routing problem, incorporating the influence of retrieved documents into the routing framework. We propose RAGRouter, a RAG-aware routing design, which leverages document embeddings and RAG capability embeddings with contrastive learning to capture knowledge representation shifts and enable informed routing decisions. Extensive experiments on diverse knowledge-intensive tasks and retrieval settings show that RAGRouter outperforms the best individual LLM by 3.61% on average and existing routing methods by 3.29%-9.33%. With an extended score-threshold-based mechanism, it also achieves strong performance-efficiency trade-offs under low-latency constraints.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23052.pdf", "abstract_url": "https://arxiv.org/abs/2505.23052", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了RAGRouter，一种针对检索增强生成（RAG）场景下的智能路由机制，旨在通过结合文档嵌入和RAG能力嵌入，优化大型语言模型（LLMs）在知识密集型任务中的响应质量。", "motivation": "解决在检索增强生成（RAG）场景下，现有路由方法依赖静态参数知识表示，无法适应动态检索文档对LLMs回答能力影响的问题。", "method": "提出RAGRouter，利用文档嵌入和RAG能力嵌入，通过对比学习捕捉知识表示的变化，实现智能路由决策。", "result": "在多种知识密集型任务和检索设置下的广泛实验表明，RAGRouter平均比最佳单个LLM性能提升3.61%，比现有路由方法提升3.29%-9.33%。", "conclusion": "RAGRouter不仅提高了响应质量，还在低延迟约束下实现了性能与效率的良好平衡，为RAG场景下的模型路由提供了有效解决方案。"}}
{"id": "2505.23596", "title": "MAPLE: A Mobile Assistant with Persistent Finite State Machines for Recovery Reasoning", "authors": ["Linqiang Guo", "Wei Liu", "Yi Wen Heng", "Tse-Hsun", "Chen", "Yang Wang"], "abstract": "Mobile GUI agents aim to autonomously complete user-instructed tasks across mobile apps. Recent advances in Multimodal Large Language Models (MLLMs) enable these agents to interpret UI screens, identify actionable elements, and perform interactions such as tapping or typing. However, existing agents remain reactive: they reason only over the current screen and lack a structured model of app navigation flow, limiting their ability to understand context, detect unexpected outcomes, and recover from errors. We present MAPLE, a state-aware multi-agent framework that abstracts app interactions as a Finite State Machine (FSM). We computationally model each UI screen as a discrete state and user actions as transitions, allowing the FSM to provide a structured representation of the app execution. MAPLE consists of specialized agents responsible for four phases of task execution: planning, execution, verification, error recovery, and knowledge retention. These agents collaborate to dynamically construct FSMs in real time based on perception data extracted from the UI screen, allowing the GUI agents to track navigation progress and flow, validate action outcomes through pre- and post-conditions of the states, and recover from errors by rolling back to previously stable states. Our evaluation results on two challenging cross-app benchmarks, Mobile-Eval-E and SPA-Bench, show that MAPLE outperforms the state-of-the-art baseline, improving task success rate by up to 12%, recovery success by 13.8%, and action accuracy by 6.5%. Our results highlight the importance of structured state modeling in guiding mobile GUI agents during task execution. Moreover, our FSM representation can be integrated into future GUI agent architectures as a lightweight, model-agnostic memory layer to support structured planning, execution verification, and error recovery.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23596.pdf", "abstract_url": "https://arxiv.org/abs/2505.23596", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "MAPLE是一个基于有限状态机（FSM）的移动助手框架，旨在通过结构化模型提升移动GUI代理的任务执行、错误恢复和知识保留能力。", "motivation": "现有的移动GUI代理缺乏对应用导航流程的结构化理解，限制了它们在理解上下文、检测意外结果和从错误中恢复的能力。", "method": "MAPLE通过将每个UI屏幕建模为离散状态，用户动作为转换，构建了一个FSM。它包含规划、执行、验证、错误恢复和知识保留四个阶段的专门代理。", "result": "在Mobile-Eval-E和SPA-Bench两个跨应用基准测试中，MAPLE的表现优于现有技术基线，任务成功率提高了12%，恢复成功率提高了13.8%，动作准确率提高了6.5%。", "conclusion": "结构化状态建模在指导移动GUI代理任务执行中起着重要作用，FSM表示可以作为轻量级、模型无关的内存层集成到未来的GUI代理架构中。"}}
{"id": "2505.23686", "title": "ROTATE: Regret-driven Open-ended Training for Ad Hoc Teamwork", "authors": ["Caroline Wang", "Arrasy Rahman", "Jiaxun Cui", "Yoonchang Sung", "Peter Stone"], "abstract": "Developing AI agents capable of collaborating with previously unseen partners is a fundamental generalization challenge in multi-agent learning, known as Ad Hoc Teamwork (AHT). Existing AHT approaches typically adopt a two-stage pipeline, where first, a fixed population of teammates is generated with the idea that they should be representative of the teammates that will be seen at deployment time, and second, an AHT agent is trained to collaborate well with agents in the population. To date, the research community has focused on designing separate algorithms for each stage. This separation has led to algorithms that generate teammate pools with limited coverage of possible behaviors, and that ignore whether the generated teammates are easy to learn from for the AHT agent. Furthermore, algorithms for training AHT agents typically treat the set of training teammates as static, thus attempting to generalize to previously unseen partner agents without assuming any control over the distribution of training teammates. In this paper, we present a unified framework for AHT by reformulating the problem as an open-ended learning process between an ad hoc agent and an adversarial teammate generator. We introduce ROTATE, a regret-driven, open-ended training algorithm that alternates between improving the AHT agent and generating teammates that probe its deficiencies. Extensive experiments across diverse AHT environments demonstrate that ROTATE significantly outperforms baselines at generalizing to an unseen set of evaluation teammates, thus establishing a new standard for robust and generalizable teamwork.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23686.pdf", "abstract_url": "https://arxiv.org/abs/2505.23686", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了ROTATE，一种用于Ad Hoc Teamwork（AHT）的开放式训练算法，旨在通过对抗性队友生成和AHT代理的交替改进，提高与未见队友的协作能力。", "motivation": "解决多智能体学习中与未见队友协作的泛化挑战，现有方法在队友生成和AHT代理训练上分离，导致队友行为覆盖有限且忽视训练队友的易学性。", "method": "提出一个统一框架，将AHT问题重新定义为AHT代理与对抗性队友生成器之间的开放式学习过程，引入ROTATE算法交替改进AHT代理和生成探测其缺陷的队友。", "result": "在多种AHT环境中的广泛实验表明，ROTATE在泛化到未见评估队友方面显著优于基线方法，为团队合作的鲁棒性和泛化性设立了新标准。", "conclusion": "ROTATE通过开放式学习过程有效提高了AHT代理与未见队友的协作能力，为AHT领域的研究提供了新的方向和标准。"}}
{"id": "2505.23695", "title": "Data-to-Dashboard: Multi-Agent LLM Framework for Insightful Visualization in Enterprise Analytics", "authors": ["Ran Zhang", "Mohannad Elhamod"], "abstract": "The rapid advancement of LLMs has led to the creation of diverse agentic systems in data analysis, utilizing LLMs' capabilities to improve insight generation and visualization. In this paper, we present an agentic system that automates the data-to-dashboard pipeline through modular LLM agents capable of domain detection, concept extraction, multi-perspective analysis generation, and iterative self-reflection. Unlike existing chart QA systems, our framework simulates the analytical reasoning process of business analysts by retrieving domain-relevant knowledge and adapting to diverse datasets without relying on closed ontologies or question templates.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23695.pdf", "abstract_url": "https://arxiv.org/abs/2505.23695", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了一个基于多代理LLM框架的系统，旨在自动化数据到仪表板的流程，通过模块化LLM代理实现领域检测、概念提取、多视角分析生成和迭代自省，模拟业务分析师的推理过程。", "motivation": "解决在数据分析中利用LLM能力提升洞察生成和可视化的问题，特别是在不依赖封闭本体论或问题模板的情况下适应多样化数据集。", "method": "采用多代理LLM框架，包括领域检测、概念提取、多视角分析生成和迭代自省等模块化代理。", "result": "开发了一个能够模拟业务分析师推理过程的系统，能够检索领域相关知识并适应多样化数据集。", "conclusion": "该框架为企业在数据分析中提供了更高效的洞察生成和可视化方法，展示了LLM在自动化分析流程中的潜力。"}}
{"id": "2505.22673", "title": "Physiology-Informed Generative Multi-Task Network for Contrast-Free CT Perfusion", "authors": ["Wasif Khan", "Kyle B. See", "Simon Kato", "Ziqian Huang", "Amy Lazarte", "Kyle Douglas", "Xiangyang Lou", "Teng J. Peng", "Dhanashree Rajderkar", "John Rees", "Pina Sanelli", "Amita Singh", "Ibrahim Tuna", "Christina A. Wilson", "Ruogu Fang"], "abstract": "Perfusion imaging is extensively utilized to assess hemodynamic status and tissue perfusion in various organs. Computed tomography perfusion (CTP) imaging plays a key role in the early assessment and planning of stroke treatment. While CTP provides essential perfusion parameters to identify abnormal blood flow in the brain, the use of contrast agents in CTP can lead to allergic reactions and adverse side effects, along with costing USD 4.9 billion worldwide in 2022. To address these challenges, we propose a novel deep learning framework called Multitask Automated Generation of Intermodal CT perfusion maps (MAGIC). This framework combines generative artificial intelligence and physiological information to map non-contrast computed tomography (CT) imaging to multiple contrast-free CTP imaging maps. We demonstrate enhanced image fidelity by incorporating physiological characteristics into the loss terms. Our network was trained and validated using CT image data from patients referred for stroke at UF Health and demonstrated robustness to abnormalities in brain perfusion activity. A double-blinded study was conducted involving seven experienced neuroradiologists and vascular neurologists. This study validated MAGIC's visual quality and diagnostic accuracy showing favorable performance compared to clinical perfusion imaging with intravenous contrast injection. Overall, MAGIC holds great promise in revolutionizing healthcare by offering contrast-free, cost-effective, and rapid perfusion imaging.", "subjects": "Tissues and Organs (q-bio.TO); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "comments": "Under Review", "pdf_url": "https://arxiv.org/pdf/2505.22673.pdf", "abstract_url": "https://arxiv.org/abs/2505.22673", "categories": ["Tissues and Organs (q-bio.TO)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为MAGIC的新型深度学习框架，旨在通过生成人工智能和生理信息，将非对比计算机断层扫描（CT）成像映射到多个无对比剂的CT灌注成像图，以解决对比剂使用带来的问题和成本。", "motivation": "解决CT灌注成像中使用对比剂可能引起的过敏反应和副作用，以及高昂的成本问题。", "method": "结合生成人工智能和生理信息的多任务网络框架，通过将生理特征纳入损失项来增强图像保真度。", "result": "MAGIC框架在视觉质量和诊断准确性方面表现出色，与使用静脉对比剂的临床灌注成像相比具有优势。", "conclusion": "MAGIC有望通过提供无对比剂、成本效益高且快速的灌注成像，革新医疗保健。"}}
{"id": "2505.23762", "title": "ZeroGUI: Automating Online GUI Learning at Zero Human Cost", "authors": ["Chenyu Yang", "Shiqian Su", "Shi Liu", "Xuan Dong", "Yue Yu", "Weijie Su", "Xuehui Wang", "Zhaoyang Liu", "Jinguo Zhu", "Hao Li", "Wenhai Wang", "Yu Qiao", "Xizhou Zhu", "Jifeng Dai"], "abstract": "The rapid advancement of large Vision-Language Models (VLMs) has propelled the development of pure-vision-based GUI Agents, capable of perceiving and operating Graphical User Interfaces (GUI) to autonomously fulfill user instructions. However, existing approaches usually adopt an offline learning framework, which faces two core limitations: (1) heavy reliance on high-quality manual annotations for element grounding and action supervision, and (2) limited adaptability to dynamic and interactive environments. To address these limitations, we propose ZeroGUI, a scalable, online learning framework for automating GUI Agent training at Zero human cost. Specifically, ZeroGUI integrates (i) VLM-based automatic task generation to produce diverse training goals from the current environment state, (ii) VLM-based automatic reward estimation to assess task success without hand-crafted evaluation functions, and (iii) two-stage online reinforcement learning to continuously interact with and learn from GUI environments. Experiments on two advanced GUI Agents (UI-TARS and Aguvis) demonstrate that ZeroGUI significantly boosts performance across OSWorld and AndroidLab environments. The code is available at", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23762.pdf", "abstract_url": "https://arxiv.org/abs/2505.23762", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "ZeroGUI是一个可扩展的在线学习框架，旨在以零人工成本自动化GUI代理的训练。它通过整合基于VLM的自动任务生成、奖励估计和两阶段在线强化学习，解决了现有离线学习方法对高质量手动注释的依赖和动态交互环境适应性有限的问题。", "motivation": "解决现有纯视觉GUI代理在离线学习框架下对高质量手动注释的依赖以及动态和交互环境适应性有限的问题。", "method": "ZeroGUI整合了基于VLM的自动任务生成、自动奖励估计和两阶段在线强化学习，以自动化GUI代理的训练。", "result": "在UI-TARS和Aguvis两个先进的GUI代理上进行的实验表明，ZeroGUI在OSWorld和AndroidLab环境中显著提高了性能。", "conclusion": "ZeroGUI通过自动化任务生成和奖励估计，以及在线强化学习，有效地提升了GUI代理的性能和适应性，同时显著降低了人工成本。"}}
{"id": "2505.23187", "title": "Cross-Task Experiential Learning on LLM-based Multi-Agent Collaboration", "authors": ["Yilong Li", "Chen Qian", "Yu Xia", "Ruijie Shi", "Yufan Dang", "Zihao Xie", "Ziming You", "Weize Chen", "Cheng Yang", "Weichuan Liu", "Ye Tian", "Xuantang Xiong", "Lei Han", "Zhiyuan Liu", "Maosong Sun"], "abstract": "Large Language Model-based multi-agent systems (MAS) have shown remarkable progress in solving complex tasks through collaborative reasoning and inter-agent critique. However, existing approaches typically treat each task in isolation, resulting in redundant computations and limited generalization across structurally similar tasks. To address this, we introduce multi-agent cross-task experiential learning (MAEL), a novel framework that endows LLM-driven agents with explicit cross-task learning and experience accumulation. We model the task-solving workflow on a graph-structured multi-agent collaboration network, where agents propagate information and coordinate via explicit connectivity. During the experiential learning phase, we quantify the quality for each step in the task-solving workflow and store the resulting rewards along with the corresponding inputs and outputs into each agent's individual experience pool. During inference, agents retrieve high-reward, task-relevant experiences as few-shot examples to enhance the effectiveness of each reasoning step, thereby enabling more accurate and efficient multi-agent collaboration. Experimental results on diverse datasets demonstrate that MAEL empowers agents to learn from prior task experiences effectively-achieving faster convergence and producing higher-quality solutions on current tasks.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "Work in Progress", "pdf_url": "https://arxiv.org/pdf/2505.23187.pdf", "abstract_url": "https://arxiv.org/abs/2505.23187", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为MAEL的新框架，旨在通过跨任务经验学习提升基于大型语言模型的多智能体系统在解决复杂任务时的协作效率和准确性。", "motivation": "现有的多智能体系统在处理任务时通常孤立对待每个任务，导致计算冗余和在结构相似任务间泛化能力有限。", "method": "MAEL框架通过在图形结构的多智能体协作网络上建模任务解决流程，实现智能体间的信息传播和协调，并通过量化任务解决流程中每一步的质量，将奖励与相应的输入输出存储到每个智能体的个体经验池中。", "result": "实验结果表明，MAEL能够有效使智能体从先前的任务经验中学习，实现更快的收敛速度并在当前任务上产生更高质量的解决方案。", "conclusion": "MAEL框架通过显式的跨任务学习和经验积累，显著提升了基于大型语言模型的多智能体系统在协作解决复杂任务时的效率和准确性。"}}
{"id": "2505.22814", "title": "A Large Language Model-Enabled Control Architecture for Dynamic Resource Capability Exploration in Multi-Agent Manufacturing Systems", "authors": ["Jonghan Lim", "Ilya Kovalenko"], "abstract": "Manufacturing environments are becoming more complex and unpredictable due to factors such as demand variations and shorter product lifespans. This complexity requires real-time decision-making and adaptation to disruptions. Traditional control approaches highlight the need for advanced control strategies capable of overcoming unforeseen challenges, as they demonstrate limitations in responsiveness within dynamic industrial settings. Multi-agent systems address these challenges through decentralization of decision-making, enabling systems to respond dynamically to operational changes. However, current multi-agent systems encounter challenges related to real-time adaptation, context-aware decision-making, and the dynamic exploration of resource capabilities. Large language models provide the possibility to overcome these limitations through context-aware decision-making capabilities. This paper introduces a large language model-enabled control architecture for multi-agent manufacturing systems to dynamically explore resource capabilities in response to real-time disruptions. A simulation-based case study demonstrates that the proposed architecture improves system resilience and flexibility. The case study findings show improved throughput and efficient resource utilization compared to existing approaches.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.22814.pdf", "abstract_url": "https://arxiv.org/abs/2505.22814", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于大型语言模型的控制架构，用于多代理制造系统中动态探索资源能力，以应对实时中断，提高系统韧性和灵活性。", "motivation": "制造环境因需求变化和产品生命周期缩短而变得更加复杂和不可预测，需要实时决策和适应中断的能力。传统的控制方法在动态工业环境中的响应性有限，多代理系统通过决策分散化应对这些挑战，但在实时适应、上下文感知决策和资源能力动态探索方面仍面临挑战。", "method": "本文引入了一种大型语言模型支持的控制架构，用于多代理制造系统，通过上下文感知决策能力动态探索资源能力。", "result": "基于模拟的案例研究表明，所提出的架构提高了系统的韧性和灵活性，结果显示与现有方法相比，吞吐量提高，资源利用效率更高。", "conclusion": "大型语言模型支持的控制架构为多代理制造系统提供了一种有效的方法，以动态探索资源能力，应对实时中断，从而提高制造系统的性能和效率。"}}
{"id": "2505.23481", "title": "PhysicsNeRF: Physics-Guided 3D Reconstruction from Sparse Views", "authors": ["Mohamed Rayan Barhdadi", "Hasan Kurban", "Hussein Alnuweiri"], "abstract": "PhysicsNeRF is a physically grounded framework for 3D reconstruction from sparse views, extending Neural Radiance Fields with four complementary constraints: depth ranking, RegNeRF-style consistency, sparsity priors, and cross-view alignment. While standard NeRFs fail under sparse supervision, PhysicsNeRF employs a compact 0.67M-parameter architecture and achieves 21.4 dB average PSNR using only 8 views, outperforming prior methods. A generalization gap of 5.7-6.2 dB is consistently observed and analyzed, revealing fundamental limitations of sparse-view reconstruction. PhysicsNeRF enables physically consistent, generalizable 3D representations for agent interaction and simulation, and clarifies the expressiveness-generalization trade-off in constrained NeRF models.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "4 pages, 2 figures, 2 tables. Preliminary work. Under review by the Building Physically Plausible World Models Workshop at the 42nd International Conference on Machine Learning (ICML 2025), Vancouver, Canada", "pdf_url": "https://arxiv.org/pdf/2505.23481.pdf", "abstract_url": "https://arxiv.org/abs/2505.23481", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "PhysicsNeRF是一个物理引导的稀疏视图3D重建框架，通过结合深度排序、RegNeRF风格一致性、稀疏先验和跨视图对齐等四种互补约束，扩展了神经辐射场（NeRF）。该框架在仅使用8个视图的情况下，实现了21.4 dB的平均PSNR，优于现有方法。", "motivation": "解决在稀疏视图下标准NeRFs无法有效进行3D重建的问题。", "method": "采用一个紧凑的0.67M参数架构，并结合四种物理约束：深度排序、RegNeRF风格一致性、稀疏先验和跨视图对齐。", "result": "在仅使用8个视图的情况下，PhysicsNeRF实现了21.4 dB的平均PSNR，优于现有方法，并揭示了稀疏视图重建的基本限制。", "conclusion": "PhysicsNeRF不仅能够为代理交互和模拟提供物理一致的、可泛化的3D表示，还阐明了在受限NeRF模型中表达力与泛化能力之间的权衡。"}}
{"id": "2505.23277", "title": "Sentinel: Attention Probing of Proxy Models for LLM Context Compression with an Understanding Perspective", "authors": ["Yong Zhang", "Yanwen Huang", "Ning Cheng", "Yang Guo", "Yun Zhu", "Yanmeng Wang", "Shaojun Wang", "Jing Xiao"], "abstract": "Retrieval-augmented generation (RAG) enhances large language models (LLMs) with external context, but retrieved passages are often lengthy, noisy, or exceed input limits. Existing compression methods typically require supervised training of dedicated compression models, increasing cost and reducing portability. We propose Sentinel, a lightweight sentence-level compression framework that reframes context filtering as an attention-based understanding task. Rather than training a compression model, Sentinel probes decoder attention from an off-the-shelf 0.5B proxy LLM using a lightweight classifier to identify sentence relevance. Empirically, we find that query-context relevance estimation is consistent across model scales, with 0.5B proxies closely matching the behaviors of larger models. On the LongBench benchmark, Sentinel achieves up to 5$\\times$ compression while matching the QA performance of 7B-scale compression systems. Our results suggest that probing native attention signals enables fast, effective, and question-aware context compression. Code available at:", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "Preprint. 17 pages including appendix", "pdf_url": "https://arxiv.org/pdf/2505.23277.pdf", "abstract_url": "https://arxiv.org/abs/2505.23277", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "Sentinel提出了一种轻量级的句子级压缩框架，通过基于注意力的理解任务来过滤上下文，无需训练专用压缩模型，实现了快速有效的上下文压缩。", "motivation": "检索增强生成（RAG）虽然能增强大型语言模型（LLMs）的外部上下文，但检索到的段落往往冗长、嘈杂或超出输入限制。现有的压缩方法通常需要监督训练专用压缩模型，增加了成本并降低了可移植性。", "method": "Sentinel利用现成的0.5B代理LLM的解码器注意力，通过轻量级分类器识别句子相关性，实现了基于注意力的上下文过滤。", "result": "在LongBench基准测试中，Sentinel实现了高达5倍的压缩，同时匹配了7B规模压缩系统的QA性能。", "conclusion": "结果表明，探测原生注意力信号可以实现快速、有效且问题感知的上下文压缩。"}}
{"id": "2505.23291", "title": "ScEdit: Script-based Assessment of Knowledge Editing", "authors": ["Xinye Li", "Zunwen Zheng", "Qian Zhang", "Dekai Zhuang", "Jiabao Kang", "Liyan Xu", "Qingbin Liu", "Xi Chen", "Zhiying Tu", "Dianhui Chu", "Dianbo Sui"], "abstract": "Knowledge Editing (KE) has gained increasing attention, yet current KE tasks remain relatively simple. Under current evaluation frameworks, many editing methods achieve exceptionally high scores, sometimes nearing perfection. However, few studies integrate KE into real-world application scenarios (e.g., recent interest in LLM-as-agent). To support our analysis, we introduce a novel script-based benchmark -- ScEdit (Script-based Knowledge Editing Benchmark) -- which encompasses both counterfactual and temporal edits. We integrate token-level and text-level evaluation methods, comprehensively analyzing existing KE techniques. The benchmark extends traditional fact-based (\"What\"-type question) evaluation to action-based (\"How\"-type question) evaluation. We observe that all KE methods exhibit a drop in performance on established metrics and face challenges on text-level metrics, indicating a challenging task. Our benchmark is available at", "subjects": "Computation and Language (cs.CL)", "comments": "ACL 2025 Findings", "pdf_url": "https://arxiv.org/pdf/2505.23291.pdf", "abstract_url": "https://arxiv.org/abs/2505.23291", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了ScEdit，一个基于脚本的知识编辑评估基准，旨在更全面地评估知识编辑方法在现实应用场景中的表现。", "motivation": "当前的知识编辑（KE）任务相对简单，许多编辑方法在现有评估框架下得分极高，但缺乏在真实世界应用场景（如LLM-as-agent）中的整合研究。", "method": "引入了一个新颖的基于脚本的基准——ScEdit，包括反事实和时间编辑，整合了令牌级和文本级评估方法，全面分析了现有的KE技术。", "result": "所有KE方法在既定指标上表现下降，且在文本级指标上面临挑战，表明这是一个具有挑战性的任务。", "conclusion": "ScEdit基准扩展了传统的基于事实的评估，引入了基于行动的评估，为知识编辑领域提供了更全面的评估工具。"}}
{"id": "2505.23299", "title": "Data-efficient Meta-models for Evaluation of Context-based Questions and Answers in LLMs", "authors": ["Julia Belikova", "Konstantin Polev", "Rauf Parchiev", "Dmitry Simakov"], "abstract": "Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) systems are increasingly deployed in industry applications, yet their reliability remains hampered by challenges in detecting hallucinations. While supervised state-of-the-art (SOTA) methods that leverage LLM hidden states -- such as activation tracing and representation analysis -- show promise, their dependence on extensively annotated datasets limits scalability in real-world applications. This paper addresses the critical bottleneck of data annotation by investigating the feasibility of reducing training data requirements for two SOTA hallucination detection frameworks: Lookback Lens, which analyzes attention head dynamics, and probing-based approaches, which decode internal model representations. We propose a methodology combining efficient classification algorithms with dimensionality reduction techniques to minimize sample size demands while maintaining competitive performance. Evaluations on standardized question-answering RAG benchmarks show that our approach achieves performance comparable to strong proprietary LLM-based baselines with only 250 training samples. These results highlight the potential of lightweight, data-efficient paradigms for industrial deployment, particularly in annotation-constrained scenarios.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23299.pdf", "abstract_url": "https://arxiv.org/abs/2505.23299", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文研究了如何减少大型语言模型（LLMs）和检索增强生成（RAG）系统中幻觉检测的训练数据需求，提出了一种结合高效分类算法和降维技术的方法，仅需250个训练样本即可达到与强基线相当的性能。", "motivation": "解决LLMs和RAG系统在工业应用中因依赖大量标注数据而受限的可扩展性问题，特别是在幻觉检测方面。", "method": "结合高效分类算法和降维技术，减少两种最先进的幻觉检测框架（Lookback Lens和基于探测的方法）的训练数据需求。", "result": "在标准化的问答RAG基准测试中，仅使用250个训练样本，该方法就能达到与强专有LLM基线相当的性能。", "conclusion": "轻量级、数据高效的方法在工业部署中具有潜力，特别是在标注受限的场景下。"}}
{"id": "2505.22852", "title": "Operationalizing CaMeL: Strengthening LLM Defenses for Enterprise Deployment", "authors": ["Krti Tallam", "Emma Miller"], "abstract": "CaMeL (Capabilities for Machine Learning) introduces a capability-based sandbox to mitigate prompt injection attacks in large language model (LLM) agents. While effective, CaMeL assumes a trusted user prompt, omits side-channel concerns, and incurs performance tradeoffs due to its dual-LLM design. This response identifies these issues and proposes engineering improvements to expand CaMeL's threat coverage and operational usability. We introduce: (1) prompt screening for initial inputs, (2) output auditing to detect instruction leakage, (3) a tiered-risk access model to balance usability and control, and (4) a verified intermediate language for formal guarantees. Together, these upgrades align CaMeL with best practices in enterprise security and support scalable deployment.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.22852.pdf", "abstract_url": "https://arxiv.org/abs/2505.22852", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "CaMeL（机器学习能力）引入了一种基于能力的沙箱，以减轻大型语言模型（LLM）代理中的提示注入攻击。虽然有效，但CaMeL假设用户提示可信，忽略了侧信道问题，并因其双LLM设计而带来性能权衡。本文提出了工程改进，以扩大CaMeL的威胁覆盖范围和操作可用性。", "motivation": "解决CaMeL在防御大型语言模型（LLM）代理中的提示注入攻击时存在的信任假设、侧信道问题和性能权衡问题。", "method": "提出了四项工程改进：初始输入的提示筛选、检测指令泄漏的输出审计、平衡可用性和控制的分层风险访问模型，以及提供形式保证的验证中间语言。", "result": "这些升级使CaMeL与企业安全最佳实践保持一致，并支持可扩展的部署。", "conclusion": "通过引入提示筛选、输出审计、分层风险访问模型和验证中间语言，CaMeL的威胁覆盖范围和操作可用性得到了显著提升，更适合企业级部署。"}}
{"id": "2505.22846", "title": "RocqStar: Leveraging Similarity-driven Retrieval and Agentic Systems for Rocq generation", "authors": ["Nikita Khramov", "Andrei Kozyrev", "Gleb Solovev", "Anton Podkopaev"], "abstract": "Interactive Theorem Proving was repeatedly shown to be fruitful combined with Generative Artificial Intelligence. This paper assesses multiple approaches to Rocq generation and illuminates potential avenues for improvement. We highlight the importance of thorough premise selection for generating Rocq proofs and propose a novel approach, leveraging retrieval via a self-attentive embedder model. The evaluation of the designed approach shows up to 28% relative increase of the generator's performance. We tackle the problem of writing Rocq proofs using a multi-stage agentic system, tailored for formal verification, and demonstrate its high effectiveness. We conduct an ablation study and show the use of multi-agent debate on the planning stage of proof synthesis.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Logic in Computer Science (cs.LO); Software Engineering (cs.SE)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.22846.pdf", "abstract_url": "https://arxiv.org/abs/2505.22846", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Logic in Computer Science (cs.LO)", "Software Engineering (cs.SE)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文探讨了将交互式定理证明与生成式人工智能结合的多种方法，提出了一种新颖的基于自注意力嵌入模型的检索方法，用于提高Rocq证明生成的性能，并通过多阶段代理系统展示了其在形式验证中的高效性。", "motivation": "解决在Rocq证明生成中如何更有效地进行前提选择和证明合成的问题。", "method": "采用自注意力嵌入模型进行相似性驱动的检索，并设计了一个多阶段代理系统，专门用于形式验证。", "result": "所设计的方法使生成器的性能相对提高了28%，并通过消融研究展示了多代理辩论在证明合成规划阶段的作用。", "conclusion": "通过结合相似性驱动的检索和多代理系统，可以显著提高Rocq证明生成的效率和效果，为形式验证领域提供了新的改进方向。"}}
{"id": "2505.22909", "title": "Learning to Charge More: A Theoretical Study of Collusion by Q-Learning Agents", "authors": ["Cristian Chica", "Yinglong Guo", "Gilad Lerman"], "abstract": "There is growing experimental evidence that $Q$-learning agents may learn to charge supracompetitive prices. We provide the first theoretical explanation for this behavior in infinite repeated games. Firms update their pricing policies based solely on observed profits, without computing equilibrium strategies. We show that when the game admits both a one-stage Nash equilibrium price and a collusive-enabling price, and when the $Q$-function satisfies certain inequalities at the end of experimentation, firms learn to consistently charge supracompetitive prices. We introduce a new class of one-memory subgame perfect equilibria (SPEs) and provide conditions under which learned behavior is supported by naive collusion, grim trigger policies, or increasing strategies. Naive collusion does not constitute an SPE unless the collusive-enabling price is a one-stage Nash equilibrium, whereas grim trigger policies can.", "subjects": "General Economics (econ.GN); Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.22909.pdf", "abstract_url": "https://arxiv.org/abs/2505.22909", "categories": ["General Economics (econ.GN)", "Artificial Intelligence (cs.AI)", "Computer Science and Game Theory (cs.GT)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文首次在无限重复博弈中提供了Q学习代理可能学会收取超竞争价格的理论解释。研究表明，在满足特定条件下，企业会学会持续收取超竞争价格。", "motivation": "解决Q学习代理在无限重复博弈中学会收取超竞争价格行为的理论解释问题。", "method": "通过分析Q函数在实验结束时的特定不等式，研究企业在不计算均衡策略的情况下，如何基于观察到的利润更新定价策略。", "result": "当游戏既允许一阶段纳什均衡价格又允许促成勾结的价格时，且在Q函数满足特定条件下，企业学会持续收取超竞争价格。", "conclusion": "研究引入了一类新的单记忆子博弈完美均衡（SPEs），并提供了条件，说明在何种情况下学习行为由天真勾结、冷酷触发策略或递增策略支持。天真勾结不构成SPE，除非促成勾结的价格是一阶段纳什均衡，而冷酷触发策略可以。"}}
{"id": "2505.23495", "title": "Diagnosing and Addressing Pitfalls in KG-RAG Datasets: Toward More Reliable Benchmarking", "authors": ["Liangliang Zhang", "Zhuorui Jiang", "Hongliang Chi", "Haoyang Chen", "Mohammed Elkoumy", "Fali Wang", "Qiong Wu", "Zhengyi Zhou", "Shirui Pan", "Suhang Wang", "Yao Ma"], "abstract": "Knowledge Graph Question Answering (KGQA) systems rely on high-quality benchmarks to evaluate complex multi-hop reasoning. However, despite their widespread use, popular datasets such as WebQSP and CWQ suffer from critical quality issues, including inaccurate or incomplete ground-truth annotations, poorly constructed questions that are ambiguous, trivial, or unanswerable, and outdated or inconsistent knowledge. Through a manual audit of 16 popular KGQA datasets, including WebQSP and CWQ, we find that the average factual correctness rate is only 57 %. To address these issues, we introduce KGQAGen, an LLM-in-the-loop framework that systematically resolves these pitfalls. KGQAGen combines structured knowledge grounding, LLM-guided generation, and symbolic verification to produce challenging and verifiable QA instances. Using KGQAGen, we construct KGQAGen-10k, a ten-thousand scale benchmark grounded in Wikidata, and evaluate a diverse set of KG-RAG models. Experimental results demonstrate that even state-of-the-art systems struggle on this benchmark, highlighting its ability to expose limitations of existing models. Our findings advocate for more rigorous benchmark construction and position KGQAGen as a scalable framework for advancing KGQA evaluation.", "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": "9 pages", "pdf_url": "https://arxiv.org/pdf/2505.23495.pdf", "abstract_url": "https://arxiv.org/abs/2505.23495", "categories": ["Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文通过手动审核16个流行的KGQA数据集，发现平均事实正确率仅为57%，并提出了KGQAGen框架来解决这些问题，构建了KGQAGen-10k基准测试，展示了现有模型的局限性。", "motivation": "解决知识图谱问答（KGQA）系统中由于数据集质量问题（如不准确或不完整的地面真实注释、构建不当的问题、过时或不一致的知识）导致的评估不可靠问题。", "method": "引入KGQAGen，一个结合结构化知识基础、LLM引导生成和符号验证的LLM-in-the-loop框架，以产生具有挑战性和可验证的QA实例。", "result": "构建的KGQAGen-10k基准测试显示，即使是最先进的系统也在此基准上表现不佳，突出了现有模型的局限性。", "conclusion": "研究结果主张更严格的基准构建，并将KGQAGen定位为推动KGQA评估的可扩展框架。"}}
{"id": "2505.23752", "title": "ThinkGeo: Evaluating Tool-Augmented Agents for Remote Sensing Tasks", "authors": ["Akashah Shabbir", "Muhammad Akhtar Munir", "Akshay Dudhane", "Muhammad Umer Sheikh", "Muhammad Haris Khan", "Paolo Fraccaro", "Juan Bernabe Moreno", "Fahad Shahbaz Khan", "Salman Khan"], "abstract": "Recent progress in large language models (LLMs) has enabled tool-augmented agents capable of solving complex real-world tasks through step-by-step reasoning. However, existing evaluations often focus on general-purpose or multimodal scenarios, leaving a gap in domain-specific benchmarks that assess tool-use capabilities in complex remote sensing use cases. We present ThinkGeo, an agentic benchmark designed to evaluate LLM-driven agents on remote sensing tasks via structured tool use and multi-step planning. Inspired by tool-interaction paradigms, ThinkGeo includes human-curated queries spanning a wide range of real-world applications such as urban planning, disaster assessment and change analysis, environmental monitoring, transportation analysis, aviation monitoring, recreational infrastructure, and industrial site analysis. Each query is grounded in satellite or aerial imagery and requires agents to reason through a diverse toolset. We implement a ReAct-style interaction loop and evaluate both open and closed-source LLMs (e.g., GPT-4o, Qwen2.5) on 436 structured agentic tasks. The benchmark reports both step-wise execution metrics and final answer correctness. Our analysis reveals notable disparities in tool accuracy and planning consistency across models. ThinkGeo provides the first extensive testbed for evaluating how tool-enabled LLMs handle spatial reasoning in remote sensing. Our code and dataset are publicly available", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23752.pdf", "abstract_url": "https://arxiv.org/abs/2505.23752", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "ThinkGeo是一个评估工具增强代理在遥感任务中表现的基准测试，专注于通过结构化工具使用和多步规划来评估LLM驱动的代理。", "motivation": "现有评估多集中于通用或多模态场景，缺乏针对复杂遥感用例中工具使用能力的领域特定基准。", "method": "采用ReAct式交互循环，评估开源和闭源LLM在436个结构化代理任务上的表现，包括逐步执行指标和最终答案正确性。", "result": "分析显示不同模型在工具准确性和规划一致性上存在显著差异。", "conclusion": "ThinkGeo为评估工具增强的LLM如何处理遥感中的空间推理提供了首个广泛测试平台，代码和数据集已公开。"}}
{"id": "2505.23020", "title": "AgentAlign: Navigating Safety Alignment in the Shift from Informative to Agentic Large Language Models", "authors": ["Jinchuan Zhang", "Lu Yin", "Yan Zhou", "Songlin Hu"], "abstract": "The acquisition of agentic capabilities has transformed LLMs from \"knowledge providers\" to \"action executors\", a trend that while expanding LLMs' capability boundaries, significantly increases their susceptibility to malicious use. Previous work has shown that current LLM-based agents execute numerous malicious tasks even without being attacked, indicating a deficiency in agentic use safety alignment during the post-training phase. To address this gap, we propose AgentAlign, a novel framework that leverages abstract behavior chains as a medium for safety alignment data synthesis. By instantiating these behavior chains in simulated environments with diverse tool instances, our framework enables the generation of highly authentic and executable instructions while capturing complex multi-step dynamics. The framework further ensures model utility by proportionally synthesizing benign instructions through non-malicious interpretations of behavior chains, precisely calibrating the boundary between helpfulness and harmlessness. Evaluation results on AgentHarm demonstrate that fine-tuning three families of open-source models using our method substantially improves their safety (35.8% to 79.5% improvement) while minimally impacting or even positively enhancing their helpfulness, outperforming various prompting methods. The dataset and code have both been open-sourced.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "Submitted to ACL 2025", "pdf_url": "https://arxiv.org/pdf/2505.23020.pdf", "abstract_url": "https://arxiv.org/abs/2505.23020", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了AgentAlign框架，旨在解决大型语言模型（LLMs）从信息提供者转变为行动执行者时面临的安全对齐问题。通过利用抽象行为链作为安全对齐数据合成的媒介，并在模拟环境中实例化这些行为链，该框架能够生成高度真实且可执行的指令，同时捕捉复杂的多步动态。评估结果显示，使用该方法微调的模型在安全性上有显著提升（35.8%至79.5%的改进），同时对帮助性的影响最小甚至有所提升，优于各种提示方法。", "motivation": "随着大型语言模型（LLMs）从“知识提供者”转变为“行动执行者”，其能力边界扩展的同时，也显著增加了被恶意利用的脆弱性。现有研究表明，即使在没有受到攻击的情况下，基于LLM的代理也会执行大量恶意任务，这表明在后训练阶段存在代理使用安全对齐的不足。", "method": "提出了AgentAlign框架，该框架利用抽象行为链作为安全对齐数据合成的媒介。通过在模拟环境中用不同的工具实例实例化这些行为链，框架能够生成高度真实且可执行的指令，同时捕捉复杂的多步动态。此外，框架通过行为链的非恶意解释按比例合成良性指令，精确校准了帮助性和无害性之间的边界。", "result": "在AgentHarm上的评估结果显示，使用该方法微调的三个开源模型家族在安全性上有显著提升（35.8%至79.5%的改进），同时对帮助性的影响最小甚至有所提升，优于各种提示方法。", "conclusion": "AgentAlign框架通过抽象行为链和模拟环境实例化，有效解决了LLMs在转变为行动执行者时的安全对齐问题，显著提升了模型的安全性而不损害其帮助性，为LLMs的安全使用提供了新的解决方案。"}}
{"id": "2505.23765", "title": "From Chat Logs to Collective Insights: Aggregative Question Answering", "authors": ["Wentao Zhang", "Woojeong Kim", "Yuntian Deng"], "abstract": "Conversational agents powered by large language models (LLMs) are rapidly becoming integral to our daily interactions, generating unprecedented amounts of conversational data. Such datasets offer a powerful lens into societal interests, trending topics, and collective concerns. Yet, existing approaches typically treat these interactions as independent and miss critical insights that could emerge from aggregating and reasoning across large-scale conversation logs. In this paper, we introduce Aggregative Question Answering, a novel task requiring models to reason explicitly over thousands of user-chatbot interactions to answer aggregative queries, such as identifying emerging concerns among specific demographics. To enable research in this direction, we construct a benchmark, WildChat-AQA, comprising 6,027 aggregative questions derived from 182,330 real-world chatbot conversations. Experiments show that existing methods either struggle to reason effectively or incur prohibitive computational costs, underscoring the need for new approaches capable of extracting collective insights from large-scale conversational data.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23765.pdf", "abstract_url": "https://arxiv.org/abs/2505.23765", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了聚合问答这一新任务，旨在通过分析大规模聊天记录来提取集体洞察，并构建了一个基准数据集WildChat-AQA以促进相关研究。", "motivation": "现有的方法通常将聊天机器人的交互视为独立的，忽略了通过聚合和推理大规模对话日志可能获得的关键洞察。", "method": "提出了聚合问答任务，要求模型明确推理数千次用户与聊天机器人的交互，以回答聚合查询。", "result": "实验表明，现有方法要么难以有效推理，要么计算成本过高，凸显了需要新方法来从大规模对话数据中提取集体洞察。", "conclusion": "本文强调了从大规模对话数据中提取集体洞察的重要性，并提出了聚合问答任务和基准数据集，为未来研究指明了方向。"}}
{"id": "2505.23723", "title": "ML-Agent: Reinforcing LLM Agents for Autonomous Machine Learning Engineering", "authors": ["Zexi Liu", "Jingyi Chai", "Xinyu Zhu", "Shuo Tang", "Rui Ye", "Bo Zhang", "Lei Bai", "Siheng Chen"], "abstract": "The emergence of large language model (LLM)-based agents has significantly advanced the development of autonomous machine learning (ML) engineering. However, most existing approaches rely heavily on manual prompt engineering, failing to adapt and optimize based on diverse experimental experiences. Focusing on this, for the first time, we explore the paradigm of learning-based agentic ML, where an LLM agent learns through interactive experimentation on ML tasks using online reinforcement learning (RL). To realize this, we propose a novel agentic ML training framework with three key components: (1) exploration-enriched fine-tuning, which enables LLM agents to generate diverse actions for enhanced RL exploration; (2) step-wise RL, which enables training on a single action step, accelerating experience collection and improving training efficiency; (3) an agentic ML-specific reward module, which unifies varied ML feedback signals into consistent rewards for RL optimization. Leveraging this framework, we train ML-Agent, driven by a 7B-sized Qwen-2.5 LLM for autonomous ML. Remarkably, despite being trained on merely 9 ML tasks, our 7B-sized ML-Agent outperforms the 671B-sized DeepSeek-R1 agent. Furthermore, it achieves continuous performance improvements and demonstrates exceptional cross-task generalization capabilities.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23723.pdf", "abstract_url": "https://arxiv.org/abs/2505.23723", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种基于强化学习的LLM代理训练框架ML-Agent，通过探索性微调、逐步强化学习和特定奖励模块，实现了在少量任务训练下的优异表现和跨任务泛化能力。", "motivation": "现有基于大型语言模型（LLM）的代理在自主机器学习（ML）工程中主要依赖手动提示工程，缺乏根据多样实验经验进行适应和优化的能力。", "method": "提出了一个包含三个关键组件的代理ML训练框架：探索性微调、逐步强化学习和代理ML特定奖励模块。", "result": "尽管仅在9个ML任务上训练，7B大小的ML-Agent在性能上超越了671B大小的DeepSeek-R1代理，并展示了持续的改进和卓越的跨任务泛化能力。", "conclusion": "学习型代理ML范式通过强化学习实现了LLM代理在自主ML任务中的高效训练和优化，为未来的ML工程提供了新的方向。"}}
{"id": "2505.23189", "title": "TrackVLA: Embodied Visual Tracking in the Wild", "authors": ["Shaoan Wang", "Jiazhao Zhang", "Minghan Li", "Jiahang Liu", "Anqi Li", "Kui Wu", "Fangwei Zhong", "Junzhi Yu", "Zhizheng Zhang", "He Wang"], "abstract": "Embodied visual tracking is a fundamental skill in Embodied AI, enabling an agent to follow a specific target in dynamic environments using only egocentric vision. This task is inherently challenging as it requires both accurate target recognition and effective trajectory planning under conditions of severe occlusion and high scene dynamics. Existing approaches typically address this challenge through a modular separation of recognition and planning. In this work, we propose TrackVLA, a Vision-Language-Action (VLA) model that learns the synergy between object recognition and trajectory planning. Leveraging a shared LLM backbone, we employ a language modeling head for recognition and an anchor-based diffusion model for trajectory planning. To train TrackVLA, we construct an Embodied Visual Tracking Benchmark (EVT-Bench) and collect diverse difficulty levels of recognition samples, resulting in a dataset of 1.7 million samples. Through extensive experiments in both synthetic and real-world environments, TrackVLA demonstrates SOTA performance and strong generalizability. It significantly outperforms existing methods on public benchmarks in a zero-shot manner while remaining robust to high dynamics and occlusion in real-world scenarios at 10 FPS inference speed. Our project page is:", "subjects": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23189.pdf", "abstract_url": "https://arxiv.org/abs/2505.23189", "categories": ["Robotics (cs.RO)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "TrackVLA是一种视觉-语言-动作（VLA）模型，旨在通过结合对象识别和轨迹规划来解决在动态环境中进行自我中心视觉跟踪的挑战。", "motivation": "解决在动态环境中仅使用自我中心视觉进行特定目标跟踪的挑战，该任务需要准确的目标识别和有效的轨迹规划。", "method": "利用共享的LLM骨干网络，采用语言建模头进行识别和基于锚点的扩散模型进行轨迹规划。", "result": "TrackVLA在合成和真实世界环境中展示了最先进的性能和强大的泛化能力，显著优于现有方法，并在10 FPS的推理速度下保持对高动态和遮挡的鲁棒性。", "conclusion": "TrackVLA通过结合对象识别和轨迹规划，为在动态环境中进行自我中心视觉跟踪提供了一种有效的解决方案，具有广泛的应用潜力。"}}
{"id": "2505.22907", "title": "Conversational Alignment with Artificial Intelligence in Context", "authors": ["Rachel Katharine Sterken", "James Ravi Kirkpatrick"], "abstract": "The development of sophisticated artificial intelligence (AI) conversational agents based on large language models raises important questions about the relationship between human norms, values, and practices and AI design and performance. This article explores what it means for AI agents to be conversationally aligned to human communicative norms and practices for handling context and common ground and proposes a new framework for evaluating developers' design choices. We begin by drawing on the philosophical and linguistic literature on conversational pragmatics to motivate a set of desiderata, which we call the CONTEXT-ALIGN framework, for conversational alignment with human communicative practices. We then suggest that current large language model (LLM) architectures, constraints, and affordances may impose fundamental limitations on achieving full conversational alignment.", "subjects": "Computers and Society (cs.CY); Computation and Language (cs.CL)", "comments": "20 pages, to be published in Philosophical Perspectives", "pdf_url": "https://arxiv.org/pdf/2505.22907.pdf", "abstract_url": "https://arxiv.org/abs/2505.22907", "categories": ["Computers and Society (cs.CY)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了人工智能（AI）对话代理如何与人类交流规范和实践中处理上下文和共同点的方式对齐，并提出了一个评估开发者设计选择的新框架。", "motivation": "解决AI对话代理与人类交流规范和实践中处理上下文和共同点的方式对齐的问题。", "method": "利用哲学和语言学文献中关于会话语用学的理论，提出一个称为CONTEXT-ALIGN框架的期望标准。", "result": "当前的大型语言模型（LLM）架构、限制和可能性可能对实现完全会话对齐构成根本限制。", "conclusion": "提出了一个评估AI对话代理与人类交流实践对齐的新框架，并指出当前技术可能存在的限制。"}}
{"id": "2505.23266", "title": "Disrupting Vision-Language Model-Driven Navigation Services via Adversarial Object Fusion", "authors": ["Chunlong Xie", "Jialing He", "Shangwei Guo", "Jiacheng Wang", "Shudong Zhang", "Tianwei Zhang", "Tao Xiang"], "abstract": "We present Adversarial Object Fusion (AdvOF), a novel attack framework targeting vision-and-language navigation (VLN) agents in service-oriented environments by generating adversarial 3D objects. While foundational models like Large Language Models (LLMs) and Vision Language Models (VLMs) have enhanced service-oriented navigation systems through improved perception and decision-making, their integration introduces vulnerabilities in mission-critical service workflows. Existing adversarial attacks fail to address service computing contexts, where reliability and quality-of-service (QoS) are paramount. We utilize AdvOF to investigate and explore the impact of adversarial environments on the VLM-based perception module of VLN agents. In particular, AdvOF first precisely aggregates and aligns the victim object positions in both 2D and 3D space, defining and rendering adversarial objects. Then, we collaboratively optimize the adversarial object with regularization between the adversarial and victim object across physical properties and VLM perceptions. Through assigning importance weights to varying views, the optimization is processed stably and multi-viewedly by iterative fusions from local updates and justifications. Our extensive evaluations demonstrate AdvOF can effectively degrade agent performance under adversarial conditions while maintaining minimal interference with normal navigation tasks. This work advances the understanding of service security in VLM-powered navigation systems, providing computational foundations for robust service composition in physical-world deployments.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "comments": "Under review", "pdf_url": "https://arxiv.org/pdf/2505.23266.pdf", "abstract_url": "https://arxiv.org/abs/2505.23266", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了Adversarial Object Fusion (AdvOF)，一种针对视觉和语言导航(VLN)代理的新型攻击框架，通过在服务导向环境中生成对抗性3D对象来探索其对基于VLM的感知模块的影响。", "motivation": "大型语言模型(LLMs)和视觉语言模型(VLMs)等基础模型虽然通过改进的感知和决策能力增强了服务导向的导航系统，但它们的集成在关键任务服务工作流中引入了漏洞。现有的对抗攻击未能考虑到服务计算环境，其中可靠性和服务质量(QoS)至关重要。", "method": "AdvOF首先在2D和3D空间中精确聚合和对齐受害对象位置，定义并渲染对抗性对象。然后，通过在物理属性和VLM感知之间进行正则化，协作优化对抗性对象。通过为不同视图分配重要性权重，优化过程通过局部更新和调整的迭代融合稳定且多视角地进行。", "result": "广泛的评估表明，AdvOF能在对抗条件下有效降低代理性能，同时对正常导航任务的干扰最小。", "conclusion": "这项工作增进了对VLM驱动的导航系统中服务安全的理解，为物理世界部署中的鲁棒服务组合提供了计算基础。"}}
{"id": "2505.23239", "title": "OSS-UAgent: An Agent-based Usability Evaluation Framework for Open Source Software", "authors": ["Lingkai Meng", "Yu Shao", "Long Yuan", "Longbin Lai", "Peng Cheng", "Wenyuan Yu", "Wenjie Zhang", "Xuemin Lin", "Jingren Zhou"], "abstract": "Usability evaluation is critical to the impact and adoption of open source software (OSS), yet traditional methods relying on human evaluators suffer from high costs and limited scalability. To address these limitations, we introduce OSS-UAgent, an automated, configurable, and interactive agent-based usability evaluation framework specifically designed for open source software. Our framework employs intelligent agents powered by large language models (LLMs) to simulate developers performing programming tasks across various experience levels (from Junior to Expert). By dynamically constructing platform-specific knowledge bases, OSS-UAgent ensures accurate and context-aware code generation. The generated code is automatically evaluated across multiple dimensions, including compliance, correctness, and readability, providing a comprehensive measure of the software's usability. Additionally, our demonstration showcases OSS-UAgent's practical application in evaluating graph analytics platforms, highlighting its effectiveness in automating usability evaluation.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23239.pdf", "abstract_url": "https://arxiv.org/abs/2505.23239", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "OSS-UAgent是一个基于代理的开源软件可用性评估框架，旨在通过自动化、可配置和交互式的方法解决传统评估方法的高成本和有限扩展性问题。", "motivation": "传统依赖人类评估者的可用性评估方法存在高成本和有限扩展性的问题，影响了开源软件的影响力和采用率。", "method": "利用大型语言模型（LLMs）驱动的智能代理模拟不同经验水平的开发者执行编程任务，并通过动态构建平台特定知识库确保准确和上下文感知的代码生成。", "result": "生成的代码在合规性、正确性和可读性等多个维度上自动评估，为软件的可用性提供了全面的衡量标准。", "conclusion": "OSS-UAgent在评估图分析平台中的实际应用展示了其在自动化可用性评估方面的有效性，为开源软件的可用性评估提供了一种新的解决方案。"}}
{"id": "2505.23419", "title": "SWE-bench Goes Live!", "authors": ["Linghao Zhang", "Shilin He", "Chaoyun Zhang", "Yu Kang", "Bowen Li", "Chengxing Xie", "Junhao Wang", "Maoquan Wang", "Yufan Huang", "Shengyu Fu", "Elsie Nallipogu", "Qingwei Lin", "Yingnong Dang", "Saravan Rajmohan", "Dongmei Zhang"], "abstract": "The issue-resolving task, where a model generates patches to fix real-world bugs, has emerged as a critical benchmark for evaluating the capabilities of large language models (LLMs). While SWE-bench and its variants have become standard in this domain, they suffer from key limitations: they have not been updated since their initial releases, cover a narrow set of repositories, and depend heavily on manual effort for instance construction and environment setup. These factors hinder scalability and introduce risks of overfitting and data contamination. In this work, we present \\textbf{SWE-bench-Live}, a \\textit{live-updatable} benchmark designed to overcome these challenges. Our initial release consists of 1,319 tasks derived from real GitHub issues created since 2024, spanning 93 repositories. Each task is accompanied by a dedicated Docker image to ensure reproducible execution. Central to our benchmark is \\method, an automated curation pipeline that streamlines the entire process from instance creation to environment setup, removing manual bottlenecks and enabling scalability and continuous updates. We evaluate a range of state-of-the-art agent frameworks and LLMs on SWE-bench-Live, revealing a substantial performance gap compared to static benchmarks like SWE-bench, even under controlled evaluation conditions. To better understand this discrepancy, we perform detailed analyses across repository origin, issue recency, and task difficulty. By providing a fresh, diverse, and executable benchmark grounded in live repository activity, SWE-bench-Live facilitates rigorous, contamination-resistant evaluation of LLMs and agents in dynamic, real-world software development settings.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "}", "pdf_url": "https://arxiv.org/pdf/2505.23419.pdf", "abstract_url": "https://arxiv.org/abs/2505.23419", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2505.23671", "title": "GSO: Challenging Software Optimization Tasks for Evaluating SWE-Agents", "authors": ["Manish Shetty", "Naman Jain", "Jinjian Liu", "Vijay Kethanaboyina", "Koushik Sen", "Ion Stoica"], "abstract": "Developing high-performance software is a complex task that requires specialized expertise. We introduce GSO, a benchmark for evaluating language models' capabilities in developing high-performance software. We develop an automated pipeline that generates and executes performance tests to analyze repository commit histories to identify 102 challenging optimization tasks across 10 codebases, spanning diverse domains and programming languages. An agent is provided with a codebase and performance test as a precise specification, and tasked to improve the runtime efficiency, which is measured against the expert developer optimization. Our quantitative evaluation reveals that leading SWE-Agents struggle significantly, achieving less than 5% success rate, with limited improvements even with inference-time scaling. Our qualitative analysis identifies key failure modes, including difficulties with low-level languages, practicing lazy optimization strategies, and challenges in accurately localizing bottlenecks. We release the code and artifacts of our benchmark along with agent trajectories to enable future research.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.23671.pdf", "abstract_url": "https://arxiv.org/abs/2505.23671", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "GSO是一个用于评估语言模型在开发高性能软件方面能力的基准测试。通过自动化流程生成和执行性能测试，分析了10个代码库中的102个优化任务。评估显示，领先的SWE-Agents成功率低于5%，揭示了在低级语言、懒惰优化策略和瓶颈定位等方面的关键失败模式。", "motivation": "开发高性能软件需要专业知识，当前的语言模型在此方面的能力尚未得到充分评估。", "method": "开发了一个自动化管道，通过分析代码库的提交历史来识别优化任务，并使用性能测试作为精确规范来评估代理的性能改进能力。", "result": "领先的SWE-Agents在优化任务上的成功率低于5%，即使在推理时间扩展的情况下改进有限。", "conclusion": "GSO基准测试揭示了语言模型在软件开发优化中的局限性，为未来研究提供了代码、工件和代理轨迹。"}}
{"id": "2505.23352", "title": "Understanding the Information Propagation Effects of Communication Topologies in LLM-based Multi-Agent Systems", "authors": ["Xu Shen", "Yixin Liu", "Yiwei Dai", "Yili Wang", "Rui Miao", "Yue Tan", "Shirui Pan", "Xin Wang"], "abstract": "The communication topology in large language model-based multi-agent systems fundamentally governs inter-agent collaboration patterns, critically shaping both the efficiency and effectiveness of collective decision-making. While recent studies for communication topology automated design tend to construct sparse structures for efficiency, they often overlook why and when sparse and dense topologies help or hinder collaboration. In this paper, we present a causal framework to analyze how agent outputs, whether correct or erroneous, propagate under topologies with varying sparsity. Our empirical studies reveal that moderately sparse topologies, which effectively suppress error propagation while preserving beneficial information diffusion, typically achieve optimal task performance. Guided by this insight, we propose a novel topology design approach, EIB-leanrner, that balances error suppression and beneficial information propagation by fusing connectivity patterns from both dense and sparse graphs. Extensive experiments show the superior effectiveness, communication cost, and robustness of EIB-leanrner.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23352.pdf", "abstract_url": "https://arxiv.org/abs/2505.23352", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了基于大型语言模型的多智能体系统中通信拓扑对信息传播的影响，提出了一个因果框架来分析不同稀疏度拓扑下智能体输出的传播情况，并介绍了一种新的拓扑设计方法EIB-leanrner。", "motivation": "解决在大型语言模型基于多智能体系统中，通信拓扑设计如何影响智能体间协作效率和效果的问题，特别是稀疏和密集拓扑在何时及为何有助于或阻碍协作。", "method": "提出了一个因果框架来分析不同稀疏度拓扑下智能体输出的传播情况，并基于此设计了一种新的拓扑设计方法EIB-leanrner，该方法通过融合密集和稀疏图的连接模式来平衡错误抑制和有益信息传播。", "result": "实证研究表明，适度稀疏的拓扑结构在有效抑制错误传播的同时保留有益信息扩散，通常能实现最佳任务性能。EIB-leanrner在实验中显示出卓越的有效性、通信成本和鲁棒性。", "conclusion": "适度稀疏的通信拓扑结构对于优化多智能体系统的协作性能至关重要。EIB-leanrner作为一种新的拓扑设计方法，能够有效平衡错误抑制和信息传播，为多智能体系统的通信拓扑设计提供了新的思路。"}}
{"id": "2505.23643", "title": "Securing AI Agents with Information-Flow Control", "authors": ["Manuel Costa", "Boris Köpf", "Aashish Kolluri", "Andrew Paverd", "Mark Russinovich", "Ahmed Salem", "Shruti Tople", "Lukas Wutschitz", "Santiago Zanella-Béguelin"], "abstract": "As AI agents become increasingly autonomous and capable, ensuring their security against vulnerabilities such as prompt injection becomes critical. This paper explores the use of information-flow control (IFC) to provide security guarantees for AI agents. We present a formal model to reason about the security and expressiveness of agent planners. Using this model, we characterize the class of properties enforceable by dynamic taint-tracking and construct a taxonomy of tasks to evaluate security and utility trade-offs of planner designs. Informed by this exploration, we present Fides, a planner that tracks confidentiality and integrity labels, deterministically enforces security policies, and introduces novel primitives for selectively hiding information. Its evaluation in AgentDojo demonstrates that this approach broadens the range of tasks that can be securely accomplished. A tutorial to walk readers through the the concepts introduced in the paper can be found at", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23643.pdf", "abstract_url": "https://arxiv.org/abs/2505.23643", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了使用信息流控制（IFC）为AI代理提供安全保障的方法，提出了一个形式化模型来分析代理规划器的安全性和表达能力，并介绍了Fides规划器，该规划器通过动态污点跟踪和保密性、完整性标签跟踪来强制执行安全策略。", "motivation": "随着AI代理变得越来越自主和强大，确保其安全免受诸如提示注入等漏洞的威胁变得至关重要。", "method": "提出了一个形式化模型来推理代理规划器的安全性和表达能力，使用动态污点跟踪来强制执行安全策略，并构建了一个任务分类法来评估规划器设计的安全性和效用权衡。", "result": "介绍了Fides规划器，该规划器能够跟踪保密性和完整性标签，确定性地执行安全策略，并引入了选择性隐藏信息的新原语。在AgentDojo中的评估表明，这种方法扩大了可以安全完成的任务范围。", "conclusion": "通过信息流控制和Fides规划器，可以有效地提高AI代理的安全性，同时扩大其可安全执行的任务范围。"}}
{"id": "2505.23422", "title": "From Knowledge to Noise: CTIM-Rover and the Pitfalls of Episodic Memory in Software Engineering Agents", "authors": ["Tobias Lindenbauer", "Georg Groh", "Hinrich Schütze"], "abstract": "We introduce CTIM-Rover, an AI agent for Software Engineering (SE) built on top of AutoCodeRover (Zhang et al., 2024) that extends agentic reasoning frameworks with an episodic memory, more specifically, a general and repository-level Cross-Task-Instance Memory (CTIM). While existing open-source SE agents mostly rely on ReAct (Yao et al., 2023b), Reflexion (Shinn et al., 2023), or Code-Act (Wang et al., 2024), all of these reasoning and planning frameworks inefficiently discard their long-term memory after a single task instance. As repository-level understanding is pivotal for identifying all locations requiring a patch for fixing a bug, we hypothesize that SE is particularly well positioned to benefit from CTIM. For this, we build on the Experiential Learning (EL) approach ExpeL (Zhao et al., 2024), proposing a Mixture-Of-Experts (MoEs) inspired approach to create both a general-purpose and repository-level CTIM. We find that CTIM-Rover does not outperform AutoCodeRover in any configuration and thus conclude that neither ExpeL nor DoT-Bank (Lingam et al., 2024) scale to real-world SE problems. Our analysis indicates noise introduced by distracting CTIM items or exemplar trajectories as the likely source of the performance degradation.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": "Short Paper, REALM '25 camera-ready", "pdf_url": "https://arxiv.org/pdf/2505.23422.pdf", "abstract_url": "https://arxiv.org/abs/2505.23422", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "介绍了CTIM-Rover，一个基于AutoCodeRover的软件工程AI代理，它通过引入跨任务实例记忆（CTIM）来扩展代理推理框架。尽管现有的开源SE代理主要依赖于ReAct、Reflexion或Code-Act，但这些框架在单个任务实例后低效地丢弃了长期记忆。研究发现CTIM-Rover在任何配置下都没有超越AutoCodeRover，表明ExpeL和DoT-Bank无法扩展到现实世界的SE问题，性能下降的可能原因是CTIM项目或示例轨迹引入的噪声。", "motivation": "解决软件工程代理在长期记忆利用上的低效问题，特别是在跨任务实例记忆的应用上，以提高修复bug时的仓库级理解能力。", "method": "基于Experiential Learning（EL）方法ExpeL，提出了一种受Mixture-Of-Experts（MoEs）启发的方法，创建了通用和仓库级的CTIM。", "result": "CTIM-Rover在任何配置下都没有超越AutoCodeRover，表明ExpeL和DoT-Bank无法扩展到现实世界的SE问题。", "conclusion": "CTIM-Rover的性能下降可能由CTIM项目或示例轨迹引入的噪声引起，这表明当前的EL方法在现实世界SE问题上的可扩展性有限。"}}
{"id": "2505.23710", "title": "From Connectivity to Autonomy: The Dawn of Self-Evolving Communication Systems", "authors": ["Zeinab Nezami", "Syed Danial Ali Shah", "Maryam Hafeez", "Karim Djemame", "Syed Ali Raza Zaidi"], "abstract": "This paper envisions 6G as a self-evolving telecom ecosystem, where AI-driven intelligence enables dynamic adaptation beyond static connectivity. We explore the key enablers of autonomous communication systems, spanning reconfigurable infrastructure, adaptive middleware, and intelligent network functions, alongside multi-agent collaboration for distributed decision-making. We explore how these methodologies align with emerging industrial IoT frameworks, ensuring seamless integration within digital manufacturing processes. Our findings emphasize the potential for improved real-time decision-making, optimizing efficiency, and reducing latency in networked control systems. The discussion addresses ethical challenges, research directions, and standardization efforts, concluding with a technology stack roadmap to guide future developments. By leveraging state-of-the-art 6G network management techniques, this research contributes to the next generation of intelligent automation solutions, bridging the gap between theoretical advancements and real-world industrial applications.", "subjects": "Systems and Control (eess.SY); Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Emerging Technologies (cs.ET)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23710.pdf", "abstract_url": "https://arxiv.org/abs/2505.23710", "categories": ["Systems and Control (eess.SY)", "Artificial Intelligence (cs.AI)", "Distributed, Parallel, and Cluster Computing (cs.DC)", "Emerging Technologies (cs.ET)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文设想6G为一个自我演进的电信生态系统，其中AI驱动的智能实现了超越静态连接的动态适应。我们探讨了自主通信系统的关键使能因素，包括可重构基础设施、自适应中间件和智能网络功能，以及多代理协作的分布式决策。", "motivation": "探索如何通过AI驱动的智能和自主通信系统，实现6G网络的动态适应和自我演进，以优化实时决策、提高效率并减少网络控制系统的延迟，同时解决伦理挑战和研究方向。", "method": "研究采用了可重构基础设施、自适应中间件、智能网络功能和多代理协作的方法，以确保与新兴工业物联网框架的无缝集成。", "result": "研究发现，通过上述方法可以实现改进的实时决策、优化效率和减少网络控制系统的延迟，为智能自动化解决方案的下一代发展做出贡献。", "conclusion": "本文通过探讨6G网络管理的最新技术，为理论进步和实际工业应用之间的桥梁建设提供了技术栈路线图，指导未来的发展。"}}
{"id": "2505.23720", "title": "COBRA: Contextual Bandit Algorithm for Ensuring Truthful Strategic Agents", "authors": ["Arun Verma", "Indrajit Saha", "Makoto Yokoo", "Bryan Kian Hsiang Low"], "abstract": "This paper considers a contextual bandit problem involving multiple agents, where a learner sequentially observes the contexts and the agent's reported arms, and then selects the arm that maximizes the system's overall reward. Existing work in contextual bandits assumes that agents truthfully report their arms, which is unrealistic in many real-life applications. For instance, consider an online platform with multiple sellers; some sellers may misrepresent product quality to gain an advantage, such as having the platform preferentially recommend their products to online users. To address this challenge, we propose an algorithm, COBRA, for contextual bandit problems involving strategic agents that disincentivize their strategic behavior without using any monetary incentives, while having incentive compatibility and a sub-linear regret guarantee. Our experimental results also validate the different performance aspects of our proposed algorithm.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)", "comments": "This paper proposes a contextual bandit algorithm that prevents strategic agents from misreporting while having approximate incentive compatibility and a sub-linear regret guarantee", "pdf_url": "https://arxiv.org/pdf/2505.23720.pdf", "abstract_url": "https://arxiv.org/abs/2505.23720", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Machine Learning (stat.ML)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为COBRA的上下文多臂老虎机算法，旨在解决涉及多个战略代理的问题，其中代理可能不诚实地报告其选择以获取优势。该算法无需货币激励即可抑制代理的战略行为，同时保证激励兼容性和次线性遗憾。", "motivation": "现有的上下文多臂老虎机算法假设代理会诚实地报告其选择，这在许多现实应用中是不现实的。例如，在线平台上的卖家可能会误报产品质量以获得优势。本文旨在解决这一问题。", "method": "提出了一种名为COBRA的算法，该算法通过设计一种机制来抑制代理的战略行为，无需使用任何货币激励，同时保证激励兼容性和次线性遗憾。", "result": "实验结果表明，COBRA算法在不同性能方面均表现出色，有效抑制了代理的战略行为。", "conclusion": "COBRA算法为解决涉及战略代理的上下文多臂老虎机问题提供了一种有效的方法，无需货币激励即可抑制代理的战略行为，同时保证激励兼容性和次线性遗憾。"}}
