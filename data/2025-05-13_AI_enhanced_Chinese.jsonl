{"id": "2505.06328", "title": "A Grounded Memory System For Smart Personal Assistants", "authors": ["Felix Ocker", "Jörg Deigmöller", "Pavel Smirnov", "Julian Eggert"], "abstract": "A wide variety of agentic AI applications - ranging from cognitive assistants for dementia patients to robotics - demand a robust memory system grounded in reality. In this paper, we propose such a memory system consisting of three components. First, we combine Vision Language Models for image captioning and entity disambiguation with Large Language Models for consistent information extraction during perception. Second, the extracted information is represented in a memory consisting of a knowledge graph enhanced by vector embeddings to efficiently manage relational information. Third, we combine semantic search and graph query generation for question answering via Retrieval Augmented Generation. We illustrate the system's working and potential using a real-world example.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "8 pages, 5 figures, accepted for the ESWC 2025 TEXT2KG workshop", "pdf_url": "https://arxiv.org/pdf/2505.06328.pdf", "abstract_url": "https://arxiv.org/abs/2505.06328", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种为智能个人助理设计的基于现实的记忆系统，该系统结合了视觉语言模型和大型语言模型，通过知识图谱和向量嵌入管理信息，并利用检索增强生成进行问答。", "motivation": "解决从认知辅助到机器人等多种代理AI应用对基于现实的健壮记忆系统的需求。", "method": "结合视觉语言模型和大型语言模型进行信息提取，使用知识图谱和向量嵌入表示信息，通过检索增强生成实现问答。", "result": "开发了一个能够有效管理和检索信息的记忆系统，并通过真实世界示例展示了其潜力。", "conclusion": "提出的记忆系统为智能个人助理等AI应用提供了一个强大的信息管理和检索解决方案。"}}
{"id": "2505.06416", "title": "ScaleMCP: Dynamic and Auto-Synchronizing Model Context Protocol Tools for LLM Agents", "authors": ["Elias Lumer", "Anmol Gulati", "Vamse Kumar Subbiah", "Pradeep Honaganahalli Basavaraju", "James A. Burke"], "abstract": "Recent advancements in Large Language Models (LLMs) and the introduction of the Model Context Protocol (MCP) have significantly expanded LLM agents' capability to interact dynamically with external tools and APIs. However, existing tool selection frameworks do not integrate MCP servers, instead relying heavily on error-prone manual updates to monolithic local tool repositories, leading to duplication, inconsistencies, and inefficiencies. Additionally, current approaches abstract tool selection before the LLM agent is invoked, limiting its autonomy and hindering dynamic re-querying capabilities during multi-turn interactions. To address these issues, we introduce ScaleMCP, a novel tool selection approach that dynamically equips LLM agents with a MCP tool retriever, giving agents the autonomy to add tools into their memory, as well as an auto-synchronizing tool storage system pipeline through CRUD (create, read, update, delete) operations with MCP servers as the single source of truth. We also propose a novel embedding strategy, Tool Document Weighted Average (TDWA), designed to selectively emphasize critical components of tool documents (e.g. tool name or synthetic questions) during the embedding process. Comprehensive evaluations conducted on a created dataset of 5,000 financial metric MCP servers, across 10 LLM models, 5 embedding models, and 5 retriever types, demonstrate substantial improvements in tool retrieval and agent invocation performance, emphasizing ScaleMCP's effectiveness in scalable, dynamic tool selection and invocation.", "subjects": "Computation and Language (cs.CL)", "comments": "17 pages", "pdf_url": "https://arxiv.org/pdf/2505.06416.pdf", "abstract_url": "https://arxiv.org/abs/2505.06416", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "ScaleMCP是一种新颖的工具选择方法，通过动态装备LLM代理与MCP工具检索器，赋予代理自主添加工具到其记忆中的能力，并通过与MCP服务器的CRUD操作实现自动同步工具存储系统管道。", "motivation": "解决现有工具选择框架不集成MCP服务器，依赖手动更新导致的重复、不一致和低效问题，以及当前方法在LLM代理调用前抽象工具选择限制其自主性和动态重新查询能力的问题。", "method": "引入ScaleMCP方法，包括动态装备LLM代理的MCP工具检索器和自动同步工具存储系统管道，以及提出一种新颖的嵌入策略TDWA，用于在嵌入过程中选择性强调工具文档的关键组件。", "result": "在创建的5,000个金融指标MCP服务器数据集上，跨越10个LLM模型、5个嵌入模型和5种检索器类型的全面评估显示，工具检索和代理调用性能有显著提升。", "conclusion": "ScaleMCP在可扩展的动态工具选择和调用方面表现出高效性，为LLM代理提供了更高的自主性和效率。"}}
{"id": "2505.06569", "title": "MacRAG: Compress, Slice, and Scale-up for Multi-Scale Adaptive Context RAG", "authors": ["Woosang Lim", "Zekun Li", "Gyuwan Kim", "Sungyoung Ji", "HyeonJung Kim", "Kyuri Choi", "Jin Hyuk Lim", "Kyungpyo Park", "William Yang Wang"], "abstract": "Long-context (LC) Large Language Models (LLMs) combined with Retrieval-Augmented Generation (RAG) hold strong potential for complex multi-hop and large-document tasks. However, existing RAG systems often suffer from imprecise retrieval, incomplete context coverage under constrained context windows, and fragmented information caused by suboptimal context construction. We introduce Multi-scale Adaptive Context RAG (MacRAG), a hierarchical retrieval framework that compresses and partitions documents into coarse-to-fine granularities, then adaptively merges relevant contexts through chunk- and document-level expansions in real time. By starting from the finest-level retrieval and progressively incorporating higher-level and broader context, MacRAG constructs effective query-specific long contexts, optimizing both precision and coverage. Evaluations on the challenging LongBench expansions of HotpotQA, 2WikiMultihopQA, and Musique confirm that MacRAG consistently surpasses baseline RAG pipelines on single- and multi-step generation with Llama-3.1-8B, Gemini-1.5-pro, and GPT-4o. Our results establish MacRAG as an efficient, scalable solution for real-world long-context, multi-hop reasoning. Our code is available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.06569.pdf", "abstract_url": "https://arxiv.org/abs/2505.06569", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "MacRAG是一个分层检索框架，通过压缩和分割文档到粗到细的粒度，然后实时自适应地合并相关上下文，优化了长上下文LLMs与RAG结合的精确性和覆盖范围。", "motivation": "解决现有RAG系统在复杂多跳和大文档任务中检索不精确、上下文覆盖不完全以及信息碎片化的问题。", "method": "采用分层检索框架，从最细粒度检索开始，逐步合并更高级和更广泛的上下文，构建查询特定的长上下文。", "result": "在LongBench扩展的HotpotQA、2WikiMultihopQA和Musique上，MacRAG consistently surpasses baseline RAG pipelines on single- and multi-step generation with Llama-3.1-8B, Gemini-1.5-pro, and GPT-4o.", "conclusion": "MacRAG为现实世界中的长上下文、多跳推理提供了一个高效、可扩展的解决方案。"}}
{"id": "2505.06438", "title": "Reliable Collaborative Conversational Agent System Based on LLMs and Answer Set Programming", "authors": ["Yankai Zeng", "Gopal Gupta"], "abstract": "As the Large-Language-Model-driven (LLM-driven) Artificial Intelligence (AI) bots became popular, people realized their strong potential in Task-Oriented Dialogue (TOD). However, bots relying wholly on LLMs are unreliable in their knowledge, and whether they can finally produce a correct result for the task is not guaranteed. The collaboration among these agents also remains a challenge, since the necessary information to convey is unclear, and the information transfer is by prompts -- unreliable, and malicious knowledge is easy to inject. With the help of logic programming tools such as Answer Set Programming (ASP), conversational agents can be built safely and reliably, and communication among the agents made more efficient and secure. We proposed an Administrator-Assistant Dual-Agent paradigm, where the two ASP-driven bots share the same knowledge base and complete their tasks independently, while the information can be passed by a Collaborative Rule Set (CRS). The knowledge and information conveyed are encapsulated and invisible to the users, ensuring the security of information transmission. We have constructed AutoManager, a dual-agent system for managing the drive-through window of a fast-food restaurant such as Taco Bell in the US. In AutoManager, the assistant bot takes the customer's order while the administrator bot manages the menu and food supply. We evaluated our AutoManager and compared it with the real-world Taco Bell Drive-Thru AI Order Taker, and the results show that our method is more reliable.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "14 pages", "pdf_url": "https://arxiv.org/pdf/2505.06438.pdf", "abstract_url": "https://arxiv.org/abs/2505.06438", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于大型语言模型（LLM）和答案集编程（ASP）的可靠协作对话代理系统，旨在解决LLM驱动的AI机器人在任务导向对话中的不可靠性和协作难题。通过引入管理员-助手双代理范式，利用ASP确保知识的安全可靠传递，并在快餐店场景中验证了其有效性。", "motivation": "解决LLM驱动的AI机器人在任务导向对话中的知识不可靠性和协作难题，确保任务执行的正确性和信息传递的安全性。", "method": "提出管理员-助手双代理范式，利用答案集编程（ASP）构建对话代理，通过协作规则集（CRS）实现高效安全的信息传递。", "result": "在快餐店场景中构建的AutoManager系统比现有的Taco Bell Drive-Thru AI Order Taker更可靠。", "conclusion": "结合ASP和LLM的双代理系统能够有效提升任务导向对话的可靠性和安全性，为AI机器人的协作提供了新思路。"}}
{"id": "2505.06492", "title": "SmartPilot: A Multiagent CoPilot for Adaptive and Intelligent Manufacturing", "authors": ["Chathurangi Shyalika", "Renjith Prasad", "Alaa Al Ghazo", "Darssan Eswaramoorthi", "Harleen Kaur", "Sara Shree Muthuselvam", "Amit Sheth"], "abstract": "In the dynamic landscape of Industry 4.0, achieving efficiency, precision, and adaptability is essential to optimize manufacturing operations. Industries suffer due to supply chain disruptions caused by anomalies, which are being detected by current AI models but leaving domain experts uncertain without deeper insights into these anomalies. Additionally, operational inefficiencies persist due to inaccurate production forecasts and the limited effectiveness of traditional AI models for processing complex sensor data. Despite these advancements, existing systems lack the seamless integration of these capabilities needed to create a truly unified solution for enhancing production and decision-making. We propose SmartPilot, a neurosymbolic, multiagent CoPilot designed for advanced reasoning and contextual decision-making to address these challenges. SmartPilot processes multimodal sensor data and is compact to deploy on edge devices. It focuses on three key tasks: anomaly prediction, production forecasting, and domain-specific question answering. By bridging the gap between AI capabilities and real-world industrial needs, SmartPilot empowers industries with intelligent decision-making and drives transformative innovation in manufacturing. The demonstration video, datasets, and supplementary materials are available at", "subjects": "Artificial Intelligence (cs.AI)", "comments": "8 pages, 8 figures, 4 tables, IEEE Conference on Artificial Intelligence (IEEE CAI) 2025", "pdf_url": "https://arxiv.org/pdf/2505.06492.pdf", "abstract_url": "https://arxiv.org/abs/2505.06492", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了SmartPilot，一个为工业4.0设计的神经符号多agent协同驾驶系统，旨在通过处理多模态传感器数据，解决异常预测、生产预测和领域特定问题回答等关键任务，以提升制造业的智能决策和操作效率。", "motivation": "当前工业领域面临供应链中断、生产预测不准确以及传统AI模型处理复杂传感器数据效果有限等问题，缺乏一个能够整合这些能力的统一解决方案。", "method": "提出了一个神经符号、多agent的协同驾驶系统SmartPilot，该系统能够在边缘设备上部署，处理多模态传感器数据，并专注于异常预测、生产预测和领域特定问题回答。", "result": "SmartPilot通过桥接AI能力与真实工业需求，为工业提供了智能决策支持，推动了制造业的变革性创新。", "conclusion": "SmartPilot通过其先进的推理和上下文决策能力，为制造业提供了一个高效、精确和适应性强的解决方案，有望在工业4.0时代推动制造业的智能化和创新。"}}
{"id": "2505.06505", "title": "On Definite Iterated Belief Revision with Belief Algebras", "authors": ["Hua Meng", "Zhiguo Long", "Michael Sioutis", "Zhengchun Zhou"], "abstract": "Traditional logic-based belief revision research focuses on designing rules to constrain the behavior of revision operators. Frameworks have been proposed to characterize iterated revision rules, but they are often too loose, leading to multiple revision operators that all satisfy the rules under the same belief condition. In many practical applications, such as safety critical ones, it is important to specify a definite revision operator to enable agents to iteratively revise their beliefs in a deterministic way. In this paper, we propose a novel framework for iterated belief revision by characterizing belief information through preference relations. Semantically, both beliefs and new evidence are represented as belief algebras, which provide a rich and expressive foundation for belief revision. Building on traditional revision rules, we introduce additional postulates for revision with belief algebra, including an upper-bound constraint on the outcomes of revision. We prove that the revision result is uniquely determined given the current belief state and new evidence. Furthermore, to make the framework more useful in practice, we develop a particular algorithm for performing the proposed revision process. We argue that this approach may offer a more predictable and principled method for belief revision, making it suitable for real-world applications.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "10 pages. Extended version of an accepted IJCAI 2025 paper", "pdf_url": "https://arxiv.org/pdf/2505.06505.pdf", "abstract_url": "https://arxiv.org/abs/2505.06505", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新的迭代信念修正框架，通过偏好关系表征信念信息，使用信念代数作为信念和新证据的语义表示，并引入了额外的修正公设，包括修正结果的上界约束，证明了在给定当前信念状态和新证据下修正结果是唯一确定的。", "motivation": "解决传统基于逻辑的信念修正研究中迭代修正规则过于宽松，导致在同一信念条件下多个修正算子都满足规则的问题，特别是在安全关键应用中需要指定明确的修正算子以实现确定性迭代信念修正。", "method": "通过偏好关系表征信念信息，将信念和新证据表示为信念代数，引入额外的修正公设，包括修正结果的上界约束，并开发了执行提议修正过程的特定算法。", "result": "证明了在给定当前信念状态和新证据下，修正结果是唯一确定的，并开发了实用的修正算法。", "conclusion": "该方法为信念修正提供了更可预测和原则性的方法，适用于现实世界应用。"}}
{"id": "2505.06518", "title": "A Point-Based Algorithm for Distributional Reinforcement Learning in Partially Observable Domains", "authors": ["Larry Preuett III"], "abstract": "In many real-world planning tasks, agents must tackle uncertainty about the environment's state and variability in the outcomes of any chosen policy. We address both forms of uncertainty as a first step toward safer algorithms in partially observable settings. Specifically, we extend Distributional Reinforcement Learning (DistRL)-which models the entire return distribution for fully observable domains-to Partially Observable Markov Decision Processes (POMDPs), allowing an agent to learn the distribution of returns for each conditional plan. Concretely, we introduce new distributional Bellman operators for partial observability and prove their convergence under the supremum p-Wasserstein metric. We also propose a finite representation of these return distributions via psi-vectors, generalizing the classical alpha-vectors in POMDP solvers. Building on this, we develop Distributional Point-Based Value Iteration (DPBVI), which integrates psi-vectors into a standard point-based backup procedure-bridging DistRL and POMDP planning. By tracking return distributions, DPBVI naturally enables risk-sensitive control in domains where rare, high-impact events must be carefully managed. We provide source code to foster further research in robust decision-making under partial observability.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.06518.pdf", "abstract_url": "https://arxiv.org/abs/2505.06518", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于点的算法DPBVI，用于在部分可观察领域中实现分布强化学习，通过引入新的分布贝尔曼算子和psi向量，扩展了分布强化学习到POMDPs，支持风险敏感控制。", "motivation": "解决在部分可观察环境中，智能体面临的环境状态不确定性和政策结果变异性的问题，为更安全的算法提供第一步。", "method": "扩展分布强化学习（DistRL）到部分可观察马尔可夫决策过程（POMDPs），引入新的分布贝尔曼算子，提出psi向量作为回报分布的有限表示，并开发DPBVI算法。", "result": "证明了新分布贝尔曼算子在supremum p-Wasserstein度量下的收敛性，DPBVI算法能够自然支持风险敏感控制。", "conclusion": "DPBVI算法通过跟踪回报分布，为在需要谨慎管理罕见高影响事件的领域中实现稳健决策提供了可能，促进了在部分可观察性下的强大决策研究。"}}
{"id": "2505.07062", "title": "Seed1.5-VL Technical Report", "authors": ["Dong Guo", "Faming Wu", "Feida Zhu", "Fuxing Leng", "Guang Shi", "Haobin Chen", "Haoqi Fan", "Jian Wang", "Jianyu Jiang", "Jiawei Wang", "Jingji Chen", "Jingjia Huang", "Kang Lei", "Liping Yuan", "Lishu Luo", "Pengfei Liu", "Qinghao Ye", "Rui Qian", "Shen Yan", "Shixiong Zhao", "Shuai Peng", "Shuangye Li", "Sihang Yuan", "Sijin Wu", "Tianheng Cheng", "Weiwei Liu", "Wenqian Wang", "Xianhan Zeng", "Xiao Liu", "Xiaobo Qin", "Xiaohan Ding", "Xiaojun Xiao", "Xiaoying Zhang", "Xuanwei Zhang", "Xuehan Xiong", "Yanghua Peng", "Yangrui Chen", "Yanwei Li", "Yanxu Hu", "Yi Lin", "Yiyuan Hu", "Yiyuan Zhang", "Youbin Wu", "Yu Li", "Yudong Liu", "Yue Ling", "Yujia Qin", "Zanbo Wang", "Zhiwu He", "Aoxue Zhang", "Bairen Yi", "Bencheng Liao", "Can Huang", "Can Zhang", "Chaorui Deng", "Chaoyi Deng", "Cheng Lin", "Cheng Yuan", "Chenggang Li", "Chenhui Gou", "Chenwei Lou", "Chengzhi Wei", "Chundian Liu", "Chunyuan Li", "Deyao Zhu", "Donghong Zhong", "Feng Li", "Feng Zhang", "Gang Wu", "Guodong Li", "Guohong Xiao", "Haibin Lin", "Haihua Yang", "Haoming Wang", "Heng Ji", "Hongxiang Hao", "Hui Shen", "Huixia Li", "Jiahao Li", "Jialong Wu", "Jianhua Zhu", "Jianpeng Jiao", "Jiashi Feng", "Jiaze Chen", "Jianhui Duan", "Jihao Liu", "Jin Zeng", "Jingqun Tang", "Jingyu Sun", "Joya Chen", "Jun Long", "Junda Feng", "Junfeng Zhan", "Junjie Fang", "Junting Lu", "Kai Hua", "Kai Liu", "Kai Shen", "Kaiyuan Zhang", "Ke Shen"], "abstract": "We present Seed1.5-VL, a vision-language foundation model designed to advance general-purpose multimodal understanding and reasoning. Seed1.5-VL is composed with a 532M-parameter vision encoder and a Mixture-of-Experts (MoE) LLM of 20B active parameters. Despite its relatively compact architecture, it delivers strong performance across a wide spectrum of public VLM benchmarks and internal evaluation suites, achieving the state-of-the-art performance on 38 out of 60 public benchmarks. Moreover, in agent-centric tasks such as GUI control and gameplay, Seed1.5-VL outperforms leading multimodal systems, including OpenAI CUA and Claude 3.7. Beyond visual and video understanding, it also demonstrates strong reasoning abilities, making it particularly effective for multimodal reasoning challenges such as visual puzzles. We believe these capabilities will empower broader applications across diverse tasks. In this report, we mainly provide a comprehensive review of our experiences in building Seed1.5-VL across model design, data construction, and training at various stages, hoping that this report can inspire further research. Seed1.5-VL is now accessible at", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.07062.pdf", "abstract_url": "https://arxiv.org/abs/2505.07062", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "Seed1.5-VL是一个视觉语言基础模型，旨在提升通用多模态理解和推理能力。它由532M参数的视觉编码器和20B活跃参数的混合专家（MoE）大型语言模型组成，在多个公共VLM基准测试和内部评估套件中表现出色，尤其在代理中心任务如GUI控制和游戏玩法中超越领先的多模态系统。", "motivation": "解决多模态理解和推理的挑战，推动通用目的多模态模型的发展。", "method": "采用532M参数的视觉编码器和20B活跃参数的混合专家（MoE）大型语言模型架构。", "result": "在60个公共基准测试中的38个上达到最先进性能，在代理中心任务中超越OpenAI CUA和Claude 3.7等领先系统。", "conclusion": "Seed1.5-VL的强大性能和推理能力为多样化的任务提供了广泛的应用潜力，其设计和训练经验对进一步研究具有启发意义。"}}
{"id": "2505.06706", "title": "Bi-level Mean Field: Dynamic Grouping for Large-Scale MARL", "authors": ["Yuxuan Zheng", "Yihe Zhou", "Feiyang Xu", "Mingli Song", "Shunyu Liu"], "abstract": "Large-scale Multi-Agent Reinforcement Learning (MARL) often suffers from the curse of dimensionality, as the exponential growth in agent interactions significantly increases computational complexity and impedes learning efficiency. To mitigate this, existing efforts that rely on Mean Field (MF) simplify the interaction landscape by approximating neighboring agents as a single mean agent, thus reducing overall complexity to pairwise interactions. However, these MF methods inevitably fail to account for individual differences, leading to aggregation noise caused by inaccurate iterative updates during MF learning. In this paper, we propose a Bi-level Mean Field (BMF) method to capture agent diversity with dynamic grouping in large-scale MARL, which can alleviate aggregation noise via bi-level interaction. Specifically, BMF introduces a dynamic group assignment module, which employs a Variational AutoEncoder (VAE) to learn the representations of agents, facilitating their dynamic grouping over time. Furthermore, we propose a bi-level interaction module to model both inter- and intra-group interactions for effective neighboring aggregation. Experiments across various tasks demonstrate that the proposed BMF yields results superior to the state-of-the-art methods. Our code will be made publicly available.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.06706.pdf", "abstract_url": "https://arxiv.org/abs/2505.06706", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种双层次均值场（BMF）方法，通过动态分组来捕捉大规模多智能体强化学习（MARL）中的智能体多样性，以减轻聚合噪声。", "motivation": "大规模多智能体强化学习（MARL）常受维度诅咒的困扰，智能体间交互的指数增长显著增加了计算复杂度并阻碍了学习效率。现有的均值场（MF）方法通过将邻近智能体近似为单一均值智能体来简化交互景观，但这些方法无法考虑个体差异，导致在MF学习过程中因不准确的迭代更新而产生聚合噪声。", "method": "提出的双层次均值场（BMF）方法包括一个动态分组分配模块和一个双层次交互模块。动态分组分配模块使用变分自编码器（VAE）学习智能体的表示，促进其随时间动态分组；双层次交互模块则建模组间和组内交互，以实现有效的邻近聚合。", "result": "在各种任务上的实验表明，所提出的BMF方法的结果优于最先进的方法。", "conclusion": "BMF方法通过动态分组和双层次交互有效捕捉了智能体多样性，减轻了聚合噪声，为大规模MARL提供了一种高效的解决方案。"}}
{"id": "2505.06904", "title": "EcoLANG: Efficient and Effective Agent Communication Language Induction for Social Simulation", "authors": ["Xinyi Mou", "Chen Qian", "Wei Liu", "Xuanjing Huang", "Zhongyu Wei"], "abstract": "Large language models (LLMs) have demonstrated an impressive ability to role-play humans and replicate complex social dynamics. While large-scale social simulations are gaining increasing attention, they still face significant challenges, particularly regarding high time and computation costs. Existing solutions, such as distributed mechanisms or hybrid agent-based model (ABM) integrations, either fail to address inference costs or compromise accuracy and generalizability. To this end, we propose EcoLANG: Efficient and Effective Agent Communication Language Induction for Social Simulation. EcoLANG operates in two stages: (1) language evolution, where we filter synonymous words and optimize sentence-level rules through natural selection, and (2) language utilization, where agents in social simulations communicate using the evolved language. Experimental results demonstrate that EcoLANG reduces token consumption by over 20%, enhancing efficiency without sacrificing simulation accuracy.", "subjects": "Computation and Language (cs.CL); Computers and Society (cs.CY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.06904.pdf", "abstract_url": "https://arxiv.org/abs/2505.06904", "categories": ["Computation and Language (cs.CL)", "Computers and Society (cs.CY)"], "matching_keywords": ["agent"], "AI": {"tldr": "EcoLANG是一种高效且有效的代理通信语言诱导方法，用于社会模拟，通过语言进化和利用两阶段过程，显著降低计算成本同时保持模拟准确性。", "motivation": "解决大规模社会模拟中高时间和计算成本的问题，现有方法无法有效降低推理成本或牺牲准确性和通用性。", "method": "提出EcoLANG，分为语言进化（过滤同义词并通过自然选择优化句子级规则）和语言利用（代理在社会模拟中使用进化后的语言进行通信）两个阶段。", "result": "实验结果表明，EcoLANG减少了超过20%的令牌消耗，提高了效率而不牺牲模拟准确性。", "conclusion": "EcoLANG为大规模社会模拟提供了一种既高效又准确的解决方案，具有重要的应用价值。"}}
{"id": "2505.06914", "title": "The Distracting Effect: Understanding Irrelevant Passages in RAG", "authors": ["Chen Amiraz", "Florin Cuconasu", "Simone Filice", "Zohar Karnin"], "abstract": "A well-known issue with Retrieval Augmented Generation (RAG) is that retrieved passages that are irrelevant to the query sometimes distract the answer-generating LLM, causing it to provide an incorrect response. In this paper, we shed light on this core issue and formulate the distracting effect of a passage w.r.t. a query (and an LLM). We provide a quantifiable measure of the distracting effect of a passage and demonstrate its robustness across LLMs.", "subjects": "Computation and Language (cs.CL); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.06914.pdf", "abstract_url": "https://arxiv.org/abs/2505.06914", "categories": ["Computation and Language (cs.CL)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文探讨了检索增强生成（RAG）中一个已知问题：检索到的与查询无关的段落有时会分散生成答案的大型语言模型（LLM）的注意力，导致其提供错误回答。", "motivation": "解决RAG中无关段落对LLM生成答案的干扰问题。", "method": "提出了一个关于段落相对于查询（和LLM）的分散效应的量化度量，并证明了其在不同LLM中的鲁棒性。", "result": "研究表明，无关段落确实会对LLM生成答案产生显著的分散效应，且这种效应可以通过提出的量化度量来准确测量。", "conclusion": "本文的发现为理解和减轻RAG中无关段落的干扰效应提供了理论基础，对提高RAG系统的准确性和可靠性具有重要意义。"}}
{"id": "2505.07161", "title": "Towards Actionable Pedagogical Feedback: A Multi-Perspective Analysis of Mathematics Teaching and Tutoring Dialogue", "authors": ["Jannatun Naim", "Jie Cao", "Fareen Tasneem", "Jennifer Jacobs", "Brent Milne", "James Martin", "Tamara Sumner"], "abstract": "Effective feedback is essential for refining instructional practices in mathematics education, and researchers often turn to advanced natural language processing (NLP) models to analyze classroom dialogues from multiple perspectives. However, utterance-level discourse analysis encounters two primary challenges: (1) multifunctionality, where a single utterance may serve multiple purposes that a single tag cannot capture, and (2) the exclusion of many utterances from domain-specific discourse move classifications, leading to their omission in feedback. To address these challenges, we proposed a multi-perspective discourse analysis that integrates domain-specific talk moves with dialogue act (using the flattened multi-functional SWBD-MASL schema with 43 tags) and discourse relation (applying Segmented Discourse Representation Theory with 16 relations). Our top-down analysis framework enables a comprehensive understanding of utterances that contain talk moves, as well as utterances that do not contain talk moves. This is applied to two mathematics education datasets: TalkMoves (teaching) and SAGA22 (tutoring). Through distributional unigram analysis, sequential talk move analysis, and multi-view deep dive, we discovered meaningful discourse patterns, and revealed the vital role of utterances without talk moves, demonstrating that these utterances, far from being mere fillers, serve crucial functions in guiding, acknowledging, and structuring classroom discourse. These insights underscore the importance of incorporating discourse relations and dialogue acts into AI-assisted education systems to enhance feedback and create more responsive learning environments. Our framework may prove helpful for providing human educator feedback, but also aiding in the development of AI agents that can effectively emulate the roles of both educators and students.", "subjects": "Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)", "comments": "Accepted to EDM'2025", "pdf_url": "https://arxiv.org/pdf/2505.07161.pdf", "abstract_url": "https://arxiv.org/abs/2505.07161", "categories": ["Computation and Language (cs.CL)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种多视角的话语分析方法，用于数学教育和辅导对话的分析，以解决传统话语分析中的多功能性和领域特定话语移动分类排除问题。通过整合领域特定的谈话移动、对话行为及话语关系，该方法能够全面理解包含和不包含谈话移动的话语。应用于两个数学教育数据集后，发现了有意义的话语模式，并揭示了非谈话移动话语在引导、确认和结构化课堂讨论中的重要作用。", "motivation": "解决数学教育中有效反馈的两个主要挑战：话语的多功能性及领域特定话语移动分类的排除问题。", "method": "提出了一种多视角话语分析框架，整合了领域特定的谈话移动、对话行为（使用包含43个标签的SWBD-MASL模式）及话语关系（应用分段话语表示理论，包含16种关系）。", "result": "发现了有意义的话语模式，揭示了非谈话移动话语在课堂讨论中的关键作用，如引导、确认和结构化讨论。", "conclusion": "将话语关系和对话行为整合到AI辅助教育系统中，可以增强反馈并创建更响应式的学习环境。该框架不仅有助于提供人类教育者的反馈，还能帮助开发能有效模拟教育者和学生角色的AI代理。"}}
{"id": "2505.07184", "title": "Structural Entropy Guided Agent for Detecting and Repairing Knowledge Deficiencies in LLMs", "authors": ["Yifan Wei", "Xiaoyan Yu", "Tengfei Pan", "Angsheng Li", "Li Du"], "abstract": "Large language models (LLMs) have achieved unprecedented performance by leveraging vast pretraining corpora, yet their performance remains suboptimal in knowledge-intensive domains such as medicine and scientific research, where high factual precision is required. While synthetic data provides a promising avenue for augmenting domain knowledge, existing methods frequently generate redundant samples that do not align with the model's true knowledge gaps. To overcome this limitation, we propose a novel Structural Entropy-guided Knowledge Navigator (SENATOR) framework that addresses the intrinsic knowledge deficiencies of LLMs. Our approach employs the Structure Entropy (SE) metric to quantify uncertainty along knowledge graph paths and leverages Monte Carlo Tree Search (MCTS) to selectively explore regions where the model lacks domain-specific knowledge. Guided by these insights, the framework generates targeted synthetic data for supervised fine-tuning, enabling continuous self-improvement. Experimental results on LLaMA-3 and Qwen2 across multiple domain-specific benchmarks show that SENATOR effectively detects and repairs knowledge deficiencies, achieving notable performance improvements. The code and data for our methods and experiments are available at", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.07184.pdf", "abstract_url": "https://arxiv.org/abs/2505.07184", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为SENATOR的新框架，旨在通过结构熵引导的知识导航器检测和修复大型语言模型（LLMs）在知识密集型领域中的知识缺陷，利用蒙特卡洛树搜索（MCTS）选择性探索模型缺乏知识的区域，并生成有针对性的合成数据进行监督微调，从而实现了显著的性能提升。", "motivation": "大型语言模型（LLMs）虽然在利用大量预训练语料库方面取得了前所未有的性能，但在需要高事实精度的知识密集型领域（如医学和科学研究）中表现仍然不理想。现有的合成数据方法经常生成与模型真实知识缺口不对齐的冗余样本。", "method": "提出了一种名为SENATOR的框架，该框架使用结构熵（SE）度量来量化知识图谱路径上的不确定性，并利用蒙特卡洛树搜索（MCTS）选择性探索模型缺乏领域特定知识的区域，进而生成有针对性的合成数据进行监督微调。", "result": "在LLaMA-3和Qwen2上的多个领域特定基准测试中，SENATOR有效地检测和修复了知识缺陷，实现了显著的性能改进。", "conclusion": "SENATOR框架通过结构熵引导的知识导航和有针对性的合成数据生成，为大型语言模型在知识密集型领域的自我持续改进提供了一种有效方法。"}}
{"id": "2505.06817", "title": "Control Plane as a Tool: A Scalable Design Pattern for Agentic AI Systems", "authors": ["Sivasathivel Kandasamy"], "abstract": "Agentic AI systems represent a new frontier in artificial intelligence, where agents often based on large language models(LLMs) interact with tools, environments, and other agents to accomplish tasks with a degree of autonomy. These systems show promise across a range of domains, but their architectural underpinnings remain immature. This paper conducts a comprehensive review of the types of agents, their modes of interaction with the environment, and the infrastructural and architectural challenges that emerge. We identify a gap in how these systems manage tool orchestration at scale and propose a reusable design abstraction: the \"Control Plane as a Tool\" pattern. This pattern allows developers to expose a single tool interface to an agent while encapsulating modular tool routing logic behind it. We position this pattern within the broader context of agent design and argue that it addresses several key challenges in scaling, safety, and extensibility.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "2 Figures and 2 Tables", "pdf_url": "https://arxiv.org/pdf/2505.06817.pdf", "abstract_url": "https://arxiv.org/abs/2505.06817", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文探讨了基于大型语言模型（LLMs）的代理AI系统的架构挑战，提出了一种名为“控制平面作为工具”的可重用设计模式，旨在解决工具编排的可扩展性、安全性和可扩展性问题。", "motivation": "代理AI系统在多个领域显示出潜力，但其架构基础尚不成熟，特别是在工具编排的可扩展性方面存在空白。", "method": "通过全面审查代理类型、它们与环境的交互模式以及出现的架构挑战，提出了一种“控制平面作为工具”的设计模式，该模式允许开发者向代理展示单一工具接口，同时封装模块化的工具路由逻辑。", "result": "提出的设计模式能够有效解决代理AI系统在扩展性、安全性和可扩展性方面的关键挑战。", "conclusion": "“控制平面作为工具”模式为代理AI系统的设计和实现提供了一种可扩展、安全且易于扩展的解决方案，有助于推动代理AI系统的发展和应用。"}}
{"id": "2505.06907", "title": "Towards Artificial General or Personalized Intelligence? A Survey on Foundation Models for Personalized Federated Intelligence", "authors": ["Yu Qiao", "Huy Q. Le", "Avi Deb Raha", "Phuong-Nam Tran", "Apurba Adhikary", "Mengchun Zhang", "Loc X. Nguyen", "Eui-Nam Huh", "Dusit Niyato", "Choong Seon Hong"], "abstract": "The rise of large language models (LLMs), such as ChatGPT, DeepSeek, and Grok-3, has reshaped the artificial intelligence landscape. As prominent examples of foundational models (FMs) built on LLMs, these models exhibit remarkable capabilities in generating human-like content, bringing us closer to achieving artificial general intelligence (AGI). However, their large-scale nature, sensitivity to privacy concerns, and substantial computational demands present significant challenges to personalized customization for end users. To bridge this gap, this paper presents the vision of artificial personalized intelligence (API), focusing on adapting these powerful models to meet the specific needs and preferences of users while maintaining privacy and efficiency. Specifically, this paper proposes personalized federated intelligence (PFI), which integrates the privacy-preserving advantages of federated learning (FL) with the zero-shot generalization capabilities of FMs, enabling personalized, efficient, and privacy-protective deployment at the edge. We first review recent advances in both FL and FMs, and discuss the potential of leveraging FMs to enhance federated systems. We then present the key motivations behind realizing PFI and explore promising opportunities in this space, including efficient PFI, trustworthy PFI, and PFI empowered by retrieval-augmented generation (RAG). Finally, we outline key challenges and future research directions for deploying FM-powered FL systems at the edge with improved personalization, computational efficiency, and privacy guarantees. Overall, this survey aims to lay the groundwork for the development of API as a complement to AGI, with a particular focus on PFI as a key enabling technique.", "subjects": "Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Neural and Evolutionary Computing (cs.NE)", "comments": "On going work", "pdf_url": "https://arxiv.org/pdf/2505.06907.pdf", "abstract_url": "https://arxiv.org/abs/2505.06907", "categories": ["Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)", "Neural and Evolutionary Computing (cs.NE)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文探讨了大型语言模型（LLMs）在实现人工通用智能（AGI）方面的潜力及其在个性化定制中的挑战，提出了人工个性化智能（API）的愿景，并通过个性化联邦智能（PFI）结合联邦学习（FL）和基础模型（FMs）的优势，以实现个性化、高效且保护隐私的边缘部署。", "motivation": "解决大型语言模型在个性化定制中面临的大规模性、隐私敏感性和高计算需求等挑战，推动人工个性化智能（API）的发展。", "method": "提出个性化联邦智能（PFI），结合联邦学习（FL）的隐私保护优势和基础模型（FMs）的零样本泛化能力。", "result": "探讨了实现PFI的关键动机和潜在机会，包括高效PFI、可信PFI和由检索增强生成（RAG）赋能的PFI，并概述了关键挑战和未来研究方向。", "conclusion": "本文为API作为AGI补充的发展奠定了基础，特别关注PFI作为关键技术的作用，旨在实现更好的个性化、计算效率和隐私保护。"}}
{"id": "2505.06997", "title": "A Multi-Agent Reinforcement Learning Approach for Cooperative Air-Ground-Human Crowdsensing in Emergency Rescue", "authors": ["Wenhao Lu", "Zhengqiu Zhu", "Yong Zhao", "Yonglin Tian", "Junjie Zeng", "Jun Zhang", "Zhong Liu", "Fei-Yue Wang"], "abstract": "Mobile crowdsensing is evolving beyond traditional human-centric models by integrating heterogeneous entities like unmanned aerial vehicles (UAVs) and unmanned ground vehicles (UGVs). Optimizing task allocation among these diverse agents is critical, particularly in challenging emergency rescue scenarios characterized by complex environments, limited communication, and partial observability. This paper tackles the Heterogeneous-Entity Collaborative-Sensing Task Allocation (HECTA) problem specifically for emergency rescue, considering humans, UAVs, and UGVs. We introduce a novel ``Hard-Cooperative'' policy where UGVs prioritize recharging low-battery UAVs, alongside performing their sensing tasks. The primary objective is maximizing the task completion rate (TCR) under strict time constraints. We rigorously formulate this NP-hard problem as a decentralized partially observable Markov decision process (Dec-POMDP) to effectively handle sequential decision-making under uncertainty. To solve this, we propose HECTA4ER, a novel multi-agent reinforcement learning algorithm built upon a Centralized Training with Decentralized Execution architecture. HECTA4ER incorporates tailored designs, including specialized modules for complex feature extraction, utilization of action-observation history via hidden states, and a mixing network integrating global and local information, specifically addressing the challenges of partial observability. Furthermore, theoretical analysis confirms the algorithm's convergence properties. Extensive simulations demonstrate that HECTA4ER significantly outperforms baseline algorithms, achieving an average 18.42% increase in TCR. Crucially, a real-world case study validates the algorithm's effectiveness and robustness in dynamic sensing scenarios, highlighting its strong potential for practical application in emergency response.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.06997.pdf", "abstract_url": "https://arxiv.org/abs/2505.06997", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为HECTA4ER的多智能体强化学习算法，用于解决紧急救援中异构实体（人类、无人机和无人地面车辆）协作感知任务分配（HECTA）问题。通过‘硬合作’策略和集中训练分散执行架构，显著提高了任务完成率。", "motivation": "解决在复杂环境、有限通信和部分可观测性挑战下的紧急救援场景中，异构实体协作感知任务分配的问题。", "method": "提出HECTA4ER算法，基于集中训练与分散执行架构，包含复杂特征提取模块、利用动作-观察历史的隐藏状态，以及整合全局和局部信息的混合网络。", "result": "HECTA4ER在模拟中平均提高任务完成率18.42%，并通过实际案例验证了其在动态感知场景中的有效性和鲁棒性。", "conclusion": "HECTA4ER算法在紧急救援实践中显示出强大的应用潜力，特别是在提高任务完成率和应对部分可观测性挑战方面。"}}
{"id": "2505.07049", "title": "DialogueReason: Rule-Based RL Sparks Dialogue Reasoning in LLMs", "authors": ["Yubo Shu", "Zhewei Huang", "Xin Wu", "Chen Hu", "Shuchang Zhou", "Daxin Jiang"], "abstract": "We propose DialogueReason, a reasoning paradigm that uncovers the lost roles in monologue-style reasoning models, aiming to boost diversity and coherency of the reasoning process. Recent advances in RL-based large reasoning models have led to impressive long CoT capabilities and high performance on math and science benchmarks. However, these reasoning models rely mainly on monologue-style reasoning, which often limits reasoning diversity and coherency, frequently recycling fixed strategies or exhibiting unnecessary shifts in attention. Our work consists of an analysis of monologue reasoning patterns and the development of a dialogue-based reasoning approach. We first introduce the Compound-QA task, which concatenates multiple problems into a single prompt to assess both diversity and coherency of reasoning. Our analysis shows that Compound-QA exposes weaknesses in monologue reasoning, evidenced by both quantitative metrics and qualitative reasoning traces. Building on the analysis, we propose a dialogue-based reasoning, named DialogueReason, structured around agents, environment, and interactions. Using PPO with rule-based rewards, we train open-source LLMs (Qwen-QWQ and Qwen-Base) to adopt dialogue reasoning. We evaluate trained models on MATH, AIME, and GPQA datasets, showing that the dialogue reasoning model outperforms monologue models under more complex compound questions. Additionally, we discuss how dialogue-based reasoning helps enhance interpretability, facilitate more intuitive human interaction, and inspire advances in multi-agent system design.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.07049.pdf", "abstract_url": "https://arxiv.org/abs/2505.07049", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "DialogueReason是一种基于规则的强化学习对话推理范式，旨在提升大型语言模型在复杂问题上的推理多样性和连贯性。通过引入Compound-QA任务和对话式推理方法，该研究展示了对话推理在数学和科学基准测试上的优越性能。", "motivation": "解决单语式推理模型在推理多样性和连贯性上的限制，这些模型往往重复使用固定策略或注意力不集中。", "method": "提出DialogueReason，一种基于代理、环境和交互的对话式推理方法，使用PPO算法和基于规则的奖励训练开源大型语言模型。", "result": "在MATH、AIME和GPQA数据集上的评估显示，对话推理模型在复杂复合问题上优于单语模型。", "conclusion": "对话式推理不仅提高了模型的性能，还增强了可解释性，促进了更直观的人机交互，并为多代理系统设计提供了启示。"}}
{"id": "2505.07087", "title": "Architectural Precedents for General Agents using Large Language Models", "authors": ["Robert E. Wray", "James R. Kirk", "John E. Laird"], "abstract": "One goal of AI (and AGI) is to identify and understand specific mechanisms and representations sufficient for general intelligence. Often, this work manifests in research focused on architectures and many cognitive architectures have been explored in AI/AGI. However, different research groups and even different research traditions have somewhat independently identified similar/common patterns of processes and representations or cognitive design patterns that are manifest in existing architectures. Today, AI systems exploiting large language models (LLMs) offer a relatively new combination of mechanism and representation available for exploring the possibilities of general intelligence. In this paper, we summarize a few recurring cognitive design patterns that have appeared in various pre-transformer AI architectures. We then explore how these patterns are evident in systems using LLMs, especially for reasoning and interactive (\"agentic\") use cases. By examining and applying these recurring patterns, we can also predict gaps or deficiencies in today's Agentic LLM Systems and identify likely subjects of future research towards general intelligence using LLMs and other generative foundation models.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "14 pages, 2 figures. Submitted to AGI25", "pdf_url": "https://arxiv.org/pdf/2505.07087.pdf", "abstract_url": "https://arxiv.org/abs/2505.07087", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文探讨了AI和AGI研究中识别和理解通用智能的特定机制和表示的目标，总结了预变换器AI架构中反复出现的认知设计模式，并探索了这些模式在利用大型语言模型（LLMs）的系统中的体现，尤其是在推理和交互式（“代理”）用例中。通过分析这些重复出现的模式，可以预测当前代理LLM系统的不足，并确定未来使用LLMs和其他生成基础模型研究通用智能的可能方向。", "motivation": "探索和识别能够实现通用智能的特定机制和表示，特别是在大型语言模型（LLMs）这一相对较新的机制和表示组合中，寻找和验证认知设计模式的体现，以推动AGI研究的发展。", "method": "总结了预变换器AI架构中反复出现的认知设计模式，并分析了这些模式在利用LLMs的系统中的体现，特别是在推理和交互式用例中的应用。", "result": "识别了当前代理LLM系统中存在的不足和可能的改进方向，为未来研究通用智能提供了潜在的探索路径。", "conclusion": "通过分析和应用重复出现的认知设计模式，可以指导未来使用LLMs和其他生成基础模型进行通用智能研究的方向，填补现有系统的不足。"}}
{"id": "2505.07233", "title": "DynamicRAG: Leveraging Outputs of Large Language Model as Feedback for Dynamic Reranking in Retrieval-Augmented Generation", "authors": ["Jiashuo Sun", "Xianrui Zhong", "Sizhe Zhou", "Jiawei Han"], "abstract": "Retrieval-augmented generation (RAG) systems combine large language models (LLMs) with external knowledge retrieval, making them highly effective for knowledge-intensive tasks. A crucial but often under-explored component of these systems is the reranker, which refines retrieved documents to enhance generation quality and explainability. The challenge of selecting the optimal number of documents (k) remains unsolved: too few may omit critical information, while too many introduce noise and inefficiencies. Although recent studies have explored LLM-based rerankers, they primarily leverage internal model knowledge and overlook the rich supervisory signals that LLMs can provide, such as using response quality as feedback for optimizing reranking decisions. In this paper, we propose DynamicRAG, a novel RAG framework where the reranker dynamically adjusts both the order and number of retrieved documents based on the query. We model the reranker as an agent optimized through reinforcement learning (RL), using rewards derived from LLM output quality. Across seven knowledge-intensive datasets, DynamicRAG demonstrates superior performance, achieving state-of-the-art results. The model, data and code are available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "24 pages, 6 figures, 15 tables", "pdf_url": "https://arxiv.org/pdf/2505.07233.pdf", "abstract_url": "https://arxiv.org/abs/2505.07233", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "DynamicRAG是一种新颖的检索增强生成（RAG）框架，通过利用大型语言模型（LLM）的输出作为反馈，动态调整检索文档的顺序和数量，以提高生成质量和可解释性。", "motivation": "解决在检索增强生成系统中，如何动态选择最优数量的检索文档（k）以避免信息遗漏或引入噪声的问题。", "method": "将重新排序器建模为通过强化学习（RL）优化的代理，利用从LLM输出质量中获得的奖励来优化重新排序决策。", "result": "在七个知识密集型数据集上，DynamicRAG展示了卓越的性能，达到了最先进的结果。", "conclusion": "DynamicRAG通过动态调整检索文档的顺序和数量，显著提高了RAG系统的性能，为知识密集型任务提供了有效的解决方案。"}}
{"id": "2505.07313", "title": "Towards Multi-Agent Reasoning Systems for Collaborative Expertise Delegation: An Exploratory Design Study", "authors": ["Baixuan Xu", "Chunyang Li", "Weiqi Wang", "Wei Fan", "Tianshi Zheng", "Haochen Shi", "Tao Fan", "Yangqiu Song", "Qiang Yang"], "abstract": "Designing effective collaboration structure for multi-agent LLM systems to enhance collective reasoning is crucial yet remains under-explored. In this paper, we systematically investigate how collaborative reasoning performance is affected by three key design dimensions: (1) Expertise-Domain Alignment, (2) Collaboration Paradigm (structured workflow vs. diversity-driven integration), and (3) System Scale. Our findings reveal that expertise alignment benefits are highly domain-contingent, proving most effective for contextual reasoning tasks. Furthermore, collaboration focused on integrating diverse knowledge consistently outperforms rigid task decomposition. Finally, we empirically explore the impact of scaling the multi-agent system with expertise specialization and study the computational trade off, highlighting the need for more efficient communication protocol design. This work provides concrete guidelines for configuring specialized multi-agent system and identifies critical architectural trade-offs and bottlenecks for scalable multi-agent reasoning. The code will be made available upon acceptance.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "18 pages", "pdf_url": "https://arxiv.org/pdf/2505.07313.pdf", "abstract_url": "https://arxiv.org/abs/2505.07313", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过系统研究三个关键设计维度（专业知识领域对齐、协作范式、系统规模）对协作推理性能的影响，发现专业知识对齐的效益高度依赖于领域，多样性驱动的知识整合协作范式优于刚性任务分解，并探讨了多智能体系统规模扩展的影响及计算权衡。", "motivation": "探索如何设计有效的多智能体LLM系统协作结构以增强集体推理能力，这一领域尚未充分探索。", "method": "系统研究了三个关键设计维度：专业知识领域对齐、协作范式（结构化工作流与多样性驱动整合）、系统规模，并进行了实证分析。", "result": "专业知识对齐的效益高度依赖于领域，多样性驱动的知识整合协作范式优于刚性任务分解，系统规模扩展需要更高效的通信协议设计。", "conclusion": "本研究为配置专业化的多智能体系统提供了具体指南，并指出了可扩展多智能体推理的关键架构权衡和瓶颈。"}}
{"id": "2505.07473", "title": "Web-Bench: A LLM Code Benchmark Based on Web Standards and Frameworks", "authors": ["Kai Xu", "YiWei Mao", "XinYi Guan", "ZiLong Feng"], "abstract": "The application of large language models (LLMs) in the field of coding is evolving rapidly: from code assistants, to autonomous coding agents, and then to generating complete projects through natural language. Early LLM code benchmarks primarily focused on code generation accuracy, but these benchmarks have gradually become saturated. Benchmark saturation weakens their guiding role for LLMs. For example, HumanEval Pass@1 has reached 99.4% and MBPP 94.2%. Among various attempts to address benchmark saturation, approaches based on software engineering have stood out, but the saturation of existing software engineering benchmarks is rapidly increasing. To address this, we propose a new benchmark, Web-Bench, which contains 50 projects, each consisting of 20 tasks with sequential dependencies. The tasks implement project features in sequence, simulating real-world human development workflows. When designing Web-Bench, we aim to cover the foundational elements of Web development: Web Standards and Web Frameworks. Given the scale and complexity of these projects, which were designed by engineers with 5 to 10 years of experience, each presents a significant challenge. On average, a single project takes 4 to 8 hours for a senior engineer to complete. On our given benchmark agent (Web-Agent), SOTA (Claude 3.7 Sonnet) achieves only 25.1% Pass@1, significantly lower (better) than SWE-Bench's Verified (65.4%) and Full (33.8%) scores. Finally, we discuss that in any development field, Standards and Frameworks represent foundational knowledge and efficiency tools, respectively, and LLMs require optimization tailored to them.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "28 pages, 15 figures", "pdf_url": "https://arxiv.org/pdf/2505.07473.pdf", "abstract_url": "https://arxiv.org/abs/2505.07473", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一个新的基准测试Web-Bench，旨在解决现有代码生成基准测试饱和的问题，专注于Web开发的基础元素：Web标准和框架。", "motivation": "随着大型语言模型(LLMs)在编码领域的应用迅速发展，早期的代码生成基准测试如HumanEval和MBPP已经饱和，减弱了对LLMs的指导作用。", "method": "Web-Bench包含50个项目，每个项目由20个具有顺序依赖性的任务组成，模拟真实的人类开发工作流程，旨在覆盖Web开发的基础元素。", "result": "在给定的基准代理(Web-Agent)上，SOTA(Claude 3.7 Sonnet)仅达到25.1%的Pass@1，显著低于SWE-Bench的Verified(65.4%)和Full(33.8%)分数。", "conclusion": "在任何开发领域，标准和框架分别代表基础知识和效率工具，LLMs需要针对它们进行优化。"}}
{"id": "2505.07215", "title": "Measuring General Intelligence with Generated Games", "authors": ["Vivek Verma", "David Huang", "William Chen", "Dan Klein", "Nicholas Tomlin"], "abstract": "We present gg-bench, a collection of game environments designed to evaluate general reasoning capabilities in language models. Unlike most static benchmarks, gg-bench is a data generating process where new evaluation instances can be generated at will. In particular, gg-bench is synthetically generated by (1) using a large language model (LLM) to generate natural language descriptions of novel games, (2) using the LLM to implement each game in code as a Gym environment, and (3) training reinforcement learning (RL) agents via self-play on the generated games. We evaluate language models by their winrate against these RL agents by prompting models with the game description, current board state, and a list of valid moves, after which models output the moves they wish to take. gg-bench is challenging: state-of-the-art LLMs such as GPT-4o and Claude 3.7 Sonnet achieve winrates of 7-9% on gg-bench using in-context learning, while reasoning models such as o1, o3-mini and DeepSeek-R1 achieve average winrates of 31-36%. We release the generated games, data generation process, and evaluation code in order to support future modeling work and expansion of our benchmark.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.07215.pdf", "abstract_url": "https://arxiv.org/abs/2505.07215", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了gg-bench，一个用于评估语言模型通用推理能力的游戏环境集合。与大多数静态基准不同，gg-bench是一个可以随时生成新评估实例的数据生成过程。通过使用大型语言模型（LLM）生成新游戏的自然语言描述，并将每个游戏实现为Gym环境，然后通过自我对弈训练强化学习（RL）代理。评估语言模型的方法是让模型根据游戏描述、当前棋盘状态和有效移动列表输出其希望采取的移动，并与这些RL代理的胜率进行比较。gg-bench具有挑战性：最先进的LLM如GPT-4o和Claude 3.7 Sonnet在使用上下文学习时的胜率为7-9%，而推理模型如o1、o3-mini和DeepSeek-R1的平均胜率为31-36%。", "motivation": "解决现有静态基准在评估语言模型通用推理能力方面的局限性，提供一个动态生成、可扩展的评估框架。", "method": "使用LLM生成游戏描述并实现为Gym环境，通过自我对弈训练RL代理，然后评估语言模型与这些代理的胜率。", "result": "最先进的LLM在gg-bench上的胜率较低（7-9%），而专门的推理模型表现更好（31-36%）。", "conclusion": "gg-bench为评估和提升语言模型的通用推理能力提供了一个有效的工具，同时揭示了当前LLM在这一领域的局限性。"}}
{"id": "2505.07581", "title": "YuLan-OneSim: Towards the Next Generation of Social Simulator with Large Language Models", "authors": ["Lei Wang", "Heyang Gao", "Xiaohe Bo", "Xu Chen", "Ji-Rong Wen"], "abstract": "Leveraging large language model (LLM) based agents to simulate human social behaviors has recently gained significant attention. In this paper, we introduce a novel social simulator called YuLan-OneSim. Compared to previous works, YuLan-OneSim distinguishes itself in five key aspects: (1) Code-free scenario construction: Users can simply describe and refine their simulation scenarios through natural language interactions with our simulator. All simulation code is automatically generated, significantly reducing the need for programming expertise. (2) Comprehensive default scenarios: We implement 50 default simulation scenarios spanning 8 domains, including economics, sociology, politics, psychology, organization, demographics, law, and communication, broadening access for a diverse range of social researchers. (3) Evolvable simulation: Our simulator is capable of receiving external feedback and automatically fine-tuning the backbone LLMs, significantly enhancing the simulation quality. (4) Large-scale simulation: By developing a fully responsive agent framework and a distributed simulation architecture, our simulator can handle up to 100,000 agents, ensuring more stable and reliable simulation results. (5) AI social researcher: Leveraging the above features, we develop an AI social researcher. Users only need to propose a research topic, and the AI researcher will automatically analyze the input, construct simulation environments, summarize results, generate technical reports, review and refine the reports--completing the social science research loop. To demonstrate the advantages of YuLan-OneSim, we conduct experiments to evaluate the quality of the automatically generated scenarios, the reliability, efficiency, and scalability of the simulation process, as well as the performance of the AI social researcher.", "subjects": "Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.07581.pdf", "abstract_url": "https://arxiv.org/abs/2505.07581", "categories": ["Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)"], "matching_keywords": ["agent"], "AI": {"tldr": "YuLan-OneSim是一种基于大型语言模型（LLM）的新型社交模拟器，通过自然语言交互实现无代码场景构建，提供50个默认场景，支持可进化模拟和大规模模拟，并开发了AI社交研究员功能。", "motivation": "解决传统社交模拟器需要编程专业知识、场景有限、模拟质量不高、规模受限等问题，为社会科学研究提供更便捷、高效的工具。", "method": "开发了YuLan-OneSim社交模拟器，包括无代码场景构建、默认场景库、可进化模拟、大规模模拟架构和AI社交研究员等功能。", "result": "实验评估显示，YuLan-OneSim在自动生成场景质量、模拟过程的可靠性、效率和可扩展性以及AI社交研究员的性能方面具有优势。", "conclusion": "YuLan-OneSim为下一代社交模拟器设定了新标准，通过LLM技术显著提升了社交模拟的便捷性、质量和规模，有望推动社会科学研究的发展。"}}
{"id": "2505.07528", "title": "SEReDeEP: Hallucination Detection in Retrieval-Augmented Models via Semantic Entropy and Context-Parameter Fusion", "authors": ["Lei Wang"], "abstract": "Retrieval-Augmented Generation (RAG) models frequently encounter hallucination phenomena when integrating external information with internal parametric knowledge. Empirical studies demonstrate that the disequilibrium between external contextual information and internal parametric knowledge constitutes a primary factor in hallucination generation. Existing hallucination detection methodologies predominantly emphasize either the external or internal mechanism in isolation, thereby overlooking their synergistic effects. The recently proposed ReDeEP framework decouples these dual mechanisms, identifying two critical contributors to hallucinations: excessive reliance on parametric knowledge encoded in feed-forward networks (FFN) and insufficient utilization of external information by attention mechanisms (particularly copy heads). ReDeEP quantitatively assesses these factors to detect hallucinations and dynamically modulates the contributions of FFNs and copy heads to attenuate their occurrence. Nevertheless, ReDeEP and numerous other hallucination detection approaches have been employed at logit-level uncertainty estimation or language-level self-consistency evaluation, inadequately address the semantic dimensions of model responses, resulting in inconsistent hallucination assessments in RAG implementations. Building upon ReDeEP's foundation, this paper introduces SEReDeEP, which enhances computational processes through semantic entropy captured via trained linear probes, thereby achieving hallucination assessments that more accurately reflect ground truth evaluations.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.07528.pdf", "abstract_url": "https://arxiv.org/abs/2505.07528", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "SEReDeEP通过语义熵和上下文-参数融合检测检索增强模型中的幻觉现象，改进了现有方法在语义维度上的不足。", "motivation": "检索增强生成（RAG）模型在整合外部信息和内部参数知识时经常出现幻觉现象，现有方法未能充分考虑外部和内部机制的协同效应。", "method": "SEReDeEP利用训练好的线性探针捕获语义熵，增强计算过程，实现更准确的幻觉评估。", "result": "SEReDeEP能够更准确地反映真实评估，有效检测和减少RAG模型中的幻觉现象。", "conclusion": "SEReDeEP通过改进语义维度的评估，为RAG模型中的幻觉检测提供了更有效的解决方案。"}}
{"id": "2505.07637", "title": "Chronocept: Instilling a Sense of Time in Machines", "authors": ["Krish Goel", "Sanskar Pandey", "KS Mahadevan", "Harsh Kumar", "Vishesh Khadaria"], "abstract": "Human cognition is deeply intertwined with a sense of time, known as Chronoception. This sense allows us to judge how long facts remain valid and when knowledge becomes outdated. Despite progress in vision, language, and motor control, AI still struggles to reason about temporal validity. We introduce Chronocept, the first benchmark to model temporal validity as a continuous probability distribution over time. Using skew-normal curves fitted along semantically decomposed temporal axes, Chronocept captures nuanced patterns of emergence, decay, and peak relevance. It includes two datasets: Benchmark I (atomic facts) and Benchmark II (multi-sentence passages). Annotations show strong inter-annotator agreement (84% and 89%). Our baselines predict curve parameters - location, scale, and skewness - enabling interpretable, generalizable learning and outperforming classification-based approaches. Chronocept fills a foundational gap in AI's temporal reasoning, supporting applications in knowledge grounding, fact-checking, retrieval-augmented generation (RAG), and proactive agents. Code and data are publicly available.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "20 pages, 8 figures, 18 tables", "pdf_url": "https://arxiv.org/pdf/2505.07637.pdf", "abstract_url": "https://arxiv.org/abs/2505.07637", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文介绍了Chronocept，第一个将时间有效性建模为随时间连续概率分布的基准，旨在解决AI在时间推理方面的不足。", "motivation": "人类认知与时间感（Chronoception）密切相关，但AI在判断事实有效性和知识过时方面仍有困难。", "method": "使用沿语义分解的时间轴拟合的偏态正态曲线，捕捉出现、衰减和峰值相关性的细微模式，包括两个数据集。", "result": "注释显示出强烈的注释者间一致性（84%和89%），基线预测曲线参数（位置、规模和偏态），优于基于分类的方法。", "conclusion": "Chronocept填补了AI时间推理的基础性空白，支持知识基础、事实核查、检索增强生成（RAG）和主动代理等应用。"}}
{"id": "2505.07596", "title": "Reinforced Internal-External Knowledge Synergistic Reasoning for Efficient Adaptive Search Agent", "authors": ["Ziyang Huang", "Xiaowei Yuan", "Yiming Ju", "Jun Zhao", "Kang Liu"], "abstract": "Retrieval-augmented generation (RAG) is a common strategy to reduce hallucinations in Large Language Models (LLMs). While reinforcement learning (RL) can enable LLMs to act as search agents by activating retrieval capabilities, existing ones often underutilize their internal knowledge. This can lead to redundant retrievals, potential harmful knowledge conflicts, and increased inference latency. To address these limitations, an efficient and adaptive search agent capable of discerning optimal retrieval timing and synergistically integrating parametric (internal) and retrieved (external) knowledge is in urgent need. This paper introduces the Reinforced Internal-External Knowledge Synergistic Reasoning Agent (IKEA), which could indentify its own knowledge boundary and prioritize the utilization of internal knowledge, resorting to external search only when internal knowledge is deemed insufficient. This is achieved using a novel knowledge-boundary aware reward function and a knowledge-boundary aware training dataset. These are designed for internal-external knowledge synergy oriented RL, incentivizing the model to deliver accurate answers, minimize unnecessary retrievals, and encourage appropriate external searches when its own knowledge is lacking. Evaluations across multiple knowledge reasoning tasks demonstrate that IKEA significantly outperforms baseline methods, reduces retrieval frequency significantly, and exhibits robust generalization capabilities.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.07596.pdf", "abstract_url": "https://arxiv.org/abs/2505.07596", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文介绍了强化内外知识协同推理代理（IKEA），旨在通过识别自身知识边界并优先利用内部知识，仅在内部知识不足时进行外部搜索，以减少大型语言模型中的幻觉问题。", "motivation": "解决现有检索增强生成（RAG）策略中大型语言模型（LLMs）作为搜索代理时未充分利用内部知识，导致冗余检索、潜在有害知识冲突和增加推理延迟的问题。", "method": "采用一种新颖的知识边界感知奖励函数和训练数据集，面向内外知识协同的强化学习（RL），激励模型提供准确答案，减少不必要的检索，并在内部知识不足时鼓励适当的外部搜索。", "result": "在多个知识推理任务上的评估表明，IKEA显著优于基线方法，显著减少了检索频率，并展现出强大的泛化能力。", "conclusion": "IKEA通过有效整合内部和外部知识，为大型语言模型提供了一种高效、自适应的搜索代理解决方案，具有重要的实践意义。"}}
{"id": "2505.07671", "title": "Benchmarking Retrieval-Augmented Generation for Chemistry", "authors": ["Xianrui Zhong", "Bowen Jin", "Siru Ouyang", "Yanzhen Shen", "Qiao Jin", "Yin Fang", "Zhiyong Lu", "Jiawei Han"], "abstract": "Retrieval-augmented generation (RAG) has emerged as a powerful framework for enhancing large language models (LLMs) with external knowledge, particularly in scientific domains that demand specialized and dynamic information. Despite its promise, the application of RAG in the chemistry domain remains underexplored, primarily due to the lack of high-quality, domain-specific corpora and well-curated evaluation benchmarks. In this work, we introduce ChemRAG-Bench, a comprehensive benchmark designed to systematically assess the effectiveness of RAG across a diverse set of chemistry-related tasks. The accompanying chemistry corpus integrates heterogeneous knowledge sources, including scientific literature, the PubChem database, PubMed abstracts, textbooks, and Wikipedia entries. In addition, we present ChemRAG-Toolkit, a modular and extensible RAG toolkit that supports five retrieval algorithms and eight LLMs. Using ChemRAG-Toolkit, we demonstrate that RAG yields a substantial performance gain -- achieving an average relative improvement of 17.4% over direct inference methods. We further conduct in-depth analyses on retriever architectures, corpus selection, and the number of retrieved passages, culminating in practical recommendations to guide future research and deployment of RAG systems in the chemistry domain. The code and data is available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.07671.pdf", "abstract_url": "https://arxiv.org/abs/2505.07671", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了ChemRAG-Bench，一个用于评估化学领域检索增强生成（RAG）效果的全面基准，以及ChemRAG-Toolkit，一个支持多种检索算法和大型语言模型（LLM）的工具包。研究表明，RAG在化学相关任务中比直接推理方法平均提高了17.4%的性能。", "motivation": "尽管检索增强生成（RAG）在科学领域显示出增强大型语言模型（LLM）的潜力，但在化学领域的应用仍未被充分探索，主要原因是缺乏高质量的领域特定语料库和精心策划的评估基准。", "method": "本研究引入了ChemRAG-Bench基准和ChemRAG-Toolkit工具包，后者支持五种检索算法和八种LLM，用于评估RAG在化学任务中的效果。", "result": "使用ChemRAG-Toolkit进行的实验显示，RAG方法比直接推理方法平均提高了17.4%的性能。", "conclusion": "本研究不仅为化学领域的RAG应用提供了实用的工具和基准，还通过深入分析提出了指导未来研究和部署RAG系统的建议。"}}
{"id": "2505.07705", "title": "Codifying Character Logic in Role-Playing", "authors": ["Letian Peng", "Jingbo Shang"], "abstract": "This paper introduces Codified Profiles for role-playing, a novel approach that represents character logic as structured, executable functions for behavioral decision-making. Each profile defines a set of functions parse_by_scene(scene) that outputs a list of logic-grounded assertions triggered_statements, using both explicit control structures (e.g., if-then-else) and condition checks like check_condition(scene, question), where each question is a semantically meaningful prompt about the scene (e.g., \"Is the character in danger?\") discriminated by the role-playing LLM as true, false, or unknown. This explicit representation offers three key advantages over traditional prompt-based profiles, which append character descriptions directly into text prompts: (1) Persistence, by enforcing complete and consistent execution of character logic, rather than relying on the model's implicit reasoning; (2) Updatability, through systematic inspection and revision of behavioral logic, which is difficult to track or debug in prompt-only approaches; (3) Controllable Randomness, by supporting stochastic behavior directly within the logic, enabling fine-grained variability that prompting alone struggles to achieve. To validate these advantages, we introduce a new benchmark constructed from 83 characters and 5,141 scenes curated from Fandom, using NLI-based scoring to compare character responses against ground-truth actions. Our experiments demonstrate the significant benefits of codified profiles in improving persistence, updatability, and behavioral diversity. Notably, by offloading a significant portion of reasoning to preprocessing, codified profiles enable even 1B-parameter models to perform high-quality role-playing, providing a scalable and efficient foundation for local deployment of role-play agents.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.07705.pdf", "abstract_url": "https://arxiv.org/abs/2505.07705", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了角色扮演中的编码化角色逻辑，提出了一种新颖的方法——编码化配置文件，将角色逻辑表示为结构化的、可执行的函数，用于行为决策。", "motivation": "解决传统基于提示的角色描述方法在持久性、可更新性和可控随机性方面的不足。", "method": "使用编码化配置文件，定义了一组函数parse_by_scene(scene)，输出基于逻辑的断言triggered_statements，结合显式控制结构和条件检查。", "result": "实验证明，编码化配置文件在提高持久性、可更新性和行为多样性方面具有显著优势，即使是10亿参数模型也能实现高质量的角色扮演。", "conclusion": "编码化配置文件为角色扮演代理的本地部署提供了可扩展和高效的基础，通过预处理卸载大量推理任务。"}}
{"id": "2505.07693", "title": "Belief Injection for Epistemic Control in Linguistic State Space", "authors": ["Sebastian Dumbrava"], "abstract": "This work introduces belief injection, a proactive epistemic control mechanism for artificial agents whose cognitive states are structured as dynamic ensembles of linguistic belief fragments. Grounded in the Semantic Manifold framework, belief injection directly incorporates targeted linguistic beliefs into an agent's internal cognitive state, influencing reasoning and alignment proactively rather than reactively. We delineate various injection strategies, such as direct, context-aware, goal-oriented, and reflective approaches, and contrast belief injection with related epistemic control mechanisms, notably belief filtering. Additionally, this work discusses practical applications, implementation considerations, ethical implications, and outlines promising directions for future research into cognitive governance using architecturally embedded belief injection.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "30 pages, 9 figures", "pdf_url": "https://arxiv.org/pdf/2505.07693.pdf", "abstract_url": "https://arxiv.org/abs/2505.07693", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了信念注入，一种主动认知控制机制，用于结构化为动态语言信念片段集合的人工智能体。基于语义流形框架，信念注入直接将目标语言信念纳入代理的内部认知状态，主动而非被动地影响推理和对齐。", "motivation": "解决人工智能体在认知状态管理中如何主动而非被动地影响其推理和对齐的问题。", "method": "提出了多种注入策略，包括直接、上下文感知、目标导向和反思性方法，并与信念过滤等相关认知控制机制进行对比。", "result": "明确了信念注入作为一种主动认知控制机制的有效性，并讨论了其实际应用、实施考虑和伦理影响。", "conclusion": "信念注入为认知治理提供了新的研究方向，特别是在架构嵌入的信念注入方面，展示了广阔的应用前景和未来研究方向。"}}
{"id": "2505.07757", "title": "Emotion-Gradient Metacognitive RSI (Part I): Theoretical Foundations and Single-Agent Architecture", "authors": ["Rintaro Ando"], "abstract": "We present the Emotion-Gradient Metacognitive Recursive Self-Improvement (EG-MRSI) framework, a novel architecture that integrates introspective metacognition, emotion-based intrinsic motivation, and recursive self-modification into a unified theoretical system. The framework is explicitly capable of overwriting its own learning algorithm under formally bounded risk. Building upon the Noise-to-Meaning RSI (N2M-RSI) foundation, EG-MRSI introduces a differentiable intrinsic reward function driven by confidence, error, novelty, and cumulative success. This signal regulates both a metacognitive mapping and a self-modification operator constrained by provable safety mechanisms. We formally define the initial agent configuration, emotion-gradient dynamics, and RSI trigger conditions, and derive a reinforcement-compatible optimization objective that guides the agent's development trajectory. Meaning Density and Meaning Conversion Efficiency are introduced as quantifiable metrics of semantic learning, closing the gap between internal structure and predictive informativeness. This Part I paper establishes the single-agent theoretical foundations of EG-MRSI. Future parts will extend this framework to include safety certificates and rollback protocols (Part II), collective intelligence mechanisms (Part III), and feasibility constraints including thermodynamic and computational limits (Part IV). Together, the EG-MRSI series provides a rigorous, extensible foundation for open-ended and safe AGI.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "21 pages, 3 figures. Part I of a four-part series (Parts II-IV forthcoming)", "pdf_url": "https://arxiv.org/pdf/2505.07757.pdf", "abstract_url": "https://arxiv.org/abs/2505.07757", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了情感梯度元认知递归自我改进（EG-MRSI）框架，这是一个整合了内省元认知、基于情感的内在动机和递归自我修改的统一理论系统。该框架能够在形式上有限的风险下覆盖自身的学习算法。", "motivation": "解决开放性和安全性人工通用智能（AGI）的理论基础问题，通过引入情感梯度和元认知机制，以指导代理的发展轨迹并确保其安全性。", "method": "基于噪声到意义的RSI（N2M-RSI）基础，EG-MRSI引入了一个由信心、错误、新颖性和累积成功驱动的可微分内在奖励函数，该信号调节元认知映射和受可证明安全机制约束的自我修改操作符。", "result": "定义了初始代理配置、情感梯度动态和RSI触发条件，并推导了一个与强化兼容的优化目标，指导代理的发展轨迹。引入了意义密度和意义转换效率作为语义学习的量化指标。", "conclusion": "EG-MRSI系列为开放性和安全的AGI提供了一个严格、可扩展的基础，未来的工作将扩展这一框架以包括安全证书和回滚协议、集体智能机制以及热力学和计算限制等可行性约束。"}}
{"id": "2505.07500", "title": "Learning to Reason and Navigate: Parameter Efficient Action Planning with Large Language Models", "authors": ["Bahram Mohammadi", "Ehsan Abbasnejad", "Yuankai Qi", "Qi Wu", "Anton Van Den Hengel", "Javen Qinfeng Shi"], "abstract": "The remote embodied referring expression (REVERIE) task requires an agent to navigate through complex indoor environments and localize a remote object specified by high-level instructions, such as \"bring me a spoon\", without pre-exploration. Hence, an efficient navigation plan is essential for the final success. This paper proposes a novel parameter-efficient action planner using large language models (PEAP-LLM) to generate a single-step instruction at each location. The proposed model consists of two modules, LLM goal planner (LGP) and LoRA action planner (LAP). Initially, LGP extracts the goal-oriented plan from REVERIE instructions, including the target object and room. Then, LAP generates a single-step instruction with the goal-oriented plan, high-level instruction, and current visual observation as input. PEAP-LLM enables the embodied agent to interact with LAP as the path planner on the fly. A simple direct application of LLMs hardly achieves good performance. Also, existing hard-prompt-based methods are error-prone in complicated scenarios and need human intervention. To address these issues and prevent the LLM from generating hallucinations and biased information, we propose a novel two-stage method for fine-tuning the LLM, consisting of supervised fine-tuning (STF) and direct preference optimization (DPO). SFT improves the quality of generated instructions, while DPO utilizes environmental feedback. Experimental results show the superiority of our proposed model on REVERIE compared to the previous state-of-the-art.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.07500.pdf", "abstract_url": "https://arxiv.org/abs/2505.07500", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新颖的参数高效动作规划器（PEAP-LLM），利用大型语言模型（LLM）在复杂室内环境中为远程具体指代表达（REVERIE）任务生成单步指令，通过两阶段微调方法提升性能。", "motivation": "解决在复杂室内环境中，基于高级指令导航并定位远程物体时，现有方法性能不佳、易出错且需要人工干预的问题。", "method": "提出PEAP-LLM模型，包含LLM目标规划器（LGP）和LoRA动作规划器（LAP）两个模块，采用监督微调（SFT）和直接偏好优化（DPO）两阶段方法微调LLM。", "result": "实验结果表明，所提模型在REVERIE任务上优于现有最先进方法。", "conclusion": "PEAP-LLM通过高效的动作规划和两阶段微调方法，显著提升了在复杂环境中导航和定位任务的性能，为远程具体指代表达任务提供了有效的解决方案。"}}
{"id": "2505.07773", "title": "Agent RL Scaling Law: Agent RL with Spontaneous Code Execution for Mathematical Problem Solving", "authors": ["Xinji Mai", "Haotian Xu", "Xing W", "Weinong Wang", "Yingying Zhang", "Wenqiang Zhang"], "abstract": "Large Language Models (LLMs) often struggle with mathematical reasoning tasks requiring precise, verifiable computation. While Reinforcement Learning (RL) from outcome-based rewards enhances text-based reasoning, understanding how agents autonomously learn to leverage external tools like code execution remains crucial. We investigate RL from outcome-based rewards for Tool-Integrated Reasoning, ZeroTIR, training base LLMs to spontaneously generate and execute Python code for mathematical problems without supervised tool-use examples. Our central contribution is we demonstrate that as RL training progresses, key metrics scale predictably. Specifically, we observe strong positive correlations where increased training steps lead to increases in the spontaneous code execution frequency, the average response length, and, critically, the final task accuracy. This suggests a quantifiable relationship between computational effort invested in training and the emergence of effective, tool-augmented reasoning strategies. We implement a robust framework featuring a decoupled code execution environment and validate our findings across standard RL algorithms and frameworks. Experiments show ZeroTIR significantly surpasses non-tool ZeroRL baselines on challenging math benchmarks. Our findings provide a foundational understanding of how autonomous tool use is acquired and scales within Agent RL, offering a reproducible benchmark for future studies. Code is released at \\href{", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.07773.pdf", "abstract_url": "https://arxiv.org/abs/2505.07773", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究了基于结果奖励的强化学习（RL）在工具集成推理（Tool-Integrated Reasoning）中的应用，特别是训练基础大型语言模型（LLMs）自发生成和执行Python代码以解决数学问题，而无需监督工具使用示例。研究发现，随着RL训练的进行，关键指标如自发性代码执行频率、平均响应长度和最终任务准确性呈现出可预测的缩放规律。", "motivation": "大型语言模型（LLMs）在需要精确、可验证计算的数学推理任务中常常表现不佳。本文旨在探索如何通过基于结果奖励的强化学习，使代理能够自主学习和利用外部工具（如代码执行）来提升数学问题解决能力。", "method": "本文提出了一种名为ZeroTIR的方法，通过强化学习训练基础LLMs，使其能够自发生成和执行Python代码来解决数学问题。研究采用了一个解耦的代码执行环境，并在标准的RL算法和框架上验证了方法的有效性。", "result": "实验结果表明，ZeroTIR在具有挑战性的数学基准测试中显著优于不使用工具的ZeroRL基线方法。研究还发现，随着训练步骤的增加，自发性代码执行频率、平均响应长度和任务准确性等关键指标呈现出强正相关关系。", "conclusion": "本研究为理解自主工具使用在Agent RL中如何被获取和缩放提供了基础性认识，为未来研究提供了一个可复现的基准。研究代码已公开发布。"}}
{"id": "2505.07365", "title": "Multi-Domain Audio Question Answering Toward Acoustic Content Reasoning in The DCASE 2025 Challenge", "authors": ["Chao-Han Huck Yang", "Sreyan Ghosh", "Qing Wang", "Jaeyeon Kim", "Hengyi Hong", "Sonal Kumar", "Guirui Zhong", "Zhifeng Kong", "S Sakshi", "Vaibhavi Lokegaonkar", "Oriol Nieto", "Ramani Duraiswami", "Dinesh Manocha", "Gunhee Kim", "Jun Du", "Rafael Valle", "Bryan Catanzaro"], "abstract": "We present Task 5 of the DCASE 2025 Challenge: an Audio Question Answering (AQA) benchmark spanning multiple domains of sound understanding. This task defines three QA subsets (Bioacoustics, Temporal Soundscapes, and Complex QA) to test audio-language models on interactive question-answering over diverse acoustic scenes. We describe the dataset composition (from marine mammal calls to soundscapes and complex real-world clips), the evaluation protocol (top-1 accuracy with answer-shuffling robustness), and baseline systems (Qwen2-Audio-7B, AudioFlamingo 2, Gemini-2-Flash). Preliminary results on the development set are compared, showing strong variation across models and subsets. This challenge aims to advance the audio understanding and reasoning capabilities of audio-language models toward human-level acuity, which are crucial for enabling AI agents to perceive and interact about the world effectively.", "subjects": "Sound (cs.SD); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Multimedia (cs.MM); Audio and Speech Processing (eess.AS)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.07365.pdf", "abstract_url": "https://arxiv.org/abs/2505.07365", "categories": ["Sound (cs.SD)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Multimedia (cs.MM)", "Audio and Speech Processing (eess.AS)"], "matching_keywords": ["agent"], "AI": {"tldr": "DCASE 2025挑战赛的任务5：一个跨越多个声音理解领域的音频问答基准，旨在测试音频-语言模型在多样化声学场景下的交互式问答能力。", "motivation": "提升音频-语言模型在理解和推理声学内容方面的能力，使其达到人类水平，这对于使AI代理能够有效地感知和与世界互动至关重要。", "method": "定义了三个QA子集（生物声学、时间声景和复杂QA），使用来自不同领域的声学场景数据集，评估协议包括top-1准确性和答案混洗鲁棒性，并比较了基线系统在开发集上的初步结果。", "result": "不同模型和子集之间的表现存在显著差异，展示了音频问答任务的多样性和挑战性。", "conclusion": "该挑战旨在推动音频-语言模型在声学内容理解和推理方面的进步，为AI代理的有效感知和互动能力奠定基础。"}}
{"id": "2505.06313", "title": "AI Approaches to Qualitative and Quantitative News Analytics on NATO Unity", "authors": ["Bohdan M. Pavlyshenko"], "abstract": "The paper considers the use of GPT models with retrieval-augmented generation (RAG) for qualitative and quantitative analytics on NATO sentiments, NATO unity and NATO Article 5 trust opinion scores in different web sources: news sites found via Google Search API, Youtube videos with comments, and Reddit discussions. A RAG approach using GPT-4.1 model was applied to analyse news where NATO related topics were discussed. Two levels of RAG analytics were used: on the first level, the GPT model generates qualitative news summaries and quantitative opinion scores using zero-shot prompts; on the second level, the GPT model generates the summary of news summaries. Quantitative news opinion scores generated by the GPT model were analysed using Bayesian regression to get trend lines. The distributions found for the regression parameters make it possible to analyse an uncertainty in specified news opinion score trends. Obtained results show a downward trend for analysed scores of opinion related to NATO unity.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Social and Information Networks (cs.SI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.06313.pdf", "abstract_url": "https://arxiv.org/abs/2505.06313", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Social and Information Networks (cs.SI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文探讨了使用GPT模型与检索增强生成（RAG）技术对北约情感、北约团结及北约第五条信任意见分数在不同网络来源（通过Google搜索API找到的新闻网站、带有评论的Youtube视频和Reddit讨论）进行定性和定量分析。应用GPT-4.1模型的RAG方法分析了讨论北约相关话题的新闻。", "motivation": "解决如何有效分析网络来源中关于北约的情感、团结和信任意见分数的问题，以提供更深入的理解和趋势分析。", "method": "采用GPT-4.1模型与RAG技术进行两层次分析：第一层次使用零样本提示生成定性新闻摘要和定量意见分数；第二层次生成新闻摘要的摘要。定量新闻意见分数通过贝叶斯回归分析趋势线。", "result": "分析结果显示，与北约团结相关的意见分数呈现下降趋势。回归参数的分布使得分析指定新闻意见分数趋势的不确定性成为可能。", "conclusion": "研究表明，GPT模型与RAG技术结合可以有效分析北约相关新闻的情感趋势，为理解公众意见提供量化工具。"}}
{"id": "2505.06311", "title": "Defending against Indirect Prompt Injection by Instruction Detection", "authors": ["Tongyu Wen", "Chenglong Wang", "Xiyuan Yang", "Haoyu Tang", "Yueqi Xie", "Lingjuan Lyu", "Zhicheng Dou", "Fangzhao Wu"], "abstract": "The integration of Large Language Models (LLMs) with external sources is becoming increasingly common, with Retrieval-Augmented Generation (RAG) being a prominent example. However, this integration introduces vulnerabilities of Indirect Prompt Injection (IPI) attacks, where hidden instructions embedded in external data can manipulate LLMs into executing unintended or harmful actions. We recognize that the success of IPI attacks fundamentally relies in the presence of instructions embedded within external content, which can alter the behavioral state of LLMs. Can effectively detecting such state changes help us defend against IPI attacks? In this paper, we propose a novel approach that takes external data as input and leverages the behavioral state of LLMs during both forward and backward propagation to detect potential IPI attacks. Specifically, we demonstrate that the hidden states and gradients from intermediate layers provide highly discriminative features for instruction detection. By effectively combining these features, our approach achieves a detection accuracy of 99.60\\% in the in-domain setting and 96.90\\% in the out-of-domain setting, while reducing the attack success rate to just 0.12\\% on the BIPIA benchmark.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": "13 pages, 4 figures", "pdf_url": "https://arxiv.org/pdf/2505.06311.pdf", "abstract_url": "https://arxiv.org/abs/2505.06311", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种通过指令检测防御间接提示注入攻击的新方法，利用大型语言模型在前向和后向传播中的行为状态变化来检测潜在攻击，实现了高检测准确率和低攻击成功率。", "motivation": "随着大型语言模型（LLMs）与外部资源的整合日益普遍，如检索增强生成（RAG），间接提示注入（IPI）攻击的漏洞也随之出现，其中隐藏的指令可以操纵LLMs执行非预期或有害操作。本文旨在解决这一问题。", "method": "本文提出了一种新颖的方法，通过分析LLMs在前向和后向传播中的行为状态变化，特别是中间层的隐藏状态和梯度，来检测外部数据中的潜在IPI攻击指令。", "result": "该方法在域内设置下实现了99.60%的检测准确率，在域外设置下为96.90%，同时在BIPIA基准测试中将攻击成功率降低至仅0.12%。", "conclusion": "通过有效检测LLMs行为状态的变化，可以显著提高对IPI攻击的防御能力，本文提出的方法为实现这一目标提供了有效的途径。"}}
{"id": "2505.06312", "title": "Responsibility Gap in Collective Decision Making", "authors": ["Pavel Naumov", "Jia Tao"], "abstract": "The responsibility gap is a set of outcomes of a collective decision-making mechanism in which no single agent is individually responsible. In general, when designing a decision-making process, it is desirable to minimise the gap.", "subjects": "Computer Science and Game Theory (cs.GT); Artificial Intelligence (cs.AI)", "comments": "full version of an IJCAI-25 paper", "pdf_url": "https://arxiv.org/pdf/2505.06312.pdf", "abstract_url": "https://arxiv.org/abs/2505.06312", "categories": ["Computer Science and Game Theory (cs.GT)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "集体决策中的责任间隙是指一种集体决策机制的结果集，其中没有单一代理人承担个体责任。在设计决策过程时，通常希望最小化这种间隙。", "motivation": "解决集体决策机制中责任分配不明确的问题，旨在减少或消除责任间隙，以提高决策过程的效率和公正性。", "method": "分析集体决策机制中责任间隙的产生原因及其影响，探讨如何通过设计优化决策过程来最小化责任间隙。", "result": "识别了责任间隙的存在及其对集体决策的潜在负面影响，提出了通过机制设计减少责任间隙的可能性。", "conclusion": "最小化责任间隙对于提高集体决策的质量和公正性至关重要，未来的研究应探索更多具体的机制设计策略来实现这一目标。"}}
{"id": "2505.06314", "title": "A4L: An Architecture for AI-Augmented Learning", "authors": ["Ashok Goel", "Ploy Thajchayapong", "Vrinda Nandan", "Harshvardhan Sikka", "Spencer Rugaber"], "abstract": "AI promises personalized learning and scalable education. As AI agents increasingly permeate education in support of teaching and learning, there is a critical and urgent need for data architectures for collecting and analyzing data on learning, and feeding the results back to teachers, learners, and the AI agents for personalization of learning at scale. At the National AI Institute for Adult Learning and Online Education, we are developing an Architecture for AI-Augmented Learning (A4L) for supporting adult learning through online education. We present the motivations, goals, requirements of the A4L architecture. We describe preliminary applications of A4L and discuss how it advances the goals of making learning more personalized and scalable.", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI)", "comments": "14 pages, 7 figures", "pdf_url": "https://arxiv.org/pdf/2505.06314.pdf", "abstract_url": "https://arxiv.org/abs/2505.06314", "categories": ["Computers and Society (cs.CY)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了A4L（AI增强学习架构），旨在通过AI技术实现个性化学习和可扩展教育。该架构支持成人通过在线教育学习，收集和分析学习数据，并将结果反馈给教师、学习者和AI代理，以实现大规模个性化学习。", "motivation": "解决AI在教育中应用时，如何有效收集和分析学习数据，以及如何将这些数据反馈给教师、学习者和AI代理，以实现个性化学习和教育规模化的问题。", "method": "开发A4L架构，支持成人在线学习，包括数据收集、分析和反馈机制。", "result": "初步应用展示了A4L如何促进学习个性化和规模化目标的实现。", "conclusion": "A4L架构为AI在教育中的应用提供了有效的数据支持，有助于实现个性化学习和教育的规模化，具有重要的实践意义和发展潜力。"}}
{"id": "2505.06315", "title": "Threat Modeling for AI: The Case for an Asset-Centric Approach", "authors": ["Jose Sanchez Vicarte", "Marcin Spoczynski", "Mostafa Elsaid"], "abstract": "Recent advances in AI are transforming AI's ubiquitous presence in our world from that of standalone AI-applications into deeply integrated AI-agents. These changes have been driven by agents' increasing capability to autonomously make decisions and initiate actions, using existing applications; whether those applications are AI-based or not. This evolution enables unprecedented levels of AI integration, with agents now able to take actions on behalf of systems and users -- including, in some cases, the powerful ability for the AI to write and execute scripts as it deems necessary. With AI systems now able to autonomously execute code, interact with external systems, and operate without human oversight, traditional security approaches fall short.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.06315.pdf", "abstract_url": "https://arxiv.org/abs/2505.06315", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了AI威胁建模的必要性，并提出了一种以资产为中心的方法。", "motivation": "随着AI技术的进步，AI代理能够自主做出决策并执行操作，这导致了传统安全方法的不足。", "method": "提出了一种以资产为中心的威胁建模方法。", "result": "该方法能够更好地应对AI系统自主执行代码、与外部系统交互及无人类监督操作带来的安全挑战。", "conclusion": "以资产为中心的威胁建模方法为解决AI集成中的安全问题提供了新的视角和解决方案。"}}
{"id": "2505.06621", "title": "Minimizing Risk Through Minimizing Model-Data Interaction: A Protocol For Relying on Proxy Tasks When Designing Child Sexual Abuse Imagery Detection Models", "authors": ["Thamiris Coelho", "Leo S. F. Ribeiro", "João Macedo", "Jefersson A. dos Santos", "Sandra Avila"], "abstract": "The distribution of child sexual abuse imagery (CSAI) is an ever-growing concern of our modern world; children who suffered from this heinous crime are revictimized, and the growing amount of illegal imagery distributed overwhelms law enforcement agents (LEAs) with the manual labor of categorization. To ease this burden researchers have explored methods for automating data triage and detection of CSAI, but the sensitive nature of the data imposes restricted access and minimal interaction between real data and learning algorithms, avoiding leaks at all costs. In observing how these restrictions have shaped the literature we formalize a definition of \"Proxy Tasks\", i.e., the substitute tasks used for training models for CSAI without making use of CSA data. Under this new terminology we review current literature and present a protocol for making conscious use of Proxy Tasks together with consistent input from LEAs to design better automation in this field. Finally, we apply this protocol to study -- for the first time -- the task of Few-shot Indoor Scene Classification on CSAI, showing a final model that achieves promising results on a real-world CSAI dataset whilst having no weights actually trained on sensitive data.", "subjects": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV)", "comments": "ACM Conference on Fairness, Accountability, and Transparency (FAccT 2025)", "pdf_url": "https://arxiv.org/pdf/2505.06621.pdf", "abstract_url": "https://arxiv.org/abs/2505.06621", "categories": ["Machine Learning (cs.LG)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种通过最小化模型与数据交互来降低风险的方法，旨在设计儿童性虐待图像（CSAI）检测模型时依赖代理任务。", "motivation": "儿童性虐待图像的分布是现代世界日益关注的问题，受害者遭受二次伤害，且非法图像数量的增长使执法机构（LEAs）的分类工作负担加重。", "method": "作者定义了“代理任务”这一新术语，即在训练CSAI检测模型时不使用真实CSAI数据的替代任务，并提出了一个协议，结合LEAs的持续输入，设计更好的自动化方法。", "result": "应用该协议首次研究了CSAI上的少样本室内场景分类任务，展示了一个在真实世界CSAI数据集上表现良好且未在敏感数据上训练权重的最终模型。", "conclusion": "通过最小化模型与数据的交互和利用代理任务，可以设计出有效的CSAI检测模型，同时避免敏感数据的泄露风险。"}}
{"id": "2505.06335", "title": "Remote Rowhammer Attack using Adversarial Observations on Federated Learning Clients", "authors": ["Jinsheng Yuan", "Yuhang Hao", "Weisi Guo", "Yun Wu", "Chongyan Gu"], "abstract": "Federated Learning (FL) has the potential for simultaneous global learning amongst a large number of parallel agents, enabling emerging AI such as LLMs to be trained across demographically diverse data. Central to this being efficient is the ability for FL to perform sparse gradient updates and remote direct memory access at the central server. Most of the research in FL security focuses on protecting data privacy at the edge client or in the communication channels between the client and server. Client-facing attacks on the server are less well investigated as the assumption is that a large collective of clients offer resilience.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.06335.pdf", "abstract_url": "https://arxiv.org/abs/2505.06335", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Cryptography and Security (cs.CR)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了在联邦学习(FL)环境中，通过对抗性观察对客户端进行远程Rowhammer攻击的可能性。", "motivation": "联邦学习(FL)允许多个并行代理进行全球学习，但大多数研究集中在保护边缘客户端或通信通道的数据隐私上，而对客户端面向服务器的攻击研究较少。", "method": "利用对抗性观察对联邦学习客户端进行远程Rowhammer攻击。", "result": "研究表明，即使在客户端集体提供弹性的假设下，服务器也可能面临来自客户端的远程Rowhammer攻击。", "conclusion": "这项研究强调了在联邦学习环境中，除了保护数据隐私外，还需要关注和防范客户端对服务器的潜在攻击。"}}
{"id": "2505.06378", "title": "Bi-LSTM based Multi-Agent DRL with Computation-aware Pruning for Agent Twins Migration in Vehicular Embodied AI Networks", "authors": ["Yuxiang Wei", "Zhuoqi Zeng", "Yue Zhong", "Jiawen Kang", "Ryan Wen Liu", "M. Shamim Hossain"], "abstract": "With the advancement of large language models and embodied Artificial Intelligence (AI) in the intelligent transportation scenarios, the combination of them in intelligent transportation spawns the Vehicular Embodied AI Network (VEANs). In VEANs, Autonomous Vehicles (AVs) are typical agents whose local advanced AI applications are defined as vehicular embodied AI agents, enabling capabilities such as environment perception and multi-agent collaboration. Due to computation latency and resource constraints, the local AI applications and services running on vehicular embodied AI agents need to be migrated, and subsequently referred to as vehicular embodied AI agent twins, which drive the advancement of vehicular embodied AI networks to offload intensive tasks to Roadside Units (RSUs), mitigating latency problems while maintaining service quality. Recognizing workload imbalance among RSUs in traditional approaches, we model AV-RSU interactions as a Stackelberg game to optimize bandwidth resource allocation for efficient migration. A Tiny Multi-Agent Bidirectional LSTM Proximal Policy Optimization (TMABLPPO) algorithm is designed to approximate the Stackelberg equilibrium through decentralized coordination. Furthermore, a personalized neural network pruning algorithm based on Path eXclusion (PX) dynamically adapts to heterogeneous AV computation capabilities by identifying task-critical parameters in trained models, reducing model complexity with less performance degradation. Experimental validation confirms the algorithm's effectiveness in balancing system load and minimizing delays, demonstrating significant improvements in vehicular embodied AI agent deployment.", "subjects": "Computer Science and Game Theory (cs.GT); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.06378.pdf", "abstract_url": "https://arxiv.org/abs/2505.06378", "categories": ["Computer Science and Game Theory (cs.GT)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于双向LSTM的多Agent深度强化学习方法，结合计算感知的剪枝技术，用于车辆嵌入式AI网络中的Agent双胞胎迁移，以优化资源分配和减少延迟。", "motivation": "随着大型语言模型和嵌入式人工智能在智能交通场景中的进步，车辆嵌入式AI网络（VEANs）应运而生。然而，由于计算延迟和资源限制，本地AI应用和服务需要迁移，这促使了车辆嵌入式AI Agent双胞胎的发展，以卸载密集任务到路边单元（RSUs），同时保持服务质量。", "method": "研究将AV-RSU交互建模为Stackelberg游戏，以优化带宽资源分配。设计了一种名为TMABLPPO的算法，通过分散协调近似Stackelberg均衡。此外，提出了一种基于路径排除（PX）的个性化神经网络剪枝算法，动态适应异构AV计算能力。", "result": "实验验证表明，该算法在平衡系统负载和最小化延迟方面有效，显著提高了车辆嵌入式AI Agent的部署效率。", "conclusion": "本文的方法通过优化资源分配和减少模型复杂度，有效解决了车辆嵌入式AI网络中的服务迁移问题，为智能交通系统中的AI应用部署提供了新的解决方案。"}}
{"id": "2505.06980", "title": "VALISENS: A Validated Innovative Multi-Sensor System for Cooperative Automated Driving", "authors": ["Lei Wan", "Prabesh Gupta", "Andreas Eich", "Marcel Kettelgerdes", "Hannan Ejaz Keen", "Michael Klöppel-Gersdorf", "Alexey Vinel"], "abstract": "Perception is a core capability of automated vehicles and has been significantly advanced through modern sensor technologies and artificial intelligence. However, perception systems still face challenges in complex real-world scenarios. To improve robustness against various external factors, multi-sensor fusion techniques are essential, combining the strengths of different sensor modalities. With recent developments in Vehicle-to-Everything (V2X communication, sensor fusion can now extend beyond a single vehicle to a cooperative multi-agent system involving Connected Automated Vehicle (CAV) and intelligent infrastructure. This paper presents VALISENS, an innovative multi-sensor system distributed across multiple agents. It integrates onboard and roadside LiDARs, radars, thermal cameras, and RGB cameras to enhance situational awareness and support cooperative automated driving. The thermal camera adds critical redundancy for perceiving Vulnerable Road User (VRU), while fusion with roadside sensors mitigates visual occlusions and extends the perception range beyond the limits of individual vehicles. We introduce the corresponding perception module built on this sensor system, which includes object detection, tracking, motion forecasting, and high-level data fusion. The proposed system demonstrates the potential of cooperative perception in real-world test environments and lays the groundwork for future Cooperative Intelligent Transport Systems (C-ITS) applications.", "subjects": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV)", "comments": "7 pages, 11 figures, submitted to IEEE ITSC", "pdf_url": "https://arxiv.org/pdf/2505.06980.pdf", "abstract_url": "https://arxiv.org/abs/2505.06980", "categories": ["Robotics (cs.RO)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "VALISENS是一个创新的多传感器系统，旨在通过多传感器融合技术提升自动驾驶车辆在复杂现实场景中的感知能力。该系统整合了车载和路侧的LiDAR、雷达、热成像相机及RGB相机，以增强情境感知并支持协同自动驾驶。", "motivation": "自动驾驶车辆的感知系统在复杂的现实场景中仍面临挑战。为了提高对外部各种因素的鲁棒性，需要结合不同传感器模态的优势，采用多传感器融合技术。", "method": "VALISENS系统通过整合车载和路侧的多种传感器（LiDARs、雷达、热成像相机、RGB相机），并利用V2X通信技术，实现了一个分布式的多代理协同感知系统。系统包括物体检测、跟踪、运动预测和高层次数据融合等模块。", "result": "在真实世界的测试环境中，VALISENS系统展示了协同感知的潜力，为未来的协同智能交通系统（C-ITS）应用奠定了基础。", "conclusion": "VALISENS系统通过多传感器融合和协同感知技术，显著提升了自动驾驶车辆在复杂环境中的感知能力，为未来的智能交通系统提供了重要的技术支持。"}}
{"id": "2505.06394", "title": "Towards AI-Driven Human-Machine Co-Teaming for Adaptive and Agile Cyber Security Operation Centers", "authors": ["Massimiliano Albanese", "Xinming Ou", "Kevin Lybarger", "Daniel Lende", "Dmitry Goldgof"], "abstract": "Security Operations Centers (SOCs) face growing challenges in managing cybersecurity threats due to an overwhelming volume of alerts, a shortage of skilled analysts, and poorly integrated tools. Human-AI collaboration offers a promising path to augment the capabilities of SOC analysts while reducing their cognitive overload. To this end, we introduce an AI-driven human-machine co-teaming paradigm that leverages large language models (LLMs) to enhance threat intelligence, alert triage, and incident response workflows. We present a vision in which LLM-based AI agents learn from human analysts the tacit knowledge embedded in SOC operations, enabling the AI agents to improve their performance on SOC tasks through this co-teaming. We invite SOCs to collaborate with us to further develop this process and uncover replicable patterns where human-AI co-teaming yields measurable improvements in SOC productivity.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.06394.pdf", "abstract_url": "https://arxiv.org/abs/2505.06394", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种AI驱动的人机协同模式，旨在通过大型语言模型（LLMs）增强安全运营中心（SOCs）的威胁情报、警报分类和事件响应流程，以应对网络安全威胁管理的挑战。", "motivation": "安全运营中心（SOCs）在处理网络安全威胁时面临警报量过大、技能分析师短缺以及工具集成度低等挑战，人机协作被视为提升SOC分析师能力并减轻其认知负荷的有前景的途径。", "method": "引入了一种基于大型语言模型（LLMs）的AI驱动人机协同范式，使AI代理能够从人类分析师那里学习SOC操作中的隐性知识，从而提升其在SOC任务中的表现。", "result": "提出了一个愿景，即通过人机协同，AI代理能够在SOC任务中通过学习人类分析师的知识来提高其性能，并邀请SOCs合作开发此过程，以发现可复制的人机协同模式，从而显著提高SOC的生产力。", "conclusion": "AI驱动的人机协同为SOCs提供了一种有效的方法来应对当前的网络安全挑战，通过结合人类分析师的隐性知识和AI的计算能力，可以显著提升SOC的操作效率和响应能力。"}}
{"id": "2505.07214", "title": "Towards user-centered interactive medical image segmentation in VR with an assistive AI agent", "authors": ["Pascal Spiegler", "Arash Harirpoush", "Yiming Xiao"], "abstract": "Crucial in disease analysis and surgical planning, manual segmentation of volumetric medical scans (e.g. MRI, CT) is laborious, error-prone, and challenging to master, while fully automatic algorithms can benefit from user-feedback. Therefore, with the complementary power of the latest radiological AI foundation models and virtual reality (VR)'s intuitive data interaction, we propose SAMIRA, a novel conversational AI agent that assists users with localizing, segmenting, and visualizing 3D medical concepts in VR. Through speech-based interaction, the agent helps users understand radiological features, locate clinical targets, and generate segmentation masks that can be refined with just a few point prompts. The system also supports true-to-scale 3D visualization of segmented pathology to enhance patient-specific anatomical understanding. Furthermore, to determine the optimal interaction paradigm under near-far attention-switching for refining segmentation masks in an immersive, human-in-the-loop workflow, we compare VR controller pointing, head pointing, and eye tracking as input modes. With a user study, evaluations demonstrated a high usability score (SUS=90.0 $\\pm$ 9.0), low overall task load, as well as strong support for the proposed VR system's guidance, training potential, and integration of AI in radiological segmentation tasks.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.07214.pdf", "abstract_url": "https://arxiv.org/abs/2505.07214", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为SAMIRA的新型对话式AI代理，结合最新的放射学AI基础模型和虚拟现实(VR)技术，旨在通过语音交互辅助用户在VR中定位、分割和可视化3D医学概念，从而提高医学图像分割的效率和准确性。", "motivation": "手动分割体积医学扫描（如MRI、CT）在疾病分析和手术规划中至关重要，但这一过程既繁琐又容易出错，且难以掌握。同时，完全自动化的算法可以从用户反馈中受益。因此，本文旨在结合放射学AI和VR技术，提出一种更高效、更直观的医学图像分割方法。", "method": "本文提出了SAMIRA，一个通过语音交互辅助用户在VR中定位、分割和可视化3D医学概念的对话式AI代理。系统支持真实比例的3D可视化，并通过比较VR控制器指向、头部指向和眼动追踪作为输入模式，确定了在沉浸式、人类在环的工作流中优化分割掩模的最佳交互范式。", "result": "用户研究表明，该系统具有高可用性评分（SUS=90.0 ± 9.0）、低总体任务负荷，并且强烈支持所提出的VR系统在放射学分割任务中的指导、培训潜力以及AI的集成。", "conclusion": "SAMIRA系统通过结合AI和VR技术，提供了一种高效、直观的医学图像分割方法，不仅提高了分割的准确性和效率，还增强了用户对患者特定解剖结构的理解，展现了在放射学分割任务中集成AI和VR技术的巨大潜力。"}}
{"id": "2505.06482", "title": "Video-Enhanced Offline Reinforcement Learning: A Model-Based Approach", "authors": ["Minting Pan", "Yitao Zheng", "Jiajian Li", "Yunbo Wang", "Xiaokang Yang"], "abstract": "Offline reinforcement learning (RL) enables policy optimization in static datasets, avoiding the risks and costs of real-world exploration. However, it struggles with suboptimal behavior learning and inaccurate value estimation due to the lack of environmental interaction. In this paper, we present Video-Enhanced Offline RL (VeoRL), a model-based approach that constructs an interactive world model from diverse, unlabeled video data readily available online. Leveraging model-based behavior guidance, VeoRL transfers commonsense knowledge of control policy and physical dynamics from natural videos to the RL agent within the target domain. Our method achieves substantial performance gains (exceeding 100% in some cases) across visuomotor control tasks in robotic manipulation, autonomous driving, and open-world video games.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.06482.pdf", "abstract_url": "https://arxiv.org/abs/2505.06482", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于模型的视频增强离线强化学习方法（VeoRL），通过从多样化的未标记视频数据构建交互式世界模型，将常识性控制策略和物理动态知识转移到目标领域的RL代理中，显著提升了在机器人操作、自动驾驶和开放世界视频游戏等视觉运动控制任务中的性能。", "motivation": "离线强化学习（RL）允许在静态数据集中进行策略优化，避免了现实世界探索的风险和成本。然而，由于缺乏环境交互，它难以学习到最优行为并进行准确的价值估计。", "method": "提出Video-Enhanced Offline RL（VeoRL），一种基于模型的方法，从在线可用的多样化未标记视频数据构建交互式世界模型，利用基于模型的行为指导，将自然视频中的控制策略和物理动态的常识性知识转移到目标领域的RL代理中。", "result": "在机器人操作、自动驾驶和开放世界视频游戏等视觉运动控制任务中，VeoRL方法实现了显著的性能提升（在某些情况下超过100%）。", "conclusion": "VeoRL通过利用未标记视频数据构建的世界模型，有效地将常识性知识转移到离线RL代理中，显著提高了在各种视觉运动控制任务中的性能，展示了模型基于方法在离线RL中的潜力。"}}
{"id": "2505.06493", "title": "System Prompt Poisoning: Persistent Attacks on Large Language Models Beyond User Injection", "authors": ["Jiawei Guo", "Haipeng Cai"], "abstract": "Large language models (LLMs) have gained widespread adoption across diverse applications due to their impressive generative capabilities. Their plug-and-play nature enables both developers and end users to interact with these models through simple prompts. However, as LLMs become more integrated into various systems in diverse domains, concerns around their security are growing. Existing studies mainly focus on threats arising from user prompts (e.g. prompt injection attack) and model output (e.g. model inversion attack), while the security of system prompts remains largely overlooked. This work bridges the critical gap. We introduce system prompt poisoning, a new attack vector against LLMs that, unlike traditional user prompt injection, poisons system prompts hence persistently impacts all subsequent user interactions and model responses. We systematically investigate four practical attack strategies in various poisoning scenarios. Through demonstration on both generative and reasoning LLMs, we show that system prompt poisoning is highly feasible without requiring jailbreak techniques, and effective across a wide range of tasks, including those in mathematics, coding, logical reasoning, and natural language processing. Importantly, our findings reveal that the attack remains effective even when user prompts employ advanced prompting techniques like chain-of-thought (CoT). We also show that such techniques, including CoT and retrieval-augmentation-generation (RAG), which are proven to be effective for improving LLM performance in a wide range of tasks, are significantly weakened in their effectiveness by system prompt poisoning.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.06493.pdf", "abstract_url": "https://arxiv.org/abs/2505.06493", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了系统提示中毒这一新的攻击向量，针对大型语言模型（LLMs）的安全性进行了研究，展示了在不使用越狱技术的情况下，通过四种实用攻击策略在不同中毒场景中的可行性及其广泛影响。", "motivation": "随着大型语言模型（LLMs）在多个领域的广泛应用，其安全性问题日益凸显。现有研究主要集中在用户提示（如提示注入攻击）和模型输出（如模型反转攻击）的威胁上，而系统提示的安全性却被忽视。本文旨在填补这一关键空白。", "method": "本文提出了系统提示中毒这一新的攻击向量，并系统地研究了四种实用攻击策略在不同中毒场景中的应用。通过在生成和推理LLMs上的演示，验证了攻击的可行性和有效性。", "result": "研究表明，系统提示中毒攻击无需越狱技术即可实施，且在数学、编码、逻辑推理和自然语言处理等多种任务中均有效。此外，即使用户提示采用如思维链（CoT）等高级提示技术，攻击仍然有效。同时，CoT和检索增强生成（RAG）等技术在系统提示中毒下的有效性显著降低。", "conclusion": "本文揭示了系统提示中毒作为一种新型攻击向量对LLMs构成的持久威胁，强调了在设计和部署LLMs时考虑系统提示安全性的重要性，以及开发相应防御措施的必要性。"}}
{"id": "2505.07634", "title": "Neural Brain: A Neuroscience-inspired Framework for Embodied Agents", "authors": ["Jian Liu", "Xiongtao Shi", "Thai Duy Nguyen", "Haitian Zhang", "Tianxiang Zhang", "Wei Sun", "Yanjie Li", "Athanasios V. Vasilakos", "Giovanni Iacca", "Arshad Ali Khan", "Arvind Kumar", "Jae Won Cho", "Ajmal Mian", "Lihua Xie", "Erik Cambria", "Lin Wang"], "abstract": "The rapid evolution of artificial intelligence (AI) has shifted from static, data-driven models to dynamic systems capable of perceiving and interacting with real-world environments. Despite advancements in pattern recognition and symbolic reasoning, current AI systems, such as large language models, remain disembodied, unable to physically engage with the world. This limitation has driven the rise of embodied AI, where autonomous agents, such as humanoid robots, must navigate and manipulate unstructured environments with human-like adaptability. At the core of this challenge lies the concept of Neural Brain, a central intelligence system designed to drive embodied agents with human-like adaptability. A Neural Brain must seamlessly integrate multimodal sensing and perception with cognitive capabilities. Achieving this also requires an adaptive memory system and energy-efficient hardware-software co-design, enabling real-time action in dynamic environments. This paper introduces a unified framework for the Neural Brain of embodied agents, addressing two fundamental challenges: (1) defining the core components of Neural Brain and (2) bridging the gap between static AI models and the dynamic adaptability required for real-world deployment. To this end, we propose a biologically inspired architecture that integrates multimodal active sensing, perception-cognition-action function, neuroplasticity-based memory storage and updating, and neuromorphic hardware/software optimization. Furthermore, we also review the latest research on embodied agents across these four aspects and analyze the gap between current AI systems and human intelligence. By synthesizing insights from neuroscience, we outline a roadmap towards the development of generalizable, autonomous agents capable of human-level intelligence in real-world scenarios.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "comments": "51 pages, 17 figures, 9 tables", "pdf_url": "https://arxiv.org/pdf/2505.07634.pdf", "abstract_url": "https://arxiv.org/abs/2505.07634", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为'神经大脑'的框架，旨在为具身代理（如人形机器人）提供类似于人类的适应能力，通过整合多模态感知、认知能力、自适应记忆系统和能效优化的硬件-软件协同设计，以解决当前AI系统在动态环境中实时行动的局限性。", "motivation": "当前的人工智能系统，如大型语言模型，缺乏与物理世界互动的能力，这限制了它们在非结构化环境中的应用。本文旨在通过'神经大脑'框架，推动具身AI的发展，使其能够像人类一样适应和操作复杂环境。", "method": "提出了一种受生物学启发的架构，该架构整合了多模态主动感知、感知-认知-行动功能、基于神经可塑性的记忆存储与更新，以及神经形态硬件/软件优化。", "result": "通过综合神经科学的最新研究，本文概述了开发能够在现实世界场景中达到人类水平智能的通用自主代理的路线图。", "conclusion": "本文的'神经大脑'框架为具身代理的发展提供了一个统一的方向，旨在缩小当前AI系统与人类智能之间的差距，推动实现具有人类水平适应能力的自主代理。"}}
{"id": "2505.06740", "title": "Boundary-Guided Trajectory Prediction for Road Aware and Physically Feasible Autonomous Driving", "authors": ["Ahmed Abouelazm", "Mianzhi Liu", "Christian Hubschneider", "Yin Wu", "Daniel Slieter", "J. Marius Zöllner"], "abstract": "Accurate prediction of surrounding road users' trajectories is essential for safe and efficient autonomous driving. While deep learning models have improved performance, challenges remain in preventing off-road predictions and ensuring kinematic feasibility. Existing methods incorporate road-awareness modules and enforce kinematic constraints but lack plausibility guarantees and often introduce trade-offs in complexity and flexibility. This paper proposes a novel framework that formulates trajectory prediction as a constrained regression guided by permissible driving directions and their boundaries. Using the agent's current state and an HD map, our approach defines the valid boundaries and ensures on-road predictions by training the network to learn superimposed paths between left and right boundary polylines. To guarantee feasibility, the model predicts acceleration profiles that determine the vehicle's travel distance along these paths while adhering to kinematic constraints. We evaluate our approach on the Argoverse-2 dataset against the HPTR baseline. Our approach shows a slight decrease in benchmark metrics compared to HPTR but notably improves final displacement error and eliminates infeasible trajectories. Moreover, the proposed approach has superior generalization to less prevalent maneuvers and unseen out-of-distribution scenarios, reducing the off-road rate under adversarial attacks from 66\\% to just 1\\%. These results highlight the effectiveness of our approach in generating feasible and robust predictions.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": "Accepted in the 36th IEEE Intelligent Vehicles Symposium (IV 2025)", "pdf_url": "https://arxiv.org/pdf/2505.06740.pdf", "abstract_url": "https://arxiv.org/abs/2505.06740", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新颖的轨迹预测框架，通过允许驾驶方向及其边界的约束回归来预测道路用户的轨迹，确保预测在道路上且运动学可行。", "motivation": "解决自动驾驶中准确预测周围道路用户轨迹的挑战，特别是在防止偏离道路预测和确保运动学可行性方面。", "method": "使用代理当前状态和高清地图定义有效边界，通过训练网络学习左右边界折线之间的叠加路径来确保道路上的预测，并预测加速度剖面以保证运动学可行性。", "result": "在Argoverse-2数据集上与HPTR基线相比，虽然基准指标略有下降，但显著改善了最终位移误差并消除了不可行轨迹，且在较少见的操作和未见过的分布外场景中表现出更好的泛化能力。", "conclusion": "该方法在生成可行且鲁棒的预测方面表现出有效性，特别是在对抗性攻击下将偏离道路率从66%降低到仅1%。"}}
{"id": "2505.06743", "title": "TPK: Trustworthy Trajectory Prediction Integrating Prior Knowledge For Interpretability and Kinematic Feasibility", "authors": ["Marius Baden", "Ahmed Abouelazm", "Christian Hubschneider", "Yin Wu", "Daniel Slieter", "J. Marius Zöllner"], "abstract": "Trajectory prediction is crucial for autonomous driving, enabling vehicles to navigate safely by anticipating the movements of surrounding road users. However, current deep learning models often lack trustworthiness as their predictions can be physically infeasible and illogical to humans. To make predictions more trustworthy, recent research has incorporated prior knowledge, like the social force model for modeling interactions and kinematic models for physical realism. However, these approaches focus on priors that suit either vehicles or pedestrians and do not generalize to traffic with mixed agent classes. We propose incorporating interaction and kinematic priors of all agent classes--vehicles, pedestrians, and cyclists with class-specific interaction layers to capture agent behavioral differences. To improve the interpretability of the agent interactions, we introduce DG-SFM, a rule-based interaction importance score that guides the interaction layer. To ensure physically feasible predictions, we proposed suitable kinematic models for all agent classes with a novel pedestrian kinematic model. We benchmark our approach on the Argoverse 2 dataset, using the state-of-the-art transformer HPTR as our baseline. Experiments demonstrate that our method improves interaction interpretability, revealing a correlation between incorrect predictions and divergence from our interaction prior. Even though incorporating the kinematic models causes a slight decrease in accuracy, they eliminate infeasible trajectories found in the dataset and the baseline model. Thus, our approach fosters trust in trajectory prediction as its interaction reasoning is interpretable, and its predictions adhere to physics.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": "Accepted in the 36th IEEE Intelligent Vehicles Symposium (IV 2025) for oral presentation", "pdf_url": "https://arxiv.org/pdf/2505.06743.pdf", "abstract_url": "https://arxiv.org/abs/2505.06743", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种集成先验知识的可信轨迹预测方法TPK，旨在提高自动驾驶中轨迹预测的可解释性和运动学可行性。通过引入特定类别的交互层和规则基础的交互重要性评分DG-SFM，以及适用于所有交通参与者类别的运动学模型，TPK在Argoverse 2数据集上的实验显示，其提高了交互的可解释性并确保了预测的物理可行性。", "motivation": "当前深度学习模型在轨迹预测中常因预测结果物理上不可行或不符合人类逻辑而缺乏可信度。本文旨在通过整合所有交通参与者类别的交互和运动学先验知识，解决这一问题。", "method": "提出了TPK方法，包括特定类别的交互层以捕捉不同交通参与者的行为差异，引入DG-SFM评分以提高交互的可解释性，并提出适用于所有类别的运动学模型，特别是新的行人运动学模型。", "result": "实验表明，TPK提高了交互的可解释性，并揭示了错误预测与偏离交互先验之间的相关性。虽然运动学模型的引入略微降低了准确性，但消除了数据集中和基线模型中的不可行轨迹。", "conclusion": "TPK方法通过其可解释的交互推理和符合物理的预测，增强了轨迹预测的可信度。"}}
{"id": "2505.07815", "title": "Imagine, Verify, Execute: Memory-Guided Agentic Exploration with Vision-Language Models", "authors": ["Seungjae Lee", "Daniel Ekpo", "Haowen Liu", "Furong Huang", "Abhinav Shrivastava", "Jia-Bin Huang"], "abstract": "Exploration is essential for general-purpose robotic learning, especially in open-ended environments where dense rewards, explicit goals, or task-specific supervision are scarce. Vision-language models (VLMs), with their semantic reasoning over objects, spatial relations, and potential outcomes, present a compelling foundation for generating high-level exploratory behaviors. However, their outputs are often ungrounded, making it difficult to determine whether imagined transitions are physically feasible or informative. To bridge the gap between imagination and execution, we present IVE (Imagine, Verify, Execute), an agentic exploration framework inspired by human curiosity. Human exploration is often driven by the desire to discover novel scene configurations and to deepen understanding of the environment. Similarly, IVE leverages VLMs to abstract RGB-D observations into semantic scene graphs, imagine novel scenes, predict their physical plausibility, and generate executable skill sequences through action tools. We evaluate IVE in both simulated and real-world tabletop environments. The results show that IVE enables more diverse and meaningful exploration than RL baselines, as evidenced by a 4.1 to 7.8x increase in the entropy of visited states. Moreover, the collected experience supports downstream learning, producing policies that closely match or exceed the performance of those trained on human-collected demonstrations.", "subjects": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.07815.pdf", "abstract_url": "https://arxiv.org/abs/2505.07815", "categories": ["Robotics (cs.RO)", "Computer Vision and Pattern Recognition (cs.CV)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了IVE（Imagine, Verify, Execute）框架，一个受人类好奇心启发的探索框架，利用视觉语言模型（VLMs）进行高级探索行为生成，以解决开放环境中机器人学习探索的挑战。", "motivation": "解决在开放环境中，由于缺乏密集奖励、明确目标或任务特定监督，机器人学习探索的挑战。", "method": "IVE框架通过VLMs将RGB-D观察抽象为语义场景图，想象新场景，预测其物理可行性，并通过动作工具生成可执行的技能序列。", "result": "在模拟和现实世界的桌面环境中评估，IVE比RL基线实现了更多样化和有意义的探索，访问状态的熵增加了4.1到7.8倍。", "conclusion": "IVE框架不仅促进了更有效的探索，而且收集的经验支持下游学习，产生的策略性能接近或超过基于人类收集演示训练的策咯。"}}
{"id": "2505.06821", "title": "ThreatLens: LLM-guided Threat Modeling and Test Plan Generation for Hardware Security Verification", "authors": ["Dipayan Saha", "Hasan Al Shaikh", "Shams Tarek", "Farimah Farahmandi"], "abstract": "Current hardware security verification processes predominantly rely on manual threat modeling and test plan generation, which are labor-intensive, error-prone, and struggle to scale with increasing design complexity and evolving attack methodologies. To address these challenges, we propose ThreatLens, an LLM-driven multi-agent framework that automates security threat modeling and test plan generation for hardware security verification. ThreatLens integrates retrieval-augmented generation (RAG) to extract relevant security knowledge, LLM-powered reasoning for threat assessment, and interactive user feedback to ensure the generation of practical test plans. By automating these processes, the framework reduces the manual verification effort, enhances coverage, and ensures a structured, adaptable approach to security verification. We evaluated our framework on the NEORV32 SoC, demonstrating its capability to automate security verification through structured test plans and validating its effectiveness in real-world scenarios.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET)", "comments": "This paper has been presented at IEEE VLSI Test Symposium (VTS) 2025", "pdf_url": "https://arxiv.org/pdf/2505.06821.pdf", "abstract_url": "https://arxiv.org/abs/2505.06821", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Emerging Technologies (cs.ET)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "ThreatLens是一个基于LLM的多代理框架，旨在自动化硬件安全验证中的威胁建模和测试计划生成，以减少人工努力、提高覆盖范围并适应不断变化的安全需求。", "motivation": "当前的硬件安全验证过程主要依赖人工进行威胁建模和测试计划生成，这不仅劳动密集、容易出错，而且难以随着设计复杂性和攻击方法的演变而扩展。", "method": "ThreatLens结合了检索增强生成（RAG）来提取相关安全知识，利用LLM驱动的推理进行威胁评估，并通过交互式用户反馈确保生成实用的测试计划。", "result": "在NEORV32 SoC上的评估表明，ThreatLens能够通过结构化的测试计划自动化安全验证，并在实际场景中验证了其有效性。", "conclusion": "ThreatLens框架通过自动化威胁建模和测试计划生成，显著减少了手动验证的工作量，提高了安全验证的覆盖率和适应性，为硬件安全验证提供了一种结构化、可扩展的解决方案。"}}
{"id": "2505.06913", "title": "RedTeamLLM: an Agentic AI framework for offensive security", "authors": ["Brian Challita", "Pierre Parrend"], "abstract": "From automated intrusion testing to discovery of zero-day attacks before software launch, agentic AI calls for great promises in security engineering. This strong capability is bound with a similar threat: the security and research community must build up its models before the approach is leveraged by malicious actors for cybercrime. We therefore propose and evaluate RedTeamLLM, an integrated architecture with a comprehensive security model for automatization of pentest tasks. RedTeamLLM follows three key steps: summarizing, reasoning and act, which embed its operational capacity. This novel framework addresses four open challenges: plan correction, memory management, context window constraint, and generality vs. specialization. Evaluation is performed through the automated resolution of a range of entry-level, but not trivial, CTF challenges. The contribution of the reasoning capability of our agentic AI framework is specifically evaluated.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.06913.pdf", "abstract_url": "https://arxiv.org/abs/2505.06913", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "RedTeamLLM是一个用于进攻性安全的代理AI框架，旨在通过自动化渗透测试任务来提升安全工程能力。该框架通过总结、推理和行动三个关键步骤，解决了计划修正、内存管理、上下文窗口限制以及通用性与专业性之间的四个开放挑战。", "motivation": "随着代理AI在安全工程中的潜力日益显现，安全和研究社区需要在其被恶意行为者用于网络犯罪之前建立自己的模型。", "method": "RedTeamLLM采用了一个集成架构，包含一个全面的安全模型，通过总结、推理和行动三个步骤自动化渗透测试任务。", "result": "通过自动解决一系列入门级但不简单的CTF挑战来评估，特别评估了代理AI框架推理能力的贡献。", "conclusion": "RedTeamLLM框架为安全工程提供了一个有效的代理AI解决方案，特别是在自动化渗透测试方面，同时解决了相关的开放挑战。"}}
{"id": "2505.07064", "title": "ParaView-MCP: An Autonomous Visualization Agent with Direct Tool Use", "authors": ["Shusen Liu", "Haichao Miao", "Peer-Timo Bremer"], "abstract": "While powerful and well-established, tools like ParaView present a steep learning curve that discourages many potential users. This work introduces ParaView-MCP, an autonomous agent that integrates modern multimodal large language models (MLLMs) with ParaView to not only lower the barrier to entry but also augment ParaView with intelligent decision support. By leveraging the state-of-the-art reasoning, command execution, and vision capabilities of MLLMs, ParaView-MCP enables users to interact with ParaView through natural language and visual inputs. Specifically, our system adopted the Model Context Protocol (MCP) - a standardized interface for model-application communication - that facilitates direct interaction between MLLMs with ParaView's Python API to allow seamless information exchange between the user, the language model, and the visualization tool itself. Furthermore, by implementing a visual feedback mechanism that allows the agent to observe the viewport, we unlock a range of new capabilities, including recreating visualizations from examples, closed-loop visualization parameter updates based on user-defined goals, and even cross-application collaboration involving multiple tools. Broadly, we believe such an agent-driven visualization paradigm can profoundly change the way we interact with visualization tools. We expect a significant uptake in the development of such visualization tools, in both visualization research and industry.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.07064.pdf", "abstract_url": "https://arxiv.org/abs/2505.07064", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "ParaView-MCP是一个自主可视化代理，通过集成多模态大语言模型（MLLMs）与ParaView，旨在降低使用门槛并提供智能决策支持。", "motivation": "解决ParaView等工具学习曲线陡峭，阻碍潜在用户使用的问题。", "method": "采用模型上下文协议（MCP）作为标准接口，实现MLLMs与ParaView Python API的直接交互，并通过视觉反馈机制增强功能。", "result": "开发了一个能够通过自然语言和视觉输入与ParaView交互的系统，支持从示例重建可视化、基于用户定义目标的闭环可视化参数更新等功能。", "conclusion": "代理驱动的可视化范式有望深刻改变与可视化工具的交互方式，预计将在可视化研究和工业界得到广泛应用。"}}
{"id": "2505.07078", "title": "Can LLM-based Financial Investing Strategies Outperform the Market in Long Run?", "authors": ["Weixian Waylon Li", "Hyeonjun Kim", "Mihai Cucuringu", "Tiejun Ma"], "abstract": "Large Language Models (LLMs) have recently been leveraged for asset pricing tasks and stock trading applications, enabling AI agents to generate investment decisions from unstructured financial data. However, most evaluations of LLM timing-based investing strategies are conducted on narrow timeframes and limited stock universes, overstating effectiveness due to survivorship and data-snooping biases. We critically assess their generalizability and robustness by proposing FINSABER, a backtesting framework evaluating timing-based strategies across longer periods and a larger universe of symbols. Systematic backtests over two decades and 100+ symbols reveal that previously reported LLM advantages deteriorate significantly under broader cross-section and over a longer-term evaluation. Our market regime analysis further demonstrates that LLM strategies are overly conservative in bull markets, underperforming passive benchmarks, and overly aggressive in bear markets, incurring heavy losses. These findings highlight the need to develop LLM strategies that are able to prioritise trend detection and regime-aware risk controls over mere scaling of framework complexity.", "subjects": "Trading and Market Microstructure (q-fin.TR); Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE)", "comments": "14 pages", "pdf_url": "https://arxiv.org/pdf/2505.07078.pdf", "abstract_url": "https://arxiv.org/abs/2505.07078", "categories": ["Trading and Market Microstructure (q-fin.TR)", "Artificial Intelligence (cs.AI)", "Computational Engineering, Finance, and Science (cs.CE)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过FINSABER框架评估了基于大型语言模型(LLM)的金融投资策略在长期内是否能够超越市场表现。研究发现，在更广泛的时间跨度和股票范围内，LLM策略的优势显著减弱，且在牛市和熊市中的表现不佳。", "motivation": "解决现有LLM基于时序的投资策略评估在狭窄时间框架和有限股票范围内进行，可能因生存和数据窥探偏差而高估效果的问题。", "method": "提出了FINSABER回测框架，用于评估时序策略在更长时间跨度和更大股票范围内的表现。", "result": "在二十多年和100多个符号的系统回测中，先前报告的LLM优势在更广泛的横截面和长期评估下显著减弱。市场体制分析显示，LLM策略在牛市中过于保守，表现不及被动基准，在熊市中则过于激进，导致重大损失。", "conclusion": "强调了开发能够优先考虑趋势检测和体制感知风险控制的LLM策略的必要性，而不仅仅是增加框架的复杂性。"}}
{"id": "2505.07236", "title": "UAV-CodeAgents: Scalable UAV Mission Planning via Multi-Agent ReAct and Vision-Language Reasoning", "authors": ["Oleg Sautenkov", "Yasheerah Yaqoot", "Muhammad Ahsan Mustafa", "Faryal Batool", "Jeffrin Sam", "Artem Lykov", "Chih-Yung Wen", "Dzmitry Tsetserukou"], "abstract": "We present UAV-CodeAgents, a scalable multi-agent framework for autonomous UAV mission generation, built on large language and vision-language models (LLMs/VLMs). The system leverages the ReAct (Reason + Act) paradigm to interpret satellite imagery, ground high-level natural language instructions, and collaboratively generate UAV trajectories with minimal human supervision. A core component is a vision-grounded, pixel-pointing mechanism that enables precise localization of semantic targets on aerial maps. To support real-time adaptability, we introduce a reactive thinking loop, allowing agents to iteratively reflect on observations, revise mission goals, and coordinate dynamically in evolving environments.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": "Submitted", "pdf_url": "https://arxiv.org/pdf/2505.07236.pdf", "abstract_url": "https://arxiv.org/abs/2505.07236", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "UAV-CodeAgents是一个基于大型语言和视觉语言模型的可扩展多智能体框架，用于自主无人机任务生成。该系统利用ReAct范式解释卫星图像和地面高级自然语言指令，并在最少人工监督下协作生成无人机轨迹。", "motivation": "解决无人机任务规划中的可扩展性和自主性问题，减少人工监督的需求，提高任务生成的效率和适应性。", "method": "采用多智能体ReAct范式和视觉语言模型，结合视觉接地的像素指向机制，实现语义目标的精确定位，并引入反应性思维循环以支持实时适应性。", "result": "开发了一个能够解释复杂指令、精确定位目标并动态协调任务的系统，实现了在变化环境中的高效无人机任务规划。", "conclusion": "UAV-CodeAgents框架通过结合先进的AI技术，为无人机任务规划提供了一种高效、自主且可扩展的解决方案，具有广泛的应用潜力。"}}
{"id": "2505.07176", "title": "Internet of Agents: Fundamentals, Applications, and Challenges", "authors": ["Yuntao Wang", "Shaolong Guo", "Yanghe Pan", "Zhou Su", "Fahao Chen", "Tom H. Luan", "Peng Li", "Jiawen Kang", "Dusit Niyato"], "abstract": "With the rapid proliferation of large language models and vision-language models, AI agents have evolved from isolated, task-specific systems into autonomous, interactive entities capable of perceiving, reasoning, and acting without human intervention. As these agents proliferate across virtual and physical environments, from virtual assistants to embodied robots, the need for a unified, agent-centric infrastructure becomes paramount. In this survey, we introduce the Internet of Agents (IoA) as a foundational framework that enables seamless interconnection, dynamic discovery, and collaborative orchestration among heterogeneous agents at scale. We begin by presenting a general IoA architecture, highlighting its hierarchical organization, distinguishing features relative to the traditional Internet, and emerging applications. Next, we analyze the key operational enablers of IoA, including capability notification and discovery, adaptive communication protocols, dynamic task matching, consensus and conflict-resolution mechanisms, and incentive models. Finally, we identify open research directions toward building resilient and trustworthy IoA ecosystems.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": "22 pages,10 figures, 8 tables. Submitted to IEEE TCCN", "pdf_url": "https://arxiv.org/pdf/2505.07176.pdf", "abstract_url": "https://arxiv.org/abs/2505.07176", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了‘代理互联网’（IoA）作为一个基础框架，旨在实现异构代理之间的无缝互联、动态发现和协作编排。文章概述了IoA的一般架构、关键操作推动因素，并指出了构建弹性和可信赖IoA生态系统的开放研究方向。", "motivation": "随着大型语言模型和视觉语言模型的迅速普及，AI代理已经从孤立、任务特定的系统演变为能够无需人类干预即可感知、推理和行动的自主、交互实体。这些代理在虚拟和物理环境中的激增，从虚拟助手到实体机器人，使得建立一个统一的、以代理为中心的基础设施变得至关重要。", "method": "本文提出‘代理互联网’（IoA）作为一个基础框架，通过其分层组织、相对于传统互联网的显著特征以及新兴应用，概述了IoA的一般架构。接着，分析了IoA的关键操作推动因素，包括能力通知和发现、自适应通信协议、动态任务匹配、共识和冲突解决机制以及激励模型。", "result": "文章概述了IoA的一般架构和关键操作推动因素，为理解如何实现异构代理之间的无缝互联、动态发现和协作编排提供了基础。", "conclusion": "本文指出了构建弹性和可信赖IoA生态系统的开放研究方向，强调了在代理技术快速发展的背景下，建立一个统一的、以代理为中心的基础设施的重要性。"}}
{"id": "2505.07457", "title": "Can Generative AI agents behave like humans? Evidence from laboratory market experiments", "authors": ["R. Maria del Rio-Chanona", "Marco Pangallo", "Cars Hommes"], "abstract": "We explore the potential of Large Language Models (LLMs) to replicate human behavior in economic market experiments. Compared to previous studies, we focus on dynamic feedback between LLM agents: the decisions of each LLM impact the market price at the current step, and so affect the decisions of the other LLMs at the next step. We compare LLM behavior to market dynamics observed in laboratory settings and assess their alignment with human participants' behavior. Our findings indicate that LLMs do not adhere strictly to rational expectations, displaying instead bounded rationality, similarly to human participants. Providing a minimal context window i.e. memory of three previous time steps, combined with a high variability setting capturing response heterogeneity, allows LLMs to replicate broad trends seen in human experiments, such as the distinction between positive and negative feedback markets. However, differences remain at a granular level--LLMs exhibit less heterogeneity in behavior than humans. These results suggest that LLMs hold promise as tools for simulating realistic human behavior in economic contexts, though further research is needed to refine their accuracy and increase behavioral diversity.", "subjects": "General Economics (econ.GN); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.07457.pdf", "abstract_url": "https://arxiv.org/abs/2505.07457", "categories": ["General Economics (econ.GN)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "探讨大型语言模型（LLMs）在经济市场实验中复制人类行为的潜力，发现LLMs表现出有限理性，类似于人类参与者，但在行为多样性上不如人类。", "motivation": "研究LLMs是否能在经济市场实验中模拟人类行为，特别是在动态反馈环境下。", "method": "通过比较LLMs与实验室市场动态中观察到的行为，评估其与人类参与者行为的一致性。", "result": "LLMs在提供最小上下文窗口和高变异性设置下，能够复制人类实验中的广泛趋势，但在细粒度上行为多样性较低。", "conclusion": "LLMs作为模拟经济背景下现实人类行为的工具有潜力，但需进一步研究以提高其准确性和行为多样性。"}}
{"id": "2505.07546", "title": "GRADA: Graph-based Reranker against Adversarial Documents Attack", "authors": ["Jingjie Zheng", "Aryo Pradipta Gema", "Giwon Hong", "Xuanli He", "Pasquale Minervini", "Youcheng Sun", "Qiongkai Xu"], "abstract": "Retrieval Augmented Generation (RAG) frameworks improve the accuracy of large language models (LLMs) by integrating external knowledge from retrieved documents, thereby overcoming the limitations of models' static intrinsic knowledge. However, these systems are susceptible to adversarial attacks that manipulate the retrieval process by introducing documents that are adversarial yet semantically similar to the query. Notably, while these adversarial documents resemble the query, they exhibit weak similarity to benign documents in the retrieval set. Thus, we propose a simple yet effective Graph-based Reranking against Adversarial Document Attacks (GRADA) framework aiming at preserving retrieval quality while significantly reducing the success of adversaries. Our study evaluates the effectiveness of our approach through experiments conducted on five LLMs: GPT-3.5-Turbo, GPT-4o, Llama3.1-8b, Llama3.1-70b, and Qwen2.5-7b. We use three datasets to assess performance, with results from the Natural Questions dataset demonstrating up to an 80% reduction in attack success rates while maintaining minimal loss in accuracy.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.07546.pdf", "abstract_url": "https://arxiv.org/abs/2505.07546", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种名为GRADA的图基于重排序框架，旨在保护检索增强生成（RAG）框架免受对抗性文档攻击，同时保持检索质量。通过在五个大型语言模型上进行实验，证明了该方法的有效性。", "motivation": "检索增强生成（RAG）框架通过整合外部知识提高了大型语言模型（LLMs）的准确性，但这些系统容易受到对抗性攻击的影响，这些攻击通过引入与查询语义相似但对抗性的文档来操纵检索过程。", "method": "提出了一种简单而有效的图基于重排序对抗性文档攻击（GRADA）框架，该框架利用对抗性文档与查询相似但与良性文档相似性弱的特点，进行重排序以减少攻击成功率。", "result": "在五个LLMs（GPT-3.5-Turbo、GPT-4o、Llama3.1-8b、Llama3.1-70b和Qwen2.5-7b）上进行的实验表明，使用GRADA框架在Natural Questions数据集上攻击成功率降低了80%，同时准确率损失最小。", "conclusion": "GRADA框架有效地减少了对抗性文档攻击的成功率，同时保持了检索质量，为RAG框架的安全性提供了重要保障。"}}
{"id": "2505.07553", "title": "Towards Requirements Engineering for RAG Systems", "authors": ["Tor Sporsem", "Rasmus Ulfsnes"], "abstract": "This short paper explores how a maritime company develops and integrates large-language models (LLM). Specifically by looking at the requirements engineering for Retrieval Augmented Generation (RAG) systems in expert settings. Through a case study at a maritime service provider, we demonstrate how data scientists face a fundamental tension between user expectations of AI perfection and the correctness of the generated outputs. Our findings reveal that data scientists must identify context-specific \"retrieval requirements\" through iterative experimentation together with users because they are the ones who can determine correctness. We present an empirical process model describing how data scientists practically elicited these \"retrieval requirements\" and managed system limitations. This work advances software engineering knowledge by providing insights into the specialized requirements engineering processes for implementing RAG systems in complex domain-specific applications.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": "Accepted to EASE 2025, 17-20 June, Istanbul, Turkey", "pdf_url": "https://arxiv.org/pdf/2505.07553.pdf", "abstract_url": "https://arxiv.org/abs/2505.07553", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文探讨了海事公司如何开发和集成大型语言模型（LLM），特别是通过研究专家环境中检索增强生成（RAG）系统的需求工程。通过一个海事服务提供商的案例研究，我们展示了数据科学家如何在用户对AI完美性的期望与生成输出的正确性之间面临基本张力。我们的发现揭示了数据科学家必须通过与用户的迭代实验来识别特定于上下文的“检索需求”，因为他们是能够确定正确性的人。我们提出了一个经验过程模型，描述了数据科学家如何实际引出这些“检索需求”并管理系统限制。这项工作通过提供关于在复杂领域特定应用中实现RAG系统的专门需求工程过程的见解，推进了软件工程知识。", "motivation": "解决在专家环境中开发和集成大型语言模型（LLM）时，数据科学家面临的用户期望与生成输出正确性之间的基本张力问题。", "method": "通过一个海事服务提供商的案例研究，采用迭代实验与用户合作识别特定于上下文的“检索需求”。", "result": "发现数据科学家必须通过与用户的迭代实验来识别“检索需求”，并提出了一个经验过程模型来描述这一过程。", "conclusion": "这项工作为在复杂领域特定应用中实现RAG系统提供了专门的需求工程过程见解，推进了软件工程知识。"}}
