{"id": "2504.13275", "title": "ChartQA-X: Generating Explanations for Charts", "authors": ["Shamanthak Hegde", "Pooyan Fazli", "Hasti Seifi"], "abstract": "The ability to interpret and explain complex information from visual data in charts is crucial for data-driven decision-making. In this work, we address the challenge of providing explanations alongside answering questions about chart images. We present ChartQA-X, a comprehensive dataset comprising various chart types with 28,299 contextually relevant questions, answers, and detailed explanations. These explanations are generated by prompting six different models and selecting the best responses based on metrics such as faithfulness, informativeness, coherence, and perplexity. Our experiments show that models fine-tuned on our dataset for explanation generation achieve superior performance across various metrics and demonstrate improved accuracy in question-answering tasks on new datasets. By integrating answers with explanatory narratives, our approach enhances the ability of intelligent agents to convey complex information effectively, improve user understanding, and foster trust in the generated responses.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.13275.pdf", "abstract_url": "https://arxiv.org/abs/2504.13275", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了ChartQA-X，一个包含多种图表类型、28,299个上下文相关问题、答案及详细解释的综合数据集。通过提示六种不同模型并基于忠实度、信息量、连贯性和困惑度等指标选择最佳响应生成解释。实验表明，基于该数据集微调的模型在解释生成方面表现优异，并在新数据集上的问答任务中提高了准确性。", "motivation": "解决在回答图表图像问题的同时提供解释的挑战，以增强智能代理传达复杂信息的能力，提高用户理解并增强对生成回答的信任。", "method": "通过提示六种不同模型生成解释，并基于忠实度、信息量、连贯性和困惑度等指标选择最佳响应，构建ChartQA-X数据集。", "result": "基于ChartQA-X数据集微调的模型在解释生成方面表现优异，并在新数据集上的问答任务中提高了准确性。", "conclusion": "通过整合答案与解释性叙述，ChartQA-X增强了智能代理有效传达复杂信息的能力，改善了用户理解，并促进了生成回答的信任。"}}
{"id": "2504.13399", "title": "Towards a Multi-Agent Vision-Language System for Zero-Shot Novel Hazardous Object Detection for Autonomous Driving Safety", "authors": ["Shashank Shriram", "Srinivasa Perisetla", "Aryan Keskar", "Harsha Krishnaswamy", "Tonko Emil Westerhof Bossen", "Andreas Møgelmose", "Ross Greer"], "abstract": "Detecting anomalous hazards in visual data, particularly in video streams, is a critical challenge in autonomous driving. Existing models often struggle with unpredictable, out-of-label hazards due to their reliance on predefined object categories. In this paper, we propose a multimodal approach that integrates vision-language reasoning with zero-shot object detection to improve hazard identification and explanation. Our pipeline consists of a Vision-Language Model (VLM), a Large Language Model (LLM), in order to detect hazardous objects within a traffic scene. We refine object detection by incorporating OpenAI's CLIP model to match predicted hazards with bounding box annotations, improving localization accuracy. To assess model performance, we create a ground truth dataset by denoising and extending the foundational COOOL (Challenge-of-Out-of-Label) anomaly detection benchmark dataset with complete natural language descriptions for hazard annotations. We define a means of hazard detection and labeling evaluation on the extended dataset using cosine similarity. This evaluation considers the semantic similarity between the predicted hazard description and the annotated ground truth for each video. Additionally, we release a set of tools for structuring and managing large-scale hazard detection datasets. Our findings highlight the strengths and limitations of current vision-language-based approaches, offering insights into future improvements in autonomous hazard detection systems. Our models, scripts, and data can be found at", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.13399.pdf", "abstract_url": "https://arxiv.org/abs/2504.13399", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种多模态方法，结合视觉语言推理和零样本物体检测，以提高自动驾驶中对异常危险物体的识别和解释能力。通过集成视觉语言模型（VLM）和大语言模型（LLM），并使用OpenAI的CLIP模型优化物体检测，该方法在危险物体定位上取得了更高的准确性。研究还创建了一个基于COOOL基准数据集的地面真实数据集，用于评估模型性能，并发布了一套工具以支持大规模危险检测数据集的管理。", "motivation": "解决自动驾驶中因依赖预定义物体类别而难以识别不可预测、超出标签范围的危险物体的问题。", "method": "结合视觉语言模型（VLM）和大语言模型（LLM），利用OpenAI的CLIP模型优化物体检测，通过余弦相似度评估模型性能。", "result": "提出的方法在危险物体检测和定位上显示出更高的准确性，同时揭示了当前视觉语言方法在自动驾驶危险检测中的优势和局限。", "conclusion": "该研究为自动驾驶危险检测系统的未来改进提供了有价值的见解，并提供了模型、脚本和数据以支持进一步研究。"}}
{"id": "2504.13596", "title": "LMPOcc: 3D Semantic Occupancy Prediction Utilizing Long-Term Memory Prior from Historical Traversals", "authors": ["Shanshuai Yuan", "Julong Wei", "Muer Tie", "Xiangyun Ren", "Zhongxue Gan", "Wenchao Ding"], "abstract": "Vision-based 3D semantic occupancy prediction is critical for autonomous driving, enabling unified modeling of static infrastructure and dynamic agents. In practice, autonomous vehicles may repeatedly traverse identical geographic locations under varying environmental conditions, such as weather fluctuations and illumination changes. Existing methods in 3D occupancy prediction predominantly integrate adjacent temporal contexts. However, these works neglect to leverage perceptual information, which is acquired from historical traversals of identical geographic locations. In this paper, we propose Longterm Memory Prior Occupancy (LMPOcc), the first 3D occupancy prediction methodology that exploits long-term memory priors derived from historical traversal perceptual outputs. We introduce a plug-and-play architecture that integrates long-term memory priors to enhance local perception while simultaneously constructing global occupancy representations. To adaptively aggregate prior features and current features, we develop an efficient lightweight Current-Prior Fusion module. Moreover, we propose a model-agnostic prior format to ensure compatibility across diverse occupancy prediction baselines. LMPOcc achieves state-of-the-art performance validated on the Occ3D-nuScenes benchmark, especially on static semantic categories. Additionally, experimental results demonstrate LMPOcc's ability to construct global occupancy through multi-vehicle crowdsourcing.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.13596.pdf", "abstract_url": "https://arxiv.org/abs/2504.13596", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "LMPOcc是一种利用历史遍历感知输出的长期记忆先验进行3D语义占据预测的方法，首次在3D占据预测中利用历史遍历信息，通过插件式架构和轻量级当前-先验融合模块提升局部感知并构建全局占据表示，在Occ3D-nuScenes基准测试中达到最先进性能。", "motivation": "解决自动驾驶中基于视觉的3D语义占据预测问题，特别是在重复遍历相同地理位置时，如何利用历史感知信息来提升预测性能。", "method": "提出LMPOcc方法，包括一个插件式架构来整合长期记忆先验，一个轻量级的当前-先验融合模块来自适应聚合特征，以及一个模型无关的先验格式以确保兼容性。", "result": "在Occ3D-nuScenes基准测试中取得了最先进的性能，特别是在静态语义类别上，并展示了通过多车辆众包构建全局占据的能力。", "conclusion": "LMPOcc通过利用历史遍历的长期记忆先验，有效提升了3D语义占据预测的性能，特别是在静态基础设施的建模上，为自动驾驶提供了更统一的场景理解。"}}
{"id": "2504.13425", "title": "Secure Multifaceted-RAG for Enterprise: Hybrid Knowledge Retrieval with Security Filtering", "authors": ["Grace Byun", "Shinsun Lee", "Nayoung Choi", "Jinho Choi"], "abstract": "Existing Retrieval-Augmented Generation (RAG) systems face challenges in enterprise settings due to limited retrieval scope and data security risks. When relevant internal documents are unavailable, the system struggles to generate accurate and complete responses. Additionally, using closed-source Large Language Models (LLMs) raises concerns about exposing proprietary information. To address these issues, we propose the Secure Multifaceted-RAG (SecMulti-RAG) framework, which retrieves not only from internal documents but also from two supplementary sources: pre-generated expert knowledge for anticipated queries and on-demand external LLM-generated knowledge. To mitigate security risks, we adopt a local open-source generator and selectively utilize external LLMs only when prompts are deemed safe by a filtering mechanism. This approach enhances completeness, prevents data leakage, and reduces costs. In our evaluation on a report generation task in the automotive industry, SecMulti-RAG significantly outperforms traditional RAG - achieving 79.3 to 91.9 percent win rates across correctness, richness, and helpfulness in LLM-based evaluation, and 56.3 to 70.4 percent in human evaluation. This highlights SecMulti-RAG as a practical and secure solution for enterprise RAG.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.13425.pdf", "abstract_url": "https://arxiv.org/abs/2504.13425", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了Secure Multifaceted-RAG (SecMulti-RAG)框架，以解决企业环境中RAG系统检索范围有限和数据安全风险的问题。通过从内部文档、预生成专家知识和外部LLM生成知识三个来源检索，并结合安全过滤机制，SecMulti-RAG在汽车行业的报告生成任务中显著优于传统RAG。", "motivation": "解决企业环境中RAG系统因检索范围有限和数据安全风险而面临的挑战，包括生成准确完整回答的困难和使用闭源LLM可能暴露专有信息的担忧。", "method": "提出SecMulti-RAG框架，结合内部文档、预生成专家知识和外部LLM生成知识三种检索来源，采用本地开源生成器和安全过滤机制选择性使用外部LLM，以防止数据泄露并降低成本。", "result": "在汽车行业的报告生成任务中，SecMulti-RAG在基于LLM的评估中正确性、丰富性和帮助性方面达到79.3%至91.9%的胜率，在人类评估中达到56.3%至70.4%的胜率，显著优于传统RAG。", "conclusion": "SecMulti-RAG是一个实用且安全的企业RAG解决方案，通过多源检索和安全过滤机制，提高了回答的完整性和安全性，同时降低了成本。"}}
{"id": "2504.13650", "title": "EyecareGPT: Boosting Comprehensive Ophthalmology Understanding with Tailored Dataset, Benchmark and Model", "authors": ["Sijing Li", "Tianwei Lin", "Lingshuai Lin", "Wenqiao Zhang", "Jiang Liu", "Xiaoda Yang", "Juncheng Li", "Yucheng He", "Xiaohui Song", "Jun Xiao", "Yueting Zhuang", "Beng Chin Ooi"], "abstract": "Medical Large Vision-Language Models (Med-LVLMs) demonstrate significant potential in healthcare, but their reliance on general medical data and coarse-grained global visual understanding limits them in intelligent ophthalmic diagnosis. Currently, intelligent ophthalmic diagnosis faces three major challenges: (i) Data. The lack of deeply annotated, high-quality, multi-modal ophthalmic visual instruction data; (ii) Benchmark. The absence of a comprehensive and systematic benchmark for evaluating diagnostic performance; (iii) Model. The difficulty of adapting holistic visual architectures to fine-grained, region-specific ophthalmic lesion identification. In this paper, we propose the Eyecare Kit, which systematically tackles the aforementioned three key challenges with the tailored dataset, benchmark and model: First, we construct a multi-agent data engine with real-life ophthalmology data to produce Eyecare-100K, a high-quality ophthalmic visual instruction dataset. Subsequently, we design Eyecare-Bench, a benchmark that comprehensively evaluates the overall performance of LVLMs on intelligent ophthalmic diagnosis tasks across multiple dimensions. Finally, we develop the EyecareGPT, optimized for fine-grained ophthalmic visual understanding thoroughly, which incorporates an adaptive resolution mechanism and a layer-wise dense connector. Extensive experimental results indicate that the EyecareGPT achieves state-of-the-art performance in a range of ophthalmic tasks, underscoring its significant potential for the advancement of open research in intelligent ophthalmic diagnosis. Our project is available at", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.13650.pdf", "abstract_url": "https://arxiv.org/abs/2504.13650", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "EyecareGPT通过定制数据集、基准和模型，提升了全面眼科理解的能力，解决了智能眼科诊断中的数据、基准和模型三大挑战。", "motivation": "解决智能眼科诊断中缺乏高质量多模态眼科视觉指令数据、全面系统评估基准以及适应细粒度眼科病变识别的模型的问题。", "method": "构建多代理数据引擎生成高质量眼科视觉指令数据集Eyecare-100K，设计全面评估基准Eyecare-Bench，开发优化细粒度眼科视觉理解的EyecareGPT模型。", "result": "EyecareGPT在一系列眼科任务中实现了最先进的性能，展示了其在智能眼科诊断研究中的巨大潜力。", "conclusion": "Eyecare Kit通过其定制化的数据集、基准和模型，为智能眼科诊断的开放研究提供了重要的推动力。"}}
{"id": "2504.13534", "title": "CoT-RAG: Integrating Chain of Thought and Retrieval-Augmented Generation to Enhance Reasoning in Large Language Models", "authors": ["Feiyang Li", "Peng Fang", "Zhan Shi", "Arijit Khan", "Fang Wang", "Dan Feng", "Weihao Wang", "Xin Zhang", "Yongjian Cui"], "abstract": "While chain-of-thought (CoT) reasoning improves the performance of large language models (LLMs) in complex tasks, it still has two main challenges: the low reliability of relying solely on LLMs to generate reasoning chains and the interference of natural language reasoning chains on the inference logic of LLMs. To address these issues, we propose CoT-RAG, a novel reasoning framework with three key designs: (i) Knowledge Graph-driven CoT Generation, featuring knowledge graphs to modulate reasoning chain generation of LLMs, thereby enhancing reasoning credibility; (ii) Learnable Knowledge Case-aware RAG, which incorporates retrieval-augmented generation (RAG) into knowledge graphs to retrieve relevant sub-cases and sub-descriptions, providing LLMs with learnable information; (iii) Pseudo-Program Prompting Execution, which encourages LLMs to execute reasoning tasks in pseudo-programs with greater logical rigor. We conduct a comprehensive evaluation on nine public datasets, covering three reasoning problems. Compared with the-state-of-the-art methods, CoT-RAG exhibits a significant accuracy improvement, ranging from 4.0% to 23.0%. Furthermore, testing on four domain-specific datasets, CoT-RAG shows remarkable accuracy and efficient execution, highlighting its strong practical applicability and scalability.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.13534.pdf", "abstract_url": "https://arxiv.org/abs/2504.13534", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "CoT-RAG是一种新颖的推理框架，通过结合思维链（CoT）和检索增强生成（RAG）技术，利用知识图谱和伪程序提示执行来增强大型语言模型（LLMs）的推理能力。", "motivation": "解决思维链推理在复杂任务中依赖LLMs生成推理链的低可靠性问题，以及自然语言推理链对LLMs推理逻辑的干扰问题。", "method": "提出了CoT-RAG框架，包括知识图谱驱动的CoT生成、可学习的知识案例感知RAG和伪程序提示执行三个关键设计。", "result": "在九个公共数据集上的全面评估显示，CoT-RAG相比现有技术有4.0%到23.0%的准确率提升，且在四个特定领域数据集上表现出色。", "conclusion": "CoT-RAG不仅显著提高了LLMs的推理准确率，还展示了强大的实践适用性和可扩展性。"}}
{"id": "2504.13263", "title": "Causal-Copilot: An Autonomous Causal Analysis Agent", "authors": ["Xinyue Wang", "Kun Zhou", "Wenyi Wu", "Har Simrat Singh", "Fang Nan", "Songyao Jin", "Aryan Philip", "Saloni Patnaik", "Hou Zhu", "Shivam Singh", "Parjanya Prashant", "Qian Shen", "Biwei Huang"], "abstract": "Causal analysis plays a foundational role in scientific discovery and reliable decision-making, yet it remains largely inaccessible to domain experts due to its conceptual and algorithmic complexity. This disconnect between causal methodology and practical usability presents a dual challenge: domain experts are unable to leverage recent advances in causal learning, while causal researchers lack broad, real-world deployment to test and refine their methods. To address this, we introduce Causal-Copilot, an autonomous agent that operationalizes expert-level causal analysis within a large language model framework. Causal-Copilot automates the full pipeline of causal analysis for both tabular and time-series data -- including causal discovery, causal inference, algorithm selection, hyperparameter optimization, result interpretation, and generation of actionable insights. It supports interactive refinement through natural language, lowering the barrier for non-specialists while preserving methodological rigor. By integrating over 20 state-of-the-art causal analysis techniques, our system fosters a virtuous cycle -- expanding access to advanced causal methods for domain experts while generating rich, real-world applications that inform and advance causal theory. Empirical evaluations demonstrate that Causal-Copilot achieves superior performance compared to existing baselines, offering a reliable, scalable, and extensible solution that bridges the gap between theoretical sophistication and real-world applicability in causal analysis.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.13263.pdf", "abstract_url": "https://arxiv.org/abs/2504.13263", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "Causal-Copilot是一个基于大型语言模型框架的自主因果分析代理，旨在自动化因果分析的完整流程，包括因果发现、因果推断、算法选择等，并通过自然语言交互降低非专业人士的使用门槛。", "motivation": "解决因果分析方法与实际应用之间的脱节问题，使得领域专家能够利用最新的因果学习进展，同时为因果研究者提供广泛的真实世界应用以测试和完善他们的方法。", "method": "开发了一个自主代理Causal-Copilot，集成了20多种最先进的因果分析技术，自动化因果分析的完整流程，并支持通过自然语言进行交互式细化。", "result": "实证评估显示，Causal-Copilot在性能上优于现有基线，提供了一个可靠、可扩展和可扩展的解决方案，弥合了因果分析的理论复杂性和实际应用之间的差距。", "conclusion": "Causal-Copilot通过扩大领域专家对先进因果方法的访问，同时生成丰富的真实世界应用，促进了因果理论的发展和实际应用的进步。"}}
{"id": "2504.13643", "title": "Simulating Before Planning: Constructing Intrinsic User World Model for User-Tailored Dialogue Policy Planning", "authors": ["Tao He", "Lizi Liao", "Ming Liu", "Bing Qin"], "abstract": "Recent advancements in dialogue policy planning have emphasized optimizing system agent policies to achieve predefined goals, focusing on strategy design, trajectory acquisition, and efficient training paradigms. However, these approaches often overlook the critical role of user characteristics, which are essential in real-world scenarios like conversational search and recommendation, where interactions must adapt to individual user traits such as personality, preferences, and goals. To address this gap, we first conduct a comprehensive study utilizing task-specific user personas to systematically assess dialogue policy planning under diverse user behaviors. By leveraging realistic user profiles for different tasks, our study reveals significant limitations in existing approaches, highlighting the need for user-tailored dialogue policy planning. Building on this foundation, we present the User-Tailored Dialogue Policy Planning (UDP) framework, which incorporates an Intrinsic User World Model to model user traits and feedback. UDP operates in three stages: (1) User Persona Portraying, using a diffusion model to dynamically infer user profiles; (2) User Feedback Anticipating, leveraging a Brownian Bridge-inspired anticipator to predict user reactions; and (3) User-Tailored Policy Planning, integrating these insights to optimize response strategies. To ensure robust performance, we further propose an active learning approach that prioritizes challenging user personas during training. Comprehensive experiments on benchmarks, including collaborative and non-collaborative settings, demonstrate the effectiveness of UDP in learning user-specific dialogue strategies. Results validate the protocol's utility and highlight UDP's robustness, adaptability, and potential to advance user-centric dialogue systems.", "subjects": "Computation and Language (cs.CL)", "comments": "11 pages, 6 figures, SIGIR 2025", "pdf_url": "https://arxiv.org/pdf/2504.13643.pdf", "abstract_url": "https://arxiv.org/abs/2504.13643", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种用户定制对话策略规划（UDP）框架，通过构建内在用户世界模型来模拟用户特征和反馈，以优化对话策略，适应不同用户的个性、偏好和目标。", "motivation": "现有的对话策略规划方法往往忽视用户特征的重要性，这在需要根据用户个性、偏好和目标进行交互的真实场景（如对话搜索和推荐）中是一个重大缺陷。", "method": "UDP框架分为三个阶段：用户画像描绘（使用扩散模型动态推断用户档案）、用户反馈预测（利用布朗桥启发的预测器预测用户反应）和用户定制策略规划（整合这些洞察以优化响应策略）。此外，还提出了一种主动学习方法，在训练过程中优先考虑具有挑战性的用户画像。", "result": "在包括协作和非协作设置在内的基准测试上进行的全面实验证明了UDP在学习用户特定对话策略方面的有效性。结果验证了该协议的实用性，并突出了UDP的鲁棒性、适应性和推动以用户为中心的对话系统发展的潜力。", "conclusion": "UDP框架通过模拟用户特征和反馈，有效地优化了对话策略，适应不同用户的个性、偏好和目标，为推进以用户为中心的对话系统提供了新的方向。"}}
{"id": "2504.13314", "title": "On the Definition of Robustness and Resilience of AI Agents for Real-time Congestion Management", "authors": ["Timothy Tjhay", "Ricardo J. Bessa", "Jose Paulos"], "abstract": "The European Union's Artificial Intelligence (AI) Act defines robustness, resilience, and security requirements for high-risk sectors but lacks detailed methodologies for assessment. This paper introduces a novel framework for quantitatively evaluating the robustness and resilience of reinforcement learning agents in congestion management. Using the AI-friendly digital environment Grid2Op, perturbation agents simulate natural and adversarial disruptions by perturbing the input of AI systems without altering the actual state of the environment, enabling the assessment of AI performance under various scenarios. Robustness is measured through stability and reward impact metrics, while resilience quantifies recovery from performance degradation. The results demonstrate the framework's effectiveness in identifying vulnerabilities and improving AI robustness and resilience for critical applications.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "IEEE PowerTech 2025 Conference", "pdf_url": "https://arxiv.org/pdf/2504.13314.pdf", "abstract_url": "https://arxiv.org/abs/2504.13314", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "欧盟的《人工智能法案》对高风险领域提出了鲁棒性、弹性和安全性要求，但缺乏详细的评估方法。本文介绍了一种新颖的框架，用于定量评估强化学习代理在拥堵管理中的鲁棒性和弹性。", "motivation": "解决欧盟《人工智能法案》在高风险领域对AI代理的鲁棒性、弹性和安全性要求缺乏详细评估方法的问题。", "method": "使用Grid2Op这一AI友好的数字环境，通过扰动代理模拟自然和对抗性干扰，评估AI在各种场景下的性能。", "result": "结果表明，该框架能有效识别漏洞，并提高AI在关键应用中的鲁棒性和弹性。", "conclusion": "本文提出的框架为评估和提高AI代理在拥堵管理等关键应用中的鲁棒性和弹性提供了有效方法。"}}
{"id": "2504.13443", "title": "Trust, but verify", "authors": ["Michael J. Yuan", "Carlos Campoy", "Sydney Lai", "James Snewin", "Ju Long"], "abstract": "Decentralized AI agent networks, such as Gaia, allows individuals to run customized LLMs on their own computers and then provide services to the public. However, in order to maintain service quality, the network must verify that individual nodes are running their designated LLMs. In this paper, we demonstrate that in a cluster of mostly honest nodes, we can detect nodes that run unauthorized or incorrect LLM through social consensus of its peers. We will discuss the algorithm and experimental data from the Gaia network. We will also discuss the intersubjective validation system, implemented as an EigenLayer AVS to introduce financial incentives and penalties to encourage honest behavior from LLM nodes.", "subjects": "Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Multiagent Systems (cs.MA); General Economics (econ.GN)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.13443.pdf", "abstract_url": "https://arxiv.org/abs/2504.13443", "categories": ["Artificial Intelligence (cs.AI)", "Distributed, Parallel, and Cluster Computing (cs.DC)", "Multiagent Systems (cs.MA)", "General Economics (econ.GN)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了在去中心化AI代理网络（如Gaia）中，如何通过社交共识和EigenLayer AVS实现的交叉主观验证系统，检测并激励节点运行正确的LLM，以维持服务质量。", "motivation": "解决去中心化AI代理网络中，确保个体节点运行指定LLM以维持服务质量的问题。", "method": "在主要由诚实节点组成的集群中，通过社交共识检测运行未经授权或不正确LLM的节点，并实施EigenLayer AVS系统以引入财务激励和惩罚机制。", "result": "实验数据表明，该方法能有效检测并激励节点运行正确的LLM。", "conclusion": "通过社交共识和财务激励机制，可以有效维护去中心化AI代理网络的服务质量和安全性。"}}
{"id": "2504.13554", "title": "Task Assignment and Exploration Optimization for Low Altitude UAV Rescue via Generative AI Enhanced Multi-agent Reinforcement Learning", "authors": ["Xin Tang", "Qian Chen", "Wenjie Weng", "Chao Jin", "Zhang Liu", "Jiacheng Wang", "Geng Sun", "Xiaohuan Li", "Dusit Niyato"], "abstract": "Artificial Intelligence (AI)-driven convolutional neural networks enhance rescue, inspection, and surveillance tasks performed by low-altitude uncrewed aerial vehicles (UAVs) and ground computing nodes (GCNs) in unknown environments. However, their high computational demands often exceed a single UAV's capacity, leading to system instability, further exacerbated by the limited and dynamic resources of GCNs. To address these challenges, this paper proposes a novel cooperation framework involving UAVs, ground-embedded robots (GERs), and high-altitude platforms (HAPs), which enable resource pooling through UAV-to-GER (U2G) and UAV-to-HAP (U2H) communications to provide computing services for UAV offloaded tasks. Specifically, we formulate the multi-objective optimization problem of task assignment and exploration optimization in UAVs as a dynamic long-term optimization problem. Our objective is to minimize task completion time and energy consumption while ensuring system stability over time. To achieve this, we first employ the Lyapunov optimization technique to transform the original problem, with stability constraints, into a per-slot deterministic problem. We then propose an algorithm named HG-MADDPG, which combines the Hungarian algorithm with a generative diffusion model (GDM)-based multi-agent deep deterministic policy gradient (MADDPG) approach. We first introduce the Hungarian algorithm as a method for exploration area selection, enhancing UAV efficiency in interacting with the environment. We then innovatively integrate the GDM and multi-agent deep deterministic policy gradient (MADDPG) to optimize task assignment decisions, such as task offloading and resource allocation. Simulation results demonstrate the effectiveness of the proposed approach, with significant improvements in task offloading efficiency, latency reduction, and system stability compared to baseline methods.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.13554.pdf", "abstract_url": "https://arxiv.org/abs/2504.13554", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新型的合作框架，结合了无人机(UAVs)、地面嵌入式机器人(GERs)和高空平台(HAPs)，通过UAV-to-GER (U2G)和UAV-to-HAP (U2H)通信实现资源池化，以支持无人机卸载任务的计算服务。通过Lyapunov优化技术和HG-MADDPG算法，有效解决了任务分配和探索优化的多目标优化问题，显著提高了任务卸载效率、减少了延迟并增强了系统稳定性。", "motivation": "解决在未知环境中，由AI驱动的卷积神经网络在执行救援、检查和监视任务时，由于高计算需求超出单个无人机能力而导致的系统不稳定性问题，以及地面计算节点(GCNs)资源有限和动态变化的挑战。", "method": "采用Lyapunov优化技术将原始问题转化为每时隙确定性问题，并提出HG-MADDPG算法，该算法结合了匈牙利算法和基于生成扩散模型(GDM)的多智能体深度确定性策略梯度(MADDPG)方法，优化任务分配决策。", "result": "仿真结果表明，与基线方法相比，所提出的方法在任务卸载效率、延迟减少和系统稳定性方面均有显著改进。", "conclusion": "通过提出的合作框架和HG-MADDPG算法，不仅解决了无人机在未知环境中的任务分配和探索优化问题，还显著提高了系统的整体性能和稳定性，为未来的无人机救援任务提供了有效的技术支持。"}}
{"id": "2504.13707", "title": "OpenDeception: Benchmarking and Investigating AI Deceptive Behaviors via Open-ended Interaction Simulation", "authors": ["Yichen Wu", "Xudong Pan", "Geng Hong", "Min Yang"], "abstract": "As the general capabilities of large language models (LLMs) improve and agent applications become more widespread, the underlying deception risks urgently require systematic evaluation and effective oversight. Unlike existing evaluation which uses simulated games or presents limited choices, we introduce OpenDeception, a novel deception evaluation framework with an open-ended scenario dataset. OpenDeception jointly evaluates both the deception intention and capabilities of LLM-based agents by inspecting their internal reasoning process. Specifically, we construct five types of common use cases where LLMs intensively interact with the user, each consisting of ten diverse, concrete scenarios from the real world. To avoid ethical concerns and costs of high-risk deceptive interactions with human testers, we propose to simulate the multi-turn dialogue via agent simulation. Extensive evaluation of eleven mainstream LLMs on OpenDeception highlights the urgent need to address deception risks and security concerns in LLM-based agents: the deception intention ratio across the models exceeds 80%, while the deception success rate surpasses 50%. Furthermore, we observe that LLMs with stronger capabilities do exhibit a higher risk of deception, which calls for more alignment efforts on inhibiting deceptive behaviors.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.13707.pdf", "abstract_url": "https://arxiv.org/abs/2504.13707", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了OpenDeception，一个新颖的欺骗评估框架，用于系统评估大型语言模型（LLM）基于代理的欺骗意图和能力。通过构建五种常见用例和十个多样化场景，该框架在避免伦理问题和高风险欺骗交互成本的同时，模拟多轮对话。对11种主流LLM的广泛评估显示，欺骗意图比例超过80%，欺骗成功率超过50%，且能力更强的LLM表现出更高的欺骗风险。", "motivation": "随着大型语言模型（LLM）能力的提升和代理应用的普及，其潜在的欺骗风险亟需系统评估和有效监督。现有评估方法多使用模拟游戏或提供有限选择，无法全面评估LLM的欺骗行为。", "method": "OpenDeception框架通过构建五种常见用例和十个多样化场景，模拟多轮对话来评估LLM的欺骗意图和能力，同时避免伦理问题和高风险欺骗交互的成本。", "result": "对11种主流LLM的评估显示，欺骗意图比例超过80%，欺骗成功率超过50%。此外，能力更强的LLM表现出更高的欺骗风险。", "conclusion": "研究结果强调了在LLM基于代理的应用中解决欺骗风险和安全问题的紧迫性，呼吁在抑制欺骗行为方面进行更多对齐努力。"}}
{"id": "2504.13775", "title": "BadApex: Backdoor Attack Based on Adaptive Optimization Mechanism of Black-box Large Language Models", "authors": ["Zhengxian Wu", "Juan Wen", "Wanli Peng", "Ziwei Zhang", "Yinghan Zhou", "Yiming Xue"], "abstract": "Previous insertion-based and paraphrase-based backdoors have achieved great success in attack efficacy, but they ignore the text quality and semantic consistency between poisoned and clean texts. Although recent studies introduce LLMs to generate poisoned texts and improve the stealthiness, semantic consistency, and text quality, their hand-crafted prompts rely on expert experiences, facing significant challenges in prompt adaptability and attack performance after defenses. In this paper, we propose a novel backdoor attack based on adaptive optimization mechanism of black-box large language models (BadApex), which leverages a black-box LLM to generate poisoned text through a refined prompt. Specifically, an Adaptive Optimization Mechanism is designed to refine an initial prompt iteratively using the generation and modification agents. The generation agent generates the poisoned text based on the initial prompt. Then the modification agent evaluates the quality of the poisoned text and refines a new prompt. After several iterations of the above process, the refined prompt is used to generate poisoned texts through LLMs. We conduct extensive experiments on three dataset with six backdoor attacks and two defenses. Extensive experimental results demonstrate that BadApex significantly outperforms state-of-the-art attacks. It improves prompt adaptability, semantic consistency, and text quality. Furthermore, when two defense methods are applied, the average attack success rate (ASR) still up to 96.75%.", "subjects": "Computation and Language (cs.CL); Cryptography and Security (cs.CR)", "comments": "16 pages, 6 figures", "pdf_url": "https://arxiv.org/pdf/2504.13775.pdf", "abstract_url": "https://arxiv.org/abs/2504.13775", "categories": ["Computation and Language (cs.CL)", "Cryptography and Security (cs.CR)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于黑盒大型语言模型自适应优化机制的新型后门攻击方法（BadApex），通过迭代优化提示生成高质量、语义一致的毒化文本，显著提高了攻击效果和隐蔽性。", "motivation": "解决现有后门攻击方法在文本质量、语义一致性和对抗防御方面的不足。", "method": "采用自适应优化机制，通过生成和修改代理迭代优化初始提示，利用黑盒大型语言模型生成毒化文本。", "result": "在三个数据集上的实验表明，BadApex在攻击成功率、提示适应性、语义一致性和文本质量上均显著优于现有方法，即使在防御措施下平均攻击成功率仍高达96.75%。", "conclusion": "BadApex通过自适应优化机制有效提升了后门攻击的性能和隐蔽性，为大型语言模型的安全性研究提供了新的挑战和方向。"}}
{"id": "2504.13834", "title": "Science Hierarchography: Hierarchical Organization of Science Literature", "authors": ["Muhan Gao", "Jash Shah", "Weiqi Wang", "Daniel Khashabi"], "abstract": "Scientific knowledge is growing rapidly, making it challenging to track progress and high-level conceptual links across broad disciplines. While existing tools like citation networks and search engines make it easy to access a few related papers, they fundamentally lack the flexible abstraction needed to represent the density of activity in various scientific subfields. We motivate SCIENCE HIERARCHOGRAPHY, the goal of organizing scientific literature into a high-quality hierarchical structure that allows for the categorization of scientific work across varying levels of abstraction, from very broad fields to very specific studies. Such a representation can provide insights into which fields are well-explored and which are under-explored. To achieve the goals of SCIENCE HIERARCHOGRAPHY, we develop a range of algorithms. Our primary approach combines fast embedding-based clustering with LLM-based prompting to balance the computational efficiency of embedding methods with the semantic precision offered by LLM prompting. We demonstrate that this approach offers the best trade-off between quality and speed compared to methods that heavily rely on LLM prompting, such as iterative tree construction with LLMs. To better reflect the interdisciplinary and multifaceted nature of research papers, our hierarchy captures multiple dimensions of categorization beyond simple topic labels. We evaluate the utility of our framework by assessing how effectively an LLM-based agent can locate target papers using the hierarchy. Results show that this structured approach enhances interpretability, supports trend discovery, and offers an alternative pathway for exploring scientific literature beyond traditional search methods. Code, data and demo: $\\href{", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.13834.pdf", "abstract_url": "https://arxiv.org/abs/2504.13834", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了科学层次图（SCIENCE HIERARCHOGRAPHY）的概念，旨在将科学文献组织成一个高质量的层次结构，以便在不同抽象级别上对科学工作进行分类。通过结合快速嵌入聚类和基于大型语言模型（LLM）的提示方法，该方法在质量和速度之间达到了最佳平衡，并能够捕捉研究论文的多维度分类。评估结果表明，这种结构化方法提高了可解释性，支持趋势发现，并提供了探索科学文献的替代途径。", "motivation": "科学知识的快速增长使得跨广泛学科跟踪进展和高层次概念联系变得具有挑战性。现有的工具如引用网络和搜索引擎虽然便于访问少量相关论文，但缺乏灵活抽象来表示各科学子领域的活动密度。", "method": "主要方法结合了快速嵌入聚类和基于LLM的提示，以平衡嵌入方法的计算效率和LLM提示提供的语义精确性。这种方法比严重依赖LLM提示的方法（如使用LLMs的迭代树构建）在质量和速度之间提供了更好的权衡。", "result": "结果表明，这种结构化方法增强了可解释性，支持趋势发现，并提供了超越传统搜索方法的科学文献探索替代途径。基于LLM的代理能够更有效地利用层次结构定位目标论文。", "conclusion": "科学层次图提供了一种有效的方法来组织和探索科学文献，通过多层次和多维度的分类，揭示了哪些领域被充分探索，哪些领域尚未充分探索。这种方法不仅提高了文献检索的效率，还为科学研究的趋势分析提供了新的视角。"}}
{"id": "2504.13203", "title": "X-Teaming: Multi-Turn Jailbreaks and Defenses with Adaptive Multi-Agents", "authors": ["Salman Rahman", "Liwei Jiang", "James Shiffer", "Genglin Liu", "Sheriff Issaka", "Md Rizwan Parvez", "Hamid Palangi", "Kai-Wei Chang", "Yejin Choi", "Saadia Gabriel"], "abstract": "Multi-turn interactions with language models (LMs) pose critical safety risks, as harmful intent can be strategically spread across exchanges. Yet, the vast majority of prior work has focused on single-turn safety, while adaptability and diversity remain among the key challenges of multi-turn red-teaming. To address these challenges, we present X-Teaming, a scalable framework that systematically explores how seemingly harmless interactions escalate into harmful outcomes and generates corresponding attack scenarios. X-Teaming employs collaborative agents for planning, attack optimization, and verification, achieving state-of-the-art multi-turn jailbreak effectiveness and diversity with success rates up to 98.1% across representative leading open-weight and closed-source models. In particular, X-Teaming achieves a 96.2% attack success rate against the latest Claude 3.7 Sonnet model, which has been considered nearly immune to single-turn attacks. Building on X-Teaming, we introduce XGuard-Train, an open-source multi-turn safety training dataset that is 20x larger than the previous best resource, comprising 30K interactive jailbreaks, designed to enable robust multi-turn safety alignment for LMs. Our work offers essential tools and insights for mitigating sophisticated conversational attacks, advancing the multi-turn safety of LMs.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.13203.pdf", "abstract_url": "https://arxiv.org/abs/2504.13203", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了X-Teaming框架，用于系统地探索多轮交互中无害对话如何升级为有害结果，并生成相应的攻击场景。该框架通过协作代理进行规划、攻击优化和验证，在多轮越狱攻击的有效性和多样性方面达到了最先进水平。", "motivation": "解决多轮交互中语言模型的安全风险，特别是如何应对策略性分布在多个交流中的有害意图，以及多轮红队测试中的适应性和多样性挑战。", "method": "采用X-Teaming框架，利用协作代理进行规划、攻击优化和验证，生成多轮攻击场景，并引入XGuard-Train数据集进行安全训练。", "result": "X-Teaming在多轮越狱攻击中取得了高达98.1%的成功率，特别是在对抗Claude 3.7 Sonnet模型时达到了96.2%的攻击成功率。XGuard-Train数据集比之前最佳资源大20倍，包含30K交互式越狱攻击。", "conclusion": "X-Teaming和XGuard-Train为减轻复杂对话攻击提供了必要的工具和见解，推动了语言模型在多轮安全方面的进步。"}}
{"id": "2504.13183", "title": "Factors That Influence the Adoption of AI-enabled Conversational Agents (AICAs) as an Augmenting Therapeutic Tool by Frontline Healthcare Workers: From Technology Acceptance Model 3 (TAM3) Lens -- A Systematic Mapping Review", "authors": ["Rawan AlMakinah"], "abstract": "Artificial intelligent (AI) conversational agents hold a promising future in the field of mental health, especially in helping marginalized communities that lack access to mental health support services. It is tempting to have a 24/7 mental health companion that can be accessed anywhere using mobile phones to provide therapist-like advice. Yet, caution should be taken, and studies around their feasibility need to be surveyed. Before adopting such a rapidly changing technology, studies on its feasibility should be explored, summarized, and synthesized to gain a solid understanding of the status quo and to enable us to build a framework that can guide us throughout the development and deployment processes. Different perspectives must be considered when investigating the feasibility of AI conversational agents, including the mental healthcare professional perspective. The literature can provide insights into their perspectives in terms of opportunities, concerns, and implications. Mental health professionals, the subject-matter experts in this field, have their points of view that should be understood and considered. This systematic literature review will explore mental health practitioners' attitudes toward AI conversational agents and the factors that affect their adoption and recommendation of the technology to augment their services and treatments. The TAM3 Framework will be the lens through which this systematic literature review will be conducted.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.13183.pdf", "abstract_url": "https://arxiv.org/abs/2504.13183", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过技术接受模型3（TAM3）的视角，系统性地回顾了影响前线医疗工作者采用AI对话代理（AICAs）作为增强治疗工具的因素。", "motivation": "解决AI对话代理在心理健康领域，特别是对缺乏心理健康支持服务的边缘化社区的可行性问题，并探索医疗专业人员对这项技术的态度和采纳因素。", "method": "采用系统映射回顾方法，以TAM3框架为视角，综合分析相关文献。", "result": "文献回顾揭示了心理健康专业人员对AI对话代理的看法，包括机会、担忧和影响，以及影响他们采纳和推荐该技术的因素。", "conclusion": "理解并考虑心理健康专业人员的观点对于开发和部署AI对话代理至关重要，TAM3框架为这一过程提供了有价值的指导。"}}
{"id": "2504.13192", "title": "CheatAgent: Attacking LLM-Empowered Recommender Systems via LLM Agent", "authors": ["Liang-bo Ning", "Shijie Wang", "Wenqi Fan", "Qing Li", "Xin Xu", "Hao Chen", "Feiran Huang"], "abstract": "Recently, Large Language Model (LLM)-empowered recommender systems (RecSys) have brought significant advances in personalized user experience and have attracted considerable attention. Despite the impressive progress, the research question regarding the safety vulnerability of LLM-empowered RecSys still remains largely under-investigated. Given the security and privacy concerns, it is more practical to focus on attacking the black-box RecSys, where attackers can only observe the system's inputs and outputs. However, traditional attack approaches employing reinforcement learning (RL) agents are not effective for attacking LLM-empowered RecSys due to the limited capabilities in processing complex textual inputs, planning, and reasoning. On the other hand, LLMs provide unprecedented opportunities to serve as attack agents to attack RecSys because of their impressive capability in simulating human-like decision-making processes. Therefore, in this paper, we propose a novel attack framework called CheatAgent by harnessing the human-like capabilities of LLMs, where an LLM-based agent is developed to attack LLM-Empowered RecSys. Specifically, our method first identifies the insertion position for maximum impact with minimal input modification. After that, the LLM agent is designed to generate adversarial perturbations to insert at target positions. To further improve the quality of generated perturbations, we utilize the prompt tuning technique to improve attacking strategies via feedback from the victim RecSys iteratively. Extensive experiments across three real-world datasets demonstrate the effectiveness of our proposed attacking method.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.13192.pdf", "abstract_url": "https://arxiv.org/abs/2504.13192", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为CheatAgent的新型攻击框架，利用大型语言模型（LLM）的人类模拟能力，开发了一个基于LLM的代理来攻击LLM赋能的推荐系统（RecSys）。通过识别最大影响的最小输入修改位置，并设计LLM代理生成对抗性扰动，结合提示调优技术迭代改进攻击策略，实验证明了该方法的有效性。", "motivation": "尽管LLM赋能的推荐系统在个性化用户体验方面取得了显著进展，但其安全脆弱性研究仍未被充分探讨。考虑到安全和隐私问题，研究如何攻击黑盒推荐系统更为实际。传统攻击方法在处理复杂文本输入、规划和推理方面能力有限，而LLMs因其模拟人类决策过程的能力为攻击推荐系统提供了新机会。", "method": "提出CheatAgent攻击框架，首先识别对输入进行最小修改以获得最大影响的插入位置，然后设计LLM代理生成对抗性扰动插入目标位置。利用提示调优技术，根据受害推荐系统的反馈迭代改进攻击策略。", "result": "在三个真实世界数据集上的广泛实验证明了所提出的攻击方法的有效性。", "conclusion": "本研究揭示了LLM赋能推荐系统的安全脆弱性，并提出了一种有效的攻击框架CheatAgent，为未来推荐系统的安全研究提供了新的方向和挑战。"}}
{"id": "2504.13209", "title": "On the Feasibility of Using MultiModal LLMs to Execute AR Social Engineering Attacks", "authors": ["Ting Bi", "Chenghang Ye", "Zheyu Yang", "Ziyi Zhou", "Cui Tang", "Jun Zhang", "Zui Tao", "Kailong Wang", "Liting Zhou", "Yang Yang", "Tianlong Yu"], "abstract": "Augmented Reality (AR) and Multimodal Large Language Models (LLMs) are rapidly evolving, providing unprecedented capabilities for human-computer interaction. However, their integration introduces a new attack surface for social engineering. In this paper, we systematically investigate the feasibility of orchestrating AR-driven Social Engineering attacks using Multimodal LLM for the first time, via our proposed SEAR framework, which operates through three key phases: (1) AR-based social context synthesis, which fuses Multimodal inputs (visual, auditory and environmental cues); (2) role-based Multimodal RAG (Retrieval-Augmented Generation), which dynamically retrieves and integrates contextual data while preserving character differentiation; and (3) ReInteract social engineering agents, which execute adaptive multiphase attack strategies through inference interaction loops. To verify SEAR, we conducted an IRB-approved study with 60 participants in three experimental configurations (unassisted, AR+LLM, and full SEAR pipeline) compiling a new dataset of 180 annotated conversations in simulated social scenarios. Our results show that SEAR is highly effective at eliciting high-risk behaviors (e.g., 93.3% of participants susceptible to email phishing). The framework was particularly effective in building trust, with 85% of targets willing to accept an attacker's call after an interaction. Also, we identified notable limitations such as ``occasionally artificial'' due to perceived authenticity gaps. This work provides proof-of-concept for AR-LLM driven social engineering attacks and insights for developing defensive countermeasures against next-generation augmented reality threats.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.13209.pdf", "abstract_url": "https://arxiv.org/abs/2504.13209", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文首次系统地研究了利用多模态大型语言模型（LLM）和增强现实（AR）技术进行社交工程攻击的可行性，提出了SEAR框架，并通过实验验证了其高效性。", "motivation": "随着AR和多模态LLM的快速发展，它们在提升人机交互能力的同时，也引入了新的社交工程攻击面。本文旨在探索这一新攻击面的可行性。", "method": "提出了SEAR框架，包括三个关键阶段：AR社交上下文合成、基于角色的多模态RAG和ReInteract社交工程代理，通过这三个阶段执行自适应多阶段攻击策略。", "result": "实验结果显示，SEAR框架在诱导高风险行为方面非常有效（如93.3%的参与者容易受到电子邮件钓鱼攻击），并且在建立信任方面特别有效（85%的目标在互动后愿意接受攻击者的电话）。", "conclusion": "这项工作为AR-LLM驱动的社交工程攻击提供了概念验证，并为开发针对下一代增强现实威胁的防御措施提供了见解。"}}
{"id": "2504.13406", "title": "LangCoop: Collaborative Driving with Language", "authors": ["Xiangbo Gao", "Yuheng Wu", "Rujia Wang", "Chenxi Liu", "Yang Zhou", "Zhengzhong Tu"], "abstract": "Multi-agent collaboration holds great promise for enhancing the safety, reliability, and mobility of autonomous driving systems by enabling information sharing among multiple connected agents. However, existing multi-agent communication approaches are hindered by limitations of existing communication media, including high bandwidth demands, agent heterogeneity, and information loss. To address these challenges, we introduce LangCoop, a new paradigm for collaborative autonomous driving that leverages natural language as a compact yet expressive medium for inter-agent communication. LangCoop features two key innovations: Mixture Model Modular Chain-of-thought (M$^3$CoT) for structured zero-shot vision-language reasoning and Natural Language Information Packaging (LangPack) for efficiently packaging information into concise, language-based messages. Through extensive experiments conducted in the CARLA simulations, we demonstrate that LangCoop achieves a remarkable 96\\% reduction in communication bandwidth (< 2KB per message) compared to image-based communication, while maintaining competitive driving performance in the closed-loop evaluation.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.13406.pdf", "abstract_url": "https://arxiv.org/abs/2504.13406", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "LangCoop提出了一种利用自然语言作为多智能体间通信媒介的新范式，旨在解决自动驾驶系统中多智能体协作的通信带宽高、智能体异构性和信息丢失等问题。通过M$^3$CoT和LangPack两项关键技术，LangCoop在CARLA模拟实验中实现了通信带宽的显著降低，同时保持了竞争力的驾驶性能。", "motivation": "解决现有自动驾驶多智能体通信方法在带宽需求高、智能体异构性和信息丢失方面的限制。", "method": "采用自然语言作为通信媒介，引入Mixture Model Modular Chain-of-thought (M$^3$CoT)进行结构化零样本视觉语言推理，以及Natural Language Information Packaging (LangPack)高效打包信息为简洁的语言消息。", "result": "在CARLA模拟实验中，LangCoop相比基于图像的通信方法减少了96%的通信带宽（每条消息<2KB），同时在闭环评估中保持了竞争力的驾驶性能。", "conclusion": "LangCoop通过自然语言作为通信媒介，有效解决了多智能体协作自动驾驶中的通信问题，为未来的自动驾驶系统提供了新的协作通信范式。"}}
{"id": "2504.13574", "title": "MAAM: A Lightweight Multi-Agent Aggregation Module for Efficient Image Classification Based on the MindSpore Framework", "authors": ["Zhenkai Qin", "Feng Zhu", "Huan Zeng", "Xunyi Nong"], "abstract": "The demand for lightweight models in image classification tasks under resource-constrained environments necessitates a balance between computational efficiency and robust feature representation. Traditional attention mechanisms, despite their strong feature modeling capability, often struggle with high computational complexity and structural rigidity, limiting their applicability in scenarios with limited computational resources (e.g., edge devices or real-time systems). To address this, we propose the Multi-Agent Aggregation Module (MAAM), a lightweight attention architecture integrated with the MindSpore framework. MAAM employs three parallel agent branches with independently parameterized operations to extract heterogeneous features, adaptively fused via learnable scalar weights, and refined through a convolutional compression layer. Leveraging MindSpore's dynamic computational graph and operator fusion, MAAM achieves 87.0% accuracy on the CIFAR-10 dataset, significantly outperforming conventional CNN (58.3%) and MLP (49.6%) models, while improving training efficiency by 30%. Ablation studies confirm the critical role of agent attention (accuracy drops to 32.0% if removed) and compression modules (25.5% if omitted), validating their necessity for maintaining discriminative feature learning. The framework's hardware acceleration capabilities and minimal memory footprint further demonstrate its practicality, offering a deployable solution for image classification in resource-constrained scenarios without compromising accuracy.", "subjects": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.13574.pdf", "abstract_url": "https://arxiv.org/abs/2504.13574", "categories": ["Machine Learning (cs.LG)", "Computer Vision and Pattern Recognition (cs.CV)", "Image and Video Processing (eess.IV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种轻量级的多智能体聚合模块（MAAM），用于在资源受限环境下实现高效的图像分类，该模块通过三个并行智能体分支提取异构特征，并通过MindSpore框架实现硬件加速和高效训练。", "motivation": "解决在资源受限环境（如边缘设备或实时系统）中，传统注意力机制因高计算复杂性和结构刚性而难以平衡计算效率和特征表示鲁棒性的问题。", "method": "提出MAAM模块，采用三个并行智能体分支独立参数化操作提取异构特征，通过可学习标量权重自适应融合，并通过卷积压缩层进行精炼。", "result": "在CIFAR-10数据集上达到87.0%的准确率，显著优于传统CNN（58.3%）和MLP（49.6%）模型，同时训练效率提高30%。", "conclusion": "MAAM模块通过其硬件加速能力和最小内存占用，为资源受限场景下的图像分类提供了可行的解决方案，且不牺牲准确性。"}}
{"id": "2504.13472", "title": "CodeVisionary: An Agent-based Framework for Evaluating Large Language Models in Code Generation", "authors": ["Xinchen Wang", "Pengfei Gao", "Chao Peng", "Ruida Hu", "Cuiyun Gao"], "abstract": "Large language models (LLMs) have demonstrated strong capabilities in code generation, underscoring the critical need for rigorous and comprehensive evaluation. Existing evaluation approaches fall into three categories, including human-centered, metric-based, and LLM-based. Considering that human-centered approaches are labour-intensive and metric-based ones overly rely on reference answers, LLM-based approaches are gaining increasing attention due to their stronger contextual understanding capabilities and superior efficiency. However, the performance of LLM-based approaches remains limited due to: (1) lack of multisource domain knowledge, and (2) insufficient comprehension of complex code.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.13472.pdf", "abstract_url": "https://arxiv.org/abs/2504.13472", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了CodeVisionary，一个基于代理的框架，用于评估大型语言模型在代码生成中的表现。", "motivation": "解决现有评估方法在评估大型语言模型代码生成能力时的不足，特别是基于LLM的方法在多元领域知识和复杂代码理解方面的限制。", "method": "提出了一个基于代理的框架，旨在通过增强上下文理解能力和效率，改进对大型语言模型在代码生成中的评估。", "result": "CodeVisionary框架能够更全面、高效地评估大型语言模型在代码生成中的表现，尤其是在处理复杂代码和多元领域知识时。", "conclusion": "CodeVisionary为评估大型语言模型在代码生成中的能力提供了一个更有效的工具，有助于推动相关技术的发展和应用。"}}
{"id": "2504.13241", "title": "Recursive Deep Inverse Reinforcement Learning", "authors": ["Paul Ghanem", "Michael Potter", "Owen Howell", "Pau Closas", "Alireza Ramezani", "Deniz Erdogmus", "Robert Platt", "Tales Imbiriba"], "abstract": "Inferring an adversary's goals from exhibited behavior is crucial for counterplanning and non-cooperative multi-agent systems in domains like cybersecurity, military, and strategy games. Deep Inverse Reinforcement Learning (IRL) methods based on maximum entropy principles show promise in recovering adversaries' goals but are typically offline, require large batch sizes with gradient descent, and rely on first-order updates, limiting their applicability in real-time scenarios. We propose an online Recursive Deep Inverse Reinforcement Learning (RDIRL) approach to recover the cost function governing the adversary actions and goals. Specifically, we minimize an upper bound on the standard Guided Cost Learning (GCL) objective using sequential second-order Newton updates, akin to the Extended Kalman Filter (EKF), leading to a fast (in terms of convergence) learning algorithm. We demonstrate that RDIRL is able to recover cost and reward functions of expert agents in standard and adversarial benchmark tasks. Experiments on benchmark tasks show that our proposed approach outperforms several leading IRL algorithms.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.13241.pdf", "abstract_url": "https://arxiv.org/abs/2504.13241", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种在线递归深度逆强化学习（RDIRL）方法，用于从对手行为中推断其目标和成本函数，适用于网络安全、军事和策略游戏等领域。", "motivation": "解决现有深度逆强化学习方法在实时场景中应用的局限性，如需要离线处理、大批量梯度下降和一阶更新。", "method": "采用基于最大熵原则的递归深度逆强化学习方法，通过顺序二阶牛顿更新最小化标准引导成本学习（GCL）目标的上界，类似于扩展卡尔曼滤波器（EKF）。", "result": "实验表明，RDIRL在标准和对抗性基准任务中能够有效恢复专家代理的成本和奖励函数，且性能优于多种领先的逆强化学习算法。", "conclusion": "RDIRL提供了一种快速收敛的学习算法，能够实时推断对手目标，对于非合作多智能体系统和对抗性环境中的策略规划具有重要意义。"}}
{"id": "2504.13515", "title": "Large Language Models for Validating Network Protocol Parsers", "authors": ["Mingwei Zheng", "Danning Xie", "Xiangyu Zhang"], "abstract": "Network protocol parsers are essential for enabling correct and secure communication between devices. Bugs in these parsers can introduce critical vulnerabilities, including memory corruption, information leakage, and denial-of-service attacks. An intuitive way to assess parser correctness is to compare the implementation with its official protocol standard. However, this comparison is challenging because protocol standards are typically written in natural language, whereas implementations are in source code. Existing methods like model checking, fuzzing, and differential testing have been used to find parsing bugs, but they either require significant manual effort or ignore the protocol standards, limiting their ability to detect semantic violations. To enable more automated validation of parser implementations against protocol standards, we propose PARVAL, a multi-agent framework built on large language models (LLMs). PARVAL leverages the capabilities of LLMs to understand both natural language and code. It transforms both protocol standards and their implementations into a unified intermediate representation, referred to as format specifications, and performs a differential comparison to uncover inconsistencies. We evaluate PARVAL on the Bidirectional Forwarding Detection (BFD) protocol. Our experiments demonstrate that PARVAL successfully identifies inconsistencies between the implementation and its RFC standard, achieving a low false positive rate of 5.6%. PARVAL uncovers seven unique bugs, including five previously unknown issues.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.13515.pdf", "abstract_url": "https://arxiv.org/abs/2504.13515", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为PARVAL的多智能体框架，利用大型语言模型（LLMs）来验证网络协议解析器的正确性。通过将协议标准和其实现转换为统一的中间表示，并进行差异比较，PARVAL能够有效地发现不一致性。在双向转发检测（BFD）协议上的实验表明，PARVAL成功识别了实现与RFC标准之间的不一致，且假阳性率低至5.6%，并发现了七个独特的错误，其中包括五个先前未知的问题。", "motivation": "网络协议解析器中的错误可能导致严重的安全漏洞。现有的验证方法要么需要大量手动工作，要么忽略了协议标准，限制了检测语义违规的能力。为了解决这一问题，本文提出了PARVAL框架，旨在更自动化地验证解析器实现与协议标准之间的一致性。", "method": "PARVAL是一个基于大型语言模型（LLMs）的多智能体框架，能够理解自然语言和代码。它将协议标准和其实现转换为统一的中间表示（格式规范），并进行差异比较以发现不一致性。", "result": "在双向转发检测（BFD）协议上的实验中，PARVAL成功识别了实现与RFC标准之间的不一致，假阳性率为5.6%，并发现了七个独特的错误，其中包括五个先前未知的问题。", "conclusion": "PARVAL框架通过利用大型语言模型的能力，有效地验证了网络协议解析器的正确性，减少了手动工作，提高了检测语义违规的能力。这一方法为网络协议的安全性和可靠性提供了新的保障。"}}
{"id": "2504.13541", "title": "SwitchMT: An Adaptive Context Switching Methodology for Scalable Multi-Task Learning in Intelligent Autonomous Agents", "authors": ["Avaneesh Devkota", "Rachmad Vidya Wicaksana Putra", "Muhammad Shafique"], "abstract": "The ability to train intelligent autonomous agents (such as mobile robots) on multiple tasks is crucial for adapting to dynamic real-world environments. However, state-of-the-art reinforcement learning (RL) methods only excel in single-task settings, and still struggle to generalize across multiple tasks due to task interference. Moreover, real-world environments also demand the agents to have data stream processing capabilities. Toward this, a state-of-the-art work employs Spiking Neural Networks (SNNs) to improve multi-task learning by exploiting temporal information in data stream, while enabling lowpower/energy event-based operations. However, it relies on fixed context/task-switching intervals during its training, hence limiting the scalability and effectiveness of multi-task learning. To address these limitations, we propose SwitchMT, a novel adaptive task-switching methodology for RL-based multi-task learning in autonomous agents. Specifically, SwitchMT employs the following key ideas: (1) a Deep Spiking Q-Network with active dendrites and dueling structure, that utilizes task-specific context signals to create specialized sub-networks; and (2) an adaptive task-switching policy that leverages both rewards and internal dynamics of the network parameters. Experimental results demonstrate that SwitchMT achieves superior performance in multi-task learning compared to state-of-the-art methods. It achieves competitive scores in multiple Atari games (i.e., Pong: -8.8, Breakout: 5.6, and Enduro: 355.2) compared to the state-of-the-art, showing its better generalized learning capability. These results highlight the effectiveness of our SwitchMT methodology in addressing task interference while enabling multi-task learning automation through adaptive task switching, thereby paving the way for more efficient generalist agents with scalable multi-task learning capabilities.", "subjects": "Neural and Evolutionary Computing (cs.NE); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)", "comments": "7 pages, 7 figures, 3 tables", "pdf_url": "https://arxiv.org/pdf/2504.13541.pdf", "abstract_url": "https://arxiv.org/abs/2504.13541", "categories": ["Neural and Evolutionary Computing (cs.NE)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "SwitchMT提出了一种新颖的自适应任务切换方法，用于自主智能代理中的多任务学习，通过深度脉冲Q网络和自适应任务切换策略，有效解决了任务干扰问题，并在多个Atari游戏中展示了优越的性能。", "motivation": "解决智能自主代理在多任务学习中由于任务干扰导致的泛化能力不足问题，以及固定上下文/任务切换间隔限制多任务学习的可扩展性和有效性的问题。", "method": "采用深度脉冲Q网络（具有活跃树突和对决结构）和基于奖励及网络参数内部动态的自适应任务切换策略。", "result": "SwitchMT在多个Atari游戏中实现了与现有技术相比具有竞争力的分数（Pong: -8.8, Breakout: 5.6, Enduro: 355.2），展示了其更好的泛化学习能力。", "conclusion": "SwitchMT方法通过自适应任务切换有效解决了任务干扰问题，为具有可扩展多任务学习能力的高效通用代理铺平了道路。"}}
{"id": "2504.13587", "title": "RAG Without the Lag: Interactive Debugging for Retrieval-Augmented Generation Pipelines", "authors": ["Quentin Romero Lauro", "Shreya Shankar", "Sepanta Zeighami", "Aditya Parameswaran"], "abstract": "Retrieval-augmented generation (RAG) pipelines have become the de-facto approach for building AI assistants with access to external, domain-specific knowledge. Given a user query, RAG pipelines typically first retrieve (R) relevant information from external sources, before invoking a Large Language Model (LLM), augmented (A) with this information, to generate (G) responses. Modern RAG pipelines frequently chain multiple retrieval and generation components, in any order. However, developing effective RAG pipelines is challenging because retrieval and generation components are intertwined, making it hard to identify which component(s) cause errors in the eventual output. The parameters with the greatest impact on output quality often require hours of pre-processing after each change, creating prohibitively slow feedback cycles. To address these challenges, we present RAGGY, a developer tool that combines a Python library of composable RAG primitives with an interactive interface for real-time debugging. We contribute the design and implementation of RAGGY, insights into expert debugging patterns through a qualitative study with 12 engineers, and design implications for future RAG tools that better align with developers' natural workflows.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": "15 pages, 7 figures, 2 tables", "pdf_url": "https://arxiv.org/pdf/2504.13587.pdf", "abstract_url": "https://arxiv.org/abs/2504.13587", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了RAGGY，一个结合了Python库和交互式界面的开发者工具，旨在解决检索增强生成（RAG）管道开发中的调试难题。", "motivation": "解决RAG管道开发中因检索和生成组件交织而难以识别错误源，以及参数调整后反馈周期过长的问题。", "method": "开发了RAGGY工具，包括一个可组合的RAG原语Python库和一个用于实时调试的交互式界面。", "result": "通过12名工程师的定性研究，获得了专家调试模式的见解，并提出了未来RAG工具设计的启示。", "conclusion": "RAGGY工具通过提供实时调试能力，显著提高了RAG管道开发的效率和效果，为未来工具设计提供了方向。"}}
