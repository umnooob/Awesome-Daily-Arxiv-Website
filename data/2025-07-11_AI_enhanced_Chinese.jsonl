{"id": "2507.07280", "title": "The Impact of Background Speech on Interruption Detection in Collaborative Groups", "authors": ["Mariah Bradford", "Nikhil Krishnaswamy", "Nathaniel Blanchard"], "abstract": "Interruption plays a crucial role in collaborative learning, shaping group interactions and influencing knowledge construction. AI-driven support can assist teachers in monitoring these interactions. However, most previous work on interruption detection and interpretation has been conducted in single-conversation environments with relatively clean audio. AI agents deployed in classrooms for collaborative learning within small groups will need to contend with multiple concurrent conversations -- in this context, overlapping speech will be ubiquitous, and interruptions will need to be identified in other ways. In this work, we analyze interruption detection in single-conversation and multi-group dialogue settings. We then create a state-of-the-art method for interruption identification that is robust to overlapping speech, and thus could be deployed in classrooms. Further, our work highlights meaningful linguistic and prosodic information about how interruptions manifest in collaborative group interactions. Our investigation also paves the way for future works to account for the influence of overlapping speech from multiple groups when tracking group dialog.", "subjects": "Computation and Language (cs.CL)", "comments": "Long Paper AIED 2025", "pdf_url": "https://arxiv.org/pdf/2507.07280.pdf", "abstract_url": "https://arxiv.org/abs/2507.07280", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究了背景语音对协作小组中打断检测的影响，提出了一种在重叠语音环境下仍能有效识别打断的最先进方法。", "motivation": "解决在多人同时对话的教室环境中，如何有效检测和解释打断行为的问题，以支持AI驱动的协作学习监控。", "method": "分析了单对话和多组对话设置中的打断检测，并开发了一种对重叠语音鲁棒的打断识别方法。", "result": "提出了一种在重叠语音环境下有效的打断识别方法，并揭示了协作小组互动中打断行为的语言和韵律特征。", "conclusion": "本研究为在多人对话环境中跟踪小组对话提供了新的方法，并为未来研究考虑多组重叠语音的影响奠定了基础。"}}
{"id": "2507.07115", "title": "Autonomous Control Leveraging LLMs: An Agentic Framework for Next-Generation Industrial Automation", "authors": ["Javal Vyas", "Mehmet Mercangoz"], "abstract": "The increasing complexity of modern chemical processes, coupled with workforce shortages and intricate fault scenarios, demands novel automation paradigms that blend symbolic reasoning with adaptive control. In this work, we introduce a unified agentic framework that leverages large language models (LLMs) for both discrete fault-recovery planning and continuous process control within a single architecture. We adopt Finite State Machines (FSMs) as interpretable operating envelopes: an LLM-driven planning agent proposes recovery sequences through the FSM, a Simulation Agent executes and checks each transition, and a Validator-Reprompting loop iteratively refines invalid plans. In Case Study 1, across 180 randomly generated FSMs of varying sizes (4-25 states, 4-300 transitions), GPT-4o and GPT-4o-mini achieve 100% valid-path success within five reprompts-outperforming open-source LLMs in both accuracy and latency. In Case Study 2, the same framework modulates dual-heater inputs on a laboratory TCLab platform (and its digital twin) to maintain a target average temperature under persistent asymmetric disturbances. Compared to classical PID control, our LLM-based controller attains similar performance, while ablation of the prompting loop reveals its critical role in handling nonlinear dynamics. We analyze key failure modes-such as instruction following lapses and coarse ODE approximations. Our results demonstrate that, with structured feedback and modular agents, LLMs can unify high-level symbolic planningand low-level continuous control, paving the way towards resilient, language-driven automation in chemical engineering.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA); Systems and Control (eess.SY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.07115.pdf", "abstract_url": "https://arxiv.org/abs/2507.07115", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)", "Systems and Control (eess.SY)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了一种利用大型语言模型（LLMs）的统一代理框架，用于化学工程中的离散故障恢复规划和连续过程控制，通过案例研究展示了其在提高自动化弹性和语言驱动自动化方面的潜力。", "motivation": "现代化学过程的复杂性增加，加上劳动力短缺和复杂的故障场景，需要新的自动化范式，将符号推理与自适应控制相结合。", "method": "采用有限状态机（FSMs）作为可解释的操作框架，通过LLM驱动的规划代理提出恢复序列，模拟代理执行和检查每个转换，以及验证-重新提示循环迭代优化无效计划。", "result": "在案例研究1中，GPT-4o和GPT-4o-mini在180个随机生成的FSMs上实现了100%的有效路径成功率；在案例研究2中，LLM-based控制器在维持目标平均温度方面与传统PID控制表现相当。", "conclusion": "通过结构化反馈和模块化代理，LLMs可以统一高级符号规划和低级连续控制，为化学工程中的弹性、语言驱动自动化铺平道路。"}}
{"id": "2507.07307", "title": "Multi-Agent Retrieval-Augmented Framework for Evidence-Based Counterspeech Against Health Misinformation", "authors": ["Anirban Saha Anik", "Xiaoying Song", "Elliott Wang", "Bryan Wang", "Bengisu Yarimbas", "Lingzi Hong"], "abstract": "Large language models (LLMs) incorporated with Retrieval-Augmented Generation (RAG) have demonstrated powerful capabilities in generating counterspeech against misinformation. However, current studies rely on limited evidence and offer less control over final outputs. To address these challenges, we propose a Multi-agent Retrieval-Augmented Framework to generate counterspeech against health misinformation, incorporating multiple LLMs to optimize knowledge retrieval, evidence enhancement, and response refinement. Our approach integrates both static and dynamic evidence, ensuring that the generated counterspeech is relevant, well-grounded, and up-to-date. Our method outperforms baseline approaches in politeness, relevance, informativeness, and factual accuracy, demonstrating its effectiveness in generating high-quality counterspeech. To further validate our approach, we conduct ablation studies to verify the necessity of each component in our framework. Furthermore, human evaluations reveal that refinement significantly enhances counterspeech quality and obtains human preference.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.07307.pdf", "abstract_url": "https://arxiv.org/abs/2507.07307", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文提出了一种多代理检索增强框架，用于生成针对健康错误信息的基于证据的反驳话语。该框架通过整合多个大型语言模型（LLMs）来优化知识检索、证据增强和响应细化，生成的反对话语在礼貌性、相关性、信息量和事实准确性方面优于基线方法。", "motivation": "当前利用大型语言模型（LLMs）和检索增强生成（RAG）生成反驳错误信息的研究依赖于有限的证据，且对最终输出的控制较少。本文旨在解决这些问题，提高反驳话语的质量和效果。", "method": "采用多代理检索增强框架，结合静态和动态证据，利用多个LLMs进行知识检索、证据增强和响应细化，以确保生成的反驳话语相关、有根据且最新。", "result": "该方法在礼貌性、相关性、信息量和事实准确性方面优于基线方法。消融研究验证了框架中每个组件的必要性，人类评估显示细化显著提高了反驳话语的质量并获得了人类的偏好。", "conclusion": "提出的多代理检索增强框架有效提高了生成反驳健康错误信息的质量，通过整合多种证据和优化生成过程，为对抗健康错误信息提供了有力的工具。"}}
{"id": "2507.07302", "title": "Application of LLMs to Multi-Robot Path Planning and Task Allocation", "authors": ["Ashish Kumar"], "abstract": "Efficient exploration is a well known problem in deep reinforcement learning and this problem is exacerbated in multi-agent reinforcement learning due the intrinsic complexities of such algorithms. There are several approaches to efficiently explore an environment to learn to solve tasks by multi-agent operating in that environment, of which, the idea of expert exploration is investigated in this work. More specifically, this work investigates the application of large-language models as expert planners for efficient exploration in planning based tasks for multiple agents.", "subjects": "Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.07302.pdf", "abstract_url": "https://arxiv.org/abs/2507.07302", "categories": ["Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了在多智能体强化学习中，利用大型语言模型作为专家规划器，以提高基于规划任务中的探索效率。", "motivation": "解决多智能体强化学习中的高效探索问题，特别是在基于规划的任务中。", "method": "研究大型语言模型作为专家规划器在多智能体环境中的应用。", "result": "研究表明，大型语言模型可以作为有效的专家规划器，提高多智能体在复杂环境中的探索效率。", "conclusion": "大型语言模型在多智能体路径规划和任务分配中显示出潜力，能够有效提升探索效率和学习效果。"}}
{"id": "2507.07441", "title": "SAND: Boosting LLM Agents with Self-Taught Action Deliberation", "authors": ["Yu Xia", "Yiran Jenny Shen", "Junda Wu", "Tong Yu", "Sungchul Kim", "Ryan A. Rossi", "Lina Yao", "Julian McAuley"], "abstract": "Large Language Model (LLM) agents are commonly tuned with supervised finetuning on ReAct-style expert trajectories or preference optimization over pairwise rollouts. Most of these methods focus on imitating specific expert behaviors or promoting chosen reasoning thoughts and actions over rejected ones. However, without reasoning and comparing over alternatives actions, LLM agents finetuned with these methods may over-commit towards seemingly plausible but suboptimal actions due to limited action space exploration. To address this, in this paper we propose Self-taught ActioN Deliberation (SAND) framework, enabling LLM agents to explicitly deliberate over candidate actions before committing to one. To tackle the challenges of when and what to deliberate given large action space and step-level action evaluation, we incorporate self-consistency action sampling and execution-guided action critique to help synthesize step-wise action deliberation thoughts using the base model of the LLM agent. In an iterative manner, the deliberation trajectories are then used to finetune the LLM agent itself. Evaluating on two representative interactive agent tasks, SAND achieves an average 20% improvement over initial supervised finetuning and also outperforms state-of-the-art agent tuning approaches.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.07441.pdf", "abstract_url": "https://arxiv.org/abs/2507.07441", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为SAND的框架，旨在通过自我教授的动作审议来提升大型语言模型（LLM）代理的性能。该框架通过审议候选动作来避免看似合理但次优的动作选择，从而解决了现有方法在动作空间探索上的限制。", "motivation": "现有的LLM代理调优方法主要侧重于模仿特定专家行为或促进选择的推理思想和动作，而忽视了在动作空间中进行充分的探索和比较，导致代理可能过度倾向于看似合理但实际上次优的动作。", "method": "SAND框架通过自我一致性动作采样和执行引导的动作批评，利用LLM代理的基础模型合成步骤级的动作审议思想，并在迭代过程中使用这些审议轨迹来微调LLM代理本身。", "result": "在两个代表性的交互式代理任务上的评估显示，SAND比初始的监督微调平均提高了20%的性能，并且优于最先进的代理调优方法。", "conclusion": "SAND框架通过引入动作审议机制，显著提升了LLM代理在交互任务中的性能，为代理调优提供了一种新的有效方法。"}}
{"id": "2507.07257", "title": "Open Source Planning & Control System with Language Agents for Autonomous Scientific Discovery", "authors": ["Licong Xu", "Milind Sarkar", "Anto I. Lonappan", "Íñigo Zubeldia", "Pablo Villanueva-Domingo", "Santiago Casas", "Christian Fidler", "Chetana Amancharla", "Ujjwal Tiwari", "Adrian Bayer", "Chadi Ait Ekiou", "Miles Cranmer", "Adrian Dimitrov", "James Fergusson", "Kahaan Gandhi", "Sven Krippendorf", "Andrew Laverick", "Julien Lesgourgues", "Antony Lewis", "Thomas Meier", "Blake Sherwin", "Kristen Surrao", "Francisco Villaescusa-Navarro", "Chi Wang", "Xueqing Xu", "Boris Bolliet"], "abstract": "We present a multi-agent system for automation of scientific research tasks, cmbagent. The system is formed by about 30 Large Language Model (LLM) agents and implements a Planning & Control strategy to orchestrate the agentic workflow, with no human-in-the-loop at any point. Each agent specializes in a different task (performing retrieval on scientific papers and codebases, writing code, interpreting results, critiquing the output of other agents) and the system is able to execute code locally. We successfully apply cmbagent to carry out a PhD level cosmology task (the measurement of cosmological parameters using supernova data) and evaluate its performance on two benchmark sets, finding superior performance over state-of-the-art LLMs. The source code is available on GitHub, demonstration videos are also available, and the system is deployed on HuggingFace and will be available on the cloud.", "subjects": "Artificial Intelligence (cs.AI); Instrumentation and Methods for Astrophysics (astro-ph.IM); Computation and Language (cs.CL); Multiagent Systems (cs.MA)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2507.07257.pdf", "abstract_url": "https://arxiv.org/abs/2507.07257", "categories": ["Artificial Intelligence (cs.AI)", "Instrumentation and Methods for Astrophysics (astro-ph.IM)", "Computation and Language (cs.CL)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "介绍了一个名为cmbagent的多智能体系统，用于自动化科学研究任务，该系统由约30个大型语言模型（LLM）智能体组成，实现了无需人工干预的规划与控制策略。", "motivation": "解决科学研究任务自动化的问题，减少人工干预，提高研究效率。", "method": "采用多智能体系统，每个智能体专注于不同的任务（如检索科学论文和代码库、编写代码、解释结果、批评其他智能体的输出），并能够在本地执行代码。", "result": "在博士级别的宇宙学任务（使用超新星数据测量宇宙学参数）中成功应用，并在两个基准测试中表现出优于现有LLMs的性能。", "conclusion": "cmbagent系统展示了在科学研究自动化方面的潜力，其源代码和演示视频已公开，系统也已部署在HuggingFace和云端。"}}
{"id": "2507.07306", "title": "ViDove: A Translation Agent System with Multimodal Context and Memory-Augmented Reasoning", "authors": ["Yichen Lu", "Wei Dai", "Jiaen Liu", "Ching Wing Kwok", "Zongheng Wu", "Xudong Xiao", "Ao Sun", "Sheng Fu", "Jianyuan Zhan", "Yian Wang", "Takatomo Saito", "Sicheng Lai"], "abstract": "LLM-based translation agents have achieved highly human-like translation results and are capable of handling longer and more complex contexts with greater efficiency. However, they are typically limited to text-only inputs. In this paper, we introduce ViDove, a translation agent system designed for multimodal input. Inspired by the workflow of human translators, ViDove leverages visual and contextual background information to enhance the translation process. Additionally, we integrate a multimodal memory system and long-short term memory modules enriched with domain-specific knowledge, enabling the agent to perform more accurately and adaptively in real-world scenarios. As a result, ViDove achieves significantly higher translation quality in both subtitle generation and general translation tasks, with a 28% improvement in BLEU scores and a 15% improvement in SubER compared to previous state-of-the-art baselines. Moreover, we introduce DoveBench, a new benchmark for long-form automatic video subtitling and translation, featuring 17 hours of high-quality, human-annotated data. Our code is available here:", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.07306.pdf", "abstract_url": "https://arxiv.org/abs/2507.07306", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Audio and Speech Processing (eess.AS)"], "matching_keywords": ["agent"], "AI": {"tldr": "ViDove是一个基于LLM的多模态翻译代理系统，通过结合视觉和上下文背景信息提升翻译质量，并在字幕生成和一般翻译任务中表现优异。", "motivation": "解决现有LLM翻译代理仅限于文本输入的问题，提升翻译的准确性和适应性。", "method": "利用视觉和上下文背景信息，集成多模态记忆系统和长短时记忆模块，增强领域特定知识。", "result": "在BLEU分数上提高了28%，在SubER上提高了15%，显著优于现有技术。", "conclusion": "ViDove通过多模态输入和记忆增强推理，显著提升了翻译质量，并引入了新的长视频字幕翻译基准DoveBench。"}}
{"id": "2507.07426", "title": "DrugMCTS: a drug repurposing framework combining multi-agent, RAG and Monte Carlo Tree Search", "authors": ["Zerui Yang", "Yuwei Wan", "Yinqiao Li", "Yudai Matsuda", "Tong Xie", "Linqi Song"], "abstract": "Recent advances in large language models have demonstrated considerable potential in scientific domains such as drug discovery. However, their effectiveness remains constrained when reasoning extends beyond the knowledge acquired during pretraining. Conventional approaches, such as fine-tuning or retrieval-augmented generation, face limitations in either imposing high computational overhead or failing to fully exploit structured scientific data. To overcome these challenges, we propose DrugMCTS, a novel framework that synergistically integrates RAG, multi-agent collaboration, and Monte Carlo Tree Search for drug repurposing. The framework employs five specialized agents tasked with retrieving and analyzing molecular and protein information, thereby enabling structured and iterative reasoning. Without requiring domain-specific fine-tuning, DrugMCTS empowers Qwen2.5-7B-Instruct to outperform Deepseek-R1 by over 20\\%. Extensive experiments on the DrugBank and KIBA datasets demonstrate that DrugMCTS achieves substantially higher recall and robustness compared to both general-purpose LLMs and deep learning baselines. Our results highlight the importance of structured reasoning, agent-based collaboration, and feedback-driven search mechanisms in advancing LLM applications for drug discovery.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.07426.pdf", "abstract_url": "https://arxiv.org/abs/2507.07426", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "DrugMCTS是一个结合多智能体、RAG和蒙特卡洛树搜索的药物再利用框架，旨在克服现有方法在计算开销和结构化科学数据利用上的限制。", "motivation": "解决大型语言模型在药物发现领域推理能力受限于预训练知识，以及传统方法如微调或检索增强生成在计算开销和数据利用上的不足。", "method": "提出DrugMCTS框架，整合RAG、多智能体协作和蒙特卡洛树搜索，使用五个专门智能体进行分子和蛋白质信息的检索与分析，实现结构化迭代推理。", "result": "无需领域特定微调，DrugMCTS使Qwen2.5-7B-Instruct性能超过Deepseek-R1 20%以上，在DrugBank和KIBA数据集上展现出更高的召回率和鲁棒性。", "conclusion": "结构化推理、基于智能体的协作和反馈驱动的搜索机制对推进LLM在药物发现中的应用至关重要。"}}
{"id": "2507.07445", "title": "StarDojo: Benchmarking Open-Ended Behaviors of Agentic Multimodal LLMs in Production-Living Simulations with Stardew Valley", "authors": ["Weihao Tan", "Changjiu Jiang", "Yu Duan", "Mingcong Lei", "Jiageng Li", "Yitian Hong", "Xinrun Wang", "Bo An"], "abstract": "Autonomous agents navigating human society must master both production activities and social interactions, yet existing benchmarks rarely evaluate these skills simultaneously. To bridge this gap, we introduce StarDojo, a novel benchmark based on Stardew Valley, designed to assess AI agents in open-ended production-living simulations. In StarDojo, agents are tasked to perform essential livelihood activities such as farming and crafting, while simultaneously engaging in social interactions to establish relationships within a vibrant community. StarDojo features 1,000 meticulously curated tasks across five key domains: farming, crafting, exploration, combat, and social interactions. Additionally, we provide a compact subset of 100 representative tasks for efficient model evaluation. The benchmark offers a unified, user-friendly interface that eliminates the need for keyboard and mouse control, supports all major operating systems, and enables the parallel execution of multiple environment instances, making it particularly well-suited for evaluating the most capable foundation agents, powered by multimodal large language models (MLLMs). Extensive evaluations of state-of-the-art MLLMs agents demonstrate substantial limitations, with the best-performing model, GPT-4.1, achieving only a 12.7% success rate, primarily due to challenges in visual understanding, multimodal reasoning and low-level manipulation. As a user-friendly environment and benchmark, StarDojo aims to facilitate further research towards robust, open-ended agents in complex production-living environments.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2507.07445.pdf", "abstract_url": "https://arxiv.org/abs/2507.07445", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "StarDojo是一个基于Stardew Valley的新型基准测试，旨在评估AI代理在开放式生产生活模拟中的表现，包括农业、手工艺、探索、战斗和社交互动等多个领域。", "motivation": "现有的基准测试很少同时评估AI代理在生产活动和社会互动方面的技能，StarDojo旨在填补这一空白。", "method": "StarDojo提供了1,000个精心策划的任务，覆盖五个关键领域，并提供了一个包含100个代表性任务的子集，用于高效模型评估。它提供了一个统一的、用户友好的界面，支持所有主要操作系统，并允许多个环境实例的并行执行。", "result": "对最先进的多模态大语言模型（MLLMs）代理的广泛评估显示出显著的局限性，表现最佳的模型GPT-4.1的成功率仅为12.7%，主要由于视觉理解、多模态推理和低级操作方面的挑战。", "conclusion": "作为一个用户友好的环境和基准测试，StarDojo旨在促进在复杂生产生活环境中开发更强大、开放式的代理的进一步研究。"}}
{"id": "2507.07544", "title": "Position: We Need An Algorithmic Understanding of Generative AI", "authors": ["Oliver Eberle", "Thomas McGee", "Hamza Giaffar", "Taylor Webb", "Ida Momennejad"], "abstract": "What algorithms do LLMs actually learn and use to solve problems? Studies addressing this question are sparse, as research priorities are focused on improving performance through scale, leaving a theoretical and empirical gap in understanding emergent algorithms. This position paper proposes AlgEval: a framework for systematic research into the algorithms that LLMs learn and use. AlgEval aims to uncover algorithmic primitives, reflected in latent representations, attention, and inference-time compute, and their algorithmic composition to solve task-specific problems. We highlight potential methodological paths and a case study toward this goal, focusing on emergent search algorithms. Our case study illustrates both the formation of top-down hypotheses about candidate algorithms, and bottom-up tests of these hypotheses via circuit-level analysis of attention patterns and hidden states. The rigorous, systematic evaluation of how LLMs actually solve tasks provides an alternative to resource-intensive scaling, reorienting the field toward a principled understanding of underlying computations. Such algorithmic explanations offer a pathway to human-understandable interpretability, enabling comprehension of the model's internal reasoning performance measures. This can in turn lead to more sample-efficient methods for training and improving performance, as well as novel architectures for end-to-end and multi-agent systems.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "Accepted at ICML 2025 as a Spotlight Position Paper", "pdf_url": "https://arxiv.org/pdf/2507.07544.pdf", "abstract_url": "https://arxiv.org/abs/2507.07544", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出AlgEval框架，旨在系统研究大型语言模型(LLMs)学习并用于解决问题的算法。通过揭示算法原语及其组合方式，该框架旨在填补对LLMs内部算法的理论理解空白。", "motivation": "当前研究主要关注通过规模提升性能，缺乏对LLMs学习算法的深入理解，导致理论和实证上的空白。", "method": "提出AlgEval框架，结合自上而下的假设形成和自下而上的电路级分析，研究LLMs中的算法原语及其组合。", "result": "案例研究展示了如何通过分析注意力模式和隐藏状态来验证候选算法，为理解LLMs的内部计算提供了系统方法。", "conclusion": "算法解释为人类可理解的解释性提供了途径，有助于开发更高效的训练方法和新型架构，推动领域向基本原理理解转变。"}}
{"id": "2507.07505", "title": "Hallucination Stations: On Some Basic Limitations of Transformer-Based Language Models", "authors": ["Varin Sikka", "Vishal Sikka"], "abstract": "With widespread adoption of transformer-based language models in AI, there is significant interest in the limits of LLMs capabilities, specifically so-called hallucinations, occurrences in which LLMs provide spurious, factually incorrect or nonsensical information when prompted on certain subjects. Furthermore, there is growing interest in agentic uses of LLMs - that is, using LLMs to create agents that act autonomously or semi-autonomously to carry out various tasks, including tasks with applications in the real world. This makes it important to understand the types of tasks LLMs can and cannot perform. We explore this topic from the perspective of the computational complexity of LLM inference. We show that LLMs are incapable of carrying out computational and agentic tasks beyond a certain complexity, and further that LLMs are incapable of verifying the accuracy of tasks beyond a certain complexity. We present examples of both, then discuss some consequences of this work.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "6 pages; to be submitted to AAAI-26 after reviews", "pdf_url": "https://arxiv.org/pdf/2507.07505.pdf", "abstract_url": "https://arxiv.org/abs/2507.07505", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文探讨了基于Transformer的语言模型在计算复杂性和代理任务上的局限性，特别是所谓的‘幻觉’现象，即模型在特定主题上提供虚假、事实错误或无意义的信息。", "motivation": "随着基于Transformer的语言模型在AI中的广泛应用，人们对其能力的限制，尤其是‘幻觉’现象，以及模型在自主或半自主执行任务中的应用潜力产生了浓厚兴趣。", "method": "从LLM推理的计算复杂性角度出发，研究了LLM在执行计算和代理任务以及验证任务准确性方面的能力限制。", "result": "研究表明，LLM无法执行超出一定复杂度的计算和代理任务，也无法验证超出一定复杂度任务的准确性。", "conclusion": "这项工作揭示了LLM在复杂任务执行和验证方面的基本限制，对LLM在现实世界应用中的潜力提出了重要考量。"}}
{"id": "2507.07509", "title": "Toward Real-World Chinese Psychological Support Dialogues: CPsDD Dataset and a Co-Evolving Multi-Agent System", "authors": ["Yuanchen Shi", "Longyin Zhang", "Fang Kong"], "abstract": "The growing need for psychological support due to increasing pressures has exposed the scarcity of relevant datasets, particularly in non-English languages. To address this, we propose a framework that leverages limited real-world data and expert knowledge to fine-tune two large language models: Dialog Generator and Dialog Modifier. The Generator creates large-scale psychological counseling dialogues based on predefined paths, which guide system response strategies and user interactions, forming the basis for effective support. The Modifier refines these dialogues to align with real-world data quality. Through both automated and manual review, we construct the Chinese Psychological support Dialogue Dataset (CPsDD), containing 68K dialogues across 13 groups, 16 psychological problems, 13 causes, and 12 support focuses. Additionally, we introduce the Comprehensive Agent Dialogue Support System (CADSS), where a Profiler analyzes user characteristics, a Summarizer condenses dialogue history, a Planner selects strategies, and a Supporter generates empathetic responses. The experimental results of the Strategy Prediction and Emotional Support Conversation (ESC) tasks demonstrate that CADSS achieves state-of-the-art performance on both CPsDD and ESConv datasets.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "10pages,8 figures", "pdf_url": "https://arxiv.org/pdf/2507.07509.pdf", "abstract_url": "https://arxiv.org/abs/2507.07509", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一个框架，利用有限的真实世界数据和专家知识来微调两个大型语言模型：对话生成器和对话修改器，以构建中文心理支持对话数据集（CPsDD），并介绍了综合代理对话支持系统（CADSS）。", "motivation": "解决由于压力增加而导致的心理支持需求增长，特别是在非英语语言中相关数据集的稀缺问题。", "method": "通过对话生成器基于预定义路径创建大规模心理咨询对话，对话修改器将这些对话与真实世界数据质量对齐，构建CPsDD数据集，并开发CADSS系统。", "result": "CPsDD包含68K对话，覆盖13个群体、16个心理问题、13个原因和12个支持重点；CADSS在策略预测和情感支持对话（ESC）任务上达到了最先进的性能。", "conclusion": "提出的框架和系统为解决心理支持对话数据稀缺问题提供了有效方法，并在相关任务上展示了优异的性能。"}}
{"id": "2507.07543", "title": "The Cross-Lingual Cost: Retrieval Biases in RAG over Arabic-English Corpora", "authors": ["Chen Amiraz", "Yaroslav Fyodorov", "Elad Haramaty", "Zohar Karnin", "Liane Lewin-Eytan"], "abstract": "Cross-lingual retrieval-augmented generation (RAG) is a critical capability for retrieving and generating answers across languages. Prior work in this context has mostly focused on generation and relied on benchmarks derived from open-domain sources, most notably Wikipedia. In such settings, retrieval challenges often remain hidden due to language imbalances, overlap with pretraining data, and memorized content. To address this gap, we study Arabic-English RAG in a domain-specific setting using benchmarks derived from real-world corporate datasets. Our benchmarks include all combinations of languages for the user query and the supporting document, drawn independently and uniformly at random. This enables a systematic study of multilingual retrieval behavior.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.07543.pdf", "abstract_url": "https://arxiv.org/abs/2507.07543", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文研究了阿拉伯语-英语跨语言检索增强生成（RAG）在特定领域设置中的检索偏差问题，使用了来自真实世界公司数据集的基准。", "motivation": "解决跨语言检索增强生成（RAG）中由于语言不平衡、与预训练数据重叠以及记忆内容导致的检索挑战未被充分研究的问题。", "method": "在特定领域设置中使用阿拉伯语-英语RAG，并采用来自真实世界公司数据集的基准，包括用户查询和支持文档的所有语言组合。", "result": "研究发现，跨语言检索行为存在偏差，这为系统研究多语言检索行为提供了基础。", "conclusion": "本研究揭示了跨语言RAG中的检索偏差问题，为未来在多语言环境中改进检索技术提供了重要见解。"}}
{"id": "2507.07634", "title": "FrugalRAG: Learning to retrieve and reason for multi-hop QA", "authors": ["Abhinav Java", "Srivathsan Koundinyan", "Nagarajan Natarajan", "Amit Sharma"], "abstract": "We consider the problem of answering complex questions, given access to a large unstructured document corpus. The de facto approach to solving the problem is to leverage language models that (iteratively) retrieve and reason through the retrieved documents, until the model has sufficient information to generate an answer. Attempts at improving this approach focus on retrieval-augmented generation (RAG) metrics such as accuracy and recall and can be categorized into two types: (a) fine-tuning on large question answering (QA) datasets augmented with chain-of-thought traces, and (b) leveraging RL-based fine-tuning techniques that rely on question-document relevance signals. However, efficiency in the number of retrieval searches is an equally important metric, which has received less attention. In this work, we show that: (1) Large-scale fine-tuning is not needed to improve RAG metrics, contrary to popular claims in recent literature. Specifically, a standard ReAct pipeline with improved prompts can outperform state-of-the-art methods on benchmarks such as HotPotQA. (2) Supervised and RL-based fine-tuning can help RAG from the perspective of frugality, i.e., the latency due to number of searches at inference time. For example, we show that we can achieve competitive RAG metrics at nearly half the cost (in terms of number of searches) on popular RAG benchmarks, using the same base model, and at a small training cost (1000 examples).", "subjects": "Computation and Language (cs.CL)", "comments": "Accepted at ICML Workshop: Efficient Systems for Foundation Models", "pdf_url": "https://arxiv.org/pdf/2507.07634.pdf", "abstract_url": "https://arxiv.org/abs/2507.07634", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了FrugalRAG，一种旨在通过改进提示和微调技术来提高多跳问答系统中检索和推理效率的方法。研究表明，大规模微调并非提升检索增强生成（RAG）性能的必要条件，且通过监督和基于强化学习的微调可以在减少检索次数的同时保持竞争力。", "motivation": "解决在大型非结构化文档库中回答复杂问题时，检索增强生成（RAG）方法的效率问题，特别是在减少检索次数（即节俭性）方面的不足。", "method": "采用标准ReAct流程结合改进的提示，以及监督和基于强化学习的微调技术，以减少推理时的检索次数。", "result": "在HotPotQA等基准测试中，该方法在仅使用1000个示例进行训练的情况下，以近乎半数的检索次数实现了与现有技术相竞争的RAG性能。", "conclusion": "研究表明，通过改进提示和有限的微调，可以在不牺牲性能的前提下显著提高RAG方法的效率，这对于实际应用中的资源节约具有重要意义。"}}
{"id": "2507.07695", "title": "KeyKnowledgeRAG (K^2RAG): An Enhanced RAG method for improved LLM question-answering capabilities", "authors": ["Hruday Markondapatnaikuni", "Basem Suleiman", "Abdelkarim Erradi", "Shijing Chen"], "abstract": "Fine-tuning is an immensely resource-intensive process when retraining Large Language Models (LLMs) to incorporate a larger body of knowledge. Although many fine-tuning techniques have been developed to reduce the time and computational cost involved, the challenge persists as LLMs continue to grow in size and complexity. To address this, a new approach to knowledge expansion in LLMs is needed. Retrieval-Augmented Generation (RAG) offers one such alternative by storing external knowledge in a database and retrieving relevant chunks to support question answering. However, naive implementations of RAG face significant limitations in scalability and answer accuracy. This paper introduces KeyKnowledgeRAG (K2RAG), a novel framework designed to overcome these limitations. Inspired by the divide-and-conquer paradigm, K2RAG integrates dense and sparse vector search, knowledge graphs, and text summarization to improve retrieval quality and system efficiency. The framework also includes a preprocessing step that summarizes the training data, significantly reducing the training time. K2RAG was evaluated using the MultiHopRAG dataset, where the proposed pipeline was trained on the document corpus and tested on a separate evaluation set. Results demonstrated notable improvements over common naive RAG implementations. K2RAG achieved the highest mean answer similarity score of 0.57, and reached the highest third quartile (Q3) similarity of 0.82, indicating better alignment with ground-truth answers. In addition to improved accuracy, the framework proved highly efficient. The summarization step reduced the average training time of individual components by 93%, and execution speed was up to 40% faster than traditional knowledge graph-based RAG systems. K2RAG also demonstrated superior scalability, requiring three times less VRAM than several naive RAG implementations tested in this study.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "21 pages, 14 figures", "pdf_url": "https://arxiv.org/pdf/2507.07695.pdf", "abstract_url": "https://arxiv.org/abs/2507.07695", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "K^2RAG是一种改进的RAG方法，通过结合密集和稀疏向量搜索、知识图谱和文本摘要技术，提高了LLM问答的准确性和效率。", "motivation": "解决大型语言模型(LLMs)在知识扩展时面临的资源密集型微调问题，以及传统RAG方法在可扩展性和答案准确性上的限制。", "method": "提出KeyKnowledgeRAG (K2RAG)框架，集成密集和稀疏向量搜索、知识图谱和文本摘要技术，并包括一个预处理步骤来总结训练数据。", "result": "K2RAG在MultiHopRAG数据集上测试，显示出比传统RAG实现更高的答案相似度得分（平均0.57，Q3 0.82），训练时间减少93%，执行速度提高40%，且VRAM需求减少三倍。", "conclusion": "K2RAG框架显著提高了问答系统的准确性和效率，同时降低了资源消耗，为LLM的知识扩展提供了一种有效的替代方案。"}}
{"id": "2507.07902", "title": "MIRA: A Novel Framework for Fusing Modalities in Medical RAG", "authors": ["Jinhong Wang", "Tajamul Ashraf", "Zongyan Han", "Jorma Laaksonen", "Rao Mohammad Anwer"], "abstract": "Multimodal Large Language Models (MLLMs) have significantly advanced AI-assisted medical diagnosis, but they often generate factually inconsistent responses that deviate from established medical knowledge. Retrieval-Augmented Generation (RAG) enhances factual accuracy by integrating external sources, but it presents two key challenges. First, insufficient retrieval can miss critical information, whereas excessive retrieval can introduce irrelevant or misleading content, disrupting model output. Second, even when the model initially provides correct answers, over-reliance on retrieved data can lead to factual errors. To address these issues, we introduce the Multimodal Intelligent Retrieval and Augmentation (MIRA) framework, designed to optimize factual accuracy in MLLM. MIRA consists of two key components: (1) a calibrated Rethinking and Rearrangement module that dynamically adjusts the number of retrieved contexts to manage factual risk, and (2) A medical RAG framework integrating image embeddings and a medical knowledge base with a query-rewrite module for efficient multimodal reasoning. This enables the model to effectively integrate both its inherent knowledge and external references. Our evaluation of publicly available medical VQA and report generation benchmarks demonstrates that MIRA substantially enhances factual accuracy and overall performance, achieving new state-of-the-art results. Code is released at", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "ACM Multimedia 2025", "pdf_url": "https://arxiv.org/pdf/2507.07902.pdf", "abstract_url": "https://arxiv.org/abs/2507.07902", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了MIRA框架，旨在通过优化多模态大型语言模型（MLLMs）中的检索增强生成（RAG）技术，提高医疗诊断中的事实准确性。", "motivation": "解决多模态大型语言模型在医疗诊断中生成的事实不一致响应，以及检索增强生成技术中检索不足或过度检索带来的问题。", "method": "提出MIRA框架，包含两个关键组件：1) 一个校准的重新思考和重排模块，动态调整检索上下文的数量以管理事实风险；2) 一个集成了图像嵌入和医疗知识库的医疗RAG框架，带有查询重写模块，以实现高效的多模态推理。", "result": "在公开可用的医疗VQA和报告生成基准测试中，MIRA显著提高了事实准确性和整体性能，达到了新的最先进水平。", "conclusion": "MIRA框架通过优化检索和增强生成过程，有效整合了模型的固有知识和外部参考，为医疗诊断中的多模态大型语言模型提供了更高的事实准确性。"}}
{"id": "2507.07984", "title": "OST-Bench: Evaluating the Capabilities of MLLMs in Online Spatio-temporal Scene Understanding", "authors": ["JingLi Lin", "Chenming Zhu", "Runsen Xu", "Xiaohan Mao", "Xihui Liu", "Tai Wang", "Jiangmiao Pang"], "abstract": "Recent advances in multimodal large language models (MLLMs) have shown remarkable capabilities in integrating vision and language for complex reasoning. While most existing benchmarks evaluate models under offline settings with a fixed set of pre-recorded inputs, we introduce OST-Bench, a benchmark designed to evaluate Online Spatio-Temporal understanding from the perspective of an agent actively exploring a scene. The Online aspect emphasizes the need to process and reason over incrementally acquired observations, while the Spatio-Temporal component requires integrating current visual inputs with historical memory to support dynamic spatial reasoning. OST-Bench better reflects the challenges of real-world embodied perception. Built on an efficient data collection pipeline, OST-Bench consists of 1.4k scenes and 10k question-answer pairs collected from ScanNet, Matterport3D, and ARKitScenes. We evaluate several leading MLLMs on OST-Bench and observe that they fall short on tasks requiring complex spatio-temporal reasoning. Under the online setting, their accuracy declines as the exploration horizon extends and the memory grows. Through further experimental analysis, we identify common error patterns across models and find that both complex clue-based spatial reasoning demands and long-term memory retrieval requirements significantly drop model performance along two separate axes, highlighting the core challenges that must be addressed to improve online embodied reasoning. To foster further research and development in the field, our codes, dataset, and benchmark are available. Our project page is:", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2507.07984.pdf", "abstract_url": "https://arxiv.org/abs/2507.07984", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "OST-Bench是一个新的基准测试，旨在评估多模态大型语言模型（MLLMs）在在线时空场景理解中的能力，特别是在主动探索场景时的表现。", "motivation": "现有的基准测试大多在离线设置下评估模型，无法充分反映现实世界中的具身感知挑战，特别是在需要处理增量获取的观察和整合历史记忆以支持动态空间推理的场景。", "method": "通过高效的数据收集流程，基于ScanNet、Matterport3D和ARKitScenes构建了包含1.4k个场景和10k个问答对的OST-Bench基准测试。", "result": "评估发现，领先的MLLMs在需要复杂时空推理的任务上表现不佳，特别是在在线设置下，随着探索范围的扩展和记忆的增长，其准确性下降。", "conclusion": "研究揭示了模型在复杂线索基础的空间推理需求和长期记忆检索需求方面的核心挑战，为改进在线具身推理提供了方向。"}}
{"id": "2507.07847", "title": "From Ambiguity to Accuracy: The Transformative Effect of Coreference Resolution on Retrieval-Augmented Generation systems", "authors": ["Youngjoon Jang", "Seongtae Hong", "Junyoung Son", "Sungjin Park", "Chanjun Park", "Heuiseok Lim"], "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a crucial framework in natural language processing (NLP), improving factual consistency and reducing hallucinations by integrating external document retrieval with large language models (LLMs). However, the effectiveness of RAG is often hindered by coreferential complexity in retrieved documents, introducing ambiguity that disrupts in-context learning. In this study, we systematically investigate how entity coreference affects both document retrieval and generative performance in RAG-based systems, focusing on retrieval relevance, contextual understanding, and overall response quality. We demonstrate that coreference resolution enhances retrieval effectiveness and improves question-answering (QA) performance. Through comparative analysis of different pooling strategies in retrieval tasks, we find that mean pooling demonstrates superior context capturing ability after applying coreference resolution. In QA tasks, we discover that smaller models benefit more from the disambiguation process, likely due to their limited inherent capacity for handling referential ambiguity. With these findings, this study aims to provide a deeper understanding of the challenges posed by coreferential complexity in RAG, providing guidance for improving retrieval and generation in knowledge-intensive AI applications.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.07847.pdf", "abstract_url": "https://arxiv.org/abs/2507.07847", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文探讨了在检索增强生成（RAG）系统中，指代消解如何从模糊性转变为准确性，从而提高检索效果和问答性能。", "motivation": "检索增强生成（RAG）框架在自然语言处理（NLP）中虽然提高了事实一致性和减少了幻觉，但其效果常因检索文档中的指代复杂性而受到阻碍，引入模糊性破坏了上下文学习。", "method": "本研究系统地调查了实体指代如何影响RAG系统中的文档检索和生成性能，重点关注检索相关性、上下文理解和整体回答质量。通过比较分析检索任务中的不同池化策略，发现应用指代消解后，均值池化展现出更优的上下文捕捉能力。", "result": "研究表明，指代消解提高了检索效果和问答性能。在问答任务中，较小的模型从消歧过程中获益更多，可能是因为它们处理指代模糊性的内在能力有限。", "conclusion": "本研究旨在更深入地理解RAG中指代复杂性带来的挑战，为改进知识密集型AI应用中的检索和生成提供指导。"}}
{"id": "2507.07870", "title": "DocCHA: Towards LLM-Augmented Interactive Online diagnosis System", "authors": ["Xinyi Liu", "Dachun Sun", "Yi R. Fung", "Dilek Hakkani-Tür", "Tarek Abdelzaher"], "abstract": "Despite the impressive capabilities of Large Language Models (LLMs), existing Conversational Health Agents (CHAs) remain static and brittle, incapable of adaptive multi-turn reasoning, symptom clarification, or transparent decision-making. This hinders their real-world applicability in clinical diagnosis, where iterative and structured dialogue is essential. We propose DocCHA, a confidence-aware, modular framework that emulates clinical reasoning by decomposing the diagnostic process into three stages: (1) symptom elicitation, (2) history acquisition, and (3) causal graph construction. Each module uses interpretable confidence scores to guide adaptive questioning, prioritize informative clarifications, and refine weak reasoning links.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.07870.pdf", "abstract_url": "https://arxiv.org/abs/2507.07870", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "DocCHA是一个面向LLM增强的交互式在线诊断系统，旨在通过模块化框架模拟临床推理，解决现有对话式健康代理在适应性多轮推理、症状澄清和透明决策方面的不足。", "motivation": "现有的对话式健康代理（CHAs）在临床诊断中显得静态和脆弱，缺乏适应性多轮推理、症状澄清或透明决策能力，这限制了它们在现实世界中的应用。", "method": "DocCHA采用一个信心感知的模块化框架，将诊断过程分解为三个阶段：症状引发、病史获取和因果图构建，每个阶段使用可解释的信心分数来指导适应性提问、优先考虑信息性澄清和优化弱推理链接。", "result": "DocCHA框架能够模拟临床推理，通过模块化和信心感知的方法，提高了对话式健康代理在临床诊断中的适应性和透明度。", "conclusion": "DocCHA通过其模块化和信心感知的方法，为对话式健康代理在临床诊断中的应用提供了一种新的、更适应和透明的解决方案，有望提高其在现实世界中的适用性。"}}
{"id": "2507.07155", "title": "Evaluating Retrieval-Augmented Generation Agents for Autonomous Scientific Discovery in Astrophysics", "authors": ["Xueqing Xu", "Boris Bolliet", "Adrian Dimitrov", "Andrew Laverick", "Francisco Villaescusa-Navarro", "Licong Xu", "Íñigo Zubeldia"], "abstract": "We evaluate 9 Retrieval Augmented Generation (RAG) agent configurations on 105 Cosmology Question-Answer (QA) pairs that we built specifically for this", "subjects": "Instrumentation and Methods for Astrophysics (astro-ph.IM); Cosmology and Nongalactic Astrophysics (astro-ph.CO); Artificial Intelligence (cs.AI)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2507.07155.pdf", "abstract_url": "https://arxiv.org/abs/2507.07155", "categories": ["Instrumentation and Methods for Astrophysics (astro-ph.IM)", "Cosmology and Nongalactic Astrophysics (astro-ph.CO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "评估了9种检索增强生成（RAG）代理配置在105个专门构建的宇宙学问答对上的表现。", "motivation": "解决在天体物理学领域进行自主科学发现时，检索增强生成代理的有效性问题。", "method": "使用了9种不同的RAG代理配置，并在105个宇宙学QA对上进行了评估。", "result": "论文未提供具体结果，但重点在于评估不同RAG配置的表现。", "conclusion": "通过评估不同RAG代理配置，为天体物理学领域的自主科学发现提供了潜在的改进方向。"}}
{"id": "2507.07887", "title": "Automating MD simulations for Proteins using Large language Models: NAMD-Agent", "authors": ["Achuth Chandrasekhar", "Amir Barati Farimani"], "abstract": "Molecular dynamics simulations are an essential tool in understanding protein structure, dynamics, and function at the atomic level. However, preparing high quality input files for MD simulations can be a time consuming and error prone process. In this work, we introduce an automated pipeline that leverages Large Language Models (LLMs), specifically Gemini 2.0 Flash, in conjunction with python scripting and Selenium based web automation to streamline the generation of MD input files. The pipeline exploits CHARMM GUI's comprehensive web-based interface for preparing simulation-ready inputs for NAMD. By integrating Gemini's code generation and iterative refinement capabilities, simulation scripts are automatically written, executed, and revised to navigate CHARMM GUI, extract appropriate parameters, and produce the required NAMD input files. Post processing is performed using additional software to further refine the simulation outputs, thereby enabling a complete and largely hands free workflow. Our results demonstrate that this approach reduces setup time, minimizes manual errors, and offers a scalable solution for handling multiple protein systems in parallel. This automated framework paves the way for broader application of LLMs in computational structural biology, offering a robust and adaptable platform for future developments in simulation automation.", "subjects": "Computation and Language (cs.CL); Computational Engineering, Finance, and Science (cs.CE); Biomolecules (q-bio.BM)", "comments": "34 pages", "pdf_url": "https://arxiv.org/pdf/2507.07887.pdf", "abstract_url": "https://arxiv.org/abs/2507.07887", "categories": ["Computation and Language (cs.CL)", "Computational Engineering, Finance, and Science (cs.CE)", "Biomolecules (q-bio.BM)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一种利用大型语言模型（LLMs）自动化生成分子动力学（MD）模拟输入文件的流程，旨在减少准备时间和人为错误。", "motivation": "准备高质量的MD模拟输入文件是一个耗时且容易出错的过程，本文旨在解决这一问题。", "method": "结合Gemini 2.0 Flash大型语言模型、Python脚本和基于Selenium的网络自动化技术，利用CHARMM GUI的网络界面自动化生成NAMD输入文件。", "result": "该方法减少了设置时间，最小化了手动错误，并为并行处理多个蛋白质系统提供了可扩展的解决方案。", "conclusion": "这一自动化框架为计算结构生物学中LLMs的更广泛应用铺平了道路，为模拟自动化的未来发展提供了一个强大且适应性强的平台。"}}
{"id": "2507.07197", "title": "Combining Pre-Trained Models for Enhanced Feature Representation in Reinforcement Learning", "authors": ["Elia Piccoli", "Malio Li", "Giacomo Carfì", "Vincenzo Lomonaco", "Davide Bacciu"], "abstract": "The recent focus and release of pre-trained models have been a key components to several advancements in many fields (e.g. Natural Language Processing and Computer Vision), as a matter of fact, pre-trained models learn disparate latent embeddings sharing insightful representations. On the other hand, Reinforcement Learning (RL) focuses on maximizing the cumulative reward obtained via agent's interaction with the environment. RL agents do not have any prior knowledge about the world, and they either learn from scratch an end-to-end mapping between the observation and action spaces or, in more recent works, are paired with monolithic and computationally expensive Foundational Models. How to effectively combine and leverage the hidden information of different pre-trained models simultaneously in RL is still an open and understudied question. In this work, we propose Weight Sharing Attention (WSA), a new architecture to combine embeddings of multiple pre-trained models to shape an enriched state representation, balancing the tradeoff between efficiency and performance. We run an extensive comparison between several combination modes showing that WSA obtains comparable performance on multiple Atari games compared to end-to-end models. Furthermore, we study the generalization capabilities of this approach and analyze how scaling the number of models influences agents' performance during and after training.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "Published at 4th Conference on Lifelong Learning Agents (CoLLAs), 2025", "pdf_url": "https://arxiv.org/pdf/2507.07197.pdf", "abstract_url": "https://arxiv.org/abs/2507.07197", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为Weight Sharing Attention (WSA)的新架构，旨在通过结合多个预训练模型的嵌入来丰富强化学习中的状态表示，平衡效率与性能之间的权衡。", "motivation": "强化学习(RL)代理通常没有关于世界的先验知识，它们要么从零开始学习观察与动作空间之间的端到端映射，要么与单一且计算成本高的基础模型配对。如何有效结合和利用不同预训练模型中的隐藏信息在RL中仍是一个开放且未被充分研究的问题。", "method": "提出Weight Sharing Attention (WSA)架构，用于结合多个预训练模型的嵌入，形成丰富的状态表示。", "result": "WSA在多个Atari游戏上获得了与端到端模型相当的性能，并研究了这种方法的泛化能力以及模型数量对代理性能的影响。", "conclusion": "WSA架构有效地结合了多个预训练模型的嵌入，为强化学习提供了丰富的状态表示，同时在效率和性能之间取得了良好的平衡。"}}
{"id": "2507.07299", "title": "LangNavBench: Evaluation of Natural Language Understanding in Semantic Navigation", "authors": ["Sonia Raychaudhuri", "Enrico Cancelli", "Tommaso Campari", "Lamberto Ballan", "Manolis Savva", "Angel X. Chang"], "abstract": "Recent progress in large vision-language models has driven improvements in language-based semantic navigation, where an embodied agent must reach a target object described in natural language. Despite these advances, we still lack a clear, language-focused benchmark for testing how well such agents ground the words in their instructions. We address this gap with LangNav, an open-set dataset specifically created to test an agent's ability to locate objects described at different levels of detail, from broad category names to fine attributes and object-object relations. Every description in LangNav was manually checked, yielding a lower error rate than existing lifelong- and semantic-navigation datasets. On top of LangNav we build LangNavBench, a benchmark that measures how well current semantic-navigation methods understand and act on these descriptions while moving toward their targets. LangNavBench allows us to systematically compare models on their handling of attributes, spatial and relational cues, and category hierarchies, offering the first thorough, language-centric evaluation of embodied navigation systems. We also present Multi-Layered Feature Map (MLFM), a method that builds a queryable multi-layered semantic map, particularly effective when dealing with small objects or instructions involving spatial relations. MLFM outperforms state-of-the-art mapping-based navigation baselines on the LangNav dataset.", "subjects": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.07299.pdf", "abstract_url": "https://arxiv.org/abs/2507.07299", "categories": ["Robotics (cs.RO)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了LangNavBench，一个专门用于测试基于语言的语义导航代理能力的开放数据集和基准测试。该数据集通过手动检查确保了低错误率，并支持从广泛类别到精细属性的多层次描述。同时，提出了Multi-Layered Feature Map (MLFM)方法，在小型对象或涉及空间关系的指令处理上表现优异。", "motivation": "当前缺乏一个明确、以语言为中心的基准来测试基于语言的语义导航代理如何理解其指令中的词汇。", "method": "创建了LangNav数据集和LangNavBench基准测试，并提出了Multi-Layered Feature Map (MLFM)方法，该方法构建了一个可查询的多层语义地图。", "result": "MLFM在LangNav数据集上优于现有的基于地图的导航基线方法。", "conclusion": "LangNavBench提供了一个系统比较模型处理属性、空间和关系线索以及类别层次结构的能力的平台，首次实现了对体现导航系统的全面、以语言为中心的评价。"}}
{"id": "2507.07957", "title": "MIRIX: Multi-Agent Memory System for LLM-Based Agents", "authors": ["Yu Wang", "Xi Chen"], "abstract": "Although memory capabilities of AI agents are gaining increasing attention, existing solutions remain fundamentally limited. Most rely on flat, narrowly scoped memory components, constraining their ability to personalize, abstract, and reliably recall user-specific information over time. To this end, we introduce MIRIX, a modular, multi-agent memory system that redefines the future of AI memory by solving the field's most critical challenge: enabling language models to truly remember. Unlike prior approaches, MIRIX transcends text to embrace rich visual and multimodal experiences, making memory genuinely useful in real-world scenarios. MIRIX consists of six distinct, carefully structured memory types: Core, Episodic, Semantic, Procedural, Resource Memory, and Knowledge Vault, coupled with a multi-agent framework that dynamically controls and coordinates updates and retrieval. This design enables agents to persist, reason over, and accurately retrieve diverse, long-term user data at scale. We validate MIRIX in two demanding settings. First, on ScreenshotVQA, a challenging multimodal benchmark comprising nearly 20,000 high-resolution computer screenshots per sequence, requiring deep contextual understanding and where no existing memory systems can be applied, MIRIX achieves 35% higher accuracy than the RAG baseline while reducing storage requirements by 99.9%. Second, on LOCOMO, a long-form conversation benchmark with single-modal textual input, MIRIX attains state-of-the-art performance of 85.4%, far surpassing existing baselines. These results show that MIRIX sets a new performance standard for memory-augmented LLM agents. To allow users to experience our memory system, we provide a packaged application powered by MIRIX. It monitors the screen in real time, builds a personalized memory base, and offers intuitive visualization and secure local storage to ensure privacy.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.07957.pdf", "abstract_url": "https://arxiv.org/abs/2507.07957", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "MIRIX是一个模块化的多代理记忆系统，旨在解决AI记忆领域的关键挑战，使语言模型能够真正记住信息。它通过六种不同的记忆类型和多代理框架，实现了对多样化、长期用户数据的持久化、推理和准确检索。在ScreenshotVQA和LOCOMO两个基准测试中，MIRIX表现出色，分别比基线提高了35%的准确率和达到了85.4%的最先进性能。", "motivation": "现有的AI代理记忆解决方案主要依赖于平面、范围狭窄的记忆组件，限制了它们在个性化、抽象和可靠回忆用户特定信息方面的能力。MIRIX旨在解决这一问题，通过引入一个能够处理丰富视觉和多模态体验的记忆系统，使记忆在现实世界场景中真正有用。", "method": "MIRIX由六种不同的记忆类型（核心、情景、语义、程序、资源记忆和知识库）和一个多代理框架组成，该框架动态控制和协调记忆的更新和检索。这种设计使代理能够持久化、推理和准确检索多样化的长期用户数据。", "result": "在ScreenshotVQA多模态基准测试中，MIRIX比RAG基线提高了35%的准确率，同时减少了99.9%的存储需求。在LOCOMO长形式对话基准测试中，MIRIX达到了85.4%的最先进性能。", "conclusion": "MIRIX为记忆增强的LLM代理设定了新的性能标准，通过其模块化和多代理的设计，能够有效地处理和检索多样化的长期用户数据。此外，MIRIX还提供了一个打包应用程序，允许用户体验其记忆系统，包括实时屏幕监控、个性化记忆库构建以及直观的可视化和安全的本地存储。"}}
{"id": "2507.07983", "title": "Performance and Practical Considerations of Large and Small Language Models in Clinical Decision Support in Rheumatology", "authors": ["Sabine Felde", "Rüdiger Buchkremer", "Gamal Chehab", "Christian Thielscher", "Jörg HW Distler", "Matthias Schneider", "Jutta G. Richter"], "abstract": "Large language models (LLMs) show promise for supporting clinical decision-making in complex fields such as rheumatology. Our evaluation shows that smaller language models (SLMs), combined with retrieval-augmented generation (RAG), achieve higher diagnostic and therapeutic performance than larger models, while requiring substantially less energy and enabling cost-efficient, local deployment. These features are attractive for resource-limited healthcare. However, expert oversight remains essential, as no model consistently reached specialist-level accuracy in rheumatology.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.07983.pdf", "abstract_url": "https://arxiv.org/abs/2507.07983", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "大型语言模型（LLMs）在复杂领域如风湿病学中支持临床决策显示出潜力。我们的评估显示，结合检索增强生成（RAG）的小型语言模型（SLMs）在诊断和治疗性能上优于大型模型，同时能耗显著降低，支持成本效益高的本地部署。这些特点对资源有限的医疗保健具有吸引力。然而，专家监督仍然必不可少，因为没有模型能持续达到风湿病学专家的准确度。", "motivation": "解决在资源有限的医疗保健环境中，如何高效、准确地支持临床决策的问题，特别是在复杂的风湿病学领域。", "method": "结合检索增强生成（RAG）的小型语言模型（SLMs）与大型语言模型（LLMs）进行比较评估。", "result": "小型语言模型（SLMs）在诊断和治疗性能上优于大型模型，同时能耗更低，支持成本效益高的本地部署。", "conclusion": "尽管小型语言模型（SLMs）在性能和能效方面优于大型模型，但在风湿病学领域，专家监督仍然是确保临床决策准确性的关键。"}}
{"id": "2507.07998", "title": "PyVision: Agentic Vision with Dynamic Tooling", "authors": ["Shitian Zhao", "Haoquan Zhang", "Shaoheng Lin", "Ming Li", "Qilong Wu", "Kaipeng Zhang", "Chen Wei"], "abstract": "LLMs are increasingly deployed as agents, systems capable of planning, reasoning, and dynamically calling external tools. However, in visual reasoning, prior approaches largely remain limited by predefined workflows and static toolsets. In this report, we present PyVision, an interactive, multi-turn framework that enables MLLMs to autonomously generate, execute, and refine Python-based tools tailored to the task at hand, unlocking flexible and interpretable problem-solving. We develop a taxonomy of the tools created by PyVision and analyze their usage across a diverse set of benchmarks. Quantitatively, PyVision achieves consistent performance gains, boosting GPT-4.1 by +7.8% on V* and Claude-4.0-Sonnet by +31.1% on VLMsAreBlind-mini. These results point to a broader shift: dynamic tooling allows models not just to use tools, but to invent them, advancing toward more agentic visual reasoning.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "comments": "26 Pages, 10 Figures, Technical report", "pdf_url": "https://arxiv.org/pdf/2507.07998.pdf", "abstract_url": "https://arxiv.org/abs/2507.07998", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "PyVision是一个交互式、多轮次的框架，使MLLMs能够自主生成、执行和优化基于Python的工具，以实现灵活和可解释的视觉问题解决。", "motivation": "解决视觉推理中预定义工作流和静态工具集的限制，提升模型的自主性和灵活性。", "method": "开发了一个动态生成和执行Python工具的框架，并对其在不同基准测试中的使用进行了分类和分析。", "result": "PyVision在多个基准测试中实现了性能提升，如GPT-4.1在V*上提升了7.8%，Claude-4.0-Sonnet在VLMsAreBlind-mini上提升了31.1%。", "conclusion": "动态工具生成不仅使模型能够使用工具，还能发明工具，推动了更自主的视觉推理发展。"}}
{"id": "2507.07376", "title": "PILOC: A Pheromone Inverse Guidance Mechanism and Local-Communication Framework for Dynamic Target Search of Multi-Agent in Unknown Environments", "authors": ["Hengrui Liu", "Yi Feng", "Qilong Zhang"], "abstract": "Multi-Agent Search and Rescue (MASAR) plays a vital role in disaster response, exploration, and reconnaissance. However, dynamic and unknown environments pose significant challenges due to target unpredictability and environmental uncertainty. To tackle these issues, we propose PILOC, a framework that operates without global prior knowledge, leveraging local perception and communication. It introduces a pheromone inverse guidance mechanism to enable efficient coordination and dynamic target localization. PILOC promotes decentralized cooperation through local communication, significantly reducing reliance on global channels. Unlike conventional heuristics, the pheromone mechanism is embedded into the observation space of Deep Reinforcement Learning (DRL), supporting indirect agent coordination based on environmental cues. We further integrate this strategy into a DRL-based multi-agent architecture and conduct extensive experiments. Results show that combining local communication with pheromone-based guidance significantly boosts search efficiency, adaptability, and system robustness. Compared to existing methods, PILOC performs better under dynamic and communication-constrained scenarios, offering promising directions for future MASAR applications.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.07376.pdf", "abstract_url": "https://arxiv.org/abs/2507.07376", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为PILOC的框架，用于在未知环境中进行多智能体动态目标搜索，通过局部感知和通信以及信息素逆向引导机制，提高了搜索效率和系统鲁棒性。", "motivation": "解决在动态和未知环境中多智能体搜索和救援（MASAR）面临的目标准确预测和环境不确定性的挑战。", "method": "提出PILOC框架，结合局部通信和信息素逆向引导机制，并将信息素机制嵌入深度强化学习（DRL）的观察空间，支持基于环境线索的间接智能体协调。", "result": "实验结果表明，结合局部通信和信息素引导的策略显著提高了搜索效率、适应性和系统鲁棒性，在动态和通信受限的场景下表现优于现有方法。", "conclusion": "PILOC为未来的MASAR应用提供了有前景的方向，特别是在动态和通信受限的环境中。"}}
{"id": "2507.07906", "title": "Agentic Retrieval of Topics and Insights from Earnings Calls", "authors": ["Anant Gupta", "Rajarshi Bhowmik", "Geoffrey Gunow"], "abstract": "Tracking the strategic focus of companies through topics in their earnings calls is a key task in financial analysis. However, as industries evolve, traditional topic modeling techniques struggle to dynamically capture emerging topics and their relationships. In this work, we propose an LLM-agent driven approach to discover and retrieve emerging topics from quarterly earnings calls. We propose an LLM-agent to extract topics from documents, structure them into a hierarchical ontology, and establish relationships between new and existing topics through a topic ontology. We demonstrate the use of extracted topics to infer company-level insights and emerging trends over time. We evaluate our approach by measuring ontology coherence, topic evolution accuracy, and its ability to surface emerging financial trends.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "The 2nd Workshop on Financial Information Retrieval in the Era of Generative AI, The 48th International ACM SIGIR Conference on Research and Development in Information Retrieval July 13-17, 2025 | Padua, Italy", "pdf_url": "https://arxiv.org/pdf/2507.07906.pdf", "abstract_url": "https://arxiv.org/abs/2507.07906", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种基于LLM-agent的方法，用于从季度收益电话会议中发现和检索新兴主题，通过构建层次化本体来动态捕捉新兴主题及其关系，并评估了其在推断公司层面见解和新兴趋势方面的有效性。", "motivation": "传统主题建模技术在动态捕捉新兴主题及其关系方面存在困难，特别是在行业快速演变的情况下。", "method": "使用LLM-agent从文档中提取主题，将其结构化为层次化本体，并通过主题本体建立新旧主题之间的关系。", "result": "通过测量本体一致性、主题演化准确性及其在发现新兴金融趋势方面的能力，评估了所提方法的有效性。", "conclusion": "所提出的LLM-agent驱动方法能够有效发现和检索新兴主题，为财务分析提供了动态捕捉公司战略焦点的新工具。"}}
{"id": "2507.07969", "title": "Reinforcement Learning with Action Chunking", "authors": ["Qiyang Li", "Zhiyuan Zhou", "Sergey Levine"], "abstract": "We present Q-chunking, a simple yet effective recipe for improving reinforcement learning (RL) algorithms for long-horizon, sparse-reward tasks. Our recipe is designed for the offline-to-online RL setting, where the goal is to leverage an offline prior dataset to maximize the sample-efficiency of online learning. Effective exploration and sample-efficient learning remain central challenges in this setting, as it is not obvious how the offline data should be utilized to acquire a good exploratory policy. Our key insight is that action chunking, a technique popularized in imitation learning where sequences of future actions are predicted rather than a single action at each timestep, can be applied to temporal difference (TD)-based RL methods to mitigate the exploration challenge. Q-chunking adopts action chunking by directly running RL in a 'chunked' action space, enabling the agent to (1) leverage temporally consistent behaviors from offline data for more effective online exploration and (2) use unbiased $n$-step backups for more stable and efficient TD learning. Our experimental results demonstrate that Q-chunking exhibits strong offline performance and online sample efficiency, outperforming prior best offline-to-online methods on a range of long-horizon, sparse-reward manipulation tasks.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Robotics (cs.RO); Machine Learning (stat.ML)", "comments": "25 pages, 15 figures", "pdf_url": "https://arxiv.org/pdf/2507.07969.pdf", "abstract_url": "https://arxiv.org/abs/2507.07969", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Robotics (cs.RO)", "Machine Learning (stat.ML)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了Q-chunking，一种通过动作分块（action chunking）技术改进强化学习算法的方法，特别适用于长周期、稀疏奖励任务，旨在提高离线到在线强化学习设置中的样本效率。", "motivation": "解决在离线到在线强化学习设置中，如何有效利用离线数据来提升在线学习的样本效率和探索效率的核心挑战。", "method": "采用动作分块技术，将未来动作序列而非单个动作预测应用于基于时间差分（TD）的强化学习方法，直接在'分块'动作空间中运行强化学习。", "result": "实验结果表明，Q-chunking在离线性能和在线样本效率方面表现出色，在一系列长周期、稀疏奖励的操作任务上优于先前最佳的离线到在线方法。", "conclusion": "Q-chunking通过动作分块技术有效解决了探索挑战，提高了强化学习在长周期、稀疏奖励任务中的性能和样本效率。"}}
