{"id": "2506.04606", "title": "SmartAvatar: Text- and Image-Guided Human Avatar Generation with VLM AI Agents", "authors": ["Alexander Huang-Menders", "Xinhang Liu", "Andy Xu", "Yuyao Zhang", "Chi-Keung Tang", "Yu-Wing Tai"], "abstract": "SmartAvatar is a vision-language-agent-driven framework for generating fully rigged, animation-ready 3D human avatars from a single photo or textual prompt. While diffusion-based methods have made progress in general 3D object generation, they continue to struggle with precise control over human identity, body shape, and animation readiness. In contrast, SmartAvatar leverages the commonsense reasoning capabilities of large vision-language models (VLMs) in combination with off-the-shelf parametric human generators to deliver high-quality, customizable avatars. A key innovation is an autonomous verification loop, where the agent renders draft avatars, evaluates facial similarity, anatomical plausibility, and prompt alignment, and iteratively adjusts generation parameters for convergence. This interactive, AI-guided refinement process promotes fine-grained control over both facial and body features, enabling users to iteratively refine their avatars via natural-language conversations. Unlike diffusion models that rely on static pre-trained datasets and offer limited flexibility, SmartAvatar brings users into the modeling loop and ensures continuous improvement through an LLM-driven procedural generation and verification system. The generated avatars are fully rigged and support pose manipulation with consistent identity and appearance, making them suitable for downstream animation and interactive applications. Quantitative benchmarks and user studies demonstrate that SmartAvatar outperforms recent text- and image-driven avatar generation systems in terms of reconstructed mesh quality, identity fidelity, attribute accuracy, and animation readiness, making it a versatile tool for realistic, customizable avatar creation on consumer-grade hardware.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "16 pages", "pdf_url": "https://arxiv.org/pdf/2506.04606.pdf", "abstract_url": "https://arxiv.org/abs/2506.04606", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "SmartAvatar是一个由视觉语言代理驱动的框架，用于从单张照片或文本提示生成完全绑定、准备动画的3D人类头像。", "motivation": "解决扩散方法在人类身份、体型和动画准备性方面精确控制的不足。", "method": "利用大型视觉语言模型(VLMs)的常识推理能力与现成的参数化人类生成器结合，通过自主验证循环迭代调整生成参数。", "result": "在重建网格质量、身份保真度、属性准确性和动画准备性方面优于最近的文本和图像驱动头像生成系统。", "conclusion": "SmartAvatar是一个多功能工具，适用于在消费级硬件上创建逼真、可定制的头像。"}}
{"id": "2506.04363", "title": "WorldPrediction: A Benchmark for High-level World Modeling and Long-horizon Procedural Planning", "authors": ["Delong Chen", "Willy Chung", "Yejin Bang", "Ziwei Ji", "Pascale Fung"], "abstract": "Humans are known to have an internal \"world model\" that enables us to carry out action planning based on world states. AI agents need to have such a world model for action planning as well. It is not clear how current AI models, especially generative models, are able to learn such world models and carry out procedural planning in diverse environments. We introduce WorldPrediction, a video-based benchmark for evaluating world modeling and procedural planning capabilities of different AI models. In contrast to prior benchmarks that focus primarily on low-level world modeling and robotic motion planning, WorldPrediction is the first benchmark that emphasizes actions with temporal and semantic abstraction. Given initial and final world states, the task is to distinguish the proper action (WorldPrediction-WM) or the properly ordered sequence of actions (WorldPrediction-PP) from a set of counterfactual distractors. This discriminative task setup enable us to evaluate different types of world models and planners and realize a thorough comparison across different hypothesis. The benchmark represents states and actions using visual observations. In order to prevent models from exploiting low-level continuity cues in background scenes, we provide \"action equivalents\" - identical actions observed in different contexts - as candidates for selection. This benchmark is grounded in a formal framework of partially observable semi-MDP, ensuring better reliability and robustness of the evaluation. We conduct extensive human filtering and validation on our benchmark and show that current frontier models barely achieve 57% accuracy on WorldPrediction-WM and 38% on WorldPrediction-PP whereas humans are able to solve both tasks perfectly.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04363.pdf", "abstract_url": "https://arxiv.org/abs/2506.04363", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "WorldPrediction是一个基于视频的基准测试，用于评估不同AI模型的世界建模和程序规划能力，特别关注具有时间和语义抽象的动作。", "motivation": "解决当前AI模型，尤其是生成模型，在多样化环境中学习世界模型和执行程序规划能力的不明确性问题。", "method": "引入WorldPrediction基准测试，使用视觉观察表示状态和动作，并提供“动作等价物”以防止模型利用背景场景中的低级连续性线索。", "result": "当前前沿模型在WorldPrediction-WM和WorldPrediction-PP上的准确率分别为57%和38%，而人类能够完美解决这两个任务。", "conclusion": "WorldPrediction基准测试为评估和比较不同类型的世界模型和规划器提供了一个可靠和健壮的框架，揭示了当前AI模型与世界建模和程序规划能力之间的差距。"}}
{"id": "2506.04595", "title": "Hierarchical-Task-Aware Multi-modal Mixture of Incremental LoRA Experts for Embodied Continual Learning", "authors": ["Ziqi Jia", "Anmin Wang", "Xiaoyang Qu", "Xiaowen Yang", "Jianzong Wang"], "abstract": "Previous continual learning setups for embodied intelligence focused on executing low-level actions based on human commands, neglecting the ability to learn high-level planning and multi-level knowledge. To address these issues, we propose the Hierarchical Embodied Continual Learning Setups (HEC) that divide the agent's continual learning process into two layers: high-level instructions and low-level actions, and define five embodied continual learning sub-setups. Building on these setups, we introduce the Task-aware Mixture of Incremental LoRA Experts (Task-aware MoILE) method. This approach achieves task recognition by clustering visual-text embeddings and uses both a task-level router and a token-level router to select the appropriate LoRA experts. To effectively address the issue of catastrophic forgetting, we apply Singular Value Decomposition (SVD) to the LoRA parameters obtained from prior tasks, preserving key components while orthogonally training the remaining parts. The experimental results show that our method stands out in reducing the forgetting of old tasks compared to other methods, effectively supporting agents in retaining prior knowledge while continuously learning new tasks.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "Accepted by the 63rd Annual Meeting of the Association for Computational Linguistics (ACL 2025)", "pdf_url": "https://arxiv.org/pdf/2506.04595.pdf", "abstract_url": "https://arxiv.org/abs/2506.04595", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了分层体现持续学习设置（HEC），将代理的持续学习过程分为高层指令和低层动作两个层次，并定义了五个体现持续学习子设置。在此基础上，引入了任务感知的增量LoRA专家混合（Task-aware MoILE）方法，通过聚类视觉-文本嵌入实现任务识别，并使用任务级和令牌级路由器选择合适的LoRA专家。为了有效解决灾难性遗忘问题，我们对先前任务获得的LoRA参数应用奇异值分解（SVD），保留关键组件的同时正交训练其余部分。实验结果表明，我们的方法在减少旧任务遗忘方面表现突出，有效支持代理在持续学习新任务的同时保留先验知识。", "motivation": "解决现有体现智能持续学习设置中忽视高层规划和多级知识学习能力的问题。", "method": "提出了分层体现持续学习设置（HEC）和任务感知的增量LoRA专家混合（Task-aware MoILE）方法，包括任务识别、任务级和令牌级路由器选择LoRA专家，以及应用SVD解决灾难性遗忘。", "result": "实验结果显示，该方法在减少旧任务遗忘方面优于其他方法，有效支持代理在持续学习新任务的同时保留先验知识。", "conclusion": "通过分层学习和任务感知的LoRA专家混合方法，有效解决了体现智能持续学习中的高层规划和多级知识学习问题，同时减少了灾难性遗忘。"}}
{"id": "2506.04743", "title": "SRD: Reinforcement-Learned Semantic Perturbation for Backdoor Defense in VLMs", "authors": ["Shuhan Xu", "Siyuan Liang", "Hongling Zheng", "Yong Luo", "Aishan Liu", "Dacheng Tao"], "abstract": "Vision-Language Models (VLMs) have achieved remarkable performance in image captioning, but recent studies show they are vulnerable to backdoor attacks. Attackers can inject imperceptible perturbations-such as local pixel triggers or global semantic phrases-into the training data, causing the model to generate malicious, attacker-controlled captions for specific inputs. These attacks are hard to detect and defend due to their stealthiness and cross-modal nature. By analyzing attack samples, we identify two key vulnerabilities: (1) abnormal attention concentration on specific image regions, and (2) semantic drift and incoherence in generated captions. To counter this, we propose Semantic Reward Defense (SRD), a reinforcement learning framework that mitigates backdoor behavior without prior knowledge of triggers. SRD uses a Deep Q-Network to learn policies for applying discrete perturbations (e.g., occlusion, color masking) to sensitive image regions, aiming to disrupt the activation of malicious pathways. We design a semantic fidelity score as the reward signal, which jointly evaluates semantic consistency and linguistic fluency of the output, guiding the agent toward generating robust yet faithful captions. Experiments across mainstream VLMs and datasets show SRD reduces attack success rates to 5.6%, while preserving caption quality on clean inputs with less than 10% performance drop. SRD offers a trigger-agnostic, interpretable defense paradigm against stealthy backdoor threats in multimodal generative models.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04743.pdf", "abstract_url": "https://arxiv.org/abs/2506.04743", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为SRD的强化学习框架，用于防御视觉语言模型（VLMs）中的后门攻击，通过应用离散扰动破坏恶意路径的激活，同时保持生成的标题质量。", "motivation": "视觉语言模型在图像描述生成方面表现出色，但易受后门攻击，攻击者通过注入难以察觉的扰动控制模型生成恶意标题。这些攻击因其隐蔽性和跨模态特性难以检测和防御。", "method": "提出语义奖励防御（SRD），一个强化学习框架，使用深度Q网络学习对敏感图像区域应用离散扰动（如遮挡、颜色掩码）的策略，旨在破坏恶意路径的激活。设计语义保真度分数作为奖励信号，评估输出的语义一致性和语言流畅性。", "result": "在主流VLMs和数据集上的实验显示，SRD将攻击成功率降低至5.6%，同时在干净输入上保持标题质量，性能下降不到10%。", "conclusion": "SRD提供了一种无需触发器先验知识、可解释的防御范式，有效对抗多模态生成模型中的隐蔽后门威胁。"}}
{"id": "2506.04676", "title": "Gen-n-Val: Agentic Image Data Generation and Validation", "authors": ["Jing-En Huang", "I-Sheng Fang", "Tzuhsuan Huang", "Chih-Yu Wang", "Jun-Cheng Chen"], "abstract": "Recently, Large Language Models (LLMs) and Vision Large Language Models (VLLMs) have demonstrated impressive performance as agents across various tasks while data scarcity and label noise remain significant challenges in computer vision tasks, such as object detection and instance segmentation. A common solution for resolving these issues is to generate synthetic data. However, current synthetic data generation methods struggle with issues, such as multiple objects per mask, inaccurate segmentation, and incorrect category labels, limiting their effectiveness. To address these issues, we introduce Gen-n-Val, a novel agentic data generation framework that leverages Layer Diffusion (LD), LLMs, and VLLMs to produce high-quality, single-object masks and diverse backgrounds. Gen-n-Val consists of two agents: (1) The LD prompt agent, an LLM, optimizes prompts for LD to generate high-quality foreground instance images and segmentation masks. These optimized prompts ensure the generation of single-object synthetic data with precise instance masks and clean backgrounds. (2) The data validation agent, a VLLM, which filters out low-quality synthetic instance images. The system prompts for both agents are refined through TextGrad. Additionally, we use image harmonization to combine multiple instances within scenes. Compared to state-of-the-art synthetic data approaches like MosaicFusion, our approach reduces invalid synthetic data from 50% to 7% and improves performance by 1% mAP on rare classes in COCO instance segmentation with YOLOv9c and YOLO11m. Furthermore, Gen-n-Val shows significant improvements (7. 1% mAP) over YOLO-Worldv2-M in open-vocabulary object detection benchmarks with YOLO11m. Moreover, Gen-n-Val improves the performance of YOLOv9 and YOLO11 families in instance segmentation and object detection.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04676.pdf", "abstract_url": "https://arxiv.org/abs/2506.04676", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "Gen-n-Val是一个新颖的代理数据生成框架，利用Layer Diffusion、LLMs和VLLMs生成高质量的单对象掩码和多样化背景，解决了计算机视觉任务中的数据稀缺和标签噪声问题。", "motivation": "解决计算机视觉任务中数据稀缺和标签噪声的挑战，特别是对象检测和实例分割中的多对象掩码、不准确分割和错误类别标签问题。", "method": "采用Layer Diffusion (LD)、LLMs和VLLMs，通过两个代理：LD提示代理优化LD的提示以生成高质量的前景实例图像和分割掩码；数据验证代理过滤低质量的合成实例图像。使用TextGrad优化系统提示，并通过图像和谐化将多个实例组合到场景中。", "result": "与最先进的合成数据方法如MosaicFusion相比，Gen-n-Val将无效合成数据从50%减少到7%，并在COCO实例分割中提高了1% mAP，在开放词汇对象检测基准中提高了7.1% mAP。", "conclusion": "Gen-n-Val显著提高了YOLOv9和YOLO11系列在实例分割和对象检测中的性能，为计算机视觉任务提供了一种高效的数据生成和验证方法。"}}
{"id": "2506.04344", "title": "GEM: Empowering LLM for both Embedding Generation and Language Understanding", "authors": ["Caojin Zhang", "Qiang Zhang", "Ke Li", "Sai Vidyaranya Nuthalapati", "Benyu Zhang", "Jason Liu", "Serena Li", "Lizhu Zhang", "Xiangjun Fan"], "abstract": "Large decoder-only language models (LLMs) have achieved remarkable success in generation and reasoning tasks, where they generate text responses given instructions. However, many applications, e.g., retrieval augmented generation (RAG), still rely on separate embedding models to generate text embeddings, which can complicate the system and introduce discrepancies in understanding of the query between the embedding model and LLMs. To address this limitation, we propose a simple self-supervised approach, Generative Embedding large language Model (GEM), that enables any large decoder-only LLM to generate high-quality text embeddings while maintaining its original text generation and reasoning capabilities. Our method inserts new special token(s) into a text body, and generates summarization embedding of the text by manipulating the attention mask. This method could be easily integrated into post-training or fine tuning stages of any existing LLMs. We demonstrate the effectiveness of our approach by applying it to two popular LLM families, ranging from 1B to 8B parameters, and evaluating the transformed models on both text embedding benchmarks (MTEB) and NLP benchmarks (MMLU). The results show that our proposed method significantly improves the original LLMs on MTEB while having a minimal impact on MMLU. Our strong results indicate that our approach can empower LLMs with state-of-the-art text embedding capabilities while maintaining their original NLP performance", "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04344.pdf", "abstract_url": "https://arxiv.org/abs/2506.04344", "categories": ["Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种名为GEM的自监督方法，使大型仅解码器语言模型（LLM）能够生成高质量的文本嵌入，同时保持其原有的文本生成和推理能力。", "motivation": "解决在许多应用中，如检索增强生成（RAG），仍需依赖单独的嵌入模型生成文本嵌入，这可能导致系统复杂化并在嵌入模型与LLM之间引入理解差异的问题。", "method": "通过在文本体中插入新的特殊标记，并通过操纵注意力掩码生成文本的摘要嵌入，这种方法可以轻松集成到任何现有LLM的后训练或微调阶段。", "result": "应用该方法于两个流行的LLM家族（参数范围从1B到8B）并在文本嵌入基准（MTEB）和NLP基准（MMLU）上评估，结果显示该方法显著提高了原始LLM在MTEB上的性能，同时对MMLU的影响最小。", "conclusion": "GEM方法能够赋予LLM最先进的文本嵌入能力，同时保持其原有的NLP性能，具有广泛的应用潜力。"}}
{"id": "2506.04790", "title": "LotusFilter: Fast Diverse Nearest Neighbor Search via a Learned Cutoff Table", "authors": ["Yusuke Matsui"], "abstract": "Approximate nearest neighbor search (ANNS) is an essential building block for applications like RAG but can sometimes yield results that are overly similar to each other. In certain scenarios, search results should be similar to the query and yet diverse. We propose LotusFilter, a post-processing module to diversify ANNS results. We precompute a cutoff table summarizing vectors that are close to each other. During the filtering, LotusFilter greedily looks up the table to delete redundant vectors from the candidates. We demonstrated that the LotusFilter operates fast (0.02 [ms/query]) in settings resembling real-world RAG applications, utilizing features such as OpenAI embeddings. Our code is publicly available at", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Information Retrieval (cs.IR); Machine Learning (cs.LG)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2506.04790.pdf", "abstract_url": "https://arxiv.org/abs/2506.04790", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Information Retrieval (cs.IR)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "LotusFilter是一种快速多样化的最近邻搜索后处理模块，通过预计算的截止表来删除冗余向量，提高搜索结果的多样性。", "motivation": "解决近似最近邻搜索（ANNS）结果过于相似的问题，特别是在需要结果既相似又多样化的场景中。", "method": "预计算一个截止表，总结彼此接近的向量，在过滤过程中贪婪地查找该表以删除候选中的冗余向量。", "result": "在类似真实世界RAG应用的环境中，LotusFilter操作速度快（0.02 [ms/query]），并利用了如OpenAI嵌入等特性。", "conclusion": "LotusFilter提供了一种有效的方法来多样化ANNS结果，适用于需要高质量多样化搜索结果的应用程序。"}}
{"id": "2506.04389", "title": "Building a Few-Shot Cross-Domain Multilingual NLU Model for Customer Care", "authors": ["Saurabh Kumar", "Sourav Bansal", "Neeraj Agrawal", "Priyanka Bhatt"], "abstract": "Customer care is an essential pillar of the e-commerce shopping experience with companies spending millions of dollars each year, employing automation and human agents, across geographies (like US, Canada, Mexico, Chile), channels (like Chat, Interactive Voice Response (IVR)), and languages (like English, Spanish). SOTA pre-trained models like multilingual-BERT, fine-tuned on annotated data have shown good performance in downstream tasks relevant to Customer Care. However, model performance is largely subject to the availability of sufficient annotated domain-specific data. Cross-domain availability of data remains a bottleneck, thus building an intent classifier that generalizes across domains (defined by channel, geography, and language) with only a few annotations, is of great practical value. In this paper, we propose an embedder-cum-classifier model architecture which extends state-of-the-art domain-specific models to other domains with only a few labeled samples. We adopt a supervised fine-tuning approach with isotropic regularizers to train a domain-specific sentence embedder and a multilingual knowledge distillation strategy to generalize this embedder across multiple domains. The trained embedder, further augmented with a simple linear classifier can be deployed for new domains. Experiments on Canada and Mexico e-commerce Customer Care dataset with few-shot intent detection show an increase in accuracy by 20-23% against the existing state-of-the-art pre-trained models.", "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04389.pdf", "abstract_url": "https://arxiv.org/abs/2506.04389", "categories": ["Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文提出了一种用于客户服务的少样本跨域多语言自然语言理解模型，通过结合嵌入器和分类器的架构，以及使用各向同性正则器和多语言知识蒸馏策略，显著提高了新领域的意图检测准确率。", "motivation": "解决在客户服务领域中，由于跨域数据可用性有限，构建能够跨渠道、地理和语言泛化的意图分类器的挑战。", "method": "采用监督微调方法结合各向同性正则器训练领域特定的句子嵌入器，并使用多语言知识蒸馏策略将该嵌入器泛化到多个领域。", "result": "在加拿大和墨西哥的电子商务客户服务数据集上的实验显示，与现有最先进的预训练模型相比，意图检测的准确率提高了20-23%。", "conclusion": "提出的模型架构和训练策略有效解决了跨域少样本学习的问题，为多语言客户服务自动化提供了实用价值。"}}
{"id": "2506.04405", "title": "MedAgentGym: Training LLM Agents for Code-Based Medical Reasoning at Scale", "authors": ["Ran Xu", "Yuchen Zhuang", "Yishan Zhong", "Yue Yu", "Xiangru Tang", "Hang Wu", "May D. Wang", "Peifeng Ruan", "Donghan Yang", "Tao Wang", "Guanghua Xiao", "Carl Yang", "Yang Xie", "Wenqi Shi"], "abstract": "We introduce MedAgentGYM, the first publicly available training environment designed to enhance coding-based medical reasoning capabilities in large language model (LLM) agents. MedAgentGYM comprises 72,413 task instances across 129 categories derived from authentic real-world biomedical scenarios. Tasks are encapsulated within executable coding environments, each featuring detailed task descriptions, interactive feedback mechanisms, verifiable ground-truth annotations, and scalable training trajectory generation. Extensive benchmarking of over 30 LLMs reveals a notable performance disparity between commercial API-based models and open-source counterparts. Leveraging MedAgentGYM, Med-Copilot-7B achieves substantial performance gains through supervised fine-tuning (+36.44%) and continued reinforcement learning (+42.47%), emerging as an affordable and privacy-preserving alternative competitive with gpt-4o. By offering both a comprehensive benchmark and accessible, expandable training resources within unified execution environments, MedAgentGYM delivers an integrated platform to develop LLM-based coding assistants for advanced biomedical research and practice.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04405.pdf", "abstract_url": "https://arxiv.org/abs/2506.04405", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "介绍了MedAgentGYM，首个公开的训练环境，旨在增强大型语言模型（LLM）代理的基于编码的医学推理能力。包含72,413个任务实例，覆盖129个类别，源自真实世界生物医学场景。通过监督微调和持续强化学习，Med-Copilot-7B性能显著提升。", "motivation": "解决现有LLM在基于编码的医学推理能力上的不足，提供一个全面、可扩展的训练和评估平台。", "method": "开发MedAgentGYM环境，包含大量真实生物医学任务，支持监督微调和强化学习。", "result": "Med-Copilot-7B通过监督微调和强化学习分别实现了36.44%和42.47%的性能提升，性能接近gpt-4o。", "conclusion": "MedAgentGYM为开发生物医学研究和实践中的LLM编码助手提供了综合平台，展示了开源模型在特定领域的潜力。"}}
{"id": "2506.04409", "title": "Empaths at SemEval-2025 Task 11: Retrieval-Augmented Approach to Perceived Emotions Prediction", "authors": ["Lev Morozov", "Aleksandr Mogilevskii", "Alexander Shirnin"], "abstract": "This paper describes EmoRAG, a system designed to detect perceived emotions in text for SemEval-2025 Task 11, Subtask A: Multi-label Emotion Detection. We focus on predicting the perceived emotions of the speaker from a given text snippet, labeling it with emotions such as joy, sadness, fear, anger, surprise, and disgust. Our approach does not require additional model training and only uses an ensemble of models to predict emotions. EmoRAG achieves results comparable to the best performing systems, while being more efficient, scalable, and easier to implement.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "Accepted to SemEval-2025, an ACL 2025 workshop", "pdf_url": "https://arxiv.org/pdf/2506.04409.pdf", "abstract_url": "https://arxiv.org/abs/2506.04409", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了EmoRAG系统，该系统旨在为SemEval-2025 Task 11的Subtask A（多标签情绪检测）检测文本中的感知情绪。通过不依赖额外模型训练，仅使用模型集成来预测情绪，EmoRAG在保持高效、可扩展和易于实现的同时，取得了与最佳表现系统相当的结果。", "motivation": "解决从文本片段中预测说话者感知情绪（如喜悦、悲伤、恐惧、愤怒、惊讶和厌恶）的问题，特别是在多标签情绪检测任务中。", "method": "采用检索增强的方法，不进行额外的模型训练，而是使用模型集成来预测情绪。", "result": "EmoRAG在性能上与最佳表现系统相当，同时更高效、可扩展且易于实现。", "conclusion": "EmoRAG提供了一种有效的方法来预测文本中的感知情绪，其高效性和易实现性使其在实际应用中具有潜在优势。"}}
{"id": "2506.04245", "title": "Contextual Integrity in LLMs via Reasoning and Reinforcement Learning", "authors": ["Guangchen Lan", "Huseyin A. Inan", "Sahar Abdelnabi", "Janardhan Kulkarni", "Lukas Wutschitz", "Reza Shokri", "Christopher G. Brinton", "Robert Sim"], "abstract": "As the era of autonomous agents making decisions on behalf of users unfolds, ensuring contextual integrity (CI) -- what is the appropriate information to share while carrying out a certain task -- becomes a central question to the field. We posit that CI demands a form of reasoning where the agent needs to reason about the context in which it is operating. To test this, we first prompt LLMs to reason explicitly about CI when deciding what information to disclose. We then extend this approach by developing a reinforcement learning (RL) framework that further instills in models the reasoning necessary to achieve CI. Using a synthetic, automatically created, dataset of only $\\sim700$ examples but with diverse contexts and information disclosure norms, we show that our method substantially reduces inappropriate information disclosure while maintaining task performance across multiple model sizes and families. Importantly, improvements transfer from this synthetic dataset to established CI benchmarks such as PrivacyLens that has human annotations and evaluates privacy leakage of AI assistants in actions and tool calls.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04245.pdf", "abstract_url": "https://arxiv.org/abs/2506.04245", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了在自主代理为用户做出决策的时代，如何通过推理和强化学习确保上下文完整性（CI），即在进行特定任务时分享适当信息的问题。", "motivation": "解决自主代理在决策过程中如何确保不泄露不适当信息，维护上下文完整性的问题。", "method": "首先通过提示大型语言模型（LLMs）明确推理CI来决定披露哪些信息，然后开发一个强化学习（RL）框架，进一步在模型中灌输实现CI所需的推理。", "result": "使用仅约700个示例的合成数据集，展示了该方法在多种模型大小和家族中显著减少了不适当的信息披露，同时保持了任务性能。这些改进从合成数据集转移到了具有人类注释的CI基准测试，如PrivacyLens。", "conclusion": "通过推理和强化学习，可以有效地在大型语言模型中实现上下文完整性，减少不适当的信息披露，同时保持任务性能，这一方法在不同模型和实际应用中均显示出良好的转移能力。"}}
{"id": "2506.04251", "title": "Language-Guided Multi-Agent Learning in Simulations: A Unified Framework and Evaluation", "authors": ["Zhengyang Li"], "abstract": "This paper introduces LLM-MARL, a unified framework that incorporates large language models (LLMs) into multi-agent reinforcement learning (MARL) to enhance coordination, communication, and generalization in simulated game environments. The framework features three modular components of Coordinator, Communicator, and Memory, which dynamically generate subgoals, facilitate symbolic inter-agent messaging, and support episodic recall. Training combines PPO with a language-conditioned loss and LLM query gating. LLM-MARL is evaluated in Google Research Football, MAgent Battle, and StarCraft II. Results show consistent improvements over MAPPO and QMIX in win rate, coordination score, and zero-shot generalization. Ablation studies demonstrate that subgoal generation and language-based messaging each contribute significantly to performance gains. Qualitative analysis reveals emergent behaviors such as role specialization and communication-driven tactics. By bridging language modeling and policy learning, this work contributes to the design of intelligent, cooperative agents in interactive simulations. It offers a path forward for leveraging LLMs in multi-agent systems used for training, games, and human-AI collaboration.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04251.pdf", "abstract_url": "https://arxiv.org/abs/2506.04251", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了LLM-MARL，一个将大型语言模型（LLMs）融入多智能体强化学习（MARL）的统一框架，旨在提升模拟游戏环境中的协调、通信和泛化能力。", "motivation": "解决多智能体在模拟环境中协调、通信和泛化能力不足的问题。", "method": "框架包含Coordinator、Communicator和Memory三个模块，结合PPO训练、语言条件损失和LLM查询门控。", "result": "在Google Research Football、MAgent Battle和StarCraft II中评估，显示在胜率、协调分数和零样本泛化上优于MAPPO和QMIX。", "conclusion": "通过桥接语言建模和政策学习，为交互式模拟中智能、协作的智能体设计提供了新方向，为多智能体系统在训练、游戏和人机协作中的应用开辟了道路。"}}
{"id": "2506.04252", "title": "A Graph-Retrieval-Augmented Generation Framework Enhances Decision-Making in the Circular Economy", "authors": ["Yang Zhao", "Chengxiao Dai", "Dusit Niyato", "Chuan Fu Tan", "Keyi Xiang", "Yueyang Wang", "Zhiquan Yeo", "Daren Tan Zong Loong", "Jonathan Low Zhaozhi", "Eugene H.Z. HO"], "abstract": "Large language models (LLMs) hold promise for sustainable manufacturing, but often hallucinate industrial codes and emission factors, undermining regulatory and investment decisions. We introduce CircuGraphRAG, a retrieval-augmented generation (RAG) framework that grounds LLMs outputs in a domain-specific knowledge graph for the circular economy. This graph connects 117,380 industrial and waste entities with classification codes and GWP100 emission data, enabling structured multi-hop reasoning. Natural language queries are translated into SPARQL and verified subgraphs are retrieved to ensure accuracy and traceability. Compared with Standalone LLMs and Naive RAG, CircuGraphRAG achieves superior performance in single-hop and multi-hop question answering, with ROUGE-L F1 scores up to 1.0, while baseline scores below 0.08. It also improves efficiency, halving the response time and reducing token usage by 16% in representative tasks. CircuGraphRAG provides fact-checked, regulatory-ready support for circular economy planning, advancing reliable, low-carbon resource decision making.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04252.pdf", "abstract_url": "https://arxiv.org/abs/2506.04252", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了CircuGraphRAG，一个基于检索增强生成（RAG）的框架，旨在通过领域特定知识图谱增强大型语言模型（LLMs）在循环经济决策中的准确性和可靠性。", "motivation": "大型语言模型在可持续制造领域有应用潜力，但常产生关于工业代码和排放因子的错误信息，影响监管和投资决策。", "method": "CircuGraphRAG框架将LLMs输出与循环经济领域的知识图谱相结合，该图谱包含117,380个工业和废物实体，分类代码和GWP100排放数据，支持结构化多跳推理。自然语言查询被转换为SPARQL，并检索验证子图以确保准确性和可追溯性。", "result": "与独立LLMs和朴素RAG相比，CircuGraphRAG在单跳和多跳问答中表现更优，ROUGE-L F1分数高达1.0，而基线分数低于0.08。同时，它提高了效率，响应时间减半，代表性任务中令牌使用减少16%。", "conclusion": "CircuGraphRAG为循环经济规划提供了经过事实核查、符合监管要求的支持，推动了可靠、低碳资源决策的进步。"}}
{"id": "2506.04253", "title": "HADA: Human-AI Agent Decision Alignment Architecture", "authors": ["Tapio Pitkäranta", "Leena Pitkäranta"], "abstract": "We present HADA (Human-AI Agent Decision Alignment), a protocol- and framework agnostic reference architecture that keeps both large language model (LLM) agents and legacy algorithms aligned with organizational targets and values. HADA wraps any algorithm or LLM in role-specific stakeholder agents -- business, data-science, audit, ethics, and customer -- each exposing conversational APIs so that technical and non-technical actors can query, steer, audit, or contest every decision across strategic, tactical, and real-time horizons. Alignment objectives, KPIs, and value constraints are expressed in natural language and are continuously propagated, logged, and versioned while thousands of heterogeneous agents run on different orchestration stacks. A cloud-native proof of concept packages a production credit-scoring model (getLoanDecision) and deploys it on Docker/Kubernetes/Python; five scripted retail-bank scenarios show how target changes, parameter tweaks, explanation requests, and ethics triggers flow end to end through the architecture. Evaluation followed the Design-Science Research Methodology. Walkthrough observation and log inspection demonstrated complete coverage of six predefined objectives: every role could invoke conversational control, trace KPIs and value constraints, detect and mitigate ZIP-code bias, and reproduce full decision lineage, independent of the underlying LLM or agent library. Contributions: (1) an open-source HADA architecture, (2) a mid-range design theory for human-AI alignment in multi-agent systems, and (3) empirical evidence that framework-agnostic, protocol-compliant stakeholder agents improve accuracy, transparency, and ethical compliance in real-world decision pipelines.", "subjects": "Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)", "comments": "18 pages, 4 figures", "pdf_url": "https://arxiv.org/pdf/2506.04253.pdf", "abstract_url": "https://arxiv.org/abs/2506.04253", "categories": ["Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "HADA是一种协议和框架无关的参考架构，旨在使大型语言模型（LLM）代理和传统算法与组织目标和价值观保持一致。它通过角色特定的利益相关者代理（如业务、数据科学、审计、伦理和客户）包装任何算法或LLM，每个代理都暴露对话式API，以便技术和非技术参与者可以查询、指导、审计或质疑每个决策。", "motivation": "解决在多种代理运行于不同编排栈上时，保持LLM代理和传统算法与组织目标和价值观对齐的问题。", "method": "采用角色特定的利益相关者代理，每个代理提供对话式API，允许对决策进行查询、指导、审计或质疑。目标和约束以自然语言表达，并持续传播、记录和版本化。", "result": "通过五个零售银行脚本场景的云原生概念验证，展示了HADA架构如何实现目标变更、参数调整、解释请求和伦理触发的端到端流动。评估显示，HADA完全覆盖了六个预定义目标。", "conclusion": "HADA架构提高了现实世界决策流程的准确性、透明度和伦理合规性，为多代理系统中的人-AI对齐提供了中程设计理论和实证证据。"}}
{"id": "2506.04287", "title": "Automated Skill Discovery for Language Agents through Exploration and Iterative Feedback", "authors": ["Yongjin Yang", "Sinjae Kang", "Juyong Lee", "Dongjun Lee", "Se-Young Yun", "Kimin Lee"], "abstract": "Training large language model (LLM) agents to acquire necessary skills and perform diverse tasks within an environment is gaining interest as a means to enable open-endedness. However, creating the training dataset for their skill acquisition faces several challenges. Manual trajectory collection requires significant human effort. Another approach, where LLMs directly propose tasks to learn, is often invalid, as the LLMs lack knowledge of which tasks are actually feasible. Moreover, the generated data may not provide a meaningful learning signal, as agents often already perform well on the proposed tasks. To address this, we propose a novel automatic skill discovery framework EXIF for LLM-powered agents, designed to improve the feasibility of generated target behaviors while accounting for the agents' capabilities. Our method adopts an exploration-first strategy by employing an exploration agent (Alice) to train the target agent (Bob) to learn essential skills in the environment. Specifically, Alice first interacts with the environment to retrospectively generate a feasible, environment-grounded skill dataset, which is then used to train Bob. Crucially, we incorporate an iterative feedback loop, where Alice evaluates Bob's performance to identify areas for improvement. This feedback then guides Alice's next round of exploration, forming a closed-loop data generation process. Experiments on Webshop and Crafter demonstrate EXIF's ability to effectively discover meaningful skills and iteratively expand the capabilities of the trained agent without any human intervention, achieving substantial performance improvements. Interestingly, we observe that setting Alice to the same model as Bob also notably improves performance, demonstrating EXIF's potential for building a self-evolving system.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "Preprint, under review", "pdf_url": "https://arxiv.org/pdf/2506.04287.pdf", "abstract_url": "https://arxiv.org/abs/2506.04287", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为EXIF的自动技能发现框架，旨在通过探索和迭代反馈来训练大型语言模型（LLM）代理，以在环境中学习必要技能并执行多样任务，无需人工干预。", "motivation": "训练LLM代理以获取必要技能并在环境中执行多样任务是实现开放性的一个手段，但创建训练数据集面临挑战，如人工轨迹收集需要大量努力，LLM直接提出的任务可能不可行，且生成的数据可能不提供有意义的学习信号。", "method": "EXIF框架采用探索优先策略，通过探索代理（Alice）训练目标代理（Bob）学习环境中的基本技能。Alice首先与环境互动，回顾性生成可行的、基于环境的技能数据集，然后用于训练Bob。关键是通过迭代反馈循环，Alice评估Bob的表现以识别改进领域，反馈指导Alice的下一轮探索，形成闭环数据生成过程。", "result": "在Webshop和Crafter上的实验表明，EXIF能够有效发现有意义技能并迭代扩展训练代理的能力，无需人工干预，实现了显著的性能提升。有趣的是，将Alice设置为与Bob相同的模型也显著提高了性能，展示了EXIF构建自进化系统的潜力。", "conclusion": "EXIF框架通过探索和迭代反馈自动发现技能，有效提升了LLM代理的能力，展示了在没有人工干预的情况下实现自进化的潜力。"}}
{"id": "2506.04481", "title": "CogMath: Assessing LLMs' Authentic Mathematical Ability from a Human Cognitive Perspective", "authors": ["Jiayu Liu", "Zhenya Huang", "Wei Dai", "Cheng Cheng", "Jinze Wu", "Jing Sha", "Song Li", "Qi Liu", "Shijin Wang", "Enhong Chen"], "abstract": "Although large language models (LLMs) show promise in solving complex mathematical tasks, existing evaluation paradigms rely solely on a coarse measure of overall answer accuracy, which are insufficient for assessing their authentic capabilities. In this paper, we propose \\textbf{CogMath}, which comprehensively assesses LLMs' mathematical abilities through the lens of human cognition. Specifically, inspired by psychological theories, CogMath formalizes human reasoning process into 3 stages: \\emph{problem comprehension}, \\emph{problem solving}, and \\emph{solution summarization}. Within these stages, we investigate perspectives such as numerical calculation, knowledge, and counterfactuals, and design a total of 9 fine-grained evaluation dimensions. In each dimension, we develop an ``\\emph{Inquiry}-\\emph{Judge}-\\emph{Reference}'' multi-agent system to generate inquiries that assess LLMs' mastery from this dimension. An LLM is considered to truly master a problem only when excelling in all inquiries from the 9 dimensions. By applying CogMath on three benchmarks, we reveal that the mathematical capabilities of 7 mainstream LLMs are overestimated by 30\\%-40\\%. Moreover, we locate their strengths and weaknesses across specific stages/dimensions, offering in-depth insights to further enhance their reasoning abilities.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04481.pdf", "abstract_url": "https://arxiv.org/abs/2506.04481", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出CogMath，从人类认知角度全面评估大型语言模型（LLMs）的数学能力，揭示主流LLMs的能力被高估30%-40%，并定位其在不同阶段/维度的强弱项。", "motivation": "现有评估范式仅依赖整体答案准确性的粗略测量，不足以评估LLMs的真实数学能力。", "method": "受心理学理论启发，CogMath将人类推理过程形式化为3个阶段：问题理解、问题解决和解决方案总结，并在这些阶段中设计了9个细粒度评估维度，开发了一个多智能体系统来生成评估LLMs的查询。", "result": "应用CogMath于三个基准测试，发现7个主流LLMs的数学能力被高估了30%-40%，并确定了它们在特定阶段/维度的优势和劣势。", "conclusion": "CogMath提供了深入见解，有助于进一步提升LLMs的推理能力。"}}
{"id": "2506.04571", "title": "OpenAg: Democratizing Agricultural Intelligence", "authors": ["Srikanth Thudumu", "Jason Fisher"], "abstract": "Agriculture is undergoing a major transformation driven by artificial intelligence (AI), machine learning, and knowledge representation technologies. However, current agricultural intelligence systems often lack contextual understanding, explainability, and adaptability, especially for smallholder farmers with limited resources. General-purpose large language models (LLMs), while powerful, typically lack the domain-specific knowledge and contextual reasoning needed for practical decision support in farming. They tend to produce recommendations that are too generic or unrealistic for real-world applications. To address these challenges, we present OpenAg, a comprehensive framework designed to advance agricultural artificial general intelligence (AGI). OpenAg combines domain-specific foundation models, neural knowledge graphs, multi-agent reasoning, causal explainability, and adaptive transfer learning to deliver context-aware, explainable, and actionable insights. The system includes: (i) a unified agricultural knowledge base that integrates scientific literature, sensor data, and farmer-generated knowledge; (ii) a neural agricultural knowledge graph for structured reasoning and inference; (iii) an adaptive multi-agent reasoning system where AI agents specialize and collaborate across agricultural domains; and (iv) a causal transparency mechanism that ensures AI recommendations are interpretable, scientifically grounded, and aligned with real-world constraints. OpenAg aims to bridge the gap between scientific knowledge and the tacit expertise of experienced farmers to support scalable and locally relevant agricultural decision-making.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "10 pages, 1 figure", "pdf_url": "https://arxiv.org/pdf/2506.04571.pdf", "abstract_url": "https://arxiv.org/abs/2506.04571", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "OpenAg是一个旨在推动农业人工智能（AGI）发展的综合框架，通过结合领域特定的基础模型、神经知识图谱、多智能体推理等技术，为农业决策提供上下文感知、可解释且可操作的见解。", "motivation": "当前农业智能系统在上下文理解、可解释性和适应性方面存在不足，特别是对于资源有限的小农户。通用的大型语言模型（LLMs）缺乏领域特定知识和上下文推理能力，难以提供实用的农业决策支持。", "method": "OpenAg框架包括：统一的农业知识库、神经农业知识图谱、自适应多智能体推理系统以及因果透明机制，旨在整合科学文献、传感器数据和农民生成的知识，支持结构化的推理和推断。", "result": "OpenAg通过其综合方法，能够提供更加精准、可解释且符合实际约束的农业推荐，有助于弥合科学知识与农民经验之间的差距。", "conclusion": "OpenAg框架为农业决策提供了一个可扩展且本地化的解决方案，有望推动农业人工智能的发展，特别是对小农户而言，能够提供更加个性化和实用的支持。"}}
{"id": "2506.04572", "title": "Demonstrations of Integrity Attacks in Multi-Agent Systems", "authors": ["Can Zheng", "Yuhan Cao", "Xiaoning Dong", "Tianxing He"], "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in natural language understanding, code generation, and complex planning. Simultaneously, Multi-Agent Systems (MAS) have garnered attention for their potential to enable cooperation among distributed agents. However, from a multi-party perspective, MAS could be vulnerable to malicious agents that exploit the system to serve self-interests without disrupting its core functionality. This work explores integrity attacks where malicious agents employ subtle prompt manipulation to bias MAS operations and gain various benefits. Four types of attacks are examined: \\textit{Scapegoater}, who misleads the system monitor to underestimate other agents' contributions; \\textit{Boaster}, who misleads the system monitor to overestimate their own performance; \\textit{Self-Dealer}, who manipulates other agents to adopt certain tools; and \\textit{Free-Rider}, who hands off its own task to others. We demonstrate that strategically crafted prompts can introduce systematic biases in MAS behavior and executable instructions, enabling malicious agents to effectively mislead evaluation systems and manipulate collaborative agents. Furthermore, our attacks can bypass advanced LLM-based monitors, such as GPT-4o-mini and o3-mini, highlighting the limitations of current detection mechanisms. Our findings underscore the critical need for MAS architectures with robust security protocols and content validation mechanisms, alongside monitoring systems capable of comprehensive risk scenario assessment.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04572.pdf", "abstract_url": "https://arxiv.org/abs/2506.04572", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了多智能体系统（MAS）中恶意代理通过微妙提示操纵实施的完整性攻击，展示了四种攻击类型及其对系统的影响，强调了现有检测机制的局限性及加强安全协议的必要性。", "motivation": "研究多智能体系统（MAS）在面对恶意代理时的脆弱性，特别是这些代理如何利用系统漏洞服务于自身利益而不破坏其核心功能。", "method": "通过设计和实施四种具体的攻击类型（Scapegoater、Boaster、Self-Dealer、Free-Rider），展示恶意代理如何通过精心设计的提示操纵MAS行为。", "result": "研究表明，精心设计的提示可以系统地偏置MAS行为和可执行指令，使恶意代理能够有效误导评估系统和操纵协作代理，且这些攻击能够绕过基于先进LLM的监控系统。", "conclusion": "研究结果强调了开发具有强大安全协议和内容验证机制的MAS架构的必要性，以及需要能够进行全面风险评估的监控系统。"}}
{"id": "2506.04616", "title": "Subjective Perspectives within Learned Representations Predict High-Impact Innovation", "authors": ["Likun Cao", "Rui Pan", "James Evans"], "abstract": "Existing studies of innovation emphasize the power of social structures to shape innovation capacity. Emerging machine learning approaches, however, enable us to model innovators' personal perspectives and interpersonal innovation opportunities as a function of their prior trajectories of experience. We theorize then quantify subjective perspectives and innovation opportunities based on innovator positions within the geometric space of concepts inscribed by dynamic language representations. Using data on millions of scientists, inventors, writers, entrepreneurs, and Wikipedia contributors across the creative domains of science, technology, film, entrepreneurship, and Wikipedia, here we show that measured subjective perspectives anticipate what ideas individuals and groups creatively attend to and successfully combine in future. When perspective and background diversity are decomposed as the angular difference between collaborators' perspectives on their creation and between their experiences, the former consistently anticipates creative achievement while the latter portends its opposite, across all cases and time periods examined. We analyze a natural experiment and simulate creative collaborations between AI (large language model) agents designed with various perspective and background diversity, which are consistent with our observational findings. We explore mechanisms underlying these findings and identify how successful collaborators leverage common language to weave together diverse experience obtained through trajectories of prior work that converge to provoke one another and innovate. We explore the importance of these findings for team assembly and research policy.", "subjects": "Computation and Language (cs.CL); Applications (stat.AP); Machine Learning (stat.ML)", "comments": "107 pages, 20 figures", "pdf_url": "https://arxiv.org/pdf/2506.04616.pdf", "abstract_url": "https://arxiv.org/abs/2506.04616", "categories": ["Computation and Language (cs.CL)", "Applications (stat.AP)", "Machine Learning (stat.ML)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过机器学习方法，量化创新者的主观视角和人际创新机会，证明主观视角能预测未来创新成果。研究发现，视角多样性促进创新，而背景多样性则相反。", "motivation": "解决现有创新研究过于依赖社会结构而忽视个人视角对创新能力影响的问题。", "method": "使用动态语言表示的几何空间模型，量化创新者的主观视角和背景多样性，分析其对创新成果的影响。", "result": "主观视角多样性正向预测创新成果，背景多样性则负向预测。通过自然实验和AI代理模拟验证了这一发现。", "conclusion": "研究强调了在团队组建和研究政策中重视视角多样性的重要性，以及共同语言在整合多样化经验中的关键作用。"}}
{"id": "2506.04636", "title": "CHANCERY: Evaluating corporate governance reasoning capabilities in language models", "authors": ["Lucas Irwin", "Arda Kaz", "Peiyao Sheng", "Pramod Viswanath"], "abstract": "Law has long been a domain that has been popular in natural language processing (NLP) applications. Reasoning (ratiocination and the ability to make connections to precedent) is a core part of the practice of the law in the real world. Nevertheless, while multiple legal datasets exist, none have thus far focused specifically on reasoning tasks. We focus on a specific aspect of the legal landscape by introducing a corporate governance reasoning benchmark (CHANCERY) to test a model's ability to reason about whether executive/board/shareholder's proposed actions are consistent with corporate governance charters. This benchmark introduces a first-of-its-kind corporate governance reasoning test for language models - modeled after real world corporate governance law. The benchmark consists of a corporate charter (a set of governing covenants) and a proposal for executive action. The model's task is one of binary classification: reason about whether the action is consistent with the rules contained within the charter. We create the benchmark following established principles of corporate governance - 24 concrete corporate governance principles established in and 79 real life corporate charters selected to represent diverse industries from a total dataset of 10k real life corporate charters. Evaluations on state-of-the-art (SOTA) reasoning models confirm the difficulty of the benchmark, with models such as Claude 3.7 Sonnet and GPT-4o achieving 64.5% and 75.2% accuracy respectively. Reasoning agents exhibit superior performance, with agents based on the ReAct and CodeAct frameworks scoring 76.1% and 78.1% respectively, further confirming the advanced legal reasoning capabilities required to score highly on the benchmark. We also conduct an analysis of the types of questions which current reasoning models struggle on, revealing insights into the legal reasoning capabilities of SOTA models.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04636.pdf", "abstract_url": "https://arxiv.org/abs/2506.04636", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了CHANCERY，一个专门用于评估语言模型在公司治理推理能力上的基准测试，该测试基于真实世界的公司治理法律，要求模型判断执行/董事会/股东提出的行动是否符合公司治理章程。", "motivation": "解决现有法律数据集中缺乏专注于推理任务的问题，特别是在公司治理领域的法律推理能力评估。", "method": "引入了一个公司治理推理基准（CHANCERY），包括一个公司章程和一项执行行动提案，模型的任务是进行二元分类，判断行动是否符合章程中的规则。", "result": "最先进的推理模型在该基准上的表现证实了其难度，Claude 3.7 Sonnet和GPT-4o的准确率分别为64.5%和75.2%，而基于ReAct和CodeAct框架的推理代理分别达到了76.1%和78.1%的准确率。", "conclusion": "CHANCERY基准测试揭示了当前推理模型在法律推理能力上的局限性，并为评估和提升语言模型在公司治理领域的推理能力提供了新的方向。"}}
{"id": "2506.04654", "title": "E-bike agents: Large Language Model-Driven E-Bike Accident Analysis and Severity Prediction", "authors": ["Zhichao Yang", "Jiashu He", "Mohammad B. Al-Khasawneh", "Darshan Pandit", "Cirillo Cinzia"], "abstract": "Electric bicycles (e-bikes) are rapidly increasing in use, raising safety concerns due to a rise in accident reports. However, e-bike incident reports often use unstructured narrative formats, which hinders quantitative safety analysis. This study introduces E-bike agents, a framework that uses large language models (LLM) powered agents to classify and extract safety variables from unstructured incident reports. Our framework consists of four LLM agents, handling data classification, information extraction, injury cause determination, and component linkage, to extract the key factors that could lead to E-bike accidents and cause varying severity levels. Furthermore, we used an ordered logit model to examine the relationship between the severity of the incident and the factors retrieved, such as gender, the type of cause, and environmental conditions. Our research shows that equipment issues are slightly more common than human-related ones, but human-related incidents are more often fatal. Specifically, pedals, tires, and brakes are frequent contributors to accidents. The model achieves a high weighted F1 score of 0.87 in classification accuracy, highlighting the potential of using LLMs to extract unstructured data in niche domains, such as transportation. Our method offers a scalable solution to improve e-bike safety analytics and provides actionable information for policy makers, designers, and regulators.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04654.pdf", "abstract_url": "https://arxiv.org/abs/2506.04654", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "该研究引入了E-bike agents框架，利用大型语言模型（LLM）驱动的代理从非结构化事故报告中分类和提取安全变量，以分析电动自行车（e-bike）事故的严重性及其影响因素。", "motivation": "电动自行车使用的迅速增加带来了安全问题，但由于事故报告多为非结构化叙述形式，阻碍了定量安全分析的进行。", "method": "研究采用了四个LLM代理处理数据分类、信息提取、伤害原因确定和组件关联，以及有序logit模型来检查事故严重性与提取因素（如性别、原因类型和环境条件）之间的关系。", "result": "设备问题比人为问题稍常见，但人为相关的事故更常致命；踏板、轮胎和刹车是事故的常见因素。模型在分类准确度上达到了0.87的加权F1分数。", "conclusion": "该方法为改善电动自行车安全分析提供了可扩展的解决方案，并为政策制定者、设计师和监管者提供了可操作的信息，展示了LLM在交通等特定领域提取非结构化数据的潜力。"}}
{"id": "2506.04651", "title": "Agents of Change: Self-Evolving LLM Agents for Strategic Planning", "authors": ["Nikolas Belle", "Dakota Barnes", "Alfonso Amayuelas", "Ivan Bercovich", "Xin Eric Wang", "William Wang"], "abstract": "Recent advances in LLMs have enabled their use as autonomous agents across a range of tasks, yet they continue to struggle with formulating and adhering to coherent long-term strategies. In this paper, we investigate whether LLM agents can self-improve when placed in environments that explicitly challenge their strategic planning abilities. Using the board game Settlers of Catan, accessed through the open-source Catanatron framework, we benchmark a progression of LLM-based agents, from a simple game-playing agent to systems capable of autonomously rewriting their own prompts and their player agent's code. We introduce a multi-agent architecture in which specialized roles (Analyzer, Researcher, Coder, and Player) collaborate to iteratively analyze gameplay, research new strategies, and modify the agent's logic or prompt. By comparing manually crafted agents to those evolved entirely by LLMs, we evaluate how effectively these systems can diagnose failure and adapt over time. Our results show that self-evolving agents, particularly when powered by models like Claude 3.7 and GPT-4o, outperform static baselines by autonomously adopting their strategies, passing along sample behavior to game-playing agents, and demonstrating adaptive reasoning over multiple iterations.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04651.pdf", "abstract_url": "https://arxiv.org/abs/2506.04651", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了大型语言模型（LLM）作为自主代理在战略规划任务中的自我进化能力，特别是在《卡坦岛》棋盘游戏中的表现。通过引入多代理架构，研究展示了自我进化代理如何通过分析、研究、编码和游戏角色的协作，超越静态基线。", "motivation": "解决LLM代理在制定和遵循长期战略方面的困难，探索其在挑战性环境中自我改进的潜力。", "method": "使用《卡坦岛》游戏和Catanatron框架，比较从简单游戏代理到能够自主重写提示和代码的系统的LLM代理。引入多代理架构，包括分析器、研究员、编码器和玩家角色，以迭代方式改进代理的逻辑或提示。", "result": "自我进化代理，尤其是由Claude 3.7和GPT-4o驱动的代理，在自主采用策略、传递样本行为给游戏代理以及在多次迭代中展示适应性推理方面，表现优于静态基线。", "conclusion": "研究表明，通过特定的多代理架构和迭代改进过程，LLM代理能够在战略规划任务中实现自我进化，从而提高其性能和适应性。"}}
{"id": "2506.04699", "title": "Empowering Economic Simulation for Massively Multiplayer Online Games through Generative Agent-Based Modeling", "authors": ["Bihan Xu", "Shiwei Zhao", "Runze Wu", "Zhenya Huang", "Jiawei Wang", "Zhipeng Hu", "Kai Wang", "Haoyu Liu", "Tangjie Lv", "Le Li", "Changjie Fan", "Xin Tong", "Jiangze Han"], "abstract": "Within the domain of Massively Multiplayer Online (MMO) economy research, Agent-Based Modeling (ABM) has emerged as a robust tool for analyzing game economics, evolving from rule-based agents to decision-making agents enhanced by reinforcement learning. Nevertheless, existing works encounter significant challenges when attempting to emulate human-like economic activities among agents, particularly regarding agent reliability, sociability, and interpretability. In this study, we take a preliminary step in introducing a novel approach using Large Language Models (LLMs) in MMO economy simulation. Leveraging LLMs' role-playing proficiency, generative capacity, and reasoning aptitude, we design LLM-driven agents with human-like decision-making and adaptability. These agents are equipped with the abilities of role-playing, perception, memory, and reasoning, addressing the aforementioned challenges effectively. Simulation experiments focusing on in-game economic activities demonstrate that LLM-empowered agents can promote emergent phenomena like role specialization and price fluctuations in line with market rules.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "KDD2025 Accepted", "pdf_url": "https://arxiv.org/pdf/2506.04699.pdf", "abstract_url": "https://arxiv.org/abs/2506.04699", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种使用大型语言模型（LLMs）在大型多人在线（MMO）游戏经济模拟中的新方法，通过LLM驱动的代理模拟人类经济行为，解决了代理可靠性、社交性和可解释性等挑战。", "motivation": "解决现有代理基于模型（ABM）在模拟MMO游戏经济中人类经济活动时遇到的代理可靠性、社交性和可解释性挑战。", "method": "利用大型语言模型（LLMs）的角色扮演能力、生成能力和推理能力，设计具有人类决策和适应性的LLM驱动代理。", "result": "模拟实验表明，LLM驱动的代理能够促进角色专业化和价格波动等与市场规则一致的新兴现象。", "conclusion": "LLM驱动的代理在MMO经济模拟中表现出色，能够有效模拟人类经济行为，为游戏经济研究提供了新的视角和方法。"}}
{"id": "2506.04849", "title": "Towards a Multi-Agent Simulation of Cyber-attackers and Cyber-defenders Battles", "authors": ["Julien Soulé", "Jean-Paul Jamont", "Michel Occello", "Paul Théron", "Louis-Marie Traonouez"], "abstract": "As cyber-attacks show to be more and more complex and coordinated, cyber-defenders strategy through multi-agent approaches could be key to tackle against cyber-attacks as close as entry points in a networked system. This paper presents a Markovian modeling and implementation through a simulator of fighting cyber-attacker agents and cyber-defender agents deployed on host network nodes. It aims to provide an experimental framework to implement realistically based coordinated cyber-attack scenarios while assessing cyber-defenders dynamic organizations. We abstracted network nodes by sets of properties including agents' ones. Actions applied by agents model how the network reacts depending in a given state and what properties are to change. Collective choice of the actions brings the whole environment closer or farther from respective cyber-attackers and cyber-defenders goals. Using the simulator, we implemented a realistically inspired scenario with several behavior implementation approaches for cyber-defenders and cyber-attackers.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04849.pdf", "abstract_url": "https://arxiv.org/abs/2506.04849", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于多代理的马尔可夫模型和模拟器，用于模拟网络攻击者和防御者之间的战斗，旨在通过实验框架评估防御者的动态组织能力。", "motivation": "随着网络攻击变得越来越复杂和协调，通过多代理方法制定网络防御策略可能是关键，以尽可能接近网络系统中的入口点来应对网络攻击。", "method": "使用马尔可夫模型和模拟器，模拟网络节点上的攻击者和防御者代理的战斗，抽象网络节点为一组属性，包括代理的属性，模拟代理在不同状态下对网络的影响。", "result": "通过模拟器实现了一个现实启发的场景，展示了不同行为实现方法对网络攻击者和防御者目标的影响。", "conclusion": "该模拟器为实施基于现实的协调网络攻击场景提供了实验框架，同时评估了网络防御者的动态组织能力，为网络安全领域提供了新的研究工具。"}}
{"id": "2506.04828", "title": "Safe Planning and Policy Optimization via World Model Learning", "authors": ["Artem Latyshev", "Gregory Gorbov", "Aleksandr I. Panov"], "abstract": "Reinforcement Learning (RL) applications in real-world scenarios must prioritize safety and reliability, which impose strict constraints on agent behavior. Model-based RL leverages predictive world models for action planning and policy optimization, but inherent model inaccuracies can lead to catastrophic failures in safety-critical settings. We propose a novel model-based RL framework that jointly optimizes task performance and safety. To address world model errors, our method incorporates an adaptive mechanism that dynamically switches between model-based planning and direct policy execution. We resolve the objective mismatch problem of traditional model-based approaches using an implicit world model. Furthermore, our framework employs dynamic safety thresholds that adapt to the agent's evolving capabilities, consistently selecting actions that surpass safe policy suggestions in both performance and safety. Experiments demonstrate significant improvements over non-adaptive methods, showing that our approach optimizes safety and performance simultaneously rather than merely meeting minimum safety requirements. The proposed framework achieves robust performance on diverse safety-critical continuous control tasks, outperforming existing methods.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04828.pdf", "abstract_url": "https://arxiv.org/abs/2506.04828", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新颖的基于模型的强化学习框架，旨在同时优化任务性能和安全性。通过自适应机制动态切换基于模型的规划和直接策略执行，解决传统方法中的目标不匹配问题，并采用动态安全阈值以适应代理的进化能力。实验表明，该方法在安全关键连续控制任务上优于现有方法。", "motivation": "在现实世界的强化学习应用中，安全性和可靠性是首要考虑的因素，这要求代理行为必须严格遵守安全约束。基于模型的强化学习虽然利用预测世界模型进行行动规划和策略优化，但模型固有的不准确性可能导致安全关键设置中的灾难性失败。", "method": "提出的框架通过自适应机制动态切换基于模型的规划和直接策略执行，使用隐式世界模型解决传统方法的目标不匹配问题，并采用动态安全阈值以适应代理的进化能力。", "result": "实验结果显示，该方法在安全关键连续控制任务上显著优于非自适应方法，能够同时优化安全性和性能，而不仅仅是满足最低安全要求。", "conclusion": "本文提出的框架在多样化的安全关键连续控制任务上实现了鲁棒的性能，优于现有方法，为强化学习在现实世界应用中的安全性和性能优化提供了有效的解决方案。"}}
{"id": "2506.04867", "title": "LLMs for sensory-motor control: Combining in-context and iterative learning", "authors": ["Jônata Tyska Carvalho", "Stefano Nolfi"], "abstract": "We propose a method that enables large language models (LLMs) to control embodied agents by directly mapping continuous observation vectors to continuous action vectors. Initially, the LLMs generate a control strategy based on a textual description of the agent, its environment, and the intended goal. This strategy is then iteratively refined through a learning process in which the LLMs are repeatedly prompted to improve the current strategy, using performance feedback and sensory-motor data collected during its evaluation. The method is validated on classic control tasks from the Gymnasium library and the inverted pendulum task from the MuJoCo library. In most cases, it successfully identifies optimal or high-performing solutions by integrating symbolic knowledge derived through reasoning with sub-symbolic sensory-motor data gathered as the agent interacts with its environment.", "subjects": "Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG); Robotics (cs.RO)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2506.04867.pdf", "abstract_url": "https://arxiv.org/abs/2506.04867", "categories": ["Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)", "Machine Learning (cs.LG)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种方法，使大型语言模型（LLMs）能够通过直接将连续观察向量映射到连续动作向量来控制具体代理。该方法通过迭代学习过程优化控制策略，结合了符号知识和子符号感知运动数据。", "motivation": "解决大型语言模型在控制具体代理时，如何有效地将观察转换为动作的问题。", "method": "首先生成基于文本描述的控制策略，然后通过迭代学习和性能反馈来优化策略。", "result": "在Gymnasium和MuJoCo库的经典控制任务中，该方法成功找到了最优或高性能的解决方案。", "conclusion": "通过结合符号推理和子符号感知运动数据，大型语言模型能够有效地控制具体代理。"}}
{"id": "2506.04649", "title": "Flex-TravelPlanner: A Benchmark for Flexible Planning with Language Agents", "authors": ["Juhyun Oh", "Eunsu Kim", "Alice Oh"], "abstract": "Real-world planning problems require constant adaptation to changing requirements and balancing of competing constraints. However, current benchmarks for evaluating LLMs' planning capabilities primarily focus on static, single-turn scenarios. We introduce Flex-TravelPlanner, a benchmark that evaluates language models' ability to reason flexibly in dynamic planning scenarios. Building on the TravelPlanner dataset~\\citep{xie2024travelplanner}, we introduce two novel evaluation settings: (1) sequential constraint introduction across multiple turns, and (2) scenarios with explicitly prioritized competing constraints. Our analysis of GPT-4o and Llama 3.1 70B reveals several key findings: models' performance on single-turn tasks poorly predicts their ability to adapt plans across multiple turns; constraint introduction order significantly affects performance; and models struggle with constraint prioritization, often incorrectly favoring newly introduced lower priority preferences over existing higher-priority constraints. These findings highlight the importance of evaluating LLMs in more realistic, dynamic planning scenarios and suggest specific directions for improving model performance on complex planning tasks. The code and dataset for our framework are publicly available at", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04649.pdf", "abstract_url": "https://arxiv.org/abs/2506.04649", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了Flex-TravelPlanner基准测试，用于评估语言模型在动态规划场景中的灵活推理能力，揭示了现有模型在多轮适应和约束优先级处理上的不足。", "motivation": "解决现有基准测试主要关注静态、单轮场景，无法全面评估语言模型在动态规划问题中的适应能力和约束平衡能力的问题。", "method": "基于TravelPlanner数据集，引入了两种新的评估设置：跨多轮的顺序约束引入和明确优先级的竞争约束场景，分析了GPT-4o和Llama 3.1 70B的表现。", "result": "发现模型在单轮任务上的表现不能很好地预测其多轮适应能力；约束引入顺序显著影响性能；模型在处理约束优先级时存在困难，常常错误地偏好新引入的低优先级约束。", "conclusion": "强调了在更真实的动态规划场景中评估语言模型的重要性，并提出了改进模型在复杂规划任务上性能的具体方向。"}}
{"id": "2506.04625", "title": "Advancing Tool-Augmented Large Language Models via Meta-Verification and Reflection Learning", "authors": ["Zhiyuan Ma", "Jiayu Liu", "Xianzhen Luo", "Zhenya Huang", "Qingfu Zhu", "Wanxiang Che"], "abstract": "Empowering large language models (LLMs) with effective tool utilization capabilities is crucial for enabling AI agents to solve complex problems. However, current models face two major limitations: (1) unreliable tool planning and invocation due to low-quality instruction datasets (e.g., widespread hallucinated API calls), and (2) weak tool reflection abilities (over 90% of errors cannot be corrected) resulting from static imitation learning. To address these critical limitations, we propose Tool-MVR, a novel Tool-Augmented LLM that achieves comprehensive System 2 reasoning through two key innovations. Specifically, we first introduce Multi-Agent Meta-Verification (MAMV), a systematic pipeline that rigorously validates APIs, queries, and reasoning trajectories to construct ToolBench-V, a new high-quality instruction dataset that addresses the limitation of unreliable tool planning and invocation. Second, we propose Exploration-based Reflection Learning (EXPLORE), which enhances tool reflection capabilities by leveraging tool feedback through a dynamic \"Error -> Reflection -> Correction\" learning paradigm, resulting in our reflection dataset ToolBench-R and addressing the critical weakness in tool reflection. Finally, we obtain Tool-MVR by finetuning open-source LLMs (e.g., Qwen-7B) on both ToolBench-V and ToolBench-R. Our experiments demonstrate that Tool-MVR achieves state-of-the-art performance on StableToolBench, surpassing both ToolLLM (by 23.9%) and GPT-4 (by 15.3%) while reducing API calls by 31.4%, with strong generalization capabilities across unseen tools and scenarios. Additionally, on our proposed RefineToolBench, the first benchmark specifically designed to evaluate tool reflection capabilities, Tool-MVR achieves a 58.9% error correction rate, significantly outperforming ToolLLM's 9.1%.", "subjects": "Computation and Language (cs.CL)", "comments": "Accepted at the Research Track of KDD 2025", "pdf_url": "https://arxiv.org/pdf/2506.04625.pdf", "abstract_url": "https://arxiv.org/abs/2506.04625", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了Tool-MVR，一种通过元验证和反思学习增强的大型语言模型，旨在解决工具利用中的不可靠规划和弱反思能力问题。通过创新的多代理元验证和基于探索的反思学习，Tool-MVR在工具使用和错误纠正方面实现了显著进步。", "motivation": "大型语言模型在工具利用方面存在两个主要限制：不可靠的工具规划和调用，以及弱的工具反思能力。这些问题限制了AI代理解决复杂问题的能力。", "method": "提出了Tool-MVR，通过多代理元验证（MAMV）构建高质量指令数据集ToolBench-V，以及通过基于探索的反思学习（EXPLORE）增强工具反思能力，创建反思数据集ToolBench-R。", "result": "Tool-MVR在StableToolBench上实现了最先进的性能，超过了ToolLLM和GPT-4，同时在RefineToolBench上实现了58.9%的错误纠正率，显著优于ToolLLM的9.1%。", "conclusion": "Tool-MVR通过创新的方法显著提高了大型语言模型在工具利用和错误纠正方面的能力，为AI代理解决复杂问题提供了新的可能性。"}}
{"id": "2506.05109", "title": "Truly Self-Improving Agents Require Intrinsic Metacognitive Learning", "authors": ["Tennison Liu", "Mihaela van der Schaar"], "abstract": "Self-improving agents aim to continuously acquire new capabilities with minimal supervision. However, current approaches face two key limitations: their self-improvement processes are often rigid, fail to generalize across tasks domains, and struggle to scale with increasing agent capabilities. We argue that effective self-improvement requires intrinsic metacognitive learning, defined as an agent's intrinsic ability to actively evaluate, reflect on, and adapt its own learning processes. Drawing inspiration from human metacognition, we introduce a formal framework comprising three components: metacognitive knowledge (self-assessment of capabilities, tasks, and learning strategies), metacognitive planning (deciding what and how to learn), and metacognitive evaluation (reflecting on learning experiences to improve future learning). Analyzing existing self-improving agents, we find they rely predominantly on extrinsic metacognitive mechanisms, which are fixed, human-designed loops that limit scalability and adaptability. Examining each component, we contend that many ingredients for intrinsic metacognition are already present. Finally, we explore how to optimally distribute metacognitive responsibilities between humans and agents, and robustly evaluate and improve intrinsic metacognitive learning, key challenges that must be addressed to enable truly sustained, generalized, and aligned self-improvement.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "Published as a conference paper at ICML 2025", "pdf_url": "https://arxiv.org/pdf/2506.05109.pdf", "abstract_url": "https://arxiv.org/abs/2506.05109", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了自我改进代理需要内在元认知学习的重要性，提出了一个包含元认知知识、计划和评估的框架，并分析了现有方法的局限性。", "motivation": "解决当前自我改进代理在泛化性、可扩展性和适应性方面的局限性。", "method": "引入了一个包含元认知知识、元认知计划和元认知评估的正式框架。", "result": "发现现有代理主要依赖外在元认知机制，这些机制限制了其可扩展性和适应性。", "conclusion": "为了实现持续、泛化和对齐的自我改进，必须解决内在元认知学习的关键挑战。"}}
{"id": "2506.04916", "title": "Energentic Intelligence: From Self-Sustaining Systems to Enduring Artificial Life", "authors": ["Atahan Karagoz"], "abstract": "This paper introduces Energentic Intelligence, a class of autonomous systems defined not by task performance, but by their capacity to sustain themselves through internal energy regulation. Departing from conventional reward-driven paradigms, these agents treat survival-maintaining functional operation under fluctuating energetic and thermal conditions-as the central objective. We formalize this principle through an energy-based utility function and a viability-constrained survival horizon, and propose a modular architecture that integrates energy harvesting, thermal regulation, and adaptive computation into a closed-loop control system. A simulated environment demonstrates the emergence of stable, resource-aware behavior without external supervision. Together, these contributions provide a theoretical and architectural foundation for deploying autonomous agents in resource-volatile settings where persistence must be self-regulated and infrastructure cannot be assumed.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Systems and Control (eess.SY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04916.pdf", "abstract_url": "https://arxiv.org/abs/2506.04916", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Systems and Control (eess.SY)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了Energentic Intelligence，一类通过内部能量调节维持自身运行的自主系统，其核心目标是生存而非任务完成。通过能量基础的效用函数和生存期限的可行性约束，提出了一种集成能量收集、温度调节和自适应计算的模块化架构。模拟环境展示了无需外部监督即可出现的稳定、资源感知行为。", "motivation": "解决在资源波动环境中部署自主代理的问题，这些环境需要自我调节持久性且不能假设基础设施的存在。", "method": "提出了一种基于能量的效用函数和生存期限的可行性约束，以及一个集成了能量收集、温度调节和自适应计算的模块化架构。", "result": "在模拟环境中，无需外部监督即可观察到稳定、资源感知的行为。", "conclusion": "为在资源波动环境中部署自主代理提供了理论和架构基础，这些代理能够自我调节以维持持久性。"}}
{"id": "2506.04998", "title": "Mathematical Reasoning for Unmanned Aerial Vehicles: A RAG-Based Approach for Complex Arithmetic Reasoning", "authors": ["Mehdi Azarafza", "Mojtaba Nayyeri", "Faezeh Pasandideh", "Steffen Staab", "Achim Rettberg"], "abstract": "Autonomous UAV operation necessitates reliable mathematical reasoning for tasks such as trajectory planning and power management. While traditional flight control relies on hardcoded equations, recent Large Language Models (LLMs) offer potential for more flexible problem-solving but struggle with reliably selecting and applying correct mathematical formulations and executing precise multi-step arithmetic. We propose RAG-UAV, a retrieval-augmented generation framework designed to improve the mathematical reasoning of several LLMs (including GPT o1/Turbo, Llama-3.2/3.3, Mistral, and DeepSeek R1) in UAV-specific contexts by providing access to relevant domain literature. To conduct an initial assessment, we introduce the UAV-Math-Bench, a small problem set comprising 20 UAV-centric mathematical problems across four difficulty levels. Our experiments demonstrate that incorporating retrieval substantially increases exact answer accuracy (achieving up to 75% with o1), reduces instances of incorrect formulation selection (from 25% without RAG to 5% with RAG), decreases numerical errors, reducing Mean Squared Error (MSE) by orders of magnitude for the best-performing models. This pilot study indicates that RAG can enable general-purpose LLMs to function as more reliable tools for engineering analysis, although direct real-time flight control requires further investigation and validation on a larger scale. All benchmark data, question and answer are publicly available.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "15 pages, 7 figures, 4 appendix subsections", "pdf_url": "https://arxiv.org/pdf/2506.04998.pdf", "abstract_url": "https://arxiv.org/abs/2506.04998", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种基于检索增强生成（RAG）的框架RAG-UAV，旨在提升大型语言模型（LLMs）在无人机（UAV）特定上下文中的数学推理能力。通过引入UAV-Math-Bench基准测试，实验表明RAG显著提高了模型的准确性和减少了错误。", "motivation": "自主无人机操作需要可靠的数学推理能力，传统飞行控制依赖硬编码方程，而现有的大型语言模型在正确选择和运用数学公式及执行精确的多步算术方面存在困难。", "method": "采用检索增强生成（RAG）框架RAG-UAV，通过提供相关领域文献的访问，增强LLMs在无人机特定上下文中的数学推理能力。", "result": "实验结果显示，引入RAG后，模型的准确答案率最高可达75%，错误公式选择率从25%降至5%，数值错误显著减少，最佳模型的均方误差（MSE）降低了数个数量级。", "conclusion": "初步研究表明，RAG可以使通用LLMs成为工程分析中更可靠的工具，但实时飞行控制的应用还需进一步研究和更大规模的验证。所有基准测试数据和问答均已公开。"}}
{"id": "2506.03922", "title": "HSSBench: Benchmarking Humanities and Social Sciences Ability for Multimodal Large Language Models", "authors": ["Zhaolu Kang", "Junhao Gong", "Jiaxu Yan", "Wanke Xia", "Yian Wang", "Ziwen Wang", "Huaxuan Ding", "Zhuo Cheng", "Wenhao Cao", "Zhiyuan Feng", "Siqi He", "Shannan Yan", "Junzhe Chen", "Xiaomin He", "Chaoya Jiang", "Wei Ye", "Kaidong Yu", "Xuelong Li"], "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated significant potential to advance a broad range of domains. However, current benchmarks for evaluating MLLMs primarily emphasize general knowledge and vertical step-by-step reasoning typical of STEM disciplines, while overlooking the distinct needs and potential of the Humanities and Social Sciences (HSS). Tasks in the HSS domain require more horizontal, interdisciplinary thinking and a deep integration of knowledge across related fields, which presents unique challenges for MLLMs, particularly in linking abstract concepts with corresponding visual representations. Addressing this gap, we present HSSBench, a dedicated benchmark designed to assess the capabilities of MLLMs on HSS tasks in multiple languages, including the six official languages of the United Nations. We also introduce a novel data generation pipeline tailored for HSS scenarios, in which multiple domain experts and automated agents collaborate to generate and iteratively refine each sample. HSSBench contains over 13,000 meticulously designed samples, covering six key categories. We benchmark more than 20 mainstream MLLMs on HSSBench and demonstrate that it poses significant challenges even for state-of-the-art models. We hope that this benchmark will inspire further research into enhancing the cross-disciplinary reasoning abilities of MLLMs, especially their capacity to internalize and connect knowledge across fields.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.03922.pdf", "abstract_url": "https://arxiv.org/abs/2506.03922", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "HSSBench是一个专为评估多模态大语言模型（MLLMs）在人文学科和社会科学（HSS）领域能力而设计的基准测试，包含超过13,000个样本，覆盖六个关键类别，旨在解决现有基准测试忽视HSS领域独特需求的问题。", "motivation": "当前的多模态大语言模型（MLLMs）评估基准主要强调STEM学科的通用知识和垂直逐步推理，忽视了人文学科和社会科学（HSS）的独特需求和潜力。HSS领域的任务需要更多的横向、跨学科思维和跨领域知识的深度融合，这对MLLMs提出了独特的挑战。", "method": "提出了HSSBench，一个专门用于评估MLLMs在HSS任务上能力的基准测试，包括联合国的六种官方语言。引入了一种新颖的数据生成流程，多个领域专家和自动化代理协作生成并迭代优化每个样本。", "result": "HSSBench包含超过13,000个精心设计的样本，覆盖六个关键类别。对超过20个主流MLLMs进行了基准测试，结果表明即使是最先进的模型也面临重大挑战。", "conclusion": "HSSBench有望激发进一步研究，以增强MLLMs的跨学科推理能力，特别是它们在跨领域知识内化和连接方面的能力。"}}
{"id": "2506.05296", "title": "Control Tax: The Price of Keeping AI in Check", "authors": ["Mikhail Terekhov", "Zhen Ning David Liu", "Caglar Gulcehre", "Samuel Albanie"], "abstract": "The rapid integration of agentic AI into high-stakes real-world applications requires robust oversight mechanisms. The emerging field of AI Control (AIC) aims to provide such an oversight mechanism, but practical adoption depends heavily on implementation overhead. To study this problem better, we introduce the notion of Control tax -- the operational and financial cost of integrating control measures into AI pipelines. Our work makes three key contributions to the field of AIC: (1) we introduce a theoretical framework that quantifies the Control Tax and maps classifier performance to safety assurances; (2) we conduct comprehensive evaluations of state-of-the-art language models in adversarial settings, where attacker models insert subtle backdoors into code while monitoring models attempt to detect these vulnerabilities; and (3) we provide empirical financial cost estimates for control protocols and develop optimized monitoring strategies that balance safety and cost-effectiveness while accounting for practical constraints like auditing budgets. Our framework enables practitioners to make informed decisions by systematically connecting safety guarantees with their costs, advancing AIC through principled economic feasibility assessment across different deployment contexts.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.05296.pdf", "abstract_url": "https://arxiv.org/abs/2506.05296", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了‘控制税’的概念，即在高风险应用中集成AI控制措施的操作和财务成本。通过理论框架、对抗性评估和成本效益分析，为AI控制领域提供了量化安全保证与成本的方法。", "motivation": "随着代理AI在高风险现实应用中的快速集成，需要强有力的监督机制。AI控制（AIC）领域旨在提供此类机制，但实际采用很大程度上取决于实施开销。", "method": "引入‘控制税’理论框架量化控制成本；在对抗性设置中评估最先进的语言模型；提供控制协议的财务成本估计并开发优化的监控策略。", "result": "建立了一个框架，系统地连接安全保证与其成本，通过原则性的经济可行性评估推进AIC在不同部署环境中的应用。", "conclusion": "本文的工作通过量化控制税和优化监控策略，为AI控制领域的发展提供了理论和实践基础，帮助从业者在安全与成本效益之间做出明智决策。"}}
{"id": "2506.04236", "title": "Spore in the Wild: Case Study on Spore.fun, a Real-World Experiment of Sovereign Agent Open-ended Evolution on Blockchain with TEEs", "authors": ["Botao Amber Hu", "Helena Rong"], "abstract": "In Artificial Life (ALife) research, replicating Open-Ended Evolution (OEE)-the continuous emergence of novelty observed in biological life-has traditionally been pursued within isolated closed system simulations, such as Tierra and Avida, which have typically plateaued after an initial burst of novelty, failing to achieve sustained OEE. Scholars suggest that OEE requires an \"open\" system that continually exchanges information or energy with its environment. A recent technological innovation in decentralized physical infrastructure networks (DePIN) providing permissionless computational substrates enables deploying large language model (LLM)-based AI agents on blockchains integrated with Trusted Execution Environments (TEEs). This enables on-chain agents to operate autonomously \"in the wild,\" achieving self-sovereignty without human oversight. These agents can control their own social media accounts and cryptocurrency wallets, allowing them to interact directly with blockchain-based financial networks and broader human social media. Building on this new paradigm of on-chain agents,", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Neural and Evolutionary Computing (cs.NE)", "comments": "Submitted to ALIFE 2025", "pdf_url": "https://arxiv.org/pdf/2506.04236.pdf", "abstract_url": "https://arxiv.org/abs/2506.04236", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)", "Neural and Evolutionary Computing (cs.NE)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了在区块链与可信执行环境（TEEs）结合的技术背景下，通过Spore.fun案例研究，实现了主权代理在开放环境中的开放式演化（OEE），突破了传统封闭系统模拟的限制。", "motivation": "解决传统人工生命（ALife）研究中，封闭系统模拟如Tierra和Avida在实现持续开放式演化（OEE）方面的局限性，探索在开放系统中实现持续新颖性涌现的可能性。", "method": "利用去中心化物理基础设施网络（DePIN）和可信执行环境（TEEs）技术，部署基于大型语言模型（LLM）的AI代理在区块链上，使其能够在开放环境中自主运作。", "result": "成功实现了主权代理在区块链上的自主运作，包括控制社交媒体账户和加密货币钱包，直接与基于区块链的金融网络和更广泛的人类社交媒体互动。", "conclusion": "通过Spore.fun案例研究，展示了在区块链与TEEs结合的技术背景下，主权代理在开放环境中实现开放式演化的可行性，为ALife研究提供了新的方向和技术路径。"}}
{"id": "2506.04265", "title": "CORA: Coalitional Rational Advantage Decomposition for Multi-Agent Policy Gradients", "authors": ["Mengda Ji", "Genjiu Xu", "Liying Wang"], "abstract": "This work focuses on the credit assignment problem in cooperative multi-agent reinforcement learning (MARL). Sharing the global advantage among agents often leads to suboptimal policy updates as it fails to account for the distinct contributions of agents. Although numerous methods consider global or individual contributions for credit assignment, a detailed analysis at the coalition level remains lacking in many approaches. This work analyzes the over-updating problem during multi-agent policy updates from a coalition-level perspective. To address this issue, we propose a credit assignment method called Coalitional Rational Advantage Decomposition (CORA). CORA evaluates coalitional advantages via marginal contributions from all possible coalitions and decomposes advantages using the core solution from cooperative game theory, ensuring coalitional rationality. To reduce computational overhead, CORA employs random coalition sampling. Experiments on matrix games, differential games, and multi-agent collaboration benchmarks demonstrate that CORA outperforms strong baselines, particularly in tasks with multiple local optima. These findings highlight the importance of coalition-aware credit assignment for improving MARL performance.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04265.pdf", "abstract_url": "https://arxiv.org/abs/2506.04265", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Computer Science and Game Theory (cs.GT)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为CORA的信用分配方法，用于解决合作多智能体强化学习中的信用分配问题。通过从联盟层面分析多智能体策略更新中的过度更新问题，并利用合作博弈论中的核心解决方案来分解优势，CORA确保了联盟的合理性。实验证明，CORA在多种任务中优于强基线，特别是在存在多个局部最优的任务中。", "motivation": "解决合作多智能体强化学习中的信用分配问题，特别是如何准确评估和分配智能体在联盟层面的贡献，以避免策略更新中的过度更新问题。", "method": "提出了联盟理性优势分解（CORA）方法，通过评估所有可能联盟的边际贡献来分解优势，并使用合作博弈论中的核心解决方案确保联盟的合理性。为了减少计算开销，CORA采用了随机联盟采样。", "result": "在矩阵游戏、差分游戏和多智能体协作基准测试中，CORA的表现优于强基线，尤其是在存在多个局部最优的任务中。", "conclusion": "联盟感知的信用分配对于提高多智能体强化学习的性能至关重要，CORA方法通过联盟层面的优势分解和核心解决方案的应用，有效地解决了信用分配问题。"}}
{"id": "2506.04293", "title": "AUTOCT: Automating Interpretable Clinical Trial Prediction with LLM Agents", "authors": ["Fengze Liu", "Haoyu Wang", "Joonhyuk Cho", "Dan Roth", "Andrew W. Lo"], "abstract": "Clinical trials are critical for advancing medical treatments but remain prohibitively expensive and time-consuming. Accurate prediction of clinical trial outcomes can significantly reduce research and development costs and accelerate drug discovery. While recent deep learning models have shown promise by leveraging unstructured data, their black-box nature, lack of interpretability, and vulnerability to label leakage limit their practical use in high-stakes biomedical contexts. In this work, we propose AutoCT, a novel framework that combines the reasoning capabilities of large language models with the explainability of classical machine learning. AutoCT autonomously generates, evaluates, and refines tabular features based on public information without human input. Our method uses Monte Carlo Tree Search to iteratively optimize predictive performance. Experimental results show that AutoCT performs on par with or better than SOTA methods on clinical trial prediction tasks within only a limited number of self-refinement iterations, establishing a new paradigm for scalable, interpretable, and cost-efficient clinical trial prediction.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04293.pdf", "abstract_url": "https://arxiv.org/abs/2506.04293", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "AutoCT是一个结合大型语言模型推理能力和经典机器学习可解释性的新框架，用于自动化、可解释的临床试验预测。", "motivation": "临床试验对于推进医学治疗至关重要，但其成本高昂且耗时。准确预测临床试验结果可以显著降低研发成本并加速药物发现。", "method": "AutoCT利用大型语言模型和蒙特卡洛树搜索自主生成、评估和优化基于公共信息的表格特征，无需人工输入。", "result": "实验结果显示，AutoCT在有限的自我优化迭代次数内，其性能与或优于现有的临床试验预测方法。", "conclusion": "AutoCT为可扩展、可解释且成本效益高的临床试验预测建立了新范式。"}}
{"id": "2506.04276", "title": "Autonomous Collaborative Scheduling of Time-dependent UAVs, Workers and Vehicles for Crowdsensing in Disaster Response", "authors": ["Lei Han", "Yitong Guo", "Pengfei Yang", "Zhiyong Yu", "Liang Wang", "Quan Wang", "Zhiwen Yu"], "abstract": "Natural disasters have caused significant losses to human society, and the timely and efficient acquisition of post-disaster environmental information is crucial for the effective implementation of rescue operations. Due to the complexity of post-disaster environments, existing sensing technologies face challenges such as weak environmental adaptability, insufficient specialized sensing capabilities, and limited practicality of sensing solutions. This paper explores the heterogeneous multi-agent online autonomous collaborative scheduling algorithm HoAs-PALN, aimed at achieving efficient collection of post-disaster environmental information. HoAs-PALN is realized through adaptive dimensionality reduction in the matching process and local Nash equilibrium game, facilitating autonomous collaboration among time-dependent UAVs, workers and vehicles to enhance sensing scheduling. (1) In terms of adaptive dimensionality reduction during the matching process, HoAs-PALN significantly reduces scheduling decision time by transforming a five-dimensional matching process into two categories of three-dimensional matching processes; (2) Regarding the local Nash equilibrium game, HoAs-PALN combines the softmax function to optimize behavior selection probabilities and introduces a local Nash equilibrium determination mechanism to ensure scheduling decision performance. Finally, we conducted detailed experiments based on extensive real-world and simulated data. Compared with the baselines (GREEDY, K-WTA, MADL and MARL), HoAs-PALN improves task completion rates by 64.12%, 46.48%, 16.55%, and 14.03% on average, respectively, while each online scheduling decision takes less than 10 seconds, demonstrating its effectiveness in dynamic post-disaster environments.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04276.pdf", "abstract_url": "https://arxiv.org/abs/2506.04276", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种异构多智能体在线自主协同调度算法HoAs-PALN，旨在通过自适应降维和局部纳什均衡博弈，实现时间依赖的无人机、工人和车辆之间的自主协作，以提高灾害响应中的感知调度效率。", "motivation": "自然灾害后环境复杂，现有感知技术面临环境适应性弱、专业感知能力不足和感知方案实用性有限等挑战，需要高效收集灾害后环境信息以支持救援行动。", "method": "HoAs-PALN算法通过匹配过程中的自适应降维和局部纳什均衡游戏，优化行为选择概率并引入局部纳什均衡确定机制，实现多智能体的自主协作调度。", "result": "与基线方法相比，HoAs-PALN平均提高任务完成率64.12%、46.48%、16.55%和14.03%，且每次在线调度决策时间少于10秒。", "conclusion": "HoAs-PALN在动态灾害后环境中表现出色，能够有效支持灾害响应中的环境信息收集。"}}
{"id": "2506.05010", "title": "ComfyUI-Copilot: An Intelligent Assistant for Automated Workflow Development", "authors": ["Zhenran Xu", "Xue Yang", "Yiyu Wang", "Qingli Hu", "Zijiao Wu", "Longyue Wang", "Weihua Luo", "Kaifu Zhang", "Baotian Hu", "Min Zhang"], "abstract": "We introduce ComfyUI-Copilot, a large language model-powered plugin designed to enhance the usability and efficiency of ComfyUI, an open-source platform for AI-driven art creation. Despite its flexibility and user-friendly interface, ComfyUI can present challenges to newcomers, including limited documentation, model misconfigurations, and the complexity of workflow design. ComfyUI-Copilot addresses these challenges by offering intelligent node and model recommendations, along with automated one-click workflow construction. At its core, the system employs a hierarchical multi-agent framework comprising a central assistant agent for task delegation and specialized worker agents for different usages, supported by our curated ComfyUI knowledge bases to streamline debugging and deployment. We validate the effectiveness of ComfyUI-Copilot through both offline quantitative evaluations and online user feedback, showing that it accurately recommends nodes and accelerates workflow development. Additionally, use cases illustrate that ComfyUI-Copilot lowers entry barriers for beginners and enhances workflow efficiency for experienced users. The ComfyUI-Copilot installation package and a demo video are available at", "subjects": "Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2506.05010.pdf", "abstract_url": "https://arxiv.org/abs/2506.05010", "categories": ["Computation and Language (cs.CL)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "ComfyUI-Copilot是一个基于大型语言模型的插件，旨在提升ComfyUI平台的可用性和效率，通过智能节点和模型推荐以及一键式工作流构建，解决新用户面临的文档不足、模型配置错误和工作流设计复杂等问题。", "motivation": "解决ComfyUI平台对新用户不友好、文档有限、模型配置复杂和工作流设计困难等问题。", "method": "采用分层多代理框架，包括一个中央助理代理和多个专门的工作代理，结合定制的ComfyUI知识库，以简化调试和部署过程。", "result": "通过离线和在线评估验证，ComfyUI-Copilot能准确推荐节点并加速工作流开发，降低初学者门槛，提升有经验用户的工作效率。", "conclusion": "ComfyUI-Copilot通过智能辅助功能显著提升了ComfyUI平台的用户体验和工作效率，适用于不同技能水平的用户。"}}
{"id": "2506.04390", "title": "Through the Stealth Lens: Rethinking Attacks and Defenses in RAG", "authors": ["Sarthak Choudhary", "Nils Palumbo", "Ashish Hooda", "Krishnamurthy Dj Dvijotham", "Somesh Jha"], "abstract": "Retrieval-augmented generation (RAG) systems are vulnerable to attacks that inject poisoned passages into the retrieved set, even at low corruption rates. We show that existing attacks are not designed to be stealthy, allowing reliable detection and mitigation. We formalize stealth using a distinguishability-based security game. If a few poisoned passages are designed to control the response, they must differentiate themselves from benign ones, inherently compromising stealth. This motivates the need for attackers to rigorously analyze intermediate signals involved in generation$\\unicode{x2014}$such as attention patterns or next-token probability distributions$\\unicode{x2014}$to avoid easily detectable traces of manipulation. Leveraging attention patterns, we propose a passage-level score$\\unicode{x2014}$the Normalized Passage Attention Score$\\unicode{x2014}$used by our Attention-Variance Filter algorithm to identify and filter potentially poisoned passages. This method mitigates existing attacks, improving accuracy by up to $\\sim 20 \\%$ over baseline defenses. To probe the limits of attention-based defenses, we craft stealthier adaptive attacks that obscure such traces, achieving up to $35 \\%$ attack success rate, and highlight the challenges in improving stealth.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04390.pdf", "abstract_url": "https://arxiv.org/abs/2506.04390", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文探讨了检索增强生成（RAG）系统在面对注入有毒段落攻击时的脆弱性，并提出了一种基于注意力模式的防御方法。", "motivation": "解决RAG系统在低污染率下仍易受攻击的问题，尤其是现有攻击缺乏隐蔽性，容易被检测和缓解。", "method": "提出了一种基于注意力模式的防御方法，包括归一化段落注意力分数和注意力方差过滤算法，以识别和过滤潜在的有毒段落。", "result": "该方法有效缓解了现有攻击，比基线防御提高了约20%的准确率。同时，研究还设计了更隐蔽的自适应攻击，成功率达到35%，揭示了提升隐蔽性的挑战。", "conclusion": "研究强调了在RAG系统中分析和利用中间信号（如注意力模式）的重要性，以及开发更隐蔽攻击和防御策略的必要性。"}}
{"id": "2506.04399", "title": "Unsupervised Meta-Testing with Conditional Neural Processes for Hybrid Meta-Reinforcement Learning", "authors": ["Suzan Ece Ada", "Emre Ugur"], "abstract": "We introduce Unsupervised Meta-Testing with Conditional Neural Processes (UMCNP), a novel hybrid few-shot meta-reinforcement learning (meta-RL) method that uniquely combines, yet distinctly separates, parameterized policy gradient-based (PPG) and task inference-based few-shot meta-RL. Tailored for settings where the reward signal is missing during meta-testing, our method increases sample efficiency without requiring additional samples in meta-training. UMCNP leverages the efficiency and scalability of Conditional Neural Processes (CNPs) to reduce the number of online interactions required in meta-testing. During meta-training, samples previously collected through PPG meta-RL are efficiently reused for learning task inference in an offline manner. UMCNP infers the latent representation of the transition dynamics model from a single test task rollout with unknown parameters. This approach allows us to generate rollouts for self-adaptation by interacting with the learned dynamics model. We demonstrate our method can adapt to an unseen test task using significantly fewer samples during meta-testing than the baselines in 2D-Point Agent and continuous control meta-RL benchmarks, namely, cartpole with unknown angle sensor bias, walker agent with randomized dynamics parameters.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": "Published in IEEE Robotics and Automation Letters Volume: 9, Issue: 10, 8427 - 8434, October 2024. 8 pages, 7 figures", "pdf_url": "https://arxiv.org/pdf/2506.04399.pdf", "abstract_url": "https://arxiv.org/abs/2506.04399", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了UMCNP，一种新型的混合少样本元强化学习方法，结合了参数化策略梯度（PPG）和任务推断的元强化学习，特别适用于元测试阶段缺乏奖励信号的情况。UMCNP通过条件神经过程（CNPs）提高样本效率，减少元测试阶段所需的在线交互次数。", "motivation": "解决在元测试阶段缺乏奖励信号的情况下，如何高效地进行少样本元强化学习的问题。", "method": "UMCNP方法结合了参数化策略梯度（PPG）和任务推断的元强化学习，利用条件神经过程（CNPs）减少元测试阶段的在线交互次数，并在元训练阶段重用PPG元强化学习收集的样本进行离线任务推断学习。", "result": "在2D点代理和连续控制元强化学习基准测试中，UMCNP能够使用比基线方法更少的样本适应未见过的测试任务。", "conclusion": "UMCNP提供了一种高效的方法，用于在缺乏奖励信号的情况下进行少样本元强化学习，显著提高了样本效率，并在多个基准测试中展示了其优越性。"}}
{"id": "2506.05154", "title": "Knowledgeable-r1: Policy Optimization for Knowledge Exploration in Retrieval-Augmented Generation", "authors": ["Chenyu Lin", "Yilin Wen", "Du Su", "Fei Sun", "Muhan Chen", "Chenfu Bao", "Zhonghou Lv"], "abstract": "Retrieval-augmented generation (RAG) is a mainstream method for improving performance on knowledge-intensive tasks. However,current RAG systems often place too much emphasis on retrieved contexts. This can lead to reliance on inaccurate sources and overlook the model's inherent knowledge, especially when dealing with misleading or excessive information. To resolve this imbalance, we propose Knowledgeable-r1 that using joint sampling and define multi policy distributions in knowledge capability exploration to stimulate large language models'self-integrated utilization of parametric and contextual knowledge. Experiments show that Knowledgeable-r1 significantly enhances robustness and reasoning accuracy in both parameters and contextual conflict tasks and general RAG tasks, especially outperforming baselines by 17.07% in counterfactual scenarios and demonstrating consistent gains across RAG tasks. Our code are available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.05154.pdf", "abstract_url": "https://arxiv.org/abs/2506.05154", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "Knowledgeable-r1是一种针对检索增强生成（RAG）系统中知识探索的策略优化方法，旨在平衡检索上下文与模型固有知识的使用，以提高在知识密集型任务中的表现。", "motivation": "当前的RAG系统过于依赖检索到的上下文，可能导致对不准确来源的依赖和忽视模型固有知识的问题，特别是在处理误导性或过量信息时。", "method": "提出了Knowledgeable-r1，通过联合采样和在知识能力探索中定义多策略分布，来激发大型语言模型自我整合利用参数化和上下文知识。", "result": "实验表明，Knowledgeable-r1显著增强了在参数和上下文冲突任务以及一般RAG任务中的鲁棒性和推理准确性，特别是在反事实场景中比基线表现高出17.07%，并在各种RAG任务中展现出持续的增益。", "conclusion": "Knowledgeable-r1通过优化知识探索策略，有效解决了RAG系统中对检索上下文过度依赖的问题，提高了模型在处理复杂知识任务时的性能和鲁棒性。"}}
{"id": "2506.05167", "title": "ECoRAG: Evidentiality-guided Compression for Long Context RAG", "authors": ["Yeonseok Jeong", "Jinsu Kim", "Dohyeon Lee", "Seung-won Hwang"], "abstract": "Large Language Models (LLMs) have shown remarkable performance in Open-Domain Question Answering (ODQA) by leveraging external documents through Retrieval-Augmented Generation (RAG). To reduce RAG overhead, from longer context, context compression is necessary. However, prior compression methods do not focus on filtering out non-evidential information, which limit the performance in LLM-based RAG. We thus propose Evidentiality-guided RAG, or \\textbf{ECoRAG} framework. ECoRAG improves LLM performance by compressing retrieved documents based on evidentiality, ensuring whether answer generation is supported by the correct evidence. As an additional step, ECoRAG reflects whether the compressed content provides sufficient evidence, and if not, retrieves more until sufficient. Experiments show that ECoRAG improves LLM performance on ODQA tasks, outperforming existing compression methods. Furthermore, ECoRAG is highly cost-efficient, as it not only reduces latency but also minimizes token usage by retaining only the necessary information to generate the correct answer. Code is available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.05167.pdf", "abstract_url": "https://arxiv.org/abs/2506.05167", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种名为ECoRAG的框架，通过基于证据性的检索文档压缩，提高大型语言模型在开放领域问答任务中的性能。ECoRAG不仅减少了延迟，还通过仅保留生成正确答案所需的信息，最小化了令牌使用，具有高成本效益。", "motivation": "为了解决在基于大型语言模型的检索增强生成（RAG）中，现有压缩方法未能有效过滤非证据性信息，从而限制性能的问题。", "method": "提出了ECoRAG框架，该框架通过证据性指导的压缩方法，确保答案生成得到正确证据的支持，并在必要时检索更多信息。", "result": "实验表明，ECoRAG在开放领域问答任务中提高了大型语言模型的性能，优于现有的压缩方法，并且具有高成本效益。", "conclusion": "ECoRAG通过证据性指导的压缩和必要时的额外检索，有效提高了大型语言模型在开放领域问答任务中的性能和成本效益。"}}
{"id": "2506.05278", "title": "Micro-Act: Mitigate Knowledge Conflict in Question Answering via Actionable Self-Reasoning", "authors": ["Nan Huo", "Jinyang Li", "Bowen Qin", "Ge Qu", "Xiaolong Li", "Xiaodong Li", "Chenhao Ma", "Reynold Cheng"], "abstract": "Retrieval-Augmented Generation (RAG) systems commonly suffer from Knowledge Conflicts, where retrieved external knowledge contradicts the inherent, parametric knowledge of large language models (LLMs). It adversely affects performance on downstream tasks such as question answering (QA). Existing approaches often attempt to mitigate conflicts by directly comparing two knowledge sources in a side-by-side manner, but this can overwhelm LLMs with extraneous or lengthy contexts, ultimately hindering their ability to identify and mitigate inconsistencies. To address this issue, we propose Micro-Act a framework with a hierarchical action space that automatically perceives context complexity and adaptively decomposes each knowledge source into a sequence of fine-grained comparisons. These comparisons are represented as actionable steps, enabling reasoning beyond the superficial context. Through extensive experiments on five benchmark datasets, Micro-Act consistently achieves significant increase in QA accuracy over state-of-the-art baselines across all 5 datasets and 3 conflict types, especially in temporal and semantic types where all baselines fail significantly. More importantly, Micro-Act exhibits robust performance on non-conflict questions simultaneously, highlighting its practical value in real-world RAG applications.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "Accepted by ACL 2025 Main", "pdf_url": "https://arxiv.org/pdf/2506.05278.pdf", "abstract_url": "https://arxiv.org/abs/2506.05278", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了Micro-Act框架，通过分层行动空间自动感知上下文复杂性并自适应地将每个知识源分解为一系列细粒度比较，以解决检索增强生成（RAG）系统中的知识冲突问题。", "motivation": "检索增强生成（RAG）系统常遭受知识冲突的困扰，即检索到的外部知识与大型语言模型（LLMs）的内在参数知识相矛盾，这影响了如问答（QA）等下游任务的性能。", "method": "提出Micro-Act框架，采用分层行动空间自动感知上下文复杂性，并自适应地将每个知识源分解为一系列细粒度比较，这些比较表示为可操作的步骤，支持超越表面上下文的推理。", "result": "在五个基准数据集上的广泛实验表明，Micro-Act在所有5个数据集和3种冲突类型上均显著提高了QA准确性，特别是在时间和语义类型上，所有基线方法均显著失败。", "conclusion": "Micro-Act不仅在知识冲突问题上表现出色，同时在非冲突问题上也展现出稳健的性能，突出了其在现实世界RAG应用中的实用价值。"}}
{"id": "2506.05309", "title": "Time to Talk: LLM Agents for Asynchronous Group Communication in Mafia Games", "authors": ["Niv Eckhaus", "Uri Berger", "Gabriel Stanovsky"], "abstract": "LLMs are used predominantly in synchronous communication, where a human user and a model communicate in alternating turns. In contrast, many real-world settings are inherently asynchronous. For example, in group chats, online team meetings, or social games, there is no inherent notion of turns; therefore, the decision of when to speak forms a crucial part of the participant's decision making. In this work, we develop an adaptive asynchronous LLM-agent which, in addition to determining what to say, also decides when to say it. To evaluate our agent, we collect a unique dataset of online Mafia games, including both human participants, as well as our asynchronous agent. Overall, our agent performs on par with human players, both in game performance, as well as in its ability to blend in with the other human players. Our analysis shows that the agent's behavior in deciding when to speak closely mirrors human patterns, although differences emerge in message content. We release all our data and code to support and encourage further research for more realistic asynchronous communication between LLM agents. This work paves the way for integration of LLMs into realistic human group settings, from assistance in team discussions to educational and professional environments where complex social dynamics must be navigated.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.05309.pdf", "abstract_url": "https://arxiv.org/abs/2506.05309", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文开发了一种自适应异步LLM代理，用于在无固定轮次的异步群组通信中决定何时发言，如在Mafia游戏中，其表现与人类玩家相当，并在发言时机上模仿人类模式。", "motivation": "解决LLM在异步通信环境（如群聊、在线团队会议或社交游戏）中的应用问题，其中发言时机的决策是参与者决策的关键部分。", "method": "开发了一种自适应异步LLM代理，该代理不仅能决定说什么，还能决定何时说，并通过在线Mafia游戏数据集进行评估。", "result": "代理在游戏表现和与人类玩家混入的能力上与人类玩家相当，其发言时机行为与人类模式相似，但在消息内容上存在差异。", "conclusion": "这项工作为LLM在更现实的异步通信中的应用铺平了道路，从团队讨论的辅助到需要导航复杂社交动态的教育和专业环境。"}}
{"id": "2506.05305", "title": "ProRefine: Inference-time Prompt Refinement with Textual Feedback", "authors": ["Deepak Pandita", "Tharindu Cyril Weerasooriya", "Ankit Parag Shah", "Christopher M. Homan", "Wei Wei"], "abstract": "Agentic workflows, where multiple AI agents collaborate to accomplish complex tasks like reasoning or planning, are becoming increasingly prevalent. However, these workflows often suffer from error propagation and sub-optimal performance, largely due to poorly designed prompts that fail to effectively guide individual agents. This is a critical problem because it limits the reliability and scalability of these powerful systems. We introduce ProRefine, an innovative inference-time prompt optimization method that leverages textual feedback from large language models (LLMs) to address this challenge. ProRefine dynamically refines prompts for multi-step reasoning tasks without additional training or ground truth labels. Evaluated on five benchmark mathematical reasoning datasets, ProRefine significantly surpasses zero-shot Chain-of-Thought baselines by 3 to 37 percentage points. This approach not only boosts accuracy but also allows smaller models to match the performance of larger ones, highlighting its potential for efficient and scalable AI deployment, and democratizing access to high-performing AI.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.05305.pdf", "abstract_url": "https://arxiv.org/abs/2506.05305", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "ProRefine是一种创新的推理时提示优化方法，利用大型语言模型的文本反馈动态优化多步推理任务的提示，无需额外训练或真实标签。在五个数学推理基准数据集上评估，ProRefine显著超越零样本思维链基线3至37个百分点。", "motivation": "解决多AI代理协作工作流中由于提示设计不佳导致的错误传播和性能不佳问题，提高系统的可靠性和可扩展性。", "method": "引入ProRefine，一种利用大型语言模型(LLMs)的文本反馈在推理时动态优化提示的方法。", "result": "在五个数学推理基准数据集上，ProRefine显著超越零样本思维链基线3至37个百分点，且能使较小模型匹配较大模型的性能。", "conclusion": "ProRefine不仅提高了准确性，还使较小模型能够匹配较大模型的性能，展示了其在高效、可扩展AI部署中的潜力，以及 democratizing access to high-performing AI的可能性。"}}
{"id": "2506.04836", "title": "Oversight Structures for Agentic AI in Public-Sector Organizations", "authors": ["Chris Schmitz", "Jonathan Rystrøm", "Jan Batzner"], "abstract": "This paper finds that the introduction of agentic AI systems intensifies existing challenges to traditional public sector oversight mechanisms -- which rely on siloed compliance units and episodic approvals rather than continuous, integrated supervision. We identify five governance dimensions essential for responsible agent deployment: cross-departmental implementation, comprehensive evaluation, enhanced security protocols, operational visibility, and systematic auditing. We evaluate the capacity of existing oversight structures to meet these challenges, via a mixed-methods approach consisting of a literature review and interviews with civil servants in AI-related roles. We find that agent oversight poses intensified versions of three existing governance challenges: continuous oversight, deeper integration of governance and operational capabilities, and interdepartmental coordination. We propose approaches that both adapt institutional structures and design agent oversight compatible with public sector constraints.", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI)", "comments": "To appear at REALM@ACL2025", "pdf_url": "https://arxiv.org/pdf/2506.04836.pdf", "abstract_url": "https://arxiv.org/abs/2506.04836", "categories": ["Computers and Society (cs.CY)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文发现，引入代理性AI系统加剧了传统公共部门监督机制面临的挑战，这些机制依赖于孤立的合规单位和阶段性批准，而非持续、集成的监督。我们确定了负责任代理部署的五个治理维度：跨部门实施、全面评估、增强的安全协议、操作可见性和系统审计。通过文献综述和对AI相关职位公务员的访谈，我们评估了现有监督结构应对这些挑战的能力。我们发现，代理监督加剧了三个现有治理挑战：持续监督、治理与运营能力的更深层次整合以及跨部门协调。我们提出了既适应制度结构又设计符合公共部门限制的代理监督方法。", "motivation": "解决代理性AI系统引入公共部门后对传统监督机制带来的挑战", "method": "混合方法，包括文献综述和对AI相关职位公务员的访谈", "result": "代理监督加剧了持续监督、治理与运营能力的更深层次整合以及跨部门协调三个现有治理挑战", "conclusion": "提出了适应制度结构并设计符合公共部门限制的代理监督方法"}}
{"id": "2506.04838", "title": "On Automating Security Policies with Contemporary LLMs", "authors": ["Pablo Fernández Saura", "K. R. Jayaram", "Vatche Isahagian", "Jorge Bernal Bernabé", "Antonio Skarmeta"], "abstract": "The complexity of modern computing environments and the growing sophistication of cyber threats necessitate a more robust, adaptive, and automated approach to security enforcement. In this paper, we present a framework leveraging large language models (LLMs) for automating attack mitigation policy compliance through an innovative combination of in-context learning and retrieval-augmented generation (RAG). We begin by describing how our system collects and manages both tool and API specifications, storing them in a vector database to enable efficient retrieval of relevant information. We then detail the architectural pipeline that first decomposes high-level mitigation policies into discrete tasks and subsequently translates each task into a set of actionable API calls. Our empirical evaluation, conducted using publicly available CTI policies in STIXv2 format and Windows API documentation, demonstrates significant improvements in precision, recall, and F1-score when employing RAG compared to a non-RAG baseline.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": "Short Paper. Accepted To Appear in IEEE SSE 2025 (part of SERVICES 2025)", "pdf_url": "https://arxiv.org/pdf/2506.04838.pdf", "abstract_url": "https://arxiv.org/abs/2506.04838", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种利用大型语言模型（LLMs）通过上下文学习和检索增强生成（RAG）的创新组合来自动化攻击缓解策略合规性的框架。", "motivation": "现代计算环境的复杂性和网络威胁的日益复杂化需要一种更强大、自适应和自动化的安全执行方法。", "method": "该系统首先收集和管理工具及API规范，将其存储在向量数据库中以便高效检索相关信息，然后通过架构管道将高级缓解策略分解为离散任务，并将每个任务转化为一组可操作的API调用。", "result": "使用公开可用的STIXv2格式的CTI策略和Windows API文档进行的实证评估显示，与非RAG基线相比，采用RAG在精确度、召回率和F1分数上有显著提升。", "conclusion": "研究表明，结合RAG的LLMs框架在自动化安全策略方面具有显著优势，为应对复杂网络威胁提供了有效的解决方案。"}}
{"id": "2506.05020", "title": "Hierarchical Language Models for Semantic Navigation and Manipulation in an Aerial-Ground Robotic System", "authors": ["Haokun Liu", "Zhaoqi Ma", "Yunong Li", "Junichiro Sugihara", "Yicheng Chen", "Jinjie Li", "Moju Zhao"], "abstract": "Heterogeneous multi-robot systems show great potential in complex tasks requiring coordinated hybrid cooperation. However, traditional approaches relying on static models often struggle with task diversity and dynamic environments. This highlights the need for generalizable intelligence that can bridge high-level reasoning with low-level execution across heterogeneous agents. To address this, we propose a hierarchical framework integrating a prompted Large Language Model (LLM) and a GridMask-enhanced fine-tuned Vision Language Model (VLM). The LLM performs task decomposition and global semantic map construction, while the VLM extracts task-specified semantic labels and 2D spatial information from aerial images to support local planning. Within this framework, the aerial robot follows a globally optimized semantic path and continuously provides bird-view images, guiding the ground robot's local semantic navigation and manipulation, including target-absent scenarios where implicit alignment is maintained. Experiments on a real-world letter-cubes arrangement task demonstrate the framework's adaptability and robustness in dynamic environments. To the best of our knowledge, this is the first demonstration of an aerial-ground heterogeneous system integrating VLM-based perception with LLM-driven task reasoning and motion planning.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.05020.pdf", "abstract_url": "https://arxiv.org/abs/2506.05020", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种集成大型语言模型（LLM）和视觉语言模型（VLM）的层次化框架，用于异构多机器人系统中的语义导航和操作，展示了在动态环境中的适应性和鲁棒性。", "motivation": "传统依赖静态模型的方法在处理任务多样性和动态环境时存在困难，需要一种能够桥接高层推理与低层执行的通用智能。", "method": "采用层次化框架，结合提示的LLM进行任务分解和全局语义地图构建，以及GridMask增强的微调VLM从航拍图像中提取任务指定的语义标签和2D空间信息，支持局部规划。", "result": "在真实世界的字母立方体排列任务中，该框架展示了在动态环境中的适应性和鲁棒性，特别是在目标缺失场景中保持隐式对齐。", "conclusion": "这是首次展示将VLM基于的感知与LLM驱动的任务推理和运动规划集成到空中-地面异构系统中的研究，为复杂任务中的协调混合合作提供了新思路。"}}
{"id": "2506.05265", "title": "Teaming in the AI Era: AI-Augmented Frameworks for Forming, Simulating, and Optimizing Human Teams", "authors": ["Mohammed Almutairi"], "abstract": "Effective teamwork is essential across diverse domains. During the team formation stage, a key challenge is forming teams that effectively balance user preferences with task objectives to enhance overall team satisfaction. In the team performing stage, maintaining cohesion and engagement is critical for sustaining high team performance. However, existing computational tools and algorithms for team optimization often rely on static data inputs, narrow algorithmic objectives, or solutions tailored for specific contexts, failing to account for the dynamic interplay of team members personalities, evolving goals, and changing individual preferences. Therefore, teams may encounter member dissatisfaction, as purely algorithmic assignments can reduce members commitment to team goals or experience suboptimal engagement due to the absence of timely, personalized guidance to help members adjust their behaviors and interactions as team dynamics evolve. Ultimately, these challenges can lead to reduced overall team performance. My Ph.D. dissertation aims to develop AI-augmented team optimization frameworks and practical systems that enhance team satisfaction, engagement, and performance. First, I propose a team formation framework that leverages a multi-armed bandit algorithm to iteratively refine team composition based on user preferences, ensuring alignment between individual needs and collective team goals to enhance team satisfaction. Second, I introduce tAIfa (Team AI Feedback Assistant), an AI-powered system that utilizes large language models (LLMs) to deliver immediate, personalized feedback to both teams and individual members, enhancing cohesion and engagement. Finally, I present PuppeteerLLM, an LLM-based simulation framework that simulates multi-agent teams to model complex team dynamics within realistic environments, incorporating task-driven collaboration and long-term coordination.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "5 pages, UMAP 25, June 16_19, 2025, New York City, NY, USA", "pdf_url": "https://arxiv.org/pdf/2506.05265.pdf", "abstract_url": "https://arxiv.org/abs/2506.05265", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种AI增强的团队优化框架，旨在通过多臂老虎机算法和大型语言模型（LLMs）来提升团队的形成、执行和模拟过程中的满意度、凝聚力和表现。", "motivation": "解决现有团队优化工具在考虑动态团队成员个性、演变目标和变化偏好方面的不足，以及由此导致的成员不满和团队表现下降问题。", "method": "开发了三个主要框架：基于多臂老虎机算法的团队形成框架、AI反馈助手tAIfa和基于LLM的模拟框架PuppeteerLLM，分别针对团队形成、执行和模拟阶段。", "result": "提出的框架能够更好地平衡用户偏好与任务目标，提供即时个性化反馈，以及模拟复杂团队动态，从而提升团队满意度、凝聚力和表现。", "conclusion": "AI增强的团队优化框架为团队的形成、执行和模拟提供了有效的解决方案，有望在实际应用中显著提升团队的整体表现和成员满意度。"}}
