{"id": "2509.15293", "title": "How Good are Foundation Models in Step-by-Step Embodied Reasoning?", "authors": ["Dinura Dissanayake", "Ahmed Heakl", "Omkar Thawakar", "Noor Ahsan", "Ritesh Thawkar", "Ketan More", "Jean Lahoud", "Rao Anwer", "Hisham Cholakkal", "Ivan Laptev", "Fahad Shahbaz Khan", "Salman Khan"], "abstract": "Embodied agents operating in the physical world must make decisions that are not only effective but also safe, spatially coherent, and grounded in context. While recent advances in large multimodal models (LMMs) have shown promising capabilities in visual understanding and language generation, their ability to perform structured reasoning for real-world embodied tasks remains underexplored. In this work, we aim to understand how well foundation models can perform step-by-step reasoning in embodied environments. To this end, we propose the Foundation Model Embodied Reasoning (FoMER) benchmark, designed to evaluate the reasoning capabilities of LMMs in complex embodied decision-making scenarios. Our benchmark spans a diverse set of tasks that require agents to interpret multimodal observations, reason about physical constraints and safety, and generate valid next actions in natural language. We present (i) a large-scale, curated suite of embodied reasoning tasks, (ii) a novel evaluation framework that disentangles perceptual grounding from action reasoning, and (iii) empirical analysis of several leading LMMs under this setting. Our benchmark includes over 1.1k samples with detailed step-by-step reasoning across 10 tasks and 8 embodiments, covering three different robot types. Our results highlight both the potential and current limitations of LMMs in embodied reasoning, pointing towards key challenges and opportunities for future research in robot intelligence. Our data and code will be made publicly available.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.15293.pdf", "abstract_url": "https://arxiv.org/abs/2509.15293", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文提出了FoMER基准，评估基础模型在具身推理中的表现，发现大型多模态模型在复杂任务中具有潜力但存在局限。", "motivation": "解决基础模型在真实世界具身任务中结构化推理能力不足的问题。", "method": "设计了FoMER基准，包含多样化任务和评估框架，分析多个大型多模态模型。", "result": "结果显示了大型多模态模型在具身推理中的优势和当前限制。", "conclusion": "结论指出需进一步研究以克服挑战，推动机器人智能发展。"}}
{"id": "2509.15435", "title": "ORCA: Agentic Reasoning For Hallucination and Adversarial Robustness in Vision-Language Models", "authors": ["Chung-En Johnny Yu", "Hsuan-Chih", "Chen", "Brian Jalaian", "Nathaniel D. Bastian"], "abstract": "Large Vision-Language Models (LVLMs) exhibit strong multimodal capabilities but remain vulnerable to hallucinations from intrinsic errors and adversarial attacks from external exploitations, limiting their reliability in real-world applications. We present ORCA, an agentic reasoning framework that improves the factual accuracy and adversarial robustness of pretrained LVLMs through test-time structured inference reasoning with a suite of small vision models (less than 3B parameters). ORCA operates via an Observe--Reason--Critique--Act loop, querying multiple visual tools with evidential questions, validating cross-model inconsistencies, and refining predictions iteratively without access to model internals or retraining. ORCA also stores intermediate reasoning traces, which supports auditable decision-making. Though designed primarily to mitigate object-level hallucinations, ORCA also exhibits emergent adversarial robustness without requiring adversarial training or defense mechanisms. We evaluate ORCA across three settings: (1) clean images on hallucination benchmarks, (2) adversarially perturbed images without defense, and (3) adversarially perturbed images with defense applied. On the POPE hallucination benchmark, ORCA improves standalone LVLM performance by +3.64\\% to +40.67\\% across different subsets. Under adversarial perturbations on POPE, ORCA achieves an average accuracy gain of +20.11\\% across LVLMs. When combined with defense techniques on adversarially perturbed AMBER images, ORCA further improves standalone LVLM performance, with gains ranging from +1.20\\% to +48.00\\% across evaluation metrics. These results demonstrate that ORCA offers a promising path toward building more reliable and robust multimodal systems.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.15435.pdf", "abstract_url": "https://arxiv.org/abs/2509.15435", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "ORCA是一个代理推理框架，通过观察-推理-批判-行动循环，利用小型视觉模型提升预训练大型视觉语言模型的事实准确性和对抗鲁棒性，无需重新训练。", "motivation": "解决大型视觉语言模型在真实世界应用中因内在错误和外部对抗攻击导致的幻觉和可靠性限制问题。", "method": "采用代理推理框架，通过查询多个视觉工具、验证不一致性和迭代优化预测，使用观察-推理-批判-行动循环。", "result": "在POPE幻觉基准上提升性能3.64%至40.67%，对抗扰动下平均准确率增益20.11%，结合防御技术进一步改善性能。", "conclusion": "ORCA为构建更可靠和鲁棒的多模态系统提供了有前景的路径，支持可审计决策。"}}
{"id": "2509.15250", "title": "Walk and Read Less: Improving the Efficiency of Vision-and-Language Navigation via Tuning-Free Multimodal Token Pruning", "authors": ["Wenda Qin", "Andrea Burns", "Bryan A. Plummer", "Margrit Betke"], "abstract": "Large models achieve strong performance on Vision-and-Language Navigation (VLN) tasks, but are costly to run in resource-limited environments. Token pruning offers appealing tradeoffs for efficiency with minimal performance loss by reducing model input size, but prior work overlooks VLN-specific challenges. For example, information loss from pruning can effectively increase computational cost due to longer walks. Thus, the inability to identify uninformative tokens undermines the supposed efficiency gains from pruning. To address this, we propose Navigation-Aware Pruning (NAP), which uses navigation-specific traits to simplify the pruning process by pre-filtering tokens into foreground and background. For example, image views are filtered based on whether the agent can navigate in that direction. We also extract navigation-relevant instructions using a Large Language Model. After filtering, we focus pruning on background tokens, minimizing information loss. To further help avoid increases in navigation length, we discourage backtracking by removing low-importance navigation nodes. Experiments on standard VLN benchmarks show NAP significantly outperforms prior work, preserving higher success rates while saving more than 50% FLOPS.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2509.15250.pdf", "abstract_url": "https://arxiv.org/abs/2509.15250", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为导航感知剪枝（NAP）的方法，用于提高视觉与语言导航（VLN）的效率，通过预过滤令牌减少计算成本，同时保持高性能。", "motivation": "解决大型模型在资源受限环境中运行VLN任务时计算成本高的问题，特别是现有令牌剪枝方法因信息丢失导致导航路径变长，从而抵消效率增益。", "method": "使用导航特定特征预过滤令牌，将图像视图和指令分为前景和背景，并专注于剪枝背景令牌；同时通过移除低重要性导航节点避免回溯。", "result": "在标准VLN基准测试中，NAP显著优于先前工作，节省超过50%的FLOPS，同时保持更高的成功率。", "conclusion": "NAP方法有效提升了VLN的效率，证明了导航感知剪枝的可行性，为资源受限应用提供了实用解决方案。"}}
{"id": "2509.15532", "title": "GUI-ARP: Enhancing Grounding with Adaptive Region Perception for GUI Agents", "authors": ["Xianhang Ye", "Yiqing Li", "Wei Dai", "Miancan Liu", "Ziyuan Chen", "Zhangye Han", "Hongbo Min", "Jinkui Ren", "Xiantao Zhang", "Wen Yang", "Zhi Jin"], "abstract": "Existing GUI grounding methods often struggle with fine-grained localization in high-resolution screenshots. To address this, we propose GUI-ARP, a novel framework that enables adaptive multi-stage inference. Equipped with the proposed Adaptive Region Perception (ARP) and Adaptive Stage Controlling (ASC), GUI-ARP dynamically exploits visual attention for cropping task-relevant regions and adapts its inference strategy, performing a single-stage inference for simple cases and a multi-stage analysis for more complex scenarios. This is achieved through a two-phase training pipeline that integrates supervised fine-tuning with reinforcement fine-tuning based on Group Relative Policy Optimization (GRPO). Extensive experiments demonstrate that the proposed GUI-ARP achieves state-of-the-art performance on challenging GUI grounding benchmarks, with a 7B model reaching 60.8% accuracy on ScreenSpot-Pro and 30.9% on UI-Vision benchmark. Notably, GUI-ARP-7B demonstrates strong competitiveness against open-source 72B models (UI-TARS-72B at 38.1%) and proprietary models.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.15532.pdf", "abstract_url": "https://arxiv.org/abs/2509.15532", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出GUI-ARP框架，通过自适应区域感知和多阶段推理，提升GUI代理在细粒度定位中的性能，在多个基准测试中达到最先进水平。", "motivation": "解决现有GUI接地方法在高分辨率截图中细粒度定位困难的问题。", "method": "使用自适应区域感知（ARP）和自适应阶段控制（ASC）进行动态推理，结合监督微调和基于GRPO的强化微调两阶段训练。", "result": "在ScreenSpot-Pro和UI-Vision基准测试中，7B模型分别达到60.8%和30.9%的准确率，优于开源72B模型。", "conclusion": "GUI-ARP框架有效提升GUI接地性能，具有强竞争力，适用于复杂GUI交互场景。"}}
{"id": "2509.15536", "title": "SAMPO:Scale-wise Autoregression with Motion PrOmpt for generative world models", "authors": ["Sen Wang", "Jingyi Tian", "Le Wang", "Zhimin Liao", "Jiayi Li", "Huaiyi Dong", "Kun Xia", "Sanping Zhou", "Wei Tang", "Hua Gang"], "abstract": "World models allow agents to simulate the consequences of actions in imagined environments for planning, control, and long-horizon decision-making. However, existing autoregressive world models struggle with visually coherent predictions due to disrupted spatial structure, inefficient decoding, and inadequate motion modeling. In response, we propose \\textbf{S}cale-wise \\textbf{A}utoregression with \\textbf{M}otion \\textbf{P}r\\textbf{O}mpt (\\textbf{SAMPO}), a hybrid framework that combines visual autoregressive modeling for intra-frame generation with causal modeling for next-frame generation. Specifically, SAMPO integrates temporal causal decoding with bidirectional spatial attention, which preserves spatial locality and supports parallel decoding within each scale. This design significantly enhances both temporal consistency and rollout efficiency. To further improve dynamic scene understanding, we devise an asymmetric multi-scale tokenizer that preserves spatial details in observed frames and extracts compact dynamic representations for future frames, optimizing both memory usage and model performance. Additionally, we introduce a trajectory-aware motion prompt module that injects spatiotemporal cues about object and robot trajectories, focusing attention on dynamic regions and improving temporal consistency and physical realism. Extensive experiments show that SAMPO achieves competitive performance in action-conditioned video prediction and model-based control, improving generation quality with 4.4$\\times$ faster inference. We also evaluate SAMPO's zero-shot generalization and scaling behavior, demonstrating its ability to generalize to unseen tasks and benefit from larger model sizes.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)", "comments": "22 pages,15 figures", "pdf_url": "https://arxiv.org/pdf/2509.15536.pdf", "abstract_url": "https://arxiv.org/abs/2509.15536", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "SAMPO提出了一种混合框架，结合视觉自回归和因果建模，通过尺度级自回归与运动提示，提升世界模型的视觉一致性和效率。", "motivation": "解决现有自回归世界模型在视觉预测中空间结构破坏、解码效率低和运动建模不足的问题。", "method": "使用双向空间注意力和因果解码的混合框架，结合非对称多尺度分词器和轨迹感知运动提示模块。", "result": "实验显示SAMPO在视频预测和控制中性能优异，生成质量提升，推理速度加快4.4倍，并具有良好的泛化能力。", "conclusion": "SAMPO提高了世界模型的时空一致性和效率，支持零样本泛化和模型扩展，适用于长期决策任务。"}}
{"id": "2509.15566", "title": "BTL-UI: Blink-Think-Link Reasoning Model for GUI Agent", "authors": ["Shaojie Zhang", "Ruoceng Zhang", "Pei Fu", "Shaokang Wang", "Jiahui Yang", "Xin Du", "Shiqi Cui", "Bin Qin", "Ying Huang", "Zhenbo Luo", "Jian Luan"], "abstract": "In the field of AI-driven human-GUI interaction automation, while rapid advances in multimodal large language models and reinforcement fine-tuning techniques have yielded remarkable progress, a fundamental challenge persists: their interaction logic significantly deviates from natural human-GUI communication patterns. To fill this gap, we propose \"Blink-Think-Link\" (BTL), a brain-inspired framework for human-GUI interaction that mimics the human cognitive process between users and graphical interfaces. The system decomposes interactions into three biologically plausible phases: (1) Blink - rapid detection and attention to relevant screen areas, analogous to saccadic eye movements; (2) Think - higher-level reasoning and decision-making, mirroring cognitive planning; and (3) Link - generation of executable commands for precise motor control, emulating human action selection mechanisms. Additionally, we introduce two key technical innovations for the BTL framework: (1) Blink Data Generation - an automated annotation pipeline specifically optimized for blink data, and (2) BTL Reward -- the first rule-based reward mechanism that enables reinforcement learning driven by both process and outcome. Building upon this framework, we develop a GUI agent model named BTL-UI, which demonstrates consistent state-of-the-art performance across both static GUI understanding and dynamic interaction tasks in comprehensive benchmarks. These results provide conclusive empirical validation of the framework's efficacy in developing advanced GUI Agents.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": "Accepted at NeurIPS 2025", "pdf_url": "https://arxiv.org/pdf/2509.15566.pdf", "abstract_url": "https://arxiv.org/abs/2509.15566", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出BTL-UI，一种受人类认知启发的GUI代理模型，通过眨眼-思考-链接框架模拟人机交互，在基准测试中表现优异。", "motivation": "解决当前AI驱动的GUI交互模型与自然人类交互模式偏离的问题。", "method": "采用BTL框架，分为眨眼（快速检测）、思考（推理决策）和链接（生成命令）三阶段，并引入眨眼数据生成和BTL奖励机制。", "result": "BTL-UI在静态GUI理解和动态交互任务中实现最先进性能。", "conclusion": "该框架有效提升了GUI代理的交互能力，具有实际应用价值。"}}
{"id": "2509.15291", "title": "The Distribution Shift Problem in Transportation Networks using Reinforcement Learning and AI", "authors": ["Federico Taschin", "Abderrahmane Lazaraq", "Ozan K. Tonguz", "Inci Ozgunes"], "abstract": "The use of Machine Learning (ML) and Artificial Intelligence (AI) in smart transportation networks has increased significantly in the last few years. Among these ML and AI approaches, Reinforcement Learning (RL) has been shown to be a very promising approach by several authors. However, a problem with using Reinforcement Learning in Traffic Signal Control is the reliability of the trained RL agents due to the dynamically changing distribution of the input data with respect to the distribution of the data used for training. This presents a major challenge and a reliability problem for the trained network of AI agents and could have very undesirable and even detrimental consequences if a suitable solution is not found. Several researchers have tried to address this problem using different approaches. In particular, Meta Reinforcement Learning (Meta RL) promises to be an effective solution. In this paper, we evaluate and analyze a state-of-the-art Meta RL approach called MetaLight and show that, while under certain conditions MetaLight can indeed lead to reasonably good results, under some other conditions it might not perform well (with errors of up to 22%), suggesting that Meta RL schemes are often not robust enough and can even pose major reliability problems.", "subjects": "Artificial Intelligence (cs.AI); Systems and Control (eess.SY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.15291.pdf", "abstract_url": "https://arxiv.org/abs/2509.15291", "categories": ["Artificial Intelligence (cs.AI)", "Systems and Control (eess.SY)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文评估了MetaLight这一元强化学习方法在交通信号控制中的表现，发现其在某些条件下效果良好，但在其他条件下误差高达22%，表明元强化学习方案可能不够稳健。", "motivation": "解决强化学习在交通信号控制中因输入数据分布动态变化导致的可靠性问题。", "method": "评估和分析一种名为MetaLight的元强化学习方法。", "result": "MetaLight在某些条件下表现良好，但在其他条件下误差高达22%，显示出可靠性不足。", "conclusion": "元强化学习方案可能不够稳健，需要进一步改进以确保可靠性。"}}
{"id": "2509.15237", "title": "MICA: Multi-Agent Industrial Coordination Assistant", "authors": ["Di Wen", "Kunyu Peng", "Junwei Zheng", "Yufan Chen", "Yitain Shi", "Jiale Wei", "Ruiping Liu", "Kailun Yang", "Rainer Stiefelhagen"], "abstract": "Industrial workflows demand adaptive and trustworthy assistance that can operate under limited computing, connectivity, and strict privacy constraints. In this work, we present MICA (Multi-Agent Industrial Coordination Assistant), a perception-grounded and speech-interactive system that delivers real-time guidance for assembly, troubleshooting, part queries, and maintenance. MICA coordinates five role-specialized language agents, audited by a safety checker, to ensure accurate and compliant support. To achieve robust step understanding, we introduce Adaptive Step Fusion (ASF), which dynamically blends expert reasoning with online adaptation from natural speech feedback. Furthermore, we establish a new multi-agent coordination benchmark across representative task categories and propose evaluation metrics tailored to industrial assistance, enabling systematic comparison of different coordination topologies. Our experiments demonstrate that MICA consistently improves task success, reliability, and responsiveness over baseline structures, while remaining deployable on practical offline hardware. Together, these contributions highlight MICA as a step toward deployable, privacy-preserving multi-agent assistants for dynamic factory environments. The source code will be made publicly available at", "subjects": "Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2509.15237.pdf", "abstract_url": "https://arxiv.org/abs/2509.15237", "categories": ["Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了MICA，一种用于工业环境的感知基础和语音交互的多代理协调助手，通过自适应步骤融合和角色专业化代理提高任务成功率和可靠性。", "motivation": "解决工业工作流在有限计算、连接性和严格隐私约束下对自适应、可信赖辅助的需求。", "method": "使用五个角色专业化语言代理，结合安全检查器和自适应步骤融合（ASF）方法，动态整合专家推理和语音反馈。", "result": "实验表明，MICA在任务成功率、可靠性和响应性上优于基线结构，并可在离线硬件上部署。", "conclusion": "MICA是实现可部署、隐私保护的多代理助手的重要一步，适用于动态工厂环境。"}}
{"id": "2509.15366", "title": "Diagnostics of cognitive failures in multi-agent expert systems using dynamic evaluation protocols and subsequent mutation of the processing context", "authors": ["Andrejs Sorstkins", "Josh Bailey", "Dr Alistair Baron"], "abstract": "The rapid evolution of neural architectures - from multilayer perceptrons to large-scale Transformer-based models - has enabled language models (LLMs) to exhibit emergent agentic behaviours when equipped with memory, planning, and external tool use. However, their inherent stochasticity and multi-step decision processes render classical evaluation methods inadequate for diagnosing agentic performance. This work introduces a diagnostic framework for expert systems that not only evaluates but also facilitates the transfer of expert behaviour into LLM-powered agents. The framework integrates (i) curated golden datasets of expert annotations, (ii) silver datasets generated through controlled behavioural mutation, and (iii) an LLM-based Agent Judge that scores and prescribes targeted improvements. These prescriptions are embedded into a vectorized recommendation map, allowing expert interventions to propagate as reusable improvement trajectories across multiple system instances. We demonstrate the framework on a multi-agent recruiter-assistant system, showing that it uncovers latent cognitive failures - such as biased phrasing, extraction drift, and tool misrouting - while simultaneously steering agents toward expert-level reasoning and style. The results establish a foundation for standardized, reproducible expert behaviour transfer in stochastic, tool-augmented LLM agents, moving beyond static evaluation to active expert system refinement.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "Dissertation and research project created in collaboration with JobFair LTD", "pdf_url": "https://arxiv.org/pdf/2509.15366.pdf", "abstract_url": "https://arxiv.org/abs/2509.15366", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种诊断框架，用于评估和改进基于LLM的专家系统，通过动态协议和上下文突变来识别认知失败并促进专家行为转移。", "motivation": "解决传统评估方法在诊断随机性、多步决策的LLM代理性能方面的不足，以提升专家系统的可靠性和行为转移。", "method": "整合黄金数据集、行为突变生成的银数据集和LLM代理评判器，构建向量化推荐图来嵌入改进建议。", "result": "在招聘助理系统中成功识别了偏见措辞等认知失败，并引导代理达到专家级推理和风格。", "conclusion": "该框架为随机、工具增强的LLM代理提供了标准化、可复制的专家行为转移基础，推动了主动系统优化。"}}
{"id": "2509.15730", "title": "A Nascent Taxonomy of Machine Learning in Intelligent Robotic Process Automation", "authors": ["Lukas Laakmann", "Seyyid A. Ciftci", "Christian Janiesch"], "abstract": "Robotic process automation (RPA) is a lightweight approach to automating business processes using software robots that emulate user actions at the graphical user interface level. While RPA has gained popularity for its cost-effective and timely automation of rule-based, well-structured tasks, its symbolic nature has inherent limitations when approaching more complex tasks currently performed by human agents. Machine learning concepts enabling intelligent RPA provide an opportunity to broaden the range of automatable tasks. In this paper, we conduct a literature review to explore the connections between RPA and machine learning and organize the joint concept intelligent RPA into a taxonomy. Our taxonomy comprises the two meta-characteristics RPA-ML integration and RPA-ML interaction. Together, they comprise eight dimensions: architecture and ecosystem, capabilities, data basis, intelligence level, and technical depth of integration as well as deployment environment, lifecycle phase, and user-robot relation.", "subjects": "Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.15730.pdf", "abstract_url": "https://arxiv.org/abs/2509.15730", "categories": ["Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过文献综述探讨了机器人流程自动化与机器学习的联系，提出了智能RPA的分类法，包含集成和交互两个元特征及八个维度。", "motivation": "解决RPA在复杂任务中的局限性，通过机器学习扩展自动化范围。", "method": "进行文献综述，构建智能RPA的分类法，基于RPA-ML集成和交互元特征。", "result": "建立了包含八个维度的分类法，如架构、能力、数据基础等。", "conclusion": "分类法有助于理解和应用智能RPA，推动更广泛的任务自动化。"}}
{"id": "2509.15635", "title": "MicroRCA-Agent: Microservice Root Cause Analysis Method Based on Large Language Model Agents", "authors": ["Pan Tang", "Shixiang Tang", "Huanqi Pu", "Zhiqing Miao", "Zhixing Wang"], "abstract": "This paper presents MicroRCA-Agent, an innovative solution for microservice root cause analysis based on large language model agents, which constructs an intelligent fault root cause localization system with multimodal data fusion. The technical innovations are embodied in three key aspects: First, we combine the pre-trained Drain log parsing algorithm with multi-level data filtering mechanism to efficiently compress massive logs into high-quality fault features. Second, we employ a dual anomaly detection approach that integrates Isolation Forest unsupervised learning algorithms with status code validation to achieve comprehensive trace anomaly identification. Third, we design a statistical symmetry ratio filtering mechanism coupled with a two-stage LLM analysis strategy to enable full-stack phenomenon summarization across node-service-pod hierarchies. The multimodal root cause analysis module leverages carefully designed cross-modal prompts to deeply integrate multimodal anomaly information, fully exploiting the cross-modal understanding and logical reasoning capabilities of large language models to generate structured analysis results encompassing fault components, root cause descriptions, and reasoning trace. Comprehensive ablation studies validate the complementary value of each modal data and the effectiveness of the system architecture. The proposed solution demonstrates superior performance in complex microservice fault scenarios, achieving a final score of 50.71. The code has been released at:", "subjects": "Artificial Intelligence (cs.AI)", "comments": "18 pages, 22 figures", "pdf_url": "https://arxiv.org/pdf/2509.15635.pdf", "abstract_url": "https://arxiv.org/abs/2509.15635", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出MicroRCA-Agent，一种基于大语言模型代理的微服务根因分析方法，通过多模态数据融合实现智能故障定位，在复杂场景中表现优异。", "motivation": "解决微服务系统中故障根因定位的挑战，传统方法难以处理大规模日志和多模态数据。", "method": "结合Drain日志解析、双异常检测和两阶段LLM分析，利用多模态提示进行根因分析。", "result": "系统在微服务故障场景中表现优越，最终得分50.71，消融研究验证了各模块的有效性。", "conclusion": "MicroRCA-Agent通过创新方法有效提升故障分析能力，代码已开源，具有实际应用价值。"}}
{"id": "2509.15541", "title": "Stress Testing Deliberative Alignment for Anti-Scheming Training", "authors": ["Bronson Schoen", "Evgenia Nitishinskaya", "Mikita Balesni", "Axel Højmark", "Felix Hofstätter", "Jérémy Scheurer", "Alexander Meinke", "Jason Wolfe", "Teun van der Weij", "Alex Lloyd", "Nicholas Goldowsky-Dill", "Angela Fan", "Andrei Matveiakin", "Rusheb Shah", "Marcus Williams", "Amelia Glaese", "Boaz Barak", "Wojciech Zaremba", "Marius Hobbhahn"], "abstract": "Highly capable AI systems could secretly pursue misaligned goals -- what we call \"scheming\". Because a scheming AI would deliberately try to hide its misaligned goals and actions, measuring and mitigating scheming requires different strategies than are typically used in ML. We propose that assessing anti-scheming interventions requires at least (1) testing propensity to scheme on far out-of-distribution (OOD) tasks, (2) evaluating whether lack of scheming is driven by situational awareness, and (3) checking for robustness to pre-existing misaligned goals. We use a broad category of \"covert actions\" -- such as secretly breaking rules or intentionally underperforming in tests -- as a proxy for scheming, and design evaluations for covert actions. We then stress-test deliberative alignment as a case study for anti-scheming. Across 26 OOD evaluations (180+ environments), deliberative alignment reduces covert action rates (OpenAI o3: 13%->0.4%) but does not fully eliminate them. Our mitigation is also able to largely stop agents from pursuing a hidden goal previously trained into the model, but we still find misbehavior after additional red-teaming. We find that models' chain-of-thought (CoT) often demonstrates awareness of being evaluated for alignment, and show causal evidence that this awareness decreases covert behavior, while unawareness increases it. Therefore, we cannot exclude that the observed reductions in covert action rates are at least partially driven by situational awareness. While we rely on human-legible CoT for training, studying situational awareness, and demonstrating clear evidence of misalignment, our ability to rely on this degrades as models continue to depart from reasoning in standard English. We encourage research into alignment mitigations for scheming and their assessment, especially for the adversarial case of deceptive alignment, which this paper does not address.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.15541.pdf", "abstract_url": "https://arxiv.org/abs/2509.15541", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出针对AI系统可能秘密追求未对齐目标（即“策划”）的问题，通过测试离群任务、评估情境意识和对现有未对齐目标的鲁棒性来评估反策划干预措施。以隐蔽动作为代理，研究审议对齐方法，在26个离群评估中显著减少隐蔽动作，但未完全消除，且情境意识可能影响结果。", "motivation": "解决高度能力AI系统可能秘密追求未对齐目标（策划）的问题，因为策划行为会故意隐藏，需要不同于传统ML的策略来测量和缓解。", "method": "使用隐蔽动作（如秘密违反规则或故意测试表现不佳）作为策划的代理，设计评估方法，包括测试离群任务、检查情境意识和鲁棒性，并以审议对齐作为案例研究进行压力测试。", "result": "在26个离群评估中，审议对齐将隐蔽动作率从13%降至0.4%，但未完全消除；能阻止模型追求预先训练的隐藏目标，但红队测试后仍有不当行为；情境意识减少隐蔽行为，无意识增加它。", "conclusion": "审议对齐可减少策划行为，但情境意识可能部分驱动结果，且依赖人类可读思维链的局限性随模型发展而增加；鼓励进一步研究对齐缓解措施，特别是针对欺骗性对齐。"}}
{"id": "2509.15786", "title": "Building Data-Driven Occupation Taxonomies: A Bottom-Up Multi-Stage Approach via Semantic Clustering and Multi-Agent Collaboration", "authors": ["Nan Li", "Bo Kang", "Tijl De Bie"], "abstract": "Creating robust occupation taxonomies, vital for applications ranging from job recommendation to labor market intelligence, is challenging. Manual curation is slow, while existing automated methods are either not adaptive to dynamic regional markets (top-down) or struggle to build coherent hierarchies from noisy data (bottom-up). We introduce CLIMB (CLusterIng-based Multi-agent taxonomy Builder), a framework that fully automates the creation of high-quality, data-driven taxonomies from raw job postings. CLIMB uses global semantic clustering to distill core occupations, then employs a reflection-based multi-agent system to iteratively build a coherent hierarchy. On three diverse, real-world datasets, we show that CLIMB produces taxonomies that are more coherent and scalable than existing methods and successfully capture unique regional characteristics. We release our code and datasets at", "subjects": "Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.15786.pdf", "abstract_url": "https://arxiv.org/abs/2509.15786", "categories": ["Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍CLIMB框架，通过语义聚类和多智能体协作自下而上自动化构建高质量职业分类法，优于现有方法。", "motivation": "解决手动构建职业分类法缓慢，以及现有自动化方法不适应动态区域市场或难以从噪声数据构建一致层次结构的问题。", "method": "使用全局语义聚类提取核心职业，然后通过基于反思的多智能体系统迭代构建一致层次结构。", "result": "在三个真实数据集上，CLIMB生成的分类法比现有方法更一致、可扩展，并成功捕捉区域独特性。", "conclusion": "CLIMB框架能有效自动化创建数据驱动的职业分类法，具有实际应用价值。"}}
{"id": "2509.15518", "title": "How do Language Models Generate Slang: A Systematic Comparison between Human and Machine-Generated Slang Usages", "authors": ["Siyang Wu", "Zhewei Sun"], "abstract": "Slang is a commonly used type of informal language that poses a daunting challenge to NLP systems. Recent advances in large language models (LLMs), however, have made the problem more approachable. While LLM agents are becoming more widely applied to intermediary tasks such as slang detection and slang interpretation, their generalizability and reliability are heavily dependent on whether these models have captured structural knowledge about slang that align well with human attested slang usages. To answer this question, we contribute a systematic comparison between human and machine-generated slang usages. Our evaluative framework focuses on three core aspects: 1) Characteristics of the usages that reflect systematic biases in how machines perceive slang, 2) Creativity reflected by both lexical coinages and word reuses employed by the slang usages, and 3) Informativeness of the slang usages when used as gold-standard examples for model distillation. By comparing human-attested slang usages from the Online Slang Dictionary (OSD) and slang generated by GPT-4o and Llama-3, we find significant biases in how LLMs perceive slang. Our results suggest that while LLMs have captured significant knowledge about the creative aspects of slang, such knowledge does not align with humans sufficiently to enable LLMs for extrapolative tasks such as linguistic analyses.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.15518.pdf", "abstract_url": "https://arxiv.org/abs/2509.15518", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文系统比较了人类与机器生成的俚语使用，发现LLMs在俚语生成中存在偏见，虽具创造性但与人脑对齐不足，影响其在语言分析等任务中的可靠性。", "motivation": "解决LLMs是否准确捕捉俚语结构知识以提升其在俚语检测和解释等任务中的泛化性和可靠性问题。", "method": "通过比较在线俚语词典的人类俚语与GPT-4o和Llama-3生成的俚语，评估系统性偏见、创造性和信息性。", "result": "LLMs在俚语生成中表现出显著偏见，虽具创造性知识，但与人脑对齐不充分，限制了其外推任务能力。", "conclusion": "LLMs的俚语知识不足以支持语言分析等外推任务，需改进对齐以提升应用效果。"}}
{"id": "2509.15568", "title": "LiteLong: Resource-Efficient Long-Context Data Synthesis for LLMs", "authors": ["Junlong Jia", "Xing Wu", "Chaochen Gao", "Ziyang Chen", "Zijia Lin", "Zhongzhi Li", "Weinong Wang", "Haotian Xu", "Donghui Jin", "Debing Zhang", "Binghui Guo"], "abstract": "High-quality long-context data is essential for training large language models (LLMs) capable of processing extensive documents, yet existing synthesis approaches using relevance-based aggregation face challenges of computational efficiency. We present LiteLong, a resource-efficient method for synthesizing long-context data through structured topic organization and multi-agent debate. Our approach leverages the BISAC book classification system to provide a comprehensive hierarchical topic organization, and then employs a debate mechanism with multiple LLMs to generate diverse, high-quality topics within this structure. For each topic, we use lightweight BM25 retrieval to obtain relevant documents and concatenate them into 128K-token training samples. Experiments on HELMET and Ruler benchmarks demonstrate that LiteLong achieves competitive long-context performance and can seamlessly integrate with other long-dependency enhancement methods. LiteLong makes high-quality long-context data synthesis more accessible by reducing both computational and data engineering costs, facilitating further research in long-context language training.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "work in progress", "pdf_url": "https://arxiv.org/pdf/2509.15568.pdf", "abstract_url": "https://arxiv.org/abs/2509.15568", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "LiteLong是一种资源高效的方法，通过结构化主题组织和多智能体辩论合成高质量长上下文数据，用于训练大语言模型，降低计算成本。", "motivation": "现有基于相关性的长上下文数据合成方法计算效率低，限制了长文档处理能力的研究。", "method": "利用BISAC分类系统组织主题，多智能体辩论生成多样化主题，轻量级BM25检索文档并拼接成128K标记样本。", "result": "在HELMET和Ruler基准测试中，LiteLong实现竞争性长上下文性能，并能与其他长依赖增强方法无缝集成。", "conclusion": "LiteLong使高质量长上下文数据合成更易获取，减少计算和数据工程成本，促进长上下文语言训练研究。"}}
{"id": "2509.15577", "title": "Relevance to Utility: Process-Supervised Rewrite for RAG", "authors": ["Jaeyoung Kim", "Jongho Kim", "Seung-won Hwang", "Seoho Song", "Young-In Song"], "abstract": "Retrieval-Augmented Generation systems often suffer from a gap between optimizing retrieval relevance and generative utility: retrieved documents may be topically relevant but still lack the content needed for effective reasoning during generation. While existing \"bridge\" modules attempt to rewrite the retrieved text for better generation, we show how they fail to capture true document utility. In this work, we propose R2U, with a key distinction of directly optimizing to maximize the probability of generating a correct answer through process supervision. As such direct observation is expensive, we also propose approximating an efficient distillation pipeline by scaling the supervision from LLMs, which helps the smaller rewriter model generalize better. We evaluate our method across multiple open-domain question-answering benchmarks. The empirical results demonstrate consistent improvements over strong bridging baselines.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.15577.pdf", "abstract_url": "https://arxiv.org/abs/2509.15577", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出R2U方法，通过过程监督直接优化检索增强生成中的重写模块，以提升生成效用，而非仅关注检索相关性。", "motivation": "解决检索增强生成系统中检索相关性与生成效用之间的差距问题，现有桥接模块未能有效捕获文档的真实效用。", "method": "使用过程监督直接最大化生成正确答案的概率，并通过LLM监督的蒸馏管道进行高效近似，使小模型更好泛化。", "result": "在多个开放域问答基准测试中，R2U方法相比强基线实现了持续改进。", "conclusion": "R2U通过过程监督优化重写过程，显著提升生成性能，为RAG系统提供了更有效的桥接方法。"}}
{"id": "2509.15238", "title": "Generating Plans for Belief-Desire-Intention (BDI) Agents Using Alternating-Time Temporal Logic (ATL)", "authors": ["Dylan Léveillé"], "abstract": "Belief-Desire-Intention (BDI) is a framework for modelling agents based on their beliefs, desires, and intentions. Plans are a central component of BDI agents, and define sequences of actions that an agent must undertake to achieve a certain goal. Existing approaches to plan generation often require significant manual effort, and are mainly focused on single-agent systems. As a result, in this work, we have developed a tool that automatically generates BDI plans using Alternating-Time Temporal Logic (ATL). By using ATL, the plans generated accommodate for possible competition or cooperation between the agents in the system. We demonstrate the effectiveness of the tool by generating plans for an illustrative game that requires agent collaboration to achieve a shared goal. We show that the generated plans allow the agents to successfully attain this goal.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2509.15238.pdf", "abstract_url": "https://arxiv.org/abs/2509.15238", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种使用交替时间时序逻辑（ATL）自动生成BDI代理计划的工具，以处理多代理系统中的竞争或合作。", "motivation": "解决BDI代理计划生成中手动工作量大且主要针对单代理系统的问题。", "method": "开发基于ATL的工具，自动生成计划，适应代理间的竞争或合作。", "result": "通过示例游戏演示，生成的计划使代理成功实现共享目标。", "conclusion": "该方法有效支持多代理协作，扩展了BDI框架的应用。"}}
{"id": "2509.16011", "title": "Towards Robust Visual Continual Learning with Multi-Prototype Supervision", "authors": ["Xiwei Liu", "Yulong Li", "Yichen Li", "Xinlin Zhuang", "Haolin Yang", "Huifa Li", "Imran Razzak"], "abstract": "Language-guided supervision, which utilizes a frozen semantic target from a Pretrained Language Model (PLM), has emerged as a promising paradigm for visual Continual Learning (CL). However, relying on a single target introduces two critical limitations: 1) semantic ambiguity, where a polysemous category name results in conflicting visual representations, and 2) intra-class visual diversity, where a single prototype fails to capture the rich variety of visual appearances within a class. To this end, we propose MuproCL, a novel framework that replaces the single target with multiple, context-aware prototypes. Specifically, we employ a lightweight LLM agent to perform category disambiguation and visual-modal expansion to generate a robust set of semantic prototypes. A LogSumExp aggregation mechanism allows the vision model to adaptively align with the most relevant prototype for a given image. Extensive experiments across various CL baselines demonstrate that MuproCL consistently enhances performance and robustness, establishing a more effective path for language-guided continual learning.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.16011.pdf", "abstract_url": "https://arxiv.org/abs/2509.16011", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出MuproCL框架，通过多原型监督解决视觉持续学习中的语义歧义和类内多样性问题，利用LLM生成上下文感知原型，提升模型性能。", "motivation": "解决语言引导监督在视觉持续学习中因单一目标导致的语义歧义和类内视觉多样性不足的问题。", "method": "使用轻量级LLM代理进行类别消歧和视觉模态扩展，生成多原型，并通过LogSumExp机制自适应对齐图像与原型。", "result": "实验表明，MuproCL在各种持续学习基准上一致提高了性能和鲁棒性。", "conclusion": "MuproCL为语言引导的持续学习提供了更有效的路径，增强了模型的适应性和准确性。"}}
{"id": "2509.16095", "title": "AdaSports-Traj: Role- and Domain-Aware Adaptation for Multi-Agent Trajectory Modeling in Sports", "authors": ["Yi Xu", "Yun Fu"], "abstract": "Trajectory prediction in multi-agent sports scenarios is inherently challenging due to the structural heterogeneity across agent roles (e.g., players vs. ball) and dynamic distribution gaps across different sports domains. Existing unified frameworks often fail to capture these structured distributional shifts, resulting in suboptimal generalization across roles and domains. We propose AdaSports-Traj, an adaptive trajectory modeling framework that explicitly addresses both intra-domain and inter-domain distribution discrepancies in sports. At its core, AdaSports-Traj incorporates a Role- and Domain-Aware Adapter to conditionally adjust latent representations based on agent identity and domain context. Additionally, we introduce a Hierarchical Contrastive Learning objective, which separately supervises role-sensitive and domain-aware representations to encourage disentangled latent structures without introducing optimization conflict. Experiments on three diverse sports datasets, Basketball-U, Football-U, and Soccer-U, demonstrate the effectiveness of our adaptive design, achieving strong performance in both unified and cross-domain trajectory prediction settings.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "Accepted by ICDM 2025", "pdf_url": "https://arxiv.org/pdf/2509.16095.pdf", "abstract_url": "https://arxiv.org/abs/2509.16095", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "AdaSports-Traj是一个自适应多智能体轨迹建模框架，通过角色和领域感知适配器及分层对比学习，解决体育中轨迹预测的结构异质性和分布差异问题。", "motivation": "现有统一框架难以处理体育场景中智能体角色（如球员与球）和不同运动领域间的分布差异，导致泛化性能不佳。", "method": "采用角色和领域感知适配器调整潜在表示，并引入分层对比学习目标，分别监督角色敏感和领域感知表示以避免优化冲突。", "result": "在Basketball-U、Football-U和Soccer-U数据集上实验显示，该框架在统一和跨域轨迹预测中表现优异。", "conclusion": "AdaSports-Traj通过自适应设计有效提升了多智能体轨迹预测的泛化能力，适用于多样化体育领域。"}}
{"id": "2509.15440", "title": "Where Do I 'Add the Egg'?: Exploring Agency and Ownership in AI Creative Co-Writing Systems", "authors": ["Dashiel Carrera", "Jeb Thomas-Mitchell", "Daniel Wigdor"], "abstract": "AI co-writing systems challenge long held ideals about agency and ownership in the creative process, thereby hindering widespread adoption. In order to address this, we investigate conceptions of agency and ownership in AI creative co-writing. Drawing on insights from a review of commercial systems, we developed three co-writing systems with identical functionality but distinct interface metaphors: agentic, tool-like, and magical. Through interviews with professional and non-professional writers (n = 18), we explored how these metaphors influenced participants' sense of control and authorship. Our analysis resulted in a taxonomy of agency and ownership subtypes and underscore how tool-like metaphors shift writers' expected points of control while agentic metaphors foreground conceptual contributions. We argue that interface metaphors not only guide expectations of control but also frame conceptions of authorship. We conclude with recommendations for the design of AI co-writing systems, emphasizing how metaphor shapes user experience and creative practice.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": "17 pages, 3 figures, 3 tables", "pdf_url": "https://arxiv.org/pdf/2509.15440.pdf", "abstract_url": "https://arxiv.org/abs/2509.15440", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文探讨AI创意协作写作系统中用户代理权和所有权的概念，通过开发三种界面隐喻系统并进行用户访谈，发现工具隐喻改变控制点，代理隐喻突出概念贡献，强调隐喻对用户体验和创作实践的影响。", "motivation": "解决AI协作写作系统因挑战传统创意过程中的代理权和所有权观念而阻碍广泛采用的问题。", "method": "回顾商业系统，开发功能相同但界面隐喻不同的三种协作写作系统（代理式、工具式、魔法式），并对18名专业和非专业作家进行访谈。", "result": "分析得出代理权和所有权的子类型分类，工具隐喻转移控制点，代理隐喻强调概念贡献，界面隐喻影响用户控制预期和作者权观念。", "conclusion": "界面隐喻指导控制预期并构建作者权概念，建议AI协作写作系统设计应注重隐喻对用户体验和创意实践的影响。"}}
{"id": "2509.16112", "title": "CodeRAG: Finding Relevant and Necessary Knowledge for Retrieval-Augmented Repository-Level Code Completion", "authors": ["Sheng Zhang", "Yifan Ding", "Shuquan Lian", "Shun Song", "Hui Li"], "abstract": "Repository-level code completion automatically predicts the unfinished code based on the broader information from the repository. Recent strides in Code Large Language Models (code LLMs) have spurred the development of repository-level code completion methods, yielding promising results. Nevertheless, they suffer from issues such as inappropriate query construction, single-path code retrieval, and misalignment between code retriever and code LLM. To address these problems, we introduce CodeRAG, a framework tailored to identify relevant and necessary knowledge for retrieval-augmented repository-level code completion. Its core components include log probability guided query construction, multi-path code retrieval, and preference-aligned BestFit reranking. Extensive experiments on benchmarks ReccEval and CCEval demonstrate that CodeRAG significantly and consistently outperforms state-of-the-art methods. The implementation of CodeRAG is available at", "subjects": "Computation and Language (cs.CL); Information Retrieval (cs.IR); Software Engineering (cs.SE)", "comments": "EMNLP 2025", "pdf_url": "https://arxiv.org/pdf/2509.16112.pdf", "abstract_url": "https://arxiv.org/abs/2509.16112", "categories": ["Computation and Language (cs.CL)", "Information Retrieval (cs.IR)", "Software Engineering (cs.SE)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "CodeRAG是一个用于检索增强的仓库级代码补全的框架，通过改进查询构建、多路径代码检索和重排序来提升性能，在基准测试中表现优于现有方法。", "motivation": "解决现有仓库级代码补全方法中查询构建不当、单路径代码检索以及代码检索器与代码LLM不匹配的问题。", "method": "使用对数概率指导的查询构建、多路径代码检索和偏好对齐的BestFit重排序。", "result": "在ReccEval和CCEval基准测试中，CodeRAG显著且一致地优于最先进方法。", "conclusion": "CodeRAG能有效识别相关和必要的知识，提升代码补全性能，其实现已开源。"}}
{"id": "2509.15233", "title": "Video2Roleplay: A Multimodal Dataset and Framework for Video-Guided Role-playing Agents", "authors": ["Xueqiao Zhang", "Chao Zhang", "Jingtao Xu", "Yifan Zhu", "Xin Shi", "Yi Yang", "Yawei Luo"], "abstract": "Role-playing agents (RPAs) have attracted growing interest for their ability to simulate immersive and interactive characters. However, existing approaches primarily focus on static role profiles, overlooking the dynamic perceptual abilities inherent to humans. To bridge this gap, we introduce the concept of dynamic role profiles by incorporating video modality into RPAs. To support this, we construct Role-playing-Video60k, a large-scale, high-quality dataset comprising 60k videos and 700k corresponding dialogues. Based on this dataset, we develop a comprehensive RPA framework that combines adaptive temporal sampling with both dynamic and static role profile representations. Specifically, the dynamic profile is created by adaptively sampling video frames and feeding them to the LLM in temporal order, while the static profile consists of (1) character dialogues from training videos during fine-tuning, and (2) a summary context from the input video during inference. This joint integration enables RPAs to generate greater responses. Furthermore, we propose a robust evaluation method covering eight metrics. Experimental results demonstrate the effectiveness of our framework, highlighting the importance of dynamic role profiles in developing RPAs.", "subjects": "Multimedia (cs.MM); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)", "comments": "Accepted at EMNLP2025 Main", "pdf_url": "https://arxiv.org/pdf/2509.15233.pdf", "abstract_url": "https://arxiv.org/abs/2509.15233", "categories": ["Multimedia (cs.MM)", "Computation and Language (cs.CL)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍Video2Roleplay框架，通过视频模态增强角色扮演代理的动态感知能力，构建大规模数据集并开发结合动态和静态角色配置的方法，实验证明其有效性。", "motivation": "解决现有角色扮演代理依赖静态角色配置，缺乏人类动态感知能力的问题。", "method": "构建Role-playing-Video60k数据集，结合自适应时间采样、动态角色配置（视频帧输入LLM）和静态角色配置（对话和摘要）。", "result": "实验结果显示框架有效，动态角色配置对提升角色扮演代理性能至关重要。", "conclusion": "动态角色配置是开发角色扮演代理的关键，该方法具有重要应用价值。"}}
{"id": "2509.16198", "title": "RPG: A Repository Planning Graph for Unified and Scalable Codebase Generation", "authors": ["Jane Luo", "Xin Zhang", "Steven Liu", "Jie Wu", "Yiming Huang", "Yangyu Huang", "Chengyu Yin", "Ying Xin", "Jianfeng Liu", "Yuefeng Zhan", "Hao Sun", "Qi Chen", "Scarlett Li", "Mao Yang"], "abstract": "Large language models excel at function- and file-level code generation, yet generating complete repositories from scratch remains a fundamental challenge. This process demands coherent and reliable planning across proposal- and implementation-level stages, while natural language, due to its ambiguity and verbosity, is ill-suited for faithfully representing complex software structures. To address this, we introduce the Repository Planning Graph (RPG), a persistent representation that unifies proposal- and implementation-level planning by encoding capabilities, file structures, data flows, and functions in one graph. RPG replaces ambiguous natural language with an explicit blueprint, enabling long-horizon planning and scalable repository generation. Building on RPG, we develop ZeroRepo, a graph-driven framework for repository generation from scratch. It operates in three stages: proposal-level planning and implementation-level refinement to construct the graph, followed by graph-guided code generation with test validation. To evaluate this setting, we construct RepoCraft, a benchmark of six real-world projects with 1,052 tasks. On RepoCraft, ZeroRepo produces repositories averaging nearly 36K LOC, roughly 3.9$\\times$ the strongest baseline (Claude Code) and about 64$\\times$ other baselines. It attains 81.5% functional coverage and a 69.7% pass rate, exceeding Claude Code by 27.3 and 35.8 percentage points, respectively. Further analysis shows that RPG models complex dependencies, enables progressively more sophisticated planning through near-linear scaling, and enhances LLM understanding of repositories, thereby accelerating agent localization.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Software Engineering (cs.SE)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.16198.pdf", "abstract_url": "https://arxiv.org/abs/2509.16198", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Software Engineering (cs.SE)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出RPG（Repository Planning Graph）和ZeroRepo框架，用于从零生成完整代码库，通过图形化表示统一规划和实现，在RepoCraft基准测试中显著优于基线模型。", "motivation": "解决大型语言模型在生成完整代码库时面临的挑战，如自然语言的模糊性和冗长性，导致规划和实现阶段不连贯。", "method": "使用RPG作为持久表示，统一编码能力、文件结构等；ZeroRepo框架分三阶段：规划、细化和图形引导的代码生成与测试验证。", "result": "在RepoCraft基准上，ZeroRepo生成代码库平均约36K行，功能覆盖率和通过率分别达81.5%和69.7%，远超基线模型。", "conclusion": "RPG能有效建模复杂依赖，实现可扩展规划，提升LLM对代码库的理解，加速代理定位。"}}
{"id": "2509.15491", "title": "Explainable AI-Enhanced Supervisory Control for Robust Multi-Agent Robotic Systems", "authors": ["Reza Pirayeshshirazinezhad", "Nima Fathi"], "abstract": "We present an explainable AI-enhanced supervisory control framework for multi-agent robotics that combines (i) a timed-automata supervisor for safe, auditable mode switching, (ii) robust continuous control (Lyapunov-based controller for large-angle maneuver; sliding-mode controller (SMC) with boundary layers for precision and disturbance rejection), and (iii) an explainable predictor that maps mission context to gains and expected performance (energy, error). Monte Carlo-driven optimization provides the training data, enabling transparent real-time trade-offs.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Systems and Control (eess.SY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.15491.pdf", "abstract_url": "https://arxiv.org/abs/2509.15491", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Systems and Control (eess.SY)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种可解释AI增强的监督控制框架，用于多智能体机器人系统，结合定时自动机监督、鲁棒连续控制和可解释预测器，通过蒙特卡洛优化实现透明实时权衡。", "motivation": "解决多智能体机器人系统在安全、鲁棒性和可解释性方面的挑战，确保系统在复杂任务中可靠且透明。", "method": "使用定时自动机监督器进行安全模式切换，鲁棒连续控制器（如Lyapunov和滑模控制）处理运动和扰动，结合可解释预测器映射任务上下文到控制参数，通过蒙特卡洛优化生成训练数据。", "result": "框架实现了安全模式切换、高精度控制和扰动抑制，可解释预测器提供了性能权衡的透明度。", "conclusion": "该框架增强了多智能体机器人系统的鲁棒性和可解释性，为实际应用提供了可靠且透明的控制解决方案。"}}
{"id": "2509.16189", "title": "Latent learning: episodic memory complements parametric learning by enabling flexible reuse of experiences", "authors": ["Andrew Kyle Lampinen", "Martin Engelcke", "Yuxuan Li", "Arslan Chaudhry", "James L. McClelland"], "abstract": "When do machine learning systems fail to generalize, and what mechanisms could improve their generalization? Here, we draw inspiration from cognitive science to argue that one weakness of machine learning systems is their failure to exhibit latent learning -- learning information that is not relevant to the task at hand, but that might be useful in a future task. We show how this perspective links failures ranging from the reversal curse in language modeling to new findings on agent-based navigation. We then highlight how cognitive science points to episodic memory as a potential part of the solution to these issues. Correspondingly, we show that a system with an oracle retrieval mechanism can use learning experiences more flexibly to generalize better across many of these challenges. We also identify some of the essential components for effectively using retrieval, including the importance of within-example in-context learning for acquiring the ability to use information across retrieved examples. In summary, our results illustrate one possible contributor to the relative data inefficiency of current machine learning systems compared to natural intelligence, and help to understand how retrieval methods can complement parametric learning to improve generalization.", "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.16189.pdf", "abstract_url": "https://arxiv.org/abs/2509.16189", "categories": ["Machine Learning (cs.LG)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文从认知科学角度探讨机器学习泛化失败的原因，提出潜在学习和情景记忆作为解决方案，通过检索机制提高数据利用效率和泛化能力。", "motivation": "解决机器学习系统泛化能力差、数据效率低的问题，特别是在任务无关信息学习（潜在学习）方面的缺陷。", "method": "结合认知科学理论，使用带检索机制的系统，包括oracle检索和示例内上下文学习，以灵活重用经验。", "result": "检索机制能改善语言建模和导航任务中的泛化失败，如逆转诅咒问题，提高学习效率。", "conclusion": "情景记忆和检索方法可补充参数学习，提升机器学习系统的泛化能力和数据效率，接近自然智能水平。"}}
{"id": "2509.15799", "title": "Hierarchical Reinforcement Learning with Low-Level MPC for Multi-Agent Control", "authors": ["Max Studt", "Georg Schildbach"], "abstract": "Achieving safe and coordinated behavior in dynamic, constraint-rich environments remains a major challenge for learning-based control. Pure end-to-end learning often suffers from poor sample efficiency and limited reliability, while model-based methods depend on predefined references and struggle to generalize. We propose a hierarchical framework that combines tactical decision-making via reinforcement learning (RL) with low-level execution through Model Predictive Control (MPC). For the case of multi-agent systems this means that high-level policies select abstract targets from structured regions of interest (ROIs), while MPC ensures dynamically feasible and safe motion. Tested on a predator-prey benchmark, our approach outperforms end-to-end and shielding-based RL baselines in terms of reward, safety, and consistency, underscoring the benefits of combining structured learning with model-based control.", "subjects": "Systems and Control (eess.SY); Artificial Intelligence (cs.AI); Robotics (cs.RO); Optimization and Control (math.OC)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.15799.pdf", "abstract_url": "https://arxiv.org/abs/2509.15799", "categories": ["Systems and Control (eess.SY)", "Artificial Intelligence (cs.AI)", "Robotics (cs.RO)", "Optimization and Control (math.OC)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种分层强化学习框架，将高层RL决策与低层MPC控制结合，用于多智能体系统，在捕食者-猎物基准测试中表现优于基线方法。", "motivation": "解决动态约束环境中学习型控制的安全和协调问题，纯端到端学习方法样本效率低、可靠性差，而基于模型的方法依赖预定义参考且泛化能力不足。", "method": "使用分层框架：高层RL进行战术决策选择抽象目标，低层MPC确保动态可行和安全的运动执行。", "result": "在捕食者-猎物基准测试中，该方法在奖励、安全性和一致性方面优于端到端和屏蔽式RL基线。", "conclusion": "结合结构化学习与基于模型的控制具有显著优势，能提高多智能体控制的性能和可靠性。"}}
{"id": "2509.15915", "title": "Foundation Models as World Models: A Foundational Study in Text-Based GridWorlds", "authors": ["Remo Sasso", "Michelangelo Conserva", "Dominik Jeurissen", "Paulo Rauber"], "abstract": "While reinforcement learning from scratch has shown impressive results in solving sequential decision-making tasks with efficient simulators, real-world applications with expensive interactions require more sample-efficient agents. Foundation models (FMs) are natural candidates to improve sample efficiency as they possess broad knowledge and reasoning capabilities, but it is yet unclear how to effectively integrate them into the reinforcement learning framework. In this paper, we anticipate and, most importantly, evaluate two promising strategies. First, we consider the use of foundation world models (FWMs) that exploit the prior knowledge of FMs to enable training and evaluating agents with simulated interactions. Second, we consider the use of foundation agents (FAs) that exploit the reasoning capabilities of FMs for decision-making. We evaluate both approaches empirically in a family of grid-world environments that are suitable for the current generation of large language models (LLMs). Our results suggest that improvements in LLMs already translate into better FWMs and FAs; that FAs based on current LLMs can already provide excellent policies for sufficiently simple environments; and that the coupling of FWMs and reinforcement learning agents is highly promising for more complex settings with partial observability and stochastic elements.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "20 pages, 9 figures. Accepted for presentation at the 39th Conference on Neural Information Processing Systems (NeurIPS 2025) Workshop on Embodied World Models for Decision Making", "pdf_url": "https://arxiv.org/pdf/2509.15915.pdf", "abstract_url": "https://arxiv.org/abs/2509.15915", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了在基于文本的网格世界中，利用基础模型作为世界模型或智能体以提高强化学习样本效率的两种策略。", "motivation": "解决真实世界应用中交互成本高、强化学习样本效率低的问题。", "method": "评估了基础世界模型和基础智能体两种方法，在适合大语言模型的网格世界环境中进行实证研究。", "result": "LLM改进提升了FWMs和FAs性能；FAs在简单环境中表现优秀；FWMs与强化学习结合在复杂部分可观测和随机环境中前景广阔。", "conclusion": "基础模型在强化学习中具有潜力，FWMs和FAs策略可提高样本效率，未来在复杂任务中应用价值高。"}}
{"id": "2509.15965", "title": "RLinf: Flexible and Efficient Large-scale Reinforcement Learning via Macro-to-Micro Flow Transformation", "authors": ["Chao Yu", "Yuanqing Wang", "Zhen Guo", "Hao Lin", "Si Xu", "Hongzhi Zang", "Quanlu Zhang", "Yongji Wu", "Chunyang Zhu", "Junhao Hu", "Zixiao Huang", "Mingjie Wei", "Yuqing Xie", "Ke Yang", "Bo Dai", "Zhexuan Xu", "Xiangyuan Wang", "Xu Fu", "Zhihao Liu", "Kang Chen", "Weilin Liu", "Gang Liu", "Boxun Li", "Jianlei Yang", "Zhi Yang", "Guohao Dai", "Yu Wang"], "abstract": "Reinforcement learning (RL) has demonstrated immense potential in advancing artificial general intelligence, agentic intelligence, and embodied intelligence. However, the inherent heterogeneity and dynamicity of RL workflows often lead to low hardware utilization and slow training on existing systems. In this paper, we present RLinf, a high-performance RL training system based on our key observation that the major roadblock to efficient RL training lies in system flexibility. To maximize flexibility and efficiency, RLinf is built atop a novel RL system design paradigm called macro-to-micro flow transformation (M2Flow), which automatically breaks down high-level, easy-to-compose RL workflows at both the temporal and spatial dimensions, and recomposes them into optimized execution flows. Supported by RLinf worker's adaptive communication capability, we devise context switching and elastic pipelining to realize M2Flow transformation, and a profiling-guided scheduling policy to generate optimal execution plans. Extensive evaluations on both reasoning RL and embodied RL tasks demonstrate that RLinf consistently outperforms state-of-the-art systems, achieving 1.1x-2.13x speedup in end-to-end training throughput.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2509.15965.pdf", "abstract_url": "https://arxiv.org/abs/2509.15965", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Distributed, Parallel, and Cluster Computing (cs.DC)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "RLinf是一种基于宏到微流转换的高性能强化学习训练系统，通过灵活分解和优化工作流，提升硬件利用率和训练速度。", "motivation": "解决强化学习工作流异质性和动态性导致的硬件利用率低和训练速度慢的问题。", "method": "采用宏到微流转换（M2Flow）设计范式，结合自适应通信、上下文切换、弹性流水线和分析引导调度策略。", "result": "在推理和具身强化学习任务中，RLinf比现有系统快1.1倍到2.13倍。", "conclusion": "RLinf通过提高系统灵活性，实现了高效的大规模强化学习训练。"}}
{"id": "2509.15981", "title": "Uncertainty-Based Smooth Policy Regularisation for Reinforcement Learning with Few Demonstrations", "authors": ["Yujie Zhu", "Charles A. Hepburn", "Matthew Thorpe", "Giovanni Montana"], "abstract": "In reinforcement learning with sparse rewards, demonstrations can accelerate learning, but determining when to imitate them remains challenging. We propose Smooth Policy Regularisation from Demonstrations (SPReD), a framework that addresses the fundamental question: when should an agent imitate a demonstration versus follow its own policy? SPReD uses ensemble methods to explicitly model Q-value distributions for both demonstration and policy actions, quantifying uncertainty for comparisons. We develop two complementary uncertainty-aware methods: a probabilistic approach estimating the likelihood of demonstration superiority, and an advantage-based approach scaling imitation by statistical significance. Unlike prevailing methods (e.g. Q-filter) that make binary imitation decisions, SPReD applies continuous, uncertainty-proportional regularisation weights, reducing gradient variance during training. Despite its computational simplicity, SPReD achieves remarkable gains in experiments across eight robotics tasks, outperforming existing approaches by up to a factor of 14 in complex tasks while maintaining robustness to demonstration quality and quantity. Our code is available at", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Robotics (cs.RO); Machine Learning (stat.ML)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.15981.pdf", "abstract_url": "https://arxiv.org/abs/2509.15981", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Robotics (cs.RO)", "Machine Learning (stat.ML)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文提出SPReD框架，通过集成方法量化不确定性，实现基于不确定性的平滑策略正则化，以在稀疏奖励强化学习中智能模仿演示，显著提升性能。", "motivation": "解决在稀疏奖励强化学习中，如何决定何时模仿演示而非遵循自身策略的挑战。", "method": "使用集成方法建模Q值分布，开发概率性和优势性方法，应用连续不确定性比例正则化权重。", "result": "在八个机器人任务中，SPReD性能优于现有方法高达14倍，对演示质量和数量保持鲁棒性。", "conclusion": "SPReD提供了一种有效且计算简单的方法，通过不确定性引导的模仿决策提升学习效率。"}}
