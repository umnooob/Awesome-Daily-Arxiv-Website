{"id": "2505.13506", "title": "EcoSafeRAG: Efficient Security through Context Analysis in Retrieval-Augmented Generation", "authors": ["Ruobing Yao", "Yifei Zhang", "Shuang Song", "Neng Gao", "Chenyang Tu"], "abstract": "Retrieval-Augmented Generation (RAG) compensates for the static knowledge limitations of Large Language Models (LLMs) by integrating external knowledge, producing responses with enhanced factual correctness and query-specific contextualization. However, it also introduces new attack surfaces such as corpus poisoning at the same time. Most of the existing defense methods rely on the internal knowledge of the model, which conflicts with the design concept of RAG. To bridge the gap, EcoSafeRAG uses sentence-level processing and bait-guided context diversity detection to identify malicious content by analyzing the context diversity of candidate documents without relying on LLM internal knowledge. Experiments show EcoSafeRAG delivers state-of-the-art security with plug-and-play deployment, simultaneously improving clean-scenario RAG performance while maintaining practical operational costs (relatively 1.2$\\times$ latency, 48\\%-80\\% token reduction versus Vanilla RAG).", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.13506.pdf", "abstract_url": "https://arxiv.org/abs/2505.13506", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "EcoSafeRAG通过上下文多样性检测和句子级处理，有效识别恶意内容，提升检索增强生成（RAG）的安全性，同时保持操作效率。", "motivation": "解决检索增强生成（RAG）因引入外部知识而带来的新攻击面（如语料库中毒）问题，现有防御方法依赖模型内部知识，与RAG设计理念冲突。", "method": "采用句子级处理和诱饵引导的上下文多样性检测，不依赖大型语言模型（LLM）内部知识，分析候选文档的上下文多样性以识别恶意内容。", "result": "实验表明，EcoSafeRAG在提供最先进安全性的同时，提升了清洁场景下的RAG性能，并保持实际操作成本（相对Vanilla RAG，延迟1.2倍，令牌减少48%-80%）。", "conclusion": "EcoSafeRAG为RAG系统提供了一种高效、安全且不依赖LLM内部知识的防御机制，具有即插即用的部署优势。"}}
{"id": "2505.13466", "title": "AgentSGEN: Multi-Agent LLM in the Loop for Semantic Collaboration and GENeration of Synthetic Data", "authors": ["Vu Dinh Xuan", "Hao Vo", "David Murphy", "Hoang D. Nguyen"], "abstract": "The scarcity of data depicting dangerous situations presents a major obstacle to training AI systems for safety-critical applications, such as construction safety, where ethical and logistical barriers hinder real-world data collection. This creates an urgent need for an end-to-end framework to generate synthetic data that can bridge this gap. While existing methods can produce synthetic scenes, they often lack the semantic depth required for scene simulations, limiting their effectiveness. To address this, we propose a novel multi-agent framework that employs an iterative, in-the-loop collaboration between two agents: an Evaluator Agent, acting as an LLM-based judge to enforce semantic consistency and safety-specific constraints, and an Editor Agent, which generates and refines scenes based on this guidance. Powered by LLM's capabilities to reasoning and common-sense knowledge, this collaborative design produces synthetic images tailored to safety-critical scenarios. Our experiments suggest this design can generate useful scenes based on realistic specifications that address the shortcomings of prior approaches, balancing safety requirements with visual semantics. This iterative process holds promise for delivering robust, aesthetically sound simulations, offering a potential solution to the data scarcity challenge in multimedia safety applications.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.13466.pdf", "abstract_url": "https://arxiv.org/abs/2505.13466", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新颖的多智能体框架AgentSGEN，通过评估者智能体和编辑者智能体的迭代协作，生成符合安全关键场景需求的合成数据，以解决安全关键应用中数据稀缺的问题。", "motivation": "安全关键应用（如建筑安全）中，由于伦理和物流障碍，难以收集真实世界的危险情况数据，这限制了AI系统的训练。现有方法生成的合成场景缺乏语义深度，影响了场景模拟的效果。", "method": "采用多智能体框架，包括基于LLM的评估者智能体（负责确保语义一致性和安全特定约束）和编辑者智能体（根据评估者的指导生成和优化场景），通过迭代协作生成合成图像。", "result": "实验表明，该框架能够根据现实规范生成有用的场景，平衡安全要求和视觉语义，解决了现有方法的不足。", "conclusion": "这种迭代协作过程有望提供强大且美观的模拟，为解决多媒体安全应用中的数据稀缺问题提供了潜在解决方案。"}}
{"id": "2505.14246", "title": "Visual Agentic Reinforcement Fine-Tuning", "authors": ["Ziyu Liu", "Yuhang Zang", "Yushan Zou", "Zijian Liang", "Xiaoyi Dong", "Yuhang Cao", "Haodong Duan", "Dahua Lin", "Jiaqi Wang"], "abstract": "A key trend in Large Reasoning Models (e.g., OpenAI's o3) is the native agentic ability to use external tools such as web browsers for searching and writing/executing code for image manipulation to think with images. In the open-source research community, while significant progress has been made in language-only agentic abilities such as function calling and tool integration, the development of multi-modal agentic capabilities that involve truly thinking with images, and their corresponding benchmarks, are still less explored. This work highlights the effectiveness of Visual Agentic Reinforcement Fine-Tuning (Visual-ARFT) for enabling flexible and adaptive reasoning abilities for Large Vision-Language Models (LVLMs). With Visual-ARFT, open-source LVLMs gain the ability to browse websites for real-time information updates and write code to manipulate and analyze input images through cropping, rotation, and other image processing techniques. We also present a Multi-modal Agentic Tool Bench (MAT) with two settings (MAT-Search and MAT-Coding) designed to evaluate LVLMs' agentic search and coding abilities. Our experimental results demonstrate that Visual-ARFT outperforms its baseline by +18.6% F1 / +13.0% EM on MAT-Coding and +10.3% F1 / +8.7% EM on MAT-Search, ultimately surpassing GPT-4o. Visual-ARFT also achieves +29.3 F1% / +25.9% EM gains on existing multi-hop QA benchmarks such as 2Wiki and HotpotQA, demonstrating strong generalization capabilities. Our findings suggest that Visual-ARFT offers a promising path toward building robust and generalizable multimodal agents.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.14246.pdf", "abstract_url": "https://arxiv.org/abs/2505.14246", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了视觉代理强化微调（Visual-ARFT）方法，用于增强大型视觉语言模型（LVLMs）的多模态代理能力，包括实时信息搜索和图像处理代码编写。通过MAT基准测试，Visual-ARFT在搜索和编码任务上显著优于基线模型和GPT-4o，并在多跳QA任务上展示了强大的泛化能力。", "motivation": "解决开源研究中多模态代理能力，尤其是涉及图像思维的代理能力及其基准测试开发不足的问题。", "method": "采用视觉代理强化微调（Visual-ARFT）方法，使LVLMs能够浏览网站获取实时信息并编写代码进行图像处理。", "result": "Visual-ARFT在MAT-Coding和MAT-Search上分别比基线提高了+18.6% F1 / +13.0% EM和+10.3% F1 / +8.7% EM，超过了GPT-4o，并在多跳QA任务上实现了+29.3% F1 / +25.9% EM的提升。", "conclusion": "Visual-ARFT为构建强大且可泛化的多模态代理提供了一条有前景的路径。"}}
{"id": "2505.13546", "title": "Prompt Stability Matters: Evaluating and Optimizing Auto-Generated Prompt in General-Purpose Systems", "authors": ["Ke Chen", "Yufei Zhou", "Xitong Zhang", "Haohan Wang"], "abstract": "Automatic prompt generation plays a crucial role in enabling general-purpose multi-agent systems to perform diverse tasks autonomously. Existing methods typically evaluate prompts based on their immediate task performance, overlooking the intrinsic qualities that determine their reliability. This outcome-centric view not only limits interpretability but also fails to account for the inherent stochasticity of large language models (LLMs). In this work, we bring attention to prompt stability-the consistency of model responses across repeated executions-as a key factor for building robust and effective prompt generation systems. To quantify this, we propose semantic stability as a criterion for assessing the response consistency of prompts, and fine-tune a LLaMA-based evaluator to measure it automatically across tasks. These components have enabled us to develop the first stability-aware general-purpose prompt generation system that leverages stability feedback to iteratively enhance both prompt quality and system-level performance. Furthermore, we establish a logical chain between prompt stability and task success by analyzing the structural dependencies within our system, proving stability as a necessary condition for effective system-level execution. Empirical results across general and domain-specific tasks demonstrate that our stability-aware framework improves both accuracy and output consistency. By shifting the focus from one-off results to persistent reliability, our work offers a new perspective on prompt design and contributes practical tools for building more trustworthy general-purpose systems.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.13546.pdf", "abstract_url": "https://arxiv.org/abs/2505.13546", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出并评估了自动生成的提示在通用系统中的稳定性，引入了语义稳定性作为评估标准，并开发了一个稳定性感知的提示生成系统，以提高提示质量和系统性能。", "motivation": "现有的自动提示生成方法通常仅基于即时任务性能评估提示，忽视了决定其可靠性的内在质量，这限制了可解释性且未能考虑大型语言模型（LLMs）的固有随机性。", "method": "提出了语义稳定性作为评估提示响应一致性的标准，并微调了一个基于LLaMA的评估器来自动测量跨任务的稳定性，开发了第一个稳定性感知的通用提示生成系统。", "result": "实证结果表明，我们的稳定性感知框架在通用和领域特定任务中均提高了准确性和输出一致性。", "conclusion": "通过将焦点从一次性结果转移到持久可靠性，我们的工作为提示设计提供了新的视角，并为构建更可信的通用系统贡献了实用工具。"}}
{"id": "2505.13511", "title": "Can AI Freelancers Compete? Benchmarking Earnings, Reliability, and Task Success at Scale", "authors": ["David Noever", "Forrest McKee"], "abstract": "This study explores Large Language Models (LLMs) as autonomous agents for real-world tasks, including freelance software development. This work presents a new benchmark that evaluates LLMs on freelance programming and data analysis tasks derived from economic data. We construct the benchmark using synthetic tasks created from a Kaggle Freelancer dataset of job postings, with all job prices standardized to USD (median fixed-project price around $250, and an average of $306). Each task is accompanied by structured input-output test cases and an estimated price tag, enabling automated correctness checking and a monetary performance valuation. This approach is inspired by OpenAI's recent SWE-Lancer benchmark (1,400 real Upwork tasks worth $1M total). Still, our framework simplifies evaluation using programmatically testable tasks and predicted price values, making it highly scalable and repeatable. On this benchmark, we evaluate four modern LLMs - Claude 3.5 Haiku, GPT-4o-mini, Qwen 2.5, and Mistral. We report each model's accuracy (task success rate and test-case pass rate) and the total \"freelance earnings\" it achieves (sum of prices of solved tasks). Our results show that Claude 3.5 Haiku performs best, earning approximately $1.52 million USD, followed closely by GPT-4o-mini at $1.49 million, then Qwen 2.5 ($1.33M) and Mistral ($0.70M). We analyze the distribution of errors per task and observe that the strongest models solve the most tasks and rarely fail completely on any project. We discuss the implications of these results for the feasibility of AI as a freelance developer, the advantages and limitations of our automated benchmark approach, and the gap between performance on structured tasks versus the true complexity of real-world freelance jobs.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.13511.pdf", "abstract_url": "https://arxiv.org/abs/2505.13511", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本研究探讨了大型语言模型（LLMs）作为自主代理完成现实世界任务的能力，特别是自由职业软件开发。通过从Kaggle自由职业者数据集中创建合成任务，建立了一个新的基准测试，评估LLMs在自由职业编程和数据分析任务上的表现。测试包括四个现代LLMs模型，结果显示Claude 3.5 Haiku表现最佳。", "motivation": "解决评估大型语言模型（LLMs）在自由职业软件开发等现实世界任务中表现的问题，提供一个可扩展和重复的自动化评估框架。", "method": "使用从Kaggle自由职业者数据集中创建的合成任务，每个任务配有结构化输入输出测试用例和预估价格标签，实现自动化正确性检查和货币性能评估。", "result": "Claude 3.5 Haiku表现最佳，赚取约152万美元，其次是GPT-4o-mini（149万美元）、Qwen 2.5（133万美元）和Mistral（70万美元）。最强模型解决了最多任务，很少在任何项目上完全失败。", "conclusion": "研究结果表明AI作为自由职业开发者的可行性，讨论了自动化基准测试方法的优势和局限性，以及在结构化任务与真实世界自由职业工作复杂性之间的表现差距。"}}
{"id": "2505.13551", "title": "Counter-Inferential Behavior in Natural and Artificial Cognitive Systems", "authors": ["Serge Dolgikh"], "abstract": "This study explores the emergence of counter-inferential behavior in natural and artificial cognitive systems, that is, patterns in which agents misattribute empirical success or suppress adaptation, leading to epistemic rigidity or maladaptive stability. We analyze archetypal scenarios in which such behavior arises: reinforcement of stability through reward imbalance, meta-cognitive attribution of success to internal superiority, and protective reframing under perceived model fragility. Rather than arising from noise or flawed design, these behaviors emerge through structured interactions between internal information models, empirical feedback, and higher-order evaluation mechanisms. Drawing on evidence from artificial systems, biological cognition, human psychology, and social dynamics, we identify counter-inferential behavior as a general cognitive vulnerability that can manifest even in otherwise well-adapted systems. The findings highlight the importance of preserving minimal adaptive activation under stable conditions and suggest design principles for cognitive architectures that can resist rigidity under informational stress.", "subjects": "Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE); Social and Information Networks (cs.SI)", "comments": "23 pages, 3 figures", "pdf_url": "https://arxiv.org/pdf/2505.13551.pdf", "abstract_url": "https://arxiv.org/abs/2505.13551", "categories": ["Artificial Intelligence (cs.AI)", "Neural and Evolutionary Computing (cs.NE)", "Social and Information Networks (cs.SI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本研究探讨了自然和人工认知系统中反推理行为的出现，即代理错误归因经验成功或抑制适应，导致认知刚性或适应不良的稳定性。通过分析典型场景，我们识别了这些行为的结构性互动，并提出了设计原则。", "motivation": "解决认知系统中出现的反推理行为问题，这些行为可能导致系统刚性或适应不良，即使在设计良好的系统中也可能出现。", "method": "分析了强化稳定性、元认知成功归因和保护性重构等典型场景中反推理行为的出现，结合人工系统、生物认知、人类心理学和社会动力学的证据。", "result": "识别了反推理行为作为一种普遍的认知脆弱性，即使在适应良好的系统中也可能出现，并提出了抵抗信息压力下刚性的设计原则。", "conclusion": "研究强调了在稳定条件下保持最小适应激活的重要性，并提出了能够抵抗信息压力下刚性的认知架构设计原则。"}}
{"id": "2505.13668", "title": "MAFA: A multi-agent framework for annotation", "authors": ["Mahmood Hegazy", "Aaron Rodrigues", "Azzam Naeem"], "abstract": "Modern applications require accurate and efficient retrieval of information in response to user queries. Mapping user utterances to the most relevant Frequently Asked Questions (FAQs) is a crucial component of these systems. Traditional approaches often rely on a single model or technique, which may not capture the nuances of diverse user inquiries. In this paper, we introduce a multi-agent framework for FAQ annotation that combines multiple specialized agents with different approaches and a judge agent that reranks candidates to produce optimal results. Our agents utilize a structured reasoning approach inspired by Attentive Reasoning Queries (ARQs), which guides them through systematic reasoning steps using targeted, task-specific JSON queries. Our framework features a specialized few-shot example strategy, where each agent receives different few-shots, enhancing ensemble diversity and coverage of the query space. We evaluate our framework on a real-world banking dataset as well as public benchmark datasets (LCQMC and FiQA), demonstrating significant improvements over single-agent approaches across multiple metrics, including a 14% increase in Top-1 accuracy, an 18% increase in Top-5 accuracy, and a 12% improvement in Mean Reciprocal Rank on our dataset, and similar gains on public benchmarks when compared with traditional single agent annotation techniques. Our framework is particularly effective at handling ambiguous queries, making it well-suited for deployment in production applications while showing strong generalization capabilities across different domains and languages.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.13668.pdf", "abstract_url": "https://arxiv.org/abs/2505.13668", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一个多智能体框架MAFA，用于FAQ注释，通过结合多个专门化的智能体和一个法官智能体来优化结果，显著提高了信息检索的准确性和效率。", "motivation": "解决传统单模型或技术在映射用户查询到最相关FAQ时无法捕捉多样化查询的细微差别的问题。", "method": "采用多智能体框架，每个智能体使用不同的方法和结构化推理方法（ARQs），并通过法官智能体重新排名候选结果。", "result": "在真实世界银行数据集和公共基准数据集上，与单智能体方法相比，Top-1准确率提高了14%，Top-5准确率提高了18%，平均倒数排名提高了12%。", "conclusion": "MAFA框架特别适合处理模糊查询，展示了在不同领域和语言中的强大泛化能力，适合部署在生产应用中。"}}
{"id": "2505.13773", "title": "Model Cards for AI Teammates: Comparing Human-AI Team Familiarization Methods for High-Stakes Environments", "authors": ["Ryan Bowers", "Richard Agbeyibor", "Jack Kolb", "Karen Feigh"], "abstract": "We compare three methods of familiarizing a human with an artificial intelligence (AI) teammate (\"agent\") prior to operation in a collaborative, fast-paced intelligence, surveillance, and reconnaissance (ISR) environment. In a between-subjects user study (n=60), participants either read documentation about the agent, trained alongside the agent prior to the mission, or were given no familiarization. Results showed that the most valuable information about the agent included details of its decision-making algorithms and its relative strengths and weaknesses compared to the human. This information allowed the familiarization groups to form sophisticated team strategies more quickly than the control group. Documentation-based familiarization led to the fastest adoption of these strategies, but also biased participants towards risk-averse behavior that prevented high scores. Participants familiarized through direct interaction were able to infer much of the same information through observation, and were more willing to take risks and experiment with different control modes, but reported weaker understanding of the agent's internal processes. Significant differences were seen between individual participants' risk tolerance and methods of AI interaction, which should be considered when designing human-AI control interfaces. Based on our findings, we recommend a human-AI team familiarization method that combines AI documentation, structured in-situ training, and exploratory interaction.", "subjects": "Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Multiagent Systems (cs.MA)", "comments": "Submitted to IEEE RO-MAN 2025 (under review). 8 pages, 7 figures", "pdf_url": "https://arxiv.org/pdf/2505.13773.pdf", "abstract_url": "https://arxiv.org/abs/2505.13773", "categories": ["Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "比较了三种人类与AI队友熟悉的方法在高风险环境中的效果，发现结合文档、结构化现场训练和探索性互动的方法最为有效。", "motivation": "解决在高风险、快节奏的ISR环境中，如何最有效地使人类与AI队友熟悉，以优化团队协作和策略形成的问题。", "method": "在60名参与者中进行了一项用户研究，比较了阅读AI文档、与AI一起训练和无熟悉三种方法的效果。", "result": "文档熟悉组能快速形成团队策略但偏向风险规避；直接互动组能通过观察推断AI特性，更愿意冒险，但对AI内部过程理解较弱。", "conclusion": "推荐结合AI文档、结构化现场训练和探索性互动的熟悉方法，同时考虑个体风险容忍度和AI交互方式的差异。"}}
{"id": "2505.13761", "title": "Simulation Agent: A Framework for Integrating Simulation and Large Language Models for Enhanced Decision-Making", "authors": ["Jacob Kleiman", "Kevin Frank", "Sindy Campagna"], "abstract": "Simulations, although powerful in accurately replicating real-world systems, often remain inaccessible to non-technical users due to their complexity. Conversely, large language models (LLMs) provide intuitive, language-based interactions but can lack the structured, causal understanding required to reliably model complex real-world dynamics. We introduce our simulation agent framework, a novel approach that integrates the strengths of both simulation models and LLMs. This framework helps empower users by leveraging the conversational capabilities of LLMs to interact seamlessly with sophisticated simulation systems, while simultaneously utilizing the simulations to ground the LLMs in accurate and structured representations of real-world phenomena. This integrated approach helps provide a robust and generalizable foundation for empirical validation and offers broad applicability across diverse domains.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.13761.pdf", "abstract_url": "https://arxiv.org/abs/2505.13761", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种模拟代理框架，旨在整合模拟模型和大型语言模型（LLMs）的优势，以增强决策制定。该框架通过LLMs的对话能力使用户能够直观地与复杂的模拟系统交互，同时利用模拟为LLMs提供真实世界现象的结构化表示，从而提高决策的准确性和可访问性。", "motivation": "模拟技术虽能准确复制现实世界系统，但对非技术用户来说过于复杂；而大型语言模型（LLMs）虽提供直观的语言交互，却缺乏对复杂现实动态的结构化理解。本文旨在解决这两种技术的局限性，通过整合它们来增强决策制定。", "method": "引入模拟代理框架，该框架结合了模拟模型的结构化、因果理解能力和LLMs的直观语言交互能力，使用户能够通过自然语言与模拟系统交互，同时确保决策基于准确的现实世界表示。", "result": "该框架提供了一个强大且可推广的基础，支持跨多个领域的实证验证，提高了决策制定的准确性和可访问性。", "conclusion": "模拟代理框架通过整合模拟和LLMs，不仅提高了非技术用户对复杂模拟系统的可访问性，还增强了决策制定的准确性和可靠性，具有广泛的适用性和重要的实践意义。"}}
{"id": "2505.13828", "title": "Multimodal RAG-driven Anomaly Detection and Classification in Laser Powder Bed Fusion using Large Language Models", "authors": ["Kiarash Naghavi Khanghah", "Zhiling Chen", "Lela Romeo", "Qian Yang", "Rajiv Malhotra", "Farhad Imani", "Hongyi Xu"], "abstract": "Additive manufacturing enables the fabrication of complex designs while minimizing waste, but faces challenges related to defects and process anomalies. This study presents a novel multimodal Retrieval-Augmented Generation-based framework that automates anomaly detection across various Additive Manufacturing processes leveraging retrieved information from literature, including images and descriptive text, rather than training datasets. This framework integrates text and image retrieval from scientific literature and multimodal generation models to perform zero-shot anomaly identification, classification, and explanation generation in a Laser Powder Bed Fusion setting. The proposed framework is evaluated on four L-PBF manufacturing datasets from Oak Ridge National Laboratory, featuring various printer makes, models, and materials. This evaluation demonstrates the framework's adaptability and generalizability across diverse images without requiring additional training. Comparative analysis using Qwen2-VL-2B and GPT-4o-mini as MLLM within the proposed framework highlights that GPT-4o-mini outperforms Qwen2-VL-2B and proportional random baseline in manufacturing anomalies classification. Additionally, the evaluation of the RAG system confirms that incorporating retrieval mechanisms improves average accuracy by 12% by reducing the risk of hallucination and providing additional information. The proposed framework can be continuously updated by integrating emerging research, allowing seamless adaptation to the evolving landscape of AM technologies. This scalable, automated, and zero-shot-capable framework streamlines AM anomaly analysis, enhancing efficiency and accuracy.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "ASME 2025 International Design Engineering Technical Conferences and Computers and Information in Engineering Conference IDETC/CIE2025, August 17-20, 2025, Anaheim, CA (IDETC2025-168615)", "pdf_url": "https://arxiv.org/pdf/2505.13828.pdf", "abstract_url": "https://arxiv.org/abs/2505.13828", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种基于多模态检索增强生成（RAG）的框架，用于激光粉末床融合（L-PBF）中的异常检测和分类，利用科学文献中的图像和描述性文本进行零样本识别，无需训练数据集。", "motivation": "增材制造在制造复杂设计时面临缺陷和过程异常的挑战，需要一种无需训练数据集即可自动检测异常的方法。", "method": "采用多模态检索增强生成框架，结合文本和图像检索以及多模态生成模型，进行零样本异常识别、分类和解释生成。", "result": "在四个L-PBF制造数据集上的评估显示，该框架具有适应性和泛化能力，GPT-4o-mini在异常分类中表现优于Qwen2-VL-2B和比例随机基线，检索机制使平均准确率提高了12%。", "conclusion": "该框架可不断更新以适应增材制造技术的发展，提供了一种可扩展、自动化且零样本能力的解决方案，提高了异常分析的效率和准确性。"}}
{"id": "2505.13851", "title": "A Challenge to Build Neuro-Symbolic Video Agents", "authors": ["Sahil Shah", "Harsh Goel", "Sai Shankar Narasimhan", "Minkyu Choi", "S P Sharan", "Oguzhan Akcin", "Sandeep Chinchali"], "abstract": "Modern video understanding systems excel at tasks such as scene classification, object detection, and short video retrieval. However, as video analysis becomes increasingly central to real-world applications, there is a growing need for proactive video agents for the systems that not only interpret video streams but also reason about events and take informed actions. A key obstacle in this direction is temporal reasoning: while deep learning models have made remarkable progress in recognizing patterns within individual frames or short clips, they struggle to understand the sequencing and dependencies of events over time, which is critical for action-driven decision-making. Addressing this limitation demands moving beyond conventional deep learning approaches. We posit that tackling this challenge requires a neuro-symbolic perspective, where video queries are decomposed into atomic events, structured into coherent sequences, and validated against temporal constraints. Such an approach can enhance interpretability, enable structured reasoning, and provide stronger guarantees on system behavior, all key properties for advancing trustworthy video agents. To this end, we present a grand challenge to the research community: developing the next generation of intelligent video agents that integrate three core capabilities: (1) autonomous video search and analysis, (2) seamless real-world interaction, and (3) advanced content generation. By addressing these pillars, we can transition from passive perception to intelligent video agents that reason, predict, and act, pushing the boundaries of video understanding.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.13851.pdf", "abstract_url": "https://arxiv.org/abs/2505.13851", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了构建神经符号视频代理的挑战，旨在超越传统的深度学习，通过神经符号方法增强视频理解，实现自主视频搜索、现实世界交互和内容生成。", "motivation": "解决视频理解系统在时间推理上的局限，即当前深度学习模型难以理解事件序列和依赖关系，这对于基于行动的决策至关重要。", "method": "采用神经符号视角，将视频查询分解为原子事件，构建连贯序列，并验证时间约束，以提高可解释性和结构化推理。", "result": "提出了一个重大挑战：开发下一代智能视频代理，集成自主视频搜索与分析、无缝现实世界交互和高级内容生成三大核心能力。", "conclusion": "通过解决这些核心问题，可以从被动感知过渡到能够推理、预测和行动的智能视频代理，推动视频理解的边界。"}}
{"id": "2505.13887", "title": "Mobile-Agent-V: A Video-Guided Approach for Effortless and Efficient Operational Knowledge Injection in Mobile Automation", "authors": ["Junyang Wang", "Haiyang Xu", "Xi Zhang", "Ming Yan", "Ji Zhang", "Fei Huang", "Jitao Sang"], "abstract": "The exponential rise in mobile device usage necessitates streamlined automation for effective task management, yet many AI frameworks fall short due to inadequate operational expertise. While manually written knowledge can bridge this gap, it is often burdensome and inefficient. We introduce Mobile-Agent-V, an innovative framework that utilizes video as a guiding tool to effortlessly and efficiently inject operational knowledge into mobile automation processes. By deriving knowledge directly from video content, Mobile-Agent-V eliminates manual intervention, significantly reducing the effort and time required for knowledge acquisition. To rigorously evaluate this approach, we propose Mobile-Knowledge, a benchmark tailored to assess the impact of external knowledge on mobile agent performance. Our experimental findings demonstrate that Mobile-Agent-V enhances performance by 36% compared to existing methods, underscoring its effortless and efficient advantages in mobile automation.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.13887.pdf", "abstract_url": "https://arxiv.org/abs/2505.13887", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了Mobile-Agent-V，一种利用视频作为指导工具的创新框架，旨在轻松高效地将操作知识注入移动自动化流程中。通过直接从视频内容中获取知识，该框架显著减少了知识获取所需的时间和努力。实验结果表明，Mobile-Agent-V的性能比现有方法提高了36%。", "motivation": "随着移动设备使用的指数级增长，需要简化的自动化以进行有效的任务管理，但许多AI框架由于操作专业知识不足而未能满足需求。虽然手动编写的知识可以弥补这一差距，但这通常是繁重且低效的。", "method": "Mobile-Agent-V框架利用视频作为指导工具，直接从视频内容中获取操作知识，无需人工干预。", "result": "实验结果表明，Mobile-Agent-V的性能比现有方法提高了36%。", "conclusion": "Mobile-Agent-V框架在移动自动化中展现了其轻松高效的优势，通过直接从视频中获取知识，显著减少了知识获取所需的时间和努力。"}}
{"id": "2505.14462", "title": "RAVENEA: A Benchmark for Multimodal Retrieval-Augmented Visual Culture Understanding", "authors": ["Jiaang Li", "Yifei Yuan", "Wenyan Li", "Mohammad Aliannejadi", "Daniel Hershcovich", "Anders Søgaard", "Ivan Vulić", "Wenxuan Zhang", "Paul Pu Liang", "Yang Deng", "Serge Belongie"], "abstract": "As vision-language models (VLMs) become increasingly integrated into daily life, the need for accurate visual culture understanding is becoming critical. Yet, these models frequently fall short in interpreting cultural nuances effectively. Prior work has demonstrated the effectiveness of retrieval-augmented generation (RAG) in enhancing cultural understanding in text-only settings, while its application in multimodal scenarios remains underexplored. To bridge this gap, we introduce RAVENEA (Retrieval-Augmented Visual culturE uNdErstAnding), a new benchmark designed to advance visual culture understanding through retrieval, focusing on two tasks: culture-focused visual question answering (cVQA) and culture-informed image captioning (cIC). RAVENEA extends existing datasets by integrating over 10,000 Wikipedia documents curated and ranked by human annotators. With RAVENEA, we train and evaluate seven multimodal retrievers for each image query, and measure the downstream impact of retrieval-augmented inputs across fourteen state-of-the-art VLMs. Our results show that lightweight VLMs, when augmented with culture-aware retrieval, outperform their non-augmented counterparts (by at least 3.2% absolute on cVQA and 6.2% absolute on cIC). This highlights the value of retrieval-augmented methods and culturally inclusive benchmarks for multimodal understanding.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.14462.pdf", "abstract_url": "https://arxiv.org/abs/2505.14462", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "RAVENEA是一个旨在通过检索增强多模态视觉文化理解的新基准，专注于文化聚焦的视觉问答和文化信息的图像描述任务。", "motivation": "解决视觉语言模型在解释文化细微差别方面的不足，探索检索增强生成在多模态场景中的应用。", "method": "引入RAVENEA基准，整合了超过10,000个由人类注释者整理和排名的Wikipedia文档，训练和评估了七种多模态检索器，并测量了检索增强输入对十四种最先进的视觉语言模型的下游影响。", "result": "轻量级视觉语言模型在增强文化感知检索后，表现优于未增强的模型（在cVQA上至少提高3.2%，在cIC上至少提高6.2%）。", "conclusion": "检索增强方法和文化包容性基准对多模态理解具有重要价值。"}}
{"id": "2505.13909", "title": "Efficient Agent Training for Computer Use", "authors": ["Yanheng He", "Jiahe Jin", "Pengfei Liu"], "abstract": "Scaling up high-quality trajectory data has long been a critical bottleneck for developing human-like computer use agents. We introduce PC Agent-E, an efficient agent training framework that significantly reduces reliance on large-scale human demonstrations. Starting with just 312 human-annotated computer use trajectories, we further improved data quality by synthesizing diverse action decisions with Claude 3.7 Sonnet. Trained on these enriched trajectories, our PC Agent-E model achieved a remarkable 141% relative improvement, surpassing the strong Claude 3.7 Sonnet with extended thinking on WindowsAgentArena-V2, an improved benchmark we also released. Furthermore, PC Agent-E demonstrates strong generalizability to different operating systems on OSWorld. Our findings suggest that strong computer use capabilities can be stimulated from a small amount of high-quality trajectory data.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.13909.pdf", "abstract_url": "https://arxiv.org/abs/2505.13909", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "PC Agent-E是一个高效的代理训练框架，显著减少了对大规模人类演示的依赖，仅需312条人类注释的计算机使用轨迹，通过合成多样化的动作决策提升数据质量，在WindowsAgentArena-V2基准测试中实现了141%的相对改进，并在OSWorld上展示了对不同操作系统的强大泛化能力。", "motivation": "解决高质量轨迹数据规模扩展这一长期存在的关键瓶颈，以开发更接近人类使用计算机的代理。", "method": "引入PC Agent-E框架，利用少量人类注释轨迹和Claude 3.7 Sonnet合成的多样化动作决策来丰富数据质量。", "result": "PC Agent-E在WindowsAgentArena-V2基准测试中实现了141%的相对改进，并在OSWorld上展示了对不同操作系统的强大泛化能力。", "conclusion": "研究表明，从少量高质量的轨迹数据中可以激发出强大的计算机使用能力，PC Agent-E框架为高效代理训练提供了新的可能性。"}}
{"id": "2505.13948", "title": "Memory-Centric Embodied Question Answer", "authors": ["Mingliang Zhai", "Zhi Gao", "Yuwei Wu", "Yunde Jia"], "abstract": "Embodied Question Answering (EQA) requires agents to autonomously explore and understand the environment to answer context-dependent questions. Existing frameworks typically center around the planner, which guides the stopping module, memory module, and answering module for reasoning. In this paper, we propose a memory-centric EQA framework named MemoryEQA. Unlike planner-centric EQA models where the memory module cannot fully interact with other modules, MemoryEQA flexible feeds memory information into all modules, thereby enhancing efficiency and accuracy in handling complex tasks, such as those involving multiple targets across different regions. Specifically, we establish a multi-modal hierarchical memory mechanism, which is divided into global memory that stores language-enhanced scene maps, and local memory that retains historical observations and state information. When performing EQA tasks, the multi-modal large language model is leveraged to convert memory information into the required input formats for injection into different modules. To evaluate EQA models' memory capabilities, we constructed the MT-HM3D dataset based on HM3D, comprising 1,587 question-answer pairs involving multiple targets across various regions, which requires agents to maintain memory of exploration-acquired target information. Experimental results on HM-EQA, MT-HM3D, and OpenEQA demonstrate the effectiveness of our framework, where a 19.8% performance gain on MT-HM3D compared to baseline model further underscores memory capability's pivotal role in resolving complex tasks.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Multimedia (cs.MM)", "comments": "14pages, 7 figures, 6 tables", "pdf_url": "https://arxiv.org/pdf/2505.13948.pdf", "abstract_url": "https://arxiv.org/abs/2505.13948", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Multimedia (cs.MM)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种以记忆为中心的EQA框架MemoryEQA，通过多模态分层记忆机制和大型语言模型，有效提升了处理复杂任务的效率和准确性。", "motivation": "解决现有EQA框架中记忆模块无法充分与其他模块交互的问题，以提升处理涉及多目标和跨区域复杂任务的性能。", "method": "采用多模态分层记忆机制，包括全局记忆和局部记忆，并利用多模态大型语言模型将记忆信息转换为不同模块所需的输入格式。", "result": "在HM-EQA、MT-HM3D和OpenEQA上的实验结果表明，MemoryEQA框架有效，特别是在MT-HM3D数据集上比基线模型性能提升了19.8%。", "conclusion": "MemoryEQA框架通过增强记忆能力，显著提高了处理复杂EQA任务的性能，证明了记忆能力在解决此类任务中的关键作用。"}}
{"id": "2505.13965", "title": "CAFES: A Collaborative Multi-Agent Framework for Multi-Granular Multimodal Essay Scoring", "authors": ["Jiamin Su", "Yibo Yan", "Zhuoran Gao", "Han Zhang", "Xiang Liu", "Xuming Hu"], "abstract": "Automated Essay Scoring (AES) is crucial for modern education, particularly with the increasing prevalence of multimodal assessments. However, traditional AES methods struggle with evaluation generalizability and multimodal perception, while even recent Multimodal Large Language Model (MLLM)-based approaches can produce hallucinated justifications and scores misaligned with human judgment. To address the limitations, we introduce CAFES, the first collaborative multi-agent framework specifically designed for AES. It orchestrates three specialized agents: an Initial Scorer for rapid, trait-specific evaluations; a Feedback Pool Manager to aggregate detailed, evidence-grounded strengths; and a Reflective Scorer that iteratively refines scores based on this feedback to enhance human alignment. Extensive experiments, using state-of-the-art MLLMs, achieve an average relative improvement of 21% in Quadratic Weighted Kappa (QWK) against ground truth, especially for grammatical and lexical diversity. Our proposed CAFES framework paves the way for an intelligent multimodal AES system. The code will be available upon acceptance.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.13965.pdf", "abstract_url": "https://arxiv.org/abs/2505.13965", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了CAFES，一个专为多模态作文评分设计的协作多智能体框架，通过三个专门代理的合作，显著提高了评分与人类判断的一致性。", "motivation": "传统的自动作文评分方法在评估的普遍性和多模态感知方面存在不足，而最新的多模态大语言模型方法可能会产生幻觉性理由和与人类判断不符的分数。", "method": "CAFES框架通过三个专门代理协作工作：初始评分者进行快速、特质特定的评估；反馈池管理者汇总详细的、基于证据的优点；反思评分者根据反馈迭代优化分数以提高与人类判断的一致性。", "result": "使用最先进的多模态大语言模型进行的广泛实验显示，CAFES在二次加权Kappa（QWK）上相对于地面真实情况平均提高了21%，特别是在语法和词汇多样性方面。", "conclusion": "CAFES框架为智能多模态自动作文评分系统开辟了道路，其代码将在接受后提供。"}}
{"id": "2505.13940", "title": "DrugPilot: LLM-based Parameterized Reasoning Agent for Drug Discovery", "authors": ["Kun Li", "Zhennan Wu", "Shoupeng Wang", "Wenbin Hu"], "abstract": "In the field of AI4Science, large-scale language models (LLMs) show great potential to parse complex scientific semantics, integrate cross-disciplinary knowledge, and assist critical task research. However, in the field of drug discovery, despite the optimization through professional data pre-training, context window expansion, and internet search, the existing LLMs are still facing challenges such as massive multi-modal and heterogeneous data processing, domain knowledge dynamic updating delay, and insufficient confidence in predicting the results of complex computational tasks. To address these challenges, we propose the DrugPilot, an LLM-based agent with parameterized reasoning for drug discovery. DrugPilot addresses key limitations of traditional end-to-end LLM prediction approaches through its parametric inference architecture. This agent system supports major phases of the drug discovery pipeline, facilitating automated planning and execution of multi-stage research tasks. To address the critical challenge of multi-modal drug data analysis (incorporating both public datasets and user-submitted data), we developed an interactive parameterized memory pool. This innovative component standardizes real-world drug data into parametric representations, simultaneously enabling efficient knowledge retrieval in multi-turn dialogue while mitigating the information loss inherent in text-based data transmission. Additionally, we created a drug instruct dataset across 8 essential drug discovery tasks for model fine-tuning and evaluation. Based on the Berkeley function calling evaluation framework, DrugPilot demonstrated the most advanced tool calling capabilities on our drug discovery tool instruction dataset, outperforming existing agents (e.g., ReAct, LoT). Specifically, it achieves task completion rates of 98.0%, 93.5%, and 64.0% on simple, multiple, and multi-turn tasks, respectively.", "subjects": "Artificial Intelligence (cs.AI); Biomolecules (q-bio.BM)", "comments": "22 pages, 10 figures, 5 tables", "pdf_url": "https://arxiv.org/pdf/2505.13940.pdf", "abstract_url": "https://arxiv.org/abs/2505.13940", "categories": ["Artificial Intelligence (cs.AI)", "Biomolecules (q-bio.BM)"], "matching_keywords": ["agent"], "AI": {"tldr": "DrugPilot是一个基于大型语言模型（LLM）的参数化推理代理，旨在解决药物发现领域中的多模态和异构数据处理、领域知识动态更新延迟以及复杂计算任务预测结果信心不足等挑战。通过其参数化推理架构和交互式参数化内存池，DrugPilot支持药物发现流程的主要阶段，并在药物发现工具指令数据集上展示了先进的工具调用能力。", "motivation": "解决药物发现领域中大型语言模型在处理多模态和异构数据、动态更新领域知识以及预测复杂计算任务结果时面临的挑战。", "method": "提出了DrugPilot，一个基于LLM的参数化推理代理，采用参数化推理架构和交互式参数化内存池来处理和标准化药物数据，同时利用药物指令数据集进行模型微调和评估。", "result": "DrugPilot在药物发现工具指令数据集上展示了最先进的工具调用能力，在简单、多重和多轮任务上的任务完成率分别为98.0%、93.5%和64.0%。", "conclusion": "DrugPilot通过其创新的参数化推理架构和交互式参数化内存池，有效地解决了药物发现领域中的关键挑战，为自动化规划和执行多阶段研究任务提供了强有力的支持。"}}
{"id": "2505.13994", "title": "Divide by Question, Conquer by Agent: SPLIT-RAG with Question-Driven Graph Partitioning", "authors": ["Ruiyi Yang", "Hao Xue", "Imran Razzak", "Hakim Hacid", "Flora D. Salim"], "abstract": "Retrieval-Augmented Generation (RAG) systems empower large language models (LLMs) with external knowledge, yet struggle with efficiency-accuracy trade-offs when scaling to large knowledge graphs. Existing approaches often rely on monolithic graph retrieval, incurring unnecessary latency for simple queries and fragmented reasoning for complex multi-hop questions. To address these challenges, this paper propose SPLIT-RAG, a multi-agent RAG framework that addresses these limitations with question-driven semantic graph partitioning and collaborative subgraph retrieval. The innovative framework first create Semantic Partitioning of Linked Information, then use the Type-Specialized knowledge base to achieve Multi-Agent RAG. The attribute-aware graph segmentation manages to divide knowledge graphs into semantically coherent subgraphs, ensuring subgraphs align with different query types, while lightweight LLM agents are assigned to partitioned subgraphs, and only relevant partitions are activated during retrieval, thus reduce search space while enhancing efficiency. Finally, a hierarchical merging module resolves inconsistencies across subgraph-derived answers through logical verifications. Extensive experimental validation demonstrates considerable improvements compared to existing approaches.", "subjects": "Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Multiagent Systems (cs.MA)", "comments": "20 pages, 4 figures", "pdf_url": "https://arxiv.org/pdf/2505.13994.pdf", "abstract_url": "https://arxiv.org/abs/2505.13994", "categories": ["Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "SPLIT-RAG是一个多代理RAG框架，通过问题驱动的语义图分区和协作子图检索，解决了大规模知识图谱中效率与准确性之间的权衡问题。", "motivation": "解决在大规模知识图谱中，现有RAG系统在简单查询和复杂多跳问题上效率与准确性之间的权衡问题。", "method": "采用问题驱动的语义图分区和协作子图检索，通过属性感知的图分割将知识图谱划分为语义连贯的子图，并分配轻量级LLM代理到分区子图，仅在检索时激活相关分区。", "result": "实验验证表明，与现有方法相比，SPLIT-RAG在效率和准确性上都有显著提升。", "conclusion": "SPLIT-RAG通过创新的图分区和多代理协作检索，有效提升了RAG系统在大规模知识图谱上的性能。"}}
{"id": "2505.14079", "title": "BAR: A Backward Reasoning based Agent for Complex Minecraft Tasks", "authors": ["Weihong Du", "Wenrui Liao", "Binyu Yan", "Hongru Liang", "Anthony G. Cohn", "Wenqiang Lei"], "abstract": "Large language model (LLM) based agents have shown great potential in following human instructions and automatically completing various tasks. To complete a task, the agent needs to decompose it into easily executed steps by planning. Existing studies mainly conduct the planning by inferring what steps should be executed next starting from the agent's initial state. However, this forward reasoning paradigm doesn't work well for complex tasks. We propose to study this issue in Minecraft, a virtual environment that simulates complex tasks based on real-world scenarios. We believe that the failure of forward reasoning is caused by the big perception gap between the agent's initial state and task goal. To this end, we leverage backward reasoning and make the planning starting from the terminal state, which can directly achieve the task goal in one step. Specifically, we design a BAckward Reasoning based agent (BAR). It is equipped with a recursive goal decomposition module, a state consistency maintaining module and a stage memory module to make robust, consistent, and efficient planning starting from the terminal state. Experimental results demonstrate the superiority of BAR over existing methods and the effectiveness of proposed modules.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.14079.pdf", "abstract_url": "https://arxiv.org/abs/2505.14079", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于逆向推理的代理BAR，用于完成Minecraft中的复杂任务。通过从终端状态开始规划，BAR能够更有效地分解任务并保持状态一致性，实验证明了其优越性和模块的有效性。", "motivation": "现有的基于大型语言模型（LLM）的代理在规划任务时主要采用正向推理，这在处理复杂任务时效果不佳。本文旨在解决这一限制，特别是在模拟现实世界复杂任务的Minecraft环境中。", "method": "BAR代理采用逆向推理，从任务的终端状态开始规划，配备递归目标分解模块、状态一致性维护模块和阶段记忆模块，以实现稳健、一致和高效的规划。", "result": "实验结果显示，BAR在完成复杂任务方面优于现有方法，且提出的模块有效。", "conclusion": "逆向推理为处理复杂任务提供了一种有效的规划方法，BAR的设计和模块在Minecraft环境中展现出了显著的性能提升。"}}
{"id": "2505.14146", "title": "s3: You Don't Need That Much Data to Train a Search Agent via RL", "authors": ["Pengcheng Jiang", "Xueqiang Xu", "Jiacheng Lin", "Jinfeng Xiao", "Zifeng Wang", "Jimeng Sun", "Jiawei Han"], "abstract": "Retrieval-augmented generation (RAG) systems empower large language models (LLMs) to access external knowledge during inference. Recent advances have enabled LLMs to act as search agents via reinforcement learning (RL), improving information acquisition through multi-turn interactions with retrieval engines. However, existing approaches either optimize retrieval using search-only metrics (e.g., NDCG) that ignore downstream utility or fine-tune the entire LLM to jointly reason and retrieve-entangling retrieval with generation and limiting the real search utility and compatibility with frozen or proprietary models. In this work, we propose s3, a lightweight, model-agnostic framework that decouples the searcher from the generator and trains the searcher using a Gain Beyond RAG reward: the improvement in generation accuracy over naive RAG. s3 requires only 2.4k training samples to outperform baselines trained on over 70x more data, consistently delivering stronger downstream performance across six general QA and five medical QA benchmarks.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.14146.pdf", "abstract_url": "https://arxiv.org/abs/2505.14146", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文提出了s3，一个轻量级、模型无关的框架，通过解耦搜索器和生成器，并使用超越RAG的增益奖励来训练搜索器，显著减少了训练数据需求。", "motivation": "现有的检索增强生成（RAG）系统要么使用忽略下游效用的搜索指标优化检索，要么通过微调整个大型语言模型（LLM）来联合推理和检索，这限制了实际搜索效用和与冻结或专有模型的兼容性。", "method": "提出了s3框架，该框架解耦了搜索器和生成器，并使用一种称为‘超越RAG的增益’的奖励来训练搜索器，即生成准确度相对于朴素RAG的改进。", "result": "s3仅需2.4k训练样本即可超越使用超过70倍数据训练的基线，在六个通用QA和五个医学QA基准测试中 consistently 提供更强的下游性能。", "conclusion": "s3框架通过解耦搜索器和生成器，并使用特定的奖励机制，显著减少了训练数据需求，同时提高了下游任务的性能，展示了在检索增强生成系统中的高效性和实用性。"}}
{"id": "2505.14141", "title": "Building a Stable Planner: An Extended Finite State Machine Based Planning Module for Mobile GUI Agent", "authors": ["Fanglin Mo", "Junzhe Chen", "Haoxuan Zhu", "Xuming Hu"], "abstract": "Mobile GUI agents execute user commands by directly interacting with the graphical user interface (GUI) of mobile devices, demonstrating significant potential to enhance user convenience. However, these agents face considerable challenges in task planning, as they must continuously analyze the GUI and generate operation instructions step by step. This process often leads to difficulties in making accurate task plans, as GUI agents lack a deep understanding of how to effectively use the target applications, which can cause them to become \"lost\" during task execution. To address the task planning issue, we propose SPlanner, a plug-and-play planning module to generate execution plans that guide vision language model(VLMs) in executing tasks. The proposed planning module utilizes extended finite state machines (EFSMs) to model the control logits and configurations of mobile applications. It then decomposes a user instruction into a sequence of primary function modeled in EFSMs, and generate the execution path by traversing the EFSMs. We further refine the execution path into a natural language plan using an LLM. The final plan is concise and actionable, and effectively guides VLMs to generate interactive GUI actions to accomplish user tasks. SPlanner demonstrates strong performance on dynamic benchmarks reflecting real-world mobile usage. On the AndroidWorld benchmark, SPlanner achieves a 63.8% task success rate when paired with Qwen2.5-VL-72B as the VLM executor, yielding a 28.8 percentage point improvement compared to using Qwen2.5-VL-72B without planning assistance.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "10 pages. Submitted to EMNLP 2025", "pdf_url": "https://arxiv.org/pdf/2505.14141.pdf", "abstract_url": "https://arxiv.org/abs/2505.14141", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为SPlanner的插件式规划模块，旨在解决移动GUI代理在任务规划中的挑战。通过使用扩展有限状态机(EFSMs)建模移动应用的控制逻辑和配置，SPlanner能够将用户指令分解为一系列主要功能，并生成执行路径。最终，通过大型语言模型(LLM)将执行路径精炼为自然语言计划，有效指导视觉语言模型(VLMs)生成交互式GUI动作以完成用户任务。在AndroidWorld基准测试中，SPlanner与Qwen2.5-VL-72B配合使用时，任务成功率达到了63.8%，比不使用规划辅助时提高了28.8个百分点。", "motivation": "移动GUI代理在执行用户命令时，由于缺乏对目标应用程序的深入理解，往往在任务规划中遇到困难，导致在执行过程中“迷失”。本文旨在解决这一问题，提高移动GUI代理的任务规划准确性和执行效率。", "method": "本文提出的SPlanner规划模块利用扩展有限状态机(EFSMs)建模移动应用的控制逻辑和配置，将用户指令分解为一系列主要功能，并通过遍历EFSMs生成执行路径。随后，使用大型语言模型(LLM)将执行路径精炼为自然语言计划。", "result": "在AndroidWorld基准测试中，SPlanner与Qwen2.5-VL-72B配合使用时，任务成功率达到了63.8%，比不使用规划辅助时提高了28.8个百分点。", "conclusion": "SPlanner作为一种插件式规划模块，能够有效提高移动GUI代理的任务规划准确性和执行效率，具有广泛的应用前景。"}}
{"id": "2505.14099", "title": "Beyond Chains: Bridging Large Language Models and Knowledge Bases in Complex Question Answering", "authors": ["Yihua Zhu", "Qianying Liu", "Akiko Aizawa", "Hidetoshi Shimodaira"], "abstract": "Knowledge Base Question Answering (KBQA) aims to answer natural language questions using structured knowledge from KBs. While LLM-only approaches offer generalization, they suffer from outdated knowledge, hallucinations, and lack of transparency. Chain-based KG-RAG methods address these issues by incorporating external KBs, but are limited to simple chain-structured questions due to the absence of planning and logical structuring. Inspired by semantic parsing methods, we propose PDRR: a four-stage framework consisting of Predict, Decompose, Retrieve, and Reason. Our method first predicts the question type and decomposes the question into structured triples. Then retrieves relevant information from KBs and guides the LLM as an agent to reason over and complete the decomposed triples. Experimental results demonstrate that PDRR consistently outperforms existing methods across various LLM backbones and achieves superior performance on both chain-structured and non-chain complex questions.", "subjects": "Computation and Language (cs.CL); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.14099.pdf", "abstract_url": "https://arxiv.org/abs/2505.14099", "categories": ["Computation and Language (cs.CL)", "Information Retrieval (cs.IR)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文提出了一种名为PDRR的四阶段框架，旨在通过预测、分解、检索和推理四个步骤，将大型语言模型与知识库结合，以解决复杂问答问题。该方法在多种LLM骨干网络上均表现出色，特别是在处理链式和非链式复杂问题时。", "motivation": "解决知识库问答（KBQA）中大型语言模型（LLM）存在的知识过时、幻觉和缺乏透明度问题，以及链式知识图谱检索增强生成（KG-RAG）方法在处理复杂问题时的局限性。", "method": "提出了PDRR框架，包括预测问题类型、将问题分解为结构化三元组、从知识库检索相关信息，并引导LLM作为代理进行推理和完成分解的三元组。", "result": "实验结果表明，PDRR在多种LLM骨干网络上均优于现有方法，在处理链式和非链式复杂问题时表现出色。", "conclusion": "PDRR框架有效地结合了大型语言模型和知识库，提高了复杂问答的准确性和效率，为KBQA领域提供了新的解决方案。"}}
{"id": "2505.14101", "title": "MultiHal: Multilingual Dataset for Knowledge-Graph Grounded Evaluation of LLM Hallucinations", "authors": ["Ernests Lavrinovics", "Russa Biswas", "Katja Hose", "Johannes Bjerva"], "abstract": "Large Language Models (LLMs) have inherent limitations of faithfulness and factuality, commonly referred to as hallucinations. Several benchmarks have been developed that provide a test bed for factuality evaluation within the context of English-centric datasets, while relying on supplementary informative context like web links or text passages but ignoring the available structured factual resources. To this end, Knowledge Graphs (KGs) have been identified as a useful aid for hallucination mitigation, as they provide a structured way to represent the facts about entities and their relations with minimal linguistic overhead. We bridge the lack of KG paths and multilinguality for factual language modeling within the existing hallucination evaluation benchmarks and propose a KG-based multilingual, multihop benchmark called \\textbf{MultiHal} framed for generative text evaluation. As part of our data collection pipeline, we mined 140k KG-paths from open-domain KGs, from which we pruned noisy KG-paths, curating a high-quality subset of 25.9k. Our baseline evaluation shows an absolute scale increase by approximately 0.12 to 0.36 points for the semantic similarity score in KG-RAG over vanilla QA across multiple languages and multiple models, demonstrating the potential of KG integration. We anticipate MultiHal will foster future research towards several graph-based hallucination mitigation and fact-checking tasks.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.14101.pdf", "abstract_url": "https://arxiv.org/abs/2505.14101", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了MultiHal，一个基于知识图谱的多语言、多跳基准测试，旨在评估大型语言模型（LLMs）的幻觉问题。通过从开放领域知识图谱中挖掘和筛选高质量的KG路径，MultiHal为生成文本评估提供了一个结构化的事实资源，展示了知识图谱整合在减少幻觉方面的潜力。", "motivation": "解决大型语言模型（LLMs）在忠实性和事实性方面的固有局限性，即幻觉问题，特别是在多语言环境下，现有评估基准缺乏对结构化事实资源的利用。", "method": "提出一个基于知识图谱（KGs）的多语言、多跳基准测试MultiHal，通过挖掘和筛选高质量的KG路径，构建了一个用于生成文本评估的数据集。", "result": "基线评估显示，与传统的问答系统相比，整合知识图谱的KG-RAG在多种语言和模型中的语义相似度得分提高了约0.12到0.36点。", "conclusion": "MultiHal基准测试有望促进未来基于图结构的幻觉减少和事实核查任务的研究，展示了知识图谱在提高语言模型事实性方面的潜力。"}}
{"id": "2505.14148", "title": "MM-Agent: LLM as Agents for Real-world Mathematical Modeling Problem", "authors": ["Fan Liu", "Zherui Yang", "Cancheng Liu", "Tianrui Song", "Xiaofeng Gao", "Hao Liu"], "abstract": "Mathematical modeling is a cornerstone of scientific discovery and engineering practice, enabling the translation of real-world problems into formal systems across domains such as physics, biology, and economics. Unlike mathematical reasoning, which assumes a predefined formulation, modeling requires open-ended problem analysis, abstraction, and principled formalization. While Large Language Models (LLMs) have shown strong reasoning capabilities, they fall short in rigorous model construction, limiting their utility in real-world problem-solving. To this end, we formalize the task of LLM-powered real-world mathematical modeling, where agents must analyze problems, construct domain-appropriate formulations, and generate complete end-to-end solutions. We introduce MM-Bench, a curated benchmark of 111 problems from the Mathematical Contest in Modeling (MCM/ICM), spanning the years 2000 to 2025 and across ten diverse domains such as physics, biology, and economics. To tackle this task, we propose MM-Agent, an expert-inspired framework that decomposes mathematical modeling into four stages: open-ended problem analysis, structured model formulation, computational problem solving, and report generation. Experiments on MM-Bench show that MM-Agent significantly outperforms baseline agents, achieving an 11.88\\% improvement over human expert solutions while requiring only 15 minutes and \\$0.88 per task using GPT-4o. Furthermore, under official MCM/ICM protocols, MM-Agent assisted two undergraduate teams in winning the Finalist Award (\\textbf{top 2.0\\% among 27,456 teams}) in MCM/ICM 2025, demonstrating its practical effectiveness as a modeling copilot. Our code is available at", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.14148.pdf", "abstract_url": "https://arxiv.org/abs/2505.14148", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文介绍了MM-Agent，一个利用大型语言模型（LLM）作为代理解决现实世界数学建模问题的框架。通过MM-Bench基准测试，MM-Agent在多个领域展现出优于基线代理和人类专家的性能，并在MCM/ICM 2025中协助团队获得优异成绩。", "motivation": "数学建模是科学发现和工程实践的基础，但现有的大型语言模型在严格的模型构建方面存在不足，限制了其在现实世界问题解决中的应用。", "method": "提出了MM-Agent框架，将数学建模分解为四个阶段：开放性问题分析、结构化模型构建、计算问题解决和报告生成。", "result": "MM-Agent在MM-Bench上显著优于基线代理，性能提升11.88%，并在MCM/ICM 2025中协助团队获得Finalist Award。", "conclusion": "MM-Agent作为一个建模助手，展示了在实际数学建模问题中的高效性和实用性，为科学和工程领域的自动化建模提供了新思路。"}}
{"id": "2505.14289", "title": "EVA: Red-Teaming GUI Agents via Evolving Indirect Prompt Injection", "authors": ["Yijie Lu", "Tianjie Ju", "Manman Zhao", "Xinbei Ma", "Yuan Guo", "ZhuoSheng Zhang"], "abstract": "As multimodal agents are increasingly trained to operate graphical user interfaces (GUIs) to complete user tasks, they face a growing threat from indirect prompt injection, attacks in which misleading instructions are embedded into the agent's visual environment, such as popups or chat messages, and misinterpreted as part of the intended task. A typical example is environmental injection, in which GUI elements are manipulated to influence agent behavior without directly modifying the user prompt. To address these emerging attacks, we propose EVA, a red teaming framework for indirect prompt injection which transforms the attack into a closed loop optimization by continuously monitoring an agent's attention distribution over the GUI and updating adversarial cues, keywords, phrasing, and layout, in response. Compared with prior one shot methods that generate fixed prompts without regard for how the model allocates visual attention, EVA dynamically adapts to emerging attention hotspots, yielding substantially higher attack success rates and far greater transferability across diverse GUI scenarios. We evaluate EVA on six widely used generalist and specialist GUI agents in realistic settings such as popup manipulation, chat based phishing, payments, and email composition. Experimental results show that EVA substantially improves success rates over static baselines. Under goal agnostic constraints, where the attacker does not know the agent's task intent, EVA still discovers effective patterns. Notably, we find that injection styles transfer well across models, revealing shared behavioral biases in GUI agents. These results suggest that evolving indirect prompt injection is a powerful tool not only for red teaming agents, but also for uncovering common vulnerabilities in their multimodal decision making.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.14289.pdf", "abstract_url": "https://arxiv.org/abs/2505.14289", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为EVA的框架，用于通过不断演化的间接提示注入来红队测试图形用户界面(GUI)代理，以提高攻击成功率和跨场景的转移能力。", "motivation": "随着多模态代理越来越多地被训练用于操作图形用户界面(GUI)以完成用户任务，它们面临着来自间接提示注入攻击的日益增长的威胁，这种攻击通过将误导性指令嵌入代理的视觉环境中来影响代理行为。", "method": "EVA框架通过持续监控代理对GUI的注意力分布并更新对抗性线索、关键词、措辞和布局，将攻击转化为一个闭环优化过程。", "result": "实验结果显示，EVA在多种GUI代理上的攻击成功率显著高于静态基线方法，并且在目标不可知的约束下仍能发现有效的攻击模式。", "conclusion": "研究表明，演化的间接提示注入不仅是红队测试代理的强大工具，还能揭示多模态决策中的共同漏洞。"}}
{"id": "2505.14209", "title": "Embedded Mean Field Reinforcement Learning for Perimeter-defense Game", "authors": ["Li Wang", "Xin Yu", "Xuxin Lv", "Gangzheng Ai", "Wenjun Wu"], "abstract": "With the rapid advancement of unmanned aerial vehicles (UAVs) and missile technologies, perimeter-defense game between attackers and defenders for the protection of critical regions have become increasingly complex and strategically significant across a wide range of domains. However, existing studies predominantly focus on small-scale, simplified two-dimensional scenarios, often overlooking realistic environmental perturbations, motion dynamics, and inherent heterogeneity--factors that pose substantial challenges to real-world applicability. To bridge this gap, we investigate large-scale heterogeneous perimeter-defense game in a three-dimensional setting, incorporating realistic elements such as motion dynamics and wind fields. We derive the Nash equilibrium strategies for both attackers and defenders, characterize the victory regions, and validate our theoretical findings through extensive simulations. To tackle large-scale heterogeneous control challenges in defense strategies, we propose an Embedded Mean-Field Actor-Critic (EMFAC) framework. EMFAC leverages representation learning to enable high-level action aggregation in a mean-field manner, supporting scalable coordination among defenders. Furthermore, we introduce a lightweight agent-level attention mechanism based on reward representation, which selectively filters observations and mean-field information to enhance decision-making efficiency and accelerate convergence in large-scale tasks. Extensive simulations across varying scales demonstrate the effectiveness and adaptability of EMFAC, which outperforms established baselines in both convergence speed and overall performance. To further validate practicality, we test EMFAC in small-scale real-world experiments and conduct detailed analyses, offering deeper insights into the framework's effectiveness in complex scenarios.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.14209.pdf", "abstract_url": "https://arxiv.org/abs/2505.14209", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究了大规模异构三维环境下的周界防御游戏，提出了嵌入式平均场演员-评论家（EMFAC）框架，以解决现实环境中的运动动力学和风场等挑战，并通过模拟和实际实验验证了其有效性。", "motivation": "随着无人机和导弹技术的快速发展，攻击者和防御者之间的周界防御游戏在多个领域变得日益复杂和战略重要。现有研究多集中于小规模、简化的二维场景，忽视了现实环境扰动、运动动力学和异构性等挑战。", "method": "本文提出了一种嵌入式平均场演员-评论家（EMFAC）框架，利用表示学习实现高级动作的均值场聚合，支持防御者之间的可扩展协调，并引入基于奖励表示的轻量级代理级注意力机制，以增强决策效率和加速大规模任务的收敛。", "result": "通过不同规模的广泛模拟，EMFAC在收敛速度和整体性能上均优于现有基线。小规模实际实验进一步验证了EMFAC在复杂场景中的有效性。", "conclusion": "EMFAC框架在解决大规模异构周界防御游戏中的挑战方面表现出色，不仅在模拟中优于现有方法，而且在实际应用中也显示出良好的适应性和有效性。"}}
{"id": "2505.14163", "title": "DSMentor: Enhancing Data Science Agents with Curriculum Learning and Online Knowledge Accumulation", "authors": ["He Wang", "Alexander Hanbo Li", "Yiqun Hu", "Sheng Zhang", "Hideo Kobayashi", "Jiani Zhang", "Henry Zhu", "Chung-Wei Hang", "Patrick Ng"], "abstract": "Large language model (LLM) agents have shown promising performance in generating code for solving complex data science problems. Recent studies primarily focus on enhancing in-context learning through improved search, sampling, and planning techniques, while overlooking the importance of the order in which problems are tackled during inference. In this work, we develop a novel inference-time optimization framework, referred to as DSMentor, which leverages curriculum learning -- a strategy that introduces simpler task first and progressively moves to more complex ones as the learner improves -- to enhance LLM agent performance in challenging data science tasks. Our mentor-guided framework organizes data science tasks in order of increasing difficulty and incorporates a growing long-term memory to retain prior experiences, guiding the agent's learning progression and enabling more effective utilization of accumulated knowledge. We evaluate DSMentor through extensive experiments on DSEval and QRData benchmarks. Experiments show that DSMentor using Claude-3.5-Sonnet improves the pass rate by up to 5.2% on DSEval and QRData compared to baseline agents. Furthermore, DSMentor demonstrates stronger causal reasoning ability, improving the pass rate by 8.8% on the causality problems compared to GPT-4 using Program-of-Thoughts prompts. Our work underscores the importance of developing effective strategies for accumulating and utilizing knowledge during inference, mirroring the human learning process and opening new avenues for improving LLM performance through curriculum-based inference optimization.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.14163.pdf", "abstract_url": "https://arxiv.org/abs/2505.14163", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "DSMentor是一个新颖的推理时优化框架，通过课程学习和在线知识积累来增强大型语言模型（LLM）代理在数据科学任务中的表现。它通过按难度递增的顺序组织任务，并利用长期记忆保留先前经验，显著提高了任务通过率和因果推理能力。", "motivation": "当前的研究主要关注通过改进搜索、采样和规划技术来增强上下文学习，而忽视了在推理过程中解决问题的顺序的重要性。DSMentor旨在通过课程学习和知识积累策略，模拟人类学习过程，提高LLM代理在复杂数据科学任务中的性能。", "method": "DSMentor采用课程学习策略，按难度递增的顺序组织数据科学任务，并结合一个不断增长的长期记忆来保留先前的经验，以指导代理的学习进程和更有效地利用积累的知识。", "result": "实验显示，使用Claude-3.5-Sonnet的DSMentor在DSEval和QRData基准测试中的通过率比基线代理提高了5.2%。在因果推理问题上，DSMentor的通过率比使用Program-of-Thoughts提示的GPT-4提高了8.8%。", "conclusion": "DSMentor的工作强调了在推理过程中积累和利用知识的重要性，模拟了人类学习过程，并通过基于课程的推理优化为提升LLM性能开辟了新途径。"}}
{"id": "2505.14510", "title": "BACON: A fully explainable AI model with graded logic for decision making problems", "authors": ["Haishi Bai", "Jozo Dujmovic", "Jianwu Wang"], "abstract": "As machine learning models and autonomous agents are increasingly deployed in high-stakes, real-world domains such as healthcare, security, finance, and robotics, the need for transparent and trustworthy explanations has become critical. To ensure end-to-end transparency of AI decisions, we need models that are not only accurate but also fully explainable and human-tunable. We introduce BACON, a novel framework for automatically training explainable AI models for decision making problems using graded logic. BACON achieves high predictive accuracy while offering full structural transparency and precise, logic-based symbolic explanations, enabling effective human-AI collaboration and expert-guided refinement. We evaluate BACON with a diverse set of scenarios: classic Boolean approximation, Iris flower classification, house purchasing decisions and breast cancer diagnosis. In each case, BACON provides high-performance models while producing compact, human-verifiable decision logic. These results demonstrate BACON's potential as a practical and principled approach for delivering crisp, trustworthy explainable AI.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.14510.pdf", "abstract_url": "https://arxiv.org/abs/2505.14510", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "BACON是一种新型的完全可解释AI模型框架，使用分级逻辑自动训练决策问题模型，旨在提供高预测准确性和完全结构透明度。", "motivation": "随着机器学习模型和自主代理在医疗、安全、金融和机器人等高风险领域的广泛应用，对透明和可信解释的需求变得至关重要。", "method": "BACON框架采用分级逻辑，自动训练可解释的AI模型，确保决策的准确性和结构透明度。", "result": "在布尔近似、鸢尾花分类、购房决策和乳腺癌诊断等多种场景中，BACON都能提供高性能模型和紧凑、人类可验证的决策逻辑。", "conclusion": "BACON展示了作为一种实用和原则性方法的潜力，能够提供清晰、可信的可解释AI，促进有效的人机合作和专家指导的改进。"}}
{"id": "2505.14396", "title": "Causal Cartographer: From Mapping to Reasoning Over Counterfactual Worlds", "authors": ["Gaël Gendron", "Jože M. Rožanec", "Michael Witbrock", "Gillian Dobbie"], "abstract": "Causal world models are systems that can answer counterfactual questions about an environment of interest, i.e. predict how it would have evolved if an arbitrary subset of events had been realized differently. It requires understanding the underlying causes behind chains of events and conducting causal inference for arbitrary unseen distributions. So far, this task eludes foundation models, notably large language models (LLMs), which do not have demonstrated causal reasoning capabilities beyond the memorization of existing causal relationships. Furthermore, evaluating counterfactuals in real-world applications is challenging since only the factual world is observed, limiting evaluation to synthetic datasets. We address these problems by explicitly extracting and modeling causal relationships and propose the Causal Cartographer framework. First, we introduce a graph retrieval-augmented generation agent tasked to retrieve causal relationships from data. This approach allows us to construct a large network of real-world causal relationships that can serve as a repository of causal knowledge and build real-world counterfactuals. In addition, we create a counterfactual reasoning agent constrained by causal relationships to perform reliable step-by-step causal inference. We show that our approach can extract causal knowledge and improve the robustness of LLMs for causal reasoning tasks while reducing inference costs and spurious correlations.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": "29 pages, 9 pages for the main paper, 20 pages for the references and appendix, 25 figures", "pdf_url": "https://arxiv.org/pdf/2505.14396.pdf", "abstract_url": "https://arxiv.org/abs/2505.14396", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了Causal Cartographer框架，旨在通过显式提取和建模因果关系，解决基础模型（如大型语言模型）在因果推理任务中的局限性，并提高其在反事实推理中的鲁棒性。", "motivation": "解决基础模型（如大型语言模型）在因果推理任务中的局限性，特别是在反事实问题上的推理能力不足，以及在实际应用中评估反事实的挑战。", "method": "提出了Causal Cartographer框架，包括一个图检索增强生成代理来从数据中检索因果关系，以及一个受因果关系约束的反事实推理代理，以进行可靠的逐步因果推理。", "result": "该方法能够提取因果知识，提高大型语言模型在因果推理任务中的鲁棒性，同时减少推理成本和虚假相关性。", "conclusion": "Causal Cartographer框架通过显式建模因果关系，为反事实推理提供了一种有效的方法，有望在因果推理领域产生重要影响。"}}
{"id": "2505.14381", "title": "SCAN: Semantic Document Layout Analysis for Textual and Visual Retrieval-Augmented Generation", "authors": ["Yuyang Dong", "Nobuhiro Ueda", "Krisztián Boros", "Daiki Ito", "Takuya Sera", "Masafumi Oyamada"], "abstract": "With the increasing adoption of Large Language Models (LLMs) and Vision-Language Models (VLMs), rich document analysis technologies for applications like Retrieval-Augmented Generation (RAG) and visual RAG are gaining significant attention. Recent research indicates that using VLMs can achieve better RAG performance, but processing rich documents still remains a challenge since a single page contains large amounts of information. In this paper, we present SCAN (\\textbf{S}emanti\\textbf{C} Document Layout \\textbf{AN}alysis), a novel approach enhancing both textual and visual Retrieval-Augmented Generation (RAG) systems working with visually rich documents. It is a VLM-friendly approach that identifies document components with appropriate semantic granularity, balancing context preservation with processing efficiency. SCAN uses a coarse-grained semantic approach that divides documents into coherent regions covering continuous components. We trained the SCAN model by fine-tuning object detection models with sophisticated annotation datasets. Our experimental results across English and Japanese datasets demonstrate that applying SCAN improves end-to-end textual RAG performance by up to 9.0\\% and visual RAG performance by up to 6.4\\%, outperforming conventional approaches and even commercial document processing solutions.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "v1", "pdf_url": "https://arxiv.org/pdf/2505.14381.pdf", "abstract_url": "https://arxiv.org/abs/2505.14381", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了SCAN，一种用于增强文本和视觉检索增强生成（RAG）系统的新方法，特别针对视觉丰富的文档。通过细粒度语义分析，SCAN有效识别文档组件，提升处理效率。实验显示，SCAN在英文和日文数据集上显著提高了RAG性能。", "motivation": "随着大型语言模型（LLMs）和视觉语言模型（VLMs）的广泛应用，针对如检索增强生成（RAG）和视觉RAG等应用的丰富文档分析技术受到重视。然而，处理包含大量信息的单个页面仍是一大挑战。", "method": "SCAN采用了一种粗粒度语义方法，将文档划分为覆盖连续组件的连贯区域。通过微调对象检测模型并结合复杂的注释数据集来训练SCAN模型。", "result": "实验结果表明，应用SCAN可以使端到端文本RAG性能提升高达9.0%，视觉RAG性能提升高达6.4%，优于传统方法甚至商业文档处理解决方案。", "conclusion": "SCAN作为一种VLM友好的方法，通过适当的语义粒度识别文档组件，在保持上下文的同时提高了处理效率，显著提升了RAG系统的性能。"}}
{"id": "2505.14544", "title": "Multi-agent Reinforcement Learning vs. Fixed-Time Control for Traffic Signal Optimization: A Simulation Study", "authors": ["Saahil Mahato"], "abstract": "Urban traffic congestion, particularly at intersections, significantly impacts travel time, fuel consumption, and emissions. Traditional fixed-time signal control systems often lack the adaptability to manage dynamic traffic patterns effectively. This study explores the application of multi-agent reinforcement learning (MARL) to optimize traffic signal coordination across multiple intersections within a simulated environment. Utilizing Pygame, a simulation was developed to model a network of interconnected intersections with randomly generated vehicle flows to reflect realistic traffic variability. A decentralized MARL controller was implemented, in which each traffic signal operates as an autonomous agent, making decisions based on local observations and information from neighboring agents. Performance was evaluated against a baseline fixed-time controller using metrics such as average vehicle wait time and overall throughput. The MARL approach demonstrated statistically significant improvements, including reduced average waiting times and improved throughput. These findings suggest that MARL-based dynamic control strategies hold substantial promise for improving urban traffic management efficiency. More research is recommended to address scalability and real-world implementation challenges.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.14544.pdf", "abstract_url": "https://arxiv.org/abs/2505.14544", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本研究通过模拟环境比较了多智能体强化学习（MARL）与固定时间控制在交通信号优化中的应用，发现MARL在减少平均等待时间和提高吞吐量方面表现更优。", "motivation": "城市交通拥堵，尤其是在十字路口，严重影响了旅行时间、燃料消耗和排放。传统的固定时间信号控制系统往往缺乏有效管理动态交通模式的适应性。", "method": "利用Pygame开发了一个模拟环境，模拟了具有随机生成车辆流的互连交叉口网络，以反映真实的交通变异性。实现了一个分散的MARL控制器，其中每个交通信号作为一个自主代理，基于局部观察和邻近代理的信息做出决策。", "result": "与基线固定时间控制器相比，MARL方法在平均车辆等待时间和整体吞吐量等指标上显示出统计上显著的改进。", "conclusion": "研究结果表明，基于MARL的动态控制策略在提高城市交通管理效率方面具有巨大潜力。建议进行更多研究以解决可扩展性和实际实施挑战。"}}
{"id": "2505.14569", "title": "Agent Context Protocols Enhance Collective Inference", "authors": ["Devansh Bhardwaj", "Arjun Beniwal", "Shreyas Chaudhari", "Ashwin Kalyan", "Tanmay Rajpurohit", "Karthik R. Narasimhan", "Ameet Deshpande", "Vishvak Murahari"], "abstract": "AI agents have become increasingly adept at complex tasks such as coding, reasoning, and multimodal understanding. However, building generalist systems requires moving beyond individual agents to collective inference -- a paradigm where multi-agent systems with diverse, task-specialized agents complement one another through structured communication and collaboration. Today, coordination is usually handled with imprecise, ad-hoc natural language, which limits complex interaction and hinders interoperability with domain-specific agents. We introduce Agent context protocols (ACPs): a domain- and agent-agnostic family of structured protocols for agent-agent communication, coordination, and error handling. ACPs combine (i) persistent execution blueprints -- explicit dependency graphs that store intermediate agent outputs -- with (ii) standardized message schemas, enabling robust and fault-tolerant multi-agent collective inference. ACP-powered generalist systems reach state-of-the-art performance: 28.3 % accuracy on AssistantBench for long-horizon web assistance and best-in-class multimodal technical reports, outperforming commercial AI systems in human evaluation. ACPs are highly modular and extensible, allowing practitioners to build top-tier generalist agents quickly.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.14569.pdf", "abstract_url": "https://arxiv.org/abs/2505.14569", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了代理上下文协议（ACPs），一种用于代理间通信、协调和错误处理的结构化协议家族，旨在通过增强集体推理来提升多代理系统的性能。", "motivation": "当前多代理系统协调通常依赖于不精确、临时的自然语言，这限制了复杂交互并阻碍了与领域特定代理的互操作性。", "method": "引入代理上下文协议（ACPs），结合持久执行蓝图和标准化消息模式，以实现健壮和容错的多代理集体推理。", "result": "使用ACPs的通用系统在长视野网络辅助和多模态技术报告方面达到了最先进的性能，优于商业AI系统。", "conclusion": "ACPs具有高度的模块化和可扩展性，使从业者能够快速构建顶级通用代理。"}}
{"id": "2505.14539", "title": "A Logic of General Attention Using Edge-Conditioned Event Models (Extended Version)", "authors": ["Gaia Belardinelli", "Thomas Bolander", "Sebastian Watzl"], "abstract": "In this work, we present the first general logic of attention. Attention is a powerful cognitive ability that allows agents to focus on potentially complex information, such as logically structured propositions, higher-order beliefs, or what other agents pay attention to. This ability is a strength, as it helps to ignore what is irrelevant, but it can also introduce biases when some types of information or agents are systematically ignored. Existing dynamic epistemic logics for attention cannot model such complex attention scenarios, as they only model attention to atomic formulas. Additionally, such logics quickly become cumbersome, as their size grows exponentially in the number of agents and announced literals. Here, we introduce a logic that overcomes both limitations. First, we generalize edge-conditioned event models, which we show to be as expressive as standard event models yet exponentially more succinct (generalizing both standard event models and generalized arrow updates). Second, we extend attention to arbitrary formulas, allowing agents to also attend to other agents' beliefs or attention. Our work treats attention as a modality, like belief or awareness. We introduce attention principles that impose closure properties on that modality and that can be used in its axiomatization. Throughout, we illustrate our framework with examples of AI agents reasoning about human attentional biases, demonstrating how such agents can discover attentional biases.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.14539.pdf", "abstract_url": "https://arxiv.org/abs/2505.14539", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了第一个通用的注意力逻辑，通过边缘条件事件模型扩展了动态认知逻辑，以建模复杂的注意力场景，包括对任意公式的关注，如其他代理的信念或注意力。", "motivation": "解决现有动态认知逻辑在建模复杂注意力场景时的局限性，特别是只能关注原子公式和模型规模随代理数量及宣布的文字数量指数增长的问题。", "method": "引入边缘条件事件模型，证明其与标准事件模型具有相同的表达能力但更简洁，并将注意力扩展到任意公式。", "result": "提出的逻辑能够更有效地建模复杂的注意力场景，包括代理对其他代理信念或注意力的关注，同时避免了模型规模的指数增长。", "conclusion": "通过将注意力视为一种模态，并引入注意力原则，本研究为AI代理推理人类注意力偏见提供了新的框架，展示了如何发现注意力偏见。"}}
{"id": "2505.14668", "title": "ContextAgent: Context-Aware Proactive LLM Agents with Open-World Sensory Perceptions", "authors": ["Bufang Yang", "Lilin Xu", "Liekang Zeng", "Kaiwei Liu", "Siyang Jiang", "Wenrui Lu", "Hongkai Chen", "Xiaofan Jiang", "Guoliang Xing", "Zhenyu Yan"], "abstract": "Recent advances in Large Language Models (LLMs) have propelled intelligent agents from reactive responses to proactive support. While promising, existing proactive agents either rely exclusively on observations from enclosed environments (e.g., desktop UIs) with direct LLM inference or employ rule-based proactive notifications, leading to suboptimal user intent understanding and limited functionality for proactive service. In this paper, we introduce ContextAgent, the first context-aware proactive agent that incorporates extensive sensory contexts to enhance the proactive capabilities of LLM agents. ContextAgent first extracts multi-dimensional contexts from massive sensory perceptions on wearables (e.g., video and audio) to understand user intentions. ContextAgent then leverages the sensory contexts and the persona contexts from historical data to predict the necessity for proactive services. When proactive assistance is needed, ContextAgent further automatically calls the necessary tools to assist users unobtrusively. To evaluate this new task, we curate ContextAgentBench, the first benchmark for evaluating context-aware proactive LLM agents, covering 1,000 samples across nine daily scenarios and twenty tools. Experiments on ContextAgentBench show that ContextAgent outperforms baselines by achieving up to 8.5% and 6.0% higher accuracy in proactive predictions and tool calling, respectively. We hope our research can inspire the development of more advanced, human-centric, proactive AI assistants.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.14668.pdf", "abstract_url": "https://arxiv.org/abs/2505.14668", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "ContextAgent是一种上下文感知的主动LLM代理，通过整合来自可穿戴设备的多维感官上下文和历史人物上下文，增强了对用户意图的理解和主动服务能力。", "motivation": "解决现有主动代理在封闭环境中依赖观察或基于规则的通知，导致用户意图理解不足和主动服务功能有限的问题。", "method": "ContextAgent首先从可穿戴设备的视频和音频等大量感官感知中提取多维上下文以理解用户意图，然后结合感官上下文和历史人物上下文预测是否需要主动服务，并在需要时自动调用必要工具。", "result": "在ContextAgentBench基准测试中，ContextAgent在主动预测和工具调用方面的准确率分别比基线高出8.5%和6.0%。", "conclusion": "ContextAgent的研究有望激发更先进、以人为中心的主动AI助手的发展。"}}
{"id": "2505.14212", "title": "Automatic Dataset Generation for Knowledge Intensive Question Answering Tasks", "authors": ["Sizhe Yuen", "Ting Su", "Ziyang Wang", "Yali Du", "Adam J. Sobey"], "abstract": "A question-answering (QA) system is to search suitable answers within a knowledge base. Current QA systems struggle with queries requiring complex reasoning or real-time knowledge integration. They are often supplemented with retrieval techniques on a data source such as Retrieval-Augmented Generation (RAG). However, RAG continues to face challenges in handling complex reasoning and logical connections between multiple sources of information. A novel approach for enhancing Large Language Models (LLMs) in knowledge-intensive QA tasks is presented through the automated generation of context-based QA pairs. This methodology leverages LLMs to create fine-tuning data, reducing reliance on human labelling and improving model comprehension and reasoning capabilities. The proposed system includes an automated QA generator and a model fine-tuner, evaluated using perplexity, ROUGE, BLEU, and BERTScore. Comprehensive experiments demonstrate improvements in logical coherence and factual accuracy, with implications for developing adaptable Artificial Intelligence (AI) systems. Mistral-7b-v0.3 outperforms Llama-3-8b with BERT F1, BLEU, and ROUGE scores 0.858, 0.172, and 0.260 of for the LLM generated QA pairs compared to scores of 0.836, 0.083, and 0.139 for the human annotated QA pairs.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.14212.pdf", "abstract_url": "https://arxiv.org/abs/2505.14212", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种自动生成基于上下文的问答对的新方法，以增强大型语言模型在知识密集型问答任务中的表现，通过减少对人类标注的依赖并提高模型的理解和推理能力。", "motivation": "当前的问答系统在处理需要复杂推理或实时知识整合的查询时存在困难，检索增强生成（RAG）等技术在应对复杂推理和多源信息逻辑连接方面仍面临挑战。", "method": "利用大型语言模型自动生成用于微调的问答对数据，包括一个自动问答生成器和一个模型微调器，并使用困惑度、ROUGE、BLEU和BERTScore进行评估。", "result": "实验显示，该方法在逻辑连贯性和事实准确性方面有所改进，Mistral-7b-v0.3在BERT F1、BLEU和ROUGE分数上优于Llama-3-8b。", "conclusion": "这项研究为开发适应性更强的人工智能系统提供了可能，展示了自动生成问答对在提升模型性能方面的潜力。"}}
{"id": "2505.13453", "title": "Pel, A Programming Language for Orchestrating AI Agents", "authors": ["Behnam Mohammadi"], "abstract": "The proliferation of Large Language Models (LLMs) has opened new frontiers in computing, yet controlling and orchestrating their capabilities beyond simple text generation remains a challenge. Current methods, such as function/tool calling and direct code generation, suffer from limitations in expressiveness, scalability, cost, security, and the ability to enforce fine-grained control. This paper introduces Pel, a novel programming language specifically designed to bridge this gap. Inspired by the strengths of Lisp, Elixir, Gleam, and Haskell, Pel provides a syntactically simple, homoiconic, and semantically rich platform for LLMs to express complex actions, control flow, and inter-agent communication safely and efficiently. Pel's design emphasizes a minimal, easily modifiable grammar suitable for constrained LLM generation, eliminating the need for complex sandboxing by enabling capability control at the syntax level. Key features include a powerful piping mechanism for linear composition, first-class closures enabling easy partial application and functional patterns, built-in support for natural language conditions evaluated by LLMs, and an advanced Read-Eval-Print-Loop (REPeL) with Common Lisp-style restarts and LLM-powered helper agents for automated error correction. Furthermore, Pel incorporates automatic parallelization of independent operations via static dependency analysis, crucial for performant agentic systems. We argue that Pel offers a more robust, secure, and expressive paradigm for LLM orchestration, paving the way for more sophisticated and reliable AI agentic frameworks.", "subjects": "Programming Languages (cs.PL); Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET)", "comments": "Added relevant figures and the section 4.5", "pdf_url": "https://arxiv.org/pdf/2505.13453.pdf", "abstract_url": "https://arxiv.org/abs/2505.13453", "categories": ["Programming Languages (cs.PL)", "Artificial Intelligence (cs.AI)", "Emerging Technologies (cs.ET)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了Pel，一种专为编排大型语言模型（LLMs）设计的新型编程语言，旨在解决当前方法在表达性、可扩展性、成本、安全性和细粒度控制方面的限制。", "motivation": "随着大型语言模型（LLMs）的普及，控制和编排其能力超越了简单的文本生成，成为一大挑战。现有方法在多个方面存在不足，Pel旨在填补这一空白。", "method": "Pel受到Lisp、Elixir、Gleam和Haskell的启发，提供了一个语法简单、同像性、语义丰富的平台，支持LLMs安全高效地表达复杂动作、控制流和代理间通信。", "result": "Pel的设计强调最小化且易于修改的语法，适合受限的LLM生成，无需复杂沙箱即可在语法级别实现能力控制。其关键特性包括强大的管道机制、一等闭包、内置自然语言条件支持以及高级REPeL等。", "conclusion": "Pel为LLM编排提供了一个更健壮、安全和表达性强的范式，为更复杂和可靠的AI代理框架铺平了道路。"}}
{"id": "2505.14398", "title": "Log-Augmented Generation: Scaling Test-Time Reasoning with Reusable Computation", "authors": ["Peter Baile Chen", "Yi Zhang", "Dan Roth", "Samuel Madden", "Jacob Andreas", "Michael Cafarella"], "abstract": "While humans naturally learn and adapt from past experiences, large language models (LLMs) and their agentic counterparts struggle to retain reasoning from previous tasks and apply them in future contexts. To address this limitation, we propose a novel framework, log-augmented generation (LAG) that directly reuses prior computation and reasoning from past logs at test time to enhance model's ability to learn from previous tasks and perform better on new, unseen challenges, all while keeping the system efficient and scalable. Specifically, our system represents task logs using key-value (KV) caches, encoding the full reasoning context of prior tasks while storing KV caches for only a selected subset of tokens. When a new task arises, LAG retrieves the KV values from relevant logs to augment generation. Our approach differs from reflection-based memory mechanisms by directly reusing prior reasoning and computations without requiring additional steps for knowledge extraction or distillation. Our method also goes beyond existing KV caching techniques, which primarily target efficiency gains rather than improving accuracy. Experiments on knowledge- and reasoning-intensive datasets demonstrate that our method significantly outperforms standard agentic systems that do not utilize logs, as well as existing solutions based on reflection and KV cache techniques.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.14398.pdf", "abstract_url": "https://arxiv.org/abs/2505.14398", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种名为日志增强生成（LAG）的新框架，旨在通过重用过去的计算和推理日志来增强大型语言模型（LLMs）在新任务上的表现，同时保持系统的高效性和可扩展性。", "motivation": "大型语言模型及其代理版本难以保留和重用过去任务的推理过程，限制了它们在新任务上的适应和学习能力。", "method": "LAG框架利用键值（KV）缓存来表示任务日志，存储选定令牌的KV缓存以编码完整推理上下文，并在新任务出现时检索相关日志的KV值以增强生成。", "result": "在知识和推理密集型数据集上的实验表明，LAG显著优于不利用日志的标准代理系统，以及基于反射和KV缓存技术的现有解决方案。", "conclusion": "LAG通过直接重用先前的推理和计算，无需额外的知识提取或蒸馏步骤，有效提升了模型在新任务上的表现，同时保持了系统的高效性和可扩展性。"}}
{"id": "2505.14418", "title": "Hidden Ghost Hand: Unveiling Backdoor Vulnerabilities in MLLM-Powered Mobile GUI Agents", "authors": ["Pengzhou Cheng", "Haowen Hu", "Zheng Wu", "Zongru Wu", "Tianjie Ju", "Daizong Ding", "Zhuosheng Zhang", "Gongshen Liu"], "abstract": "Graphical user interface (GUI) agents powered by multimodal large language models (MLLMs) have shown greater promise for human-interaction. However, due to the high fine-tuning cost, users often rely on open-source GUI agents or APIs offered by AI providers, which introduces a critical but underexplored supply chain threat: backdoor attacks. In this work, we first unveil that MLLM-powered GUI agents naturally expose multiple interaction-level triggers, such as historical steps, environment states, and task progress. Based on this observation, we introduce AgentGhost, an effective and stealthy framework for red-teaming backdoor attacks. Specifically, we first construct composite triggers by combining goal and interaction levels, allowing GUI agents to unintentionally activate backdoors while ensuring task utility. Then, we formulate backdoor injection as a Min-Max optimization problem that uses supervised contrastive learning to maximize the feature difference across sample classes at the representation space, improving flexibility of the backdoor. Meanwhile, it adopts supervised fine-tuning to minimize the discrepancy between backdoor and clean behavior generation, enhancing effectiveness and utility. Extensive evaluations of various agent models in two established mobile benchmarks show that AgentGhost is effective and generic, with attack accuracy that reaches 99.7\\% on three attack objectives, and shows stealthiness with only 1\\% utility degradation. Furthermore, we tailor a defense method against AgentGhost that reduces the attack accuracy to 22.1\\%. Our code is available at \\texttt{anonymous}.", "subjects": "Computation and Language (cs.CL)", "comments": "25 pages, 10 figures, 12 Tables", "pdf_url": "https://arxiv.org/pdf/2505.14418.pdf", "abstract_url": "https://arxiv.org/abs/2505.14418", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文揭示了多模态大语言模型（MLLM）驱动的图形用户界面（GUI）代理在供应链中存在的后门攻击威胁，并提出了一个名为AgentGhost的有效且隐蔽的后门攻击框架。该框架通过结合目标和交互级别的触发器，以及采用监督对比学习和监督微调的方法，实现了高攻击准确性和低效用退化。此外，还提出了一种防御方法，显著降低了攻击成功率。", "motivation": "由于高微调成本，用户常依赖开源GUI代理或AI提供商提供的API，这引入了供应链中的后门攻击威胁。本文旨在揭示这一威胁并提出解决方案。", "method": "提出了AgentGhost框架，通过构建复合触发器和将后门注入建模为Min-Max优化问题，使用监督对比学习和监督微调来增强后门的灵活性和有效性。", "result": "在两个移动基准测试中，AgentGhost对三种攻击目标的攻击准确率达到99.7%，效用退化仅为1%。提出的防御方法将攻击准确率降低至22.1%。", "conclusion": "AgentGhost框架有效揭示了MLLM驱动的GUI代理的后门漏洞，同时提出的防御方法为对抗此类攻击提供了可能。"}}
{"id": "2505.13504", "title": "An agentic system with reinforcement-learned subsystem improvements for parsing form-like documents", "authors": ["Ayesha Amjad", "Saurav Sthapit", "Tahir Qasim Syed"], "abstract": "Extracting alphanumeric data from form-like documents such as invoices, purchase orders, bills, and financial documents is often performed via vision (OCR) and learning algorithms or monolithic pipelines with limited potential for systemic improvements. We propose an agentic AI system that leverages Large Language Model (LLM) agents and a reinforcement learning (RL) driver agent to automate consistent, self-improving extraction under LLM inference uncertainty. Our work highlights the limitations of monolithic LLM-based extraction and introduces a modular, multi-agent framework with task-specific prompts and an RL policy of rewards and penalties to guide a meta-prompting agent to learn from past errors and improve prompt-based actor agents. This self-corrective adaptive system handles diverse documents, file formats, layouts, and LLMs, aiming to automate accurate information extraction without the need for human intervention. Results as reported on two benchmark datasets of SOIRE, and CORD, are promising for the agentic AI framework.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.13504.pdf", "abstract_url": "https://arxiv.org/abs/2505.13504", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种基于大型语言模型（LLM）代理和强化学习（RL）驱动代理的自主AI系统，用于从表单类文档中自动提取数据，旨在通过模块化多代理框架和自我纠正机制提高提取的准确性和适应性。", "motivation": "解决从发票、采购订单等表单类文档中提取数据时，现有方法（如OCR和单一学习算法）在系统性改进方面的局限性。", "method": "采用模块化多代理框架，包括任务特定提示和RL策略，通过奖励和惩罚机制指导元提示代理从过去的错误中学习并改进基于提示的演员代理。", "result": "在SOIRE和CORD两个基准数据集上的结果表明，该自主AI框架在自动化信息提取方面表现出色。", "conclusion": "该研究展示了一种无需人工干预即可处理多样化文档、文件格式和布局的自我纠正自适应系统，为自动化信息提取提供了新的可能性。"}}
{"id": "2505.13523", "title": "ACPs: Agent Collaboration Protocols for the Internet of Agents", "authors": ["Jun Liu", "Ke Yu", "Keliang Chen", "Ke Li", "Yuxinyue Qian", "Xiaolian Guo", "Haozhe Song", "Yinming Li"], "abstract": "With the rapid advancement of artificial intelligence, the proliferation of autonomous agents has introduced new challenges in interoperability, scalability, and coordination. The Internet of Agents (IoA) aims to interconnect heterogeneous agents through standardized communication protocols, enabling seamless collaboration and intelligent task execution. However, existing agent communication protocols such as MCP, A2A, and ANP remain fragmented and scenario-specific. To address this gap, we propose Agent Collaboration Protocols (ACPs), a comprehensive protocol suite for the IoA. ACPs include registration, discovery, interaction, and tooling protocols to support trustable access, capability orchestration, and workflow construction. We present the architecture, key technologies, and application workflows of ACPs, and demonstrate its effectiveness in a collaborative restaurant booking scenario. ACPs lay the foundation for building a secure, open, and scalable agent internet infrastructure.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": "7 pages, 8 figures", "pdf_url": "https://arxiv.org/pdf/2505.13523.pdf", "abstract_url": "https://arxiv.org/abs/2505.13523", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了代理协作协议（ACPs），旨在解决互联网代理（IoA）中的互操作性、可扩展性和协调性问题。ACPs通过一套全面的协议套件，包括注册、发现、交互和工具协议，支持可信访问、能力编排和工作流构建，为构建安全、开放和可扩展的代理互联网基础设施奠定了基础。", "motivation": "随着人工智能的快速发展，自主代理的激增带来了互操作性、可扩展性和协调性方面的新挑战。现有的代理通信协议如MCP、A2A和ANP仍然分散且场景特定，无法满足需求。", "method": "提出了代理协作协议（ACPs），包括注册、发现、交互和工具协议，以支持可信访问、能力编排和工作流构建。", "result": "通过一个协作餐厅预订场景的演示，证明了ACPs的有效性。", "conclusion": "ACPs为构建安全、开放和可扩展的代理互联网基础设施奠定了基础。"}}
{"id": "2505.13516", "title": "HALO: Hierarchical Autonomous Logic-Oriented Orchestration for Multi-Agent LLM Systems", "authors": ["Zhipeng Hou", "Junyi Tang", "Yipeng Wang"], "abstract": "Recent advancements in Multi-Agent Systems (MAS) powered by Large Language Models (LLMs) have demonstrated tremendous potential in diverse task scenarios. Nonetheless, existing agentic systems typically rely on predefined agent-role design spaces and static communication structures, limiting their adaptability as well as flexibility in complex interaction environments and leading to subpar performance on highly specialized and expert-level tasks. To address these issues, we introduce HALO, a multi-agent collaboration framework based on a hierarchical reasoning architecture. Specifically, we incorporate a high-level planning agent for task decomposition, mid-level role-design agents for subtask-specific agent instantiation, and low-level inference agents for subtask execution. Particularly, subtask execution is reformulated as a structured workflow search problem, where Monte Carlo Tree Search (MCTS) systematically explores the agentic action space to construct optimal reasoning trajectories. Additionally, as the majority of users lack expertise in prompt engineering, we leverage an Adaptive Prompt Refinement module to transform raw queries into task-specific prompts. Empirical evaluations on Code Generation (HumanEval), General Reasoning (MMLU), and Arithmetic Reasoning (MATH) benchmark datasets highlight the effectiveness of HALO, yielding a 14.4% average improvement over state-of-the-art baselines. Notably, HALO achieves up to 13.3% performance gain on the Moral Scenarios subject in the MMLU benchmark and up to 19.6% performance gain on the Algebra subarea in the MATH benchmark, indicating its advanced proficiency in tackling highly specialized and expert-level tasks. The code repository is available at", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.13516.pdf", "abstract_url": "https://arxiv.org/abs/2505.13516", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "HALO是一个基于分层推理架构的多智能体协作框架，旨在解决现有多智能体系统在复杂交互环境中的适应性和灵活性不足的问题。通过高层次规划、中层次角色设计和低层次推理智能体的协作，以及蒙特卡洛树搜索和自适应提示细化模块的应用，HALO在代码生成、一般推理和算术推理等任务上实现了显著的性能提升。", "motivation": "现有基于大型语言模型的多智能体系统通常依赖于预定义的智能体角色设计空间和静态通信结构，这限制了它们在复杂交互环境中的适应性和灵活性，导致在高度专业化和专家级任务上表现不佳。", "method": "HALO采用分层推理架构，包括高层次规划智能体进行任务分解，中层次角色设计智能体实例化特定子任务的智能体，以及低层次推理智能体执行子任务。子任务执行被重新表述为结构化工作流搜索问题，利用蒙特卡洛树搜索系统地探索智能体动作空间以构建最优推理轨迹。此外，还引入了自适应提示细化模块，将原始查询转换为任务特定的提示。", "result": "在代码生成（HumanEval）、一般推理（MMLU）和算术推理（MATH）基准数据集上的实证评估显示，HALO比现有最先进基线平均提高了14.4%。特别是在MMLU基准的道德情景科目和MATH基准的代数子领域，HALO分别实现了高达13.3%和19.6%的性能增益。", "conclusion": "HALO通过其分层推理架构和自适应提示细化模块，显著提高了多智能体系统在高度专业化和专家级任务上的性能，展示了其在复杂交互环境中的强大适应性和灵活性。"}}
{"id": "2505.13528", "title": "LLM-Based User Simulation for Low-Knowledge Shilling Attacks on Recommender Systems", "authors": ["Shengkang Gu", "Jiahao Liu", "Dongsheng Li", "Guangping Zhang", "Mingzhe Han", "Hansu Gu", "Peng Zhang", "Ning Gu", "Li Shang", "Tun Lu"], "abstract": "Recommender systems (RS) are increasingly vulnerable to shilling attacks, where adversaries inject fake user profiles to manipulate system outputs. Traditional attack strategies often rely on simplistic heuristics, require access to internal RS data, and overlook the manipulation potential of textual reviews. In this work, we introduce Agent4SR, a novel framework that leverages Large Language Model (LLM)-based agents to perform low-knowledge, high-impact shilling attacks through both rating and review generation. Agent4SR simulates realistic user behavior by orchestrating adversarial interactions, selecting items, assigning ratings, and crafting reviews, while maintaining behavioral plausibility. Our design includes targeted profile construction, hybrid memory retrieval, and a review attack strategy that propagates target item features across unrelated reviews to amplify manipulation. Extensive experiments on multiple datasets and RS architectures demonstrate that Agent4SR outperforms existing low-knowledge baselines in both effectiveness and stealth. Our findings reveal a new class of emergent threats posed by LLM-driven agents, underscoring the urgent need for enhanced defenses in modern recommender systems.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "comments": "11 pages, under review", "pdf_url": "https://arxiv.org/pdf/2505.13528.pdf", "abstract_url": "https://arxiv.org/abs/2505.13528", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了Agent4SR，一个利用大型语言模型（LLM）代理进行低知识、高影响力的推荐系统（RS）虚假攻击的新框架。通过模拟真实用户行为，包括选择项目、分配评分和制作评论，Agent4SR在保持行为合理性的同时，提高了攻击的有效性和隐蔽性。", "motivation": "推荐系统（RS）越来越容易受到虚假攻击，传统攻击策略依赖简单启发式方法，需要访问内部RS数据，且忽视了文本评论的操纵潜力。", "method": "Agent4SR框架利用LLM代理模拟真实用户行为，包括目标档案构建、混合记忆检索和评论攻击策略，通过在不相关的评论中传播目标项目特征来放大操纵效果。", "result": "在多数据集和RS架构上的广泛实验表明，Agent4SR在有效性和隐蔽性上均优于现有的低知识基线方法。", "conclusion": "研究揭示了LLM驱动代理带来的新兴威胁类别，强调了现代推荐系统迫切需要加强防御措施。"}}
{"id": "2505.13538", "title": "RAGXplain: From Explainable Evaluation to Actionable Guidance of RAG Pipelines", "authors": ["Dvir Cohen", "Lin Burg", "Gilad Barkan"], "abstract": "Retrieval-Augmented Generation (RAG) systems show promise by coupling large language models with external knowledge, yet traditional RAG evaluation methods primarily report quantitative scores while offering limited actionable guidance for refining these complex pipelines. In this paper, we introduce RAGXplain, an evaluation framework that quantifies RAG performance and translates these assessments into clear insights that clarify the workings of its complex, multi-stage pipeline and offer actionable recommendations. Using LLM reasoning, RAGXplain converts raw scores into coherent narratives identifying performance gaps and suggesting targeted improvements. By providing transparent explanations for AI decision-making, our framework fosters user trust-a key challenge in AI adoption. Our LLM-based metric assessments show strong alignment with human judgments, and experiments on public question-answering datasets confirm that applying RAGXplain's actionable recommendations measurably improves system performance. RAGXplain thus bridges quantitative evaluation and practical optimization, empowering users to understand, trust, and enhance their AI systems.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.13538.pdf", "abstract_url": "https://arxiv.org/abs/2505.13538", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "RAGXplain是一个评估框架，旨在通过将检索增强生成（RAG）系统的性能评估转化为清晰的见解和可操作的建议，以优化复杂的多阶段流程。", "motivation": "传统的RAG评估方法主要提供定量评分，但缺乏对复杂流程的具体改进指导，RAGXplain旨在解决这一问题。", "method": "利用大型语言模型（LLM）的推理能力，RAGXplain将原始分数转化为连贯的叙述，识别性能差距并提出针对性改进建议。", "result": "RAGXplain的LLM基于度量的评估与人类判断高度一致，实验证明其建议显著提高了系统性能。", "conclusion": "RAGXplain通过提供透明的AI决策解释，增强了用户信任，并架起了定量评估与实际优化之间的桥梁。"}}
{"id": "2505.13567", "title": "Learning Dynamics of RNNs in Closed-Loop Environments", "authors": ["Yoav Ger", "Omri Barak"], "abstract": "Recurrent neural networks (RNNs) trained on neuroscience-inspired tasks offer powerful models of brain computation. However, typical training paradigms rely on open-loop, supervised settings, whereas real-world learning unfolds in closed-loop environments. Here, we develop a mathematical theory describing the learning dynamics of linear RNNs trained in closed-loop contexts. We first demonstrate that two otherwise identical RNNs, trained in either closed- or open-loop modes, follow markedly different learning trajectories. To probe this divergence, we analytically characterize the closed-loop case, revealing distinct stages aligned with the evolution of the training loss. Specifically, we show that the learning dynamics of closed-loop RNNs, in contrast to open-loop ones, are governed by an interplay between two competing objectives: short-term policy improvement and long-term stability of the agent-environment interaction. Finally, we apply our framework to a realistic motor control task, highlighting its broader applicability. Taken together, our results underscore the importance of modeling closed-loop dynamics in a biologically plausible setting.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Neurons and Cognition (q-bio.NC)", "comments": "9 pages with 6 figures", "pdf_url": "https://arxiv.org/pdf/2505.13567.pdf", "abstract_url": "https://arxiv.org/abs/2505.13567", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Neurons and Cognition (q-bio.NC)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文开发了一个数学理论，描述在闭环环境中训练的线性RNN的学习动态，揭示了闭环与开环训练模式下RNN学习轨迹的显著差异，并应用于实际运动控制任务。", "motivation": "解决在神经科学启发任务中训练的RNN通常依赖于开环、监督设置，而现实世界学习在闭环环境中展开的问题。", "method": "开发了一个数学理论，分析闭环环境中线性RNN的学习动态，并通过实际运动控制任务验证理论的广泛适用性。", "result": "发现闭环训练的RNN学习动态由短期策略改进和长期代理-环境交互稳定性两个竞争目标共同支配，与开环训练有显著不同。", "conclusion": "结果强调了在生物合理设置中建模闭环动态的重要性，为理解大脑计算提供了更强大的模型。"}}
{"id": "2505.13545", "title": "Know Or Not: a library for evaluating out-of-knowledge base robustness", "authors": ["Jessica Foo", "Pradyumna Shyama Prasad", "Shaun Khoo"], "abstract": "While the capabilities of large language models (LLMs) have progressed significantly, their use in high-stakes applications have been limited due to risks of hallucination. One key approach in reducing hallucination is retrieval-augmented generation (RAG), but even in such setups, LLMs may still hallucinate when presented with questions outside of the knowledge base. Such behavior is unacceptable in high-stake applications where LLMs are expected to abstain from answering queries it does not have sufficient context on. In this work, we present a novel methodology for systematically evaluating out-of-knowledge base (OOKB) robustness of LLMs (whether LLMs know or do not know) in the RAG setting, without the need for manual annotation of gold standard answers. We implement our methodology in knowornot, an open-source library that enables users to develop their own customized evaluation data and pipelines for OOKB robustness. knowornot comprises four main features. Firstly, it provides a unified, high-level API that streamlines the process of setting up and running robustness benchmarks. Secondly, its modular architecture emphasizes extensibility and flexibility, allowing users to easily integrate their own LLM clients and RAG settings. Thirdly, its rigorous data modeling design ensures experiment reproducibility, reliability and traceability. Lastly, it implements a comprehensive suite of tools for users to customize their pipelines. We demonstrate the utility of knowornot by developing a challenging benchmark, PolicyBench, which spans four Question-Answer (QA) chatbots on government policies, and analyze its OOKB robustness. The source code of knowornot is available", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.13545.pdf", "abstract_url": "https://arxiv.org/abs/2505.13545", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了一个名为knowornot的开源库，旨在评估大型语言模型（LLMs）在检索增强生成（RAG）设置中对知识库外（OOKB）问题的鲁棒性，即判断LLMs是否知道答案。该库提供了统一的API、模块化架构、严格的数据建模设计以及一套全面的工具，支持用户自定义评估数据和管道。通过PolicyBench基准测试，展示了knowornot的实用性。", "motivation": "大型语言模型（LLMs）在高风险应用中的使用受到幻觉风险的限制。即使在检索增强生成（RAG）设置中，LLMs仍可能对知识库外的问题产生幻觉，这在需要模型在缺乏足够上下文时避免回答的高风险应用中是不可接受的。", "method": "提出了一种系统评估LLMs在RAG设置中对知识库外（OOKB）问题鲁棒性的新方法，无需手动标注黄金标准答案。该方法通过knowornot库实现，该库提供了统一的API、模块化架构、严格的数据建模设计和自定义管道工具。", "result": "通过开发一个名为PolicyBench的挑战性基准测试，展示了knowornot库的实用性。PolicyBench涵盖了四个关于政府政策的问答聊天机器人，并分析了它们的OOKB鲁棒性。", "conclusion": "knowornot库为评估LLMs在RAG设置中的OOKB鲁棒性提供了一种有效且灵活的方法，支持用户自定义评估，有助于提高LLMs在高风险应用中的可靠性。"}}
{"id": "2505.13557", "title": "AMAQA: A Metadata-based QA Dataset for RAG Systems", "authors": ["Davide Bruni", "Marco Avvenuti", "Nicola Tonellotto", "Maurizio Tesconi"], "abstract": "Retrieval-augmented generation (RAG) systems are widely used in question-answering (QA) tasks, but current benchmarks lack metadata integration, hindering evaluation in scenarios requiring both textual data and external information. To address this, we present AMAQA, a new open-access QA dataset designed to evaluate tasks combining text and metadata. The integration of metadata is especially important in fields that require rapid analysis of large volumes of data, such as cybersecurity and intelligence, where timely access to relevant information is critical. AMAQA includes about 1.1 million English messages collected from 26 public Telegram groups, enriched with metadata such as timestamps, topics, emotional tones, and toxicity indicators, which enable precise and contextualized queries by filtering documents based on specific criteria. It also includes 450 high-quality QA pairs, making it a valuable resource for advancing research on metadata-driven QA and RAG systems. To the best of our knowledge, AMAQA is the first single-hop QA benchmark to incorporate metadata and labels such as topics covered in the messages. We conduct extensive tests on the benchmark, establishing a new standard for future research. We show that leveraging metadata boosts accuracy from 0.12 to 0.61, highlighting the value of structured context. Building on this, we explore several strategies to refine the LLM input by iterating over provided context and enriching it with noisy documents, achieving a further 3-point gain over the best baseline and a 14-point improvement over simple metadata filtering. The dataset is available at", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.13557.pdf", "abstract_url": "https://arxiv.org/abs/2505.13557", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "AMAQA是一个新的开放访问QA数据集，专为评估结合文本和元数据的任务设计，包含约110万条英文消息和450个高质量QA对，旨在提升RAG系统在需要文本和外部信息场景下的评估能力。", "motivation": "当前的问答任务基准缺乏元数据集成，限制了在需要文本数据和外部信息场景下的评估。AMAQA旨在填补这一空白，特别是在需要快速分析大量数据的领域，如网络安全和情报。", "method": "AMAQA数据集收集了26个公共Telegram群组中的约110万条英文消息，并丰富了时间戳、主题、情感语气和毒性指标等元数据。此外，还包括450个高质量QA对，支持基于特定标准的文档过滤和精确查询。", "result": "利用元数据可以将准确率从0.12提升到0.61，显示了结构化上下文的价值。通过迭代提供的上下文并用嘈杂文档丰富它，实现了比最佳基线进一步3点的增益和比简单元数据过滤14点的改进。", "conclusion": "AMAQA为元数据驱动的QA和RAG系统研究提供了宝贵的资源，通过整合元数据显著提高了问答任务的准确性，为未来研究设立了新标准。"}}
{"id": "2505.13572", "title": "Q${}^2$Forge: Minting Competency Questions and SPARQL Queries for Question-Answering Over Knowledge Graphs", "authors": ["Yousouf Taghzouti", "Franck Michel", "Tao Jiang", "Louis-Félix Nothias", "Fabien Gandon"], "abstract": "The SPARQL query language is the standard method to access knowledge graphs (KGs). However, formulating SPARQL queries is a significant challenge for non-expert users, and remains time-consuming for the experienced ones. Best practices recommend to document KGs with competency questions and example queries to contextualise the knowledge they contain and illustrate their potential applications. In practice, however, this is either not the case or the examples are provided in limited numbers. Large Language Models (LLMs) are being used in conversational agents and are proving to be an attractive solution with a wide range of applications, from simple question-answering about common knowledge to generating code in a targeted programming language. However, training and testing these models to produce high quality SPARQL queries from natural language questions requires substantial datasets of question-query pairs. In this paper, we present Q${}^2$Forge that addresses the challenge of generating new competency questions for a KG and corresponding SPARQL queries. It iteratively validates those queries with human feedback and LLM as a judge. Q${}^2$Forge is open source, generic, extensible and modular, meaning that the different modules of the application (CQ generation, query generation and query refinement) can be used separately, as an integrated pipeline, or replaced by alternative services. The result is a complete pipeline from competency question formulation to query evaluation, supporting the creation of reference query sets for any target KG.", "subjects": "Databases (cs.DB); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.13572.pdf", "abstract_url": "https://arxiv.org/abs/2505.13572", "categories": ["Databases (cs.DB)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["agent"], "AI": {"tldr": "Q${}^2$Forge是一个开源、通用、可扩展和模块化的工具，旨在为知识图谱生成新的能力问题和相应的SPARQL查询，并通过人类反馈和大型语言模型作为评判者迭代验证这些查询。", "motivation": "解决非专家用户在知识图谱上制定SPARQL查询的挑战，以及为知识图谱提供能力问题和示例查询的不足。", "method": "使用大型语言模型（LLMs）生成能力问题和SPARQL查询，并通过人类反馈和LLM作为评判者进行迭代验证。", "result": "开发了一个完整的管道，从能力问题制定到查询评估，支持为任何目标知识图谱创建参考查询集。", "conclusion": "Q${}^2$Forge通过其模块化和可扩展的设计，为知识图谱的查询生成和验证提供了一个有效的解决方案，有助于提升知识图谱的可访问性和应用潜力。"}}
{"id": "2505.13577", "title": "VocalAgent: Large Language Models for Vocal Health Diagnostics with Safety-Aware Evaluation", "authors": ["Yubin Kim", "Taehan Kim", "Wonjune Kang", "Eugene Park", "Joonsik Yoon", "Dongjae Lee", "Xin Liu", "Daniel McDuff", "Hyeonhoon Lee", "Cynthia Breazeal", "Hae Won Park"], "abstract": "Vocal health plays a crucial role in peoples' lives, significantly impacting their communicative abilities and interactions. However, despite the global prevalence of voice disorders, many lack access to convenient diagnosis and treatment. This paper introduces VocalAgent, an audio large language model (LLM) to address these challenges through vocal health diagnosis. We leverage Qwen-Audio-Chat fine-tuned on three datasets collected in-situ from hospital patients, and present a multifaceted evaluation framework encompassing a safety assessment to mitigate diagnostic biases, cross-lingual performance analysis, and modality ablation studies. VocalAgent demonstrates superior accuracy on voice disorder classification compared to state-of-the-art baselines. Its LLM-based method offers a scalable solution for broader adoption of health diagnostics, while underscoring the importance of ethical and technical validation.", "subjects": "Sound (cs.SD); Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.13577.pdf", "abstract_url": "https://arxiv.org/abs/2505.13577", "categories": ["Sound (cs.SD)", "Artificial Intelligence (cs.AI)", "Audio and Speech Processing (eess.AS)"], "matching_keywords": ["agent"], "AI": {"tldr": "VocalAgent是一个基于大型语言模型（LLM）的音频处理工具，旨在通过声音健康诊断解决全球范围内声音障碍诊断和治疗不便的问题。", "motivation": "全球范围内声音障碍普遍存在，但许多人缺乏便捷的诊断和治疗途径。VocalAgent旨在通过技术手段解决这一问题。", "method": "利用Qwen-Audio-Chat模型，并在医院患者收集的三个数据集上进行微调，采用包括安全性评估、跨语言性能分析和模态消融研究在内的多方面评估框架。", "result": "VocalAgent在声音障碍分类上的准确率优于现有最先进的基线模型。", "conclusion": "VocalAgent的LLM方法为健康诊断的广泛采用提供了可扩展的解决方案，同时强调了伦理和技术验证的重要性。"}}
{"id": "2505.13482", "title": "MedEIR: A Specialized Medical Embedding Model for Enhanced Information Retrieval", "authors": ["Anand Selvadurai", "Jasheen Shaik", "Girish Chandrasekar", "ShriRadhaKrishnan Balamurugan", "Eswara Reddy"], "abstract": "Embedding models have become essential for retrieval-augmented generation (RAG) tasks, semantic clustering, and text re-ranking. But despite their growing use, many of these come with notable limitations. For example, Jina fails to capture the semantic content of medical documents, while models such as MiniLM often perform poorly on long-form documents. Domain-adapted models, while specialized, often underperform in general-purpose tasks, reducing their overall applicability. General-domain tokenizers often misinterpret medical vocabulary. The limitations of current embedding models, whether in tokenization accuracy, domain comprehension, or handling long sequences, highlight the need for more versatile solutions. In this work, we present MedEIR, a novel embedding model and tokenizer jointly optimized for both medical and general NLP tasks, incorporating ALiBi-based long-context processing to support sequences of up to 8,192 tokens. MedEIR was pre-trained on only 6 billion tokens, significantly fewer than Jina's, followed by fine-tuning on 3 million sentence pairs. MedEIR consistently outperforms Jina V2 and MiniLM across MTEB benchmarks, achieving top scores on ArguAna (55.24), NFCorpus (38.44), MedicalQARetrieval (74.25), SciFact (72.04), and TRECCOVID (79.56). These results highlight the potential of MedEIR as a highly effective embedding model, demonstrating strong performance across both general-purpose and domain-specific tasks and outperforming existing models on multiple benchmarks.", "subjects": "Information Retrieval (cs.IR); Computation and Language (cs.CL)", "comments": "9 pages, 1 figure. This manuscript is a substantial revision of a previously submitted paper. We have explicitly clarified novelty, strengthened scholarly depth, and expanded experimental validation", "pdf_url": "https://arxiv.org/pdf/2505.13482.pdf", "abstract_url": "https://arxiv.org/abs/2505.13482", "categories": ["Information Retrieval (cs.IR)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "MedEIR是一种专为医学和信息检索任务优化的新型嵌入模型和分词器，通过ALiBi长上下文处理支持长达8,192个标记的序列，在多个基准测试中表现优异。", "motivation": "现有的嵌入模型在医学文档的语义内容捕捉、长文档处理及医学词汇理解方面存在局限，需要更通用的解决方案。", "method": "MedEIR结合了ALiBi长上下文处理技术，预训练仅使用了60亿个标记，随后对300万个句子对进行了微调。", "result": "MedEIR在MTEB基准测试中 consistently outperforms Jina V2和MiniLM，在多个任务上取得了最高分。", "conclusion": "MedEIR作为一种高效的嵌入模型，在通用和特定领域任务中均表现出色，展示了其在多个基准测试中超越现有模型的潜力。"}}
{"id": "2505.13581", "title": "RAR: Setting Knowledge Tripwires for Retrieval Augmented Rejection", "authors": ["Tommaso Mario Buonocore", "Enea Parimbelli"], "abstract": "Content moderation for large language models (LLMs) remains a significant challenge, requiring flexible and adaptable solutions that can quickly respond to emerging threats. This paper introduces Retrieval Augmented Rejection (RAR), a novel approach that leverages a retrieval-augmented generation (RAG) architecture to dynamically reject unsafe user queries without model retraining. By strategically inserting and marking malicious documents into the vector database, the system can identify and reject harmful requests when these documents are retrieved. Our preliminary results show that RAR achieves comparable performance to embedded moderation in LLMs like Claude 3.5 Sonnet, while offering superior flexibility and real-time customization capabilities, a fundamental feature to timely address critical vulnerabilities. This approach introduces no architectural changes to existing RAG systems, requiring only the addition of specially crafted documents and a simple rejection mechanism based on retrieval results.", "subjects": "Information Retrieval (cs.IR); Computation and Language (cs.CL); Cryptography and Security (cs.CR)", "comments": "7 pages, 4 figures, 2 tables", "pdf_url": "https://arxiv.org/pdf/2505.13581.pdf", "abstract_url": "https://arxiv.org/abs/2505.13581", "categories": ["Information Retrieval (cs.IR)", "Computation and Language (cs.CL)", "Cryptography and Security (cs.CR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了检索增强拒绝（RAR）方法，利用检索增强生成（RAG）架构动态拒绝不安全的用户查询，无需模型重新训练。", "motivation": "解决大型语言模型（LLMs）内容审核的挑战，需要灵活适应的解决方案以快速应对新兴威胁。", "method": "通过在向量数据库中策略性地插入和标记恶意文档，系统可以在检索到这些文档时识别并拒绝有害请求。", "result": "初步结果显示，RAR在性能上与Claude 3.5 Sonnet等LLMs中的嵌入式审核相当，同时提供更优的灵活性和实时定制能力。", "conclusion": "RAR方法无需对现有RAG系统进行架构更改，仅需添加特别设计的文档和基于检索结果的简单拒绝机制，为及时解决关键漏洞提供了基础功能。"}}
{"id": "2505.13808", "title": "RAG/LLM Augmented Switching Driven Polymorphic Metaheuristic Framework", "authors": ["Faramarz Safi Esfahani", "Ghassan Beydoun", "Morteza Saberi", "Brad McCusker", "Biswajeet Pradhan"], "abstract": "Metaheuristic algorithms are widely used for solving complex optimization problems, yet their effectiveness is often constrained by fixed structures and the need for extensive tuning. The Polymorphic Metaheuristic Framework (PMF) addresses this limitation by introducing a self-adaptive metaheuristic switching mechanism driven by real-time performance feedback and dynamic algorithmic selection. PMF leverages the Polymorphic Metaheuristic Agent (PMA) and the Polymorphic Metaheuristic Selection Agent (PMSA) to dynamically select and transition between metaheuristic algorithms based on key performance indicators, ensuring continuous adaptation. This approach enhances convergence speed, adaptability, and solution quality, outperforming traditional metaheuristics in high-dimensional, dynamic, and multimodal environments. Experimental results on benchmark functions demonstrate that PMF significantly improves optimization efficiency by mitigating stagnation and balancing exploration-exploitation strategies across various problem landscapes. By integrating AI-driven decision-making and self-correcting mechanisms, PMF paves the way for scalable, intelligent, and autonomous optimization frameworks, with promising applications in engineering, logistics, and complex decision-making systems.", "subjects": "Neural and Evolutionary Computing (cs.NE); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.13808.pdf", "abstract_url": "https://arxiv.org/abs/2505.13808", "categories": ["Neural and Evolutionary Computing (cs.NE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文提出了一种名为多态元启发式框架（PMF）的自适应元启发式切换机制，通过实时性能反馈和动态算法选择来解决传统元启发式算法在解决复杂优化问题时固定结构和需要大量调参的限制。PMF利用多态元启发式代理（PMA）和多态元启发式选择代理（PMSA）动态选择和转换元启发式算法，以提高收敛速度、适应性和解的质量。", "motivation": "传统元启发式算法在解决复杂优化问题时存在固定结构和需要大量调参的限制，影响了其效果和效率。", "method": "PMF引入了一种自适应的元启发式切换机制，通过实时性能反馈和动态算法选择，利用PMA和PMSA动态选择和转换元启发式算法。", "result": "在基准函数上的实验结果表明，PMF显著提高了优化效率，通过缓解停滞和平衡探索-利用策略，在各种问题景观中表现优于传统元启发式算法。", "conclusion": "通过整合AI驱动的决策和自我纠正机制，PMF为可扩展、智能和自主的优化框架铺平了道路，在工程、物流和复杂决策系统等领域具有广阔的应用前景。"}}
{"id": "2505.13820", "title": "Structured Agent Distillation for Large Language Model", "authors": ["Jun Liu", "Zhenglun Kong", "Peiyan Dong", "Changdi Yang", "Tianqi Li", "Hao Tang", "Geng Yuan", "Wei Niu", "Wenbin Zhang", "Pu Zhao", "Xue Lin", "Dong Huang", "Yanzhi Wang"], "abstract": "Large language models (LLMs) exhibit strong capabilities as decision-making agents by interleaving reasoning and actions, as seen in ReAct-style frameworks. Yet, their practical deployment is constrained by high inference costs and large model sizes. We propose Structured Agent Distillation, a framework that compresses large LLM-based agents into smaller student models while preserving both reasoning fidelity and action consistency. Unlike standard token-level distillation, our method segments trajectories into {[REASON]} and {[ACT]} spans, applying segment-specific losses to align each component with the teacher's behavior. This structure-aware supervision enables compact agents to better replicate the teacher's decision process. Experiments on ALFWorld, HotPotQA-ReAct, and WebShop show that our approach consistently outperforms token-level and imitation learning baselines, achieving significant compression with minimal performance drop. Scaling and ablation results further highlight the importance of span-level alignment for efficient and deployable agents.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.13820.pdf", "abstract_url": "https://arxiv.org/abs/2505.13820", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了结构化代理蒸馏（Structured Agent Distillation）框架，旨在将基于大型语言模型（LLM）的代理压缩成更小的学生模型，同时保持推理保真度和行动一致性。通过将轨迹分割为{[REASON]}和{[ACT]}跨度，并应用特定于段的损失来对齐每个组件与教师模型的行为，该方法在多个实验数据集上表现优于基线方法，实现了显著的压缩且性能下降最小。", "motivation": "大型语言模型（LLMs）作为决策代理展现出强大的能力，但其实际部署受到高推理成本和大模型规模的限制。本文旨在解决如何压缩这些大型LLM-based代理，使其更高效、更易于部署的问题。", "method": "提出了结构化代理蒸馏框架，通过将代理的轨迹分割为{[REASON]}和{[ACT]}跨度，并应用特定于段的损失来对齐学生模型与教师模型的行为，从而保持推理和行动的一致性。", "result": "在ALFWorld、HotPotQA-ReAct和WebShop等数据集上的实验表明，该方法在压缩模型大小的同时，性能下降最小，且 consistently outperforms token-level and imitation learning baselines。", "conclusion": "结构化代理蒸馏框架通过span-level的对齐，实现了高效且可部署的代理压缩，为大型语言模型的实际应用提供了可行的解决方案。"}}
{"id": "2505.13652", "title": "Guided Search Strategies in Non-Serializable Environments with Applications to Software Engineering Agents", "authors": ["Karina Zainullina", "Alexander Golubev", "Maria Trofimova", "Sergei Polezhaev", "Ibragim Badertdinov", "Daria Litvintseva", "Simon Karasik", "Filipp Fisin", "Sergei Skvortsov", "Maksim Nekrashevich", "Anton Shevtsov", "Boris Yangel"], "abstract": "Large language models (LLMs) have recently achieved remarkable results in complex multi-step tasks, such as mathematical reasoning and agentic software engineering. However, they often struggle to maintain consistent performance across multiple solution attempts. One effective approach to narrow the gap between average-case and best-case performance is guided test-time search, which explores multiple solution paths to identify the most promising one. Unfortunately, effective search techniques (e.g. MCTS) are often unsuitable for non-serializable RL environments, such as Docker containers, where intermediate environment states cannot be easily saved and restored. We investigate two complementary search strategies applicable to such environments: 1-step lookahead and trajectory selection, both guided by a learned action-value function estimator. On the SWE-bench Verified benchmark, a key testbed for agentic software engineering, we find these methods to double the average success rate of a fine-tuned Qwen-72B model, achieving 40.8%, the new state-of-the-art for open-weights models. Additionally, we show that these techniques are transferable to more advanced closed models, yielding similar improvements with GPT-4o.", "subjects": "Software Engineering (cs.SE); Computation and Language (cs.CL)", "comments": "ICML", "pdf_url": "https://arxiv.org/pdf/2505.13652.pdf", "abstract_url": "https://arxiv.org/abs/2505.13652", "categories": ["Software Engineering (cs.SE)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文探讨了在不可序列化环境中（如Docker容器）应用引导搜索策略，以提高大型语言模型（LLMs）在复杂多步任务中的表现。通过研究一步前瞻和轨迹选择两种互补的搜索策略，并在SWE-bench Verified基准测试中实现了40.8%的平均成功率，为开源模型设定了新的最先进水平。", "motivation": "大型语言模型在复杂多步任务中表现优异，但在多次尝试中保持一致性表现方面存在困难。特别是在不可序列化的强化学习环境中，如Docker容器，传统的搜索技术（如MCTS）难以应用。", "method": "研究并应用了两种互补的搜索策略：一步前瞻和轨迹选择，这两种策略都由学习的动作价值函数估计器引导。", "result": "在SWE-bench Verified基准测试中，这些方法使微调的Qwen-72B模型的平均成功率翻倍，达到40.8%，为开源模型设定了新的最先进水平。同时，这些技术也能转移到更先进的封闭模型（如GPT-4o）中，带来类似的改进。", "conclusion": "引导搜索策略在不可序列化环境中有效提高了大型语言模型的性能，特别是在代理软件工程任务中，为开源和封闭模型都带来了显著的改进。"}}
{"id": "2505.13862", "title": "PandaGuard: Systematic Evaluation of LLM Safety in the Era of Jailbreaking Attacks", "authors": ["Guobin Shen", "Dongcheng Zhao", "Linghao Feng", "Xiang He", "Jihang Wang", "Sicheng Shen", "Haibo Tong", "Yiting Dong", "Jindong Li", "Xiang Zheng", "Yi Zeng"], "abstract": "Large language models (LLMs) have achieved remarkable capabilities but remain vulnerable to adversarial prompts known as jailbreaks, which can bypass safety alignment and elicit harmful outputs. Despite growing efforts in LLM safety research, existing evaluations are often fragmented, focused on isolated attack or defense techniques, and lack systematic, reproducible analysis. In this work, we introduce PandaGuard, a unified and modular framework that models LLM jailbreak safety as a multi-agent system comprising attackers, defenders, and judges. Our framework implements 19 attack methods and 12 defense mechanisms, along with multiple judgment strategies, all within a flexible plugin architecture supporting diverse LLM interfaces, multiple interaction modes, and configuration-driven experimentation that enhances reproducibility and practical deployment. Built on this framework, we develop PandaBench, a comprehensive benchmark that evaluates the interactions between these attack/defense methods across 49 LLMs and various judgment approaches, requiring over 3 billion tokens to execute. Our extensive evaluation reveals key insights into model vulnerabilities, defense cost-performance trade-offs, and judge consistency. We find that no single defense is optimal across all dimensions and that judge disagreement introduces nontrivial variance in safety assessments. We release the code, configurations, and evaluation results to support transparent and reproducible research in LLM safety.", "subjects": "Cryptography and Security (cs.CR); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.13862.pdf", "abstract_url": "https://arxiv.org/abs/2505.13862", "categories": ["Cryptography and Security (cs.CR)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了PandaGuard，一个统一的模块化框架，用于系统评估大型语言模型（LLM）在越狱攻击时代的安全性。通过多代理系统模拟攻击者、防御者和法官，实现了19种攻击方法和12种防御机制，并在PandaBench上进行了全面评估。", "motivation": "大型语言模型（LLM）虽然能力显著，但仍易受越狱攻击的影响，这些攻击可以绕过安全对齐并引发有害输出。现有的安全评估往往分散，缺乏系统性和可重复性分析。", "method": "引入PandaGuard框架，模拟LLM越狱安全为一个多代理系统，包括攻击者、防御者和法官。框架实现了多种攻击和防御方法，以及判断策略，支持灵活的插件架构和配置驱动的实验。", "result": "通过PandaBench对49个LLM和多种判断方法进行了评估，揭示了模型漏洞、防御成本性能权衡和法官一致性的关键见解。发现没有单一防御在所有维度上都是最优的，法官分歧引入了安全评估中的非平凡方差。", "conclusion": "PandaGuard和PandaBench为LLM安全研究提供了透明和可重复的支持，揭示了当前防御方法的局限性和评估中的挑战。"}}
{"id": "2505.13834", "title": "Toward Real-World Cooperative and Competitive Soccer with Quadrupedal Robot Teams", "authors": ["Zhi Su", "Yuman Gao", "Emily Lukas", "Yunfei Li", "Jiaze Cai", "Faris Tulbah", "Fei Gao", "Chao Yu", "Zhongyu Li", "Yi Wu", "Koushil Sreenath"], "abstract": "Achieving coordinated teamwork among legged robots requires both fine-grained locomotion control and long-horizon strategic decision-making. Robot soccer offers a compelling testbed for this challenge, combining dynamic, competitive, and multi-agent interactions. In this work, we present a hierarchical multi-agent reinforcement learning (MARL) framework that enables fully autonomous and decentralized quadruped robot soccer. First, a set of highly dynamic low-level skills is trained for legged locomotion and ball manipulation, such as walking, dribbling, and kicking. On top of these, a high-level strategic planning policy is trained with Multi-Agent Proximal Policy Optimization (MAPPO) via Fictitious Self-Play (FSP). This learning framework allows agents to adapt to diverse opponent strategies and gives rise to sophisticated team behaviors, including coordinated passing, interception, and dynamic role allocation. With an extensive ablation study, the proposed learning method shows significant advantages in the cooperative and competitive multi-agent soccer game. We deploy the learned policies to real quadruped robots relying solely on onboard proprioception and decentralized localization, with the resulting system supporting autonomous robot-robot and robot-human soccer matches on indoor and outdoor soccer courts.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": "11 pages, 12 figures", "pdf_url": "https://arxiv.org/pdf/2505.13834.pdf", "abstract_url": "https://arxiv.org/abs/2505.13834", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种分层多智能体强化学习（MARL）框架，用于实现四足机器人足球的完全自主和分散式协作与竞争。通过低层次技能训练和高层次战略规划，机器人能够适应多样化的对手策略，并展现出复杂的团队行为。", "motivation": "解决在动态、竞争性和多智能体交互的机器人足球测试平台上，实现协调团队合作所需的精细运动控制和长期战略决策的问题。", "method": "采用分层多智能体强化学习框架，包括低层次的腿部运动和球操作技能训练，以及通过多智能体近端策略优化（MAPPO）和虚构自玩（FSP）训练的高层次战略规划策略。", "result": "提出的学习方法在合作和竞争的多智能体足球游戏中显示出显著优势，能够在真实四足机器人上实现自主机器人-机器人和机器人-人类足球比赛。", "conclusion": "该框架不仅提高了机器人在复杂环境中的协作和竞争能力，还为未来在更多实际应用中实现多智能体协调提供了可能。"}}
{"id": "2505.13957", "title": "Beyond Text: Unveiling Privacy Vulnerabilities in Multi-modal Retrieval-Augmented Generation", "authors": ["Jiankun Zhang", "Shenglai Zeng", "Jie Ren", "Tianqi Zheng", "Hui Liu", "Xianfeng Tang", "Hui Liu", "Yi Chang"], "abstract": "Multimodal Retrieval-Augmented Generation (MRAG) systems enhance LMMs by integrating external multimodal databases, but introduce unexplored privacy vulnerabilities. While text-based RAG privacy risks have been studied, multimodal data presents unique challenges. We provide the first systematic analysis of MRAG privacy vulnerabilities across vision-language and speech-language modalities. Using a novel compositional structured prompt attack in a black-box setting, we demonstrate how attackers can extract private information by manipulating queries. Our experiments reveal that LMMs can both directly generate outputs resembling retrieved content and produce descriptions that indirectly expose sensitive information, highlighting the urgent need for robust privacy-preserving MRAG techniques.", "subjects": "Cryptography and Security (cs.CR); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.13957.pdf", "abstract_url": "https://arxiv.org/abs/2505.13957", "categories": ["Cryptography and Security (cs.CR)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文首次系统分析了多模态检索增强生成（MRAG）系统在视觉-语言和语音-语言模态中的隐私漏洞，通过黑盒设置下的新型组合结构化提示攻击，展示了攻击者如何通过操纵查询提取私人信息。实验表明，LMMs既可以直接生成与检索内容相似的输出，也可以产生间接暴露敏感信息的描述，强调了开发强大的隐私保护MRAG技术的紧迫性。", "motivation": "解决多模态检索增强生成（MRAG）系统中未探索的隐私漏洞问题，特别是在视觉-语言和语音-语言模态中，这些漏洞可能导致私人信息被提取。", "method": "使用一种新颖的组合结构化提示攻击方法，在黑盒设置下进行实验，展示攻击者如何通过操纵查询来提取私人信息。", "result": "实验结果显示，LMMs能够直接生成与检索内容相似的输出，以及间接暴露敏感信息的描述，证实了MRAG系统存在严重的隐私风险。", "conclusion": "研究强调了开发强大的隐私保护MRAG技术的紧迫性，以应对多模态数据带来的独特隐私挑战。"}}
{"id": "2505.13941", "title": "MLZero: A Multi-Agent System for End-to-end Machine Learning Automation", "authors": ["Haoyang Fang", "Boran Han", "Nick Erickson", "Xiyuan Zhang", "Su Zhou", "Anirudh Dagar", "Jiani Zhang", "Ali Caner Turkmen", "Cuixiong Hu", "Huzefa Rangwala", "Ying Nian Wu", "Bernie Wang", "George Karypis"], "abstract": "Existing AutoML systems have advanced the automation of machine learning (ML); however, they still require substantial manual configuration and expert input, particularly when handling multimodal data. We introduce MLZero, a novel multi-agent framework powered by Large Language Models (LLMs) that enables end-to-end ML automation across diverse data modalities with minimal human intervention. A cognitive perception module is first employed, transforming raw multimodal inputs into perceptual context that effectively guides the subsequent workflow. To address key limitations of LLMs, such as hallucinated code generation and outdated API knowledge, we enhance the iterative code generation process with semantic and episodic memory. MLZero demonstrates superior performance on MLE-Bench Lite, outperforming all competitors in both success rate and solution quality, securing six gold medals. Additionally, when evaluated on our Multimodal AutoML Agent Benchmark, which includes 25 more challenging tasks spanning diverse data modalities, MLZero outperforms the competing methods by a large margin with a success rate of 0.92 (+263.6\\%) and an average rank of 2.28. Our approach maintains its robust effectiveness even with a compact 8B LLM, outperforming full-size systems from existing solutions.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.13941.pdf", "abstract_url": "https://arxiv.org/abs/2505.13941", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "MLZero是一个基于大型语言模型（LLMs）的多智能体系统，旨在实现端到端的机器学习自动化，特别是在处理多模态数据时减少人工干预。通过认知感知模块和增强的迭代代码生成过程，MLZero在多个基准测试中表现出色，显著优于现有解决方案。", "motivation": "现有的AutoML系统虽然在机器学习自动化方面取得了进展，但在处理多模态数据时仍需要大量手动配置和专家输入。MLZero旨在解决这一问题，实现更高效的端到端ML自动化。", "method": "MLZero采用了一个基于大型语言模型的多智能体框架，包括认知感知模块和增强的迭代代码生成过程，后者通过语义和情景记忆来克服LLMs的局限性。", "result": "MLZero在MLE-Bench Lite上表现出色，获得了六枚金牌，并在多模态AutoML代理基准测试中以92%的成功率和2.28的平均排名大幅领先竞争对手。", "conclusion": "MLZero通过其创新的多智能体框架和增强的代码生成过程，显著提高了机器学习自动化的效率和效果，即使在资源受限的情况下也能保持强大的性能。"}}
{"id": "2505.13938", "title": "CLEVER: A Curated Benchmark for Formally Verified Code Generation", "authors": ["Amitayush Thakur", "Jasper Lee", "George Tsoukalas", "Meghana Sistla", "Matthew Zhao", "Stefan Zetzche", "Greg Durrett", "Yisong Yue", "Swarat Chaudhuri"], "abstract": "We introduce ${\\rm C{\\small LEVER}}$, a high-quality, curated benchmark of 161 problems for end-to-end verified code generation in Lean. Each problem consists of (1) the task of generating a specification that matches a held-out ground-truth specification, and (2) the task of generating a Lean implementation that provably satisfies this specification. Unlike prior benchmarks, ${\\rm C{\\small LEVER}}$ avoids test-case supervision, LLM-generated annotations, and specifications that leak implementation logic or allow vacuous solutions. All outputs are verified post-hoc using Lean's type checker to ensure machine-checkable correctness. We use ${\\rm C{\\small LEVER}}$ to evaluate several few-shot and agentic approaches based on state-of-the-art language models. These methods all struggle to achieve full verification, establishing it as a challenging frontier benchmark for program synthesis and formal reasoning. Our benchmark can be found on GitHub(", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Logic in Computer Science (cs.LO); Programming Languages (cs.PL); Software Engineering (cs.SE)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.13938.pdf", "abstract_url": "https://arxiv.org/abs/2505.13938", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Logic in Computer Science (cs.LO)", "Programming Languages (cs.PL)", "Software Engineering (cs.SE)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "介绍了${\\rm C{\\small LEVER}}$，一个高质量的、精心策划的基准测试，包含161个问题，用于在Lean中进行端到端的验证代码生成。每个问题包括生成与保留的真实规范相匹配的规范的任务，以及生成满足此规范的Lean实现的任务。与之前的基准测试不同，${\\rm C{\\small LEVER}}$避免了测试用例监督、LLM生成的注释以及泄露实现逻辑或允许空洞解决方案的规范。所有输出都使用Lean的类型检查器进行事后验证，以确保机器可检查的正确性。", "motivation": "解决现有基准测试在验证代码生成方面的不足，如依赖测试用例监督、LLM生成的注释和可能泄露实现逻辑的规范，提供一个更高质量和挑战性的基准。", "method": "创建了一个包含161个问题的基准测试${\\rm C{\\small LEVER}}$，每个问题要求生成与真实规范相匹配的规范及其Lean实现，所有输出通过Lean的类型检查器验证。", "result": "评估了几种基于最先进语言模型的少样本和代理方法，这些方法在实现完全验证方面均遇到困难，确立了${\\rm C{\\small LEVER}}$作为程序合成和形式推理的一个具有挑战性的前沿基准。", "conclusion": "${\\rm C{\\small LEVER}}$为程序合成和形式推理领域提供了一个高质量、挑战性的新基准，有助于推动相关技术的发展。"}}
{"id": "2505.14356", "title": "PersonaTAB: Predicting Personality Traits using Textual, Acoustic, and Behavioral Cues in Fully-Duplex Speech Dialogs", "authors": ["Sho Inoue", "Shai Wang", "Haizhou Li"], "abstract": "Despite significant progress in neural spoken dialog systems, personality-aware conversation agents -- capable of adapting behavior based on personalities -- remain underexplored due to the absence of personality annotations in speech datasets. We propose a pipeline that preprocesses raw audio recordings to create a dialogue dataset annotated with timestamps, response types, and emotion/sentiment labels. We employ an automatic speech recognition (ASR) system to extract transcripts and timestamps, then generate conversation-level annotations. Leveraging these annotations, we design a system that employs large language models to predict conversational personality. Human evaluators were engaged to identify conversational characteristics and assign personality labels. Our analysis demonstrates that the proposed system achieves stronger alignment with human judgments compared to existing approaches.", "subjects": "Sound (cs.SD); Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.14356.pdf", "abstract_url": "https://arxiv.org/abs/2505.14356", "categories": ["Sound (cs.SD)", "Computation and Language (cs.CL)", "Audio and Speech Processing (eess.AS)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种流程，通过预处理原始音频记录来创建一个带有时间戳、响应类型和情感/情绪标签的对话数据集，并利用大型语言模型预测对话个性，结果显示该系统与人类判断的一致性优于现有方法。", "motivation": "由于语音数据集中缺乏个性注释，能够根据个性调整行为的个性感知对话代理仍然未被充分探索。", "method": "使用自动语音识别(ASR)系统提取转录和时间戳，生成对话级注释，并设计一个系统利用大型语言模型预测对话个性。", "result": "分析表明，所提出的系统与人类判断的一致性优于现有方法。", "conclusion": "该研究为个性感知对话系统的发展提供了新的视角和方法，展示了利用文本、声学和行为线索预测个性特征的潜力。"}}
{"id": "2505.14680", "title": "NExT-Search: Rebuilding User Feedback Ecosystem for Generative AI Search", "authors": ["Sunhao Dai", "Wenjie Wang", "Liang Pang", "Jun Xu", "See-Kiong Ng", "Ji-Rong Wen", "Tat-Seng Chua"], "abstract": "Generative AI search is reshaping information retrieval by offering end-to-end answers to complex queries, reducing users' reliance on manually browsing and summarizing multiple web pages. However, while this paradigm enhances convenience, it disrupts the feedback-driven improvement loop that has historically powered the evolution of traditional Web search. Web search can continuously improve their ranking models by collecting large-scale, fine-grained user feedback (e.g., clicks, dwell time) at the document level. In contrast, generative AI search operates through a much longer search pipeline, spanning query decomposition, document retrieval, and answer generation, yet typically receives only coarse-grained feedback on the final answer. This introduces a feedback loop disconnect, where user feedback for the final output cannot be effectively mapped back to specific system components, making it difficult to improve each intermediate stage and sustain the feedback loop. In this paper, we envision NExT-Search, a next-generation paradigm designed to reintroduce fine-grained, process-level feedback into generative AI search. NExT-Search integrates two complementary modes: User Debug Mode, which allows engaged users to intervene at key stages; and Shadow User Mode, where a personalized user agent simulates user preferences and provides AI-assisted feedback for less interactive users. Furthermore, we envision how these feedback signals can be leveraged through online adaptation, which refines current search outputs in real-time, and offline update, which aggregates interaction logs to periodically fine-tune query decomposition, retrieval, and generation models. By restoring human control over key stages of the generative AI search pipeline, we believe NExT-Search offers a promising direction for building feedback-rich AI search systems that can evolve continuously alongside human feedback.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)", "comments": "SIGIR 2025 Perspective Paper", "pdf_url": "https://arxiv.org/pdf/2505.14680.pdf", "abstract_url": "https://arxiv.org/abs/2505.14680", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "NExT-Search是一个旨在重建生成式AI搜索中用户反馈生态系统的新范式，通过引入细粒度的过程级反馈来解决现有生成式AI搜索中反馈循环断开的问题。", "motivation": "生成式AI搜索通过提供端到端的答案改变了信息检索的方式，但同时也破坏了传统网页搜索中依赖用户反馈驱动的改进循环。这种模式使得用户对最终输出的反馈难以映射回系统的具体组件，从而难以持续改进。", "method": "NExT-Search引入了两种互补模式：用户调试模式，允许积极参与的用户在关键阶段进行干预；影子用户模式，通过个性化用户代理模拟用户偏好并为互动较少的用户提供AI辅助反馈。此外，还探讨了如何通过这些反馈信号进行在线适应和离线更新。", "result": "通过恢复人类对生成式AI搜索关键阶段的控制，NExT-Search为构建能够与人类反馈共同持续进化的反馈丰富的AI搜索系统提供了有前景的方向。", "conclusion": "NExT-Search通过重新引入细粒度的过程级反馈，为解决生成式AI搜索中的反馈循环断开问题提供了有效途径，有望推动AI搜索系统的持续进化。"}}
{"id": "2505.14533", "title": "Energy-Efficient Deep Reinforcement Learning with Spiking Transformers", "authors": ["Mohammad Irfan Uddin", "Nishad Tasnim", "Md Omor Faruk", "Zejian Zhou"], "abstract": "Agent-based Transformers have been widely adopted in recent reinforcement learning advances due to their demonstrated ability to solve complex tasks. However, the high computational complexity of Transformers often results in significant energy consumption, limiting their deployment in real-world autonomous systems. Spiking neural networks (SNNs), with their biologically inspired structure, offer an energy-efficient alternative for machine learning. In this paper, a novel Spike-Transformer Reinforcement Learning (STRL) algorithm that combines the energy efficiency of SNNs with the powerful decision-making capabilities of reinforcement learning is developed. Specifically, an SNN using multi-step Leaky Integrate-and-Fire (LIF) neurons and attention mechanisms capable of processing spatio-temporal patterns over multiple time steps is designed. The architecture is further enhanced with state, action, and reward encodings to create a Transformer-like structure optimized for reinforcement learning tasks. Comprehensive numerical experiments conducted on state-of-the-art benchmarks demonstrate that the proposed SNN Transformer achieves significantly improved policy performance compared to conventional agent-based Transformers. With both enhanced energy efficiency and policy optimality, this work highlights a promising direction for deploying bio-inspired, low-cost machine learning models in complex real-world decision-making scenarios.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.14533.pdf", "abstract_url": "https://arxiv.org/abs/2505.14533", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新型的Spike-Transformer强化学习算法（STRL），将脉冲神经网络（SNN）的能量效率与强化学习的强大决策能力相结合，旨在解决传统Transformer在强化学习中高能耗的问题。", "motivation": "传统Transformer在强化学习中的应用虽然强大，但其高计算复杂度导致的高能耗限制了其在现实世界自主系统中的部署。", "method": "开发了一种使用多步Leaky Integrate-and-Fire（LIF）神经元和注意力机制的SNN，能够处理多时间步的时空模式，并通过状态、动作和奖励编码进一步增强，构建了一个优化于强化学习任务的Transformer-like结构。", "result": "在最先进的基准测试中进行的全面数值实验表明，提出的SNN Transformer在策略性能上显著优于传统的基于代理的Transformer。", "conclusion": "这项工作展示了在复杂的现实世界决策场景中部署生物启发、低成本机器学习模型的有前景方向，同时提高了能量效率和策略最优性。"}}
