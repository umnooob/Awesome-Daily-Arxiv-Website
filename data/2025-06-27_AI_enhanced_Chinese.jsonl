{"id": "2506.20911", "title": "FaSTA$^*$: Fast-Slow Toolpath Agent with Subroutine Mining for Efficient Multi-turn Image Editing", "authors": ["Advait Gupta", "Rishie Raj", "Dang Nguyen", "Tianyi Zhou"], "abstract": "We develop a cost-efficient neurosymbolic agent to address challenging multi-turn image editing tasks such as \"Detect the bench in the image while recoloring it to pink. Also, remove the cat for a clearer view and recolor the wall to yellow.'' It combines the fast, high-level subtask planning by large language models (LLMs) with the slow, accurate, tool-use, and local A$^*$ search per subtask to find a cost-efficient toolpath -- a sequence of calls to AI tools. To save the cost of A$^*$ on similar subtasks, we perform inductive reasoning on previously successful toolpaths via LLMs to continuously extract/refine frequently used subroutines and reuse them as new tools for future tasks in an adaptive fast-slow planning, where the higher-level subroutines are explored first, and only when they fail, the low-level A$^*$ search is activated. The reusable symbolic subroutines considerably save exploration cost on the same types of subtasks applied to similar images, yielding a human-like fast-slow toolpath agent \"FaSTA$^*$'': fast subtask planning followed by rule-based subroutine selection per subtask is attempted by LLMs at first, which is expected to cover most tasks, while slow A$^*$ search is only triggered for novel and challenging subtasks. By comparing with recent image editing approaches, we demonstrate FaSTA$^*$ is significantly more computationally efficient while remaining competitive with the state-of-the-art baseline in terms of success rate.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.20911.pdf", "abstract_url": "https://arxiv.org/abs/2506.20911", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "FaSTA$^*$是一种结合了大型语言模型（LLMs）快速高级子任务规划和局部A$^*$搜索的神经符号代理，用于高效处理多轮图像编辑任务。通过归纳推理提取和优化常用子程序，并在未来任务中重用，实现了快速-慢速规划，显著提高了计算效率。", "motivation": "解决多轮图像编辑任务中的成本效率问题，如同时执行检测、重新着色和移除对象等复杂指令。", "method": "结合LLMs的快速子任务规划和局部A$^*$搜索的慢速准确工具使用，通过归纳推理提取和优化常用子程序，实现快速-慢速规划。", "result": "FaSTA$^*$在计算效率上显著优于现有图像编辑方法，同时在成功率上与最先进的基线方法竞争。", "conclusion": "FaSTA$^*$通过快速-慢速规划和子程序重用，有效提高了多轮图像编辑任务的执行效率和成功率。"}}
{"id": "2506.20737", "title": "MAGPIE: A dataset for Multi-AGent contextual PrIvacy Evaluation", "authors": ["Gurusha Juneja", "Alon Albalak", "Wenyue Hua", "William Yang Wang"], "abstract": "The proliferation of LLM-based agents has led to increasing deployment of inter-agent collaboration for tasks like scheduling, negotiation, resource allocation etc. In such systems, privacy is critical, as agents often access proprietary tools and domain-specific databases requiring strict confidentiality. This paper examines whether LLM-based agents demonstrate an understanding of contextual privacy. And, if instructed, do these systems preserve inference time user privacy in non-adversarial multi-turn conversation. Existing benchmarks to evaluate contextual privacy in LLM-agents primarily assess single-turn, low-complexity tasks where private information can be easily excluded. We first present a benchmark - MAGPIE comprising 158 real-life high-stakes scenarios across 15 domains. These scenarios are designed such that complete exclusion of private data impedes task completion yet unrestricted information sharing could lead to substantial losses. We then evaluate the current state-of-the-art LLMs on (a) their understanding of contextually private data and (b) their ability to collaborate without violating user privacy. Empirical experiments demonstrate that current models, including GPT-4o and Claude-2.7-Sonnet, lack robust understanding of contextual privacy, misclassifying private data as shareable 25.2\\% and 43.6\\% of the time. In multi-turn conversations, these models disclose private information in 59.9\\% and 50.5\\% of cases even under explicit privacy instructions. Furthermore, multi-agent systems fail to complete tasks in 71\\% of scenarios. These results underscore that current models are not aligned towards both contextual privacy preservation and collaborative task-solving.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.20737.pdf", "abstract_url": "https://arxiv.org/abs/2506.20737", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了MAGPIE数据集，用于评估多代理系统中的上下文隐私保护能力。研究发现，现有LLM在理解和保护上下文隐私方面存在不足，尤其在多轮对话中容易泄露隐私信息。", "motivation": "随着基于LLM的代理在任务协作中的广泛应用，隐私保护变得尤为重要。现有评估基准主要针对单轮、低复杂度的任务，难以全面评估代理在多轮对话中的隐私保护能力。", "method": "研究团队创建了MAGPIE基准，包含158个高风险场景，覆盖15个领域。随后评估了包括GPT-4o和Claude-2.7-Sonnet在内的当前最先进LLM在理解上下文隐私和协作时不侵犯用户隐私的能力。", "result": "实验显示，当前模型对上下文隐私的理解不足，错误地将隐私数据分类为可共享的比例分别为25.2%和43.6%。在多轮对话中，即使有明确的隐私指令，模型仍分别有59.9%和50.5%的情况下泄露隐私信息。此外，多代理系统在71%的场景中未能完成任务。", "conclusion": "研究结果表明，当前模型在上下文隐私保护和协作任务解决方面尚未达到理想的对齐状态，亟需改进。"}}
{"id": "2506.20964", "title": "Evidence-based diagnostic reasoning with multi-agent copilot for human pathology", "authors": ["Chengkuan Chen", "Luca L. Weishaupt", "Drew F. K. Williamson", "Richard J. Chen", "Tong Ding", "Bowen Chen", "Anurag Vaidya", "Long Phi Le", "Guillaume Jaume", "Ming Y. Lu", "Faisal Mahmood"], "abstract": "Pathology is experiencing rapid digital transformation driven by whole-slide imaging and artificial intelligence (AI). While deep learning-based computational pathology has achieved notable success, traditional models primarily focus on image analysis without integrating natural language instruction or rich, text-based context. Current multimodal large language models (MLLMs) in computational pathology face limitations, including insufficient training data, inadequate support and evaluation for multi-image understanding, and a lack of autonomous, diagnostic reasoning capabilities. To address these limitations, we introduce PathChat+, a new MLLM specifically designed for human pathology, trained on over 1 million diverse, pathology-specific instruction samples and nearly 5.5 million question answer turns. Extensive evaluations across diverse pathology benchmarks demonstrated that PathChat+ substantially outperforms the prior PathChat copilot, as well as both state-of-the-art (SOTA) general-purpose and other pathology-specific models. Furthermore, we present SlideSeek, a reasoning-enabled multi-agent AI system leveraging PathChat+ to autonomously evaluate gigapixel whole-slide images (WSIs) through iterative, hierarchical diagnostic reasoning, reaching high accuracy on DDxBench, a challenging open-ended differential diagnosis benchmark, while also capable of generating visually grounded, humanly-interpretable summary reports.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.20964.pdf", "abstract_url": "https://arxiv.org/abs/2506.20964", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了PathChat+，一种专为人类病理学设计的新型多模态大型语言模型（MLLM），通过超过100万种多样化的病理学特定指令样本和近550万个问答对的训练，显著优于现有模型。此外，还介绍了SlideSeek，一个利用PathChat+通过迭代、分层诊断推理自主评估千兆像素全幻灯片图像（WSIs）的AI系统。", "motivation": "解决当前计算病理学中多模态大型语言模型（MLLMs）的局限性，包括训练数据不足、多图像理解支持与评估不足，以及缺乏自主诊断推理能力。", "method": "开发PathChat+模型，训练于大量病理学特定指令样本和问答对，并构建SlideSeek系统，利用PathChat+进行自主WSIs评估。", "result": "PathChat+在多样化的病理学基准测试中显著优于现有模型，SlideSeek在开放式的差异诊断基准测试DDxBench上达到高准确率，并能生成视觉基础的人类可解读总结报告。", "conclusion": "PathChat+和SlideSeek的引入为病理学的数字转型提供了强有力的工具，通过集成自然语言指令和文本上下文，提升了诊断推理的准确性和效率。"}}
{"id": "2506.21506", "title": "Mind2Web 2: Evaluating Agentic Search with Agent-as-a-Judge", "authors": ["Boyu Gou", "Zanming Huang", "Yuting Ning", "Yu Gu", "Michael Lin", "Weijian Qi", "Andrei Kopanev", "Botao Yu", "Bernal Jiménez Gutiérrez", "Yiheng Shu", "Chan Hee Song", "Jiaman Wu", "Shijie Chen", "Hanane Nour Moussa", "Tianshu Zhang", "Jian Xie", "Yifei Li", "Tianci Xue", "Zeyi Liao", "Kai Zhang", "Boyuan Zheng", "Zhaowei Cai", "Viktor Rozgic", "Morteza Ziyadi", "Huan Sun", "Yu Su"], "abstract": "Agentic search such as Deep Research systems, where large language models autonomously browse the web, synthesize information, and return comprehensive citation-backed answers, represents a major shift in how users interact with web-scale information. While promising greater efficiency and cognitive offloading, the growing complexity and open-endedness of agentic search have outpaced existing evaluation benchmarks and methodologies, which largely assume short search horizons and static answers. In this paper, we introduce Mind2Web 2, a benchmark of 130 realistic, high-quality, and long-horizon tasks that require real-time web browsing and extensive information synthesis, constructed with over 1,000 hours of human labor. To address the challenge of evaluating time-varying and complex answers, we propose a novel Agent-as-a-Judge framework. Our method constructs task-specific judge agents based on a tree-structured rubric design to automatically assess both answer correctness and source attribution. We conduct a comprehensive evaluation of nine frontier agentic search systems and human performance, along with a detailed error analysis to draw insights for future development. The best-performing system, OpenAI Deep Research, can already achieve 50-70% of human performance while spending half the time, showing a great potential. Altogether, Mind2Web 2 provides a rigorous foundation for developing and benchmarking the next generation of agentic search systems.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2506.21506.pdf", "abstract_url": "https://arxiv.org/abs/2506.21506", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了Mind2Web 2，一个包含130个现实、高质量、长视野任务的基准，用于评估代理搜索系统，并提出了一种新颖的Agent-as-a-Judge框架来自动评估答案正确性和来源归属。", "motivation": "代理搜索系统的复杂性和开放性已经超过了现有的评估基准和方法，这些基准和方法大多假设搜索视野短且答案静态。", "method": "提出了一个基于树形结构评分设计的任务特定法官代理框架，用于自动评估答案正确性和来源归属。", "result": "评估了九个前沿代理搜索系统和人类表现，最佳表现系统OpenAI Deep Research已经能够达到人类表现的50-70%，同时花费的时间减半。", "conclusion": "Mind2Web 2为开发和基准测试下一代代理搜索系统提供了严格的基础，展示了巨大的潜力。"}}
{"id": "2506.20949", "title": "Beyond Reactive Safety: Risk-Aware LLM Alignment via Long-Horizon Simulation", "authors": ["Chenkai Sun", "Denghui Zhang", "ChengXiang Zhai", "Heng Ji"], "abstract": "Given the growing influence of language model-based agents on high-stakes societal decisions, from public policy to healthcare, ensuring their beneficial impact requires understanding the far-reaching implications of their suggestions. We propose a proof-of-concept framework that projects how model-generated advice could propagate through societal systems on a macroscopic scale over time, enabling more robust alignment. To assess the long-term safety awareness of language models, we also introduce a dataset of 100 indirect harm scenarios, testing models' ability to foresee adverse, non-obvious outcomes from seemingly harmless user prompts. Our approach achieves not only over 20% improvement on the new dataset but also an average win rate exceeding 70% against strong baselines on existing safety benchmarks (AdvBench, SafeRLHF, WildGuardMix), suggesting a promising direction for safer agents.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.20949.pdf", "abstract_url": "https://arxiv.org/abs/2506.20949", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种概念验证框架，用于评估和提升语言模型在社会决策中的长期安全意识和一致性。通过宏观社会系统模拟和新的间接危害场景数据集，该方法在安全基准测试中表现出色。", "motivation": "随着基于语言模型的代理在高风险社会决策中的影响力增加，理解其建议的深远影响以确保其有益影响变得至关重要。", "method": "提出了一个框架，通过宏观社会系统模拟来预测模型生成的建议如何随时间传播，并引入了一个包含100个间接危害场景的数据集来测试模型的长期安全意识。", "result": "该方法在新数据集上实现了超过20%的改进，并在现有安全基准测试（AdvBench、SafeRLHF、WildGuardMix）上平均胜率超过70%。", "conclusion": "这项研究为开发更安全的语言模型代理提供了一个有前景的方向，特别是在理解和减轻长期、非显而易见的危害方面。"}}
{"id": "2506.21490", "title": "Ad-Hoc Human-AI Coordination Challenge", "authors": ["Tin Dizdarević", "Ravi Hammond", "Tobias Gessler", "Anisoara Calinescu", "Jonathan Cook", "Matteo Gallici", "Andrei Lupu", "Jakob Nicolaus Foerster"], "abstract": "Achieving seamless coordination between AI agents and humans is crucial for real-world applications, yet it remains a significant open challenge. Hanabi is a cooperative card game featuring imperfect information, constrained communication, theory of mind requirements, and coordinated action -- making it an ideal testbed for human-AI coordination. However, its use for human-AI interaction has been limited by the challenges of human evaluation. In this work, we introduce the Ad-Hoc Human-AI Coordination Challenge (AH2AC2) to overcome the constraints of costly and difficult-to-reproduce human evaluations. We develop \\textit{human proxy agents} on a large-scale human dataset that serve as robust, cheap, and reproducible human-like evaluation partners in AH2AC2. To encourage the development of data-efficient methods, we open-source a dataset of 3,079 games, deliberately limiting the amount of available human gameplay data. We present baseline results for both two- and three- player Hanabi scenarios. To ensure fair evaluation, we host the proxy agents through a controlled evaluation system rather than releasing them publicly. The code is available at \\href{", "subjects": "Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Multiagent Systems (cs.MA)", "comments": "Published at ICML 2025", "pdf_url": "https://arxiv.org/pdf/2506.21490.pdf", "abstract_url": "https://arxiv.org/abs/2506.21490", "categories": ["Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了Ad-Hoc Human-AI Coordination Challenge (AH2AC2)，旨在通过开发人类代理代理来解决人类与AI协调的挑战，特别是在Hanabi游戏中。通过开源有限的人类游戏数据集和使用代理代理进行评价，促进了数据高效方法的发展。", "motivation": "解决AI代理与人类在现实应用中的无缝协调问题，特别是在Hanabi这一具有不完全信息、受限通信、心智理论要求和协调行动的游戏中。", "method": "开发大规模人类数据集上的人类代理代理，作为AH2AC2中稳健、廉价且可重复的人类评价伙伴，并开源了一个包含3,079个游戏的有限数据集。", "result": "为两玩家和三玩家的Hanabi场景提供了基线结果，并通过受控评价系统确保公平评价。", "conclusion": "AH2AC2通过人类代理代理和有限数据集，为人类-AI协调研究提供了一个可重复、成本效益高的评价框架，推动了数据高效方法的发展。"}}
{"id": "2504.15217", "title": "DRAGON: Distributional Rewards Optimize Diffusion Generative Models", "authors": ["Yatong Bai", "Jonah Casebeer", "Somayeh Sojoudi", "Nicholas J. Bryan"], "abstract": "We present Distributional RewArds for Generative OptimizatioN (DRAGON), a versatile framework for fine-tuning media generation models towards a desired outcome. Compared with traditional reinforcement learning with human feedback (RLHF) or pairwise preference approaches such as direct preference optimization (DPO), DRAGON is more flexible. It can optimize reward functions that evaluate either individual examples or distributions of them, making it compatible with a broad spectrum of instance-wise, instance-to-distribution, and distribution-to-distribution rewards. Leveraging this versatility, we construct novel reward functions by selecting an encoder and a set of reference examples to create an exemplar distribution. When cross-modality encoders such as CLAP are used, the reference examples may be of a different modality (e.g., text versus audio). Then, DRAGON gathers online and on-policy generations, scores them to construct a positive demonstration set and a negative set, and leverages the contrast between the two sets to maximize the reward. For evaluation, we fine-tune an audio-domain text-to-music diffusion model with 20 different reward functions, including a custom music aesthetics model, CLAP score, Vendi diversity, and Frechet audio distance (FAD). We further compare instance-wise (per-song) and full-dataset FAD settings while ablating multiple FAD encoders and reference sets. Over all 20 target rewards, DRAGON achieves an 81.45% average win rate. Moreover, reward functions based on exemplar sets indeed enhance generations and are comparable to model-based rewards. With an appropriate exemplar set, DRAGON achieves a 60.95% human-voted music quality win rate without training on human preference annotations. As such, DRAGON exhibits a new approach to designing and optimizing reward functions for improving human-perceived quality. Sound examples at", "subjects": "Sound (cs.SD); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multimedia (cs.MM)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.15217.pdf", "abstract_url": "https://arxiv.org/abs/2504.15217", "categories": ["Sound (cs.SD)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Multimedia (cs.MM)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "DRAGON是一个用于微调媒体生成模型的框架，通过分布奖励优化生成模型，比传统方法更灵活，支持多种奖励函数，并在音频领域取得了显著效果。", "motivation": "解决传统强化学习与人类反馈（RLHF）或直接偏好优化（DPO）等方法在优化媒体生成模型时的局限性，提供更灵活的奖励函数优化方案。", "method": "利用选定的编码器和参考示例创建示范分布，通过对比正负示例集来最大化奖励，支持实例级、实例到分布和分布到分布的奖励函数。", "result": "在20种不同的奖励函数上，DRAGON平均胜率达到81.45%，且基于示范集的奖励函数能有效提升生成质量，无需人类偏好注释训练即可达到60.95%的人类投票音乐质量胜率。", "conclusion": "DRAGON提供了一种新的奖励函数设计和优化方法，显著提高了人类感知的生成质量，展示了在无需大量人类标注数据下优化生成模型的潜力。"}}
{"id": "2506.21536", "title": "PsyLite Technical Report", "authors": ["Fangjun Ding", "Renyu Zhang", "Xinyu Feng", "Chengye Xie", "Zheng Zhang", "Yanting Zhang"], "abstract": "With the rapid development of digital technology, AI-driven psychological counseling has gradually become an important research direction in the field of mental health. However, existing models still have deficiencies in dialogue safety, detailed scenario handling, and lightweight deployment. To address these issues, this study proposes PsyLite, a lightweight psychological counseling large language model agent developed based on the base model InternLM2.5-7B-chat. Through a two-stage training strategy (hybrid distillation data fine-tuning and ORPO preference optimization), PsyLite enhances the model's deep-reasoning ability, psychological counseling ability, and safe dialogue ability. After deployment using Ollama and Open WebUI, a custom workflow is created with Pipelines. An innovative conditional RAG is designed to introduce crosstalk humor elements at appropriate times during psychological counseling to enhance user experience and decline dangerous requests to strengthen dialogue safety. Evaluations show that PsyLite outperforms the baseline models in the Chinese general evaluation (CEval), psychological counseling professional evaluation (CPsyCounE), and dialogue safety evaluation (SafeDialBench), particularly in psychological counseling professionalism (CPsyCounE score improvement of 47.6\\%) and dialogue safety (\\safe{} score improvement of 2.4\\%). Additionally, the model uses quantization technology (GGUF q4\\_k\\_m) to achieve low hardware deployment (5GB memory is sufficient for operation), providing a feasible solution for psychological counseling applications in resource-constrained environments.", "subjects": "Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.21536.pdf", "abstract_url": "https://arxiv.org/abs/2506.21536", "categories": ["Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本研究提出了PsyLite，一个基于InternLM2-7B-chat开发的轻量级心理咨询大语言模型代理，通过两阶段训练策略增强模型的深度推理能力、心理咨询能力和安全对话能力，并在资源受限环境中提供可行的心理咨询应用解决方案。", "motivation": "随着数字技术的快速发展，AI驱动的心理咨询已成为心理健康领域的重要研究方向。然而，现有模型在对话安全、详细场景处理和轻量级部署方面仍存在不足。", "method": "采用两阶段训练策略（混合蒸馏数据微调和ORPO偏好优化），并通过Ollama和Open WebUI部署，设计创新的条件RAG在心理咨询中适时引入相声幽默元素以增强用户体验，同时拒绝危险请求以加强对话安全。", "result": "评估显示，PsyLite在中文通用评估（CEval）、心理咨询专业评估（CPsyCounE）和对话安全评估（SafeDialBench）中优于基线模型，特别是在心理咨询专业性（CPsyCounE得分提高47.6%）和对话安全（Safe得分提高2.4%）方面表现突出。", "conclusion": "PsyLite通过量化技术（GGUF q4_k_m）实现了低硬件部署（仅需5GB内存即可运行），为资源受限环境中的心理咨询应用提供了可行的解决方案。"}}
{"id": "2506.21121", "title": "GoIRL: Graph-Oriented Inverse Reinforcement Learning for Multimodal Trajectory Prediction", "authors": ["Muleilan Pei", "Shaoshuai Shi", "Lu Zhang", "Peiliang Li", "Shaojie Shen"], "abstract": "Trajectory prediction for surrounding agents is a challenging task in autonomous driving due to its inherent uncertainty and underlying multimodality. Unlike prevailing data-driven methods that primarily rely on supervised learning, in this paper, we introduce a novel Graph-oriented Inverse Reinforcement Learning (GoIRL) framework, which is an IRL-based predictor equipped with vectorized context representations. We develop a feature adaptor to effectively aggregate lane-graph features into grid space, enabling seamless integration with the maximum entropy IRL paradigm to infer the reward distribution and obtain the policy that can be sampled to induce multiple plausible plans. Furthermore, conditioned on the sampled plans, we implement a hierarchical parameterized trajectory generator with a refinement module to enhance prediction accuracy and a probability fusion strategy to boost prediction confidence. Extensive experimental results showcase our approach not only achieves state-of-the-art performance on the large-scale Argoverse & nuScenes motion forecasting benchmarks but also exhibits superior generalization abilities compared to existing supervised models.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)", "comments": "Accepted by ICML 2025", "pdf_url": "https://arxiv.org/pdf/2506.21121.pdf", "abstract_url": "https://arxiv.org/abs/2506.21121", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新颖的图导向逆强化学习框架GoIRL，用于自动驾驶中的多模态轨迹预测，通过在网格空间中有效聚合车道图特征，结合最大熵IRL范式推断奖励分布，并通过分层参数化轨迹生成器提高预测准确性和置信度。", "motivation": "自动驾驶中周围代理的轨迹预测由于其固有的不确定性和潜在的多模态性而具有挑战性。现有的数据驱动方法主要依赖监督学习，本文旨在通过逆强化学习框架解决这一问题。", "method": "开发了一个特征适配器，将车道图特征有效聚合到网格空间中，结合最大熵IRL范式推断奖励分布，并通过分层参数化轨迹生成器与细化模块增强预测准确性。", "result": "在Argoverse和nuScenes运动预测基准测试中，GoIRL不仅实现了最先进的性能，而且与现有监督模型相比表现出更优的泛化能力。", "conclusion": "GoIRL框架为自动驾驶中的多模态轨迹预测提供了一种有效的解决方案，通过结合逆强化学习和图表示学习，显著提高了预测性能和泛化能力。"}}
{"id": "2506.20821", "title": "MultiFinRAG: An Optimized Multimodal Retrieval-Augmented Generation (RAG) Framework for Financial Question Answering", "authors": ["Chinmay Gondhalekar", "Urjitkumar Patel", "Fang-Chun Yeh"], "abstract": "Financial documents--such as 10-Ks, 10-Qs, and investor presentations--span hundreds of pages and combine diverse modalities, including dense narrative text, structured tables, and complex figures. Answering questions over such content often requires joint reasoning across modalities, which strains traditional large language models (LLMs) and retrieval-augmented generation (RAG) pipelines due to token limitations, layout loss, and fragmented cross-modal context. We introduce MultiFinRAG, a retrieval-augmented generation framework purpose-built for financial QA. MultiFinRAG first performs multimodal extraction by grouping table and figure images into batches and sending them to a lightweight, quantized open-source multimodal LLM, which produces both structured JSON outputs and concise textual summaries. These outputs, along with narrative text, are embedded and indexed with modality-aware similarity thresholds for precise retrieval. A tiered fallback strategy then dynamically escalates from text-only to text+table+image contexts when necessary, enabling cross-modal reasoning while reducing irrelevant context. Despite running on commodity hardware, MultiFinRAG achieves 19 percentage points higher accuracy than ChatGPT-4o (free-tier) on complex financial QA tasks involving text, tables, images, and combined multimodal reasoning.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE)", "comments": "Preprint Copy", "pdf_url": "https://arxiv.org/pdf/2506.20821.pdf", "abstract_url": "https://arxiv.org/abs/2506.20821", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Computational Engineering, Finance, and Science (cs.CE)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "MultiFinRAG是一个专为金融问答设计的优化多模态检索增强生成框架，通过多模态提取和动态回退策略，显著提高了复杂金融问答任务的准确性。", "motivation": "解决传统大型语言模型和检索增强生成管道在处理跨模态金融文档时的局限性，如令牌限制、布局丢失和跨模态上下文碎片化。", "method": "采用多模态提取方法，将表格和图形图像批量处理，生成结构化JSON输出和简洁文本摘要，然后通过模态感知相似性阈值进行嵌入和索引，实现精确检索。", "result": "MultiFinRAG在涉及文本、表格、图像和组合多模态推理的复杂金融问答任务上，比ChatGPT-4o（免费版）准确率高出19个百分点。", "conclusion": "MultiFinRAG框架在商品硬件上运行，有效支持跨模态推理，同时减少无关上下文，为金融问答提供了高效的解决方案。"}}
{"id": "2506.20806", "title": "Poster: Enhancing GNN Robustness for Network Intrusion Detection via Agent-based Analysis", "authors": ["Zhonghao Zhan", "Huichi Zhou", "Hamed Haddadi"], "abstract": "Graph Neural Networks (GNNs) show great promise for Network Intrusion Detection Systems (NIDS), particularly in IoT environments, but suffer performance degradation due to distribution drift and lack robustness against realistic adversarial attacks. Current robustness evaluations often rely on unrealistic synthetic perturbations and lack demonstrations on systematic analysis of different kinds of adversarial attack, which encompass both black-box and white-box scenarios. This work proposes a novel approach to enhance GNN robustness and generalization by employing Large Language Models (LLMs) in an agentic pipeline as simulated cybersecurity expert agents. These agents scrutinize graph structures derived from network flow data, identifying and potentially mitigating suspicious or adversarially perturbed elements before GNN processing. Our experiments, using a framework designed for realistic evaluation and testing with a variety of adversarial attacks including a dataset collected from physical testbed experiments, demonstrate that integrating LLM analysis can significantly improve the resilience of GNN-based NIDS against challenges, showcasing the potential of LLM agent as a complementary layer in intrusion detection architectures.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": "Poster accepted at the 10th IEEE European Symposium on Security and Privacy (Euro S&P 2025)", "pdf_url": "https://arxiv.org/pdf/2506.20806.pdf", "abstract_url": "https://arxiv.org/abs/2506.20806", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种新颖的方法，通过利用大型语言模型（LLMs）作为模拟网络安全专家代理，来增强图神经网络（GNNs）在网络入侵检测系统（NIDS）中的鲁棒性和泛化能力。", "motivation": "图神经网络（GNNs）在网络入侵检测系统（NIDS）中显示出巨大潜力，尤其是在物联网（IoT）环境中，但由于分布漂移和对现实对抗攻击缺乏鲁棒性，其性能会下降。当前的鲁棒性评估往往依赖于不现实的合成扰动，缺乏对不同种类对抗攻击（包括黑盒和白盒场景）的系统分析。", "method": "本研究提出了一种新颖的方法，通过利用大型语言模型（LLMs）在代理管道中作为模拟网络安全专家代理，来增强GNN的鲁棒性和泛化能力。这些代理会审查来自网络流量数据的图结构，识别并可能在GNN处理之前缓解可疑或对抗性扰动的元素。", "result": "我们的实验，使用一个为现实评估和测试设计的框架，包括从物理测试台实验收集的数据集，展示了整合LLM分析可以显著提高基于GNN的NIDS对抗挑战的韧性，展示了LLM代理作为入侵检测架构中补充层的潜力。", "conclusion": "整合LLM分析可以显著提高基于GNN的NIDS对抗挑战的韧性，展示了LLM代理作为入侵检测架构中补充层的潜力。"}}
{"id": "2506.20876", "title": "Decide less, communicate more: On the construct validity of end-to-end fact-checking in medicine", "authors": ["Sebastian Joseph", "Lily Chen", "Barry Wei", "Michael Mackert", "Iain J. Marshall", "Paul Pu Liang", "Ramez Kouzy", "Byron C. Wallace", "Junyi Jessy Li"], "abstract": "Technological progress has led to concrete advancements in tasks that were regarded as challenging, such as automatic fact-checking. Interest in adopting these systems for public health and medicine has grown due to the high-stakes nature of medical decisions and challenges in critically appraising a vast and diverse medical literature. Evidence-based medicine connects to every individual, and yet the nature of it is highly technical, rendering the medical literacy of majority users inadequate to sufficiently navigate the domain. Such problems with medical communication ripens the ground for end-to-end fact-checking agents: check a claim against current medical literature and return with an evidence-backed verdict. And yet, such systems remain largely unused. To understand this, we present the first study examining how clinical experts verify real claims from social media by synthesizing medical evidence. In searching for this upper-bound, we reveal fundamental challenges in end-to-end fact-checking when applied to medicine: Difficulties connecting claims in the wild to scientific evidence in the form of clinical trials; ambiguities in underspecified claims mixed with mismatched intentions; and inherently subjective veracity labels. We argue that fact-checking should be approached and evaluated as an interactive communication problem, rather than an end-to-end process.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.20876.pdf", "abstract_url": "https://arxiv.org/abs/2506.20876", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了在医学领域实施端到端事实核查的构建有效性，指出尽管技术进步使得自动事实核查成为可能，但在医学领域的应用仍面临根本性挑战。", "motivation": "解决医学决策中的高风险性质及广大用户在医学文献批判性评估上的困难，探讨为何端到端事实核查系统在医学领域未被广泛采用。", "method": "通过研究临床专家如何通过综合医学证据验证社交媒体上的真实声明，寻找端到端事实核查在医学应用中的上限。", "result": "揭示了医学端到端事实核查的根本挑战：将野生声明与临床试验形式的科学证据联系起来的困难；未明确声明的模糊性与不匹配意图的混合；以及本质上主观的真实性标签。", "conclusion": "主张事实核查应被视为一个互动沟通问题来接近和评估，而非一个端到端的过程。"}}
{"id": "2506.21098", "title": "ComRAG: Retrieval-Augmented Generation with Dynamic Vector Stores for Real-time Community Question Answering in Industry", "authors": ["Qinwen Chen", "Wenbiao Tao", "Zhiwei Zhu", "Mingfan Xi", "Liangzhong Guo", "Yuan Wang", "Wei Wang", "Yunshi Lan"], "abstract": "Community Question Answering (CQA) platforms can be deemed as important knowledge bases in community, but effectively leveraging historical interactions and domain knowledge in real-time remains a challenge. Existing methods often underutilize external knowledge, fail to incorporate dynamic historical QA context, or lack memory mechanisms suited for industrial deployment. We propose ComRAG, a retrieval-augmented generation framework for real-time industrial CQA that integrates static knowledge with dynamic historical QA pairs via a centroid-based memory mechanism designed for retrieval, generation, and efficient storage. Evaluated on three industrial CQA datasets, ComRAG consistently outperforms all baselines--achieving up to 25.9% improvement in vector similarity, reducing latency by 8.7% to 23.3%, and lowering chunk growth from 20.23% to 2.06% over iterations.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "7 pages, 4 figures. Accepted at ACL 2025 Industry Track", "pdf_url": "https://arxiv.org/pdf/2506.21098.pdf", "abstract_url": "https://arxiv.org/abs/2506.21098", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "ComRAG是一个为实时工业社区问答设计的检索增强生成框架，通过基于质心的记忆机制整合静态知识和动态历史问答对，显著提高了性能并降低了延迟。", "motivation": "社区问答平台作为重要的知识库，在实时利用历史互动和领域知识方面存在挑战，现有方法未能充分利用外部知识或缺乏适合工业部署的记忆机制。", "method": "提出了ComRAG框架，通过基于质心的记忆机制整合静态知识和动态历史问答对，优化检索、生成和存储效率。", "result": "在三个工业CQA数据集上的评估显示，ComRAG在向量相似性上提高了25.9%，延迟降低了8.7%至23.3%，块增长从20.23%降至2.06%。", "conclusion": "ComRAG通过创新的记忆机制和高效的存储策略，为工业社区问答提供了有效的解决方案，显著提升了性能和效率。"}}
{"id": "2506.20869", "title": "Engineering RAG Systems for Real-World Applications: Design, Development, and Evaluation", "authors": ["Md Toufique Hasan", "Muhammad Waseem", "Kai-Kristian Kemell", "Ayman Asad Khan", "Mika Saari", "Pekka Abrahamsson"], "abstract": "Retrieval-Augmented Generation (RAG) systems are emerging as a key approach for grounding Large Language Models (LLMs) in external knowledge, addressing limitations in factual accuracy and contextual relevance. However, there is a lack of empirical studies that report on the development of RAG-based implementations grounded in real-world use cases, evaluated through general user involvement, and accompanied by systematic documentation of lessons learned. This paper presents five domain-specific RAG applications developed for real-world scenarios across governance, cybersecurity, agriculture, industrial research, and medical diagnostics. Each system incorporates multilingual OCR, semantic retrieval via vector embeddings, and domain-adapted LLMs, deployed through local servers or cloud APIs to meet distinct user needs. A web-based evaluation involving a total of 100 participants assessed the systems across six dimensions: (i) Ease of Use, (ii) Relevance, (iii) Transparency, (iv) Responsiveness, (v) Accuracy, and (vi) Likelihood of Recommendation. Based on user feedback and our development experience, we documented twelve key lessons learned, highlighting technical, operational, and ethical challenges affecting the reliability and usability of RAG systems in practice.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": "Accepted as a full paper to the 51st Euromicro Conference on Software Engineering and Advanced Applications (SEAA 2025). 9 pages, 4 figures. This is the preprint version and not the final camera ready version", "pdf_url": "https://arxiv.org/pdf/2506.20869.pdf", "abstract_url": "https://arxiv.org/abs/2506.20869", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了五种针对现实世界场景的RAG系统应用，涵盖了治理、网络安全、农业、工业研究和医疗诊断等领域，并通过100名参与者的网络评估，从六个维度评估了这些系统的性能，最终总结了十二个关键经验教训。", "motivation": "解决大型语言模型(LLMs)在事实准确性和上下文相关性方面的限制，缺乏基于真实用例的RAG系统实证研究的问题。", "method": "开发了五种领域特定的RAG应用，结合了多语言OCR、通过向量嵌入的语义检索和领域适应的LLMs，并通过本地服务器或云API部署。", "result": "通过100名参与者的评估，系统在易用性、相关性、透明度、响应性、准确性和推荐可能性六个维度上表现良好，并总结了十二个关键经验教训。", "conclusion": "RAG系统在实践中面临技术、操作和伦理挑战，但通过系统开发和用户评估，可以显著提高其可靠性和可用性。"}}
{"id": "2506.20883", "title": "Complex Model Transformations by Reinforcement Learning with Uncertain Human Guidance", "authors": ["Kyanna Dagenais", "Istvan David"], "abstract": "Model-driven engineering problems often require complex model transformations (MTs), i.e., MTs that are chained in extensive sequences. Pertinent examples of such problems include model synchronization, automated model repair, and design space exploration. Manually developing complex MTs is an error-prone and often infeasible process. Reinforcement learning (RL) is an apt way to alleviate these issues. In RL, an autonomous agent explores the state space through trial and error to identify beneficial sequences of actions, such as MTs. However, RL methods exhibit performance issues in complex problems. In these situations, human guidance can be of high utility. In this paper, we present an approach and technical framework for developing complex MT sequences through RL, guided by potentially uncertain human advice. Our framework allows user-defined MTs to be mapped onto RL primitives, and executes them as RL programs to find optimal MT sequences. Our evaluation shows that human guidance, even if uncertain, substantially improves RL performance, and results in more efficient development of complex MTs. Through a trade-off between the certainty and timeliness of human advice, our method takes a step towards RL-driven human-in-the-loop engineering methods.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "Accepted for ACM/IEEE MODELS'25", "pdf_url": "https://arxiv.org/pdf/2506.20883.pdf", "abstract_url": "https://arxiv.org/abs/2506.20883", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种通过强化学习（RL）结合不确定的人类指导来开发复杂模型转换（MT）序列的方法和技术框架。该框架允许将用户定义的MT映射到RL原语上，并通过执行RL程序来寻找最优的MT序列。评估表明，即使人类指导存在不确定性，也能显著提高RL性能，并更高效地开发复杂MT。", "motivation": "解决模型驱动工程中复杂模型转换（MT）序列开发过程中的错误率高和可行性低的问题。", "method": "使用强化学习（RL）结合不确定的人类指导，开发了一个技术框架，将用户定义的MT映射到RL原语上，并通过执行RL程序来寻找最优的MT序列。", "result": "评估显示，人类指导即使不确定，也能显著提高RL性能，并更高效地开发复杂MT。", "conclusion": "通过权衡人类建议的确定性和及时性，该方法向RL驱动的人类在环工程方法迈进了一步。"}}
{"id": "2506.20921", "title": "LLM-guided Chemical Process Optimization with a Multi-Agent Approach", "authors": ["Tong Zeng", "Srivathsan Badrinarayanan", "Janghoon Ock", "Cheng-Kai Lai", "Amir Barati Farimani"], "abstract": "Chemical process optimization is crucial to maximize production efficiency and economic performance. Traditional methods, including gradient-based solvers, evolutionary algorithms, and parameter grid searches, become impractical when operating constraints are ill-defined or unavailable, requiring engineers to rely on subjective heuristics to estimate feasible parameter ranges. To address this constraint definition bottleneck, we present a multi-agent framework of large language model (LLM) agents that autonomously infer operating constraints from minimal process descriptions, then collaboratively guide optimization using the inferred constraints. Our AutoGen-based agentic framework employs OpenAI's o3 model, with specialized agents for constraint generation, parameter validation, simulation execution, and optimization guidance. Through two phases - autonomous constraint generation using embedded domain knowledge, followed by iterative multi-agent optimization - the framework eliminates the need for predefined operational bounds. Validated on the hydrodealkylation process across cost, yield, and yield-to-cost ratio metrics, the framework demonstrated competitive performance with conventional optimization methods while achieving better computational efficiency, requiring fewer iterations to converge. Our approach converged in under 20 minutes, achieving a 31-fold speedup over grid search. Beyond computational efficiency, the framework's reasoning-guided search demonstrates sophisticated process understanding, correctly identifying utility trade-offs, and applying domain-informed heuristics. This approach shows significant potential for optimization scenarios where operational constraints are poorly characterized or unavailable, particularly for emerging processes and retrofit applications.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE)", "comments": "16 pages (main manuscript without references), 2 figures", "pdf_url": "https://arxiv.org/pdf/2506.20921.pdf", "abstract_url": "https://arxiv.org/abs/2506.20921", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computational Engineering, Finance, and Science (cs.CE)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种基于大型语言模型（LLM）的多智能体框架，用于化学过程优化，特别是在操作约束不明确或不可用的情况下。该框架通过自主推断操作约束并协作指导优化，显著提高了计算效率和优化性能。", "motivation": "解决化学过程优化中操作约束不明确或不可用的问题，传统方法在这种情况下变得不切实际，需要工程师依赖主观启发式方法来估计可行参数范围。", "method": "采用基于AutoGen的多智能体框架，利用OpenAI的o3模型，包括约束生成、参数验证、模拟执行和优化指导等专门智能体，通过自主约束生成和迭代多智能体优化两阶段进行优化。", "result": "在氢化脱烷基过程中，该框架在成本、产量和产量成本比指标上表现出与传统优化方法竞争的性能，同时实现了更好的计算效率，收敛所需迭代次数更少，速度比网格搜索快31倍。", "conclusion": "该方法在操作约束不明确或不可用的优化场景中显示出巨大潜力，特别是对于新兴过程和改造应用，其推理引导的搜索展示了复杂的过程理解和领域知识应用。"}}
{"id": "2506.21252", "title": "Agent-RewardBench: Towards a Unified Benchmark for Reward Modeling across Perception, Planning, and Safety in Real-World Multimodal Agents", "authors": ["Tianyi Men", "Zhuoran Jin", "Pengfei Cao", "Yubo Chen", "Kang Liu", "Jun Zhao"], "abstract": "As Multimodal Large Language Models (MLLMs) advance, multimodal agents show promise in real-world tasks like web navigation and embodied intelligence. However, due to limitations in a lack of external feedback, these agents struggle with self-correction and generalization. A promising approach is to use reward models as external feedback, but there is no clear on how to select reward models for agents. Thus, there is an urgent need to build a reward bench targeted at agents. To address these challenges, we propose Agent-RewardBench, a benchmark designed to evaluate reward modeling ability in MLLMs. The benchmark is characterized by three key features: (1) Multiple dimensions and real-world agent scenarios evaluation. It covers perception, planning, and safety with 7 scenarios; (2) Step-level reward evaluation. It allows for the assessment of agent capabilities at the individual steps of a task, providing a more granular view of performance during the planning process; and (3) Appropriately difficulty and high-quality. We carefully sample from 10 diverse models, difficulty control to maintain task challenges, and manual verification to ensure the integrity of the data. Experiments demonstrate that even state-of-the-art multimodal models show limited performance, highlighting the need for specialized training in agent reward modeling. Code is available at github.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "ACL 2025 Main", "pdf_url": "https://arxiv.org/pdf/2506.21252.pdf", "abstract_url": "https://arxiv.org/abs/2506.21252", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了Agent-RewardBench，一个旨在评估多模态大语言模型（MLLMs）奖励建模能力的基准测试，覆盖感知、规划和安全三个维度，包含7个真实世界代理场景，通过步骤级奖励评估和高质量数据设计，揭示了当前先进多模态模型在代理奖励建模上的局限性。", "motivation": "随着多模态大语言模型（MLLMs）的发展，多模态代理在真实世界任务中展现出潜力，但由于缺乏外部反馈，这些代理在自我纠正和泛化方面存在困难。奖励模型作为一种外部反馈方法，其选择和评估尚无明确标准，因此迫切需要建立一个针对代理的奖励基准。", "method": "提出了Agent-RewardBench基准，该基准具有三个关键特征：（1）多维度、真实世界代理场景评估，覆盖感知、规划和安全三个维度，包含7个场景；（2）步骤级奖励评估，允许在任务的各个步骤评估代理能力；（3）适当难度和高质量，通过从10个多样模型中精心采样、难度控制和人工验证确保数据完整性。", "result": "实验表明，即使是最先进的多模态模型也表现出有限的性能，突出了在代理奖励建模方面进行专门训练的必要性。", "conclusion": "Agent-RewardBench作为一个统一的基准，为评估多模态代理在感知、规划和安全方面的奖励建模能力提供了重要工具，揭示了当前模型的局限性，并指出了未来研究的方向。"}}
{"id": "2506.21384", "title": "Leveraging LLM-Assisted Query Understanding for Live Retrieval-Augmented Generation", "authors": ["Guanting Dong", "Xiaoxi Li", "Yuyao Zhang", "Mengjie Deng"], "abstract": "Real-world live retrieval-augmented generation (RAG) systems face significant challenges when processing user queries that are often noisy, ambiguous, and contain multiple intents. While RAG enhances large language models (LLMs) with external knowledge, current systems typically struggle with such complex inputs, as they are often trained or evaluated on cleaner data. This paper introduces Omni-RAG, a novel framework designed to improve the robustness and effectiveness of RAG systems in live, open-domain settings. Omni-RAG employs LLM-assisted query understanding to preprocess user inputs through three key modules: (1) Deep Query Understanding and Decomposition, which utilizes LLMs with tailored prompts to denoise queries (e.g., correcting spelling errors) and decompose multi-intent queries into structured sub-queries; (2) Intent-Aware Knowledge Retrieval, which performs retrieval for each sub-query from a corpus (i.e., FineWeb using OpenSearch) and aggregates the results; and (3) Reranking and Generation, where a reranker (i.e., BGE) refines document selection before a final response is generated by an LLM (i.e., Falcon-10B) using a chain-of-thought prompt. Omni-RAG aims to bridge the gap between current RAG capabilities and the demands of real-world applications, such as those highlighted by the SIGIR 2025 LiveRAG Challenge, by robustly handling complex and noisy queries.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": "Accepted at SIGIR 2025 LiveRAG Workshop (Oral Presentation)", "pdf_url": "https://arxiv.org/pdf/2506.21384.pdf", "abstract_url": "https://arxiv.org/abs/2506.21384", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "Omni-RAG是一个新颖的框架，旨在提高实时检索增强生成（RAG）系统在开放域设置中的鲁棒性和有效性。通过LLM辅助的查询理解，它能够处理嘈杂、模糊和包含多意图的用户查询。", "motivation": "解决实时RAG系统在处理复杂和嘈杂查询时的挑战，这些查询往往包含噪音、模糊性和多意图，而现有系统通常在更干净的数据上训练或评估，难以应对这些复杂输入。", "method": "Omni-RAG采用LLM辅助的查询理解，通过三个关键模块预处理用户输入：深度查询理解和分解、意图感知的知识检索以及重新排名和生成。", "result": "Omni-RAG能够有效地去噪查询、分解多意图查询为结构化子查询，并从语料库中检索相关信息，最终通过LLM生成响应，显著提高了RAG系统处理复杂查询的能力。", "conclusion": "Omni-RAG通过其创新的查询理解和处理机制，弥合了当前RAG能力与实时应用需求之间的差距，为处理复杂和嘈杂查询提供了有效的解决方案。"}}
{"id": "2506.21129", "title": "Curriculum-Guided Antifragile Reinforcement Learning for Secure UAV Deconfliction under Observation-Space Attacks", "authors": ["Deepak Kumar Panda", "Adolfo Perrusquia", "Weisi Guo"], "abstract": "Reinforcement learning (RL) policies deployed in safety-critical systems, such as unmanned aerial vehicle (UAV) navigation in dynamic airspace, are vulnerable to out-ofdistribution (OOD) adversarial attacks in the observation space. These attacks induce distributional shifts that significantly degrade value estimation, leading to unsafe or suboptimal decision making rendering the existing policy fragile. To address this vulnerability, we propose an antifragile RL framework designed to adapt against curriculum of incremental adversarial perturbations. The framework introduces a simulated attacker which incrementally increases the strength of observation-space perturbations which enables the RL agent to adapt and generalize across a wider range of OOD observations and anticipate previously unseen attacks. We begin with a theoretical characterization of fragility, formally defining catastrophic forgetting as a monotonic divergence in value function distributions with increasing perturbation strength. Building on this, we define antifragility as the boundedness of such value shifts and derive adaptation conditions under which forgetting is stabilized. Our method enforces these bounds through iterative expert-guided critic alignment using Wasserstein distance minimization across incrementally perturbed observations. We empirically evaluate the approach in a UAV deconfliction scenario involving dynamic 3D obstacles. Results show that the antifragile policy consistently outperforms standard and robust RL baselines when subjected to both projected gradient descent (PGD) and GPS spoofing attacks, achieving up to 15% higher cumulative reward and over 30% fewer conflict events. These findings demonstrate the practical and theoretical viability of antifragile reinforcement learning for secure and resilient decision-making in environments with evolving threat scenarios.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.21129.pdf", "abstract_url": "https://arxiv.org/abs/2506.21129", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种抗脆弱的强化学习框架，旨在通过逐步增加的对抗性扰动课程来适应和抵御观察空间中的攻击，以提高无人机在动态空域中的导航安全性。", "motivation": "安全关键系统中的强化学习策略，如无人机导航，容易受到观察空间中的分布外对抗攻击，这些攻击会导致价值估计显著下降，从而引发不安全或次优的决策。", "method": "通过引入一个模拟攻击者，逐步增加观察空间的扰动强度，使强化学习代理能够适应和泛化到更广泛的分布外观察，并通过Wasserstein距离最小化在逐步扰动的观察中实施专家指导的批评者对齐。", "result": "在无人机避碰场景中，抗脆弱策略在受到投影梯度下降和GPS欺骗攻击时， consistently outperforms标准和鲁棒的强化学习基线，实现了高达15%的更高累积奖励和超过30%的冲突事件减少。", "conclusion": "研究结果表明，抗脆弱强化学习在具有演变威胁场景的环境中，对于安全和弹性的决策制定具有实际和理论的可行性。"}}
{"id": "2506.21552", "title": "Whole-Body Conditioned Egocentric Video Prediction", "authors": ["Yutong Bai", "Danny Tran", "Amir Bar", "Yann LeCun", "Trevor Darrell", "Jitendra Malik"], "abstract": "We train models to Predict Ego-centric Video from human Actions (PEVA), given the past video and an action represented by the relative 3D body pose. By conditioning on kinematic pose trajectories, structured by the joint hierarchy of the body, our model learns to simulate how physical human actions shape the environment from a first-person point of view. We train an auto-regressive conditional diffusion transformer on Nymeria, a large-scale dataset of real-world egocentric video and body pose capture. We further design a hierarchical evaluation protocol with increasingly challenging tasks, enabling a comprehensive analysis of the model's embodied prediction and control abilities. Our work represents an initial attempt to tackle the challenges of modeling complex real-world environments and embodied agent behaviors with video prediction from the perspective of a human.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multimedia (cs.MM); Robotics (cs.RO)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2506.21552.pdf", "abstract_url": "https://arxiv.org/abs/2506.21552", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Multimedia (cs.MM)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过训练模型来预测基于人类动作的自我中心视频（PEVA），利用过去的视频和由相对3D身体姿态表示的动作。通过条件化于由身体关节层次结构化的运动学姿态轨迹，模型学习模拟物理人类动作如何从第一人称视角塑造环境。", "motivation": "解决从人类动作预测自我中心视频的挑战，模拟复杂现实世界环境和体现代理行为。", "method": "在Nymeria数据集上训练自回归条件扩散变换器，该数据集包含大规模的真实世界自我中心视频和身体姿态捕捉数据。", "result": "设计了一个分层评估协议，包含越来越具有挑战性的任务，全面分析了模型的体现预测和控制能力。", "conclusion": "这项工作是从人类视角解决视频预测中复杂现实世界环境和体现代理行为建模挑战的初步尝试。"}}
{"id": "2506.21037", "title": "RL-Selector: Reinforcement Learning-Guided Data Selection via Redundancy Assessment", "authors": ["Suorong Yang", "Peijia Li", "Furao Shen", "Jian Zhao"], "abstract": "Modern deep architectures often rely on large-scale datasets, but training on these datasets incurs high computational and storage overhead. Real-world datasets often contain substantial redundancies, prompting the need for more data-efficient training paradigms. Data selection has shown promise to mitigate redundancy by identifying the most representative samples, thereby reducing training costs without compromising performance. Existing methods typically rely on static scoring metrics or pretrained models, overlooking the combined effect of selected samples and their evolving dynamics during training. We introduce the concept of epsilon-sample cover, which quantifies sample redundancy based on inter-sample relationships, capturing the intrinsic structure of the dataset. Based on this, we reformulate data selection as a reinforcement learning (RL) process and propose RL-Selector, where a lightweight RL agent optimizes the selection policy by leveraging epsilon-sample cover derived from evolving dataset distribution as a reward signal. Extensive experiments across benchmark datasets and diverse architectures demonstrate that our method consistently outperforms existing state-of-the-art baselines. Models trained with our selected datasets show enhanced generalization performance with improved training efficiency.", "subjects": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV)", "comments": "ICCV 2025", "pdf_url": "https://arxiv.org/pdf/2506.21037.pdf", "abstract_url": "https://arxiv.org/abs/2506.21037", "categories": ["Machine Learning (cs.LG)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了RL-Selector，一种通过强化学习指导的数据选择方法，旨在通过评估冗余性来优化训练数据的选取，从而提高训练效率而不牺牲模型性能。", "motivation": "现代深度学习架构通常依赖于大规模数据集，但这些数据集的训练带来了高计算和存储开销。现实世界的数据集往往包含大量冗余，这促使需要更高效的数据训练范式。数据选择通过识别最具代表性的样本来减少冗余，从而在不影响性能的情况下降低训练成本。现有方法通常依赖于静态评分指标或预训练模型，忽视了选定样本的综合效应及其在训练过程中的动态变化。", "method": "我们引入了epsilon-sample cover的概念，它基于样本间关系量化样本冗余，捕捉数据集的内在结构。基于此，我们将数据选择重新表述为一个强化学习（RL）过程，并提出了RL-Selector，其中轻量级RL代理通过利用从演变的数据集分布中派生的epsilon-sample cover作为奖励信号来优化选择策略。", "result": "在基准数据集和多样化架构上的大量实验表明，我们的方法 consistently outperforms existing state-of-the-art baselines。使用我们选定的数据集训练的模型显示出增强的泛化性能和 improved training efficiency。", "conclusion": "RL-Selector通过强化学习指导的数据选择，有效地减少了训练数据的冗余，提高了训练效率和模型性能，为深度学习提供了一种更高效的数据训练范式。"}}
