{"id": "2509.09307", "title": "Can Multimodal LLMs See Materials Clearly? A Multimodal Benchmark on Materials Characterization", "authors": ["Zhengzhao Lai", "Youbin Zheng", "Zhenyang Cai", "Haonan Lyu", "Jinpu Yang", "Hongqing Liang", "Yan Hu", "Benyou Wang"], "abstract": "Materials characterization is fundamental to acquiring materials information, revealing the processing-microstructure-property relationships that guide material design and optimization. While multimodal large language models (MLLMs) have recently shown promise in generative and predictive tasks within materials science, their capacity to understand real-world characterization imaging data remains underexplored. To bridge this gap, we present MatCha, the first benchmark for materials characterization image understanding, comprising 1,500 questions that demand expert-level domain expertise. MatCha encompasses four key stages of materials research comprising 21 distinct tasks, each designed to reflect authentic challenges faced by materials scientists. Our evaluation of state-of-the-art MLLMs on MatCha reveals a significant performance gap compared to human experts. These models exhibit degradation when addressing questions requiring higher-level expertise and sophisticated visual perception. Simple few-shot and chain-of-thought prompting struggle to alleviate these limitations. These findings highlight that existing MLLMs still exhibit limited adaptability to real-world materials characterization scenarios. We hope MatCha will facilitate future research in areas such as new material discovery and autonomous scientific agents. MatCha is available at", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Multimedia (cs.MM)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.09307.pdf", "abstract_url": "https://arxiv.org/abs/2509.09307", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Multimedia (cs.MM)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文介绍了MatCha基准测试，评估多模态大语言模型在材料表征图像理解中的能力，发现其性能远低于人类专家，并强调现有模型的局限性。", "motivation": "解决多模态大语言模型在材料科学中处理真实世界表征成像数据时能力不足的问题，以填补这一研究空白。", "method": "开发MatCha基准测试，包含1,500个需要专家级知识的问题，涵盖材料研究的四个阶段和21个任务，并评估现有MLLMs的性能。", "result": "评估显示MLLMs在MatCha上表现显著落后于人类专家，尤其是在需要高级专业知识和复杂视觉感知的问题上，且简单提示方法无法有效改善。", "conclusion": "现有MLLMs对真实世界材料表征场景的适应性有限，MatCha基准旨在促进新材料发现和自主科学代理等领域的未来研究。"}}
{"id": "2509.08903", "title": "Noise or Nuance: An Investigation Into Useful Information and Filtering For LLM Driven AKBC", "authors": ["Alex Clay", "Ernesto Jiménez-Ruiz", "Pranava Madhyastha"], "abstract": "RAG and fine-tuning are prevalent strategies for improving the quality of LLM outputs. However, in constrained situations, such as that of the 2025 LM-KBC challenge, such techniques are restricted. In this work we investigate three facets of the triple completion task: generation, quality assurance, and LLM response parsing. Our work finds that in this constrained setting: additional information improves generation quality, LLMs can be effective at filtering poor quality triples, and the tradeoff between flexibility and consistency with LLM response parsing is setting dependent.", "subjects": "Computation and Language (cs.CL)", "comments": "8 pages, 1 figure, accepted to the ISWC 2025 LM-KBC Workshop", "pdf_url": "https://arxiv.org/pdf/2509.08903.pdf", "abstract_url": "https://arxiv.org/abs/2509.08903", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文研究了在受限环境下（如2025 LM-KBC挑战），通过生成、质量保证和LLM响应解析三个方面改进LLM输出质量，发现额外信息提升生成质量，LLM能有效过滤低质量三元组，解析的灵活性与一致性权衡取决于设置。", "motivation": "解决在约束情境（如LM-KBC挑战中RAG和微调受限）下，如何提高LLM输出质量的问题。", "method": "调查三元组完成任务的三方面：生成、质量保证和LLM响应解析。", "result": "额外信息改善生成质量，LLM能过滤低质量三元组，解析的灵活性与一致性权衡是设置依赖的。", "conclusion": "在受限设置中，信息增强和LLM过滤有效，解析策略需根据具体情境调整。"}}
{"id": "2509.08907", "title": "Automated Evidence Extraction and Scoring for Corporate Climate Policy Engagement: A Multilingual RAG Approach", "authors": ["Imene Kolli", "Ario Saeid Vaghefi", "Chiara Colesanti Senni", "Shantam Raj", "Markus Leippold"], "abstract": "InfluenceMap's LobbyMap Platform monitors the climate policy engagement of over 500 companies and 250 industry associations, assessing each entity's support or opposition to science-based policy pathways for achieving the Paris Agreement's goal of limiting global warming to 1.5°C. Although InfluenceMap has made progress with automating key elements of the analytical workflow, a significant portion of the assessment remains manual, making it time- and labor-intensive and susceptible to human error. We propose an AI-assisted framework to accelerate the monitoring of corporate climate policy engagement by leveraging Retrieval-Augmented Generation to automate the most time-intensive extraction of relevant evidence from large-scale textual data. Our evaluation shows that a combination of layout-aware parsing, the Nomic embedding model, and few-shot prompting strategies yields the best performance in extracting and classifying evidence from multilingual corporate documents. We conclude that while the automated RAG system effectively accelerates evidence extraction, the nuanced nature of the analysis necessitates a human-in-the-loop approach where the technology augments, rather than replaces, expert judgment to ensure accuracy.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.08907.pdf", "abstract_url": "https://arxiv.org/abs/2509.08907", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种基于检索增强生成（RAG）的AI辅助框架，用于自动从多语言企业文档中提取和分类气候政策参与证据，以加速监控，但强调需结合专家判断以确保准确性。", "motivation": "解决InfluenceMap平台在监控企业气候政策参与时，手动评估部分耗时、易出错的问题，旨在自动化证据提取以提高效率。", "method": "采用检索增强生成（RAG）方法，结合布局感知解析、Nomic嵌入模型和少样本提示策略，从大规模文本数据中自动化提取和分类证据。", "result": "评估显示，该方法在提取和分类多语言证据方面性能最佳，有效加速了证据提取过程。", "conclusion": "自动化RAG系统能显著提升效率，但由于分析的复杂性，需要人机协同，即技术辅助而非替代专家判断，以确保准确性。"}}
{"id": "2509.08970", "title": "Global Constraint LLM Agents for Text-to-Model Translation", "authors": ["Junyang Cai", "Serdar Kadioglu", "Bistra Dilkina"], "abstract": "Natural language descriptions of optimization or satisfaction problems are challenging to translate into correct MiniZinc models, as this process demands both logical reasoning and constraint programming expertise. We introduce a framework that addresses this challenge with an agentic approach: multiple specialized large language model (LLM) agents decompose the modeling task by global constraint type. Each agent is dedicated to detecting and generating code for a specific class of global constraint, while a final assembler agent integrates these constraint snippets into a complete MiniZinc model. By dividing the problem into smaller, well-defined sub-tasks, each LLM handles a simpler reasoning challenge, potentially reducing overall complexity. We conduct initial experiments with several LLMs and show better performance against baselines such as one-shot prompting and chain-of-thought prompting. Finally, we outline a comprehensive roadmap for future work, highlighting potential enhancements and directions for improvement.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.08970.pdf", "abstract_url": "https://arxiv.org/abs/2509.08970", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种基于多智能体LLM的框架，用于将自然语言描述的优化或满足问题翻译为MiniZinc模型，通过分解任务提高性能。", "motivation": "解决将自然语言描述的问题翻译为正确MiniZinc模型的挑战，这需要逻辑推理和约束编程专业知识。", "method": "使用多个专门的LLM智能体，按全局约束类型分解建模任务，每个智能体检测和生成特定约束的代码，最后由组装智能体整合成完整模型。", "result": "初步实验显示，相比单次提示和思维链提示等基线方法，性能更好。", "conclusion": "框架有效降低了复杂性，并提出了未来工作的路线图，包括潜在改进方向。"}}
{"id": "2509.09071", "title": "Understanding Economic Tradeoffs Between Human and AI Agents in Bargaining Games", "authors": ["Crystal Qian", "Kehang Zhu", "John Horton", "Benjamin S. Manning", "Vivian Tsai", "James Wexler", "Nithum Thain"], "abstract": "Coordination tasks traditionally performed by humans are increasingly being delegated to autonomous agents. As this pattern progresses, it becomes critical to evaluate not only these agents' performance but also the processes through which they negotiate in dynamic, multi-agent environments. Furthermore, different agents exhibit distinct advantages: traditional statistical agents, such as Bayesian models, may excel under well-specified conditions, whereas large language models (LLMs) can generalize across contexts. In this work, we compare humans (N = 216), LLMs (GPT-4o, Gemini 1.5 Pro), and Bayesian agents in a dynamic negotiation setting that enables direct, identical-condition comparisons across populations, capturing both outcomes and behavioral dynamics. Bayesian agents extract the highest surplus through aggressive optimization, at the cost of frequent trade rejections. Humans and LLMs can achieve similar overall surplus, but through distinct behaviors: LLMs favor conservative, concessionary trades with few rejections, while humans employ more strategic, risk-taking, and fairness-oriented behaviors. Thus, we find that performance parity -- a common benchmark in agent evaluation -- can conceal fundamental differences in process and alignment, which are critical for practical deployment in real-world coordination tasks.", "subjects": "Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT); Human-Computer Interaction (cs.HC)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.09071.pdf", "abstract_url": "https://arxiv.org/abs/2509.09071", "categories": ["Artificial Intelligence (cs.AI)", "Computer Science and Game Theory (cs.GT)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文比较了人类、LLM和贝叶斯代理在动态谈判游戏中的表现，发现贝叶斯代理通过激进优化获得最高盈余但拒绝率高，而人类和LLM通过不同行为实现类似盈余，强调绩效平等可能掩盖过程和一致性差异。", "motivation": "评估自主代理在动态多代理环境中谈判过程的性能差异，以解决实际协调任务中的部署问题。", "method": "在相同条件下比较人类、LLM（GPT-4o、Gemini 1.5 Pro）和贝叶斯代理在动态谈判游戏中的行为和结果。", "result": "贝叶斯代理盈余最高但拒绝率高；人类和LLM盈余相似，但LLM行为保守，人类行为更战略和公平导向。", "conclusion": "绩效平等基准可能忽略过程和一致性差异，这对实际应用至关重要。"}}
{"id": "2509.09154", "title": "Mind Meets Space: Rethinking Agentic Spatial Intelligence from a Neuroscience-inspired Perspective", "authors": ["Bui Duc Manh", "Soumyaratna Debnath", "Zetong Zhang", "Shriram Damodaran", "Arvind Kumar", "Yueyi Zhang", "Lu Mi", "Erik Cambria", "Lin Wang"], "abstract": "Recent advances in agentic AI have led to systems capable of autonomous task execution and language-based reasoning, yet their spatial reasoning abilities remain limited and underexplored, largely constrained to symbolic and sequential processing. In contrast, human spatial intelligence, rooted in integrated multisensory perception, spatial memory, and cognitive maps, enables flexible, context-aware decision-making in unstructured environments. Therefore, bridging this gap is critical for advancing Agentic Spatial Intelligence toward better interaction with the physical 3D world. To this end, we first start from scrutinizing the spatial neural models as studied in computational neuroscience, and accordingly introduce a novel computational framework grounded in neuroscience principles. This framework maps core biological functions to six essential computation modules: bio-inspired multimodal sensing, multi-sensory integration, egocentric-allocentric conversion, an artificial cognitive map, spatial memory, and spatial reasoning. Together, these modules form a perspective landscape for agentic spatial reasoning capability across both virtual and physical environments. On top, we conduct a framework-guided analysis of recent methods, evaluating their relevance to each module and identifying critical gaps that hinder the development of more neuroscience-grounded spatial reasoning modules. We further examine emerging benchmarks and datasets and explore potential application domains ranging from virtual to embodied systems, such as robotics. Finally, we outline potential research directions, emphasizing the promising roadmap that can generalize spatial reasoning across dynamic or unstructured environments. We hope this work will benefit the research community with a neuroscience-grounded perspective and a structured pathway. Our project page can be found at Github.", "subjects": "Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "comments": "54 pages, journal", "pdf_url": "https://arxiv.org/pdf/2509.09154.pdf", "abstract_url": "https://arxiv.org/abs/2509.09154", "categories": ["Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "该论文从神经科学角度重新思考智能体的空间智能，提出了一个基于神经科学原理的计算框架，包括六个核心模块，以弥合当前AI系统在空间推理方面的差距，并分析了现有方法、基准和应用。", "motivation": "解决当前智能体AI在空间推理能力上的局限性，这些系统主要依赖符号和序列处理，而人类空间智能基于多感官整合和认知地图，需要提升以更好地与物理3D世界互动。", "method": "引入一个基于神经科学原理的计算框架，包含生物启发的多模态感知、多感官整合、自我中心-异中心转换、人工认知地图、空间记忆和空间推理六个模块，并分析现有方法和数据集。", "result": "框架提供了一个结构化视角，用于评估和改进空间推理模块，识别了关键差距，并探讨了在虚拟和物理环境中的应用潜力，如机器人技术。", "conclusion": "该工作为研究社区提供了神经科学基础的视角和路径，强调了在动态或非结构化环境中推广空间推理的潜力，有望推动智能体空间智能的发展。"}}
{"id": "2509.09210", "title": "ProgD: Progressive Multi-scale Decoding with Dynamic Graphs for Joint Multi-agent Motion Forecasting", "authors": ["Xing Gao", "Zherui Huang", "Weiyao Lin", "Xiao Sun"], "abstract": "Accurate motion prediction of surrounding agents is crucial for the safe planning of autonomous vehicles. Recent advancements have extended prediction techniques from individual agents to joint predictions of multiple interacting agents, with various strategies to address complex interactions within future motions of agents. However, these methods overlook the evolving nature of these interactions. To address this limitation, we propose a novel progressive multi-scale decoding strategy, termed ProgD, with the help of dynamic heterogeneous graph-based scenario modeling. In particular, to explicitly and comprehensively capture the evolving social interactions in future scenarios, given their inherent uncertainty, we design a progressive modeling of scenarios with dynamic heterogeneous graphs. With the unfolding of such dynamic heterogeneous graphs, a factorized architecture is designed to process the spatio-temporal dependencies within future scenarios and progressively eliminate uncertainty in future motions of multiple agents. Furthermore, a multi-scale decoding procedure is incorporated to improve on the future scenario modeling and consistent prediction of agents' future motion. The proposed ProgD achieves state-of-the-art performance on the INTERACTION multi-agent prediction benchmark, ranking $1^{st}$, and the Argoverse 2 multi-world forecasting benchmark.", "subjects": "Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.09210.pdf", "abstract_url": "https://arxiv.org/abs/2509.09210", "categories": ["Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "ProgD是一种用于多智能体运动预测的渐进式多尺度解码方法，利用动态异构图建模场景，在INTERACTION和Argoverse 2基准测试中达到最先进性能。", "motivation": "解决现有方法忽视交互演化的问题，以提高自动驾驶车辆的安全规划。", "method": "使用动态异构图进行渐进式场景建模，结合多尺度解码处理时空依赖性和不确定性。", "result": "在INTERACTION和Argoverse 2基准测试中排名第一，实现最先进的预测性能。", "conclusion": "ProgD方法有效捕捉交互演化，提升多智能体运动预测的准确性和一致性。"}}
{"id": "2509.09215", "title": "Enabling Regulatory Multi-Agent Collaboration: Architecture, Challenges, and Solutions", "authors": ["Qinnan Hu", "Yuntao Wang", "Yuan Gao", "Zhou Su", "Linkang Du"], "abstract": "Large language models (LLMs)-empowered autonomous agents are transforming both digital and physical environments by enabling adaptive, multi-agent collaboration. While these agents offer significant opportunities across domains such as finance, healthcare, and smart manufacturing, their unpredictable behaviors and heterogeneous capabilities pose substantial governance and accountability challenges. In this paper, we propose a blockchain-enabled layered architecture for regulatory agent collaboration, comprising an agent layer, a blockchain data layer, and a regulatory application layer. Within this framework, we design three key modules: (i) an agent behavior tracing and arbitration module for automated accountability, (ii) a dynamic reputation evaluation module for trust assessment in collaborative scenarios, and (iii) a malicious behavior forecasting module for early detection of adversarial activities. Our approach establishes a systematic foundation for trustworthy, resilient, and scalable regulatory mechanisms in large-scale agent ecosystems. Finally, we discuss the future research directions for blockchain-enabled regulatory frameworks in multi-agent systems.", "subjects": "Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)", "comments": "7 pages, 6 figures", "pdf_url": "https://arxiv.org/pdf/2509.09215.pdf", "abstract_url": "https://arxiv.org/abs/2509.09215", "categories": ["Artificial Intelligence (cs.AI)", "Cryptography and Security (cs.CR)"], "matching_keywords": ["agent"], "AI": {"tldr": "提出基于区块链的分层架构，用于监管多智能体协作，包括行为追踪、声誉评估和恶意行为预测模块，以解决治理和问责挑战。", "motivation": "解决大语言模型驱动的自主智能体在协作中不可预测行为和异构能力带来的治理与问责问题。", "method": "设计区块链支持的分层架构，包含智能体层、区块链数据层和监管应用层，并集成行为追踪、声誉评估和恶意行为预测模块。", "result": "建立了可信、弹性和可扩展的监管机制基础，支持大规模智能体生态系统中的协作。", "conclusion": "为多智能体系统中的区块链监管框架提供了系统基础，并指出了未来研究方向。"}}
{"id": "2509.09245", "title": "Jupiter: Enhancing LLM Data Analysis Capabilities via Notebook and Inference-Time Value-Guided Search", "authors": ["Shuocheng Li", "Yihao Liu", "Silin Du", "Wenxuan Zeng", "Zhe Xu", "Mengyu Zhou", "Yeye He", "Haoyu Dong", "Shi Han", "Dongmei Zhang"], "abstract": "Large language models (LLMs) have shown great promise in automating data science workflows, but existing models still struggle with multi-step reasoning and tool use, which limits their effectiveness on complex data analysis tasks. To address this, we propose a scalable pipeline that extracts high-quality, tool-based data analysis tasks and their executable multi-step solutions from real-world Jupyter notebooks and associated data files. Using this pipeline, we introduce NbQA, a large-scale dataset of standardized task-solution pairs that reflect authentic tool-use patterns in practical data science scenarios. To further enhance multi-step reasoning, we present Jupiter, a framework that formulates data analysis as a search problem and applies Monte Carlo Tree Search (MCTS) to generate diverse solution trajectories for value model learning. During inference, Jupiter combines the value model and node visit counts to efficiently collect executable multi-step plans with minimal search steps. Experimental results show that Qwen2.5-7B and 14B-Instruct models on NbQA solve 77.82% and 86.38% of tasks on InfiAgent-DABench, respectively-matching or surpassing GPT-4o and advanced agent frameworks. Further evaluations demonstrate improved generalization and stronger tool-use reasoning across diverse multi-step reasoning tasks.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.09245.pdf", "abstract_url": "https://arxiv.org/abs/2509.09245", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "Jupiter框架通过从Jupyter笔记本提取高质量工具使用任务，结合MCTS和价值模型学习，提升LLM在数据分析和多步推理中的性能，在基准测试中达到或超越先进模型。", "motivation": "解决大型语言模型在复杂数据分析任务中多步推理和工具使用能力不足的问题。", "method": "从真实Jupyter笔记本提取任务-解决方案对构建NbQA数据集，使用MCTS进行搜索和价值模型学习，推理时结合价值模型和节点访问计数生成可执行计划。", "result": "Qwen2.5-7B和14B-Instruct模型在NbQA上分别解决77.82%和86.38%的任务，性能匹配或超越GPT-4o和先进代理框架，并展示出更好的泛化和工具使用推理能力。", "conclusion": "Jupiter框架有效提升了LLM的数据分析能力，具有实际应用潜力。"}}
{"id": "2509.09272", "title": "Fusing Knowledge and Language: A Comparative Study of Knowledge Graph-Based Question Answering with LLMs", "authors": ["Vaibhav Chaudhary", "Neha Soni", "Narotam Singh", "Amita Kapoor"], "abstract": "Knowledge graphs, a powerful tool for structuring information through relational triplets, have recently become the new front-runner in enhancing question-answering systems. While traditional Retrieval Augmented Generation (RAG) approaches are proficient in fact-based and local context-based extraction from concise texts, they encounter limitations when addressing the thematic and holistic understanding of complex, extensive texts, requiring a deeper analysis of both text and context. This paper presents a comprehensive technical comparative study of three different methodologies for constructing knowledge graph triplets and integrating them with Large Language Models (LLMs) for question answering: spaCy, Stanford CoreNLP-OpenIE, and GraphRAG, all leveraging open source technologies. We evaluate the effectiveness, feasibility, and adaptability of these methods by analyzing their capabilities, state of development, and their impact on the performance of LLM-based question answering. Experimental results indicate that while OpenIE provides the most comprehensive coverage of triplets, GraphRAG demonstrates superior reasoning abilities among the three. We conclude with a discussion on the strengths and limitations of each method and provide insights into future directions for improving knowledge graph-based question answering.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "46 pages, 4 figures, 17 tables", "pdf_url": "https://arxiv.org/pdf/2509.09272.pdf", "abstract_url": "https://arxiv.org/abs/2509.09272", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文比较了三种知识图谱构建方法（spaCy、Stanford CoreNLP-OpenIE、GraphRAG）与LLMs集成用于问答，发现OpenIE覆盖最全，GraphRAG推理最强。", "motivation": "解决传统RAG方法在处理复杂文本主题和整体理解时的局限性，通过知识图谱增强问答系统。", "method": "使用spaCy、Stanford CoreNLP-OpenIE和GraphRAG构建知识图谱三元组，并与LLMs集成进行问答评估。", "result": "实验显示OpenIE提供最全面的三元组覆盖，GraphRAG在推理能力上表现最佳。", "conclusion": "讨论了各方法的优缺点，并指出未来改进知识图谱问答的方向。"}}
{"id": "2509.09234", "title": "Agentic LLMs for Question Answering over Tabular Data", "authors": ["Rishit Tyagi", "Mohit Gupta", "Rahul Bouri"], "abstract": "Question Answering over Tabular Data (Table QA) presents unique challenges due to the diverse structure, size, and data types of real-world tables. The SemEval 2025 Task 8 (DataBench) introduced a benchmark composed of large-scale, domain-diverse datasets to evaluate the ability of models to accurately answer structured queries. We propose a Natural Language to SQL (NL-to-SQL) approach leveraging large language models (LLMs) such as GPT-4o, GPT-4o-mini, and DeepSeek v2:16b to generate SQL queries dynamically. Our system follows a multi-stage pipeline involving example selection, SQL query generation, answer extraction, verification, and iterative refinement. Experiments demonstrate the effectiveness of our approach, achieving 70.5\\% accuracy on DataBench QA and 71.6\\% on DataBench Lite QA, significantly surpassing baseline scores of 26\\% and 27\\% respectively. This paper details our methodology, experimental results, and alternative approaches, providing insights into the strengths and limitations of LLM-driven Table QA.", "subjects": "Computation and Language (cs.CL)", "comments": "Accepted at ACL workshop SemEval 2025", "pdf_url": "https://arxiv.org/pdf/2509.09234.pdf", "abstract_url": "https://arxiv.org/abs/2509.09234", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种基于大型语言模型（如GPT-4o、DeepSeek v2:16b）的自然语言到SQL方法，用于表格数据问答，通过多阶段管道实现查询生成和迭代优化，在DataBench基准上显著超越基线，准确率达70%以上。", "motivation": "解决表格数据问答（Table QA）中因表格结构、大小和数据类型多样性带来的挑战，利用SemEval 2025 Task 8基准评估模型性能。", "method": "采用多阶段管道方法，包括示例选择、SQL查询生成、答案提取、验证和迭代优化，使用大型语言模型如GPT-4o和DeepSeek v2:16b动态生成SQL查询。", "result": "在DataBench QA和DataBench Lite QA上分别达到70.5%和71.6%的准确率，显著高于基线（26%和27%）。", "conclusion": "LLM驱动的Table QA方法有效，但存在局限性，论文提供了方法论和实验结果，为未来研究提供见解。"}}
{"id": "2509.09360", "title": "MetaRAG: Metamorphic Testing for Hallucination Detection in RAG Systems", "authors": ["Channdeth Sok", "David Luz", "Yacine Haddam"], "abstract": "Large Language Models (LLMs) are increasingly deployed in enterprise applications, yet their reliability remains limited by hallucinations, i.e., confident but factually incorrect information. Existing detection approaches, such as SelfCheckGPT and MetaQA, primarily target standalone LLMs and do not address the unique challenges of Retrieval-Augmented Generation (RAG) systems, where responses must be consistent with retrieved evidence. We therefore present MetaRAG, a metamorphic testing framework for hallucination detection in Retrieval-Augmented Generation (RAG) systems. MetaRAG operates in a real-time, unsupervised, black-box setting, requiring neither ground-truth references nor access to model internals, making it suitable for proprietary and high-stakes domains. The framework proceeds in four stages: (1) decompose answers into atomic factoids, (2) generate controlled mutations of each factoid using synonym and antonym substitutions, (3) verify each variant against the retrieved context (synonyms are expected to be entailed and antonyms contradicted), and (4) aggregate penalties for inconsistencies into a response-level hallucination score. Crucially for identity-aware AI, MetaRAG localizes unsupported claims at the factoid span where they occur (e.g., pregnancy-specific precautions, LGBTQ+ refugee rights, or labor eligibility), allowing users to see flagged spans and enabling system designers to configure thresholds and guardrails for identity-sensitive queries. Experiments on a proprietary enterprise dataset illustrate the effectiveness of MetaRAG for detecting hallucinations and enabling trustworthy deployment of RAG-based conversational agents. We also outline a topic-based deployment design that translates MetaRAG's span-level scores into identity-aware safeguards; this design is discussed but not evaluated in our experiments.", "subjects": "Computation and Language (cs.CL)", "comments": "under review", "pdf_url": "https://arxiv.org/pdf/2509.09360.pdf", "abstract_url": "https://arxiv.org/abs/2509.09360", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "MetaRAG是一种用于检测检索增强生成（RAG）系统中幻觉的无监督黑盒测试框架，通过分解答案、生成变异、验证一致性和聚合分数来识别不一致性，并在企业数据上验证有效。", "motivation": "解决大语言模型在RAG系统中产生幻觉（即与检索证据不一致的自信错误信息）的问题，现有方法如SelfCheckGPT和MetaQA主要针对独立LLM，不适用于RAG的独特挑战。", "method": "使用蜕变测试框架，分四步：分解答案为原子事实、生成同义词和反义词变异、验证变异与检索上下文的一致性（同义词应被蕴含，反义词应被矛盾）、聚合不一致性惩罚为幻觉分数。", "result": "在专有企业数据集上的实验显示MetaRAG能有效检测幻觉，支持可信部署，并可定位到具体事实跨度，适用于身份敏感查询。", "conclusion": "MetaRAG提供了一种实时、无监督的方法来检测RAG系统中的幻觉，增强了可靠性和身份感知能力，但基于主题的部署设计尚未评估。"}}
{"id": "2509.09292", "title": "LightAgent: Production-level Open-source Agentic AI Framework", "authors": ["Weige Cai", "Tong Zhu", "Jinyi Niu", "Ruiqi Hu", "Lingyao Li", "Tenglong Wang", "Xiaowu Dai", "Weining Shen", "Liwen Zhang"], "abstract": "With the rapid advancement of large language models (LLMs), Multi-agent Systems (MAS) have achieved significant progress in various application scenarios. However, substantial challenges remain in designing versatile, robust, and efficient platforms for agent deployment. To address these limitations, we propose \\textbf{LightAgent}, a lightweight yet powerful agentic framework, effectively resolving the trade-off between flexibility and simplicity found in existing frameworks. LightAgent integrates core functionalities such as Memory (mem0), Tools, and Tree of Thought (ToT), while maintaining an extremely lightweight structure. As a fully open-source solution, it seamlessly integrates with mainstream chat platforms, enabling developers to easily build self-learning agents. We have released LightAgent at \\href{", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.09292.pdf", "abstract_url": "https://arxiv.org/abs/2509.09292", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "LightAgent是一个轻量级开源代理AI框架，解决现有框架在灵活性与简洁性之间的权衡问题，集成核心功能如内存、工具和思维树，支持与主流聊天平台无缝集成。", "motivation": "随着大语言模型和多智能体系统的发展，现有代理部署平台在多功能性、鲁棒性和效率方面存在挑战，需要设计更优框架。", "method": "提出LightAgent框架，集成内存（mem0）、工具和思维树（ToT）等核心功能，保持轻量级结构，并开源实现与主流平台集成。", "result": "LightAgent有效解决了灵活性与简洁性的权衡，使开发者能轻松构建自学习代理。", "conclusion": "LightAgent作为开源解决方案，推动了代理AI框架的发展，具有实际部署和应用潜力。"}}
{"id": "2509.09321", "title": "Towards Adaptive ML Benchmarks: Web-Agent-Driven Construction, Domain Expansion, and Metric Optimization", "authors": ["Hangyi Jia", "Yuxi Qian", "Hanwen Tong", "Xinhui Wu", "Lin Chen", "Feng Wei"], "abstract": "Recent advances in large language models (LLMs) have enabled the emergence of general-purpose agents for automating end-to-end machine learning (ML) workflows, including data analysis, feature engineering, model training, and competition solving. However, existing benchmarks remain limited in task coverage, domain diversity, difficulty modeling, and evaluation rigor, failing to capture the full capabilities of such agents in realistic settings. We present TAM Bench, a diverse, realistic, and structured benchmark for evaluating LLM-based agents on end-to-end ML tasks. TAM Bench features three key innovations: (1) A browser automation and LLM-based task acquisition system that automatically collects and structures ML challenges from platforms such as Kaggle, AIcrowd, and Biendata, spanning multiple task types and data modalities (e.g., tabular, text, image, graph, audio); (2) A leaderboard-driven difficulty modeling mechanism that estimates task complexity using participant counts and score dispersion, enabling scalable and objective task calibration; (3) A multi-dimensional evaluation framework incorporating performance, format compliance, constraint adherence, and task generalization. Based on 150 curated AutoML tasks, we construct three benchmark subsets of different sizes -- Lite, Medium, and Full -- designed for varying evaluation scenarios. The Lite version, with 18 tasks and balanced coverage across modalities and difficulty levels, serves as a practical testbed for daily benchmarking and comparative studies.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.09321.pdf", "abstract_url": "https://arxiv.org/abs/2509.09321", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了TAM Bench，一个用于评估基于LLM的代理在端到端机器学习任务上的多样、现实和结构化基准，通过自动任务收集、难度建模和多维评估来克服现有基准的局限性。", "motivation": "现有基准在任务覆盖、领域多样性、难度建模和评估严谨性方面有限，无法全面评估LLM代理在真实环境中的能力。", "method": "使用浏览器自动化和LLM的任务获取系统从平台收集任务，基于排行榜的难度建模机制，以及多维评估框架（包括性能、格式合规、约束遵守和任务泛化）。", "result": "基于150个AutoML任务，构建了三个不同大小的基准子集（Lite、Medium和Full），其中Lite版本包含18个任务，覆盖多种模态和难度级别。", "conclusion": "TAM Bench提供了一个可扩展和客观的基准，用于评估LLM代理，支持日常基准测试和比较研究。"}}
{"id": "2509.09467", "title": "Inteligencia Artificial jurídica y el desafío de la veracidad: análisis de alucinaciones, optimización de RAG y principios para una integración responsable", "authors": ["Alex Dantart"], "abstract": "This technical report analyzes the challenge of \"hallucinations\" (false information) in LLMs applied to law. It examines their causes, manifestations, and the effectiveness of the RAG mitigation strategy, highlighting its limitations and proposing holistic optimizations. The paper explores the ethical and regulatory implications, emphasizing human oversight as an irreplaceable role. It concludes that the solution lies not in incrementally improving generative models, but in adopting a \"consultative\" AI paradigm that prioritizes veracity and traceability, acting as a tool to amplify, not replace, professional judgment.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "in Spanish and English languages", "pdf_url": "https://arxiv.org/pdf/2509.09467.pdf", "abstract_url": "https://arxiv.org/abs/2509.09467", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "分析法律领域大语言模型的幻觉问题，评估RAG缓解策略的有效性和局限性，提出优化和负责任整合原则。", "motivation": "解决法律应用中大语言模型产生虚假信息（幻觉）的问题，确保信息的真实性和可靠性。", "method": "分析幻觉的原因和表现，评估检索增强生成（RAG）策略，并提出整体优化方法和咨询式AI范式。", "result": "RAG策略有局限性，需要人类监督和优先真实性的方法，以增强而非替代专业判断。", "conclusion": "解决方案在于采用咨询式AI范式，强调真实性和可追溯性，结合人类监督进行负责任整合。"}}
{"id": "2509.09356", "title": "Curriculum-Based Multi-Tier Semantic Exploration via Deep Reinforcement Learning", "authors": ["Abdel Hakim Drid", "Vincenzo Suriani", "Daniele Nardi", "Abderrezzak Debilou"], "abstract": "Navigating and understanding complex and unknown environments autonomously demands more than just basic perception and movement from embodied agents. Truly effective exploration requires agents to possess higher-level cognitive abilities, the ability to reason about their surroundings, and make more informed decisions regarding exploration strategies. However, traditional RL approaches struggle to balance efficient exploration and semantic understanding due to limited cognitive capabilities embedded in the small policies for the agents, leading often to human drivers when dealing with semantic exploration. In this paper, we address this challenge by presenting a novel Deep Reinforcement Learning (DRL) architecture that is specifically designed for resource efficient semantic exploration. A key methodological contribution is the integration of a Vision-Language Model (VLM) common-sense through a layered reward function. The VLM query is modeled as a dedicated action, allowing the agent to strategically query the VLM only when deemed necessary for gaining external guidance, thereby conserving resources. This mechanism is combined with a curriculum learning strategy designed to guide learning at different levels of complexity to ensure robust and stable learning. Our experimental evaluation results convincingly demonstrate that our agent achieves significantly enhanced object discovery rates and develops a learned capability to effectively navigate towards semantically rich regions. Furthermore, it also shows a strategic mastery of when to prompt for external environmental information. By demonstrating a practical and scalable method for embedding common-sense semantic reasoning with autonomous agents, this research provides a novel approach to pursuing a fully intelligent and self-guided exploration in robotics.", "subjects": "Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": "The 19th International Conference on Intelligent Autonomous Systems (IAS 19), 2025, Genoa", "pdf_url": "https://arxiv.org/pdf/2509.09356.pdf", "abstract_url": "https://arxiv.org/abs/2509.09356", "categories": ["Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "提出了一种结合课程学习和深度强化学习的新架构，通过分层奖励函数整合视觉语言模型，实现资源高效的语义探索，提高物体发现率和导航能力。", "motivation": "解决传统强化学习方法在平衡高效探索和语义理解方面的不足，由于代理认知能力有限，常需人工干预。", "method": "使用深度强化学习架构，集成视觉语言模型作为专用动作，结合课程学习策略，通过分层奖励函数优化资源使用。", "result": "实验显示代理显著提升物体发现率，学会导航至语义丰富区域，并掌握何时请求外部信息。", "conclusion": "提供了一种实用且可扩展的方法，嵌入常识语义推理，推动机器人完全智能自主探索。"}}
{"id": "2509.09498", "title": "SEDM: Scalable Self-Evolving Distributed Memory for Agents", "authors": ["Haoran Xu", "Jiacong Hu", "Ke Zhang", "Lei Yu", "Yuxin Tang", "Xinyuan Song", "Yiqun Duan", "Lynn Ai", "Bill Shi"], "abstract": "Long-term multi-agent systems inevitably generate vast amounts of trajectories and historical interactions, which makes efficient memory management essential for both performance and scalability. Existing methods typically depend on vector retrieval and hierarchical storage, yet they are prone to noise accumulation, uncontrolled memory expansion, and limited generalization across domains. To address these challenges, we present SEDM, Self-Evolving Distributed Memory, a verifiable and adaptive framework that transforms memory from a passive repository into an active, self-optimizing component. SEDM integrates verifiable write admission based on reproducible replay, a self-scheduling memory controller that dynamically ranks and consolidates entries according to empirical utility, and cross-domain knowledge diffusion that abstracts reusable insights to support transfer across heterogeneous tasks. Evaluations on benchmark datasets demonstrate that SEDM improves reasoning accuracy while reducing token overhead compared with strong memory baselines, and further enables knowledge distilled from fact verification to enhance multi-hop reasoning. The results highlight SEDM as a scalable and sustainable memory mechanism for open-ended multi-agent collaboration. The code will be released in the later stage of this project.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.09498.pdf", "abstract_url": "https://arxiv.org/abs/2509.09498", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "SEDM是一种可扩展的自进化分布式内存框架，通过可验证写入、动态调度和跨域知识扩散，提升多智能体系统的记忆管理和泛化能力，减少噪声和开销。", "motivation": "解决多智能体系统中长期轨迹和交互导致的内存管理问题，如噪声积累、内存膨胀和跨域泛化受限。", "method": "集成可验证写入、自调度内存控制器和跨域知识扩散，将记忆从被动存储转变为主动自优化组件。", "result": "在基准数据集上，SEDM提高了推理准确性，减少了token开销，并支持从事实验证中提取知识以增强多跳推理。", "conclusion": "SEDM是开放多智能体协作中可扩展且可持续的记忆机制，具有实际应用潜力。"}}
{"id": "2509.09560", "title": "Boosting Embodied AI Agents through Perception-Generation Disaggregation and Asynchronous Pipeline Execution", "authors": ["Shulai Zhang", "Ao Xu", "Quan Chen", "Han Zhao", "Weihao Cui", "Ningxin Zheng", "Haibin Lin", "Xin Liu", "Minyi Guo"], "abstract": "Embodied AI systems operate in dynamic environments, requiring seamless integration of perception and generation modules to process high-frequency input and output demands. Traditional sequential computation patterns, while effective in ensuring accuracy, face significant limitations in achieving the necessary \"thinking\" frequency for real-world applications. In this work, we present Auras, an algorithm-system co-designed inference framework to optimize the inference frequency of embodied AI agents. Auras disaggregates the perception and generation and provides controlled pipeline parallelism for them to achieve high and stable throughput. Faced with the data staleness problem that appears when the parallelism is increased, Auras establishes a public context for perception and generation to share, thereby promising the accuracy of embodied agents. Experimental results show that Auras improves throughput by 2.54x on average while achieving 102.7% of the original accuracy, demonstrating its efficacy in overcoming the constraints of sequential computation and providing high throughput.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.09560.pdf", "abstract_url": "https://arxiv.org/abs/2509.09560", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出Auras框架，通过解耦感知与生成模块并采用异步流水线执行，提升具身AI代理的推理频率和吞吐量，同时保持准确性。", "motivation": "解决传统顺序计算模式在动态环境中无法满足高频率输入输出需求的问题，以提高具身AI系统的实时性能。", "method": "使用算法-系统协同设计，解耦感知和生成模块，引入受控流水线并行和共享公共上下文来避免数据陈旧问题。", "result": "实验显示吞吐量平均提升2.54倍，准确率达到原系统的102.7%，证明框架有效。", "conclusion": "Auras框架成功克服顺序计算限制，提供高吞吐量，适用于实时具身AI应用。"}}
{"id": "2509.09677", "title": "The Illusion of Diminishing Returns: Measuring Long Horizon Execution in LLMs", "authors": ["Akshit Sinha", "Arvindh Arun", "Shashwat Goel", "Steffen Staab", "Jonas Geiping"], "abstract": "Does continued scaling of large language models (LLMs) yield diminishing returns? Real-world value often stems from the length of task an agent can complete. We start this work by observing the simple but counterintuitive fact that marginal gains in single-step accuracy can compound into exponential improvements in the length of a task a model can successfully complete. Then, we argue that failures of LLMs when simple tasks are made longer arise from mistakes in execution, rather than an inability to reason. We propose isolating execution capability, by explicitly providing the knowledge and plan needed to solve a long-horizon task. We find that larger models can correctly execute significantly more turns even when small models have 100\\% single-turn accuracy. We observe that the per-step accuracy of models degrades as the number of steps increases. This is not just due to long-context limitations -- curiously, we observe a self-conditioning effect -- models become more likely to make mistakes when the context contains their errors from prior turns. Self-conditioning does not reduce by just scaling the model size. In contrast, recent thinking models do not self-condition, and can also execute much longer tasks in a single turn. We conclude by benchmarking frontier thinking models on the length of task they can execute in a single turn. Overall, by focusing on the ability to execute, we hope to reconcile debates on how LLMs can solve complex reasoning problems yet fail at simple tasks when made longer, and highlight the massive benefits of scaling model size and sequential test-time compute for long-horizon tasks.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.09677.pdf", "abstract_url": "https://arxiv.org/abs/2509.09677", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨大型语言模型（LLM）在长任务执行中的表现，发现单步准确性的微小提升可带来任务长度的指数级改善，但执行错误和自条件效应限制性能，强调模型规模和顺序计算的重要性。", "motivation": "解决LLM在简单任务延长时失败的问题，质疑规模扩展是否带来收益递减，并强调执行能力而非推理能力是关键。", "method": "通过提供知识和计划隔离执行能力，比较不同大小模型在长任务中的表现，并分析自条件效应和思考模型。", "result": "大模型能执行更多步骤，但每步准确性随步骤增加而下降，自条件效应不随规模减小，思考模型无此问题且能执行更长任务。", "conclusion": "聚焦执行能力可调和LLM在复杂推理与简单长任务间的矛盾，突显模型规模和顺序计算对长任务的大益处。"}}
{"id": "2509.08835", "title": "Deep opacity and AI: A threat to XAI and to privacy protection mechanisms", "authors": ["Vincent C. Müller"], "abstract": "It is known that big data analytics and AI pose a threat to privacy, and that some of this is due to some kind of \"black box problem\" in AI. I explain how this becomes a problem in the context of justification for judgments and actions. Furthermore, I suggest distinguishing three kinds of opacity: 1) the subjects do not know what the system does (\"shallow opacity\"), 2) the analysts do not know what the system does (\"standard black box opacity\"), or 3) the analysts cannot possibly know what the system might do (\"deep opacity\"). If the agents, data subjects as well as analytics experts, operate under opacity, then these agents cannot provide justifications for judgments that are necessary to protect privacy, e.g., they cannot give \"informed consent\", or guarantee \"anonymity\". It follows from these points that agents in big data analytics and AI often cannot make the judgments needed to protect privacy. So I conclude that big data analytics makes the privacy problems worse and the remedies less effective. As a positive note, I provide a brief outlook on technical ways to handle this situation.", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.08835.pdf", "abstract_url": "https://arxiv.org/abs/2509.08835", "categories": ["Computers and Society (cs.CY)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了大数据分析和AI中的不透明性如何加剧隐私威胁，区分了三种不透明类型，并指出这阻碍了隐私保护所需的判断和理由提供。", "motivation": "解决AI和大数据分析中的'黑盒问题'对隐私保护的负面影响，特别是在提供判断理由方面的挑战。", "method": "通过概念分析区分三种不透明性（浅层、标准黑盒、深层），并讨论其对隐私保护机制的影响。", "result": "发现不透明性导致数据主体和分析专家无法提供必要的隐私保护理由，如知情同意或匿名保证。", "conclusion": "大数据分析和AI恶化了隐私问题并削弱了补救措施的有效性，但提供了技术应对的展望。"}}
{"id": "2509.09629", "title": "Bridging the Capability Gap: Joint Alignment Tuning for Harmonizing LLM-based Multi-Agent Systems", "authors": ["Minghang Zhu", "Zhengliang Shi", "Zhiwei Xu", "Shiguang Wu", "Lingjie Wang", "Pengjie Ren", "Zhaochun Ren", "Zhumin Chen"], "abstract": "The advancement of large language models (LLMs) has enabled the construction of multi-agent systems to solve complex tasks by dividing responsibilities among specialized agents, such as a planning agent for subgoal generation and a grounding agent for executing tool-use actions. Most existing methods typically fine-tune these agents independently, leading to capability gaps among them with poor coordination. To address this, we propose MOAT, a Multi-Agent Joint Alignment Tuning framework that improves agents collaboration through iterative alignment. MOAT alternates between two key stages: (1) Planning Agent Alignment, which optimizes the planning agent to generate subgoal sequences that better guide the grounding agent; and (2) Grounding Agent Improving, which fine-tunes the grounding agent using diverse subgoal-action pairs generated by the agent itself to enhance its generalization capablity. Theoretical analysis proves that MOAT ensures a non-decreasing and progressively convergent training process. Experiments across six benchmarks demonstrate that MOAT outperforms state-of-the-art baselines, achieving average improvements of 3.1% on held-in tasks and 4.4% on held-out tasks.", "subjects": "Computation and Language (cs.CL)", "comments": "EMNLP 2025 Findings", "pdf_url": "https://arxiv.org/pdf/2509.09629.pdf", "abstract_url": "https://arxiv.org/abs/2509.09629", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "MOAT框架通过联合对齐调优，提升多智能体LLM系统的协作能力，在多个基准测试中优于现有方法。", "motivation": "解决独立微调智能体导致能力差距和协调差的问题。", "method": "使用迭代对齐，交替优化规划智能体和接地智能体。", "result": "在held-in任务上平均提升3.1%，held-out任务上提升4.4%。", "conclusion": "MOAT确保训练过程收敛，有效改善多智能体系统的性能。"}}
{"id": "2509.08859", "title": "Multi Robot Coordination in Highly Dynamic Environments: Tackling Asymmetric Obstacles and Limited Communication", "authors": ["Vincenzo Suriani", "Daniele Affinita", "Domenico D. Bloisi", "Daniele Nardi"], "abstract": "Coordinating a fully distributed multi-agent system (MAS) can be challenging when the communication channel has very limited capabilities in terms of sending rate and packet payload. When the MAS has to deal with active obstacles in a highly partially observable environment, the communication channel acquires considerable relevance. In this paper, we present an approach to deal with task assignments in extremely active scenarios, where tasks need to be frequently reallocated among the agents participating in the coordination process. Inspired by market-based task assignments, we introduce a novel distributed coordination method to orchestrate autonomous agents' actions efficiently in low communication scenarios. In particular, our algorithm takes into account asymmetric obstacles. While in the real world, the majority of obstacles are asymmetric, they are usually treated as symmetric ones, thus limiting the applicability of existing methods. To summarize, the presented architecture is designed to tackle scenarios where the obstacles are active and asymmetric, the communication channel is poor and the environment is partially observable. Our approach has been validated in simulation and in the real world, using a team of NAO robots during official RoboCup competitions. Experimental results show a notable reduction in task overlaps in limited communication settings, with a decrease of 52% in the most frequent reallocated task.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": "The 19th International Conference on Intelligent Autonomous Systems (IAS 19), 2025, Genoa", "pdf_url": "https://arxiv.org/pdf/2509.08859.pdf", "abstract_url": "https://arxiv.org/abs/2509.08859", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种分布式多机器人协调方法，用于处理高度动态环境中的不对称障碍和有限通信问题，通过市场启发式任务分配减少任务重叠。", "motivation": "解决在通信受限、环境部分可观测且存在主动不对称障碍的情况下，多智能体系统的任务分配和协调挑战。", "method": "基于市场启发式的分布式协调算法，考虑不对称障碍，优化任务重新分配。", "result": "在仿真和真实NAO机器人实验中，任务重叠显著减少52%，验证了方法的有效性。", "conclusion": "该方法能有效提升多机器人系统在动态环境中的协调效率，适用于RoboCup等实际应用。"}}
{"id": "2509.09594", "title": "ObjectReact: Learning Object-Relative Control for Visual Navigation", "authors": ["Sourav Garg", "Dustin Craggs", "Vineeth Bhat", "Lachlan Mares", "Stefan Podgorski", "Madhava Krishna", "Feras Dayoub", "Ian Reid"], "abstract": "Visual navigation using only a single camera and a topological map has recently become an appealing alternative to methods that require additional sensors and 3D maps. This is typically achieved through an \"image-relative\" approach to estimating control from a given pair of current observation and subgoal image. However, image-level representations of the world have limitations because images are strictly tied to the agent's pose and embodiment. In contrast, objects, being a property of the map, offer an embodiment- and trajectory-invariant world representation. In this work, we present a new paradigm of learning \"object-relative\" control that exhibits several desirable characteristics: a) new routes can be traversed without strictly requiring to imitate prior experience, b) the control prediction problem can be decoupled from solving the image matching problem, and c) high invariance can be achieved in cross-embodiment deployment for variations across both training-testing and mapping-execution settings. We propose a topometric map representation in the form of a \"relative\" 3D scene graph, which is used to obtain more informative object-level global path planning costs. We train a local controller, dubbed \"ObjectReact\", conditioned directly on a high-level \"WayObject Costmap\" representation that eliminates the need for an explicit RGB input. We demonstrate the advantages of learning object-relative control over its image-relative counterpart across sensor height variations and multiple navigation tasks that challenge the underlying spatial understanding capability, e.g., navigating a map trajectory in the reverse direction. We further show that our sim-only policy is able to generalize well to real-world indoor environments. Code and supplementary material are accessible via project page:", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Systems and Control (eess.SY)", "comments": "CoRL 2025; 23 pages including appendix", "pdf_url": "https://arxiv.org/pdf/2509.09594.pdf", "abstract_url": "https://arxiv.org/abs/2509.09594", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)", "Machine Learning (cs.LG)", "Systems and Control (eess.SY)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出ObjectReact方法，通过对象相对控制学习视觉导航，利用拓扑图和3D场景图实现高不变性和泛化能力。", "motivation": "解决图像相对导航方法因图像与代理姿态绑定而导致的局限性，如泛化能力差和需要模仿先验经验的问题。", "method": "使用对象级表示和相对3D场景图进行全局路径规划，训练基于WayObject Costmap的本地控制器，无需RGB输入。", "result": "在传感器高度变化和反向导航等任务中优于图像相对方法，仿真策略能泛化到真实室内环境。", "conclusion": "对象相对控制提供更鲁棒和可泛化的视觉导航，减少对先验经验的依赖，并支持跨部署设置。"}}
{"id": "2509.09265", "title": "Harnessing Uncertainty: Entropy-Modulated Policy Gradients for Long-Horizon LLM Agents", "authors": ["Jiawei Wang", "Jiacai Liu", "Yuqian Fu", "Yingru Li", "Xintao Wang", "Yuan Lin", "Yu Yue", "Lin Zhang", "Yang Wang", "Ke Wang"], "abstract": "In long-horizon tasks, recent agents based on Large Language Models (LLMs) face a significant challenge that sparse, outcome-based rewards make it difficult to assign credit to intermediate steps. Previous methods mainly focus on creating dense reward signals to guide learning, either through traditional reinforcement learning techniques like inverse reinforcement learning or by using Process Reward Models for step-by-step feedback. In this paper, we identify a fundamental problem in the learning dynamics of LLMs: the magnitude of policy gradients is inherently coupled with the entropy, which leads to inefficient small updates for confident correct actions and potentially destabilizes large updates for uncertain ones. To resolve this, we propose Entropy-Modulated Policy Gradients (EMPG), a framework that re-calibrates the learning signal based on step-wise uncertainty and the final task outcome. EMPG amplifies updates for confident correct actions, penalizes confident errors, and attenuates updates from uncertain steps to stabilize exploration. We further introduce a bonus term for future clarity that encourages agents to find more predictable solution paths. Through comprehensive experiments on three challenging agent tasks, WebShop, ALFWorld, and Deep Search, we demonstrate that EMPG achieves substantial performance gains and significantly outperforms strong policy gradient baselines. Project page is at", "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL)", "comments": "ICLR 2026 Under review", "pdf_url": "https://arxiv.org/pdf/2509.09265.pdf", "abstract_url": "https://arxiv.org/abs/2509.09265", "categories": ["Machine Learning (cs.LG)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出熵调制策略梯度（EMPG）框架，通过基于不确定性和任务结果重新校准学习信号，解决长视野任务中稀疏奖励导致的信用分配问题，并在实验中显著提升性能。", "motivation": "解决基于大型语言模型的智能体在长视野任务中，由于稀疏、基于结果的奖励难以对中间步骤分配信用的问题。", "method": "使用熵调制策略梯度（EMPG）框架，基于步骤不确定性和最终任务结果重新校准学习信号，包括放大自信正确动作的更新、惩罚自信错误，并引入未来清晰度奖励项。", "result": "在WebShop、ALFWorld和Deep Search等任务上，EMPG实现了显著性能提升，优于强策略梯度基线方法。", "conclusion": "EMPG通过调制学习信号稳定探索并提升效率，为长视野任务中的智能体学习提供了有效解决方案。"}}
{"id": "2509.09651", "title": "Retrieval-Augmented Generation for Reliable Interpretation of Radio Regulations", "authors": ["Zakaria El Kassimi", "Fares Fourati", "Mohamed-Slim Alouini"], "abstract": "We study question answering in the domain of radio regulations, a legally sensitive and high-stakes area. We propose a telecom-specific Retrieval-Augmented Generation (RAG) pipeline and introduce, to our knowledge, the first multiple-choice evaluation set for this domain, constructed from authoritative sources using automated filtering and human validation. To assess retrieval quality, we define a domain-specific retrieval metric, under which our retriever achieves approximately 97% accuracy. Beyond retrieval, our approach consistently improves generation accuracy across all tested models. In particular, while naively inserting documents without structured retrieval yields only marginal gains for GPT-4o (less than 1%), applying our pipeline results in nearly a 12% relative improvement. These findings demonstrate that carefully targeted grounding provides a simple yet strong baseline and an effective domain-specific solution for regulatory question answering. All code and evaluation scripts, along with our derived question-answer dataset, are available at", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Signal Processing (eess.SP)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.09651.pdf", "abstract_url": "https://arxiv.org/abs/2509.09651", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)", "Signal Processing (eess.SP)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种针对无线电法规的检索增强生成（RAG）管道，通过特定领域检索和评估集，显著提高了生成准确性。", "motivation": "解决无线电法规领域高敏感和高风险问题中的问答可靠性问题。", "method": "使用电信特定RAG管道，包括自动化过滤和人工验证构建评估集，并定义领域特定检索指标。", "result": "检索器准确率约97%，RAG管道使GPT-4o生成准确性相对提升近12%。", "conclusion": "针对性地提供基础信息是简单有效的领域特定解决方案，代码和数据集已公开。"}}
{"id": "2509.09208", "title": "Incentivizing Safer Actions in Policy Optimization for Constrained Reinforcement Learning", "authors": ["Somnath Hazra", "Pallab Dasgupta", "Soumyajit Dey"], "abstract": "Constrained Reinforcement Learning (RL) aims to maximize the return while adhering to predefined constraint limits, which represent domain-specific safety requirements. In continuous control settings, where learning agents govern system actions, balancing the trade-off between reward maximization and constraint satisfaction remains a significant challenge. Policy optimization methods often exhibit instability near constraint boundaries, resulting in suboptimal training performance. To address this issue, we introduce a novel approach that integrates an adaptive incentive mechanism in addition to the reward structure to stay within the constraint bound before approaching the constraint boundary. Building on this insight, we propose Incrementally Penalized Proximal Policy Optimization (IP3O), a practical algorithm that enforces a progressively increasing penalty to stabilize training dynamics. Through empirical evaluation on benchmark environments, we demonstrate the efficacy of IP3O compared to the performance of state-of-the-art Safe RL algorithms. Furthermore, we provide theoretical guarantees by deriving a bound on the worst-case error of the optimality achieved by our algorithm.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "11 pages, Accepted to the 34th International Joint Conference on Artificial Intelligence (IJCAI) 2025, Main Track", "pdf_url": "https://arxiv.org/pdf/2509.09208.pdf", "abstract_url": "https://arxiv.org/abs/2509.09208", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种在约束强化学习中激励更安全行动的新方法，通过自适应激励机制和逐步增加的惩罚来稳定训练，并在基准环境中验证了其优于现有算法的性能。", "motivation": "解决在连续控制设置中，策略优化方法在约束边界附近的不稳定性问题，以平衡奖励最大化和约束满足之间的权衡。", "method": "引入自适应激励机制，并基于此提出增量惩罚近端策略优化（IP3O）算法，逐步增加惩罚以稳定训练动态。", "result": "在基准环境中的实证评估显示，IP3O在性能上优于最先进的安全强化学习算法，并提供了理论保证，推导了算法最优性的最坏情况误差界限。", "conclusion": "该方法有效提升了约束强化学习的训练稳定性和性能，具有理论和实践意义。"}}
{"id": "2509.09219", "title": "Vejde: A Framework for Inductive Deep Reinforcement Learning Based on Factor Graph Color Refinement", "authors": ["Jakob Nyberg", "Pontus Johnson"], "abstract": "We present and evaluate Vejde; a framework which combines data abstraction, graph neural networks and reinforcement learning to produce inductive policy functions for decision problems with richly structured states, such as object classes and relations. MDP states are represented as data bases of facts about entities, and Vejde converts each state to a bipartite graph, which is mapped to latent states through neural message passing. The factored representation of both states and actions allows Vejde agents to handle problems of varying size and structure. We tested Vejde agents on eight problem domains defined in RDDL, with ten problem instances each, where policies were trained using both supervised and reinforcement learning. To test policy generalization, we separate problem instances in two sets, one for training and the other solely for testing. Test results on unseen instances for the Vejde agents were compared to MLP agents trained on each problem instance, as well as the online planning algorithm Prost. Our results show that Vejde policies in average generalize to the test instances without a significant loss in score. Additionally, the inductive agents received scores on unseen test instances that on average were close to the instance-specific MLP agents.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.09219.pdf", "abstract_url": "https://arxiv.org/abs/2509.09219", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "Vejde是一个结合数据抽象、图神经网络和强化学习的框架，用于为具有结构化状态的决策问题生成归纳策略函数，并在多个领域测试中显示出良好的泛化能力。", "motivation": "解决在具有丰富结构化状态（如对象类和关系）的决策问题中，如何生成能够泛化到不同大小和结构问题的归纳策略函数的问题。", "method": "使用数据抽象将MDP状态转换为二分图，通过神经网络消息传递映射到潜在状态，并结合监督和强化学习训练策略。", "result": "在RDDL定义的八个问题域中，Vejde代理在未见实例上的得分与实例特定MLP代理相近，且泛化性能优于在线规划算法Prost。", "conclusion": "Vejde框架能有效处理可变大小和结构的决策问题，其归纳策略在泛化方面表现优异，具有实际应用潜力。"}}
