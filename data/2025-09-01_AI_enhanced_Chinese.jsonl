{"id": "2508.21137", "title": "How Does Cognitive Bias Affect Large Language Models? A Case Study on the Anchoring Effect in Price Negotiation Simulations", "authors": ["Yoshiki Takenami", "Yin Jou Huang", "Yugo Murawaki", "Chenhui Chu"], "abstract": "Cognitive biases, well-studied in humans, can also be observed in LLMs, affecting their reliability in real-world applications. This paper investigates the anchoring effect in LLM-driven price negotiations. To this end, we instructed seller LLM agents to apply the anchoring effect and evaluated negotiations using not only an objective metric but also a subjective metric. Experimental results show that LLMs are influenced by the anchoring effect like humans. Additionally, we investigated the relationship between the anchoring effect and factors such as reasoning and personality. It was shown that reasoning models are less prone to the anchoring effect, suggesting that the long chain of thought mitigates the effect. However, we found no significant correlation between personality traits and susceptibility to the anchoring effect. These findings contribute to a deeper understanding of cognitive biases in LLMs and to the realization of safe and responsible application of LLMs in society.", "subjects": "Computation and Language (cs.CL)", "comments": "work in progress", "pdf_url": "https://arxiv.org/pdf/2508.21137.pdf", "abstract_url": "https://arxiv.org/abs/2508.21137", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究了大型语言模型（LLMs）在价格谈判模拟中的锚定效应，发现LLMs像人类一样易受影响，推理能力可减轻效应，但人格特质无显著关联。", "motivation": "解决LLMs中认知偏见（如锚定效应）影响可靠性的问题，以促进其安全和社会应用。", "method": "通过指令卖家LLM代理应用锚定效应，并使用客观和主观指标评估谈判，分析推理和人格因素的影响。", "result": "LLMs受锚定效应影响，推理模型更不易受影响，但人格特质无相关性。", "conclusion": "研究加深了对LLMs认知偏见的理解，强调了推理在减轻偏见中的作用，有助于实现LLMs的安全和负责任应用。"}}
{"id": "2508.21767", "title": "UItron: Foundational GUI Agent with Advanced Perception and Planning", "authors": ["Zhixiong Zeng", "Jing Huang", "Liming Zheng", "Wenkang Han", "Yufeng Zhong", "Lei Chen", "Longrong Yang", "Yingjie Chu", "Yuzhi He", "Lin Ma"], "abstract": "GUI agent aims to enable automated operations on Mobile/PC devices, which is an important task toward achieving artificial general intelligence. The rapid advancement of VLMs accelerates the development of GUI agents, owing to their powerful capabilities in visual understanding and task planning. However, building a GUI agent remains a challenging task due to the scarcity of operation trajectories, the availability of interactive infrastructure, and the limitation of initial capabilities in foundation models. In this work, we introduce UItron, an open-source foundational model for automatic GUI agents, featuring advanced GUI perception, grounding, and planning capabilities. UItron highlights the necessity of systemic data engineering and interactive infrastructure as foundational components for advancing GUI agent development. It not only systematically studies a series of data engineering strategies to enhance training effects, but also establishes an interactive environment connecting both Mobile and PC devices. In training, UItron adopts supervised finetuning over perception and planning tasks in various GUI scenarios, and then develop a curriculum reinforcement learning framework to enable complex reasoning and exploration for online environments. As a result, UItron achieves superior performance in benchmarks of GUI perception, grounding, and planning. In particular, UItron highlights the interaction proficiency with top-tier Chinese mobile APPs, as we identified a general lack of Chinese capabilities even in state-of-the-art solutions. To this end, we manually collect over one million steps of operation trajectories across the top 100 most popular apps, and build the offline and online agent evaluation environments. Experimental results demonstrate that UItron achieves significant progress in Chinese app scenarios, propelling GUI agents one step closer to real-world application.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "24 pages", "pdf_url": "https://arxiv.org/pdf/2508.21767.pdf", "abstract_url": "https://arxiv.org/abs/2508.21767", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "UItron是一个开源的基础GUI代理模型，通过先进感知和规划能力，结合数据工程和交互基础设施，在移动和PC设备上实现自动化操作，尤其在中文应用场景中表现卓越。", "motivation": "解决GUI代理开发中操作轨迹稀缺、交互基础设施不足以及基础模型初始能力限制的问题，推动人工通用智能的实现。", "method": "采用监督微调感知和规划任务，结合课程强化学习框架，进行系统性数据工程和建立移动与PC设备的交互环境。", "result": "在GUI感知、接地和规划基准测试中取得优异性能，特别是在中文移动应用场景中显著进步，收集了超过百万步操作轨迹并构建评估环境。", "conclusion": "UItron展示了系统性方法和基础设施对GUI代理发展的必要性，推动其在真实世界应用中的进展。"}}
{"id": "2508.21148", "title": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers", "authors": ["Ming Hu", "Chenglong Ma", "Wei Li", "Wanghan Xu", "Jiamin Wu", "Jucheng Hu", "Tianbin Li", "Guohang Zhuang", "Jiaqi Liu", "Yingzhou Lu", "Ying Chen", "Chaoyang Zhang", "Cheng Tan", "Jie Ying", "Guocheng Wu", "Shujian Gao", "Pengcheng Chen", "Jiashi Lin", "Haitao Wu", "Lulu Chen", "Fengxiang Wang", "Yuanyuan Zhang", "Xiangyu Zhao", "Feilong Tang", "Encheng Su", "Junzhi Ning", "Xinyao Liu", "Ye Du", "Changkai Ji", "Cheng Tang", "Huihui Xu", "Ziyang Chen", "Ziyan Huang", "Jiyao Liu", "Pengfei Jiang", "Yizhou Wang", "Chen Tang", "Jianyu Wu", "Yuchen Ren", "Siyuan Yan", "Zhonghua Wang", "Zhongxing Xu", "Shiyan Su", "Shangquan Sun", "Runkai Zhao", "Zhisheng Zhang", "Yu Liu", "Fudi Wang", "Yuanfeng Ji", "Yanzhou Su", "Hongming Shan", "Chunmei Feng", "Jiahao Xu", "Jiangtao Yan", "Wenhao Tang", "Diping Song", "Lihao Liu", "Yanyan Huang", "Lequan Yu", "Bin Fu", "Shujun Wang", "Xiaomeng Li", "Xiaowei Hu", "Yun Gu", "Ben Fei", "Zhongying Deng", "Benyou Wang", "Yuewen Cao", "Minjie Shen", "Haodong Duan", "Jie Xu", "Yirong Chen", "Fang Yan", "Hongxia Hao", "Jielan Li", "Jiajun Du", "Yanbo Wang", "Imran Razzak", "Chi Zhang", "Lijun Wu", "Conghui He", "Zhaohui Lu", "Jinhai Huang", "Yihao Liu", "Fenghua Ling", "Yuqiang Li", "Aoran Wang", "Qihao Zheng", "Nanqing Dong", "Tianfan Fu", "Dongzhan Zhou", "Yan Lu", "Wenlong Zhang", "Jin Ye", "Jianfei Cai", "Wanli Ouyang", "Yu Qiao", "Zongyuan Ge", "Shixiang Tang", "Junjun He"], "abstract": "Scientific Large Language Models (Sci-LLMs) are transforming how knowledge is represented, integrated, and applied in scientific research, yet their progress is shaped by the complex nature of scientific data. This survey presents a comprehensive, data-centric synthesis that reframes the development of Sci-LLMs as a co-evolution between models and their underlying data substrate. We formulate a unified taxonomy of scientific data and a hierarchical model of scientific knowledge, emphasizing the multimodal, cross-scale, and domain-specific challenges that differentiate scientific corpora from general natural language processing datasets. We systematically review recent Sci-LLMs, from general-purpose foundations to specialized models across diverse scientific disciplines, alongside an extensive analysis of over 270 pre-/post-training datasets, showing why Sci-LLMs pose distinct demands -- heterogeneous, multi-scale, uncertainty-laden corpora that require representations preserving domain invariance and enabling cross-modal reasoning. On evaluation, we examine over 190 benchmark datasets and trace a shift from static exams toward process- and discovery-oriented assessments with advanced evaluation protocols. These data-centric analyses highlight persistent issues in scientific data development and discuss emerging solutions involving semi-automated annotation pipelines and expert validation. Finally, we outline a paradigm shift toward closed-loop systems where autonomous agents based on Sci-LLMs actively experiment, validate, and contribute to a living, evolving knowledge base. Collectively, this work provides a roadmap for building trustworthy, continually evolving artificial intelligence (AI) systems that function as a true partner in accelerating scientific discovery.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.21148.pdf", "abstract_url": "https://arxiv.org/abs/2508.21148", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本论文全面综述了科学大语言模型（Sci-LLMs）的发展，强调数据与模型的协同进化，提出统一的数据分类和知识层次模型，并探讨从静态评估到闭环代理系统的范式转变，旨在加速科学发现。", "motivation": "解决科学数据复杂、多模态、跨尺度等挑战，以改进Sci-LLMs在科学研究和知识整合中的应用。", "method": "采用数据中心的综合方法，包括统一数据分类、知识层次模型构建、系统回顾Sci-LLMs和数据集分析，以及评估基准和新兴解决方案的讨论。", "result": "分析显示Sci-LLMs需要处理异构、多尺度、不确定的数据，并识别评估向过程导向的转变，提出了半自动化标注和专家验证等解决方案。", "conclusion": "Sci-LLMs有望通过闭环代理系统成为可信赖的AI伙伴，加速科学发现，但需持续解决数据开发问题。"}}
{"id": "2508.21184", "title": "BED-LLM: Intelligent Information Gathering with LLMs and Bayesian Experimental Design", "authors": ["Deepro Choudhury", "Sinead Williamson", "Adam Goliński", "Ning Miao", "Freddie Bickford Smith", "Michael Kirchhof", "Yizhe Zhang", "Tom Rainforth"], "abstract": "We propose a general-purpose approach for improving the ability of Large Language Models (LLMs) to intelligently and adaptively gather information from a user or other external source using the framework of sequential Bayesian experimental design (BED). This enables LLMs to act as effective multi-turn conversational agents and interactively interface with external environments. Our approach, which we call BED-LLM (Bayesian Experimental Design with Large Language Models), is based on iteratively choosing questions or queries that maximize the expected information gain (EIG) about the task of interest given the responses gathered previously. We show how this EIG can be formulated in a principled way using a probabilistic model derived from the LLM's belief distribution and provide detailed insights into key decisions in its construction. Further key to the success of BED-LLM are a number of specific innovations, such as a carefully designed estimator for the EIG, not solely relying on in-context updates for conditioning on previous responses, and a targeted strategy for proposing candidate queries. We find that BED-LLM achieves substantial gains in performance across a wide range of tests based on the 20-questions game and using the LLM to actively infer user preferences, compared to direct prompting of the LLM and other adaptive design strategies.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.21184.pdf", "abstract_url": "https://arxiv.org/abs/2508.21184", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (stat.ML)"], "matching_keywords": ["agent"], "AI": {"tldr": "提出BED-LLM方法，结合LLM和贝叶斯实验设计，通过最大化信息增益选择查询，提升多轮对话和信息收集性能。", "motivation": "解决LLM在智能自适应信息收集中的不足，使其能更有效地作为对话代理与外部环境交互。", "method": "基于序列贝叶斯实验设计，迭代选择最大化期望信息增益的查询，使用概率模型和特定创新如EIG估计器。", "result": "在20问题游戏和用户偏好推断测试中，性能显著优于直接提示和其他自适应策略。", "conclusion": "BED-LLM是提升LLM信息收集能力的有效方法，具有广泛的应用潜力。"}}
{"id": "2508.21238", "title": "Addressing accuracy and hallucination of LLMs in Alzheimer's disease research through knowledge graphs", "authors": ["Tingxuan Xu", "Jiarui Feng", "Justin Melendez", "Kaleigh Roberts", "Donghong Cai", "Mingfang Zhu", "Donald Elbert", "Yixin Chen", "Randall J. Bateman"], "abstract": "In the past two years, large language model (LLM)-based chatbots, such as ChatGPT, have revolutionized various domains by enabling diverse task completion and question-answering capabilities. However, their application in scientific research remains constrained by challenges such as hallucinations, limited domain-specific knowledge, and lack of explainability or traceability for the response. Graph-based Retrieval-Augmented Generation (GraphRAG) has emerged as a promising approach to improving chatbot reliability by integrating domain-specific contextual information before response generation, addressing some limitations of standard LLMs. Despite its potential, there are only limited studies that evaluate GraphRAG on specific domains that require intensive knowledge, like Alzheimer's disease or other biomedical domains. In this paper, we assess the quality and traceability of two popular GraphRAG systems. We compile a database of 50 papers and 70 expert questions related to Alzheimer's disease, construct a GraphRAG knowledge base, and employ GPT-4o as the LLM for answering queries. We then compare the quality of responses generated by GraphRAG with those from a standard GPT-4o model. Additionally, we discuss and evaluate the traceability of several Retrieval-Augmented Generation (RAG) and GraphRAG systems. Finally, we provide an easy-to-use interface with a pre-built Alzheimer's disease database for researchers to test the performance of both standard RAG and GraphRAG.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.21238.pdf", "abstract_url": "https://arxiv.org/abs/2508.21238", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "评估GraphRAG系统在阿尔茨海默病研究中的准确性和可追溯性，通过构建知识库和比较GPT-4o响应，提供用户界面。", "motivation": "解决LLM在科学研究中的幻觉、知识局限和可解释性问题，特别是在阿尔茨海默病等专业领域。", "method": "使用GraphRAG集成领域知识，编译50篇论文和70个专家问题，构建知识库，并用GPT-4o比较标准模型和GraphRAG的响应。", "result": "GraphRAG可能提高响应质量和可追溯性，但需进一步评估具体性能。", "conclusion": "GraphRAG有潜力增强LLM在生物医学应用中的可靠性，提供可访问工具供研究者测试。"}}
{"id": "2508.21307", "title": "MultiFluxAI Enhancing Platform Engineering with Advanced Agent-Orchestrated Retrieval Systems", "authors": ["Sri Ram Macharla", "Sridhar Murthy J", "Anjaneyulu Pasala"], "abstract": "MultiFluxAI is an innovative AI platform developed to address the challenges of managing and integrating vast, disparate data sources in product engineering across application domains. It addresses both current and new service related queries that enhance user engagement in the digital ecosystem. This platform leverages advanced AI techniques, such as Generative AI, vectorization, and agentic orchestration to provide dynamic and context-aware responses to complex user queries.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "Abstract accepted for presentation at ACM ISEC 2025", "pdf_url": "https://arxiv.org/pdf/2508.21307.pdf", "abstract_url": "https://arxiv.org/abs/2508.21307", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "MultiFluxAI是一个创新的AI平台，旨在通过高级代理编排检索系统增强平台工程，解决管理和集成大量不同数据源的挑战，利用生成AI、向量化和代理编排技术提供动态、上下文感知的响应。", "motivation": "解决产品工程中管理和集成庞大、不同数据源的挑战，以增强数字生态系统中的用户参与度。", "method": "利用生成AI、向量化和代理编排等先进AI技术，构建动态和上下文感知的检索系统。", "result": "平台能够处理当前和新服务相关查询，提供改进的用户响应和参与。", "conclusion": "MultiFluxAI通过先进AI方法有效提升数据集成和查询处理能力，具有广泛的应用潜力。"}}
{"id": "2508.21365", "title": "Think in Games: Learning to Reason in Games via Reinforcement Learning with Large Language Models", "authors": ["Yi Liao", "Yu Gu", "Yuan Sui", "Zining Zhu", "Yifan Lu", "Guohua Tang", "Zhongqian Sun", "Wei Yang"], "abstract": "Large language models (LLMs) excel at complex reasoning tasks such as mathematics and coding, yet they frequently struggle with simple interactive tasks that young children perform effortlessly. This discrepancy highlights a critical gap between declarative knowledge (knowing about something) and procedural knowledge (knowing how to do something). Although traditional reinforcement learning (RL) agents can acquire procedural knowledge through environmental interaction, they often operate as black boxes and require substantial training data. In contrast, LLMs possess extensive world knowledge and reasoning capabilities, but are unable to effectively convert this static knowledge into dynamic decision-making in interactive settings. To address this challenge, we propose Think in Games (TiG), a novel framework that empowers LLMs to develop procedural understanding through direct interaction with game environments, while retaining their inherent reasoning and explanatory abilities. Specifically, TiG reformulates RL-based decision-making as a language modeling task: LLMs generate language-guided policies, which are refined iteratively through online reinforcement learning based on environmental feedback. Our experimental results show that TiG successfully bridges the gap between declarative and procedural knowledge, achieving competitive performance with dramatically lower data and computational demands compared to conventional RL methods. Moreover, TiG provides step-by-step natural language explanations for its decisions, greatly improving transparency and interpretability in complex interactive tasks.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.21365.pdf", "abstract_url": "https://arxiv.org/abs/2508.21365", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "提出TiG框架，通过强化学习结合大型语言模型，使LLMs在游戏中学习程序性知识，提升决策透明度和效率。", "motivation": "解决大型语言模型在交互任务中程序性知识不足的问题，弥合声明性知识与程序性知识之间的差距。", "method": "使用TiG框架，将强化学习决策重新表述为语言建模任务，通过环境反馈迭代优化语言引导策略。", "result": "TiG在数据需求和计算成本上显著优于传统强化学习方法，并提供自然语言解释，提高透明度和性能。", "conclusion": "TiG有效结合LLMs的推理能力和强化学习的交互学习，为复杂交互任务提供高效、可解释的解决方案。"}}
{"id": "2508.21394", "title": "AI Compute Architecture and Evolution Trends", "authors": ["Bor-Sung Liang"], "abstract": "The focus of AI development has shifted from academic research to practical applications. However, AI development faces numerous challenges at various levels. This article will attempt to analyze the opportunities and challenges of AI from several different perspectives using a structured approach. This article proposes a seven-layer model for AI compute architecture, including Physical Layer, Link Layer, Neural Network Layer, Context Layer, Agent Layer, Orchestrator Layer, and Application Layer, from bottom to top. It also explains how AI computing has evolved into this 7-layer architecture through the three-stage evolution on large-scale language models (LLMs). For each layer, we describe the development trajectory and key technologies. In Layers 1 and 2 we discuss AI computing issues and the impact of Scale-Up and Scale-Out strategies on computing architecture. In Layer 3 we explore two different development paths for LLMs. In Layer 4 we discuss the impact of contextual memory on LLMs and compares it to traditional processor memory. In Layers 5 to 7 we discuss the trends of AI agents and explore the issues in evolution from a single AI agent to an AI-based ecosystem, and their impact on the AI industry. Furthermore, AI development involves not only technical challenges but also the economic issues to build self-sustainable ecosystem. This article analyzes the internet industry to provide predictions on the future trajectory of AI development.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "29 pages, 26 figures", "pdf_url": "https://arxiv.org/pdf/2508.21394.pdf", "abstract_url": "https://arxiv.org/abs/2508.21394", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出AI计算的七层架构模型，分析其演变趋势、各层关键技术，并探讨技术和经济挑战。", "motivation": "解决AI从学术研究转向实际应用时面临的多层次挑战，包括技术和经济问题。", "method": "使用结构化方法，提出七层模型（物理层到应用层），分析大语言模型的三个阶段演变和各层发展轨迹。", "result": "识别了Scale-Up/Scale-Out策略的影响、LLM发展路径、上下文内存作用、AI代理趋势，并基于互联网行业预测AI未来。", "conclusion": "AI发展需构建可持续生态系统，涉及技术和经济因素，七层架构有助于理解演变和应对挑战。"}}
{"id": "2508.21411", "title": "CARJAN: Agent-Based Generation and Simulation of Traffic Scenarios with AJAN", "authors": ["Leonard Frank Neis", "Andre Antakli", "Matthias Klusch"], "abstract": "User-friendly modeling and virtual simulation of urban traffic scenarios with different types of interacting agents such as pedestrians, cyclists and autonomous vehicles remains a challenge. We present CARJAN, a novel tool for semi-automated generation and simulation of such scenarios based on the multi-agent engineering framework AJAN and the driving simulator CARLA. CARJAN provides a visual user interface for the modeling, storage and maintenance of traffic scenario layouts, and leverages SPARQL Behavior Tree-based decision-making and interactions for agents in dynamic scenario simulations in CARLA. CARJAN provides a first integrated approach for interactive, intelligent agent-based generation and simulation of virtual traffic scenarios in CARLA.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.21411.pdf", "abstract_url": "https://arxiv.org/abs/2508.21411", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "CARJAN是一种基于AJAN和CARLA的新工具，用于半自动生成和模拟城市交通场景，支持行人、自行车和自动驾驶车辆等智能体交互，提供可视化界面和SPARQL行为树决策。", "motivation": "解决城市交通场景中不同类型智能体交互的建模和虚拟仿真挑战，提升用户友好性和自动化程度。", "method": "基于多智能体工程框架AJAN和驾驶模拟器CARLA，使用SPARQL行为树进行智能体决策和交互，提供可视化界面进行场景布局建模和存储。", "result": "CARJAN成功实现了交互式、智能化的交通场景生成和模拟，为CARLA提供了首个集成方法。", "conclusion": "CARJAN为虚拟交通场景的生成和仿真提供了有效工具，具有实际应用潜力，推动了多智能体模拟技术的发展。"}}
{"id": "2508.21441", "title": "A General Framework of Epistemic Forgetting and its Instantiation by Ranking Functions", "authors": ["Christoph Beierle", "Alexander Hahn", "Diana Howey", "Gabriele Kern-Isberner", "Kai Sauerwald"], "abstract": "Forgetting as a knowledge management operation deliberately ignores parts of the knowledge and beliefs of an agent, for various reasons. Forgetting has many facets, one may want to forget parts of the syntax, a proposition, or a conditional. In the literature, two main operators suitable for performing forgetting have been proposed and investigated in depth: First, variable elimination is a syntactical method that blends out certain atomic variables to focus on the rest of the language. It has been mainly used in the area of logic programming and answer set programming. Second, contraction in AGM belief revision theory effectively removes propositions from belief sets under logical deduction. Both operations rely mainly on classical logics. In this article, we take an epistemic perspective and study forgetting operations in epistemic states with richer semantic structures, but with clear links to propositional logic. This allows us to investigate what forgetting in the epistemic background means, thereby lifting well-known and novel forgetting operations to the epistemic level. We present five general types of epistemic forgetting and instantiate them with seven concrete forgetting operations for Spohn's ranking functions. We take inspiration from postulates of forgetting both from logic programming and AGM theory to propose a rich landscape of axioms for evaluating forgetting operations. Finally, we evaluate all concrete forgetting operations according to all postulates, leading to a novel comprehensive overview highlighting differences and commonalities among the forgetting operators.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.21441.pdf", "abstract_url": "https://arxiv.org/abs/2508.21441", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一个通用的认知遗忘框架，基于Spohn排名函数实例化七种具体操作，并通过公理评估其差异和共性。", "motivation": "解决知识管理中遗忘操作的多样性和语义丰富性问题，扩展经典逻辑方法到认知状态。", "method": "采用认知视角，定义五种通用遗忘类型，并基于逻辑编程和AGM理论的公理进行评估。", "result": "评估了七种具体遗忘操作，揭示了它们之间的差异和共同点，提供了全面的概述。", "conclusion": "该框架提升了遗忘操作到认知层面，为知识管理提供了更丰富的工具和理论基础。"}}
{"id": "2508.21475", "title": "MMSearch-Plus: A Simple Yet Challenging Benchmark for Multimodal Browsing Agents", "authors": ["Xijia Tao", "Yihua Teng", "Xinxing Su", "Xinyu Fu", "Jihao Wu", "Chaofan Tao", "Ziru Liu", "Haoli Bai", "Rui Liu", "Lingpeng Kong"], "abstract": "Large multimodal language models (MLLMs) are increasingly deployed as web agents, yet many multimodal browsing benchmarks can be solved by shallow, fixed workflows that lean on high-recall image search and nearby text-masking the genuinely multimodal challenges of fine-grained visual reasoning, provenance verification, and long-horizon tool use. We introduce MMSearch-Plus, a benchmark of 311 tasks that highly demand multimodal understanding while preserving the difficulty profile of strong text-only browsing suites. Each item is constructed to contain multiple weak, localized visual signals that must be extracted, propagated through iterative text-image search, and cross-validated under retrieval noise before answering. Our curation procedure, Spatial-Temporal Extrapolation, seeds questions whose answers require extrapolating from spatial cues (micro-text, part-level appearance, layouts, signage) and temporal traces (broadcast overlays, seasonal context) to out-of-image facts such as events, dates, and venues. We provide a model-agnostic agent framework with browsing tools and evaluate a range of closed and open MLLMs. The strongest agent (o3) attains 15.1% without search and 36.0% accuracy with rollout under our framework, while a strong open-source model (Qwen-2.5-VL-72B-Instruct) achieves 0.0% without search and 6.9% after 20 rounds of search. Beyond answer accuracy, we assess bounding-box production and cropped-image search, and conduct an error analysis that surfaces failures in source verification, part-based reasoning, and long-horizon planning.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2508.21475.pdf", "abstract_url": "https://arxiv.org/abs/2508.21475", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "MMSearch-Plus是一个针对多模态浏览代理的基准测试，包含311个任务，强调细粒度视觉推理和长期工具使用，挑战现有模型。", "motivation": "解决当前多模态浏览基准测试中浅层工作流占主导的问题，无法有效评估真正的多模态理解能力。", "method": "使用空间-时间外推法构建任务，要求提取弱视觉信号并通过迭代文本-图像搜索进行传播和交叉验证。", "result": "最佳代理准确率为36.0%，开源模型准确率低至6.9%，显示模型在来源验证和部分推理方面存在失败。", "conclusion": "MMSearch-Plus提供了一个具有挑战性的基准，突出现有多模态模型的不足，并促进更强大的代理开发。"}}
{"id": "2508.21456", "title": "Morae: Proactively Pausing UI Agents for User Choices", "authors": ["Yi-Hao Peng", "Dingzeyu Li", "Jeffrey P. Bigham", "Amy Pavel"], "abstract": "User interface (UI) agents promise to make inaccessible or complex UIs easier to access for blind and low-vision (BLV) users. However, current UI agents typically perform tasks end-to-end without involving users in critical choices or making them aware of important contextual information, thus reducing user agency. For example, in our field study, a BLV participant asked to buy the cheapest available sparkling water, and the agent automatically chose one from several equally priced options, without mentioning alternative products with different flavors or better ratings. To address this problem, we introduce Morae, a UI agent that automatically identifies decision points during task execution and pauses so that users can make choices. Morae uses large multimodal models to interpret user queries alongside UI code and screenshots, and prompt users for clarification when there is a choice to be made. In a study over real-world web tasks with BLV participants, Morae helped users complete more tasks and select options that better matched their preferences, as compared to baseline agents, including OpenAI Operator. More broadly, this work exemplifies a mixed-initiative approach in which users benefit from the automation of UI agents while being able to express their preferences.", "subjects": "Human-Computer Interaction (cs.HC); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)", "comments": "ACM UIST 2025", "pdf_url": "https://arxiv.org/pdf/2508.21456.pdf", "abstract_url": "https://arxiv.org/abs/2508.21456", "categories": ["Human-Computer Interaction (cs.HC)", "Computation and Language (cs.CL)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "Morae是一个UI代理，通过暂停让用户在决策点选择，增强盲人和低视力用户的控制力，提高任务完成率和偏好匹配。", "motivation": "解决当前UI代理在任务执行中不涉及用户选择或提供上下文信息，减少用户代理性的问题。", "method": "使用大型多模态模型解释用户查询、UI代码和截图，自动识别决策点并暂停提示用户澄清。", "result": "在真实网络任务研究中，Morae比基线代理（如OpenAI Operator）帮助用户完成更多任务并选择更符合偏好的选项。", "conclusion": "这项工作展示了混合主动方法，用户从UI代理的自动化中受益，同时能表达偏好，提升可访问性。"}}
{"id": "2508.21595", "title": "Scalable Solution Methods for Dec-POMDPs with Deterministic Dynamics", "authors": ["Yang You", "Alex Schutz", "Zhikun Li", "Bruno Lacerda", "Robert Skilton", "Nick Hawes"], "abstract": "Many high-level multi-agent planning problems, including multi-robot navigation and path planning, can be effectively modeled using deterministic actions and observations.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.21595.pdf", "abstract_url": "https://arxiv.org/abs/2508.21595", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了在确定性动态下可扩展的Dec-POMDP解决方案方法，适用于多机器人导航等规划问题。", "motivation": "解决多智能体规划问题中确定性动作和观测的有效建模需求，以提高可扩展性。", "method": "使用确定性动态的Dec-POMDP方法，开发可扩展的求解算法。", "result": "方法在多机器人导航等场景中有效，实现了高效的规划。", "conclusion": "确定性Dec-POMDP方法为多智能体规划提供了可扩展的解决方案，具有实际应用价值。"}}
{"id": "2508.21476", "title": "Igniting Creative Writing in Small Language Models: LLM-as-a-Judge versus Multi-Agent Refined Rewards", "authors": ["Xiaolong Wei", "Bo Lu", "Xingyu Zhang", "Zhejun Zhao", "Dongdong Shen", "Long Xia", "Dawei Yin"], "abstract": "Large Language Models (LLMs) have demonstrated remarkable creative writing capabilities, yet their substantial computational demands hinder widespread use. Enhancing Small Language Models (SLMs) offers a promising alternative, but current methods like Supervised Fine-Tuning (SFT) struggle with novelty, and Reinforcement Learning from Human Feedback (RLHF) is costly. This paper explores two distinct AI-driven reward strategies within a Reinforcement Learning from AI Feedback (RLAIF) framework to ignite the creative writing of a 7B-parameter SLM, specifically for generating Chinese greetings. The first strategy employs a RM trained on high-quality preference data curated by a novel multi-agent rejection sampling framework designed for creative tasks. The second, more novel strategy utilizes a principle-guided LLM-as-a-Judge, whose reward function is optimized via an adversarial training scheme with a reflection mechanism, to directly provide reward signals. Comprehensive experiments reveal that while both approaches significantly enhance creative output over baselines, the principle-guided LLM-as-a-Judge demonstrably yields superior generation quality. Furthermore, it offers notable advantages in training efficiency and reduced dependency on human-annotated data, presenting a more scalable and effective path towards creative SLMs. Our automated evaluation methods also exhibit strong alignment with human judgments. Our code and data are publicly available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "EMNLP 2025 Main", "pdf_url": "https://arxiv.org/pdf/2508.21476.pdf", "abstract_url": "https://arxiv.org/abs/2508.21476", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了在RLAIF框架下，使用多智能体精炼奖励和LLM-as-a-Judge两种AI驱动奖励策略，以提升7B参数小语言模型的中文问候语创意写作能力，发现LLM-as-a-Judge方法在质量、效率和可扩展性上更优。", "motivation": "解决大语言模型计算需求高、小语言模型创意写作能力不足的问题，避免SFT缺乏新颖性和RLHF成本高昂的局限。", "method": "采用强化学习从AI反馈（RLAIF）框架，比较基于多智能体拒绝采样的奖励模型和基于原则引导的LLM-as-a-Judge奖励策略，后者通过对抗训练和反思机制优化。", "result": "两种方法均显著提升创意输出，但LLM-as-a-Judge在生成质量、训练效率和减少人类标注数据依赖方面表现更优，自动化评估与人类判断高度一致。", "conclusion": "原则引导的LLM-as-a-Judge策略为创意小语言模型提供了一条更可扩展和有效的路径，代码和数据已公开。"}}
{"id": "2508.21622", "title": "Integrating Large Language Models with Network Optimization for Interactive and Explainable Supply Chain Planning: A Real-World Case Study", "authors": ["Saravanan Venkatachalam"], "abstract": "This paper presents an integrated framework that combines traditional network optimization models with large language models (LLMs) to deliver interactive, explainable, and role-aware decision support for supply chain planning. The proposed system bridges the gap between complex operations research outputs and business stakeholder understanding by generating natural language summaries, contextual visualizations, and tailored key performance indicators (KPIs). The core optimization model addresses tactical inventory redistribution across a network of distribution centers for multi-period and multi-item, using a mixed-integer formulation. The technical architecture incorporates AI agents, RESTful APIs, and a dynamic user interface to support real-time interaction, configuration updates, and simulation-based insights. A case study demonstrates how the system improves planning outcomes by preventing stockouts, reducing costs, and maintaining service levels. Future extensions include integrating private LLMs, transfer learning, reinforcement learning, and Bayesian neural networks to enhance explainability, adaptability, and real-time decision-making.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.21622.pdf", "abstract_url": "https://arxiv.org/abs/2508.21622", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种结合大型语言模型和网络优化的集成框架，用于供应链规划，提供交互式、可解释和角色感知的决策支持，并通过案例研究验证了其有效性。", "motivation": "解决传统运筹学输出与业务利益相关者理解之间的差距，提高供应链规划的交互性和可解释性。", "method": "使用混合整数规划模型进行库存再分配，结合LLMs生成自然语言摘要、可视化和KPIs，并集成AI代理、RESTful API和动态用户界面。", "result": "系统通过案例研究证明，能够预防缺货、降低成本并维持服务水平。", "conclusion": "框架提升了规划效果，未来可扩展集成私有LLMs、强化学习等以增强适应性和实时决策能力。"}}
{"id": "2508.21720", "title": "PosterForest: Hierarchical Multi-Agent Collaboration for Scientific Poster Generation", "authors": ["Jiho Choi", "Seojeong Park", "Seongjong Song", "Hyunjung Shim"], "abstract": "We present a novel training-free framework, \\textit{PosterForest}, for automated scientific poster generation. Unlike prior approaches, which largely neglect the hierarchical structure of scientific documents and the semantic integration of textual and visual elements, our method addresses both challenges directly. We introduce the \\textit{Poster Tree}, a hierarchical intermediate representation that jointly encodes document structure and visual-textual relationships at multiple levels. Our framework employs a multi-agent collaboration strategy, where agents specializing in content summarization and layout planning iteratively coordinate and provide mutual feedback. This approach enables the joint optimization of logical consistency, content fidelity, and visual coherence. Extensive experiments on multiple academic domains show that our method outperforms existing baselines in both qualitative and quantitative evaluations. The resulting posters achieve quality closest to expert-designed ground truth and deliver superior information preservation, structural clarity, and user preference.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.21720.pdf", "abstract_url": "https://arxiv.org/abs/2508.21720", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "PosterForest是一种无需训练的多智能体协作框架，用于自动生成科学海报，通过分层表示和协作优化，在质量和用户偏好上优于现有方法。", "motivation": "解决现有方法忽略科学文档分层结构和文本-视觉元素语义整合的问题。", "method": "使用Poster Tree分层中间表示和多智能体协作策略，包括内容摘要和布局规划智能体的迭代协调。", "result": "在多个学术领域的实验中，方法在定性和定量评估上超越基线，海报质量接近专家设计，信息保留和结构清晰度更优。", "conclusion": "该方法能有效生成高质量科学海报，提升逻辑一致性、内容保真度和视觉连贯性。"}}
{"id": "2508.21097", "title": "Model-Driven Quantum Code Generation Using Large Language Models and Retrieval-Augmented Generation", "authors": ["Nazanin Siavash", "Armin Moin"], "abstract": "This paper introduces a novel research direction for model-to-text/code transformations by leveraging Large Language Models (LLMs) that can be enhanced with Retrieval-Augmented Generation (RAG) pipelines. The focus is on quantum and hybrid quantum-classical software systems, where model-driven approaches can help reduce the costs and mitigate the risks associated with the heterogeneous platform landscape and lack of developers' skills. We validate one of the proposed ideas regarding generating code out of UML model instances of software systems. This Python code uses a well-established library, called Qiskit, to execute on gate-based or circuit-based quantum computers. The RAG pipeline that we deploy incorporates sample Qiskit code from public GitHub repositories. Experimental results show that well-engineered prompts can improve CodeBLEU scores by up to a factor of four, yielding more accurate and consistent quantum code. However, the proposed research direction can go beyond this through further investigation in the future by conducting experiments to address our other research questions and ideas proposed here, such as deploying software system model instances as the source of information in the RAG pipelines, or deploying LLMs for code-to-code transformations, for instance, for transpilation use cases.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": "This paper is accepted to the New Ideas and Emerging Results (NIER) track of the ACM/IEEE 28th International Conference on Model Driven Engineering Languages and Systems (MODELS)", "pdf_url": "https://arxiv.org/pdf/2508.21097.pdf", "abstract_url": "https://arxiv.org/abs/2508.21097", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出利用大型语言模型和检索增强生成进行模型驱动量子代码生成的新方法，通过实验验证了在Qiskit库上生成更准确代码，并指出未来研究方向。", "motivation": "解决量子计算中平台异构和开发者技能不足的问题，降低成本和风险。", "method": "使用LLM和RAG管道，从UML模型实例生成Python代码，并整合GitHub上的Qiskit代码样本。", "result": "优化提示可将CodeBLEU分数提高至四倍，生成更准确和一致的量子代码。", "conclusion": "该方法有效，未来可扩展至模型实例作为RAG信息源或代码到代码转换等用例。"}}
{"id": "2508.21803", "title": "Automated Clinical Problem Detection from SOAP Notes using a Collaborative Multi-Agent LLM Architecture", "authors": ["Yeawon Lee", "Xiaoyang Wang", "Christopher C. Yang"], "abstract": "Accurate interpretation of clinical narratives is critical for patient care, but the complexity of these notes makes automation challenging. While Large Language Models (LLMs) show promise, single-model approaches can lack the robustness required for high-stakes clinical tasks. We introduce a collaborative multi-agent system (MAS) that models a clinical consultation team to address this gap. The system is tasked with identifying clinical problems by analyzing only the Subjective (S) and Objective (O) sections of SOAP notes, simulating the diagnostic reasoning process of synthesizing raw data into an assessment. A Manager agent orchestrates a dynamically assigned team of specialist agents who engage in a hierarchical, iterative debate to reach a consensus. We evaluated our MAS against a single-agent baseline on a curated dataset of 420 MIMIC-III notes. The dynamic multi-agent configuration demonstrated consistently improved performance in identifying congestive heart failure, acute kidney injury, and sepsis. Qualitative analysis of the agent debates reveals that this structure effectively surfaces and weighs conflicting evidence, though it can occasionally be susceptible to groupthink. By modeling a clinical team's reasoning process, our system offers a promising path toward more accurate, robust, and interpretable clinical decision support tools.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "Accepted to The 16th ACM Conference on Bioinformatics, Computational Biology, and Health Informatics (ACM-BCB 2025)(Poster Paper)", "pdf_url": "https://arxiv.org/pdf/2508.21803.pdf", "abstract_url": "https://arxiv.org/abs/2508.21803", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "使用协作多智能体LLM架构从SOAP笔记中自动检测临床问题，通过模拟临床团队推理过程提高准确性。", "motivation": "解决临床叙述复杂性导致的自动化挑战，单模型方法在高风险临床任务中缺乏鲁棒性。", "method": "引入协作多智能体系统，由Manager代理协调专家代理进行分层迭代辩论，仅分析SOAP笔记的S和O部分。", "result": "在420个MIMIC-III笔记数据集上，动态多智能体配置在识别充血性心力衰竭、急性肾损伤和败血症方面性能一致提升，但偶尔易受群体思维影响。", "conclusion": "该系统为更准确、鲁棒和可解释的临床决策支持工具提供了有前景的路径。"}}
{"id": "2508.21209", "title": "Designing Smarter Conversational Agents for Kids: Lessons from Cognitive Work and Means-Ends Analyses", "authors": ["Vanessa Figueiredo"], "abstract": "This paper presents two studies on how Brazilian children (ages 9--11) use conversational agents (CAs) for schoolwork, discovery, and entertainment, and how structured scaffolds can enhance these interactions. In Study 1, a seven-week online investigation with 23 participants (children, parents, teachers) employed interviews, observations, and Cognitive Work Analysis to map children's information-processing flows, the role of more knowledgeable others, functional uses, contextual goals, and interaction patterns to inform conversation-tree design. We identified three CA functions: School, Discovery, Entertainment, and derived ``recipe'' scaffolds mirroring parent-child support. In Study 2, we prompted GPT-4o-mini on 1,200 simulated child-CA exchanges, comparing conversation-tree recipes based on structured-prompting to an unstructured baseline. Quantitative evaluation of readability, question count/depth/diversity, and coherence revealed gains for the recipe approach. Building on these findings, we offer design recommendations: scaffolded conversation-trees, child-dedicated profiles for personalized context, and caregiver-curated content. Our contributions include the first CWA application with Brazilian children, an empirical framework of child-CA information flows, and an LLM-scaffolding ``recipe'' (i.e., structured-prompting) for effective, scaffolded learning.", "subjects": "Human-Computer Interaction (cs.HC); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.21209.pdf", "abstract_url": "https://arxiv.org/abs/2508.21209", "categories": ["Human-Computer Interaction (cs.HC)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过两项研究探讨巴西儿童使用对话代理（CAs）的情况，提出结构化支架（如对话树和提示）可提升互动效果，并提供设计建议。", "motivation": "解决儿童在使用对话代理进行学习、探索和娱乐时互动效率低的问题，以增强其教育效果和用户体验。", "method": "采用认知工作分析和手段-目的分析，包括访谈、观察和基于GPT-4o-mini的模拟实验，比较结构化与无结构提示方法。", "result": "结构化支架方法在可读性、问题数量/深度/多样性和连贯性方面优于基线，显示出显著改进。", "conclusion": "建议使用支架化对话树、儿童专用配置文件和看护人策划内容，为儿童对话代理设计提供实证框架和实用指导。"}}
{"id": "2508.21104", "title": "PVPO: Pre-Estimated Value-Based Policy Optimization for Agentic Reasoning", "authors": ["Wenfeng Feng", "Penghong Zhao", "Guochao Jiang", "Chuzhan Hao", "Yuewei Zhang", "Hao Wang"], "abstract": "Critic-free reinforcement learning methods, particularly group policies, have attracted considerable attention for their efficiency in complex tasks. However, these methods rely heavily on multiple sampling and comparisons within the policy to estimate advantage, which may cause the policy to fall into local optimum and increase computational cost. To address these issues, we propose PVPO, an efficient reinforcement learning method enhanced by an advantage reference anchor and data pre-sampling. Specifically, we use the reference model to rollout in advance and employ the calculated reward score as a reference anchor. Our approach effectively corrects the cumulative bias introduced by intra-group comparisons and significantly reduces reliance on the number of rollouts. Meanwhile, the reference model can assess sample difficulty during data pre-sampling, enabling effective selection of high-gain data to improve training efficiency. Experiments conducted on nine datasets across two domains demonstrate that PVPO achieves State-Of-The-Art (SOTA) performance. Our approach not only demonstrates robust generalization across multiple tasks, but also exhibits scalable performance across models of varying scales.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "14 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2508.21104.pdf", "abstract_url": "https://arxiv.org/abs/2508.21104", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "PVPO是一种高效的强化学习方法，通过优势参考锚点和数据预采样减少计算成本并避免局部最优，在多个数据集上实现最先进性能。", "motivation": "解决无评论者强化学习方法依赖多次采样和比较导致局部最优和高计算成本的问题。", "method": "使用参考模型提前rollout计算奖励分数作为参考锚点，结合数据预采样选择高增益数据。", "result": "在九个数据集上实现SOTA性能，展示强泛化能力和可扩展性。", "conclusion": "PVPO有效提升训练效率和性能，适用于多种任务和模型规模。"}}
{"id": "2508.21101", "title": "Beyond Prediction: Reinforcement Learning as the Defining Leap in Healthcare AI", "authors": ["Dilruk Perera", "Gousia Habib", "Qianyi Xu", "Daniel J. Tan", "Kai He", "Erik Cambria", "Mengling Feng"], "abstract": "Reinforcement learning (RL) marks a fundamental shift in how artificial intelligence is applied in healthcare. Instead of merely predicting outcomes, RL actively decides interventions with long term goals. Unlike traditional models that operate on fixed associations, RL systems learn through trial, feedback, and long-term reward optimization, introducing transformative possibilities and new risks. From an information fusion lens, healthcare RL typically integrates multi-source signals such as vitals, labs clinical notes, imaging and device telemetry using temporal and decision-level mechanisms. These systems can operate within centralized, federated, or edge architectures to meet real-time clinical constraints, and naturally span data, features and decision fusion levels. This survey explore RL's rise in healthcare as more than a set of tools, rather a shift toward agentive intelligence in clinical environments. We first structure the landscape of RL techniques including model-based and model-free methods, offline and batch-constrained approaches, and emerging strategies for reward specification and uncertainty calibration through the lens of healthcare constraints. We then comprehensively analyze RL applications spanning critical care, chronic disease, mental health, diagnostics, and robotic assistance, identifying their trends, gaps, and translational bottlenecks. In contrast to prior reviews, we critically analyze RL's ethical, deployment, and reward design challenges, and synthesize lessons for safe, human-aligned policy learning. This paper serves as both a a technical roadmap and a critical reflection of RL's emerging transformative role in healthcare AI not as prediction machinery, but as agentive clinical intelligence.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "40 pages in total (including appendix)", "pdf_url": "https://arxiv.org/pdf/2508.21101.pdf", "abstract_url": "https://arxiv.org/abs/2508.21101", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "强化学习在医疗AI中从预测转向主动决策，整合多源数据，应用广泛但面临伦理和部署挑战。", "motivation": "解决传统AI模型仅预测结果的问题，通过强化学习实现长期目标驱动的主动干预，提升医疗智能。", "method": "使用强化学习技术，包括基于模型和无模型方法、离线学习，融合多源信号如生命体征和临床数据。", "result": "分析显示强化学习在重症监护、慢性病等领域有应用潜力，但存在奖励设计和不确定性校准等瓶颈。", "conclusion": "强化学习是医疗AI的变革性进展，强调代理智能，需关注安全、伦理和人类对齐的政策学习。"}}
{"id": "2508.21111", "title": "Automating the Deep Space Network Data Systems; A Case Study in Adaptive Anomaly Detection through Agentic AI", "authors": ["Evan J. Chou", "Lisa S. Locke", "Harvey M. Soldan"], "abstract": "The Deep Space Network (DSN) is NASA's largest network of antenna facilities that generate a large volume of multivariate time-series data. These facilities contain DSN antennas and transmitters that undergo degradation over long periods of time, which may cause costly disruptions to the data flow and threaten the earth-connection of dozens of spacecraft that rely on the Deep Space Network for their lifeline. The purpose of this study was to experiment with different methods that would be able to assist JPL engineers with directly pinpointing anomalies and equipment degradation through collected data, and continue conducting maintenance and operations of the DSN for future space missions around our universe. As such, we have researched various machine learning techniques that can fully reconstruct data through predictive analysis, and determine anomalous data entries within real-time datasets through statistical computations and thresholds. On top of the fully trained and tested machine learning models, we have also integrated the use of a reinforcement learning subsystem that classifies identified anomalies based on severity level and a Large Language Model that labels an explanation for each anomalous data entry, all of which can be improved and fine-tuned over time through human feedback/input. Specifically, for the DSN transmitters, we have also implemented a full data pipeline system that connects the data extraction, parsing, and processing workflow all together as there was no coherent program or script for performing these tasks before. Using this data pipeline system, we were able to then also connect the models trained from DSN antenna data, completing the data workflow for DSN anomaly detection. This was all wrapped around and further connected by an agentic AI system, where complex reasoning was utilized to determine the classifications and predictions of anomalous data.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.21111.pdf", "abstract_url": "https://arxiv.org/abs/2508.21111", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文通过结合机器学习、强化学习和大型语言模型，开发了一个基于代理AI的自适应异常检测系统，用于自动化NASA深空网络的数据系统，以实时识别和分类设备退化异常，提高维护效率。", "motivation": "解决深空网络中天线和发射机随时间退化导致的成本高昂中断问题，确保数十个航天器的地球连接可靠性，辅助JPL工程师进行维护和操作。", "method": "使用机器学习技术进行预测分析和统计计算检测异常，集成强化学习子系统分类异常严重程度，大型语言模型提供异常解释，并通过人类反馈优化；实现完整数据管道系统连接数据提取、解析和处理。", "result": "开发了集成数据管道和代理AI的系统，能够实时识别和分类异常，提高异常检测的准确性和自动化水平。", "conclusion": "该系统成功自动化了深空网络异常检测，可扩展用于未来太空任务，通过持续学习和人类反馈提升性能。"}}
{"id": "2508.21253", "title": "Reinforcement Learning for Optimizing Large Qubit Array based Quantum Sensor Circuits", "authors": ["Laxmisha Ashok Attisara", "Sathish Kumar"], "abstract": "As the number of qubits in a sensor increases, the complexity of designing and controlling the quantum circuits grows exponentially. Manually optimizing these circuits becomes infeasible. Optimizing entanglement distribution in large-scale quantum circuits is critical for enhancing the sensitivity and efficiency of quantum sensors [5], [6]. This paper presents an engineering integration of reinforcement learning with tensor-network-based simulation (MPS) for scalable circuit optimization for optimizing quantum sensor circuits with up to 60 qubits. To enable efficient simulation and scalability, we adopt tensor network methods, specifically the Matrix Product State (MPS) representation, instead of traditional state vector or density matrix approaches. Our reinforcement learning agent learns to restructure circuits to maximize Quantum Fisher Information (QFI) and entanglement entropy while reducing gate counts and circuit depth. Experimental results show consistent improvements, with QFI values approaching 1, entanglement entropy in the 0.8-1.0 range, and up to 90% reduction in depth and gate count. These results highlight the potential of combining quantum machine learning and tensor networks to optimize complex quantum circuits under realistic constraints.", "subjects": "Quantum Physics (quant-ph); Artificial Intelligence (cs.AI)", "comments": "10 pages, 13 figures, 2 tables", "pdf_url": "https://arxiv.org/pdf/2508.21253.pdf", "abstract_url": "https://arxiv.org/abs/2508.21253", "categories": ["Quantum Physics (quant-ph)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种结合强化学习和张量网络模拟的方法，用于优化多达60个量子比特的量子传感器电路，显著提高了量子费希尔信息、纠缠熵，并减少了门数和电路深度。", "motivation": "随着量子比特数量的增加，手动优化量子电路变得不可行，需要自动化方法来处理大规模量子电路的复杂性和控制问题。", "method": "使用强化学习与矩阵乘积状态（MPS）张量网络模拟相结合，学习重构电路以最大化量子费希尔信息和纠缠熵，同时减少门数和电路深度。", "result": "实验结果显示，量子费希尔信息接近1，纠缠熵在0.8-1.0范围内，深度和门数减少高达90%。", "conclusion": "结合量子机器学习和张量网络可以有效优化复杂量子电路，具有实际应用潜力。"}}
{"id": "2508.21246", "title": "HCQA: Hybrid Classical-Quantum Agent for Generating Optimal Quantum Sensor Circuits", "authors": ["Ahmad Alomari", "Sathish A. P. Kumar"], "abstract": "This study proposes an HCQA for designing optimal Quantum Sensor Circuits (QSCs) to address complex quantum physics problems. The HCQA integrates computational intelligence techniques by leveraging a Deep Q-Network (DQN) for learning and policy optimization, enhanced by a quantum-based action selection mechanism based on the Q-values. A quantum circuit encodes the agent current state using Ry gates, and then creates a superposition of possible actions. Measurement of the circuit results in probabilistic action outcomes, allowing the agent to generate optimal QSCs by selecting sequences of gates that maximize the Quantum Fisher Information (QFI) while minimizing the number of gates. This computational intelligence-driven HCQA enables the automated generation of entangled quantum states, specifically the squeezed states, with high QFI sensitivity for quantum state estimation and control. Evaluation of the HCQA on a QSC that consists of two qubits and a sequence of Rx, Ry, and S gates demonstrates its efficiency in generating optimal QSCs with a QFI of 1. This work highlights the synergy between AI-driven learning and quantum computation, illustrating how intelligent agents can autonomously discover optimal quantum circuit designs for enhanced sensing and estimation tasks.", "subjects": "Quantum Physics (quant-ph); Artificial Intelligence (cs.AI)", "comments": "9 pages, 9 figures", "pdf_url": "https://arxiv.org/pdf/2508.21246.pdf", "abstract_url": "https://arxiv.org/abs/2508.21246", "categories": ["Quantum Physics (quant-ph)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本研究提出了一种混合经典量子代理（HCQA），用于自动生成最优量子传感器电路，结合深度Q网络和量子机制，以最大化量子费希尔信息并最小化门数，在双量子比特系统中验证了高效性。", "motivation": "解决复杂量子物理问题中设计最优量子传感器电路的挑战，旨在通过自动化方法提升量子传感和估计任务的性能。", "method": "使用深度Q网络（DQN）进行学习和策略优化，结合基于Q值的量子动作选择机制，通过Ry门编码状态并创建动作叠加，测量后概率选择动作以优化电路。", "result": "在双量子比特系统中，HCQA成功生成了最优量子传感器电路，实现了量子费希尔信息为1的高灵敏度，并最小化了门数。", "conclusion": "HCQA展示了AI驱动学习与量子计算的协同作用，能够自主发现最优量子电路设计，提升量子传感和控制的自动化水平。"}}
{"id": "2508.21302", "title": "Locus: Agentic Predicate Synthesis for Directed Fuzzing", "authors": ["Jie Zhu", "Chihao Shen", "Ziyang Li", "Jiahao Yu", "Yizheng Chen", "Kexin Pei"], "abstract": "Directed fuzzing aims to find program inputs that lead to specified target program states. It has broad applications, such as debugging system crashes, confirming reported bugs, and generating exploits for potential vulnerabilities. This task is inherently challenging because target states are often deeply nested in the program, while the search space manifested by numerous possible program inputs is prohibitively large. Existing approaches rely on branch distances or manually-specified constraints to guide the search; however, the branches alone are often insufficient to precisely characterize progress toward reaching the target states, while the manually specified constraints are often tailored for specific bug types and thus difficult to generalize to diverse target states and programs.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Software Engineering (cs.SE)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.21302.pdf", "abstract_url": "https://arxiv.org/abs/2508.21302", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Software Engineering (cs.SE)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出Locus方法，通过自动合成谓词来指导定向模糊测试，以更精确地引导搜索到达目标程序状态，解决现有方法依赖分支距离或手动约束的局限性。", "motivation": "定向模糊测试用于发现导致特定目标程序状态的输入，但目标状态常深藏于程序中，搜索空间巨大；现有方法依赖分支距离或手动约束，不够精确且难以泛化。", "method": "使用代理式谓词合成方法，自动生成约束来精确引导搜索，避免对分支或手动输入的依赖。", "result": "Locus方法能更有效地到达目标状态，提高定向模糊测试的效率和泛化能力。", "conclusion": "自动合成谓词是改进定向模糊测试的关键，可广泛应用于调试、漏洞确认和利用生成。"}}
{"id": "2508.21368", "title": "EconAgentic in DePIN Markets: A Large Language Model Approach to the Sharing Economy of Decentralized Physical Infrastructure", "authors": ["Yulin Liu", "Mocca Schweitzer"], "abstract": "The Decentralized Physical Infrastructure (DePIN) market is revolutionizing the sharing economy through token-based economics and smart contracts that govern decentralized operations. By 2024, DePIN projects have exceeded \\$10 billion in market capitalization, underscoring their rapid growth. However, the unregulated nature of these markets, coupled with the autonomous deployment of AI agents in smart contracts, introduces risks such as inefficiencies and potential misalignment with human values. To address these concerns, we introduce EconAgentic, a Large Language Model (LLM)-powered framework designed to mitigate these challenges. Our research focuses on three key areas: 1) modeling the dynamic evolution of DePIN markets, 2) evaluating stakeholders' actions and their economic impacts, and 3) analyzing macroeconomic indicators to align market outcomes with societal goals. Through EconAgentic, we simulate how AI agents respond to token incentives, invest in infrastructure, and adapt to market conditions, comparing AI-driven decisions with human heuristic benchmarks. Our results show that EconAgentic provides valuable insights into the efficiency, inclusion, and stability of DePIN markets, contributing to both academic understanding and practical improvements in the design and governance of decentralized, tokenized economies.", "subjects": "General Economics (econ.GN); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.21368.pdf", "abstract_url": "https://arxiv.org/abs/2508.21368", "categories": ["General Economics (econ.GN)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了EconAgentic，一个基于大语言模型的框架，用于解决DePIN市场中因AI代理自主操作带来的效率低下和价值不对齐问题，通过模拟和分析提升市场效率、包容性和稳定性。", "motivation": "DePIN市场快速增长但存在监管缺失和AI代理风险，如效率低下和与人类价值不对齐，需要一种方法来缓解这些问题。", "method": "使用大语言模型（LLM）框架EconAgentic，模拟AI代理对代币激励的响应、基础设施投资和市场适应，并与人类启发式基准进行比较。", "result": "EconAgentic提供了对DePIN市场效率、包容性和稳定性的宝贵见解，有助于学术理解和实际改进。", "conclusion": "EconAgentic框架能有效改善DePIN市场的设计和治理，促进去中心化、代币化经济的更好对齐社会目标。"}}
{"id": "2508.21433", "title": "The Complexity Trap: Simple Observation Masking Is as Efficient as LLM Summarization for Agent Context Management", "authors": ["Tobias Lindenbauer", "Igor Slinko", "Ludwig Felder", "Egor Bogomolov", "Yaroslav Zharov"], "abstract": "Large Language Model (LLM)-based agents solve complex tasks through iterative reasoning, exploration, and tool-use, a process that can result in long, expensive context histories. While state-of-the-art Software Engineering ( SE) agents like OpenHands or Cursor use LLM-based summarization to tackle this issue, it is unclear whether the increased complexity offers tangible performance benefits compared to simply omitting older observations. We present a systematic comparison of these strategies within SWE-agent on SWE-bench Verified across five diverse model configurations. We find that a simple observation-masking strategy halves cost relative to a raw agent while matching, and sometimes slightly exceeding, the solve rate of LLM summarization. For example, with Qwen3-Coder 480B, masking improves solve rate from 53.8% (raw agent) to 54.8%, while remaining competitive with summarization at a lower cost. These results suggest that, at least within SWE-agent on SWE-bench Verified, the most effective and efficient context management can be the simplest. We release code and data for reproducibility", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.21433.pdf", "abstract_url": "https://arxiv.org/abs/2508.21433", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "在SWE-agent和SWE-bench Verified上，简单观察屏蔽策略与LLM摘要相比，成本减半且解决率相当或略高，表明简单方法更高效。", "motivation": "解决LLM代理在复杂任务中上下文历史过长和成本高的问题，比较摘要与屏蔽策略的效率。", "method": "在SWE-agent上使用SWE-bench Verified数据集，比较五种模型配置下的观察屏蔽和LLM摘要策略。", "result": "屏蔽策略将成本减半，解决率从53.8%提升至54.8%，与摘要策略竞争但成本更低。", "conclusion": "在给定环境中，简单观察屏蔽是最有效和高效的上下文管理方法，代码和数据已发布。"}}
