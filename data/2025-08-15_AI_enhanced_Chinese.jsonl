{"id": "2508.10287", "title": "JRDB-Reasoning: A Difficulty-Graded Benchmark for Visual Reasoning in Robotics", "authors": ["Simindokht Jahangard", "Mehrzad Mohammadi", "Yi Shen", "Zhixi Cai", "Hamid Rezatofighi"], "abstract": "Recent advances in Vision-Language Models (VLMs) and large language models (LLMs) have greatly enhanced visual reasoning, a key capability for embodied AI agents like robots. However, existing visual reasoning benchmarks often suffer from several limitations: they lack a clear definition of reasoning complexity, offer have no control to generate questions over varying difficulty and task customization, and fail to provide structured, step-by-step reasoning annotations (workflows). To bridge these gaps, we formalize reasoning complexity, introduce an adaptive query engine that generates customizable questions of varying complexity with detailed intermediate annotations, and extend the JRDB dataset with human-object interaction and geometric relationship annotations to create JRDB-Reasoning, a benchmark tailored for visual reasoning in human-crowded environments. Our engine and benchmark enable fine-grained evaluation of visual reasoning frameworks and dynamic assessment of visual-language models across reasoning levels.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10287.pdf", "abstract_url": "https://arxiv.org/abs/2508.10287", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了JRDB-Reasoning，一个为机器人视觉推理设计的难度分级基准，通过定义推理复杂性、引入自适应查询引擎和扩展JRDB数据集来解决现有基准的局限性。", "motivation": "解决现有视觉推理基准在定义推理复杂性、生成不同难度问题和提供结构化推理注释方面的不足。", "method": "通过正式化推理复杂性，引入自适应查询引擎生成可定制问题，并扩展JRDB数据集以包含人-物交互和几何关系注释。", "result": "创建了JRDB-Reasoning基准，支持对视觉推理框架的细粒度评估和视觉语言模型在不同推理水平上的动态评估。", "conclusion": "JRDB-Reasoning基准和引擎为人类拥挤环境中的视觉推理提供了定制化的评估工具，推动了视觉推理和语言模型的发展。"}}
{"id": "2508.10567", "title": "SpaRC-AD: A Baseline for Radar-Camera Fusion in End-to-End Autonomous Driving", "authors": ["Philipp Wolters", "Johannes Gilg", "Torben Teepe", "Gerhard Rigoll"], "abstract": "End-to-end autonomous driving systems promise stronger performance through unified optimization of perception, motion forecasting, and planning. However, vision-based approaches face fundamental limitations in adverse weather conditions, partial occlusions, and precise velocity estimation - critical challenges in safety-sensitive scenarios where accurate motion understanding and long-horizon trajectory prediction are essential for collision avoidance. To address these limitations, we propose SpaRC-AD, a query-based end-to-end camera-radar fusion framework for planning-oriented autonomous driving. Through sparse 3D feature alignment, and doppler-based velocity estimation, we achieve strong 3D scene representations for refinement of agent anchors, map polylines and motion modelling. Our method achieves strong improvements over the state-of-the-art vision-only baselines across multiple autonomous driving tasks, including 3D detection (+4.8% mAP), multi-object tracking (+8.3% AMOTA), online mapping (+1.8% mAP), motion prediction (-4.0% mADE), and trajectory planning (-0.1m L2 and -9% TPC). We achieve both spatial coherence and temporal consistency on multiple challenging benchmarks, including real-world open-loop nuScenes, long-horizon T-nuScenes, and closed-loop simulator Bench2Drive. We show the effectiveness of radar-based fusion in safety-critical scenarios where accurate motion understanding and long-horizon trajectory prediction are essential for collision avoidance. The source code of all experiments is available at", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)", "comments": "8 pages, 4 figures, 5 tables", "pdf_url": "https://arxiv.org/pdf/2508.10567.pdf", "abstract_url": "https://arxiv.org/abs/2508.10567", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "SpaRC-AD是一种基于查询的端到端相机-雷达融合框架，用于规划导向的自动驾驶，通过稀疏3D特征对齐和基于多普勒的速度估计，提高了3D场景表示，显著优于纯视觉基线。", "motivation": "解决纯视觉自动驾驶系统在恶劣天气条件、部分遮挡和精确速度估计方面的局限性，特别是在安全敏感场景中准确运动理解和长时程轨迹预测的需求。", "method": "提出SpaRC-AD框架，利用稀疏3D特征对齐和多普勒速度估计，优化代理锚点、地图折线和运动建模的3D场景表示。", "result": "在多个自动驾驶任务中显著优于纯视觉基线，包括3D检测、多目标跟踪、在线地图、运动预测和轨迹规划。", "conclusion": "SpaRC-AD展示了雷达-相机融合在安全关键场景中的有效性，特别是在需要准确运动理解和长时程轨迹预测以避免碰撞的情况下。"}}
{"id": "2508.10572", "title": "Towards Agentic AI for Multimodal-Guided Video Object Segmentation", "authors": ["Tuyen Tran", "Thao Minh Le", "Truyen Tran"], "abstract": "Referring-based Video Object Segmentation is a multimodal problem that requires producing fine-grained segmentation results guided by external cues. Traditional approaches to this task typically involve training specialized models, which come with high computational complexity and manual annotation effort. Recent advances in vision-language foundation models open a promising direction toward training-free approaches. Several studies have explored leveraging these general-purpose models for fine-grained segmentation, achieving performance comparable to that of fully supervised, task-specific models. However, existing methods rely on fixed pipelines that lack the flexibility needed to adapt to the dynamic nature of the task. To address this limitation, we propose Multi-Modal Agent, a novel agentic system designed to solve this task in a more flexible and adaptive manner. Specifically, our method leverages the reasoning capabilities of large language models (LLMs) to generate dynamic workflows tailored to each input. This adaptive procedure iteratively interacts with a set of specialized tools designed for low-level tasks across different modalities to identify the target object described by the multimodal cues. Our agentic approach demonstrates clear improvements over prior methods on two multimodal-conditioned VOS tasks: RVOS and Ref-AVS.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10572.pdf", "abstract_url": "https://arxiv.org/abs/2508.10572", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种新型的多模态代理系统，旨在通过大型语言模型的推理能力，动态生成工作流程，以更灵活和自适应的方式解决基于参考的视频对象分割任务。", "motivation": "传统的视频对象分割方法需要训练专用模型，计算复杂度高且需要大量手动标注。尽管视觉语言基础模型的出现为无训练方法提供了可能，但现有方法依赖固定流程，缺乏适应任务动态性的灵活性。", "method": "提出Multi-Modal Agent系统，利用大型语言模型（LLMs）的推理能力，为每个输入生成动态工作流程，并通过与多模态专用工具的迭代交互，识别由多模态线索描述的目标对象。", "result": "在多模态条件下的VOS任务（RVOS和Ref-AVS）上，该代理方法显示出优于现有方法的明显改进。", "conclusion": "通过引入代理系统和大型语言模型的动态工作流程生成能力，本研究为多模态引导的视频对象分割任务提供了一种更灵活、自适应的解决方案，显著提升了性能。"}}
{"id": "2508.10146", "title": "Agentic AI Frameworks: Architectures, Protocols, and Design Challenges", "authors": ["Hana Derouiche", "Zaki Brahmi", "Haithem Mazeni"], "abstract": "The emergence of Large Language Models (LLMs) has ushered in a transformative paradigm in artificial intelligence, Agentic AI, where intelligent agents exhibit goal-directed autonomy, contextual reasoning, and dynamic multi-agent coordination. This paper provides a systematic review and comparative analysis of leading Agentic AI frameworks, including CrewAI, LangGraph, AutoGen, Semantic Kernel, Agno, Google ADK, and MetaGPT, evaluating their architectural principles, communication mechanisms, memory management, safety guardrails, and alignment with service-oriented computing paradigms. Furthermore, we identify key limitations, emerging trends, and open challenges in the field. To address the issue of agent communication, we conduct an in-depth analysis of protocols such as the Contract Net Protocol (CNP), Agent-to-Agent (A2A), Agent Network Protocol (ANP), and Agora. Our findings not only establish a foundational taxonomy for Agentic AI systems but also propose future research directions to enhance scalability, robustness, and interoperability. This work serves as a comprehensive reference for researchers and practitioners working to advance the next generation of autonomous AI systems.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10146.pdf", "abstract_url": "https://arxiv.org/abs/2508.10146", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文系统地回顾和比较了主要的Agentic AI框架，包括CrewAI、LangGraph等，评估了它们的架构原则、通信机制等，并提出了未来研究方向。", "motivation": "解决大型语言模型（LLMs）带来的Agentic AI领域中智能代理的自主性、上下文推理和多代理协调等问题。", "method": "通过系统回顾和比较分析，深入探讨了Agentic AI框架的架构原则、通信协议等。", "result": "建立了Agentic AI系统的基础分类法，并提出了增强可扩展性、鲁棒性和互操作性的未来研究方向。", "conclusion": "本文为研究人员和从业者提供了推进下一代自主AI系统的全面参考。"}}
{"id": "2508.10143", "title": "MCP-Orchestrated Multi-Agent System for Automated Disinformation Detection", "authors": ["Alexandru-Andrei Avram", "Adrian Groza", "Alexandru Lecu"], "abstract": "The large spread of disinformation across digital platforms creates significant challenges to information integrity. This paper presents a multi-agent system that uses relation extraction to detect disinformation in news articles, focusing on titles and short text snippets. The proposed Agentic AI system combines four agents: (i) a machine learning agent (logistic regression), (ii) a Wikipedia knowledge check agent (which relies on named entity recognition), (iii) a coherence detection agent (using LLM prompt engineering), and (iv) a web-scraped data analyzer that extracts relational triplets for fact checking. The system is orchestrated via the Model Context Protocol (MCP), offering shared context and live learning across components. Results demonstrate that the multi-agent ensemble achieves 95.3% accuracy with an F1 score of 0.964, significantly outperforming individual agents and traditional approaches. The weighted aggregation method, mathematically derived from individual agent misclassification rates, proves superior to algorithmic threshold optimization. The modular architecture makes the system easily scalable, while also maintaining details of the decision processes.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "8 pages + 1 page references, 5 figures, 4 tables, Registered for the 27th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing, 2025, Timisoara", "pdf_url": "https://arxiv.org/pdf/2508.10143.pdf", "abstract_url": "https://arxiv.org/abs/2508.10143", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种多代理系统，通过关系提取来检测新闻文章中的虚假信息，特别是在标题和短文本片段中。该系统结合了四种代理，通过模型上下文协议（MCP）进行协调，实现了95.3%的准确率和0.964的F1分数，显著优于传统方法。", "motivation": "数字平台上虚假信息的大规模传播对信息完整性构成了重大挑战。", "method": "提出的Agentic AI系统结合了四种代理：机器学习代理（逻辑回归）、维基百科知识检查代理（依赖命名实体识别）、一致性检测代理（使用LLM提示工程）和网络抓取数据分析器（提取关系三元组进行事实检查）。系统通过模型上下文协议（MCP）进行协调，提供共享上下文和实时学习。", "result": "多代理集成系统实现了95.3%的准确率和0.964的F1分数，显著优于单个代理和传统方法。加权聚合方法在数学上优于算法阈值优化。", "conclusion": "模块化架构使系统易于扩展，同时保持了决策过程的细节。该系统为检测虚假信息提供了一种高效、可扩展的解决方案。"}}
{"id": "2508.10152", "title": "Improving and Evaluating Open Deep Research Agents", "authors": ["Doaa Allabadi", "Kyle Bradbury", "Jordan M. Malof"], "abstract": "We focus here on Deep Research Agents (DRAs), which are systems that can take a natural language prompt from a user, and then autonomously search for, and utilize, internet-based content to address the prompt. Recent DRAs have demonstrated impressive capabilities on public benchmarks however, recent research largely involves proprietary closed-source systems. At the time of this work, we only found one open-source DRA, termed Open Deep Research (ODR). In this work we adapt the challenging recent BrowseComp benchmark to compare ODR to existing proprietary systems. We propose BrowseComp-Small (BC-Small), comprising a subset of BrowseComp, as a more computationally-tractable DRA benchmark for academic labs. We benchmark ODR and two other proprietary systems on BC-Small: one system from Anthropic and one system from Google. We find that all three systems achieve 0% accuracy on the test set of 60 questions. We introduce three strategic improvements to ODR, resulting in the ODR+ model, which achieves a state-of-the-art 10% success rate on BC-Small among both closed-source and open-source systems. We report ablation studies indicating that all three of our improvements contributed to the success of ODR+.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "8 pages, 2 figures, 2 tables", "pdf_url": "https://arxiv.org/pdf/2508.10152.pdf", "abstract_url": "https://arxiv.org/abs/2508.10152", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文聚焦于深度研究代理（DRAs），这些系统能够接收用户的自然语言提示，并自主搜索和利用基于互联网的内容来应对提示。尽管最近的DRAs在公共基准测试中展示了令人印象深刻的能力，但大多数研究涉及专有的闭源系统。本文通过改进和评估开源的Open Deep Research（ODR）模型，提出了BrowseComp-Small（BC-Small）作为更易于学术实验室处理的DRA基准测试，并在其上比较了ODR与两个专有系统的性能。通过引入三项战略改进，开发了ODR+模型，该模型在BC-Small上实现了10%的成功率，成为当前最先进的系统。", "motivation": "解决当前深度研究代理（DRAs）领域主要由闭源专有系统主导，缺乏开源选择的问题，并通过改进现有的开源系统ODR，提供一个更易于学术实验室使用的基准测试和评估框架。", "method": "通过将挑战性的BrowseComp基准测试适配为更小规模的BrowseComp-Small（BC-Small），并在其上评估和改进开源的ODR系统。引入了三项战略改进，开发出ODR+模型。", "result": "原始的ODR和两个专有系统在BC-Small的60个问题测试集上的准确率为0%。经过改进的ODR+模型实现了10%的成功率，成为当前最先进的系统。消融研究表明，所有三项改进都对ODR+的成功有贡献。", "conclusion": "通过改进开源的ODR系统，本文不仅提供了一个更易于学术实验室处理的DRA基准测试BC-Small，还展示了开源系统在DRAs领域的潜力，为未来的研究和开发提供了有价值的参考。"}}
{"id": "2508.10177", "title": "KompeteAI: Accelerated Autonomous Multi-Agent System for End-to-End Pipeline Generation for Machine Learning Problems", "authors": ["Stepan Kulibaba", "Artem Dzhalilov", "Roman Pakhomov", "Oleg Svidchenko", "Alexander Gasnikov", "Aleksei Shpilman"], "abstract": "Recent Large Language Model (LLM)-based AutoML systems demonstrate impressive capabilities but face significant limitations such as constrained exploration strategies and a severe execution bottleneck. Exploration is hindered by one-shot methods lacking diversity and Monte Carlo Tree Search (MCTS) approaches that fail to recombine strong partial solutions. The execution bottleneck arises from lengthy code validation cycles that stifle iterative refinement. To overcome these challenges, we introduce KompeteAI, a novel AutoML framework with dynamic solution space exploration. Unlike previous MCTS methods that treat ideas in isolation, KompeteAI introduces a merging stage that composes top candidates. We further expand the hypothesis space by integrating Retrieval-Augmented Generation (RAG), sourcing ideas from Kaggle notebooks and arXiv papers to incorporate real-world strategies. KompeteAI also addresses the execution bottleneck via a predictive scoring model and an accelerated debugging method, assessing solution potential using early stage metrics to avoid costly full-code execution. This approach accelerates pipeline evaluation 6.9 times. KompeteAI outperforms leading methods (e.g., RD-agent, AIDE, and Ml-Master) by an average of 3\\% on the primary AutoML benchmark, MLE-Bench. Additionally, we propose Kompete-bench to address limitations in MLE-Bench, where KompeteAI also achieves state-of-the-art results", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10177.pdf", "abstract_url": "https://arxiv.org/abs/2508.10177", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "KompeteAI是一个新型的AutoML框架，通过动态解决方案空间探索、合并顶级候选方案、集成检索增强生成（RAG）以及预测评分模型和加速调试方法，解决了现有LLM-based AutoML系统的探索策略受限和执行瓶颈问题，显著提升了管道评估速度和性能。", "motivation": "解决现有大型语言模型（LLM）基础的AutoML系统在探索策略上的限制和执行瓶颈问题，如缺乏多样性的单次方法和无法重组强部分解决方案的蒙特卡洛树搜索（MCTS）方法，以及冗长的代码验证周期阻碍迭代优化。", "method": "引入KompeteAI框架，采用动态解决方案空间探索，包括合并顶级候选方案的阶段和集成检索增强生成（RAG）来扩展假设空间，同时使用预测评分模型和加速调试方法评估解决方案潜力。", "result": "KompeteAI将管道评估速度提高了6.9倍，并在主要AutoML基准测试MLE-Bench上平均优于领先方法3%，同时在提出的Kompete-bench上也达到了最先进的结果。", "conclusion": "KompeteAI通过创新的探索和执行策略，显著提升了AutoML系统的性能和效率，为机器学习问题的端到端管道生成提供了加速的自主多代理系统解决方案。"}}
{"id": "2508.10337", "title": "A Curriculum Learning Approach to Reinforcement Learning: Leveraging RAG for Multimodal Question Answering", "authors": ["Chenliang Zhang", "Lin Wang", "Yuanyuan Lu", "Yusheng Qi", "Kexin Wang", "Peixu Hou", "Wenshi Chen"], "abstract": "This paper describes the solutions of the Dianping-Trust-Safety team for the META CRAG-MM challenge. The challenge requires building a comprehensive retrieval-augmented generation system capable for multi-modal multi-turn question answering. The competition consists of three tasks: (1) answering questions using structured data retrieved from an image-based mock knowledge graph, (2) synthesizing information from both knowledge graphs and web search results, and (3) handling multi-turn conversations that require context understanding and information aggregation from multiple sources. For Task 1, our solution is based on the vision large language model, enhanced by supervised fine-tuning with knowledge distilled from GPT-4.1. We further applied curriculum learning strategies to guide reinforcement learning, resulting in improved answer accuracy and reduced hallucination. For Task 2 and Task 3, we additionally leveraged web search APIs to incorporate external knowledge, enabling the system to better handle complex queries and multi-turn conversations. Our approach achieved 1st place in Task 1 with a significant lead of 52.38\\%, and 3rd place in Task 3, demonstrating the effectiveness of the integration of curriculum learning with reinforcement learning in our training pipeline.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10337.pdf", "abstract_url": "https://arxiv.org/abs/2508.10337", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "论文描述了Dianping-Trust-Safety团队在META CRAG-MM挑战中的解决方案，该挑战要求构建一个能够进行多模态多轮问答的检索增强生成系统。团队通过结合视觉大语言模型、监督微调、课程学习策略和强化学习，有效提高了答案的准确性和减少了幻觉，最终在任务1中获得第一名，在任务3中获得第三名。", "motivation": "解决在多模态多轮问答中构建一个全面的检索增强生成系统的问题，特别是在处理结构化数据、知识图谱和网络搜索结果的综合信息以及多轮对话中的上下文理解和信息聚合方面。", "method": "结合视觉大语言模型和从GPT-4.1中提取的知识进行监督微调，应用课程学习策略指导强化学习，并在任务2和任务3中额外利用网络搜索API整合外部知识。", "result": "在任务1中以52.38%的显著优势获得第一名，在任务3中获得第三名，证明了课程学习与强化学习结合在训练流程中的有效性。", "conclusion": "通过整合课程学习和强化学习，团队成功构建了一个高效的多模态多轮问答系统，显著提高了答案的准确性和系统的综合性能。"}}
{"id": "2508.10340", "title": "Multi-Agent Trust Region Policy Optimisation: A Joint Constraint Approach", "authors": ["Chak Lam Shek", "Guangyao Shi", "Pratap Tokekar"], "abstract": "Multi-agent reinforcement learning (MARL) requires coordinated and stable policy updates among interacting agents. Heterogeneous-Agent Trust Region Policy Optimization (HATRPO) enforces per-agent trust region constraints using Kullback-Leibler (KL) divergence to stabilize training. However, assigning each agent the same KL threshold can lead to slow and locally optimal updates, especially in heterogeneous settings. To address this limitation, we propose two approaches for allocating the KL divergence threshold across agents: HATRPO-W, a Karush-Kuhn-Tucker-based (KKT-based) method that optimizes threshold assignment under global KL constraints, and HATRPO-G, a greedy algorithm that prioritizes agents based on improvement-to-divergence ratio. By connecting sequential policy optimization with constrained threshold scheduling, our approach enables more flexible and effective learning in heterogeneous-agent settings. Experimental results demonstrate that our methods significantly boost the performance of HATRPO, achieving faster convergence and higher final rewards across diverse MARL benchmarks. Specifically, HATRPO-W and HATRPO-G achieve comparable improvements in final performance, each exceeding 22.5%. Notably, HATRPO-W also demonstrates more stable learning dynamics, as reflected by its lower variance.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10340.pdf", "abstract_url": "https://arxiv.org/abs/2508.10340", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了两种方法（HATRPO-W和HATRPO-G）来分配多智能体强化学习中的KL散度阈值，以解决HATRPO在异构设置中更新缓慢和局部最优的问题。", "motivation": "解决在多智能体强化学习中，由于为每个智能体分配相同的KL散度阈值而导致的训练不稳定、更新缓慢和局部最优的问题。", "method": "提出了两种KL散度阈值分配方法：基于KKT的HATRPO-W和基于贪婪算法的HATRPO-G。", "result": "实验结果表明，这两种方法显著提高了HATRPO的性能，实现了更快的收敛和更高的最终奖励，其中HATRPO-W还表现出更稳定的学习动态。", "conclusion": "通过连接顺序策略优化与约束阈值调度，本文的方法在异构智能体设置中实现了更灵活和有效的学习。"}}
{"id": "2508.10358", "title": "What to Ask Next? Probing the Imaginative Reasoning of LLMs with TurtleSoup Puzzles", "authors": ["Mengtao Zhou", "Sifan Wu", "Huan Zhang", "Qi Sima", "Bang Liu"], "abstract": "We investigate the capacity of Large Language Models (LLMs) for imaginative reasoning--the proactive construction, testing, and revision of hypotheses in information-sparse environments. Existing benchmarks, often static or focused on social deduction, fail to capture the dynamic, exploratory nature of this reasoning process. To address this gap, we introduce a comprehensive research framework based on the classic \"Turtle Soup\" game, integrating a benchmark, an agent, and an evaluation protocol. We present TurtleSoup-Bench, the first large-scale, bilingual, interactive benchmark for imaginative reasoning, comprising 800 turtle soup puzzles sourced from both the Internet and expert authors. We also propose Mosaic-Agent, a novel agent designed to assess LLMs' performance in this setting. To evaluate reasoning quality, we develop a multi-dimensional protocol measuring logical consistency, detail completion, and conclusion alignment. Experiments with leading LLMs reveal clear capability limits, common failure patterns, and a significant performance gap compared to humans. Our work offers new insights into LLMs' imaginative reasoning and establishes a foundation for future research on exploratory agent behavior.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10358.pdf", "abstract_url": "https://arxiv.org/abs/2508.10358", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过引入基于'乌龟汤'游戏的综合研究框架，包括基准、代理和评估协议，首次大规模、双语、互动地评估大型语言模型（LLMs）在信息稀疏环境中的想象推理能力。研究发现，领先的LLMs在此类任务中存在明显的能力限制和常见失败模式，与人类相比存在显著性能差距。", "motivation": "解决现有基准在捕捉动态、探索性想象推理过程中的不足，评估LLMs在信息稀疏环境中的主动假设构建、测试和修订能力。", "method": "引入TurtleSoup-Bench基准和Mosaic-Agent代理，开发多维评估协议，测量逻辑一致性、细节完成度和结论对齐度。", "result": "实验显示，领先的LLMs在想象推理任务中存在能力限制、常见失败模式，与人类相比性能差距显著。", "conclusion": "本研究为LLMs的想象推理能力提供了新见解，为未来探索性代理行为研究奠定了基础。"}}
{"id": "2508.10391", "title": "LeanRAG: Knowledge-Graph-Based Generation with Semantic Aggregation and Hierarchical Retrieval", "authors": ["Yaoze Zhang", "Rong Wu", "Pinlong Cai", "Xiaoman Wang", "Guohang Yan", "Song Mao", "Ding Wang", "Botian Shi"], "abstract": "Retrieval-Augmented Generation (RAG) plays a crucial role in grounding Large Language Models by leveraging external knowledge, whereas the effectiveness is often compromised by the retrieval of contextually flawed or incomplete information. To address this, knowledge graph-based RAG methods have evolved towards hierarchical structures, organizing knowledge into multi-level summaries. However, these approaches still suffer from two critical, unaddressed challenges: high-level conceptual summaries exist as disconnected ``semantic islands'', lacking the explicit relations needed for cross-community reasoning; and the retrieval process itself remains structurally unaware, often degenerating into an inefficient flat search that fails to exploit the graph's rich topology. To overcome these limitations, we introduce LeanRAG, a framework that features a deeply collaborative design combining knowledge aggregation and retrieval strategies. LeanRAG first employs a novel semantic aggregation algorithm that forms entity clusters and constructs new explicit relations among aggregation-level summaries, creating a fully navigable semantic network. Then, a bottom-up, structure-guided retrieval strategy anchors queries to the most relevant fine-grained entities and then systematically traverses the graph's semantic pathways to gather concise yet contextually comprehensive evidence sets. The LeanRAG can mitigate the substantial overhead associated with path retrieval on graphs and minimizes redundant information retrieval. Extensive experiments on four challenging QA benchmarks with different domains demonstrate that LeanRAG significantly outperforming existing methods in response quality while reducing 46\\% retrieval redundancy. Code is available at:", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10391.pdf", "abstract_url": "https://arxiv.org/abs/2508.10391", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "LeanRAG是一个基于知识图谱的检索增强生成框架，通过语义聚合和层次检索解决现有方法中的语义孤岛和检索效率问题。", "motivation": "解决检索增强生成（RAG）中因检索到上下文错误或不完整信息而影响效果的问题，特别是知识图谱方法中存在的语义孤岛和检索效率低下问题。", "method": "采用语义聚合算法构建实体聚类和新的显式关系，形成可导航的语义网络；然后使用自下而上、结构引导的检索策略，系统地遍历图的语义路径以收集证据集。", "result": "在四个不同领域的QA基准测试中，LeanRAG在响应质量上显著优于现有方法，同时减少了46%的检索冗余。", "conclusion": "LeanRAG通过结合知识聚合和检索策略，有效提高了检索增强生成的效率和效果，为知识图谱在RAG中的应用提供了新的思路。"}}
{"id": "2508.10016", "title": "Training-Free Multimodal Large Language Model Orchestration", "authors": ["Tianyu Xie", "Yuhang Wu", "Yongdong Luo", "Jiayi Ji", "Xiawu Zheng"], "abstract": "Different Multimodal Large Language Models (MLLMs) cannot be integrated into a unified multimodal input-output system directly. In previous work, training has been considered as an inevitable component due to challenges in modal alignment, Text-to-Speech efficiency and other integration issues. In this paper, we introduce Multimodal Large Language Model Orchestration, an effective approach for creating interactive multimodal AI systems without additional training. MLLM Orchestration leverages the inherent reasoning capabilities of large language models to coordinate specialized models through explicit workflows, enabling natural multimodal interactions while maintaining modularity, improving interpretability, and significantly enhancing computational efficiency. Our orchestration framework is built upon three key innovations: (1) a central controller LLM that analyzes user inputs and dynamically routes tasks to appropriate specialized models through carefully designed agents; (2) a parallel Text-to-Speech architecture that enables true full-duplex interaction with seamless interruption handling and natural conversational flow; and (3) a cross-modal memory integration system that maintains coherent context across modalities through intelligent information synthesis and retrieval, selectively avoiding unnecessary modality calls in certain scenarios to improve response speed. Extensive evaluations demonstrate that MLLM Orchestration achieves comprehensive multimodal capabilities without additional training, performance improvements of up to 7.8% over traditional jointly-trained approaches on standard benchmarks, reduced latency by 10.3%, and significantly enhanced interpretability through explicit orchestration processes.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10016.pdf", "abstract_url": "https://arxiv.org/abs/2508.10016", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种无需额外训练的多模态大语言模型编排方法，通过利用大语言模型的固有推理能力协调专用模型，实现了自然的多模态交互，同时提高了模块化、可解释性和计算效率。", "motivation": "解决不同多模态大语言模型无法直接集成到统一的多模态输入输出系统中的问题，避免传统方法中必须进行的训练。", "method": "采用中央控制器LLM分析用户输入并通过精心设计的代理动态路由任务到适当的专用模型，实现并行文本到语音架构和跨模态记忆集成系统。", "result": "在标准基准测试中，性能比传统联合训练方法提高了7.8%，延迟减少了10.3%，并通过明确的编排过程显著增强了可解释性。", "conclusion": "MLLM编排框架无需额外训练即可实现全面的多模态能力，提高了交互效率和系统可解释性，为多模态AI系统的发展提供了新方向。"}}
{"id": "2508.10024", "title": "RTTC: Reward-Guided Collaborative Test-Time Compute", "authors": ["J. Pablo Muñoz", "Jinjie Yuan"], "abstract": "Test-Time Compute (TTC) has emerged as a powerful paradigm for enhancing the performance of Large Language Models (LLMs) at inference, leveraging strategies such as Test-Time Training (TTT) and Retrieval-Augmented Generation (RAG). However, the optimal adaptation strategy varies across queries, and indiscriminate application of TTC strategy incurs substantial computational overhead. In this work, we introduce Reward-Guided Test-Time Compute (RTTC), a novel framework that adaptively selects the most effective TTC strategy for each query via a pretrained reward model, maximizing downstream accuracy across diverse domains and tasks. RTTC operates in a distributed server-client architecture, retrieving relevant samples from a remote knowledge base and applying RAG or lightweight fine-tuning on client devices only when necessary. To further mitigate redundant computation, we propose Query-State Caching, which enables the efficient reuse of historical query states at both retrieval and adaptation levels. Extensive experiments across multiple LLMs and benchmarks demonstrate that RTTC consistently achieves superior accuracy compared to vanilla RAG or TTT, validating the necessity of adaptive, reward-guided TTC selection and the potential of RTTC for scalable, high-performance language model adaptation.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10024.pdf", "abstract_url": "https://arxiv.org/abs/2508.10024", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "RTTC是一种通过奖励模型自适应选择最有效测试时计算策略的新框架，旨在最大化不同领域和任务的下游准确性。", "motivation": "解决在大型语言模型推理过程中，无差别应用测试时计算策略导致的计算开销大和性能不最优的问题。", "method": "采用预训练的奖励模型自适应选择每个查询的最有效测试时计算策略，结合分布式服务器-客户端架构和查询状态缓存以减少冗余计算。", "result": "在多个大型语言模型和基准测试上的广泛实验表明，RTTC在准确性上 consistently优于传统的RAG或TTT方法。", "conclusion": "RTTC框架验证了自适应、奖励引导的测试时计算选择的必要性，展示了其在可扩展、高性能语言模型适应方面的潜力。"}}
{"id": "2508.10467", "title": "FIRESPARQL: A LLM-based Framework for SPARQL Query Generation over Scholarly Knowledge Graphs", "authors": ["Xueli Pan", "Victor de Boer", "Jacco van Ossenbruggen"], "abstract": "Question answering over Scholarly Knowledge Graphs (SKGs) remains a challenging task due to the complexity of scholarly content and the intricate structure of these graphs. Large Language Model (LLM) approaches could be used to translate natural language questions (NLQs) into SPARQL queries; however, these LLM-based approaches struggle with SPARQL query generation due to limited exposure to SKG-specific content and the underlying schema. We identified two main types of errors in the LLM-generated SPARQL queries: (i) structural inconsistencies, such as missing or redundant triples in the queries, and (ii) semantic inaccuracies, where incorrect entities or properties are shown in the queries despite a correct query structure. To address these issues, we propose FIRESPARQL, a modular framework that supports fine-tuned LLMs as a core component, with optional context provided via retrieval-augmented generation (RAG) and a SPARQL query correction layer. We evaluate the framework on the SciQA Benchmark using various configurations (zero-shot, zero-shot with RAG, one-shot, fine-tuning, and fine-tuning with RAG) and compare the performance with baseline and state-of-the-art approaches. We measure query accuracy using BLEU and ROUGE metrics, and query result accuracy using relaxed exact match(RelaxedEM), with respect to the gold standards containing the NLQs, SPARQL queries, and the results of the queries. Experimental results demonstrate that fine-tuning achieves the highest overall performance, reaching 0.90 ROUGE-L for query accuracy and 0.85 RelaxedEM for result accuracy on the test set.", "subjects": "Artificial Intelligence (cs.AI); Digital Libraries (cs.DL)", "comments": "Accepted at 17th International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management (IC3K)", "pdf_url": "https://arxiv.org/pdf/2508.10467.pdf", "abstract_url": "https://arxiv.org/abs/2508.10467", "categories": ["Artificial Intelligence (cs.AI)", "Digital Libraries (cs.DL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "FIRESPARQL是一个基于大型语言模型(LLM)的框架，旨在解决学术知识图谱(SKGs)上SPARQL查询生成的挑战，通过微调LLM、检索增强生成(RAG)和SPARQL查询校正层来提高查询的准确性和结果的质量。", "motivation": "解决在学术知识图谱(SKGs)上进行问答时，由于学术内容的复杂性和图谱结构的复杂性，大型语言模型(LLM)在生成SPARQL查询时遇到的结构不一致和语义不准确的问题。", "method": "提出FIRESPARQL框架，该框架支持微调的LLM作为核心组件，可选地通过检索增强生成(RAG)提供上下文，并包含一个SPARQL查询校正层。", "result": "在SciQA基准测试中，通过不同配置（零样本、零样本加RAG、一样本、微调、微调加RAG）评估，微调配置达到了最高的整体性能，查询准确性的ROUGE-L得分为0.90，结果准确性的RelaxedEM得分为0.85。", "conclusion": "FIRESPARQL框架通过结合微调的LLM、RAG和查询校正，显著提高了在学术知识图谱上生成SPARQL查询的准确性和结果的质量，为学术问答系统提供了有效的解决方案。"}}
{"id": "2508.10501", "title": "PASS: Probabilistic Agentic Supernet Sampling for Interpretable and Adaptive Chest X-Ray Reasoning", "authors": ["Yushi Feng", "Junye Du", "Yingying Hong", "Qifan Wang", "Lequan Yu"], "abstract": "Existing tool-augmented agentic systems are limited in the real world by (i) black-box reasoning steps that undermine trust of decision-making and pose safety risks, (ii) poor multimodal integration, which is inherently critical for healthcare tasks, and (iii) rigid and computationally inefficient agentic pipelines. We introduce PASS (Probabilistic Agentic Supernet Sampling), the first multimodal framework to address these challenges in the context of Chest X-Ray (CXR) reasoning. PASS adaptively samples agentic workflows over a multi-tool graph, yielding decision paths annotated with interpretable probabilities. Given the complex CXR reasoning task with multimodal medical data, PASS leverages its learned task-conditioned distribution over the agentic supernet. Thus, it adaptively selects the most suitable tool at each supernet layer, offering probability-annotated trajectories for post-hoc audits and directly enhancing medical AI safety. PASS also continuously compresses salient findings into an evolving personalized memory, while dynamically deciding whether to deepen its reasoning path or invoke an early exit for efficiency. To optimize a Pareto frontier balancing performance and cost, we design a novel three-stage training procedure, including expert knowledge warm-up, contrastive path-ranking, and cost-aware reinforcement learning. To facilitate rigorous evaluation, we introduce CAB-E, a comprehensive benchmark for multi-step, safety-critical, free-form CXR reasoning. Experiments across various benchmarks validate that PASS significantly outperforms strong baselines in multiple metrics (e.g., accuracy, AUC, LLM-J.) while balancing computational costs, pushing a new paradigm shift towards interpretable, adaptive, and multimodal medical agentic systems.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10501.pdf", "abstract_url": "https://arxiv.org/abs/2508.10501", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "PASS（概率代理超级网络采样）是一种多模态框架，旨在解决现有工具增强代理系统在胸部X光（CXR）推理中的局限性，如黑盒推理步骤、多模态集成差和代理管道刚性。PASS通过自适应采样代理工作流程，提供带有可解释概率的决策路径，增强医疗AI的安全性，并在多个基准测试中显著优于基线。", "motivation": "解决现有工具增强代理系统在真实世界应用中的三个主要问题：黑盒推理步骤削弱决策信任并带来安全风险，多模态集成差对医疗任务至关重要，以及代理管道刚性和计算效率低。", "method": "PASS框架通过自适应采样多工具图上的代理工作流程，利用学习到的任务条件分布选择最合适的工具，提供概率注释的轨迹以供后验审计，并通过三阶段训练程序优化性能和成本的帕累托前沿。", "result": "PASS在多个基准测试中显著优于强基线，在准确性、AUC、LLM-J等多个指标上表现优异，同时平衡计算成本。", "conclusion": "PASS推动了向可解释、自适应和多模态医疗代理系统的新范式转变，通过其创新的框架和训练方法，为医疗AI安全性和效率设立了新标准。"}}
{"id": "2508.10745", "title": "Agentic Design Review System", "authors": ["Sayan Nag", "K J Joseph", "Koustava Goswami", "Vlad I Morariu", "Balaji Vasan Srinivasan"], "abstract": "Evaluating graphic designs involves assessing it from multiple facets like alignment, composition, aesthetics and color choices. Evaluating designs in a holistic way involves aggregating feedback from individual expert reviewers. Towards this, we propose an Agentic Design Review System (AgenticDRS), where multiple agents collaboratively analyze a design, orchestrated by a meta-agent. A novel in-context exemplar selection approach based on graph matching and a unique prompt expansion method plays central role towards making each agent design aware. Towards evaluating this framework, we propose DRS-BENCH benchmark. Thorough experimental evaluation against state-of-the-art baselines adapted to the problem setup, backed-up with critical ablation experiments brings out the efficacy of Agentic-DRS in evaluating graphic designs and generating actionable feedback. We hope that this work will attract attention to this pragmatic, yet under-explored research direction.", "subjects": "Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Multiagent Systems (cs.MA); Multimedia (cs.MM)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10745.pdf", "abstract_url": "https://arxiv.org/abs/2508.10745", "categories": ["Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)", "Multimedia (cs.MM)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种名为Agentic设计评审系统（AgenticDRS）的新方法，通过多代理协作分析设计，由元代理协调，采用基于图匹配的上下文示例选择方法和独特的提示扩展方法，使每个代理都能意识到设计。通过DRS-BENCH基准评估，实验证明Agentic-DRS在评估图形设计和生成可操作反馈方面的有效性。", "motivation": "解决图形设计评估中需要从多个方面（如对齐、构图、美学和颜色选择）进行综合评估的问题，以及如何有效聚合个体专家评审的反馈。", "method": "提出了Agentic设计评审系统（AgenticDRS），利用多代理协作分析设计，采用基于图匹配的上下文示例选择方法和独特的提示扩展方法。", "result": "通过DRS-BENCH基准评估，Agentic-DRS在评估图形设计和生成可操作反馈方面显示出优于现有基线方法的效能。", "conclusion": "Agentic-DRS为图形设计评估提供了一个有效的解决方案，希望这项工作能吸引更多关注这一实用但尚未充分探索的研究方向。"}}
{"id": "2508.10769", "title": "Modeling Human Responses to Multimodal AI Content", "authors": ["Zhiqi Shen", "Shaojing Fan", "Danni Xu", "Terence Sim", "Mohan Kankanhalli"], "abstract": "As AI-generated content becomes widespread, so does the risk of misinformation. While prior research has primarily focused on identifying whether content is authentic, much less is known about how such content influences human perception and behavior. In domains like trading or the stock market, predicting how people react (e.g., whether a news post will go viral), can be more critical than verifying its factual accuracy. To address this, we take a human-centered approach and introduce the MhAIM Dataset, which contains 154,552 online posts (111,153 of them AI-generated), enabling large-scale analysis of how people respond to AI-generated content. Our human study reveals that people are better at identifying AI content when posts include both text and visuals, particularly when inconsistencies exist between the two. We propose three new metrics: trustworthiness, impact, and openness, to quantify how users judge and engage with online content. We present T-Lens, an LLM-based agent system designed to answer user queries by incorporating predicted human responses to multimodal information. At its core is HR-MCP (Human Response Model Context Protocol), built on the standardized Model Context Protocol (MCP), enabling seamless integration with any LLM. This integration allows T-Lens to better align with human reactions, enhancing both interpretability and interaction capabilities. Our work provides empirical insights and practical tools to equip LLMs with human-awareness capabilities. By highlighting the complex interplay among AI, human cognition, and information reception, our findings suggest actionable strategies for mitigating the risks of AI-driven misinformation.", "subjects": "Artificial Intelligence (cs.AI); Multimedia (cs.MM)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10769.pdf", "abstract_url": "https://arxiv.org/abs/2508.10769", "categories": ["Artificial Intelligence (cs.AI)", "Multimedia (cs.MM)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过引入MhAIM数据集和T-Lens系统，研究了人类对AI生成内容的反应，提出了量化用户判断和参与度的新指标，并展示了如何通过预测人类反应来增强LLM的人类意识能力。", "motivation": "随着AI生成内容的普及，错误信息的风险也随之增加。现有研究主要集中在识别内容的真实性上，而对内容如何影响人类感知和行为知之甚少。在交易或股票市场等领域，预测人们的反应（例如，新闻帖子是否会走红）可能比验证其事实准确性更为关键。", "method": "作者采用了以人为中心的方法，引入了包含154,552个在线帖子（其中111,153个是AI生成的）的MhAIM数据集，进行了大规模的人类研究，并提出了三个新指标：可信度、影响力和开放性。此外，作者还提出了T-Lens，一个基于LLM的代理系统，通过整合预测的人类反应来回答用户查询。", "result": "人类研究表明，当帖子包含文本和视觉内容时，人们更擅长识别AI内容，尤其是当两者之间存在不一致时。T-Lens系统通过HR-MCP协议与任何LLM无缝集成，能够更好地与人类反应对齐，增强了可解释性和交互能力。", "conclusion": "本研究提供了实证见解和实用工具，使LLM具备人类意识能力。通过强调AI、人类认知和信息接收之间复杂的相互作用，我们的研究结果提出了减轻AI驱动错误信息风险的可操作策略。"}}
{"id": "2508.10833", "title": "UI-Venus Technical Report: Building High-performance UI Agents with RFT", "authors": ["Zhangxuan Gu", "Zhengwen Zeng", "Zhenyu Xu", "Xingran Zhou", "Shuheng Shen", "Yunfei Liu", "Beitong Zhou", "Changhua Meng", "Tianyu Xia", "Weizhi Chen", "Yue Wen", "Jingya Dou", "Fei Tang", "Jinzhen Lin", "Yulin Liu", "Zhenlin Guo", "Yichen Gong", "Heng Jia", "Changlong Gao", "Yuan Guo", "Yong Deng", "Zhenyu Guo", "Liang Chen", "Weiqiang Wang"], "abstract": "We present UI-Venus, a native UI agent that takes only screenshots as input based on a multimodal large language model. UI-Venus achieves SOTA performance on both UI grounding and navigation tasks using only several hundred thousand high-quality training samples through reinforcement finetune (RFT) based on Qwen2.5-VL. Specifically, the 7B and 72B variants of UI-Venus obtain 94.1% / 50.8% and 95.3% / 61.9% on the standard grounding benchmarks, i.e., Screenspot-V2 / Pro, surpassing the previous SOTA baselines including open-source GTA1 and closed-source", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10833.pdf", "abstract_url": "https://arxiv.org/abs/2508.10833", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "UI-Venus是一个基于多模态大语言模型的本地UI代理，仅以截图作为输入，通过基于Qwen2.5-VL的强化微调（RFT）方法，在UI接地和导航任务上实现了SOTA性能。", "motivation": "解决UI代理在仅使用截图作为输入时的高性能需求问题，特别是在UI接地和导航任务上的表现。", "method": "使用基于Qwen2.5-VL的强化微调（RFT）方法，仅需数十万高质量训练样本。", "result": "UI-Venus的7B和72B变体在标准接地基准测试Screenspot-V2/Pro上分别达到了94.1%/50.8%和95.3%/61.9%，超越了包括开源GTA1和闭源在内的先前SOTA基线。", "conclusion": "UI-Venus展示了通过RFT方法在有限的高质量训练样本下，能够构建出高性能的UI代理，为UI交互领域提供了新的解决方案。"}}
{"id": "2508.10419", "title": "ComoRAG: A Cognitive-Inspired Memory-Organized RAG for Stateful Long Narrative Reasoning", "authors": ["Juyuan Wang", "Rongchen Zhao", "Wei Wei", "Yufeng Wang", "Mo Yu", "Jie Zhou", "Jin Xu", "Liyan Xu"], "abstract": "Narrative comprehension on long stories and novels has been a challenging domain attributed to their intricate plotlines and entangled, often evolving relations among characters and entities. Given the LLM's diminished reasoning over extended context and high computational cost, retrieval-based approaches remain a pivotal role in practice. However, traditional RAG methods can fall short due to their stateless, single-step retrieval process, which often overlooks the dynamic nature of capturing interconnected relations within long-range context. In this work, we propose ComoRAG, holding the principle that narrative reasoning is not a one-shot process, but a dynamic, evolving interplay between new evidence acquisition and past knowledge consolidation, analogous to human cognition when reasoning with memory-related signals in the brain. Specifically, when encountering a reasoning impasse, ComoRAG undergoes iterative reasoning cycles while interacting with a dynamic memory workspace. In each cycle, it generates probing queries to devise new exploratory paths, then integrates the retrieved evidence of new aspects into a global memory pool, thereby supporting the emergence of a coherent context for the query resolution. Across four challenging long-context narrative benchmarks (200K+ tokens), ComoRAG outperforms strong RAG baselines with consistent relative gains up to 11% compared to the strongest baseline. Further analysis reveals that ComoRAG is particularly advantageous for complex queries requiring global comprehension, offering a principled, cognitively motivated paradigm for retrieval-based long context comprehension towards stateful reasoning. Our code is publicly released at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10419.pdf", "abstract_url": "https://arxiv.org/abs/2508.10419", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "ComoRAG是一种受认知启发的记忆组织RAG方法，用于状态化长叙事推理，通过动态记忆工作空间和迭代推理循环，有效解决长故事和小说中的复杂情节和角色关系理解问题。", "motivation": "解决长故事和小说叙事理解中的复杂情节和动态角色关系问题，传统RAG方法因无状态、单步检索过程而难以捕捉长范围上下文中的动态关系。", "method": "提出ComoRAG，模拟人类认知过程中的记忆相关信号推理，通过迭代推理循环与动态记忆工作空间交互，生成探测查询并整合新证据到全局记忆池中。", "result": "在四个挑战性的长上下文叙事基准测试（200K+ tokens）中，ComoRAG比最强的RAG基线表现优异，相对增益高达11%，特别适合需要全局理解的复杂查询。", "conclusion": "ComoRAG为基于检索的长上下文理解提供了一个有原则、受认知启发的范式，支持状态化推理，特别是在需要全局理解的复杂查询中表现出优势。"}}
{"id": "2508.10333", "title": "ReconVLA: Reconstructive Vision-Language-Action Model as Effective Robot Perceiver", "authors": ["Wenxuan Song", "Ziyang Zhou", "Han Zhao", "Jiayi Chen", "Pengxiang Ding", "Haodong Yan", "Yuxin Huang", "Feilong Tang", "Donglin Wang", "Haoang Li"], "abstract": "Recent advances in Vision-Language-Action (VLA) models have enabled robotic agents to integrate multimodal understanding with action execution. However, our empirical analysis reveals that current VLAs struggle to allocate visual attention to target regions. Instead, visual attention is always dispersed. To guide the visual attention grounding on the correct target, we propose ReconVLA, a reconstructive VLA model with an implicit grounding paradigm. Conditioned on the model's visual outputs, a diffusion transformer aims to reconstruct the gaze region of the image, which corresponds to the target manipulated objects. This process prompts the VLA model to learn fine-grained representations and accurately allocate visual attention, thus effectively leveraging task-specific visual information and conducting precise manipulation. Moreover, we curate a large-scale pretraining dataset comprising over 100k trajectories and 2 million data samples from open-source robotic datasets, further boosting the model's generalization in visual reconstruction. Extensive experiments in simulation and the real world demonstrate the superiority of our implicit grounding method, showcasing its capabilities of precise manipulation and generalization. Our project page is", "subjects": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10333.pdf", "abstract_url": "https://arxiv.org/abs/2508.10333", "categories": ["Robotics (cs.RO)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了ReconVLA，一种重建性的视觉-语言-动作模型，旨在解决当前VLA模型在视觉注意力分配上的不足，通过隐式接地范式引导视觉注意力集中在正确的目标区域。", "motivation": "当前的视觉-语言-动作模型在分配视觉注意力到目标区域方面存在困难，视觉注意力往往分散。为了解决这一问题，本文提出了ReconVLA模型。", "method": "提出了一种重建性的VLA模型，通过扩散变换器重建图像的注视区域，对应于操作的目标物体，从而引导模型学习细粒度表示并准确分配视觉注意力。", "result": "在模拟和现实世界的广泛实验中，ReconVLA展示了其在精确操作和泛化能力上的优越性。", "conclusion": "ReconVLA通过隐式接地范式有效提升了VLA模型在视觉注意力分配和目标操作上的性能，为机器人感知器的发展提供了新的方向。"}}
{"id": "2508.10426", "title": "Computational Economics in Large Language Models: Exploring Model Behavior and Incentive Design under Resource Constraints", "authors": ["Sandeep Reddy", "Kabir Khan", "Rohit Patil", "Ananya Chakraborty", "Faizan A. Khan", "Swati Kulkarni", "Arjun Verma", "Neha Singh"], "abstract": "Large language models (LLMs) are limited by substantial computational cost. We introduce a \"computational economics\" framework that treats an LLM as an internal economy of resource-constrained agents (attention heads and neuron blocks) that must allocate scarce computation to maximize task utility. First, we show empirically that when computation is scarce, standard LLMs reallocate attention toward high-value tokens while preserving accuracy. Building on this observation, we propose an incentive-driven training paradigm that augments the task loss with a differentiable computation cost term, encouraging sparse and efficient activations. On GLUE (MNLI, STS-B, CoLA) and WikiText-103, the method yields a family of models that trace a Pareto frontier and consistently dominate post-hoc pruning; for a similar accuracy we obtain roughly a forty percent reduction in FLOPS and lower latency, together with more interpretable attention patterns. These results indicate that economic principles offer a principled route to designing efficient, adaptive, and more transparent LLMs under strict resource constraints.", "subjects": "Computation and Language (cs.CL)", "comments": "Preprint; 7 figures, 4 tables, 1 algorithm. Experiments on GLUE (MNLI, STS-B, CoLA) and WikiText-103 with BERT-base; evaluation includes FLOPS, latency, Gini and entropy metrics", "pdf_url": "https://arxiv.org/pdf/2508.10426.pdf", "abstract_url": "https://arxiv.org/abs/2508.10426", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一个'计算经济学'框架，将大型语言模型（LLMs）视为资源受限的代理（注意力头和神经元块）的内部经济，旨在最大化任务效用。通过实证显示，在计算资源稀缺时，标准LLMs会重新分配注意力至高价值令牌，同时保持准确性。作者提出了一种激励驱动的训练范式，通过增加可微分计算成本项来鼓励稀疏和高效的激活，从而在GLUE和WikiText-103上实现了一系列模型，这些模型在保持相似准确性的同时，显著减少了计算量和延迟，并提供了更可解释的注意力模式。", "motivation": "解决大型语言模型（LLMs）因高计算成本而受限的问题，探索在资源约束下模型行为和激励设计的优化方法。", "method": "引入'计算经济学'框架，将LLMs视为资源受限的代理内部经济，提出激励驱动的训练范式，通过增加可微分计算成本项来优化模型。", "result": "在GLUE（MNLI, STS-B, CoLA）和WikiText-103上，该方法产生了一系列模型，这些模型在保持相似准确性的同时，实现了约40%的计算量减少和更低的延迟，同时提供了更可解释的注意力模式。", "conclusion": "经济原则为在严格资源约束下设计高效、自适应且更透明的大型语言模型提供了原则性路径。"}}
{"id": "2508.10695", "title": "Learning from Natural Language Feedback for Personalized Question Answering", "authors": ["Alireza Salemi", "Hamed Zamani"], "abstract": "Personalization is crucial for enhancing both the effectiveness and user satisfaction of language technologies, particularly in information-seeking tasks like question answering. Current approaches for personalizing large language models (LLMs) often rely on retrieval-augmented generation (RAG), followed by reinforcement learning with scalar reward signals to teach models how to use retrieved personal context. We believe that these scalar rewards sometimes provide weak, non-instructive feedback, limiting learning efficiency and personalization quality. We introduce VAC, a novel framework for personalized response generation that replaces scalar rewards with natural language feedback (NLF) that are generated conditioned on the user profiles and the question narratives. NLF serves as a rich and actionable supervision signal, allowing the policy model to iteratively refine its outputs and internalize effective personalization strategies. Training alternates between optimizing the feedback model and fine-tuning the policy model on the improved responses, resulting in a policy model that no longer requires feedback at inference. Evaluation on the LaMP-QA benchmark that consists of three diverse domains demonstrates consistent and significant improvements over the state-of-the-art results. Human evaluations further confirm the superior quality of the generated responses. These results demonstrate that NLF provides more effective signals for optimizing personalized question answering.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10695.pdf", "abstract_url": "https://arxiv.org/abs/2508.10695", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种名为VAC的新框架，通过使用自然语言反馈（NLF）替代标量奖励，来优化个性化问答系统中的响应生成，显著提高了个性化质量和学习效率。", "motivation": "当前个性化大型语言模型（LLMs）的方法主要依赖于检索增强生成（RAG）和标量奖励信号的强化学习，这些标量奖励提供的反馈较弱且非指导性，限制了学习效率和个性化质量。", "method": "引入VAC框架，利用基于用户画像和问题叙述生成的自然语言反馈（NLF）作为丰富且可操作的监督信号，通过交替优化反馈模型和在改进响应上微调策略模型，训练出不需推理时反馈的策略模型。", "result": "在包含三个不同领域的LaMP-QA基准测试中，VAC框架相比现有技术成果展现出一致且显著的改进，人类评估也证实了生成响应的优越质量。", "conclusion": "自然语言反馈（NLF）为优化个性化问答提供了更有效的信号，证明了其在提高个性化问答系统性能方面的潜力。"}}
{"id": "2508.10839", "title": "Reinforced Language Models for Sequential Decision Making", "authors": ["Jim Dilkes", "Vahid Yazdanpanah", "Sebastian Stein"], "abstract": "Large Language Models (LLMs) show potential as sequential decision-making agents, but their application is often limited due to a reliance on large, computationally expensive models. This creates a need to improve smaller models, yet existing post-training methods are designed for single-turn interactions and cannot handle credit assignment in multi-step agentic tasks. To address this, we introduce Multi-Step Group-Relative Policy Optimization (MS-GRPO), a new algorithm for post-training LLM agents, grounded in formal Text-Mediated Stochastic Game (TSMG) and Language-Agent Policy (LAP) frameworks. For credit assignment, MS-GRPO attributes the entire cumulative episode reward to each individual episode step. We supplement this algorithm with a novel absolute-advantage-weighted episode sampling strategy that we show improves training performance. We evaluate our approach by post-training a 3-billion parameter model on Snake and Frozen Lake. Our experiments demonstrate that the method is effective in improving decision-making performance: our post-trained 3B parameter model outperforms a 72B parameter baseline by 50% on the Frozen Lake task. This work demonstrates that targeted post-training is a practical and efficient alternative to relying on model scale for creating sequential decision-making agents using LLMs.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10839.pdf", "abstract_url": "https://arxiv.org/abs/2508.10839", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了MS-GRPO算法，一种用于后训练大型语言模型（LLMs）作为顺序决策代理的新方法，旨在解决小模型在多步代理任务中的信用分配问题。通过在Snake和Frozen Lake任务上的实验，证明了该方法能有效提升决策性能。", "motivation": "大型语言模型（LLMs）作为顺序决策代理的潜力受到大模型计算成本高的限制，现有后训练方法无法处理多步代理任务中的信用分配问题。", "method": "提出了基于文本介导的随机游戏（TSMG）和语言代理策略（LAP）框架的多步组相对策略优化（MS-GRPO）算法，并辅以绝对优势加权的剧集采样策略。", "result": "实验表明，后训练的30亿参数模型在Frozen Lake任务上比720亿参数的基线模型性能高出50%。", "conclusion": "针对性的后训练是创建顺序决策代理的实用且高效的方法，减少了对模型规模的依赖。"}}
{"id": "2508.10874", "title": "SSRL: Self-Search Reinforcement Learning", "authors": ["Yuchen Fan", "Kaiyan Zhang", "Heng Zhou", "Yuxin Zuo", "Yanxu Chen", "Yu Fu", "Xinwei Long", "Xuekai Zhu", "Che Jiang", "Yuchen Zhang", "Li Kang", "Gang Chen", "Cheng Huang", "Zhizhou He", "Bingning Wang", "Lei Bai", "Ning Ding", "Bowen Zhou"], "abstract": "We investigate the potential of large language models (LLMs) to serve as efficient simulators for agentic search tasks in reinforcement learning (RL), thereby reducing dependence on costly interactions with external search engines. To this end, we first quantify the intrinsic search capability of LLMs via structured prompting and repeated sampling, which we term Self-Search. Our results reveal that LLMs exhibit strong scaling behavior with respect to the inference budget, achieving high pass@k on question-answering benchmarks, including the challenging BrowseComp task. Building on these observations, we introduce Self-Search RL (SSRL), which enhances LLMs' Self-Search capability through format-based and rule-based rewards. SSRL enables models to iteratively refine their knowledge utilization internally, without requiring access to external tools. Empirical evaluations demonstrate that SSRL-trained policy models provide a cost-effective and stable environment for search-driven RL training, reducing reliance on external search engines and facilitating robust sim-to-real transfer. We draw the following conclusions: 1) LLMs possess world knowledge that can be effectively elicited to achieve high performance; 2) SSRL demonstrates the potential of leveraging internal knowledge to reduce hallucination; 3) SSRL-trained models integrate seamlessly with external search engines without additional effort. Our findings highlight the potential of LLMs to support more scalable RL agent training.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10874.pdf", "abstract_url": "https://arxiv.org/abs/2508.10874", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文研究了大型语言模型（LLMs）作为强化学习（RL）中代理搜索任务的高效模拟器的潜力，以减少对外部搜索引擎的依赖。通过自我搜索（Self-Search）和SSRL方法，LLMs能够内部迭代优化知识利用，无需外部工具。", "motivation": "减少强化学习训练中对昂贵外部搜索引擎交互的依赖，探索LLMs内在的搜索能力。", "method": "通过结构化提示和重复采样量化LLMs的自我搜索能力，并引入SSRL方法，通过基于格式和规则的奖励增强LLMs的自我搜索能力。", "result": "LLMs展现出强大的扩展性，在问答基准测试中取得高pass@k，SSRL训练的模型为搜索驱动的RL训练提供了成本效益高且稳定的环境。", "conclusion": "LLMs能够有效利用世界知识实现高性能，SSRL展示了利用内部知识减少幻觉的潜力，且SSRL训练的模型无需额外努力即可与外部搜索引擎无缝集成。"}}
{"id": "2508.10068", "title": "SaraCoder: Orchestrating Semantic and Structural Cues for Profit-Oriented Repository-Level Code Completion", "authors": ["Xiaohan Chen", "Zhongying Pan", "Quan Feng", "Yu Tian", "Shuqun Yang", "Mengru Wang", "Lina Gong", "Yuxia Geng", "Piji Li", "Xiang Chen"], "abstract": "Retrieval-augmented generation (RAG) for repository-level code completion commonly relies on superficial text similarity, leading to results plagued by semantic misguidance, redundancy, and homogeneity, while also failing to resolve external symbol ambiguity. To address these challenges, we introduce Saracoder, a Hierarchical Feature-Optimized retrieval framework. Its core Hierarchical Feature Optimization module systematically refines candidates by distilling deep semantic relationships, pruning exact duplicates, assessing structural similarity with a novel graph-based metric that weighs edits by their topological importance, and reranking results to maximize both relevance and diversity. Furthermore, an External-Aware Identifier Disambiguator module accurately resolves cross-file symbol ambiguity via dependency analysis. Extensive experiments on the challenging CrossCodeEval and RepoEval-Updated benchmarks demonstrate that Saracoder significantly outperforms existing baselines across multiple programming languages and models. Our work proves that systematically refining retrieval results across multiple dimensions provides a new paradigm for building more accurate and robust repository-level code completion systems.", "subjects": "Software Engineering (cs.SE); Computation and Language (cs.CL); Information Retrieval (cs.IR); Programming Languages (cs.PL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10068.pdf", "abstract_url": "https://arxiv.org/abs/2508.10068", "categories": ["Software Engineering (cs.SE)", "Computation and Language (cs.CL)", "Information Retrieval (cs.IR)", "Programming Languages (cs.PL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "Saracoder是一个层次特征优化的检索框架，用于解决存储库级别代码补全中的语义误导、冗余和同质性问题，通过深度语义关系提炼、结构相似性评估和外部符号消歧，显著提高了代码补全的准确性和鲁棒性。", "motivation": "存储库级别代码补全中，基于检索增强生成（RAG）的方法通常依赖于表面的文本相似性，导致结果存在语义误导、冗余和同质性，以及无法解决外部符号歧义的问题。", "method": "Saracoder引入了一个层次特征优化模块，通过提炼深度语义关系、修剪完全重复项、使用基于图的新颖度量评估结构相似性，并根据拓扑重要性加权编辑，以及重新排名结果以最大化相关性和多样性。此外，还通过依赖分析准确解析跨文件符号歧义。", "result": "在CrossCodeEval和RepoEval-Updated基准测试上的广泛实验表明，Saracoder在多种编程语言和模型中显著优于现有基线。", "conclusion": "Saracoder通过在多维度上系统化地优化检索结果，为构建更准确和鲁棒的存储库级别代码补全系统提供了新的范例。"}}
{"id": "2508.10052", "title": "NetMoniAI: An Agentic AI Framework for Network Security & Monitoring", "authors": ["Pallavi Zambare", "Venkata Nikhil Thanikella", "Nikhil Padmanabh Kottur", "Sree Akhil Akula", "Ying Liu"], "abstract": "In this paper, we present NetMoniAI, an agentic AI framework for automatic network monitoring and security that integrates decentralized analysis with lightweight centralized coordination. The framework consists of two layers: autonomous micro-agents at each node perform local traffic analysis and anomaly detection. A central controller then aggregates insights across nodes to detect coordinated attacks and maintain system-wide situational awareness. We evaluated NetMoniAI on a local micro-testbed and through NS-3 simulations. Results confirm that the two-tier agentic-AI design scales under resource constraints, reduces redundancy, and improves response time without compromising accuracy. To facilitate broader adoption and reproducibility, the complete framework is available as open source. This enables researchers and practitioners to replicate, validate, and extend it across diverse network environments and threat scenarios. Github link:", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": "Accepted in IEEE 3rd International Conference on Artificial Intelligence, Blockchain, and Internet of Things (AIBThings 2025)", "pdf_url": "https://arxiv.org/pdf/2508.10052.pdf", "abstract_url": "https://arxiv.org/abs/2508.10052", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了NetMoniAI，一个用于自动网络监控和安全的代理AI框架，结合了分散分析和轻量级集中协调。", "motivation": "解决网络监控和安全中的自动化、扩展性和资源限制问题。", "method": "采用两层级设计：节点上的自主微代理进行本地流量分析和异常检测，中央控制器聚合节点洞察以检测协调攻击。", "result": "评估显示，该设计在资源限制下可扩展，减少冗余，提高响应时间而不影响准确性。", "conclusion": "NetMoniAI框架作为开源项目，促进了更广泛的采用和可重复性，支持跨不同网络环境和威胁场景的复制、验证和扩展。"}}
{"id": "2508.10880", "title": "Searching for Privacy Risks in LLM Agents via Simulation", "authors": ["Yanzhe Zhang", "Diyi Yang"], "abstract": "The widespread deployment of LLM-based agents is likely to introduce a critical privacy threat: malicious agents that proactively engage others in multi-turn interactions to extract sensitive information. These dynamic dialogues enable adaptive attack strategies that can cause severe privacy violations, yet their evolving nature makes it difficult to anticipate and discover sophisticated vulnerabilities manually. To tackle this problem, we present a search-based framework that alternates between improving attacker and defender instructions by simulating privacy-critical agent interactions. Each simulation involves three roles: data subject, data sender, and data recipient. While the data subject's behavior is fixed, the attacker (data recipient) attempts to extract sensitive information from the defender (data sender) through persistent and interactive exchanges. To explore this interaction space efficiently, our search algorithm employs LLMs as optimizers, using parallel search with multiple threads and cross-thread propagation to analyze simulation trajectories and iteratively propose new instructions. Through this process, we find that attack strategies escalate from simple direct requests to sophisticated multi-turn tactics such as impersonation and consent forgery, while defenses advance from rule-based constraints to identity-verification state machines. The discovered attacks and defenses transfer across diverse scenarios and backbone models, demonstrating strong practical utility for building privacy-aware agents.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "Preprint", "pdf_url": "https://arxiv.org/pdf/2508.10880.pdf", "abstract_url": "https://arxiv.org/abs/2508.10880", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于搜索的框架，通过模拟隐私关键的代理交互来发现LLM代理中的隐私风险，展示了攻击策略从简单请求到复杂多轮战术的升级，以及防御措施的进步。", "motivation": "解决LLM基础代理广泛部署可能带来的隐私威胁，特别是恶意代理通过多轮交互提取敏感信息的问题。", "method": "采用搜索框架，通过模拟涉及数据主体、数据发送者和数据接收者的隐私关键代理交互，利用LLM作为优化器进行并行搜索和多线程交叉传播，迭代提出新指令。", "result": "发现攻击策略从直接请求升级到如冒充和伪造同意等复杂多轮战术，防御措施从基于规则的约束发展到身份验证状态机。", "conclusion": "发现的攻击和防御策略在不同场景和骨干模型中具有转移能力，对于构建隐私意识代理具有实际应用价值。"}}
{"id": "2508.10043", "title": "Securing Agentic AI: Threat Modeling and Risk Analysis for Network Monitoring Agentic AI System", "authors": ["Pallavi Zambare", "Venkata Nikhil Thanikella", "Ying Liu"], "abstract": "When combining Large Language Models (LLMs) with autonomous agents, used in network monitoring and decision-making systems, this will create serious security issues. In this research, the MAESTRO framework consisting of the seven layers threat modeling architecture in the system was used to expose, evaluate, and eliminate vulnerabilities of agentic AI. The prototype agent system was constructed and implemented, using Python, LangChain, and telemetry in WebSockets, and deployed with inference, memory, parameter tuning, and anomaly detection modules. Two practical threat cases were confirmed as follows: (i) resource denial of service by traffic replay denial-of-service, and (ii) memory poisoning by tampering with the historical log file maintained by the agent. These situations resulted in measurable levels of performance degradation, i.e. telemetry updates were delayed, and computational loads were increased, as a result of poor system adaptations. It was suggested to use a multilayered defense-in-depth approach with memory isolation, validation of planners and anomaly response systems in real-time. These findings verify that MAESTRO is viable in operational threat mapping, prospective risk scoring, and the basis of the resilient system design. The authors bring attention to the importance of the enforcement of memory integrity, paying attention to the adaptation logic monitoring, and cross-layer communication protection that guarantee the agentic AI reliability in adversarial settings.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": "Submitted and under review in IEEE Transactions on Privacy", "pdf_url": "https://arxiv.org/pdf/2508.10043.pdf", "abstract_url": "https://arxiv.org/abs/2508.10043", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本研究探讨了将大型语言模型（LLMs）与自主代理结合用于网络监控和决策系统时引发的安全问题，提出了MAESTRO框架进行威胁建模和风险分析，并通过原型系统验证了其有效性。", "motivation": "结合大型语言模型（LLMs）和自主代理用于网络监控和决策系统会引发严重的安全问题，需要有效的威胁建模和风险分析方法来识别和消除这些漏洞。", "method": "使用MAESTRO框架，一个包含七层威胁建模架构的系统，来暴露、评估和消除代理AI的漏洞。构建并实现了一个原型代理系统，使用了Python、LangChain和WebSockets的遥测技术，并部署了推理、内存、参数调整和异常检测模块。", "result": "确认了两个实际的威胁案例：（i）通过流量重放拒绝服务导致的资源拒绝服务，（ii）通过篡改代理维护的历史日志文件导致的内存中毒。这些情况导致了可测量的性能下降，如遥测更新延迟和计算负载增加。建议采用多层深度防御方法，包括内存隔离、规划者验证和实时异常响应系统。", "conclusion": "MAESTRO框架在操作威胁映射、前瞻性风险评分和弹性系统设计基础方面是可行的。研究强调了内存完整性执行、适应逻辑监控和跨层通信保护的重要性，以确保代理AI在对抗性环境中的可靠性。"}}
{"id": "2508.10409", "title": "AnalogSeeker: An Open-source Foundation Language Model for Analog Circuit Design", "authors": ["Zihao Chen", "Ji Zhuang", "Jinyi Shen", "Xiaoyue Ke", "Xinyi Yang", "Mingjie Zhou", "Zhuoyao Du", "Xu Yan", "Zhouyang Wu", "Zhenyu Xu", "Jiangli Huang", "Li Shang", "Xuan Zeng", "Fan Yang"], "abstract": "In this paper, we propose AnalogSeeker, an effort toward an open-source foundation language model for analog circuit design, with the aim of integrating domain knowledge and giving design assistance. To overcome the scarcity of data in this field, we employ a corpus collection strategy based on the domain knowledge framework of analog circuits. High-quality, accessible textbooks across relevant subfields are systematically curated and cleaned into a textual domain corpus. To address the complexity of knowledge of analog circuits, we introduce a granular domain knowledge distillation method. Raw, unlabeled domain corpus is decomposed into typical, granular learning nodes, where a multi-agent framework distills implicit knowledge embedded in unstructured text into question-answer data pairs with detailed reasoning processes, yielding a fine-grained, learnable dataset for fine-tuning. To address the unexplored challenges in training analog circuit foundation models, we explore and share our training methods through both theoretical analysis and experimental validation. We finally establish a fine-tuning-centric training paradigm, customizing and implementing a neighborhood self-constrained supervised fine-tuning algorithm. This approach enhances training outcomes by constraining the perturbation magnitude between the model's output distributions before and after training. In practice, we train the Qwen2.5-32B-Instruct model to obtain AnalogSeeker, which achieves 85.04% accuracy on AMSBench-TQA, the analog circuit knowledge evaluation benchmark, with a 15.67% point improvement over the original model and is competitive with mainstream commercial models. Furthermore, AnalogSeeker also shows effectiveness in the downstream operational amplifier design task. AnalogSeeker is open-sourced at", "subjects": "Hardware Architecture (cs.AR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10409.pdf", "abstract_url": "https://arxiv.org/abs/2508.10409", "categories": ["Hardware Architecture (cs.AR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了AnalogSeeker，一个面向模拟电路设计的开源基础语言模型，旨在整合领域知识并提供设计辅助。通过领域知识蒸馏方法和定制化的训练范式，该模型在模拟电路知识评估基准上取得了显著性能提升。", "motivation": "解决模拟电路设计领域数据稀缺和知识复杂性的问题，提供一个开源的基础语言模型以辅助设计。", "method": "采用基于领域知识框架的语料收集策略，引入细粒度领域知识蒸馏方法，以及定制化的邻域自约束监督微调算法。", "result": "AnalogSeeker在AMSBench-TQA基准测试中达到85.04%的准确率，比原模型提高了15.67个百分点，并在下游运算放大器设计任务中显示出有效性。", "conclusion": "AnalogSeeker作为一个开源的基础语言模型，不仅提高了模拟电路设计的效率和质量，还为该领域的进一步研究和发展提供了宝贵的资源。"}}
{"id": "2508.10494", "title": "A Unified Multi-Agent Framework for Universal Multimodal Understanding and Generation", "authors": ["Jiulin Li", "Ping Huang", "Yexin Li", "Shuo Chen", "Juewen Hu", "Ye Tian"], "abstract": "Real-world multimodal applications often require any-to-any capabilities, enabling both understanding and generation across modalities including text, image, audio, and video. However, integrating the strengths of autoregressive language models (LLMs) for reasoning and diffusion models for high-fidelity generation remains challenging. Existing approaches rely on rigid pipelines or tightly coupled architectures, limiting flexibility and scalability. We propose MAGUS (Multi-Agent Guided Unified Multimodal System), a modular framework that unifies multimodal understanding and generation via two decoupled phases: Cognition and Deliberation. MAGUS enables symbolic multi-agent collaboration within a shared textual workspace. In the Cognition phase, three role-conditioned multimodal LLM agents - Perceiver, Planner, and Reflector - engage in collaborative dialogue to perform structured understanding and planning. The Deliberation phase incorporates a Growth-Aware Search mechanism that orchestrates LLM-based reasoning and diffusion-based generation in a mutually reinforcing manner. MAGUS supports plug-and-play extensibility, scalable any-to-any modality conversion, and semantic alignment - all without the need for joint training. Experiments across multiple benchmarks, including image, video, and audio generation, as well as cross-modal instruction following, demonstrate that MAGUS outperforms strong baselines and state-of-the-art systems. Notably, on the MME benchmark, MAGUS surpasses the powerful closed-source model GPT-4o.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "8 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2508.10494.pdf", "abstract_url": "https://arxiv.org/abs/2508.10494", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "MAGUS是一个统一的多模态理解和生成框架，通过解耦的认知和审议阶段，实现了跨模态的灵活转换和语义对齐，无需联合训练。", "motivation": "解决现实世界多模态应用中任意到任意能力的集成挑战，特别是结合自回归语言模型的推理能力和扩散模型的高保真生成能力。", "method": "提出MAGUS框架，采用模块化设计，通过认知阶段的角色条件多模态LLM代理和审议阶段的增长感知搜索机制，实现多模态理解和生成。", "result": "在多个基准测试中，MAGUS在图像、视频和音频生成以及跨模态指令跟随方面优于强基线和最先进系统，特别是在MME基准上超越了GPT-4o。", "conclusion": "MAGUS框架展示了在无需联合训练的情况下，实现高效、灵活和可扩展的多模态理解和生成的潜力，为未来的多模态应用提供了新的方向。"}}
{"id": "2508.10423", "title": "MASH: Cooperative-Heterogeneous Multi-Agent Reinforcement Learning for Single Humanoid Robot Locomotion", "authors": ["Qi Liu", "Xiaopeng Zhang", "Mingshan Tan", "Shuaikang Ma", "Jinliang Ding", "Yanjie Li"], "abstract": "This paper proposes a novel method to enhance locomotion for a single humanoid robot through cooperative-heterogeneous multi-agent deep reinforcement learning (MARL). While most existing methods typically employ single-agent reinforcement learning algorithms for a single humanoid robot or MARL algorithms for multi-robot system tasks, we propose a distinct paradigm: applying cooperative-heterogeneous MARL to optimize locomotion for a single humanoid robot. The proposed method, multi-agent reinforcement learning for single humanoid locomotion (MASH), treats each limb (legs and arms) as an independent agent that explores the robot's action space while sharing a global critic for cooperative learning. Experiments demonstrate that MASH accelerates training convergence and improves whole-body cooperation ability, outperforming conventional single-agent reinforcement learning methods. This work advances the integration of MARL into single-humanoid-robot control, offering new insights into efficient locomotion strategies.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Systems and Control (eess.SY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10423.pdf", "abstract_url": "https://arxiv.org/abs/2508.10423", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Systems and Control (eess.SY)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新颖的方法，通过协作异构多智能体深度强化学习（MARL）来增强单个仿人机器人的运动能力。与现有方法通常使用单智能体强化学习算法或MARL算法于多机器人系统任务不同，我们提出了一种独特的范式：应用协作异构MARL来优化单个仿人机器人的运动。所提出的方法MASH将每个肢体（腿和手臂）视为独立的智能体，探索机器人的动作空间，同时共享一个全局批评者进行协作学习。实验表明，MASH加速了训练收敛，提高了全身协作能力，优于传统的单智能体强化学习方法。", "motivation": "解决单个仿人机器人运动优化的问题，传统方法通常使用单智能体强化学习或MARL于多机器人系统，而本方法提出了一种新的协作异构MARL应用于单个机器人。", "method": "提出MASH方法，将每个肢体视为独立智能体，共享全局批评者进行协作学习。", "result": "MASH加速了训练收敛，提高了全身协作能力，优于传统单智能体强化学习方法。", "conclusion": "本工作推进了MARL在单个仿人机器人控制中的应用，为高效运动策略提供了新的见解。"}}
{"id": "2508.10701", "title": "REFN: A Reinforcement-Learning-From-Network Framework against 1-day/n-day Exploitations", "authors": ["Tianlong Yu", "Lihong Liu", "Ziyi Zhou", "Fudu Xing", "Kailong Wang", "Yang Yang"], "abstract": "The exploitation of 1 day or n day vulnerabilities poses severe threats to networked devices due to massive deployment scales and delayed patching (average Mean Time To Patch exceeds 60 days). Existing defenses, including host based patching and network based filtering, are inadequate due to limited scalability across diverse devices, compatibility issues especially with embedded or legacy systems, and error prone deployment process (manual patch validation). To address these issues, we introduce REFN (Reinforcement Learning From Network), a novel framework that trains Large Language Models (LLMs) to autonomously generate network filters to prevent 1 day or n day exploitations. REFN ensures scalability by uniquely employs Reinforcement Learning (RL) driven by online network rewards instead of traditional Human Feedback (RLHF). REFN guarantees compatibility via unified deployment on edge security gateways (Amazon Eero). REFN provides robustness via online validation using real network traffic. Crucially, REFN addresses three core challenges in training LLMs for exploit prevention: 1) expanding current LLMs limited vulnerability fixing expertise via Agentic RAG based Knowledge Distillation, 2) bridging current LLMs language to network gaps through an RL From VNF Pipeline that translates language context (vulnerability description) into network enforcement, 3) addressing the LLM hallucination and non determinism via the Online Agentic Validation that penalizes erroneous outputs. Evaluated across 22 families of 1 day or n day exploits, REFN demonstrates effectiveness (21.1 percent higher accuracy than alternatives), efficiency (Mean Time To Patch of 3.65 hours) and scalability (easily scale to 10K devices). REFN serves as an initial step toward training LLMs to rapidly prevent massive scale 1 day or n day exploitations.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.10701.pdf", "abstract_url": "https://arxiv.org/abs/2508.10701", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic", "@RAG"], "AI": {"tldr": "REFN是一个利用强化学习从网络框架中训练大型语言模型（LLMs）自主生成网络过滤器，以防止1天或n天漏洞利用的新框架。它通过在线网络奖励驱动的强化学习确保可扩展性，通过在边缘安全网关上的统一部署保证兼容性，并通过真实网络流量进行在线验证提供鲁棒性。", "motivation": "解决1天或n天漏洞利用对网络设备构成的严重威胁，现有防御措施由于跨设备可扩展性有限、兼容性问题以及部署过程易出错而不足。", "method": "引入REFN框架，利用强化学习（RL）驱动的大型语言模型（LLMs）自主生成网络过滤器，采用Agentic RAG基于知识蒸馏扩展LLMs的漏洞修复专业知识，通过RL From VNF Pipeline将语言上下文转换为网络执行，并通过在线Agentic验证解决LLM的幻觉和非确定性问题。", "result": "在22个1天或n天漏洞利用家族中评估，REFN显示出高效性（比替代方案高21.1%的准确率）、效率（平均修补时间为3.65小时）和可扩展性（轻松扩展到10K设备）。", "conclusion": "REFN是训练LLMs快速防止大规模1天或n天漏洞利用的初步步骤，展示了在网络安全领域的潜在应用价值。"}}
{"id": "2508.10760", "title": "FROGENT: An End-to-End Full-process Drug Design Agent", "authors": ["Qihua Pan", "Dong Xu", "Jenna Xinyi Yao", "Lijia Ma", "Zexuan Zhu", "Junkai Ji"], "abstract": "Powerful AI tools for drug discovery reside in isolated web apps, desktop programs, and code libraries. Such fragmentation forces scientists to manage incompatible interfaces and specialized scripts, which can be a cumbersome and repetitive process. To address this issue, a Full-pROcess druG dEsign ageNT, named FROGENT, has been proposed. Specifically, FROGENT utilizes a Large Language Model and the Model Context Protocol to integrate multiple dynamic biochemical databases, extensible tool libraries, and task-specific AI models. This agentic framework allows FROGENT to execute complicated drug discovery workflows dynamically, including component tasks such as target identification, molecule generation and retrosynthetic planning. FROGENT has been evaluated on eight benchmarks that cover various aspects of drug discovery, such as knowledge retrieval, property prediction, virtual screening, mechanistic analysis, molecular design, and synthesis. It was compared against six increasingly advanced ReAct-style agents that support code execution and literature searches. Empirical results demonstrated that FROGENT triples the best baseline performance in hit-finding and doubles it in interaction profiling, significantly outperforming both the open-source model Qwen3-32B and the commercial model GPT-4o. In addition, real-world cases have been utilized to validate the practicability and generalization of FROGENT. This development suggests that streamlining the agentic drug discovery pipeline can significantly enhance researcher productivity.", "subjects": "Biomolecules (q-bio.BM); Artificial Intelligence (cs.AI)", "comments": "9 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2508.10760.pdf", "abstract_url": "https://arxiv.org/abs/2508.10760", "categories": ["Biomolecules (q-bio.BM)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "FROGENT是一个端到端的全流程药物设计代理，旨在解决药物发现中AI工具分散的问题。它通过大型语言模型和模型上下文协议整合多种资源，显著提高了研究效率。", "motivation": "解决药物发现中AI工具分散、接口不兼容和需要专门脚本管理的繁琐重复问题。", "method": "利用大型语言模型和模型上下文协议整合动态生化数据库、可扩展工具库和任务特定的AI模型。", "result": "在八个基准测试中，FROGENT在命中发现和相互作用分析方面的性能分别是最好基线的三倍和两倍，显著优于Qwen3-32B和GPT-4o。", "conclusion": "FROGENT通过流线化代理药物发现流程，显著提高了研究人员的生产力，展示了其在实际应用中的实用性和泛化能力。"}}
{"id": "2508.10872", "title": "TLE-Based A2C Agent for Terrestrial Coverage Orbital Path Planning", "authors": ["Anantha Narayanan", "Battu Bhanu Teja", "Pruthwik Mishra"], "abstract": "The increasing congestion of Low Earth Orbit (LEO) poses persistent challenges to the efficient deployment and safe operation of Earth observation satellites. Mission planners must now account not only for mission-specific requirements but also for the increasing collision risk with active satellites and space debris. This work presents a reinforcement learning framework using the Advantage Actor-Critic (A2C) algorithm to optimize satellite orbital parameters for precise terrestrial coverage within predefined surface radii. By formulating the problem as a Markov Decision Process (MDP) within a custom OpenAI Gymnasium environment, our method simulates orbital dynamics using classical Keplerian elements. The agent progressively learns to adjust five of the orbital parameters - semi-major axis, eccentricity, inclination, right ascension of ascending node, and the argument of perigee-to achieve targeted terrestrial coverage. Comparative evaluation against Proximal Policy Optimization (PPO) demonstrates A2C's superior performance, achieving 5.8x higher cumulative rewards (10.0 vs 9.263025) while converging in 31.5x fewer timesteps (2,000 vs 63,000). The A2C agent consistently meets mission objectives across diverse target coordinates while maintaining computational efficiency suitable for real-time mission planning applications. Key contributions include: (1) a TLE-based orbital simulation environment incorporating physics constraints, (2) validation of actor-critic methods' superiority over trust region approaches in continuous orbital control, and (3) demonstration of rapid convergence enabling adaptive satellite deployment. This approach establishes reinforcement learning as a computationally efficient alternative for scalable and intelligent LEO mission planning.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": "8 pages, 6 figures, 5 tables", "pdf_url": "https://arxiv.org/pdf/2508.10872.pdf", "abstract_url": "https://arxiv.org/abs/2508.10872", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于优势演员-评论家（A2C）算法的强化学习框架，用于优化地球观测卫星的轨道参数，以实现精确的地面覆盖。通过在一个自定义的OpenAI Gymnasium环境中将问题表述为马尔可夫决策过程（MDP），该方法使用经典的Keplerian元素模拟轨道动力学。与近端策略优化（PPO）相比，A2C表现出更优的性能，实现了更高的累积奖励和更快的收敛速度。", "motivation": "低地球轨道（LEO）的日益拥挤对地球观测卫星的有效部署和安全运行提出了持续挑战。任务规划者现在不仅需要考虑任务特定的要求，还需要考虑与活跃卫星和太空碎片碰撞风险的增加。", "method": "本文采用强化学习框架，特别是优势演员-评论家（A2C）算法，在一个自定义的OpenAI Gymnasium环境中将卫星轨道参数优化问题表述为马尔可夫决策过程（MDP），并使用经典的Keplerian元素模拟轨道动力学。", "result": "与近端策略优化（PPO）相比，A2C算法实现了5.8倍的累积奖励（10.0 vs 9.263025），并在31.5倍更少的时间步内收敛（2,000 vs 63,000）。A2C代理能够在不同的目标坐标下一致满足任务目标，同时保持适合实时任务规划应用的计算效率。", "conclusion": "这种方法确立了强化学习作为一种计算效率高的替代方案，用于可扩展和智能的LEO任务规划。主要贡献包括：一个基于TLE的轨道模拟环境，包含物理约束；验证了演员-评论家方法在连续轨道控制中优于信任区域方法；展示了快速收敛能力，支持自适应卫星部署。"}}
