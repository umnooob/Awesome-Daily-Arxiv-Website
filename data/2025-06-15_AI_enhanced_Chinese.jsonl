{"id": "2506.10055", "title": "TaskCraft: Automated Generation of Agentic Tasks", "authors": ["Dingfeng Shi", "Jingyi Cao", "Qianben Chen", "Weichen Sun", "Weizhen Li", "Hongxuan Lu", "Fangchen Dong", "Tianrui Qin", "King Zhu", "Minghao Yang", "Jian Yang", "Ge Zhang", "Jiaheng Liu", "Changwang Zhang", "Jun Wang", "Yuchen Eleanor Jiang", "Wangchunshu Zhou"], "abstract": "Agentic tasks, which require multi-step problem solving with autonomy, tool use, and adaptive reasoning, are becoming increasingly central to the advancement of NLP and AI. However, existing instruction data lacks tool interaction, and current agentic benchmarks rely on costly human annotation, limiting their scalability. We introduce \\textsc{TaskCraft}, an automated workflow for generating difficulty-scalable, multi-tool, and verifiable agentic tasks with execution trajectories. TaskCraft expands atomic tasks using depth-based and width-based extensions to create structurally and hierarchically complex challenges. Empirical results show that these tasks improve prompt optimization in the generation workflow and enhance supervised fine-tuning of agentic foundation models. We present a large-scale synthetic dataset of approximately 36,000 tasks with varying difficulty to support future research on agent tuning and evaluation.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.10055.pdf", "abstract_url": "https://arxiv.org/abs/2506.10055", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "TaskCraft是一个自动化工作流程，用于生成难度可扩展、多工具且可验证的代理任务，旨在解决现有指令数据缺乏工具交互和代理基准依赖昂贵人工标注的问题。", "motivation": "解决现有指令数据缺乏工具交互和代理基准依赖昂贵人工标注的问题，以支持NLP和AI的发展。", "method": "通过深度和宽度扩展原子任务，创建结构和层次复杂的挑战，自动化生成代理任务。", "result": "生成了约36,000个难度不一的任务，这些任务改进了生成工作流程中的提示优化，并增强了代理基础模型的监督微调。", "conclusion": "TaskCraft为代理调优和评估的未来研究提供了大规模合成数据集，推动了代理任务自动化生成的发展。"}}
{"id": "2506.10086", "title": "Chat-of-Thought: Collaborative Multi-Agent System for Generating Domain Specific Information", "authors": ["Christodoulos Constantinides", "Shuxin Lin", "Nianjun Zhou", "Dhaval Patel"], "abstract": "This paper presents a novel multi-agent system called Chat-of-Thought, designed to facilitate the generation of Failure Modes and Effects Analysis (FMEA) documents for industrial assets. Chat-of-Thought employs multiple collaborative Large Language Model (LLM)-based agents with specific roles, leveraging advanced AI techniques and dynamic task routing to optimize the generation and validation of FMEA tables. A key innovation in this system is the introduction of a Chat of Thought, where dynamic, multi-persona-driven discussions enable iterative refinement of content. This research explores the application domain of industrial equipment monitoring, highlights key challenges, and demonstrates the potential of Chat-of-Thought in addressing these challenges through interactive, template-driven workflows and context-aware agent collaboration.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.10086.pdf", "abstract_url": "https://arxiv.org/abs/2506.10086", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一种名为Chat-of-Thought的新型多代理系统，旨在为工业资产生成故障模式与影响分析（FMEA）文档。该系统利用具有特定角色的多个协作大型语言模型（LLM）代理，通过先进的AI技术和动态任务路由优化FMEA表的生成和验证。", "motivation": "解决工业设备监控领域中FMEA文档生成的挑战，通过多代理协作和动态讨论提高文档质量和效率。", "method": "采用多代理系统，每个代理具有特定角色，利用大型语言模型（LLM）和动态任务路由技术，通过动态、多角色驱动的讨论迭代优化内容。", "result": "展示了Chat-of-Thought在工业设备监控领域的应用潜力，通过交互式、模板驱动的工作流程和上下文感知的代理协作，有效解决了FMEA文档生成的挑战。", "conclusion": "Chat-of-Thought系统通过多代理协作和动态讨论，为工业资产FMEA文档生成提供了一种高效、高质量的解决方案，展现了在工业设备监控等领域的广泛应用前景。"}}
{"id": "2506.10077", "title": "A quantum semantic framework for natural language processing", "authors": ["Christopher J. Agostino", "Quan Le Thien", "Molly Apsel", "Denizhan Pak", "Elina Lesyk", "Ashabari Majumdar"], "abstract": "Semantic degeneracy represents a fundamental property of natural language that extends beyond simple polysemy to encompass the combinatorial explosion of potential interpretations that emerges as semantic expressions increase in complexity. Large Language Models (LLMs) and other modern NLP systems face inherent limitations precisely because they operate within natural language itself, making them subject to the same interpretive constraints imposed by semantic degeneracy. In this work, we argue using Kolmogorov complexity that as an expression's complexity grows, the likelihood of any interpreting agent (human or LLM-powered AI) recovering the single intended meaning vanishes. This computational intractability suggests the classical view that linguistic forms possess meaning in and of themselves is flawed. We alternatively posit that meaning is instead actualized through an observer-dependent interpretive act. To test this, we conducted a semantic Bell inequality test using diverse LLM agents as ``computational cognitive systems'' to interpret ambiguous word pairs under varied contextual settings. Across several independent experiments, we found average CHSH expectation values ranging from 1.2 to 2.8, with several runs yielding values (e.g., 2.3-2.4) that significantly violate the classical boundary ($|S|\\leq2$). This demonstrates that linguistic interpretation under ambiguity can exhibit non-classical contextuality, consistent with results from human cognition experiments. These results inherently imply that classical frequentist-based analytical approaches for natural language are necessarily lossy. Instead, we propose that Bayesian-style repeated sampling approaches can provide more practically useful and appropriate characterizations of linguistic meaning in context.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Information Theory (cs.IT)", "comments": "12 pages, 2 figures, accepted submission to Quantum AI and NLP 2025", "pdf_url": "https://arxiv.org/pdf/2506.10077.pdf", "abstract_url": "https://arxiv.org/abs/2506.10077", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)", "Information Theory (cs.IT)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种量子语义框架，用于解决自然语言处理中的语义退化问题，通过Kolmogorov复杂性论证了随着表达复杂性的增加，恢复单一预期意义的可能性消失，并通过语义贝尔不等式测试展示了语言解释在模糊性下可以表现出非经典上下文性。", "motivation": "解决自然语言处理中语义退化带来的解释限制问题，特别是大型语言模型（LLMs）和其他现代NLP系统在自然语言操作中面临的固有局限性。", "method": "使用Kolmogorov复杂性理论分析语义退化的影响，并通过语义贝尔不等式测试，利用不同的LLM代理作为“计算认知系统”来解释在不同上下文设置下的模糊词对。", "result": "实验结果显示，平均CHSH期望值范围从1.2到2.8，多个运行结果（如2.3-2.4）显著违反了经典边界（|S|≤2），表明在模糊性下的语言解释可以表现出非经典上下文性。", "conclusion": "研究结果表明，基于经典频率的分析方法在处理自然语言时必然存在信息丢失，而贝叶斯风格的重复采样方法可以提供更实用和适当的语境中语言意义的表征。"}}
{"id": "2506.10192", "title": "Towards Responsible AI: Advances in Safety, Fairness, and Accountability of Autonomous Systems", "authors": ["Filip Cano"], "abstract": "Ensuring responsible use of artificial intelligence (AI) has become imperative as autonomous systems increasingly influence critical societal domains. However, the concept of trustworthy AI remains broad and multi-faceted. This thesis advances knowledge in the safety, fairness, transparency, and accountability of AI systems. In safety, we extend classical deterministic shielding techniques to become resilient against delayed observations, enabling practical deployment in real-world conditions. We also implement both deterministic and probabilistic safety shields into simulated autonomous vehicles to prevent collisions with road users, validating the use of these techniques in realistic driving simulators. We introduce fairness shields, a novel post-processing approach to enforce group fairness in sequential decision-making settings over finite and periodic time horizons. By optimizing intervention costs while strictly ensuring fairness constraints, this method efficiently balances fairness with minimal interference. For transparency and accountability, we propose a formal framework for assessing intentional behaviour in probabilistic decision-making agents, introducing quantitative metrics of agency and intention quotient. We use these metrics to propose a retrospective analysis of intention, useful for determining responsibility when autonomous systems cause unintended harm. Finally, we unify these contributions through the ``reactive decision-making'' framework, providing a general formalization that consolidates previous approaches. Collectively, the advancements presented contribute practically to the realization of safer, fairer, and more accountable AI systems, laying the foundations for future research in trustworthy AI.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "202 pages, 38 figures, PhD Thesis", "pdf_url": "https://arxiv.org/pdf/2506.10192.pdf", "abstract_url": "https://arxiv.org/abs/2506.10192", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了如何实现负责任的人工智能（AI），特别是在安全性、公平性、透明度和问责制方面的进展。通过扩展确定性屏蔽技术、引入公平性屏蔽、提出量化代理和意图商的正式框架，以及统一这些贡献于“反应性决策”框架中，为构建更安全、更公平、更负责任的AI系统奠定了基础。", "motivation": "随着自主系统在关键社会领域的影响日益增加，确保AI的负责任使用变得至关重要。然而，可信赖AI的概念仍然广泛且多面。", "method": "研究采用了多种方法，包括扩展确定性屏蔽技术以适应延迟观察、在模拟自动驾驶车辆中实施安全屏蔽、引入公平性屏蔽以在序列决策中强制执行群体公平性、提出量化代理和意图商的正式框架，以及通过“反应性决策”框架统一这些方法。", "result": "研究结果表明，所提出的技术和方法能够有效提高AI系统的安全性、公平性和问责制，特别是在防止自动驾驶车辆碰撞和确保决策公平性方面。", "conclusion": "本文的贡献为未来可信赖AI的研究奠定了基础，展示了如何通过技术进步实现更安全、更公平、更负责任的AI系统。"}}
{"id": "2506.10326", "title": "A Benchmark for Generalizing Across Diverse Team Strategies in Competitive Pokémon", "authors": ["Cameron Angliss", "Jiaxun Cui", "Jiaheng Hu", "Arrasy Rahman", "Peter Stone"], "abstract": "Developing AI agents that can robustly adapt to dramatically different strategic landscapes without retraining is a central challenge for multi-agent learning. Pokémon Video Game Championships (VGC) is a domain with an extraordinarily large space of possible team configurations of approximately $10^{139}$ - far larger than those of Dota or Starcraft. The highly discrete, combinatorial nature of team building in Pokémon VGC causes optimal strategies to shift dramatically depending on both the team being piloted and the opponent's team, making generalization uniquely challenging. To advance research on this problem, we introduce VGC-Bench: a benchmark that provides critical infrastructure, standardizes evaluation protocols, and supplies human-play datasets and a range of baselines - from large-language-model agents and behavior cloning to reinforcement learning and empirical game-theoretic methods such as self-play, fictitious play, and double oracle. In the restricted setting where an agent is trained and evaluated on a single-team configuration, our methods are able to win against a professional VGC competitor. We extensively evaluated all baseline methods over progressively larger team sets and find that even the best-performing algorithm in the single-team setting struggles at scaling up as team size grows. Thus, policy generalization across diverse team strategies remains an open challenge for the community. Our code is open sourced at", "subjects": "Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT); Machine Learning (cs.LG); Multiagent Systems (cs.MA)", "comments": "15 pages, 3 figures, 10 tables, submitted to NeurIPS 2025 Datasets & Benchmarks Track", "pdf_url": "https://arxiv.org/pdf/2506.10326.pdf", "abstract_url": "https://arxiv.org/abs/2506.10326", "categories": ["Artificial Intelligence (cs.AI)", "Computer Science and Game Theory (cs.GT)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了VGC-Bench，一个用于评估AI代理在多智能体学习中跨不同团队策略泛化能力的基准。Pokémon视频游戏锦标赛（VGC）因其庞大的团队配置空间和策略多样性，成为研究这一挑战的理想领域。", "motivation": "解决AI代理在不重新训练的情况下，适应截然不同策略环境的泛化能力问题。Pokémon VGC的团队配置空间极大，策略变化剧烈，为研究提供了独特挑战。", "method": "引入了VGC-Bench基准，包括基础设施、评估协议、人类游戏数据集及多种基线方法（如大型语言模型代理、行为克隆、强化学习和博弈论方法）。", "result": "在单一团队配置下，某些方法能击败专业VGC选手。但随着团队规模扩大，即使是表现最佳的算法也面临泛化挑战。", "conclusion": "跨多样团队策略的策略泛化仍是一个开放挑战。VGC-Bench为社区提供了研究这一问题的工具和数据。"}}
{"id": "2506.10264", "title": "WGSR-Bench: Wargame-based Game-theoretic Strategic Reasoning Benchmark for Large Language Models", "authors": ["Qiyue Yin", "Pei Xu", "Qiaozhe Li", "Shengda Liu", "Shengqi Shen", "Tong Wang", "Yihong Han", "Xiaonan Zhao", "Likun Yang", "Shiyue Cao", "Shiyu Qiu", "Yuxuan Liu", "Shizhao Yu", "Lei Cui", "Chengxin Yan", "Jie Sun", "Xiangquan Tang", "Kaiqi Huang"], "abstract": "Recent breakthroughs in Large Language Models (LLMs) have led to a qualitative leap in artificial intelligence' s performance on reasoning tasks, particularly demonstrating remarkable capabilities in mathematical, symbolic, and commonsense reasoning. However, as a critical component of advanced human cognition, strategic reasoning, i.e., the ability to assess multi-agent behaviors in dynamic environments, formulate action plans, and adapt strategies, has yet to be systematically evaluated or modeled. To address this gap, this paper introduces WGSR-Bench, the first strategy reasoning benchmark for LLMs using wargame as its evaluation environment. Wargame, a quintessential high-complexity strategic scenario, integrates environmental uncertainty, adversarial dynamics, and non-unique strategic choices, making it an effective testbed for assessing LLMs' capabilities in multi-agent decision-making, intent inference, and counterfactual reasoning. WGSR-Bench designs test samples around three core tasks, i.e., Environmental situation awareness, Opponent risk modeling and Policy generation, which serve as the core S-POE architecture, to systematically assess main abilities of strategic reasoning. Finally, an LLM-based wargame agent is designed to integrate these parts for a comprehensive strategy reasoning assessment. With WGSR-Bench, we hope to assess the strengths and limitations of state-of-the-art LLMs in game-theoretic strategic reasoning and to advance research in large model-driven strategic intelligence.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "15 pages, 17 figures", "pdf_url": "https://arxiv.org/pdf/2506.10264.pdf", "abstract_url": "https://arxiv.org/abs/2506.10264", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了WGSR-Bench，这是一个基于战争游戏的战略推理基准测试，旨在评估大型语言模型在多代理决策、意图推断和反事实推理等方面的能力。", "motivation": "解决大型语言模型在战略推理能力方面缺乏系统性评估或建模的问题。", "method": "使用战争游戏作为评估环境，设计了围绕环境态势感知、对手风险建模和政策生成三个核心任务的测试样本，构建了S-POE架构，并设计了一个基于LLM的战争游戏代理进行综合评估。", "result": "WGSR-Bench能够系统地评估大型语言模型在战略推理方面的主要能力，揭示了当前最先进大型语言模型在游戏理论战略推理中的优势和局限性。", "conclusion": "WGSR-Bench的引入不仅为评估大型语言模型的战略推理能力提供了有效工具，还推动了大型模型驱动的战略智能研究的发展。"}}
{"id": "2506.10357", "title": "Optimus-3: Towards Generalist Multimodal Minecraft Agents with Scalable Task Experts", "authors": ["Zaijing Li", "Yuquan Xie", "Rui Shao", "Gongwei Chen", "Weili Guan", "Dongmei Jiang", "Liqiang Nie"], "abstract": "Recently, agents based on multimodal large language models (MLLMs) have achieved remarkable progress across various domains. However, building a generalist agent with capabilities such as perception, planning, action, grounding, and reflection in open-world environments like Minecraft remains challenges: insufficient domain-specific data, interference among heterogeneous tasks, and visual diversity in open-world settings. In this paper, we address these challenges through three key contributions. 1) We propose a knowledge-enhanced data generation pipeline to provide scalable and high-quality training data for agent development. 2) To mitigate interference among heterogeneous tasks, we introduce a Mixture-of-Experts (MoE) architecture with task-level routing. 3) We develop a Multimodal Reasoning-Augmented Reinforcement Learning approach to enhance the agent's reasoning ability for visual diversity in Minecraft. Built upon these innovations, we present Optimus-3, a general-purpose agent for Minecraft. Extensive experimental results demonstrate that Optimus-3 surpasses both generalist multimodal large language models and existing state-of-the-art agents across a wide range of tasks in the Minecraft environment. Project page:", "subjects": "Artificial Intelligence (cs.AI)", "comments": "24 pages, 10 figures", "pdf_url": "https://arxiv.org/pdf/2506.10357.pdf", "abstract_url": "https://arxiv.org/abs/2506.10357", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了Optimus-3，一个针对Minecraft的通用多模态代理，通过知识增强的数据生成管道、任务级路由的专家混合架构和多模态推理增强的强化学习方法，解决了开放世界环境中代理开发的挑战。", "motivation": "解决在开放世界环境（如Minecraft）中构建具有感知、规划、行动、基础和反思能力的通用代理所面临的挑战，包括领域特定数据不足、异构任务间的干扰以及开放世界设置中的视觉多样性问题。", "method": "1) 提出知识增强的数据生成管道以提供可扩展的高质量训练数据；2) 引入任务级路由的专家混合（MoE）架构以减少异构任务间的干扰；3) 开发多模态推理增强的强化学习方法以增强代理在视觉多样性环境中的推理能力。", "result": "实验结果表明，Optimus-3在Minecraft环境中的广泛任务上超越了通用多模态大型语言模型和现有的最先进代理。", "conclusion": "通过创新的数据生成、架构设计和强化学习方法，Optimus-3作为一个通用代理，在开放世界环境中展现出了卓越的性能和潜力。"}}
{"id": "2506.10384", "title": "NeuroPAL: Punctuated Anytime Learning with Neuroevolution for Macromanagement in Starcraft: Brood War", "authors": ["Jim O'Connor", "Yeonghun Lee", "Gary B Parker"], "abstract": "StarCraft: Brood War remains a challenging benchmark for artificial intelligence research, particularly in the domain of macromanagement, where long-term strategic planning is required. Traditional approaches to StarCraft AI rely on rule-based systems or supervised deep learning, both of which face limitations in adaptability and computational efficiency. In this work, we introduce NeuroPAL, a neuroevolutionary framework that integrates Neuroevolution of Augmenting Topologies (NEAT) with Punctuated Anytime Learning (PAL) to improve the efficiency of evolutionary training. By alternating between frequent, low-fidelity training and periodic, high-fidelity evaluations, PAL enhances the sample efficiency of NEAT, enabling agents to discover effective strategies in fewer training iterations. We evaluate NeuroPAL in a fixed-map, single-race scenario in StarCraft: Brood War and compare its performance to standard NEAT-based training. Our results show that PAL significantly accelerates the learning process, allowing the agent to reach competitive levels of play in approximately half the training time required by NEAT alone. Additionally, the evolved agents exhibit emergent behaviors such as proxy barracks placement and defensive building optimization, strategies commonly used by expert human players. These findings suggest that structured evaluation mechanisms like PAL can enhance the scalability and effectiveness of neuroevolution in complex real-time strategy environments.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "IEEE Conference on Games 2025", "pdf_url": "https://arxiv.org/pdf/2506.10384.pdf", "abstract_url": "https://arxiv.org/abs/2506.10384", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "NeuroPAL是一种结合神经进化增强拓扑（NEAT）和间断性随时学习（PAL）的框架，用于提高《星际争霸：母巢之战》中宏观管理的进化训练效率。", "motivation": "解决《星际争霸：母巢之战》中宏观管理长期战略规划的传统AI方法在适应性和计算效率上的限制。", "method": "通过交替进行频繁的低保真训练和周期性的高保真评估，PAL提高了NEAT的样本效率。", "result": "PAL显著加速了学习过程，使代理在约一半的训练时间内达到竞争水平，并展现出专家玩家常用的策略。", "conclusion": "结构化评估机制如PAL可以增强神经进化在复杂实时战略环境中的可扩展性和有效性。"}}
{"id": "2506.10387", "title": "Mirage-1: Augmenting and Updating GUI Agent with Hierarchical Multimodal Skills", "authors": ["Yuquan Xie", "Zaijing Li", "Rui Shao", "Gongwei Chen", "Kaiwen Zhou", "Yinchuan Li", "Dongmei Jiang", "Liqiang Nie"], "abstract": "Recent efforts to leverage the Multi-modal Large Language Model (MLLM) as GUI agents have yielded promising outcomes. However, these agents still struggle with long-horizon tasks in online environments, primarily due to insufficient knowledge and the inherent gap between offline and online domains. In this paper, inspired by how humans generalize knowledge in open-ended environments, we propose a Hierarchical Multimodal Skills (HMS) module to tackle the issue of insufficient knowledge. It progressively abstracts trajectories into execution skills, core skills, and ultimately meta-skills, providing a hierarchical knowledge structure for long-horizon task planning. To bridge the domain gap, we propose the Skill-Augmented Monte Carlo Tree Search (SA-MCTS) algorithm, which efficiently leverages skills acquired in offline environments to reduce the action search space during online tree exploration. Building on HMS, we propose Mirage-1, a multimodal, cross-platform, plug-and-play GUI agent. To validate the performance of Mirage-1 in real-world long-horizon scenarios, we constructed a new benchmark, AndroidLH. Experimental results show that Mirage-1 outperforms previous agents by 32\\%, 19\\%, 15\\%, and 79\\% on AndroidWorld, MobileMiniWob++, Mind2Web-Live, and AndroidLH, respectively. Project page:", "subjects": "Artificial Intelligence (cs.AI)", "comments": "20 pages, 5 figures, 5 tables", "pdf_url": "https://arxiv.org/pdf/2506.10387.pdf", "abstract_url": "https://arxiv.org/abs/2506.10387", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了Mirage-1，一个多模态、跨平台、即插即用的GUI代理，通过分层多模态技能（HMS）模块和技能增强蒙特卡洛树搜索（SA-MCTS）算法，解决了多模态大型语言模型（MLLM）作为GUI代理在在线环境中执行长时任务时知识不足和离线与在线领域间固有差距的问题。", "motivation": "解决多模态大型语言模型（MLLM）作为GUI代理在在线环境中执行长时任务时面临的知识不足和离线与在线领域间固有差距的问题。", "method": "提出了分层多模态技能（HMS）模块来逐步抽象轨迹为执行技能、核心技能和元技能，以及技能增强蒙特卡洛树搜索（SA-MCTS）算法来有效利用离线环境中获得的技能以减少在线树探索时的动作搜索空间。", "result": "实验结果显示，Mirage-1在AndroidWorld、MobileMiniWob++、Mind2Web-Live和AndroidLH上的表现分别比之前的代理提高了32%、19%、15%和79%。", "conclusion": "Mirage-1通过HMS和SA-MCTS算法的结合，显著提高了GUI代理在长时任务中的性能，为解决类似问题提供了新的思路和方法。"}}
{"id": "2506.10408", "title": "Reasoning RAG via System 1 or System 2: A Survey on Reasoning Agentic Retrieval-Augmented Generation for Industry Challenges", "authors": ["Jintao Liang", "Gang Su", "Huifeng Lin", "You Wu", "Rui Zhao", "Ziyue Li"], "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a powerful framework to overcome the knowledge limitations of Large Language Models (LLMs) by integrating external retrieval with language generation. While early RAG systems based on static pipelines have shown effectiveness in well-structured tasks, they struggle in real-world scenarios requiring complex reasoning, dynamic retrieval, and multi-modal integration. To address these challenges, the field has shifted toward Reasoning Agentic RAG, a paradigm that embeds decision-making and adaptive tool use directly into the retrieval process. In this paper, we present a comprehensive review of Reasoning Agentic RAG methods, categorizing them into two primary systems: predefined reasoning, which follows fixed modular pipelines to boost reasoning, and agentic reasoning, where the model autonomously orchestrates tool interaction during inference. We analyze representative techniques under both paradigms, covering architectural design, reasoning strategies, and tool coordination. Finally, we discuss key research challenges and propose future directions to advance the flexibility, robustness, and applicability of reasoning agentic RAG systems. Our collection of the relevant research has been organized into a", "subjects": "Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.10408.pdf", "abstract_url": "https://arxiv.org/abs/2506.10408", "categories": ["Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["agent", "agentic", "@RAG"], "AI": {"tldr": "本文综述了推理代理性检索增强生成（Reasoning Agentic RAG）方法，将其分为预定义推理和代理性推理两大类，并探讨了相关技术、挑战及未来方向。", "motivation": "解决大型语言模型（LLMs）在知识限制、复杂推理、动态检索和多模态集成等现实场景中的挑战。", "method": "通过系统1（预定义推理）和系统2（代理性推理）分类，分析代表性技术的架构设计、推理策略和工具协调。", "result": "提出了提高推理代理性RAG系统灵活性、鲁棒性和适用性的关键研究方向。", "conclusion": "推理代理性RAG系统的发展需要进一步研究以应对复杂和多变的工业挑战。"}}
{"id": "2506.10420", "title": "Multi-dimensional Autoscaling of Processing Services: A Comparison of Agent-based Methods", "authors": ["Boris Sedlak", "Alireza Furutanpey", "Zihang Wang", "Víctor Casamayor Pujol", "Schahram Dustdar"], "abstract": "Edge computing breaks with traditional autoscaling due to strict resource constraints, thus, motivating more flexible scaling behaviors using multiple elasticity dimensions. This work introduces an agent-based autoscaling framework that dynamically adjusts both hardware resources and internal service configurations to maximize requirements fulfillment in constrained environments. We compare four types of scaling agents: Active Inference, Deep Q Network, Analysis of Structural Knowledge, and Deep Active Inference, using two real-world processing services running in parallel: YOLOv8 for visual recognition and OpenCV for QR code detection. Results show all agents achieve acceptable SLO performance with varying convergence patterns. While the Deep Q Network benefits from pre-training, the structural analysis converges quickly, and the deep active inference agent combines theoretical foundations with practical scalability advantages. Our findings provide evidence for the viability of multi-dimensional agent-based autoscaling for edge environments and encourage future work in this research direction.", "subjects": "Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Emerging Technologies (cs.ET); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.10420.pdf", "abstract_url": "https://arxiv.org/abs/2506.10420", "categories": ["Artificial Intelligence (cs.AI)", "Distributed, Parallel, and Cluster Computing (cs.DC)", "Emerging Technologies (cs.ET)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一个基于代理的自动扩展框架，用于在边缘计算环境中动态调整硬件资源和内部服务配置，以最大化在资源受限环境下的需求满足。通过比较四种类型的扩展代理，证明了多维度基于代理的自动扩展在边缘环境中的可行性。", "motivation": "边缘计算由于严格的资源限制，与传统自动扩展不同，需要更灵活的扩展行为，利用多个弹性维度来满足需求。", "method": "引入了一个基于代理的自动扩展框架，比较了四种类型的扩展代理：主动推理、深度Q网络、结构知识分析和深度主动推理，使用YOLOv8和OpenCV两种并行运行的真实世界处理服务进行测试。", "result": "结果显示所有代理都达到了可接受的SLO性能，但收敛模式不同。深度Q网络受益于预训练，结构分析快速收敛，深度主动推理代理结合了理论基础和实践可扩展性优势。", "conclusion": "研究结果为边缘环境中多维度基于代理的自动扩展的可行性提供了证据，并鼓励未来在这一研究方向上的工作。"}}
{"id": "2506.10504", "title": "Beyond Single-User Dialogue: Assessing Multi-User Dialogue State Tracking Capabilities of Large Language Models", "authors": ["Sangmin Song", "Juhwan Choi", "JungMin Yun", "YoungBin Kim"], "abstract": "Large language models (LLMs) have demonstrated remarkable performance in zero-shot dialogue state tracking (DST), reducing the need for task-specific training. However, conventional DST benchmarks primarily focus on structured user-agent conversations, failing to capture the complexities of real-world multi-user interactions. In this study, we assess the robustness of LLMs in multi-user DST while minimizing dataset construction costs. Inspired by recent advances in LLM-based data annotation, we extend an existing DST dataset by generating utterances of a second user based on speech act theory. Our methodology systematically incorporates a second user's utterances into conversations, enabling a controlled evaluation of LLMs in multi-user settings. Experimental results reveal a significant performance drop compared to single-user DST, highlighting the limitations of current LLMs in extracting and tracking dialogue states amidst multiple speakers. Our findings emphasize the need for future research to enhance LLMs for multi-user DST scenarios, paving the way for more realistic and robust DST models.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.10504.pdf", "abstract_url": "https://arxiv.org/abs/2506.10504", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "评估大型语言模型在多用户对话状态跟踪中的能力，发现其在多用户场景下性能显著下降。", "motivation": "传统对话状态跟踪基准主要关注结构化用户-代理对话，未能捕捉现实世界多用户交互的复杂性。", "method": "基于言语行为理论，通过生成第二个用户的语句扩展现有DST数据集，系统地将第二个用户的语句融入对话中。", "result": "实验结果显示，与单用户DST相比，性能显著下降，揭示了当前LLMs在多说话者中提取和跟踪对话状态的局限性。", "conclusion": "强调了未来研究需要增强LLMs在多用户DST场景中的能力，为更现实和健壮的DST模型铺平道路。"}}
{"id": "2506.10380", "title": "TableRAG: A Retrieval Augmented Generation Framework for Heterogeneous Document Reasoning", "authors": ["Xiaohan Yu", "Pu Jian", "Chong Chen"], "abstract": "Retrieval-Augmented Generation (RAG) has demonstrated considerable effectiveness in open-domain question answering. However, when applied to heterogeneous documents, comprising both textual and tabular components, existing RAG approaches exhibit critical limitations. The prevailing practice of flattening tables and chunking strategies disrupts the intrinsic tabular structure, leads to information loss, and undermines the reasoning capabilities of LLMs in multi-hop, global queries. To address these challenges, we propose TableRAG, an hybrid framework that unifies textual understanding and complex manipulations over tabular data. TableRAG iteratively operates in four steps: context-sensitive query decomposition, text retrieval, SQL programming and execution, and compositional intermediate answer generation. We also develop HeteQA, a novel benchmark designed to evaluate the multi-hop heterogeneous reasoning capabilities. Experimental results demonstrate that TableRAG consistently outperforms existing baselines on both public datasets and our HeteQA, establishing a new state-of-the-art for heterogeneous document question answering. We release TableRAG at", "subjects": "Computation and Language (cs.CL); Information Retrieval (cs.IR)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2506.10380.pdf", "abstract_url": "https://arxiv.org/abs/2506.10380", "categories": ["Computation and Language (cs.CL)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "TableRAG是一个针对异构文档（包含文本和表格）推理的检索增强生成框架，通过结合文本理解和表格操作，解决了现有RAG方法在处理表格数据时的局限性。", "motivation": "现有的检索增强生成（RAG）方法在处理包含文本和表格的异构文档时，由于扁平化表格和分块策略破坏了表格结构，导致信息丢失和推理能力下降。", "method": "TableRAG采用混合框架，通过上下文敏感的查询分解、文本检索、SQL编程和执行、以及组合性中间答案生成四个步骤，统一了文本理解和表格数据的复杂操作。", "result": "实验结果表明，TableRAG在公共数据集和新开发的HeteQA基准测试上均优于现有基线，为异构文档问答设立了新的技术标准。", "conclusion": "TableRAG通过其创新的框架和步骤，有效提升了异构文档的推理能力，为相关领域的研究和应用提供了新的方向。"}}
{"id": "2506.10622", "title": "SDialog: A Python Toolkit for Synthetic Dialogue Generation and Analysis", "authors": ["Sergio Burdisso", "Esaú Villatoro-Tello", "Petr Motlicek"], "abstract": "The advancement of conversational AI systems relies on the availability of high-quality, flexible, and reproducible synthetic dialogues for training, evaluation, and benchmarking. SDialog is a modular, extensible Python toolkit designed to address the challenges of synthetic dialogue generation and analysis. By leveraging instruction-tuned Large Language Models (LLMs), SDialog provides abstractions for personas, orchestration, and scenario management, enabling the creation of realistic, diverse, and controllable conversational data for research and development. SDialog supports workflows such as multi-agent simulation and scenario-driven generation, and represents a step forward in the standardization of tools and frameworks for synthetic data generation, a crucial advancement for ensuring reproducibility in today's fast-evolving research landscape.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2506.10622.pdf", "abstract_url": "https://arxiv.org/abs/2506.10622", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "SDialog是一个模块化、可扩展的Python工具包，旨在解决合成对话生成和分析的挑战。它利用指令调优的大型语言模型（LLMs），为人格、编排和场景管理提供抽象，从而为研究和开发创建现实、多样且可控的对话数据。", "motivation": "对话AI系统的进步依赖于高质量、灵活且可重复的合成对话的可用性，用于训练、评估和基准测试。", "method": "SDialog通过指令调优的大型语言模型（LLMs）提供人格、编排和场景管理的抽象，支持多代理模拟和场景驱动生成等工作流程。", "result": "SDialog能够生成现实、多样且可控的对话数据，代表了在合成数据生成工具和框架标准化方面的重要进展。", "conclusion": "SDialog是当今快速发展的研究领域中确保可重复性的关键进步，为对话AI系统的研究和开发提供了强有力的支持。"}}
{"id": "2506.10764", "title": "OPT-BENCH: Evaluating LLM Agent on Large-Scale Search Spaces Optimization Problems", "authors": ["Xiaozhe Li", "Jixuan Chen", "Xinyu Fang", "Shengyuan Ding", "Haodong Duan", "Qingwen Liu", "Kai Chen"], "abstract": "Large Language Models (LLMs) have shown remarkable capabilities in solving diverse tasks. However, their proficiency in iteratively optimizing complex solutions through learning from previous feedback remains insufficiently explored. To bridge this gap, we present OPT-BENCH, a comprehensive benchmark designed to evaluate LLM agents on large-scale search space optimization problems. OPT-BENCH includes 20 real-world machine learning tasks sourced from Kaggle and 10 classical NP problems, offering a diverse and challenging environment for assessing LLM agents on iterative reasoning and solution refinement. To enable rigorous evaluation, we introduce OPT-Agent, an end-to-end optimization framework that emulates human reasoning when tackling complex problems by generating, validating, and iteratively improving solutions through leveraging historical feedback. Through extensive experiments on 9 state-of-the-art LLMs from 6 model families, we analyze the effects of optimization iterations, temperature settings, and model architectures on solution quality and convergence. Our results demonstrate that incorporating historical context significantly enhances optimization performance across both ML and NP tasks. All datasets, code, and evaluation tools are open-sourced to promote further research in advancing LLM-driven optimization and iterative reasoning. Project page: \\href{", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.10764.pdf", "abstract_url": "https://arxiv.org/abs/2506.10764", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了OPT-BENCH，一个用于评估大型语言模型（LLM）代理在大规模搜索空间优化问题上表现的全面基准。OPT-BENCH包含20个来自Kaggle的机器学习任务和10个经典NP问题，旨在评估LLM代理在迭代推理和解决方案优化方面的能力。", "motivation": "尽管大型语言模型在解决多样化任务方面显示出显著能力，但它们在通过从先前反馈中学习来迭代优化复杂解决方案方面的熟练程度尚未充分探索。", "method": "为了填补这一空白，作者提出了OPT-BENCH基准和OPT-Agent，一个端到端的优化框架，模拟人类在解决复杂问题时的推理过程，通过利用历史反馈生成、验证和迭代改进解决方案。", "result": "通过对6个模型家族的9个最先进LLM进行广泛实验，研究发现，结合历史上下文显著提高了在机器学习和NP任务上的优化性能。", "conclusion": "所有数据集、代码和评估工具均已开源，以促进在推进LLM驱动的优化和迭代推理方面的进一步研究。"}}
{"id": "2506.10821", "title": "VideoDeepResearch: Long Video Understanding With Agentic Tool Using", "authors": ["Huaying Yuan", "Zheng Liu", "Junjie Zhou", "Ji-Rong Wen", "Zhicheng Dou"], "abstract": "Long video understanding (LVU) presents a significant challenge for current multi-modal large language models (MLLMs) due to the task's inherent complexity and context window constraint. It is widely assumed that addressing LVU tasks requires foundation MLLMs with extended context windows, strong visual perception capabilities, and proficient domain expertise. In this work, we challenge this common belief by introducing VideoDeepResearch, a novel agentic framework for long video understanding. Our approach relies solely on a text-only large reasoning model (LRM) combined with a modular multi-modal toolkit, including multimodal retrievers and visual perceivers, all of which are readily available in practice. For each LVU task, the system formulates a problem-solving strategy through reasoning, while selectively accessing and utilizing essential video content via tool using. We conduct extensive experiments on popular LVU benchmarks, including MLVU, Video-MME, and LVBench. Our results demonstrate that VideoDeepResearch achieves substantial improvements over existing MLLM baselines, surpassing the previous state-of-the-art by 9.6%, 6.6%, and 3.9% on MLVU (test), LVBench, and LongVideoBench, respectively. These findings highlight the promise of agentic systems in overcoming key challenges in LVU problems.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.10821.pdf", "abstract_url": "https://arxiv.org/abs/2506.10821", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "VideoDeepResearch提出了一种新颖的代理框架，用于长视频理解（LVU），仅使用文本大型推理模型（LRM）和模块化多模态工具包，显著提高了在多个LVU基准测试上的性能。", "motivation": "解决长视频理解（LVU）任务的传统方法依赖于具有扩展上下文窗口、强大视觉感知能力和专业领域知识的多模态大型语言模型（MLLMs），但这些方法存在复杂性和上下文窗口限制的问题。", "method": "引入VideoDeepResearch，一个仅依赖文本大型推理模型（LRM）和模块化多模态工具包（包括多模态检索器和视觉感知器）的代理框架，通过推理制定问题解决策略，并选择性访问和利用关键视频内容。", "result": "在MLVU（测试）、LVBench和LongVideoBench等流行的LVU基准测试上，VideoDeepResearch比现有的MLLM基线有显著提升，分别超过了之前的最先进水平9.6%、6.6%和3.9%。", "conclusion": "这些发现突出了代理系统在克服LVU问题中的关键挑战方面的潜力，表明不需要依赖具有扩展上下文窗口和强大视觉感知能力的MLLMs。"}}
{"id": "2506.10844", "title": "CIIR@LiveRAG 2025: Optimizing Multi-Agent Retrieval Augmented Generation through Self-Training", "authors": ["Alireza Salemi", "Mukta Maddipatla", "Hamed Zamani"], "abstract": "This paper presents mRAG, a multi-agent retrieval-augmented generation (RAG) framework composed of specialized agents for subtasks such as planning, searching, reasoning, and coordination. Our system uses a self-training paradigm with reward-guided trajectory sampling to optimize inter-agent collaboration and enhance response generation. Evaluated on DataMorgana-derived datasets during the SIGIR 2025 LiveRAG competition, mRAG outperforms conventional RAG baselines. We further analyze competition outcomes and showcase the framework's strengths with case studies, demonstrating its efficacy for complex, real-world RAG tasks.", "subjects": "Computation and Language (cs.CL); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.10844.pdf", "abstract_url": "https://arxiv.org/abs/2506.10844", "categories": ["Computation and Language (cs.CL)", "Information Retrieval (cs.IR)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文介绍了mRAG，一个多代理检索增强生成（RAG）框架，通过自训练范式优化代理间协作，提升响应生成质量。", "motivation": "解决传统RAG在处理复杂、现实世界任务时的协作和效率问题。", "method": "采用多代理框架，结合自训练和奖励引导的轨迹采样优化协作。", "result": "在SIGIR 2025 LiveRAG竞赛中，mRAG优于传统RAG基线。", "conclusion": "mRAG框架有效提升了复杂RAG任务的性能，展示了多代理协作的潜力。"}}
{"id": "2506.10030", "title": "Safeguarding Multimodal Knowledge Copyright in the RAG-as-a-Service Environment", "authors": ["Tianyu Chen", "Jian Lou", "Wenjie Wang"], "abstract": "As Retrieval-Augmented Generation (RAG) evolves into service-oriented platforms (Rag-as-a-Service) with shared knowledge bases, protecting the copyright of contributed data becomes essential. Existing watermarking methods in RAG focus solely on textual knowledge, leaving image knowledge unprotected. In this work, we propose AQUA, the first watermark framework for image knowledge protection in Multimodal RAG systems. AQUA embeds semantic signals into synthetic images using two complementary methods: acronym-based triggers and spatial relationship cues. These techniques ensure watermark signals survive indirect watermark propagation from image retriever to textual generator, being efficient, effective and imperceptible. Experiments across diverse models and datasets show that AQUA enables robust, stealthy, and reliable copyright tracing, filling a key gap in multimodal RAG protection.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.10030.pdf", "abstract_url": "https://arxiv.org/abs/2506.10030", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了AQUA，首个用于多模态RAG系统中图像知识保护的水印框架，通过将语义信号嵌入合成图像来保护版权。", "motivation": "随着检索增强生成（RAG）向服务导向平台（Rag-as-a-Service）发展，共享知识库中贡献数据的版权保护变得至关重要。现有的RAG水印方法仅关注文本知识，图像知识未受保护。", "method": "AQUA框架采用两种互补的方法将语义信号嵌入合成图像：基于缩写的触发器和空间关系线索。这些技术确保水印信号在从图像检索器到文本生成器的间接水印传播中存活，既高效又有效且不易察觉。", "result": "跨多种模型和数据集的实验表明，AQUA能够实现强大、隐秘且可靠的版权追踪。", "conclusion": "AQUA填补了多模态RAG保护中的一个关键空白，为图像知识提供了有效的水印保护方案。"}}
{"id": "2506.10934", "title": "Dynamic Epistemic Friction in Dialogue", "authors": ["Timothy Obiso", "Kenneth Lai", "Abhijnan Nath", "Nikhil Krishnaswamy", "James Pustejovsky"], "abstract": "Recent developments in aligning Large Language Models (LLMs) with human preferences have significantly enhanced their utility in human-AI collaborative scenarios. However, such approaches often neglect the critical role of \"epistemic friction,\" or the inherent resistance encountered when updating beliefs in response to new, conflicting, or ambiguous information. In this paper, we define dynamic epistemic friction as the resistance to epistemic integration, characterized by the misalignment between an agent's current belief state and new propositions supported by external evidence. We position this within the framework of Dynamic Epistemic Logic (Van Benthem and Pacuit, 2011), where friction emerges as nontrivial belief-revision during the interaction. We then present analyses from a situated collaborative task that demonstrate how this model of epistemic friction can effectively predict belief updates in dialogues, and we subsequently discuss how the model of belief alignment as a measure of epistemic resistance or friction can naturally be made more sophisticated to accommodate the complexities of real-world dialogue scenarios.", "subjects": "Computation and Language (cs.CL)", "comments": "11 pages, 2 figures, 2 tables, CoNLL 2025", "pdf_url": "https://arxiv.org/pdf/2506.10934.pdf", "abstract_url": "https://arxiv.org/abs/2506.10934", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了大型语言模型（LLMs）与人类偏好对齐的最新进展，但指出这些方法常忽视“认知摩擦”的关键作用，即在面对新、冲突或模糊信息时更新信念的内在阻力。作者提出了动态认知摩擦的概念，并将其置于动态认知逻辑框架中，通过分析协作任务展示了该模型如何有效预测对话中的信念更新，并讨论了如何使信念对齐模型更复杂以适应现实世界对话场景的复杂性。", "motivation": "解决大型语言模型在与人类协作场景中忽视认知摩擦的问题，即更新信念时遇到的内在阻力。", "method": "将动态认知摩擦定义为认知整合的阻力，并在动态认知逻辑框架中定位，通过协作任务分析展示模型的有效性。", "result": "动态认知摩擦模型能有效预测对话中的信念更新，信念对齐作为认知阻力或摩擦的度量可更复杂以适应现实对话场景。", "conclusion": "动态认知摩擦模型为理解和预测对话中的信念更新提供了新视角，其复杂化有助于更好地适应现实世界对话的复杂性。"}}
{"id": "2506.10974", "title": "AutoMind: Adaptive Knowledgeable Agent for Automated Data Science", "authors": ["Yixin Ou", "Yujie Luo", "Jingsheng Zheng", "Lanning Wei", "Shuofei Qiao", "Jintian Zhang", "Da Zheng", "Huajun Chen", "Ningyu Zhang"], "abstract": "Large Language Model (LLM) agents have shown great potential in addressing real-world data science problems. LLM-driven data science agents promise to automate the entire machine learning pipeline, yet their real-world effectiveness remains limited. Existing frameworks depend on rigid, pre-defined workflows and inflexible coding strategies; consequently, they excel only on relatively simple, classical problems and fail to capture the empirical expertise that human practitioners bring to complex, innovative tasks. In this work, we introduce AutoMind, an adaptive, knowledgeable LLM-agent framework that overcomes these deficiencies through three key advances: (1) a curated expert knowledge base that grounds the agent in domain expert knowledge, (2) an agentic knowledgeable tree search algorithm that strategically explores possible solutions, and (3) a self-adaptive coding strategy that dynamically tailors code generation to task complexity. Evaluations on two automated data science benchmarks demonstrate that AutoMind delivers superior performance versus state-of-the-art baselines. Additional analyses confirm favorable effectiveness, efficiency, and qualitative solution quality, highlighting AutoMind as an efficient and robust step toward fully automated data science.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG); Multiagent Systems (cs.MA)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2506.10974.pdf", "abstract_url": "https://arxiv.org/abs/2506.10974", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "AutoMind是一个自适应、知识丰富的LLM代理框架，旨在通过专家知识库、代理知识树搜索算法和自适应编码策略，提高数据科学自动化中的效果和灵活性。", "motivation": "解决现有LLM驱动数据科学代理在复杂、创新任务中因依赖刚性预定义工作流程和编码策略而表现不佳的问题。", "method": "引入三个关键进展：专家知识库、代理知识树搜索算法和自适应编码策略。", "result": "在两个自动化数据科学基准测试中，AutoMind表现出优于现有技术的性能，证实了其在效果、效率和解决方案质量上的优势。", "conclusion": "AutoMind是朝着完全自动化数据科学迈出的高效且稳健的一步，展示了在复杂任务中超越现有方法的潜力。"}}
{"id": "2506.10171", "title": "Disclosure Audits for LLM Agents", "authors": ["Saswat Das", "Jameson Sandler", "Ferdinando Fioretto"], "abstract": "Large Language Model agents have begun to appear as personal assistants, customer service bots, and clinical aides. While these applications deliver substantial operational benefits, they also require continuous access to sensitive data, which increases the likelihood of unauthorized disclosures. This study proposes an auditing framework for conversational privacy that quantifies and audits these risks. The proposed Conversational Manipulation for Privacy Leakage (CMPL) framework, is an iterative probing strategy designed to stress-test agents that enforce strict privacy directives. Rather than focusing solely on a single disclosure event, CMPL simulates realistic multi-turn interactions to systematically uncover latent vulnerabilities. Our evaluation on diverse domains, data modalities, and safety configurations demonstrate the auditing framework's ability to reveal privacy risks that are not deterred by existing single-turn defenses. In addition to introducing CMPL as a diagnostic tool, the paper delivers (1) an auditing procedure grounded in quantifiable risk metrics and (2) an open benchmark for evaluation of conversational privacy across agent implementations.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.10171.pdf", "abstract_url": "https://arxiv.org/abs/2506.10171", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种用于大型语言模型代理的对话隐私审计框架CMPL，旨在通过多轮交互测试揭示隐私泄露风险。", "motivation": "大型语言模型代理在提供操作便利的同时，因持续访问敏感数据而增加了未经授权披露的风险。", "method": "提出了CMPL框架，一种迭代探测策略，用于压力测试执行严格隐私指令的代理。", "result": "评估显示，CMPL能够揭示现有单轮防御无法阻止的隐私风险。", "conclusion": "CMPL不仅作为诊断工具，还提供了基于可量化风险指标的审计程序和开放的对话隐私评估基准。"}}
{"id": "2506.10142", "title": "Rethinking Brain Tumor Segmentation from the Frequency Domain Perspective", "authors": ["Minye Shao", "Zeyu Wang", "Haoran Duan", "Yawen Huang", "Bing Zhai", "Shizheng Wang", "Yang Long", "Yefeng Zheng"], "abstract": "Precise segmentation of brain tumors, particularly contrast-enhancing regions visible in post-contrast MRI (areas highlighted by contrast agent injection), is crucial for accurate clinical diagnosis and treatment planning but remains challenging. However, current methods exhibit notable performance degradation in segmenting these enhancing brain tumor areas, largely due to insufficient consideration of MRI-specific tumor features such as complex textures and directional variations. To address this, we propose the Harmonized Frequency Fusion Network (HFF-Net), which rethinks brain tumor segmentation from a frequency-domain perspective. To comprehensively characterize tumor regions, we develop a Frequency Domain Decomposition (FDD) module that separates MRI images into low-frequency components, capturing smooth tumor contours and high-frequency components, highlighting detailed textures and directional edges. To further enhance sensitivity to tumor boundaries, we introduce an Adaptive Laplacian Convolution (ALC) module that adaptively emphasizes critical high-frequency details using dynamically updated convolution kernels. To effectively fuse tumor features across multiple scales, we design a Frequency Domain Cross-Attention (FDCA) integrating semantic, positional, and slice-specific information. We further validate and interpret frequency-domain improvements through visualization, theoretical reasoning, and experimental analyses. Extensive experiments on four public datasets demonstrate that HFF-Net achieves an average relative improvement of 4.48\\% (ranging from 2.39\\% to 7.72\\%) in the mean Dice scores across the three major subregions, and an average relative improvement of 7.33% (ranging from 5.96% to 8.64%) in the segmentation of contrast-enhancing tumor regions, while maintaining favorable computational efficiency and clinical applicability. Code:", "subjects": "Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV)", "comments": "Accepted by IEEE Transactions on Medical Imaging", "pdf_url": "https://arxiv.org/pdf/2506.10142.pdf", "abstract_url": "https://arxiv.org/abs/2506.10142", "categories": ["Image and Video Processing (eess.IV)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种从频域角度重新思考脑肿瘤分割的方法，即和谐频率融合网络（HFF-Net），通过频域分解模块、自适应拉普拉斯卷积模块和频域交叉注意力模块，显著提高了对比增强脑肿瘤区域的分割性能。", "motivation": "当前方法在分割对比增强的脑肿瘤区域时表现不佳，主要由于对MRI特定肿瘤特征（如复杂纹理和方向变化）的考虑不足。", "method": "提出了HFF-Net，包括频域分解模块（FDD）用于分离MRI图像的低频和高频成分，自适应拉普拉斯卷积模块（ALC）用于增强对肿瘤边界的敏感性，以及频域交叉注意力模块（FDCA）用于多尺度肿瘤特征融合。", "result": "在四个公共数据集上的实验表明，HFF-Net在三个主要子区域的平均Dice得分上实现了4.48%的相对改进，在对比增强肿瘤区域的分割上实现了7.33%的相对改进。", "conclusion": "HFF-Net不仅在分割性能上取得了显著提升，而且保持了良好的计算效率和临床适用性，为脑肿瘤分割提供了新的视角和方法。"}}
{"id": "2506.10540", "title": "AniMaker: Automated Multi-Agent Animated Storytelling with MCTS-Driven Clip Generation", "authors": ["Haoyuan Shi", "Yunxin Li", "Xinyu Chen", "Longyue Wang", "Baotian Hu", "Min Zhang"], "abstract": "Despite rapid advancements in video generation models, generating coherent storytelling videos that span multiple scenes and characters remains challenging. Current methods often rigidly convert pre-generated keyframes into fixed-length clips, resulting in disjointed narratives and pacing issues. Furthermore, the inherent instability of video generation models means that even a single low-quality clip can significantly degrade the entire output animation's logical coherence and visual continuity. To overcome these obstacles, we introduce AniMaker, a multi-agent framework enabling efficient multi-candidate clip generation and storytelling-aware clip selection, thus creating globally consistent and story-coherent animation solely from text input. The framework is structured around specialized agents, including the Director Agent for storyboard generation, the Photography Agent for video clip generation, the Reviewer Agent for evaluation, and the Post-Production Agent for editing and voiceover. Central to AniMaker's approach are two key technical components: MCTS-Gen in Photography Agent, an efficient Monte Carlo Tree Search (MCTS)-inspired strategy that intelligently navigates the candidate space to generate high-potential clips while optimizing resource usage; and AniEval in Reviewer Agent, the first framework specifically designed for multi-shot animation evaluation, which assesses critical aspects such as story-level consistency, action completion, and animation-specific features by considering each clip in the context of its preceding and succeeding clips. Experiments demonstrate that AniMaker achieves superior quality as measured by popular metrics including VBench and our proposed AniEval framework, while significantly improving the efficiency of multi-candidate generation, pushing AI-generated storytelling animation closer to production standards.", "subjects": "Multiagent Systems (cs.MA); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.10540.pdf", "abstract_url": "https://arxiv.org/abs/2506.10540", "categories": ["Multiagent Systems (cs.MA)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "AniMaker是一个多代理框架，旨在通过MCTS驱动的剪辑生成和故事感知的剪辑选择，从文本输入中创建全局一致且故事连贯的动画。", "motivation": "解决当前视频生成模型在生成跨多个场景和角色的连贯故事视频时面临的挑战，如叙事不连贯和节奏问题。", "method": "采用多代理框架，包括导演代理、摄影代理、评审代理和后期制作代理，以及MCTS-Gen和AniEval两个关键技术组件。", "result": "实验表明，AniMaker在VBench和我们提出的AniEval框架等流行指标上实现了卓越的质量，同时显著提高了多候选生成的效率。", "conclusion": "AniMaker将AI生成的故事动画推向生产标准，通过其多代理框架和关键技术组件，实现了故事连贯和视觉连续的动画生成。"}}
{"id": "2506.10172", "title": "A Navigation Framework Utilizing Vision-Language Models", "authors": ["Yicheng Duan", "Kaiyu tang"], "abstract": "Vision-and-Language Navigation (VLN) presents a complex challenge in embodied AI, requiring agents to interpret natural language instructions and navigate through visually rich, unfamiliar environments. Recent advances in large vision-language models (LVLMs), such as CLIP and Flamingo, have significantly improved multimodal understanding but introduced new challenges related to computational cost and real-time deployment. In this project, we propose a modular, plug-and-play navigation framework that decouples vision-language understanding from action planning. By integrating a frozen vision-language model, Qwen2.5-VL-7B-Instruct, with lightweight planning logic, we aim to achieve flexible, fast, and adaptable navigation without extensive model fine-tuning. Our framework leverages prompt engineering, structured history management, and a two-frame visual input strategy to enhance decision-making continuity across navigation steps. We evaluate our system on the Room-to-Room benchmark within the VLN-CE setting using the Matterport3D dataset and Habitat-Lab simulation environment. Although our initial results reveal challenges in generalizing to unseen environments under strict evaluation settings, our modular approach lays a foundation for scalable and efficient navigation systems, highlighting promising directions for future improvement through enhanced environmental priors and expanded multimodal input integration.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.10172.pdf", "abstract_url": "https://arxiv.org/abs/2506.10172", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种利用视觉语言模型（VLMs）的模块化导航框架，旨在解决视觉与语言导航（VLN）中的计算成本和实时部署挑战。通过结合冻结的视觉语言模型和轻量级规划逻辑，实现了无需大量微调的灵活、快速和适应性强的导航。", "motivation": "视觉与语言导航（VLN）在嵌入式AI中提出了复杂挑战，需要代理解释自然语言指令并在视觉丰富的陌生环境中导航。大型视觉语言模型（LVLMs）的进步虽然提升了多模态理解，但也带来了计算成本和实时部署的新挑战。", "method": "提出了一种模块化、即插即用的导航框架，将视觉语言理解与动作规划解耦。通过集成冻结的视觉语言模型Qwen2.5-VL-7B-Instruct和轻量级规划逻辑，利用提示工程、结构化历史管理和双帧视觉输入策略来增强导航步骤中的决策连续性。", "result": "在VLN-CE设置下的Room-to-Room基准测试中使用Matterport3D数据集和Habitat-Lab模拟环境进行评估。初步结果显示在严格评估设置下对未见环境的泛化能力存在挑战，但模块化方法为可扩展和高效的导航系统奠定了基础。", "conclusion": "模块化方法为未来通过增强环境先验和扩展多模态输入集成提供了有前景的改进方向，为可扩展和高效的导航系统奠定了基础。"}}
{"id": "2506.10341", "title": "Provably Learning from Language Feedback", "authors": ["Wanqiao Xu", "Allen Nie", "Ruijie Zheng", "Aditya Modi", "Adith Swaminathan", "Ching-An Cheng"], "abstract": "Interactively learning from observation and language feedback is an increasingly studied area driven by the emergence of large language model (LLM) agents. While impressive empirical demonstrations have been shown, so far a principled framing of these decision problems remains lacking. In this paper, we formalize the Learning from Language Feedback (LLF) problem, assert sufficient assumptions to enable learning despite latent rewards, and introduce $\\textit{transfer eluder dimension}$ as a complexity measure to characterize the hardness of LLF problems. We show that transfer eluder dimension captures the intuition that information in the feedback changes the learning complexity of the LLF problem. We demonstrate cases where learning from rich language feedback can be exponentially faster than learning from reward. We develop a no-regret algorithm, called $\\texttt{HELiX}$, that provably solves LLF problems through sequential interactions, with performance guarantees that scale with the transfer eluder dimension of the problem. Across several empirical domains, we show that $\\texttt{HELiX}$ performs well even when repeatedly prompting LLMs does not work reliably. Our contributions mark a first step towards designing principled interactive learning algorithms from generic language feedback.", "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.10341.pdf", "abstract_url": "https://arxiv.org/abs/2506.10341", "categories": ["Machine Learning (cs.LG)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了从语言反馈中学习（LLF）问题的正式框架，引入了转移迷惑维度作为衡量LLF问题复杂性的指标，并开发了一种名为HELiX的无悔算法，该算法通过顺序交互解决LLF问题，其性能保证与问题的转移迷惑维度成比例。", "motivation": "尽管大型语言模型（LLM）代理的出现推动了从观察和语言反馈中交互式学习的研究，但这一决策问题的原则性框架仍然缺乏。本文旨在填补这一空白，提供一个正式的学习框架。", "method": "本文通过引入转移迷惑维度作为复杂性度量，正式化了LLF问题，并开发了HELiX算法，该算法通过顺序交互解决LLF问题，并提供了与转移迷惑维度成比例的性能保证。", "result": "研究表明，转移迷惑维度能够捕捉反馈信息改变LLF问题学习复杂性的直觉，展示了在某些情况下，从丰富的语言反馈中学习可以比从奖励中学习快指数倍。HELiX算法在多个实证领域中表现良好，即使在重复提示LLMs不可靠的情况下也是如此。", "conclusion": "本文的贡献标志着向设计从通用语言反馈中交互式学习的原则性算法迈出了第一步，为未来的研究奠定了基础。"}}
{"id": "2506.10825", "title": "Generalist Models in Medical Image Segmentation: A Survey and Performance Comparison with Task-Specific Approaches", "authors": ["Andrea Moglia", "Matteo Leccardi", "Matteo Cavicchioli", "Alice Maccarini", "Marco Marcon", "Luca Mainardi", "Pietro Cerveri"], "abstract": "Following the successful paradigm shift of large language models, leveraging pre-training on a massive corpus of data and fine-tuning on different downstream tasks, generalist models have made their foray into computer vision. The introduction of Segment Anything Model (SAM) set a milestone on segmentation of natural images, inspiring the design of a multitude of architectures for medical image segmentation. In this survey we offer a comprehensive and in-depth investigation on generalist models for medical image segmentation. We start with an introduction on the fundamentals concepts underpinning their development. Then, we provide a taxonomy on the different declinations of SAM in terms of zero-shot, few-shot, fine-tuning, adapters, on the recent SAM 2, on other innovative models trained on images alone, and others trained on both text and images. We thoroughly analyze their performances at the level of both primary research and best-in-literature, followed by a rigorous comparison with the state-of-the-art task-specific models. We emphasize the need to address challenges in terms of compliance with regulatory frameworks, privacy and security laws, budget, and trustworthy artificial intelligence (AI). Finally, we share our perspective on future directions concerning synthetic data, early fusion, lessons learnt from generalist models in natural language processing, agentic AI and physical AI, and clinical translation.", "subjects": "Image and Video Processing (eess.IV); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "comments": "132 pages, 26 figures, 23 tables. Andrea Moglia and Matteo Leccardi are equally contributing authors", "pdf_url": "https://arxiv.org/pdf/2506.10825.pdf", "abstract_url": "https://arxiv.org/abs/2506.10825", "categories": ["Image and Video Processing (eess.IV)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文综述了医学图像分割中的通用模型，特别是受Segment Anything Model（SAM）启发的多种架构，并对其性能与任务特定模型进行了比较。", "motivation": "探索通用模型在医学图像分割领域的应用，解决如何利用大规模预训练和微调在不同下游任务上实现高效分割的问题。", "method": "通过分类SAM的不同变体（如零样本、少样本、微调、适配器等）及其他创新模型，分析其在医学图像分割中的性能。", "result": "通用模型在医学图像分割中展现出潜力，但仍需解决合规性、隐私安全、预算及可信AI等挑战。", "conclusion": "未来研究方向包括合成数据、早期融合、从自然语言处理中学习的通用模型经验、代理AI和物理AI，以及临床转化。"}}
{"id": "2506.10968", "title": "Eye, Robot: Learning to Look to Act with a BC-RL Perception-Action Loop", "authors": ["Justin Kerr", "Kush Hari", "Ethan Weber", "Chung Min Kim", "Brent Yi", "Tyler Bonnen", "Ken Goldberg", "Angjoo Kanazawa"], "abstract": "Humans do not passively observe the visual world -- we actively look in order to act. Motivated by this principle, we introduce EyeRobot, a robotic system with gaze behavior that emerges from the need to complete real-world tasks. We develop a mechanical eyeball that can freely rotate to observe its surroundings and train a gaze policy to control it using reinforcement learning. We accomplish this by first collecting teleoperated demonstrations paired with a 360 camera. This data is imported into a simulation environment that supports rendering arbitrary eyeball viewpoints, allowing episode rollouts of eye gaze on top of robot demonstrations. We then introduce a BC-RL loop to train the hand and eye jointly: the hand (BC) agent is trained from rendered eye observations, and the eye (RL) agent is rewarded when the hand produces correct action predictions. In this way, hand-eye coordination emerges as the eye looks towards regions which allow the hand to complete the task. EyeRobot implements a foveal-inspired policy architecture allowing high resolution with a small compute budget, which we find also leads to the emergence of more stable fixation as well as improved ability to track objects and ignore distractors. We evaluate EyeRobot on five panoramic workspace manipulation tasks requiring manipulation in an arc surrounding the robot arm. Our experiments suggest EyeRobot exhibits hand-eye coordination behaviors which effectively facilitate manipulation over large workspaces with a single camera. See project site for videos:", "subjects": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2506.10968.pdf", "abstract_url": "https://arxiv.org/abs/2506.10968", "categories": ["Robotics (cs.RO)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "EyeRobot是一个模仿人类主动观察行为的机器人系统，通过强化学习训练凝视策略，以实现手眼协调完成真实世界任务。", "motivation": "解决机器人如何像人类一样通过主动观察来指导行动的问题。", "method": "开发了一个可以自由旋转的机械眼球，收集遥操作演示数据，并在模拟环境中训练手（BC）和眼（RL）的联合策略。", "result": "EyeRobot在五个全景工作空间操作任务中表现出有效的手眼协调行为，能够在单一摄像头下完成大工作空间的操纵。", "conclusion": "EyeRobot通过模仿人类的主动观察行为，实现了有效的手眼协调，为机器人在大工作空间中的操作提供了新方法。"}}
{"id": "2506.10751", "title": "Neural at ArchEHR-QA 2025: Agentic Prompt Optimization for Evidence-Grounded Clinical Question Answering", "authors": ["Sai Prasanna Teja Reddy Bogireddy", "Abrar Majeedi", "Viswanatha Reddy Gajjala", "Zhuoyan Xu", "Siddhant Rai", "Vaishnav Potlapalli"], "abstract": "Automated question answering (QA) over electronic health records (EHRs) can bridge critical information gaps for clinicians and patients, yet it demands both precise evidence retrieval and faithful answer generation under limited supervision. In this work, we present Neural, the runner-up in the BioNLP 2025 ArchEHR-QA shared task on evidence-grounded clinical QA. Our proposed method decouples the task into (1) sentence-level evidence identification and (2) answer synthesis with explicit citations. For each stage, we automatically explore the prompt space with DSPy's MIPROv2 optimizer, jointly tuning instructions and few-shot demonstrations on the development set. A self-consistency voting scheme further improves evidence recall without sacrificing precision. On the hidden test set, our method attains an overall score of 51.5, placing second stage while outperforming standard zero-shot and few-shot prompting by over 20 and 10 points, respectively. These results indicate that data-driven prompt optimization is a cost-effective alternative to model fine-tuning for high-stakes clinical QA, advancing the reliability of AI assistants in healthcare.", "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.10751.pdf", "abstract_url": "https://arxiv.org/abs/2506.10751", "categories": ["Machine Learning (cs.LG)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了Neural在BioNLP 2025 ArchEHR-QA共享任务中的亚军方法，该方法通过解耦任务为证据识别和答案合成，并利用DSPy的MIPROv2优化器自动探索提示空间，提高了临床问答的准确性和可靠性。", "motivation": "解决电子健康记录(EHRs)自动问答(QA)中的精确证据检索和有限监督下的忠实答案生成问题，以填补临床医生和患者的关键信息缺口。", "method": "将任务解耦为句子级证据识别和带明确引用的答案合成两个阶段，使用DSPy的MIPROv2优化器自动探索提示空间，并通过自一致性投票方案提高证据召回率。", "result": "在隐藏测试集上，该方法获得了51.5的总分，位居第二，比标准的零样本和少样本提示分别高出20和10分以上。", "conclusion": "数据驱动的提示优化是高风险临床QA中模型微调的成本效益替代方案，提高了医疗保健中AI助手的可靠性。"}}
{"id": "2506.10953", "title": "Build the web for agents, not agents for the web", "authors": ["Xing Han Lù", "Gaurav Kamath", "Marius Mosbach", "Siva Reddy"], "abstract": "Recent advancements in Large Language Models (LLMs) and multimodal counterparts have spurred significant interest in developing web agents -- AI systems capable of autonomously navigating and completing tasks within web environments. While holding tremendous promise for automating complex web interactions, current approaches face substantial challenges due to the fundamental mismatch between human-designed interfaces and LLM capabilities. Current methods struggle with the inherent complexity of web inputs, whether processing massive DOM trees, relying on screenshots augmented with additional information, or bypassing the user interface entirely through API interactions. This position paper advocates for a paradigm shift in web agent research: rather than forcing web agents to adapt to interfaces designed for humans, we should develop a new interaction paradigm specifically optimized for agentic capabilities. To this end, we introduce the concept of an Agentic Web Interface (AWI), an interface specifically designed for agents to navigate a website. We establish six guiding principles for AWI design, emphasizing safety, efficiency, and standardization, to account for the interests of all primary stakeholders. This reframing aims to overcome fundamental limitations of existing interfaces, paving the way for more efficient, reliable, and transparent web agent design, which will be a collaborative effort involving the broader ML community.", "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.10953.pdf", "abstract_url": "https://arxiv.org/abs/2506.10953", "categories": ["Machine Learning (cs.LG)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种新的网络代理研究范式，主张开发专为代理能力优化的交互范式，而非让代理适应人类设计的界面。", "motivation": "解决当前网络代理方法因人类设计界面与大型语言模型能力不匹配而面临的重大挑战。", "method": "引入代理性网络界面（AWI）的概念，并建立了六项设计原则，强调安全性、效率和标准化。", "result": "提出了一个旨在克服现有界面基本限制的新框架，为更高效、可靠和透明的网络代理设计铺平道路。", "conclusion": "通过更广泛的ML社区的合作努力，这一重新框架旨在推动网络代理设计的进步。"}}
{"id": "2506.10330", "title": "Augmenting Large Language Models with Static Code Analysis for Automated Code Quality Improvements", "authors": ["Seyed Moein Abtahi", "Akramul Azim"], "abstract": "This study examined code issue detection and revision automation by integrating Large Language Models (LLMs) such as OpenAI's GPT-3.5 Turbo and GPT-4o into software development workflows. A static code analysis framework detects issues such as bugs, vulnerabilities, and code smells within a large-scale software project. Detailed information on each issue was extracted and organized to facilitate automated code revision using LLMs. An iterative prompt engineering process is applied to ensure that prompts are structured to produce accurate and organized outputs aligned with the project requirements. Retrieval-augmented generation (RAG) is implemented to enhance the relevance and precision of the revisions, enabling LLM to access and integrate real-time external knowledge. The issue of LLM hallucinations - where the model generates plausible but incorrect outputs - is addressed by a custom-built \"Code Comparison App,\" which identifies and corrects erroneous changes before applying them to the codebase. Subsequent scans using the static code analysis framework revealed a significant reduction in code issues, demonstrating the effectiveness of combining LLMs, static analysis, and RAG to improve code quality, streamline the software development process, and reduce time and resource expenditure.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": "Accepted at FORGE 2025", "pdf_url": "https://arxiv.org/pdf/2506.10330.pdf", "abstract_url": "https://arxiv.org/abs/2506.10330", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本研究探讨了通过将大型语言模型（LLMs）如OpenAI的GPT-3.5 Turbo和GPT-4o集成到软件开发工作流中，实现代码问题检测和修订自动化的方法。通过静态代码分析框架检测大规模软件项目中的问题，并利用LLMs进行自动化代码修订。采用迭代提示工程和检索增强生成（RAG）技术提高修订的准确性和相关性，同时通过自定义的“代码比较应用”解决LLM幻觉问题。结果表明，该方法显著减少了代码问题，提高了代码质量。", "motivation": "解决软件开发过程中代码质量问题，通过自动化检测和修订代码问题，提高开发效率，减少时间和资源消耗。", "method": "结合静态代码分析框架和大型语言模型（LLMs），采用迭代提示工程和检索增强生成（RAG）技术，以及自定义的“代码比较应用”来检测和修订代码问题。", "result": "通过后续的静态代码分析扫描，发现代码问题显著减少，证明了结合LLMs、静态分析和RAG技术在提高代码质量方面的有效性。", "conclusion": "研究表明，将大型语言模型与静态代码分析和检索增强生成技术结合，可以有效地自动化代码质量改进，优化软件开发流程，减少资源消耗。"}}
{"id": "2506.10467", "title": "Specification and Evaluation of Multi-Agent LLM Systems -- Prototype and Cybersecurity Applications", "authors": ["Felix Härer"], "abstract": "Recent advancements in LLMs indicate potential for novel applications, e.g., through reasoning capabilities in the latest OpenAI and DeepSeek models. For applying these models in specific domains beyond text generation, LLM-based multi-agent approaches can be utilized that solve complex tasks by combining reasoning techniques, code generation, and software execution. Applications might utilize these capabilities and the knowledge of specialized LLM agents. However, while many evaluations are performed on LLMs, reasoning techniques, and applications individually, their joint specification and combined application is not explored well. Defined specifications for multi-agent LLM systems are required to explore their potential and their suitability for specific applications, allowing for systematic evaluations of LLMs, reasoning techniques, and related aspects. This paper reports the results of exploratory research to specify and evaluate these aspects through a multi-agent system. The system architecture and prototype are extended from previous research and a specification is introduced for multi-agent systems. Test cases involving cybersecurity tasks indicate feasibility of the architecture and evaluation approach. In particular, the results show the evaluation of question answering, server security, and network security tasks that were completed correctly by agents with LLMs from OpenAI and DeepSeek.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.10467.pdf", "abstract_url": "https://arxiv.org/abs/2506.10467", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了基于LLM的多智能体系统在特定领域（如网络安全）中的应用潜力，提出了一个多智能体系统的规范，并通过原型和测试案例验证了其可行性。", "motivation": "探索LLM在多智能体系统中的联合应用潜力，特别是在网络安全等特定领域，以解决复杂任务。", "method": "扩展了之前研究的系统架构和原型，引入了多智能体系统的规范，并通过网络安全任务的测试案例进行评估。", "result": "测试结果表明，使用OpenAI和DeepSeek的LLM智能体能够正确完成问答、服务器安全和网络安全任务。", "conclusion": "研究表明，基于LLM的多智能体系统在特定应用中具有潜力，提出的规范和评估方法为未来的系统化评估奠定了基础。"}}
{"id": "2506.10460", "title": "Equitable Mechanism Design for Facility Location", "authors": ["Toby Walsh"], "abstract": "We consider strategy proof mechanisms for facility location which maximize equitability between agents. As is common in the literature, we measure equitability with the Gini index. We first prove a simple but fundamental impossibility result that no strategy proof mechanism can bound the approximation ratio of the optimal Gini index of utilities for one or more facilities. We propose instead computing approximation ratios of the complemented Gini index of utilities, and consider how well both deterministic and randomized mechanisms approximate this. In addition, as Nash welfare is often put forwards as an equitable compromise between egalitarian and utilitarian outcomes, we consider how well mechanisms approximate the Nash welfare.", "subjects": "Computer Science and Game Theory (cs.GT); Artificial Intelligence (cs.AI)", "comments": "To appear in Proceedings of IJCAI 2025", "pdf_url": "https://arxiv.org/pdf/2506.10460.pdf", "abstract_url": "https://arxiv.org/abs/2506.10460", "categories": ["Computer Science and Game Theory (cs.GT)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究了设施选址的策略证明机制，旨在最大化代理之间的公平性，使用基尼指数衡量公平性。首先证明了一个基本的不可能性结果，即没有策略证明机制可以限制一个或多个设施的最优基尼指数的近似比。然后提出了计算效用补充基尼指数的近似比，并考虑了确定性和随机性机制对此的近似效果。此外，还探讨了机制如何近似纳什福利，作为平等主义和功利主义结果之间的公平折衷。", "motivation": "解决在设施选址问题中如何设计策略证明机制以最大化代理之间的公平性，特别是在无法限制最优基尼指数近似比的情况下，寻找替代的公平性衡量方法和机制。", "method": "使用基尼指数衡量公平性，提出计算效用补充基尼指数的近似比，并分析确定性和随机性机制对此的近似效果；同时考虑纳什福利作为公平性衡量标准。", "result": "证明了一个基本的不可能性结果，即没有策略证明机制可以限制最优基尼指数的近似比；提出了计算效用补充基尼指数的近似比，并展示了不同机制对此的近似效果。", "conclusion": "在设施选址的策略证明机制设计中，直接限制最优基尼指数的近似比是不可能的，但通过计算效用补充基尼指数的近似比和考虑纳什福利，可以找到有效的公平性衡量和机制设计方法。"}}
{"id": "2506.10925", "title": "Agentic Semantic Control for Autonomous Wireless Space Networks: Extending Space-O-RAN with MCP-Driven Distributed Intelligence", "authors": ["Eduardo Baena", "Paolo Testolina", "Michele Polese", "Sergi Aliaga", "Andrew Benincasa", "Dimitrios Koutsonikolas", "Josep Jornet", "Tommaso Melodia"], "abstract": "Lunar surface operations impose stringent requirements on wireless communication systems, including autonomy, robustness to disruption, and the ability to adapt to environmental and mission-driven context. While Space-O-RAN provides a distributed orchestration model aligned with 3GPP standards, its decision logic is limited to static policies and lacks semantic integration. We propose a novel extension incorporating a semantic agentic layer enabled by the Model Context Protocol (MCP) and Agent-to-Agent (A2A) communication protocols, allowing context-aware decision making across real-time, near-real-time, and non-real-time control layers. Distributed cognitive agents deployed in rovers, landers, and lunar base stations implement wireless-aware coordination strategies, including delay-adaptive reasoning and bandwidth-aware semantic compression, while interacting with multiple MCP servers to reason over telemetry, locomotion planning, and mission constraints.", "subjects": "Networking and Internet Architecture (cs.NI); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Systems and Control (eess.SY)", "comments": "Lunar Surface Innovation Consortium 2025 Spring Meeting, May 20-22", "pdf_url": "https://arxiv.org/pdf/2506.10925.pdf", "abstract_url": "https://arxiv.org/abs/2506.10925", "categories": ["Networking and Internet Architecture (cs.NI)", "Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)", "Systems and Control (eess.SY)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种新型的扩展方法，通过模型上下文协议（MCP）和代理到代理（A2A）通信协议，为Space-O-RAN增加了语义代理层，以实现跨实时、近实时和非实时控制层的上下文感知决策。", "motivation": "月球表面操作对无线通信系统提出了严格的要求，包括自主性、对中断的鲁棒性以及适应环境和任务驱动上下文的能力。Space-O-RAN的决策逻辑仅限于静态策略，缺乏语义集成。", "method": "采用MCP和A2A通信协议，引入语义代理层，部署分布式认知代理于漫游车、着陆器和月球基站，实现无线感知协调策略。", "result": "提出的方法能够实现延迟自适应推理和带宽感知语义压缩，同时与多个MCP服务器交互，以推理遥测、运动规划和任务约束。", "conclusion": "通过扩展Space-O-RAN，本研究为月球表面操作提供了一种更加自主和适应性强的无线通信解决方案，具有重要的实际应用价值。"}}
{"id": "2506.10756", "title": "Grounded Vision-Language Navigation for UAVs with Open-Vocabulary Goal Understanding", "authors": ["Yuhang Zhang", "Haosheng Yu", "Jiaping Xiao", "Mir Feroskhan"], "abstract": "Vision-and-language navigation (VLN) is a long-standing challenge in autonomous robotics, aiming to empower agents with the ability to follow human instructions while navigating complex environments. Two key bottlenecks remain in this field: generalization to out-of-distribution environments and reliance on fixed discrete action spaces. To address these challenges, we propose Vision-Language Fly (VLFly), a framework tailored for Unmanned Aerial Vehicles (UAVs) to execute language-guided flight. Without the requirement for localization or active ranging sensors, VLFly outputs continuous velocity commands purely from egocentric observations captured by an onboard monocular camera. The VLFly integrates three modules: an instruction encoder based on a large language model (LLM) that reformulates high-level language into structured prompts, a goal retriever powered by a vision-language model (VLM) that matches these prompts to goal images via vision-language similarity, and a waypoint planner that generates executable trajectories for real-time UAV control. VLFly is evaluated across diverse simulation environments without additional fine-tuning and consistently outperforms all baselines. Moreover, real-world VLN tasks in indoor and outdoor environments under direct and indirect instructions demonstrate that VLFly achieves robust open-vocabulary goal understanding and generalized navigation capabilities, even in the presence of abstract language input.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.10756.pdf", "abstract_url": "https://arxiv.org/abs/2506.10756", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了Vision-Language Fly (VLFly)框架，专为无人机(UAVs)设计，通过语言引导飞行解决视觉与语言导航(VLN)中的泛化问题和固定离散动作空间的依赖问题。VLFly无需定位或主动测距传感器，仅通过单目摄像头捕获的自我中心观察输出连续速度命令，集成了基于大型语言模型(LLM)的指令编码器、基于视觉语言模型(VLM)的目标检索器和航点规划器，在多样化的模拟环境和真实世界的VLN任务中表现出色。", "motivation": "解决视觉与语言导航(VLN)领域中的两个关键瓶颈：对分布外环境的泛化能力和对固定离散动作空间的依赖。", "method": "提出VLFly框架，集成指令编码器、目标检索器和航点规划器三个模块，通过大型语言模型(LLM)和视觉语言模型(VLM)实现语言指令到连续速度命令的转换。", "result": "VLFly在多样化模拟环境中无需额外微调即超越所有基线方法，在真实世界的室内外VLN任务中展现出强大的开放词汇目标理解和泛化导航能力。", "conclusion": "VLFly框架通过集成先进的LLM和VLM技术，显著提升了无人机在复杂环境中执行语言引导飞行的能力，特别是在处理抽象语言输入时表现出色。"}}
{"id": "2506.10949", "title": "Monitoring Decomposition Attacks in LLMs with Lightweight Sequential Monitors", "authors": ["Chen Yueh-Han", "Nitish Joshi", "Yulin Chen", "Maksym Andriushchenko", "Rico Angell", "He He"], "abstract": "Current LLM safety defenses fail under decomposition attacks, where a malicious goal is decomposed into benign subtasks that circumvent refusals. The challenge lies in the existing shallow safety alignment techniques: they only detect harm in the immediate prompt and do not reason about long-range intent, leaving them blind to malicious intent that emerges over a sequence of seemingly benign instructions. We therefore propose adding an external monitor that observes the conversation at a higher granularity. To facilitate our study of monitoring decomposition attacks, we curate the largest and most diverse dataset to date, including question-answering, text-to-image, and agentic tasks. We verify our datasets by testing them on frontier LLMs and show an 87% attack success rate on average on GPT-4o. This confirms that decomposition attack is broadly effective. Additionally, we find that random tasks can be injected into the decomposed subtasks to further obfuscate malicious intents. To defend in real time, we propose a lightweight sequential monitoring framework that cumulatively evaluates each subtask. We show that a carefully prompt engineered lightweight monitor achieves a 93% defense success rate, beating reasoning models like o3 mini as a monitor. Moreover, it remains robust against random task injection and cuts cost by 90% and latency by 50%. Our findings suggest that lightweight sequential monitors are highly effective in mitigating decomposition attacks and are viable in deployment.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.10949.pdf", "abstract_url": "https://arxiv.org/abs/2506.10949", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种轻量级序列监控框架，用于监测和防御大型语言模型（LLMs）中的分解攻击，通过累积评估每个子任务来有效识别和阻止恶意意图，同时显著降低成本和延迟。", "motivation": "当前的大型语言模型安全防御在分解攻击下失效，即恶意目标被分解为规避拒绝的良性子任务。现有浅层安全对齐技术仅能检测即时提示中的危害，无法推理长程意图，导致对看似良性指令序列中显现的恶意意图视而不见。", "method": "提出添加一个外部监控器，以更高粒度观察对话。为了研究监控分解攻击，作者策划了迄今为止最大、最多样化的数据集，包括问答、文本到图像和代理任务。并提出了一个轻量级序列监控框架，累积评估每个子任务。", "result": "在GPT-4o上平均攻击成功率达到87%，证实分解攻击广泛有效。提出的轻量级监控器防御成功率达到93%，优于推理模型如o3 mini，且对随机任务注入保持鲁棒，成本和延迟分别降低90%和50%。", "conclusion": "轻量级序列监控器在缓解分解攻击方面非常有效，且在实际部署中可行。"}}
{"id": "2506.10954", "title": "SWE-Factory: Your Automated Factory for Issue Resolution Training Data and Evaluation Benchmarks", "authors": ["Lianghong Guo", "Yanlin Wang", "Caihua Li", "Pengyu Yang", "Jiachi Chen", "Wei Tao", "Yingtian Zou", "Duyu Tang", "Zibin Zheng"], "abstract": "Constructing large-scale datasets for the GitHub issue resolution task is crucial for both training and evaluating the software engineering capabilities of Large Language Models (LLMs). However, the traditional process for creating such benchmarks is notoriously challenging and labor-intensive, particularly in the stages of setting up evaluation environments, grading test outcomes, and validating task instances. In this paper, we propose SWE-Factory, an automated pipeline designed to address these challenges. To tackle these issues, our pipeline integrates three core automated components. First, we introduce SWE-Builder, a multi-agent system that automates evaluation environment construction, which employs four specialized agents that work in a collaborative, iterative loop and leverages an environment memory pool to enhance efficiency. Second, we introduce a standardized, exit-code-based grading method that eliminates the need for manually writing custom parsers. Finally, we automate the fail2pass validation process using these reliable exit code signals. Experiments on 671 issues across four programming languages show that our pipeline can effectively construct valid task instances; for example, with GPT-4.1-mini, our SWE-Builder constructs 269 valid instances at $0.045 per instance, while with Gemini-2.5-flash, it achieves comparable performance at the lowest cost of $0.024 per instance. We also demonstrate that our exit-code-based grading achieves 100% accuracy compared to manual inspection, and our automated fail2pass validation reaches a precision of 0.92 and a recall of 1.00. We hope our automated pipeline will accelerate the collection of large-scale, high-quality GitHub issue resolution datasets for both training and evaluation. Our code and datasets are released at", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.10954.pdf", "abstract_url": "https://arxiv.org/abs/2506.10954", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "SWE-Factory是一个自动化管道，旨在解决构建GitHub问题解决任务大规模数据集的挑战，通过集成三个核心自动化组件来高效构建评估环境、标准化评分和自动化验证过程。", "motivation": "传统构建GitHub问题解决任务基准的过程既具挑战性又劳动密集型，特别是在设置评估环境、评分测试结果和验证任务实例阶段。", "method": "SWE-Factory集成了三个自动化组件：SWE-Builder（一个多代理系统，自动化评估环境构建）、基于退出码的标准化评分方法、以及利用可靠退出码信号自动化fail2pass验证过程。", "result": "在四种编程语言的671个问题上进行的实验显示，SWE-Factory能有效构建有效任务实例，如GPT-4.1-mini构建269个有效实例，每个实例成本$0.045；基于退出码的评分达到100%准确率；自动化fail2pass验证达到0.92的精确度和1.00的召回率。", "conclusion": "SWE-Factory的自动化管道有望加速大规模、高质量GitHub问题解决数据集的收集，为训练和评估提供支持。"}}
