{"id": "2504.18070", "title": "PropRAG: Guiding Retrieval with Beam Search over Proposition Paths", "authors": ["Jingjin Wang"], "abstract": "Retrieval Augmented Generation (RAG) has become the standard non-parametric approach for equipping Large Language Models (LLMs) with up-to-date knowledge and mitigating catastrophic forgetting common in continual learning. However, standard RAG, relying on independent passage retrieval, fails to capture the interconnected nature of human memory crucial for complex reasoning (associativity) and contextual understanding (sense-making). While structured RAG methods like HippoRAG utilize knowledge graphs (KGs) built from triples, the inherent context loss limits fidelity. We introduce PropRAG, a framework leveraging contextually rich propositions and a novel beam search algorithm over proposition paths to explicitly discover multi-step reasoning chains. Crucially, PropRAG's online retrieval process operates entirely without invoking generative LLMs, relying instead on efficient graph traversal and pre-computed embeddings. This avoids online LLM inference costs and potential inconsistencies during evidence gathering. LLMs are used effectively offline for high-quality proposition extraction and post-retrieval for answer generation. PropRAG achieves state-of-the-art zero-shot Recall@5 results on PopQA (55.3%), 2Wiki (93.7%), HotpotQA (97.0%), and MuSiQue (77.3%), alongside top F1 scores (e.g., 52.4% on MuSiQue). By improving evidence retrieval through richer representation and explicit, LLM-free online path finding, PropRAG advances non-parametric continual learning.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2504.18070.pdf", "abstract_url": "https://arxiv.org/abs/2504.18070", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "PropRAG是一种新型的检索增强生成框架，通过利用丰富的上下文命题和创新的束搜索算法，显式发现多步推理链，以改进标准RAG方法在复杂推理和上下文理解方面的不足。", "motivation": "解决标准RAG方法在捕获人类记忆的互联性（关联性和意义构建）方面的不足，以及结构化RAG方法如HippoRAG因知识图谱构建中的上下文丢失而受限的问题。", "method": "引入PropRAG框架，利用上下文丰富的命题和一种新颖的束搜索算法在命题路径上进行搜索，完全依赖高效的图遍历和预计算嵌入，避免在线LLM推理成本和证据收集过程中的不一致性。", "result": "在PopQA、2Wiki、HotpotQA和MuSiQue等数据集上实现了最先进的零样本Recall@5结果和顶级F1分数。", "conclusion": "通过更丰富的表示和显式的、无需LLM的在线路径查找改进证据检索，PropRAG推动了非参数持续学习的进步。"}}
{"id": "2504.18041", "title": "RAG LLMs are Not Safer: A Safety Analysis of Retrieval-Augmented Generation for Large Language Models", "authors": ["Bang An", "Shiyue Zhang", "Mark Dredze"], "abstract": "Efforts to ensure the safety of large language models (LLMs) include safety fine-tuning, evaluation, and red teaming. However, despite the widespread use of the Retrieval-Augmented Generation (RAG) framework, AI safety work focuses on standard LLMs, which means we know little about how RAG use cases change a model's safety profile. We conduct a detailed comparative analysis of RAG and non-RAG frameworks with eleven LLMs. We find that RAG can make models less safe and change their safety profile. We explore the causes of this change and find that even combinations of safe models with safe documents can cause unsafe generations. In addition, we evaluate some existing red teaming methods for RAG settings and show that they are less effective than when used for non-RAG settings. Our work highlights the need for safety research and red-teaming methods specifically tailored for RAG LLMs.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "NAACL 2025", "pdf_url": "https://arxiv.org/pdf/2504.18041.pdf", "abstract_url": "https://arxiv.org/abs/2504.18041", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文通过对比分析RAG与非RAG框架下的十一个大型语言模型，发现RAG可能降低模型的安全性并改变其安全特性。研究还探讨了导致这种变化的原因，并评估了现有红队方法在RAG环境下的效果，指出需要专门针对RAG LLMs的安全研究和红队方法。", "motivation": "尽管检索增强生成（RAG）框架被广泛使用，但AI安全研究主要集中在标准大型语言模型（LLMs）上，对RAG如何改变模型的安全特性知之甚少。", "method": "进行了RAG与非RAG框架的详细对比分析，涉及十一个LLMs，并探讨了安全变化的原因及现有红队方法在RAG环境下的有效性。", "result": "研究发现RAG可能使模型安全性降低，并改变其安全特性；即使安全模型与安全文档结合也可能产生不安全的内容；现有红队方法在RAG环境下效果较差。", "conclusion": "强调了需要针对RAG LLMs进行专门的安全研究和开发更有效的红队方法。"}}
{"id": "2504.18058", "title": "Exploring Personality-Aware Interactions in Salesperson Dialogue Agents", "authors": ["Sijia Cheng", "Wen-Yu Chang", "Yun-Nung Chen"], "abstract": "The integration of dialogue agents into the sales domain requires a deep understanding of how these systems interact with users possessing diverse personas. This study explores the influence of user personas, defined using the Myers-Briggs Type Indicator (MBTI), on the interaction quality and performance of sales-oriented dialogue agents. Through large-scale testing and analysis, we assess the pre-trained agent's effectiveness, adaptability, and personalization capabilities across a wide range of MBTI-defined user types. Our findings reveal significant patterns in interaction dynamics, task completion rates, and dialogue naturalness, underscoring the future potential for dialogue agents to refine their strategies to better align with varying personality traits. This work not only provides actionable insights for building more adaptive and user-centric conversational systems in the sales domain but also contributes broadly to the field by releasing persona-defined user simulators. These simulators, unconstrained by domain, offer valuable tools for future research and demonstrate the potential for scaling personalized dialogue systems across diverse applications.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "Accepted by IWSDS 2025", "pdf_url": "https://arxiv.org/pdf/2504.18058.pdf", "abstract_url": "https://arxiv.org/abs/2504.18058", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本研究探讨了基于MBTI定义的用户人格对销售导向对话代理交互质量和性能的影响，揭示了交互动态、任务完成率和对话自然度的显著模式，为构建更适应和以用户为中心的对话系统提供了可操作的见解。", "motivation": "将对话代理集成到销售领域需要深入理解这些系统如何与具有不同人格的用户互动。", "method": "通过大规模测试和分析，评估预训练代理在广泛MBTI定义用户类型中的有效性、适应性和个性化能力。", "result": "发现交互动态、任务完成率和对话自然度的显著模式，强调了对话代理未来潜力，以优化其策略更好地适应不同人格特质。", "conclusion": "这项工作不仅为销售领域构建更适应和以用户为中心的对话系统提供了可操作的见解，还通过发布不受领域限制的人格定义用户模拟器，为未来研究和扩展个性化对话系统到多样化应用展示了潜力。"}}
{"id": "2504.18349", "title": "Revisiting Data Auditing in Large Vision-Language Models", "authors": ["Hongyu Zhu", "Sichu Liang", "Wenwen Wang", "Boheng Li", "Tongxin Yuan", "Fangqi Li", "ShiLin Wang", "Zhuosheng Zhang"], "abstract": "With the surge of large language models (LLMs), Large Vision-Language Models (VLMs)--which integrate vision encoders with LLMs for accurate visual grounding--have shown great potential in tasks like generalist agents and robotic control. However, VLMs are typically trained on massive web-scraped images, raising concerns over copyright infringement and privacy violations, and making data auditing increasingly urgent. Membership inference (MI), which determines whether a sample was used in training, has emerged as a key auditing technique, with promising results on open-source VLMs like LLaVA (AUC > 80%). In this work, we revisit these advances and uncover a critical issue: current MI benchmarks suffer from distribution shifts between member and non-member images, introducing shortcut cues that inflate MI performance. We further analyze the nature of these shifts and propose a principled metric based on optimal transport to quantify the distribution discrepancy. To evaluate MI in realistic settings, we construct new benchmarks with i.i.d. member and non-member images. Existing MI methods fail under these unbiased conditions, performing only marginally better than chance. Further, we explore the theoretical upper bound of MI by probing the Bayes Optimality within the VLM's embedding space and find the irreducible error rate remains high. Despite this pessimistic outlook, we analyze why MI for VLMs is particularly challenging and identify three practical scenarios--fine-tuning, access to ground-truth texts, and set-based inference--where auditing becomes feasible. Our study presents a systematic view of the limits and opportunities of MI for VLMs, providing guidance for future efforts in trustworthy data auditing.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Cryptography and Security (cs.CR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.18349.pdf", "abstract_url": "https://arxiv.org/abs/2504.18349", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Cryptography and Security (cs.CR)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文重新审视了大型视觉语言模型（VLMs）中的数据审计问题，揭示了当前成员推理（MI）基准测试中存在的分布偏移问题，并提出了一种基于最优传输的原则性度量来量化分布差异。研究发现，在无偏条件下，现有的MI方法表现不佳，接近随机猜测。尽管前景悲观，但研究指出了三种实际场景，使得审计变得可行。", "motivation": "随着大型语言模型（LLMs）的兴起，大型视觉语言模型（VLMs）在通用代理和机器人控制等任务中显示出巨大潜力。然而，VLMs通常在大规模网络抓取的图像上训练，引发了版权侵权和隐私侵犯的担忧，使得数据审计变得日益紧迫。", "method": "本文分析了当前MI基准测试中的分布偏移问题，提出了一种基于最优传输的原则性度量来量化分布差异，并构建了新的i.i.d.成员和非成员图像基准测试来评估MI。此外，探索了MI的理论上限，并分析了VLM嵌入空间中的贝叶斯最优性。", "result": "研究发现，现有的MI方法在无偏条件下表现不佳，仅略优于随机猜测。同时，发现MI的不可约错误率仍然很高。然而，研究指出了三种实际场景（微调、访问真实文本和基于集合的推理），在这些场景下审计变得可行。", "conclusion": "本研究系统地探讨了MI在VLMs中的局限性和机会，为未来可信数据审计的努力提供了指导。尽管MI在VLMs中面临挑战，但在特定实际场景下，审计仍然是可行的。"}}
{"id": "2504.18355", "title": "Interpretable Affordance Detection on 3D Point Clouds with Probabilistic Prototypes", "authors": ["Maximilian Xiling Li", "Korbinian Rudolf", "Nils Blank", "Rudolf Lioutikov"], "abstract": "Robotic agents need to understand how to interact with objects in their environment, both autonomously and during human-robot interactions. Affordance detection on 3D point clouds, which identifies object regions that allow specific interactions, has traditionally relied on deep learning models like PointNet++, DGCNN, or PointTransformerV3. However, these models operate as black boxes, offering no insight into their decision-making processes. Prototypical Learning methods, such as ProtoPNet, provide an interpretable alternative to black-box models by employing a \"this looks like that\" case-based reasoning approach. However, they have been primarily applied to image-based tasks. In this work, we apply prototypical learning to models for affordance detection on 3D point clouds. Experiments on the 3D-AffordanceNet benchmark dataset show that prototypical models achieve competitive performance with state-of-the-art black-box models and offer inherent interpretability. This makes prototypical models a promising candidate for human-robot interaction scenarios that require increased trust and safety.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.18355.pdf", "abstract_url": "https://arxiv.org/abs/2504.18355", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于概率原型的可解释性3D点云功能检测方法，旨在通过原型学习方法提高模型的可解释性，同时在3D-AffordanceNet基准数据集上实现了与最先进黑盒模型相竞争的性能。", "motivation": "解决传统深度学习模型在3D点云功能检测中作为黑盒模型缺乏决策过程透明度的问题，特别是在需要增加信任和安全的人机交互场景中。", "method": "应用原型学习方法（如ProtoPNet）到3D点云功能检测模型中，采用“这看起来像那个”的基于案例的推理方法。", "result": "在3D-AffordanceNet基准数据集上的实验表明，原型模型不仅实现了与最先进黑盒模型相竞争的性能，而且提供了固有的可解释性。", "conclusion": "原型模型因其竞争性能和可解释性，成为需要增加信任和安全的人机交互场景的有力候选。"}}
{"id": "2504.18225", "title": "Even Small Reasoners Should Quote Their Sources: Introducing the Pleias-RAG Model Family", "authors": ["Pierre-Carl Langlais", "Pavel Chizhov", "Mattia Nee", "Carlos Rosas Hinostroza", "Matthieu Delsart", "Irène Girard", "Othman Hicheur", "Anastasia Stasenko", "Ivan P. Yamshchikov"], "abstract": "We introduce a new generation of small reasoning models for RAG, search, and source summarization. Pleias-RAG-350m and Pleias-RAG-1B are mid-trained on a large synthetic dataset emulating the retrieval of a wide variety of multilingual open sources from the Common Corpus. They provide native support for citation and grounding with literal quotes and reintegrate multiple features associated with RAG workflows, such as query routing, query reformulation, and source reranking. Pleias-RAG-350m and Pleias-RAG-1B outperform SLMs below 4 billion parameters on standardized RAG benchmarks (HotPotQA, 2wiki) and are competitive with popular larger models, including Qwen-2.5-7B, Llama-3.1-8B, and Gemma-3-4B. They are the only SLMs to date maintaining consistent RAG performance across leading European languages and ensuring systematic reference grounding for statements. Due to their size and ease of deployment on constrained infrastructure and higher factuality by design, the models unlock a range of new use cases for generative AI.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.18225.pdf", "abstract_url": "https://arxiv.org/abs/2504.18225", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "介绍了Pleias-RAG模型家族，包括Pleias-RAG-350m和Pleias-RAG-1B，这些小型推理模型在RAG、搜索和源摘要方面表现出色，支持引用和基础，并在多语言环境下保持一致的RAG性能。", "motivation": "解决小型推理模型在RAG（检索增强生成）任务中的性能问题，特别是在多语言环境和引用基础方面的不足。", "method": "通过在大型合成数据集上进行中期训练，模拟从Common Corpus检索多种多语言开放资源，集成RAG工作流程的多个功能。", "result": "Pleias-RAG-350m和Pleias-RAG-1B在标准RAG基准测试中优于参数低于40亿的SLMs，并与更大的模型竞争，同时在主要欧洲语言中保持一致的RAG性能。", "conclusion": "由于模型大小适中、易于部署和设计上的高事实性，Pleias-RAG模型为生成AI开辟了一系列新的用例。"}}
{"id": "2504.18260", "title": "MAGI: Multi-Agent Guided Interview for Psychiatric Assessment", "authors": ["Guanqun Bi", "Zhuang Chen", "Zhoufu Liu", "Hongkai Wang", "Xiyao Xiao", "Yuqiang Xie", "Wen Zhang", "Yongkang Huang", "Yuxuan Chen", "Libiao Peng", "Yi Feng", "Minlie Huang"], "abstract": "Automating structured clinical interviews could revolutionize mental healthcare accessibility, yet existing large language models (LLMs) approaches fail to align with psychiatric diagnostic protocols. We present MAGI, the first framework that transforms the gold-standard Mini International Neuropsychiatric Interview (MINI) into automatic computational workflows through coordinated multi-agent collaboration. MAGI dynamically navigates clinical logic via four specialized agents: 1) an interview tree guided navigation agent adhering to the MINI's branching structure, 2) an adaptive question agent blending diagnostic probing, explaining, and empathy, 3) a judgment agent validating whether the response from participants meet the node, and 4) a diagnosis Agent generating Psychometric Chain-of- Thought (PsyCoT) traces that explicitly map symptoms to clinical criteria. Experimental results on 1,002 real-world participants covering depression, generalized anxiety, social anxiety and suicide shows that MAGI advances LLM- assisted mental health assessment by combining clinical rigor, conversational adaptability, and explainable reasoning.", "subjects": "Computation and Language (cs.CL)", "comments": "In progress", "pdf_url": "https://arxiv.org/pdf/2504.18260.pdf", "abstract_url": "https://arxiv.org/abs/2504.18260", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "MAGI是一个通过多智能体协作将标准精神病学访谈自动化的框架，首次将MINI访谈转化为自动化计算流程，结合临床严谨性、对话适应性和可解释性推理。", "motivation": "解决现有大型语言模型在精神病学诊断协议对齐上的不足，提升心理健康评估的可及性和效率。", "method": "通过四个专门化的智能体动态导航临床逻辑：访谈树导航智能体、自适应问题智能体、判断智能体和诊断智能体，生成明确的症状到临床标准的映射。", "result": "在1002名覆盖抑郁、广泛性焦虑、社交焦虑和自杀倾向的真实世界参与者上的实验结果显示，MAGI在结合临床严谨性、对话适应性和可解释性推理方面取得了进展。", "conclusion": "MAGI框架为自动化精神病学评估提供了临床严谨、适应性强且解释性高的新方法，有望改善心理健康服务的可及性。"}}
{"id": "2504.18373", "title": "Auto-SLURP: A Benchmark Dataset for Evaluating Multi-Agent Frameworks in Smart Personal Assistant", "authors": ["Lei Shen", "Xiaoyu Shen"], "abstract": "In recent years, multi-agent frameworks powered by large language models (LLMs) have advanced rapidly. Despite this progress, there is still a notable absence of benchmark datasets specifically tailored to evaluate their performance. To bridge this gap, we introduce Auto-SLURP, a benchmark dataset aimed at evaluating LLM-based multi-agent frameworks in the context of intelligent personal assistants. Auto-SLURP extends the original SLURP dataset -- initially developed for natural language understanding tasks -- by relabeling the data and integrating simulated servers and external services. This enhancement enables a comprehensive end-to-end evaluation pipeline, covering language understanding, task execution, and response generation. Our experiments demonstrate that Auto-SLURP presents a significant challenge for current state-of-the-art frameworks, highlighting that truly reliable and intelligent multi-agent personal assistants remain a work in progress. The dataset and related code are available at", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.18373.pdf", "abstract_url": "https://arxiv.org/abs/2504.18373", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了Auto-SLURP，一个专门用于评估基于大型语言模型（LLM）的多智能体框架在智能个人助理中表现的基准数据集。", "motivation": "当前缺乏专门用于评估多智能体框架性能的基准数据集，尤其是在智能个人助理领域。", "method": "通过重新标记原始SLURP数据集并集成模拟服务器和外部服务，创建了Auto-SLURP数据集，以支持全面的端到端评估流程。", "result": "实验表明，Auto-SLURP对当前最先进的框架构成了显著挑战，表明真正可靠和智能的多智能体个人助理仍在开发中。", "conclusion": "Auto-SLURP为评估多智能体框架提供了一个重要的基准，突显了在智能个人助理领域进一步研究的必要性。"}}
{"id": "2504.17967", "title": "LLM Agent Swarm for Hypothesis-Driven Drug Discovery", "authors": ["Kevin Song", "Andrew Trotter", "Jake Y. Chen"], "abstract": "Drug discovery remains a formidable challenge: more than 90 percent of candidate molecules fail in clinical evaluation, and development costs often exceed one billion dollars per approved therapy. Disparate data streams, from genomics and transcriptomics to chemical libraries and clinical records, hinder coherent mechanistic insight and slow progress. Meanwhile, large language models excel at reasoning and tool integration but lack the modular specialization and iterative memory required for regulated, hypothesis-driven workflows. We introduce PharmaSwarm, a unified multi-agent framework that orchestrates specialized LLM \"agents\" to propose, validate, and refine hypotheses for novel drug targets and lead compounds. Each agent accesses dedicated functionality--automated genomic and expression analysis; a curated biomedical knowledge graph; pathway enrichment and network simulation; interpretable binding affinity prediction--while a central Evaluator LLM continuously ranks proposals by biological plausibility, novelty, in silico efficacy, and safety. A shared memory layer captures validated insights and fine-tunes underlying submodels over time, yielding a self-improving system. Deployable on low-code platforms or Kubernetes-based microservices, PharmaSwarm supports literature-driven discovery, omics-guided target identification, and market-informed repurposing. We also describe a rigorous four-tier validation pipeline spanning retrospective benchmarking, independent computational assays, experimental testing, and expert user studies to ensure transparency, reproducibility, and real-world impact. By acting as an AI copilot, PharmaSwarm can accelerate translational research and deliver high-confidence hypotheses more efficiently than traditional pipelines.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "15 pages, 3 figures", "pdf_url": "https://arxiv.org/pdf/2504.17967.pdf", "abstract_url": "https://arxiv.org/abs/2504.17967", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了PharmaSwarm，一个统一的多智能体框架，用于药物发现中的假设提出、验证和优化。", "motivation": "药物发现面临巨大挑战，90%以上的候选分子在临床评估中失败，开发成本高昂，且数据流分散阻碍了机制性洞察和进展。", "method": "引入PharmaSwarm框架，通过协调专门的LLM“智能体”来提出、验证和优化新药物靶点和先导化合物的假设，每个智能体访问特定功能，中央评估LLM持续排名提案。", "result": "PharmaSwarm支持文献驱动的发现、组学指导的靶点识别和市场知情的再利用，通过四层验证管道确保透明度、可重复性和实际影响。", "conclusion": "作为AI副驾驶，PharmaSwarm可以加速转化研究，比传统管道更高效地提供高置信度假设。"}}
{"id": "2504.18039", "title": "MultiMind: Enhancing Werewolf Agents with Multimodal Reasoning and Theory of Mind", "authors": ["Zheng Zhang", "Nuoqian Xiao", "Qi Chai", "Deheng Ye", "Hao Wang"], "abstract": "Large Language Model (LLM) agents have demonstrated impressive capabilities in social deduction games (SDGs) like Werewolf, where strategic reasoning and social deception are essential. However, current approaches remain limited to textual information, ignoring crucial multimodal cues such as facial expressions and tone of voice that humans naturally use to communicate. Moreover, existing SDG agents primarily focus on inferring other players' identities without modeling how others perceive themselves or fellow players. To address these limitations, we use One Night Ultimate Werewolf (ONUW) as a testbed and present MultiMind, the first framework integrating multimodal information into SDG agents. MultiMind processes facial expressions and vocal tones alongside verbal content, while employing a Theory of Mind (ToM) model to represent each player's suspicion levels toward others. By combining this ToM model with Monte Carlo Tree Search (MCTS), our agent identifies communication strategies that minimize suspicion directed at itself. Through comprehensive evaluation in both agent-versus-agent simulations and studies with human players, we demonstrate MultiMind's superior performance in gameplay. Our work presents a significant advancement toward LLM agents capable of human-like social reasoning across multimodal domains.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.18039.pdf", "abstract_url": "https://arxiv.org/abs/2504.18039", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "MultiMind是一个增强狼人杀代理的多模态推理和心理理论框架，通过整合面部表情、声调等非文本信息和心理理论模型，提升代理在社交推理游戏中的表现。", "motivation": "解决当前大型语言模型代理在社交推理游戏中仅依赖文本信息，忽视多模态沟通线索和他人自我感知建模的局限性。", "method": "使用One Night Ultimate Werewolf作为测试平台，整合多模态信息（面部表情、声调）和心理理论模型，结合蒙特卡洛树搜索优化沟通策略。", "result": "在代理对代理模拟和人类玩家研究中，MultiMind展现出卓越的游戏表现。", "conclusion": "MultiMind在实现跨多模态领域的人类类似社交推理能力方面迈出了重要一步。"}}
{"id": "2504.17934", "title": "Toward a Human-Centered Evaluation Framework for Trustworthy LLM-Powered GUI Agents", "authors": ["Chaoran Chen", "Zhiping Zhang", "Ibrahim Khalilov", "Bingcan Guo", "Simret A Gebreegziabher", "Yanfang Ye", "Ziang Xiao", "Yaxing Yao", "Tianshi Li", "Toby Jia-Jun Li"], "abstract": "The rise of Large Language Models (LLMs) has revolutionized Graphical User Interface (GUI) automation through LLM-powered GUI agents, yet their ability to process sensitive data with limited human oversight raises significant privacy and security risks. This position paper identifies three key risks of GUI agents and examines how they differ from traditional GUI automation and general autonomous agents. Despite these risks, existing evaluations focus primarily on performance, leaving privacy and security assessments largely unexplored. We review current evaluation metrics for both GUI and general LLM agents and outline five key challenges in integrating human evaluators for GUI agent assessments. To address these gaps, we advocate for a human-centered evaluation framework that incorporates risk assessments, enhances user awareness through in-context consent, and embeds privacy and security considerations into GUI agent design and evaluation.", "subjects": "Human-Computer Interaction (cs.HC); Computation and Language (cs.CL); Cryptography and Security (cs.CR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.17934.pdf", "abstract_url": "https://arxiv.org/abs/2504.17934", "categories": ["Human-Computer Interaction (cs.HC)", "Computation and Language (cs.CL)", "Cryptography and Security (cs.CR)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种以人为中心的评估框架，旨在解决由大型语言模型（LLM）驱动的图形用户界面（GUI）代理在隐私和安全方面的风险。", "motivation": "随着大型语言模型（LLMs）的兴起，LLM驱动的GUI代理在自动化处理敏感数据时，由于缺乏足够的人类监督，引发了重大的隐私和安全风险。", "method": "本文识别了GUI代理的三个关键风险，并探讨了它们与传统GUI自动化和一般自主代理的不同之处。同时，回顾了现有的评估指标，并提出了整合人类评估者的五个关键挑战。", "result": "提出了一种以人为中心的评估框架，该框架包括风险评估、通过上下文同意增强用户意识，以及将隐私和安全考虑嵌入GUI代理的设计和评估中。", "conclusion": "为了填补现有评估主要关注性能而忽视隐私和安全评估的空白，本文倡导采用一种更加全面和人性化的评估方法，以确保GUI代理的可靠性和安全性。"}}
{"id": "2504.17950", "title": "Collaborating Action by Action: A Multi-agent LLM Framework for Embodied Reasoning", "authors": ["Isadora White", "Kolby Nottingham", "Ayush Maniar", "Max Robinson", "Hansen Lillemark", "Mehul Maheshwari", "Lianhui Qin", "Prithviraj Ammanabrolu"], "abstract": "Collaboration is ubiquitous and essential in day-to-day life -- from exchanging ideas, to delegating tasks, to generating plans together. This work studies how LLMs can adaptively collaborate to perform complex embodied reasoning tasks. To this end we introduce MINDcraft, an easily extensible platform built to enable LLM agents to control characters in the open-world game of Minecraft; and MineCollab, a benchmark to test the different dimensions of embodied and collaborative reasoning. An experimental study finds that the primary bottleneck in collaborating effectively for current state-of-the-art agents is efficient natural language communication, with agent performance dropping as much as 15% when they are required to communicate detailed task completion plans. We conclude that existing LLM agents are ill-optimized for multi-agent collaboration, especially in embodied scenarios, and highlight the need to employ methods beyond in-context and imitation learning. Our website can be found here:", "subjects": "Multiagent Systems (cs.MA); Computation and Language (cs.CL)", "comments": "9 pages of main paper with 6 main figures, overall 28 pages", "pdf_url": "https://arxiv.org/pdf/2504.17950.pdf", "abstract_url": "https://arxiv.org/abs/2504.17950", "categories": ["Multiagent Systems (cs.MA)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了MINDcraft平台和MineCollab基准测试，旨在研究LLM代理如何在开放式游戏Minecraft中协作完成复杂的具身推理任务。研究发现，当前最先进的代理在有效协作方面的主要瓶颈是自然语言沟通效率，代理性能在需要详细任务完成计划沟通时下降多达15%。", "motivation": "研究LLM代理如何适应性地协作以执行复杂的具身推理任务，解决现有LLM代理在多代理协作，尤其是在具身场景中的不足。", "method": "引入MINDcraft平台和MineCollab基准测试，通过实验研究LLM代理在Minecraft游戏中的协作表现。", "result": "研究发现，自然语言沟通效率是当前最先进代理协作的主要瓶颈，代理性能在需要详细任务完成计划沟通时显著下降。", "conclusion": "现有LLM代理在多代理协作，尤其是具身场景中表现不佳，需要采用超越上下文和模仿学习的方法来优化。"}}
{"id": "2504.18024", "title": "SMARTFinRAG: Interactive Modularized Financial RAG Benchmark", "authors": ["Yiwei Zha"], "abstract": "Financial sectors are rapidly adopting language model technologies, yet evaluating specialized RAG systems in this domain remains challenging. This paper introduces SMARTFinRAG, addressing three critical gaps in financial RAG assessment: (1) a fully modular architecture where components can be dynamically interchanged during runtime; (2) a document-centric evaluation paradigm generating domain-specific QA pairs from newly ingested financial documents; and (3) an intuitive interface bridging research-implementation divides. Our evaluation quantifies both retrieval efficacy and response quality, revealing significant performance variations across configurations. The platform's open-source architecture supports transparent, reproducible research while addressing practical deployment challenges faced by financial institutions implementing RAG systems.", "subjects": "Computational Engineering, Finance, and Science (cs.CE); Computation and Language (cs.CL); Information Retrieval (cs.IR)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2504.18024.pdf", "abstract_url": "https://arxiv.org/abs/2504.18024", "categories": ["Computational Engineering, Finance, and Science (cs.CE)", "Computation and Language (cs.CL)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了SMARTFinRAG，一个针对金融领域RAG系统评估的平台，解决了模块化架构、领域特定QA对生成和研究与实施之间的桥梁三个关键问题。", "motivation": "金融领域迅速采用语言模型技术，但评估该领域的专业RAG系统仍具挑战性。", "method": "SMARTFinRAG提供了一个完全模块化的架构，组件可以在运行时动态交换；采用文档中心的评估范式，从新摄入的金融文档生成领域特定的QA对；并提供了一个直观的界面，弥合研究与实施之间的鸿沟。", "result": "评估量化了检索效果和响应质量，揭示了不同配置间的显著性能差异。", "conclusion": "SMARTFinRAG的开源架构支持透明、可重复的研究，同时解决了金融机构实施RAG系统时面临的实际部署挑战。"}}
{"id": "2504.17872", "title": "Flow Matching Ergodic Coverage", "authors": ["Max Muchen Sun", "Allison Pinosky", "Todd Murphey"], "abstract": "Ergodic coverage effectively generates exploratory behaviors for embodied agents by aligning the spatial distribution of the agent's trajectory with a target distribution, where the difference between these two distributions is measured by the ergodic metric. However, existing ergodic coverage methods are constrained by the limited set of ergodic metrics available for control synthesis, fundamentally limiting their performance. In this work, we propose an alternative approach to ergodic coverage based on flow matching, a technique widely used in generative inference for efficient and scalable sampling. We formally derive the flow matching problem for ergodic coverage and show that it is equivalent to a linear quadratic regulator problem with a closed-form solution. Our formulation enables alternative ergodic metrics from generative inference that overcome the limitations of existing ones. These metrics were previously infeasible for control synthesis but can now be supported with no computational overhead. Specifically, flow matching with the Stein variational gradient flow enables control synthesis directly over the score function of the target distribution, improving robustness to the unnormalized distributions; on the other hand, flow matching with the Sinkhorn divergence flow enables an optimal transport-based ergodic metric, improving coverage performance on non-smooth distributions with irregular supports. We validate the improved performance and competitive computational efficiency of our method through comprehensive numerical benchmarks and across different nonlinear dynamics. We further demonstrate the practicality of our method through a series of drawing and erasing tasks on a Franka robot.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2504.17872.pdf", "abstract_url": "https://arxiv.org/abs/2504.17872", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于流匹配的遍历覆盖新方法，通过将智能体的轨迹空间分布与目标分布对齐来生成探索行为，克服了现有遍历覆盖方法在控制合成中度量有限的限制。", "motivation": "现有遍历覆盖方法因控制合成中可用的遍历度量有限而性能受限，本文旨在解决这一问题。", "method": "采用流匹配技术，正式推导出遍历覆盖的流匹配问题，并证明其等同于具有闭式解的线性二次调节器问题。", "result": "新方法支持从生成推理中获取替代遍历度量，提高了对未归一化分布的鲁棒性，并在非平滑分布上表现出更好的覆盖性能。", "conclusion": "通过综合数值基准测试和在不同非线性动力学上的应用，验证了新方法的性能提升和计算效率，展示了其在Franka机器人上的实际应用潜力。"}}
{"id": "2504.18010", "title": "Sky-Drive: A Distributed Multi-Agent Simulation Platform for Socially-Aware and Human-AI Collaborative Future Transportation", "authors": ["Zilin Huang", "Zihao Sheng", "Zhengyang Wan", "Yansong Qu", "Yuhao Luo", "Boyue Wang", "Pei Li", "Yen-Jung Chen", "Jiancong Chen", "Keke Long", "Jiayi Meng", "Yue Leng", "Sikai Chen"], "abstract": "Recent advances in autonomous system simulation platforms have significantly enhanced the safe and scalable testing of driving policies. However, existing simulators do not yet fully meet the needs of future transportation research, particularly in modeling socially-aware driving agents and enabling effective human-AI collaboration. This paper introduces Sky-Drive, a novel distributed multi-agent simulation platform that addresses these limitations through four key innovations: (a) a distributed architecture for synchronized simulation across multiple terminals; (b) a multi-modal human-in-the-loop framework integrating diverse sensors to collect rich behavioral data; (c) a human-AI collaboration mechanism supporting continuous and adaptive knowledge exchange; and (d) a digital twin (DT) framework for constructing high-fidelity virtual replicas of real-world transportation environments. Sky-Drive supports diverse applications such as autonomous vehicle (AV)-vulnerable road user (VRU) interaction modeling, human-in-the-loop training, socially-aware reinforcement learning, personalized driving policy, and customized scenario generation. Future extensions will incorporate foundation models for context-aware decision support and hardware-in-the-loop (HIL) testing for real-world validation. By bridging scenario generation, data collection, algorithm training, and hardware integration, Sky-Drive has the potential to become a foundational platform for the next generation of socially-aware and human-centered autonomous transportation research. The demo video and code are available at:", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)", "comments": "15 pages, 7 figures", "pdf_url": "https://arxiv.org/pdf/2504.18010.pdf", "abstract_url": "https://arxiv.org/abs/2504.18010", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "Sky-Drive是一个创新的分布式多代理模拟平台，专为未来交通研究设计，专注于社会意识驾驶代理和人类-AI协作。", "motivation": "现有的自动驾驶系统模拟平台未能完全满足未来交通研究的需求，特别是在模拟社会意识驾驶代理和实现有效的人类-AI协作方面。", "method": "Sky-Drive通过四个关键创新解决这些限制：分布式架构、多模态人类在环框架、人类-AI协作机制和数字孪生框架。", "result": "Sky-Drive支持多种应用，如自动驾驶车辆与弱势道路使用者的互动建模、人类在环训练、社会意识强化学习等，并计划未来扩展以包括基础模型和硬件在环测试。", "conclusion": "Sky-Drive通过桥接场景生成、数据收集、算法训练和硬件集成，有潜力成为下一代社会意识和以人为中心的自动驾驶研究的基础平台。"}}
{"id": "2504.18113", "title": "Learning from Less: SINDy Surrogates in RL", "authors": ["Aniket Dixit", "Muhammad Ibrahim Khan", "Faizan Ahmed", "James Brusey"], "abstract": "This paper introduces an approach for developing surrogate environments in reinforcement learning (RL) using the Sparse Identification of Nonlinear Dynamics (SINDy) algorithm. We demonstrate the effectiveness of our approach through extensive experiments in OpenAI Gym environments, particularly Mountain Car and Lunar Lander. Our results show that SINDy-based surrogate models can accurately capture the underlying dynamics of these environments while reducing computational costs by 20-35%. With only 75 interactions for Mountain Car and 1000 for Lunar Lander, we achieve state-wise correlations exceeding 0.997, with mean squared errors as low as 3.11e-06 for Mountain Car velocity and 1.42e-06 for LunarLander position. RL agents trained in these surrogate environments require fewer total steps (65,075 vs. 100,000 for Mountain Car and 801,000 vs. 1,000,000 for Lunar Lander) while achieving comparable performance to those trained in the original environments, exhibiting similar convergence patterns and final performance metrics. This work contributes to the field of model-based RL by providing an efficient method for generating accurate, interpretable surrogate environments.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "World Models @ ICLR 2025", "pdf_url": "https://arxiv.org/pdf/2504.18113.pdf", "abstract_url": "https://arxiv.org/abs/2504.18113", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一种在强化学习中使用SINDy算法开发替代环境的方法，通过在OpenAI Gym环境中的实验证明了其有效性。", "motivation": "解决强化学习中计算成本高的问题，通过开发准确的替代环境来减少训练所需的交互次数。", "method": "使用Sparse Identification of Nonlinear Dynamics (SINDy)算法开发替代环境。", "result": "SINDy-based替代模型能准确捕捉环境动态，减少20-35%的计算成本，且在较少的交互次数下达到高准确度。", "conclusion": "为基于模型的强化学习领域提供了一种高效生成准确、可解释替代环境的方法。"}}
{"id": "2504.18253", "title": "Depth-Constrained ASV Navigation with Deep RL and Limited Sensing", "authors": ["Amirhossein Zhalehmehrabi", "Daniele Meli", "Francesco Dal Santo", "Francesco Trotti", "Alessandro Farinelli"], "abstract": "Autonomous Surface Vehicles (ASVs) play a crucial role in maritime operations, yet their navigation in shallow-water environments remains challenging due to dynamic disturbances and depth constraints. Traditional navigation strategies struggle with limited sensor information, making safe and efficient operation difficult. In this paper, we propose a reinforcement learning (RL) framework for ASV navigation under depth constraints, where the vehicle must reach a target while avoiding unsafe areas with only a single depth measurement per timestep from a downward-facing Single Beam Echosounder (SBES). To enhance environmental awareness, we integrate Gaussian Process (GP) regression into the RL framework, enabling the agent to progressively estimate a bathymetric depth map from sparse sonar readings. This approach improves decision-making by providing a richer representation of the environment. Furthermore, we demonstrate effective sim-to-real transfer, ensuring that trained policies generalize well to real-world aquatic conditions. Experimental results validate our method's capability to improve ASV navigation performance while maintaining safety in challenging shallow-water environments.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": "9 pages, 8 figures", "pdf_url": "https://arxiv.org/pdf/2504.18253.pdf", "abstract_url": "https://arxiv.org/abs/2504.18253", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种结合深度强化学习和高斯过程回归的自主水面车辆（ASV）导航框架，旨在解决浅水环境中动态干扰和深度限制下的导航挑战。该方法通过稀疏声纳读数逐步估计水深图，提高了环境感知能力，并展示了有效的模拟到现实的迁移能力。", "motivation": "自主水面车辆（ASV）在浅水环境中的导航面临动态干扰和深度限制的挑战，传统导航策略在传感器信息有限的情况下难以实现安全高效的操作。", "method": "本文提出了一种强化学习（RL）框架，结合高斯过程（GP）回归，利用单次向下单波束回声测深仪（SBES）的深度测量，逐步估计水深图，以增强环境感知。", "result": "实验结果表明，该方法能够提高ASV在挑战性浅水环境中的导航性能，同时保持安全性，并实现了有效的模拟到现实的迁移。", "conclusion": "本文的方法通过结合深度强化学习和高斯过程回归，不仅提高了ASV在浅水环境中的导航能力，还确保了训练策略在现实水生条件下的良好泛化能力。"}}
{"id": "2504.18316", "title": "Towards Adaptive Software Agents for Debugging", "authors": ["Yacine Majdoub", "Eya Ben Charrada", "Haifa Touati"], "abstract": "Using multiple agents was found to improve the debugging capabilities of Large Language Models. However, increasing the number of LLM-agents has several drawbacks such as increasing the running costs and rising the risk for the agents to lose focus. In this work, we propose an adaptive agentic design, where the number of agents and their roles are determined dynamically based on the characteristics of the task to be achieved. In this design, the agents roles are not predefined, but are generated after analyzing the problem to be solved. Our initial evaluation shows that, with the adaptive design, the number of agents that are generated depends on the complexity of the buggy code. In fact, for simple code with mere syntax issues, the problem was usually fixed using one agent only. However, for more complex problems, we noticed the creation of a higher number of agents. Regarding the effectiveness of the fix, we noticed an average improvement of 11% compared to the one-shot prompting. Given these promising results, we outline future research directions to improve our design for adaptive software agents that can autonomously plan and conduct their software goals.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": "5 pages, 3 figures, FSE2025", "pdf_url": "https://arxiv.org/pdf/2504.18316.pdf", "abstract_url": "https://arxiv.org/abs/2504.18316", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种自适应代理设计，用于提高大型语言模型（LLM）的调试能力。通过动态确定代理数量和角色，根据任务特性来优化调试过程，初步评估显示，此方法能根据代码复杂性调整代理数量，并在修复效果上比单次提示平均提高11%。", "motivation": "解决使用多个LLM代理进行调试时增加运行成本和代理可能失去焦点的问题。", "method": "提出一种自适应代理设计，动态确定代理数量和角色，基于待解决问题的特性。", "result": "初步评估表明，自适应设计能根据代码复杂性调整代理数量，简单问题通常只需一个代理，复杂问题则需要更多代理，修复效果比单次提示平均提高11%。", "conclusion": "自适应软件代理设计在调试方面显示出潜力，未来研究方向包括改进设计以实现代理自主规划和执行软件目标。"}}
{"id": "2504.18423", "title": "LLMpatronous: Harnessing the Power of LLMs For Vulnerability Detection", "authors": ["Rajesh Yarra"], "abstract": "Despite the transformative impact of Artificial Intelligence (AI) across various sectors, cyber security continues to rely on traditional static and dynamic analysis tools, hampered by high false positive rates and superficial code comprehension. While generative AI offers promising automation capabilities for software development, leveraging Large Language Models (LLMs) for vulnerability detection presents unique challenges. This paper explores the potential and limitations of LLMs in identifying vulnerabilities, acknowledging inherent weaknesses such as hallucinations, limited context length, and knowledge cut-offs. Previous attempts employing machine learning models for vulnerability detection have proven ineffective due to limited real-world applicability, feature engineering challenges, lack of contextual understanding, and the complexities of training models to keep pace with the evolving threat landscape. Therefore, we propose a robust AI-driven approach focused on mitigating these limitations and ensuring the quality and reliability of LLM based vulnerability detection. Through innovative methodologies combining Retrieval-Augmented Generation (RAG) and Mixtureof-Agents (MoA), this research seeks to leverage the strengths of LLMs while addressing their weaknesses, ultimately paving the way for dependable and efficient AI-powered solutions in securing the ever-evolving software landscape.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.18423.pdf", "abstract_url": "https://arxiv.org/abs/2504.18423", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文探讨了利用大型语言模型（LLMs）进行漏洞检测的潜力与限制，提出了一种结合检索增强生成（RAG）和混合代理（MoA）的创新方法，旨在克服LLMs的固有弱点，为软件安全提供可靠高效的AI驱动解决方案。", "motivation": "尽管人工智能（AI）在各领域产生了变革性影响，网络安全仍依赖传统的静态和动态分析工具，这些工具存在高误报率和浅层代码理解的局限性。生成式AI为软件开发提供了有前景的自动化能力，但利用LLMs进行漏洞检测面临独特挑战。", "method": "本研究提出了一种结合检索增强生成（RAG）和混合代理（MoA）的创新方法，旨在利用LLMs的优势同时解决其弱点。", "result": "通过这种方法，研究旨在克服LLMs在漏洞检测中的固有弱点，如幻觉、有限的上下文长度和知识截止，为软件安全提供更可靠和高效的AI驱动解决方案。", "conclusion": "本研究为依赖AI的漏洞检测提供了新的方向，通过创新的方法结合RAG和MoA，不仅解决了LLMs的局限性，还为不断演变的软件安全威胁提供了可持续的解决方案。"}}
