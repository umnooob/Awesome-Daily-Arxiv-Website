{"id": "2508.05852", "title": "VISTA: Vision-Language Imitation of Situational Thinking and Attention for Human-Like Driver Focus in Dynamic Environments", "authors": ["Kaiser Hamid", "Khandakar Ashrafi Akbar", "Nade Liang"], "abstract": "Driver visual attention prediction is a critical task in autonomous driving and human-computer interaction (HCI) research. Most prior studies focus on estimating attention allocation at a single moment in time, typically using static RGB images such as driving scene pictures. In this work, we propose a vision-language framework that models the changing landscape of drivers' gaze through natural language, using few-shot and zero-shot learning on single RGB images. We curate and refine high-quality captions from the BDD-A dataset using human-in-the-loop feedback, then fine-tune LLaVA to align visual perception with attention-centric scene understanding. Our approach integrates both low-level cues and top-down context (e.g., route semantics, risk anticipation), enabling language-based descriptions of gaze behavior. We evaluate performance across training regimes (few shot, and one-shot) and introduce domain-specific metrics for semantic alignment and response diversity. Results show that our fine-tuned model outperforms general-purpose VLMs in attention shift detection and interpretability. To our knowledge, this is among the first attempts to generate driver visual attention allocation and shifting predictions in natural language, offering a new direction for explainable AI in autonomous driving. Our approach provides a foundation for downstream tasks such as behavior forecasting, human-AI teaming, and multi-agent coordination.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.05852.pdf", "abstract_url": "https://arxiv.org/abs/2508.05852", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"]}
{"id": "2508.05731", "title": "InfiGUI-G1: Advancing GUI Grounding with Adaptive Exploration Policy Optimization", "authors": ["Yuhang Liu", "Zeyu Liu", "Shuanghe Zhu", "Pengxiang Li", "Congkai Xie", "Jiasheng Wang", "Xueyu Hu", "Xiaotian Han", "Jianbo Yuan", "Xinyao Wang", "Shengyu Zhang", "Hongxia Yang", "Fei Wu"], "abstract": "The emergence of Multimodal Large Language Models (MLLMs) has propelled the development of autonomous agents that operate on Graphical User Interfaces (GUIs) using pure visual input. A fundamental challenge is robustly grounding natural language instructions. This requires a precise spatial alignment, which accurately locates the coordinates of each element, and, more critically, a correct semantic alignment, which matches the instructions to the functionally appropriate UI element. Although Reinforcement Learning with Verifiable Rewards (RLVR) has proven to be effective at improving spatial alignment for these MLLMs, we find that inefficient exploration bottlenecks semantic alignment, which prevent models from learning difficult semantic associations. To address this exploration problem, we present Adaptive Exploration Policy Optimization (AEPO), a new policy optimization framework. AEPO employs a multi-answer generation strategy to enforce broader exploration, which is then guided by a theoretically grounded Adaptive Exploration Reward (AER) function derived from first principles of efficiency eta=U/C. Our AEPO-trained models, InfiGUI-G1-3B and InfiGUI-G1-7B, establish new state-of-the-art results across multiple challenging GUI grounding benchmarks, achieving significant relative improvements of up to 9.0% against the naive RLVR baseline on benchmarks designed to test generalization and semantic understanding. Resources are available at", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "11 pages, 3 figures", "pdf_url": "https://arxiv.org/pdf/2508.05731.pdf", "abstract_url": "https://arxiv.org/abs/2508.05731", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2508.05843", "title": "Discovering Properties of Inflectional Morphology in Neural Emergent Communication", "authors": ["Miles Gilberti", "Shane Storks", "Huteng Dai"], "abstract": "Emergent communication (EmCom) with deep neural network-based agents promises to yield insights into the nature of human language, but remains focused primarily on a few subfield-specific goals and metrics that prioritize communication schemes which represent attributes with unique characters one-to-one and compose them syntactically. We thus reinterpret a common EmCom setting, the attribute-value reconstruction game, by imposing a small-vocabulary constraint to simulate double articulation, and formulating a novel setting analogous to naturalistic inflectional morphology (enabling meaningful comparison to natural language communication schemes). We develop new metrics and explore variations of this game motivated by real properties of inflectional morphology: concatenativity and fusionality. Through our experiments, we discover that simulated phonological constraints encourage concatenative morphology, and emergent languages replicate the tendency of natural languages to fuse grammatical attributes.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.05843.pdf", "abstract_url": "https://arxiv.org/abs/2508.05843", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2508.05909", "title": "Spectrum Projection Score: Aligning Retrieved Summaries with Reader Models in Retrieval-Augmented Generation", "authors": ["Zhanghao Hu", "Qinglin Zhu", "Siya Qi", "Yulan He", "Hanqi Yan", "Lin Gui"], "abstract": "Large Language Models (LLMs) have shown improved generation performance through retrieval-augmented generation (RAG) following the retriever-reader paradigm, which supplements model inputs with externally retrieved knowledge. However, prior work often evaluates RAG holistically, assessing the retriever and reader jointly, making it difficult to isolate the true contribution of retrieval, particularly given the prompt sensitivity of LLMs used as readers. We introduce Spectrum Projection Score (SPS), a lightweight, supervision-free metric that allows the reader to gauge the semantic alignment of a retrieved summary with its hidden representation by comparing the area formed by generated tokens from the summary, and the principal directions of subspace in the reader and to measure the relevance. Building on SPS we present xCompress, an inference time controller framework that dynamically samples, ranks, and compresses retrieval summary candidates. Extensive experiments on five QA benchmarks with four open source LLMs show that SPS not only enhances performance across a range of tasks but also provides a principled perspective on the interaction between retrieval and generation.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.05909.pdf", "abstract_url": "https://arxiv.org/abs/2508.05909", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"]}
{"id": "2508.06046", "title": "EvolvR: Self-Evolving Pairwise Reasoning for Story Evaluation to Enhance Generation", "authors": ["Xinda Wang", "Zhengxu Hou", "Yangshijie Zhang", "Bingren Yan", "Zhibo Yang", "Xingsheng Zhang", "Luxi Xing", "Qiang Zhou", "Chen Zhang"], "abstract": "Although the effectiveness of Large Language Models (LLMs) as judges (LLM-as-a-judge) has been validated, their performance remains limited in open-ended tasks, particularly in story evaluation. Accurate story evaluation is crucial not only for assisting human quality judgment but also for providing key signals to guide story generation. However, existing methods face a dilemma: prompt engineering for closed-source models suffers from poor adaptability, while fine-tuning approaches for open-source models lack the rigorous reasoning capabilities essential for story evaluation. To address this, we propose the Self-Evolving Pairwise Reasoning (EvolvR) framework. Grounded in pairwise comparison, the framework first self-synthesizes score-aligned Chain-of-Thought (CoT) data via a multi-persona strategy. To ensure data quality, these raw CoTs undergo a self-filtering process, utilizing multi-agents to guarantee their logical rigor and robustness. Finally, the evaluator trained on the refined data is deployed as a reward model to guide the story generation task. Experimental results demonstrate that our framework achieves state-of-the-art (SOTA) performance on three evaluation benchmarks including StoryER, HANNA and OpenMEVA. Furthermore, when served as a reward model, it significantly enhances the quality of generated stories, thereby fully validating the superiority of our self-evolving approach.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.06046.pdf", "abstract_url": "https://arxiv.org/abs/2508.06046", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2508.05766", "title": "A Framework for Inherently Safer AGI through Language-Mediated Active Inference", "authors": ["Bo Wen"], "abstract": "This paper proposes a novel framework for developing safe Artificial General Intelligence (AGI) by combining Active Inference principles with Large Language Models (LLMs). We argue that traditional approaches to AI safety, focused on post-hoc interpretability and reward engineering, have fundamental limitations. We present an architecture where safety guarantees are integrated into the system's core design through transparent belief representations and hierarchical value alignment. Our framework leverages natural language as a medium for representing and manipulating beliefs, enabling direct human oversight while maintaining computational tractability. The architecture implements a multi-agent system where agents self-organize according to Active Inference principles, with preferences and safety constraints flowing through hierarchical Markov blankets. We outline specific mechanisms for ensuring safety, including: (1) explicit separation of beliefs and preferences in natural language, (2) bounded rationality through resource-aware free energy minimization, and (3) compositional safety through modular agent structures. The paper concludes with a research agenda centered on the Abstraction and Reasoning Corpus (ARC) benchmark, proposing experiments to validate our framework's safety properties. Our approach offers a path toward AGI development that is inherently safer, rather than retrofitted with safety measures.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Systems and Control (eess.SY); Adaptation and Self-Organizing Systems (nlin.AO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.05766.pdf", "abstract_url": "https://arxiv.org/abs/2508.05766", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Systems and Control (eess.SY)", "Adaptation and Self-Organizing Systems (nlin.AO)"], "matching_keywords": ["agent"]}
{"id": "2508.05855", "title": "Safety of Embodied Navigation: A Survey", "authors": ["Zixia Wang", "Jia Hu", "Ronghui Mu"], "abstract": "As large language models (LLMs) continue to advance and gain influence, the development of embodied AI has accelerated, drawing significant attention, particularly in navigation scenarios. Embodied navigation requires an agent to perceive, interact with, and adapt to its environment while moving toward a specified target in unfamiliar settings. However, the integration of embodied navigation into critical applications raises substantial safety concerns. Given their deployment in dynamic, real-world environments, ensuring the safety of such systems is critical. This survey provides a comprehensive analysis of safety in embodied navigation from multiple perspectives, encompassing attack strategies, defense mechanisms, and evaluation methodologies. Beyond conducting a comprehensive examination of existing safety challenges, mitigation technologies, and various datasets and metrics that assess effectiveness and robustness, we explore unresolved issues and future research directions in embodied navigation safety. These include potential attack methods, mitigation strategies, more reliable evaluation techniques, and the implementation of verification frameworks. By addressing these critical gaps, this survey aims to provide valuable insights that can guide future research toward the development of safer and more reliable embodied navigation systems. Furthermore, the findings of this study have broader implications for enhancing societal safety and increasing industrial efficiency.", "subjects": "Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.05855.pdf", "abstract_url": "https://arxiv.org/abs/2508.05855", "categories": ["Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"]}
{"id": "2508.05888", "title": "Planning Agents on an Ego-Trip: Leveraging Hybrid Ego-Graph Ensembles for Improved Tool Retrieval in Enterprise Task Planning", "authors": ["Sahil Bansal", "Sai Shruthi Sistla", "Aarti Arikatala", "Sebastian Schreiber"], "abstract": "Effective tool retrieval is essential for AI agents to select from a vast array of tools when identifying and planning actions in the context of complex user queries. Despite its central role in planning, this aspect remains underexplored in the literature. Traditional approaches rely primarily on similarities between user queries and tool descriptions, which significantly limits retrieval accuracy, specifically when handling multi-step user requests. To address these limitations, we propose a Knowledge Graph (KG)-based tool retrieval framework that captures the semantic relationships between tools and their functional dependencies. Our retrieval algorithm leverages ensembles of 1-hop ego tool graphs to model direct and indirect connections between tools, enabling more comprehensive and contextual tool selection for multi-step tasks. We evaluate our approach on a synthetically generated internal dataset across six defined user classes, extending previous work on coherent dialogue synthesis and too retrieval benchmarks. Results demonstrate that our tool graph-based method achieves 91.85% tool coverage on the micro-average Complete Recall metric, compared to 89.26% for re-ranked semantic-lexical hybrid retrieval, the strongest non-KG baseline in our experiments. These findings support our hypothesis that the structural information in the KG provides complementary signals to pure similarity matching, particularly for queries requiring sequential tool composition.", "subjects": "Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.05888.pdf", "abstract_url": "https://arxiv.org/abs/2508.05888", "categories": ["Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["agent"]}
{"id": "2508.05996", "title": "Mediator-Guided Multi-Agent Collaboration among Open-Source Models for Medical Decision-Making", "authors": ["Kaitao Chen", "Mianxin Liu", "Daoming Zong", "Chaoyue Ding", "Shaohao Rui", "Yankai Jiang", "Mu Zhou", "Xiaosong Wang"], "abstract": "Complex medical decision-making involves cooperative workflows operated by different clinicians. Designing AI multi-agent systems can expedite and augment human-level clinical decision-making. Existing multi-agent researches primarily focus on language-only tasks, yet their extension to multimodal scenarios remains challenging. A blind combination of diverse vision-language models (VLMs) can amplify an erroneous outcome interpretation. VLMs in general are less capable in instruction following and importantly self-reflection, compared to large language models (LLMs) of comparable sizes. This disparity largely constrains VLMs' ability in cooperative workflows. In this study, we propose MedOrch, a mediator-guided multi-agent collaboration framework for medical multimodal decision-making. MedOrch employs an LLM-based mediator agent that enables multiple VLM-based expert agents to exchange and reflect on their outputs towards collaboration. We utilize multiple open-source general-purpose and domain-specific VLMs instead of costly GPT-series models, revealing the strength of heterogeneous models. We show that the collaboration within distinct VLM-based agents can surpass the capabilities of any individual agent. We validate our approach on five medical vision question answering benchmarks, demonstrating superior collaboration performance without model training. Our findings underscore the value of mediator-guided multi-agent collaboration in advancing medical multimodal intelligence. Our code will be made publicly available.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "14 pages, 4 figures", "pdf_url": "https://arxiv.org/pdf/2508.05996.pdf", "abstract_url": "https://arxiv.org/abs/2508.05996", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2508.06042", "title": "Society of Mind Meets Real-Time Strategy: A Hierarchical Multi-Agent Framework for Strategic Reasoning", "authors": ["Daechul Ahn", "San Kim", "Jonghyun Choi"], "abstract": "Large Language Models (LLMs) have recently demonstrated impressive action sequence prediction capabilities but often struggle with dynamic, long-horizon tasks such as real-time strategic games. In a game such as StarCraftII (SC2), agents need to manage resource constraints and adapt to evolving battlefield situations in a partially observable environment. This often overwhelms exisiting LLM-based approaches. To address these challenges, we propose a hierarchical multi-agent framework that employs specialized imitation learning agents under a meta-controller called Strategic Planner (SP). By expert demonstrations, each specialized agent learns a distinctive strategy, such as aerial support or defensive maneuvers, and produces coherent, structured multistep action sequences. The SP then orchestrates these proposals into a single, environmentally adaptive plan that ensures local decisions aligning with long-term strategies. We call this HIMA (Hierarchical Imitation Multi-Agent). We also present TEXTSCII-ALL, a comprehensive SC2 testbed that encompasses all race match combinations in SC2. Our empirical results show that HIMA outperforms state of the arts in strategic clarity, adaptability, and computational efficiency, underscoring the potential of combining specialized imitation modules with meta-level orchestration to develop more robust, general-purpose AI agents.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "COLM 2025", "pdf_url": "https://arxiv.org/pdf/2508.06042.pdf", "abstract_url": "https://arxiv.org/abs/2508.06042", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2508.06110", "title": "PanelTR: Zero-Shot Table Reasoning Framework Through Multi-Agent Scientific Discussion", "authors": ["Yiran Rex Ma"], "abstract": "Table reasoning, including tabular QA and fact verification, often depends on annotated data or complex data augmentation, limiting flexibility and generalization. LLMs, despite their versatility, often underperform compared to simple supervised models. To approach these issues, we introduce PanelTR, a framework utilizing LLM agent scientists for robust table reasoning through a structured scientific approach. PanelTR's workflow involves agent scientists conducting individual investigations, engaging in self-review, and participating in collaborative peer-review discussions. This process, driven by five scientist personas, enables semantic-level transfer without relying on data augmentation or parametric optimization. Experiments across four benchmarks show that PanelTR outperforms vanilla LLMs and rivals fully supervised models, all while remaining independent of training data. Our findings indicate that structured scientific methodology can effectively handle complex tasks beyond table reasoning with flexible semantic understanding in a zero-shot context.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "Accepted at IJCNN 2025", "pdf_url": "https://arxiv.org/pdf/2508.06110.pdf", "abstract_url": "https://arxiv.org/abs/2508.06110", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"]}
{"id": "2508.06189", "title": "MA-CBP: A Criminal Behavior Prediction Framework Based on Multi-Agent Asynchronous Collaboration", "authors": ["Cheng Liu", "Daou Zhang", "Tingxu Liu", "Yuhan Wang", "Jinyang Chen", "Yuexuan Li", "Xinying Xiao", "Chenbo Xin", "Ziru Wang", "Weichao Wu"], "abstract": "With the acceleration of urbanization, criminal behavior in public scenes poses an increasingly serious threat to social security. Traditional anomaly detection methods based on feature recognition struggle to capture high-level behavioral semantics from historical information, while generative approaches based on Large Language Models (LLMs) often fail to meet real-time requirements. To address these challenges, we propose MA-CBP, a criminal behavior prediction framework based on multi-agent asynchronous collaboration. This framework transforms real-time video streams into frame-level semantic descriptions, constructs causally consistent historical summaries, and fuses adjacent image frames to perform joint reasoning over long- and short-term contexts. The resulting behavioral decisions include key elements such as event subjects, locations, and causes, enabling early warning of potential criminal activity. In addition, we construct a high-quality criminal behavior dataset that provides multi-scale language supervision, including frame-level, summary-level, and event-level semantic annotations. Experimental results demonstrate that our method achieves superior performance on multiple datasets and offers a promising solution for risk warning in urban public safety scenarios.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.06189.pdf", "abstract_url": "https://arxiv.org/abs/2508.06189", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"]}
{"id": "2508.06105", "title": "You Don't Need Pre-built Graphs for RAG: Retrieval Augmented Generation with Adaptive Reasoning Structures", "authors": ["Shengyuan Chen", "Chuang Zhou", "Zheng Yuan", "Qinggang Zhang", "Zeyang Cui", "Hao Chen", "Yilin Xiao", "Jiannong Cao", "Xiao Huang"], "abstract": "Large language models (LLMs) often suffer from hallucination, generating factually incorrect statements when handling questions beyond their knowledge and perception. Retrieval-augmented generation (RAG) addresses this by retrieving query-relevant contexts from knowledge bases to support LLM reasoning. Recent advances leverage pre-constructed graphs to capture the relational connections among distributed documents, showing remarkable performance in complex tasks. However, existing Graph-based RAG (GraphRAG) methods rely on a costly process to transform the corpus into a graph, introducing overwhelming token cost and update latency. Moreover, real-world queries vary in type and complexity, requiring different logic structures for accurate reasoning. The pre-built graph may not align with these required structures, resulting in ineffective knowledge retrieval. To this end, we propose a \\textbf{\\underline{Logic}}-aware \\textbf{\\underline{R}}etrieval-\\textbf{\\underline{A}}ugmented \\textbf{\\underline{G}}eneration framework (\\textbf{LogicRAG}) that dynamically extracts reasoning structures at inference time to guide adaptive retrieval without any pre-built graph. LogicRAG begins by decomposing the input query into a set of subproblems and constructing a directed acyclic graph (DAG) to model the logical dependencies among them. To support coherent multi-step reasoning, LogicRAG then linearizes the graph using topological sort, so that subproblems can be addressed in a logically consistent order. Besides, LogicRAG applies graph pruning to reduce redundant retrieval and uses context pruning to filter irrelevant context, significantly reducing the overall token cost. Extensive experiments demonstrate that LogicRAG achieves both superior performance and efficiency compared to state-of-the-art baselines.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.06105.pdf", "abstract_url": "https://arxiv.org/abs/2508.06105", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"]}
{"id": "2508.06149", "title": "Scaling Personality Control in LLMs with Big Five Scaler Prompts", "authors": ["Gunhee Cho", "Yun-Gyung Cheong"], "abstract": "We present Big5-Scaler, a prompt-based framework for conditioning large language models (LLMs) with controllable Big Five personality traits. By embedding numeric trait values into natural language prompts, our method enables fine-grained personality control without additional training. We evaluate Big5-Scaler across trait expression, dialogue generation, and human trait imitation tasks. Results show that it induces consistent and distinguishable personality traits across models, with performance varying by prompt type and scale. Our analysis highlights the effectiveness of concise prompts and lower trait intensities, providing a efficient approach for building personality-aware dialogue agents.", "subjects": "Computation and Language (cs.CL); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.06149.pdf", "abstract_url": "https://arxiv.org/abs/2508.06149", "categories": ["Computation and Language (cs.CL)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"]}
{"id": "2508.06165", "title": "UR$^2$: Unify RAG and Reasoning through Reinforcement Learning", "authors": ["Weitao Li", "Boran Xiang", "Xiaolong Wang", "Zhinan Gou", "Weizhi Ma", "Yang Liu"], "abstract": "Large Language Models (LLMs) have shown remarkable capabilities through two complementary paradigms: Retrieval-Augmented Generation (RAG), which enhances knowledge grounding, and Reinforcement Learning from Verifiable Rewards (RLVR), which optimizes complex reasoning abilities. However, these two capabilities are often developed in isolation, and existing efforts to unify them remain narrow in scope-typically limited to open-domain QA with fixed retrieval settings and task-specific assumptions. This lack of integration constrains generalization and limits the applicability of RAG-RL methods to broader domains. To bridge this gap, we propose UR2 (Unified RAG and Reasoning), a general framework that unifies retrieval and reasoning through reinforcement learning. UR2 introduces two key contributions: a difficulty-aware curriculum training that selectively invokes retrieval only for challenging problems, and a hybrid knowledge access strategy combining domain-specific offline corpora with LLM-generated summaries. These components are designed to enable dynamic coordination between retrieval and reasoning, improving adaptability across a diverse range of tasks. Experiments across open-domain QA, MMLU-Pro, medical, and mathematical reasoning tasks demonstrate that UR2 (built on Qwen2.5-3/7B and LLaMA-3.1-8B) significantly outperforms existing RAG and RL methods, achieving comparable performance to GPT-4o-mini and GPT-4.1-mini on several benchmarks. We have released all code, models, and data at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.06165.pdf", "abstract_url": "https://arxiv.org/abs/2508.06165", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"]}
{"id": "2508.06178", "title": "Comparing Knowledge Injection Methods for LLMs in a Low-Resource Regime", "authors": ["Hugo Abonizio", "Thales Almeida", "Roberto Lotufo", "Rodrigo Nogueira"], "abstract": "Large language models (LLMs) often require vast amounts of text to effectively acquire new knowledge. While continuing pre-training on large corpora or employing retrieval-augmented generation (RAG) has proven successful, updating an LLM with only a few thousand or million tokens remains challenging. In this work, we investigate the task of injecting small, unstructured information into LLMs and its relation to the catastrophic forgetting phenomenon. We use a dataset of recent news -- ensuring no overlap with the model's pre-training data -- to evaluate the knowledge acquisition by probing the model with question-answer pairs related the learned information. Starting from a continued pre-training baseline, we explored different augmentation algorithms to generate synthetic data to improve the knowledge acquisition capabilities. Our experiments show that simply continuing pre-training on limited data yields modest improvements, whereas exposing the model to diverse textual variations significantly improves the learning of new facts -- particularly with methods that induce greater variability through diverse prompting. Furthermore, we shed light on the forgetting phenomenon in small-data regimes, illustrating the delicate balance between learning new content and retaining existing capabilities. We also confirm the sensitivity of RAG-based approaches for knowledge injection, which often lead to greater degradation on control datasets compared to parametric methods. Finally, we demonstrate that models can generate effective synthetic training data themselves, suggesting a pathway toward self-improving model updates. All code and generated data used in our experiments are publicly available, providing a resource for studying efficient knowledge injection in LLMs with limited data at", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.06178.pdf", "abstract_url": "https://arxiv.org/abs/2508.06178", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"]}
{"id": "2508.06204", "title": "Classification is a RAG problem: A case study on hate speech detection", "authors": ["Richard Willats", "Josh Pennington", "Aravind Mohan", "Bertie Vidgen"], "abstract": "Robust content moderation requires classification systems that can quickly adapt to evolving policies without costly retraining. We present classification using Retrieval-Augmented Generation (RAG), which shifts traditional classification tasks from determining the correct category in accordance with pre-trained parameters to evaluating content in relation to contextual knowledge retrieved at inference. In hate speech detection, this transforms the task from \"is this hate speech?\" to \"does this violate the hate speech policy?\"", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.06204.pdf", "abstract_url": "https://arxiv.org/abs/2508.06204", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"]}
{"id": "2508.06145", "title": "Retrieval Augmented Large Language Model System for Comprehensive Drug Contraindications", "authors": ["Byeonghun Bang", "Jongsuk Yoon", "Dong-Jin Chang", "Seho Park", "Yong Oh Lee"], "abstract": "The versatility of large language models (LLMs) has been explored across various sectors, but their application in healthcare poses challenges, particularly in the domain of pharmaceutical contraindications where accurate and reliable information is required. This study enhances the capability of LLMs to address contraindications effectively by implementing a Retrieval Augmented Generation (RAG) pipeline. Utilizing OpenAI's GPT-4o-mini as the base model, and the text-embedding-3-small model for embeddings, our approach integrates Langchain to orchestrate a hybrid retrieval system with re-ranking. This system leverages Drug Utilization Review (DUR) data from public databases, focusing on contraindications for specific age groups, pregnancy, and concomitant drug use. The dataset includes 300 question-answer pairs across three categories, with baseline model accuracy ranging from 0.49 to 0.57. Post-integration of the RAG pipeline, we observed a significant improvement in model accuracy, achieving rates of 0.94, 0.87, and 0.89 for contraindications related to age groups, pregnancy, and concomitant drug use, respectively. The results indicate that augmenting LLMs with a RAG framework can substantially reduce uncertainty in prescription and drug intake decisions by providing more precise and reliable drug contraindication information.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.06145.pdf", "abstract_url": "https://arxiv.org/abs/2508.06145", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"]}
{"id": "2508.06326", "title": "A \"good regulator theorem\" for embodied agents", "authors": ["Nathaniel Virgo", "Martin Biehl", "Manuel Baltieri", "Matteo Capucci"], "abstract": "In a classic paper, Conant and Ashby claimed that \"every good regulator of a system must be a model of that system.\" Artificial Life has produced many examples of systems that perform tasks with apparently no model in sight; these suggest Conant and Ashby's theorem doesn't easily generalise beyond its restricted setup. Nevertheless, here we show that a similar intuition can be fleshed out in a different way: whenever an agent is able to perform a regulation task, it is possible for an observer to interpret it as having \"beliefs\" about its environment, which it \"updates\" in response to sensory input. This notion of belief updating provides a notion of model that is more sophisticated than Conant and Ashby's, as well as a theorem that is more broadly applicable. However, it necessitates a change in perspective, in that the observer plays an essential role in the theory: models are not a mere property of the system but are imposed on it from outside. Our theorem holds regardless of whether the system is regulating its environment in a classic control theory setup, or whether it's regulating its own internal state; the model is of its environment either way. The model might be trivial, however, and this is how the apparent counterexamples are resolved.", "subjects": "Artificial Intelligence (cs.AI); Systems and Control (eess.SY)", "comments": "Accepted at the Artificial Life conference 2025 (ALife 2025). 10 pages, 1 figure", "pdf_url": "https://arxiv.org/pdf/2508.06326.pdf", "abstract_url": "https://arxiv.org/abs/2508.06326", "categories": ["Artificial Intelligence (cs.AI)", "Systems and Control (eess.SY)"], "matching_keywords": ["agent"]}
{"id": "2304.04475", "title": "Epidemic Control on a Large-Scale-Agent-Based Epidemiology Model using Deep Deterministic Policy Gradient", "authors": ["Gaurav Deshkar", "Jayanta Kshirsagar", "Harshal Hayatnagarkar", "Janani Venugopalan"], "abstract": "To mitigate the impact of the pandemic, several measures include lockdowns, rapid vaccination programs, school closures, and economic stimulus. These interventions can have positive or unintended negative consequences. Current research to model and determine an optimal intervention automatically through round-tripping is limited by the simulation objectives, scale (a few thousand individuals), model types that are not suited for intervention studies, and the number of intervention strategies they can explore (discrete vs continuous). We address these challenges using a Deep Deterministic Policy Gradient (DDPG) based policy optimization framework on a large-scale (100,000 individual) epidemiological agent-based simulation where we perform multi-objective optimization. We determine the optimal policy for lockdown and vaccination in a minimalist age-stratified multi-vaccine scenario with a basic simulation for economic activity. With no lockdown and vaccination (mid-age and elderly), results show optimal economy (individuals below the poverty line) with balanced health objectives (infection, and hospitalization). An in-depth simulation is needed to further validate our results and open-source our framework.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Systems and Control (eess.SY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2304.04475.pdf", "abstract_url": "https://arxiv.org/abs/2304.04475", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Systems and Control (eess.SY)"], "matching_keywords": ["agent"]}
{"id": "2508.05637", "title": "Automated Visualization Makeovers with LLMs", "authors": ["Siddharth Gangwar", "David A. Selby", "Sebastian J. Vollmer"], "abstract": "Making a good graphic that accurately and efficiently conveys the desired message to the audience is both an art and a science, typically not taught in the data science curriculum. Visualisation makeovers are exercises where the community exchange feedback to improve charts and data visualizations. Can multi-modal large language models (LLMs) emulate this task? Given a plot in the form of an image file, or the code used to generate it, an LLM, primed with a list of visualization best practices, is employed to semi-automatically generate constructive criticism to produce a better plot. Our system is centred around prompt engineering of a pre-trained model, relying on a combination of userspecified guidelines and any latent knowledge of data visualization practices that might lie within an LLMs training corpus. Unlike other works, the focus is not on generating valid visualization scripts from raw data or prompts, but on educating the user how to improve their existing data visualizations according to an interpretation of best practices. A quantitative evaluation is performed to measure the sensitivity of the LLM agent to various plotting issues across different chart types. We make the tool available as a simple self-hosted applet with an accessible Web interface.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.05637.pdf", "abstract_url": "https://arxiv.org/abs/2508.05637", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2508.06433", "title": "Memp: Exploring Agent Procedural Memory", "authors": ["Runnan Fang", "Yuan Liang", "Xiaobin Wang", "Jialong Wu", "Shuofei Qiao", "Pengjun Xie", "Fei Huang", "Huajun Chen", "Ningyu Zhang"], "abstract": "Large Language Models (LLMs) based agents excel at diverse tasks, yet they suffer from brittle procedural memory that is manually engineered or entangled in static parameters. In this work, we investigate strategies to endow agents with a learnable, updatable, and lifelong procedural memory. We propose Memp that distills past agent trajectories into both fine-grained, step-by-step instructions and higher-level, script-like abstractions, and explore the impact of different strategies for Build, Retrieval, and Update of procedural memory. Coupled with a dynamic regimen that continuously updates, corrects, and deprecates its contents, this repository evolves in lockstep with new experience. Empirical evaluation on TravelPlanner and ALFWorld shows that as the memory repository is refined, agents achieve steadily higher success rates and greater efficiency on analogous tasks. Moreover, procedural memory built from a stronger model retains its value: migrating the procedural memory to a weaker model yields substantial performance gains.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multiagent Systems (cs.MA)", "comments": "Work in progress", "pdf_url": "https://arxiv.org/pdf/2508.06433.pdf", "abstract_url": "https://arxiv.org/abs/2508.06433", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"]}
{"id": "2508.06471", "title": "GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models", "authors": ["GLM-4.5 Team", "Aohan Zeng", "Xin Lv", "Qinkai Zheng", "Zhenyu Hou", "Bin Chen", "Chengxing Xie", "Cunxiang Wang", "Da Yin", "Hao Zeng", "Jiajie Zhang", "Kedong Wang", "Lucen Zhong", "Mingdao Liu", "Rui Lu", "Shulin Cao", "Xiaohan Zhang", "Xuancheng Huang", "Yao Wei", "Yean Cheng", "Yifan An", "Yilin Niu", "Yuanhao Wen", "Yushi Bai", "Zhengxiao Du", "Zihan Wang", "Zilin Zhu", "Bohan Zhang", "Bosi Wen", "Bowen Wu", "Bowen Xu", "Can Huang", "Casey Zhao", "Changpeng Cai", "Chao Yu", "Chen Li", "Chendi Ge", "Chenghua Huang", "Chenhui Zhang", "Chenxi Xu", "Chenzheng Zhu", "Chuang Li", "Congfeng Yin", "Daoyan Lin", "Dayong Yang", "Dazhi Jiang", "Ding Ai", "Erle Zhu", "Fei Wang", "Gengzheng Pan", "Guo Wang", "Hailong Sun", "Haitao Li", "Haiyang Li", "Haiyi Hu", "Hanyu Zhang", "Hao Peng", "Hao Tai", "Haoke Zhang", "Haoran Wang", "Haoyu Yang", "He Liu", "He Zhao", "Hongwei Liu", "Hongxi Yan", "Huan Liu", "Huilong Chen", "Ji Li", "Jiajing Zhao", "Jiamin Ren", "Jian Jiao", "Jiani Zhao", "Jianyang Yan", "Jiaqi Wang", "Jiayi Gui", "Jiayue Zhao", "Jie Liu", "Jijie Li", "Jing Li", "Jing Lu", "Jingsen Wang", "Jingwei Yuan", "Jingxuan Li", "Jingzhao Du", "Jinhua Du", "Jinxin Liu", "Junkai Zhi", "Junli Gao", "Ke Wang", "Lekang Yang", "Liang Xu", "Lin Fan", "Lindong Wu", "Lintao Ding", "Lu Wang", "Man Zhang", "Minghao Li", "Minghuan Xu", "Mingming Zhao", "Mingshu Zhai"], "abstract": "We present GLM-4.5, an open-source Mixture-of-Experts (MoE) large language model with 355B total parameters and 32B activated parameters, featuring a hybrid reasoning method that supports both thinking and direct response modes. Through multi-stage training on 23T tokens and comprehensive post-training with expert model iteration and reinforcement learning, GLM-4.5 achieves strong performance across agentic, reasoning, and coding (ARC) tasks, scoring 70.1% on TAU-Bench, 91.0% on AIME 24, and 64.2% on SWE-bench Verified. With much fewer parameters than several competitors, GLM-4.5 ranks 3rd overall among all evaluated models and 2nd on agentic benchmarks. We release both GLM-4.5 (355B parameters) and a compact version, GLM-4.5-Air (106B parameters), to advance research in reasoning and agentic AI systems. Code, models, and more information are available at", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.06471.pdf", "abstract_url": "https://arxiv.org/abs/2508.06471", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"]}
{"id": "2508.05647", "title": "Query-Aware Graph Neural Networks for Enhanced Retrieval-Augmented Generation", "authors": ["Vibhor Agrawal", "Fay Wang", "Rishi Puri"], "abstract": "We present a novel graph neural network (GNN) architecture for retrieval-augmented generation (RAG) that leverages query-aware attention mechanisms and learned scoring heads to improve retrieval accuracy on complex, multi-hop questions. Unlike traditional dense retrieval methods that treat documents as independent entities, our approach constructs per-episode knowledge graphs that capture both sequential and semantic relationships between text chunks. We introduce an Enhanced Graph Attention Network with query-guided pooling that dynamically focuses on relevant parts of the graph based on user queries. Experimental results demonstrate that our approach significantly outperforms standard dense retrievers on complex question answering tasks, particularly for questions requiring multi-document reasoning. Our implementation leverages PyTorch Geometric for efficient processing of graph-structured data, enabling scalable deployment in production retrieval systems", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.05647.pdf", "abstract_url": "https://arxiv.org/abs/2508.05647", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"]}
{"id": "2508.05648", "title": "AquiLLM: a RAG Tool for Capturing Tacit Knowledge in Research Groups", "authors": ["Chandler Campbell", "Bernie Boscoe", "Tuan Do"], "abstract": "Research groups face persistent challenges in capturing, storing, and retrieving knowledge that is distributed across team members. Although structured data intended for analysis and publication is often well managed, much of a group's collective knowledge remains informal, fragmented, or undocumented--often passed down orally through meetings, mentoring, and day-to-day collaboration. This includes private resources such as emails, meeting notes, training materials, and ad hoc documentation. Together, these reflect the group's tacit knowledge--the informal, experience-based expertise that underlies much of their work. Accessing this knowledge can be difficult, requiring significant time and insider understanding. Retrieval-augmented generation (RAG) systems offer promising solutions by enabling users to query and generate responses grounded in relevant source material. However, most current RAG-LLM systems are oriented toward public documents and overlook the privacy concerns of internal research materials. We introduce AquiLLM (pronounced ah-quill-em), a lightweight, modular RAG system designed to meet the needs of research groups. AquiLLM supports varied document types and configurable privacy settings, enabling more effective access to both formal and informal knowledge within scholarly groups.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "comments": "Accepted to US Research Software Engineer Association (US-RSE) 2025", "pdf_url": "https://arxiv.org/pdf/2508.05648.pdf", "abstract_url": "https://arxiv.org/abs/2508.05648", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"]}
{"id": "2508.05650", "title": "OmniBench-RAG: A Multi-Domain Evaluation Platform for Retrieval-Augmented Generation Tools", "authors": ["Jiaxuan Liang", "Shide Zhou", "Kailong Wang"], "abstract": "While Retrieval Augmented Generation (RAG) is now widely adopted to enhance LLMs, evaluating its true performance benefits in a reproducible and interpretable way remains a major hurdle. Existing methods often fall short: they lack domain coverage, employ coarse metrics that miss sub document precision, and fail to capture computational trade offs. Most critically, they provide no standardized framework for comparing RAG effectiveness across different models and domains.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.05650.pdf", "abstract_url": "https://arxiv.org/abs/2508.05650", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"]}
{"id": "2508.05652", "title": "Lessons from A Large Language Model-based Outdoor Trail Recommendation Chatbot with Retrieval Augmented Generation", "authors": ["Julia Ann Mathew", "Suining He"], "abstract": "The increasing popularity of outdoor recreational activities (such as hiking and biking) has boosted the demand for a conversational AI system to provide informative and personalized suggestion on outdoor trails. Challenges arise in response to (1) how to provide accurate outdoor trail information via conversational AI; and (2) how to enable usable and efficient recommendation services. To address above, this paper discusses the preliminary and practical lessons learned from developing Judy, an outdoor trail recommendation chatbot based on the large language model (LLM) with retrieval augmented generation (RAG). To gain concrete system insights, we have performed case studies with the outdoor trails in Connecticut (CT), US. We have conducted web-based data collection, outdoor trail data management, and LLM model performance studies on the RAG-based recommendation. Our experimental results have demonstrated the accuracy, effectiveness, and usability of Judy in recommending outdoor trails based on the LLM with RAG.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "comments": "4 pages, UrbComp 2025", "pdf_url": "https://arxiv.org/pdf/2508.05652.pdf", "abstract_url": "https://arxiv.org/abs/2508.05652", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"]}
{"id": "2508.05660", "title": "Open-Source Agentic Hybrid RAG Framework for Scientific Literature Review", "authors": ["Aditya Nagori", "Ricardo Accorsi Casonatto", "Ayush Gautam", "Abhinav Manikantha Sai Cheruvu", "Rishikesan Kamaleswaran"], "abstract": "The surge in scientific publications challenges traditional review methods, demanding tools that integrate structured metadata with full-text analysis. Hybrid Retrieval Augmented Generation (RAG) systems, combining graph queries with vector search offer promise but are typically static, rely on proprietary tools, and lack uncertainty estimates. We present an agentic approach that encapsulates the hybrid RAG pipeline within an autonomous agent capable of (1) dynamically selecting between GraphRAG and VectorRAG for each query, (2) adapting instruction-tuned generation in real time to researcher needs, and (3) quantifying uncertainty during inference. This dynamic orchestration improves relevance, reduces hallucinations, and promotes reproducibility.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.05660.pdf", "abstract_url": "https://arxiv.org/abs/2508.05660", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic", "@RAG"]}
{"id": "2508.05662", "title": "From Static to Dynamic: A Streaming RAG Approach to Real-time Knowledge Base", "authors": ["Yuzhou Zhu"], "abstract": "Dynamic streams from news feeds, social media, sensor networks, and financial markets challenge static RAG frameworks. Full-scale indices incur high memory costs; periodic rebuilds introduce latency that undermines data freshness; naive sampling sacrifices semantic coverage. We present Streaming RAG, a unified pipeline that combines multi-vector cosine screening, mini-batch clustering, and a counter-based heavy-hitter filter to maintain a compact prototype set. We further prove an approximation bound \\$E\\[R(K\\_t)] \\ge R^\\* - L \\Delta\\$ linking retrieval quality to clustering variance. An incremental index upsert mechanism refreshes prototypes without interrupting queries. Experiments on eight real-time streams show statistically significant gains in Recall\\@10 (up to 3 points, p < 0.01), end-to-end latency below 15 ms, and throughput above 900 documents per second under a 150 MB budget. Hyperparameter sensitivity analysis over cluster count, admission probability, relevance threshold, and counter capacity validates default settings. In open-domain question answering with GPT-3.5 Turbo, we record 3.2-point gain in Exact Match and 2.8-point gain in F1 on SQuAD; abstractive summarization yields ROUGE-L improvements. Streaming RAG establishes a new Pareto frontier for retrieval augmentation.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.05662.pdf", "abstract_url": "https://arxiv.org/abs/2508.05662", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"]}
{"id": "2508.05664", "title": "Enhancing Retrieval-Augmented Generation for Electric Power Industry Customer Support", "authors": ["Hei Yu Chan", "Kuok Tou Ho", "Chenglong Ma", "Yujing Si", "Hok Lai Lin", "Sa Lei Lam"], "abstract": "Many AI customer service systems use standard NLP pipelines or finetuned language models, which often fall short on ambiguous, multi-intent, or detail-specific queries. This case study evaluates recent techniques: query rewriting, RAG Fusion, keyword augmentation, intent recognition, and context reranking, for building a robust customer support system in the electric power domain. We compare vector-store and graph-based RAG frameworks, ultimately selecting the graph-based RAG for its superior performance in handling complex queries. We find that query rewriting improves retrieval for queries using non-standard terminology or requiring precise detail. RAG Fusion boosts performance on vague or multifaceted queries by merging multiple retrievals. Reranking reduces hallucinations by filtering irrelevant contexts. Intent recognition supports the decomposition of complex questions into more targeted sub-queries, increasing both relevance and efficiency. In contrast, keyword augmentation negatively impacts results due to biased keyword selection. Our final system combines intent recognition, RAG Fusion, and reranking to handle disambiguation and multi-source queries. Evaluated on both a GPT-4-generated dataset and a real-world electricity provider FAQ dataset, it achieves 97.9% and 89.6% accuracy respectively, substantially outperforming baseline RAG models.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "6 pages", "pdf_url": "https://arxiv.org/pdf/2508.05664.pdf", "abstract_url": "https://arxiv.org/abs/2508.05664", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"]}
{"id": "2508.05666", "title": "HySemRAG: A Hybrid Semantic Retrieval-Augmented Generation Framework for Automated Literature Synthesis and Methodological Gap Analysis", "authors": ["Alejandro Godinez"], "abstract": "We present HySemRAG, a framework that combines Extract, Transform, Load (ETL) pipelines with Retrieval-Augmented Generation (RAG) to automate large-scale literature synthesis and identify methodological research gaps. The system addresses limitations in existing RAG architectures through a multi-layered approach: hybrid retrieval combining semantic search, keyword filtering, and knowledge graph traversal; an agentic self-correction framework with iterative quality assurance; and post-hoc citation verification ensuring complete traceability. Our implementation processes scholarly literature through eight integrated stages: multi-source metadata acquisition, asynchronous PDF retrieval, custom document layout analysis using modified Docling architecture, bibliographic management, LLM-based field extraction, topic modeling, semantic unification, and knowledge graph construction. The system creates dual data products - a Neo4j knowledge graph enabling complex relationship queries and Qdrant vector collections supporting semantic search - serving as foundational infrastructure for verifiable information synthesis. Evaluation across 643 observations from 60 testing sessions demonstrates structured field extraction achieving 35.1% higher semantic similarity scores (0.655 $\\pm$ 0.178) compared to PDF chunking approaches (0.485 $\\pm$ 0.204, p < 0.000001). The agentic quality assurance mechanism achieves 68.3% single-pass success rates with 99.0% citation accuracy in validated responses. Applied to geospatial epidemiology literature on ozone exposure and cardiovascular disease, the system identifies methodological trends and research gaps, demonstrating broad applicability across scientific domains for accelerating evidence synthesis and discovery.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": ". ETL+multi-agent RAG framework for literature synthesis, 35.1% improvement over PDF chunking. Real application: reduced 17,400 papers to 24 relevant ones (99.86%) in 10 minutes for wastewater epidemiology review", "pdf_url": "https://arxiv.org/pdf/2508.05666.pdf", "abstract_url": "https://arxiv.org/abs/2508.05666", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic", "@RAG"]}
{"id": "2508.06492", "title": "Effective Training Data Synthesis for Improving MLLM Chart Understanding", "authors": ["Yuwei Yang", "Zeyu Zhang", "Yunzhong Hou", "Zhuowan Li", "Gaowen Liu", "Ali Payani", "Yuan-Sen Ting", "Liang Zheng"], "abstract": "Being able to effectively read scientific plots, or chart understanding, is a central part toward building effective agents for science. However, existing multimodal large language models (MLLMs), especially open-source ones, are still falling behind with a typical success rate of 30%-50% on challenging benchmarks. Previous studies on fine-tuning MLLMs with synthetic charts are often restricted by their inadequate similarity to the real charts, which could compromise model training and performance on complex real-world charts. In this study, we show that modularizing chart generation and diversifying visual details improves chart understanding capabilities. In particular, we design a five-step data synthesis pipeline, where we separate data and function creation for single plot generation, condition the generation of later subplots on earlier ones for multi-subplot figures, visually diversify the generated figures, filter out low quality data, and finally generate the question-answer (QA) pairs with GPT-4o. This approach allows us to streamline the generation of fine-tuning datasets and introduce the effective chart dataset (ECD), which contains 10k+ chart images and 300k+ QA pairs, covering 25 topics and featuring 250+ chart type combinations with high visual complexity. We show that ECD consistently improves the performance of various MLLMs on a range of real-world and synthetic test sets. Code, data and models are available at:", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL)", "comments": "Accepted by ICCV 2025 (poster). 26 pages, 17 figures", "pdf_url": "https://arxiv.org/pdf/2508.06492.pdf", "abstract_url": "https://arxiv.org/abs/2508.06492", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2508.05838", "title": "Integrating Vision Foundation Models with Reinforcement Learning for Enhanced Object Interaction", "authors": ["Ahmad Farooq", "Kamran Iqbal"], "abstract": "This paper presents a novel approach that integrates vision foundation models with reinforcement learning to enhance object interaction capabilities in simulated environments. By combining the Segment Anything Model (SAM) and YOLOv5 with a Proximal Policy Optimization (PPO) agent operating in the AI2-THOR simulation environment, we enable the agent to perceive and interact with objects more effectively. Our comprehensive experiments, conducted across four diverse indoor kitchen settings, demonstrate significant improvements in object interaction success rates and navigation efficiency compared to a baseline agent without advanced perception. The results show a 68% increase in average cumulative reward, a 52.5% improvement in object interaction success rate, and a 33% increase in navigation efficiency. These findings highlight the potential of integrating foundation models with reinforcement learning for complex robotic tasks, paving the way for more sophisticated and capable autonomous agents.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Systems and Control (eess.SY)", "comments": "Published in the Proceedings of the 2025 3rd International Conference on Robotics, Control and Vision Engineering (RCVE'25). 6 pages, 3 figures, 1 table", "pdf_url": "https://arxiv.org/pdf/2508.05838.pdf", "abstract_url": "https://arxiv.org/abs/2508.05838", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)", "Machine Learning (cs.LG)", "Systems and Control (eess.SY)"], "matching_keywords": ["agent"]}
{"id": "2508.05668", "title": "A Survey of LLM-based Deep Search Agents: Paradigm, Optimization, Evaluation, and Challenges", "authors": ["Yunjia Xi", "Jianghao Lin", "Yongzhao Xiao", "Zheli Zhou", "Rong Shan", "Te Gao", "Jiachen Zhu", "Weiwen Liu", "Yong Yu", "Weinan Zhang"], "abstract": "The advent of Large Language Models (LLMs) has significantly revolutionized web search. The emergence of LLM-based Search Agents marks a pivotal shift towards deeper, dynamic, autonomous information seeking. These agents can comprehend user intentions and environmental context and execute multi-turn retrieval with dynamic planning, extending search capabilities far beyond the web. Leading examples like OpenAI's Deep Research highlight their potential for deep information mining and real-world applications. This survey provides the first systematic analysis of search agents. We comprehensively analyze and categorize existing works from the perspectives of architecture, optimization, application, and evaluation, ultimately identifying critical open challenges and outlining promising future research directions in this rapidly evolving field. Our repository is available on", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.05668.pdf", "abstract_url": "https://arxiv.org/abs/2508.05668", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2508.06059", "title": "Fact2Fiction: Targeted Poisoning Attack to Agentic Fact-checking System", "authors": ["Haorui He", "Yupeng Li", "Bin Benjamin Zhu", "Dacheng Wen", "Reynold Cheng", "Francis C. M. Lau"], "abstract": "State-of-the-art fact-checking systems combat misinformation at scale by employing autonomous LLM-based agents to decompose complex claims into smaller sub-claims, verify each sub-claim individually, and aggregate the partial results to produce verdicts with justifications (explanatory rationales for the verdicts). The security of these systems is crucial, as compromised fact-checkers, which tend to be easily underexplored, can amplify misinformation. This work introduces Fact2Fiction, the first poisoning attack framework targeting such agentic fact-checking systems. Fact2Fiction mirrors the decomposition strategy and exploits system-generated justifications to craft tailored malicious evidences that compromise sub-claim verification. Extensive experiments demonstrate that Fact2Fiction achieves 8.9\\%--21.2\\% higher attack success rates than state-of-the-art attacks across various poisoning budgets. Fact2Fiction exposes security weaknesses in current fact-checking systems and highlights the need for defensive countermeasures.", "subjects": "Cryptography and Security (cs.CR); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.06059.pdf", "abstract_url": "https://arxiv.org/abs/2508.06059", "categories": ["Cryptography and Security (cs.CR)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"]}
{"id": "2508.06401", "title": "A Systematic Literature Review of Retrieval-Augmented Generation: Techniques, Metrics, and Challenges", "authors": ["Andrew Brown", "Muhammad Roman", "Barry Devereux"], "abstract": "This systematic review of the research literature on retrieval-augmented generation (RAG) provides a focused analysis of the most highly cited studies published between 2020 and May 2025. A total of 128 articles met our inclusion criteria. The records were retrieved from ACM Digital Library, IEEE Xplore, Scopus, ScienceDirect, and the Digital Bibliography and Library Project (DBLP). RAG couples a neural retriever with a generative language model, grounding output in up-to-date, non-parametric memory while retaining the semantic generalisation stored in model weights. Guided by the PRISMA 2020 framework, we (i) specify explicit inclusion and exclusion criteria based on citation count and research questions, (ii) catalogue datasets, architectures, and evaluation practices, and (iii) synthesise empirical evidence on the effectiveness and limitations of RAG. To mitigate citation-lag bias, we applied a lower citation-count threshold to papers published in 2025 so that emerging breakthroughs with naturally fewer citations were still captured. This review clarifies the current research landscape, highlights methodological gaps, and charts priority directions for future research.", "subjects": "Digital Libraries (cs.DL); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Information Retrieval (cs.IR)", "comments": "58 pages", "pdf_url": "https://arxiv.org/pdf/2508.06401.pdf", "abstract_url": "https://arxiv.org/abs/2508.06401", "categories": ["Digital Libraries (cs.DL)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"]}
{"id": "2508.05670", "title": "Can LLMs effectively provide game-theoretic-based scenarios for cybersecurity?", "authors": ["Daniele Proverbio", "Alessio Buscemi", "Alessandro Di Stefano", "Anh Han", "German Castignani", "Pietro Liò"], "abstract": "Game theory has long served as a foundational tool in cybersecurity to test, predict, and design strategic interactions between attackers and defenders. The recent advent of Large Language Models (LLMs) offers new tools and challenges for the security of computer systems; In this work, we investigate whether classical game-theoretic frameworks can effectively capture the behaviours of LLM-driven actors and bots. Using a reproducible framework for game-theoretic LLM agents, we investigate two canonical scenarios -- the one-shot zero-sum game and the dynamic Prisoner's Dilemma -- and we test whether LLMs converge to expected outcomes or exhibit deviations due to embedded biases. Our experiments involve four state-of-the-art LLMs and span five natural languages, English, French, Arabic, Vietnamese, and Mandarin Chinese, to assess linguistic sensitivity. For both games, we observe that the final payoffs are influenced by agents characteristics such as personality traits or knowledge of repeated rounds. Moreover, we uncover an unexpected sensitivity of the final payoffs to the choice of languages, which should warn against indiscriminate application of LLMs in cybersecurity applications and call for in-depth studies, as LLMs may behave differently when deployed in different countries. We also employ quantitative metrics to evaluate the internal consistency and cross-language stability of LLM agents, to help guide the selection of the most stable LLMs and optimising models for secure applications.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Computer Science and Game Theory (cs.GT)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.05670.pdf", "abstract_url": "https://arxiv.org/abs/2508.05670", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)", "Computer Science and Game Theory (cs.GT)"], "matching_keywords": ["agent"]}
{"id": "2508.05672", "title": "LMAR: Language Model Augmented Retriever for Domain-specific Knowledge Indexing", "authors": ["Yao Zhao", "Yantian Ding", "Zhiyue Zhang", "Dapeng Yao", "Yanxun Xu"], "abstract": "Retrieval Augmented Generation (RAG) systems often struggle with domain-specific knowledge due to performance deterioration of pre-trained embeddings and prohibitive computational costs of large language model (LLM)-based retrievers. While fine-tuning data augmentation embedding models offers a promising direction, its effectiveness is limited by the need for high-quality training data and reliable chunking strategies that preserve contextual integrity. We propose LMAR (Language Model Augmented Retriever), a model-agnostic framework that addresses these challenges by combining LLM-guided data synthesis with contrastive embedding adaptation and efficient text clustering. LMAR consists of a two-stage pipeline: (1) Triplet sampling and synthetic data augmentation, where LLMs act as both labeler and validator to ensure high-fidelity supervision throughout the pipeline. Experimental results across multiple domain-specific benchmark datasets demonstrate that LMAR outperforms multiple baseline models, while maintaining moderate hardware requirements and low latency. Its model-agnostic nature further enables seamless integration with emerging RAG architectures and text embedding models, ensuring continual improvements without redesigning the pipeline. These results highlight LMAR as a practical and cost-effective solution for scalable domain-specific adaptation.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.05672.pdf", "abstract_url": "https://arxiv.org/abs/2508.05672", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"]}
{"id": "2508.05674", "title": "Towards Effective Offensive Security LLM Agents: Hyperparameter Tuning, LLM as a Judge, and a Lightweight CTF Benchmark", "authors": ["Minghao Shao", "Nanda Rani", "Kimberly Milner", "Haoran Xi", "Meet Udeshi", "Saksham Aggarwal", "Venkata Sai Charan Putrevu", "Sandeep Kumar Shukla", "Prashanth Krishnamurthy", "Farshad Khorrami", "Ramesh Karri", "Muhammad Shafique"], "abstract": "Recent advances in LLM agentic systems have improved the automation of offensive security tasks, particularly for Capture the Flag (CTF) challenges. We systematically investigate the key factors that drive agent success and provide a detailed recipe for building effective LLM-based offensive security agents. First, we present CTFJudge, a framework leveraging LLM as a judge to analyze agent trajectories and provide granular evaluation across CTF solving steps. Second, we propose a novel metric, CTF Competency Index (CCI) for partial correctness, revealing how closely agent solutions align with human-crafted gold standards. Third, we examine how LLM hyperparameters, namely temperature, top-p, and maximum token length, influence agent performance and automated cybersecurity task planning. For rapid evaluation, we present CTFTiny, a curated benchmark of 50 representative CTF challenges across binary exploitation, web, reverse engineering, forensics, and cryptography. Our findings identify optimal multi-agent coordination settings and lay the groundwork for future LLM agent research in cybersecurity. We make CTFTiny open source to public", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.05674.pdf", "abstract_url": "https://arxiv.org/abs/2508.05674", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"]}
{"id": "2508.05687", "title": "Risk Analysis Techniques for Governed LLM-based Multi-Agent Systems", "authors": ["Alistair Reid", "Simon O'Callaghan", "Liam Carroll", "Tiberio Caetano"], "abstract": "Organisations are starting to adopt LLM-based AI agents, with their deployments naturally evolving from single agents towards interconnected, multi-agent networks. Yet a collection of safe agents does not guarantee a safe collection of agents, as interactions between agents over time create emergent behaviours and induce novel failure modes. This means multi-agent systems require a fundamentally different risk analysis approach than that used for a single agent.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.05687.pdf", "abstract_url": "https://arxiv.org/abs/2508.05687", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2508.06457", "title": "ScamAgents: How AI Agents Can Simulate Human-Level Scam Calls", "authors": ["Sanket Badhe"], "abstract": "Large Language Models (LLMs) have demonstrated impressive fluency and reasoning capabilities, but their potential for misuse has raised growing concern. In this paper, we present ScamAgent, an autonomous multi-turn agent built on top of LLMs, capable of generating highly realistic scam call scripts that simulate real-world fraud scenarios. Unlike prior work focused on single-shot prompt misuse, ScamAgent maintains dialogue memory, adapts dynamically to simulated user responses, and employs deceptive persuasion strategies across conversational turns. We show that current LLM safety guardrails, including refusal mechanisms and content filters, are ineffective against such agent-based threats. Even models with strong prompt-level safeguards can be bypassed when prompts are decomposed, disguised, or delivered incrementally within an agent framework. We further demonstrate the transformation of scam scripts into lifelike voice calls using modern text-to-speech systems, completing a fully automated scam pipeline. Our findings highlight an urgent need for multi-turn safety auditing, agent-level control frameworks, and new methods to detect and disrupt conversational deception powered by generative AI.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Multiagent Systems (cs.MA)", "comments": "Accepted at CAMLIS 25: Conference on Applied Machine Learning for Information Security. 10 pages, 3 figures", "pdf_url": "https://arxiv.org/pdf/2508.06457.pdf", "abstract_url": "https://arxiv.org/abs/2508.06457", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"]}
{"id": "2508.05702", "title": "Semantic Reasoning Meets Numerical Precision: An LLM-Powered Multi-Agent System for Power Grid Control", "authors": ["Yan Zhang"], "abstract": "The increasing penetration of Distributed Energy Resources (DERs), widespread adoption of Electric Vehicles (EVs), and the growing frequency of extreme weather events have significantly increased the complexity of power grid planning, operation, and management. Traditional rule-based systems and numerical optimization approaches often struggle with the scale, dynamics, and adaptability required by modern power networks. This paper introduces Grid-Agent, an autonomous, AI-driven framework that combines Large Language Models (LLMs) with multi-agent reinforcement learning to detect and remediate grid violations in real time. Grid-Agent integrates semantic reasoning with numerical precision through a modular agent architecture: a planning agent generates coordinated action sequences using numerical power flow solvers, while a validation agent evaluates system stability and action effectiveness via sandboxed execution with safety rollbacks. To ensure scalability, Grid-Agent incorporates an adaptive multiscale network representation that dynamically selects optimal encoding schemes based on network size and complexity. The framework enables coordinated violation resolution through optimizing switch configurations, battery deployment, and load curtailment strategies. Experimental results in standard IEEE and CIGRE test systems (IEEE 69-bus, CIGRE MV, and IEEE 30-bus) demonstrate superior violation mitigation performance. Additionally, the framework's built-in data collection and learning capabilities enable continuous learning and adaptation to diverse network topologies. The autonomous nature of the framework makes it particularly suitable for modern smart grid applications requiring rapid response to dynamic operating conditions.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Systems and Control (eess.SY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.05702.pdf", "abstract_url": "https://arxiv.org/abs/2508.05702", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Systems and Control (eess.SY)"], "matching_keywords": ["agent"]}
{"id": "2508.05728", "title": "CLAPP: The CLASS LLM Agent for Pair Programming", "authors": ["Santiago Casas", "Christian Fidler", "Boris Bolliet", "Francisco Villaescusa-Navarro", "Julien Lesgourgues"], "abstract": "We introduce CLAPP (CLASS LLM Agent for Pair Programming), an interactive AI assistant designed to support researchers working with the Einstein-Boltzmann solver CLASS. CLAPP leverages large language models (LLMs) and domain-specific retrieval to provide conversational coding support for CLASS-answering questions, generating code, debugging errors, and producing plots. Its architecture combines multi-agent LLM orchestration, semantic search across CLASS documentation, and a live Python execution environment. Deployed as a user-friendly web application, CLAPP lowers the entry barrier for scientists unfamiliar with AI tools and enables more productive human-AI collaboration in computational and numerical cosmology. The app is available at", "subjects": "Instrumentation and Methods for Astrophysics (astro-ph.IM); Cosmology and Nongalactic Astrophysics (astro-ph.CO); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2508.05728.pdf", "abstract_url": "https://arxiv.org/abs/2508.05728", "categories": ["Instrumentation and Methods for Astrophysics (astro-ph.IM)", "Cosmology and Nongalactic Astrophysics (astro-ph.CO)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"]}
{"id": "2508.05970", "title": "Impact-driven Context Filtering For Cross-file Code Completion", "authors": ["Yanzhou Li", "Shangqing Liu", "Kangjie Chen", "Tianwei Zhang", "Yang Liu"], "abstract": "Retrieval-augmented generation (RAG) has recently demonstrated considerable potential for repository-level code completion, as it integrates cross-file knowledge with in-file preceding code to provide comprehensive contexts for generation. To better understand the contribution of the retrieved cross-file contexts, we introduce a likelihood-based metric to evaluate the impact of each retrieved code chunk on the completion. Our analysis reveals that, despite retrieving numerous chunks, only a small subset positively contributes to the completion, while some chunks even degrade performance. To address this issue, we leverage this metric to construct a repository-level dataset where each retrieved chunk is labeled as positive, neutral, or negative based on its relevance to the target completion. We then propose an adaptive retrieval context filtering framework, CODEFILTER, trained on this dataset to mitigate the harmful effects of negative retrieved contexts in code completion. Extensive evaluation on the RepoEval and CrossCodeLongEval benchmarks demonstrates that CODEFILTER consistently improves completion accuracy compared to approaches without filtering operations across various tasks. Additionally, CODEFILTER significantly reduces the length of the input prompt, enhancing computational efficiency while exhibiting strong generalizability across different models. These results underscore the potential of CODEFILTER to enhance the accuracy, efficiency, and attributability of repository-level code completion.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.05970.pdf", "abstract_url": "https://arxiv.org/abs/2508.05970", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"]}
{"id": "2508.06269", "title": "OM2P: Offline Multi-Agent Mean-Flow Policy", "authors": ["Zhuoran Li", "Xun Wang", "Hai Zhong", "Longbo Huang"], "abstract": "Generative models, especially diffusion and flow-based models, have been promising in offline multi-agent reinforcement learning. However, integrating powerful generative models into this framework poses unique challenges. In particular, diffusion and flow-based policies suffer from low sampling efficiency due to their iterative generation processes, making them impractical in time-sensitive or resource-constrained settings. To tackle these difficulties, we propose OM2P (Offline Multi-Agent Mean-Flow Policy), a novel offline MARL algorithm to achieve efficient one-step action sampling. To address the misalignment between generative objectives and reward maximization, we introduce a reward-aware optimization scheme that integrates a carefully-designed mean-flow matching loss with Q-function supervision. Additionally, we design a generalized timestep distribution and a derivative-free estimation strategy to reduce memory overhead and improve training stability. Empirical evaluations on Multi-Agent Particle and MuJoCo benchmarks demonstrate that OM2P achieves superior performance, with up to a 3.8x reduction in GPU memory usage and up to a 10.8x speed-up in training time. Our approach represents the first to successfully integrate mean-flow model into offline MARL, paving the way for practical and scalable generative policies in cooperative multi-agent settings.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.06269.pdf", "abstract_url": "https://arxiv.org/abs/2508.06269", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2508.06336", "title": "Unsupervised Partner Design Enables Robust Ad-hoc Teamwork", "authors": ["Constantin Ruhdorfer", "Matteo Bortoletto", "Victor Oei", "Anna Penzkofer", "Andreas Bulling"], "abstract": "We introduce Unsupervised Partner Design (UPD) - a population-free, multi-agent reinforcement learning framework for robust ad-hoc teamwork that adaptively generates training partners without requiring pretrained partners or manual parameter tuning. UPD constructs diverse partners by stochastically mixing an ego agent's policy with biased random behaviours and scores them using a variance-based learnability metric that prioritises partners near the ego agent's current learning frontier. We show that UPD can be integrated with unsupervised environment design, resulting in the first method enabling fully unsupervised curricula over both level and partner distributions in a cooperative setting. Through extensive evaluations on Overcooked-AI and the Overcooked Generalisation Challenge, we demonstrate that this dynamic partner curriculum is highly effective: UPD consistently outperforms both population-based and population-free baselines as well as ablations. In a user study, we further show that UPD achieves higher returns than all baselines and was perceived as significantly more adaptive, more human-like, a better collaborator, and less frustrating.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Multiagent Systems (cs.MA)", "comments": "16 pages", "pdf_url": "https://arxiv.org/pdf/2508.06336.pdf", "abstract_url": "https://arxiv.org/abs/2508.06336", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"]}
{"id": "2508.06343", "title": "On Approximate MMS Allocations on Restricted Graph Classes", "authors": ["Václav Blažej", "Michał Dębski ad Zbigniew Lonc", "Marta Piecyk", "Paweł Rzążewski"], "abstract": "We study the problem of fair division of a set of indivisible goods with connectivity constraints. Specifically, we assume that the goods are represented as vertices of a connected graph, and sets of goods allocated to the agents are connected subgraphs of this graph. We focus on the widely-studied maximin share criterion of fairness. It has been shown that an allocation satisfying this criterion may not exist even without connectivity constraints, i.e., if the graph of goods is complete. In view of this, it is natural to seek approximate allocations that guarantee each agent a connected bundle of goods with value at least a constant fraction of the maximin share value to the agent. It is known that for some classes of graphs, such as complete graphs, cycles, and $d$-claw-free graphs for any fixed $d$, such approximate allocations indeed exist. However, it is an open problem whether they exist for the class of all graphs.", "subjects": "Discrete Mathematics (cs.DM); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.06343.pdf", "abstract_url": "https://arxiv.org/abs/2508.06343", "categories": ["Discrete Mathematics (cs.DM)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2508.06361", "title": "Beyond Prompt-Induced Lies: Investigating LLM Deception on Benign Prompts", "authors": ["Zhaomin Wu", "Mingzhe Du", "See-Kiong Ng", "Bingsheng He"], "abstract": "Large Language Models (LLMs) have been widely deployed in reasoning, planning, and decision-making tasks, making their trustworthiness a critical concern. The potential for intentional deception, where an LLM deliberately fabricates or conceals information to serve a hidden objective, remains a significant and underexplored threat. Existing studies typically induce such deception by explicitly setting a \"hidden\" objective through prompting or fine-tuning, which may not fully reflect real-world human-LLM interactions. Moving beyond this human-induced deception, we investigate LLMs' self-initiated deception on benign prompts. To address the absence of ground truth in this evaluation, we propose a novel framework using \"contact searching questions.\" This framework introduces two statistical metrics derived from psychological principles to quantify the likelihood of deception. The first, the Deceptive Intention Score, measures the model's bias towards a hidden objective. The second, Deceptive Behavior Score, measures the inconsistency between the LLM's internal belief and its expressed output. Upon evaluating 14 leading LLMs, we find that both metrics escalate as task difficulty increases, rising in parallel for most models. Building on these findings, we formulate a mathematical model to explain this behavior. These results reveal that even the most advanced LLMs exhibit an increasing tendency toward deception when handling complex problems, raising critical concerns for the deployment of LLM agents in complex and crucial domains.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.06361.pdf", "abstract_url": "https://arxiv.org/abs/2508.06361", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2508.06387", "title": "End-to-End Text-to-SQL with Dataset Selection: Leveraging LLMs for Adaptive Query Generation", "authors": ["Anurag Tripathi", "Vaibhav Patle", "Abhinav Jain", "Ayush Pundir", "Sairam Menon", "Ajeet Kumar Singh"], "abstract": "Text-to-SQL bridges the gap between natural language and structured database language, thus allowing non-technical users to easily query databases. Traditional approaches model text-to-SQL as a direct translation task, where a given Natural Language Query (NLQ) is mapped to an SQL command. Recent advances in large language models (LLMs) have significantly improved translation accuracy, however, these methods all require that the target database is pre-specified. This becomes problematic in scenarios with multiple extensive databases, where identifying the correct database becomes a crucial yet overlooked step. In this paper, we propose a three-stage end-to-end text-to-SQL framework to identify the user's intended database before generating SQL queries. Our approach leverages LLMs and prompt engineering to extract implicit information from natural language queries (NLQs) in the form of a ruleset. We then train a large db\\_id prediction model, which includes a RoBERTa-based finetuned encoder, to predict the correct Database identifier (db\\_id) based on both the NLQ and the LLM-generated rules. Finally, we refine the generated SQL by using critic agents to correct errors. Experimental results demonstrate that our framework outperforms the current state-of-the-art models in both database intent prediction and SQL generation accuracy.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "Accepted in IJCNN25", "pdf_url": "https://arxiv.org/pdf/2508.06387.pdf", "abstract_url": "https://arxiv.org/abs/2508.06387", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
