{"id": "2504.17213", "title": "MCAF: Efficient Agent-based Video Understanding Framework through Multimodal Coarse-to-Fine Attention Focusing", "authors": ["Shiwen Cao", "Zhaoxing Zhang", "Junming Jiao", "Juyi Qiao", "Guowen Song", "Rong Shen"], "abstract": "Even in the era of rapid advances in large models, video understanding, particularly long videos, remains highly challenging. Compared with textual or image-based information, videos commonly contain more information with redundancy, requiring large models to strategically allocate attention at a global level for accurate comprehension. To address this, we propose MCAF, an agent-based, training-free framework perform video understanding through Multimodal Coarse-to-fine Attention Focusing. The key innovation lies in its ability to sense and prioritize segments of the video that are highly relevant to the understanding task. First, MCAF hierarchically concentrates on highly relevant frames through multimodal information, enhancing the correlation between the acquired contextual information and the query. Second, it employs a dilated temporal expansion mechanism to mitigate the risk of missing crucial details when extracting information from these concentrated frames. In addition, our framework incorporates a self-reflection mechanism utilizing the confidence level of the model's responses as feedback. By iteratively applying these two creative focusing strategies, it adaptively adjusts attention to capture highly query-connected context and thus improves response accuracy. MCAF outperforms comparable state-of-the-art methods on average. On the EgoSchema dataset, it achieves a remarkable 5% performance gain over the leading approach. Meanwhile, on Next-QA and IntentQA datasets, it outperforms the current state-of-the-art standard by 0.2% and 0.3% respectively. On the Video-MME dataset, which features videos averaging nearly an hour in length, MCAF also outperforms other agent-based methods.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.17213.pdf", "abstract_url": "https://arxiv.org/abs/2504.17213", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "MCAF是一个基于代理的、无需训练的视频理解框架，通过多模态粗到细的注意力聚焦来提高长视频理解的效率和准确性。", "motivation": "解决长视频理解中的信息冗余和注意力分配问题，提高模型对视频内容的准确理解能力。", "method": "采用多模态粗到细的注意力聚焦策略，包括层次化聚焦相关帧和使用扩张时间扩展机制，以及自我反思机制来调整注意力。", "result": "在EgoSchema数据集上性能提升5%，在Next-QA和IntentQA数据集上分别提升0.2%和0.3%，在Video-MME数据集上也优于其他基于代理的方法。", "conclusion": "MCAF通过创新的注意力聚焦策略，有效提高了视频理解的准确性和效率，特别是在处理长视频时表现出色。"}}
{"id": "2504.17207", "title": "Perspective-Aware Reasoning in Vision-Language Models via Mental Imagery Simulation", "authors": ["Phillip Y. Lee", "Jihyeon Je", "Chanho Park", "Mikaela Angelina Uy", "Leonidas Guibas", "Minhyuk Sung"], "abstract": "We present a framework for perspective-aware reasoning in vision-language models (VLMs) through mental imagery simulation. Perspective-taking, the ability to perceive an environment or situation from an alternative viewpoint, is a key benchmark for human-level visual understanding, essential for environmental interaction and collaboration with autonomous agents. Despite advancements in spatial reasoning within VLMs, recent research has shown that modern VLMs significantly lack perspective-aware reasoning capabilities and exhibit a strong bias toward egocentric interpretations. To bridge the gap between VLMs and human perception, we focus on the role of mental imagery, where humans perceive the world through abstracted representations that facilitate perspective shifts. Motivated by this, we propose a framework for perspective-aware reasoning, named Abstract Perspective Change (APC), that effectively leverages vision foundation models, such as object detection, segmentation, and orientation estimation, to construct scene abstractions and enable perspective transformations. Our experiments on synthetic and real-image benchmarks, compared with various VLMs, demonstrate significant improvements in perspective-aware reasoning with our framework, further outperforming fine-tuned spatial reasoning models and novel-view-synthesis-based approaches.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2504.17207.pdf", "abstract_url": "https://arxiv.org/abs/2504.17207", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一个通过心理意象模拟在视觉语言模型（VLMs）中进行视角感知推理的框架，名为抽象视角变化（APC），旨在弥补VLMs与人类感知之间的差距。", "motivation": "现代视觉语言模型在视角感知推理能力上存在显著不足，且表现出强烈的自我中心解释偏见，这限制了它们的环境交互和与自主代理的协作能力。", "method": "提出的APC框架利用视觉基础模型（如物体检测、分割和方向估计）构建场景抽象，并实现视角转换，以模拟人类通过抽象表示感知世界的方式。", "result": "在合成和真实图像基准测试中，与各种VLMs相比，APC框架在视角感知推理方面表现出显著改进，甚至优于经过微调的空间推理模型和基于新视角合成的方法。", "conclusion": "APC框架通过模拟心理意象，有效提升了VLMs的视角感知推理能力，为视觉理解和与自主代理的协作开辟了新途径。"}}
{"id": "2504.17371", "title": "Highly Accurate and Diverse Traffic Data: The DeepScenario Open 3D Dataset", "authors": ["Oussema Dhaouadi", "Johannes Meier", "Luca Wahl", "Jacques Kaiser", "Luca Scalerandi", "Nick Wandelburg", "Zhuolun Zhou", "Nijanthan Berinpanathan", "Holger Banzhaf", "Daniel Cremers"], "abstract": "Accurate 3D trajectory data is crucial for advancing autonomous driving. Yet, traditional datasets are usually captured by fixed sensors mounted on a car and are susceptible to occlusion. Additionally, such an approach can precisely reconstruct the dynamic environment in the close vicinity of the measurement vehicle only, while neglecting objects that are further away. In this paper, we introduce the DeepScenario Open 3D Dataset (DSC3D), a high-quality, occlusion-free dataset of 6 degrees of freedom bounding box trajectories acquired through a novel monocular camera drone tracking pipeline. Our dataset includes more than 175,000 trajectories of 14 types of traffic participants and significantly exceeds existing datasets in terms of diversity and scale, containing many unprecedented scenarios such as complex vehicle-pedestrian interaction on highly populated urban streets and comprehensive parking maneuvers from entry to exit. DSC3D dataset was captured in five various locations in Europe and the United States and include: a parking lot, a crowded inner-city, a steep urban intersection, a federal highway, and a suburban intersection. Our 3D trajectory dataset aims to enhance autonomous driving systems by providing detailed environmental 3D representations, which could lead to improved obstacle interactions and safety. We demonstrate its utility across multiple applications including motion prediction, motion planning, scenario mining, and generative reactive traffic agents. Our interactive online visualization platform and the complete dataset are publicly available at", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.17371.pdf", "abstract_url": "https://arxiv.org/abs/2504.17371", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了DeepScenario Open 3D数据集（DSC3D），这是一个高质量、无遮挡的6自由度边界框轨迹数据集，通过新型单眼相机无人机跟踪流程获取，旨在提升自动驾驶系统的环境3D表示能力。", "motivation": "传统数据集由于固定传感器安装和遮挡问题，难以精确重建动态环境，尤其是在测量车辆较远的物体。DSC3D数据集解决了这一问题，提供了更广泛和多样化的交通参与者轨迹。", "method": "采用新型单眼相机无人机跟踪流程，捕获了超过175,000条14种交通参与者的轨迹，覆盖了五种不同的地理位置。", "result": "DSC3D数据集在多样性和规模上显著超过现有数据集，包含了许多前所未有的场景，如高度城市化街道上的复杂车辆-行人互动和全面的停车操作。", "conclusion": "DSC3D数据集通过提供详细的环境3D表示，有望改善自动驾驶系统中的障碍物交互和安全性，适用于运动预测、运动规划、场景挖掘和生成反应性交通代理等多种应用。"}}
{"id": "2504.17447", "title": "FRAG: Frame Selection Augmented Generation for Long Video and Long Document Understanding", "authors": ["De-An Huang", "Subhashree Radhakrishnan", "Zhiding Yu", "Jan Kautz"], "abstract": "There has been impressive progress in Large Multimodal Models (LMMs). Recent works extend these models to long inputs, including multi-page documents and long videos. However, the model size and performance of these long context models are still limited due to the computational cost in both training and inference. In this work, we explore an orthogonal direction and process long inputs without long context LMMs. We propose Frame Selection Augmented Generation (FRAG), where the model first selects relevant frames within the input, and then only generates the final outputs based on the selected frames. The core of the selection process is done by scoring each frame independently, which does not require long context processing. The frames with the highest scores are then selected by a simple Top-K selection. We show that this frustratingly simple framework is applicable to both long videos and multi-page documents using existing LMMs without any fine-tuning. We consider two models, LLaVA-OneVision and InternVL2, in our experiments and show that FRAG consistently improves the performance and achieves state-of-the-art performances for both long video and long document understanding. For videos, FRAG substantially improves InternVL2-76B by 5.8% on MLVU and 3.7% on Video-MME. For documents, FRAG achieves over 20% improvements on MP-DocVQA compared with recent LMMs specialized in long document understanding. Code is available at:", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.17447.pdf", "abstract_url": "https://arxiv.org/abs/2504.17447", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种名为FRAG的框架，用于长视频和多页文档的理解，通过独立评分选择相关帧，无需长上下文处理，显著提高了现有大型多模态模型的性能。", "motivation": "解决大型多模态模型在处理长输入（如多页文档和长视频）时因计算成本高而受限的问题。", "method": "提出Frame Selection Augmented Generation (FRAG)框架，通过独立评分选择相关帧，然后仅基于选定的帧生成最终输出。", "result": "FRAG在长视频和多页文档理解任务中显著提高了性能，如在MLVU和Video-MME上分别提高了5.8%和3.7%，在MP-DocVQA上实现了超过20%的改进。", "conclusion": "FRAG框架简单有效，无需微调即可应用于现有的大型多模态模型，显著提升了长视频和长文档理解的性能，达到了最先进的水平。"}}
{"id": "2504.17137", "title": "MIRAGE: A Metric-Intensive Benchmark for Retrieval-Augmented Generation Evaluation", "authors": ["Chanhee Park", "Hyeonseok Moon", "Chanjun Park", "Heuiseok Lim"], "abstract": "Retrieval-Augmented Generation (RAG) has gained prominence as an effective method for enhancing the generative capabilities of Large Language Models (LLMs) through the incorporation of external knowledge. However, the evaluation of RAG systems remains a challenge, due to the intricate interplay between retrieval and generation components. This limitation has resulted in a scarcity of benchmarks that facilitate a detailed, component-specific assessment. In this work, we present MIRAGE, a Question Answering dataset specifically designed for RAG evaluation. MIRAGE consists of 7,560 curated instances mapped to a retrieval pool of 37,800 entries, enabling an efficient and precise evaluation of both retrieval and generation tasks. We also introduce novel evaluation metrics aimed at measuring RAG adaptability, encompassing dimensions such as noise vulnerability, context acceptability, context insensitivity, and context misinterpretation. Through comprehensive experiments across various retriever-LLM configurations, we provide new insights into the optimal alignment of model pairs and the nuanced dynamics within RAG systems. The dataset and evaluation code are publicly available, allowing for seamless integration and customization in diverse research settings\\footnote{The MIRAGE code and data are available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "Accepted to NAACL2025 Findings", "pdf_url": "https://arxiv.org/pdf/2504.17137.pdf", "abstract_url": "https://arxiv.org/abs/2504.17137", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了MIRAGE，一个专为检索增强生成（RAG）评估设计的问答数据集，包含7,560个实例和37,800个检索条目，旨在通过新颖的评价指标解决RAG系统评估的挑战。", "motivation": "检索增强生成（RAG）系统评估的复杂性导致了缺乏能够进行详细、组件特定评估的基准，本文旨在解决这一问题。", "method": "提出了MIRAGE数据集，包含大量精心策划的实例和检索条目，并引入了新的评价指标来衡量RAG的适应性。", "result": "通过在不同检索器-LLM配置上的全面实验，提供了关于模型对最佳对齐和RAG系统内部细微动态的新见解。", "conclusion": "MIRAGE数据集和评估代码的公开可用性，为多样化的研究环境提供了无缝集成和定制化的可能性。"}}
{"id": "2504.17192", "title": "Paper2Code: Automating Code Generation from Scientific Papers in Machine Learning", "authors": ["Minju Seo", "Jinheon Baek", "Seongyun Lee", "Sung Ju Hwang"], "abstract": "Despite the rapid growth of machine learning research, corresponding code implementations are often unavailable, making it slow and labor-intensive for researchers to reproduce results and build upon prior work. In the meantime, recent Large Language Models (LLMs) excel at understanding scientific documents and generating high-quality code. Inspired by this, we introduce PaperCoder, a multi-agent LLM framework that transforms machine learning papers into functional code repositories. PaperCoder operates in three stages: planning, where it constructs a high-level roadmap, designs the system architecture with diagrams, identifies file dependencies, and generates configuration files; analysis, which focuses on interpreting implementation-specific details; and generation, where modular, dependency-aware code is produced. Moreover, each phase is instantiated through a set of specialized agents designed to collaborate effectively across the pipeline. We then evaluate PaperCoder on generating code implementations from machine learning papers based on both model-based and human evaluations, specifically from the original paper authors, with author-released repositories as ground truth if available. Our results demonstrate the effectiveness of PaperCoder in creating high-quality, faithful implementations. Furthermore, it consistently shows strengths in the recently released PaperBench benchmark, surpassing strong baselines by substantial margins.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.17192.pdf", "abstract_url": "https://arxiv.org/abs/2504.17192", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "PaperCoder是一个多代理大型语言模型框架，旨在将机器学习论文转化为功能性代码库，通过规划、分析和生成三个阶段自动化代码生成过程。", "motivation": "机器学习研究的快速增长与代码实现的不可用性之间的矛盾，使得研究人员难以复现结果和基于先前工作构建。", "method": "PaperCoder采用三阶段方法：规划阶段构建高级路线图和系统架构；分析阶段解释实现细节；生成阶段产生模块化、依赖感知的代码。每个阶段由专门设计的代理实例化，以在管道中有效协作。", "result": "PaperCoder在从机器学习论文生成代码实现方面显示出高效性，能够创建高质量、忠实的实现，并在PaperBench基准测试中大幅超越强基线。", "conclusion": "PaperCoder通过自动化代码生成，显著提高了机器学习研究的可复现性和效率，为研究人员提供了一个强大的工具来加速科学进步。"}}
{"id": "2504.17200", "title": "A RAG-Based Multi-Agent LLM System for Natural Hazard Resilience and Adaptation", "authors": ["Yangxinyu Xie", "Bowen Jiang", "Tanwi Mallick", "Joshua David Bergerson", "John K. Hutchison", "Duane R. Verner", "Jordan Branham", "M. Ross Alexander", "Robert B. Ross", "Yan Feng", "Leslie-Anne Levy", "Weijie Su", "Camillo J. Taylor"], "abstract": "Large language models (LLMs) are a transformational capability at the frontier of artificial intelligence and machine learning that can support decision-makers in addressing pressing societal challenges such as extreme natural hazard events. As generalized models, LLMs often struggle to provide context-specific information, particularly in areas requiring specialized knowledge. In this work we propose a retrieval-augmented generation (RAG)-based multi-agent LLM system to support analysis and decision-making in the context of natural hazards and extreme weather events. As a proof of concept, we present WildfireGPT, a specialized system focused on wildfire hazards. The architecture employs a user-centered, multi-agent design to deliver tailored risk insights across diverse stakeholder groups. By integrating natural hazard and extreme weather projection data, observational datasets, and scientific literature through an RAG framework, the system ensures both the accuracy and contextual relevance of the information it provides. Evaluation across ten expert-led case studies demonstrates that WildfireGPT significantly outperforms existing LLM-based solutions for decision support.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.17200.pdf", "abstract_url": "https://arxiv.org/abs/2504.17200", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文提出了一种基于检索增强生成（RAG）的多代理大型语言模型（LLM）系统，旨在支持自然灾害和极端天气事件的分析与决策。通过WildfireGPT这一专注于野火灾害的专门系统作为概念验证，展示了该系统如何通过整合自然灾害和极端天气预测数据、观测数据集及科学文献，为用户提供准确且上下文相关的信息。", "motivation": "大型语言模型（LLMs）虽然在人工智能和机器学习的前沿具有变革性能力，但在需要专业知识的领域，如极端自然灾害事件，往往难以提供特定上下文的信息。本文旨在解决这一问题，通过开发一个专门化的系统来支持决策者在自然灾害和极端天气事件中的分析和决策。", "method": "采用基于检索增强生成（RAG）的多代理LLM系统架构，整合自然灾害和极端天气的预测数据、观测数据集及科学文献，确保提供信息的准确性和上下文相关性。", "result": "通过十个专家主导的案例研究评估，WildfireGPT在决策支持方面显著优于现有的基于LLM的解决方案。", "conclusion": "本文提出的RAG-based多代理LLM系统，特别是WildfireGPT，为自然灾害和极端天气事件的决策支持提供了一个有效且专门化的解决方案，展示了LLMs在解决社会挑战中的潜力。"}}
{"id": "2504.16939", "title": "A Desideratum for Conversational Agents: Capabilities, Challenges, and Future Directions", "authors": ["Emre Can Acikgoz", "Cheng Qian", "Hongru Wang", "Vardhan Dongre", "Xiusi Chen", "Heng Ji", "Dilek Hakkani-Tür", "Gokhan Tur"], "abstract": "Recent advances in Large Language Models (LLMs) have propelled conversational AI from traditional dialogue systems into sophisticated agents capable of autonomous actions, contextual awareness, and multi-turn interactions with users. Yet, fundamental questions about their capabilities, limitations, and paths forward remain open. This survey paper presents a desideratum for next-generation Conversational Agents - what has been achieved, what challenges persist, and what must be done for more scalable systems that approach human-level intelligence. To that end, we systematically analyze LLM-driven Conversational Agents by organizing their capabilities into three primary dimensions: (i) Reasoning - logical, systematic thinking inspired by human intelligence for decision making, (ii) Monitor - encompassing self-awareness and user interaction monitoring, and (iii) Control - focusing on tool utilization and policy following. Building upon this, we introduce a novel taxonomy by classifying recent work on Conversational Agents around our proposed desideratum. We identify critical research gaps and outline key directions, including realistic evaluations, long-term multi-turn reasoning skills, self-evolution capabilities, collaborative and multi-agent task completion, personalization, and proactivity. This work aims to provide a structured foundation, highlight existing limitations, and offer insights into potential future research directions for Conversational Agents, ultimately advancing progress toward Artificial General Intelligence (AGI). We maintain a curated repository of papers at:", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.16939.pdf", "abstract_url": "https://arxiv.org/abs/2504.16939", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文是一篇关于对话代理的综述论文，探讨了大型语言模型（LLMs）驱动的对话代理的能力、挑战和未来发展方向。", "motivation": "尽管大型语言模型（LLMs）推动了对话AI的发展，使其能够进行自主行动、上下文感知和多轮交互，但关于其能力、局限性和未来发展路径的基本问题仍然开放。本文旨在为下一代对话代理提供一个期望标准，明确已实现的成就、存在的挑战以及实现更接近人类智能的可扩展系统所需采取的措施。", "method": "本文通过将LLM驱动的对话代理的能力组织成三个主要维度（推理、监控和控制），系统地分析了这些代理，并围绕提出的期望标准对近期关于对话代理的工作进行了分类，引入了一个新的分类法。", "result": "识别了关键的研究空白，并概述了主要的研究方向，包括现实评估、长期多轮推理能力、自我进化能力、协作和多代理任务完成、个性化以及主动性。", "conclusion": "本文旨在提供一个结构化的基础，突出现有的局限性，并为对话代理的未来研究方向提供见解，最终推动向人工通用智能（AGI）的进步。"}}
{"id": "2504.17087", "title": "Leveraging LLMs as Meta-Judges: A Multi-Agent Framework for Evaluating LLM Judgments", "authors": ["Yuran Li", "Jama Hussein Mohamud", "Chongren Sun", "Di Wu", "Benoit Boulet"], "abstract": "Large language models (LLMs) are being widely applied across various fields, but as tasks become more complex, evaluating their responses is increasingly challenging. Compared to human evaluators, the use of LLMs to support performance evaluation offers a more efficient alternative. However, most studies focus mainly on aligning LLMs' judgments with human preferences, overlooking the existence of biases and mistakes in human judgment. Furthermore, how to select suitable LLM judgments given multiple potential LLM responses remains underexplored. To address these two aforementioned issues, we propose a three-stage meta-judge selection pipeline: 1) developing a comprehensive rubric with GPT-4 and human experts, 2) using three advanced LLM agents to score judgments, and 3) applying a threshold to filter out low-scoring judgments. Compared to methods using a single LLM as both judge and meta-judge, our pipeline introduces multi-agent collaboration and a more comprehensive rubric. Experimental results on the JudgeBench dataset show about 15.55\\% improvement compared to raw judgments and about 8.37\\% improvement over the single-agent baseline. Our work demonstrates the potential of LLMs as meta-judges and lays the foundation for future research on constructing preference datasets for LLM-as-a-judge reinforcement learning.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "12 pages, 5 figures, 6 tables", "pdf_url": "https://arxiv.org/pdf/2504.17087.pdf", "abstract_url": "https://arxiv.org/abs/2504.17087", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种三阶段元评判选择流程，利用多智能体协作和全面评分标准，以提高大型语言模型（LLMs）作为评判者的效率和准确性。", "motivation": "随着任务复杂度的增加，评估LLMs的响应变得越来越困难。现有研究主要关注将LLMs的判断与人类偏好对齐，忽视了人类判断中的偏见和错误，以及如何从多个潜在的LLM响应中选择合适的判断。", "method": "提出了一个三阶段的元评判选择流程：1) 与GPT-4和人类专家共同开发全面评分标准；2) 使用三个先进的LLM智能体对判断进行评分；3) 应用阈值过滤低分判断。", "result": "在JudgeBench数据集上的实验结果显示，与原始判断相比提高了约15.55%，与单智能体基线相比提高了约8.37%。", "conclusion": "我们的工作展示了LLMs作为元评判者的潜力，并为未来研究构建LLM作为评判者的强化学习偏好数据集奠定了基础。"}}
{"id": "2504.17282", "title": "Cracking the Code of Action: a Generative Approach to Affordances for Reinforcement Learning", "authors": ["Lynn Cherif", "Flemming Kondrup", "David Venuto", "Ankit Anand", "Doina Precup", "Khimya Khetarpal"], "abstract": "Agents that can autonomously navigate the web through a graphical user interface (GUI) using a unified action space (e.g., mouse and keyboard actions) can require very large amounts of domain-specific expert demonstrations to achieve good performance. Low sample efficiency is often exacerbated in sparse-reward and large-action-space environments, such as a web GUI, where only a few actions are relevant in any given situation. In this work, we consider the low-data regime, with limited or no access to expert behavior. To enable sample-efficient learning, we explore the effect of constraining the action space through $\\textit{intent-based affordances}$ -- i.e., considering in any situation only the subset of actions that achieve a desired outcome. We propose $\\textbf{Code as Generative Affordances}$ $(\\textbf{$\\texttt{CoGA}$})$, a method that leverages pre-trained vision-language models (VLMs) to generate code that determines affordable actions through implicit intent-completion functions and using a fully-automated program generation and verification pipeline. These programs are then used in-the-loop of a reinforcement learning agent to return a set of affordances given a pixel observation. By greatly reducing the number of actions that an agent must consider, we demonstrate on a wide range of tasks in the MiniWob++ benchmark that: $\\textbf{1)}$ $\\texttt{CoGA}$ is orders of magnitude more sample efficient than its RL agent, $\\textbf{2)}$ $\\texttt{CoGA}$'s programs can generalize within a family of tasks, and $\\textbf{3)}$ $\\texttt{CoGA}$ performs better or on par compared with behavior cloning when a small number of expert demonstrations is available.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.17282.pdf", "abstract_url": "https://arxiv.org/abs/2504.17282", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为CoGA的方法，通过利用预训练的视觉语言模型生成代码来限制动作空间，从而提高强化学习在低数据环境下的样本效率。", "motivation": "解决在图形用户界面（GUI）中，由于动作空间大和奖励稀疏导致的样本效率低下的问题，特别是在专家演示有限或不可用的情况下。", "method": "使用预训练的视觉语言模型（VLMs）生成代码，通过隐式意图完成函数和全自动程序生成与验证流程，确定可行的动作子集。", "result": "在MiniWob++基准测试中，CoGA显示出比其RL代理更高的样本效率，其程序能够在任务家族内泛化，并且在少量专家演示可用时，表现与行为克隆相当或更好。", "conclusion": "CoGA通过限制动作空间显著提高了强化学习代理的样本效率，且在有限专家数据下表现优异，为自动化网页导航提供了有效的解决方案。"}}
{"id": "2504.17356", "title": "Comprehend, Divide, and Conquer: Feature Subspace Exploration via Multi-Agent Hierarchical Reinforcement Learning", "authors": ["Weiliang Zhang", "Xiaohan Huang", "Yi Du", "Ziyue Qiao", "Qingqing Long", "Zhen Meng", "Yuanchun Zhou", "Meng Xiao"], "abstract": "Feature selection aims to preprocess the target dataset, find an optimal and most streamlined feature subset, and enhance the downstream machine learning task. Among filter, wrapper, and embedded-based approaches, the reinforcement learning (RL)-based subspace exploration strategy provides a novel objective optimization-directed perspective and promising performance. Nevertheless, even with improved performance, current reinforcement learning approaches face challenges similar to conventional methods when dealing with complex datasets. These challenges stem from the inefficient paradigm of using one agent per feature and the inherent complexities present in the datasets. This observation motivates us to investigate and address the above issue and propose a novel approach, namely HRLFS. Our methodology initially employs a Large Language Model (LLM)-based hybrid state extractor to capture each feature's mathematical and semantic characteristics. Based on this information, features are clustered, facilitating the construction of hierarchical agents for each cluster and sub-cluster. Extensive experiments demonstrate the efficiency, scalability, and robustness of our approach. Compared to contemporary or the one-feature-one-agent RL-based approaches, HRLFS improves the downstream ML performance with iterative feature subspace exploration while accelerating total run time by reducing the number of agents involved.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "20 pages, keywords: Automated Feature Engineering, Tabular Dataset, Multi-Agent Reinforcement Learning, Feature Selection", "pdf_url": "https://arxiv.org/pdf/2504.17356.pdf", "abstract_url": "https://arxiv.org/abs/2504.17356", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为HRLFS的新方法，通过多智能体分层强化学习进行特征子空间探索，旨在优化特征选择过程并提升下游机器学习任务的性能。", "motivation": "当前基于强化学习的特征选择方法在处理复杂数据集时面临效率低下和挑战，主要问题在于每个特征使用一个代理的范式效率不高以及数据集本身的复杂性。", "method": "HRLFS方法首先利用基于大型语言模型（LLM）的混合状态提取器捕获每个特征的数学和语义特征，然后根据这些信息对特征进行聚类，进而为每个聚类和子聚类构建分层代理。", "result": "大量实验证明，HRLFS方法在效率、可扩展性和鲁棒性方面表现出色，与当代或一特征一代理的基于RL的方法相比，HRLFS通过减少涉及的代理数量加速了总运行时间，同时通过迭代特征子空间探索提高了下游ML性能。", "conclusion": "HRLFS提供了一种高效、可扩展且鲁棒的特征选择方法，通过分层强化学习策略优化了特征子空间的探索过程，显著提升了机器学习任务的性能。"}}
{"id": "2504.17574", "title": "RAGAT-Mind: A Multi-Granular Modeling Approach for Rumor Detection Based on MindSpore", "authors": ["Zhenkai Qin", "Guifang Yang", "Dongze Wu"], "abstract": "As false information continues to proliferate across social media platforms, effective rumor detection has emerged as a pressing challenge in natural language processing. This paper proposes RAGAT-Mind, a multi-granular modeling approach for Chinese rumor detection, built upon the MindSpore deep learning framework. The model integrates TextCNN for local semantic extraction, bidirectional GRU for sequential context learning, Multi-Head Self-Attention for global dependency focusing, and Bidirectional Graph Convolutional Networks (BiGCN) for structural representation of word co-occurrence graphs. Experiments on the Weibo1-Rumor dataset demonstrate that RAGAT-Mind achieves superior classification performance, attaining 99.2% accuracy and a macro-F1 score of 0.9919. The results validate the effectiveness of combining hierarchical linguistic features with graph-based semantic structures. Furthermore, the model exhibits strong generalization and interpretability, highlighting its practical value for real-world rumor detection applications.", "subjects": "Computation and Language (cs.CL); Computers and Society (cs.CY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.17574.pdf", "abstract_url": "https://arxiv.org/abs/2504.17574", "categories": ["Computation and Language (cs.CL)", "Computers and Society (cs.CY)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种基于MindSpore深度学习框架的多粒度建模方法RAGAT-Mind，用于中文谣言检测，结合了TextCNN、双向GRU、多头自注意力和双向图卷积网络，在微博谣言数据集上表现出色。", "motivation": "随着虚假信息在社交媒体平台上的不断扩散，有效的谣言检测成为自然语言处理中的一个紧迫挑战。", "method": "RAGAT-Mind模型整合了TextCNN用于局部语义提取，双向GRU用于序列上下文学习，多头自注意力用于全局依赖关注，以及双向图卷积网络用于词共现图的结构表示。", "result": "在Weibo1-Rumor数据集上的实验表明，RAGAT-Mind达到了99.2%的准确率和0.9919的宏观F1分数。", "conclusion": "结果验证了将分层语言特征与基于图的语义结构相结合的有效性，模型展现出强大的泛化能力和可解释性，突出了其在现实世界谣言检测应用中的实用价值。"}}
{"id": "2504.16946", "title": "MobileCity: An Efficient Framework for Large-Scale Urban Behavior Simulation", "authors": ["Xiaotong Ye", "Nicolas Bougie", "Toshihiko Yamasaki", "Narimasa Watanabe"], "abstract": "Generative agents offer promising capabilities for simulating realistic urban behaviors. However, existing methods oversimplify transportation choices in modern cities, and require prohibitive computational resources for large-scale population simulation. To address these limitations, we first present a virtual city that features multiple functional buildings and transportation modes. Then, we conduct extensive surveys to model behavioral choices and mobility preferences among population groups. Building on these insights, we introduce a simulation framework that captures the complexity of urban mobility while remaining scalable, enabling the simulation of over 4,000 agents. To assess the realism of the generated behaviors, we perform a series of micro and macro-level analyses. Beyond mere performance comparison, we explore insightful experiments, such as predicting crowd density from movement patterns and identifying trends in vehicle preferences across agent demographics.", "subjects": "Social and Information Networks (cs.SI); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.16946.pdf", "abstract_url": "https://arxiv.org/abs/2504.16946", "categories": ["Social and Information Networks (cs.SI)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为MobileCity的高效框架，用于大规模城市行为模拟，解决了现有方法在模拟现代城市交通选择时的过度简化问题，并减少了大规模人口模拟所需的计算资源。", "motivation": "现有生成代理在模拟现实城市行为时，对现代城市交通选择的模拟过于简化，且大规模人口模拟需要极高的计算资源。", "method": "首先构建了一个具有多种功能建筑和交通方式的虚拟城市，然后通过广泛调查模拟人口群体的行为选择和移动偏好，在此基础上引入了一个既捕捉城市移动复杂性又可扩展的模拟框架。", "result": "该框架能够模拟超过4,000个代理，通过一系列微观和宏观层面的分析评估了生成行为的真实性，并进行了如从移动模式预测人群密度和识别不同代理人口统计中车辆偏好趋势等有洞察力的实验。", "conclusion": "MobileCity框架在保持城市移动复杂性的同时，实现了大规模城市行为的高效模拟，为城市规划和行为研究提供了有价值的工具。"}}
{"id": "2504.16947", "title": "SCRAG: Social Computing-Based Retrieval Augmented Generation for Community Response Forecasting in Social Media Environments", "authors": ["Dachun Sun", "You Lyu", "Jinning Li", "Yizhuo Chen", "Tianshi Wang", "Tomoyoshi Kimura", "Tarek Abdelzaher"], "abstract": "This paper introduces SCRAG, a prediction framework inspired by social computing, designed to forecast community responses to real or hypothetical social media posts. SCRAG can be used by public relations specialists (e.g., to craft messaging in ways that avoid unintended misinterpretations) or public figures and influencers (e.g., to anticipate social responses), among other applications related to public sentiment prediction, crisis management, and social what-if analysis. While large language models (LLMs) have achieved remarkable success in generating coherent and contextually rich text, their reliance on static training data and susceptibility to hallucinations limit their effectiveness at response forecasting in dynamic social media environments. SCRAG overcomes these challenges by integrating LLMs with a Retrieval-Augmented Generation (RAG) technique rooted in social computing. Specifically, our framework retrieves (i) historical responses from the target community to capture their ideological, semantic, and emotional makeup, and (ii) external knowledge from sources such as news articles to inject time-sensitive context. This information is then jointly used to forecast the responses of the target community to new posts or narratives. Extensive experiments across six scenarios on the X platform (formerly Twitter), tested with various embedding models and LLMs, demonstrate over 10% improvements on average in key evaluation metrics. A concrete example further shows its effectiveness in capturing diverse ideologies and nuances. Our work provides a social computing tool for applications where accurate and concrete insights into community responses are crucial.", "subjects": "Social and Information Networks (cs.SI); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.16947.pdf", "abstract_url": "https://arxiv.org/abs/2504.16947", "categories": ["Social and Information Networks (cs.SI)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了SCRAG，一个受社会计算启发的预测框架，旨在预测社区对真实或假设社交媒体帖子的反应。SCRAG通过整合大型语言模型（LLMs）与基于社会计算的检索增强生成（RAG）技术，克服了LLMs在动态社交媒体环境中预测反应的局限性。", "motivation": "解决大型语言模型（LLMs）在动态社交媒体环境中预测社区反应时因依赖静态训练数据和易产生幻觉而受限的问题。", "method": "整合LLMs与基于社会计算的RAG技术，检索目标社区的历史反应和外部知识（如新闻文章），以预测社区对新帖子或叙述的反应。", "result": "在X平台（原Twitter）上的六种场景中进行广泛实验，使用不同的嵌入模型和LLMs，关键评估指标平均提高了10%以上。", "conclusion": "SCRAG为需要准确和具体洞察社区反应的应用提供了一个社会计算工具，展示了在捕捉多样意识形态和细微差别方面的有效性。"}}
{"id": "2504.17129", "title": "Peer-Aware Cost Estimation in Nonlinear General-Sum Dynamic Games for Mutual Learning and Intent Inference", "authors": ["Seyed Yousef Soltanian", "Wenlong Zhang"], "abstract": "Human-robot interactions can be modeled as incomplete-information general-sum dynamic games since the objective functions of both agents are not explicitly known to each other. However, solving for equilibrium policies for such games presents a major challenge, especially if the games involve nonlinear underlying dynamics. To simplify the problem, existing work often assumes that one agent is an expert with complete information about its peer, which can lead to biased estimates and failures in coordination. To address this challenge, we propose a nonlinear peer-aware cost estimation (N-PACE) algorithm for general-sum dynamic games. In N-PACE, using iterative linear quadratic (LQ) approximation of the nonlinear general-sum game, each agent explicitly models the learning dynamics of its peer agent while inferring their objective functions, leading to unbiased fast learning in inferring the unknown objective function of the peer agent, which is critical for task completion and safety assurance. Additionally, we demonstrate how N-PACE enables \\textbf{intent communication} in such multi-agent systems by explicitly modeling the peer's learning dynamics.", "subjects": "Systems and Control (eess.SY); Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.17129.pdf", "abstract_url": "https://arxiv.org/abs/2504.17129", "categories": ["Systems and Control (eess.SY)", "Artificial Intelligence (cs.AI)", "Computer Science and Game Theory (cs.GT)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种非线性同伴感知成本估计算法（N-PACE），用于解决不完全信息一般和动态游戏中的人类-机器人交互问题，通过迭代线性二次近似和显式建模同伴的学习动态，实现了对同伴未知目标函数的无偏快速学习。", "motivation": "解决在不完全信息一般和动态游戏中，由于假设一个代理是完全信息的专家而导致的估计偏差和协调失败问题。", "method": "使用迭代线性二次（LQ）近似非线性一般和游戏，每个代理显式建模其同伴代理的学习动态，同时推断其目标函数。", "result": "N-PACE算法能够实现对同伴未知目标函数的无偏快速学习，这对于任务完成和安全保证至关重要，并且支持多代理系统中的意图通信。", "conclusion": "N-PACE算法通过显式建模同伴的学习动态，不仅提高了在不完全信息一般和动态游戏中的学习效率和协调能力，还支持了意图通信，为人类-机器人交互提供了新的解决方案。"}}
{"id": "2504.17355", "title": "Collaborative Multi-Agent Reinforcement Learning for Automated Feature Transformation with Graph-Driven Path Optimization", "authors": ["Xiaohan Huang", "Dongjie Wang", "Zhiyuan Ning", "Ziyue Qiao", "Qingqing Long", "Haowei Zhu", "Yi Du", "Min Wu", "Yuanchun Zhou", "Meng Xiao"], "abstract": "Feature transformation methods aim to find an optimal mathematical feature-feature crossing process that generates high-value features and improves the performance of downstream machine learning tasks. Existing frameworks, though designed to mitigate manual costs, often treat feature transformations as isolated operations, ignoring dynamic dependencies between transformation steps. To address the limitations, we propose TCTO, a collaborative multi-agent reinforcement learning framework that automates feature engineering through graph-driven path optimization. The framework's core innovation lies in an evolving interaction graph that models features as nodes and transformations as edges. Through graph pruning and backtracking, it dynamically eliminates low-impact edges, reduces redundant operations, and enhances exploration stability. This graph also provides full traceability to empower TCTO to reuse high-utility subgraphs from historical transformations. To demonstrate the efficacy and adaptability of our approach, we conduct comprehensive experiments and case studies, which show superior performance across a range of datasets.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "13 pages, Keywords: Automated Feature Transformation, Tabular Dataset, Reinforcement Learning", "pdf_url": "https://arxiv.org/pdf/2504.17355.pdf", "abstract_url": "https://arxiv.org/abs/2504.17355", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为TCTO的协作多智能体强化学习框架，用于通过图驱动的路径优化自动化特征工程。该框架通过演化交互图动态优化特征转换过程，提高了下游机器学习任务的性能。", "motivation": "现有的特征转换方法往往将特征转换视为孤立操作，忽略了转换步骤之间的动态依赖关系，这限制了特征工程的效率和效果。", "method": "TCTO框架利用协作多智能体强化学习，通过图驱动的路径优化自动化特征工程。其核心创新是一个演化交互图，该图将特征建模为节点，转换建模为边，并通过图剪枝和回溯动态优化转换路径。", "result": "实验和案例研究表明，TCTO框架在多种数据集上表现出 superior performance，能够有效减少冗余操作并提高探索稳定性。", "conclusion": "TCTO框架通过图驱动的路径优化和协作多智能体强化学习，自动化了特征工程，提高了特征转换的效率和效果，为下游机器学习任务提供了更高质量的特征。"}}
{"id": "2504.17490", "title": "Plasticine: Accelerating Research in Plasticity-Motivated Deep Reinforcement Learning", "authors": ["Mingqi Yuan", "Qi Wang", "Guozheng Ma", "Bo Li", "Xin Jin", "Yunbo Wang", "Xiaokang Yang", "Wenjun Zeng", "Dacheng Tao"], "abstract": "Developing lifelong learning agents is crucial for artificial general intelligence. However, deep reinforcement learning (RL) systems often suffer from plasticity loss, where neural networks gradually lose their ability to adapt during training. Despite its significance, this field lacks unified benchmarks and evaluation protocols. We introduce Plasticine, the first open-source framework for benchmarking plasticity optimization in deep RL. Plasticine provides single-file implementations of over 13 mitigation methods, 10 evaluation metrics, and learning scenarios with increasing non-stationarity levels from standard to open-ended environments. This framework enables researchers to systematically quantify plasticity loss, evaluate mitigation strategies, and analyze plasticity dynamics across different contexts. Our documentation, examples, and source code are available at", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "23 pages", "pdf_url": "https://arxiv.org/pdf/2504.17490.pdf", "abstract_url": "https://arxiv.org/abs/2504.17490", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "Plasticine是首个用于深度强化学习(RL)中可塑性优化的开源框架，旨在解决神经网络在训练过程中逐渐失去适应能力的可塑性损失问题。它提供了13种缓解方法、10种评估指标以及从标准到开放式环境的不同非平稳性水平的学习场景的单文件实现。", "motivation": "开发终身学习代理对于人工智能通用智能至关重要，但深度强化学习系统经常遭受可塑性损失的问题，即神经网络在训练过程中逐渐失去适应能力。这一领域缺乏统一的基准和评估协议。", "method": "引入了Plasticine，这是一个开源框架，用于在深度RL中基准测试可塑性优化。它提供了超过13种缓解方法、10种评估指标以及不同非平稳性水平的学习场景的单文件实现。", "result": "Plasticine框架使研究人员能够系统地量化可塑性损失，评估缓解策略，并分析不同背景下的可塑性动态。", "conclusion": "Plasticine为可塑性优化的研究提供了一个系统化的工具，有助于推动终身学习代理的发展，并为解决深度RL中的可塑性损失问题提供了新的研究方向。"}}
{"id": "2504.17669", "title": "Towards a HIPAA Compliant Agentic AI System in Healthcare", "authors": ["Subash Neupane", "Shaswata Mitra", "Sudip Mittal", "Shahram Rahimi"], "abstract": "Agentic AI systems powered by Large Language Models (LLMs) as their foundational reasoning engine, are transforming clinical workflows such as medical report generation and clinical summarization by autonomously analyzing sensitive healthcare data and executing decisions with minimal human oversight. However, their adoption demands strict compliance with regulatory frameworks such as Health Insurance Portability and Accountability Act (HIPAA), particularly when handling Protected Health Information (PHI). This work-in-progress paper introduces a HIPAA-compliant Agentic AI framework that enforces regulatory compliance through dynamic, context-aware policy enforcement. Our framework integrates three core mechanisms: (1) Attribute-Based Access Control (ABAC) for granular PHI governance, (2) a hybrid PHI sanitization pipeline combining regex patterns and BERT-based model to minimize leakage, and (3) immutable audit trails for compliance verification.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.17669.pdf", "abstract_url": "https://arxiv.org/abs/2504.17669", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Emerging Technologies (cs.ET)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "介绍了一个符合HIPAA标准的Agentic AI框架，旨在通过动态、上下文感知的策略执行来确保处理敏感医疗数据时的合规性。", "motivation": "解决Agentic AI系统在处理受保护健康信息(PHI)时如何严格遵守HIPAA等法规框架的问题。", "method": "集成了三个核心机制：基于属性的访问控制(ABAC)用于细粒度PHI治理，结合正则表达式模式和基于BERT模型的混合PHI清理管道以减少泄露，以及不可变的审计跟踪用于合规性验证。", "result": "提出了一个工作进展中的框架，展示了如何通过技术手段实现HIPAA合规的Agentic AI系统。", "conclusion": "该框架为在医疗保健领域安全、合规地部署Agentic AI系统提供了可行的解决方案，强调了技术集成在满足法规要求中的重要性。"}}
