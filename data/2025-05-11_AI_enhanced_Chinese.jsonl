{"id": "2505.04921", "title": "Perception, Reason, Think, and Plan: A Survey on Large Multimodal Reasoning Models", "authors": ["Yunxin Li", "Zhenyu Liu", "Zitao Li", "Xuanyu Zhang", "Zhenran Xu", "Xinyu Chen", "Haoyuan Shi", "Shenyuan Jiang", "Xintong Wang", "Jifang Wang", "Shouzheng Huang", "Xinping Zhao", "Borui Jiang", "Lanqing Hong", "Longyue Wang", "Zhuotao Tian", "Baoxing Huai", "Wenhan Luo", "Weihua Luo", "Zheng Zhang", "Baotian Hu", "Min Zhang"], "abstract": "Reasoning lies at the heart of intelligence, shaping the ability to make decisions, draw conclusions, and generalize across domains. In artificial intelligence, as systems increasingly operate in open, uncertain, and multimodal environments, reasoning becomes essential for enabling robust and adaptive behavior. Large Multimodal Reasoning Models (LMRMs) have emerged as a promising paradigm, integrating modalities such as text, images, audio, and video to support complex reasoning capabilities and aiming to achieve comprehensive perception, precise understanding, and deep reasoning. As research advances, multimodal reasoning has rapidly evolved from modular, perception-driven pipelines to unified, language-centric frameworks that offer more coherent cross-modal understanding. While instruction tuning and reinforcement learning have improved model reasoning, significant challenges remain in omni-modal generalization, reasoning depth, and agentic behavior. To address these issues, we present a comprehensive and structured survey of multimodal reasoning research, organized around a four-stage developmental roadmap that reflects the field's shifting design philosophies and emerging capabilities. First, we review early efforts based on task-specific modules, where reasoning was implicitly embedded across stages of representation, alignment, and fusion. Next, we examine recent approaches that unify reasoning into multimodal LLMs, with advances such as Multimodal Chain-of-Thought (MCoT) and multimodal reinforcement learning enabling richer and more structured reasoning chains. Finally, drawing on empirical insights from challenging benchmarks and experimental cases of OpenAI O3 and O4-mini, we discuss the conceptual direction of native large multimodal reasoning models (N-LMRMs), which aim to support scalable, agentic, and adaptive reasoning and planning in complex, real-world environments.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.04921.pdf", "abstract_url": "https://arxiv.org/abs/2505.04921", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文综述了大型多模态推理模型（LMRMs）的发展，探讨了从模块化、感知驱动的管道到统一、以语言为中心的框架的演变，以及指令调整和强化学习在提升模型推理能力方面的作用。", "motivation": "解决在多模态开放和不确定环境中实现鲁棒和自适应行为所需的推理能力问题。", "method": "通过四阶段发展路线图，回顾了从任务特定模块到统一多模态LLMs的演进，包括多模态思维链（MCoT）和多模态强化学习的进展。", "result": "指出了在全模态泛化、推理深度和代理行为方面的挑战，并提出了原生大型多模态推理模型（N-LMRMs）的概念方向。", "conclusion": "N-LMRMs旨在支持复杂现实环境中的可扩展、代理和自适应推理与规划，代表了多模态推理研究的未来方向。"}}
{"id": "2505.04769", "title": "Vision-Language-Action Models: Concepts, Progress, Applications and Challenges", "authors": ["Ranjan Sapkota", "Yang Cao", "Konstantinos I. Roumeliotis", "Manoj Karkee"], "abstract": "Vision-Language-Action (VLA) models mark a transformative advancement in artificial intelligence, aiming to unify perception, natural language understanding, and embodied action within a single computational framework. This foundational review presents a comprehensive synthesis of recent advancements in Vision-Language-Action models, systematically organized across five thematic pillars that structure the landscape of this rapidly evolving field. We begin by establishing the conceptual foundations of VLA systems, tracing their evolution from cross-modal learning architectures to generalist agents that tightly integrate vision-language models (VLMs), action planners, and hierarchical controllers. Our methodology adopts a rigorous literature review framework, covering over 80 VLA models published in the past three years. Key progress areas include architectural innovations, parameter-efficient training strategies, and real-time inference accelerations. We explore diverse application domains such as humanoid robotics, autonomous vehicles, medical and industrial robotics, precision agriculture, and augmented reality navigation. The review further addresses major challenges across real-time control, multimodal action representation, system scalability, generalization to unseen tasks, and ethical deployment risks. Drawing from the state-of-the-art, we propose targeted solutions including agentic AI adaptation, cross-embodiment generalization, and unified neuro-symbolic planning. In our forward-looking discussion, we outline a future roadmap where VLA models, VLMs, and agentic AI converge to power socially aligned, adaptive, and general-purpose embodied agents. This work serves as a foundational reference for advancing intelligent, real-world robotics and artificial general intelligence. >Vision-language-action, Agentic AI, AI Agents, Vision-language Models", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "36 pages, 18 Figures, 4 Tables", "pdf_url": "https://arxiv.org/pdf/2505.04769.pdf", "abstract_url": "https://arxiv.org/abs/2505.04769", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "视觉-语言-动作（VLA）模型代表了人工智能领域的一项变革性进步，旨在将感知、自然语言理解和具体行动统一在一个计算框架内。本文综述了VLA模型的最新进展，包括其概念基础、架构创新、应用领域及面临的挑战，并提出了未来发展方向。", "motivation": "解决如何将视觉、语言理解和具体行动统一在一个计算框架内，以推动智能机器人和通用人工智能的发展。", "method": "采用严格的文献综述框架，覆盖了过去三年发表的80多个VLA模型，系统地组织了这一快速发展的领域的五个主题支柱。", "result": "识别了VLA模型在架构创新、参数高效训练策略和实时推理加速等关键进展领域，以及在人形机器人、自动驾驶汽车等多个应用领域的应用。", "conclusion": "提出了包括代理AI适应、跨体现泛化和统一的神经符号规划在内的针对性解决方案，并展望了VLA模型、视觉语言模型和代理AI融合的未来路线图，以推动社会对齐、自适应和通用目的的体现代理的发展。"}}
{"id": "2505.04965", "title": "DenseGrounding: Improving Dense Language-Vision Semantics for Ego-Centric 3D Visual Grounding", "authors": ["Henry Zheng", "Hao Shi", "Qihang Peng", "Yong Xien Chng", "Rui Huang", "Yepeng Weng", "Zhongchao Shi", "Gao Huang"], "abstract": "Enabling intelligent agents to comprehend and interact with 3D environments through natural language is crucial for advancing robotics and human-computer interaction. A fundamental task in this field is ego-centric 3D visual grounding, where agents locate target objects in real-world 3D spaces based on verbal descriptions. However, this task faces two significant challenges: (1) loss of fine-grained visual semantics due to sparse fusion of point clouds with ego-centric multi-view images, (2) limited textual semantic context due to arbitrary language descriptions. We propose DenseGrounding, a novel approach designed to address these issues by enhancing both visual and textual semantics. For visual features, we introduce the Hierarchical Scene Semantic Enhancer, which retains dense semantics by capturing fine-grained global scene features and facilitating cross-modal alignment. For text descriptions, we propose a Language Semantic Enhancer that leverages large language models to provide rich context and diverse language descriptions with additional context during model training. Extensive experiments show that DenseGrounding significantly outperforms existing methods in overall accuracy, with improvements of 5.81% and 7.56% when trained on the comprehensive full dataset and smaller mini subset, respectively, further advancing the SOTA in egocentric 3D visual grounding. Our method also achieves 1st place and receives the Innovation Award in the CVPR 2024 Autonomous Grand Challenge Multi-view 3D Visual Grounding Track, validating its effectiveness and robustness.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "Accepted by ICLR 2025", "pdf_url": "https://arxiv.org/pdf/2505.04965.pdf", "abstract_url": "https://arxiv.org/abs/2505.04965", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "DenseGrounding是一种新颖的方法，旨在通过增强视觉和文本语义来解决以自我为中心的3D视觉接地任务中的挑战，显著提高了准确性并在CVPR 2024挑战赛中获得了第一名和创新奖。", "motivation": "解决智能代理在3D环境中通过自然语言理解和交互的两个主要挑战：由于点云与自我中心多视图图像的稀疏融合导致的细粒度视觉语义丢失，以及由于任意语言描述导致的有限文本语义上下文。", "method": "提出了DenseGrounding方法，包括视觉特征的层次场景语义增强器（Hierarchical Scene Semantic Enhancer）和文本描述的语言语义增强器（Language Semantic Enhancer），前者保留密集语义，后者利用大型语言模型提供丰富的上下文和多样化的语言描述。", "result": "在全面数据集和较小迷你子集上训练时，DenseGrounding的整体准确性分别提高了5.81%和7.56%，在CVPR 2024自主大赛多视图3D视觉接地赛道中获得第一名和创新奖。", "conclusion": "DenseGrounding通过增强视觉和文本语义，显著提高了以自我为中心的3D视觉接地的性能，验证了其有效性和鲁棒性，为机器人和人机交互领域的进步提供了重要支持。"}}
{"id": "2505.04638", "title": "Towards Artificial Intelligence Research Assistant for Expert-Involved Learning", "authors": ["Tianyu Liu", "Simeng Han", "Xiao Luo", "Hanchen Wang", "Pan Lu", "Biqing Zhu", "Yuge Wang", "Keyi Li", "Jiapeng Chen", "Rihao Qu", "Yufeng Liu", "Xinyue Cui", "Aviv Yaish", "Yuhang Chen", "Minsheng Hao", "Chuhan Li", "Kexing Li", "Arman Cohan", "Hua Xu", "Mark Gerstein", "James Zou", "Hongyu Zhao"], "abstract": "Large Language Models (LLMs) and Large Multi-Modal Models (LMMs) have emerged as transformative tools in scientific research, yet their reliability and specific contributions to biomedical applications remain insufficiently characterized. In this study, we present \\textbf{AR}tificial \\textbf{I}ntelligence research assistant for \\textbf{E}xpert-involved \\textbf{L}earning (ARIEL), a multimodal dataset designed to benchmark and enhance two critical capabilities of LLMs and LMMs in biomedical research: summarizing extensive scientific texts and interpreting complex biomedical figures. To facilitate rigorous assessment, we create two open-source sets comprising biomedical articles and figures with designed questions. We systematically benchmark both open- and closed-source foundation models, incorporating expert-driven human evaluations conducted by doctoral-level experts. Furthermore, we improve model performance through targeted prompt engineering and fine-tuning strategies for summarizing research papers, and apply test-time computational scaling to enhance the reasoning capabilities of LMMs, achieving superior accuracy compared to human-expert corrections. We also explore the potential of using LMM Agents to generate scientific hypotheses from diverse multimodal inputs. Overall, our results delineate clear strengths and highlight significant limitations of current foundation models, providing actionable insights and guiding future advancements in deploying large-scale language and multi-modal models within biomedical research.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Information Retrieval (cs.IR)", "comments": "36 pages, 7 figures", "pdf_url": "https://arxiv.org/pdf/2505.04638.pdf", "abstract_url": "https://arxiv.org/abs/2505.04638", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Information Retrieval (cs.IR)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了ARIEL，一个多模态数据集，旨在评估和提升大型语言模型和多模态模型在生物医学研究中的两大关键能力：总结科学文本和解释复杂生物医学图表。通过专家驱动的人类评估和模型优化策略，研究展示了当前基础模型的优势和局限。", "motivation": "大型语言模型和多模态模型在科学研究中的可靠性和对生物医学应用的具体贡献尚未充分表征。", "method": "创建了两个开源数据集，包含生物医学文章和图表，并设计了问题。系统地评估了开源和闭源的基础模型，结合了博士级专家的评估。通过提示工程和微调策略优化模型性能，并应用测试时计算扩展提升多模态模型的推理能力。", "result": "研究结果明确了当前基础模型的明显优势和显著局限，为在生物医学研究中部署大规模语言和多模态模型提供了可操作的见解和未来发展的指导。", "conclusion": "ARIEL数据集和研究成果为未来在生物医学研究中更有效地利用大型语言和多模态模型奠定了基础，同时指出了需要进一步改进的方向。"}}
{"id": "2505.04628", "title": "How Social is It? A Benchmark for LLMs' Capabilities in Multi-user Multi-turn Social Agent Tasks", "authors": ["Yusen Wu", "Junwu Xiong", "Xiaotie Deng"], "abstract": "Expanding the application of large language models (LLMs) to societal life, instead of primary function only as auxiliary assistants to communicate with only one person at a time, necessitates LLMs' capabilities to independently play roles in multi-user, multi-turn social agent tasks within complex social settings. However, currently the capability has not been systematically measured with available benchmarks. To address this gap, we first introduce an agent task leveling framework grounded in sociological principles. Concurrently, we propose a novel benchmark, How Social Is It (we call it HSII below), designed to assess LLM's social capabilities in comprehensive social agents tasks and benchmark representative models. HSII comprises four stages: format parsing, target selection, target switching conversation, and stable conversation, which collectively evaluate the communication and task completion capabilities of LLMs within realistic social interaction scenarios dataset, HSII-Dataset. The dataset is derived step by step from news dataset. We perform an ablation study by doing clustering to the dataset. Additionally, we investigate the impact of chain of thought (COT) method on enhancing LLMs' social performance. Since COT cost more computation, we further introduce a new statistical metric, COT-complexity, to quantify the efficiency of certain LLMs with COTs for specific social tasks and strike a better trade-off between measurement of correctness and efficiency. Various results of our experiments demonstrate that our benchmark is well-suited for evaluating social skills in LLMs.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.04628.pdf", "abstract_url": "https://arxiv.org/abs/2505.04628", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Social and Information Networks (cs.SI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了HSII基准，用于评估大型语言模型（LLMs）在多用户多轮社交代理任务中的社交能力，包括格式解析、目标选择、目标切换对话和稳定对话四个阶段，并提出了COT-complexity新统计指标以平衡正确性和效率。", "motivation": "当前缺乏系统性衡量LLMs在复杂社交环境中独立扮演角色能力的基准，本文旨在填补这一空白。", "method": "提出基于社会学原理的代理任务分级框架和HSII基准，包括四个评估阶段，并使用HSII-Dataset进行实验，包括消融研究和COT方法的影响研究。", "result": "实验结果表明，HSII基准能有效评估LLMs的社交技能，COT方法虽能提升性能但增加计算成本，COT-complexity指标有助于平衡正确性和效率。", "conclusion": "HSII基准适用于评估LLMs的社交能力，为未来研究提供了新的评估工具和方法。"}}
{"id": "2505.04646", "title": "Computational Irreducibility as the Foundation of Agency: A Formal Model Connecting Undecidability to Autonomous Behavior in Complex Systems", "authors": ["Poria Azadi"], "abstract": "This article explores the emergence of autonomy and agency by connecting fundamental computational limits (decidability, completeness, computational irreducibility) with physical concepts. We introduce a formal model of a \"minimal agent\" operating within potentially Turing-complete environments. Using algorithmic information theory, we argue that the inherent undecidability and computational irreducibility of agent-environment interaction lead to unpredictability and novel information generation, enabling agency (effective goal-directed action). Computational irreducibility prevents full external prediction, creating necessary conditions for autonomous behavior. We relate this to computational sourcehood, where an agent is the irreducible origin of its behavior, though formalizing this concept remains challenging. Our central thesis, formally proven, is that genuine autonomy necessarily implies undecidability from an external perspective, distinguishing autonomous systems from predictable ones. We propose that agency arises when agent-environment coupling complexity allows mutual information between internal states and relevant environmental variables to increase, particularly where analytical solutions are absent and operational closure is needed for persistence. This framework links agency directly to the computational properties of interaction, offering implications for understanding consciousness, designing autonomous AI, and reconceptualizing free will in a deterministic yet computationally irreducible universe.", "subjects": "Artificial Intelligence (cs.AI); Computational Complexity (cs.CC); Information Theory (cs.IT)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.04646.pdf", "abstract_url": "https://arxiv.org/abs/2505.04646", "categories": ["Artificial Intelligence (cs.AI)", "Computational Complexity (cs.CC)", "Information Theory (cs.IT)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过将基本计算限制（可判定性、完备性、计算不可约性）与物理概念联系起来，探讨了自主性和代理性的出现。我们引入了一个在潜在图灵完备环境中操作的“最小代理”的形式模型。使用算法信息理论，我们认为代理-环境交互的固有不可判定性和计算不可约性导致不可预测性和新信息生成，从而实现了代理性（有效的目标导向行动）。计算不可约性阻止了完全的外部预测，为自主行为创造了必要条件。我们将这与计算源联系起来，其中代理是其行为的不可约起源，尽管形式化这一概念仍然具有挑战性。我们的中心论点，正式证明，真正的自主性必然意味着从外部视角看是不可判定的，将自主系统与可预测系统区分开来。我们提出，当代理-环境耦合复杂性允许内部状态与相关环境变量之间的互信息增加时，特别是在分析解决方案缺失且需要操作闭合以保持持久性的情况下，代理性就会出现。这一框架将代理性直接与交互的计算属性联系起来，为理解意识、设计自主AI以及在确定但计算不可约的宇宙中重新构想自由意志提供了启示。", "motivation": "探索自主性和代理性如何从基本计算限制和物理概念中涌现，以及这些概念如何与复杂系统中的自主行为相关联。", "method": "引入了一个形式模型“最小代理”，并使用算法信息理论来分析代理-环境交互的不可判定性和计算不可约性。", "result": "证明了真正的自主性必然意味着从外部视角看是不可判定的，并且代理性在代理-环境耦合复杂性允许内部状态与相关环境变量之间的互信息增加时出现。", "conclusion": "这一框架将代理性直接与交互的计算属性联系起来，为理解意识、设计自主AI以及在确定但计算不可约的宇宙中重新构想自由意志提供了新的视角。"}}
{"id": "2505.04843", "title": "Large Language Models are Autonomous Cyber Defenders", "authors": ["Sebastián R. Castro", "Roberto Campbell", "Nancy Lau", "Octavio Villalobos", "Jiaqi Duan", "Alvaro A. Cardenas"], "abstract": "Fast and effective incident response is essential to prevent adversarial cyberattacks. Autonomous Cyber Defense (ACD) aims to automate incident response through Artificial Intelligence (AI) agents that plan and execute actions. Most ACD approaches focus on single-agent scenarios and leverage Reinforcement Learning (RL). However, ACD RL-trained agents depend on costly training, and their reasoning is not always explainable or transferable. Large Language Models (LLMs) can address these concerns by providing explainable actions in general security contexts. Researchers have explored LLM agents for ACD but have not evaluated them on multi-agent scenarios or interacting with other ACD agents. In this paper, we show the first study on how LLMs perform in multi-agent ACD environments by proposing a new integration to the CybORG CAGE 4 environment. We examine how ACD teams of LLM and RL agents can interact by proposing a novel communication protocol. Our results highlight the strengths and weaknesses of LLMs and RL and help us identify promising research directions to create, train, and deploy future teams of ACD agents.", "subjects": "Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)", "comments": "Presented at IEEE CAI Workshop on Adaptive Cyber Defense 2025. Proceedings to appear", "pdf_url": "https://arxiv.org/pdf/2505.04843.pdf", "abstract_url": "https://arxiv.org/abs/2505.04843", "categories": ["Artificial Intelligence (cs.AI)", "Cryptography and Security (cs.CR)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究了大型语言模型（LLMs）在多代理自主网络防御（ACD）环境中的表现，提出了与CybORG CAGE 4环境的新集成，并探讨了LLM和强化学习（RL）代理团队的互动方式。", "motivation": "解决自主网络防御（ACD）中单代理场景的局限性，以及RL训练代理的高成本和不可解释性问题。", "method": "提出了一种新的通信协议，用于LLM和RL代理在多代理ACD环境中的互动，并在CybORG CAGE 4环境中进行了评估。", "result": "研究结果突出了LLMs和RL的优势和弱点，为未来ACD代理团队的创建、训练和部署指明了研究方向。", "conclusion": "LLMs在多代理ACD环境中展现出潜力，但仍需进一步研究以优化其性能和交互能力。"}}
{"id": "2505.04927", "title": "Belief Filtering for Epistemic Control in Linguistic State Space", "authors": ["Sebastian Dumbrava"], "abstract": "We examine belief filtering as a mechanism for the epistemic control of artificial agents, focusing on the regulation of internal cognitive states represented as linguistic expressions. This mechanism is developed within the Semantic Manifold framework, where belief states are dynamic, structured ensembles of natural language fragments. Belief filters act as content-aware operations on these fragments across various cognitive transitions. This paper illustrates how the inherent interpretability and modularity of such a linguistically-grounded cognitive architecture directly enable belief filtering, offering a principled approach to agent regulation. The study highlights the potential for enhancing AI safety and alignment through structured interventions in an agent's internal semantic space and points to new directions for architecturally embedded cognitive governance.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "18 pages", "pdf_url": "https://arxiv.org/pdf/2505.04927.pdf", "abstract_url": "https://arxiv.org/abs/2505.04927", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了信念过滤作为一种机制，用于人工代理的认知控制，特别是在调节以语言表达为内部认知状态的情况下。该机制在语义流形框架内开发，其中信念状态是自然语言片段的动态、结构化集合。信念过滤器作为对这些片段的内容感知操作，在各种认知转换中发挥作用。", "motivation": "解决如何通过结构化干预增强AI的安全性和对齐性，以及在代理的内部语义空间中实现认知治理的问题。", "method": "在语义流形框架内开发信念过滤机制，对自然语言片段进行内容感知操作。", "result": "研究表明，基于语言的认知架构的固有可解释性和模块化直接支持信念过滤，为代理调节提供了原则性方法。", "conclusion": "通过结构化干预代理的内部语义空间，可以增强AI的安全性和对齐性，为认知治理的架构嵌入指明了新方向。"}}
{"id": "2505.04997", "title": "Foam-Agent: Towards Automated Intelligent CFD Workflows", "authors": ["Ling Yue", "Nithin Somasekharan", "Yadi Cao", "Shaowu Pan"], "abstract": "Computational Fluid Dynamics (CFD) is an essential simulation tool in various engineering disciplines, but it often requires substantial domain expertise and manual configuration, creating barriers to entry. We present Foam-Agent, a multi-agent framework that automates complex OpenFOAM-based CFD simulation workflows from natural language inputs. Our innovation includes (1) a hierarchical multi-index retrieval system with specialized indices for different simulation aspects, (2) a dependency-aware file generation system that provides consistency management across configuration files, and (3) an iterative error correction mechanism that diagnoses and resolves simulation failures without human intervention. Through comprehensive evaluation on the dataset of 110 simulation tasks, Foam-Agent achieves an 83.6% success rate with Claude 3.5 Sonnet, significantly outperforming existing frameworks (55.5% for MetaOpenFOAM and 37.3% for OpenFOAM-GPT). Ablation studies demonstrate the critical contribution of each system component, with the specialized error correction mechanism providing a 36.4% performance improvement. Foam-Agent substantially lowers the CFD expertise threshold while maintaining modeling accuracy, demonstrating the potential of specialized multi-agent systems to democratize access to complex scientific simulation tools. The code is public at", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.04997.pdf", "abstract_url": "https://arxiv.org/abs/2505.04997", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了Foam-Agent，一个多智能体框架，旨在通过自然语言输入自动化复杂的基于OpenFOAM的CFD模拟工作流程，显著降低了CFD的专业门槛。", "motivation": "计算流体动力学(CFD)是工程学科中重要的模拟工具，但其需要大量的领域专业知识和手动配置，形成了进入壁垒。", "method": "Foam-Agent采用了(1)分层多索引检索系统，(2)依赖感知的文件生成系统，以及(3)迭代错误校正机制，来自动化和优化CFD模拟工作流程。", "result": "在110个模拟任务的数据集上，Foam-Agent以83.6%的成功率显著优于现有框架（MetaOpenFOAM为55.5%，OpenFOAM-GPT为37.3%），错误校正机制提供了36.4%的性能提升。", "conclusion": "Foam-Agent在保持建模准确性的同时，显著降低了CFD的专业门槛，展示了专门的多智能体系统在普及复杂科学模拟工具方面的潜力。"}}
{"id": "2505.05029", "title": "A Reputation System for Large Language Model-based Multi-agent Systems to Avoid the Tragedy of the Commons", "authors": ["Siyue Ren", "Wanli Fu", "Xinkun Zou", "Chen Shen", "Yi Cai", "Chen Chu", "Zhen Wang", "Shuyue Hu"], "abstract": "The tragedy of the commons, where individual self-interest leads to collectively disastrous outcomes, is a pervasive challenge in human society. Recent studies have demonstrated that similar phenomena can arise in generative multi-agent systems (MASs). To address this challenge, this paper explores the use of reputation systems as a remedy. We propose RepuNet, a dynamic, dual-level reputation framework that models both agent-level reputation dynamics and system-level network evolution. Specifically, driven by direct interactions and indirect gossip, agents form reputations for both themselves and their peers, and decide whether to connect or disconnect other agents for future interactions. Through two distinct scenarios, we show that RepuNet effectively mitigates the 'tragedy of the commons', promoting and sustaining cooperation in generative MASs. Moreover, we find that reputation systems can give rise to rich emergent behaviors in generative MASs, such as the formation of cooperative clusters, the social isolation of exploitative agents, and the preference for sharing positive gossip rather than negative ones.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.05029.pdf", "abstract_url": "https://arxiv.org/abs/2505.05029", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出RepuNet，一个动态的双层声誉框架，旨在解决生成式多智能体系统中的'公地悲剧'问题。通过直接互动和间接八卦，智能体形成对自己和同行的声誉，并决定是否连接或断开其他智能体以进行未来互动。研究表明，RepuNet有效促进了合作，并观察到了丰富的涌现行为。", "motivation": "解决生成式多智能体系统中因个体自利行为导致的集体灾难性后果，即'公地悲剧'问题。", "method": "提出RepuNet，一个动态的双层声誉框架，包括智能体级声誉动态和系统级网络演化。", "result": "RepuNet有效缓解了'公地悲剧'，促进了生成式多智能体系统中的合作，并观察到了如合作集群形成、剥削性智能体的社会隔离等涌现行为。", "conclusion": "声誉系统如RepuNet能够有效解决生成式多智能体系统中的合作问题，并引发有益的涌现行为，为类似系统提供了新的治理思路。"}}
{"id": "2505.05059", "title": "Enhancing Reinforcement Learning for the Floorplanning of Analog ICs with Beam Search", "authors": ["Sandro Junior Della Rovere", "Davide Basso", "Luca Bortolussi", "Mirjana Videnovic-Misic", "Husni Habal"], "abstract": "The layout of analog ICs requires making complex trade-offs, while addressing device physics and variability of the circuits. This makes full automation with learning-based solutions hard to achieve. However, reinforcement learning (RL) has recently reached significant results, particularly in solving the floorplanning problem. This paper presents a hybrid method that combines RL with a beam (BS) strategy. The BS algorithm enhances the agent's inference process, allowing for the generation of flexible floorplans by accomodating various objective weightings, and addressing congestion without without the need for policy retraining or fine-tuning. Moreover, the RL agent's generalization ability stays intact, along with its efficient handling of circuit features and constraints. Experimental results show approx. 5-85% improvement in area, dead space and half-perimeter wire length compared to a standard RL application, along with higher rewards for the agent. Moreover, performance and efficiency align closely with those of existing state-of-the-art techniques.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "Published in Proceedings of the 21st International Conference on Synthesis, Modeling, Analysis and Simulation Methods, and Applications to Circuit Design (SMACD 2025). 4 pages, 3 figures", "pdf_url": "https://arxiv.org/pdf/2505.05059.pdf", "abstract_url": "https://arxiv.org/abs/2505.05059", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种结合强化学习（RL）与波束搜索（BS）策略的混合方法，用于模拟集成电路的布局规划。该方法通过BS算法增强代理的推理过程，能够在不需重新训练或微调策略的情况下，生成灵活的布局方案，同时处理拥塞问题。实验结果显示，与标准RL应用相比，该方法在面积、死区和半周长线长等方面实现了约5-85%的改进，且代理获得的奖励更高，性能与效率与现有最先进技术相当。", "motivation": "模拟集成电路的布局需要做出复杂的权衡，同时解决器件物理和电路的变异性问题，这使得基于学习的全自动化解决方案难以实现。本文旨在通过结合RL与BS策略，提高布局规划的自动化水平和效率。", "method": "本文采用了一种混合方法，将强化学习（RL）与波束搜索（BS）策略相结合。BS算法用于增强RL代理的推理过程，使其能够生成灵活的布局方案，并处理拥塞问题，而无需重新训练或微调策略。", "result": "实验结果表明，与标准RL应用相比，该方法在面积、死区和半周长线长等方面实现了约5-85%的改进，同时代理获得的奖励更高。此外，该方法的性能与效率与现有最先进技术相当。", "conclusion": "本文提出的混合方法有效地提高了模拟集成电路布局规划的自动化水平和效率，通过结合RL与BS策略，不仅保持了RL代理的泛化能力，还显著改善了布局质量，为模拟集成电路的设计提供了新的解决方案。"}}
{"id": "2505.04649", "title": "FRAME: Feedback-Refined Agent Methodology for Enhancing Medical Research Insights", "authors": ["Chengzhang Yu", "Yiming Zhang", "Zhixin Liu", "Zenghui Ding", "Yining Sun", "Zhanpeng Jin"], "abstract": "The automation of scientific research through large language models (LLMs) presents significant opportunities but faces critical challenges in knowledge synthesis and quality assurance. We introduce Feedback-Refined Agent Methodology (FRAME), a novel framework that enhances medical paper generation through iterative refinement and structured feedback. Our approach comprises three key innovations: (1) A structured dataset construction method that decomposes 4,287 medical papers into essential research components through iterative refinement; (2) A tripartite architecture integrating Generator, Evaluator, and Reflector agents that progressively improve content quality through metric-driven feedback; and (3) A comprehensive evaluation framework that combines statistical metrics with human-grounded benchmarks. Experimental results demonstrate FRAME's effectiveness, achieving significant improvements over conventional approaches across multiple models (9.91% average gain with DeepSeek V3, comparable improvements with GPT-4o Mini) and evaluation dimensions. Human evaluation confirms that FRAME-generated papers achieve quality comparable to human-authored works, with particular strength in synthesizing future research directions. The results demonstrated our work could efficiently assist medical research by building a robust foundation for automated medical research paper generation while maintaining rigorous academic standards.", "subjects": "Computation and Language (cs.CL)", "comments": "12 pages, 4 figures, 5 table", "pdf_url": "https://arxiv.org/pdf/2505.04649.pdf", "abstract_url": "https://arxiv.org/abs/2505.04649", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了FRAME（反馈精炼代理方法），一种通过迭代精炼和结构化反馈增强医学论文生成的新框架。FRAME通过分解医学论文、集成生成器、评估器和反射器代理，以及结合统计指标和人类基准的评估框架，显著提高了论文生成的质量。实验结果表明，FRAME在多个模型和评估维度上优于传统方法，生成论文的质量接近人类作者，尤其在综合未来研究方向方面表现突出。", "motivation": "自动化科学研究面临知识合成和质量保证的关键挑战。本文旨在通过FRAME框架解决这些问题，提升医学论文生成的效率和质量。", "method": "FRAME框架包括三个关键创新：结构化数据集构建方法、集成生成器、评估器和反射器代理的三方架构，以及结合统计指标和人类基准的全面评估框架。", "result": "实验结果显示，FRAME在多个模型（如DeepSeek V3和GPT-4o Mini）和评估维度上显著优于传统方法，生成论文的质量接近人类作者，尤其在综合未来研究方向方面表现突出。", "conclusion": "FRAME为自动化医学研究论文生成建立了坚实的基础，同时保持了严格的学术标准，能有效辅助医学研究。"}}
{"id": "2505.04651", "title": "Scientific Hypothesis Generation and Validation: Methods, Datasets, and Future Directions", "authors": ["Adithya Kulkarni", "Fatimah Alotaibi", "Xinyue Zeng", "Longfeng Wu", "Tong Zeng", "Barry Menglong Yao", "Minqian Liu", "Shuaicheng Zhang", "Lifu Huang", "Dawei Zhou"], "abstract": "Large Language Models (LLMs) are transforming scientific hypothesis generation and validation by enabling information synthesis, latent relationship discovery, and reasoning augmentation. This survey provides a structured overview of LLM-driven approaches, including symbolic frameworks, generative models, hybrid systems, and multi-agent architectures. We examine techniques such as retrieval-augmented generation, knowledge-graph completion, simulation, causal inference, and tool-assisted reasoning, highlighting trade-offs in interpretability, novelty, and domain alignment. We contrast early symbolic discovery systems (e.g., BACON, KEKADA) with modern LLM pipelines that leverage in-context learning and domain adaptation via fine-tuning, retrieval, and symbolic grounding. For validation, we review simulation, human-AI collaboration, causal modeling, and uncertainty quantification, emphasizing iterative assessment in open-world contexts. The survey maps datasets across biomedicine, materials science, environmental science, and social science, introducing new resources like AHTech and CSKG-600. Finally, we outline a roadmap emphasizing novelty-aware generation, multimodal-symbolic integration, human-in-the-loop systems, and ethical safeguards, positioning LLMs as agents for principled, scalable scientific discovery.", "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.04651.pdf", "abstract_url": "https://arxiv.org/abs/2505.04651", "categories": ["Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文综述了大型语言模型（LLMs）在科学假设生成和验证中的应用，包括方法、数据集和未来方向。", "motivation": "探讨LLMs如何通过信息合成、潜在关系发现和推理增强来改变科学假设的生成和验证过程。", "method": "综述了LLM驱动的方法，包括符号框架、生成模型、混合系统和多智能体架构，以及检索增强生成、知识图完成等技术。", "result": "对比了早期的符号发现系统和现代LLM管道，并回顾了验证技术，如模拟、人机协作等，同时介绍了新的数据集资源。", "conclusion": "提出了一个路线图，强调新颖性感知生成、多模态符号整合、人在环系统和伦理保障，将LLMs定位为原则性、可扩展科学发现的代理。"}}
{"id": "2505.04666", "title": "Fine-Tuning Large Language Models and Evaluating Retrieval Methods for Improved Question Answering on Building Codes", "authors": ["Mohammad Aqib", "Mohd Hamza", "Qipei Mei", "Ying Hei Chui"], "abstract": "Building codes are regulations that establish standards for the design, construction, and safety of buildings to ensure structural integrity, fire protection, and accessibility. They are often extensive, complex, and subject to frequent updates, making manual querying challenging and time-consuming. Key difficulties include navigating large volumes of text, interpreting technical language, and identifying relevant clauses across different sections. A potential solution is to build a Question-Answering (QA) system that answers user queries based on building codes. Among the various methods for building a QA system, Retrieval-Augmented Generation (RAG) stands out in performance. RAG consists of two components: a retriever and a language model. This study focuses on identifying a suitable retriever method for building codes and optimizing the generational capability of the language model using fine-tuning techniques. We conducted a detailed evaluation of various retrieval methods by performing the retrieval on the National Building Code of Canada (NBCC) and explored the impact of domain-specific fine-tuning on several language models using the dataset derived from NBCC. Our analysis included a comparative assessment of different retrievers and the performance of both pre-trained and fine-tuned models to determine the efficacy and domain-specific adaptation of language models using fine-tuning on the NBCC dataset. Experimental results showed that Elasticsearch proved to be the most robust retriever among all. The findings also indicate that fine-tuning language models on an NBCC-specific dataset can enhance their ability to generate contextually relevant responses. When combined with context retrieved by a powerful retriever like Elasticsearch, this improvement in LLM performance can optimize the RAG system, enabling it to better navigate the complexities of the NBCC.", "subjects": "Computation and Language (cs.CL); Information Retrieval (cs.IR); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.04666.pdf", "abstract_url": "https://arxiv.org/abs/2505.04666", "categories": ["Computation and Language (cs.CL)", "Information Retrieval (cs.IR)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "该研究通过微调大型语言模型和评估检索方法，旨在提高基于建筑规范的问答系统性能。研究重点是比较不同检索方法的效果，并探索领域特定微调对语言模型性能的影响。实验结果表明，Elasticsearch是最强大的检索器，且对语言模型进行特定领域的微调能显著提升其生成相关回答的能力。", "motivation": "建筑规范内容庞大、复杂且频繁更新，手动查询既耗时又困难。本研究旨在通过构建一个基于建筑规范的问答系统来解决这些问题，特别是通过改进检索增强生成（RAG）系统中的检索器和语言模型来提高系统性能。", "method": "研究采用了检索增强生成（RAG）方法，包括一个检索器和一个语言模型。研究比较了不同检索方法在加拿大国家建筑规范（NBCC）上的效果，并探索了使用NBCC特定数据集对多种语言模型进行领域特定微调的影响。", "result": "实验结果显示，Elasticsearch在所有检索器中表现最为鲁棒。此外，对语言模型进行NBCC特定数据集的微调，能够显著提高其生成上下文相关回答的能力。结合强大的检索器如Elasticsearch，可以进一步优化RAG系统的性能。", "conclusion": "通过结合高效的检索器和经过领域特定微调的语言模型，可以显著提升基于建筑规范的问答系统的性能，使其更好地应对NBCC等复杂建筑规范的查询需求。"}}
{"id": "2505.05108", "title": "Multi-agent Embodied AI: Advances and Future Directions", "authors": ["Zhaohan Feng", "Ruiqi Xue", "Lei Yuan", "Yang Yu", "Ning Ding", "Meiqin Liu", "Bingzhao Gao", "Jian Sun", "Gang Wang"], "abstract": "Embodied artificial intelligence (Embodied AI) plays a pivotal role in the application of advanced technologies in the intelligent era, where AI systems are integrated with physical bodies that enable them to perceive, reason, and interact with their environments. Through the use of sensors for input and actuators for action, these systems can learn and adapt based on real-world feedback, allowing them to perform tasks effectively in dynamic and unpredictable environments. As techniques such as deep learning (DL), reinforcement learning (RL), and large language models (LLMs) mature, embodied AI has become a leading field in both academia and industry, with applications spanning robotics, healthcare, transportation, and manufacturing. However, most research has focused on single-agent systems that often assume static, closed environments, whereas real-world embodied AI must navigate far more complex scenarios. In such settings, agents must not only interact with their surroundings but also collaborate with other agents, necessitating sophisticated mechanisms for adaptation, real-time learning, and collaborative problem-solving. Despite increasing interest in multi-agent systems, existing research remains narrow in scope, often relying on simplified models that fail to capture the full complexity of dynamic, open environments for multi-agent embodied AI. Moreover, no comprehensive survey has systematically reviewed the advancements in this area. As embodied AI rapidly evolves, it is crucial to deepen our understanding of multi-agent embodied AI to address the challenges presented by real-world applications. To fill this gap and foster further development in the field, this paper reviews the current state of research, analyzes key contributions, and identifies challenges and future directions, providing insights to guide innovation and progress in this field.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.05108.pdf", "abstract_url": "https://arxiv.org/abs/2505.05108", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了多智能体具身人工智能（Embodied AI）的进展与未来方向，强调了在动态和不可预测环境中多智能体协作的重要性，并指出了当前研究的局限性。", "motivation": "解决单智能体系统在静态封闭环境中的局限性，探索多智能体在复杂动态环境中协作的挑战与机遇。", "method": "通过综述当前研究状态，分析关键贡献，识别挑战和未来方向，为领域内的创新和进步提供指导。", "result": "指出了多智能体具身AI研究的不足，如简化模型未能充分捕捉动态开放环境的复杂性，并提出了未来发展的方向。", "conclusion": "为了推动多智能体具身AI的发展，需要更深入地理解其在现实世界应用中的挑战，并促进跨学科合作和技术创新。"}}
{"id": "2505.05318", "title": "Mapping User Trust in Vision Language Models: Research Landscape, Challenges, and Prospects", "authors": ["Agnese Chiatti", "Sara Bernardini", "Lara Shibelski Godoy Piccolo", "Viola Schiaffonati", "Matteo Matteucci"], "abstract": "The rapid adoption of Vision Language Models (VLMs), pre-trained on large image-text and video-text datasets, calls for protecting and informing users about when to trust these systems. This survey reviews studies on trust dynamics in user-VLM interactions, through a multi-disciplinary taxonomy encompassing different cognitive science capabilities, collaboration modes, and agent behaviours. Literature insights and findings from a workshop with prospective VLM users inform preliminary requirements for future VLM trust studies.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Human-Computer Interaction (cs.HC); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.05318.pdf", "abstract_url": "https://arxiv.org/abs/2505.05318", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)", "Human-Computer Interaction (cs.HC)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文综述了用户与视觉语言模型（VLMs）互动中的信任动态，通过多学科分类法探讨了认知科学能力、协作模式和代理行为，并基于文献和未来VLM用户的研讨会提出了未来VLM信任研究的初步要求。", "motivation": "随着视觉语言模型（VLMs）在大型图像-文本和视频-文本数据集上的预训练快速普及，需要保护并告知用户何时可以信任这些系统。", "method": "通过多学科分类法回顾了用户-VLM互动中信任动态的研究，并结合文献见解和未来VLM用户的研讨会发现。", "result": "提出了未来VLM信任研究的初步要求，强调了认知科学能力、协作模式和代理行为在理解用户信任中的重要性。", "conclusion": "本文为理解和增强用户对VLMs的信任提供了研究框架和方向，指出了未来研究的关键挑战和前景。"}}
{"id": "2505.05115", "title": "Is there a half-life for the success rates of AI agents?", "authors": ["Toby Ord"], "abstract": "Building on the recent empirical work of Kwa et al. (2025), I show that within their suite of research-engineering tasks the performance of AI agents on longer-duration tasks can be explained by an extremely simple mathematical model -- a constant rate of failing during each minute a human would take to do the task. This implies an exponentially declining success rate with the length of the task and that each agent could be characterised by its own half-life. This empirical regularity allows us to estimate the success rate for an agent at different task lengths. And the fact that this model is a good fit for the data is suggestive of the underlying causes of failure on longer tasks -- that they involve increasingly large sets of subtasks where failing any one fails the task. Whether this model applies more generally on other suites of tasks is unknown and an important subject for further work.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "9 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2505.05115.pdf", "abstract_url": "https://arxiv.org/abs/2505.05115", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "基于Kwa等人（2025年）的实证研究，本文提出一个简单数学模型，解释AI代理在长时间任务中表现下降的现象，即每分钟失败率恒定，导致成功率随任务长度呈指数下降。每个代理可被其半衰期表征。", "motivation": "解决AI代理在长时间任务中表现下降的原因及其预测问题。", "method": "使用一个简单的数学模型，即每分钟失败率恒定，来分析AI代理在长时间任务中的表现。", "result": "发现AI代理的成功率随任务长度呈指数下降，每个代理有其独特的半衰期。", "conclusion": "该模型为预测AI代理在不同长度任务中的成功率提供了工具，并暗示长时间任务失败可能与子任务数量增加有关。模型在其他任务中的适用性尚待研究。"}}
{"id": "2505.05197", "title": "Societal and technological progress as sewing an ever-growing, ever-changing, patchy, and polychrome quilt", "authors": ["Joel Z. Leibo", "Alexander Sasha Vezhnevets", "William A. Cunningham", "Sébastien Krier", "Manfred Diaz", "Simon Osindero"], "abstract": "Artificial Intelligence (AI) systems are increasingly placed in positions where their decisions have real consequences, e.g., moderating online spaces, conducting research, and advising on policy. Ensuring they operate in a safe and ethically acceptable fashion is thus critical. However, most solutions have been a form of one-size-fits-all \"alignment\". We are worried that such systems, which overlook enduring moral diversity, will spark resistance, erode trust, and destabilize our institutions. This paper traces the underlying problem to an often-unstated Axiom of Rational Convergence: the idea that under ideal conditions, rational agents will converge in the limit of conversation on a single ethics. Treating that premise as both optional and doubtful, we propose what we call the appropriateness framework: an alternative approach grounded in conflict theory, cultural evolution, multi-agent systems, and institutional economics. The appropriateness framework treats persistent disagreement as the normal case and designs for it by applying four principles: (1) contextual grounding, (2) community customization, (3) continual adaptation, and (4) polycentric governance. We argue here that adopting these design principles is a good way to shift the main alignment metaphor from moral unification to a more productive metaphor of conflict management, and that taking this step is both desirable and urgent.", "subjects": "Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "comments": "16 pages", "pdf_url": "https://arxiv.org/pdf/2505.05197.pdf", "abstract_url": "https://arxiv.org/abs/2505.05197", "categories": ["Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了人工智能系统在决策时面临的伦理多样性问题，提出了一种名为“适当性框架”的替代方法，以应对持续的道德分歧。", "motivation": "解决人工智能系统在决策时忽视道德多样性，可能导致抵抗、信任侵蚀和制度不稳定的问题。", "method": "提出了基于冲突理论、文化进化、多智能体系统和制度经济学的“适当性框架”，包含四个原则：上下文基础、社区定制、持续适应和多中心治理。", "result": "通过将道德统一的对齐隐喻转变为冲突管理，提出了一种更有效的方法来处理持续的道德分歧。", "conclusion": "采用这些设计原则不仅可取而且紧迫，有助于在人工智能系统中实现更安全和伦理上可接受的决策。"}}
{"id": "2505.05177", "title": "MARK: Memory Augmented Refinement of Knowledge", "authors": ["Anish Ganguli", "Prabal Deb", "Debleena Banerjee"], "abstract": "Large Language Models (LLMs) assist in specialized tasks but struggle to align with evolving domain knowledge without costly fine-tuning. Domain knowledge consists of: Knowledge: Immutable facts (e.g., 'A stone is solid') and generally accepted principles (e.g., ethical standards); Refined Memory: Evolving insights shaped by business needs and real-world changes. However, a significant gap often exists between a domain expert's deep, nuanced understanding and the system's domain knowledge, which can hinder accurate information retrieval and application. Our Memory-Augmented Refinement of Knowledge (MARK) framework enables LLMs to continuously learn without retraining by leveraging structured refined memory, inspired by the Society of Mind. MARK operates through specialized agents, each serving a distinct role: Residual Refined Memory Agent: Stores and retrieves domain-specific insights to maintain context over time; User Question Refined Memory Agent: Captures user-provided facts, abbreviations, and terminology for better comprehension; LLM Response Refined Memory Agent: Extracts key elements from responses for refinement and personalization. These agents analyse stored refined memory, detect patterns, resolve contradictions, and improve response accuracy. Temporal factors like recency and frequency prioritize relevant information while discarding outdated insights. MARK enhances LLMs in multiple ways: Ground Truth Strategy: Reduces hallucinations by establishing a structured reference; Domain-Specific Adaptation: Essential for fields like healthcare, law, and manufacturing, where proprietary insights are absent from public datasets; Personalized AI Assistants: Improves virtual assistants by remembering user preferences, ensuring coherent responses over time.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.05177.pdf", "abstract_url": "https://arxiv.org/abs/2505.05177", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "MARK框架通过结构化精炼记忆使大型语言模型（LLMs）无需重新训练即可持续学习，解决了LLMs难以适应不断演变的领域知识的问题。", "motivation": "解决大型语言模型（LLMs）在适应不断演变的领域知识时需要进行昂贵微调的问题，以及领域专家深度、细致理解与系统领域知识之间存在显著差距的问题。", "method": "采用MARK框架，通过专门的代理（如残差精炼记忆代理、用户问题精炼记忆代理和LLM响应精炼记忆代理）来存储、检索和分析精炼记忆，检测模式，解决矛盾，并提高响应准确性。", "result": "MARK框架通过结构化参考减少幻觉，实现领域特定适应，并提升个性化AI助手的性能，确保随时间推移的连贯响应。", "conclusion": "MARK框架为LLMs提供了一种无需重新训练即可持续学习和适应不断演变的领域知识的方法，特别是在医疗、法律和制造等领域的应用中显示出巨大潜力。"}}
{"id": "2505.05440", "title": "EcoAgent: An Efficient Edge-Cloud Collaborative Multi-Agent Framework for Mobile Automation", "authors": ["Biao Yi", "Xavier Hu", "Yurun Chen", "Shengyu Zhang", "Hongxia Yang", "Fan Wu", "Fei Wu"], "abstract": "Cloud-based mobile agents powered by (multimodal) large language models ((M)LLMs) offer strong reasoning abilities but suffer from high latency and cost. While fine-tuned (M)SLMs enable edge deployment, they often lose general capabilities and struggle with complex tasks. To address this, we propose EcoAgent, an Edge-Cloud cOllaborative multi-agent framework for mobile automation. EcoAgent features a closed-loop collaboration among a cloud-based Planning Agent and two edge-based agents: the Execution Agent for action execution and the Observation Agent for verifying outcomes. The Observation Agent uses a Pre-Understanding Module to compress screen images into concise text, reducing token usage. In case of failure, the Planning Agent retrieves screen history and replans via a Reflection Module. Experiments on AndroidWorld show that EcoAgent maintains high task success rates while significantly reducing MLLM token consumption, enabling efficient and practical mobile automation.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.05440.pdf", "abstract_url": "https://arxiv.org/abs/2505.05440", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "EcoAgent是一个高效的边缘-云协作多代理框架，旨在解决移动自动化中云代理的高延迟和成本问题，同时保持强大的推理能力。", "motivation": "解决基于云的大型语言模型在移动自动化中的高延迟和高成本问题，以及边缘部署的简化模型在复杂任务上的性能不足。", "method": "提出了EcoAgent框架，包括云端的规划代理和边缘的执行代理与观察代理，通过预理解模块压缩图像信息，并通过反射模块在失败时重新规划。", "result": "在AndroidWorld上的实验表明，EcoAgent在保持高任务成功率的同时，显著减少了大型语言模型的令牌消耗。", "conclusion": "EcoAgent框架实现了高效且实用的移动自动化，通过边缘-云协作平衡了性能和成本。"}}
{"id": "2505.04847", "title": "Benchmarking LLM Faithfulness in RAG with Evolving Leaderboards", "authors": ["Manveer Singh Tamber", "Forrest Sheng Bao", "Chenyu Xu", "Ge Luo", "Suleman Kazi", "Minseok Bae", "Miaoran Li", "Ofer Mendelevitch", "Renyi Qu", "Jimmy Lin"], "abstract": "Hallucinations remain a persistent challenge for LLMs. RAG aims to reduce hallucinations by grounding responses in contexts. However, even when provided context, LLMs still frequently introduce unsupported information or contradictions. This paper presents our efforts to measure LLM hallucinations with a focus on summarization tasks, assessing how often various LLMs introduce hallucinations when summarizing documents. We discuss Vectara's existing LLM hallucination leaderboard, based on the Hughes Hallucination Evaluation Model (HHEM). While HHEM and Vectara's Hallucination Leaderboard have garnered great research interest, we examine challenges faced by HHEM and current hallucination detection methods by analyzing the effectiveness of these methods on existing hallucination datasets. To address these limitations, we propose FaithJudge, an LLM-as-a-judge approach guided by few-shot human hallucination annotations, which substantially improves automated LLM hallucination evaluation over current methods. We introduce an enhanced hallucination leaderboard centered on FaithJudge, alongside our current hallucination leaderboard, enabling more reliable benchmarking of LLMs for hallucinations in RAG.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.04847.pdf", "abstract_url": "https://arxiv.org/abs/2505.04847", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文探讨了LLM在RAG中的幻觉问题，提出了FaithJudge方法以改进幻觉评估，并引入了基于FaithJudge的增强幻觉排行榜。", "motivation": "解决LLM在提供上下文时仍产生不支持的或矛盾信息的问题，特别是在摘要任务中的幻觉现象。", "method": "提出FaithJudge方法，一种基于少量人工幻觉注释的LLM-as-a-judge方法，以提高自动化LLM幻觉评估的准确性。", "result": "FaithJudge方法显著优于现有的幻觉检测方法，基于此方法建立的增强幻觉排行榜能更可靠地评估LLM在RAG中的幻觉问题。", "conclusion": "FaithJudge和增强幻觉排行榜为评估和减少LLM幻觉提供了更有效的工具，有助于推动相关研究和应用的发展。"}}
{"id": "2505.04844", "title": "Osiris: A Lightweight Open-Source Hallucination Detection System", "authors": ["Alex Shan", "John Bauer", "Christopher D. Manning"], "abstract": "Retrieval-Augmented Generation (RAG) systems have gained widespread adoption by application builders because they leverage sources of truth to enable Large Language Models (LLMs) to generate more factually sound responses. However, hallucinations, instances of LLM responses that are unfaithful to the provided context, often prevent these systems from being deployed in production environments. Current hallucination detection methods typically involve human evaluation or the use of closed-source models to review RAG system outputs for hallucinations. Both human evaluators and closed-source models suffer from scaling issues due to their high costs and slow inference speeds. In this work, we introduce a perturbed multi-hop QA dataset with induced hallucinations. Via supervised fine-tuning on our dataset, we achieve better recall with a 7B model than GPT-4o on the RAGTruth hallucination detection benchmark and offer competitive performance on precision and accuracy, all while using a fraction of the parameters. Code is released at our repository.", "subjects": "Computation and Language (cs.CL)", "comments": "Stanford 191W", "pdf_url": "https://arxiv.org/pdf/2505.04844.pdf", "abstract_url": "https://arxiv.org/abs/2505.04844", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了Osiris，一个轻量级开源的幻觉检测系统，旨在解决检索增强生成（RAG）系统中大型语言模型（LLMs）生成的响应与提供上下文不忠实的问题。通过监督微调在一个扰动的多跳QA数据集上，Osiris在RAGTruth幻觉检测基准上以7B模型实现了比GPT-4o更好的召回率，并在精确度和准确度上提供了竞争性表现，同时使用的参数数量仅为一部分。", "motivation": "解决RAG系统中由于幻觉（即LLM响应与提供上下文不忠实）而难以部署到生产环境的问题，以及当前依赖人工评估或闭源模型的幻觉检测方法在扩展性上的高成本和慢推理速度问题。", "method": "通过在一个扰动的多跳QA数据集上进行监督微调，开发了一个轻量级开源的幻觉检测系统Osiris。", "result": "Osiris在RAGTruth幻觉检测基准上以7B模型实现了比GPT-4o更好的召回率，并在精确度和准确度上提供了竞争性表现，同时使用的参数数量仅为一部分。", "conclusion": "Osiris作为一个轻量级开源的幻觉检测系统，能够有效解决RAG系统中的幻觉问题，且在性能和成本上都具有优势，为RAG系统的生产部署提供了可行的解决方案。"}}
{"id": "2505.04916", "title": "An Open-Source Dual-Loss Embedding Model for Semantic Retrieval in Higher Education", "authors": ["Ramteja Sajja", "Yusuf Sermet", "Ibrahim Demir"], "abstract": "Recent advances in AI have catalyzed the adoption of intelligent educational tools, yet many semantic retrieval systems remain ill-suited to the unique linguistic and structural characteristics of academic content. This study presents two open-source embedding models fine-tuned for educational question answering, particularly in the context of course syllabi. A synthetic dataset of 3,197 sentence pairs, spanning synonymous terminology, paraphrased questions, and implicit-explicit mappings, was constructed through a combination of manual curation and large language model (LLM)-assisted generation. Two training strategies were evaluated: (1) a baseline model fine-tuned using MultipleNegativesRankingLoss (MNRL), and (2) a dual-loss model that combines MNRL with CosineSimilarityLoss to improve both semantic ranking and similarity calibration. Evaluations were conducted on 28 university course syllabi using a fixed set of natural language questions categorized into course, faculty, and teaching assistant information. Results demonstrate that both fine-tuned models outperform strong open-source baselines, including all-MiniLM-L6-v2 and multi-qa-MiniLM-L6-cos-v1, and that the dual-loss model narrows the performance gap with high-performing proprietary embeddings such as OpenAI's text-embedding-3 series. This work contributes reusable, domain-aligned embedding models and provides a replicable framework for educational semantic retrieval, supporting downstream applications such as academic chatbots, retrieval-augmented generation (RAG) systems, and learning management system (LMS) integrations.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": "17 pages, 3 Tables", "pdf_url": "https://arxiv.org/pdf/2505.04916.pdf", "abstract_url": "https://arxiv.org/abs/2505.04916", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本研究提出了两种针对教育问答，特别是课程大纲的开放源代码嵌入模型，通过结合手动整理和大型语言模型辅助生成的方法构建了一个包含3,197个句子对的合成数据集，并评估了两种训练策略。结果表明，这两种微调模型均优于强大的开放源代码基线，且双损失模型缩小了与高性能专有嵌入模型的性能差距。", "motivation": "解决当前语义检索系统在学术内容的独特语言和结构特征上表现不佳的问题，特别是在教育问答领域。", "method": "构建了一个合成数据集，并评估了两种训练策略：一种是使用MultipleNegativesRankingLoss（MNRL）的基线模型，另一种是结合MNRL和CosineSimilarityLoss的双损失模型。", "result": "微调模型在28门大学课程大纲上进行的评估中，均优于开放源代码基线，双损失模型进一步缩小了与专有嵌入模型的性能差距。", "conclusion": "这项工作贡献了可重用的、与领域对齐的嵌入模型，并为教育语义检索提供了一个可复制的框架，支持学术聊天机器人、检索增强生成（RAG）系统和学习管理系统（LMS）集成等下游应用。"}}
{"id": "2505.04784", "title": "A Proposal for Evaluating the Operational Risk for ChatBots based on Large Language Models", "authors": ["Pedro Pinacho-Davidson", "Fernando Gutierrez", "Pablo Zapata", "Rodolfo Vergara", "Pablo Aqueveque"], "abstract": "The emergence of Generative AI (Gen AI) and Large Language Models (LLMs) has enabled more advanced chatbots capable of human-like interactions. However, these conversational agents introduce a broader set of operational risks that extend beyond traditional cybersecurity considerations. In this work, we propose a novel, instrumented risk-assessment metric that simultaneously evaluates potential threats to three key stakeholders: the service-providing organization, end users, and third parties. Our approach incorporates the technical complexity required to induce erroneous behaviors in the chatbot--ranging from non-induced failures to advanced prompt-injection attacks--as well as contextual factors such as the target industry, user age range, and vulnerability severity. To validate our metric, we leverage Garak, an open-source framework for LLM vulnerability testing. We further enhance Garak to capture a variety of threat vectors (e.g., misinformation, code hallucinations, social engineering, and malicious code generation). Our methodology is demonstrated in a scenario involving chatbots that employ retrieval-augmented generation (RAG), showing how the aggregated risk scores guide both short-term mitigation and longer-term improvements in model design and deployment. The results underscore the importance of multi-dimensional risk assessments in operationalizing secure, reliable AI-driven conversational systems.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "comments": "21 pages", "pdf_url": "https://arxiv.org/pdf/2505.04784.pdf", "abstract_url": "https://arxiv.org/abs/2505.04784", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文提出了一种基于大型语言模型（LLMs）的聊天机器人操作风险评估新方法，旨在评估对服务提供商、终端用户和第三方可能构成的威胁。", "motivation": "随着生成式AI（Gen AI）和大型语言模型（LLMs）的发展，聊天机器人能够进行类似人类的交互，但这也带来了超越传统网络安全考虑的更广泛的操作风险。", "method": "采用了一种新颖的、工具化的风险评估指标，结合了诱导聊天机器人错误行为的技术复杂性和上下文因素，如目标行业、用户年龄范围和漏洞严重性。使用并增强了开源框架Garak来捕捉多种威胁向量。", "result": "通过涉及采用检索增强生成（RAG）的聊天机器人的场景验证了该方法，结果显示聚合风险评分有助于指导短期缓解和长期模型设计与部署的改进。", "conclusion": "研究强调了在多维度风险评估中操作化安全、可靠的AI驱动对话系统的重要性。"}}
{"id": "2505.04725", "title": "Geometric Fault-Tolerant Neural Network Tracking Control of Unknown Systems on Matrix Lie Groups", "authors": ["Robin Chhabra", "Farzaneh Abdollahi"], "abstract": "We present a geometric neural network-based tracking controller for systems evolving on matrix Lie groups under unknown dynamics, actuator faults, and bounded disturbances. Leveraging the left-invariance of the tangent bundle of matrix Lie groups, viewed as an embedded submanifold of the vector space $\\R^{N\\times N}$, we propose a set of learning rules for neural network weights that are intrinsically compatible with the Lie group structure and do not require explicit parameterization. Exploiting the geometric properties of Lie groups, this approach circumvents parameterization singularities and enables a global search for optimal weights. The ultimate boundedness of all error signals -- including the neural network weights, the coordinate-free configuration error function, and the tracking velocity error -- is established using Lyapunov's direct method. To validate the effectiveness of the proposed method, we provide illustrative simulation results for decentralized formation control of multi-agent systems on the Special Euclidean group.", "subjects": "Systems and Control (eess.SY); Artificial Intelligence (cs.AI); Robotics (cs.RO); Dynamical Systems (math.DS)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.04725.pdf", "abstract_url": "https://arxiv.org/abs/2505.04725", "categories": ["Systems and Control (eess.SY)", "Artificial Intelligence (cs.AI)", "Robotics (cs.RO)", "Dynamical Systems (math.DS)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于几何神经网络的跟踪控制器，用于处理矩阵李群上未知动态、执行器故障和有界干扰下的系统。通过利用矩阵李群切丛的左不变性，提出了一组与李群结构内在兼容的神经网络权重学习规则，无需显式参数化。该方法利用李群的几何特性，避免了参数化奇点，并实现了对最优权重的全局搜索。使用Lyapunov直接方法建立了所有误差信号的最终有界性，包括神经网络权重、无坐标构型误差函数和跟踪速度误差。通过在多智能体系统上的仿真验证了方法的有效性。", "motivation": "解决矩阵李群上系统在未知动态、执行器故障和有界干扰下的跟踪控制问题。", "method": "利用矩阵李群切丛的左不变性，提出与李群结构兼容的神经网络权重学习规则，无需显式参数化。", "result": "建立了所有误差信号的最终有界性，并通过仿真验证了方法的有效性。", "conclusion": "提出的几何神经网络跟踪控制器在矩阵李群上有效处理了未知动态、执行器故障和干扰，为多智能体系统的分散形成控制提供了新方法。"}}
{"id": "2505.05225", "title": "QualBench: Benchmarking Chinese LLMs with Localized Professional Qualifications for Vertical Domain Evaluation", "authors": ["Mengze Hong", "Wailing Ng", "Di Jiang", "Chen Jason Zhang"], "abstract": "The rapid advancement of Chinese large language models (LLMs) underscores the need for domain-specific evaluations to ensure reliable applications. However, existing benchmarks often lack coverage in vertical domains and offer limited insights into the Chinese working context. Leveraging qualification exams as a unified framework for human expertise evaluation, we introduce QualBench, the first multi-domain Chinese QA benchmark dedicated to localized assessment of Chinese LLMs. The dataset includes over 17,000 questions across six vertical domains, with data selections grounded in 24 Chinese qualifications to closely align with national policies and working standards. Through comprehensive evaluation, the Qwen2.5 model outperformed the more advanced GPT-4o, with Chinese LLMs consistently surpassing non-Chinese models, highlighting the importance of localized domain knowledge in meeting qualification requirements. The best performance of 75.26% reveals the current gaps in domain coverage within model capabilities. Furthermore, we present the failure of LLM collaboration with crowdsourcing mechanisms and suggest the opportunities for multi-domain RAG knowledge enhancement and vertical domain LLM training with Federated Learning.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.05225.pdf", "abstract_url": "https://arxiv.org/abs/2505.05225", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "QualBench是首个专注于中文大语言模型（LLMs）本地化评估的多领域中文QA基准，包含六个垂直领域的17,000多个问题，基于24项中国资格认证。评估显示，Qwen2.5模型表现优于GPT-4o，中文LLMs普遍优于非中文模型，凸显了本地化领域知识的重要性。最佳表现达到75.26%，揭示了模型能力在领域覆盖上的不足。同时，研究指出了LLM与众包机制合作的失败，并提出了多领域RAG知识增强和联邦学习训练垂直领域LLM的机会。", "motivation": "随着中文大语言模型的快速发展，需要领域特定的评估以确保应用的可靠性。现有基准在垂直领域覆盖不足，且对中国工作环境的洞察有限。", "method": "利用资格考试作为人类专业知识评估的统一框架，引入QualBench基准，包含基于24项中国资格认证的六个垂直领域的17,000多个问题。", "result": "Qwen2.5模型表现优于GPT-4o，中文LLMs普遍优于非中文模型，最佳表现达到75.26%，揭示了模型能力在领域覆盖上的不足。", "conclusion": "研究强调了本地化领域知识在满足资格要求中的重要性，并指出了LLM与众包机制合作的失败，提出了多领域RAG知识增强和联邦学习训练垂直领域LLM的机会。"}}
{"id": "2505.05445", "title": "clem:todd: A Framework for the Systematic Benchmarking of LLM-Based Task-Oriented Dialogue System Realisations", "authors": ["Chalamalasetti Kranti", "Sherzod Hakimov", "David Schlangen"], "abstract": "The emergence of instruction-tuned large language models (LLMs) has advanced the field of dialogue systems, enabling both realistic user simulations and robust multi-turn conversational agents. However, existing research often evaluates these components in isolation-either focusing on a single user simulator or a specific system design-limiting the generalisability of insights across architectures and configurations. In this work, we propose clem todd (chat-optimized LLMs for task-oriented dialogue systems development), a flexible framework for systematically evaluating dialogue systems under consistent conditions. clem todd enables detailed benchmarking across combinations of user simulators and dialogue systems, whether existing models from literature or newly developed ones. It supports plug-and-play integration and ensures uniform datasets, evaluation metrics, and computational constraints. We showcase clem todd's flexibility by re-evaluating existing task-oriented dialogue systems within this unified setup and integrating three newly proposed dialogue systems into the same evaluation pipeline. Our results provide actionable insights into how architecture, scale, and prompting strategies affect dialogue performance, offering practical guidance for building efficient and effective conversational AI systems.", "subjects": "Computation and Language (cs.CL)", "comments": "30 pages", "pdf_url": "https://arxiv.org/pdf/2505.05445.pdf", "abstract_url": "https://arxiv.org/abs/2505.05445", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了clem todd框架，用于系统评估基于大型语言模型的任务导向对话系统，支持在不同用户模拟器和对话系统组合下进行统一评估。", "motivation": "现有研究往往孤立评估对话系统的单个组件，限制了跨架构和配置的通用性见解。", "method": "提出clem todd框架，支持插件式集成，确保统一的数据集、评估指标和计算约束。", "result": "通过统一设置重新评估现有系统，并集成三个新提出的对话系统，提供了关于架构、规模和提示策略如何影响对话性能的可操作见解。", "conclusion": "clem todd框架为构建高效有效的对话AI系统提供了实用指导，展示了其在评估和比较不同对话系统配置中的灵活性。"}}
{"id": "2505.04846", "title": "HiPerRAG: High-Performance Retrieval Augmented Generation for Scientific Insights", "authors": ["Ozan Gokdemir", "Carlo Siebenschuh", "Alexander Brace", "Azton Wells", "Brian Hsu", "Kyle Hippe", "Priyanka V. Setty", "Aswathy Ajith", "J. Gregory Pauloski", "Varuni Sastry", "Sam Foreman", "Huihuo Zheng", "Heng Ma", "Bharat Kale", "Nicholas Chia", "Thomas Gibbs", "Michael E. Papka", "Thomas Brettin", "Francis J. Alexander", "Anima Anandkumar", "Ian Foster", "Rick Stevens", "Venkatram Vishwanath", "Arvind Ramanathan"], "abstract": "The volume of scientific literature is growing exponentially, leading to underutilized discoveries, duplicated efforts, and limited cross-disciplinary collaboration. Retrieval Augmented Generation (RAG) offers a way to assist scientists by improving the factuality of Large Language Models (LLMs) in processing this influx of information. However, scaling RAG to handle millions of articles introduces significant challenges, including the high computational costs associated with parsing documents and embedding scientific knowledge, as well as the algorithmic complexity of aligning these representations with the nuanced semantics of scientific content. To address these issues, we introduce HiPerRAG, a RAG workflow powered by high performance computing (HPC) to index and retrieve knowledge from more than 3.6 million scientific articles. At its core are Oreo, a high-throughput model for multimodal document parsing, and ColTrast, a query-aware encoder fine-tuning algorithm that enhances retrieval accuracy by using contrastive learning and late-interaction techniques. HiPerRAG delivers robust performance on existing scientific question answering benchmarks and two new benchmarks introduced in this work, achieving 90% accuracy on SciQ and 76% on PubMedQA-outperforming both domain-specific models like PubMedGPT and commercial LLMs such as GPT-4. Scaling to thousands of GPUs on the Polaris, Sunspot, and Frontier supercomputers, HiPerRAG delivers million document-scale RAG workflows for unifying scientific knowledge and fostering interdisciplinary innovation.", "subjects": "Information Retrieval (cs.IR); Computational Engineering, Finance, and Science (cs.CE); Computation and Language (cs.CL); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)", "comments": "This paper has been accepted at the Platform for Advanced Scientific Computing Conference (PASC 25), June 16-18, 2025, Brugg-Windisch, Switzerland", "pdf_url": "https://arxiv.org/pdf/2505.04846.pdf", "abstract_url": "https://arxiv.org/abs/2505.04846", "categories": ["Information Retrieval (cs.IR)", "Computational Engineering, Finance, and Science (cs.CE)", "Computation and Language (cs.CL)", "Distributed, Parallel, and Cluster Computing (cs.DC)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "HiPerRAG是一个高性能的检索增强生成系统，旨在通过高性能计算处理超过360万篇科学文章，解决科学文献快速增长带来的问题，提高大型语言模型在处理科学信息时的准确性。", "motivation": "科学文献的指数级增长导致了许多发现未被充分利用、努力重复和跨学科合作有限的问题。检索增强生成（RAG）可以辅助科学家，通过提高大型语言模型（LLMs）处理这些信息时的准确性来解决这一问题。然而，将RAG扩展到处理数百万篇文章带来了重大挑战，包括解析文档和嵌入科学知识的高计算成本，以及将这些表示与科学内容的细微语义对齐的算法复杂性。", "method": "HiPerRAG是一个由高性能计算（HPC）驱动的RAG工作流程，核心包括Oreo（一个用于多模态文档解析的高吞吐量模型）和ColTrast（一个查询感知的编码器微调算法，通过对比学习和后期交互技术提高检索准确性）。", "result": "HiPerRAG在现有的科学问答基准和本工作中引入的两个新基准上表现出色，在SciQ上达到90%的准确率，在PubMedQA上达到76%的准确率，超过了PubMedGPT等特定领域模型和GPT-4等商业LLM。通过在Polaris、Sunspot和Frontier超级计算机上扩展到数千个GPU，HiPerRAG实现了百万文档规模的RAG工作流程，用于统一科学知识和促进跨学科创新。", "conclusion": "HiPerRAG通过高性能计算技术有效解决了科学文献处理中的挑战，不仅提高了检索和生成的准确性，还为跨学科的科学创新提供了强有力的工具。"}}
{"id": "2505.05223", "title": "Multi-Objective Reinforcement Learning for Adaptive Personalized Autonomous Driving", "authors": ["Hendrik Surmann", "Jorge de Heuvel", "Maren Bennewitz"], "abstract": "Human drivers exhibit individual preferences regarding driving style. Adapting autonomous vehicles to these preferences is essential for user trust and satisfaction. However, existing end-to-end driving approaches often rely on predefined driving styles or require continuous user feedback for adaptation, limiting their ability to support dynamic, context-dependent preferences. We propose a novel approach using multi-objective reinforcement learning (MORL) with preference-driven optimization for end-to-end autonomous driving that enables runtime adaptation to driving style preferences. Preferences are encoded as continuous weight vectors to modulate behavior along interpretable style objectives$\\unicode{x2013}$including efficiency, comfort, speed, and aggressiveness$\\unicode{x2013}$without requiring policy retraining. Our single-policy agent integrates vision-based perception in complex mixed-traffic scenarios and is evaluated in diverse urban environments using the CARLA simulator. Experimental results demonstrate that the agent dynamically adapts its driving behavior according to changing preferences while maintaining performance in terms of collision avoidance and route completion.", "subjects": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.05223.pdf", "abstract_url": "https://arxiv.org/abs/2505.05223", "categories": ["Robotics (cs.RO)", "Computer Vision and Pattern Recognition (cs.CV)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种使用多目标强化学习（MORL）与偏好驱动优化的新颖方法，用于端到端自动驾驶，以实现对驾驶风格偏好的运行时适应。", "motivation": "人类驾驶员展现出个性化的驾驶风格偏好。为了使自动驾驶车辆适应这些偏好，提高用户的信任和满意度，需要一种能够支持动态、上下文相关偏好的方法。", "method": "采用多目标强化学习（MORL）和偏好驱动优化，将偏好编码为连续权重向量，以在不重新训练策略的情况下，沿可解释的风格目标（包括效率、舒适度、速度和攻击性）调整行为。", "result": "实验结果表明，该代理能够根据变化的偏好动态调整其驾驶行为，同时在避免碰撞和完成路线方面保持性能。", "conclusion": "提出的方法能够有效适应个性化的驾驶风格偏好，为自动驾驶车辆的个性化提供了新的可能性。"}}
{"id": "2505.05015", "title": "An Agent-Based Modeling Approach to Free-Text Keyboard Dynamics for Continuous Authentication", "authors": ["Roberto Dillon", "Arushi"], "abstract": "Continuous authentication systems leveraging free-text keyboard dynamics offer a promising additional layer of security in a multifactor authentication setup that can be used in a transparent way with no impact on user experience. This study investigates the efficacy of behavioral biometrics by employing an Agent-Based Model (ABM) to simulate diverse typing profiles across mechanical and membrane keyboards. Specifically, we generated synthetic keystroke data from five unique agents, capturing features related to dwell time, flight time, and error rates within sliding 5-second windows updated every second. Two machine learning approaches, One-Class Support Vector Machine (OC-SVM) and Random Forest (RF), were evaluated for user verification. Results revealed a stark contrast in performance: while One-Class SVM failed to differentiate individual users within each group, Random Forest achieved robust intra-keyboard user recognition (Accuracy > 0.7) but struggled to generalize across keyboards for the same user, highlighting the significant impact of keyboard hardware on typing behavior. These findings suggest that: (1) keyboard-specific user profiles may be necessary for reliable authentication, and (2) ensemble methods like RF outperform One-Class SVM in capturing fine-grained user-specific patterns.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)", "comments": "16 pages, 5 figures, 12 tables", "pdf_url": "https://arxiv.org/pdf/2505.05015.pdf", "abstract_url": "https://arxiv.org/abs/2505.05015", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Cryptography and Security (cs.CR)"], "matching_keywords": ["agent"], "AI": {"tldr": "本研究通过基于代理的模型（ABM）模拟不同键盘上的打字行为，评估了自由文本键盘动态在连续认证中的有效性。使用两种机器学习方法（OC-SVM和RF）进行用户验证，发现RF在键盘内用户识别上表现良好，但跨键盘识别效果不佳。", "motivation": "解决在多因素认证中，如何利用自由文本键盘动态作为透明且不影响用户体验的额外安全层的问题。", "method": "采用基于代理的模型（ABM）模拟机械和薄膜键盘上的多样化打字行为，生成合成击键数据，并使用OC-SVM和RF两种机器学习方法进行用户验证。", "result": "RF在键盘内用户识别上表现出色（准确率>0.7），但在跨键盘识别同一用户时表现不佳；OC-SVM则无法区分组内用户。", "conclusion": "研究结果表明：（1）可能需要键盘特定的用户配置文件以实现可靠认证；（2）集成方法如RF在捕捉用户特定细粒度模式上优于OC-SVM。"}}
{"id": "2505.05211", "title": "Incentive-Aware Machine Learning; Robustness, Fairness, Improvement & Causality", "authors": ["Chara Podimata"], "abstract": "The article explores the emerging domain of incentive-aware machine learning (ML), which focuses on algorithmic decision-making in contexts where individuals can strategically modify their inputs to influence outcomes. It categorizes the research into three perspectives: robustness, aiming to design models resilient to \"gaming\"; fairness, analyzing the societal impacts of such systems; and improvement/causality, recognizing situations where strategic actions lead to genuine personal or societal improvement. The paper introduces a unified framework encapsulating models for these perspectives, including offline, online, and causal settings, and highlights key challenges such as differentiating between gaming and improvement and addressing heterogeneity among agents. By synthesizing findings from diverse works, we outline theoretical advancements and practical solutions for robust, fair, and causally-informed incentive-aware ML systems.", "subjects": "Computer Science and Game Theory (cs.GT); Artificial Intelligence (cs.AI)", "comments": "This literature review was published in SIGEcom Exchanges in 2025", "pdf_url": "https://arxiv.org/pdf/2505.05211.pdf", "abstract_url": "https://arxiv.org/abs/2505.05211", "categories": ["Computer Science and Game Theory (cs.GT)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了激励感知机器学习（ML）的新兴领域，专注于在个体可以策略性修改输入以影响结果的背景下进行算法决策。研究分为三个视角：鲁棒性、公平性和改进/因果性，并提出了一个统一的框架来封装这些视角的模型。", "motivation": "解决在个体可能策略性行为影响ML系统决策时，如何设计鲁棒、公平且能促进真实改进的算法。", "method": "通过分类研究视角（鲁棒性、公平性、改进/因果性）并引入一个统一的框架，包括离线、在线和因果设置，来探索激励感知ML。", "result": "提出了理论进展和实用解决方案，以区分游戏和改进，处理代理的异质性，从而设计出鲁棒、公平且因果感知的ML系统。", "conclusion": "激励感知ML在鲁棒性、公平性和因果性方面的研究为设计更公正和有效的算法决策系统提供了重要见解和解决方案。"}}
{"id": "2505.05283", "title": "Software Development Life Cycle Perspective: A Survey of Benchmarks for CodeLLMs and Agents", "authors": ["Kaixin Wang", "Tianlin Li", "Xiaoyu Zhang", "Chong Wang", "Weisong Sun", "Yang Liu", "Bin Shi"], "abstract": "Code large language models (CodeLLMs) and agents have shown great promise in tackling complex software engineering", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.05283.pdf", "abstract_url": "https://arxiv.org/abs/2505.05283", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文对代码大型语言模型（CodeLLMs）和代理在解决复杂软件工程问题中的潜力进行了调查，特别关注了从软件开发生命周期（SDLC）角度出发的基准测试。", "motivation": "探讨CodeLLMs和代理在软件工程领域的应用潜力，以及如何通过基准测试评估它们在软件开发生命周期各阶段的表现。", "method": "通过调查和分析现有的基准测试，评估CodeLLMs和代理在软件开发生命周期不同阶段的应用效果。", "result": "CodeLLMs和代理在解决复杂软件工程问题方面显示出巨大潜力，但需要更全面的基准测试来评估它们在SDLC各阶段的表现。", "conclusion": "虽然CodeLLMs和代理在软件工程领域具有广泛应用前景，但开发更全面的基准测试对于评估和提升它们在软件开发生命周期各阶段的性能至关重要。"}}
{"id": "2505.05262", "title": "Enhancing Cooperative Multi-Agent Reinforcement Learning with State Modelling and Adversarial Exploration", "authors": ["Andreas Kontogiannis", "Konstantinos Papathanasiou", "Yi Shen", "Giorgos Stamou", "Michael M. Zavlanos", "George Vouros"], "abstract": "Learning to cooperate in distributed partially observable environments with no communication abilities poses significant challenges for multi-agent deep reinforcement learning (MARL). This paper addresses key concerns in this domain, focusing on inferring state representations from individual agent observations and leveraging these representations to enhance agents' exploration and collaborative task execution policies. To this end, we propose a novel state modelling framework for cooperative MARL, where agents infer meaningful belief representations of the non-observable state, with respect to optimizing their own policies, while filtering redundant and less informative joint state information. Building upon this framework, we propose the MARL SMPE algorithm. In SMPE, agents enhance their own policy's discriminative abilities under partial observability, explicitly by incorporating their beliefs into the policy network, and implicitly by adopting an adversarial type of exploration policies which encourages agents to discover novel, high-value states while improving the discriminative abilities of others. Experimentally, we show that SMPE outperforms state-of-the-art MARL algorithms in complex fully cooperative tasks from the MPE, LBF, and RWARE benchmarks.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "Accepted (Poster) at ICML 2025", "pdf_url": "https://arxiv.org/pdf/2505.05262.pdf", "abstract_url": "https://arxiv.org/abs/2505.05262", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新颖的状态建模框架和MARL SMPE算法，旨在通过推断个体代理观察到的状态表示并利用这些表示来增强代理的探索和协作任务执行策略，从而解决分布式部分可观察环境中无通信能力的多代理深度强化学习（MARL）的合作问题。实验表明，SMPE在MPE、LBF和RWARE基准测试中的复杂全合作任务中优于最先进的MARL算法。", "motivation": "解决在无通信能力的分布式部分可观察环境中，多代理深度强化学习（MARL）合作学习面临的挑战，特别是从个体代理观察中推断状态表示并利用这些表示来增强代理的探索和协作任务执行策略。", "method": "提出了一种新颖的状态建模框架，代理在其中推断非可观察状态的有意义信念表示，并基于此框架提出了MARL SMPE算法，该算法通过将代理的信念纳入策略网络和采用对抗性探索策略来增强策略的区分能力。", "result": "实验结果显示，SMPE在MPE、LBF和RWARE基准测试中的复杂全合作任务中表现优于现有的MARL算法。", "conclusion": "通过状态建模和对抗性探索，SMPE算法有效地提高了多代理在部分可观察环境中的合作效率和任务执行能力，为MARL领域的研究和应用提供了新的方向。"}}
