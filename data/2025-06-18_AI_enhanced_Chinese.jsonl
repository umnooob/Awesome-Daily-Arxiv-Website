{"id": "2506.14512", "title": "SIRI-Bench: Challenging VLMs' Spatial Intelligence through Complex Reasoning Tasks", "authors": ["Zijian Song", "Xiaoxin Lin", "Qiuming Huang", "Guangrun Wang", "Liang Lin"], "abstract": "Large Language Models (LLMs) are experiencing rapid advancements in complex reasoning, exhibiting remarkable generalization in mathematics and programming. In contrast, while spatial intelligence is fundamental for Vision-Language Models (VLMs) in real-world interaction, the systematic evaluation of their complex reasoning ability within spatial contexts remains underexplored. To bridge this gap, we introduce SIRI-Bench, a benchmark designed to evaluate VLMs' spatial intelligence through video-based reasoning tasks. SIRI-Bench comprises nearly 1K video-question-answer triplets, where each problem is embedded in a realistic 3D scene and captured by video. By carefully designing questions and corresponding 3D scenes, our benchmark ensures that solving the questions requires both spatial comprehension for extracting information and high-level reasoning for deriving solutions, making it a challenging benchmark for evaluating VLMs. To facilitate large-scale data synthesis, we develop an Automatic Scene Creation Engine. This engine, leveraging multiple specialized LLM agents, can generate realistic 3D scenes from abstract math problems, ensuring faithfulness to the original descriptions. Experimental results reveal that state-of-the-art VLMs struggle significantly on SIRI-Bench, underscoring the challenge of spatial reasoning. We hope that our study will bring researchers' attention to spatially grounded reasoning and advance VLMs in visual problem-solving.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "16 pages, 9 figures", "pdf_url": "https://arxiv.org/pdf/2506.14512.pdf", "abstract_url": "https://arxiv.org/abs/2506.14512", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了SIRI-Bench，一个旨在通过视频推理任务评估视觉语言模型(VLMs)空间智能的基准。该基准包含近1K个视频-问题-答案三元组，每个问题嵌入在现实的3D场景中，要求模型具备空间理解和高层次推理能力。", "motivation": "尽管大型语言模型(LLMs)在复杂推理方面取得了快速进展，但视觉语言模型(VLMs)在空间智能方面的系统评估仍然不足。本文旨在填补这一空白，通过SIRI-Bench评估VLMs在空间上下文中的复杂推理能力。", "method": "开发了SIRI-Bench基准，包含视频推理任务，利用自动场景创建引擎生成现实的3D场景，确保问题解决需要空间理解和高层次推理。", "result": "实验结果显示，最先进的VLMs在SIRI-Bench上表现不佳，突出了空间推理的挑战。", "conclusion": "本研究旨在引起研究者对空间基础推理的关注，并推动VLMs在视觉问题解决中的进步。"}}
{"id": "2506.14142", "title": "RadFabric: Agentic AI System with Reasoning Capability for Radiology", "authors": ["Wenting Chen", "Yi Dong", "Zhaojun Ding", "Yucheng Shi", "Yifan Zhou", "Fang Zeng", "Yijun Luo", "Tianyu Lin", "Yihang Su", "Yichen Wu", "Kai Zhang", "Zhen Xiang", "Tianming Liu", "Ninghao Liu", "Lichao Sun", "Yixuan Yuan", "Xiang Li"], "abstract": "Chest X ray (CXR) imaging remains a critical diagnostic tool for thoracic conditions, but current automated systems face limitations in pathology coverage, diagnostic accuracy, and integration of visual and textual reasoning. To address these gaps, we propose RadFabric, a multi agent, multimodal reasoning framework that unifies visual and textual analysis for comprehensive CXR interpretation. RadFabric is built on the Model Context Protocol (MCP), enabling modularity, interoperability, and scalability for seamless integration of new diagnostic agents. The system employs specialized CXR agents for pathology detection, an Anatomical Interpretation Agent to map visual findings to precise anatomical structures, and a Reasoning Agent powered by large multimodal reasoning models to synthesize visual, anatomical, and clinical data into transparent and evidence based diagnoses. RadFabric achieves significant performance improvements, with near-perfect detection of challenging pathologies like fractures (1.000 accuracy) and superior overall diagnostic accuracy (0.799) compared to traditional systems (0.229 to 0.527). By integrating cross modal feature alignment and preference-driven reasoning, RadFabric advances AI-driven radiology toward transparent, anatomically precise, and clinically actionable CXR analysis.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL)", "comments": "4 figures, 2 tables", "pdf_url": "https://arxiv.org/pdf/2506.14142.pdf", "abstract_url": "https://arxiv.org/abs/2506.14142", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "RadFabric是一个多代理、多模态推理框架，旨在通过视觉和文本分析的统一，提高胸部X光（CXR）成像的综合解读能力。", "motivation": "当前自动化系统在病理覆盖范围、诊断准确性以及视觉和文本推理的整合方面存在局限，RadFabric旨在解决这些问题。", "method": "RadFabric基于模型上下文协议（MCP），采用专门化的CXR代理进行病理检测，解剖解释代理将视觉发现映射到精确的解剖结构，以及由大型多模态推理模型驱动的推理代理，综合视觉、解剖和临床数据，形成透明且基于证据的诊断。", "result": "RadFabric在挑战性病理如骨折的检测上达到了近乎完美的准确率（1.000），整体诊断准确性（0.799）显著优于传统系统（0.229至0.527）。", "conclusion": "通过整合跨模态特征对齐和偏好驱动的推理，RadFabric推动了AI驱动的放射学向透明、解剖精确和临床可操作的CXR分析迈进。"}}
{"id": "2506.14035", "title": "SimpleDoc: Multi-Modal Document Understanding with Dual-Cue Page Retrieval and Iterative Refinement", "authors": ["Chelsi Jain", "Yiran Wu", "Yifan Zeng", "Jiale Liu", "S hengyu Dai", "Zhenwen Shao", "Qingyun Wu", "Huazheng Wang"], "abstract": "Document Visual Question Answering (DocVQA) is a practical yet challenging task, which is to ask questions based on documents while referring to multiple pages and different modalities of information, e.g, images and tables. To handle multi-modality, recent methods follow a similar Retrieval Augmented Generation (RAG) pipeline, but utilize Visual Language Models (VLMs) based embedding model to embed and retrieve relevant pages as images, and generate answers with VLMs that can accept an image as input. In this paper, we introduce SimpleDoc, a lightweight yet powerful retrieval - augmented framework for DocVQA. It boosts evidence page gathering by first retrieving candidates through embedding similarity and then filtering and re-ranking these candidates based on page summaries. A single VLM-based reasoner agent repeatedly invokes this dual-cue retriever, iteratively pulling fresh pages into a working memory until the question is confidently answered. SimpleDoc outperforms previous baselines by 3.2% on average on 4 DocVQA datasets with much fewer pages retrieved. Our code is available at", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.14035.pdf", "abstract_url": "https://arxiv.org/abs/2506.14035", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "SimpleDoc是一个轻量级但功能强大的检索增强框架，用于文档视觉问答（DocVQA）。它通过双重线索检索和迭代精炼来提升证据页面的收集效率，显著提高了在多个DocVQA数据集上的性能。", "motivation": "解决文档视觉问答（DocVQA）任务中，如何有效处理多模态信息（如图像和表格）并准确回答基于多页文档的问题。", "method": "采用检索增强生成（RAG）流程，结合视觉语言模型（VLMs）的嵌入模型，通过嵌入相似性检索候选页面，然后基于页面摘要进行过滤和重新排序。一个基于VLM的推理代理重复调用这个双重线索检索器，迭代地将新页面拉入工作内存，直到问题被自信地回答。", "result": "SimpleDoc在4个DocVQA数据集上的平均性能比之前的基线提高了3.2%，且检索的页面数量大大减少。", "conclusion": "SimpleDoc通过其双重线索检索和迭代精炼的方法，有效地提升了DocVQA任务的性能，展示了在处理多模态文档理解任务中的潜力。"}}
{"id": "2506.14199", "title": "MAS-LitEval : Multi-Agent System for Literary Translation Quality Assessment", "authors": ["Junghwan Kim", "Kieun Park", "Sohee Park", "Hyunggug Kim", "Bongwon Suh"], "abstract": "Literary translation requires preserving cultural nuances and stylistic elements, which traditional metrics like BLEU and METEOR fail to assess due to their focus on lexical overlap. This oversight neglects the narrative consistency and stylistic fidelity that are crucial for literary works. To address this, we propose MAS-LitEval, a multi-agent system using Large Language Models (LLMs) to evaluate translations based on terminology, narrative, and style. We tested MAS-LitEval on translations of The Little Prince and A Connecticut Yankee in King Arthur's Court, generated by various LLMs, and compared it to traditional metrics. \\textbf{MAS-LitEval} outperformed these metrics, with top models scoring up to 0.890 in capturing literary nuances. This work introduces a scalable, nuanced framework for Translation Quality Assessment (TQA), offering a practical tool for translators and researchers.", "subjects": "Computation and Language (cs.CL)", "comments": "4 Pages, 2 tables, EMNLP submitted", "pdf_url": "https://arxiv.org/pdf/2506.14199.pdf", "abstract_url": "https://arxiv.org/abs/2506.14199", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "MAS-LitEval是一种基于大型语言模型的多代理系统，用于评估文学翻译质量，专注于术语、叙事和风格，优于传统指标。", "motivation": "传统翻译质量评估指标如BLEU和METEOR无法评估文学翻译中的文化细微差别和风格元素，忽视了叙事一致性和风格保真度的重要性。", "method": "提出MAS-LitEval，一个使用大型语言模型（LLMs）的多代理系统，用于基于术语、叙事和风格评估翻译质量。", "result": "MAS-LitEval在评估《小王子》和《亚瑟王宫廷中的康涅狄格北方佬》的翻译时，表现优于传统指标，最高模型在捕捉文学细微差别方面得分达0.890。", "conclusion": "这项工作为翻译质量评估（TQA）引入了一个可扩展、细致的框架，为翻译者和研究人员提供了实用工具。"}}
{"id": "2506.14205", "title": "AgentSynth: Scalable Task Generation for Generalist Computer-Use Agents", "authors": ["Jingxu Xie", "Dylan Xu", "Xuandong Zhao", "Dawn Song"], "abstract": "We introduce AgentSynth, a scalable and cost-efficient pipeline for automatically synthesizing high-quality tasks and trajectory datasets for generalist computer-use agents. Leveraging information asymmetry, AgentSynth constructs subtasks that are simple during generation but significantly more challenging when composed into long-horizon tasks, enabling the creation of over 6,000 diverse and realistic tasks. Our pipeline begins with an LLM-based task proposer guided by a persona, followed by an execution agent that completes the task and logs the trajectory. This process is repeated iteratively to form a sequence of subtasks, which are then summarized by a separate agent into a composite task of controllable difficulty. A key strength of AgentSynth is its ability to precisely modulate task complexity by varying the number of subtasks. Empirical evaluations show that state-of-the-art LLM agents suffer a steep performance drop, from 18% success at difficulty level 1 to just 4% at level 6, highlighting the benchmark's difficulty and discriminative power. Moreover, our pipeline achieves a low average cost of \\$0.60 per trajectory, orders of magnitude cheaper than human annotations. Our code and data are publicly available at", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.14205.pdf", "abstract_url": "https://arxiv.org/abs/2506.14205", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "AgentSynth是一个可扩展且成本效益高的流程，用于自动合成高质量的任务和轨迹数据集，适用于通用计算机使用代理。通过信息不对称，它构建了在生成时简单但在组合成长时间任务时更具挑战性的子任务，从而创建了6,000多个多样化和现实的任务。", "motivation": "解决为通用计算机使用代理生成高质量、多样化任务和轨迹数据集的挑战，同时保持成本效益和可扩展性。", "method": "利用基于LLM的任务提议者（由角色指导）和执行代理（完成任务并记录轨迹）的迭代流程，构建子任务序列，然后由另一个代理总结为可控难度的复合任务。", "result": "实证评估显示，最先进的LLM代理在难度级别1的成功率为18%，在级别6降至4%，证明了基准的难度和区分能力。每个轨迹的平均成本仅为0.60美元，远低于人工注释。", "conclusion": "AgentSynth提供了一种高效、低成本的方法来生成高质量的任务和轨迹数据集，为通用计算机使用代理的开发和评估提供了强大的工具。"}}
{"id": "2506.14234", "title": "Xolver: Multi-Agent Reasoning with Holistic Experience Learning Just Like an Olympiad Team", "authors": ["Md Tanzib Hosain", "Salman Rahman", "Md Kishor Morol", "Md Rizwan Parvez"], "abstract": "Despite impressive progress on complex reasoning, current large language models (LLMs) typically operate in isolation - treating each problem as an independent attempt, without accumulating or integrating experiential knowledge. In contrast, expert problem solvers - such as Olympiad or programming contest teams - leverage a rich tapestry of experiences: absorbing mentorship from coaches, developing intuition from past problems, leveraging knowledge of tool usage and library functionality, adapting strategies based on the expertise and experiences of peers, continuously refining their reasoning through trial and error, and learning from other related problems even during competition. We introduce Xolver, a training-free multi-agent reasoning framework that equips a black-box LLM with a persistent, evolving memory of holistic experience. Xolver integrates diverse experience modalities, including external and self-retrieval, tool use, collaborative interactions, agent-driven evaluation, and iterative refinement. By learning from relevant strategies, code fragments, and abstract reasoning patterns at inference time, Xolver avoids generating solutions from scratch - marking a transition from isolated inference toward experience-aware language agents. Built on both open-weight and proprietary models, Xolver consistently outperforms specialized reasoning agents. Even with lightweight backbones (e.g., QWQ-32B), it often surpasses advanced models including Qwen3-235B, Gemini 2.5 Pro, o3, and o4-mini-high. With o3-mini-high, it achieves new best results on GSM8K (98.1%), AIME'24 (94.4%), AIME'25 (93.7%), Math-500 (99.8%), and LiveCodeBench-V5 (91.6%) - highlighting holistic experience learning as a key step toward generalist agents capable of expert-level reasoning. Code and data are available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.14234.pdf", "abstract_url": "https://arxiv.org/abs/2506.14234", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "Xolver是一个无需训练的多智能体推理框架，通过整合多样化的经验模态，使大型语言模型（LLM）能够像奥林匹克团队一样进行复杂推理，显著提升了推理能力。", "motivation": "当前的大型语言模型在处理复杂问题时通常孤立运作，无法积累或整合经验知识，而专家问题解决者（如奥林匹克团队）则能够利用丰富的经验进行推理。Xolver旨在弥补这一差距，通过引入全面的经验学习，提升模型的推理能力。", "method": "Xolver是一个训练免费的多智能体推理框架，它为黑盒LLM提供了一个持久、进化的全面经验记忆。该框架整合了多种经验模态，包括外部和自我检索、工具使用、协作互动、智能体驱动的评估和迭代 refinement。", "result": "Xolver在多个基准测试中 consistently outperforms specialized reasoning agents，包括GSM8K（98.1%）、AIME'24（94.4%）、AIME'25（93.7%）、Math-500（99.8%）和LiveCodeBench-V5（91.6%）。", "conclusion": "Xolver通过全面的经验学习，标志着从孤立推理向经验感知语言智能体的转变，是朝着能够进行专家级推理的通才智能体迈出的关键一步。"}}
{"id": "2506.13803", "title": "Causality in the human niche: lessons for machine learning", "authors": ["Richard D. Lange", "Konrad P. Kording"], "abstract": "Humans interpret the world around them in terms of cause and effect and communicate their understanding of the world to each other in causal terms. These causal aspects of human cognition are thought to underlie humans' ability to generalize and learn efficiently in new domains, an area where current machine learning systems are weak. Building human-like causal competency into machine learning systems may facilitate the construction of effective and interpretable AI. Indeed, the machine learning community has been importing ideas on causality formalized by the Structural Causal Model (SCM) framework, which provides a rigorous formal language for many aspects of causality and has led to significant advances. However, the SCM framework fails to capture some salient aspects of human causal cognition and has likewise not yet led to advances in machine learning in certain critical areas where humans excel. We contend that the problem of causality in the ``human niche'' -- for a social, autonomous, and goal-driven agent sensing and acting in the world in which humans live -- is quite different from the kind of causality captured by SCMs. For example, everyday objects come in similar types that have similar causal properties, and so humans readily generalize knowledge of one type of object (cups) to another related type (bowls) by drawing causal analogies between objects with similar properties, but such analogies are at best awkward to express in SCMs. We explore how such causal capabilities are adaptive in, and motivated by, the human niche. By better appreciating properties of human causal cognition and, crucially, how those properties are adaptive in the niche in which humans live, we hope that future work at the intersection of machine learning and causality will leverage more human-like inductive biases to create more capable, controllable, and interpretable systems.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "23 pages, 2 figures", "pdf_url": "https://arxiv.org/pdf/2506.13803.pdf", "abstract_url": "https://arxiv.org/abs/2506.13803", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了人类因果认知对机器学习的影响，提出将人类因果能力融入机器学习系统以提高其效能和可解释性。", "motivation": "解决当前机器学习系统在泛化和高效学习新领域方面的不足，通过借鉴人类因果认知来提升AI的能力和可解释性。", "method": "分析了结构性因果模型（SCM）框架的局限性，并探讨了人类因果认知的特性及其在人类生态位中的适应性。", "result": "发现SCM框架未能完全捕捉人类因果认知的某些关键方面，特别是在物体类型间的因果类比方面。", "conclusion": "通过更深入地理解人类因果认知及其适应性，未来的机器学习研究可以开发出更具能力、可控性和可解释性的系统。"}}
{"id": "2506.13774", "title": "Personalized Constitutionally-Aligned Agentic Superego: Secure AI Behavior Aligned to Diverse Human Values", "authors": ["Nell Watson", "Ahmed Amer", "Evan Harris", "Preeti Ravindra", "Shujun Zhang"], "abstract": "Agentic AI systems, possessing capabilities for autonomous planning and action, exhibit immense potential across diverse domains. However, their practical deployment is significantly hampered by challenges in aligning their behavior with varied human values, complex safety requirements, and specific compliance needs. Existing alignment methodologies often falter when faced with the intricate task of providing deep, personalized contextual information without inducing confabulation or operational inefficiencies. This paper introduces a novel solution: a 'superego' agent, designed as a personalized oversight mechanism for agentic AI. This system dynamically steers AI planning by referencing user-selected \"Creed Constitutions\"-encapsulating diverse rule sets-with adjustable adherence levels to fit non-negotiable values. A real-time compliance enforcer validates plans against these constitutions and a universal ethical floor before execution. We present a functional system, including a demonstration interface (", "subjects": "Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Multiagent Systems (cs.MA)", "comments": "39 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2506.13774.pdf", "abstract_url": "https://arxiv.org/abs/2506.13774", "categories": ["Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了一种新型的'超我'代理，作为代理性AI的个性化监督机制，旨在通过参考用户选择的'信条宪法'来动态引导AI规划，以适应多样化的规则集和不可协商的价值观。", "motivation": "代理性AI系统在实际部署中面临与多样化人类价值观、复杂安全要求和特定合规需求对齐的挑战。现有的对齐方法在提供深入的个性化上下文信息时往往会导致虚构或操作效率低下。", "method": "提出了一种'超我'代理，该系统通过参考用户选择的'信条宪法'来动态引导AI规划，并包括一个实时合规执行器，用于在执行前验证计划是否符合这些宪法和普遍的伦理底线。", "result": "展示了一个功能系统，包括一个演示界面，表明该方法能够有效地对齐AI行为与多样化的规则集和不可协商的价值观。", "conclusion": "这种'超我'代理为代理性AI系统提供了一种新颖的个性化监督机制，能够有效地对齐AI行为与多样化的规则集和不可协商的价值观，同时保持操作效率和避免虚构。"}}
{"id": "2506.13825", "title": "The Reflexive Integrated Information Unit: A Differentiable Primitive for Artificial Consciousness", "authors": ["Gnankan Landry Regis N'guessan", "Issa Karambal"], "abstract": "Research on artificial consciousness lacks the equivalent of the perceptron: a small, trainable module that can be copied, benchmarked, and iteratively improved. We introduce the Reflexive Integrated Information Unit (RIIU), a recurrent cell that augments its hidden state $h$ with two additional vectors: (i) a meta-state $\\mu$ that records the cell's own causal footprint, and (ii) a broadcast buffer $B$ that exposes that footprint to the rest of the network. A sliding-window covariance and a differentiable Auto-$\\Phi$ surrogate let each RIIU maximize local information integration online. We prove that RIIUs (1) are end-to-end differentiable, (2) compose additively, and (3) perform $\\Phi$-monotone plasticity under gradient ascent. In an eight-way Grid-world, a four-layer RIIU agent restores $>90\\%$ reward within 13 steps after actuator failure, twice as fast as a parameter-matched GRU, while maintaining a non-zero Auto-$\\Phi$ signal. By shrinking \"consciousness-like\" computation down to unit scale, RIIUs turn a philosophical debate into an empirical mathematical problem.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.13825.pdf", "abstract_url": "https://arxiv.org/abs/2506.13825", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了反射性集成信息单元（RIIU），一种可训练的小型模块，旨在作为人工意识研究的感知机等价物。RIIU通过增加元状态和广播缓冲区，以及使用滑动窗口协方差和可微分Auto-Φ替代，实现在线最大化局部信息集成。", "motivation": "解决人工意识研究中缺乏类似于感知机的小型、可训练模块的问题，该模块可以被复制、基准测试和迭代改进。", "method": "引入RIIU，一种循环单元，通过增加元状态和广播缓冲区，以及使用滑动窗口协方差和可微分Auto-Φ替代，实现在线最大化局部信息集成。", "result": "在八方向网格世界中，四层RIIU智能体在13步内恢复了>90%的奖励，比参数匹配的GRU快两倍，同时保持非零的Auto-Φ信号。", "conclusion": "通过将“类似意识”的计算缩小到单元规模，RIIUs将哲学辩论转化为一个经验数学问题。"}}
{"id": "2506.14315", "title": "ImmerseGen: Agent-Guided Immersive World Generation with Alpha-Textured Proxies", "authors": ["Jinyan Yuan", "Bangbang Yang", "Keke Wang", "Panwang Pan", "Lin Ma", "Xuehai Zhang", "Xiao Liu", "Zhaopeng Cui", "Yuewen Ma"], "abstract": "Automatic creation of 3D scenes for immersive VR presence has been a significant research focus for decades. However, existing methods often rely on either high-poly mesh modeling with post-hoc simplification or massive 3D Gaussians, resulting in a complex pipeline or limited visual realism. In this paper, we demonstrate that such exhaustive modeling is unnecessary for achieving compelling immersive experience. We introduce ImmerseGen, a novel agent-guided framework for compact and photorealistic world modeling. ImmerseGen represents scenes as hierarchical compositions of lightweight geometric proxies, i.e., simplified terrain and billboard meshes, and generates photorealistic appearance by synthesizing RGBA textures onto these proxies. Specifically, we propose terrain-conditioned texturing for user-centric base world synthesis, and RGBA asset texturing for midground and foreground", "subjects": "Graphics (cs.GR); Computer Vision and Pattern Recognition (cs.CV)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2506.14315.pdf", "abstract_url": "https://arxiv.org/abs/2506.14315", "categories": ["Graphics (cs.GR)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "ImmerseGen是一种新颖的代理引导框架，用于紧凑且逼真的世界建模，通过层次化组合轻量级几何代理和合成RGBA纹理来实现沉浸式体验。", "motivation": "解决现有方法在自动创建3D场景时依赖高多边形网格建模或大量3D高斯分布，导致流程复杂或视觉真实感有限的问题。", "method": "引入ImmerseGen框架，使用轻量级几何代理（简化地形和广告牌网格）和RGBA纹理合成技术，提出地形条件纹理化和RGBA资产纹理化方法。", "result": "证明了无需详尽建模即可实现引人入胜的沉浸式体验，通过轻量级代理和纹理合成技术实现了紧凑且逼真的世界建模。", "conclusion": "ImmerseGen通过创新的代理和纹理合成方法，为沉浸式VR体验提供了一种高效且逼真的3D场景生成解决方案。"}}
{"id": "2506.13841", "title": "LocationReasoner: Evaluating LLMs on Real-World Site Selection Reasoning", "authors": ["Miho Koda", "Yu Zheng", "Ruixian Ma", "Mingyang Sun", "Devesh Pansare", "Fabio Duarte", "Paolo Santi"], "abstract": "Recent advances in large language models (LLMs), particularly those enhanced through reinforced post-training, have demonstrated impressive reasoning capabilities, as exemplified by models such as OpenAI o1 and DeepSeek-R1. However, these capabilities are predominantly benchmarked on domains like mathematical problem solving and code generation -- leaving open the question of whether such reasoning skills generalize to complex, real-world scenarios. In this paper, we introduce LocationReasoner, a benchmark designed to evaluate LLMs' reasoning abilities in the context of real-world site selection, where models must identify feasible locations by reasoning over diverse and complicated spatial, environmental, and logistical constraints. The benchmark comprises over 300 carefully crafted queries of varying difficulty levels, supported by a sandbox environment with in-house tools for constraint-based location search. Extensive evaluations reveal that state-of-the-art reasoning models offer limited improvement over their non-reasoning predecessors in real-world contexts, with even the latest OpenAI o4 model failing on 30% of site selection tasks. Moreover, agentic strategies such as ReAct and Reflexion often suffer from over-reasoning, leading to worse outcomes than direct code-generation prompting. With key limitations of LLMs in holistic and non-linear reasoning highlighted, we release LocationReasoner to foster the development of LLMs and agents capable of robust, grounded reasoning in real-world decision-making tasks. Codes and data for our benchmark are available at", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.13841.pdf", "abstract_url": "https://arxiv.org/abs/2506.13841", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了LocationReasoner，一个旨在评估大型语言模型（LLMs）在现实世界选址推理中能力的基准测试。通过300多个不同难度级别的查询和沙盒环境，研究发现即使是先进的推理模型在现实场景中的表现也有限，且某些代理策略可能导致更差的结果。", "motivation": "评估LLMs在复杂现实世界场景中的推理能力，特别是在需要考虑多种空间、环境和物流约束的选址问题上，现有基准主要集中于数学问题解决和代码生成领域。", "method": "引入LocationReasoner基准，包含300多个精心设计的查询和沙盒环境，用于评估LLMs在现实世界选址任务中的推理能力。", "result": "研究发现，即使是先进的推理模型如OpenAI o4，在30%的选址任务中失败，且某些代理策略如ReAct和Reflexion因过度推理而导致结果更差。", "conclusion": "LocationReasoner的发布旨在促进能够进行稳健、接地气的现实世界决策推理的LLMs和代理的发展，同时突出了LLMs在整体和非线性推理中的关键限制。"}}
{"id": "2506.14285", "title": "From What to Respond to When to Respond: Timely Response Generation for Open-domain Dialogue Agents", "authors": ["Seongbo Jang", "Minjin Jeon", "Jaehoon Lee", "Seonghyeon Lee", "Dongha Lee", "Hwanjo Yu"], "abstract": "While research on dialogue response generation has primarily focused on generating coherent responses conditioning on textual context, the critical question of when to respond grounded on the temporal context remains underexplored. To bridge this gap, we propose a novel task called timely dialogue response generation and introduce the TimelyChat benchmark, which evaluates the capabilities of language models to predict appropriate time intervals and generate time-conditioned responses. Additionally, we construct a large-scale training dataset by leveraging unlabeled event knowledge from a temporal commonsense knowledge graph and employing a large language model (LLM) to synthesize 55K event-driven dialogues. We then train Timer, a dialogue agent designed to proactively predict time intervals and generate timely responses that align with those intervals. Experimental results show that Timer outperforms prompting-based LLMs and other fine-tuned baselines in both turn-level and dialogue-level evaluations. We publicly release our data, model, and code.", "subjects": "Computation and Language (cs.CL)", "comments": "Work in progress", "pdf_url": "https://arxiv.org/pdf/2506.14285.pdf", "abstract_url": "https://arxiv.org/abs/2506.14285", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新颖的任务——及时对话响应生成，并介绍了TimelyChat基准，用于评估语言模型预测适当时间间隔和生成时间条件响应的能力。通过利用时间常识知识图中的未标记事件知识和大型语言模型（LLM）合成55K事件驱动对话，构建了一个大规模训练数据集。训练了一个名为Timer的对话代理，旨在主动预测时间间隔并生成与这些间隔对齐的及时响应。实验结果表明，Timer在回合级和对话级评估中均优于基于提示的LLMs和其他微调基线。", "motivation": "对话响应生成的研究主要集中在基于文本上下文生成连贯响应，而基于时间上下文的何时响应这一关键问题尚未得到充分探索。", "method": "提出了及时对话响应生成任务，构建了TimelyChat基准和大规模训练数据集，训练了Timer对话代理。", "result": "Timer在回合级和对话级评估中均优于基于提示的LLMs和其他微调基线。", "conclusion": "本文的工作为对话代理的及时响应生成提供了新的研究方向和实践工具，公开了数据、模型和代码。"}}
{"id": "2506.14302", "title": "Expectation Confirmation Preference Optimization for Multi-Turn Conversational Recommendation Agent", "authors": ["Xueyang Feng", "Jingsen Zhang", "Jiakai Tang", "Wei Li", "Guohao Cai", "Xu Chen", "Quanyu Dai", "Yue Zhu", "Zhenhua Dong"], "abstract": "Recent advancements in Large Language Models (LLMs) have significantly propelled the development of Conversational Recommendation Agents (CRAs). However, these agents often generate short-sighted responses that fail to sustain user guidance and meet expectations. Although preference optimization has proven effective in aligning LLMs with user expectations, it remains costly and performs poorly in multi-turn dialogue. To address this challenge, we introduce a novel multi-turn preference optimization (MTPO) paradigm ECPO, which leverages Expectation Confirmation Theory to explicitly model the evolution of user satisfaction throughout multi-turn dialogues, uncovering the underlying causes of dissatisfaction. These causes can be utilized to support targeted optimization of unsatisfactory responses, thereby achieving turn-level preference optimization. ECPO ingeniously eliminates the significant sampling overhead of existing MTPO methods while ensuring the optimization process drives meaningful improvements. To support ECPO, we introduce an LLM-based user simulator, AILO, to simulate user feedback and perform expectation confirmation during conversational recommendations. Experimental results show that ECPO significantly enhances CRA's interaction capabilities, delivering notable improvements in both efficiency and effectiveness over existing MTPO methods.", "subjects": "Computation and Language (cs.CL)", "comments": "Accepted to Findings of ACL 2025", "pdf_url": "https://arxiv.org/pdf/2506.14302.pdf", "abstract_url": "https://arxiv.org/abs/2506.14302", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新颖的多轮偏好优化范式ECPO，利用期望确认理论来明确建模多轮对话中用户满意度的演变，以解决现有方法在成本和性能上的不足。", "motivation": "大型语言模型（LLMs）在推动对话推荐代理（CRAs）发展方面取得了显著进展，但这些代理往往生成短视的响应，无法持续引导用户并满足期望。尽管偏好优化在使LLMs与用户期望对齐方面证明有效，但其成本高昂且在多轮对话中表现不佳。", "method": "引入了一种基于期望确认理论的多轮偏好优化（MTPO）范式ECPO，明确建模多轮对话中用户满意度的演变，发现不满的根本原因，并利用这些原因支持有针对性的优化。同时，引入了一个基于LLM的用户模拟器AILO，模拟用户反馈并在对话推荐过程中进行期望确认。", "result": "实验结果表明，ECPO显著提升了CRA的交互能力，在效率和效果上都比现有的MTPO方法有显著改进。", "conclusion": "ECPO巧妙地消除了现有MTPO方法的显著采样开销，同时确保优化过程带来有意义的改进，为多轮对话推荐代理的发展提供了新的方向。"}}
{"id": "2506.13983", "title": "SANGAM: SystemVerilog Assertion Generation via Monte Carlo Tree Self-Refine", "authors": ["Adarsh Gupta", "Bhabesh Mali", "Chandan Karfa"], "abstract": "Recent advancements in the field of reasoning using Large Language Models (LLMs) have created new possibilities for more complex and automatic Hardware Assertion Generation techniques. This paper introduces SANGAM, a SystemVerilog Assertion Generation framework using LLM-guided Monte Carlo Tree Search for the automatic generation of SVAs from industry-level specifications. The proposed framework utilizes a three-stage approach: Stage 1 consists of multi-modal Specification Processing using Signal Mapper, SPEC Analyzer, and Waveform Analyzer LLM Agents. Stage 2 consists of using the Monte Carlo Tree Self-Refine (MCTSr) algorithm for automatic reasoning about SVAs for each signal, and finally, Stage 3 combines the MCTSr-generated reasoning traces to generate SVA assertions for each signal. The results demonstrated that our framework, SANGAM, can generate a robust set of SVAs, performing better in the evaluation process in comparison to the recent methods.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "Adarsh Gupta and Bhabesh Mali contributed equally to this work", "pdf_url": "https://arxiv.org/pdf/2506.13983.pdf", "abstract_url": "https://arxiv.org/abs/2506.13983", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "SANGAM是一个利用大型语言模型（LLMs）引导的蒙特卡洛树搜索自动生成SystemVerilog断言（SVAs）的框架。它采用三阶段方法处理行业级规范，最终生成针对每个信号的SVA断言，结果显示其性能优于现有方法。", "motivation": "解决在硬件断言生成领域中，如何利用大型语言模型的推理能力来自动生成复杂且准确的SystemVerilog断言（SVAs）的问题。", "method": "三阶段方法：1. 多模态规范处理（信号映射器、SPEC分析器、波形分析器LLM代理）；2. 使用蒙特卡洛树自优化（MCTSr）算法对每个信号进行SVA的自动推理；3. 结合MCTSr生成的推理轨迹为每个信号生成SVA断言。", "result": "SANGAM框架能够生成一组健壮的SVAs，在评估过程中表现优于最近的方法。", "conclusion": "SANGAM框架通过结合大型语言模型和蒙特卡洛树搜索，有效地自动生成了高质量的SystemVerilog断言，为硬件设计和验证领域提供了新的可能性。"}}
{"id": "2506.14045", "title": "Discovering Temporal Structure: An Overview of Hierarchical Reinforcement Learning", "authors": ["Martin Klissarov", "Akhil Bagaria", "Ziyan Luo", "George Konidaris", "Doina Precup", "Marlos C. Machado"], "abstract": "Developing agents capable of exploring, planning and learning in complex open-ended environments is a grand challenge in artificial intelligence (AI). Hierarchical reinforcement learning (HRL) offers a promising solution to this challenge by discovering and exploiting the temporal structure within a stream of experience. The strong appeal of the HRL framework has led to a rich and diverse body of literature attempting to discover a useful structure. However, it is still not clear how one might define what constitutes good structure in the first place, or the kind of problems in which identifying it may be helpful. This work aims to identify the benefits of HRL from the perspective of the fundamental challenges in decision-making, as well as highlight its impact on the performance trade-offs of AI agents. Through these benefits, we then cover the families of methods that discover temporal structure in HRL, ranging from learning directly from online experience to offline datasets, to leveraging large language models (LLMs). Finally, we highlight the challenges of temporal structure discovery and the domains that are particularly well-suited for such endeavours.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.14045.pdf", "abstract_url": "https://arxiv.org/abs/2506.14045", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文概述了分层强化学习（HRL）在发现和利用经验流中的时间结构方面的潜力，探讨了HRL在决策制定中的好处及其对AI代理性能权衡的影响，并介绍了从在线经验学习到利用大型语言模型（LLMs）等多种发现时间结构的方法家族。", "motivation": "解决在复杂开放环境中开发能够探索、规划和学习的AI代理的挑战，以及如何定义和发现有用的时间结构。", "method": "通过分层强化学习（HRL）框架，探索从在线经验学习到离线数据集，再到利用大型语言模型（LLMs）等多种方法来发现时间结构。", "result": "识别了HRL在决策制定中的好处及其对AI代理性能权衡的影响，并概述了多种发现时间结构的方法。", "conclusion": "HRL为解决AI代理在复杂环境中的探索、规划和学习问题提供了有前景的解决方案，但时间结构的发现仍面临挑战，某些领域特别适合此类探索。"}}
{"id": "2506.14079", "title": "FormGym: Doing Paperwork with Agents", "authors": ["Matthew Toles", "Rattandeep Singh", "Isaac Song Zhou Yu"], "abstract": "Completing paperwork is a challenging and time-consuming problem. Form filling is especially challenging in the pure-image domain without access to OCR, typeset PDF text, or a DOM. For computer agents, it requires multiple abilities, including multi-modal understanding, information retrieval, and tool-use. We present a novel form-filling benchmark consisting of 432 fields spread across 55 documents and 3 tasks, requiring knowledge of 236 features per user. We find that baseline VLAs achieve less than 1% accuracy in most cases, primarily due to poor localization ability. GUI agents also struggle, scoring between 10.6-68.0% despite high cost and latency. Therefore, we also contribute FieldFinder, a tool to assist LLMs in identifying where to place text on a form. With FieldFinder, all models achieve equal or better performance in all six study conditions, with a maximum increase from 2% to 56%.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.14079.pdf", "abstract_url": "https://arxiv.org/abs/2506.14079", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "FormGym是一个旨在通过代理完成文书工作的新基准，特别关注纯图像领域的表单填写，提出了FieldFinder工具以提升LLMs在表单上的文本定位能力。", "motivation": "解决在无法访问OCR、排版PDF文本或DOM的纯图像领域中，完成文书工作尤其是表单填写的挑战性和耗时问题。", "method": "提出了一个包含432个字段、55个文档和3个任务的新表单填写基准，并开发了FieldFinder工具来帮助LLMs识别表单上的文本放置位置。", "result": "基线VLAs在大多数情况下的准确率低于1%，GUI代理的得分在10.6-68.0%之间。使用FieldFinder后，所有模型在所有六种研究条件下均达到相同或更好的性能，最大提升从2%到56%。", "conclusion": "FieldFinder显著提高了代理在表单填写任务中的性能，为解决纯图像领域中的表单填写问题提供了有效的工具。"}}
{"id": "2506.14084", "title": "Lightweight Relevance Grader in RAG", "authors": ["Taehee Jeong"], "abstract": "Retrieval-Augmented Generation (RAG) addresses limitations of large language models (LLMs) by leveraging a vector database to provide more accurate and up-to-date information. When a user submits a query, RAG executes a vector search to find relevant documents, which are then used to generate a response. However, ensuring the relevance of retrieved documents with a query would be a big challenge. To address this, a secondary model, known as a relevant grader, can be served to verify its relevance. To reduce computational requirements of a relevant grader, a lightweight small language model is preferred. In this work, we finetuned llama-3.2-1b as a relevant grader and achieved a significant increase in precision from 0.1301 to 0.7750. Its precision is comparable to that of llama-3.1-70b. Our code is available at", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.14084.pdf", "abstract_url": "https://arxiv.org/abs/2506.14084", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种轻量级的相关性评分器（relevance grader），用于改进检索增强生成（RAG）系统中检索文档的相关性。通过微调llama-3.2-1b模型，显著提高了相关性评分的精确度，从0.1301提升至0.7750，且其性能与更大的llama-3.1-70b模型相当。", "motivation": "解决RAG系统中检索文档与查询相关性验证的挑战，减少计算资源需求。", "method": "微调轻量级小语言模型llama-3.2-1b作为相关性评分器。", "result": "相关性评分的精确度从0.1301显著提升至0.7750，与llama-3.1-70b模型性能相当。", "conclusion": "轻量级小语言模型可以作为有效的相关性评分器，在减少计算资源的同时保持高精确度。"}}
{"id": "2506.14246", "title": "Mxplainer: Explain and Learn Insights by Imitating Mahjong Agents", "authors": ["Lingfeng Li", "Yunlong Lu", "Yongyi Wang", "Qifan Zheng", "Wenxin Li"], "abstract": "People need to internalize the skills of AI agents to improve their own capabilities. Our paper focuses on Mahjong, a multiplayer game involving imperfect information and requiring effective long-term decision-making amidst randomness and hidden information. Through the efforts of AI researchers, several impressive Mahjong AI agents have already achieved performance levels comparable to those of professional human players; however, these agents are often treated as black boxes from which few insights can be gleaned. This paper introduces Mxplainer, a parameterized search algorithm that can be converted into an equivalent neural network to learn the parameters of black-box agents. Experiments conducted on AI and human player data demonstrate that the learned parameters provide human-understandable insights into these agents' characteristics and play styles. In addition to analyzing the learned parameters, we also showcase how our search-based framework can locally explain the decision-making processes of black-box agents for most Mahjong game states.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.14246.pdf", "abstract_url": "https://arxiv.org/abs/2506.14246", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了Mxplainer，一种参数化搜索算法，可转换为等效的神经网络以学习黑盒代理的参数，旨在通过模仿麻将代理来解释和学习见解。", "motivation": "解决AI代理作为黑盒难以从中获取见解的问题，帮助人们内化AI代理的技能以提升自身能力。", "method": "使用参数化搜索算法转换为等效的神经网络，学习黑盒代理的参数。", "result": "实验证明，学习到的参数提供了对人类可理解的代理特性和玩法的见解，并能局部解释黑盒代理的决策过程。", "conclusion": "Mxplainer不仅能分析学习到的参数，还能展示其搜索框架如何解释黑盒代理在大多数麻将游戏状态下的决策过程。"}}
{"id": "2506.14580", "title": "GenerationPrograms: Fine-grained Attribution with Executable Programs", "authors": ["David Wan", "Eran Hirsch", "Elias Stengel-Eskin", "Ido Dagan", "Mohit Bansal"], "abstract": "Recent large language models (LLMs) achieve impressive performance in source-conditioned text generation but often fail to correctly provide fine-grained attributions for their outputs, undermining verifiability and trust. Moreover, existing attribution methods do not explain how and why models leverage the provided source documents to generate their final responses, limiting interpretability. To overcome these challenges, we introduce a modular generation framework, GenerationPrograms, inspired by recent advancements in executable \"code agent\" architectures. Unlike conventional generation methods that simultaneously generate outputs and attributions or rely on post-hoc attribution, GenerationPrograms decomposes the process into two distinct stages: first, creating an executable program plan composed of modular text operations (such as paraphrasing, compression, and fusion) explicitly tailored to the query, and second, executing these operations following the program's specified instructions to produce the final response. Empirical evaluations demonstrate that GenerationPrograms significantly improves attribution quality at both the document level and sentence level across two long-form question-answering tasks and a multi-document summarization task. We further demonstrate that GenerationPrograms can effectively function as a post-hoc attribution method, outperforming traditional techniques in recovering accurate attributions. In addition, the interpretable programs generated by GenerationPrograms enable localized refinement through modular-level improvements that further enhance overall attribution quality.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2506.14580.pdf", "abstract_url": "https://arxiv.org/abs/2506.14580", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种模块化生成框架GenerationPrograms，通过将生成过程分解为创建可执行程序计划和执行这些操作两个阶段，显著提高了长形式问答和多文档摘要任务中的归因质量。", "motivation": "解决大型语言模型在源条件文本生成中难以提供细粒度归因的问题，以及现有归因方法无法解释模型如何利用源文档生成最终响应的问题。", "method": "引入模块化生成框架GenerationPrograms，首先生成针对查询的模块化文本操作的可执行程序计划，然后执行这些操作以产生最终响应。", "result": "GenerationPrograms在两个长形式问答任务和一个多文档摘要任务中，显著提高了文档级别和句子级别的归因质量，并能作为后归因方法优于传统技术。", "conclusion": "GenerationPrograms通过其可解释的程序实现了局部细化，进一步提高了整体归因质量，为文本生成提供了更高的可验证性和信任度。"}}
{"id": "2506.14299", "title": "ADRD: LLM-Driven Autonomous Driving Based on Rule-based Decision Systems", "authors": ["Fanzhi Zeng", "Siqi Wang", "Chuzhao Zhu", "Li Li"], "abstract": "How to construct an interpretable autonomous driving decision-making system has become a focal point in academic research. In this study, we propose a novel approach that leverages large language models (LLMs) to generate executable, rule-based decision systems to address this challenge. Specifically, harnessing the strong reasoning and programming capabilities of LLMs, we introduce the ADRD(LLM-Driven Autonomous Driving Based on Rule-based Decision Systems) framework, which integrates three core modules: the Information Module, the Agents Module, and the Testing Module. The framework operates by first aggregating contextual driving scenario information through the Information Module, then utilizing the Agents Module to generate rule-based driving tactics. These tactics are iteratively refined through continuous interaction with the Testing Module. Extensive experimental evaluations demonstrate that ADRD exhibits superior performance in autonomous driving decision tasks. Compared to traditional reinforcement learning approaches and the most advanced LLM-based methods, ADRD shows significant advantages in terms of interpretability, response speed, and driving performance. These results highlight the framework's ability to achieve comprehensive and accurate understanding of complex driving scenarios, and underscore the promising future of transparent, rule-based decision systems that are easily modifiable and broadly applicable. To the best of our knowledge, this is the first work that integrates large language models with rule-based systems for autonomous driving decision-making, and our findings validate its potential for real-world deployment.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.14299.pdf", "abstract_url": "https://arxiv.org/abs/2506.14299", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本研究提出了一种基于大型语言模型（LLMs）的可解释自动驾驶决策系统ADRD，通过整合信息模块、代理模块和测试模块，生成可执行的基于规则的驾驶策略，并在实验中显示出优于传统强化学习和先进LLM方法的性能。", "motivation": "构建可解释的自动驾驶决策系统是学术研究的焦点，本研究旨在利用LLMs的强大推理和编程能力来解决这一挑战。", "method": "ADRD框架通过信息模块聚合驾驶场景信息，代理模块生成基于规则的驾驶策略，并通过测试模块的持续交互迭代优化这些策略。", "result": "ADRD在自动驾驶决策任务中表现出色，尤其在可解释性、响应速度和驾驶性能方面显著优于传统和先进的LLM方法。", "conclusion": "ADRD框架展示了将大型语言模型与基于规则的系统相结合在自动驾驶决策中的潜力，验证了其实际部署的可能性。"}}
{"id": "2506.14336", "title": "AviationLLM: An LLM-based Knowledge System for Aviation Training", "authors": ["Jia'ang Wan", "Feng Shen", "Fujuan Li", "Yanjin Sun", "Yan Li", "Shiwen Zhang"], "abstract": "Aviation training is a core link in ensuring flight safety, improving industry efficiency and promoting sustainable development. It not only involves flight simulation but also requires the learning of a great deal of professional aviation theory knowledge. In the existing training system, the knowledge is mainly imparted by the the instructors. However, the number of instructors is limited and the professional answers obtained from the Internet are not accurate enough, resulting in low training efficiency. To address this, we introduced LLM, but the basic pre-trained model cannot provide accurate answers to professional fields, so we fine-tuned it. Traditional Supervised Fine-Tuning (SFT) risk generating superficially plausible but factually incorrect responses due to insufficient data coverage. To address this, we employ Direct Preference Optimization(DPO). This paper proposes Retrieval-Augmented LLM Alignment via Direct Preference Optimization(RALA-DPO). We select open source pre-trained LLM Qwen and adapt it to aviation theory training through DPO-based domain alignment. Simultaneously, to mitigate hallucinations caused by training data biases, knowledge obsolescence, or domain knowledge gaps, we implement Retrieval-Augmented Generation(RAG) technology that combines generative and retrieval models. RALA-DPO effectively retrieves relevant information from external knowledge bases and delivers precise and high-quality responses through the generative model. Experimental results demonstrate that RALA-DPO can improve accuracy in response to professional aviation knowledge. With integrated RAG mechanisms, this system can further improve the accuracy of answers and achieve zero-cost knowledge updates simultaneously.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.14336.pdf", "abstract_url": "https://arxiv.org/abs/2506.14336", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种基于LLM的航空培训知识系统AviationLLM，通过直接偏好优化(DPO)和检索增强生成(RAG)技术，提高了对专业航空知识回答的准确性。", "motivation": "解决现有航空培训体系中，由于教练数量有限和互联网专业答案不准确导致的培训效率低下问题。", "method": "采用基于DPO的领域对齐方法对开源预训练LLM Qwen进行微调，并结合RAG技术以减少幻觉现象。", "result": "实验结果表明，RALA-DPO能够提高对专业航空知识回答的准确性，并通过集成的RAG机制进一步改善答案的准确性，同时实现零成本知识更新。", "conclusion": "RALA-DPO系统通过结合生成和检索模型，有效提高了航空理论培训的效率和准确性，为航空培训领域提供了一种创新的解决方案。"}}
{"id": "2506.14496", "title": "LLM-Powered Swarms: A New Frontier or a Conceptual Stretch?", "authors": ["Muhammad Atta Ur Rahman", "Melanie Schranz"], "abstract": "Swarm intelligence traditionally refers to systems of simple, decentralized agents whose local interactions lead to emergent, collective behavior. Recently, the term 'swarm' has been extended to describe AI systems like OpenAI's Swarm, where large language models (LLMs) act as collaborative agents. This paper contrasts traditional swarm algorithms with LLM-driven swarms exploring how decentralization, scalability, and emergence are redefined in modern artificial intelligence (AI). We implement and compare both paradigms using Boids and Ant Colony Optimization (ACO), evaluating latency, resource usage, and behavioral accuracy. The suitability of both cloud-based and local LLMs is assessed for the agent-based use in swarms. Although LLMs offer powerful reasoning and abstraction capabilities, they introduce new constraints in computation and coordination that challenge traditional notions of swarm design. This study highlights the opportunities and limitations of integrating LLMs into swarm systems and discusses the evolving definition of 'swarm' in modern AI research.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "This is the author's version of a paper submitted to IEEE Intelligent Systems. 6 Tables, 3 Figures", "pdf_url": "https://arxiv.org/pdf/2506.14496.pdf", "abstract_url": "https://arxiv.org/abs/2506.14496", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了传统群智能算法与基于大型语言模型（LLM）的群系统之间的对比，评估了它们在延迟、资源使用和行为准确性方面的表现，并讨论了在现代AI研究中‘群’定义的演变。", "motivation": "解决传统群智能算法与基于LLM的群系统之间的差异和潜在整合问题，探索在现代AI中‘群’概念的新定义。", "method": "通过实现和比较Boids和蚁群优化（ACO）两种范式，评估了基于云和本地的LLM在群系统中的适用性。", "result": "虽然LLM提供了强大的推理和抽象能力，但它们在计算和协调方面引入了新的约束，挑战了传统群设计的观念。", "conclusion": "研究强调了将LLM整合到群系统中的机会和限制，并讨论了现代AI研究中‘群’定义的演变。"}}
{"id": "2506.14477", "title": "GUI-Robust: A Comprehensive Dataset for Testing GUI Agent Robustness in Real-World Anomalies", "authors": ["Jingqi Yang", "Zhilong Song", "Jiawei Chen", "Mingli Song", "Sheng Zhou", "linjun sun", "Xiaogang Ouyang", "Chun Chen", "Can Wang"], "abstract": "The development of high-quality datasets is crucial for benchmarking and advancing research in Graphical User Interface (GUI) agents. Despite their importance, existing datasets are often constructed under idealized conditions, overlooking the diverse anomalies frequently encountered in real-world deployments. To address this limitation, we introduce GUI-Robust, a novel dataset designed for comprehensive GUI agent evaluation, explicitly incorporating seven common types of anomalies observed in everyday GUI interactions. Furthermore, we propose a semi-automated dataset construction paradigm that collects user action sequences from natural interactions via RPA tools and then generate corresponding step and task descriptions for these actions with the assistance of MLLMs. This paradigm significantly reduces annotation time cost by a factor of over 19 times. Finally, we assess state-of-the-art GUI agents using the GUI-Robust dataset, revealing their substantial performance degradation in abnormal scenarios. We anticipate that our work will highlight the importance of robustness in GUI agents and inspires more future research in this direction. The dataset and code are available at", "subjects": "Artificial Intelligence (cs.AI)", "comments": "10 pages, 4 figures, submitted to NIPS 2025", "pdf_url": "https://arxiv.org/pdf/2506.14477.pdf", "abstract_url": "https://arxiv.org/abs/2506.14477", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了GUI-Robust，一个专为全面评估GUI代理而设计的新数据集，该数据集明确包含了日常GUI交互中观察到的七种常见异常类型。同时，提出了一种半自动化的数据集构建范式，显著减少了注释时间成本。", "motivation": "现有的GUI代理数据集通常在理想化条件下构建，忽略了现实世界部署中常见的多样异常，这限制了GUI代理的鲁棒性研究。", "method": "采用半自动化的数据集构建范式，通过RPA工具收集自然交互中的用户动作序列，并利用MLLMs为这些动作生成相应的步骤和任务描述。", "result": "使用GUI-Robust数据集评估最先进的GUI代理，揭示了它们在异常场景中的显著性能下降。", "conclusion": "GUI-Robust数据集强调了GUI代理鲁棒性的重要性，并有望激发未来在这一方向的更多研究。"}}
{"id": "2506.14502", "title": "Toward Safety-First Human-Like Decision Making for Autonomous Vehicles in Time-Varying Traffic Flow", "authors": ["Xiao Wang", "Junru Yu", "Jun Huang", "Qiong Wu", "Ljubo Vacic", "Changyin Sun"], "abstract": "Despite the recent advancements in artificial intelligence technologies have shown great potential in improving transport efficiency and safety, autonomous vehicles(AVs) still face great challenge of driving in time-varying traffic flow, especially in dense and interactive situations. Meanwhile, human have free wills and usually do not make the same decisions even situate in the exactly same scenarios, leading to the data-driven methods suffer from poor migratability and high search cost problems, decreasing the efficiency and effectiveness of the behavior policy. In this research, we propose a safety-first human-like decision-making framework(SF-HLDM) for AVs to drive safely, comfortably, and social compatiblely in effiency. The framework integrates a hierarchical progressive framework, which combines a spatial-temporal attention (S-TA) mechanism for other road users' intention inference, a social compliance estimation module for behavior regulation, and a Deep Evolutionary Reinforcement Learning(DERL) model for expanding the search space efficiently and effectively to make avoidance of falling into the local optimal trap and reduce the risk of overfitting, thus make human-like decisions with interpretability and flexibility. The SF-HLDM framework enables autonomous driving AI agents dynamically adjusts decision parameters to maintain safety margins and adhering to contextually appropriate driving behaviors at the same time.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.14502.pdf", "abstract_url": "https://arxiv.org/abs/2506.14502", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种安全第一的类人决策框架（SF-HLDM），用于自动驾驶车辆在时变交通流中安全、舒适且社会兼容地驾驶。该框架结合了空间-时间注意力机制、社会合规性估计模块和深度进化强化学习模型，以提高决策的效率和效果。", "motivation": "自动驾驶车辆在密集和交互性强的时变交通流中驾驶仍面临巨大挑战，且人类驾驶行为的自由意志导致数据驱动方法存在迁移性差和搜索成本高的问题，影响了行为策略的效率和效果。", "method": "提出了一个结合空间-时间注意力（S-TA）机制、社会合规性估计模块和深度进化强化学习（DERL）模型的分层渐进框架，以高效有效地扩展搜索空间，避免陷入局部最优陷阱和过拟合风险。", "result": "SF-HLDM框架使自动驾驶AI代理能够动态调整决策参数，保持安全边际，同时遵守情境适当的驾驶行为，实现具有可解释性和灵活性的类人决策。", "conclusion": "该研究为自动驾驶车辆在复杂交通环境中的决策提供了一种安全第一、类人化的解决方案，有望提高自动驾驶的安全性和社会兼容性。"}}
{"id": "2506.13778", "title": "Knowledge Compression via Question Generation: Enhancing Multihop Document Retrieval without Fine-tuning", "authors": ["Anvi Alex Eponon", "Moein Shahiki-Tash", "Ildar Batyrshin", "Christian E. Maldonado-Sifuentes", "Grigori Sidorov", "Alexander Gelbukh"], "abstract": "This study presents a question-based knowledge encoding approach that improves retrieval-augmented generation (RAG) systems without requiring fine-tuning or traditional chunking. We encode textual content using generated questions that span the lexical and semantic space, creating targeted retrieval cues combined with a custom syntactic reranking method.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.13778.pdf", "abstract_url": "https://arxiv.org/abs/2506.13778", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本研究提出了一种基于问题的知识编码方法，旨在无需微调或传统分块的情况下，改进检索增强生成（RAG）系统。通过生成跨越词汇和语义空间的问题来编码文本内容，结合自定义的句法重新排序方法，创建有针对性的检索线索。", "motivation": "解决检索增强生成（RAG）系统在无需微调或传统分块的情况下，如何更有效地检索和利用文档信息的问题。", "method": "采用基于问题的知识编码方法，生成跨越词汇和语义空间的问题来编码文本内容，并结合自定义的句法重新排序方法。", "result": "提出的方法能够创建有针对性的检索线索，从而提高多跳文档检索的效率，无需进行模型微调。", "conclusion": "通过问题生成进行知识压缩的方法，为多跳文档检索提供了一种有效的解决方案，无需依赖模型微调或传统分块技术，具有广泛的应用潜力。"}}
{"id": "2506.14539", "title": "Doppelgänger Method: Breaking Role Consistency in LLM Agent via Prompt-based Transferable Adversarial Attack", "authors": ["Daewon Kang", "YeongHwan Shin", "Doyeon Kim", "Kyu-Hwan Jung", "Meong Hi Son"], "abstract": "Since the advent of large language models, prompt engineering now enables the rapid, low-effort creation of diverse autonomous agents that are already in widespread use. Yet this convenience raises urgent concerns about the safety, robustness, and behavioral consistency of the underlying prompts, along with the pressing challenge of preventing those prompts from being exposed to user's attempts. In this paper, we propose the ''Doppelgänger method'' to demonstrate the risk of an agent being hijacked, thereby exposing system instructions and internal information. Next, we define the ''Prompt Alignment Collapse under Adversarial Transfer (PACAT)'' level to evaluate the vulnerability to this adversarial transfer attack. We also propose a ''Caution for Adversarial Transfer (CAT)'' prompt to counter the Doppelgänger method. The experimental results demonstrate that the Doppelgänger method can compromise the agent's consistency and expose its internal information. In contrast, CAT prompts enable effective defense against this adversarial attack.", "subjects": "Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.14539.pdf", "abstract_url": "https://arxiv.org/abs/2506.14539", "categories": ["Artificial Intelligence (cs.AI)", "Cryptography and Security (cs.CR)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了'替身方法'来展示大型语言模型代理被劫持的风险，定义了'对抗性转移下的提示对齐崩溃（PACAT）'级别来评估这种攻击的脆弱性，并提出'对抗性转移警告（CAT）'提示作为防御手段。实验证明替身方法能破坏代理的一致性并暴露其内部信息，而CAT提示能有效防御此类攻击。", "motivation": "随着大型语言模型的出现，提示工程使得快速、低努力地创建多样化的自主代理成为可能，但这些代理的安全性、健壮性和行为一致性引发了紧迫的担忧，尤其是如何防止提示被用户尝试暴露。", "method": "提出了'替身方法'来演示代理被劫持的风险，定义了PACAT级别来评估脆弱性，并提出了CAT提示作为防御手段。", "result": "实验结果表明，替身方法能够破坏代理的一致性并暴露其内部信息，而CAT提示能够有效防御这种对抗性攻击。", "conclusion": "本文通过替身方法和PACAT级别的定义，揭示了大型语言模型代理在对抗性转移攻击下的脆弱性，并提出CAT提示作为一种有效的防御策略，为提升代理的安全性和健壮性提供了新的思路。"}}
{"id": "2506.13811", "title": "Investigating the Potential of Large Language Model-Based Router Multi-Agent Architectures for Foundation Design Automation: A Task Classification and Expert Selection Study", "authors": ["Sompote Youwai", "David Phim", "Vianne Gayl Murcia", "Rianne Clair Onas"], "abstract": "This study investigates router-based multi-agent systems for automating foundation design calculations through intelligent task classification and expert selection. Three approaches were evaluated: single-agent processing, multi-agent designer-checker architecture, and router-based expert selection. Performance assessment utilized baseline models including DeepSeek R1, ChatGPT 4 Turbo, Grok 3, and Gemini 2.5 Pro across shallow foundation and pile design scenarios. The router-based configuration achieved performance scores of 95.00% for shallow foundations and 90.63% for pile design, representing improvements of 8.75 and 3.13 percentage points over standalone Grok 3 performance respectively. The system outperformed conventional agentic workflows by 10.0 to 43.75 percentage points. Grok 3 demonstrated superior standalone performance without external computational tools, indicating advances in direct LLM mathematical reasoning for engineering applications. The dual-tier classification framework successfully distinguished foundation types, enabling appropriate analytical approaches. Results establish router-based multi-agent systems as optimal for foundation design automation while maintaining professional documentation standards. Given safety-critical requirements in civil engineering, continued human oversight remains essential, positioning these systems as advanced computational assistance tools rather than autonomous design replacements in professional practice.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.13811.pdf", "abstract_url": "https://arxiv.org/abs/2506.13811", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本研究探讨了基于路由器多智能体系统在自动化基础设计计算中的应用，通过智能任务分类和专家选择，评估了三种方法，并展示了路由器配置在浅基础和桩设计中的优越性能。", "motivation": "解决基础设计自动化中的任务分类和专家选择问题，以提高设计计算的效率和准确性。", "method": "评估了单智能体处理、多智能体设计-检查架构和基于路由器的专家选择三种方法，使用了包括DeepSeek R1、ChatGPT 4 Turbo、Grok 3和Gemini 2.5 Pro在内的基线模型。", "result": "基于路由器的配置在浅基础和桩设计中分别达到了95.00%和90.63%的性能分数，优于传统工作流程和独立模型。", "conclusion": "基于路由器的多智能体系统为基础设计自动化提供了最优解决方案，同时强调了在土木工程中继续人类监督的必要性。"}}
{"id": "2506.14728", "title": "AgentDistill: Training-Free Agent Distillation with Generalizable MCP Boxes", "authors": ["Jiahao Qiu", "Xinzhe Juan", "Yimin Wang", "Ling Yang", "Xuan Qi", "Tongcheng Zhang", "Jiacheng Guo", "Yifu Lu", "Zixin Yao", "Hongru Wang", "Shilong Liu", "Xun Jiang", "Liu Leqi", "Mengdi Wang"], "abstract": "While knowledge distillation has become a mature field for compressing large language models (LLMs) into smaller ones by aligning their outputs or internal representations, the distillation of LLM-based agents, which involve planning, memory, and tool use, remains relatively underexplored. Existing agent distillation methods typically replay full teacher trajectories or imitate step-by-step teacher tool usage, but they often struggle to train student agents to dynamically plan and act in novel environments. We propose AgentDistill, a novel, training-free agent distillation framework that enables efficient and scalable knowledge transfer via direct reuse of Model-Context-Protocols (MCPs), which are structured and reusable task-solving modules autonomously generated by teacher agents. The reuse of these distilled MCPs enables student agents to generalize their capabilities across domains and solve new problems with minimal supervision or human intervention. Experiments on biomedical and mathematical benchmarks demonstrate that our distilled student agents, built on small language models, can achieve performance comparable to advanced systems using large LLMs such as OctoTools (GPT-4o), highlighting the effectiveness of our framework in building scalable and cost-efficient intelligent agents.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "10 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2506.14728.pdf", "abstract_url": "https://arxiv.org/abs/2506.14728", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种无需训练的代理蒸馏框架AgentDistill，通过直接重用教师代理自主生成的结构化和可重用的任务解决模块（MCPs），实现了高效和可扩展的知识转移。", "motivation": "尽管知识蒸馏在将大型语言模型（LLMs）压缩成较小模型方面已成熟，但基于LLM的代理（涉及规划、记忆和工具使用）的蒸馏仍相对未被充分探索。现有方法通常重放完整的教师轨迹或模仿逐步的教师工具使用，但难以训练学生代理在新环境中动态规划和行动。", "method": "提出了AgentDistill，一种无需训练的代理蒸馏框架，通过直接重用教师代理自主生成的Model-Context-Protocols（MCPs）模块，实现知识转移。", "result": "在生物医学和数学基准测试中，基于小语言模型的蒸馏学生代理能够达到与使用大型LLMs（如GPT-4o的OctoTools）的高级系统相媲美的性能。", "conclusion": "AgentDistill框架在构建可扩展和成本效益高的智能代理方面表现出高效性，使学生代理能够在最小监督或人工干预下跨领域泛化其能力并解决新问题。"}}
{"id": "2506.13782", "title": "XGraphRAG: Interactive Visual Analysis for Graph-based Retrieval-Augmented Generation", "authors": ["Ke Wang", "Bo Pan", "Yingchaojie Feng", "Yuwei Wu", "Jieyi Chen", "Minfeng Zhu", "Wei Chen"], "abstract": "Graph-based Retrieval-Augmented Generation (RAG) has shown great capability in enhancing Large Language Model (LLM)'s answer with an external knowledge base. Compared to traditional RAG, it introduces a graph as an intermediate representation to capture better structured relational knowledge in the corpus, elevating the precision and comprehensiveness of generation results. However, developers usually face challenges in analyzing the effectiveness of GraphRAG on their dataset due to GraphRAG's complex information processing pipeline and the overwhelming amount of LLM invocations involved during graph construction and query, which limits GraphRAG interpretability and accessibility. This research proposes a visual analysis framework that helps RAG developers identify critical recalls of GraphRAG and trace these recalls through the GraphRAG pipeline. Based on this framework, we develop XGraphRAG, a prototype system incorporating a set of interactive visualizations to facilitate users' analysis process, boosting failure cases collection and improvement opportunities identification. Our evaluation demonstrates the effectiveness and usability of our approach. Our work is open-sourced and available at", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "comments": "Accepted to IEEE Pacific Visualization Conference 2025", "pdf_url": "https://arxiv.org/pdf/2506.13782.pdf", "abstract_url": "https://arxiv.org/abs/2506.13782", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了XGraphRAG，一个交互式视觉分析框架，旨在帮助开发者分析和改进基于图的检索增强生成（GraphRAG）的效果。通过可视化工具，开发者能够追踪GraphRAG管道中的关键召回，从而提升生成结果的准确性和全面性。", "motivation": "GraphRAG通过引入图作为中间表示来增强大型语言模型（LLM）的回答，但其复杂的信息处理流程和大量的LLM调用限制了其可解释性和可访问性。开发者难以分析GraphRAG在其数据集上的有效性。", "method": "研究提出了一个视觉分析框架，并开发了原型系统XGraphRAG，该系统包含一组交互式可视化工具，以帮助用户分析GraphRAG的召回情况，并识别改进机会。", "result": "评估表明，该方法在提升GraphRAG的失败案例收集和改进机会识别方面具有有效性和可用性。", "conclusion": "XGraphRAG通过交互式视觉分析提高了GraphRAG的可解释性和可访问性，为开发者提供了强大的工具来优化基于图的检索增强生成过程。"}}
{"id": "2506.13800", "title": "Enhancing Clinical Decision Support and EHR Insights through LLMs and the Model Context Protocol: An Open-Source MCP-FHIR Framework", "authors": ["Abul Ehtesham", "Aditi Singh", "Saket Kumar"], "abstract": "Enhancing clinical decision support (CDS), reducing documentation burdens, and improving patient health literacy remain persistent challenges in digital health. This paper presents an open-source, agent-based framework that integrates Large Language Models (LLMs) with HL7 FHIR data via the Model Context Protocol (MCP) for dynamic extraction and reasoning over electronic health records (EHRs). Built on the established MCP-FHIR implementation, the framework enables declarative access to diverse FHIR resources through JSON-based configurations, supporting real-time summarization, interpretation, and personalized communication across multiple user personas, including clinicians, caregivers, and patients. To ensure privacy and reproducibility, the framework is evaluated using synthetic EHR data from the SMART Health IT sandbox (", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.13800.pdf", "abstract_url": "https://arxiv.org/abs/2506.13800", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种开源、基于代理的框架，通过模型上下文协议（MCP）将大型语言模型（LLMs）与HL7 FHIR数据集成，以动态提取和推理电子健康记录（EHRs），旨在增强临床决策支持（CDS）、减轻文档负担并提高患者健康素养。", "motivation": "解决数字健康领域中临床决策支持（CDS）的增强、文档负担的减轻以及患者健康素养的提高等持续挑战。", "method": "开发了一个基于MCP-FHIR实现的开源框架，支持通过JSON配置声明性访问多样化的FHIR资源，实现实时总结、解释和跨多用户角色（包括临床医生、护理人员和患者）的个性化沟通。", "result": "框架使用SMART Health IT沙箱中的合成EHR数据进行评估，确保了隐私和可重复性。", "conclusion": "该框架为增强临床决策支持、减轻医疗文档负担及提升患者健康素养提供了一种有效的方法，同时保障了隐私和可重复性。"}}
{"id": "2506.13817", "title": "DeepSeq: High-Throughput Single-Cell RNA Sequencing Data Labeling via Web Search-Augmented Agentic Generative AI Foundation Models", "authors": ["Saleem A. Al Dajani", "Abel Sanchez", "John R. Williams"], "abstract": "Generative AI foundation models offer transformative potential for processing structured biological data, particularly in single-cell RNA sequencing, where datasets are rapidly scaling toward billions of cells. We propose the use of agentic foundation models with real-time web search to automate the labeling of experimental data, achieving up to 82.5% accuracy. This addresses a key bottleneck in supervised learning for structured omics data by increasing annotation throughput without manual curation and human error. Our approach enables the development of virtual cell foundation models capable of downstream tasks such as cell-typing and perturbation prediction. As data volume grows, these models may surpass human performance in labeling, paving the way for reliable inference in large-scale perturbation screens. This application demonstrates domain-specific innovation in health monitoring and diagnostics, aligned with efforts like the Human Cell Atlas and Human Tumor Atlas Network.", "subjects": "Genomics (q-bio.GN); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Software Engineering (cs.SE); Quantitative Methods (q-bio.QM)", "comments": ". Workshop on Multi-modal Foundation Models and Large Language Models for Life Sciences (FM4LS)}, July 2025", "pdf_url": "https://arxiv.org/pdf/2506.13817.pdf", "abstract_url": "https://arxiv.org/abs/2506.13817", "categories": ["Genomics (q-bio.GN)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Software Engineering (cs.SE)", "Quantitative Methods (q-bio.QM)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种名为DeepSeq的方法，利用增强型生成AI基础模型和实时网络搜索来自动标记单细胞RNA测序数据，准确率高达82.5%。", "motivation": "解决单细胞RNA测序数据在监督学习中标注效率低和人为错误的问题。", "method": "使用代理基础模型结合实时网络搜索自动化标注实验数据。", "result": "实现了高达82.5%的标注准确率，支持下游任务如细胞分型和扰动预测。", "conclusion": "随着数据量的增长，这些模型可能在标注上超越人类性能，为大规模扰动筛查中的可靠推断铺平道路。"}}
{"id": "2506.13805", "title": "Dr. GPT Will See You Now, but Should It? Exploring the Benefits and Harms of Large Language Models in Medical Diagnosis using Crowdsourced Clinical Cases", "authors": ["Bonam Mingole", "Aditya Majumdar", "Firdaus Ahmed Choudhury", "Jennifer L. Kraschnewski", "Shyam S. Sundar", "Amulya Yadav"], "abstract": "The proliferation of Large Language Models (LLMs) in high-stakes applications such as medical (self-)diagnosis and preliminary triage raises significant ethical and practical concerns about the effectiveness, appropriateness, and possible harmfulness of the use of these technologies for health-related concerns and queries. Some prior work has considered the effectiveness of LLMs in answering expert-written health queries/prompts, questions from medical examination banks, or queries based on pre-existing clinical cases. Unfortunately, these existing studies completely ignore an in-the-wild evaluation of the effectiveness of LLMs in answering everyday health concerns and queries typically asked by general users, which corresponds to the more prevalent use case for LLMs. To address this research gap, this paper presents the findings from a university-level competition that leveraged a novel, crowdsourced approach for evaluating the effectiveness of LLMs in answering everyday health queries. Over the course of a week, a total of 34 participants prompted four publicly accessible LLMs with 212 real (or imagined) health concerns, and the LLM generated responses were evaluated by a team of nine board-certified physicians. At a high level, our findings indicate that on average, 76% of the 212 LLM responses were deemed to be accurate by physicians. Further, with the help of medical professionals, we investigated whether RAG versions of these LLMs (powered with a comprehensive medical knowledge base) can improve the quality of responses generated by LLMs. Finally, we also derive qualitative insights to explain our quantitative findings by conducting interviews with seven medical professionals who were shown all the prompts in our competition. This paper aims to provide a more grounded understanding of how LLMs perform in real-world everyday health communication.", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.13805.pdf", "abstract_url": "https://arxiv.org/abs/2506.13805", "categories": ["Computers and Society (cs.CY)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文探讨了大型语言模型（LLMs）在医疗诊断中的利弊，通过众包临床案例评估其在日常健康咨询中的效果。研究发现，76%的LLM回答被医生认为准确，并探讨了结合医学知识库是否能提升回答质量。", "motivation": "解决现有研究忽略LLMs在日常健康咨询中实际效果的问题，评估其在真实世界健康沟通中的表现。", "method": "利用大学级别竞赛，收集34名参与者对4个公开LLMs的212个健康咨询，由9名认证医生评估回答准确性，并探讨RAG版本LLMs的效果。", "result": "76%的LLM回答被医生评为准确，RAG版本LLMs可能提升回答质量。", "conclusion": "LLMs在日常健康咨询中表现良好，但需进一步研究以优化其在医疗领域的应用。"}}
{"id": "2506.13932", "title": "How Does LLM Reasoning Work for Code? A Survey and a Call to Action", "authors": ["Ira Ceka", "Saurabh Pujar", "Irene Manotas", "Gail Kaiser", "Baishakhi Ray", "Shyam Ramji"], "abstract": "The rise of large language models (LLMs) has led to dramatic improvements across a wide range of natural language tasks. These advancements have extended into the domain of code, facilitating complex tasks such as code generation, translation, summarization, and repair. However, their utility for real-world deployment in-the-wild has only recently been studied, particularly on software engineering (SWE) tasks such as GitHub issue resolution. In this study, we examine the code reasoning techniques that underlie the ability to perform such tasks, and examine the paradigms used to drive their performance. Our contributions in this paper are: (1) the first dedicated survey on code reasoning for code tasks, highlighting overarching strategies, hybrid and agentic approaches; (2) a taxonomy of various techniques used to drive code reasoning; (3) a comprehensive overview of performance on common benchmarks and a showcase of new, under-explored benchmarks with high potential in SWE; (4) an exploration on how core properties of code can be used to explain different reasoning techniques; and (5) gaps and potentially under-explored areas for future research.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.13932.pdf", "abstract_url": "https://arxiv.org/abs/2506.13932", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文调查了大型语言模型（LLMs）在代码任务中的推理技术，提出了代码推理的首次专门调查，包括策略、混合和代理方法，建立了技术分类，概述了常见基准性能，并探讨了代码核心属性如何解释不同推理技术，以及未来研究的潜在领域。", "motivation": "大型语言模型在自然语言任务上的显著进步已扩展到代码领域，支持代码生成、翻译、总结和修复等复杂任务。然而，它们在现实世界软件工程任务中的实际应用效用最近才开始研究。本研究旨在探讨支持这些任务的代码推理技术及其性能驱动范式。", "method": "研究通过首次专门调查代码推理，突出总体策略、混合和代理方法，建立技术分类，全面概述常见基准性能，并展示软件工程中具有高潜力的新基准，探讨代码核心属性如何解释不同推理技术。", "result": "研究提出了代码推理的首次专门调查，建立了技术分类，概述了性能基准，并展示了新基准的潜力，探讨了代码属性与推理技术的关系，指出了未来研究的空白和潜在领域。", "conclusion": "本研究为理解LLMs在代码任务中的推理提供了全面视角，指出了当前研究的不足和未来探索的方向，对推动代码推理技术的发展具有重要意义。"}}
{"id": "2506.14159", "title": "StorySage: Conversational Autobiography Writing Powered by a Multi-Agent Framework", "authors": ["Shayan Talaei", "Meijin Li", "Kanu Grover", "James Kent Hippler", "Diyi Yang", "Amin Saberi"], "abstract": "Every individual carries a unique and personal life story shaped by their memories and experiences. However, these memories are often scattered and difficult to organize into a coherent narrative, a challenge that defines the task of autobiography writing. Existing conversational writing assistants tend to rely on generic user interactions and pre-defined guidelines, making it difficult for these systems to capture personal memories and develop a complete biography over time. We introduce StorySage, a user-driven software system designed to meet the needs of a diverse group of users that supports a flexible conversation and a structured approach to autobiography writing. Powered by a multi-agent framework composed of an Interviewer, Session Scribe, Planner, Section Writer, and Session Coordinator, our system iteratively collects user memories, updates their autobiography, and plans for future conversations. In experimental simulations, StorySage demonstrates its ability to navigate multiple sessions and capture user memories across many conversations. User studies (N=28) highlight how StorySage maintains improved conversational flow, narrative completeness, and higher user satisfaction when compared to a baseline. In summary, StorySage contributes both a novel architecture for autobiography writing and insights into how multi-agent systems can enhance human-AI creative partnerships.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.14159.pdf", "abstract_url": "https://arxiv.org/abs/2506.14159", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "StorySage是一个基于多代理框架的对话式自传写作系统，旨在帮助用户组织和记录个人记忆，形成连贯的自传。", "motivation": "解决个人记忆分散难以组织成连贯自传的问题，现有对话写作助手依赖通用交互和预定义指南，难以捕捉个人记忆并随时间发展完整传记。", "method": "采用多代理框架，包括采访者、会话记录员、规划者、章节作者和会话协调员，迭代收集用户记忆，更新自传并规划未来对话。", "result": "实验模拟显示StorySage能够跨多次会话导航并捕捉用户记忆；用户研究（N=28）表明，与基线相比，StorySage在对话流畅性、叙事完整性和用户满意度方面表现更优。", "conclusion": "StorySage不仅为自传写作提供了一种新颖的架构，还揭示了多代理系统如何增强人类与AI的创造性合作。"}}
{"id": "2506.14411", "title": "Adaptive Reinforcement Learning for Unobservable Random Delays", "authors": ["John Wikman", "Alexandre Proutiere", "David Broman"], "abstract": "In standard Reinforcement Learning (RL) settings, the interaction between the agent and the environment is typically modeled as a Markov Decision Process (MDP), which assumes that the agent observes the system state instantaneously, selects an action without delay, and executes it immediately. In real-world dynamic environments, such as cyber-physical systems, this assumption often breaks down due to delays in the interaction between the agent and the system. These delays can vary stochastically over time and are typically unobservable, meaning they are unknown when deciding on an action. Existing methods deal with this uncertainty conservatively by assuming a known fixed upper bound on the delay, even if the delay is often much lower. In this work, we introduce the interaction layer, a general framework that enables agents to adaptively and seamlessly handle unobservable and time-varying delays. Specifically, the agent generates a matrix of possible future actions to handle both unpredictable delays and lost action packets sent over networks. Building on this framework, we develop a model-based algorithm, Actor-Critic with Delay Adaptation (ACDA), which dynamically adjusts to delay patterns. Our method significantly outperforms state-of-the-art approaches across a wide range of locomotion benchmark environments.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.14411.pdf", "abstract_url": "https://arxiv.org/abs/2506.14411", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为'交互层'的通用框架，使强化学习（RL）代理能够自适应且无缝地处理不可观察和时变的延迟。基于此框架，开发了一种基于模型的算法ACDA，动态调整以适应延迟模式，显著优于现有方法。", "motivation": "在现实世界的动态环境中，如网络物理系统，代理与系统之间的交互延迟会随机变化且通常不可观察，这打破了标准RL设置中的马尔可夫决策过程（MDP）假设。现有方法保守地假设延迟有一个已知的固定上限，即使延迟通常低得多。", "method": "引入交互层框架，代理生成可能的未来动作矩阵以处理不可预测的延迟和网络中丢失的动作包。基于此框架，开发了模型基于的算法ACDA，动态调整以适应延迟模式。", "result": "ACDA算法在一系列运动基准环境中显著优于现有最先进的方法。", "conclusion": "通过交互层框架和ACDA算法，本文为解决RL中不可观察和时变延迟的问题提供了一种有效的方法，具有广泛的应用潜力。"}}
{"id": "2506.14412", "title": "RAGtifier: Evaluating RAG Generation Approaches of State-of-the-Art RAG Systems for the SIGIR LiveRAG Competition", "authors": ["Tim Cofala", "Oleh Astappiev", "William Xion", "Hailay Teklehaymanot"], "abstract": "Retrieval-Augmented Generation (RAG) enriches Large Language Models (LLMs) by combining their internal, parametric knowledge with external, non-parametric sources, with the goal of improving factual correctness and minimizing hallucinations. The LiveRAG 2025 challenge explores RAG solutions to maximize accuracy on DataMorgana's QA pairs, which are composed of single-hop and multi-hop questions. The challenge provides access to sparse OpenSearch and dense Pinecone indices of the Fineweb 10BT dataset. It restricts model use to LLMs with up to 10B parameters and final answer generation with Falcon-3-10B. A judge-LLM assesses the submitted answers along with human evaluators. By exploring distinct retriever combinations and RAG solutions under the challenge conditions, our final solution emerged using InstructRAG in combination with a Pinecone retriever and a BGE reranker. Our solution achieved a correctness score of 1.13 and a faithfulness score of 0.55, placing fourth in the SIGIR 2025 LiveRAG Challenge.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "4 pages, 5 figures. Report for SIGIR 2025 LiveRAG Challenge", "pdf_url": "https://arxiv.org/pdf/2506.14412.pdf", "abstract_url": "https://arxiv.org/abs/2506.14412", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了RAGtifier系统，该系统在SIGIR LiveRAG竞赛中评估了最先进的RAG生成方法，旨在通过结合内部参数知识和外部非参数源来提高LLMs的事实正确性并减少幻觉。", "motivation": "解决大型语言模型(LLMs)在事实正确性方面的不足，并通过检索增强生成(RAG)技术减少幻觉现象。", "method": "使用InstructRAG结合Pinecone检索器和BGE重新排序器，在LiveRAG 2025挑战的条件下探索不同的检索器组合和RAG解决方案。", "result": "最终解决方案在SIGIR 2025 LiveRAG挑战中获得了1.13的正确性得分和0.55的忠实度得分，排名第四。", "conclusion": "研究表明，结合特定检索器和重新排序器的RAG解决方案可以有效提高LLMs的准确性和忠实度，尽管在竞赛中排名第四，但仍显示出RAG技术的潜力。"}}
{"id": "2506.14456", "title": "Hamiltonian Formalism for Comparing Quantum and Classical Intelligence", "authors": ["Elija Perrier"], "abstract": "The prospect of AGI instantiated on quantum substrates motivates the development of mathematical frameworks that enable direct comparison of their operation in classical and quantum environments. To this end, we introduce a Hamiltonian formalism for describing classical and quantum AGI tasks as a means of contrasting their interaction with the environment. We propose a decomposition of AGI dynamics into Hamiltonian generators for core functions such as induction, reasoning, recursion, learning, measurement, and memory. This formalism aims to contribute to the development of a precise mathematical language for how quantum and classical agents differ via environmental interaction.", "subjects": "Quantum Physics (quant-ph); Artificial Intelligence (cs.AI)", "comments": "This is the version accepted at AGI 25 (camera ready length limit of 10 pages plus references and appendices). Further work detailing bounds and limitations is in preparation. Comments and criticisms welcome", "pdf_url": "https://arxiv.org/pdf/2506.14456.pdf", "abstract_url": "https://arxiv.org/abs/2506.14456", "categories": ["Quantum Physics (quant-ph)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种哈密顿形式主义，用于比较量子与经典智能的操作，旨在为量子与经典AGI任务提供一个数学框架，以便直接对比它们与环境的交互方式。", "motivation": "开发数学框架以直接比较量子与经典智能在各自环境中的操作，特别是针对量子基质上实现的AGI。", "method": "引入哈密顿形式主义，将AGI动力学分解为核心功能（如归纳、推理、递归、学习、测量和记忆）的哈密顿生成器。", "result": "提出了一种精确的数学语言，用于描述量子与经典代理通过环境交互的差异。", "conclusion": "该形式主义有助于理解量子与经典智能在环境交互上的根本差异，为未来AGI的发展提供了理论基础。"}}
{"id": "2506.14648", "title": "SENIOR: Efficient Query Selection and Preference-Guided Exploration in Preference-based Reinforcement Learning", "authors": ["Hexian Ni", "Tao Lu", "Haoyuan Hu", "Yinghao Cai", "Shuo Wang"], "abstract": "Preference-based Reinforcement Learning (PbRL) methods provide a solution to avoid reward engineering by learning reward models based on human preferences. However, poor feedback- and sample- efficiency still remain the problems that hinder the application of PbRL. In this paper, we present a novel efficient query selection and preference-guided exploration method, called SENIOR, which could select the meaningful and easy-to-comparison behavior segment pairs to improve human feedback-efficiency and accelerate policy learning with the designed preference-guided intrinsic rewards. Our key idea is twofold: (1) We designed a Motion-Distinction-based Selection scheme (MDS). It selects segment pairs with apparent motion and different directions through kernel density estimation of states, which is more task-related and easy for human preference labeling; (2) We proposed a novel preference-guided exploration method (PGE). It encourages the exploration towards the states with high preference and low visits and continuously guides the agent achieving the valuable samples. The synergy between the two mechanisms could significantly accelerate the progress of reward and policy learning. Our experiments show that SENIOR outperforms other five existing methods in both human feedback-efficiency and policy convergence speed on six complex robot manipulation tasks from simulation and four real-worlds.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": "8 pages, 8 figures", "pdf_url": "https://arxiv.org/pdf/2506.14648.pdf", "abstract_url": "https://arxiv.org/abs/2506.14648", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为SENIOR的高效查询选择和偏好引导探索方法，旨在解决基于偏好的强化学习（PbRL）中的反馈和样本效率低下的问题。通过设计运动区分选择方案（MDS）和偏好引导探索方法（PGE），SENIOR能够选择有意义且易于比较的行为片段对，以提高人类反馈效率，并通过设计的偏好引导内在奖励加速策略学习。实验表明，SENIOR在六种复杂的机器人操作任务中，无论是从模拟还是四个现实世界来看，都优于其他五种现有方法。", "motivation": "基于偏好的强化学习（PbRL）方法通过基于人类偏好学习奖励模型，避免了奖励工程的需要。然而，反馈和样本效率低下仍然是阻碍PbRL应用的问题。", "method": "SENIOR方法包括两个关键思想：（1）设计了基于运动区分的选择方案（MDS），通过状态的内核密度估计选择具有明显运动和不同方向的片段对，这些片段更与任务相关且易于人类偏好标注；（2）提出了一种新颖的偏好引导探索方法（PGE），鼓励探索那些偏好高且访问量低的状态，并持续引导代理实现有价值的样本。", "result": "实验结果显示，SENIOR在六种复杂的机器人操作任务中，无论是在模拟还是四个现实世界中，都优于其他五种现有方法，在人类反馈效率和策略收敛速度方面表现出色。", "conclusion": "SENIOR通过其设计的MDS和PGE机制，显著加速了奖励和策略学习的进程，为解决PbRL中的反馈和样本效率低下问题提供了有效方案。"}}
{"id": "2506.14670", "title": "StreetLens: Enabling Human-Centered AI Agents for Neighborhood Assessment from Street View Imagery", "authors": ["Jina Kim", "Leeje Jang", "Yao-Yi Chiang", "Guanyu Wang", "Michelle Pasco"], "abstract": "Traditionally, neighborhood studies have employed interviews, surveys, and manual image annotation guided by detailed protocols to identify environmental characteristics, including physical disorder, decay, street safety, and sociocultural symbols, and to examine their impact on developmental and health outcomes. While these methods yield rich insights, they are time-consuming and require intensive expert intervention. Recent technological advances, including vision-language models (VLMs), have begun to automate parts of this process; however, existing efforts are often ad hoc and lack adaptability across research designs and geographic contexts. In this demo paper, we present StreetLens, a human-centered, researcher-configurable workflow that embeds relevant social science expertise in a VLM for scalable neighborhood environmental assessments. StreetLens mimics the process of trained human coders by grounding the analysis in questions derived from established interview protocols, retrieving relevant street view imagery (SVI), and generating a wide spectrum of semantic annotations from objective features (e.g., the number of cars) to subjective perceptions (e.g., the sense of disorder in an image). By enabling researchers to define the VLM's role through domain-informed prompting, StreetLens places domain knowledge at the core of the analysis process. It also supports the integration of prior survey data to enhance robustness and expand the range of characteristics assessed across diverse settings. We provide a Google Colab notebook to make StreetLens accessible and extensible for researchers working with public or custom SVI datasets. StreetLens represents a shift toward flexible, agentic AI systems that work closely with researchers to accelerate and scale neighborhood studies.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.14670.pdf", "abstract_url": "https://arxiv.org/abs/2506.14670", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "StreetLens是一个以人为中心、可配置的研究工作流，利用视觉语言模型（VLM）进行街区环境评估，旨在自动化传统耗时且需要专家干预的街区研究方法。", "motivation": "解决传统街区研究方法（如访谈、调查和手动图像注释）耗时且需要大量专家干预的问题，以及现有技术方法缺乏跨研究设计和地理环境适应性的局限性。", "method": "开发了一个名为StreetLens的工作流，该工作流通过嵌入相关社会科学专业知识到VLM中，模仿训练有素的人类编码员的分析过程，包括从既定访谈协议中派生问题、检索相关街景图像（SVI）以及生成从客观特征到主观感知的广泛语义注释。", "result": "StreetLens通过允许研究人员通过领域知识提示定义VLM的角色，将领域知识置于分析过程的核心，并支持整合先前的调查数据以增强鲁棒性并扩大跨多样化环境评估的特征范围。", "conclusion": "StreetLens代表了向灵活、主动的AI系统的转变，这些系统与研究人员紧密合作，加速和扩展街区研究，提供了一个可访问和可扩展的Google Colab笔记本，以便研究人员使用公共或自定义的SVI数据集。"}}
{"id": "2506.14683", "title": "Unified Software Engineering agent as AI Software Engineer", "authors": ["Leonhard Applis", "Yuntong Zhang", "Shanchao Liang", "Nan Jiang", "Lin Tan", "Abhik Roychoudhury"], "abstract": "The growth of Large Language Model (LLM) technology has raised expectations for automated coding. However, software engineering is more than coding and is concerned with activities including maintenance and evolution of a project. In this context, the concept of LLM agents has gained traction, which utilize LLMs as reasoning engines to invoke external tools autonomously. But is an LLM agent the same as an AI software engineer? In this paper, we seek to understand this question by developing a Unified Software Engineering agent or USEagent. Unlike existing work which builds specialized agents for specific software tasks such as testing, debugging, and repair, our goal is to build a unified agent which can orchestrate and handle multiple capabilities. This gives the agent the promise of handling complex scenarios in software development such as fixing an incomplete patch, adding new features, or taking over code written by others. We envision USEagent as the first draft of a future AI Software Engineer which can be a team member in future software development teams involving both AI and humans. To evaluate the efficacy of USEagent, we build a Unified Software Engineering bench (USEbench) comprising of myriad tasks such as coding, testing, and patching. USEbench is a judicious mixture of tasks from existing benchmarks such as SWE-bench, SWT-bench, and REPOCOD. In an evaluation on USEbench consisting of 1,271 repository-level software engineering tasks, USEagent shows improved efficacy compared to existing general agents such as OpenHands CodeActAgent. There exist gaps in the capabilities of USEagent for certain coding tasks, which provides hints on further developing the AI Software Engineer of the future.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": "Leonhard Applis and Yuntong Zhang contributed equally to this work", "pdf_url": "https://arxiv.org/pdf/2506.14683.pdf", "abstract_url": "https://arxiv.org/abs/2506.14683", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了统一软件工程代理（USEagent）的概念，旨在通过利用大型语言模型（LLM）技术，构建一个能够协调和处理多种软件工程任务的多功能代理，以解决现有专门代理仅能处理特定软件任务的局限性。USEagent被设想为未来AI软件工程师的初稿，能够在包含AI和人类的软件开发团队中作为成员。通过构建统一软件工程基准（USEbench）进行评估，USEagent在1,271个仓库级软件工程任务上显示出比现有通用代理如OpenHands CodeActAgent更高的效能，尽管在某些编码任务上仍存在能力差距。", "motivation": "解决现有大型语言模型（LLM）代理仅能处理特定软件任务（如测试、调试和修复）的局限性，构建一个能够协调和处理多种软件工程任务的多功能代理，以应对软件开发中的复杂场景。", "method": "开发统一软件工程代理（USEagent），利用LLM作为推理引擎自主调用外部工具，并通过构建统一软件工程基准（USEbench）进行评估。", "result": "在1,271个仓库级软件工程任务上，USEagent显示出比现有通用代理如OpenHands CodeActAgent更高的效能，尽管在某些编码任务上仍存在能力差距。", "conclusion": "USEagent作为未来AI软件工程师的初稿，展示了在软件开发团队中作为成员的潜力，但其在某些编码任务上的能力差距提示了未来AI软件工程师发展的方向。"}}
