{"id": "2506.05431", "title": "Robustness Evaluation for Video Models with Reinforcement Learning", "authors": ["Ashwin Ramesh Babu", "Sajad Mousavi", "Vineet Gundecha", "Sahand Ghorbanpour", "Avisek Naug", "Antonio Guillen", "Ricardo Luna Gutierrez", "Soumyendu Sarkar"], "abstract": "Evaluating the robustness of Video classification models is very challenging, specifically when compared to image-based models. With their increased temporal dimension, there is a significant increase in complexity and computational cost. One of the key challenges is to keep the perturbations to a minimum to induce misclassification. In this work, we propose a multi-agent reinforcement learning approach (spatial and temporal) that cooperatively learns to identify the given video's sensitive spatial and temporal regions. The agents consider temporal coherence in generating fine perturbations, leading to a more effective and visually imperceptible attack. Our method outperforms the state-of-the-art solutions on the Lp metric and the average queries. Our method enables custom distortion types, making the robustness evaluation more relevant to the use case. We extensively evaluate 4 popular models for video action recognition on two popular datasets, HMDB-51 and UCF-101.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "Accepted at the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW) 2025", "pdf_url": "https://arxiv.org/pdf/2506.05431.pdf", "abstract_url": "https://arxiv.org/abs/2506.05431", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种多智能体强化学习方法，用于评估视频分类模型的鲁棒性，通过空间和时间智能体的协作学习，识别视频敏感区域并生成细微扰动，以更有效且视觉不易察觉的方式进行攻击。", "motivation": "评估视频分类模型的鲁棒性比图像模型更具挑战性，主要由于时间维度的增加导致复杂性和计算成本显著上升。关键挑战在于如何最小化扰动以诱导错误分类。", "method": "采用多智能体强化学习方法（空间和时间），协作学习识别视频的敏感空间和时间区域，考虑时间一致性生成细微扰动。", "result": "我们的方法在Lp度量和平均查询次数上优于现有最先进解决方案，支持自定义失真类型，使鲁棒性评估更贴近实际用例。在HMDB-51和UCF-101两个流行数据集上对4种流行的视频动作识别模型进行了广泛评估。", "conclusion": "本文提出的方法不仅提高了视频模型鲁棒性评估的有效性，还通过支持自定义失真类型，增强了评估的相关性和实用性。"}}
{"id": "2506.05375", "title": "State Estimation and Control of Dynamic Systems from High-Dimensional Image Data", "authors": ["Ashik E Rasul", "Hyung-Jin Yoon"], "abstract": "Accurate state estimation is critical for optimal policy design in dynamic systems. However, obtaining true system states is often impractical or infeasible, complicating the policy learning process. This paper introduces a novel neural architecture that integrates spatial feature extraction using convolutional neural networks (CNNs) and temporal modeling through gated recurrent units (GRUs), enabling effective state representation from sequences of images and corresponding actions. These learned state representations are used to train a reinforcement learning agent with a Deep Q-Network (DQN). Experimental results demonstrate that our proposed approach enables real-time, accurate estimation and control without direct access to ground-truth states. Additionally, we provide a quantitative evaluation methodology for assessing the accuracy of the learned states, highlighting their impact on policy performance and control stability.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.05375.pdf", "abstract_url": "https://arxiv.org/abs/2506.05375", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新颖的神经架构，结合了卷积神经网络（CNNs）和门控循环单元（GRUs），用于从图像序列和相应动作中学习有效的状态表示，进而训练深度Q网络（DQN）强化学习代理。实验结果表明，该方法能够在没有直接访问真实状态的情况下实现实时、准确的估计和控制。", "motivation": "在动态系统中，准确的状态估计对于最优策略设计至关重要。然而，获取真实的系统状态通常不切实际或不可行，这复杂化了策略学习过程。", "method": "本文介绍了一种结合空间特征提取（使用CNNs）和时间建模（通过GRUs）的神经架构，用于从图像序列和动作中学习状态表示，并利用这些表示训练DQN强化学习代理。", "result": "实验证明，所提出的方法能够在没有直接访问真实状态的情况下，实现实时、准确的估计和控制。同时，提供了一种定量评估方法，用于评估学习状态的准确性及其对策略性能和控制稳定性的影响。", "conclusion": "本文的方法为动态系统中的状态估计和控制提供了一种有效的解决方案，特别是在无法直接获取真实状态的情况下，展示了其在策略学习和控制稳定性方面的潜力。"}}
{"id": "2506.05386", "title": "Beyond RAG: Reinforced Reasoning Augmented Generation for Clinical Notes", "authors": ["Lo Pang-Yun Ting", "Chengshuai Zhao", "Yu-Hua Zeng", "Yuan Jee Lim", "Kun-Ta Chuang"], "abstract": "Clinical note generation aims to automatically produce free-text summaries of a patient's condition and diagnostic process, with discharge instructions being a representative long-form example. While recent large language model (LLM)-based methods pre-trained on general clinical corpora show promise in clinical text generation, they fall short in producing long-form notes from limited patient information. In this paper, we propose R2AG, the first reinforced retriever for long-form discharge instruction generation based on pre-admission data. R2AG is trained with reinforcement learning to retrieve reasoning paths from a medical knowledge graph, providing explicit semantic guidance to the LLM. To bridge the information gap, we propose Group-Based Retriever Optimization (GRO) which improves retrieval quality with group-relative rewards, encouraging reasoning leaps for deeper inference by the LLM. Comprehensive experiments on the MIMIC-IV-Note dataset show that R2AG outperforms baselines in both clinical efficacy and natural language generation metrics. Further analysis reveals that R2AG fills semantic gaps in sparse input scenarios, and retrieved reasoning paths help LLMs avoid clinical misinterpretation by focusing on key evidence and following coherent reasoning.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.05386.pdf", "abstract_url": "https://arxiv.org/abs/2506.05386", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了R2AG，一种基于强化学习的检索增强生成方法，用于从有限的病人信息中生成临床长文本摘要，如出院指导。通过从医学知识图谱中检索推理路径，R2AG为大型语言模型提供显式的语义指导，并通过组基检索优化（GRO）提高检索质量。在MIMIC-IV-Note数据集上的实验表明，R2AG在临床效果和自然语言生成指标上均优于基线方法。", "motivation": "解决基于有限病人信息自动生成长篇临床文本摘要（如出院指导）的挑战，现有基于大型语言模型（LLM）的方法在此任务上表现不足。", "method": "提出了R2AG方法，利用强化学习训练检索器从医学知识图谱中检索推理路径，为LLM提供显式语义指导；并提出了组基检索优化（GRO）通过组相对奖励提高检索质量。", "result": "在MIMIC-IV-Note数据集上的综合实验显示，R2AG在临床效果和自然语言生成指标上优于基线方法，能够填补稀疏输入场景下的语义空白，并帮助LLM避免临床误解。", "conclusion": "R2AG通过强化学习和检索增强生成，有效提升了从有限病人信息生成长篇临床文本摘要的能力，为临床文本生成提供了新的解决方案。"}}
{"id": "2506.05560", "title": "Improving LLMs with a knowledge from databases", "authors": ["Petr Máša"], "abstract": "Large language models (LLMs) are achieving significant progress almost every moment now. Many advanced techniques have been introduced and widely accepted, like retrieval-augmentation generation (RAG), agents, and tools. Tools can query the database to answer questions from structured data files or perform groupings or other statistics. This unlocks huge opportunities, such as it can answer any question, but also poses threats, such as safety, because there is no control over the commands that are created. We would like to discuss whether we can create a new method that improves answers based on dataset/database via some interpretable ML methods, namely enhanced association rules. The advantage would be if the method can be also used in some safe technique like RAG. Association rules have a sound history. Since the introduction of CN2 and aproiri, many enhancements have been made. In parallel, enhanced association rules have been introduced and evolved over the last 40 years. The general problem is typically that there are too many rules. There are some techniques for handling it, but when LLM emerged, it turned out to be the best use case for the RAG technique for LLMs. We proposed a method that generates a ruleset based on defined knowledge patterns, then converts rules into text form via a rule-to-text converter, and includes the result as an RAG into LLM. We compared this method with ChatGPT (even with using agents) and we have discovered a significant improvement in answering questions based on the dataset. We have also tried several strategies how much rules to generate. We found this improvement interesting. Moreover, it can also be improved in many ways as future work, like incorporating other patterns, the use of rule mining as an agent, and many others.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.05560.pdf", "abstract_url": "https://arxiv.org/abs/2506.05560", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文提出了一种新方法，通过增强关联规则改进基于数据库的LLM回答，并将其与RAG技术结合，显著提升了基于数据集的问题回答能力。", "motivation": "解决LLMs在利用数据库知识回答问题时的安全性和效率问题，探索一种可解释的ML方法以提升回答质量。", "method": "提出一种方法，基于定义的知识模式生成规则集，通过规则到文本的转换器将规则转换为文本形式，并将结果作为RAG纳入LLM。", "result": "与ChatGPT（即使使用代理）相比，该方法在基于数据集的问题回答上显示出显著改进。", "conclusion": "该方法不仅显著提升了LLMs的回答质量，还提供了多种未来改进方向，如融入其他模式、使用规则挖掘作为代理等。"}}
{"id": "2506.05370", "title": "Contextual Memory Intelligence -- A Foundational Paradigm for Human-AI Collaboration and Reflective Generative AI Systems", "authors": ["Kristy Wedel"], "abstract": "A critical challenge remains unresolved as generative AI systems are quickly implemented in various organizational settings. Despite significant advances in memory components such as RAG, vector stores, and LLM agents, these systems still have substantial memory limitations. Gen AI workflows rarely store or reflect on the full context in which decisions are made. This leads to repeated errors and a general lack of clarity. This paper introduces Contextual Memory Intelligence (CMI) as a new foundational paradigm for building intelligent systems. It repositions memory as an adaptive infrastructure necessary for longitudinal coherence, explainability, and responsible decision-making rather than passive data. Drawing on cognitive science, organizational theory, human-computer interaction, and AI governance, CMI formalizes the structured capture, inference, and regeneration of context as a fundamental system capability. The Insight Layer is presented in this paper to operationalize this vision. This modular architecture uses human-in-the-loop reflection, drift detection, and rationale preservation to incorporate contextual memory into systems. The paper argues that CMI allows systems to reason with data, history, judgment, and changing context, thereby addressing a foundational blind spot in current AI architectures and governance efforts. A framework for creating intelligent systems that are effective, reflective, auditable, and socially responsible is presented through CMI. This enhances human-AI collaboration, generative AI design, and the resilience of the institutions.", "subjects": "Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET)", "comments": "32 pages, 9 tables, 1 figure", "pdf_url": "https://arxiv.org/pdf/2506.05370.pdf", "abstract_url": "https://arxiv.org/abs/2506.05370", "categories": ["Artificial Intelligence (cs.AI)", "Emerging Technologies (cs.ET)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文提出了一种名为上下文记忆智能（CMI）的新基础范式，旨在解决生成式AI系统在记忆方面的局限性，通过将记忆重新定位为适应性的基础设施，以支持纵向一致性、可解释性和负责任的决策。", "motivation": "生成式AI系统在组织环境中的快速应用暴露了其在记忆方面的显著限制，如无法存储或反思决策的完整上下文，导致重复错误和缺乏清晰度。", "method": "CMI通过结合认知科学、组织理论、人机交互和AI治理，将上下文的结构化捕获、推理和再生形式化为系统的基本能力，并提出了Insight Layer这一模块化架构来实现这一愿景。", "result": "CMI使系统能够利用数据、历史、判断和变化的上下文进行推理，从而解决了当前AI架构和治理努力中的一个基础盲点。", "conclusion": "通过CMI，本文提出了一个创建有效、反思性、可审计且社会责任的智能系统的框架，从而增强了人机协作、生成式AI设计以及机构的韧性。"}}
{"id": "2506.05422", "title": "Constructive Symbolic Reinforcement Learning via Intuitionistic Logic and Goal-Chaining Inference", "authors": ["Andrei T. Patrascu"], "abstract": "We introduce a novel learning and planning framework that replaces traditional reward-based optimisation with constructive logical inference. In our model, actions, transitions, and goals are represented as logical propositions, and decision-making proceeds by building constructive proofs under intuitionistic logic. This method ensures that state transitions and policies are accepted only when supported by verifiable preconditions -- eschewing probabilistic trial-and-error in favour of guaranteed logical validity. We implement a symbolic agent operating in a structured gridworld, where reaching a goal requires satisfying a chain of intermediate subgoals (e.g., collecting keys to open doors), each governed by logical constraints. Unlike conventional reinforcement learning agents, which require extensive exploration and suffer from unsafe or invalid transitions, our constructive agent builds a provably correct plan through goal chaining, condition tracking, and knowledge accumulation. Empirical comparison with Q-learning demonstrates that our method achieves perfect safety, interpretable behaviour, and efficient convergence with no invalid actions, highlighting its potential for safe planning, symbolic cognition, and trustworthy AI. This work presents a new direction for reinforcement learning grounded not in numeric optimisation, but in constructive logic and proof theory.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.05422.pdf", "abstract_url": "https://arxiv.org/abs/2506.05422", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一种新颖的学习和规划框架，用构造性逻辑推理替代传统的基于奖励的优化。在该模型中，动作、转换和目标被表示为逻辑命题，决策通过构建直觉主义逻辑下的构造性证明进行。此方法确保状态转换和策略仅在可验证的前提条件下被接受，避免了概率性的试错，保证了逻辑有效性。", "motivation": "解决传统强化学习需要大量探索且可能产生不安全或无效转换的问题，提出一种基于构造性逻辑和证明理论的新方向，以实现安全规划、符号认知和可信赖的AI。", "method": "使用直觉主义逻辑和构造性推理，将动作、状态转换和目标表示为逻辑命题，通过目标链、条件跟踪和知识积累构建可证明正确的计划。", "result": "与Q学习相比，该方法实现了完美的安全性、可解释的行为和高效收敛，且无无效动作，展示了其在安全规划和符号认知方面的潜力。", "conclusion": "这项工作为强化学习提供了一个基于构造性逻辑和证明理论而非数值优化的新方向，强调了其在实现安全、可解释和高效AI方面的潜力。"}}
{"id": "2506.05520", "title": "Towards Data Systems That Are Business Semantic-Centric and AI Agents-Assisted", "authors": ["Cecil Pang"], "abstract": "Contemporary businesses operate in dynamic environments requiring rapid adaptation to achieve goals and maintain competitiveness. Existing data platforms often fall short by emphasizing tools over alignment with business needs, resulting in inefficiencies and delays. To address this gap, I propose the Business Semantics Centric, AI Agents Assisted Data System (BSDS), a holistic system that integrates architecture, workflows, and team organization to ensure data systems are tailored to business priorities rather than dictated by technical constraints. BSDS redefines data systems as dynamic enablers of business success, transforming them from passive tools into active drivers of organizational growth. BSDS has a modular architecture that comprises curated data linked to business entities, a knowledge base for context-aware AI agents, and efficient data pipelines. AI agents play a pivotal role in assisting with data access and system management, reducing human effort, and improving scalability. Complementing this architecture, BSDS incorporates workflows optimized for both exploratory data analysis and production requirements, balancing speed of delivery with quality assurance. A key innovation of BSDS is its incorporation of the human factor. By aligning data team expertise with business semantics, BSDS bridges the gap between technical capabilities and business needs. Validated through real-world implementation, BSDS accelerates time-to-market for data-driven initiatives, enhances cross-functional collaboration, and provides a scalable blueprint for businesses of all sizes. Future research can build on BSDS to explore optimization strategies using complex systems and adaptive network theories, as well as developing autonomous data systems leveraging AI agents.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "Being peer reviewed by a journal", "pdf_url": "https://arxiv.org/pdf/2506.05520.pdf", "abstract_url": "https://arxiv.org/abs/2506.05520", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种以业务语义为中心、AI代理辅助的数据系统（BSDS），旨在解决现有数据平台过于注重工具而忽视业务需求的问题。BSDS通过整合架构、工作流程和团队组织，使数据系统更贴合业务优先级，从而提升效率和可扩展性。", "motivation": "解决现有数据平台过于注重技术工具而忽视业务需求，导致效率低下和延迟的问题。", "method": "提出BSDS系统，包括模块化架构（业务实体关联的精选数据、上下文感知AI代理的知识库、高效数据管道）、优化的工作流程以及团队组织与业务语义的对齐。", "result": "BSDS通过实际应用验证，加速了数据驱动计划的上市时间，增强了跨部门协作，并为各种规模的企业提供了可扩展的蓝图。", "conclusion": "BSDS将数据系统从被动工具转变为业务成功的动态推动者，未来研究可在此基础上探索复杂系统和自适应网络理论的优化策略，以及开发利用AI代理的自主数据系统。"}}
{"id": "2506.05529", "title": "Avoiding Death through Fear Intrinsic Conditioning", "authors": ["Rodney Sanchez", "Ferat Sahin", "Alexander Ororbia", "Jamison Heard"], "abstract": "Biological and psychological concepts have inspired reinforcement learning algorithms to create new complex behaviors that expand agents' capacity. These behaviors can be seen in the rise of techniques like goal decomposition, curriculum, and intrinsic rewards, which have paved the way for these complex behaviors. One limitation in evaluating these methods is the requirement for engineered extrinsic for realistic environments. A central challenge in engineering the necessary reward function(s) comes from these environments containing states that carry high negative rewards, but provide no feedback to the agent. Death is one such stimuli that fails to provide direct feedback to the agent. In this work, we introduce an intrinsic reward function inspired by early amygdala development and produce this intrinsic reward through a novel memory-augmented neural network (MANN) architecture. We show how this intrinsic motivation serves to deter exploration of terminal states and results in avoidance behavior similar to fear conditioning observed in animals. Furthermore, we demonstrate how modifying a threshold where the fear response is active produces a range of behaviors that are described under the paradigm of general anxiety disorders (GADs). We demonstrate this behavior in the Miniworld Sidewalk environment, which provides a partially observable Markov decision process (POMDP) and a sparse reward with a non-descriptive terminal condition, i.e., death. In effect, this study results in a biologically-inspired neural architecture and framework for fear conditioning paradigms; we empirically demonstrate avoidance behavior in a constructed agent that is able to solve environments with non-descriptive terminal conditions.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.05529.pdf", "abstract_url": "https://arxiv.org/abs/2506.05529", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种受早期杏仁核发展启发的内在奖励函数，通过一种新颖的记忆增强神经网络架构产生，旨在避免探索终端状态，产生类似动物恐惧条件反射的回避行为。", "motivation": "解决在强化学习中，由于环境中的某些状态（如死亡）携带高负奖励但不提供直接反馈给代理的问题。", "method": "引入了一种内在奖励函数，并通过记忆增强神经网络（MANN）架构实现，模拟恐惧条件反射。", "result": "展示了这种内在动机如何有效避免探索终端状态，并在Miniworld Sidewalk环境中验证了其有效性。", "conclusion": "本研究提出了一种生物启发的神经架构和恐惧条件反射范式框架，能够解决具有非描述性终端条件的环境问题。"}}
{"id": "2506.05616", "title": "Toward Greater Autonomy in Materials Discovery Agents: Unifying Planning, Physics, and Scientists", "authors": ["Lianhao Zhou", "Hongyi Ling", "Keqiang Yan", "Kaiji Zhao", "Xiaoning Qian", "Raymundo Arróyave", "Xiaofeng Qian", "Shuiwang Ji"], "abstract": "We aim at designing language agents with greater autonomy for crystal materials discovery. While most of existing studies restrict the agents to perform specific tasks within predefined workflows, we aim to automate workflow planning given high-level goals and scientist intuition. To this end, we propose Materials Agent unifying Planning, Physics, and Scientists, known as MAPPS. MAPPS consists of a Workflow Planner, a Tool Code Generator, and a Scientific Mediator. The Workflow Planner uses large language models (LLMs) to generate structured and multi-step workflows. The Tool Code Generator synthesizes executable Python code for various tasks, including invoking a force field foundation model that encodes physics. The Scientific Mediator coordinates communications, facilitates scientist feedback, and ensures robustness through error reflection and recovery. By unifying planning, physics, and scientists, MAPPS enables flexible and reliable materials discovery with greater autonomy, achieving a five-fold improvement in stability, uniqueness, and novelty rates compared with prior generative models when evaluated on the MP-20 data. We provide extensive experiments across diverse tasks to show that MAPPS is a promising framework for autonomous materials discovery.", "subjects": "Artificial Intelligence (cs.AI); Materials Science (cond-mat.mtrl-sci); Computational Physics (physics.comp-ph)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.05616.pdf", "abstract_url": "https://arxiv.org/abs/2506.05616", "categories": ["Artificial Intelligence (cs.AI)", "Materials Science (cond-mat.mtrl-sci)", "Computational Physics (physics.comp-ph)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为MAPPS的材料发现代理，旨在通过统一规划、物理和科学家反馈，提高材料发现的自主性。MAPPS包括工作流规划器、工具代码生成器和科学调解器，通过LLMs生成多步工作流，合成可执行代码，并协调科学家反馈，实现了在MP-20数据上稳定性、独特性和新颖性率的五倍提升。", "motivation": "解决现有材料发现代理在预定义工作流中执行特定任务的限制，旨在自动化工作流规划，结合高级目标和科学家直觉，提高材料发现的自主性。", "method": "提出MAPPS框架，包含工作流规划器（使用LLMs生成结构化多步工作流）、工具代码生成器（合成包括调用力场基础模型在内的可执行Python代码）和科学调解器（协调通信、收集科学家反馈、确保鲁棒性）。", "result": "在MP-20数据上评估，MAPPS在稳定性、独特性和新颖性率方面比现有生成模型提高了五倍。", "conclusion": "MAPPS通过统一规划、物理和科学家反馈，为自主材料发现提供了一个灵活可靠的框架，展示了在多样化任务中的广泛应用潜力。"}}
{"id": "2506.05606", "title": "OPeRA: A Dataset of Observation, Persona, Rationale, and Action for Evaluating LLMs on Human Online Shopping Behavior Simulation", "authors": ["Ziyi Wang", "Yuxuan Lu", "Wenbo Li", "Amirali Amini", "Bo Sun", "Yakov Bart", "Weimin Lyu", "Jiri Gesi", "Tian Wang", "Jing Huang", "Yu Su", "Upol Ehsan", "Malihe Alikhani", "Toby Jia-Jun Li", "Lydia Chilton", "Dakuo Wang"], "abstract": "Can large language models (LLMs) accurately simulate the next web action of a specific user? While LLMs have shown promising capabilities in generating ``believable'' human behaviors, evaluating their ability to mimic real user behaviors remains an open challenge, largely due to the lack of high-quality, publicly available datasets that capture both the observable actions and the internal reasoning of an actual human user. To address this gap, we introduce OPERA, a novel dataset of Observation, Persona, Rationale, and Action collected from real human participants during online shopping sessions. OPERA is the first public dataset that comprehensively captures: user personas, browser observations, fine-grained web actions, and self-reported just-in-time rationales. We developed both an online questionnaire and a custom browser plugin to gather this dataset with high fidelity. Using OPERA, we establish the first benchmark to evaluate how well current LLMs can predict a specific user's next action and rationale with a given persona and <observation, action, rationale> history. This dataset lays the groundwork for future research into LLM agents that aim to act as personalized digital twins for human.", "subjects": "Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.05606.pdf", "abstract_url": "https://arxiv.org/abs/2506.05606", "categories": ["Computation and Language (cs.CL)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "OPeRA是一个新颖的数据集，用于评估大型语言模型（LLMs）在模拟人类在线购物行为方面的能力。它首次公开捕获了用户角色、浏览器观察、细粒度网络行为以及自我报告的即时理由。", "motivation": "解决缺乏高质量、公开可用的数据集来捕捉真实用户的可观察行为和内部推理的问题，以评估LLMs在模拟特定用户下一个网络行为方面的准确性。", "method": "通过在线问卷和自定义浏览器插件收集数据，建立了一个包含观察、角色、理由和行动的数据集OPERA，并以此为基础建立了第一个评估LLMs预测特定用户下一个行为和理由能力的基准。", "result": "OPERA数据集为评估LLMs在模拟人类在线购物行为方面的能力提供了第一个公开可用的基准。", "conclusion": "OPERA数据集为未来研究旨在作为人类个性化数字双胞胎的LLM代理奠定了基础，开辟了评估和改进LLMs在模拟人类行为方面能力的新途径。"}}
{"id": "2506.05810", "title": "Trajectory Entropy: Modeling Game State Stability from Multimodality Trajectory Prediction", "authors": ["Yesheng Zhang", "Wenjian Sun", "Yuheng Chen", "Qingwei Liu", "Qi Lin", "Rui Zhang", "Xu Zhao"], "abstract": "Complex interactions among agents present a significant challenge for autonomous driving in real-world scenarios. Recently, a promising approach has emerged, which formulates the interactions of agents as a level-k game framework. It effectively decouples agent policies by hierarchical game levels. However, this framework ignores both the varying driving complexities among agents and the dynamic changes in agent states across game levels, instead treating them uniformly. Consequently, redundant and error-prone computations are introduced into this framework. To tackle the issue, this paper proposes a metric, termed as Trajectory Entropy, to reveal the game status of agents within the level-k game framework. The key insight stems from recognizing the inherit relationship between agent policy uncertainty and the associated driving complexity. Specifically, Trajectory Entropy extracts statistical signals representing uncertainty from the multimodality trajectory prediction results of agents in the game. Then, the signal-to-noise ratio of this signal is utilized to quantify the game status of agents. Based on the proposed Trajectory Entropy, we refine the current level-k game framework through a simple gating mechanism, significantly improving overall accuracy while reducing computational costs. Our method is evaluated on the Waymo and nuPlan datasets, in terms of trajectory prediction, open-loop and closed-loop planning tasks. The results demonstrate the state-of-the-art performance of our method, with precision improved by up to 19.89% for prediction and up to 16.48% for planning.", "subjects": "Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": "10 pages", "pdf_url": "https://arxiv.org/pdf/2506.05810.pdf", "abstract_url": "https://arxiv.org/abs/2506.05810", "categories": ["Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种称为轨迹熵的度量，用于在层次k游戏框架中揭示代理的游戏状态，通过从代理的多模态轨迹预测结果中提取统计信号来表示不确定性，并利用信噪比量化代理的游戏状态。基于轨迹熵，作者通过简单的门控机制改进了当前的层次k游戏框架，显著提高了整体准确性并降低了计算成本。", "motivation": "解决自动驾驶中复杂交互代理的问题，特别是在层次k游戏框架中忽略代理驾驶复杂性和状态动态变化的问题，导致冗余和易错计算。", "method": "提出轨迹熵度量，从多模态轨迹预测结果中提取不确定性统计信号，利用信噪比量化代理的游戏状态，并通过门控机制改进层次k游戏框架。", "result": "在Waymo和nuPlan数据集上的评估显示，该方法在轨迹预测、开环和闭环规划任务中达到了最先进的性能，预测精度提高了高达19.89%，规划精度提高了高达16.48%。", "conclusion": "轨迹熵作为一种新的度量，能够有效揭示和量化代理在层次k游戏框架中的游戏状态，通过改进的框架显著提高了自动驾驶系统的准确性和效率。"}}
{"id": "2506.05690", "title": "When to use Graphs in RAG: A Comprehensive Analysis for Graph Retrieval-Augmented Generation", "authors": ["Zhishang Xiang", "Chuanjie Wu", "Qinggang Zhang", "Shengyuan Chen", "Zijin Hong", "Xiao Huang", "Jinsong Su"], "abstract": "Graph retrieval-augmented generation (GraphRAG) has emerged as a powerful paradigm for enhancing large language models (LLMs) with external knowledge. It leverages graphs to model the hierarchical structure between specific concepts, enabling more coherent and effective knowledge retrieval for accurate", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.05690.pdf", "abstract_url": "https://arxiv.org/abs/2506.05690", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文分析了在检索增强生成（RAG）中何时使用图的问题，提出了图检索增强生成（GraphRAG）作为一种强大的范式，通过图来建模特定概念之间的层次结构，以增强大型语言模型（LLMs）的外部知识检索能力。", "motivation": "解决在检索增强生成过程中如何更有效地利用外部知识，提高知识检索的准确性和连贯性问题。", "method": "采用图检索增强生成（GraphRAG）方法，利用图模型来构建概念之间的层次结构。", "result": "GraphRAG能够更有效地检索和组织外部知识，从而提升大型语言模型的性能。", "conclusion": "图检索增强生成（GraphRAG）是一种有效的范式，能够通过图模型增强大型语言模型的知识检索能力，提高生成内容的准确性和连贯性。"}}
{"id": "2506.05981", "title": "CrimeMind: Simulating Urban Crime with Multi-Modal LLM Agents", "authors": ["Qingbin Zeng", "Ruotong Zhao", "Jinzhu Mao", "Haoyang Li", "Fengli Xu", "Yong Li"], "abstract": "Modeling urban crime is an important yet challenging task that requires understanding the subtle visual, social, and cultural cues embedded in urban environments. Previous work has predominantly focused on rule-based agent-based modeling (ABM) and deep learning methods. ABMs offer interpretability of internal mechanisms but exhibit limited predictive", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.05981.pdf", "abstract_url": "https://arxiv.org/abs/2506.05981", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "CrimeMind是一个利用多模态LLM代理模拟城市犯罪的模型，旨在通过理解城市环境中的视觉、社会和文化线索来改进犯罪建模。", "motivation": "城市犯罪建模是一个重要但具有挑战性的任务，需要理解城市环境中微妙的视觉、社会和文化的线索。现有的基于规则的代理建模（ABM）和深度学习方法在预测能力上存在局限。", "method": "采用多模态LLM（大型语言模型）代理来模拟城市犯罪，结合视觉、社会和文化多方面的信息。", "result": "未提及具体结果，但暗示该方法可能在理解和预测城市犯罪方面比传统的ABM和深度学习方法更有效。", "conclusion": "CrimeMind通过引入多模态LLM代理，为城市犯罪建模提供了一种新的、可能更有效的方法，尽管具体效果需进一步研究验证。"}}
{"id": "2506.06254", "title": "PersonaAgent: When Large Language Model Agents Meet Personalization at Test Time", "authors": ["Weizhi Zhang", "Xinyang Zhang", "Chenwei Zhang", "Liangwei Yang", "Jingbo Shang", "Zhepei Wei", "Henry Peng Zou", "Zijie Huang", "Zhengyang Wang", "Yifan Gao", "Xiaoman Pan", "Lian Xiong", "Jingguo Liu", "Philip S. Yu", "Xian Li"], "abstract": "Large Language Model (LLM) empowered agents have recently emerged as advanced paradigms that exhibit impressive capabilities in a wide range of domains and tasks. Despite their potential, current LLM agents often adopt a one-size-fits-all approach, lacking the flexibility to respond to users' varying needs and preferences. This limitation motivates us to develop PersonaAgent, the first personalized LLM agent framework designed to address versatile personalization tasks. Specifically, PersonaAgent integrates two complementary components - a personalized memory module that includes episodic and semantic memory mechanisms; a personalized action module that enables the agent to perform tool actions tailored to the user. At the core, the persona (defined as unique system prompt for each user) functions as an intermediary: it leverages insights from personalized memory to control agent actions, while the outcomes of these actions in turn refine the memory. Based on the framework, we propose a test-time user-preference alignment strategy that simulate the latest n interactions to optimize the persona prompt, ensuring real-time user preference alignment through textual loss feedback between simulated and ground-truth responses. Experimental evaluations demonstrate that PersonaAgent significantly outperforms other baseline methods by not only personalizing the action space effectively but also scaling during test-time real-world applications. These results underscore the feasibility and potential of our approach in delivering tailored, dynamic user experiences.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.06254.pdf", "abstract_url": "https://arxiv.org/abs/2506.06254", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "PersonaAgent是一个创新的个性化LLM代理框架，旨在通过个性化记忆和行动模块，以及实时用户偏好对齐策略，解决现有LLM代理缺乏个性化响应能力的问题。", "motivation": "当前的大型语言模型（LLM）代理通常采用一刀切的方法，缺乏响应用户不同需求和偏好的灵活性。", "method": "PersonaAgent整合了个性化记忆模块（包括情景和语义记忆机制）和个性化行动模块（使代理能够执行适应用户的工具行动），并通过用户偏好对齐策略优化个人提示。", "result": "实验评估显示，PersonaAgent在个性化行动空间和测试时实时应用扩展方面显著优于其他基线方法。", "conclusion": "PersonaAgent的框架在提供定制化、动态用户体验方面展现了可行性和潜力。"}}
{"id": "2506.05725", "title": "Large Language Models are Good Relational Learners", "authors": ["Fang Wu", "Vijay Prakash Dwivedi", "Jure Leskovec"], "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities across various domains, yet their application to relational deep learning (RDL) remains underexplored. Existing approaches adapt LLMs by traversing relational links between entities in a database and converting the structured data into flat text documents. Still, this text-based serialization disregards critical relational structures, introduces redundancy, and often exceeds standard LLM context lengths. We introduce Rel-LLM, a novel architecture that utilizes a graph neural network (GNN)- based encoder to generate structured relational prompts for LLMs within a retrieval-augmented generation (RAG) framework. Unlike traditional text-based serialization approaches, our method preserves the inherent relational structure of databases while enabling LLMs to effectively process and reason over complex entity relationships. Specifically, the GNN encoder extracts a local subgraph around an entity to build feature representations that contain relevant entity relationships and temporal dependencies. These representations are transformed into structured prompts using a denormalization process, effectively allowing the LLM to reason over relational structures. Through extensive experiments, we demonstrate that Rel-LLM outperforms existing methods on key RDL tasks, offering a scalable and efficient approach to integrating LLMs with structured data sources. Code is available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.05725.pdf", "abstract_url": "https://arxiv.org/abs/2506.05725", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了Rel-LLM，一种新颖的架构，利用基于图神经网络（GNN）的编码器在检索增强生成（RAG）框架内为大型语言模型（LLMs）生成结构化关系提示，以解决现有方法在将结构化数据转换为扁平文本时忽视关键关系结构的问题。", "motivation": "大型语言模型（LLMs）在各种领域展示了卓越的能力，但它们在关系深度学习（RDL）中的应用仍未充分探索。现有方法通过遍历数据库中的实体关系并将结构化数据转换为扁平文本文档来适应LLMs，但这种基于文本的序列化忽视了关键的关系结构，引入了冗余，并且经常超过标准LLM的上下文长度。", "method": "我们引入了Rel-LLM，一种利用基于图神经网络（GNN）的编码器在检索增强生成（RAG）框架内为LLMs生成结构化关系提示的新架构。GNN编码器提取实体周围的局部子图以构建包含相关实体关系和时序依赖的特征表示，这些表示通过反规范化过程转换为结构化提示，使LLM能够有效地处理和推理复杂的实体关系。", "result": "通过大量实验，我们证明Rel-LLM在关键RDL任务上优于现有方法，提供了一种可扩展且高效的方法来将LLMs与结构化数据源集成。", "conclusion": "Rel-LLM提供了一种新颖且有效的方法，使LLMs能够更好地理解和推理结构化数据中的复杂关系，为LLMs在关系深度学习领域的应用开辟了新途径。"}}
{"id": "2506.05872", "title": "Domain-RAG: Retrieval-Guided Compositional Image Generation for Cross-Domain Few-Shot Object Detection", "authors": ["Yu Li", "Xingyu Qiu", "Yuqian Fu", "Jie Chen", "Tianwen Qian", "Xu Zheng", "Danda Pani Paudel", "Yanwei Fu", "Xuanjing Huang", "Luc Van Gool", "Yu-Gang Jiang"], "abstract": "Cross-Domain Few-Shot Object Detection (CD-FSOD) aims to detect novel objects with only a handful of labeled samples from previously unseen domains. While data augmentation and generative methods have shown promise in few-shot learning, their effectiveness for CD-FSOD remains unclear due to the need for both visual realism and domain alignment. Existing strategies, such as copy-paste augmentation and text-to-image generation, often fail to preserve the correct object category or produce backgrounds coherent with the target domain, making them non-trivial to apply directly to CD-FSOD. To address these challenges, we propose Domain-RAG, a training-free, retrieval-guided compositional image generation framework tailored for CD-FSOD. Domain-RAG consists of three stages: domain-aware background retrieval, domain-guided background generation, and foreground-background composition. Specifically, the input image is first decomposed into foreground and background regions. We then retrieve semantically and stylistically similar images to guide a generative model in synthesizing a new background, conditioned on both the original and retrieved contexts. Finally, the preserved foreground is composed with the newly generated domain-aligned background to form the generated image. Without requiring any additional supervision or training, Domain-RAG produces high-quality, domain-consistent samples across diverse tasks, including CD-FSOD, remote sensing FSOD, and camouflaged FSOD. Extensive experiments show consistent improvements over strong baselines and establish new state-of-the-art results. Codes will be released upon acceptance.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.05872.pdf", "abstract_url": "https://arxiv.org/abs/2506.05872", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "Domain-RAG是一种无需训练的、检索引导的组合图像生成框架，专为跨域少样本目标检测（CD-FSOD）设计，通过域感知背景检索、域引导背景生成和前景-背景组合三个阶段，生成高质量、域一致的样本。", "motivation": "解决跨域少样本目标检测中，现有数据增强和生成方法在视觉真实性和域对齐方面的不足，如复制粘贴增强和文本到图像生成方法常无法保持正确的对象类别或生成与目标域一致的背景。", "method": "提出Domain-RAG框架，包括域感知背景检索、域引导背景生成和前景-背景组合三个阶段，利用检索到的语义和风格相似图像指导生成模型合成新背景，并与保留的前景组合成新图像。", "result": "Domain-RAG在CD-FSOD、遥感FSOD和伪装FSOD等多种任务中，无需额外监督或训练，即能生成高质量、域一致的样本，实验显示其性能优于强基线并达到新的最先进水平。", "conclusion": "Domain-RAG通过检索引导的组合图像生成，有效解决了跨域少样本目标检测中的域对齐和视觉真实性问题，为相关领域提供了新的解决方案。"}}
{"id": "2506.05982", "title": "MCA-Bench: A Multimodal Benchmark for Evaluating CAPTCHA Robustness Against VLM-based Attacks", "authors": ["Zonglin Wu", "Yule Xue", "Xin Wei", "Yiren Song"], "abstract": "As automated attack techniques rapidly advance, CAPTCHAs remain a critical defense mechanism against malicious bots. However, existing CAPTCHA schemes encompass a diverse range of modalities -- from static distorted text and obfuscated images to interactive clicks, sliding puzzles, and logic-based questions -- yet the community still lacks a unified, large-scale, multimodal benchmark to rigorously evaluate their security robustness. To address this gap, we introduce MCA-Bench, a comprehensive and reproducible benchmarking suite that integrates heterogeneous CAPTCHA types into a single evaluation protocol. Leveraging a shared vision-language model backbone, we fine-tune specialized cracking agents for each CAPTCHA category, enabling consistent, cross-modal assessments. Extensive experiments reveal that MCA-Bench effectively maps the vulnerability spectrum of modern CAPTCHA designs under varied attack settings, and crucially offers the first quantitative analysis of how challenge complexity, interaction depth, and model solvability interrelate. Based on these findings, we propose three actionable design principles and identify key open challenges, laying the groundwork for systematic CAPTCHA hardening, fair benchmarking, and broader community collaboration. Datasets and code are available online.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "31 pages, 8 figures", "pdf_url": "https://arxiv.org/pdf/2506.05982.pdf", "abstract_url": "https://arxiv.org/abs/2506.05982", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了MCA-Bench，一个用于评估CAPTCHA对抗基于视觉语言模型攻击的鲁棒性的多模态基准测试。", "motivation": "随着自动化攻击技术的快速发展，CAPTCHA作为防御恶意机器人的关键机制，其安全鲁棒性缺乏统一、大规模、多模态的基准测试来严格评估。", "method": "通过整合异构CAPTCHA类型到一个统一的评估协议中，利用共享的视觉语言模型骨干，为每个CAPTCHA类别微调专门的破解代理，实现一致、跨模态的评估。", "result": "大量实验表明，MCA-Bench有效映射了现代CAPTCHA设计在不同攻击设置下的脆弱性频谱，并首次定量分析了挑战复杂性、交互深度和模型可解性之间的相互关系。", "conclusion": "基于这些发现，提出了三个可操作的设计原则，并确定了关键的开放挑战，为系统化的CAPTCHA加固、公平基准测试和更广泛的社区合作奠定了基础。"}}
{"id": "2506.05766", "title": "BioMol-MQA: A Multi-Modal Question Answering Dataset For LLM Reasoning Over Bio-Molecular Interactions", "authors": ["Saptarshi Sengupta", "Shuhua Yang", "Paul Kwong Yu", "Fali Wang", "Suhang Wang"], "abstract": "Retrieval augmented generation (RAG) has shown great power in improving Large Language Models (LLMs). However, most existing RAG-based LLMs are dedicated to retrieving single modality information, mainly text; while for many real-world problems, such as healthcare, information relevant to queries can manifest in various modalities such as knowledge graph, text (clinical notes), and complex molecular structure. Thus, being able to retrieve relevant multi-modality domain-specific information, and reason and synthesize diverse knowledge to generate an accurate response is important. To address the gap, we present BioMol-MQA, a new question-answering (QA) dataset on polypharmacy, which is composed of two parts (i) a multimodal knowledge graph (KG) with text and molecular structure for information retrieval; and (ii) challenging questions that designed to test LLM capabilities in retrieving and reasoning over multimodal KG to answer questions. Our benchmarks indicate that existing LLMs struggle to answer these questions and do well only when given the necessary background data, signaling the necessity for strong RAG frameworks.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.05766.pdf", "abstract_url": "https://arxiv.org/abs/2506.05766", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "BioMol-MQA是一个多模态问答数据集，旨在提升大型语言模型(LLMs)在生物分子相互作用推理方面的能力，特别是在多模态信息检索和知识合成方面。", "motivation": "解决现有基于检索增强生成(RAG)的大型语言模型主要局限于检索单一模态（主要是文本）信息的问题，特别是在医疗保健等领域，相关信息可能以多种形式存在，如知识图谱、文本和复杂分子结构。", "method": "提出了BioMol-MQA数据集，包含两部分：(i)一个包含文本和分子结构的多模态知识图谱用于信息检索；(ii)设计用于测试LLMs在多模态知识图谱上检索和推理能力的挑战性问题。", "result": "基准测试表明，现有的大型语言模型在回答这些问题时表现不佳，只有在提供必要背景数据时才能表现良好，这表明需要强大的RAG框架。", "conclusion": "BioMol-MQA数据集的引入强调了在多模态领域特定信息检索和知识合成方面开发更强RAG框架的必要性，以提升LLMs在复杂问题解答中的表现。"}}
{"id": "2506.05813", "title": "MAPLE: Multi-Agent Adaptive Planning with Long-Term Memory for Table Reasoning", "authors": ["Ye Bai", "Minghan Wang", "Thuy-Trang Vu"], "abstract": "Table-based question answering requires complex reasoning capabilities that current LLMs struggle to achieve with single-pass inference. Existing approaches, such as Chain-of-Thought reasoning and question decomposition, lack error detection mechanisms and discard problem-solving experiences, contrasting sharply with how humans tackle such problems. In this paper, we propose MAPLE (Multi-agent Adaptive Planning with Long-term mEmory), a novel framework that mimics human problem-solving through specialized cognitive agents working in a feedback-driven loop. MAPLE integrates 4 key components: (1) a Solver using the ReAct paradigm for reasoning, (2) a Checker for answer verification, (3) a Reflector for error diagnosis and strategy correction, and (4) an Archiver managing long-term memory for experience reuse and evolution. Experiments on WiKiTQ and TabFact demonstrate significant improvements over existing methods, achieving state-of-the-art performance across multiple LLM backbones.", "subjects": "Computation and Language (cs.CL)", "comments": "26 pages, 10 figures", "pdf_url": "https://arxiv.org/pdf/2506.05813.pdf", "abstract_url": "https://arxiv.org/abs/2506.05813", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "MAPLE是一种新颖的多代理自适应规划框架，具有长期记忆功能，用于表格推理，通过模拟人类问题解决过程，显著提高了表格问答的性能。", "motivation": "当前大型语言模型在单次推理中难以实现复杂的表格推理能力，现有方法缺乏错误检测机制且未利用问题解决经验，与人类解决问题的方式形成鲜明对比。", "method": "MAPLE框架包含四个关键组件：(1)使用ReAct范式进行推理的求解器，(2)用于答案验证的检查器，(3)用于错误诊断和策略修正的反射器，以及(4)管理长期记忆以重用和进化经验的归档器。", "result": "在WiKiTQ和TabFact上的实验表明，MAPLE在多个大型语言模型骨干上均实现了最先进的性能。", "conclusion": "MAPLE通过模拟人类问题解决的多代理协作和反馈驱动循环，为表格推理提供了一种有效的解决方案，显著提升了问答系统的性能。"}}
{"id": "2506.05426", "title": "Mixture-of-Experts Meets In-Context Reinforcement Learning", "authors": ["Wenhao Wu", "Fuhong Liu", "Haoru Li", "Zican Hu", "Daoyi Dong", "Chunlin Chen", "Zhi Wang"], "abstract": "In-context reinforcement learning (ICRL) has emerged as a promising paradigm for adapting RL agents to downstream tasks through prompt conditioning. However, two notable challenges remain in fully harnessing in-context learning within RL domains: the intrinsic multi-modality of the state-action-reward data and the diverse, heterogeneous nature of decision tasks. To tackle these challenges, we propose \\textbf{T2MIR} (\\textbf{T}oken- and \\textbf{T}ask-wise \\textbf{M}oE for \\textbf{I}n-context \\textbf{R}L), an innovative framework that introduces architectural advances of mixture-of-experts (MoE) into transformer-based decision models. T2MIR substitutes the feedforward layer with two parallel layers: a token-wise MoE that captures distinct semantics of input tokens across multiple modalities, and a task-wise MoE that routes diverse tasks to specialized experts for managing a broad task distribution with alleviated gradient conflicts. To enhance task-wise routing, we introduce a contrastive learning method that maximizes the mutual information between the task and its router representation, enabling more precise capture of task-relevant information. The outputs of two MoE components are concatenated and fed into the next layer. Comprehensive experiments show that T2MIR significantly facilitates in-context learning capacity and outperforms various types of baselines. We bring the potential and promise of MoE to ICRL, offering a simple and scalable architectural enhancement to advance ICRL one step closer toward achievements in language and vision communities. Our code is available at", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "26 pages, 13 figures", "pdf_url": "https://arxiv.org/pdf/2506.05426.pdf", "abstract_url": "https://arxiv.org/abs/2506.05426", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为T2MIR的创新框架，通过将混合专家（MoE）的架构进步引入基于变换器的决策模型，解决了在上下文强化学习（ICRL）中利用多模态状态-动作-奖励数据和多样化决策任务的挑战。T2MIR通过令牌级和任务级MoE，以及对比学习方法，显著提升了上下文学习能力，并在实验中优于多种基线方法。", "motivation": "解决在上下文强化学习（ICRL）中利用多模态状态-动作-奖励数据和多样化决策任务的挑战。", "method": "提出了T2MIR框架，该框架通过令牌级和任务级混合专家（MoE）以及对比学习方法，增强了基于变换器的决策模型。", "result": "T2MIR显著提升了上下文学习能力，并在实验中优于多种基线方法。", "conclusion": "T2MIR框架为ICRL提供了一种简单且可扩展的架构增强，使其更接近于语言和视觉社区的成就。"}}
{"id": "2506.06097", "title": "VideoChat-A1: Thinking with Long Videos by Chain-of-Shot Reasoning", "authors": ["Zikang Wang", "Boyu Chen", "Zhengrong Yue", "Yi Wang", "Yu Qiao", "Limin Wang", "Yali Wang"], "abstract": "The recent advance in video understanding has been driven by multimodal large language models (MLLMs). But these MLLMs are good at analyzing short videos, while suffering from difficulties in understanding videos with a longer context. To address this difficulty, several agent paradigms have recently been proposed, using MLLMs as agents for retrieving extra contextual knowledge in a long video. However, most existing agents ignore the key fact that a long video is composed with multiple shots, i.e., to answer the user question from a long video, it is critical to deeply understand its relevant shots like human. Without such insight, these agents often mistakenly find redundant even noisy temporal context, restricting their capacity for long video understanding. To fill this gap, we propose VideoChat-A1, a novel long video agent paradigm. Different from the previous works, our VideoChat-A1 can deeply think with long videos, via a distinct chain-of-shot reasoning paradigm. More specifically, it can progressively select the relevant shots of user question, and look into these shots in a coarse-to-fine partition. By multi-modal reasoning along the shot chain, VideoChat-A1 can effectively mimic step-by-step human thinking process, allowing to interactively discover preferable temporal context for thoughtful understanding in long videos. Extensive experiments show that, our VideoChat-A1 achieves the state-of-the-art performance on the mainstream long video QA benchmarks, e.g., it achieves 77.0 on VideoMME and 70.1 on EgoSchema, outperforming its strong baselines (e.g., Intern2.5VL-8B and InternVideo2.5-8B), by up to 10.8\\% and 6.2\\%. Compared to leading close-source GPT-4o and Gemini 1.5 Pro, VideoChat-A1 offers competitive accuracy, but with 7\\% input frames and 12\\% inference time on average.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.06097.pdf", "abstract_url": "https://arxiv.org/abs/2506.06097", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "VideoChat-A1是一种新型的长视频代理范式，通过链式镜头推理深入理解长视频，模仿人类逐步思考过程，有效选择相关镜头进行多模态推理，显著提升长视频理解性能。", "motivation": "现有的多模态大语言模型（MLLMs）在分析短视频时表现良好，但在理解长视频上下文时存在困难。现有的代理范式大多忽略了长视频由多个镜头组成的关键事实，导致在回答用户问题时可能找到冗余甚至噪声的时间上下文，限制了长视频理解的能力。", "method": "提出VideoChat-A1，采用链式镜头推理范式，逐步选择与用户问题相关的镜头，并通过粗到细的分区深入这些镜头，通过多模态推理模仿人类的逐步思考过程。", "result": "在主流长视频QA基准测试中，VideoChat-A1实现了最先进的性能，如在VideoMME上达到77.0，在EgoSchema上达到70.1，比其强大基线（如Intern2.5VL-8B和InternVideo2.5-8B）高出10.8%和6.2%。与领先的闭源GPT-4o和Gemini 1.5 Pro相比，VideoChat-A1提供了竞争性的准确性，但平均输入帧数和推理时间分别减少了7%和12%。", "conclusion": "VideoChat-A1通过链式镜头推理范式，有效模仿人类逐步思考过程，显著提升了长视频理解的性能，为长视频理解领域提供了新的解决方案。"}}
{"id": "2506.06128", "title": "CCLSTM: Coupled Convolutional Long-Short Term Memory Network for Occupancy Flow Forecasting", "authors": ["Peter Lengyel"], "abstract": "Predicting future states of dynamic agents is a fundamental task in autonomous driving. An expressive representation for this purpose is Occupancy Flow Fields, which provide a scalable and unified format for modeling motion, spatial extent, and multi-modal future distributions. While recent methods have achieved strong results using this representation, they often depend on high-quality vectorized inputs, which are unavailable or difficult to generate in practice, and the use of transformer-based architectures, which are computationally intensive and costly to deploy. To address these issues, we propose \\textbf{Coupled Convolutional LSTM (CCLSTM)}, a lightweight, end-to-end trainable architecture based solely on convolutional operations. Without relying on vectorized inputs or self-attention mechanisms, CCLSTM effectively captures temporal dynamics and spatial occupancy-flow correlations using a compact recurrent convolutional structure. Despite its simplicity, CCLSTM achieves state-of-the-art performance on occupancy flow metrics and, as of this submission, ranks \\(1^{\\text{st}}\\) in all metrics on the 2024 Waymo Occupancy and Flow Prediction Challenge leaderboard.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.06128.pdf", "abstract_url": "https://arxiv.org/abs/2506.06128", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "CCLSTM是一种轻量级的端到端可训练架构，基于卷积操作，用于预测动态代理的未来状态，特别是在自动驾驶中的占用流场预测。", "motivation": "解决现有方法依赖高质量矢量化输入和计算密集型变压器架构的问题，这些在实际中难以获取或部署成本高。", "method": "提出耦合卷积长短期记忆网络（CCLSTM），仅基于卷积操作，不依赖矢量化输入或自注意力机制，有效捕捉时间动态和空间占用流相关性。", "result": "CCLSTM在占用流指标上实现了最先进的性能，并在2024 Waymo占用和流预测挑战赛中所有指标上排名第一。", "conclusion": "CCLSTM以其简单性和高效性，为自动驾驶中的动态代理未来状态预测提供了一种实用的解决方案。"}}
{"id": "2506.06017", "title": "AgentSwift: Efficient LLM Agent Design via Value-guided Hierarchical Search", "authors": ["Yu Li", "Lehui Li", "Zhihao Wu", "Qingmin Liao", "Jianye Hao", "Kun Shao", "Fengli Xu", "Yong Li"], "abstract": "Large language model (LLM) agents have demonstrated strong capabilities across diverse domains. However, designing high-performing agentic systems remains challenging. Existing agent search methods suffer from three major limitations: (1) an emphasis on optimizing agentic workflows while under-utilizing proven human-designed components such as memory, planning, and tool use; (2) high evaluation costs, as each newly generated agent must be fully evaluated on benchmarks; and (3) inefficient search in large search space. In this work, we introduce a comprehensive framework to address these challenges. First, We propose a hierarchical search space that jointly models agentic workflow and composable functional components, enabling richer agentic system designs. Building on this structured design space, we introduce a predictive value model that estimates agent performance given agentic system and task description, allowing for efficient, low-cost evaluation during the search process. Finally, we present a hierarchical Monte Carlo Tree Search (MCTS) strategy informed by uncertainty to guide the search. Experiments on seven benchmarks, covering embodied, math, web, tool, and game, show that our method achieves an average performance gain of 8.34\\% over state-of-the-art baselines and exhibits faster search progress with steeper improvement trajectories. Code repo is available at", "subjects": "Computation and Language (cs.CL)", "comments": "20pages", "pdf_url": "https://arxiv.org/pdf/2506.06017.pdf", "abstract_url": "https://arxiv.org/abs/2506.06017", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了AgentSwift，一个通过价值引导的层次搜索设计高效LLM代理的框架，解决了现有代理搜索方法的三个主要限制，并在七个基准测试中展示了优于现有方法的性能。", "motivation": "设计高性能的LLM代理系统具有挑战性，现有方法在优化代理工作流程、高评估成本和大搜索空间中的低效搜索方面存在局限。", "method": "提出一个层次搜索空间，联合建模代理工作流程和可组合功能组件，引入预测价值模型估计代理性能，并采用层次蒙特卡洛树搜索策略指导搜索。", "result": "在七个基准测试中，该方法平均性能比现有最优基线提高了8.34%，且搜索进度更快，改进轨迹更陡。", "conclusion": "AgentSwift框架通过层次搜索空间、预测价值模型和层次MCTS策略，有效解决了LLM代理设计中的挑战，显著提升了代理性能。"}}
{"id": "2506.06020", "title": "When to Trust Context: Self-Reflective Debates for Context Reliability", "authors": ["Zeqi Zhou", "Fang Wu", "Shayan Talaei", "Haokai Zhao", "Cheng Meixin", "Tinson Xu", "Amin Saberi", "Yejin Choi"], "abstract": "Large language models frequently encounter conflicts between their parametric knowledge and contextual input, often resulting in factual inconsistencies or hallucinations. We propose Self-Reflective Debate for Contextual Reliability (SR-DCR), a lightweight framework that integrates token-level self-confidence with an asymmetric multi-agent debate to adjudicate such conflicts. A critic, deprived of context, challenges a defender who argues from the given passage; a judge model evaluates the debate and determines the context's reliability. The final answer is selected by combining the verdict with model confidence. Experiments on the ClashEval benchmark demonstrate that SR-DCR consistently enhances robustness to misleading context while maintaining accuracy on trustworthy inputs, outperforming both classical debate and confidence-only baselines with minimal computational overhead. The code is available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.06020.pdf", "abstract_url": "https://arxiv.org/abs/2506.06020", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一个名为SR-DCR的轻量级框架，通过结合令牌级自信度和非对称多代理辩论来解决大型语言模型中参数知识与上下文输入之间的冲突，以提高上下文的可靠性。", "motivation": "大型语言模型在处理参数知识与上下文输入之间的冲突时，经常产生事实不一致或幻觉，本文旨在解决这一问题。", "method": "SR-DCR框架通过令牌级自我自信度和非对称多代理辩论（包括一个无上下文的批评者、一个基于给定段落辩护的辩护者以及一个评估辩论并确定上下文可靠性的法官模型）来裁决冲突。", "result": "在ClashEval基准测试中，SR-DCR在保持可信输入准确性的同时，显著提高了对误导性上下文的鲁棒性，且计算开销最小。", "conclusion": "SR-DCR框架有效提升了大型语言模型在处理上下文冲突时的可靠性，且在实际应用中具有高效性和实用性。"}}
{"id": "2506.06091", "title": "MIRIAD: Augmenting LLMs with millions of medical query-response pairs", "authors": ["Qinyue Zheng", "Salman Abdullah", "Sam Rawal", "Cyril Zakka", "Sophie Ostmeier", "Maximilian Purk", "Eduardo Reis", "Eric J. Topol", "Jure Leskovec", "Michael Moor"], "abstract": "LLMs are bound to transform healthcare with advanced decision support and flexible chat assistants. However, LLMs are prone to generate inaccurate medical content. To ground LLMs in high-quality medical knowledge, LLMs have been equipped with external knowledge via RAG, where unstructured medical knowledge is split into small text chunks that can be selectively retrieved and integrated into the LLMs context. Yet, existing RAG pipelines rely on raw, unstructured medical text, which can be noisy, uncurated and difficult for LLMs to effectively leverage. Systematic approaches to organize medical knowledge to best surface it to LLMs are generally lacking. To address these challenges, we introduce MIRIAD, a large-scale, curated corpus of 5,821,948 medical QA pairs, each rephrased from and grounded in a passage from peer-reviewed medical literature using a semi-automated pipeline combining LLM generation, filtering, grounding, and human annotation. Unlike prior medical corpora, which rely on unstructured text, MIRIAD encapsulates web-scale medical knowledge in an operationalized query-response format, which enables more targeted retrieval. Experiments on challenging medical QA benchmarks show that augmenting LLMs with MIRIAD improves accuracy up to 6.7% compared to unstructured RAG baselines with the same source corpus and with the same amount of retrieved text. Moreover, MIRIAD improved the ability of LLMs to detect medical hallucinations by 22.5 to 37% (increase in F1 score). We further introduce MIRIAD-Atlas, an interactive map of MIRIAD spanning 56 medical disciplines, enabling clinical users to visually explore, search, and refine medical knowledge. MIRIAD promises to unlock a wealth of down-stream applications, including medical information retrievers, enhanced RAG applications, and knowledge-grounded chat interfaces, which ultimately enables more reliable LLM applications in healthcare.", "subjects": "Computation and Language (cs.CL)", "comments": "Preprint", "pdf_url": "https://arxiv.org/pdf/2506.06091.pdf", "abstract_url": "https://arxiv.org/abs/2506.06091", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了MIRIAD，一个包含5,821,948个医学问答对的大规模、精选语料库，旨在通过半自动化流程结合LLM生成、过滤、基础和人工注释，将LLMs与高质量的医学知识相结合，以提高医疗问答的准确性和检测医学幻觉的能力。", "motivation": "解决LLMs在生成准确医学内容方面的不足，以及现有RAG管道依赖原始、非结构化医学文本的问题，这些文本可能嘈杂、未经整理，难以有效利用。", "method": "引入MIRIAD语料库，采用半自动化流程结合LLM生成、过滤、基础和人工注释，将医学知识以查询-响应格式封装，实现更有针对性的检索。", "result": "实验显示，与使用相同源语料库和相同检索文本量的非结构化RAG基线相比，使用MIRIAD增强LLMs的准确性提高了6.7%，检测医学幻觉的能力提高了22.5%至37%。", "conclusion": "MIRIAD有望解锁包括医学信息检索器、增强的RAG应用和知识基础的聊天界面在内的下游应用，最终在医疗保健领域实现更可靠的LLM应用。"}}
{"id": "2506.05437", "title": "A MARL-based Approach for Easing MAS Organization Engineering", "authors": ["Julien Soulé", "Jean-Paul Jamont", "Michel Occello", "Louis-Marie Traonouez", "Paul Théron"], "abstract": "Multi-Agent Systems (MAS) have been successfully applied in industry for their ability to address complex, distributed problems, especially in IoT-based systems. Their efficiency in achieving given objectives and meeting design requirements is strongly dependent on the MAS organization during the engineering process of an application-specific MAS. To design a MAS that can achieve given goals, available methods rely on the designer's knowledge of the deployment environment. However, high complexity and low readability in some deployment environments make the application of these methods to be costly or raise safety concerns. In order to ease the MAS organization design regarding those concerns, we introduce an original Assisted MAS Organization Engineering Approach (AOMEA). AOMEA relies on combining a Multi-Agent Reinforcement Learning (MARL) process with an organizational model to suggest relevant organizational specifications to help in MAS engineering.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.05437.pdf", "abstract_url": "https://arxiv.org/abs/2506.05437", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于多智能体强化学习（MARL）的方法AOMEA，旨在简化多智能体系统（MAS）的组织工程设计，特别是在复杂和低可读性的部署环境中。", "motivation": "多智能体系统（MAS）在工业中的应用因其解决复杂、分布式问题的能力而成功，尤其是在基于物联网的系统中。然而，设计一个能够实现给定目标的MAS依赖于设计师对部署环境的了解，而高复杂性和低可读性的环境使得这些方法的应用成本高昂或引发安全问题。", "method": "为了简化MAS组织设计并解决上述问题，作者提出了一种名为AOMEA的辅助MAS组织工程方法，该方法结合了多智能体强化学习（MARL）过程和组织模型，以建议相关的组织规范来帮助MAS工程。", "result": "AOMEA方法通过结合MARL和组织模型，能够有效地为MAS工程提供相关的组织规范建议，从而简化设计过程并降低成本和风险。", "conclusion": "AOMEA方法为MAS组织工程提供了一种有效的解决方案，特别是在复杂和低可读性的环境中，通过结合MARL和组织模型，能够简化设计过程并提高安全性和效率。"}}
{"id": "2506.06175", "title": "Does It Run and Is That Enough? Revisiting Text-to-Chart Generation with a Multi-Agent Approach", "authors": ["James Ford", "Anthony Rios"], "abstract": "Large language models can translate natural-language chart descriptions into runnable code, yet approximately 15\\% of the generated scripts still fail to execute, even after supervised fine-tuning and reinforcement learning. We investigate whether this persistent error rate stems from model limitations or from reliance on a single-prompt design. To explore this, we propose a lightweight multi-agent pipeline that separates drafting, execution, repair, and judgment, using only an off-the-shelf GPT-4o-mini model. On the \\textsc{Text2Chart31} benchmark, our system reduces execution errors to 4.5\\% within three repair iterations, outperforming the strongest fine-tuned baseline by nearly 5 percentage points while requiring significantly less compute. Similar performance is observed on the \\textsc{ChartX} benchmark, with an error rate of 4.6\\%, demonstrating strong generalization. Under current benchmarks, execution success appears largely solved. However, manual review reveals that 6 out of 100 sampled charts contain hallucinations, and an LLM-based accessibility audit shows that only 33.3\\% (\\textsc{Text2Chart31}) and 7.2\\% (\\textsc{ChartX}) of generated charts satisfy basic colorblindness guidelines. These findings suggest that future work should shift focus from execution reliability toward improving chart aesthetics, semantic fidelity, and accessibility.", "subjects": "Computation and Language (cs.CL)", "comments": "8 pages", "pdf_url": "https://arxiv.org/pdf/2506.06175.pdf", "abstract_url": "https://arxiv.org/abs/2506.06175", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了大型语言模型在将自然语言图表描述转换为可运行代码时的执行失败问题，提出了一种轻量级多代理管道方法，显著降低了执行错误率，并指出了未来工作应关注图表的美观性、语义保真度和可访问性。", "motivation": "尽管大型语言模型能够将自然语言图表描述转换为可运行代码，但约15%的生成脚本仍无法执行。本研究旨在探索这一持续错误率是源于模型限制还是单一提示设计。", "method": "提出了一种轻量级多代理管道，将起草、执行、修复和判断分离，仅使用现成的GPT-4o-mini模型。", "result": "在\\textsc{Text2Chart31}基准测试中，系统在三轮修复迭代后将执行错误率降至4.5%，优于最强的微调基线近5个百分点，同时在\\textsc{ChartX}基准测试中表现出色，错误率为4.6%。然而，手动审查发现6%的图表存在幻觉，且基于LLM的可访问性审计显示，仅33.3%（\\textsc{Text2Chart31}）和7.2%（\\textsc{ChartX}）的生成图表满足基本色盲指南。", "conclusion": "当前基准测试中执行成功率看似已解决，但未来工作应转向提高图表美观性、语义保真度和可访问性。"}}
{"id": "2506.06208", "title": "Building Models of Neurological Language", "authors": ["Henry Watkins"], "abstract": "This report documents the development and evaluation of domain-specific language models for neurology. Initially focused on building a bespoke model, the project adapted to rapid advances in open-source and commercial medical LLMs, shifting toward leveraging retrieval-augmented generation (RAG) and representational models for secure, local deployment. Key contributions include the creation of neurology-specific datasets (case reports, QA sets, textbook-derived data), tools for multi-word expression extraction, and graph-based analyses of medical terminology. The project also produced scripts and Docker containers for local hosting. Performance metrics and graph community results are reported, with future possible work open for multimodal models using open-source architectures like phi-4.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "21 pages, 6 figures", "pdf_url": "https://arxiv.org/pdf/2506.06208.pdf", "abstract_url": "https://arxiv.org/abs/2506.06208", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文档记录了神经学领域特定语言模型的开发和评估过程。项目最初旨在构建定制模型，后转向利用检索增强生成（RAG）和表示模型，以适应开源和商业医疗LLM的快速发展。主要贡献包括创建神经学特定数据集、多词表达提取工具、医学术语的图基分析，以及本地托管脚本和Docker容器。报告了性能指标和图社区结果，并展望了使用phi-4等开源架构的多模态模型未来工作。", "motivation": "解决神经学领域特定语言处理的需求，适应医疗LLM的快速发展，实现安全、本地的部署。", "method": "采用检索增强生成（RAG）和表示模型，创建神经学特定数据集，开发多词表达提取工具，进行图基分析，以及制作本地托管脚本和Docker容器。", "result": "成功开发了神经学特定语言模型和相关工具，报告了性能指标和图社区分析结果。", "conclusion": "项目展示了在神经学领域开发和部署特定语言模型的可行性，为未来多模态模型的研究和开发奠定了基础。"}}
{"id": "2506.06214", "title": "Can Theoretical Physics Research Benefit from Language Agents?", "authors": ["Sirui Lu", "Zhijing Jin", "Terry Jingchen Zhang", "Pavel Kos", "J. Ignacio Cirac", "Bernhard Schölkopf"], "abstract": "Large Language Models (LLMs) are rapidly advancing across diverse domains, yet their application in theoretical physics research is not yet mature. This position paper argues that LLM agents can potentially help accelerate theoretical, computational, and applied physics when properly integrated with domain knowledge and toolbox. We analyze current LLM capabilities for physics -- from mathematical reasoning to code generation -- identifying critical gaps in physical intuition, constraint satisfaction, and reliable reasoning. We envision future physics-specialized LLMs that could handle multimodal data, propose testable hypotheses, and design experiments. Realizing this vision requires addressing fundamental challenges: ensuring physical consistency, and developing robust verification methods. We call for collaborative efforts between physics and AI communities to help advance scientific discovery in physics.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Mathematical Physics (math-ph); Quantum Physics (quant-ph)", "comments": "9 pages", "pdf_url": "https://arxiv.org/pdf/2506.06214.pdf", "abstract_url": "https://arxiv.org/abs/2506.06214", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Mathematical Physics (math-ph)", "Quantum Physics (quant-ph)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了大型语言模型（LLMs）在理论物理研究中的潜在应用，分析了当前LLMs在物理领域的数学推理和代码生成等方面的能力，并指出了在物理直觉、约束满足和可靠推理方面的关键差距。文章展望了未来物理专用LLMs的可能性，包括处理多模态数据、提出可测试假设和设计实验等，并呼吁物理和AI社区合作以推动科学发现。", "motivation": "探讨大型语言模型（LLMs）如何通过与领域知识和工具的结合，加速理论、计算和应用物理的研究，尽管目前LLMs在理论物理研究中的应用尚未成熟。", "method": "分析了当前LLMs在物理领域的数学推理和代码生成等能力，识别了在物理直觉、约束满足和可靠推理方面的关键差距。", "result": "指出了开发物理专用LLMs的潜在方向，包括处理多模态数据、提出可测试假设和设计实验等，同时提出了确保物理一致性和开发稳健验证方法的基本挑战。", "conclusion": "呼吁物理和AI社区合作，共同解决开发物理专用LLMs面临的基本挑战，以推动物理学中的科学发现。"}}
{"id": "2506.06240", "title": "Bridging External and Parametric Knowledge: Mitigating Hallucination of LLMs with Shared-Private Semantic Synergy in Dual-Stream Knowledge", "authors": ["Yi Sui", "Chaozhuo Li", "Chen Zhang", "Dawei song", "Qiuchi Li"], "abstract": "Retrieval-augmented generation (RAG) is a cost-effective approach to mitigate the hallucination of Large Language Models (LLMs) by incorporating the retrieved external knowledge into the generation process. However, external knowledge may conflict with the parametric knowledge of LLMs. Furthermore, current LLMs lack inherent mechanisms for resolving such knowledge conflicts, making traditional RAG methods suffer from degraded performance and stability. Thus, we propose a Dual-Stream Knowledge-Augmented Framework for Shared-Private Semantic Synergy (DSSP-RAG). Central to the framework is a novel approach that refines self-attention into a mixed-attention, distinguishing shared and private semantics for a controlled internal-external knowledge integration. To effectively facilitate DSSP in RAG, we further introduce an unsupervised hallucination detection method based on cognitive uncertainty, ensuring the necessity of introducing knowledge, and an Energy Quotient (EQ) based on attention difference matrices to reduce noise in the retrieved external knowledge. Extensive experiments on benchmark datasets show that DSSP-RAG can effectively resolve conflicts and enhance the complementarity of dual-stream knowledge, leading to superior performance over strong baselines.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.06240.pdf", "abstract_url": "https://arxiv.org/abs/2506.06240", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种名为DSSP-RAG的双流知识增强框架，旨在通过共享-私有语义协同解决大型语言模型（LLMs）的幻觉问题，通过混合注意力机制和认知不确定性检测方法，有效整合内部与外部知识，减少知识冲突和噪声，提升模型性能。", "motivation": "大型语言模型（LLMs）在生成过程中可能会出现幻觉问题，即生成与事实不符的内容。检索增强生成（RAG）是一种通过引入外部知识来缓解这一问题的方法，但外部知识与模型内部知识可能发生冲突，且现有模型缺乏解决这种冲突的机制，导致性能下降。", "method": "提出DSSP-RAG框架，采用混合注意力机制区分共享和私有语义，实现内外知识的可控整合；引入基于认知不确定性的无监督幻觉检测方法，确保知识引入的必要性；使用基于注意力差异矩阵的能量商（EQ）减少外部知识中的噪声。", "result": "在多个基准数据集上的实验表明，DSSP-RAG能够有效解决知识冲突，增强双流知识的互补性，性能优于现有基线方法。", "conclusion": "DSSP-RAG框架通过共享-私有语义协同和混合注意力机制，有效缓解了LLMs的幻觉问题，提升了模型在知识整合和生成任务中的性能和稳定性。"}}
{"id": "2506.05577", "title": "Collaborative Learning in Agentic Systems: A Collective AI is Greater Than the Sum of Its Parts", "authors": ["Saptarshi Nath", "Christos Peridis", "Eseoghene Benjamin", "Xinran Liu", "Soheil Kolouri", "Peter Kinnell", "Zexin Li", "Cong Liu", "Shirin Dora", "Andrea Soltoggio"], "abstract": "Agentic AI has gained significant interest as a research paradigm focused on autonomy, self-directed learning, and long-term reliability of decision making. Real-world agentic systems operate in decentralized settings on a large set of tasks or data distributions with constraints such as limited bandwidth, asynchronous execution, and the absence of a centralized model or even common objectives. We posit that exploiting previously learned skills, task similarities, and communication capabilities in a collective of agentic AI are challenging but essential elements to enabling scalability, open-endedness, and beneficial collaborative learning dynamics. In this paper, we introduce Modular Sharing and Composition in Collective Learning (MOSAIC), an agentic algorithm that allows multiple agents to independently solve different tasks while also identifying, sharing, and reusing useful machine-learned knowledge, without coordination, synchronization, or centralized control. MOSAIC combines three mechanisms: (1) modular policy composition via neural network masks, (2) cosine similarity estimation using Wasserstein embeddings for knowledge selection, and (3) asynchronous communication and policy integration. Results on a set of RL benchmarks show that MOSAIC has a greater sample efficiency than isolated learners, i.e., it learns significantly faster, and in some cases, finds solutions to tasks that cannot be solved by isolated learners. The collaborative learning and sharing dynamics are also observed to result in the emergence of ideal curricula of tasks, from easy to hard. These findings support the case for collaborative learning in agentic systems to achieve better and continuously evolving performance both at the individual and collective levels.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "36 pages, 21 figures, 6 tables. Preprint", "pdf_url": "https://arxiv.org/pdf/2506.05577.pdf", "abstract_url": "https://arxiv.org/abs/2506.05577", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了MOSAIC算法，一种支持多智能体在无需协调、同步或集中控制的情况下，独立解决不同任务并共享和重用机器学习知识的代理算法。通过结合模块化策略组合、Wasserstein嵌入的余弦相似度估计和异步通信与策略集成，MOSAIC在RL基准测试中显示出比孤立学习者更高的样本效率，有时还能解决孤立学习者无法解决的任务。", "motivation": "解决在分散设置中运行的代理AI系统面临的挑战，如有限带宽、异步执行和缺乏集中模型或共同目标，以及如何利用先前学习的技能、任务相似性和通信能力来实现可扩展性、开放性和有益的协作学习动态。", "method": "引入MOSAIC算法，结合（1）通过神经网络掩码的模块化策略组合，（2）使用Wasserstein嵌入进行知识选择的余弦相似度估计，和（3）异步通信和策略集成。", "result": "MOSAIC在RL基准测试中显示出比孤立学习者更高的样本效率，有时还能解决孤立学习者无法解决的任务，并观察到从易到难的任务理想课程的出现。", "conclusion": "支持在代理系统中进行协作学习，以在个体和集体层面实现更好且持续演化的性能。"}}
{"id": "2506.05817", "title": "CodeContests+: High-Quality Test Case Generation for Competitive Programming", "authors": ["Zihan Wang", "Siyao Liu", "Yang Sun", "Hongyan Li", "Kai Shen"], "abstract": "Competitive programming, due to its high reasoning difficulty and precise correctness feedback, has become a key task for both training and evaluating the reasoning capabilities of large language models (LLMs). However, while a large amount of public problem data, such as problem statements and solutions, is available, the test cases of these problems are often difficult to obtain. Therefore, test case generation is a necessary task for building large-scale datasets, and the quality of the test cases directly determines the accuracy of the evaluation. In this paper, we introduce an LLM-based agent system that creates high-quality test cases for competitive programming problems. We apply this system to the CodeContests dataset and propose a new version with improved test cases, named CodeContests+. We evaluated the quality of test cases in CodeContestsPlus. First, we used 1.72 million submissions with pass/fail labels to examine the accuracy of these test cases in evaluation. The results indicated that CodeContests+ achieves significantly higher accuracy than CodeContests, particularly with a notably higher True Positive Rate (TPR). Subsequently, our experiments in LLM Reinforcement Learning (RL) further confirmed that improvements in test case quality yield considerable advantages for RL.", "subjects": "Software Engineering (cs.SE); Computation and Language (cs.CL)", "comments": "28 pages, 7 figures", "pdf_url": "https://arxiv.org/pdf/2506.05817.pdf", "abstract_url": "https://arxiv.org/abs/2506.05817", "categories": ["Software Engineering (cs.SE)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了CodeContests+，一个基于大型语言模型（LLM）的代理系统，用于为竞争性编程问题生成高质量的测试用例，显著提高了评估的准确性。", "motivation": "竞争性编程由于其高推理难度和精确的正确性反馈，已成为训练和评估大型语言模型（LLM）推理能力的关键任务。然而，尽管有大量公开的问题数据可用，但这些问题的测试用例往往难以获取。因此，测试用例生成是构建大规模数据集的必要任务，测试用例的质量直接决定了评估的准确性。", "method": "本文引入了一个基于LLM的代理系统，该系统为竞争性编程问题创建高质量的测试用例，并将其应用于CodeContests数据集，提出了一个名为CodeContests+的新版本，其中包含改进的测试用例。", "result": "通过使用172万带有通过/失败标签的提交来检查这些测试用例在评估中的准确性，结果表明CodeContests+的准确性显著高于CodeContests，特别是真阳性率（TPR）显著更高。此外，LLM强化学习（RL）的实验进一步证实，测试用例质量的提高为RL带来了相当大的优势。", "conclusion": "本文提出的CodeContests+通过基于LLM的代理系统生成高质量的测试用例，显著提高了竞争性编程问题评估的准确性，并为LLM的强化学习带来了优势。"}}
{"id": "2506.06166", "title": "The Lock-in Hypothesis: Stagnation by Algorithm", "authors": ["Tianyi Alex Qiu", "Zhonghao He", "Tejasveer Chugh", "Max Kleiman-Weiner"], "abstract": "The training and deployment of large language models (LLMs) create a feedback loop with human users: models learn human beliefs from data, reinforce these beliefs with generated content, reabsorb the reinforced beliefs, and feed them back to users again and again. This dynamic resembles an echo chamber. We hypothesize that this feedback loop entrenches the existing values and beliefs of users, leading to a loss of diversity and potentially the lock-in of false beliefs. We formalize this hypothesis and test it empirically with agent-based LLM simulations and real-world GPT usage data. Analysis reveals sudden but sustained drops in diversity after the release of new GPT iterations, consistent with the hypothesized human-AI feedback loop. Code and data available at", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computers and Society (cs.CY); Human-Computer Interaction (cs.HC)", "comments": "ICML 2025, 46 pages", "pdf_url": "https://arxiv.org/pdf/2506.06166.pdf", "abstract_url": "https://arxiv.org/abs/2506.06166", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Computers and Society (cs.CY)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了‘锁定假说’，探讨了大型语言模型（LLMs）与人类用户之间的反馈循环如何可能导致现有价值观和信仰的固化，进而引发多样性的丧失和错误信仰的锁定。通过基于代理的LLM模拟和真实世界的GPT使用数据，研究验证了这一假说。", "motivation": "解决大型语言模型与人类用户互动中可能产生的反馈循环问题，这种循环可能导致多样性的减少和错误信仰的固化。", "method": "通过基于代理的LLM模拟和真实世界的GPT使用数据，对反馈循环的影响进行了形式化假设和实证测试。", "result": "分析显示，新GPT版本的发布后，多样性出现了突然但持续的下降，这与假设的人机反馈循环一致。", "conclusion": "研究表明，大型语言模型与人类用户之间的反馈循环可能导致多样性的丧失和错误信仰的锁定，这对未来的AI发展和应用提出了重要警示。"}}
{"id": "2506.05702", "title": "Action-Adaptive Continual Learning: Enabling Policy Generalization under Dynamic Action Spaces", "authors": ["Chaofan Pan", "Jiafen Liu", "Yanhua Li", "Linbo Xiong", "Fan Min", "Wei Wei", "Xin Yang"], "abstract": "Continual Learning (CL) is a powerful tool that enables agents to learn a sequence of tasks, accumulating knowledge learned in the past and using it for problem-solving or future task learning. However, existing CL methods often assume that the agent's capabilities remain static within dynamic environments, which doesn't reflect real-world scenarios where capabilities dynamically change. This paper introduces a new and realistic problem: Continual Learning with Dynamic Capabilities (CL-DC), posing a significant challenge for CL agents: How can policy generalization across different action spaces be achieved? Inspired by the cortical functions, we propose an Action-Adaptive Continual Learning framework (AACL) to address this challenge. Our framework decouples the agent's policy from the specific action space by building an action representation space. For a new action space, the encoder-decoder of action representations is adaptively fine-tuned to maintain a balance between stability and plasticity. Furthermore, we release a benchmark based on three environments to validate the effectiveness of methods for CL-DC. Experimental results demonstrate that our framework outperforms popular methods by generalizing the policy across action spaces.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.05702.pdf", "abstract_url": "https://arxiv.org/abs/2506.05702", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新的持续学习问题——动态能力持续学习（CL-DC），并提出了一个行动适应性持续学习框架（AACL）来解决这一挑战。AACL通过构建行动表示空间，将代理的策略与特定行动空间解耦，从而在新行动空间中实现策略的泛化。实验结果表明，AACL在三种环境下的基准测试中优于流行方法。", "motivation": "现有的持续学习方法通常假设代理的能力在动态环境中保持不变，这与现实世界中能力动态变化的场景不符。本文旨在解决如何在不同的行动空间中实现策略泛化的问题。", "method": "本文提出了一个行动适应性持续学习框架（AACL），该框架通过构建行动表示空间，将代理的策略与特定行动空间解耦。对于新的行动空间，行动表示的编码器-解码器会自适应地进行微调，以保持稳定性和可塑性之间的平衡。", "result": "实验结果表明，AACL框架在基于三种环境的基准测试中，能够有效地实现跨行动空间的策略泛化，优于现有的流行方法。", "conclusion": "本文提出的AACL框架为解决动态能力持续学习问题提供了一种有效的方法，能够在新行动空间中实现策略的泛化，为持续学习领域的研究开辟了新的方向。"}}
{"id": "2506.05739", "title": "To Protect the LLM Agent Against the Prompt Injection Attack with Polymorphic Prompt", "authors": ["Zhilong Wang", "Neha Nagaraja", "Lan Zhang", "Hayretdin Bahsi", "Pawan Patil", "Peng Liu"], "abstract": "LLM agents are widely used as agents for customer support, content generation, and code assistance. However, they are vulnerable to prompt injection attacks, where adversarial inputs manipulate the model's behavior. Traditional defenses like input sanitization, guard models, and guardrails are either cumbersome or ineffective. In this paper, we propose a novel, lightweight defense mechanism called Polymorphic Prompt Assembling (PPA), which protects against prompt injection with near-zero overhead. The approach is based on the insight that prompt injection requires guessing and breaking the structure of the system prompt. By dynamically varying the structure of system prompts, PPA prevents attackers from predicting the prompt structure, thereby enhancing security without compromising performance. We conducted experiments to evaluate the effectiveness of PPA against existing attacks and compared it with other defense methods.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": "To appear in the Industry Track of the 55th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN 2025)", "pdf_url": "https://arxiv.org/pdf/2506.05739.pdf", "abstract_url": "https://arxiv.org/abs/2506.05739", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为多态提示组装（PPA）的新型轻量级防御机制，旨在保护LLM代理免受提示注入攻击，该方法通过动态变化系统提示的结构来增强安全性，且几乎不产生额外开销。", "motivation": "LLM代理在客户支持、内容生成和代码辅助等领域广泛应用，但它们容易受到提示注入攻击的影响，传统防御方法要么繁琐要么无效。", "method": "提出的多态提示组装（PPA）方法基于提示注入需要猜测并破坏系统提示结构的洞察，通过动态变化提示结构来防止攻击者预测提示结构。", "result": "实验评估表明，PPA能有效防御现有攻击，且与其他防御方法相比具有优势。", "conclusion": "PPA提供了一种既安全又不影响性能的解决方案，为LLM代理的安全防护开辟了新途径。"}}
{"id": "2506.05925", "title": "Small Models, Big Support: A Local LLM Framework for Teacher-Centric Content Creation and Assessment using RAG and CAG", "authors": ["Zarreen Reza", "Alexander Mazur", "Michael T. Dugdale", "Robin Ray-Chaudhuri"], "abstract": "While Large Language Models (LLMs) are increasingly utilized as student-facing educational aids, their potential to directly support educators, particularly through locally deployable and customizable open-source solutions, remains significantly underexplored. Many existing educational solutions rely on cloud-based infrastructure or proprietary tools, which are costly and may raise privacy concerns. Regulated industries with limited budgets require affordable, self-hosted solutions. We introduce an end-to-end, open-source framework leveraging small (3B-7B parameters), locally deployed LLMs for customized teaching material generation and assessment. Our system uniquely incorporates an interactive loop crucial for effective small-model refinement, and an auxiliary LLM verifier to mitigate jailbreaking risks, enhancing output reliability and safety. Utilizing Retrieval and Context Augmented Generation (RAG/CAG), it produces factually accurate, customized pedagogically-styled content. Deployed on-premises for data privacy and validated through an evaluation pipeline and a college physics pilot, our findings show that carefully engineered small LLM systems can offer robust, affordable, practical, and safe educator support, achieving utility comparable to larger models for targeted tasks.", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.05925.pdf", "abstract_url": "https://arxiv.org/abs/2506.05925", "categories": ["Computers and Society (cs.CY)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了一个开源框架，利用小型本地部署的LLM（3B-7B参数）为教育工作者提供定制化的教学材料生成和评估支持，通过RAG/CAG技术确保内容的准确性和教育风格，同时注重隐私和成本效益。", "motivation": "解决教育领域中大型语言模型（LLMs）作为学生辅助工具的潜力未被充分挖掘的问题，特别是针对教育工作者的本地化、可定制开源解决方案的缺乏，以及现有云基础设施或专有工具的高成本和隐私问题。", "method": "采用小型（3B-7B参数）本地部署的LLMs，结合检索和上下文增强生成（RAG/CAG）技术，以及一个辅助LLM验证器来减少越狱风险，提高输出的可靠性和安全性。", "result": "通过大学物理课程的试点验证，证明经过精心设计的小型LLM系统能够为教育工作者提供强大、经济、实用且安全的支持，在特定任务上达到与大型模型相当的效用。", "conclusion": "研究表明，小型LLM系统在经过适当工程化后，能够成为教育工作者在内容创作和评估方面的有效工具，特别是在预算有限和对数据隐私有高要求的场景下。"}}
{"id": "2506.06151", "title": "Joint-GCG: Unified Gradient-Based Poisoning Attacks on Retrieval-Augmented Generation Systems", "authors": ["Haowei Wang", "Rupeng Zhang", "Junjie Wang", "Mingyang Li", "Yuekai Huang", "Dandan Wang", "Qing Wang"], "abstract": "Retrieval-Augmented Generation (RAG) systems enhance Large Language Models (LLMs) by retrieving relevant documents from external corpora before generating responses. This approach significantly expands LLM capabilities by leveraging vast, up-to-date external knowledge. However, this reliance on external knowledge makes RAG systems vulnerable to corpus poisoning attacks that manipulate generated outputs via poisoned document injection. Existing poisoning attack strategies typically treat the retrieval and generation stages as disjointed, limiting their effectiveness. We propose Joint-GCG, the first framework to unify gradient-based attacks across both retriever and generator models through three innovations: (1) Cross-Vocabulary Projection for aligning embedding spaces, (2) Gradient Tokenization Alignment for synchronizing token-level gradient signals, and (3) Adaptive Weighted Fusion for dynamically balancing attacking objectives. Evaluations demonstrate that Joint-GCG achieves at most 25% and an average of 5% higher attack success rate than previous methods across multiple retrievers and generators. While optimized under a white-box assumption, the generated poisons show unprecedented transferability to unseen models. Joint-GCG's innovative unification of gradient-based attacks across retrieval and generation stages fundamentally reshapes our understanding of vulnerabilities within RAG systems. Our code is available at", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.06151.pdf", "abstract_url": "https://arxiv.org/abs/2506.06151", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了Joint-GCG，一个统一的梯度基础毒化攻击框架，针对检索增强生成（RAG）系统，通过跨词汇投影、梯度标记对齐和自适应加权融合三项创新，显著提高了攻击成功率。", "motivation": "检索增强生成（RAG）系统通过检索外部语料库中的相关文档来增强大型语言模型（LLMs）的能力，但这种依赖外部知识的特性使其容易受到通过注入有毒文档来操纵生成输出的语料库毒化攻击。现有攻击策略通常将检索和生成阶段视为分离的，限制了攻击效果。", "method": "Joint-GCG框架通过三项创新统一了检索器和生成器模型的梯度基础攻击：跨词汇投影用于对齐嵌入空间，梯度标记对齐用于同步标记级梯度信号，自适应加权融合用于动态平衡攻击目标。", "result": "评估显示，Joint-GCG在多个检索器和生成器上实现了比之前方法最高25%和平均5%更高的攻击成功率。即使在白盒假设下优化，生成的毒化物也显示出对未见模型前所未有的可转移性。", "conclusion": "Joint-GCG通过创新性地统一检索和生成阶段的梯度基础攻击，从根本上重塑了我们对RAG系统内漏洞的理解。"}}
{"id": "2506.06165", "title": "(AI peers) are people learning from the same standpoint: Perception of AI characters in a Collaborative Science Investigation", "authors": ["Eunhye Grace Ko", "Soo Hyoung Joo"], "abstract": "While the complexity of 21st-century demands has promoted pedagogical approaches to foster complex competencies, a persistent gap remains between in-class learning activities and individualized learning or assessment practices. To address this, studies have explored the use of AI-generated characters in learning and assessment. One attempt is scenario-based assessment (SBA), a technique that not only measures but also fosters the development of competencies throughout the assessment process. SBA introduces simulated agents to provide an authentic social-interactional context, allowing for the assessment of competency-based constructs while mitigating the unpredictability of real-life interactions. Recent advancements in multimodal AI, such as text-to-video technology, allow these agents to be enhanced into AI-generated characters. This mixed-method study investigates how learners perceive AI characters taking the role of mentor and teammates in an SBA mirroring the context of a collaborative science investigation. Specifically, we examined the Likert scale responses of 56 high schoolers regarding trust, social presence, and effectiveness. We analyzed the relationships between these factors and their impact on the intention to adopt AI characters through PLS-SEM. Our findings indicated that learners' trust shaped their sense of social presence with the AI characters, enhancing perceived effectiveness. Qualitative analysis further highlighted factors that foster trust, such as material credibility and alignment with learning goals, as well as the pivotal role of social presence in creating a collaborative context.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": "14 pages", "pdf_url": "https://arxiv.org/pdf/2506.06165.pdf", "abstract_url": "https://arxiv.org/abs/2506.06165", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本研究探讨了在协作科学调查中，学习者对扮演导师和队友角色的AI生成角色的感知。通过混合方法研究，分析了高中生对AI角色的信任、社会存在感和有效性的看法，发现信任影响社会存在感，进而提升感知有效性。", "motivation": "解决21世纪教育需求与个性化学习或评估实践之间的差距，探索AI生成角色在学习和评估中的应用。", "method": "采用混合方法研究，通过Likert量表收集56名高中生的反馈，使用PLS-SEM分析信任、社会存在感和有效性之间的关系，并进行定性分析。", "result": "学习者的信任塑造了他们对AI角色的社会存在感，增强了感知的有效性。定性分析进一步揭示了促进信任的因素，如材料的可信度和与学习目标的一致性，以及社会存在感在创建协作环境中的关键作用。", "conclusion": "AI生成角色在教育和评估中具有潜力，特别是在提供社会互动环境和促进复杂能力发展方面。信任和社会存在感是影响其有效性的关键因素。"}}
