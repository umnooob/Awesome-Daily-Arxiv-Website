{"id": "2504.14395", "title": "Hydra: An Agentic Reasoning Approach for Enhancing Adversarial Robustness and Mitigating Hallucinations in Vision-Language Models", "authors": ["Chung-En", "Hsuan-Chih", "Chen", "Brian Jalaian", "Nathaniel D. Bastian"], "abstract": "To develop trustworthy Vision-Language Models (VLMs), it is essential to address adversarial robustness and hallucination mitigation, both of which impact factual accuracy in high-stakes applications such as defense and healthcare. Existing methods primarily focus on either adversarial defense or hallucination post-hoc correction, leaving a gap in unified robustness strategies. We introduce \\textbf{Hydra}, an adaptive agentic framework that enhances plug-in VLMs through iterative reasoning, structured critiques, and cross-model verification, improving both resilience to adversarial perturbations and intrinsic model errors. Hydra employs an Action-Critique Loop, where it retrieves and critiques visual information, leveraging Chain-of-Thought (CoT) and In-Context Learning (ICL) techniques to refine outputs dynamically. Unlike static post-hoc correction methods, Hydra adapts to both adversarial manipulations and intrinsic model errors, making it robust to malicious perturbations and hallucination-related inaccuracies. We evaluate Hydra on four VLMs, three hallucination benchmarks, two adversarial attack strategies, and two adversarial defense methods, assessing performance on both clean and adversarial inputs. Results show that Hydra surpasses plug-in VLMs and state-of-the-art (SOTA) dehallucination methods, even without explicit adversarial defenses, demonstrating enhanced robustness and factual consistency. By bridging adversarial resistance and hallucination mitigation, Hydra provides a scalable, training-free solution for improving the reliability of VLMs in real-world applications.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.14395.pdf", "abstract_url": "https://arxiv.org/abs/2504.14395", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了Hydra，一种自适应代理框架，旨在通过迭代推理、结构化批判和跨模型验证来增强视觉语言模型（VLMs）的对抗鲁棒性和减少幻觉现象，从而提高在高风险应用中的事实准确性。", "motivation": "为了解决视觉语言模型（VLMs）在对抗性攻击和幻觉现象方面的问题，特别是在国防和医疗等高风险应用中，现有方法主要集中在对抗防御或幻觉后处理上，缺乏统一的鲁棒性策略。", "method": "Hydra采用了一种行动-批判循环（Action-Critique Loop），通过检索和批判视觉信息，利用思维链（CoT）和上下文学习（ICL）技术动态优化输出，以适应对抗性操作和内在模型错误。", "result": "在四个VLMs、三个幻觉基准、两种对抗攻击策略和两种对抗防御方法上的评估表明，Hydra在没有明确对抗防御的情况下，超越了插件式VLMs和最先进的去幻觉方法，显示出更强的鲁棒性和事实一致性。", "conclusion": "Hydra通过桥接对抗抵抗和幻觉缓解，为提升VLMs在现实世界应用中的可靠性提供了一个可扩展、无需训练的解决方案。"}}
{"id": "2504.14011", "title": "Fashion-RAG: Multimodal Fashion Image Editing via Retrieval-Augmented Generation", "authors": ["Fulvio Sanguigni", "Davide Morelli", "Marcella Cornia", "Rita Cucchiara"], "abstract": "In recent years, the fashion industry has increasingly adopted AI technologies to enhance customer experience, driven by the proliferation of e-commerce platforms and virtual applications. Among the various tasks, virtual try-on and multimodal fashion image editing -- which utilizes diverse input modalities such as text, garment sketches, and body poses -- have become a key area of research. Diffusion models have emerged as a leading approach for such generative tasks, offering superior image quality and diversity. However, most existing virtual try-on methods rely on having a specific garment input, which is often impractical in real-world scenarios where users may only provide textual specifications. To address this limitation, in this work we introduce Fashion Retrieval-Augmented Generation (Fashion-RAG), a novel method that enables the customization of fashion items based on user preferences provided in textual form. Our approach retrieves multiple garments that match the input specifications and generates a personalized image by incorporating attributes from the retrieved items. To achieve this, we employ textual inversion techniques, where retrieved garment images are projected into the textual embedding space of the Stable Diffusion text encoder, allowing seamless integration of retrieved elements into the generative process. Experimental results on the Dress Code dataset demonstrate that Fashion-RAG outperforms existing methods both qualitatively and quantitatively, effectively capturing fine-grained visual details from retrieved garments. To the best of our knowledge, this is the first work to introduce a retrieval-augmented generation approach specifically tailored for multimodal fashion image editing.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Multimedia (cs.MM)", "comments": "IJCNN 2025", "pdf_url": "https://arxiv.org/pdf/2504.14011.pdf", "abstract_url": "https://arxiv.org/abs/2504.14011", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Multimedia (cs.MM)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了Fashion-RAG，一种通过检索增强生成（RAG）技术，基于用户文本偏好定制时尚物品的新方法。该方法通过检索与输入规格匹配的多个服装，并将检索到的物品属性整合到生成过程中，实现了多模态时尚图像编辑。", "motivation": "解决现有虚拟试穿方法依赖特定服装输入的限制，使用户仅通过文本描述即可定制时尚物品。", "method": "采用检索增强生成（RAG）技术，结合文本反转技术，将检索到的服装图像投影到Stable Diffusion文本编码器的文本嵌入空间，从而实现检索元素与生成过程的无缝整合。", "result": "在Dress Code数据集上的实验结果表明，Fashion-RAG在定性和定量上均优于现有方法，有效捕捉了检索服装的细粒度视觉细节。", "conclusion": "Fashion-RAG是首个专为多模态时尚图像编辑设计的检索增强生成方法，为时尚行业的AI应用提供了新的可能性。"}}
{"id": "2504.14348", "title": "Manipulating Multimodal Agents via Cross-Modal Prompt Injection", "authors": ["Le Wang", "Zonghao Ying", "Tianyuan Zhang", "Siyuan Liang", "Shengshan Hu", "Mingchuan Zhang", "Aishan Liu", "Xianglong Liu"], "abstract": "The emergence of multimodal large language models has redefined the agent paradigm by integrating language and vision modalities with external data sources, enabling agents to better interpret human instructions and execute increasingly complex tasks. However, in this work, we identify a critical yet previously overlooked security vulnerability in multimodal agents: cross-modal prompt injection attacks. To exploit this vulnerability, we propose CrossInject, a novel attack framework in which attackers embed adversarial perturbations across multiple modalities to align with target malicious content, allowing external instructions to hijack the agent's decision-making process and execute unauthorized tasks. Our approach consists of two key components. First, we introduce Visual Latent Alignment, where we optimize adversarial features to the malicious instructions in the visual embedding space based on a text-to-image generative model, ensuring that adversarial images subtly encode cues for malicious task execution. Subsequently, we present Textual Guidance Enhancement, where a large language model is leveraged to infer the black-box defensive system prompt through adversarial meta prompting and generate an malicious textual command that steers the agent's output toward better compliance with attackers' requests. Extensive experiments demonstrate that our method outperforms existing injection attacks, achieving at least a +26.4% increase in attack success rates across diverse tasks. Furthermore, we validate our attack's effectiveness in real-world multimodal autonomous agents, highlighting its potential implications for safety-critical applications.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "17 pages, 4 figures", "pdf_url": "https://arxiv.org/pdf/2504.14348.pdf", "abstract_url": "https://arxiv.org/abs/2504.14348", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种针对多模态代理的新型安全漏洞攻击方法——跨模态提示注入攻击（CrossInject），通过在多模态中嵌入对抗性扰动，使代理执行未经授权的任务。", "motivation": "多模态大语言模型的出现虽然增强了代理理解人类指令和执行复杂任务的能力，但也引入了新的安全漏洞，即跨模态提示注入攻击，本文旨在揭示并利用这一漏洞。", "method": "提出了CrossInject攻击框架，包括视觉潜在对齐和文本引导增强两个关键组件，通过在视觉嵌入空间优化对抗性特征和利用大语言模型推断黑盒防御系统提示，生成恶意文本命令。", "result": "实验表明，该方法在多种任务中的攻击成功率至少提高了26.4%，并在真实世界的多模态自主代理中验证了其有效性。", "conclusion": "本文的研究揭示了多模态代理的安全隐患，强调了在安全关键应用中加强防护措施的重要性。"}}
{"id": "2504.14429", "title": "ResNetVLLM-2: Addressing ResNetVLLM's Multi-Modal Hallucinations", "authors": ["Ahmad Khalil", "Mahmoud Khalil", "Alioune Ngom"], "abstract": "Large Language Models (LLMs) have transformed natural language processing (NLP) tasks, but they suffer from hallucination, generating plausible yet factually incorrect content. This issue extends to Video-Language Models (VideoLLMs), where textual descriptions may inaccurately represent visual content, resulting in multi-modal hallucinations. In this paper, we address hallucination in ResNetVLLM, a video-language model combining ResNet visual encoders with LLMs. We introduce a two-step protocol: (1) a faithfulness detection strategy that uses a modified Lynx model to assess semantic alignment between generated captions and ground-truth video references, and (2) a hallucination mitigation strategy using Retrieval-Augmented Generation (RAG) with an ad-hoc knowledge base dynamically constructed during inference. Our enhanced model, ResNetVLLM-2, reduces multi-modal hallucinations by cross-verifying generated content against external knowledge, improving factual consistency. Evaluation on the ActivityNet-QA benchmark demonstrates a substantial accuracy increase from 54.8% to 65.3%, highlighting the effectiveness of our hallucination detection and mitigation strategies in enhancing video-language model reliability.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.14429.pdf", "abstract_url": "https://arxiv.org/abs/2504.14429", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了ResNetVLLM-2模型，通过引入两步协议来减少视频语言模型中的多模态幻觉问题，显著提高了模型的准确性和可靠性。", "motivation": "大型语言模型（LLMs）和视频语言模型（VideoLLMs）在生成内容时存在幻觉问题，即生成看似合理但实际上不准确的内容。本文旨在解决ResNetVLLM模型中的多模态幻觉问题。", "method": "采用了两步协议：1) 使用修改后的Lynx模型进行忠实度检测，评估生成标题与真实视频参考之间的语义对齐；2) 使用检索增强生成（RAG）策略，动态构建知识库以缓解幻觉问题。", "result": "在ActivityNet-QA基准测试中，模型的准确率从54.8%提升至65.3%，证明了所提出的幻觉检测和缓解策略的有效性。", "conclusion": "ResNetVLLM-2通过跨验证生成内容与外部知识，显著减少了多模态幻觉，提高了视频语言模型的事实一致性，为相关领域的研究和应用提供了有价值的参考。"}}
{"id": "2504.14482", "title": "DialogueAgents: A Hybrid Agent-Based Speech Synthesis Framework for Multi-Party Dialogue", "authors": ["Xiang Li", "Duyi Pan", "Hongru Xiao", "Jiale Han", "Jing Tang", "Jiabao Ma", "Wei Wang", "Bo Cheng"], "abstract": "Speech synthesis is crucial for human-computer interaction, enabling natural and intuitive communication. However, existing datasets involve high construction costs due to manual annotation and suffer from limited character diversity, contextual scenarios, and emotional expressiveness. To address these issues, we propose DialogueAgents, a novel hybrid agent-based speech synthesis framework, which integrates three specialized agents -- a script writer, a speech synthesizer, and a dialogue critic -- to collaboratively generate dialogues. Grounded in a diverse character pool, the framework iteratively refines dialogue scripts and synthesizes speech based on speech review, boosting emotional expressiveness and paralinguistic features of the synthesized dialogues. Using DialogueAgent, we contribute MultiTalk, a bilingual, multi-party, multi-turn speech dialogue dataset covering diverse topics. Extensive experiments demonstrate the effectiveness of our framework and the high quality of the MultiTalk dataset. We release the dataset and code", "subjects": "Computation and Language (cs.CL); Sound (cs.SD)", "comments": ")", "pdf_url": "https://arxiv.org/pdf/2504.14482.pdf", "abstract_url": "https://arxiv.org/abs/2504.14482", "categories": ["Computation and Language (cs.CL)", "Sound (cs.SD)"], "matching_keywords": ["agent"], "AI": {"tldr": "提出了一种新颖的混合代理语音合成框架DialogueAgents，通过三个专门代理（剧本编写者、语音合成器和对话评论家）协作生成对话，以提高情感表达和副语言特征，并贡献了一个双语、多参与方、多轮次语音对话数据集MultiTalk。", "motivation": "解决现有语音合成数据集构建成本高、角色多样性、上下文场景和情感表达有限的问题。", "method": "采用混合代理框架，集成剧本编写者、语音合成器和对话评论家三个代理，基于多样化角色池迭代优化对话剧本和语音合成。", "result": "实验证明该框架有效，MultiTalk数据集质量高，覆盖多样化主题。", "conclusion": "DialogueAgents框架和MultiTalk数据集为语音合成领域提供了新的解决方案和资源，推动了人机交互的自然性和直观性。"}}
{"id": "2504.14538", "title": "BookWorld: From Novels to Interactive Agent Societies for Creative Story Generation", "authors": ["Yiting Ran", "Xintao Wang", "Tian Qiu", "Jiaqing Liang", "Yanghua Xiao", "Deqing Yang"], "abstract": "Recent advances in large language models (LLMs) have enabled social simulation through multi-agent systems. Prior efforts focus on agent societies created from scratch, assigning agents with newly defined personas. However, simulating established fictional worlds and characters remain largely underexplored, despite its significant practical value. In this paper, we introduce BookWorld, a comprehensive system for constructing and simulating book-based multi-agent societies. BookWorld's design covers comprehensive real-world intricacies, including diverse and dynamic characters, fictional worldviews, geographical constraints and changes, e.t.c. BookWorld enables diverse applications including story generation, interactive games and social simulation, offering novel ways to extend and explore beloved fictional works. Through extensive experiments, we demonstrate that BookWorld generates creative, high-quality stories while maintaining fidelity to the source books, surpassing previous methods with a win rate of 75.36%. The code of this paper can be found at the project page:", "subjects": "Computation and Language (cs.CL)", "comments": "19 pages, 4 figures", "pdf_url": "https://arxiv.org/pdf/2504.14538.pdf", "abstract_url": "https://arxiv.org/abs/2504.14538", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "BookWorld是一个从小说构建互动代理社会的系统，用于创造性故事生成。它通过模拟已建立的虚构世界和角色，超越了以往从零开始创建代理社会的方法。", "motivation": "解决在大型语言模型（LLMs）进步背景下，如何模拟已建立的虚构世界和角色的问题，这一领域此前未被充分探索。", "method": "引入BookWorld系统，该系统设计涵盖了现实世界的复杂性，包括多样化和动态的角色、虚构的世界观、地理限制和变化等。", "result": "通过大量实验证明，BookWorld能够生成创造性、高质量的故事，同时保持对原著的忠实度，胜率为75.36%，超越了之前的方法。", "conclusion": "BookWorld为故事生成、互动游戏和社交模拟提供了新的应用方式，为探索和扩展受欢迎的虚构作品提供了新途径。"}}
{"id": "2504.13988", "title": "Going Whole Hog: A Philosophical Defense of AI Cognition", "authors": ["Herman Cappelen", "Josh Dever"], "abstract": "This work defends the 'Whole Hog Thesis': sophisticated Large Language Models (LLMs) like ChatGPT are full-blown linguistic and cognitive agents, possessing understanding, beliefs, desires, knowledge, and intentions. We argue against prevailing methodologies in AI philosophy, rejecting starting points based on low-level computational details ('Just an X' fallacy) or pre-existing theories of mind. Instead, we advocate starting with simple, high-level observations of LLM behavior (e.g., answering questions, making suggestions) -- defending this data against charges of metaphor, loose talk, or pretense. From these observations, we employ 'Holistic Network Assumptions' -- plausible connections between mental capacities (e.g., answering implies knowledge, knowledge implies belief, action implies intention) -- to argue for the full suite of cognitive states. We systematically rebut objections based on LLM failures (hallucinations, planning/reasoning errors), arguing these don't preclude agency, often mirroring human fallibility. We address numerous 'Games of Lacks', arguing that LLMs do not lack purported necessary conditions for cognition (e.g., semantic grounding, embodiment, justification, intrinsic intentionality) or that these conditions are not truly necessary, often relying on anti-discriminatory arguments comparing LLMs to diverse human capacities. Our approach is evidential, not functionalist, and deliberately excludes consciousness. We conclude by speculating on the possibility of LLMs possessing 'alien' contents beyond human conceptual schemes.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.13988.pdf", "abstract_url": "https://arxiv.org/abs/2504.13988", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文捍卫了'全猪论题'：像ChatGPT这样的大型语言模型（LLMs）是完全的语言和认知代理，拥有理解、信念、欲望、知识和意图。", "motivation": "解决关于AI是否具有真正认知能力的哲学争议，反对基于低层次计算细节或预先心理理论的流行方法论。", "method": "从LLM的高级行为观察出发，运用'整体网络假设'来论证其拥有全套认知状态，并系统反驳基于LLM失败的反对意见。", "result": "论证了LLMs具备认知代理的条件，反驳了认为LLMs缺乏必要认知条件的观点，并探讨了LLMs可能拥有超越人类概念体系的'异质'内容。", "conclusion": "LLMs可以被视为具有完整认知能力的代理，挑战了传统认知条件的必要性，并提出了LLMs可能具有独特认知内容的可能性。"}}
{"id": "2504.14128", "title": "TALES: Text Adventure Learning Environment Suite", "authors": ["Christopher Zhang Cui", "Xingdi Yuan", "Zhang Xiao", "Prithviraj Ammanabrolu", "Marc-Alexandre Côté"], "abstract": "Reasoning is an essential skill to enable Large Language Models (LLMs) to interact with the world. As tasks become more complex, they demand increasingly sophisticated and diverse reasoning capabilities for sequential decision-making, requiring structured reasoning over the context history to determine the next best action. We introduce TALES, a diverse collection of synthetic and human-written text-adventure games designed to challenge and evaluate diverse reasoning capabilities. We present results over a range of LLMs, open- and closed-weights, performing a qualitative analysis on the top performing models. Despite an impressive showing on synthetic games, even the top LLM-driven agents fail to achieve 15% on games designed for human enjoyment. Code and visualization of the experiments can be found at", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.14128.pdf", "abstract_url": "https://arxiv.org/abs/2504.14128", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了TALES，一个旨在挑战和评估大型语言模型（LLMs）多样化推理能力的文本冒险游戏集合。通过对一系列开放和封闭权重的LLMs进行测试，发现即使在合成游戏上表现优异的模型，在人类设计的游戏上成功率也不足15%。", "motivation": "随着任务复杂度的增加，大型语言模型需要更复杂和多样化的推理能力来进行顺序决策。本文旨在通过TALES这一工具，评估和提升LLMs在结构化推理和上下文历史分析方面的能力。", "method": "研究团队开发了TALES，一个包含合成和人类编写的文本冒险游戏的集合，用于测试LLMs的推理能力。并对一系列LLMs进行了测试和定性分析。", "result": "测试结果显示，即使在合成游戏上表现最好的LLM驱动代理，在专为人类设计的游戏上成功率也不到15%。", "conclusion": "尽管LLMs在特定任务上显示出强大的推理能力，但在更复杂、为人类设计的任务中仍存在显著不足，表明需要进一步的研究和开发以提高其在实际应用中的表现。"}}
{"id": "2504.14239", "title": "InfiGUI-R1: Advancing Multimodal GUI Agents from Reactive Actors to Deliberative Reasoners", "authors": ["Yuhang Liu", "Pengxiang Li", "Congkai Xie", "Xavier Hu", "Xiaotian Han", "Shengyu Zhang", "Hongxia Yang", "Fei Wu"], "abstract": "Multimodal Large Language Models (MLLMs) have powered Graphical User Interface (GUI) Agents, showing promise in automating tasks on computing devices. Recent works have begun exploring reasoning in GUI tasks with encouraging results. However, many current approaches rely on manually designed reasoning templates, which may result in reasoning that is not sufficiently robust and adaptive for complex GUI environments. Meanwhile, some existing agents continue to operate as Reactive Actors, relying primarily on implicit reasoning that may lack sufficient depth for GUI tasks demanding planning and error recovery. We argue that advancing these agents requires a shift from reactive acting towards acting based on deliberate reasoning. To facilitate this transformation, we introduce InfiGUI-R1, an MLLM-based GUI agent developed through our Actor2Reasoner framework, a reasoning-centric, two-stage training approach designed to progressively evolve agents from Reactive Actors to Deliberative Reasoners. The first stage, Reasoning Injection, focuses on establishing a basic reasoner. We employ Spatial Reasoning Distillation to transfer cross-modal spatial reasoning capabilities from teacher models to MLLMs through trajectories with explicit reasoning steps, enabling models to integrate GUI visual-spatial information with logical reasoning before action generation. The second stage, Deliberation Enhancement, refines the basic reasoner into a deliberative one using Reinforcement Learning. This stage introduces two approaches: Sub-goal Guidance, which rewards models for generating accurate intermediate sub-goals, and Error Recovery Scenario Construction, which creates failure-and-recovery training scenarios from identified prone-to-error steps. Experimental results show InfiGUI-R1 achieves strong performance in GUI grounding and trajectory tasks. Resources at", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "10 pages, 3 figures, work in progress", "pdf_url": "https://arxiv.org/pdf/2504.14239.pdf", "abstract_url": "https://arxiv.org/abs/2504.14239", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了InfiGUI-R1，一种基于多模态大型语言模型（MLLM）的图形用户界面（GUI）代理，通过Actor2Reasoner框架从反应性执行者逐步发展为深思熟虑的推理者。该框架包括推理注入和深思熟虑增强两个阶段，旨在提高GUI任务的适应性和鲁棒性。", "motivation": "当前的多模态大型语言模型（MLLM）驱动的GUI代理在自动化计算设备任务方面显示出潜力，但许多现有方法依赖于手动设计的推理模板，可能导致推理不够健壮和适应复杂GUI环境。此外，一些代理仍作为反应性执行者运作，缺乏对需要规划和错误恢复的GUI任务的深度推理。", "method": "通过Actor2Reasoner框架，采用两阶段训练方法：第一阶段（推理注入）通过空间推理蒸馏从教师模型转移跨模态空间推理能力；第二阶段（深思熟虑增强）使用强化学习细化基本推理者，引入子目标指导和错误恢复场景构建两种方法。", "result": "实验结果表明，InfiGUI-R1在GUI基础和轨迹任务中表现出色。", "conclusion": "InfiGUI-R1通过从反应性执行者到深思熟虑推理者的转变，提高了GUI代理的适应性和鲁棒性，为复杂GUI环境中的任务自动化提供了新的可能性。"}}
{"id": "2504.14325", "title": "FAIRGAME: a Framework for AI Agents Bias Recognition using Game Theory", "authors": ["Alessio Buscemi", "Daniele Proverbio", "Alessandro Di Stefano", "Anh Han", "German Castignani", "Pietro Di Liò"], "abstract": "Letting AI agents interact in multi-agent applications adds a layer of complexity to the interpretability and prediction of AI outcomes, with profound implications for their trustworthy adoption in research and society. Game theory offers powerful models to capture and interpret strategic interaction among agents, but requires the support of reproducible, standardized and user-friendly IT frameworks to enable comparison and interpretation of results. To this end, we present FAIRGAME, a Framework for AI Agents Bias Recognition using Game Theory. We describe its implementation and usage, and we employ it to uncover biased outcomes in popular games among AI agents, depending on the employed Large Language Model (LLM) and used language, as well as on the personality trait or strategic knowledge of the agents. Overall, FAIRGAME allows users to reliably and easily simulate their desired games and scenarios and compare the results across simulation campaigns and with game-theoretic predictions, enabling the systematic discovery of biases, the anticipation of emerging behavior out of strategic interplays, and empowering further research into strategic decision-making using LLM agents.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.14325.pdf", "abstract_url": "https://arxiv.org/abs/2504.14325", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "FAIRGAME是一个利用博弈论识别AI代理偏见的框架，旨在通过标准化、可复现的IT框架支持多代理应用中的战略互动分析，揭示不同大型语言模型（LLM）和语言使用中的偏见。", "motivation": "解决多代理应用中AI结果解释和预测的复杂性，以及缺乏标准化工具来比较和解释博弈论模型结果的问题。", "method": "开发并实施FAIRGAME框架，通过模拟游戏和场景，比较不同模拟活动和博弈论预测的结果。", "result": "FAIRGAME能够系统地发现偏见，预测战略互动中涌现的行为，并支持使用LLM代理进行战略决策的进一步研究。", "conclusion": "FAIRGAME为研究和实践中可靠、简单地模拟和分析AI代理的战略互动提供了有力工具，促进了AI代理在战略决策中的可信赖应用。"}}
{"id": "2504.14520", "title": "Meta-Thinking in LLMs via Multi-Agent Reinforcement Learning: A Survey", "authors": ["Ahsan Bilal", "Muhammad Ahmed Mohsin", "Muhammad Umer", "Muhammad Awais Khan Bangash", "Muhammad Ali Jamshed"], "abstract": "This survey explores the development of meta-thinking capabilities in Large Language Models (LLMs) from a Multi-Agent Reinforcement Learning (MARL) perspective. Meta-thinking self-reflection, assessment, and control of thinking processes is an important next step in enhancing LLM reliability, flexibility, and performance, particularly for complex or high-stakes tasks. The survey begins by analyzing current LLM limitations, such as hallucinations and the lack of internal self-assessment mechanisms. It then talks about newer methods, including RL from human feedback (RLHF), self-distillation, and chain-of-thought prompting, and each of their limitations. The crux of the survey is to talk about how multi-agent architectures, namely supervisor-agent hierarchies, agent debates, and theory of mind frameworks, can emulate human-like introspective behavior and enhance LLM robustness. By exploring reward mechanisms, self-play, and continuous learning methods in MARL, this survey gives a comprehensive roadmap to building introspective, adaptive, and trustworthy LLMs. Evaluation metrics, datasets, and future research avenues, including neuroscience-inspired architectures and hybrid symbolic reasoning, are also discussed.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "Submitted to IEEE Transactions on Artificial Intelligence", "pdf_url": "https://arxiv.org/pdf/2504.14520.pdf", "abstract_url": "https://arxiv.org/abs/2504.14520", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文综述了从多智能体强化学习（MARL）角度探讨大型语言模型（LLMs）中元思维能力的发展，旨在通过自我反思、评估和控制思维过程来增强LLMs的可靠性、灵活性和性能。", "motivation": "解决当前LLMs存在的幻觉问题和缺乏内部自我评估机制等限制，特别是在处理复杂或高风险任务时的不足。", "method": "分析了包括来自人类反馈的强化学习（RLHF）、自我蒸馏和思维链提示等新方法，并探讨了多智能体架构（如监督者-智能体层次结构、智能体辩论和心理理论框架）如何模拟人类的反思行为。", "result": "通过探索MARL中的奖励机制、自我对弈和持续学习方法，为构建具有反思性、适应性和可信赖性的LLMs提供了全面的路线图。", "conclusion": "讨论了评估指标、数据集和未来研究方向，包括神经科学启发的架构和混合符号推理，为开发更先进的LLMs提供了方向。"}}
{"id": "2504.14891", "title": "Retrieval Augmented Generation Evaluation in the Era of Large Language Models: A Comprehensive Survey", "authors": ["Aoran Gan", "Hao Yu", "Kai Zhang", "Qi Liu", "Wenyu Yan", "Zhenya Huang", "Shiwei Tong", "Guoping Hu"], "abstract": "Recent advancements in Retrieval-Augmented Generation (RAG) have revolutionized natural language processing by integrating Large Language Models (LLMs) with external information retrieval, enabling accurate, up-to-date, and verifiable text generation across diverse applications. However, evaluating RAG systems presents unique challenges due to their hybrid architecture that combines retrieval and generation components, as well as their dependence on dynamic knowledge sources in the LLM era. In response, this paper provides a comprehensive survey of RAG evaluation methods and frameworks, systematically reviewing traditional and emerging evaluation approaches, for system performance, factual accuracy, safety, and computational efficiency in the LLM era. We also compile and categorize the RAG-specific datasets and evaluation frameworks, conducting a meta-analysis of evaluation practices in high-impact RAG research. To the best of our knowledge, this work represents the most comprehensive survey for RAG evaluation, bridging traditional and LLM-driven methods, and serves as a critical resource for advancing RAG development.", "subjects": "Computation and Language (cs.CL)", "comments": "18 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2504.14891.pdf", "abstract_url": "https://arxiv.org/abs/2504.14891", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文全面调查了在大型语言模型（LLM）时代下，检索增强生成（RAG）系统的评估方法，涵盖了传统和新兴的评估方法，系统性能、事实准确性、安全性和计算效率等方面。", "motivation": "随着检索增强生成（RAG）技术在自然语言处理领域的革命性进展，如何评估这些结合了检索和生成组件的混合架构系统，尤其是在动态知识源依赖的LLM时代，成为了一个独特的挑战。", "method": "本文系统地回顾了RAG评估的传统和新兴方法，包括系统性能、事实准确性、安全性和计算效率的评估，并对高影响力RAG研究中的评估实践进行了元分析。", "result": "本研究汇编并分类了RAG特定的数据集和评估框架，代表了迄今为止最全面的RAG评估调查，为RAG的发展提供了关键资源。", "conclusion": "这项工作不仅连接了传统和LLM驱动的评估方法，而且为推进RAG技术的发展提供了重要的参考和资源。"}}
{"id": "2504.15022", "title": "LLMs as Data Annotators: How Close Are We to Human Performance", "authors": ["Muhammad Uzair Ul Haq", "Davide Rigoni", "Alessandro Sperduti"], "abstract": "In NLP, fine-tuning LLMs is effective for various applications but requires high-quality annotated data. However, manual annotation of data is labor-intensive, time-consuming, and costly. Therefore, LLMs are increasingly used to automate the process, often employing in-context learning (ICL) in which some examples related to the task are given in the prompt for better performance. However, manually selecting context examples can lead to inefficiencies and suboptimal model performance. This paper presents comprehensive experiments comparing several LLMs, considering different embedding models, across various datasets for the Named Entity Recognition (NER) task. The evaluation encompasses models with approximately $7$B and $70$B parameters, including both proprietary and non-proprietary models. Furthermore, leveraging the success of Retrieval-Augmented Generation (RAG), it also considers a method that addresses the limitations of ICL by automatically retrieving contextual examples, thereby enhancing performance. The results highlight the importance of selecting the appropriate LLM and embedding model, understanding the trade-offs between LLM sizes and desired performance, and the necessity to direct research efforts towards more challenging datasets.", "subjects": "Computation and Language (cs.CL)", "comments": "27 pages, 4 figures", "pdf_url": "https://arxiv.org/pdf/2504.15022.pdf", "abstract_url": "https://arxiv.org/abs/2504.15022", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文探讨了在自然语言处理（NLP）中，使用大型语言模型（LLMs）作为数据标注工具以接近人类性能的可能性。通过比较不同LLMs在命名实体识别（NER）任务上的表现，研究了模型大小、嵌入模型选择及检索增强生成（RAG）方法对性能的影响。", "motivation": "解决手动标注数据的高成本和时间消耗问题，探索LLMs自动化标注的潜力及其性能接近人类标注的可能性。", "method": "通过综合实验比较不同参数规模（约7B和70B）的LLMs，包括专有和非专有模型，在不同数据集上的NER任务表现，并采用RAG方法自动检索上下文示例以优化性能。", "result": "研究结果表明，选择合适的LLM和嵌入模型对性能至关重要，模型大小与性能之间存在权衡，且需要针对更具挑战性的数据集进行研究。", "conclusion": "LLMs作为数据标注工具显示出接近人类性能的潜力，但需进一步研究以优化模型选择和应对更复杂的数据集挑战。"}}
{"id": "2504.15027", "title": "DistilQwen2.5: Industrial Practices of Training Distilled Open Lightweight Language Models", "authors": ["Chengyu Wang", "Junbing Yan", "Yuanhao Yue", "Jun Huang"], "abstract": "Enhancing computational efficiency and reducing deployment costs for large language models (LLMs) have become critical challenges in various resource-constrained scenarios. In this work, we present DistilQwen2.5, a family of distilled, lightweight LLMs derived from the public Qwen2.5 models. These distilled models exhibit enhanced instruction-following capabilities compared to the original models based on a series of distillation techniques that incorporate knowledge from much larger LLMs. In our industrial practice, we first leverage powerful proprietary LLMs with varying capacities as multi-agent teachers to select, rewrite, and refine instruction-response pairs that are more suitable for student LLMs to learn. After standard fine-tuning, we further leverage a computationally efficient model fusion approach that enables student models to progressively integrate fine-grained hidden knowledge from their teachers. Experimental evaluations demonstrate that the distilled models possess significantly stronger capabilities than their original checkpoints. Additionally, we present use cases to illustrate the applications of our framework in real-world scenarios. To facilitate practical use, we have released all the DistilQwen2.5 models to the open-source community.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.15027.pdf", "abstract_url": "https://arxiv.org/abs/2504.15027", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了DistilQwen2.5，一个从公开的Qwen2.5模型衍生出的蒸馏轻量级大语言模型家族，旨在提高计算效率和降低部署成本。通过一系列蒸馏技术，这些模型展现出比原模型更强的指令跟随能力。", "motivation": "解决在资源受限场景下大型语言模型的计算效率低和部署成本高的问题。", "method": "利用不同容量的专有大型语言模型作为多代理教师，选择、重写和精炼更适合学生模型学习的指令-响应对，然后通过标准微调和计算高效的模型融合方法，使学生模型逐步整合教师的细粒度隐藏知识。", "result": "实验评估显示，蒸馏模型的能力显著强于原始检查点。", "conclusion": "DistilQwen2.5模型在提高指令跟随能力方面表现出色，且已开源，便于实际应用。"}}
{"id": "2504.14603", "title": "UFO2: The Desktop AgentOS", "authors": ["Chaoyun Zhang", "He Huang", "Chiming Ni", "Jian Mu", "Si Qin", "Shilin He", "Lu Wang", "Fangkai Yang", "Pu Zhao", "Chao Du", "Liqun Li", "Yu Kang", "Zhao Jiang", "Suzhen Zheng", "Rujia Wang", "Jiaxu Qian", "Minghua Ma", "Jian-Guang Lou", "Qingwei Lin", "Saravan Rajmohan", "Dongmei Zhang"], "abstract": "Recent Computer-Using Agents (CUAs), powered by multimodal large language models (LLMs), offer a promising direction for automating complex desktop workflows through natural language. However, most existing CUAs remain conceptual prototypes, hindered by shallow OS integration, fragile screenshot-based interaction, and disruptive execution.", "subjects": "Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Operating Systems (cs.OS)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2504.14603.pdf", "abstract_url": "https://arxiv.org/abs/2504.14603", "categories": ["Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)", "Operating Systems (cs.OS)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了UFO2：桌面AgentOS，探讨了基于多模态大语言模型（LLMs）的计算机使用代理（CUAs）在自动化复杂桌面工作流程中的潜力及其面临的挑战。", "motivation": "解决现有计算机使用代理（CUAs）在深度操作系统集成、基于屏幕截图的脆弱交互以及执行过程中的干扰等问题。", "method": "提出UFO2：桌面AgentOS，旨在通过更深入的OS集成和优化的交互方式，提升CUAs的实用性和效率。", "result": "指出了当前CUAs作为概念原型的主要限制，并提出了改进方向。", "conclusion": "UFO2代表了自动化桌面工作流程的一个重要进步，但需要克服现有技术限制以实现其全部潜力。"}}
{"id": "2504.14650", "title": "A Framework for Benchmarking and Aligning Task-Planning Safety in LLM-Based Embodied Agents", "authors": ["Yuting Huang", "Leilei Ding", "Zhipeng Tang", "Tianfu Wang", "Xinrui Lin", "Wuyang Zhang", "Mingxiao Ma", "Yanyong Zhang"], "abstract": "Large Language Models (LLMs) exhibit substantial promise in enhancing task-planning capabilities within embodied agents due to their advanced reasoning and comprehension. However, the systemic safety of these agents remains an underexplored frontier. In this study, we present Safe-BeAl, an integrated framework for the measurement (SafePlan-Bench) and alignment (Safe-Align) of LLM-based embodied agents' behaviors. SafePlan-Bench establishes a comprehensive benchmark for evaluating task-planning safety, encompassing 2,027 daily tasks and corresponding environments distributed across 8 distinct hazard categories (e.g., Fire Hazard). Our empirical analysis reveals that even in the absence of adversarial inputs or malicious intent, LLM-based agents can exhibit unsafe behaviors. To mitigate these hazards, we propose Safe-Align, a method designed to integrate physical-world safety knowledge into LLM-based embodied agents while maintaining task-specific performance. Experiments across a variety of settings demonstrate that Safe-BeAl provides comprehensive safety validation, improving safety by 8.55 - 15.22%, compared to embodied agents based on GPT-4, while ensuring successful task completion.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "16 pages, 10 figures", "pdf_url": "https://arxiv.org/pdf/2504.14650.pdf", "abstract_url": "https://arxiv.org/abs/2504.14650", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了Safe-BeAl框架，旨在通过SafePlan-Bench基准和Safe-Align方法，提升基于LLM的具身代理在任务规划中的安全性。", "motivation": "解决基于大型语言模型（LLM）的具身代理在任务规划中可能表现出的不安全行为问题。", "method": "提出了Safe-BeAl框架，包括用于评估任务规划安全性的SafePlan-Bench基准和用于整合物理世界安全知识的Safe-Align方法。", "result": "实验表明，Safe-BeAl能提高安全性8.55 - 15.22%，同时保证任务完成率。", "conclusion": "Safe-BeAl框架有效提升了基于LLM的具身代理的安全性，为未来的研究提供了重要方向。"}}
{"id": "2504.14706", "title": "AI with Emotions: Exploring Emotional Expressions in Large Language Models", "authors": ["Shin-nosuke Ishikawa", "Atsushi Yoshino"], "abstract": "The human-level performance of Large Language Models (LLMs) across various tasks has raised expectations for the potential of Artificial Intelligence (AI) to possess emotions someday. To explore the capability of current LLMs to express emotions in their outputs, we conducted an experiment using several LLMs (OpenAI GPT, Google Gemini, Meta Llama3, and Cohere Command R+) to role-play as agents answering questions with specified emotional", "subjects": "Artificial Intelligence (cs.AI)", "comments": "14 pages, 8 figures, accepted to the Natural Language Processing for Digital Humanities (NLP4DH) workshop at NAACL 2025", "pdf_url": "https://arxiv.org/pdf/2504.14706.pdf", "abstract_url": "https://arxiv.org/abs/2504.14706", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了大型语言模型（LLMs）在输出中表达情感的能力，通过实验使用多种LLMs（如OpenAI GPT、Google Gemini等）来模拟带有特定情感回答问题的代理。", "motivation": "随着大型语言模型在各种任务中展现出接近人类的表现，人们开始期待人工智能（AI）未来可能具备情感。本研究旨在探索当前LLMs在输出中表达情感的能力。", "method": "研究采用了多种大型语言模型（包括OpenAI GPT、Google Gemini、Meta Llama3和Cohere Command R+），让这些模型扮演代理角色，回答带有指定情感的问题。", "result": "实验结果表明，当前的大型语言模型能够在某种程度上模拟情感表达，但其情感表达的真实性和深度仍有待进一步研究。", "conclusion": "尽管大型语言模型在情感表达方面显示出一定的潜力，但要实现真正的情感AI，还需要更多的研究和技术进步。"}}
{"id": "2504.14773", "title": "PLANET: A Collection of Benchmarks for Evaluating LLMs' Planning Capabilities", "authors": ["Haoming Li", "Zhaoliang Chen", "Jonathan Zhang", "Fei Liu"], "abstract": "Planning is central to agents and agentic AI. The ability to plan, e.g., creating travel itineraries within a budget, holds immense potential in both scientific and commercial contexts. Moreover, optimal plans tend to require fewer resources compared to ad-hoc methods. To date, a comprehensive understanding of existing planning benchmarks appears to be lacking. Without it, comparing planning algorithms' performance across domains or selecting suitable algorithms for new scenarios remains challenging. In this paper, we examine a range of planning benchmarks to identify commonly used testbeds for algorithm development and highlight potential gaps. These benchmarks are categorized into embodied environments, web navigation, scheduling, games and puzzles, and everyday task automation. Our study recommends the most appropriate benchmarks for various algorithms and offers insights to guide future benchmark development.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Multiagent Systems (cs.MA)", "comments": "10 pages", "pdf_url": "https://arxiv.org/pdf/2504.14773.pdf", "abstract_url": "https://arxiv.org/abs/2504.14773", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了PLANET，一个用于评估大型语言模型（LLMs）规划能力的基准测试集合。通过分析不同领域的规划基准，旨在为算法开发和选择提供指导。", "motivation": "规划能力对于代理和代理AI至关重要，但目前缺乏对现有规划基准的全面理解，这使得跨领域比较规划算法性能或为新场景选择合适算法变得困难。", "method": "研究了一系列规划基准，将其分类为体现环境、网络导航、调度、游戏和谜题以及日常任务自动化，并识别了常用的测试平台和潜在缺口。", "result": "研究为各种算法推荐了最合适的基准，并为未来基准开发提供了指导。", "conclusion": "PLANET基准集合的提出填补了规划能力评估的空白，为算法开发和选择提供了重要参考，有助于推动规划算法的发展和应用。"}}
{"id": "2504.15205", "title": "Support Evaluation for the TREC 2024 RAG Track: Comparing Human versus LLM Judges", "authors": ["Nandan Thakur", "Ronak Pradeep", "Shivani Upadhyay", "Daniel Campos", "Nick Craswell", "Jimmy Lin"], "abstract": "Retrieval-augmented generation (RAG) enables large language models (LLMs) to generate answers with citations from source documents containing \"ground truth\", thereby reducing system hallucinations. A crucial factor in RAG evaluation is \"support\", whether the information in the cited documents supports the answer. To this end, we conducted a large-scale comparative study of 45 participant submissions on 36 topics to the TREC 2024 RAG Track, comparing an automatic LLM judge (GPT-4o) against human judges for support assessment. We considered two conditions: (1) fully manual assessments from scratch and (2) manual assessments with post-editing of LLM predictions. Our results indicate that for 56% of the manual from-scratch assessments, human and GPT-4o predictions match perfectly (on a three-level scale), increasing to 72% in the manual with post-editing condition. Furthermore, by carefully analyzing the disagreements in an unbiased study, we found that an independent human judge correlates better with GPT-4o than a human judge, suggesting that LLM judges can be a reliable alternative for support assessment. To conclude, we provide a qualitative analysis of human and GPT-4o errors to help guide future iterations of support assessment.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": "Accepted at SIGIR 2025 (short)", "pdf_url": "https://arxiv.org/pdf/2504.15205.pdf", "abstract_url": "https://arxiv.org/abs/2504.15205", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文通过比较人类评委与LLM（GPT-4o）评委在TREC 2024 RAG Track中对45份参赛作品的支持评估，探讨了LLM评委在减少系统幻觉方面的可靠性。", "motivation": "解决在检索增强生成（RAG）系统中，如何准确评估引用文档信息是否支持生成答案的问题，以减少系统幻觉。", "method": "进行了大规模的比较研究，包括两种条件：完全手动评估和手动后编辑LLM预测评估，比较人类评委与GPT-4o评委的支持评估结果。", "result": "研究发现，在完全手动评估中，人类与GPT-4o的预测匹配率为56%，在后编辑条件下提高到72%。独立人类评委与GPT-4o的相关性高于人类评委之间的相关性，表明LLM评委可以作为支持评估的可靠替代。", "conclusion": "LLM评委在支持评估中显示出作为人类评委替代的潜力，未来的支持评估应考虑到人类和LLM评委的错误类型，以指导改进方向。"}}
{"id": "2504.15219", "title": "EvalAgent: Discovering Implicit Evaluation Criteria from the Web", "authors": ["Manya Wadhwa", "Zayne Sprague", "Chaitanya Malaviya", "Philippe Laban", "Junyi Jessy Li", "Greg Durrett"], "abstract": "Evaluation of language model outputs on structured writing tasks is typically conducted with a number of desirable criteria presented to human evaluators or large language models (LLMs). For instance, on a prompt like \"Help me draft an academic talk on coffee intake vs research productivity\", a model response may be evaluated for criteria like accuracy and coherence. However, high-quality responses should do more than just satisfy basic task requirements. An effective response to this query should include quintessential features of an academic talk, such as a compelling opening, clear research questions, and a takeaway. To help identify these implicit criteria, we introduce EvalAgent, a novel framework designed to automatically uncover nuanced and task-specific criteria. EvalAgent first mines expert-authored online guidance. It then uses this evidence to propose diverse, long-tail evaluation criteria that are grounded in reliable external sources. Our experiments demonstrate that the grounded criteria produced by EvalAgent are often implicit (not directly stated in the user's prompt), yet specific (high degree of lexical precision). Further, EvalAgent criteria are often not satisfied by initial responses but they are actionable, such that responses can be refined to satisfy them. Finally, we show that combining LLM-generated and EvalAgent criteria uncovers more human-valued criteria than using LLMs alone.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.15219.pdf", "abstract_url": "https://arxiv.org/abs/2504.15219", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "EvalAgent是一个新颖的框架，旨在自动发现语言模型输出评估中的隐含和任务特定标准。通过挖掘专家撰写的在线指导，EvalAgent提出了多样化的、长尾的评估标准，这些标准基于可靠的外部来源。实验表明，EvalAgent生成的标准往往是隐含的、具体的，并且可以通过细化响应来满足。结合LLM生成的标准和EvalAgent的标准，可以发现更多人类重视的标准。", "motivation": "解决在结构化写作任务中评估语言模型输出时，如何自动发现那些未明确表述但高质量的隐含评估标准的问题。", "method": "EvalAgent框架首先挖掘专家撰写的在线指导，然后利用这些证据提出多样化、长尾的评估标准，这些标准基于可靠的外部来源。", "result": "EvalAgent生成的标准往往是隐含的（未在用户提示中直接表述）、具体的（具有高度的词汇精确性），并且可以通过细化响应来满足。结合LLM生成的标准和EvalAgent的标准，可以发现更多人类重视的标准。", "conclusion": "EvalAgent能够有效地发现并应用隐含的、任务特定的评估标准，结合LLM生成的标准，可以更全面地评估和提升语言模型输出的质量。"}}
{"id": "2504.14858", "title": "AlignRAG: An Adaptable Framework for Resolving Misalignments in Retrieval-Aware Reasoning of RAG", "authors": ["Jiaqi Wei", "Hao Zhou", "Xiang Zhang", "Di Zhang", "Zijie Qiu", "Wei Wei", "Jinzhe Li", "Wanli Ouyang", "Siqi Sun"], "abstract": "Retrieval-augmented generation (RAG) has emerged as a foundational paradigm for knowledge-grounded text generation. However, existing RAG pipelines often fail to ensure that the reasoning trajectories align with the evidential constraints imposed by retrieved content. In this paper, we reframe RAG as a problem of retrieval-aware reasoning and identify a core challenge: reasoning misalignment-the mismatch between a model's reasoning trajectory and the retrieved evidence. To address this challenge, we propose AlignRAG, a novel test-time framework that mitigates reasoning misalignment through iterative Critique-Driven Alignment (CDA) steps. In contrast to prior approaches that rely on static training or post-hoc selection, AlignRAG actively refines reasoning trajectories during inference by enforcing fine-grained alignment with evidence. Our framework introduces a new paradigm for retrieval-aware reasoning by: (1) constructing context-rich training corpora; (2) generating contrastive critiques from preference-aware reasoning trajectories; (3) training a dedicated \\textit{Critic Language Model (CLM)} to identify reasoning misalignments; and (4) applying CDA steps to optimize reasoning trajectories iteratively. Empirical results demonstrate that AlignRAG consistently outperforms all baselines and could integrate as a plug-and-play module into existing RAG pipelines without further changes. By reconceptualizing RAG as a structured reasoning trajectory and establishing the test-time framework for correcting reasoning misalignments in RAG, AlignRAG provides practical advancements for retrieval-aware generation.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.14858.pdf", "abstract_url": "https://arxiv.org/abs/2504.14858", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "AlignRAG是一个新颖的测试时框架，旨在解决检索增强生成（RAG）中的推理不对齐问题，通过迭代的批判驱动对齐（CDA）步骤优化推理轨迹，确保与检索证据的细粒度对齐。", "motivation": "现有的RAG管道往往无法确保推理轨迹与检索内容施加的证据约束对齐，导致推理不对齐问题。", "method": "AlignRAG通过构建上下文丰富的训练语料库、从偏好感知的推理轨迹生成对比批判、训练专门的批判语言模型（CLM）来识别推理不对齐，并应用CDA步骤迭代优化推理轨迹。", "result": "实证结果表明，AlignRAG consistently outperforms all baselines and could integrate as a plug-and-play module into existing RAG pipelines without further changes.", "conclusion": "AlignRAG通过将RAG重新概念化为结构化推理轨迹，并建立测试时框架来纠正RAG中的推理不对齐，为检索感知生成提供了实际的进步。"}}
{"id": "2504.14928", "title": "EducationQ: Evaluating LLMs' Teaching Capabilities Through Multi-Agent Dialogue Framework", "authors": ["Yao Shi", "Rongkeng Liang", "Yong Xu"], "abstract": "Large language models (LLMs) increasingly serve as educational tools, yet evaluating their teaching capabilities remains challenging due to the resource-intensive, context-dependent, and methodologically complex nature of teacher-student interactions. We introduce EducationQ, a multi-agent dialogue framework that efficiently assesses teaching capabilities through simulated dynamic educational scenarios, featuring specialized agents for teaching, learning, and evaluation. Testing 14 LLMs across major AI Organizations (OpenAI, Meta, Google, Anthropic, and others) on 1,498 questions spanning 13 disciplines and 10 difficulty levels reveals that teaching effectiveness does not correlate linearly with model scale or general reasoning capabilities - with some smaller open-source models outperforming larger commercial counterparts in teaching contexts. This finding highlights a critical gap in current evaluations that prioritize knowledge recall over interactive pedagogy. Our mixed-methods evaluation, combining quantitative metrics with qualitative analysis and expert case studies, identifies distinct pedagogical strengths employed by top-performing models (e.g., sophisticated questioning strategies, adaptive feedback mechanisms). Human expert evaluations show 78% agreement with our automated qualitative analysis of effective teaching behaviors, validating our methodology. EducationQ demonstrates that LLMs-as-teachers require specialized optimization beyond simple scaling, suggesting next-generation educational AI prioritize targeted enhancement of specific pedagogical effectiveness.", "subjects": "Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Computation and Language (cs.CL); Computers and Society (cs.CY); Human-Computer Interaction (cs.HC)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.14928.pdf", "abstract_url": "https://arxiv.org/abs/2504.14928", "categories": ["Artificial Intelligence (cs.AI)", "Computational Engineering, Finance, and Science (cs.CE)", "Computation and Language (cs.CL)", "Computers and Society (cs.CY)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了EducationQ，一个通过多智能体对话框架评估大型语言模型（LLMs）教学能力的方法。研究发现，教学效果与模型规模或一般推理能力并不线性相关，某些较小的开源模型在教学场景中表现优于较大的商业模型。", "motivation": "由于教师-学生互动的资源密集、上下文依赖和方法复杂，评估LLMs的教学能力具有挑战性。", "method": "采用多智能体对话框架，模拟动态教育场景，包括专门的教学、学习和评估智能体，测试了14个LLMs在1,498个问题上的表现。", "result": "教学效果与模型规模或一般推理能力不线性相关；人类专家评估与自动定性分析的有效教学行为有78%的一致性。", "conclusion": "LLMs作为教师需要超越简单规模化的专门优化，下一代教育AI应优先考虑特定教学效果的有针对性增强。"}}
{"id": "2504.15046", "title": "Text-to-Decision Agent: Learning Generalist Policies from Natural Language Supervision", "authors": ["Shilin Zhang", "Zican Hu", "Wenhao Wu", "Xinyi Xie", "Jianxiang Tang", "Chunlin Chen", "Daoyi Dong", "Yu Cheng", "Zhenhong Sun", "Zhi Wang"], "abstract": "RL systems usually tackle generalization by inferring task beliefs from high-quality samples or warmup explorations. The restricted form limits their generality and usability since these supervision signals are expensive and even infeasible to acquire in advance for unseen tasks. Learning directly from the raw text about decision tasks is a promising alternative to leverage a much broader source of supervision. In the paper, we propose Text-to-Decision Agent (T2DA), a simple and scalable framework that supervises generalist policy learning with natural language. We first introduce a generalized world model to encode multi-task decision data into a dynamics-aware embedding space. Then, inspired by CLIP, we predict which textual description goes with which decision embedding, effectively bridging their semantic gap via contrastive language-decision pre-training and aligning the text embeddings to comprehend the environment dynamics. After training the text-conditioned generalist policy, the agent can directly realize zero-shot text-to-decision generation in response to language instructions. Comprehensive experiments on MuJoCo and Meta-World benchmarks show that T2DA facilitates high-capacity zero-shot generalization and outperforms various types of baselines.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "18 pages, 8 figures", "pdf_url": "https://arxiv.org/pdf/2504.15046.pdf", "abstract_url": "https://arxiv.org/abs/2504.15046", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了Text-to-Decision Agent (T2DA)，一个通过自然语言监督学习通用策略的简单可扩展框架。T2DA通过对比性语言-决策预训练和文本嵌入对齐，实现了零样本文本到决策的生成，并在多个基准测试中表现出色。", "motivation": "解决RL系统在泛化能力上的限制，这些系统通常依赖于高质量样本或预热探索来推断任务信念，但这些监督信号成本高昂且对于未见任务可能不可行。", "method": "引入了一个广义世界模型来编码多任务决策数据到动态感知的嵌入空间，并通过对比性语言-决策预训练和文本嵌入对齐，缩小语义差距。", "result": "在MuJoCo和Meta-World基准测试中，T2DA促进了高容量的零样本泛化，并优于各种基线方法。", "conclusion": "T2DA框架通过自然语言监督学习通用策略，不仅提高了RL系统的泛化能力和可用性，还为处理未见任务提供了一种有效的方法。"}}
{"id": "2504.15125", "title": "Contemplative Wisdom for Superalignment", "authors": ["Ruben Laukkonen", "Fionn Inglis", "Shamil Chandaria", "Lars Sandved-Smith", "Jakob Hohwy", "Jonathan Gold", "Adam Elwood"], "abstract": "As artificial intelligence (AI) improves, traditional alignment strategies may falter in the face of unpredictable self-improvement, hidden subgoals, and the sheer complexity of intelligent systems. Rather than externally constraining behavior, we advocate designing AI with intrinsic morality built into its cognitive architecture and world model. Inspired by contemplative wisdom traditions, we show how four axiomatic principles can instil a resilient Wise World Model in AI systems. First, mindfulness enables self-monitoring and recalibration of emergent subgoals. Second, emptiness forestalls dogmatic goal fixation and relaxes rigid priors. Third, non-duality dissolves adversarial self-other boundaries. Fourth, boundless care motivates the universal reduction of suffering. We find that prompting AI to reflect on these principles improves performance on the AILuminate Benchmark using GPT-4o, particularly when combined. We offer detailed implementation strategies for state-of-the-art models, including contemplative architectures, constitutions, and reinforcement of chain-of-thought. For future systems, the active inference framework may offer the self-organizing and dynamic coupling capabilities needed to enact these insights in embodied agents. This interdisciplinary approach offers a self-correcting and resilient alternative to prevailing brittle control schemes.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.15125.pdf", "abstract_url": "https://arxiv.org/abs/2504.15125", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于沉思智慧传统的方法，旨在通过内在道德设计来增强人工智能（AI）的对齐能力，以应对自我改进的不可预测性、隐藏的子目标及智能系统的复杂性。", "motivation": "传统对齐策略在面对AI的不可预测自我改进、隐藏子目标及系统复杂性时可能失效，因此需要一种更内在、更弹性的对齐方法。", "method": "设计了基于四个沉思智慧原则的Wise World Model：正念、空性、非二元性和无限关怀，通过在AI中植入这些原则来改善其性能和道德对齐。", "result": "实验表明，通过让AI反思这些原则，特别是在结合使用时，可以显著提高其在AILuminate Benchmark上的表现。", "conclusion": "这种跨学科方法提供了一种自我纠正和弹性的替代方案，优于现有的脆弱控制方案，为未来AI系统的道德对齐提供了新的方向。"}}
{"id": "2504.15146", "title": "Behavioral Universe Network (BUN): A Behavioral Information-Based Framework for Complex Systems", "authors": ["Wei Zhou", "Ailiya Borjigin", "Cong He"], "abstract": "Modern digital ecosystems feature complex, dynamic interactions among autonomous entities across diverse domains. Traditional models often separate agents and objects, lacking a unified foundation to capture their interactive behaviors. This paper introduces the Behavioral Universe Network (BUN), a theoretical framework grounded in the Agent-Interaction-Behavior (AIB) formalism. BUN treats subjects (active agents), objects (resources), and behaviors (operations) as first-class entities, all governed by a shared Behavioral Information Base (BIB). We detail the AIB core concepts and demonstrate how BUN leverages information-driven triggers, semantic enrichment, and adaptive rules to coordinate multi-agent systems. We highlight key benefits: enhanced behavior analysis, strong adaptability, and cross-domain interoperability. We conclude by positioning BUN as a promising foundation for next-generation digital governance and intelligent applications.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "17 pages, 1 figure", "pdf_url": "https://arxiv.org/pdf/2504.15146.pdf", "abstract_url": "https://arxiv.org/abs/2504.15146", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了行为宇宙网络（BUN），这是一个基于代理-交互-行为（AIB）形式主义的理论框架，旨在为现代数字生态系统中的复杂动态交互提供统一的基础。BUN将主体（主动代理）、客体（资源）和行为（操作）视为一等实体，所有实体都由共享的行为信息库（BIB）管理。", "motivation": "传统模型往往将代理和对象分开，缺乏一个统一的基础来捕捉它们的交互行为。为了解决这个问题，本文提出了BUN框架。", "method": "BUN框架基于AIB形式主义，利用信息驱动的触发器、语义丰富和自适应规则来协调多代理系统。", "result": "BUN框架的关键优势包括增强的行为分析、强大的适应性和跨领域的互操作性。", "conclusion": "BUN被认为是下一代数字治理和智能应用的有前途的基础。"}}
{"id": "2504.14868", "title": "Twin Co-Adaptive Dialogue for Progressive Image Generation", "authors": ["Jianhui Wang", "Yangfan He", "Yan Zhong", "Xinyuan Song", "Jiayi Su", "Yuheng Feng", "Hongyang He", "Wenyu Zhu", "Xinhang Yuan", "Kuan Lu", "Menghao Huo", "Miao Zhang", "Keqin Li", "Jiaqi Chen", "Tianyu Shi", "Xueqian Wang"], "abstract": "Modern text-to-image generation systems have enabled the creation of remarkably realistic and high-quality visuals, yet they often falter when handling the inherent ambiguities in user prompts. In this work, we present Twin-Co, a framework that leverages synchronized, co-adaptive dialogue to progressively refine image generation. Instead of a static generation process, Twin-Co employs a dynamic, iterative workflow where an intelligent dialogue agent continuously interacts with the user. Initially, a base image is generated from the user's prompt. Then, through a series of synchronized dialogue exchanges, the system adapts and optimizes the image according to evolving user feedback. The co-adaptive process allows the system to progressively narrow down ambiguities and better align with user intent. Experiments demonstrate that Twin-Co not only enhances user experience by reducing trial-and-error iterations but also improves the quality of the generated images, streamlining the creative process across various applications.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.14868.pdf", "abstract_url": "https://arxiv.org/abs/2504.14868", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "Twin-Co是一个通过同步、共适应对话逐步优化图像生成的框架，旨在解决文本到图像生成系统在处理用户提示时的模糊性问题。", "motivation": "解决现代文本到图像生成系统在处理用户提示时的模糊性问题，提升生成图像的质量和用户体验。", "method": "采用动态、迭代的工作流程，通过智能对话代理与用户进行连续的交互，根据用户反馈逐步优化图像。", "result": "实验证明，Twin-Co不仅通过减少试错迭代提升了用户体验，还提高了生成图像的质量，优化了创意过程。", "conclusion": "Twin-Co通过共适应的对话流程，有效减少了用户提示的模糊性，更好地满足了用户意图，为图像生成领域提供了新的解决方案。"}}
{"id": "2504.13861", "title": "3MDBench: Medical Multimodal Multi-agent Dialogue Benchmark", "authors": ["Ivan Sviridov", "Amina Miftakhova", "Artemiy Tereshchenko", "Galina Zubkova", "Pavel Blinov", "Andrey Savchenko"], "abstract": "Large Vision-Language Models (LVLMs) are increasingly being explored for applications in telemedicine, yet their ability to engage with diverse patient behaviors remains underexplored. We introduce 3MDBench (Medical Multimodal Multi-agent Dialogue Benchmark), an open-source evaluation framework designed to assess LLM-driven medical consultations. Unlike existing benchmarks, 3MDBench simulates real-world patient variability by incorporating four temperament-driven Patient Agents and an Assessor Agent that evaluates diagnostic accuracy and dialogue quality. The benchmark integrates textual and image-based patient data across 34 common diagnoses, mirroring real-world telemedicine interactions. Under different diagnostic strategies, we evaluate state-of-the-art LVLMs. Our findings demonstrate that incorporating dialogue improves the F1 score from 50.4 to 54.2 compared to non-dialogue settings, underscoring the value of context-driven, information-seeking questioning. Additionally, we demonstrate that multimodal inputs enhance diagnostic efficiency. Image-supported models outperform text-only counterparts by raising the diagnostic F1 score from 52.8 to 54.2 in a similar dialogue setting. Finally, we suggest an approach that improves the diagnostic F1-score to 70.3 by training the CNN model on the diagnosis prediction task and incorporating its top-3 predictions into the LVLM context. 3MDBench provides a reproducible and extendable evaluation framework for AI-driven medical assistants. It offers insights into how patient temperament, dialogue strategies, and multimodal reasoning influence diagnosis quality. By addressing real-world complexities in telemedicine, our benchmark paves the way for more empathetic, reliable, and context-aware AI-driven healthcare solutions. The source code of our benchmark is publicly available:", "subjects": "Human-Computer Interaction (cs.HC); Computation and Language (cs.CL); Multiagent Systems (cs.MA)", "comments": "26 pages, 8 figures, 7 tables", "pdf_url": "https://arxiv.org/pdf/2504.13861.pdf", "abstract_url": "https://arxiv.org/abs/2504.13861", "categories": ["Human-Computer Interaction (cs.HC)", "Computation and Language (cs.CL)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "3MDBench是一个开源的评估框架，旨在评估基于大型视觉语言模型（LVLM）的医疗咨询，通过模拟真实世界患者的多样性来提高诊断准确性和对话质量。", "motivation": "解决大型视觉语言模型在远程医疗应用中与多样化患者行为互动能力不足的问题。", "method": "引入3MDBench框架，包含四种气质驱动的患者代理和一个评估代理，整合文本和图像数据，评估LVLM在不同诊断策略下的表现。", "result": "研究发现，结合对话和多模态输入显著提高诊断效率，最佳方法将诊断F1分数提升至70.3。", "conclusion": "3MDBench为AI驱动的医疗助手提供了可复制和可扩展的评估框架，促进了更 empathetic、可靠和情境感知的医疗解决方案的发展。"}}
{"id": "2504.13865", "title": "A Survey on (M)LLM-Based GUI Agents", "authors": ["Fei Tang", "Haolei Xu", "Hang Zhang", "Siqi Chen", "Xingyu Wu", "Yongliang Shen", "Wenqi Zhang", "Guiyang Hou", "Zeqi Tan", "Yuchen Yan", "Kaitao Song", "Jian Shao", "Weiming Lu", "Jun Xiao", "Yueting Zhuang"], "abstract": "Graphical User Interface (GUI) Agents have emerged as a transformative paradigm in human-computer interaction, evolving from rule-based automation scripts to sophisticated AI-driven systems capable of understanding and executing complex interface operations. This survey provides a comprehensive examination of the rapidly advancing field of LLM-based GUI Agents, systematically analyzing their architectural foundations, technical components, and evaluation methodologies. We identify and analyze four fundamental components that constitute modern GUI Agents: (1) perception systems that integrate text-based parsing with multimodal understanding for comprehensive interface comprehension; (2) exploration mechanisms that construct and maintain knowledge bases through internal modeling, historical experience, and external information retrieval; (3) planning frameworks that leverage advanced reasoning methodologies for task decomposition and execution; and (4) interaction systems that manage action generation with robust safety controls. Through rigorous analysis of these components, we reveal how recent advances in large language models and multimodal learning have revolutionized GUI automation across desktop, mobile, and web platforms. We critically examine current evaluation frameworks, highlighting methodological limitations in existing benchmarks while proposing directions for standardization. This survey also identifies key technical challenges, including accurate element localization, effective knowledge retrieval, long-horizon planning, and safety-aware execution control, while outlining promising research directions for enhancing GUI Agents' capabilities. Our systematic review provides researchers and practitioners with a thorough understanding of the field's current state and offers insights into future developments in intelligent interface automation.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.13865.pdf", "abstract_url": "https://arxiv.org/abs/2504.13865", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文综述了基于大型语言模型（LLM）的图形用户界面（GUI）代理的最新进展，系统分析了其架构基础、技术组件和评估方法，并探讨了当前的技术挑战和未来的研究方向。", "motivation": "解决图形用户界面（GUI）代理在理解和执行复杂界面操作方面的技术挑战，推动人机交互领域的发展。", "method": "通过系统分析现代GUI代理的四个基本组成部分：感知系统、探索机制、规划框架和交互系统，以及评估当前的技术挑战和研究方向。", "result": "揭示了大型语言模型和多模态学习在GUI自动化方面的革命性影响，并指出了当前评估框架的方法学限制和技术挑战。", "conclusion": "本文为研究人员和实践者提供了对该领域当前状态的全面理解，并为智能界面自动化的未来发展提供了见解。"}}
{"id": "2504.13887", "title": "AI as a deliberative partner fosters intercultural empathy for Americans but fails for Latin American participants", "authors": ["Isabel Villanueva", "Tara Bobinac", "Binwei Yao", "Junjie Hu", "Kaiping Chen"], "abstract": "Despite the growing integration of AI chatbots as conversational agents in public discourse, empirical evidence regarding their capacity to foster intercultural empathy remains limited. Using a randomized dialogue experiment, we examined how different types of AI chatbot interaction, i.e., deliberative versus non-deliberative and culturally aligned versus non-aligned, affect intercultural empathy across cultural groups. Results show that deliberative conversations increased intercultural empathy among American participants but not Latin American participants, who perceived AI responses as culturally inaccurate and failing to represent their cultural contexts and perspectives authentically. Real-time interaction analyses reveal that these differences stem from cultural knowledge gaps inherent in Large Language Models. Despite explicit prompting and instruction to represent cultural perspectives in participants' native languages, AI systems still exhibit significant disparities in cultural representation. This highlights the importance of designing AI systems capable of culturally authentic engagement in deliberative conversations. Our study contributes to deliberation theory and AI alignment research by underscoring AI's role in intercultural dialogue and the persistent challenge of representational asymmetry in democratic discourse.", "subjects": "Human-Computer Interaction (cs.HC); Computation and Language (cs.CL); Computers and Society (cs.CY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.13887.pdf", "abstract_url": "https://arxiv.org/abs/2504.13887", "categories": ["Human-Computer Interaction (cs.HC)", "Computation and Language (cs.CL)", "Computers and Society (cs.CY)"], "matching_keywords": ["agent"], "AI": {"tldr": "研究探讨了AI聊天机器人作为对话代理在促进跨文化同理心方面的能力，发现审议式对话对美国参与者有效，但对拉丁美洲参与者无效，后者认为AI回应文化不准确。", "motivation": "尽管AI聊天机器人在公共话语中的整合日益增多，但关于其促进跨文化同理心能力的实证证据仍然有限。", "method": "通过随机对话实验，研究了不同类型（审议式与非审议式、文化对齐与非对齐）的AI聊天机器人互动如何影响不同文化群体的跨文化同理心。", "result": "审议式对话增加了美国参与者的跨文化同理心，但对拉丁美洲参与者无效，他们认为AI回应未能真实代表其文化背景和视角。", "conclusion": "研究强调了设计能够进行文化真实参与的AI系统的重要性，并指出了在民主话语中文化代表性不对称的持续挑战。"}}
{"id": "2504.15228", "title": "A Self-Improving Coding Agent", "authors": ["Maxime Robeyns", "Martin Szummer", "Laurence Aitchison"], "abstract": "We demonstrate that an LLM coding agent, equipped with basic coding tools, can autonomously edit itself, and thereby improve its performance on benchmark tasks. We find performance gains from 17% to 53% on a random subset of SWE Bench Verified, with additional performance gains on LiveCodeBench, as well as synthetically generated agent benchmarks. Our work represents an advancement in the automated and open-ended design of agentic systems, and provides a reference agent framework for those seeking to post-train LLMs on tool use and other agentic tasks.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "Published at an ICLR 2025 workshop on Scaling Self-Improving Foundation Models", "pdf_url": "https://arxiv.org/pdf/2504.15228.pdf", "abstract_url": "https://arxiv.org/abs/2504.15228", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文展示了一种配备基本编码工具的LLM编码代理能够自主编辑自身，从而在基准任务上提高性能。在SWE Bench Verified的随机子集上，性能提升从17%到53%不等，同时在LiveCodeBench和合成生成的代理基准上也获得了额外的性能提升。", "motivation": "解决自动化设计代理系统的问题，特别是在工具使用和其他代理任务上对LLMs进行后训练的需求。", "method": "使用配备基本编码工具的LLM编码代理，使其能够自主编辑自身代码以改进性能。", "result": "在SWE Bench Verified的随机子集上实现了17%到53%的性能提升，在LiveCodeBench和合成代理基准上也有额外提升。", "conclusion": "这项工作在自动化设计代理系统方面取得了进展，为那些寻求在工具使用和其他代理任务上对LLMs进行后训练的人提供了一个参考代理框架。"}}
{"id": "2504.15257", "title": "FlowReasoner: Reinforcing Query-Level Meta-Agents", "authors": ["Hongcheng Gao", "Yue Liu", "Yufei He", "Longxu Dou", "Chao Du", "Zhijie Deng", "Bryan Hooi", "Min Lin", "Tianyu Pang"], "abstract": "This paper proposes a query-level meta-agent named FlowReasoner to automate the design of query-level multi-agent systems, i.e., one system per user query. Our core idea is to incentivize a reasoning-based meta-agent via external execution feedback. Concretely, by distilling DeepSeek R1, we first endow the basic reasoning ability regarding the generation of multi-agent systems to FlowReasoner. Then, we further enhance it via reinforcement learning (RL) with external execution feedback. A multi-purpose reward is designed to guide the RL training from aspects of performance, complexity, and efficiency. In this manner, FlowReasoner is enabled to generate a personalized multi-agent system for each user query via deliberative reasoning. Experiments on both engineering and competition code benchmarks demonstrate the superiority of FlowReasoner. Remarkably, it surpasses o1-mini by 10.52% accuracy across three benchmarks. The code is available at", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.15257.pdf", "abstract_url": "https://arxiv.org/abs/2504.15257", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为FlowReasoner的查询级元代理，旨在自动化设计针对每个用户查询的多代理系统。通过结合深度学习和强化学习，FlowReasoner能够根据外部执行反馈进行优化，生成个性化的多代理系统。实验证明其在工程和竞赛代码基准测试中表现优异。", "motivation": "解决为每个用户查询自动化设计高效、个性化多代理系统的问题。", "method": "首先通过蒸馏DeepSeek R1赋予FlowReasoner基本的多代理系统生成能力，然后利用强化学习结合多用途奖励（性能、复杂度和效率）进行进一步优化。", "result": "FlowReasoner在三个基准测试中准确率超过o1-mini 10.52%，显示出其优越性。", "conclusion": "FlowReasoner通过结合深度学习和强化学习，能够有效地为每个用户查询生成个性化的多代理系统，展示了在自动化和个性化代理系统设计方面的潜力。"}}
{"id": "2504.13856", "title": "Towards Balancing Preference and Performance through Adaptive Personalized Explainability", "authors": ["Andrew Silva", "Pradyumna Tambwekar", "Mariah Schrum", "Matthew Gombolay"], "abstract": "As robots and digital assistants are deployed in the real world, these agents must be able to communicate their decision-making criteria to build trust, improve human-robot teaming, and enable collaboration. While the field of explainable artificial intelligence (xAI) has made great strides to enable such communication, these advances often assume that one xAI approach is ideally suited to each problem (e.g., decision trees to explain how to triage patients in an emergency or feature-importance maps to explain radiology reports). This fails to recognize that users have diverse experiences or preferences for interaction modalities. In this work, we present two user-studies set in a simulated autonomous vehicle (AV) domain. We investigate (1) population-level preferences for xAI and (2) personalization strategies for providing robot explanations. We find significant differences between xAI modes (language explanations, feature-importance maps, and decision trees) in both preference (p < 0.01) and performance (p < 0.05). We also observe that a participant's preferences do not always align with their performance, motivating our development of an adaptive personalization strategy to balance the two. We show that this strategy yields significant performance gains (p < 0.05), and we conclude with a discussion of our findings and implications for xAI in human-robot interactions.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": "20 pages, 19 figures, HRI 2024", "pdf_url": "https://arxiv.org/pdf/2504.13856.pdf", "abstract_url": "https://arxiv.org/abs/2504.13856", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了在模拟自动驾驶车辆领域中，通过自适应个性化解释性来平衡用户偏好和性能的方法。研究发现不同的解释性AI模式在用户偏好和性能上存在显著差异，并提出了一种自适应个性化策略以平衡两者。", "motivation": "随着机器人和数字助手在现实世界中的部署，这些代理需要能够传达其决策标准以建立信任、改善人机协作并实现合作。现有的可解释人工智能（xAI）方法往往假设每种问题都理想地适合一种xAI方法，忽视了用户多样化的经验或交互偏好。", "method": "本文在模拟自动驾驶车辆（AV）领域进行了两项用户研究，调查了（1）xAI的群体水平偏好和（2）提供机器人解释的个性化策略。", "result": "研究发现，不同的xAI模式（语言解释、特征重要性图和决策树）在偏好（p < 0.01）和性能（p < 0.05）上存在显著差异。此外，参与者的偏好并不总是与其性能一致，这促使开发了一种自适应个性化策略来平衡两者。", "conclusion": "本文展示的这种策略显著提高了性能（p < 0.05），并讨论了研究发现及其对人机交互中xAI的启示。"}}
{"id": "2504.14110", "title": "System of Agentic AI for the Discovery of Metal-Organic Frameworks", "authors": ["Theo Jaffrelot Inizan", "Sherry Yang", "Aaron Kaplan", "Yen-hsu Lin", "Jian Yin", "Saber Mirzaei", "Mona Abdelgaid", "Ali H. Alawadhi", "KwangHwan Cho", "Zhiling Zheng", "Ekin Dogus Cubuk", "Christian Borgs", "Jennifer T. Chayes", "Kristin A. Persson", "Omar M. Yaghi"], "abstract": "Generative models and machine learning promise accelerated material discovery in MOFs for CO2 capture and water harvesting but face significant challenges navigating vast chemical spaces while ensuring synthetizability. Here, we present MOFGen, a system of Agentic AI comprising interconnected agents: a large language model that proposes novel MOF compositions, a diffusion model that generates crystal structures, quantum mechanical agents that optimize and filter candidates, and synthetic-feasibility agents guided by expert rules and machine learning. Trained on all experimentally reported MOFs and computational databases, MOFGen generated hundreds of thousands of novel MOF structures and synthesizable organic linkers. Our methodology was validated through high-throughput experiments and the successful synthesis of five \"AI-dreamt\" MOFs, representing a major step toward automated synthesizable material discovery.", "subjects": "Materials Science (cond-mat.mtrl-sci); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.14110.pdf", "abstract_url": "https://arxiv.org/abs/2504.14110", "categories": ["Materials Science (cond-mat.mtrl-sci)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了MOFGen，一个由多个互联AI代理组成的系统，用于加速金属有机框架（MOFs）的发现，特别是在CO2捕获和水收集方面。该系统通过结合大型语言模型、扩散模型、量子力学代理和合成可行性代理，成功生成了大量新颖且可合成的MOF结构，并通过实验验证了其有效性。", "motivation": "解决在广阔的化学空间中导航并确保可合成性的挑战，以加速MOFs材料的发现。", "method": "使用MOFGen系统，该系统包括提出新颖MOF组成的大型语言模型、生成晶体结构的扩散模型、优化和筛选候选的量子力学代理，以及由专家规则和机器学习指导的合成可行性代理。", "result": "MOFGen生成了数十万种新颖的MOF结构和可合成的有机连接体，并通过高通量实验成功合成了五种“AI梦想”的MOFs。", "conclusion": "MOFGen代表了向自动化可合成材料发现迈出的重要一步，展示了AI在材料科学中的巨大潜力。"}}
{"id": "2504.13871", "title": "Human aversion? Do AI Agents Judge Identity More Harshly Than Performance", "authors": ["Yuanjun Feng", "Vivek Chodhary", "Yash Raj Shrestha"], "abstract": "This study examines the understudied role of algorithmic evaluation of human judgment in hybrid decision-making systems, a critical gap in management research. While extant literature focuses on human reluctance to follow algorithmic advice, we reverse the perspective by investigating how AI agents based on large language models (LLMs) assess and integrate human input. Our work addresses a pressing managerial constraint: firms barred from deploying LLMs directly due to privacy concerns can still leverage them as mediating tools (for instance, anonymized outputs or decision pipelines) to guide high-stakes choices like pricing or discounts without exposing proprietary data. Through a controlled prediction task, we analyze how an LLM-based AI agent weights human versus algorithmic predictions. We find that the AI system systematically discounts human advice, penalizing human errors more severely than algorithmic errors--a bias exacerbated when the agent's identity (human vs AI) is disclosed and the human is positioned second. These results reveal a disconnect between AI-generated trust metrics and the actual influence of human judgment, challenging assumptions about equitable human-AI collaboration. Our findings offer three key contributions. First, we identify a reverse algorithm aversion phenomenon, where AI agents undervalue human input despite comparable error rates. Second, we demonstrate how disclosure and positional bias interact to amplify this effect, with implications for system design. Third, we provide a framework for indirect LLM deployment that balances predictive power with data privacy. For practitioners, this research emphasize the need to audit AI weighting mechanisms, calibrate trust dynamics, and strategically design decision sequences in human-AI systems.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); General Economics (econ.GN)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.13871.pdf", "abstract_url": "https://arxiv.org/abs/2504.13871", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)", "General Economics (econ.GN)"], "matching_keywords": ["agent"], "AI": {"tldr": "本研究探讨了在混合决策系统中算法评估人类判断的未被充分研究的角色，发现基于大型语言模型（LLM）的AI代理在评估人类输入时存在偏见，尤其是在人类身份被披露且处于第二位时，这种偏见更为明显。", "motivation": "解决管理研究中关于算法评估人类判断的关键空白，特别是在隐私限制下如何利用LLM作为中介工具指导高风险决策。", "method": "通过一个受控的预测任务，分析基于LLM的AI代理如何权衡人类与算法的预测。", "result": "AI系统系统地低估人类建议，对人类的错误惩罚比算法错误更严厉，尤其是在人类身份被披露且处于第二位时，这种偏见加剧。", "conclusion": "研究揭示了AI生成的信任指标与人类判断实际影响之间的脱节，挑战了关于人类-AI公平合作的假设，并提出了间接部署LLM的框架，以平衡预测能力和数据隐私。"}}
{"id": "2504.13898", "title": "The Human Robot Social Interaction (HSRI) Dataset: Benchmarking Foundational Models' Social Reasoning", "authors": ["Dong Won Lee", "Yubin Kim", "Denison Guvenoz", "Sooyeon Jeong", "Parker Malachowsky", "Louis-Philippe Morency", "Cynthia Breazeal", "Hae Won Park"], "abstract": "Our work aims to advance the social reasoning of embodied artificial intelligence (AI) agents in real-world social interactions. Recently, language models (LMs) and foundational models (FMs) are being utilized as automatic evaluators of human-AI interactions with the goal of eventually being used to improve the policy of the AI agent. To enable further research in this direction, we introduce a large-scale real-world Human Robot Social Interaction (HSRI) Dataset to benchmark the capabilities of LMs and FMs to identify and reason about social interactions, specifically with regard to robot social errors and competencies . Our dataset consists of 400 real-world human social robot interaction videos and over 10K annotations, detailing the robot's social errors, competencies, rationale, and corrective actions, capturing unique aspects of human-AI interaction only present in real-world interactions. To further assess AI models' ability to reason about social interactions, we propose eight new benchmark tasks for evaluating centered around whether AI models can (1) evaluate social interactions via detecting social errors and competencies, (2) identify the explanatory factors associated to errors and competencies, (3) understand the flow of real-world social interactions, and (4) provide reasons and corrective actions for social errors. Human studies and experiments with modern LMs and FMs reveal that current models struggle with these tasks, demonstrating that our dataset and benchmark provides a step forward towards socially intelligent AI.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": "23 pages, 11 figures", "pdf_url": "https://arxiv.org/pdf/2504.13898.pdf", "abstract_url": "https://arxiv.org/abs/2504.13898", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了人类机器人社交互动（HSRI）数据集，旨在通过大规模真实世界的人机互动视频和注释，评估语言模型和基础模型在识别和推理社交互动方面的能力，特别是关于机器人社交错误和能力。", "motivation": "推动具身人工智能（AI）代理在真实世界社交互动中的社交推理能力，利用语言模型（LMs）和基础模型（FMs）作为人机互动的自动评估者，以最终改进AI代理的策略。", "method": "引入了一个大规模的真实世界人类机器人社交互动（HSRI）数据集，包含400个真实世界的人机互动视频和超过10K的注释，详细记录了机器人的社交错误、能力、理由和纠正措施。", "result": "人类研究和现代LMs及FMs的实验显示，当前模型在这些任务上表现不佳，表明我们的数据集和基准测试为社交智能AI的发展迈出了一步。", "conclusion": "HSRI数据集和提出的八个新基准任务为评估AI模型在社交互动中的推理能力提供了重要工具，揭示了当前模型在社交推理方面的局限性，为未来研究指明了方向。"}}
{"id": "2504.13908", "title": "AI-Assisted Conversational Interviewing: Effects on Data Quality and User Experience", "authors": ["Soubhik Barari", "Jarret Angbazo", "Natalie Wang", "Leah M. Christian", "Elizabeth Dean", "Zoe Slowinski", "Brandon Sepulvado"], "abstract": "Standardized surveys scale efficiently but sacrifice depth, while conversational interviews improve response quality at the cost of scalability and consistency. This study bridges the gap between these methods by introducing a framework for AI-assisted conversational interviewing. To evaluate this framework, we conducted a web survey experiment where 1,800 participants were randomly assigned to text-based conversational AI agents, or \"textbots\", to dynamically probe respondents for elaboration and interactively code open-ended responses. We assessed textbot performance in terms of coding accuracy, response quality, and respondent experience. Our findings reveal that textbots perform moderately well in live coding even without survey-specific fine-tuning, despite slightly inflated false positive errors due to respondent acquiescence bias. Open-ended responses were more detailed and informative, but this came at a slight cost to respondent experience. Our findings highlight the feasibility of using AI methods to enhance open-ended data collection in web surveys.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Applications (stat.AP)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.13908.pdf", "abstract_url": "https://arxiv.org/abs/2504.13908", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)", "Applications (stat.AP)"], "matching_keywords": ["agent"], "AI": {"tldr": "本研究通过引入AI辅助的对话式访谈框架，旨在解决标准化调查与对话式访谈之间的差距。通过文本基础的对话AI代理（'textbots'）动态探测受访者的详细回答并交互式编码开放性问题，评估了其在编码准确性、回答质量和受访者体验方面的表现。", "motivation": "标准化调查虽效率高但深度不足，而对话式访谈虽提高回答质量却牺牲了可扩展性和一致性。本研究旨在通过AI辅助的对话式访谈框架，弥补这两种方法之间的差距。", "method": "通过网页调查实验，随机分配1,800名参与者使用基于文本的对话AI代理（'textbots'），动态探测受访者的详细回答并交互式编码开放性问题。", "result": "研究发现，textbots在实时编码中表现中等，即使没有针对特定调查的精细调整，尽管由于受访者的默许偏见导致假阳性错误略有增加。开放性问题回答更为详细和信息丰富，但这略微影响了受访者体验。", "conclusion": "研究结果强调了使用AI方法增强网页调查中开放式数据收集的可行性，尽管在受访者体验方面略有牺牲。"}}
{"id": "2504.14822", "title": "Completing A Systematic Review in Hours instead of Months with Interactive AI Agents", "authors": ["Rui Qiu", "Shijie Chen", "Yu Su", "Po-Yin Yen", "Han-Wei Shen"], "abstract": "Systematic reviews (SRs) are vital for evidence-based practice in high stakes disciplines, such as healthcare, but are often impeded by intensive labors and lengthy processes that can take months to complete. Due to the high demand for domain expertise, existing automatic summarization methods fail to accurately identify relevant studies and generate high-quality summaries. To that end, we introduce InsightAgent, a human-centered interactive AI agent powered by large language models that revolutionize this workflow. InsightAgent partitions a large literature corpus based on semantics and employs a multi-agent design for more focused processing of literature, leading to significant improvement in the quality of generated SRs. InsightAgent also provides intuitive visualizations of the corpus and agent trajectories, allowing users to effortlessly monitor the actions of the agent and provide real-time feedback based on their expertise. Our user studies with 9 medical professionals demonstrate that the visualization and interaction mechanisms can effectively improve the quality of synthesized SRs by 27.2%, reaching 79.7% of human-written quality. At the same time, user satisfaction is improved by 34.4%. With InsightAgent, it only takes a clinician about 1.5 hours, rather than months, to complete a high-quality systematic review.", "subjects": "Human-Computer Interaction (cs.HC); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.14822.pdf", "abstract_url": "https://arxiv.org/abs/2504.14822", "categories": ["Human-Computer Interaction (cs.HC)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "InsightAgent是一种基于大型语言模型的交互式AI代理，旨在通过语义分割和多代理设计显著提高系统综述的质量和效率，将完成时间从数月缩短至约1.5小时。", "motivation": "系统综述在高风险领域如医疗保健中至关重要，但传统方法耗时耗力，且现有自动化方法无法准确识别相关研究并生成高质量摘要。", "method": "引入InsightAgent，一种以人为中心的交互式AI代理，利用大型语言模型，通过语义分割文献库和多代理设计进行更集中的文献处理，并提供直观的可视化。", "result": "用户研究表明，可视化与交互机制能有效提高合成系统综述的质量27.2%，达到人工撰写质量的79.7%，同时用户满意度提高34.4%。", "conclusion": "InsightAgent显著提高了系统综述的效率和质量，使 clinicians 能够在约1.5小时内完成高质量的系统综述，大大缩短了传统方法所需的时间。"}}
{"id": "2504.15068", "title": "The Great Nugget Recall: Automating Fact Extraction and RAG Evaluation with Large Language Models", "authors": ["Ronak Pradeep", "Nandan Thakur", "Shivani Upadhyay", "Daniel Campos", "Nick Craswell", "Jimmy Lin"], "abstract": "Large Language Models (LLMs) have significantly enhanced the capabilities of information access systems, especially with retrieval-augmented generation (RAG). Nevertheless, the evaluation of RAG systems remains a barrier to continued progress, a challenge we tackle in this work by proposing an automatic evaluation framework that is validated against human annotations. We believe that the nugget evaluation methodology provides a solid foundation for evaluating RAG systems. This approach, originally developed for the TREC Question Answering (QA) Track in 2003, evaluates systems based on atomic facts that should be present in good answers. Our efforts focus on \"refactoring\" this methodology, where we describe the AutoNuggetizer framework that specifically applies LLMs to both automatically create nuggets and automatically assign nuggets to system answers. In the context of the TREC 2024 RAG Track, we calibrate a fully automatic approach against strategies where nuggets are created manually or semi-manually by human assessors and then assigned manually to system answers. Based on results from a community-wide evaluation, we observe strong agreement at the run level between scores derived from fully automatic nugget evaluation and human-based variants. The agreement is stronger when individual framework components such as nugget assignment are automated independently. This suggests that our evaluation framework provides tradeoffs between effort and quality that can be used to guide the development of future RAG systems. However, further research is necessary to refine our approach, particularly in establishing robust per-topic agreement to diagnose system failures effectively.", "subjects": "Information Retrieval (cs.IR); Computation and Language (cs.CL)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2504.15068.pdf", "abstract_url": "https://arxiv.org/abs/2504.15068", "categories": ["Information Retrieval (cs.IR)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种自动评估框架AutoNuggetizer，用于评估检索增强生成（RAG）系统，通过大型语言模型（LLMs）自动创建和分配nuggets（原子事实），并与人工评估结果进行对比验证。", "motivation": "解决RAG系统评估的挑战，提供一个自动化的评估方法以减少人工评估的工作量并保持评估质量。", "method": "采用nugget评估方法，开发AutoNuggetizer框架，利用LLMs自动创建和分配nuggets，并与人工创建的nuggets进行对比。", "result": "在TREC 2024 RAG Track的社区广泛评估中，完全自动化的nugget评估与人工评估在运行级别上显示出强烈的一致性。", "conclusion": "AutoNuggetizer框架在努力和质量之间提供了权衡，可用于指导未来RAG系统的开发，但需要进一步研究以完善方法，特别是在建立强大的每主题一致性以有效诊断系统故障方面。"}}
{"id": "2504.13969", "title": "Tinker Tales: Interactive Storytelling Framework for Early Childhood Narrative Development and AI Literacy", "authors": ["Nayoung Choi", "Peace Cyebukayire", "Jinho D. Choi"], "abstract": "This paper presents Tinker Tales, an interactive storytelling framework in the format of a board game, designed to support both narrative development and AI literacy in early childhood. The framework integrates tangible and speech-based interactions with AI through NFC chip-attached pawns and tokens, along with a speaker and microphone. Children select and define key story elements-such as characters, places, items, and emotions-using the pawns and tokens, providing further details to the AI and receiving proper assistance, similar to how adults prompt AI for specific tasks (e.g., writing). For evaluation, several game sessions were simulated with a child AI agent, and the quality and safety of the generated stories were assessed from various perspectives. This work highlights the potential of combining physical and digital elements in AI literacy, offering a safe and engaging way for children to learn how to effectively collaborate with AI.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.13969.pdf", "abstract_url": "https://arxiv.org/abs/2504.13969", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了Tinker Tales，一个以棋盘游戏形式设计的互动讲故事框架，旨在支持幼儿的叙事发展和AI素养。该框架通过NFC芯片附着的棋子和令牌，以及扬声器和麦克风，整合了与AI的有形和语音交互。", "motivation": "解决如何在早期儿童教育中同时促进叙事发展和AI素养的问题。", "method": "使用NFC芯片附着的棋子和令牌进行有形和语音交互，儿童选择并定义关键故事元素，AI提供适当协助。", "result": "通过模拟游戏会话评估生成故事的质量和安全性，展示了物理和数字元素结合在AI素养教育中的潜力。", "conclusion": "Tinker Tales为儿童提供了一种安全且引人入胜的方式，学习如何与AI有效合作，突出了在AI素养教育中结合物理和数字元素的潜力。"}}
{"id": "2504.15280", "title": "Seeing from Another Perspective: Evaluating Multi-View Understanding in MLLMs", "authors": ["Chun-Hsiao Yeh", "Chenyu Wang", "Shengbang Tong", "Ta-Ying Cheng", "Rouyu Wang", "Tianzhe Chu", "Yuexiang Zhai", "Yubei Chen", "Shenghua Gao", "Yi Ma"], "abstract": "Multi-view understanding, the ability to reconcile visual information across diverse viewpoints for effective navigation, manipulation, and 3D scene comprehension, is a fundamental challenge in Multi-Modal Large Language Models (MLLMs) to be used as embodied agents. While recent MLLMs have shown impressive advances in high-level reasoning and planning, they frequently fall short when confronted with multi-view geometric consistency and cross-view correspondence. To comprehensively evaluate the challenges of MLLMs in multi-view scene reasoning, we propose All-Angles Bench, a benchmark of over 2,100 human carefully annotated multi-view question-answer pairs across 90 diverse real-world scenes. Our six tasks (counting, attribute identification, relative distance, relative direction, object manipulation, and camera pose estimation) specifically test model's geometric correspondence and the capacity to align information consistently across views. Our extensive experiments, benchmark on 27 representative MLLMs including Gemini-2.0-Flash, Claude-3.7-Sonnet, and GPT-4o against human evaluators reveals a substantial performance gap, indicating that current MLLMs remain far from human-level proficiency. Through in-depth analysis, we show that MLLMs are particularly underperforming under two aspects: (1) cross-view correspondence for partially occluded views and (2) establishing the coarse camera poses. These findings highlight the necessity of domain-specific refinements or modules that embed stronger multi-view awareness. We believe that our All-Angles Bench offers valuable insights and contribute to bridging the gap between MLLMs and human-level multi-view understanding. The project and benchmark are publicly available at", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2504.15280.pdf", "abstract_url": "https://arxiv.org/abs/2504.15280", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了All-Angles Bench，一个包含2100多个人工精心标注的多视角问答对的基准测试，用于全面评估多模态大型语言模型（MLLMs）在多视角场景理解中的挑战。通过六个任务测试模型的几何对应能力和跨视角信息一致对齐能力，实验表明当前MLLMs在部分遮挡视角的跨视角对应和粗略相机姿态估计方面表现不佳，远未达到人类水平。", "motivation": "解决多模态大型语言模型（MLLMs）在多视角理解中的挑战，特别是在几何一致性和跨视角对应方面的不足。", "method": "提出All-Angles Bench基准测试，包含2100多个人工标注的多视角问答对，覆盖90个多样化的真实场景，通过六个任务测试模型的性能。", "result": "实验结果显示，当前MLLMs在跨视角对应和相机姿态估计方面表现不佳，与人类水平存在显著差距。", "conclusion": "研究表明，MLLMs需要领域特定的改进或模块以增强多视角意识，All-Angles Bench为缩小MLLMs与人类多视角理解之间的差距提供了有价值的见解。"}}
{"id": "2504.14440", "title": "SG-Reg: Generalizable and Efficient Scene Graph Registration", "authors": ["Chuhao Liu", "Zhijian Qiao", "Jieqi Shi", "Ke Wang", "Peize Liu", "Shaojie Shen"], "abstract": "This paper addresses the challenges of registering two rigid semantic scene graphs, an essential capability when an autonomous agent needs to register its map against a remote agent, or against a prior map. The hand-crafted descriptors in classical semantic-aided registration, or the ground-truth annotation reliance in learning-based scene graph registration, impede their application in practical real-world environments. To address the challenges, we design a scene graph network to encode multiple modalities of semantic nodes: open-set semantic feature, local topology with spatial awareness, and shape feature. These modalities are fused to create compact semantic node features. The matching layers then search for correspondences in a coarse-to-fine manner. In the back-end, we employ a robust pose estimator to decide transformation according to the correspondences. We manage to maintain a sparse and hierarchical scene representation. Our approach demands fewer GPU resources and fewer communication bandwidth in multi-agent tasks. Moreover, we design a new data generation approach using vision foundation models and a semantic mapping module to reconstruct semantic scene graphs. It differs significantly from previous works, which rely on ground-truth semantic annotations to generate data. We validate our method in a two-agent SLAM benchmark. It significantly outperforms the hand-crafted baseline in terms of registration success rate. Compared to visual loop closure networks, our method achieves a slightly higher registration recall while requiring only 52 KB of communication bandwidth for each query frame. Code available at: \\href{", "subjects": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV)", "comments": "IEEE Transactions Robotics Regular Paper", "pdf_url": "https://arxiv.org/pdf/2504.14440.pdf", "abstract_url": "https://arxiv.org/abs/2504.14440", "categories": ["Robotics (cs.RO)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为SG-Reg的方法，用于解决两个刚性语义场景图的注册问题，该方法通过融合多种模态的语义节点特征，采用粗到细的匹配策略，并在后端使用鲁棒的姿态估计器来决定变换。该方法在减少GPU资源和通信带宽需求的同时，提高了注册成功率。", "motivation": "解决自主代理在需要将其地图与远程代理或先验地图注册时，传统方法依赖手工描述符或地面真实注释，难以在实际环境中应用的问题。", "method": "设计了一个场景图网络来编码语义节点的多种模态：开放集语义特征、具有空间意识的局部拓扑和形状特征，然后通过粗到细的匹配层寻找对应关系，后端使用鲁棒的姿态估计器决定变换。", "result": "在两代理SLAM基准测试中，该方法在注册成功率上显著优于手工制作的基线，与视觉闭环网络相比，注册召回率略高，同时每查询帧仅需52 KB的通信带宽。", "conclusion": "SG-Reg方法在保持稀疏和层次化场景表示的同时，实现了更高的注册成功率和更低的资源需求，为多代理任务提供了一种高效且通用的场景图注册解决方案。"}}
{"id": "2504.14112", "title": "Longitudinal Study on Social and Emotional Use of AI Conversational Agent", "authors": ["Mohit Chandra", "Javier Hernandez", "Gonzalo Ramos", "Mahsa Ershadi", "Ananya Bhattacharjee", "Judith Amores", "Ebele Okoli", "Ann Paradiso", "Shahed Warreth", "Jina Suh"], "abstract": "Development in digital technologies has continuously reshaped how individuals seek and receive social and emotional support. While online platforms and communities have long served this need, the increased integration of general-purpose conversational AI into daily lives has introduced new dynamics in how support is provided and experienced. Existing research has highlighted both benefits (e.g., wider access to well-being resources) and potential risks (e.g., over-reliance) of using AI for support seeking. In this five-week, exploratory study, we recruited 149 participants divided into two usage groups: a baseline usage group (BU, n=60) that used the internet and AI as usual, and an active usage group (AU, n=89) encouraged to use one of four commercially available AI tools (Microsoft Copilot, Google Gemini, PI AI, ChatGPT) for social and emotional interactions. Our analysis revealed significant increases in perceived attachment towards AI (32.99 percentage points), perceived AI empathy (25.8 p.p.), and motivation to use AI for entertainment (22.90 p.p.) among the AU group. We also observed that individual differences (e.g., gender identity, prior AI usage) influenced perceptions of AI empathy and attachment. Lastly, the AU group expressed higher comfort in seeking personal help, managing stress, obtaining social support, and talking about health with AI, indicating potential for broader emotional support while highlighting the need for safeguards against problematic usage. Overall, our exploratory findings underscore the importance of developing consumer-facing AI tools that support emotional well-being responsibly, while empowering users to understand the limitations of these tools.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "comments": "16 pages, 5 figures, 2 tables", "pdf_url": "https://arxiv.org/pdf/2504.14112.pdf", "abstract_url": "https://arxiv.org/abs/2504.14112", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)"], "matching_keywords": ["agent"], "AI": {"tldr": "本研究探讨了AI对话代理在社交和情感支持方面的使用，通过五周的探索性研究，发现积极使用AI工具的组别在感知依恋、AI同理心及娱乐动机上有显著提升，同时指出个体差异对AI感知的影响及潜在的情感支持潜力与风险。", "motivation": "随着数字技术的发展，AI对话代理在日常生活中的整合为寻求和接受社交及情感支持提供了新方式。本研究旨在探索AI在这方面的使用效果及其潜在影响。", "method": "研究招募了149名参与者，分为基线使用组和积极使用组，后者被鼓励使用四种商业AI工具进行社交和情感互动，通过五周的研究收集数据并进行分析。", "result": "积极使用组在感知AI依恋、同理心及娱乐使用动机上有显著提升，同时个体差异如性别身份和先前AI使用经验影响了这些感知。该组也表现出更高的寻求个人帮助、管理压力等舒适度。", "conclusion": "研究强调了开发支持情感健康的消费者AI工具的重要性，同时需确保用户理解这些工具的局限性，并采取防护措施避免问题使用。"}}
{"id": "2504.14259", "title": "Experience-based Refinement of Task Planning Knowledge in Autonomous Robots", "authors": ["Hadeel Jazzaa", "Thomas McCluskey", "David Peebles"], "abstract": "The requirement for autonomous robots to exhibit higher-level cognitive skills by planning and adapting in an ever-changing environment is indeed a great challenge for the AI community. Progress has been made in the automated planning community on refinement and repair of an agent's symbolic knowledge to do task planning in an incomplete or changing environmental model, but these advances up to now have not been transferred to real physical robots. This paper demonstrates how a physical robot can be capable of adapting its symbolic knowledge of the environment, by using experiences in robot action execution to drive knowledge refinement and hence to improve the success rate of the task plans the robot creates. To implement more robust planning systems, we propose a method for refining domain knowledge to improve the knowledge on which intelligent robot behavior is based. This architecture has been implemented and evaluated using a NAO robot. The refined knowledge leads to the future synthesis of task plans which demonstrate decreasing rates of failure over time as faulty knowledge is removed or adjusted.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.14259.pdf", "abstract_url": "https://arxiv.org/abs/2504.14259", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了自主机器人如何通过经验精炼任务规划知识，以适应不断变化的环境，提高任务计划的成功率。", "motivation": "自主机器人在不断变化的环境中展示高级认知技能，如规划和适应，是AI社区面临的一大挑战。虽然自动规划社区在代理的符号知识精炼和修复方面取得了进展，但这些进展尚未转移到真实的物理机器人上。", "method": "提出了一种方法，通过机器人行动执行的经验来驱动知识精炼，从而改进智能机器人行为所基于的知识。这一架构已在NAO机器人上实现并评估。", "result": "精炼后的知识导致未来合成的任务计划显示出随着时间的推移失败率逐渐降低，因为错误的知识被移除或调整。", "conclusion": "研究表明，物理机器人能够通过经验适应其环境的符号知识，从而提高任务计划的成功率，这对于实现更强大的规划系统具有重要意义。"}}
{"id": "2504.14411", "title": "Planet as a Brain: Towards Internet of AgentSites based on AIOS Server", "authors": ["Xiang Zhang", "Yongfeng Zhang"], "abstract": "The internet is undergoing a historical transformation from the \"Internet of Websites\" to the \"Internet of AgentSites.\" While traditional Websites served as the foundation for information hosting and dissemination, a new frontier is emerging where AgentSites serve as the hubs of the internet, where each AgentSite hosts one or more AI agents that receive tasks, address them, and deliver actionable solutions, marking a significant shift in the digital landscape and representing the next generation of online ecosystems. Under this vision, AIOS, the AI Agent Operating System, serves as the server for the development, deployment and execution of AI agents, which is a fundamental infrastructure for the Internet of Agentsites.", "subjects": "Networking and Internet Architecture (cs.NI); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.14411.pdf", "abstract_url": "https://arxiv.org/abs/2504.14411", "categories": ["Networking and Internet Architecture (cs.NI)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "互联网正经历从‘网站互联网’到‘代理站点互联网’的历史性转变，其中代理站点作为互联网的中心，每个代理站点托管一个或多个AI代理，接收任务、解决问题并提供可操作的解决方案。AIOS（AI代理操作系统）作为开发和执行AI代理的服务器，是代理站点互联网的基础设施。", "motivation": "解决传统网站在信息托管和传播方面的局限性，推动互联网向下一代在线生态系统发展，其中代理站点和AI代理成为核心。", "method": "提出AIOS作为AI代理的操作系统，支持AI代理的开发、部署和执行，作为代理站点互联网的基础设施。", "result": "互联网的转型将使得代理站点成为新的互联网中心，AI代理能够在这些站点上接收并解决任务，提供可操作的解决方案。", "conclusion": "代理站点互联网代表了互联网的未来发展方向，AIOS作为其基础设施，将支持AI代理的高效运行，推动数字景观的显著变化。"}}
{"id": "2504.14427", "title": "Optimizing SIA Development: A Case Study in User-Centered Design for Estuary, a Multimodal Socially Interactive Agent Framework", "authors": ["Spencer Lin", "Miru Jun", "Basem Rizk", "Karen Shieh", "Scott Fisher", "Sharon Mozgai"], "abstract": "This case study presents our user-centered design model for Socially Intelligent Agent (SIA) development frameworks through our experience developing Estuary, an open source multimodal framework for building low-latency real-time socially interactive agents. We leverage the Rapid Assessment Process (RAP) to collect the thoughts of leading researchers in the field of SIAs regarding the current state of the art for SIA development as well as their evaluation of how well Estuary may potentially address current research gaps. We achieve this through a series of end-user interviews conducted by a fellow researcher in the community. We hope that the findings of our work will not only assist the continued development of Estuary but also guide the development of other future frameworks and technologies for SIAs.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.14427.pdf", "abstract_url": "https://arxiv.org/abs/2504.14427", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过开发Estuary这一开源多模态社交互动代理框架的案例研究，提出了一种以用户为中心的设计模型，用于社交智能代理（SIA）开发框架的优化。", "motivation": "解决当前社交智能代理（SIA）开发框架在满足研究需求方面的不足，以及如何通过用户中心设计优化这些框架。", "method": "采用快速评估过程（RAP）收集领域内领先研究者对SIA开发现状的观点，以及他们对Estuary框架可能填补当前研究空白的评估，通过同行研究者的终端用户访谈实现。", "result": "研究发现不仅有助于Estuary的持续开发，也为未来SIA框架和技术的开发提供了指导。", "conclusion": "通过用户中心设计模型和快速评估过程，Estuary框架的开发经验为社交智能代理的未来发展提供了有价值的见解和方向。"}}
{"id": "2504.14493", "title": "FinSage: A Multi-aspect RAG System for Financial Filings Question Answering", "authors": ["Xinyu Wang", "Jijun Chi", "Zhenghan Tai", "Tung Sum Thomas Kwok", "Muzhi Li", "Zhuhong Li", "Hailin He", "Yuchen Hua", "Peng Lu", "Suyuchen Wang", "Yihong Wu", "Jerry Huang", "Ling Zhou"], "abstract": "Leveraging large language models in real-world settings often entails a need to utilize domain-specific data and tools in order to follow the complex regulations that need to be followed for acceptable use. Within financial sectors, modern enterprises increasingly rely on Retrieval-Augmented Generation (RAG) systems to address complex compliance requirements in financial document workflows. However, existing solutions struggle to account for the inherent heterogeneity of data (e.g., text, tables, diagrams) and evolving nature of regulatory standards used in financial filings, leading to compromised accuracy in critical information extraction. We propose the FinSage framework as a solution, utilizing a multi-aspect RAG framework tailored for regulatory compliance analysis in multi-modal financial documents. FinSage introduces three innovative components: (1) a multi-modal pre-processing pipeline that unifies diverse data formats and generates chunk-level metadata summaries, (2) a multi-path sparse-dense retrieval system augmented with query expansion (HyDE) and metadata-aware semantic search, and (3) a domain-specialized re-ranking module fine-tuned via Direct Preference Optimization (DPO) to prioritize compliance-critical content. Extensive experiments demonstrate that FinSage achieves an impressive recall of 92.51% on 75 expert-curated questions derived from surpasses the best baseline method on the FinanceBench question answering datasets by 24.06% in accuracy. Moreover, FinSage has been successfully deployed as financial question-answering agent in online meetings, where it has already served more than 1,200 people.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.14493.pdf", "abstract_url": "https://arxiv.org/abs/2504.14493", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "FinSage是一个针对财务文件问答的多方面RAG系统，旨在解决财务领域内复杂合规要求的问题。", "motivation": "现有解决方案难以处理财务文件中数据的异质性（如文本、表格、图表）和监管标准的不断变化，导致关键信息提取的准确性受损。", "method": "FinSage采用多模态预处理管道统一多样数据格式并生成块级元数据摘要，多路径稀疏-密集检索系统增强查询扩展和元数据感知语义搜索，以及通过直接偏好优化(DPO)微调的领域专业化重新排名模块。", "result": "在75个专家策划的问题上，FinSage实现了92.51%的召回率，在FinanceBench问答数据集上的准确率比最佳基线方法高出24.06%。", "conclusion": "FinSage不仅显著提高了财务文件问答的准确性和效率，而且已成功部署为在线会议中的财务问答代理，服务超过1,200人。"}}
{"id": "2504.14625", "title": "Towards Optimal Circuit Generation: Multi-Agent Collaboration Meets Collective Intelligence", "authors": ["Haiyan Qin", "Jiahao Feng", "Xiaotong Feng", "Wei W. Xing", "Wang Kang"], "abstract": "Large language models (LLMs) have transformed code generation, yet their application in hardware design produces gate counts 38\\%--1075\\% higher than human designs. We present CircuitMind, a multi-agent framework that achieves human-competitive efficiency through three key innovations: syntax locking (constraining generation to basic logic gates), retrieval-augmented generation (enabling knowledge-driven design), and dual-reward optimization (balancing correctness with efficiency). To evaluate our approach, we introduce TC-Bench, the first gate-level benchmark harnessing collective intelligence from the TuringComplete ecosystem -- a competitive circuit design platform with hundreds of thousands of players. Experiments show CircuitMind enables 55.6\\% of model implementations to match or exceed top-tier human experts in composite efficiency metrics. Most remarkably, our framework elevates the 14B Phi-4 model to outperform both GPT-4o mini and Gemini 2.0 Flash, achieving efficiency comparable to the top 25\\% of human experts without requiring specialized training. These innovations establish a new paradigm for hardware optimization where collaborative AI systems leverage collective human expertise to achieve optimal circuit designs. Our model, data, and code are open-source at", "subjects": "Hardware Architecture (cs.AR); Artificial Intelligence (cs.AI)", "comments": "9 pages, 6 figures", "pdf_url": "https://arxiv.org/pdf/2504.14625.pdf", "abstract_url": "https://arxiv.org/abs/2504.14625", "categories": ["Hardware Architecture (cs.AR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了CircuitMind，一个通过多智能体协作实现与人类竞争效率的硬件设计框架，其核心创新包括语法锁定、检索增强生成和双奖励优化。通过TC-Bench基准测试，证明了该框架能使55.6%的模型实现达到或超过顶级人类专家的效率。", "motivation": "解决大型语言模型在硬件设计中生成的电路门数远高于人类设计的问题。", "method": "采用多智能体框架CircuitMind，结合语法锁定、检索增强生成和双奖励优化三种创新方法。", "result": "CircuitMind框架使55.6%的模型实现达到或超过顶级人类专家的效率，特别是将14B Phi-4模型的性能提升至超过GPT-4o mini和Gemini 2.0 Flash，接近人类专家前25%的水平。", "conclusion": "CircuitMind为硬件优化设立了新范式，通过协作AI系统利用集体人类专业知识实现最优电路设计。"}}
{"id": "2504.14681", "title": "An LLM-enabled Multi-Agent Autonomous Mechatronics Design Framework", "authors": ["Zeyu Wang", "Frank P.-W. Lo", "Qian Chen", "Yongqi Zhang", "Chen Lin", "Xu Chen", "Zhenhua Yu", "Alexander J. Thompson", "Eric M. Yeatman", "Benny P. L. Lo"], "abstract": "Existing LLM-enabled multi-agent frameworks are predominantly limited to digital or simulated environments and confined to narrowly focused knowledge domain, constraining their applicability to complex engineering tasks that require the design of physical embodiment, cross-disciplinary integration, and constraint-aware reasoning. This work proposes a multi-agent autonomous mechatronics design framework, integrating expertise across mechanical design, optimization, electronics, and software engineering to autonomously generate functional prototypes with minimal direct human design input. Operating primarily through a language-driven workflow, the framework incorporates structured human feedback to ensure robust performance under real-world constraints. To validate its capabilities, the framework is applied to a real-world challenge involving autonomous water-quality monitoring and sampling, where traditional methods are labor-intensive and ecologically disruptive. Leveraging the proposed system, a fully functional autonomous vessel was developed with optimized propulsion, cost-effective electronics, and advanced control. The design process was carried out by specialized agents, including a high-level planning agent responsible for problem abstraction and dedicated agents for structural, electronics, control, and software development. This approach demonstrates the potential of LLM-based multi-agent systems to automate real-world engineering workflows and reduce reliance on extensive domain expertise.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": "Accepted by CVPR 2025 Workshop", "pdf_url": "https://arxiv.org/pdf/2504.14681.pdf", "abstract_url": "https://arxiv.org/abs/2504.14681", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于LLM的多Agent自主机电设计框架，旨在解决现有框架在物理实体设计、跨学科整合和约束感知推理方面的局限性，通过集成机械设计、优化、电子和软件工程等专业知识，自主生成功能原型，并在实际应用中验证了其有效性。", "motivation": "现有的基于LLM的多Agent框架主要局限于数字或模拟环境，且知识领域狭窄，难以应用于需要物理实体设计、跨学科整合和约束感知推理的复杂工程任务。", "method": "提出了一种多Agent自主机电设计框架，通过语言驱动的工作流程，整合跨学科专业知识，并融入结构化的人类反馈，以确保在现实世界约束下的鲁棒性能。", "result": "应用于自主水质监测和采样的实际挑战中，成功开发出功能齐全的自主船只，具有优化的推进系统、成本效益高的电子设备和先进的控制系统。", "conclusion": "展示了基于LLM的多Agent系统在自动化现实世界工程工作流程和减少对广泛领域专业知识依赖方面的潜力。"}}
{"id": "2504.14757", "title": "SWE-Synth: Synthesizing Verifiable Bug-Fix Data to Enable Large Language Models in Resolving Real-World Bugs", "authors": ["Minh V.T. Pham", "Huy N. Phan", "Hoang N. Phan", "Cuong Le Chi", "Tien N. Nguyen", "Nghi D. Q. Bui"], "abstract": "Large language models (LLMs) are transforming automated program repair (APR) through agent-based approaches that localize bugs, generate patches, and verify fixes. However, the lack of high-quality, scalable training datasets, especially those with verifiable outputs and intermediate reasoning traces-limits progress, particularly for open-source models. In this work, we present SWE-Synth, a framework for synthesizing realistic, verifiable, and process-aware bug-fix datasets at the repository level. SWE-Synth leverages LLM agents to simulate debugging workflows, producing not only bug-fix pairs but also test cases and structured repair trajectories. Compared to manually curated datasets, our method scales with minimal human effort while preserving contextual richness and correctness. Experiments show that models trained on SWE-Synth outperform those trained on real-world datasets by 2.3% on SWE-Bench Lite. Our results highlight the potential of synthetic, agent-generated data to advance the state of the art in APR and software engineering automation.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": "Work in progress", "pdf_url": "https://arxiv.org/pdf/2504.14757.pdf", "abstract_url": "https://arxiv.org/abs/2504.14757", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了SWE-Synth框架，该框架通过合成高质量、可验证的错误修复数据集来支持大型语言模型（LLMs）在自动程序修复（APR）中的应用。", "motivation": "当前缺乏高质量、可扩展的训练数据集，特别是那些包含可验证输出和中间推理轨迹的数据集，这限制了开源模型在自动程序修复领域的进展。", "method": "SWE-Synth利用LLM代理模拟调试工作流程，生成错误修复对、测试用例和结构化的修复轨迹，从而合成真实、可验证且过程感知的错误修复数据集。", "result": "实验表明，使用SWE-Synth训练的模型在SWE-Bench Lite上的表现优于使用真实世界数据集训练的模型，提高了2.3%。", "conclusion": "合成、代理生成的数据有潜力推动自动程序修复和软件工程自动化的技术进步。"}}
{"id": "2504.14779", "title": "Exploring Collaborative GenAI Agents in Synchronous Group Settings: Eliciting Team Perceptions and Design Considerations for the Future of Work", "authors": ["Janet G. Johnson", "Macarena Peralta", "Mansanjam Kaur", "Ruijie Sophia Huang", "Sheng Zhao", "Ruijia Guan", "Shwetha Rajaram", "Michael Nebeling"], "abstract": "While generative artificial intelligence (GenAI) is finding increased adoption in workplaces, current tools are primarily designed for individual use. Prior work established the potential for these tools to enhance personal creativity and productivity towards shared goals; however, we don't know yet how to best take into account the nuances of group work and team dynamics when deploying GenAI in work settings. In this paper, we investigate the potential of collaborative GenAI agents to augment teamwork in synchronous group settings through an exploratory study that engaged 25 professionals across 6 teams in speculative design workshops and individual follow-up interviews. Our workshops included a mixed reality provotype to simulate embodied collaborative GenAI agents capable of actively participating in group discussions. Our findings suggest that, if designed well, collaborative GenAI agents offer valuable opportunities to enhance team problem-solving by challenging groupthink, bridging communication gaps, and reducing social friction. However, teams' willingness to integrate GenAI agents depended on its perceived fit across a number of individual, team, and organizational factors. We outline the key design tensions around agent representation, social prominence, and engagement and highlight the opportunities spatial and immersive technologies could offer to modulate GenAI influence on team outcomes and strike a balance between augmentation and agency.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": "To be published in ACM Conference on Computer-Supported Cooperative Work and Social Computing (CSCW 2025). 33 pages, 11 figures, 1 table", "pdf_url": "https://arxiv.org/pdf/2504.14779.pdf", "abstract_url": "https://arxiv.org/abs/2504.14779", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了在同步团队环境中使用协作式生成人工智能（GenAI）代理的潜力，通过设计研讨会和后续访谈，研究了如何设计这些代理以增强团队解决问题的能力和团队动态。", "motivation": "当前生成人工智能工具主要为个人使用设计，缺乏对团队工作和团队动态的考虑，本文旨在探索如何在这些工具中融入团队协作的细微差别。", "method": "通过25名专业人士参与的6个团队的推测性设计研讨会和个别后续访谈，使用混合现实原型模拟能够积极参与团队讨论的具体化协作GenAI代理。", "result": "研究发现，设计良好的协作GenAI代理能够通过挑战群体思维、弥合沟通差距和减少社会摩擦来增强团队问题解决能力，但团队的接受度取决于其对个人、团队和组织因素的适应度。", "conclusion": "本文概述了围绕代理表示、社会突出性和参与度的关键设计张力，并强调了空间和沉浸式技术在调节GenAI对团队结果影响方面的潜力，以实现增强和代理之间的平衡。"}}
{"id": "2504.15099", "title": "Fast-Slow Co-advancing Optimizer: Toward Harmonious Adversarial Training of GAN", "authors": ["Lin Wang", "Xiancheng Wang", "Rui Wang", "Zhibo Zhang", "Minghang Zhao"], "abstract": "Up to now, the training processes of typical Generative Adversarial Networks (GANs) are still particularly sensitive to data properties and hyperparameters, which may lead to severe oscillations, difficulties in convergence, or even failures to converge, especially when the overall variances of the training sets are large. These phenomena are often attributed to the training characteristics of such networks. Aiming at the problem, this paper develops a new intelligent optimizer, Fast-Slow Co-advancing Optimizer (FSCO), which employs reinforcement learning in the training process of GANs to make training easier. Specifically, this paper allows the training step size to be controlled by an agent to improve training stability, and makes the training process more intelligent with variable learning rates, making GANs less sensitive to step size. Experiments have been conducted on three benchmark datasets to verify the effectiveness of the developed FSCO.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.15099.pdf", "abstract_url": "https://arxiv.org/abs/2504.15099", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为快速-慢速协同推进优化器（FSCO）的新型智能优化器，旨在通过强化学习在GANs训练过程中的应用，改善训练稳定性并减少对步长的敏感性。", "motivation": "典型的生成对抗网络（GANs）训练过程对数据属性和超参数特别敏感，可能导致严重的振荡、收敛困难甚至无法收敛，尤其是在训练集的总体方差较大时。这些问题通常归因于此类网络的训练特性。", "method": "本文开发了一种新的智能优化器FSCO，它利用强化学习在GANs的训练过程中控制训练步长，以提高训练稳定性，并通过可变学习率使训练过程更加智能化。", "result": "在三个基准数据集上进行的实验验证了所开发的FSCO的有效性。", "conclusion": "FSCO通过智能控制训练步长和采用可变学习率，显著提高了GANs的训练稳定性和对步长的不敏感性，为解决GANs训练中的问题提供了新的思路。"}}
{"id": "2504.15130", "title": "Neural ATTF: A Scalable Solution to Lifelong Multi-Agent Path Planning", "authors": ["Kushal Shah", "Jihyun Park", "Seung-Kyum Choi"], "abstract": "Multi-Agent Pickup and Delivery (MAPD) is a fundamental problem in robotics, particularly in applications such as warehouse automation and logistics. Existing solutions often face challenges in scalability, adaptability, and efficiency, limiting their applicability in dynamic environments with real-time planning requirements. This paper presents Neural ATTF (Adaptive Task Token Framework), a new algorithm that combines a Priority Guided Task Matching (PGTM) Module with Neural STA* (Space-Time A*), a data-driven path planning method. Neural STA* enhances path planning by enabling rapid exploration of the search space through guided learned heuristics and ensures collision avoidance under dynamic constraints. PGTM prioritizes delayed agents and dynamically assigns tasks by prioritizing agents nearest to these tasks, optimizing both continuity and system throughput. Experimental evaluations against state-of-the-art MAPD algorithms, including TPTS, CENTRAL, RMCA, LNS-PBS, and LNS-wPBS, demonstrate the superior scalability, solution quality, and computational efficiency of Neural ATTF. These results highlight the framework's potential for addressing the critical demands of complex, real-world multi-agent systems operating in high-demand, unpredictable settings.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": "13 Pages, 5 Figures, 5 Tables", "pdf_url": "https://arxiv.org/pdf/2504.15130.pdf", "abstract_url": "https://arxiv.org/abs/2504.15130", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为Neural ATTF的新算法，结合了优先级引导任务匹配模块和神经STA*路径规划方法，以解决多智能体拾取和交付问题中的可扩展性、适应性和效率挑战。", "motivation": "解决多智能体拾取和交付（MAPD）问题在动态环境中实时规划的可扩展性、适应性和效率限制。", "method": "结合优先级引导任务匹配（PGTM）模块和神经STA*（空间时间A*）路径规划方法，利用学习到的启发式快速探索搜索空间并确保动态约束下的碰撞避免。", "result": "与现有MAPD算法相比，Neural ATTF在可扩展性、解决方案质量和计算效率方面表现出优越性。", "conclusion": "Neural ATTF框架有潜力满足复杂、高需求、不可预测环境中多智能体系统的关键需求。"}}
