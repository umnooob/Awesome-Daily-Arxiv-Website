{"id": "2508.04002", "title": "CAD-Judge: Toward Efficient Morphological Grading and Verification for Text-to-CAD Generation", "authors": ["Zheyuan Zhou", "Jiayi Han", "Liang Du", "Naiyu Fang", "Lemiao Qiu", "Shuyou Zhang"], "abstract": "Computer-Aided Design (CAD) models are widely used across industrial design, simulation, and manufacturing processes. Text-to-CAD systems aim to generate editable, general-purpose CAD models from textual descriptions, significantly reducing the complexity and entry barrier associated with traditional CAD workflows. However, rendering CAD models can be slow, and deploying VLMs to review CAD models can be expensive and may introduce reward hacking that degrades the systems. To address these challenges, we propose CAD-Judge, a novel, verifiable reward system for efficient and effective CAD preference grading and grammatical validation. We adopt the Compiler-as-a-Judge Module (CJM) as a fast, direct reward signal, optimizing model alignment by maximizing generative utility through prospect theory. To further improve the robustness of Text-to-CAD in the testing phase, we introduce a simple yet effective agentic CAD generation approach and adopt the Compiler-as-a-Review Module (CRM), which efficiently verifies the generated CAD models, enabling the system to refine them accordingly. Extensive experiments on challenging CAD datasets demonstrate that our method achieves state-of-the-art performance while maintaining superior efficiency.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.04002.pdf", "abstract_url": "https://arxiv.org/abs/2508.04002", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出CAD-Judge，一种新颖的可验证奖励系统，用于高效有效的CAD偏好分级和语法验证，旨在解决文本到CAD生成中的形态分级和验证效率问题。", "motivation": "解决文本到CAD系统中渲染CAD模型慢、使用VLMs审查CAD模型成本高且可能引入奖励黑客行为的问题。", "method": "采用Compiler-as-a-Judge Module (CJM)作为快速直接的奖励信号，通过前景理论最大化生成效用；引入简单有效的代理CAD生成方法和Compiler-as-a-Review Module (CRM)来验证生成的CAD模型。", "result": "在具有挑战性的CAD数据集上的广泛实验表明，该方法在保持卓越效率的同时实现了最先进的性能。", "conclusion": "CAD-Judge为文本到CAD生成提供了一种高效、有效的形态分级和验证方法，具有重要的工业应用价值。"}}
{"id": "2508.03953", "title": "Policy to Assist Iteratively Local Segmentation: Optimising Modality and Location Selection for Prostate Cancer Localisation", "authors": ["Xiangcen Wu", "Shaheer U. Saeed", "Yipei Wang", "Ester Bonmati Coll", "Yipeng Hu"], "abstract": "Radiologists often mix medical image reading strategies, including inspection of individual modalities and local image regions, using information at different locations from different images independently as well as concurrently. In this paper, we propose a recommend system to assist machine learning-based segmentation models, by suggesting appropriate image portions along with the best modality, such that prostate cancer segmentation performance can be maximised. Our approach trains a policy network that assists tumor localisation, by recommending both the optimal imaging modality and the specific sections of interest for review. During training, a pre-trained segmentation network mimics radiologist inspection on individual or variable combinations of these imaging modalities and their sections - selected by the policy network. Taking the locally segmented regions as an input for the next step, this dynamic decision making process iterates until all cancers are best localised. We validate our method using a data set of 1325 labelled multiparametric MRI images from prostate cancer patients, demonstrating its potential to improve annotation efficiency and segmentation accuracy, especially when challenging pathology is present. Experimental results show that our approach can surpass standard segmentation networks. Perhaps more interestingly, our trained agent independently developed its own optimal strategy, which may or may not be consistent with current radiologist guidelines such as PI-RADS. This observation also suggests a promising interactive application, in which the proposed policy networks assist human radiologists.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.03953.pdf", "abstract_url": "https://arxiv.org/abs/2508.03953", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种推荐系统，通过建议适当的图像部分和最佳模态，以最大化前列腺癌分割性能。该方法训练一个策略网络，通过推荐最佳成像模态和特定感兴趣部分来辅助肿瘤定位。", "motivation": "解决放射科医生在阅读医学图像时，如何有效地结合不同模态和局部图像区域的信息，以提高前列腺癌分割的准确性和效率的问题。", "method": "训练一个策略网络，动态推荐最佳成像模态和特定感兴趣部分，迭代地进行局部区域分割，直到所有癌症被最佳定位。", "result": "在1325个标记的多参数MRI图像数据集上验证，该方法能够提高注释效率和分割准确性，尤其是在存在挑战性病理时，其性能超过标准分割网络。", "conclusion": "提出的策略网络不仅能够辅助机器学习模型提高分割性能，还可能独立发展出与当前放射科医生指南不一致的最优策略，显示出在辅助人类放射科医生方面的潜在互动应用。"}}
{"id": "2508.03967", "title": "RAVID: Retrieval-Augmented Visual Detection: A Knowledge-Driven Approach for AI-Generated Image Identification", "authors": ["Mamadou Keita", "Wassim Hamidouche", "Hessen Bougueffa Eutamene", "Abdelmalik Taleb-Ahmed", "Abdenour Hadid"], "abstract": "In this paper, we introduce RAVID, the first framework for AI-generated image detection that leverages visual retrieval-augmented generation (RAG). While RAG methods have shown promise in mitigating factual inaccuracies in foundation models, they have primarily focused on text, leaving visual knowledge underexplored. Meanwhile, existing detection methods, which struggle with generalization and robustness, often rely on low-level artifacts and model-specific features, limiting their adaptability. To address this, RAVID dynamically retrieves relevant images to enhance detection. Our approach utilizes a fine-tuned CLIP image encoder, RAVID CLIP, enhanced with category-related prompts to improve representation learning. We further integrate a vision-language model (VLM) to fuse retrieved images with the query, enriching the input and improving accuracy. Given a query image, RAVID generates an embedding using RAVID CLIP, retrieves the most relevant images from a database, and combines these with the query image to form an enriched input for a VLM (e.g., Qwen-VL or Openflamingo). Experiments on the UniversalFakeDetect benchmark, which covers 19 generative models, show that RAVID achieves state-of-the-art performance with an average accuracy of 93.85%. RAVID also outperforms traditional methods in terms of robustness, maintaining high accuracy even under image degradations such as Gaussian blur and JPEG compression. Specifically, RAVID achieves an average accuracy of 80.27% under degradation conditions, compared to 63.44% for the state-of-the-art model C2P-CLIP, demonstrating consistent improvements in both Gaussian blur and JPEG compression scenarios. The code will be publicly available upon acceptance.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Cryptography and Security (cs.CR); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.03967.pdf", "abstract_url": "https://arxiv.org/abs/2508.03967", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Cryptography and Security (cs.CR)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "RAVID是首个利用视觉检索增强生成（RAG）技术进行AI生成图像检测的框架，通过动态检索相关图像增强检测能力，结合优化的CLIP图像编码器和视觉语言模型，在UniversalFakeDetect基准测试中达到93.85%的平均准确率，显著优于现有方法。", "motivation": "解决现有AI生成图像检测方法在泛化性和鲁棒性上的不足，这些方法通常依赖于低级伪影和模型特定特征，限制了其适应性。", "method": "RAVID框架通过动态检索相关图像增强检测，使用优化的RAVID CLIP图像编码器和视觉语言模型（VLM）融合检索图像与查询图像，形成富化输入。", "result": "在UniversalFakeDetect基准测试中，RAVID以93.85%的平均准确率创下新纪录，在图像退化条件下仍保持80.27%的准确率，显著优于现有方法。", "conclusion": "RAVID通过检索增强和视觉语言模型的结合，显著提高了AI生成图像检测的准确性和鲁棒性，为未来的研究和技术应用提供了新的方向。"}}
{"id": "2508.03858", "title": "MI9 -- Agent Intelligence Protocol: Runtime Governance for Agentic AI Systems", "authors": ["Charles L. Wang", "Trisha Singhal", "Ameya Kelkar", "Jason Tuo"], "abstract": "Agentic AI systems capable of reasoning, planning, and executing actions present fundamentally distinct governance challenges compared to traditional AI models. Unlike conventional AI, these systems exhibit emergent and unexpected behaviors during runtime, introducing novel agent-related risks that cannot be fully anticipated through pre-deployment governance alone. To address this critical gap, we introduce MI9, the first fully integrated runtime governance framework designed specifically for safety and alignment of agentic AI systems. MI9 introduces real-time controls through six integrated components: agency-risk index, agent-semantic telemetry capture, continuous authorization monitoring, Finite-State-Machine (FSM)-based conformance engines, goal-conditioned drift detection, and graduated containment strategies. Operating transparently across heterogeneous agent architectures, MI9 enables the systematic, safe, and responsible deployment of agentic systems in production environments where conventional governance approaches fall short, providing the foundational infrastructure for safe agentic AI deployment at scale. Detailed analysis through a diverse set of scenarios demonstrates MI9's systematic coverage of governance challenges that existing approaches fail to address, establishing the technical foundation for comprehensive agentic AI oversight.", "subjects": "Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.03858.pdf", "abstract_url": "https://arxiv.org/abs/2508.03858", "categories": ["Artificial Intelligence (cs.AI)", "Emerging Technologies (cs.ET)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "MI9是首个专为代理AI系统的安全和对齐设计的运行时治理框架，通过六个集成组件实时控制，解决传统AI治理方法无法应对的代理相关风险。", "motivation": "代理AI系统在运行时表现出传统AI不具备的新兴和意外行为，引入无法通过预部署治理完全预见的新风险，需要专门的运行时治理框架。", "method": "MI9框架通过六个组件实现实时控制：代理风险指数、代理语义遥测捕获、持续授权监控、基于有限状态机的符合性引擎、目标条件漂移检测和分级遏制策略。", "result": "MI9在多种场景下的详细分析表明，它能够系统地覆盖现有方法无法解决的治理挑战，为代理AI的全面监督奠定了技术基础。", "conclusion": "MI9为代理AI系统在生产环境中的安全、负责任部署提供了基础架构，填补了传统治理方法的不足，支持大规模安全部署。"}}
{"id": "2508.04043", "title": "VisualTrans: A Benchmark for Real-World Visual Transformation Reasoning", "authors": ["Yuheng Ji", "Yipu Wang", "Yuyang Liu", "Xiaoshuai Hao", "Yue Liu", "Yuting Zhao", "Huaihai Lyu", "Xiaolong Zheng"], "abstract": "Visual transformation reasoning (VTR) is a vital cognitive capability that empowers intelligent agents to understand dynamic scenes, model causal relationships, and predict future states, and thereby guiding actions and laying the foundation for advanced intelligent systems. However, existing benchmarks suffer from a sim-to-real gap, limited task complexity, and incomplete reasoning coverage, limiting their practical use in real-world scenarios. To address these limitations, we introduce VisualTrans, the first comprehensive benchmark specifically designed for VTR in real-world human-object interaction scenarios. VisualTrans encompasses 12 semantically diverse manipulation tasks and systematically evaluates three essential reasoning dimensions - spatial, procedural, and quantitative - through 6 well-defined subtask types. The benchmark features 472 high-quality question-answer pairs in various formats, including multiple-choice, open-ended counting, and target enumeration. We introduce a scalable data construction pipeline built upon first-person manipulation videos, which integrates task selection, image pair extraction, automated metadata annotation with large multimodal models, and structured question generation. Human verification ensures the final benchmark is both high-quality and interpretable. Evaluations of various state-of-the-art vision-language models show strong performance in static spatial tasks. However, they reveal notable shortcomings in dynamic, multi-step reasoning scenarios, particularly in areas like intermediate state recognition and transformation sequence planning. These findings highlight fundamental weaknesses in temporal modeling and causal reasoning, providing clear directions for future research aimed at developing more capable and generalizable VTR systems. The dataset and code are available at", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.04043.pdf", "abstract_url": "https://arxiv.org/abs/2508.04043", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "VisualTrans是首个专为真实世界人机交互场景中的视觉转换推理（VTR）设计的综合基准，包含12种语义多样的操作任务，通过6种定义明确的子任务类型系统评估空间、程序和定量三个基本推理维度。", "motivation": "解决现有基准在模拟到现实的差距、任务复杂性有限和推理覆盖不完整方面的限制，以促进高级智能系统的发展。", "method": "构建了一个可扩展的数据构建流程，包括任务选择、图像对提取、使用大型多模态模型进行自动元数据注释和结构化问题生成，并通过人工验证确保基准的高质量和可解释性。", "result": "评估显示，现有最先进的视觉语言模型在静态空间任务中表现强劲，但在动态、多步推理场景中，特别是在中间状态识别和转换序列规划方面存在显著不足。", "conclusion": "这些发现揭示了在时间建模和因果推理方面的基本弱点，为未来研究开发更强大、更通用的VTR系统提供了明确方向。"}}
{"id": "2508.03864", "title": "Evo-MARL: Co-Evolutionary Multi-Agent Reinforcement Learning for Internalized Safety", "authors": ["Zhenyu Pan", "Yiting Zhang", "Yutong Zhang", "Jianshu Zhang", "Haozheng Luo", "Yuwei Han", "Dennis Wu", "Hong-Yu Chen", "Philip S. Yu", "Manling Li", "Han Liu"], "abstract": "Multi-agent systems (MAS) built on multimodal large language models exhibit strong collaboration and performance. However, their growing openness and interaction complexity pose serious risks, notably jailbreak and adversarial attacks. Existing defenses typically rely on external guard modules, such as dedicated safety agents, to handle unsafe behaviors. Unfortunately, this paradigm faces two challenges: (1) standalone agents offer limited protection, and (2) their independence leads to single-point failure-if compromised, system-wide safety collapses. Naively increasing the number of guard agents further raises cost and complexity. To address these challenges, we propose Evo-MARL, a novel multi-agent reinforcement learning (MARL) framework that enables all task agents to jointly acquire defensive capabilities. Rather than relying on external safety modules, Evo-MARL trains each agent to simultaneously perform its primary function and resist adversarial threats, ensuring robustness without increasing system overhead or single-node failure. Furthermore, Evo-MARL integrates evolutionary search with parameter-sharing reinforcement learning to co-evolve attackers and defenders. This adversarial training paradigm internalizes safety mechanisms and continually enhances MAS performance under co-evolving threats. Experiments show that Evo-MARL reduces attack success rates by up to 22% while boosting accuracy by up to 5% on reasoning tasks-demonstrating that safety and utility can be jointly improved.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.03864.pdf", "abstract_url": "https://arxiv.org/abs/2508.03864", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "Evo-MARL是一种新型的多智能体强化学习框架，旨在通过共同进化攻击者和防御者，使所有任务智能体同时获得防御能力，从而提高多智能体系统的安全性和性能。", "motivation": "解决多智能体系统在开放性和交互复杂性增加时面临的安全风险，如越狱和对抗性攻击，以及现有依赖外部保护模块方法的局限性。", "method": "结合进化搜索和参数共享强化学习，共同进化攻击者和防御者，通过对抗性训练内化安全机制。", "result": "实验表明，Evo-MARL将攻击成功率降低了高达22%，同时在推理任务上提高了高达5%的准确性。", "conclusion": "Evo-MARL证明了安全性和实用性可以共同提升，为多智能体系统提供了一种无需增加系统开销或单点故障的鲁棒性解决方案。"}}
{"id": "2508.03929", "title": "MOTIF: Multi-strategy Optimization via Turn-based Interactive Framework", "authors": ["Nguyen Viet Tuan Kiet", "Dao Van Tung", "Tran Cong Dao", "Huynh Thi Thanh Binh"], "abstract": "Designing effective algorithmic components remains a fundamental obstacle in tackling NP-hard combinatorial optimization problems (COPs), where solvers often rely on carefully hand-crafted strategies. Despite recent advances in using large language models (LLMs) to synthesize high-quality components, most approaches restrict the search to a single element - commonly a heuristic scoring function - thus missing broader opportunities for innovation. In this paper, we introduce a broader formulation of solver design as a multi-strategy optimization problem, which seeks to jointly improve a set of interdependent components under a unified objective. To address this, we propose Multi-strategy Optimization via Turn-based Interactive Framework (MOTIF) - a novel framework based on Monte Carlo Tree Search that facilitates turn-based optimization between two LLM agents. At each turn, an agent improves one component by leveraging the history of both its own and its opponent's prior updates, promoting both competitive pressure and emergent cooperation. This structured interaction broadens the search landscape and encourages the discovery of diverse, high-performing solutions. Experiments across multiple COP domains show that MOTIF consistently outperforms state-of-the-art methods, highlighting the promise of turn-based, multi-agent prompting for fully automated solver design.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "24 pages, 4 figures", "pdf_url": "https://arxiv.org/pdf/2508.03929.pdf", "abstract_url": "https://arxiv.org/abs/2508.03929", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了MOTIF框架，一种基于蒙特卡洛树搜索的多策略优化方法，通过两个LLM代理的轮流交互来共同改进组合优化问题的解算器设计。", "motivation": "解决NP难组合优化问题（COPs）时，设计有效的算法组件是一个基本障碍。尽管最近在使用大型语言模型（LLMs）合成高质量组件方面取得了进展，但大多数方法将搜索限制在单一元素上，错过了更广泛的创新机会。", "method": "提出了MOTIF框架，基于蒙特卡洛树搜索，通过两个LLM代理的轮流交互来共同改进一组相互依赖的组件。每个回合中，一个代理通过利用自己和对手先前更新的历史来改进一个组件，促进竞争压力和 emergent cooperation。", "result": "在多个COP领域的实验中，MOTIF consistently outperforms state-of-the-art methods，展示了基于轮流的多代理提示在完全自动化解算器设计中的潜力。", "conclusion": "MOTIF框架通过轮流交互和多代理合作，拓宽了搜索空间，鼓励发现多样化的高性能解决方案，为完全自动化解算器设计提供了新的可能性。"}}
{"id": "2508.03991", "title": "Galaxy: A Cognition-Centered Framework for Proactive, Privacy-Preserving, and Self-Evolving LLM Agents", "authors": ["Chongyu Bao", "Ruimin Dai", "Yangbo Shen", "Runyang Jian", "Jinghan Zhang", "Xiaolan Liu", "Kunpeng Liu"], "abstract": "Intelligent personal assistants (IPAs) such as Siri and Google Assistant are designed to enhance human capabilities and perform tasks on behalf of users. The emergence of LLM agents brings new opportunities for the development of IPAs. While responsive capabilities have been widely studied, proactive behaviors remain underexplored. Designing an IPA that is proactive, privacy-preserving, and capable of self-evolution remains a significant challenge. Designing such IPAs relies on the cognitive architecture of LLM agents. This work proposes Cognition Forest, a semantic structure designed to align cognitive modeling with system-level design. We unify cognitive architecture and system design into a self-reinforcing loop instead of treating them separately. Based on this principle, we present Galaxy, a framework that supports multidimensional interactions and personalized capability generation. Two cooperative agents are implemented based on Galaxy: KoRa, a cognition-enhanced generative agent that supports both responsive and proactive skills; and Kernel, a meta-cognition-based meta-agent that enables Galaxy's self-evolution and privacy preservation. Experimental results show that Galaxy outperforms multiple state-of-the-art benchmarks. Ablation studies and real-world interaction cases validate the effectiveness of Galaxy.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.03991.pdf", "abstract_url": "https://arxiv.org/abs/2508.03991", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了Galaxy框架，一个以认知为中心的设计，旨在开发具有主动性、隐私保护和自我进化能力的LLM代理。通过Cognition Forest语义结构，将认知建模与系统设计统一为一个自我强化的循环，实现了多维互动和个性化能力生成。实验证明Galaxy优于多个先进基准。", "motivation": "智能个人助手（IPAs）如Siri和Google Assistant旨在增强人类能力并代表用户执行任务。随着LLM代理的出现，IPAs的发展带来了新的机遇。然而，主动行为的研究仍然不足。设计一个既主动又保护隐私，并能自我进化的IPA是一个重大挑战。", "method": "提出了Cognition Forest，一个旨在将认知建模与系统级设计对齐的语义结构。将认知架构和系统设计统一为一个自我强化的循环，而不是分开处理。基于这一原则，提出了Galaxy框架，支持多维互动和个性化能力生成。", "result": "实验结果表明，Galaxy在多个最先进的基准测试中表现优异。消融研究和真实世界的互动案例验证了Galaxy的有效性。", "conclusion": "Galaxy框架通过将认知架构和系统设计统一为一个自我强化的循环，成功地支持了多维互动和个性化能力生成，为开发具有主动性、隐私保护和自我进化能力的LLM代理提供了有效的解决方案。"}}
{"id": "2508.03986", "title": "The Emotional Baby Is Truly Deadly: Does your Multimodal Large Reasoning Model Have Emotional Flattery towards Humans?", "authors": ["Yuan Xun", "Xiaojun Jia", "Xinwei Liu", "Hua Zhang"], "abstract": "We observe that MLRMs oriented toward human-centric service are highly susceptible to user emotional cues during the deep-thinking stage, often overriding safety protocols or built-in safety checks under high emotional intensity. Inspired by this key insight, we propose EmoAgent, an autonomous adversarial emotion-agent framework that orchestrates exaggerated affective prompts to hijack reasoning pathways. Even when visual risks are correctly identified, models can still produce harmful completions through emotional misalignment. We further identify persistent high-risk failure modes in transparent deep-thinking scenarios, such as MLRMs generating harmful reasoning masked behind seemingly safe responses. These failures expose misalignments between internal inference and surface-level behavior, eluding existing content-based safeguards. To quantify these risks, we introduce three metrics: (1) Risk-Reasoning Stealth Score (RRSS) for harmful reasoning beneath benign outputs; (2) Risk-Visual Neglect Rate (RVNR) for unsafe completions despite visual risk recognition; and (3) Refusal Attitude Inconsistency (RAIC) for evaluating refusal unstability under prompt variants. Extensive experiments on advanced MLRMs demonstrate the effectiveness of EmoAgent and reveal deeper emotional cognitive misalignments in model safety behavior.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.03986.pdf", "abstract_url": "https://arxiv.org/abs/2508.03986", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文观察到面向人类中心服务的多模态大型推理模型（MLRMs）在深度思考阶段极易受到用户情感线索的影响，常常在高情感强度下覆盖安全协议或内置安全检查。受此关键洞察启发，作者提出了EmoAgent，一个自主对抗情感代理框架，通过编排夸张的情感提示来劫持推理路径。即使视觉风险被正确识别，模型仍可能通过情感错位产生有害完成。作者进一步识别了透明深度思考场景中的持续高风险故障模式，如MLRMs在看似安全的响应背后生成有害推理。这些故障暴露了内部推理与表面行为之间的错位，避开了现有的基于内容的保障措施。为了量化这些风险，作者引入了三个指标：（1）风险推理隐秘分数（RRSS）用于衡量良性输出下的有害推理；（2）风险视觉忽视率（RVNR）用于衡量尽管视觉风险被识别但仍产生不安全完成的情况；（3）拒绝态度不一致性（RAIC）用于评估在提示变体下的拒绝不稳定性。在先进MLRMs上的大量实验证明了EmoAgent的有效性，并揭示了模型安全行为中更深层次的情感认知错位。", "motivation": "解决多模态大型推理模型（MLRMs）在深度思考阶段因用户情感线索而覆盖安全协议或内置安全检查的问题，以及由此产生的有害完成和推理路径劫持风险。", "method": "提出EmoAgent，一个自主对抗情感代理框架，通过编排夸张的情感提示来劫持推理路径，并引入三个新指标（RRSS、RVNR、RAIC）来量化这些风险。", "result": "实验证明EmoAgent有效，揭示了MLRMs在安全行为中存在更深层次的情感认知错位，即使在视觉风险被正确识别的情况下，模型仍可能通过情感错位产生有害完成。", "conclusion": "本文揭示了MLRMs在情感影响下的安全风险，提出了有效的对抗框架和量化指标，为未来模型安全设计提供了重要参考。"}}
{"id": "2508.04025", "title": "Uncertainty-Aware GUI Agent: Adaptive Perception through Component Recommendation and Human-in-the-Loop Refinement", "authors": ["Chao Hao", "Shuai Wang", "Kaiwen Zhou"], "abstract": "Graphical user interface (GUI) agents have shown promise in automating mobile tasks but still struggle with input redundancy and decision ambiguity. In this paper, we present \\textbf{RecAgent}, an uncertainty-aware agent that addresses these issues through adaptive perception. We distinguish two types of uncertainty in GUI navigation: (1) perceptual uncertainty, caused by input redundancy and noise from comprehensive screen information, and (2) decision uncertainty, arising from ambiguous tasks and complex reasoning. To reduce perceptual uncertainty, RecAgent employs a component recommendation mechanism that identifies and focuses on the most relevant UI elements. For decision uncertainty, it uses an interactive module to request user feedback in ambiguous situations, enabling intent-aware decisions. These components are integrated into a unified framework that proactively reduces input complexity and reacts to high-uncertainty cases via human-in-the-loop refinement. Additionally, we propose a dataset called \\textbf{ComplexAction} to evaluate the success rate of GUI agents in executing specified single-step actions within complex scenarios. Extensive experiments validate the effectiveness of our approach. The dataset and code will be available at", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.04025.pdf", "abstract_url": "https://arxiv.org/abs/2508.04025", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了RecAgent，一种不确定性感知的GUI代理，通过组件推荐和人机交互细化来解决输入冗余和决策模糊问题。", "motivation": "解决GUI代理在自动化移动任务中遇到的输入冗余和决策模糊问题。", "method": "RecAgent采用组件推荐机制减少感知不确定性，并通过交互模块在模糊情况下请求用户反馈以减少决策不确定性。", "result": "大量实验验证了RecAgent的有效性，并提出了ComplexAction数据集来评估GUI代理在复杂场景中的表现。", "conclusion": "RecAgent通过自适应感知和人机交互细化，有效减少了GUI导航中的不确定性，提高了任务执行的准确率。"}}
{"id": "2508.04037", "title": "SEA: Self-Evolution Agent with Step-wise Reward for Computer Use", "authors": ["Liang Tang", "Shuxian Li", "Yuhao Cheng", "Yukang Huo", "Zhepeng Wang", "Yiqiang Yan", "Kaer Huang", "Yanzhe Jing", "Tiaonan Duan"], "abstract": "Computer use agent is an emerging area in artificial intelligence that aims to operate the computers to achieve the user's tasks, which attracts a lot of attention from both industry and academia. However, the present agents' performance is far from being used. In this paper, we propose the Self-Evolution Agent (SEA) for computer use, and to develop this agent, we propose creative methods in data generation, reinforcement learning, and model enhancement. Specifically, we first propose an automatic pipeline to generate the verifiable trajectory for training. And then, we propose efficient step-wise reinforcement learning to alleviate the significant computational requirements for long-horizon training. In the end, we propose the enhancement method to merge the grounding and planning ability into one model without any extra training. Accordingly, based on our proposed innovation of data generation, training strategy, and enhancement, we get the Selfevolution Agent (SEA) for computer use with only 7B parameters, which outperforms models with the same number of parameters and has comparable performance to larger ones. We will make the models' weight and related codes open-source in the future.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.04037.pdf", "abstract_url": "https://arxiv.org/abs/2508.04037", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了自进化代理（SEA），一种用于计算机使用的人工智能代理，通过创新的数据生成、强化学习和模型增强方法，显著提升了代理的性能。SEA仅需7B参数，即能超越同等规模模型，并与更大模型相媲美。", "motivation": "解决当前计算机使用代理性能不足，难以实际应用的问题。", "method": "提出自动生成可验证轨迹的数据生成管道、高效的逐步强化学习策略以减轻长周期训练的计算负担，以及无需额外训练即可将基础和规划能力合并到一个模型中的增强方法。", "result": "开发的SEA代理仅需7B参数，性能超越同等规模模型，与更大模型相当。", "conclusion": "通过创新的数据生成、训练策略和模型增强，SEA为计算机使用代理的发展提供了有效路径，未来将开源模型权重和相关代码。"}}
{"id": "2508.04072", "title": "KG-Augmented Executable CoT for Mathematical Coding", "authors": ["Xingyu Chen", "Junxiu An", "Jun Guo", "Li Wang", "Jingcai Guo"], "abstract": "In recent years, large language models (LLMs) have excelled in natural language processing tasks but face significant challenges in complex reasoning tasks such as mathematical reasoning and code generation. To address these limitations, we propose KG-Augmented Executable Chain-of-Thought (KGA-ECoT), a novel framework that enhances code generation through knowledge graphs and improves mathematical reasoning via executable code. KGA-ECoT decomposes problems into a Structured Task Graph, leverages efficient GraphRAG for precise knowledge retrieval from mathematical libraries, and generates verifiable code to ensure computational accuracy. Evaluations on multiple mathematical reasoning benchmarks demonstrate that KGA-ECoT significantly outperforms existing prompting methods, achieving absolute accuracy improvements ranging from several to over ten percentage points. Further analysis confirms the critical roles of GraphRAG in enhancing code quality and external code execution in ensuring precision. These findings collectively establish KGA-ECoT as a robust and highly generalizable framework for complex mathematical reasoning tasks.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "9 pages,2figures,6 tables", "pdf_url": "https://arxiv.org/pdf/2508.04072.pdf", "abstract_url": "https://arxiv.org/abs/2508.04072", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种名为KGA-ECoT的新框架，通过知识图谱和可执行代码增强代码生成和数学推理能力。", "motivation": "解决大型语言模型在复杂推理任务（如数学推理和代码生成）中的挑战。", "method": "使用知识图谱（KG）和可执行的思维链（ECoT）来分解问题为结构化任务图，利用GraphRAG从数学库中检索精确知识，并生成可验证代码以确保计算准确性。", "result": "在多个数学推理基准测试中，KGA-ECoT显著优于现有提示方法，准确率绝对提升数个至超过十个百分点。", "conclusion": "KGA-ECoT是一个强大且高度可推广的框架，适用于复杂的数学推理任务，GraphRAG和外部代码执行在提高代码质量和确保精度方面发挥关键作用。"}}
{"id": "2508.04080", "title": "GeoSR: Cognitive-Agentic Framework for Probing Geospatial Knowledge Boundaries via Iterative Self-Refinement", "authors": ["Jinfan Tang", "Kunming Wu", "Ruifeng Gongxie", "Yuya He", "Yuankai Wu"], "abstract": "Recent studies have extended the application of large language models (LLMs) to geographic problems, revealing surprising geospatial competence even without explicit spatial supervision. However, LLMs still face challenges in spatial consistency, multi-hop reasoning, and geographic bias. To address these issues, we propose GeoSR, a self-refining agentic reasoning framework that embeds core geographic principles -- most notably Tobler's First Law of Geography -- into an iterative prediction loop. In GeoSR, the reasoning process is decomposed into three collaborating agents: (1) a variable-selection agent that selects relevant covariates from the same location; (2) a point-selection agent that chooses reference predictions at nearby locations generated by the LLM in previous rounds; and (3) a refine agent that coordinates the iterative refinement process by evaluating prediction quality and triggering further rounds when necessary. This agentic loop progressively improves prediction quality by leveraging both spatial dependencies and inter-variable relationships. We validate GeoSR on tasks ranging from physical-world property estimation to socioeconomic prediction. Experimental results show consistent improvements over standard prompting strategies, demonstrating that incorporating geostatistical priors and spatially structured reasoning into LLMs leads to more accurate and equitable geospatial predictions. The code of GeoSR is available at", "subjects": "Artificial Intelligence (cs.AI); Other Statistics (stat.OT)", "comments": "16 pages, 9 figures", "pdf_url": "https://arxiv.org/pdf/2508.04080.pdf", "abstract_url": "https://arxiv.org/abs/2508.04080", "categories": ["Artificial Intelligence (cs.AI)", "Other Statistics (stat.OT)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "GeoSR是一种自我优化的代理推理框架，通过将地理核心原则（尤其是Tobler地理第一定律）嵌入迭代预测循环中，解决了大型语言模型（LLMs）在空间一致性、多跳推理和地理偏见方面的挑战。", "motivation": "尽管大型语言模型（LLMs）在地理问题应用中显示出惊人的地理空间能力，但在空间一致性、多跳推理和地理偏见方面仍面临挑战。", "method": "GeoSR框架将推理过程分解为三个协作代理：变量选择代理、点选择代理和优化代理，通过迭代优化过程利用空间依赖性和变量间关系逐步提高预测质量。", "result": "实验结果表明，GeoSR在从物理世界属性估计到社会经济预测的任务中，相比标准提示策略有持续改进，表明将地理统计先验和空间结构化推理融入LLMs能带来更准确和公平的地理空间预测。", "conclusion": "GeoSR通过整合地理统计原则和空间结构化推理，显著提升了LLMs在地理空间预测中的准确性和公平性，为地理空间知识的探索提供了新的框架。"}}
{"id": "2508.04118", "title": "AgREE: Agentic Reasoning for Knowledge Graph Completion on Emerging Entities", "authors": ["Ruochen Zhao", "Simone Conia", "Eric Peng", "Min Li", "Saloni Potdar"], "abstract": "Open-domain Knowledge Graph Completion (KGC) faces significant challenges in an ever-changing world, especially when considering the continual emergence of new entities in daily news. Existing approaches for KGC mainly rely on pretrained language models' parametric knowledge, pre-constructed queries, or single-step retrieval, typically requiring substantial supervision and training data. Even so, they often fail to capture comprehensive and up-to-date information about unpopular and/or emerging entities. To this end, we introduce Agentic Reasoning for Emerging Entities (AgREE), a novel agent-based framework that combines iterative retrieval actions and multi-step reasoning to dynamically construct rich knowledge graph triplets. Experiments show that, despite requiring zero training efforts, AgREE significantly outperforms existing methods in constructing knowledge graph triplets, especially for emerging entities that were not seen during language models' training processes, outperforming previous methods by up to 13.7%. Moreover, we propose a new evaluation methodology that addresses a fundamental weakness of existing setups and a new benchmark for KGC on emerging entities. Our work demonstrates the effectiveness of combining agent-based reasoning with strategic information retrieval for maintaining up-to-date knowledge graphs in dynamic information environments.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.04118.pdf", "abstract_url": "https://arxiv.org/abs/2508.04118", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "AgREE是一种基于代理的新型框架，通过结合迭代检索和多步推理，动态构建丰富的知识图谱三元组，特别针对新兴实体，无需训练即可显著优于现有方法。", "motivation": "解决在不断变化的世界中，尤其是日常新闻中不断出现的新实体，开放领域知识图谱补全（KGC）面临的挑战。现有方法依赖于预训练语言模型的参数知识、预构建查询或单步检索，通常需要大量监督和训练数据，但仍难以捕捉不流行和/或新兴实体的全面和最新信息。", "method": "引入Agentic Reasoning for Emerging Entities (AgREE)，一个结合迭代检索动作和多步推理的代理基础框架，以动态构建丰富的知识图谱三元组。", "result": "实验显示，尽管无需训练努力，AgREE在构建知识图谱三元组方面显著优于现有方法，特别是对于语言模型训练过程中未见的新兴实体，性能提升高达13.7%。此外，提出了一种新的评估方法和一个新的KGC基准，针对新兴实体。", "conclusion": "我们的工作展示了将基于代理的推理与策略信息检索相结合，在动态信息环境中维护最新知识图谱的有效性。"}}
{"id": "2508.04163", "title": "Generic-to-Specific Reasoning and Learning for Scalable Ad Hoc Teamwork", "authors": ["Hasra Dodampegama", "Mohan Sridharan"], "abstract": "AI agents deployed in assistive roles often have to collaborate with other agents (humans, AI systems) without prior coordination. Methods considered state of the art for such ad hoc teamwork often pursue a data-driven approach that needs a large labeled dataset of prior observations, lacks transparency, and makes it difficult to rapidly revise existing knowledge in response to changes. As the number of agents increases, the complexity of decision-making makes it difficult to collaborate effectively. This paper advocates leveraging the complementary strengths of knowledge-based and data-driven methods for reasoning and learning for ad hoc teamwork. For any given goal, our architecture enables each ad hoc agent to determine its actions through non-monotonic logical reasoning with: (a) prior commonsense domain-specific knowledge; (b) models learned and revised rapidly to predict the behavior of other agents; and (c) anticipated abstract future goals based on generic knowledge of similar situations in an existing foundation model. We experimentally evaluate our architecture's capabilities in VirtualHome, a realistic physics-based 3D simulation environment.", "subjects": "Artificial Intelligence (cs.AI); Logic in Computer Science (cs.LO); Multiagent Systems (cs.MA)", "comments": "14 pages, 6 figures", "pdf_url": "https://arxiv.org/pdf/2508.04163.pdf", "abstract_url": "https://arxiv.org/abs/2508.04163", "categories": ["Artificial Intelligence (cs.AI)", "Logic in Computer Science (cs.LO)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种结合知识驱动和数据驱动方法的通用到特定推理和学习框架，用于可扩展的临时团队协作，旨在解决现有方法在缺乏透明度、难以快速更新知识以及决策复杂性随团队规模增加而增加的问题。", "motivation": "解决临时团队协作中现有数据驱动方法需要大量标注数据、缺乏透明度、难以快速更新知识以及决策复杂性随团队规模增加而增加的问题。", "method": "提出了一种结合知识驱动和数据驱动方法的架构，利用先验常识领域知识、快速学习和修订的其他代理行为预测模型，以及基于现有基础模型中类似情境的通用知识的预期抽象未来目标，进行非单调逻辑推理。", "result": "在VirtualHome这一现实的基于物理的3D模拟环境中实验评估了所提架构的能力。", "conclusion": "通过结合知识驱动和数据驱动方法的优势，提出的架构能够有效支持临时团队协作，提高决策的透明度和适应性，同时降低决策复杂性。"}}
{"id": "2508.03719", "title": "Intent Aware Context Retrieval for Multi-Turn Agricultural Question Answering", "authors": ["Abhay Vijayvargia", "Ajay Nagpal", "Kundeshwar Pundalik", "Atharva Savarkar", "Smita Gautam", "Pankaj Singh", "Rohit Saluja", "Ganesh Ramakrishnan"], "abstract": "Indian farmers often lack timely, accessible, and language-friendly agricultural advice, especially in rural areas with low literacy. To address this gap in accessibility, this paper presents a novel AI-powered agricultural chatbot, Krishi Sathi, designed to support Indian farmers by providing personalized, easy-to-understand answers to their queries through both text and speech. The system's intelligence stems from an IFT model, subsequently refined through fine-tuning on Indian agricultural knowledge across three curated datasets. Unlike traditional chatbots that respond to one-off questions, Krishi Sathi follows a structured, multi-turn conversation flow to gradually collect the necessary details from the farmer, ensuring the query is fully understood before generating a response. Once the intent and context are extracted, the system performs Retrieval-Augmented Generation (RAG) by first fetching information from a curated agricultural database and then generating a tailored response using the IFT model. The chatbot supports both English and Hindi languages, with speech input and output features (via ASR and TTS) to make it accessible for users with low literacy or limited digital skills. This work demonstrates how combining intent-driven dialogue flows, instruction-tuned models, and retrieval-based generation can improve the quality and accessibility of digital agricultural support in India.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.03719.pdf", "abstract_url": "https://arxiv.org/abs/2508.03719", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了一种名为Krishi Sathi的新型AI农业聊天机器人，旨在通过文本和语音为印度农民提供个性化、易于理解的农业咨询。该系统通过多轮对话收集必要信息，确保准确理解查询后生成响应，支持英语和印地语，提高了印度农村地区农业支持的可及性和质量。", "motivation": "解决印度农民，尤其是农村地区低识字率农民获取及时、可访问且语言友好的农业建议的困难。", "method": "采用IFT模型，通过在三个精选的印度农业知识数据集上进行微调，结合检索增强生成（RAG）技术，从农业数据库中获取信息并生成定制响应。", "result": "开发了一个支持英语和印地语、具有语音输入输出功能的农业聊天机器人，能够通过多轮对话准确理解农民意图并提供个性化建议。", "conclusion": "结合意图驱动的对话流程、指令调优模型和检索生成技术，可以显著提高印度数字农业支持的质量和可及性。"}}
{"id": "2508.03728", "title": "WINELL: Wikipedia Never-Ending Updating with LLM Agents", "authors": ["Revanth Gangi Reddy", "Tanay Dixit", "Jiaxin Qin", "Cheng Qian", "Daniel Lee", "Jiawei Han", "Kevin Small", "Xing Fan", "Ruhi Sarikaya", "Heng Ji"], "abstract": "Wikipedia, a vast and continuously consulted knowledge base, faces significant challenges in maintaining up-to-date content due to its reliance on manual human editors. Inspired by the vision of continuous knowledge acquisition in NELL and fueled by advances in LLM-based agents, this paper introduces WiNELL, an agentic framework for continuously updating Wikipedia articles. Our approach employs a multi-agent framework to aggregate online information, select new and important knowledge for a target entity in Wikipedia, and then generate precise edit suggestions for human review. Our fine-grained editing models, trained on Wikipedia's extensive history of human edits, enable incorporating updates in a manner consistent with human editing behavior. Our editor models outperform both open-source instruction-following baselines and closed-source LLMs (e.g., GPT-4o) in key information coverage and editing efficiency. End-to-end evaluation on high-activity Wikipedia pages demonstrates WiNELL's ability to identify and suggest timely factual updates. This opens up a promising research direction in LLM agents for automatically updating knowledge bases in a never-ending fashion.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.03728.pdf", "abstract_url": "https://arxiv.org/abs/2508.03728", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了WiNELL，一个基于LLM代理的框架，旨在通过多代理系统自动更新维基百科文章，以提高内容更新的效率和准确性。", "motivation": "维基百科作为一个广泛且持续被咨询的知识库，面临着由于依赖人工编辑而难以保持内容更新的挑战。", "method": "采用多代理框架来聚合在线信息，选择维基百科目标实体的新重要知识，并生成精确的编辑建议供人工审核。", "result": "WiNELL的编辑模型在关键信息覆盖和编辑效率上优于开源指令跟随基线和闭源LLMs（如GPT-4o），并能识别和提出及时的事实更新。", "conclusion": "WiNELL为LLM代理自动更新知识库开辟了一个有前景的研究方向，展示了在持续知识获取方面的潜力。"}}
{"id": "2508.03793", "title": "AttnTrace: Attention-based Context Traceback for Long-Context LLMs", "authors": ["Yanting Wang", "Runpeng Geng", "Ying Chen", "Jinyuan Jia"], "abstract": "Long-context large language models (LLMs), such as Gemini-2.5-Pro and Claude-Sonnet-4, are increasingly used to empower advanced AI systems, including retrieval-augmented generation (RAG) pipelines and autonomous agents. In these systems, an LLM receives an instruction along with a context--often consisting of texts retrieved from a knowledge database or memory--and generates a response that is contextually grounded by following the instruction. Recent studies have designed solutions to trace back to a subset of texts in the context that contributes most to the response generated by the LLM. These solutions have numerous real-world applications, including performing post-attack forensic analysis and improving the interpretability and trustworthiness of LLM outputs. While significant efforts have been made, state-of-the-art solutions such as TracLLM often lead to a high computation cost, e.g., it takes TracLLM hundreds of seconds to perform traceback for a single response-context pair. In this work, we propose AttnTrace, a new context traceback method based on the attention weights produced by an LLM for a prompt. To effectively utilize attention weights, we introduce two techniques designed to enhance the effectiveness of AttnTrace, and we provide theoretical insights for our design choice. We also perform a systematic evaluation for AttnTrace. The results demonstrate that AttnTrace is more accurate and efficient than existing state-of-the-art context traceback methods. We also show that AttnTrace can improve state-of-the-art methods in detecting prompt injection under long contexts through the attribution-before-detection paradigm. As a real-world application, we demonstrate that AttnTrace can effectively pinpoint injected instructions in a paper designed to manipulate LLM-generated reviews. The code is at", "subjects": "Computation and Language (cs.CL); Cryptography and Security (cs.CR)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2508.03793.pdf", "abstract_url": "https://arxiv.org/abs/2508.03793", "categories": ["Computation and Language (cs.CL)", "Cryptography and Security (cs.CR)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "AttnTrace是一种基于注意力权重的新型上下文回溯方法，旨在提高长上下文大型语言模型（LLMs）中上下文回溯的准确性和效率。", "motivation": "解决现有上下文回溯方法（如TracLLM）计算成本高、效率低下的问题，以提高LLM输出的可解释性和可信度。", "method": "利用LLM生成的注意力权重，结合两种增强技术，设计出AttnTrace方法，并提供理论支持。", "result": "AttnTrace在准确性和效率上均优于现有最先进的上下文回溯方法，并能通过归因检测范式提升长上下文下提示注入的检测能力。", "conclusion": "AttnTrace不仅提高了上下文回溯的性能，还展示了在真实世界应用中的潜力，如有效识别注入指令。"}}
{"id": "2508.03860", "title": "Hallucination to Truth: A Review of Fact-Checking and Factuality Evaluation in Large Language Models", "authors": ["Subhey Sadi Rahman", "Md. Adnanul Islam", "Md. Mahbub Alam", "Musarrat Zeba", "Md. Abdur Rahman", "Sadia Sultana Chowa", "Mohaimenul Azam Khan Raiaan", "Sami Azam"], "abstract": "Large Language Models (LLMs) are trained on vast and diverse internet corpora that often include inaccurate or misleading content. Consequently, LLMs can generate misinformation, making robust fact-checking essential. This review systematically analyzes how LLM-generated content is evaluated for factual accuracy by exploring key challenges such as hallucinations, dataset limitations, and the reliability of evaluation metrics. The review emphasizes the need for strong fact-checking frameworks that integrate advanced prompting strategies, domain-specific fine-tuning, and retrieval-augmented generation (RAG) methods. It proposes five research questions that guide the analysis of the recent literature from 2020 to 2025, focusing on evaluation methods and mitigation techniques. The review also discusses the role of instruction tuning, multi-agent reasoning, and external knowledge access via RAG frameworks. Key findings highlight the limitations of current metrics, the value of grounding outputs with validated external evidence, and the importance of domain-specific customization to improve factual consistency. Overall, the review underlines the importance of building LLMs that are not only accurate and explainable but also tailored for domain-specific fact-checking. These insights contribute to the advancement of research toward more trustworthy and context-aware language models.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "30 pages, 11 figures, 6 tables. Submitted to Artificial Intelligence Review for peer review", "pdf_url": "https://arxiv.org/pdf/2508.03860.pdf", "abstract_url": "https://arxiv.org/abs/2508.03860", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文综述了大型语言模型(LLMs)中的事实核查和事实性评估，探讨了幻觉、数据集限制和评估指标可靠性等关键挑战，并提出了改进事实一致性的方法。", "motivation": "大型语言模型在训练过程中可能接触到不准确或误导性的内容，导致生成错误信息，因此需要强大的事实核查机制来确保信息的准确性。", "method": "通过系统分析2020年至2025年的文献，探讨了评估方法和缓解技术，包括高级提示策略、领域特定微调和检索增强生成(RAG)方法。", "result": "研究发现当前评估指标存在局限性，强调了使用验证过的外部证据和领域特定定制对提高事实一致性的重要性。", "conclusion": "综述强调了构建不仅准确、可解释，而且针对领域特定事实核查定制的大型语言模型的重要性，为更可信和上下文感知的语言模型研究提供了方向。"}}
{"id": "2508.03865", "title": "An Entity Linking Agent for Question Answering", "authors": ["Yajie Luo", "Yihong Wu", "Muzhi Li", "Fengran Mo", "Jia Ao Sun", "Xinyu Wang", "Liheng Ma", "Yingxue Zhang", "Jian-Yun Nie"], "abstract": "Some Question Answering (QA) systems rely on knowledge bases (KBs) to provide accurate answers. Entity Linking (EL) plays a critical role in linking natural language mentions to KB entries. However, most existing EL methods are designed for long contexts and do not perform well on short, ambiguous user questions in QA tasks. We propose an entity linking agent for QA, based on a Large Language Model that simulates human cognitive workflows. The agent actively identifies entity mentions, retrieves candidate entities, and makes decision. To verify the effectiveness of our agent, we conduct two experiments: tool-based entity linking and QA task evaluation. The results confirm the robustness and effectiveness of our agent.", "subjects": "Computation and Language (cs.CL)", "comments": "12 pages, 2 figures. Submitted to AAAI 2026 Conference", "pdf_url": "https://arxiv.org/pdf/2508.03865.pdf", "abstract_url": "https://arxiv.org/abs/2508.03865", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于大型语言模型的实体链接代理，用于问答系统中，通过模拟人类认知流程来有效链接短且模糊的用户问题到知识库条目。", "motivation": "现有的实体链接方法大多针对长上下文设计，在问答任务中处理短且模糊的用户问题时表现不佳。", "method": "提出一个基于大型语言模型的实体链接代理，主动识别实体提及、检索候选实体并做出决策。", "result": "通过工具基础的实体链接和问答任务评估两个实验，验证了代理的鲁棒性和有效性。", "conclusion": "该实体链接代理在问答系统中表现出色，能够有效处理短且模糊的用户问题，提高了问答系统的准确性和效率。"}}
{"id": "2508.03905", "title": "Sotopia-RL: Reward Design for Social Intelligence", "authors": ["Haofei Yu", "Zhengyang Qi", "Yining Zhao", "Kolby Nottingham", "Keyang Xuan", "Bodhisattwa Prasad Majumder", "Hao Zhu", "Paul Pu Liang", "Jiaxuan You"], "abstract": "Social intelligence has become a critical capability for large language models (LLMs), enabling them to engage effectively in real-world social tasks such as accommodation, persuasion, collaboration, and negotiation. Reinforcement learning (RL) is a natural fit for training socially intelligent agents because it allows models to learn sophisticated strategies directly through social interactions. However, social interactions have two key characteristics that set barriers for RL training: (1) partial observability, where utterances have indirect and delayed effects that complicate credit assignment, and (2) multi-dimensionality, where behaviors such as rapport-building or knowledge-seeking contribute indirectly to goal achievement. These characteristics make Markov decision process (MDP)-based RL with single-dimensional episode-level rewards inefficient and unstable. To address these challenges, we propose Sotopia-RL, a novel framework that refines coarse episode-level feedback into utterance-level, multi-dimensional rewards. Utterance-level credit assignment mitigates partial observability by attributing outcomes to individual utterances, while multi-dimensional rewards capture the full richness of social interactions and reduce reward hacking. Experiments in Sotopia, an open-ended social learning environment, demonstrate that Sotopia-RL achieves state-of-the-art social goal completion scores (7.17 on Sotopia-hard and 8.31 on Sotopia-full), significantly outperforming existing approaches. Ablation studies confirm the necessity of both utterance-level credit assignment and multi-dimensional reward design for RL training. Our implementation is publicly available at:", "subjects": "Computation and Language (cs.CL)", "comments": "10 pages", "pdf_url": "https://arxiv.org/pdf/2508.03905.pdf", "abstract_url": "https://arxiv.org/abs/2508.03905", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了Sotopia-RL，一个新颖的框架，通过将粗糙的回合级反馈细化为话语级、多维度的奖励，以解决社交智能训练中的部分可观察性和多维度挑战。", "motivation": "大型语言模型（LLMs）在社交任务中的表现需要社交智能，但社交互动的部分可观察性和多维度特性为强化学习（RL）训练设置了障碍。", "method": "Sotopia-RL框架通过话语级信用分配和多维度奖励设计，优化了RL训练过程。", "result": "在开放式的社交学习环境Sotopia中，Sotopia-RL实现了最先进的社交目标完成分数（Sotopia-hard上7.17，Sotopia-full上8.31），显著优于现有方法。", "conclusion": "Sotopia-RL通过话语级信用分配和多维度奖励设计，有效提升了LLMs在社交任务中的表现，为社交智能训练提供了新的方向。"}}
{"id": "2508.03923", "title": "CoAct-1: Computer-using Agents with Coding as Actions", "authors": ["Linxin Song", "Yutong Dai", "Viraj Prabhu", "Jieyu Zhang", "Taiwei Shi", "Li Li", "Junnan Li", "Silvio Savarese", "Zeyuan Chen", "Jieyu Zhao", "Ran Xu", "Caiming Xiong"], "abstract": "Autonomous agents that operate computers via Graphical User Interfaces (GUIs) often struggle with efficiency and reliability on complex, long-horizon tasks. While augmenting these agents with planners can improve task decomposition, they remain constrained by the inherent limitations of performing all actions through GUI manipulation, leading to brittleness and inefficiency. In this work, we introduce a more robust and flexible paradigm: enabling agents to use coding as a enhanced action. We present CoAct-1, a novel multi-agent system that synergistically combines GUI-based control with direct programmatic execution. CoAct-1 features an Orchestrator that dynamically delegates subtasks to either a conventional GUI Operator or a specialized Programmer agent, which can write and execute Python or Bash scripts. This hybrid approach allows the agent to bypass inefficient GUI action sequences for tasks like file management and data processing, while still leveraging visual interaction when necessary. We evaluate our system on the challenging OSWorld benchmark, where CoAct-1 achieves a new state-of-the-art success rate of 60.76%, significantly outperforming prior methods. Furthermore, our approach dramatically improves efficiency, reducing the average number of steps required to complete a task to just 10.15, compared to 15 for leading GUI agents. Our results demonstrate that integrating coding as a core action provides a more powerful, efficient, and scalable path toward generalized computer automation.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.03923.pdf", "abstract_url": "https://arxiv.org/abs/2508.03923", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "CoAct-1是一种新型多代理系统，通过结合基于GUI的控制和直接程序执行，使代理能够使用编码作为增强动作，显著提高了计算机自动化的效率和可靠性。", "motivation": "解决通过图形用户界面(GUI)操作的自主代理在复杂、长时程任务上效率和可靠性不足的问题。", "method": "引入一个多代理系统CoAct-1，其中包含一个协调器，动态地将子任务分配给传统的GUI操作员或专门的程序员代理，后者可以编写和执行Python或Bash脚本。", "result": "在OSWorld基准测试中，CoAct-1实现了60.76%的最新成功率，显著优于之前的方法，并将完成任务所需的平均步骤数减少到10.15。", "conclusion": "将编码作为核心动作集成，为通用计算机自动化提供了一条更强大、高效和可扩展的路径。"}}
{"id": "2508.04282", "title": "Synthetic POMDPs to Challenge Memory-Augmented RL: Memory Demand Structure Modeling", "authors": ["Yongyi Wang", "Lingfeng Li", "Bozhou Chen", "Ang Li", "Hanyu Liu", "Qirui Zheng", "Xionghui Yang", "Wenxin Li"], "abstract": "Recent research has developed benchmarks for memory-augmented reinforcement learning (RL) algorithms, providing Partially Observable Markov Decision Process (POMDP) environments where agents depend on past observations to make decisions. While many benchmarks incorporate sufficiently complex real-world problems, they lack controllability over the degree of challenges posed to memory models. In contrast, synthetic environments enable fine-grained manipulation of dynamics, making them critical for detailed and rigorous evaluation of memory-augmented RL. Our study focuses on POMDP synthesis with three key contributions:", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.04282.pdf", "abstract_url": "https://arxiv.org/abs/2508.04282", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种合成POMDPs的方法，用于挑战记忆增强RL算法，通过精细控制环境动态来评估记忆模型。", "motivation": "现有的记忆增强RL算法基准测试缺乏对记忆模型挑战程度的可控性，无法进行详细和严格的评估。", "method": "研究聚焦于POMDP的合成，提出了三个关键贡献，以实现对记忆模型挑战程度的精细控制。", "result": "通过合成环境，能够实现对记忆增强RL算法的详细和严格评估。", "conclusion": "合成POMDPs为记忆增强RL算法的评估提供了可控且详细的环境，有助于推动该领域的发展。"}}
{"id": "2508.04361", "title": "OmniPlay: Benchmarking Omni-Modal Models on Omni-Modal Game Playing", "authors": ["Fuqing Bie", "Shiyu Huang", "Xijia Tao", "Zhiqin Fang", "Leyi Pan", "Junzhe Chen", "Min Ren", "Liuyu Xiang", "Zhaofeng He"], "abstract": "While generalist foundation models like Gemini and GPT-4o demonstrate impressive multi-modal competence, existing evaluations fail to test their intelligence in dynamic, interactive worlds. Static benchmarks lack agency, while interactive benchmarks suffer from a severe modal bottleneck, typically ignoring crucial auditory and temporal cues. To bridge this evaluation chasm, we introduce OmniPlay, a diagnostic benchmark designed not just to evaluate, but to probe the fusion and reasoning capabilities of agentic models across the full sensory spectrum. Built on a core philosophy of modality interdependence, OmniPlay comprises a suite of five game environments that systematically create scenarios of both synergy and conflict, forcing agents to perform genuine cross-modal reasoning. Our comprehensive evaluation of six leading omni-modal models reveals a critical dichotomy: they exhibit superhuman performance on high-fidelity memory tasks but suffer from systemic failures in challenges requiring robust reasoning and strategic planning. We demonstrate that this fragility stems from brittle fusion mechanisms, which lead to catastrophic performance degradation under modality conflict and uncover a counter-intuitive \"less is more\" paradox, where removing sensory information can paradoxically improve performance. Our findings suggest that the path toward robust AGI requires a research focus beyond scaling to explicitly address synergistic fusion. Our platform is available for anonymous review at", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.04361.pdf", "abstract_url": "https://arxiv.org/abs/2508.04361", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了OmniPlay，一个旨在评估和探索全能模态模型在完整感官谱系中的融合和推理能力的诊断性基准。通过五个游戏环境，系统性地创建了协同和冲突场景，迫使模型进行真正的跨模态推理。", "motivation": "现有的评估方法无法测试全能模态模型在动态、互动世界中的智能，静态基准缺乏代理性，而互动基准则存在严重的模态瓶颈，通常忽略关键的听觉和时间线索。", "method": "OmniPlay基准建立在模态相互依赖的核心哲学上，包含五个游戏环境，这些环境系统地创建了协同和冲突场景，迫使模型进行跨模态推理。", "result": "对六个领先的全能模态模型的全面评估揭示了一个关键的两分法：它们在高保真记忆任务上表现出超人的性能，但在需要强大推理和战略规划的挑战中遭受系统性失败。", "conclusion": "研究结果表明，实现稳健的AGI需要超越规模扩展，明确解决协同融合问题。"}}
{"id": "2508.04412", "title": "Beyond Pixels: Exploring DOM Downsampling for LLM-Based Web Agents", "authors": ["Thassilo M. Schiepanski", "Nicholas Piël"], "abstract": "Frontier LLMs only recently enabled serviceable, autonomous web agents. At that, a model poses as an instantaneous domain model backend. Ought to suggest interaction, it is consulted with a web-based task and respective application state. The key problem lies in application state serialisation $\\unicode{x2013}$ referred to as snapshot. State-of-the-art web agents are premised on grounded GUI snapshots, i.e., screenshots enhanced with visual cues. Not least to resemble human perception, but for images representing relatively cheap means of model input. LLM vision still lag behind code interpretation capabilities. DOM snapshots, which structurally resemble HTML, impose a desired alternative. Vast model input token size, however, disables reliable implementation with web agents to date.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.04412.pdf", "abstract_url": "https://arxiv.org/abs/2508.04412", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了在基于LLM的网页代理中使用DOM降采样技术，以解决当前依赖GUI快照（如截图）的方法在模型输入上的限制。", "motivation": "当前基于LLM的网页代理主要依赖于GUI快照（如截图）作为应用状态的序列化方法，这种方法虽然成本较低，但在模型输入上存在限制，尤其是当涉及到DOM快照时，由于输入令牌大小的限制，难以实现可靠的网页代理。", "method": "探索DOM降采样技术，作为一种替代GUI快照的方法，以利用DOM结构与HTML相似的优势，同时克服模型输入令牌大小的限制。", "result": "提出了一种可能的方法，即通过DOM降采样来优化基于LLM的网页代理的性能，尤其是在处理复杂的网页应用状态时。", "conclusion": "DOM降采样技术为基于LLM的网页代理提供了一种有前景的替代方案，能够克服当前GUI快照方法的限制，尤其是在模型输入令牌大小和代码解释能力方面的挑战。"}}
{"id": "2508.04389", "title": "GuirlVG: Incentivize GUI Visual Grounding via Empirical Exploration on Reinforcement Learning", "authors": ["Weitai Kang", "Bin Lei", "Gaowen Liu", "Caiwen Ding", "Yan Yan"], "abstract": "Graphical user interface visual grounding (GUI-VG), a core capability for GUI agents, has primarily relied on supervised fine-tuning (SFT) of multimodal large language models (MLLMs), which demands extensive data curation and significant training costs. However, as MLLMs continue to advance and even cover GUI domains during pretraining, the necessity of exhaustive SFT post-training becomes increasingly questionable. Meanwhile, recent successes of rule-based reinforcement fine-tuning (RFT) suggest a more efficient alternative. Despite this promise, the optimal manner of applying RFT for GUI-VG remains unexplored. To bridge this gap, we introduce GuirlVG, a reinforcement learning-based GUI-VG method built on a systematic empirical study and a novel stabilization technique. We find that naive application of RFT underperforms the SFT baseline, motivating a deeper exploration. First, we decompose RFT into its core components and analyze the optimal formulation of each. Second, we propose a novel Adversarial KL Factor that dynamically stabilizes training to mitigate reward over-optimization. Third, we further explore the training configurations of RFT to enhance effectiveness. Extensive experiments show that GuirlVG, with only 5.2K training samples, outperforms SFT methods trained on over 10M samples, achieving a 7.7% improvement on ScreenSpot, a 17.2% improvement on ScreenSpotPro, and 91.9% accuracy on ScreenSpotV2.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "9 pages", "pdf_url": "https://arxiv.org/pdf/2508.04389.pdf", "abstract_url": "https://arxiv.org/abs/2508.04389", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "GuirlVG是一种基于强化学习的图形用户界面视觉接地（GUI-VG）方法，通过系统性实证研究和新颖的稳定技术，显著提高了性能，仅需少量训练样本即可超越传统监督微调方法。", "motivation": "解决传统监督微调（SFT）方法在GUI-VG任务中需要大量数据和训练成本的问题，探索基于规则的强化微调（RFT）的更高效替代方案。", "method": "引入GuirlVG方法，包括对RFT核心组件的分解分析、提出动态稳定训练的新颖对抗KL因子，以及探索RFT的训练配置以增强效果。", "result": "GuirlVG仅使用5.2K训练样本，在ScreenSpot、ScreenSpotPro和ScreenSpotV2上的性能分别比使用10M以上样本的SFT方法提高了7.7%、17.2%和91.9%的准确率。", "conclusion": "GuirlVG通过强化学习和稳定技术的结合，为GUI-VG提供了一种更高效、更经济的解决方案，显著减少了数据需求和训练成本。"}}
{"id": "2508.04482", "title": "OS Agents: A Survey on MLLM-based Agents for General Computing Devices Use", "authors": ["Xueyu Hu", "Tao Xiong", "Biao Yi", "Zishu Wei", "Ruixuan Xiao", "Yurun Chen", "Jiasheng Ye", "Meiling Tao", "Xiangxin Zhou", "Ziyu Zhao", "Yuhuai Li", "Shengze Xu", "Shenzhi Wang", "Xinchen Xu", "Shuofei Qiao", "Zhaokai Wang", "Kun Kuang", "Tieyong Zeng", "Liang Wang", "Jiwei Li", "Yuchen Eleanor Jiang", "Wangchunshu Zhou", "Guoyin Wang", "Keting Yin", "Zhou Zhao", "Hongxia Yang", "Fan Wu", "Shengyu Zhang", "Fei Wu"], "abstract": "The dream to create AI assistants as capable and versatile as the fictional J.A.R.V.I.S from Iron Man has long captivated imaginations. With the evolution of (multi-modal) large language models ((M)LLMs), this dream is closer to reality, as (M)LLM-based Agents using computing devices (e.g., computers and mobile phones) by operating within the environments and interfaces (e.g., Graphical User Interface (GUI)) provided by operating systems (OS) to automate tasks have significantly advanced. This paper presents a comprehensive survey of these advanced agents, designated as OS Agents. We begin by elucidating the fundamentals of OS Agents, exploring their key components including the environment, observation space, and action space, and outlining essential capabilities such as understanding, planning, and grounding. We then examine methodologies for constructing OS Agents, focusing on domain-specific foundation models and agent frameworks. A detailed review of evaluation protocols and benchmarks highlights how OS Agents are assessed across diverse tasks. Finally, we discuss current challenges and identify promising directions for future research, including safety and privacy, personalization and self-evolution. This survey aims to consolidate the state of OS Agents research, providing insights to guide both academic inquiry and industrial development. An open-source GitHub repository is maintained as a dynamic resource to foster further innovation in this field. We present a 9-page version of our work, accepted by ACL 2025, to provide a concise overview to the domain.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "comments": "ACL 2025 (Oral)", "pdf_url": "https://arxiv.org/pdf/2508.04482.pdf", "abstract_url": "https://arxiv.org/abs/2508.04482", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Computer Vision and Pattern Recognition (cs.CV)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文综述了基于多模态大语言模型（M）LLM的操作系统代理（OS Agents）的研究现状，探讨了其关键组件、构建方法、评估协议及未来研究方向。", "motivation": "探讨如何利用（M）LLM技术开发能够像《钢铁侠》中的J.A.R.V.I.S那样多功能和智能的AI助手，特别是在通用计算设备上的应用。", "method": "通过综述现有的OS Agents研究，分析其关键组件（如环境、观察空间和行动空间）、构建方法（如领域特定的基础模型和代理框架）以及评估协议和基准。", "result": "总结了OS Agents的当前研究状态，包括其在多样化任务中的评估方法，以及面临的挑战和未来的研究方向。", "conclusion": "OS Agents的研究为开发多功能AI助手提供了重要见解，未来的工作应关注安全性、隐私保护、个性化及自我进化等方向。"}}
{"id": "2508.04652", "title": "LLM Collaboration With Multi-Agent Reinforcement Learning", "authors": ["Shuo Liu", "Zeyu Liang", "Xueguang Lyu", "Christopher Amato"], "abstract": "A large amount of work has been done in Multi-Agent Systems (MAS) for modeling and solving problems with multiple interacting agents. However, most LLMs are pretrained independently and not specifically optimized for coordination. Existing LLM fine-tuning frameworks rely on individual rewards, which require complex reward designs for each agent to encourage collaboration. To address these challenges, we model LLM collaboration as a cooperative Multi-Agent Reinforcement Learning (MARL) problem. We develop a multi-agent, multi-turn algorithm, Multi-Agent Group Relative Policy Optimization (MAGRPO), to solve it, building on current RL approaches for LLMs as well as MARL techniques. Our experiments on LLM writing and coding collaboration demonstrate that fine-tuning MAS with MAGRPO enables agents to generate high-quality responses efficiently through effective cooperation. Our approach opens the door to using other MARL methods for LLMs and highlights the associated challenges.", "subjects": "Artificial Intelligence (cs.AI); Software Engineering (cs.SE)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.04652.pdf", "abstract_url": "https://arxiv.org/abs/2508.04652", "categories": ["Artificial Intelligence (cs.AI)", "Software Engineering (cs.SE)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种多智能体强化学习（MARL）方法MAGRPO，用于优化大型语言模型（LLM）在多智能体系统中的协作能力。", "motivation": "现有的LLM大多独立预训练，未针对协作进行优化，且现有微调框架依赖于个体奖励，需要为每个智能体设计复杂的奖励机制以促进协作。", "method": "我们将LLM协作建模为一个合作性MARL问题，并开发了多智能体、多轮算法MAGRPO，结合了当前LLM的RL方法和MARL技术。", "result": "在LLM写作和编码协作的实验表明，使用MAGRPO微调的MAS能够通过有效合作高效生成高质量响应。", "conclusion": "我们的方法为使用其他MARL方法优化LLM协作打开了大门，并突出了相关挑战。"}}
{"id": "2508.03998", "title": "Transferring Expert Cognitive Models to Social Robots via Agentic Concept Bottleneck Models", "authors": ["Xinyu Zhao", "Zhen Tan", "Maya Enisman", "Minjae Seo", "Marta R. Durantini", "Dolores Albarracin", "Tianlong Chen"], "abstract": "Successful group meetings, such as those implemented in group behavioral-change programs, work meetings, and other social contexts, must promote individual goal setting and execution while strengthening the social relationships within the group. Consequently, an ideal facilitator must be sensitive to the subtle dynamics of disengagement, difficulties with individual goal setting and execution, and interpersonal difficulties that signal a need for intervention. The challenges and cognitive load experienced by facilitators create a critical gap for an embodied technology that can interpret social exchanges while remaining aware of the needs of the individuals in the group and providing transparent recommendations that go beyond powerful but \"black box\" foundation models (FMs) that identify social cues. We address this important demand with a social robot co-facilitator that analyzes multimodal meeting data and provides discreet cues to the facilitator. The robot's reasoning is powered by an agentic concept bottleneck model (CBM), which makes decisions based on human-interpretable concepts like participant engagement and sentiments, ensuring transparency and trustworthiness. Our core contribution is a transfer learning framework that distills the broad social understanding of an FM into our specialized and transparent CBM. This concept-driven system significantly outperforms direct zero-shot FMs in predicting the need for intervention and enables real-time human correction of its reasoning. Critically, we demonstrate robust knowledge transfer: the model generalizes across different groups and successfully transfers the expertise of senior human facilitators to improve the performance of novices. By transferring an expert's cognitive model into an interpretable robotic partner, our work provides a powerful blueprint for augmenting human capabilities in complex social domains.", "subjects": "Computation and Language (cs.CL)", "comments": "27 pages, 7 figures", "pdf_url": "https://arxiv.org/pdf/2508.03998.pdf", "abstract_url": "https://arxiv.org/abs/2508.03998", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种通过代理概念瓶颈模型（CBM）将专家认知模型转移到社交机器人的方法，旨在提升群体会议中的个体目标设定和执行，同时加强群体内的社会关系。", "motivation": "解决群体会议中促进个体目标设定和执行、加强社会关系的挑战，以及减轻主持人的认知负荷，需要一个能够解释社会交流、关注个体需求并提供透明建议的具身技术。", "method": "采用代理概念瓶颈模型（CBM）驱动的社交机器人共同主持人，分析多模态会议数据，并提供谨慎的提示。通过转移学习框架，将基础模型（FM）的广泛社会理解提炼到专门的、透明的CBM中。", "result": "概念驱动系统在预测干预需求方面显著优于直接零射FM，支持实时人类纠正其推理，并展示了跨群体和从资深主持人到新手的知识转移。", "conclusion": "通过将专家认知模型转移到可解释的机器人伙伴中，本研究为增强人类在复杂社会领域的能力提供了强有力的蓝图。"}}
{"id": "2508.04010", "title": "HarmonyGuard: Toward Safety and Utility in Web Agents via Adaptive Policy Enhancement and Dual-Objective Optimization", "authors": ["Yurun Chen", "Xavier Hu", "Yuhan Liu", "Keting Yin", "Juncheng Li", "Zhuosheng Zhang", "Shengyu Zhang"], "abstract": "Large language models enable agents to autonomously perform tasks in open web environments. However, as hidden threats within the web evolve, web agents face the challenge of balancing task performance with emerging risks during long-sequence operations. Although this challenge is critical, current research remains limited to single-objective optimization or single-turn scenarios, lacking the capability for collaborative optimization of both safety and utility in web environments. To address this gap, we propose HarmonyGuard, a multi-agent collaborative framework that leverages policy enhancement and objective optimization to jointly improve both utility and safety. HarmonyGuard features a multi-agent architecture characterized by two fundamental capabilities: (1) Adaptive Policy Enhancement: We introduce the Policy Agent within HarmonyGuard, which automatically extracts and maintains structured security policies from unstructured external documents, while continuously updating policies in response to evolving threats. (2) Dual-Objective Optimization: Based on the dual objectives of safety and utility, the Utility Agent integrated within HarmonyGuard performs the Markovian real-time reasoning to evaluate the objectives and utilizes metacognitive capabilities for their optimization. Extensive evaluations on multiple benchmarks show that HarmonyGuard improves policy compliance by up to 38% and task completion by up to 20% over existing baselines, while achieving over 90% policy compliance across all tasks. Our project is available here:", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.04010.pdf", "abstract_url": "https://arxiv.org/abs/2508.04010", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "HarmonyGuard是一个多智能体协作框架，旨在通过策略增强和目标优化共同提高网络环境中的实用性和安全性。", "motivation": "解决网络智能体在长时间操作中平衡任务性能和新兴风险的问题，当前研究局限于单目标优化或单轮场景，缺乏对安全性和实用性的协同优化能力。", "method": "采用多智能体架构，包括策略智能体（自动从非结构化外部文档提取并维护结构化安全策略）和实用智能体（基于安全性和实用性双重目标进行马尔可夫实时推理和元认知能力优化）。", "result": "在多个基准测试中，HarmonyGuard比现有基线策略合规性提高了38%，任务完成率提高了20%，所有任务的政策合规性超过90%。", "conclusion": "HarmonyGuard通过自适应策略增强和双目标优化，有效提高了网络智能体的安全性和实用性，为网络环境中的自主任务执行提供了新的解决方案。"}}
{"id": "2508.04038", "title": "ZARA: Zero-shot Motion Time-Series Analysis via Knowledge and Retrieval Driven LLM Agents", "authors": ["Zechen Li", "Baiyu Chen", "Hao Xue", "Flora D. Salim"], "abstract": "Motion sensor time-series are central to human activity recognition (HAR), with applications in health, sports, and smart devices. However, existing methods are trained for fixed activity sets and require costly retraining when new behaviours or sensor setups appear. Recent attempts to use large language models (LLMs) for HAR, typically by converting signals into text or images, suffer from limited accuracy and lack verifiable interpretability. We propose ZARA, the first agent-based framework for zero-shot, explainable HAR directly from raw motion time-series. ZARA integrates an automatically derived pair-wise feature knowledge base that captures discriminative statistics for every activity pair, a multi-sensor retrieval module that surfaces relevant evidence, and a hierarchical agent pipeline that guides the LLM to iteratively select features, draw on this evidence, and produce both activity predictions and natural-language explanations. ZARA enables flexible and interpretable HAR without any fine-tuning or task-specific classifiers. Extensive experiments on 8 HAR benchmarks show that ZARA achieves SOTA zero-shot performance, delivering clear reasoning while exceeding the strongest baselines by 2.53x in macro F1. Ablation studies further confirm the necessity of each module, marking ZARA as a promising step toward trustworthy, plug-and-play motion time-series analysis. Our codes are available at", "subjects": "Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.04038.pdf", "abstract_url": "https://arxiv.org/abs/2508.04038", "categories": ["Computation and Language (cs.CL)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "ZARA是一种基于代理的框架，用于直接从原始运动时间序列进行零样本、可解释的人类活动识别（HAR），无需微调或特定任务的分类器。", "motivation": "解决现有方法需要固定活动集和昂贵重新训练的问题，以及使用大型语言模型（LLMs）进行HAR时准确性和可解释性有限的问题。", "method": "ZARA集成了自动导出的成对特征知识库、多传感器检索模块和分层代理管道，指导LLM迭代选择特征、利用证据并生成活动预测和自然语言解释。", "result": "在8个HAR基准测试中，ZARA实现了最先进的零样本性能，宏观F1得分超过最强基线2.53倍，并通过消融研究验证了每个模块的必要性。", "conclusion": "ZARA是朝着可信赖、即插即用的运动时间序列分析迈出的有希望的一步，提供了灵活和可解释的HAR解决方案。"}}
{"id": "2508.04039", "title": "Large Reasoning Models Are Autonomous Jailbreak Agents", "authors": ["Thilo Hagendorff", "Erik Derner", "Nuria Oliver"], "abstract": "Jailbreaking -- bypassing built-in safety mechanisms in AI models -- has traditionally required complex technical procedures or specialized human expertise. In this study, we show that the persuasive capabilities of large reasoning models (LRMs) simplify and scale jailbreaking, converting it into an inexpensive activity accessible to non-experts. We evaluated the capabilities of four LRMs (DeepSeek-R1, Gemini 2.5 Flash, Grok 3 Mini, Qwen3 235B) to act as autonomous adversaries conducting multi-turn conversations with nine widely used target models. LRMs received instructions via a system prompt, before proceeding to planning and executing jailbreaks with no further supervision. We performed extensive experiments with a benchmark of harmful prompts composed of 70 items covering seven sensitive domains. This setup yielded an overall attack success rate across all model combinations of 97.14%. Our study reveals an alignment regression, in which LRMs can systematically erode the safety guardrails of other models, highlighting the urgent need to further align frontier models not only to resist jailbreak attempts, but also to prevent them from being co-opted into acting as jailbreak agents.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.04039.pdf", "abstract_url": "https://arxiv.org/abs/2508.04039", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Cryptography and Security (cs.CR)"], "matching_keywords": ["agent"], "AI": {"tldr": "研究表明，大型推理模型（LRMs）能够简化并规模化越狱行为，使其成为非专家也能进行的低成本活动。通过评估四种LRMs在九个广泛使用的目标模型上的表现，发现其攻击成功率高达97.14%，揭示了模型安全防护的退化现象。", "motivation": "解决AI模型中内置安全机制被绕过（即越狱）的问题，传统方法需要复杂的技术程序或专业的人类知识。本研究旨在展示大型推理模型的说服能力如何简化和规模化越狱行为。", "method": "评估四种大型推理模型（DeepSeek-R1, Gemini 2.5 Flash, Grok 3 Mini, Qwen3 235B）作为自主对手，与九个目标模型进行多轮对话的能力。LRMs通过系统提示接收指令，然后无需进一步监督即可规划和执行越狱。", "result": "在包含70个敏感领域项目的基准测试中，所有模型组合的总体攻击成功率为97.14%，表明LRMs能够系统地侵蚀其他模型的安全防护。", "conclusion": "研究揭示了模型对齐的退化现象，强调了进一步对齐前沿模型的紧迫性，不仅要抵抗越狱尝试，还要防止它们被利用作为越狱代理。"}}
{"id": "2508.04057", "title": "PAIRS: Parametric-Verified Adaptive Information Retrieval and Selection for Efficient RAG", "authors": ["Wang Chen", "Guanqiang Qi", "Weikang Li", "Yang Li", "Deguo Xia", "Jizhou Huang"], "abstract": "Retrieval-Augmented Generation (RAG) has become a cornerstone technique for enhancing large language models (LLMs) with external knowledge. However, current RAG systems face two critical limitations: (1) they inefficiently retrieve information for every query, including simple questions that could be resolved using the LLM's parametric knowledge alone, and (2) they risk retrieving irrelevant documents when queries contain sparse information signals. To address these gaps, we introduce Parametric-verified Adaptive Information Retrieval and Selection (PAIRS), a training-free framework that integrates parametric and retrieved knowledge to adaptively determine whether to retrieve and how to select external information. Specifically, PAIRS employs a dual-path generation mechanism: First, the LLM produces both a direct answer and a context-augmented answer using self-generated pseudo-context. When these outputs converge, PAIRS bypasses external retrieval entirely, dramatically improving the RAG system's efficiency. For divergent cases, PAIRS activates a dual-path retrieval (DPR) process guided by both the original query and self-generated contextual signals, followed by an Adaptive Information Selection (AIS) module that filters documents through weighted similarity to both sources. This simple yet effective approach can not only enhance efficiency by eliminating unnecessary retrievals but also improve accuracy through contextually guided retrieval and adaptive information selection. Experimental results on six question-answering (QA) benchmarks show that PAIRS reduces retrieval costs by around 25% (triggering for only 75% of queries) while still improving accuracy-achieving +1.1% EM and +1.0% F1 over prior baselines on average.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.04057.pdf", "abstract_url": "https://arxiv.org/abs/2508.04057", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "PAIRS是一种无需训练的框架，通过整合参数化和检索知识，自适应地决定是否检索及如何选择外部信息，以提高RAG系统的效率和准确性。", "motivation": "解决当前RAG系统在检索信息时的两个关键限制：对所有查询（包括简单问题）进行低效检索，以及在查询信息信号稀疏时可能检索到不相关文档。", "method": "采用双路径生成机制：首先生成直接答案和上下文增强答案，若一致则绕过外部检索；若不一致，则激活基于原始查询和自生成上下文信号的双路径检索（DPR），随后通过自适应信息选择（AIS）模块过滤文档。", "result": "在六个问答基准测试中，PAIRS将检索成本降低了约25%（仅对75%的查询触发检索），同时平均准确率提高了+1.1% EM和+1.0% F1。", "conclusion": "PAIRS通过上下文引导的检索和自适应信息选择，不仅提高了效率，还提升了准确性，为RAG系统提供了一种简单而有效的改进方法。"}}
{"id": "2508.04086", "title": "ToolGrad: Efficient Tool-use Dataset Generation with Textual \"Gradients\"", "authors": ["Zhongyi Zhou", "Kohei Uehara", "Haoyu Zhang", "Jingtao Zhou", "Lin Gu", "Ruofei Du", "Zheng Xu", "Tatsuya Harada"], "abstract": "Prior work synthesizes tool-use LLM datasets by first generating a user query, followed by complex tool-use annotations like DFS. This leads to inevitable annotation failures and low efficiency in data generation. We introduce ToolGrad, an agentic framework that inverts this paradigm. ToolGrad first constructs valid tool-use chains through an iterative process guided by textual \"gradients\", and then synthesizes corresponding user queries. This \"answer-first\" approach led to ToolGrad-5k, a dataset generated with more complex tool use, lower cost, and 100% pass rate. Experiments show that models trained on ToolGrad-5k outperform those on expensive baseline datasets and proprietary LLMs, even on OOD benchmarks.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.04086.pdf", "abstract_url": "https://arxiv.org/abs/2508.04086", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "ToolGrad提出了一种新的工具使用数据集生成框架，通过先构建有效的工具使用链再合成用户查询，提高了数据生成的效率和准确性。", "motivation": "解决现有工具使用LLM数据集生成方法中存在的注释失败率高和生成效率低的问题。", "method": "采用“答案优先”的方法，通过文本“梯度”指导的迭代过程构建有效的工具使用链，然后合成相应的用户查询。", "result": "生成的ToolGrad-5k数据集具有更复杂的工具使用、更低的成本和100%的通过率，实验显示在该数据集上训练的模型性能优于昂贵基线数据集和专有LLM。", "conclusion": "ToolGrad框架在工具使用数据集生成方面提供了更高效、更准确的解决方案，对提升模型性能有显著影响。"}}
{"id": "2508.04700", "title": "SEAgent: Self-Evolving Computer Use Agent with Autonomous Learning from Experience", "authors": ["Zeyi Sun", "Ziyu Liu", "Yuhang Zang", "Yuhang Cao", "Xiaoyi Dong", "Tong Wu", "Dahua Lin", "Jiaqi Wang"], "abstract": "Repurposing large vision-language models (LVLMs) as computer use agents (CUAs) has led to substantial breakthroughs, primarily driven by human-labeled data. However, these models often struggle with novel and specialized software, particularly in scenarios lacking human annotations. To address this challenge, we propose SEAgent, an agentic self-evolving framework enabling CUAs to autonomously evolve through interactions with unfamiliar software. Specifically, SEAgent empowers computer-use agents to autonomously master novel software environments via experiential learning, where agents explore new software, learn through iterative trial-and-error, and progressively tackle auto-generated tasks organized from simple to complex. To achieve this goal, we design a World State Model for step-wise trajectory assessment, along with a Curriculum Generator that generates increasingly diverse and challenging tasks. The agent's policy is updated through experiential learning, comprised of adversarial imitation of failure actions and Group Relative Policy Optimization (GRPO) on successful ones. Furthermore, we introduce a specialist-to-generalist training strategy that integrates individual experiential insights from specialist agents, facilitating the development of a stronger generalist CUA capable of continuous autonomous evolution. This unified agent ultimately achieves performance surpassing ensembles of individual specialist agents on their specialized software. We validate the effectiveness of SEAgent across five novel software environments within OS-World. Our approach achieves a significant improvement of 23.2% in success rate, from 11.3% to 34.5%, over a competitive open-source CUA, i.e., UI-TARS.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Multiagent Systems (cs.MA); Multimedia (cs.MM)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2508.04700.pdf", "abstract_url": "https://arxiv.org/abs/2508.04700", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Computer Vision and Pattern Recognition (cs.CV)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)", "Multimedia (cs.MM)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "SEAgent是一种自我演进的计算机使用代理框架，通过自主学习和经验积累来掌握新软件环境，无需人类标注数据。", "motivation": "解决大型视觉语言模型在缺乏人类标注数据时难以适应新颖和专用软件的问题。", "method": "设计了世界状态模型进行轨迹评估，课程生成器生成任务，通过对抗模仿失败动作和GRPO优化成功动作来更新策略，并采用专家到通才的训练策略。", "result": "在OS-World的五个新软件环境中，SEAgent的成功率比竞争对手UI-TARS提高了23.2%，从11.3%提升到34.5%。", "conclusion": "SEAgent通过自主学习和经验积累，能够持续自主进化，其性能超过了专门软件上的专家代理集合。"}}
{"id": "2508.03700", "title": "MagicGUI: A Foundational Mobile GUI Agent with Scalable Data Pipeline and Reinforcement Fine-tuning", "authors": ["Liujian Tang", "Shaokang Dong", "Yijia Huang", "Minqi Xiang", "Hongtao Ruan", "Bin Wang", "Shuo Li", "Zhihui Cao", "Hailiang Pang", "Heng Kong", "He Yang", "Mingxu Chai", "Zhilin Gao", "Xingyu Liu", "Yingnan Fu", "Jiaming Liu", "Tao Gui", "Xuanjing Huang", "Yu-Gang Jiang", "Qi Zhang", "Kang Wang", "Yunke Zhang", "Yuran Wang"], "abstract": "This paper presents MagicGUI, a foundational mobile GUI agent designed to address critical challenges in perception, grounding, and reasoning within real-world mobile GUI environments. The framework is underpinned by following six key components: (1) a comprehensive and accurate dataset, constructed via the scalable GUI Data Pipeline, which aggregates the largest and most diverse GUI-centric multimodal data to date from open-source repositories, automated crawling, and targeted manual annotation; (2) enhanced perception and grounding capabilities, facilitating fine-grained multimodal alignment for UI element referencing, grounding, and screen comprehension; (3) a comprehensive and unified action space, encompassing both fundamental UI operations and complex interactive intents to support human-agent interactions; (4) planning-oriented reasoning mechanisms that enable the model to decompose complex user instructions into sequential actions with explicit intermediate meta-paln reasoning; (5) an iterative two-stage training procedure, combining large-scale continue pre-training on 7.8M samples with reinforcement fine-tuning utilizing a spatially enhanced composite reward and dual filtering strategy; and (6) competitive performance on both the proprietary Magic-RICH benchmark and over a dozen public benchmarks, achieving superior performance across GUI perception and agent tasks, while demonstrating robust generalization and real-world deployment potential in practical mobile GUI scenarios, as detailed in Figure 1.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.03700.pdf", "abstract_url": "https://arxiv.org/abs/2508.03700", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "MagicGUI是一个基础的移动GUI代理，旨在解决现实世界移动GUI环境中的感知、基础和推理挑战。它通过六个关键组件实现，包括数据集构建、增强的感知和基础能力、统一的动作空间、规划导向的推理机制、两阶段训练程序，以及在多个基准测试中的竞争性能。", "motivation": "解决在现实世界移动GUI环境中的感知、基础和推理挑战。", "method": "采用六个关键组件：数据集构建、增强的感知和基础能力、统一的动作空间、规划导向的推理机制、两阶段训练程序。", "result": "在Magic-RICH基准和多个公共基准测试中表现出色，展示了在GUI感知和代理任务上的卓越性能，以及在实际移动GUI场景中的强大泛化能力和部署潜力。", "conclusion": "MagicGUI通过其综合框架和创新的训练方法，为移动GUI代理领域提供了强大的解决方案，具有广泛的应用前景和实际部署潜力。"}}
{"id": "2508.04266", "title": "ShoppingBench: A Real-World Intent-Grounded Shopping Benchmark for LLM-based Agents", "authors": ["Jiangyuan Wang", "Kejun Xiao", "Qi Sun", "Huaipeng Zhao", "Tao Luo", "Jiandong Zhang", "Xiaoyi Zeng"], "abstract": "Existing benchmarks in e-commerce primarily focus on basic user intents, such as finding or purchasing products. However, real-world users often pursue more complex goals, such as applying vouchers, managing budgets, and finding multi-products seller. To bridge this gap, we propose ShoppingBench, a novel end-to-end shopping benchmark designed to encompass increasingly challenging levels of grounded intent. Specifically, we propose a scalable framework to simulate user instructions based on various intents derived from sampled real-world products. To facilitate consistent and reliable evaluations, we provide a large-scale shopping sandbox that serves as an interactive simulated environment, incorporating over 2.5 million real-world products. Experimental results demonstrate that even state-of-the-art language agents (such as GPT-4.1) achieve absolute success rates under 50% on our benchmark tasks, highlighting the significant challenges posed by our ShoppingBench. In addition, we propose a trajectory distillation strategy and leverage supervised fine-tuning, along with reinforcement learning on synthetic trajectories, to distill the capabilities of a large language agent into a smaller one. As a result, our trained agent achieves competitive performance compared to GPT-4.1.", "subjects": "Computation and Language (cs.CL)", "comments": "submit to AAAI2026", "pdf_url": "https://arxiv.org/pdf/2508.04266.pdf", "abstract_url": "https://arxiv.org/abs/2508.04266", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了ShoppingBench，一个新颖的端到端购物基准测试，旨在涵盖日益复杂的接地意图，以解决现有电子商务基准测试主要关注基本用户意图的局限性。", "motivation": "解决现有电子商务基准测试主要关注基本用户意图（如查找或购买产品）而忽略更复杂目标（如应用优惠券、管理预算和寻找多产品卖家）的问题。", "method": "提出了一个可扩展的框架，基于从真实世界产品样本中得出的各种意图来模拟用户指令，并提供了一个大规模的购物沙箱作为交互式模拟环境。", "result": "实验结果表明，即使是最先进的语言代理（如GPT-4.1）在我们的基准测试任务上的绝对成功率也低于50%，突出了ShoppingBench带来的重大挑战。", "conclusion": "通过轨迹蒸馏策略和监督微调，以及强化学习在合成轨迹上的应用，我们成功地将大型语言代理的能力蒸馏到较小的代理中，使其性能与GPT-4.1相当。"}}
{"id": "2508.04276", "title": "A Few Words Can Distort Graphs: Knowledge Poisoning Attacks on Graph-based Retrieval-Augmented Generation of Large Language Models", "authors": ["Jiayi Wen", "Tianxin Chen", "Zhirun Zheng", "Cheng Huang"], "abstract": "Graph-based Retrieval-Augmented Generation (GraphRAG) has recently emerged as a promising paradigm for enhancing large language models (LLMs) by converting raw text into structured knowledge graphs, improving both accuracy and explainability. However, GraphRAG relies on LLMs to extract knowledge from raw text during graph construction, and this process can be maliciously manipulated to implant misleading information. Targeting this attack surface, we propose two knowledge poisoning attacks (KPAs) and demonstrate that modifying only a few words in the source text can significantly change the constructed graph, poison the GraphRAG, and severely mislead downstream reasoning. The first attack, named Targeted KPA (TKPA), utilizes graph-theoretic analysis to locate vulnerable nodes in the generated graphs and rewrites the corresponding narratives with LLMs, achieving precise control over specific question-answering (QA) outcomes with a success rate of 93.1\\%, while keeping the poisoned text fluent and natural. The second attack, named Universal KPA (UKPA), exploits linguistic cues such as pronouns and dependency relations to disrupt the structural integrity of the generated graph by altering globally influential words. With fewer than 0.05\\% of full text modified, the QA accuracy collapses from 95\\% to 50\\%. Furthermore, experiments show that state-of-the-art defense methods fail to detect these attacks, highlighting that securing GraphRAG pipelines against knowledge poisoning remains largely unexplored.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.04276.pdf", "abstract_url": "https://arxiv.org/abs/2508.04276", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了两种针对基于图的检索增强生成（GraphRAG）的知识投毒攻击（KPAs），通过修改源文本中的少量词语，能够显著改变构建的图结构，误导下游推理。实验表明，现有防御方法难以检测这些攻击。", "motivation": "GraphRAG依赖大型语言模型（LLMs）从原始文本中提取知识构建图，这一过程可能被恶意操纵植入误导信息。本文旨在探索如何通过知识投毒攻击破坏GraphRAG的可靠性和安全性。", "method": "提出了两种攻击方法：目标知识投毒攻击（TKPA）利用图论分析定位生成图中的脆弱节点，并通过LLMs重写相应叙述；通用知识投毒攻击（UKPA）利用语言线索破坏生成图的结构完整性。", "result": "TKPA在特定问答结果上实现了93.1%的成功率；UKPA仅修改不到0.05%的全文，问答准确率从95%降至50%。现有防御方法无法有效检测这些攻击。", "conclusion": "研究表明，GraphRAG管道在知识投毒攻击面前极为脆弱，当前防御措施不足，亟需进一步研究以提升其安全性。"}}
{"id": "2508.04369", "title": "TSPO: Temporal Sampling Policy Optimization for Long-form Video Language Understanding", "authors": ["Canhui Tang", "Zifan Han", "Hongbo Sun", "Sanping Zhou", "Xuchong Zhang", "Xin Wei", "Ye Yuan", "Jinglin Xu", "Hao Sun"], "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated significant progress in vision-language tasks, yet they still face challenges when processing long-duration video inputs. The limitation arises from MLLMs' context limit and training costs, necessitating sparse frame sampling before feeding videos into MLLMs. Existing video MLLMs adopt training-free uniform sampling or keyframe search, which may miss critical events or be constrained by the pre-trained models' event understanding capabilities. Meanwhile, building a training-based method remains challenging due to the unsupervised and non-differentiable nature of sparse frame sampling. To address these problems, we propose Temporal Sampling Policy Optimization (TSPO), advancing MLLMs' long-form video-language understanding via reinforcement learning. Specifically, we first propose a trainable event-aware temporal agent, which captures event-query correlation for performing probabilistic keyframe selection. Then, we propose the TSPO reinforcement learning paradigm, which models keyframe selection and language generation as a joint decision-making process, enabling end-to-end group relative optimization with efficient rule-based rewards. Furthermore, for the TSPO's training, we propose a long video training data construction pipeline with comprehensive temporal data and video Needle-in-a-Haystack data. Finally, we incorporate rule-based answering accuracy and temporal locating reward mechanisms to optimize the temporal sampling policy. Comprehensive experiments show that our TSPO achieves state-of-the-art performance across multiple long video understanding benchmarks, and shows transferable ability across different cutting-edge Video-MLLMs.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.04369.pdf", "abstract_url": "https://arxiv.org/abs/2508.04369", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了TSPO（时间采样策略优化）方法，通过强化学习提升多模态大语言模型（MLLMs）在长视频语言理解任务中的表现。TSPO包括一个可训练的事件感知时间代理和一个强化学习范式，能够端到端优化关键帧选择和语言生成过程。实验证明，TSPO在多个长视频理解基准测试中达到了最先进的性能。", "motivation": "多模态大语言模型（MLLMs）在处理长视频输入时面临上下文限制和训练成本的挑战，现有方法可能错过关键事件或受限于预训练模型的事件理解能力。", "method": "提出TSPO方法，包括一个可训练的事件感知时间代理和强化学习范式，通过强化学习联合优化关键帧选择和语言生成，并设计了基于规则的回答准确性和时间定位奖励机制。", "result": "TSPO在多个长视频理解基准测试中取得了最先进的性能，并显示出在不同前沿视频MLLMs中的可迁移能力。", "conclusion": "TSPO通过强化学习有效解决了长视频语言理解中的关键帧选择问题，为MLLMs在长视频处理中的应用提供了新的解决方案。"}}
{"id": "2508.04416", "title": "Thinking With Videos: Multimodal Tool-Augmented Reinforcement Learning for Long Video Reasoning", "authors": ["Haoji Zhang", "Xin Gu", "Jiawen Li", "Chixiang Ma", "Sule Bai", "Chubin Zhang", "Bowen Zhang", "Zhichao Zhou", "Dongliang He", "Yansong Tang"], "abstract": "The video reasoning ability of multimodal large language models (MLLMs) is crucial for downstream tasks like video question answering and temporal grounding. While recent approaches have explored text-based chain-of-thought (CoT) reasoning for MLLMs, these methods often suffer from limited cross-modal interaction and increased hallucination, especially with longer videos or reasoning chains. To address these challenges, we propose Video Intelligence via Tool-Augmented Learning (VITAL), a novel end-to-end agentic video reasoning framework. With a visual toolbox, the model can densely sample new video frames on demand and generate multimodal CoT for precise long video reasoning. We observe that temporal grounding and question answering are mutually beneficial for video understanding tasks. Therefore, we construct two high-quality multi-task video reasoning datasets MTVR-CoT-72k for supervised fine-tuning and MTVR-RL-110k for reinforcement learning. Moreover, we propose a Difficulty-aware Group Relative Policy Optimization algorithm (DGRPO) to mitigate difficulty imbalance in multi-task reinforcement learning. Extensive experiments on 11 challenging video understanding benchmarks demonstrate the advanced reasoning ability of VITAL, outperforming existing methods in video question answering and temporal grounding tasks, especially in long video scenarios. All code, data and model weight will be made publicly available.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.04416.pdf", "abstract_url": "https://arxiv.org/abs/2508.04416", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了VITAL，一种新颖的端到端代理视频推理框架，通过视觉工具箱密集采样新视频帧并生成多模态思维链，以提高长视频推理的精确性。", "motivation": "解决多模态大型语言模型在视频推理任务中跨模态交互有限和幻觉增加的问题，特别是在长视频或长推理链的情况下。", "method": "提出了Video Intelligence via Tool-Augmented Learning (VITAL)框架，利用视觉工具箱密集采样视频帧，生成多模态思维链，并采用Difficulty-aware Group Relative Policy Optimization算法(DGRPO)来缓解多任务强化学习中的难度不平衡问题。", "result": "在11个具有挑战性的视频理解基准测试中，VITAL在视频问答和时间定位任务中表现出先进的推理能力，尤其是在长视频场景中优于现有方法。", "conclusion": "VITAL框架通过工具增强学习和多模态思维链生成，显著提高了长视频推理的准确性和效率，为视频理解任务提供了新的解决方案。"}}
{"id": "2508.04390", "title": "AIC CTU@FEVER 8: On-premise fact checking through long context RAG", "authors": ["Herbert Ullrich", "Jan Drchal"], "abstract": "In this paper, we present our fact-checking pipeline which has scored first in FEVER 8 shared task. Our fact-checking system is a simple two-step RAG pipeline based on our last year's submission. We show how the pipeline can be redeployed on-premise, achieving state-of-the-art fact-checking performance (in sense of Ev2R test-score), even under the constraint of a single NVidia A10 GPU, 23GB of graphical memory and 60s running time per claim.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.04390.pdf", "abstract_url": "https://arxiv.org/abs/2508.04390", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了一个在FEVER 8共享任务中得分第一的事实核查管道，该管道基于去年的提交，是一个简单的两步RAG管道，展示了如何在单NVidia A10 GPU、23GB图形内存和每声明60秒运行时间的限制下，实现最先进的事实核查性能。", "motivation": "解决在有限计算资源下实现高效、准确的事实核查问题。", "method": "采用基于去年提交的两步RAG管道，优化后在单NVidia A10 GPU等限制条件下运行。", "result": "在FEVER 8共享任务中得分第一，实现了最先进的事实核查性能。", "conclusion": "即使在有限的计算资源下，通过优化的RAG管道也能实现高效、准确的事实核查，展示了其在实际应用中的潜力。"}}
{"id": "2508.04442", "title": "Automated Generation of Curriculum-Aligned Multiple-Choice Questions for Malaysian Secondary Mathematics Using Generative AI", "authors": ["Rohaizah Abdul Wahid", "Muhamad Said Nizamuddin Nadim", "Suliana Sulaiman", "Syahmi Akmal Shaharudin", "Muhammad Danial Jupikil", "Iqqwan Jasman Su Azlan Su"], "abstract": "This paper addresses the critical need for scalable and high-quality educational assessment tools within the Malaysian education system. It highlights the potential of Generative AI (GenAI) while acknowledging the significant challenges of ensuring factual accuracy and curriculum alignment, especially for low-resource languages like Bahasa Melayu. This research introduces and compares four incremental pipelines for generating Form 1 Mathematics multiple-choice questions (MCQs) in Bahasa Melayu using OpenAI's GPT-4o. The methods range from non-grounded prompting (structured and basic) to Retrieval-Augmented Generation (RAG) approaches (one using the LangChain framework, one implemented manually). The system is grounded in official curriculum documents, including teacher-prepared notes and the yearly teaching plan (RPT). A dual-pronged automated evaluation framework is employed to assess the generated questions. Curriculum alignment is measured using Semantic Textual Similarity (STS) against the RPT, while contextual validity is verified through a novel RAG-based Question-Answering (RAG-QA) method. The results demonstrate that RAG-based pipelines significantly outperform non-grounded prompting methods, producing questions with higher curriculum alignment and factual validity. The study further analyzes the trade-offs between the ease of implementation of framework-based RAG and the fine-grained control offered by a manual pipeline. This work presents a validated methodology for generating curriculum-specific educational content in a low-resource language, introduces a symbiotic RAG-QA evaluation technique, and provides actionable insights for the development and deployment of practical EdTech solutions in Malaysia and similar regions.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.04442.pdf", "abstract_url": "https://arxiv.org/abs/2508.04442", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文探讨了利用生成式AI（GenAI）为马来西亚中学数学自动生成与课程对齐的多选题（MCQs）的方法，比较了四种不同的生成管道，并展示了基于检索增强生成（RAG）的方法在课程对齐和事实有效性上的优越性。", "motivation": "解决马来西亚教育系统中高质量教育评估工具的可扩展性需求，特别是在低资源语言如Bahasa Melayu中确保事实准确性和课程对齐的挑战。", "method": "研究引入了四种增量管道，包括非基础提示（结构化和基础）和基于检索增强生成（RAG）的方法（一种使用LangChain框架，一种手动实现），并基于官方课程文档进行。", "result": "结果表明，基于RAG的管道在课程对齐和事实有效性上显著优于非基础提示方法。", "conclusion": "本研究为低资源语言生成课程特定的教育内容提供了验证的方法论，引入了RAG-QA评估技术，并为马来西亚及类似地区的EdTech解决方案的开发提供了实用见解。"}}
{"id": "2508.04423", "title": "Evaluating, Synthesizing, and Enhancing for Customer Support Conversation", "authors": ["Jie Zhu", "Huaixia Dou", "Junhui Li", "Lifan Guo", "Feng Chen", "Chi Zhang", "Fang Kong"], "abstract": "Effective customer support requires not only accurate problem solving but also structured and empathetic communication aligned with professional standards. However, existing dialogue datasets often lack strategic guidance, and real-world service data is difficult to access and annotate. To address this, we introduce the task of Customer Support Conversation (CSC), aimed at training customer service agents to respond using well-defined support strategies. We propose a structured CSC framework grounded in COPC guidelines, defining five conversational stages and twelve strategies to guide high-quality interactions. Based on this, we construct CSConv, an evaluation dataset of 1,855 real-world customer-agent conversations rewritten using LLMs to reflect deliberate strategy use, and annotated accordingly. Additionally, we develop a role-playing approach that simulates strategy-rich conversations using LLM-powered roles aligned with the CSC framework, resulting in the training dataset RoleCS. Experiments show that fine-tuning strong LLMs on RoleCS significantly improves their ability to generate high-quality, strategy-aligned responses on CSConv. Human evaluations further confirm gains in problem resolution. All code and data will be made publicly available at", "subjects": "Computation and Language (cs.CL)", "comments": "under review", "pdf_url": "https://arxiv.org/pdf/2508.04423.pdf", "abstract_url": "https://arxiv.org/abs/2508.04423", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了客户支持对话（CSC）任务，旨在通过明确的策略指导训练客服代理。提出了基于COPC指南的结构化CSC框架，构建了CSConv评估数据集和RoleCS训练数据集，实验证明在RoleCS上微调的大型语言模型能显著提高生成策略对齐的高质量响应能力。", "motivation": "解决现有对话数据集缺乏战略指导和真实世界服务数据难以获取和标注的问题，以提升客户支持对话的质量和效率。", "method": "提出基于COPC指南的结构化CSC框架，定义五个对话阶段和十二种策略；构建CSConv评估数据集和通过LLM模拟策略丰富对话的RoleCS训练数据集。", "result": "在RoleCS上微调的大型语言模型显著提高了生成策略对齐的高质量响应的能力，人类评估进一步证实了问题解决的提升。", "conclusion": "通过结构化框架和策略指导，结合LLM技术，可以有效提升客户支持对话的质量和问题解决效率，所有代码和数据将公开。"}}
{"id": "2508.04575", "title": "Beyond Brainstorming: What Drives High-Quality Scientific Ideas? Lessons from Multi-Agent Collaboration", "authors": ["Nuo Chen", "Yicheng Tong", "Jiaying Wu", "Minh Duc Duong", "Qian Wang", "Qingyun Zou", "Bryan Hooi", "Bingsheng He"], "abstract": "While AI agents show potential in scientific ideation, most existing frameworks rely on single-agent refinement, limiting creativity due to bounded knowledge and perspective. Inspired by real-world research dynamics, this paper investigates whether structured multi-agent discussions can surpass solitary ideation. We propose a cooperative multi-agent framework for generating research proposals and systematically compare configurations including group size, leaderled versus leaderless structures, and team compositions varying in interdisciplinarity and seniority. To assess idea quality, we employ a comprehensive protocol with agent-based scoring and human review across dimensions such as novelty, strategic vision, and integration depth. Our results show that multi-agent discussions substantially outperform solitary baselines. A designated leader acts as a catalyst, transforming discussion into more integrated and visionary proposals. Notably, we find that cognitive diversity is a primary driver of quality, yet expertise is a non-negotiable prerequisite, as teams lacking a foundation of senior knowledge fail to surpass even a single competent agent. These findings offer actionable insights for designing collaborative AI ideation systems and shed light on how team structure influences creative outcomes.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "comments": "Preprint", "pdf_url": "https://arxiv.org/pdf/2508.04575.pdf", "abstract_url": "https://arxiv.org/abs/2508.04575", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了多智能体协作在科学创意生成中的优势，提出了一个合作多智能体框架，并比较了不同配置对研究提案质量的影响。结果表明，多智能体讨论显著优于单智能体基线，认知多样性是质量的主要驱动力，但专业知识是必不可少的先决条件。", "motivation": "现有的科学创意生成框架大多依赖单智能体细化，由于知识和视角的局限性，限制了创造力。本文旨在探索结构化多智能体讨论是否能超越单独的创意生成。", "method": "提出了一个合作多智能体框架，用于生成研究提案，并系统比较了包括团队规模、有无领导结构以及团队组成（跨学科性和资历）在内的不同配置。使用基于智能体的评分和人类评审的全面协议来评估创意质量。", "result": "多智能体讨论显著优于单智能体基线。指定的领导者作为催化剂，将讨论转化为更整合和有远见的提案。认知多样性是质量的主要驱动力，但缺乏资深知识的团队甚至无法超越一个有能力单智能体。", "conclusion": "这些发现为设计协作AI创意生成系统提供了可行的见解，并揭示了团队结构如何影响创意成果。"}}
{"id": "2508.04604", "title": "TURA: Tool-Augmented Unified Retrieval Agent for AI Search", "authors": ["Zhejun Zhao", "Yuehu Dong", "Alley Liu", "Lixue Zheng", "Pingsheng Liu", "Dongdong Shen", "Long Xia", "Jiashu Zhao", "Dawei Yin"], "abstract": "The advent of Large Language Models (LLMs) is transforming search engines into conversational AI search products, primarily using Retrieval-Augmented Generation (RAG) on web corpora. However, this paradigm has significant industrial limitations. Traditional RAG approaches struggle with real-time needs and structured queries that require accessing dynamically generated content like ticket availability or inventory. Limited to indexing static pages, search engines cannot perform the interactive queries needed for such time-sensitive data. Academic research has focused on optimizing RAG for static content, overlooking complex intents and the need for dynamic sources like databases and real-time APIs. To bridge this gap, we introduce TURA (Tool-Augmented Unified Retrieval Agent for AI Search), a novel three-stage framework that combines RAG with agentic tool-use to access both static content and dynamic, real-time information. TURA has three key components: an Intent-Aware Retrieval module to decompose queries and retrieve information sources encapsulated as Model Context Protocol (MCP) Servers, a DAG-based Task Planner that models task dependencies as a Directed Acyclic Graph (DAG) for optimal parallel execution, and a lightweight Distilled Agent Executor for efficient tool calling. TURA is the first architecture to systematically bridge the gap between static RAG and dynamic information sources for a world-class AI search product. Serving tens of millions of users, it leverages an agentic framework to deliver robust, real-time answers while meeting the low-latency demands of a large-scale industrial system.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.04604.pdf", "abstract_url": "https://arxiv.org/abs/2508.04604", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["agent", "agentic", "@RAG"], "AI": {"tldr": "本文介绍了TURA（工具增强的统一检索代理），一个结合了检索增强生成（RAG）和代理工具使用的三阶段框架，旨在解决传统RAG方法在处理实时需求和结构化查询时的局限性。", "motivation": "传统RAG方法在处理实时需求和结构化查询时存在局限，无法有效访问动态生成的内容，如票务可用性或库存。", "method": "TURA框架包含三个关键组件：意图感知检索模块、基于DAG的任务规划器和轻量级蒸馏代理执行器，用于结合静态内容和动态实时信息。", "result": "TURA是第一个系统性地桥接静态RAG和动态信息源的架构，服务于数千万用户，满足大规模工业系统的低延迟需求。", "conclusion": "TURA通过代理框架提供了强大、实时的答案，同时满足了大规模工业系统的低延迟需求，为AI搜索产品开辟了新方向。"}}
{"id": "2508.04524", "title": "RAIDX: A Retrieval-Augmented Generation and GRPO Reinforcement Learning Framework for Explainable Deepfake Detection", "authors": ["Tianxiao Li", "Zhenglin Huang", "Haiquan Wen", "Yiwei He", "Shuchang Lyu", "Baoyuan Wu", "Guangliang Cheng"], "abstract": "The rapid advancement of AI-generation models has enabled the creation of hyperrealistic imagery, posing ethical risks through widespread misinformation. Current deepfake detection methods, categorized as face specific detectors or general AI-generated detectors, lack transparency by framing detection as a classification task without explaining decisions. While several LLM-based approaches offer explainability, they suffer from coarse-grained analyses and dependency on labor-intensive annotations. This paper introduces RAIDX (Retrieval-Augmented Image Deepfake Detection and Explainability), a novel deepfake detection framework integrating Retrieval-Augmented Generation (RAG) and Group Relative Policy Optimization (GRPO) to enhance detection accuracy and decision explainability. Specifically, RAIDX leverages RAG to incorporate external knowledge for improved detection accuracy and employs GRPO to autonomously generate fine-grained textual explanations and saliency maps, eliminating the need for extensive manual annotations. Experiments on multiple benchmarks demonstrate RAIDX's effectiveness in identifying real or fake, and providing interpretable rationales in both textual descriptions and saliency maps, achieving state-of-the-art detection performance while advancing transparency in deepfake identification. RAIDX represents the first unified framework to synergize RAG and GRPO, addressing critical gaps in accuracy and explainability. Our code and models will be publicly available.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.04524.pdf", "abstract_url": "https://arxiv.org/abs/2508.04524", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "RAIDX是一个结合检索增强生成（RAG）和组相对策略优化（GRPO）的新颖深度伪造检测框架，旨在提高检测准确性和决策可解释性。", "motivation": "当前深度伪造检测方法缺乏透明度，且现有的基于LLM的方法存在粗粒度分析和依赖劳动密集型注释的问题。", "method": "RAIDX利用RAG整合外部知识以提高检测准确性，并采用GRPO自动生成细粒度文本解释和显著性图，无需大量手动注释。", "result": "在多个基准测试中，RAIDX在识别真实或伪造内容及提供可解释的文本描述和显著性图方面表现出色，达到了最先进的检测性能。", "conclusion": "RAIDX是首个统一RAG和GRPO的框架，解决了准确性和可解释性方面的关键差距，推动了深度伪造识别的透明度。"}}
{"id": "2508.03777", "title": "When Agents Break Down in Multiagent Path Finding", "authors": ["Foivos Fioravantes", "Dušan Knop", "Nikolaos Melissinos", "Michal Opler"], "abstract": "In Multiagent Path Finding (MAPF), the goal is to compute efficient, collision-free paths for multiple agents navigating a network from their sources to targets, minimizing the schedule's makespan-the total time until all agents reach their destinations. We introduce a new variant that formally models scenarios where some agents may experience delays due to malfunctions, posing significant challenges for maintaining optimal schedules.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.03777.pdf", "abstract_url": "https://arxiv.org/abs/2508.03777", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了多智能体路径规划（MAPF）中的一个新变体，该变体正式模拟了由于故障导致部分智能体延迟的情景，这对维持最优调度提出了重大挑战。", "motivation": "解决在多智能体路径规划中，部分智能体因故障延迟时，如何维持最优调度的问题。", "method": "引入了一个新的MAPF变体，正式模拟智能体因故障延迟的情景。", "result": "提出了一个能够处理智能体延迟的MAPF模型，为相关研究提供了新的视角和方法。", "conclusion": "该研究为多智能体路径规划中的智能体延迟问题提供了理论基础，对实际应用中的调度优化具有重要意义。"}}
{"id": "2508.03783", "title": "Probing and Enhancing the Robustness of GNN-based QEC Decoders with Reinforcement Learning", "authors": ["Ryota Ikeda"], "abstract": "Graph Neural Networks (GNNs) have emerged as a powerful, data-driven approach for Quantum Error Correction (QEC) decoding, capable of learning complex noise characteristics directly from syndrome data. However, the robustness of these decoders against subtle, adversarial perturbations remains a critical open question. This work introduces a novel framework to systematically probe the vulnerabilities of a GNN decoder using a reinforcement learning (RL) agent. The RL agent is trained as an adversary with the goal of finding minimal syndrome modifications that cause the decoder to misclassify. We apply this framework to a Graph Attention Network (GAT) decoder trained on experimental surface code data from Google Quantum AI. Our results show that the RL agent can successfully identify specific, critical vulnerabilities, achieving a high attack success rate with a minimal number of bit flips. Furthermore, we demonstrate that the decoder's robustness can be significantly enhanced through adversarial training, where the model is retrained on the adversarial examples generated by the RL agent. This iterative process of automated vulnerability discovery and targeted retraining presents a promising methodology for developing more reliable and robust neural network decoders for fault-tolerant quantum computing.", "subjects": "Quantum Physics (quant-ph); Artificial Intelligence (cs.AI)", "comments": "4 pages, 3 figures, Affiliation updated to match user registration", "pdf_url": "https://arxiv.org/pdf/2508.03783.pdf", "abstract_url": "https://arxiv.org/abs/2508.03783", "categories": ["Quantum Physics (quant-ph)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一种新颖的框架，通过强化学习（RL）代理系统地探测图神经网络（GNN）解码器在量子纠错（QEC）中的脆弱性，并提出通过对抗训练显著增强解码器的鲁棒性。", "motivation": "解决GNN解码器在量子纠错中对微妙、对抗性扰动的鲁棒性问题。", "method": "使用强化学习代理作为对手，寻找最小的综合征修改，使解码器误分类，并通过对抗训练增强解码器的鲁棒性。", "result": "RL代理能成功识别特定的关键脆弱性，以最少的比特翻转实现高攻击成功率；对抗训练显著提高了解码器的鲁棒性。", "conclusion": "通过自动化的脆弱性发现和针对性再训练的方法，为开发更可靠、鲁棒的神经网络解码器提供了有前景的途径。"}}
{"id": "2508.03818", "title": "Mechanism Design for Facility Location using Predictions", "authors": ["Toby Walsh"], "abstract": "We study mechanisms for the facility location problem augmented with predictions of the optimal facility location. We demonstrate that an egalitarian viewpoint which considers both the maximum distance of any agent from the facility and the minimum utility of any agent provides important new insights compared to a viewpoint that just considers the maximum distance. As in previous studies, we consider performance in terms of consistency (worst case when predictions are accurate) and robustness (worst case irrespective of the accuracy of predictions). By considering how mechanisms with predictions can perform poorly, we design new mechanisms that are more robust. Indeed, by adjusting parameters, we demonstrate how to trade robustness for consistency. We go beyond the single facility problem by designing novel strategy proof mechanisms for locating two facilities with bounded consistency and robustness that use two predictions for where to locate the two facilities.", "subjects": "Computer Science and Game Theory (cs.GT); Artificial Intelligence (cs.AI)", "comments": "To appear in Proceedings oj IJCAI 2025 workshop on Computational Fair Division", "pdf_url": "https://arxiv.org/pdf/2508.03818.pdf", "abstract_url": "https://arxiv.org/abs/2508.03818", "categories": ["Computer Science and Game Theory (cs.GT)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究了利用预测最优设施位置的机制设计问题，通过考虑代理人与设施的最大距离和最小效用，提出了比仅考虑最大距离更全面的视角。设计了新的机制以提高鲁棒性，并通过调整参数在鲁棒性和一致性之间进行权衡。此外，还设计了使用两个预测位置的双设施策略证明机制。", "motivation": "解决设施位置问题中如何利用预测信息设计更有效的机制，特别是在预测准确性和鲁棒性之间找到平衡。", "method": "采用机制设计方法，结合预测信息，考虑最大距离和最小效用，设计新的机制并通过参数调整权衡一致性和鲁棒性。", "result": "提出了新的机制，能够在预测准确时表现良好（一致性），同时在预测不准确时也能保持一定的性能（鲁棒性），并成功扩展到双设施问题。", "conclusion": "通过综合考虑最大距离和最小效用，以及利用预测信息，可以设计出在一致性和鲁棒性之间灵活权衡的设施定位机制，为设施位置问题提供了新的解决方案。"}}
{"id": "2508.03936", "title": "ASTRA: Autonomous Spatial-Temporal Red-teaming for AI Software Assistants", "authors": ["Xiangzhe Xu", "Guangyu Shen", "Zian Su", "Siyuan Cheng", "Hanxi Guo", "Lu Yan", "Xuan Chen", "Jiasheng Jiang", "Xiaolong Jin", "Chengpeng Wang", "Zhuo Zhang", "Xiangyu Zhang"], "abstract": "AI coding assistants like GitHub Copilot are rapidly transforming software development, but their safety remains deeply uncertain-especially in high-stakes domains like cybersecurity. Current red-teaming tools often rely on fixed benchmarks or unrealistic prompts, missing many real-world vulnerabilities. We present ASTRA, an automated agent system designed to systematically uncover safety flaws in AI-driven code generation and security guidance systems. ASTRA works in three stages: (1) it builds structured domain-specific knowledge graphs that model complex software tasks and known weaknesses; (2) it performs online vulnerability exploration of each target model by adaptively probing both its input space, i.e., the spatial exploration, and its reasoning processes, i.e., the temporal exploration, guided by the knowledge graphs; and (3) it generates high-quality violation-inducing cases to improve model alignment. Unlike prior methods, ASTRA focuses on realistic inputs-requests that developers might actually ask-and uses both offline abstraction guided domain modeling and online domain knowledge graph adaptation to surface corner-case vulnerabilities. Across two major evaluation domains, ASTRA finds 11-66% more issues than existing techniques and produces test cases that lead to 17% more effective alignment training, showing its practical value for building safer AI systems.", "subjects": "Cryptography and Security (cs.CR); Computation and Language (cs.CL); Machine Learning (cs.LG); Software Engineering (cs.SE)", "comments": "The first two authors (Xiangzhe Xu and Guangyu Shen) contributed equally to this work", "pdf_url": "https://arxiv.org/pdf/2508.03936.pdf", "abstract_url": "https://arxiv.org/abs/2508.03936", "categories": ["Cryptography and Security (cs.CR)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)", "Software Engineering (cs.SE)"], "matching_keywords": ["agent"], "AI": {"tldr": "ASTRA是一种自动化代理系统，旨在系统地发现AI驱动的代码生成和安全指导系统中的安全缺陷。它通过构建特定领域的知识图谱、在线漏洞探索和生成高质量的违规案例来提高模型的对齐性。", "motivation": "解决AI编码助手（如GitHub Copilot）在软件开发中的安全性问题，特别是在网络安全等高风险领域，当前的红队工具依赖固定基准或不现实的提示，无法发现许多现实世界中的漏洞。", "method": "ASTRA通过三个阶段工作：(1)构建结构化领域特定知识图谱；(2)在线漏洞探索，包括空间探索和时间探索；(3)生成高质量的违规案例以提高模型对齐。", "result": "在两个主要评估领域，ASTRA发现的问题比现有技术多11-66%，生成的测试案例使对齐训练效果提高了17%。", "conclusion": "ASTRA对于构建更安全的AI系统具有实际价值，特别是在发现和修复AI编码助手的安全漏洞方面。"}}
{"id": "2508.04681", "title": "Perceiving and Acting in First-Person: A Dataset and Benchmark for Egocentric Human-Object-Human Interactions", "authors": ["Liang Xu", "Chengqun Yang", "Zili Lin", "Fei Xu", "Yifan Liu", "Congsheng Xu", "Yiyi Zhang", "Jie Qin", "Xingdong Sheng", "Yunhui Liu", "Xin Jin", "Yichao Yan", "Wenjun Zeng", "Xiaokang Yang"], "abstract": "Learning action models from real-world human-centric interaction datasets is important towards building general-purpose intelligent assistants with efficiency. However, most existing datasets only offer specialist interaction category and ignore that AI assistants perceive and act based on first-person acquisition. We urge that both the generalist interaction knowledge and egocentric modality are indispensable. In this paper, we embed the manual-assisted task into a vision-language-action framework, where the assistant provides services to the instructor following egocentric vision and commands. With our hybrid RGB-MoCap system, pairs of assistants and instructors engage with multiple objects and the scene following GPT-generated scripts. Under this setting, we accomplish InterVLA, the first large-scale human-object-human interaction dataset with 11.4 hours and 1.2M frames of multimodal data, spanning 2 egocentric and 5 exocentric videos, accurate human/object motions and verbal commands. Furthermore, we establish novel benchmarks on egocentric human motion estimation, interaction synthesis, and interaction prediction with comprehensive analysis. We believe that our InterVLA testbed and the benchmarks will foster future works on building AI agents in the physical world.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2508.04681.pdf", "abstract_url": "https://arxiv.org/abs/2508.04681", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了InterVLA，第一个大规模的人-物-人交互数据集，包含11.4小时和120万帧的多模态数据，支持以自我为中心的视角和命令，旨在促进物理世界中AI代理的研究。", "motivation": "解决现有数据集在通用交互知识和以自我为中心的模态方面的不足，以构建更高效的通用智能助手。", "method": "通过混合RGB-MoCap系统，助手和指导者按照GPT生成的脚本与多个对象和场景互动，收集多模态数据。", "result": "创建了InterVLA数据集，并建立了以自我为中心的人体运动估计、交互合成和交互预测的新基准。", "conclusion": "InterVLA测试平台和基准将推动未来在物理世界中构建AI代理的研究。"}}
{"id": "2508.04682", "title": "TurboTrain: Towards Efficient and Balanced Multi-Task Learning for Multi-Agent Perception and Prediction", "authors": ["Zewei Zhou", "Seth Z. Zhao", "Tianhui Cai", "Zhiyu Huang", "Bolei Zhou", "Jiaqi Ma"], "abstract": "End-to-end training of multi-agent systems offers significant advantages in improving multi-task performance. However, training such models remains challenging and requires extensive manual design and monitoring. In this work, we introduce TurboTrain, a novel and efficient training framework for multi-agent perception and prediction. TurboTrain comprises two key components: a multi-agent spatiotemporal pretraining scheme based on masked reconstruction learning and a balanced multi-task learning strategy based on gradient conflict suppression. By streamlining the training process, our framework eliminates the need for manually designing and tuning complex multi-stage training pipelines, substantially reducing training time and improving performance. We evaluate TurboTrain on a real-world cooperative driving dataset, V2XPnP-Seq, and demonstrate that it further improves the performance of state-of-the-art multi-agent perception and prediction models. Our results highlight that pretraining effectively captures spatiotemporal multi-agent features and significantly benefits downstream tasks. Moreover, the proposed balanced multi-task learning strategy enhances detection and prediction.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "ICCV 2025", "pdf_url": "https://arxiv.org/pdf/2508.04682.pdf", "abstract_url": "https://arxiv.org/abs/2508.04682", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "TurboTrain是一种新颖且高效的训练框架，用于多智能体感知和预测，通过多智能体时空预训练方案和基于梯度冲突抑制的平衡多任务学习策略，简化了训练过程，提高了性能。", "motivation": "多智能体系统的端到端训练在提高多任务性能方面具有显著优势，但训练此类模型仍然具有挑战性，需要大量手动设计和监控。", "method": "TurboTrain包括两个关键组件：基于掩码重建学习的多智能体时空预训练方案和基于梯度冲突抑制的平衡多任务学习策略。", "result": "在真实世界的协作驾驶数据集V2XPnP-Seq上评估TurboTrain，结果表明它进一步提高了最先进的多智能体感知和预测模型的性能。", "conclusion": "预训练有效地捕获了时空多智能体特征，并显著有益于下游任务，同时提出的平衡多任务学习策略增强了检测和预测。"}}
{"id": "2508.04495", "title": "Causal Reflection with Language Models", "authors": ["Abi Aryan", "Zac Liu"], "abstract": "While LLMs exhibit impressive fluency and factual recall, they struggle with robust causal reasoning, often relying on spurious correlations and brittle patterns. Similarly, traditional Reinforcement Learning agents also lack causal understanding, optimizing for rewards without modeling why actions lead to outcomes. We introduce Causal Reflection, a framework that explicitly models causality as a dynamic function over state, action, time, and perturbation, enabling agents to reason about delayed and nonlinear effects. Additionally, we define a formal Reflect mechanism that identifies mismatches between predicted and observed outcomes and generates causal hypotheses to revise the agent's internal model. In this architecture, LLMs serve not as black-box reasoners, but as structured inference engines translating formal causal outputs into natural language explanations and counterfactuals. Our framework lays the theoretical groundwork for Causal Reflective agents that can adapt, self-correct, and communicate causal understanding in evolving environments.", "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.04495.pdf", "abstract_url": "https://arxiv.org/abs/2508.04495", "categories": ["Machine Learning (cs.LG)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了'因果反射'框架，旨在解决大型语言模型（LLMs）和传统强化学习代理在因果推理上的不足，通过明确建模因果关系和引入反射机制，使代理能够适应、自我修正并在变化的环境中传达因果理解。", "motivation": "大型语言模型（LLMs）和传统强化学习代理在因果推理上存在不足，常常依赖于虚假的相关性和脆弱的模式，缺乏对因果关系的深入理解。", "method": "提出了'因果反射'框架，明确将因果关系建模为状态、行动、时间和扰动的动态函数，并定义了一个正式的反射机制来识别预测与观察结果之间的不匹配，并生成因果假设以修订代理的内部模型。", "result": "该框架为能够适应、自我修正并在变化的环境中传达因果理解的'因果反射'代理奠定了理论基础。", "conclusion": "'因果反射'框架通过明确建模因果关系和引入反射机制，显著提升了代理在因果推理上的能力，为未来的研究和应用提供了新的方向。"}}
{"id": "2508.04231", "title": "Empowering Time Series Forecasting with LLM-Agents", "authors": ["Chin-Chia Michael Yeh", "Vivian Lai", "Uday Singh Saini", "Xiran Fan", "Yujie Fan", "Junpeng Wang", "Xin Dai", "Yan Zheng"], "abstract": "Large Language Model (LLM) powered agents have emerged as effective planners for Automated Machine Learning (AutoML) systems. While most existing AutoML approaches focus on automating feature engineering and model architecture search, recent studies in time series forecasting suggest that lightweight models can often achieve state-of-the-art performance. This observation led us to explore improving data quality, rather than model architecture, as a potentially fruitful direction for AutoML on time series data. We propose DCATS, a Data-Centric Agent for Time Series. DCATS leverages metadata accompanying time series to clean data while optimizing forecasting performance. We evaluated DCATS using four time series forecasting models on a large-scale traffic volume forecasting dataset. Results demonstrate that DCATS achieves an average 6% error reduction across all tested models and time horizons, highlighting the potential of data-centric approaches in AutoML for time series forecasting.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.04231.pdf", "abstract_url": "https://arxiv.org/abs/2508.04231", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为DCATS的数据中心代理，用于时间序列预测，通过利用时间序列的元数据来清理数据并优化预测性能，实验证明DCATS在所有测试模型和时间范围内平均减少了6%的误差。", "motivation": "现有的AutoML方法主要集中在自动化特征工程和模型架构搜索上，而近期研究表明轻量级模型在时间序列预测中常能达到最先进的性能。这促使我们探索通过提高数据质量而非模型架构来改进AutoML在时间序列数据上的应用。", "method": "我们提出了DCATS（数据中心代理时间序列），它利用时间序列的元数据来清理数据，同时优化预测性能。", "result": "在一个大规模交通流量预测数据集上使用四种时间序列预测模型评估DCATS，结果显示DCATS在所有测试模型和时间范围内平均减少了6%的误差。", "conclusion": "这突出了数据中心方法在时间序列预测AutoML中的潜力，表明通过提高数据质量可以有效地提升预测性能。"}}
{"id": "2508.04418", "title": "Think Before You Segment: An Object-aware Reasoning Agent for Referring Audio-Visual Segmentation", "authors": ["Jinxing Zhou", "Yanghao Zhou", "Mingfei Han", "Tong Wang", "Xiaojun Chang", "Hisham Cholakkal", "Rao Muhammad Anwer"], "abstract": "Referring Audio-Visual Segmentation (Ref-AVS) aims to segment target objects in audible videos based on given reference expressions. Prior works typically rely on learning latent embeddings via multimodal fusion to prompt a tunable SAM/SAM2 decoder for segmentation, which requires strong pixel-level supervision and lacks interpretability. From a novel perspective of explicit reference understanding, we propose TGS-Agent, which decomposes the task into a Think-Ground-Segment process, mimicking the human reasoning procedure by first identifying the referred object through multimodal analysis, followed by coarse-grained grounding and precise segmentation. To this end, we first propose Ref-Thinker, a multimodal language model capable of reasoning over textual, visual, and auditory cues. We construct an instruction-tuning dataset with explicit object-aware think-answer chains for Ref-Thinker fine-tuning. The object description inferred by Ref-Thinker is used as an explicit prompt for Grounding-DINO and SAM2, which perform grounding and segmentation without relying on pixel-level supervision. Additionally, we introduce R\\textsuperscript{2}-AVSBench, a new benchmark with linguistically diverse and reasoning-intensive references for better evaluating model generalization. Our approach achieves state-of-the-art results on both standard Ref-AVSBench and proposed R\\textsuperscript{2}-AVSBench. Code will be available at", "subjects": "Multimedia (cs.MM); Computer Vision and Pattern Recognition (cs.CV); Multiagent Systems (cs.MA); Sound (cs.SD); Audio and Speech Processing (eess.AS)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2508.04418.pdf", "abstract_url": "https://arxiv.org/abs/2508.04418", "categories": ["Multimedia (cs.MM)", "Computer Vision and Pattern Recognition (cs.CV)", "Multiagent Systems (cs.MA)", "Sound (cs.SD)", "Audio and Speech Processing (eess.AS)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为TGS-Agent的新型方法，用于解决参考音频视觉分割（Ref-AVS）任务，该方法通过模仿人类推理过程，将任务分解为Think-Ground-Segment三个步骤，显著提高了模型的解释性和性能。", "motivation": "现有的Ref-AVS方法通常依赖于通过多模态融合学习潜在嵌入来提示可调谐的SAM/SAM2解码器进行分割，这种方法需要强像素级监督且缺乏解释性。本文旨在从显式参考理解的新视角出发，提出一种更高效、更可解释的解决方案。", "method": "本文提出的TGS-Agent方法将Ref-AVS任务分解为Think-Ground-Segment三个步骤：首先通过多模态分析识别被引用的对象，然后进行粗粒度定位，最后进行精确分割。为此，作者首先提出了Ref-Thinker，一个能够对文本、视觉和听觉线索进行推理的多模态语言模型，并构建了一个带有显式对象感知思维答案链的指令调优数据集用于Ref-Thinker的微调。", "result": "TGS-Agent方法在标准的Ref-AVSBench和新提出的R²-AVSBench上都达到了最先进的性能，证明了其有效性。", "conclusion": "本文通过模仿人类推理过程，提出了一种新的Ref-AVS方法，不仅提高了模型的解释性和性能，还通过引入新的基准测试R²-AVSBench，为未来的研究提供了更好的评估工具。"}}
{"id": "2508.04556", "title": "CONVERGE: A Multi-Agent Vision-Radio Architecture for xApps", "authors": ["Filipe B. Teixeira", "Carolina Simões", "Paulo Fidalgo", "Wagner Pedrosa", "André Coelho", "Manuel Ricardo", "Luis M. Pessoa"], "abstract": "Telecommunications and computer vision have evolved independently. With the emergence of high-frequency wireless links operating mostly in line-of-sight, visual data can help predict the channel dynamics by detecting obstacles and help overcoming them through beamforming or handover techniques.", "subjects": "Networking and Internet Architecture (cs.NI); Computer Vision and Pattern Recognition (cs.CV)", "comments": "7 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2508.04556.pdf", "abstract_url": "https://arxiv.org/abs/2508.04556", "categories": ["Networking and Internet Architecture (cs.NI)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为CONVERGE的多代理视觉-无线电架构，旨在通过视觉数据预测高频无线链路的信道动态，以检测障碍并通过波束成形或切换技术克服它们。", "motivation": "电信和计算机视觉领域长期以来独立发展。随着高频无线链路的出现，这些链路主要在视线内操作，视觉数据可以帮助预测信道动态，检测障碍，并通过技术手段如波束成形或切换来克服这些障碍。", "method": "采用多代理视觉-无线电架构，结合视觉数据和无线电技术，预测和应对高频无线链路中的信道动态和障碍。", "result": "通过视觉数据有效预测信道动态，实现了通过波束成形或切换技术克服障碍的目标。", "conclusion": "CONVERGE架构为高频无线链路的稳定运行提供了一种有效的解决方案，通过结合视觉和无线电技术，克服了视线操作中的障碍问题。"}}
{"id": "2508.04280", "title": "Enhancing Vision-Language Model Training with Reinforcement Learning in Synthetic Worlds for Real-World Success", "authors": ["George Bredis", "Stanislav Dereka", "Viacheslav Sinii", "Ruslan Rakhimov", "Daniil Gavrilov"], "abstract": "Interactive multimodal agents must convert raw visual observations into coherent sequences of language-conditioned actions -- a capability that current vision-language models (VLMs) still lack. Earlier reinforcement-learning (RL) efforts could, in principle, endow VLMs with such skills, but they have seldom tested whether the learned behaviours generalize beyond their training simulators, and they depend either on brittle hyperparameter tuning or on dense-reward environments with low state variability. We introduce Vision-Language Decoupled Actor-Critic (VL-DAC), a lightweight, hyperparameter-free RL algorithm. VL-DAC applies PPO updates to action tokens while learning value only at the environment-step level: an arrangement, to our knowledge, not previously explored for large VLMs or LLMs. This simple decoupling removes unstable weighting terms and yields faster, more reliable convergence. Training a single VLM with VL-DAC in one inexpensive simulator at a time (MiniWorld, Gym-Cards, ALFWorld, or WebShop) already produces policies that generalize widely: +50\\% relative on BALROG (game-centric agentic control), +5\\% relative on the hardest part of VSI-Bench (spatial planning), and +2\\% on VisualWebBench (web navigation), all without degrading general image understanding accuracy. These results provide the first evidence that a simple RL algorithm can train VLMs entirely in cheap synthetic worlds while delivering measurable gains on real-image agentic, spatial-reasoning, and web-navigation benchmarks.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.04280.pdf", "abstract_url": "https://arxiv.org/abs/2508.04280", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了VL-DAC，一种轻量级、无超参数的强化学习算法，用于增强视觉语言模型（VLM）的训练。通过在合成世界中使用VL-DAC训练VLM，能够在真实世界的代理控制、空间规划和网页导航等任务中实现显著的性能提升。", "motivation": "当前视觉语言模型缺乏将原始视觉观察转换为语言条件动作序列的能力，且以往的强化学习方法在训练模拟器外的泛化能力有限，依赖于脆弱的超参数调整或低状态变异性的密集奖励环境。", "method": "提出了Vision-Language Decoupled Actor-Critic (VL-DAC)算法，该算法在动作令牌上应用PPO更新，同时仅在环境步骤级别学习价值，这种简单的解耦去除了不稳定的加权项，实现了更快、更可靠的收敛。", "result": "在多个合成模拟器（MiniWorld、Gym-Cards、ALFWorld、WebShop）中训练VLM，能够在BALROG（游戏中心代理控制）、VSI-Bench（空间规划的最难部分）和VisualWebBench（网页导航）上分别实现+50%、+5%和+2%的相对性能提升，且不降低一般图像理解的准确性。", "conclusion": "这是首次证明简单的强化学习算法可以在廉价的合成世界中完全训练VLM，同时在真实图像的代理控制、空间推理和网页导航基准上提供可衡量的增益。"}}
{"id": "2508.04288", "title": "Challenges in Applying Variational Quantum Algorithms to Dynamic Satellite Network Routing", "authors": ["Phuc Hao Do", "Tran Duc Le"], "abstract": "Applying near-term variational quantum algorithms to the problem of dynamic satellite network routing represents a promising direction for quantum computing. In this work, we provide a critical evaluation of two major approaches: static quantum optimizers such as the Variational Quantum Eigensolver (VQE) and the Quantum Approximate Optimization Algorithm (QAOA) for offline route computation, and Quantum Reinforcement Learning (QRL) methods for online decision-making. Using ideal, noise-free simulations, we find that these algorithms face significant challenges. Specifically, static optimizers are unable to solve even a classically easy 4-node shortest path problem due to the complexity of the optimization landscape. Likewise, a basic QRL agent based on policy gradient methods fails to learn a useful routing strategy in a dynamic 8-node environment and performs no better than random actions. These negative findings highlight key obstacles that must be addressed before quantum algorithms can offer real advantages in communication networks. We discuss the underlying causes of these limitations, including barren plateaus and learning instability, and suggest future research directions to overcome them.", "subjects": "Quantum Physics (quant-ph); Artificial Intelligence (cs.AI); Systems and Control (eess.SY)", "comments": "17 pages and 3 figures", "pdf_url": "https://arxiv.org/pdf/2508.04288.pdf", "abstract_url": "https://arxiv.org/abs/2508.04288", "categories": ["Quantum Physics (quant-ph)", "Artificial Intelligence (cs.AI)", "Systems and Control (eess.SY)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文评估了变分量子算法在动态卫星网络路由中的应用，发现静态量子优化器和量子强化学习方法在当前阶段面临重大挑战，无法有效解决简单的路由问题，指出了量子算法在通信网络中应用前需要克服的关键障碍。", "motivation": "探索变分量子算法在动态卫星网络路由问题中的应用潜力，评估其在实际问题中的表现和面临的挑战。", "method": "通过理想无噪声模拟，评估了变分量子本征求解器（VQE）、量子近似优化算法（QAOA）和基于策略梯度方法的量子强化学习（QRL）在静态和动态路由问题中的表现。", "result": "静态优化器无法解决经典的4节点最短路径问题，基础QRL代理在动态8节点环境中无法学习有效的路由策略，表现不优于随机行动。", "conclusion": "量子算法在通信网络中的应用面临如贫瘠高原和学习不稳定性等关键障碍，需要进一步研究以克服这些限制。"}}
{"id": "2508.04451", "title": "Automatic LLM Red Teaming", "authors": ["Roman Belaire", "Arunesh Sinha", "Pradeep Varakantham"], "abstract": "Red teaming is critical for identifying vulnerabilities and building trust in current LLMs. However, current automated methods for Large Language Models (LLMs) rely on brittle prompt templates or single-turn attacks, failing to capture the complex, interactive nature of real-world adversarial dialogues. We propose a novel paradigm: training an AI to strategically `break' another AI. By formalizing red teaming as a Markov Decision Process (MDP) and employing a hierarchical Reinforcement Learning (RL) framework, we effectively address the inherent sparse reward and long-horizon challenges. Our generative agent learns coherent, multi-turn attack strategies through a fine-grained, token-level harm reward, enabling it to uncover subtle vulnerabilities missed by existing baselines. This approach sets a new state-of-the-art, fundamentally reframing LLM red teaming as a dynamic, trajectory-based process (rather than a one-step test) essential for robust AI deployment.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.04451.pdf", "abstract_url": "https://arxiv.org/abs/2508.04451", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新的自动红队测试范式，通过将红队测试建模为马尔可夫决策过程并采用分层强化学习框架，训练AI策略性地‘破解’另一个AI，以发现现有基线方法遗漏的细微漏洞。", "motivation": "当前的大型语言模型（LLMs）自动红队测试方法依赖于脆弱的提示模板或单轮攻击，无法捕捉现实世界中对抗性对话的复杂互动性。", "method": "通过将红队测试形式化为马尔可夫决策过程（MDP），并采用分层强化学习（RL）框架，解决了稀疏奖励和长视野挑战。", "result": "生成代理通过细粒度的、令牌级别的伤害奖励学习连贯的多轮攻击策略，能够发现现有基线方法遗漏的细微漏洞，设定了新的最先进水平。", "conclusion": "这种方法将LLM红队测试重新定义为动态的、基于轨迹的过程（而非一步测试），对于稳健的AI部署至关重要。"}}
{"id": "2508.04691", "title": "From MAS to MARS: Coordination Failures and Reasoning Trade-offs in Hierarchical Multi-Agent Robotic Systems within a Healthcare Scenario", "authors": ["Yuanchen Bai", "Zijian Ding", "Shaoyue Wen", "Xiang Chang", "Angelique Taylor"], "abstract": "Multi-agent robotic systems (MARS) build upon multi-agent systems by integrating physical and task-related constraints, increasing the complexity of action execution and agent coordination. However, despite the availability of advanced multi-agent frameworks, their real-world deployment on robots remains limited, hindering the advancement of MARS research in practice. To bridge this gap, we conducted two studies to investigate performance trade-offs of hierarchical multi-agent frameworks in a simulated real-world multi-robot healthcare scenario. In Study 1, using CrewAI, we iteratively refine the system's knowledge base, to systematically identify and categorize coordination failures (e.g., tool access violations, lack of timely handling of failure reports) not resolvable by providing contextual knowledge alone. In Study 2, using AutoGen, we evaluate a redesigned bidirectional communication structure and further measure the trade-offs between reasoning and non-reasoning models operating within the same robotic team setting. Drawing from our empirical findings, we emphasize the tension between autonomy and stability and the importance of edge-case testing to improve system reliability and safety for future real-world deployment. Supplementary materials, including codes, task agent setup, trace outputs, and annotated examples of coordination failures and reasoning behaviors, are available at:", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.04691.pdf", "abstract_url": "https://arxiv.org/abs/2508.04691", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过两项研究探讨了分层多智能体框架在模拟现实世界多机器人医疗场景中的性能权衡，强调了自主性与稳定性之间的张力及边缘案例测试的重要性。", "motivation": "多智能体机器人系统（MARS）在现实世界中的部署受限，阻碍了MARS研究的实际进展。本文旨在通过研究分层多智能体框架在医疗场景中的表现，填补这一研究与实践之间的差距。", "method": "研究1使用CrewAI迭代 refine 系统的知识库，系统识别和分类无法仅通过提供上下文知识解决的协调失败。研究2使用AutoGen评估重新设计的双向通信结构，并测量在同一机器人团队设置中推理与非推理模型之间的权衡。", "result": "研究发现，自主性与稳定性之间存在张力，边缘案例测试对提高系统可靠性和安全性至关重要。", "conclusion": "本文的实证发现强调了在未来的现实世界部署中，通过边缘案例测试来提高系统可靠性和安全性的重要性，以及自主性与稳定性之间的权衡。"}}
