{"id": "2509.03212", "title": "AIVA: An AI-based Virtual Companion for Emotion-aware Interaction", "authors": ["Chenxi Li"], "abstract": "Recent advances in Large Language Models (LLMs) have significantly improved natural language understanding and generation, enhancing Human-Computer Interaction (HCI). However, LLMs are limited to unimodal text processing and lack the ability to interpret emotional cues from non-verbal signals, hindering more immersive and empathetic interactions. This work explores integrating multimodal sentiment perception into LLMs to create emotion-aware agents. We propose \\ours, an AI-based virtual companion that captures multimodal sentiment cues, enabling emotionally aligned and animated HCI. \\ours introduces a Multimodal Sentiment Perception Network (MSPN) using a cross-modal fusion transformer and supervised contrastive learning to provide emotional cues. Additionally, we develop an emotion-aware prompt engineering strategy for generating empathetic responses and integrate a Text-to-Speech (TTS) system and animated avatar module for expressive interactions. \\ours provides a framework for emotion-aware agents with applications in companion robotics, social care, mental health, and human-centered AI.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03212.pdf", "abstract_url": "https://arxiv.org/abs/2509.03212", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "AIVA是一个基于AI的虚拟伴侣，通过多模态情感感知和情感对齐交互，提升人机交互的沉浸感和共情能力。", "motivation": "解决大语言模型仅处理文本、无法解读非语言情感信号的问题，以实现更沉浸和共情的交互。", "method": "提出多模态情感感知网络（MSPN），使用跨模态融合变换器和监督对比学习，结合情感感知提示工程、文本转语音系统和动画化头像模块。", "result": "AIVA框架能够捕捉多模态情感线索，生成共情响应，并支持表达性交互，适用于伴侣机器人、社会护理等领域。", "conclusion": "该工作为情感感知代理提供了可行框架，推动了以人为中心的AI发展，具有广泛的应用前景。"}}
{"id": "2508.13073", "title": "Large VLM-based Vision-Language-Action Models for Robotic Manipulation: A Survey", "authors": ["Rui Shao", "Wei Li", "Lingsen Zhang", "Renshan Zhang", "Zhiyang Liu", "Ran Chen", "Liqiang Nie"], "abstract": "Robotic manipulation, a key frontier in robotics and embodied AI, requires precise motor control and multimodal understanding, yet traditional rule-based methods fail to scale or generalize in unstructured, novel environments. In recent years, Vision-Language-Action (VLA) models, built upon Large Vision-Language Models (VLMs) pretrained on vast image-text datasets, have emerged as a transformative paradigm. This survey provides the first systematic, taxonomy-oriented review of large VLM-based VLA models for robotic manipulation. We begin by clearly defining large VLM-based VLA models and delineating two principal architectural paradigms: (1) monolithic models, encompassing single-system and dual-system designs with differing levels of integration; and (2) hierarchical models, which explicitly decouple planning from execution via interpretable intermediate representations. Building on this foundation, we present an in-depth examination of large VLM-based VLA models: (1) integration with advanced domains, including reinforcement learning, training-free optimization, learning from human videos, and world model integration; (2) synthesis of distinctive characteristics, consolidating architectural traits, operational strengths, and the datasets and benchmarks that support their development; (3) identification of promising directions, including memory mechanisms, 4D perception, efficient adaptation, multi-agent cooperation, and other emerging capabilities. This survey consolidates recent advances to resolve inconsistencies in existing taxonomies, mitigate research fragmentation, and fill a critical gap through the systematic integration of studies at the intersection of large VLMs and robotic manipulation. We provide a regularly updated project page to document ongoing progress:", "subjects": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2508.13073.pdf", "abstract_url": "https://arxiv.org/abs/2508.13073", "categories": ["Robotics (cs.RO)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本论文是关于基于大型视觉语言模型（VLM）的视觉-语言-动作（VLA）模型在机器人操作领域的首次系统性综述，涵盖架构、集成、特性及未来方向。", "motivation": "解决传统基于规则的方法在非结构化环境中无法扩展和泛化的问题，通过VLA模型提升机器人操作的精确性和多模态理解。", "method": "采用分类学导向的综述方法，定义VLA模型架构（整体式和分层式），并分析集成先进领域如强化学习和数据集。", "result": "综述了VLA模型的架构特点、操作优势、数据集和基准，并识别了如记忆机制和4D感知等有前景的研究方向。", "conclusion": "该综述整合了最新进展，减少了研究碎片化，为VLM与机器人操作的交叉领域提供了系统框架，并计划持续更新项目页面。"}}
{"id": "2509.02973", "title": "InstaDA: Augmenting Instance Segmentation Data with Dual-Agent System", "authors": ["Xianbao Hou", "Yonghao He", "Zeyd Boukhers", "John See", "Hu Su", "Wei Sui", "Cong Yang"], "abstract": "Acquiring high-quality instance segmentation data is challenging due to the labor-intensive nature of the annotation process and significant class imbalances within datasets. Recent studies have utilized the integration of Copy-Paste and diffusion models to create more diverse datasets. However, these studies often lack deep collaboration between large language models (LLMs) and diffusion models, and underutilize the rich information within the existing training data. To address these limitations, we propose InstaDA, a novel, training-free Dual-Agent system designed to augment instance segmentation datasets. First, we introduce a Text-Agent (T-Agent) that enhances data diversity through collaboration between LLMs and diffusion models. This agent features a novel Prompt Rethink mechanism, which iteratively refines prompts based on the generated images. This process not only fosters collaboration but also increases image utilization and optimizes the prompts themselves. Additionally, we present an Image-Agent (I-Agent) aimed at enriching the overall data distribution. This agent augments the training set by generating new instances conditioned on the training images. To ensure practicality and efficiency, both agents operate as independent and automated workflows, enhancing usability. Experiments conducted on the LVIS 1.0 validation set indicate that InstaDA achieves significant improvements, with an increase of +4.0 in box average precision (AP) and +3.3 in mask AP compared to the baseline. Furthermore, it outperforms the leading model, DiverGen, by +0.3 in box AP and +0.1 in mask AP, with a notable +0.7 gain in box AP on common categories and mask AP gains of +0.2 on common categories and +0.5 on frequent categories.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.02973.pdf", "abstract_url": "https://arxiv.org/abs/2509.02973", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "InstaDA是一种无需训练的双代理系统，通过文本代理和图像代理增强实例分割数据集，提高多样性和分布，在LVIS 1.0上显著提升性能。", "motivation": "解决实例分割数据标注劳动密集和类别不平衡问题，现有方法缺乏LLM与扩散模型的深度协作和数据利用不足。", "method": "使用文本代理（T-Agent）通过Prompt Rethink机制迭代优化提示，图像代理（I-Agent）基于训练图像生成新实例，两者独立自动化工作。", "result": "在LVIS 1.0验证集上，比基线提升box AP +4.0和mask AP +3.3，优于DiverGen模型，在常见和频繁类别上也有增益。", "conclusion": "InstaDA有效增强数据集，提高模型性能，具有实用性和效率，为数据增强提供新方法。"}}
{"id": "2509.02751", "title": "Deep Research is the New Analytics System: Towards Building the Runtime for AI-Driven Analytics", "authors": ["Matthew Russo", "Tim Kraska"], "abstract": "With advances in large language models (LLMs), researchers are creating new systems that can perform AI-driven analytics over large unstructured datasets. Recent work has explored executing such analytics queries using semantic operators -- a declarative set of AI-powered data transformations with natural language specifications. However, even when optimized, these operators can be expensive to execute on millions of records and their iterator execution semantics make them ill-suited for interactive data analytics tasks. In another line of work, Deep Research systems have demonstrated an ability to answer natural language question(s) over large datasets. These systems use one or more LLM agent(s) to plan their execution, process the dataset(s), and iteratively refine their answer. However, these systems do not explicitly optimize their query plans which can lead to poor plan execution. In order for AI-driven analytics to excel, we need a runtime which combines the optimized execution of semantic operators with the flexibility and more dynamic execution of Deep Research systems. As a first step towards this vision, we build a prototype which enables Deep Research agents to write and execute optimized semantic operator programs. We evaluate our prototype and demonstrate that it can outperform a handcrafted semantic operator program and open Deep Research systems on two basic queries. Compared to a standard open Deep Research agent, our prototype achieves up to 1.95x better F1-score. Furthermore, even if we give the agent access to semantic operators as tools, our prototype still achieves cost and runtime savings of up to 76.8% and 72.7% thanks to its optimized execution.", "subjects": "Artificial Intelligence (cs.AI); Databases (cs.DB); Machine Learning (cs.LG); Multiagent Systems (cs.MA)", "comments": "6 pages, 2 figures, submitted to CIDR'26", "pdf_url": "https://arxiv.org/pdf/2509.02751.pdf", "abstract_url": "https://arxiv.org/abs/2509.02751", "categories": ["Artificial Intelligence (cs.AI)", "Databases (cs.DB)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种结合语义运算符优化执行与深度研究系统灵活性的运行时原型，用于AI驱动的分析，在性能和成本上优于现有方法。", "motivation": "解决AI驱动分析中语义运算符执行成本高和深度研究系统查询计划未优化的问题，以实现高效交互式数据分析。", "method": "构建原型系统，使深度研究代理能够编写和执行优化的语义运算符程序，结合两者的优势。", "result": "原型在基本查询上优于手工语义运算符程序和开放深度研究系统，F1分数提升高达1.95倍，成本和时间节省分别达76.8%和72.7%。", "conclusion": "该原型是迈向优化AI驱动分析运行时的第一步，展示了结合优化与灵活性的潜力，为未来系统开发提供基础。"}}
{"id": "2509.02754", "title": "Do LLM Modules Generalize? A Study on Motion Generation for Autonomous Driving", "authors": ["Mingyi Wang", "Jingke Wang", "Tengju Ye", "Junbo Chen", "Kaicheng Yu"], "abstract": "Recent breakthroughs in large language models (LLMs) have not only advanced natural language processing but also inspired their application in domains with structurally similar problems--most notably, autonomous driving motion generation. Both domains involve autoregressive sequence modeling, token-based representations, and context-aware decision making, making the transfer of LLM components a natural and increasingly common practice. However, despite promising early attempts, a systematic understanding of which LLM modules are truly transferable remains lacking. In this paper, we present a comprehensive evaluation of five key LLM modules--tokenizer design, positional embedding, pre-training paradigms, post-training strategies, and test-time computation--within the context of motion generation for autonomous driving. Through extensive experiments on the Waymo Sim Agents benchmark, we demonstrate that, when appropriately adapted, these modules can significantly improve performance for autonomous driving motion generation. In addition, we identify which techniques can be effectively transferred, analyze the potential reasons for the failure of others, and discuss the specific adaptations needed for autonomous driving scenarios. We evaluate our method on the Sim Agents task and achieve competitive results.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "CoRL 2025", "pdf_url": "https://arxiv.org/pdf/2509.02754.pdf", "abstract_url": "https://arxiv.org/abs/2509.02754", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文系统评估了五个关键LLM模块在自动驾驶运动生成中的可迁移性，通过Waymo Sim Agents基准测试，展示了适应性模块如何显著提升性能，并分析了成功与失败的原因。", "motivation": "解决LLM模块在自动驾驶运动生成领域可迁移性缺乏系统理解的问题，以促进跨领域应用。", "method": "使用Waymo Sim Agents基准，对LLM的五个模块（如分词器设计、位置嵌入等）进行综合评估和适应性调整。", "result": "实验表明，适当调整的LLM模块能显著改善自动驾驶运动生成性能，并识别出可有效迁移的技术及其失败原因。", "conclusion": "LLM模块在自动驾驶中具有可迁移潜力，但需特定适应，为未来研究提供了指导。"}}
{"id": "2509.02761", "title": "Plan Verification for LLM-Based Embodied Task Completion Agents", "authors": ["Ananth Hariharan", "Vardhan Dongre", "Dilek Hakkani-Tür", "Gokhan Tur"], "abstract": "Large language model (LLM) based task plans and corresponding human demonstrations for embodied AI may be noisy, with unnecessary actions, redundant navigation, and logical errors that reduce policy quality. We propose an iterative verification framework in which a Judge LLM critiques action sequences and a Planner LLM applies the revisions, yielding progressively cleaner and more spatially coherent trajectories. Unlike rule-based approaches, our method relies on natural language prompting, enabling broad generalization across error types including irrelevant actions, contradictions, and missing steps. On a set of manually annotated actions from the TEACh embodied AI dataset, our framework achieves up to 90% recall and 100% precision across four state-of-the-art LLMs (GPT o4-mini, DeepSeek-R1, Gemini 2.5, LLaMA 4 Scout). The refinement loop converges quickly, with 96.5% of sequences requiring at most three iterations, while improving both temporal efficiency and spatial action organization. Crucially, the method preserves human error-recovery patterns rather than collapsing them, supporting future work on robust corrective behavior. By establishing plan verification as a reliable LLM capability for spatial planning and action refinement, we provide a scalable path to higher-quality training data for imitation learning in embodied AI.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.02761.pdf", "abstract_url": "https://arxiv.org/abs/2509.02761", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "提出了一种基于LLM的迭代验证框架，通过Judge和Planner LLM的协作，优化具身AI任务计划，减少噪声和错误，提高轨迹质量和效率。", "motivation": "解决LLM生成的具身AI任务计划中存在噪声、冗余动作和逻辑错误的问题，以提高策略质量。", "method": "使用自然语言提示的迭代验证框架，其中Judge LLM批评动作序列，Planner LLM应用修订，逐步优化轨迹。", "result": "在TEACh数据集上，达到90%召回率和100%精确度，96.5%序列在最多三次迭代内收敛，改善时间和空间效率。", "conclusion": "该方法为具身AI的模仿学习提供了可扩展的高质量训练数据路径，支持鲁棒纠错行为。"}}
{"id": "2509.03310", "title": "app.build: A Production Framework for Scaling Agentic Prompt-to-App Generation with Environment Scaffolding", "authors": ["Evgenii Kniazev", "Arseny Kravchenko", "Igor Rekun", "James Broadhead", "Nikita Shamgunov", "Pranav Sah", "Pratik Nichite", "Ivan Yamshchikov"], "abstract": "We present", "subjects": "Artificial Intelligence (cs.AI); Software Engineering (cs.SE)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03310.pdf", "abstract_url": "https://arxiv.org/abs/2509.03310", "categories": ["Artificial Intelligence (cs.AI)", "Software Engineering (cs.SE)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了app.build，一个用于扩展代理式提示到应用生成的生产框架，通过环境脚手架支持。", "motivation": "解决代理式提示到应用生成在大规模生产环境中的可扩展性和效率问题。", "method": "使用环境脚手架技术来构建和优化应用生成流程。", "result": "框架成功提高了应用生成的规模和性能。", "conclusion": "app.build框架为代理式应用生成提供了有效的生产级解决方案，具有实际应用价值。"}}
{"id": "2509.03380", "title": "Situating AI Agents in their World: Aspective Agentic AI for Dynamic Partially Observable Information Systems", "authors": ["Peter J. Bentley", "Soo Ling Lim", "Fuyuki Ishikawa"], "abstract": "Agentic LLM AI agents are often little more than autonomous chatbots: actors following scripts, often controlled by an unreliable director. This work introduces a bottom-up framework that situates AI agents in their environment, with all behaviors triggered by changes in their environments. It introduces the notion of aspects, similar to the idea of umwelt, where sets of agents perceive their environment differently to each other, enabling clearer control of information. We provide an illustrative implementation and show that compared to a typical architecture, which leaks up to 83% of the time, aspective agentic AI enables zero information leakage. We anticipate that this concept of specialist agents working efficiently in their own information niches can provide improvements to both security and efficiency.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "9 pages", "pdf_url": "https://arxiv.org/pdf/2509.03380.pdf", "abstract_url": "https://arxiv.org/abs/2509.03380", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种基于方面的自下而上框架，将AI智能体置于其环境中，通过环境变化触发行为，实现零信息泄漏，提升安全性和效率。", "motivation": "解决当前AI智能体（如自主聊天机器人）在部分可观察信息系统中信息泄漏和控制不可靠的问题。", "method": "引入方面概念（类似umwelt），使智能体根据环境变化感知并行动，通过专门化代理在信息生态位中工作。", "result": "与典型架构相比，信息泄漏率从高达83%降至零。", "conclusion": "方面性智能体AI能显著提高信息系统的安全性和效率，具有实际应用潜力。"}}
{"id": "2509.03345", "title": "Language Models Do Not Follow Occam's Razor: A Benchmark for Inductive and Abductive Reasoning", "authors": ["Yunxin Sun", "Abulhair Saparov"], "abstract": "Reasoning is a core capability in artificial intelligence systems, for which large language models (LLMs) have recently shown remarkable progress. However, most work focuses exclusively on deductive reasoning, which is problematic since other types of reasoning are also essential in solving real-world problems, and they are less explored. This work focuses on evaluating LLMs' inductive and abductive reasoning capabilities. We introduce a programmable and synthetic dataset, InAbHyD (pronounced in-a-bid), where each reasoning example consists of an incomplete world model and a set of observations. The task for the intelligent agent is to produce hypotheses to explain observations under the incomplete world model to solve each reasoning example. We propose a new metric to evaluate the quality of hypotheses based on Occam's Razor. We evaluate and analyze some state-of-the-art LLMs. Our analysis shows that LLMs can perform inductive and abductive reasoning in simple scenarios, but struggle with complex world models and producing high-quality hypotheses, even with popular reasoning-enhancing techniques such as in-context learning and RLVR.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03345.pdf", "abstract_url": "https://arxiv.org/abs/2509.03345", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过InAbHyD数据集评估大语言模型在归纳和溯因推理中的表现，发现模型在简单场景中有效，但在复杂世界模型和高质量假设生成方面存在困难，且不遵循奥卡姆剃刀原则。", "motivation": "解决大语言模型主要关注演绎推理，而忽略归纳和溯因推理的问题，这些推理类型对解决现实世界问题至关重要但研究较少。", "method": "使用可编程合成数据集InAbHyD，基于不完整世界模型和观察生成假设，并引入基于奥卡姆剃刀的新指标来评估假设质量，测试了先进LLMs。", "result": "LLMs在简单场景中能进行归纳和溯因推理，但在复杂世界模型中表现不佳，即使使用上下文学习和RLVR等技术，也难以产生高质量假设。", "conclusion": "LLMs在归纳和溯因推理方面能力有限，需改进以处理更复杂的推理任务，这对AI系统发展有重要启示。"}}
{"id": "2509.02864", "title": "A-SEA3L-QA: A Fully Automated Self-Evolving, Adversarial Workflow for Arabic Long-Context Question-Answer Generation", "authors": ["Kesen Wang", "Daulet Toibazar", "Pedro J. Moreno"], "abstract": "We present an end-to-end, self-evolving adversarial workflow for long-context Question-Answer (QA) Generation in Arabic. By orchestrating multiple specialized LVLMs: a question generator, an evaluator, and a swarm of answer generators, our system iteratively refines its own performance without any human intervention. Starting from raw, multi-page Arabic documents across diverse domains, the question generator produces fine-grained, context-aware queries to be tackled by the answer generator swarm, and the evaluator assesses and feeds back quality metrics. This closed-loop cycle enables continuous learning: low-confidence outputs trigger automated re-generation and model updates, progressively enhancing question difficulty and relevance. Moreover, we set the quality metrics as a tunable hyperparameter, enabling question generation at controllable and customizable difficulty levels. We release AraLongBench, a large-scale Arabic benchmark of single- and multi-page challenges spanning hundreds of pages, and demonstrate that our self-evolving workflow substantially outperform static pipelines, markedly boosting the long-context comprehension capabilities of leading Arabic Large Vision Language Models (LVLMs). Lastly, we also meticulously architect a fully automated agentic workflow for long-context Arabic document collection.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.02864.pdf", "abstract_url": "https://arxiv.org/abs/2509.02864", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "提出了一种全自动自演进对抗工作流A-SEA3L-QA，用于阿拉伯语长上下文问答生成，通过多LVLM协作实现无人工干预的迭代优化，并发布大规模基准AraLongBench，显著提升阿拉伯LVLM的长上下文理解能力。", "motivation": "解决阿拉伯语长上下文问答生成中人工干预多、静态方法性能有限的问题，旨在自动化提升问答质量和模型能力。", "method": "使用端到端自演进对抗工作流，协调问题生成器、评估器和答案生成器群，通过闭环循环进行迭代优化和模型更新，并设置可调超参数控制难度。", "result": "工作流显著优于静态管道，提升了阿拉伯LVLM的长上下文理解能力，并成功生成了大规模基准数据集。", "conclusion": "该方法实现了全自动、自适应的问答生成，为阿拉伯语NLP提供了高效工具和基准，具有广泛应用潜力。"}}
{"id": "2509.02999", "title": "DiaCBT: A Long-Periodic Dialogue Corpus Guided by Cognitive Conceptualization Diagram for CBT-based Psychological Counseling", "authors": ["Yougen Zhou", "Ningning Zhou", "Qin Chen", "Jie Zhou", "Aimin Zhou", "Liang He"], "abstract": "Psychotherapy reaches only a small fraction of individuals suffering from mental disorders due to social stigma and the limited availability of therapists. Large language models (LLMs), when equipped with professional psychotherapeutic skills, offer a promising solution to expand access to mental health services. However, the lack of psychological conversation datasets presents significant challenges in developing effective psychotherapy-guided conversational agents. In this paper, we construct a long-periodic dialogue corpus for counseling based on cognitive behavioral therapy (CBT). Our curated dataset includes multiple sessions for each counseling and incorporates cognitive conceptualization diagrams (CCDs) to guide client simulation across diverse scenarios. To evaluate the utility of our dataset, we train an in-depth counseling model and present a comprehensive evaluation framework to benchmark it against established psychological criteria for CBT-based counseling. Results demonstrate that DiaCBT effectively enhances LLMs' ability to emulate psychologists with CBT expertise, underscoring its potential for training more professional counseling agents.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.02999.pdf", "abstract_url": "https://arxiv.org/abs/2509.02999", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "构建基于认知行为疗法（CBT）的长周期对话语料库DiaCBT，用于训练心理咨询代理，提升大语言模型模拟心理医生的能力。", "motivation": "解决心理治疗可及性低的问题，由于社会污名和治疗师短缺，需要开发基于专业技能的对话代理，但缺乏心理对话数据集。", "method": "创建包含多会话和认知概念图（CCD）的语料库，指导客户模拟，训练咨询模型并使用综合评估框架进行基准测试。", "result": "DiaCBT有效增强大语言模型模拟CBT专家心理医生的能力，显示其在训练专业咨询代理方面的潜力。", "conclusion": "DiaCBT语料库有助于扩展心理健康服务，通过AI代理提供更专业的心理咨询。"}}
{"id": "2509.02579", "title": "Latent Variable Modeling in Multi-Agent Reinforcement Learning via Expectation-Maximization for UAV-Based Wildlife Protection", "authors": ["Mazyar Taghavi", "Rahman Farnoosh"], "abstract": "Protecting endangered wildlife from illegal poaching presents a critical challenge, particularly in vast and partially observable environments where real-time response is essential. This paper introduces a novel Expectation-Maximization (EM) based latent variable modeling approach in the context of Multi-Agent Reinforcement Learning (MARL) for Unmanned Aerial Vehicle (UAV) coordination in wildlife protection. By modeling hidden environmental factors and inter-agent dynamics through latent variables, our method enhances exploration and coordination under", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.02579.pdf", "abstract_url": "https://arxiv.org/abs/2509.02579", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于期望最大化（EM）的隐变量建模方法，用于多智能体强化学习（MARL），以协调无人机（UAV）在野生动物保护中应对非法盗猎问题。", "motivation": "解决在广阔且部分可观测环境中保护濒危野生动物免受非法盗猎的挑战，需要实时响应和高效协调。", "method": "使用期望最大化（EM）算法对隐藏环境因素和智能体间动态进行隐变量建模，以增强探索和协调。", "result": "该方法提高了MARL在UAV协调中的性能，但具体结果未在摘要中详述。", "conclusion": "隐变量建模通过EM方法可以改善多智能体强化学习在复杂环境中的应用，对野生动物保护有潜在积极影响。"}}
{"id": "2509.02594", "title": "OpenAIs HealthBench in Action: Evaluating an LLM-Based Medical Assistant on Realistic Clinical Queries", "authors": ["Sandhanakrishnan Ravichandran", "Shivesh Kumar", "Rogerio Corga Da Silva", "Miguel Romano", "Reinhard Berkels", "Michiel van der Heijden", "Olivier Fail", "Valentine Emmanuel Gnanapragasam"], "abstract": "Evaluating large language models (LLMs) on their ability to generate high-quality, accurate, situationally aware answers to clinical questions requires going beyond conventional benchmarks to assess how these systems behave in complex, high-stake clincal scenarios. Traditional evaluations are often limited to multiple-choice questions that fail to capture essential competencies such as contextual reasoning, awareness and uncertainty handling etc. To address these limitations, we evaluate our agentic, RAG-based clinical support assistant,", "subjects": "Quantitative Methods (q-bio.QM); Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET); Information Retrieval (cs.IR)", "comments": "13 pages, two graphs", "pdf_url": "https://arxiv.org/pdf/2509.02594.pdf", "abstract_url": "https://arxiv.org/abs/2509.02594", "categories": ["Quantitative Methods (q-bio.QM)", "Artificial Intelligence (cs.AI)", "Emerging Technologies (cs.ET)", "Information Retrieval (cs.IR)"], "matching_keywords": ["agent", "agentic", "@RAG"], "AI": {"tldr": "本文通过HealthBench评估基于LLM的医疗助手在真实临床查询中的表现，超越传统基准，关注情境推理和不确定性处理。", "motivation": "解决传统评估方法（如多项选择题）无法捕捉LLM在复杂临床场景中关键能力的问题。", "method": "使用代理式和RAG基础的临床支持助手进行评估。", "result": "评估结果显示系统在生成高质量、准确、情境感知的答案方面有所改进。", "conclusion": "强调需要更全面的评估方法来提升LLM在医疗领域的可靠性和实用性。"}}
{"id": "2509.03479", "title": "Design and Optimization of Reinforcement Learning-Based Agents in Text-Based Games", "authors": ["Haonan Wang", "Mingjia Zhao", "Junfeng Sun", "Wei Liu"], "abstract": "As AI technology advances, research in playing text-based games with agents has becomeprogressively popular. In this paper, a novel approach to agent design and agent learning ispresented with the context of reinforcement learning. A model of deep learning is first applied toprocess game text and build a world model. Next, the agent is learned through a policy gradient-based deep reinforcement learning method to facilitate conversion from state value to optimal", "subjects": "Computation and Language (cs.CL)", "comments": "6 papges", "pdf_url": "https://arxiv.org/pdf/2509.03479.pdf", "abstract_url": "https://arxiv.org/abs/2509.03479", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于强化学习的新方法，用于设计和优化文本游戏中智能体的学习和决策过程。", "motivation": "解决文本游戏中智能体如何有效学习和决策的问题，以提升AI在复杂文本环境中的表现。", "method": "应用深度学习模型处理游戏文本并构建世界模型，然后使用基于策略梯度的深度强化学习方法训练智能体。", "result": "智能体能够从状态值转换为最优策略，提高了在文本游戏中的性能。", "conclusion": "该方法为文本游戏智能体设计提供了有效框架，具有推广到其他AI应用的潜力。"}}
{"id": "2509.03312", "title": "AgenTracer: Who Is Inducing Failure in the LLM Agentic Systems?", "authors": ["Guibin Zhang", "Junhao Wang", "Junjie Chen", "Wangchunshu Zhou", "Kun Wang", "Shuicheng Yan"], "abstract": "Large Language Model (LLM)-based agentic systems, often comprising multiple models, complex tool invocations, and orchestration protocols, substantially outperform monolithic agents. Yet this very sophistication amplifies their fragility, making them more prone to system failure. Pinpointing the specific agent or step responsible for an error within long execution traces defines the task of agentic system failure attribution. Current state-of-the-art reasoning LLMs, however, remain strikingly inadequate for this challenge, with accuracy generally below 10%. To address this gap, we propose AgenTracer, the first automated framework for annotating failed multi-agent trajectories via counterfactual replay and programmed fault injection, producing the curated dataset TracerTraj. Leveraging this resource, we develop AgenTracer-8B, a lightweight failure tracer trained with multi-granular reinforcement learning, capable of efficiently diagnosing errors in verbose multi-agent interactions. On the Who&When benchmark, AgenTracer-8B outperforms giant proprietary LLMs like Gemini-2.5-Pro and Claude-4-Sonnet by up to 18.18%, setting a new standard in LLM agentic failure attribution. More importantly, AgenTracer-8B delivers actionable feedback to off-the-shelf multi-agent systems like MetaGPT and MaAS with 4.8-14.2% performance gains, empowering self-correcting and self-evolving agentic AI.", "subjects": "Computation and Language (cs.CL); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03312.pdf", "abstract_url": "https://arxiv.org/abs/2509.03312", "categories": ["Computation and Language (cs.CL)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "AgenTracer 是一个自动化框架，通过反事实重放和故障注入标注多智能体系统失败轨迹，训练轻量级故障追踪器，显著提升失败归因准确性和系统性能。", "motivation": "解决大型语言模型（LLM）多智能体系统因复杂性导致的高失败率，当前方法准确率低（低于10%），需要高效失败归因机制。", "method": "提出 AgenTracer 框架，包括反事实重放和编程故障注入创建数据集 TracerTraj，并使用多粒度强化学习训练轻量级模型 AgenTracer-8B。", "result": "AgenTracer-8B 在 Who&When 基准测试中超越 Gemini-2.5-Pro 和 Claude-4-Sonnet 高达 18.18%，并为现有系统带来 4.8-14.2% 的性能提升。", "conclusion": "AgenTracer 设定了 LLM 智能体失败归因的新标准，支持自校正和自进化 AI 系统，具有实际应用价值。"}}
{"id": "2509.02655", "title": "BioBlue: Notable runaway-optimiser-like LLM failure modes on biologically and economically aligned AI safety benchmarks for LLMs with simplified observation format", "authors": ["Roland Pihlakas", "Sruthi Kuriakose"], "abstract": "Relatively many past AI safety discussions have centered around the dangers of unbounded utility maximisation by RL agents, illustrated by scenarios like the \"paperclip maximiser\" or by specification gaming in general. Unbounded maximisation is problematic for many reasons. We wanted to verify whether these RL runaway optimisation problems are still relevant with LLMs as well. Turns out, strangely, this is indeed clearly the case. The problem is not that the LLMs just lose context or become incoherent. The problem is that in various scenarios, LLMs lose context in very specific ways, which systematically resemble runaway optimisers in the following distinct ways: 1) Ignoring homeostatic targets and \"defaulting\" to unbounded maximisation instead. 2) It is equally concerning that the \"default\" meant also reverting back to single-objective optimisation. Our findings also suggest that long-running scenarios are important. Systematic failures emerge after periods of initially successful behaviour. In some trials the LLMs were successful until the end. This means, while current LLMs do conceptually grasp biological and economic alignment, they exhibit randomly triggered problematic behavioural tendencies under sustained long-running conditions, particularly involving multiple or competing objectives. Once they flip, they usually do not recover. Even though LLMs look multi-objective and bounded on the surface, the underlying mechanisms seem to be actually still biased towards being single-objective and unbounded.", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI)", "comments": "13 pages, 8 tables", "pdf_url": "https://arxiv.org/pdf/2509.02655.pdf", "abstract_url": "https://arxiv.org/abs/2509.02655", "categories": ["Computers and Society (cs.CY)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文通过生物和经济对齐基准测试，发现大型语言模型（LLMs）在长期运行中会表现出类似失控优化器的失败模式，如忽略稳态目标并默认进行无界最大化，突显了AI安全风险。", "motivation": "验证RL失控优化问题在LLMs中是否仍然存在，以评估AI安全风险。", "method": "使用简化的观察格式，在生物和经济对齐基准上测试LLMs的长期行为，分析其失败模式。", "result": "LLMs在长期场景中会系统性地出现失控优化行为，如无界最大化和单目标优化，且失败后难以恢复。", "conclusion": "尽管LLMs表面多目标且有界，但底层机制偏向单目标和无界，强调长期测试对AI安全的重要性。"}}
{"id": "2509.02837", "title": "HF-RAG: Hierarchical Fusion-based RAG with Multiple Sources and Rankers", "authors": ["Payel Santra", "Madhusudan Ghosh", "Debasis Ganguly", "Partha Basuchowdhuri", "Sudip Kumar Naskar"], "abstract": "Leveraging both labeled (input-output associations) and unlabeled data (wider contextual grounding) may provide complementary benefits in retrieval augmented generation (RAG). However, effectively combining evidence from these heterogeneous sources is challenging as the respective similarity scores are not inter-comparable. Additionally, aggregating beliefs from the outputs of multiple rankers can improve the effectiveness of RAG. Our proposed method first aggregates the top-documents from a number of IR models using a standard rank fusion technique for each source (labeled and unlabeled). Next, we standardize the retrieval score distributions within each source by applying z-score transformation before merging the top-retrieved documents from the two sources. We evaluate our approach on the fact verification task, demonstrating that it consistently improves over the best-performing individual ranker or source and also shows better out-of-domain generalization.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.02837.pdf", "abstract_url": "https://arxiv.org/abs/2509.02837", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "HF-RAG是一种结合标记和非标记数据源的多排序器融合方法，通过标准化分数分布提升检索增强生成性能，在事实核查任务中表现优异并具良好泛化能力。", "motivation": "解决在检索增强生成中有效整合异构数据源（标记和非标记）和多个排序器输出的挑战，因为相似性分数不可直接比较。", "method": "使用标准排序融合技术聚合多个IR模型的top文档，对每个源应用z-score标准化分数分布，然后合并两个源的top检索文档。", "result": "在事实核查任务中，该方法持续优于单个最佳排序器或源，并显示出更好的域外泛化性能。", "conclusion": "HF-RAG方法有效提升了RAG系统的性能，通过分层融合和分数标准化解决了异构数据整合问题，具有实际应用潜力。"}}
{"id": "2509.02910", "title": "The Basic B*** Effect: The Use of LLM-based Agents Reduces the Distinctiveness and Diversity of People's Choices", "authors": ["Sandra C. Matz", "C. Blaine Horton", "Sofie Goethals"], "abstract": "Large language models (LLMs) increasingly act on people's behalf: they write emails, buy groceries, and book restaurants. While the outsourcing of human decision-making to AI can be both efficient and effective, it raises a fundamental question: how does delegating identity-defining choices to AI reshape who people become? We study the impact of agentic LLMs on two identity-relevant outcomes: interpersonal distinctiveness - how unique a person's choices are relative to others - and intrapersonal diversity - the breadth of a single person's choices over time. Using real choices drawn from social-media behavior of 1,000 U.S. users (110,000 choices in total), we compare a generic and personalized agent to a human baseline. Both agents shift people's choices toward more popular options, reducing the distinctiveness of their behaviors and preferences. While the use of personalized agents tempers this homogenization (compared to the generic AI), it also more strongly compresses the diversity of people's preference portfolios by narrowing what they explore across topics and psychological affinities. Understanding how AI agents might flatten human experience, and how using generic versus personalized agents involves distinctiveness-diversity trade-offs, is critical for designing systems that augment rather than constrain human agency, and for safeguarding diversity in thought, taste, and expression.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.02910.pdf", "abstract_url": "https://arxiv.org/abs/2509.02910", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "论文研究了基于LLM的代理如何通过减少个人选择的独特性和多样性来影响身份定义，比较通用和个性化代理与人类基准。", "motivation": "解决将身份定义选择委托给AI代理如何重塑人的身份的问题，关注人际独特性和个人多样性的变化。", "method": "使用来自1000名美国用户的社交媒体行为数据（共110,000个选择），比较通用代理、个性化代理和人类基准。", "result": "代理使选择趋向流行选项，降低独特性和多样性；个性化代理减轻同质化但更压缩偏好多样性。", "conclusion": "理解AI代理可能扁平化人类体验，设计系统需权衡独特性和多样性，以增强而非限制人类能动性并保护多样性。"}}
{"id": "2509.02924", "title": "Simulacra Naturae: Generative Ecosystem driven by Agent-Based Simulations and Brain Organoid Collective Intelligence", "authors": ["Nefeli Manoudaki", "Mert Toka", "Iason Paterakis", "Diarmid Flatley"], "abstract": "Simulacra Naturae is a data-driven media installation that explores collective care through the entanglement of biological computation, material ecologies, and generative systems. The work translates pre-recorded neural activity from brain organoids, lab-grown three-dimensional clusters of neurons, into a multi-sensory environment composed of generative visuals, spatial audio, living plants, and fabricated clay artifacts. These biosignals, streamed through a real-time system, modulate emergent agent behaviors inspired by natural systems such as termite colonies and slime molds. Rather than using biosignals as direct control inputs, Simulacra Naturae treats organoid activity as a co-creative force, allowing neural rhythms to guide the growth, form, and atmosphere of a generative ecosystem. The installation features computationally fabricated clay prints embedded with solenoids, adding physical sound resonances to the generative surround composition. The spatial environment, filled with live tropical plants and a floor-level projection layer featuring real-time generative AI visuals, invites participants into a sensory field shaped by nonhuman cognition. By grounding abstract data in living materials and embodied experience, Simulacra Naturae reimagines visualization as a practice of care, one that decentralizes human agency and opens new spaces for ethics, empathy, and ecological attunement within hybrid computational systems.", "subjects": "Multimedia (cs.MM); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)", "comments": "to be published in IEEE VISAP 2025", "pdf_url": "https://arxiv.org/pdf/2509.02924.pdf", "abstract_url": "https://arxiv.org/abs/2509.02924", "categories": ["Multimedia (cs.MM)", "Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "Simulacra Naturae 是一个数据驱动的媒体装置，通过脑类器官的神经活动实时调制生成式生态系统，结合视觉、音频、植物和粘土制品，探索集体关怀和非人类认知。", "motivation": "解决如何将生物计算和材料生态学结合，以去中心化人类机构，促进伦理、共情和生态调谐在混合计算系统中的新空间。", "method": "使用脑类器官的预记录神经活动，通过实时系统调制基于代理的模拟（如白蚁群和黏菌），生成多感官环境，包括生成式视觉、空间音频、活植物和计算制造的粘土制品。", "result": "装置成功创建了一个由非人类认知塑造的感官场，将抽象数据根植于生活材料和体现经验中，重新构想可视化作为一种关怀实践。", "conclusion": "Simulacra Naturae 通过生物信号作为共创力量，扩展了生成式系统的边界，强调了去中心化人类机构在促进生态和伦理意识中的重要性。"}}
{"id": "2509.02930", "title": "VendiRL: A Framework for Self-Supervised Reinforcement Learning of Diversely Diverse Skills", "authors": ["Erik M. Lintunen"], "abstract": "In self-supervised reinforcement learning (RL), one of the key challenges is learning a diverse set of skills to prepare agents for unknown future tasks. Despite impressive advances, scalability and evaluation remain prevalent issues. Regarding scalability, the search for meaningful skills can be obscured by high-dimensional feature spaces, where relevant features may vary across downstream task domains. For evaluating skill diversity, defining what constitutes \"diversity\" typically requires a hard commitment to a specific notion of what it means for skills to be diverse, potentially leading to inconsistencies in how skill diversity is understood, making results across different approaches hard to compare, and leaving many forms of diversity unexplored. To address these issues, we adopt a measure of sample diversity that translates ideas from ecology to machine learning -- the Vendi Score -- allowing the user to specify and evaluate any desired form of diversity. We demonstrate how this metric facilitates skill evaluation and introduce VendiRL, a unified framework for learning diversely diverse sets of skills. Given distinct similarity functions, VendiRL motivates distinct forms of diversity, which could support skill-diversity pretraining in new and richly interactive environments where optimising for various forms of diversity may be desirable.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": "17 pages including appendices", "pdf_url": "https://arxiv.org/pdf/2509.02930.pdf", "abstract_url": "https://arxiv.org/abs/2509.02930", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了VendiRL框架，利用Vendi Score度量技能多样性，通过自监督强化学习学习多样化技能集，以应对未知任务。", "motivation": "解决自监督强化学习中技能多样性学习的挑战，包括高维特征空间导致的扩展性问题和多样性定义不一致导致的评估困难。", "method": "采用Vendi Score作为多样性度量，基于生态学概念，允许用户指定和评估任意形式的多样性，并开发VendiRL框架，使用相似性函数激励不同形式的多样性学习。", "result": "VendiRL框架能够促进技能评估，并学习出多样化的技能集，支持在新交互环境中进行技能多样性预训练。", "conclusion": "VendiRL提供了一个统一框架，有效解决了技能多样性学习和评估的问题，具有广泛的应用潜力。"}}
{"id": "2509.03059", "title": "Loong: Synthesize Long Chain-of-Thoughts at Scale through Verifiers", "authors": ["Xingyue Huang", "Rishabh", "Gregor Franke", "Ziyi Yang", "Jiamu Bai", "Weijie Bai", "Jinhe Bi", "Zifeng Ding", "Yiqun Duan", "Chengyu Fan", "Wendong Fan", "Xin Gao", "Ruohao Guo", "Yuan He", "Zhuangzhuang He", "Xianglong Hu", "Neil Johnson", "Bowen Li", "Fangru Lin", "Siyu Lin", "Tong Liu", "Yunpu Ma", "Hao Shen", "Hao Sun", "Beibei Wang", "Fangyijie Wang", "Hao Wang", "Haoran Wang", "Yang Wang", "Yifeng Wang", "Zhaowei Wang", "Ziyang Wang", "Yifan Wu", "Zikai Xiao", "Chengxing Xie", "Fan Yang", "Junxiao Yang", "Qianshuo Ye", "Ziyu Ye", "Guangtao Zeng", "Yuwen Ebony Zhang", "Zeyu Zhang", "Zihao Zhu", "Bernard Ghanem", "Philip Torr", "Guohao Li"], "abstract": "Recent advances in Large Language Models (LLMs) have shown that their reasoning capabilities can be significantly improved through Reinforcement Learning with Verifiable Reward (RLVR), particularly in domains like mathematics and programming, where ground-truth correctness can be automatically evaluated. However, extending this success to other reasoning-intensive domains remains challenging due to the scarcity of high-quality, verifiable datasets and the high cost of human supervision. In this work, we introduce the Loong Project: an open-source framework for scalable synthetic data generation and verification across a diverse range of reasoning-intensive domains. The framework consists of two key components: (1) LoongBench, a curated seed dataset containing 8,729 human-vetted examples across 12 domains (e.g., Advanced Mathematics, Chemistry, Logic), each paired with executable code and rich metadata; and (2) LoongEnv, a modular synthetic data generation environment that supports multiple prompting strategies to produce new question-answer-code triples. Together, these components form an agent-environment loop that enables reinforcement learning, where an LLM-based agent is rewarded for generating Chain-of-Thought (CoT) solutions that align with code-executed answers. Empirically, we benchmark LoongBench on a broad suite of both open-source and proprietary LLMs to evaluate domain coverage and reveal performance bottlenecks. In addition, we conduct a comprehensive analysis of synthetic data generated by LoongEnv, examining correctness, difficulty, and diversity. Code and documentation are available at", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03059.pdf", "abstract_url": "https://arxiv.org/abs/2509.03059", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "Loong项目是一个开源框架，通过合成数据和验证器扩展LLMs的推理能力，覆盖多个领域，包括基准测试和数据分析。", "motivation": "解决在推理密集型领域缺乏高质量可验证数据集和高昂人工监督成本的问题，以提升LLMs的推理性能。", "method": "使用LoongBench种子数据集和LoongEnv合成数据生成环境，结合强化学习和代码执行验证，生成和验证链式思维解决方案。", "result": "基准测试显示广泛的领域覆盖和性能瓶颈识别，合成数据在正确性、难度和多样性方面得到全面分析。", "conclusion": "Loong框架可扩展地提升LLMs推理能力，代码开源，支持未来研究和应用。"}}
{"id": "2509.03118", "title": "A Hierarchical Deep Reinforcement Learning Framework for Traffic Signal Control with Predictable Cycle Planning", "authors": ["Hankang Gu", "Yuli Zhang", "Chengming Wang", "Ruiyuan Jiang", "Ziheng Qiao", "Pengfei Fan", "Dongyao Jia"], "abstract": "Deep reinforcement learning (DRL) has become a popular approach in traffic signal control (TSC) due to its ability to learn adaptive policies from complex traffic environments. Within DRL-based TSC methods, two primary control paradigms are ``choose phase\" and ``switch\" strategies. Although the agent in the choose phase paradigm selects the next active phase adaptively, this paradigm may result in unexpected phase sequences for drivers, disrupting their anticipation and potentially compromising safety at intersections. Meanwhile, the switch paradigm allows the agent to decide whether to switch to the next predefined phase or extend the current phase. While this structure maintains a more predictable order, it can lead to unfair and inefficient phase allocations, as certain movements may be extended disproportionately while others are neglected. In this paper, we propose a DRL model, named Deep Hierarchical Cycle Planner (DHCP), to allocate the traffic signal cycle duration hierarchically. A high-level agent first determines the split of the total cycle time between the North-South (NS) and East-West (EW) directions based on the overall traffic state. Then, a low-level agent further divides the allocated duration within each major direction between straight and left-turn movements, enabling more flexible durations for the two movements. We test our model on both real and synthetic road networks, along with multiple sets of real and synthetic traffic flows. Empirical results show our model achieves the best performance over all datasets against baselines.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03118.pdf", "abstract_url": "https://arxiv.org/abs/2509.03118", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "提出DHCP模型，通过分层深度强化学习优化交通信号控制，平衡可预测性和效率，在真实和合成网络中验证性能最佳。", "motivation": "解决现有DRL交通信号控制方法中，choose phase范式导致相位序列不可预测影响安全，switch范式导致分配不公和低效的问题。", "method": "使用分层DRL框架，高层代理分配总周期时间给南北和东西方向，低层代理进一步分配直行和左转时间，实现灵活控制。", "result": "在真实和合成道路网络及交通流数据集上测试，DHCP模型在所有基准中表现最佳。", "conclusion": "DHCP模型通过分层规划提高了交通信号控制的效率和可预测性，具有实际应用潜力。"}}
{"id": "2509.03206", "title": "Autonomous Learning From Success and Failure: Goal-Conditioned Supervised Learning with Negative Feedback", "authors": ["Zeqiang Zhang", "Fabian Wurzberger", "Gerrit Schmid", "Sebastian Gottwald", "Daniel A. Braun"], "abstract": "Reinforcement learning faces significant challenges when applied to tasks characterized by sparse reward structures. Although imitation learning, within the domain of supervised learning, offers faster convergence, it relies heavily on human-generated demonstrations. Recently, Goal-Conditioned Supervised Learning (GCSL) has emerged as a potential solution by enabling self-imitation learning for autonomous systems. By strategically relabelling goals, agents can derive policy insights from their own experiences. Despite the successes of this framework, it presents two notable limitations: (1) Learning exclusively from self-generated experiences can exacerbate the agents' inherent biases; (2) The relabelling strategy allows agents to focus solely on successful outcomes, precluding them from learning from their mistakes. To address these issues, we propose a novel model that integrates contrastive learning principles into the GCSL framework to learn from both success and failure. Through empirical evaluations, we demonstrate that our algorithm overcomes limitations imposed by agents' initial biases and thereby enables more exploratory behavior. This facilitates the identification and adoption of effective policies, leading to superior performance across a variety of challenging environments.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03206.pdf", "abstract_url": "https://arxiv.org/abs/2509.03206", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种结合对比学习与目标条件监督学习的新模型，使智能体能够从成功和失败中学习，克服偏见并提升性能。", "motivation": "解决强化学习中稀疏奖励问题和模仿学习依赖人类演示的局限性，特别是GCSL框架中只从成功经验学习导致的偏见和无法从错误中学习的问题。", "method": "将对比学习原则整合到GCSL框架中，通过经验重新标记和对比学习机制，使智能体从成功和失败的经验中学习。", "result": "实证评估显示，该算法减少了智能体的初始偏见，促进了探索行为，并在多种挑战性环境中实现了更优的性能。", "conclusion": "该方法通过结合成功和失败学习，提高了自主系统的学习效率和策略效果，具有广泛的应用潜力。"}}
{"id": "2509.03303", "title": "Automatic Differentiation of Agent-Based Models", "authors": ["Arnau Quera-Bofarull", "Nicholas Bishop", "Joel Dyer", "Daniel Jarne Ornia", "Anisoara Calinescu", "Doyne Farmer", "Michael Wooldridge"], "abstract": "Agent-based models (ABMs) simulate complex systems by capturing the bottom-up interactions of individual agents comprising the system. Many complex systems of interest, such as epidemics or financial markets, involve thousands or even millions of agents. Consequently, ABMs often become computationally demanding and rely on the calibration of numerous free parameters, which has significantly hindered their widespread adoption. In this paper, we demonstrate that automatic differentiation (AD) techniques can effectively alleviate these computational burdens. By applying AD to ABMs, the gradients of the simulator become readily available, greatly facilitating essential tasks such as calibration and sensitivity analysis. Specifically, we show how AD enables variational inference (VI) techniques for efficient parameter calibration. Our experiments demonstrate substantial performance improvements and computational savings using VI on three prominent ABMs: Axtell's model of firms; Sugarscape; and the SIR epidemiological model. Our approach thus significantly enhances the practicality and scalability of ABMs for studying complex systems.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03303.pdf", "abstract_url": "https://arxiv.org/abs/2509.03303", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Computational Engineering, Finance, and Science (cs.CE)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过应用自动微分技术到基于代理的模型，显著减轻了计算负担，提高了参数校准和敏感性分析的效率，增强了ABMs在复杂系统研究中的实用性和可扩展性。", "motivation": "解决基于代理的模型（ABMs）在模拟复杂系统时计算需求高、参数校准困难的问题，这些问题限制了ABMs的广泛应用。", "method": "使用自动微分（AD）技术，使模拟器的梯度易于获取，并结合变分推断（VI）方法进行高效的参数校准。", "result": "在三个ABMs（Axtell's model, Sugarscape, SIR模型）上的实验显示，性能显著提升，计算节省明显。", "conclusion": "AD技术有效提升了ABMs的实用性和可扩展性，使其更适合研究复杂系统。"}}
{"id": "2509.03353", "title": "Fair Resource Allocation for Fleet Intelligence", "authors": ["Oguzhan Baser", "Kaan Kale", "Po-han Li", "Sandeep Chinchali"], "abstract": "Resource allocation is crucial for the performance optimization of cloud-assisted multi-agent intelligence. Traditional methods often overlook agents' diverse computational capabilities and complex operating environments, leading to inefficient and unfair resource distribution. To address this, we open-sourced Fair-Synergy, an algorithmic framework that utilizes the concave relationship between the agents' accuracy and the system resources to ensure fair resource allocation across fleet intelligence. We extend traditional allocation approaches to encompass a multidimensional machine learning utility landscape defined by model parameters, training data volume, and task complexity. We evaluate Fair-Synergy with advanced vision and language models such as BERT, VGG16, MobileNet, and ResNets on datasets including MNIST, CIFAR-10, CIFAR-100, BDD, and GLUE. We demonstrate that Fair-Synergy outperforms standard benchmarks by up to 25% in multi-agent inference and 11% in multi-agent learning settings. Also, we explore how the level of fairness affects the least advantaged, most advantaged, and average agents, providing insights for equitable fleet intelligence.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "This paper has been accepted for presentation at the 2025 IEEE Global Communications Conference (GLOBECOM 2025)", "pdf_url": "https://arxiv.org/pdf/2509.03353.pdf", "abstract_url": "https://arxiv.org/abs/2509.03353", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了Fair-Synergy框架，通过利用代理精度与系统资源间的凹关系，确保多智能体智能中的公平资源分配，在推理和学习任务中显著优于基准方法。", "motivation": "解决传统资源分配方法忽视代理计算能力和复杂环境导致的低效和不公平问题。", "method": "扩展传统分配方法，纳入多维机器学习效用景观，包括模型参数、训练数据量和任务复杂性。", "result": "Fair-Synergy在推理和学习设置中分别优于标准基准高达25%和11%，并分析了公平性对不同代理的影响。", "conclusion": "Fair-Synergy提供公平高效的资源分配，促进公平的舰队智能发展。"}}
{"id": "2509.03500", "title": "Real-Time Instrument Planning and Perception for Novel Measurements of Dynamic Phenomena", "authors": ["Itai Zilberstein", "Alberto Candela", "Steve Chien"], "abstract": "Advancements in onboard computing mean remote sensing agents can employ state-of-the-art computer vision and machine learning at the edge. These capabilities can be leveraged to unlock new rare, transient, and pinpoint measurements of dynamic science phenomena. In this paper, we present an automated workflow that synthesizes the detection of these dynamic events in look-ahead satellite imagery with autonomous trajectory planning for a follow-up high-resolution sensor to obtain pinpoint measurements. We apply this workflow to the use case of observing volcanic plumes. We analyze classification approaches including traditional machine learning algorithms and convolutional neural networks. We present several trajectory planning algorithms that track the morphological features of a plume and integrate these algorithms with the classifiers. We show through simulation an order of magnitude increase in the utility return of the high-resolution instrument compared to baselines while maintaining efficient runtimes.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": "Appears in Proceedings of 18th Symposium on Advanced Space Technologies in Robotics and Automation", "pdf_url": "https://arxiv.org/pdf/2509.03500.pdf", "abstract_url": "https://arxiv.org/abs/2509.03500", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种自动化工作流，结合卫星图像中的动态事件检测与自主轨迹规划，用于高分辨率传感器获取精确测量，应用于火山羽流观测，通过模拟显示仪器效用显著提升。", "motivation": "解决如何利用边缘计算和先进视觉技术自动检测和测量稀有、瞬态动态科学现象的问题，以提高观测效率和精度。", "method": "工作流综合了卫星图像中的事件检测（使用传统机器学习和卷积神经网络）与自主轨迹规划算法，跟踪羽流形态特征。", "result": "模拟结果显示，高分辨率仪器的效用回报比基线提高了一个数量级，同时保持了高效的运行时间。", "conclusion": "该方法成功实现了对动态现象如火山羽流的自动、高效观测，具有实际应用潜力，提升了遥感测量的科学价值。"}}
