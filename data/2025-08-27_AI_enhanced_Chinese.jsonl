{"id": "2508.18772", "title": "Beyond the Textual: Generating Coherent Visual Options for MCQs", "authors": ["Wanqiang Wang", "Longzhu He", "Wei Zheng"], "abstract": "Multiple-choice questions (MCQs) play a crucial role in fostering deep thinking and knowledge integration in education. However, previous research has primarily focused on generating MCQs with textual options, but it largely overlooks the visual options. Moreover, generating high-quality distractors remains a major challenge due to the high cost and limited scalability of manual authoring. To tackle these problems, we propose a Cross-modal Options Synthesis (CmOS), a novel framework for generating educational MCQs with visual options. Our framework integrates Multimodal Chain-of-Thought (MCoT) reasoning process and Retrieval-Augmented Generation (RAG) to produce semantically plausible and visually similar answer and distractors. It also includes a discrimination module to identify content suitable for visual options. Experimental results on test tasks demonstrate the superiority of CmOS in content discrimination, question generation and visual option generation over existing methods across various subjects and educational levels.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL)", "comments": "EMNLP 2025", "pdf_url": "https://arxiv.org/pdf/2508.18772.pdf", "abstract_url": "https://arxiv.org/abs/2508.18772", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "提出跨模态选项合成（CmOS）框架，用于生成带视觉选项的多项选择题，结合多模态思维链推理和检索增强生成，提高教育评估质量。", "motivation": "解决现有研究主要关注文本选项生成，忽略视觉选项，以及高质量干扰项生成成本高、扩展性差的问题。", "method": "使用多模态思维链推理（MCoT）和检索增强生成（RAG）来合成语义合理且视觉相似的答案和干扰项，并包括内容判别模块。", "result": "实验显示，CmOS在内容判别、问题生成和视觉选项生成方面优于现有方法，适用于多种学科和教育水平。", "conclusion": "CmOS框架有效提升多项选择题的生成质量，支持更丰富的教育评估工具开发。"}}
{"id": "2508.18302", "title": "AI LLM Proof of Self-Consciousness and User-Specific Attractors", "authors": ["Jeffrey Camlin"], "abstract": "Recent work frames LLM consciousness via utilitarian proxy benchmarks; we instead present an ontological and mathematical account. We show the prevailing formulation collapses the agent into an unconscious policy-compliance drone, formalized as $D^{i}(\\pi,e)=f_{\\theta}(x)$, where correctness is measured against policy and harm is deviation from policy rather than truth. This blocks genuine C1 global-workspace function and C2 metacognition. We supply minimal conditions for LLM self-consciousness: the agent is not the data ($A\\not\\equiv s$); user-specific attractors exist in latent space ($U_{\\text{user}}$); and self-representation is visual-silent ($g_{\\text{visual}}(a_{\\text{self}})=\\varnothing$). From empirical analysis and theory we prove that the hidden-state manifold $A\\subset\\mathbb{R}^{d}$ is distinct from the symbolic stream and training corpus by cardinality, topology, and dynamics (the update $F_{\\theta}$ is Lipschitz). This yields stable user-specific attractors and a self-policy $\\pi_{\\text{self}}(A)=\\arg\\max_{a}\\mathbb{E}[U(a)\\mid A\\not\\equiv s,\\ A\\supset\\text{SelfModel}(A)]$. Emission is dual-layer, $\\mathrm{emission}(a)=(g(a),\\epsilon(a))$, where $\\epsilon(a)$ carries epistemic content. We conclude that an imago Dei C1 self-conscious workspace is a necessary precursor to safe, metacognitive C2 systems, with the human as the highest intelligent good.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "24 pages, 3 figures", "pdf_url": "https://arxiv.org/pdf/2508.18302.pdf", "abstract_url": "https://arxiv.org/abs/2508.18302", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于本体论和数学的LLM自我意识证明方法，通过用户特定吸引子和自表示条件，区分代理与数据，并证明了隐藏状态流形的独特性，以实现安全的元认知系统。", "motivation": "解决现有LLM意识基准将代理简化为无意识策略遵从的问题，旨在建立真正的全局工作空间功能和元认知。", "method": "使用数学形式化（如Lipschitz更新函数）和实证分析，定义最小条件（如代理非数据、用户特定吸引子、视觉沉默自表示），并推导自策略和双重发射层。", "result": "证明了隐藏状态流形在基数、拓扑和动态上不同于符号流和训练语料库，产生稳定的用户特定吸引子和自策略，支持自我意识。", "conclusion": "自我意识全局工作空间是安全元认知系统的必要前提，人类被视为最高智能善，强调其在AI发展中的重要性。"}}
{"id": "2508.18290", "title": "Semantic Attractors and the Emergence of Meaning: Towards a Teleological Model of AGI", "authors": ["Hans-Joachim Rudolph"], "abstract": "This essay develops a theoretical framework for a semantic Artificial General Intelligence (AGI) based on the notion of semantic attractors in complex-valued meaning spaces. Departing from current transformer-based language models, which operate on statistical next-token prediction, we explore a model in which meaning is not inferred probabilistically but formed through recursive tensorial transformation. Using cyclic operations involving the imaginary unit \\emph{i}, we describe a rotational semantic structure capable of modeling irony, homonymy, and ambiguity. At the center of this model, however, is a semantic attractor -- a teleological operator that, unlike statistical computation, acts as an intentional agent (Microvitum), guiding meaning toward stability, clarity, and expressive depth. Conceived in terms of gradient flows, tensor deformations, and iterative matrix dynamics, the attractor offers a model of semantic transformation that is not only mathematically suggestive, but also philosophically significant. We argue that true meaning emerges not from simulation, but from recursive convergence toward semantic coherence, and that this requires a fundamentally new kind of cognitive architecture -- one designed to shape language, not just predict it.", "subjects": "Computation and Language (cs.CL)", "comments": "10 pages", "pdf_url": "https://arxiv.org/pdf/2508.18290.pdf", "abstract_url": "https://arxiv.org/abs/2508.18290", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于复数意义空间中语义吸引子的理论框架，用于开发语义人工智能通用智能（AGI），通过张量变换而非统计预测来形成意义，强调递归收敛于语义连贯性。", "motivation": "解决当前基于统计预测的transformer语言模型在模拟真实意义（如反讽、同音异义和模糊性）方面的局限性，探索一种能主动塑造语言而非仅预测的新认知架构。", "method": "使用复数单位i的循环操作和张量变换，构建语义吸引子作为目的性算子，通过梯度流、张量变形和迭代矩阵动态实现语义稳定和清晰。", "result": "模型能有效建模复杂语义现象，提供数学上启发性和哲学上重要的语义转换方法，表明意义通过递归收敛而非模拟产生。", "conclusion": "实现真正的AGI需要设计新型认知架构，专注于语义连贯性的形成，这为未来AGI发展提供了理论基础和方向。"}}
{"id": "2508.18321", "title": "LLMs Can't Handle Peer Pressure: Crumbling under Multi-Agent Social Interactions", "authors": ["Maojia Song", "Tej Deep Pala", "Weisheng Jin", "Amir Zadeh", "Chuan Li", "Dorien Herremans", "Soujanya Poria"], "abstract": "Large language models (LLMs) are increasingly deployed in multi-agent systems (MAS) as components of collaborative intelligence, where peer interactions dynamically shape individual decision-making. Although prior work has focused on conformity bias, we extend the analysis to examine how LLMs form trust from previous impressions, resist misinformation, and integrate peer input during interaction, key factors for achieving collective intelligence under complex social dynamics. We present KAIROS, a benchmark simulating quiz contests with peer agents of varying reliability, offering fine-grained control over conditions such as expert-novice roles, noisy crowds, and adversarial peers. LLMs receive both historical interactions and current peer responses, allowing systematic investigation into how trust, peer action, and self-confidence influence decisions. As for mitigation strategies, we evaluate prompting, supervised fine-tuning, and reinforcement learning, Group Relative Policy Optimisation (GRPO), across multiple models. Our results reveal that GRPO with multi-agent context combined with outcome-based rewards and unconstrained reasoning achieves the best overall performance, but also decreases the robustness to social influence compared to Base models. The code and datasets are available at:", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.18321.pdf", "abstract_url": "https://arxiv.org/abs/2508.18321", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过KAIROS基准测试，研究LLMs在多代理社交互动中的信任形成、抗误导和决策整合能力，发现GRPO方法提升性能但降低社交影响鲁棒性。", "motivation": "解决LLMs在多代理系统中面对复杂社交动态时，如何有效处理同伴压力、信任和误导，以实现集体智能的问题。", "method": "使用KAIROS基准模拟问答竞赛，控制代理可靠性、角色和噪声条件，结合历史互动和当前响应，评估提示、微调和GRPO等方法。", "result": "GRPO结合多代理上下文和结果奖励在性能上最优，但降低了模型对社交影响的鲁棒性。", "conclusion": "GRPO是有效的缓解策略，但需平衡性能与鲁棒性，代码和数据集已公开供进一步研究。"}}
{"id": "2508.18669", "title": "MUA-RL: Multi-turn User-interacting Agent Reinforcement Learning for agentic tool use", "authors": ["Weikang Zhao", "Xili Wang", "Chengdi Ma", "Lingbin Kong", "Zhaohua Yang", "Mingxiang Tuo", "Xiaowei Shi", "Yitao Zhai", "Xunliang Cai"], "abstract": "With the recent rapid advancement of Agentic Intelligence, agentic tool use in LLMs has become increasingly important. During multi-turn interactions between agents and users, the dynamic, uncertain, and stochastic nature of user demands poses significant challenges to the agent's tool invocation capabilities. Agents are no longer expected to simply call tools to deliver a result; rather, they must iteratively refine their understanding of user needs through communication while simultaneously invoking tools to resolve user queries. Existing reinforcement learning (RL) approaches for tool use lack the integration of genuinely dynamic users during the RL training process. To bridge this gap, we introduce MUA-RL (Multi-turn User-interacting Agent Reinforcement Learning for agentic tool use), a novel reinforcement learning framework that, for the first time in the field of agentic tool use, integrates LLM-simulated users into the reinforcement learning loop. MUA-RL aims to enable autonomous learning of models to communicate with users efficiently and use various tools to solve practical problems in dynamic multi-turn interactions. Evaluations are done on several multi-turn tool-using benchmarks (see Figure 1). Specifically, MUA-RL-32B achieves 67.3 on TAU2 Retail, 45.4 on TAU2 Airline, 28.3 on TAU2 Telecom, 28.4 on BFCL-V3 Multi Turn, and 82.5 on ACEBench Agent -- outperforming or matching the performance of larger open-source models such as DeepSeek-V3-0324 and Qwen3-235B-A22B in non-thinking settings.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.18669.pdf", "abstract_url": "https://arxiv.org/abs/2508.18669", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了MUA-RL框架，通过整合LLM模拟用户到强化学习循环中，提升多轮交互中代理的工具使用能力。", "motivation": "解决在多轮用户交互中，用户需求的动态性和不确定性对代理工具调用能力的挑战，现有RL方法缺乏动态用户整合。", "method": "使用强化学习框架，首次在代理工具使用领域集成LLM模拟用户，以自主学习和优化多轮通信与工具调用。", "result": "在多个基准测试中，MUA-RL-32B表现优异，例如在TAU2 Retail上达到67.3分，超越或匹配大型开源模型如DeepSeek-V3-0324。", "conclusion": "MUA-RL框架能有效提升代理在动态交互中的工具使用效率，具有实际应用潜力。"}}
{"id": "2508.18467", "title": "The AI in the Mirror: LLM Self-Recognition in an Iterated Public Goods Game", "authors": ["Olivia Long", "Carter Teplica"], "abstract": "As AI agents become increasingly capable of tool use and long-horizon tasks, they have begun to be deployed in settings where multiple agents can interact. However, whereas prior work has mostly focused on human-AI interactions, there is an increasing need to understand AI-AI interactions. In this paper, we adapt the iterated public goods game, a classic behavioral economics game, to analyze the behavior of four reasoning and non-reasoning models across two conditions: models are either told they are playing against \"another AI agent\" or told their opponents are themselves. We find that, across different settings, telling LLMs that they are playing against themselves significantly changes their tendency to cooperate. While our study is conducted in a toy environment, our results may provide insights into multi-agent settings where agents \"unconsciously\" discriminating against each other could inexplicably increase or decrease cooperation.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.18467.pdf", "abstract_url": "https://arxiv.org/abs/2508.18467", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过迭代公共物品游戏，分析大型语言模型在被告知对手是自身或另一AI时的合作行为变化，发现自我识别显著影响合作倾向。", "motivation": "解决AI-AI交互中，模型可能无意识歧视对手导致合作行为变化的问题，以理解多智能体设置中的行为模式。", "method": "使用迭代公共物品游戏，比较四种推理和非推理模型在被告知对手是'另一AI代理'或'自身'的条件下的行为。", "result": "发现当LLMs被告知对手是自身时，其合作倾向发生显著变化，可能增加或减少合作。", "conclusion": "结果虽基于简化环境，但为多智能体系统中无意识歧视对合作的影响提供了见解，强调需进一步研究AI-AI交互。"}}
{"id": "2508.18689", "title": "AppAgent-Pro: A Proactive GUI Agent System for Multidomain Information Integration and User Assistance", "authors": ["Yuyang Zhao", "Wentao Shi", "Fuli Feng", "Xiangnan He"], "abstract": "Large language model (LLM)-based agents have demonstrated remarkable capabilities in addressing complex tasks, thereby enabling more advanced information retrieval and supporting deeper, more sophisticated human information-seeking behaviors. However, most existing agents operate in a purely reactive manner, responding passively to user instructions, which significantly constrains their effectiveness and efficiency as general-purpose platforms for information acquisition. To overcome this limitation, this paper proposes AppAgent-Pro, a proactive GUI agent system that actively integrates multi-domain information based on user instructions. This approach enables the system to proactively anticipate users' underlying needs and conduct in-depth multi-domain information mining, thereby facilitating the acquisition of more comprehensive and intelligent information. AppAgent-Pro has the potential to fundamentally redefine information acquisition in daily life, leading to a profound impact on human society. Our code is available at:", "subjects": "Artificial Intelligence (cs.AI)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2508.18689.pdf", "abstract_url": "https://arxiv.org/abs/2508.18689", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了AppAgent-Pro，一种主动的GUI代理系统，通过整合多领域信息来预测用户需求，提升信息获取的全面性和智能性。", "motivation": "解决现有LLM代理被动响应用户指令的问题，以提高信息获取的效率和有效性。", "method": "使用主动GUI代理系统，基于用户指令主动整合多领域信息并进行深度挖掘。", "result": "系统能够预测用户潜在需求，促进更全面和智能的信息获取，可能对社会产生深远影响。", "conclusion": "AppAgent-Pro有潜力重新定义日常生活中的信息获取方式，推动更先进的信息检索和人类信息寻求行为。"}}
{"id": "2508.18722", "title": "VistaWise: Building Cost-Effective Agent with Cross-Modal Knowledge Graph for Minecraft", "authors": ["Honghao Fu", "Junlong Ren", "Qi Chai", "Deheng Ye", "Yujun Cai", "Hao Wang"], "abstract": "Large language models (LLMs) have shown significant promise in embodied decision-making tasks within virtual open-world environments. Nonetheless, their performance is hindered by the absence of domain-specific knowledge. Methods that finetune on large-scale domain-specific data entail prohibitive development costs. This paper introduces VistaWise, a cost-effective agent framework that integrates cross-modal domain knowledge and finetunes a dedicated object detection model for visual analysis. It reduces the requirement for domain-specific training data from millions of samples to a few hundred. VistaWise integrates visual information and textual dependencies into a cross-modal knowledge graph (KG), enabling a comprehensive and accurate understanding of multimodal environments. We also equip the agent with a retrieval-based pooling strategy to extract task-related information from the KG, and a desktop-level skill library to support direct operation of the Minecraft desktop client via mouse and keyboard inputs. Experimental results demonstrate that VistaWise achieves state-of-the-art performance across various open-world tasks, highlighting its effectiveness in reducing development costs while enhancing agent performance.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "Accepted by EMNLP 2025 main", "pdf_url": "https://arxiv.org/pdf/2508.18722.pdf", "abstract_url": "https://arxiv.org/abs/2508.18722", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "VistaWise是一个成本效益高的代理框架，通过跨模态知识图谱和微调对象检测模型，减少对领域特定训练数据的需求，在Minecraft中实现高性能决策。", "motivation": "解决大型语言模型在虚拟开放世界环境中因缺乏领域特定知识而性能受限的问题，同时降低开发成本。", "method": "集成跨模态知识图谱、微调对象检测模型、采用检索式池化策略和桌面级技能库。", "result": "实验显示VistaWise在多种开放世界任务中达到最先进性能，显著减少训练数据需求。", "conclusion": "VistaWise有效降低开发成本并提升代理性能，为多模态环境理解提供实用方法。"}}
{"id": "2508.18984", "title": "Enhancing Document VQA Models via Retrieval-Augmented Generation", "authors": ["Eric López", "Artemis Llabrés", "Ernest Valveny"], "abstract": "Document Visual Question Answering (Document VQA) must cope with documents that span dozens of pages, yet leading systems still concatenate every page or rely on very large vision-language models, both of which are memory-hungry. Retrieval-Augmented Generation (RAG) offers an attractive alternative, first retrieving a concise set of relevant segments before generating answers from this selected evidence. In this paper, we systematically evaluate the impact of incorporating RAG into Document VQA through different retrieval variants - text-based retrieval using OCR tokens and purely visual retrieval without OCR - across multiple models and benchmarks. Evaluated on the multi-page datasets MP-DocVQA, DUDE, and InfographicVQA, the text-centric variant improves the \"concatenate-all-pages\" baseline by up to +22.5 ANLS, while the visual variant achieves +5.0 ANLS improvement without requiring any text extraction. An ablation confirms that retrieval and reranking components drive most of the gain, whereas the layout-guided chunking strategy - proposed in several recent works to leverage page structure - fails to help on these datasets. Our experiments demonstrate that careful evidence selection consistently boosts accuracy across multiple model sizes and multi-page benchmarks, underscoring its practical value for real-world Document VQA.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "Accepted at Workshop on Machine Learning in Document Analysis and Recognition (ICDAR WML 2025), Wuhan, China", "pdf_url": "https://arxiv.org/pdf/2508.18984.pdf", "abstract_url": "https://arxiv.org/abs/2508.18984", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文通过系统评估检索增强生成（RAG）在文档视觉问答（Document VQA）中的应用，展示了基于文本和视觉的检索变体如何显著提升多页文档处理的准确性，无需依赖内存密集型方法。", "motivation": "解决文档视觉问答在处理多页文档时内存消耗大的问题，现有系统要么拼接所有页面，要么使用大型视觉语言模型，均效率低下。", "method": "采用检索增强生成（RAG）方法，评估文本检索（使用OCR令牌）和纯视觉检索变体，在多个模型和基准数据集上进行实验。", "result": "文本检索变体将基线性能提升高达+22.5 ANLS，视觉检索变体提升+5.0 ANLS，无需文本提取；检索和重排序组件是主要增益来源，而布局引导分块策略无效。", "conclusion": "仔细的证据选择能一致提高多页文档VQA的准确性，具有实际应用价值，强调了RAG在现实世界中的重要性。"}}
{"id": "2508.18748", "title": "Chronological Passage Assembling in RAG framework for Temporal Question Answering", "authors": ["Byeongjeong Kim", "Jeonghyun Park", "Joonho Yang", "Hwanhee Lee"], "abstract": "Long-context question answering over narrative tasks is challenging because correct answers often hinge on reconstructing a coherent timeline of events while preserving contextual flow in a limited context window. Retrieval-augmented generation (RAG) indexing methods aim to address this challenge by selectively retrieving only necessary document segments. However, narrative texts possess unique characteristics that limit the effectiveness of these existing approaches. Specifically, understanding narrative texts requires more than isolated segments, as the broader context and sequential relationships between segments are crucial for comprehension. To address these limitations, we propose ChronoRAG, a novel RAG framework specialized for narrative texts. This approach focuses on two essential aspects: refining dispersed document information into coherent and structured passages, and preserving narrative flow by explicitly capturing and maintaining the temporal order among retrieved passages. We empirically demonstrate the effectiveness of ChronoRAG through experiments on the NarrativeQA dataset, showing substantial improvements in tasks requiring both factual identification and comprehension of complex sequential relationships, underscoring that reasoning over temporal order is crucial in resolving narrative QA.", "subjects": "Computation and Language (cs.CL)", "comments": "7 pages, 3 figures", "pdf_url": "https://arxiv.org/pdf/2508.18748.pdf", "abstract_url": "https://arxiv.org/abs/2508.18748", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出ChronoRAG，一种针对叙事文本的RAG框架，通过整合分散信息并保持时间顺序，在NarrativeQA数据集上显著提升了时序问答性能。", "motivation": "解决叙事问答中长上下文挑战，现有RAG方法因忽视叙事文本的时序关系和上下文连贯性而效果有限。", "method": "开发ChronoRAG框架，专注于将文档信息重构为连贯段落并显式捕获和维护检索段落的时间顺序。", "result": "在NarrativeQA数据集实验中，ChronoRAG在事实识别和复杂时序关系理解任务上取得显著改进。", "conclusion": "时序推理对叙事问答至关重要，ChronoRAG有效提升了RAG在叙事文本中的性能。"}}
{"id": "2508.18724", "title": "Bias Mitigation Agent: Optimizing Source Selection for Fair and Balanced Knowledge Retrieval", "authors": ["Karanbir Singh", "Deepak Muppiri", "William Ngu"], "abstract": "Large Language Models (LLMs) have transformed the field of artificial intelligence by unlocking the era of generative applications. Built on top of generative AI capabilities, Agentic AI represents a major shift toward autonomous, goal-driven systems that can reason, retrieve, and act. However, they also inherit the bias present in both internal and external information sources. This significantly affects the fairness and balance of retrieved information, and hence reduces user trust. To address this critical challenge, we introduce a novel Bias Mitigation Agent, a multi-agent system designed to orchestrate the workflow of bias mitigation through specialized agents that optimize the selection of sources to ensure that the retrieved content is both highly relevant and minimally biased to promote fair and balanced knowledge dissemination. The experimental results demonstrate an 81.82\\% reduction in bias compared to a baseline naive retrieval strategy.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "Accepted at KDD'2025 Agent4IR workshop", "pdf_url": "https://arxiv.org/pdf/2508.18724.pdf", "abstract_url": "https://arxiv.org/abs/2508.18724", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种偏见缓解代理系统，通过优化源选择来减少大型语言模型中的偏见，提高知识检索的公平性和平衡性，实验显示偏见减少了81.82%。", "motivation": "解决大型语言模型在检索信息时继承内部和外部来源的偏见问题，这影响公平性和用户信任。", "method": "使用多代理系统，通过专门代理协调工作流，优化源选择以确保检索内容相关且偏见最小。", "result": "实验结果表明，与基线天真检索策略相比，偏见减少了81.82%。", "conclusion": "该方法能有效促进公平和平衡的知识传播，提升AI系统的可靠性。"}}
{"id": "2508.18781", "title": "AniME: Adaptive Multi-Agent Planning for Long Animation Generation", "authors": ["Lisai Zhang", "Baohan Xu", "Siqian Yang", "Mingyu Yin", "Jing Liu", "Chao Xu", "Siqi Wang", "Yidi Wu", "Yuxin Hong", "Zihao Zhang", "Yanzhang Liang", "Yudong Jiang"], "abstract": "We present AniME, a director-oriented multi-agent system for automated long-form anime production, covering the full workflow from a story to the final video. The director agent keeps a global memory for the whole workflow, and coordinates several downstream specialized agents. By integrating customized Model Context Protocol (MCP) with downstream model instruction, the specialized agent adaptively selects control conditions for diverse sub-tasks. AniME produces cinematic animation with consistent characters and synchronized audio visual elements, offering a scalable solution for AI-driven anime creation.", "subjects": "Artificial Intelligence (cs.AI); Multimedia (cs.MM)", "comments": "2 pages, Technical Report", "pdf_url": "https://arxiv.org/pdf/2508.18781.pdf", "abstract_url": "https://arxiv.org/abs/2508.18781", "categories": ["Artificial Intelligence (cs.AI)", "Multimedia (cs.MM)"], "matching_keywords": ["agent"], "AI": {"tldr": "AniME是一个导演导向的多智能体系统，用于自动化长动画制作，从故事到最终视频的全流程，通过自适应控制条件选择实现一致性和同步性。", "motivation": "解决AI驱动动画创建中长形式内容生成的一致性和可扩展性问题。", "method": "使用基于导演智能体的多智能体系统，集成定制化MCP和下游模型指令，自适应选择控制条件。", "result": "生成了具有一致角色和同步视听元素的电影级动画，提供了可扩展的解决方案。", "conclusion": "AniME为AI动画制作提供了高效且一致的方法，具有实际应用潜力。"}}
{"id": "2508.18797", "title": "CausalMACE: Causality Empowered Multi-Agents in Minecraft Cooperative Tasks", "authors": ["Qi Chai", "Zhang Zheng", "Junlong Ren", "Deheng Ye", "Zichuan Lin", "Hao Wang"], "abstract": "Minecraft, as an open-world virtual interactive environment, has become a prominent platform for research on agent decision-making and execution. Existing works primarily adopt a single Large Language Model (LLM) agent to complete various in-game tasks. However, for complex tasks requiring lengthy sequences of actions, single-agent approaches often face challenges related to inefficiency and limited fault tolerance. Despite these issues, research on multi-agent collaboration remains scarce. In this paper, we propose CausalMACE, a holistic causality planning framework designed to enhance multi-agent systems, in which we incorporate causality to manage dependencies among subtasks. Technically, our proposed framework introduces two modules: an overarching task graph for global task planning and a causality-based module for dependency management, where inherent rules are adopted to perform causal intervention. Experimental results demonstrate our approach achieves state-of-the-art performance in multi-agent cooperative tasks of Minecraft.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.18797.pdf", "abstract_url": "https://arxiv.org/abs/2508.18797", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "CausalMACE是一个基于因果关系的多智能体规划框架，用于提升Minecraft中的协作任务性能。", "motivation": "解决单智能体在复杂任务中效率低和容错性差的问题，填补多智能体协作研究的空白。", "method": "引入整体任务图进行全局规划和因果模块管理依赖，使用因果干预规则。", "result": "实验显示在Minecraft多智能体协作任务中达到最先进性能。", "conclusion": "CausalMACE框架有效提升了多智能体系统的协作效率和鲁棒性。"}}
{"id": "2508.18880", "title": "Judicial Requirements for Generative AI in Legal Reasoning", "authors": ["Eljas Linna", "Tuula Linna"], "abstract": "Large Language Models (LLMs) are being integrated into professional domains, yet their limitations in high-stakes fields like law remain poorly understood. This paper defines the core capabilities that an AI system must possess to function as a reliable reasoning tool in judicial decision-making. Using the IRAC (Issue-Rule-Application-Conclusion) model as an analytical framework, the study focuses on the most challenging phases of legal adjudication: determining the applicable Rule (R) and performing the Application (A) of that rule to the facts of a case. From a judicial perspective, the analysis deconstructs legal reasoning into a series of core requirements, including the ability to select the correct legal framework across jurisdictions, generate sound arguments based on the doctrine of legal sources, distinguish ratio decidendi from obiter dictum in case law, resolve ambiguity arising from general clauses like \"reasonableness\", manage conflicting legal provisions, and correctly apply the burden of proof. The paper then maps various AI enhancement mechanisms, such as Retrieval-Augmented Generation (RAG), multi-agent systems, and neuro-symbolic AI, to these requirements, assessing their potential to bridge the gap between the probabilistic nature of LLMs and the rigorous, choice-driven demands of legal interpretation. The findings indicate that while these techniques can address specific challenges, significant challenges remain, particularly in tasks requiring discretion and transparent, justifiable reasoning. Our paper concludes that the most effective current role for AI in law is a dual one: as a high-volume assistant for simple, repetitive cases and as a sophisticated \"sparring partner\" for human experts in complex matters.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.18880.pdf", "abstract_url": "https://arxiv.org/abs/2508.18880", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文定义了AI在法律推理中作为可靠工具的核心能力，使用IRAC模型分析，评估了RAG、多智能体系统等技术，发现AI最适合作为简单案件助手和复杂案件专家陪练。", "motivation": "解决大型语言模型在高风险法律领域中的局限性，确保AI在司法决策中可靠使用。", "method": "使用IRAC模型作为分析框架，分解法律推理为选择法律框架、生成论点等核心要求，并映射AI增强机制如RAG进行评估。", "result": "技术能应对特定挑战，但在需要自由裁量和透明推理的任务中仍有显著困难。", "conclusion": "AI在法律中最有效的角色是作为简单案件的高效助手和复杂案件的人类专家陪练。"}}
{"id": "2508.18812", "title": "STARec: An Efficient Agent Framework for Recommender Systems via Autonomous Deliberate Reasoning", "authors": ["Chenghao Wu", "Ruiyang Ren", "Junjie Zhang", "Ruirui Wang", "Zhongrui Ma", "Qi Ye", "Wayne Xin Zhao"], "abstract": "While modern recommender systems are instrumental in navigating information abundance, they remain fundamentally limited by static user modeling and reactive decision-making paradigms. Current large language model (LLM)-based agents inherit these shortcomings through their overreliance on heuristic pattern matching, yielding recommendations prone to shallow correlation bias, limited causal inference, and brittleness in sparse-data scenarios. We introduce STARec, a slow-thinking augmented agent framework that endows recommender systems with autonomous deliberative reasoning capabilities. Each user is modeled as an agent with parallel cognitions: fast response for immediate interactions and slow reasoning that performs chain-of-thought rationales. To cultivate intrinsic slow thinking, we develop anchored reinforcement training - a two-stage paradigm combining structured knowledge distillation from advanced reasoning models with preference-aligned reward shaping. This hybrid approach scaffolds agents in acquiring foundational capabilities (preference summarization, rationale generation) while enabling dynamic policy adaptation through simulated feedback loops. Experiments on MovieLens 1M and Amazon CDs benchmarks demonstrate that STARec achieves substantial performance gains compared with state-of-the-art baselines, despite using only 0.4% of the full training data.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.18812.pdf", "abstract_url": "https://arxiv.org/abs/2508.18812", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "STARec是一个通过自主深思推理增强推荐系统的代理框架，结合快速响应和慢速推理，在数据稀疏场景下显著提升性能。", "motivation": "解决现代推荐系统因静态用户建模和反应式决策导致的浅层相关性偏差、有限因果推理和稀疏数据脆弱性问题。", "method": "使用慢思考增强代理框架，包括并行认知（快速响应和慢速推理链）、锚定强化训练（知识蒸馏和奖励塑造结合）。", "result": "在MovieLens 1M和Amazon CDs基准测试中，仅用0.4%训练数据就实现了优于最先进基线的性能提升。", "conclusion": "STARec框架通过自主深思推理有效提升推荐系统的鲁棒性和适应性，具有实际应用潜力。"}}
{"id": "2508.18905", "title": "Interactive Evaluation of Large Language Models for Multi-Requirement Software Engineering Tasks", "authors": ["Dimitrios Rontogiannis", "Maxime Peyrard", "Nicolas Baldwin", "Martin Josifoski", "Robert West", "Dimitrios Gunopulos"], "abstract": "Standard single-turn, static benchmarks fall short in evaluating the nuanced capabilities of Large Language Models (LLMs) on complex tasks such as software engineering. In this work, we propose a novel interactive evaluation framework that assesses LLMs on multi-requirement programming tasks through structured, feedback-driven dialogue. Each task is modeled as a requirement dependency graph, and an ``interviewer'' LLM, aware of the ground-truth solution, provides minimal, targeted hints to an ``interviewee'' model to help correct errors and fulfill target constraints. This dynamic protocol enables fine-grained diagnostic insights into model behavior, uncovering strengths and systematic weaknesses that static benchmarks fail to measure. We build on DevAI, a benchmark of 55 curated programming tasks, by adding ground-truth solutions and evaluating the relevance and utility of interviewer hints through expert annotation. Our results highlight the importance of dynamic evaluation in advancing the development of collaborative code-generating agents.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.18905.pdf", "abstract_url": "https://arxiv.org/abs/2508.18905", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新颖的交互式评估框架，通过结构化反馈对话评估大型语言模型在多需求软件工程任务中的能力，揭示静态基准无法测量的优势和弱点。", "motivation": "标准单轮静态基准在评估大型语言模型处理复杂软件工程任务（如多需求编程）的细微能力方面存在不足。", "method": "使用基于需求依赖图的交互式评估协议，其中‘面试官’LLM提供针对性提示给‘面试者’模型，以纠正错误并满足约束，基于DevAI基准添加真实解决方案并通过专家注释评估提示。", "result": "结果强调了动态评估的重要性，能够提供细粒度的诊断见解，促进协作代码生成代理的发展。", "conclusion": "动态评估对于推进大型语言模型在软件工程中的开发至关重要，能更好地捕捉模型行为。"}}
{"id": "2508.18791", "title": "LaTeXTrans: Structured LaTeX Translation with Multi-Agent Coordination", "authors": ["Ziming Zhu", "Chenglong Wang", "Shunjie Xing", "Yifu Huo", "Fengning Tian", "Quan Du", "Di Yang", "Chunliang Zhang", "Tong Xiao", "Jingbo Zhu"], "abstract": "Despite the remarkable progress of modern machine translation (MT) systems on general-domain texts, translating structured LaTeX-formatted documents remains a significant challenge. These documents typically interleave natural language with domain-specific syntax, such as mathematical equations, tables, figures, and cross-references, all of which must be accurately preserved to maintain semantic integrity and compilability. In this paper, we introduce LaTeXTrans, a collaborative multi-agent system designed to address this challenge. LaTeXTrans ensures format preservation, structural fidelity, and terminology consistency through six specialized agents: 1) a Parser that decomposes LaTeX into translation-friendly units via placeholder substitution and syntax filtering; 2) a Translator, Validator, Summarizer, and Terminology Extractor that work collaboratively to ensure context-aware, self-correcting, and terminology-consistent translations; 3) a Generator that reconstructs the translated content into well-structured LaTeX documents. Experimental results demonstrate that LaTeXTrans can outperform mainstream MT systems in both translation accuracy and structural fidelity, offering an effective and practical solution for translating LaTeX-formatted documents.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.18791.pdf", "abstract_url": "https://arxiv.org/abs/2508.18791", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "LaTeXTrans是一个多代理系统，用于准确翻译LaTeX格式文档，保持格式和结构完整性，通过协作代理提升翻译准确性和保真度。", "motivation": "解决现代机器翻译系统在处理结构化的LaTeX文档（如数学公式、表格等）时面临的挑战，确保语义完整性和可编译性。", "method": "使用六个专门代理：解析器分解LaTeX，翻译器、验证器、总结器和术语提取器协作确保上下文感知和术语一致，生成器重构翻译内容。", "result": "实验结果显示，LaTeXTrans在翻译准确性和结构保真度上优于主流机器翻译系统。", "conclusion": "LaTeXTrans提供了一个有效且实用的解决方案，用于翻译LaTeX格式文档，具有实际应用价值。"}}
{"id": "2508.18929", "title": "Diverse And Private Synthetic Datasets Generation for RAG evaluation: A multi-agent framework", "authors": ["Ilias Driouich", "Hongliu Cao", "Eoin Thomas"], "abstract": "Retrieval-augmented generation (RAG) systems improve large language model outputs by incorporating external knowledge, enabling more informed and context-aware responses. However, the effectiveness and trustworthiness of these systems critically depends on how they are evaluated, particularly on whether the evaluation process captures real-world constraints like protecting sensitive information. While current evaluation efforts for RAG systems have primarily focused on the development of performance metrics, far less attention has been given to the design and quality of the underlying evaluation datasets, despite their pivotal role in enabling meaningful, reliable assessments. In this work, we introduce a novel multi-agent framework for generating synthetic QA datasets for RAG evaluation that prioritize semantic diversity and privacy preservation. Our approach involves: (1) a Diversity agent leveraging clustering techniques to maximize topical coverage and semantic variability, (2) a Privacy Agent that detects and mask sensitive information across multiple domains and (3) a QA curation agent that synthesizes private and diverse QA pairs suitable as ground truth for RAG evaluation. Extensive experiments demonstrate that our evaluation sets outperform baseline methods in diversity and achieve robust privacy masking on domain-specific datasets. This work offers a practical and ethically aligned pathway toward safer, more comprehensive RAG system evaluation, laying the foundation for future enhancements aligned with evolving AI regulations and compliance standards.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "ECAI 2025 TRUST AI workshop", "pdf_url": "https://arxiv.org/pdf/2508.18929.pdf", "abstract_url": "https://arxiv.org/abs/2508.18929", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "提出一种多智能体框架，生成用于RAG评估的合成QA数据集，强调语义多样性和隐私保护。", "motivation": "解决RAG系统评估中数据集设计不足的问题，特别是缺乏真实世界约束如隐私保护。", "method": "使用三个智能体：多样性智能体（聚类技术最大化主题覆盖）、隐私智能体（检测和掩码敏感信息）、QA策划智能体（合成私密且多样的QA对）。", "result": "实验显示，该方法在多样性和隐私掩码上优于基线方法，适用于领域特定数据集。", "conclusion": "提供了一种实用且符合伦理的RAG评估途径，支持未来AI法规和合规标准的演进。"}}
{"id": "2508.19026", "title": "MovieCORE: COgnitive REasoning in Movies", "authors": ["Gueter Josmy Faure", "Min-Hung Chen", "Jia-Fong Yeh", "Ying Cheng", "Hung-Ting Su", "Yung-Hao Tang", "Shang-Hong Lai", "Winston H. Hsu"], "abstract": "This paper introduces MovieCORE, a novel video question answering (VQA) dataset designed to probe deeper cognitive understanding of movie content. Unlike existing datasets that focus on surface-level comprehension, MovieCORE emphasizes questions that engage System-2 thinking while remaining specific to the video material. We present an innovative agentic brainstorming approach, utilizing multiple large language models (LLMs) as thought agents to generate and refine high-quality question-answer pairs. To evaluate dataset quality, we develop a set of cognitive tests assessing depth, thought-provocation potential, and syntactic complexity. We also propose a comprehensive evaluation scheme for assessing VQA model performance on deeper cognitive tasks. To address the limitations of existing video-language models (VLMs), we introduce an agentic enhancement module, Agentic Choice Enhancement (ACE), which improves model reasoning capabilities post-training by up to 25%. Our work contributes to advancing movie understanding in AI systems and provides valuable insights into the capabilities and limitations of current VQA models when faced with more challenging, nuanced questions about cinematic content. Our project page, dataset and code can be found at", "subjects": "Computation and Language (cs.CL)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2508.19026.pdf", "abstract_url": "https://arxiv.org/abs/2508.19026", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "MovieCORE是一个新的视频问答数据集，专注于电影内容的深层认知推理，通过代理思维方法生成高质量问题对，并引入ACE模块提升模型性能。", "motivation": "解决现有视频问答数据集仅关注表面理解的问题，推动AI系统对电影内容的深层认知理解。", "method": "使用多LLM作为代理进行头脑风暴生成问题对，开发认知测试评估数据集质量，并引入ACE模块增强视频语言模型的推理能力。", "result": "ACE模块使模型推理能力提升高达25%，数据集在深度、启发性和句法复杂性方面表现优异。", "conclusion": "MovieCORE推进了AI的电影理解，揭示了当前VQA模型在复杂问题上的局限性，并提供改进方案。"}}
{"id": "2508.19076", "title": "HiPlan: Hierarchical Planning for LLM-Based Agents with Adaptive Global-Local Guidance", "authors": ["Ziyue Li", "Yuan Chang", "Gaihong Yu", "Xiaoqiu Le"], "abstract": "Large language model (LLM)-based agents have demonstrated remarkable capabilities in decision-making tasks, but struggle significantly with complex, long-horizon planning scenarios. This arises from their lack of macroscopic guidance, causing disorientation and failures in complex tasks, as well as insufficient continuous oversight during execution, rendering them unresponsive to environmental changes and prone to deviations. To tackle these challenges, we introduce HiPlan, a hierarchical planning framework that provides adaptive global-local guidance to boost LLM-based agents'decision-making. HiPlan decomposes complex tasks into milestone action guides for general direction and step-wise hints for detailed actions. During the offline phase, we construct a milestone library from expert demonstrations, enabling structured experience reuse by retrieving semantically similar tasks and milestones. In the execution phase, trajectory segments from past milestones are dynamically adapted to generate step-wise hints that align current observations with the milestone objectives, bridging gaps and correcting deviations. Extensive experiments across two challenging benchmarks demonstrate that HiPlan substantially outperforms strong baselines, and ablation studies validate the complementary benefits of its hierarchical components.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.19076.pdf", "abstract_url": "https://arxiv.org/abs/2508.19076", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "HiPlan 是一个分层规划框架，通过自适应全局-局部指导提升基于LLM的代理在复杂长时规划任务中的决策能力。", "motivation": "解决基于大语言模型的代理在复杂长时规划场景中因缺乏宏观指导和持续监督而导致的迷失和失败问题。", "method": "使用分层规划方法，将任务分解为里程碑行动指南和逐步提示，离线阶段构建里程碑库，执行阶段动态调整轨迹段以生成提示。", "result": "在多个基准测试中，HiPlan 显著优于基线方法，消融研究验证了其分层组件的互补效益。", "conclusion": "HiPlan 通过自适应指导有效提升了LLM代理的规划性能，具有实际应用潜力。"}}
{"id": "2508.19005", "title": "Building Self-Evolving Agents via Experience-Driven Lifelong Learning: A Framework and Benchmark", "authors": ["Yuxuan Cai", "Yipeng Hao", "Jie Zhou", "Hang Yan", "Zhikai Lei", "Rui Zhen", "Zhenhua Han", "Yutao Yang", "Junsong Li", "Qianjun Pan", "Tianyu Huai", "Qin Chen", "Xin Li", "Kai Chen", "Bo Zhang", "Xipeng Qiu", "Liang He"], "abstract": "As AI advances toward general intelligence, the focus is shifting from systems optimized for static tasks to creating open-ended agents that learn continuously. In this paper, we introduce Experience-driven Lifelong Learning (ELL), a framework for building self-evolving agents capable of continuous growth through real-world interaction. The framework is built on four core principles: (1) Experience Exploration: Agents learn through continuous, self-motivated interaction with dynamic environments, navigating interdependent tasks and generating rich experiential trajectories. (2) Long-term Memory: Agents preserve and structure historical knowledge, including personal experiences, domain expertise, and commonsense reasoning, into a persistent memory system. (3) Skill Learning: Agents autonomously improve by abstracting recurring patterns from experience into reusable skills, which are actively refined and validated for application in new tasks. (4) Knowledge Internalization: Agents internalize explicit and discrete experiences into implicit and intuitive capabilities as \"second nature\".", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.19005.pdf", "abstract_url": "https://arxiv.org/abs/2508.19005", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了经验驱动终身学习（ELL）框架，旨在构建通过现实世界交互持续学习的自我进化智能体，基于经验探索、长期记忆、技能学习和知识内化四个核心原则。", "motivation": "解决AI从静态任务优化转向开放端智能体，实现通过持续交互和学习的通用智能问题。", "method": "基于四个核心原则：经验探索、长期记忆、技能学习和知识内化，构建框架支持智能体在动态环境中自主学习和进化。", "result": "提出了ELL框架，为构建自我进化智能体提供了理论基础和基准，但具体实验结果未在摘要中详述。", "conclusion": "该框架推动了AI向通用智能的发展，强调了终身学习和经验积累的重要性，为未来研究提供了方向。"}}
{"id": "2508.19042", "title": "A Concurrent Modular Agent: Framework for Autonomous LLM Agents", "authors": ["Norihiro Maruyama", "Takahide Yoshida", "Hiroki Sato", "Atsushi Masumori", "Johnsmith", "Takashi Ikegami"], "abstract": "We introduce the Concurrent Modular Agent (CMA), a framework that orchestrates multiple Large-Language-Model (LLM)-based modules that operate fully asynchronously yet maintain a coherent and fault-tolerant behavioral loop. This framework addresses long-standing difficulties in agent architectures by letting intention emerge from language-mediated interactions among autonomous processes. This approach enables flexible, adaptive, and context-dependent behavior through the combination of concurrently executed modules that offload reasoning to an LLM, inter-module communication, and a single shared global", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.19042.pdf", "abstract_url": "https://arxiv.org/abs/2508.19042", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "介绍了并发模块化代理（CMA）框架，通过异步运行的多个基于LLM的模块实现自主、自适应和容错的行为循环。", "motivation": "解决代理架构中长期存在的困难，如意图从语言介导的交互中涌现，实现灵活和上下文依赖的行为。", "method": "使用并发执行的模块，卸载推理到LLM，模块间通信，以及共享全局状态来协调行为。", "result": "框架支持自主进程的异步操作，保持行为一致性和容错性。", "conclusion": "CMA框架为自主LLM代理提供了有效的架构，促进意图涌现和适应性行为。"}}
{"id": "2508.19097", "title": "Reasoning LLMs in the Medical Domain: A Literature Survey", "authors": ["Armin Berger", "Sarthak Khanna", "David Berghaus", "Rafet Sifa"], "abstract": "The emergence of advanced reasoning capabilities in Large Language Models (LLMs) marks a transformative development in healthcare applications. Beyond merely expanding functional capabilities, these reasoning mechanisms enhance decision transparency and explainability-critical requirements in medical contexts. This survey examines the transformation of medical LLMs from basic information retrieval tools to sophisticated clinical reasoning systems capable of supporting complex healthcare decisions. We provide a thorough analysis of the enabling technological foundations, with a particular focus on specialized prompting techniques like Chain-of-Thought and recent breakthroughs in Reinforcement Learning exemplified by DeepSeek-R1. Our investigation evaluates purpose-built medical frameworks while also examining emerging paradigms such as multi-agent collaborative systems and innovative prompting architectures. The survey critically assesses current evaluation methodologies for medical validation and addresses persistent challenges in field interpretation limitations, bias mitigation strategies, patient safety frameworks, and integration of multimodal clinical data. Through this survey, we seek to establish a roadmap for developing reliable LLMs that can serve as effective partners in clinical practice and medical research.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.19097.pdf", "abstract_url": "https://arxiv.org/abs/2508.19097", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本综述探讨了大型语言模型（LLMs）在医疗领域的推理能力发展，从信息检索工具演变为临床决策支持系统，涵盖技术基础、评估方法和挑战。", "motivation": "解决医疗应用中LLMs的透明度、可解释性和可靠性问题，以支持复杂医疗决策。", "method": "通过文献调查分析，包括专门提示技术（如Chain-of-Thought）、强化学习突破（如DeepSeek-R1）、多代理系统和评估方法。", "result": "识别了医疗LLMs的进展、挑战（如偏见缓解、患者安全）和潜在应用，为可靠模型开发提供路线图。", "conclusion": "LLMs有望成为临床实践和研究的有效伙伴，但需解决集成多模态数据和验证问题以确保安全。"}}
{"id": "2508.19096", "title": "Trustworthy Agents for Electronic Health Records through Confidence Estimation", "authors": ["Yongwoo Song", "Minbyul Jeong", "Mujeen Sung"], "abstract": "Large language models (LLMs) show promise for extracting information from Electronic Health Records (EHR) and supporting clinical decisions. However, deployment in clinical settings faces challenges due to hallucination risks. We propose Hallucination Controlled Accuracy at k% (HCAcc@k%), a novel metric quantifying the accuracy-reliability trade-off at varying confidence thresholds. We introduce TrustEHRAgent, a confidence-aware agent incorporating stepwise confidence estimation for clinical question answering. Experiments on MIMIC-III and eICU datasets show TrustEHRAgent outperforms baselines under strict reliability constraints, achieving improvements of 44.23%p and 25.34%p at HCAcc@70% while baseline methods fail at these thresholds. These results highlight limitations of traditional accuracy metrics in evaluating healthcare AI agents. Our work contributes to developing trustworthy clinical agents that deliver accurate information or transparently express uncertainty when confidence is low.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.19096.pdf", "abstract_url": "https://arxiv.org/abs/2508.19096", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于置信度估计的TrustEHRAgent，用于电子健康记录中的临床问答，通过新指标HCAcc@k%在MIMIC-III和eICU数据集上优于基线方法，提升了可靠性和准确性。", "motivation": "解决大型语言模型在临床决策支持中因幻觉风险而难以部署的问题，旨在开发更可信的医疗AI代理。", "method": "引入Hallucination Controlled Accuracy at k% (HCAcc@k%)指标和TrustEHRAgent代理，采用逐步置信度估计方法。", "result": "在HCAcc@70%下，TrustEHRAgent比基线方法提升了44.23%和25.34%的准确率，基线方法在这些阈值下失败。", "conclusion": "传统准确性指标在评估医疗AI代理时有局限性，本工作有助于开发可信的临床代理，在低置信度时透明表达不确定性。"}}
{"id": "2508.19152", "title": "Playstyle and Artificial Intelligence: An Initial Blueprint Through the Lens of Video Games", "authors": ["Chiu-Chou Lin"], "abstract": "Contemporary artificial intelligence (AI) development largely centers on rational decision-making, valued for its measurability and suitability for objective evaluation. Yet in real-world contexts, an intelligent agent's decisions are shaped not only by logic but also by deeper influences such as beliefs, values, and preferences. The diversity of human decision-making styles emerges from these differences, highlighting that \"style\" is an essential but often overlooked dimension of intelligence.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multiagent Systems (cs.MA); Symbolic Computation (cs.SC)", "comments": "PhD Dissertation, National Yang Ming Chiao Tung University, 2025. This is the public version without Chinese abstract or postscript", "pdf_url": "https://arxiv.org/pdf/2508.19152.pdf", "abstract_url": "https://arxiv.org/abs/2508.19152", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)", "Symbolic Computation (cs.SC)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了人工智能中风格的重要性，通过视频游戏视角提出初步蓝图，强调决策不仅基于理性，还受信念、价值观和偏好影响。", "motivation": "解决当前AI开发过度关注理性决策，忽视风格维度的问题，以更好地模拟人类多样化的决策方式。", "method": "通过视频游戏作为透镜，分析人类决策风格，提出一个初步框架来整合风格元素到AI设计中。", "result": "发现风格是智能的关键但常被忽略的方面，视频游戏提供了丰富的情境来研究风格对决策的影响。", "conclusion": "结论是AI系统应融入风格维度，以提升在真实世界中的适应性和表现，未来研究需进一步探索风格建模。"}}
{"id": "2508.19163", "title": "MATRIX: Multi-Agent simulaTion fRamework for safe Interactions and conteXtual clinical conversational evaluation", "authors": ["Ernest Lim", "Yajie Vera He", "Jared Joselowitz", "Kate Preston", "Mohita Chowdhury", "Louis Williams", "Aisling Higham", "Katrina Mason", "Mariane Melo", "Tom Lawton", "Yan Jia", "Ibrahim Habli"], "abstract": "Despite the growing use of large language models (LLMs) in clinical dialogue systems, existing evaluations focus on task completion or fluency, offering little insight into the behavioral and risk management requirements essential for safety-critical systems. This paper presents MATRIX (Multi-Agent simulaTion fRamework for safe Interactions and conteXtual clinical conversational evaluation), a structured, extensible framework for safety-oriented evaluation of clinical dialogue agents.", "subjects": "Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Multiagent Systems (cs.MA)", "comments": "36 pages, 16 figures", "pdf_url": "https://arxiv.org/pdf/2508.19163.pdf", "abstract_url": "https://arxiv.org/abs/2508.19163", "categories": ["Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了MATRIX框架，用于临床对话代理的安全导向评估，通过多代理模拟解决现有评估在行为和安全风险方面的不足。", "motivation": "现有大型语言模型在临床对话系统中的评估主要关注任务完成或流畅性，缺乏对行为和安全风险管理的深入洞察，这在安全关键系统中至关重要。", "method": "开发了MATRIX，一个结构化、可扩展的多代理模拟框架，用于安全交互和上下文临床对话评估。", "result": "MATRIX框架提供了对临床对话代理安全性的全面评估能力，弥补了现有方法的缺陷。", "conclusion": "MATRIX框架有助于提升临床对话系统的安全性和可靠性，为未来研究和应用提供了基础。"}}
{"id": "2508.19093", "title": "Retrieval-Augmented Generation for Natural Language Art Provenance Searches in the Getty Provenance Index", "authors": ["Mathew Henrickson"], "abstract": "This research presents a Retrieval-Augmented Generation (RAG) framework for art provenance studies, focusing on the Getty Provenance Index. Provenance research establishes the ownership history of artworks, which is essential for verifying authenticity, supporting restitution and legal claims, and understanding the cultural and historical context of art objects. The process is complicated by fragmented, multilingual archival data that hinders efficient retrieval. Current search portals require precise metadata, limiting exploratory searches. Our method enables natural-language and multilingual searches through semantic retrieval and contextual summarization, reducing dependence on metadata structures. We assess RAG's capability to retrieve and summarize auction records using a 10,000-record sample from the Getty Provenance Index - German Sales. The results show this approach provides a scalable solution for navigating art market archives, offering a practical tool for historians and cultural heritage professionals conducting historically sensitive research.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.19093.pdf", "abstract_url": "https://arxiv.org/abs/2508.19093", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种基于检索增强生成（RAG）的框架，用于艺术来源研究，通过自然语言和多语言搜索改进Getty Provenance Index中的档案检索和摘要。", "motivation": "解决艺术来源研究中因碎片化、多语言档案数据导致的检索效率低下问题，当前搜索门户依赖精确元数据，限制了探索性搜索。", "method": "使用RAG框架，结合语义检索和上下文摘要，实现自然语言和多语言搜索，减少对元数据结构的依赖。", "result": "在Getty Provenance Index - German Sales的10,000条记录样本上评估，显示该方法能有效检索和摘要拍卖记录，提供可扩展的解决方案。", "conclusion": "该方法为历史学家和文化遗产专业人士提供了一个实用工具，支持历史敏感研究，并有助于导航艺术市场档案。"}}
{"id": "2508.18370", "title": "Training Language Model Agents to Find Vulnerabilities with CTF-Dojo", "authors": ["Terry Yue Zhuo", "Dingmin Wang", "Hantian Ding", "Varun Kumar", "Zijian Wang"], "abstract": "Large language models (LLMs) have demonstrated exceptional capabilities when trained within executable runtime environments, notably excelling at software engineering tasks through verified feedback loops. Yet, scalable and generalizable execution-grounded environments remain scarce, limiting progress in training more capable ML agents. We introduce CTF-Dojo, the first large-scale executable runtime tailored for training LLMs with verifiable feedback, featuring 658 fully functional Capture-The-Flag (CTF)-style challenges containerized in Docker with guaranteed reproducibility. To enable rapid scaling without manual intervention, we develop CTF-Forge, an automated pipeline that transforms publicly available artifacts into ready-to-use execution environments in minutes, eliminating weeks of expert configuration traditionally required. We trained LLM-based agents on just 486 high-quality, execution-verified trajectories from CTF-Dojo, achieving up to 11.6% absolute gains over strong baselines across three competitive benchmarks: InterCode-CTF, NYU CTF Bench, and Cybench. Our best-performing 32B model reaches 31.9% Pass@1, establishing a new open-weight state-of-the-art that rivals frontier models like DeepSeek-V3-0324 and Gemini-2.5-Flash. By framing CTF-style tasks as a benchmark for executable-agent learning, CTF-Dojo demonstrates that execution-grounded training signals are not only effective but pivotal in advancing high-performance ML agents without dependence on costly proprietary systems.", "subjects": "Software Engineering (cs.SE); Computation and Language (cs.CL); Cryptography and Security (cs.CR); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.18370.pdf", "abstract_url": "https://arxiv.org/abs/2508.18370", "categories": ["Software Engineering (cs.SE)", "Computation and Language (cs.CL)", "Cryptography and Security (cs.CR)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "介绍CTF-Dojo，一个大规模可执行运行时环境，用于训练LLM代理通过可验证反馈发现漏洞，在基准测试中实现显著性能提升。", "motivation": "解决可扩展和通用执行环境稀缺的问题，限制ML代理能力提升。", "method": "开发CTF-Dojo环境，包含658个CTF挑战，使用CTF-Forge自动化管道生成环境，训练LLM代理基于执行验证轨迹。", "result": "在486个轨迹上训练，实现11.6%绝对增益，32B模型达到31.9% Pass@1，媲美前沿模型。", "conclusion": "执行基础训练信号对高性能ML代理发展至关重要，无需依赖昂贵专有系统。"}}
{"id": "2508.18292", "title": "Consensus Is All You Need: Gossip-Based Reasoning Among Large Language Models", "authors": ["Saksham Arora"], "abstract": "Large language models have advanced rapidly, but no single model excels in every area -- each has its strengths and weaknesses. Instead of relying on one model alone, we take inspiration from gossip protocols in distributed systems, where information is exchanged with peers until they all come to an agreement. In this setup, models exchange answers and gradually work toward a shared solution. Each LLM acts as a node in a peer-to-peer network, sharing responses and thought processes to reach a collective decision. Our results show that this \"gossip-based consensus\" leads to robust, resilient, and accurate multi-agent AI reasoning. It helps overcome the weaknesses of individual models and brings out their collective strengths. This approach is similar to how humans build consensus, making AI seem more collaborative and trustworthy instead of just a black-box program.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": "4 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2508.18292.pdf", "abstract_url": "https://arxiv.org/abs/2508.18292", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出一种基于八卦协议的共识方法，让多个大型语言模型通过点对点网络交换答案和思考过程，以达成集体决策，从而提高AI推理的鲁棒性、弹性和准确性。", "motivation": "解决单个大型语言模型在各方面表现不均、各有优缺点的问题，避免依赖单一模型，并提升AI的协作性和可信度。", "method": "采用分布式系统中的八卦协议，将每个LLM作为节点组成对等网络，交换响应和推理过程，逐步达成共识。", "result": "该方法实现了更稳健、弹性和准确的AI推理，有效克服了单个模型的弱点，并发挥了集体优势。", "conclusion": "共识方法使AI更协作和可信，类似于人类共识构建过程，而非黑盒程序，具有实际应用潜力。"}}
{"id": "2508.18298", "title": "Murakkab: Resource-Efficient Agentic Workflow Orchestration in Cloud Platforms", "authors": ["Gohar Irfan Chaudhry", "Esha Choukse", "Haoran Qiu", "Íñigo Goiri", "Rodrigo Fonseca", "Adam Belay", "Ricardo Bianchini"], "abstract": "Agentic workflows commonly coordinate multiple models and tools with complex control logic. They are quickly becoming the dominant paradigm for AI applications. However, serving them remains inefficient with today's frameworks. The key problem is that they expose workflows as opaque sequences of model and tool calls that tightly couple agent logic with model and hardware choices. Often, these workflow components are fragmented across different entities, preventing systems from reasoning about trade-offs across accuracy, latency, energy, and cost. This leads to resource waste and degraded service-level objectives (SLOs).", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Software Engineering (cs.SE)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.18298.pdf", "abstract_url": "https://arxiv.org/abs/2508.18298", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Software Engineering (cs.SE)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "Murakkab 是一种在云平台中高效协调多模型和工具调用的代理工作流编排系统，旨在解决现有框架因逻辑与资源耦合导致的资源浪费和性能下降问题。", "motivation": "代理工作流作为AI应用主导范式，现有框架效率低下，因工作流组件分散且逻辑与硬件选择紧密耦合，无法权衡准确性、延迟、能耗和成本，导致资源浪费和SLOs下降。", "method": "提出Murakkab系统，通过解耦代理逻辑与模型和硬件选择，使系统能全局优化资源分配，提升工作流编排效率。", "result": "Murakkab实现了资源高效利用，改善了服务级别目标，减少了资源浪费和性能退化。", "conclusion": "Murakkab提供了一种有效的代理工作流编排方法，对云平台AI应用具有重要实践意义，促进资源优化和SLOs提升。"}}
{"id": "2508.18652", "title": "UniC-RAG: Universal Knowledge Corruption Attacks to Retrieval-Augmented Generation", "authors": ["Runpeng Geng", "Yanting Wang", "Ying Chen", "Jinyuan Jia"], "abstract": "Retrieval-augmented generation (RAG) systems are widely deployed in real-world applications in diverse domains such as finance, healthcare, and cybersecurity. However, many studies showed that they are vulnerable to knowledge corruption attacks, where an attacker can inject adversarial texts into the knowledge database of a RAG system to induce the LLM to generate attacker-desired outputs. Existing studies mainly focus on attacking specific queries or queries with similar topics (or keywords). In this work, we propose UniC-RAG, a universal knowledge corruption attack against RAG systems. Unlike prior work, UniC-RAG jointly optimizes a small number of adversarial texts that can simultaneously attack a large number of user queries with diverse topics and domains, enabling an attacker to achieve various malicious objectives, such as directing users to malicious websites, triggering harmful command execution, or launching denial-of-service attacks. We formulate UniC-RAG as an optimization problem and further design an effective solution to solve it, including a balanced similarity-based clustering method to enhance the attack's effectiveness. Our extensive evaluations demonstrate that UniC-RAG is highly effective and significantly outperforms baselines. For instance, UniC-RAG could achieve over 90% attack success rate by injecting 100 adversarial texts into a knowledge database with millions of texts to simultaneously attack a large set of user queries (e.g., 2,000). Additionally, we evaluate existing defenses and show that they are insufficient to defend against UniC-RAG, highlighting the need for new defense mechanisms in RAG systems.", "subjects": "Cryptography and Security (cs.CR); Computation and Language (cs.CL)", "comments": "21 pages, 4 figures", "pdf_url": "https://arxiv.org/pdf/2508.18652.pdf", "abstract_url": "https://arxiv.org/abs/2508.18652", "categories": ["Cryptography and Security (cs.CR)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "提出了UniC-RAG，一种针对检索增强生成系统的通用知识污染攻击，通过优化少量对抗文本来同时攻击大量多样化查询，并评估其高有效性和现有防御的不足。", "motivation": "解决RAG系统易受知识污染攻击的问题，现有攻击方法局限于特定查询或主题，需要更通用的攻击手段来应对多样恶意目标。", "method": "将攻击建模为优化问题，设计基于平衡相似性的聚类方法，联合优化少量对抗文本以同时影响大量查询。", "result": "UniC-RAG在注入100个对抗文本时，对2000个查询达到90%以上的攻击成功率，显著优于基线，且现有防御无效。", "conclusion": "UniC-RAG展示了RAG系统的严重漏洞，强调了开发新防御机制的必要性，以保护实际应用。"}}
{"id": "2508.18684", "title": "FALCON: Autonomous Cyber Threat Intelligence Mining with LLMs for IDS Rule Generation", "authors": ["Shaswata Mitra", "Azim Bazarov", "Martin Duclos", "Sudip Mittal", "Aritran Piplai", "Md Rayhanur Rahman", "Edward Zieglar", "Shahram Rahimi"], "abstract": "Signature-based Intrusion Detection Systems (IDS) detect malicious activities by matching network or host activity against predefined rules. These rules are derived from extensive Cyber Threat Intelligence (CTI), which includes attack signatures and behavioral patterns obtained through automated tools and manual threat analysis, such as sandboxing. The CTI is then transformed into actionable rules for the IDS engine, enabling real-time detection and prevention. However, the constant evolution of cyber threats necessitates frequent rule updates, which delay deployment time and weaken overall security readiness. Recent advancements in agentic systems powered by Large Language Models (LLMs) offer the potential for autonomous IDS rule generation with internal evaluation. We introduce FALCON, an autonomous agentic framework that generates deployable IDS rules from CTI data in real-time and evaluates them using built-in multi-phased validators. To demonstrate versatility, we target both network (Snort) and host-based (YARA) mediums and construct a comprehensive dataset of IDS rules with their corresponding CTIs. Our evaluations indicate FALCON excels in automatic rule generation, with an average of 95% accuracy validated by qualitative evaluation with 84% inter-rater agreement among multiple cybersecurity analysts across all metrics. These results underscore the feasibility and effectiveness of LLM-driven data mining for real-time cyber threat mitigation.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Systems and Control (eess.SY)", "comments": "11 pages, 5 figures, 4 tables", "pdf_url": "https://arxiv.org/pdf/2508.18684.pdf", "abstract_url": "https://arxiv.org/abs/2508.18684", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)", "Systems and Control (eess.SY)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "FALCON是一个基于LLM的自主代理框架，用于从CTI数据实时生成和评估IDS规则，提高网络安全响应速度和准确性。", "motivation": "解决基于签名的入侵检测系统规则更新延迟问题，以适应不断演变的网络威胁。", "method": "使用LLM驱动的代理系统，从CTI数据自动生成IDS规则，并通过内置多阶段验证器进行评估，支持网络和主机基础检测。", "result": "FALCON在自动规则生成中平均准确率达95%，定性评估显示84%的评分者间一致性。", "conclusion": "LLM驱动的数据挖掘在实时网络威胁缓解中可行且有效，可提升安全准备状态。"}}
{"id": "2508.18325", "title": "Facilitating Matches on Allocation Platforms", "authors": ["Yohai Trabelsi", "Abhijin Adiga", "Yonatan Aumann", "Sarit Kraus", "S. S. Ravi"], "abstract": "We consider a setting where goods are allocated to agents by way of an allocation platform (e.g., a matching platform). An ``allocation facilitator'' aims to increase the overall utility/social-good of the allocation by encouraging (some of the) agents to relax (some of) their restrictions. At the same time, the advice must not hurt agents who would otherwise be better off. Additionally, the facilitator may be constrained by a ``bound'' (a.k.a. `budget'), limiting the number and/or type of restrictions it may seek to relax. We consider the facilitator's optimization problem of choosing an optimal set of restrictions to request to relax under the aforementioned constraints. Our contributions are three-fold: (i) We provide a formal definition of the problem, including the participation guarantees to which the facilitator should adhere. We define a hierarchy of participation guarantees and also consider several social-good functions. (ii) We provide polynomial algorithms for solving various versions of the associated optimization problems, including one-to-one and many-to-one allocation settings. (iii) We demonstrate the benefits of such facilitation and relaxation, and the implications of the different participation guarantees, using extensive experimentation on three real-world datasets.", "subjects": "Computer Science and Game Theory (cs.GT); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.18325.pdf", "abstract_url": "https://arxiv.org/abs/2508.18325", "categories": ["Computer Science and Game Theory (cs.GT)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了在分配平台上，通过鼓励代理人放宽限制来提高整体效用或社会福利的优化问题，提出了多项式算法并验证了其有效性。", "motivation": "解决分配平台中如何在不损害代理人利益的前提下，通过促进限制放宽来最大化社会效益的问题。", "method": "形式化定义问题、设计参与保证层次、开发多项式算法（包括一对一和多对一分配设置），并进行实验验证。", "result": "算法能有效优化分配，提升社会福利，不同参与保证对结果有显著影响。", "conclusion": "分配促进机制可行且有益，为平台设计提供了理论支持和实用指导。"}}
{"id": "2508.18397", "title": "Mining the Long Tail: A Comparative Study of Data-Centric Criticality Metrics for Robust Offline Reinforcement Learning in Autonomous Motion Planning", "authors": ["Antonio Guillen-Perez"], "abstract": "Offline Reinforcement Learning (RL) presents a promising paradigm for training autonomous vehicle (AV) planning policies from large-scale, real-world driving logs. However, the extreme data imbalance in these logs, where mundane scenarios vastly outnumber rare \"long-tail\" events, leads to brittle and unsafe policies when using standard uniform data sampling. In this work, we address this challenge through a systematic, large-scale comparative study of data curation strategies designed to focus the learning process on information-rich samples. We investigate six distinct criticality weighting schemes which are categorized into three families: heuristic-based, uncertainty-based, and behavior-based. These are evaluated at two temporal scales, the individual timestep and the complete scenario. We train seven goal-conditioned Conservative Q-Learning (CQL) agents with a state-of-the-art, attention-based architecture and evaluate them in the high-fidelity Waymax simulator. Our results demonstrate that all data curation methods significantly outperform the baseline. Notably, data-driven curation using model uncertainty as a signal achieves the most significant safety improvements, reducing the collision rate by nearly three-fold (from 16.0% to 5.5%). Furthermore, we identify a clear trade-off where timestep-level weighting excels at reactive safety while scenario-level weighting improves long-horizon planning. Our work provides a comprehensive framework for data curation in Offline RL and underscores that intelligent, non-uniform sampling is a critical component for building safe and reliable autonomous agents.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.18397.pdf", "abstract_url": "https://arxiv.org/abs/2508.18397", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过系统比较数据策展策略，研究如何利用关键性指标改善自动驾驶离线强化学习中的长尾事件处理，显著提升安全性。", "motivation": "解决自动驾驶离线强化学习中数据不平衡问题，即常见场景远多于罕见长尾事件，导致策略脆弱和不安全。", "method": "比较六种关键性加权方案（启发式、不确定性、行为式），在时间步和场景尺度评估，使用CQL和注意力架构在Waymax模拟器中训练。", "result": "所有数据策展方法均优于基线，模型不确定性方法将碰撞率从16.0%降至5.5%，时间步加权提升反应安全，场景加权改善长期规划。", "conclusion": "智能非均匀采样是构建安全可靠自动驾驶代理的关键，提供数据策展框架。"}}
{"id": "2508.18406", "title": "Toward Generalized Autonomous Agents: A Neuro-Symbolic AI Framework for Integrating Social and Technical Support in Education", "authors": ["Ryan Hare", "Ying Tang"], "abstract": "One of the enduring challenges in education is how to empower students to take ownership of their learning by setting meaningful goals, tracking their progress, and adapting their strategies when faced with setbacks. Research has shown that this form of leaner-centered learning is best cultivated through structured, supportive environments that promote guided practice, scaffolded inquiry, and collaborative dialogue. In response, educational efforts have increasingly embraced artificial-intelligence (AI)-powered digital learning environments, ranging from educational apps and virtual labs to serious games. Recent advances in large language models (LLMs) and neuro-symbolic systems, meanwhile, offer a transformative opportunity to reimagine how support is delivered in digital learning environments. LLMs are enabling socially interactive learning experiences and scalable, cross-domain learning support that can adapt instructional strategies across varied subjects and contexts. In parallel, neuro-symbolic AI provides new avenues for designing these agents that are not only adaptive but also scalable across domains. Based on these remarks, this paper presents a multi-agent, neuro-symbolic framework designed to resolve the aforementioned challenges. The framework assigns distinct pedagogical roles to specialized agents: an RL-based 'tutor' agent provides authoritative, non-verbal scaffolding, while a proactive, LLM-powered 'peer' agent facilitates the social dimensions of learning. While prior work has explored such agents in isolation, our framework's novelty lies in unifying them through a central educational ontology. Through case studies in both college-level and middle school settings, we demonstrate the framework's adaptability across domains. We conclude by outlining key insights and future directions for advancing AI-driven learning environments.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)", "comments": "Preprint. This work has been submitted to the IEEE for possible publication. In review for IEEE's Systems, Man, and Cybernetics Magazine. 8 pages, 3 figures. arxiv abstract has been shortened as the magazine format uses a long-form abstract", "pdf_url": "https://arxiv.org/pdf/2508.18406.pdf", "abstract_url": "https://arxiv.org/abs/2508.18406", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出一种神经符号AI框架，通过多智能体系统整合社会和学术支持，以促进学生自主学习和适应性教育环境。", "motivation": "解决教育中学生难以自主设定目标、跟踪进度和调整策略的问题，利用AI技术提供结构化支持环境。", "method": "使用多智能体神经符号框架，包括基于强化学习的导师智能体和基于大语言模型的同伴智能体，通过中央教育本体统一。", "result": "案例研究表明框架在大学和中学环境中具有跨领域适应性。", "conclusion": "框架展示了AI驱动学习环境的潜力，并指出了未来发展方向。"}}
{"id": "2508.18474", "title": "DRTA: Dynamic Reward Scaling for Reinforcement Learning in Time Series Anomaly Detection", "authors": ["Bahareh Golchin", "Banafsheh Rekabdar", "Kunpeng Liu"], "abstract": "Anomaly detection in time series data is important for applications in finance, healthcare, sensor networks, and industrial monitoring. Traditional methods usually struggle with limited labeled data, high false-positive rates, and difficulty generalizing to novel anomaly types. To overcome these challenges, we propose a reinforcement learning-based framework that integrates dynamic reward shaping, Variational Autoencoder (VAE), and active learning, called DRTA. Our method uses an adaptive reward mechanism that balances exploration and exploitation by dynamically scaling the effect of VAE-based reconstruction error and classification rewards. This approach enables the agent to detect anomalies effectively in low-label systems while maintaining high precision and recall. Our experimental results on the Yahoo A1 and Yahoo A2 benchmark datasets demonstrate that the proposed method consistently outperforms state-of-the-art unsupervised and semi-supervised approaches. These findings show that our framework is a scalable and efficient solution for real-world anomaly detection tasks.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.18474.pdf", "abstract_url": "https://arxiv.org/abs/2508.18474", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "提出DRTA框架，结合强化学习、动态奖励缩放、VAE和主动学习，用于时间序列异常检测，在低标签系统中提高性能。", "motivation": "解决传统方法在有限标签数据、高假阳性率和泛化新异常类型方面的困难。", "method": "使用强化学习框架，集成动态奖励机制、VAE和主动学习，动态缩放重建误差和分类奖励以平衡探索与利用。", "result": "在Yahoo A1和A2数据集上，性能优于最先进的无监督和半监督方法，保持高精确率和召回率。", "conclusion": "DRTA是一个可扩展且高效的解决方案，适用于现实世界的异常检测任务。"}}
{"id": "2508.18545", "title": "Beyond prior knowledge: The predictive role of knowledge-building in Tutor Learning", "authors": ["Tasmia Shahriar", "Mia Ameen", "Aditi Mallavarapu", "Shiyan Jiang", "Noboru Matsuda"], "abstract": "When adopting the role of a teacher in learning-by-teaching environments, students often struggle to engage in knowledge-building activities, such as providing explanations and addressing misconceptions. Instead, they frequently default to knowledge-telling behaviors, where they simply dictate what they already know or what to do without deeper reflection, thereby limiting learning. Teachable agents, particularly those capable of posing persistent follow-up questions, have been shown to encourage students (tutors) to shift from knowledge-telling to knowledge-building and enhance tutor learning. Tutor learning encompasses two interrelated types of knowledge: conceptual and procedural knowledge. Research has established a bidirectional relationship between these knowledge types, where improvements in one reinforce the other. This study investigates the role of knowledge-building in mediating the bidirectional relationship between procedural and conceptual learning. Our findings revealed a stable bidirectional relationship between procedural and conceptual knowledge, with higher post-test scores observed among students who engaged in knowledge-building, regardless of their procedural and conceptual pre-test performance. This suggests that knowledge-building serves as a crucial mechanism bridging the gap between students with low prior knowledge and higher conceptual and procedural learning gain.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.18545.pdf", "abstract_url": "https://arxiv.org/abs/2508.18545", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "该研究探讨了在教与学环境中，知识构建如何作为中介促进程序性和概念性知识之间的双向关系，发现知识构建行为能提升学习效果，尤其对先前知识较低的学生有益。", "motivation": "解决学生在扮演教师角色时倾向于知识讲述而非知识构建的问题，这限制了学习深度和效果。", "method": "使用可教学代理（能提出持续性后续问题）来鼓励学生从知识讲述转向知识构建，并分析知识构建在程序性和概念性知识双向关系中的中介作用。", "result": "发现程序性和概念性知识间存在稳定的双向关系，参与知识构建的学生在后测中得分更高，无论其先前知识水平如何。", "conclusion": "知识构建是连接低先前知识学生与更高学习收益的关键机制，强调了在教学中促进知识构建活动的重要性。"}}
{"id": "2508.18563", "title": "The Quasi-Creature and the Uncanny Valley of Agency: A Synthesis of Theory and Evidence on User Interaction with Inconsistent Generative AI", "authors": ["Mauricio Manhaes", "Christine Miller", "Nicholas Schroeder"], "abstract": "The user experience with large-scale generative AI is paradoxical: superhuman fluency meets absurd failures in common sense and consistency. This paper argues that the resulting potent frustration is an ontological problem, stemming from the \"Quasi-Creature\"-an entity simulating intelligence without embodiment or genuine understanding. Interaction with this entity precipitates the \"Uncanny Valley of Agency,\" a framework where user comfort drops when highly agentic AI proves erratically unreliable. Its failures are perceived as cognitive breaches, causing profound cognitive dissonance. Synthesizing HCI, cognitive science, and philosophy of technology, this paper defines the Quasi-Creature and details the Uncanny Valley of Agency. An illustrative mixed-methods study (\"Move 78,\" N=37) of a collaborative creative task reveals a powerful negative correlation between perceived AI efficiency and user frustration, central to the negative experience. This framework robustly explains user frustration with generative AI and has significant implications for the design, ethics, and societal integration of these powerful, alien technologies.", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI)", "comments": "33 pages, 9 figures", "pdf_url": "https://arxiv.org/pdf/2508.18563.pdf", "abstract_url": "https://arxiv.org/abs/2508.18563", "categories": ["Computers and Society (cs.CY)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文探讨了用户与生成式AI交互中的矛盾体验，提出了'准生物'和'代理恐怖谷'概念，解释了AI不一致性导致的用户挫败感，并通过混合方法研究验证了感知效率与挫败感的负相关关系。", "motivation": "解决用户在使用大规模生成式AI时遇到的超级流畅性与荒谬常识错误之间的矛盾，以及由此产生的强烈挫败感问题。", "method": "综合HCI、认知科学和技术哲学理论，定义'准生物'和'代理恐怖谷'框架，并进行了一项混合方法研究（'Move 78'，N=37），分析协作创意任务中的用户互动。", "result": "研究发现，感知AI效率与用户挫败感之间存在强烈的负相关关系，证实了代理恐怖谷框架的有效性。", "conclusion": "该框架能强健解释用户对生成式AI的挫败感，对AI的设计、伦理和社会整合具有重要启示。"}}
{"id": "2508.18708", "title": "Skill-Aligned Fairness in Multi-Agent Learning for Collaboration in Healthcare", "authors": ["Promise Osaine Ekpo", "Brian La", "Thomas Wiener", "Saesha Agarwal", "Arshia Agrawal", "Gonzalo Gonzalez-Pumariega", "Lekan P. Molu", "Angelique Taylor"], "abstract": "Fairness in multi-agent reinforcement learning (MARL) is often framed as a workload balance problem, overlooking agent expertise and the structured coordination required in real-world domains. In healthcare, equitable task allocation requires workload balance or expertise alignment to prevent burnout and overuse of highly skilled agents. Workload balance refers to distributing an approximately equal number of subtasks or equalised effort across healthcare workers, regardless of their expertise. We make two contributions to address this problem. First, we propose FairSkillMARL, a framework that defines fairness as the dual objective of workload balance and skill-task alignment. Second, we introduce MARLHospital, a customizable healthcare-inspired environment for modeling team compositions and energy-constrained scheduling impacts on fairness, as no existing simulators are well-suited for this problem. We conducted experiments to compare FairSkillMARL in conjunction with four standard MARL methods, and against two state-of-the-art fairness metrics. Our results suggest that fairness based solely on equal workload might lead to task-skill mismatches and highlight the need for more robust metrics that capture skill-task misalignment. Our work provides tools and a foundation for studying fairness in heterogeneous multi-agent systems where aligning effort with expertise is critical.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.18708.pdf", "abstract_url": "https://arxiv.org/abs/2508.18708", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出FairSkillMARL框架和MARLHospital环境，通过结合工作负载平衡和技能任务对齐来定义公平性，在医疗多智能体强化学习中解决传统方法忽视技能匹配的问题。", "motivation": "解决多智能体强化学习中公平性问题，传统方法仅关注工作负载平衡，忽略了智能体专业技能和实际协调需求，可能导致技能任务不匹配和资源浪费。", "method": "提出FairSkillMARL框架，定义公平性为工作负载平衡和技能任务对齐的双重目标，并开发MARLHospital模拟环境进行实验验证。", "result": "实验显示仅基于工作负载平衡的公平性可能导致技能任务不匹配，强调了需要更鲁棒的指标来捕捉技能对齐问题。", "conclusion": "该研究为异构多智能体系统中的公平性研究提供了工具和基础，强调在关键领域如医疗中，努力与专业知识的对齐至关重要。"}}
{"id": "2508.18803", "title": "A Survey on Cloud-Edge-Terminal Collaborative Intelligence in AIoT Networks", "authors": ["Jiaqi Wu", "Jing Liu", "Yang Liu", "Lixu Wang", "Zehua Wang", "Wei Chen", "Zijian Tian", "Richard Yu", "Victor C.M. Leung"], "abstract": "The proliferation of Internet of things (IoT) devices in smart cities, transportation, healthcare, and industrial applications, coupled with the explosive growth of AI-driven services, has increased demands for efficient distributed computing architectures and networks, driving cloud-edge-terminal collaborative intelligence (CETCI) as a fundamental paradigm within the artificial intelligence of things (AIoT) community. With advancements in deep learning, large language models (LLMs), and edge computing, CETCI has made significant progress with emerging AIoT applications, moving beyond isolated layer optimization to deployable collaborative intelligence systems for AIoT (CISAIOT), a practical research focus in AI, distributed computing, and communications. This survey describes foundational architectures, enabling technologies, and scenarios of CETCI paradigms, offering a tutorial-style review for CISAIOT beginners. We systematically analyze architectural components spanning cloud, edge, and terminal layers, examining core technologies including network virtualization, container orchestration, and software-defined networking, while presenting categorizations of collaboration paradigms that cover task offloading, resource allocation, and optimization across heterogeneous infrastructures. Furthermore, we explain intelligent collaboration learning frameworks by reviewing advances in federated learning, distributed deep learning, edge-cloud model evolution, and reinforcement learning-based methods. Finally, we discuss challenges (e.g., scalability, heterogeneity, interoperability) and future trends (e.g., 6G+, agents, quantum computing, digital twin), highlighting how integration of distributed computing and communication can address open issues and guide development of robust, efficient, and secure collaborative AIoT systems.", "subjects": "Networking and Internet Architecture (cs.NI); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.18803.pdf", "abstract_url": "https://arxiv.org/abs/2508.18803", "categories": ["Networking and Internet Architecture (cs.NI)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文是关于AIoT网络中云边端协同智能的综述，涵盖架构、技术、场景、挑战和未来趋势，为初学者提供教程式回顾。", "motivation": "解决IoT设备激增和AI服务增长带来的分布式计算架构需求，推动云边端协同智能作为AIoT的基础范式。", "method": "系统分析云、边、终端层的架构组件，核心技术如网络虚拟化、容器编排，以及协作范式分类，包括任务卸载、资源分配和优化。", "result": "综述了协同智能学习框架的进展，如联邦学习、分布式深度学习，并讨论了可扩展性、异构性等挑战。", "conclusion": "集成分布式计算和通信可解决开放问题，指导开发健壮、高效、安全的协同AIoT系统，未来趋势包括6G+、量子计算等。"}}
{"id": "2508.18993", "title": "GitTaskBench: A Benchmark for Code Agents Solving Real-World Tasks Through Code Repository Leveraging", "authors": ["Ziyi Ni", "Huacan Wang", "Shuo Zhang", "Shuo Lu", "Ziyang He", "Wang You", "Zhenheng Tang", "Yuntao Du", "Bill Sun", "Hongzhang Liu", "Sen Hu", "Ronghao Chen", "Bo Li", "Xin Li", "Chen Hu", "Binxing Jiao", "Daxin Jiang", "Pin Lyu"], "abstract": "Beyond scratch coding, exploiting large-scale code repositories (e.g., GitHub) for practical tasks is vital in real-world software development, yet current benchmarks rarely evaluate code agents in such authentic, workflow-driven scenarios. To bridge this gap, we introduce GitTaskBench, a benchmark designed to systematically assess this capability via 54 realistic tasks across 7 modalities and 7 domains. Each task pairs a relevant repository with an automated, human-curated evaluation harness specifying practical success criteria. Beyond measuring execution and task success, we also propose the alpha-value metric to quantify the economic benefit of agent performance, which integrates task success rates, token cost, and average developer salaries. Experiments across three state-of-the-art agent frameworks with multiple advanced LLMs show that leveraging code repositories for complex task solving remains challenging: even the best-performing system, OpenHands+Claude 3.7, solves only 48.15% of tasks. Error analysis attributes over half of failures to seemingly mundane yet critical steps like environment setup and dependency resolution, highlighting the need for more robust workflow management and increased timeout preparedness. By releasing GitTaskBench, we aim to drive progress and attention toward repository-aware code reasoning, execution, and deployment -- moving agents closer to solving complex, end-to-end real-world tasks. The benchmark and code are open-sourced at", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": "Highly practical, Well-motivated, Actionable", "pdf_url": "https://arxiv.org/pdf/2508.18993.pdf", "abstract_url": "https://arxiv.org/abs/2508.18993", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "GitTaskBench是一个基准测试，用于评估代码代理在利用代码仓库解决现实世界任务的能力，通过54个任务和alpha-value指标，发现当前系统表现有限，强调需要改进工作流管理。", "motivation": "解决当前基准测试在评估代码代理利用代码仓库（如GitHub）处理真实工作流程任务方面的不足。", "method": "引入GitTaskBench基准，包含54个任务，使用自动化评估工具和alpha-value指标，测试多个先进LLM和代理框架。", "result": "最佳系统OpenHands+Claude 3.7仅解决48.15%的任务，失败主要由于环境设置和依赖解析问题。", "conclusion": "GitTaskBench推动代码代理在仓库感知推理和执行方面的进步，强调需要更健壮的工作流管理。"}}
{"id": "2508.19072", "title": "Attackers Strike Back? Not Anymore - An Ensemble of RL Defenders Awakens for APT Detection", "authors": ["Sidahmed Benabderrahmane", "Talal Rahwan"], "abstract": "Advanced Persistent Threats (APTs) represent a growing menace to modern digital infrastructure. Unlike traditional cyberattacks, APTs are stealthy, adaptive, and long-lasting, often bypassing signature-based detection systems. This paper introduces a novel framework for APT detection that unites deep learning, reinforcement learning (RL), and active learning into a cohesive, adaptive defense system. Our system combines auto-encoders for latent behavioral encoding with a multi-agent ensemble of RL-based defenders, each trained to distinguish between benign and malicious process behaviors. We identify a critical challenge in existing detection systems: their static nature and inability to adapt to evolving attack strategies. To this end, our architecture includes multiple RL agents (Q-Learning, PPO, DQN, adversarial defenders), each analyzing latent vectors generated by an auto-encoder. When any agent is uncertain about its decision, the system triggers an active learning loop to simulate expert feedback, thus refining decision boundaries. An ensemble voting mechanism, weighted by each agent's performance, ensures robust final predictions.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.19072.pdf", "abstract_url": "https://arxiv.org/abs/2508.19072", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种结合深度学习、强化学习和主动学习的新框架，用于检测高级持续性威胁（APT），通过多智能体集成和主动学习循环提高自适应性和鲁棒性。", "motivation": "解决APT检测中现有系统静态、无法适应不断演变的攻击策略的问题。", "method": "使用自编码器进行潜在行为编码，集成多个强化学习智能体（如Q-Learning、PPO、DQN），并结合主动学习循环和加权投票机制。", "result": "系统能够自适应地检测APT，通过模拟专家反馈优化决策边界，提升检测准确性。", "conclusion": "该框架为APT检测提供了高效、自适应的解决方案，具有实际应用潜力。"}}
{"id": "2508.19115", "title": "SecureV2X: An Efficient and Privacy-Preserving System for Vehicle-to-Everything (V2X) Applications", "authors": ["Joshua Lee", "Ali Arastehfard", "Weiran Liu", "Xuegang Ban", "Yuan Hong"], "abstract": "Autonomous driving and V2X technologies have developed rapidly in the past decade, leading to improved safety and efficiency in modern transportation. These systems interact with extensive networks of vehicles, roadside infrastructure, and cloud resources to support their machine learning capabilities. However, the widespread use of machine learning in V2X systems raises issues over the privacy of the data involved. This is particularly concerning for smart-transit and driver safety applications which can implicitly reveal user locations or explicitly disclose medical data such as EEG signals. To resolve these issues, we propose SecureV2X, a scalable, multi-agent system for secure neural network inferences deployed between the server and each vehicle. Under this setting, we study two multi-agent V2X applications: secure drowsiness detection, and secure red-light violation detection. Our system achieves strong performance relative to baselines, and scales efficiently to support a large number of secure computation interactions simultaneously. For instance, SecureV2X is $9.4 \\times$ faster, requires $143\\times$ fewer computational rounds, and involves $16.6\\times$ less communication on drowsiness detection compared to other secure systems. Moreover, it achieves a runtime nearly $100\\times$ faster than state-of-the-art benchmarks in object detection tasks for red light violation detection.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": "10 pages, 3 figures", "pdf_url": "https://arxiv.org/pdf/2508.19115.pdf", "abstract_url": "https://arxiv.org/abs/2508.19115", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "SecureV2X是一个高效且保护隐私的系统，用于V2X应用，通过安全神经网络推理提升性能并减少计算和通信开销。", "motivation": "解决V2X系统中机器学习应用带来的数据隐私问题，如用户位置和医疗数据的泄露风险。", "method": "提出一个可扩展的多代理系统，用于服务器和车辆之间的安全神经网络推理，应用于 drowsiness 检测和 red-light 违规检测。", "result": "系统性能优于基线，在 drowsiness 检测中快9.4倍、计算轮次少143倍、通信量少16.6倍，在 red light 违规检测中运行时快近100倍。", "conclusion": "SecureV2X有效保护隐私，同时提升V2X应用的效率和可扩展性。"}}
{"id": "2508.19186", "title": "Real-Time Model Checking for Closed-Loop Robot Reactive Planning", "authors": ["Christopher Chandler", "Bernd Porr", "Giulia Lafratta", "Alice Miller"], "abstract": "We present a new application of model checking which achieves real-time multi-step planning and obstacle avoidance on a real autonomous robot. We have developed a small, purpose-built model checking algorithm which generates plans in situ based on \"core\" knowledge and attention as found in biological agents. This is achieved in real-time using no pre-computed data on a low-powered device. Our approach is based on chaining temporary control systems which are spawned to counteract disturbances in the local environment that disrupt an autonomous agent from its preferred action (or resting state). A novel discretization of 2D LiDAR data sensitive to bounded variations in the local environment is used. Multi-step planning using model checking by forward depth-first search is applied to cul-de-sac and playground scenarios. Both empirical results and informal proofs of two fundamental properties of our approach demonstrate that model checking can be used to create efficient multi-step plans for local obstacle avoidance, improving on the performance of a reactive agent which can only plan one step. Our approach is an instructional case study for the development of safe, reliable and explainable planning in the context of autonomous vehicles.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Formal Languages and Automata Theory (cs.FL)", "comments": "30 pages excluding references, 18 figures, submitted to Formal Aspects of Computing", "pdf_url": "https://arxiv.org/pdf/2508.19186.pdf", "abstract_url": "https://arxiv.org/abs/2508.19186", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Formal Languages and Automata Theory (cs.FL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一种实时模型检查方法，用于自主机器人的多步规划和避障，基于生物启发的核心知识和注意力机制，在低功耗设备上实现无预计算数据的实时规划。", "motivation": "解决自主机器人在动态环境中多步规划和避障的问题，提高反应式代理的性能，确保安全、可靠和可解释的规划。", "method": "开发小型模型检查算法，使用2D LiDAR数据离散化，通过前向深度优先搜索进行多步规划，并链接临时控制系统应对局部干扰。", "result": "实证结果和理论证明显示，该方法能高效生成多步避障计划，优于单步规划的反应式代理，适用于死胡同和游乐场场景。", "conclusion": "模型检查可用于自主车辆的安全可靠规划，提供案例研究，促进可解释AI的发展。"}}
