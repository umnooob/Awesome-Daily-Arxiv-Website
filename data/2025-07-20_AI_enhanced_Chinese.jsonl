{"id": "2507.13285", "title": "Multi-Agent Synergy-Driven Iterative Visual Narrative Synthesis", "authors": ["Wang Xi", "Quan Shi", "Tian Yu", "Yujie Peng", "Jiayi Sun", "Mengxing Ren", "Zenghui Ding", "Ningguang Yao"], "abstract": "Automated generation of high-quality media presentations is challenging, requiring robust content extraction, narrative planning, visual design, and overall quality optimization. Existing methods often produce presentations with logical inconsistencies and suboptimal layouts, thereby struggling to meet professional standards. To address these challenges, we introduce RCPS (Reflective Coherent Presentation Synthesis), a novel framework integrating three key components: (1) Deep Structured Narrative Planning; (2) Adaptive Layout Generation; (3) an Iterative Optimization Loop. Additionally, we propose PREVAL, a preference-based evaluation framework employing rationale-enhanced multi-dimensional models to assess presentation quality across Content, Coherence, and Design. Experimental results demonstrate that RCPS significantly outperforms baseline methods across all quality dimensions, producing presentations that closely approximate human expert standards. PREVAL shows strong correlation with human judgments, validating it as a reliable automated tool for assessing presentation quality.", "subjects": "Computation and Language (cs.CL)", "comments": "22 pages, 7 figures, 3 tables. Submitted to an ACL-style conference", "pdf_url": "https://arxiv.org/pdf/2507.13285.pdf", "abstract_url": "https://arxiv.org/abs/2507.13285", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了RCPS框架，通过深度结构化叙事规划、自适应布局生成和迭代优化循环，以及PREVAL评估框架，显著提升了自动生成媒体演示的质量。", "motivation": "解决自动生成高质量媒体演示中的逻辑不一致和布局次优问题，以满足专业标准。", "method": "采用RCPS框架，结合深度结构化叙事规划、自适应布局生成和迭代优化循环，以及PREVAL偏好评估框架。", "result": "RCPS在所有质量维度上显著优于基线方法，PREVAL与人类判断有强相关性。", "conclusion": "RCPS和PREVAL框架有效提升了自动生成演示的质量和评估可靠性，接近人类专家水平。"}}
{"id": "2507.12732", "title": "Strategy Adaptation in Large Language Model Werewolf Agents", "authors": ["Fuya Nakamori", "Yin Jou Huang", "Fei Cheng"], "abstract": "This study proposes a method to improve the performance of Werewolf agents by switching between predefined strategies based on the attitudes of other players and the context of conversations. While prior works of Werewolf agents using prompt engineering have employed methods where effective strategies are implicitly defined, they cannot adapt to changing situations. In this research, we propose a method that explicitly selects an appropriate strategy based on the game context and the estimated roles of other players. We compare the strategy adaptation Werewolf agents with baseline agents using implicit or fixed strategies and verify the effectiveness of our proposed method.", "subjects": "Computation and Language (cs.CL)", "comments": "7 pages, 2 figures", "pdf_url": "https://arxiv.org/pdf/2507.12732.pdf", "abstract_url": "https://arxiv.org/abs/2507.12732", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本研究提出了一种通过根据其他玩家的态度和对话上下文切换预定义策略来提高狼人杀代理性能的方法。与之前使用提示工程隐式定义有效策略的狼人杀代理工作不同，我们的方法能够根据游戏上下文和其他玩家的估计角色明确选择适当的策略。我们比较了策略适应狼人杀代理与使用隐式或固定策略的基线代理，并验证了所提方法的有效性。", "motivation": "解决现有狼人杀代理无法适应变化情境的问题，通过明确选择策略来提高代理性能。", "method": "提出一种方法，根据游戏上下文和其他玩家的估计角色，明确选择适当的策略。", "result": "策略适应狼人杀代理在性能上优于使用隐式或固定策略的基线代理。", "conclusion": "明确选择策略的方法有效提高了狼人杀代理的适应性和性能，为类似情境下的代理设计提供了新思路。"}}
{"id": "2507.13190", "title": "GEMMAS: Graph-based Evaluation Metrics for Multi Agent Systems", "authors": ["Jisoo Lee", "Raeyoung Chang", "Dongwook Kwon", "Harmanpreet Singh", "Nikhil Verma"], "abstract": "Multi-agent systems built on language models have shown strong performance on collaborative reasoning tasks. However, existing evaluations focus only on the correctness of the final output, overlooking how inefficient communication and poor coordination contribute to redundant reasoning and higher computational costs. We introduce GEMMAS, a graph-based evaluation framework that analyzes the internal collaboration process by modeling agent interactions as a directed acyclic graph. To capture collaboration quality, we propose two process-level metrics: Information Diversity Score (IDS) to measure semantic variation in inter-agent messages, and Unnecessary Path Ratio (UPR) to quantify redundant reasoning paths. We evaluate GEMMAS across five benchmarks and highlight results on GSM8K, where systems with only a 2.1% difference in accuracy differ by 12.8% in IDS and 80% in UPR, revealing substantial variation in internal collaboration. These findings demonstrate that outcome-only metrics are insufficient for evaluating multi-agent performance and highlight the importance of process-level diagnostics in designing more interpretable and resource-efficient collaborative AI systems.", "subjects": "Computation and Language (cs.CL)", "comments": "4 figures, 1 algorithm, 2 tables, 6 pages, under review at EMNLP Industry track 2025", "pdf_url": "https://arxiv.org/pdf/2507.13190.pdf", "abstract_url": "https://arxiv.org/abs/2507.13190", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "GEMMAS是一个基于图的评估框架，用于分析多智能体系统中的内部协作过程，通过建模智能体交互为有向无环图，并提出两个过程级指标来捕捉协作质量。", "motivation": "现有的多智能体系统评估仅关注最终输出的正确性，忽视了低效沟通和协调不足导致的冗余推理和更高计算成本。", "method": "引入GEMMAS框架，建模智能体交互为有向无环图，并提出信息多样性得分（IDS）和不必要路径比率（UPR）两个过程级指标。", "result": "在GSM8K等五个基准测试中，GEMMAS揭示了仅2.1%准确度差异的系统在IDS和UPR上分别有12.8%和80%的差异，表明内部协作存在显著差异。", "conclusion": "仅基于结果的评估指标不足以全面评价多智能体性能，过程级诊断对于设计更可解释和资源高效的协作AI系统至关重要。"}}
{"id": "2507.12774", "title": "A Comprehensive Survey of Electronic Health Record Modeling: From Deep Learning Approaches to Large Language Models", "authors": ["Weijieying Ren", "Jingxi Zhu", "Zehao Liu", "Tianxiang Zhao", "Vasant Honavar"], "abstract": "Artificial intelligence (AI) has demonstrated significant potential in transforming healthcare through the analysis and modeling of electronic health records (EHRs). However, the inherent heterogeneity, temporal irregularity, and domain-specific nature of EHR data present unique challenges that differ fundamentally from those in vision and natural language tasks. This survey offers a comprehensive overview of recent advancements at the intersection of deep learning, large language models (LLMs), and EHR modeling. We introduce a unified taxonomy that spans five key design dimensions: data-centric approaches, neural architecture design, learning-focused strategies, multimodal learning, and LLM-based modeling systems. Within each dimension, we review representative methods addressing data quality enhancement, structural and temporal representation, self-supervised learning, and integration with clinical knowledge. We further highlight emerging trends such as foundation models, LLM-driven clinical agents, and EHR-to-text translation for downstream reasoning. Finally, we discuss open challenges in benchmarking, explainability, clinical alignment, and generalization across diverse clinical settings. This survey aims to provide a structured roadmap for advancing AI-driven EHR modeling and clinical decision support. For a comprehensive list of EHR-related methods, kindly refer to", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.12774.pdf", "abstract_url": "https://arxiv.org/abs/2507.12774", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文综述了电子健康记录（EHR）建模的最新进展，特别是深度学习和大型语言模型（LLMs）在其中的应用。提出了一个统一的分类法，涵盖了数据为中心的方法、神经架构设计、学习策略、多模态学习和基于LLM的建模系统五个关键设计维度。", "motivation": "解决EHR数据的异质性、时间不规则性和领域特定性带来的独特挑战，这些挑战与视觉和自然语言任务中的挑战有根本不同。", "method": "通过综述和分类法，回顾了数据质量增强、结构和时间表示、自监督学习以及与临床知识整合的代表性方法。", "result": "突出了基础模型、LLM驱动的临床代理和EHR到文本翻译等新兴趋势，并讨论了在基准测试、可解释性、临床对齐和跨不同临床环境的泛化方面的开放挑战。", "conclusion": "本文旨在为推进AI驱动的EHR建模和临床决策支持提供结构化的路线图。"}}
{"id": "2507.12484", "title": "AI-Powered Math Tutoring: Platform for Personalized and Adaptive Education", "authors": ["Jarosław A. Chudziak", "Adam Kostka"], "abstract": "The growing ubiquity of artificial intelligence (AI), in particular large language models (LLMs), has profoundly altered the way in which learners gain knowledge and interact with learning material, with many claiming that AI positively influences their learning achievements. Despite this advancement, current AI tutoring systems face limitations associated with their reactive nature, often providing direct answers without encouraging deep reflection or incorporating structured pedagogical tools and strategies. This limitation is most apparent in the field of mathematics, in which AI tutoring systems remain underdeveloped. This research addresses the question: How can AI tutoring systems move beyond providing reactive assistance to enable structured, individualized, and tool-assisted learning experiences? We introduce a novel multi-agent AI tutoring platform that combines adaptive and personalized feedback, structured course generation, and textbook knowledge retrieval to enable modular, tool-assisted learning processes. This system allows students to learn new topics while identifying and targeting their weaknesses, revise for exams effectively, and practice on an unlimited number of personalized exercises. This article contributes to the field of artificial intelligence in education by introducing a novel platform that brings together pedagogical agents and AI-driven components, augmenting the field with modular and effective systems for teaching mathematics.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "8 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2507.12484.pdf", "abstract_url": "https://arxiv.org/abs/2507.12484", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一种新型的多智能体AI辅导平台，旨在通过结合自适应和个性化反馈、结构化课程生成和教科书知识检索，提供模块化、工具辅助的学习过程，以解决当前AI辅导系统在数学教育中的局限性。", "motivation": "当前AI辅导系统存在反应性限制，无法鼓励深度反思或融入结构化教学工具和策略，特别是在数学领域。本研究旨在探索如何使AI辅导系统超越提供反应性帮助，实现结构化、个性化和工具辅助的学习体验。", "method": "研究引入了一个多智能体AI辅导平台，该平台结合了自适应和个性化反馈、结构化课程生成和教科书知识检索，以支持模块化和工具辅助的学习过程。", "result": "开发的系统使学生能够学习新主题，识别并针对自己的弱点，有效复习考试，并在无限数量的个性化练习中练习。", "conclusion": "本文通过引入一个结合教学代理和AI驱动组件的新平台，为人工智能在教育领域的应用贡献了模块化和有效的数学教学系统。"}}
{"id": "2507.13334", "title": "A Survey of Context Engineering for Large Language Models", "authors": ["Lingrui Mei", "Jiayu Yao", "Yuyao Ge", "Yiwei Wang", "Baolong Bi", "Yujun Cai", "Jiazhi Liu", "Mingyu Li", "Zhong-Zhi Li", "Duzhen Zhang", "Chenlin Zhou", "Jiayi Mao", "Tianze Xia", "Jiafeng Guo", "Shenghua Liu"], "abstract": "The performance of Large Language Models (LLMs) is fundamentally determined by the contextual information provided during inference. This survey introduces Context Engineering, a formal discipline that transcends simple prompt design to encompass the systematic optimization of information payloads for LLMs. We present a comprehensive taxonomy decomposing Context Engineering into its foundational components and the sophisticated implementations that integrate them into intelligent systems. We first examine the foundational components: context retrieval and generation, context processing and context management. We then explore how these components are architecturally integrated to create sophisticated system implementations: retrieval-augmented generation (RAG), memory systems and tool-integrated reasoning, and multi-agent systems. Through this systematic analysis of over 1300 research papers, our survey not only establishes a technical roadmap for the field but also reveals a critical research gap: a fundamental asymmetry exists between model capabilities. While current models, augmented by advanced context engineering, demonstrate remarkable proficiency in understanding complex contexts, they exhibit pronounced limitations in generating equally sophisticated, long-form outputs. Addressing this gap is a defining priority for future research. Ultimately, this survey provides a unified framework for both researchers and engineers advancing context-aware AI.", "subjects": "Computation and Language (cs.CL)", "comments": "ongoing work; 165 pages, 1401 citations", "pdf_url": "https://arxiv.org/pdf/2507.13334.pdf", "abstract_url": "https://arxiv.org/abs/2507.13334", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文介绍了上下文工程（Context Engineering）这一新兴领域，旨在通过系统优化大型语言模型（LLMs）推理过程中的信息负载，提升模型性能。文章提出了一个全面的分类法，将上下文工程分解为基础组件和高级系统实现，并通过分析1300多篇研究论文，揭示了模型能力间存在的不对称性，为未来研究指明了方向。", "motivation": "大型语言模型（LLMs）的性能在很大程度上取决于推理过程中提供的上下文信息。当前，尽管模型在理解复杂上下文方面表现出色，但在生成同等复杂的长篇输出方面存在明显限制。本文旨在通过引入上下文工程这一系统化方法，解决这一不对称性问题。", "method": "文章提出了一个综合分类法，将上下文工程分解为基础组件（如上下文检索与生成、上下文处理和上下文管理）和高级系统实现（如检索增强生成（RAG）、记忆系统和工具集成推理，以及多代理系统）。通过对1300多篇研究论文的系统分析，建立了该领域的技术路线图。", "result": "研究发现，当前模型在理解复杂上下文方面表现出色，但在生成复杂长篇输出方面存在限制。这种能力上的不对称性是未来研究的关键挑战。", "conclusion": "本文为研究人员和工程师提供了一个统一的框架，以推动上下文感知AI的发展。解决模型能力间的不对称性将是未来研究的重点。"}}
{"id": "2507.12494", "title": "MR-LDM -- The Merge-Reactive Longitudinal Decision Model: Game Theoretic Human Decision Modeling for Interactive Sim Agents", "authors": ["Dustin Holley", "Jovin D'sa", "Hossein Nourkhiz Mahjoub", "Gibran Ali"], "abstract": "Enhancing simulation environments to replicate real-world driver behavior, i.e., more humanlike sim agents, is essential for developing autonomous vehicle technology. In the context of highway merging, previous works have studied the operational-level yielding dynamics of lag vehicles in response to a merging car at highway on-ramps. Other works focusing on tactical decision modeling generally consider limited action sets or utilize payoff functions with large parameter sets and limited payoff bounds. In this work, we aim to improve the simulation of the highway merge scenario by targeting a game theoretic model for tactical decision-making with improved payoff functions and lag actions. We couple this with an underlying dynamics model to have a unified decision and dynamics model that can capture merging interactions and simulate more realistic interactions in an explainable and interpretable fashion. The proposed model demonstrated good reproducibility of complex interactions when validated on a real-world dataset. The model was finally integrated into a high fidelity simulation environment and confirmed to have adequate computation time efficiency for use in large-scale simulations to support autonomous vehicle development.", "subjects": "Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT); Multiagent Systems (cs.MA); Robotics (cs.RO)", "comments": "8 pages", "pdf_url": "https://arxiv.org/pdf/2507.12494.pdf", "abstract_url": "https://arxiv.org/abs/2507.12494", "categories": ["Artificial Intelligence (cs.AI)", "Computer Science and Game Theory (cs.GT)", "Multiagent Systems (cs.MA)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "MR-LDM模型是一种用于模拟高速公路合并场景中人类驾驶员战术决策的博弈论模型，旨在通过改进的收益函数和滞后动作来增强模拟环境的真实性和可解释性。", "motivation": "为了提高自动驾驶车辆技术的开发效率，需要更真实地模拟人类驾驶员在高速公路合并场景中的行为。现有的研究在战术决策建模方面存在动作集有限或收益函数参数多、界限有限的问题。", "method": "本研究提出了一种结合博弈论战术决策模型和底层动力学模型的统一框架，用于模拟合并交互，并通过真实世界数据集验证了模型的有效性。", "result": "模型在真实世界数据集上验证了能够良好复现复杂的交互行为，并且在集成到高保真模拟环境后，计算时间效率足以支持大规模模拟。", "conclusion": "MR-LDM模型不仅提高了模拟交互的真实性和可解释性，而且计算效率高，适用于支持自动驾驶车辆开发的大规模模拟。"}}
{"id": "2507.12806", "title": "MCPEval: Automatic MCP-based Deep Evaluation for AI Agent Models", "authors": ["Zhiwei Liu", "Jielin Qiu", "Shiyu Wang", "Jianguo Zhang", "Zuxin Liu", "Roshan Ram", "Haolin Chen", "Weiran Yao", "Huan Wang", "Shelby Heinecke", "Silvio Savarese", "Caiming Xiong"], "abstract": "The rapid rise of Large Language Models (LLMs)-based intelligent agents underscores the need for robust, scalable evaluation frameworks. Existing methods rely on static benchmarks and labor-intensive data collection, limiting practical assessment. We introduce \\oursystemname, an open-source Model Context Protocol (MCP)-based framework that automates end-to-end task generation and deep evaluation of LLM agents across diverse domains. MCPEval standardizes metrics, seamlessly integrates with native agent tools, and eliminates manual effort in building evaluation pipelines. Empirical results across five real-world domains show its effectiveness in revealing nuanced, domain-specific performance. We publicly release MCPEval", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2507.12806.pdf", "abstract_url": "https://arxiv.org/abs/2507.12806", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "MCPEval是一个基于模型上下文协议（MCP）的开源框架，旨在自动化大型语言模型（LLM）智能代理的端到端任务生成和深度评估，解决了现有评估方法依赖静态基准和劳动密集型数据收集的局限性。", "motivation": "随着基于大型语言模型（LLM）的智能代理的迅速崛起，需要强大、可扩展的评估框架来克服现有方法的局限性，如依赖静态基准和劳动密集型数据收集。", "method": "引入了MCPEval，一个基于模型上下文协议（MCP）的框架，自动化了LLM代理的端到端任务生成和深度评估，标准化了度量标准，并与原生代理工具无缝集成。", "result": "在五个现实世界领域的实证结果表明，MCPEval在揭示细微、领域特定的性能方面有效。", "conclusion": "MCPEval为LLM代理的评估提供了一个自动化、标准化的解决方案，公开释放了该框架以促进更广泛的应用和研究。"}}
{"id": "2507.12599", "title": "A Survey of Explainable Reinforcement Learning: Targets, Methods and Needs", "authors": ["Léo Saulières"], "abstract": "The success of recent Artificial Intelligence (AI) models has been accompanied by the opacity of their internal mechanisms, due notably to the use of deep neural networks. In order to understand these internal mechanisms and explain the output of these AI models, a set of methods have been proposed, grouped under the domain of eXplainable AI (XAI). This paper focuses on a sub-domain of XAI, called eXplainable Reinforcement Learning (XRL), which aims to explain the actions of an agent that has learned by reinforcement learning. We propose an intuitive taxonomy based on two questions \"What\" and \"How\". The first question focuses on the target that the method explains, while the second relates to the way the explanation is provided. We use this taxonomy to provide a state-of-the-art review of over 250 papers. In addition, we present a set of domains close to XRL, which we believe should get attention from the community. Finally, we identify some needs for the field of XRL.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "69 pages, 19 figures", "pdf_url": "https://arxiv.org/pdf/2507.12599.pdf", "abstract_url": "https://arxiv.org/abs/2507.12599", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文综述了可解释性强化学习（XRL）领域，提出了基于‘什么’和‘如何’两个问题的直观分类法，并利用这一分类法对250多篇论文进行了最新综述。此外，还介绍了一系列与XRL密切相关的领域，并指出了该领域的一些需求。", "motivation": "随着人工智能（AI）模型，尤其是深度神经网络的成功，其内部机制的不透明性也随之增加。为了理解这些内部机制并解释AI模型的输出，一系列方法被提出，统称为可解释性AI（XAI）。本文专注于XAI的一个子领域——可解释性强化学习（XRL），旨在解释通过强化学习学习的智能体的行为。", "method": "本文提出了一个基于‘什么’和‘如何’两个问题的直观分类法。‘什么’问题关注于方法解释的目标，‘如何’问题则与提供解释的方式相关。利用这一分类法，作者对250多篇论文进行了最新综述。", "result": "通过这一分类法，本文不仅提供了XRL领域的最新综述，还展示了一系列与XRL密切相关的领域，并指出了该领域的一些需求。", "conclusion": "本文通过提出一个直观的分类法，为XRL领域提供了一个全面的视角，并指出了未来研究的方向和需求。这对于推动XRL领域的发展具有重要意义。"}}
{"id": "2507.12666", "title": "Fly, Fail, Fix: Iterative Game Repair with Reinforcement Learning and Large Multimodal Models", "authors": ["Alex Zook", "Josef Spjut", "Jonathan Tremblay"], "abstract": "Game design hinges on understanding how static rules and content translate into dynamic player behavior - something modern generative systems that inspect only a game's code or assets struggle to capture. We present an automated design iteration framework that closes this gap by pairing a reinforcement learning (RL) agent, which playtests the game, with a large multimodal model (LMM), which revises the game based on what the agent does. In each loop the RL player completes several episodes, producing (i) numerical play metrics and/or (ii) a compact image strip summarising recent video frames. The LMM designer receives a gameplay goal and the current game configuration, analyses the play traces, and edits the configuration to steer future behaviour toward the goal. We demonstrate results that LMMs can reason over behavioral traces supplied by RL agents to iteratively refine game mechanics, pointing toward practical, scalable tools for AI-assisted game design.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2507.12666.pdf", "abstract_url": "https://arxiv.org/abs/2507.12666", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种自动化设计迭代框架，通过结合强化学习（RL）代理和大型多模态模型（LMM），自动测试和修改游戏设计，以更好地实现游戏目标。", "motivation": "现代生成系统仅通过检查游戏的代码或资源难以捕捉静态规则和内容如何转化为动态玩家行为，这限制了游戏设计的效率和效果。", "method": "框架中，RL代理进行游戏测试，产生游戏指标和视频帧摘要；LMM根据这些数据和游戏目标，分析并修改游戏配置，以引导玩家行为朝向目标。", "result": "研究表明，LMM能够通过RL代理提供的行为痕迹迭代优化游戏机制，为AI辅助游戏设计提供了实用、可扩展的工具。", "conclusion": "该框架为游戏设计提供了一种新的自动化迭代方法，展示了AI在理解和改进玩家行为方面的潜力，推动了AI辅助游戏设计的实际应用。"}}
{"id": "2507.12801", "title": "Imitating Mistakes in a Learning Companion AI Agent for Online Peer Learning", "authors": ["Sosui Moribe", "Taketoshi Ushiama"], "abstract": "In recent years, peer learning has gained attention as a method that promotes spontaneous thinking among learners, and its effectiveness has been confirmed by numerous studies. This study aims to develop an AI Agent as a learning companion that enables peer learning anytime and anywhere. However, peer learning between humans has various limitations, and it is not always effective. Effective peer learning requires companions at the same proficiency levels. In this study, we assume that a learner's peers with the same proficiency level as the learner make the same mistakes as the learner does and focus on English composition as a specific example to validate this approach.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": ")", "pdf_url": "https://arxiv.org/pdf/2507.12801.pdf", "abstract_url": "https://arxiv.org/abs/2507.12801", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了开发一种作为学习伴侣的AI代理，以实现在线同伴学习，特别关注英语作文中学习者与同等水平同伴共同犯错的情景。", "motivation": "解决同伴学习在人类之间存在的各种限制，以及不总是有效的问题，特别是需要与学习者同等熟练度的同伴。", "method": "假设学习者的同等熟练度同伴会犯与学习者相同的错误，并以英语作文为例验证这一方法。", "result": "尚未提供具体结果，但研究旨在验证通过AI代理模仿错误以促进有效同伴学习的假设。", "conclusion": "如果成功，这种AI代理可以作为一种有效的学习伴侣，使同伴学习变得更加普遍和有效。"}}
{"id": "2507.12821", "title": "Assessing adaptive world models in machines with novel games", "authors": ["Lance Ying", "Katherine M. Collins", "Prafull Sharma", "Cedric Colas", "Kaiya Ivy Zhao", "Adrian Weller", "Zenna Tavares", "Phillip Isola", "Samuel J. Gershman", "Jacob D. Andreas", "Thomas L. Griffiths", "Francois Chollet", "Kelsey R. Allen", "Joshua B. Tenenbaum"], "abstract": "Human intelligence exhibits a remarkable capacity for rapid adaptation and effective problem-solving in novel and unfamiliar contexts. We argue that this profound adaptability is fundamentally linked to the efficient construction and refinement of internal representations of the environment, commonly referred to as world models, and we refer to this adaptation mechanism as world model induction. However, current understanding and evaluation of world models in artificial intelligence (AI) remains narrow, often focusing on static representations learned from training on a massive corpora of data, instead of the efficiency and efficacy of models in learning these representations through interaction and exploration within a novel environment. In this Perspective, we provide a view of world model induction drawing on decades of research in cognitive science on how humans learn and adapt so efficiently; we then call for a new evaluation framework for assessing adaptive world models in AI. Concretely, we propose a new benchmarking paradigm based on suites of carefully designed games with genuine, deep and continually refreshing novelty in the underlying game structures -- we refer to this kind of games as novel games. We detail key desiderata for constructing these games and propose appropriate metrics to explicitly challenge and evaluate the agent's ability for rapid world model induction. We hope that this new evaluation framework will inspire future evaluation efforts on world models in AI and provide a crucial step towards developing AI systems capable of the human-like rapid adaptation and robust generalization -- a critical component of artificial general intelligence.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "17 pages, 4 figures", "pdf_url": "https://arxiv.org/pdf/2507.12821.pdf", "abstract_url": "https://arxiv.org/abs/2507.12821", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了人类智能在快速适应和解决新问题方面的能力，认为这与高效构建和精炼环境内部表征（即世界模型）的能力密切相关。作者提出了一种新的评估框架，通过设计具有持续新颖性的游戏来评估人工智能中适应性世界模型的能力。", "motivation": "当前对人工智能中世界模型的理解和评估过于狭窄，主要集中在从大量数据中学习的静态表征上，而不是通过在新环境中的互动和探索来学习这些表征的效率和效果。", "method": "作者提出了一种新的评估范式，基于一系列精心设计的游戏，这些游戏在底层结构上具有真正的、深层次的和持续更新的新颖性，称为“新颖游戏”。", "result": "提出了一套构建这些游戏的关键要求和适当的度量标准，以明确挑战和评估代理快速诱导世界模型的能力。", "conclusion": "这种新的评估框架有望激发未来对人工智能世界模型的评估努力，并为开发具有人类类似快速适应和强大泛化能力的人工智能系统迈出关键一步。"}}
{"id": "2507.12862", "title": "Information-Theoretic Aggregation of Ethical Attributes in Simulated-Command", "authors": ["Hussein Abbass", "Taylan Akay", "Harrison Tolley"], "abstract": "In the age of AI, human commanders need to use the computational powers available in today's environment to simulate a very large number of scenarios. Within each scenario, situations occur where different decision design options could have ethical consequences. Making these decisions reliant on human judgement is both counter-productive to the aim of exploring very large number of scenarios in a timely manner and infeasible when considering the workload needed to involve humans in each of these choices. In this paper, we move human judgement outside the simulation decision cycle. Basically, the human will design the ethical metric space, leaving it to the simulated environment to explore the space. When the simulation completes its testing cycles, the testing environment will come back to the human commander with a few options to select from. The human commander will then exercise human-judgement to select the most appropriate course of action, which will then get executed accordingly. We assume that the problem of designing metrics that are sufficiently granular to assess the ethical implications of decisions is solved. Subsequently, the fundamental problem we look at in this paper is how to weight ethical decisions during the running of these simulations; that is, how to dynamically weight the ethical attributes when agents are faced with decision options with ethical implications during generative simulations. The multi-criteria decision making literature has started to look at nearby problems, where the concept of entropy has been used to determine the weights during aggregation. We draw from that literature different approaches to automatically calculate the weights for ethical attributes during simulation-based testing and evaluation.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.12862.pdf", "abstract_url": "https://arxiv.org/abs/2507.12862", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "在AI时代，人类指挥官需要利用计算能力模拟大量场景，其中涉及伦理决策。本文提出将人类判断移出模拟决策循环，由人类设计伦理度量空间，模拟环境探索空间，最终由人类选择最合适的行动方案。", "motivation": "解决在大量模拟场景中依赖人类判断进行伦理决策的低效和不可行问题。", "method": "人类设计伦理度量空间，模拟环境探索该空间并生成选项，最后由人类选择行动方案。利用多准则决策文献中的熵概念动态加权伦理属性。", "result": "提出了一种方法，通过自动计算伦理属性的权重，在模拟测试和评估中动态加权伦理决策。", "conclusion": "该方法将人类判断从模拟决策循环中移出，提高了效率，同时保留了人类在最终决策中的作用。"}}
{"id": "2507.12795", "title": "City-VLM: Towards Multidomain Perception Scene Understanding via Multimodal Incomplete Learning", "authors": ["Penglei Sun", "Yaoxian Song", "Xiangru Zhu", "Xiang Liu", "Qiang Wang", "Yue Liu", "Changqun Xia", "Tiefeng Li", "Yang Yang", "Xiaowen Chu"], "abstract": "Scene understanding enables intelligent agents to interpret and comprehend their environment. While existing large vision-language models (LVLMs) for scene understanding have primarily focused on indoor household tasks, they face two significant limitations when applied to outdoor large-scale scene understanding. First, outdoor scenarios typically encompass larger-scale environments observed through various sensors from multiple viewpoints (e.g., bird view and terrestrial view), while existing indoor LVLMs mainly analyze single visual modalities within building-scale contexts from humanoid viewpoints. Second, existing LVLMs suffer from missing multidomain perception outdoor data and struggle to effectively integrate 2D and 3D visual information. To address the aforementioned limitations, we build the first multidomain perception outdoor scene understanding dataset, named \\textbf{\\underline{SVM-City}}, deriving from multi\\textbf{\\underline{S}}cale scenarios with multi\\textbf{\\underline{V}}iew and multi\\textbf{\\underline{M}}odal instruction tuning data. It contains $420$k images and $4, 811$M point clouds with $567$k question-answering pairs from vehicles, low-altitude drones, high-altitude aerial planes, and satellite. To effectively fuse the multimodal data in the absence of one modality, we introduce incomplete multimodal learning to model outdoor scene understanding and design the LVLM named \\textbf{\\underline{City-VLM}}. Multimodal fusion is realized by constructing a joint probabilistic distribution space rather than implementing directly explicit fusion operations (e.g., concatenation). Experimental results on three typical outdoor scene understanding tasks show City-VLM achieves $18.14 \\%$ performance surpassing existing LVLMs in question-answering tasks averagely. Our method demonstrates pragmatic and generalization performance across multiple outdoor scenes.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.12795.pdf", "abstract_url": "https://arxiv.org/abs/2507.12795", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了City-VLM，一个针对多领域感知户外场景理解的多模态不完全学习模型，以及其配套的数据集SVM-City。该模型通过构建联合概率分布空间有效融合多模态数据，在三种典型户外场景理解任务中表现优异。", "motivation": "解决现有大型视觉语言模型（LVLMs）在户外大尺度场景理解中的两个主要限制：一是户外场景通常涉及更大尺度的环境和多视角观察，而现有模型主要针对室内单一视觉模态；二是缺乏多领域感知户外数据及有效整合2D和3D视觉信息的能力。", "method": "构建了首个多领域感知户外场景理解数据集SVM-City，并提出了City-VLM模型，采用不完全多模态学习方法，通过构建联合概率分布空间实现多模态数据的有效融合。", "result": "City-VLM在问答任务中的表现平均超过现有LVLMs 18.14%，展示了在多个户外场景中的实用性和泛化性能。", "conclusion": "City-VLM和SVM-City数据集为户外多领域感知场景理解提供了有效的解决方案，展示了在多模态数据融合和场景理解任务中的优越性能。"}}
{"id": "2507.13175", "title": "Black Box Deployed -- Functional Criteria for Artificial Moral Agents in the LLM Era", "authors": ["Matthew E. Brophy"], "abstract": "The advancement of powerful yet opaque large language models (LLMs) necessitates a fundamental revision of the philosophical criteria used to evaluate artificial moral agents (AMAs). Pre-LLM frameworks often relied on the assumption of transparent architectures, which LLMs defy due to their stochastic outputs and opaque internal states. This paper argues that traditional ethical criteria are pragmatically obsolete for LLMs due to this mismatch. Engaging with core themes in the philosophy of technology, this paper proffers a revised set of ten functional criteria to evaluate LLM-based artificial moral agents: moral concordance, context sensitivity, normative integrity, metaethical awareness, system resilience, trustworthiness, corrigibility, partial transparency, functional autonomy, and moral imagination. These guideposts, applied to what we term \"SMA-LLS\" (Simulating Moral Agency through Large Language Systems), aim to steer AMAs toward greater alignment and beneficial societal integration in the coming years. We illustrate these criteria using hypothetical scenarios involving an autonomous public bus (APB) to demonstrate their practical applicability in morally salient contexts.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "42 pages. Supplementary material included at end of article", "pdf_url": "https://arxiv.org/pdf/2507.13175.pdf", "abstract_url": "https://arxiv.org/abs/2507.13175", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一套修订后的十项功能标准，用于评估基于大型语言模型（LLM）的人工道德代理（AMAs），以应对LLM时代中传统伦理标准的不适用性。", "motivation": "由于大型语言模型（LLMs）的随机输出和不透明的内部状态，传统的伦理标准在评估人工道德代理（AMAs）时变得不切实际，这促使了对评估标准进行根本性修订的需求。", "method": "本文通过与技术哲学的核心主题对话，提出了一套修订后的十项功能标准，用于评估LLM-based AMAs，并通过假设情景（如自动驾驶公共汽车）来展示这些标准的实际应用。", "result": "提出的十项功能标准旨在指导AMAs在未来的发展中实现更好的社会融合和道德对齐。", "conclusion": "本文的结论是，为了在LLM时代有效地评估和指导AMAs的发展，必须采用新的功能标准，这些标准能够更好地适应LLMs的特性和挑战。"}}
{"id": "2507.12475", "title": "Coarse Addition and the St. Petersburg Paradox: A Heuristic Perspective", "authors": ["Takashi Izumo"], "abstract": "The St. Petersburg paradox presents a longstanding challenge in decision theory. It describes a game whose expected value is infinite, yet for which no rational finite stake can be determined. Traditional solutions introduce auxiliary assumptions, such as diminishing marginal utility, temporal discounting, or extended number systems. These methods often involve mathematical refinements that may not correspond to how people actually perceive or process numerical information. This paper explores an alternative approach based on a modified operation of addition defined over coarse partitions of the outcome space. In this model, exact numerical values are grouped into perceptual categories, and each value is replaced by a representative element of its group before being added. This method allows for a phenomenon where repeated additions eventually cease to affect the outcome, a behavior described as inertial stabilization. Although this is not intended as a definitive resolution of the paradox, the proposed framework offers a plausible way to represent how agents with limited cognitive precision might handle divergent reward structures. We demonstrate that the St. Petersburg series can become inert under this coarse addition for a suitably constructed partition. The approach may also have broader applications in behavioral modeling and the study of machine reasoning under perceptual limitations.", "subjects": "Theoretical Economics (econ.TH); Artificial Intelligence (cs.AI); Optimization and Control (math.OC)", "comments": "16 pages, no figure", "pdf_url": "https://arxiv.org/pdf/2507.12475.pdf", "abstract_url": "https://arxiv.org/abs/2507.12475", "categories": ["Theoretical Economics (econ.TH)", "Artificial Intelligence (cs.AI)", "Optimization and Control (math.OC)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了圣彼得堡悖论，提出了基于粗粒度加法的新视角，通过将数值分组并替换为代表元素来处理无限期望值问题，为有限认知能力的代理提供了一种处理发散奖励结构的可能方法。", "motivation": "解决圣彼得堡悖论这一决策理论中的长期挑战，传统方法依赖于辅助假设，如边际效用递减、时间折扣或扩展数系，但这些方法可能与人们实际处理数字信息的方式不符。", "method": "采用基于结果空间粗粒度分区的修改加法操作，将精确数值分组并用代表元素替换后进行加法运算，实现惯性稳定化现象。", "result": "研究表明，在适当构建的分区下，圣彼得堡级数可以在这种粗粒度加法下变得惰性。", "conclusion": "提出的框架为有限认知精度的代理处理发散奖励结构提供了一种合理的表示方法，可能在行为建模和机器在感知限制下的推理研究中有更广泛的应用。"}}
{"id": "2507.12486", "title": "On multiagent online problems with predictions", "authors": ["Gabriel Istrate", "Cosmin Bonchis", "Victor Bogdan"], "abstract": "We study the power of (competitive) algorithms with predictions in a multiagent setting. We introduce a two predictor framework, that assumes that agents use one predictor for their future (self) behavior, and one for the behavior of the other players. The main problem we are concerned with is understanding what are the best competitive ratios that can be achieved by employing such predictors, under various assumptions on predictor quality.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2507.12486.pdf", "abstract_url": "https://arxiv.org/abs/2507.12486", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Computer Science and Game Theory (cs.GT)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究了在多智能体在线问题中使用预测的（竞争性）算法的能力。提出了一个双预测器框架，假设智能体使用一个预测器预测自身未来行为，另一个预测其他玩家的行为。主要关注的问题是理解在不同预测器质量假设下，使用此类预测器可以实现的最佳竞争比。", "motivation": "解决在多智能体环境中，如何利用预测器来提高算法的竞争性能，特别是在预测自身和其他智能体行为时的最佳竞争比问题。", "method": "引入了一个双预测器框架，分别用于预测智能体自身和其他智能体的未来行为，并分析在不同预测质量下的竞争比。", "result": "探讨了在不同预测器质量假设下，使用双预测器框架可以实现的最佳竞争比。", "conclusion": "研究表明，通过合理设计和利用双预测器框架，可以在多智能体在线问题中实现更优的竞争性能，具体效果取决于预测器的质量。"}}
{"id": "2507.12496", "title": "FOUNDER: Grounding Foundation Models in World Models for Open-Ended Embodied Decision Making", "authors": ["Yucen Wang", "Rui Yu", "Shenghua Wan", "Le Gan", "De-Chuan Zhan"], "abstract": "Foundation Models (FMs) and World Models (WMs) offer complementary strengths in task generalization at different levels. In this work, we propose FOUNDER, a framework that integrates the generalizable knowledge embedded in FMs with the dynamic modeling capabilities of WMs to enable open-ended task solving in embodied environments in a reward-free manner. We learn a mapping function that grounds FM representations in the WM state space, effectively inferring the agent's physical states in the world simulator from external observations. This mapping enables the learning of a goal-conditioned policy through imagination during behavior learning, with the mapped task serving as the goal state. Our method leverages the predicted temporal distance to the goal state as an informative reward signal. FOUNDER demonstrates superior performance on various multi-task offline visual control benchmarks, excelling in capturing the deep-level semantics of tasks specified by text or videos, particularly in scenarios involving complex observations or domain gaps where prior methods struggle. The consistency of our learned reward function with the ground-truth reward is also empirically validated. Our project website is", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "Accepted by Forty-Second International Conference on Machine Learning (ICML 2025)", "pdf_url": "https://arxiv.org/pdf/2507.12496.pdf", "abstract_url": "https://arxiv.org/abs/2507.12496", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了FOUNDER框架，通过将基础模型（FMs）与世界模型（WMs）相结合，实现在无奖励的具身环境中开放式的任务解决。FOUNDER通过学习一个映射函数，将FM的表征基础于WM的状态空间，从而在行为学习期间通过想象学习目标条件策略，并利用预测到目标状态的时间距离作为奖励信号。该方法在多种多任务离线视觉控制基准测试中表现出色，特别是在涉及复杂观察或领域差距的场景中。", "motivation": "解决在具身环境中实现开放式任务解决的挑战，特别是在复杂观察或领域差距的情况下，现有方法表现不佳的问题。", "method": "提出FOUNDER框架，通过集成基础模型（FMs）和世界模型（WMs）的互补优势，学习一个映射函数将FM的表征基础于WM的状态空间，并利用预测的时间距离作为奖励信号。", "result": "FOUNDER在多种多任务离线视觉控制基准测试中表现出色，特别是在涉及复杂观察或领域差距的场景中，能够有效捕捉由文本或视频指定的任务的深层次语义。", "conclusion": "FOUNDER框架通过结合FMs和WMs的优势，为在具身环境中实现开放式任务解决提供了一种有效的方法，特别是在复杂或领域差距大的情况下。"}}
{"id": "2507.12767", "title": "Autonomy for Older Adult-Agent Interaction", "authors": ["Jiaxin An"], "abstract": "As the global population ages, artificial intelligence (AI)-powered agents have emerged as potential tools to support older adults' caregiving. Prior research has explored agent autonomy by identifying key interaction stages in task processes and defining the agent's role at each stage. However, ensuring that agents align with older adults' autonomy preferences remains a critical challenge. Drawing on interdisciplinary conceptualizations of autonomy, this paper examines four key dimensions of autonomy for older adults: decision-making autonomy, goal-oriented autonomy, control autonomy, and social responsibility autonomy. This paper then proposes the following research directions: (1) Addressing social responsibility autonomy, which concerns the ethical and social implications of agent use in communal settings; (2) Operationalizing agent autonomy from the task perspective; and (3) Developing autonomy measures.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": "7 pages", "pdf_url": "https://arxiv.org/pdf/2507.12767.pdf", "abstract_url": "https://arxiv.org/abs/2507.12767", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了人工智能代理在支持老年人护理中的自主性问题，提出了四个关键自主性维度，并建议了未来研究方向。", "motivation": "随着全球人口老龄化，人工智能代理成为支持老年人护理的潜在工具，但如何确保这些代理与老年人的自主性偏好保持一致仍是一个关键挑战。", "method": "本文通过跨学科的自主性概念化，研究了老年人的四个关键自主性维度：决策自主性、目标导向自主性、控制自主性和社会责任自主性。", "result": "提出了三个研究方向：解决社会责任自主性问题、从任务角度操作化代理自主性以及开发自主性测量方法。", "conclusion": "本文强调了在老年人-代理互动中考虑自主性的重要性，并提出了未来研究的方向，以更好地满足老年人的需求和偏好。"}}
{"id": "2507.13152", "title": "SE-VLN: A Self-Evolving Vision-Language Navigation Framework Based on Multimodal Large Language Models", "authors": ["Xiangyu Dong", "Haoran Zhao", "Jiang Gao", "Haozhou Li", "Xiaoguang Ma", "Yaoming Zhou", "Fuhai Chen", "Juan Liu"], "abstract": "Recent advances in vision-language navigation (VLN) were mainly attributed to emerging large language models (LLMs). These methods exhibited excellent generalization capabilities in instruction understanding and task reasoning. However, they were constrained by the fixed knowledge bases and reasoning abilities of LLMs, preventing fully incorporating experiential knowledge and thus resulting in a lack of efficient evolutionary capacity. To address this, we drew inspiration from the evolution capabilities of natural agents, and proposed a self-evolving VLN framework (SE-VLN) to endow VLN agents with the ability to continuously evolve during testing. To the best of our knowledge, it was the first time that an multimodal LLM-powered self-evolving VLN framework was proposed. Specifically, SE-VLN comprised three core modules, i.e., a hierarchical memory module to transfer successful and failure cases into reusable knowledge, a retrieval-augmented thought-based reasoning module to retrieve experience and enable multi-step decision-making, and a reflection module to realize continual evolution. Comprehensive tests illustrated that the SE-VLN achieved navigation success rates of 57% and 35.2% in unseen environments, representing absolute performance improvements of 23.9% and 15.0% over current state-of-the-art methods on R2R and REVERSE datasets, respectively. Moreover, the SE-VLN showed performance improvement with increasing experience repository, elucidating its great potential as a self-evolving agent framework for VLN.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.13152.pdf", "abstract_url": "https://arxiv.org/abs/2507.13152", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于多模态大语言模型的自进化视觉语言导航框架（SE-VLN），旨在解决现有视觉语言导航（VLN）方法因固定知识库和推理能力而无法有效整合经验知识的问题。", "motivation": "现有的视觉语言导航方法受限于大语言模型（LLMs）的固定知识库和推理能力，无法有效整合经验知识，缺乏高效的进化能力。", "method": "SE-VLN框架包含三个核心模块：分层记忆模块用于将成功和失败案例转化为可重用知识，检索增强的基于思维的推理模块用于检索经验并实现多步决策，以及反思模块实现持续进化。", "result": "在未见过的环境中，SE-VLN的导航成功率分别达到了57%和35.2%，在R2R和REVERSE数据集上分别比现有最先进方法提高了23.9%和15.0%。", "conclusion": "SE-VLN作为一种自进化代理框架，展示了随着经验库增加而性能提升的潜力，为视觉语言导航领域提供了新的研究方向。"}}
{"id": "2507.12846", "title": "Enter the Mind Palace: Reasoning and Planning for Long-term Active Embodied Question Answering", "authors": ["Muhammad Fadhil Ginting", "Dong-Ki Kim", "Xiangyun Meng", "Andrzej Reinke", "Bandi Jai Krishna", "Navid Kayhani", "Oriana Peltzer", "David D. Fan", "Amirreza Shaban", "Sung-Kyun Kim", "Mykel J. Kochenderfer", "Ali-akbar Agha-mohammadi", "Shayegan Omidshafiei"], "abstract": "As robots become increasingly capable of operating over extended periods -- spanning days, weeks, and even months -- they are expected to accumulate knowledge of their environments and leverage this experience to assist humans more effectively. This paper studies the problem of Long-term Active Embodied Question Answering (LA-EQA), a new task in which a robot must both recall past experiences and actively explore its environment to answer complex, temporally-grounded questions. Unlike traditional EQA settings, which typically focus either on understanding the present environment alone or on recalling a single past observation, LA-EQA challenges an agent to reason over past, present, and possible future states, deciding when to explore, when to consult its memory, and when to stop gathering observations and provide a final answer. Standard EQA approaches based on large models struggle in this setting due to limited context windows, absence of persistent memory, and an inability to combine memory recall with active exploration. To address this, we propose a structured memory system for robots, inspired by the mind palace method from cognitive science. Our method encodes episodic experiences as scene-graph-based world instances, forming a reasoning and planning algorithm that enables targeted memory retrieval and guided navigation. To balance the exploration-recall trade-off, we introduce value-of-information-based stopping criteria that determines when the agent has gathered sufficient information. We evaluate our method on real-world experiments and introduce a new benchmark that spans popular simulation environments and actual industrial sites. Our approach significantly outperforms state-of-the-art baselines, yielding substantial gains in both answer accuracy and exploration efficiency.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.12846.pdf", "abstract_url": "https://arxiv.org/abs/2507.12846", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究了长期主动实体问答（LA-EQA）问题，提出了一种受认知科学中“记忆宫殿”方法启发的结构化记忆系统，用于机器人回忆过去经验并主动探索环境以回答复杂的时间基础问题。", "motivation": "解决机器人在长时间操作中如何有效积累和利用环境知识，以更有效地协助人类的问题。", "method": "提出了一种基于场景图的世界实例编码的推理和规划算法，结合了目标记忆检索和引导导航，并引入了基于信息价值的停止标准来平衡探索与回忆的权衡。", "result": "在真实世界实验中，该方法显著优于现有基线，在回答准确性和探索效率方面都有显著提升。", "conclusion": "通过结构化记忆系统和有效的推理规划算法，机器人能够更好地处理长期主动实体问答任务，为未来的机器人辅助人类提供了新的可能性。"}}
{"id": "2507.12624", "title": "Pathology-Guided Virtual Staining Metric for Evaluation and Training", "authors": ["Qiankai Wang", "James E.D. Tweel", "Parsin Haji Reza", "Anita Layton"], "abstract": "Virtual staining has emerged as a powerful alternative to traditional histopathological staining techniques, enabling rapid, reagent-free image transformations. However, existing evaluation methods predominantly rely on full-reference image quality assessment (FR-IQA) metrics such as structural similarity, which are originally designed for natural images and often fail to capture pathology-relevant features. Expert pathology reviews have also been used, but they are inherently subjective and time-consuming.", "subjects": "Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV); Systems and Control (eess.SY)", "comments": "19 pages, 10 figures. Intended for submission to the Journal of Imaging Informatics in Medicine (JIIM)", "pdf_url": "https://arxiv.org/pdf/2507.12624.pdf", "abstract_url": "https://arxiv.org/abs/2507.12624", "categories": ["Image and Video Processing (eess.IV)", "Computer Vision and Pattern Recognition (cs.CV)", "Systems and Control (eess.SY)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新的病理引导的虚拟染色评估和训练方法，旨在克服现有评估方法的局限性。", "motivation": "现有的虚拟染色评估方法主要依赖于为自然图像设计的全参考图像质量评估(FR-IQA)指标，这些指标往往无法捕捉到病理相关的特征。此外，专家病理评审虽然被使用，但本质上具有主观性和耗时性。", "method": "提出了一种病理引导的虚拟染色度量方法，用于评估和训练，旨在更准确地反映病理相关特征。", "result": "该方法能够更有效地评估虚拟染色技术的性能，克服了传统FR-IQA指标和专家评审的局限性。", "conclusion": "病理引导的虚拟染色度量方法为虚拟染色技术的评估和训练提供了一种更准确、更高效的解决方案，有助于推动该技术的发展和应用。"}}
{"id": "2507.13169", "title": "Prompt Injection 2.0: Hybrid AI Threats", "authors": ["Jeremy McHugh", "Kristina Šekrst", "Jon Cefalu"], "abstract": "Prompt injection attacks, where malicious input is designed to manipulate AI systems into ignoring their original instructions and following unauthorized commands instead, were first discovered by Preamble, Inc. in May 2022 and responsibly disclosed to OpenAI. Over the last three years, these attacks have continued to pose a critical security threat to LLM-integrated systems. The emergence of agentic AI systems, where LLMs autonomously perform multistep tasks through tools and coordination with other agents, has fundamentally transformed the threat landscape. Modern prompt injection attacks can now combine with traditional cybersecurity exploits to create hybrid threats that systematically evade traditional security controls. This paper presents a comprehensive analysis of Prompt Injection 2.0, examining how prompt injections integrate with Cross-Site Scripting (XSS), Cross-Site Request Forgery (CSRF), and other web security vulnerabilities to bypass traditional security measures. We build upon Preamble's foundational research and mitigation technologies, evaluating them against contemporary threats, including AI worms, multi-agent infections, and hybrid cyber-AI attacks. Our analysis incorporates recent benchmarks that demonstrate how traditional web application firewalls, XSS filters, and CSRF tokens fail against AI-enhanced attacks. We also present architectural solutions that combine prompt isolation, runtime security, and privilege separation with novel threat detection capabilities.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.13169.pdf", "abstract_url": "https://arxiv.org/abs/2507.13169", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文分析了Prompt Injection 2.0的混合AI威胁，探讨了提示注入攻击如何与传统的网络安全漏洞结合，形成能够绕过传统安全措施的混合威胁。", "motivation": "随着代理性AI系统的出现，提示注入攻击已经演变成能够与传统网络安全漏洞结合的混合威胁，这对LLM集成系统构成了严重的安全挑战。", "method": "本文通过综合分析方法，评估了Preamble的基础研究和缓解技术，并针对当代威胁（包括AI蠕虫、多代理感染和混合网络-AI攻击）进行了测试。", "result": "研究表明，传统的网络应用防火墙、XSS过滤器和CSRF令牌在面对AI增强的攻击时失效。", "conclusion": "本文提出了结合提示隔离、运行时安全和权限分离的架构解决方案，以及新颖的威胁检测能力，以应对Prompt Injection 2.0带来的挑战。"}}
{"id": "2507.13171", "title": "Aligning Humans and Robots via Reinforcement Learning from Implicit Human Feedback", "authors": ["Suzie Kim", "Hye-Bin Shin", "Seong-Whan Lee"], "abstract": "Conventional reinforcement learning (RL) ap proaches often struggle to learn effective policies under sparse reward conditions, necessitating the manual design of complex, task-specific reward functions. To address this limitation, rein forcement learning from human feedback (RLHF) has emerged as a promising strategy that complements hand-crafted rewards with human-derived evaluation signals. However, most existing RLHF methods depend on explicit feedback mechanisms such as button presses or preference labels, which disrupt the natural interaction process and impose a substantial cognitive load on the user. We propose a novel reinforcement learning from implicit human feedback (RLIHF) framework that utilizes non-invasive electroencephalography (EEG) signals, specifically error-related potentials (ErrPs), to provide continuous, implicit feedback without requiring explicit user intervention. The proposed method adopts a pre-trained decoder to transform raw EEG signals into probabilistic reward components, en abling effective policy learning even in the presence of sparse external rewards. We evaluate our approach in a simulation environment built on the MuJoCo physics engine, using a Kinova Gen2 robotic arm to perform a complex pick-and-place task that requires avoiding obstacles while manipulating target objects. The results show that agents trained with decoded EEG feedback achieve performance comparable to those trained with dense, manually designed rewards. These findings validate the potential of using implicit neural feedback for scalable and human-aligned reinforcement learning in interactive robotics.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.13171.pdf", "abstract_url": "https://arxiv.org/abs/2507.13171", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新颖的隐式人类反馈强化学习（RLIHF）框架，利用非侵入性脑电图（EEG）信号，特别是错误相关电位（ErrPs），在不需用户明确干预的情况下提供连续、隐式的反馈。该方法通过预训练的解码器将原始EEG信号转换为概率奖励组件，即使在外部奖励稀疏的情况下也能实现有效的策略学习。在基于MuJoCo物理引擎的仿真环境中，使用Kinova Gen2机械臂进行的复杂拾取放置任务中，该方法表现出与密集手动设计奖励相当的性能。", "motivation": "传统的强化学习方法在稀疏奖励条件下往往难以学习有效策略，需要手动设计复杂、任务特定的奖励函数。现有的基于人类反馈的强化学习（RLHF）方法大多依赖于显式反馈机制，如按钮按压或偏好标签，这不仅打断了自然交互过程，还给用户带来了巨大的认知负担。", "method": "提出了一种利用非侵入性脑电图（EEG）信号，特别是错误相关电位（ErrPs），提供连续、隐式反馈的强化学习框架（RLIHF）。该方法采用预训练的解码器将原始EEG信号转换为概率奖励组件，以在稀疏外部奖励的情况下实现有效的策略学习。", "result": "在基于MuJoCo物理引擎的仿真环境中，使用Kinova Gen2机械臂进行的复杂拾取放置任务中，通过解码EEG反馈训练的智能体表现出与密集手动设计奖励相当的性能。", "conclusion": "这些发现验证了在交互式机器人中使用隐式神经反馈进行可扩展和人类对齐的强化学习的潜力。"}}
