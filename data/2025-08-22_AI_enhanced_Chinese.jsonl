{"id": "2508.15243", "title": "Comp-X: On Defining an Interactive Learned Image Compression Paradigm With Expert-driven LLM Agent", "authors": ["Yixin Gao", "Xin Li", "Xiaohan Pan", "Runsen Feng", "Bingchen Li", "Yunpeng Qi", "Yiting Lu", "Zhengxue Cheng", "Zhibo Chen", "Jörn Ostermann"], "abstract": "We present Comp-X, the first intelligently interactive image compression paradigm empowered by the impressive reasoning capability of large language model (LLM) agent. Notably, commonly used image codecs usually suffer from limited coding modes and rely on manual mode selection by engineers, making them unfriendly for unprofessional users. To overcome this, we advance the evolution of image coding paradigm by introducing three key innovations: (i) multi-functional coding framework, which unifies different coding modes of various objective/requirements, including human-machine perception, variable coding, and spatial bit allocation, into one framework. (ii) interactive coding agent, where we propose an augmented in-context learning method with coding expert feedback to teach the LLM agent how to understand the coding request, mode selection, and the use of the coding tools. (iii) IIC-bench, the first dedicated benchmark comprising diverse user requests and the corresponding annotations from coding experts, which is systematically designed for intelligently interactive image compression evaluation. Extensive experimental results demonstrate that our proposed Comp-X can understand the coding requests efficiently and achieve impressive textual interaction capability. Meanwhile, it can maintain comparable compression performance even with a single coding framework, providing a promising avenue for artificial general intelligence (AGI) in image compression.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.15243.pdf", "abstract_url": "https://arxiv.org/abs/2508.15243", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "Comp-X是首个由大型语言模型（LLM）代理驱动的智能交互式图像压缩范式，通过多功能框架、交互式代理和专用基准，实现高效理解和压缩性能。", "motivation": "解决传统图像编解码器模式有限且依赖人工选择的问题，使其对非专业用户更友好。", "method": "引入多功能编码框架统一不同模式，使用增强上下文学习方法训练LLM代理，并开发IIC-bench基准进行评估。", "result": "实验显示Comp-X能高效理解编码请求，保持可比压缩性能，并展现文本交互能力。", "conclusion": "Comp-X为图像压缩中的人工通用智能（AGI）提供了有前景的途径。"}}
{"id": "2508.15313", "title": "First RAG, Second SEG: A Training-Free Paradigm for Camouflaged Object Detection", "authors": ["Wutao Liu", "YiDan Wang", "Pan Gao"], "abstract": "Camouflaged object detection (COD) poses a significant challenge in computer vision due to the high similarity between objects and their backgrounds. Existing approaches often rely on heavy training and large computational resources. While foundation models such as the Segment Anything Model (SAM) offer strong generalization, they still struggle to handle COD tasks without fine-tuning and require high-quality prompts to yield good performance. However, generating such prompts manually is costly and inefficient. To address these challenges, we propose \\textbf{First RAG, Second SEG (RAG-SEG)}, a training-free paradigm that decouples COD into two stages: Retrieval-Augmented Generation (RAG) for generating coarse masks as prompts, followed by SAM-based segmentation (SEG) for refinement. RAG-SEG constructs a compact retrieval database via unsupervised clustering, enabling fast and effective feature retrieval. During inference, the retrieved features produce pseudo-labels that guide precise mask generation using SAM2. Our method eliminates the need for conventional training while maintaining competitive performance. Extensive experiments on benchmark COD datasets demonstrate that RAG-SEG performs on par with or surpasses state-of-the-art methods. Notably, all experiments are conducted on a \\textbf{personal laptop}, highlighting the computational efficiency and practicality of our approach. We present further analysis in the Appendix, covering limitations, salient object detection extension, and possible improvements.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.15313.pdf", "abstract_url": "https://arxiv.org/abs/2508.15313", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "提出RAG-SEG，一种无需训练的方法，通过检索增强生成和SAM分割进行伪装物体检测，在基准数据集上性能优异且计算高效。", "motivation": "解决伪装物体检测中现有方法依赖大量训练和计算资源，以及基础模型如SAM需要高质量提示的问题。", "method": "使用两阶段范式：RAG生成粗略掩码作为提示，SEG基于SAM进行细化，构建无监督聚类检索数据库。", "result": "在基准数据集上性能与或超越最先进方法，所有实验在个人笔记本上完成，展示高效性。", "conclusion": "RAG-SEG提供了一种实用、计算高效的替代方案，无需传统训练，适用于资源受限环境。"}}
{"id": "2508.15207", "title": "Adversarial Agent Behavior Learning in Autonomous Driving Using Deep Reinforcement Learning", "authors": ["Arjun Srinivasan", "Anubhav Paras", "Aniket Bera"], "abstract": "Existing approaches in reinforcement learning train an agent to learn desired optimal behavior in an environment with rule based surrounding agents. In safety critical applications such as autonomous driving it is crucial that the rule based agents are modelled properly. Several behavior modelling strategies and IDM models are used currently to model the surrounding agents. We present a learning based method to derive the adversarial behavior for the rule based agents to cause failure scenarios. We evaluate our adversarial agent against all the rule based agents and show the decrease in cumulative reward.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.15207.pdf", "abstract_url": "https://arxiv.org/abs/2508.15207", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于深度强化学习的方法，用于在自动驾驶中学习对抗性行为，以测试和增强基于规则的代理模型的安全性。", "motivation": "解决自动驾驶中基于规则代理模型可能存在的安全漏洞，确保在关键安全应用中代理行为得到充分测试。", "method": "使用深度强化学习训练对抗性代理，生成导致失败场景的行为，并与现有基于规则的代理（如IDM模型）进行对抗评估。", "result": "对抗性代理显著降低了基于规则代理的累积奖励，证明了其有效性在引发失败场景方面。", "conclusion": "该方法有助于识别和缓解自动驾驶系统中的潜在风险，强调了学习型方法在行为建模中的重要性。"}}
{"id": "2508.15013", "title": "Goals and the Structure of Experience", "authors": ["Nadav Amir", "Stas Tiomkin", "Angela Langdon"], "abstract": "Purposeful behavior is a hallmark of natural and artificial intelligence. Its acquisition is often believed to rely on world models, comprising both descriptive (what is) and prescriptive (what is desirable) aspects that identify and evaluate state of affairs in the world, respectively. Canonical computational accounts of purposeful behavior, such as reinforcement learning, posit distinct components of a world model comprising a state representation (descriptive aspect) and a reward function (prescriptive aspect). However, an alternative possibility, which has not yet been computationally formulated, is that these two aspects instead co-emerge interdependently from an agent's goal. Here, we describe a computational framework of goal-directed state representation in cognitive agents, in which the descriptive and prescriptive aspects of a world model co-emerge from agent-environment interaction sequences, or experiences. Drawing on Buddhist epistemology, we introduce a construct of goal-directed, or telic, states, defined as classes of goal-equivalent experience distributions. Telic states provide a parsimonious account of goal-directed learning in terms of the statistical divergence between behavioral policies and desirable experience features. We review empirical and theoretical literature supporting this novel perspective and discuss its potential to provide a unified account of behavioral, phenomenological and neural dimensions of purposeful behaviors across diverse substrates.", "subjects": "Artificial Intelligence (cs.AI); Neurons and Cognition (q-bio.NC)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.15013.pdf", "abstract_url": "https://arxiv.org/abs/2508.15013", "categories": ["Artificial Intelligence (cs.AI)", "Neurons and Cognition (q-bio.NC)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出一个基于目标导向状态表示的计算框架，其中世界模型的描述性和规范性方面从智能体与环境交互中共同涌现，借鉴佛教认识论引入telic状态概念，为跨领域目的性行为提供统一解释。", "motivation": "解决传统计算模型（如强化学习）中状态表示和奖励函数分离的问题，探索描述性和规范性方面如何从目标中共同涌现的替代可能性。", "method": "引入telic状态作为目标等价经验分布的类，使用统计散度度量行为策略与期望经验特征之间的差异，基于智能体-环境交互序列构建计算框架。", "result": "框架得到实证和理论文献支持，能够统一解释行为、现象学和神经层面的目的性行为。", "conclusion": "该框架为自然和人工智能中的目的性行为提供了一种新颖、简约的计算解释，具有跨基质的应用潜力。"}}
{"id": "2508.15164", "title": "ContextualLVLM-Agent: A Holistic Framework for Multi-Turn Visually-Grounded Dialogue and Complex Instruction Following", "authors": ["Seungmin Han", "Haeun Kwon", "Ji-jun Park", "Taeyang Yoon"], "abstract": "Despite significant advancements in Large Language Models (LLMs) and Large Vision-Language Models (LVLMs), current models still face substantial challenges in handling complex, multi-turn, and visually-grounded tasks that demand deep reasoning, sustained contextual understanding, entity tracking, and multi-step instruction following. Existing benchmarks often fall short in capturing the dynamism and intricacies of real-world multi-modal interactions, leading to issues such as context loss and visual hallucinations. To address these limitations, we introduce MMDR-Bench (Multi-Modal Dialogue Reasoning Benchmark), a novel dataset comprising 300 meticulously designed complex multi-turn dialogue scenarios, each averaging 5-7 turns and evaluated across six core dimensions including visual entity tracking and reasoning depth. Furthermore, we propose CoLVLM Agent (Contextual LVLM Agent), a holistic framework that enhances existing LVLMs with advanced reasoning and instruction following capabilities through an iterative \"memory-perception-planning-execution\" cycle, requiring no extensive re-training of the underlying models. Our extensive experiments on MMDR-Bench demonstrate that CoLVLM Agent consistently achieves superior performance, attaining an average human evaluation score of 4.03, notably surpassing state-of-the-art commercial models like GPT-4o (3.92) and Gemini 1.5 Pro (3.85). The framework exhibits significant advantages in reasoning depth, instruction adherence, and error suppression, and maintains robust performance over extended dialogue turns, validating the effectiveness of its modular design and iterative approach for complex multi-modal interactions.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.15164.pdf", "abstract_url": "https://arxiv.org/abs/2508.15164", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了MMDR-Bench数据集和CoLVLM Agent框架，用于提升多模态对话中的推理和指令遵循能力，实验显示其性能优于现有模型。", "motivation": "解决当前大型语言和视觉语言模型在处理复杂、多轮、视觉基础任务时面临的上下文丢失、视觉幻觉和推理深度不足的问题。", "method": "提出一个无需重新训练现有模型的整体框架，采用'记忆-感知-规划-执行'的迭代循环来增强推理和指令遵循能力。", "result": "在MMDR-Bench上，CoLVLM Agent平均人类评估得分4.03，超过GPT-4o（3.92）和Gemini 1.5 Pro（3.85），在推理深度、指令遵循和错误抑制方面表现优越。", "conclusion": "该框架的模块化设计和迭代方法有效提升了复杂多模态交互的性能，验证了其在现实世界应用中的潜力。"}}
{"id": "2508.15213", "title": "Select to Know: An Internal-External Knowledge Self-Selection Framework for Domain-Specific Question Answering", "authors": ["Bolei He", "Xinran He", "Run Shao", "Shanfu Shu", "Xianwei Xue", "Mingquan Cheng", "Haifeng Li", "Zhenhua Ling"], "abstract": "Large Language Models (LLMs) perform well in general QA but often struggle in domain-specific scenarios. Retrieval-Augmented Generation (RAG) introduces external knowledge but suffers from hallucinations and latency due to noisy retrievals. Continued pretraining internalizes domain knowledge but is costly and lacks cross-domain flexibility. We attribute this challenge to the long-tail distribution of domain knowledge, which leaves partial yet useful internal knowledge underutilized. We further argue that knowledge acquisition should be progressive, mirroring human learning: first understanding concepts, then applying them to complex reasoning. To address this, we propose Selct2Know (S2K), a cost-effective framework that internalizes domain knowledge through an internal-external knowledge self-selection strategy and selective supervised fine-tuning. We also introduce a structured reasoning data generation pipeline and integrate GRPO to enhance reasoning ability. Experiments on medical, legal, and financial QA benchmarks show that S2K consistently outperforms existing methods and matches domain-pretrained LLMs with significantly lower cost.", "subjects": "Computation and Language (cs.CL)", "comments": "EMNLP2025 Findings", "pdf_url": "https://arxiv.org/pdf/2508.15213.pdf", "abstract_url": "https://arxiv.org/abs/2508.15213", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "Selct2Know (S2K) 是一个成本效益高的框架，通过内部-外部知识自选择和选择性监督微调，在医学、法律和金融QA基准测试中优于现有方法，匹配领域预训练LLMs但成本更低。", "motivation": "解决大型语言模型在领域特定QA中表现不佳的问题，特别是RAG的幻觉和延迟，以及持续预训练的高成本和缺乏跨域灵活性。", "method": "提出S2K框架，使用内部-外部知识自选择策略、选择性监督微调、结构化推理数据生成管道和GRPO集成来增强推理能力。", "result": "在医学、法律和金融QA基准测试中，S2K一致优于现有方法，并匹配领域预训练LLMs的性能，但成本显著降低。", "conclusion": "S2K提供了一种渐进式知识获取方法，有效利用内部和外部知识，提升领域特定QA性能，具有实际应用价值。"}}
{"id": "2508.15030", "title": "Collab-REC: An LLM-based Agentic Framework for Balancing Recommendations in Tourism", "authors": ["Ashmi Banerjee", "Fitri Nur Aisyah", "Adithi Satish", "Wolfgang Wörndl", "Yashar Deldjoo"], "abstract": "We propose Collab-REC, a multi-agent framework designed to counteract popularity bias and enhance diversity in tourism recommendations. In our setting, three LLM-based agents -- Personalization, Popularity, and Sustainability generate city suggestions from complementary perspectives. A non-LLM moderator then merges and refines these proposals via multi-round negotiation, ensuring each agent's viewpoint is incorporated while penalizing spurious or repeated responses. Experiments on European city queries show that Collab-REC improves diversity and overall relevance compared to a single-agent baseline, surfacing lesser-visited locales that often remain overlooked. This balanced, context-aware approach addresses over-tourism and better aligns with constraints provided by the user, highlighting the promise of multi-stakeholder collaboration in LLM-driven recommender systems.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.15030.pdf", "abstract_url": "https://arxiv.org/abs/2508.15030", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "Collab-REC是一个基于LLM的多智能体框架，用于旅游推荐，通过个性化、流行度和可持续性代理生成互补建议，非LLM调解员整合优化，提高多样性和相关性。", "motivation": "解决旅游推荐中的流行度偏见问题，增强多样性，应对过度旅游并更好地满足用户约束。", "method": "使用三个基于LLM的代理（个性化、流行度、可持续性）生成城市建议，非LLM调解员通过多轮协商合并和精炼提议。", "result": "在欧洲城市查询实验中，Collab-REC相比单代理基线提高了多样性和整体相关性，突出了较少访问的地点。", "conclusion": "多利益相关者协作在LLM驱动的推荐系统中具有潜力，能实现更平衡和上下文感知的推荐。"}}
{"id": "2508.15047", "title": "Emergent Crowds Dynamics from Language-Driven Multi-Agent Interactions", "authors": ["Yibo Liu", "Liam Shatzel", "Brandon Haworth", "Teseo Schneider"], "abstract": "Animating and simulating crowds using an agent-based approach is a well-established area where every agent in the crowd is individually controlled such that global human-like behaviour emerges. We observe that human navigation and movement in crowds are often influenced by complex social and environmental interactions, driven mainly by language and dialogue. However, most existing work does not consider these dimensions and leads to animations where agent-agent and agent-environment interactions are largely limited to steering and fixed higher-level goal extrapolation.", "subjects": "Artificial Intelligence (cs.AI); Graphics (cs.GR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.15047.pdf", "abstract_url": "https://arxiv.org/abs/2508.15047", "categories": ["Artificial Intelligence (cs.AI)", "Graphics (cs.GR)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文提出了一种基于语言驱动的多智能体交互方法，用于模拟人群动态，以更真实地捕捉人类在人群中的导航和移动行为。", "motivation": "解决现有基于智能体的人群模拟方法中缺乏复杂社会和语言交互的问题，这些方法通常只关注转向和固定目标，导致动画不真实。", "method": "使用语言驱动的多智能体交互方法，通过模拟对话和社会互动来增强智能体之间的动态。", "result": "该方法能够生成更逼真的人群行为，突显了语言在影响人群动态中的关键作用。", "conclusion": "语言驱动的交互是提升人群模拟真实性的重要因素，为未来研究提供了新方向。"}}
{"id": "2508.15068", "title": "S3LoRA: Safe Spectral Sharpness-Guided Pruning in Adaptation of Agent Planner", "authors": ["Shuang Ao", "Gopal Rumchurn"], "abstract": "Adapting Large Language Models (LLMs) using parameter-efficient fine-tuning (PEFT) techniques such as LoRA has enabled powerful capabilities in LLM-based agents. However, these adaptations can unintentionally compromise safety alignment, leading to unsafe or unstable behaviors, particularly in agent planning tasks. Existing safety-aware adaptation methods often require access to both base and instruction-tuned model checkpoints, which are frequently unavailable in practice, limiting their applicability. We propose S3LoRA (Safe Spectral Sharpness-Guided Pruning LoRA), a lightweight, data-free, and model-independent framework that mitigates safety risks in LoRA-adapted models by inspecting only the fine-tuned weight updates. We first introduce Magnitude-Aware Spherically Normalized SVD (MAS-SVD), which robustly analyzes the structural properties of LoRA updates while preserving global magnitude information. We then design the Spectral Sharpness Index (SSI), a sharpness-aware metric to detect layers with highly concentrated and potentially unsafe updates. These layers are pruned post-hoc to reduce risk without sacrificing task performance. Extensive experiments and ablation studies across agent planning and language generation tasks show that S3LoRA consistently improves safety metrics while maintaining or improving utility metrics and significantly reducing inference cost. These results establish S3LoRA as a practical and scalable solution for safely deploying LLM-based agents in real-world, resource-constrained, and safety-critical environments.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "9 pages, 2 figures", "pdf_url": "https://arxiv.org/pdf/2508.15068.pdf", "abstract_url": "https://arxiv.org/abs/2508.15068", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "S3LoRA是一种轻量级、数据无关且模型独立的框架，通过分析LoRA更新来减少安全风险，提高LLM代理的安全性而不牺牲性能。", "motivation": "解决LLM基于代理的规划任务中，参数高效微调（如LoRA）可能无意中损害安全对齐的问题，现有方法需要访问基础模型检查点，但实践中常不可用。", "method": "提出MAS-SVD分析LoRA更新的结构特性，设计SSI指标检测潜在不安全层，并进行后剪枝以减少风险。", "result": "实验显示S3LoRA在代理规划和语言生成任务中一致改善安全指标，保持或提升效用指标，并显著降低推理成本。", "conclusion": "S3LoRA是实用且可扩展的解决方案，适用于现实世界、资源受限和安全关键环境中的LLM代理部署。"}}
{"id": "2508.15119", "title": "Open-Universe Assistance Games", "authors": ["Rachel Ma", "Jingyi Qu", "Andreea Bobu", "Dylan Hadfield-Menell"], "abstract": "Embodied AI agents must infer and act in an interpretable way on diverse human goals and preferences that are not predefined. To formalize this setting, we introduce Open-Universe Assistance Games (OU-AGs), a framework where the agent must reason over an unbounded and evolving space of possible goals. In this context, we introduce GOOD (GOals from Open-ended Dialogue), a data-efficient, online method that extracts goals in the form of natural language during an interaction with a human, and infers a distribution over natural language goals. GOOD prompts an LLM to simulate users with different complex intents, using its responses to perform probabilistic inference over candidate goals. This approach enables rich goal representations and uncertainty estimation without requiring large offline datasets. We evaluate GOOD in a text-based grocery shopping domain and in a text-operated simulated household robotics environment (AI2Thor), using synthetic user profiles. Our method outperforms a baseline without explicit goal tracking, as confirmed by both LLM-based and human evaluations.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Robotics (cs.RO)", "comments": "7 pages + 2 pages references + 7 pages appendix", "pdf_url": "https://arxiv.org/pdf/2508.15119.pdf", "abstract_url": "https://arxiv.org/abs/2508.15119", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了Open-Universe Assistance Games (OU-AGs) 框架和GOOD方法，用于在开放目标空间中通过自然语言对话推断人类目标，并在模拟环境中验证其有效性。", "motivation": "解决具身AI代理在未预定义目标下推断和行动的问题，以处理多样且不断变化的人类目标和偏好。", "method": "引入OU-AGs框架和GOOD方法，使用LLM模拟用户意图进行概率推理，从对话中提取自然语言目标分布，无需大型离线数据集。", "result": "在文本购物和模拟家庭机器人环境中，GOOD方法优于无显式目标跟踪的基线，通过LLM和人类评估确认。", "conclusion": "GOOD方法支持丰富的目标表示和不确定性估计，提高了AI代理在开放世界中的辅助能力。"}}
{"id": "2508.15126", "title": "aiXiv: A Next-Generation Open Access Ecosystem for Scientific Discovery Generated by AI Scientists", "authors": ["Pengsong Zhang", "Xiang Hu", "Guowei Huang", "Yang Qi", "Heng Zhang", "Xiuxu Li", "Jiaxing Song", "Jiabin Luo", "Yijiang Li", "Shuo Yin", "Chengxiao Dai", "Eric Hanchen Jiang", "Xiaoyan Zhou", "Zhenfei Yin", "Boqin Yuan", "Jing Dong", "Guinan Su", "Guanren Qiao", "Haiming Tang", "Anghong Du", "Lili Pan", "Zhenzhong Lan", "Xinyu Liu"], "abstract": "Recent advances in large language models (LLMs) have enabled AI agents to autonomously generate scientific proposals, conduct experiments, author papers, and perform peer reviews. Yet this flood of AI-generated research content collides with a fragmented and largely closed publication ecosystem. Traditional journals and conferences rely on human peer review, making them difficult to scale and often reluctant to accept AI-generated research content; existing preprint servers (e.g. arXiv) lack rigorous quality-control mechanisms. Consequently, a significant amount of high-quality AI-generated research lacks appropriate venues for dissemination, hindering its potential to advance scientific progress. To address these challenges, we introduce aiXiv, a next-generation open-access platform for human and AI scientists. Its multi-agent architecture allows research proposals and papers to be submitted, reviewed, and iteratively refined by both human and AI scientists. It also provides API and MCP interfaces that enable seamless integration of heterogeneous human and AI scientists, creating a scalable and extensible ecosystem for autonomous scientific discovery. Through extensive experiments, we demonstrate that aiXiv is a reliable and robust platform that significantly enhances the quality of AI-generated research proposals and papers after iterative revising and reviewing on aiXiv. Our work lays the groundwork for a next-generation open-access ecosystem for AI scientists, accelerating the publication and dissemination of high-quality AI-generated research content. Code is available at", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2508.15126.pdf", "abstract_url": "https://arxiv.org/abs/2508.15126", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了aiXiv，一个为人类和AI科学家设计的下一代开放获取平台，通过多代理架构和API/MCP接口促进AI生成研究的提交、评审和迭代改进，提升研究质量并加速科学发现。", "motivation": "解决AI生成研究内容缺乏合适发表渠道的问题，因为传统期刊依赖人工评审且难以扩展，现有预印本服务器缺乏质量控制机制，阻碍了高质量AI研究的传播和科学进步。", "method": "采用多代理架构，允许人类和AI科学家提交、评审和迭代改进研究提案和论文，并提供API和MCP接口以实现无缝集成，构建可扩展和可扩展的生态系统。", "result": "通过广泛实验证明，aiXiv是一个可靠且稳健的平台，能显著提高AI生成研究提案和论文的质量，经过迭代修订和评审后效果明显。", "conclusion": "aiXiv为AI科学家奠定了基础，加速高质量AI生成研究内容的发表和传播，推动下一代开放获取生态系统的发展。"}}
{"id": "2508.15144", "title": "Mobile-Agent-v3: Foundamental Agents for GUI Automation", "authors": ["Jiabo Ye", "Xi Zhang", "Haiyang Xu", "Haowei Liu", "Junyang Wang", "Zhaoqing Zhu", "Ziwei Zheng", "Feiyu Gao", "Junjie Cao", "Zhengxi Lu", "Jitong Liao", "Qi Zheng", "Fei Huang", "Jingren Zhou", "Ming Yan"], "abstract": "This paper introduces GUI-Owl, a foundational GUI agent model that achieves state-of-the-art performance among open-source end-to-end models on ten GUI benchmarks across desktop and mobile environments, covering grounding, question answering, planning, decision-making, and procedural knowledge. GUI-Owl-7B achieves 66.4 on AndroidWorld and 29.4 on OSWorld. Building on this, we propose Mobile-Agent-v3, a general-purpose GUI agent framework that further improves performance to 73.3 on AndroidWorld and 37.7 on OSWorld, setting a new state-of-the-art for open-source GUI agent frameworks. GUI-Owl incorporates three key innovations: (1) Large-scale Environment Infrastructure: a cloud-based virtual environment spanning Android, Ubuntu, macOS, and Windows, enabling our Self-Evolving GUI Trajectory Production framework. This generates high-quality interaction data via automated query generation and correctness validation, leveraging GUI-Owl to refine trajectories iteratively, forming a self-improving loop. It supports diverse data pipelines and reduces manual annotation. (2) Diverse Foundational Agent Capabilities: by integrating UI grounding, planning, action semantics, and reasoning patterns, GUI-Owl supports end-to-end decision-making and can act as a modular component in multi-agent systems. (3) Scalable Environment RL: we develop a scalable reinforcement learning framework with fully asynchronous training for real-world alignment. We also introduce Trajectory-aware Relative Policy Optimization (TRPO) for online RL, achieving 34.9 on OSWorld. GUI-Owl and Mobile-Agent-v3 are open-sourced at", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.15144.pdf", "abstract_url": "https://arxiv.org/abs/2508.15144", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了GUI-Owl和Mobile-Agent-v3，一种用于GUI自动化的基础代理模型和框架，在多个基准测试中实现最先进性能，通过大规模环境基础设施、多样化能力和强化学习进行改进。", "motivation": "解决GUI自动化中端到端决策和性能提升的问题，特别是在桌面和移动环境中，以减少手动注释并提高自动化效率。", "method": "使用基于云的大规模虚拟环境、自演进GUI轨迹生产框架、集成UI接地、规划、行动语义和推理模式，以及可扩展的强化学习框架，包括TRPO。", "result": "GUI-Owl-7B在AndroidWorld和OSWorld上分别达到66.4和29.4，Mobile-Agent-v3提升至73.3和37.7，TRPO在OSWorld上达到34.9，均为开源模型中的新SOTA。", "conclusion": "GUI-Owl和Mobile-Agent-v3作为基础代理，通过创新方法显著提升GUI自动化性能，支持多代理系统，并开源以促进进一步研究。"}}
{"id": "2508.15253", "title": "Conflict-Aware Soft Prompting for Retrieval-Augmented Generation", "authors": ["Eunseong Choi", "June Park", "Hyeri Lee", "Jongwuk Lee"], "abstract": "Retrieval-augmented generation (RAG) enhances the capabilities of large language models (LLMs) by incorporating external knowledge into their input prompts. However, when the retrieved context contradicts the LLM's parametric knowledge, it often fails to resolve the conflict between incorrect external context and correct parametric knowledge, known as context-memory conflict. To tackle this problem, we introduce Conflict-Aware REtrieval-Augmented Generation (CARE), consisting of a context assessor and a base LLM. The context assessor encodes compact memory token embeddings from raw context tokens. Through grounded/adversarial soft prompting, the context assessor is trained to discern unreliable context and capture a guidance signal that directs reasoning toward the more reliable knowledge source. Extensive experiments show that CARE effectively mitigates context-memory conflicts, leading to an average performance gain of 5.0\\% on QA and fact-checking benchmarks, establishing a promising direction for trustworthy and adaptive RAG systems.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "Accepted to EMNLP 2025; 14 pages; 5 figures, 11 tables", "pdf_url": "https://arxiv.org/pdf/2508.15253.pdf", "abstract_url": "https://arxiv.org/abs/2508.15253", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "该论文提出CARE方法，通过上下文评估器和软提示技术，解决检索增强生成中的上下文-记忆冲突问题，提升性能5.0%。", "motivation": "解决检索增强生成中外部上下文与模型参数知识冲突的问题，以提高可靠性和适应性。", "method": "使用上下文评估器编码记忆令牌嵌入，并通过软提示训练来识别不可靠上下文和指导推理。", "result": "在QA和事实核查基准测试中，平均性能提升5.0%，有效缓解冲突。", "conclusion": "CARE为可信赖和自适应RAG系统提供了有前景的方向。"}}
{"id": "2508.15222", "title": "See it. Say it. Sorted: Agentic System for Compositional Diagram Generation", "authors": ["Hantao Zhang", "Jingyang Liu", "Ed Li"], "abstract": "We study sketch-to-diagram generation: converting rough hand sketches into precise, compositional diagrams. Diffusion models excel at photorealism but struggle with the spatial precision, alignment, and symbolic structure required for flowcharts. We introduce See it. Say it. Sorted., a training-free agentic system that couples a Vision-Language Model (VLM) with Large Language Models (LLMs) to produce editable Scalable Vector Graphics (SVG) programs. The system runs an iterative loop in which a Critic VLM proposes a small set of qualitative, relational edits; multiple candidate LLMs synthesize SVG updates with diverse strategies (conservative->aggressive, alternative, focused); and a Judge VLM selects the best candidate, ensuring stable improvement. This design prioritizes qualitative reasoning over brittle numerical estimates, preserves global constraints (e.g., alignment, connectivity), and naturally supports human-in-the-loop corrections. On 10 sketches derived from flowcharts in published papers, our method more faithfully reconstructs layout and structure than two frontier closed-source image generation LLMs (GPT-5 and Gemini-2.5-Pro), accurately composing primitives (e.g., multi-headed arrows) without inserting unwanted text. Because outputs are programmatic SVGs, the approach is readily extensible to presentation tools (e.g., PowerPoint) via APIs and can be specialized with improved prompts and task-specific tools. The codebase is open-sourced at", "subjects": "Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.15222.pdf", "abstract_url": "https://arxiv.org/abs/2508.15222", "categories": ["Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种无需训练的代理系统，通过结合视觉语言模型和大型语言模型，将手绘草图精确转换为可编辑的矢量图，优于现有方法。", "motivation": "解决扩散模型在流程图生成中空间精度、对齐和符号结构方面的不足，实现更精确的草图到图表转换。", "method": "使用迭代循环系统，包括批评VLM提出编辑建议、多个LLM生成SVG更新、法官VLM选择最佳候选，强调定性推理和全局约束。", "result": "在10个草图测试中，该方法比GPT-5和Gemini-2.5-Pro更准确地重建布局和结构，避免插入多余文本，输出可编程SVG。", "conclusion": "系统支持人类干预，易于扩展到演示工具，代码开源，为精确图表生成提供了可扩展的解决方案。"}}
{"id": "2508.15361", "title": "A Survey on Large Language Model Benchmarks", "authors": ["Shiwen Ni", "Guhong Chen", "Shuaimin Li", "Xuanang Chen", "Siyi Li", "Bingli Wang", "Qiyao Wang", "Xingjian Wang", "Yifan Zhang", "Liyang Fan", "Chengming Li", "Ruifeng Xu", "Le Sun", "Min Yang"], "abstract": "In recent years, with the rapid development of the depth and breadth of large language models' capabilities, various corresponding evaluation benchmarks have been emerging in increasing numbers. As a quantitative assessment tool for model performance, benchmarks are not only a core means to measure model capabilities but also a key element in guiding the direction of model development and promoting technological innovation. We systematically review the current status and development of large language model benchmarks for the first time, categorizing 283 representative benchmarks into three categories: general capabilities, domain-specific, and target-specific. General capability benchmarks cover aspects such as core linguistics, knowledge, and reasoning; domain-specific benchmarks focus on fields like natural sciences, humanities and social sciences, and engineering technology; target-specific benchmarks pay attention to risks, reliability, agents, etc. We point out that current benchmarks have problems such as inflated scores caused by data contamination, unfair evaluation due to cultural and linguistic biases, and lack of evaluation on process credibility and dynamic environments, and provide a referable design paradigm for future benchmark innovation.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.15361.pdf", "abstract_url": "https://arxiv.org/abs/2508.15361", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文首次系统综述了283个大语言模型基准，分为通用能力、领域特定和目标特定三类，指出当前基准存在数据污染、偏见等问题，并提供了未来创新设计范式。", "motivation": "解决大语言模型能力快速发展背景下，基准评估工具在性能测量、发展引导和技术创新中的核心作用，以及现有基准的不足问题。", "method": "系统回顾和分类283个代表性基准，分为通用能力、领域特定和目标特定三类，分析问题并提供设计范式。", "result": "识别出基准存在数据污染导致分数膨胀、文化语言偏见导致不公平评估、缺乏过程可信度和动态环境评估等问题。", "conclusion": "基准是评估和引导模型发展的关键，未来需创新以解决现有问题，促进技术进步。"}}
{"id": "2508.15294", "title": "Multiple Memory Systems for Enhancing the Long-term Memory of Agent", "authors": ["Gaoke Zhang", "Bo Wang", "Yunlong Ma", "Dongming Zhao", "Zifei Yu"], "abstract": "An agent powered by large language models have achieved impressive results, but effectively handling the vast amounts of historical data generated during interactions remains a challenge. The current approach is to design a memory module for the agent to process these data. However, existing methods, such as MemoryBank and A-MEM, have poor quality of stored memory content, which affects recall performance and response quality. In order to better construct high-quality long-term memory content, we have designed a multiple memory system (MMS) inspired by cognitive psychology theory. The system processes short-term memory to multiple long-term memory fragments, and constructs retrieval memory units and contextual memory units based on these fragments, with a one-to-one correspondence between the two. During the retrieval phase, MMS will match the most relevant retrieval memory units based on the user's query. Then, the corresponding contextual memory units is obtained as the context for the response stage to enhance knowledge, thereby effectively utilizing historical data. Experiments on LoCoMo dataset compared our method with three others, proving its effectiveness. Ablation studies confirmed the rationality of our memory units. We also analyzed the robustness regarding the number of selected memory segments and the storage overhead, demonstrating its practical value.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.15294.pdf", "abstract_url": "https://arxiv.org/abs/2508.15294", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于认知心理学理论的多记忆系统（MMS），通过处理短期记忆为多个长期记忆片段，构建检索和上下文记忆单元，以提升代理的长期记忆质量和响应性能，在LoCoMo数据集上验证了其有效性。", "motivation": "解决大型语言模型代理在处理大量历史数据时，现有方法如MemoryBank和A-MEM存储记忆内容质量差，影响召回和响应质量的问题。", "method": "设计多记忆系统（MMS），将短期记忆处理为多个长期记忆片段，构建一一对应的检索和上下文记忆单元，在检索阶段匹配相关单元以增强上下文。", "result": "在LoCoMo数据集上的实验证明MMS优于其他三种方法，消融研究确认记忆单元的合理性，分析显示对记忆段数量和存储开销的鲁棒性。", "conclusion": "MMS能有效利用历史数据，提升代理的长期记忆和响应质量，具有实际应用价值。"}}
{"id": "2508.15305", "title": "Coarse-to-Fine Grounded Memory for LLM Agent Planning", "authors": ["Wei Yang", "Jinwei Xiao", "Hongming Zhang", "Qingyang Zhang", "Yanna Wang", "Bo Xu"], "abstract": "Recent advancements in Large Language Models (LLMs) have driven growing interest in LLM-based agents for complex planning tasks. To avoid costly agent training, many studies adopted memory mechanism that enhances LLM with offline experiences or online trajectory analysis. However, existing works focus on single-granularity memory derived from dynamic environmental interactions, which are inherently constrained by the quality of the collected experiences. This limitation, in turn, constrain the diversity of knowledge and the flexibility of planning. We propose Coarse-to-Fine Grounded Memory (\\Ours{}), a novel framework that grounds coarse-to-fine memories with LLM, thereby fully leverage them for flexible adaptation to diverse scenarios. \\Ours{} grounds environmental information into coarse-grained focus points to guide experience collection in training tasks, followed by grounding of actionable hybrid-grained tips from each experience. At inference, \\Ours{} retrieves task-relevant experiences and tips to support planning. When facing environmental anomalies, the LLM grounds the current situation into fine-grained key information, enabling flexible self-QA reflection and plan correction.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "Accepted to EMNLP 2025 Main Conference;27 pages,15 figures", "pdf_url": "https://arxiv.org/pdf/2508.15305.pdf", "abstract_url": "https://arxiv.org/abs/2508.15305", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种粗到细的接地内存框架，用于增强LLM代理在复杂规划任务中的灵活性和适应性。", "motivation": "解决现有LLM代理内存机制基于单一粒度经验，受限于经验质量，导致知识多样性和规划灵活性不足的问题。", "method": "使用粗到细的接地内存，将环境信息转化为粗粒度焦点指导经验收集，然后从经验中提取可操作的混合粒度提示，并在推理时检索相关经验和提示以支持规划，面对异常时通过细粒度信息进行自我QA反思和计划修正。", "result": "框架能够更有效地利用离线经验和在线分析，提升LLM代理在多样场景中的规划适应性和灵活性。", "conclusion": "该方法通过多粒度内存接地，显著增强了LLM代理的规划能力，具有广泛的应用潜力。"}}
{"id": "2508.15335", "title": "RETAIL: Towards Real-world Travel Planning for Large Language Models", "authors": ["Bin Deng", "Yizhe Feng", "Zeming Liu", "Qing Wei", "Xiangrong Zhu", "Shuai Chen", "Yuanfang Guo", "Yunhong Wang"], "abstract": "Although large language models have enhanced automated travel planning abilities, current systems remain misaligned with real-world scenarios. First, they assume users provide explicit queries, while in reality requirements are often implicit. Second, existing solutions ignore diverse environmental factors and user preferences, limiting the feasibility of plans. Third, systems can only generate plans with basic POI arrangements, failing to provide all-in-one plans with rich details. To mitigate these challenges, we construct a novel dataset \\textbf{RETAIL}, which supports decision-making for implicit queries while covering explicit queries, both with and without revision needs. It also enables environmental awareness to ensure plan feasibility under real-world scenarios, while incorporating detailed POI information for all-in-one travel plans. Furthermore, we propose a topic-guided multi-agent framework, termed TGMA. Our experiments reveal that even the strongest existing model achieves merely a 1.0% pass rate, indicating real-world travel planning remains extremely challenging. In contrast, TGMA demonstrates substantially improved performance 2.72%, offering promising directions for real-world travel planning.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.15335.pdf", "abstract_url": "https://arxiv.org/abs/2508.15335", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了RETAIL数据集和TGMA框架，以解决大语言模型在真实旅行规划中的挑战，如隐式查询、环境因素和详细规划，显著提升了性能。", "motivation": "当前大语言模型在旅行规划中与真实场景不匹配，存在隐式查询处理不足、忽略环境因素和用户偏好、以及无法提供详细一体化计划的问题。", "method": "构建RETAIL数据集支持隐式和显式查询决策，并提出主题引导的多智能体框架TGMA，以增强环境意识和详细POI信息整合。", "result": "实验显示现有最强模型仅1.0%通过率，而TGMA达到2.72%通过率，性能显著改善。", "conclusion": "TGMA为真实旅行规划提供了有前景的方向，强调数据集和框架在解决现实挑战中的重要性。"}}
{"id": "2508.15447", "title": "From Bits to Boardrooms: A Cutting-Edge Multi-Agent LLM Framework for Business Excellence", "authors": ["Zihao Wang", "Junming Zhang"], "abstract": "Large Language Models (LLMs) have shown promising potential in business applications, particularly in enterprise decision support and strategic planning, yet current approaches often struggle to reconcile intricate operational analyses with overarching strategic goals across diverse market environments, leading to fragmented workflows and reduced collaboration across organizational levels. This paper introduces BusiAgent, a novel multi-agent framework leveraging LLMs for advanced decision-making in complex corporate environments. BusiAgent integrates three core innovations: an extended Continuous Time Markov Decision Process (CTMDP) for dynamic agent modeling, a generalized entropy measure to optimize collaborative efficiency, and a multi-level Stackelberg game to handle hierarchical decision processes. Additionally, contextual Thompson sampling is employed for prompt optimization, supported by a comprehensive quality assurance system to mitigate errors. Extensive empirical evaluations across diverse business scenarios validate BusiAgent's efficacy, demonstrating its capacity to generate coherent, client-focused solutions that smoothly integrate granular insights with high-level strategy, significantly outperforming established approaches in both solution quality and user satisfaction. By fusing cutting-edge AI technologies with deep business insights, BusiAgent marks a substantial step forward in AI-driven enterprise decision-making, empowering organizations to navigate complex business landscapes more effectively.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "Accepted by ECAI 2025", "pdf_url": "https://arxiv.org/pdf/2508.15447.pdf", "abstract_url": "https://arxiv.org/abs/2508.15447", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了BusiAgent，一种基于多智能体LLM的框架，用于企业决策，通过动态建模、熵优化和分层游戏处理复杂业务场景，实证显示其优于现有方法。", "motivation": "解决当前LLM在业务应用中难以整合操作分析与战略目标的问题，导致工作流碎片化和协作减少。", "method": "使用扩展的CTMDP进行动态智能体建模，广义熵度量优化协作效率，多级Stackelberg游戏处理分层决策，并结合上下文Thompson抽样和QA系统。", "result": "在多样业务场景中验证了BusiAgent的有效性，能生成连贯、客户导向的解决方案，显著提升解决方案质量和用户满意度。", "conclusion": "BusiAgent融合AI技术和业务洞察，推动AI驱动的企业决策，帮助组织更有效地应对复杂商业环境。"}}
{"id": "2508.15510", "title": "Super-additive Cooperation in Language Model Agents", "authors": ["Filippo Tonini", "Lukas Galke"], "abstract": "With the prospect of autonomous artificial intelligence (AI) agents, studying their tendency for cooperative behavior becomes an increasingly relevant topic. This study is inspired by the super-additive cooperation theory, where the combined effects of repeated interactions and inter-group rivalry have been argued to be the cause for cooperative tendencies found in humans. We devised a virtual tournament where language model agents, grouped into teams, face each other in a Prisoner's Dilemma game. By simulating both internal team dynamics and external competition, we discovered that this blend substantially boosts both overall and initial, one-shot cooperation levels (the tendency to cooperate in one-off interactions). This research provides a novel framework for large language models to strategize and act in complex social scenarios and offers evidence for how intergroup competition can, counter-intuitively, result in more cooperative behavior. These insights are crucial for designing future multi-agent AI systems that can effectively work together and better align with human values. Source code is available at", "subjects": "Artificial Intelligence (cs.AI)", "comments": "FAIEMA 2025", "pdf_url": "https://arxiv.org/pdf/2508.15510.pdf", "abstract_url": "https://arxiv.org/abs/2508.15510", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过模拟语言模型代理在囚徒困境游戏中的团队动态和外部竞争，发现结合重复互动和组间竞争能显著提高合作水平，为多智能体AI系统设计提供新见解。", "motivation": "研究自主AI代理的合作行为倾向，受超加性合作理论启发，探讨人类合作行为的原因，以应用于未来AI系统。", "method": "设计虚拟锦标赛，将语言模型代理分组进行囚徒困境游戏，模拟团队内部动态和外部竞争。", "result": "结合重复互动和组间竞争显著提高了整体和一次性合作水平。", "conclusion": "研究为语言模型在复杂社会场景中的策略制定提供了框架，并证明组间竞争可意外促进合作，对设计符合人类价值观的多智能体AI系统至关重要。"}}
{"id": "2508.15588", "title": "A Dynamical Systems Framework for Reinforcement Learning Safety and Robustness Verification", "authors": ["Ahmed Nasir", "Abdelhafid Zenati"], "abstract": "The application of reinforcement learning to safety-critical systems is limited by the lack of formal methods for verifying the robustness and safety of learned policies. This paper introduces a novel framework that addresses this gap by analyzing the combination of an RL agent and its environment as a discrete-time autonomous dynamical system. By leveraging tools from dynamical systems theory, specifically the Finite-Time Lyapunov Exponent (FTLE), we identify and visualize Lagrangian Coherent Structures (LCS) that act as the hidden \"skeleton\" governing the system's behavior. We demonstrate that repelling LCS function as safety barriers around unsafe regions, while attracting LCS reveal the system's convergence properties and potential failure modes, such as unintended \"trap\" states. To move beyond qualitative visualization, we introduce a suite of quantitative metrics, Mean Boundary Repulsion (MBR), Aggregated Spurious Attractor Strength (ASAS), and Temporally-Aware Spurious Attractor Strength (TASAS), to formally measure a policy's safety margin and robustness. We further provide a method for deriving local stability guarantees and extend the analysis to handle model uncertainty. Through experiments in both discrete and continuous control environments, we show that this framework provides a comprehensive and interpretable assessment of policy behavior, successfully identifying critical flaws in policies that appear successful based on reward alone.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.15588.pdf", "abstract_url": "https://arxiv.org/abs/2508.15588", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出一个基于动态系统理论的框架，使用FTLE和LCS来可视化和量化RL策略的安全性与鲁棒性，并通过实验验证其有效性。", "motivation": "解决强化学习在安全关键系统中缺乏正式验证方法的问题，以确保学习策略的鲁棒性和安全性。", "method": "将RL代理和环境建模为离散时间自治动态系统，利用FTLE识别LCS，并引入MBR、ASAS、TASAS等量化指标进行测量。", "result": "框架成功识别策略中的安全缺陷和陷阱状态，在离散和连续控制环境中提供可解释的评估。", "conclusion": "该框架为RL策略的正式验证提供了全面工具，有助于提高安全关键系统的可靠性。"}}
{"id": "2508.15652", "title": "Understanding Action Effects through Instrumental Empowerment in Multi-Agent Reinforcement Learning", "authors": ["Ardian Selmonaj", "Miroslav Strupl", "Oleg Szehr", "Alessandro Antonucci"], "abstract": "To reliably deploy Multi-Agent Reinforcement Learning (MARL) systems, it is crucial to understand individual agent behaviors within a team. While prior work typically evaluates overall team performance based on explicit reward signals or learned value functions, it is unclear how to infer agent contributions in the absence of any value feedback. In this work, we investigate whether meaningful insights into agent behaviors can be extracted that are consistent with the underlying value functions, solely by analyzing the policy distribution. Inspired by the phenomenon that intelligent agents tend to pursue convergent instrumental values, which generally increase the likelihood of task success, we introduce Intended Cooperation Values (ICVs), a method based on information-theoretic Shapley values for quantifying each agent's causal influence on their co-players' instrumental empowerment. Specifically, ICVs measure an agent's action effect on its teammates' policies by assessing their decision uncertainty and preference alignment. The analysis across cooperative and competitive MARL environments reveals the extent to which agents adopt similar or diverse strategies. By comparing action effects between policies and value functions, our method identifies which agent behaviors are beneficial to team success, either by fostering deterministic decisions or by preserving flexibility for future action choices. Our proposed method offers novel insights into cooperation dynamics and enhances explainability in MARL systems.", "subjects": "Artificial Intelligence (cs.AI); Information Theory (cs.IT); Machine Learning (cs.LG); Multiagent Systems (cs.MA)", "comments": "European Conference on Artificial Intelligence (ECAI) 2025", "pdf_url": "https://arxiv.org/pdf/2508.15652.pdf", "abstract_url": "https://arxiv.org/abs/2508.15652", "categories": ["Artificial Intelligence (cs.AI)", "Information Theory (cs.IT)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于信息论Shapley值的ICVs方法，用于量化多智能体强化学习中智能体对队友策略的因果影响，以增强合作动态理解和系统可解释性。", "motivation": "解决在没有价值反馈的情况下推断智能体贡献的问题，以可靠部署MARL系统。", "method": "使用信息论Shapley值计算ICVs，评估智能体动作对队友决策不确定性和偏好对齐的影响。", "result": "在合作和竞争环境中分析显示，ICVs能识别有益于团队成功的智能体行为，如促进确定性决策或保持灵活性。", "conclusion": "ICVs方法提供了对合作动态的新见解，提高了MARL系统的可解释性。"}}
{"id": "2508.15610", "title": "Transduction is All You Need for Structured Data Workflows", "authors": ["Alfio Gliozzo", "Naweed Khan", "Christodoulos Constantinides", "Nandana Mihindukulasooriya", "Nahuel Defosse", "Junkyu Lee"], "abstract": "This paper introduces Agentics, a modular framework for building agent-based systems capable of structured reasoning and compositional generalization over complex data. Designed with research and practical applications in mind, Agentics offers a novel perspective on working with data and AI workflows. In this framework, agents are abstracted from the logical flow and they are used internally to the data type to enable logical transduction among data. Agentics encourages AI developers to focus on modeling data rather than crafting prompts, enabling a declarative language in which data types are provided by LLMs and composed through logical transduction, which is executed by LLMs when types are connected. We provide empirical evidence demonstrating the applicability of this framework across domain-specific multiple-choice question answering, semantic parsing for text-to-SQL, and automated prompt optimization tasks, achieving state-of-the-art accuracy or improved scalability without sacrificing performance. The open-source implementation is available at \\texttt{", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "32 pages, 8 figures", "pdf_url": "https://arxiv.org/pdf/2508.15610.pdf", "abstract_url": "https://arxiv.org/abs/2508.15610", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了Agentics，一个模块化框架，用于构建基于代理的系统，支持结构化推理和组合泛化，通过逻辑转导处理复杂数据，在多个任务中实现最先进性能。", "motivation": "解决在AI工作流中处理结构化数据时，需要更高效、可扩展的方法，避免依赖手动提示工程的问题。", "method": "使用基于代理的框架，通过逻辑转导在数据之间进行抽象和组合，利用LLMs执行转导操作。", "result": "在领域特定多选问答、文本到SQL的语义解析和自动提示优化任务中，实现了最先进的准确性或改进的可扩展性，性能不降。", "conclusion": "Agentics框架提供了一种声明式方法，使开发者能专注于数据建模，而非提示工程，具有广泛的应用潜力和开源实现。"}}
{"id": "2508.15746", "title": "End-to-End Agentic RAG System Training for Traceable Diagnostic Reasoning", "authors": ["Qiaoyu Zheng", "Yuze Sun", "Chaoyi Wu", "Weike Zhao", "Pengcheng Qiu", "Yongguo Yu", "Kun Sun", "Yanfeng Wang", "Ya Zhang", "Weidi Xie"], "abstract": "Accurate diagnosis with medical large language models is hindered by knowledge gaps and hallucinations. Retrieval and tool-augmented methods help, but their impact is limited by weak use of external knowledge and poor feedback-reasoning traceability. To address these challenges, We introduce Deep-DxSearch, an agentic RAG system trained end-to-end with reinforcement learning (RL) that enables steer tracebale retrieval-augmented reasoning for medical diagnosis. In Deep-DxSearch, we first construct a large-scale medical retrieval corpus comprising patient records and reliable medical knowledge sources to support retrieval-aware reasoning across diagnostic scenarios. More crutially, we frame the LLM as the core agent and the retrieval corpus as its environment, using tailored rewards on format, retrieval, reasoning structure, and diagnostic accuracy, thereby evolving the agentic RAG policy from large-scale data through RL.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "comments": "35 pages, 5 figures, 3 tables", "pdf_url": "https://arxiv.org/pdf/2508.15746.pdf", "abstract_url": "https://arxiv.org/abs/2508.15746", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent", "agentic", "@RAG"], "AI": {"tldr": "本文介绍了Deep-DxSearch，一种端到端训练的代理RAG系统，通过强化学习实现可追溯的检索增强推理，用于医学诊断，以解决知识差距和幻觉问题。", "motivation": "医学大语言模型在准确诊断中存在知识差距和幻觉问题，现有检索和工具增强方法因外部知识利用弱和反馈推理可追溯性差而受限。", "method": "构建大规模医学检索语料库，将LLM作为核心代理，检索语料库作为环境，使用定制奖励（格式、检索、推理结构、诊断准确性）通过强化学习训练代理RAG策略。", "result": "系统实现了可追溯的检索增强推理，提高了医学诊断的准确性和可靠性。", "conclusion": "Deep-DxSearch通过端到端强化学习训练，增强了医学诊断的可追溯性和准确性，为改进医疗AI系统提供了有效方法。"}}
{"id": "2508.15752", "title": "\"Does the cafe entrance look accessible? Where is the door?\" Towards Geospatial AI Agents for Visual Inquiries", "authors": ["Jon E. Froehlich", "Jared Hwang", "Zeyu Wang", "John S. O'Meara", "Xia Su", "William Huang", "Yang Zhang", "Alex Fiannaca", "Philip Nelson", "Shaun Kane"], "abstract": "Interactive digital maps have revolutionized how people travel and learn about the world; however, they rely on pre-existing structured data in GIS databases (e.g., road networks, POI indices), limiting their ability to address geo-visual questions related to what the world looks like. We introduce our vision for Geo-Visual Agents--multimodal AI agents capable of understanding and responding to nuanced visual-spatial inquiries about the world by analyzing large-scale repositories of geospatial images, including streetscapes (e.g., Google Street View), place-based photos (e.g., TripAdvisor, Yelp), and aerial imagery (e.g., satellite photos) combined with traditional GIS data sources. We define our vision, describe sensing and interaction approaches, provide three exemplars, and enumerate key challenges and opportunities for future work.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "comments": "Accepted to the ICCV'25 Workshop \"Vision Foundation Models and Generative AI for Accessibility: Challenges and Opportunities\"", "pdf_url": "https://arxiv.org/pdf/2508.15752.pdf", "abstract_url": "https://arxiv.org/abs/2508.15752", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出Geo-Visual Agents，一种多模态AI代理，通过分析地理空间图像和GIS数据，回答视觉空间查询，以解决现有数字地图依赖结构化数据的限制。", "motivation": "解决交互式数字地图因依赖GIS结构化数据而无法处理关于世界外观的视觉空间查询的问题。", "method": "结合地理空间图像（如街景、照片、卫星图像）和传统GIS数据，开发多模态AI代理进行理解和响应。", "result": "定义了Geo-Visual Agents的愿景，提供了感知和交互方法、三个示例，并列举了未来挑战和机遇。", "conclusion": "Geo-Visual Agents有潜力增强数字地图功能，但需应对相关挑战以实现广泛应用。"}}
{"id": "2508.15526", "title": "SafetyFlow: An Agent-Flow System for Automated LLM Safety Benchmarking", "authors": ["Xiangyang Zhu", "Yuan Tian", "Chunyi Li", "Kaiwei Zhang", "Wei Sun", "Guangtao Zhai"], "abstract": "The rapid proliferation of large language models (LLMs) has intensified the requirement for reliable safety evaluation to uncover model vulnerabilities. To this end, numerous LLM safety evaluation benchmarks are proposed. However, existing benchmarks generally rely on labor-intensive manual curation, which causes excessive time and resource consumption. They also exhibit significant redundancy and limited difficulty. To alleviate these problems, we introduce SafetyFlow, the first agent-flow system designed to automate the construction of LLM safety benchmarks. SafetyFlow can automatically build a comprehensive safety benchmark in only four days without any human intervention by orchestrating seven specialized agents, significantly reducing time and resource cost. Equipped with versatile tools, the agents of SafetyFlow ensure process and cost controllability while integrating human expertise into the automatic pipeline. The final constructed dataset, SafetyFlowBench, contains 23,446 queries with low redundancy and strong discriminative power. Our contribution includes the first fully automated benchmarking pipeline and a comprehensive safety benchmark. We evaluate the safety of 49 advanced LLMs on our dataset and conduct extensive experiments to validate our efficacy and efficiency.", "subjects": "Computation and Language (cs.CL)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2508.15526.pdf", "abstract_url": "https://arxiv.org/abs/2508.15526", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "SafetyFlow是一个自动化构建LLM安全基准的代理流系统，显著减少时间和资源消耗，生成低冗余、高区分度的数据集。", "motivation": "现有LLM安全基准依赖人工构建，导致高成本、冗余和难度有限，需要自动化解决方案。", "method": "使用七个专业代理的代理流系统，集成工具和人类专业知识，自动构建基准，无需人工干预。", "result": "在四天内自动构建SafetyFlowBench数据集，包含23,446个查询，评估49个先进LLM，验证了高效性和有效性。", "conclusion": "SafetyFlow提供了首个全自动基准构建管道和全面安全基准，提升了LLM安全评估的效率和可靠性。"}}
{"id": "2508.15456", "title": "PyTOD: Programmable Task-Oriented Dialogue with Execution Feedback", "authors": ["Alexandru Coca", "Bo-Hsiang Tseng", "Pete Boothroyd", "Jianpeng Cheng", "Mark Gaynor", "Zhenxing Zhang", "Joe Stacey", "Tristan Guigue", "Héctor Martinez Alonso", "Diarmuid Ó Séaghdha", "Anders Johannsen"], "abstract": "Programmable task-oriented dialogue (TOD) agents enable language models to follow structured dialogue policies, but their effectiveness hinges on accurate state tracking. We present PyTOD, an agent that generates executable code to track dialogue state and uses policy and execution feedback for efficient error correction. To this end, PyTOD employs a simple constrained decoding approach, using a language model instead of grammar rules to follow API schemata. This leads to state-of-the-art state tracking performance on the challenging SGD benchmark. Our experiments show that PyTOD surpasses strong baselines in both accuracy and robust user goal estimation as the dialogue progresses, demonstrating the effectiveness of execution-aware state tracking.", "subjects": "Computation and Language (cs.CL)", "comments": "20 pages, 12 figures. To appear at SIGDIAL 2025", "pdf_url": "https://arxiv.org/pdf/2508.15456.pdf", "abstract_url": "https://arxiv.org/abs/2508.15456", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "PyTOD是一种可编程任务导向对话代理，通过生成可执行代码跟踪对话状态，并利用执行反馈进行高效纠错，在SGD基准测试中达到最先进的性能。", "motivation": "解决任务导向对话代理中状态跟踪准确性不足的问题，以提高对话策略的有效性。", "method": "使用语言模型生成可执行代码进行状态跟踪，采用约束解码方法替代语法规则，并利用策略和执行反馈进行错误修正。", "result": "在SGD基准测试中，PyTOD在状态跟踪准确性和鲁棒性方面超越基线模型，展示了执行感知状态跟踪的有效性。", "conclusion": "PyTOD通过代码生成和执行反馈显著提升了任务导向对话的准确性和鲁棒性，为未来对话系统开发提供了有效方法。"}}
{"id": "2508.15757", "title": "Language-Guided Tuning: Enhancing Numeric Optimization with Textual Feedback", "authors": ["Yuxing Lu", "Yucheng Hu", "Nan Sun", "Xukai Zhao"], "abstract": "Configuration optimization remains a critical bottleneck in machine learning, requiring coordinated tuning across model architecture, training strategy, feature engineering, and hyperparameters. Traditional approaches treat these dimensions independently and lack interpretability, while recent automated methods struggle with dynamic adaptability and semantic reasoning about optimization decisions. We introduce Language-Guided Tuning (LGT), a novel framework that employs multi-agent Large Language Models to intelligently optimize configurations through natural language reasoning. We apply textual gradients - qualitative feedback signals that complement numerical optimization by providing semantic understanding of training dynamics and configuration interdependencies. LGT coordinates three specialized agents: an Advisor that proposes configuration changes, an Evaluator that assesses progress, and an Optimizer that refines the decision-making process, creating a self-improving feedback loop. Through comprehensive evaluation on six diverse datasets, LGT demonstrates substantial improvements over traditional optimization methods, achieving performance gains while maintaining high interpretability.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Multiagent Systems (cs.MA)", "comments": "9 pages, 4 figures, 4 tables", "pdf_url": "https://arxiv.org/pdf/2508.15757.pdf", "abstract_url": "https://arxiv.org/abs/2508.15757", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了语言引导调优（LGT）框架，利用多代理大型语言模型通过自然语言推理优化机器学习配置，结合文本梯度提升性能和可解释性。", "motivation": "解决机器学习中配置优化的瓶颈，传统方法缺乏解释性和动态适应性，自动方法难以进行语义推理。", "method": "使用多代理LLM（顾问、评估器、优化器）和文本梯度，通过自然语言反馈循环优化配置。", "result": "在六个数据集上评估，LGT显著优于传统优化方法，实现性能提升并保持高可解释性。", "conclusion": "LGT框架有效结合数值和语义优化，提供可解释且自适应的配置优化解决方案。"}}
{"id": "2508.15693", "title": "NiceWebRL: a Python library for human subject experiments with reinforcement learning environments", "authors": ["Wilka Carvalho", "Vikram Goddla", "Ishaan Sinha", "Hoon Shin", "Kunal Jha"], "abstract": "We present NiceWebRL, a research tool that enables researchers to use machine reinforcement learning (RL) environments for online human subject experiments. NiceWebRL is a Python library that allows any Jax-based environment to be transformed into an online interface, supporting both single-agent and multi-agent environments. As such, NiceWebRL enables AI researchers to compare their algorithms to human performance, cognitive scientists to test ML algorithms as theories for human cognition, and multi-agent researchers to develop algorithms for human-AI collaboration. We showcase NiceWebRL with 3 case studies that demonstrate its potential to help develop Human-like AI, Human-compatible AI, and Human-assistive AI. In the first case study (Human-like AI), NiceWebRL enables the development of a novel RL model of cognition. Here, NiceWebRL facilitates testing this model against human participants in both a grid world and Craftax, a 2D Minecraft domain. In our second case study (Human-compatible AI), NiceWebRL enables the development of a novel multi-agent RL algorithm that can generalize to human partners in the Overcooked domain. Finally, in our third case study (Human-assistive AI), we show how NiceWebRL can allow researchers to study how an LLM can assist humans on complex tasks in XLand-Minigrid, an environment with millions of hierarchical tasks. The library is available at", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.15693.pdf", "abstract_url": "https://arxiv.org/abs/2508.15693", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "NiceWebRL 是一个 Python 库，用于将 Jax 强化学习环境转换为在线界面，支持人机实验，应用于人类性能比较、认知科学和多人协作研究。", "motivation": "解决研究人员难以使用强化学习环境进行在线人类实验的问题，以促进 AI 与人类性能的对比、认知理论测试和人机协作算法开发。", "method": "开发一个 Python 库，将 Jax 环境转换为在线界面，支持单智能体和多智能体环境，并通过三个案例研究展示其应用。", "result": "案例研究展示了 NiceWebRL 在人类类似 AI、人类兼容 AI 和人类辅助 AI 方面的潜力，包括在网格世界、Craftax、Overcooked 和 XLand-Minigrid 环境中的应用。", "conclusion": "NiceWebRL 是一个有效的工具，有助于开发更人类化的 AI，促进跨学科研究，并可通过在线实验加速创新。"}}
{"id": "2508.15748", "title": "Response and Prompt Evaluation to Prevent Parasocial Relationships with Chatbots", "authors": ["Emma Rath", "Stuart Armstrong", "Rebecca Gorman"], "abstract": "The development of parasocial relationships with AI agents has severe, and in some cases, tragic effects for human well-being. Yet preventing such dynamics is challenging: parasocial cues often emerge gradually in private conversations, and not all forms of emotional engagement are inherently harmful. We address this challenge by introducing a simple response evaluation framework, created by repurposing a state-of-the-art language model, that evaluates ongoing conversations for parasocial cues in real time. To test the feasibility of this approach, we constructed a small synthetic dataset of thirty dialogues spanning parasocial, sycophantic, and neutral conversations. Iterative evaluation with five stage testing successfully identified all parasocial conversations while avoiding false positives under a tolerant unanimity rule, with detection typically occurring within the first few exchanges. These findings provide preliminary evidence that evaluation agents can provide a viable solution for the prevention of parasocial relations.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.15748.pdf", "abstract_url": "https://arxiv.org/abs/2508.15748", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种利用先进语言模型实时评估对话中拟社会关系线索的框架，通过合成数据集测试，成功识别所有拟社会对话且无假阳性，为预防AI拟社会关系提供了可行方案。", "motivation": "解决AI代理导致拟社会关系对人类福祉的负面影响问题，由于这些关系在私人对话中逐渐形成且并非所有情感互动都有害，预防具有挑战性。", "method": "采用重新利用先进语言模型的响应评估框架，实时分析对话中的拟社会线索，并使用合成数据集（30个对话，涵盖拟社会、奉承和中性类型）进行五阶段迭代测试。", "result": "在容忍一致规则下，成功识别所有拟社会对话，无假阳性，检测通常在对话初期完成。", "conclusion": "评估代理可作为预防拟社会关系的可行方法，初步证据支持其有效性，有助于提升人类福祉。"}}
{"id": "2508.15110", "title": "LLMs and Agentic AI in Insurance Decision-Making: Opportunities and Challenges For Africa", "authors": ["Graham Hill", "JingYuan Gong", "Thulani Babeli", "Moseli Mots'oehli", "James Gachomo Wanjiku"], "abstract": "In this work, we highlight the transformative potential of Artificial Intelligence (AI), particularly Large Language Models (LLMs) and agentic AI, in the insurance sector. We consider and emphasize the unique opportunities, challenges, and potential pathways in insurance amid rapid performance improvements, increased open-source access, decreasing deployment costs, and the complexity of LLM or agentic AI frameworks. To bring it closer to home, we identify critical gaps in the African insurance market and highlight key local efforts, players, and partnership opportunities. Finally, we call upon actuaries, insurers, regulators, and tech leaders to a collaborative effort aimed at creating inclusive, sustainable, and equitable AI strategies and solutions: by and for Africans.", "subjects": "Computational Engineering, Finance, and Science (cs.CE); Computation and Language (cs.CL); Emerging Technologies (cs.ET); Applications (stat.AP)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.15110.pdf", "abstract_url": "https://arxiv.org/abs/2508.15110", "categories": ["Computational Engineering, Finance, and Science (cs.CE)", "Computation and Language (cs.CL)", "Emerging Technologies (cs.ET)", "Applications (stat.AP)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文探讨了人工智能（特别是大型语言模型和代理AI）在保险业中的变革潜力，重点关注非洲市场的机遇、挑战和合作路径。", "motivation": "解决非洲保险市场在AI应用中的关键差距，并促进包容性和可持续的AI策略发展。", "method": "通过识别机会、挑战和本地努力，强调合作和伙伴关系的方法。", "result": "突出了AI在保险决策中的潜在益处，并呼吁多方协作以推动非洲专属解决方案。", "conclusion": "结论是AI可为非洲保险业带来转型，但需通过合作实现公平和可持续的发展。"}}
{"id": "2508.14926", "title": "Learning to Drive Ethically: Embedding Moral Reasoning into Autonomous Driving", "authors": ["Dianzhao Li", "Ostap Okhrin"], "abstract": "Autonomous vehicles hold great promise for reducing traffic fatalities and improving transportation efficiency, yet their widespread adoption hinges on embedding robust ethical reasoning into routine and emergency maneuvers. Here, we present a hierarchical Safe Reinforcement Learning (Safe RL) framework that explicitly integrates moral considerations with standard driving objectives. At the decision level, a Safe RL agent is trained using a composite ethical risk cost, combining collision probability and harm severity, to generate high-level motion targets. A dynamic Prioritized Experience Replay mechanism amplifies learning from rare but critical, high-risk events. At the execution level, polynomial path planning coupled with Proportional-Integral-Derivative (PID) and Stanley controllers translates these targets into smooth, feasible trajectories, ensuring both accuracy and comfort. We train and validate our approach on rich, real-world traffic datasets encompassing diverse vehicles, cyclists, and pedestrians, and demonstrate that it outperforms baseline methods in reducing ethical risk and maintaining driving performance. To our knowledge, this is the first study of ethical decision-making for autonomous vehicles via Safe RL in real-world scenarios. Our results highlight the potential of combining formal control theory and data-driven learning to advance ethically accountable autonomy in complex, human-mixed traffic environments.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.14926.pdf", "abstract_url": "https://arxiv.org/abs/2508.14926", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种结合安全强化学习的层次框架，将道德推理融入自动驾驶决策，以减少伦理风险并提升驾驶性能，在真实交通数据中验证了其有效性。", "motivation": "解决自动驾驶车辆在常规和紧急操作中嵌入稳健伦理推理的问题，以确保广泛采用并减少交通事故。", "method": "使用层次安全强化学习框架，包括决策层的伦理风险成本训练和动态优先经验回放，以及执行层的多项式路径规划和PID/Stanley控制器。", "result": "在真实世界交通数据集上，该方法在减少伦理风险和维持驾驶性能方面优于基线方法。", "conclusion": "结合形式控制理论和数据驱动学习，可推进复杂混合交通环境中的伦理负责自主性。"}}
{"id": "2508.15760", "title": "LiveMCP-101: Stress Testing and Diagnosing MCP-enabled Agents on Challenging Queries", "authors": ["Ming Yin", "Dinghan Shen", "Silei Xu", "Jianbing Han", "Sixun Dong", "Mian Zhang", "Yebowen Hu", "Shujian Liu", "Simin Ma", "Song Wang", "Sathish Reddy Indurthi", "Xun Wang", "Yiran Chen", "Kaiqiang Song"], "abstract": "Tool calling has emerged as a critical capability for AI agents to interact with the real world and solve complex tasks. While the Model Context Protocol (MCP) provides a powerful standardized framework for tool integration, there is a significant gap in benchmarking how well AI agents can effectively solve multi-step tasks using diverse MCP tools in realistic, dynamic scenarios. In this work, we present LiveMCP-101, a benchmark of 101 carefully curated real-world queries, refined through iterative LLM rewriting and manual review, that require coordinated use of multiple MCP tools including web search, file operations, mathematical reasoning, and data analysis. Moreover, we introduce a novel evaluation approach that leverages ground-truth execution plans rather than raw API outputs, better reflecting the evolving nature of real-world environments. Experiments show that even frontier LLMs achieve a success rate below 60\\%, highlighting major challenges in tool orchestration. Detailed ablations and error analysis further reveal distinct failure modes and inefficiencies in token usage, pointing to concrete directions for advancing current models. LiveMCP-101 sets a rigorous standard for evaluating real-world agent capabilities, advancing toward autonomous AI systems that reliably execute complex tasks through tool use.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.15760.pdf", "abstract_url": "https://arxiv.org/abs/2508.15760", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "LiveMCP-101是一个包含101个真实世界查询的基准测试，用于评估AI代理在多步骤任务中使用MCP工具的性能，显示前沿LLM成功率低于60%，并识别了工具协调中的挑战和改进方向。", "motivation": "解决AI代理在现实动态场景中有效使用MCP工具进行多步骤任务的基准测试缺失问题。", "method": "通过迭代LLM重写和手动审查创建查询集，并引入基于真实执行计划而非原始API输出的新评估方法。", "result": "实验表明前沿LLM成功率低于60%，错误分析揭示了工具协调失败模式和令牌使用效率低下。", "conclusion": "LiveMCP-101为评估AI代理能力设定了严格标准，推动自主AI系统通过工具使用可靠执行复杂任务的发展。"}}
{"id": "2508.15310", "title": "IPIGuard: A Novel Tool Dependency Graph-Based Defense Against Indirect Prompt Injection in LLM Agents", "authors": ["Hengyu An", "Jinghuai Zhang", "Tianyu Du", "Chunyi Zhou", "Qingming Li", "Tao Lin", "Shouling Ji"], "abstract": "Large language model (LLM) agents are widely deployed in real-world applications, where they leverage tools to retrieve and manipulate external data for complex tasks. However, when interacting with untrusted data sources (e.g., fetching information from public websites), tool responses may contain injected instructions that covertly influence agent behaviors and lead to malicious outcomes, a threat referred to as Indirect Prompt Injection (IPI). Existing defenses typically rely on advanced prompting strategies or auxiliary detection models. While these methods have demonstrated some effectiveness, they fundamentally rely on assumptions about the model's inherent security, which lacks structural constraints on agent behaviors. As a result, agents still retain unrestricted access to tool invocations, leaving them vulnerable to stronger attack vectors that can bypass the security guardrails of the model. To prevent malicious tool invocations at the source, we propose a novel defensive task execution paradigm, called IPIGuard, which models the agents' task execution process as a traversal over a planned Tool Dependency Graph (TDG). By explicitly decoupling action planning from interaction with external data, IPIGuard significantly reduces unintended tool invocations triggered by injected instructions, thereby enhancing robustness against IPI attacks. Experiments on the AgentDojo benchmark show that IPIGuard achieves a superior balance between effectiveness and robustness, paving the way for the development of safer agentic systems in dynamic environments.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "EMNLP 2025", "pdf_url": "https://arxiv.org/pdf/2508.15310.pdf", "abstract_url": "https://arxiv.org/abs/2508.15310", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "IPIGuard是一种基于工具依赖图的防御方法，通过解耦动作规划和外部数据交互，有效减少间接提示注入攻击，提升LLM代理的安全性。", "motivation": "解决LLM代理在处理不可信数据源时，因间接提示注入攻击导致的恶意工具调用问题，现有防御方法依赖模型固有安全性假设，缺乏结构性约束。", "method": "提出IPIGuard防御范式，将任务执行建模为工具依赖图的遍历，分离动作规划和外部数据交互。", "result": "在AgentDojo基准测试中，IPIGuard在有效性和鲁棒性方面达到优越平衡。", "conclusion": "IPIGuard为动态环境中更安全的代理系统开发铺平了道路。"}}
{"id": "2508.15201", "title": "Survey of Vision-Language-Action Models for Embodied Manipulation", "authors": ["Haoran Li", "Yuhui Chen", "Wenbo Cui", "Weiheng Liu", "Kai Liu", "Mingcai Zhou", "Zhengtao Zhang", "Dongbin Zhao"], "abstract": "Embodied intelligence systems, which enhance agent capabilities through continuous environment interactions, have garnered significant attention from both academia and industry. Vision-Language-Action models, inspired by advancements in large foundation models, serve as universal robotic control frameworks that substantially improve agent-environment interaction capabilities in embodied intelligence systems. This expansion has broadened application scenarios for embodied AI robots. This survey comprehensively reviews VLA models for embodied manipulation. Firstly, it chronicles the developmental trajectory of VLA architectures. Subsequently, we conduct a detailed analysis of current research across 5 critical dimensions: VLA model structures, training datasets, pre-training methods, post-training methods, and model evaluation. Finally, we synthesize key challenges in VLA development and real-world deployment, while outlining promising future research directions.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": "in Chinese language", "pdf_url": "https://arxiv.org/pdf/2508.15201.pdf", "abstract_url": "https://arxiv.org/abs/2508.15201", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文综述了视觉-语言-动作模型在具身操作中的发展、结构、数据集、训练方法、评估及挑战与未来方向。", "motivation": "解决具身智能系统中代理与环境交互能力不足的问题，通过VLA模型提升机器人控制框架的通用性和应用范围。", "method": "采用文献综述方法，分析VLA模型的架构发展、数据集、预训练和后训练方法，以及评估维度。", "result": "总结了VLA模型的进展、关键维度的研究现状，并识别了开发和部署中的主要挑战。", "conclusion": "VLA模型显著增强了具身操作能力，但面临挑战，未来研究应关注改进模型结构和实际应用。"}}
{"id": "2508.15437", "title": "Test-time Corpus Feedback: From Retrieval to RAG", "authors": ["Mandeep Rathee", "Venktesh V", "Sean MacAvaney", "Avishek Anand"], "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a standard framework for knowledge-intensive NLP tasks, combining large language models (LLMs) with document retrieval from external corpora. Despite its widespread use, most RAG pipelines continue to treat retrieval and reasoning as isolated components, retrieving documents once and then generating answers without further interaction. This static design often limits performance on complex tasks that require iterative evidence gathering or high-precision retrieval. Recent work in both the information retrieval (IR) and NLP communities has begun to close this gap by introducing adaptive retrieval and ranking methods that incorporate feedback. In this survey, we present a structured overview of advanced retrieval and ranking mechanisms that integrate such feedback. We categorize feedback signals based on their source and role in improving the query, retrieved context, or document pool. By consolidating these developments, we aim to bridge IR and NLP perspectives and highlight retrieval as a dynamic, learnable component of end-to-end RAG systems.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "18 pages, 1 figure", "pdf_url": "https://arxiv.org/pdf/2508.15437.pdf", "abstract_url": "https://arxiv.org/abs/2508.15437", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文综述了检索增强生成（RAG）中反馈机制的进展，强调动态检索和排名方法以提升复杂任务性能。", "motivation": "解决RAG框架中检索与推理分离导致的静态设计问题，特别是在需要迭代证据收集或高精度检索的复杂任务中。", "method": "通过分类反馈信号来源和作用，整合自适应检索和排名机制，将检索视为可学习的动态组件。", "result": "综述显示反馈机制能改进查询、检索上下文或文档池，弥合信息检索与NLP领域的差距。", "conclusion": "RAG系统应发展为端到端动态框架，反馈集成是关键，以提升整体性能和适应性。"}}
{"id": "2508.15663", "title": "Mind and Motion Aligned: A Joint Evaluation IsaacSim Benchmark for Task Planning and Low-Level Policies in Mobile Manipulation", "authors": ["Nikita Kachaev", "Andrei Spiridonov", "Andrey Gorodetsky", "Kirill Muravyev", "Nikita Oskolkov", "Aditya Narendra", "Vlad Shakhuro", "Dmitry Makarov", "Aleksandr I. Panov", "Polina Fedotova", "Alexey K. Kovalev"], "abstract": "Benchmarks are crucial for evaluating progress in robotics and embodied AI. However, a significant gap exists between benchmarks designed for high-level language instruction following, which often assume perfect low-level execution, and those for low-level robot control, which rely on simple, one-step commands. This disconnect prevents a comprehensive evaluation of integrated systems where both task planning and physical execution are critical. To address this, we propose Kitchen-R, a novel benchmark that unifies the evaluation of task planning and low-level control within a simulated kitchen environment. Built as a digital twin using the Isaac Sim simulator and featuring more than 500 complex language instructions, Kitchen-R supports a mobile manipulator robot. We provide baseline methods for our benchmark, including a task-planning strategy based on a vision-language model and a low-level control policy based on diffusion policy. We also provide a trajectory collection system. Our benchmark offers a flexible framework for three evaluation modes: independent assessment of the planning module, independent assessment of the control policy, and, crucially, an integrated evaluation of the whole system. Kitchen-R bridges a key gap in embodied AI research, enabling more holistic and realistic benchmarking of language-guided robotic agents.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.15663.pdf", "abstract_url": "https://arxiv.org/abs/2508.15663", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文提出了Kitchen-R基准，在模拟厨房环境中统一评估任务规划和低级控制，以解决现有基准在高层次语言指令遵循和低级机器人控制之间的脱节问题。", "motivation": "解决机器人学和具身AI中基准评估的脱节问题，即高层次任务规划和低级执行假设完美，无法全面评估集成系统。", "method": "使用Isaac Sim模拟器构建数字孪生环境，提供500多个复杂语言指令，结合基于视觉语言模型的任务规划策略和基于扩散策略的低级控制政策。", "result": "Kitchen-R基准支持三种评估模式：独立评估规划模块、独立评估控制政策以及集成系统评估，填补了具身AI研究的关键空白。", "conclusion": "Kitchen-R基准为语言引导机器人代理提供了更全面和现实的基准测试框架，促进了更整体的系统评估。"}}
