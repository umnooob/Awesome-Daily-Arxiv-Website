{"id": "2506.14831", "title": "Recent Advances in Multi-Agent Human Trajectory Prediction: A Comprehensive Review", "authors": ["Céline Finet", "Stephane Da Silva Martins", "Jean-Bernard Hayet", "Ioannis Karamouzas", "Javad Amirian", "Sylvie Le Hégarat-Mascle", "Julien Pettré", "Emanuel Aldea"], "abstract": "With the emergence of powerful data-driven methods in human trajectory prediction (HTP), gaining a finer understanding of multi-agent interactions lies within hand's reach, with important implications in areas such as autonomous navigation and crowd modeling. This survey reviews some of the most recent advancements in deep learning-based multi-agent trajectory prediction, focusing on studies published between 2020 and 2024. We categorize the existing methods based on their architectural design, their input representations, and their overall prediction strategies, placing a particular emphasis on models evaluated using the ETH/UCY benchmark. Furthermore, we highlight key challenges and future research directions in the field of multi-agent HTP.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Robotics (cs.RO)", "comments": "30 pages", "pdf_url": "https://arxiv.org/pdf/2506.14831.pdf", "abstract_url": "https://arxiv.org/abs/2506.14831", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Machine Learning (cs.LG)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文综述了2020年至2024年间基于深度学习的多智能体人类轨迹预测的最新进展，重点关注了使用ETH/UCY基准评估的模型，并讨论了该领域的关键挑战和未来研究方向。", "motivation": "随着数据驱动方法在人类轨迹预测（HTP）中的兴起，深入理解多智能体交互变得触手可及，这对自动驾驶导航和人群建模等领域具有重要意义。", "method": "本文根据架构设计、输入表示和整体预测策略对现有方法进行了分类，特别关注了使用ETH/UCY基准评估的模型。", "result": "综述了多智能体HTP领域的最新进展，并识别了该领域的关键挑战和未来研究方向。", "conclusion": "多智能体人类轨迹预测领域在深度学习的推动下取得了显著进展，但仍面临挑战，需要进一步研究以解决这些问题。"}}
{"id": "2506.14990", "title": "MEAL: A Benchmark for Continual Multi-Agent Reinforcement Learning", "authors": ["Tristan Tomilin", "Luka van den Boogaard", "Samuel Garcin", "Bram Grooten", "Meng Fang", "Mykola Pechenizkiy"], "abstract": "Benchmarks play a crucial role in the development and analysis of reinforcement learning (RL) algorithms, with environment availability strongly impacting research. One particularly underexplored intersection is continual learning (CL) in cooperative multi-agent settings. To remedy this, we introduce MEAL (Multi-agent Environments for Adaptive Learning), the first benchmark tailored for continual multi-agent reinforcement learning (CMARL). Existing CL benchmarks run environments on the CPU, leading to computational bottlenecks and limiting the length of task sequences. MEAL leverages JAX for GPU acceleration, enabling continual learning across sequences of 100 tasks on a standard desktop PC in a few hours. We show that naively combining popular CL and MARL methods yields strong performance on simple environments, but fails to scale to more complex settings requiring sustained coordination and adaptation. Our ablation study identifies architectural and algorithmic features critical for CMARL on MEAL.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.14990.pdf", "abstract_url": "https://arxiv.org/abs/2506.14990", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "MEAL是一个专为持续多智能体强化学习（CMARL）设计的基准测试，利用JAX进行GPU加速，支持在标准桌面PC上几小时内完成100个任务的持续学习。", "motivation": "解决在合作多智能体设置中持续学习（CL）研究不足的问题，以及现有CL基准测试因在CPU上运行而导致的计算瓶颈和任务序列长度限制。", "method": "引入MEAL基准测试，利用JAX实现GPU加速，支持长任务序列的持续学习，并通过消融研究识别对CMARL关键的架构和算法特征。", "result": "简单环境中，流行的CL和MARL方法结合表现良好，但在需要持续协调和适应的复杂环境中表现不佳。", "conclusion": "MEAL为CMARL研究提供了首个基准测试，揭示了在复杂多智能体环境中持续学习的关键挑战和解决方案。"}}
{"id": "2506.15131", "title": "Modeling the One-to-Many Property in Open-Domain Dialogue with LLMs", "authors": ["Jing Yang Lee", "Kong-Aik Lee", "Woon-Seng Gan"], "abstract": "Open-domain Dialogue (OD) exhibits a one-to-many (o2m) property, whereby multiple appropriate responses exist for a single dialogue context. Despite prior research showing that modeling this property boosts response diversity, most modern LLM-based dialogue agents do not explicitly do so. In this work, we model the o2m property of OD in LLMs by decomposing OD generation into two key tasks: Multi-Response Generation (MRG) and Preference-based Selection (PS), which entail generating a set of n semantically and lexically diverse high-quality responses for a given dialogue context, followed by selecting a single response based on human preference, respectively. To facilitate MRG and PS, we introduce o2mDial, a dialogue corpus explicitly designed to capture the o2m property by featuring multiple plausible responses for each context. Leveraging o2mDial, we propose new in-context learning and instruction-tuning strategies, as well as novel evaluation metrics for MRG, alongside a model-based approach for PS. Empirical results demonstrate that applying the proposed two-stage framework to smaller LLMs for OD generation enhances overall response diversity while maintaining contextual coherence, improving response quality by up to 90%, bringing them closer to the performance of larger models.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.15131.pdf", "abstract_url": "https://arxiv.org/abs/2506.15131", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种方法来建模开放域对话（OD）中的一对多（o2m）属性，通过将OD生成分解为多响应生成（MRG）和基于偏好的选择（PS）两个关键任务，以提高响应多样性同时保持上下文连贯性。", "motivation": "开放域对话中存在一对多的属性，即对于单个对话上下文存在多个合适的响应。尽管先前研究表明建模这一属性可以增加响应多样性，但大多数基于大型语言模型（LLM）的对话代理并未明确这样做。", "method": "通过引入o2mDial对话语料库来促进MRG和PS，提出了新的上下文学习和指令调整策略，以及MRG的新评估指标和PS的基于模型的方法。", "result": "实证结果表明，将提出的两阶段框架应用于较小的LLMs进行OD生成，可以提高整体响应多样性，同时保持上下文连贯性，响应质量提高了高达90%，使其性能接近更大的模型。", "conclusion": "通过明确建模开放域对话中的一对多属性，可以显著提高对话代理的响应多样性和质量，这对于开发更自然、更人性化的对话系统具有重要意义。"}}
{"id": "2506.15225", "title": "Joint Computation Offloading and Resource Allocation for Uncertain Maritime MEC via Cooperation of UAVs and Vessels", "authors": ["Jiahao You", "Ziye Jia", "Chao Dong", "Qihui Wu", "Zhu Han"], "abstract": "The computation demands from the maritime Internet of Things (MIoT) increase rapidly in recent years, and the unmanned aerial vehicles (UAVs) and vessels based multi-access edge computing (MEC) can fulfill these MIoT requirements. However, the uncertain maritime tasks present significant challenges of inefficient computation offloading and resource allocation. In this paper, we focus on the maritime computation offloading and resource allocation through the cooperation of UAVs and vessels, with consideration of uncertain tasks. Specifically, we propose a cooperative MEC framework for computation offloading and resource allocation, including MIoT devices, UAVs and vessels. Then, we formulate the optimization problem to minimize the total execution time. As for the uncertain MIoT tasks, we leverage Lyapunov optimization to tackle the unpredictable task arrivals and varying computational resource availability. \nBy converting the long-term constraints into short-term constraints, we obtain a set of small-scale optimization problems. Further, considering the heterogeneity of actions and resources of UAVs and vessels, we reformulate the small-scale optimization problem into a Markov game (MG). Moreover, a heterogeneous-agent soft actor-critic is proposed to sequentially update various neural networks and effectively solve the MG problem. \nFinally, simulations are conducted to verify the effectiveness in addressing computational offloading and resource allocation.", "subjects": "Artificial Intelligence (cs.AI); Signal Processing (eess.SP)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.15225.pdf", "abstract_url": "https://arxiv.org/abs/2506.15225", "categories": ["Artificial Intelligence (cs.AI)", "Signal Processing (eess.SP)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种通过无人机和船只合作的海上多接入边缘计算（MEC）框架，以应对海上物联网（MIoT）中不确定任务的计算卸载和资源分配问题，旨在最小化总执行时间。", "motivation": "海上物联网（MIoT）的计算需求迅速增长，但不确定的海上任务给计算卸载和资源分配带来了效率低下的挑战。", "method": "提出了一种合作MEC框架，利用Lyapunov优化处理不确定任务，将长期约束转化为短期约束，并将问题重新表述为马尔可夫游戏（MG），采用异构代理软演员-评论家方法解决。", "result": "仿真验证了所提方法在解决计算卸载和资源分配问题上的有效性。", "conclusion": "通过无人机和船只的合作，可以有效应对海上MEC中的不确定任务，优化计算卸载和资源分配，提高执行效率。"}}
{"id": "2506.15207", "title": "Multi-Agent Reinforcement Learning for Autonomous Multi-Satellite Earth Observation: A Realistic Case Study", "authors": ["Mohamad A. Hady", "Siyi Hu", "Mahardhika Pratama", "Jimmy Cao", "Ryszard Kowalczyk"], "abstract": "The exponential growth of Low Earth Orbit (LEO) satellites has revolutionised Earth Observation (EO) missions, addressing challenges in climate monitoring, disaster management, and more. However, autonomous coordination in multi-satellite systems remains a fundamental challenge. Traditional optimisation approaches struggle to handle the real-time decision-making demands of dynamic EO missions, necessitating the use of Reinforcement Learning (RL) and Multi-Agent Reinforcement Learning (MARL). In this paper, we investigate RL-based autonomous EO mission planning by modelling single-satellite operations and extending to multi-satellite constellations using MARL frameworks. We address key challenges, including energy and data storage limitations, uncertainties in satellite observations, and the complexities of decentralised coordination under partial observability. By leveraging a near-realistic satellite simulation environment, we evaluate the training stability and performance of state-of-the-art MARL algorithms, including PPO, IPPO, MAPPO, and HAPPO. Our results demonstrate that MARL can effectively balance imaging and resource management while addressing non-stationarity and reward interdependency in multi-satellite coordination. The insights gained from this study provide a foundation for autonomous satellite operations, offering practical guidelines for improving policy learning in decentralised EO missions.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.15207.pdf", "abstract_url": "https://arxiv.org/abs/2506.15207", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究了基于强化学习（RL）和多智能体强化学习（MARL）的自主地球观测（EO）任务规划，针对多卫星星座中的自主协调问题，提出了一种解决方案。", "motivation": "随着低地球轨道（LEO）卫星数量的指数增长，地球观测任务在气候监测、灾害管理等领域面临挑战。传统优化方法难以满足动态EO任务的实时决策需求，因此需要利用RL和MARL技术。", "method": "研究通过模拟单卫星操作并扩展到多卫星星座，使用MARL框架（包括PPO、IPPO、MAPPO和HAPPO算法）来训练和评估模型，解决了能源和数据存储限制、观测不确定性及部分可观测下的分散协调等关键挑战。", "result": "结果表明，MARL能有效平衡成像和资源管理，同时解决多卫星协调中的非平稳性和奖励依赖性问题。", "conclusion": "本研究为自主卫星操作提供了基础，为改进分散EO任务中的策略学习提供了实用指南。"}}
{"id": "2506.15377", "title": "Efficient and Generalizable Environmental Understanding for Visual Navigation", "authors": ["Ruoyu Wang", "Xinshu Li", "Chen Wang", "Lina Yao"], "abstract": "Visual Navigation is a core task in Embodied AI, enabling agents to navigate complex environments toward given objectives. Across diverse settings within Navigation tasks, many necessitate the modelling of sequential data accumulated from preceding time steps. While existing methods perform well, they typically process all historical observations simultaneously, overlooking the internal association structure within the data, which may limit the potential for further improvements in task performance. We address this by examining the unique characteristics of Navigation tasks through the lens of causality, introducing a causal framework to highlight the limitations of conventional sequential methods. Leveraging this insight, we propose Causality-Aware Navigation (CAN), which incorporates a Causal Understanding Module to enhance the agent's environmental understanding capability. Empirical evaluations show that our approach consistently outperforms baselines across various tasks and simulation environments. Extensive ablations studies attribute these gains to the Causal Understanding Module, which generalizes effectively in both Reinforcement and Supervised Learning settings without computational overhead.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.15377.pdf", "abstract_url": "https://arxiv.org/abs/2506.15377", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于因果关系的视觉导航方法（CAN），通过引入因果理解模块来增强代理的环境理解能力，从而在各种任务和模拟环境中一致优于基线方法。", "motivation": "视觉导航是体现AI中的核心任务，但现有方法通常同时处理所有历史观察，忽略了数据内部的关联结构，这可能限制了任务性能的进一步提升。", "method": "通过因果关系的视角审视导航任务的独特特性，引入了一个因果框架来突出传统序列方法的局限性，并提出了包含因果理解模块的Causality-Aware Navigation（CAN）。", "result": "实证评估表明，CAN方法在各种任务和模拟环境中一致优于基线方法，广泛的消融研究将这些增益归因于因果理解模块，该模块在强化和监督学习设置中都能有效泛化，且无需计算开销。", "conclusion": "CAN方法通过增强代理的环境理解能力，不仅在性能上优于现有方法，而且在不同的学习设置中展现出良好的泛化能力，为视觉导航任务提供了新的研究方向。"}}
{"id": "2506.15567", "title": "Managing Complex Failure Analysis Workflows with LLM-based Reasoning and Acting Agents", "authors": ["Aline Dobrovsky", "Konstantin Schekotihin", "Christian Burmer"], "abstract": "Failure Analysis (FA) is a highly intricate and knowledge-intensive process. The integration of AI components within the computational infrastructure of FA labs has the potential to automate a variety of tasks, including the detection of non-conformities in images, the retrieval of analogous cases from diverse data sources, and the generation of reports from annotated images. However, as the number of deployed AI models increases, the challenge lies in orchestrating these components into cohesive and efficient workflows that seamlessly integrate with the FA process.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.15567.pdf", "abstract_url": "https://arxiv.org/abs/2506.15567", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了在复杂的故障分析(FA)工作流程中，如何利用基于大型语言模型(LLM)的推理和行动代理来自动化多种任务，并解决随着AI模型数量增加而出现的工作流程协调挑战。", "motivation": "故障分析是一个高度复杂且知识密集的过程。随着FA实验室中AI组件数量的增加，如何将这些组件协调成高效且与FA过程无缝集成的工作流程成为一个主要挑战。", "method": "采用基于大型语言模型(LLM)的推理和行动代理，自动化包括图像中非一致性检测、从多样化数据源检索类似案例以及从注释图像生成报告等任务。", "result": "研究表明，LLM-based代理能够有效管理和协调FA工作流程中的多个AI组件，提高故障分析的效率和效果。", "conclusion": "通过集成LLM-based推理和行动代理，可以显著提升故障分析工作流程的自动化和协调能力，为FA实验室带来更高的效率和更广泛的应用潜力。"}}
{"id": "2506.15624", "title": "The Effect of State Representation on LLM Agent Behavior in Dynamic Routing Games", "authors": ["Lyle Goodyear", "Rachel Guo", "Ramesh Johari"], "abstract": "Large Language Models (LLMs) have shown promise as decision-makers in dynamic settings, but their stateless nature necessitates creating a natural language representation of history. We present a unifying framework for systematically constructing natural language \"state\" representations for prompting LLM agents in repeated multi-agent games. Previous work on games with LLM agents has taken an ad hoc approach to encoding game history, which not only obscures the impact of state representation on agents' behavior, but also limits comparability between studies. Our framework addresses these gaps by characterizing methods of state representation along three axes: action informativeness (i.e., the extent to which the state representation captures actions played); reward informativeness (i.e., the extent to which the state representation describes rewards obtained); and prompting style (or natural language compression, i.e., the extent to which the full text history is summarized).", "subjects": "Artificial Intelligence (cs.AI)", "comments": "27 pages, 20 figures", "pdf_url": "https://arxiv.org/pdf/2506.15624.pdf", "abstract_url": "https://arxiv.org/abs/2506.15624", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一个统一的框架，用于在重复多智能体游戏中系统地构建自然语言“状态”表示，以提示LLM智能体。该框架通过三个维度来表征状态表示方法：动作信息性、奖励信息性和提示风格。", "motivation": "解决LLM智能体在动态环境中作为决策者时，由于其无状态性质需要创建历史自然语言表示的问题，以及之前工作中对游戏历史编码的临时方法导致的行为影响不明确和研究成果可比性受限的问题。", "method": "提出了一个系统框架，通过动作信息性（捕捉已执行动作的程度）、奖励信息性（描述获得奖励的程度）和提示风格（自然语言压缩，即总结完整文本历史的程度）三个维度来构建自然语言状态表示。", "result": "该框架为LLM智能体在重复多智能体游戏中的状态表示提供了一种系统的方法，有助于明确状态表示对智能体行为的影响，并提高研究之间的可比性。", "conclusion": "通过系统化的状态表示框架，可以更有效地利用LLM智能体在动态路由游戏等重复多智能体游戏中的决策能力，为未来的研究提供了新的方向和方法。"}}
{"id": "2506.15672", "title": "SwarmAgentic: Towards Fully Automated Agentic System Generation via Swarm Intelligence", "authors": ["Yao Zhang", "Chenyang Lin", "Shijie Tang", "Haokun Chen", "Shijie Zhou", "Yunpu Ma", "Volker Tresp"], "abstract": "The rapid progress of Large Language Models has advanced agentic systems in decision-making, coordination, and task execution. Yet, existing agentic system generation frameworks lack full autonomy, missing from-scratch agent generation, self-optimizing agent functionality, and collaboration, limiting adaptability and scalability. We propose SwarmAgentic, a framework for fully automated agentic system generation that constructs agentic systems from scratch and jointly optimizes agent functionality and collaboration as interdependent components through language-driven exploration. To enable efficient search over system-level structures, SwarmAgentic maintains a population of candidate systems and evolves them via feedback-guided updates, drawing inspiration from Particle Swarm Optimization (PSO). We evaluate our method on six real-world, open-ended, and exploratory tasks involving high-level planning, system-level coordination, and creative reasoning. Given only a task description and an objective function, SwarmAgentic outperforms all baselines, achieving a +261.8% relative improvement over ADAS on the TravelPlanner benchmark, highlighting the effectiveness of full automation in structurally unconstrained tasks. This framework marks a significant step toward scalable and autonomous agentic system design, bridging swarm intelligence with fully automated system multi-agent generation. Our code is publicly released at", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "41 pages", "pdf_url": "https://arxiv.org/pdf/2506.15672.pdf", "abstract_url": "https://arxiv.org/abs/2506.15672", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "SwarmAgentic是一个通过群体智能实现完全自动化代理系统生成的框架，旨在解决现有代理系统生成框架在自主性、自我优化和协作方面的不足。", "motivation": "现有代理系统生成框架缺乏完全自主性，无法实现从零开始的代理生成、自我优化代理功能及协作，限制了系统的适应性和可扩展性。", "method": "SwarmAgentic框架通过语言驱动的探索，从零开始构建代理系统，并联合优化代理功能和协作作为相互依赖的组件，采用粒子群优化（PSO）的反馈引导更新来高效搜索系统级结构。", "result": "在六个涉及高级规划、系统级协调和创造性推理的真实世界开放性和探索性任务中，SwarmAgentic仅给定任务描述和目标函数，就超越了所有基线，如在TravelPlanner基准测试中相对于ADAS实现了+261.8%的相对改进。", "conclusion": "SwarmAgentic框架在可扩展和自主代理系统设计方面迈出了重要一步，将群体智能与完全自动化的系统多代理生成相结合，标志着代理系统生成技术的一个重要进展。"}}
{"id": "2506.15677", "title": "Embodied Web Agents: Bridging Physical-Digital Realms for Integrated Agent Intelligence", "authors": ["Yining Hong", "Rui Sun", "Bingxuan Li", "Xingcheng Yao", "Maxine Wu", "Alexander Chien", "Da Yin", "Ying Nian Wu", "Zhecan James Wang", "Kai-Wei Chang"], "abstract": "AI agents today are mostly siloed - they either retrieve and reason over vast amount of digital information and knowledge obtained online; or interact with the physical world through embodied perception, planning and action - but rarely both. This separation limits their ability to solve tasks that require integrated physical and digital intelligence, such as cooking from online recipes, navigating with dynamic map data, or interpreting real-world landmarks using web knowledge. We introduce Embodied Web Agents, a novel paradigm for AI agents that fluidly bridge embodiment and web-scale reasoning. To operationalize this concept, we first develop the Embodied Web Agents task environments, a unified simulation platform that tightly integrates realistic 3D indoor and outdoor environments with functional web interfaces. Building upon this platform, we construct and release the Embodied Web Agents Benchmark, which encompasses a diverse suite of tasks including cooking, navigation, shopping, tourism, and geolocation - all requiring coordinated reasoning across physical and digital realms for systematic assessment of cross-domain intelligence. Experimental results reveal significant performance gaps between state-of-the-art AI systems and human capabilities, establishing both challenges and opportunities at the intersection of embodied cognition and web-scale knowledge access. All datasets, codes and websites are publicly available at our project page", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.15677.pdf", "abstract_url": "https://arxiv.org/abs/2506.15677", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Computer Vision and Pattern Recognition (cs.CV)", "Multimedia (cs.MM)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了‘具身网络智能体’这一新范式，旨在解决AI智能体在物理与数字领域间割裂的问题，通过统一的仿真平台和多样化的任务基准，评估和推动跨领域智能的发展。", "motivation": "当前AI智能体大多局限于单一领域，无法有效整合物理世界的交互与数字信息的处理，限制了其在需要跨领域智能的任务中的应用。", "method": "开发了‘具身网络智能体任务环境’，一个集成了真实3D环境和功能性网络接口的统一仿真平台，并在此基础上构建了包含多种任务的基准测试。", "result": "实验结果显示，现有最先进的AI系统与人类能力之间存在显著差距，揭示了在具身认知与网络知识访问交叉领域的挑战与机遇。", "conclusion": "通过‘具身网络智能体’这一新范式，为AI智能体在物理与数字领域的整合提供了新的研究方向和实践平台，所有数据集、代码和网站均已公开。"}}
{"id": "2506.15635", "title": "FindingDory: A Benchmark to Evaluate Memory in Embodied Agents", "authors": ["Karmesh Yadav", "Yusuf Ali", "Gunshi Gupta", "Yarin Gal", "Zsolt Kira"], "abstract": "Large vision-language models have recently demonstrated impressive performance in planning and control tasks, driving interest in their application to real-world robotics. However, deploying these models for reasoning in embodied contexts is limited by their ability to incorporate long-term experience collected across multiple days and represented by vast collections of images. Current VLMs typically struggle to process more than a few hundred images concurrently, highlighting the need for more efficient mechanisms to handle long-term memory in embodied settings. To effectively evaluate these models for long-horizon control, a benchmark must specifically target scenarios where memory is crucial for success. Existing long-video QA benchmarks overlook embodied challenges like object manipulation and navigation, which demand low-level skills and fine-grained reasoning over past interactions. Moreover, effective memory integration in embodied agents involves both recalling relevant historical information and executing actions based on that information, making it essential to study these aspects together rather than in isolation. In this work, we introduce a new benchmark for long-range embodied tasks in the Habitat simulator. This benchmark evaluates memory-based capabilities across 60 tasks requiring sustained engagement and contextual awareness in an environment. The tasks can also be procedurally extended to longer and more challenging versions, enabling scalable evaluation of memory and reasoning. We also present baselines that integrate state-of-the-art VLMs with low level navigation policies, assessing their performance on these memory-intensive tasks and highlight areas for improvement.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2506.15635.pdf", "abstract_url": "https://arxiv.org/abs/2506.15635", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了FindingDory基准测试，旨在评估具身代理中的记忆能力，特别是在需要长期记忆和上下文感知的任务中。", "motivation": "大型视觉语言模型在规划和控制任务中表现出色，但在具身环境中处理长期经验（如多日收集的大量图像）的能力有限，需要更高效的记忆机制。", "method": "在Habitat模拟器中引入了一个新的基准测试，包含60个需要持续参与和上下文感知的任务，这些任务可以程序化扩展到更长和更具挑战性的版本。", "result": "提出了将最先进的视觉语言模型与低级导航策略结合的基线，评估了它们在记忆密集型任务上的表现，并指出了需要改进的领域。", "conclusion": "该基准测试为评估具身代理中的记忆和推理能力提供了可扩展的方法，突出了当前模型在处理长期记忆任务时的局限性。"}}
{"id": "2506.15241", "title": "Research on Graph-Retrieval Augmented Generation Based on Historical Text Knowledge Graphs", "authors": ["Yang Fan", "Zhang Qi", "Xing Wenqian", "Liu Chang", "Liu Liu"], "abstract": "This article addresses domain knowledge gaps in general large language models for historical text analysis in the context of computational humanities and AIGC technology. We propose the Graph RAG framework, combining chain-of-thought prompting, self-instruction generation, and process supervision to create a The First Four Histories character relationship dataset with minimal manual annotation. This dataset supports automated historical knowledge extraction, reducing labor costs. In the graph-augmented generation phase, we introduce a collaborative mechanism between knowledge graphs and retrieval-augmented generation, improving the alignment of general models with historical knowledge. Experiments show that the domain-specific model Xunzi-Qwen1.5-14B, with Simplified Chinese input and chain-of-thought prompting, achieves optimal performance in relation extraction (F1 = 0.68). The DeepSeek model integrated with GraphRAG improves F1 by 11% (0.08-0.19) on the open-domain C-CLUE relation extraction dataset, surpassing the F1 value of Xunzi-Qwen1.5-14B (0.12), effectively alleviating hallucinations phenomenon, and improving interpretability. This framework offers a low-resource solution for classical text knowledge extraction, advancing historical knowledge services and humanities research.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.15241.pdf", "abstract_url": "https://arxiv.org/abs/2506.15241", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出Graph RAG框架，结合思维链提示、自指令生成和过程监督，以最小人工注释创建《前四史》人物关系数据集，支持自动化历史知识提取，降低劳动成本。通过知识图谱与检索增强生成的协作机制，提升通用模型与历史知识的对齐。实验显示，Xunzi-Qwen1.5-14B模型在关系提取上表现最佳（F1 = 0.68），集成GraphRAG的DeepSeek模型在开放域C-CLUE数据集上F1提升11%，有效缓解幻觉现象，提高可解释性。", "motivation": "解决通用大语言模型在计算人文和AIGC技术背景下历史文本分析中的领域知识缺口问题。", "method": "提出Graph RAG框架，结合思维链提示、自指令生成和过程监督，创建历史人物关系数据集，并引入知识图谱与检索增强生成的协作机制。", "result": "Xunzi-Qwen1.5-14B模型在关系提取上达到最佳性能（F1 = 0.68），集成GraphRAG的DeepSeek模型在C-CLUE数据集上F1提升11%，有效缓解幻觉现象。", "conclusion": "该框架为经典文本知识提取提供了低资源解决方案，推动了历史知识服务和人文研究的进步。"}}
{"id": "2506.15246", "title": "TopClustRAG at SIGIR 2025 LiveRAG Challenge", "authors": ["Juli Bakagianni", "John Pavlopoulos", "Aristidis Likas"], "abstract": "We present TopClustRAG, a retrieval-augmented generation (RAG) system developed for the LiveRAG Challenge, which evaluates end-to-end question answering over large-scale web corpora. Our system employs a hybrid retrieval strategy combining sparse and dense indices, followed by K-Means clustering to group semantically similar passages. Representative passages from each cluster are used to construct cluster-specific prompts for a large language model (LLM), generating intermediate answers that are filtered, reranked, and finally synthesized into a single, comprehensive response. This multi-stage pipeline enhances answer diversity, relevance, and faithfulness to retrieved evidence. Evaluated on the FineWeb Sample-10BT dataset, TopClustRAG ranked 2nd in faithfulness and 7th in correctness on the official leaderboard, demonstrating the effectiveness of clustering-based context filtering and prompt aggregation in large-scale RAG systems.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.15246.pdf", "abstract_url": "https://arxiv.org/abs/2506.15246", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "TopClustRAG是一个为LiveRAG挑战开发的检索增强生成系统，结合稀疏和密集索引的混合检索策略，通过K-Means聚类和特定集群提示生成答案，提高了答案的多样性、相关性和忠实度。", "motivation": "解决在大规模网络语料库上进行端到端问答时，如何提高生成答案的多样性、相关性和忠实度的问题。", "method": "采用混合检索策略结合稀疏和密集索引，使用K-Means聚类对语义相似的段落进行分组，然后为每个集群构建特定的提示，生成中间答案，最后通过过滤、重新排名和综合生成全面回答。", "result": "在FineWeb Sample-10BT数据集上评估，TopClustRAG在忠实度排名第2，正确性排名第7，证明了基于聚类的上下文过滤和提示聚合在大规模RAG系统中的有效性。", "conclusion": "TopClustRAG通过聚类和特定集群提示的方法，有效提高了大规模RAG系统中答案的多样性、相关性和忠实度，为未来的研究提供了有价值的参考。"}}
{"id": "2506.15425", "title": "Understanding GUI Agent Localization Biases through Logit Sharpness", "authors": ["Xingjian Tao", "Yiwei Wang", "Yujun Cai", "Zhicheng Yang", "Jing Tang"], "abstract": "Multimodal large language models (MLLMs) have enabled GUI agents to interact with operating systems by grounding language into spatial actions. Despite their promising performance, these models frequently exhibit hallucinations-systematic localization errors that compromise reliability. We propose a fine-grained evaluation framework that categorizes model predictions into four distinct types, revealing nuanced failure modes beyond traditional accuracy metrics. To better quantify model uncertainty, we introduce the Peak Sharpness Score (PSS), a metric that evaluates the alignment between semantic continuity and logits distribution in coordinate prediction. Building on this insight, we further propose Context-Aware Cropping, a training-free technique that improves model performance by adaptively refining input context. Extensive experiments demonstrate that our framework and methods provide actionable insights and enhance the interpretability and robustness of GUI agent behavior.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.15425.pdf", "abstract_url": "https://arxiv.org/abs/2506.15425", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种细粒度的评估框架和新的度量标准Peak Sharpness Score (PSS)，以理解和改善多模态大语言模型(MLLMs)在GUI代理中的定位偏差，并通过Context-Aware Cropping技术提升模型性能。", "motivation": "解决多模态大语言模型(MLLMs)在GUI代理中出现的系统性定位错误（幻觉），这些错误影响了模型的可靠性。", "method": "提出了一个细粒度的评估框架，将模型预测分为四种类型，并引入了Peak Sharpness Score (PSS)来量化模型的不确定性。此外，提出了Context-Aware Cropping技术，这是一种无需训练的方法，通过自适应地细化输入上下文来提升模型性能。", "result": "实验表明，提出的框架和方法不仅提供了可操作的见解，还增强了GUI代理行为的可解释性和鲁棒性。", "conclusion": "通过细粒度的评估和新的度量标准，可以更好地理解和改善MLLMs在GUI代理中的定位偏差，Context-Aware Cropping技术有效提升了模型性能，为GUI代理的可靠性提供了新的解决方案。"}}
{"id": "2506.15451", "title": "AgentGroupChat-V2: Divide-and-Conquer Is What LLM-Based Multi-Agent System Need", "authors": ["Zhouhong Gu", "Xiaoxuan Zhu", "Yin Cai", "Hao Shen", "Xingzhou Chen", "Qingyi Wang", "Jialin Li", "Xiaoran Shi", "Haoran Guo", "Wenxuan Huang", "Hongwei Feng", "Yanghua Xiao", "Zheyu Ye", "Yao Hu", "Shaosheng Cao"], "abstract": "Large language model based multi-agent systems have demonstrated significant potential in social simulation and complex task resolution domains. However, current frameworks face critical challenges in system architecture design, cross-domain generalizability, and performance guarantees, particularly as task complexity and number of agents increases. We introduces AgentGroupChat-V2, a novel framework addressing these challenges through three core innovations: (1) a divide-and-conquer fully parallel architecture that decomposes user queries into hierarchical task forest structures enabling dependency management and distributed concurrent processing. (2) an adaptive collaboration engine that dynamically selects heterogeneous LLM combinations and interaction modes based on task characteristics. (3) agent organization optimization strategies combining divide-and-conquer approaches for efficient problem decomposition. Extensive experiments demonstrate AgentGroupChat-V2's superior performance across diverse domains, achieving 91.50% accuracy on GSM8K (exceeding the best baseline by 5.6 percentage points), 30.4% accuracy on competition-level AIME (nearly doubling other methods), and 79.20% pass@1 on HumanEval. Performance advantages become increasingly pronounced with higher task difficulty, particularly on Level 5 MATH problems where improvements exceed 11 percentage points compared to state-of-the-art baselines. These results confirm that AgentGroupChat-V2 provides a comprehensive solution for building efficient, general-purpose LLM multi-agent systems with significant advantages in complex reasoning scenarios. Code is available at", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.15451.pdf", "abstract_url": "https://arxiv.org/abs/2506.15451", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "AgentGroupChat-V2是一个基于大型语言模型的多智能体系统框架，通过分而治之的全并行架构、自适应协作引擎和智能体组织优化策略，有效解决了系统架构设计、跨领域通用性和性能保证等关键挑战。", "motivation": "当前基于大型语言模型的多智能体系统在系统架构设计、跨领域通用性和性能保证方面面临挑战，特别是在任务复杂性和智能体数量增加时。", "method": "AgentGroupChat-V2采用了三种核心创新：1) 分而治之的全并行架构，将用户查询分解为层次化的任务森林结构；2) 自适应协作引擎，根据任务特性动态选择异构LLM组合和交互模式；3) 结合分而治之方法的智能体组织优化策略。", "result": "在多个领域的广泛实验中，AgentGroupChat-V2表现出卓越的性能，如在GSM8K上达到91.50%的准确率，在AIME上达到30.4%的准确率，在HumanEval上达到79.20%的pass@1。随着任务难度的增加，性能优势更加明显。", "conclusion": "AgentGroupChat-V2为构建高效、通用的LLM多智能体系统提供了全面解决方案，在复杂推理场景中具有显著优势。"}}
{"id": "2506.15569", "title": "SciVer: Evaluating Foundation Models for Multimodal Scientific Claim Verification", "authors": ["Chengye Wang", "Yifei Shen", "Zexi Kuang", "Arman Cohan", "Yilun Zhao"], "abstract": "We introduce SciVer, the first benchmark specifically designed to evaluate the ability of foundation models to verify claims within a multimodal scientific context. SciVer consists of 3,000 expert-annotated examples over 1,113 scientific papers, covering four subsets, each representing a common reasoning type in multimodal scientific claim verification. To enable fine-grained evaluation, each example includes expert-annotated supporting evidence. We assess the performance of 21 state-of-the-art multimodal foundation models, including o4-mini, Gemini-2.5-Flash, Llama-3.2-Vision, and Qwen2.5-VL. Our experiment reveals a substantial performance gap between these models and human experts on SciVer. Through an in-depth analysis of retrieval-augmented generation (RAG), and human-conducted error evaluations, we identify critical limitations in current open-source models, offering key insights to advance models' comprehension and reasoning in multimodal scientific literature tasks.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.15569.pdf", "abstract_url": "https://arxiv.org/abs/2506.15569", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "SciVer是首个专门设计用于评估基础模型在多模态科学背景下验证声明能力的基准。", "motivation": "解决当前基础模型在多模态科学声明验证中的能力评估不足的问题。", "method": "构建了一个包含3,000个专家标注示例的基准，覆盖四种常见的多模态科学声明验证推理类型，并评估了21种最先进的多模态基础模型。", "result": "实验揭示了这些模型与人类专家在SciVer上的显著性能差距，并识别了当前开源模型的关键限制。", "conclusion": "通过深入分析检索增强生成（RAG）和人类进行的错误评估，为提升模型在多模态科学文献任务中的理解和推理能力提供了关键见解。"}}
{"id": "2506.15522", "title": "Lessons from Training Grounded LLMs with Verifiable Rewards", "authors": ["Shang Hong Sim", "Tej Deep Pala", "Vernon Toh", "Hai Leong Chieu", "Amir Zadeh", "Chuan Li", "Navonil Majumder", "Soujanya Poria"], "abstract": "Generating grounded and trustworthy responses remains a key challenge for large language models (LLMs). While retrieval-augmented generation (RAG) with citation-based grounding holds promise, instruction-tuned models frequently fail even in straightforward scenarios: missing explicitly stated answers, citing incorrectly, or refusing when evidence is available. In this work, we explore how reinforcement learning (RL) and internal reasoning can enhance grounding in LLMs. We use the GRPO (Group Relative Policy Optimization) method to train models using verifiable outcome-based rewards targeting answer correctness, citation sufficiency, and refusal quality, without requiring gold reasoning traces or expensive annotations. Through comprehensive experiments across ASQA, QAMPARI, ELI5, and ExpertQA we show that reasoning-augmented models significantly outperform instruction-only variants, especially in handling unanswerable queries and generating well-cited responses. A two-stage training setup, first optimizing answer and citation behavior and then refusal, further improves grounding by stabilizing the learning signal. Additionally, we revisit instruction tuning via GPT-4 distillation and find that combining it with GRPO enhances performance on long-form, generative QA tasks. Overall, our findings highlight the value of reasoning, stage-wise optimization, and outcome-driven RL for building more verifiable and reliable LLMs.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.15522.pdf", "abstract_url": "https://arxiv.org/abs/2506.15522", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文探讨了如何通过强化学习（RL）和内部推理来增强大型语言模型（LLMs）的接地性和可信赖性。使用GRPO方法训练模型，针对答案正确性、引用充分性和拒绝质量进行可验证的结果奖励，无需黄金推理轨迹或昂贵注释。实验表明，推理增强模型在未回答查询和生成良好引用响应方面显著优于仅指令调整的变体。", "motivation": "生成接地且可信赖的响应仍然是大型语言模型（LLMs）面临的关键挑战。尽管基于引用的检索增强生成（RAG）有潜力，但指令调整模型即使在简单场景中也经常失败：错过明确陈述的答案、错误引用或在证据可用时拒绝回答。", "method": "使用GRPO（Group Relative Policy Optimization）方法训练模型，利用可验证的结果奖励针对答案正确性、引用充分性和拒绝质量，无需黄金推理轨迹或昂贵注释。采用两阶段训练设置，首先优化答案和引用行为，然后优化拒绝行为，以稳定学习信号。", "result": "在ASQA、QAMPARI、ELI5和ExpertQA上的综合实验表明，推理增强模型在未回答查询和生成良好引用响应方面显著优于仅指令调整的变体。结合GPT-4蒸馏的指令调整和GRPO进一步提高了长形式生成QA任务的性能。", "conclusion": "研究结果强调了推理、阶段优化和结果驱动的强化学习对于构建更可验证和可靠的大型语言模型的价值。"}}
{"id": "2506.14852", "title": "Cost-Efficient Serving of LLM Agents via Test-Time Plan Caching", "authors": ["Qizheng Zhang", "Michael Wornow", "Kunle Olukotun"], "abstract": "LLM-based agentic applications have shown increasingly remarkable capabilities in complex workflows but incur substantial costs due to extensive planning and reasoning requirements. Existing LLM caching techniques (like context caching and semantic caching), primarily designed for serving chatbots, are insufficient for agentic applications where outputs depend on external data or environmental contexts. We propose agentic plan caching, a novel approach that extracts, stores, adapts, and reuses structured plan templates from planning stages of agentic applications across semantically similar tasks to reduce the cost of serving. Unlike traditional semantic caching, our system extracts plan templates from completed agent executions at test-time, employs keyword extraction to match new requests against cached plans, and utilizes lightweight models to adapt these templates to task-specific plans with contexts. Evaluation across multiple real-world agentic applications shows that our system can reduce costs by 46.62% on average while maintaining performance, offering a more efficient solution for serving LLM-based agents that complements existing LLM serving infrastructures.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Performance (cs.PF)", "comments": "23 pages", "pdf_url": "https://arxiv.org/pdf/2506.14852.pdf", "abstract_url": "https://arxiv.org/abs/2506.14852", "categories": ["Distributed, Parallel, and Cluster Computing (cs.DC)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)", "Performance (cs.PF)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种名为agentic plan caching的新方法，旨在通过提取、存储、适应和重用结构化计划模板来降低基于LLM的代理应用的服务成本。", "motivation": "现有的LLM缓存技术（如上下文缓存和语义缓存）主要为聊天机器人设计，对于依赖外部数据或环境上下文的代理应用来说不足。", "method": "该方法从代理执行的规划阶段提取结构化计划模板，使用关键词提取匹配新请求与缓存计划，并利用轻量级模型将这些模板适应到特定任务的计划中。", "result": "评估显示，该系统平均可降低成本46.62%，同时保持性能。", "conclusion": "agentic plan caching为基于LLM的代理应用提供了一个更高效的解决方案，与现有的LLM服务基础设施互补。"}}
{"id": "2506.15674", "title": "Leaky Thoughts: Large Reasoning Models Are Not Private Thinkers", "authors": ["Tommaso Green", "Martin Gubri", "Haritz Puerto", "Sangdoo Yun", "Seong Joon Oh"], "abstract": "We study privacy leakage in the reasoning traces of large reasoning models used as personal agents. Unlike final outputs, reasoning traces are often assumed to be internal and safe. We challenge this assumption by showing that reasoning traces frequently contain sensitive user data, which can be extracted via prompt injections or accidentally leak into outputs. Through probing and agentic evaluations, we demonstrate that test-time compute approaches, particularly increased reasoning steps, amplify such leakage. While increasing the budget of those test-time compute approaches makes models more cautious in their final answers, it also leads them to reason more verbosely and leak more in their own thinking. This reveals a core tension: reasoning improves utility but enlarges the privacy attack surface. We argue that safety efforts must extend to the model's internal thinking, not just its outputs.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.15674.pdf", "abstract_url": "https://arxiv.org/abs/2506.15674", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Cryptography and Security (cs.CR)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "研究大型推理模型作为个人代理时，其推理轨迹中的隐私泄露问题。挑战了推理轨迹内部安全的假设，展示了敏感用户数据可通过提示注入或意外泄露。", "motivation": "解决大型推理模型在作为个人代理使用时，其推理轨迹中可能泄露敏感用户数据的隐私问题。", "method": "通过探测和代理评估，研究了测试时计算方法，特别是增加的推理步骤，如何放大隐私泄露。", "result": "发现增加测试时计算预算虽然使模型在最终答案上更为谨慎，但也导致其推理更加冗长，从而在思考过程中泄露更多信息。", "conclusion": "揭示了推理提高效用但扩大隐私攻击面的核心矛盾，强调安全努力必须扩展到模型的内部思考，而不仅仅是其输出。"}}
{"id": "2506.14988", "title": "Fair Algorithms with Probing for Multi-Agent Multi-Armed Bandits", "authors": ["Tianyi Xu", "Jiaxin Liu", "Zizhan Zheng"], "abstract": "We propose a multi-agent multi-armed bandit (MA-MAB) framework aimed at ensuring fair outcomes across agents while maximizing overall system performance. A key challenge in this setting is decision-making under limited information about arm rewards. To address this, we introduce a novel probing framework that strategically gathers information about selected arms before allocation. In the offline setting, where reward distributions are known, we leverage submodular properties to design a greedy probing algorithm with a provable performance bound. For the more complex online setting, we develop an algorithm that achieves sublinear regret while maintaining fairness. Extensive experiments on synthetic and real-world datasets show that our approach outperforms baseline methods, achieving better fairness and efficiency.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.14988.pdf", "abstract_url": "https://arxiv.org/abs/2506.14988", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种多智能体多臂老虎机（MA-MAB）框架，旨在确保智能体间的公平结果同时最大化系统整体性能。通过引入新颖的探测框架，在有限信息下战略性地收集选定臂的奖励信息。在离线设置中，利用子模性质设计了具有可证明性能界的贪婪探测算法；在线设置中，开发了一种在保持公平性的同时实现亚线性遗憾的算法。实验表明，该方法在公平性和效率上优于基线方法。", "motivation": "解决多智能体多臂老虎机（MA-MAB）中在有限信息下决策的挑战，确保公平结果同时最大化系统性能。", "method": "引入探测框架战略性地收集信息；离线设置中利用子模性质设计贪婪探测算法；在线设置中开发实现亚线性遗憾的算法。", "result": "在合成和真实数据集上的广泛实验显示，该方法在公平性和效率上优于基线方法。", "conclusion": "提出的MA-MAB框架和算法在保证公平性的同时，有效提高了系统性能，为多智能体决策问题提供了新的解决方案。"}}
{"id": "2506.15167", "title": "LLM Agent for Hyper-Parameter Optimization", "authors": ["Wanzhe Wang", "Jianqiu Peng", "Menghao Hu", "Weihuang Zhong", "Tong Zhang", "Shuai Wang", "Yixin Zhang", "Mingjie Shao", "Wanli Ni"], "abstract": "Hyper-parameters are essential and critical for the performance of communication algorithms. However, current hyper-parameters tuning methods for warm-start particles swarm optimization with cross and mutation (WS-PSO-CM) algortihm for radio map-enabled unmanned aerial vehicle (UAV) trajectory and communication are primarily heuristic-based, exhibiting low levels of automation and unsatisfactory performance. In this paper, we design an large language model (LLM) agent for automatic hyper-parameters-tuning, where an iterative framework and model context protocol (MCP) are applied. In particular, the LLM agent is first setup via a profile, which specifies the mission, background, and output format. Then, the LLM agent is driven by the prompt requirement, and iteratively invokes WS-PSO-CM algorithm for exploration. Finally, the LLM agent autonomously terminates the loop and returns a set of hyper-parameters. Our experiment results show that the minimal sum-rate achieved by hyper-parameters generated via our LLM agent is significantly higher than those by both human heuristics and random generation methods. This indicates that an LLM agent with PSO knowledge and WS-PSO-CM algorithm background is useful in finding high-performance hyper-parameters.", "subjects": "Information Theory (cs.IT); Artificial Intelligence (cs.AI)", "comments": "6 pages, 6 figures", "pdf_url": "https://arxiv.org/pdf/2506.15167.pdf", "abstract_url": "https://arxiv.org/abs/2506.15167", "categories": ["Information Theory (cs.IT)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文设计了一个基于大型语言模型（LLM）的代理，用于自动调整WS-PSO-CM算法的超参数，以提高无人机轨迹和通信的性能。通过迭代框架和模型上下文协议（MCP），LLM代理能够自主探索并终止循环，返回一组高性能的超参数。实验结果表明，与人工启发式和随机生成方法相比，LLM代理生成的超参数能显著提高最小和速率。", "motivation": "当前用于WS-PSO-CM算法的超参数调整方法主要是基于启发式的，自动化水平低且性能不理想。本文旨在解决这一问题，通过设计一个LLM代理来实现超参数的自动调整，以提高通信算法的性能。", "method": "本文采用了一个基于LLM的代理，通过设置代理的配置文件（包括任务、背景和输出格式），并在提示要求的驱动下，迭代调用WS-PSO-CM算法进行探索，最终自主终止循环并返回一组超参数。", "result": "实验结果显示，与人工启发式和随机生成方法相比，LLM代理生成的超参数能显著提高最小和速率，表明具有PSO知识和WS-PSO-CM算法背景的LLM代理在寻找高性能超参数方面非常有用。", "conclusion": "本文提出的LLM代理方法在超参数优化方面表现出色，不仅提高了自动化水平，还显著提升了通信算法的性能，为未来的研究提供了新的方向。"}}
{"id": "2506.15253", "title": "RAS-Eval: A Comprehensive Benchmark for Security Evaluation of LLM Agents in Real-World Environments", "authors": ["Yuchuan Fu", "Xiaohan Yuan", "Dongxia Wang"], "abstract": "The rapid deployment of Large language model (LLM) agents in critical domains like healthcare and finance necessitates robust security frameworks. To address the absence of standardized evaluation benchmarks for these agents in dynamic environments, we introduce RAS-Eval, a comprehensive security benchmark supporting both simulated and real-world tool execution. RAS-Eval comprises 80 test cases and 3,802 attack tasks mapped to 11 Common Weakness Enumeration (CWE) categories, with tools implemented in JSON, LangGraph, and Model Context Protocol (MCP) formats. We evaluate 6 state-of-the-art LLMs across diverse scenarios, revealing significant vulnerabilities: attacks reduced agent task completion rates (TCR) by 36.78% on average and achieved an 85.65% success rate in academic settings. Notably, scaling laws held for security capabilities, with larger models outperforming smaller counterparts. Our findings expose critical risks in real-world agent deployments and provide a foundational framework for future security research. Code and data are available at", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": "12 pages, 8 figures", "pdf_url": "https://arxiv.org/pdf/2506.15253.pdf", "abstract_url": "https://arxiv.org/abs/2506.15253", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了RAS-Eval，一个全面的安全基准测试，用于评估在动态环境中部署的大型语言模型（LLM）代理的安全性。", "motivation": "随着大型语言模型（LLM）代理在医疗和金融等关键领域的快速部署，缺乏标准化评估基准来评估这些代理在动态环境中的安全性成为了一个问题。", "method": "RAS-Eval包括80个测试用例和3,802个攻击任务，覆盖11个常见弱点枚举（CWE）类别，工具以JSON、LangGraph和模型上下文协议（MCP）格式实现。评估了6种最先进的LLM在不同场景下的表现。", "result": "攻击平均降低了代理任务完成率（TCR）36.78%，在学术环境中成功率达到85.65%。较大的模型在安全能力上表现优于较小的模型。", "conclusion": "研究结果揭示了现实世界代理部署中的关键风险，并为未来的安全研究提供了基础框架。"}}
{"id": "2506.15421", "title": "Reward Models in Deep Reinforcement Learning: A Survey", "authors": ["Rui Yu", "Shenghua Wan", "Yucen Wang", "Chen-Xiao Gao", "Le Gan", "Zongzhang Zhang", "De-Chuan Zhan"], "abstract": "In reinforcement learning (RL), agents continually interact with the environment and use the feedback to refine their behavior. To guide policy optimization, reward models are introduced as proxies of the desired objectives, such that when the agent maximizes the accumulated reward, it also fulfills the task designer's intentions. Recently, significant attention from both academic and industrial researchers has focused on developing reward models that not only align closely with the true objectives but also facilitate policy optimization. In this survey, we provide a comprehensive review of reward modeling techniques within the deep RL literature. We begin by outlining the background and preliminaries in reward modeling. Next, we present an overview of recent reward modeling approaches, categorizing them based on the source, the mechanism, and the learning paradigm. Building on this understanding, we discuss various applications of these reward modeling techniques and review methods for evaluating reward models. Finally, we conclude by highlighting promising research directions in reward modeling. Altogether, this survey includes both established and emerging methods, filling the vacancy of a systematic review of reward models in current literature.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "IJCAI 2025 Survey Track (To Appear)", "pdf_url": "https://arxiv.org/pdf/2506.15421.pdf", "abstract_url": "https://arxiv.org/abs/2506.15421", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文综述了深度强化学习中的奖励模型技术，包括背景、最新方法分类、应用及评估方法，并指出了未来研究方向。", "motivation": "解决深度强化学习中奖励模型与真实目标对齐及促进策略优化的问题。", "method": "通过文献综述，分类介绍了基于来源、机制和学习范式的奖励建模方法。", "result": "综述了现有及新兴的奖励建模技术，填补了当前文献中系统综述的空白。", "conclusion": "奖励建模技术在深度强化学习中具有重要应用价值，未来研究需进一步探索其潜力。"}}
{"id": "2506.15468", "title": "Co-Creative Learning via Metropolis-Hastings Interaction between Humans and AI", "authors": ["Ryota Okumura", "Tadahiro Taniguchi", "Akira Taniguchi", "Yoshinobu Hagiwara"], "abstract": "We propose co-creative learning as a novel paradigm where humans and AI, i.e., biological and artificial agents, mutually integrate their partial perceptual information and knowledge to construct shared external representations, a process we interpret as symbol emergence. Unlike traditional AI teaching based on unilateral knowledge transfer, this addresses the challenge of integrating information from inherently different modalities. We empirically test this framework using a human-AI interaction model based on the Metropolis-Hastings naming game (MHNG), a decentralized Bayesian inference mechanism. In an online experiment, 69 participants played a joint attention naming game (JA-NG) with one of three computer agent types (MH-based, always-accept, or always-reject) under partial observability. Results show that human-AI pairs with an MH-based agent significantly improved categorization accuracy through interaction and achieved stronger convergence toward a shared sign system. Furthermore, human acceptance behavior aligned closely with the MH-derived acceptance probability. These findings provide the first empirical evidence for co-creative learning emerging in human-AI dyads via MHNG-based interaction. This suggests a promising path toward symbiotic AI systems that learn with humans, rather than from them, by dynamically aligning perceptual experiences, opening a new venue for symbiotic AI alignment.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.15468.pdf", "abstract_url": "https://arxiv.org/abs/2506.15468", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为‘共同创造学习’的新范式，通过Metropolis-Hastings命名游戏（MHNG）实现人类与AI之间的互动，旨在通过整合双方的部分感知信息和知识来构建共享的外部表示。", "motivation": "解决传统AI教学中单向知识传递无法整合来自不同模态信息的挑战，探索人类与AI如何通过互动共同学习和构建共享符号系统。", "method": "使用基于Metropolis-Hastings命名游戏（MHNG）的人类-AI互动模型进行实证测试，通过在线实验比较三种不同类型的计算机代理（基于MH的、总是接受或总是拒绝）在部分可观察性下的表现。", "result": "实验结果显示，与基于MH的代理配对的人类-AI组合通过互动显著提高了分类准确性，并更强烈地趋向于共享符号系统。此外，人类的接受行为与MH衍生的接受概率高度一致。", "conclusion": "这些发现首次提供了通过MHNG互动在人类-AI对中涌现共同创造学习的实证证据，为开发能够与人类共同学习而非仅从人类学习的共生AI系统开辟了新途径。"}}
{"id": "2506.15513", "title": "RePCS: Diagnosing Data Memorization in LLM-Powered Retrieval-Augmented Generation", "authors": ["Le Vu Anh", "Nguyen Viet Anh", "Mehmet Dik", "Luong Van Nghia"], "abstract": "Retrieval-augmented generation (RAG) has become a common strategy for updating large language model (LLM) responses with current, external information. However, models may still rely on memorized training data, bypass the retrieved evidence, and produce contaminated outputs. We introduce Retrieval-Path Contamination Scoring (RePCS), a diagnostic method that detects such behavior without requiring model access or retraining. RePCS compares two inference paths: (i) a parametric path using only the query, and (ii) a retrieval-augmented path using both the query and retrieved context by computing the Kullback-Leibler (KL) divergence between their output distributions. A low divergence suggests that the retrieved context had minimal impact, indicating potential memorization. This procedure is model-agnostic, requires no gradient or internal state access, and adds only a single additional forward pass. We further derive PAC-style guarantees that link the KL threshold to user-defined false positive and false negative rates. On the Prompt-WNQA benchmark, RePCS achieves a ROC-AUC of 0.918. This result outperforms the strongest prior method by 6.5 percentage points while keeping latency overhead below 4.7% on an NVIDIA T4 GPU. RePCS offers a lightweight, black-box safeguard to verify whether a RAG system meaningfully leverages retrieval, making it especially valuable in safety-critical applications.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "11 pages, 7 figures, 5 tables", "pdf_url": "https://arxiv.org/pdf/2506.15513.pdf", "abstract_url": "https://arxiv.org/abs/2506.15513", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了RePCS，一种诊断大型语言模型（LLM）驱动的检索增强生成（RAG）中数据记忆化的方法。RePCS通过比较两种推理路径的KL散度来检测模型是否依赖记忆数据而非检索证据，无需模型访问或重新训练。", "motivation": "解决检索增强生成（RAG）中模型可能依赖记忆数据而非检索证据，导致输出污染的问题。", "method": "提出检索路径污染评分（RePCS），通过计算仅使用查询的参数路径和使用查询及检索上下文的检索增强路径之间的KL散度来诊断数据记忆化。", "result": "在Prompt-WNQA基准测试中，RePCS的ROC-AUC达到0.918，比之前最强方法提高了6.5个百分点，延迟开销低于4.7%。", "conclusion": "RePCS提供了一种轻量级、黑盒保护措施，验证RAG系统是否有效利用检索，特别适用于安全关键应用。"}}
{"id": "2506.15543", "title": "Learning Algorithms in the Limit", "authors": ["Hristo Papazov", "Nicolas Flammarion"], "abstract": "This paper studies the problem of learning computable functions in the limit by extending Gold's inductive inference framework to incorporate \\textit{computational observations} and \\textit{restricted input sources}. Complimentary to the traditional Input-Output Observations, we introduce Time-Bound Observations, and Policy-Trajectory Observations to study the learnability of general recursive functions under more realistic constraints. While input-output observations do not suffice for learning the class of general recursive functions in the limit, we overcome this learning barrier by imposing computational complexity constraints or supplementing with approximate time-bound observations. Further, we build a formal framework around observations of \\textit{computational agents} and show that learning computable functions from policy trajectories reduces to learning rational functions from input and output, thereby revealing interesting connections to finite-state transducer inference. On the negative side, we show that computable or polynomial-mass characteristic sets cannot exist for the class of linear-time computable functions even for policy-trajectory observations.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Data Structures and Algorithms (cs.DS); Formal Languages and Automata Theory (cs.FL)", "comments": "Accepted at COLT 2025. This version matches the proceedings version", "pdf_url": "https://arxiv.org/pdf/2506.15543.pdf", "abstract_url": "https://arxiv.org/abs/2506.15543", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Data Structures and Algorithms (cs.DS)", "Formal Languages and Automata Theory (cs.FL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过扩展Gold的归纳推理框架，引入计算观察和受限输入源，研究在极限下学习可计算函数的问题。通过时间限制观察和策略轨迹观察，探讨在更现实约束下一般递归函数的可学习性。", "motivation": "解决在传统输入输出观察不足以学习一般递归函数的问题，通过引入计算复杂性约束或近似时间限制观察来克服学习障碍。", "method": "扩展Gold的归纳推理框架，引入时间限制观察和策略轨迹观察，构建围绕计算代理观察的正式框架。", "result": "发现通过策略轨迹学习可计算函数可简化为从输入和输出学习有理函数，揭示了与有限状态转换器推断的有趣联系。同时证明，对于线性时间可计算函数，即使有策略轨迹观察，也不存在可计算或多项式质量的特征集。", "conclusion": "通过引入新的观察类型和框架，本研究为在极限下学习可计算函数提供了新的视角和方法，同时也揭示了某些函数类学习的固有局限性。"}}
