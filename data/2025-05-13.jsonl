{"id": "2505.06416", "title": "ScaleMCP: Dynamic and Auto-Synchronizing Model Context Protocol Tools for LLM Agents", "authors": ["Elias Lumer", "Anmol Gulati", "Vamse Kumar Subbiah", "Pradeep Honaganahalli Basavaraju", "James A. Burke"], "abstract": "Recent advancements in Large Language Models (LLMs) and the introduction of the Model Context Protocol (MCP) have significantly expanded LLM agents' capability to interact dynamically with external tools and APIs. However, existing tool selection frameworks do not integrate MCP servers, instead relying heavily on error-prone manual updates to monolithic local tool repositories, leading to duplication, inconsistencies, and inefficiencies. Additionally, current approaches abstract tool selection before the LLM agent is invoked, limiting its autonomy and hindering dynamic re-querying capabilities during multi-turn interactions. To address these issues, we introduce ScaleMCP, a novel tool selection approach that dynamically equips LLM agents with a MCP tool retriever, giving agents the autonomy to add tools into their memory, as well as an auto-synchronizing tool storage system pipeline through CRUD (create, read, update, delete) operations with MCP servers as the single source of truth. We also propose a novel embedding strategy, Tool Document Weighted Average (TDWA), designed to selectively emphasize critical components of tool documents (e.g. tool name or synthetic questions) during the embedding process. Comprehensive evaluations conducted on a created dataset of 5,000 financial metric MCP servers, across 10 LLM models, 5 embedding models, and 5 retriever types, demonstrate substantial improvements in tool retrieval and agent invocation performance, emphasizing ScaleMCP's effectiveness in scalable, dynamic tool selection and invocation.", "subjects": "Computation and Language (cs.CL)", "comments": "17 pages", "pdf_url": "https://arxiv.org/pdf/2505.06416.pdf", "abstract_url": "https://arxiv.org/abs/2505.06416", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2505.06569", "title": "MacRAG: Compress, Slice, and Scale-up for Multi-Scale Adaptive Context RAG", "authors": ["Woosang Lim", "Zekun Li", "Gyuwan Kim", "Sungyoung Ji", "HyeonJung Kim", "Kyuri Choi", "Jin Hyuk Lim", "Kyungpyo Park", "William Yang Wang"], "abstract": "Long-context (LC) Large Language Models (LLMs) combined with Retrieval-Augmented Generation (RAG) hold strong potential for complex multi-hop and large-document tasks. However, existing RAG systems often suffer from imprecise retrieval, incomplete context coverage under constrained context windows, and fragmented information caused by suboptimal context construction. We introduce Multi-scale Adaptive Context RAG (MacRAG), a hierarchical retrieval framework that compresses and partitions documents into coarse-to-fine granularities, then adaptively merges relevant contexts through chunk- and document-level expansions in real time. By starting from the finest-level retrieval and progressively incorporating higher-level and broader context, MacRAG constructs effective query-specific long contexts, optimizing both precision and coverage. Evaluations on the challenging LongBench expansions of HotpotQA, 2WikiMultihopQA, and Musique confirm that MacRAG consistently surpasses baseline RAG pipelines on single- and multi-step generation with Llama-3.1-8B, Gemini-1.5-pro, and GPT-4o. Our results establish MacRAG as an efficient, scalable solution for real-world long-context, multi-hop reasoning. Our code is available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.06569.pdf", "abstract_url": "https://arxiv.org/abs/2505.06569", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"]}
{"id": "2505.06328", "title": "A Grounded Memory System For Smart Personal Assistants", "authors": ["Felix Ocker", "Jörg Deigmöller", "Pavel Smirnov", "Julian Eggert"], "abstract": "A wide variety of agentic AI applications - ranging from cognitive assistants for dementia patients to robotics - demand a robust memory system grounded in reality. In this paper, we propose such a memory system consisting of three components. First, we combine Vision Language Models for image captioning and entity disambiguation with Large Language Models for consistent information extraction during perception. Second, the extracted information is represented in a memory consisting of a knowledge graph enhanced by vector embeddings to efficiently manage relational information. Third, we combine semantic search and graph query generation for question answering via Retrieval Augmented Generation. We illustrate the system's working and potential using a real-world example.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "8 pages, 5 figures, accepted for the ESWC 2025 TEXT2KG workshop", "pdf_url": "https://arxiv.org/pdf/2505.06328.pdf", "abstract_url": "https://arxiv.org/abs/2505.06328", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"]}
{"id": "2505.06438", "title": "Reliable Collaborative Conversational Agent System Based on LLMs and Answer Set Programming", "authors": ["Yankai Zeng", "Gopal Gupta"], "abstract": "As the Large-Language-Model-driven (LLM-driven) Artificial Intelligence (AI) bots became popular, people realized their strong potential in Task-Oriented Dialogue (TOD). However, bots relying wholly on LLMs are unreliable in their knowledge, and whether they can finally produce a correct result for the task is not guaranteed. The collaboration among these agents also remains a challenge, since the necessary information to convey is unclear, and the information transfer is by prompts -- unreliable, and malicious knowledge is easy to inject. With the help of logic programming tools such as Answer Set Programming (ASP), conversational agents can be built safely and reliably, and communication among the agents made more efficient and secure. We proposed an Administrator-Assistant Dual-Agent paradigm, where the two ASP-driven bots share the same knowledge base and complete their tasks independently, while the information can be passed by a Collaborative Rule Set (CRS). The knowledge and information conveyed are encapsulated and invisible to the users, ensuring the security of information transmission. We have constructed AutoManager, a dual-agent system for managing the drive-through window of a fast-food restaurant such as Taco Bell in the US. In AutoManager, the assistant bot takes the customer's order while the administrator bot manages the menu and food supply. We evaluated our AutoManager and compared it with the real-world Taco Bell Drive-Thru AI Order Taker, and the results show that our method is more reliable.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "14 pages", "pdf_url": "https://arxiv.org/pdf/2505.06438.pdf", "abstract_url": "https://arxiv.org/abs/2505.06438", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.06492", "title": "SmartPilot: A Multiagent CoPilot for Adaptive and Intelligent Manufacturing", "authors": ["Chathurangi Shyalika", "Renjith Prasad", "Alaa Al Ghazo", "Darssan Eswaramoorthi", "Harleen Kaur", "Sara Shree Muthuselvam", "Amit Sheth"], "abstract": "In the dynamic landscape of Industry 4.0, achieving efficiency, precision, and adaptability is essential to optimize manufacturing operations. Industries suffer due to supply chain disruptions caused by anomalies, which are being detected by current AI models but leaving domain experts uncertain without deeper insights into these anomalies. Additionally, operational inefficiencies persist due to inaccurate production forecasts and the limited effectiveness of traditional AI models for processing complex sensor data. Despite these advancements, existing systems lack the seamless integration of these capabilities needed to create a truly unified solution for enhancing production and decision-making. We propose SmartPilot, a neurosymbolic, multiagent CoPilot designed for advanced reasoning and contextual decision-making to address these challenges. SmartPilot processes multimodal sensor data and is compact to deploy on edge devices. It focuses on three key tasks: anomaly prediction, production forecasting, and domain-specific question answering. By bridging the gap between AI capabilities and real-world industrial needs, SmartPilot empowers industries with intelligent decision-making and drives transformative innovation in manufacturing. The demonstration video, datasets, and supplementary materials are available at", "subjects": "Artificial Intelligence (cs.AI)", "comments": "8 pages, 8 figures, 4 tables, IEEE Conference on Artificial Intelligence (IEEE CAI) 2025", "pdf_url": "https://arxiv.org/pdf/2505.06492.pdf", "abstract_url": "https://arxiv.org/abs/2505.06492", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.06505", "title": "On Definite Iterated Belief Revision with Belief Algebras", "authors": ["Hua Meng", "Zhiguo Long", "Michael Sioutis", "Zhengchun Zhou"], "abstract": "Traditional logic-based belief revision research focuses on designing rules to constrain the behavior of revision operators. Frameworks have been proposed to characterize iterated revision rules, but they are often too loose, leading to multiple revision operators that all satisfy the rules under the same belief condition. In many practical applications, such as safety critical ones, it is important to specify a definite revision operator to enable agents to iteratively revise their beliefs in a deterministic way. In this paper, we propose a novel framework for iterated belief revision by characterizing belief information through preference relations. Semantically, both beliefs and new evidence are represented as belief algebras, which provide a rich and expressive foundation for belief revision. Building on traditional revision rules, we introduce additional postulates for revision with belief algebra, including an upper-bound constraint on the outcomes of revision. We prove that the revision result is uniquely determined given the current belief state and new evidence. Furthermore, to make the framework more useful in practice, we develop a particular algorithm for performing the proposed revision process. We argue that this approach may offer a more predictable and principled method for belief revision, making it suitable for real-world applications.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "10 pages. Extended version of an accepted IJCAI 2025 paper", "pdf_url": "https://arxiv.org/pdf/2505.06505.pdf", "abstract_url": "https://arxiv.org/abs/2505.06505", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.06518", "title": "A Point-Based Algorithm for Distributional Reinforcement Learning in Partially Observable Domains", "authors": ["Larry Preuett III"], "abstract": "In many real-world planning tasks, agents must tackle uncertainty about the environment's state and variability in the outcomes of any chosen policy. We address both forms of uncertainty as a first step toward safer algorithms in partially observable settings. Specifically, we extend Distributional Reinforcement Learning (DistRL)-which models the entire return distribution for fully observable domains-to Partially Observable Markov Decision Processes (POMDPs), allowing an agent to learn the distribution of returns for each conditional plan. Concretely, we introduce new distributional Bellman operators for partial observability and prove their convergence under the supremum p-Wasserstein metric. We also propose a finite representation of these return distributions via psi-vectors, generalizing the classical alpha-vectors in POMDP solvers. Building on this, we develop Distributional Point-Based Value Iteration (DPBVI), which integrates psi-vectors into a standard point-based backup procedure-bridging DistRL and POMDP planning. By tracking return distributions, DPBVI naturally enables risk-sensitive control in domains where rare, high-impact events must be carefully managed. We provide source code to foster further research in robust decision-making under partial observability.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.06518.pdf", "abstract_url": "https://arxiv.org/abs/2505.06518", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.06706", "title": "Bi-level Mean Field: Dynamic Grouping for Large-Scale MARL", "authors": ["Yuxuan Zheng", "Yihe Zhou", "Feiyang Xu", "Mingli Song", "Shunyu Liu"], "abstract": "Large-scale Multi-Agent Reinforcement Learning (MARL) often suffers from the curse of dimensionality, as the exponential growth in agent interactions significantly increases computational complexity and impedes learning efficiency. To mitigate this, existing efforts that rely on Mean Field (MF) simplify the interaction landscape by approximating neighboring agents as a single mean agent, thus reducing overall complexity to pairwise interactions. However, these MF methods inevitably fail to account for individual differences, leading to aggregation noise caused by inaccurate iterative updates during MF learning. In this paper, we propose a Bi-level Mean Field (BMF) method to capture agent diversity with dynamic grouping in large-scale MARL, which can alleviate aggregation noise via bi-level interaction. Specifically, BMF introduces a dynamic group assignment module, which employs a Variational AutoEncoder (VAE) to learn the representations of agents, facilitating their dynamic grouping over time. Furthermore, we propose a bi-level interaction module to model both inter- and intra-group interactions for effective neighboring aggregation. Experiments across various tasks demonstrate that the proposed BMF yields results superior to the state-of-the-art methods. Our code will be made publicly available.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.06706.pdf", "abstract_url": "https://arxiv.org/abs/2505.06706", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.07062", "title": "Seed1.5-VL Technical Report", "authors": ["Dong Guo", "Faming Wu", "Feida Zhu", "Fuxing Leng", "Guang Shi", "Haobin Chen", "Haoqi Fan", "Jian Wang", "Jianyu Jiang", "Jiawei Wang", "Jingji Chen", "Jingjia Huang", "Kang Lei", "Liping Yuan", "Lishu Luo", "Pengfei Liu", "Qinghao Ye", "Rui Qian", "Shen Yan", "Shixiong Zhao", "Shuai Peng", "Shuangye Li", "Sihang Yuan", "Sijin Wu", "Tianheng Cheng", "Weiwei Liu", "Wenqian Wang", "Xianhan Zeng", "Xiao Liu", "Xiaobo Qin", "Xiaohan Ding", "Xiaojun Xiao", "Xiaoying Zhang", "Xuanwei Zhang", "Xuehan Xiong", "Yanghua Peng", "Yangrui Chen", "Yanwei Li", "Yanxu Hu", "Yi Lin", "Yiyuan Hu", "Yiyuan Zhang", "Youbin Wu", "Yu Li", "Yudong Liu", "Yue Ling", "Yujia Qin", "Zanbo Wang", "Zhiwu He", "Aoxue Zhang", "Bairen Yi", "Bencheng Liao", "Can Huang", "Can Zhang", "Chaorui Deng", "Chaoyi Deng", "Cheng Lin", "Cheng Yuan", "Chenggang Li", "Chenhui Gou", "Chenwei Lou", "Chengzhi Wei", "Chundian Liu", "Chunyuan Li", "Deyao Zhu", "Donghong Zhong", "Feng Li", "Feng Zhang", "Gang Wu", "Guodong Li", "Guohong Xiao", "Haibin Lin", "Haihua Yang", "Haoming Wang", "Heng Ji", "Hongxiang Hao", "Hui Shen", "Huixia Li", "Jiahao Li", "Jialong Wu", "Jianhua Zhu", "Jianpeng Jiao", "Jiashi Feng", "Jiaze Chen", "Jianhui Duan", "Jihao Liu", "Jin Zeng", "Jingqun Tang", "Jingyu Sun", "Joya Chen", "Jun Long", "Junda Feng", "Junfeng Zhan", "Junjie Fang", "Junting Lu", "Kai Hua", "Kai Liu", "Kai Shen", "Kaiyuan Zhang", "Ke Shen"], "abstract": "We present Seed1.5-VL, a vision-language foundation model designed to advance general-purpose multimodal understanding and reasoning. Seed1.5-VL is composed with a 532M-parameter vision encoder and a Mixture-of-Experts (MoE) LLM of 20B active parameters. Despite its relatively compact architecture, it delivers strong performance across a wide spectrum of public VLM benchmarks and internal evaluation suites, achieving the state-of-the-art performance on 38 out of 60 public benchmarks. Moreover, in agent-centric tasks such as GUI control and gameplay, Seed1.5-VL outperforms leading multimodal systems, including OpenAI CUA and Claude 3.7. Beyond visual and video understanding, it also demonstrates strong reasoning abilities, making it particularly effective for multimodal reasoning challenges such as visual puzzles. We believe these capabilities will empower broader applications across diverse tasks. In this report, we mainly provide a comprehensive review of our experiences in building Seed1.5-VL across model design, data construction, and training at various stages, hoping that this report can inspire further research. Seed1.5-VL is now accessible at", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.07062.pdf", "abstract_url": "https://arxiv.org/abs/2505.07062", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.06904", "title": "EcoLANG: Efficient and Effective Agent Communication Language Induction for Social Simulation", "authors": ["Xinyi Mou", "Chen Qian", "Wei Liu", "Xuanjing Huang", "Zhongyu Wei"], "abstract": "Large language models (LLMs) have demonstrated an impressive ability to role-play humans and replicate complex social dynamics. While large-scale social simulations are gaining increasing attention, they still face significant challenges, particularly regarding high time and computation costs. Existing solutions, such as distributed mechanisms or hybrid agent-based model (ABM) integrations, either fail to address inference costs or compromise accuracy and generalizability. To this end, we propose EcoLANG: Efficient and Effective Agent Communication Language Induction for Social Simulation. EcoLANG operates in two stages: (1) language evolution, where we filter synonymous words and optimize sentence-level rules through natural selection, and (2) language utilization, where agents in social simulations communicate using the evolved language. Experimental results demonstrate that EcoLANG reduces token consumption by over 20%, enhancing efficiency without sacrificing simulation accuracy.", "subjects": "Computation and Language (cs.CL); Computers and Society (cs.CY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.06904.pdf", "abstract_url": "https://arxiv.org/abs/2505.06904", "categories": ["Computation and Language (cs.CL)", "Computers and Society (cs.CY)"], "matching_keywords": ["agent"]}
{"id": "2505.06914", "title": "The Distracting Effect: Understanding Irrelevant Passages in RAG", "authors": ["Chen Amiraz", "Florin Cuconasu", "Simone Filice", "Zohar Karnin"], "abstract": "A well-known issue with Retrieval Augmented Generation (RAG) is that retrieved passages that are irrelevant to the query sometimes distract the answer-generating LLM, causing it to provide an incorrect response. In this paper, we shed light on this core issue and formulate the distracting effect of a passage w.r.t. a query (and an LLM). We provide a quantifiable measure of the distracting effect of a passage and demonstrate its robustness across LLMs.", "subjects": "Computation and Language (cs.CL); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.06914.pdf", "abstract_url": "https://arxiv.org/abs/2505.06914", "categories": ["Computation and Language (cs.CL)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"]}
{"id": "2505.07161", "title": "Towards Actionable Pedagogical Feedback: A Multi-Perspective Analysis of Mathematics Teaching and Tutoring Dialogue", "authors": ["Jannatun Naim", "Jie Cao", "Fareen Tasneem", "Jennifer Jacobs", "Brent Milne", "James Martin", "Tamara Sumner"], "abstract": "Effective feedback is essential for refining instructional practices in mathematics education, and researchers often turn to advanced natural language processing (NLP) models to analyze classroom dialogues from multiple perspectives. However, utterance-level discourse analysis encounters two primary challenges: (1) multifunctionality, where a single utterance may serve multiple purposes that a single tag cannot capture, and (2) the exclusion of many utterances from domain-specific discourse move classifications, leading to their omission in feedback. To address these challenges, we proposed a multi-perspective discourse analysis that integrates domain-specific talk moves with dialogue act (using the flattened multi-functional SWBD-MASL schema with 43 tags) and discourse relation (applying Segmented Discourse Representation Theory with 16 relations). Our top-down analysis framework enables a comprehensive understanding of utterances that contain talk moves, as well as utterances that do not contain talk moves. This is applied to two mathematics education datasets: TalkMoves (teaching) and SAGA22 (tutoring). Through distributional unigram analysis, sequential talk move analysis, and multi-view deep dive, we discovered meaningful discourse patterns, and revealed the vital role of utterances without talk moves, demonstrating that these utterances, far from being mere fillers, serve crucial functions in guiding, acknowledging, and structuring classroom discourse. These insights underscore the importance of incorporating discourse relations and dialogue acts into AI-assisted education systems to enhance feedback and create more responsive learning environments. Our framework may prove helpful for providing human educator feedback, but also aiding in the development of AI agents that can effectively emulate the roles of both educators and students.", "subjects": "Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)", "comments": "Accepted to EDM'2025", "pdf_url": "https://arxiv.org/pdf/2505.07161.pdf", "abstract_url": "https://arxiv.org/abs/2505.07161", "categories": ["Computation and Language (cs.CL)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"]}
{"id": "2505.07184", "title": "Structural Entropy Guided Agent for Detecting and Repairing Knowledge Deficiencies in LLMs", "authors": ["Yifan Wei", "Xiaoyan Yu", "Tengfei Pan", "Angsheng Li", "Li Du"], "abstract": "Large language models (LLMs) have achieved unprecedented performance by leveraging vast pretraining corpora, yet their performance remains suboptimal in knowledge-intensive domains such as medicine and scientific research, where high factual precision is required. While synthetic data provides a promising avenue for augmenting domain knowledge, existing methods frequently generate redundant samples that do not align with the model's true knowledge gaps. To overcome this limitation, we propose a novel Structural Entropy-guided Knowledge Navigator (SENATOR) framework that addresses the intrinsic knowledge deficiencies of LLMs. Our approach employs the Structure Entropy (SE) metric to quantify uncertainty along knowledge graph paths and leverages Monte Carlo Tree Search (MCTS) to selectively explore regions where the model lacks domain-specific knowledge. Guided by these insights, the framework generates targeted synthetic data for supervised fine-tuning, enabling continuous self-improvement. Experimental results on LLaMA-3 and Qwen2 across multiple domain-specific benchmarks show that SENATOR effectively detects and repairs knowledge deficiencies, achieving notable performance improvements. The code and data for our methods and experiments are available at", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.07184.pdf", "abstract_url": "https://arxiv.org/abs/2505.07184", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2505.06817", "title": "Control Plane as a Tool: A Scalable Design Pattern for Agentic AI Systems", "authors": ["Sivasathivel Kandasamy"], "abstract": "Agentic AI systems represent a new frontier in artificial intelligence, where agents often based on large language models(LLMs) interact with tools, environments, and other agents to accomplish tasks with a degree of autonomy. These systems show promise across a range of domains, but their architectural underpinnings remain immature. This paper conducts a comprehensive review of the types of agents, their modes of interaction with the environment, and the infrastructural and architectural challenges that emerge. We identify a gap in how these systems manage tool orchestration at scale and propose a reusable design abstraction: the \"Control Plane as a Tool\" pattern. This pattern allows developers to expose a single tool interface to an agent while encapsulating modular tool routing logic behind it. We position this pattern within the broader context of agent design and argue that it addresses several key challenges in scaling, safety, and extensibility.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "2 Figures and 2 Tables", "pdf_url": "https://arxiv.org/pdf/2505.06817.pdf", "abstract_url": "https://arxiv.org/abs/2505.06817", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"]}
{"id": "2505.06907", "title": "Towards Artificial General or Personalized Intelligence? A Survey on Foundation Models for Personalized Federated Intelligence", "authors": ["Yu Qiao", "Huy Q. Le", "Avi Deb Raha", "Phuong-Nam Tran", "Apurba Adhikary", "Mengchun Zhang", "Loc X. Nguyen", "Eui-Nam Huh", "Dusit Niyato", "Choong Seon Hong"], "abstract": "The rise of large language models (LLMs), such as ChatGPT, DeepSeek, and Grok-3, has reshaped the artificial intelligence landscape. As prominent examples of foundational models (FMs) built on LLMs, these models exhibit remarkable capabilities in generating human-like content, bringing us closer to achieving artificial general intelligence (AGI). However, their large-scale nature, sensitivity to privacy concerns, and substantial computational demands present significant challenges to personalized customization for end users. To bridge this gap, this paper presents the vision of artificial personalized intelligence (API), focusing on adapting these powerful models to meet the specific needs and preferences of users while maintaining privacy and efficiency. Specifically, this paper proposes personalized federated intelligence (PFI), which integrates the privacy-preserving advantages of federated learning (FL) with the zero-shot generalization capabilities of FMs, enabling personalized, efficient, and privacy-protective deployment at the edge. We first review recent advances in both FL and FMs, and discuss the potential of leveraging FMs to enhance federated systems. We then present the key motivations behind realizing PFI and explore promising opportunities in this space, including efficient PFI, trustworthy PFI, and PFI empowered by retrieval-augmented generation (RAG). Finally, we outline key challenges and future research directions for deploying FM-powered FL systems at the edge with improved personalization, computational efficiency, and privacy guarantees. Overall, this survey aims to lay the groundwork for the development of API as a complement to AGI, with a particular focus on PFI as a key enabling technique.", "subjects": "Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Neural and Evolutionary Computing (cs.NE)", "comments": "On going work", "pdf_url": "https://arxiv.org/pdf/2505.06907.pdf", "abstract_url": "https://arxiv.org/abs/2505.06907", "categories": ["Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)", "Neural and Evolutionary Computing (cs.NE)"], "matching_keywords": ["@RAG"]}
{"id": "2505.06997", "title": "A Multi-Agent Reinforcement Learning Approach for Cooperative Air-Ground-Human Crowdsensing in Emergency Rescue", "authors": ["Wenhao Lu", "Zhengqiu Zhu", "Yong Zhao", "Yonglin Tian", "Junjie Zeng", "Jun Zhang", "Zhong Liu", "Fei-Yue Wang"], "abstract": "Mobile crowdsensing is evolving beyond traditional human-centric models by integrating heterogeneous entities like unmanned aerial vehicles (UAVs) and unmanned ground vehicles (UGVs). Optimizing task allocation among these diverse agents is critical, particularly in challenging emergency rescue scenarios characterized by complex environments, limited communication, and partial observability. This paper tackles the Heterogeneous-Entity Collaborative-Sensing Task Allocation (HECTA) problem specifically for emergency rescue, considering humans, UAVs, and UGVs. We introduce a novel ``Hard-Cooperative'' policy where UGVs prioritize recharging low-battery UAVs, alongside performing their sensing tasks. The primary objective is maximizing the task completion rate (TCR) under strict time constraints. We rigorously formulate this NP-hard problem as a decentralized partially observable Markov decision process (Dec-POMDP) to effectively handle sequential decision-making under uncertainty. To solve this, we propose HECTA4ER, a novel multi-agent reinforcement learning algorithm built upon a Centralized Training with Decentralized Execution architecture. HECTA4ER incorporates tailored designs, including specialized modules for complex feature extraction, utilization of action-observation history via hidden states, and a mixing network integrating global and local information, specifically addressing the challenges of partial observability. Furthermore, theoretical analysis confirms the algorithm's convergence properties. Extensive simulations demonstrate that HECTA4ER significantly outperforms baseline algorithms, achieving an average 18.42% increase in TCR. Crucially, a real-world case study validates the algorithm's effectiveness and robustness in dynamic sensing scenarios, highlighting its strong potential for practical application in emergency response.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.06997.pdf", "abstract_url": "https://arxiv.org/abs/2505.06997", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.07049", "title": "DialogueReason: Rule-Based RL Sparks Dialogue Reasoning in LLMs", "authors": ["Yubo Shu", "Zhewei Huang", "Xin Wu", "Chen Hu", "Shuchang Zhou", "Daxin Jiang"], "abstract": "We propose DialogueReason, a reasoning paradigm that uncovers the lost roles in monologue-style reasoning models, aiming to boost diversity and coherency of the reasoning process. Recent advances in RL-based large reasoning models have led to impressive long CoT capabilities and high performance on math and science benchmarks. However, these reasoning models rely mainly on monologue-style reasoning, which often limits reasoning diversity and coherency, frequently recycling fixed strategies or exhibiting unnecessary shifts in attention. Our work consists of an analysis of monologue reasoning patterns and the development of a dialogue-based reasoning approach. We first introduce the Compound-QA task, which concatenates multiple problems into a single prompt to assess both diversity and coherency of reasoning. Our analysis shows that Compound-QA exposes weaknesses in monologue reasoning, evidenced by both quantitative metrics and qualitative reasoning traces. Building on the analysis, we propose a dialogue-based reasoning, named DialogueReason, structured around agents, environment, and interactions. Using PPO with rule-based rewards, we train open-source LLMs (Qwen-QWQ and Qwen-Base) to adopt dialogue reasoning. We evaluate trained models on MATH, AIME, and GPQA datasets, showing that the dialogue reasoning model outperforms monologue models under more complex compound questions. Additionally, we discuss how dialogue-based reasoning helps enhance interpretability, facilitate more intuitive human interaction, and inspire advances in multi-agent system design.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.07049.pdf", "abstract_url": "https://arxiv.org/abs/2505.07049", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.07087", "title": "Architectural Precedents for General Agents using Large Language Models", "authors": ["Robert E. Wray", "James R. Kirk", "John E. Laird"], "abstract": "One goal of AI (and AGI) is to identify and understand specific mechanisms and representations sufficient for general intelligence. Often, this work manifests in research focused on architectures and many cognitive architectures have been explored in AI/AGI. However, different research groups and even different research traditions have somewhat independently identified similar/common patterns of processes and representations or cognitive design patterns that are manifest in existing architectures. Today, AI systems exploiting large language models (LLMs) offer a relatively new combination of mechanism and representation available for exploring the possibilities of general intelligence. In this paper, we summarize a few recurring cognitive design patterns that have appeared in various pre-transformer AI architectures. We then explore how these patterns are evident in systems using LLMs, especially for reasoning and interactive (\"agentic\") use cases. By examining and applying these recurring patterns, we can also predict gaps or deficiencies in today's Agentic LLM Systems and identify likely subjects of future research towards general intelligence using LLMs and other generative foundation models.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "14 pages, 2 figures. Submitted to AGI25", "pdf_url": "https://arxiv.org/pdf/2505.07087.pdf", "abstract_url": "https://arxiv.org/abs/2505.07087", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"]}
{"id": "2505.07233", "title": "DynamicRAG: Leveraging Outputs of Large Language Model as Feedback for Dynamic Reranking in Retrieval-Augmented Generation", "authors": ["Jiashuo Sun", "Xianrui Zhong", "Sizhe Zhou", "Jiawei Han"], "abstract": "Retrieval-augmented generation (RAG) systems combine large language models (LLMs) with external knowledge retrieval, making them highly effective for knowledge-intensive tasks. A crucial but often under-explored component of these systems is the reranker, which refines retrieved documents to enhance generation quality and explainability. The challenge of selecting the optimal number of documents (k) remains unsolved: too few may omit critical information, while too many introduce noise and inefficiencies. Although recent studies have explored LLM-based rerankers, they primarily leverage internal model knowledge and overlook the rich supervisory signals that LLMs can provide, such as using response quality as feedback for optimizing reranking decisions. In this paper, we propose DynamicRAG, a novel RAG framework where the reranker dynamically adjusts both the order and number of retrieved documents based on the query. We model the reranker as an agent optimized through reinforcement learning (RL), using rewards derived from LLM output quality. Across seven knowledge-intensive datasets, DynamicRAG demonstrates superior performance, achieving state-of-the-art results. The model, data and code are available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "24 pages, 6 figures, 15 tables", "pdf_url": "https://arxiv.org/pdf/2505.07233.pdf", "abstract_url": "https://arxiv.org/abs/2505.07233", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "@RAG"]}
{"id": "2505.07313", "title": "Towards Multi-Agent Reasoning Systems for Collaborative Expertise Delegation: An Exploratory Design Study", "authors": ["Baixuan Xu", "Chunyang Li", "Weiqi Wang", "Wei Fan", "Tianshi Zheng", "Haochen Shi", "Tao Fan", "Yangqiu Song", "Qiang Yang"], "abstract": "Designing effective collaboration structure for multi-agent LLM systems to enhance collective reasoning is crucial yet remains under-explored. In this paper, we systematically investigate how collaborative reasoning performance is affected by three key design dimensions: (1) Expertise-Domain Alignment, (2) Collaboration Paradigm (structured workflow vs. diversity-driven integration), and (3) System Scale. Our findings reveal that expertise alignment benefits are highly domain-contingent, proving most effective for contextual reasoning tasks. Furthermore, collaboration focused on integrating diverse knowledge consistently outperforms rigid task decomposition. Finally, we empirically explore the impact of scaling the multi-agent system with expertise specialization and study the computational trade off, highlighting the need for more efficient communication protocol design. This work provides concrete guidelines for configuring specialized multi-agent system and identifies critical architectural trade-offs and bottlenecks for scalable multi-agent reasoning. The code will be made available upon acceptance.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "18 pages", "pdf_url": "https://arxiv.org/pdf/2505.07313.pdf", "abstract_url": "https://arxiv.org/abs/2505.07313", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.07215", "title": "Measuring General Intelligence with Generated Games", "authors": ["Vivek Verma", "David Huang", "William Chen", "Dan Klein", "Nicholas Tomlin"], "abstract": "We present gg-bench, a collection of game environments designed to evaluate general reasoning capabilities in language models. Unlike most static benchmarks, gg-bench is a data generating process where new evaluation instances can be generated at will. In particular, gg-bench is synthetically generated by (1) using a large language model (LLM) to generate natural language descriptions of novel games, (2) using the LLM to implement each game in code as a Gym environment, and (3) training reinforcement learning (RL) agents via self-play on the generated games. We evaluate language models by their winrate against these RL agents by prompting models with the game description, current board state, and a list of valid moves, after which models output the moves they wish to take. gg-bench is challenging: state-of-the-art LLMs such as GPT-4o and Claude 3.7 Sonnet achieve winrates of 7-9% on gg-bench using in-context learning, while reasoning models such as o1, o3-mini and DeepSeek-R1 achieve average winrates of 31-36%. We release the generated games, data generation process, and evaluation code in order to support future modeling work and expansion of our benchmark.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.07215.pdf", "abstract_url": "https://arxiv.org/abs/2505.07215", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.07473", "title": "Web-Bench: A LLM Code Benchmark Based on Web Standards and Frameworks", "authors": ["Kai Xu", "YiWei Mao", "XinYi Guan", "ZiLong Feng"], "abstract": "The application of large language models (LLMs) in the field of coding is evolving rapidly: from code assistants, to autonomous coding agents, and then to generating complete projects through natural language. Early LLM code benchmarks primarily focused on code generation accuracy, but these benchmarks have gradually become saturated. Benchmark saturation weakens their guiding role for LLMs. For example, HumanEval Pass@1 has reached 99.4% and MBPP 94.2%. Among various attempts to address benchmark saturation, approaches based on software engineering have stood out, but the saturation of existing software engineering benchmarks is rapidly increasing. To address this, we propose a new benchmark, Web-Bench, which contains 50 projects, each consisting of 20 tasks with sequential dependencies. The tasks implement project features in sequence, simulating real-world human development workflows. When designing Web-Bench, we aim to cover the foundational elements of Web development: Web Standards and Web Frameworks. Given the scale and complexity of these projects, which were designed by engineers with 5 to 10 years of experience, each presents a significant challenge. On average, a single project takes 4 to 8 hours for a senior engineer to complete. On our given benchmark agent (Web-Agent), SOTA (Claude 3.7 Sonnet) achieves only 25.1% Pass@1, significantly lower (better) than SWE-Bench's Verified (65.4%) and Full (33.8%) scores. Finally, we discuss that in any development field, Standards and Frameworks represent foundational knowledge and efficiency tools, respectively, and LLMs require optimization tailored to them.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "28 pages, 15 figures", "pdf_url": "https://arxiv.org/pdf/2505.07473.pdf", "abstract_url": "https://arxiv.org/abs/2505.07473", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.07581", "title": "YuLan-OneSim: Towards the Next Generation of Social Simulator with Large Language Models", "authors": ["Lei Wang", "Heyang Gao", "Xiaohe Bo", "Xu Chen", "Ji-Rong Wen"], "abstract": "Leveraging large language model (LLM) based agents to simulate human social behaviors has recently gained significant attention. In this paper, we introduce a novel social simulator called YuLan-OneSim. Compared to previous works, YuLan-OneSim distinguishes itself in five key aspects: (1) Code-free scenario construction: Users can simply describe and refine their simulation scenarios through natural language interactions with our simulator. All simulation code is automatically generated, significantly reducing the need for programming expertise. (2) Comprehensive default scenarios: We implement 50 default simulation scenarios spanning 8 domains, including economics, sociology, politics, psychology, organization, demographics, law, and communication, broadening access for a diverse range of social researchers. (3) Evolvable simulation: Our simulator is capable of receiving external feedback and automatically fine-tuning the backbone LLMs, significantly enhancing the simulation quality. (4) Large-scale simulation: By developing a fully responsive agent framework and a distributed simulation architecture, our simulator can handle up to 100,000 agents, ensuring more stable and reliable simulation results. (5) AI social researcher: Leveraging the above features, we develop an AI social researcher. Users only need to propose a research topic, and the AI researcher will automatically analyze the input, construct simulation environments, summarize results, generate technical reports, review and refine the reports--completing the social science research loop. To demonstrate the advantages of YuLan-OneSim, we conduct experiments to evaluate the quality of the automatically generated scenarios, the reliability, efficiency, and scalability of the simulation process, as well as the performance of the AI social researcher.", "subjects": "Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.07581.pdf", "abstract_url": "https://arxiv.org/abs/2505.07581", "categories": ["Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)"], "matching_keywords": ["agent"]}
{"id": "2505.07528", "title": "SEReDeEP: Hallucination Detection in Retrieval-Augmented Models via Semantic Entropy and Context-Parameter Fusion", "authors": ["Lei Wang"], "abstract": "Retrieval-Augmented Generation (RAG) models frequently encounter hallucination phenomena when integrating external information with internal parametric knowledge. Empirical studies demonstrate that the disequilibrium between external contextual information and internal parametric knowledge constitutes a primary factor in hallucination generation. Existing hallucination detection methodologies predominantly emphasize either the external or internal mechanism in isolation, thereby overlooking their synergistic effects. The recently proposed ReDeEP framework decouples these dual mechanisms, identifying two critical contributors to hallucinations: excessive reliance on parametric knowledge encoded in feed-forward networks (FFN) and insufficient utilization of external information by attention mechanisms (particularly copy heads). ReDeEP quantitatively assesses these factors to detect hallucinations and dynamically modulates the contributions of FFNs and copy heads to attenuate their occurrence. Nevertheless, ReDeEP and numerous other hallucination detection approaches have been employed at logit-level uncertainty estimation or language-level self-consistency evaluation, inadequately address the semantic dimensions of model responses, resulting in inconsistent hallucination assessments in RAG implementations. Building upon ReDeEP's foundation, this paper introduces SEReDeEP, which enhances computational processes through semantic entropy captured via trained linear probes, thereby achieving hallucination assessments that more accurately reflect ground truth evaluations.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.07528.pdf", "abstract_url": "https://arxiv.org/abs/2505.07528", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"]}
{"id": "2505.07596", "title": "Reinforced Internal-External Knowledge Synergistic Reasoning for Efficient Adaptive Search Agent", "authors": ["Ziyang Huang", "Xiaowei Yuan", "Yiming Ju", "Jun Zhao", "Kang Liu"], "abstract": "Retrieval-augmented generation (RAG) is a common strategy to reduce hallucinations in Large Language Models (LLMs). While reinforcement learning (RL) can enable LLMs to act as search agents by activating retrieval capabilities, existing ones often underutilize their internal knowledge. This can lead to redundant retrievals, potential harmful knowledge conflicts, and increased inference latency. To address these limitations, an efficient and adaptive search agent capable of discerning optimal retrieval timing and synergistically integrating parametric (internal) and retrieved (external) knowledge is in urgent need. This paper introduces the Reinforced Internal-External Knowledge Synergistic Reasoning Agent (IKEA), which could indentify its own knowledge boundary and prioritize the utilization of internal knowledge, resorting to external search only when internal knowledge is deemed insufficient. This is achieved using a novel knowledge-boundary aware reward function and a knowledge-boundary aware training dataset. These are designed for internal-external knowledge synergy oriented RL, incentivizing the model to deliver accurate answers, minimize unnecessary retrievals, and encourage appropriate external searches when its own knowledge is lacking. Evaluations across multiple knowledge reasoning tasks demonstrate that IKEA significantly outperforms baseline methods, reduces retrieval frequency significantly, and exhibits robust generalization capabilities.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.07596.pdf", "abstract_url": "https://arxiv.org/abs/2505.07596", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "@RAG"]}
{"id": "2505.07637", "title": "Chronocept: Instilling a Sense of Time in Machines", "authors": ["Krish Goel", "Sanskar Pandey", "KS Mahadevan", "Harsh Kumar", "Vishesh Khadaria"], "abstract": "Human cognition is deeply intertwined with a sense of time, known as Chronoception. This sense allows us to judge how long facts remain valid and when knowledge becomes outdated. Despite progress in vision, language, and motor control, AI still struggles to reason about temporal validity. We introduce Chronocept, the first benchmark to model temporal validity as a continuous probability distribution over time. Using skew-normal curves fitted along semantically decomposed temporal axes, Chronocept captures nuanced patterns of emergence, decay, and peak relevance. It includes two datasets: Benchmark I (atomic facts) and Benchmark II (multi-sentence passages). Annotations show strong inter-annotator agreement (84% and 89%). Our baselines predict curve parameters - location, scale, and skewness - enabling interpretable, generalizable learning and outperforming classification-based approaches. Chronocept fills a foundational gap in AI's temporal reasoning, supporting applications in knowledge grounding, fact-checking, retrieval-augmented generation (RAG), and proactive agents. Code and data are publicly available.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "20 pages, 8 figures, 18 tables", "pdf_url": "https://arxiv.org/pdf/2505.07637.pdf", "abstract_url": "https://arxiv.org/abs/2505.07637", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "@RAG"]}
{"id": "2505.07671", "title": "Benchmarking Retrieval-Augmented Generation for Chemistry", "authors": ["Xianrui Zhong", "Bowen Jin", "Siru Ouyang", "Yanzhen Shen", "Qiao Jin", "Yin Fang", "Zhiyong Lu", "Jiawei Han"], "abstract": "Retrieval-augmented generation (RAG) has emerged as a powerful framework for enhancing large language models (LLMs) with external knowledge, particularly in scientific domains that demand specialized and dynamic information. Despite its promise, the application of RAG in the chemistry domain remains underexplored, primarily due to the lack of high-quality, domain-specific corpora and well-curated evaluation benchmarks. In this work, we introduce ChemRAG-Bench, a comprehensive benchmark designed to systematically assess the effectiveness of RAG across a diverse set of chemistry-related tasks. The accompanying chemistry corpus integrates heterogeneous knowledge sources, including scientific literature, the PubChem database, PubMed abstracts, textbooks, and Wikipedia entries. In addition, we present ChemRAG-Toolkit, a modular and extensible RAG toolkit that supports five retrieval algorithms and eight LLMs. Using ChemRAG-Toolkit, we demonstrate that RAG yields a substantial performance gain -- achieving an average relative improvement of 17.4% over direct inference methods. We further conduct in-depth analyses on retriever architectures, corpus selection, and the number of retrieved passages, culminating in practical recommendations to guide future research and deployment of RAG systems in the chemistry domain. The code and data is available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.07671.pdf", "abstract_url": "https://arxiv.org/abs/2505.07671", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"]}
{"id": "2505.07705", "title": "Codifying Character Logic in Role-Playing", "authors": ["Letian Peng", "Jingbo Shang"], "abstract": "This paper introduces Codified Profiles for role-playing, a novel approach that represents character logic as structured, executable functions for behavioral decision-making. Each profile defines a set of functions parse_by_scene(scene) that outputs a list of logic-grounded assertions triggered_statements, using both explicit control structures (e.g., if-then-else) and condition checks like check_condition(scene, question), where each question is a semantically meaningful prompt about the scene (e.g., \"Is the character in danger?\") discriminated by the role-playing LLM as true, false, or unknown. This explicit representation offers three key advantages over traditional prompt-based profiles, which append character descriptions directly into text prompts: (1) Persistence, by enforcing complete and consistent execution of character logic, rather than relying on the model's implicit reasoning; (2) Updatability, through systematic inspection and revision of behavioral logic, which is difficult to track or debug in prompt-only approaches; (3) Controllable Randomness, by supporting stochastic behavior directly within the logic, enabling fine-grained variability that prompting alone struggles to achieve. To validate these advantages, we introduce a new benchmark constructed from 83 characters and 5,141 scenes curated from Fandom, using NLI-based scoring to compare character responses against ground-truth actions. Our experiments demonstrate the significant benefits of codified profiles in improving persistence, updatability, and behavioral diversity. Notably, by offloading a significant portion of reasoning to preprocessing, codified profiles enable even 1B-parameter models to perform high-quality role-playing, providing a scalable and efficient foundation for local deployment of role-play agents.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.07705.pdf", "abstract_url": "https://arxiv.org/abs/2505.07705", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2505.07693", "title": "Belief Injection for Epistemic Control in Linguistic State Space", "authors": ["Sebastian Dumbrava"], "abstract": "This work introduces belief injection, a proactive epistemic control mechanism for artificial agents whose cognitive states are structured as dynamic ensembles of linguistic belief fragments. Grounded in the Semantic Manifold framework, belief injection directly incorporates targeted linguistic beliefs into an agent's internal cognitive state, influencing reasoning and alignment proactively rather than reactively. We delineate various injection strategies, such as direct, context-aware, goal-oriented, and reflective approaches, and contrast belief injection with related epistemic control mechanisms, notably belief filtering. Additionally, this work discusses practical applications, implementation considerations, ethical implications, and outlines promising directions for future research into cognitive governance using architecturally embedded belief injection.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "30 pages, 9 figures", "pdf_url": "https://arxiv.org/pdf/2505.07693.pdf", "abstract_url": "https://arxiv.org/abs/2505.07693", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.07757", "title": "Emotion-Gradient Metacognitive RSI (Part I): Theoretical Foundations and Single-Agent Architecture", "authors": ["Rintaro Ando"], "abstract": "We present the Emotion-Gradient Metacognitive Recursive Self-Improvement (EG-MRSI) framework, a novel architecture that integrates introspective metacognition, emotion-based intrinsic motivation, and recursive self-modification into a unified theoretical system. The framework is explicitly capable of overwriting its own learning algorithm under formally bounded risk. Building upon the Noise-to-Meaning RSI (N2M-RSI) foundation, EG-MRSI introduces a differentiable intrinsic reward function driven by confidence, error, novelty, and cumulative success. This signal regulates both a metacognitive mapping and a self-modification operator constrained by provable safety mechanisms. We formally define the initial agent configuration, emotion-gradient dynamics, and RSI trigger conditions, and derive a reinforcement-compatible optimization objective that guides the agent's development trajectory. Meaning Density and Meaning Conversion Efficiency are introduced as quantifiable metrics of semantic learning, closing the gap between internal structure and predictive informativeness. This Part I paper establishes the single-agent theoretical foundations of EG-MRSI. Future parts will extend this framework to include safety certificates and rollback protocols (Part II), collective intelligence mechanisms (Part III), and feasibility constraints including thermodynamic and computational limits (Part IV). Together, the EG-MRSI series provides a rigorous, extensible foundation for open-ended and safe AGI.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "21 pages, 3 figures. Part I of a four-part series (Parts II-IV forthcoming)", "pdf_url": "https://arxiv.org/pdf/2505.07757.pdf", "abstract_url": "https://arxiv.org/abs/2505.07757", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"]}
{"id": "2505.07773", "title": "Agent RL Scaling Law: Agent RL with Spontaneous Code Execution for Mathematical Problem Solving", "authors": ["Xinji Mai", "Haotian Xu", "Xing W", "Weinong Wang", "Yingying Zhang", "Wenqiang Zhang"], "abstract": "Large Language Models (LLMs) often struggle with mathematical reasoning tasks requiring precise, verifiable computation. While Reinforcement Learning (RL) from outcome-based rewards enhances text-based reasoning, understanding how agents autonomously learn to leverage external tools like code execution remains crucial. We investigate RL from outcome-based rewards for Tool-Integrated Reasoning, ZeroTIR, training base LLMs to spontaneously generate and execute Python code for mathematical problems without supervised tool-use examples. Our central contribution is we demonstrate that as RL training progresses, key metrics scale predictably. Specifically, we observe strong positive correlations where increased training steps lead to increases in the spontaneous code execution frequency, the average response length, and, critically, the final task accuracy. This suggests a quantifiable relationship between computational effort invested in training and the emergence of effective, tool-augmented reasoning strategies. We implement a robust framework featuring a decoupled code execution environment and validate our findings across standard RL algorithms and frameworks. Experiments show ZeroTIR significantly surpasses non-tool ZeroRL baselines on challenging math benchmarks. Our findings provide a foundational understanding of how autonomous tool use is acquired and scales within Agent RL, offering a reproducible benchmark for future studies. Code is released at \\href{", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.07773.pdf", "abstract_url": "https://arxiv.org/abs/2505.07773", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.07500", "title": "Learning to Reason and Navigate: Parameter Efficient Action Planning with Large Language Models", "authors": ["Bahram Mohammadi", "Ehsan Abbasnejad", "Yuankai Qi", "Qi Wu", "Anton Van Den Hengel", "Javen Qinfeng Shi"], "abstract": "The remote embodied referring expression (REVERIE) task requires an agent to navigate through complex indoor environments and localize a remote object specified by high-level instructions, such as \"bring me a spoon\", without pre-exploration. Hence, an efficient navigation plan is essential for the final success. This paper proposes a novel parameter-efficient action planner using large language models (PEAP-LLM) to generate a single-step instruction at each location. The proposed model consists of two modules, LLM goal planner (LGP) and LoRA action planner (LAP). Initially, LGP extracts the goal-oriented plan from REVERIE instructions, including the target object and room. Then, LAP generates a single-step instruction with the goal-oriented plan, high-level instruction, and current visual observation as input. PEAP-LLM enables the embodied agent to interact with LAP as the path planner on the fly. A simple direct application of LLMs hardly achieves good performance. Also, existing hard-prompt-based methods are error-prone in complicated scenarios and need human intervention. To address these issues and prevent the LLM from generating hallucinations and biased information, we propose a novel two-stage method for fine-tuning the LLM, consisting of supervised fine-tuning (STF) and direct preference optimization (DPO). SFT improves the quality of generated instructions, while DPO utilizes environmental feedback. Experimental results show the superiority of our proposed model on REVERIE compared to the previous state-of-the-art.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.07500.pdf", "abstract_url": "https://arxiv.org/abs/2505.07500", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"]}
{"id": "2505.06313", "title": "AI Approaches to Qualitative and Quantitative News Analytics on NATO Unity", "authors": ["Bohdan M. Pavlyshenko"], "abstract": "The paper considers the use of GPT models with retrieval-augmented generation (RAG) for qualitative and quantitative analytics on NATO sentiments, NATO unity and NATO Article 5 trust opinion scores in different web sources: news sites found via Google Search API, Youtube videos with comments, and Reddit discussions. A RAG approach using GPT-4.1 model was applied to analyse news where NATO related topics were discussed. Two levels of RAG analytics were used: on the first level, the GPT model generates qualitative news summaries and quantitative opinion scores using zero-shot prompts; on the second level, the GPT model generates the summary of news summaries. Quantitative news opinion scores generated by the GPT model were analysed using Bayesian regression to get trend lines. The distributions found for the regression parameters make it possible to analyse an uncertainty in specified news opinion score trends. Obtained results show a downward trend for analysed scores of opinion related to NATO unity.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Social and Information Networks (cs.SI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.06313.pdf", "abstract_url": "https://arxiv.org/abs/2505.06313", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Social and Information Networks (cs.SI)"], "matching_keywords": ["@RAG"]}
{"id": "2505.07365", "title": "Multi-Domain Audio Question Answering Toward Acoustic Content Reasoning in The DCASE 2025 Challenge", "authors": ["Chao-Han Huck Yang", "Sreyan Ghosh", "Qing Wang", "Jaeyeon Kim", "Hengyi Hong", "Sonal Kumar", "Guirui Zhong", "Zhifeng Kong", "S Sakshi", "Vaibhavi Lokegaonkar", "Oriol Nieto", "Ramani Duraiswami", "Dinesh Manocha", "Gunhee Kim", "Jun Du", "Rafael Valle", "Bryan Catanzaro"], "abstract": "We present Task 5 of the DCASE 2025 Challenge: an Audio Question Answering (AQA) benchmark spanning multiple domains of sound understanding. This task defines three QA subsets (Bioacoustics, Temporal Soundscapes, and Complex QA) to test audio-language models on interactive question-answering over diverse acoustic scenes. We describe the dataset composition (from marine mammal calls to soundscapes and complex real-world clips), the evaluation protocol (top-1 accuracy with answer-shuffling robustness), and baseline systems (Qwen2-Audio-7B, AudioFlamingo 2, Gemini-2-Flash). Preliminary results on the development set are compared, showing strong variation across models and subsets. This challenge aims to advance the audio understanding and reasoning capabilities of audio-language models toward human-level acuity, which are crucial for enabling AI agents to perceive and interact about the world effectively.", "subjects": "Sound (cs.SD); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Multimedia (cs.MM); Audio and Speech Processing (eess.AS)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.07365.pdf", "abstract_url": "https://arxiv.org/abs/2505.07365", "categories": ["Sound (cs.SD)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Multimedia (cs.MM)", "Audio and Speech Processing (eess.AS)"], "matching_keywords": ["agent"]}
{"id": "2505.06311", "title": "Defending against Indirect Prompt Injection by Instruction Detection", "authors": ["Tongyu Wen", "Chenglong Wang", "Xiyuan Yang", "Haoyu Tang", "Yueqi Xie", "Lingjuan Lyu", "Zhicheng Dou", "Fangzhao Wu"], "abstract": "The integration of Large Language Models (LLMs) with external sources is becoming increasingly common, with Retrieval-Augmented Generation (RAG) being a prominent example. However, this integration introduces vulnerabilities of Indirect Prompt Injection (IPI) attacks, where hidden instructions embedded in external data can manipulate LLMs into executing unintended or harmful actions. We recognize that the success of IPI attacks fundamentally relies in the presence of instructions embedded within external content, which can alter the behavioral state of LLMs. Can effectively detecting such state changes help us defend against IPI attacks? In this paper, we propose a novel approach that takes external data as input and leverages the behavioral state of LLMs during both forward and backward propagation to detect potential IPI attacks. Specifically, we demonstrate that the hidden states and gradients from intermediate layers provide highly discriminative features for instruction detection. By effectively combining these features, our approach achieves a detection accuracy of 99.60\\% in the in-domain setting and 96.90\\% in the out-of-domain setting, while reducing the attack success rate to just 0.12\\% on the BIPIA benchmark.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": "13 pages, 4 figures", "pdf_url": "https://arxiv.org/pdf/2505.06311.pdf", "abstract_url": "https://arxiv.org/abs/2505.06311", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"]}
{"id": "2505.06312", "title": "Responsibility Gap in Collective Decision Making", "authors": ["Pavel Naumov", "Jia Tao"], "abstract": "The responsibility gap is a set of outcomes of a collective decision-making mechanism in which no single agent is individually responsible. In general, when designing a decision-making process, it is desirable to minimise the gap.", "subjects": "Computer Science and Game Theory (cs.GT); Artificial Intelligence (cs.AI)", "comments": "full version of an IJCAI-25 paper", "pdf_url": "https://arxiv.org/pdf/2505.06312.pdf", "abstract_url": "https://arxiv.org/abs/2505.06312", "categories": ["Computer Science and Game Theory (cs.GT)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.06314", "title": "A4L: An Architecture for AI-Augmented Learning", "authors": ["Ashok Goel", "Ploy Thajchayapong", "Vrinda Nandan", "Harshvardhan Sikka", "Spencer Rugaber"], "abstract": "AI promises personalized learning and scalable education. As AI agents increasingly permeate education in support of teaching and learning, there is a critical and urgent need for data architectures for collecting and analyzing data on learning, and feeding the results back to teachers, learners, and the AI agents for personalization of learning at scale. At the National AI Institute for Adult Learning and Online Education, we are developing an Architecture for AI-Augmented Learning (A4L) for supporting adult learning through online education. We present the motivations, goals, requirements of the A4L architecture. We describe preliminary applications of A4L and discuss how it advances the goals of making learning more personalized and scalable.", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI)", "comments": "14 pages, 7 figures", "pdf_url": "https://arxiv.org/pdf/2505.06314.pdf", "abstract_url": "https://arxiv.org/abs/2505.06314", "categories": ["Computers and Society (cs.CY)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.06315", "title": "Threat Modeling for AI: The Case for an Asset-Centric Approach", "authors": ["Jose Sanchez Vicarte", "Marcin Spoczynski", "Mostafa Elsaid"], "abstract": "Recent advances in AI are transforming AI's ubiquitous presence in our world from that of standalone AI-applications into deeply integrated AI-agents. These changes have been driven by agents' increasing capability to autonomously make decisions and initiate actions, using existing applications; whether those applications are AI-based or not. This evolution enables unprecedented levels of AI integration, with agents now able to take actions on behalf of systems and users -- including, in some cases, the powerful ability for the AI to write and execute scripts as it deems necessary. With AI systems now able to autonomously execute code, interact with external systems, and operate without human oversight, traditional security approaches fall short.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.06315.pdf", "abstract_url": "https://arxiv.org/abs/2505.06315", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.06621", "title": "Minimizing Risk Through Minimizing Model-Data Interaction: A Protocol For Relying on Proxy Tasks When Designing Child Sexual Abuse Imagery Detection Models", "authors": ["Thamiris Coelho", "Leo S. F. Ribeiro", "João Macedo", "Jefersson A. dos Santos", "Sandra Avila"], "abstract": "The distribution of child sexual abuse imagery (CSAI) is an ever-growing concern of our modern world; children who suffered from this heinous crime are revictimized, and the growing amount of illegal imagery distributed overwhelms law enforcement agents (LEAs) with the manual labor of categorization. To ease this burden researchers have explored methods for automating data triage and detection of CSAI, but the sensitive nature of the data imposes restricted access and minimal interaction between real data and learning algorithms, avoiding leaks at all costs. In observing how these restrictions have shaped the literature we formalize a definition of \"Proxy Tasks\", i.e., the substitute tasks used for training models for CSAI without making use of CSA data. Under this new terminology we review current literature and present a protocol for making conscious use of Proxy Tasks together with consistent input from LEAs to design better automation in this field. Finally, we apply this protocol to study -- for the first time -- the task of Few-shot Indoor Scene Classification on CSAI, showing a final model that achieves promising results on a real-world CSAI dataset whilst having no weights actually trained on sensitive data.", "subjects": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV)", "comments": "ACM Conference on Fairness, Accountability, and Transparency (FAccT 2025)", "pdf_url": "https://arxiv.org/pdf/2505.06621.pdf", "abstract_url": "https://arxiv.org/abs/2505.06621", "categories": ["Machine Learning (cs.LG)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"]}
{"id": "2505.06335", "title": "Remote Rowhammer Attack using Adversarial Observations on Federated Learning Clients", "authors": ["Jinsheng Yuan", "Yuhang Hao", "Weisi Guo", "Yun Wu", "Chongyan Gu"], "abstract": "Federated Learning (FL) has the potential for simultaneous global learning amongst a large number of parallel agents, enabling emerging AI such as LLMs to be trained across demographically diverse data. Central to this being efficient is the ability for FL to perform sparse gradient updates and remote direct memory access at the central server. Most of the research in FL security focuses on protecting data privacy at the edge client or in the communication channels between the client and server. Client-facing attacks on the server are less well investigated as the assumption is that a large collective of clients offer resilience.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.06335.pdf", "abstract_url": "https://arxiv.org/abs/2505.06335", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Cryptography and Security (cs.CR)"], "matching_keywords": ["agent"]}
{"id": "2505.06378", "title": "Bi-LSTM based Multi-Agent DRL with Computation-aware Pruning for Agent Twins Migration in Vehicular Embodied AI Networks", "authors": ["Yuxiang Wei", "Zhuoqi Zeng", "Yue Zhong", "Jiawen Kang", "Ryan Wen Liu", "M. Shamim Hossain"], "abstract": "With the advancement of large language models and embodied Artificial Intelligence (AI) in the intelligent transportation scenarios, the combination of them in intelligent transportation spawns the Vehicular Embodied AI Network (VEANs). In VEANs, Autonomous Vehicles (AVs) are typical agents whose local advanced AI applications are defined as vehicular embodied AI agents, enabling capabilities such as environment perception and multi-agent collaboration. Due to computation latency and resource constraints, the local AI applications and services running on vehicular embodied AI agents need to be migrated, and subsequently referred to as vehicular embodied AI agent twins, which drive the advancement of vehicular embodied AI networks to offload intensive tasks to Roadside Units (RSUs), mitigating latency problems while maintaining service quality. Recognizing workload imbalance among RSUs in traditional approaches, we model AV-RSU interactions as a Stackelberg game to optimize bandwidth resource allocation for efficient migration. A Tiny Multi-Agent Bidirectional LSTM Proximal Policy Optimization (TMABLPPO) algorithm is designed to approximate the Stackelberg equilibrium through decentralized coordination. Furthermore, a personalized neural network pruning algorithm based on Path eXclusion (PX) dynamically adapts to heterogeneous AV computation capabilities by identifying task-critical parameters in trained models, reducing model complexity with less performance degradation. Experimental validation confirms the algorithm's effectiveness in balancing system load and minimizing delays, demonstrating significant improvements in vehicular embodied AI agent deployment.", "subjects": "Computer Science and Game Theory (cs.GT); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.06378.pdf", "abstract_url": "https://arxiv.org/abs/2505.06378", "categories": ["Computer Science and Game Theory (cs.GT)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.06394", "title": "Towards AI-Driven Human-Machine Co-Teaming for Adaptive and Agile Cyber Security Operation Centers", "authors": ["Massimiliano Albanese", "Xinming Ou", "Kevin Lybarger", "Daniel Lende", "Dmitry Goldgof"], "abstract": "Security Operations Centers (SOCs) face growing challenges in managing cybersecurity threats due to an overwhelming volume of alerts, a shortage of skilled analysts, and poorly integrated tools. Human-AI collaboration offers a promising path to augment the capabilities of SOC analysts while reducing their cognitive overload. To this end, we introduce an AI-driven human-machine co-teaming paradigm that leverages large language models (LLMs) to enhance threat intelligence, alert triage, and incident response workflows. We present a vision in which LLM-based AI agents learn from human analysts the tacit knowledge embedded in SOC operations, enabling the AI agents to improve their performance on SOC tasks through this co-teaming. We invite SOCs to collaborate with us to further develop this process and uncover replicable patterns where human-AI co-teaming yields measurable improvements in SOC productivity.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.06394.pdf", "abstract_url": "https://arxiv.org/abs/2505.06394", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.06980", "title": "VALISENS: A Validated Innovative Multi-Sensor System for Cooperative Automated Driving", "authors": ["Lei Wan", "Prabesh Gupta", "Andreas Eich", "Marcel Kettelgerdes", "Hannan Ejaz Keen", "Michael Klöppel-Gersdorf", "Alexey Vinel"], "abstract": "Perception is a core capability of automated vehicles and has been significantly advanced through modern sensor technologies and artificial intelligence. However, perception systems still face challenges in complex real-world scenarios. To improve robustness against various external factors, multi-sensor fusion techniques are essential, combining the strengths of different sensor modalities. With recent developments in Vehicle-to-Everything (V2X communication, sensor fusion can now extend beyond a single vehicle to a cooperative multi-agent system involving Connected Automated Vehicle (CAV) and intelligent infrastructure. This paper presents VALISENS, an innovative multi-sensor system distributed across multiple agents. It integrates onboard and roadside LiDARs, radars, thermal cameras, and RGB cameras to enhance situational awareness and support cooperative automated driving. The thermal camera adds critical redundancy for perceiving Vulnerable Road User (VRU), while fusion with roadside sensors mitigates visual occlusions and extends the perception range beyond the limits of individual vehicles. We introduce the corresponding perception module built on this sensor system, which includes object detection, tracking, motion forecasting, and high-level data fusion. The proposed system demonstrates the potential of cooperative perception in real-world test environments and lays the groundwork for future Cooperative Intelligent Transport Systems (C-ITS) applications.", "subjects": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV)", "comments": "7 pages, 11 figures, submitted to IEEE ITSC", "pdf_url": "https://arxiv.org/pdf/2505.06980.pdf", "abstract_url": "https://arxiv.org/abs/2505.06980", "categories": ["Robotics (cs.RO)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"]}
{"id": "2505.07214", "title": "Towards user-centered interactive medical image segmentation in VR with an assistive AI agent", "authors": ["Pascal Spiegler", "Arash Harirpoush", "Yiming Xiao"], "abstract": "Crucial in disease analysis and surgical planning, manual segmentation of volumetric medical scans (e.g. MRI, CT) is laborious, error-prone, and challenging to master, while fully automatic algorithms can benefit from user-feedback. Therefore, with the complementary power of the latest radiological AI foundation models and virtual reality (VR)'s intuitive data interaction, we propose SAMIRA, a novel conversational AI agent that assists users with localizing, segmenting, and visualizing 3D medical concepts in VR. Through speech-based interaction, the agent helps users understand radiological features, locate clinical targets, and generate segmentation masks that can be refined with just a few point prompts. The system also supports true-to-scale 3D visualization of segmented pathology to enhance patient-specific anatomical understanding. Furthermore, to determine the optimal interaction paradigm under near-far attention-switching for refining segmentation masks in an immersive, human-in-the-loop workflow, we compare VR controller pointing, head pointing, and eye tracking as input modes. With a user study, evaluations demonstrated a high usability score (SUS=90.0 $\\pm$ 9.0), low overall task load, as well as strong support for the proposed VR system's guidance, training potential, and integration of AI in radiological segmentation tasks.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.07214.pdf", "abstract_url": "https://arxiv.org/abs/2505.07214", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"]}
{"id": "2505.06482", "title": "Video-Enhanced Offline Reinforcement Learning: A Model-Based Approach", "authors": ["Minting Pan", "Yitao Zheng", "Jiajian Li", "Yunbo Wang", "Xiaokang Yang"], "abstract": "Offline reinforcement learning (RL) enables policy optimization in static datasets, avoiding the risks and costs of real-world exploration. However, it struggles with suboptimal behavior learning and inaccurate value estimation due to the lack of environmental interaction. In this paper, we present Video-Enhanced Offline RL (VeoRL), a model-based approach that constructs an interactive world model from diverse, unlabeled video data readily available online. Leveraging model-based behavior guidance, VeoRL transfers commonsense knowledge of control policy and physical dynamics from natural videos to the RL agent within the target domain. Our method achieves substantial performance gains (exceeding 100% in some cases) across visuomotor control tasks in robotic manipulation, autonomous driving, and open-world video games.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.06482.pdf", "abstract_url": "https://arxiv.org/abs/2505.06482", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"]}
{"id": "2505.06493", "title": "System Prompt Poisoning: Persistent Attacks on Large Language Models Beyond User Injection", "authors": ["Jiawei Guo", "Haipeng Cai"], "abstract": "Large language models (LLMs) have gained widespread adoption across diverse applications due to their impressive generative capabilities. Their plug-and-play nature enables both developers and end users to interact with these models through simple prompts. However, as LLMs become more integrated into various systems in diverse domains, concerns around their security are growing. Existing studies mainly focus on threats arising from user prompts (e.g. prompt injection attack) and model output (e.g. model inversion attack), while the security of system prompts remains largely overlooked. This work bridges the critical gap. We introduce system prompt poisoning, a new attack vector against LLMs that, unlike traditional user prompt injection, poisons system prompts hence persistently impacts all subsequent user interactions and model responses. We systematically investigate four practical attack strategies in various poisoning scenarios. Through demonstration on both generative and reasoning LLMs, we show that system prompt poisoning is highly feasible without requiring jailbreak techniques, and effective across a wide range of tasks, including those in mathematics, coding, logical reasoning, and natural language processing. Importantly, our findings reveal that the attack remains effective even when user prompts employ advanced prompting techniques like chain-of-thought (CoT). We also show that such techniques, including CoT and retrieval-augmentation-generation (RAG), which are proven to be effective for improving LLM performance in a wide range of tasks, are significantly weakened in their effectiveness by system prompt poisoning.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.06493.pdf", "abstract_url": "https://arxiv.org/abs/2505.06493", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"]}
{"id": "2505.07634", "title": "Neural Brain: A Neuroscience-inspired Framework for Embodied Agents", "authors": ["Jian Liu", "Xiongtao Shi", "Thai Duy Nguyen", "Haitian Zhang", "Tianxiang Zhang", "Wei Sun", "Yanjie Li", "Athanasios V. Vasilakos", "Giovanni Iacca", "Arshad Ali Khan", "Arvind Kumar", "Jae Won Cho", "Ajmal Mian", "Lihua Xie", "Erik Cambria", "Lin Wang"], "abstract": "The rapid evolution of artificial intelligence (AI) has shifted from static, data-driven models to dynamic systems capable of perceiving and interacting with real-world environments. Despite advancements in pattern recognition and symbolic reasoning, current AI systems, such as large language models, remain disembodied, unable to physically engage with the world. This limitation has driven the rise of embodied AI, where autonomous agents, such as humanoid robots, must navigate and manipulate unstructured environments with human-like adaptability. At the core of this challenge lies the concept of Neural Brain, a central intelligence system designed to drive embodied agents with human-like adaptability. A Neural Brain must seamlessly integrate multimodal sensing and perception with cognitive capabilities. Achieving this also requires an adaptive memory system and energy-efficient hardware-software co-design, enabling real-time action in dynamic environments. This paper introduces a unified framework for the Neural Brain of embodied agents, addressing two fundamental challenges: (1) defining the core components of Neural Brain and (2) bridging the gap between static AI models and the dynamic adaptability required for real-world deployment. To this end, we propose a biologically inspired architecture that integrates multimodal active sensing, perception-cognition-action function, neuroplasticity-based memory storage and updating, and neuromorphic hardware/software optimization. Furthermore, we also review the latest research on embodied agents across these four aspects and analyze the gap between current AI systems and human intelligence. By synthesizing insights from neuroscience, we outline a roadmap towards the development of generalizable, autonomous agents capable of human-level intelligence in real-world scenarios.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "comments": "51 pages, 17 figures, 9 tables", "pdf_url": "https://arxiv.org/pdf/2505.07634.pdf", "abstract_url": "https://arxiv.org/abs/2505.07634", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"]}
{"id": "2505.06740", "title": "Boundary-Guided Trajectory Prediction for Road Aware and Physically Feasible Autonomous Driving", "authors": ["Ahmed Abouelazm", "Mianzhi Liu", "Christian Hubschneider", "Yin Wu", "Daniel Slieter", "J. Marius Zöllner"], "abstract": "Accurate prediction of surrounding road users' trajectories is essential for safe and efficient autonomous driving. While deep learning models have improved performance, challenges remain in preventing off-road predictions and ensuring kinematic feasibility. Existing methods incorporate road-awareness modules and enforce kinematic constraints but lack plausibility guarantees and often introduce trade-offs in complexity and flexibility. This paper proposes a novel framework that formulates trajectory prediction as a constrained regression guided by permissible driving directions and their boundaries. Using the agent's current state and an HD map, our approach defines the valid boundaries and ensures on-road predictions by training the network to learn superimposed paths between left and right boundary polylines. To guarantee feasibility, the model predicts acceleration profiles that determine the vehicle's travel distance along these paths while adhering to kinematic constraints. We evaluate our approach on the Argoverse-2 dataset against the HPTR baseline. Our approach shows a slight decrease in benchmark metrics compared to HPTR but notably improves final displacement error and eliminates infeasible trajectories. Moreover, the proposed approach has superior generalization to less prevalent maneuvers and unseen out-of-distribution scenarios, reducing the off-road rate under adversarial attacks from 66\\% to just 1\\%. These results highlight the effectiveness of our approach in generating feasible and robust predictions.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": "Accepted in the 36th IEEE Intelligent Vehicles Symposium (IV 2025)", "pdf_url": "https://arxiv.org/pdf/2505.06740.pdf", "abstract_url": "https://arxiv.org/abs/2505.06740", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.06743", "title": "TPK: Trustworthy Trajectory Prediction Integrating Prior Knowledge For Interpretability and Kinematic Feasibility", "authors": ["Marius Baden", "Ahmed Abouelazm", "Christian Hubschneider", "Yin Wu", "Daniel Slieter", "J. Marius Zöllner"], "abstract": "Trajectory prediction is crucial for autonomous driving, enabling vehicles to navigate safely by anticipating the movements of surrounding road users. However, current deep learning models often lack trustworthiness as their predictions can be physically infeasible and illogical to humans. To make predictions more trustworthy, recent research has incorporated prior knowledge, like the social force model for modeling interactions and kinematic models for physical realism. However, these approaches focus on priors that suit either vehicles or pedestrians and do not generalize to traffic with mixed agent classes. We propose incorporating interaction and kinematic priors of all agent classes--vehicles, pedestrians, and cyclists with class-specific interaction layers to capture agent behavioral differences. To improve the interpretability of the agent interactions, we introduce DG-SFM, a rule-based interaction importance score that guides the interaction layer. To ensure physically feasible predictions, we proposed suitable kinematic models for all agent classes with a novel pedestrian kinematic model. We benchmark our approach on the Argoverse 2 dataset, using the state-of-the-art transformer HPTR as our baseline. Experiments demonstrate that our method improves interaction interpretability, revealing a correlation between incorrect predictions and divergence from our interaction prior. Even though incorporating the kinematic models causes a slight decrease in accuracy, they eliminate infeasible trajectories found in the dataset and the baseline model. Thus, our approach fosters trust in trajectory prediction as its interaction reasoning is interpretable, and its predictions adhere to physics.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": "Accepted in the 36th IEEE Intelligent Vehicles Symposium (IV 2025) for oral presentation", "pdf_url": "https://arxiv.org/pdf/2505.06743.pdf", "abstract_url": "https://arxiv.org/abs/2505.06743", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.07815", "title": "Imagine, Verify, Execute: Memory-Guided Agentic Exploration with Vision-Language Models", "authors": ["Seungjae Lee", "Daniel Ekpo", "Haowen Liu", "Furong Huang", "Abhinav Shrivastava", "Jia-Bin Huang"], "abstract": "Exploration is essential for general-purpose robotic learning, especially in open-ended environments where dense rewards, explicit goals, or task-specific supervision are scarce. Vision-language models (VLMs), with their semantic reasoning over objects, spatial relations, and potential outcomes, present a compelling foundation for generating high-level exploratory behaviors. However, their outputs are often ungrounded, making it difficult to determine whether imagined transitions are physically feasible or informative. To bridge the gap between imagination and execution, we present IVE (Imagine, Verify, Execute), an agentic exploration framework inspired by human curiosity. Human exploration is often driven by the desire to discover novel scene configurations and to deepen understanding of the environment. Similarly, IVE leverages VLMs to abstract RGB-D observations into semantic scene graphs, imagine novel scenes, predict their physical plausibility, and generate executable skill sequences through action tools. We evaluate IVE in both simulated and real-world tabletop environments. The results show that IVE enables more diverse and meaningful exploration than RL baselines, as evidenced by a 4.1 to 7.8x increase in the entropy of visited states. Moreover, the collected experience supports downstream learning, producing policies that closely match or exceed the performance of those trained on human-collected demonstrations.", "subjects": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.07815.pdf", "abstract_url": "https://arxiv.org/abs/2505.07815", "categories": ["Robotics (cs.RO)", "Computer Vision and Pattern Recognition (cs.CV)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"]}
{"id": "2505.06821", "title": "ThreatLens: LLM-guided Threat Modeling and Test Plan Generation for Hardware Security Verification", "authors": ["Dipayan Saha", "Hasan Al Shaikh", "Shams Tarek", "Farimah Farahmandi"], "abstract": "Current hardware security verification processes predominantly rely on manual threat modeling and test plan generation, which are labor-intensive, error-prone, and struggle to scale with increasing design complexity and evolving attack methodologies. To address these challenges, we propose ThreatLens, an LLM-driven multi-agent framework that automates security threat modeling and test plan generation for hardware security verification. ThreatLens integrates retrieval-augmented generation (RAG) to extract relevant security knowledge, LLM-powered reasoning for threat assessment, and interactive user feedback to ensure the generation of practical test plans. By automating these processes, the framework reduces the manual verification effort, enhances coverage, and ensures a structured, adaptable approach to security verification. We evaluated our framework on the NEORV32 SoC, demonstrating its capability to automate security verification through structured test plans and validating its effectiveness in real-world scenarios.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET)", "comments": "This paper has been presented at IEEE VLSI Test Symposium (VTS) 2025", "pdf_url": "https://arxiv.org/pdf/2505.06821.pdf", "abstract_url": "https://arxiv.org/abs/2505.06821", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Emerging Technologies (cs.ET)"], "matching_keywords": ["agent", "@RAG"]}
{"id": "2505.06913", "title": "RedTeamLLM: an Agentic AI framework for offensive security", "authors": ["Brian Challita", "Pierre Parrend"], "abstract": "From automated intrusion testing to discovery of zero-day attacks before software launch, agentic AI calls for great promises in security engineering. This strong capability is bound with a similar threat: the security and research community must build up its models before the approach is leveraged by malicious actors for cybercrime. We therefore propose and evaluate RedTeamLLM, an integrated architecture with a comprehensive security model for automatization of pentest tasks. RedTeamLLM follows three key steps: summarizing, reasoning and act, which embed its operational capacity. This novel framework addresses four open challenges: plan correction, memory management, context window constraint, and generality vs. specialization. Evaluation is performed through the automated resolution of a range of entry-level, but not trivial, CTF challenges. The contribution of the reasoning capability of our agentic AI framework is specifically evaluated.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.06913.pdf", "abstract_url": "https://arxiv.org/abs/2505.06913", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)"], "matching_keywords": ["agent", "agentic"]}
{"id": "2505.07064", "title": "ParaView-MCP: An Autonomous Visualization Agent with Direct Tool Use", "authors": ["Shusen Liu", "Haichao Miao", "Peer-Timo Bremer"], "abstract": "While powerful and well-established, tools like ParaView present a steep learning curve that discourages many potential users. This work introduces ParaView-MCP, an autonomous agent that integrates modern multimodal large language models (MLLMs) with ParaView to not only lower the barrier to entry but also augment ParaView with intelligent decision support. By leveraging the state-of-the-art reasoning, command execution, and vision capabilities of MLLMs, ParaView-MCP enables users to interact with ParaView through natural language and visual inputs. Specifically, our system adopted the Model Context Protocol (MCP) - a standardized interface for model-application communication - that facilitates direct interaction between MLLMs with ParaView's Python API to allow seamless information exchange between the user, the language model, and the visualization tool itself. Furthermore, by implementing a visual feedback mechanism that allows the agent to observe the viewport, we unlock a range of new capabilities, including recreating visualizations from examples, closed-loop visualization parameter updates based on user-defined goals, and even cross-application collaboration involving multiple tools. Broadly, we believe such an agent-driven visualization paradigm can profoundly change the way we interact with visualization tools. We expect a significant uptake in the development of such visualization tools, in both visualization research and industry.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.07064.pdf", "abstract_url": "https://arxiv.org/abs/2505.07064", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.07078", "title": "Can LLM-based Financial Investing Strategies Outperform the Market in Long Run?", "authors": ["Weixian Waylon Li", "Hyeonjun Kim", "Mihai Cucuringu", "Tiejun Ma"], "abstract": "Large Language Models (LLMs) have recently been leveraged for asset pricing tasks and stock trading applications, enabling AI agents to generate investment decisions from unstructured financial data. However, most evaluations of LLM timing-based investing strategies are conducted on narrow timeframes and limited stock universes, overstating effectiveness due to survivorship and data-snooping biases. We critically assess their generalizability and robustness by proposing FINSABER, a backtesting framework evaluating timing-based strategies across longer periods and a larger universe of symbols. Systematic backtests over two decades and 100+ symbols reveal that previously reported LLM advantages deteriorate significantly under broader cross-section and over a longer-term evaluation. Our market regime analysis further demonstrates that LLM strategies are overly conservative in bull markets, underperforming passive benchmarks, and overly aggressive in bear markets, incurring heavy losses. These findings highlight the need to develop LLM strategies that are able to prioritise trend detection and regime-aware risk controls over mere scaling of framework complexity.", "subjects": "Trading and Market Microstructure (q-fin.TR); Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE)", "comments": "14 pages", "pdf_url": "https://arxiv.org/pdf/2505.07078.pdf", "abstract_url": "https://arxiv.org/abs/2505.07078", "categories": ["Trading and Market Microstructure (q-fin.TR)", "Artificial Intelligence (cs.AI)", "Computational Engineering, Finance, and Science (cs.CE)"], "matching_keywords": ["agent"]}
{"id": "2505.07176", "title": "Internet of Agents: Fundamentals, Applications, and Challenges", "authors": ["Yuntao Wang", "Shaolong Guo", "Yanghe Pan", "Zhou Su", "Fahao Chen", "Tom H. Luan", "Peng Li", "Jiawen Kang", "Dusit Niyato"], "abstract": "With the rapid proliferation of large language models and vision-language models, AI agents have evolved from isolated, task-specific systems into autonomous, interactive entities capable of perceiving, reasoning, and acting without human intervention. As these agents proliferate across virtual and physical environments, from virtual assistants to embodied robots, the need for a unified, agent-centric infrastructure becomes paramount. In this survey, we introduce the Internet of Agents (IoA) as a foundational framework that enables seamless interconnection, dynamic discovery, and collaborative orchestration among heterogeneous agents at scale. We begin by presenting a general IoA architecture, highlighting its hierarchical organization, distinguishing features relative to the traditional Internet, and emerging applications. Next, we analyze the key operational enablers of IoA, including capability notification and discovery, adaptive communication protocols, dynamic task matching, consensus and conflict-resolution mechanisms, and incentive models. Finally, we identify open research directions toward building resilient and trustworthy IoA ecosystems.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": "22 pages,10 figures, 8 tables. Submitted to IEEE TCCN", "pdf_url": "https://arxiv.org/pdf/2505.07176.pdf", "abstract_url": "https://arxiv.org/abs/2505.07176", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.07236", "title": "UAV-CodeAgents: Scalable UAV Mission Planning via Multi-Agent ReAct and Vision-Language Reasoning", "authors": ["Oleg Sautenkov", "Yasheerah Yaqoot", "Muhammad Ahsan Mustafa", "Faryal Batool", "Jeffrin Sam", "Artem Lykov", "Chih-Yung Wen", "Dzmitry Tsetserukou"], "abstract": "We present UAV-CodeAgents, a scalable multi-agent framework for autonomous UAV mission generation, built on large language and vision-language models (LLMs/VLMs). The system leverages the ReAct (Reason + Act) paradigm to interpret satellite imagery, ground high-level natural language instructions, and collaboratively generate UAV trajectories with minimal human supervision. A core component is a vision-grounded, pixel-pointing mechanism that enables precise localization of semantic targets on aerial maps. To support real-time adaptability, we introduce a reactive thinking loop, allowing agents to iteratively reflect on observations, revise mission goals, and coordinate dynamically in evolving environments.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": "Submitted", "pdf_url": "https://arxiv.org/pdf/2505.07236.pdf", "abstract_url": "https://arxiv.org/abs/2505.07236", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.07457", "title": "Can Generative AI agents behave like humans? Evidence from laboratory market experiments", "authors": ["R. Maria del Rio-Chanona", "Marco Pangallo", "Cars Hommes"], "abstract": "We explore the potential of Large Language Models (LLMs) to replicate human behavior in economic market experiments. Compared to previous studies, we focus on dynamic feedback between LLM agents: the decisions of each LLM impact the market price at the current step, and so affect the decisions of the other LLMs at the next step. We compare LLM behavior to market dynamics observed in laboratory settings and assess their alignment with human participants' behavior. Our findings indicate that LLMs do not adhere strictly to rational expectations, displaying instead bounded rationality, similarly to human participants. Providing a minimal context window i.e. memory of three previous time steps, combined with a high variability setting capturing response heterogeneity, allows LLMs to replicate broad trends seen in human experiments, such as the distinction between positive and negative feedback markets. However, differences remain at a granular level--LLMs exhibit less heterogeneity in behavior than humans. These results suggest that LLMs hold promise as tools for simulating realistic human behavior in economic contexts, though further research is needed to refine their accuracy and increase behavioral diversity.", "subjects": "General Economics (econ.GN); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.07457.pdf", "abstract_url": "https://arxiv.org/abs/2505.07457", "categories": ["General Economics (econ.GN)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.07546", "title": "GRADA: Graph-based Reranker against Adversarial Documents Attack", "authors": ["Jingjie Zheng", "Aryo Pradipta Gema", "Giwon Hong", "Xuanli He", "Pasquale Minervini", "Youcheng Sun", "Qiongkai Xu"], "abstract": "Retrieval Augmented Generation (RAG) frameworks improve the accuracy of large language models (LLMs) by integrating external knowledge from retrieved documents, thereby overcoming the limitations of models' static intrinsic knowledge. However, these systems are susceptible to adversarial attacks that manipulate the retrieval process by introducing documents that are adversarial yet semantically similar to the query. Notably, while these adversarial documents resemble the query, they exhibit weak similarity to benign documents in the retrieval set. Thus, we propose a simple yet effective Graph-based Reranking against Adversarial Document Attacks (GRADA) framework aiming at preserving retrieval quality while significantly reducing the success of adversaries. Our study evaluates the effectiveness of our approach through experiments conducted on five LLMs: GPT-3.5-Turbo, GPT-4o, Llama3.1-8b, Llama3.1-70b, and Qwen2.5-7b. We use three datasets to assess performance, with results from the Natural Questions dataset demonstrating up to an 80% reduction in attack success rates while maintaining minimal loss in accuracy.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.07546.pdf", "abstract_url": "https://arxiv.org/abs/2505.07546", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"]}
{"id": "2505.07553", "title": "Towards Requirements Engineering for RAG Systems", "authors": ["Tor Sporsem", "Rasmus Ulfsnes"], "abstract": "This short paper explores how a maritime company develops and integrates large-language models (LLM). Specifically by looking at the requirements engineering for Retrieval Augmented Generation (RAG) systems in expert settings. Through a case study at a maritime service provider, we demonstrate how data scientists face a fundamental tension between user expectations of AI perfection and the correctness of the generated outputs. Our findings reveal that data scientists must identify context-specific \"retrieval requirements\" through iterative experimentation together with users because they are the ones who can determine correctness. We present an empirical process model describing how data scientists practically elicited these \"retrieval requirements\" and managed system limitations. This work advances software engineering knowledge by providing insights into the specialized requirements engineering processes for implementing RAG systems in complex domain-specific applications.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": "Accepted to EASE 2025, 17-20 June, Istanbul, Turkey", "pdf_url": "https://arxiv.org/pdf/2505.07553.pdf", "abstract_url": "https://arxiv.org/abs/2505.07553", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"]}
