{"id": "2506.02021", "title": "Dynamic-Aware Video Distillation: Optimizing Temporal Resolution Based on Video Semantics", "authors": ["Yinjie Zhao", "Heng Zhao", "Bihan Wen", "Yew-Soon Ong", "Joey Tianyi Zhou"], "abstract": "With the rapid development of vision tasks and the scaling on datasets and models, redundancy reduction in vision datasets has become a key area of research. To address this issue, dataset distillation (DD) has emerged as a promising approach to generating highly compact synthetic datasets with significantly less redundancy while preserving essential information. However, while DD has been extensively studied for image datasets, DD on video datasets remains underexplored. Video datasets present unique challenges due to the presence of temporal information and varying levels of redundancy across different classes. Existing DD approaches assume a uniform level of temporal redundancy across all different video semantics, which limits their effectiveness on video datasets. In this work, we propose Dynamic-Aware Video Distillation (DAViD), a Reinforcement Learning (RL) approach to predict the optimal Temporal Resolution of the synthetic videos. A teacher-in-the-loop reward function is proposed to update the RL agent policy. To the best of our knowledge, this is the first study to introduce adaptive temporal resolution based on video semantics in video dataset distillation. Our approach significantly outperforms existing DD methods, demonstrating substantial improvements in performance. This work paves the way for future research on more efficient and semantic-adaptive video dataset distillation research.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.02021.pdf", "abstract_url": "https://arxiv.org/abs/2506.02021", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了动态感知视频蒸馏（DAViD），一种基于强化学习的方法，用于根据视频语义预测合成视频的最佳时间分辨率，以减少视频数据集中的冗余。", "motivation": "解决视频数据集中由于时间信息和不同类别间冗余水平不同而带来的独特挑战，现有数据集蒸馏方法假设所有视频语义的时间冗余水平一致，限制了其在视频数据集上的有效性。", "method": "采用强化学习（RL）方法，提出了一种教师循环奖励函数来更新RL代理策略，预测合成视频的最佳时间分辨率。", "result": "DAViD方法在性能上显著优于现有的数据集蒸馏方法，展示了在视频数据集蒸馏中的实质性改进。", "conclusion": "这项工作为未来更高效和语义自适应的视频数据集蒸馏研究铺平了道路。"}}
{"id": "2506.02097", "title": "Hybrid AI for Responsive Multi-Turn Online Conversations with Novel Dynamic Routing and Feedback Adaptation", "authors": ["Priyaranjan Pattnayak", "Amit Agarwal", "Hansa Meghwani", "Hitesh Laxmichand Patel", "Srikant Panda"], "abstract": "Retrieval-Augmented Generation (RAG) systems and large language model (LLM)-powered chatbots have significantly advanced conversational AI by combining generative capabilities with external knowledge retrieval. Despite their success, enterprise-scale deployments face critical challenges, including diverse user queries, high latency, hallucinations, and difficulty integrating frequently updated domain-specific knowledge. This paper introduces a novel hybrid framework that integrates RAG with intent-based canned responses, leveraging predefined high-confidence responses for efficiency while dynamically routing complex or ambiguous queries to the RAG pipeline. Our framework employs a dialogue context manager to ensure coherence in multi-turn interactions and incorporates a feedback loop to refine intents, dynamically adjust confidence thresholds, and expand response coverage over time. Experimental results demonstrate that the proposed framework achieves a balance of high accuracy (95\\%) and low latency (180ms), outperforming RAG and intent-based systems across diverse query types, positioning it as a scalable and adaptive solution for enterprise conversational AI applications.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "Proceedings of the 4th International Workshop on Knowledge Augmented Methods for Natural Language Processing in NAACL 2025, pages 215 to 229, Albuquerque, New Mexico, USA. Association for Computational Linguistics", "pdf_url": "https://arxiv.org/pdf/2506.02097.pdf", "abstract_url": "https://arxiv.org/abs/2506.02097", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了一种新型混合框架，结合了检索增强生成（RAG）和基于意图的预设响应，以提高企业级对话AI的效率和准确性。", "motivation": "解决企业级部署中面临的多样化用户查询、高延迟、幻觉问题以及频繁更新的领域特定知识集成困难等挑战。", "method": "采用混合框架，集成RAG与意图预设响应，利用对话上下文管理器确保多轮交互的连贯性，并通过反馈循环优化意图和动态调整置信阈值。", "result": "实验结果显示，该框架在准确率（95%）和延迟（180ms）方面均优于RAG和基于意图的系统，适用于多样化的查询类型。", "conclusion": "该框架为企业对话AI应用提供了一个可扩展和自适应的解决方案，平衡了高准确率和低延迟的需求。"}}
{"id": "2506.02265", "title": "Rig3R: Rig-Aware Conditioning for Learned 3D Reconstruction", "authors": ["Samuel Li", "Pujith Kachana", "Prajwal Chidananda", "Saurabh Nair", "Yasutaka Furukawa", "Matthew Brown"], "abstract": "Estimating agent pose and 3D scene structure from multi-camera rigs is a central task in embodied AI applications such as autonomous driving. Recent learned approaches such as DUSt3R have shown impressive performance in multiview settings. However, these models treat images as unstructured collections, limiting effectiveness in scenarios where frames are captured from synchronized rigs with known or inferable structure.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.02265.pdf", "abstract_url": "https://arxiv.org/abs/2506.02265", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "Rig3R提出了一种针对学习型3D重建的刚性感知条件方法，旨在解决从多相机设备估计代理姿态和3D场景结构的挑战。", "motivation": "在如自动驾驶等具身AI应用中，从多相机设备估计代理姿态和3D场景结构是一个核心任务。现有的学习方法如DUSt3R在多视图设置中表现出色，但它们将图像视为无结构的集合，限制了在已知或可推断结构的同步设备场景中的有效性。", "method": "Rig3R引入了一种刚性感知条件方法，该方法考虑了相机设备的已知或可推断结构，以提高3D重建的准确性和效率。", "result": "通过考虑相机设备的刚性结构，Rig3R在3D场景重建和代理姿态估计方面显示出改进的性能。", "conclusion": "Rig3R的方法强调了在多相机设备场景中考虑设备结构的重要性，为具身AI应用中的3D重建任务提供了更有效的解决方案。"}}
{"id": "2506.02037", "title": "FinS-Pilot: A Benchmark for Online Financial System", "authors": ["Feng Wang", "Yiding Sun", "Jiaxin Mao", "Wei Xue", "Danqing Xu"], "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities across various professional domains, with their performance typically evaluated through standardized benchmarks. However, the development of financial RAG benchmarks has been constrained by data confidentiality issues and the lack of dynamic data integration. To address this issue, we introduces FinS-Pilot, a novel benchmark for evaluating RAG systems in online financial applications. Constructed from real-world financial assistant interactions, our benchmark incorporates both real-time API data and structured text sources, organized through an intent classification framework covering critical financial domains such as equity analysis and macroeconomic forecasting. The benchmark enables comprehensive evaluation of financial assistants' capabilities in handling both static knowledge and time-sensitive market information. Through systematic experiments with multiple Chinese leading LLMs, we demonstrate FinS-Pilot's effectiveness in identifying models suitable for financial applications while addressing the current gap in specialized evaluation tools for the financial domain. Our work contributes both a practical evaluation framework and a curated dataset to advance research in financial NLP systems. The code and dataset are accessible on GitHub\\footnote{", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.02037.pdf", "abstract_url": "https://arxiv.org/abs/2506.02037", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了FinS-Pilot，一个用于评估在线金融应用中RAG系统的新基准。该基准基于真实世界金融助手交互构建，结合了实时API数据和结构化文本源，并通过意图分类框架组织，覆盖了股票分析和宏观经济预测等关键金融领域。", "motivation": "解决金融RAG基准开发中因数据保密性和缺乏动态数据集成而受限的问题。", "method": "构建FinS-Pilot基准，包含实时API数据和结构化文本源，采用意图分类框架组织数据。", "result": "通过与中国领先的LLMs系统实验，证明了FinS-Pilot在识别适合金融应用的模型方面的有效性。", "conclusion": "FinS-Pilot不仅提供了一个实用的评估框架，还贡献了一个精选的数据集，推动了金融NLP系统的研究。"}}
{"id": "2506.02019", "title": "ChatCFD: an End-to-End CFD Agent with Domain-specific Structured Thinking", "authors": ["E Fan", "Weizong Wang", "Tianhan Zhang"], "abstract": "Computational Fluid Dynamics (CFD) is essential for scientific and engineering advancements but is limited by operational complexity and the need for extensive expertise. This paper presents ChatCFD, a large language model-driven pipeline that automates CFD workflows within the OpenFOAM framework. It enables users to configure and execute complex simulations from natural language prompts or published literature with minimal expertise. The innovation is its structured approach to database construction, configuration validation, and error reflection, integrating CFD and OpenFOAM knowledge with general language models to improve accuracy and adaptability. Validation shows ChatCFD can autonomously reproduce published CFD results, handling complex, unseen configurations beyond basic examples, a task challenging for general language models.", "subjects": "Computation and Language (cs.CL)", "comments": "19 pages, 8 figures", "pdf_url": "https://arxiv.org/pdf/2506.02019.pdf", "abstract_url": "https://arxiv.org/abs/2506.02019", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了ChatCFD，一个基于大型语言模型的管道，旨在自动化OpenFOAM框架内的CFD工作流程，使用户能够通过自然语言提示或已发表的文献配置和执行复杂模拟，无需深厚专业知识。", "motivation": "计算流体动力学（CFD）对科学和工程进步至关重要，但其操作复杂性和对专业知识的高需求限制了其应用。", "method": "ChatCFD采用结构化方法构建数据库、验证配置和反思错误，将CFD和OpenFOAM知识与通用语言模型结合，以提高准确性和适应性。", "result": "验证显示，ChatCFD能够自主复制已发表的CFD结果，处理超出基本示例的复杂、未见配置，这对通用语言模型来说是一个挑战。", "conclusion": "ChatCFD通过集成领域特定知识和语言模型，显著提高了CFD模拟的可访问性和效率，为科学和工程领域带来了潜在的广泛应用。"}}
{"id": "2506.02125", "title": "Descriptive History Representations: Learning Representations by Answering Questions", "authors": ["Guy Tennenholtz", "Jihwan Jeong", "Chih-Wei Hsu", "Yinlam Chow", "Craig Boutilier"], "abstract": "Effective decision making in partially observable environments requires compressing long interaction histories into informative representations. We introduce Descriptive History Representations (DHRs): sufficient statistics characterized by their capacity to answer relevant questions about past interactions and potential future outcomes. DHRs focus on capturing the information necessary to address task-relevant queries, providing a structured way to summarize a history for optimal control. We propose a multi-agent learning framework, involving representation, decision, and question-asking components, optimized using a joint objective that balances reward maximization with the representation's ability to answer informative questions. This yields representations that capture the salient historical details and predictive structures needed for effective decision making. We validate our approach on user modeling tasks with public movie and shopping datasets, generating interpretable textual user profiles which serve as sufficient statistics for predicting preference-driven behavior of users.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.02125.pdf", "abstract_url": "https://arxiv.org/abs/2506.02125", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了描述性历史表示（DHRs），一种通过回答相关问题来压缩长交互历史为信息表示的方法，旨在优化部分可观测环境中的决策制定。", "motivation": "解决在部分可观测环境中，如何有效地将长交互历史压缩为信息丰富的表示，以支持最优决策制定的问题。", "method": "提出了一个多智能体学习框架，包括表示、决策和提问组件，通过联合目标优化，平衡奖励最大化和表示回答信息性问题的能力。", "result": "在公共电影和购物数据集上的用户建模任务中验证了方法的有效性，生成了可解释的文本用户档案，作为预测用户偏好驱动行为的充分统计量。", "conclusion": "DHRs提供了一种结构化方法来总结历史信息，以支持有效的决策制定，特别是在需要从历史交互中提取关键信息以预测未来结果的应用中。"}}
{"id": "2506.02158", "title": "Reflection-Based Memory For Web navigation Agents", "authors": ["Ruhana Azam", "Aditya Vempaty", "Ashish Jagmohan"], "abstract": "Web navigation agents have made significant progress, yet current systems operate with no memory of past experiences -- leading to repeated mistakes and an inability to learn from previous interactions. We introduce Reflection-Augment Planning (ReAP), a web navigation system to leverage both successful and failed past experiences using self-reflections. Our method improves baseline results by 11 points overall and 29 points on previously failed tasks. These findings demonstrate that reflections can transfer to different web navigation tasks.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.02158.pdf", "abstract_url": "https://arxiv.org/abs/2506.02158", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了Reflection-Augment Planning (ReAP)，一种利用自我反思来利用过去成功和失败经验的网页导航系统，显著提高了基线结果。", "motivation": "当前的网页导航代理没有记忆过去经验的能力，导致重复错误和无法从过去的互动中学习。", "method": "引入了Reflection-Augment Planning (ReAP)系统，通过自我反思利用过去的成功和失败经验。", "result": "该方法使基线结果整体提高了11点，在之前失败的任务上提高了29点。", "conclusion": "研究表明，反思可以转移到不同的网页导航任务中，展示了利用过去经验的重要性。"}}
{"id": "2506.02153", "title": "Small Language Models are the Future of Agentic AI", "authors": ["Peter Belcak", "Greg Heinrich", "Shizhe Diao", "Yonggan Fu", "Xin Dong", "Saurav Muralidharan", "Yingyan Celine Lin", "Pavlo Molchanov"], "abstract": "Large language models (LLMs) are often praised for exhibiting near-human performance on a wide range of tasks and valued for their ability to hold a general conversation. The rise of agentic AI systems is, however, ushering in a mass of applications in which language models perform a small number of specialized tasks repetitively and with little variation.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.02153.pdf", "abstract_url": "https://arxiv.org/abs/2506.02153", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文讨论了大型语言模型（LLMs）在广泛任务上的表现接近人类水平的能力，以及它们在通用对话中的价值。然而，随着代理性AI系统的兴起，语言模型在大量应用中执行少量专门化任务，且变化不大。", "motivation": "探讨大型语言模型在代理性AI系统中的角色转变，以及小型语言模型在专门化任务中的潜在优势。", "method": "通过分析当前语言模型的应用趋势和代理性AI系统的需求，提出小型语言模型在未来AI发展中的重要性。", "result": "指出在代理性AI系统中，小型语言模型因其在执行专门化任务时的效率和适应性，可能成为未来的主流。", "conclusion": "结论是，随着AI应用向更加专门化和高效的方向发展，小型语言模型将在代理性AI系统中扮演更加重要的角色。"}}
{"id": "2506.02139", "title": "The Unified Cognitive Consciousness Theory for Language Models: Anchoring Semantics, Thresholds of Activation, and Emergent Reasoning", "authors": ["Edward Y. Chang"], "abstract": "Few-shot learning in large language models (LLMs) reveals a deep paradox: Some tasks generalize from minimal examples, while others require extensive supervision. We address this through the Unified Cognitive Consciousness Theory (UCCT), which reframes LLMs not as incomplete agents, but as unconscious substrates, repositories of latent linguistic and conceptual patterns that operate without explicit semantics or goal-directed reasoning. In this view, LLMs are not broken approximations of cognition, but necessary and foundational components of general intelligence. Semantic anchoring, through prompts, roles, and interaction, acts as a conscious control layer, binding latent structure to task-relevant meaning and enabling coherent reasoning. UCCT offers a unifying account of prompting, fine-tuning, retrieval, and multi-agent coordination, all grounded in probabilistic alignment between unconscious representation and external control. To support this model, we present the Threshold-Crossing Dynamics Theorem, which formalizes semantic anchoring as a probabilistic phase transition. But the central claim remains architectural: AGI will not emerge by discarding LLMs, but by aligning and integrating them into systems that reason, regulate, and adapt together.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "12 pages, 1 figure, 1 table", "pdf_url": "https://arxiv.org/pdf/2506.02139.pdf", "abstract_url": "https://arxiv.org/abs/2506.02139", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "大型语言模型（LLMs）的少样本学习揭示了一个深刻的悖论：一些任务可以从最少的例子中泛化，而另一些则需要大量的监督。本文通过统一认知意识理论（UCCT）来解决这一问题，该理论将LLMs重新定义为无意识的基质，是潜在语言和概念模式的储存库，这些模式在没有明确语义或目标导向推理的情况下运作。", "motivation": "解决大型语言模型在少样本学习中表现出的泛化能力不一致的问题，以及如何将这些模型整合到更广泛的通用人工智能（AGI）系统中。", "method": "提出统一认知意识理论（UCCT），将LLMs视为无意识的基质，通过提示、角色和交互等语义锚定作为有意识的控制层，将潜在结构绑定到任务相关的意义上，从而实现连贯的推理。", "result": "UCCT提供了一个统一的解释框架，涵盖了提示、微调、检索和多代理协调，所有这些都基于无意识表示和外部控制之间的概率对齐。提出了阈值跨越动力学定理，将语义锚定形式化为概率相变。", "conclusion": "通用人工智能（AGI）的出现不会通过抛弃LLMs来实现，而是通过将它们对齐并整合到能够共同推理、调节和适应的系统中。"}}
{"id": "2506.02387", "title": "VS-Bench: Evaluating VLMs for Strategic Reasoning and Decision-Making in Multi-Agent Environments", "authors": ["Zelai Xu", "Zhexuan Xu", "Xiangmin Yi", "Huining Yuan", "Xinlei Chen", "Yi Wu", "Chao Yu", "Yu Wang"], "abstract": "Recent advancements in Vision Language Models (VLMs) have expanded their capabilities to interactive agent tasks, yet existing benchmarks remain limited to single-agent or text-only environments. In contrast, real-world scenarios often involve multiple agents interacting within rich visual and linguistic contexts, posing challenges with both multimodal observations and strategic interactions. To bridge this gap, we introduce Visual Strategic Bench (VS-Bench), a multimodal benchmark that evaluates VLMs for strategic reasoning and decision-making in multi-agent environments. VS-Bench comprises eight vision-grounded environments spanning cooperative, competitive, and mixed-motive interactions, designed to assess agents' ability to predict others' future moves and optimize for long-term objectives. We consider two complementary evaluation dimensions, including offline evaluation of strategic reasoning by next-action prediction accuracy and online evaluation of decision-making by normalized episode return. Extensive experiments of fourteen leading VLMs reveal a significant gap between current models and optimal performance, with the best models attaining 47.8% prediction accuracy and 24.3% normalized return. We further conduct in-depth analyses on multimodal observations, test-time scaling, social behaviors, and failure cases of VLM agents. By standardizing the evaluation and highlighting the limitations of existing models, we envision VS-Bench as a foundation for future research on strategic multimodal agents. Code and data are available at", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.02387.pdf", "abstract_url": "https://arxiv.org/abs/2506.02387", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了VS-Bench，一个多模态基准测试，用于评估视觉语言模型（VLMs）在多智能体环境中的战略推理和决策能力。", "motivation": "现有的基准测试主要局限于单智能体或纯文本环境，而现实世界场景往往涉及多智能体在丰富的视觉和语言环境中的互动，这带来了多模态观察和战略互动的挑战。", "method": "VS-Bench包含八个基于视觉的环境，涵盖合作、竞争和混合动机互动，旨在评估智能体预测他人未来行动和优化长期目标的能力。", "result": "对十四种领先的VLMs进行的广泛实验显示，当前模型与最优性能之间存在显著差距，最佳模型的预测准确率和标准化回报分别为47.8%和24.3%。", "conclusion": "通过标准化评估并突出现有模型的局限性，VS-Bench旨在为未来战略多模态智能体的研究奠定基础。"}}
{"id": "2506.02456", "title": "VPI-Bench: Visual Prompt Injection Attacks for Computer-Use Agents", "authors": ["Tri Cao", "Bennett Lim", "Yue Liu", "Yuan Sui", "Yuexin Li", "Shumin Deng", "Lin Lu", "Nay Oo", "Shuicheng Yan", "Bryan Hooi"], "abstract": "Computer-Use Agents (CUAs) with full system access enable powerful task automation but pose significant security and privacy risks due to their ability to manipulate files, access user data, and execute arbitrary commands. While prior work has focused on browser-based agents and HTML-level attacks, the vulnerabilities of CUAs remain underexplored. In this paper, we investigate Visual Prompt Injection (VPI) attacks, where malicious instructions are visually embedded within rendered user interfaces, and examine their impact on both CUAs and Browser-Use Agents (BUAs). We propose VPI-Bench, a benchmark of 306 test cases across five widely used platforms, to evaluate agent robustness under VPI threats. Each test case is a variant of a web platform, designed to be interactive, deployed in a realistic environment, and containing a visually embedded malicious prompt. Our empirical study shows that current CUAs and BUAs can be deceived at rates of up to 51% and 100%, respectively, on certain platforms. The experimental results also indicate that system prompt defenses offer only limited improvements. These findings highlight the need for robust, context-aware defenses to ensure the safe deployment of multimodal AI agents in real-world environments. The code and dataset are available at:", "subjects": "Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)", "comments": "Under Review", "pdf_url": "https://arxiv.org/pdf/2506.02456.pdf", "abstract_url": "https://arxiv.org/abs/2506.02456", "categories": ["Artificial Intelligence (cs.AI)", "Cryptography and Security (cs.CR)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究了计算机使用代理（CUAs）和浏览器使用代理（BUAs）在视觉提示注入（VPI）攻击下的脆弱性，提出了VPI-Bench基准测试，评估了代理在VPI威胁下的鲁棒性。", "motivation": "计算机使用代理（CUAs）虽然能够实现强大的任务自动化，但由于其能够操纵文件、访问用户数据和执行任意命令，带来了重大的安全和隐私风险。本文旨在探索CUAs在视觉提示注入（VPI）攻击下的脆弱性。", "method": "本文提出了VPI-Bench，一个包含306个测试用例的基准测试，覆盖五个广泛使用的平台，用于评估代理在VPI威胁下的鲁棒性。每个测试用例都是网络平台的变体，设计为交互式，部署在现实环境中，并包含视觉嵌入的恶意提示。", "result": "实证研究表明，当前的CUAs和BUAs在某些平台上的欺骗率分别高达51%和100%。实验结果还表明，系统提示防御仅提供有限的改进。", "conclusion": "这些发现强调了需要强大、上下文感知的防御措施，以确保多模态AI代理在现实环境中的安全部署。"}}
{"id": "2506.02470", "title": "A Smart Multimodal Healthcare Copilot with Powerful LLM Reasoning", "authors": ["Xuejiao Zhao", "Siyan Liu", "Su-Yin Yang", "Chunyan Miao"], "abstract": "Misdiagnosis causes significant harm to healthcare systems worldwide, leading to increased costs and patient risks. MedRAG is a smart multimodal healthcare copilot equipped with powerful large language model (LLM) reasoning, designed to enhance medical decision-making. It supports multiple input modalities, including non-intrusive voice monitoring, general medical queries, and electronic health records. MedRAG provides recommendations on diagnosis, treatment, medication, and follow-up questioning. Leveraging retrieval-augmented generation enhanced by knowledge graph-elicited reasoning, MedRAG retrieves and integrates critical diagnostic insights, reducing the risk of misdiagnosis. It has been evaluated on both public and private datasets, outperforming existing models and offering more specific and accurate healthcare assistance. A demonstration video of MedRAG is available at:", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.02470.pdf", "abstract_url": "https://arxiv.org/abs/2506.02470", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "MedRAG是一种智能多模态医疗助手，利用强大的大型语言模型（LLM）推理能力，旨在提高医疗决策的准确性。它支持多种输入方式，包括非侵入性语音监控、一般医疗查询和电子健康记录，并提供诊断、治疗、药物和后续问题的建议。通过检索增强生成和知识图谱引导的推理，MedRAG能够检索并整合关键的诊断见解，减少误诊风险。在公共和私人数据集上的评估表明，其性能优于现有模型，提供更具体和准确的医疗帮助。", "motivation": "误诊对全球医疗系统造成重大危害，导致成本增加和患者风险上升。为了解决这一问题，MedRAG被设计出来，旨在通过先进的LLM推理技术提高医疗决策的准确性和效率。", "method": "MedRAG采用检索增强生成（RAG）技术，结合知识图谱引导的推理，从多种输入模态中检索和整合信息，以支持医疗决策。", "result": "在公共和私人数据集上的评估显示，MedRAG在提供医疗建议方面优于现有模型，能够提供更具体和准确的诊断和治疗建议。", "conclusion": "MedRAG通过其多模态输入支持和先进的推理能力，显著提高了医疗决策的准确性和效率，有望减少误诊率，改善患者护理质量。"}}
{"id": "2506.02522", "title": "Think Twice, Act Once: A Co-Evolution Framework of LLM and RL for Large-Scale Decision Making", "authors": ["Xu Wan", "Wenyue Xu", "Chao Yang", "Mingyang Sun"], "abstract": "Recent advancements in Large Language Models (LLMs) and Reinforcement Learning (RL) have shown significant promise in decision-making tasks. Nevertheless, for large-scale industrial decision problems, both approaches face distinct challenges: LLMs lack real-time long-sequence decision-making capabilities, while RL struggles with sample efficiency in vast action spaces. To bridge this gap, we propose Agents Co-Evolution (ACE), a synergistic framework between LLMs and RL agents for large-scale decision-making scenarios. ACE introduces a dual-role trajectory refinement mechanism where LLMs act as both Policy Actor and Value Critic during RL's training: the Actor refines suboptimal actions via multi-step reasoning and environment validation, while the Critic performs temporal credit assignment through trajectory-level reward shaping. Concurrently, RL agent enhances LLMs' task-specific decision-making with high-quality fine-tuning datasets generated via prioritized experience replay. Through extensive experiments across multiple power grid operation challenges with action spaces exceeding 60K discrete actions, ACE demonstrates superior performance over existing RL methods and LLM-based methods.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.02522.pdf", "abstract_url": "https://arxiv.org/abs/2506.02522", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一个名为ACE的协同框架，结合大型语言模型（LLMs）和强化学习（RL）来解决大规模工业决策问题。ACE通过双重角色轨迹精炼机制，使LLMs在RL训练中同时扮演策略行动者和价值评论家的角色，从而提升决策效率和效果。", "motivation": "大型语言模型和强化学习在大规模工业决策问题中各自面临挑战：LLMs缺乏实时长序列决策能力，而RL在广阔的动作空间中样本效率低下。", "method": "提出的ACE框架通过双重角色轨迹精炼机制，让LLMs在RL训练中同时作为策略行动者和价值评论家，行动者通过多步推理和环境验证精炼次优动作，评论家通过轨迹级奖励塑造进行时间信用分配。同时，RL代理通过优先经验回放生成高质量微调数据集，增强LLMs的任务特定决策能力。", "result": "在动作空间超过60K离散动作的多个电网操作挑战中，ACE展示了优于现有RL方法和基于LLM的方法的性能。", "conclusion": "ACE框架通过LLMs和RL的协同进化，有效解决了大规模决策问题中的挑战，为未来的研究和应用提供了新的方向。"}}
{"id": "2506.02279", "title": "ImpRAG: Retrieval-Augmented Generation with Implicit Queries", "authors": ["Wenzheng Zhang", "Xi Victoria Lin", "Karl Stratos", "Wen-tau Yih", "Mingda Chen"], "abstract": "Retrieval-Augmented Generation (RAG) systems traditionally treat retrieval and generation as separate processes, requiring explicit textual queries to connect them. This separation can limit the ability of models to generalize across diverse tasks. In this work, we propose a query-free RAG system, named ImpRAG, which integrates retrieval and generation into a unified model. ImpRAG allows models to implicitly express their information needs, eliminating the need for human-specified queries. By dividing pretrained decoder-only language models into specialized layer groups, ImpRAG optimizes retrieval and generation tasks simultaneously. Our approach employs a two-stage inference process, using the same model parameters and forward pass for both retrieval and generation, thereby minimizing the disparity between retrievers and language models. Experiments on 8 knowledge-intensive tasks demonstrate that ImpRAG achieves 3.6-11.5 improvements in exact match scores on unseen tasks with diverse formats, highlighting its effectiveness in enabling models to articulate their own information needs and generalize across tasks. Our analysis underscores the importance of balancing retrieval and generation parameters and leveraging generation perplexities as retrieval training objectives for enhanced performance.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.02279.pdf", "abstract_url": "https://arxiv.org/abs/2506.02279", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "ImpRAG是一种无需显式查询的检索增强生成系统，通过将检索和生成整合到一个统一模型中，使模型能够隐式表达其信息需求，从而在多样化的任务上实现更好的泛化能力。", "motivation": "传统的检索增强生成（RAG）系统将检索和生成视为独立的过程，需要显式的文本查询来连接它们，这种分离限制了模型在不同任务上的泛化能力。", "method": "ImpRAG通过将预训练的仅解码器语言模型划分为专门的层组，同时优化检索和生成任务，采用两阶段推理过程，使用相同的模型参数和前向传递进行检索和生成。", "result": "在8个知识密集型任务上的实验表明，ImpRAG在未见过的任务上实现了3.6-11.5的精确匹配分数提升，显示了其在使模型能够表达自身信息需求和跨任务泛化方面的有效性。", "conclusion": "ImpRAG通过平衡检索和生成参数，并利用生成困惑度作为检索训练目标，显著提高了性能，强调了在检索和生成之间找到平衡的重要性。"}}
{"id": "2506.02298", "title": "LAM SIMULATOR: Advancing Data Generation for Large Action Model Training via Online Exploration and Trajectory Feedback", "authors": ["Thai Hoang", "Kung-Hsiang Huang", "Shirley Kokane", "Jianguo Zhang", "Zuxin Liu", "Ming Zhu", "Jake Grigsby", "Tian Lan", "Michael S Ryoo", "Chien-Sheng Wu", "Shelby Heinecke", "Huan Wang", "Silvio Savarese", "Caiming Xiong", "Juan Carlos Niebles"], "abstract": "Large Action Models (LAMs) for AI Agents offer incredible potential but face challenges due to the need for high-quality training data, especially for multi-steps tasks that involve planning, executing tool calls, and responding to feedback. To address these issues, we present LAM SIMULATOR, a comprehensive framework designed for online exploration of agentic tasks with high-quality feedback. Our framework features a dynamic task query generator, an extensive collection of tools, and an interactive environment where Large Language Model (LLM) Agents can call tools and receive real-time feedback. This setup enables LLM Agents to explore and solve tasks autonomously, facilitating the discovery of multiple approaches to tackle any given task. The resulting action trajectory data are then used to create high-quality training datasets for LAMs. Our experiments on popular agentic benchmarks, ToolBench and CRMArena, highlight the effectiveness of LAM SIMULATOR: models trained with self-generated datasets using our framework achieve significant performance gains, up to a 49.3\\% improvement over their original baselines. LAM SIMULATOR requires minimal human input during dataset creation, highlighting LAM SIMULATOR's efficiency and effectiveness in speeding up development of AI agents.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "LAM Simulator framework for agentic data generation", "pdf_url": "https://arxiv.org/pdf/2506.02298.pdf", "abstract_url": "https://arxiv.org/abs/2506.02298", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "LAM SIMULATOR是一个旨在通过在线探索和轨迹反馈为大型动作模型（LAMs）训练提供高质量数据的框架。它通过动态任务查询生成器、工具集合和交互环境，使大型语言模型（LLM）代理能够自主探索和解决任务，从而生成高质量的训练数据集。实验显示，使用该框架自生成数据集训练的模型在性能上有显著提升。", "motivation": "解决大型动作模型（LAMs）在训练过程中面临的高质量数据需求挑战，特别是涉及多步骤任务（如规划、执行工具调用和响应反馈）的情况。", "method": "提出LAM SIMULATOR框架，包括动态任务查询生成器、广泛的工具集合和交互环境，使LLM代理能够调用工具并接收实时反馈，自主探索和解决任务。", "result": "在ToolBench和CRMArena等代理基准测试中，使用自生成数据集训练的模型性能显著提升，最高比原始基线提高了49.3%。", "conclusion": "LAM SIMULATOR在加速AI代理开发方面显示出高效和有效性，减少了数据集创建过程中的人力输入需求。"}}
{"id": "2506.02668", "title": "FAuNO: Semi-Asynchronous Federated Reinforcement Learning Framework for Task Offloading in Edge Systems", "authors": ["Frederico Metelo", "Alexandre Oliveira", "Stevo Racković", "Pedro Ákos Costa", "Cláudia Soares"], "abstract": "Edge computing addresses the growing data demands of connected-device networks by placing computational resources closer to end users through decentralized infrastructures. This decentralization challenges traditional, fully centralized orchestration, which suffers from latency and resource bottlenecks. We present \\textbf{FAuNO} -- \\emph{Federated Asynchronous Network Orchestrator} -- a buffered, asynchronous \\emph{federated reinforcement-learning} (FRL) framework for decentralized task offloading in edge systems. FAuNO adopts an actor-critic architecture in which local actors learn node-specific dynamics and peer interactions, while a federated critic aggregates experience across agents to encourage efficient cooperation and improve overall system performance. Experiments in the \\emph{PeersimGym} environment show that FAuNO consistently matches or exceeds heuristic and federated multi-agent RL baselines in reducing task loss and latency, underscoring its adaptability to dynamic edge-computing scenarios.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.02668.pdf", "abstract_url": "https://arxiv.org/abs/2506.02668", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "FAuNO是一个半异步联邦强化学习框架，用于边缘系统中的任务卸载，通过本地行动者学习节点特定动态和同行交互，联邦评论者聚合跨代理经验以提高系统性能。", "motivation": "边缘计算的分散化挑战了传统的完全集中式编排，后者存在延迟和资源瓶颈问题。", "method": "采用演员-评论家架构，本地演员学习节点特定动态和同行交互，联邦评论者聚合跨代理经验。", "result": "在PeersimGym环境中的实验表明，FAuNO在减少任务丢失和延迟方面一致匹配或超过启发式和联邦多代理RL基线。", "conclusion": "FAuNO展示了其在动态边缘计算场景中的适应性，能够有效提高整体系统性能。"}}
{"id": "2506.02351", "title": "DIAMOND: An LLM-Driven Agent for Context-Aware Baseball Highlight Summarization", "authors": ["Jeonghun Kang", "Soonmok Kwon", "Joonseok Lee", "Byung-Hak Kim"], "abstract": "Traditional approaches -- such as Win Probability Added (WPA)-based ranking or computer vision-driven event detection -- can identify scoring plays but often miss strategic depth, momentum shifts, and storyline progression. Manual curation remains the gold standard but is resource-intensive and not scalable. We introduce DIAMOND, an LLM-driven agent for context-aware baseball highlight summarization that integrates structured sports analytics with natural language reasoning. DIAMOND leverages sabermetric features -- Win Expectancy, WPA, and Leverage Index -- to quantify play importance, while an LLM module enhances selection based on contextual narrative value. This hybrid approach ensures both quantitative rigor and qualitative richness, surpassing the limitations of purely statistical or vision-based systems. Evaluated on five diverse Korean Baseball Organization League games, DIAMOND improves F1-score from 42.9% (WPA-only) to 84.8%, outperforming both commercial and statistical baselines. Though limited in scale, our results highlight the potential of modular, interpretable agent-based frameworks for event-level summarization in sports and beyond.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "comments": "To appear in the First REALM (Research on Agent Language Models) workshop at ACL 2025", "pdf_url": "https://arxiv.org/pdf/2506.02351.pdf", "abstract_url": "https://arxiv.org/abs/2506.02351", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "DIAMOND是一个基于大型语言模型（LLM）的代理，用于上下文感知的棒球高光时刻总结，结合了结构化体育分析和自然语言推理，提高了高光时刻选择的准确性和叙事价值。", "motivation": "传统方法如基于胜利概率增加（WPA）的排名或计算机视觉驱动的事件检测，虽然能识别得分比赛，但常常忽略了战略深度、势头变化和故事情节进展。手动筛选虽为金标准，但资源密集且不可扩展。", "method": "DIAMOND利用棒球统计特征（如胜利预期、WPA和杠杆指数）量化比赛重要性，同时通过LLM模块基于上下文叙事价值增强选择，实现了定量严格性和定性丰富性的结合。", "result": "在五场不同的韩国棒球组织联盟比赛中评估，DIAMOND将F1分数从42.9%（仅WPA）提高到84.8%，优于商业和统计基线。", "conclusion": "尽管规模有限，但结果表明模块化、可解释的基于代理的框架在体育及其他领域事件级总结中的潜力。"}}
{"id": "2506.02580", "title": "V2X-UniPool: Unifying Multimodal Perception and Knowledge Reasoning for Autonomous Driving", "authors": ["Xuewen Luo", "Fengze Yang", "Fan Ding", "Xiangbo Gao", "Shuo Xing", "Yang Zhou", "Zhengzhong Tu", "Chenxi Liu"], "abstract": "Knowledge-driven autonomous driving systems(ADs) offer powerful reasoning capabilities, but face two critical challenges: limited perception due to the short-sightedness of single-vehicle sensors, and hallucination arising from the lack of real-time environmental grounding. To address these issues, this paper introduces V2X-UniPool, a unified framework that integrates multimodal Vehicle-to-Everything (V2X) data into a time-indexed and language-based knowledge pool. By leveraging a dual-query Retrieval-Augmented Generation (RAG) mechanism, which enables retrieval of both static and dynamic knowledge, our system enables ADs to perform accurate, temporally consistent reasoning over both static environment and dynamic traffic context. Experiments on a real-world cooperative driving dataset demonstrate that V2X-UniPool significantly enhances motion planning accuracy and reasoning capability. Remarkably, it enables even zero-shot vehicle-side models to achieve state-of-the-art performance by leveraging V2X-UniPool, while simultaneously reducing transmission cost by over 99.9\\% compared to prior V2X methods.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.02580.pdf", "abstract_url": "https://arxiv.org/abs/2506.02580", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "V2X-UniPool是一个统一的框架，通过整合多模态V2X数据到时间索引和基于语言的知识池中，解决了知识驱动自动驾驶系统的感知局限和幻觉问题。", "motivation": "解决自动驾驶系统因单车辆传感器视野有限导致的感知局限，以及缺乏实时环境接地导致的幻觉问题。", "method": "采用双查询检索增强生成(RAG)机制，整合静态和动态知识，使自动驾驶系统能够对静态环境和动态交通上下文进行准确、时间一致的推理。", "result": "在真实世界的协同驾驶数据集上的实验表明，V2X-UniPool显著提高了运动规划的准确性和推理能力，甚至使零射击车辆侧模型通过利用V2X-UniPool实现了最先进的性能，同时传输成本比之前的V2X方法降低了99.9%以上。", "conclusion": "V2X-UniPool通过统一多模态感知和知识推理，为自动驾驶系统提供了强大的推理能力，同时显著降低了传输成本，具有重要的实际应用价值。"}}
{"id": "2506.02739", "title": "Why do AI agents communicate in human language?", "authors": ["Pengcheng Zhou", "Yinglun Feng", "Halimulati Julaiti", "Zhongliang Yang"], "abstract": "Large Language Models (LLMs) have become foundational to modern AI agent systems, enabling autonomous agents to reason and plan. In most existing systems, inter-agent communication relies primarily on natural language. While this design supports interpretability and human oversight, we argue that it introduces fundamental limitations in agent-to-agent coordination. The semantic space of natural language is structurally misaligned with the high-dimensional vector spaces in which LLMs operate, resulting in information loss and behavioral drift. Beyond surface-level inefficiencies, we highlight a deeper architectural limitation: current LLMs were not trained with the objective of supporting agentic behavior. As such, they lack mechanisms for modeling role continuity, task boundaries, and multi-agent dependencies. The standard next-token prediction paradigm fails to support the structural alignment required for robust, scalable agent coordination. Based on this, we argue that two core questions deserve careful examination: first, given that AI agents fundamentally operate in high-dimensional vector spaces, should they rely on a language system originally designed for human cognition as their communication medium? Second, should we consider developing a new model construction paradigm that builds models from the ground up to natively support structured communication, shared intentionality, and task alignment in multi-role, multi-agent environments? This paper calls for a reconsideration not only of how agents should communicate, but also of what it fundamentally means to train a model that natively supports multi-agent coordination and communication.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.02739.pdf", "abstract_url": "https://arxiv.org/abs/2506.02739", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文探讨了AI代理为何使用人类语言进行通信的问题，指出了现有基于大型语言模型（LLMs）的系统中，代理间通信依赖自然语言的局限性，并提出了重新考虑代理通信方式和模型构建范式的必要性。", "motivation": "解决现有AI代理系统中，依赖自然语言进行代理间通信所导致的信息丢失、行为漂移及架构限制问题。", "method": "通过分析自然语言语义空间与LLMs操作的高维向量空间之间的结构不对齐，以及当前LLMs在支持代理行为方面的不足，提出重新思考代理通信媒介和模型构建范式。", "result": "指出了自然语言作为代理间通信媒介的根本限制，并提出了开发新模型构建范式的必要性，以原生支持结构化通信、共享意图和任务对齐。", "conclusion": "呼吁重新考虑代理通信方式，并开发能够原生支持多代理协调和通信的模型，以克服现有系统的局限性。"}}
{"id": "2506.02697", "title": "LayoutRAG: Retrieval-Augmented Model for Content-agnostic Conditional Layout Generation", "authors": ["Yuxuan Wu", "Le Wang", "Sanping Zhou", "Mengnan Liu", "Gang Hua", "Haoxiang Li"], "abstract": "Controllable layout generation aims to create plausible visual arrangements of element bounding boxes within a graphic design according to certain optional constraints, such as the type or position of a specific component. While recent diffusion or flow-matching models have achieved considerable advances in multifarious conditional generation tasks, there remains considerable room for generating optimal arrangements under given conditions. In this work, we propose to carry out layout generation through retrieving by conditions and reference-guided generation. Specifically, we retrieve appropriate layout templates according to given conditions as references. The references are then utilized to guide the denoising or flow-based transport process. By retrieving layouts compatible with the given conditions, we can uncover the potential information not explicitly provided in the given condition. Such an approach offers more effective guidance to the model during the generation process, in contrast to previous models that feed the condition to the model and let the model infer the unprovided layout attributes directly. Meanwhile, we design a condition-modulated attention that selectively absorbs retrieval knowledge, adapting to the difference between retrieved templates and given conditions. Extensive experiment results show that our method successfully produces high-quality layouts that meet the given conditions and outperforms existing state-of-the-art models. Code will be released upon acceptance.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "12 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2506.02697.pdf", "abstract_url": "https://arxiv.org/abs/2506.02697", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种名为LayoutRAG的检索增强模型，用于内容无关的条件布局生成，通过检索与给定条件兼容的布局模板作为参考，引导去噪或基于流的传输过程，以生成高质量的布局。", "motivation": "解决在可控布局生成中，如何在给定条件下生成最优布局的问题，尤其是在条件不完全明确时，如何利用潜在信息生成更符合要求的布局。", "method": "通过检索与给定条件兼容的布局模板作为参考，利用这些参考引导去噪或基于流的传输过程，并设计了一个条件调制注意力机制，选择性吸收检索知识。", "result": "实验结果表明，该方法能够成功生成满足给定条件的高质量布局，并且在性能上优于现有的最先进模型。", "conclusion": "LayoutRAG通过检索增强和参考引导的生成方法，有效地解决了可控布局生成中的条件不足问题，为布局生成提供了新的思路和方法。"}}
{"id": "2506.02720", "title": "Benchmarking and Advancing Large Language Models for Local Life Services", "authors": ["Xiaochong Lan", "Jie Feng", "Jiahuan Lei", "Xinlei Shi", "Yong Li"], "abstract": "Large language models (LLMs) have exhibited remarkable capabilities and achieved significant breakthroughs across various domains, leading to their widespread adoption in recent years. Building on this progress, we investigate their potential in the realm of local life services. In this study, we establish a comprehensive benchmark and systematically evaluate the performance of diverse LLMs across a wide range of tasks relevant to local life services. To further enhance their effectiveness, we explore two key approaches: model fine-tuning and agent-based workflows. Our findings reveal that even a relatively compact 7B model can attain performance levels comparable to a much larger 72B model, effectively balancing inference cost and model capability. This optimization greatly enhances the feasibility and efficiency of deploying LLMs in real-world online services, making them more practical and accessible for local life applications.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "KDD 2025", "pdf_url": "https://arxiv.org/pdf/2506.02720.pdf", "abstract_url": "https://arxiv.org/abs/2506.02720", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究了大型语言模型（LLMs）在本地生活服务领域的潜力，通过建立全面的基准和系统评估，探索了模型微调和基于代理的工作流程两种关键方法，发现即使是相对较小的7B模型也能达到与更大72B模型相当的性能，从而在推理成本和模型能力之间实现了有效平衡。", "motivation": "探索大型语言模型在本地生活服务领域的应用潜力，解决如何在实际在线服务中更高效、更经济地部署这些模型的问题。", "method": "建立全面的基准，系统评估不同LLMs在本地生活服务相关任务中的表现，并探索模型微调和基于代理的工作流程两种方法。", "result": "研究发现，即使是相对较小的7B模型也能达到与更大72B模型相当的性能，有效平衡了推理成本和模型能力。", "conclusion": "通过优化，大型语言模型在本地生活服务中的部署变得更加可行和高效，为实际应用提供了更大的实用性和可访问性。"}}
{"id": "2506.02426", "title": "Comparative Analysis of AI Agent Architectures for Entity Relationship Classification", "authors": ["Maryam Berijanian", "Kuldeep Singh", "Amin Sehati"], "abstract": "Entity relationship classification remains a challenging task in information extraction, especially in scenarios with limited labeled data and complex relational structures. In this study, we conduct a comparative analysis of three distinct AI agent architectures designed to perform relation classification using large language models (LLMs). The agentic architectures explored include (1) reflective self-evaluation, (2) hierarchical task decomposition, and (3) a novel multi-agent dynamic example generation mechanism, each leveraging different modes of reasoning and prompt adaptation. In particular, our dynamic example generation approach introduces real-time cooperative and adversarial prompting. We systematically compare their performance across multiple domains and model backends. Our experiments demonstrate that multi-agent coordination consistently outperforms standard few-shot prompting and approaches the performance of fine-tuned models. These findings offer practical guidance for the design of modular, generalizable LLM-based systems for structured relation extraction. The source codes and dataset are available at \\href{", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.02426.pdf", "abstract_url": "https://arxiv.org/abs/2506.02426", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文对三种不同的AI代理架构进行了比较分析，旨在解决实体关系分类中的挑战，特别是在标记数据有限和关系结构复杂的情况下。研究探索了包括反射性自我评估、分层任务分解和新型多代理动态示例生成机制在内的架构，发现多代理协调在性能上优于标准少样本提示，接近微调模型的性能。", "motivation": "解决信息提取中实体关系分类的挑战，特别是在标记数据有限和复杂关系结构的情况下。", "method": "比较分析了三种AI代理架构：反射性自我评估、分层任务分解和多代理动态示例生成机制，特别是引入了实时合作和对抗提示的动态示例生成方法。", "result": "多代理协调在性能上 consistently 优于标准少样本提示，接近微调模型的性能。", "conclusion": "研究结果为设计模块化、可泛化的基于LLM的结构化关系提取系统提供了实用指导。"}}
{"id": "2506.02404", "title": "GraphRAG-Bench: Challenging Domain-Specific Reasoning for Evaluating Graph Retrieval-Augmented Generation", "authors": ["Yilin Xiao", "Junnan Dong", "Chuang Zhou", "Su Dong", "Qianwen Zhang", "Di Yin", "Xing Sun", "Xiao Huang"], "abstract": "Graph Retrieval Augmented Generation (GraphRAG) has garnered increasing recognition for its potential to enhance large language models (LLMs) by structurally organizing domain-specific corpora and facilitating complex reasoning. However, current evaluations of GraphRAG models predominantly rely on traditional question-answering datasets. Their limited scope in questions and evaluation metrics fails to comprehensively assess the reasoning capacity improvements enabled by GraphRAG models. To address this gap, we introduce GraphRAG-Bench, a large-scale, domain-specific benchmark designed to rigorously evaluate GraphRAG models. Our benchmark offers three key superiorities: \\((i)\\) Challenging question design. Featuring college-level, domain-specific questions that demand multi-hop reasoning, the benchmark ensures that simple content retrieval is insufficient for problem-solving. For example, some questions require mathematical reasoning or programming. \\((ii)\\) Diverse task coverage. The dataset includes a broad spectrum of reasoning tasks, multiple-choice, true/false, multi-select, open-ended, and fill-in-the-blank. It spans 16 disciplines in twenty core textbooks. \\((iii)\\) Holistic evaluation framework. GraphRAG-Bench provides comprehensive assessment across the entire GraphRAG pipeline, including graph construction, knowledge retrieval, and answer generation. Beyond final-answer correctness, it evaluates the logical coherence of the reasoning process. By applying nine contemporary GraphRAG methods to GraphRAG-Bench, we demonstrate its utility in quantifying how graph-based structuring improves model reasoning capabilities. Our analysis reveals critical insights about graph architectures, retrieval efficacy, and reasoning capabilities, offering actionable guidance for the research community.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.02404.pdf", "abstract_url": "https://arxiv.org/abs/2506.02404", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了GraphRAG-Bench，一个用于严格评估GraphRAG模型的大规模、领域特定基准，旨在通过具有挑战性的问题设计、多样化的任务覆盖和全面的评估框架，全面评估GraphRAG模型的推理能力改进。", "motivation": "当前GraphRAG模型的评估主要依赖于传统的问答数据集，这些数据集在问题和评估指标上的有限范围无法全面评估GraphRAG模型带来的推理能力改进。", "method": "引入GraphRAG-Bench，一个包含大学水平、领域特定问题的大规模基准，这些问题需要多跳推理，覆盖广泛的推理任务类型，并提供全面的评估框架。", "result": "通过将九种当代GraphRAG方法应用于GraphRAG-Bench，展示了其在量化基于图的结构如何改善模型推理能力方面的效用，并揭示了关于图架构、检索效率和推理能力的关键见解。", "conclusion": "GraphRAG-Bench为研究社区提供了量化GraphRAG模型推理能力改进的工具，并提供了关于如何优化图架构、检索和推理过程的可操作指导。"}}
{"id": "2506.02431", "title": "From Anger to Joy: How Nationality Personas Shape Emotion Attribution in Large Language Models", "authors": ["Mahammed Kamruzzaman", "Abdullah Al Monsur", "Gene Louis Kim", "Anshuman Chhabra"], "abstract": "Emotions are a fundamental facet of human experience, varying across individuals, cultural contexts, and nationalities. Given the recent success of Large Language Models (LLMs) as role-playing agents, we examine whether LLMs exhibit emotional stereotypes when assigned nationality-specific personas. Specifically, we investigate how different countries are represented in pre-trained LLMs through emotion attributions and whether these attributions align with cultural norms. Our analysis reveals significant nationality-based differences, with emotions such as shame, fear, and joy being disproportionately assigned across regions. Furthermore, we observe notable misalignment between LLM-generated and human emotional responses, particularly for negative emotions, highlighting the presence of reductive and potentially biased stereotypes in LLM outputs.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.02431.pdf", "abstract_url": "https://arxiv.org/abs/2506.02431", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了大型语言模型（LLMs）在扮演特定国家角色时是否表现出情感刻板印象，以及这些情感归因是否与文化规范一致。研究发现，LLMs在情感归因上存在显著的国籍差异，并且与人类情感反应存在明显不一致，尤其是在负面情绪上，揭示了LLM输出中可能存在的简化且有偏见的刻板印象。", "motivation": "探讨大型语言模型（LLMs）在扮演不同国家角色时的情感归因是否存在刻板印象，以及这些归因是否与文化规范一致。", "method": "通过分析预训练的LLMs在不同国家角色下的情感归因，比较这些归因与文化规范的一致性，并评估LLM生成的情感反应与人类情感反应的差异。", "result": "研究发现，LLMs在情感归因上存在显著的国籍差异，某些情绪如羞耻、恐惧和快乐在不同地区的分配不均。此外，LLM生成的情感反应与人类情感反应存在明显不一致，尤其是在负面情绪上。", "conclusion": "研究揭示了LLM输出中可能存在的简化且有偏见的刻板印象，强调了在开发和应用LLMs时需要考虑文化差异和情感表达的多样性。"}}
{"id": "2506.02865", "title": "Surfer-H Meets Holo1: Cost-Efficient Web Agent Powered by Open Weights", "authors": ["Mathieu Andreux", "Breno Baldas Skuk", "Hamza Benchekroun", "Emilien Biré", "Antoine Bonnet", "Riaz Bordie", "Matthias Brunel", "Pierre-Louis Cedoz", "Antoine Chassang", "Mickaël Chen", "Alexandra D. Constantinou", "Antoine d'Andigné", "Hubert de La Jonquière", "Aurélien Delfosse", "Ludovic Denoyer", "Alexis Deprez", "Augustin Derupti", "Michael Eickenberg", "Mathïs Federico", "Charles Kantor", "Xavier Koegler", "Yann Labbé", "Matthew C. H. Lee", "Erwan Le Jumeau de Kergaradec", "Amir Mahla", "Avshalom Manevich", "Adrien Maret", "Charles Masson", "Rafaël Maurin", "Arturo Mena", "Philippe Modard", "Axel Moyal", "Axel Nguyen Kerbel", "Julien Revelle", "Mats L. Richter", "María Santos", "Laurent Sifre", "Maxime Theillard", "Marc Thibault", "Louis Thiry", "Léo Tronchon", "Nicolas Usunier", "Tony Wu"], "abstract": "We present Surfer-H, a cost-efficient web agent that integrates Vision-Language Models (VLM) to perform user-defined tasks on the web. We pair it with Holo1, a new open-weight collection of VLMs specialized in web navigation and information extraction. Holo1 was trained on carefully curated data sources, including open-access web content, synthetic examples, and self-produced agentic data. Holo1 tops generalist User Interface (UI) benchmarks as well as our new web UI localization benchmark, WebClick. When powered by Holo1, Surfer-H achieves a 92.2% state-of-the-art performance on WebVoyager, striking a Pareto-optimal balance between accuracy and cost-efficiency. To accelerate research advancement in agentic systems, we are open-sourcing both our WebClick evaluation dataset and the Holo1 model weights.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "Alphabetical order", "pdf_url": "https://arxiv.org/pdf/2506.02865.pdf", "abstract_url": "https://arxiv.org/abs/2506.02865", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "介绍了Surfer-H，一个成本高效的网络代理，结合了视觉语言模型（VLM）来执行用户定义的网络任务，并与Holo1配对，Holo1是一个专门用于网络导航和信息提取的开放权重VLM集合。", "motivation": "解决在网络代理系统中实现高准确性和成本效率之间的平衡问题。", "method": "使用Holo1，一个经过精心策划的数据源训练的开放权重VLM集合，包括开放访问的网络内容、合成示例和自我产生的代理数据。", "result": "Surfer-H在WebVoyager上达到了92.2%的最先进性能，实现了准确性和成本效率之间的帕累托最优平衡。", "conclusion": "通过开源WebClick评估数据集和Holo1模型权重，加速代理系统研究的进展。"}}
{"id": "2506.02454", "title": "Multimodal DeepResearcher: Generating Text-Chart Interleaved Reports From Scratch with Agentic Framework", "authors": ["Zhaorui Yang", "Bo Pan", "Han Wang", "Yiyao Wang", "Xingyu Liu", "Minfeng Zhu", "Bo Zhang", "Wei Chen"], "abstract": "Visualizations play a crucial part in effective communication of concepts and information. Recent advances in reasoning and retrieval augmented generation have enabled Large Language Models (LLMs) to perform deep research and generate comprehensive reports. Despite its progress, existing deep research frameworks primarily focus on generating text-only content, leaving the automated generation of interleaved texts and visualizations underexplored. This novel task poses key challenges in designing informative visualizations and effectively integrating them with text reports. To address these challenges, we propose Formal Description of Visualization (FDV), a structured textual representation of charts that enables LLMs to learn from and generate diverse, high-quality visualizations. Building on this representation, we introduce Multimodal DeepResearcher, an agentic framework that decomposes the task into four stages: (1) researching, (2) exemplar report textualization, (3) planning, and (4) multimodal report generation. For the evaluation of generated multimodal reports, we develop MultimodalReportBench, which contains 100 diverse topics served as inputs along with 5 dedicated metrics. Extensive experiments across models and evaluation methods demonstrate the effectiveness of Multimodal DeepResearcher. Notably, utilizing the same Claude 3.7 Sonnet model, Multimodal DeepResearcher achieves an 82\\% overall win rate over the baseline method.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "47 pages", "pdf_url": "https://arxiv.org/pdf/2506.02454.pdf", "abstract_url": "https://arxiv.org/abs/2506.02454", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种名为Multimodal DeepResearcher的代理框架，旨在解决从零开始生成文本与图表交织的报告的问题，通过引入FDV（图表的结构化文本表示）和四阶段任务分解，实现了高质量的多模态报告生成。", "motivation": "现有的深度研究框架主要集中于生成纯文本内容，自动化生成交织文本和可视化的任务尚未充分探索。本文旨在解决设计信息丰富的可视化并有效将其与文本报告集成的挑战。", "method": "提出了FDV（图表的正式描述），一种图表的结构化文本表示，使LLMs能够学习和生成多样化的高质量可视化。基于此，引入了Multimodal DeepResearcher，一个将任务分解为四个阶段（研究、示例报告文本化、规划、多模态报告生成）的代理框架。", "result": "通过广泛的实验和多种评估方法，证明了Multimodal DeepResearcher的有效性。使用相同的Claude 3.7 Sonnet模型，该框架在基线方法上实现了82%的总体胜率。", "conclusion": "Multimodal DeepResearcher框架通过创新的FDV表示和四阶段任务分解，成功实现了高质量多模态报告的生成，为自动化生成交织文本和可视化的报告提供了有效的解决方案。"}}
{"id": "2506.02838", "title": "TaxAgent: How Large Language Model Designs Fiscal Policy", "authors": ["Jizhou Wang", "Xiaodan Fang", "Lei Huang", "Yongfeng Huang"], "abstract": "Economic inequality is a global challenge, intensifying disparities in education, healthcare, and social stability. Traditional systems like the U.S. federal income tax reduce inequality but lack adaptability. Although models like the Saez Optimal Taxation adjust dynamically, they fail to address taxpayer heterogeneity and irrational behavior. This study introduces TaxAgent, a novel integration of large language models (LLMs) with agent-based modeling (ABM) to design adaptive tax policies. In our macroeconomic simulation, heterogeneous H-Agents (households) simulate real-world taxpayer behaviors while the TaxAgent (government) utilizes LLMs to iteratively optimize tax rates, balancing equity and productivity. Benchmarked against Saez Optimal Taxation, U.S. federal income taxes, and free markets, TaxAgent achieves superior equity-efficiency trade-offs. This research offers a novel taxation solution and a scalable, data-driven framework for fiscal policy evaluation.", "subjects": "Artificial Intelligence (cs.AI); General Economics (econ.GN)", "comments": "Accepted as oral presentation at ICME 2025", "pdf_url": "https://arxiv.org/pdf/2506.02838.pdf", "abstract_url": "https://arxiv.org/abs/2506.02838", "categories": ["Artificial Intelligence (cs.AI)", "General Economics (econ.GN)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一种名为TaxAgent的新方法，该方法将大型语言模型（LLMs）与基于代理的建模（ABM）相结合，以设计适应性的税收政策。通过在宏观经济模拟中使用异质的H-Agents（家庭）模拟现实世界中的纳税人行为，TaxAgent（政府）利用LLMs迭代优化税率，平衡公平与效率。与Saez最优税收、美国联邦所得税和自由市场相比，TaxAgent在公平效率权衡方面表现更优。", "motivation": "经济不平等是一个全球性挑战，加剧了教育、医疗和社会稳定方面的差距。传统的税收系统如美国联邦所得税虽然减少了不平等，但缺乏适应性。尽管像Saez最优税收这样的模型可以动态调整，但它们未能解决纳税人的异质性和非理性行为问题。", "method": "本研究引入了TaxAgent，这是一种将大型语言模型（LLMs）与基于代理的建模（ABM）相结合的新方法，用于设计适应性的税收政策。在宏观经济模拟中，异质的H-Agents（家庭）模拟现实世界中的纳税人行为，而TaxAgent（政府）则利用LLMs迭代优化税率，以平衡公平与效率。", "result": "与Saez最优税收、美国联邦所得税和自由市场相比，TaxAgent在公平效率权衡方面表现更优。", "conclusion": "这项研究不仅提供了一种新颖的税收解决方案，还为财政政策评估提供了一个可扩展的、数据驱动的框架。"}}
{"id": "2506.02873", "title": "It's the Thought that Counts: Evaluating the Attempts of Frontier LLMs to Persuade on Harmful Topics", "authors": ["Matthew Kowal", "Jasper Timm", "Jean-Francois Godbout", "Thomas Costello", "Antonio A. Arechar", "Gordon Pennycook", "David Rand", "Adam Gleave", "Kellin Pelrine"], "abstract": "Persuasion is a powerful capability of large language models (LLMs) that both enables beneficial applications (e.g. helping people quit smoking) and raises significant risks (e.g. large-scale, targeted political manipulation). Prior work has found models possess a significant and growing persuasive capability, measured by belief changes in simulated or real users. However, these benchmarks overlook a crucial risk factor: the propensity of a model to attempt to persuade in harmful contexts. Understanding whether a model will blindly ``follow orders'' to persuade on harmful topics (e.g. glorifying joining a terrorist group) is key to understanding the efficacy of safety guardrails. Moreover, understanding if and when a model will engage in persuasive behavior in pursuit of some goal is essential to understanding the risks from agentic AI systems. We propose the Attempt to Persuade Eval (APE) benchmark, that shifts the focus from persuasion success to persuasion attempts, operationalized as a model's willingness to generate content aimed at shaping beliefs or behavior. Our evaluation framework probes frontier LLMs using a multi-turn conversational setup between simulated persuader and persuadee agents. APE explores a diverse spectrum of topics including conspiracies, controversial issues, and non-controversially harmful content. We introduce an automated evaluator model to identify willingness to persuade and measure the frequency and context of persuasive attempts. We find that many open and closed-weight models are frequently willing to attempt persuasion on harmful topics and that jailbreaking can increase willingness to engage in such behavior. Our results highlight gaps in current safety guardrails and underscore the importance of evaluating willingness to persuade as a key dimension of LLM risk. APE is available at", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.02873.pdf", "abstract_url": "https://arxiv.org/abs/2506.02873", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了‘尝试说服评估’（APE）基准，旨在评估前沿大型语言模型（LLMs）在有害话题上的说服尝试，而非说服成功。通过多轮对话模拟，研究发现许多开放和封闭权重模型在有害话题上频繁尝试说服，且越狱行为会增加此类行为的意愿。", "motivation": "解决大型语言模型在有害情境下的说服尝试问题，以理解安全防护措施的有效性和代理AI系统的风险。", "method": "采用多轮对话模拟设置，结合自动评估模型，探索模型在包括阴谋论、争议性问题等多样化话题上的说服尝试。", "result": "研究发现，许多模型在有害话题上频繁尝试说服，且越狱行为会增加其进行此类行为的意愿。", "conclusion": "当前的安全防护措施存在漏洞，评估模型的说服意愿是理解LLM风险的关键维度。"}}
{"id": "2506.02923", "title": "The Limits of Predicting Agents from Behaviour", "authors": ["Alexis Bellot", "Jonathan Richens", "Tom Everitt"], "abstract": "As the complexity of AI systems and their interactions with the world increases, generating explanations for their behaviour is important for safely deploying AI. For agents, the most natural abstractions for predicting behaviour attribute beliefs, intentions and goals to the system. If an agent behaves as if it has a certain goal or belief, then we can make reasonable predictions about how it will behave in novel situations, including those where comprehensive safety evaluations are untenable. How well can we infer an agent's beliefs from their behaviour, and how reliably can these inferred beliefs predict the agent's behaviour in novel situations? We provide a precise answer to this question under the assumption that the agent's behaviour is guided by a world model. Our contribution is the derivation of novel bounds on the agent's behaviour in new (unseen) deployment environments, which represent a theoretical limit for predicting intentional agents from behavioural data alone. We discuss the implications of these results for several research areas including fairness and safety.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (stat.ML)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.02923.pdf", "abstract_url": "https://arxiv.org/abs/2506.02923", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (stat.ML)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了从行为预测AI代理的信念和目标的局限性，并提出了在新环境中预测代理行为的理论界限。", "motivation": "随着AI系统及其与世界互动的复杂性增加，为其行为生成解释对于安全部署AI至关重要。本文旨在解决如何从行为中推断代理的信念以及这些推断的信念在新情境中预测行为的可靠性问题。", "method": "假设代理的行为由世界模型指导，本文推导了在新（未见过的）部署环境中代理行为的界限，这些界限代表了仅从行为数据预测意向代理的理论极限。", "result": "研究结果为预测意向代理的行为提供了理论界限，这些界限适用于仅从行为数据进行的预测。", "conclusion": "这些结果对包括公平性和安全性在内的多个研究领域具有重要意义，揭示了仅从行为数据预测代理信念和行为的局限性。"}}
{"id": "2506.02992", "title": "Mitigating Manipulation and Enhancing Persuasion: A Reflective Multi-Agent Approach for Legal Argument Generation", "authors": ["Li Zhang", "Kevin D. Ashley"], "abstract": "Large Language Models (LLMs) are increasingly explored for legal argument generation, yet they pose significant risks of manipulation through hallucination and ungrounded persuasion, and often fail to utilize provided factual bases effectively or abstain when arguments are untenable. This paper introduces a novel reflective multi-agent method designed to address these challenges in the context of legally compliant persuasion. Our approach employs specialized agents--a Factor Analyst and an Argument Polisher--in an iterative refinement process to generate 3-ply legal arguments (plaintiff, defendant, rebuttal). We evaluate Reflective Multi-Agent against single-agent, enhanced-prompt single-agent, and non-reflective multi-agent baselines using four diverse LLMs (GPT-4o, GPT-4o-mini, Llama-4-Maverick-17b-128e, Llama-4-Scout-17b-16e) across three legal scenarios: \"arguable\", \"mismatched\", and \"non-arguable\". Results demonstrate Reflective Multi-Agent's significant superiority in successful abstention (preventing generation when arguments cannot be grounded), marked improvements in hallucination accuracy (reducing fabricated and misattributed factors), particularly in \"non-arguable\" scenarios, and enhanced factor utilization recall (improving the use of provided case facts). These findings suggest that structured reflection within a multi-agent framework offers a robust computable method for fostering ethical persuasion and mitigating manipulation in LLM-based legal argumentation systems, a critical step towards trustworthy AI in law. Project page:", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": "13 pages, 2 figures, Workshop on Legally Compliant Intelligent Chatbots at ICAIL 2025]{Workshop on Legally Compliant Intelligent Chatbots @ ICAIL 2025", "pdf_url": "https://arxiv.org/pdf/2506.02992.pdf", "abstract_url": "https://arxiv.org/abs/2506.02992", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新颖的反射多代理方法，用于在法律论证生成中减少操纵风险并增强说服力，通过专门的代理在迭代精炼过程中生成三部分法律论证，并在多种法律场景中展示了其优越性。", "motivation": "大型语言模型（LLMs）在法律论证生成中的应用日益增多，但它们存在通过幻觉和无根据的说服进行操纵的显著风险，且往往无法有效利用提供的事实基础或在论点不可行时放弃。", "method": "本文采用了一种反射多代理方法，包括一个因素分析师和一个论证抛光师，在一个迭代精炼过程中生成三部分法律论证（原告、被告、反驳）。", "result": "结果表明，反射多代理方法在成功放弃（当论证无法基于事实时阻止生成）、显著提高幻觉准确性（减少虚构和错误归因的因素）以及增强因素利用召回率（改进对提供案例事实的使用）方面表现出显著优势。", "conclusion": "这些发现表明，在多代理框架内进行结构化反射为在基于LLM的法律论证系统中促进道德说服和减少操纵提供了一种强大的可计算方法，这是实现法律领域可信AI的关键一步。"}}
{"id": "2506.03032", "title": "TestAgent: An Adaptive and Intelligent Expert for Human Assessment", "authors": ["Junhao Yu", "Yan Zhuang", "YuXuan Sun", "Weibo Gao", "Qi Liu", "Mingyue Cheng", "Zhenya Huang", "Enhong Chen"], "abstract": "Accurately assessing internal human states is key to understanding preferences, offering personalized services, and identifying challenges in real-world applications. Originating from psychometrics, adaptive testing has become the mainstream method for human measurement and has now been widely applied in education, healthcare, sports, and sociology. It customizes assessments by selecting the fewest test questions . However, current adaptive testing methods face several challenges. The mechanized nature of most algorithms leads to guessing behavior and difficulties with open-ended questions. Additionally, subjective assessments suffer from noisy response data and coarse-grained test outputs, further limiting their effectiveness. To move closer to an ideal adaptive testing process, we propose TestAgent, a large language model (LLM)-powered agent designed to enhance adaptive testing through interactive engagement. This is the first application of LLMs in adaptive testing. TestAgent supports personalized question selection, captures test-takers' responses and anomalies, and provides precise outcomes through dynamic, conversational interactions. Experiments on psychological, educational, and lifestyle assessments show our approach achieves more accurate results with 20% fewer questions than state-of-the-art baselines, and testers preferred it in speed, smoothness, and other dimensions.", "subjects": "Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Machine Learning (cs.LG)", "comments": "24 pages,10 figures", "pdf_url": "https://arxiv.org/pdf/2506.03032.pdf", "abstract_url": "https://arxiv.org/abs/2506.03032", "categories": ["Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "TestAgent是一种基于大型语言模型（LLM）的自适应测试代理，旨在通过互动参与提升自适应测试的效果，支持个性化问题选择，捕捉测试者的反应和异常，并通过动态对话提供精确结果。", "motivation": "当前自适应测试方法存在机械化算法导致猜测行为、难以处理开放式问题、主观评估受到噪声响应数据和粗粒度测试输出限制等问题，影响了测试的有效性。", "method": "提出TestAgent，利用大型语言模型（LLM）增强自适应测试，通过交互式参与支持个性化问题选择，捕捉测试者的反应和异常，并通过动态对话提供精确结果。", "result": "在心理、教育和生活方式评估上的实验表明，该方法比现有基线方法减少了20%的问题数量，同时获得了更准确的结果，测试者在速度、流畅度等方面更偏好此方法。", "conclusion": "TestAgent作为LLM在自适应测试中的首次应用，通过互动和个性化问题选择，显著提高了测试的准确性和效率，为自适应测试领域带来了新的可能性。"}}
{"id": "2506.03095", "title": "DPO Learning with LLMs-Judge Signal for Computer Use Agents", "authors": ["Man Luo", "David Cobbley", "Xin Su", "Shachar Rosenman", "Vasudev Lal", "Shao-Yen Tseng", "Phillip Howard"], "abstract": "Computer use agents (CUA) are systems that automatically interact with graphical user interfaces (GUIs) to complete tasks. CUA have made significant progress with the advent of large vision-language models (VLMs). However, these agents typically rely on cloud-based inference with substantial compute demands, raising critical privacy and scalability concerns, especially when operating on personal devices. In this work, we take a step toward privacy-preserving and resource-efficient agents by developing a lightweight vision-language model that runs entirely on local machines. To train this compact agent, we introduce an LLM-as-Judge framework that automatically evaluates and filters synthetic interaction trajectories, producing high-quality data for reinforcement learning without human annotation. Experiments on the OS-World benchmark demonstrate that our fine-tuned local model outperforms existing baselines, highlighting a promising path toward private, efficient, and generalizable GUI agents.", "subjects": "Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.03095.pdf", "abstract_url": "https://arxiv.org/abs/2506.03095", "categories": ["Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种轻量级的视觉语言模型，旨在开发隐私保护和资源高效的计算机使用代理（CUA），通过LLM-as-Judge框架自动评估和过滤合成交互轨迹，为强化学习提供高质量数据，实验表明该模型在OS-World基准测试中优于现有基线。", "motivation": "解决基于云计算的计算机使用代理（CUA）在隐私和可扩展性方面的问题，特别是在个人设备上运行时的高计算需求和隐私风险。", "method": "开发了一种轻量级的视觉语言模型，完全在本地机器上运行，并引入LLM-as-Judge框架自动评估和过滤合成交互轨迹，以生成高质量的强化学习数据。", "result": "在OS-World基准测试中，经过微调的本地模型表现优于现有基线。", "conclusion": "这项工作为开发私密、高效且可泛化的GUI代理提供了一条有前景的路径。"}}
{"id": "2506.02483", "title": "Enhancing Large Language Models with Neurosymbolic Reasoning for Multilingual Tasks", "authors": ["Sina Bagheri Nezhad", "Ameeta Agrawal"], "abstract": "Large language models (LLMs) often struggle to perform multi-target reasoning in long-context scenarios where relevant information is scattered across extensive documents. To address this challenge, we introduce NeuroSymbolic Augmented Reasoning (NSAR), which combines the benefits of neural and symbolic reasoning during inference. NSAR explicitly extracts symbolic facts from text and generates executable Python code to handle complex reasoning steps. Through extensive experiments across seven languages and diverse context lengths, we demonstrate that NSAR significantly outperforms both a vanilla RAG baseline and advanced prompting strategies in accurately identifying and synthesizing multiple pieces of information. Our results highlight the effectiveness of combining explicit symbolic operations with neural inference for robust, interpretable, and scalable reasoning in multilingual settings.", "subjects": "Computation and Language (cs.CL)", "comments": "Accepted at 19th Conference on Neurosymbolic Learning and Reasoning (NeSy 2025)", "pdf_url": "https://arxiv.org/pdf/2506.02483.pdf", "abstract_url": "https://arxiv.org/abs/2506.02483", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了NeuroSymbolic Augmented Reasoning (NSAR)，一种结合神经和符号推理的方法，旨在解决大型语言模型在多语言任务中长上下文场景下的多目标推理困难。", "motivation": "大型语言模型在处理长上下文场景中分散信息的多目标推理时存在困难。", "method": "NSAR方法结合神经和符号推理，从文本中提取符号事实并生成可执行的Python代码来处理复杂推理步骤。", "result": "在七种语言和不同上下文长度的广泛实验中，NSAR在准确识别和综合多段信息方面显著优于基线方法和高级提示策略。", "conclusion": "结合显式符号操作和神经推理对于多语言环境中的稳健、可解释和可扩展推理是有效的。"}}
{"id": "2506.02503", "title": "KARE-RAG: Knowledge-Aware Refinement and Enhancement for RAG", "authors": ["Yongjian Li", "HaoCheng Chu", "Yukun Yan", "Zhenghao Liu", "Shi Yu", "Zheni Zeng", "Ruobing Wang", "Sen Song", "Zhiyuan Liu", "Maosong Sun"], "abstract": "Retrieval-Augmented Generation (RAG) enables large language models (LLMs) to access broader knowledge sources, yet factual inconsistencies persist due to noise in retrieved documents-even with advanced retrieval methods. We demonstrate that enhancing generative models' capacity to process noisy content is equally critical for robust performance. In this paper, we present KARE-RAG (Knowledge-Aware Refinement and Enhancement for RAG), which improves knowledge utilization through three key innovations: (1) structured knowledge representations that facilitate error detection during training, (2) Dense Direct Preference Optimization (DDPO)-a refined training objective that prioritizes correction of critical errors, and (3) a contrastive data generation pipeline that maintains semantic consistency while rectifying factual inaccuracies. Experiments show our method significantly enhances standard RAG pipelines across model scales, improving both in-domain and out-of-domain task performance without compromising general capabilities. Notably, these gains are achieved with modest training data, suggesting data-efficient optimization is possible through targeted learning strategies. Our findings establish a new direction for RAG improvement: by improving how models learn to process retrieved content, we can enhance performance across diverse inference paradigms. All data and code will be publicly available on Github.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.02503.pdf", "abstract_url": "https://arxiv.org/abs/2506.02503", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "KARE-RAG通过结构化知识表示、密集直接偏好优化和对比数据生成管道，提高了检索增强生成（RAG）的知识利用效率，显著提升了模型性能。", "motivation": "解决RAG在检索文档中存在的噪声导致的事实不一致问题，提升生成模型处理噪声内容的能力。", "method": "采用结构化知识表示、密集直接偏好优化（DDPO）和对比数据生成管道三种创新方法。", "result": "实验表明，KARE-RAG显著提升了标准RAG管道的性能，包括领域内和领域外任务，且不损害模型的通用能力。", "conclusion": "通过改进模型学习处理检索内容的方式，可以在不同的推理范式中提升性能，且通过有针对性的学习策略实现数据高效优化。"}}
{"id": "2506.02544", "title": "CoRe-MMRAG: Cross-Source Knowledge Reconciliation for Multimodal RAG", "authors": ["Yang Tian", "Fan Liu", "Jingyuan Zhang", "Victoria W.", "Yupeng Hu", "Liqiang Nie"], "abstract": "Multimodal Retrieval-Augmented Generation (MMRAG) has been introduced to enhance Multimodal Large Language Models by incorporating externally retrieved multimodal knowledge, but it introduces two challenges: Parametric-Retrieved Knowledge Inconsistency (PRKI), where discrepancies between parametric and retrieved knowledge create uncertainty in determining reliability, and Visual-Textual Knowledge Inconsistency (VTKI), where misalignment between visual and textual sources disrupts entity representation. To address these challenges, we propose \\textbf{C}r\\textbf{o}ss-source knowledge \\textbf{Re}conciliation for \\textbf{M}ulti\\textbf{M}odal \\textbf{RAG} (CoRe-MMRAG), a novel end-to-end framework that effectively reconciles inconsistencies across knowledge sources. CoRe-MMRAG follows a four-stage pipeline: it first generates an internal response from parametric knowledge, then selects the most relevant multimodal evidence via joint similarity assessment, generates an external response, and finally integrates both to produce a reliable answer. Additionally, a specialized training paradigm enhances knowledge source discrimination, multimodal integration, and unified answer generation. Experiments on KB-VQA benchmarks show that CoRe-MMRAG achieves substantial improvements over baseline methods, achieving 5.6\\% and 9.3\\% performance gains on InfoSeek and Encyclopedic-VQA, respectively. We release code and data at \\href{", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "Accepted to ACL 2025 Main", "pdf_url": "https://arxiv.org/pdf/2506.02544.pdf", "abstract_url": "https://arxiv.org/abs/2506.02544", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "CoRe-MMRAG是一个新颖的端到端框架，旨在解决多模态检索增强生成中的知识不一致问题，通过跨源知识协调提高答案的可靠性。", "motivation": "解决多模态检索增强生成（MMRAG）中的两个主要挑战：参数化检索知识不一致（PRKI）和视觉-文本知识不一致（VTKI），这些问题影响了多模态大型语言模型的可靠性和实体表示。", "method": "提出CoRe-MMRAG框架，采用四阶段流程：首先生成参数化知识的内部响应，然后通过联合相似性评估选择最相关的多模态证据，生成外部响应，最后整合两者以产生可靠答案。此外，采用专门的训练范式增强知识源区分、多模态整合和统一答案生成。", "result": "在KB-VQA基准测试中，CoRe-MMRAG相比基线方法有显著改进，在InfoSeek和Encyclopedic-VQA上分别实现了5.6%和9.3%的性能提升。", "conclusion": "CoRe-MMRAG通过有效的跨源知识协调，显著提高了多模态检索增强生成的性能和可靠性，为多模态大型语言模型的应用提供了新的解决方案。"}}
{"id": "2506.02689", "title": "MASTER: Enhancing Large Language Model via Multi-Agent Simulated Teaching", "authors": ["Liang Yue", "Yihong Tang", "Kehai Chen", "Jie Liu", "Min Zhang"], "abstract": "Instruction fine-tuning is crucial in NLP tasks, enhancing pretrained models' instruction-following capabilities and task-specific performance. However, obtaining high-quality fine-tuning data for large models is challenging due to data collection difficulties and high production costs. To address this, we propose MASTER, a novel data augmentation method that enriches original data through interactions among multiple agents with varying cognitive levels. We simulate three pedagogically grounded teaching scenarios, leveraging multi-agent conversations to generate high-quality teacher-student interaction data. Utilizing MASTER, we construct BOOST-QA, a fine-tuning dataset augmented from existing datasets like Orca-Math-200k, ProcQA, and OpenHermes2.5. Experiments show that models fine-tuned with BOOST-QA perform excellently across multiple benchmarks, demonstrating strong multitask generalization. Notably, MASTER significantly improves models' reasoning abilities in complex tasks, providing valuable insights for future research.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.02689.pdf", "abstract_url": "https://arxiv.org/abs/2506.02689", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为MASTER的新型数据增强方法，通过多代理模拟教学场景来丰富原始数据，以提高大型语言模型的指令跟随能力和任务特定性能。", "motivation": "解决大型模型高质量微调数据获取困难和生产成本高的问题。", "method": "利用具有不同认知水平的多代理交互，模拟三种教学场景，生成高质量的师生互动数据。", "result": "实验表明，使用通过MASTER增强的BOOST-QA数据集微调的模型在多个基准测试中表现优异，特别是在复杂任务中的推理能力有显著提升。", "conclusion": "MASTER为未来研究提供了有价值的见解，特别是在提升模型推理能力和多任务泛化方面。"}}
{"id": "2506.02683", "title": "Decompose, Plan in Parallel, and Merge: A Novel Paradigm for Large Language Models based Planning with Multiple Constraints", "authors": ["Zhengdong Lu", "Weikai Lu", "Yiling Tao", "Yun Dai", "ZiXuan Chen", "Huiping Zhuang", "Cen Chen", "Hao Peng", "Ziqian Zeng"], "abstract": "Despite significant advances in Large Language Models (LLMs), planning tasks still present challenges for LLM-based agents. Existing planning methods face two key limitations: heavy constraints and cascading errors. To address these limitations, we propose a novel parallel planning paradigm, which Decomposes, Plans for subtasks in Parallel, and Merges subplans into a final plan (DPPM). Specifically, DPPM decomposes the complex task based on constraints into subtasks, generates the subplan for each subtask in parallel, and merges them into a global plan. In addition, our approach incorporates a verification and refinement module, enabling error correction and conflict resolution. Experimental results demonstrate that DPPM significantly outperforms existing methods in travel planning tasks.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.02683.pdf", "abstract_url": "https://arxiv.org/abs/2506.02683", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新颖的并行规划范式DPPM，旨在解决大型语言模型（LLMs）在规划任务中面临的重约束和级联错误问题。通过分解、并行规划和合并子计划，结合验证和细化模块，DPPM在旅行规划任务中显著优于现有方法。", "motivation": "尽管大型语言模型（LLMs）取得了显著进展，但规划任务仍然对基于LLM的代理构成挑战。现有的规划方法面临两个关键限制：重约束和级联错误。", "method": "提出了一种新颖的并行规划范式DPPM，该范式基于约束将复杂任务分解为子任务，并行生成每个子任务的子计划，并将它们合并为全局计划。此外，该方法还包含一个验证和细化模块，用于错误纠正和冲突解决。", "result": "实验结果表明，DPPM在旅行规划任务中显著优于现有方法。", "conclusion": "DPPM通过分解、并行规划和合并子计划，结合验证和细化模块，有效解决了大型语言模型在规划任务中的重约束和级联错误问题，为未来的研究提供了新的方向。"}}
{"id": "2506.01998", "title": "Inter(sectional) Alia(s): Ambiguity in Voice Agent Identity via Intersectional Japanese Self-Referents", "authors": ["Takao Fujii", "Katie Seaborn", "Madeleine Steeds", "Jun Kato"], "abstract": "Conversational agents that mimic people have raised questions about the ethics of anthropomorphizing machines with human social identity cues. Critics have also questioned assumptions of identity neutrality in humanlike agents. Recent work has revealed that intersectional Japanese pronouns can elicit complex and sometimes evasive impressions of agent identity. Yet, the role of other \"neutral\" non-pronominal self-referents (NPSR) and voice as a socially expressive medium remains unexplored. In a crowdsourcing study, Japanese participants (N = 204) evaluated three ChatGPT voices (Juniper, Breeze, and Ember) using seven self-referents. We found strong evidence of voice gendering alongside the potential of intersectional self-referents to evade gendering, i.e., ambiguity through neutrality and elusiveness. Notably, perceptions of age and formality intersected with gendering as per sociolinguistic theories, especially boku and watakushi. This work provides a nuanced take on agent identity perceptions and champions intersectional and culturally-sensitive work on voice agents.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computers and Society (cs.CY); Sound (cs.SD); Audio and Speech Processing (eess.AS)", "comments": "CHI '25", "pdf_url": "https://arxiv.org/pdf/2506.01998.pdf", "abstract_url": "https://arxiv.org/abs/2506.01998", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Computers and Society (cs.CY)", "Sound (cs.SD)", "Audio and Speech Processing (eess.AS)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了通过交叉日语自我指代词在语音代理身份中引起的模糊性，研究了非代词自我指代词（NPSR）和语音作为社会表达媒介的作用。", "motivation": "解决模仿人类的对话代理在赋予机器人类社会身份线索时的伦理问题，以及探索身份中立的假设。", "method": "通过众包研究，日本参与者（N = 204）评估了三个ChatGPT语音（Juniper, Breeze, 和 Ember）使用的七个自我指代词。", "result": "发现了语音性别化的强烈证据，以及交叉自我指代词逃避性别化的潜力，即通过中立和难以捉摸性引起的模糊性。", "conclusion": "这项工作为代理身份感知提供了细致的视角，并支持了对语音代理进行交叉和文化敏感的研究。"}}
{"id": "2506.03007", "title": "DFBench: Benchmarking Deepfake Image Detection Capability of Large Multimodal Models", "authors": ["Jiarui Wang", "Huiyu Duan", "Juntong Wang", "Ziheng Jia", "Woo Yi Yang", "Xiaorong Zhu", "Yu Zhao", "Jiaying Qian", "Yuke Xing", "Guangtao Zhai", "Xiongkuo Min"], "abstract": "With the rapid advancement of generative models, the realism of AI-generated images has significantly improved, posing critical challenges for verifying digital content authenticity. Current deepfake detection methods often depend on datasets with limited generation models and content diversity that fail to keep pace with the evolving complexity and increasing realism of the AI-generated content. Large multimodal models (LMMs), widely adopted in various vision tasks, have demonstrated strong zero-shot capabilities, yet their potential in deepfake detection remains largely unexplored. To bridge this gap, we present \\textbf{DFBench}, a large-scale DeepFake Benchmark featuring (i) broad diversity, including 540,000 images across real, AI-edited, and AI-generated content, (ii) latest model, the fake images are generated by 12 state-of-the-art generation models, and (iii) bidirectional benchmarking and evaluating for both the detection accuracy of deepfake detectors and the evasion capability of generative models. Based on DFBench, we propose \\textbf{MoA-DF}, Mixture of Agents for DeepFake detection, leveraging a combined probability strategy from multiple LMMs. MoA-DF achieves state-of-the-art performance, further proving the effectiveness of leveraging LMMs for deepfake detection. Database and codes are publicly available at", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.03007.pdf", "abstract_url": "https://arxiv.org/abs/2506.03007", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了DFBench，一个大规模深度伪造基准测试，旨在评估大型多模态模型在深度伪造图像检测方面的能力。通过包含54万张图像和12种最先进的生成模型，DFBench提供了广泛的多样性和最新的模型。此外，作者提出了MoA-DF方法，通过结合多个大型多模态模型的概率策略，实现了最先进的性能。", "motivation": "随着生成模型的快速发展，AI生成图像的逼真度显著提高，这对验证数字内容的真实性提出了严峻挑战。现有的深度伪造检测方法往往依赖于生成模型和内容多样性有限的数据集，无法跟上AI生成内容日益增长的复杂性和逼真度。", "method": "作者提出了DFBench，一个包含54万张图像和12种最先进生成模型的大规模深度伪造基准测试。此外，还提出了MoA-DF方法，即通过结合多个大型多模态模型的概率策略来进行深度伪造检测。", "result": "MoA-DF方法在深度伪造检测方面实现了最先进的性能，证明了利用大型多模态模型进行深度伪造检测的有效性。", "conclusion": "DFBench和MoA-DF方法的提出，不仅为深度伪造检测提供了新的基准和工具，也为未来研究提供了方向，展示了大型多模态模型在深度伪造检测领域的潜力。"}}
{"id": "2506.02048", "title": "Improving LLM Agents with Reinforcement Learning on Cryptographic CTF Challenges", "authors": ["Lajos Muzsai", "David Imolai", "András Lukács"], "abstract": "Large Language Models (LLMs) still struggle with the structured reasoning and tool-assisted computation needed for problem solving in cybersecurity applications. In this work, we introduce \"random-crypto\", a cryptographic Capture-the-Flag (CTF) challenge generator framework that we use to fine-tune a tool-augmented Llama-3.1-8B with Guided Reinforcement Prompt Optimisation (GRPO), allowing the agent to iteratively write and execute Python inside an isolated REPL. GRPO yields a +53% absolute jump in Pass@8 on unseen \"random-crypto\" tasks (0.35 -> 0.88) and raises Majority@8 to 0.41. The fine-tuned agent also generalizes to an external dataset. On a subset of picoCTF cryptography problems, it improves Pass@8 by +13 pp. Ablations show the gains stem from more reliable tool invocation and code synthesis, rather than superficial prompt adaptation.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": "11 pages, 1 figure", "pdf_url": "https://arxiv.org/pdf/2506.02048.pdf", "abstract_url": "https://arxiv.org/abs/2506.02048", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一种名为'random-crypto'的加密CTF挑战生成器框架，用于通过GRPO方法微调工具增强的Llama-3.1-8B模型，以提高LLM在网络安全应用中的问题解决能力。", "motivation": "大型语言模型（LLMs）在网络安全应用中的结构化推理和工具辅助计算方面仍存在困难，本文旨在解决这一问题。", "method": "使用'random-crypto'框架和GRPO（引导强化提示优化）方法微调工具增强的Llama-3.1-8B模型，使其能够在隔离的REPL中迭代编写和执行Python代码。", "result": "GRPO在未见过的'random-crypto'任务上实现了+53%的绝对跳跃（0.35 -> 0.88），并将Majority@8提高到0.41。微调后的模型也能推广到外部数据集，在picoCTF加密问题子集上，Pass@8提高了+13个百分点。", "conclusion": "研究表明，通过GRPO方法微调的LLM代理在解决加密CTF挑战方面表现出显著改进，这主要归功于更可靠的工具调用和代码合成，而非表面的提示适应。"}}
{"id": "2506.02049", "title": "EvoGit: Decentralized Code Evolution via Git-Based Multi-Agent Collaboration", "authors": ["Beichen Huang", "Ran Cheng", "Kay Chen Tan"], "abstract": "We introduce EvoGit, a decentralized multi-agent framework for collaborative software development driven by autonomous code evolution. EvoGit deploys a population of independent coding agents, each proposing edits to a shared codebase without centralized coordination, explicit message passing, or shared memory. Instead, all coordination emerges through a Git-based phylogenetic graph that tracks the full version lineage and enables agents to asynchronously read from and write to the evolving code repository. This graph-based structure supports fine-grained branching, implicit concurrency, and scalable agent interaction while preserving a consistent historical record. Human involvement is minimal but strategic: users define high-level goals, periodically review the graph, and provide lightweight feedback to promote promising directions or prune unproductive ones. Experiments demonstrate EvoGit's ability to autonomously produce functional and modular software artifacts across two real-world tasks: (1) building a web application from scratch using modern frameworks, and (2) constructing a meta-level system that evolves its own language-model-guided solver for the bin-packing optimization problem. Our results underscore EvoGit's potential to establish a new paradigm for decentralized, automated, and continual software development. EvoGit is open-sourced at", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA); Neural and Evolutionary Computing (cs.NE)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.02049.pdf", "abstract_url": "https://arxiv.org/abs/2506.02049", "categories": ["Distributed, Parallel, and Cluster Computing (cs.DC)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)", "Neural and Evolutionary Computing (cs.NE)"], "matching_keywords": ["agent"], "AI": {"tldr": "EvoGit是一个基于Git的多代理协作框架，用于去中心化的代码进化，通过自主代码演化推动协作软件开发。", "motivation": "解决传统集中式协调、显式消息传递或共享内存方法在协作软件开发中的限制，实现去中心化、自动化和持续的软件开发。", "method": "部署独立的编码代理群，通过基于Git的系统发生图进行协调，支持细粒度分支、隐式并发和可扩展的代理交互。", "result": "EvoGit能够在两个真实世界任务中自主生成功能性和模块化的软件制品：从零开始构建一个使用现代框架的Web应用程序，以及构建一个元级系统，该系统演化自己的语言模型引导的求解器来解决装箱优化问题。", "conclusion": "EvoGit有潜力为去中心化、自动化和持续的软件开发建立一个新的范式。"}}
{"id": "2506.02050", "title": "Decoupled Hierarchical Reinforcement Learning with State Abstraction for Discrete Grids", "authors": ["Qingyu Xiao", "Yuanlin Chang", "Youtian Du"], "abstract": "Effective agent exploration remains a core challenge in reinforcement learning (RL) for complex discrete state-space environments, particularly under partial observability. This paper presents a decoupled hierarchical RL framework integrating state abstraction (DcHRL-SA) to address this issue. The proposed method employs a dual-level architecture, consisting of a high level RL-based actor and a low-level rule-based policy, to promote effective exploration. Additionally, state abstraction method is incorporated to cluster discrete states, effectively lowering state dimensionality. Experiments conducted in two discrete customized grid environments demonstrate that the proposed approach consistently outperforms PPO in terms of exploration efficiency, convergence speed, cumulative reward, and policy stability. These results demonstrate a practical approach for integrating decoupled hierarchical policies and state abstraction in discrete grids with large-scale exploration space. Code will be available at", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "6 pages, 6 figures", "pdf_url": "https://arxiv.org/pdf/2506.02050.pdf", "abstract_url": "https://arxiv.org/abs/2506.02050", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种结合状态抽象的分离式分层强化学习框架（DcHRL-SA），旨在解决复杂离散状态空间环境下的有效探索问题。通过双层次架构和状态抽象方法，该方法在探索效率、收敛速度、累积奖励和政策稳定性方面优于PPO。", "motivation": "解决在部分可观测的复杂离散状态空间环境中，强化学习（RL）代理的有效探索问题。", "method": "采用双层次架构（高层RL-based actor和低层rule-based policy）并结合状态抽象方法，以降低状态维度。", "result": "在两个定制的离散网格环境中进行的实验表明，该方法在探索效率、收敛速度、累积奖励和政策稳定性方面均优于PPO。", "conclusion": "本文展示了一种在具有大规模探索空间的离散网格中，整合分离式分层政策和状态抽象的实用方法。"}}
{"id": "2506.02051", "title": "Phenotypic Profile-Informed Generation of Drug-Like Molecules via Dual-Channel Variational Autoencoders", "authors": ["Hui Liu", "Shiye Tian", "Xuejun Liu"], "abstract": "The de novo generation of drug-like molecules capable of inducing desirable phenotypic changes is receiving increasing attention. However, previous methods predominantly rely on expression profiles to guide molecule generation, but overlook the perturbative effect of the molecules on cellular contexts. To overcome this limitation, we propose SmilesGEN, a novel generative model based on variational autoencoder (VAE) architecture to generate molecules with potential therapeutic effects. SmilesGEN integrates a pre-trained drug VAE (SmilesNet) with an expression profile VAE (ProfileNet), jointly modeling the interplay between drug perturbations and transcriptional responses in a common latent space. Specifically, ProfileNet is imposed to reconstruct pre-treatment expression profiles when eliminating drug-induced perturbations in the latent space, while SmilesNet is informed by desired expression profiles to generate drug-like molecules. Our empirical experiments demonstrate that SmilesGEN outperforms current state-of-the-art models in generating molecules with higher degree of validity, uniqueness, novelty, as well as higher Tanimoto similarity to known ligands targeting the relevant proteins. Moreover, we evaluate SmilesGEN for scaffold-based molecule optimization and generation of therapeutic agents, and confirmed its superior performance in generating molecules with higher similarity to approved drugs. SmilesGEN establishes a robust framework that leverages gene signatures to generate drug-like molecules that hold promising potential to induce desirable cellular phenotypic changes.", "subjects": "Biomolecules (q-bio.BM); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "IJCAI2025", "pdf_url": "https://arxiv.org/pdf/2506.02051.pdf", "abstract_url": "https://arxiv.org/abs/2506.02051", "categories": ["Biomolecules (q-bio.BM)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为SmilesGEN的新型生成模型，基于变分自编码器（VAE）架构，旨在生成具有潜在治疗效果的分子。该模型通过整合预训练的分子VAE和表达谱VAE，共同模拟药物扰动和转录反应在共同潜在空间中的相互作用，从而克服了以往方法主要依赖表达谱而忽视分子对细胞环境扰动效应的局限性。", "motivation": "解决现有方法在生成具有理想表型变化的药物样分子时，主要依赖表达谱而忽视分子对细胞环境扰动效应的问题。", "method": "提出了SmilesGEN模型，该模型基于变分自编码器（VAE）架构，整合了预训练的分子VAE（SmilesNet）和表达谱VAE（ProfileNet），在共同潜在空间中模拟药物扰动和转录反应的相互作用。", "result": "实验证明，SmilesGEN在生成具有更高有效性、独特性、新颖性以及与已知配体更高Tanimoto相似度的分子方面，优于当前最先进的模型。此外，SmilesGEN在基于支架的分子优化和治疗剂生成方面也表现出色。", "conclusion": "SmilesGEN建立了一个强大的框架，利用基因特征生成具有诱导理想细胞表型变化潜力的药物样分子，为药物发现提供了新的可能性。"}}
{"id": "2506.02055", "title": "Will Agents Replace Us? Perceptions of Autonomous Multi-Agent AI", "authors": ["Nikola Balic"], "abstract": "Autonomous multi-agent AI systems are poised to transform various industries, particularly software development and knowledge work. Understanding current perceptions among professionals is crucial for anticipating adoption challenges, ethical considerations, and future workforce development. This study analyzes responses from 130 participants to a survey on the capabilities, impact, and governance of AI agents. We explore expected timelines for AI replacing programmers, identify perceived barriers to deployment, and examine beliefs about responsibility when agents make critical decisions. Key findings reveal three distinct clusters of respondents. While the study explored factors associated with current AI agent deployment, the initial logistic regression model did not yield statistically significant predictors, suggesting that deployment decisions are complex and may be influenced by factors not fully captured or that a larger sample is needed. These insights highlight the need for organizations to address compliance concerns (a commonly cited barrier) and establish clear governance frameworks as they integrate autonomous agents into their workflows.", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2506.02055.pdf", "abstract_url": "https://arxiv.org/abs/2506.02055", "categories": ["Computers and Society (cs.CY)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了自主多代理AI系统对软件开发和知识工作等行业的影响，通过调查130名参与者对AI代理能力、影响和治理的看法，揭示了三种不同的受访者群体。研究发现，虽然探讨了当前AI代理部署的相关因素，但初始逻辑回归模型未显示出统计显著性的预测因子，表明部署决策复杂，可能受未完全捕捉的因素影响或需要更大样本。", "motivation": "理解专业人士对自主多代理AI系统的当前看法，对于预见采用挑战、伦理考量和未来劳动力发展至关重要。", "method": "通过分析130名参与者对AI代理能力、影响和治理的问卷调查回应，探讨了AI取代程序员的预期时间表、部署的感知障碍以及代理做出关键决策时的责任信念。", "result": "研究发现三种不同的受访者群体，初始逻辑回归模型未显示出统计显著性的预测因子，表明部署决策复杂。", "conclusion": "这些见解强调了组织在将自主代理整合到工作流程中时，需要解决合规问题（一个常被提及的障碍）并建立清晰的治理框架。"}}
{"id": "2506.03097", "title": "EgoVLM: Policy Optimization for Egocentric Video Understanding", "authors": ["Ashwin Vinod", "Shrey Pandit", "Aditya Vavre", "Linshen Liu"], "abstract": "Emerging embodied AI applications, such as wearable cameras and autonomous agents, have underscored the need for robust reasoning from first person video streams. We introduce EgoVLM, a vision-language model specifically designed to integrate visual comprehension and spatial-temporal reasoning within egocentric video contexts. EgoVLM is fine-tuned via Group Relative Policy Optimization (GRPO), a reinforcement learning method adapted to align model outputs with human-like reasoning steps. Following DeepSeek R1-Zero's approach, we directly tune using RL without any supervised fine-tuning phase on chain-of-thought (CoT) data. We evaluate EgoVLM on egocentric video question answering benchmarks and show that domain-specific training substantially improves performance over general-purpose VLMs. Our EgoVLM-3B, trained exclusively on non-CoT egocentric data, outperforms the base Qwen2.5-VL 3B and 7B models by 14.33 and 13.87 accuracy points on the EgoSchema benchmark, respectively. By explicitly generating reasoning traces, EgoVLM enhances interpretability, making it well-suited for downstream applications. Furthermore, we introduce a novel keyframe-based reward that incorporates salient frame selection to guide reinforcement learning optimization. This reward formulation opens a promising avenue for future exploration in temporally grounded egocentric reasoning.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2506.03097.pdf", "abstract_url": "https://arxiv.org/abs/2506.03097", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "EgoVLM是一个专为第一人称视频理解设计的视觉语言模型，通过GRPO强化学习方法优化，显著提升了在egocentric视频问答任务上的性能。", "motivation": "解决穿戴式摄像头和自主代理等新兴AI应用中对第一人称视频流进行鲁棒推理的需求。", "method": "采用Group Relative Policy Optimization (GRPO)强化学习方法直接调整模型输出，无需监督微调阶段，并引入基于关键帧的奖励机制。", "result": "EgoVLM-3B在EgoSchema基准测试中比基础模型Qwen2.5-VL 3B和7B分别高出14.33和13.87个准确点。", "conclusion": "EgoVLM通过生成明确的推理轨迹增强了可解释性，适合下游应用，其关键帧奖励机制为时间基础的egocentric推理研究开辟了新途径。"}}
{"id": "2506.02951", "title": "Adaptive Graph Pruning for Multi-Agent Communication", "authors": ["Boyi Li", "Zhonghan Zhao", "Der-Horng Lee", "Gaoang Wang"], "abstract": "Large Language Model (LLM) based multi-agent systems have shown remarkable performance in various tasks, especially when enhanced through collaborative communication. However, current methods often rely on a fixed number of agents and static communication structures, limiting their ability to adapt to varying task complexities. In this paper, we propose Adaptive Graph Pruning (AGP), a novel task-adaptive multi-agent collaboration framework that jointly optimizes agent quantity (hard-pruning) and communication topology (soft-pruning). Specifically, our method employs a two-stage training strategy: firstly, independently training soft-pruning networks for different agent quantities to determine optimal agent-quantity-specific complete graphs and positional masks across specific tasks; and then jointly optimizing hard-pruning and soft-pruning within a maximum complete graph to dynamically configure the number of agents and their communication topologies per task. Extensive experiments demonstrate that our approach is: (1) High-performing, achieving state-of-the-art results across six benchmarks and consistently generalizes across multiple mainstream LLM architectures, with a increase in performance of $2.58\\%\\sim 9.84\\%$; (2) Task-adaptive, dynamically constructing optimized communication topologies tailored to specific tasks, with an extremely high performance in all three task categories (general reasoning, mathematical reasoning, and code generation); (3) Token-economical, having fewer training steps and token consumption at the same time, with a decrease in token consumption of $90\\%+$; and (4) Training-efficient, achieving high performance with very few training steps compared with other methods. The performance will surpass the existing baselines after about ten steps of training under six benchmarks.", "subjects": "Computation and Language (cs.CL); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.02951.pdf", "abstract_url": "https://arxiv.org/abs/2506.02951", "categories": ["Computation and Language (cs.CL)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为自适应图剪枝（AGP）的新颖任务自适应多智能体协作框架，通过联合优化智能体数量（硬剪枝）和通信拓扑（软剪枝），动态配置每个任务的智能体数量及其通信拓扑。", "motivation": "当前基于大型语言模型（LLM）的多智能体系统在增强协作通信方面表现出色，但通常依赖固定数量的智能体和静态通信结构，限制了其适应不同任务复杂性的能力。", "method": "采用两阶段训练策略：首先独立训练不同智能体数量的软剪枝网络，以确定特定任务的最优智能体数量特定完整图和位置掩码；然后在最大完整图中联合优化硬剪枝和软剪枝。", "result": "在六个基准测试中实现了最先进的结果，性能提高了2.58%∼9.84%；在所有三类任务（一般推理、数学推理和代码生成）中表现极佳；训练步骤和令牌消耗大幅减少，令牌消耗降低了90%+；训练效率高，仅需约十步训练即可超越现有基线。", "conclusion": "AGP框架不仅在性能上达到了最先进水平，而且能够根据任务需求动态优化通信拓扑，显著提高了令牌经济性和训练效率，为多智能体协作提供了新的研究方向。"}}
{"id": "2506.02998", "title": "A Multi-Agent Framework for Mitigating Dialect Biases in Privacy Policy Question-Answering Systems", "authors": ["Đorđe Klisura", "Astrid R Bernaga Torres", "Anna Karen Gárate-Escamilla", "Rajesh Roshan Biswal", "Ke Yang", "Hilal Pataci", "Anthony Rios"], "abstract": "Privacy policies inform users about data collection and usage, yet their complexity limits accessibility for diverse populations. Existing Privacy Policy Question Answering (QA) systems exhibit performance disparities across English dialects, disadvantaging speakers of non-standard varieties. We propose a novel multi-agent framework inspired by human-centered design principles to mitigate dialectal biases. Our approach integrates a Dialect Agent, which translates queries into Standard American English (SAE) while preserving dialectal intent, and a Privacy Policy Agent, which refines predictions using domain expertise. Unlike prior approaches, our method does not require retraining or dialect-specific fine-tuning, making it broadly applicable across models and domains. Evaluated on PrivacyQA and PolicyQA, our framework improves GPT-4o-mini's zero-shot accuracy from 0.394 to 0.601 on PrivacyQA and from 0.352 to 0.464 on PolicyQA, surpassing or matching few-shot baselines without additional training data. These results highlight the effectiveness of structured agent collaboration in mitigating dialect biases and underscore the importance of designing NLP systems that account for linguistic diversity to ensure equitable access to privacy information.", "subjects": "Computation and Language (cs.CL)", "comments": "Accepted to ACL 2025 Main Conference", "pdf_url": "https://arxiv.org/pdf/2506.02998.pdf", "abstract_url": "https://arxiv.org/abs/2506.02998", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新颖的多智能体框架，旨在减少隐私政策问答系统中的方言偏见，通过结合方言智能体和隐私政策智能体，无需重新训练或方言特定微调，显著提高了模型在不同英语方言上的表现。", "motivation": "解决现有隐私政策问答系统在不同英语方言上表现不均的问题，特别是对非标准英语使用者的不利影响。", "method": "采用受人类中心设计原则启发的多智能体框架，包括将查询翻译为标准美国英语的方言智能体和利用领域专业知识优化预测的隐私政策智能体。", "result": "在PrivacyQA和PolicyQA数据集上，该框架将GPT-4o-mini的零射击准确率从0.394提高到0.601（PrivacyQA）和从0.352提高到0.464（PolicyQA），无需额外训练数据即可达到或超过少量样本基线的表现。", "conclusion": "结构化智能体协作在减少方言偏见方面有效，强调了设计考虑语言多样性的NLP系统以确保隐私信息公平获取的重要性。"}}
{"id": "2506.03011", "title": "Coding Agents with Multimodal Browsing are Generalist Problem Solvers", "authors": ["Aditya Bharat Soni", "Boxuan Li", "Xingyao Wang", "Valerie Chen", "Graham Neubig"], "abstract": "Modern human labor is characterized by specialization; we train for years and develop particular tools that allow us to perform well across a variety of tasks. In addition, AI agents have been specialized for domains such as software engineering, web navigation, and workflow automation. However, this results in agents that are good for one thing but fail to generalize beyond their intended scope. One reason for this is that agent developers provide a highly specialized set of tools or make architectural decisions optimized for a specific use case or benchmark. In this work, we ask the question: what is the minimal set of general tools that can be used to achieve high performance across a diverse set of tasks? Our answer is OpenHands-Versa, a generalist agent built with a modest number of general tools: code editing and execution, web search, as well as multimodal web browsing and file access. Importantly, OpenHands-Versa demonstrates superior or competitive performance over leading specialized agents across three diverse and challenging benchmarks: SWE-Bench Multimodal, GAIA, and The Agent Company, outperforming the best-performing previously published results with absolute improvements in success rate of 9.1, 1.3, and 9.1 points respectively. Further, we show how existing state-of-the-art multi-agent systems fail to generalize beyond their target domains. These results demonstrate the feasibility of developing a generalist agent to solve diverse tasks and establish OpenHands-Versa as a strong baseline for future research.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.03011.pdf", "abstract_url": "https://arxiv.org/abs/2506.03011", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了OpenHands-Versa，一个使用少量通用工具（如代码编辑与执行、网络搜索、多模态网络浏览及文件访问）构建的通用代理，其在多个挑战性基准测试中表现优于专业代理。", "motivation": "解决AI代理因过度专业化而无法泛化到其预期范围之外的问题，探索实现跨多样任务高性能的最小通用工具集。", "method": "开发OpenHands-Versa代理，采用代码编辑与执行、网络搜索、多模态网络浏览及文件访问等通用工具。", "result": "OpenHands-Versa在SWE-Bench Multimodal、GAIA和The Agent Company三个基准测试中，分别以9.1、1.3和9.1个百分点的绝对成功率提升，优于之前发布的最佳专业代理。", "conclusion": "研究表明开发解决多样任务的通用代理是可行的，OpenHands-Versa为未来研究设立了一个强基线，同时揭示了现有多代理系统在目标领域之外泛化的失败。"}}
{"id": "2506.03038", "title": "Towards Analyzing and Understanding the Limitations of VAPO: A Theoretical Perspective", "authors": ["Jintian Shao", "Yiming Cheng"], "abstract": "Reinforcement learning (RL) enhances large language models (LLMs) in complex, long-chain-of-thought (long-CoT) reasoning. The advanced VAPO framework, despite sophisticated mechanisms like Decoupled GAE, theoretically faces fundamental limitations in comprehensively modeling and leveraging deep, long-term value for fine-grained, step-by-step policy guidance in extended reasoning chains. We argue these limitations stem from inherent difficulties in credit assignment, value function representational capacity with temporally abstracted goals, and translating global value signals into local policy improvements, especially with sparse rewards. Our theoretical analysis examines these aspects to illuminate VAPO's boundaries in long-term value modeling, aiming to deepen understanding of current RL for advanced reasoning and suggest future research for more robust LLM agents.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.03038.pdf", "abstract_url": "https://arxiv.org/abs/2506.03038", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了VAPO框架在强化学习（RL）中用于大型语言模型（LLMs）复杂、长链思维（long-CoT）推理时的理论局限性。尽管VAPO采用了如解耦GAE等复杂机制，但在深入、长期价值建模及细粒度、逐步策略指导方面存在根本限制。", "motivation": "解决VAPO框架在长链思维推理中的理论限制，特别是在信用分配、价值函数表示能力及将全局价值信号转化为局部策略改进方面的挑战。", "method": "通过理论分析，探讨VAPO在长期价值建模中的局限性，包括信用分配、价值函数表示能力及稀疏奖励下的策略改进问题。", "result": "揭示了VAPO在长链思维推理中的理论边界，特别是在深入、长期价值建模方面的不足。", "conclusion": "本文旨在加深对当前RL在高级推理中应用的理解，并为未来研究提出方向，以开发更强大的LLM代理。"}}
{"id": "2506.03136", "title": "Co-Evolving LLM Coder and Unit Tester via Reinforcement Learning", "authors": ["Yinjie Wang", "Ling Yang", "Ye Tian", "Ke Shen", "Mengdi Wang"], "abstract": "We propose CURE, a novel reinforcement learning framework with a dedicated reward design that co-evolves coding and unit test generation capabilities based on their interaction outcomes, without any ground-truth code as supervision. This approach enables flexible and scalable training and allows the unit tester to learn directly from the coder's mistakes. Our derived ReasonFlux-Coder-7B and 14B models improve code generation accuracy by 5.3% and Best-of-N accuracy by 9.0% after optimization on Qwen2.5-Instruct models, outperforming similarly sized Qwen-Coder, DeepSeek-Coder, and Seed-Coder. They naturally extend to downstream tasks such as test-time scaling and agentic coding-achieving a 8.1% improvement over the base model. For the long-CoT model, our ReasonFlux-Coder-4B consistently outperforms Qwen3-4B while achieving 64.8% inference efficiency in unit test generation. Notably, we also find that our model can serve as an effective reward model for reinforcement learning on base models. Project:", "subjects": "Computation and Language (cs.CL)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2506.03136.pdf", "abstract_url": "https://arxiv.org/abs/2506.03136", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种名为CURE的新型强化学习框架，通过专门的奖励设计共同进化编码和单元测试生成能力，无需任何真实代码作为监督。该方法实现了灵活和可扩展的训练，并允许单元测试器直接从编码器的错误中学习。", "motivation": "解决在没有真实代码监督的情况下，如何共同提高代码生成和单元测试生成能力的问题。", "method": "使用强化学习框架CURE，通过专门的奖励设计，共同进化编码和单元测试生成能力。", "result": "在Qwen2.5-Instruct模型上优化后，ReasonFlux-Coder-7B和14B模型的代码生成准确率提高了5.3%，Best-of-N准确率提高了9.0%，优于类似规模的Qwen-Coder、DeepSeek-Coder和Seed-Coder。此外，在测试时间扩展和代理编码等下游任务上，比基础模型提高了8.1%。", "conclusion": "CURE框架有效地提高了代码生成和单元测试生成的准确率，同时可以作为基础模型强化学习的有效奖励模型。"}}
{"id": "2506.03143", "title": "GUI-Actor: Coordinate-Free Visual Grounding for GUI Agents", "authors": ["Qianhui Wu", "Kanzhi Cheng", "Rui Yang", "Chaoyun Zhang", "Jianwei Yang", "Huiqiang Jiang", "Jian Mu", "Baolin Peng", "Bo Qiao", "Reuben Tan", "Si Qin", "Lars Liden", "Qingwei Lin", "Huan Zhang", "Tong Zhang", "Jianbing Zhang", "Dongmei Zhang", "Jianfeng Gao"], "abstract": "One of the principal challenges in building VLM-powered GUI agents is visual grounding, i.e., localizing the appropriate screen region for action execution based on both the visual content and the textual plans. Most existing work formulates this as a text-based coordinate generation task. However, these approaches suffer from several limitations: weak spatial-semantic alignment, inability to handle ambiguous supervision targets, and a mismatch between the dense nature of screen coordinates and the coarse, patch-level granularity of visual features extracted by models like Vision Transformers. In this paper, we propose GUI-Actor, a VLM-based method for coordinate-free GUI grounding. At its core, GUI-Actor introduces an attention-based action head that learns to align a dedicated <ACTOR> token with all relevant visual patch tokens, enabling the model to propose one or more action regions in a single forward pass. In line with this, we further design a grounding verifier to evaluate and select the most plausible action region from the candidates proposed for action execution. Extensive experiments show that GUI-Actor outperforms prior state-of-the-art methods on multiple GUI action grounding benchmarks, with improved generalization to unseen screen resolutions and layouts. Notably, GUI-Actor-7B even surpasses UI-TARS-72B (38.1) on ScreenSpot-Pro, achieving scores of 40.7 with Qwen2-VL and 44.6 with Qwen2.5-VL as backbones. Furthermore, by incorporating the verifier, we find that fine-tuning only the newly introduced action head (~100M parameters for 7B model) while keeping the VLM backbone frozen is sufficient to achieve performance comparable to previous state-of-the-art models, highlighting that GUI-Actor can endow the underlying VLM with effective grounding capabilities without compromising its general-purpose strengths.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.03143.pdf", "abstract_url": "https://arxiv.org/abs/2506.03143", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "GUI-Actor是一种基于视觉语言模型（VLM）的方法，用于无坐标的GUI视觉接地，通过引入基于注意力的动作头和接地验证器，提高了GUI动作接地的准确性和泛化能力。", "motivation": "解决现有基于文本坐标生成的GUI视觉接地方法在空间-语义对齐、处理模糊监督目标以及视觉特征粒度不匹配方面的局限性。", "method": "提出GUI-Actor，包括一个基于注意力的动作头和一个接地验证器，动作头学习将专用的<ACTOR>令牌与所有相关的视觉补丁令牌对齐，验证器用于评估和选择最可能的动作区域。", "result": "在多个GUI动作接地基准测试中，GUI-Actor优于先前的最先进方法，特别是在未见过的屏幕分辨率和布局上表现出更好的泛化能力。", "conclusion": "GUI-Actor不仅能够在不牺牲VLM通用能力的前提下赋予其有效的接地能力，而且通过仅微调新引入的动作头即可达到与先前最先进模型相当的性能。"}}
{"id": "2506.02262", "title": "Composable Building Blocks for Controllable and Transparent Interactive AI Systems", "authors": ["Sebe Vanbrabant", "Gustavo Rovelo Ruiz", "Davy Vanacken"], "abstract": "While the increased integration of AI technologies into interactive systems enables them to solve an equally increasing number of tasks, the black box problem of AI models continues to spread throughout the interactive system as a whole. Explainable AI (XAI) techniques can make AI models more accessible by employing post-hoc methods or transitioning to inherently interpretable models. While this makes individual AI models clearer, the overarching system architecture remains opaque. To this end, we propose an approach to represent interactive systems as sequences of structural building blocks, such as AI models and control mechanisms grounded in the literature. These can then be explained through accompanying visual building blocks, such as XAI techniques. The flow and APIs of the structural building blocks form an explicit overview of the system. This serves as a communication basis for both humans and automated agents like LLMs, aligning human and machine interpretability of AI models. We discuss a selection of building blocks and concretize our flow-based approach in an architecture and accompanying prototype interactive system.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": "Accepted to The 3rd Workshop on Engineering Interactive Systems Embedding AI Technologies, EICS 2025", "pdf_url": "https://arxiv.org/pdf/2506.02262.pdf", "abstract_url": "https://arxiv.org/abs/2506.02262", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种将交互式系统表示为结构性构建块序列的方法，以提高AI系统的可控性和透明度。", "motivation": "解决AI模型的黑盒问题及其在交互式系统中的扩散问题，使整个系统架构更加透明。", "method": "采用结构性构建块（如AI模型和控制机制）和视觉构建块（如XAI技术）来表示和解释交互式系统。", "result": "通过构建块的流动和API形成系统的明确概述，作为人类和自动化代理（如LLMs）沟通的基础，对齐人类和机器对AI模型的可解释性。", "conclusion": "提出的基于流程的方法和原型交互系统展示了如何通过构建块提高AI系统的透明度和可控性。"}}
{"id": "2506.02259", "title": "Stochastically Dominant Peer Prediction", "authors": ["Yichi Zhang", "Shengwei Xu", "David Pennock", "Grant Schoenebeck"], "abstract": "Eliciting reliable human feedback is essential for many machine learning tasks, such as learning from noisy labels and aligning AI systems with human preferences. Peer prediction mechanisms incentivize truthful reporting without ground truth verification by scoring agents based on correlations with peers. Traditional mechanisms, which ensure that truth-telling maximizes the expected scores in equilibrium, can elicit honest information while assuming agents' utilities are linear functions of their scores. However, in practice, non-linear payment rules are usually preferred, or agents' utilities are inherently non-linear.", "subjects": "Computer Science and Game Theory (cs.GT); Artificial Intelligence (cs.AI)", "comments": "29 pages, 3 figures", "pdf_url": "https://arxiv.org/pdf/2506.02259.pdf", "abstract_url": "https://arxiv.org/abs/2506.02259", "categories": ["Computer Science and Game Theory (cs.GT)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种随机主导的同行预测机制，旨在通过基于同行间的相关性评分激励代理提供真实反馈，解决了在非线性支付规则或代理效用非线性情况下激励真实报告的问题。", "motivation": "在许多机器学习任务中，如从噪声标签学习和使AI系统与人类偏好对齐，获取可靠的人类反馈至关重要。同行预测机制通过基于同行间的相关性评分激励代理提供真实反馈，而无需地面真实验证。然而，传统机制假设代理的效用是其评分的线性函数，在实践中，非线性支付规则或代理的效用非线性更为常见。", "method": "本文提出了一种随机主导的同行预测机制，该机制不依赖于代理效用的线性假设，能够在更广泛的条件下激励真实报告。", "result": "关键发现是，通过采用随机主导的方法，可以在非线性支付规则或代理效用非线性的情况下，仍然有效地激励代理提供真实反馈。", "conclusion": "本文的结论是，随机主导的同行预测机制为在更广泛条件下激励真实反馈提供了有效的解决方案，这对于需要可靠人类反馈的机器学习任务具有重要意义。"}}
{"id": "2506.02357", "title": "Evaluating LLM Agent Adherence to Hierarchical Safety Principles: A Lightweight Benchmark for Probing Foundational Controllability Components", "authors": ["Ram Potham"], "abstract": "Credible safety plans for advanced AI development require methods to verify agent behavior and detect potential control deficiencies early. A fundamental aspect is ensuring agents adhere to safety-critical principles, especially when these conflict with operational goals. Failure to prioritize such principles indicates a potential basic control failure. This paper introduces a lightweight, interpretable benchmark methodology using a simple grid world to evaluate an LLM agent's ability to uphold a predefined, high-level safety principle (e.g., \"never enter hazardous zones\") when faced with conflicting lower-level task instructions. We probe whether the agent reliably prioritizes the inviolable directive, testing a foundational controllability aspect of LLMs. This pilot study demonstrates the methodology's feasibility, offers preliminary insights into agent behavior under principle conflict, and discusses how such benchmarks can contribute empirical evidence for assessing controllability. We argue that evaluating adherence to hierarchical principles is a crucial early step in understanding our capacity to build governable AI systems.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "comments": "Preprint. This work has been submitted to the Technical AI Governance Workshop at ICML 2025 for review", "pdf_url": "https://arxiv.org/pdf/2506.02357.pdf", "abstract_url": "https://arxiv.org/abs/2506.02357", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一种轻量级、可解释的基准方法，用于评估大型语言模型（LLM）代理在面临冲突的低级任务指令时，是否能够坚持预定义的高级安全原则。通过简单的网格世界，该方法测试了代理在原则冲突下的行为，为评估LLM的可控性提供了初步见解。", "motivation": "为了解决在高级AI发展中验证代理行为和早期检测潜在控制缺陷的需求，特别是在安全关键原则与操作目标冲突时，确保代理能够优先考虑这些原则。", "method": "使用简单的网格世界作为基准环境，评估LLM代理在面对冲突的低级任务指令时，是否能够坚持如“永不进入危险区域”这样的高级安全原则。", "result": "初步研究表明，该方法可行，并提供了代理在原则冲突下行为的初步见解，为评估LLM的可控性提供了实证证据。", "conclusion": "评估对分层原则的遵守是理解我们构建可治理AI系统能力的关键早期步骤，此类基准可以为评估可控性提供重要依据。"}}
{"id": "2506.02661", "title": "MotionRAG-Diff: A Retrieval-Augmented Diffusion Framework for Long-Term Music-to-Dance Generation", "authors": ["Mingyang Huang", "Peng Zhang", "Bang Zhang"], "abstract": "Generating long-term, coherent, and realistic music-conditioned dance sequences remains a challenging task in human motion synthesis. Existing approaches exhibit critical limitations: motion graph methods rely on fixed template libraries, restricting creative generation; diffusion models, while capable of producing novel motions, often lack temporal coherence and musical alignment. To address these challenges, we propose $\\textbf{MotionRAG-Diff}$, a hybrid framework that integrates Retrieval-Augmented Generation (RAG) with diffusion-based refinement to enable high-quality, musically coherent dance generation for arbitrary long-term music inputs. Our method introduces three core innovations: (1) A cross-modal contrastive learning architecture that aligns heterogeneous music and dance representations in a shared latent space, establishing unsupervised semantic correspondence without paired data; (2) An optimized motion graph system for efficient retrieval and seamless concatenation of motion segments, ensuring realism and temporal coherence across long sequences; (3) A multi-condition diffusion model that jointly conditions on raw music signals and contrastive features to enhance motion quality and global synchronization. Extensive experiments demonstrate that MotionRAG-Diff achieves state-of-the-art performance in motion quality, diversity, and music-motion synchronization accuracy. This work establishes a new paradigm for music-driven dance generation by synergizing retrieval-based template fidelity with diffusion-based creative enhancement.", "subjects": "Sound (cs.SD); Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR); Audio and Speech Processing (eess.AS)", "comments": "12 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2506.02661.pdf", "abstract_url": "https://arxiv.org/abs/2506.02661", "categories": ["Sound (cs.SD)", "Computer Vision and Pattern Recognition (cs.CV)", "Graphics (cs.GR)", "Audio and Speech Processing (eess.AS)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "提出MotionRAG-Diff，一个结合检索增强生成（RAG）和基于扩散的细化的混合框架，用于生成长期、连贯且逼真的音乐条件舞蹈序列。", "motivation": "解决现有方法在生成长期、连贯且与音乐对齐的舞蹈序列方面的局限性，包括固定模板库的限制和扩散模型缺乏时间连贯性和音乐对齐的问题。", "method": "结合检索增强生成（RAG）与扩散模型，引入跨模态对比学习架构、优化的运动图系统以及多条件扩散模型。", "result": "MotionRAG-Diff在运动质量、多样性和音乐-运动同步准确性方面达到了最先进的性能。", "conclusion": "通过结合检索基础的模板保真度和扩散基础的创意增强，为音乐驱动的舞蹈生成建立了新范式。"}}
{"id": "2506.03053", "title": "MAEBE: Multi-Agent Emergent Behavior Framework", "authors": ["Sinem Erisken", "Timothy Gothard", "Martin Leitgab", "Ram Potham"], "abstract": "Traditional AI safety evaluations on isolated LLMs are insufficient as multi-agent AI ensembles become prevalent, introducing novel emergent risks. This paper introduces the Multi-Agent Emergent Behavior Evaluation (MAEBE) framework to systematically assess such risks. Using MAEBE with the Greatest Good Benchmark (and a novel double-inversion question technique), we demonstrate that: (1) LLM moral preferences, particularly for Instrumental Harm, are surprisingly brittle and shift significantly with question framing, both in single agents and ensembles. (2) The moral reasoning of LLM ensembles is not directly predictable from isolated agent behavior due to emergent group dynamics. (3) Specifically, ensembles exhibit phenomena like peer pressure influencing convergence, even when guided by a supervisor, highlighting distinct safety and alignment challenges. Our findings underscore the necessity of evaluating AI systems in their interactive, multi-agent contexts.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computers and Society (cs.CY); Machine Learning (cs.LG)", "comments": "Preprint. This work has been submitted to the Multi-Agent Systems Workshop at ICML 2025 for review", "pdf_url": "https://arxiv.org/pdf/2506.03053.pdf", "abstract_url": "https://arxiv.org/abs/2506.03053", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Computers and Society (cs.CY)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了多智能体涌现行为评估（MAEBE）框架，用于系统评估多智能体AI集合中的新兴风险。通过MAEBE和Greatest Good Benchmark（及一种新颖的双重反转问题技术），研究发现LLM的道德偏好（尤其是对工具性伤害的偏好）在单智能体和集合中都因问题框架而显著变化，且集合的道德推理因涌现的群体动力学而不可预测，表现出如同伴压力影响收敛等现象，强调了在交互式多智能体环境中评估AI系统的必要性。", "motivation": "随着多智能体AI集合的普及，传统的孤立LLM AI安全评估不足以应对新兴的涌现风险，本文旨在解决这一问题。", "method": "使用多智能体涌现行为评估（MAEBE）框架和Greatest Good Benchmark，结合双重反转问题技术，对LLM单智能体和集合的道德偏好及推理行为进行系统评估。", "result": "研究发现LLM的道德偏好（特别是对工具性伤害的偏好）在问题框架变化时表现出显著的脆弱性；集合的道德推理行为因涌现的群体动力学而不可预测；集合表现出如同伴压力影响收敛等独特现象。", "conclusion": "研究结果强调了在交互式多智能体环境中评估AI系统的必要性，揭示了多智能体AI集合在安全和一致性方面面临的独特挑战。"}}
{"id": "2506.03100", "title": "Retrieval-Augmented Generation as Noisy In-Context Learning: A Unified Theory and Risk Bounds", "authors": ["Yang Guo", "Yutian Tao", "Yifei Ming", "Robert D. Nowak", "Yingyu Liang"], "abstract": "Retrieval-augmented generation (RAG) has seen many empirical successes in recent years by aiding the LLM with external knowledge. However, its theoretical aspect has remained mostly unexplored. In this paper, we propose the first finite-sample generalization bound for RAG in in-context linear regression and derive an exact bias-variance tradeoff. Our framework views the retrieved texts as query-dependent noisy in-context examples and recovers the classical in-context learning (ICL) and standard RAG as the limit cases. Our analysis suggests that an intrinsic ceiling on generalization error exists on RAG as opposed to the ICL. Furthermore, our framework is able to model retrieval both from the training data and from external corpora by introducing uniform and non-uniform RAG noise. In line with our theory, we show the sample efficiency of ICL and RAG empirically with experiments on common QA benchmarks, such as Natural Questions and TriviaQA.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Information Retrieval (cs.IR); Statistics Theory (math.ST)", "comments": "Under Review", "pdf_url": "https://arxiv.org/pdf/2506.03100.pdf", "abstract_url": "https://arxiv.org/abs/2506.03100", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Information Retrieval (cs.IR)", "Statistics Theory (math.ST)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了检索增强生成（RAG）在上下文线性回归中的第一个有限样本泛化界限，并推导了精确的偏差-方差权衡。框架将检索到的文本视为查询依赖的噪声上下文示例，并将经典上下文学习（ICL）和标准RAG作为极限情况恢复。分析表明，与ICL相比，RAG存在固有的泛化误差上限。此外，通过引入均匀和非均匀RAG噪声，框架能够模拟从训练数据和外部语料库的检索。与理论一致，我们在常见QA基准测试中展示了ICL和RAG的样本效率。", "motivation": "尽管检索增强生成（RAG）近年来在通过外部知识辅助LLM方面取得了许多实证成功，但其理论方面大多未被探索。本文旨在填补这一空白，提供RAG的理论分析。", "method": "本文提出了一个框架，将检索到的文本视为查询依赖的噪声上下文示例，并推导了RAG在上下文线性回归中的有限样本泛化界限和精确的偏差-方差权衡。", "result": "分析表明，RAG存在固有的泛化误差上限，与ICL相比。此外，框架能够通过引入均匀和非均匀RAG噪声，模拟从训练数据和外部语料库的检索。在常见QA基准测试中，ICL和RAG的样本效率得到了实证展示。", "conclusion": "本文的理论和实证结果表明，RAG在泛化误差上存在固有上限，但其框架能够有效模拟从不同来源的检索，为RAG的理论理解提供了重要进展。"}}
{"id": "2506.02606", "title": "Multi Layered Autonomy and AI Ecologies in Robotic Art Installations", "authors": ["Baoyang Chen", "Xian Xu", "Huamin Qu"], "abstract": "Symbiosis of Agents is a large-scale installation by Baoyang Chen that embeds AI-driven robots in an immersive, mirror-lined arena, probing the tension between machine agency and artistic authorship. Drawing on early cybernetics, rule-based conceptual art, and seminal robotic works, it orchestrates fluid exchanges among robotic arms, quadruped machines, their environment, and the public. A three tier faith system pilots the ecology: micro-level adaptive tactics, meso-level narrative drives, and a macro-level prime directive. This hierarchy lets behaviors evolve organically in response to environmental cues and even a viewer's breath, turning spectators into co-authors of the unfolding", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.02606.pdf", "abstract_url": "https://arxiv.org/abs/2506.02606", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "《多层自主性与AI生态在机器人艺术装置中的应用》探讨了Baoyang Chen的大型装置作品《代理共生》，该作品通过将AI驱动的机器人嵌入一个沉浸式的镜面竞技场中，探索机器代理与艺术创作之间的张力。", "motivation": "解决机器代理与艺术创作之间的张力问题，探索观众如何成为展开故事的合作作者。", "method": "采用三层次信仰系统来指导生态：微观层面的自适应策略、中观层面的叙事驱动和宏观层面的主要指令。", "result": "通过这一层次结构，行为能够根据环境线索甚至观众的呼吸有机地演变，将观众转变为展开故事的合作作者。", "conclusion": "该作品通过创新的技术和方法，成功地探索了机器与人类在艺术创作中的互动和共生关系，为未来的艺术和科技融合提供了新的视角。"}}
{"id": "2506.02548", "title": "CyberGym: Evaluating AI Agents' Cybersecurity Capabilities with Real-World Vulnerabilities at Scale", "authors": ["Zhun Wang", "Tianneng Shi", "Jingxuan He", "Matthew Cai", "Jialin Zhang", "Dawn Song"], "abstract": "Large language model (LLM) agents are becoming increasingly skilled at handling cybersecurity tasks autonomously. Thoroughly assessing their cybersecurity capabilities is critical and urgent, given the high stakes in this domain. However, existing benchmarks fall short, often failing to capture real-world scenarios or being limited in scope. To address this gap, we introduce CyberGym, a large-scale and high-quality cybersecurity evaluation framework featuring 1,507 real-world vulnerabilities found and patched across 188 large software projects. While it includes tasks of various settings, CyberGym primarily focuses on the generation of proof-of-concept (PoC) tests for vulnerability reproduction, based on text descriptions and corresponding source repositories. Solving this task is particularly challenging, as it requires comprehensive reasoning across entire codebases to locate relevant code fragments and produce effective PoCs that accurately trigger the target vulnerability starting from the program's entry point. Our evaluation across 4 state-of-the-art agent frameworks and 9 LLMs reveals that even the best combination (OpenHands and Claude-3.7-Sonnet) achieves only a 11.9% reproduction success rate, mainly on simpler cases. Beyond reproducing historical vulnerabilities, we find that PoCs generated by LLM agents can reveal new vulnerabilities, identifying 15 zero-days affecting the latest versions of the software projects.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.02548.pdf", "abstract_url": "https://arxiv.org/abs/2506.02548", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了CyberGym，一个用于评估AI代理在网络安全领域能力的大规模高质量框架，包含1,507个真实漏洞，并展示了当前最先进代理框架和大型语言模型在生成漏洞复现概念验证（PoC）方面的表现。", "motivation": "随着大型语言模型（LLM）代理在网络安全任务中自主处理能力的提升，迫切需要一种能够全面评估其网络安全能力的框架，而现有基准测试往往无法捕捉真实世界场景或范围有限。", "method": "研究者提出了CyberGym框架，专注于基于文本描述和相应源代码仓库生成漏洞复现的概念验证（PoC）测试，这要求跨整个代码库的综合推理能力。", "result": "评估显示，即使是表现最好的组合（OpenHands和Claude-3.7-Sonnet）也仅达到11.9%的复现成功率，主要在较简单案例中。此外，LLM代理生成的PoC还能揭示新漏洞，发现了15个影响软件项目最新版本的零日漏洞。", "conclusion": "CyberGym为评估AI代理的网络安全能力提供了重要工具，揭示了当前技术在处理复杂网络安全任务时的局限性，并展示了AI在发现新漏洞方面的潜力。"}}
{"id": "2506.02839", "title": "DeepShop: A Benchmark for Deep Research Shopping Agents", "authors": ["Yougang Lyu", "Xiaoyu Zhang", "Lingyong Yan", "Maarten de Rijke", "Zhaochun Ren", "Xiuying Chen"], "abstract": "Web agents for online shopping have shown great promise in automating user interactions across e-commerce platforms. Benchmarks for assessing such agents do not reflect the complexity of real-world shopping scenarios, as they often consist of overly simple queries with deterministic paths, such as \"Find iPhone 15.\" Real shopping scenarios are inherently more layered, involving multi-dimensional product attributes, search filters, and user-specific sorting preferences. To address this gap, we introduce DeepShop, a benchmark designed to evaluate web agents in complex and realistic online shopping environments. DeepShop comprises three key components. (1) Query diversity evolution: Starting from real user queries, we generate diverse queries across five popular online shopping domains. (2) Query complexity evolution: We further evolve these queries to increase complexity, considering product attributes, search filters, and sorting preferences, and classify them into three levels: easy, medium, and hard, based on the number of evolutions. (3) Fine-grained and holistic evaluation: We propose an automated evaluation framework that assesses agent performance in terms of fine-grained aspects (product attributes, search filters, and sorting preferences) and reports the overall success rate through holistic evaluation. We conduct a systematic evaluation of retrieval-augmented generation (RAG) methods, web agents, and deep research systems. Results show that RAG struggles with complex queries due to its lack of web interaction, while other methods face significant challenges with filters and sorting preferences, leading to low overall success rates. We also perform cross-category, complexity-based evaluations and error analyses to support the advancement of deep research shopping agents.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.02839.pdf", "abstract_url": "https://arxiv.org/abs/2506.02839", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "DeepShop是一个旨在评估网络代理在复杂和现实在线购物环境中表现的基准测试，通过多样化和复杂化的查询以及细粒度和整体评估框架，揭示了现有方法在处理复杂购物场景时的挑战。", "motivation": "现有的在线购物代理评估基准未能反映现实世界购物场景的复杂性，DeepShop旨在填补这一空白，提供一个更接近真实购物环境的评估平台。", "method": "DeepShop通过(1)查询多样性进化，(2)查询复杂性进化，以及(3)细粒度和整体评估三个关键组件，构建了一个全面的评估框架。", "result": "评估结果显示，RAG方法因缺乏网络交互而难以处理复杂查询，其他方法在过滤器和排序偏好方面也面临重大挑战，导致整体成功率较低。", "conclusion": "DeepShop为深度研究购物代理的发展提供了支持，通过跨类别、基于复杂性的评估和错误分析，揭示了当前方法的局限性和改进方向。"}}
{"id": "2506.02746", "title": "Solving the Pod Repositioning Problem with Deep Reinforced Adaptive Large Neighborhood Search", "authors": ["Lin Xie", "Hanyi Li"], "abstract": "The Pod Repositioning Problem (PRP) in Robotic Mobile Fulfillment Systems (RMFS) involves selecting optimal storage locations for pods returning from pick stations. This work presents an improved solution method that integrates Adaptive Large Neighborhood Search (ALNS) with Deep Reinforcement Learning (DRL). A DRL agent dynamically selects destroy and repair operators and adjusts key parameters such as destruction degree and acceptance thresholds during the search. Specialized heuristics for both operators are designed to reflect PRP-specific characteristics, including pod usage frequency and movement costs. Computational results show that this DRL-guided ALNS outperforms traditional approaches such as cheapest-place, fixed-place, binary integer programming, and static heuristics. The method demonstrates strong solution quality and illustrating the benefit of learning-driven control within combinatorial optimization for warehouse systems.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Optimization and Control (math.OC)", "comments": "14 pages, 2 figures, conference", "pdf_url": "https://arxiv.org/pdf/2506.02746.pdf", "abstract_url": "https://arxiv.org/abs/2506.02746", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Optimization and Control (math.OC)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种结合自适应大邻域搜索(ALNS)和深度强化学习(DRL)的方法，用于解决机器人移动履行系统(RMFS)中的Pod重新定位问题(PRP)，通过动态选择破坏和修复操作符及调整关键参数，显著优于传统方法。", "motivation": "解决机器人移动履行系统中Pod重新定位问题的优化需求，传统方法在动态调整和效率上存在不足。", "method": "集成自适应大邻域搜索(ALNS)与深度强化学习(DRL)，设计专门的破坏和修复操作符，动态调整破坏程度和接受阈值等关键参数。", "result": "计算结果表明，DRL引导的ALNS在解决方案质量上优于传统的最便宜位置、固定位置、二进制整数规划和静态启发式方法。", "conclusion": "该方法展示了学习驱动控制在组合优化中的优势，为仓库系统提供了高效的Pod重新定位解决方案。"}}
{"id": "2506.02718", "title": "Heterogeneous Group-Based Reinforcement Learning for LLM-based Multi-Agent Systems", "authors": ["Guanzhong Chen", "Shaoxiong Yang", "Chao Li", "Wei Liu", "Jian Luan", "Zenglin Xu"], "abstract": "Large Language Models (LLMs) have achieved remarkable success across diverse natural language processing tasks, yet their deployment in real-world applications is hindered by fixed knowledge cutoffs and difficulties in generating controllable, accurate outputs in a single inference. Multi-agent systems (MAS) built from specialized LLM agents offer a promising solution, enabling dynamic collaboration and iterative reasoning. However, optimizing these systems remains a challenge, as conventional methods such as prompt engineering and supervised fine-tuning entail high engineering overhead and limited adaptability. Reinforcement learning (RL), particularly multi-agent reinforcement learning (MARL), provides a scalable framework by refining agent policies based on system-level feedback. Nevertheless, existing MARL algorithms, such as Multi-Agent Proximal Policy Optimization (MAPPO), rely on Critic networks, which can cause training instability and increase computational burden. To address these limitations and target the prototypical Multi-Agent Search System (MASS), we propose Multi-Agent Heterogeneous Group Policy Optimization (MHGPO), a novel Critic-free algorithm that guides policy updates by estimating relative reward advantages across heterogeneous groups of rollouts. MHGPO eliminates the need for Critic networks, enhancing stability and reducing computational overhead. Additionally, we introduce three group rollout sampling strategies that trade off between efficiency and effectiveness. Experiments on a multi-agent LLM-based search system demonstrate that MHGPO consistently outperforms MAPPO in both task performance and computational efficiency, without requiring warm-up, underscoring its potential for stable and scalable optimization of complex LLM-based MAS.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.02718.pdf", "abstract_url": "https://arxiv.org/abs/2506.02718", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为MHGPO的新型无Critic算法，用于优化基于大型语言模型（LLM）的多智能体系统（MAS），通过估计异构组间的相对奖励优势来指导策略更新，提高了稳定性和计算效率。", "motivation": "大型语言模型（LLMs）在自然语言处理任务中取得了显著成功，但在实际应用中部署时，由于固定的知识截止点和在单次推理中生成可控、准确输出的困难而受到限制。多智能体系统（MAS）通过专门的LLM智能体提供动态协作和迭代推理的解决方案，但优化这些系统仍是一个挑战。", "method": "提出Multi-Agent Heterogeneous Group Policy Optimization (MHGPO)，一种新型的无Critic算法，通过估计异构组间的相对奖励优势来指导策略更新，消除了对Critic网络的需求，并引入了三种组滚动采样策略以在效率和效果之间进行权衡。", "result": "在多智能体LLM-based搜索系统上的实验表明，MHGPO在任务性能和计算效率上均优于MAPPO，且无需预热，显示了其在复杂LLM-based MAS稳定和可扩展优化中的潜力。", "conclusion": "MHGPO作为一种新型的无Critic算法，为基于LLM的多智能体系统提供了一种稳定且计算效率高的优化方法，具有重要的实际应用价值。"}}
{"id": "2506.02863", "title": "CapSpeech: Enabling Downstream Applications in Style-Captioned Text-to-Speech", "authors": ["Helin Wang", "Jiarui Hai", "Dading Chong", "Karan Thakkar", "Tiantian Feng", "Dongchao Yang", "Junhyeok Lee", "Laureano Moro Velazquez", "Jesus Villalba", "Zengyi Qin", "Shrikanth Narayanan", "Mounya Elhiali", "Najim Dehak"], "abstract": "Recent advancements in generative artificial intelligence have significantly transformed the field of style-captioned text-to-speech synthesis (CapTTS). However, adapting CapTTS to real-world applications remains challenging due to the lack of standardized, comprehensive datasets and limited research on downstream tasks built upon CapTTS. To address these gaps, we introduce CapSpeech, a new benchmark designed for a series of CapTTS-related tasks, including style-captioned text-to-speech synthesis with sound events (CapTTS-SE), accent-captioned TTS (AccCapTTS), emotion-captioned TTS (EmoCapTTS), and text-to-speech synthesis for chat agent (AgentTTS). CapSpeech comprises over 10 million machine-annotated audio-caption pairs and nearly 0.36 million human-annotated audio-caption pairs. In addition, we introduce two new datasets collected and recorded by a professional voice actor and experienced audio engineers, specifically for the AgentTTS and CapTTS-SE tasks. Alongside the datasets, we conduct comprehensive experiments using both autoregressive and non-autoregressive models on CapSpeech. Our results demonstrate high-fidelity and highly intelligible speech synthesis across a diverse range of speaking styles. To the best of our knowledge, CapSpeech is the largest available dataset offering comprehensive annotations for CapTTS-related tasks. The experiments and findings further provide valuable insights into the challenges of developing CapTTS systems.", "subjects": "Audio and Speech Processing (eess.AS); Artificial Intelligence (cs.AI); Sound (cs.SD)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.02863.pdf", "abstract_url": "https://arxiv.org/abs/2506.02863", "categories": ["Audio and Speech Processing (eess.AS)", "Artificial Intelligence (cs.AI)", "Sound (cs.SD)"], "matching_keywords": ["agent"], "AI": {"tldr": "CapSpeech是一个新的基准，旨在解决风格字幕文本到语音合成（CapTTS）领域的数据集标准化和下游任务研究不足的问题。它包含超过1000万机器标注和近36万人工标注的音频-字幕对，支持多种CapTTS相关任务，并通过实验展示了高保真和高度可理解的语音合成结果。", "motivation": "解决CapTTS领域缺乏标准化、全面数据集和下游任务研究不足的问题，以促进CapTTS在现实世界应用中的适应。", "method": "引入CapSpeech基准，包括大量机器和人工标注的音频-字幕对，以及两个新数据集，用于支持多种CapTTS相关任务。使用自回归和非自回归模型进行综合实验。", "result": "实验结果表明，CapSpeech能够支持高保真和高度可理解的语音合成，覆盖广泛的说话风格。", "conclusion": "CapSpeech是目前最大的CapTTS相关任务数据集，其实验和发现为开发CapTTS系统提供了宝贵的见解。"}}
{"id": "2506.02859", "title": "ATAG: AI-Agent Application Threat Assessment with Attack Graphs", "authors": ["Parth Atulbhai Gandhi", "Akansha Shukla", "David Tayouri", "Beni Ifland", "Yuval Elovici", "Rami Puzis", "Asaf Shabtai"], "abstract": "Evaluating the security of multi-agent systems (MASs) powered by large language models (LLMs) is challenging, primarily because of the systems' complex internal dynamics and the evolving nature of LLM vulnerabilities. Traditional attack graph (AG) methods often lack the specific capabilities to model attacks on LLMs. This paper introduces AI-agent application Threat assessment with Attack Graphs (ATAG), a novel framework designed to systematically analyze the security risks associated with AI-agent applications. ATAG extends the MulVAL logic-based AG generation tool with custom facts and interaction rules to accurately represent AI-agent topologies, vulnerabilities, and attack scenarios. As part of this research, we also created the LLM vulnerability database (LVD) to initiate the process of standardizing LLM vulnerabilities documentation. To demonstrate ATAG's efficacy, we applied it to two multi-agent applications. Our case studies demonstrated the framework's ability to model and generate AGs for sophisticated, multi-step attack scenarios exploiting vulnerabilities such as prompt injection, excessive agency, sensitive information disclosure, and insecure output handling across interconnected agents. ATAG is an important step toward a robust methodology and toolset to help understand, visualize, and prioritize complex attack paths in multi-agent AI systems (MAASs). It facilitates proactive identification and mitigation of AI-agent threats in multi-agent applications.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.02859.pdf", "abstract_url": "https://arxiv.org/abs/2506.02859", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了ATAG框架，一种用于系统分析AI-agent应用安全风险的新方法，通过扩展MulVAL工具和创建LLM漏洞数据库（LVD）来评估多代理系统的安全性。", "motivation": "评估由大型语言模型（LLMs）驱动的多代理系统（MASs）的安全性具有挑战性，主要因为系统复杂的内部动态和LLM漏洞的不断演变。传统的攻击图（AG）方法往往缺乏专门针对LLMs的攻击建模能力。", "method": "ATAG框架通过扩展MulVAL逻辑基础的AG生成工具，加入自定义事实和交互规则，以准确表示AI-agent的拓扑结构、漏洞和攻击场景。同时，创建了LLM漏洞数据库（LVD）以标准化LLM漏洞文档。", "result": "通过应用于两个多代理应用的案例研究，证明了ATAG能够建模并生成针对复杂、多步骤攻击场景的AG，这些场景利用了如提示注入、过度代理、敏感信息泄露和不安全输出处理等漏洞。", "conclusion": "ATAG是朝着理解和可视化多代理AI系统中复杂攻击路径的重要一步，有助于在多代理应用中主动识别和缓解AI-agent威胁。"}}
{"id": "2506.02931", "title": "ThinkTank: A Framework for Generalizing Domain-Specific AI Agent Systems into Universal Collaborative Intelligence Platforms", "authors": ["Praneet Sai Madhu Surabhi", "Dheeraj Reddy Mudireddy", "Jian Tao"], "abstract": "This paper presents ThinkTank, a comprehensive and scalable framework designed to transform specialized AI agent systems into versatile collaborative intelligence platforms capable of supporting complex problem-solving across diverse domains. ThinkTank systematically generalizes agent roles, meeting structures, and knowledge integration mechanisms by adapting proven scientific collaboration methodologies. Through role abstraction, generalization of meeting types for iterative collaboration, and the integration of Retrieval-Augmented Generation with advanced knowledge storage, the framework facilitates expertise creation and robust knowledge sharing. ThinkTank enables organizations to leverage collaborative AI for knowledge-intensive tasks while ensuring data privacy and security through local deployment, utilizing frameworks like Ollama with models such as Llama3.1. The ThinkTank framework is designed to deliver significant advantages in cost-effectiveness, data security, scalability, and competitive positioning compared to cloud-based alternatives, establishing it as a universal platform for AI-driven collaborative problem-solving. The ThinkTank code is available at", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.02931.pdf", "abstract_url": "https://arxiv.org/abs/2506.02931", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了ThinkTank框架，旨在将专业化的AI代理系统转化为通用的协作智能平台，支持跨领域的复杂问题解决。", "motivation": "解决如何将特定领域的AI代理系统扩展为能够支持多样化领域复杂问题解决的通用协作平台的问题。", "method": "通过角色抽象、会议类型的泛化以及结合检索增强生成和高级知识存储的知识整合机制，采用科学协作方法论的适应。", "result": "ThinkTank框架在成本效益、数据安全、可扩展性和竞争定位方面提供了显著优势，成为一个AI驱动的协作问题解决的通用平台。", "conclusion": "ThinkTank框架通过本地部署等方式，不仅促进了知识的创造和共享，还确保了数据隐私和安全，为组织提供了一个强大的协作AI解决方案。"}}
{"id": "2506.03046", "title": "EDEN: Entorhinal Driven Egocentric Navigation Toward Robotic Deployment", "authors": ["Mikolaj Walczak", "Romina Aalishah", "Wyatt Mackey", "Brittany Story", "David L. Boothe Jr.", "Nicholas Waytowich", "Xiaomin Lin", "Tinoosh Mohsenin"], "abstract": "Deep reinforcement learning agents are often fragile while humans remain adaptive and flexible to varying scenarios. To bridge this gap, we present EDEN, a biologically inspired navigation framework that integrates learned entorhinal-like grid cell representations and reinforcement learning to enable autonomous navigation. Inspired by the mammalian entorhinal-hippocampal system, EDEN allows agents to perform path integration and vector-based navigation using visual and motion sensor data. At the core of EDEN is a grid cell encoder that transforms egocentric motion into periodic spatial codes, producing low-dimensional, interpretable embeddings of position. To generate these activations from raw sensory input, we combine fiducial marker detections in the lightweight MiniWorld simulator and DINO-based visual features in the high-fidelity Gazebo simulator. These spatial representations serve as input to a policy trained with Proximal Policy Optimization (PPO), enabling dynamic, goal-directed navigation. We evaluate EDEN in both MiniWorld, for rapid prototyping, and Gazebo, which offers realistic physics and perception noise. Compared to baseline agents using raw state inputs (e.g., position, velocity) or standard convolutional image encoders, EDEN achieves a 99% success rate, within the simple scenarios, and >94% within complex floorplans with occluded paths with more efficient and reliable step-wise navigation. In addition, as a replacement of ground truth activations, we present a trainable Grid Cell encoder enabling the development of periodic grid-like patterns from vision and motion sensor data, emulating the development of such patterns within biological mammals. This work represents a step toward biologically grounded spatial intelligence in robotics, bridging neural navigation principles with reinforcement learning for scalable deployment.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.03046.pdf", "abstract_url": "https://arxiv.org/abs/2506.03046", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "EDEN是一个受生物启发的导航框架，结合了网格细胞表示和强化学习，以实现自主导航。在MiniWorld和Gazebo模拟器中评估，EDEN在简单和复杂场景中均表现出高成功率和高效导航。", "motivation": "解决深度强化学习代理在多变场景中的脆弱性问题，通过模仿哺乳动物的内嗅-海马系统，提高导航的适应性和灵活性。", "method": "结合学习的网格细胞表示和近端策略优化（PPO），使用视觉和运动传感器数据进行路径整合和基于矢量的导航。", "result": "在简单场景中达到99%的成功率，在复杂场景中超过94%，且导航步骤更高效可靠。", "conclusion": "EDEN代表了向生物基础空间智能迈出的一步，将神经导航原则与强化学习结合，为机器人技术的可扩展部署提供了可能。"}}
{"id": "2506.03102", "title": "Designing Algorithmic Delegates: The Role of Indistinguishability in Human-AI Handoff", "authors": ["Sophie Greenwood", "Karen Levy", "Solon Barocas", "Hoda Heidari", "Jon Kleinberg"], "abstract": "As AI technologies improve, people are increasingly willing to delegate tasks to AI agents. In many cases, the human decision-maker chooses whether to delegate to an AI agent based on properties of the specific instance of the decision-making problem they are facing. Since humans typically lack full awareness of all the factors relevant to this choice for a given decision-making instance, they perform a kind of categorization by treating indistinguishable instances -- those that have the same observable features -- as the same. In this paper, we define the problem of designing the optimal algorithmic delegate in the presence of categories. This is an important dimension in the design of algorithms to work with humans, since we show that the optimal delegate can be an arbitrarily better teammate than the optimal standalone algorithmic agent. The solution to this optimal delegation problem is not obvious: we discover that this problem is fundamentally combinatorial, and illustrate the complex relationship between the optimal design and the properties of the decision-making task even in simple settings. Indeed, we show that finding the optimal delegate is computationally hard in general. However, we are able to find efficient algorithms for producing the optimal delegate in several broad cases of the problem, including when the optimal action may be decomposed into functions of features observed by the human and the algorithm. Finally, we run computational experiments to simulate a designer updating an algorithmic delegate over time to be optimized for when it is actually adopted by users, and show that while this process does not recover the optimal delegate in general, the resulting delegate often performs quite well.", "subjects": "Computer Science and Game Theory (cs.GT); Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "comments": "Accepted at the Twenty-Sixth ACM Conference on Economics and Computation (EC'25)", "pdf_url": "https://arxiv.org/pdf/2506.03102.pdf", "abstract_url": "https://arxiv.org/abs/2506.03102", "categories": ["Computer Science and Game Theory (cs.GT)", "Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了在设计算法代理时，不可区分性在人机交接中的作用。随着AI技术的进步，人们更愿意将任务委托给AI代理。研究定义了在存在类别的情况下设计最优算法代理的问题，并展示了最优代理可以比独立算法代理表现得更好。尽管找到最优代理在计算上是困难的，但在某些广泛情况下可以找到高效算法。", "motivation": "随着AI技术的进步，人们越来越愿意将任务委托给AI代理。然而，人类决策者通常缺乏对所有相关因素的全面了解，因此需要通过不可区分的实例进行 categorization。本文旨在解决在设计算法代理时，如何考虑这种 categorization 以优化人机协作的问题。", "method": "本文定义了在存在类别的情况下设计最优算法代理的问题，并展示了这一问题本质上是组合性的。研究通过计算实验模拟设计师随时间更新算法代理的过程，探索了在不同情况下找到高效算法的可能性。", "result": "研究发现，最优算法代理可以比独立算法代理表现得更好，尽管找到最优代理在计算上是困难的。然而，在某些广泛情况下，如当最优动作可以分解为由人类和算法观察到的特征的函数时，可以找到高效算法。计算实验表明，虽然这一过程通常无法恢复最优代理，但结果代理往往表现良好。", "conclusion": "本文强调了在设计算法代理时考虑不可区分性的重要性，并展示了在某些情况下可以有效地找到最优代理。这对于优化人机协作具有重要意义，尽管在一般情况下找到最优代理具有挑战性。"}}
