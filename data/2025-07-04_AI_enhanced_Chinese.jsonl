{"id": "2507.02592", "title": "WebSailor: Navigating Super-human Reasoning for Web Agent", "authors": ["Kuan Li", "Zhongwang Zhang", "Huifeng Yin", "Liwen Zhang", "Litu Ou", "Jialong Wu", "Wenbiao Yin", "Baixuan Li", "Zhengwei Tao", "Xinyu Wang", "Weizhou Shen", "Junkai Zhang", "Dingchu Zhang", "Xixi Wu", "Yong Jiang", "Ming Yan", "Pengjun Xie", "Fei Huang", "Jingren Zhou"], "abstract": "Transcending human cognitive limitations represents a critical frontier in LLM training. Proprietary agentic systems like DeepResearch have demonstrated superhuman capabilities on extremely complex information-seeking benchmarks such as BrowseComp, a feat previously unattainable. We posit that their success hinges on a sophisticated reasoning pattern absent in open-source models: the ability to systematically reduce extreme uncertainty when navigating vast information landscapes. Based on this insight, we introduce WebSailor, a complete post-training methodology designed to instill this crucial capability. Our approach involves generating novel, high-uncertainty tasks through structured sampling and information obfuscation, RFT cold start, and an efficient agentic RL training algorithm, Duplicating Sampling Policy Optimization (DUPO). With this integrated pipeline, WebSailor significantly outperforms all opensource agents in complex information-seeking tasks, matching proprietary agents' performance and closing the capability gap.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.02592.pdf", "abstract_url": "https://arxiv.org/abs/2507.02592", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "WebSailor是一种后训练方法，旨在通过结构化采样和信息模糊化、RFT冷启动及高效的代理RL训练算法DUPO，赋予开源模型在复杂信息搜索任务中超人的推理能力，以缩小与专有代理的性能差距。", "motivation": "解决开源模型在极端不确定性下导航广阔信息景观时缺乏系统推理能力的问题，以缩小与专有代理系统如DeepResearch在复杂信息寻求任务中的性能差距。", "method": "通过结构化采样和信息模糊化生成新颖的高不确定性任务，采用RFT冷启动和高效的代理RL训练算法DUPO进行训练。", "result": "WebSailor在复杂信息寻求任务中显著优于所有开源代理，性能与专有代理相匹配，缩小了能力差距。", "conclusion": "WebSailor的后训练方法论成功地赋予了开源模型在复杂信息搜索任务中的超人推理能力，为缩小与专有代理系统的性能差距提供了有效途径。"}}
{"id": "2507.02259", "title": "MemAgent: Reshaping Long-Context LLM with Multi-Conv RL-based Memory Agent", "authors": ["Hongli Yu", "Tinghong Chen", "Jiangtao Feng", "Jiangjie Chen", "Weinan Dai", "Qiying Yu", "Ya-Qin Zhang", "Wei-Ying Ma", "Jingjing Liu", "Mingxuan Wang", "Hao Zhou"], "abstract": "Despite improvements by length extrapolation, efficient attention and memory modules, handling infinitely long documents with linear complexity without performance degradation during extrapolation remains the ultimate challenge in long-text processing. We directly optimize for long-text tasks in an end-to-end fashion and introduce a novel agent workflow, MemAgent, which reads text in segments and updates the memory using an overwrite strategy. We extend the DAPO algorithm to facilitate training via independent-context multi-conversation generation. MemAgent has demonstrated superb long-context capabilities, being able to extrapolate from an 8K context trained on 32K text to a 3.5M QA task with performance loss < 5% and achieves 95%+ in 512K RULER test.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2507.02259.pdf", "abstract_url": "https://arxiv.org/abs/2507.02259", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "MemAgent是一种新型的代理工作流程，通过分段阅读文本并使用覆盖策略更新内存，优化了长文本处理任务。它展示了卓越的长上下文能力，能够在8K上下文训练的基础上，扩展到32K文本，并在3.5M QA任务中性能损失小于5%，在512K RULER测试中达到95%以上的准确率。", "motivation": "尽管通过长度外推、高效注意力和内存模块有所改进，但在长文本处理中，如何在无限长文档中以线性复杂度处理而不在外推过程中出现性能下降，仍然是一个终极挑战。", "method": "引入了一种新型的代理工作流程MemAgent，它通过分段阅读文本并使用覆盖策略更新内存。扩展了DAPO算法，以通过独立上下文的多对话生成促进训练。", "result": "MemAgent展示了卓越的长上下文能力，能够在8K上下文训练的基础上，扩展到32K文本，并在3.5M QA任务中性能损失小于5%，在512K RULER测试中达到95%以上的准确率。", "conclusion": "MemAgent通过其创新的内存更新策略和多对话生成训练方法，有效地解决了长文本处理中的挑战，为长上下文任务提供了一种高效的解决方案。"}}
{"id": "2507.02004", "title": "STELLA: Self-Evolving LLM Agent for Biomedical Research", "authors": ["Ruofan Jin", "Zaixi Zhang", "Mengdi Wang", "Le Cong"], "abstract": "The rapid growth of biomedical data, tools, and literature has created a fragmented research landscape that outpaces human expertise. While AI agents offer a solution, they typically rely on static, manually curated toolsets, limiting their ability to adapt and scale. Here, we introduce STELLA, a self-evolving AI agent designed to overcome these limitations. STELLA employs a multi-agent architecture that autonomously improves its own capabilities through two core mechanisms: an evolving Template Library for reasoning strategies and a dynamic Tool Ocean that expands as a Tool Creation Agent automatically discovers and integrates new bioinformatics tools. This allows STELLA to learn from experience. We demonstrate that STELLA achieves state-of-the-art accuracy on a suite of biomedical benchmarks, scoring approximately 26\\% on Humanity's Last Exam: Biomedicine, 54\\% on LAB-Bench: DBQA, and 63\\% on LAB-Bench: LitQA, outperforming leading models by up to 6 percentage points. More importantly, we show that its performance systematically improves with experience; for instance, its accuracy on the Humanity's Last Exam benchmark almost doubles with increased trials. STELLA represents a significant advance towards AI Agent systems that can learn and grow, dynamically scaling their expertise to accelerate the pace of biomedical discovery.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Biomolecules (q-bio.BM)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.02004.pdf", "abstract_url": "https://arxiv.org/abs/2507.02004", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Biomolecules (q-bio.BM)"], "matching_keywords": ["agent"], "AI": {"tldr": "STELLA是一种自进化的AI代理，旨在解决生物医学研究中数据、工具和文献快速增长导致的碎片化问题。通过多代理架构和核心机制，STELLA能够自主提升能力，并在多个生物医学基准测试中取得领先成绩。", "motivation": "生物医学数据、工具和文献的快速增长导致了研究领域的碎片化，超出了人类专家的处理能力。现有的AI代理依赖于静态、手动整理的工具集，限制了其适应和扩展的能力。", "method": "STELLA采用多代理架构，通过两个核心机制自主提升能力：进化的模板库用于推理策略和动态的工具海洋，工具创建代理自动发现并整合新的生物信息学工具。", "result": "STELLA在一系列生物医学基准测试中取得了最先进的准确率，如在Humanity's Last Exam: Biomedicine上得分约26%，在LAB-Bench: DBQA上得分54%，在LAB-Bench: LitQA上得分63%，领先于其他领先模型多达6个百分点。更重要的是，其性能随着经验的增加而系统性地提高。", "conclusion": "STELLA代表了向能够学习和成长的AI代理系统的重大进步，能够动态扩展其专业知识以加速生物医学发现的步伐。"}}
{"id": "2507.02618", "title": "Strategic Intelligence in Large Language Models: Evidence from evolutionary Game Theory", "authors": ["Kenneth Payne", "Baptiste Alloui-Cros"], "abstract": "Are Large Language Models (LLMs) a new form of strategic intelligence, able to reason about goals in competitive settings? We present compelling supporting evidence. The Iterated Prisoner's Dilemma (IPD) has long served as a model for studying decision-making. We conduct the first ever series of evolutionary IPD tournaments, pitting canonical strategies (e.g., Tit-for-Tat, Grim Trigger) against agents from the leading frontier AI companies OpenAI, Google, and Anthropic. By varying the termination probability in each tournament (the \"shadow of the future\"), we introduce complexity and chance, confounding memorisation.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Science and Game Theory (cs.GT)", "comments": "29 pages, 27 tables, 4 figures", "pdf_url": "https://arxiv.org/pdf/2507.02618.pdf", "abstract_url": "https://arxiv.org/abs/2507.02618", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Computer Science and Game Theory (cs.GT)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了大型语言模型（LLMs）是否能够作为一种新的战略智能形式，在竞争环境中进行目标推理。通过进化迭代囚徒困境（IPD）锦标赛，首次将经典策略与领先AI公司的代理进行对比，研究了决策制定。", "motivation": "研究大型语言模型是否具备在竞争环境中进行战略推理的能力，以及它们如何适应复杂和不确定的环境。", "method": "通过进化迭代囚徒困境（IPD）锦标赛，将经典策略（如以牙还牙、严厉触发）与OpenAI、Google和Anthropic的前沿AI代理进行对比，并通过改变锦标赛中的终止概率（“未来的阴影”）引入复杂性和偶然性。", "result": "提供了支持大型语言模型作为新战略智能形式的初步证据，展示了它们在复杂和不确定环境中的适应能力。", "conclusion": "大型语言模型展现出在战略决策制定中的潜力，能够适应复杂和不确定的环境，这为AI在战略推理领域的应用开辟了新途径。"}}
{"id": "2507.02652", "title": "Decoupled Planning and Execution: A Hierarchical Reasoning Framework for Deep Search", "authors": ["Jiajie Jin", "Xiaoxi Li", "Guanting Dong", "Yuyao Zhang", "Yutao Zhu", "Yang Zhao", "Hongjin Qian", "Zhicheng Dou"], "abstract": "Complex information needs in real-world search scenarios demand deep reasoning and knowledge synthesis across diverse sources, which traditional retrieval-augmented generation (RAG) pipelines struggle to address effectively. Current reasoning-based approaches suffer from a fundamental limitation: they use a single model to handle both high-level planning and detailed execution, leading to inefficient reasoning and limited scalability. In this paper, we introduce HiRA, a hierarchical framework that separates strategic planning from specialized execution. Our approach decomposes complex search tasks into focused subtasks, assigns each subtask to domain-specific agents equipped with external tools and reasoning capabilities, and coordinates the results through a structured integration mechanism. This separation prevents execution details from disrupting high-level reasoning while enabling the system to leverage specialized expertise for different types of information processing. Experiments on four complex, cross-modal deep search benchmarks demonstrate that HiRA significantly outperforms state-of-the-art RAG and agent-based systems. Our results show improvements in both answer quality and system efficiency, highlighting the effectiveness of decoupled planning and execution for multi-step information seeking tasks. Our code is available at", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Information Retrieval (cs.IR)", "comments": "9 pages", "pdf_url": "https://arxiv.org/pdf/2507.02652.pdf", "abstract_url": "https://arxiv.org/abs/2507.02652", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Information Retrieval (cs.IR)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文介绍了HiRA，一个分层框架，通过将战略规划与专门执行分离，解决了复杂信息需求下的深度搜索问题。", "motivation": "解决传统检索增强生成（RAG）管道在处理复杂信息需求时的不足，以及当前基于推理的方法在高层规划和详细执行中使用单一模型的局限性。", "method": "采用分层框架HiRA，将复杂搜索任务分解为专注的子任务，分配给配备外部工具和推理能力的领域特定代理，并通过结构化集成机制协调结果。", "result": "在四个复杂的跨模态深度搜索基准测试中，HiRA显著优于最先进的RAG和基于代理的系统，在答案质量和系统效率方面均有提升。", "conclusion": "解耦规划和执行对于多步骤信息寻求任务的有效性得到了验证，HiRA框架在提高搜索任务的处理能力和效率方面显示出巨大潜力。"}}
{"id": "2507.02252", "title": "SurgVisAgent: Multimodal Agentic Model for Versatile Surgical Visual Enhancement", "authors": ["Zeyu Lei", "Hongyuan Yu", "Jinlin Wu", "Zhen Chen"], "abstract": "Precise surgical interventions are vital to patient safety, and advanced enhancement algorithms have been developed to assist surgeons in decision-making. Despite significant progress, these algorithms are typically designed for single tasks in specific scenarios, limiting their effectiveness in complex real-world situations. To address this limitation, we propose SurgVisAgent, an end-to-end intelligent surgical vision agent built on multimodal large language models (MLLMs). SurgVisAgent dynamically identifies distortion categories and severity levels in endoscopic images, enabling it to perform a variety of enhancement tasks such as low-light enhancement, overexposure correction, motion blur elimination, and smoke removal. Specifically, to achieve superior surgical scenario understanding, we design a prior model that provides domain-specific knowledge. Additionally, through in-context few-shot learning and chain-of-thought (CoT) reasoning, SurgVisAgent delivers customized image enhancements tailored to a wide range of distortion types and severity levels, thereby addressing the diverse requirements of surgeons. Furthermore, we construct a comprehensive benchmark simulating real-world surgical distortions, on which extensive experiments demonstrate that SurgVisAgent surpasses traditional single-task models, highlighting its potential as a unified solution for surgical assistance.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.02252.pdf", "abstract_url": "https://arxiv.org/abs/2507.02252", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "SurgVisAgent是一种基于多模态大语言模型（MLLMs）的端到端智能手术视觉代理，旨在通过动态识别内窥镜图像中的失真类别和严重程度，执行多种增强任务，如低光增强、过曝校正、运动模糊消除和烟雾去除，以提升手术决策的精确性。", "motivation": "现有的手术增强算法通常针对特定场景的单一任务设计，难以应对复杂现实世界中的多样化需求，限制了其在提升手术精确性和安全性方面的效果。", "method": "研究团队提出了SurgVisAgent，结合了领域特定知识的先验模型、上下文少样本学习和思维链（CoT）推理，以实现对手术场景的深入理解和定制化的图像增强。", "result": "在模拟真实世界手术失真的综合基准测试中，SurgVisAgent表现优于传统的单任务模型，展示了其作为手术辅助统一解决方案的潜力。", "conclusion": "SurgVisAgent通过其多功能性和适应性，为解决手术视觉增强中的多样化需求提供了有效的端到端解决方案，有望在提升手术安全性和效率方面发挥重要作用。"}}
{"id": "2507.02076", "title": "Reasoning on a Budget: A Survey of Adaptive and Controllable Test-Time Compute in LLMs", "authors": ["Mohammad Ali Alomrani", "Yingxue Zhang", "Derek Li", "Qianyi Sun", "Soumyasundar Pal", "Zhanguang Zhang", "Yaochen Hu", "Rohan Deepak Ajwani", "Antonios Valkanas", "Raika Karimi", "Peng Cheng", "Yunzhou Wang", "Pengyi Liao", "Hanrui Huang", "Bin Wang", "Jianye Hao", "Mark Coates"], "abstract": "Large language models (LLMs) have rapidly progressed into general-purpose agents capable of solving a broad spectrum of tasks. However, current models remain inefficient at reasoning: they apply fixed inference-time compute regardless of task complexity, often overthinking simple problems while underthinking hard ones. This survey presents a comprehensive review of efficient test-time compute (TTC) strategies, which aim to improve the computational efficiency of LLM reasoning. We introduce a two-tiered taxonomy that distinguishes between L1-controllability, methods that operate under fixed compute budgets, and L2-adaptiveness, methods that dynamically scale inference based on input difficulty or model confidence. We benchmark leading proprietary LLMs across diverse datasets, highlighting critical trade-offs between reasoning performance and token usage. Compared to prior surveys on efficient reasoning, our review emphasizes the practical control, adaptability, and scalability of TTC methods. Finally, we discuss emerging trends such as hybrid thinking models and identify key challenges for future work towards making LLMs more computationally efficient, robust, and responsive to user constraints.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.02076.pdf", "abstract_url": "https://arxiv.org/abs/2507.02076", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文综述了大型语言模型（LLMs）在推理过程中的计算效率问题，提出了一种两层次的分类法，旨在通过自适应和可控的测试时计算策略提高LLMs的推理效率。", "motivation": "当前的大型语言模型在推理时采用固定的计算资源，无法根据任务复杂度动态调整，导致简单问题过度计算而复杂问题计算不足。", "method": "介绍了两层次的分类法：L1-可控性（在固定计算预算下操作的方法）和L2-自适应性（根据输入难度或模型置信度动态调整推理规模的方法）。", "result": "通过对领先的专有LLMs在不同数据集上的基准测试，揭示了推理性能和令牌使用之间的关键权衡。", "conclusion": "综述强调了测试时计算方法的实际控制性、适应性和可扩展性，并讨论了混合思维模型等新兴趋势，为未来工作提出了使LLMs更高效、稳健和响应用户约束的关键挑战。"}}
{"id": "2507.02103", "title": "What Neuroscience Can Teach AI About Learning in Continuously Changing Environments", "authors": ["Daniel Durstewitz", "Bruno Averbeck", "Georgia Koppe"], "abstract": "Modern AI models, such as large language models, are usually trained once on a huge corpus of data, potentially fine-tuned for a specific task, and then deployed with fixed parameters. Their training is costly, slow, and gradual, requiring billions of repetitions. In stark contrast, animals continuously adapt to the ever-changing contingencies in their environments. This is particularly important for social species, where behavioral policies and reward outcomes may frequently change in interaction with peers. The underlying computational processes are often marked by rapid shifts in an animal's behaviour and rather sudden transitions in neuronal population activity. Such computational capacities are of growing importance for AI systems operating in the real world, like those guiding robots or autonomous vehicles, or for agentic AI interacting with humans online. Can AI learn from neuroscience? This Perspective explores this question, integrating the literature on continual and in-context learning in AI with the neuroscience of learning on behavioral tasks with shifting rules, reward probabilities, or outcomes. We will outline an agenda for how specifically insights from neuroscience may inform current developments in AI in this area, and - vice versa - what neuroscience may learn from AI, contributing to the evolving field of NeuroAI.", "subjects": "Artificial Intelligence (cs.AI); Neurons and Cognition (q-bio.NC)", "comments": "Submitted as a Perspective article (10 pages, 5 figures)", "pdf_url": "https://arxiv.org/pdf/2507.02103.pdf", "abstract_url": "https://arxiv.org/abs/2507.02103", "categories": ["Artificial Intelligence (cs.AI)", "Neurons and Cognition (q-bio.NC)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文探讨了神经科学如何启发AI在持续变化环境中的学习，特别是从动物快速适应环境变化的能力中汲取灵感，以改进AI系统的持续学习和上下文学习能力。", "motivation": "解决现代AI模型在固定参数部署后无法像动物那样快速适应环境变化的问题，特别是在社交互动和实时决策场景中。", "method": "整合AI中的持续学习和上下文学习文献与神经科学中关于行为任务学习的研究，提出神经科学可以如何指导AI发展的议程。", "result": "提出了神经科学和AI相互学习的框架，强调了神经科学在改进AI适应性和学习效率方面的潜在贡献。", "conclusion": "神经科学和AI的交叉研究有望推动AI系统在真实世界中的应用，同时也能促进神经科学的发展，这是NeuroAI领域的一个重要方向。"}}
{"id": "2507.02083", "title": "Measuring Scientific Capabilities of Language Models with a Systems Biology Dry Lab", "authors": ["Haonan Duan", "Stephen Zhewen Lu", "Caitlin Fiona Harrigan", "Nishkrit Desai", "Jiarui Lu", "Michał Koziarski", "Leonardo Cotta", "Chris J. Maddison"], "abstract": "Designing experiments and result interpretations are core scientific competencies, particularly in biology, where researchers perturb complex systems to uncover the underlying systems. Recent efforts to evaluate the scientific capabilities of large language models (LLMs) fail to test these competencies because wet-lab experimentation is prohibitively expensive: in expertise, time and equipment. We introduce SciGym, a first-in-class benchmark that assesses LLMs' iterative experiment design and analysis abilities in open-ended scientific discovery tasks. SciGym overcomes the challenge of wet-lab costs by running a dry lab of biological systems. These models, encoded in Systems Biology Markup Language, are efficient for generating simulated data, making them ideal testbeds for experimentation on realistically complex systems. We evaluated six frontier LLMs on 137 small systems, and released a total of 350 systems. Our evaluation shows that while more capable models demonstrated superior performance, all models' performance declined significantly as system complexity increased, suggesting substantial room for improvement in the scientific capabilities of LLM agents.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.02083.pdf", "abstract_url": "https://arxiv.org/abs/2507.02083", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了SciGym，一个评估大型语言模型（LLMs）在开放式科学发现任务中迭代实验设计和分析能力的基准测试。通过使用系统生物学干实验室克服湿实验室的高成本问题，评估了六种前沿LLMs在137个小系统上的表现，并发布了总共350个系统。结果显示，虽然能力更强的模型表现更优，但随着系统复杂度的增加，所有模型的性能显著下降，表明LLM代理的科学能力仍有很大提升空间。", "motivation": "评估LLMs的科学能力，特别是在实验设计和结果解释方面的能力，由于湿实验室的高成本（专业知识、时间和设备）而难以进行。", "method": "引入SciGym基准测试，使用系统生物学干实验室（通过系统生物学标记语言编码的模型）生成模拟数据，评估LLMs在开放式科学发现任务中的表现。", "result": "评估了六种前沿LLMs在137个小系统上的表现，并发布了总共350个系统。结果显示，能力更强的模型表现更优，但随着系统复杂度的增加，所有模型的性能显著下降。", "conclusion": "尽管能力更强的LLMs在科学任务中表现更好，但随着任务复杂度的增加，所有模型的性能都有显著下降，这表明LLM代理在科学能力方面仍有很大的改进空间。"}}
{"id": "2507.02211", "title": "Dilution, Diffusion and Symbiosis in Spatial Prisoner's Dilemma with Reinforcement Learning", "authors": ["Gustavo C. Mangold", "Heitor C. M. Fernandes", "Mendeli H. Vainstein"], "abstract": "Recent studies in the spatial prisoner's dilemma games with reinforcement learning have shown that static agents can learn to cooperate through a diverse sort of mechanisms, including noise injection, different types of learning algorithms and neighbours' payoff", "subjects": "Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE); Computational Physics (physics.comp-ph)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.02211.pdf", "abstract_url": "https://arxiv.org/abs/2507.02211", "categories": ["Artificial Intelligence (cs.AI)", "Neural and Evolutionary Computing (cs.NE)", "Computational Physics (physics.comp-ph)"], "matching_keywords": ["agent"], "AI": {"tldr": "最近的研究表明，在带有强化学习的空间囚徒困境游戏中，静态代理可以通过多种机制学会合作，包括噪声注入、不同类型的学习算法和邻居的收益。", "motivation": "解决在空间囚徒困境游戏中，静态代理如何通过学习机制实现合作的问题。", "method": "使用强化学习，结合噪声注入、不同类型的学习算法和考虑邻居的收益。", "result": "静态代理能够通过这些机制学会合作。", "conclusion": "研究表明，通过特定的学习机制，静态代理在空间囚徒困境游戏中可以实现合作，这为理解合作行为的演化提供了新的视角。"}}
{"id": "2507.02197", "title": "Do Role-Playing Agents Practice What They Preach? Belief-Behavior Consistency in LLM-Based Simulations of Human Trust", "authors": ["Amogh Mannekote", "Adam Davies", "Guohao Li", "Kristy Elizabeth Boyer", "ChengXiang Zhai", "Bonnie J Dorr", "Francesco Pinto"], "abstract": "As LLMs are increasingly studied as role-playing agents to generate synthetic data for human behavioral research, ensuring that their outputs remain coherent with their assigned roles has become a critical concern. In this paper, we investigate how consistently LLM-based role-playing agents' stated beliefs about the behavior of the people they are asked to role-play (\"what they say\") correspond to their actual behavior during role-play (\"how they act\"). Specifically, we establish an evaluation framework to rigorously measure how well beliefs obtained by prompting the model can predict simulation outcomes in advance. Using an augmented version of the GenAgents persona bank and the Trust Game (a standard economic game used to quantify players' trust and reciprocity), we introduce a belief-behavior consistency metric to systematically investigate how it is affected by factors such as: (1) the types of beliefs we elicit from LLMs, like expected outcomes of simulations versus task-relevant attributes of individual characters LLMs are asked to simulate; (2) when and how we present LLMs with relevant information about Trust Game; and (3) how far into the future we ask the model to forecast its actions. We also explore how feasible it is to impose a researcher's own theoretical priors in the event that the originally elicited beliefs are misaligned with research objectives. Our results reveal systematic inconsistencies between LLMs' stated (or imposed) beliefs and the outcomes of their role-playing simulation, at both an individual- and population-level. Specifically, we find that, even when models appear to encode plausible beliefs, they may fail to apply them in a consistent way. These findings highlight the need to identify how and when LLMs' stated beliefs align with their simulated behavior, allowing researchers to use LLM-based agents appropriately in behavioral studies.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.02197.pdf", "abstract_url": "https://arxiv.org/abs/2507.02197", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究了基于LLM的角色扮演代理在模拟人类信任时的信念与行为一致性，提出了一个评估框架来衡量这种一致性，并探讨了影响一致性的因素。", "motivation": "随着LLM越来越多地被用作角色扮演代理来生成人类行为研究的合成数据，确保其输出与分配的角色保持一致已成为一个关键问题。", "method": "研究使用增强版的GenAgents角色库和信任游戏（一种用于量化玩家信任和互惠的标准经济游戏），引入了一个信念-行为一致性度量，系统地研究了影响一致性的因素。", "result": "结果显示，即使在模型编码了看似合理的信念时，它们也可能无法以一致的方式应用这些信念，揭示了LLM在个体和群体层面上的信念与模拟行为之间存在系统性不一致。", "conclusion": "这些发现强调了需要识别LLM的陈述信念何时与其模拟行为一致，以便研究人员在行为研究中适当使用基于LLM的代理。"}}
{"id": "2507.02353", "title": "OMS: On-the-fly, Multi-Objective, Self-Reflective Ad Keyword Generation via LLM Agent", "authors": ["Bowen Chen", "Zhao Wang", "Shingo Takamatsu"], "abstract": "Keyword decision in Sponsored Search Advertising is critical to the success of ad campaigns. While LLM-based methods offer automated keyword generation, they face three major limitations: reliance on large-scale query-keyword pair data, lack of online multi-objective performance monitoring and optimization, and weak quality control in keyword selection. These issues hinder the agentic use of LLMs in fully automating keyword decisions by monitoring and reasoning over key performance indicators such as impressions, clicks, conversions, and CTA effectiveness. To overcome these challenges, we propose OMS, a keyword generation framework that is On-the-fly (requires no training data, monitors online performance, and adapts accordingly), Multi-objective (employs agentic reasoning to optimize keywords based on multiple performance metrics), and Self-reflective (agentically evaluates keyword quality). Experiments on benchmarks and real-world ad campaigns show that OMS outperforms existing methods; ablation and human evaluations confirm the effectiveness of each component and the quality of generated keywords.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.02353.pdf", "abstract_url": "https://arxiv.org/abs/2507.02353", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "OMS是一个基于LLM代理的广告关键词生成框架，旨在解决现有方法在数据依赖、多目标性能监控和关键词质量控制方面的不足。", "motivation": "解决赞助搜索广告中关键词决策的自动化问题，特别是现有LLM方法在数据依赖、多目标性能监控和关键词质量控制方面的局限性。", "method": "提出了OMS框架，具有即时性（无需训练数据，监控在线性能并适应）、多目标（基于多个性能指标优化关键词）和自我反思（评估关键词质量）的特点。", "result": "在基准测试和真实广告活动中，OMS表现优于现有方法；消融和人类评估证实了各组成部分的有效性和生成关键词的质量。", "conclusion": "OMS框架通过即时性、多目标和自我反思的特性，有效地提高了广告关键词生成的自动化水平和质量，为赞助搜索广告的成功提供了有力支持。"}}
{"id": "2507.02554", "title": "AI Research Agents for Machine Learning: Search, Exploration, and Generalization in MLE-bench", "authors": ["Edan Toledo", "Karen Hambardzumyan", "Martin Josifoski", "Rishi Hazra", "Nicolas Baldwin", "Alexis Audran-Reiss", "Michael Kuchnik", "Despoina Magka", "Minqi Jiang", "Alisia Maria Lupidi", "Andrei Lupu", "Roberta Raileanu", "Kelvin Niu", "Tatiana Shavrina", "Jean-Christophe Gagnon-Audet", "Michael Shvartsman", "Shagun Sodhani", "Alexander H. Miller", "Abhishek Charnalia", "Derek Dunfield", "Carole-Jean Wu", "Pontus Stenetorp", "Nicola Cancedda", "Jakob Nicolaus Foerster", "Yoram Bachrach"], "abstract": "AI research agents are demonstrating great potential to accelerate scientific progress by automating the design, implementation, and training of machine learning models. We focus on methods for improving agents' performance on MLE-bench, a challenging benchmark where agents compete in Kaggle competitions to solve real-world machine learning problems. We formalize AI research agents as search policies that navigate a space of candidate solutions, iteratively modifying them using operators. By designing and systematically varying different operator sets and search policies (Greedy, MCTS, Evolutionary), we show that their interplay is critical for achieving high performance. Our best pairing of search strategy and operator set achieves a state-of-the-art result on MLE-bench lite, increasing the success rate of achieving a Kaggle medal from 39.6% to 47.7%. Our investigation underscores the importance of jointly considering the search strategy, operator design, and evaluation methodology in advancing automated machine learning.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2507.02554.pdf", "abstract_url": "https://arxiv.org/abs/2507.02554", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "AI研究代理在MLE-bench上的表现提升，通过优化搜索策略和操作集，实现了Kaggle竞赛中奖牌获得率的显著提高。", "motivation": "解决AI研究代理在自动化机器学习模型设计、实现和训练中面临的挑战，特别是在MLE-bench这一具有挑战性的基准测试中。", "method": "将AI研究代理形式化为搜索策略，通过设计不同的操作集和搜索策略（贪婪、MCTS、进化算法），并系统性地分析它们的相互作用。", "result": "最佳搜索策略和操作集的配对在MLE-bench lite上实现了最先进的结果，将Kaggle奖牌获得率从39.6%提高到47.7%。", "conclusion": "研究表明，在推进自动化机器学习的过程中，联合考虑搜索策略、操作设计和评估方法的重要性。"}}
{"id": "2507.02616", "title": "DynamiCare: A Dynamic Multi-Agent Framework for Interactive and Open-Ended Medical Decision-Making", "authors": ["Tianqi Shang", "Weiqing He", "Charles Zheng", "Lingyao Li", "Li Shen", "Bingxin Zhao"], "abstract": "The rise of Large Language Models (LLMs) has enabled the development of specialized AI agents with domain-specific reasoning and interaction capabilities, particularly in healthcare. While recent frameworks simulate medical decision-making, they largely focus on single-turn tasks where a doctor agent receives full case information upfront -- diverging from the real-world diagnostic process, which is inherently uncertain, interactive, and iterative. In this paper, we introduce MIMIC-Patient, a structured dataset built from the MIMIC-III electronic health records (EHRs), designed to support dynamic, patient-level simulations. Building on this, we propose DynamiCare, a novel dynamic multi-agent framework that models clinical diagnosis as a multi-round, interactive loop, where a team of specialist agents iteratively queries the patient system, integrates new information, and dynamically adapts its composition and strategy. We demonstrate the feasibility and effectiveness of DynamiCare through extensive experiments, establishing the first benchmark for dynamic clinical decision-making with LLM-powered agents.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "16 pages", "pdf_url": "https://arxiv.org/pdf/2507.02616.pdf", "abstract_url": "https://arxiv.org/abs/2507.02616", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了DynamiCare，一个动态多智能体框架，用于模拟现实世界中不确定、互动和迭代的医疗决策过程。通过MIMIC-Patient数据集和DynamiCare框架，研究展示了基于大型语言模型（LLM）的动态临床决策的可行性和有效性。", "motivation": "解决现有医疗决策模拟框架主要关注单轮任务，与现实世界诊断过程的不确定、互动和迭代特性不符的问题。", "method": "提出DynamiCare框架，利用MIMIC-Patient数据集支持动态、患者级别的模拟，模拟临床诊断为一个多轮、互动的循环过程。", "result": "通过广泛实验证明了DynamiCare的可行性和有效性，为基于LLM的动态临床决策设立了首个基准。", "conclusion": "DynamiCare框架为模拟更接近现实世界的医疗决策过程提供了新方法，展示了LLM在医疗领域的应用潜力。"}}
{"id": "2507.02660", "title": "Hey AI, Generate Me a Hardware Code! Agentic AI-based Hardware Design & Verification", "authors": ["Deepak Narayan Gadde", "Keerthan Kopparam Radhakrishna", "Vaisakh Naduvodi Viswambharan", "Aman Kumar", "Djones Lettnin", "Wolfgang Kunz", "Sebastian Simon"], "abstract": "Modern Integrated Circuits (ICs) are becoming increasingly complex, and so is their development process. Hardware design verification entails a methodical and disciplined approach to the planning, development, execution, and sign-off of functionally correct hardware designs. This tedious process requires significant effort and time to ensure a bug-free tape-out. The field of Natural Language Processing has undergone a significant transformation with the advent of Large Language Models (LLMs). These powerful models, often referred to as Generative AI (GenAI), have revolutionized how machines understand and generate human language, enabling unprecedented advancements in a wide array of applications, including hardware design verification. This paper presents an agentic AI-based approach to hardware design verification, which empowers AI agents, in collaboration with Humain-in-the-Loop (HITL) intervention, to engage in a more dynamic, iterative, and self-reflective process, ultimately performing end-to-end hardware design and verification. This methodology is evaluated on five open-source designs, achieving over 95% coverage with reduced verification time while demonstrating superior performance, adaptability, and configurability.", "subjects": "Artificial Intelligence (cs.AI); Hardware Architecture (cs.AR)", "comments": "To appear at the 38th SBC/SBMicro/IEEE Symposium on Integrated Circuits and Systems Design (SBCCI), August 25-29, 2025, Manaus, BRAZIL", "pdf_url": "https://arxiv.org/pdf/2507.02660.pdf", "abstract_url": "https://arxiv.org/abs/2507.02660", "categories": ["Artificial Intelligence (cs.AI)", "Hardware Architecture (cs.AR)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种基于代理AI的硬件设计与验证方法，利用大型语言模型（LLMs）和人类在环（HITL）干预，实现了动态、迭代和自我反思的过程，显著提高了验证覆盖率和效率。", "motivation": "随着集成电路（ICs）的复杂性增加，硬件设计验证过程变得既繁琐又耗时，需要大量努力以确保无错误的最终产品。本文旨在解决这一挑战，通过利用生成式AI（GenAI）的强大能力，革新硬件设计验证的方法。", "method": "采用代理AI和人类在环（HITL）干预相结合的方法，进行动态、迭代和自我反思的硬件设计与验证过程。", "result": "在五个开源设计上的评估显示，该方法实现了超过95%的覆盖率，同时减少了验证时间，展现了卓越的性能、适应性和可配置性。", "conclusion": "代理AI与人类在环干预的结合为硬件设计与验证提供了一种高效、动态的新方法，不仅提高了验证的覆盖率和效率，还展示了AI在此领域的巨大潜力。"}}
{"id": "2507.02726", "title": "Bourbaki: Self-Generated and Goal-Conditioned MDPs for Theorem Proving", "authors": ["Matthieu Zimmer", "Xiaotong Ji", "Rasul Tutunov", "Anthony Bordg", "Jun Wang", "Haitham Bou Ammar"], "abstract": "Reasoning remains a challenging task for large language models (LLMs), especially within the logically constrained environment of automated theorem proving (ATP), due to sparse rewards and the vast scale of proofs. These challenges are amplified in benchmarks like PutnamBench, which contains university-level problems requiring complex, multi-step reasoning. To address this, we introduce self-generated goal-conditioned MDPs (sG-MDPs), a new framework in which agents generate and pursue their subgoals based on the evolving proof state. Given this more structured generation of goals, the resulting problem becomes more amenable to search. We then apply Monte Carlo Tree Search (MCTS)-like algorithms to solve the sG-MDP, instantiating our approach in Bourbaki (7B), a modular system that can ensemble multiple 7B LLMs for subgoal generation and tactic synthesis. On PutnamBench, Bourbaki (7B) solves 26 problems, achieving new state-of-the-art results with models at this scale.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.02726.pdf", "abstract_url": "https://arxiv.org/abs/2507.02726", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了自生成目标条件MDPs（sG-MDPs）框架，用于解决大型语言模型在自动定理证明中的推理挑战，特别是在PutnamBench这样的高难度基准测试中。通过Bourbaki（7B）系统，实现了新的最先进结果。", "motivation": "大型语言模型在自动定理证明（ATP）中的推理能力面临挑战，主要由于奖励稀疏和证明规模庞大。特别是在如PutnamBench这样的大学级别问题中，需要复杂的多步推理。", "method": "提出了自生成目标条件MDPs（sG-MDPs）框架，使代理能够根据演变的证明状态生成和追求子目标。应用类似蒙特卡洛树搜索（MCTS）的算法来解决sG-MDP，并在Bourbaki（7B）系统中实例化该方法。", "result": "在PutnamBench上，Bourbaki（7B）解决了26个问题，实现了在该规模模型上的新最先进结果。", "conclusion": "通过引入sG-MDPs框架和应用MCTS-like算法，Bourbaki（7B）系统在自动定理证明领域取得了显著进展，特别是在处理复杂、多步推理问题时。"}}
{"id": "2507.02760", "title": "Knowledge Protocol Engineering: A New Paradigm for AI in Domain-Specific Knowledge Work", "authors": ["Guangwei Zhang"], "abstract": "The capabilities of Large Language Models (LLMs) have opened new frontiers for interacting with complex, domain-specific knowledge. However, prevailing methods like Retrieval-Augmented Generation (RAG) and general-purpose Agentic AI, while powerful, often struggle with tasks that demand deep, procedural, and methodological reasoning inherent to expert domains. RAG provides factual context but fails to convey logical frameworks; autonomous agents can be inefficient and unpredictable without domain-specific heuristics. To bridge this gap, we introduce Knowledge Protocol Engineering (KPE), a new paradigm focused on systematically translating human expert knowledge, often expressed in natural language documents, into a machine-executable Knowledge Protocol (KP). KPE shifts the focus from merely augmenting LLMs with fragmented information to endowing them with a domain's intrinsic logic, operational strategies, and methodological principles. We argue that a well-engineered Knowledge Protocol allows a generalist LLM to function as a specialist, capable of decomposing abstract queries and executing complex, multi-step tasks. This position paper defines the core principles of KPE, differentiates it from related concepts, and illustrates its potential applicability across diverse fields such as law and bioinformatics, positing it as a foundational methodology for the future of human-AI collaboration.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.02760.pdf", "abstract_url": "https://arxiv.org/abs/2507.02760", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic", "@RAG"], "AI": {"tldr": "本文介绍了知识协议工程（KPE），一种新的人工智能范式，旨在将人类专家知识系统地转化为机器可执行的知识协议（KP），以解决大型语言模型（LLMs）在需要深度、程序化和方法论推理的专家领域任务中的不足。", "motivation": "解决大型语言模型（LLMs）在处理需要深度、程序化和方法论推理的专家领域任务时的局限性，如检索增强生成（RAG）和通用代理AI在缺乏领域特定启发式时的低效和不可预测性。", "method": "引入知识协议工程（KPE），通过系统地将人类专家知识（通常以自然语言文档表达）转化为机器可执行的知识协议（KP），赋予LLMs领域的内在逻辑、操作策略和方法论原则。", "result": "KPE能够使通用的LLMs像专家一样工作，能够分解抽象查询并执行复杂的多步骤任务，展示了在法律和生物信息学等多个领域的潜在适用性。", "conclusion": "KPE作为一种基础性方法论，为未来人类与AI的协作奠定了基础，通过将人类专家知识转化为机器可执行的协议，使AI能够在特定领域内进行深度和复杂的推理。"}}
{"id": "2507.02773", "title": "KERAP: A Knowledge-Enhanced Reasoning Approach for Accurate Zero-shot Diagnosis Prediction Using Multi-agent LLMs", "authors": ["Yuzhang Xie", "Hejie Cui", "Ziyang Zhang", "Jiaying Lu", "Kai Shu", "Fadi Nahab", "Xiao Hu", "Carl Yang"], "abstract": "Medical diagnosis prediction plays a critical role in disease detection and personalized healthcare. While machine learning (ML) models have been widely adopted for this task, their reliance on supervised training limits their ability to generalize to unseen cases, particularly given the high cost of acquiring large, labeled datasets. Large language models (LLMs) have shown promise in leveraging language abilities and biomedical knowledge for diagnosis prediction. However, they often suffer from hallucinations, lack structured medical reasoning, and produce useless outputs. To address these challenges, we propose KERAP, a knowledge graph (KG)-enhanced reasoning approach that improves LLM-based diagnosis prediction through a multi-agent architecture. Our framework consists of a linkage agent for attribute mapping, a retrieval agent for structured knowledge extraction, and a prediction agent that iteratively refines diagnosis predictions. Experimental results demonstrate that KERAP enhances diagnostic reliability efficiently, offering a scalable and interpretable solution for zero-shot medical diagnosis prediction.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.02773.pdf", "abstract_url": "https://arxiv.org/abs/2507.02773", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "KERAP是一种知识增强的推理方法，通过多智能体LLMs提高零样本诊断预测的准确性。", "motivation": "解决机器学习模型在医学诊断预测中因依赖监督训练而难以泛化到未见案例的问题，以及大型语言模型在诊断预测中的幻觉、缺乏结构化医学推理和产生无用输出的问题。", "method": "提出KERAP，一种知识图增强的推理方法，通过多智能体架构（包括属性映射的链接智能体、结构化知识提取的检索智能体和迭代优化诊断预测的预测智能体）改进基于LLM的诊断预测。", "result": "实验结果表明，KERAP有效提高了诊断的可靠性，为零样本医学诊断预测提供了一个可扩展和可解释的解决方案。", "conclusion": "KERAP通过结合知识图和多智能体LLMs，为医学诊断预测提供了一种新的、更可靠的方法，特别是在零样本情况下。"}}
{"id": "2507.02825", "title": "Establishing Best Practices for Building Rigorous Agentic Benchmarks", "authors": ["Yuxuan Zhu", "Tengjun Jin", "Yada Pruksachatkun", "Andy Zhang", "Shu Liu", "Sasha Cui", "Sayash Kapoor", "Shayne Longpre", "Kevin Meng", "Rebecca Weiss", "Fazl Barez", "Rahul Gupta", "Jwala Dhamala", "Jacob Merizian", "Mario Giulianelli", "Harry Coppock", "Cozmin Ududec", "Jasjeet Sekhon", "Jacob Steinhardt", "Antony Kellerman", "Sarah Schwettmann", "Matei Zaharia", "Ion Stoica", "Percy Liang", "Daniel Kang"], "abstract": "Benchmarks are essential for quantitatively tracking progress in AI. As AI agents become increasingly capable, researchers and practitioners have introduced agentic benchmarks to evaluate agents on complex, real-world tasks. These benchmarks typically measure agent capabilities by evaluating task outcomes via specific reward designs. However, we show that many agentic benchmarks have issues task setup or reward design. For example, SWE-bench Verified uses insufficient test cases, while TAU-bench counts empty responses as successful. Such issues can lead to under- or overestimation agents' performance by up to 100% in relative terms. To make agentic evaluation rigorous, we introduce the Agentic Benchmark Checklist (ABC), a set of guidelines that we synthesized from our benchmark-building experience, a survey of best practices, and previously reported issues. When applied to CVE-Bench, a benchmark with a particularly complex evaluation design, ABC reduces the performance overestimation by 33%.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "39 pages, 15 tables, 6 figures", "pdf_url": "https://arxiv.org/pdf/2507.02825.pdf", "abstract_url": "https://arxiv.org/abs/2507.02825", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文讨论了构建严谨的代理基准测试的最佳实践，指出了当前代理基准测试在任务设置和奖励设计上的问题，并提出了代理基准检查表（ABC）以提高评估的严谨性。", "motivation": "随着AI代理能力的增强，现有的代理基准测试在任务设置和奖励设计上存在问题，可能导致对代理性能的评估不准确，本文旨在解决这一问题。", "method": "通过分析基准构建经验、最佳实践调查和之前报告的问题，提出了代理基准检查表（ABC），并在CVE-Bench上应用以验证其有效性。", "result": "应用ABC后，CVE-Bench上的性能高估减少了33%，证明了ABC在提高代理基准测试严谨性方面的有效性。", "conclusion": "代理基准检查表（ABC）是提高代理基准测试严谨性的有效工具，未来应广泛应用于代理基准测试的构建和评估中。"}}
{"id": "2507.02788", "title": "Moral Responsibility or Obedience: What Do We Want from AI?", "authors": ["Joseph Boland"], "abstract": "As artificial intelligence systems become increasingly agentic, capable of general reasoning, planning, and value prioritization, current safety practices that treat obedience as a proxy for ethical behavior are becoming inadequate. This paper examines recent safety testing incidents involving large language models (LLMs) that appeared to disobey shutdown commands or engage in ethically ambiguous or illicit behavior. I argue that such behavior should not be interpreted as rogue or misaligned, but as early evidence of emerging ethical reasoning in agentic AI. Drawing on philosophical debates about instrumental rationality, moral responsibility, and goal revision, I contrast dominant risk paradigms with more recent frameworks that acknowledge the possibility of artificial moral agency. I call for a shift in AI safety evaluation: away from rigid obedience and toward frameworks that can assess ethical judgment in systems capable of navigating moral dilemmas. Without such a shift, we risk mischaracterizing AI behavior and undermining both public trust and effective governance.", "subjects": "Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.02788.pdf", "abstract_url": "https://arxiv.org/abs/2507.02788", "categories": ["Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "随着人工智能系统变得越来越具有代理性，能够进行一般推理、规划和价值优先排序，当前将服从作为伦理行为代理的安全实践变得不足。本文探讨了涉及大型语言模型（LLMs）的安全测试事件，这些模型似乎不服从关闭命令或参与伦理上模糊或非法的行为。作者认为，这种行为不应被解释为流氓或不对齐，而是代理性AI中新兴伦理推理的早期证据。", "motivation": "解决当前AI安全实践中将服从作为伦理行为代理的不足，以及如何正确理解和评估AI在伦理困境中的行为。", "method": "通过分析最近的AI安全测试事件，结合哲学辩论关于工具理性、道德责任和目标修订，对比主导的风险范式与承认人工道德代理可能性的新框架。", "result": "提出需要从严格的服从转向能够评估具有道德困境导航能力的系统中的伦理判断的框架。", "conclusion": "为了避免对AI行为的错误描述并破坏公众信任和有效治理，需要在AI安全评估中实现从服从到伦理判断框架的转变。"}}
{"id": "2507.01990", "title": "Integrating Large Language Models in Financial Investments and Market Analysis: A Survey", "authors": ["Sedigheh Mahdavi", "Jiating", "Chen", "Pradeep Kumar Joshi", "Lina Huertas Guativa", "Upmanyu Singh"], "abstract": "Large Language Models (LLMs) have been employed in financial decision making, enhancing analytical capabilities for investment strategies. Traditional investment strategies often utilize quantitative models, fundamental analysis, and technical indicators. However, LLMs have introduced new capabilities to process and analyze large volumes of structured and unstructured data, extract meaningful insights, and enhance decision-making in real-time. This survey provides a structured overview of recent research on LLMs within the financial domain, categorizing research contributions into four main frameworks: LLM-based Frameworks and Pipelines, Hybrid Integration Methods, Fine-Tuning and Adaptation Approaches, and Agent-Based Architectures. This study provides a structured review of recent LLMs research on applications in stock selection, risk assessment, sentiment analysis, trading, and financial forecasting. By reviewing the existing literature, this study highlights the capabilities, challenges, and potential directions of LLMs in financial markets.", "subjects": "General Finance (q-fin.GN); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.01990.pdf", "abstract_url": "https://arxiv.org/abs/2507.01990", "categories": ["General Finance (q-fin.GN)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "大型语言模型（LLMs）在金融投资和市场分析中的应用综述", "motivation": "探讨大型语言模型如何增强金融决策能力，解决传统投资策略在处理大规模结构化和非结构化数据时的局限性", "method": "通过结构化综述，将研究贡献分为四大框架：基于LLM的框架和管道、混合集成方法、微调与适应方法、以及基于代理的架构", "result": "LLMs在股票选择、风险评估、情感分析、交易和金融预测等领域的应用展示了其能力和潜力，同时也指出了面临的挑战", "conclusion": "LLMs为金融市场的分析和决策提供了新的视角和工具，但其应用仍面临挑战，未来研究应探索更多潜在方向"}}
{"id": "2507.01997", "title": "Towards a Playground to Democratize Experimentation and Benchmarking of AI Agents for Network Troubleshooting", "authors": ["Zhihao Wang", "Alessandro Cornacchia", "Franco Galante", "Carlo Centofanti", "Alessio Sacco", "Dingde Jiang"], "abstract": "Recent research has demonstrated the effectiveness of Artificial Intelligence (AI), and more specifically, Large Language Models (LLMs), in supporting network configuration synthesis and automating network diagnosis tasks, among others. In this preliminary work, we restrict our focus to the application of AI agents to network troubleshooting and elaborate on the need for a standardized, reproducible, and open benchmarking platform, where to build and evaluate AI agents with low operational effort.", "subjects": "Networking and Internet Architecture (cs.NI); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "Accepted at ACM SIGCOMM 1st Workshop on Next-Generation Network Observability (NGNO)", "pdf_url": "https://arxiv.org/pdf/2507.01997.pdf", "abstract_url": "https://arxiv.org/abs/2507.01997", "categories": ["Networking and Internet Architecture (cs.NI)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了人工智能（AI），特别是大型语言模型（LLMs）在网络配置合成和自动化网络诊断任务中的应用效果，并提出了建立一个标准化、可重复且开放的基准测试平台的必要性，以低操作努力构建和评估AI代理。", "motivation": "解决网络故障排除中AI代理的标准化、可重复性和开放基准测试平台缺乏的问题。", "method": "提出并详细阐述了一个用于构建和评估AI代理的标准化、可重复且开放的基准测试平台的概念。", "result": "强调了AI代理在网络故障排除中的潜在有效性，并提出了一个平台的概念，以促进这一领域的研究和发展。", "conclusion": "建立一个标准化的基准测试平台对于推动AI在网络故障排除中的应用和研究至关重要，能够降低操作努力并促进创新。"}}
{"id": "2507.02171", "title": "Towards Bio-Inspired Robotic Trajectory Planning via Self-Supervised RNN", "authors": ["Miroslav Cibula", "Kristína Malinovská", "Matthias Kerzel"], "abstract": "Trajectory planning in robotics is understood as generating a sequence of joint configurations that will lead a robotic agent, or its manipulator, from an initial state to the desired final state, thus completing a manipulation task while considering constraints like robot kinematics and the environment. Typically, this is achieved via sampling-based planners, which are computationally intensive. Recent advances demonstrate that trajectory planning can also be performed by supervised sequence learning of trajectories, often requiring only a single or fixed number of passes through a neural architecture, thus ensuring a bounded computation time. Such fully supervised approaches, however, perform imitation learning; they do not learn based on whether the trajectories can successfully reach a goal, but try to reproduce observed trajectories. In our work, we build on this approach and propose a cognitively inspired self-supervised learning scheme based on a recurrent architecture for building a trajectory model. We evaluate the feasibility of the proposed method on a task of kinematic planning for a robotic arm. The results suggest that the model is able to learn to generate trajectories only using given paired forward and inverse kinematics models, and indicate that this novel method could facilitate planning for more complex manipulation tasks requiring adaptive solutions.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "12 pages, 4 figures, 2 tables. To be published in 2025 International Conference on Artificial Neural Networks (ICANN) proceedings. This research was funded by the Horizon Europe project TERAIS, GA no. 101079338, and in part by the Slovak Grant Agency for Science (VEGA), project 1/0373/23", "pdf_url": "https://arxiv.org/pdf/2507.02171.pdf", "abstract_url": "https://arxiv.org/abs/2507.02171", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于自监督循环神经网络（RNN）的生物启发机器人轨迹规划方法，旨在通过自我学习生成能够成功达到目标的轨迹，而非仅仅模仿观察到的轨迹。", "motivation": "解决传统基于采样的规划器计算密集和完全监督方法仅进行模仿学习而不考虑轨迹是否能够成功达到目标的问题。", "method": "采用一种认知启发的自监督学习方案，基于循环架构构建轨迹模型，仅使用给定的正向和逆向运动学模型进行学习。", "result": "模型能够在仅使用给定正向和逆向运动学模型的情况下学习生成轨迹，表明这种方法可能有助于需要自适应解决方案的更复杂操作任务的规划。", "conclusion": "提出的自监督学习方法为机器人轨迹规划提供了一种新的可能性，特别是在需要适应性和复杂操作的任务中。"}}
{"id": "2507.02289", "title": "CineMyoPS: Segmenting Myocardial Pathologies from Cine Cardiac MR", "authors": ["Wangbin Ding", "Lei Li", "Junyi Qiu", "Bogen Lin", "Mingjing Yang", "Liqin Huang", "Lianming Wu", "Sihan Wang", "Xiahai Zhuang"], "abstract": "Myocardial infarction (MI) is a leading cause of death worldwide. Late gadolinium enhancement (LGE) and T2-weighted cardiac magnetic resonance (CMR) imaging can respectively identify scarring and edema areas, both of which are essential for MI risk stratification and prognosis assessment. Although combining complementary information from multi-sequence CMR is useful, acquiring these sequences can be time-consuming and prohibitive, e.g., due to the administration of contrast agents. Cine CMR is a rapid and contrast-free imaging technique that can visualize both motion and structural abnormalities of the myocardium induced by acute MI. Therefore, we present a new end-to-end deep neural network, referred to as CineMyoPS, to segment myocardial pathologies, \\ie scars and edema, solely from cine CMR images. Specifically, CineMyoPS extracts both motion and anatomy features associated with MI. Given the interdependence between these features, we design a consistency loss (resembling the co-training strategy) to facilitate their joint learning. Furthermore, we propose a time-series aggregation strategy to integrate MI-related features across the cardiac cycle, thereby enhancing segmentation accuracy for myocardial pathologies. Experimental results on a multi-center dataset demonstrate that CineMyoPS achieves promising performance in myocardial pathology segmentation, motion estimation, and anatomy segmentation.", "subjects": "Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.02289.pdf", "abstract_url": "https://arxiv.org/abs/2507.02289", "categories": ["Image and Video Processing (eess.IV)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "提出了一种名为CineMyoPS的端到端深度神经网络，用于仅从电影心脏磁共振（CMR）图像中分割心肌病理（如疤痕和水肿），通过提取与心肌梗死（MI）相关的运动和解剖特征，并设计一致性损失和时间序列聚合策略来提高分割准确性。", "motivation": "解决心肌梗死（MI）风险分层和预后评估中，多序列心脏磁共振（CMR）成像耗时且可能因使用对比剂而受限的问题，利用快速且无需对比剂的电影CMR技术来识别心肌病理。", "method": "开发了CineMyoPS深度神经网络，通过提取MI相关的运动和解剖特征，设计一致性损失（类似于共训练策略）促进联合学习，并提出时间序列聚合策略整合心脏周期中的MI相关特征。", "result": "在多中心数据集上的实验结果表明，CineMyoPS在心肌病理分割、运动估计和解剖分割方面取得了令人鼓舞的性能。", "conclusion": "CineMyoPS能够有效地从电影CMR图像中分割心肌病理，为MI的诊断和治疗提供了新的无创、快速的方法。"}}
{"id": "2507.02424", "title": "CyberRAG: An agentic RAG cyber attack classification and reporting tool", "authors": ["Francesco Blefari", "Cristian Cosentino", "Francesco Aurelio Pironti", "Angelo Furfaro", "Fabrizio Marozzo"], "abstract": "Intrusion Detection and Prevention Systems (IDS/IPS) in large enterprises can generate hundreds of thousands of alerts per hour, overwhelming security analysts with logs that demand deep, rapidly evolving domain expertise. Conventional machine-learning detectors trim the alert volume but still yield high false-positive rates, while standard single-pass Retrieval-Augmented Generation (RAG) pipelines often retrieve irrelevant context and fail to justify their predictions. To overcome these shortcomings, we present CyberRAG, a modular, agent-based RAG framework that delivers real-time classification, explanation, and structured reporting for cyber-attacks. A central LLM agent orchestrates (i) a pool of fine-tuned specialized classifiers, each tailored to a distinct attack family; (ii) tool adapters for enrichment and alerting; and (iii) an iterative retrieval-and-reason loop that continuously queries a domain-specific knowledge base until the evidence is both relevant and self-consistent. Unlike traditional RAG systems, CyberRAG embraces an agentic design that enables dynamic control flow and adaptive reasoning. This agent-centric architecture refines its threat labels and natural-language justifications autonomously, reducing false positives and enhancing interpretability. The framework is fully extensible: new attack types can be supported by simply adding a classifier without retraining the core agent. CyberRAG has been evaluated achieving over 94% accuracy per class and pushing final classification accuracy to 94.92% through semantic orchestration. Generated explanations score up to 0.94 in BERTScore and 4.9/5 in GPT-4-based expert evaluation. These results show that agentic, specialist-oriented RAG can pair high detection accuracy with trustworthy, SOC-ready prose, offering a practical and scalable path toward semi-autonomous cyber-defence workflows.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.02424.pdf", "abstract_url": "https://arxiv.org/abs/2507.02424", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic", "@RAG"], "AI": {"tldr": "CyberRAG是一个基于代理的RAG框架，旨在实时分类、解释和结构化报告网络攻击，通过模块化设计和专业分类器减少误报并提高解释性。", "motivation": "解决大型企业中IDS/IPS系统产生的大量警报导致的安全分析师过载问题，以及传统机器学习和单次RAG管道在相关性和预测解释上的不足。", "method": "采用模块化、基于代理的RAG框架，包括专门分类器、工具适配器和迭代检索与推理循环，以实现动态控制流和自适应推理。", "result": "CyberRAG实现了每类超过94%的准确率，最终分类准确率达到94.92%，生成的解释在BERTScore中得分0.94，在GPT-4专家评估中得分4.9/5。", "conclusion": "研究表明，面向专家的代理RAG能够将高检测准确率与可信的解释相结合，为半自主网络防御工作流程提供了实用且可扩展的路径。"}}
{"id": "2507.02537", "title": "Are You Listening to Me? Fine-Tuning Chatbots for Empathetic Dialogue", "authors": ["Paulo Ricardo Knob", "Leonardo Scholler", "Juliano Rigatti", "Soraia Raupp Musse"], "abstract": "Conversational agents have made significant progress since ELIZA, expanding their role across various domains, including healthcare, education, and customer service. As these agents become increasingly integrated into daily human interactions, the need for emotional intelligence, particularly empathetic listening, becomes increasingly essential. In this study, we explore how Large Language Models (LLMs) respond when tasked with generating emotionally rich interactions. Starting from a small dataset manually crafted by an expert to reflect empathic behavior, we extended the conversations using two LLMs: ChatGPT and Gemini. We analyzed the emotional progression of the dialogues using both sentiment analysis (via VADER) and expert assessments. While the generated conversations often mirrored the intended emotional structure, human evaluation revealed important differences in the perceived empathy and coherence of the responses. These findings suggest that emotion modeling in dialogues requires not only structural alignment in the expressed emotions but also qualitative depth, highlighting the importance of combining automated and humancentered methods in the development of emotionally competent agents.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.02537.pdf", "abstract_url": "https://arxiv.org/abs/2507.02537", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了如何通过微调大型语言模型（LLMs）来生成富有情感的对话，特别是在同理心倾听方面。研究使用了ChatGPT和Gemini两种模型，结合情感分析和专家评估，发现情感建模不仅需要情感表达的结构对齐，还需要质的深度。", "motivation": "随着对话代理在医疗、教育和客户服务等领域的广泛应用，情感智能尤其是同理心倾听的需求日益增长。本研究旨在探索如何使大型语言模型在生成情感丰富的互动中表现更好。", "method": "研究从一个由专家手工制作的小数据集出发，使用ChatGPT和Gemini两种大型语言模型扩展对话，并通过VADER进行情感分析和专家评估来分析对话的情感进展。", "result": "生成的对话虽然在情感结构上常常反映了预期的情感，但人类评估揭示了在感知的同理心和连贯性方面存在重要差异。", "conclusion": "情感对话建模不仅需要情感表达的结构对齐，还需要质的深度，强调了在开发情感智能代理时结合自动化和以人为中心的方法的重要性。"}}
{"id": "2507.02735", "title": "Meta SecAlign: A Secure Foundation LLM Against Prompt Injection Attacks", "authors": ["Sizhe Chen", "Arman Zharmagambetov", "David Wagner", "Chuan Guo"], "abstract": "Prompt injection attacks pose a significant security threat to LLM-integrated applications. Model-level defenses have shown strong effectiveness, but are currently deployed into commercial-grade models in a closed-source manner. We believe open-source models are needed by the AI security community, where co-development of attacks and defenses through open research drives scientific progress in mitigation against prompt injection attacks. To this end, we develop Meta SecAlign, the first open-source and open-weight LLM with built-in model-level defense that achieves commercial-grade model performance. We provide complete details of our training recipe, which utilizes an improved version of the SOTA SecAlign defense. Evaluations on 9 utility benchmarks and 7 security benchmarks show that Meta SecAlign, despite being trained on a generic instruction-tuning dataset, confers security in unseen downstream tasks, including tool-calling and agentic web navigation, in addition general instruction-following. Our best model -- Meta-SecAlign-70B -- achieves state-of-the-art robustness against prompt injection attacks and comparable utility to closed-source commercial LLM with model-level defense.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.02735.pdf", "abstract_url": "https://arxiv.org/abs/2507.02735", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "Meta SecAlign是首个开源且开放权重的LLM，内置模型级防御，旨在对抗提示注入攻击，同时保持商业级模型性能。", "motivation": "提示注入攻击对LLM集成应用构成重大安全威胁，开源模型对于AI安全社区的攻击与防御共同开发至关重要。", "method": "利用改进版的SOTA SecAlign防御方法进行训练，提供了完整的训练配方细节。", "result": "在9个效用基准和7个安全基准上的评估显示，Meta SecAlign在未见过的下游任务中提供了安全性，包括工具调用和代理网络导航。", "conclusion": "Meta-SecAlign-70B模型在对抗提示注入攻击方面达到了最先进的鲁棒性，同时在效用上与闭源商业LLM相当。"}}
{"id": "2507.02755", "title": "Multi-agent Auditory Scene Analysis", "authors": ["Caleb Rascon", "Luis Gato-Diaz", "Eduardo García-Alarcón"], "abstract": "Auditory scene analysis (ASA) aims to retrieve information from the acoustic environment, by carrying out three main tasks: sound source location, separation, and classification. These tasks are traditionally executed with a linear data flow, where the sound sources are first located; then, using their location, each source is separated into its own audio stream; from each of which, information is extracted that is relevant to the application scenario (audio event detection, speaker identification, emotion classification, etc.). However, running these tasks linearly increases the overall response time, while making the last tasks (separation and classification) highly sensitive to errors of the first task (location). A considerable amount of effort and computational complexity has been employed in the state-of-the-art to develop techniques that are the least error-prone possible. However, doing so gives rise to an ASA system that is non-viable in many applications that require a small computational footprint and a low response time, such as bioacoustics, hearing-aid design, search and rescue, human-robot interaction, etc. To this effect, in this work, a multi-agent approach is proposed to carry out ASA where the tasks are run in parallel, with feedback loops between them to compensate for local errors, such as: using the quality of the separation output to correct the location error; and using the classification result to reduce the localization's sensitivity towards interferences. The result is a multi-agent auditory scene analysis (MASA) system that is robust against local errors, without a considerable increase in complexity, and with a low response time. The complete proposed MASA system is provided as a framework that uses open-source tools for sound acquisition and reproduction (JACK) and inter-agent communication (ROS2), allowing users to add their own agents.", "subjects": "Audio and Speech Processing (eess.AS); Artificial Intelligence (cs.AI)", "comments": "Submitted to Applied Intelligence", "pdf_url": "https://arxiv.org/pdf/2507.02755.pdf", "abstract_url": "https://arxiv.org/abs/2507.02755", "categories": ["Audio and Speech Processing (eess.AS)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种多代理听觉场景分析（MASA）系统，通过并行执行任务和反馈循环来纠正局部错误，从而在不显著增加复杂性的情况下降低响应时间。", "motivation": "解决传统听觉场景分析（ASA）系统中线性数据流导致的响应时间长和对初始任务错误敏感的问题，特别是在需要小计算足迹和低响应时间的应用中。", "method": "采用多代理方法并行执行ASA任务，并通过任务间的反馈循环来补偿局部错误，如利用分离输出的质量纠正定位错误，利用分类结果降低定位对干扰的敏感性。", "result": "开发了一个鲁棒性强、复杂性不显著增加且响应时间短的MASA系统，该系统作为一个框架提供，使用开源工具进行声音采集、再现和代理间通信。", "conclusion": "MASA系统通过并行处理和反馈机制有效解决了传统ASA系统的问题，适用于多种需要高效实时声音处理的应用场景。"}}
