{"id": "2509.14267", "title": "Graph-Enhanced Retrieval-Augmented Question Answering for E-Commerce Customer Support", "authors": ["Piyushkumar Patel"], "abstract": "E-Commerce customer support requires quick and accurate answers grounded in product data and past support cases. This paper develops a novel retrieval-augmented generation (RAG) framework that uses knowledge graphs (KGs) to improve the relevance of the answer and the factual grounding. We examine recent advances in knowledge-augmented RAG and chatbots based on large language models (LLM) in customer support, including Microsoft's GraphRAG and hybrid retrieval architectures. We then propose a new answer synthesis algorithm that combines structured subgraphs from a domain-specific KG with text documents retrieved from support archives, producing more coherent and grounded responses. We detail the architecture and knowledge flow of our system, provide comprehensive experimental evaluation, and justify its design in real-time support settings. Our implementation demonstrates 23\\% improvement in factual accuracy and 89\\% user satisfaction in e-Commerce QA scenarios.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Theory (cs.IT)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14267.pdf", "abstract_url": "https://arxiv.org/abs/2509.14267", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Information Theory (cs.IT)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种基于知识图谱的检索增强生成框架，用于提升电子商务客户支持中问答的准确性和相关性。", "motivation": "解决电子商务客户支持中需要快速、准确且基于产品数据和历史案例的答案的问题。", "method": "使用知识图谱和文本检索相结合的新颖算法，结合结构化子图和文档检索来合成答案。", "result": "在实验中，事实准确性提高了23%，用户满意度达到89%。", "conclusion": "该方法在实时支持场景中有效，提高了回答的连贯性和事实基础。"}}
{"id": "2509.14257", "title": "From Correction to Mastery: Reinforced Distillation of Large Language Model Agents", "authors": ["Yuanjie Lyu", "Chengyu Wang", "Jun Huang", "Tong Xu"], "abstract": "Large Language Model agents excel at solving complex tasks through iterative reasoning and tool use, but typically depend on ultra-large, costly backbones. Existing distillation approaches train smaller students to imitate full teacher trajectories, yet reasoning and knowledge gaps between the teacher and student often lead to compounding errors. We propose SCoRe, a student-centered framework in which the student generates trajectories and the teacher intervenes only at the first critical error, producing training data matched to the student's ability and exposing specific weaknesses. The student is first fine-tuned on corrected trajectories. Subsequently, short-horizon reinforcement learning starts from the verified prefix before the first critical error, with target rewards assigned at that step. This design encourages autonomous problem-solving beyond imitation and improves training stability. Particularly, on 12 challenging benchmarks, a 7B-parameter student distilled with SCoRe matches the agentic performance of a 72B-parameter teacher.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14257.pdf", "abstract_url": "https://arxiv.org/abs/2509.14257", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "SCoRe框架通过教师仅在首次关键错误时干预，结合纠正轨迹微调和短视距强化学习，使7B参数学生模型在12个基准上匹配72B参数教师的代理性能。", "motivation": "解决大型语言模型代理依赖昂贵大模型，以及现有蒸馏方法中学生推理和知识差距导致错误累积的问题。", "method": "使用SCoRe框架：学生生成轨迹，教师干预首次关键错误，先微调纠正轨迹，再应用短视距强化学习从已验证前缀开始。", "result": "在12个挑战性基准上，7B参数学生模型达到72B参数教师的代理性能。", "conclusion": "SCoRe框架有效减少模型大小和成本，提升学生模型的自主问题解决能力和训练稳定性。"}}
{"id": "2509.14268", "title": "DetectAnyLLM: Towards Generalizable and Robust Detection of Machine-Generated Text Across Domains and Models", "authors": ["Jiachen Fu", "Chun-Le Guo", "Chongyi Li"], "abstract": "The rapid advancement of large language models (LLMs) has drawn urgent attention to the task of machine-generated text detection (MGTD). However, existing approaches struggle in complex real-world scenarios: zero-shot detectors rely heavily on scoring model's output distribution while training-based detectors are often constrained by overfitting to the training data, limiting generalization. We found that the performance bottleneck of training-based detectors stems from the misalignment between training objective and task needs. To address this, we propose Direct Discrepancy Learning (DDL), a novel optimization strategy that directly optimizes the detector with task-oriented knowledge. DDL enables the detector to better capture the core semantics of the detection task, thereby enhancing both robustness and generalization. Built upon this, we introduce DetectAnyLLM, a unified detection framework that achieves state-of-the-art MGTD performance across diverse LLMs. To ensure a reliable evaluation, we construct MIRAGE, the most diverse multi-task MGTD benchmark. MIRAGE samples human-written texts from 10 corpora across 5 text-domains, which are then re-generated or revised using 17 cutting-edge LLMs, covering a wide spectrum of proprietary models and textual styles. Extensive experiments on MIRAGE reveal the limitations of existing methods in complex environment. In contrast, DetectAnyLLM consistently outperforms them, achieving over a 70% performance improvement under the same training data and base scoring model, underscoring the effectiveness of our DDL. Project page: {", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14268.pdf", "abstract_url": "https://arxiv.org/abs/2509.14268", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "提出了DetectAnyLLM框架和DDL优化策略，通过MIRAGE基准测试，在跨域和模型的机器生成文本检测中实现最先进性能，提升泛化性和鲁棒性。", "motivation": "解决现有机器生成文本检测方法在零样本和训练型检测器中泛化不足和过拟合的问题，以适应复杂真实场景。", "method": "引入直接差异学习（DDL）优化策略，直接优化检测器以捕获任务核心语义，并构建DetectAnyLLM统一框架。", "result": "在MIRAGE基准上，DetectAnyLLM相比现有方法性能提升超过70%，显示出更好的泛化和鲁棒性。", "conclusion": "DDL和DetectAnyLLM有效提升了检测性能，为机器生成文本检测提供了更通用的解决方案，具有实际应用价值。"}}
{"id": "2509.14435", "title": "Causal-Counterfactual RAG: The Integration of Causal-Counterfactual Reasoning into RAG", "authors": ["Harshad Khadilkar", "Abhay Gupta"], "abstract": "Large language models (LLMs) have transformed natural language processing (NLP), enabling diverse applications by integrating large-scale pre-trained knowledge. However, their static knowledge limits dynamic reasoning over external information, especially in knowledge-intensive domains. Retrieval-Augmented Generation (RAG) addresses this challenge by combining retrieval mechanisms with generative modeling to improve contextual understanding. Traditional RAG systems suffer from disrupted contextual integrity due to text chunking and over-reliance on semantic similarity for retrieval, often resulting in shallow and less accurate responses. We propose Causal-Counterfactual RAG, a novel framework that integrates explicit causal graphs representing cause-effect relationships into the retrieval process and incorporates counterfactual reasoning grounded on the causal structure. Unlike conventional methods, our framework evaluates not only direct causal evidence but also the counterfactuality of associated causes, combining results from both to generate more robust, accurate, and interpretable answers. By leveraging causal pathways and associated hypothetical scenarios, Causal-Counterfactual RAG preserves contextual coherence, reduces hallucination, and enhances reasoning fidelity.", "subjects": "Computation and Language (cs.CL); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14435.pdf", "abstract_url": "https://arxiv.org/abs/2509.14435", "categories": ["Computation and Language (cs.CL)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "提出Causal-Counterfactual RAG框架，通过整合因果图和反事实推理，提升RAG系统的准确性、鲁棒性和可解释性。", "motivation": "解决传统RAG系统因文本分块和过度依赖语义相似性导致的上下文完整性破坏和浅层响应问题。", "method": "集成显式因果图到检索过程，并基于因果结构进行反事实推理，结合因果证据和反事实性评估。", "result": "框架保持上下文连贯性，减少幻觉，增强推理保真度，生成更准确和可解释的答案。", "conclusion": "Causal-Counterfactual RAG通过因果-反事实推理改进RAG，适用于知识密集型领域，提升LLMs的动态推理能力。"}}
{"id": "2509.14477", "title": "Ticket-Bench: A Kickoff for Multilingual and Regionalized Agent Evaluation", "authors": ["Thales Sales Almeida", "João Guilherme Alves Santos", "Thiago Laitz", "Giovana Kerche Bonás"], "abstract": "Large language models (LLMs) are increasingly deployed as task-oriented agents, where success depends on their ability to generate accurate function calls under realistic, multilingual conditions. However, existing agent evaluations largely overlook cultural and linguistic diversity, often relying on monolingual or naively translated benchmarks. We introduce Ticket-Bench, a benchmark for multilingual agent evaluation in task-oriented scenarios. Ticket-Bench simulates the domain of soccer ticket purchases across six major languages: Portuguese, English, Spanish, German, Italian, and French. Using localized teams, cities, and user profiles to provide a higher level of realism. We evaluate a wide range of commercial and open-source LLMs, measuring function-calling accuracy and consistency across languages. Results show that reasoning-oriented models (e.g., GPT-5, Qwen3-235B) dominate performance but still exhibit notable cross-lingual disparities. These findings underscore the need for culturally aware, multilingual benchmarks to guide the development of robust LLM agents.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14477.pdf", "abstract_url": "https://arxiv.org/abs/2509.14477", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "介绍了Ticket-Bench基准，用于多语言和区域化代理评估，模拟足球票购买场景，评估LLMs在六种语言中的函数调用准确性和一致性。", "motivation": "解决现有代理评估忽视文化和语言多样性、依赖单语或简单翻译基准的问题。", "method": "创建Ticket-Bench基准，使用本地化元素模拟多语言任务导向场景，评估商业和开源LLMs的函数调用性能。", "result": "推理导向模型（如GPT-5、Qwen3-235B）表现最佳，但存在显著的跨语言差异。", "conclusion": "强调需要文化感知的多语言基准来指导稳健LLM代理的开发。"}}
{"id": "2509.14480", "title": "Process-Supervised Reinforcement Learning for Interactive Multimodal Tool-Use Agents", "authors": ["Weiting Tan", "Xinghua Qu", "Ming Tu", "Meng Ge", "Andy T. Liu", "Philipp Koehn", "Lu Lu"], "abstract": "Effective interactive tool use requires agents to master Tool Integrated Reasoning (TIR): a complex process involving multi-turn planning and long-context dialogue management. To train agents for this dynamic process, particularly in multi-modal contexts, we introduce a sandbox environment for reinforcement learning (RL) that supports interleaved speech-text rollouts. Our core strategy, Turn-level Adjudicated Reinforcement Learning (TARL), addresses the challenge of credit assignment in long-horizon tasks by employing a Large Language Model (LLM) as a judge to provide turn-level evaluation. To enhance exploration, we integrate a mixed-task training curriculum with mathematical reasoning problems. This unified approach boosts the task pass rate on the text-based $\\tau$-bench by over 6% compared to strong RL baselines. Crucially, we demonstrate our framework's suitability for fine-tuning a multi-modal foundation model for agentic tasks. By training a base multi-modal LLM on interleaved speech-text rollouts, we equip it with tool-use abilities, paving the way for more natural, voice-driven interactive agents.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14480.pdf", "abstract_url": "https://arxiv.org/abs/2509.14480", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种用于交互式多模态工具使用代理的强化学习框架，通过Turn-level Adjudicated Reinforcement Learning (TARL) 和混合任务课程，提高了任务通过率，并展示了在多模态基础模型上的适用性。", "motivation": "解决在交互式工具使用中，代理需要掌握Tool Integrated Reasoning (TIR)，包括多轮规划和长上下文对话管理的挑战，特别是在多模态环境中。", "method": "使用强化学习沙盒环境支持语音-文本交错展开，核心策略TARL利用大型语言模型作为评判进行轮级评估，并集成混合任务课程以增强探索。", "result": "在文本基准τ-bench上，任务通过率比强RL基线提高了超过6%，并成功微调多模态基础模型，使其具备工具使用能力。", "conclusion": "该框架为开发更自然的语音驱动交互代理铺平了道路，强调了其在多模态代理任务中的适用性和有效性。"}}
{"id": "2509.14635", "title": "SWE-QA: Can Language Models Answer Repository-level Code Questions?", "authors": ["Weihan Peng", "Yuling Shi", "Yuhang Wang", "Xinyun Zhang", "Beijun Shen", "Xiaodong Gu"], "abstract": "Understanding and reasoning about entire software repositories is an essential capability for intelligent software engineering tools. While existing benchmarks such as CoSQA and CodeQA have advanced the field, they predominantly focus on small, self-contained code snippets. These setups fail to capture the complexity of real-world repositories, where effective understanding and reasoning often require navigating multiple files, understanding software architecture, and grounding answers in long-range code dependencies. In this paper, we present SWE-QA, a repository-level code question answering (QA) benchmark designed to facilitate research on automated QA systems in realistic code environments. SWE-QA involves 576 high-quality question-answer pairs spanning diverse categories, including intention understanding, cross-file reasoning, and multi-hop dependency analysis. To construct SWE-QA, we first crawled 77,100 GitHub issues from 11 popular repositories. Based on an analysis of naturally occurring developer questions extracted from these issues, we developed a two-level taxonomy of repository-level questions and constructed a set of seed questions for each category. For each category, we manually curated and validated questions and collected their corresponding answers. As a prototype application, we further develop SWE-QA-Agent, an agentic framework in which LLM agents reason and act to find answers automatically. We evaluate six advanced LLMs on SWE-QA under various context augmentation strategies. Experimental results highlight the promise of LLMs, particularly our SWE-QA-Agent framework, in addressing repository-level QA, while also revealing open challenges and pointing to future research directions.", "subjects": "Computation and Language (cs.CL); Programming Languages (cs.PL); Software Engineering (cs.SE)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2509.14635.pdf", "abstract_url": "https://arxiv.org/abs/2509.14635", "categories": ["Computation and Language (cs.CL)", "Programming Languages (cs.PL)", "Software Engineering (cs.SE)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了SWE-QA，一个仓库级代码问答基准，用于评估语言模型在真实软件仓库环境中的问答能力，并开发了SWE-QA-Agent框架进行实验验证。", "motivation": "现有基准如CoSQA和CodeQA主要关注小代码片段，无法捕捉真实仓库的复杂性，需要解决多文件导航、软件架构理解和长距离依赖推理的问题。", "method": "通过爬取GitHub问题，开发两级分类法，手动构建高质量问答对，并创建SWE-QA-Agent框架，使用LLM代理进行自动推理和答案查找。", "result": "实验评估显示LLM（特别是SWE-QA-Agent）在仓库级问答中表现出潜力，但也揭示了开放挑战，如上下文增强策略的局限性。", "conclusion": "SWE-QA推动了自动化问答系统研究，指出了未来方向，如改进LLM在复杂代码环境中的推理能力。"}}
{"id": "2509.14671", "title": "TableDART: Dynamic Adaptive Multi-Modal Routing for Table Understanding", "authors": ["Xiaobo Xing", "Wei Yuan", "Tong Chen", "Quoc Viet Hung Nguyen", "Xiangliang Zhang", "Hongzhi Yin"], "abstract": "Modeling semantic and structural information from tabular data remains a core challenge for effective table understanding. Existing Table-as-Text approaches flatten tables for large language models (LLMs), but lose crucial structural cues, while Table-as-Image methods preserve structure yet struggle with fine-grained semantics. Recent Table-as-Multimodality strategies attempt to combine textual and visual views, but they (1) statically process both modalities for every query-table pair within a large multimodal LLMs (MLLMs), inevitably introducing redundancy and even conflicts, and (2) depend on costly fine-tuning of MLLMs. In light of this, we propose TableDART, a training-efficient framework that integrates multimodal views by reusing pretrained single-modality models. TableDART introduces a lightweight 2.59M-parameter MLP gating network that dynamically selects the optimal path (either Text-only, Image-only, or Fusion) for each table-query pair, effectively reducing redundancy and conflicts from both modalities. In addition, we propose a novel agent to mediate cross-modal knowledge integration by analyzing outputs from text- and image-based models, either selecting the best result or synthesizing a new answer through reasoning. This design avoids the prohibitive costs of full MLLM fine-tuning. Extensive experiments on seven benchmarks show that TableDART establishes new state-of-the-art performance among open-source models, surpassing the strongest baseline by an average of 4.02%. The code is available at:", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14671.pdf", "abstract_url": "https://arxiv.org/abs/2509.14671", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "TableDART is a training-efficient framework for table understanding that dynamically selects optimal multimodal paths using a lightweight gating network, achieving state-of-the-art performance without full MLLM fine-tuning.", "motivation": "Existing table understanding methods either lose structural cues (Table-as-Text) or struggle with semantics (Table-as-Image), and multimodal approaches are redundant, conflict-prone, and costly to fine-tune.", "method": "Uses a 2.59M-parameter MLP gating network to dynamically route queries to text-only, image-only, or fusion paths, and an agent for cross-modal integration, reusing pretrained single-modality models.", "result": "Outperforms baselines by an average of 4.02% on seven benchmarks, establishing new state-of-the-art among open-source models.", "conclusion": "TableDART effectively reduces redundancy and costs in multimodal table understanding, offering a scalable and efficient solution with significant performance improvements."}}
{"id": "2509.14834", "title": "LLM Agents at the Roundtable: A Multi-Perspective and Dialectical Reasoning Framework for Essay Scoring", "authors": ["Jinhee Jang", "Ayoung Moon", "Minkyoung Jung", "YoungBin Kim. Seung Jin Lee"], "abstract": "The emergence of large language models (LLMs) has brought a new paradigm to automated essay scoring (AES), a long-standing and practical application of natural language processing in education. However, achieving human-level multi-perspective understanding and judgment remains a challenge. In this work, we propose Roundtable Essay Scoring (RES), a multi-agent evaluation framework designed to perform precise and human-aligned scoring under a zero-shot setting. RES constructs evaluator agents based on LLMs, each tailored to a specific prompt and topic context. Each agent independently generates a trait-based rubric and conducts a multi-perspective evaluation. Then, by simulating a roundtable-style discussion, RES consolidates individual evaluations through a dialectical reasoning process to produce a final holistic score that more closely aligns with human evaluation. By enabling collaboration and consensus among agents with diverse evaluation perspectives, RES outperforms prior zero-shot AES approaches. Experiments on the ASAP dataset using ChatGPT and Claude show that RES achieves up to a 34.86% improvement in average QWK over straightforward prompting (Vanilla) methods.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14834.pdf", "abstract_url": "https://arxiv.org/abs/2509.14834", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为RES的多智能体评估框架，用于零样本自动论文评分，通过模拟圆桌讨论整合多视角评估，显著提升与人类评分的一致性。", "motivation": "解决大型语言模型在自动论文评分中难以达到人类多视角理解和判断水平的问题。", "method": "构建基于LLM的评估器智能体，每个智能体独立生成评分标准并进行多视角评估，然后通过模拟圆桌讨论的辩证推理过程整合评估结果。", "result": "在ASAP数据集上，RES使用ChatGPT和Claude实现了平均QWK指标最高34.86%的提升，优于现有零样本方法。", "conclusion": "RES框架通过多智能体协作和共识机制，有效提高了自动论文评分的准确性和人类对齐性，具有实际应用潜力。"}}
{"id": "2509.14289", "title": "From Capabilities to Performance: Evaluating Key Functional Properties of LLM Architectures in Penetration Testing", "authors": ["Lanxiao Huang", "Daksh Dave", "Ming Jin", "Tyler Cody", "Peter Beling"], "abstract": "Large language models (LLMs) are increasingly used to automate or augment penetration testing, but their effectiveness and reliability across attack phases remain unclear. We present a comprehensive evaluation of multiple LLM-based agents, from single-agent to modular designs, across realistic penetration testing scenarios, measuring empirical performance and recurring failure patterns. We also isolate the impact of five core functional capabilities via targeted augmentations: Global Context Memory (GCM), Inter-Agent Messaging (IAM), Context-Conditioned Invocation (CCI), Adaptive Planning (AP), and Real-Time Monitoring (RTM). These interventions support, respectively: (i) context coherence and retention, (ii) inter-component coordination and state management, (iii) tool use accuracy and selective execution, (iv) multi-step strategic planning, error detection, and recovery, and (v) real-time dynamic responsiveness. Our results show that while some architectures natively exhibit subsets of these properties, targeted augmentations substantially improve modular agent performance, especially in complex, multi-step, and real-time penetration testing tasks.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14289.pdf", "abstract_url": "https://arxiv.org/abs/2509.14289", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "评估LLM架构在渗透测试中的关键功能属性，通过增强核心能力提升性能。", "motivation": "解决LLM在自动化渗透测试中效果和可靠性不明确的问题。", "method": "综合评估多种LLM代理，通过针对性增强隔离五个核心功能能力的影响。", "result": "针对性增强显著提高模块化代理在复杂任务中的性能。", "conclusion": "增强核心功能能力可改善LLM在渗透测试中的表现。"}}
{"id": "2509.14382", "title": "Detecting Pipeline Failures through Fine-Grained Analysis of Web Agents", "authors": ["Daniel Röder", "Akhil Juneja", "Roland Roller", "Sven Schmeier"], "abstract": "Web agents powered by large language models (LLMs) can autonomously perform complex, multistep tasks in dynamic web environments. However, current evaluations mostly focus on the overall success while overlooking intermediate errors. This limits insight into failure modes and hinders systematic improvement. This work analyzes existing benchmarks and highlights the lack of fine-grained diagnostic tools. To address this gap, we propose a modular evaluation framework that decomposes agent pipelines into interpretable stages for detailed error analysis. Using the SeeAct framework and the Mind2Web dataset as a case study, we show how this approach reveals actionable weaknesses missed by standard metrics - paving the way for more robust and generalizable web agents.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14382.pdf", "abstract_url": "https://arxiv.org/abs/2509.14382", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种模块化评估框架，用于对基于LLM的Web代理进行细粒度错误分析，以揭示标准指标遗漏的可操作弱点。", "motivation": "当前评估主要关注整体成功率，忽略了中间错误，限制了失败模式的洞察和系统改进。", "method": "使用模块化评估框架将代理管道分解为可解释阶段，以SeeAct框架和Mind2Web数据集为案例进行详细错误分析。", "result": "该方法揭示了标准指标未捕捉到的可操作弱点，有助于开发更鲁棒和可泛化的Web代理。", "conclusion": "细粒度分析为Web代理的改进提供了途径，促进了更系统的评估和增强。"}}
{"id": "2509.14485", "title": "Beyond the high score: Prosocial ability profiles of multi-agent populations", "authors": ["Marko Tesic", "Yue Zhao", "Joel Z. Leibo", "Rakshit S. Trivedi", "Jose Hernandez-Orallo"], "abstract": "The development and evaluation of social capabilities in AI agents require complex environments where competitive and cooperative behaviours naturally emerge. While game-theoretic properties can explain why certain teams or agent populations outperform others, more abstract behaviours, such as convention following, are harder to control in training and evaluation settings. The Melting Pot contest is a social AI evaluation suite designed to assess the cooperation capabilities of AI systems. In this paper, we apply a Bayesian approach known as Measurement Layouts to infer the capability profiles of multi-agent systems in the Melting Pot contest. We show that these capability profiles not only predict future performance within the Melting Pot suite but also reveal the underlying prosocial abilities of agents. Our analysis indicates that while higher prosocial capabilities sometimes correlate with better performance, this is not a universal trend-some lower-scoring agents exhibit stronger cooperation abilities. Furthermore, we find that top-performing contest submissions are more likely to achieve high scores in scenarios where prosocial capabilities are not required. These findings, together with reports that the contest winner used a hard-coded solution tailored to specific environments, suggest that at least one top-performing team may have optimised for conditions where cooperation was not necessary, potentially exploiting limitations in the evaluation framework. We provide recommendations for improving the annotation of cooperation demands and propose future research directions to account for biases introduced by different testing environments. Our results demonstrate that Measurement Layouts offer both strong predictive accuracy and actionable insights, contributing to a more transparent and generalisable approach to evaluating AI systems in complex social settings.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14485.pdf", "abstract_url": "https://arxiv.org/abs/2509.14485", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文使用贝叶斯测量布局方法分析多智能体系统在Melting Pot竞赛中的能力，发现亲社会能力与性能不完全相关，并提出改进评估框架的建议。", "motivation": "解决AI智能体在复杂社会环境中亲社会能力评估的挑战，避免评估偏差。", "method": "应用贝叶斯测量布局方法推断多智能体系统的能力概况。", "result": "亲社会能力不一定与高分相关，顶级团队可能利用评估限制，测量布局提供高预测准确性和洞察。", "conclusion": "测量布局有助于更透明和可泛化的AI评估，需改进合作需求标注以减少环境偏见。"}}
{"id": "2509.14507", "title": "DeKeyNLU: Enhancing Natural Language to SQL Generation through Task Decomposition and Keyword Extraction", "authors": ["Jian Chen", "Zhenyan Chen", "Xuming Hu", "Peilin Zhou", "Yining Hua", "Han Fang", "Cissy Hing Yee Choy", "Xinmei Ke", "Jingfeng Luo", "Zixuan Yuan"], "abstract": "Natural Language to SQL (NL2SQL) provides a new model-centric paradigm that simplifies database access for non-technical users by converting natural language queries into SQL commands. Recent advancements, particularly those integrating Retrieval-Augmented Generation (RAG) and Chain-of-Thought (CoT) reasoning, have made significant strides in enhancing NL2SQL performance. However, challenges such as inaccurate task decomposition and keyword extraction by LLMs remain major bottlenecks, often leading to errors in SQL generation. While existing datasets aim to mitigate these issues by fine-tuning models, they struggle with over-fragmentation of tasks and lack of domain-specific keyword annotations, limiting their effectiveness. To address these limitations, we present DeKeyNLU, a novel dataset which contains 1,500 meticulously annotated QA pairs aimed at refining task decomposition and enhancing keyword extraction precision for the RAG pipeline. Fine-tuned with DeKeyNLU, we propose DeKeySQL, a RAG-based NL2SQL pipeline that employs three distinct modules for user question understanding, entity retrieval, and generation to improve SQL generation accuracy. We benchmarked multiple model configurations within DeKeySQL RAG pipeline. Experimental results demonstrate that fine-tuning with DeKeyNLU significantly improves SQL generation accuracy on both BIRD (62.31% to 69.10%) and Spider (84.2% to 88.7%) dev datasets.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14507.pdf", "abstract_url": "https://arxiv.org/abs/2509.14507", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "DeKeyNLU 是一个新数据集，通过任务分解和关键词提取增强 NL2SQL 生成，DeKeySQL 管道提高了 SQL 准确性。", "motivation": "解决大型语言模型在 NL2SQL 中任务分解和关键词提取不准确的问题，现有数据集存在过度碎片化和缺乏领域特定注释的局限。", "method": "创建 DeKeyNLU 数据集（1500 个标注 QA 对），并基于 RAG 构建 DeKeySQL 管道，包含问题理解、实体检索和生成模块。", "result": "在 BIRD 和 Spider 数据集上，SQL 生成准确率分别从 62.31% 提升到 69.10% 和从 84.2% 提升到 88.7%。", "conclusion": "DeKeyNLU 数据集和 DeKeySQL 管道有效提升了 NL2SQL 性能，为简化数据库访问提供了改进方案。"}}
{"id": "2509.14546", "title": "Rationality Check! Benchmarking the Rationality of Large Language Models", "authors": ["Zhilun Zhou", "Jing Yi Wang", "Nicholas Sukiennik", "Chen Gao", "Fengli Xu", "Yong Li", "James Evans"], "abstract": "Large language models (LLMs), a recent advance in deep learning and machine intelligence, have manifested astonishing capacities, now considered among the most promising for artificial general intelligence. With human-like capabilities, LLMs have been used to simulate humans and serve as AI assistants across many applications. As a result, great concern has arisen about whether and under what circumstances LLMs think and behave like real human agents. Rationality is among the most important concepts in assessing human behavior, both in thinking (i.e., theoretical rationality) and in taking action (i.e., practical rationality). In this work, we propose the first benchmark for evaluating the omnibus rationality of LLMs, covering a wide range of domains and LLMs. The benchmark includes an easy-to-use toolkit, extensive experimental results, and analysis that illuminates where LLMs converge and diverge from idealized human rationality. We believe the benchmark can serve as a foundational tool for both developers and users of LLMs.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14546.pdf", "abstract_url": "https://arxiv.org/abs/2509.14546", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了首个评估大型语言模型（LLMs）全方位理性的基准，包括工具包、实验结果和分析，以比较LLMs与理想人类理性的异同。", "motivation": "解决LLMs是否以及在何种情况下像真实人类一样思考和行为的担忧，特别是评估其理论理性和实践理性。", "method": "开发一个基准，涵盖多个领域和LLMs，包括易用工具包、实验和分析方法。", "result": "基准提供了广泛实验结果，揭示了LLMs在理性方面与人类收敛和分歧的具体情况。", "conclusion": "该基准可作为LLMs开发者和用户的基础工具，促进对LLMs理性的评估和改进。"}}
{"id": "2509.14547", "title": "(P)rior(D)yna(F)low: A Priori Dynamic Workflow Construction via Multi-Agent Collaboration", "authors": ["Yi Lin", "Lujin Zhao", "Yijie Shi"], "abstract": "Recent studies have shown that carefully designed workflows coordinating large language models(LLMs) significantly enhance task-solving capabilities compared to using a single model. While an increasing number of works focus on autonomous workflow construction, most existing approaches rely solely on historical experience, leading to limitations in efficiency and adaptability. We argue that while historical experience is valuable, workflow construction should also flexibly respond to the unique characteristics of each task. To this end, we propose an a priori dynamic framework for automated workflow construction. Our framework first leverages Q-table learning to optimize the decision space, guiding agent decisions and enabling effective use of historical experience. At the same time, agents evaluate the current task progress and make a priori decisions regarding the next executing agent, allowing the system to proactively select the more suitable workflow structure for each given task. Additionally, we incorporate mechanisms such as cold-start initialization, early stopping, and pruning to further improve system efficiency. Experimental evaluations on four benchmark datasets demonstrate the feasibility and effectiveness of our approach. Compared to state-of-the-art baselines, our method achieves an average improvement of 4.05%, while reducing workflow construction and inference costs to only 30.68%-48.31% of those required by existing methods.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14547.pdf", "abstract_url": "https://arxiv.org/abs/2509.14547", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种先验动态工作流构建框架，通过多智能体协作，结合Q表学习和任务进度评估，优化决策空间并主动选择合适的工作流结构，在四个基准数据集上验证了其有效性和效率。", "motivation": "解决现有自主工作流构建方法仅依赖历史经验导致的效率低和适应性差的问题，强调需要针对每个任务的独特特性灵活响应。", "method": "使用Q表学习优化决策空间，智能体评估任务进度并做先验决策，结合冷启动初始化、早停和剪枝机制提高效率。", "result": "在基准数据集上，相比最先进基线方法，平均性能提升4.05%，工作流构建和推理成本降至30.68%-48.31%。", "conclusion": "该框架可行且有效，能显著提升任务解决能力和降低成本，为自动化工作流构建提供了新方向。"}}
{"id": "2509.14647", "title": "AgentCompass: Towards Reliable Evaluation of Agentic Workflows in Production", "authors": ["NVJK Kartik", "Garvit Sapra", "Rishav Hada", "Nikhil Pareek"], "abstract": "With the growing adoption of Large Language Models (LLMs) in automating complex, multi-agent workflows, organizations face mounting risks from errors, emergent behaviors, and systemic failures that current evaluation methods fail to capture. We present AgentCompass, the first evaluation framework designed specifically for post-deployment monitoring and debugging of agentic workflows. AgentCompass models the reasoning process of expert debuggers through a structured, multi-stage analytical pipeline: error identification and categorization, thematic clustering, quantitative scoring, and strategic summarization. The framework is further enhanced with a dual memory system-episodic and semantic-that enables continual learning across executions. Through collaborations with design partners, we demonstrate the framework's practical utility on real-world deployments, before establishing its efficacy against the publicly available TRAIL benchmark. AgentCompass achieves state-of-the-art results on key metrics, while uncovering critical issues missed in human annotations, underscoring its role as a robust, developer-centric tool for reliable monitoring and improvement of agentic systems in production.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14647.pdf", "abstract_url": "https://arxiv.org/abs/2509.14647", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "AgentCompass 是一个专为生产环境中多智能体工作流设计的后部署评估框架，通过结构化分析和双记忆系统实现可靠监控和调试。", "motivation": "随着大语言模型在多智能体工作流中的广泛应用，现有评估方法无法有效捕捉错误、涌现行为和系统故障，导致组织面临风险。", "method": "采用多阶段分析管道（错误识别与分类、主题聚类、量化评分和战略总结）和双记忆系统（情景和语义记忆）进行建模和持续学习。", "result": "在真实部署和 TRAIL 基准测试中，AgentCompass 取得了最先进的结果，并发现人类标注遗漏的关键问题。", "conclusion": "AgentCompass 是一个强大、以开发者为中心的工具，可提升生产环境中智能体系统的可靠性和改进能力。"}}
{"id": "2509.14566", "title": "DICE: Diffusion Consensus Equilibrium for Sparse-view CT Reconstruction", "authors": ["Leon Suarez-Rodriguez", "Roman Jacome", "Romario Gualdron-Hurtado", "Ana Mantilla-Dulcey", "Henry Arguello"], "abstract": "Sparse-view computed tomography (CT) reconstruction is fundamentally challenging due to undersampling, leading to an ill-posed inverse problem. Traditional iterative methods incorporate handcrafted or learned priors to regularize the solution but struggle to capture the complex structures present in medical images. In contrast, diffusion models (DMs) have recently emerged as powerful generative priors that can accurately model complex image distributions. In this work, we introduce Diffusion Consensus Equilibrium (DICE), a framework that integrates a two-agent consensus equilibrium into the sampling process of a DM. DICE alternates between: (i) a data-consistency agent, implemented through a proximal operator enforcing measurement consistency, and (ii) a prior agent, realized by a DM performing a clean image estimation at each sampling step. By balancing these two complementary agents iteratively, DICE effectively combines strong generative prior capabilities with measurement consistency. Experimental results show that DICE significantly outperforms state-of-the-art baselines in reconstructing high-quality CT images under uniform and non-uniform sparse-view settings of 15, 30, and 60 views (out of a total of 180), demonstrating both its effectiveness and robustness.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "8 pages, 4 figures, confenrence", "pdf_url": "https://arxiv.org/pdf/2509.14566.pdf", "abstract_url": "https://arxiv.org/abs/2509.14566", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "DICE框架通过结合扩散模型和共识平衡，有效解决了稀疏视图CT重建中的逆问题，显著优于现有方法。", "motivation": "稀疏视图CT重建因采样不足导致逆问题病态，传统方法难以捕捉复杂结构，需要更强先验。", "method": "集成双代理共识平衡到扩散模型采样过程，交替执行数据一致性代理和先验代理以平衡生成能力和测量一致性。", "result": "在15、30和60视图的均匀和非均匀稀疏设置下，DICE显著优于最先进基线，重建高质量CT图像。", "conclusion": "DICE成功结合生成先验和测量一致性，提供有效且鲁棒的CT重建解决方案。"}}
{"id": "2509.14750", "title": "Enhancing Retrieval Augmentation via Adversarial Collaboration", "authors": ["Letian Zhang", "Guanghao Meng", "Xudong Ren", "Yiming Wang", "Shu-Tao Xia"], "abstract": "Retrieval-augmented Generation (RAG) is a prevalent approach for domain-specific LLMs, yet it is often plagued by \"Retrieval Hallucinations\"--a phenomenon where fine-tuned models fail to recognize and act upon poor-quality retrieved documents, thus undermining performance. To address this, we propose the Adversarial Collaboration RAG (AC-RAG) framework. AC-RAG employs two heterogeneous agents: a generalist Detector that identifies knowledge gaps, and a domain-specialized Resolver that provides precise solutions. Guided by a moderator, these agents engage in an adversarial collaboration, where the Detector's persistent questioning challenges the Resolver's expertise. This dynamic process allows for iterative problem dissection and refined knowledge retrieval. Extensive experiments show that AC-RAG significantly improves retrieval accuracy and outperforms state-of-the-art RAG methods across various vertical domains.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14750.pdf", "abstract_url": "https://arxiv.org/abs/2509.14750", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "该论文提出了AC-RAG框架，通过对抗性协作提升检索增强生成，减少检索幻觉，提高准确性。", "motivation": "解决检索增强生成中的检索幻觉问题，即模型无法识别低质量检索文档，从而影响性能。", "method": "使用AC-RAG框架，包括通用检测器和领域专业解析器，在调解者引导下进行对抗性协作，迭代优化检索。", "result": "实验表明，AC-RAG显著提高检索准确性，并在多个垂直领域超越现有RAG方法。", "conclusion": "AC-RAG通过对抗性协作有效解决检索幻觉，提升检索增强生成性能，具有广泛应用潜力。"}}
{"id": "2509.14778", "title": "OpenLens AI: Fully Autonomous Research Agent for Health Infomatics", "authors": ["Yuxiao Cheng", "Jinli Suo"], "abstract": "Health informatics research is characterized by diverse data modalities, rapid knowledge expansion, and the need to integrate insights across biomedical science, data analytics, and clinical practice. These characteristics make it particularly well-suited for agent-based approaches that can automate knowledge exploration, manage complex workflows, and generate clinically meaningful outputs. Recent progress in large language model (LLM)-based agents has demonstrated promising capabilities in literature synthesis, data analysis, and even end-to-end research execution. However, existing systems remain limited for health informatics because they lack mechanisms to interpret medical visualizations and often overlook domain-specific quality requirements. To address these gaps, we introduce OpenLens AI, a fully automated framework tailored to health informatics. OpenLens AI integrates specialized agents for literature review, data analysis, code generation, and manuscript preparation, enhanced by vision-language feedback for medical visualization and quality control for reproducibility. The framework automates the entire research pipeline, producing publication-ready LaTeX manuscripts with transparent and traceable workflows, thereby offering a domain-adapted solution for advancing health informatics research.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14778.pdf", "abstract_url": "https://arxiv.org/abs/2509.14778", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "OpenLens AI是一个专为健康信息学设计的全自动研究代理框架，整合文献综述、数据分析、代码生成和手稿准备，通过视觉语言反馈和质量控制提升可重复性。", "motivation": "解决现有LLM代理在健康信息学中无法解释医学可视化且忽视领域特定质量要求的问题。", "method": "集成专门代理，结合视觉语言反馈和质量控制机制，自动化整个研究流程。", "result": "框架能够生成可发表的LaTeX手稿，提供透明和可追溯的工作流。", "conclusion": "OpenLens AI为健康信息学研究提供了领域适应的自动化解决方案，促进研究进展。"}}
{"id": "2509.14956", "title": "Sentinel Agents for Secure and Trustworthy Agentic AI in Multi-Agent Systems", "authors": ["Diego Gosmar", "Deborah A. Dahl"], "abstract": "This paper proposes a novel architectural framework aimed at enhancing security and reliability in multi-agent systems (MAS). A central component of this framework is a network of Sentinel Agents, functioning as a distributed security layer that integrates techniques such as semantic analysis via large language models (LLMs), behavioral analytics, retrieval-augmented verification, and cross-agent anomaly detection. Such agents can potentially oversee inter-agent communications, identify potential threats, enforce privacy and access controls, and maintain comprehensive audit records. Complementary to the idea of Sentinel Agents is the use of a Coordinator Agent. The Coordinator Agent supervises policy implementation, and manages agent participation. In addition, the Coordinator also ingests alerts from Sentinel Agents. Based on these alerts, it can adapt policies, isolate or quarantine misbehaving agents, and contain threats to maintain the integrity of the MAS ecosystem. This dual-layered security approach, combining the continuous monitoring of Sentinel Agents with the governance functions of Coordinator Agents, supports dynamic and adaptive defense mechanisms against a range of threats, including prompt injection, collusive agent behavior, hallucinations generated by LLMs, privacy breaches, and coordinated multi-agent attacks. In addition to the architectural design, we present a simulation study where 162 synthetic attacks of different families (prompt injection, hallucination, and data exfiltration) were injected into a multi-agent conversational environment. The Sentinel Agents successfully detected the attack attempts, confirming the practical feasibility of the proposed monitoring approach. The framework also offers enhanced system observability, supports regulatory compliance, and enables policy evolution over time.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "25 pages, 12 figures", "pdf_url": "https://arxiv.org/pdf/2509.14956.pdf", "abstract_url": "https://arxiv.org/abs/2509.14956", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种结合哨兵代理和协调代理的双层安全框架，用于增强多代理系统的安全性和可靠性，并通过模拟研究验证了其有效性。", "motivation": "解决多代理系统中的安全威胁，如提示注入、幻觉和隐私泄露，以确保系统的可信赖性。", "method": "使用哨兵代理进行分布式监控，集成语义分析、行为分析和异常检测，配合协调代理进行策略管理和威胁响应。", "result": "在模拟环境中，哨兵代理成功检测了162次合成攻击，证明了监控方法的可行性。", "conclusion": "该框架提供了动态防御机制，增强了系统可观察性和合规性，支持策略演化，适用于实际应用。"}}
{"id": "2509.14998", "title": "A Knowledge-driven Adaptive Collaboration of LLMs for Enhancing Medical Decision-making", "authors": ["Xiao Wu", "Ting-Zhu Huang", "Liang-Jian Deng", "Yanyuan Qiao", "Imran Razzak", "Yutong Xie"], "abstract": "Medical decision-making often involves integrating knowledge from multiple clinical specialties, typically achieved through multidisciplinary teams. Inspired by this collaborative process, recent work has leveraged large language models (LLMs) in multi-agent collaboration frameworks to emulate expert teamwork. While these approaches improve reasoning through agent interaction, they are limited by static, pre-assigned roles, which hinder adaptability and dynamic knowledge integration. To address these limitations, we propose KAMAC, a Knowledge-driven Adaptive Multi-Agent Collaboration framework that enables LLM agents to dynamically form and expand expert teams based on the evolving diagnostic context. KAMAC begins with one or more expert agents and then conducts a knowledge-driven discussion to identify and fill knowledge gaps by recruiting additional specialists as needed. This supports flexible, scalable collaboration in complex clinical scenarios, with decisions finalized through reviewing updated agent comments. Experiments on two real-world medical benchmarks demonstrate that KAMAC significantly outperforms both single-agent and advanced multi-agent methods, particularly in complex clinical scenarios (i.e., cancer prognosis) requiring dynamic, cross-specialty expertise. Our code is publicly available at:", "subjects": "Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "comments": "The paper has been accepted to the EMNLP 2025 Main Conference", "pdf_url": "https://arxiv.org/pdf/2509.14998.pdf", "abstract_url": "https://arxiv.org/abs/2509.14998", "categories": ["Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了KAMAMAC框架，通过知识驱动的动态多智能体协作来增强医疗决策，在复杂临床场景中显著优于现有方法。", "motivation": "解决现有多智能体协作框架中静态角色分配导致的适应性和动态知识整合不足的问题。", "method": "使用KAMAC框架，基于诊断上下文动态形成和扩展专家团队，通过知识驱动讨论填补知识空白。", "result": "在真实医疗基准测试中，KAMAC在复杂场景如癌症预后方面显著优于单智能体和先进多智能体方法。", "conclusion": "KAMAC支持灵活、可扩展的协作，提升医疗决策质量，代码已公开。"}}
{"id": "2509.15172", "title": "Internalizing Self-Consistency in Language Models: Multi-Agent Consensus Alignment", "authors": ["Ankur Samanta", "Akshayaa Magesh", "Youliang Yu", "Runzhe Wu", "Ayush Jain", "Daniel Jiang", "Boris Vidolov", "Paul Sajda", "Yonathan Efroni", "Kaveh Hassani"], "abstract": "Language Models (LMs) are inconsistent reasoners, often generating contradictory responses to identical prompts. While inference-time methods can mitigate these inconsistencies, they fail to address the core problem: LMs struggle to reliably select reasoning pathways leading to consistent outcomes under exploratory sampling. To address this, we formalize self-consistency as an intrinsic property of well-aligned reasoning models and introduce Multi-Agent Consensus Alignment (MACA), a reinforcement learning framework that post-trains models to favor reasoning trajectories aligned with their internal consensus using majority/minority outcomes from multi-agent debate. These trajectories emerge from deliberative exchanges where agents ground reasoning in peer arguments, not just aggregation of independent attempts, creating richer consensus signals than single-round majority voting. MACA enables agents to teach themselves to be more decisive and concise, and better leverage peer insights in multi-agent settings without external supervision, driving substantial improvements across self-consistency (+27.6% on GSM8K), single-agent reasoning (+23.7% on MATH), sampling-based inference (+22.4% Pass@20 on MATH), and multi-agent ensemble decision-making (+42.7% on MathQA). These findings, coupled with strong generalization to unseen benchmarks (+16.3% on GPQA, +11.6% on CommonsenseQA), demonstrate robust self-alignment that more reliably unlocks latent reasoning potential of language models.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.15172.pdf", "abstract_url": "https://arxiv.org/abs/2509.15172", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出MACA框架，通过多智能体辩论和强化学习提升语言模型的自一致性，显著改善推理和决策性能。", "motivation": "语言模型在推理中存在不一致性，生成矛盾响应，现有方法无法可靠选择一致推理路径。", "method": "使用多智能体共识对齐（MACA），基于多数/少数结果进行强化学习后训练，促进内部共识对齐的推理轨迹。", "result": "在多个基准测试中，自一致性、单智能体推理、采样推理和多智能体决策性能大幅提升，泛化能力强。", "conclusion": "MACA实现稳健自对齐，可靠释放语言模型的潜在推理能力，无需外部监督。"}}
{"id": "2509.14284", "title": "The Sum Leaks More Than Its Parts: Compositional Privacy Risks and Mitigations in Multi-Agent Collaboration", "authors": ["Vaidehi Patil", "Elias Stengel-Eskin", "Mohit Bansal"], "abstract": "As large language models (LLMs) become integral to multi-agent systems, new privacy risks emerge that extend beyond memorization, direct inference, or single-turn evaluations. In particular, seemingly innocuous responses, when composed across interactions, can cumulatively enable adversaries to recover sensitive information, a phenomenon we term compositional privacy leakage. We present the first systematic study of such compositional privacy leaks and possible mitigation methods in multi-agent LLM systems. First, we develop a framework that models how auxiliary knowledge and agent interactions jointly amplify privacy risks, even when each response is benign in isolation. Next, to mitigate this, we propose and evaluate two defense strategies: (1) Theory-of-Mind defense (ToM), where defender agents infer a questioner's intent by anticipating how their outputs may be exploited by adversaries, and (2) Collaborative Consensus Defense (CoDef), where responder agents collaborate with peers who vote based on a shared aggregated state to restrict sensitive information spread. Crucially, we balance our evaluation across compositions that expose sensitive information and compositions that yield benign inferences. Our experiments quantify how these defense strategies differ in balancing the privacy-utility trade-off. We find that while chain-of-thought alone offers limited protection to leakage (~39% sensitive blocking rate), our ToM defense substantially improves sensitive query blocking (up to 97%) but can reduce benign task success. CoDef achieves the best balance, yielding the highest Balanced Outcome (79.8%), highlighting the benefit of combining explicit reasoning with defender collaboration. Together, our results expose a new class of risks in collaborative LLM deployments and provide actionable insights for designing safeguards against compositional, context-driven privacy leakage.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2509.14284.pdf", "abstract_url": "https://arxiv.org/abs/2509.14284", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文系统研究了多智能体LLM系统中的组合隐私泄露问题，提出了两种防御策略（ToM和CoDef），并评估了它们在隐私-效用权衡中的表现。", "motivation": "解决多智能体系统中LLM的隐私风险，特别是看似无害的响应在组合交互中累积导致敏感信息泄露的问题。", "method": "开发了一个框架建模辅助知识和智能体交互如何放大风险，并提出并评估了Theory-of-Mind防御和Collaborative Consensus防御策略。", "result": "ToM防御显著提高敏感查询阻止率（高达97%），但降低良性任务成功率；CoDef实现最佳平衡，平衡结果达79.8%。", "conclusion": "研究揭示了协作LLM部署中的新风险，并提供了可操作的防护设计见解，强调结合显式推理和防御者协作的重要性。"}}
{"id": "2509.14265", "title": "Evolution of Kernels: Automated RISC-V Kernel Optimization with Large Language Models", "authors": ["Siyuan Chen", "Zhichao Lu", "Qingfu Zhang"], "abstract": "Automated kernel design is critical for overcoming software ecosystem barriers in emerging hardware platforms like RISC-V. While large language models (LLMs) have shown promise for automated kernel optimization, demonstrating success in CUDA domains with comprehensive technical documents and mature codebases, their effectiveness remains unproven for reference-scarce domains like RISC-V. We present Evolution of Kernels (EoK), a novel LLM-based evolutionary program search framework that automates kernel design for domains with limited reference material. EoK mitigates reference scarcity by mining and formalizing reusable optimization ideas (general design principles + actionable thoughts) from established kernel libraries' development histories; it then guides parallel LLM explorations using these ideas, enriched via Retrieval-Augmented Generation (RAG) with RISC-V-specific context, prioritizing historically effective techniques. Empirically, EoK achieves a median 1.27x speedup, surpassing human experts on all 80 evaluated kernel design tasks and improving upon prior LLM-based automated kernel design methods by 20%. These results underscore the viability of incorporating human experience into emerging domains and highlight the immense potential of LLM-based automated kernel optimization.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": "Technical report", "pdf_url": "https://arxiv.org/pdf/2509.14265.pdf", "abstract_url": "https://arxiv.org/abs/2509.14265", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "EoK是一个基于大型语言模型的进化程序搜索框架，通过挖掘和形式化优化思想，自动化RISC-V内核设计，在80个任务中实现中位1.27倍加速，超越人类专家和先前方法。", "motivation": "解决RISC-V等新兴硬件平台中参考材料稀缺导致的自动内核设计难题。", "method": "使用LLM-based进化搜索框架，结合RAG技术，从现有内核库开发历史中提取和重用优化思想。", "result": "在评估任务中实现中位1.27倍速度提升，优于人类专家和先前LLM方法20%。", "conclusion": "EoK证明了在参考稀缺领域整合人类经验的可行性，突显LLM在自动内核优化中的巨大潜力。"}}
{"id": "2509.14276", "title": "Constructive Conflict-Driven Multi-Agent Reinforcement Learning for Strategic Diversity", "authors": ["Yuxiang Mai", "Qiyue Yin", "Wancheng Ni", "Pei Xu", "Kaiqi Huang"], "abstract": "In recent years, diversity has emerged as a useful mechanism to enhance the efficiency of multi-agent reinforcement learning (MARL). However, existing methods predominantly focus on designing policies based on individual agent characteristics, often neglecting the interplay and mutual influence among agents during policy formation. To address this gap, we propose Competitive Diversity through Constructive Conflict (CoDiCon), a novel approach that incorporates competitive incentives into cooperative scenarios to encourage policy exchange and foster strategic diversity among agents. Drawing inspiration from sociological research, which highlights the benefits of moderate competition and constructive conflict in group decision-making, we design an intrinsic reward mechanism using ranking features to introduce competitive motivations. A centralized intrinsic reward module generates and distributes varying reward values to agents, ensuring an effective balance between competition and cooperation. By optimizing the parameterized centralized reward module to maximize environmental rewards, we reformulate the constrained bilevel optimization problem to align with the original task objectives. We evaluate our algorithm against state-of-the-art methods in the SMAC and GRF environments. Experimental results demonstrate that CoDiCon achieves superior performance, with competitive intrinsic rewards effectively promoting diverse and adaptive strategies among cooperative agents.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": "Accepted by IJCAI 2025", "pdf_url": "https://arxiv.org/pdf/2509.14276.pdf", "abstract_url": "https://arxiv.org/abs/2509.14276", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出CoDiCon方法，通过引入竞争性内在奖励机制，在合作多智能体强化学习中促进策略多样性和性能提升。", "motivation": "解决现有方法忽视智能体间相互影响、缺乏策略多样性的问题。", "method": "设计基于排名特征的内在奖励模块，平衡竞争与合作，通过双层优化问题对齐任务目标。", "result": "在SMAC和GRF环境中，CoDiCon优于现有方法，有效促进多样和自适应策略。", "conclusion": "竞争性内在奖励能增强多智能体强化学习的效率和适应性。"}}
{"id": "2509.14279", "title": "Towards Robust Agentic CUDA Kernel Benchmarking, Verification, and Optimization", "authors": ["Robert Tjarko Lange", "Qi Sun", "Aaditya Prasad", "Maxence Faldor", "Yujin Tang", "David Ha"], "abstract": "Recent advances in large language models (LLMs) demonstrate their effectiveness in scaling test-time compute for software engineering tasks. However, these approaches often focus on high-level solutions, with limited attention to optimizing low-level CUDA kernel implementations. Additionally, existing kernel generation benchmarks suffer from exploitable loopholes and insufficient diversity in testing conditions, hindering true generalization assessment. To address these limitations, we introduce robust-kbench, a new benchmark for rigorous evaluation of kernel performance and correctness across varied scenarios. Furthermore, we present a comprehensive agentic framework that automates CUDA kernel discovery, verification, and optimization. This pipeline enables frontier LLMs to translate torch code to CUDA kernels and iteratively improve their runtime within our robust evaluation setting. Our sequential workflow first translates PyTorch code into equivalent CUDA kernels. It then optimizes their runtime using a novel evolutionary meta-generation procedure tailored to the CUDA ecosystem, guided by LLM-based verifiers for correctness and efficient filtering. Evaluated on robust-kbench, our approach produces CUDA kernels outperforming torch implementations for practical applications, including forward and backward passes. It can fuse operations and deploy various runtime optimization strategies. The verifier workflow accurately classifies incorrect kernels, enhancing hardware verification efficiency.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "62 pages, 10 figures", "pdf_url": "https://arxiv.org/pdf/2509.14279.pdf", "abstract_url": "https://arxiv.org/abs/2509.14279", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了robust-kbench基准和自动化框架，用于CUDA内核的评估、验证和优化，利用LLM提升性能和正确性。", "motivation": "解决LLM在软件工程中优化低层CUDA内核的不足，以及现有基准的漏洞和多样性不足问题。", "method": "使用robust-kbench基准和自动化框架，包括PyTorch到CUDA的翻译、进化元生成优化和基于LLM的验证器。", "result": "在robust-kbench上评估，生成的CUDA内核性能优于torch实现，能融合操作和优化策略，验证器准确分类错误内核。", "conclusion": "该方法提高了CUDA内核的泛化评估和优化效率，对实际应用有积极影响。"}}
{"id": "2509.14860", "title": "MARIC: Multi-Agent Reasoning for Image Classification", "authors": ["Wonduk Seo", "Minhyeong Yu", "Hyunjin An", "Seunghyun Lee"], "abstract": "Image classification has traditionally relied on parameter-intensive model training, requiring large-scale annotated datasets and extensive fine tuning to achieve competitive performance. While recent vision language models (VLMs) alleviate some of these constraints, they remain limited by their reliance on single pass representations, often failing to capture complementary aspects of visual content. In this paper, we introduce Multi Agent based Reasoning for Image Classification (MARIC), a multi agent framework that reformulates image classification as a collaborative reasoning process. MARIC first utilizes an Outliner Agent to analyze the global theme of the image and generate targeted prompts. Based on these prompts, three Aspect Agents extract fine grained descriptions along distinct visual dimensions. Finally, a Reasoning Agent synthesizes these complementary outputs through integrated reflection step, producing a unified representation for classification. By explicitly decomposing the task into multiple perspectives and encouraging reflective synthesis, MARIC mitigates the shortcomings of both parameter-heavy training and monolithic VLM reasoning. Experiments on 4 diverse image classification benchmark datasets demonstrate that MARIC significantly outperforms baselines, highlighting the effectiveness of multi-agent visual reasoning for robust and interpretable image classification.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Multiagent Systems (cs.MA)", "comments": "Preprint", "pdf_url": "https://arxiv.org/pdf/2509.14860.pdf", "abstract_url": "https://arxiv.org/abs/2509.14860", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "MARIC 是一个多智能体框架，通过协作推理进行图像分类，优于基线方法。", "motivation": "解决传统图像分类方法依赖大量参数训练和单次表示的问题，提高鲁棒性和可解释性。", "method": "使用 Outliner Agent 分析全局主题并生成提示，三个 Aspect Agents 提取细粒度描述，Reasoning Agent 合成输出进行分类。", "result": "在四个基准数据集上显著优于基线，验证了多智能体视觉推理的有效性。", "conclusion": "MARIC 通过多视角分解和反思合成，缓解了参数密集训练和单一 VLM 推理的局限性，适用于鲁棒和可解释的图像分类。"}}
{"id": "2509.14627", "title": "Towards Human-like Multimodal Conversational Agent by Generating Engaging Speech", "authors": ["Taesoo Kim", "Yongsik Jo", "Hyunmin Song", "Taehwan Kim"], "abstract": "Human conversation involves language, speech, and visual cues, with each medium providing complementary information. For instance, speech conveys a vibe or tone not fully captured by text alone. While multimodal LLMs focus on generating text responses from diverse inputs, less attention has been paid to generating natural and engaging speech. We propose a human-like agent that generates speech responses based on conversation mood and responsive style information. To achieve this, we build a novel MultiSensory Conversation dataset focused on speech to enable agents to generate natural speech. We then propose a multimodal LLM-based model for generating text responses and voice descriptions, which are used to generate speech covering paralinguistic information. Experimental results demonstrate the effectiveness of utilizing both visual and audio modalities in conversation to generate engaging speech. The source code is available in", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "Published in Interspeech 2025", "pdf_url": "https://arxiv.org/pdf/2509.14627.pdf", "abstract_url": "https://arxiv.org/abs/2509.14627", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于多模态LLM的对话代理，通过生成自然且吸引人的语音来模拟人类对话，结合视觉和音频模态提升语音生成效果。", "motivation": "解决多模态LLMs在生成自然和吸引人语音方面的不足，因为当前研究多关注文本响应，忽略了语音在传达语调和氛围中的重要性。", "method": "构建MultiSensory Conversation数据集，并开发一个多模态LLM模型，用于生成文本响应和语音描述，进而合成包含副语言信息的语音。", "result": "实验结果表明，结合视觉和音频模态能有效生成更吸引人的语音，验证了方法的有效性。", "conclusion": "该方法推动了人机对话的自然化，强调了多模态信息在语音生成中的关键作用，未来可扩展至更广泛的对话系统。"}}
{"id": "2509.15159", "title": "AIP: Subverting Retrieval-Augmented Generation via Adversarial Instructional Prompt", "authors": ["Saket S. Chaturvedi", "Gaurav Bagwe", "Lan Zhang", "Xiaoyong Yuan"], "abstract": "Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by retrieving relevant documents from external sources to improve factual accuracy and verifiability. However, this reliance introduces new attack surfaces within the retrieval pipeline, beyond the LLM itself. While prior RAG attacks have exposed such vulnerabilities, they largely rely on manipulating user queries, which is often infeasible in practice due to fixed or protected user inputs. This narrow focus overlooks a more realistic and stealthy vector: instructional prompts, which are widely reused, publicly shared, and rarely audited. Their implicit trust makes them a compelling target for adversaries to manipulate RAG behavior covertly.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL)", "comments": "Accepted at EMNLP 2025 Conference", "pdf_url": "https://arxiv.org/pdf/2509.15159.pdf", "abstract_url": "https://arxiv.org/abs/2509.15159", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "论文探讨了通过对抗性指令提示颠覆检索增强生成的攻击方法，强调指令提示的脆弱性。", "motivation": "解决检索增强生成（RAG）中因依赖外部检索而引入的新攻击面，特别是用户查询固定或受保护时，指令提示被忽略的漏洞。", "method": "利用广泛重用且很少审计的指令提示作为攻击向量，通过对抗性操纵来隐秘影响RAG行为。", "result": "揭示了指令提示的潜在风险，表明攻击者可以绕过传统防护，实现隐蔽的RAG操纵。", "conclusion": "指令提示的隐式信任使其成为现实攻击目标，呼吁加强审计和安全措施以保护RAG系统。"}}
{"id": "2509.14436", "title": "When Content is Goliath and Algorithm is David: The Style and Semantic Effects of Generative Search Engine", "authors": ["Lijia Ma", "Juan Qin", "Xingchen Xu", "Yong Tan"], "abstract": "Generative search engines (GEs) leverage large language models (LLMs) to deliver AI-generated summaries with website citations, establishing novel traffic acquisition channels while fundamentally altering the search engine optimization landscape. To investigate the distinctive characteristics of GEs, we collect data through interactions with Google's generative and conventional search platforms, compiling a dataset of approximately ten thousand websites across both channels. Our empirical analysis reveals that GEs exhibit preferences for citing content characterized by significantly higher predictability for underlying LLMs and greater semantic similarity among selected sources. Through controlled experiments utilizing retrieval augmented generation (RAG) APIs, we demonstrate that these citation preferences emerge from intrinsic LLM tendencies to favor content aligned with their generative expression patterns. Motivated by applications of LLMs to optimize website content, we conduct additional experimentation to explore how LLM-based content polishing by website proprietors alters AI summaries, finding that such polishing paradoxically enhances information diversity within AI summaries. Finally, to assess the user-end impact of LLM-induced information increases, we design a generative search engine and recruit Prolific participants to conduct a randomized controlled experiment involving an information-seeking and writing task. We find that higher-educated users exhibit minimal changes in their final outputs' information diversity but demonstrate significantly reduced task completion time when original sites undergo polishing. Conversely, lower-educated users primarily benefit through enhanced information density in their task outputs while maintaining similar completion times across experimental groups.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "comments": "59 pages, 6 figures, 20 tables", "pdf_url": "https://arxiv.org/pdf/2509.14436.pdf", "abstract_url": "https://arxiv.org/abs/2509.14436", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "生成式搜索引擎偏好可预测和语义相似的内容，LLM优化增强信息多样性，对不同教育水平用户影响各异。", "motivation": "研究生成式搜索引擎如何改变搜索优化和用户信息获取，探索LLM偏好对内容引用的影响。", "method": "收集数据、实证分析、RAG实验、LLM内容优化测试、用户随机对照实验。", "result": "GEs偏好LLM可预测内容，优化增加信息多样性，高教育用户节省时间，低教育用户提升信息密度。", "conclusion": "LLM驱动搜索需关注公平性，优化策略可改善用户体验但可能加剧信息不平等。"}}
{"id": "2509.15160", "title": "An Evaluation-Centric Paradigm for Scientific Visualization Agents", "authors": ["Kuangshi Ai", "Haichao Miao", "Zhimin Li", "Chaoli Wang", "Shusen Liu"], "abstract": "Recent advances in multi-modal large language models (MLLMs) have enabled increasingly sophisticated autonomous visualization agents capable of translating user intentions into data visualizations. However, measuring progress and comparing different agents remains challenging, particularly in scientific visualization (SciVis), due to the absence of comprehensive, large-scale benchmarks for evaluating real-world capabilities. This position paper examines the various types of evaluation required for SciVis agents, outlines the associated challenges, provides a simple proof-of-concept evaluation example, and discusses how evaluation benchmarks can facilitate agent self-improvement. We advocate for a broader collaboration to develop a SciVis agentic evaluation benchmark that would not only assess existing capabilities but also drive innovation and stimulate future development in the field.", "subjects": "Human-Computer Interaction (cs.HC); Computation and Language (cs.CL); Graphics (cs.GR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.15160.pdf", "abstract_url": "https://arxiv.org/abs/2509.15160", "categories": ["Human-Computer Interaction (cs.HC)", "Computation and Language (cs.CL)", "Graphics (cs.GR)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种以评估为中心的范式，用于科学可视化代理，强调开发大规模基准测试以衡量和比较代理能力，促进自我改进和创新。", "motivation": "多模态大语言模型（MLLMs）使自主可视化代理能够将用户意图转化为数据可视化，但由于缺乏全面的大规模基准测试，衡量进展和比较不同代理在科学可视化（SciVis）中具有挑战性。", "method": "本文作为立场论文，审查了所需的评估类型，概述了相关挑战，提供了一个简单的概念验证评估示例，并讨论了评估基准如何促进代理自我改进。", "result": "通过概念验证示例，展示了评估基准的可行性，并强调了其在推动领域创新和发展中的潜力。", "conclusion": "倡导更广泛的合作开发SciVis代理评估基准，以评估现有能力并驱动未来发展和创新。"}}
{"id": "2509.14537", "title": "ClearFairy: Capturing Creative Workflows through Decision Structuring, In-Situ Questioning, and Rationale Inference", "authors": ["Kihoon Son", "DaEun Choi", "Tae Soo Kim", "Young-Ho Kim", "Sangdoo Yun", "Juho Kim"], "abstract": "Capturing professionals' decision-making in creative workflows is essential for reflection, collaboration, and knowledge sharing, yet existing methods often leave rationales incomplete and implicit decisions hidden. To address this, we present CLEAR framework that structures reasoning into cognitive decision steps-linked units of actions, artifacts, and self-explanations that make decisions traceable. Building on this framework, we introduce ClearFairy, a think-aloud AI assistant for UI design that detects weak explanations, asks lightweight clarifying questions, and infers missing rationales to ease the knowledge-sharing burden. In a study with twelve creative professionals, 85% of ClearFairy's inferred rationales were accepted, increasing strong explanations from 14% to over 83% of decision steps without adding cognitive demand. The captured steps also enhanced generative AI agents in Figma, yielding next-action predictions better aligned with professionals and producing more coherent design outcomes. For future research on human knowledge-grounded creative AI agents, we release a dataset of captured 417 decision steps.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14537.pdf", "abstract_url": "https://arxiv.org/abs/2509.14537", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "ClearFairy是一个AI助手，通过结构化决策步骤、现场提问和推理缺失理由，捕获创意工作流中的决策过程，提高知识共享和AI代理性能。", "motivation": "解决创意工作流中决策捕获不完整和隐含决策的问题，以支持反思、协作和知识共享。", "method": "使用CLEAR框架结构化推理步骤，结合AI助手检测弱解释、提问和推理缺失理由。", "result": "在12名专业人士研究中，85%的推理理由被接受，强解释比例从14%提升至83%以上，且AI代理预测更准确、设计结果更连贯。", "conclusion": "ClearFairy有效捕获决策，减轻知识共享负担，并发布数据集支持未来创意AI研究。"}}
{"id": "2509.15219", "title": "Out-of-Sight Trajectories: Tracking, Fusion, and Prediction", "authors": ["Haichao Zhang", "Yi Xu", "Yun Fu"], "abstract": "Trajectory prediction is a critical task in computer vision and autonomous systems, playing a key role in autonomous driving, robotics, surveillance, and virtual reality. Existing methods often rely on complete and noise-free observational data, overlooking the challenges associated with out-of-sight objects and the inherent noise in sensor data caused by limited camera coverage, obstructions, and the absence of ground truth for denoised trajectories. These limitations pose safety risks and hinder reliable prediction in real-world scenarios. In this extended work, we present advancements in Out-of-Sight Trajectory (OST), a novel task that predicts the noise-free visual trajectories of out-of-sight objects using noisy sensor data. Building on our previous research, we broaden the scope of Out-of-Sight Trajectory Prediction (OOSTraj) to include pedestrians and vehicles, extending its applicability to autonomous driving, robotics, surveillance, and virtual reality. Our enhanced Vision-Positioning Denoising Module leverages camera calibration to establish a vision-positioning mapping, addressing the lack of visual references, while effectively denoising noisy sensor data in an unsupervised manner. Through extensive evaluations on the Vi-Fi and JRDB datasets, our approach achieves state-of-the-art performance in both trajectory denoising and prediction, significantly surpassing previous baselines. Additionally, we introduce comparisons with traditional denoising methods, such as Kalman filtering, and adapt recent trajectory prediction models to our task, providing a comprehensive benchmark. This work represents the first initiative to integrate vision-positioning projection for denoising noisy sensor trajectories of out-of-sight agents, paving the way for future advances. The code and preprocessed datasets are available at", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Multiagent Systems (cs.MA); Multimedia (cs.MM); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.15219.pdf", "abstract_url": "https://arxiv.org/abs/2509.15219", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)", "Multimedia (cs.MM)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了Out-of-Sight Trajectory (OST)任务，通过视觉-定位去噪模块，在无监督方式下使用噪声传感器数据预测视野外物体的无噪声轨迹，在多个数据集上实现最先进性能。", "motivation": "解决现有轨迹预测方法依赖完整无噪声观测数据的问题，应对视野外物体和传感器噪声带来的安全风险和可靠性挑战。", "method": "扩展Out-of-Sight Trajectory Prediction (OOSTraj)范围，利用相机校准建立视觉-定位映射，开发增强的视觉-定位去噪模块进行无监督去噪。", "result": "在Vi-Fi和JRDB数据集上，轨迹去噪和预测性能显著超越先前基线，与卡尔曼滤波等传统方法相比表现优越。", "conclusion": "首次整合视觉-定位投影用于去噪视野外代理的噪声传感器轨迹，为未来进展铺平道路，代码和数据集已公开。"}}
{"id": "2509.15221", "title": "ScaleCUA: Scaling Open-Source Computer Use Agents with Cross-Platform Data", "authors": ["Zhaoyang Liu", "JingJing Xie", "Zichen Ding", "Zehao Li", "Bowen Yang", "Zhenyu Wu", "Xuehui Wang", "Qiushi Sun", "Shi Liu", "Weiyun Wang", "Shenglong Ye", "Qingyun Li", "Zeyue Tian", "Gen Luo", "Xiangyu Yue", "Biqing Qi", "Kai Chen", "Bowen Zhou", "Yu Qiao", "Qifeng Chen", "Wenhai Wang"], "abstract": "Vision-Language Models (VLMs) have enabled computer use agents (CUAs) that operate GUIs autonomously, showing great potential, yet progress is limited by the lack of large-scale, open-source computer use data and foundation models. In this work, we introduce ScaleCUA, a step toward scaling open-source CUAs. It offers a large-scale dataset spanning 6 operating systems and 3 task domains, built via a closed-loop pipeline uniting automated agents with human experts. Trained on this scaled-up data, ScaleCUA can operate seamlessly across platforms. Specifically, it delivers strong gains over baselines (+26.6 on WebArena-Lite-v2, +10.7 on ScreenSpot-Pro) and sets new state-of-the-art results (94.4% on MMBench-GUI L1-Hard, 60.6% on OSWorld-G, 47.4% on WebArena-Lite-v2). These findings underscore the power of data-driven scaling for general-purpose computer use agents. We will release data, models, and code to advance future research:", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.15221.pdf", "abstract_url": "https://arxiv.org/abs/2509.15221", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "ScaleCUA 是一个通过大规模跨平台数据集和训练提升开源计算机使用代理性能的项目，在多个基准测试中取得显著改进。", "motivation": "解决计算机使用代理因缺乏大规模开源数据和基础模型而进展受限的问题。", "method": "使用跨6个操作系统和3个任务域的大规模数据集，通过自动化代理与人类专家结合的闭环管道构建，并基于此数据训练模型。", "result": "在基准测试中表现优异，如WebArena-Lite-v2提升26.6分，ScreenSpot-Pro提升10.7分，并在多个测试中创下新纪录。", "conclusion": "数据驱动的扩展对通用计算机使用代理具有强大潜力，将发布数据、模型和代码以推动未来研究。"}}
{"id": "2509.14608", "title": "Enterprise AI Must Enforce Participant-Aware Access Control", "authors": ["Shashank Shreedhar Bhatt", "Tanmay Rajore", "Khushboo Aggarwal", "Ganesh Ananthanarayanan", "Ranveer Chandra", "Nishanth Chandran", "Suyash Choudhury", "Divya Gupta", "Emre Kiciman", "Sumit Kumar Pandey", "Srinath Setty", "Rahul Sharma", "Teijia Zhao"], "abstract": "Large language models (LLMs) are increasingly deployed in enterprise settings where they interact with multiple users and are trained or fine-tuned on sensitive internal data. While fine-tuning enhances performance by internalizing domain knowledge, it also introduces a critical security risk: leakage of confidential training data to unauthorized users. These risks are exacerbated when LLMs are combined with Retrieval-Augmented Generation (RAG) pipelines that dynamically fetch contextual documents at inference time.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14608.pdf", "abstract_url": "https://arxiv.org/abs/2509.14608", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "企业AI需实施参与者感知访问控制，以防止LLM在微调和RAG中泄露敏感数据。", "motivation": "解决企业环境中LLM部署时，微调和RAG可能导致的机密训练数据泄露给未授权用户的安全风险。", "method": "提出参与者感知访问控制方法，以增强安全性和控制数据访问。", "result": "强调了风险的存在，并建议了控制措施的必要性。", "conclusion": "企业必须采用访问控制机制来保护敏感数据，确保AI系统的安全部署。"}}
{"id": "2509.14622", "title": "Adversarial Distilled Retrieval-Augmented Guarding Model for Online Malicious Intent Detection", "authors": ["Yihao Guo", "Haocheng Bian", "Liutong Zhou", "Ze Wang", "Zhaoyi Zhang", "Francois Kawala", "Milan Dean", "Ian Fischer", "Yuantao Peng", "Noyan Tokgozoglu", "Ivan Barrientos", "Riyaaz Shaik", "Rachel Li", "Chandru Venkataraman", "Reza Shifteh Far", "Moses Pawar", "Venkat Sundaranatha", "Michael Xu", "Frank Chu"], "abstract": "With the deployment of Large Language Models (LLMs) in interactive applications, online malicious intent detection has become increasingly critical. However, existing approaches fall short of handling diverse and complex user queries in real time. To address these challenges, we introduce ADRAG (Adversarial Distilled Retrieval-Augmented Guard), a two-stage framework for robust and efficient online malicious intent detection. In the training stage, a high-capacity teacher model is trained on adversarially perturbed, retrieval-augmented inputs to learn robust decision boundaries over diverse and complex user queries. In the inference stage, a distillation scheduler transfers the teacher's knowledge into a compact student model, with a continually updated knowledge base collected online. At deployment, the compact student model leverages top-K similar safety exemplars retrieved from the online-updated knowledge base to enable both online and real-time malicious query detection. Evaluations across ten safety benchmarks demonstrate that ADRAG, with a 149M-parameter model, achieves 98.5% of WildGuard-7B's performance, surpasses GPT-4 by 3.3% and Llama-Guard-3-8B by 9.5% on out-of-distribution detection, while simultaneously delivering up to 5.6x lower latency at 300 queries per second (QPS) in real-time applications.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14622.pdf", "abstract_url": "https://arxiv.org/abs/2509.14622", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "提出ADRAG框架，通过对抗蒸馏和检索增强实现高效实时的在线恶意意图检测，性能优于现有模型且延迟更低。", "motivation": "解决大型语言模型部署中现有方法无法实时处理多样复杂用户查询的问题。", "method": "使用两阶段框架：训练阶段用对抗扰动和检索增强的输入训练教师模型，推理阶段通过蒸馏调度器将知识转移到紧凑学生模型，并利用在线更新的知识库进行检索。", "result": "在十个安全基准测试中，ADRAG以149M参数达到WildGuard-7B性能的98.5%，在分布外检测上超越GPT-4 3.3%和Llama-Guard-3-8B 9.5%，实时应用中延迟降低5.6倍。", "conclusion": "ADRAG提供了一种鲁棒且高效的在线恶意意图检测方法，适用于实时应用，具有显著性能提升和低延迟优势。"}}
{"id": "2509.15076", "title": "Forecasting and Visualizing Air Quality from Sky Images with Vision-Language Models", "authors": ["Mohammad Saleh Vahdatpour", "Maryam Eyvazi", "Yanqing Zhang"], "abstract": "Air pollution remains a critical threat to public health and environmental sustainability, yet conventional monitoring systems are often constrained by limited spatial coverage and accessibility. This paper proposes an AI-driven agent that predicts ambient air pollution levels from sky images and synthesizes realistic visualizations of pollution scenarios using generative modeling. Our approach combines statistical texture analysis with supervised learning for pollution classification, and leverages vision-language model (VLM)-guided image generation to produce interpretable representations of air quality conditions. The generated visuals simulate varying degrees of pollution, offering a foundation for user-facing interfaces that improve transparency and support informed environmental decision-making. These outputs can be seamlessly integrated into intelligent applications aimed at enhancing situational awareness and encouraging behavioral responses based on real-time forecasts. We validate our method using a dataset of urban sky images and demonstrate its effectiveness in both pollution level estimation and semantically consistent visual synthesis. The system design further incorporates human-centered user experience principles to ensure accessibility, clarity, and public engagement in air quality forecasting. To support scalable and energy-efficient deployment, future iterations will incorporate a green CNN architecture enhanced with FPGA-based incremental learning, enabling real-time inference on edge platforms.", "subjects": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV)", "comments": "Published at ICCVW 2025", "pdf_url": "https://arxiv.org/pdf/2509.15076.pdf", "abstract_url": "https://arxiv.org/abs/2509.15076", "categories": ["Machine Learning (cs.LG)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文提出了一种基于AI的代理，利用天空图像预测空气质量，并通过生成模型合成可视化污染场景，结合统计纹理分析和监督学习进行分类，以及VLM引导的图像生成，以提高透明度和支持环境决策。", "motivation": "解决传统空气质量监测系统空间覆盖有限和可访问性不足的问题，以改善公共健康和环境可持续性。", "method": "结合统计纹理分析和监督学习进行污染分类，并利用视觉语言模型（VLM）引导生成图像，以合成可解释的空气质量可视化。", "result": "验证了方法在城市天空图像数据集上的有效性，在污染水平估计和语义一致的视觉合成方面表现出色。", "conclusion": "系统设计融合了以人为中心的用户体验原则，未来将集成绿色CNN架构和FPGA增量学习，实现实时边缘平台部署，增强可扩展性和能效。"}}
{"id": "2509.14803", "title": "OnlineMate: An LLM-Based Multi-Agent Companion System for Cognitive Support in Online Learning", "authors": ["Xian Gao", "Zongyun Zhang", "Ting Liu", "Yuzhuo Fu"], "abstract": "In online learning environments, students often lack personalized peer interactions, which play a crucial role in supporting cognitive development and learning engagement. Although previous studies have utilized large language models (LLMs) to simulate interactive dynamic learning environments for students, these interactions remain limited to conversational exchanges, lacking insights and adaptations to the learners' individualized learning and cognitive states. As a result, students' interest in discussions with AI learning companions is low, and they struggle to gain inspiration from such interactions. To address this challenge, we propose OnlineMate, a multi-agent learning companion system driven by LLMs that integrates the Theory of Mind (ToM). OnlineMate is capable of simulating peer-like agent roles, adapting to learners' cognitive states during collaborative discussions, and inferring their psychological states, such as misunderstandings, confusion, or motivation. By incorporating Theory of Mind capabilities, the system can dynamically adjust its interaction strategies to support the development of higher-order thinking and cognition. Experimental results in simulated learning scenarios demonstrate that OnlineMate effectively fosters deep learning and discussions while enhancing cognitive engagement in online educational settings.", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14803.pdf", "abstract_url": "https://arxiv.org/abs/2509.14803", "categories": ["Computers and Society (cs.CY)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "OnlineMate是一个基于LLM的多智能体学习伴侣系统，通过整合心理理论，模拟同伴角色并适应学习者认知状态，以提升在线学习中的认知支持和参与度。", "motivation": "解决在线学习中学生缺乏个性化同伴互动的问题，现有AI学习伴侣仅限于对话，无法适应个体学习状态，导致学生兴趣低和难以获得启发。", "method": "使用大型语言模型驱动的多智能体系统，整合心理理论，模拟同伴角色，动态调整互动策略以适应学习者的认知和心理状态。", "result": "实验结果显示，在模拟学习场景中，OnlineMate有效促进了深度学习和讨论，并增强了认知参与度。", "conclusion": "该系统通过心理理论整合，能动态支持高阶思维发展，改善在线教育环境中的学习体验和认知发展。"}}
{"id": "2509.14877", "title": "AI-Driven Multi-Agent Vehicular Planning for Battery Efficiency and QoS in 6G Smart Cities", "authors": ["Rohin Gillgallon", "Giacomo Bergami", "Reham Almutairi", "Graham Morgan"], "abstract": "While simulators exist for vehicular IoT nodes communicating with the Cloud through Edge nodes in a fully-simulated osmotic architecture, they often lack support for dynamic agent planning and optimisation to minimise vehicular battery consumption while ensuring fair communication times. Addressing these challenges requires extending current simulator architectures with AI algorithms for both traffic prediction and dynamic agent planning. This paper presents an extension of SimulatorOrchestrator (SO) to meet these requirements. Preliminary results over a realistic urban dataset show that utilising vehicular planning algorithms can lead to improved battery and QoS performance compared with traditional shortest path algorithms. The additional inclusion of desirability areas enabled more ambulances to be routed to their target destinations while utilising less energy to do so, compared to traditional and weighted algorithms without desirability considerations.", "subjects": "Networking and Internet Architecture (cs.NI); Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET)", "comments": "16 pages, 2 figures, 2 tables, 2 algorithms", "pdf_url": "https://arxiv.org/pdf/2509.14877.pdf", "abstract_url": "https://arxiv.org/abs/2509.14877", "categories": ["Networking and Internet Architecture (cs.NI)", "Artificial Intelligence (cs.AI)", "Emerging Technologies (cs.ET)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文扩展了SimulatorOrchestrator模拟器，集成AI算法进行多智能体车辆规划，以在6G智慧城市中优化电池效率和QoS。初步结果显示，相比传统最短路径算法，该方法能改善电池和QoS性能，并通过引入期望区域提高救护车路由效率。", "motivation": "解决现有车辆IoT模拟器缺乏动态智能体规划和优化的问题，以最小化车辆电池消耗并确保公平通信时间。", "method": "扩展SimulatorOrchestrator模拟器，集成AI算法进行交通预测和动态智能体规划，包括期望区域概念。", "result": "在真实城市数据集上，车辆规划算法比传统最短路径算法在电池和QoS性能上表现更好，期望区域使救护车路由更高效且能耗更低。", "conclusion": "AI驱动的多智能体规划能有效提升车辆网络性能，为6G智慧城市应用提供优化方案。"}}
{"id": "2509.15042", "title": "Reinforcement Learning Agent for a 2D Shooter Game", "authors": ["Thomas Ackermann", "Moritz Spang", "Hamza A. A. Gardi"], "abstract": "Reinforcement learning agents in complex game environments often suffer from sparse rewards, training instability, and poor sample efficiency. This paper presents a hybrid training approach that combines offline imitation learning with online reinforcement learning for a 2D shooter game agent. We implement a multi-head neural network with separate outputs for behavioral cloning and Q-learning, unified by shared feature extraction layers with attention mechanisms. Initial experiments using pure deep Q-Networks exhibited significant instability, with agents frequently reverting to poor policies despite occasional good performance. To address this, we developed a hybrid methodology that begins with behavioral cloning on demonstration data from rule-based agents, then transitions to reinforcement learning. Our hybrid approach achieves consistently above 70% win rate against rule-based opponents, substantially outperforming pure reinforcement learning methods which showed high variance and frequent performance degradation. The multi-head architecture enables effective knowledge transfer between learning modes while maintaining training stability. Results demonstrate that combining demonstration-based initialization with reinforcement learning optimization provides a robust solution for developing game AI agents in complex multi-agent environments where pure exploration proves insufficient.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.15042.pdf", "abstract_url": "https://arxiv.org/abs/2509.15042", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种结合离线模仿学习和在线强化学习的混合训练方法，用于2D射击游戏AI代理，通过多头部神经网络和注意力机制，提高了训练稳定性和胜率。", "motivation": "解决强化学习在复杂游戏环境中因稀疏奖励、训练不稳定和样本效率低导致的问题。", "method": "使用多头部神经网络，结合行为克隆和Q学习，共享特征提取层和注意力机制，从演示数据初始化后过渡到强化学习。", "result": "混合方法在对抗基于规则的对手时达到70%以上的胜率，显著优于纯强化学习方法，后者表现出高方差和性能退化。", "conclusion": "结合演示初始化和强化学习优化为复杂多智能体环境中的游戏AI开发提供了鲁棒解决方案。"}}
{"id": "2509.15032", "title": "Sample Efficient Experience Replay in Non-stationary Environments", "authors": ["Tianyang Duan", "Zongyuan Zhang", "Songxiao Guo", "Yuanye Zhao", "Zheng Lin", "Zihan Fang", "Yi Liu", "Dianxin Luan", "Dong Huang", "Heming Cui", "Yong Cui"], "abstract": "Reinforcement learning (RL) in non-stationary environments is challenging, as changing dynamics and rewards quickly make past experiences outdated. Traditional experience replay (ER) methods, especially those using TD-error prioritization, struggle to distinguish between changes caused by the agent's policy and those from the environment, resulting in inefficient learning under dynamic conditions. To address this challenge, we propose the Discrepancy of Environment Dynamics (DoE), a metric that isolates the effects of environment shifts on value functions. Building on this, we introduce Discrepancy of Environment Prioritized Experience Replay (DEER), an adaptive ER framework that prioritizes transitions based on both policy updates and environmental changes. DEER uses a binary classifier to detect environment changes and applies distinct prioritization strategies before and after each shift, enabling more sample-efficient learning. Experiments on four non-stationary benchmarks demonstrate that DEER further improves the performance of off-policy algorithms by 11.54 percent compared to the best-performing state-of-the-art ER methods.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Networking and Internet Architecture (cs.NI)", "comments": "5 pages, 3 figures", "pdf_url": "https://arxiv.org/pdf/2509.15032.pdf", "abstract_url": "https://arxiv.org/abs/2509.15032", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Networking and Internet Architecture (cs.NI)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文提出了一种名为DEER的自适应经验回放框架，通过度量环境动态差异（DoE）来优先处理策略更新和环境变化，在非平稳环境中显著提高了样本效率和强化学习性能。", "motivation": "解决在非平稳环境中强化学习因环境动态和奖励变化导致过去经验快速过时的问题，传统经验回放方法难以区分策略和环境变化的影响，导致学习效率低下。", "method": "引入环境动态差异（DoE）度量，并基于此开发DEER框架，使用二元分类器检测环境变化，并在变化前后应用不同的优先策略来优化经验回放。", "result": "在四个非平稳基准测试中，DEER将离线策略算法的性能比现有最佳经验回放方法提高了11.54%。", "conclusion": "DEER框架有效提升了非平稳环境中的样本效率和强化学习性能，为动态环境下的RL应用提供了实用解决方案。"}}
{"id": "2509.15103", "title": "Vulnerable Agent Identification in Large-Scale Multi-Agent Reinforcement Learning", "authors": ["Simin Li", "Zheng Yuwei", "Zihao Mao", "Linhao Wang", "Ruixiao Xu", "Chengdong Ma", "Xin Yu", "Yuqing Ma", "Qi Dou", "Xin Wang", "Jie Luo", "Bo An", "Yaodong Yang", "Weifeng Lv", "Xianglong Liu"], "abstract": "Partial agent failure becomes inevitable when systems scale up, making it crucial to identify the subset of agents whose compromise would most severely degrade overall performance. In this paper, we study this Vulnerable Agent Identification (VAI) problem in large-scale multi-agent reinforcement learning (MARL). We frame VAI as a Hierarchical Adversarial Decentralized Mean Field Control (HAD-MFC), where the upper level involves an NP-hard combinatorial task of selecting the most vulnerable agents, and the lower level learns worst-case adversarial policies for these agents using mean-field MARL. The two problems are coupled together, making HAD-MFC difficult to solve. To solve this, we first decouple the hierarchical process by Fenchel-Rockafellar transform, resulting a regularized mean-field Bellman operator for upper level that enables independent learning at each level, thus reducing computational complexity. We then reformulate the upper-level combinatorial problem as a MDP with dense rewards from our regularized mean-field Bellman operator, enabling us to sequentially identify the most vulnerable agents by greedy and RL algorithms. This decomposition provably preserves the optimal solution of the original HAD-MFC. Experiments show our method effectively identifies more vulnerable agents in large-scale MARL and the rule-based system, fooling system into worse failures, and learns a value function that reveals the vulnerability of each agent.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": "submitted to NIPS 2025", "pdf_url": "https://arxiv.org/pdf/2509.15103.pdf", "abstract_url": "https://arxiv.org/abs/2509.15103", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文提出了一种分层对抗分散平均场控制（HAD-MFC）方法，用于大规模多智能体强化学习中的脆弱智能体识别问题，通过Fenchel-Rockafellar变换解耦层次过程，并证明其有效性和计算效率。", "motivation": "解决大规模多智能体系统中部分智能体故障不可避免的问题，识别哪些智能体被妥协会最严重地降低整体性能。", "method": "使用HAD-MFC框架，上层通过组合优化选择脆弱智能体，下层使用平均场MARL学习对抗策略；通过Fenchel-Rockafellar变换解耦层次，并重新表述为MDP问题，采用贪婪和RL算法。", "result": "实验表明，该方法能有效识别更多脆弱智能体，诱导系统更严重的故障，并学习到揭示每个智能体脆弱性的价值函数。", "conclusion": "该方法分解了原始HAD-MFC问题，保持最优解，提高了计算效率，适用于大规模MARL和规则基系统，具有实际应用价值。"}}
