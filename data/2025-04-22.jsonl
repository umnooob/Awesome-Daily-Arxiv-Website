{"id": "2504.14011", "title": "Fashion-RAG: Multimodal Fashion Image Editing via Retrieval-Augmented Generation", "authors": ["Fulvio Sanguigni", "Davide Morelli", "Marcella Cornia", "Rita Cucchiara"], "abstract": "In recent years, the fashion industry has increasingly adopted AI technologies to enhance customer experience, driven by the proliferation of e-commerce platforms and virtual applications. Among the various tasks, virtual try-on and multimodal fashion image editing -- which utilizes diverse input modalities such as text, garment sketches, and body poses -- have become a key area of research. Diffusion models have emerged as a leading approach for such generative tasks, offering superior image quality and diversity. However, most existing virtual try-on methods rely on having a specific garment input, which is often impractical in real-world scenarios where users may only provide textual specifications. To address this limitation, in this work we introduce Fashion Retrieval-Augmented Generation (Fashion-RAG), a novel method that enables the customization of fashion items based on user preferences provided in textual form. Our approach retrieves multiple garments that match the input specifications and generates a personalized image by incorporating attributes from the retrieved items. To achieve this, we employ textual inversion techniques, where retrieved garment images are projected into the textual embedding space of the Stable Diffusion text encoder, allowing seamless integration of retrieved elements into the generative process. Experimental results on the Dress Code dataset demonstrate that Fashion-RAG outperforms existing methods both qualitatively and quantitatively, effectively capturing fine-grained visual details from retrieved garments. To the best of our knowledge, this is the first work to introduce a retrieval-augmented generation approach specifically tailored for multimodal fashion image editing.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Multimedia (cs.MM)", "comments": "IJCNN 2025", "pdf_url": "https://arxiv.org/pdf/2504.14011.pdf", "abstract_url": "https://arxiv.org/abs/2504.14011", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Multimedia (cs.MM)"], "matching_keywords": ["@RAG"]}
{"id": "2504.14348", "title": "Manipulating Multimodal Agents via Cross-Modal Prompt Injection", "authors": ["Le Wang", "Zonghao Ying", "Tianyuan Zhang", "Siyuan Liang", "Shengshan Hu", "Mingchuan Zhang", "Aishan Liu", "Xianglong Liu"], "abstract": "The emergence of multimodal large language models has redefined the agent paradigm by integrating language and vision modalities with external data sources, enabling agents to better interpret human instructions and execute increasingly complex tasks. However, in this work, we identify a critical yet previously overlooked security vulnerability in multimodal agents: cross-modal prompt injection attacks. To exploit this vulnerability, we propose CrossInject, a novel attack framework in which attackers embed adversarial perturbations across multiple modalities to align with target malicious content, allowing external instructions to hijack the agent's decision-making process and execute unauthorized tasks. Our approach consists of two key components. First, we introduce Visual Latent Alignment, where we optimize adversarial features to the malicious instructions in the visual embedding space based on a text-to-image generative model, ensuring that adversarial images subtly encode cues for malicious task execution. Subsequently, we present Textual Guidance Enhancement, where a large language model is leveraged to infer the black-box defensive system prompt through adversarial meta prompting and generate an malicious textual command that steers the agent's output toward better compliance with attackers' requests. Extensive experiments demonstrate that our method outperforms existing injection attacks, achieving at least a +26.4% increase in attack success rates across diverse tasks. Furthermore, we validate our attack's effectiveness in real-world multimodal autonomous agents, highlighting its potential implications for safety-critical applications.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "17 pages, 4 figures", "pdf_url": "https://arxiv.org/pdf/2504.14348.pdf", "abstract_url": "https://arxiv.org/abs/2504.14348", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"]}
{"id": "2504.14395", "title": "Hydra: An Agentic Reasoning Approach for Enhancing Adversarial Robustness and Mitigating Hallucinations in Vision-Language Models", "authors": ["Chung-En", "Hsuan-Chih", "Chen", "Brian Jalaian", "Nathaniel D. Bastian"], "abstract": "To develop trustworthy Vision-Language Models (VLMs), it is essential to address adversarial robustness and hallucination mitigation, both of which impact factual accuracy in high-stakes applications such as defense and healthcare. Existing methods primarily focus on either adversarial defense or hallucination post-hoc correction, leaving a gap in unified robustness strategies. We introduce \\textbf{Hydra}, an adaptive agentic framework that enhances plug-in VLMs through iterative reasoning, structured critiques, and cross-model verification, improving both resilience to adversarial perturbations and intrinsic model errors. Hydra employs an Action-Critique Loop, where it retrieves and critiques visual information, leveraging Chain-of-Thought (CoT) and In-Context Learning (ICL) techniques to refine outputs dynamically. Unlike static post-hoc correction methods, Hydra adapts to both adversarial manipulations and intrinsic model errors, making it robust to malicious perturbations and hallucination-related inaccuracies. We evaluate Hydra on four VLMs, three hallucination benchmarks, two adversarial attack strategies, and two adversarial defense methods, assessing performance on both clean and adversarial inputs. Results show that Hydra surpasses plug-in VLMs and state-of-the-art (SOTA) dehallucination methods, even without explicit adversarial defenses, demonstrating enhanced robustness and factual consistency. By bridging adversarial resistance and hallucination mitigation, Hydra provides a scalable, training-free solution for improving the reliability of VLMs in real-world applications.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.14395.pdf", "abstract_url": "https://arxiv.org/abs/2504.14395", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"]}
{"id": "2504.14429", "title": "ResNetVLLM-2: Addressing ResNetVLLM's Multi-Modal Hallucinations", "authors": ["Ahmad Khalil", "Mahmoud Khalil", "Alioune Ngom"], "abstract": "Large Language Models (LLMs) have transformed natural language processing (NLP) tasks, but they suffer from hallucination, generating plausible yet factually incorrect content. This issue extends to Video-Language Models (VideoLLMs), where textual descriptions may inaccurately represent visual content, resulting in multi-modal hallucinations. In this paper, we address hallucination in ResNetVLLM, a video-language model combining ResNet visual encoders with LLMs. We introduce a two-step protocol: (1) a faithfulness detection strategy that uses a modified Lynx model to assess semantic alignment between generated captions and ground-truth video references, and (2) a hallucination mitigation strategy using Retrieval-Augmented Generation (RAG) with an ad-hoc knowledge base dynamically constructed during inference. Our enhanced model, ResNetVLLM-2, reduces multi-modal hallucinations by cross-verifying generated content against external knowledge, improving factual consistency. Evaluation on the ActivityNet-QA benchmark demonstrates a substantial accuracy increase from 54.8% to 65.3%, highlighting the effectiveness of our hallucination detection and mitigation strategies in enhancing video-language model reliability.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.14429.pdf", "abstract_url": "https://arxiv.org/abs/2504.14429", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"]}
{"id": "2504.14482", "title": "DialogueAgents: A Hybrid Agent-Based Speech Synthesis Framework for Multi-Party Dialogue", "authors": ["Xiang Li", "Duyi Pan", "Hongru Xiao", "Jiale Han", "Jing Tang", "Jiabao Ma", "Wei Wang", "Bo Cheng"], "abstract": "Speech synthesis is crucial for human-computer interaction, enabling natural and intuitive communication. However, existing datasets involve high construction costs due to manual annotation and suffer from limited character diversity, contextual scenarios, and emotional expressiveness. To address these issues, we propose DialogueAgents, a novel hybrid agent-based speech synthesis framework, which integrates three specialized agents -- a script writer, a speech synthesizer, and a dialogue critic -- to collaboratively generate dialogues. Grounded in a diverse character pool, the framework iteratively refines dialogue scripts and synthesizes speech based on speech review, boosting emotional expressiveness and paralinguistic features of the synthesized dialogues. Using DialogueAgent, we contribute MultiTalk, a bilingual, multi-party, multi-turn speech dialogue dataset covering diverse topics. Extensive experiments demonstrate the effectiveness of our framework and the high quality of the MultiTalk dataset. We release the dataset and code", "subjects": "Computation and Language (cs.CL); Sound (cs.SD)", "comments": ")", "pdf_url": "https://arxiv.org/pdf/2504.14482.pdf", "abstract_url": "https://arxiv.org/abs/2504.14482", "categories": ["Computation and Language (cs.CL)", "Sound (cs.SD)"], "matching_keywords": ["agent"]}
{"id": "2504.14538", "title": "BookWorld: From Novels to Interactive Agent Societies for Creative Story Generation", "authors": ["Yiting Ran", "Xintao Wang", "Tian Qiu", "Jiaqing Liang", "Yanghua Xiao", "Deqing Yang"], "abstract": "Recent advances in large language models (LLMs) have enabled social simulation through multi-agent systems. Prior efforts focus on agent societies created from scratch, assigning agents with newly defined personas. However, simulating established fictional worlds and characters remain largely underexplored, despite its significant practical value. In this paper, we introduce BookWorld, a comprehensive system for constructing and simulating book-based multi-agent societies. BookWorld's design covers comprehensive real-world intricacies, including diverse and dynamic characters, fictional worldviews, geographical constraints and changes, e.t.c. BookWorld enables diverse applications including story generation, interactive games and social simulation, offering novel ways to extend and explore beloved fictional works. Through extensive experiments, we demonstrate that BookWorld generates creative, high-quality stories while maintaining fidelity to the source books, surpassing previous methods with a win rate of 75.36%. The code of this paper can be found at the project page:", "subjects": "Computation and Language (cs.CL)", "comments": "19 pages, 4 figures", "pdf_url": "https://arxiv.org/pdf/2504.14538.pdf", "abstract_url": "https://arxiv.org/abs/2504.14538", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2504.13988", "title": "Going Whole Hog: A Philosophical Defense of AI Cognition", "authors": ["Herman Cappelen", "Josh Dever"], "abstract": "This work defends the 'Whole Hog Thesis': sophisticated Large Language Models (LLMs) like ChatGPT are full-blown linguistic and cognitive agents, possessing understanding, beliefs, desires, knowledge, and intentions. We argue against prevailing methodologies in AI philosophy, rejecting starting points based on low-level computational details ('Just an X' fallacy) or pre-existing theories of mind. Instead, we advocate starting with simple, high-level observations of LLM behavior (e.g., answering questions, making suggestions) -- defending this data against charges of metaphor, loose talk, or pretense. From these observations, we employ 'Holistic Network Assumptions' -- plausible connections between mental capacities (e.g., answering implies knowledge, knowledge implies belief, action implies intention) -- to argue for the full suite of cognitive states. We systematically rebut objections based on LLM failures (hallucinations, planning/reasoning errors), arguing these don't preclude agency, often mirroring human fallibility. We address numerous 'Games of Lacks', arguing that LLMs do not lack purported necessary conditions for cognition (e.g., semantic grounding, embodiment, justification, intrinsic intentionality) or that these conditions are not truly necessary, often relying on anti-discriminatory arguments comparing LLMs to diverse human capacities. Our approach is evidential, not functionalist, and deliberately excludes consciousness. We conclude by speculating on the possibility of LLMs possessing 'alien' contents beyond human conceptual schemes.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.13988.pdf", "abstract_url": "https://arxiv.org/abs/2504.13988", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2504.14128", "title": "TALES: Text Adventure Learning Environment Suite", "authors": ["Christopher Zhang Cui", "Xingdi Yuan", "Zhang Xiao", "Prithviraj Ammanabrolu", "Marc-Alexandre Côté"], "abstract": "Reasoning is an essential skill to enable Large Language Models (LLMs) to interact with the world. As tasks become more complex, they demand increasingly sophisticated and diverse reasoning capabilities for sequential decision-making, requiring structured reasoning over the context history to determine the next best action. We introduce TALES, a diverse collection of synthetic and human-written text-adventure games designed to challenge and evaluate diverse reasoning capabilities. We present results over a range of LLMs, open- and closed-weights, performing a qualitative analysis on the top performing models. Despite an impressive showing on synthetic games, even the top LLM-driven agents fail to achieve 15% on games designed for human enjoyment. Code and visualization of the experiments can be found at", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.14128.pdf", "abstract_url": "https://arxiv.org/abs/2504.14128", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2504.14239", "title": "InfiGUI-R1: Advancing Multimodal GUI Agents from Reactive Actors to Deliberative Reasoners", "authors": ["Yuhang Liu", "Pengxiang Li", "Congkai Xie", "Xavier Hu", "Xiaotian Han", "Shengyu Zhang", "Hongxia Yang", "Fei Wu"], "abstract": "Multimodal Large Language Models (MLLMs) have powered Graphical User Interface (GUI) Agents, showing promise in automating tasks on computing devices. Recent works have begun exploring reasoning in GUI tasks with encouraging results. However, many current approaches rely on manually designed reasoning templates, which may result in reasoning that is not sufficiently robust and adaptive for complex GUI environments. Meanwhile, some existing agents continue to operate as Reactive Actors, relying primarily on implicit reasoning that may lack sufficient depth for GUI tasks demanding planning and error recovery. We argue that advancing these agents requires a shift from reactive acting towards acting based on deliberate reasoning. To facilitate this transformation, we introduce InfiGUI-R1, an MLLM-based GUI agent developed through our Actor2Reasoner framework, a reasoning-centric, two-stage training approach designed to progressively evolve agents from Reactive Actors to Deliberative Reasoners. The first stage, Reasoning Injection, focuses on establishing a basic reasoner. We employ Spatial Reasoning Distillation to transfer cross-modal spatial reasoning capabilities from teacher models to MLLMs through trajectories with explicit reasoning steps, enabling models to integrate GUI visual-spatial information with logical reasoning before action generation. The second stage, Deliberation Enhancement, refines the basic reasoner into a deliberative one using Reinforcement Learning. This stage introduces two approaches: Sub-goal Guidance, which rewards models for generating accurate intermediate sub-goals, and Error Recovery Scenario Construction, which creates failure-and-recovery training scenarios from identified prone-to-error steps. Experimental results show InfiGUI-R1 achieves strong performance in GUI grounding and trajectory tasks. Resources at", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "10 pages, 3 figures, work in progress", "pdf_url": "https://arxiv.org/pdf/2504.14239.pdf", "abstract_url": "https://arxiv.org/abs/2504.14239", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2504.14325", "title": "FAIRGAME: a Framework for AI Agents Bias Recognition using Game Theory", "authors": ["Alessio Buscemi", "Daniele Proverbio", "Alessandro Di Stefano", "Anh Han", "German Castignani", "Pietro Di Liò"], "abstract": "Letting AI agents interact in multi-agent applications adds a layer of complexity to the interpretability and prediction of AI outcomes, with profound implications for their trustworthy adoption in research and society. Game theory offers powerful models to capture and interpret strategic interaction among agents, but requires the support of reproducible, standardized and user-friendly IT frameworks to enable comparison and interpretation of results. To this end, we present FAIRGAME, a Framework for AI Agents Bias Recognition using Game Theory. We describe its implementation and usage, and we employ it to uncover biased outcomes in popular games among AI agents, depending on the employed Large Language Model (LLM) and used language, as well as on the personality trait or strategic knowledge of the agents. Overall, FAIRGAME allows users to reliably and easily simulate their desired games and scenarios and compare the results across simulation campaigns and with game-theoretic predictions, enabling the systematic discovery of biases, the anticipation of emerging behavior out of strategic interplays, and empowering further research into strategic decision-making using LLM agents.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.14325.pdf", "abstract_url": "https://arxiv.org/abs/2504.14325", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2504.14520", "title": "Meta-Thinking in LLMs via Multi-Agent Reinforcement Learning: A Survey", "authors": ["Ahsan Bilal", "Muhammad Ahmed Mohsin", "Muhammad Umer", "Muhammad Awais Khan Bangash", "Muhammad Ali Jamshed"], "abstract": "This survey explores the development of meta-thinking capabilities in Large Language Models (LLMs) from a Multi-Agent Reinforcement Learning (MARL) perspective. Meta-thinking self-reflection, assessment, and control of thinking processes is an important next step in enhancing LLM reliability, flexibility, and performance, particularly for complex or high-stakes tasks. The survey begins by analyzing current LLM limitations, such as hallucinations and the lack of internal self-assessment mechanisms. It then talks about newer methods, including RL from human feedback (RLHF), self-distillation, and chain-of-thought prompting, and each of their limitations. The crux of the survey is to talk about how multi-agent architectures, namely supervisor-agent hierarchies, agent debates, and theory of mind frameworks, can emulate human-like introspective behavior and enhance LLM robustness. By exploring reward mechanisms, self-play, and continuous learning methods in MARL, this survey gives a comprehensive roadmap to building introspective, adaptive, and trustworthy LLMs. Evaluation metrics, datasets, and future research avenues, including neuroscience-inspired architectures and hybrid symbolic reasoning, are also discussed.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "Submitted to IEEE Transactions on Artificial Intelligence", "pdf_url": "https://arxiv.org/pdf/2504.14520.pdf", "abstract_url": "https://arxiv.org/abs/2504.14520", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2504.14891", "title": "Retrieval Augmented Generation Evaluation in the Era of Large Language Models: A Comprehensive Survey", "authors": ["Aoran Gan", "Hao Yu", "Kai Zhang", "Qi Liu", "Wenyu Yan", "Zhenya Huang", "Shiwei Tong", "Guoping Hu"], "abstract": "Recent advancements in Retrieval-Augmented Generation (RAG) have revolutionized natural language processing by integrating Large Language Models (LLMs) with external information retrieval, enabling accurate, up-to-date, and verifiable text generation across diverse applications. However, evaluating RAG systems presents unique challenges due to their hybrid architecture that combines retrieval and generation components, as well as their dependence on dynamic knowledge sources in the LLM era. In response, this paper provides a comprehensive survey of RAG evaluation methods and frameworks, systematically reviewing traditional and emerging evaluation approaches, for system performance, factual accuracy, safety, and computational efficiency in the LLM era. We also compile and categorize the RAG-specific datasets and evaluation frameworks, conducting a meta-analysis of evaluation practices in high-impact RAG research. To the best of our knowledge, this work represents the most comprehensive survey for RAG evaluation, bridging traditional and LLM-driven methods, and serves as a critical resource for advancing RAG development.", "subjects": "Computation and Language (cs.CL)", "comments": "18 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2504.14891.pdf", "abstract_url": "https://arxiv.org/abs/2504.14891", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"]}
{"id": "2504.15022", "title": "LLMs as Data Annotators: How Close Are We to Human Performance", "authors": ["Muhammad Uzair Ul Haq", "Davide Rigoni", "Alessandro Sperduti"], "abstract": "In NLP, fine-tuning LLMs is effective for various applications but requires high-quality annotated data. However, manual annotation of data is labor-intensive, time-consuming, and costly. Therefore, LLMs are increasingly used to automate the process, often employing in-context learning (ICL) in which some examples related to the task are given in the prompt for better performance. However, manually selecting context examples can lead to inefficiencies and suboptimal model performance. This paper presents comprehensive experiments comparing several LLMs, considering different embedding models, across various datasets for the Named Entity Recognition (NER) task. The evaluation encompasses models with approximately $7$B and $70$B parameters, including both proprietary and non-proprietary models. Furthermore, leveraging the success of Retrieval-Augmented Generation (RAG), it also considers a method that addresses the limitations of ICL by automatically retrieving contextual examples, thereby enhancing performance. The results highlight the importance of selecting the appropriate LLM and embedding model, understanding the trade-offs between LLM sizes and desired performance, and the necessity to direct research efforts towards more challenging datasets.", "subjects": "Computation and Language (cs.CL)", "comments": "27 pages, 4 figures", "pdf_url": "https://arxiv.org/pdf/2504.15022.pdf", "abstract_url": "https://arxiv.org/abs/2504.15022", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"]}
{"id": "2504.15027", "title": "DistilQwen2.5: Industrial Practices of Training Distilled Open Lightweight Language Models", "authors": ["Chengyu Wang", "Junbing Yan", "Yuanhao Yue", "Jun Huang"], "abstract": "Enhancing computational efficiency and reducing deployment costs for large language models (LLMs) have become critical challenges in various resource-constrained scenarios. In this work, we present DistilQwen2.5, a family of distilled, lightweight LLMs derived from the public Qwen2.5 models. These distilled models exhibit enhanced instruction-following capabilities compared to the original models based on a series of distillation techniques that incorporate knowledge from much larger LLMs. In our industrial practice, we first leverage powerful proprietary LLMs with varying capacities as multi-agent teachers to select, rewrite, and refine instruction-response pairs that are more suitable for student LLMs to learn. After standard fine-tuning, we further leverage a computationally efficient model fusion approach that enables student models to progressively integrate fine-grained hidden knowledge from their teachers. Experimental evaluations demonstrate that the distilled models possess significantly stronger capabilities than their original checkpoints. Additionally, we present use cases to illustrate the applications of our framework in real-world scenarios. To facilitate practical use, we have released all the DistilQwen2.5 models to the open-source community.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.15027.pdf", "abstract_url": "https://arxiv.org/abs/2504.15027", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2504.14603", "title": "UFO2: The Desktop AgentOS", "authors": ["Chaoyun Zhang", "He Huang", "Chiming Ni", "Jian Mu", "Si Qin", "Shilin He", "Lu Wang", "Fangkai Yang", "Pu Zhao", "Chao Du", "Liqun Li", "Yu Kang", "Zhao Jiang", "Suzhen Zheng", "Rujia Wang", "Jiaxu Qian", "Minghua Ma", "Jian-Guang Lou", "Qingwei Lin", "Saravan Rajmohan", "Dongmei Zhang"], "abstract": "Recent Computer-Using Agents (CUAs), powered by multimodal large language models (LLMs), offer a promising direction for automating complex desktop workflows through natural language. However, most existing CUAs remain conceptual prototypes, hindered by shallow OS integration, fragile screenshot-based interaction, and disruptive execution.", "subjects": "Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Operating Systems (cs.OS)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2504.14603.pdf", "abstract_url": "https://arxiv.org/abs/2504.14603", "categories": ["Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)", "Operating Systems (cs.OS)"], "matching_keywords": ["agent"]}
{"id": "2504.14650", "title": "A Framework for Benchmarking and Aligning Task-Planning Safety in LLM-Based Embodied Agents", "authors": ["Yuting Huang", "Leilei Ding", "Zhipeng Tang", "Tianfu Wang", "Xinrui Lin", "Wuyang Zhang", "Mingxiao Ma", "Yanyong Zhang"], "abstract": "Large Language Models (LLMs) exhibit substantial promise in enhancing task-planning capabilities within embodied agents due to their advanced reasoning and comprehension. However, the systemic safety of these agents remains an underexplored frontier. In this study, we present Safe-BeAl, an integrated framework for the measurement (SafePlan-Bench) and alignment (Safe-Align) of LLM-based embodied agents' behaviors. SafePlan-Bench establishes a comprehensive benchmark for evaluating task-planning safety, encompassing 2,027 daily tasks and corresponding environments distributed across 8 distinct hazard categories (e.g., Fire Hazard). Our empirical analysis reveals that even in the absence of adversarial inputs or malicious intent, LLM-based agents can exhibit unsafe behaviors. To mitigate these hazards, we propose Safe-Align, a method designed to integrate physical-world safety knowledge into LLM-based embodied agents while maintaining task-specific performance. Experiments across a variety of settings demonstrate that Safe-BeAl provides comprehensive safety validation, improving safety by 8.55 - 15.22%, compared to embodied agents based on GPT-4, while ensuring successful task completion.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "16 pages, 10 figures", "pdf_url": "https://arxiv.org/pdf/2504.14650.pdf", "abstract_url": "https://arxiv.org/abs/2504.14650", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2504.14706", "title": "AI with Emotions: Exploring Emotional Expressions in Large Language Models", "authors": ["Shin-nosuke Ishikawa", "Atsushi Yoshino"], "abstract": "The human-level performance of Large Language Models (LLMs) across various tasks has raised expectations for the potential of Artificial Intelligence (AI) to possess emotions someday. To explore the capability of current LLMs to express emotions in their outputs, we conducted an experiment using several LLMs (OpenAI GPT, Google Gemini, Meta Llama3, and Cohere Command R+) to role-play as agents answering questions with specified emotional", "subjects": "Artificial Intelligence (cs.AI)", "comments": "14 pages, 8 figures, accepted to the Natural Language Processing for Digital Humanities (NLP4DH) workshop at NAACL 2025", "pdf_url": "https://arxiv.org/pdf/2504.14706.pdf", "abstract_url": "https://arxiv.org/abs/2504.14706", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2504.14773", "title": "PLANET: A Collection of Benchmarks for Evaluating LLMs' Planning Capabilities", "authors": ["Haoming Li", "Zhaoliang Chen", "Jonathan Zhang", "Fei Liu"], "abstract": "Planning is central to agents and agentic AI. The ability to plan, e.g., creating travel itineraries within a budget, holds immense potential in both scientific and commercial contexts. Moreover, optimal plans tend to require fewer resources compared to ad-hoc methods. To date, a comprehensive understanding of existing planning benchmarks appears to be lacking. Without it, comparing planning algorithms' performance across domains or selecting suitable algorithms for new scenarios remains challenging. In this paper, we examine a range of planning benchmarks to identify commonly used testbeds for algorithm development and highlight potential gaps. These benchmarks are categorized into embodied environments, web navigation, scheduling, games and puzzles, and everyday task automation. Our study recommends the most appropriate benchmarks for various algorithms and offers insights to guide future benchmark development.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Multiagent Systems (cs.MA)", "comments": "10 pages", "pdf_url": "https://arxiv.org/pdf/2504.14773.pdf", "abstract_url": "https://arxiv.org/abs/2504.14773", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"]}
{"id": "2504.15205", "title": "Support Evaluation for the TREC 2024 RAG Track: Comparing Human versus LLM Judges", "authors": ["Nandan Thakur", "Ronak Pradeep", "Shivani Upadhyay", "Daniel Campos", "Nick Craswell", "Jimmy Lin"], "abstract": "Retrieval-augmented generation (RAG) enables large language models (LLMs) to generate answers with citations from source documents containing \"ground truth\", thereby reducing system hallucinations. A crucial factor in RAG evaluation is \"support\", whether the information in the cited documents supports the answer. To this end, we conducted a large-scale comparative study of 45 participant submissions on 36 topics to the TREC 2024 RAG Track, comparing an automatic LLM judge (GPT-4o) against human judges for support assessment. We considered two conditions: (1) fully manual assessments from scratch and (2) manual assessments with post-editing of LLM predictions. Our results indicate that for 56% of the manual from-scratch assessments, human and GPT-4o predictions match perfectly (on a three-level scale), increasing to 72% in the manual with post-editing condition. Furthermore, by carefully analyzing the disagreements in an unbiased study, we found that an independent human judge correlates better with GPT-4o than a human judge, suggesting that LLM judges can be a reliable alternative for support assessment. To conclude, we provide a qualitative analysis of human and GPT-4o errors to help guide future iterations of support assessment.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": "Accepted at SIGIR 2025 (short)", "pdf_url": "https://arxiv.org/pdf/2504.15205.pdf", "abstract_url": "https://arxiv.org/abs/2504.15205", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"]}
{"id": "2504.15219", "title": "EvalAgent: Discovering Implicit Evaluation Criteria from the Web", "authors": ["Manya Wadhwa", "Zayne Sprague", "Chaitanya Malaviya", "Philippe Laban", "Junyi Jessy Li", "Greg Durrett"], "abstract": "Evaluation of language model outputs on structured writing tasks is typically conducted with a number of desirable criteria presented to human evaluators or large language models (LLMs). For instance, on a prompt like \"Help me draft an academic talk on coffee intake vs research productivity\", a model response may be evaluated for criteria like accuracy and coherence. However, high-quality responses should do more than just satisfy basic task requirements. An effective response to this query should include quintessential features of an academic talk, such as a compelling opening, clear research questions, and a takeaway. To help identify these implicit criteria, we introduce EvalAgent, a novel framework designed to automatically uncover nuanced and task-specific criteria. EvalAgent first mines expert-authored online guidance. It then uses this evidence to propose diverse, long-tail evaluation criteria that are grounded in reliable external sources. Our experiments demonstrate that the grounded criteria produced by EvalAgent are often implicit (not directly stated in the user's prompt), yet specific (high degree of lexical precision). Further, EvalAgent criteria are often not satisfied by initial responses but they are actionable, such that responses can be refined to satisfy them. Finally, we show that combining LLM-generated and EvalAgent criteria uncovers more human-valued criteria than using LLMs alone.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.15219.pdf", "abstract_url": "https://arxiv.org/abs/2504.15219", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2504.14858", "title": "AlignRAG: An Adaptable Framework for Resolving Misalignments in Retrieval-Aware Reasoning of RAG", "authors": ["Jiaqi Wei", "Hao Zhou", "Xiang Zhang", "Di Zhang", "Zijie Qiu", "Wei Wei", "Jinzhe Li", "Wanli Ouyang", "Siqi Sun"], "abstract": "Retrieval-augmented generation (RAG) has emerged as a foundational paradigm for knowledge-grounded text generation. However, existing RAG pipelines often fail to ensure that the reasoning trajectories align with the evidential constraints imposed by retrieved content. In this paper, we reframe RAG as a problem of retrieval-aware reasoning and identify a core challenge: reasoning misalignment-the mismatch between a model's reasoning trajectory and the retrieved evidence. To address this challenge, we propose AlignRAG, a novel test-time framework that mitigates reasoning misalignment through iterative Critique-Driven Alignment (CDA) steps. In contrast to prior approaches that rely on static training or post-hoc selection, AlignRAG actively refines reasoning trajectories during inference by enforcing fine-grained alignment with evidence. Our framework introduces a new paradigm for retrieval-aware reasoning by: (1) constructing context-rich training corpora; (2) generating contrastive critiques from preference-aware reasoning trajectories; (3) training a dedicated \\textit{Critic Language Model (CLM)} to identify reasoning misalignments; and (4) applying CDA steps to optimize reasoning trajectories iteratively. Empirical results demonstrate that AlignRAG consistently outperforms all baselines and could integrate as a plug-and-play module into existing RAG pipelines without further changes. By reconceptualizing RAG as a structured reasoning trajectory and establishing the test-time framework for correcting reasoning misalignments in RAG, AlignRAG provides practical advancements for retrieval-aware generation.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.14858.pdf", "abstract_url": "https://arxiv.org/abs/2504.14858", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"]}
{"id": "2504.14928", "title": "EducationQ: Evaluating LLMs' Teaching Capabilities Through Multi-Agent Dialogue Framework", "authors": ["Yao Shi", "Rongkeng Liang", "Yong Xu"], "abstract": "Large language models (LLMs) increasingly serve as educational tools, yet evaluating their teaching capabilities remains challenging due to the resource-intensive, context-dependent, and methodologically complex nature of teacher-student interactions. We introduce EducationQ, a multi-agent dialogue framework that efficiently assesses teaching capabilities through simulated dynamic educational scenarios, featuring specialized agents for teaching, learning, and evaluation. Testing 14 LLMs across major AI Organizations (OpenAI, Meta, Google, Anthropic, and others) on 1,498 questions spanning 13 disciplines and 10 difficulty levels reveals that teaching effectiveness does not correlate linearly with model scale or general reasoning capabilities - with some smaller open-source models outperforming larger commercial counterparts in teaching contexts. This finding highlights a critical gap in current evaluations that prioritize knowledge recall over interactive pedagogy. Our mixed-methods evaluation, combining quantitative metrics with qualitative analysis and expert case studies, identifies distinct pedagogical strengths employed by top-performing models (e.g., sophisticated questioning strategies, adaptive feedback mechanisms). Human expert evaluations show 78% agreement with our automated qualitative analysis of effective teaching behaviors, validating our methodology. EducationQ demonstrates that LLMs-as-teachers require specialized optimization beyond simple scaling, suggesting next-generation educational AI prioritize targeted enhancement of specific pedagogical effectiveness.", "subjects": "Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Computation and Language (cs.CL); Computers and Society (cs.CY); Human-Computer Interaction (cs.HC)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.14928.pdf", "abstract_url": "https://arxiv.org/abs/2504.14928", "categories": ["Artificial Intelligence (cs.AI)", "Computational Engineering, Finance, and Science (cs.CE)", "Computation and Language (cs.CL)", "Computers and Society (cs.CY)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"]}
{"id": "2504.15046", "title": "Text-to-Decision Agent: Learning Generalist Policies from Natural Language Supervision", "authors": ["Shilin Zhang", "Zican Hu", "Wenhao Wu", "Xinyi Xie", "Jianxiang Tang", "Chunlin Chen", "Daoyi Dong", "Yu Cheng", "Zhenhong Sun", "Zhi Wang"], "abstract": "RL systems usually tackle generalization by inferring task beliefs from high-quality samples or warmup explorations. The restricted form limits their generality and usability since these supervision signals are expensive and even infeasible to acquire in advance for unseen tasks. Learning directly from the raw text about decision tasks is a promising alternative to leverage a much broader source of supervision. In the paper, we propose Text-to-Decision Agent (T2DA), a simple and scalable framework that supervises generalist policy learning with natural language. We first introduce a generalized world model to encode multi-task decision data into a dynamics-aware embedding space. Then, inspired by CLIP, we predict which textual description goes with which decision embedding, effectively bridging their semantic gap via contrastive language-decision pre-training and aligning the text embeddings to comprehend the environment dynamics. After training the text-conditioned generalist policy, the agent can directly realize zero-shot text-to-decision generation in response to language instructions. Comprehensive experiments on MuJoCo and Meta-World benchmarks show that T2DA facilitates high-capacity zero-shot generalization and outperforms various types of baselines.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "18 pages, 8 figures", "pdf_url": "https://arxiv.org/pdf/2504.15046.pdf", "abstract_url": "https://arxiv.org/abs/2504.15046", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2504.15125", "title": "Contemplative Wisdom for Superalignment", "authors": ["Ruben Laukkonen", "Fionn Inglis", "Shamil Chandaria", "Lars Sandved-Smith", "Jakob Hohwy", "Jonathan Gold", "Adam Elwood"], "abstract": "As artificial intelligence (AI) improves, traditional alignment strategies may falter in the face of unpredictable self-improvement, hidden subgoals, and the sheer complexity of intelligent systems. Rather than externally constraining behavior, we advocate designing AI with intrinsic morality built into its cognitive architecture and world model. Inspired by contemplative wisdom traditions, we show how four axiomatic principles can instil a resilient Wise World Model in AI systems. First, mindfulness enables self-monitoring and recalibration of emergent subgoals. Second, emptiness forestalls dogmatic goal fixation and relaxes rigid priors. Third, non-duality dissolves adversarial self-other boundaries. Fourth, boundless care motivates the universal reduction of suffering. We find that prompting AI to reflect on these principles improves performance on the AILuminate Benchmark using GPT-4o, particularly when combined. We offer detailed implementation strategies for state-of-the-art models, including contemplative architectures, constitutions, and reinforcement of chain-of-thought. For future systems, the active inference framework may offer the self-organizing and dynamic coupling capabilities needed to enact these insights in embodied agents. This interdisciplinary approach offers a self-correcting and resilient alternative to prevailing brittle control schemes.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.15125.pdf", "abstract_url": "https://arxiv.org/abs/2504.15125", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2504.15146", "title": "Behavioral Universe Network (BUN): A Behavioral Information-Based Framework for Complex Systems", "authors": ["Wei Zhou", "Ailiya Borjigin", "Cong He"], "abstract": "Modern digital ecosystems feature complex, dynamic interactions among autonomous entities across diverse domains. Traditional models often separate agents and objects, lacking a unified foundation to capture their interactive behaviors. This paper introduces the Behavioral Universe Network (BUN), a theoretical framework grounded in the Agent-Interaction-Behavior (AIB) formalism. BUN treats subjects (active agents), objects (resources), and behaviors (operations) as first-class entities, all governed by a shared Behavioral Information Base (BIB). We detail the AIB core concepts and demonstrate how BUN leverages information-driven triggers, semantic enrichment, and adaptive rules to coordinate multi-agent systems. We highlight key benefits: enhanced behavior analysis, strong adaptability, and cross-domain interoperability. We conclude by positioning BUN as a promising foundation for next-generation digital governance and intelligent applications.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "17 pages, 1 figure", "pdf_url": "https://arxiv.org/pdf/2504.15146.pdf", "abstract_url": "https://arxiv.org/abs/2504.15146", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2504.14868", "title": "Twin Co-Adaptive Dialogue for Progressive Image Generation", "authors": ["Jianhui Wang", "Yangfan He", "Yan Zhong", "Xinyuan Song", "Jiayi Su", "Yuheng Feng", "Hongyang He", "Wenyu Zhu", "Xinhang Yuan", "Kuan Lu", "Menghao Huo", "Miao Zhang", "Keqin Li", "Jiaqi Chen", "Tianyu Shi", "Xueqian Wang"], "abstract": "Modern text-to-image generation systems have enabled the creation of remarkably realistic and high-quality visuals, yet they often falter when handling the inherent ambiguities in user prompts. In this work, we present Twin-Co, a framework that leverages synchronized, co-adaptive dialogue to progressively refine image generation. Instead of a static generation process, Twin-Co employs a dynamic, iterative workflow where an intelligent dialogue agent continuously interacts with the user. Initially, a base image is generated from the user's prompt. Then, through a series of synchronized dialogue exchanges, the system adapts and optimizes the image according to evolving user feedback. The co-adaptive process allows the system to progressively narrow down ambiguities and better align with user intent. Experiments demonstrate that Twin-Co not only enhances user experience by reducing trial-and-error iterations but also improves the quality of the generated images, streamlining the creative process across various applications.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.14868.pdf", "abstract_url": "https://arxiv.org/abs/2504.14868", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"]}
{"id": "2504.13861", "title": "3MDBench: Medical Multimodal Multi-agent Dialogue Benchmark", "authors": ["Ivan Sviridov", "Amina Miftakhova", "Artemiy Tereshchenko", "Galina Zubkova", "Pavel Blinov", "Andrey Savchenko"], "abstract": "Large Vision-Language Models (LVLMs) are increasingly being explored for applications in telemedicine, yet their ability to engage with diverse patient behaviors remains underexplored. We introduce 3MDBench (Medical Multimodal Multi-agent Dialogue Benchmark), an open-source evaluation framework designed to assess LLM-driven medical consultations. Unlike existing benchmarks, 3MDBench simulates real-world patient variability by incorporating four temperament-driven Patient Agents and an Assessor Agent that evaluates diagnostic accuracy and dialogue quality. The benchmark integrates textual and image-based patient data across 34 common diagnoses, mirroring real-world telemedicine interactions. Under different diagnostic strategies, we evaluate state-of-the-art LVLMs. Our findings demonstrate that incorporating dialogue improves the F1 score from 50.4 to 54.2 compared to non-dialogue settings, underscoring the value of context-driven, information-seeking questioning. Additionally, we demonstrate that multimodal inputs enhance diagnostic efficiency. Image-supported models outperform text-only counterparts by raising the diagnostic F1 score from 52.8 to 54.2 in a similar dialogue setting. Finally, we suggest an approach that improves the diagnostic F1-score to 70.3 by training the CNN model on the diagnosis prediction task and incorporating its top-3 predictions into the LVLM context. 3MDBench provides a reproducible and extendable evaluation framework for AI-driven medical assistants. It offers insights into how patient temperament, dialogue strategies, and multimodal reasoning influence diagnosis quality. By addressing real-world complexities in telemedicine, our benchmark paves the way for more empathetic, reliable, and context-aware AI-driven healthcare solutions. The source code of our benchmark is publicly available:", "subjects": "Human-Computer Interaction (cs.HC); Computation and Language (cs.CL); Multiagent Systems (cs.MA)", "comments": "26 pages, 8 figures, 7 tables", "pdf_url": "https://arxiv.org/pdf/2504.13861.pdf", "abstract_url": "https://arxiv.org/abs/2504.13861", "categories": ["Human-Computer Interaction (cs.HC)", "Computation and Language (cs.CL)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"]}
{"id": "2504.13865", "title": "A Survey on (M)LLM-Based GUI Agents", "authors": ["Fei Tang", "Haolei Xu", "Hang Zhang", "Siqi Chen", "Xingyu Wu", "Yongliang Shen", "Wenqi Zhang", "Guiyang Hou", "Zeqi Tan", "Yuchen Yan", "Kaitao Song", "Jian Shao", "Weiming Lu", "Jun Xiao", "Yueting Zhuang"], "abstract": "Graphical User Interface (GUI) Agents have emerged as a transformative paradigm in human-computer interaction, evolving from rule-based automation scripts to sophisticated AI-driven systems capable of understanding and executing complex interface operations. This survey provides a comprehensive examination of the rapidly advancing field of LLM-based GUI Agents, systematically analyzing their architectural foundations, technical components, and evaluation methodologies. We identify and analyze four fundamental components that constitute modern GUI Agents: (1) perception systems that integrate text-based parsing with multimodal understanding for comprehensive interface comprehension; (2) exploration mechanisms that construct and maintain knowledge bases through internal modeling, historical experience, and external information retrieval; (3) planning frameworks that leverage advanced reasoning methodologies for task decomposition and execution; and (4) interaction systems that manage action generation with robust safety controls. Through rigorous analysis of these components, we reveal how recent advances in large language models and multimodal learning have revolutionized GUI automation across desktop, mobile, and web platforms. We critically examine current evaluation frameworks, highlighting methodological limitations in existing benchmarks while proposing directions for standardization. This survey also identifies key technical challenges, including accurate element localization, effective knowledge retrieval, long-horizon planning, and safety-aware execution control, while outlining promising research directions for enhancing GUI Agents' capabilities. Our systematic review provides researchers and practitioners with a thorough understanding of the field's current state and offers insights into future developments in intelligent interface automation.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.13865.pdf", "abstract_url": "https://arxiv.org/abs/2504.13865", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"]}
{"id": "2504.13887", "title": "AI as a deliberative partner fosters intercultural empathy for Americans but fails for Latin American participants", "authors": ["Isabel Villanueva", "Tara Bobinac", "Binwei Yao", "Junjie Hu", "Kaiping Chen"], "abstract": "Despite the growing integration of AI chatbots as conversational agents in public discourse, empirical evidence regarding their capacity to foster intercultural empathy remains limited. Using a randomized dialogue experiment, we examined how different types of AI chatbot interaction, i.e., deliberative versus non-deliberative and culturally aligned versus non-aligned, affect intercultural empathy across cultural groups. Results show that deliberative conversations increased intercultural empathy among American participants but not Latin American participants, who perceived AI responses as culturally inaccurate and failing to represent their cultural contexts and perspectives authentically. Real-time interaction analyses reveal that these differences stem from cultural knowledge gaps inherent in Large Language Models. Despite explicit prompting and instruction to represent cultural perspectives in participants' native languages, AI systems still exhibit significant disparities in cultural representation. This highlights the importance of designing AI systems capable of culturally authentic engagement in deliberative conversations. Our study contributes to deliberation theory and AI alignment research by underscoring AI's role in intercultural dialogue and the persistent challenge of representational asymmetry in democratic discourse.", "subjects": "Human-Computer Interaction (cs.HC); Computation and Language (cs.CL); Computers and Society (cs.CY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.13887.pdf", "abstract_url": "https://arxiv.org/abs/2504.13887", "categories": ["Human-Computer Interaction (cs.HC)", "Computation and Language (cs.CL)", "Computers and Society (cs.CY)"], "matching_keywords": ["agent"]}
{"id": "2504.15228", "title": "A Self-Improving Coding Agent", "authors": ["Maxime Robeyns", "Martin Szummer", "Laurence Aitchison"], "abstract": "We demonstrate that an LLM coding agent, equipped with basic coding tools, can autonomously edit itself, and thereby improve its performance on benchmark tasks. We find performance gains from 17% to 53% on a random subset of SWE Bench Verified, with additional performance gains on LiveCodeBench, as well as synthetically generated agent benchmarks. Our work represents an advancement in the automated and open-ended design of agentic systems, and provides a reference agent framework for those seeking to post-train LLMs on tool use and other agentic tasks.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "Published at an ICLR 2025 workshop on Scaling Self-Improving Foundation Models", "pdf_url": "https://arxiv.org/pdf/2504.15228.pdf", "abstract_url": "https://arxiv.org/abs/2504.15228", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"]}
{"id": "2504.15257", "title": "FlowReasoner: Reinforcing Query-Level Meta-Agents", "authors": ["Hongcheng Gao", "Yue Liu", "Yufei He", "Longxu Dou", "Chao Du", "Zhijie Deng", "Bryan Hooi", "Min Lin", "Tianyu Pang"], "abstract": "This paper proposes a query-level meta-agent named FlowReasoner to automate the design of query-level multi-agent systems, i.e., one system per user query. Our core idea is to incentivize a reasoning-based meta-agent via external execution feedback. Concretely, by distilling DeepSeek R1, we first endow the basic reasoning ability regarding the generation of multi-agent systems to FlowReasoner. Then, we further enhance it via reinforcement learning (RL) with external execution feedback. A multi-purpose reward is designed to guide the RL training from aspects of performance, complexity, and efficiency. In this manner, FlowReasoner is enabled to generate a personalized multi-agent system for each user query via deliberative reasoning. Experiments on both engineering and competition code benchmarks demonstrate the superiority of FlowReasoner. Remarkably, it surpasses o1-mini by 10.52% accuracy across three benchmarks. The code is available at", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.15257.pdf", "abstract_url": "https://arxiv.org/abs/2504.15257", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2504.13856", "title": "Towards Balancing Preference and Performance through Adaptive Personalized Explainability", "authors": ["Andrew Silva", "Pradyumna Tambwekar", "Mariah Schrum", "Matthew Gombolay"], "abstract": "As robots and digital assistants are deployed in the real world, these agents must be able to communicate their decision-making criteria to build trust, improve human-robot teaming, and enable collaboration. While the field of explainable artificial intelligence (xAI) has made great strides to enable such communication, these advances often assume that one xAI approach is ideally suited to each problem (e.g., decision trees to explain how to triage patients in an emergency or feature-importance maps to explain radiology reports). This fails to recognize that users have diverse experiences or preferences for interaction modalities. In this work, we present two user-studies set in a simulated autonomous vehicle (AV) domain. We investigate (1) population-level preferences for xAI and (2) personalization strategies for providing robot explanations. We find significant differences between xAI modes (language explanations, feature-importance maps, and decision trees) in both preference (p < 0.01) and performance (p < 0.05). We also observe that a participant's preferences do not always align with their performance, motivating our development of an adaptive personalization strategy to balance the two. We show that this strategy yields significant performance gains (p < 0.05), and we conclude with a discussion of our findings and implications for xAI in human-robot interactions.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": "20 pages, 19 figures, HRI 2024", "pdf_url": "https://arxiv.org/pdf/2504.13856.pdf", "abstract_url": "https://arxiv.org/abs/2504.13856", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"]}
{"id": "2504.14110", "title": "System of Agentic AI for the Discovery of Metal-Organic Frameworks", "authors": ["Theo Jaffrelot Inizan", "Sherry Yang", "Aaron Kaplan", "Yen-hsu Lin", "Jian Yin", "Saber Mirzaei", "Mona Abdelgaid", "Ali H. Alawadhi", "KwangHwan Cho", "Zhiling Zheng", "Ekin Dogus Cubuk", "Christian Borgs", "Jennifer T. Chayes", "Kristin A. Persson", "Omar M. Yaghi"], "abstract": "Generative models and machine learning promise accelerated material discovery in MOFs for CO2 capture and water harvesting but face significant challenges navigating vast chemical spaces while ensuring synthetizability. Here, we present MOFGen, a system of Agentic AI comprising interconnected agents: a large language model that proposes novel MOF compositions, a diffusion model that generates crystal structures, quantum mechanical agents that optimize and filter candidates, and synthetic-feasibility agents guided by expert rules and machine learning. Trained on all experimentally reported MOFs and computational databases, MOFGen generated hundreds of thousands of novel MOF structures and synthesizable organic linkers. Our methodology was validated through high-throughput experiments and the successful synthesis of five \"AI-dreamt\" MOFs, representing a major step toward automated synthesizable material discovery.", "subjects": "Materials Science (cond-mat.mtrl-sci); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.14110.pdf", "abstract_url": "https://arxiv.org/abs/2504.14110", "categories": ["Materials Science (cond-mat.mtrl-sci)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"]}
{"id": "2504.13871", "title": "Human aversion? Do AI Agents Judge Identity More Harshly Than Performance", "authors": ["Yuanjun Feng", "Vivek Chodhary", "Yash Raj Shrestha"], "abstract": "This study examines the understudied role of algorithmic evaluation of human judgment in hybrid decision-making systems, a critical gap in management research. While extant literature focuses on human reluctance to follow algorithmic advice, we reverse the perspective by investigating how AI agents based on large language models (LLMs) assess and integrate human input. Our work addresses a pressing managerial constraint: firms barred from deploying LLMs directly due to privacy concerns can still leverage them as mediating tools (for instance, anonymized outputs or decision pipelines) to guide high-stakes choices like pricing or discounts without exposing proprietary data. Through a controlled prediction task, we analyze how an LLM-based AI agent weights human versus algorithmic predictions. We find that the AI system systematically discounts human advice, penalizing human errors more severely than algorithmic errors--a bias exacerbated when the agent's identity (human vs AI) is disclosed and the human is positioned second. These results reveal a disconnect between AI-generated trust metrics and the actual influence of human judgment, challenging assumptions about equitable human-AI collaboration. Our findings offer three key contributions. First, we identify a reverse algorithm aversion phenomenon, where AI agents undervalue human input despite comparable error rates. Second, we demonstrate how disclosure and positional bias interact to amplify this effect, with implications for system design. Third, we provide a framework for indirect LLM deployment that balances predictive power with data privacy. For practitioners, this research emphasize the need to audit AI weighting mechanisms, calibrate trust dynamics, and strategically design decision sequences in human-AI systems.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); General Economics (econ.GN)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.13871.pdf", "abstract_url": "https://arxiv.org/abs/2504.13871", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)", "General Economics (econ.GN)"], "matching_keywords": ["agent"]}
{"id": "2504.13898", "title": "The Human Robot Social Interaction (HSRI) Dataset: Benchmarking Foundational Models' Social Reasoning", "authors": ["Dong Won Lee", "Yubin Kim", "Denison Guvenoz", "Sooyeon Jeong", "Parker Malachowsky", "Louis-Philippe Morency", "Cynthia Breazeal", "Hae Won Park"], "abstract": "Our work aims to advance the social reasoning of embodied artificial intelligence (AI) agents in real-world social interactions. Recently, language models (LMs) and foundational models (FMs) are being utilized as automatic evaluators of human-AI interactions with the goal of eventually being used to improve the policy of the AI agent. To enable further research in this direction, we introduce a large-scale real-world Human Robot Social Interaction (HSRI) Dataset to benchmark the capabilities of LMs and FMs to identify and reason about social interactions, specifically with regard to robot social errors and competencies . Our dataset consists of 400 real-world human social robot interaction videos and over 10K annotations, detailing the robot's social errors, competencies, rationale, and corrective actions, capturing unique aspects of human-AI interaction only present in real-world interactions. To further assess AI models' ability to reason about social interactions, we propose eight new benchmark tasks for evaluating centered around whether AI models can (1) evaluate social interactions via detecting social errors and competencies, (2) identify the explanatory factors associated to errors and competencies, (3) understand the flow of real-world social interactions, and (4) provide reasons and corrective actions for social errors. Human studies and experiments with modern LMs and FMs reveal that current models struggle with these tasks, demonstrating that our dataset and benchmark provides a step forward towards socially intelligent AI.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": "23 pages, 11 figures", "pdf_url": "https://arxiv.org/pdf/2504.13898.pdf", "abstract_url": "https://arxiv.org/abs/2504.13898", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2504.13908", "title": "AI-Assisted Conversational Interviewing: Effects on Data Quality and User Experience", "authors": ["Soubhik Barari", "Jarret Angbazo", "Natalie Wang", "Leah M. Christian", "Elizabeth Dean", "Zoe Slowinski", "Brandon Sepulvado"], "abstract": "Standardized surveys scale efficiently but sacrifice depth, while conversational interviews improve response quality at the cost of scalability and consistency. This study bridges the gap between these methods by introducing a framework for AI-assisted conversational interviewing. To evaluate this framework, we conducted a web survey experiment where 1,800 participants were randomly assigned to text-based conversational AI agents, or \"textbots\", to dynamically probe respondents for elaboration and interactively code open-ended responses. We assessed textbot performance in terms of coding accuracy, response quality, and respondent experience. Our findings reveal that textbots perform moderately well in live coding even without survey-specific fine-tuning, despite slightly inflated false positive errors due to respondent acquiescence bias. Open-ended responses were more detailed and informative, but this came at a slight cost to respondent experience. Our findings highlight the feasibility of using AI methods to enhance open-ended data collection in web surveys.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Applications (stat.AP)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.13908.pdf", "abstract_url": "https://arxiv.org/abs/2504.13908", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)", "Applications (stat.AP)"], "matching_keywords": ["agent"]}
{"id": "2504.14822", "title": "Completing A Systematic Review in Hours instead of Months with Interactive AI Agents", "authors": ["Rui Qiu", "Shijie Chen", "Yu Su", "Po-Yin Yen", "Han-Wei Shen"], "abstract": "Systematic reviews (SRs) are vital for evidence-based practice in high stakes disciplines, such as healthcare, but are often impeded by intensive labors and lengthy processes that can take months to complete. Due to the high demand for domain expertise, existing automatic summarization methods fail to accurately identify relevant studies and generate high-quality summaries. To that end, we introduce InsightAgent, a human-centered interactive AI agent powered by large language models that revolutionize this workflow. InsightAgent partitions a large literature corpus based on semantics and employs a multi-agent design for more focused processing of literature, leading to significant improvement in the quality of generated SRs. InsightAgent also provides intuitive visualizations of the corpus and agent trajectories, allowing users to effortlessly monitor the actions of the agent and provide real-time feedback based on their expertise. Our user studies with 9 medical professionals demonstrate that the visualization and interaction mechanisms can effectively improve the quality of synthesized SRs by 27.2%, reaching 79.7% of human-written quality. At the same time, user satisfaction is improved by 34.4%. With InsightAgent, it only takes a clinician about 1.5 hours, rather than months, to complete a high-quality systematic review.", "subjects": "Human-Computer Interaction (cs.HC); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.14822.pdf", "abstract_url": "https://arxiv.org/abs/2504.14822", "categories": ["Human-Computer Interaction (cs.HC)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2504.15068", "title": "The Great Nugget Recall: Automating Fact Extraction and RAG Evaluation with Large Language Models", "authors": ["Ronak Pradeep", "Nandan Thakur", "Shivani Upadhyay", "Daniel Campos", "Nick Craswell", "Jimmy Lin"], "abstract": "Large Language Models (LLMs) have significantly enhanced the capabilities of information access systems, especially with retrieval-augmented generation (RAG). Nevertheless, the evaluation of RAG systems remains a barrier to continued progress, a challenge we tackle in this work by proposing an automatic evaluation framework that is validated against human annotations. We believe that the nugget evaluation methodology provides a solid foundation for evaluating RAG systems. This approach, originally developed for the TREC Question Answering (QA) Track in 2003, evaluates systems based on atomic facts that should be present in good answers. Our efforts focus on \"refactoring\" this methodology, where we describe the AutoNuggetizer framework that specifically applies LLMs to both automatically create nuggets and automatically assign nuggets to system answers. In the context of the TREC 2024 RAG Track, we calibrate a fully automatic approach against strategies where nuggets are created manually or semi-manually by human assessors and then assigned manually to system answers. Based on results from a community-wide evaluation, we observe strong agreement at the run level between scores derived from fully automatic nugget evaluation and human-based variants. The agreement is stronger when individual framework components such as nugget assignment are automated independently. This suggests that our evaluation framework provides tradeoffs between effort and quality that can be used to guide the development of future RAG systems. However, further research is necessary to refine our approach, particularly in establishing robust per-topic agreement to diagnose system failures effectively.", "subjects": "Information Retrieval (cs.IR); Computation and Language (cs.CL)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2504.15068.pdf", "abstract_url": "https://arxiv.org/abs/2504.15068", "categories": ["Information Retrieval (cs.IR)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"]}
{"id": "2504.13969", "title": "Tinker Tales: Interactive Storytelling Framework for Early Childhood Narrative Development and AI Literacy", "authors": ["Nayoung Choi", "Peace Cyebukayire", "Jinho D. Choi"], "abstract": "This paper presents Tinker Tales, an interactive storytelling framework in the format of a board game, designed to support both narrative development and AI literacy in early childhood. The framework integrates tangible and speech-based interactions with AI through NFC chip-attached pawns and tokens, along with a speaker and microphone. Children select and define key story elements-such as characters, places, items, and emotions-using the pawns and tokens, providing further details to the AI and receiving proper assistance, similar to how adults prompt AI for specific tasks (e.g., writing). For evaluation, several game sessions were simulated with a child AI agent, and the quality and safety of the generated stories were assessed from various perspectives. This work highlights the potential of combining physical and digital elements in AI literacy, offering a safe and engaging way for children to learn how to effectively collaborate with AI.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.13969.pdf", "abstract_url": "https://arxiv.org/abs/2504.13969", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)"], "matching_keywords": ["agent"]}
{"id": "2504.15280", "title": "Seeing from Another Perspective: Evaluating Multi-View Understanding in MLLMs", "authors": ["Chun-Hsiao Yeh", "Chenyu Wang", "Shengbang Tong", "Ta-Ying Cheng", "Rouyu Wang", "Tianzhe Chu", "Yuexiang Zhai", "Yubei Chen", "Shenghua Gao", "Yi Ma"], "abstract": "Multi-view understanding, the ability to reconcile visual information across diverse viewpoints for effective navigation, manipulation, and 3D scene comprehension, is a fundamental challenge in Multi-Modal Large Language Models (MLLMs) to be used as embodied agents. While recent MLLMs have shown impressive advances in high-level reasoning and planning, they frequently fall short when confronted with multi-view geometric consistency and cross-view correspondence. To comprehensively evaluate the challenges of MLLMs in multi-view scene reasoning, we propose All-Angles Bench, a benchmark of over 2,100 human carefully annotated multi-view question-answer pairs across 90 diverse real-world scenes. Our six tasks (counting, attribute identification, relative distance, relative direction, object manipulation, and camera pose estimation) specifically test model's geometric correspondence and the capacity to align information consistently across views. Our extensive experiments, benchmark on 27 representative MLLMs including Gemini-2.0-Flash, Claude-3.7-Sonnet, and GPT-4o against human evaluators reveals a substantial performance gap, indicating that current MLLMs remain far from human-level proficiency. Through in-depth analysis, we show that MLLMs are particularly underperforming under two aspects: (1) cross-view correspondence for partially occluded views and (2) establishing the coarse camera poses. These findings highlight the necessity of domain-specific refinements or modules that embed stronger multi-view awareness. We believe that our All-Angles Bench offers valuable insights and contribute to bridging the gap between MLLMs and human-level multi-view understanding. The project and benchmark are publicly available at", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2504.15280.pdf", "abstract_url": "https://arxiv.org/abs/2504.15280", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2504.14440", "title": "SG-Reg: Generalizable and Efficient Scene Graph Registration", "authors": ["Chuhao Liu", "Zhijian Qiao", "Jieqi Shi", "Ke Wang", "Peize Liu", "Shaojie Shen"], "abstract": "This paper addresses the challenges of registering two rigid semantic scene graphs, an essential capability when an autonomous agent needs to register its map against a remote agent, or against a prior map. The hand-crafted descriptors in classical semantic-aided registration, or the ground-truth annotation reliance in learning-based scene graph registration, impede their application in practical real-world environments. To address the challenges, we design a scene graph network to encode multiple modalities of semantic nodes: open-set semantic feature, local topology with spatial awareness, and shape feature. These modalities are fused to create compact semantic node features. The matching layers then search for correspondences in a coarse-to-fine manner. In the back-end, we employ a robust pose estimator to decide transformation according to the correspondences. We manage to maintain a sparse and hierarchical scene representation. Our approach demands fewer GPU resources and fewer communication bandwidth in multi-agent tasks. Moreover, we design a new data generation approach using vision foundation models and a semantic mapping module to reconstruct semantic scene graphs. It differs significantly from previous works, which rely on ground-truth semantic annotations to generate data. We validate our method in a two-agent SLAM benchmark. It significantly outperforms the hand-crafted baseline in terms of registration success rate. Compared to visual loop closure networks, our method achieves a slightly higher registration recall while requiring only 52 KB of communication bandwidth for each query frame. Code available at: \\href{", "subjects": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV)", "comments": "IEEE Transactions Robotics Regular Paper", "pdf_url": "https://arxiv.org/pdf/2504.14440.pdf", "abstract_url": "https://arxiv.org/abs/2504.14440", "categories": ["Robotics (cs.RO)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"]}
{"id": "2504.14112", "title": "Longitudinal Study on Social and Emotional Use of AI Conversational Agent", "authors": ["Mohit Chandra", "Javier Hernandez", "Gonzalo Ramos", "Mahsa Ershadi", "Ananya Bhattacharjee", "Judith Amores", "Ebele Okoli", "Ann Paradiso", "Shahed Warreth", "Jina Suh"], "abstract": "Development in digital technologies has continuously reshaped how individuals seek and receive social and emotional support. While online platforms and communities have long served this need, the increased integration of general-purpose conversational AI into daily lives has introduced new dynamics in how support is provided and experienced. Existing research has highlighted both benefits (e.g., wider access to well-being resources) and potential risks (e.g., over-reliance) of using AI for support seeking. In this five-week, exploratory study, we recruited 149 participants divided into two usage groups: a baseline usage group (BU, n=60) that used the internet and AI as usual, and an active usage group (AU, n=89) encouraged to use one of four commercially available AI tools (Microsoft Copilot, Google Gemini, PI AI, ChatGPT) for social and emotional interactions. Our analysis revealed significant increases in perceived attachment towards AI (32.99 percentage points), perceived AI empathy (25.8 p.p.), and motivation to use AI for entertainment (22.90 p.p.) among the AU group. We also observed that individual differences (e.g., gender identity, prior AI usage) influenced perceptions of AI empathy and attachment. Lastly, the AU group expressed higher comfort in seeking personal help, managing stress, obtaining social support, and talking about health with AI, indicating potential for broader emotional support while highlighting the need for safeguards against problematic usage. Overall, our exploratory findings underscore the importance of developing consumer-facing AI tools that support emotional well-being responsibly, while empowering users to understand the limitations of these tools.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "comments": "16 pages, 5 figures, 2 tables", "pdf_url": "https://arxiv.org/pdf/2504.14112.pdf", "abstract_url": "https://arxiv.org/abs/2504.14112", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)"], "matching_keywords": ["agent"]}
{"id": "2504.14259", "title": "Experience-based Refinement of Task Planning Knowledge in Autonomous Robots", "authors": ["Hadeel Jazzaa", "Thomas McCluskey", "David Peebles"], "abstract": "The requirement for autonomous robots to exhibit higher-level cognitive skills by planning and adapting in an ever-changing environment is indeed a great challenge for the AI community. Progress has been made in the automated planning community on refinement and repair of an agent's symbolic knowledge to do task planning in an incomplete or changing environmental model, but these advances up to now have not been transferred to real physical robots. This paper demonstrates how a physical robot can be capable of adapting its symbolic knowledge of the environment, by using experiences in robot action execution to drive knowledge refinement and hence to improve the success rate of the task plans the robot creates. To implement more robust planning systems, we propose a method for refining domain knowledge to improve the knowledge on which intelligent robot behavior is based. This architecture has been implemented and evaluated using a NAO robot. The refined knowledge leads to the future synthesis of task plans which demonstrate decreasing rates of failure over time as faulty knowledge is removed or adjusted.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.14259.pdf", "abstract_url": "https://arxiv.org/abs/2504.14259", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2504.14411", "title": "Planet as a Brain: Towards Internet of AgentSites based on AIOS Server", "authors": ["Xiang Zhang", "Yongfeng Zhang"], "abstract": "The internet is undergoing a historical transformation from the \"Internet of Websites\" to the \"Internet of AgentSites.\" While traditional Websites served as the foundation for information hosting and dissemination, a new frontier is emerging where AgentSites serve as the hubs of the internet, where each AgentSite hosts one or more AI agents that receive tasks, address them, and deliver actionable solutions, marking a significant shift in the digital landscape and representing the next generation of online ecosystems. Under this vision, AIOS, the AI Agent Operating System, serves as the server for the development, deployment and execution of AI agents, which is a fundamental infrastructure for the Internet of Agentsites.", "subjects": "Networking and Internet Architecture (cs.NI); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.14411.pdf", "abstract_url": "https://arxiv.org/abs/2504.14411", "categories": ["Networking and Internet Architecture (cs.NI)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2504.14427", "title": "Optimizing SIA Development: A Case Study in User-Centered Design for Estuary, a Multimodal Socially Interactive Agent Framework", "authors": ["Spencer Lin", "Miru Jun", "Basem Rizk", "Karen Shieh", "Scott Fisher", "Sharon Mozgai"], "abstract": "This case study presents our user-centered design model for Socially Intelligent Agent (SIA) development frameworks through our experience developing Estuary, an open source multimodal framework for building low-latency real-time socially interactive agents. We leverage the Rapid Assessment Process (RAP) to collect the thoughts of leading researchers in the field of SIAs regarding the current state of the art for SIA development as well as their evaluation of how well Estuary may potentially address current research gaps. We achieve this through a series of end-user interviews conducted by a fellow researcher in the community. We hope that the findings of our work will not only assist the continued development of Estuary but also guide the development of other future frameworks and technologies for SIAs.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.14427.pdf", "abstract_url": "https://arxiv.org/abs/2504.14427", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2504.14493", "title": "FinSage: A Multi-aspect RAG System for Financial Filings Question Answering", "authors": ["Xinyu Wang", "Jijun Chi", "Zhenghan Tai", "Tung Sum Thomas Kwok", "Muzhi Li", "Zhuhong Li", "Hailin He", "Yuchen Hua", "Peng Lu", "Suyuchen Wang", "Yihong Wu", "Jerry Huang", "Ling Zhou"], "abstract": "Leveraging large language models in real-world settings often entails a need to utilize domain-specific data and tools in order to follow the complex regulations that need to be followed for acceptable use. Within financial sectors, modern enterprises increasingly rely on Retrieval-Augmented Generation (RAG) systems to address complex compliance requirements in financial document workflows. However, existing solutions struggle to account for the inherent heterogeneity of data (e.g., text, tables, diagrams) and evolving nature of regulatory standards used in financial filings, leading to compromised accuracy in critical information extraction. We propose the FinSage framework as a solution, utilizing a multi-aspect RAG framework tailored for regulatory compliance analysis in multi-modal financial documents. FinSage introduces three innovative components: (1) a multi-modal pre-processing pipeline that unifies diverse data formats and generates chunk-level metadata summaries, (2) a multi-path sparse-dense retrieval system augmented with query expansion (HyDE) and metadata-aware semantic search, and (3) a domain-specialized re-ranking module fine-tuned via Direct Preference Optimization (DPO) to prioritize compliance-critical content. Extensive experiments demonstrate that FinSage achieves an impressive recall of 92.51% on 75 expert-curated questions derived from surpasses the best baseline method on the FinanceBench question answering datasets by 24.06% in accuracy. Moreover, FinSage has been successfully deployed as financial question-answering agent in online meetings, where it has already served more than 1,200 people.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.14493.pdf", "abstract_url": "https://arxiv.org/abs/2504.14493", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "@RAG"]}
{"id": "2504.14625", "title": "Towards Optimal Circuit Generation: Multi-Agent Collaboration Meets Collective Intelligence", "authors": ["Haiyan Qin", "Jiahao Feng", "Xiaotong Feng", "Wei W. Xing", "Wang Kang"], "abstract": "Large language models (LLMs) have transformed code generation, yet their application in hardware design produces gate counts 38\\%--1075\\% higher than human designs. We present CircuitMind, a multi-agent framework that achieves human-competitive efficiency through three key innovations: syntax locking (constraining generation to basic logic gates), retrieval-augmented generation (enabling knowledge-driven design), and dual-reward optimization (balancing correctness with efficiency). To evaluate our approach, we introduce TC-Bench, the first gate-level benchmark harnessing collective intelligence from the TuringComplete ecosystem -- a competitive circuit design platform with hundreds of thousands of players. Experiments show CircuitMind enables 55.6\\% of model implementations to match or exceed top-tier human experts in composite efficiency metrics. Most remarkably, our framework elevates the 14B Phi-4 model to outperform both GPT-4o mini and Gemini 2.0 Flash, achieving efficiency comparable to the top 25\\% of human experts without requiring specialized training. These innovations establish a new paradigm for hardware optimization where collaborative AI systems leverage collective human expertise to achieve optimal circuit designs. Our model, data, and code are open-source at", "subjects": "Hardware Architecture (cs.AR); Artificial Intelligence (cs.AI)", "comments": "9 pages, 6 figures", "pdf_url": "https://arxiv.org/pdf/2504.14625.pdf", "abstract_url": "https://arxiv.org/abs/2504.14625", "categories": ["Hardware Architecture (cs.AR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2504.14681", "title": "An LLM-enabled Multi-Agent Autonomous Mechatronics Design Framework", "authors": ["Zeyu Wang", "Frank P.-W. Lo", "Qian Chen", "Yongqi Zhang", "Chen Lin", "Xu Chen", "Zhenhua Yu", "Alexander J. Thompson", "Eric M. Yeatman", "Benny P. L. Lo"], "abstract": "Existing LLM-enabled multi-agent frameworks are predominantly limited to digital or simulated environments and confined to narrowly focused knowledge domain, constraining their applicability to complex engineering tasks that require the design of physical embodiment, cross-disciplinary integration, and constraint-aware reasoning. This work proposes a multi-agent autonomous mechatronics design framework, integrating expertise across mechanical design, optimization, electronics, and software engineering to autonomously generate functional prototypes with minimal direct human design input. Operating primarily through a language-driven workflow, the framework incorporates structured human feedback to ensure robust performance under real-world constraints. To validate its capabilities, the framework is applied to a real-world challenge involving autonomous water-quality monitoring and sampling, where traditional methods are labor-intensive and ecologically disruptive. Leveraging the proposed system, a fully functional autonomous vessel was developed with optimized propulsion, cost-effective electronics, and advanced control. The design process was carried out by specialized agents, including a high-level planning agent responsible for problem abstraction and dedicated agents for structural, electronics, control, and software development. This approach demonstrates the potential of LLM-based multi-agent systems to automate real-world engineering workflows and reduce reliance on extensive domain expertise.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": "Accepted by CVPR 2025 Workshop", "pdf_url": "https://arxiv.org/pdf/2504.14681.pdf", "abstract_url": "https://arxiv.org/abs/2504.14681", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2504.14757", "title": "SWE-Synth: Synthesizing Verifiable Bug-Fix Data to Enable Large Language Models in Resolving Real-World Bugs", "authors": ["Minh V.T. Pham", "Huy N. Phan", "Hoang N. Phan", "Cuong Le Chi", "Tien N. Nguyen", "Nghi D. Q. Bui"], "abstract": "Large language models (LLMs) are transforming automated program repair (APR) through agent-based approaches that localize bugs, generate patches, and verify fixes. However, the lack of high-quality, scalable training datasets, especially those with verifiable outputs and intermediate reasoning traces-limits progress, particularly for open-source models. In this work, we present SWE-Synth, a framework for synthesizing realistic, verifiable, and process-aware bug-fix datasets at the repository level. SWE-Synth leverages LLM agents to simulate debugging workflows, producing not only bug-fix pairs but also test cases and structured repair trajectories. Compared to manually curated datasets, our method scales with minimal human effort while preserving contextual richness and correctness. Experiments show that models trained on SWE-Synth outperform those trained on real-world datasets by 2.3% on SWE-Bench Lite. Our results highlight the potential of synthetic, agent-generated data to advance the state of the art in APR and software engineering automation.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": "Work in progress", "pdf_url": "https://arxiv.org/pdf/2504.14757.pdf", "abstract_url": "https://arxiv.org/abs/2504.14757", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2504.14779", "title": "Exploring Collaborative GenAI Agents in Synchronous Group Settings: Eliciting Team Perceptions and Design Considerations for the Future of Work", "authors": ["Janet G. Johnson", "Macarena Peralta", "Mansanjam Kaur", "Ruijie Sophia Huang", "Sheng Zhao", "Ruijia Guan", "Shwetha Rajaram", "Michael Nebeling"], "abstract": "While generative artificial intelligence (GenAI) is finding increased adoption in workplaces, current tools are primarily designed for individual use. Prior work established the potential for these tools to enhance personal creativity and productivity towards shared goals; however, we don't know yet how to best take into account the nuances of group work and team dynamics when deploying GenAI in work settings. In this paper, we investigate the potential of collaborative GenAI agents to augment teamwork in synchronous group settings through an exploratory study that engaged 25 professionals across 6 teams in speculative design workshops and individual follow-up interviews. Our workshops included a mixed reality provotype to simulate embodied collaborative GenAI agents capable of actively participating in group discussions. Our findings suggest that, if designed well, collaborative GenAI agents offer valuable opportunities to enhance team problem-solving by challenging groupthink, bridging communication gaps, and reducing social friction. However, teams' willingness to integrate GenAI agents depended on its perceived fit across a number of individual, team, and organizational factors. We outline the key design tensions around agent representation, social prominence, and engagement and highlight the opportunities spatial and immersive technologies could offer to modulate GenAI influence on team outcomes and strike a balance between augmentation and agency.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": "To be published in ACM Conference on Computer-Supported Cooperative Work and Social Computing (CSCW 2025). 33 pages, 11 figures, 1 table", "pdf_url": "https://arxiv.org/pdf/2504.14779.pdf", "abstract_url": "https://arxiv.org/abs/2504.14779", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2504.15099", "title": "Fast-Slow Co-advancing Optimizer: Toward Harmonious Adversarial Training of GAN", "authors": ["Lin Wang", "Xiancheng Wang", "Rui Wang", "Zhibo Zhang", "Minghang Zhao"], "abstract": "Up to now, the training processes of typical Generative Adversarial Networks (GANs) are still particularly sensitive to data properties and hyperparameters, which may lead to severe oscillations, difficulties in convergence, or even failures to converge, especially when the overall variances of the training sets are large. These phenomena are often attributed to the training characteristics of such networks. Aiming at the problem, this paper develops a new intelligent optimizer, Fast-Slow Co-advancing Optimizer (FSCO), which employs reinforcement learning in the training process of GANs to make training easier. Specifically, this paper allows the training step size to be controlled by an agent to improve training stability, and makes the training process more intelligent with variable learning rates, making GANs less sensitive to step size. Experiments have been conducted on three benchmark datasets to verify the effectiveness of the developed FSCO.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.15099.pdf", "abstract_url": "https://arxiv.org/abs/2504.15099", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2504.15130", "title": "Neural ATTF: A Scalable Solution to Lifelong Multi-Agent Path Planning", "authors": ["Kushal Shah", "Jihyun Park", "Seung-Kyum Choi"], "abstract": "Multi-Agent Pickup and Delivery (MAPD) is a fundamental problem in robotics, particularly in applications such as warehouse automation and logistics. Existing solutions often face challenges in scalability, adaptability, and efficiency, limiting their applicability in dynamic environments with real-time planning requirements. This paper presents Neural ATTF (Adaptive Task Token Framework), a new algorithm that combines a Priority Guided Task Matching (PGTM) Module with Neural STA* (Space-Time A*), a data-driven path planning method. Neural STA* enhances path planning by enabling rapid exploration of the search space through guided learned heuristics and ensures collision avoidance under dynamic constraints. PGTM prioritizes delayed agents and dynamically assigns tasks by prioritizing agents nearest to these tasks, optimizing both continuity and system throughput. Experimental evaluations against state-of-the-art MAPD algorithms, including TPTS, CENTRAL, RMCA, LNS-PBS, and LNS-wPBS, demonstrate the superior scalability, solution quality, and computational efficiency of Neural ATTF. These results highlight the framework's potential for addressing the critical demands of complex, real-world multi-agent systems operating in high-demand, unpredictable settings.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": "13 Pages, 5 Figures, 5 Tables", "pdf_url": "https://arxiv.org/pdf/2504.15130.pdf", "abstract_url": "https://arxiv.org/abs/2504.15130", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
