{"id": "2506.18920", "title": "Signal Use and Emergent Cooperation", "authors": ["Michael Williams"], "abstract": "In this work, we investigate how autonomous agents, organized into tribes, learn to use communication signals to coordinate their activities and enhance their collective efficiency. Using the NEC-DAC (Neurally Encoded Culture - Distributed Autonomous Communicators) system, where each agent is equipped with its own neural network for decision-making, we demonstrate how these agents develop a shared behavioral system -- akin to a culture -- through learning and signalling. Our research focuses on the self-organization of culture within these tribes of agents and how varying communication strategies impact their fitness and cooperation. By analyzing different social structures, such as authority hierarchies, we show that the culture of cooperation significantly influences the tribe's performance. Furthermore, we explore how signals not only facilitate the emergence of culture but also enable its transmission across generations of agents. Additionally, we examine the benefits of coordinating behavior and signaling within individual agents' neural networks.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multiagent Systems (cs.MA); Neural and Evolutionary Computing (cs.NE); Social and Information Networks (cs.SI)", "comments": "167 pages, 19 figures, PhD dissertation, UCLA, 2006", "pdf_url": "https://arxiv.org/pdf/2506.18920.pdf", "abstract_url": "https://arxiv.org/abs/2506.18920", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)", "Neural and Evolutionary Computing (cs.NE)", "Social and Information Networks (cs.SI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本研究探讨了自治代理如何通过通信信号协调活动并提高集体效率，使用NEC-DAC系统展示了代理如何通过学习和信号发展共享行为系统。", "motivation": "解决自治代理如何通过通信信号协调活动和提高集体效率的问题。", "method": "使用NEC-DAC系统，每个代理配备自己的神经网络进行决策，研究信号使用和文化自组织。", "result": "发现合作文化显著影响部落性能，信号不仅促进文化的出现，还支持其在代理世代间的传递。", "conclusion": "通信信号在自治代理中促进了文化的自组织和跨代传递，对集体效率和合作有重要影响。"}}
{"id": "2506.19488", "title": "SceneCrafter: Controllable Multi-View Driving Scene Editing", "authors": ["Zehao Zhu", "Yuliang Zou", "Chiyu Max Jiang", "Bo Sun", "Vincent Casser", "Xiukun Huang", "Jiahao Wang", "Zhenpei Yang", "Ruiqi Gao", "Leonidas Guibas", "Mingxing Tan", "Dragomir Anguelov"], "abstract": "Simulation is crucial for developing and evaluating autonomous vehicle (AV) systems. Recent literature builds on a new generation of generative models to synthesize highly realistic images for full-stack simulation. However, purely synthetically generated scenes are not grounded in reality and have difficulty in inspiring confidence in the relevance of its outcomes. Editing models, on the other hand, leverage source scenes from real driving logs, and enable the simulation of different traffic layouts, behaviors, and operating conditions such as weather and time of day. While image editing is an established topic in computer vision, it presents fresh sets of challenges in driving simulation: (1) the need for cross-camera 3D consistency, (2) learning ``empty street\" priors from driving data with foreground occlusions, and (3) obtaining paired image tuples of varied editing conditions while preserving consistent layout and geometry. To address these challenges, we propose SceneCrafter, a versatile editor for realistic 3D-consistent manipulation of driving scenes captured from multiple cameras. We build on recent advancements in multi-view diffusion models, using a fully controllable framework that scales seamlessly to multi-modality conditions like weather, time of day, agent boxes and high-definition maps. To generate paired data for supervising the editing model, we propose a novel framework on top of Prompt-to-Prompt to generate geometrically consistent synthetic paired data with global edits. We also introduce an alpha-blending framework to synthesize data with local edits, leveraging a model trained on empty street priors through novel masked training and multi-view repaint paradigm. SceneCrafter demonstrates powerful editing capabilities and achieves state-of-the-art realism, controllability, 3D consistency, and scene editing quality compared to existing baselines.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "CVPR 2025", "pdf_url": "https://arxiv.org/pdf/2506.19488.pdf", "abstract_url": "https://arxiv.org/abs/2506.19488", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "SceneCrafter是一种可控的多视角驾驶场景编辑工具，旨在解决自动驾驶系统仿真中的现实基础和3D一致性问题。", "motivation": "为了解决纯合成场景在自动驾驶仿真中缺乏现实基础和难以激发信心的问题，以及应对驾驶场景编辑中的跨相机3D一致性、学习‘空街’先验和获取配对图像元组等挑战。", "method": "基于多视角扩散模型的可控框架，结合Prompt-to-Prompt生成几何一致的合成配对数据，以及通过掩码训练和多视角重绘范式学习空街先验的alpha混合框架。", "result": "SceneCrafter在编辑能力、真实感、可控性、3D一致性和场景编辑质量方面达到了最先进的水平。", "conclusion": "SceneCrafter为驾驶场景的逼真3D一致操作提供了强大的编辑工具，推动了自动驾驶仿真技术的发展。"}}
{"id": "2506.19433", "title": "Mem4Nav: Boosting Vision-and-Language Navigation in Urban Environments with a Hierarchical Spatial-Cognition Long-Short Memory System", "authors": ["Lixuan He", "Haoyu Dong", "Zhenxing Chen", "Yangcheng Yu", "Jie Feng", "Yong Li"], "abstract": "Vision-and-Language Navigation (VLN) in large-scale urban environments requires embodied agents to ground linguistic instructions in complex scenes and recall relevant experiences over extended time horizons. Prior modular pipelines offer interpretability but lack unified memory, while end-to-end (M)LLM agents excel at fusing vision and language yet remain constrained by fixed context windows and implicit spatial reasoning. We introduce \\textbf{Mem4Nav}, a hierarchical spatial-cognition long-short memory system that can augment any VLN backbone. Mem4Nav fuses a sparse octree for fine-grained voxel indexing with a semantic topology graph for high-level landmark connectivity, storing both in trainable memory tokens embedded via a reversible Transformer. Long-term memory (LTM) compresses and retains historical observations at both octree and graph nodes, while short-term memory (STM) caches recent multimodal entries in relative coordinates for real-time obstacle avoidance and local planning. At each step, STM retrieval sharply prunes dynamic context, and, when deeper history is needed, LTM tokens are decoded losslessly to reconstruct past embeddings. Evaluated on Touchdown and Map2Seq across three backbones (modular, state-of-the-art VLN with prompt-based LLM, and state-of-the-art VLN with strided-attention MLLM), Mem4Nav yields 7-13 pp gains in Task Completion, sufficient SPD reduction, and >10 pp nDTW improvement. Ablations confirm the indispensability of both the hierarchical map and dual memory modules. Our codes are open-sourced via", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.19433.pdf", "abstract_url": "https://arxiv.org/abs/2506.19433", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "Mem4Nav是一种分层空间认知长短记忆系统，旨在提升大规模城市环境中的视觉与语言导航（VLN）能力。它通过结合稀疏八叉树和语义拓扑图，以及可训练的记忆令牌，有效地融合了长期和短期记忆，显著提高了任务完成率和导航效率。", "motivation": "解决在大规模城市环境中进行视觉与语言导航时，现有方法因缺乏统一记忆或固定上下文窗口限制而面临的挑战。", "method": "引入Mem4Nav系统，结合稀疏八叉树进行细粒度体素索引和语义拓扑图进行高级地标连接，使用可逆Transformer嵌入记忆令牌，实现长期记忆（LTM）和短期记忆（STM）的有效融合。", "result": "在Touchdown和Map2Seq数据集上，Mem4Nav在三种不同骨干网络上的任务完成率提高了7-13个百分点，显著降低了SPD，并提高了超过10个百分点的nDTW。", "conclusion": "Mem4Nav通过其分层地图和双记忆模块，显著提升了VLN在复杂城市环境中的性能，证明了这两种模块的不可或缺性。"}}
{"id": "2506.19209", "title": "Augmenting Multi-Agent Communication with State Delta Trajectory", "authors": ["Yichen Tang", "Weihang Su", "Yujia Zhou", "Yiqun Liu", "Min Zhang", "Shaoping Ma", "Qingyao Ai"], "abstract": "Multi-agent techniques such as role playing or multi-turn debates have been shown to be effective in improving the performance of large language models (LLMs) in downstream tasks. Despite their differences in workflows, existing LLM-based multi-agent systems mostly use natural language for agent communication. While this is appealing for its simplicity and interpretability, it also introduces inevitable information loss as one model must down sample its continuous state vectors to concrete tokens before transferring them to the other model. Such losses are particularly significant when the information to transfer is not simple facts, but reasoning logics or abstractive thoughts. To tackle this problem, we propose a new communication protocol that transfers both natural language tokens and token-wise state transition trajectory from one agent to another. Particularly, compared to the actual state value, we find that the sequence of state changes in LLMs after generating each token can better reflect the information hidden behind the inference process, so we propose a State Delta Encoding (SDE) method to represent state transition trajectories. The experimental results show that multi-agent systems with SDE achieve SOTA performance compared to other communication protocols, particularly in tasks that involve complex reasoning. This shows the potential of communication augmentation for LLM-based multi-agent systems.", "subjects": "Computation and Language (cs.CL)", "comments": "22 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2506.19209.pdf", "abstract_url": "https://arxiv.org/abs/2506.19209", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新的多智能体通信协议，通过传输自然语言令牌和令牌间状态转换轨迹来减少信息损失，特别是在涉及复杂推理的任务中，使用状态增量编码（SDE）方法的多智能体系统实现了最先进的性能。", "motivation": "现有的基于大型语言模型（LLMs）的多智能体系统大多使用自然语言进行智能体间通信，虽然简单且可解释，但在传输推理逻辑或抽象思维时会导致不可避免的信息损失。", "method": "提出了一种新的通信协议，该协议传输自然语言令牌和令牌间状态转换轨迹，并引入了状态增量编码（SDE）方法来表示状态转换轨迹。", "result": "实验结果表明，使用SDE的多智能体系统在涉及复杂推理的任务中，相比其他通信协议实现了最先进的性能。", "conclusion": "这项研究表明，通信增强对于基于LLM的多智能体系统具有潜在的重要价值，特别是在需要复杂推理的任务中。"}}
{"id": "2506.18957", "title": "A Comment On \"The Illusion of Thinking\": Reframing the Reasoning Cliff as an Agentic Gap", "authors": ["Sheraz Khan", "Subha Madhavan", "Kannan Natarajan"], "abstract": "The recent work by Shojaee et al. (2025), titled The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity, presents a compelling empirical finding, a reasoning cliff, where the performance of Large Reasoning Models (LRMs) collapses beyond a specific complexity threshold, which the authors posit as an intrinsic scaling limitation of Chain-of-Thought (CoT) reasoning. This commentary, while acknowledging the study's methodological rigor, contends that this conclusion is confounded by experimental artifacts. We argue that the observed failure is not evidence of a fundamental cognitive boundary, but rather a predictable outcome of system-level constraints in the static, text-only evaluation paradigm, including tool use restrictions, context window recall issues, the absence of crucial cognitive baselines, inadequate statistical reporting, and output generation limits. We reframe this performance collapse through the lens of an agentic gap, asserting that the models are not failing at reasoning, but at execution within a profoundly restrictive interface. We empirically substantiate this critique by demonstrating a striking reversal. A model, initially declaring a puzzle impossible when confined to text-only generation, now employs agentic tools to not only solve it but also master variations of complexity far beyond the reasoning cliff it previously failed to surmount. Additionally, our empirical analysis of tool-enabled models like o4-mini and GPT-4o reveals a hierarchy of agentic reasoning, from simple procedural execution to complex meta-cognitive self-correction, which has significant implications for how we define and measure machine intelligence. The illusion of thinking attributed to LRMs is less a reasoning deficit and more a consequence of an otherwise capable mind lacking the tools for action.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": ")", "pdf_url": "https://arxiv.org/pdf/2506.18957.pdf", "abstract_url": "https://arxiv.org/abs/2506.18957", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "对Shojaee等人（2025年）提出的'思维幻觉'研究进行评论，认为其发现的推理模型性能崩溃并非根本认知限制，而是实验范式限制的结果。通过引入代理工具，模型能够解决之前无法完成的复杂问题，揭示了代理推理的层次结构。", "motivation": "解决对大型推理模型（LRMs）性能崩溃现象的错误解释，指出这是由于实验设计的限制而非模型本身的推理能力缺陷。", "method": "通过实证分析，使用代理工具扩展模型的执行能力，对比静态文本评估范式下的表现差异。", "result": "展示了模型在引入代理工具后能够解决之前无法完成的复杂问题，揭示了从简单程序执行到复杂元认知自我修正的代理推理层次。", "conclusion": "认为所谓的'思维幻觉'更多是由于执行工具的限制而非推理能力的缺乏，这对如何定义和测量机器智能有重要影响。"}}
{"id": "2506.19191", "title": "Bayesian Evolutionary Swarm Architecture: A Formal Epistemic System Grounded in Truth-Based Competition", "authors": ["Craig Steven Wright"], "abstract": "We introduce a mathematically rigorous framework for an artificial intelligence system composed of probabilistic agents evolving through structured competition and belief revision. The architecture, grounded in Bayesian inference, measure theory, and population dynamics, defines agent fitness as a function of alignment with a fixed external oracle representing ground truth. Agents compete in a discrete-time environment, adjusting posterior beliefs through observed outcomes, with higher-rated agents reproducing and lower-rated agents undergoing extinction. Ratings are updated via pairwise truth-aligned utility comparisons, and belief updates preserve measurable consistency and stochastic convergence. We introduce hash-based cryptographic identity commitments to ensure traceability, alongside causal inference operators using do-calculus. Formal theorems on convergence, robustness, and evolutionary stability are provided. The system establishes truth as an evolutionary attractor, demonstrating that verifiable knowledge arises from adversarial epistemic pressure within a computable, self-regulating swarm.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Science and Game Theory (cs.GT); Logic (math.LO)", "comments": "83 pages, 14 sections, 92 formal results, no prior conference publication", "pdf_url": "https://arxiv.org/pdf/2506.19191.pdf", "abstract_url": "https://arxiv.org/abs/2506.19191", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Computer Science and Game Theory (cs.GT)", "Logic (math.LO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一个基于贝叶斯推理、测度论和种群动力学的数学严谨的人工智能系统框架，该系统通过结构化竞争和信念修订使概率代理进化。", "motivation": "解决如何在人工智能系统中通过竞争和信念修订来实现代理的进化，以及如何确保这些代理的信念与外部真理对齐的问题。", "method": "使用贝叶斯推理、测度论和种群动力学，定义代理的适应度为其与固定外部真理对齐的函数，通过观察结果调整后验信念，并通过成对真理对齐的效用比较更新评级。", "result": "系统证明了真理作为一个进化吸引子，表明可验证的知识来自于可计算的、自我调节的群体中的对抗性认知压力。", "conclusion": "该架构为人工智能系统提供了一个数学严谨的框架，通过竞争和信念修订实现代理的进化，并确保其信念与真理对齐，具有收敛性、鲁棒性和进化稳定性的形式定理支持。"}}
{"id": "2506.19385", "title": "Conversational Intent-Driven GraphRAG: Enhancing Multi-Turn Dialogue Systems through Adaptive Dual-Retrieval of Flow Patterns and Context Semantics", "authors": ["Ziqi Zhu", "Tao Hu", "Honglong Zhang", "Dan Yang", "HanGeng Chen", "Mengran Zhang", "Xilun Chen"], "abstract": "We present CID-GraphRAG (Conversational Intent-Driven Graph Retrieval Augmented Generation), a novel framework that addresses the limitations of existing dialogue systems in maintaining both contextual coherence and goal-oriented progression in multi-turn customer service conversations. Unlike traditional RAG systems that rely solely on semantic similarity (Conversation RAG) or standard knowledge graphs (GraphRAG), CID-GraphRAG constructs dynamic intent transition graphs from goal achieved historical dialogues and implements a dual-retrieval mechanism that adaptively balances intent-based graph traversal with semantic search. This approach enables the system to simultaneously leverage both conversional intent flow patterns and contextual semantics, significantly improving retrieval quality and response quality. In extensive experiments on real-world customer service dialogues, we employ both automatic metrics and LLM-as-judge assessments, demonstrating that CID-GraphRAG significantly outperforms both semantic-based Conversation RAG and intent-based GraphRAG baselines across all evaluation criteria. Quantitatively, CID-GraphRAG demonstrates substantial improvements over Conversation RAG across automatic metrics, with relative gains of 11% in BLEU, 5% in ROUGE-L, 6% in METEOR, and most notably, a 58% improvement in response quality according to LLM-as-judge evaluations. These results demonstrate that the integration of intent transition structures with semantic retrieval creates a synergistic effect that neither approach achieves independently, establishing CID-GraphRAG as an effective framework for addressing the challenges of maintaining contextual coherence and goal-oriented progression in knowledge-intensive multi-turn dialogues.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.19385.pdf", "abstract_url": "https://arxiv.org/abs/2506.19385", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "CID-GraphRAG是一种新型对话系统框架，通过动态意图转移图和双重检索机制，有效结合对话意图流模式和上下文语义，显著提升多轮客户服务对话的连贯性和目标导向性。", "motivation": "解决现有对话系统在多轮客户服务对话中保持上下文连贯性和目标导向性的局限性。", "method": "构建动态意图转移图，并实施双重检索机制，自适应地平衡基于意图的图遍历与语义搜索。", "result": "在真实世界客户服务对话的广泛实验中，CID-GraphRAG在自动指标和LLM-as-judge评估中均显著优于基于语义的Conversation RAG和基于意图的GraphRAG基线。", "conclusion": "意图转移结构与语义检索的整合产生了协同效应，为知识密集型多轮对话中的上下文连贯性和目标导向性挑战提供了有效解决方案。"}}
{"id": "2506.19290", "title": "Skywork-SWE: Unveiling Data Scaling Laws for Software Engineering in LLMs", "authors": ["Liang Zeng", "Yongcong Li", "Yuzhen Xiao", "Changshi Li", "Chris Yuhao Liu", "Rui Yan", "Tianwen Wei", "Jujie He", "Xuchen Song", "Yang Liu", "Yahui Zhou"], "abstract": "Software engineering (SWE) has recently emerged as a crucial testbed for next-generation LLM agents, demanding inherent capabilities in two critical dimensions: sustained iterative problem-solving (e.g., >50 interaction rounds) and long-context dependency resolution (e.g., >32k tokens). However, the data curation process in SWE remains notoriously time-consuming, as it heavily relies on manual annotation for code file filtering and the setup of dedicated runtime environments to execute and validate unit tests. Consequently, most existing datasets are limited to only a few thousand GitHub-sourced instances. To this end, we propose an incremental, automated data-curation pipeline that systematically scales both the volume and diversity of SWE datasets. Our dataset comprises 10,169 real-world Python task instances from 2,531 distinct GitHub repositories, each accompanied by a task specified in natural language and a dedicated runtime-environment image for automated unit-test validation. We have carefully curated over 8,000 successfully runtime-validated training trajectories from our proposed SWE dataset. When fine-tuning the Skywork-SWE model on these trajectories, we uncover a striking data scaling phenomenon: the trained model's performance for software engineering capabilities in LLMs continues to improve as the data size increases, showing no signs of saturation. Notably, our Skywork-SWE model achieves 38.0% pass@1 accuracy on the SWE-bench Verified benchmark without using verifiers or multiple rollouts, establishing a new state-of-the-art (SOTA) among the Qwen2.5-Coder-32B-based LLMs built on the OpenHands agent framework. Furthermore, with the incorporation of test-time scaling techniques, the performance further improves to 47.0% accuracy, surpassing the previous SOTA results for sub-32B parameter models. We release the Skywork-SWE-32B model checkpoint to accelerate future research.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.19290.pdf", "abstract_url": "https://arxiv.org/abs/2506.19290", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了Skywork-SWE，一个用于软件工程(LLMs)的数据扩展法则的研究，通过自动化数据整理流程扩大数据集规模和多样性，揭示了模型性能随数据量增加而持续提升的现象，并在SWE-bench Verified基准测试中创下新纪录。", "motivation": "解决软件工程(LLMs)中数据整理过程耗时且依赖手动标注的问题，以及现有数据集规模有限的问题。", "method": "提出了一种增量式、自动化的数据整理流程，系统性地扩大了软件工程数据集的规模和多样性，并在此基础上训练了Skywork-SWE模型。", "result": "Skywork-SWE模型在SWE-bench Verified基准测试中达到了38.0%的pass@1准确率，使用测试时扩展技术后进一步提升至47.0%，创下了基于OpenHands代理框架的Qwen2.5-Coder-32B LLMs的新纪录。", "conclusion": "研究表明，软件工程能力的LLM模型性能随着数据量的增加而持续提升，未出现饱和迹象，Skywork-SWE模型的发布将加速未来研究。"}}
{"id": "2506.19408", "title": "Is an object-centric representation beneficial for robotic manipulation ?", "authors": ["Alexandre Chapin", "Emmanuel Dellandrea", "Liming Chen"], "abstract": "Object-centric representation (OCR) has recently become a subject of interest in the computer vision community for learning a structured representation of images and videos. It has been several times presented as a potential way to improve data-efficiency and generalization capabilities to learn an agent on downstream tasks. However, most existing work only evaluates such models on scene decomposition, without any notion of reasoning over the learned representation. Robotic manipulation tasks generally involve multi-object environments with potential inter-object interaction. We thus argue that they are a very interesting playground to really evaluate the potential of existing object-centric work. To do so, we create several robotic manipulation tasks in simulated environments involving multiple objects (several distractors, the robot, etc.) and a high-level of randomization (object positions, colors, shapes, background, initial positions, etc.). We then evaluate one classical object-centric method across several generalization scenarios and compare its results against several state-of-the-art hollistic representations. Our results exhibit that existing methods are prone to failure in difficult scenarios involving complex scene structures, whereas object-centric methods help overcome these challenges.", "subjects": "Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.19408.pdf", "abstract_url": "https://arxiv.org/abs/2506.19408", "categories": ["Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了对象中心表示（OCR）在机器人操作任务中的潜在益处，通过创建多个模拟环境中的机器人操作任务来评估OCR方法的性能，并与整体表示方法进行比较。", "motivation": "解决在机器人操作任务中，如何通过对象中心表示提高数据效率和泛化能力的问题。", "method": "创建了涉及多个对象和高度随机化的机器人操作任务，评估了一种经典的对象中心方法在多个泛化场景中的表现，并与几种最先进的整体表示方法进行比较。", "result": "结果表明，在涉及复杂场景结构的困难场景中，现有方法容易失败，而对象中心方法有助于克服这些挑战。", "conclusion": "对象中心表示在机器人操作任务中具有潜在的优势，尤其是在处理复杂场景和多对象交互时，能够提供更好的泛化能力和数据效率。"}}
{"id": "2506.19639", "title": "HOIverse: A Synthetic Scene Graph Dataset With Human Object Interactions", "authors": ["Mrunmai Vivek Phatak", "Julian Lorenz", "Nico Hörmann", "Jörg Hähner", "Rainer Lienhart"], "abstract": "When humans and robotic agents coexist in an environment, scene understanding becomes crucial for the agents to carry out various downstream tasks like navigation and planning. Hence, an agent must be capable of localizing and identifying actions performed by the human. Current research lacks reliable datasets for performing scene understanding within indoor environments where humans are also a part of the scene. Scene Graphs enable us to generate a structured representation of a scene or an image to perform visual scene understanding. To tackle this, we present HOIverse a synthetic dataset at the intersection of scene graph and human-object interaction, consisting of accurate and dense relationship ground truths between humans and surrounding objects along with corresponding RGB images, segmentation masks, depth images and human keypoints. We compute parametric relations between various pairs of objects and human-object pairs, resulting in an accurate and unambiguous relation definitions. In addition, we benchmark our dataset on state-of-the-art scene graph generation models to predict parametric relations and human-object interactions. Through this dataset, we aim to accelerate research in the field of scene understanding involving people.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.19639.pdf", "abstract_url": "https://arxiv.org/abs/2506.19639", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "HOIverse是一个合成场景图数据集，专注于人类与物体的交互，旨在促进涉及人类的场景理解研究。", "motivation": "当前研究缺乏在室内环境中进行场景理解的可靠数据集，特别是在人类也是场景一部分的情况下。", "method": "通过生成场景的结构化表示（场景图），HOIverse提供了RGB图像、分割掩码、深度图像和人体关键点，以及人类与周围物体之间的准确密集关系地面真实。", "result": "数据集包含了各种物体对和人类-物体对的参数化关系，提供了准确且无歧义的关系定义，并在最先进的场景图生成模型上进行了基准测试。", "conclusion": "HOIverse数据集旨在加速涉及人类的场景理解领域的研究，特别是在导航和规划等下游任务中。"}}
{"id": "2506.19484", "title": "Dialogic Pedagogy for Large Language Models: Aligning Conversational AI with Proven Theories of Learning", "authors": ["Russell Beale"], "abstract": "Large Language Models (LLMs) are rapidly transforming education by enabling rich conversational learning experiences. This article provides a comprehensive review of how LLM-based conversational agents are being used in higher education, with extensions to secondary and lifelong learning contexts. We synthesize existing literature on LLMs in education and theories of conversational and dialogic pedagogy - including Vygotsky's sociocultural learning (scaffolding and the Zone of Proximal Development), the Socratic method, and Laurillard's conversational framework - and examine how prompting strategies and retrieval-augmented generation (RAG) can align LLM behaviors with these pedagogical theories, and how it can support personalized, adaptive learning. We map educational theories to LLM capabilities, highlighting where LLM-driven dialogue supports established learning principles and where it challenges or falls short of traditional pedagogical assumptions. Notable gaps in applying prior theories to LLMs are identified, such as the models tendency to provide direct answers instead of fostering co-construction of knowledge, and the need to account for the constant availability and broad but non-human expertise of LLM tutors. In response, we propose practical strategies to better align LLM interactions with sound pedagogy - for example, designing prompts that encourage Socratic questioning, scaffolded guidance, and student reflection, as well as integrating retrieval mechanisms to ensure accuracy and contextual relevance. Our aim is to bridge the gap between educational theory and the emerging practice of AI-driven conversational learning, offering insights and tools for making LLM-based dialogues more educationally productive and theory-aligned.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.19484.pdf", "abstract_url": "https://arxiv.org/abs/2506.19484", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文综述了大型语言模型（LLMs）在高等教育中的应用，并扩展到中等和终身学习环境，探讨了如何通过对话和对话教学理论（如维果茨基的社会文化学习、苏格拉底方法和劳里拉德的对话框架）来调整LLM行为，以支持个性化和适应性学习。", "motivation": "解决LLMs在教育应用中如何更好地与传统教学理论对齐，特别是在促进知识共建和适应非人类专家的LLM导师方面存在的挑战。", "method": "通过综合现有文献和教学理论，分析LLM能力与教育理论的对应关系，提出如设计鼓励苏格拉底式提问、支架式指导和学生反思的提示策略，以及整合检索机制以确保准确性和上下文相关性。", "result": "识别了将先前理论应用于LLMs的显著差距，并提出了实际策略以更好地将LLM互动与健全的教学法对齐。", "conclusion": "旨在弥合教育理论与AI驱动对话学习新兴实践之间的差距，提供见解和工具，使基于LLM的对话更具教育生产力和理论对齐性。"}}
{"id": "2506.19512", "title": "heiDS at ArchEHR-QA 2025: From Fixed-k to Query-dependent-k for Retrieval Augmented Generation", "authors": ["Ashish Chouhan", "Michael Gertz"], "abstract": "This paper presents the approach of our team called heiDS for the ArchEHR-QA 2025 shared task. A pipeline using a retrieval augmented generation (RAG) framework is designed to generate answers that are attributed to clinical evidence from the electronic health records (EHRs) of patients in response to patient-specific questions. We explored various components of a RAG framework, focusing on ranked list truncation (RLT) retrieval strategies and attribution approaches. Instead of using a fixed top-k RLT retrieval strategy, we employ a query-dependent-k retrieval strategy, including the existing surprise and autocut methods and two new methods proposed in this work, autocut* and elbow. The experimental results show the benefits of our strategy in producing factual and relevant answers when compared to a fixed-$k$.", "subjects": "Computation and Language (cs.CL)", "comments": "12 pages, 2 figures, 6 tables, Workshop on BioNLP and Shared Tasks at ACL 2025", "pdf_url": "https://arxiv.org/pdf/2506.19512.pdf", "abstract_url": "https://arxiv.org/abs/2506.19512", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了团队heiDS在ArchEHR-QA 2025共享任务中的方法，设计了一个使用检索增强生成（RAG）框架的流程，旨在根据患者特定的问题，从电子健康记录（EHRs）中生成归因于临床证据的答案。", "motivation": "解决在电子健康记录（EHRs）中为患者特定问题生成准确且相关答案的挑战，特别是在检索增强生成（RAG）框架中如何更有效地选择和利用检索到的信息。", "method": "采用查询依赖的k检索策略，包括现有的surprise和autocut方法，以及本文提出的两种新方法autocut*和elbow，替代传统的固定top-k检索策略。", "result": "实验结果表明，与固定k策略相比，我们的策略在生成事实性和相关性更强的答案方面具有优势。", "conclusion": "查询依赖的k检索策略在检索增强生成框架中展现出潜力，能够提高生成答案的质量和相关性，特别是在处理电子健康记录时。"}}
{"id": "2506.19527", "title": "KnowMap: Efficient Knowledge-Driven Task Adaptation for LLMs", "authors": ["Kelin Fu", "Kaigui Bian"], "abstract": "While Large Language Models (LLMs) possess significant capabilities in open-world agent tasks, they also face challenges in rapidly adapting to new, specialized tasks due to their reliance on static pre-trained knowledge. Traditional methods such as fine-tuning are often costly, data-intensive, and may lead to \"catastrophic forgetting.\" Therefore, we present KnowMap, a novel approach that dynamically constructs a knowledge base from environmental and experiential data. KnowMap fine-tunes a small knowledge-embedding model to equip a larger LLM with valuable task-specific knowledge. Our experiments on the ScienceWorld benchmark demonstrate 17.71% improvement for the performance of gpt-4-turbo model. KnowMap not only provides an efficient and effective means for LLM task-adapting, but also highlights how integrating environmental and experiential knowledge can enhance LLMs' reasoning capabilities.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.19527.pdf", "abstract_url": "https://arxiv.org/abs/2506.19527", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "KnowMap是一种新颖的方法，通过动态构建知识库来增强大型语言模型（LLM）的任务适应能力，特别是在科学世界基准测试中展示了显著的性能提升。", "motivation": "解决大型语言模型在快速适应新的、专业化任务时面临的挑战，如依赖静态预训练知识和传统微调方法的高成本、数据密集性及可能导致‘灾难性遗忘’的问题。", "method": "动态构建来自环境和经验数据的知识库，并微调一个小型知识嵌入模型，以赋予更大的LLM有价值的任务特定知识。", "result": "在ScienceWorld基准测试中，gpt-4-turbo模型的性能提高了17.71%。", "conclusion": "KnowMap不仅为LLM任务适应提供了一种高效有效的方法，还强调了整合环境和经验知识如何增强LLMs的推理能力。"}}
{"id": "2506.19420", "title": "Commander-GPT: Dividing and Routing for Multimodal Sarcasm Detection", "authors": ["Yazhou Zhang", "Chunwang Zou", "Bo Wang", "Jing Qin"], "abstract": "Multimodal sarcasm understanding is a high-order cognitive task. Although large language models (LLMs) have shown impressive performance on many downstream NLP tasks, growing evidence suggests that they struggle with sarcasm understanding. In this paper, we propose Commander-GPT, a modular decision routing framework inspired by military command theory. Rather than relying on a single LLM's capability, Commander-GPT orchestrates a team of specialized LLM agents where each agent will be selectively assigned to a focused sub-task such as context modeling, sentiment analysis, etc. Their outputs are then routed back to the commander, which integrates the information and performs the final sarcasm judgment. To coordinate these agents, we introduce three types of centralized commanders: (1) a trained lightweight encoder-based commander (e.g., multi-modal BERT); (2) four small autoregressive language models, serving as moderately capable commanders (e.g., DeepSeek-VL); (3) two large LLM-based commander (Gemini Pro and GPT-4o) that performs task routing, output aggregation, and sarcasm decision-making in a zero-shot fashion. We evaluate Commander-GPT on the MMSD and MMSD 2.0 benchmarks, comparing five prompting strategies. Experimental results show that our framework achieves 4.4% and 11.7% improvement in F1 score over state-of-the-art (SoTA) baselines on average, demonstrating its effectiveness.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.19420.pdf", "abstract_url": "https://arxiv.org/abs/2506.19420", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了Commander-GPT，一个受军事指挥理论启发的模块化决策路由框架，用于多模态讽刺检测。通过协调一组专门的LLM代理，每个代理专注于特定的子任务，如上下文建模、情感分析等，然后将输出路由回指挥官进行最终判断。实验结果表明，该框架在MMSD和MMSD 2.0基准测试中优于现有技术。", "motivation": "尽管大型语言模型（LLMs）在许多下游NLP任务上表现出色，但越来越多的证据表明它们在讽刺理解方面存在困难。本文旨在解决这一问题。", "method": "提出了Commander-GPT框架，通过协调一组专门的LLM代理，每个代理专注于特定的子任务，如上下文建模、情感分析等，然后将输出路由回指挥官进行最终判断。引入了三种类型的集中指挥官来协调这些代理。", "result": "在MMSD和MMSD 2.0基准测试中，Commander-GPT框架的平均F1分数比现有技术提高了4.4%和11.7%。", "conclusion": "Commander-GPT框架通过模块化决策路由和多代理协作，有效提高了多模态讽刺检测的性能，为复杂认知任务的解决提供了新思路。"}}
{"id": "2506.19466", "title": "KunLunBaizeRAG: Reinforcement Learning Driven Inference Performance Leap for Large Language Models", "authors": ["Cheng Li", "Jiexiong Liu", "Yixuan Chen", "Qihang Zhou", "KunLun Meta"], "abstract": "This paper introduces KunLunBaizeRAG, a reinforcement learning-driven reasoning framework designed to enhance the reasoning capabilities of large language models (LLMs) in complex multi-hop question-answering tasks. The framework addresses key limitations of traditional RAG, such as retrieval drift, information redundancy, and strategy rigidity. Key innovations include the RAG-driven Reasoning Alignment (RDRA) mechanism, the Search-Think Iterative Enhancement (STIE) mechanism, the Network-Local Intelligent Routing (NLR) mechanism, and a progressive hybrid training strategy. Experimental results demonstrate significant improvements in exact match (EM) and LLM-judged score (LJ) across four benchmarks, highlighting the framework's robustness and effectiveness in complex reasoning scenarios.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.19466.pdf", "abstract_url": "https://arxiv.org/abs/2506.19466", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了KunLunBaizeRAG，一个基于强化学习的推理框架，旨在提升大型语言模型在复杂多跳问答任务中的推理能力。", "motivation": "解决传统RAG在检索漂移、信息冗余和策略刚性等方面的关键限制。", "method": "采用了RAG驱动的推理对齐(RDRA)机制、搜索-思考迭代增强(STIE)机制、网络-本地智能路由(NLR)机制以及渐进式混合训练策略。", "result": "实验结果显示，在四个基准测试中，精确匹配(EM)和LLM评判分数(LJ)有显著提升，证明了该框架在复杂推理场景中的鲁棒性和有效性。", "conclusion": "KunLunBaizeRAG框架通过创新的机制和策略，显著提升了大型语言模型在复杂推理任务中的性能。"}}
{"id": "2506.19500", "title": "NaviAgent: Bilevel Planning on Tool Dependency Graphs for Function Calling", "authors": ["Yan Jiang", "Hao Zhou", "LiZhong GU", "Ai Han", "TianLong Li"], "abstract": "LLMs' reliance on static knowledge and fragile tool invocation severely hinders the orchestration of complex, heterogeneous toolchains, particularly at large scales. Existing methods typically use rigid single-path execution, resulting in poor error recovery and exponentially growing search spaces. We introduce NaviAgent, a graph-navigated bilevel planning architecture for robust function calling, comprising a Multi-Path Decider and Graph-Encoded Navigator. As an LLM-powered agent, the Multi-Path Decider defines a four-dimensional decision space and continuously perceives environmental states, dynamically selecting the optimal action to fully cover all tool invocation scenarios. The Graph-Encoded Navigator constructs a Tool Dependency Heterogeneous Graph (TDHG), where node embeddings explicitly fuse API schema structure with historical invocation behavior. It also integrates a novel heuristic search strategy that guides the Decider toward efficient and highly successful toolchains, even for unseen tool combinations. Experiments show that NaviAgent consistently achieves the highest task success rate (TSR) across all foundation models and task complexities, outperforming the average baselines (ReAct, ToolLLM, {\\alpha}-UMI) by 13.5%, 16.4%, and 19.0% on Qwen2.5-14B, Qwen2.5-32B, and Deepseek-V3, respectively. Its execution steps are typically within one step of the most efficient baseline, ensuring a strong balance between quality and efficiency. Notably, a fine-tuned Qwen2.5-14B model achieves a TSR of 49.5%, surpassing the much larger 32B model (44.9%) under our architecture. Incorporating the Graph-Encoded Navigator further boosts TSR by an average of 2.4 points, with gains up over 9 points on complex tasks for larger models (Deepseek-V3 and GPT-4o), highlighting its essential role in toolchain orchestration.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.19500.pdf", "abstract_url": "https://arxiv.org/abs/2506.19500", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "NaviAgent是一种基于图导航的双层规划架构，旨在提高大型语言模型（LLMs）在复杂、异构工具链编排中的鲁棒性和效率。通过多路径决策器和图编码导航器的结合，NaviAgent在任务成功率上显著优于现有基线方法。", "motivation": "解决LLMs在静态知识和脆弱工具调用上的依赖问题，这些问题严重阻碍了复杂、异构工具链的编排，尤其是在大规模场景下。现有方法通常采用单一路径执行，导致错误恢复能力差和搜索空间指数级增长。", "method": "引入NaviAgent，一个图导航的双层规划架构，包括多路径决策器和图编码导航器。多路径决策器定义四维决策空间并动态选择最优动作；图编码导航器构建工具依赖异构图（TDHG），并集成启发式搜索策略。", "result": "NaviAgent在所有基础模型和任务复杂度上均实现了最高的任务成功率（TSR），平均比基线方法（ReAct、ToolLLM、α-UMI）高出13.5%、16.4%和19.0%。图编码导航器的加入进一步平均提升了2.4个百分点的TSR。", "conclusion": "NaviAgent通过其双层规划架构和工具依赖异构图，显著提高了LLMs在复杂工具链编排中的性能和效率，特别是在处理未见工具组合时表现出色。"}}
{"id": "2506.19592", "title": "Adaptive Domain Modeling with Language Models: A Multi-Agent Approach to Task Planning", "authors": ["Harisankar Babu", "Philipp Schillinger", "Tamim Asfour"], "abstract": "We introduce TAPAS (Task-based Adaptation and Planning using AgentS), a multi-agent framework that integrates Large Language Models (LLMs) with symbolic planning to solve complex tasks without the need for manually defined environment models. TAPAS employs specialized LLM-based agents that collaboratively generate and adapt domain models, initial states, and goal specifications as needed using structured tool-calling mechanisms. Through this tool-based interaction, downstream agents can request modifications from upstream agents, enabling adaptation to novel attributes and constraints without manual domain redefinition. A ReAct (Reason+Act)-style execution agent, coupled with natural language plan translation, bridges the gap between dynamically generated plans and real-world robot capabilities. TAPAS demonstrates strong performance in benchmark planning domains and in the VirtualHome simulated real-world environment.", "subjects": "Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.19592.pdf", "abstract_url": "https://arxiv.org/abs/2506.19592", "categories": ["Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了TAPAS，一个多智能体框架，结合大型语言模型和符号规划解决复杂任务，无需手动定义环境模型。", "motivation": "解决复杂任务规划中需要手动定义环境模型的问题，提高适应性和自动化水平。", "method": "采用多智能体框架，结合大型语言模型和符号规划，通过工具调用机制动态生成和调整领域模型、初始状态和目标规范。", "result": "TAPAS在基准规划领域和VirtualHome模拟现实环境中表现出色。", "conclusion": "TAPAS框架通过多智能体协作和动态模型调整，有效解决了复杂任务规划中的适应性问题，展示了在实际应用中的潜力。"}}
{"id": "2506.19613", "title": "Position: Intelligent Science Laboratory Requires the Integration of Cognitive and Embodied AI", "authors": ["Sha Zhang", "Suorong Yang", "Tong Xie", "Xiangyuan Xue", "Zixuan Hu", "Rui Li", "Wenxi Qu", "Zhenfei Yin", "Tianfan Fu", "Di Hu", "Andres M Bran", "Nian Ran", "Bram Hoex", "Wangmeng Zuo", "Philippe Schwaller", "Wanli Ouyang", "Lei Bai", "Yanyong Zhang", "Lingyu Duan", "Shixiang Tang", "Dongzhan Zhou"], "abstract": "Scientific discovery has long been constrained by human limitations in expertise, physical capability, and sleep cycles. The recent rise of AI scientists and automated laboratories has accelerated both the cognitive and operational aspects of research. However, key limitations persist: AI systems are often confined to virtual environments, while automated laboratories lack the flexibility and autonomy to adaptively test new hypotheses in the physical world. Recent advances in embodied AI, such as generalist robot foundation models, diffusion-based action policies, fine-grained manipulation learning, and sim-to-real transfer, highlight the promise of integrating cognitive and embodied intelligence. This convergence opens the door to closed-loop systems that support iterative, autonomous experimentation and the possibility of serendipitous discovery. In this position paper, we propose the paradigm of Intelligent Science Laboratories (ISLs): a multi-layered, closed-loop framework that deeply integrates cognitive and embodied intelligence. ISLs unify foundation models for scientific reasoning, agent-based workflow orchestration, and embodied agents for robust physical experimentation. We argue that such systems are essential for overcoming the current limitations of scientific discovery and for realizing the full transformative potential of AI-driven science.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.19613.pdf", "abstract_url": "https://arxiv.org/abs/2506.19613", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出智能科学实验室（ISLs）的概念，旨在通过整合认知与具身AI，克服科学发现的当前限制，实现AI驱动科学的全面变革潜力。", "motivation": "科学发现长期受限于人类在专业知识、物理能力和睡眠周期方面的限制。尽管AI科学家和自动化实验室加速了研究的认知和操作方面，但AI系统常限于虚拟环境，自动化实验室缺乏在物理世界中适应性测试新假设的灵活性和自主性。", "method": "提出智能科学实验室（ISLs）的多层次闭环框架，深度整合认知与具身智能，统一科学推理的基础模型、基于代理的工作流程编排和用于稳健物理实验的具身代理。", "result": "通过整合认知和具身AI，ISLs能够支持迭代、自主的实验，并有可能实现偶然发现，从而克服科学发现的当前限制。", "conclusion": "智能科学实验室（ISLs）是实现AI驱动科学全面变革的关键，通过整合认知与具身智能，可以克服现有科学发现的限制，开启科学探索的新篇章。"}}
{"id": "2506.19724", "title": "From Reproduction to Replication: Evaluating Research Agents with Progressive Code Masking", "authors": ["Gyeongwon James Kim", "Alex Wilf", "Louis-Philippe Morency", "Daniel Fried"], "abstract": "Recent progress in autonomous code generation has fueled excitement around AI agents capable of accelerating scientific discovery by running experiments. However, there is currently no benchmark that evaluates whether such agents can implement scientific ideas when given varied amounts of code as a starting point, interpolating between reproduction (running code) and from-scratch replication (fully re-implementing and running code). We introduce AutoExperiment, a benchmark that evaluates AI agents' ability to implement and run machine learning experiments based on natural language descriptions in research papers. In each task, agents are given a research paper, a codebase with key functions masked out, and a command to run the experiment. The goal is to generate the missing code, execute the experiment in a sandboxed environment, and reproduce the results. AutoExperiment scales in difficulty by varying the number of missing functions $n$, ranging from partial reproduction to full replication. We evaluate state-of-the-art agents and find that performance degrades rapidly as $n$ increases. Agents that can dynamically interact with the environment (e.g. to debug their code) can outperform agents in fixed \"agentless\" harnesses, and there exists a significant gap between single-shot and multi-trial success rates (Pass@1 vs. Pass@5), motivating verifier approaches to our benchmark. Our findings highlight critical challenges in long-horizon code generation, context retrieval, and autonomous experiment execution, establishing AutoExperiment as a new benchmark for evaluating progress in AI-driven scientific experimentation. Our data and code are open-sourced at", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.19724.pdf", "abstract_url": "https://arxiv.org/abs/2506.19724", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了AutoExperiment，一个评估AI代理根据研究论文中的自然语言描述实现和运行机器学习实验能力的基准。通过逐步增加代码掩码的难度，从部分复制到完全复制，评估了最先进代理的性能，并探讨了动态交互环境对性能的影响。", "motivation": "当前缺乏评估AI代理在给定不同数量代码作为起点时实现科学想法的能力的基准，这介于复制（运行代码）和从头复制（完全重新实现和运行代码）之间。", "method": "引入了AutoExperiment基准，通过变化缺失函数的数量$n$来调整任务难度，评估AI代理生成缺失代码、在沙盒环境中执行实验并复制结果的能力。", "result": "发现随着$n$的增加，性能迅速下降；能够动态与环境交互的代理在固定“无代理”环境中表现更优；单次尝试与多次尝试成功率之间存在显著差距。", "conclusion": "研究结果突出了在长视野代码生成、上下文检索和自主实验执行方面的关键挑战，确立了AutoExperiment作为评估AI驱动科学实验进展的新基准。"}}
{"id": "2506.19835", "title": "MAM: Modular Multi-Agent Framework for Multi-Modal Medical Diagnosis via Role-Specialized Collaboration", "authors": ["Yucheng Zhou", "Lingran Song", "Jianbing Shen"], "abstract": "Recent advancements in medical Large Language Models (LLMs) have showcased their powerful reasoning and diagnostic capabilities. Despite their success, current unified multimodal medical LLMs face limitations in knowledge update costs, comprehensiveness, and flexibility. To address these challenges, we introduce the Modular Multi-Agent Framework for Multi-Modal Medical Diagnosis (MAM). Inspired by our empirical findings highlighting the benefits of role assignment and diagnostic discernment in LLMs, MAM decomposes the medical diagnostic process into specialized roles: a General Practitioner, Specialist Team, Radiologist, Medical Assistant, and Director, each embodied by an LLM-based agent. This modular and collaborative framework enables efficient knowledge updates and leverages existing medical LLMs and knowledge bases. Extensive experimental evaluations conducted on a wide range of publicly accessible multimodal medical datasets, incorporating text, image, audio, and video modalities, demonstrate that MAM consistently surpasses the performance of modality-specific LLMs. Notably, MAM achieves significant performance improvements ranging from 18% to 365% compared to baseline models. Our code is released at", "subjects": "Computation and Language (cs.CL)", "comments": "ACL 2025 Findings", "pdf_url": "https://arxiv.org/pdf/2506.19835.pdf", "abstract_url": "https://arxiv.org/abs/2506.19835", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一种模块化多智能体框架（MAM），用于通过角色专业化协作进行多模态医学诊断，旨在解决当前统一多模态医学大型语言模型（LLMs）在知识更新成本、全面性和灵活性方面的限制。", "motivation": "当前统一的多模态医学LLMs在知识更新成本、全面性和灵活性方面存在限制，这促使研究者开发了MAM框架，以更高效地更新知识和利用现有医学LLMs和知识库。", "method": "MAM框架将医学诊断过程分解为专门的角色：全科医生、专家团队、放射科医生、医疗助理和主任，每个角色由一个基于LLM的智能体体现，实现模块化和协作式诊断。", "result": "在广泛的多模态医学数据集上的实验评估显示，MAM consistently surpasses the performance of modality-specific LLMs，性能提升幅度从18%到365%不等。", "conclusion": "MAM框架通过角色专业化的协作，显著提高了多模态医学诊断的性能和效率，为医学LLMs的应用提供了新的方向。"}}
{"id": "2506.19783", "title": "SAGE: Strategy-Adaptive Generation Engine for Query Rewriting", "authors": ["Teng Wang", "Hailei Gong", "Changwang Zhang", "Jun Wang"], "abstract": "Query rewriting is pivotal for enhancing dense retrieval, yet current methods demand large-scale supervised data or suffer from inefficient reinforcement learning (RL) exploration. In this work, we first establish that guiding Large Language Models (LLMs) with a concise set of expert-crafted strategies, such as semantic expansion and entity disambiguation, substantially improves retrieval effectiveness on challenging benchmarks, including HotpotQA, FEVER, NFCorpus, and SciFact. Building on this insight, we introduce the Strategy-Adaptive Generation Engine (SAGE), which operationalizes these strategies in an RL framework. SAGE introduces two novel reward shaping mechanisms-Strategic Credit Shaping (SCS) and Contrastive Reward Shaping (CRS)-to deliver more informative learning signals. This strategy-guided approach not only achieves new state-of-the-art NDCG@10 results, but also uncovers a compelling emergent behavior: the agent learns to select optimal strategies, reduces unnecessary exploration, and generates concise rewrites, lowering inference cost without sacrificing performance. Our findings demonstrate that strategy-guided RL, enhanced with nuanced reward shaping, offers a scalable, efficient, and more interpretable paradigm for developing the next generation of robust information retrieval systems.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.19783.pdf", "abstract_url": "https://arxiv.org/abs/2506.19783", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了SAGE（Strategy-Adaptive Generation Engine），一种用于查询重写的策略自适应生成引擎，通过结合专家策略和强化学习框架，提高了检索效率并降低了推理成本。", "motivation": "当前查询重写方法需要大规模监督数据或强化学习探索效率低下，SAGE旨在通过策略引导的强化学习解决这些问题。", "method": "SAGE采用强化学习框架，引入了两种新的奖励塑造机制——战略信用塑造（SCS）和对比奖励塑造（CRS），以提供更丰富的学习信号。", "result": "SAGE在HotpotQA、FEVER、NFCorpus和SciFact等挑战性基准测试中实现了新的最先进NDCG@10结果，同时减少了不必要的探索并生成了简洁的重写。", "conclusion": "策略引导的强化学习结合细致的奖励塑造，为开发下一代强大信息检索系统提供了可扩展、高效且更可解释的范式。"}}
{"id": "2506.19785", "title": "Learning Task Belief Similarity with Latent Dynamics for Meta-Reinforcement Learning", "authors": ["Menglong Zhang", "Fuyuan Qian"], "abstract": "Meta-reinforcement learning requires utilizing prior task distribution information obtained during exploration to rapidly adapt to unknown tasks. The efficiency of an agent's exploration hinges on accurately identifying the current task. Recent Bayes-Adaptive Deep RL approaches often rely on reconstructing the environment's reward signal, which is challenging in sparse reward settings, leading to suboptimal exploitation. Inspired by bisimulation metrics, which robustly extracts behavioral similarity in continuous MDPs, we propose SimBelief-a novel meta-RL framework via measuring similarity of task belief in Bayes-Adaptive MDP (BAMDP). SimBelief effectively extracts common features of similar task distributions, enabling efficient task identification and exploration in sparse reward environments. We introduce latent task belief metric to learn the common structure of similar tasks and incorporate it into the specific task belief. By learning the latent dynamics across task distributions, we connect shared latent task belief features with specific task features, facilitating rapid task identification and adaptation. Our method outperforms state-of-the-art baselines on sparse reward MuJoCo and panda-gym tasks.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2506.19785.pdf", "abstract_url": "https://arxiv.org/abs/2506.19785", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为SimBelief的新型元强化学习框架，通过测量贝叶斯自适应MDP（BAMDP）中的任务信念相似性，有效提取相似任务分布的共同特征，从而在稀疏奖励环境中实现高效的任务识别和探索。", "motivation": "解决在稀疏奖励设置中，现有Bayes-Adaptive Deep RL方法依赖重建环境奖励信号而导致次优利用的问题。", "method": "提出SimBelief框架，通过引入潜在任务信念度量学习相似任务的共同结构，并将其融入特定任务信念中，通过学习跨任务分布的潜在动态，连接共享的潜在任务信念特征与特定任务特征。", "result": "在稀疏奖励的MuJoCo和panda-gym任务上，我们的方法优于最先进的基线。", "conclusion": "SimBelief通过测量任务信念相似性和学习潜在动态，有效促进了快速任务识别和适应，为稀疏奖励环境中的元强化学习提供了新的解决方案。"}}
{"id": "2506.19846", "title": "JoyAgents-R1: Joint Evolution Dynamics for Versatile Multi-LLM Agents with Reinforcement Learning", "authors": ["Ai Han", "Junxing Hu", "Pu Wei", "Zhiqian Zhang", "Yuhang Guo", "Jiawei Lu", "Zicheng Zhang"], "abstract": "Multi-agent reinforcement learning (MARL) has emerged as a prominent paradigm for increasingly complex tasks. However, joint evolution across heterogeneous agents remains challenging due to cooperative inefficiency and training instability. In this paper, we propose the joint evolution dynamics for MARL called JoyAgents-R1, which first applies Group Relative Policy Optimization (GRPO) to the joint training of heterogeneous multi-agents. By iteratively refining agents' large language models (LLMs) and memories, the method achieves holistic equilibrium with optimal decision-making and memory capabilities. Specifically, JoyAgents-R1 first implements node-wise Monte Carlo sampling on the behavior of each agent across entire reasoning trajectories to enhance GRPO sampling efficiency while maintaining policy diversity. Then, our marginal benefit-driven selection strategy identifies top-$K$ sampling groups with maximal reward fluctuations, enabling targeted agent model updates that improve training stability and maximize joint benefits through cost-effective parameter adjustments. Meanwhile, JoyAgents-R1 introduces an adaptive memory evolution mechanism that repurposes GRPO rewards as cost-free supervisory signals to eliminate repetitive reasoning and accelerate convergence. Experiments across general and domain-specific scenarios demonstrate that JoyAgents-R1 achieves performance comparable to that of larger LLMs while built on smaller open-source models.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "33 pages, 7 figures, under review", "pdf_url": "https://arxiv.org/pdf/2506.19846.pdf", "abstract_url": "https://arxiv.org/abs/2506.19846", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了JoyAgents-R1，一种用于多智能体强化学习（MARL）的联合进化动力学方法，通过Group Relative Policy Optimization（GRPO）和自适应记忆进化机制，实现了异构多智能体的高效合作和训练稳定性。", "motivation": "解决多智能体强化学习中异构智能体联合进化时的合作效率低下和训练不稳定的问题。", "method": "采用Group Relative Policy Optimization（GRPO）进行异构多智能体的联合训练，通过节点级蒙特卡洛采样和边际效益驱动的选择策略优化采样效率和训练稳定性，同时引入自适应记忆进化机制。", "result": "实验表明，JoyAgents-R1在通用和领域特定场景下都能达到与更大规模LLMs相媲美的性能，同时基于较小的开源模型构建。", "conclusion": "JoyAgents-R1通过创新的联合进化动力学和记忆进化机制，为多智能体强化学习提供了高效、稳定的训练方法，具有广泛的应用潜力。"}}
{"id": "2506.17336", "title": "Privacy-Preserving LLM Interaction with Socratic Chain-of-Thought Reasoning and Homomorphically Encrypted Vector Databases", "authors": ["Yubeen Bae", "Minchan Kim", "Jaejin Lee", "Sangbum Kim", "Jaehyung Kim", "Yejin Choi", "Niloofar Mireshghallah"], "abstract": "Large language models (LLMs) are increasingly used as personal agents, accessing sensitive user data such as calendars, emails, and medical records. Users currently face a trade-off: They can send private records, many of which are stored in remote databases, to powerful but untrusted LLM providers, increasing their exposure risk. Alternatively, they can run less powerful models locally on trusted devices. We bridge this gap. Our Socratic Chain-of-Thought Reasoning first sends a generic, non-private user query to a powerful, untrusted LLM, which generates a Chain-of-Thought (CoT) prompt and detailed sub-queries without accessing user data. Next, we embed these sub-queries and perform encrypted sub-second semantic search using our Homomorphically Encrypted Vector Database across one million entries of a single user's private data. This represents a realistic scale of personal documents, emails, and records accumulated over years of digital activity. Finally, we feed the CoT prompt and the decrypted records to a local language model and generate the final response. On the LoCoMo long-context QA benchmark, our hybrid framework, combining GPT-4o with a local Llama-3.2-1B model, outperforms using GPT-4o alone by up to 7.1 percentage points. This demonstrates a first step toward systems where tasks are decomposed and split between untrusted strong LLMs and weak local ones, preserving user privacy.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": "29 pages", "pdf_url": "https://arxiv.org/pdf/2506.17336.pdf", "abstract_url": "https://arxiv.org/abs/2506.17336", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种结合苏格拉底式链式思考推理和同态加密向量数据库的隐私保护LLM交互方法，旨在解决用户在使用强大但不可信的LLM服务时面临的隐私风险问题。", "motivation": "解决用户在使用大型语言模型（LLMs）作为个人代理时，如何在不牺牲隐私的前提下，既能利用强大LLM的能力，又能保护敏感数据不被泄露的问题。", "method": "采用苏格拉底式链式思考推理（Socratic Chain-of-Thought Reasoning）和同态加密向量数据库（Homomorphically Encrypted Vector Database）技术，将任务分解并在不可信的强大LLM和可信的本地弱模型之间分配，以实现隐私保护。", "result": "在LoCoMo长上下文QA基准测试中，结合GPT-4o和本地Llama-3.2-1B模型的混合框架，比单独使用GPT-4o性能提升了高达7.1个百分点。", "conclusion": "本文展示了一种初步的系统设计，通过任务分解和分配，在保护用户隐私的同时，有效利用了强大LLM的能力，为隐私保护的LLM交互提供了新的思路。"}}
{"id": "2506.18959", "title": "From Web Search towards Agentic Deep Research: Incentivizing Search with Reasoning Agents", "authors": ["Weizhi Zhang", "Yangning Li", "Yuanchen Bei", "Junyu Luo", "Guancheng Wan", "Liangwei Yang", "Chenxuan Xie", "Yuyao Yang", "Wei-Chieh Huang", "Chunyu Miao", "Henry Peng Zou", "Xiao Luo", "Yusheng Zhao", "Yankai Chen", "Chunkit Chan", "Peilin Zhou", "Xinyang Zhang", "Chenwei Zhang", "Jingbo Shang", "Ming Zhang", "Yangqiu Song", "Irwin King", "Philip S. Yu"], "abstract": "Information retrieval is a cornerstone of modern knowledge acquisition, enabling billions of queries each day across diverse domains. However, traditional keyword-based search engines are increasingly inadequate for handling complex, multi-step information needs. Our position is that Large Language Models (LLMs), endowed with reasoning and agentic capabilities, are ushering in a new paradigm termed Agentic Deep Research. These systems transcend conventional information search techniques by tightly integrating autonomous reasoning, iterative retrieval, and information synthesis into a dynamic feedback loop. We trace the evolution from static web search to interactive, agent-based systems that plan, explore, and learn. We also introduce a test-time scaling law to formalize the impact of computational depth on reasoning and search. Supported by benchmark results and the rise of open-source implementations, we demonstrate that Agentic Deep Research not only significantly outperforms existing approaches, but is also poised to become the dominant paradigm for future information seeking. All the related resources, including industry products, research papers, benchmark datasets, and open-source implementations, are collected for the community in", "subjects": "Information Retrieval (cs.IR); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.18959.pdf", "abstract_url": "https://arxiv.org/abs/2506.18959", "categories": ["Information Retrieval (cs.IR)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种名为‘代理深度研究’的新范式，利用具有推理和代理能力的大型语言模型（LLMs），通过自主推理、迭代检索和信息合成的动态反馈循环，超越了传统的关键词搜索引擎，以解决复杂、多步骤的信息需求。", "motivation": "传统的关键词搜索引擎在处理复杂、多步骤的信息需求时越来越显得不足。本文旨在探索如何利用大型语言模型（LLMs）的推理和代理能力，推动信息检索技术向更高级的‘代理深度研究’范式转变。", "method": "本文通过整合自主推理、迭代检索和信息合成到一个动态反馈循环中，提出了‘代理深度研究’这一新范式。同时，引入了一个测试时扩展定律，以形式化计算深度对推理和搜索的影响。", "result": "基准测试结果和开源实现的兴起表明，‘代理深度研究’不仅显著优于现有方法，而且有望成为未来信息寻求的主导范式。", "conclusion": "本文得出结论，‘代理深度研究’通过利用大型语言模型的推理和代理能力，为信息检索领域带来了革命性的变化，预示着未来信息寻求方式的重要转变。"}}
{"id": "2506.18952", "title": "LLMs on a Budget? Say HOLA", "authors": ["Zohaib Hasan Siddiqui", "Jiechao Gao", "Ebad Shabbir", "Mohammad Anas Azeez", "Rafiq Ali", "Gautam Siddharth Kashyap", "Usman Naseem"], "abstract": "Running Large Language Models (LLMs) on edge devices is constrained by high compute and memory demands posing a barrier for real-time applications in sectors like healthcare, education, and embedded systems. Current solutions such as quantization, pruning, and retrieval-augmented generation (RAG) offer only partial optimizations and often compromise on speed or accuracy. We introduce HOLA, an end-to-end optimization framework for efficient LLM deployment. Internally, it leverages Hierarchical Speculative Decoding (HSD) for faster inference without quality loss. Externally, AdaComp-RAG adjusts retrieval complexity based on context needs. Together with LoBi, which blends structured pruning (LoRA) and quantization, HOLA delivers significant gains: 17.6% EMA on GSM8K, 10.5% MCA on ARC, and reduced latency and memory on edge devices like Jetson Nano--proving both scalable and production-ready.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.18952.pdf", "abstract_url": "https://arxiv.org/abs/2506.18952", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了HOLA，一种用于高效部署大型语言模型（LLMs）的端到端优化框架，旨在解决边缘设备上运行LLMs时的高计算和内存需求问题。", "motivation": "解决在边缘设备上运行大型语言模型时面临的高计算和内存需求问题，这些需求阻碍了在医疗、教育和嵌入式系统等领域的实时应用。", "method": "HOLA框架内部采用分层推测解码（HSD）以在不损失质量的情况下加速推理，外部通过AdaComp-RAG根据上下文需求调整检索复杂度，并结合LoBi（结合了结构化剪枝和量化技术）进行优化。", "result": "HOLA在GSM8K上实现了17.6%的EMA提升，在ARC上实现了10.5%的MCA提升，并在Jetson Nano等边缘设备上降低了延迟和内存使用，证明了其可扩展性和生产就绪性。", "conclusion": "HOLA框架通过综合优化技术，显著提升了大型语言模型在边缘设备上的运行效率和性能，为实时应用提供了可行的解决方案。"}}
{"id": "2506.19579", "title": "Fake or Real, Can Robots Tell? Evaluating Embodied Vision-Language Models on Real and 3D-Printed Objects", "authors": ["Federico Tavella", "Kathryn Mearns", "Angelo Cangelosi"], "abstract": "Robotic scene understanding increasingly relies on vision-language models (VLMs) to generate natural language descriptions of the environment. In this work, we present a comparative study of captioning strategies for tabletop scenes captured by a robotic arm equipped with an RGB camera. The robot collects images of objects from multiple viewpoints, and we evaluate several models that generate scene descriptions. We compare the performance of various captioning models, like BLIP and VLMs. Our experiments examine the trade-offs between single-view and multi-view captioning, and difference between recognising real-world and 3D printed objects. We quantitatively evaluate object identification accuracy, completeness, and naturalness of the generated captions. Results show that VLMs can be used in robotic settings where common objects need to be recognised, but fail to generalise to novel representations. Our findings provide practical insights into deploying foundation models for embodied agents in real-world settings.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.19579.pdf", "abstract_url": "https://arxiv.org/abs/2506.19579", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Computer Vision and Pattern Recognition (cs.CV)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过比较不同描述策略，评估了在机器人场景理解中使用的视觉语言模型（VLMs）对真实和3D打印物体的识别能力。研究发现，VLMs在识别常见物体方面有效，但在处理新颖表现时存在局限。", "motivation": "解决机器人场景理解中视觉语言模型（VLMs）在识别真实和3D打印物体时的性能差异和泛化能力问题。", "method": "使用装备RGB相机的机器人手臂从多个视角收集桌面场景的图像，并评估包括BLIP和VLMs在内的多种描述模型，比较单视角与多视角描述的性能差异。", "result": "VLMs在识别常见物体方面表现良好，但在面对新颖表现时泛化能力不足。", "conclusion": "研究为在现实世界环境中部署基础模型提供了实用见解，指出了VLMs在机器人应用中的潜力和限制。"}}
{"id": "2506.19806", "title": "LLM-Based Social Simulations Require a Boundary", "authors": ["Zengqing Wu", "Run Peng", "Takayuki Ito", "Chuan Xiao"], "abstract": "This position paper argues that large language model (LLM)-based social simulations should establish clear boundaries to meaningfully contribute to social science research. While LLMs offer promising capabilities for modeling human-like agents compared to traditional agent-based modeling, they face fundamental limitations that constrain their reliability for social pattern discovery. The core issue lies in LLMs' tendency towards an ``average persona'' that lacks sufficient behavioral heterogeneity, a critical requirement for simulating complex social dynamics. We examine three key boundary problems: alignment (simulated behaviors matching real-world patterns), consistency (maintaining coherent agent behavior over time), and robustness (reproducibility under varying conditions). We propose heuristic boundaries for determining when LLM-based simulations can reliably advance social science understanding. We believe that these simulations are more valuable when focusing on (1) collective patterns rather than individual trajectories, (2) agent behaviors aligning with real population averages despite limited variance, and (3) proper validation methods available for testing simulation robustness. We provide a practical checklist to guide researchers in determining the appropriate scope and claims for LLM-based social simulations.", "subjects": "Computers and Society (cs.CY); Computation and Language (cs.CL); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.19806.pdf", "abstract_url": "https://arxiv.org/abs/2506.19806", "categories": ["Computers and Society (cs.CY)", "Computation and Language (cs.CL)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文主张基于大型语言模型（LLM）的社会模拟应设定明确界限，以有意义地贡献于社会科学研究。尽管LLM在模拟人类行为方面比传统基于代理的模型更有前景，但其存在根本限制，影响了社会模式发现的可靠性。核心问题在于LLM倾向于缺乏行为异质性的“平均人格”，这是模拟复杂社会动态的关键要求。", "motivation": "解决LLM在社会模拟中因缺乏行为异质性而限制其可靠性的问题，以促进社会科学研究。", "method": "提出三个关键边界问题：对齐性、一致性和鲁棒性，并提出启发式边界来确定LLM模拟何时能可靠推进社会科学理解。", "result": "建议LLM模拟应聚焦于集体模式而非个体轨迹，代理行为应与真实人口平均值对齐，并采用适当的验证方法测试模拟的鲁棒性。", "conclusion": "提供实用检查清单，指导研究者确定LLM社会模拟的适当范围和主张，强调在明确边界内LLM模拟对社会科学的价值。"}}
{"id": "2506.18951", "title": "SWE-SQL: Illuminating LLM Pathways to Solve User SQL Issues in Real-World Applications", "authors": ["Jinyang Li", "Xiaolong Li", "Ge Qu", "Per Jacobsson", "Bowen Qin", "Binyuan Hui", "Shuzheng Si", "Nan Huo", "Xiaohan Xu", "Yue Zhang", "Ziwei Tang", "Yuanshuai Li", "Florensia Widjaja", "Xintong Zhu", "Feige Zhou", "Yongfeng Huang", "Yannis Papakonstantinou", "Fatma Ozcan", "Chenhao Ma", "Reynold Cheng"], "abstract": "Resolution of complex SQL issues persists as a significant bottleneck in real-world database applications. Current Large Language Models (LLMs), while adept at text-to-SQL translation, have not been rigorously evaluated on the more challenging task of debugging SQL issues. To address this gap, we introduce BIRD-CRITIC, a new SQL issue debugging benchmark comprising 530 PostgreSQL tasks (BIRD-CRITIC-PG) and 570 multi-dialect tasks (BIRD-CRITIC-Multi), distilled from authentic user issues and replayed within new environments to facilitate rigorous evaluation. Baseline evaluations underscore the task's complexity, with the leading reasoning model O3-Mini achieving only 38.87% success rate on BIRD-CRITIC-PG and 33.33% on BIRD-CRITIC-Multi. Meanwhile, advancing open-source models for database tasks is crucial for empowering local development while safeguarding data privacy. Therefore, we present Six-Gym (Sql-fIX-Gym), a training environment for elevating open-source model capabilities for SQL issue debugging. This environment leverages SQL-Rewind strategy, which automatically generates executable issue-solution datasets by reverse-engineering issues from verified SQLs. However, popular trajectory-based fine-tuning methods do not explore substantial supervisory signals. We further propose f-Plan Boosting, which extracts high-level debugging plans from SQL solutions, enabling teacher LLMs to produce 73.7% more successful trajectories for training. We integrate these components into an open-source agent, Bird-Fixer. Based on Qwen-2.5-Coder-14B, Bird-Fixer achieves 38.11% success rate on BIRD-CRITIC-PG and 29.65% on BIRD-CRITIC-Multi, surpassing leading proprietary models such as Claude-3.7-Sonnet and GPT-4.1, marking a significant step toward democratizing sophisticated SQL-debugging capabilities. The leaderboard and source code are available:", "subjects": "Databases (cs.DB); Artificial Intelligence (cs.AI)", "comments": "26 pages, 9 figures", "pdf_url": "https://arxiv.org/pdf/2506.18951.pdf", "abstract_url": "https://arxiv.org/abs/2506.18951", "categories": ["Databases (cs.DB)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了BIRD-CRITIC和Six-Gym（Sql-fIX-Gym），旨在解决现实世界应用中复杂的SQL问题调试挑战。通过创建新的SQL问题调试基准和训练环境，以及提出f-Plan Boosting方法，显著提升了开源模型在SQL调试任务上的性能。", "motivation": "解决现实世界数据库应用中复杂SQL问题的调试瓶颈，并推动开源模型在数据库任务中的发展，以保护数据隐私。", "method": "引入了BIRD-CRITIC基准和Six-Gym训练环境，采用SQL-Rewind策略自动生成可执行的issue-solution数据集，并提出f-Plan Boosting方法从SQL解决方案中提取高级调试计划。", "result": "基于Qwen-2.5-Coder-14B的Bird-Fixer在BIRD-CRITIC-PG和BIRD-CRITIC-Multi上的成功率分别为38.11%和29.65%，超过了领先的专有模型如Claude-3.7-Sonnet和GPT-4.1。", "conclusion": "这项工作在民主化复杂SQL调试能力方面迈出了重要一步，通过开源工具和方法显著提升了模型性能，为本地开发和数据隐私保护提供了支持。"}}
{"id": "2506.19250", "title": "Robust Behavior Cloning Via Global Lipschitz Regularization", "authors": ["Shili Wu", "Yizhao Jin", "Puhua Niu", "Aniruddha Datta", "Sean B. Andersson"], "abstract": "Behavior Cloning (BC) is an effective imitation learning technique and has even been adopted in some safety-critical domains such as autonomous vehicles. BC trains a policy to mimic the behavior of an expert by using a dataset composed of only state-action pairs demonstrated by the expert, without any additional interaction with the environment. However, During deployment, the policy observations may contain measurement errors or adversarial disturbances. Since the observations may deviate from the true states, they can mislead the agent into making sub-optimal actions. In this work, we use a global Lipschitz regularization approach to enhance the robustness of the learned policy network. We then show that the resulting global Lipschitz property provides a robustness certificate to the policy with respect to different bounded norm perturbations. Then, we propose a way to construct a Lipschitz neural network that ensures the policy robustness. We empirically validate our theory across various environments in Gymnasium. Keywords: Robust Reinforcement Learning; Behavior Cloning; Lipschitz Neural Network", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.19250.pdf", "abstract_url": "https://arxiv.org/abs/2506.19250", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种通过全局Lipschitz正则化增强行为克隆（BC）鲁棒性的方法，旨在解决在部署时因观测误差或对抗性干扰导致的策略性能下降问题。", "motivation": "行为克隆（BC）是一种有效的模仿学习技术，但在部署时，由于观测可能包含测量误差或对抗性干扰，这些偏离真实状态的观测可能导致代理做出次优动作。本文旨在通过增强学习策略网络的鲁棒性来解决这一问题。", "method": "本文采用全局Lipschitz正则化方法来增强学习策略网络的鲁棒性，并提出了构建Lipschitz神经网络以确保策略鲁棒性的方法。", "result": "实验在Gymnasium的各种环境中验证了所提理论的有效性，证明了全局Lipschitz属性能够为策略提供关于不同有界范数扰动的鲁棒性证书。", "conclusion": "通过全局Lipschitz正则化，可以显著提高行为克隆策略在面对观测误差或对抗性干扰时的鲁棒性，这对于安全关键领域如自动驾驶等具有重要意义。"}}
{"id": "2506.19597", "title": "Robotics Under Construction: Challenges on Job Sites", "authors": ["Haruki Uchiito", "Akhilesh Bhat", "Koji Kusaka", "Xiaoya Zhang", "Hiraku Kinjo", "Honoka Uehara", "Motoki Koyama", "Shinji Natsume"], "abstract": "As labor shortages and productivity stagnation increasingly challenge the construction industry, automation has become essential for sustainable infrastructure development. This paper presents an autonomous payload transportation system as an initial step toward fully unmanned construction sites. Our system, based on the CD110R-3 crawler carrier, integrates autonomous navigation, fleet management, and GNSS-based localization to facilitate material transport in construction site environments. While the current system does not yet incorporate dynamic environment adaptation algorithms, we have begun fundamental investigations into external-sensor based perception and mapping system. Preliminary results highlight the potential challenges, including navigation in evolving terrain, environmental perception under construction-specific conditions, and sensor placement optimization for improving autonomy and efficiency. Looking forward, we envision a construction ecosystem where collaborative autonomous agents dynamically adapt to site conditions, optimizing workflow and reducing human intervention. This paper provides foundational insights into the future of robotics-driven construction automation and identifies critical areas for further technological development.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Hardware Architecture (cs.AR); Emerging Technologies (cs.ET); Systems and Control (eess.SY)", "comments": "Workshop on Field Robotics, ICRA", "pdf_url": "https://arxiv.org/pdf/2506.19597.pdf", "abstract_url": "https://arxiv.org/abs/2506.19597", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Hardware Architecture (cs.AR)", "Emerging Technologies (cs.ET)", "Systems and Control (eess.SY)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了在劳动力短缺和生产力停滞的背景下，自动化对建筑行业的重要性，介绍了一种基于CD110R-3履带运输车的自主载荷运输系统，作为实现完全无人建筑工地的初步步骤。", "motivation": "解决建筑行业面临的劳动力短缺和生产力停滞问题，推动可持续基础设施发展。", "method": "集成自主导航、车队管理和基于GNSS的定位系统，促进建筑工地环境中的材料运输。", "result": "初步结果揭示了在变化的地形中导航、建筑特定条件下的环境感知以及传感器放置优化等潜在挑战。", "conclusion": "展望了一个协作自主代理能动态适应工地条件、优化工作流程并减少人为干预的建筑生态系统，为机器人驱动的建筑自动化未来提供了基础性见解，并指出了关键技术发展的关键领域。"}}
{"id": "2506.19502", "title": "MATE: LLM-Powered Multi-Agent Translation Environment for Accessibility Applications", "authors": ["Aleksandr Algazinov", "Matt Laing", "Paul Laban"], "abstract": "Accessibility remains a critical concern in today's society, as many technologies are not developed to support the full range of user needs. Existing multi-agent systems (MAS) often cannot provide comprehensive assistance for users in need due to the lack of customization stemming from closed-source designs. Consequently, individuals with disabilities frequently encounter significant barriers when attempting to interact with digital environments. We introduce MATE, a multimodal accessibility MAS, which performs the modality conversions based on the user's needs. The system is useful for assisting people with disabilities by ensuring that data will be converted to an understandable format. For instance, if the user cannot see well and receives an image, the system converts this image to its audio description. MATE can be applied to a wide range of domains, industries, and areas, such as healthcare, and can become a useful assistant for various groups of users. The system supports multiple types of models, ranging from LLM API calling to using custom machine learning (ML) classifiers. This flexibility ensures that the system can be adapted to various needs and is compatible with a wide variety of hardware. Since the system is expected to run locally, it ensures the privacy and security of sensitive information. In addition, the framework can be effectively integrated with institutional technologies (e.g., digital healthcare service) for real-time user assistance. Furthermore, we introduce ModCon-Task-Identifier, a model that is capable of extracting the precise modality conversion task from the user input. Numerous experiments show that ModCon-Task-Identifier consistently outperforms other LLMs and statistical models on our custom data. Our code and data are publicly available at", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.19502.pdf", "abstract_url": "https://arxiv.org/abs/2506.19502", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "MATE是一个多模态可访问性多代理系统，旨在通过模态转换帮助残障人士更好地与数字环境互动。该系统支持多种模型，从LLM API调用到自定义机器学习分类器，确保适应各种需求并与多种硬件兼容。", "motivation": "解决现有多代理系统因闭源设计缺乏定制化，无法为有需要的用户提供全面帮助的问题，特别是残障人士在数字环境互动中遇到的障碍。", "method": "引入MATE系统，执行基于用户需求的模态转换，并开发ModCon-Task-Identifier模型，从用户输入中精确提取模态转换任务。", "result": "实验表明，ModCon-Task-Identifier在自定义数据上 consistently outperforms其他LLMs和统计模型。", "conclusion": "MATE系统通过灵活的模态转换和强大的任务识别能力，为残障人士提供了广泛的可访问性支持，同时确保了数据隐私和安全性。"}}
{"id": "2506.19769", "title": "A Survey of Multi-sensor Fusion Perception for Embodied AI: Background, Methods, Challenges and Prospects", "authors": ["Shulan Ruan", "Rongwei Wang", "Xuchen Shen", "Huijie Liu", "Baihui Xiao", "Jun Shi", "Kun Zhang", "Zhenya Huang", "Yu Liu", "Enhong Chen", "You He"], "abstract": "Multi-sensor fusion perception (MSFP) is a key technology for embodied AI, which can serve a variety of downstream tasks (e.g., 3D object detection and semantic segmentation) and application scenarios (e.g., autonomous driving and swarm robotics). Recently, impressive achievements on AI-based MSFP methods have been reviewed in relevant surveys. However, we observe that the existing surveys have some limitations after a rigorous and detailed investigation. For one thing, most surveys are oriented to a single task or research field, such as 3D object detection or autonomous driving. Therefore, researchers in other related tasks often find it difficult to benefit directly. For another, most surveys only introduce MSFP from a single perspective of multi-modal fusion, while lacking consideration of the diversity of MSFP methods, such as multi-view fusion and time-series fusion. To this end, in this paper, we hope to organize MSFP research from a task-agnostic perspective, where methods are reported from various technical views. Specifically, we first introduce the background of MSFP. Next, we review multi-modal and multi-agent fusion methods. A step further, time-series fusion methods are analyzed. In the era of LLM, we also investigate multimodal LLM fusion methods. Finally, we discuss open challenges and future directions for MSFP. We hope this survey can help researchers understand the important progress in MSFP and provide possible insights for future research.", "subjects": "Multimedia (cs.MM); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.19769.pdf", "abstract_url": "https://arxiv.org/abs/2506.19769", "categories": ["Multimedia (cs.MM)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文综述了多传感器融合感知（MSFP）在具身AI中的关键作用，提出了现有综述的局限性，并从任务无关的角度组织了MSFP研究，介绍了多模态和多智能体融合方法，分析了时间序列融合方法，并探讨了多模态LLM融合方法，最后讨论了MSFP的开放挑战和未来方向。", "motivation": "现有的多传感器融合感知（MSFP）综述大多针对单一任务或研究领域，且仅从多模态融合的单一视角介绍，缺乏对MSFP方法多样性的考虑。本文旨在从任务无关的角度组织MSFP研究，以帮助研究人员理解MSFP的重要进展并为未来研究提供可能的见解。", "method": "本文首先介绍了MSFP的背景，然后回顾了多模态和多智能体融合方法，进一步分析了时间序列融合方法，并调查了多模态LLM融合方法。", "result": "本文提供了一个全面的MSFP研究综述，涵盖了多模态、多智能体、时间序列和多模态LLM融合方法，为研究人员提供了MSFP领域的重要进展和未来研究方向。", "conclusion": "本文不仅帮助研究人员理解MSFP的重要进展，还为未来研究提供了可能的见解，特别是在多模态LLM融合和解决开放挑战方面。"}}
