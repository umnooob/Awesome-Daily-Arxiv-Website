{"id": "2509.14566", "title": "DICE: Diffusion Consensus Equilibrium for Sparse-view CT Reconstruction", "authors": ["Leon Suarez-Rodriguez", "Roman Jacome", "Romario Gualdron-Hurtado", "Ana Mantilla-Dulcey", "Henry Arguello"], "abstract": "Sparse-view computed tomography (CT) reconstruction is fundamentally challenging due to undersampling, leading to an ill-posed inverse problem. Traditional iterative methods incorporate handcrafted or learned priors to regularize the solution but struggle to capture the complex structures present in medical images. In contrast, diffusion models (DMs) have recently emerged as powerful generative priors that can accurately model complex image distributions. In this work, we introduce Diffusion Consensus Equilibrium (DICE), a framework that integrates a two-agent consensus equilibrium into the sampling process of a DM. DICE alternates between: (i) a data-consistency agent, implemented through a proximal operator enforcing measurement consistency, and (ii) a prior agent, realized by a DM performing a clean image estimation at each sampling step. By balancing these two complementary agents iteratively, DICE effectively combines strong generative prior capabilities with measurement consistency. Experimental results show that DICE significantly outperforms state-of-the-art baselines in reconstructing high-quality CT images under uniform and non-uniform sparse-view settings of 15, 30, and 60 views (out of a total of 180), demonstrating both its effectiveness and robustness.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "8 pages, 4 figures, confenrence", "pdf_url": "https://arxiv.org/pdf/2509.14566.pdf", "abstract_url": "https://arxiv.org/abs/2509.14566", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "DICE框架通过结合扩散模型和共识平衡，有效解决了稀疏视角CT重建中的欠采样问题，显著优于现有方法。", "motivation": "稀疏视角CT重建由于欠采样导致逆问题不适定，传统方法难以捕捉复杂结构，而扩散模型作为强大先验可改善此问题。", "method": "DICE框架集成双代理共识平衡，交替使用数据一致性代理（近端算子）和先验代理（扩散模型），迭代平衡生成先验和测量一致性。", "result": "实验显示，DICE在15、30和60视图的均匀和非均匀稀疏设置下，显著优于最先进基线，重建高质量CT图像。", "conclusion": "DICE有效结合生成先验和测量一致性，证明其在稀疏视角CT重建中的有效性和鲁棒性。"}}
{"id": "2509.14257", "title": "From Correction to Mastery: Reinforced Distillation of Large Language Model Agents", "authors": ["Yuanjie Lyu", "Chengyu Wang", "Jun Huang", "Tong Xu"], "abstract": "Large Language Model agents excel at solving complex tasks through iterative reasoning and tool use, but typically depend on ultra-large, costly backbones. Existing distillation approaches train smaller students to imitate full teacher trajectories, yet reasoning and knowledge gaps between the teacher and student often lead to compounding errors. We propose SCoRe, a student-centered framework in which the student generates trajectories and the teacher intervenes only at the first critical error, producing training data matched to the student's ability and exposing specific weaknesses. The student is first fine-tuned on corrected trajectories. Subsequently, short-horizon reinforcement learning starts from the verified prefix before the first critical error, with target rewards assigned at that step. This design encourages autonomous problem-solving beyond imitation and improves training stability. Particularly, on 12 challenging benchmarks, a 7B-parameter student distilled with SCoRe matches the agentic performance of a 72B-parameter teacher.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14257.pdf", "abstract_url": "https://arxiv.org/abs/2509.14257", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "SCoRe框架通过教师仅在首次关键错误时干预，结合纠错轨迹微调和短视距强化学习，使7B参数学生模型在12个基准上匹配72B教师模型的性能。", "motivation": "解决大型语言模型代理依赖昂贵大模型，以及现有蒸馏方法中学生模仿教师轨迹时因推理和知识差距导致错误累积的问题。", "method": "提出SCoRe学生中心框架，教师干预首次关键错误生成匹配学生能力的训练数据，先微调纠错轨迹，再使用短视距强化学习从已验证前缀开始。", "result": "在12个挑战性基准测试中，7B参数学生模型达到了72B参数教师模型的代理性能水平。", "conclusion": "SCoRe通过针对性干预和强化学习，有效提升小模型自主问题解决能力，减少对大模型的依赖，具有实际应用价值。"}}
{"id": "2509.14860", "title": "MARIC: Multi-Agent Reasoning for Image Classification", "authors": ["Wonduk Seo", "Minhyeong Yu", "Hyunjin An", "Seunghyun Lee"], "abstract": "Image classification has traditionally relied on parameter-intensive model training, requiring large-scale annotated datasets and extensive fine tuning to achieve competitive performance. While recent vision language models (VLMs) alleviate some of these constraints, they remain limited by their reliance on single pass representations, often failing to capture complementary aspects of visual content. In this paper, we introduce Multi Agent based Reasoning for Image Classification (MARIC), a multi agent framework that reformulates image classification as a collaborative reasoning process. MARIC first utilizes an Outliner Agent to analyze the global theme of the image and generate targeted prompts. Based on these prompts, three Aspect Agents extract fine grained descriptions along distinct visual dimensions. Finally, a Reasoning Agent synthesizes these complementary outputs through integrated reflection step, producing a unified representation for classification. By explicitly decomposing the task into multiple perspectives and encouraging reflective synthesis, MARIC mitigates the shortcomings of both parameter-heavy training and monolithic VLM reasoning. Experiments on 4 diverse image classification benchmark datasets demonstrate that MARIC significantly outperforms baselines, highlighting the effectiveness of multi-agent visual reasoning for robust and interpretable image classification.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Multiagent Systems (cs.MA)", "comments": "Preprint", "pdf_url": "https://arxiv.org/pdf/2509.14860.pdf", "abstract_url": "https://arxiv.org/abs/2509.14860", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "MARIC 是一个多智能体框架，将图像分类重新定义为协作推理过程，通过多个智能体提取和合成视觉信息，显著优于基线方法，实现鲁棒且可解释的分类。", "motivation": "解决传统图像分类方法依赖参数密集型训练和大规模标注数据的问题，以及现有视觉语言模型（VLMs）因单次表示而无法捕捉互补视觉方面的局限性。", "method": "使用多智能体框架：Outliner Agent 分析图像全局主题并生成提示，三个 Aspect Agents 提取细粒度描述，Reasoning Agent 通过反思步骤合成输出以生成统一表示进行分类。", "result": "在4个多样化图像分类基准数据集上的实验显示，MARIC 显著优于基线方法，验证了多智能体视觉推理的有效性。", "conclusion": "MARIC 通过分解任务和鼓励反思合成，缓解了参数密集型训练和单次推理的缺点，为鲁棒和可解释的图像分类提供了有效方法。"}}
{"id": "2509.14267", "title": "Graph-Enhanced Retrieval-Augmented Question Answering for E-Commerce Customer Support", "authors": ["Piyushkumar Patel"], "abstract": "E-Commerce customer support requires quick and accurate answers grounded in product data and past support cases. This paper develops a novel retrieval-augmented generation (RAG) framework that uses knowledge graphs (KGs) to improve the relevance of the answer and the factual grounding. We examine recent advances in knowledge-augmented RAG and chatbots based on large language models (LLM) in customer support, including Microsoft's GraphRAG and hybrid retrieval architectures. We then propose a new answer synthesis algorithm that combines structured subgraphs from a domain-specific KG with text documents retrieved from support archives, producing more coherent and grounded responses. We detail the architecture and knowledge flow of our system, provide comprehensive experimental evaluation, and justify its design in real-time support settings. Our implementation demonstrates 23\\% improvement in factual accuracy and 89\\% user satisfaction in e-Commerce QA scenarios.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Theory (cs.IT)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14267.pdf", "abstract_url": "https://arxiv.org/abs/2509.14267", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Information Theory (cs.IT)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种基于知识图谱的检索增强生成框架，用于提升电子商务客户支持问答的准确性和相关性。", "motivation": "解决电子商务客户支持中快速准确回答基于产品数据和历史支持案例的问题。", "method": "使用知识图谱和文本检索结合的新答案合成算法，整合结构化子图和文档。", "result": "在事实准确性上提升23%，用户满意度达89%。", "conclusion": "该方法在实时支持场景中有效，提高了回答的连贯性和事实基础。"}}
{"id": "2509.14435", "title": "Causal-Counterfactual RAG: The Integration of Causal-Counterfactual Reasoning into RAG", "authors": ["Harshad Khadilkar", "Abhay Gupta"], "abstract": "Large language models (LLMs) have transformed natural language processing (NLP), enabling diverse applications by integrating large-scale pre-trained knowledge. However, their static knowledge limits dynamic reasoning over external information, especially in knowledge-intensive domains. Retrieval-Augmented Generation (RAG) addresses this challenge by combining retrieval mechanisms with generative modeling to improve contextual understanding. Traditional RAG systems suffer from disrupted contextual integrity due to text chunking and over-reliance on semantic similarity for retrieval, often resulting in shallow and less accurate responses. We propose Causal-Counterfactual RAG, a novel framework that integrates explicit causal graphs representing cause-effect relationships into the retrieval process and incorporates counterfactual reasoning grounded on the causal structure. Unlike conventional methods, our framework evaluates not only direct causal evidence but also the counterfactuality of associated causes, combining results from both to generate more robust, accurate, and interpretable answers. By leveraging causal pathways and associated hypothetical scenarios, Causal-Counterfactual RAG preserves contextual coherence, reduces hallucination, and enhances reasoning fidelity.", "subjects": "Computation and Language (cs.CL); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14435.pdf", "abstract_url": "https://arxiv.org/abs/2509.14435", "categories": ["Computation and Language (cs.CL)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出Causal-Counterfactual RAG框架，通过整合因果图和反事实推理到RAG中，提升检索和生成的准确性、鲁棒性和可解释性。", "motivation": "解决传统RAG系统因文本分块和过度依赖语义相似性导致的上下文完整性破坏和浅层响应问题，特别是在知识密集型领域。", "method": "集成显式因果图表示因果关系到检索过程，并基于因果结构进行反事实推理，结合因果证据和反事实性评估。", "result": "框架通过因果路径和假设场景，保持上下文连贯性，减少幻觉，并增强推理保真度。", "conclusion": "Causal-Counterfactual RAG能生成更准确、鲁棒和可解释的答案，改进动态推理能力。"}}
{"id": "2509.14268", "title": "DetectAnyLLM: Towards Generalizable and Robust Detection of Machine-Generated Text Across Domains and Models", "authors": ["Jiachen Fu", "Chun-Le Guo", "Chongyi Li"], "abstract": "The rapid advancement of large language models (LLMs) has drawn urgent attention to the task of machine-generated text detection (MGTD). However, existing approaches struggle in complex real-world scenarios: zero-shot detectors rely heavily on scoring model's output distribution while training-based detectors are often constrained by overfitting to the training data, limiting generalization. We found that the performance bottleneck of training-based detectors stems from the misalignment between training objective and task needs. To address this, we propose Direct Discrepancy Learning (DDL), a novel optimization strategy that directly optimizes the detector with task-oriented knowledge. DDL enables the detector to better capture the core semantics of the detection task, thereby enhancing both robustness and generalization. Built upon this, we introduce DetectAnyLLM, a unified detection framework that achieves state-of-the-art MGTD performance across diverse LLMs. To ensure a reliable evaluation, we construct MIRAGE, the most diverse multi-task MGTD benchmark. MIRAGE samples human-written texts from 10 corpora across 5 text-domains, which are then re-generated or revised using 17 cutting-edge LLMs, covering a wide spectrum of proprietary models and textual styles. Extensive experiments on MIRAGE reveal the limitations of existing methods in complex environment. In contrast, DetectAnyLLM consistently outperforms them, achieving over a 70% performance improvement under the same training data and base scoring model, underscoring the effectiveness of our DDL. Project page: {", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14268.pdf", "abstract_url": "https://arxiv.org/abs/2509.14268", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种名为DetectAnyLLM的统一检测框架，通过Direct Discrepancy Learning优化策略，显著提高了机器生成文本检测的泛化性和鲁棒性，在多样化基准测试中表现优异。", "motivation": "解决现有机器生成文本检测方法在复杂现实场景中泛化能力不足的问题，如零样本检测器依赖输出分布评分，而训练型检测器易过拟合。", "method": "采用Direct Discrepancy Learning (DDL)优化策略，直接优化检测器以捕获任务核心语义，并构建DetectAnyLLM框架和MIRAGE基准测试。", "result": "在MIRAGE基准上，DetectAnyLLM consistently outperforms existing methods, achieving over a 70% performance improvement under the same conditions.", "conclusion": "DDL和DetectAnyLLM框架有效提升了检测性能，强调了任务导向知识在增强泛化和鲁棒性方面的重要性。"}}
{"id": "2509.14477", "title": "Ticket-Bench: A Kickoff for Multilingual and Regionalized Agent Evaluation", "authors": ["Thales Sales Almeida", "João Guilherme Alves Santos", "Thiago Laitz", "Giovana Kerche Bonás"], "abstract": "Large language models (LLMs) are increasingly deployed as task-oriented agents, where success depends on their ability to generate accurate function calls under realistic, multilingual conditions. However, existing agent evaluations largely overlook cultural and linguistic diversity, often relying on monolingual or naively translated benchmarks. We introduce Ticket-Bench, a benchmark for multilingual agent evaluation in task-oriented scenarios. Ticket-Bench simulates the domain of soccer ticket purchases across six major languages: Portuguese, English, Spanish, German, Italian, and French. Using localized teams, cities, and user profiles to provide a higher level of realism. We evaluate a wide range of commercial and open-source LLMs, measuring function-calling accuracy and consistency across languages. Results show that reasoning-oriented models (e.g., GPT-5, Qwen3-235B) dominate performance but still exhibit notable cross-lingual disparities. These findings underscore the need for culturally aware, multilingual benchmarks to guide the development of robust LLM agents.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14477.pdf", "abstract_url": "https://arxiv.org/abs/2509.14477", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "Ticket-Bench 是一个多语言代理评估基准，专注于足球票务场景，涵盖六种语言，用于评估 LLM 在任务导向环境中的函数调用准确性和一致性。", "motivation": "现有代理评估忽视文化和语言多样性，依赖单语或简单翻译基准，无法准确反映多语言现实条件。", "method": "创建 Ticket-Bench 基准，模拟足球票务购买，使用本地化团队、城市和用户资料，评估多种商业和开源 LLM 的函数调用准确性和跨语言一致性。", "result": "推理导向模型（如 GPT-5、Qwen3-235B）性能领先，但仍存在显著的跨语言差异。", "conclusion": "需要文化感知的多语言基准来指导开发更稳健的 LLM 代理。"}}
{"id": "2509.14480", "title": "Process-Supervised Reinforcement Learning for Interactive Multimodal Tool-Use Agents", "authors": ["Weiting Tan", "Xinghua Qu", "Ming Tu", "Meng Ge", "Andy T. Liu", "Philipp Koehn", "Lu Lu"], "abstract": "Effective interactive tool use requires agents to master Tool Integrated Reasoning (TIR): a complex process involving multi-turn planning and long-context dialogue management. To train agents for this dynamic process, particularly in multi-modal contexts, we introduce a sandbox environment for reinforcement learning (RL) that supports interleaved speech-text rollouts. Our core strategy, Turn-level Adjudicated Reinforcement Learning (TARL), addresses the challenge of credit assignment in long-horizon tasks by employing a Large Language Model (LLM) as a judge to provide turn-level evaluation. To enhance exploration, we integrate a mixed-task training curriculum with mathematical reasoning problems. This unified approach boosts the task pass rate on the text-based $\\tau$-bench by over 6% compared to strong RL baselines. Crucially, we demonstrate our framework's suitability for fine-tuning a multi-modal foundation model for agentic tasks. By training a base multi-modal LLM on interleaved speech-text rollouts, we equip it with tool-use abilities, paving the way for more natural, voice-driven interactive agents.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14480.pdf", "abstract_url": "https://arxiv.org/abs/2509.14480", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种用于交互式多模态工具使用代理的强化学习框架，通过沙盒环境和TARL方法，结合LLM作为评判者，提升任务完成率，并成功微调多模态基础模型。", "motivation": "解决在长视野任务中信用分配和探索的挑战，特别是在多模态上下文中训练代理进行工具集成推理。", "method": "使用沙盒环境进行强化学习，采用Turn-level Adjudicated Reinforcement Learning (TARL)方法，利用LLM作为评判者进行回合级评估，并结合混合任务训练课程。", "result": "在文本基准τ-bench上，任务通过率比强RL基线提高了超过6%，并成功微调了多模态基础模型以具备工具使用能力。", "conclusion": "该框架为更自然的语音驱动交互代理铺平了道路，展示了其在多模态代理任务中的适用性和有效性。"}}
{"id": "2509.15159", "title": "AIP: Subverting Retrieval-Augmented Generation via Adversarial Instructional Prompt", "authors": ["Saket S. Chaturvedi", "Gaurav Bagwe", "Lan Zhang", "Xiaoyong Yuan"], "abstract": "Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by retrieving relevant documents from external sources to improve factual accuracy and verifiability. However, this reliance introduces new attack surfaces within the retrieval pipeline, beyond the LLM itself. While prior RAG attacks have exposed such vulnerabilities, they largely rely on manipulating user queries, which is often infeasible in practice due to fixed or protected user inputs. This narrow focus overlooks a more realistic and stealthy vector: instructional prompts, which are widely reused, publicly shared, and rarely audited. Their implicit trust makes them a compelling target for adversaries to manipulate RAG behavior covertly.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL)", "comments": "Accepted at EMNLP 2025 Conference", "pdf_url": "https://arxiv.org/pdf/2509.15159.pdf", "abstract_url": "https://arxiv.org/abs/2509.15159", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "该论文探讨了检索增强生成（RAG）系统中通过对抗性指令提示进行攻击的新方法，揭示了指令提示作为隐蔽攻击向量的风险。", "motivation": "解决RAG系统在依赖外部检索时引入的新攻击面，特别是针对用户查询操纵不切实际的情况，关注更现实的指令提示漏洞。", "method": "通过分析和利用广泛重用且未审计的指令提示，设计对抗性指令来隐秘地操纵RAG行为，超越传统查询操纵攻击。", "result": "发现指令提示是有效的攻击向量，能够在不修改用户输入的情况下颠覆RAG系统，提高攻击的隐蔽性和可行性。", "conclusion": "结论是RAG系统需要加强对指令提示的审计和安全措施，以防止潜在的攻击，并提升整体系统的鲁棒性。"}}
{"id": "2509.15219", "title": "Out-of-Sight Trajectories: Tracking, Fusion, and Prediction", "authors": ["Haichao Zhang", "Yi Xu", "Yun Fu"], "abstract": "Trajectory prediction is a critical task in computer vision and autonomous systems, playing a key role in autonomous driving, robotics, surveillance, and virtual reality. Existing methods often rely on complete and noise-free observational data, overlooking the challenges associated with out-of-sight objects and the inherent noise in sensor data caused by limited camera coverage, obstructions, and the absence of ground truth for denoised trajectories. These limitations pose safety risks and hinder reliable prediction in real-world scenarios. In this extended work, we present advancements in Out-of-Sight Trajectory (OST), a novel task that predicts the noise-free visual trajectories of out-of-sight objects using noisy sensor data. Building on our previous research, we broaden the scope of Out-of-Sight Trajectory Prediction (OOSTraj) to include pedestrians and vehicles, extending its applicability to autonomous driving, robotics, surveillance, and virtual reality. Our enhanced Vision-Positioning Denoising Module leverages camera calibration to establish a vision-positioning mapping, addressing the lack of visual references, while effectively denoising noisy sensor data in an unsupervised manner. Through extensive evaluations on the Vi-Fi and JRDB datasets, our approach achieves state-of-the-art performance in both trajectory denoising and prediction, significantly surpassing previous baselines. Additionally, we introduce comparisons with traditional denoising methods, such as Kalman filtering, and adapt recent trajectory prediction models to our task, providing a comprehensive benchmark. This work represents the first initiative to integrate vision-positioning projection for denoising noisy sensor trajectories of out-of-sight agents, paving the way for future advances. The code and preprocessed datasets are available at", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Multiagent Systems (cs.MA); Multimedia (cs.MM); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.15219.pdf", "abstract_url": "https://arxiv.org/abs/2509.15219", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)", "Multimedia (cs.MM)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新颖的视觉-定位去噪模块，用于预测视线外物体的无噪声轨迹，在多个数据集上实现了最先进的性能。", "motivation": "解决现有方法依赖完整无噪声观测数据的问题，应对视线外物体和传感器噪声带来的挑战，以提高自动驾驶等领域的预测可靠性。", "method": "使用视觉-定位映射和相机校准，以无监督方式去噪传感器数据，并扩展应用到行人和车辆。", "result": "在Vi-Fi和JRDB数据集上，轨迹去噪和预测性能显著超越基线，优于卡尔曼滤波等传统方法。", "conclusion": "首次整合视觉-定位投影，为视线外代理的轨迹处理开辟了新途径，代码和数据集已公开。"}}
{"id": "2509.15221", "title": "ScaleCUA: Scaling Open-Source Computer Use Agents with Cross-Platform Data", "authors": ["Zhaoyang Liu", "JingJing Xie", "Zichen Ding", "Zehao Li", "Bowen Yang", "Zhenyu Wu", "Xuehui Wang", "Qiushi Sun", "Shi Liu", "Weiyun Wang", "Shenglong Ye", "Qingyun Li", "Zeyue Tian", "Gen Luo", "Xiangyu Yue", "Biqing Qi", "Kai Chen", "Bowen Zhou", "Yu Qiao", "Qifeng Chen", "Wenhai Wang"], "abstract": "Vision-Language Models (VLMs) have enabled computer use agents (CUAs) that operate GUIs autonomously, showing great potential, yet progress is limited by the lack of large-scale, open-source computer use data and foundation models. In this work, we introduce ScaleCUA, a step toward scaling open-source CUAs. It offers a large-scale dataset spanning 6 operating systems and 3 task domains, built via a closed-loop pipeline uniting automated agents with human experts. Trained on this scaled-up data, ScaleCUA can operate seamlessly across platforms. Specifically, it delivers strong gains over baselines (+26.6 on WebArena-Lite-v2, +10.7 on ScreenSpot-Pro) and sets new state-of-the-art results (94.4% on MMBench-GUI L1-Hard, 60.6% on OSWorld-G, 47.4% on WebArena-Lite-v2). These findings underscore the power of data-driven scaling for general-purpose computer use agents. We will release data, models, and code to advance future research:", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.15221.pdf", "abstract_url": "https://arxiv.org/abs/2509.15221", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "ScaleCUA 是一个通过大规模跨平台数据集和训练提升开源计算机使用代理性能的项目，在多个基准测试中取得显著改进和新的最先进结果。", "motivation": "解决由于缺乏大规模开源计算机使用数据和基础模型而限制计算机使用代理发展的瓶颈问题。", "method": "构建一个大规模数据集，覆盖6个操作系统和3个任务领域，使用自动化代理与人类专家结合的闭环管道进行数据收集和训练。", "result": "在多个基准测试中表现出色，如 WebArena-Lite-v2 提升26.6分，ScreenSpot-Pro 提升10.7分，并在 MMBench-GUI L1-Hard 等测试中达到新最先进水平。", "conclusion": "数据驱动的扩展方法对通用计算机使用代理具有强大潜力，将发布数据、模型和代码以促进未来研究。"}}
{"id": "2509.14635", "title": "SWE-QA: Can Language Models Answer Repository-level Code Questions?", "authors": ["Weihan Peng", "Yuling Shi", "Yuhang Wang", "Xinyun Zhang", "Beijun Shen", "Xiaodong Gu"], "abstract": "Understanding and reasoning about entire software repositories is an essential capability for intelligent software engineering tools. While existing benchmarks such as CoSQA and CodeQA have advanced the field, they predominantly focus on small, self-contained code snippets. These setups fail to capture the complexity of real-world repositories, where effective understanding and reasoning often require navigating multiple files, understanding software architecture, and grounding answers in long-range code dependencies. In this paper, we present SWE-QA, a repository-level code question answering (QA) benchmark designed to facilitate research on automated QA systems in realistic code environments. SWE-QA involves 576 high-quality question-answer pairs spanning diverse categories, including intention understanding, cross-file reasoning, and multi-hop dependency analysis. To construct SWE-QA, we first crawled 77,100 GitHub issues from 11 popular repositories. Based on an analysis of naturally occurring developer questions extracted from these issues, we developed a two-level taxonomy of repository-level questions and constructed a set of seed questions for each category. For each category, we manually curated and validated questions and collected their corresponding answers. As a prototype application, we further develop SWE-QA-Agent, an agentic framework in which LLM agents reason and act to find answers automatically. We evaluate six advanced LLMs on SWE-QA under various context augmentation strategies. Experimental results highlight the promise of LLMs, particularly our SWE-QA-Agent framework, in addressing repository-level QA, while also revealing open challenges and pointing to future research directions.", "subjects": "Computation and Language (cs.CL); Programming Languages (cs.PL); Software Engineering (cs.SE)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2509.14635.pdf", "abstract_url": "https://arxiv.org/abs/2509.14635", "categories": ["Computation and Language (cs.CL)", "Programming Languages (cs.PL)", "Software Engineering (cs.SE)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了SWE-QA基准，用于评估语言模型在软件仓库级代码问答中的能力，包括构建高质量问答对和开发SWE-QA-Agent框架，实验显示LLMs的潜力与挑战。", "motivation": "现有基准如CoSQA和CodeQA主要关注小代码片段，无法捕捉真实仓库的复杂性，需要解决多文件导航、软件架构理解和长程依赖推理的问题。", "method": "通过爬取GitHub问题，开发两级分类法，手动构建和验证576个问答对，并创建SWE-QA-Agent框架，使用LLM代理自动推理和行动。", "result": "实验评估了六种先进LLM，SWE-QA-Agent框架在仓库级QA中表现出前景，但也揭示了开放挑战。", "conclusion": "SWE-QA促进了自动化QA系统研究，指出了未来方向，强调LLMs在真实代码环境中的应用潜力。"}}
{"id": "2509.14671", "title": "TableDART: Dynamic Adaptive Multi-Modal Routing for Table Understanding", "authors": ["Xiaobo Xing", "Wei Yuan", "Tong Chen", "Quoc Viet Hung Nguyen", "Xiangliang Zhang", "Hongzhi Yin"], "abstract": "Modeling semantic and structural information from tabular data remains a core challenge for effective table understanding. Existing Table-as-Text approaches flatten tables for large language models (LLMs), but lose crucial structural cues, while Table-as-Image methods preserve structure yet struggle with fine-grained semantics. Recent Table-as-Multimodality strategies attempt to combine textual and visual views, but they (1) statically process both modalities for every query-table pair within a large multimodal LLMs (MLLMs), inevitably introducing redundancy and even conflicts, and (2) depend on costly fine-tuning of MLLMs. In light of this, we propose TableDART, a training-efficient framework that integrates multimodal views by reusing pretrained single-modality models. TableDART introduces a lightweight 2.59M-parameter MLP gating network that dynamically selects the optimal path (either Text-only, Image-only, or Fusion) for each table-query pair, effectively reducing redundancy and conflicts from both modalities. In addition, we propose a novel agent to mediate cross-modal knowledge integration by analyzing outputs from text- and image-based models, either selecting the best result or synthesizing a new answer through reasoning. This design avoids the prohibitive costs of full MLLM fine-tuning. Extensive experiments on seven benchmarks show that TableDART establishes new state-of-the-art performance among open-source models, surpassing the strongest baseline by an average of 4.02%. The code is available at:", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14671.pdf", "abstract_url": "https://arxiv.org/abs/2509.14671", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "TableDART 是一个高效的多模态框架，通过动态路径选择和知识集成，提升表格理解性能，无需昂贵微调。", "motivation": "解决现有表格理解方法在保留结构和语义信息时存在的冗余、冲突和高成本问题。", "method": "使用轻量级门控网络动态选择文本、图像或融合路径，并通过代理集成跨模态知识。", "result": "在七个基准测试中，平均性能提升 4.02%，达到开源模型中的最先进水平。", "conclusion": "TableDART 提供了一种训练高效的方法，有效结合多模态视图，减少冗余和成本，具有实际应用潜力。"}}
{"id": "2509.14998", "title": "A Knowledge-driven Adaptive Collaboration of LLMs for Enhancing Medical Decision-making", "authors": ["Xiao Wu", "Ting-Zhu Huang", "Liang-Jian Deng", "Yanyuan Qiao", "Imran Razzak", "Yutong Xie"], "abstract": "Medical decision-making often involves integrating knowledge from multiple clinical specialties, typically achieved through multidisciplinary teams. Inspired by this collaborative process, recent work has leveraged large language models (LLMs) in multi-agent collaboration frameworks to emulate expert teamwork. While these approaches improve reasoning through agent interaction, they are limited by static, pre-assigned roles, which hinder adaptability and dynamic knowledge integration. To address these limitations, we propose KAMAC, a Knowledge-driven Adaptive Multi-Agent Collaboration framework that enables LLM agents to dynamically form and expand expert teams based on the evolving diagnostic context. KAMAC begins with one or more expert agents and then conducts a knowledge-driven discussion to identify and fill knowledge gaps by recruiting additional specialists as needed. This supports flexible, scalable collaboration in complex clinical scenarios, with decisions finalized through reviewing updated agent comments. Experiments on two real-world medical benchmarks demonstrate that KAMAC significantly outperforms both single-agent and advanced multi-agent methods, particularly in complex clinical scenarios (i.e., cancer prognosis) requiring dynamic, cross-specialty expertise. Our code is publicly available at:", "subjects": "Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "comments": "The paper has been accepted to the EMNLP 2025 Main Conference", "pdf_url": "https://arxiv.org/pdf/2509.14998.pdf", "abstract_url": "https://arxiv.org/abs/2509.14998", "categories": ["Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出KAMAC框架，通过知识驱动的自适应多智能体协作，动态组建专家团队以增强医疗决策，在复杂场景中显著优于现有方法。", "motivation": "解决现有多智能体协作框架中静态角色分配导致的适应性和动态知识整合不足的问题。", "method": "使用KAMAC框架，基于诊断上下文动态形成和扩展专家团队，通过知识驱动讨论填补知识缺口，并审查更新评论以最终决策。", "result": "在两个真实医疗基准测试中，KAMAC在复杂临床场景（如癌症预后）中显著优于单智能体和先进多智能体方法。", "conclusion": "KAMAC支持灵活、可扩展的协作，提升医疗决策质量，代码已公开。"}}
{"id": "2509.15076", "title": "Forecasting and Visualizing Air Quality from Sky Images with Vision-Language Models", "authors": ["Mohammad Saleh Vahdatpour", "Maryam Eyvazi", "Yanqing Zhang"], "abstract": "Air pollution remains a critical threat to public health and environmental sustainability, yet conventional monitoring systems are often constrained by limited spatial coverage and accessibility. This paper proposes an AI-driven agent that predicts ambient air pollution levels from sky images and synthesizes realistic visualizations of pollution scenarios using generative modeling. Our approach combines statistical texture analysis with supervised learning for pollution classification, and leverages vision-language model (VLM)-guided image generation to produce interpretable representations of air quality conditions. The generated visuals simulate varying degrees of pollution, offering a foundation for user-facing interfaces that improve transparency and support informed environmental decision-making. These outputs can be seamlessly integrated into intelligent applications aimed at enhancing situational awareness and encouraging behavioral responses based on real-time forecasts. We validate our method using a dataset of urban sky images and demonstrate its effectiveness in both pollution level estimation and semantically consistent visual synthesis. The system design further incorporates human-centered user experience principles to ensure accessibility, clarity, and public engagement in air quality forecasting. To support scalable and energy-efficient deployment, future iterations will incorporate a green CNN architecture enhanced with FPGA-based incremental learning, enabling real-time inference on edge platforms.", "subjects": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV)", "comments": "Published at ICCVW 2025", "pdf_url": "https://arxiv.org/pdf/2509.15076.pdf", "abstract_url": "https://arxiv.org/abs/2509.15076", "categories": ["Machine Learning (cs.LG)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于AI的方法，利用天空图像预测空气质量，并通过生成模型合成可视化污染场景，结合统计纹理分析和监督学习进行分类，以及VLM引导的图像生成，以提高透明度和支持环境决策。", "motivation": "解决传统空气质量监测系统空间覆盖有限和可访问性不足的问题，以改善公共健康和环境可持续性。", "method": "结合统计纹理分析和监督学习进行污染分类，并利用视觉语言模型引导生成图像来模拟不同污染程度。", "result": "方法在数据集上验证有效，能准确估计污染水平并生成语义一致的视觉合成，支持实时预测和用户界面集成。", "conclusion": "系统设计注重用户体验，未来将采用绿色CNN和FPGA增量学习以实现可扩展、节能的边缘部署，提升环境意识和行为响应。"}}
{"id": "2509.14834", "title": "LLM Agents at the Roundtable: A Multi-Perspective and Dialectical Reasoning Framework for Essay Scoring", "authors": ["Jinhee Jang", "Ayoung Moon", "Minkyoung Jung", "YoungBin Kim. Seung Jin Lee"], "abstract": "The emergence of large language models (LLMs) has brought a new paradigm to automated essay scoring (AES), a long-standing and practical application of natural language processing in education. However, achieving human-level multi-perspective understanding and judgment remains a challenge. In this work, we propose Roundtable Essay Scoring (RES), a multi-agent evaluation framework designed to perform precise and human-aligned scoring under a zero-shot setting. RES constructs evaluator agents based on LLMs, each tailored to a specific prompt and topic context. Each agent independently generates a trait-based rubric and conducts a multi-perspective evaluation. Then, by simulating a roundtable-style discussion, RES consolidates individual evaluations through a dialectical reasoning process to produce a final holistic score that more closely aligns with human evaluation. By enabling collaboration and consensus among agents with diverse evaluation perspectives, RES outperforms prior zero-shot AES approaches. Experiments on the ASAP dataset using ChatGPT and Claude show that RES achieves up to a 34.86% improvement in average QWK over straightforward prompting (Vanilla) methods.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14834.pdf", "abstract_url": "https://arxiv.org/abs/2509.14834", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了Roundtable Essay Scoring (RES)框架，利用多智能体系统进行零样本自动论文评分，通过模拟圆桌讨论整合多视角评估，显著提升评分准确性和与人类评价的一致性。", "motivation": "解决大型语言模型在自动论文评分中难以实现人类水平的多视角理解和判断的问题。", "method": "构建基于LLM的评估智能体，每个智能体独立生成评分标准并进行多视角评估，通过圆桌式讨论进行辩证推理整合个体评估。", "result": "在ASAP数据集上，RES相比简单提示方法，平均QWK提高了高达34.86%。", "conclusion": "RES框架通过智能体协作和共识，有效提升了零样本自动论文评分的性能，更接近人类评价。"}}
{"id": "2509.14289", "title": "From Capabilities to Performance: Evaluating Key Functional Properties of LLM Architectures in Penetration Testing", "authors": ["Lanxiao Huang", "Daksh Dave", "Ming Jin", "Tyler Cody", "Peter Beling"], "abstract": "Large language models (LLMs) are increasingly used to automate or augment penetration testing, but their effectiveness and reliability across attack phases remain unclear. We present a comprehensive evaluation of multiple LLM-based agents, from single-agent to modular designs, across realistic penetration testing scenarios, measuring empirical performance and recurring failure patterns. We also isolate the impact of five core functional capabilities via targeted augmentations: Global Context Memory (GCM), Inter-Agent Messaging (IAM), Context-Conditioned Invocation (CCI), Adaptive Planning (AP), and Real-Time Monitoring (RTM). These interventions support, respectively: (i) context coherence and retention, (ii) inter-component coordination and state management, (iii) tool use accuracy and selective execution, (iv) multi-step strategic planning, error detection, and recovery, and (v) real-time dynamic responsiveness. Our results show that while some architectures natively exhibit subsets of these properties, targeted augmentations substantially improve modular agent performance, especially in complex, multi-step, and real-time penetration testing tasks.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14289.pdf", "abstract_url": "https://arxiv.org/abs/2509.14289", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "评估LLM架构在渗透测试中的关键功能属性，通过针对性增强提升性能。", "motivation": "解决LLM在渗透测试中有效性和可靠性不明确的问题。", "method": "综合评估多种LLM代理，通过隔离和增强核心功能能力进行实验。", "result": "针对性增强显著提高模块化代理在复杂任务中的性能。", "conclusion": "增强功能属性可改善LLM在渗透测试中的表现，具有实际应用价值。"}}
{"id": "2509.14284", "title": "The Sum Leaks More Than Its Parts: Compositional Privacy Risks and Mitigations in Multi-Agent Collaboration", "authors": ["Vaidehi Patil", "Elias Stengel-Eskin", "Mohit Bansal"], "abstract": "As large language models (LLMs) become integral to multi-agent systems, new privacy risks emerge that extend beyond memorization, direct inference, or single-turn evaluations. In particular, seemingly innocuous responses, when composed across interactions, can cumulatively enable adversaries to recover sensitive information, a phenomenon we term compositional privacy leakage. We present the first systematic study of such compositional privacy leaks and possible mitigation methods in multi-agent LLM systems. First, we develop a framework that models how auxiliary knowledge and agent interactions jointly amplify privacy risks, even when each response is benign in isolation. Next, to mitigate this, we propose and evaluate two defense strategies: (1) Theory-of-Mind defense (ToM), where defender agents infer a questioner's intent by anticipating how their outputs may be exploited by adversaries, and (2) Collaborative Consensus Defense (CoDef), where responder agents collaborate with peers who vote based on a shared aggregated state to restrict sensitive information spread. Crucially, we balance our evaluation across compositions that expose sensitive information and compositions that yield benign inferences. Our experiments quantify how these defense strategies differ in balancing the privacy-utility trade-off. We find that while chain-of-thought alone offers limited protection to leakage (~39% sensitive blocking rate), our ToM defense substantially improves sensitive query blocking (up to 97%) but can reduce benign task success. CoDef achieves the best balance, yielding the highest Balanced Outcome (79.8%), highlighting the benefit of combining explicit reasoning with defender collaboration. Together, our results expose a new class of risks in collaborative LLM deployments and provide actionable insights for designing safeguards against compositional, context-driven privacy leakage.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2509.14284.pdf", "abstract_url": "https://arxiv.org/abs/2509.14284", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文系统研究了多智能体LLM系统中的组合隐私泄露问题，提出了两种防御策略（ToM和CoDef），并评估了它们在隐私与效用权衡中的表现。", "motivation": "解决大型语言模型在多智能体系统中，看似无害的响应在组合交互中累积导致敏感信息泄露的新隐私风险。", "method": "开发了一个框架建模辅助知识和智能体交互如何放大隐私风险，并提出了理论思维防御（ToM）和协作共识防御（CoDef）两种缓解方法。", "result": "ToM防御显著提高了敏感查询阻止率（高达97%），但降低了良性任务成功率；CoDef实现了最佳平衡，平衡结果达79.8%。", "conclusion": "研究揭示了协作LLM部署中的新风险类别，并提供了设计防护措施的可操作见解，以应对组合和上下文驱动的隐私泄露。"}}
{"id": "2509.14507", "title": "DeKeyNLU: Enhancing Natural Language to SQL Generation through Task Decomposition and Keyword Extraction", "authors": ["Jian Chen", "Zhenyan Chen", "Xuming Hu", "Peilin Zhou", "Yining Hua", "Han Fang", "Cissy Hing Yee Choy", "Xinmei Ke", "Jingfeng Luo", "Zixuan Yuan"], "abstract": "Natural Language to SQL (NL2SQL) provides a new model-centric paradigm that simplifies database access for non-technical users by converting natural language queries into SQL commands. Recent advancements, particularly those integrating Retrieval-Augmented Generation (RAG) and Chain-of-Thought (CoT) reasoning, have made significant strides in enhancing NL2SQL performance. However, challenges such as inaccurate task decomposition and keyword extraction by LLMs remain major bottlenecks, often leading to errors in SQL generation. While existing datasets aim to mitigate these issues by fine-tuning models, they struggle with over-fragmentation of tasks and lack of domain-specific keyword annotations, limiting their effectiveness. To address these limitations, we present DeKeyNLU, a novel dataset which contains 1,500 meticulously annotated QA pairs aimed at refining task decomposition and enhancing keyword extraction precision for the RAG pipeline. Fine-tuned with DeKeyNLU, we propose DeKeySQL, a RAG-based NL2SQL pipeline that employs three distinct modules for user question understanding, entity retrieval, and generation to improve SQL generation accuracy. We benchmarked multiple model configurations within DeKeySQL RAG pipeline. Experimental results demonstrate that fine-tuning with DeKeyNLU significantly improves SQL generation accuracy on both BIRD (62.31% to 69.10%) and Spider (84.2% to 88.7%) dev datasets.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14507.pdf", "abstract_url": "https://arxiv.org/abs/2509.14507", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "DeKeyNLU 是一个新颖的数据集，用于通过任务分解和关键词提取改进 NL2SQL 生成，DeKeySQL 管道在 BIRD 和 Spider 数据集上显著提高了准确性。", "motivation": "解决自然语言到 SQL 转换中任务分解和关键词提取不准确的问题，这些是 LLMs 的主要瓶颈，导致 SQL 生成错误。", "method": "提出 DeKeyNLU 数据集（包含 1,500 个标注 QA 对），并基于 RAG 构建 DeKeySQL 管道，使用三个模块进行问题理解、实体检索和生成。", "result": "在 BIRD 数据集上准确率从 62.31% 提升到 69.10%，在 Spider 数据集上从 84.2% 提升到 88.7%。", "conclusion": "DeKeyNLU 数据集和 DeKeySQL 管道有效提升了 NL2SQL 性能，解决了现有方法的局限性。"}}
{"id": "2509.14627", "title": "Towards Human-like Multimodal Conversational Agent by Generating Engaging Speech", "authors": ["Taesoo Kim", "Yongsik Jo", "Hyunmin Song", "Taehwan Kim"], "abstract": "Human conversation involves language, speech, and visual cues, with each medium providing complementary information. For instance, speech conveys a vibe or tone not fully captured by text alone. While multimodal LLMs focus on generating text responses from diverse inputs, less attention has been paid to generating natural and engaging speech. We propose a human-like agent that generates speech responses based on conversation mood and responsive style information. To achieve this, we build a novel MultiSensory Conversation dataset focused on speech to enable agents to generate natural speech. We then propose a multimodal LLM-based model for generating text responses and voice descriptions, which are used to generate speech covering paralinguistic information. Experimental results demonstrate the effectiveness of utilizing both visual and audio modalities in conversation to generate engaging speech. The source code is available in", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "Published in Interspeech 2025", "pdf_url": "https://arxiv.org/pdf/2509.14627.pdf", "abstract_url": "https://arxiv.org/abs/2509.14627", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种通过生成引人入胜的语音来模拟人类多模态对话的智能体，利用多感官对话数据集和基于多模态LLM的模型，结合视觉和音频模态，有效提升语音生成的自然度和吸引力。", "motivation": "解决当前多模态LLM主要关注文本响应生成，而忽视生成自然和引人入胜语音的问题，以更全面地模拟人类对话中的语言、语音和视觉线索。", "method": "构建一个新颖的MultiSensory Conversation数据集，并开发基于多模态LLM的模型，生成文本响应和语音描述，用于覆盖副语言信息的语音生成。", "result": "实验结果表明，利用视觉和音频模态在对话中生成引人入胜的语音是有效的，代码已开源。", "conclusion": "该方法成功实现了人类化多模态对话代理，强调了多模态整合的重要性，并提供了可复现的资源。"}}
{"id": "2509.14647", "title": "AgentCompass: Towards Reliable Evaluation of Agentic Workflows in Production", "authors": ["NVJK Kartik", "Garvit Sapra", "Rishav Hada", "Nikhil Pareek"], "abstract": "With the growing adoption of Large Language Models (LLMs) in automating complex, multi-agent workflows, organizations face mounting risks from errors, emergent behaviors, and systemic failures that current evaluation methods fail to capture. We present AgentCompass, the first evaluation framework designed specifically for post-deployment monitoring and debugging of agentic workflows. AgentCompass models the reasoning process of expert debuggers through a structured, multi-stage analytical pipeline: error identification and categorization, thematic clustering, quantitative scoring, and strategic summarization. The framework is further enhanced with a dual memory system-episodic and semantic-that enables continual learning across executions. Through collaborations with design partners, we demonstrate the framework's practical utility on real-world deployments, before establishing its efficacy against the publicly available TRAIL benchmark. AgentCompass achieves state-of-the-art results on key metrics, while uncovering critical issues missed in human annotations, underscoring its role as a robust, developer-centric tool for reliable monitoring and improvement of agentic systems in production.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14647.pdf", "abstract_url": "https://arxiv.org/abs/2509.14647", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "AgentCompass 是一个专为生产环境中多智能体工作流设计的后部署监控和调试评估框架，通过结构化分析和双记忆系统实现可靠评估。", "motivation": "解决大型语言模型在多智能体工作流自动化中因错误、涌现行为和系统性故障而带来的风险，当前评估方法无法有效捕获这些问题。", "method": "采用多阶段分析管道（错误识别和分类、主题聚类、量化评分和战略总结），并结合情景和语义双记忆系统实现持续学习。", "result": "在真实部署和TRAIL基准测试中取得最先进结果，发现人工标注遗漏的关键问题，证明其实用性和有效性。", "conclusion": "AgentCompass 是一个强大、以开发者为中心的工具，可可靠地监控和改进生产环境中的智能体系统。"}}
{"id": "2509.15160", "title": "An Evaluation-Centric Paradigm for Scientific Visualization Agents", "authors": ["Kuangshi Ai", "Haichao Miao", "Zhimin Li", "Chaoli Wang", "Shusen Liu"], "abstract": "Recent advances in multi-modal large language models (MLLMs) have enabled increasingly sophisticated autonomous visualization agents capable of translating user intentions into data visualizations. However, measuring progress and comparing different agents remains challenging, particularly in scientific visualization (SciVis), due to the absence of comprehensive, large-scale benchmarks for evaluating real-world capabilities. This position paper examines the various types of evaluation required for SciVis agents, outlines the associated challenges, provides a simple proof-of-concept evaluation example, and discusses how evaluation benchmarks can facilitate agent self-improvement. We advocate for a broader collaboration to develop a SciVis agentic evaluation benchmark that would not only assess existing capabilities but also drive innovation and stimulate future development in the field.", "subjects": "Human-Computer Interaction (cs.HC); Computation and Language (cs.CL); Graphics (cs.GR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.15160.pdf", "abstract_url": "https://arxiv.org/abs/2509.15160", "categories": ["Human-Computer Interaction (cs.HC)", "Computation and Language (cs.CL)", "Graphics (cs.GR)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出以评估为中心的科学可视化代理范式，强调开发全面基准以衡量和比较代理能力，促进自改进和创新。", "motivation": "多模态大语言模型进步使自主可视化代理更先进，但科学可视化领域缺乏大规模基准，难以评估和比较代理的真实能力。", "method": "作为立场论文，分析评估类型、挑战，提供概念验证评估示例，并讨论基准如何促进代理自改进。", "result": "概述了评估需求和挑战，展示了简单评估示例，并强调基准对推动领域发展的潜力。", "conclusion": "呼吁广泛合作开发科学可视化代理评估基准，以评估现有能力并驱动未来创新和发展。"}}
{"id": "2509.14382", "title": "Detecting Pipeline Failures through Fine-Grained Analysis of Web Agents", "authors": ["Daniel Röder", "Akhil Juneja", "Roland Roller", "Sven Schmeier"], "abstract": "Web agents powered by large language models (LLMs) can autonomously perform complex, multistep tasks in dynamic web environments. However, current evaluations mostly focus on the overall success while overlooking intermediate errors. This limits insight into failure modes and hinders systematic improvement. This work analyzes existing benchmarks and highlights the lack of fine-grained diagnostic tools. To address this gap, we propose a modular evaluation framework that decomposes agent pipelines into interpretable stages for detailed error analysis. Using the SeeAct framework and the Mind2Web dataset as a case study, we show how this approach reveals actionable weaknesses missed by standard metrics - paving the way for more robust and generalizable web agents.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14382.pdf", "abstract_url": "https://arxiv.org/abs/2509.14382", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种模块化评估框架，用于对基于LLM的Web代理进行细粒度错误分析，以揭示标准指标遗漏的弱点，从而提升代理的鲁棒性和泛化能力。", "motivation": "当前评估主要关注整体成功率，忽略中间错误，限制了失败模式的理解和系统改进。", "method": "提出模块化评估框架，将代理管道分解为可解释的阶段，使用SeeAct框架和Mind2Web数据集进行案例研究。", "result": "该方法揭示了标准指标遗漏的可操作弱点。", "conclusion": "该方法为开发更鲁棒和可泛化的Web代理铺平了道路。"}}
{"id": "2509.14485", "title": "Beyond the high score: Prosocial ability profiles of multi-agent populations", "authors": ["Marko Tesic", "Yue Zhao", "Joel Z. Leibo", "Rakshit S. Trivedi", "Jose Hernandez-Orallo"], "abstract": "The development and evaluation of social capabilities in AI agents require complex environments where competitive and cooperative behaviours naturally emerge. While game-theoretic properties can explain why certain teams or agent populations outperform others, more abstract behaviours, such as convention following, are harder to control in training and evaluation settings. The Melting Pot contest is a social AI evaluation suite designed to assess the cooperation capabilities of AI systems. In this paper, we apply a Bayesian approach known as Measurement Layouts to infer the capability profiles of multi-agent systems in the Melting Pot contest. We show that these capability profiles not only predict future performance within the Melting Pot suite but also reveal the underlying prosocial abilities of agents. Our analysis indicates that while higher prosocial capabilities sometimes correlate with better performance, this is not a universal trend-some lower-scoring agents exhibit stronger cooperation abilities. Furthermore, we find that top-performing contest submissions are more likely to achieve high scores in scenarios where prosocial capabilities are not required. These findings, together with reports that the contest winner used a hard-coded solution tailored to specific environments, suggest that at least one top-performing team may have optimised for conditions where cooperation was not necessary, potentially exploiting limitations in the evaluation framework. We provide recommendations for improving the annotation of cooperation demands and propose future research directions to account for biases introduced by different testing environments. Our results demonstrate that Measurement Layouts offer both strong predictive accuracy and actionable insights, contributing to a more transparent and generalisable approach to evaluating AI systems in complex social settings.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14485.pdf", "abstract_url": "https://arxiv.org/abs/2509.14485", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文使用贝叶斯测量布局方法分析多智能体系统在Melting Pot竞赛中的能力概况，发现亲社会能力与性能不完全相关，并揭示评估框架的局限性。", "motivation": "解决AI智能体在复杂社交环境中亲社会能力评估的挑战，特别是竞争与合作行为自然涌现时的评估问题。", "method": "应用贝叶斯测量布局方法推断多智能体系统的能力概况，并在Melting Pot竞赛中进行评估。", "result": "能力概况能预测性能并揭示亲社会能力，但亲社会能力与高分不完全相关；顶级提交可能在不需要合作的场景中得分高，表明评估框架存在偏见。", "conclusion": "测量布局方法提供准确预测和可操作见解，建议改进合作需求标注和未来研究以减少环境偏见，促进AI系统评估的透明性和通用性。"}}
{"id": "2509.14546", "title": "Rationality Check! Benchmarking the Rationality of Large Language Models", "authors": ["Zhilun Zhou", "Jing Yi Wang", "Nicholas Sukiennik", "Chen Gao", "Fengli Xu", "Yong Li", "James Evans"], "abstract": "Large language models (LLMs), a recent advance in deep learning and machine intelligence, have manifested astonishing capacities, now considered among the most promising for artificial general intelligence. With human-like capabilities, LLMs have been used to simulate humans and serve as AI assistants across many applications. As a result, great concern has arisen about whether and under what circumstances LLMs think and behave like real human agents. Rationality is among the most important concepts in assessing human behavior, both in thinking (i.e., theoretical rationality) and in taking action (i.e., practical rationality). In this work, we propose the first benchmark for evaluating the omnibus rationality of LLMs, covering a wide range of domains and LLMs. The benchmark includes an easy-to-use toolkit, extensive experimental results, and analysis that illuminates where LLMs converge and diverge from idealized human rationality. We believe the benchmark can serve as a foundational tool for both developers and users of LLMs.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14546.pdf", "abstract_url": "https://arxiv.org/abs/2509.14546", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了首个评估大型语言模型（LLMs）综合理性的基准，包括工具包、实验结果和分析，以比较LLMs与理想人类理性的异同。", "motivation": "解决LLMs是否以及在何种情况下像真实人类一样思考和行为的担忧，特别是评估其理论理性和实践理性。", "method": "开发一个基准，涵盖多个领域和LLMs，包括易用工具包、实验和分析。", "result": "基准提供了广泛实验结果，揭示了LLMs在理性方面与人类收敛和分歧的具体情况。", "conclusion": "该基准可作为LLMs开发者和用户的基础工具，促进对LLMs理性的理解和改进。"}}
{"id": "2509.14547", "title": "(P)rior(D)yna(F)low: A Priori Dynamic Workflow Construction via Multi-Agent Collaboration", "authors": ["Yi Lin", "Lujin Zhao", "Yijie Shi"], "abstract": "Recent studies have shown that carefully designed workflows coordinating large language models(LLMs) significantly enhance task-solving capabilities compared to using a single model. While an increasing number of works focus on autonomous workflow construction, most existing approaches rely solely on historical experience, leading to limitations in efficiency and adaptability. We argue that while historical experience is valuable, workflow construction should also flexibly respond to the unique characteristics of each task. To this end, we propose an a priori dynamic framework for automated workflow construction. Our framework first leverages Q-table learning to optimize the decision space, guiding agent decisions and enabling effective use of historical experience. At the same time, agents evaluate the current task progress and make a priori decisions regarding the next executing agent, allowing the system to proactively select the more suitable workflow structure for each given task. Additionally, we incorporate mechanisms such as cold-start initialization, early stopping, and pruning to further improve system efficiency. Experimental evaluations on four benchmark datasets demonstrate the feasibility and effectiveness of our approach. Compared to state-of-the-art baselines, our method achieves an average improvement of 4.05%, while reducing workflow construction and inference costs to only 30.68%-48.31% of those required by existing methods.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14547.pdf", "abstract_url": "https://arxiv.org/abs/2509.14547", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文提出了一种先验动态工作流构建框架，通过多智能体协作和Q表学习优化决策，提高任务解决效率和适应性。", "motivation": "解决现有工作流构建方法仅依赖历史经验导致的效率和适应性不足问题，强调需要根据任务特性灵活调整工作流。", "method": "使用Q表学习优化决策空间，结合智能体评估任务进度和先验决策，并整合冷启动、早停和剪枝机制提升效率。", "result": "在四个基准数据集上，方法平均性能提升4.05%，工作流构建和推理成本降至现有方法的30.68%-48.31%。", "conclusion": "该方法可行且有效，显著提升了工作流构建的效率和任务解决能力，具有实际应用价值。"}}
{"id": "2509.14750", "title": "Enhancing Retrieval Augmentation via Adversarial Collaboration", "authors": ["Letian Zhang", "Guanghao Meng", "Xudong Ren", "Yiming Wang", "Shu-Tao Xia"], "abstract": "Retrieval-augmented Generation (RAG) is a prevalent approach for domain-specific LLMs, yet it is often plagued by \"Retrieval Hallucinations\"--a phenomenon where fine-tuned models fail to recognize and act upon poor-quality retrieved documents, thus undermining performance. To address this, we propose the Adversarial Collaboration RAG (AC-RAG) framework. AC-RAG employs two heterogeneous agents: a generalist Detector that identifies knowledge gaps, and a domain-specialized Resolver that provides precise solutions. Guided by a moderator, these agents engage in an adversarial collaboration, where the Detector's persistent questioning challenges the Resolver's expertise. This dynamic process allows for iterative problem dissection and refined knowledge retrieval. Extensive experiments show that AC-RAG significantly improves retrieval accuracy and outperforms state-of-the-art RAG methods across various vertical domains.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14750.pdf", "abstract_url": "https://arxiv.org/abs/2509.14750", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "该论文提出了AC-RAG框架，通过对抗性协作提升检索增强生成，减少检索幻觉，提高检索准确性。", "motivation": "解决检索增强生成中的检索幻觉问题，即模型无法识别低质量检索文档，导致性能下降。", "method": "使用AC-RAG框架，包含一个通用检测器和一个领域专业解析器，在调解者指导下进行对抗性协作，迭代优化知识检索。", "result": "实验显示AC-RAG显著提高检索准确性，超越现有RAG方法。", "conclusion": "AC-RAG有效缓解检索幻觉，提升领域特定LLMs的性能，具有广泛应用前景。"}}
{"id": "2509.14778", "title": "OpenLens AI: Fully Autonomous Research Agent for Health Infomatics", "authors": ["Yuxiao Cheng", "Jinli Suo"], "abstract": "Health informatics research is characterized by diverse data modalities, rapid knowledge expansion, and the need to integrate insights across biomedical science, data analytics, and clinical practice. These characteristics make it particularly well-suited for agent-based approaches that can automate knowledge exploration, manage complex workflows, and generate clinically meaningful outputs. Recent progress in large language model (LLM)-based agents has demonstrated promising capabilities in literature synthesis, data analysis, and even end-to-end research execution. However, existing systems remain limited for health informatics because they lack mechanisms to interpret medical visualizations and often overlook domain-specific quality requirements. To address these gaps, we introduce OpenLens AI, a fully automated framework tailored to health informatics. OpenLens AI integrates specialized agents for literature review, data analysis, code generation, and manuscript preparation, enhanced by vision-language feedback for medical visualization and quality control for reproducibility. The framework automates the entire research pipeline, producing publication-ready LaTeX manuscripts with transparent and traceable workflows, thereby offering a domain-adapted solution for advancing health informatics research.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14778.pdf", "abstract_url": "https://arxiv.org/abs/2509.14778", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "OpenLens AI是一个专为健康信息学设计的全自动研究框架，整合文献回顾、数据分析、代码生成和手稿准备，通过视觉语言反馈和质量控制提升可重复性。", "motivation": "解决现有基于大语言模型的代理在健康信息学中无法解释医学可视化且忽视领域特定质量要求的问题。", "method": "集成专门代理，包括文献回顾、数据分析、代码生成和手稿准备，并采用视觉语言反馈和质量控制机制。", "result": "框架自动化整个研究流程，生成可发布的LaTeX手稿，提供透明和可追溯的工作流。", "conclusion": "OpenLens AI为健康信息学研究提供了一个领域适应的自动化解决方案，推动该领域的发展。"}}
{"id": "2509.15172", "title": "Internalizing Self-Consistency in Language Models: Multi-Agent Consensus Alignment", "authors": ["Ankur Samanta", "Akshayaa Magesh", "Youliang Yu", "Runzhe Wu", "Ayush Jain", "Daniel Jiang", "Boris Vidolov", "Paul Sajda", "Yonathan Efroni", "Kaveh Hassani"], "abstract": "Language Models (LMs) are inconsistent reasoners, often generating contradictory responses to identical prompts. While inference-time methods can mitigate these inconsistencies, they fail to address the core problem: LMs struggle to reliably select reasoning pathways leading to consistent outcomes under exploratory sampling. To address this, we formalize self-consistency as an intrinsic property of well-aligned reasoning models and introduce Multi-Agent Consensus Alignment (MACA), a reinforcement learning framework that post-trains models to favor reasoning trajectories aligned with their internal consensus using majority/minority outcomes from multi-agent debate. These trajectories emerge from deliberative exchanges where agents ground reasoning in peer arguments, not just aggregation of independent attempts, creating richer consensus signals than single-round majority voting. MACA enables agents to teach themselves to be more decisive and concise, and better leverage peer insights in multi-agent settings without external supervision, driving substantial improvements across self-consistency (+27.6% on GSM8K), single-agent reasoning (+23.7% on MATH), sampling-based inference (+22.4% Pass@20 on MATH), and multi-agent ensemble decision-making (+42.7% on MathQA). These findings, coupled with strong generalization to unseen benchmarks (+16.3% on GPQA, +11.6% on CommonsenseQA), demonstrate robust self-alignment that more reliably unlocks latent reasoning potential of language models.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.15172.pdf", "abstract_url": "https://arxiv.org/abs/2509.15172", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文提出MACA框架，通过多智能体辩论和强化学习，提高语言模型的自一致性，在多个推理任务中显著提升性能。", "motivation": "语言模型在推理时存在不一致性，生成矛盾回答，现有方法未能解决核心问题。", "method": "使用多智能体共识对齐（MACA），基于强化学习，通过多数/少数结果训练模型偏好一致推理路径。", "result": "在GSM8K、MATH等基准上自一致性提升27.6%，推理能力改善，泛化到未见数据集如GPQA。", "conclusion": "MACA实现鲁棒自对齐，可靠释放语言模型的潜在推理能力，无需外部监督。"}}
{"id": "2509.14956", "title": "Sentinel Agents for Secure and Trustworthy Agentic AI in Multi-Agent Systems", "authors": ["Diego Gosmar", "Deborah A. Dahl"], "abstract": "This paper proposes a novel architectural framework aimed at enhancing security and reliability in multi-agent systems (MAS). A central component of this framework is a network of Sentinel Agents, functioning as a distributed security layer that integrates techniques such as semantic analysis via large language models (LLMs), behavioral analytics, retrieval-augmented verification, and cross-agent anomaly detection. Such agents can potentially oversee inter-agent communications, identify potential threats, enforce privacy and access controls, and maintain comprehensive audit records. Complementary to the idea of Sentinel Agents is the use of a Coordinator Agent. The Coordinator Agent supervises policy implementation, and manages agent participation. In addition, the Coordinator also ingests alerts from Sentinel Agents. Based on these alerts, it can adapt policies, isolate or quarantine misbehaving agents, and contain threats to maintain the integrity of the MAS ecosystem. This dual-layered security approach, combining the continuous monitoring of Sentinel Agents with the governance functions of Coordinator Agents, supports dynamic and adaptive defense mechanisms against a range of threats, including prompt injection, collusive agent behavior, hallucinations generated by LLMs, privacy breaches, and coordinated multi-agent attacks. In addition to the architectural design, we present a simulation study where 162 synthetic attacks of different families (prompt injection, hallucination, and data exfiltration) were injected into a multi-agent conversational environment. The Sentinel Agents successfully detected the attack attempts, confirming the practical feasibility of the proposed monitoring approach. The framework also offers enhanced system observability, supports regulatory compliance, and enables policy evolution over time.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "25 pages, 12 figures", "pdf_url": "https://arxiv.org/pdf/2509.14956.pdf", "abstract_url": "https://arxiv.org/abs/2509.14956", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种新颖的架构框架，通过Sentinel和Coordinator代理增强多代理系统的安全性和可靠性，包括语义分析、行为分析等技术，并通过模拟实验验证了其有效性。", "motivation": "解决多代理系统中存在的安全威胁，如提示注入、幻觉和隐私泄露，以提高系统的信任度和可靠性。", "method": "使用Sentinel代理进行分布式安全监控，结合LLM语义分析和异常检测，Coordinator代理管理策略和威胁响应。", "result": "在模拟环境中，Sentinel代理成功检测了162次合成攻击，证明了监控方法的可行性。", "conclusion": "该框架提供了动态防御机制，增强系统可观测性，支持合规性，并允许策略演进，对MAS安全有重要应用价值。"}}
{"id": "2509.14265", "title": "Evolution of Kernels: Automated RISC-V Kernel Optimization with Large Language Models", "authors": ["Siyuan Chen", "Zhichao Lu", "Qingfu Zhang"], "abstract": "Automated kernel design is critical for overcoming software ecosystem barriers in emerging hardware platforms like RISC-V. While large language models (LLMs) have shown promise for automated kernel optimization, demonstrating success in CUDA domains with comprehensive technical documents and mature codebases, their effectiveness remains unproven for reference-scarce domains like RISC-V. We present Evolution of Kernels (EoK), a novel LLM-based evolutionary program search framework that automates kernel design for domains with limited reference material. EoK mitigates reference scarcity by mining and formalizing reusable optimization ideas (general design principles + actionable thoughts) from established kernel libraries' development histories; it then guides parallel LLM explorations using these ideas, enriched via Retrieval-Augmented Generation (RAG) with RISC-V-specific context, prioritizing historically effective techniques. Empirically, EoK achieves a median 1.27x speedup, surpassing human experts on all 80 evaluated kernel design tasks and improving upon prior LLM-based automated kernel design methods by 20%. These results underscore the viability of incorporating human experience into emerging domains and highlight the immense potential of LLM-based automated kernel optimization.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": "Technical report", "pdf_url": "https://arxiv.org/pdf/2509.14265.pdf", "abstract_url": "https://arxiv.org/abs/2509.14265", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出EoK，一种基于LLM的进化程序搜索框架，用于自动化RISC-V等参考稀缺领域的核设计，通过挖掘和形式化优化理念，结合RAG技术，实现中位1.27倍加速，超越人类专家和现有方法。", "motivation": "解决RISC-V等新兴硬件平台中软件生态系统障碍，特别是参考材料稀缺导致的自动化核设计挑战。", "method": "使用基于LLM的进化搜索框架，从成熟核库开发历史中挖掘可重用优化理念，并通过RAG增强RISC-V特定上下文，指导并行LLM探索。", "result": "在80个核设计任务中，EoK实现中位1.27倍加速，优于人类专家和先前LLM方法20%。", "conclusion": "EoK证明将人类经验融入新兴领域的可行性，突显LLM自动化核优化的巨大潜力。"}}
{"id": "2509.14276", "title": "Constructive Conflict-Driven Multi-Agent Reinforcement Learning for Strategic Diversity", "authors": ["Yuxiang Mai", "Qiyue Yin", "Wancheng Ni", "Pei Xu", "Kaiqi Huang"], "abstract": "In recent years, diversity has emerged as a useful mechanism to enhance the efficiency of multi-agent reinforcement learning (MARL). However, existing methods predominantly focus on designing policies based on individual agent characteristics, often neglecting the interplay and mutual influence among agents during policy formation. To address this gap, we propose Competitive Diversity through Constructive Conflict (CoDiCon), a novel approach that incorporates competitive incentives into cooperative scenarios to encourage policy exchange and foster strategic diversity among agents. Drawing inspiration from sociological research, which highlights the benefits of moderate competition and constructive conflict in group decision-making, we design an intrinsic reward mechanism using ranking features to introduce competitive motivations. A centralized intrinsic reward module generates and distributes varying reward values to agents, ensuring an effective balance between competition and cooperation. By optimizing the parameterized centralized reward module to maximize environmental rewards, we reformulate the constrained bilevel optimization problem to align with the original task objectives. We evaluate our algorithm against state-of-the-art methods in the SMAC and GRF environments. Experimental results demonstrate that CoDiCon achieves superior performance, with competitive intrinsic rewards effectively promoting diverse and adaptive strategies among cooperative agents.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": "Accepted by IJCAI 2025", "pdf_url": "https://arxiv.org/pdf/2509.14276.pdf", "abstract_url": "https://arxiv.org/abs/2509.14276", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出CoDiCon方法，通过引入竞争性内在奖励促进多智能体强化学习中的战略多样性，在SMAC和GRF环境中优于现有方法。", "motivation": "解决现有MARL方法忽视智能体间相互影响的问题，以增强战略多样性。", "method": "使用基于排名的内在奖励机制，通过集中式模块平衡竞争与合作，并优化双层优化问题。", "result": "实验显示CoDiCon性能优越，能有效促进多样和自适应策略。", "conclusion": "CoDiCon通过建设性冲突提升MARL效率，具有实际应用潜力。"}}
{"id": "2509.14279", "title": "Towards Robust Agentic CUDA Kernel Benchmarking, Verification, and Optimization", "authors": ["Robert Tjarko Lange", "Qi Sun", "Aaditya Prasad", "Maxence Faldor", "Yujin Tang", "David Ha"], "abstract": "Recent advances in large language models (LLMs) demonstrate their effectiveness in scaling test-time compute for software engineering tasks. However, these approaches often focus on high-level solutions, with limited attention to optimizing low-level CUDA kernel implementations. Additionally, existing kernel generation benchmarks suffer from exploitable loopholes and insufficient diversity in testing conditions, hindering true generalization assessment. To address these limitations, we introduce robust-kbench, a new benchmark for rigorous evaluation of kernel performance and correctness across varied scenarios. Furthermore, we present a comprehensive agentic framework that automates CUDA kernel discovery, verification, and optimization. This pipeline enables frontier LLMs to translate torch code to CUDA kernels and iteratively improve their runtime within our robust evaluation setting. Our sequential workflow first translates PyTorch code into equivalent CUDA kernels. It then optimizes their runtime using a novel evolutionary meta-generation procedure tailored to the CUDA ecosystem, guided by LLM-based verifiers for correctness and efficient filtering. Evaluated on robust-kbench, our approach produces CUDA kernels outperforming torch implementations for practical applications, including forward and backward passes. It can fuse operations and deploy various runtime optimization strategies. The verifier workflow accurately classifies incorrect kernels, enhancing hardware verification efficiency.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "62 pages, 10 figures", "pdf_url": "https://arxiv.org/pdf/2509.14279.pdf", "abstract_url": "https://arxiv.org/abs/2509.14279", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了robust-kbench基准和自动化框架，用于CUDA内核的生成、验证和优化，利用LLM提升性能并确保正确性。", "motivation": "解决现有LLM方法在低级别CUDA内核优化和基准测试中的不足，如漏洞和多样性缺乏问题。", "method": "使用基于LLM的代理框架，包括PyTorch代码翻译为CUDA内核、进化元生成优化和验证器指导的过滤。", "result": "在robust-kbench上评估，生成的CUDA内核性能优于torch实现，能融合操作并准确分类错误内核。", "conclusion": "该框架有效提升了CUDA内核的鲁棒性和效率，具有实际应用价值。"}}
{"id": "2509.14436", "title": "When Content is Goliath and Algorithm is David: The Style and Semantic Effects of Generative Search Engine", "authors": ["Lijia Ma", "Juan Qin", "Xingchen Xu", "Yong Tan"], "abstract": "Generative search engines (GEs) leverage large language models (LLMs) to deliver AI-generated summaries with website citations, establishing novel traffic acquisition channels while fundamentally altering the search engine optimization landscape. To investigate the distinctive characteristics of GEs, we collect data through interactions with Google's generative and conventional search platforms, compiling a dataset of approximately ten thousand websites across both channels. Our empirical analysis reveals that GEs exhibit preferences for citing content characterized by significantly higher predictability for underlying LLMs and greater semantic similarity among selected sources. Through controlled experiments utilizing retrieval augmented generation (RAG) APIs, we demonstrate that these citation preferences emerge from intrinsic LLM tendencies to favor content aligned with their generative expression patterns. Motivated by applications of LLMs to optimize website content, we conduct additional experimentation to explore how LLM-based content polishing by website proprietors alters AI summaries, finding that such polishing paradoxically enhances information diversity within AI summaries. Finally, to assess the user-end impact of LLM-induced information increases, we design a generative search engine and recruit Prolific participants to conduct a randomized controlled experiment involving an information-seeking and writing task. We find that higher-educated users exhibit minimal changes in their final outputs' information diversity but demonstrate significantly reduced task completion time when original sites undergo polishing. Conversely, lower-educated users primarily benefit through enhanced information density in their task outputs while maintaining similar completion times across experimental groups.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "comments": "59 pages, 6 figures, 20 tables", "pdf_url": "https://arxiv.org/pdf/2509.14436.pdf", "abstract_url": "https://arxiv.org/abs/2509.14436", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "生成式搜索引擎（GEs）利用大语言模型（LLMs）提供AI生成的摘要和网站引用，改变SEO格局，偏好可预测和语义相似的内容，通过实验发现内容优化增强信息多样性，用户教育水平影响任务结果。", "motivation": "解决生成式搜索引擎如何改变搜索优化和用户信息获取的问题，探索LLMs的引用偏好及其对内容多样性和用户效率的影响。", "method": "收集Google生成和传统搜索数据，进行实证分析和控制实验，包括使用RAG API和设计用户实验，招募参与者进行随机对照试验。", "result": "GEs偏好LLMs可预测和语义相似的内容；内容优化增加AI摘要的信息多样性；高教育用户任务时间减少，低教育用户信息密度提高。", "conclusion": "生成式搜索引擎基于LLM特性改变信息呈现，内容优化可提升多样性，用户教育水平调节影响，对SEO和AI应用有启示。"}}
{"id": "2509.14537", "title": "ClearFairy: Capturing Creative Workflows through Decision Structuring, In-Situ Questioning, and Rationale Inference", "authors": ["Kihoon Son", "DaEun Choi", "Tae Soo Kim", "Young-Ho Kim", "Sangdoo Yun", "Juho Kim"], "abstract": "Capturing professionals' decision-making in creative workflows is essential for reflection, collaboration, and knowledge sharing, yet existing methods often leave rationales incomplete and implicit decisions hidden. To address this, we present CLEAR framework that structures reasoning into cognitive decision steps-linked units of actions, artifacts, and self-explanations that make decisions traceable. Building on this framework, we introduce ClearFairy, a think-aloud AI assistant for UI design that detects weak explanations, asks lightweight clarifying questions, and infers missing rationales to ease the knowledge-sharing burden. In a study with twelve creative professionals, 85% of ClearFairy's inferred rationales were accepted, increasing strong explanations from 14% to over 83% of decision steps without adding cognitive demand. The captured steps also enhanced generative AI agents in Figma, yielding next-action predictions better aligned with professionals and producing more coherent design outcomes. For future research on human knowledge-grounded creative AI agents, we release a dataset of captured 417 decision steps.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14537.pdf", "abstract_url": "https://arxiv.org/abs/2509.14537", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "ClearFairy是一个AI助手，通过结构化决策步骤、实时提问和推断理由，捕获创意工作流程中的决策，提高解释质量和生成AI代理的性能。", "motivation": "解决创意工作流程中决策理由不完整和隐含决策难以捕获的问题，以支持反思、协作和知识共享。", "method": "使用CLEAR框架结构化推理，引入ClearFairy AI助手检测弱解释、提问并推断缺失理由。", "result": "在12名专业人士研究中，85%的推断理由被接受，强解释从14%增至83%以上，且提升生成AI代理的预测和设计连贯性。", "conclusion": "ClearFairy有效捕获决策步骤，减轻知识共享负担，并发布数据集支持未来创意AI代理研究。"}}
{"id": "2509.14608", "title": "Enterprise AI Must Enforce Participant-Aware Access Control", "authors": ["Shashank Shreedhar Bhatt", "Tanmay Rajore", "Khushboo Aggarwal", "Ganesh Ananthanarayanan", "Ranveer Chandra", "Nishanth Chandran", "Suyash Choudhury", "Divya Gupta", "Emre Kiciman", "Sumit Kumar Pandey", "Srinath Setty", "Rahul Sharma", "Teijia Zhao"], "abstract": "Large language models (LLMs) are increasingly deployed in enterprise settings where they interact with multiple users and are trained or fine-tuned on sensitive internal data. While fine-tuning enhances performance by internalizing domain knowledge, it also introduces a critical security risk: leakage of confidential training data to unauthorized users. These risks are exacerbated when LLMs are combined with Retrieval-Augmented Generation (RAG) pipelines that dynamically fetch contextual documents at inference time.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14608.pdf", "abstract_url": "https://arxiv.org/abs/2509.14608", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "企业AI需实施参与者感知访问控制，以防止LLM微调和RAG管道中的敏感数据泄露。", "motivation": "解决在企业环境中部署LLM时，由于微调和RAG使用导致的机密训练数据泄露给未授权用户的安全风险。", "method": "提出参与者感知访问控制方法，以增强LLM在企业设置中的安全性。", "result": "强调了数据泄露风险，并建议通过访问控制机制来缓解这些风险。", "conclusion": "企业AI系统必须集成访问控制，以保护敏感信息并确保合规性。"}}
{"id": "2509.14622", "title": "Adversarial Distilled Retrieval-Augmented Guarding Model for Online Malicious Intent Detection", "authors": ["Yihao Guo", "Haocheng Bian", "Liutong Zhou", "Ze Wang", "Zhaoyi Zhang", "Francois Kawala", "Milan Dean", "Ian Fischer", "Yuantao Peng", "Noyan Tokgozoglu", "Ivan Barrientos", "Riyaaz Shaik", "Rachel Li", "Chandru Venkataraman", "Reza Shifteh Far", "Moses Pawar", "Venkat Sundaranatha", "Michael Xu", "Frank Chu"], "abstract": "With the deployment of Large Language Models (LLMs) in interactive applications, online malicious intent detection has become increasingly critical. However, existing approaches fall short of handling diverse and complex user queries in real time. To address these challenges, we introduce ADRAG (Adversarial Distilled Retrieval-Augmented Guard), a two-stage framework for robust and efficient online malicious intent detection. In the training stage, a high-capacity teacher model is trained on adversarially perturbed, retrieval-augmented inputs to learn robust decision boundaries over diverse and complex user queries. In the inference stage, a distillation scheduler transfers the teacher's knowledge into a compact student model, with a continually updated knowledge base collected online. At deployment, the compact student model leverages top-K similar safety exemplars retrieved from the online-updated knowledge base to enable both online and real-time malicious query detection. Evaluations across ten safety benchmarks demonstrate that ADRAG, with a 149M-parameter model, achieves 98.5% of WildGuard-7B's performance, surpasses GPT-4 by 3.3% and Llama-Guard-3-8B by 9.5% on out-of-distribution detection, while simultaneously delivering up to 5.6x lower latency at 300 queries per second (QPS) in real-time applications.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14622.pdf", "abstract_url": "https://arxiv.org/abs/2509.14622", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出ADRAG框架，通过对抗蒸馏和检索增强实现高效实时的在线恶意意图检测，在多个基准测试中表现优异且延迟低。", "motivation": "解决大型语言模型部署中现有方法无法实时处理多样复杂用户查询的问题。", "method": "使用两阶段框架：训练阶段用对抗扰动和检索增强训练教师模型，推理阶段通过蒸馏调度器将知识转移到紧凑学生模型，并利用在线更新的知识库进行检索。", "result": "ADRAG在10个安全基准测试中，以149M参数模型达到WildGuard-7B性能的98.5%，超越GPT-4 3.3%和Llama-Guard-3-8B 9.5%的OOD检测，延迟降低5.6倍，支持300 QPS。", "conclusion": "ADRAG提供了一种鲁棒且高效的在线恶意意图检测方法，适用于实时应用，具有高准确性和低延迟的优势。"}}
{"id": "2509.14803", "title": "OnlineMate: An LLM-Based Multi-Agent Companion System for Cognitive Support in Online Learning", "authors": ["Xian Gao", "Zongyun Zhang", "Ting Liu", "Yuzhuo Fu"], "abstract": "In online learning environments, students often lack personalized peer interactions, which play a crucial role in supporting cognitive development and learning engagement. Although previous studies have utilized large language models (LLMs) to simulate interactive dynamic learning environments for students, these interactions remain limited to conversational exchanges, lacking insights and adaptations to the learners' individualized learning and cognitive states. As a result, students' interest in discussions with AI learning companions is low, and they struggle to gain inspiration from such interactions. To address this challenge, we propose OnlineMate, a multi-agent learning companion system driven by LLMs that integrates the Theory of Mind (ToM). OnlineMate is capable of simulating peer-like agent roles, adapting to learners' cognitive states during collaborative discussions, and inferring their psychological states, such as misunderstandings, confusion, or motivation. By incorporating Theory of Mind capabilities, the system can dynamically adjust its interaction strategies to support the development of higher-order thinking and cognition. Experimental results in simulated learning scenarios demonstrate that OnlineMate effectively fosters deep learning and discussions while enhancing cognitive engagement in online educational settings.", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14803.pdf", "abstract_url": "https://arxiv.org/abs/2509.14803", "categories": ["Computers and Society (cs.CY)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "OnlineMate是一个基于LLM的多智能体学习伴侣系统，整合心智理论，模拟同伴角色，适应学习者认知状态，提升在线学习中的深度讨论和认知参与。", "motivation": "解决在线学习中学生缺乏个性化同伴互动的问题，现有LLM系统仅限对话，无法适应个体学习状态，导致学生兴趣低和启发不足。", "method": "使用LLM驱动的多智能体系统，集成心智理论，模拟同伴角色，动态调整互动策略以适应学习者的认知和心理状态。", "result": "实验结果显示，在模拟学习场景中，OnlineMate有效促进深度学习和讨论，增强认知参与。", "conclusion": "OnlineMate系统通过心智理论整合，能动态支持高阶思维发展，改善在线教育中的认知支持。"}}
{"id": "2509.14877", "title": "AI-Driven Multi-Agent Vehicular Planning for Battery Efficiency and QoS in 6G Smart Cities", "authors": ["Rohin Gillgallon", "Giacomo Bergami", "Reham Almutairi", "Graham Morgan"], "abstract": "While simulators exist for vehicular IoT nodes communicating with the Cloud through Edge nodes in a fully-simulated osmotic architecture, they often lack support for dynamic agent planning and optimisation to minimise vehicular battery consumption while ensuring fair communication times. Addressing these challenges requires extending current simulator architectures with AI algorithms for both traffic prediction and dynamic agent planning. This paper presents an extension of SimulatorOrchestrator (SO) to meet these requirements. Preliminary results over a realistic urban dataset show that utilising vehicular planning algorithms can lead to improved battery and QoS performance compared with traditional shortest path algorithms. The additional inclusion of desirability areas enabled more ambulances to be routed to their target destinations while utilising less energy to do so, compared to traditional and weighted algorithms without desirability considerations.", "subjects": "Networking and Internet Architecture (cs.NI); Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET)", "comments": "16 pages, 2 figures, 2 tables, 2 algorithms", "pdf_url": "https://arxiv.org/pdf/2509.14877.pdf", "abstract_url": "https://arxiv.org/abs/2509.14877", "categories": ["Networking and Internet Architecture (cs.NI)", "Artificial Intelligence (cs.AI)", "Emerging Technologies (cs.ET)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文扩展了SimulatorOrchestrator，通过AI算法优化多智能体车辆规划，在6G智慧城市中提高电池效率和QoS。初步结果显示，相比传统算法，能改善电池寿命和通信质量，并更有效地路由救护车。", "motivation": "解决现有模拟器在动态智能体规划和优化方面的不足，特别是最小化车辆电池消耗并确保公平通信时间的问题。", "method": "扩展SimulatorOrchestrator，集成AI算法用于交通预测和动态智能体规划，包括引入可取性区域。", "result": "在真实城市数据集上，车辆规划算法比传统最短路径算法提高了电池和QoS性能；可取性区域使救护车路由更高效且能耗更低。", "conclusion": "AI驱动的多智能体规划能显著提升6G智慧城市中的资源效率和通信公平性，具有实际应用潜力。"}}
{"id": "2509.15032", "title": "Sample Efficient Experience Replay in Non-stationary Environments", "authors": ["Tianyang Duan", "Zongyuan Zhang", "Songxiao Guo", "Yuanye Zhao", "Zheng Lin", "Zihan Fang", "Yi Liu", "Dianxin Luan", "Dong Huang", "Heming Cui", "Yong Cui"], "abstract": "Reinforcement learning (RL) in non-stationary environments is challenging, as changing dynamics and rewards quickly make past experiences outdated. Traditional experience replay (ER) methods, especially those using TD-error prioritization, struggle to distinguish between changes caused by the agent's policy and those from the environment, resulting in inefficient learning under dynamic conditions. To address this challenge, we propose the Discrepancy of Environment Dynamics (DoE), a metric that isolates the effects of environment shifts on value functions. Building on this, we introduce Discrepancy of Environment Prioritized Experience Replay (DEER), an adaptive ER framework that prioritizes transitions based on both policy updates and environmental changes. DEER uses a binary classifier to detect environment changes and applies distinct prioritization strategies before and after each shift, enabling more sample-efficient learning. Experiments on four non-stationary benchmarks demonstrate that DEER further improves the performance of off-policy algorithms by 11.54 percent compared to the best-performing state-of-the-art ER methods.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Networking and Internet Architecture (cs.NI)", "comments": "5 pages, 3 figures", "pdf_url": "https://arxiv.org/pdf/2509.15032.pdf", "abstract_url": "https://arxiv.org/abs/2509.15032", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Networking and Internet Architecture (cs.NI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种在非平稳环境中提高样本效率的经验回放方法DEER，通过度量环境动态差异和自适应优先级策略，在四个基准测试中性能提升11.54%。", "motivation": "解决强化学习在非平稳环境中传统经验回放方法难以区分策略和环境变化导致学习效率低的问题。", "method": "引入环境动态差异度量DoE，并基于此开发DEER框架，使用二元分类器检测环境变化并应用优先级策略。", "result": "在四个非平稳基准测试中，DEER相比最先进方法性能提升11.54%。", "conclusion": "DEER能有效提升非平稳环境下的样本效率和算法性能，具有实际应用价值。"}}
{"id": "2509.15042", "title": "Reinforcement Learning Agent for a 2D Shooter Game", "authors": ["Thomas Ackermann", "Moritz Spang", "Hamza A. A. Gardi"], "abstract": "Reinforcement learning agents in complex game environments often suffer from sparse rewards, training instability, and poor sample efficiency. This paper presents a hybrid training approach that combines offline imitation learning with online reinforcement learning for a 2D shooter game agent. We implement a multi-head neural network with separate outputs for behavioral cloning and Q-learning, unified by shared feature extraction layers with attention mechanisms. Initial experiments using pure deep Q-Networks exhibited significant instability, with agents frequently reverting to poor policies despite occasional good performance. To address this, we developed a hybrid methodology that begins with behavioral cloning on demonstration data from rule-based agents, then transitions to reinforcement learning. Our hybrid approach achieves consistently above 70% win rate against rule-based opponents, substantially outperforming pure reinforcement learning methods which showed high variance and frequent performance degradation. The multi-head architecture enables effective knowledge transfer between learning modes while maintaining training stability. Results demonstrate that combining demonstration-based initialization with reinforcement learning optimization provides a robust solution for developing game AI agents in complex multi-agent environments where pure exploration proves insufficient.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.15042.pdf", "abstract_url": "https://arxiv.org/abs/2509.15042", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种结合离线模仿学习和在线强化学习的混合训练方法，用于2D射击游戏AI代理，通过多头部神经网络和注意力机制，提高了训练稳定性和胜率。", "motivation": "解决强化学习代理在复杂游戏环境中面临的稀疏奖励、训练不稳定和样本效率低的问题。", "method": "使用多头部神经网络，结合行为克隆和Q学习，通过共享特征提取层和注意力机制，从演示数据初始化后过渡到强化学习。", "result": "混合方法在对抗基于规则的对手时达到超过70%的胜率，显著优于纯强化学习方法，后者表现出高方差和性能退化。", "conclusion": "结合演示初始化和强化学习优化为复杂多代理环境中的游戏AI开发提供了稳健解决方案。"}}
{"id": "2509.15103", "title": "Vulnerable Agent Identification in Large-Scale Multi-Agent Reinforcement Learning", "authors": ["Simin Li", "Zheng Yuwei", "Zihao Mao", "Linhao Wang", "Ruixiao Xu", "Chengdong Ma", "Xin Yu", "Yuqing Ma", "Qi Dou", "Xin Wang", "Jie Luo", "Bo An", "Yaodong Yang", "Weifeng Lv", "Xianglong Liu"], "abstract": "Partial agent failure becomes inevitable when systems scale up, making it crucial to identify the subset of agents whose compromise would most severely degrade overall performance. In this paper, we study this Vulnerable Agent Identification (VAI) problem in large-scale multi-agent reinforcement learning (MARL). We frame VAI as a Hierarchical Adversarial Decentralized Mean Field Control (HAD-MFC), where the upper level involves an NP-hard combinatorial task of selecting the most vulnerable agents, and the lower level learns worst-case adversarial policies for these agents using mean-field MARL. The two problems are coupled together, making HAD-MFC difficult to solve. To solve this, we first decouple the hierarchical process by Fenchel-Rockafellar transform, resulting a regularized mean-field Bellman operator for upper level that enables independent learning at each level, thus reducing computational complexity. We then reformulate the upper-level combinatorial problem as a MDP with dense rewards from our regularized mean-field Bellman operator, enabling us to sequentially identify the most vulnerable agents by greedy and RL algorithms. This decomposition provably preserves the optimal solution of the original HAD-MFC. Experiments show our method effectively identifies more vulnerable agents in large-scale MARL and the rule-based system, fooling system into worse failures, and learns a value function that reveals the vulnerability of each agent.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": "submitted to NIPS 2025", "pdf_url": "https://arxiv.org/pdf/2509.15103.pdf", "abstract_url": "https://arxiv.org/abs/2509.15103", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文提出了一种分层对抗分散平均场控制（HAD-MFC）方法，用于大规模多智能体强化学习中识别最易受攻击的智能体，通过Fenchel-Rockafellar变换解耦问题，并使用贪婪和RL算法有效识别，实验证明其有效性。", "motivation": "随着系统规模扩大，部分智能体故障不可避免，需要识别那些妥协会严重降低整体性能的智能体子集。", "method": "将问题建模为HAD-MFC，上层为NP-hard组合任务选择易受攻击智能体，下层使用平均场MARL学习最坏情况对抗策略，通过Fenchel-Rockafellar变换解耦并正则化Bellman算子，将上层问题转化为MDP进行序列识别。", "result": "实验表明，该方法在大规模MARL和基于规则的系统中有效识别更多易受攻击智能体，诱导更严重的故障，并学习到揭示每个智能体脆弱性的价值函数。", "conclusion": "该方法分解了HAD-MFC问题，保留最优解，降低了计算复杂度，为大规模MARL中的脆弱性识别提供了有效解决方案。"}}
