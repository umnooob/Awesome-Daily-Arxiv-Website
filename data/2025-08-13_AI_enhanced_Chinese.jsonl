{"id": "2508.08283", "title": "MinionsLLM: a Task-adaptive Framework For The Training and Control of Multi-Agent Systems Through Natural Language", "authors": ["Andres Garcia Rincon", "Eliseo Ferrante"], "abstract": "This paper presents MinionsLLM, a novel framework that integrates Large Language Models (LLMs) with Behavior Trees (BTs) and Formal Grammars to enable natural language control of multi-agent systems within arbitrary, user-defined environments. MinionsLLM provides standardized interfaces for defining environments, agents, and behavioral primitives, and introduces two synthetic dataset generation methods (Method A and Method B) to fine-tune LLMs for improved syntactic validity and semantic task relevance. We validate our approach using Google's Gemma 3 model family at three parameter scales (1B, 4B, and 12B) and demonstrate substantial gains: Method B increases syntactic validity to 92.6% and achieves a mean task performance improvement of 33% over baseline. Notably, our experiments show that smaller models benefit most from fine-tuning, suggesting promising directions for deploying compact, locally hosted LLMs in resource-constrained multi-agent control scenarios. The framework and all resources are released open-source to support reproducibility and future research.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multiagent Systems (cs.MA); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.08283.pdf", "abstract_url": "https://arxiv.org/abs/2508.08283", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了MinionsLLM，一个将大型语言模型（LLMs）与行为树（BTs）和形式文法相结合的新框架，旨在通过自然语言控制多智能体系统。", "motivation": "解决在多智能体系统中通过自然语言实现有效控制和任务适应性的问题。", "method": "结合大型语言模型、行为树和形式文法，引入两种合成数据集生成方法（方法A和方法B）来微调LLMs，以提高语法有效性和语义任务相关性。", "result": "使用方法B时，语法有效性提高到92.6%，任务性能平均比基线提高了33%。较小的模型通过微调获益最多。", "conclusion": "MinionsLLM框架为资源受限的多智能体控制场景提供了有效的解决方案，支持开源以促进可重复性和未来研究。"}}
{"id": "2508.08487", "title": "MAViS: A Multi-Agent Framework for Long-Sequence Video Storytelling", "authors": ["Qian Wang", "Ziqi Huang", "Ruoxi Jia", "Paul Debevec", "Ning Yu"], "abstract": "Despite recent advances, long-sequence video generation frameworks still suffer from significant limitations: poor assistive capability, suboptimal visual quality, and limited expressiveness. To mitigate these limitations, we propose MAViS, an end-to-end multi-agent collaborative framework for long-sequence video storytelling. MAViS orchestrates specialized agents across multiple stages, including script writing, shot designing, character modeling, keyframe generation, video animation, and audio generation. In each stage, agents operate under the 3E Principle -- Explore, Examine, and Enhance -- to ensure the completeness of intermediate outputs. Considering the capability limitations of current generative models, we propose the Script Writing Guidelines to optimize compatibility between scripts and generative tools. Experimental results demonstrate that MAViS achieves state-of-the-art performance in assistive capability, visual quality, and video expressiveness. Its modular framework further enables scalability with diverse generative models and tools. With just a brief user prompt, MAViS is capable of producing high-quality, expressive long-sequence video storytelling, enriching inspirations and creativity for users. To the best of our knowledge, MAViS is the only framework that provides multimodal design output -- videos with narratives and background music.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "Video Generation Agent", "pdf_url": "https://arxiv.org/pdf/2508.08487.pdf", "abstract_url": "https://arxiv.org/abs/2508.08487", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "MAViS是一个多代理协作框架，用于生成长序列视频故事，通过分阶段专业代理协作和3E原则优化，实现了在辅助能力、视觉质量和视频表现力方面的最先进性能。", "motivation": "解决长序列视频生成框架在辅助能力、视觉质量和表现力方面的局限性。", "method": "提出了MAViS，一个端到端的多代理协作框架，包括脚本编写、镜头设计、角色建模、关键帧生成、视频动画和音频生成等阶段，每个阶段代理遵循探索、检查和增强的3E原则。", "result": "实验结果表明，MAViS在辅助能力、视觉质量和视频表现力方面达到了最先进的性能，其模块化框架还支持与多样化的生成模型和工具的扩展性。", "conclusion": "MAViS能够仅凭简短的用户提示，生成高质量、富有表现力的长序列视频故事，丰富了用户的灵感和创造力，是目前唯一提供多模态设计输出的框架。"}}
{"id": "2508.08821", "title": "3DFroMLLM: 3D Prototype Generation only from Pretrained Multimodal LLMs", "authors": ["Noor Ahmed", "Cameron Braunstein", "Steffen Eger", "Eddy Ilg"], "abstract": "Recent Multi-Modal Large Language Models (MLLMs) have demonstrated strong capabilities in learning joint representations from text and images. However, their spatial reasoning remains limited. We introduce 3DFroMLLM, a novel framework that enables the generation of 3D object prototypes directly from MLLMs, including geometry and part labels. Our pipeline is agentic, comprising a designer, coder, and visual inspector operating in a refinement loop. Notably, our approach requires no additional training data or detailed user instructions. Building on prior work in 2D generation, we demonstrate that rendered images produced by our framework can be effectively used for image classification pretraining tasks and outperforms previous methods by 15%. As a compelling real-world use case, we show that the generated prototypes can be leveraged to improve fine-grained vision-language models by using the rendered, part-labeled prototypes to fine-tune CLIP for part segmentation and achieving a 55% accuracy improvement without relying on any additional human-labeled data.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.08821.pdf", "abstract_url": "https://arxiv.org/abs/2508.08821", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "3DFroMLLM是一种新颖的框架，能够直接从多模态大型语言模型（MLLMs）生成3D对象原型，包括几何和部分标签，无需额外训练数据或详细用户指令。", "motivation": "尽管多模态大型语言模型（MLLMs）在文本和图像的联合表示学习方面表现出强大的能力，但其空间推理能力仍然有限。", "method": "采用一个由设计师、编码员和视觉检查员组成的代理流程，在细化循环中操作，直接从MLLMs生成3D对象原型。", "result": "生成的渲染图像可以有效地用于图像分类预训练任务，性能比之前的方法提高了15%。此外，生成的原型可以通过使用渲染的部分标记原型来微调CLIP以进行部分分割，从而在不依赖任何额外人工标记数据的情况下实现55%的准确率提升。", "conclusion": "3DFroMLLM框架不仅展示了从MLLMs直接生成3D原型的可行性，而且还提供了一种改进细粒度视觉语言模型的有效方法，具有重要的实际应用价值。"}}
{"id": "2508.08344", "title": "What Breaks Knowledge Graph based RAG? Empirical Insights into Reasoning under Incomplete Knowledge", "authors": ["Dongzhuoran Zhou", "Yuqicheng Zhu", "Xiaxia Wang", "Hongkuan Zhou", "Yuan He", "Jiaoyan Chen", "Evgeny Kharlamov", "Steffen Staab"], "abstract": "Knowledge Graph-based Retrieval-Augmented Generation (KG-RAG) is an increasingly explored approach for combining the reasoning capabilities of large language models with the structured evidence of knowledge graphs. However, current evaluation practices fall short: existing benchmarks often include questions that can be directly answered using existing triples in KG, making it unclear whether models perform reasoning or simply retrieve answers directly. Moreover, inconsistent evaluation metrics and lenient answer matching criteria further obscure meaningful comparisons. In this work, we introduce a general method for constructing benchmarks, together with an evaluation protocol, to systematically assess KG-RAG methods under knowledge incompleteness. Our empirical results show that current KG-RAG methods have limited reasoning ability under missing knowledge, often rely on internal memorization, and exhibit varying degrees of generalization depending on their design.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.08344.pdf", "abstract_url": "https://arxiv.org/abs/2508.08344", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文探讨了基于知识图谱的检索增强生成（KG-RAG）方法在知识不完整情况下的推理能力，提出了构建基准和评估协议的一般方法，并实证分析了当前KG-RAG方法的局限性。", "motivation": "当前基于知识图谱的检索增强生成（KG-RAG）方法的评估实践存在不足，现有基准往往包含可以直接通过知识图谱中的三元组回答的问题，这使得难以判断模型是否真正进行了推理。此外，不一致的评估标准和宽松的答案匹配标准进一步模糊了有意义的比较。", "method": "本文介绍了一种构建基准的一般方法，以及一个评估协议，用于系统地评估知识不完整情况下的KG-RAG方法。", "result": "实证结果表明，当前的KG-RAG方法在知识缺失情况下的推理能力有限，往往依赖于内部记忆，并且根据其设计表现出不同程度的泛化能力。", "conclusion": "本文的发现强调了需要更严格的评估标准和更先进的KG-RAG方法，以更好地处理知识不完整情况下的推理任务。"}}
{"id": "2508.08501", "title": "GVGAI-LLM: Evaluating Large Language Model Agents with Infinite Games", "authors": ["Yuchen Li", "Cong Lin", "Muhammad Umair Nasir", "Philip Bontrager", "Jialin Liu", "Julian Togelius"], "abstract": "We introduce GVGAI-LLM, a video game benchmark for evaluating the reasoning and problem-solving capabilities of large language models (LLMs). Built on the General Video Game AI framework, it features a diverse collection of arcade-style games designed to test a model's ability to handle tasks that differ from most existing LLM benchmarks. The benchmark leverages a game description language that enables rapid creation of new games and levels, helping to prevent overfitting over time. Each game scene is represented by a compact set of ASCII characters, allowing for efficient processing by language models. GVGAI-LLM defines interpretable metrics, including the meaningful step ratio, step efficiency, and overall score, to assess model behavior. Through zero-shot evaluations across a broad set of games and levels with diverse challenges and skill depth, we reveal persistent limitations of LLMs in spatial reasoning and basic planning. Current models consistently exhibit spatial and logical errors, motivating structured prompting and spatial grounding techniques. While these interventions lead to partial improvements, the benchmark remains very far from solved. GVGAI-LLM provides a reproducible testbed for advancing research on language model capabilities, with a particular emphasis on agentic behavior and contextual reasoning.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.08501.pdf", "abstract_url": "https://arxiv.org/abs/2508.08501", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "GVGAI-LLM是一个基于通用视频游戏AI框架的视频游戏基准，用于评估大型语言模型（LLMs）的推理和问题解决能力。它通过多样化的街机风格游戏测试模型处理与现有基准不同任务的能力，并定义了可解释的指标来评估模型行为。", "motivation": "解决现有大型语言模型在空间推理和基本规划方面的持续限制，提供一个可重复的测试平台以推进语言模型能力的研究。", "method": "利用游戏描述语言快速创建新游戏和关卡，防止过拟合；通过ASCII字符集高效表示游戏场景；定义包括有意义步骤比率、步骤效率和总体分数在内的可解释指标。", "result": "零射击评估揭示了LLMs在空间推理和基本规划方面的持续限制，模型表现出空间和逻辑错误，结构化提示和空间接地技术带来部分改进，但基准远未解决。", "conclusion": "GVGAI-LLM为推进语言模型能力研究提供了可重复的测试平台，特别强调代理行为和上下文推理。"}}
{"id": "2508.09032", "title": "Spatial Traces: Enhancing VLA Models with Spatial-Temporal Understanding", "authors": ["Maxim A. Patratskiy", "Alexey K. Kovalev", "Aleksandr I. Panov"], "abstract": "Vision-Language-Action models have demonstrated remarkable capabilities in predicting agent movements within virtual environments and real-world scenarios based on visual observations and textual instructions. Although recent research has focused on enhancing spatial and temporal understanding independently, this paper presents a novel approach that integrates both aspects through visual prompting. We introduce a method that projects visual traces of key points from observations onto depth maps, enabling models to capture both spatial and temporal information simultaneously. The experiments in SimplerEnv show that the mean number of tasks successfully solved increased for 4% compared to SpatialVLA and 19% compared to TraceVLA. Furthermore, we show that this enhancement can be achieved with minimal training data, making it particularly valuable for real-world applications where data collection is challenging. The project page is available at", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.09032.pdf", "abstract_url": "https://arxiv.org/abs/2508.09032", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种通过视觉提示整合空间和时间理解的新方法，通过在深度图上投影观察到的关键点的视觉痕迹，使模型能够同时捕捉空间和时间信息。在SimplerEnv中的实验表明，与SpatialVLA和TraceVLA相比，成功解决的任务平均数量分别增加了4%和19%。此外，这种方法可以在少量训练数据下实现增强，对于数据收集困难的现实世界应用特别有价值。", "motivation": "尽管最近的研究集中在独立增强空间和时间理解上，但本文旨在通过视觉提示整合这两个方面，以提升Vision-Language-Action模型在虚拟环境和现实场景中预测代理运动的能力。", "method": "本文介绍了一种方法，该方法将观察到的关键点的视觉痕迹投影到深度图上，使模型能够同时捕捉空间和时间信息。", "result": "在SimplerEnv中的实验显示，与SpatialVLA和TraceVLA相比，成功解决的任务平均数量分别增加了4%和19%。", "conclusion": "这种方法不仅提高了模型性能，而且可以在少量训练数据下实现增强，对于数据收集困难的现实世界应用具有重要价值。"}}
{"id": "2508.07292", "title": "EndoAgent: A Memory-Guided Reflective Agent for Intelligent Endoscopic Vision-to-Decision Reasoning", "authors": ["Yi Tang", "Kaini Wang", "Yang Chen", "Guangquan Zhou"], "abstract": "Developing general artificial intelligence (AI) systems to support endoscopic image diagnosis is an emerging research priority. Existing methods based on large-scale pretraining often lack unified coordination across tasks and struggle to handle the multi-step processes required in complex clinical workflows. While AI agents have shown promise in flexible instruction parsing and tool integration across domains, their potential in endoscopy remains underexplored. To address this gap, we propose EndoAgent, the first memory-guided agent for vision-to-decision endoscopic analysis that integrates iterative reasoning with adaptive tool selection and collaboration. Built on a dual-memory design, it enables sophisticated decision-making by ensuring logical coherence through short-term action tracking and progressively enhancing reasoning acuity through long-term experiential learning. To support diverse clinical tasks, EndoAgent integrates a suite of expert-designed tools within a unified reasoning loop. We further introduce EndoAgentBench, a benchmark of 5,709 visual question-answer pairs that assess visual understanding and language generation capabilities in realistic scenarios. Extensive experiments show that EndoAgent consistently outperforms both general and medical multimodal models, exhibiting its strong flexibility and reasoning capabilities.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.07292.pdf", "abstract_url": "https://arxiv.org/abs/2508.07292", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了EndoAgent，一种用于内窥镜视觉到决策推理的记忆引导反射代理，旨在解决现有方法在复杂临床工作流程中多步骤处理能力的不足。", "motivation": "开发支持内窥镜图像诊断的通用人工智能系统是一个新兴的研究重点，现有的大规模预训练方法缺乏跨任务的统一协调，难以处理复杂临床工作流程中的多步骤过程。", "method": "提出了EndoAgent，这是一种基于双记忆设计的代理，通过短期行动跟踪和长期经验学习来增强推理能力，并整合了一套专家设计的工具在一个统一的推理循环中。", "result": "广泛的实验表明，EndoAgent在视觉理解和语言生成能力上 consistently outperforms both general and medical multimodal models，展示了其强大的灵活性和推理能力。", "conclusion": "EndoAgent作为一种记忆引导的代理，通过其双记忆设计和统一的推理循环，为内窥镜视觉到决策的智能分析提供了新的可能性，展示了在复杂临床工作流程中的强大应用潜力。"}}
{"id": "2508.08610", "title": "Optimizing Retrieval-Augmented Generation (RAG) for Colloquial Cantonese: A LoRA-Based Systematic Review", "authors": ["David Santandreu Calonge", "Linda Smail"], "abstract": "This review examines recent advances in Parameter-Efficient Fine-Tuning (PEFT), with a focus on Low-Rank Adaptation (LoRA), to optimize Retrieval-Augmented Generation (RAG) systems like Qwen3, DeepSeek, and Kimi. These systems face challenges in understanding and generating authentic Cantonese colloquial expressions due to limited annotated data and linguistic variability. The review evaluates the integration of LoRA within RAG frameworks, benchmarks PEFT methods for retrieval and generation accuracy, identify domain adaptation strategies under limited data, and compares fine-tuning techniques aimed at improving semantic fidelity under data-scarce conditions. A systematic analysis of recent studies employing diverse LoRA variants, synthetic data generation, user feedback integration, and adaptive parameter allocation was conducted to assess their impact on computational efficiency, retrieval precision, linguistic authenticity, and scalability. Findings reveal that dynamic and ensemble LoRA adaptations significantly reduce trainable parameters without sacrificing retrieval accuracy and generation quality in dialectal contexts. However, limitations remain in fully preserving fine-grained linguistic nuances, especially for low-resource settings like Cantonese. The integration of real-time user feedback and domain-specific data remains underdeveloped, limiting model adaptability and personalization. While selective parameter freezing and nonlinear adaptation methods offer better trade-offs between efficiency and accuracy, their robustness at scale remains an open challenge. This review highlights the promise of PEFT-enhanced RAG systems for domain-specific language tasks and calls for future work targeting dialectal authenticity, dynamic adaptation, and scalable fine-tuning pipelines.", "subjects": "Computation and Language (cs.CL)", "comments": "27 pages, 1 figure, 8 tables", "pdf_url": "https://arxiv.org/pdf/2508.08610.pdf", "abstract_url": "https://arxiv.org/abs/2508.08610", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文回顾了参数高效微调（PEFT）的最新进展，特别是低秩适应（LoRA），以优化检索增强生成（RAG）系统，如Qwen3、DeepSeek和Kimi。这些系统在理解和生成地道的粤语口语表达方面面临挑战。", "motivation": "解决RAG系统在理解和生成地道粤语口语表达方面的挑战，尤其是在标注数据有限和语言变异性大的情况下。", "method": "评估了LoRA在RAG框架中的整合，对PEFT方法在检索和生成准确性上的基准测试，识别了在有限数据下的领域适应策略，并比较了旨在提高数据稀缺条件下语义保真度的微调技术。", "result": "发现动态和集成LoRA适应显著减少了可训练参数，而不牺牲方言上下文中的检索准确性和生成质量。但在完全保留细粒度语言细微差别方面仍有局限，特别是在粤语等低资源设置中。", "conclusion": "本综述强调了PEFT增强的RAG系统在特定领域语言任务中的潜力，并呼吁未来工作针对方言真实性、动态适应和可扩展的微调流程。"}}
{"id": "2508.08636", "title": "InternBootcamp Technical Report: Boosting LLM Reasoning with Verifiable Task Scaling", "authors": ["Peiji Li", "Jiasheng Ye", "Yongkang Chen", "Yichuan Ma", "Zijie Yu", "Kedi Chen", "Ganqu Cui", "Haozhan Li", "Jiacheng Chen", "Chengqi Lyu", "Wenwei Zhang", "Linyang Li", "Qipeng Guo", "Dahua Lin", "Bowen Zhou", "Kai Chen"], "abstract": "Large language models (LLMs) have revolutionized artificial intelligence by enabling complex reasoning capabilities. While recent advancements in reinforcement learning (RL) have primarily focused on domain-specific reasoning tasks (e.g., mathematics or code generation), real-world reasoning scenarios often require models to handle diverse and complex environments that narrow-domain benchmarks cannot fully capture. To address this gap, we present InternBootcamp, an open-source framework comprising 1000+ domain-diverse task environments specifically designed for LLM reasoning research. Our codebase offers two key functionalities: (1) automated generation of unlimited training/testing cases with configurable difficulty levels, and (2) integrated verification modules for objective response evaluation. These features make InternBootcamp fundamental infrastructure for RL-based model optimization, synthetic data generation, and model evaluation. Although manually developing such a framework with enormous task coverage is extremely cumbersome, we accelerate the development procedure through an automated agent workflow supplemented by manual validation protocols, which enables the task scope to expand rapidly. % With these bootcamps, we further establish Bootcamp-EVAL, an automatically generated benchmark for comprehensive performance assessment. Evaluation reveals that frontier models still underperform in many reasoning tasks, while training with InternBootcamp provides an effective way to significantly improve performance, leading to our 32B model that achieves state-of-the-art results on Bootcamp-EVAL and excels on other established benchmarks. In particular, we validate that consistent performance gains come from including more training tasks, namely \\textbf{task scaling}, over two orders of magnitude, offering a promising route towards capable reasoning generalist.", "subjects": "Computation and Language (cs.CL)", "comments": "InternBootcamp Tech Report", "pdf_url": "https://arxiv.org/pdf/2508.08636.pdf", "abstract_url": "https://arxiv.org/abs/2508.08636", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了InternBootcamp，一个开源的、包含1000多个领域多样化任务环境的框架，旨在促进大型语言模型（LLM）的推理研究。通过自动化生成训练/测试案例和集成验证模块，该框架支持基于强化学习的模型优化、合成数据生成和模型评估。评估显示，使用InternBootcamp训练能显著提升模型性能，特别是在任务规模扩大时。", "motivation": "解决现有强化学习（RL）在领域特定推理任务上的局限性，以及缺乏能够全面捕捉现实世界复杂推理场景的多样化任务环境的问题。", "method": "开发了InternBootcamp框架，包括自动化生成无限训练/测试案例和集成验证模块，通过自动化代理工作流程加速开发过程。", "result": "前沿模型在许多推理任务中表现不佳，但使用InternBootcamp训练能显著提升性能，特别是在任务规模扩大时，产生了在Bootcamp-EVAL和其他基准测试中达到最先进结果的32B模型。", "conclusion": "InternBootcamp为LLM推理研究提供了基础架构，任务规模的扩大是提高推理能力的一个有希望的途径。"}}
{"id": "2508.08632", "title": "AgriGPT: a Large Language Model Ecosystem for Agriculture", "authors": ["Bo Yang", "Yu Zhang", "Lanfei Feng", "Yunkui Chen", "Jianyu Zhang", "Xiao Xu", "Nueraili Aierken", "Yurui Li", "Yuxuan Chen", "Guijun Yang", "Yong He", "Runhe Huang", "Shijian Li"], "abstract": "Despite the rapid progress of Large Language Models (LLMs), their application in agriculture remains limited due to the lack of domain-specific models, curated datasets, and robust evaluation frameworks. To address these challenges, we propose AgriGPT, a domain-specialized LLM ecosystem for agricultural usage. At its core, we design a multi-agent scalable data engine that systematically compiles credible data sources into Agri-342K, a high-quality, standardized question-answer (QA) dataset. Trained on this dataset, AgriGPT supports a broad range of agricultural stakeholders, from practitioners to policy-makers. To enhance factual grounding, we employ Tri-RAG, a three-channel Retrieval-Augmented Generation framework combining dense retrieval, sparse retrieval, and multi-hop knowledge graph reasoning, thereby improving the LLM's reasoning reliability. For comprehensive evaluation, we introduce AgriBench-13K, a benchmark suite comprising 13 tasks with varying types and complexities. Experiments demonstrate that AgriGPT significantly outperforms general-purpose LLMs on both domain adaptation and reasoning. Beyond the model itself, AgriGPT represents a modular and extensible LLM ecosystem for agriculture, comprising structured data construction, retrieval-enhanced generation, and domain-specific evaluation. This work provides a generalizable framework for developing scientific and industry-specialized LLMs. All models, datasets, and code will be released to empower agricultural communities, especially in underserved regions, and to promote open, impactful research.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.08632.pdf", "abstract_url": "https://arxiv.org/abs/2508.08632", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文提出了AgriGPT，一个专为农业领域设计的大型语言模型生态系统，旨在解决农业领域缺乏专业模型、精选数据集和强大评估框架的问题。", "motivation": "尽管大型语言模型（LLMs）发展迅速，但由于缺乏领域特定模型、精选数据集和强大的评估框架，其在农业领域的应用仍然有限。", "method": "AgriGPT采用了一个多代理可扩展的数据引擎，系统地编译可信数据源为Agri-342K，一个高质量、标准化的问答数据集。为了提高事实基础，采用了Tri-RAG，一个结合密集检索、稀疏检索和多跳知识图谱推理的三通道检索增强生成框架。", "result": "实验表明，AgriGPT在领域适应性和推理能力上显著优于通用大型语言模型。", "conclusion": "AgriGPT不仅是一个模型，更是一个模块化和可扩展的农业大型语言模型生态系统，包括结构化数据构建、检索增强生成和领域特定评估。这项工作为开发科学和行业专业化的大型语言模型提供了一个可推广的框架。"}}
{"id": "2508.08645", "title": "Quick on the Uptake: Eliciting Implicit Intents from Human Demonstrations for Personalized Mobile-Use Agents", "authors": ["Zheng Wu", "Heyuan Huang", "Yanjia Yang", "Yuanyi Song", "Xingyu Lou", "Weiwen Liu", "Weinan Zhang", "Jun Wang", "Zhuosheng Zhang"], "abstract": "As multimodal large language models advance rapidly, the automation of mobile tasks has become increasingly feasible through the use of mobile-use agents that mimic human interactions from graphical user interface. To further enhance mobile-use agents, previous studies employ demonstration learning to improve mobile-use agents from human demonstrations. However, these methods focus solely on the explicit intention flows of humans (e.g., step sequences) while neglecting implicit intention flows (e.g., personal preferences), which makes it difficult to construct personalized mobile-use agents. In this work, to evaluate the \\textbf{I}ntention \\textbf{A}lignment \\textbf{R}ate between mobile-use agents and humans, we first collect \\textbf{MobileIAR}, a dataset containing human-intent-aligned actions and ground-truth actions. This enables a comprehensive assessment of the agents' understanding of human intent. Then we propose \\textbf{IFRAgent}, a framework built upon \\textbf{I}ntention \\textbf{F}low \\textbf{R}ecognition from human demonstrations. IFRAgent analyzes explicit intention flows from human demonstrations to construct a query-level vector library of standard operating procedures (SOP), and analyzes implicit intention flows to build a user-level habit repository. IFRAgent then leverages a SOP extractor combined with retrieval-augmented generation and a query rewriter to generate personalized query and SOP from a raw ambiguous query, enhancing the alignment between mobile-use agents and human intent. Experimental results demonstrate that IFRAgent outperforms baselines by an average of 6.79\\% (32.06\\% relative improvement) in human intention alignment rate and improves step completion rates by an average of 5.30\\% (26.34\\% relative improvement). The codes are available at", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.08645.pdf", "abstract_url": "https://arxiv.org/abs/2508.08645", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为IFRAgent的框架，旨在通过分析人类演示中的显性和隐性意图流，构建个性化的移动使用代理，以提高与人类意图的对齐率。", "motivation": "随着多模态大型语言模型的快速发展，通过模仿图形用户界面的人类交互来自动化移动任务变得越来越可行。然而，现有方法仅关注人类的显性意图流（如步骤序列），而忽略了隐性意图流（如个人偏好），这使得构建个性化的移动使用代理变得困难。", "method": "本文首先收集了一个名为MobileIAR的数据集，包含与人类意图对齐的动作和真实动作，以全面评估代理对人类意图的理解。然后提出了IFRAgent框架，该框架通过分析人类演示中的显性意图流构建标准操作程序（SOP）的查询级向量库，并通过分析隐性意图流构建用户级习惯库。IFRAgent利用SOP提取器结合检索增强生成和查询重写器，从原始模糊查询生成个性化查询和SOP，从而增强移动使用代理与人类意图的对齐。", "result": "实验结果表明，IFRAgent在人类意图对齐率上平均优于基线6.79%（相对改进32.06%），并在步骤完成率上平均提高了5.30%（相对改进26.34%）。", "conclusion": "IFRAgent框架通过综合考虑显性和隐性意图流，显著提高了移动使用代理与人类意图的对齐率和任务完成率，为构建个性化的移动使用代理提供了有效的方法。"}}
{"id": "2508.08726", "title": "Simulating Generative Social Agents via Theory-Informed Workflow Design", "authors": ["Yuwei Yan", "Jinghua Piao", "Xiaochong Lan", "Chenyang Shao", "Pan Hui", "Yong Li"], "abstract": "Recent advances in large language models have demonstrated strong reasoning and role-playing capabilities, opening new opportunities for agent-based social simulations. However, most existing agents' implementations are scenario-tailored, without a unified framework to guide the design. This lack of a general social agent limits their ability to generalize across different social contexts and to produce consistent, realistic behaviors. To address this challenge, we propose a theory-informed framework that provides a systematic design process for LLM-based social agents. Our framework is grounded in principles from Social Cognition Theory and introduces three key modules: motivation, action planning, and learning. These modules jointly enable agents to reason about their goals, plan coherent actions, and adapt their behavior over time, leading to more flexible and contextually appropriate responses. Comprehensive experiments demonstrate that our theory-driven agents reproduce realistic human behavior patterns under complex conditions, achieving up to 75% lower deviation from real-world behavioral data across multiple fidelity metrics compared to classical generative baselines. Ablation studies further show that removing motivation, planning, or learning modules increases errors by 1.5 to 3.2 times, confirming their distinct and essential contributions to generating realistic and coherent social behaviors.", "subjects": "Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.08726.pdf", "abstract_url": "https://arxiv.org/abs/2508.08726", "categories": ["Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于理论的工作流设计框架，用于模拟生成性社会代理，通过整合动机、行动规划和学习三个关键模块，使基于大型语言模型的代理能够在不同社会情境下产生一致且现实的行为。", "motivation": "解决现有代理实现多为场景定制，缺乏统一框架指导设计，限制其在不同社会情境下的泛化能力和产生一致、现实行为的问题。", "method": "提出一个基于社会认知理论的理论知情框架，包含动机、行动规划和学习三个关键模块，系统地指导基于大型语言模型的社会代理设计。", "result": "综合实验表明，理论驱动的代理在复杂条件下再现了现实人类行为模式，与经典生成基线相比，在多个保真度指标上偏离真实世界行为数据的程度降低了75%。消融研究进一步证实，移除动机、规划或学习模块会使错误增加1.5至3.2倍。", "conclusion": "理论知情框架通过动机、行动规划和学习模块的联合作用，使代理能够推理目标、规划连贯行动并随时间适应行为，从而产生更灵活和情境适当的响应，为生成现实和连贯的社会行为提供了重要贡献。"}}
{"id": "2508.08774", "title": "Designing Memory-Augmented AR Agents for Spatiotemporal Reasoning in Personalized Task Assistance", "authors": ["Dongwook Choi", "Taeyoon Kwon", "Dongil Yang", "Hyojun Kim", "Jinyoung Yeo"], "abstract": "Augmented Reality (AR) systems are increasingly integrating foundation models, such as Multimodal Large Language Models (MLLMs), to provide more context-aware and adaptive user experiences. This integration has led to the development of AR agents to support intelligent, goal-directed interactions in real-world environments. While current AR agents effectively support immediate tasks, they struggle with complex multi-step scenarios that require understanding and leveraging user's long-term experiences and preferences. This limitation stems from their inability to capture, retain, and reason over historical user interactions in spatiotemporal contexts. To address these challenges, we propose a conceptual framework for memory-augmented AR agents that can provide personalized task assistance by learning from and adapting to user-specific experiences over time. Our framework consists of four interconnected modules: (1) Perception Module for multimodal sensor processing, (2) Memory Module for persistent spatiotemporal experience storage, (3) Spatiotemporal Reasoning Module for synthesizing past and present contexts, and (4) Actuator Module for effective AR communication. We further present an implementation roadmap, a future evaluation strategy, a potential target application and use cases to demonstrate the practical applicability of our framework across diverse domains. We aim for this work to motivate future research toward developing more intelligent AR systems that can effectively bridge user's interaction history with adaptive, context-aware task assistance.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "7 pages, 2 figures", "pdf_url": "https://arxiv.org/pdf/2508.08774.pdf", "abstract_url": "https://arxiv.org/abs/2508.08774", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一个记忆增强的AR代理概念框架，旨在通过学习和适应用户的长期经验和偏好，提供个性化的任务辅助，解决现有AR代理在复杂多步骤场景中的局限性。", "motivation": "当前AR代理在支持即时任务方面表现良好，但在需要理解和利用用户长期经验和偏好的复杂多步骤场景中表现不佳，这主要是因为它们无法在时空上下文中捕获、保留和推理历史用户交互。", "method": "提出了一个由四个相互连接的模块组成的框架：感知模块（用于多模态传感器处理）、记忆模块（用于持久的时空经验存储）、时空推理模块（用于综合过去和现在的上下文）和执行器模块（用于有效的AR通信）。", "result": "提出了一个实现路线图、未来评估策略、潜在目标应用和用例，以展示该框架在不同领域的实际适用性。", "conclusion": "这项工作旨在激励未来研究开发更智能的AR系统，有效地将用户的交互历史与自适应的、上下文感知的任务辅助结合起来。"}}
{"id": "2508.08816", "title": "Efficient Agent: Optimizing Planning Capability for Multimodal Retrieval Augmented Generation", "authors": ["Yuechen Wang", "Yuming Qiao", "Dan Meng", "Jun Yang", "Haonan Lu", "Zhenyu Yang", "Xudong Zhang"], "abstract": "Multimodal Retrieval-Augmented Generation (mRAG) has emerged as a promising solution to address the temporal limitations of Multimodal Large Language Models (MLLMs) in real-world scenarios like news analysis and trending topics. However, existing approaches often suffer from rigid retrieval strategies and under-utilization of visual information. To bridge this gap, we propose E-Agent, an agent framework featuring two key innovations: a mRAG planner trained to dynamically orchestrate multimodal tools based on contextual reasoning, and a task executor employing tool-aware execution sequencing to implement optimized mRAG workflows. E-Agent adopts a one-time mRAG planning strategy that enables efficient information retrieval while minimizing redundant tool invocations. To rigorously assess the planning capabilities of mRAG systems, we introduce the Real-World mRAG Planning (RemPlan) benchmark. This novel benchmark contains both retrieval-dependent and retrieval-independent question types, systematically annotated with essential retrieval tools required for each instance. The benchmark's explicit mRAG planning annotations and diverse question design enhance its practical relevance by simulating real-world scenarios requiring dynamic mRAG decisions. Experiments across RemPlan and three established benchmarks demonstrate E-Agent's superiority: 13% accuracy gain over state-of-the-art mRAG methods while reducing redundant searches by 37%.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.08816.pdf", "abstract_url": "https://arxiv.org/abs/2508.08816", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文提出了E-Agent，一个通过动态编排多模态工具和优化工作流来提升多模态检索增强生成（mRAG）效率的代理框架，并在新基准RemPlan上验证了其优越性。", "motivation": "解决多模态大型语言模型（MLLMs）在实时场景（如新闻分析和趋势话题）中的时间限制问题，以及现有方法在检索策略和视觉信息利用上的不足。", "method": "提出了E-Agent框架，包括一个基于上下文推理动态编排多模态工具的mRAG规划器和一个采用工具感知执行序列化实现优化mRAG工作流的任务执行器。", "result": "E-Agent在RemPlan和三个现有基准上的实验显示，其准确率比最先进的mRAG方法提高了13%，同时减少了37%的冗余搜索。", "conclusion": "E-Agent通过其创新的规划策略和执行机制，显著提升了mRAG系统的效率和效果，为实时多模态信息处理提供了有力工具。"}}
{"id": "2508.08882", "title": "Reducing Cognitive Load in Multi-Agent Reinforcement Learning for Mathematical Problem Solving: Decoupling Reasoning and Code Generation", "authors": ["Dayu Wang", "Jiaye Yang", "Weikang Li", "Jiahui Liang", "Yang Li"], "abstract": "Current tool-integrated mathematical reasoning systems often adopt a single-agent paradigm, where one large language model handles problem reasoning, code generation, and code execution in an integrated workflow. While this design eases coordination, we hypothesize that it imposes cognitive load interference, as the agent must interleave long-horizon reasoning with precise program synthesis. We validate this hypothesis through a controlled comparison between a reasoning-only agent and a reasoning-plus-code agent, finding that the latter produces significantly fewer correct reasoning paths despite having tool-calling capabilities. To address this, we propose a dual-agent hybrid framework: a Reasoning Agent performs stepwise problem decomposition, and a Code Agent handles code generation and execution. Training combines imitation learning and reinforcement learning: the Code Agent receives strong rewards for matching intermediate ground-truth programs and weaker rewards for valid execution, while the Reasoning Agent is optimized chiefly via final-answer accuracy using advantage estimation to credit intermediate steps. This decoupled role design reduces cognitive interference and promotes stable reasoning-coding coordination.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.08882.pdf", "abstract_url": "https://arxiv.org/abs/2508.08882", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种双代理混合框架，以减少多智能体强化学习在数学问题解决中的认知负荷，通过解耦推理和代码生成来提高效率。", "motivation": "当前工具集成的数学推理系统通常采用单代理范式，其中一个大型语言模型处理问题推理、代码生成和代码执行。这种设计虽然便于协调，但假设它会导致认知负荷干扰，因为代理必须在长时程推理和精确程序合成之间交替。", "method": "提出了一个双代理混合框架：推理代理负责逐步问题分解，代码代理负责代码生成和执行。训练结合了模仿学习和强化学习：代码代理通过匹配中间真实程序获得强奖励，通过有效执行获得弱奖励；推理代理主要通过最终答案准确性进行优化，使用优势估计来归功于中间步骤。", "result": "发现解耦的角色设计减少了认知干扰，促进了稳定的推理-编码协调。", "conclusion": "通过解耦推理和代码生成，双代理框架有效减少了认知负荷干扰，提高了数学问题解决的效率和准确性。"}}
{"id": "2508.08742", "title": "SciRerankBench: Benchmarking Rerankers Towards Scientific Retrieval-Augmented Generated LLMs", "authors": ["Haotian Chen", "Qingqing Long", "Meng Xiao", "Xiao Luo", "Wei Ju", "Chengrui Wang", "Xuezhi Wang", "Yuanchun Zhou", "Hengshu Zhu"], "abstract": "Scientific literature question answering is a pivotal step towards new scientific discoveries. Recently, \\textit{two-stage} retrieval-augmented generated large language models (RAG-LLMs) have shown impressive advancements in this domain. Such a two-stage framework, especially the second stage (reranker), is particularly essential in the scientific domain, where subtle differences in terminology may have a greatly negative impact on the final factual-oriented or knowledge-intensive answers. Despite this significant progress, the potential and limitations of these works remain unexplored. In this work, we present a Scientific Rerank-oriented RAG Benchmark (SciRerankBench), for evaluating rerankers within RAG-LLMs systems, spanning five scientific subjects. To rigorously assess the reranker performance in terms of noise resilience, relevance disambiguation, and factual consistency, we develop three types of question-context-answer (Q-C-A) pairs, i.e., Noisy Contexts (NC), Semantically Similar but Logically Irrelevant Contexts (SSLI), and Counterfactual Contexts (CC). Through systematic evaluation of 13 widely used rerankers on five families of LLMs, we provide detailed insights into their relative strengths and limitations. To the best of our knowledge, SciRerankBench is the first benchmark specifically developed to evaluate rerankers within RAG-LLMs, which provides valuable observations and guidance for their future development.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.08742.pdf", "abstract_url": "https://arxiv.org/abs/2508.08742", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "SciRerankBench是一个专门为评估RAG-LLMs系统中的重排序器而设计的基准测试，涵盖五个科学学科，旨在通过系统评估13种广泛使用的重排序器在五种LLM家族上的表现，提供对其相对优势和局限性的详细见解。", "motivation": "科学文献问答是迈向新科学发现的关键步骤。尽管两阶段检索增强生成大型语言模型（RAG-LLMs）在这一领域显示出令人印象深刻的进展，但这些工作的潜力和局限性仍未得到充分探索。", "method": "开发了一个科学重排序导向的RAG基准（SciRerankBench），包括三种类型的问题-上下文-答案（Q-C-A）对，即噪声上下文（NC）、语义相似但逻辑无关的上下文（SSLI）和反事实上下文（CC），以严格评估重排序器在噪声弹性、相关性消歧和事实一致性方面的性能。", "result": "通过对五种LLM家族上的13种广泛使用的重排序器进行系统评估，提供了关于它们相对优势和局限性的详细见解。", "conclusion": "SciRerankBench是第一个专门为评估RAG-LLMs中的重排序器而开发的基准测试，为它们的未来发展提供了宝贵的观察和指导。"}}
{"id": "2508.08785", "title": "Privacy-protected Retrieval-Augmented Generation for Knowledge Graph Question Answering", "authors": ["Yunfeng Ning", "Mayi Xu", "Jintao Wen", "Qiankun Pi", "Yuanyuan Zhu", "Ming Zhong", "Jiawei Jiang", "Tieyun Qian"], "abstract": "LLMs often suffer from hallucinations and outdated or incomplete knowledge. RAG is proposed to address these issues by integrating external knowledge like that in KGs into LLMs. However, leveraging private KGs in RAG systems poses significant privacy risks due to the black-box nature of LLMs and potential insecure data transmission, especially when using third-party LLM APIs lacking transparency and control. In this paper, we investigate the privacy-protected RAG scenario for the first time, where entities in KGs are anonymous for LLMs, thus preventing them from accessing entity semantics. Due to the loss of semantics of entities, previous RAG systems cannot retrieve question-relevant knowledge from KGs by matching questions with the meaningless identifiers of anonymous entities. To realize an effective RAG system in this scenario, two key challenges must be addressed: (1) How can anonymous entities be converted into retrievable information. (2) How to retrieve question-relevant anonymous entities. Hence, we propose a novel ARoG framework including relation-centric abstraction and structure-oriented abstraction strategies. For challenge (1), the first strategy abstracts entities into high-level concepts by dynamically capturing the semantics of their adjacent relations. It supplements meaningful semantics which can further support the retrieval process. For challenge (2), the second strategy transforms unstructured natural language questions into structured abstract concept paths. These paths can be more effectively aligned with the abstracted concepts in KGs, thereby improving retrieval performance. To guide LLMs to effectively retrieve knowledge from KGs, the two strategies strictly protect privacy from being exposed to LLMs. Experiments on three datasets demonstrate that ARoG achieves strong performance and privacy-robustness.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.08785.pdf", "abstract_url": "https://arxiv.org/abs/2508.08785", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种名为ARoG的新框架，旨在解决在知识图谱问答中使用隐私保护的检索增强生成（RAG）时遇到的挑战，特别是在处理匿名实体时的语义丢失问题。通过关系中心抽象和结构导向抽象策略，ARoG有效地将匿名实体转换为可检索信息，并提高了检索性能，同时严格保护了隐私。", "motivation": "大型语言模型（LLMs）在处理知识图谱（KGs）时存在幻觉、知识过时或不完整的问题。虽然检索增强生成（RAG）通过整合外部知识来缓解这些问题，但在使用私有KGs时，由于LLMs的黑盒性质和潜在的不安全数据传输，存在显著的隐私风险。本文首次研究了隐私保护的RAG场景，其中KGs中的实体对LLMs是匿名的，以防止它们访问实体语义。", "method": "提出了ARoG框架，包括两种策略：关系中心抽象和结构导向抽象。关系中心抽象通过动态捕获相邻关系的语义将匿名实体抽象为高级概念，补充有意义的语义以支持检索过程。结构导向抽象将非结构化的自然语言问题转换为结构化的抽象概念路径，这些路径能更有效地与KGs中的抽象概念对齐，从而提高检索性能。", "result": "在三个数据集上的实验表明，ARoG在保持强大性能的同时，也展现了隐私鲁棒性。", "conclusion": "ARoG框架有效地解决了在隐私保护前提下使用RAG进行知识图谱问答的两个关键挑战，不仅提高了检索性能，还严格保护了隐私不被LLMs暴露。这一研究为隐私保护的RAG系统提供了新的解决方案。"}}
{"id": "2508.08761", "title": "DevNous: An LLM-Based Multi-Agent System for Grounding IT Project Management in Unstructured Conversation", "authors": ["Stavros Doropoulos", "Stavros Vologiannidis", "Ioannis Magnisalis"], "abstract": "The manual translation of unstructured team dialogue into the structured artifacts required for Information Technology (IT) project governance is a critical bottleneck in modern information systems management. We introduce DevNous, a Large Language Model-based (LLM) multi-agent expert system, to automate this unstructured-to-structured translation process. DevNous integrates directly into team chat environments, identifying actionable intents from informal dialogue and managing stateful, multi-turn workflows for core administrative tasks like automated task formalization and progress summary synthesis. To quantitatively evaluate the system, we introduce a new benchmark of 160 realistic, interactive conversational turns. The dataset was manually annotated with a multi-label ground truth and is publicly available. On this benchmark, DevNous achieves an exact match turn accuracy of 81.3\\% and a multiset F1-Score of 0.845, providing strong evidence for its viability. The primary contributions of this work are twofold: (1) a validated architectural pattern for developing ambient administrative agents, and (2) the introduction of the first robust empirical baseline and public benchmark dataset for this challenging problem domain.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.08761.pdf", "abstract_url": "https://arxiv.org/abs/2508.08761", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "DevNous是一个基于大型语言模型的多专家系统，旨在自动化将非结构化团队对话转化为IT项目管理所需的结构化产物。该系统在团队聊天环境中直接集成，能够从非正式对话中识别可操作的意图，并管理核心管理任务的状态化、多轮工作流程。通过一个新基准的定量评估，DevNous展示了其可行性。", "motivation": "解决现代信息系统管理中，将非结构化团队对话手动转化为结构化产物这一关键瓶颈问题。", "method": "引入DevNous，一个基于大型语言模型的多专家系统，自动化非结构化到结构化的翻译过程，并在团队聊天环境中直接集成。", "result": "在新引入的160个现实交互对话轮次的基准上，DevNous实现了81.3%的精确匹配轮次准确率和0.845的多集F1分数，证明了其可行性。", "conclusion": "本工作的主要贡献包括：(1)为开发环境管理代理提供了一个经过验证的架构模式，(2)引入了针对这一挑战性问题领域的第一个稳健的经验基线和公共基准数据集。"}}
{"id": "2508.08942", "title": "Jointly Generating and Attributing Answers using Logits of Document-Identifier Tokens", "authors": ["Lucas Albarede", "Jose Moreno", "Lynda Tamine", "Luce Lefeuvre"], "abstract": "Despite their impressive performances, Large Language Models (LLMs) remain prone to hallucination, which critically undermines their trustworthiness. While most of the previous work focused on tackling answer and attribution correctness, a recent line of work investigated faithfulness, with a focus on leveraging internal model signals to reflect a model's actual decision-making process while generating the answer. Nevertheless, these methods induce additional latency and have shown limitations in directly aligning token generation with attribution generation. In this paper, we introduce LoDIT, a method that jointly generates and faithfully attributes answers in RAG by leveraging specific token logits during generation. It consists of two steps: (1) marking the documents with specific token identifiers and then leveraging the logits of these tokens to estimate the contribution of each document to the answer during generation, and (2) aggregating these contributions into document attributions. Experiments on a trustworthiness-focused attributed text-generation benchmark, Trust-Align, show that LoDIT significantly outperforms state-of-the-art models on several metrics. Finally, an in-depth analysis of LoDIT shows both its efficiency in terms of latency and its robustness in different settings.", "subjects": "Computation and Language (cs.CL); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.08942.pdf", "abstract_url": "https://arxiv.org/abs/2508.08942", "categories": ["Computation and Language (cs.CL)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了LoDIT方法，通过利用生成过程中的特定令牌logits，在RAG中联合生成并忠实归因答案，显著提高了模型的可信度和效率。", "motivation": "大型语言模型（LLMs）虽然性能优异，但仍容易产生幻觉，严重影响其可信度。现有方法在答案和归因正确性方面有所进展，但在忠实性方面仍有不足，且存在额外延迟和令牌生成与归因生成直接对齐的限制。", "method": "LoDIT方法包括两个步骤：(1) 用特定令牌标识符标记文档，并利用这些令牌的logits估计每个文档在生成答案时的贡献；(2) 将这些贡献聚合为文档归因。", "result": "在专注于可信度的归因文本生成基准Trust-Align上的实验表明，LoDIT在多个指标上显著优于最先进的模型。深入分析显示，LoDIT在延迟效率和不同设置下的鲁棒性方面表现出色。", "conclusion": "LoDIT通过联合生成和忠实归因答案，不仅提高了模型的可信度，还保持了高效率和高鲁棒性，为LLMs的可信度问题提供了有效的解决方案。"}}
{"id": "2508.08997", "title": "Intrinsic Memory Agents: Heterogeneous Multi-Agent LLM Systems through Structured Contextual Memory", "authors": ["Sizhe Yuen", "Francisco Gomez Medina", "Ting Su", "Yali Du", "Adam J. Sobey"], "abstract": "Multi-agent systems built on Large Language Models (LLMs) show exceptional promise for complex collaborative problem-solving, yet they face fundamental challenges stemming from context window limitations that impair memory consistency, role adherence, and procedural integrity. This paper introduces Intrinsic Memory Agents, a novel framework that addresses these limitations through structured agent-specific memories that evolve intrinsically with agent outputs. Specifically, our method maintains role-aligned memory templates that preserve specialized perspectives while focusing on task-relevant information. We benchmark our approach on the PDDL dataset, comparing its performance to existing state-of-the-art multi-agentic memory approaches and showing an improvement of 38.6\\% with the highest token efficiency. An additional evaluation is performed on a complex data pipeline design task, we demonstrate that our approach produces higher quality designs when comparing 5 metrics: scalability, reliability, usability, cost-effectiveness and documentation with additional qualitative evidence of the improvements. Our findings suggest that addressing memory limitations through structured, intrinsic approaches can improve the capabilities of multi-agent LLM systems on structured planning tasks.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.08997.pdf", "abstract_url": "https://arxiv.org/abs/2508.08997", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了Intrinsic Memory Agents，一种通过结构化特定代理记忆来解决多代理LLM系统中记忆一致性、角色遵守和程序完整性挑战的新框架。", "motivation": "解决基于大型语言模型（LLMs）的多代理系统在复杂协作问题解决中面临的上下文窗口限制，这些限制影响了记忆一致性、角色遵守和程序完整性。", "method": "提出了一种通过结构化代理特定记忆来内在演化代理输出的方法，保持角色对齐的记忆模板，专注于任务相关信息。", "result": "在PDDL数据集上的基准测试显示，与现有最先进的多代理记忆方法相比，性能提高了38.6%，并具有最高的令牌效率。在复杂数据管道设计任务上的额外评估显示，在可扩展性、可靠性、可用性、成本效益和文档化五个指标上产生了更高质量的设计。", "conclusion": "通过结构化的内在方法解决记忆限制，可以提高多代理LLM系统在结构化规划任务上的能力。"}}
{"id": "2508.09105", "title": "SMA: Who Said That? Auditing Membership Leakage in Semi-Black-box RAG Controlling", "authors": ["Shixuan Sun", "Siyuan Liang", "Ruoyu Chen", "Jianjie Huang", "Jingzhi Li", "Xiaochun Cao"], "abstract": "Retrieval-Augmented Generation (RAG) and its Multimodal Retrieval-Augmented Generation (MRAG) significantly improve the knowledge coverage and contextual understanding of Large Language Models (LLMs) by introducing external knowledge sources. However, retrieval and multimodal fusion obscure content provenance, rendering existing membership inference methods unable to reliably attribute generated outputs to pre-training, external retrieval, or user input, thus undermining privacy leakage accountability", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.09105.pdf", "abstract_url": "https://arxiv.org/abs/2508.09105", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文探讨了在Semi-Black-box RAG控制中，如何审计成员信息泄漏的问题，特别是在检索增强生成（RAG）和多模态检索增强生成（MRAG）系统中，由于检索和多模态融合导致的内容来源不明确，使得现有的成员推理方法无法可靠地将生成输出归因于预训练、外部检索或用户输入，从而削弱了隐私泄漏的责任归属。", "motivation": "解决在RAG和MRAG系统中，由于内容来源不明确导致的隐私泄漏责任归属问题。", "method": "审计成员信息泄漏的方法，特别是在Semi-Black-box RAG控制中的应用。", "result": "现有的成员推理方法在RAG和MRAG系统中无法可靠地追踪生成输出的来源，影响了隐私泄漏的问责。", "conclusion": "需要开发新的方法来明确RAG和MRAG系统中生成输出的来源，以加强隐私泄漏的问责机制。"}}
{"id": "2508.09123", "title": "OpenCUA: Open Foundations for Computer-Use Agents", "authors": ["Xinyuan Wang", "Bowen Wang", "Dunjie Lu", "Junlin Yang", "Tianbao Xie", "Junli Wang", "Jiaqi Deng", "Xiaole Guo", "Yiheng Xu", "Chen Henry Wu", "Zhennan Shen", "Zhuokai Li", "Ryan Li", "Xiaochuan Li", "Junda Chen", "Boyuan Zheng", "Peihang Li", "Fangyu Lei", "Ruisheng Cao", "Yeqiao Fu", "Dongchan Shin", "Martin Shin", "Jiarui Hu", "Yuyan Wang", "Jixuan Chen", "Yuxiao Ye", "Danyang Zhang", "Dikang Du", "Hao Hu", "Huarong Chen", "Zaida Zhou", "Yipu Wang", "Heng Wang", "Diyi Yang", "Victor Zhong", "Flood Sung", "Y.Charles", "Zhilin Yang", "Tao Yu"], "abstract": "Vision-language models have demonstrated impressive capabilities as computer-use agents (CUAs) capable of automating diverse computer tasks. As their commercial potential grows, critical details of the most capable CUA systems remain closed. As these agents will increasingly mediate digital interactions and execute consequential decisions on our behalf, the research community needs access to open CUA frameworks to study their capabilities, limitations, and risks. To bridge this gap, we propose OpenCUA, a comprehensive open-source framework for scaling CUA data and foundation models. Our framework consists of: (1) an annotation infrastructure that seamlessly captures human computer-use demonstrations; (2) AgentNet, the first large-scale computer-use task dataset spanning 3 operating systems and 200+ applications and websites; (3) a scalable pipeline that transforms demonstrations into state-action pairs with reflective long Chain-of-Thought reasoning that sustain robust performance gains as data scales. Our end-to-end agent models demonstrate strong performance across CUA benchmarks. In particular, OpenCUA-32B achieves an average success rate of 34.8% on OSWorld-Verified, establishing a new state-of-the-art (SOTA) among open-source models and surpassing OpenAI CUA (GPT-4o). Further analysis confirms that our approach generalizes well across domains and benefits significantly from increased test-time computation. We release our annotation tool, datasets, code, and models to build open foundations for further CUA research.", "subjects": "Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.09123.pdf", "abstract_url": "https://arxiv.org/abs/2508.09123", "categories": ["Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "OpenCUA是一个开源的计算机使用代理（CUA）框架，旨在通过提供数据收集、大规模任务数据集和可扩展的模型训练管道，支持对CUA能力、限制和风险的研究。", "motivation": "随着视觉语言模型作为计算机使用代理（CUAs）的商业潜力增长，最强大的CUA系统的关键细节仍然封闭。为了研究其能力、限制和风险，研究社区需要开放的CUA框架。", "method": "OpenCUA框架包括：(1) 一个无缝捕捉人类计算机使用示范的注释基础设施；(2) AgentNet，第一个大规模计算机使用任务数据集，涵盖3个操作系统和200多个应用程序和网站；(3) 一个可扩展的管道，将示范转化为状态-动作对，并通过反思性长链思维推理维持稳健的性能提升。", "result": "OpenCUA-32B在OSWorld-Verified上的平均成功率达到34.8%，在开源模型中建立了新的最先进（SOTA）水平，超过了OpenAI CUA（GPT-4o）。", "conclusion": "OpenCUA为CUA研究提供了开放的基础，包括注释工具、数据集、代码和模型，支持进一步的研究和开发。"}}
{"id": "2508.09129", "title": "BrowseMaster: Towards Scalable Web Browsing via Tool-Augmented Programmatic Agent Pair", "authors": ["Xianghe Pang", "Shuo Tang", "Rui Ye", "Yuwen Du", "Yaxin Du", "Siheng Chen"], "abstract": "Effective information seeking in the vast and ever-growing digital landscape requires balancing expansive search with strategic reasoning. Current large language model (LLM)-based agents struggle to achieve this balance due to limitations in search breadth and reasoning depth, where slow, serial querying restricts coverage of relevant sources and noisy raw inputs disrupt the continuity of multi-step reasoning. To address these challenges, we propose BrowseMaster, a scalable framework built around a programmatically augmented planner-executor agent pair. The planner formulates and adapts search strategies based on task constraints, while the executor conducts efficient, targeted retrieval to supply the planner with concise, relevant evidence. This division of labor preserves coherent, long-horizon reasoning while sustaining broad and systematic exploration, overcoming the trade-off that limits existing agents. Extensive experiments on challenging English and Chinese benchmarks show that BrowseMaster consistently outperforms open-source and proprietary baselines, achieving scores of 30.0 on BrowseComp-en and 46.5 on BrowseComp-zh, which demonstrates its strong capability in complex, reasoning-heavy information-seeking tasks at scale.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.09129.pdf", "abstract_url": "https://arxiv.org/abs/2508.09129", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "BrowseMaster是一个通过工具增强的程序化代理对实现可扩展网络浏览的框架，旨在解决大型语言模型代理在搜索广度和推理深度上的限制。", "motivation": "当前基于大型语言模型（LLM）的代理在数字信息搜索中难以平衡广泛的搜索和战略性的推理，主要因为缓慢的串行查询限制了相关来源的覆盖范围，而嘈杂的原始输入破坏了多步推理的连续性。", "method": "BrowseMaster框架围绕一个程序化增强的规划者-执行者代理对构建，规划者根据任务约束制定和调整搜索策略，执行者进行高效、有针对性的检索，为规划者提供简洁、相关的证据。", "result": "在具有挑战性的英语和中文基准测试中，BrowseMaster consistently outperforms open-source and proprietary baselines, achieving scores of 30.0 on BrowseComp-en and 46.5 on BrowseComp-zh。", "conclusion": "BrowseMaster通过分工合作保持了连贯、长期的推理能力，同时支持广泛和系统的探索，克服了现有代理的限制，展示了在复杂、需要大量推理的信息搜索任务中的强大能力。"}}
{"id": "2508.09042", "title": "LLM-as-a-Supervisor: Mistaken Therapeutic Behaviors Trigger Targeted Supervisory Feedback", "authors": ["Chen Xu", "Zhenyu Lv", "Tian Lan", "Xianyang Wang", "Luyao Ji", "Leyang Cui", "Minqiang Yang", "Jian Shen", "Qunxi Dong", "Xiuling Liu", "Juan Wang", "Bin Hu"], "abstract": "Although large language models (LLMs) hold significant promise in psychotherapy, their direct application in patient-facing scenarios raises ethical and safety concerns. Therefore, this work shifts towards developing an LLM as a supervisor to train real therapists. In addition to the privacy of clinical therapist training data, a fundamental contradiction complicates the training of therapeutic behaviors: clear feedback standards are necessary to ensure a controlled training system, yet there is no absolute \"gold standard\" for appropriate therapeutic behaviors in practice. In contrast, many common therapeutic mistakes are universal and identifiable, making them effective triggers for targeted feedback that can serve as clearer evidence. Motivated by this, we create a novel therapist-training paradigm: (1) guidelines for mistaken behaviors and targeted correction strategies are first established as standards; (2) a human-in-the-loop dialogue-feedback dataset is then constructed, where a mistake-prone agent intentionally makes standard mistakes during interviews naturally, and a supervisor agent locates and identifies mistakes and provides targeted feedback; (3) after fine-tuning on this dataset, the final supervisor model is provided for real therapist training. The detailed experimental results of automated, human and downstream assessments demonstrate that models fine-tuned on our dataset MATE, can provide high-quality feedback according to the clinical guideline, showing significant potential for the therapist training scenario.", "subjects": "Computation and Language (cs.CL)", "comments": "9 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2508.09042.pdf", "abstract_url": "https://arxiv.org/abs/2508.09042", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新颖的治疗师训练范式，利用大型语言模型（LLM）作为监督者，通过识别普遍的治疗错误并提供针对性反馈来训练真实治疗师。", "motivation": "尽管大型语言模型在心理治疗中具有巨大潜力，但其直接应用于患者面对的场景会引发伦理和安全问题。因此，本研究转向开发一种作为监督者的LLM来训练真实治疗师。", "method": "研究首先建立了错误行为和针对性纠正策略的指南作为标准；然后构建了一个人类参与的对话-反馈数据集，其中易犯错误的代理在访谈中故意犯标准错误，监督代理则定位并识别错误并提供针对性反馈；最后，在该数据集上微调后，提供最终的监督模型用于真实治疗师训练。", "result": "自动化、人类和下游评估的详细实验结果表明，基于我们的数据集MATE微调的模型能够根据临床指南提供高质量的反馈，显示出治疗师训练场景的巨大潜力。", "conclusion": "本研究展示了一种有效的治疗师训练方法，通过利用LLM作为监督者，能够识别并提供针对性的反馈，从而提高治疗师的专业技能，为心理治疗领域带来了新的可能性。"}}
{"id": "2508.09057", "title": "MVISU-Bench: Benchmarking Mobile Agents for Real-World Tasks by Multi-App, Vague, Interactive, Single-App and Unethical Instructions", "authors": ["Zeyu Huang", "Juyuan Wang", "Longfeng Chen", "Boyi Xiao", "Leng Cai", "Yawen Zeng", "Jin Xu"], "abstract": "Given the significant advances in Large Vision Language Models (LVLMs) in reasoning and visual understanding, mobile agents are rapidly emerging to meet users' automation needs. However, existing evaluation benchmarks are disconnected from the real world and fail to adequately address the diverse and complex requirements of users. From our extensive collection of user questionnaire, we identified five tasks: Multi-App, Vague, Interactive, Single-App, and Unethical Instructions. Around these tasks, we present \\textbf{MVISU-Bench}, a bilingual benchmark that includes 404 tasks across 137 mobile applications. Furthermore, we propose Aider, a plug-and-play module that acts as a dynamic prompt prompter to mitigate risks and clarify user intent for mobile agents. Our Aider is easy to integrate into several frameworks and has successfully improved overall success rates by 19.55\\% compared to the current state-of-the-art (SOTA) on MVISU-Bench. Specifically, it achieves success rate improvements of 53.52\\% and 29.41\\% for unethical and interactive instructions, respectively. Through extensive experiments and analysis, we highlight the gap between existing mobile agents and real-world user expectations.", "subjects": "Computation and Language (cs.CL)", "comments": "ACM MM 2025", "pdf_url": "https://arxiv.org/pdf/2508.09057.pdf", "abstract_url": "https://arxiv.org/abs/2508.09057", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "MVISU-Bench是一个双语基准测试，包含404个任务，覆盖137个移动应用，旨在评估移动代理在现实世界任务中的表现。研究还提出了Aider模块，以动态提示的方式提高移动代理的成功率。", "motivation": "现有的评估基准与现实世界脱节，无法充分满足用户多样化和复杂的需求。", "method": "通过用户问卷收集的五类任务（多应用、模糊、交互、单应用和不道德指令），构建MVISU-Bench基准，并开发Aider模块作为动态提示器。", "result": "Aider模块成功将整体成功率提高了19.55%，在不道德和交互指令上的成功率分别提高了53.52%和29.41%。", "conclusion": "研究揭示了现有移动代理与用户期望之间的差距，Aider模块的提出为缩小这一差距提供了有效工具。"}}
{"id": "2508.09124", "title": "OdysseyBench: Evaluating LLM Agents on Long-Horizon Complex Office Application Workflows", "authors": ["Weixuan Wang", "Dongge Han", "Daniel Madrigal Diaz", "Jin Xu", "Victor Rühle", "Saravan Rajmohan"], "abstract": "Autonomous agents powered by large language models (LLMs) are increasingly deployed in real-world applications requiring complex, long-horizon workflows. However, existing benchmarks predominantly focus on atomic tasks that are self-contained and independent, failing to capture the long-term contextual dependencies and multi-interaction coordination required in realistic scenarios. To address this gap, we introduce OdysseyBench, a comprehensive benchmark for evaluating LLM agents on long-horizon workflows across diverse office applications including Word, Excel, PDF, Email, and Calendar. Our benchmark comprises two complementary splits: OdysseyBench+ with 300 tasks derived from real-world use cases, and OdysseyBench-Neo with 302 newly synthesized complex tasks. Each task requires agent to identify essential information from long-horizon interaction histories and perform multi-step reasoning across various applications. To enable scalable benchmark creation, we propose HomerAgents, a multi-agent framework that automates the generation of long-horizon workflow benchmarks through systematic environment exploration, task generation, and dialogue synthesis. Our extensive evaluation demonstrates that OdysseyBench effectively challenges state-of-the-art LLM agents, providing more accurate assessment of their capabilities in complex, real-world contexts compared to existing atomic task benchmarks. We believe that OdysseyBench will serve as a valuable resource for advancing the development and evaluation of LLM agents in real-world productivity scenarios. In addition, we release OdysseyBench and HomerAgents to foster research along this line.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.09124.pdf", "abstract_url": "https://arxiv.org/abs/2508.09124", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了OdysseyBench，一个用于评估大型语言模型（LLM）代理在长期复杂办公应用工作流程中表现的全面基准。", "motivation": "现有的基准主要关注自包含和独立的原子任务，未能捕捉现实场景中所需的长期上下文依赖和多交互协调。", "method": "提出了OdysseyBench，包括两个互补的分割：OdysseyBench+和OdysseyBench-Neo，以及HomerAgents，一个多代理框架，用于自动化生成长期工作流程基准。", "result": "OdysseyBench有效地挑战了最先进的LLM代理，提供了比现有原子任务基准更准确的复杂、现实世界上下文中的能力评估。", "conclusion": "OdysseyBench将成为推动LLM代理在现实世界生产力场景中开发和评估的宝贵资源。"}}
{"id": "2508.09125", "title": "Complex Logical Instruction Generation", "authors": ["Mian Zhang", "Shujian Liu", "Sixun Dong", "Ming Yin", "Yebowen Hu", "Xun Wang", "Steven Ma", "Song Wang", "Sathish Reddy Indurthi", "Haoyun Deng", "Zhiyu Zoey Chen", "Kaiqiang Song"], "abstract": "Instruction following has catalyzed the recent era of Large Language Models (LLMs) and is the foundational skill underpinning more advanced capabilities such as reasoning and agentic behaviors. As tasks grow more challenging, the logic structures embedded in natural language instructions becomes increasingly intricate. However, how well LLMs perform on such logic-rich instructions remains under-explored. We propose LogicIFGen and LogicIFEval. LogicIFGen is a scalable, automated framework for generating verifiable instructions from code functions, which can naturally express rich logic such as conditionals, nesting, recursion, and function calls. We further curate a collection of complex code functions and use LogicIFGen to construct LogicIFEval, a benchmark comprising 426 verifiable logic-rich instructions. Our experiments demonstrate that current state-of-the-art LLMs still struggle to correctly follow the instructions in LogicIFEval. Most LLMs can only follow fewer than 60% of the instructions, revealing significant deficiencies in the instruction-following ability. Code and Benchmark:", "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.09125.pdf", "abstract_url": "https://arxiv.org/abs/2508.09125", "categories": ["Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了LogicIFGen和LogicIFEval，一个用于从代码函数生成可验证指令的自动化框架和一个包含426条逻辑丰富指令的基准测试。实验显示，当前最先进的大型语言模型在遵循这些复杂指令方面仍存在困难。", "motivation": "探索大型语言模型（LLMs）在处理逻辑丰富的自然语言指令方面的表现，目前这一领域尚未充分研究。", "method": "开发了LogicIFGen框架，通过代码函数自动生成可验证的、逻辑丰富的指令，并构建了LogicIFEval基准测试来评估LLMs的性能。", "result": "实验结果表明，当前最先进的LLMs在LogicIFEval基准测试中只能正确遵循不到60%的指令，显示出在指令遵循能力上的显著不足。", "conclusion": "这项研究揭示了LLMs在处理复杂逻辑指令方面的局限性，为未来改进LLMs的指令遵循能力提供了方向和基准。"}}
{"id": "2508.08322", "title": "Context Engineering for Multi-Agent LLM Code Assistants Using Elicit, NotebookLM, ChatGPT, and Claude Code", "authors": ["Muhammad Haseeb"], "abstract": "Large Language Models (LLMs) have shown promise in automating code generation and software engineering tasks, yet they often struggle with complex, multi-file projects due to context limitations and knowledge gaps. We propose a novel context engineering workflow that combines multiple AI components: an Intent Translator (GPT-5) for clarifying user requirements, an Elicit-powered semantic literature retrieval for injecting domain knowledge, NotebookLM-based document synthesis for contextual understanding, and a Claude Code multi-agent system for code generation and validation. Our integrated approach leverages intent clarification, retrieval-augmented generation, and specialized sub-agents orchestrated via Claude's agent framework. We demonstrate that this method significantly improves the accuracy and reliability of code assistants in real-world repositories, yielding higher single-shot success rates and better adherence to project context than baseline single-agent approaches. Qualitative results on a large", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": "15 pages, 5 figures, research paper on multi-agent LLM systems for code generation", "pdf_url": "https://arxiv.org/pdf/2508.08322.pdf", "abstract_url": "https://arxiv.org/abs/2508.08322", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新颖的上下文工程工作流程，结合了多种AI组件，以提高大型语言模型（LLMs）在复杂、多文件项目中的代码生成和软件工程任务的准确性和可靠性。", "motivation": "大型语言模型在自动化代码生成和软件工程任务中显示出潜力，但由于上下文限制和知识差距，它们在复杂的多文件项目中常常遇到困难。", "method": "提出的方法结合了意图翻译器（GPT-5）用于澄清用户需求，Elicit驱动的语义文献检索用于注入领域知识，NotebookLM基于文档的合成用于上下文理解，以及Claude Code多代理系统用于代码生成和验证。", "result": "该方法在现实世界仓库中显著提高了代码助手的准确性和可靠性，比基线单代理方法具有更高的单次成功率和更好的项目上下文遵循性。", "conclusion": "集成的上下文工程工作流程通过意图澄清、检索增强生成和专门子代理的协调，显著提升了代码助手在复杂项目中的性能。"}}
{"id": "2508.08325", "title": "Algorithmic Collusion of Pricing and Advertising on E-commerce Platforms", "authors": ["Hangcheng Zhao", "Ron Berman"], "abstract": "Online sellers have been adopting AI learning algorithms to automatically make product pricing and advertising decisions on e-commerce platforms. When sellers compete using such algorithms, one concern is that of tacit collusion - the algorithms learn to coordinate on higher than competitive. We empirically investigate whether these concerns are valid when sellers make pricing and advertising decisions together, i.e., two-dimensional decisions. Our empirical strategy is to analyze competition with multi-agent reinforcement learning, which we calibrate to a large-scale dataset collected from", "subjects": "General Economics (econ.GN); Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Computer Science and Game Theory (cs.GT); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.08325.pdf", "abstract_url": "https://arxiv.org/abs/2508.08325", "categories": ["General Economics (econ.GN)", "Artificial Intelligence (cs.AI)", "Computational Engineering, Finance, and Science (cs.CE)", "Computer Science and Game Theory (cs.GT)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了电子商务平台上卖家使用AI学习算法自动制定产品定价和广告决策时可能出现的隐性串谋问题。通过多智能体强化学习的方法，结合大规模数据集，研究了在定价和广告两个维度决策下的竞争情况。", "motivation": "解决在线卖家使用AI算法在定价和广告决策中可能导致的隐性串谋问题，即算法学会协调以维持高于竞争水平的价格。", "method": "采用多智能体强化学习的方法，并结合大规模数据集进行校准，以分析在定价和广告两个维度决策下的竞争情况。", "result": "研究发现，当卖家在定价和广告两个维度上使用AI算法进行决策时，确实存在隐性串谋的风险。", "conclusion": "本文的结论强调了在电子商务平台上，卖家使用AI算法进行定价和广告决策时，需要警惕隐性串谋的可能性，并可能需要对算法进行监管以防止此类行为。"}}
{"id": "2508.08544", "title": "AI Agents and the Law", "authors": ["Mark O. Riedl", "Deven R. Desai"], "abstract": "As AI becomes more \"agentic,\" it faces technical and socio-legal issues it must address if it is to fulfill its promise of increased economic productivity and efficiency. This paper uses technical and legal perspectives to explain how things change when AI systems start being able to directly execute tasks on behalf of a user. We show how technical conceptions of agents track some, but not all, socio-legal conceptions of agency. That is, both computer science and the law recognize the problems of under-specification for an agent, and both disciplines have robust conceptions of how to address ensuring an agent does what the programmer, or in the law, the principal desires and no more. However, to date, computer science has under-theorized issues related to questions of loyalty and to third parties that interact with an agent, both of which are central parts of the law of agency. First, we examine the correlations between implied authority in agency law and the principle of value-alignment in AI, wherein AI systems must operate under imperfect objective specification. Second, we reveal gaps in the current computer science view of agents pertaining to the legal concepts of disclosure and loyalty, and how failure to account for them can result in unintended effects in AI ecommerce agents. In surfacing these gaps, we show a path forward for responsible AI agent development and deployment.", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI)", "comments": "2025 AAAI Conference on AI, Ethics, and Society", "pdf_url": "https://arxiv.org/pdf/2508.08544.pdf", "abstract_url": "https://arxiv.org/abs/2508.08544", "categories": ["Computers and Society (cs.CY)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文探讨了AI代理在技术和法律层面的挑战，特别是在AI系统能够直接代表用户执行任务时。通过技术和法律视角，分析了AI代理与法律代理概念的异同，并指出了计算机科学在忠诚度和第三方互动方面的理论不足。", "motivation": "解决AI代理在成为更具‘代理性’时面临的技术和社会法律问题，以实现其提高经济生产力和效率的承诺。", "method": "结合技术和法律视角，分析AI代理与法律代理概念的异同，并探讨计算机科学在相关理论上的不足。", "result": "揭示了计算机科学在AI代理忠诚度和第三方互动方面的理论不足，并提出了负责任的AI代理开发和部署的路径。", "conclusion": "通过填补计算机科学在AI代理忠诚度和第三方互动方面的理论空白，可以促进AI代理的负责任发展和部署。"}}
{"id": "2508.08810", "title": "Not in My Backyard! Temporal Voting Over Public Chores", "authors": ["Edith Elkind", "Tzeh Yuan Neoh", "Nicholas Teh"], "abstract": "We study a temporal voting model where voters have dynamic preferences over a set of public chores -- projects that benefit society, but impose individual costs on those affected by their implementation. We investigate the computational complexity of optimizing utilitarian and egalitarian welfare. Our results show that while optimizing the former is computationally straightforward, minimizing the latter is computationally intractable, even in very restricted cases. Nevertheless, we identify several settings where this problem can be solved efficiently, either exactly or by an approximation algorithm. We also examine the effects of enforcing temporal fairness and its impact on social welfare, and analyze the competitive ratio of online algorithms. We then explore the strategic behavior of agents, providing insights into potential malfeasance in such decision-making environments. Finally, we discuss a range of fairness measures and their suitability for our setting.", "subjects": "Computer Science and Game Theory (cs.GT); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA); Theoretical Economics (econ.TH)", "comments": "Appears in the 34th International Joint Conference on Artificial Intelligence (IJCAI), 2025", "pdf_url": "https://arxiv.org/pdf/2508.08810.pdf", "abstract_url": "https://arxiv.org/abs/2508.08810", "categories": ["Computer Science and Game Theory (cs.GT)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)", "Theoretical Economics (econ.TH)"], "matching_keywords": ["agent"], "AI": {"tldr": "研究了一个时间投票模型，其中选民对公共事务（对社会有益但给受影响个体带来成本的项目）有动态偏好。探讨了优化功利主义和平均主义福利的计算复杂性。", "motivation": "解决在公共事务决策中，如何平衡社会利益与个体成本，以及如何高效计算最优决策的问题。", "method": "通过计算复杂性分析、近似算法研究、在线算法竞争比分析及代理策略行为探讨。", "result": "优化功利主义福利计算简单，而最小化平均主义福利即使在严格限制下也计算困难。但在某些设置下可高效解决，精确或近似。", "conclusion": "时间公平性强制执行对社会福利有影响，代理策略行为揭示了决策环境中的潜在不当行为，讨论了多种公平性度量及其适用性。"}}
{"id": "2508.08627", "title": "QoE-Aware Service Provision for Mobile AR Rendering: An Agent-Driven Approach", "authors": ["Conghao Zhou", "Lulu Sun", "Xiucheng Wang", "Peng Yang", "Feng Lyu", "Sihan Lu", "Xuemin Shen"], "abstract": "Mobile augmented reality (MAR) is envisioned as a key immersive application in 6G, enabling virtual content rendering aligned with the physical environment through device pose estimation. In this paper, we propose a novel agent-driven communication service provisioning approach for edge-assisted MAR, aiming to reduce communication overhead between MAR devices and the edge server while ensuring the quality of experience (QoE). First, to address the inaccessibility of MAR application-specific information to the network controller, we establish a digital agent powered by large language models (LLMs) on behalf of the MAR service provider, bridging the data and function gap between the MAR service and network domains. Second, to cope with the user-dependent and dynamic nature of data traffic patterns for individual devices, we develop a user-level QoE modeling method that captures the relationship between communication resource demands and perceived user QoE, enabling personalized, agent-driven communication resource management. Trace-driven simulation results demonstrate that the proposed approach outperforms conventional LLM-based QoE-aware service provisioning methods in both user-level QoE modeling accuracy and communication resource efficiency.", "subjects": "Networking and Internet Architecture (cs.NI); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.08627.pdf", "abstract_url": "https://arxiv.org/abs/2508.08627", "categories": ["Networking and Internet Architecture (cs.NI)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新颖的代理驱动通信服务供应方法，用于边缘辅助移动增强现实（MAR），旨在减少MAR设备与边缘服务器之间的通信开销，同时确保体验质量（QoE）。通过建立由大型语言模型（LLMs）驱动的数字代理，以及开发用户级QoE建模方法，实现了个性化和高效的通信资源管理。", "motivation": "解决移动增强现实（MAR）在6G中作为关键沉浸式应用时，网络控制器无法访问MAR应用特定信息的问题，以及用户依赖性和动态数据流量模式对通信资源管理的挑战。", "method": "首先，建立由大型语言模型（LLMs）驱动的数字代理，以桥接MAR服务和网络领域之间的数据和功能差距；其次，开发用户级QoE建模方法，以捕捉通信资源需求与感知用户QoE之间的关系。", "result": "跟踪驱动仿真结果表明，所提出的方法在用户级QoE建模准确性和通信资源效率方面优于传统的基于LLM的QoE感知服务供应方法。", "conclusion": "通过代理驱动的方法和用户级QoE建模，能够有效减少通信开销，同时保证用户体验质量，为边缘辅助MAR服务提供了高效的通信资源管理解决方案。"}}
{"id": "2508.08837", "title": "The Roots of International Perceptions: Simulating US Attitude Changes Towards China with LLM Agents", "authors": ["Nicholas Sukiennik", "Yichuan Xu", "Yuqing Kan", "Jinghua Piao", "Yuwei Yan", "Chen Gao", "Yong Li"], "abstract": "The rise of LLMs poses new possibilities in modeling opinion evolution, a long-standing task in simulation, by leveraging advanced reasoning abilities to recreate complex, large-scale human cognitive trends. While most prior works focus on opinion evolution surrounding specific isolated events or the views within a country, ours is the first to model the large-scale attitude evolution of a population representing an entire country towards another -- US citizens' perspectives towards China. To tackle the challenges of this broad scenario, we propose a framework that integrates media data collection, user profile creation, and cognitive architecture for opinion updates to successfully reproduce the real trend of US attitudes towards China over a 20-year period from 2005 to today. We also leverage LLMs' capabilities to introduce debiased media exposure, extracting neutral events from typically subjective news contents, to uncover the roots of polarized opinion formation, as well as a devils advocate agent to help explain the rare reversal from negative to positive attitudes towards China, corresponding with changes in the way Americans obtain information about the country. The simulation results, beyond validating our framework architecture, also reveal the impact of biased framing and selection bias in shaping attitudes. Overall, our work contributes to a new paradigm for LLM-based modeling of cognitive behaviors in a large-scale, long-term, cross-border social context, providing insights into the formation of international biases and offering valuable implications for media consumers to better understand the factors shaping their perspectives, and ultimately contributing to the larger social need for bias reduction and cross-cultural tolerance.", "subjects": "Social and Information Networks (cs.SI); Artificial Intelligence (cs.AI)", "comments": "Submitted to AAAI Social Impact 2026", "pdf_url": "https://arxiv.org/pdf/2508.08837.pdf", "abstract_url": "https://arxiv.org/abs/2508.08837", "categories": ["Social and Information Networks (cs.SI)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种利用大型语言模型（LLM）代理模拟美国对中国态度变化的框架，通过整合媒体数据收集、用户档案创建和认知架构，成功再现了2005年至今20年间美国对中国态度的真实趋势。研究还利用LLM的能力引入了去偏见的媒体曝光和魔鬼代言人代理，揭示了极化意见形成的根源以及态度从负面转向正面的罕见逆转。", "motivation": "解决如何利用大型语言模型（LLM）模拟大规模、长期、跨国社会背景下认知行为的问题，特别是美国公民对中国态度的演变。", "method": "提出一个框架，整合媒体数据收集、用户档案创建和认知架构，用于意见更新，并利用LLM的能力引入去偏见的媒体曝光和魔鬼代言人代理。", "result": "成功再现了美国对中国态度的真实趋势，揭示了偏见框架和选择偏见在塑造态度中的影响，以及态度逆转的原因。", "conclusion": "本研究为基于LLM的大规模、长期、跨国社会认知行为建模提供了新范式，揭示了国际偏见的形成机制，为媒体消费者提供了理解视角形成因素的宝贵见解，有助于减少偏见和促进跨文化容忍。"}}
