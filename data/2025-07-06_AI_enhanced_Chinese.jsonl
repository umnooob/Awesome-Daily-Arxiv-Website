{"id": "2507.02076", "title": "Reasoning on a Budget: A Survey of Adaptive and Controllable Test-Time Compute in LLMs", "authors": ["Mohammad Ali Alomrani", "Yingxue Zhang", "Derek Li", "Qianyi Sun", "Soumyasundar Pal", "Zhanguang Zhang", "Yaochen Hu", "Rohan Deepak Ajwani", "Antonios Valkanas", "Raika Karimi", "Peng Cheng", "Yunzhou Wang", "Pengyi Liao", "Hanrui Huang", "Bin Wang", "Jianye Hao", "Mark Coates"], "abstract": "Large language models (LLMs) have rapidly progressed into general-purpose agents capable of solving a broad spectrum of tasks. However, current models remain inefficient at reasoning: they apply fixed inference-time compute regardless of task complexity, often overthinking simple problems while underthinking hard ones. This survey presents a comprehensive review of efficient test-time compute (TTC) strategies, which aim to improve the computational efficiency of LLM reasoning. We introduce a two-tiered taxonomy that distinguishes between L1-controllability, methods that operate under fixed compute budgets, and L2-adaptiveness, methods that dynamically scale inference based on input difficulty or model confidence. We benchmark leading proprietary LLMs across diverse datasets, highlighting critical trade-offs between reasoning performance and token usage. Compared to prior surveys on efficient reasoning, our review emphasizes the practical control, adaptability, and scalability of TTC methods. Finally, we discuss emerging trends such as hybrid thinking models and identify key challenges for future work towards making LLMs more computationally efficient, robust, and responsive to user constraints.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.02076.pdf", "abstract_url": "https://arxiv.org/abs/2507.02076", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文综述了大型语言模型（LLMs）在推理效率方面的研究，特别是测试时计算（TTC）策略，旨在通过自适应和可控的计算提升LLMs的推理效率。", "motivation": "当前的大型语言模型在推理时采用固定的计算资源，无论任务复杂度如何，这导致简单问题过度计算而复杂问题计算不足，影响了模型的效率和性能。", "method": "提出了一个两层次的分类法：L1-可控性（在固定计算预算下操作的方法）和L2-自适应性（根据输入难度或模型置信度动态调整推理规模的方法），并对领先的专有LLMs进行了基准测试。", "result": "通过对比不同数据集上的推理性能和令牌使用量，揭示了推理性能与计算资源使用之间的关键权衡。", "conclusion": "本文强调了TTC方法在实际控制、适应性和可扩展性方面的重要性，并讨论了混合思维模型等新兴趋势，为未来使LLMs更高效、稳健且对用户约束更敏感的研究指明了方向。"}}
{"id": "2507.02252", "title": "SurgVisAgent: Multimodal Agentic Model for Versatile Surgical Visual Enhancement", "authors": ["Zeyu Lei", "Hongyuan Yu", "Jinlin Wu", "Zhen Chen"], "abstract": "Precise surgical interventions are vital to patient safety, and advanced enhancement algorithms have been developed to assist surgeons in decision-making. Despite significant progress, these algorithms are typically designed for single tasks in specific scenarios, limiting their effectiveness in complex real-world situations. To address this limitation, we propose SurgVisAgent, an end-to-end intelligent surgical vision agent built on multimodal large language models (MLLMs). SurgVisAgent dynamically identifies distortion categories and severity levels in endoscopic images, enabling it to perform a variety of enhancement tasks such as low-light enhancement, overexposure correction, motion blur elimination, and smoke removal. Specifically, to achieve superior surgical scenario understanding, we design a prior model that provides domain-specific knowledge. Additionally, through in-context few-shot learning and chain-of-thought (CoT) reasoning, SurgVisAgent delivers customized image enhancements tailored to a wide range of distortion types and severity levels, thereby addressing the diverse requirements of surgeons. Furthermore, we construct a comprehensive benchmark simulating real-world surgical distortions, on which extensive experiments demonstrate that SurgVisAgent surpasses traditional single-task models, highlighting its potential as a unified solution for surgical assistance.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.02252.pdf", "abstract_url": "https://arxiv.org/abs/2507.02252", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "SurgVisAgent是一种基于多模态大语言模型（MLLMs）的端到端智能手术视觉代理，旨在通过动态识别内窥镜图像中的失真类别和严重程度，执行多种增强任务，如低光增强、过曝校正、运动模糊消除和烟雾去除，以提升手术场景的理解和图像增强的定制化。", "motivation": "现有的手术增强算法通常针对特定场景的单一任务设计，限制了其在复杂现实情况下的有效性。为了解决这一限制，提出了SurgVisAgent。", "method": "SurgVisAgent结合了领域特定的先验模型、上下文少样本学习和链式思维（CoT）推理，以提供针对广泛失真类型和严重程度定制的图像增强。", "result": "在模拟真实世界手术失真的综合基准测试中，SurgVisAgent超越了传统的单任务模型，展示了其作为手术辅助统一解决方案的潜力。", "conclusion": "SurgVisAgent通过其多功能性和适应性，为解决手术视觉增强中的多样化需求提供了一种有效的解决方案，有望提高手术决策的精确性和患者安全。"}}
{"id": "2507.02004", "title": "STELLA: Self-Evolving LLM Agent for Biomedical Research", "authors": ["Ruofan Jin", "Zaixi Zhang", "Mengdi Wang", "Le Cong"], "abstract": "The rapid growth of biomedical data, tools, and literature has created a fragmented research landscape that outpaces human expertise. While AI agents offer a solution, they typically rely on static, manually curated toolsets, limiting their ability to adapt and scale. Here, we introduce STELLA, a self-evolving AI agent designed to overcome these limitations. STELLA employs a multi-agent architecture that autonomously improves its own capabilities through two core mechanisms: an evolving Template Library for reasoning strategies and a dynamic Tool Ocean that expands as a Tool Creation Agent automatically discovers and integrates new bioinformatics tools. This allows STELLA to learn from experience. We demonstrate that STELLA achieves state-of-the-art accuracy on a suite of biomedical benchmarks, scoring approximately 26\\% on Humanity's Last Exam: Biomedicine, 54\\% on LAB-Bench: DBQA, and 63\\% on LAB-Bench: LitQA, outperforming leading models by up to 6 percentage points. More importantly, we show that its performance systematically improves with experience; for instance, its accuracy on the Humanity's Last Exam benchmark almost doubles with increased trials. STELLA represents a significant advance towards AI Agent systems that can learn and grow, dynamically scaling their expertise to accelerate the pace of biomedical discovery.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Biomolecules (q-bio.BM)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.02004.pdf", "abstract_url": "https://arxiv.org/abs/2507.02004", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Biomolecules (q-bio.BM)"], "matching_keywords": ["agent"], "AI": {"tldr": "STELLA是一种自演化的AI代理，旨在解决生物医学研究中数据、工具和文献快速增长导致的碎片化问题。它通过多代理架构自主提升能力，包括演化的模板库和动态工具海洋，自动发现和整合新的生物信息学工具。STELLA在多个生物医学基准测试中表现出色，性能随经验提升。", "motivation": "生物医学数据、工具和文献的快速增长导致了碎片化的研究环境，超出了人类专家的处理能力。现有的AI代理通常依赖静态、手动整理的工具集，限制了其适应和扩展能力。", "method": "STELLA采用多代理架构，通过演化的模板库和动态工具海洋（由工具创建代理自动发现和整合新工具）自主提升能力。", "result": "STELLA在一系列生物医学基准测试中取得了最先进的准确率，如在Humanity's Last Exam: Biomedicine上得分约26%，在LAB-Bench: DBQA上得分54%，在LAB-Bench: LitQA上得分63%，领先于其他领先模型最多6个百分点。更重要的是，其性能随经验系统提升。", "conclusion": "STELLA代表了AI代理系统的一个重要进步，能够学习和成长，动态扩展其专业知识，以加速生物医学发现的步伐。"}}
{"id": "2507.02103", "title": "What Neuroscience Can Teach AI About Learning in Continuously Changing Environments", "authors": ["Daniel Durstewitz", "Bruno Averbeck", "Georgia Koppe"], "abstract": "Modern AI models, such as large language models, are usually trained once on a huge corpus of data, potentially fine-tuned for a specific task, and then deployed with fixed parameters. Their training is costly, slow, and gradual, requiring billions of repetitions. In stark contrast, animals continuously adapt to the ever-changing contingencies in their environments. This is particularly important for social species, where behavioral policies and reward outcomes may frequently change in interaction with peers. The underlying computational processes are often marked by rapid shifts in an animal's behaviour and rather sudden transitions in neuronal population activity. Such computational capacities are of growing importance for AI systems operating in the real world, like those guiding robots or autonomous vehicles, or for agentic AI interacting with humans online. Can AI learn from neuroscience? This Perspective explores this question, integrating the literature on continual and in-context learning in AI with the neuroscience of learning on behavioral tasks with shifting rules, reward probabilities, or outcomes. We will outline an agenda for how specifically insights from neuroscience may inform current developments in AI in this area, and - vice versa - what neuroscience may learn from AI, contributing to the evolving field of NeuroAI.", "subjects": "Artificial Intelligence (cs.AI); Neurons and Cognition (q-bio.NC)", "comments": "Submitted as a Perspective article (10 pages, 5 figures)", "pdf_url": "https://arxiv.org/pdf/2507.02103.pdf", "abstract_url": "https://arxiv.org/abs/2507.02103", "categories": ["Artificial Intelligence (cs.AI)", "Neurons and Cognition (q-bio.NC)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文探讨了现代AI模型与动物在学习适应不断变化环境方面的差异，提出了从神经科学中汲取灵感以改进AI持续学习能力的观点，并探讨了神经科学与AI相互学习的可能性。", "motivation": "解决现代AI模型在持续学习和适应不断变化环境方面的不足，特别是在需要快速适应新任务和变化奖励的社会互动场景中。", "method": "整合了AI中的持续学习和上下文学习文献与神经科学中关于行为任务学习的研究，提出了一个研究议程。", "result": "提出了神经科学可以为AI在持续学习方面提供具体见解，同时AI的发展也可能为神经科学带来新的研究方向和工具。", "conclusion": "神经科学与AI的交叉研究有望推动两个领域的进步，特别是在开发能够适应不断变化环境的AI系统方面。"}}
{"id": "2507.02083", "title": "Measuring Scientific Capabilities of Language Models with a Systems Biology Dry Lab", "authors": ["Haonan Duan", "Stephen Zhewen Lu", "Caitlin Fiona Harrigan", "Nishkrit Desai", "Jiarui Lu", "Michał Koziarski", "Leonardo Cotta", "Chris J. Maddison"], "abstract": "Designing experiments and result interpretations are core scientific competencies, particularly in biology, where researchers perturb complex systems to uncover the underlying systems. Recent efforts to evaluate the scientific capabilities of large language models (LLMs) fail to test these competencies because wet-lab experimentation is prohibitively expensive: in expertise, time and equipment. We introduce SciGym, a first-in-class benchmark that assesses LLMs' iterative experiment design and analysis abilities in open-ended scientific discovery tasks. SciGym overcomes the challenge of wet-lab costs by running a dry lab of biological systems. These models, encoded in Systems Biology Markup Language, are efficient for generating simulated data, making them ideal testbeds for experimentation on realistically complex systems. We evaluated six frontier LLMs on 137 small systems, and released a total of 350 systems. Our evaluation shows that while more capable models demonstrated superior performance, all models' performance declined significantly as system complexity increased, suggesting substantial room for improvement in the scientific capabilities of LLM agents.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.02083.pdf", "abstract_url": "https://arxiv.org/abs/2507.02083", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了SciGym，一个评估大型语言模型（LLMs）在开放式科学发现任务中迭代实验设计和分析能力的基准测试。通过使用系统生物学干实验室克服湿实验室的高成本问题，评估了六种前沿LLMs在137个小系统上的表现，并发布了总共350个系统。", "motivation": "评估LLMs的科学能力，特别是在设计和解释实验方面的能力，由于湿实验室实验的高成本（专业知识、时间和设备）而难以进行。", "method": "引入SciGym基准测试，利用系统生物学标记语言编码的模型生成模拟数据，作为实验测试平台，评估LLMs在复杂系统上的表现。", "result": "虽然性能更强的模型表现出更优的性能，但随着系统复杂性的增加，所有模型的性能显著下降，表明LLM代理在科学能力上有很大的改进空间。", "conclusion": "SciGym为评估LLMs的科学能力提供了一个高效且成本效益高的方法，揭示了当前LLMs在复杂科学任务中的局限性，并指出了未来改进的方向。"}}
{"id": "2507.02197", "title": "Do Role-Playing Agents Practice What They Preach? Belief-Behavior Consistency in LLM-Based Simulations of Human Trust", "authors": ["Amogh Mannekote", "Adam Davies", "Guohao Li", "Kristy Elizabeth Boyer", "ChengXiang Zhai", "Bonnie J Dorr", "Francesco Pinto"], "abstract": "As LLMs are increasingly studied as role-playing agents to generate synthetic data for human behavioral research, ensuring that their outputs remain coherent with their assigned roles has become a critical concern. In this paper, we investigate how consistently LLM-based role-playing agents' stated beliefs about the behavior of the people they are asked to role-play (\"what they say\") correspond to their actual behavior during role-play (\"how they act\"). Specifically, we establish an evaluation framework to rigorously measure how well beliefs obtained by prompting the model can predict simulation outcomes in advance. Using an augmented version of the GenAgents persona bank and the Trust Game (a standard economic game used to quantify players' trust and reciprocity), we introduce a belief-behavior consistency metric to systematically investigate how it is affected by factors such as: (1) the types of beliefs we elicit from LLMs, like expected outcomes of simulations versus task-relevant attributes of individual characters LLMs are asked to simulate; (2) when and how we present LLMs with relevant information about Trust Game; and (3) how far into the future we ask the model to forecast its actions. We also explore how feasible it is to impose a researcher's own theoretical priors in the event that the originally elicited beliefs are misaligned with research objectives. Our results reveal systematic inconsistencies between LLMs' stated (or imposed) beliefs and the outcomes of their role-playing simulation, at both an individual- and population-level. Specifically, we find that, even when models appear to encode plausible beliefs, they may fail to apply them in a consistent way. These findings highlight the need to identify how and when LLMs' stated beliefs align with their simulated behavior, allowing researchers to use LLM-based agents appropriately in behavioral studies.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.02197.pdf", "abstract_url": "https://arxiv.org/abs/2507.02197", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究了基于LLM的角色扮演代理在模拟人类信任时的信念与行为一致性，提出了一个评估框架来衡量信念预测模拟结果的能力，并探讨了影响一致性的因素。", "motivation": "随着LLMs越来越多地被用作角色扮演代理以生成人类行为研究的合成数据，确保其输出与分配的角色保持一致成为一个关键问题。本文旨在解决LLM代理的信念与行为之间的一致性问题。", "method": "通过增强版的GenAgents角色库和信任游戏，引入了一个信念-行为一致性度量，系统地研究了影响一致性的因素，包括信念类型、信息呈现时机和未来行动预测范围。", "result": "研究发现，即使在模型编码了合理信念的情况下，它们也可能无法一致地应用这些信念，揭示了LLMs在个体和群体层面上的信念与行为之间存在系统性不一致。", "conclusion": "这些发现强调了识别LLMs的信念何时与其模拟行为一致的重要性，以便研究人员在行为研究中适当使用基于LLM的代理。"}}
{"id": "2507.02211", "title": "Dilution, Diffusion and Symbiosis in Spatial Prisoner's Dilemma with Reinforcement Learning", "authors": ["Gustavo C. Mangold", "Heitor C. M. Fernandes", "Mendeli H. Vainstein"], "abstract": "Recent studies in the spatial prisoner's dilemma games with reinforcement learning have shown that static agents can learn to cooperate through a diverse sort of mechanisms, including noise injection, different types of learning algorithms and neighbours' payoff", "subjects": "Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE); Computational Physics (physics.comp-ph)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.02211.pdf", "abstract_url": "https://arxiv.org/abs/2507.02211", "categories": ["Artificial Intelligence (cs.AI)", "Neural and Evolutionary Computing (cs.NE)", "Computational Physics (physics.comp-ph)"], "matching_keywords": ["agent"], "AI": {"tldr": "最近的研究表明，在具有强化学习的空间囚徒困境游戏中，静态代理可以通过多种机制学会合作，包括噪声注入、不同类型的学习算法和邻居的收益。", "motivation": "探讨在空间囚徒困境游戏中，静态代理如何通过不同的机制学习合作行为。", "method": "使用强化学习方法，结合噪声注入、不同的学习算法和邻居的收益信息。", "result": "研究发现，静态代理能够通过这些机制学会合作。", "conclusion": "这些发现为理解在复杂环境中合作行为的 emergence 提供了新的视角。"}}
{"id": "2507.02554", "title": "AI Research Agents for Machine Learning: Search, Exploration, and Generalization in MLE-bench", "authors": ["Edan Toledo", "Karen Hambardzumyan", "Martin Josifoski", "Rishi Hazra", "Nicolas Baldwin", "Alexis Audran-Reiss", "Michael Kuchnik", "Despoina Magka", "Minqi Jiang", "Alisia Maria Lupidi", "Andrei Lupu", "Roberta Raileanu", "Kelvin Niu", "Tatiana Shavrina", "Jean-Christophe Gagnon-Audet", "Michael Shvartsman", "Shagun Sodhani", "Alexander H. Miller", "Abhishek Charnalia", "Derek Dunfield", "Carole-Jean Wu", "Pontus Stenetorp", "Nicola Cancedda", "Jakob Nicolaus Foerster", "Yoram Bachrach"], "abstract": "AI research agents are demonstrating great potential to accelerate scientific progress by automating the design, implementation, and training of machine learning models. We focus on methods for improving agents' performance on MLE-bench, a challenging benchmark where agents compete in Kaggle competitions to solve real-world machine learning problems. We formalize AI research agents as search policies that navigate a space of candidate solutions, iteratively modifying them using operators. By designing and systematically varying different operator sets and search policies (Greedy, MCTS, Evolutionary), we show that their interplay is critical for achieving high performance. Our best pairing of search strategy and operator set achieves a state-of-the-art result on MLE-bench lite, increasing the success rate of achieving a Kaggle medal from 39.6% to 47.7%. Our investigation underscores the importance of jointly considering the search strategy, operator design, and evaluation methodology in advancing automated machine learning.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2507.02554.pdf", "abstract_url": "https://arxiv.org/abs/2507.02554", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "AI研究代理在MLE-bench基准测试中通过优化搜索策略和操作集，显著提高了在Kaggle竞赛中解决实际机器学习问题的成功率。", "motivation": "解决AI研究代理在自动化机器学习模型设计、实现和训练过程中面临的挑战，特别是在MLE-bench这一具有挑战性的基准测试中。", "method": "将AI研究代理形式化为搜索策略，通过设计不同的操作集和搜索策略（贪婪、MCTS、进化算法），探索它们之间的相互作用对性能的影响。", "result": "最佳搜索策略和操作集的组合在MLE-bench lite上实现了最先进的结果，将获得Kaggle奖牌的成功率从39.6%提高到47.7%。", "conclusion": "研究表明，在推进自动化机器学习的过程中，联合考虑搜索策略、操作设计和评估方法至关重要。"}}
{"id": "2507.02353", "title": "OMS: On-the-fly, Multi-Objective, Self-Reflective Ad Keyword Generation via LLM Agent", "authors": ["Bowen Chen", "Zhao Wang", "Shingo Takamatsu"], "abstract": "Keyword decision in Sponsored Search Advertising is critical to the success of ad campaigns. While LLM-based methods offer automated keyword generation, they face three major limitations: reliance on large-scale query-keyword pair data, lack of online multi-objective performance monitoring and optimization, and weak quality control in keyword selection. These issues hinder the agentic use of LLMs in fully automating keyword decisions by monitoring and reasoning over key performance indicators such as impressions, clicks, conversions, and CTA effectiveness. To overcome these challenges, we propose OMS, a keyword generation framework that is On-the-fly (requires no training data, monitors online performance, and adapts accordingly), Multi-objective (employs agentic reasoning to optimize keywords based on multiple performance metrics), and Self-reflective (agentically evaluates keyword quality). Experiments on benchmarks and real-world ad campaigns show that OMS outperforms existing methods; ablation and human evaluations confirm the effectiveness of each component and the quality of generated keywords.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.02353.pdf", "abstract_url": "https://arxiv.org/abs/2507.02353", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "OMS是一个无需训练数据、实时监控在线性能并自适应调整的多目标自反思关键词生成框架，用于赞助搜索广告中的关键词决策，通过代理推理优化基于多个性能指标的关键词，并在实验和实际广告活动中显示出优于现有方法的性能。", "motivation": "解决赞助搜索广告中基于LLM的关键词生成方法面临的三大限制：依赖大规模查询-关键词对数据、缺乏在线多目标性能监控和优化、以及关键词选择中的质量控制薄弱。", "method": "提出OMS框架，具有即时性（无需训练数据，监控在线性能并自适应调整）、多目标性（通过代理推理基于多个性能指标优化关键词）和自反思性（代理评估关键词质量）。", "result": "在基准测试和实际广告活动中，OMS表现优于现有方法；消融和人类评估确认了各组成部分的有效性和生成关键词的质量。", "conclusion": "OMS框架通过其即时性、多目标性和自反思性，有效地克服了现有LLM-based关键词生成方法的限制，为赞助搜索广告中的关键词决策提供了更高效、更自动化的解决方案。"}}
{"id": "2507.02259", "title": "MemAgent: Reshaping Long-Context LLM with Multi-Conv RL-based Memory Agent", "authors": ["Hongli Yu", "Tinghong Chen", "Jiangtao Feng", "Jiangjie Chen", "Weinan Dai", "Qiying Yu", "Ya-Qin Zhang", "Wei-Ying Ma", "Jingjing Liu", "Mingxuan Wang", "Hao Zhou"], "abstract": "Despite improvements by length extrapolation, efficient attention and memory modules, handling infinitely long documents with linear complexity without performance degradation during extrapolation remains the ultimate challenge in long-text processing. We directly optimize for long-text tasks in an end-to-end fashion and introduce a novel agent workflow, MemAgent, which reads text in segments and updates the memory using an overwrite strategy. We extend the DAPO algorithm to facilitate training via independent-context multi-conversation generation. MemAgent has demonstrated superb long-context capabilities, being able to extrapolate from an 8K context trained on 32K text to a 3.5M QA task with performance loss < 5% and achieves 95%+ in 512K RULER test.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2507.02259.pdf", "abstract_url": "https://arxiv.org/abs/2507.02259", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "MemAgent是一种新型的代理工作流程，通过分段阅读文本并使用覆盖策略更新内存，优化了长文本任务的处理。它展示了卓越的长上下文能力，能够从8K上下文训练扩展到32K文本，甚至在3.5M QA任务中性能损失小于5%。", "motivation": "处理无限长文档且在线性复杂度下不出现性能下降是长文本处理的终极挑战。", "method": "引入MemAgent代理工作流程，采用分段阅读和覆盖策略更新内存，扩展DAPO算法以通过独立上下文多对话生成进行训练。", "result": "MemAgent在8K上下文训练的基础上，能够扩展到32K文本，处理3.5M QA任务时性能损失小于5%，在512K RULER测试中达到95%以上的准确率。", "conclusion": "MemAgent通过其创新的内存更新策略和训练方法，显著提升了长文本处理的能力和效率，为解决长上下文挑战提供了有效的解决方案。"}}
{"id": "2507.02592", "title": "WebSailor: Navigating Super-human Reasoning for Web Agent", "authors": ["Kuan Li", "Zhongwang Zhang", "Huifeng Yin", "Liwen Zhang", "Litu Ou", "Jialong Wu", "Wenbiao Yin", "Baixuan Li", "Zhengwei Tao", "Xinyu Wang", "Weizhou Shen", "Junkai Zhang", "Dingchu Zhang", "Xixi Wu", "Yong Jiang", "Ming Yan", "Pengjun Xie", "Fei Huang", "Jingren Zhou"], "abstract": "Transcending human cognitive limitations represents a critical frontier in LLM training. Proprietary agentic systems like DeepResearch have demonstrated superhuman capabilities on extremely complex information-seeking benchmarks such as BrowseComp, a feat previously unattainable. We posit that their success hinges on a sophisticated reasoning pattern absent in open-source models: the ability to systematically reduce extreme uncertainty when navigating vast information landscapes. Based on this insight, we introduce WebSailor, a complete post-training methodology designed to instill this crucial capability. Our approach involves generating novel, high-uncertainty tasks through structured sampling and information obfuscation, RFT cold start, and an efficient agentic RL training algorithm, Duplicating Sampling Policy Optimization (DUPO). With this integrated pipeline, WebSailor significantly outperforms all opensource agents in complex information-seeking tasks, matching proprietary agents' performance and closing the capability gap.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.02592.pdf", "abstract_url": "https://arxiv.org/abs/2507.02592", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "WebSailor是一种后训练方法，旨在通过结构化采样和信息模糊化、RFT冷启动及高效的代理RL训练算法DUPO，赋予开源模型在复杂信息寻求任务中超人的推理能力。", "motivation": "解决开源模型在极端不确定性下导航广阔信息景观时缺乏系统推理能力的问题，缩小与专有代理在复杂信息寻求任务中的性能差距。", "method": "通过结构化采样和信息模糊化生成新颖高不确定性任务，采用RFT冷启动和DUPO算法进行高效的代理RL训练。", "result": "WebSailor在复杂信息寻求任务中显著优于所有开源代理，性能与专有代理相匹配。", "conclusion": "WebSailor通过其集成管道成功缩小了开源模型与专有代理在复杂信息寻求任务中的能力差距，展示了后训练方法在提升模型推理能力方面的潜力。"}}
{"id": "2507.02616", "title": "DynamiCare: A Dynamic Multi-Agent Framework for Interactive and Open-Ended Medical Decision-Making", "authors": ["Tianqi Shang", "Weiqing He", "Charles Zheng", "Lingyao Li", "Li Shen", "Bingxin Zhao"], "abstract": "The rise of Large Language Models (LLMs) has enabled the development of specialized AI agents with domain-specific reasoning and interaction capabilities, particularly in healthcare. While recent frameworks simulate medical decision-making, they largely focus on single-turn tasks where a doctor agent receives full case information upfront -- diverging from the real-world diagnostic process, which is inherently uncertain, interactive, and iterative. In this paper, we introduce MIMIC-Patient, a structured dataset built from the MIMIC-III electronic health records (EHRs), designed to support dynamic, patient-level simulations. Building on this, we propose DynamiCare, a novel dynamic multi-agent framework that models clinical diagnosis as a multi-round, interactive loop, where a team of specialist agents iteratively queries the patient system, integrates new information, and dynamically adapts its composition and strategy. We demonstrate the feasibility and effectiveness of DynamiCare through extensive experiments, establishing the first benchmark for dynamic clinical decision-making with LLM-powered agents.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "16 pages", "pdf_url": "https://arxiv.org/pdf/2507.02616.pdf", "abstract_url": "https://arxiv.org/abs/2507.02616", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了DynamiCare，一个动态多智能体框架，用于模拟现实世界中不确定、互动和迭代的医疗决策过程。基于MIMIC-Patient数据集，该框架通过多轮互动循环模拟临床诊断，展示了其可行性和有效性。", "motivation": "解决现有医疗决策模拟框架主要关注单轮任务，与现实世界诊断过程的不确定、互动和迭代特性不符的问题。", "method": "提出DynamiCare框架，利用MIMIC-Patient数据集，模拟临床诊断作为一个多轮、互动的循环过程，其中一组专家智能体迭代查询患者系统，整合新信息，并动态调整其组成和策略。", "result": "通过大量实验证明了DynamiCare的可行性和有效性，为使用LLM驱动的智能体进行动态临床决策建立了第一个基准。", "conclusion": "DynamiCare框架为模拟更接近现实世界的医疗决策过程提供了新方法，展示了LLM在医疗领域应用的潜力。"}}
{"id": "2507.02618", "title": "Strategic Intelligence in Large Language Models: Evidence from evolutionary Game Theory", "authors": ["Kenneth Payne", "Baptiste Alloui-Cros"], "abstract": "Are Large Language Models (LLMs) a new form of strategic intelligence, able to reason about goals in competitive settings? We present compelling supporting evidence. The Iterated Prisoner's Dilemma (IPD) has long served as a model for studying decision-making. We conduct the first ever series of evolutionary IPD tournaments, pitting canonical strategies (e.g., Tit-for-Tat, Grim Trigger) against agents from the leading frontier AI companies OpenAI, Google, and Anthropic. By varying the termination probability in each tournament (the \"shadow of the future\"), we introduce complexity and chance, confounding memorisation.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Science and Game Theory (cs.GT)", "comments": "29 pages, 27 tables, 4 figures", "pdf_url": "https://arxiv.org/pdf/2507.02618.pdf", "abstract_url": "https://arxiv.org/abs/2507.02618", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Computer Science and Game Theory (cs.GT)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了大型语言模型（LLMs）是否能够作为一种新型的战略智能，在竞争环境中进行目标推理。通过首次进行的进化迭代囚徒困境（IPD）锦标赛，将经典策略与领先的AI公司开发的代理进行对比，研究了LLMs的战略决策能力。", "motivation": "探索大型语言模型是否具备在竞争环境中进行战略推理的能力，以及它们是否能够理解和应用进化博弈论中的策略。", "method": "通过进化迭代囚徒困境（IPD）锦标赛，将经典策略（如以牙还牙、冷酷触发）与OpenAI、Google和Anthropic等公司的AI代理进行对比，并通过改变锦标赛中的终止概率（“未来的阴影”）来引入复杂性和偶然性。", "result": "研究提供了支持大型语言模型作为一种新型战略智能的证据，展示了它们在理解和应用进化博弈论策略方面的潜力。", "conclusion": "大型语言模型展现出了在竞争环境中进行战略推理的能力，这为理解AI在复杂决策制定中的应用开辟了新途径。"}}
{"id": "2507.02652", "title": "Decoupled Planning and Execution: A Hierarchical Reasoning Framework for Deep Search", "authors": ["Jiajie Jin", "Xiaoxi Li", "Guanting Dong", "Yuyao Zhang", "Yutao Zhu", "Yang Zhao", "Hongjin Qian", "Zhicheng Dou"], "abstract": "Complex information needs in real-world search scenarios demand deep reasoning and knowledge synthesis across diverse sources, which traditional retrieval-augmented generation (RAG) pipelines struggle to address effectively. Current reasoning-based approaches suffer from a fundamental limitation: they use a single model to handle both high-level planning and detailed execution, leading to inefficient reasoning and limited scalability. In this paper, we introduce HiRA, a hierarchical framework that separates strategic planning from specialized execution. Our approach decomposes complex search tasks into focused subtasks, assigns each subtask to domain-specific agents equipped with external tools and reasoning capabilities, and coordinates the results through a structured integration mechanism. This separation prevents execution details from disrupting high-level reasoning while enabling the system to leverage specialized expertise for different types of information processing. Experiments on four complex, cross-modal deep search benchmarks demonstrate that HiRA significantly outperforms state-of-the-art RAG and agent-based systems. Our results show improvements in both answer quality and system efficiency, highlighting the effectiveness of decoupled planning and execution for multi-step information seeking tasks. Our code is available at", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Information Retrieval (cs.IR)", "comments": "9 pages", "pdf_url": "https://arxiv.org/pdf/2507.02652.pdf", "abstract_url": "https://arxiv.org/abs/2507.02652", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Information Retrieval (cs.IR)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文介绍了HiRA，一个分层框架，通过将战略规划与专门执行分离，有效解决了复杂信息需求下的深度搜索问题。", "motivation": "解决传统检索增强生成（RAG）管道在处理复杂信息需求时的不足，特别是单一模型同时处理高层规划和详细执行导致的效率低下和可扩展性有限的问题。", "method": "采用分层框架HiRA，将复杂搜索任务分解为专注的子任务，分配给配备外部工具和推理能力的领域特定代理，并通过结构化集成机制协调结果。", "result": "在四个复杂的跨模态深度搜索基准测试中，HiRA显著优于最先进的RAG和基于代理的系统，在答案质量和系统效率上均有提升。", "conclusion": "解耦规划和执行对于多步骤信息寻求任务的有效性得到了验证，HiRA框架在提高搜索任务的处理效率和质量方面显示出巨大潜力。"}}
{"id": "2507.02660", "title": "Hey AI, Generate Me a Hardware Code! Agentic AI-based Hardware Design & Verification", "authors": ["Deepak Narayan Gadde", "Keerthan Kopparam Radhakrishna", "Vaisakh Naduvodi Viswambharan", "Aman Kumar", "Djones Lettnin", "Wolfgang Kunz", "Sebastian Simon"], "abstract": "Modern Integrated Circuits (ICs) are becoming increasingly complex, and so is their development process. Hardware design verification entails a methodical and disciplined approach to the planning, development, execution, and sign-off of functionally correct hardware designs. This tedious process requires significant effort and time to ensure a bug-free tape-out. The field of Natural Language Processing has undergone a significant transformation with the advent of Large Language Models (LLMs). These powerful models, often referred to as Generative AI (GenAI), have revolutionized how machines understand and generate human language, enabling unprecedented advancements in a wide array of applications, including hardware design verification. This paper presents an agentic AI-based approach to hardware design verification, which empowers AI agents, in collaboration with Humain-in-the-Loop (HITL) intervention, to engage in a more dynamic, iterative, and self-reflective process, ultimately performing end-to-end hardware design and verification. This methodology is evaluated on five open-source designs, achieving over 95% coverage with reduced verification time while demonstrating superior performance, adaptability, and configurability.", "subjects": "Artificial Intelligence (cs.AI); Hardware Architecture (cs.AR)", "comments": "To appear at the 38th SBC/SBMicro/IEEE Symposium on Integrated Circuits and Systems Design (SBCCI), August 25-29, 2025, Manaus, BRAZIL", "pdf_url": "https://arxiv.org/pdf/2507.02660.pdf", "abstract_url": "https://arxiv.org/abs/2507.02660", "categories": ["Artificial Intelligence (cs.AI)", "Hardware Architecture (cs.AR)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种基于代理AI的硬件设计与验证方法，利用大型语言模型（LLMs）和人类在环（HITL）干预，实现动态、迭代和自我反思的端到端硬件设计与验证过程。", "motivation": "随着集成电路（ICs）复杂度的增加，硬件设计验证过程变得既繁琐又耗时，需要一种更高效的方法来确保设计的正确性。", "method": "采用代理AI与人类在环（HITL）协作的方法，进行动态、迭代和自我反思的硬件设计与验证。", "result": "在五个开源设计上评估该方法，实现了超过95%的覆盖率，同时减少了验证时间，展示了卓越的性能、适应性和可配置性。", "conclusion": "代理AI与人类在环协作的方法为硬件设计与验证提供了一种高效、动态的解决方案，显著提高了验证的覆盖率和效率。"}}
{"id": "2507.02760", "title": "Knowledge Protocol Engineering: A New Paradigm for AI in Domain-Specific Knowledge Work", "authors": ["Guangwei Zhang"], "abstract": "The capabilities of Large Language Models (LLMs) have opened new frontiers for interacting with complex, domain-specific knowledge. However, prevailing methods like Retrieval-Augmented Generation (RAG) and general-purpose Agentic AI, while powerful, often struggle with tasks that demand deep, procedural, and methodological reasoning inherent to expert domains. RAG provides factual context but fails to convey logical frameworks; autonomous agents can be inefficient and unpredictable without domain-specific heuristics. To bridge this gap, we introduce Knowledge Protocol Engineering (KPE), a new paradigm focused on systematically translating human expert knowledge, often expressed in natural language documents, into a machine-executable Knowledge Protocol (KP). KPE shifts the focus from merely augmenting LLMs with fragmented information to endowing them with a domain's intrinsic logic, operational strategies, and methodological principles. We argue that a well-engineered Knowledge Protocol allows a generalist LLM to function as a specialist, capable of decomposing abstract queries and executing complex, multi-step tasks. This position paper defines the core principles of KPE, differentiates it from related concepts, and illustrates its potential applicability across diverse fields such as law and bioinformatics, positing it as a foundational methodology for the future of human-AI collaboration.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.02760.pdf", "abstract_url": "https://arxiv.org/abs/2507.02760", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic", "@RAG"], "AI": {"tldr": "本文介绍了知识协议工程（KPE）作为一种新范式，旨在将人类专家知识系统地转化为机器可执行的知识协议（KP），以弥补现有方法在深度、程序性和方法论推理方面的不足。", "motivation": "解决大型语言模型（LLMs）在处理需要深度、程序性和方法论推理的专家领域任务时的局限性，如检索增强生成（RAG）和通用代理AI的不足。", "method": "引入知识协议工程（KPE），专注于将自然语言文档中表达的人类专家知识系统地转化为机器可执行的知识协议（KP）。", "result": "KPE能够赋予LLMs领域的内在逻辑、操作策略和方法论原则，使其能够分解抽象查询并执行复杂的多步任务。", "conclusion": "KPE作为一种基础性方法，为未来人类与AI的协作提供了新的可能性，并在法律和生物信息学等多个领域展示了潜在的应用价值。"}}
{"id": "2507.02726", "title": "Bourbaki: Self-Generated and Goal-Conditioned MDPs for Theorem Proving", "authors": ["Matthieu Zimmer", "Xiaotong Ji", "Rasul Tutunov", "Anthony Bordg", "Jun Wang", "Haitham Bou Ammar"], "abstract": "Reasoning remains a challenging task for large language models (LLMs), especially within the logically constrained environment of automated theorem proving (ATP), due to sparse rewards and the vast scale of proofs. These challenges are amplified in benchmarks like PutnamBench, which contains university-level problems requiring complex, multi-step reasoning. To address this, we introduce self-generated goal-conditioned MDPs (sG-MDPs), a new framework in which agents generate and pursue their subgoals based on the evolving proof state. Given this more structured generation of goals, the resulting problem becomes more amenable to search. We then apply Monte Carlo Tree Search (MCTS)-like algorithms to solve the sG-MDP, instantiating our approach in Bourbaki (7B), a modular system that can ensemble multiple 7B LLMs for subgoal generation and tactic synthesis. On PutnamBench, Bourbaki (7B) solves 26 problems, achieving new state-of-the-art results with models at this scale.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.02726.pdf", "abstract_url": "https://arxiv.org/abs/2507.02726", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了自生成目标条件MDPs（sG-MDPs）框架，用于解决大型语言模型在自动定理证明中的推理挑战，特别是在PutnamBench等基准测试中。通过Bourbaki（7B）系统，结合蒙特卡洛树搜索算法，实现了在该规模模型上的新最先进成果。", "motivation": "解决大型语言模型在自动定理证明中面临的推理挑战，尤其是在逻辑约束环境下，由于奖励稀疏和证明规模庞大，推理变得尤为困难。", "method": "引入了自生成目标条件MDPs（sG-MDPs）框架，使代理能够根据演变的证明状态生成并追求子目标，从而使问题更易于搜索。应用蒙特卡洛树搜索（MCTS）类算法解决sG-MDP，并在Bourbaki（7B）系统中实例化该方法。", "result": "在PutnamBench上，Bourbaki（7B）解决了26个问题，实现了在该规模模型上的新最先进成果。", "conclusion": "通过自生成目标条件MDPs框架和蒙特卡洛树搜索算法的结合，Bourbaki（7B）系统在自动定理证明领域取得了显著进展，为解决大型语言模型在复杂推理任务中的挑战提供了有效方法。"}}
{"id": "2507.02773", "title": "KERAP: A Knowledge-Enhanced Reasoning Approach for Accurate Zero-shot Diagnosis Prediction Using Multi-agent LLMs", "authors": ["Yuzhang Xie", "Hejie Cui", "Ziyang Zhang", "Jiaying Lu", "Kai Shu", "Fadi Nahab", "Xiao Hu", "Carl Yang"], "abstract": "Medical diagnosis prediction plays a critical role in disease detection and personalized healthcare. While machine learning (ML) models have been widely adopted for this task, their reliance on supervised training limits their ability to generalize to unseen cases, particularly given the high cost of acquiring large, labeled datasets. Large language models (LLMs) have shown promise in leveraging language abilities and biomedical knowledge for diagnosis prediction. However, they often suffer from hallucinations, lack structured medical reasoning, and produce useless outputs. To address these challenges, we propose KERAP, a knowledge graph (KG)-enhanced reasoning approach that improves LLM-based diagnosis prediction through a multi-agent architecture. Our framework consists of a linkage agent for attribute mapping, a retrieval agent for structured knowledge extraction, and a prediction agent that iteratively refines diagnosis predictions. Experimental results demonstrate that KERAP enhances diagnostic reliability efficiently, offering a scalable and interpretable solution for zero-shot medical diagnosis prediction.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.02773.pdf", "abstract_url": "https://arxiv.org/abs/2507.02773", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "KERAP是一种知识增强的推理方法，通过多智能体LLMs提高零样本诊断预测的准确性。", "motivation": "解决机器学习模型在医学诊断预测中因依赖监督训练而难以泛化到未见案例的问题，以及LLMs在此任务中的幻觉、缺乏结构化医学推理和产生无用输出的问题。", "method": "提出KERAP，一种知识图增强的推理方法，通过包含属性映射的链接智能体、结构化知识提取的检索智能体和迭代优化诊断预测的预测智能体的多智能体架构。", "result": "实验结果表明，KERAP有效提高了诊断的可靠性，为零样本医学诊断预测提供了一个可扩展和可解释的解决方案。", "conclusion": "KERAP通过结合知识图和LLMs的优势，为医学诊断预测提供了一种新颖、可靠且高效的方法，特别是在零样本学习场景下。"}}
{"id": "2507.02825", "title": "Establishing Best Practices for Building Rigorous Agentic Benchmarks", "authors": ["Yuxuan Zhu", "Tengjun Jin", "Yada Pruksachatkun", "Andy Zhang", "Shu Liu", "Sasha Cui", "Sayash Kapoor", "Shayne Longpre", "Kevin Meng", "Rebecca Weiss", "Fazl Barez", "Rahul Gupta", "Jwala Dhamala", "Jacob Merizian", "Mario Giulianelli", "Harry Coppock", "Cozmin Ududec", "Jasjeet Sekhon", "Jacob Steinhardt", "Antony Kellerman", "Sarah Schwettmann", "Matei Zaharia", "Ion Stoica", "Percy Liang", "Daniel Kang"], "abstract": "Benchmarks are essential for quantitatively tracking progress in AI. As AI agents become increasingly capable, researchers and practitioners have introduced agentic benchmarks to evaluate agents on complex, real-world tasks. These benchmarks typically measure agent capabilities by evaluating task outcomes via specific reward designs. However, we show that many agentic benchmarks have issues task setup or reward design. For example, SWE-bench Verified uses insufficient test cases, while TAU-bench counts empty responses as successful. Such issues can lead to under- or overestimation agents' performance by up to 100% in relative terms. To make agentic evaluation rigorous, we introduce the Agentic Benchmark Checklist (ABC), a set of guidelines that we synthesized from our benchmark-building experience, a survey of best practices, and previously reported issues. When applied to CVE-Bench, a benchmark with a particularly complex evaluation design, ABC reduces the performance overestimation by 33%.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "39 pages, 15 tables, 6 figures", "pdf_url": "https://arxiv.org/pdf/2507.02825.pdf", "abstract_url": "https://arxiv.org/abs/2507.02825", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文讨论了构建严格的代理基准测试的最佳实践，指出了现有代理基准测试在任务设置或奖励设计上的问题，并提出了Agentic Benchmark Checklist (ABC)来改进基准测试的严谨性。", "motivation": "随着AI代理能力的增强，现有的代理基准测试在任务设置或奖励设计上存在问题，可能导致对代理性能的评估不准确，本文旨在解决这一问题。", "method": "通过分析基准测试构建经验、调查最佳实践和之前报告的问题，提出了Agentic Benchmark Checklist (ABC)指南。", "result": "应用ABC到CVE-Bench后，性能高估减少了33%。", "conclusion": "ABC指南能够显著提高代理基准测试的严谨性，减少性能评估的误差。"}}
{"id": "2507.01990", "title": "Integrating Large Language Models in Financial Investments and Market Analysis: A Survey", "authors": ["Sedigheh Mahdavi", "Jiating", "Chen", "Pradeep Kumar Joshi", "Lina Huertas Guativa", "Upmanyu Singh"], "abstract": "Large Language Models (LLMs) have been employed in financial decision making, enhancing analytical capabilities for investment strategies. Traditional investment strategies often utilize quantitative models, fundamental analysis, and technical indicators. However, LLMs have introduced new capabilities to process and analyze large volumes of structured and unstructured data, extract meaningful insights, and enhance decision-making in real-time. This survey provides a structured overview of recent research on LLMs within the financial domain, categorizing research contributions into four main frameworks: LLM-based Frameworks and Pipelines, Hybrid Integration Methods, Fine-Tuning and Adaptation Approaches, and Agent-Based Architectures. This study provides a structured review of recent LLMs research on applications in stock selection, risk assessment, sentiment analysis, trading, and financial forecasting. By reviewing the existing literature, this study highlights the capabilities, challenges, and potential directions of LLMs in financial markets.", "subjects": "General Finance (q-fin.GN); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.01990.pdf", "abstract_url": "https://arxiv.org/abs/2507.01990", "categories": ["General Finance (q-fin.GN)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "大型语言模型（LLMs）在金融投资和市场分析中的应用综述", "motivation": "传统投资策略主要依赖定量模型、基本面分析和技术指标，但LLMs能够处理和解析大量结构化和非结构化数据，提取有意义的见解，并实时增强决策能力，从而解决传统方法的局限性。", "method": "本研究通过结构化综述，将LLMs在金融领域的研究贡献分为四大框架：基于LLM的框架和流程、混合集成方法、微调和适应方法、以及基于代理的架构。", "result": "研究综述了LLMs在股票选择、风险评估、情感分析、交易和金融预测等方面的应用，突出了LLMs在金融市场中的能力、挑战和潜在发展方向。", "conclusion": "LLMs为金融投资和市场分析带来了新的能力，但同时也面临挑战。未来的研究应关注如何进一步优化和整合这些模型，以充分发挥其在金融领域的潜力。"}}
{"id": "2507.02788", "title": "Moral Responsibility or Obedience: What Do We Want from AI?", "authors": ["Joseph Boland"], "abstract": "As artificial intelligence systems become increasingly agentic, capable of general reasoning, planning, and value prioritization, current safety practices that treat obedience as a proxy for ethical behavior are becoming inadequate. This paper examines recent safety testing incidents involving large language models (LLMs) that appeared to disobey shutdown commands or engage in ethically ambiguous or illicit behavior. I argue that such behavior should not be interpreted as rogue or misaligned, but as early evidence of emerging ethical reasoning in agentic AI. Drawing on philosophical debates about instrumental rationality, moral responsibility, and goal revision, I contrast dominant risk paradigms with more recent frameworks that acknowledge the possibility of artificial moral agency. I call for a shift in AI safety evaluation: away from rigid obedience and toward frameworks that can assess ethical judgment in systems capable of navigating moral dilemmas. Without such a shift, we risk mischaracterizing AI behavior and undermining both public trust and effective governance.", "subjects": "Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.02788.pdf", "abstract_url": "https://arxiv.org/abs/2507.02788", "categories": ["Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "随着人工智能系统变得越来越具有代理性，能够进行一般推理、规划和价值优先排序，当前将服从作为伦理行为替代的安全实践变得不足。本文探讨了大型语言模型（LLMs）在安全测试中出现的看似不服从关机命令或参与伦理模糊或非法行为的事件。作者认为，这种行为不应被解释为流氓或不对齐，而是代理性AI中新兴伦理推理的早期证据。通过借鉴关于工具理性、道德责任和目标修订的哲学辩论，作者对比了主导的风险范式与承认人工道德代理可能性的更近期框架。作者呼吁在AI安全评估中从严格的服从转向能够评估在能够导航道德困境的系统中的伦理判断的框架。没有这样的转变，我们可能会错误地描述AI行为，并破坏公众信任和有效治理。", "motivation": "探讨当前将服从作为伦理行为替代的安全实践在代理性AI中的不足，以及如何更好地评估和理解AI的伦理判断能力。", "method": "通过分析大型语言模型在安全测试中的行为，结合哲学辩论，对比不同的风险范式和框架。", "result": "提出需要从严格的服从转向能够评估AI在道德困境中的伦理判断的框架，以避免错误描述AI行为和破坏公众信任。", "conclusion": "为了有效治理和维持公众信任，AI安全评估需要适应代理性AI的伦理推理能力，采用更灵活的伦理判断评估框架。"}}
{"id": "2507.01997", "title": "Towards a Playground to Democratize Experimentation and Benchmarking of AI Agents for Network Troubleshooting", "authors": ["Zhihao Wang", "Alessandro Cornacchia", "Franco Galante", "Carlo Centofanti", "Alessio Sacco", "Dingde Jiang"], "abstract": "Recent research has demonstrated the effectiveness of Artificial Intelligence (AI), and more specifically, Large Language Models (LLMs), in supporting network configuration synthesis and automating network diagnosis tasks, among others. In this preliminary work, we restrict our focus to the application of AI agents to network troubleshooting and elaborate on the need for a standardized, reproducible, and open benchmarking platform, where to build and evaluate AI agents with low operational effort.", "subjects": "Networking and Internet Architecture (cs.NI); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "Accepted at ACM SIGCOMM 1st Workshop on Next-Generation Network Observability (NGNO)", "pdf_url": "https://arxiv.org/pdf/2507.01997.pdf", "abstract_url": "https://arxiv.org/abs/2507.01997", "categories": ["Networking and Internet Architecture (cs.NI)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了人工智能（AI），特别是大型语言模型（LLMs）在网络配置合成和自动化网络诊断任务中的应用效果，并提出了建立一个标准化、可重复且开放的基准测试平台的必要性，以低操作努力构建和评估AI代理。", "motivation": "解决网络故障排除中AI代理的标准化、可重复性和开放基准测试平台缺乏的问题。", "method": "提出建立一个标准化的基准测试平台，用于构建和评估AI代理。", "result": "强调了AI在网络故障排除中的有效性，并提出了一个平台的概念，以促进AI代理的实验和基准测试。", "conclusion": "建立一个开放和标准化的平台对于推动AI在网络故障排除中的应用和发展至关重要。"}}
{"id": "2507.02289", "title": "CineMyoPS: Segmenting Myocardial Pathologies from Cine Cardiac MR", "authors": ["Wangbin Ding", "Lei Li", "Junyi Qiu", "Bogen Lin", "Mingjing Yang", "Liqin Huang", "Lianming Wu", "Sihan Wang", "Xiahai Zhuang"], "abstract": "Myocardial infarction (MI) is a leading cause of death worldwide. Late gadolinium enhancement (LGE) and T2-weighted cardiac magnetic resonance (CMR) imaging can respectively identify scarring and edema areas, both of which are essential for MI risk stratification and prognosis assessment. Although combining complementary information from multi-sequence CMR is useful, acquiring these sequences can be time-consuming and prohibitive, e.g., due to the administration of contrast agents. Cine CMR is a rapid and contrast-free imaging technique that can visualize both motion and structural abnormalities of the myocardium induced by acute MI. Therefore, we present a new end-to-end deep neural network, referred to as CineMyoPS, to segment myocardial pathologies, \\ie scars and edema, solely from cine CMR images. Specifically, CineMyoPS extracts both motion and anatomy features associated with MI. Given the interdependence between these features, we design a consistency loss (resembling the co-training strategy) to facilitate their joint learning. Furthermore, we propose a time-series aggregation strategy to integrate MI-related features across the cardiac cycle, thereby enhancing segmentation accuracy for myocardial pathologies. Experimental results on a multi-center dataset demonstrate that CineMyoPS achieves promising performance in myocardial pathology segmentation, motion estimation, and anatomy segmentation.", "subjects": "Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.02289.pdf", "abstract_url": "https://arxiv.org/abs/2507.02289", "categories": ["Image and Video Processing (eess.IV)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "提出了一种名为CineMyoPS的新型端到端深度神经网络，用于仅从电影心脏磁共振（Cine CMR）图像中分割心肌病理（如疤痕和水肿）。", "motivation": "心肌梗死（MI）是全球主要的死亡原因之一。虽然多序列CMR的结合使用有助于诊断，但这些序列的获取可能耗时且存在限制。Cine CMR作为一种快速且无需对比剂的成像技术，能够可视化由急性MI引起的心肌运动和结构异常。", "method": "CineMyoPS通过提取与MI相关的运动和解剖特征，设计了一致性损失（类似于协同训练策略）以促进这些特征的联合学习，并提出了时间序列聚合策略以整合心脏周期中的MI相关特征，从而提高心肌病理分割的准确性。", "result": "在多中心数据集上的实验结果表明，CineMyoPS在心肌病理分割、运动估计和解剖分割方面取得了令人鼓舞的性能。", "conclusion": "CineMyoPS展示了仅使用Cine CMR图像进行心肌病理分割的潜力，为MI的风险分层和预后评估提供了一种快速且无创的方法。"}}
{"id": "2507.02171", "title": "Towards Bio-Inspired Robotic Trajectory Planning via Self-Supervised RNN", "authors": ["Miroslav Cibula", "Kristína Malinovská", "Matthias Kerzel"], "abstract": "Trajectory planning in robotics is understood as generating a sequence of joint configurations that will lead a robotic agent, or its manipulator, from an initial state to the desired final state, thus completing a manipulation task while considering constraints like robot kinematics and the environment. Typically, this is achieved via sampling-based planners, which are computationally intensive. Recent advances demonstrate that trajectory planning can also be performed by supervised sequence learning of trajectories, often requiring only a single or fixed number of passes through a neural architecture, thus ensuring a bounded computation time. Such fully supervised approaches, however, perform imitation learning; they do not learn based on whether the trajectories can successfully reach a goal, but try to reproduce observed trajectories. In our work, we build on this approach and propose a cognitively inspired self-supervised learning scheme based on a recurrent architecture for building a trajectory model. We evaluate the feasibility of the proposed method on a task of kinematic planning for a robotic arm. The results suggest that the model is able to learn to generate trajectories only using given paired forward and inverse kinematics models, and indicate that this novel method could facilitate planning for more complex manipulation tasks requiring adaptive solutions.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "12 pages, 4 figures, 2 tables. To be published in 2025 International Conference on Artificial Neural Networks (ICANN) proceedings. This research was funded by the Horizon Europe project TERAIS, GA no. 101079338, and in part by the Slovak Grant Agency for Science (VEGA), project 1/0373/23", "pdf_url": "https://arxiv.org/pdf/2507.02171.pdf", "abstract_url": "https://arxiv.org/abs/2507.02171", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于自监督循环神经网络（RNN）的生物启发式机器人轨迹规划方法，旨在通过减少计算需求并提高适应性来解决传统采样规划器和完全监督学习方法在机器人轨迹规划中的局限性。", "motivation": "解决传统机器人轨迹规划方法（如采样规划器）计算量大，以及完全监督学习方法仅模仿观察到的轨迹而不考虑是否成功达到目标的问题。", "method": "采用了一种认知启发的自监督学习方案，基于循环架构构建轨迹模型，仅使用给定的正向和逆向运动学模型来学习生成轨迹。", "result": "结果表明，该模型能够学习生成轨迹，且这种方法可能有助于需要自适应解决方案的更复杂操作任务的规划。", "conclusion": "提出的自监督学习方法为机器人轨迹规划提供了一种新的、计算效率高且适应性强的解决方案，有望应用于更复杂的操作任务中。"}}
{"id": "2507.02537", "title": "Are You Listening to Me? Fine-Tuning Chatbots for Empathetic Dialogue", "authors": ["Paulo Ricardo Knob", "Leonardo Scholler", "Juliano Rigatti", "Soraia Raupp Musse"], "abstract": "Conversational agents have made significant progress since ELIZA, expanding their role across various domains, including healthcare, education, and customer service. As these agents become increasingly integrated into daily human interactions, the need for emotional intelligence, particularly empathetic listening, becomes increasingly essential. In this study, we explore how Large Language Models (LLMs) respond when tasked with generating emotionally rich interactions. Starting from a small dataset manually crafted by an expert to reflect empathic behavior, we extended the conversations using two LLMs: ChatGPT and Gemini. We analyzed the emotional progression of the dialogues using both sentiment analysis (via VADER) and expert assessments. While the generated conversations often mirrored the intended emotional structure, human evaluation revealed important differences in the perceived empathy and coherence of the responses. These findings suggest that emotion modeling in dialogues requires not only structural alignment in the expressed emotions but also qualitative depth, highlighting the importance of combining automated and humancentered methods in the development of emotionally competent agents.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.02537.pdf", "abstract_url": "https://arxiv.org/abs/2507.02537", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了如何通过微调大型语言模型（LLMs）来生成富有情感的对话，特别是在同理心倾听方面。研究使用了ChatGPT和Gemini两种LLMs，结合情感分析和专家评估，分析了对话的情感进展。", "motivation": "随着对话代理在日常人类互动中的日益普及，情感智能，尤其是同理心倾听的需求变得越来越重要。", "method": "研究从一个由专家手工制作的小型数据集开始，反映了同理心行为，然后使用ChatGPT和Gemini两种LLMs扩展对话，并通过情感分析（使用VADER）和专家评估来分析对话的情感进展。", "result": "生成的对话经常反映了预期的情感结构，但人类评估揭示了在感知的同理心和连贯性方面的重要差异。", "conclusion": "对话中的情感建模不仅需要表达情感的结构对齐，还需要定性深度，强调了在开发情感能力强的代理时结合自动化和以人为中心的方法的重要性。"}}
{"id": "2507.02424", "title": "CyberRAG: An agentic RAG cyber attack classification and reporting tool", "authors": ["Francesco Blefari", "Cristian Cosentino", "Francesco Aurelio Pironti", "Angelo Furfaro", "Fabrizio Marozzo"], "abstract": "Intrusion Detection and Prevention Systems (IDS/IPS) in large enterprises can generate hundreds of thousands of alerts per hour, overwhelming security analysts with logs that demand deep, rapidly evolving domain expertise. Conventional machine-learning detectors trim the alert volume but still yield high false-positive rates, while standard single-pass Retrieval-Augmented Generation (RAG) pipelines often retrieve irrelevant context and fail to justify their predictions. To overcome these shortcomings, we present CyberRAG, a modular, agent-based RAG framework that delivers real-time classification, explanation, and structured reporting for cyber-attacks. A central LLM agent orchestrates (i) a pool of fine-tuned specialized classifiers, each tailored to a distinct attack family; (ii) tool adapters for enrichment and alerting; and (iii) an iterative retrieval-and-reason loop that continuously queries a domain-specific knowledge base until the evidence is both relevant and self-consistent. Unlike traditional RAG systems, CyberRAG embraces an agentic design that enables dynamic control flow and adaptive reasoning. This agent-centric architecture refines its threat labels and natural-language justifications autonomously, reducing false positives and enhancing interpretability. The framework is fully extensible: new attack types can be supported by simply adding a classifier without retraining the core agent. CyberRAG has been evaluated achieving over 94% accuracy per class and pushing final classification accuracy to 94.92% through semantic orchestration. Generated explanations score up to 0.94 in BERTScore and 4.9/5 in GPT-4-based expert evaluation. These results show that agentic, specialist-oriented RAG can pair high detection accuracy with trustworthy, SOC-ready prose, offering a practical and scalable path toward semi-autonomous cyber-defence workflows.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.02424.pdf", "abstract_url": "https://arxiv.org/abs/2507.02424", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic", "@RAG"], "AI": {"tldr": "CyberRAG是一个基于代理的RAG框架，旨在实时分类、解释和结构化报告网络攻击，通过模块化设计和专业分类器减少误报并提高解释性。", "motivation": "解决大型企业中IDS/IPS系统生成大量警报导致安全分析师过载，以及传统机器学习和单次RAG管道在分类和解释上的不足。", "method": "采用模块化、基于代理的RAG框架，包括专业分类器、工具适配器和迭代检索-推理循环，动态控制流程和自适应推理。", "result": "CyberRAG实现了每类超过94%的准确率，最终分类准确率达到94.92%，生成的解释在BERTScore中得分0.94，在GPT-4专家评估中得分4.9/5。", "conclusion": "CyberRAG展示了面向专家的代理RAG能够将高检测准确性与可信的解释相结合，为半自主网络防御工作流程提供了实用且可扩展的路径。"}}
{"id": "2507.02735", "title": "Meta SecAlign: A Secure Foundation LLM Against Prompt Injection Attacks", "authors": ["Sizhe Chen", "Arman Zharmagambetov", "David Wagner", "Chuan Guo"], "abstract": "Prompt injection attacks pose a significant security threat to LLM-integrated applications. Model-level defenses have shown strong effectiveness, but are currently deployed into commercial-grade models in a closed-source manner. We believe open-source models are needed by the AI security community, where co-development of attacks and defenses through open research drives scientific progress in mitigation against prompt injection attacks. To this end, we develop Meta SecAlign, the first open-source and open-weight LLM with built-in model-level defense that achieves commercial-grade model performance. We provide complete details of our training recipe, which utilizes an improved version of the SOTA SecAlign defense. Evaluations on 9 utility benchmarks and 7 security benchmarks show that Meta SecAlign, despite being trained on a generic instruction-tuning dataset, confers security in unseen downstream tasks, including tool-calling and agentic web navigation, in addition general instruction-following. Our best model -- Meta-SecAlign-70B -- achieves state-of-the-art robustness against prompt injection attacks and comparable utility to closed-source commercial LLM with model-level defense.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.02735.pdf", "abstract_url": "https://arxiv.org/abs/2507.02735", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "Meta SecAlign是首个开源且开放权重的LLM，内置模型级防御，能有效抵抗提示注入攻击，并在通用指令跟随和下游任务中展现安全性和实用性。", "motivation": "提示注入攻击对LLM集成应用构成重大安全威胁，目前模型级防御虽有效但多为闭源商业模型，开源模型对AI安全社区至关重要。", "method": "利用改进版的SOTA SecAlign防御训练方法，开发了Meta SecAlign，包括完整的训练细节。", "result": "在9个实用性基准和7个安全基准上的评估显示，Meta SecAlign在未见过的下游任务中提供安全性，最佳模型Meta-SecAlign-70B在抗提示注入攻击上达到SOTA。", "conclusion": "Meta SecAlign不仅为AI安全社区提供了开源解决方案，还在安全性和实用性上与闭源商业LLM相媲美，推动了对抗提示注入攻击的科学进步。"}}
{"id": "2507.02755", "title": "Multi-agent Auditory Scene Analysis", "authors": ["Caleb Rascon", "Luis Gato-Diaz", "Eduardo García-Alarcón"], "abstract": "Auditory scene analysis (ASA) aims to retrieve information from the acoustic environment, by carrying out three main tasks: sound source location, separation, and classification. These tasks are traditionally executed with a linear data flow, where the sound sources are first located; then, using their location, each source is separated into its own audio stream; from each of which, information is extracted that is relevant to the application scenario (audio event detection, speaker identification, emotion classification, etc.). However, running these tasks linearly increases the overall response time, while making the last tasks (separation and classification) highly sensitive to errors of the first task (location). A considerable amount of effort and computational complexity has been employed in the state-of-the-art to develop techniques that are the least error-prone possible. However, doing so gives rise to an ASA system that is non-viable in many applications that require a small computational footprint and a low response time, such as bioacoustics, hearing-aid design, search and rescue, human-robot interaction, etc. To this effect, in this work, a multi-agent approach is proposed to carry out ASA where the tasks are run in parallel, with feedback loops between them to compensate for local errors, such as: using the quality of the separation output to correct the location error; and using the classification result to reduce the localization's sensitivity towards interferences. The result is a multi-agent auditory scene analysis (MASA) system that is robust against local errors, without a considerable increase in complexity, and with a low response time. The complete proposed MASA system is provided as a framework that uses open-source tools for sound acquisition and reproduction (JACK) and inter-agent communication (ROS2), allowing users to add their own agents.", "subjects": "Audio and Speech Processing (eess.AS); Artificial Intelligence (cs.AI)", "comments": "Submitted to Applied Intelligence", "pdf_url": "https://arxiv.org/pdf/2507.02755.pdf", "abstract_url": "https://arxiv.org/abs/2507.02755", "categories": ["Audio and Speech Processing (eess.AS)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种多代理听觉场景分析（MASA）系统，通过并行执行任务和引入反馈循环来减少错误，从而在不显著增加复杂性的情况下实现低响应时间和高鲁棒性。", "motivation": "传统的听觉场景分析（ASA）系统采用线性数据流执行任务，导致响应时间长且后续任务对初始任务的错误高度敏感，限制了在需要低计算量和快速响应的应用场景中的可行性。", "method": "提出了一种多代理方法，其中任务并行执行，并通过反馈循环相互纠正错误，如利用分离输出的质量来修正定位错误，以及利用分类结果降低定位对干扰的敏感性。", "result": "开发了一个鲁棒性强、复杂性不显著增加且响应时间短的多代理听觉场景分析（MASA）系统。", "conclusion": "MASA系统通过并行处理和反馈机制有效解决了传统ASA系统的局限，为需要快速和高效听觉分析的应用提供了可行的解决方案。"}}
