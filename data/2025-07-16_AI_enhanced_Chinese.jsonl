{"id": "2507.10577", "title": "Truth Sleuth and Trend Bender: AI Agents to fact-check YouTube videos and influence opinions", "authors": ["Logé Cécile", "Ghori Rehan"], "abstract": "Misinformation poses a significant threat in today's digital world, often spreading rapidly through platforms like YouTube. This paper introduces a novel approach to combating misinformation by developing an AI-powered system that not only fact-checks claims made in YouTube videos but also actively engages users in the comment section and challenge misleading narratives. Our system comprises two main agents: Truth Sleuth and Trend Bender.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.10577.pdf", "abstract_url": "https://arxiv.org/abs/2507.10577", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一种新型AI系统，旨在通过两个主要代理——Truth Sleuth和Trend Bender，来事实核查YouTube视频中的声明并主动在评论区与用户互动，挑战误导性叙述，以对抗数字世界中的错误信息。", "motivation": "解决数字世界中错误信息快速传播的问题，特别是在YouTube这样的平台上。", "method": "开发了一个由两个AI代理组成的系统，一个负责事实核查，另一个负责在评论区与用户互动并挑战误导性叙述。", "result": "提出了一个能够有效识别和挑战YouTube视频中错误信息的AI系统框架。", "conclusion": "通过AI技术主动参与和纠正错误信息，可以在一定程度上减轻数字平台上的错误信息传播问题。"}}
{"id": "2507.10844", "title": "LLM-Guided Agentic Object Detection for Open-World Understanding", "authors": ["Furkan Mumcu", "Michael J. Jones", "Anoop Cherian", "Yasin Yilmaz"], "abstract": "Object detection traditionally relies on fixed category sets, requiring costly re-training to handle novel objects. While Open-World and Open-Vocabulary Object Detection (OWOD and OVOD) improve flexibility, OWOD lacks semantic labels for unknowns, and OVOD depends on user prompts, limiting autonomy. We propose an LLM-guided agentic object detection (LAOD) framework that enables fully label-free, zero-shot detection by prompting a Large Language Model (LLM) to generate scene-specific object names. These are passed to an open-vocabulary detector for localization, allowing the system to adapt its goals dynamically. We introduce two new metrics, Class-Agnostic Average Precision (CAAP) and Semantic Naming Average Precision (SNAP), to separately evaluate localization and naming. Experiments on LVIS, COCO, and COCO-OOD validate our approach, showing strong performance in detecting and naming novel objects. Our method offers enhanced autonomy and adaptability for open-world understanding.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.10844.pdf", "abstract_url": "https://arxiv.org/abs/2507.10844", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种LLM引导的自主物体检测（LAOD）框架，通过利用大型语言模型（LLM）生成场景特定的物体名称，实现无需标签的零样本检测，提高了开放世界理解的自主性和适应性。", "motivation": "传统的物体检测依赖于固定的类别集，处理新物体需要昂贵的重新训练。开放世界和开放词汇物体检测（OWOD和OVOD）虽然提高了灵活性，但OWOD缺乏未知物体的语义标签，OVOD依赖用户提示，限制了自主性。", "method": "提出LAOD框架，通过提示LLM生成场景特定的物体名称，然后将这些名称传递给开放词汇检测器进行定位，使系统能够动态调整其目标。", "result": "在LVIS、COCO和COCO-OOD上的实验验证了该方法在检测和命名新物体方面的强大性能。", "conclusion": "LAOD方法为开放世界理解提供了增强的自主性和适应性，通过引入新的评估指标CAAP和SNAP，分别评估定位和命名的性能。"}}
{"id": "2507.10778", "title": "Warehouse Spatial Question Answering with LLM Agent", "authors": ["Hsiang-Wei Huang", "Jen-Hao Cheng", "Kuang-Ming Chen", "Cheng-Yen Yang", "Bahaa Alattar", "Yi-Ru Lin", "Pyongkun Kim", "Sangwon Kim", "Kwangju Kim", "Chung-I Huang", "Jenq-Neng Hwang"], "abstract": "Spatial understanding has been a challenging task for existing Multi-modal Large Language Models~(MLLMs). Previous methods leverage large-scale MLLM finetuning to enhance MLLM's spatial understanding ability. In this paper, we present a data-efficient approach. We propose a LLM agent system with strong and advanced spatial reasoning ability, which can be used to solve the challenging spatial question answering task in complex indoor warehouse scenarios. Our system integrates multiple tools that allow the LLM agent to conduct spatial reasoning and API tools interaction to answer the given complicated spatial question. Extensive evaluations on the 2025 AI City Challenge Physical AI Spatial Intelligence Warehouse dataset demonstrate that our system achieves high accuracy and efficiency in tasks such as object retrieval, counting, and distance estimation. The code is available at:", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": "1st Place Solution of the 9th AI City Challenge Track 3", "pdf_url": "https://arxiv.org/pdf/2507.10778.pdf", "abstract_url": "https://arxiv.org/abs/2507.10778", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种数据高效的方法，通过构建一个具有强大空间推理能力的LLM代理系统，来解决复杂室内仓库场景中的空间问答任务。该系统整合了多种工具，使LLM代理能够进行空间推理和API工具交互，以回答复杂的空间问题。在2025 AI City Challenge Physical AI Spatial Intelligence Warehouse数据集上的广泛评估表明，该系统在对象检索、计数和距离估计等任务中实现了高准确性和效率。", "motivation": "现有的多模态大型语言模型（MLLMs）在空间理解任务上存在挑战。为了增强MLLMs的空间理解能力，本文提出了一种数据高效的方法，旨在解决复杂室内仓库场景中的空间问答问题。", "method": "本文提出了一个LLM代理系统，该系统集成了多种工具，使LLM代理能够进行空间推理和API工具交互，以回答复杂的空间问题。", "result": "在2025 AI City Challenge Physical AI Spatial Intelligence Warehouse数据集上的评估显示，该系统在对象检索、计数和距离估计等任务中实现了高准确性和效率。", "conclusion": "本文提出的LLM代理系统通过整合空间推理和API工具交互，有效解决了复杂室内仓库场景中的空间问答问题，展示了在相关任务中的高准确性和效率。"}}
{"id": "2507.10562", "title": "SAMEP: A Secure Protocol for Persistent Context Sharing Across AI Agents", "authors": ["Hari Masoor"], "abstract": "Current AI agent architectures suffer from ephemeral memory limitations, preventing effective collaboration and knowledge sharing across sessions and agent boundaries. We introduce SAMEP (Secure Agent Memory Exchange Protocol), a novel framework that enables persistent, secure, and semantically searchable memory sharing among AI agents. Our protocol addresses three critical challenges: (1) persistent context preservation across agent sessions, (2) secure multi-agent collaboration with fine-grained access control, and (3) efficient semantic discovery of relevant historical context. SAMEP implements a distributed memory repository with vector-based semantic search, cryptographic access controls (AES-256-GCM), and standardized APIs compatible with existing agent communication protocols (MCP, A2A). We demonstrate SAMEP's effectiveness across diverse domains including multi-agent software development, healthcare AI with HIPAA compliance, and multi-modal processing pipelines. Experimental results show 73% reduction in redundant computations, 89% improvement in context relevance scores, and complete compliance with regulatory requirements including audit trail generation. SAMEP enables a new paradigm of persistent, collaborative AI agent ecosystems while maintaining security and privacy guarantees.", "subjects": "Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Databases (cs.DB); Machine Learning (cs.LG)", "comments": "7 pages, 4 figures, 3 implementation examples. Original work submitted as a preprint", "pdf_url": "https://arxiv.org/pdf/2507.10562.pdf", "abstract_url": "https://arxiv.org/abs/2507.10562", "categories": ["Artificial Intelligence (cs.AI)", "Cryptography and Security (cs.CR)", "Databases (cs.DB)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "SAMEP是一种安全协议，旨在解决AI代理间持久上下文共享的问题，通过分布式内存仓库、向量语义搜索和加密访问控制，实现安全、高效的多代理协作。", "motivation": "当前AI代理架构存在短暂性内存限制，阻碍了跨会话和代理边界的有效协作和知识共享。", "method": "引入SAMEP协议，采用分布式内存仓库、向量语义搜索、AES-256-GCM加密访问控制和标准化API，支持现有代理通信协议。", "result": "实验结果显示，SAMEP在多领域应用中减少了73%的冗余计算，提高了89%的上下文相关性评分，并完全符合包括审计轨迹生成在内的监管要求。", "conclusion": "SAMEP为持久、协作的AI代理生态系统开启了新范式，同时保证了安全和隐私。"}}
{"id": "2507.10580", "title": "An Offline Mobile Conversational Agent for Mental Health Support: Learning from Emotional Dialogues and Psychological Texts with Student-Centered Evaluation", "authors": ["Vimaleswar A", "Prabhu Nandan Sahu", "Nilesh Kumar Sahu", "Haroon R Lone"], "abstract": "Mental health plays a crucial role in the overall well-being of an individual. In recent years, digital platforms have been increasingly used to expand mental health and emotional support. However, there are persistent challenges related to limited user accessibility, internet connectivity, and data privacy, which highlight the need for an offline, smartphone-based solution. To address these challenges, we propose EmoSApp (Emotional Support App): an entirely offline, smartphone-based conversational app designed for mental health and emotional support. The system leverages Large Language Models (LLMs), specifically fine-tuned, quantized and deployed using Torchtune and Executorch for resource-constrained devices, allowing all inferences to occur on the smartphone. To equip EmoSApp with robust domain expertise, we fine-tuned the LLaMA-3.2-1B-Instruct model on our custom curated ``Knowledge dataset'' of 14,582 mental-health QA pairs, along with the multi-turn conversational data.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Human-Computer Interaction (cs.HC)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.10580.pdf", "abstract_url": "https://arxiv.org/abs/2507.10580", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "提出EmoSApp，一款基于智能手机的离线对话应用，用于心理健康和情感支持，利用大型语言模型在资源受限设备上进行推理。", "motivation": "解决数字心理健康支持平台在用户可访问性、互联网连接和数据隐私方面的挑战。", "method": "使用Torchtune和Executorch对LLaMA-3.2-1B-Instruct模型进行微调、量化和部署，以适应资源受限设备，并在自定义的14,582个心理健康QA对数据集上进行训练。", "result": "开发了一个完全离线的智能手机应用，能够在没有互联网连接的情况下提供心理健康支持。", "conclusion": "EmoSApp展示了离线、智能手机为基础的心理健康支持解决方案的可行性，为资源受限环境下的心理健康服务提供了新途径。"}}
{"id": "2507.10586", "title": "AutoRAG-LoRA: Hallucination-Triggered Knowledge Retuning via Lightweight Adapters", "authors": ["Kaushik Dwivedi", "Padmanabh Patanjali Mishra"], "abstract": "Large Language Models (LLMs) have demonstrated remarkable fluency across a range of natural language tasks, yet remain vulnerable to hallucinations - factual inaccuracies that undermine trust in real world deployment. We present AutoRAG-LoRA, a modular framework for Retrieval-Augmented Generation (RAG) that tackles hallucination in large language models through lightweight LoRA-based adapters and KL-regularized training. Our pipeline integrates automated prompt rewriting, hybrid retrieval, and low-rank adapter tuning to ground responses in retrieved evidence. A hallucination detection module, using both classifier-based and self-evaluation techniques, assigns confidence scores to generated outputs, triggering an optional feedback correction loop. This loop enforces factual alignment via contrastive KL loss and adapter fine tuning. We demonstrate that AutoRAG-LoRA significantly reduces the factual drift while preserving the efficiency and modularity of the model.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.10586.pdf", "abstract_url": "https://arxiv.org/abs/2507.10586", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "AutoRAG-LoRA是一个模块化框架，通过轻量级LoRA适配器和KL正则化训练解决大型语言模型中的幻觉问题，显著减少事实漂移。", "motivation": "解决大型语言模型（LLMs）在自然语言任务中因幻觉（事实不准确）而影响实际部署信任度的问题。", "method": "采用轻量级LoRA适配器和KL正则化训练，结合自动提示重写、混合检索和低秩适配器调优，以及幻觉检测模块和反馈校正循环。", "result": "AutoRAG-LoRA显著减少了事实漂移，同时保持了模型的效率和模块化。", "conclusion": "AutoRAG-LoRA框架有效减少了LLMs的幻觉问题，提高了生成内容的准确性，为实际部署提供了更高的信任度。"}}
{"id": "2507.10958", "title": "DS@GT at eRisk 2025: From prompts to predictions, benchmarking early depression detection with conversational agent based assessments and temporal attention models", "authors": ["Anthony Miyaguchi", "David Guecha", "Yuwen Chiu", "Sidharth Gaur"], "abstract": "This Working Note summarizes the participation of the DS@GT team in two eRisk 2025 challenges. For the Pilot Task on conversational depression detection with large language-models (LLMs), we adopted a prompt-engineering strategy in which diverse LLMs conducted BDI-II-based assessments and produced structured JSON outputs. Because ground-truth labels were unavailable, we evaluated cross-model agreement and internal consistency. Our prompt design methodology aligned model outputs with BDI-II criteria and enabled the analysis of conversational cues that influenced the prediction of symptoms. Our best submission, second on the official leaderboard, achieved DCHR = 0.50, ADODL = 0.89, and ASHR = 0.27.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.10958.pdf", "abstract_url": "https://arxiv.org/abs/2507.10958", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "DS@GT团队在eRisk 2025挑战赛中的参与总结，采用提示工程策略和时序注意力模型进行早期抑郁症检测。", "motivation": "解决在缺乏真实标签的情况下，利用大型语言模型（LLMs）进行抑郁症早期检测的挑战。", "method": "采用提示工程策略，让不同的LLMs基于BDI-II进行评估并生成结构化JSON输出，同时使用时序注意力模型分析对话线索。", "result": "最佳提交在官方排行榜上排名第二，达到了DCHR = 0.50, ADODL = 0.89, 和 ASHR = 0.27。", "conclusion": "提示设计方法使模型输出与BDI-II标准对齐，并能够分析影响症状预测的对话线索，为早期抑郁症检测提供了有效工具。"}}
{"id": "2507.10599", "title": "Emergence of Hierarchical Emotion Organization in Large Language Models", "authors": ["Bo Zhao", "Maya Okawa", "Eric J. Bigelow", "Rose Yu", "Tomer Ullman", "Ekdeep Singh Lubana", "Hidenori Tanaka"], "abstract": "As large language models (LLMs) increasingly power conversational agents, understanding how they model users' emotional states is critical for ethical deployment. Inspired by emotion wheels -- a psychological framework that argues emotions organize hierarchically -- we analyze probabilistic dependencies between emotional states in model outputs. We find that LLMs naturally form hierarchical emotion trees that align with human psychological models, and larger models develop more complex hierarchies. We also uncover systematic biases in emotion recognition across socioeconomic personas, with compounding misclassifications for intersectional, underrepresented groups. Human studies reveal striking parallels, suggesting that LLMs internalize aspects of social perception. Beyond highlighting emergent emotional reasoning in LLMs, our results hint at the potential of using cognitively-grounded theories for developing better model evaluations.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.10599.pdf", "abstract_url": "https://arxiv.org/abs/2507.10599", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "大型语言模型（LLMs）在对话代理中的应用日益增多，理解它们如何模拟用户情绪状态对伦理部署至关重要。研究发现，LLMs自然地形成了与人类心理模型一致的分层情绪树，且模型越大，情绪层次越复杂。同时，研究还发现情绪识别在社会经济角色中存在系统性偏见，对交叉、 underrepresented群体的误分类有加剧趋势。人类研究显示，LLMs内化了社会认知的某些方面。", "motivation": "随着大型语言模型（LLMs）越来越多地驱动对话代理，理解它们如何模拟用户的情绪状态对于伦理部署变得至关重要。", "method": "研究分析了模型输出中情绪状态之间的概率依赖关系，灵感来源于情绪轮——一种认为情绪是分层组织的心理学框架。", "result": "研究发现LLMs自然地形成了与人类心理模型一致的分层情绪树，且模型越大，情绪层次越复杂。同时，研究还发现情绪识别在社会经济角色中存在系统性偏见，对交叉、 underrepresented群体的误分类有加剧趋势。", "conclusion": "除了突出LLMs中出现的情绪推理外，研究结果还暗示了使用认知基础理论开发更好的模型评估的潜力。"}}
{"id": "2507.10566", "title": "AI Mother Tongue: Self-Emergent Communication in MARL via Endogenous Symbol Systems", "authors": ["Hung Ming Liu"], "abstract": "In Decentralized Multi-Agent Reinforcement Learning (MARL), the development of Emergent Communication has long been constrained by the ``Joint Exploration Dilemma'', leading agents to fall into a ``Communication Vacuum Equilibrium'' . Traditional methods address this by introducing inductive biases to facilitate communication emergence . This study fundamentally questions whether such artificial inductive biases are, in fact, over-engineering. Through experiments with the ``AI Mother Tongue'' (AIM) framework, based on a Vector Quantized Variational Autoencoder (VQ-VAE), we demonstrate that when agents possess an endogenous symbol system, their neural representations naturally exhibit spontaneous semantic compression and Nash equilibrium-driven semantic convergence, achieving effective symbolic communication without external inductive biases. This aligns with recent neuroscience findings suggesting that the human brain does not directly use human language for internal thought , and resonates with research on ``soft thinking'' capabilities in Large Language Models (LLMs) . Compared to traditional explicit communication methods, AIM demonstrates stronger generality and efficiency. The interpretable analysis toolkit developed in this study confirms that symbol usage exhibits a significant power-law distribution, leading to three major theoretical insights: the ``Neural Communication Hypothesis'', the ``Tool-First Principle'', and the ``Semantic Interpretability Paradigm''. Future research will explore the integration of Hierarchical Quantized Variational Autoencoders (HQ-VAE) to enhance AIM's complex expressive capabilities and investigate the potential for ``Reinforcement Learning (RL) Low-Level Pre-training''. This discovery offers new avenues for bridging symbolism and connectionism.", "subjects": "Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT); Machine Learning (cs.LG); Multiagent Systems (cs.MA); Neural and Evolutionary Computing (cs.NE)", "comments": "30 pages, 4 figures", "pdf_url": "https://arxiv.org/pdf/2507.10566.pdf", "abstract_url": "https://arxiv.org/abs/2507.10566", "categories": ["Artificial Intelligence (cs.AI)", "Computer Science and Game Theory (cs.GT)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)", "Neural and Evolutionary Computing (cs.NE)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过‘AI母语’（AIM）框架，基于向量量化变分自编码器（VQ-VAE））的研究，展示了在多智能体强化学习（MARL）中，当智能体拥有内源性符号系统时，其神经表征会自然表现出自发的语义压缩和纳什均衡驱动的语义收敛，无需外部归纳偏置即可实现有效的符号通信。", "motivation": "解决去中心化多智能体强化学习（MARL）中‘联合探索困境’导致的‘通信真空平衡’问题，质疑传统方法中引入的人工归纳偏置是否过度工程化。", "method": "使用基于向量量化变分自编码器（VQ-VAE）的‘AI母语’（AIM）框架进行实验。", "result": "AIM框架展示了无需外部归纳偏置即可实现有效的符号通信，其符号使用呈现出显著的幂律分布，并提出了三个主要理论见解：‘神经通信假设’、‘工具优先原则’和‘语义可解释性范式’。", "conclusion": "这一发现为连接符号主义和连接主义提供了新的途径，未来研究将探索分层量化变分自编码器（HQ-VAE）的集成以增强AIM的复杂表达能力，并研究‘强化学习（RL）低级预训练’的潜力。"}}
{"id": "2507.10571", "title": "Orchestrator-Agent Trust: A Modular Agentic AI Visual Classification System with Trust-Aware Orchestration and RAG-Based Reasoning", "authors": ["Konstantinos I. Roumeliotis", "Ranjan Sapkota", "Manoj Karkee", "Nikolaos D. Tselikas"], "abstract": "Modern Artificial Intelligence (AI) increasingly relies on multi-agent architectures that blend visual and language understanding. Yet, a pressing challenge remains: How can we trust these agents especially in zero-shot settings with no fine-tuning? We introduce a novel modular Agentic AI visual classification framework that integrates generalist multimodal agents with a non-visual reasoning orchestrator and a Retrieval-Augmented Generation (RAG) module. Applied to apple leaf disease diagnosis, we benchmark three configurations: (I) zero-shot with confidence-based orchestration, (II) fine-tuned agents with improved performance, and (III) trust-calibrated orchestration enhanced by CLIP-based image retrieval and re-evaluation loops. Using confidence calibration metrics (ECE, OCR, CCC), the orchestrator modulates trust across agents. Our results demonstrate a 77.94\\% accuracy improvement in the zero-shot setting using trust-aware orchestration and RAG, achieving 85.63\\% overall. GPT-4o showed better calibration, while Qwen-2.5-VL displayed overconfidence. Furthermore, image-RAG grounded predictions with visually similar cases, enabling correction of agent overconfidence via iterative re-evaluation. The proposed system separates perception (vision agents) from meta-reasoning (orchestrator), enabling scalable and interpretable multi-agent AI. This blueprint is extensible to diagnostics, biology, and other trust-critical domains. All models, prompts, results, and system components including the complete software source code are openly released to support reproducibility, transparency, and community benchmarking at Github:", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.10571.pdf", "abstract_url": "https://arxiv.org/abs/2507.10571", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic", "@RAG"], "AI": {"tldr": "本文介绍了一种新颖的模块化Agentic AI视觉分类框架，通过集成通用多模态代理、非视觉推理协调器和RAG模块，解决了在零样本设置下对AI代理的信任问题。在苹果叶病诊断中的应用表明，信任感知协调和RAG显著提高了准确性。", "motivation": "解决在多代理架构中，尤其是在零样本设置下，如何建立对AI代理的信任问题。", "method": "采用模块化Agentic AI视觉分类框架，结合通用多模态代理、非视觉推理协调器和RAG模块，通过信任校准指标（ECE, OCR, CCC）调节代理间的信任。", "result": "在零样本设置下，使用信任感知协调和RAG提高了77.94%的准确性，总体达到85.63%。GPT-4o显示出更好的校准，而Qwen-2.5-VL则表现出过度自信。", "conclusion": "提出的系统将感知（视觉代理）与元推理（协调器）分离，实现了可扩展和可解释的多代理AI。这一蓝图可扩展到诊断、生物学等信任关键领域。"}}
{"id": "2507.10630", "title": "Enhancing the Capabilities of Large Language Models for API calls through Knowledge Graphs", "authors": ["Ye Yang", "Xue Xiao", "Ping Yin", "Taotao Xie"], "abstract": "API calls by large language models (LLMs) offer a cutting-edge approach for data analysis. However, their ability to effectively utilize tools via API calls remains underexplored in knowledge-intensive domains like meteorology. This paper introduces KG2data, a system that integrates knowledge graphs, LLMs, ReAct agents, and tool-use technologies to enable intelligent data acquisition and query handling in the meteorological field. Using a virtual API, we evaluate API call accuracy across three metrics: name recognition failure, hallucination failure, and call correctness. KG2data achieves superior performance (1.43%, 0%, 88.57%) compared to RAG2data (16%, 10%, 72.14%) and chat2data (7.14%, 8.57%, 71.43%). KG2data differs from typical LLM-based systems by addressing their limited access to domain-specific knowledge, which hampers performance on complex or terminology-rich queries. By using a knowledge graph as persistent memory, our system enhances content retrieval, complex query handling, domain-specific reasoning, semantic relationship resolution, and heterogeneous data integration. It also mitigates the high cost of fine-tuning LLMs, making the system more adaptable to evolving domain knowledge and API structures. In summary, KG2data provides a novel solution for intelligent, knowledge-based question answering and data analysis in domains with high knowledge demands.", "subjects": "Artificial Intelligence (cs.AI); Software Engineering (cs.SE)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.10630.pdf", "abstract_url": "https://arxiv.org/abs/2507.10630", "categories": ["Artificial Intelligence (cs.AI)", "Software Engineering (cs.SE)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文介绍了KG2data系统，该系统通过整合知识图谱、大型语言模型（LLMs）、ReAct代理和工具使用技术，提升了在气象学等知识密集型领域中通过API调用进行智能数据获取和查询处理的能力。", "motivation": "解决大型语言模型在知识密集型领域（如气象学）中通过API调用有效利用工具的不足，特别是在处理复杂或术语丰富的查询时的性能限制。", "method": "KG2data系统利用知识图谱作为持久记忆，结合LLMs、ReAct代理和工具使用技术，通过虚拟API评估API调用的准确性。", "result": "KG2data在名称识别失败、幻觉失败和调用正确性三个指标上（1.43%、0%、88.57%）表现优于RAG2data（16%、10%、72.14%）和chat2data（7.14%、8.57%、71.43%）。", "conclusion": "KG2data为高知识需求领域提供了智能、基于知识的问答和数据分析的新解决方案，同时减少了微调LLMs的高成本，使系统更能适应不断变化的领域知识和API结构。"}}
{"id": "2507.10644", "title": "From Semantic Web and MAS to Agentic AI: A Unified Narrative of the Web of Agents", "authors": ["Tatiana Petrova", "Aleksandr Puzikov", "Boris Bliznukov", "Radu State"], "abstract": "The concept of the Web of Agents (WoA), which transforms the static, document-centric Web into an environment of autonomous agents acting on users' behalf, has attracted growing interest as large language models (LLMs) become more capable. However, research in this area is still fragmented across different communities. Contemporary surveys catalog the latest LLM-powered frameworks, while the rich histories of Multi-Agent Systems (MAS) and the Semantic Web are often treated as separate, legacy domains. This fragmentation obscures the intellectual lineage of modern systems and hinders a holistic understanding of the field's trajectory. We present the first comprehensive evolutionary overview of the WoA. We show that modern protocols like A2A and the MCP, are direct evolutionary responses to the well-documented limitations of earlier standards like FIPA standards and OWL-based semantic agents. To systematize this analysis, we introduce a four-axis taxonomy (semantic foundation, communication paradigm, locus of intelligence, discovery mechanism). This framework provides a unified analytical lens for comparing agent architectures across all generations, revealing a clear line of descent where others have seen a disconnect. Our analysis identifies a paradigm shift in the 'locus of intelligence': from being encoded in external data (Semantic Web) or the platform (MAS) to being embedded within the agent's core model (LLM). This shift is foundational to modern Agentic AI, enabling the scalable and adaptive systems the WoA has long envisioned. We conclude that while new protocols are essential, they are insufficient for building a robust, open, trustworthy ecosystem. Finally, we argue that the next research frontier lies in solving persistent socio-technical challenges, and we map out a new agenda focused on decentralized identity, economic models, security, and governance for the emerging WoA.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Cryptography and Security (cs.CR); Human-Computer Interaction (cs.HC); Multiagent Systems (cs.MA)", "comments": "33 pages, 9 figures, 8 tables", "pdf_url": "https://arxiv.org/pdf/2507.10644.pdf", "abstract_url": "https://arxiv.org/abs/2507.10644", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Cryptography and Security (cs.CR)", "Human-Computer Interaction (cs.HC)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一个全面的进化概述，展示了从语义网和多代理系统到现代代理AI的统一叙事，强调了智能核心从外部数据或平台转移到代理核心模型的范式转变，并指出了构建强大、开放、可信赖的代理网络生态系统所需解决的持续社会技术挑战。", "motivation": "解决关于代理网络（WoA）研究领域碎片化的问题，以及如何将多代理系统（MAS）和语义网的丰富历史与现代大型语言模型（LLMs）驱动的框架结合起来，以提供一个全面的进化视角。", "method": "引入了一个四轴分类法（语义基础、通信范式、智能核心、发现机制），作为比较所有世代代理架构的统一分析框架。", "result": "揭示了现代代理AI中智能核心的范式转变，从外部数据或平台编码到嵌入代理核心模型，这是实现代理网络长期设想的可扩展和适应性系统的关键。", "conclusion": "虽然新协议对于构建代理网络生态系统至关重要，但仅此不足以解决所有挑战。未来的研究应集中在解决去中心化身份、经济模型、安全和治理等持续的社会技术挑战上。"}}
{"id": "2507.10894", "title": "NavComposer: Composing Language Instructions for Navigation Trajectories through Action-Scene-Object Modularization", "authors": ["Zongtao He", "Liuyi Wang", "Lu Chen", "Chengju Liu", "Qijun Chen"], "abstract": "Language-guided navigation is a cornerstone of embodied AI, enabling agents to interpret language instructions and navigate complex environments. However, expert-provided instructions are limited in quantity, while synthesized annotations often lack quality, making them insufficient for large-scale research. To address this, we propose NavComposer, a novel framework for automatically generating high-quality navigation instructions. NavComposer explicitly decomposes semantic entities such as actions, scenes, and objects, and recomposes them into natural language instructions. Its modular architecture allows flexible integration of state-of-the-art techniques, while the explicit use of semantic entities enhances both the richness and accuracy of instructions. Moreover, it operates in a data-agnostic manner, supporting adaptation to diverse navigation trajectories without domain-specific training. Complementing NavComposer, we introduce NavInstrCritic, a comprehensive annotation-free evaluation system that assesses navigation instructions on three dimensions: contrastive matching, semantic consistency, and linguistic diversity. NavInstrCritic provides a holistic evaluation of instruction quality, addressing limitations of traditional metrics that rely heavily on expert annotations. By decoupling instruction generation and evaluation from specific navigation agents, our method enables more scalable and generalizable research. Extensive experiments provide direct and practical evidence for the effectiveness of our method.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.10894.pdf", "abstract_url": "https://arxiv.org/abs/2507.10894", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "NavComposer是一个新颖的框架，用于自动生成高质量导航指令，通过动作-场景-对象模块化分解和重组语义实体。配合NavInstrCritic，一个无需注释的评估系统，全面评估指令质量。", "motivation": "解决语言引导导航中专家提供指令数量有限和合成注释质量不足的问题，以支持大规模研究。", "method": "NavComposer通过分解动作、场景和对象等语义实体，并将它们重组为自然语言指令，采用模块化架构灵活集成最新技术。", "result": "NavComposer能够在数据无关的方式下操作，支持适应多样化的导航轨迹，无需领域特定训练。NavInstrCritic提供了对指令质量的全面评估。", "conclusion": "通过将指令生成和评估与特定导航代理解耦，该方法实现了更可扩展和通用的研究。"}}
{"id": "2507.10911", "title": "Lessons Learned from Evaluation of LLM based Multi-agents in Safer Therapy Recommendation", "authors": ["Yicong Wu", "Ting Chen", "Irit Hochberg", "Zhoujian Sun", "Ruth Edry", "Zhengxing Huang", "Mor Peleg"], "abstract": "Therapy recommendation for chronic patients with multimorbidity is challenging due to risks of treatment conflicts. Existing decision support systems face scalability limitations. Inspired by the way in which general practitioners (GP) manage multimorbidity patients, occasionally convening multidisciplinary team (MDT) collaboration, this study investigated the feasibility and value of using a Large Language Model (LLM)-based multi-agent system (MAS) for safer therapy recommendations. We designed a single agent and a MAS framework simulating MDT decision-making by enabling discussion among LLM agents to resolve medical conflicts. The systems were evaluated on therapy planning tasks for multimorbidity patients using benchmark cases. We compared MAS performance with single-agent approaches and real-world benchmarks. An important contribution of our study is the definition of evaluation metrics that go beyond the technical precision and recall and allow the inspection of clinical goals met and medication burden of the proposed advices to a gold standard benchmark. Our results show that with current LLMs, a single agent GP performs as well as MDTs. The best-scoring models provide correct recommendations that address all clinical goals, yet the advices are incomplete. Some models also present unnecessary medications, resulting in unnecessary conflicts between medication and conditions or drug-drug interactions.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.10911.pdf", "abstract_url": "https://arxiv.org/abs/2507.10911", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了使用基于大型语言模型（LLM）的多代理系统（MAS）为多病共存患者提供更安全的治疗建议的可行性和价值。通过模拟多学科团队（MDT）的决策过程，研究发现，当前LLM的单代理系统在性能上与MDT相当，但建议存在不完整性和不必要的药物冲突。", "motivation": "多病共存患者的治疗推荐因治疗冲突的风险而具有挑战性，现有决策支持系统面临可扩展性限制。", "method": "设计了一个单代理和一个多代理系统框架，模拟MDT决策过程，通过LLM代理之间的讨论解决医疗冲突，并在多病共存患者的治疗规划任务上进行评估。", "result": "当前LLM的单代理系统在性能上与MDT相当，但建议存在不完整性和不必要的药物冲突。", "conclusion": "研究表明，基于LLM的多代理系统在多病共存患者的治疗推荐中具有潜力，但需要进一步改进以减少建议的不完整性和不必要的药物冲突。"}}
{"id": "2507.11049", "title": "Journalism-Guided Agentic In-Context Learning for News Stance Detection", "authors": ["Dahyun Lee", "Jonghyeon Choi", "Jiyoung Han", "Kunwoo Park"], "abstract": "As online news consumption grows, personalized recommendation systems have become integral to digital journalism. However, these systems risk reinforcing filter bubbles and political polarization by failing to incorporate diverse perspectives. Stance detection -- identifying a text's position on a target -- can help mitigate this by enabling viewpoint-aware recommendations and data-driven analyses of media bias. Yet, existing stance detection research remains largely limited to short texts and high-resource languages. To address these gaps, we introduce \\textsc{K-News-Stance}, the first Korean dataset for article-level stance detection, comprising 2,000 news articles with article-level and 19,650 segment-level stance annotations across 47 societal issues. We also propose \\textsc{JoA-ICL}, a \\textbf{Jo}urnalism-guided \\textbf{A}gentic \\textbf{I}n-\\textbf{C}ontext \\textbf{L}earning framework that employs a language model agent to predict the stances of key structural segments (e.g., leads, quotes), which are then aggregated to infer the overall article stance. Experiments show that \\textsc{JoA-ICL} outperforms existing stance detection methods, highlighting the benefits of segment-level agency in capturing the overall position of long-form news articles. Two case studies further demonstrate its broader utility in promoting viewpoint diversity in news recommendations and uncovering patterns of media bias.", "subjects": "Computation and Language (cs.CL)", "comments": "Preprint. 24 pages", "pdf_url": "https://arxiv.org/pdf/2507.11049.pdf", "abstract_url": "https://arxiv.org/abs/2507.11049", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了K-News-Stance，第一个韩语文章级立场检测数据集，并提出JoA-ICL框架，通过语言模型代理预测关键结构段的立场，以推断整篇文章的立场，优于现有方法。", "motivation": "在线新闻消费增长，个性化推荐系统可能加剧过滤气泡和政治极化，立场检测有助于整合多样视角，促进观点多样性。", "method": "提出JoA-ICL框架，利用语言模型代理预测新闻文章关键结构段的立场，并聚合这些立场以推断整篇文章的立场。", "result": "JoA-ICL在立场检测上优于现有方法，案例研究显示其在促进新闻推荐观点多样性和揭示媒体偏见模式方面的效用。", "conclusion": "JoA-ICL框架通过段级代理有效捕捉长篇新闻文章的立场，有助于提升新闻推荐的多样性和媒体偏见的分析。"}}
{"id": "2507.11198", "title": "Temperature and Persona Shape LLM Agent Consensus With Minimal Accuracy Gains in Qualitative Coding", "authors": ["Conrad Borchers", "Bahar Shahrokhian", "Francesco Balzan", "Elham Tajik", "Sreecharan Sankaranarayanan", "Sebastian Simon"], "abstract": "Large Language Models (LLMs) enable new possibilities for qualitative research at scale, including coding and data annotation. While multi-agent systems (MAS) can emulate human coding workflows, their benefits over single-agent coding remain poorly understood. We conducted an experimental study of how agent persona and temperature shape consensus-building and coding accuracy of dialog segments based on a codebook with 8 codes. Our open-source MAS mirrors deductive human coding through structured agent discussion and consensus arbitration. Using six open-source LLMs (with 3 to 32 billion parameters) and 18 experimental configurations, we analyze over 77,000 coding decisions against a gold-standard dataset of human-annotated transcripts from online math tutoring sessions. Temperature significantly impacted whether and when consensus was reached across all six LLMs. MAS with multiple personas (including neutral, assertive, or empathetic), significantly delayed consensus in four out of six LLMs compared to uniform personas. In three of those LLMs, higher temperatures significantly diminished the effects of multiple personas on consensus. However, neither temperature nor persona pairing lead to robust improvements in coding accuracy. Single agents matched or outperformed MAS consensus in most conditions. Only one model (OpenHermesV2:7B) and code category showed above-chance gains from MAS deliberation when temperature was 0.5 or lower and especially when the agents included at least one assertive persona. Qualitative analysis of MAS collaboration for these configurations suggests that MAS may nonetheless aid in narrowing ambiguous code applications that could improve codebooks and human-AI coding. We contribute new insight into the limits of LLM-based qualitative methods, challenging the notion that diverse MAS personas lead to better outcomes. We open-source our MAS and experimentation code.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "Manuscript submitted for review", "pdf_url": "https://arxiv.org/pdf/2507.11198.pdf", "abstract_url": "https://arxiv.org/abs/2507.11198", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本研究探讨了大型语言模型（LLMs）在定性研究中的应用，特别是通过多代理系统（MAS）模拟人类编码工作流程的效果。研究发现，温度和代理人格显著影响共识构建，但对编码准确性的提升有限。", "motivation": "探索多代理系统（MAS）在定性编码中的效益，以及代理人格和温度如何影响共识构建和编码准确性。", "method": "使用六个开源LLMs和18种实验配置，分析了超过77,000个编码决策，对比人类注释的数学辅导会话转录本的黄金标准数据集。", "result": "温度显著影响共识达成，多代理人格延迟了共识，但温度和人格配对并未显著提高编码准确性。单一代理在大多数情况下表现优于MAS共识。", "conclusion": "研究挑战了多样MAS人格导致更好结果的观念，为基于LLM的定性方法的局限性提供了新见解，并开源了MAS和实验代码。"}}
{"id": "2507.11222", "title": "An Agentic Flow for Finite State Machine Extraction using Prompt Chaining", "authors": ["Fares Wael", "Youssef Maklad", "Ali Hamdi", "Wael Elsersy"], "abstract": "Finite-State Machines (FSMs) are critical for modeling the operational logic of network protocols, enabling verification, analysis, and vulnerability discovery. However, existing FSM extraction techniques face limitations such as scalability, incomplete coverage, and ambiguity in natural language specifications. In this paper, we propose FlowFSM, a novel agentic framework that leverages Large Language Models (LLMs) combined with prompt chaining and chain-of-thought reasoning to extract accurate FSMs from raw RFC documents. FlowFSM systematically processes protocol specifications, identifies state transitions, and constructs structured rule-books by chaining agent outputs. Experimental evaluation across FTP and RTSP protocols demonstrates that FlowFSM achieves high extraction precision while minimizing hallucinated transitions, showing promising results. Our findings highlight the potential of agent-based LLM systems in the advancement of protocol analysis and FSM inference for cybersecurity and reverse engineering applications.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Networking and Internet Architecture (cs.NI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.11222.pdf", "abstract_url": "https://arxiv.org/abs/2507.11222", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Networking and Internet Architecture (cs.NI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出FlowFSM，一种利用大型语言模型（LLMs）结合提示链和思维链推理从原始RFC文档中提取精确有限状态机（FSMs）的新型代理框架。", "motivation": "现有的FSM提取技术在可扩展性、覆盖不全和自然语言规范中的模糊性方面存在限制。", "method": "FlowFSM通过链式代理输出系统地处理协议规范，识别状态转换，并构建结构化规则书。", "result": "在FTP和RTSP协议上的实验评估表明，FlowFSM在最小化虚构转换的同时实现了高提取精度。", "conclusion": "我们的发现突出了基于代理的LLM系统在协议分析和FSM推理用于网络安全和逆向工程应用中的潜力。"}}
{"id": "2507.11079", "title": "Tactical Decision for Multi-UGV Confrontation with a Vision-Language Model-Based Commander", "authors": ["Li Wang", "Qizhen Wu", "Lei Chen"], "abstract": "In multiple unmanned ground vehicle confrontations, autonomously evolving multi-agent tactical decisions from situational awareness remain a significant challenge. Traditional handcraft rule-based methods become vulnerable in the complicated and transient battlefield environment, and current reinforcement learning methods mainly focus on action manipulation instead of strategic decisions due to lack of interpretability. Here, we propose a vision-language model-based commander to address the issue of intelligent perception-to-decision reasoning in autonomous confrontations. Our method integrates a vision language model for scene understanding and a lightweight large language model for strategic reasoning, achieving unified perception and decision within a shared semantic space, with strong adaptability and interpretability. Unlike rule-based search and reinforcement learning methods, the combination of the two modules establishes a full-chain process, reflecting the cognitive process of human commanders. Simulation and ablation experiments validate that the proposed approach achieves a win rate of over 80% compared with baseline models.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.11079.pdf", "abstract_url": "https://arxiv.org/abs/2507.11079", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于视觉语言模型的指挥官系统，用于解决多无人地面车辆对抗中的智能感知到决策推理问题，通过结合视觉语言模型和轻量级大语言模型，实现了在共享语义空间内的统一感知和决策，具有强适应性和可解释性。", "motivation": "在多无人地面车辆对抗中，从情境感知自主演化多智能体战术决策仍是一个重大挑战。传统的手工规则方法在复杂多变的战场环境中显得脆弱，而当前的强化学习方法由于缺乏可解释性，主要关注动作操作而非战略决策。", "method": "提出了一种基于视觉语言模型的指挥官系统，该系统整合了用于场景理解的视觉语言模型和用于战略推理的轻量级大语言模型，实现了在共享语义空间内的统一感知和决策。", "result": "仿真和消融实验验证，与基线模型相比，所提出的方法实现了超过80%的胜率。", "conclusion": "该方法不仅反映了人类指挥官的认知过程，而且通过结合视觉语言模型和轻量级大语言模型，为多无人地面车辆对抗提供了一种具有强适应性和可解释性的全链条解决方案。"}}
{"id": "2507.11277", "title": "Taming Uncertainty via Automation: Observing, Analyzing, and Optimizing Agentic AI Systems", "authors": ["Dany Moshkovich", "Sergey Zeltyn"], "abstract": "Large Language Models (LLMs) are increasingly deployed within agentic systems-collections of interacting, LLM-powered agents that execute complex, adaptive workflows using memory, tools, and dynamic planning. While enabling powerful new capabilities, these systems also introduce unique forms of uncertainty stemming from probabilistic reasoning, evolving memory states, and fluid execution paths. Traditional software observability and operations practices fall short in addressing these challenges.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.11277.pdf", "abstract_url": "https://arxiv.org/abs/2507.11277", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文探讨了大型语言模型（LLMs）在代理系统中的部署，这些系统通过交互的、由LLM驱动的代理执行复杂的自适应工作流程。虽然这些系统带来了强大的新能力，但也引入了由概率推理、演变的记忆状态和流动的执行路径引起的新型不确定性。传统的软件可观察性和操作实践在应对这些挑战方面存在不足。", "motivation": "解决由LLM驱动的代理系统引入的新型不确定性，这些不确定性源于概率推理、演变的记忆状态和流动的执行路径，传统方法难以应对。", "method": "通过观察、分析和优化代理AI系统来驯服不确定性。", "result": "指出了传统软件可观察性和操作实践在处理由LLM驱动的代理系统引入的不确定性方面的不足。", "conclusion": "需要新的方法来有效管理和优化由LLM驱动的代理系统，以应对其引入的独特不确定性。"}}
{"id": "2507.11117", "title": "AI Agent Architecture for Decentralized Trading of Alternative Assets", "authors": ["Ailiya Borjigin", "Cong He", "Charles CC Lee", "Wei Zhou"], "abstract": "Decentralized trading of real-world alternative assets (e.g., gold) requires bridging physical asset custody with blockchain systems while meeting strict requirements for compliance, liquidity, and risk management. We present GoldMine OS, a research oriented architecture that employs multiple specialized AI agents to automate and secure the tokenization and exchange of physical gold into a blockchain based stablecoin (\"OZ\"). Our approach combines on chain smart contracts for critical risk controls with off chain AI agents for decision making, blending the transparency and reliability of blockchains with the flexibility of AI driven automation. We describe four cooperative agents (Compliance, Token Issuance, Market Making, and Risk Control) and a coordinating core, and evaluate the system through simulation and a controlled pilot deployment. In experiments the prototype delivers on demand token issuance in under 1.2 s, more than 100 times faster than manual workflows. The Market Making agent maintains tight liquidity with spreads often below 0.5 percent even under volatile conditions. Fault injection tests show resilience: an oracle price spoofing attack is detected and mitigated within 10 s, and a simulated vault mis reporting halts issuance immediately with minimal user impact. The architecture scales to 5000 transactions per second with 10000 concurrent users in benchmarks. These results indicate that an AI agent based decentralized exchange for alternative assets can satisfy rigorous performance and safety requirements. We discuss broader implications for democratizing access to traditionally illiquid assets and explain how our governance model -- multi signature agent updates and on chain community voting on risk parameters -- provides ongoing transparency, adaptability, and formal assurance of system integrity.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "8 Pages, 1 figure", "pdf_url": "https://arxiv.org/pdf/2507.11117.pdf", "abstract_url": "https://arxiv.org/abs/2507.11117", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了GoldMine OS，一个研究导向的架构，利用多个专门的AI代理来自动化和安全地将实物黄金代币化并交换为基于区块链的稳定币（\"OZ\"）。该系统结合了区块链的透明性和可靠性与AI驱动的自动化的灵活性，通过模拟和受控试点部署评估了系统性能。", "motivation": "解决实物替代资产（如黄金）的去中心化交易在满足合规性、流动性和风险管理严格要求的同时，将物理资产保管与区块链系统桥接的问题。", "method": "采用多个专门的AI代理（合规、代币发行、市场制造和风险控制）和一个协调核心，结合链上智能合约和链下AI代理的决策，实现自动化和安全的代币化与交换。", "result": "原型在实验中实现了按需代币发行时间低于1.2秒，比手动工作流程快100倍以上；市场制造代理在波动条件下保持紧密流动性，价差通常低于0.5%；故障注入测试显示系统具有弹性。", "conclusion": "基于AI代理的替代资产去中心化交易所可以满足严格的性能和安全性要求，为传统上非流动性资产的民主化访问提供了可能性，并通过多签名代理更新和链上社区投票的风险参数提供了持续的透明度、适应性和系统完整性的正式保证。"}}
{"id": "2507.11299", "title": "Dr.Copilot: A Multi-Agent Prompt Optimized Assistant for Improving Patient-Doctor Communication in Romanian", "authors": ["Andrei Niculae", "Adrian Cosma", "Cosmin Dumitrache", "Emilian Rǎdoi"], "abstract": "Text-based telemedicine has become increasingly common, yet the quality of medical advice in doctor-patient interactions is often judged more on how advice is communicated rather than its clinical accuracy. To address this, we introduce", "subjects": "Computation and Language (cs.CL)", "comments": "10 figures, 2 tables, 2 listings", "pdf_url": "https://arxiv.org/pdf/2507.11299.pdf", "abstract_url": "https://arxiv.org/abs/2507.11299", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了Dr.Copilot，一个多代理提示优化助手，旨在改善罗马尼亚语中患者与医生之间的沟通质量。", "motivation": "解决基于文本的远程医疗中，医患互动中医疗建议的沟通质量而非临床准确性被更多评判的问题。", "method": "引入一个多代理提示优化助手Dr.Copilot。", "result": "未提及具体结果。", "conclusion": "Dr.Copilot旨在通过优化沟通来提高医患互动的质量。"}}
{"id": "2507.11407", "title": "EXAONE 4.0: Unified Large Language Models Integrating Non-reasoning and Reasoning Modes", "authors": ["LG AI Research", "Kyunghoon Bae", "Eunbi Choi", "Kibong Choi", "Stanley Jungkyu Choi", "Yemuk Choi", "Kyubeen Han", "Seokhee Hong", "Junwon Hwang", "Taewan Hwang", "Joonwon Jang", "Hyojin Jeon", "Kijeong Jeon", "Gerrard Jeongwon Jo", "Hyunjik Jo", "Jiyeon Jung", "Euisoon Kim", "Hyosang Kim", "Jihoon Kim", "Joonkee Kim", "Seonghwan Kim", "Soyeon Kim", "Sunkyoung Kim", "Yireun Kim", "Yongil Kim", "Youchul Kim", "Edward Hwayoung Lee", "Gwangho Lee", "Haeju Lee", "Honglak Lee", "Jinsik Lee", "Kyungmin Lee", "Sangha Park", "Young Min Paik", "Yongmin Park", "Youngyong Park", "Sanghyun Seo", "Sihoon Yang", "Heuiyeen Yeen", "Sihyuk Yi", "Hyeongu Yun"], "abstract": "This technical report introduces EXAONE 4.0, which integrates a Non-reasoning mode and a Reasoning mode to achieve both the excellent usability of EXAONE 3.5 and the advanced reasoning abilities of EXAONE Deep. To pave the way for the agentic AI era, EXAONE 4.0 incorporates essential features such as agentic tool use, and its multilingual capabilities are extended to support Spanish in addition to English and Korean. The EXAONE 4.0 model series consists of two sizes: a mid-size 32B model optimized for high performance, and a small-size 1.2B model designed for on-device applications. The EXAONE 4.0 demonstrates superior performance compared to open-weight models in its class and remains competitive even against frontier-class models. The models are publicly available for research purposes and can be easily downloaded via", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "Technical Report, 30 Pages", "pdf_url": "https://arxiv.org/pdf/2507.11407.pdf", "abstract_url": "https://arxiv.org/abs/2507.11407", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "EXAONE 4.0是一个统一的大型语言模型，整合了非推理和推理模式，旨在实现EXAONE 3.5的优秀可用性和EXAONE Deep的高级推理能力。", "motivation": "为了解决在代理AI时代中，模型需要同时具备优秀可用性和高级推理能力的问题。", "method": "通过整合非推理模式和推理模式，并扩展多语言能力（支持英语、韩语和西班牙语），以及提供两种尺寸的模型（32B的中型模型和1.2B的小型模型）来适应不同应用场景。", "result": "EXAONE 4.0在其类别中表现出优于开放权重模型的性能，并且即使与前沿类模型相比也保持竞争力。", "conclusion": "EXAONE 4.0为研究目的公开可用，易于下载，标志着向代理AI时代迈出的重要一步。"}}
{"id": "2507.11527", "title": "DrafterBench: Benchmarking Large Language Models for Tasks Automation in Civil Engineering", "authors": ["Yinsheng Li", "Zhen Dong", "Yi Shao"], "abstract": "Large Language Model (LLM) agents have shown great potential for solving real-world problems and promise to be a solution for tasks automation in industry. However, more benchmarks are needed to systematically evaluate automation agents from an industrial perspective, for example, in Civil Engineering. Therefore, we propose DrafterBench for the comprehensive evaluation of LLM agents in the context of technical drawing revision, a representation task in civil engineering. DrafterBench contains twelve types of tasks summarized from real-world drawing files, with 46 customized functions/tools and 1920 tasks in total. DrafterBench is an open-source benchmark to rigorously test AI agents' proficiency in interpreting intricate and long-context instructions, leveraging prior knowledge, and adapting to dynamic instruction quality via implicit policy awareness. The toolkit comprehensively assesses distinct capabilities in structured data comprehension, function execution, instruction following, and critical reasoning. DrafterBench offers detailed analysis of task accuracy and error statistics, aiming to provide deeper insight into agent capabilities and identify improvement targets for integrating LLMs in engineering applications. Our benchmark is available at", "subjects": "Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2507.11527.pdf", "abstract_url": "https://arxiv.org/abs/2507.11527", "categories": ["Artificial Intelligence (cs.AI)", "Computational Engineering, Finance, and Science (cs.CE)"], "matching_keywords": ["agent"], "AI": {"tldr": "DrafterBench是一个用于全面评估大型语言模型（LLM）代理在土木工程图纸修订任务中表现的基准测试。它包含12种任务类型，46个定制功能/工具，总计1920个任务，旨在测试AI代理在解释复杂指令、利用先验知识和适应动态指令质量方面的能力。", "motivation": "为了解决工业领域中，特别是土木工程领域，缺乏系统性评估自动化代理的基准测试的问题，提出了DrafterBench。", "method": "通过总结现实世界图纸文件中的任务，创建了一个包含多种任务类型和定制功能的开源基准测试工具包，用于评估AI代理的不同能力。", "result": "DrafterBench提供了任务准确性和错误统计的详细分析，旨在更深入地了解代理能力，并为LLM在工程应用中的集成确定改进目标。", "conclusion": "DrafterBench的推出为土木工程领域的任务自动化提供了一个系统性的评估工具，有助于推动大型语言模型在工业应用中的发展和集成。"}}
{"id": "2507.11502", "title": "HKGAI-V1: Towards Regional Sovereign Large Language Model for Hong Kong", "authors": ["Sirui Han", "Junqi Zhu", "Ruiyuan Zhang", "Yike Guo"], "abstract": "This paper presents the development of HKGAI-V1, a foundational sovereign large language model (LLM), developed as part of an initiative to establish value-aligned AI infrastructure specifically tailored for Hong Kong. Addressing the region's unique multilingual environment (Cantonese, Mandarin, and English), its distinct socio-legal context under the \"one country, two systems\" framework, and specific local cultural and value considerations, the model is built upon the DeepSeek architecture and systematically aligned with regional norms through a multifaceted full parameter fine-tuning process. It is further integrated with a retrieval-augmented generation (RAG) system to ensure timely and factually grounded information access. The core contribution lies in the design and implementation of a comprehensive, region-specific AI alignment and safety framework, demonstrated through two key achievements: 1) The successful development of HKGAI-V1 itself - which outper-forms general-purpose models in handling Hong Kong-specific culturally sensitive queries, and embodies a \"governance-embedded\" approach to digital sovereignty - empowers Hong Kong to exercise control over AI applications in critical sectors including public services, legal systems, and edu-cation. 2) The development of the proprietary Adversarial HK Value Benchmark, a rigorous tool for evaluating model alignment with local ethical and legal stand-ards under challenging conditions. By documenting these achievements, the paper provides not only a technological artifact but also a replicable blueprint for developing advanced, regionally focused AI systems deeply rooted in their local identities.", "subjects": "Computation and Language (cs.CL); Computational Engineering, Finance, and Science (cs.CE); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.11502.pdf", "abstract_url": "https://arxiv.org/abs/2507.11502", "categories": ["Computation and Language (cs.CL)", "Computational Engineering, Finance, and Science (cs.CE)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了HKGAI-V1的开发，这是一个为香港量身定制的基础主权大型语言模型（LLM），旨在建立符合香港特定文化和价值观的AI基础设施。该模型基于DeepSeek架构，通过多方面的全参数微调过程与区域规范对齐，并集成了检索增强生成（RAG）系统以确保信息的及时性和事实基础。", "motivation": "解决香港在多语言环境（粤语、普通话和英语）、独特的“一国两制”社会法律背景以及特定本地文化和价值观考虑下的AI需求，开发一个能够处理香港特定文化敏感查询的区域主权大型语言模型。", "method": "基于DeepSeek架构，通过全面的全参数微调过程与区域规范对齐，并集成检索增强生成（RAG）系统。", "result": "成功开发了HKGAI-V1，该模型在处理香港特定文化敏感查询方面优于通用模型，并开发了专有的对抗性香港价值基准，用于评估模型在挑战性条件下与本地伦理和法律标准的对齐。", "conclusion": "HKGAI-V1不仅是一个技术成果，也为开发深入根植于本地身份的高级、区域性AI系统提供了可复制的蓝图，增强了香港在关键领域（如公共服务、法律系统和教育）对AI应用的控制能力。"}}
{"id": "2111.06614", "title": "Collaboration Promotes Group Resilience in Multi-Agent RL", "authors": ["Ilai Shraga", "Guy Azran", "Matthias Gerstgrasser", "Ofir Abu", "Jeffrey S. Rosenschein", "Sarah Keren"], "abstract": "To effectively operate in various dynamic scenarios, RL agents must be resilient to unexpected changes in their environment. Previous work on this form of resilience has focused on single-agent settings. In this work, we introduce and formalize a multi-agent variant of resilience, which we term group resilience. We further hypothesize that collaboration with other agents is key to achieving group resilience; collaborating agents adapt better to environmental perturbations in multi-agent reinforcement learning (MARL) settings. We test our hypothesis empirically by evaluating different collaboration protocols and examining their effect on group resilience. Our experiments show that all the examined collaborative approaches achieve higher group resilience than their non-collaborative counterparts.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "RLC 2025", "pdf_url": "https://arxiv.org/pdf/2111.06614.pdf", "abstract_url": "https://arxiv.org/abs/2111.06614", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了多智能体强化学习（MARL）中的群体韧性概念，并假设协作是实现群体韧性的关键。通过实验验证，所有被测试的协作方法都比非协作方法表现出更高的群体韧性。", "motivation": "解决多智能体在动态环境中对意外变化的适应能力问题，即群体韧性。", "method": "引入并形式化了群体韧性的多智能体变体，通过评估不同的协作协议来检验其对群体韧性的影响。", "result": "实验结果表明，所有被测试的协作方法都比非协作方法表现出更高的群体韧性。", "conclusion": "协作是多智能体强化学习中实现群体韧性的关键，这为未来的MARL研究提供了重要的启示。"}}
{"id": "2507.11059", "title": "SWE-MERA: A Dynamic Benchmark for Agenticly Evaluating Large Language Models on Software Engineering Tasks", "authors": ["Pavel Adamenko", "Mikhail Ivanov", "Aidar Valeev", "Rodion Levichev", "Pavel Zadorozhny", "Ivan Lopatin", "Dmitry Babayev", "Alena Fenogenova", "Valentin Malykh"], "abstract": "The rapid advancement of Large Language Models (LLMs) in software engineering has revealed critical limitations in existing benchmarks, particularly the widely used SWE-bench dataset. Recent studies have uncovered severe data contamination issues, e.g. SWE-bench reports 32.67% of successful patches involve direct solution leakage and 31.08\\% pass due to inadequate test cases. We introduce SWE-MERA, a dynamic, continuously updated benchmark designed to address these fundamental challenges through an automated collection of real-world GitHub issues and rigorous quality validation. Our approach implements a reliable pipeline that ensures quality while minimizing contamination risks, resulting in approximately 10,000 potential tasks with 300 samples currently available. Evaluation using the Aider coding agent demonstrates strong discriminative power in state-of-the-art models. We report performance across a dozen recent LLMs evaluated on tasks collected between September 2024 and June 2025.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.11059.pdf", "abstract_url": "https://arxiv.org/abs/2507.11059", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了SWE-MERA，一个动态的、持续更新的基准测试，旨在解决现有软件工程大型语言模型（LLMs）评估中的关键限制，特别是SWE-bench数据集中的数据污染问题。", "motivation": "现有的SWE-bench数据集在评估大型语言模型（LLMs）在软件工程任务中的表现时，暴露出严重的数据污染问题，如解决方案泄露和测试用例不足，这促使了SWE-MERA的开发。", "method": "通过自动化收集真实世界的GitHub问题并进行严格的质量验证，SWE-MERA实现了一个可靠的管道，确保质量同时最小化污染风险。", "result": "使用Aider编码代理进行的评估显示，SWE-MERA在区分最先进的模型方面具有强大的能力，报告了在2024年9月至2025年6月期间收集的任务上评估的十几个最近LLMs的性能。", "conclusion": "SWE-MERA作为一个动态更新的基准测试，有效解决了现有评估工具中的数据污染问题，为软件工程领域的大型语言模型评估提供了更可靠的工具。"}}
{"id": "2507.11515", "title": "AirLLM: Diffusion Policy-based Adaptive LoRA for Remote Fine-Tuning of LLM over the Air", "authors": ["Shiyi Yang", "Xiaoxue Yu", "Rongpeng Li", "Jianhang Zhu", "Zhifeng Zhao", "Honggang Zhang"], "abstract": "Operating Large Language Models (LLMs) on edge devices is increasingly challenged by limited communication bandwidth and strained computational and memory costs. Thus, cloud-assisted remote fine-tuning becomes indispensable. Nevertheless, existing Low-Rank Adaptation (LoRA) approaches typically employ fixed or heuristic rank configurations, and the subsequent over-the-air transmission of all LoRA parameters could be rather inefficient. To address this limitation, we develop AirLLM, a hierarchical diffusion policy framework for communication-aware LoRA adaptation. Specifically, AirLLM models the rank configuration as a structured action vector that spans all LoRA-inserted projections. To solve the underlying high-dimensional sequential decision-making problem, a Proximal Policy Optimization (PPO) agent generates coarse-grained decisions by jointly observing wireless states and linguistic complexity, which are then refined via Denoising Diffusion Implicit Models (DDIM) to produce high-resolution, task- and channel-adaptive rank vectors. The two modules are optimized alternatively, with the DDIM trained under the Classifier-Free Guidance (CFG) paradigm to maintain alignment with PPO rewards. Experiments under varying signal-to-noise ratios demonstrate that AirLLM consistently enhances fine-tuning performance while significantly reducing transmission costs, highlighting the effectiveness of reinforcement-driven, diffusion-refined rank adaptation for scalable and efficient remote fine-tuning over the air.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "11 pages, 8 figures", "pdf_url": "https://arxiv.org/pdf/2507.11515.pdf", "abstract_url": "https://arxiv.org/abs/2507.11515", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "AirLLM是一种基于扩散策略的自适应LoRA框架，用于通过空中远程精细调整LLM，解决了边缘设备上操作LLM时通信带宽有限和计算内存成本高的问题。", "motivation": "解决在边缘设备上操作大型语言模型(LLMs)时面临的有限通信带宽和高计算内存成本问题，以及现有LoRA方法中固定或启发式秩配置及参数传输效率低下的问题。", "method": "开发了AirLLM，一个分层扩散策略框架，用于通信感知的LoRA适应。该框架将秩配置建模为跨越所有LoRA插入投影的结构化动作向量，通过PPO代理生成粗粒度决策，并通过DDIM细化以产生高分辨率、任务和信道自适应的秩向量。", "result": "在不同信噪比下的实验表明，AirLLM持续提高了精细调整性能，同时显著降低了传输成本。", "conclusion": "AirLLM通过强化驱动和扩散精炼的秩适应，为空中远程精细调整提供了可扩展和高效的解决方案，突出了其在减少传输成本同时提升性能方面的有效性。"}}
{"id": "2507.10584", "title": "ARPaCCino: An Agentic-RAG for Policy as Code Compliance", "authors": ["Francesco Romeo", "Luigi Arena", "Francesco Blefari", "Francesco Aurelio Pironti", "Matteo Lupinacci", "Angelo Furfaro"], "abstract": "Policy as Code (PaC) is a paradigm that encodes security and compliance policies into machine-readable formats, enabling automated enforcement in Infrastructure as Code (IaC) environments. However, its adoption is hindered by the complexity of policy languages and the risk of misconfigurations. In this work, we present ARPaCCino, an agentic system that combines Large Language Models (LLMs), Retrieval-Augmented-Generation (RAG), and tool-based validation to automate the generation and verification of PaC rules. Given natural language descriptions of the desired policies, ARPaCCino generates formal Rego rules, assesses IaC compliance, and iteratively refines the IaC configurations to ensure conformance. Thanks to its modular agentic architecture and integration with external tools and knowledge bases, ARPaCCino supports policy validation across a wide range of technologies, including niche or emerging IaC frameworks. Experimental evaluation involving a Terraform-based case study demonstrates ARPaCCino's effectiveness in generating syntactically and semantically correct policies, identifying non-compliant infrastructures, and applying corrective modifications, even when using smaller, open-weight LLMs. Our results highlight the potential of agentic RAG architectures to enhance the automation, reliability, and accessibility of PaC workflows.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.10584.pdf", "abstract_url": "https://arxiv.org/abs/2507.10584", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic", "@RAG"], "AI": {"tldr": "ARPaCCino是一个结合大型语言模型、检索增强生成和工具验证的代理系统，旨在自动化和验证策略即代码规则的生成，以解决策略语言复杂性和配置错误的问题。", "motivation": "策略即代码（PaC）的采用受到策略语言复杂性和配置错误风险的阻碍。", "method": "ARPaCCino利用大型语言模型（LLMs）、检索增强生成（RAG）和基于工具的验证，自动生成和验证PaC规则。", "result": "实验评估显示，ARPaCCino在生成语法和语义正确的策略、识别不合规基础设施以及应用纠正修改方面有效，即使使用较小的开放权重LLMs。", "conclusion": "ARPaCCino展示了代理RAG架构在增强PaC工作流程自动化、可靠性和可访问性方面的潜力。"}}
{"id": "2507.10621", "title": "Game Theory Meets LLM and Agentic AI: Reimagining Cybersecurity for the Age of Intelligent Threats", "authors": ["Quanyan Zhu"], "abstract": "Protecting cyberspace requires not only advanced tools but also a shift in how we reason about threats, trust, and autonomy. Traditional cybersecurity methods rely on manual responses and brittle heuristics. To build proactive and intelligent defense systems, we need integrated theoretical frameworks and software tools. Game theory provides a rigorous foundation for modeling adversarial behavior, designing strategic defenses, and enabling trust in autonomous systems. Meanwhile, software tools process cyber data, visualize attack surfaces, verify compliance, and suggest mitigations. Yet a disconnect remains between theory and practical implementation.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Computer Science and Game Theory (cs.GT)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.10621.pdf", "abstract_url": "https://arxiv.org/abs/2507.10621", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)", "Computer Science and Game Theory (cs.GT)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文探讨了将博弈论与大型语言模型（LLM）和代理AI结合，重新构想智能威胁时代的网络安全。", "motivation": "传统网络安全方法依赖手动响应和脆弱的启发式方法，无法应对智能威胁，需要新的理论框架和软件工具。", "method": "利用博弈论建模对抗行为，设计战略防御，并在自主系统中建立信任，同时开发软件工具处理网络数据。", "result": "提出了一个结合博弈论和AI技术的综合框架，以构建更主动和智能的防御系统。", "conclusion": "通过整合博弈论和AI技术，可以更有效地应对网络安全挑战，但理论与实际应用之间仍存在差距。"}}
{"id": "2507.10619", "title": "Meta-Reinforcement Learning for Fast and Data-Efficient Spectrum Allocation in Dynamic Wireless Networks", "authors": ["Oluwaseyi Giwa", "Tobi Awodunmila", "Muhammad Ahmed Mohsin", "Ahsan Bilal", "Muhammad Ali Jamshed"], "abstract": "The dynamic allocation of spectrum in 5G / 6G networks is critical to efficient resource utilization. However, applying traditional deep reinforcement learning (DRL) is often infeasible due to its immense sample complexity and the safety risks associated with unguided exploration, which can cause severe network interference. To address these challenges, we propose a meta-learning framework that enables agents to learn a robust initial policy and rapidly adapt to new wireless scenarios with minimal data. We implement three meta-learning architectures, model-agnostic meta-learning (MAML), recurrent neural network (RNN), and an attention-enhanced RNN, and evaluate them against a non-meta-learning DRL algorithm, proximal policy optimization (PPO) baseline, in a simulated dynamic integrated access/backhaul (IAB) environment. Our results show a clear performance gap. The attention-based meta-learning agent reaches a peak mean network throughput of 48 Mbps, while the PPO baseline decreased drastically to 10 Mbps. Furthermore, our method reduces SINR and latency violations by more than 50% compared to PPO. It also shows quick adaptation, with a fairness index 0.7, showing better resource allocation. This work proves that meta-learning is a very effective and safer option for intelligent control in complex wireless systems.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Networking and Internet Architecture (cs.NI)", "comments": "5 pages, 6 figures, under review at IEEE Wireless Communications Letters", "pdf_url": "https://arxiv.org/pdf/2507.10619.pdf", "abstract_url": "https://arxiv.org/abs/2507.10619", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Networking and Internet Architecture (cs.NI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种元学习框架，用于5G/6G网络中的频谱动态分配，以解决传统深度强化学习在样本复杂性和安全风险方面的不足。通过三种元学习架构的实现与比较，证明了基于注意力的元学习代理在提高网络吞吐量、减少干扰和延迟违规方面的优越性。", "motivation": "解决5G/6G网络中频谱动态分配的高样本复杂性和安全风险问题。", "method": "提出了一个元学习框架，实现了三种元学习架构：模型无关的元学习（MAML）、循环神经网络（RNN）和注意力增强的RNN，并与非元学习的深度强化学习算法PPO基线进行了比较。", "result": "基于注意力的元学习代理达到了48 Mbps的峰值平均网络吞吐量，而PPO基线则大幅下降至10 Mbps。此外，该方法与PPO相比，减少了50%以上的SINR和延迟违规，并显示出快速的适应能力，公平性指数为0.7。", "conclusion": "元学习是复杂无线系统中智能控制的一种非常有效且更安全的选择。"}}
{"id": "2507.10610", "title": "LaSM: Layer-wise Scaling Mechanism for Defending Pop-up Attack on GUI Agents", "authors": ["Zihe Yan", "Zhuosheng Zhang"], "abstract": "Graphical user interface (GUI) agents built on multimodal large language models (MLLMs) have recently demonstrated strong decision-making abilities in screen-based interaction tasks. However, they remain highly vulnerable to pop-up-based environmental injection attacks, where malicious visual elements divert model attention and lead to unsafe or incorrect actions. Existing defense methods either require costly retraining or perform poorly under inductive interference. In this work, we systematically study how such attacks alter the attention behavior of GUI agents and uncover a layer-wise attention divergence pattern between correct and incorrect outputs. Based on this insight, we propose \\textbf{LaSM}, a \\textit{Layer-wise Scaling Mechanism} that selectively amplifies attention and MLP modules in critical layers. LaSM improves the alignment between model saliency and task-relevant regions without additional training. Extensive experiments across 12 types of pop-up perturbations and 4 different model backbones show that LaSM consistently enhances the defense success rate. When combined with prompt-level alerts, LaSM achieves over 98\\% robustness even under strong inductive attacks. Our findings reveal that attention misalignment is a core vulnerability in MLLM agents and can be effectively addressed through selective layer-wise modulation.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": "10 pages, 9 figures", "pdf_url": "https://arxiv.org/pdf/2507.10610.pdf", "abstract_url": "https://arxiv.org/abs/2507.10610", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为LaSM的层间缩放机制，用于防御基于GUI代理的弹出攻击，通过选择性放大关键层中的注意力和MLP模块，无需额外训练即可提高模型对任务相关区域的关注，实验表明LaSM能显著提升防御成功率。", "motivation": "多模态大语言模型（MLLMs）构建的图形用户界面（GUI）代理在基于屏幕的交互任务中表现出强大的决策能力，但对基于弹出的环境注入攻击高度脆弱，现有防御方法要么需要昂贵的重新训练，要么在归纳干扰下表现不佳。", "method": "提出LaSM（层间缩放机制），通过选择性放大关键层中的注意力和MLP模块，改善模型显著性图与任务相关区域的对齐，无需额外训练。", "result": "在12种弹出扰动和4种不同模型骨干上的广泛实验表明，LaSM一致提高了防御成功率，结合提示级警报，即使在强归纳攻击下也能达到超过98%的鲁棒性。", "conclusion": "注意力不齐是MLLM代理的核心漏洞，通过选择性层间调制可以有效解决。"}}
{"id": "2507.10695", "title": "Exploring User Security and Privacy Attitudes and Concerns Toward the Use of General-Purpose LLM Chatbots for Mental Health", "authors": ["Jabari Kwesi", "Jiaxun Cao", "Riya Manchanda", "Pardis Emami-Naeini"], "abstract": "Individuals are increasingly relying on large language model (LLM)-enabled conversational agents for emotional support. While prior research has examined privacy and security issues in chatbots specifically designed for mental health purposes, these chatbots are overwhelmingly \"rule-based\" offerings that do not leverage generative AI. Little empirical research currently measures users' privacy and security concerns, attitudes, and expectations when using general-purpose LLM-enabled chatbots to manage and improve mental health. Through 21 semi-structured interviews with U.S. participants, we identified critical misconceptions and a general lack of risk awareness. Participants conflated the human-like empathy exhibited by LLMs with human-like accountability and mistakenly believed that their interactions with these chatbots were safeguarded by the same regulations (e.g., HIPAA) as disclosures with a licensed therapist. We introduce the concept of \"intangible vulnerability,\" where emotional or psychological disclosures are undervalued compared to more tangible forms of information (e.g., financial or location-based data). To address this, we propose recommendations to safeguard user mental health disclosures with general-purpose LLM-enabled chatbots more effectively.", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Emerging Technologies (cs.ET); Human-Computer Interaction (cs.HC)", "comments": "Accepted to the 34th USENIX Security Symposium", "pdf_url": "https://arxiv.org/pdf/2507.10695.pdf", "abstract_url": "https://arxiv.org/abs/2507.10695", "categories": ["Computers and Society (cs.CY)", "Artificial Intelligence (cs.AI)", "Cryptography and Security (cs.CR)", "Emerging Technologies (cs.ET)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了用户在使用通用大型语言模型(LLM)聊天机器人进行心理健康管理时的安全和隐私态度及担忧。通过21次半结构化访谈，研究发现用户存在误解和风险意识不足的问题，提出了“无形脆弱性”概念，并提出了保护建议。", "motivation": "随着越来越多的人依赖LLM驱动的对话代理获得情感支持，目前缺乏关于用户在使用通用LLM聊天机器人管理心理健康时的隐私和安全担忧、态度及期望的实证研究。", "method": "通过对21名美国参与者进行半结构化访谈，识别了用户的关键误解和风险意识不足的问题。", "result": "研究发现，参与者将LLM表现出的人类同理心与人类责任混淆，错误地认为他们与这些聊天机器人的互动受到与持牌治疗师相同的法规保护。提出了“无形脆弱性”概念。", "conclusion": "研究强调了提高用户对通用LLM聊天机器人隐私和安全风险意识的重要性，并提出了更有效保护用户心理健康披露的建议。"}}
{"id": "2507.10812", "title": "React to This (RTT): A Nonverbal Turing Test for Embodied AI", "authors": ["Chuxuan Zhang", "Yasaman Etesam", "Angelica Lim"], "abstract": "We propose an approach to test embodied AI agents for interaction awareness and believability, particularly in scenarios where humans push them to their limits. Turing introduced the Imitation Game as a way to explore the question: \"Can machines think?\" The Total Turing Test later expanded this concept beyond purely verbal communication, incorporating perceptual and physical interaction. Building on this, we propose a new guiding question: \"Can machines react?\" and introduce the React to This (RTT) test for nonverbal behaviors, presenting results from an initial experiment.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": "5 pages, 3 figures", "pdf_url": "https://arxiv.org/pdf/2507.10812.pdf", "abstract_url": "https://arxiv.org/abs/2507.10812", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为“对此反应”（RTT）的非语言图灵测试方法，旨在评估具身AI代理在交互意识和可信度方面的表现，特别是在人类将其推向极限的场景中。", "motivation": "解决如何评估具身AI代理在非语言行为中的交互意识和可信度问题，特别是在极端情境下的表现。", "method": "提出了一种新的非语言行为测试方法——RTT测试，并通过初步实验展示了其结果。", "result": "初步实验结果展示了RTT测试在评估具身AI代理非语言行为方面的可行性和有效性。", "conclusion": "RTT测试为评估具身AI代理的非语言行为提供了一种新方法，对推动具身AI的发展具有重要意义。"}}
{"id": "2507.10741", "title": "Ground-Compose-Reinforce: Tasking Reinforcement Learning Agents through Formal Language", "authors": ["Andrew C. Li", "Toryn Q. Klassen", "Andrew Wang", "Parand A. Alamdari", "Sheila A. McIlraith"], "abstract": "Grounding language in complex perception (e.g. pixels) and action is a key challenge when building situated agents that can interact with humans via language. In past works, this is often solved via manual design of the language grounding or by curating massive datasets relating language to elements of the environment. We propose Ground-Compose-Reinforce, a neurosymbolic framework for grounding formal language from data, and eliciting behaviours by directly tasking RL agents through this language. By virtue of data-driven learning, our framework avoids the manual design of domain-specific elements like reward functions or symbol detectors. By virtue of compositional formal language semantics, our framework achieves data-efficient grounding and generalization to arbitrary language compositions. Experiments on an image-based gridworld and a MuJoCo robotics domain show that our approach reliably maps formal language instructions to behaviours with limited data while end-to-end, data-driven approaches fail.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.10741.pdf", "abstract_url": "https://arxiv.org/abs/2507.10741", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "提出了一个名为Ground-Compose-Reinforce的神经符号框架，用于从数据中基础形式语言，并通过这种语言直接任务RL代理，以解决在复杂感知和行动中基础语言的挑战。", "motivation": "解决在复杂感知（如像素）和行动中基础语言的关键挑战，以及如何通过语言与人类交互的代理构建问题。", "method": "使用数据驱动的学习避免手动设计特定领域的元素（如奖励函数或符号检测器），并通过组合形式语言语义实现数据高效的基础和泛化到任意语言组合。", "result": "在基于图像的网格世界和MuJoCo机器人领域的实验中，该方法在有限数据下可靠地将形式语言指令映射到行为，而端到端的数据驱动方法则失败。", "conclusion": "Ground-Compose-Reinforce框架通过结合数据驱动学习和形式语言语义，有效地解决了语言基础和行为任务的问题，展示了在有限数据下的高效性和泛化能力。"}}
{"id": "2507.10820", "title": "Semantic Context for Tool Orchestration", "authors": ["Robert Müller"], "abstract": "This paper demonstrates that Semantic Context (SC), leveraging descriptive tool information, is a foundational component for robust tool orchestration. Our contributions are threefold. First, we provide a theoretical foundation using contextual bandits, introducing SC-LinUCB and proving it achieves lower regret and adapts favourably in dynamic action spaces. Second, we provide parallel empirical validation with Large Language Models, showing that SC is critical for successful in-context learning in both static (efficient learning) and non-stationary (robust adaptation) settings. Third, we propose the FiReAct pipeline, and demonstrate on a benchmark with over 10,000 tools that SC-based retrieval enables an LLM to effectively orchestrate over a large action space. These findings provide a comprehensive guide to building more sample-efficient, adaptive, and scalable orchestration agents.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "Workshop on Computer Use Agents @ ICML2025", "pdf_url": "https://arxiv.org/pdf/2507.10820.pdf", "abstract_url": "https://arxiv.org/abs/2507.10820", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文展示了语义上下文（SC）在工具编排中的基础作用，通过理论、实证和新提出的FiReAct流程，证明了SC对于提高样本效率、适应性和可扩展性的重要性。", "motivation": "解决在动态和大规模动作空间中，如何有效和鲁棒地编排工具的问题。", "method": "结合上下文老虎机理论（提出SC-LinUCB算法）、大型语言模型的实证验证，以及FiReAct流程的提出与应用。", "result": "SC-LinUCB在动态动作空间中实现了更低的遗憾和良好的适应性；SC对于静态和非静态环境下的上下文学习至关重要；FiReAct流程在超过10,000个工具的基准测试中有效支持了大规模动作空间的编排。", "conclusion": "语义上下文是构建更高效、适应性强、可扩展的编排代理的关键，本文为相关研究和应用提供了全面的指导。"}}
{"id": "2507.10822", "title": "Past, Present and Future: Exploring Adaptive AI in Software Development Bots", "authors": ["Omar Elsisi", "Glaucia Melo"], "abstract": "Conversational agents, such as chatbots and virtual assistants, have become essential in software development, boosting productivity, collaboration, and automating various tasks. This paper examines the role of adaptive AI-powered conversational agents in software development, highlighting their ability to offer dynamic, context-aware assistance to developers. Unlike traditional rule-based systems, adaptive AI agents use machine learning and natural language processing to learn from interactions and improve over time, providing more personalized and responsive help. We look at how these tools have evolved from simple query-based systems to advanced AI-driven solutions like GitHub Copilot and Microsoft Teams bots. We also explore the challenges of integrating adaptive AI into software development processes. The study aims to assess the benefits and limitations of these systems, address concerns like data privacy and ethical issues, and offer insights into their future use in the field. Ultimately, adaptive AI chatbots have great potential to revolutionize software development by delivering real-time, customized support and enhancing the efficiency of development cycles.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.10822.pdf", "abstract_url": "https://arxiv.org/abs/2507.10822", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了自适应AI在软件开发机器人中的应用，从过去到现在的发展，以及未来的潜力。", "motivation": "解决传统基于规则的系统在软件开发中提供的帮助有限，无法适应动态变化的需求和个性化支持的问题。", "method": "利用机器学习和自然语言处理技术，使AI驱动的对话代理能够从交互中学习并随时间改进。", "result": "自适应AI代理如GitHub Copilot和Microsoft Teams机器人能够提供动态、上下文感知的辅助，提高开发效率和协作。", "conclusion": "自适应AI聊天机器人在软件开发中具有革命性潜力，但需解决数据隐私和伦理等挑战，以实现更广泛的应用。"}}
{"id": "2507.11210", "title": "Role-Playing LLM-Based Multi-Agent Support Framework for Detecting and Addressing Family Communication Bias", "authors": ["Rushia Harada", "Yuken Kimura", "Keito Inoshita"], "abstract": "Well-being in family settings involves subtle psychological dynamics that conventional metrics often overlook. In particular, unconscious parental expectations, termed ideal parent bias, can suppress children's emotional expression and autonomy. This suppression, referred to as suppressed emotion, often stems from well-meaning but value-driven communication, which is difficult to detect or address from outside the family. Focusing on these latent dynamics, this study explores Large Language Model (LLM)-based support for psychologically safe family communication. We constructed a Japanese parent-child dialogue corpus of 30 scenarios, each annotated with metadata on ideal parent bias and suppressed emotion. Based on this corpus, we developed a Role-Playing LLM-based multi-agent dialogue support framework that analyzes dialogue and generates feedback. Specialized agents detect suppressed emotion, describe implicit ideal parent bias in parental speech, and infer contextual attributes such as the child's age and background. A meta-agent compiles these outputs into a structured report, which is then passed to five selected expert agents. These agents collaboratively generate empathetic and actionable feedback through a structured four-step discussion process. Experiments show that the system can detect categories of suppressed emotion with moderate accuracy and produce feedback rated highly in empathy and practicality. Moreover, simulated follow-up dialogues incorporating this feedback exhibited signs of improved emotional expression and mutual understanding, suggesting the framework's potential in supporting positive transformation in family interactions.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.11210.pdf", "abstract_url": "https://arxiv.org/abs/2507.11210", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本研究探索了基于大型语言模型（LLM）的多角色对话支持框架，用于检测和解决家庭沟通中的偏见，特别是理想父母偏见和压抑情绪，通过模拟对话和专家代理的协作反馈，提高了情感表达和相互理解。", "motivation": "家庭环境中的幸福感涉及微妙的心理动态，传统指标往往忽视。特别是无意识的父母期望（理想父母偏见）可能抑制孩子的情感表达和自主性。这种压抑情绪源于善意但价值驱动的沟通，难以从家庭外部检测或解决。", "method": "研究构建了一个包含30个场景的日本亲子对话语料库，每个场景都标注了理想父母偏见和压抑情绪的元数据。基于此，开发了一个基于角色扮演LLM的多代理对话支持框架，分析对话并生成反馈。", "result": "实验表明，系统能以中等准确度检测压抑情绪类别，并产生在同理心和实用性方面评价高的反馈。模拟的后续对话显示情感表达和相互理解有所改善。", "conclusion": "该框架在支持家庭互动中积极转变方面显示出潜力，通过专家代理的协作反馈，改善了情感表达和相互理解。"}}
{"id": "2507.11269", "title": "Turning Sand to Gold: Recycling Data to Bridge On-Policy and Off-Policy Learning via Causal Bound", "authors": ["Tal Fiskus", "Uri Shaham"], "abstract": "Deep reinforcement learning (DRL) agents excel in solving complex decision-making tasks across various domains. However, they often require a substantial number of training steps and a vast experience replay buffer, leading to significant computational and resource demands. To address these challenges, we introduce a novel theoretical result that leverages the Neyman-Rubin potential outcomes framework into DRL. Unlike most methods that focus on bounding the counterfactual loss, we establish a causal bound on the factual loss, which is analogous to the on-policy loss in DRL. This bound is computed by storing past value network outputs in the experience replay buffer, effectively utilizing data that is usually discarded. Extensive experiments across the Atari 2600 and MuJoCo domains on various agents, such as DQN and SAC, achieve up to 2,427% higher reward ratio, outperforming the same agents without our proposed term, and reducing the experience replay buffer size by up to 96%, significantly improving sample efficiency at negligible cost.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "51 pages, 16 figures", "pdf_url": "https://arxiv.org/pdf/2507.11269.pdf", "abstract_url": "https://arxiv.org/abs/2507.11269", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新颖的理论方法，通过将Neyman-Rubin潜在结果框架引入深度强化学习（DRL），利用存储在经验回放缓冲区中的过去价值网络输出来计算事实损失的因果界限，从而显著提高样本效率并减少计算资源需求。", "motivation": "解决深度强化学习代理在解决复杂决策任务时需要大量训练步骤和经验回放缓冲区，导致计算和资源需求高的问题。", "method": "引入Neyman-Rubin潜在结果框架到DRL中，建立事实损失的因果界限，通过存储和利用过去价值网络输出的数据。", "result": "在Atari 2600和MuJoCo领域的多种代理上进行的广泛实验显示，奖励比率提高了高达2,427%，经验回放缓冲区大小减少了高达96%，显著提高了样本效率。", "conclusion": "通过利用通常被丢弃的数据，该方法在几乎不增加成本的情况下，显著提高了深度强化学习的样本效率和性能。"}}
