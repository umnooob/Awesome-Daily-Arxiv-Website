{"id": "2504.12667", "title": "Two Tasks, One Goal: Uniting Motion and Planning for Excellent End To End Autonomous Driving Performance", "authors": ["Lin Liu", "Ziying Song", "Hongyu Pan", "Lei Yang", "Caiyan Jia"], "abstract": "End-to-end autonomous driving has made impressive progress in recent years. Former end-to-end autonomous driving approaches often decouple planning and motion tasks, treating them as separate modules. This separation overlooks the potential benefits that planning can gain from learning out-of-distribution data encountered in motion tasks. However, unifying these tasks poses significant challenges, such as constructing shared contextual representations and handling the unobservability of other vehicles' states. To address these challenges, we propose TTOG, a novel two-stage trajectory generation framework. In the first stage, a diverse set of trajectory candidates is generated, while the second stage focuses on refining these candidates through vehicle state information. To mitigate the issue of unavailable surrounding vehicle states, TTOG employs a self-vehicle data-trained state estimator, subsequently extended to other vehicles. Furthermore, we introduce ECSA (equivariant context-sharing scene adapter) to enhance the generalization of scene representations across different agents. Experimental results demonstrate that TTOG achieves state-of-the-art performance across both planning and motion tasks. Notably, on the challenging open-loop nuScenes dataset, TTOG reduces the L2 distance by 36.06\\%. Furthermore, on the closed-loop Bench2Drive dataset, our approach achieves a 22\\% improvement in the driving score (DS), significantly outperforming existing baselines.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12667.pdf", "abstract_url": "https://arxiv.org/abs/2504.12667", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出TTOG框架，通过两阶段轨迹生成方法统一自动驾驶中的规划和运动任务，利用ECSA增强场景表示，显著提升性能。", "motivation": "解决现有端到端自动驾驶方法中规划和运动任务分离的问题，探索通过学习运动任务中的分布外数据来提升规划性能。", "method": "提出TTOG框架，包括生成多样化轨迹候选的第一阶段和通过车辆状态信息精化候选的第二阶段，使用自车数据训练的状态估计器和ECSA。", "result": "TTOG在nuScenes数据集上减少L2距离36.06%，在Bench2Drive数据集上驾驶分数提高22%，显著优于现有基线。", "conclusion": "TTOG通过统一规划和运动任务，利用共享表示和状态估计，实现了自动驾驶性能的显著提升。"}}
{"id": "2504.12679", "title": "TongUI: Building Generalized GUI Agents by Learning from Multimodal Web Tutorials", "authors": ["Bofei Zhang", "Zirui Shang", "Zhi Gao", "Wang Zhang", "Rui Xie", "Xiaojian Ma", "Tao Yuan", "Xinxiao Wu", "Song-Chun Zhu", "Qing Li"], "abstract": "Building Graphical User Interface (GUI) agents is a promising research direction, which simulates human interaction with computers or mobile phones to perform diverse GUI tasks. However, a major challenge in developing generalized GUI agents is the lack of sufficient trajectory data across various operating systems and applications, mainly due to the high cost of manual annotations. In this paper, we propose the TongUI framework that builds generalized GUI agents by learning from rich multimodal web tutorials. Concretely, we crawl and process online GUI tutorials (such as videos and articles) into GUI agent trajectory data, through which we produce the GUI-Net dataset containing 143K trajectory data across five operating systems and more than 200 applications. We develop the TongUI agent by fine-tuning Qwen2.5-VL-3B/7B models on GUI-Net, which show remarkable performance improvements on commonly used grounding and navigation benchmarks, outperforming baseline agents about 10\\% on multiple benchmarks, showing the effectiveness of the GUI-Net dataset and underscoring the significance of our TongUI framework. We will fully open-source the code, the GUI-Net dataset, and the trained models soon.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12679.pdf", "abstract_url": "https://arxiv.org/abs/2504.12679", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "TongUI框架通过从多模态网络教程中学习，构建了通用的GUI代理，解决了因手动标注成本高而缺乏跨操作系统和应用程序轨迹数据的问题。", "motivation": "开发通用GUI代理的主要挑战是缺乏跨各种操作系统和应用程序的足够轨迹数据，这主要是由于手动标注的高成本。", "method": "通过爬取和处理在线GUI教程（如视频和文章）到GUI代理轨迹数据，创建了包含143K轨迹数据的GUI-Net数据集，并在该数据集上微调Qwen2.5-VL-3B/7B模型来开发TongUI代理。", "result": "TongUI代理在常用的基础和导航基准测试中表现出显著的性能提升，在多个基准测试中优于基线代理约10%。", "conclusion": "GUI-Net数据集的有效性和TongUI框架的重要性得到了证明，代码、GUI-Net数据集和训练模型将完全开源。"}}
{"id": "2504.12696", "title": "Collaborative Perception Datasets for Autonomous Driving: A Review", "authors": ["Naibang Wang", "Deyong Shang", "Yan Gong", "Xiaoxi Hu", "Ziying Song", "Lei Yang", "Yuhan Huang", "Xiaoyu Wang", "Jianli Lu"], "abstract": "Collaborative perception has attracted growing interest from academia and industry due to its potential to enhance perception accuracy, safety, and robustness in autonomous driving through multi-agent information fusion. With the advancement of Vehicle-to-Everything (V2X) communication, numerous collaborative perception datasets have emerged, varying in cooperation paradigms, sensor configurations, data sources, and application scenarios. However, the absence of systematic summarization and comparative analysis hinders effective resource utilization and standardization of model evaluation. As the first comprehensive review focused on collaborative perception datasets, this work reviews and compares existing resources from a multi-dimensional perspective. We categorize datasets based on cooperation paradigms, examine their data sources and scenarios, and analyze sensor modalities and supported tasks. A detailed comparative analysis is conducted across multiple dimensions. We also outline key challenges and future directions, including dataset scalability, diversity, domain adaptation, standardization, privacy, and the integration of large language models. To support ongoing research, we provide a continuously updated online repository of collaborative perception datasets and related literature:", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "18pages, 7figures, journal", "pdf_url": "https://arxiv.org/pdf/2504.12696.pdf", "abstract_url": "https://arxiv.org/abs/2504.12696", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文综述了自动驾驶领域中协作感知数据集的研究现状，首次从多维度角度对现有资源进行了系统总结和比较分析，旨在促进资源的有效利用和模型评估的标准化。", "motivation": "随着车联网(V2X)通信技术的发展，协作感知在提升自动驾驶感知准确性、安全性和鲁棒性方面显示出巨大潜力。然而，缺乏对协作感知数据集的系统总结和比较分析，阻碍了资源的有效利用和模型评估的标准化。", "method": "本文从合作范式、数据来源和场景、传感器模态及支持的任务等多个维度对现有协作感知数据集进行了分类和比较分析。", "result": "通过多维度比较分析，本文揭示了协作感知数据集在可扩展性、多样性、领域适应性、标准化、隐私保护及与大语言模型整合等方面面临的主要挑战。", "conclusion": "本文不仅为自动驾驶协作感知领域的研究提供了全面的数据集综述和比较分析，还指出了未来研究方向，并建立了一个持续更新的在线资源库，以支持相关研究。"}}
{"id": "2504.12477", "title": "Towards Conversational AI for Human-Machine Collaborative MLOps", "authors": ["George Fatouros", "Georgios Makridis", "George Kousiouris", "John Soldatos", "Anargyros Tsadimas", "Dimosthenis Kyriazis"], "abstract": "This paper presents a Large Language Model (LLM) based conversational agent system designed to enhance human-machine collaboration in Machine Learning Operations (MLOps). We introduce the Swarm Agent, an extensible architecture that integrates specialized agents to create and manage ML workflows through natural language interactions. The system leverages a hierarchical, modular design incorporating a KubeFlow Pipelines (KFP) Agent for ML pipeline orchestration, a MinIO Agent for data management, and a Retrieval-Augmented Generation (RAG) Agent for domain-specific knowledge integration. Through iterative reasoning loops and context-aware processing, the system enables users with varying technical backgrounds to discover, execute, and monitor ML pipelines; manage datasets and artifacts; and access relevant documentation, all via intuitive conversational interfaces. Our approach addresses the accessibility gap in complex MLOps platforms like Kubeflow, making advanced ML tools broadly accessible while maintaining the flexibility to extend to other platforms. The paper describes the architecture, implementation details, and demonstrates how this conversational MLOps assistant reduces complexity and lowers barriers to entry for users across diverse technical skill levels.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)", "comments": "8 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2504.12477.pdf", "abstract_url": "https://arxiv.org/abs/2504.12477", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文介绍了一种基于大型语言模型（LLM）的对话代理系统，旨在增强人类与机器在机器学习操作（MLOps）中的协作。通过Swarm Agent的可扩展架构，系统整合了专门代理，通过自然语言交互创建和管理ML工作流程。", "motivation": "解决复杂MLOps平台（如Kubeflow）的可访问性问题，使不同技术背景的用户能够通过直观的对话界面使用高级ML工具。", "method": "采用分层模块化设计，整合了KubeFlow Pipelines（KFP）代理用于ML管道编排，MinIO代理用于数据管理，以及检索增强生成（RAG）代理用于领域特定知识集成。", "result": "通过迭代推理循环和上下文感知处理，系统成功降低了用户的技术门槛，使不同技术水平的用户都能发现、执行和监控ML管道，管理数据集和工件，并访问相关文档。", "conclusion": "该对话式MLOps助手减少了复杂性，降低了用户进入的门槛，同时保持了扩展到其他平台的灵活性。"}}
{"id": "2504.12482", "title": "Agentic AI Optimisation (AAIO): what it is, how it works, why it matters, and how to deal with it", "authors": ["Luciano Floridi", "Carlotta Buttaboni", "Emmie Hine", "Jessica Morley", "Claudio Novelli", "Tyler Schroder"], "abstract": "The emergence of Agentic Artificial Intelligence (AAI) systems capable of independently initiating digital interactions necessitates a new optimisation paradigm designed explicitly for seamless agent-platform interactions. This article introduces Agentic AI Optimisation (AAIO) as an essential methodology for ensuring effective integration between websites and agentic AI systems. Like how Search Engine Optimisation (SEO) has shaped digital content discoverability, AAIO can define interactions between autonomous AI agents and online platforms. By examining the mutual interdependency between website optimisation and agentic AI success, the article highlights the virtuous cycle that AAIO can create. It further explores the governance, ethical, legal, and social implications (GELSI) of AAIO, emphasising the necessity of proactive regulatory frameworks to mitigate potential negative impacts. The article concludes by affirming AAIO's essential role as part of a fundamental digital infrastructure in the era of autonomous digital agents, advocating for equitable and inclusive access to its benefits.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12482.pdf", "abstract_url": "https://arxiv.org/abs/2504.12482", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了代理性人工智能优化（AAIO）作为一种新方法，旨在确保网站与代理性AI系统之间的有效整合。类似于搜索引擎优化（SEO）对数字内容可发现性的影响，AAIO可以定义自主AI代理与在线平台之间的互动。文章探讨了AAIO在治理、伦理、法律和社会影响（GELSI）方面的重要性，并强调了建立积极监管框架的必要性。", "motivation": "随着能够独立发起数字互动的代理性人工智能（AAI）系统的出现，需要一种新的优化范式来专门确保代理与平台之间的无缝互动。", "method": "文章提出了代理性人工智能优化（AAIO）作为一种关键方法，通过分析网站优化与代理性AI成功之间的相互依赖性，展示了AAIO可以创造的良性循环。", "result": "AAIO不仅能够促进代理性AI系统与在线平台之间的有效整合，还能在治理、伦理、法律和社会影响（GELSI）方面产生深远影响。", "conclusion": "文章确认了AAIO在自主数字代理时代作为基本数字基础设施的重要组成部分，并倡导公平和包容地获取其好处。"}}
{"id": "2504.12497", "title": "Heuristic Recognition and Rapid Response to Unfamiliar Events Outside of Agent Design Scope", "authors": ["Robert E. Wray", "Steven J. Jones", "John E. Laird"], "abstract": "Regardless of past learning, an agent in an open world will face unfamiliar situations and events outside of prior experience, existing models, or policies. Further, the agent will sometimes lack relevant knowledge and/or sufficient time to assess the situation, generate and evaluate options, and pursue a robustly considered course of action. How can an agent respond reasonably to situations that are outside of its original design scope? How can it recognize such situations sufficiently quickly and reliably to determine reasonable, adaptive courses of action? We identify key characteristics needed for solutions, evaluate the state-of-the-art by these requirements, and outline a proposed, novel approach that combines domain-general meta-knowledge (in the form of appraisals inspired by human cognition) and metareasoning. It has the potential to provide fast, adaptive responses to unfamiliar situations, more fully meeting the performance characteristics required for open-world, general agents.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "12 pages, 3 figures. Submitted to AGI25 conference", "pdf_url": "https://arxiv.org/pdf/2504.12497.pdf", "abstract_url": "https://arxiv.org/abs/2504.12497", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了开放世界中智能体面对超出其设计范围的不熟悉事件时，如何快速识别并合理响应的问题。作者提出了一种结合领域通用元知识（受人类认知启发的评估）和元推理的新方法，旨在为开放世界的通用智能体提供快速、自适应的响应。", "motivation": "解决智能体在开放世界中遇到超出其经验、模型或政策范围的不熟悉情况时，如何在没有足够知识或时间进行彻底评估的情况下，快速识别并合理响应的问题。", "method": "提出了一种结合领域通用元知识（以人类认知启发的评估形式）和元推理的新方法。", "result": "该方法有潜力为开放世界的通用智能体提供快速、自适应的响应，更全面地满足其性能要求。", "conclusion": "通过结合领域通用元知识和元推理，智能体能够更有效地识别和响应超出其原始设计范围的不熟悉事件，这对于开放世界中的通用智能体至关重要。"}}
{"id": "2504.12612", "title": "The Chronicles of Foundation AI for Forensics of Multi-Agent Provenance", "authors": ["Ching-Chun Chang", "Isao Echizen"], "abstract": "Provenance is the chronology of things, resonating with the fundamental pursuit to uncover origins, trace connections, and situate entities within the flow of space and time. As artificial intelligence advances towards autonomous agents capable of interactive collaboration on complex tasks, the provenance of generated content becomes entangled in the interplay of collective creation, where contributions are continuously revised, extended or overwritten. In a multi-agent generative chain, content undergoes successive transformations, often leaving little, if any, trace of prior contributions. In this study, we investigates the problem of tracking multi-agent provenance across the temporal dimension of generation. We propose a chronological system for post hoc attribution of generative history from content alone, without reliance on internal memory states or external meta-information. At its core lies the notion of symbolic chronicles, representing signed and time-stamped records, in a form analogous to the chain of custody in forensic science. The system operates through a feedback loop, whereby each generative timestep updates the chronicle of prior interactions and synchronises it with the synthetic content in the very act of generation. This research seeks to develop an accountable form of collaborative artificial intelligence within evolving cyber ecosystems.", "subjects": "Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12612.pdf", "abstract_url": "https://arxiv.org/abs/2504.12612", "categories": ["Artificial Intelligence (cs.AI)", "Cryptography and Security (cs.CR)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了在多智能体生成链中追踪内容来源的问题，提出了一种基于符号编年史的系统，用于事后归因生成历史，旨在开发一种可追溯的协作人工智能形式。", "motivation": "随着人工智能向能够交互协作完成复杂任务的自主智能体发展，生成内容的来源在多智能体集体创作中变得复杂，难以追踪。", "method": "研究提出了一种基于符号编年史的系统，通过反馈循环更新交互记录，并与生成内容同步，无需依赖内部记忆状态或外部元信息。", "result": "开发了一种能够在多智能体生成链中追踪内容来源的系统，实现了对生成历史的可追溯归因。", "conclusion": "这项研究为在不断演变的网络生态系统中开发可追溯的协作人工智能形式提供了基础。"}}
{"id": "2504.12682", "title": "WebLists: Extracting Structured Information From Complex Interactive Websites Using Executable LLM Agents", "authors": ["Arth Bohra", "Manvel Saroyan", "Danil Melkozerov", "Vahe Karufanyan", "Gabriel Maher", "Pascal Weinberger", "Artem Harutyunyan", "Giovanni Campagna"], "abstract": "Most recent web agent research has focused on navigation and transaction tasks, with little emphasis on extracting structured data at scale. We present WebLists, a benchmark of 200 data-extraction tasks across four common business and enterprise use-cases. Each task requires an agent to navigate to a webpage, configure it appropriately, and extract complete datasets with well-defined schemas. We show that both LLMs with search capabilities and SOTA web agents struggle with these tasks, with a recall of 3% and 31%, respectively, despite higher performance on question-answering tasks.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12682.pdf", "abstract_url": "https://arxiv.org/abs/2504.12682", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "WebLists提出了一个包含200个数据提取任务的基准，用于评估LLM代理在复杂交互网站中提取结构化数据的能力。", "motivation": "解决当前网络代理研究在导航和交易任务上集中，而缺乏大规模结构化数据提取能力的问题。", "method": "通过创建包含四个常见商业和企业用例的基准任务，评估LLM和SOTA网络代理在数据提取上的表现。", "result": "结果显示，尽管在问答任务上表现较好，LLM和SOTA网络代理在这些数据提取任务上的召回率分别仅为3%和31%。", "conclusion": "该研究强调了在复杂交互网站中提取结构化数据的挑战，为未来网络代理技术的发展提供了方向。"}}
{"id": "2504.13032", "title": "InstructRAG: Leveraging Retrieval-Augmented Generation on Instruction Graphs for LLM-Based Task Planning", "authors": ["Zheng Wang", "Shu Xian Teo", "Jun Jie Chew", "Wei Shi"], "abstract": "Recent advancements in large language models (LLMs) have enabled their use as agents for planning complex tasks. Existing methods typically rely on a thought-action-observation (TAO) process to enhance LLM performance, but these approaches are often constrained by the LLMs' limited knowledge of complex tasks. Retrieval-augmented generation (RAG) offers new opportunities by leveraging external databases to ground generation in retrieved information. In this paper, we identify two key challenges (enlargability and transferability) in applying RAG to task planning. We propose InstructRAG, a novel solution within a multi-agent meta-reinforcement learning framework, to address these challenges. InstructRAG includes a graph to organize past instruction paths (sequences of correct actions), an RL-Agent with Reinforcement Learning to expand graph coverage for enlargability, and an ML-Agent with Meta-Learning to improve task generalization for transferability. The two agents are trained end-to-end to optimize overall planning performance. Our experiments on four widely used task planning datasets demonstrate that InstructRAG significantly enhances performance and adapts efficiently to new tasks, achieving up to a 19.2% improvement over the best existing approach.", "subjects": "Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": "This paper has been accepted by SIGIR 2025", "pdf_url": "https://arxiv.org/pdf/2504.13032.pdf", "abstract_url": "https://arxiv.org/abs/2504.13032", "categories": ["Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文提出了InstructRAG，一种在多智能体元强化学习框架下的新解决方案，旨在通过检索增强生成（RAG）技术解决任务规划中的可扩展性和可转移性挑战。", "motivation": "大型语言模型（LLMs）在规划复杂任务时，受限于其对复杂任务的有限知识，现有的思维-行动-观察（TAO）方法难以满足需求。检索增强生成（RAG）通过利用外部数据库为生成提供信息基础，为解决这一问题提供了新机会。", "method": "InstructRAG包括一个用于组织过去指令路径的图、一个通过强化学习扩展图覆盖范围的RL-Agent，以及一个通过元学习提高任务泛化能力的ML-Agent。这两个智能体通过端到端训练优化整体规划性能。", "result": "在四个广泛使用的任务规划数据集上的实验表明，InstructRAG显著提高了性能，并能高效适应新任务，比现有最佳方法提高了19.2%。", "conclusion": "InstructRAG通过结合检索增强生成和多智能体元强化学习，有效解决了任务规划中的可扩展性和可转移性问题，为LLM-based任务规划提供了新的研究方向。"}}
{"id": "2504.13145", "title": "Exploring Expert Failures Improves LLM Agent Tuning", "authors": ["Li-Cheng Lan", "Andrew Bai", "Minhao Cheng", "Ruochen Wang", "Cho-Jui Hsieh", "Tianyi Zhou"], "abstract": "Large Language Models (LLMs) have shown tremendous potential as agents, excelling at tasks that require multiple rounds of reasoning and interactions. Rejection Sampling Fine-Tuning (RFT) has emerged as an effective method for finetuning LLMs as agents: it first imitates expert-generated successful trajectories and further improves agentic skills through iterative fine-tuning on successful, self-generated trajectories. However, since the expert (e.g., GPT-4) succeeds primarily on simpler subtasks and RFT inherently favors simpler scenarios, many complex subtasks remain unsolved and persistently out-of-distribution (OOD). Upon investigating these challenging subtasks, we discovered that previously failed expert trajectories can often provide valuable guidance, e.g., plans and key actions, that can significantly improve agent exploration efficiency and acquisition of critical skills. Motivated by these observations, we propose Exploring Expert Failures (EEF), which identifies beneficial actions from failed expert trajectories and integrates them into the training dataset. Potentially harmful actions are meticulously excluded to prevent contamination of the model learning process. By leveraging the beneficial actions in expert failures, EEF successfully solves some previously unsolvable subtasks and improves agent tuning performance. Remarkably, our approach achieved a 62\\% win rate in WebShop, outperforming RFT (53. 6\\%) and GPT-4 (35. 6\\%), and to the best of our knowledge, setting a new state-of-the-art as the first method to surpass a score of 0.81 in WebShop and exceed 81 in SciWorld.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.13145.pdf", "abstract_url": "https://arxiv.org/abs/2504.13145", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种名为探索专家失败（EEF）的新方法，通过分析专家（如GPT-4）在复杂子任务上的失败轨迹，提取有价值的指导信息来优化大型语言模型（LLM）代理的调优过程。EEF不仅解决了之前无法解决的子任务，还在WebShop和SciWorld等任务中实现了新的最先进性能。", "motivation": "尽管拒绝采样微调（RFT）在微调LLM代理方面表现出色，但它在处理复杂子任务时往往效果不佳，因为这些任务超出了其分布范围。专家在这些复杂任务上的失败轨迹可能包含宝贵的学习信息，但目前的方法未能充分利用这些信息。", "method": "EEF方法通过识别专家失败轨迹中的有益行动，并将这些行动整合到训练数据集中，同时排除潜在有害的行动，以避免污染模型学习过程。这种方法显著提高了代理的探索效率和关键技能的获取。", "result": "EEF在WebShop任务中实现了62%的胜率，优于RFT的53.6%和GPT-4的35.6%，并在WebShop和SciWorld中创下了新的最先进记录，首次在WebShop中超过0.81分，在SciWorld中超过81分。", "conclusion": "通过利用专家失败中的有益信息，EEF不仅解决了之前无法解决的子任务，还显著提高了LLM代理的性能，为代理调优提供了新的方向。"}}
{"id": "2504.13171", "title": "Sleep-time Compute: Beyond Inference Scaling at Test-time", "authors": ["Kevin Lin", "Charlie Snell", "Yu Wang", "Charles Packer", "Sarah Wooders", "Ion Stoica", "Joseph E. Gonzalez"], "abstract": "Scaling test-time compute has emerged as a key ingredient for enabling large language models (LLMs) to solve difficult problems, but comes with high latency and inference cost. We introduce sleep-time compute, which allows models to \"think\" offline about contexts before queries are presented: by anticipating what queries users might ask and pre-computing useful quantities, we can significantly reduce the compute requirements at test-time. To demonstrate the efficacy of our method, we create modified versions of two reasoning tasks - Stateful GSM-Symbolic and Stateful AIME. We find that sleep-time compute can reduce the amount of test-time compute needed to achieve the same accuracy by ~ 5x on Stateful GSM-Symbolic and Stateful AIME and that by scaling sleep-time compute we can further increase accuracy by up to 13% on Stateful GSM-Symbolic and 18% on Stateful AIME. Furthermore, we introduce Multi-Query GSM-Symbolic, which extends GSM-Symbolic by including multiple related queries per context. By amortizing sleep-time compute across related queries about the same context using Multi-Query GSM-Symbolic, we can decrease the average cost per query by 2.5x. We then conduct additional analysis to understand when sleep-time compute is most effective, finding the predictability of the user query to be well correlated with the efficacy of sleep-time compute. Finally, we conduct a case-study of applying sleep-time compute to a realistic agentic SWE task.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2504.13171.pdf", "abstract_url": "https://arxiv.org/abs/2504.13171", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了‘睡眠时间计算’方法，通过在查询前预计算有用量，显著减少测试时的计算需求，并在多个推理任务中验证了其有效性。", "motivation": "解决大型语言模型在测试时因扩展计算而带来的高延迟和高成本问题。", "method": "引入‘睡眠时间计算’，允许模型在查询前离线‘思考’上下文，预计算有用量。", "result": "在Stateful GSM-Symbolic和Stateful AIME任务中，测试时计算需求减少约5倍，准确率提升高达13%和18%；通过Multi-Query GSM-Symbolic，每个查询的平均成本降低2.5倍。", "conclusion": "睡眠时间计算能有效减少测试时的计算需求和成本，特别是在用户查询可预测性高时效果更佳。"}}
{"id": "2504.12322", "title": "A Strategic Coordination Framework of Small LLMs Matches Large LLMs in Data Synthesis", "authors": ["Xin Gao", "Qizhi Pei", "Zinan Tang", "Yu Li", "Honglin Lin", "Jiang Wu", "Conghui He", "Lijun Wu"], "abstract": "While data synthesis and distillation are promising strategies to enhance small language models, current approaches heavily rely on Large Language Models (LLMs), which suffer from high computational costs, environmental inefficiency, and potential biases inherited from monolithic architectures. In contrast, smaller LLMs are more accessible and sustainable, but their individual capabilities often fall short in generating high-quality, diverse, and reliable data. Inspired by collaborative human processes (e.g., peer review), we propose a multiple small LLMs involved framework, GRA, that aggregates specialized roles across small LLMs to iterative refinement and quality control typically achieved by a single large LLM. In this collaborative framework, multiple small LLMs assume distinct roles-Generator, Reviewer, and Adjudicator-to simulate a peer-review-inspired data synthesis pipeline. The Generator proposes initial data samples, the Reviewer critiques their quality and diversity, and the Adjudicator resolves conflicts to finalize the output. By decomposing the synthesis process into specialized sub-tasks, collaborative small LLMs can achieve data-level parity with large LLM-based distillation. Through experiments across multiple benchmarks, we demonstrate that GRA-produced data matches or exceeds the quality of single large LLM outputs, e.g., Qwen-2.5-72B-Instruct. Our results challenge the necessity of monolithic large models for high-quality data synthesis, advocating instead for strategic coordination of smaller agents. Our datasets, models, and code are publicly available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12322.pdf", "abstract_url": "https://arxiv.org/abs/2504.12322", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一个名为GRA的战略协调框架，通过多个小型语言模型（LLMs）的协作，模拟同行评审过程，以实现高质量数据合成，挑战了大型LLMs在此领域的必要性。", "motivation": "当前数据合成和蒸馏方法过度依赖大型语言模型（LLMs），存在计算成本高、环境效率低及潜在偏见问题。小型LLMs虽更易获取和可持续，但单独使用时在生成高质量、多样化数据方面能力不足。", "method": "提出了GRA框架，通过分配小型LLMs不同的角色（生成器、评审者和裁决者），模拟同行评审过程，进行数据合成的迭代优化和质量控制。", "result": "实验证明，GRA框架生成的数据质量与或超过单个大型LLM（如Qwen-2.5-72B-Instruct）的输出，挑战了大型模型在高质量数据合成中的必要性。", "conclusion": "研究表明，通过小型LLMs的战略协调，可以实现与大型LLMs相当的数据合成质量，为更高效、可持续的数据合成方法提供了可能。"}}
{"id": "2504.12323", "title": "The Other Side of the Coin: Exploring Fairness in Retrieval-Augmented Generation", "authors": ["Zheng Zhang", "Ning Li", "Qi Liu", "Rui Li", "Weibo Gao", "Qingyang Mao", "Zhenya Huang", "Baosheng Yu", "Dacheng Tao"], "abstract": "Retrieval-Augmented Generation (RAG) enhances Large Language Models (LLMs) by retrieving relevant document from external knowledge sources. By referencing this external knowledge, RAG effectively reduces the generation of factually incorrect content and addresses hallucination issues within LLMs. Recently, there has been growing attention to improving the performance and efficiency of RAG systems from various perspectives. While these advancements have yielded significant results, the application of RAG in domains with considerable societal implications raises a critical question about fairness: What impact does the introduction of the RAG paradigm have on the fairness of LLMs? To address this question, we conduct extensive experiments by varying the LLMs, retrievers, and retrieval sources. Our experimental analysis reveals that the scale of the LLMs plays a significant role in influencing fairness outcomes within the RAG framework. When the model scale is smaller than 8B, the integration of retrieval mechanisms often exacerbates unfairness in small-scale LLMs (e.g., LLaMA3.2-1B, Mistral-7B, and LLaMA3-8B). To mitigate the fairness issues introduced by RAG for small-scale LLMs, we propose two approaches, FairFT and FairFilter. Specifically, in FairFT, we align the retriever with the LLM in terms of fairness, enabling it to retrieve documents that facilitate fairer model outputs. In FairFilter, we propose a fairness filtering mechanism to filter out biased content after retrieval. Finally, we validate our proposed approaches on real-world datasets, demonstrating their effectiveness in improving fairness while maintaining performance.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "12 pages", "pdf_url": "https://arxiv.org/pdf/2504.12323.pdf", "abstract_url": "https://arxiv.org/abs/2504.12323", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文探讨了检索增强生成（RAG）在大型语言模型（LLMs）中应用的公平性问题，发现小规模LLMs（小于8B）在集成检索机制时往往会加剧不公平性，并提出了FairFT和FairFilter两种方法来缓解这一问题。", "motivation": "随着检索增强生成（RAG）系统在具有重大社会影响的领域中的应用日益增多，其对大型语言模型（LLMs）公平性的影响成为一个关键问题。", "method": "通过变化LLMs、检索器和检索源进行广泛实验，分析了RAG对LLMs公平性的影响，并提出了FairFT和FairFilter两种方法来改善小规模LLMs的公平性。", "result": "实验分析显示，当模型规模小于8B时，检索机制的集成往往会加剧小规模LLMs的不公平性。提出的FairFT和FairFilter方法在真实数据集上验证了其有效性，能够在保持性能的同时改善公平性。", "conclusion": "研究表明，RAG在小规模LLMs中可能加剧不公平性，但通过FairFT和FairFilter方法可以有效缓解这一问题，为未来在敏感领域应用RAG提供了重要参考。"}}
{"id": "2504.12330", "title": "HM-RAG: Hierarchical Multi-Agent Multimodal Retrieval Augmented Generation", "authors": ["Pei Liu", "Xin Liu", "Ruoyu Yao", "Junming Liu", "Siyuan Meng", "Ding Wang", "Jun Ma"], "abstract": "While Retrieval-Augmented Generation (RAG) augments Large Language Models (LLMs) with external knowledge, conventional single-agent RAG remains fundamentally limited in resolving complex queries demanding coordinated reasoning across heterogeneous data ecosystems. We present HM-RAG, a novel Hierarchical Multi-agent Multimodal RAG framework that pioneers collaborative intelligence for dynamic knowledge synthesis across structured, unstructured, and graph-based data. The framework is composed of three-tiered architecture with specialized agents: a Decomposition Agent that dissects complex queries into contextually coherent sub-tasks via semantic-aware query rewriting and schema-guided context augmentation; Multi-source Retrieval Agents that carry out parallel, modality-specific retrieval using plug-and-play modules designed for vector, graph, and web-based databases; and a Decision Agent that uses consistency voting to integrate multi-source answers and resolve discrepancies in retrieval results through Expert Model Refinement. This architecture attains comprehensive query understanding by combining textual, graph-relational, and web-derived evidence, resulting in a remarkable 12.95% improvement in answer accuracy and a 3.56% boost in question classification accuracy over baseline RAG systems on the ScienceQA and CrisisMMD benchmarks. Notably, HM-RAG establishes state-of-the-art results in zero-shot settings on both datasets. Its modular architecture ensures seamless integration of new data modalities while maintaining strict data governance, marking a significant advancement in addressing the critical challenges of multimodal reasoning and knowledge synthesis in RAG systems. Code is available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12330.pdf", "abstract_url": "https://arxiv.org/abs/2504.12330", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "HM-RAG是一种新颖的分层多代理多模态检索增强生成框架，通过协作智能动态合成跨结构化、非结构化和基于图的数据的知识，显著提高了答案准确性和问题分类准确性。", "motivation": "解决传统单代理RAG在处理需要跨异构数据生态系统协调推理的复杂查询时的根本限制。", "method": "采用三层架构，包括分解代理、多源检索代理和决策代理，通过语义感知查询重写、模式引导上下文增强、并行多模态特定检索和一致性投票等方法。", "result": "在ScienceQA和CrisisMMD基准测试中，答案准确性提高了12.95%，问题分类准确性提高了3.56%，并在零样本设置中建立了最先进的结果。", "conclusion": "HM-RAG的模块化架构确保了新数据模态的无缝集成，同时保持严格的数据治理，标志着在解决RAG系统中多模态推理和知识合成的关键挑战方面取得了重大进展。"}}
{"id": "2504.12342", "title": "Benchmarking Biopharmaceuticals Retrieval-Augmented Generation Evaluation", "authors": ["Hanmeng Zhong", "Linqing Chen", "Weilei Wang", "Wentao Wu"], "abstract": "Recently, the application of the retrieval-augmented Large Language Models (LLMs) in specific domains has gained significant attention, especially in biopharmaceuticals. However, in this context, there is no benchmark specifically designed for biopharmaceuticals to evaluate LLMs. In this paper, we introduce the Biopharmaceuticals Retrieval-Augmented Generation Evaluation (BRAGE) , the first benchmark tailored for evaluating LLMs' Query and Reference Understanding Capability (QRUC) in the biopharmaceutical domain, available in English, French, German and Chinese. In addition, Traditional Question-Answering (QA) metrics like accuracy and exact match fall short in the open-ended retrieval-augmented QA scenarios. To address this, we propose a citation-based classification method to evaluate the QRUC of LLMs to understand the relationship between queries and references. We apply this method to evaluate the mainstream LLMs on BRAGE. Experimental results show that there is a significant gap in the biopharmaceutical QRUC of mainstream LLMs, and their QRUC needs to be improved.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12342.pdf", "abstract_url": "https://arxiv.org/abs/2504.12342", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了首个针对生物制药领域的检索增强大型语言模型（LLMs）评估基准——BRAGE，旨在评估LLMs在生物制药领域的查询和参考理解能力（QRUC），并提出了基于引用的分类方法以改进传统QA指标在开放检索增强QA场景中的不足。", "motivation": "当前缺乏专门针对生物制药领域的基准来评估检索增强大型语言模型（LLMs）的性能，特别是在查询和参考理解能力（QRUC）方面。", "method": "提出了Biopharmaceuticals Retrieval-Augmented Generation Evaluation (BRAGE)基准，并开发了一种基于引用的分类方法，以评估LLMs的QRUC。", "result": "实验结果显示，主流LLMs在生物制药QRUC方面存在显著差距，需要改进。", "conclusion": "BRAGE基准和提出的评估方法为生物制药领域LLMs的性能评估提供了重要工具，揭示了当前模型的不足，并指出了改进方向。"}}
{"id": "2504.12313", "title": "Exploring the Impact of Personality Traits on Conversational Recommender Systems: A Simulation with Large Language Models", "authors": ["Xiaoyan Zhao", "Yang Deng", "Wenjie Wang", "Hongzhan lin", "Hong Cheng", "Rui Zhang", "See-Kiong Ng", "Tat-Seng Chua"], "abstract": "Conversational Recommender Systems (CRSs) engage users in multi-turn interactions to deliver personalized recommendations. The emergence of large language models (LLMs) further enhances these systems by enabling more natural and dynamic user interactions. However, a key challenge remains in understanding how personality traits shape conversational recommendation outcomes. Psychological evidence highlights the influence of personality traits on user interaction behaviors. To address this, we introduce an LLM-based personality-aware user simulation for CRSs (PerCRS). The user agent induces customizable personality traits and preferences, while the system agent possesses the persuasion capability to simulate realistic interaction in CRSs. We incorporate multi-aspect evaluation to ensure robustness and conduct extensive analysis from both user and system perspectives. Experimental results demonstrate that state-of-the-art LLMs can effectively generate diverse user responses aligned with specified personality traits, thereby prompting CRSs to dynamically adjust their recommendation strategies. Our experimental analysis offers empirical insights into the impact of personality traits on the outcomes of conversational recommender systems.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12313.pdf", "abstract_url": "https://arxiv.org/abs/2504.12313", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了人格特质对对话推荐系统（CRSs）的影响，通过大型语言模型（LLMs）进行模拟，提出了一个基于LLM的人格感知用户模拟系统（PerCRS），该系统能够根据用户的人格特质动态调整推荐策略。", "motivation": "对话推荐系统（CRSs）通过多轮交互为用户提供个性化推荐，大型语言模型（LLMs）的出现进一步提升了这些系统的交互自然性和动态性。然而，理解人格特质如何影响对话推荐结果仍是一个关键挑战。", "method": "我们引入了基于LLM的人格感知用户模拟系统（PerCRS），用户代理能够诱导可定制的人格特质和偏好，系统代理则具备说服能力，以模拟CRSs中的真实交互。我们采用多方面评估以确保鲁棒性，并从用户和系统两个角度进行广泛分析。", "result": "实验结果表明，最先进的LLMs能够有效生成与指定人格特质一致的用户多样化响应，从而促使CRSs动态调整其推荐策略。", "conclusion": "我们的实验分析为理解人格特质对对话推荐系统结果的影响提供了实证见解，展示了LLMs在模拟人格感知用户交互中的潜力。"}}
{"id": "2504.12345", "title": "Reimagining Urban Science: Scaling Causal Inference with Large Language Models", "authors": ["Yutong Xia", "Ao Qu", "Yunhan Zheng", "Yihong Tang", "Dingyi Zhuang", "Yuxuan Liang", "Cathy Wu", "Roger Zimmermann", "Jinhua Zhao"], "abstract": "Urban causal research is essential for understanding the complex dynamics of cities and informing evidence-based policies. However, it is challenged by the inefficiency and bias of hypothesis generation, barriers to multimodal data complexity, and the methodological fragility of causal experimentation. Recent advances in large language models (LLMs) present an opportunity to rethink how urban causal analysis is conducted. This Perspective examines current urban causal research by analyzing taxonomies that categorize research topics, data sources, and methodological approaches to identify structural gaps. We then introduce an LLM-driven conceptual framework, AutoUrbanCI, composed of four distinct modular agents responsible for hypothesis generation, data engineering, experiment design and execution, and results interpretation with policy recommendations. We propose evaluation criteria for rigor and transparency and reflect on implications for human-AI collaboration, equity, and accountability. We call for a new research agenda that embraces AI-augmented workflows not as replacements for human expertise but as tools to broaden participation, improve reproducibility, and unlock more inclusive forms of urban causal reasoning.", "subjects": "Computation and Language (cs.CL); Computers and Society (cs.CY); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12345.pdf", "abstract_url": "https://arxiv.org/abs/2504.12345", "categories": ["Computation and Language (cs.CL)", "Computers and Society (cs.CY)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种利用大型语言模型（LLMs）重新构想城市科学的方法，特别是通过AutoUrbanCI框架来提升城市因果研究的效率和广度。", "motivation": "城市因果研究对于理解城市的复杂动态和制定基于证据的政策至关重要，但目前面临假设生成的效率和偏见、多模态数据复杂性的障碍以及因果实验方法脆弱性等挑战。", "method": "引入了一个由四个独立模块化代理组成的LLM驱动概念框架AutoUrbanCI，分别负责假设生成、数据工程、实验设计与执行以及结果解释与政策建议。", "result": "提出了评估严谨性和透明度的标准，并反思了人机协作、公平性和责任性的影响。", "conclusion": "呼吁一个新的研究议程，将AI增强的工作流程视为拓宽参与、提高可重复性并解锁更包容的城市因果推理形式的工具，而非替代人类专业知识。"}}
{"id": "2504.12546", "title": "Anonymous Public Announcements", "authors": ["Thomas Ågotnes", "Rustam Galimullin", "Ken Satoh", "Satoshi Tojo"], "abstract": "We formalise the notion of an \\emph{anonymous public announcement} in the tradition of public announcement logic. Such announcements can be seen as in-between a public announcement from ``the outside\" (an announcement of $\\phi$) and a public announcement by one of the agents (an announcement of $K_a\\phi$): we get more information than just $\\phi$, but not (necessarily) about exactly who made it. Even if such an announcement is prima facie anonymous, depending on the background knowledge of the agents it might reveal the identity of the announcer: if I post something on a message board, the information might reveal who I am even if I don't sign my name. Furthermore, like in the Russian Cards puzzle, if we assume that the announcer's intention was to stay anonymous, that in fact might reveal more information. In this paper we first look at the case when no assumption about intentions are made, in which case the logic with an anonymous public announcement operator is reducible to epistemic logic. We then look at the case when we assume common knowledge of the intention to stay anonymous, which is both more complex and more interesting: in several ways it boils down to the notion of a ``safe\" announcement (again, similarly to Russian Cards). Main results include formal expressivity results and axiomatic completeness for key logical languages.", "subjects": "Logic in Computer Science (cs.LO); Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12546.pdf", "abstract_url": "https://arxiv.org/abs/2504.12546", "categories": ["Logic in Computer Science (cs.LO)", "Artificial Intelligence (cs.AI)", "Cryptography and Security (cs.CR)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文在公共公告逻辑的传统中形式化了匿名公共公告的概念，探讨了在不同背景下公告可能揭示公告者身份的情况，并研究了在保持匿名意图的共同知识下的逻辑复杂性。", "motivation": "解决在公共公告中如何形式化和理解匿名公告的问题，特别是在公告可能无意中揭示公告者身份的情况下。", "method": "使用公共公告逻辑和认知逻辑，研究匿名公共公告的形式化表达，并在不同假设下（如无意图假设和共同知识假设）分析其逻辑性质。", "result": "在无意图假设下，匿名公共公告逻辑可简化为认知逻辑；在共同知识假设下，逻辑更为复杂，与“安全”公告概念相关。", "conclusion": "匿名公共公告在不同假设下展现出不同的逻辑性质，特别是在共同知识假设下，其复杂性与安全公告概念密切相关，为理解匿名公告提供了新的视角。"}}
{"id": "2504.12557", "title": "TraCeS: Trajectory Based Credit Assignment From Sparse Safety Feedback", "authors": ["Siow Meng Low", "Akshat Kumar"], "abstract": "In safe reinforcement learning (RL), auxiliary safety costs are used to align the agent to safe decision making. In practice, safety constraints, including cost functions and budgets, are unknown or hard to specify, as it requires anticipation of all possible unsafe behaviors. We therefore address a general setting where the true safety definition is unknown, and has to be learned from sparsely labeled data. Our key contributions are: first, we design a safety model that performs credit assignment to estimate each decision step's impact on the overall safety using a dataset of diverse trajectories and their corresponding binary safety labels (i.e., whether the corresponding trajectory is safe/unsafe). Second, we illustrate the architecture of our safety model to demonstrate its ability to learn a separate safety score for each timestep. Third, we reformulate the safe RL problem using the proposed safety model and derive an effective algorithm to optimize a safe yet rewarding policy. Finally, our empirical results corroborate our findings and show that this approach is effective in satisfying unknown safety definition, and scalable to various continuous control tasks.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12557.pdf", "abstract_url": "https://arxiv.org/abs/2504.12557", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于轨迹的稀疏安全反馈信用分配方法（TraCeS），用于在安全强化学习中学习未知的安全定义，并通过实验验证了其有效性。", "motivation": "在安全强化学习中，安全约束（包括成本函数和预算）通常是未知或难以指定的，因为这需要预测所有可能的不安全行为。本文旨在解决安全定义未知且需要从稀疏标记数据中学习的一般设置问题。", "method": "首先，设计了一个安全模型，通过信用分配来估计每个决策步骤对整体安全的影响；其次，展示了安全模型的架构，证明其能够为每个时间步学习单独的安全分数；第三，使用提出的安全模型重新制定了安全强化学习问题，并推导出一个有效的算法来优化安全且有益的策略。", "result": "实证结果支持了我们的发现，表明这种方法在满足未知安全定义方面是有效的，并且可以扩展到各种连续控制任务。", "conclusion": "本文提出的TraCeS方法能够有效地从稀疏的安全反馈中学习安全定义，并在多种连续控制任务中实现安全且有益的决策。"}}
{"id": "2504.12563", "title": "MetaSynth: Meta-Prompting-Driven Agentic Scaffolds for Diverse Synthetic Data Generation", "authors": ["Haris Riaz", "Sourav Bhabesh", "Vinayak Arannil", "Miguel Ballesteros", "Graham Horwood"], "abstract": "Recent smaller language models such Phi-3.5 and Phi-4 rely on synthetic data generated using larger Language models. Questions remain about leveraging synthetic data for other use cases, such as adapting LLMs to specific domains. A key limitation of synthetic data is low diversity, which negatively impacts its downstream applicability for improving other models. To address this, we propose MetaSynth, a method for generating synthetic data that enhances diversity through meta-prompting, where a language model orchestrates multiple \"expert\" LLM agents to collaboratively generate data. Using only 25 million tokens of synthetic data generated with MetaSynth, we successfully adapt a well-trained LLM (Mistral-7B-v0.3) to two specialized domains-Finance and Biomedicine-without compromising the capabilities of the resulting model in general tasks. In addition, we evaluate the diversity of our synthetic data using seven automated metrics, and find that it approaches the diversity of LLM pre-training corpora.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "33 pages, 17 figures. Preprint", "pdf_url": "https://arxiv.org/pdf/2504.12563.pdf", "abstract_url": "https://arxiv.org/abs/2504.12563", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "MetaSynth提出了一种通过元提示驱动多专家LLM代理协作生成合成数据的方法，以提高数据多样性，成功将Mistral-7B-v0.3模型适配到金融和生物医学领域。", "motivation": "解决合成数据多样性不足的问题，以提升其在特定领域适配LLM时的下游应用效果。", "method": "使用元提示技术，让一个语言模型协调多个“专家”LLM代理共同生成数据。", "result": "仅用2500万标记的MetaSynth合成数据，成功将Mistral-7B-v0.3模型适配到金融和生物医学领域，且不损害其在通用任务上的能力。", "conclusion": "MetaSynth生成的合成数据在多样性上接近LLM预训练语料库，为特定领域适配LLM提供了有效途径。"}}
{"id": "2504.12516", "title": "BrowseComp: A Simple Yet Challenging Benchmark for Browsing Agents", "authors": ["Jason Wei", "Zhiqing Sun", "Spencer Papay", "Scott McKinney", "Jeffrey Han", "Isa Fulford", "Hyung Won Chung", "Alex Tachard Passos", "William Fedus", "Amelia Glaese"], "abstract": "We present BrowseComp, a simple yet challenging benchmark for measuring the ability for agents to browse the web. BrowseComp comprises 1,266 questions that require persistently navigating the internet in search of hard-to-find, entangled information. Despite the difficulty of the questions, BrowseComp is simple and easy-to-use, as predicted answers are short and easily verifiable against reference answers. BrowseComp for browsing agents can be seen as analogous to how programming competitions are an incomplete but useful benchmark for coding agents. While BrowseComp sidesteps challenges of a true user query distribution, like generating long answers or resolving ambiguity, it measures the important core capability of exercising persistence and creativity in finding information. BrowseComp can be found at", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12516.pdf", "abstract_url": "https://arxiv.org/abs/2504.12516", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "介绍了BrowseComp，一个简单但具有挑战性的基准测试，用于评估网页浏览代理的能力。", "motivation": "解决评估代理在网络上持久导航和寻找难以找到的纠缠信息能力的问题。", "method": "创建包含1,266个问题的基准测试，这些问题需要代理在互联网上持续导航以寻找信息。", "result": "BrowseComp提供了一个简单易用但具有挑战性的测试平台，能够有效评估代理的持久性和创造性。", "conclusion": "BrowseComp作为浏览代理的基准测试，虽然不完全模拟真实用户查询分布，但有效测量了代理在寻找信息时的核心能力。"}}
{"id": "2504.12673", "title": "ACoRN: Noise-Robust Abstractive Compression in Retrieval-Augmented Language Models", "authors": ["Singon Kim", "Gunho Jung", "Seong-Whan Lee"], "abstract": "Abstractive compression utilizes smaller langauge models to condense query-relevant context, reducing computational costs in retrieval-augmented generation (RAG). However,retrieved documents often include information that is either irrelevant to answering the query or misleading due to factual incorrect content, despite having high relevance scores. This behavior indicates that abstractive compressors are more likely to omit important information essential for the correct answer, especially in long contexts where attention dispersion occurs. To address this issue, we categorize retrieved documents in a more fine-grained manner and propose Abstractive Compression Robust against Noise (ACoRN), which introduces two novel training steps. First, we use offline data augmentation on the training dataset to enhance compressor robustness against two distinct types of retrieval noise. Second, since the language modelbased compressor cannot fully utilize information from multiple retrieved documents and exhibits positional bias, we perform finetuning to generate summaries centered around key information that directly supports the correct answer. Our experiments demonstrate that T5-large, trained with ACoRN as a compressor, improves EM and F1 scores while preserving the answer string, which could serve as direct evidence. ACoRN excels on datasets with many accuracy-reducing documents, making it highly useful in real-world scenarios.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12673.pdf", "abstract_url": "https://arxiv.org/abs/2504.12673", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "ACoRN提出了一种针对检索增强语言模型的噪声鲁棒性抽象压缩方法，通过细粒度分类检索文档和引入两个新颖的训练步骤，提高了压缩模型在存在噪声情况下的性能。", "motivation": "解决在检索增强生成（RAG）中，由于检索到的文档可能包含无关或误导信息，导致抽象压缩模型忽略重要信息的问题。", "method": "首先，使用离线数据增强训练数据集以增强压缩模型对两种检索噪声的鲁棒性；其次，通过微调使模型能够围绕支持正确答案的关键信息生成摘要。", "result": "实验表明，采用ACoRN训练的T5-large作为压缩器，在保持答案字符串的同时，提高了EM和F1分数，尤其在包含大量降低准确性文档的数据集上表现优异。", "conclusion": "ACoRN在现实世界场景中非常有用，特别是在处理包含大量噪声文档的情况下，能够有效提高抽象压缩的准确性和鲁棒性。"}}
{"id": "2504.12714", "title": "Cross-environment Cooperation Enables Zero-shot Multi-agent Coordination", "authors": ["Kunal Jha", "Wilka Carvalho", "Yancheng Liang", "Simon S. Du", "Max Kleiman-Weiner", "Natasha Jaques"], "abstract": "Zero-shot coordination (ZSC), the ability to adapt to a new partner in a cooperative task, is a critical component of human-compatible AI. While prior work has focused on training agents to cooperate on a single task, these specialized models do not generalize to new tasks, even if they are highly similar. Here, we study how reinforcement learning on a distribution of environments with a single partner enables learning general cooperative skills that support ZSC with many new partners on many new problems. We introduce two Jax-based, procedural generators that create billions of solvable coordination challenges. We develop a new paradigm called Cross-Environment Cooperation (CEC), and show that it outperforms competitive baselines quantitatively and qualitatively when collaborating with real people. Our findings suggest that learning to collaborate across many unique scenarios encourages agents to develop general norms, which prove effective for collaboration with different partners. Together, our results suggest a new route toward designing generalist cooperative agents capable of interacting with humans without requiring human data.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "Accepted to CogSci 2025, In-review for ICML 2025", "pdf_url": "https://arxiv.org/pdf/2504.12714.pdf", "abstract_url": "https://arxiv.org/abs/2504.12714", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究了如何通过在不同环境中的强化学习训练，使AI代理能够零样本协调（ZSC）与多个新伙伴在新任务上合作。通过引入两个Jax-based的程序生成器和跨环境合作（CEC）新范式，研究表明这种方法在与人合作时优于竞争基线。", "motivation": "解决AI代理在零样本协调（ZSC）中与不同伙伴在新任务上合作的能力不足问题，特别是在没有人类数据的情况下。", "method": "使用强化学习在多个环境中与单一伙伴训练，引入两个Jax-based的程序生成器创建大量可解决的协调挑战，并开发跨环境合作（CEC）新范式。", "result": "CEC在与人合作时在数量和质量上均优于竞争基线，表明通过学习在多种独特场景中合作，代理能够发展出有效的通用规范。", "conclusion": "研究提出了一种新的方法，通过跨环境合作训练，设计出能够无需人类数据即可与人类交互的通用合作代理。"}}
{"id": "2504.12722", "title": "SimUSER: Simulating User Behavior with Large Language Models for Recommender System Evaluation", "authors": ["Nicolas Bougie", "Narimasa Watanabe"], "abstract": "Recommender systems play a central role in numerous real-life applications, yet evaluating their performance remains a significant challenge due to the gap between offline metrics and online behaviors. Given the scarcity and limits (e.g., privacy issues) of real user data, we introduce SimUSER, an agent framework that serves as believable and cost-effective human proxies. SimUSER first identifies self-consistent personas from historical data, enriching user profiles with unique backgrounds and personalities. Then, central to this evaluation are users equipped with persona, memory, perception, and brain modules, engaging in interactions with the recommender system. SimUSER exhibits closer alignment with genuine humans than prior work, both at micro and macro levels. Additionally, we conduct insightful experiments to explore the effects of thumbnails on click rates, the exposure effect, and the impact of reviews on user engagement. Finally, we refine recommender system parameters based on offline A/B test results, resulting in improved user engagement in the real world.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12722.pdf", "abstract_url": "https://arxiv.org/abs/2504.12722", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了SimUSER，一个用于模拟用户行为以评估推荐系统性能的代理框架。通过创建具有个性化背景和性格的用户代理，SimUSER在微观和宏观层面上更接近真实用户行为，为推荐系统的离线评估提供了一种可信且成本效益高的方法。", "motivation": "推荐系统在现实应用中扮演着重要角色，但由于离线指标与在线行为之间的差距，评估其性能仍面临挑战。真实用户数据的稀缺和限制（如隐私问题）促使了SimUSER的提出。", "method": "SimUSER框架首先从历史数据中识别自我一致的角色，丰富用户档案的独特背景和个性。然后，通过配备角色、记忆、感知和大脑模块的用户代理与推荐系统进行交互。", "result": "SimUSER在微观和宏观层面上显示出与真实用户更接近的对齐。实验还探讨了缩略图对点击率的影响、曝光效应以及评论对用户参与度的影响。基于离线A/B测试结果优化推荐系统参数，提高了现实世界中的用户参与度。", "conclusion": "SimUSER作为一种可信且成本效益高的用户代理框架，为推荐系统的评估提供了一种新方法，能够更准确地模拟真实用户行为，从而优化推荐系统的性能。"}}
{"id": "2504.12734", "title": "Pandora: A Code-Driven Large Language Model Agent for Unified Reasoning Across Diverse Structured Knowledge", "authors": ["Yongrui Chen", "Junhao He", "Linbo Fu", "Shenyu Zhang", "Rihui Jin", "Xinbang Dai", "Jiaqi Li", "Dehai Min", "Nan Hu", "Yuxin Zhang", "Guilin Qi", "Yi Huang", "Tongtong Wu"], "abstract": "Unified Structured Knowledge Reasoning (USKR) aims to answer natural language questions (NLQs) by using structured sources such as tables, databases, and knowledge graphs in a unified way. Existing USKR methods either rely on employing task-specific strategies or custom-defined representations, which struggle to leverage the knowledge transfer between different SKR tasks or align with the prior of LLMs, thereby limiting their performance. This paper proposes a novel USKR framework named \\textsc{Pandora}, which takes advantage of \\textsc{Python}'s \\textsc{Pandas} API to construct a unified knowledge representation for alignment with LLM pre-training. It employs an LLM to generate textual reasoning steps and executable Python code for each question. Demonstrations are drawn from a memory of training examples that cover various SKR tasks, facilitating knowledge transfer. Extensive experiments on four benchmarks involving three SKR tasks demonstrate that \\textsc{Pandora} outperforms existing unified frameworks and competes effectively with task-specific methods.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12734.pdf", "abstract_url": "https://arxiv.org/abs/2504.12734", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "Pandora是一个基于代码驱动的大型语言模型代理，旨在通过统一的Python Pandas API表示结构化知识，实现跨不同结构化知识推理任务的统一推理。", "motivation": "解决现有统一结构化知识推理(USKR)方法因依赖任务特定策略或自定义表示而难以利用不同SKR任务间的知识转移或与LLMs先验对齐，从而限制性能的问题。", "method": "利用Python的Pandas API构建统一的知识表示以与LLM预训练对齐，使用LLM生成文本推理步骤和可执行的Python代码，并从覆盖各种SKR任务的训练示例中提取演示以促进知识转移。", "result": "在涉及三个SKR任务的四个基准测试上的广泛实验表明，Pandora优于现有的统一框架，并能有效与任务特定方法竞争。", "conclusion": "Pandora通过统一的代码驱动方法，有效地实现了跨不同结构化知识推理任务的统一推理，展示了在USKR任务中的优越性能和潜力。"}}
{"id": "2504.12735", "title": "The Athenian Academy: A Seven-Layer Architecture Model for Multi-Agent Systems", "authors": ["Lidong Zhai", "Zhijie Qiu", "Xizhong Guo", "Jiaqi Li"], "abstract": "This paper proposes the \"Academy of Athens\" multi-agent seven-layer framework, aimed at systematically addressing challenges in multi-agent systems (MAS) within artificial intelligence (AI) art creation, such as collaboration efficiency, role allocation, environmental adaptation, and task parallelism. The framework divides MAS into seven layers: multi-agent collaboration, single-agent multi-role playing, single-agent multi-scene traversal, single-agent multi-capability incarnation, different single agents using the same large model to achieve the same target agent, single-agent using different large models to achieve the same target agent, and multi-agent synthesis of the same target agent. Through experimental validation in art creation, the framework demonstrates its unique advantages in task collaboration, cross-scene adaptation, and model fusion. This paper further discusses current challenges such as collaboration mechanism optimization, model stability, and system security, proposing future exploration through technologies like meta-learning and federated learning. The framework provides a structured methodology for multi-agent collaboration in AI art creation and promotes innovative applications in the art field.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12735.pdf", "abstract_url": "https://arxiv.org/abs/2504.12735", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一个名为'雅典学院'的多智能体七层框架，旨在系统解决人工智能艺术创作中多智能体系统面临的协作效率、角色分配、环境适应和任务并行等挑战。", "motivation": "解决多智能体系统在人工智能艺术创作中的协作效率、角色分配、环境适应和任务并行等问题。", "method": "提出了一个七层框架，包括多智能体协作、单智能体多角色扮演、单智能体多场景遍历、单智能体多能力化身、不同单智能体使用同一大模型实现同一目标智能体、单智能体使用不同大模型实现同一目标智能体，以及多智能体合成同一目标智能体。", "result": "在艺术创作中的实验验证表明，该框架在任务协作、跨场景适应和模型融合方面具有独特优势。", "conclusion": "该框架为人工智能艺术创作中的多智能体协作提供了结构化方法，并促进了艺术领域的创新应用。同时，讨论了当前面临的挑战，如协作机制优化、模型稳定性和系统安全性，并提出了通过元学习和联邦学习等技术进行未来探索的方向。"}}
{"id": "2504.12560", "title": "CDF-RAG: Causal Dynamic Feedback for Adaptive Retrieval-Augmented Generation", "authors": ["Elahe Khatibi", "Ziyu Wang", "Amir M. Rahmani"], "abstract": "Retrieval-Augmented Generation (RAG) has significantly enhanced large language models (LLMs) in knowledge-intensive tasks by incorporating external knowledge retrieval. However, existing RAG frameworks primarily rely on semantic similarity and correlation-driven retrieval, limiting their ability to distinguish true causal relationships from spurious associations. This results in responses that may be factually grounded but fail to establish cause-and-effect mechanisms, leading to incomplete or misleading insights. To address this issue, we introduce Causal Dynamic Feedback for Adaptive Retrieval-Augmented Generation (CDF-RAG), a framework designed to improve causal consistency, factual accuracy, and explainability in generative reasoning. CDF-RAG iteratively refines queries, retrieves structured causal graphs, and enables multi-hop causal reasoning across interconnected knowledge sources. Additionally, it validates responses against causal pathways, ensuring logically coherent and factually grounded outputs. We evaluate CDF-RAG on four diverse datasets, demonstrating its ability to improve response accuracy and causal correctness over existing RAG-based methods. Our code is publicly available at", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12560.pdf", "abstract_url": "https://arxiv.org/abs/2504.12560", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "CDF-RAG是一种旨在通过迭代优化查询、检索结构化因果图并进行多跳因果推理来提高生成推理中因果一致性、事实准确性和可解释性的框架。", "motivation": "现有的RAG框架主要依赖语义相似性和相关性驱动的检索，难以区分真实的因果关系与虚假的关联，导致生成的反应可能基于事实但缺乏因果机制，产生不完整或误导性的见解。", "method": "CDF-RAG框架通过迭代细化查询、检索结构化因果图、实现跨互联知识源的多跳因果推理，并根据因果路径验证反应，确保逻辑一致和事实基础。", "result": "在四个不同的数据集上评估CDF-RAG，证明其能够提高反应准确性和因果正确性，优于现有的基于RAG的方法。", "conclusion": "CDF-RAG通过改进因果一致性和事实准确性，为知识密集型任务中的大型语言模型提供了更可靠的生成推理能力，其代码已公开。"}}
{"id": "2504.12757", "title": "MCP Guardian: A Security-First Layer for Safeguarding MCP-Based AI System", "authors": ["Sonu Kumar", "Anubhav Girdhar", "Ritesh Patil", "Divyansh Tripathi"], "abstract": "As Agentic AI gain mainstream adoption, the industry invests heavily in model capabilities, achieving rapid leaps in reasoning and quality. However, these systems remain largely confined to data silos, and each new integration requires custom logic that is difficult to scale. The Model Context Protocol (MCP) addresses this challenge by defining a universal, open standard for securely connecting AI-based applications (MCP clients) to data sources (MCP servers). However, the flexibility of the MCP introduces new risks, including malicious tool servers and compromised data integrity. We present MCP Guardian, a framework that strengthens MCP-based communication with authentication, rate-limiting, logging, tracing, and Web Application Firewall (WAF) scanning. Through real-world scenarios and empirical testing, we demonstrate how MCP Guardian effectively mitigates attacks and ensures robust oversight with minimal overheads. Our approach fosters secure, scalable data access for AI assistants, underscoring the importance of a defense-in-depth approach that enables safer and more transparent innovation in AI-driven environments.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12757.pdf", "abstract_url": "https://arxiv.org/abs/2504.12757", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了MCP Guardian，一个为基于MCP的AI系统提供安全保护的框架，通过认证、速率限制、日志记录、追踪和WAF扫描等措施，有效减轻攻击并确保强健的监督，同时最小化开销。", "motivation": "随着Agentic AI的普及，行业在模型能力上投入巨大，实现了推理和质量的快速提升。然而，这些系统大多局限于数据孤岛，每次新的集成都需要难以扩展的自定义逻辑。MCP通过定义一个通用的、开放的标准来解决这一挑战，但MCP的灵活性也带来了新的风险。", "method": "提出了MCP Guardian框架，通过实施认证、速率限制、日志记录、追踪和WAF扫描等措施，加强基于MCP的通信安全。", "result": "通过真实场景和实证测试，证明了MCP Guardian能够有效减轻攻击，确保强健的监督，同时保持最小开销。", "conclusion": "MCP Guardian促进了AI助手的安全、可扩展数据访问，强调了深度防御方法在实现AI驱动环境中更安全、更透明创新的重要性。"}}
{"id": "2504.12777", "title": "Multi-Agent Reinforcement Learning Simulation for Environmental Policy Synthesis", "authors": ["James Rudd-Jones", "Mirco Musolesi", "María Pérez-Ortiz"], "abstract": "Climate policy development faces significant challenges due to deep uncertainty, complex system dynamics, and competing stakeholder interests. Climate simulation methods, such as Earth System Models, have become valuable tools for policy exploration. However, their typical use is for evaluating potential polices, rather than directly synthesizing them. The problem can be inverted to optimize for policy pathways, but the traditional optimization approaches often struggle with non-linear dynamics, heterogeneous agents, and comprehensive uncertainty quantification. We propose a framework for augmenting climate simulations with Multi-Agent Reinforcement Learning (MARL) to address these limitations. We identify key challenges at the interface between climate simulations and the application of MARL in the context of policy synthesis, including reward definition, scalability with increasing agents and state spaces, uncertainty propagation across linked systems, and solution validation. Additionally, we discuss challenges in making MARL-derived solutions interpretable and useful for policy-makers. Our framework provides a foundation for more sophisticated climate policy exploration while acknowledging important limitations and areas for future research.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": "Published in AAMAS'25 Blue Sky Ideas Track", "pdf_url": "https://arxiv.org/pdf/2504.12777.pdf", "abstract_url": "https://arxiv.org/abs/2504.12777", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种利用多智能体强化学习（MARL）增强气候模拟的框架，以解决气候政策制定中的深层次不确定性、复杂系统动态和利益相关者竞争问题。", "motivation": "气候政策发展面临深层次不确定性、复杂系统动态和利益相关者竞争等挑战，传统的气候模拟方法主要用于评估潜在政策，而非直接合成政策。传统优化方法在处理非线性动态、异质智能体和全面不确定性量化方面存在困难。", "method": "提出一个框架，通过多智能体强化学习（MARL）增强气候模拟，以解决政策合成中的奖励定义、可扩展性、不确定性传播和解决方案验证等关键挑战。", "result": "该框架为更复杂的气候政策探索提供了基础，同时承认了重要的局限性和未来研究的领域。", "conclusion": "通过结合MARL和气候模拟，可以更有效地合成气候政策，但需要进一步研究以提高解决方案的可解释性和对政策制定者的实用性。"}}
{"id": "2504.12891", "title": "Are AI agents the new machine translation frontier? Challenges and opportunities of single- and multi-agent systems for multilingual digital communication", "authors": ["Vicent Briva-Iglesias"], "abstract": "The rapid evolution of artificial intelligence (AI) has introduced AI agents as a disruptive paradigm across various industries, yet their application in machine translation (MT) remains underexplored. This paper describes and analyses the potential of single- and multi-agent systems for MT, reflecting on how they could enhance multilingual digital communication. While single-agent systems are well-suited for simpler translation tasks, multi-agent systems, which involve multiple specialized AI agents collaborating in a structured manner, may offer a promising solution for complex scenarios requiring high accuracy, domain-specific knowledge, and contextual awareness. To demonstrate the feasibility of multi-agent workflows in MT, we are conducting a pilot study in legal MT. The study employs a multi-agent system involving four specialized AI agents for (i) translation, (ii) adequacy review, (iii) fluency review, and (iv) final editing. Our findings suggest that multi-agent systems may have the potential to significantly improve domain-adaptability and contextual awareness, with superior translation quality to traditional MT or single-agent systems. This paper also sets the stage for future research into multi-agent applications in MT, integration into professional translation workflows, and shares a demo of the system analyzed in the paper.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET); Human-Computer Interaction (cs.HC)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12891.pdf", "abstract_url": "https://arxiv.org/abs/2504.12891", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Emerging Technologies (cs.ET)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了AI代理在机器翻译（MT）中的应用潜力，特别是单代理和多代理系统如何提升多语言数字通信。通过法律MT的试点研究，展示了多代理系统在提高翻译质量和领域适应性方面的优势。", "motivation": "探索AI代理在机器翻译领域的应用，解决传统机器翻译或单代理系统在复杂场景下的局限性，如高准确性、领域特定知识和上下文意识的需求。", "method": "采用多代理系统进行法律MT的试点研究，该系统包括四个专业AI代理，分别负责翻译、充分性审查、流畅性审查和最终编辑。", "result": "研究发现，多代理系统在领域适应性和上下文意识方面具有显著优势，翻译质量优于传统MT或单代理系统。", "conclusion": "多代理系统为机器翻译提供了新的可能性，特别是在需要高准确性和专业知识的复杂场景中。本文为未来研究多代理在MT中的应用和集成到专业翻译工作流程中奠定了基础。"}}
{"id": "2504.12951", "title": "Are Retrials All You Need? Enhancing Large Language Model Reasoning Without Verbalized Feedback", "authors": ["Nearchos Potamitis", "Akhil Arora"], "abstract": "Recent advancements in large language models (LLMs) have catalyzed the development of general-purpose autonomous agents, demonstrating remarkable performance in complex reasoning tasks across various domains. This surge has spurred the evolution of a plethora of prompt-based reasoning frameworks. A recent focus has been on iterative reasoning strategies that refine outputs through self-evaluation and verbalized feedback. However, these strategies require additional computational complexity to enable models to recognize and correct their mistakes, leading to a significant increase in their cost. In this work, we introduce the concept of ``retrials without feedback'', an embarrassingly simple yet powerful mechanism for enhancing reasoning frameworks by allowing LLMs to retry problem-solving attempts upon identifying incorrect answers. Unlike conventional iterative refinement methods, our method does not require explicit self-reflection or verbalized feedback, simplifying the refinement process. Our findings indicate that simpler retrial-based approaches often outperform more sophisticated reasoning frameworks, suggesting that the benefits of complex methods may not always justify their computational costs. By challenging the prevailing assumption that more intricate reasoning strategies inherently lead to better performance, our work offers new insights into how simpler, more efficient approaches can achieve optimal results. So, are retrials all you need?", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2504.12951.pdf", "abstract_url": "https://arxiv.org/abs/2504.12951", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种无需反馈的简单重试机制，用于增强大型语言模型的推理能力，挑战了复杂推理策略必然带来更好性能的普遍假设。", "motivation": "解决现有迭代推理策略因需要自我评估和反馈而增加计算复杂性和成本的问题。", "method": "引入了“无需反馈的重试”概念，允许大型语言模型在识别错误答案后重新尝试解决问题，无需显式自我反思或反馈。", "result": "研究发现，基于重试的简单方法往往能超越更复杂的推理框架，表明复杂方法的益处可能并不总是能证明其计算成本的合理性。", "conclusion": "通过展示更简单、更高效的方法可以实现最佳结果，本文为大型语言模型推理框架的设计提供了新的见解。"}}
{"id": "2504.12961", "title": "QLLM: Do We Really Need a Mixing Network for Credit Assignment in Multi-Agent Reinforcement Learning?", "authors": ["Zhouyang Jiang", "Bin Zhang", "Airong Wei", "Zhiwei Xu"], "abstract": "Credit assignment has remained a fundamental challenge in multi-agent reinforcement learning (MARL). Previous studies have primarily addressed this issue through value decomposition methods under the centralized training with decentralized execution paradigm, where neural networks are utilized to approximate the nonlinear relationship between individual Q-values and the global Q-value. Although these approaches have achieved considerable success in various benchmark tasks, they still suffer from several limitations, including imprecise attribution of contributions, limited interpretability, and poor scalability in high-dimensional state spaces. To address these challenges, we propose a novel algorithm, \\textbf{QLLM}, which facilitates the automatic construction of credit assignment functions using large language models (LLMs). Specifically, the concept of \\textbf{TFCAF} is introduced, wherein the credit allocation process is represented as a direct and expressive nonlinear functional formulation. A custom-designed \\textit{coder-evaluator} framework is further employed to guide the generation, verification, and refinement of executable code by LLMs, significantly mitigating issues such as hallucination and shallow reasoning during inference. Extensive experiments conducted on several standard MARL benchmarks demonstrate that the proposed method consistently outperforms existing state-of-the-art baselines. Moreover, QLLM exhibits strong generalization capability and maintains compatibility with a wide range of MARL algorithms that utilize mixing networks, positioning it as a promising and versatile solution for complex multi-agent scenarios.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": "9 pages, 7 figures", "pdf_url": "https://arxiv.org/pdf/2504.12961.pdf", "abstract_url": "https://arxiv.org/abs/2504.12961", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为QLLM的新算法，利用大型语言模型（LLMs）自动构建信用分配函数，以解决多智能体强化学习（MARL）中的信用分配问题。通过引入TFCAF概念和定制设计的coder-evaluator框架，QLLM在多个标准MARL基准测试中表现优异，展示了强大的泛化能力和广泛的兼容性。", "motivation": "解决多智能体强化学习中的信用分配问题，特别是现有方法在贡献归属不精确、可解释性有限和高维状态空间扩展性差等方面的局限性。", "method": "提出QLLM算法，利用大型语言模型自动构建信用分配函数，引入TFCAF概念表示信用分配过程，并采用coder-evaluator框架指导LLMs生成、验证和优化可执行代码。", "result": "在多个标准MARL基准测试中，QLLM consistently outperforms existing state-of-the-art baselines，展示了强大的泛化能力和广泛的兼容性。", "conclusion": "QLLM作为一种新颖且多功能的解决方案，适用于复杂的多智能体场景，为解决MARL中的信用分配问题提供了新的思路。"}}
{"id": "2504.12982", "title": "Accommodate Knowledge Conflicts in Retrieval-augmented LLMs: Towards Reliable Response Generation in the Wild", "authors": ["Jiatai Wang", "Zhiwei Xu", "Di Jin", "Xuewen Yang", "Tao Li"], "abstract": "The proliferation of large language models (LLMs) has significantly advanced information retrieval systems, particularly in response generation (RG). Unfortunately, LLMs often face knowledge conflicts between internal memory and retrievaled external information, arising from misinformation, biases, or outdated knowledge. These conflicts undermine response reliability and introduce uncertainty in decision-making. In this work, we analyze how LLMs navigate knowledge conflicts from an information-theoretic perspective and reveal that when conflicting and supplementary information exhibit significant differences, LLMs confidently resolve their preferences. However, when the distinction is ambiguous, LLMs experience heightened uncertainty. Based on this insight, we propose Swin-VIB, a novel framework that integrates a pipeline of variational information bottleneck models into adaptive augmentation of retrieved information and guiding LLM preference in response generation. Extensive experiments on single-choice, open-ended question-answering (QA), and retrieval augmented generation (RAG) validate our theoretical findings and demonstrate the efficacy of Swin-VIB. Notably, our method improves single-choice task accuracy by at least 7.54\\% over competitive baselines.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12982.pdf", "abstract_url": "https://arxiv.org/abs/2504.12982", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文探讨了大型语言模型(LLMs)在处理内部记忆与检索外部信息之间的知识冲突时的挑战，提出了一种名为Swin-VIB的新框架，旨在通过变分信息瓶颈模型增强检索信息的适应性，并指导LLM在响应生成中的偏好，从而提高响应生成的可靠性。", "motivation": "解决大型语言模型在面对内部记忆与检索到的外部信息之间的知识冲突时，如何提高响应生成的可靠性和减少决策中的不确定性问题。", "method": "提出Swin-VIB框架，该框架集成了一系列变分信息瓶颈模型，用于自适应地增强检索信息并指导LLM在响应生成中的偏好。", "result": "在单选择、开放式问答和检索增强生成任务上的广泛实验验证了理论发现，并显示Swin-VIB的有效性，特别是在单选择任务上比竞争基线至少提高了7.54%的准确率。", "conclusion": "Swin-VIB框架通过有效处理知识冲突，显著提高了大型语言模型在复杂信息环境下的响应生成可靠性和准确性，为未来的信息检索和响应生成系统提供了有价值的参考。"}}
{"id": "2504.12972", "title": "Estimating Optimal Context Length for Hybrid Retrieval-augmented Multi-document Summarization", "authors": ["Adithya Pratapa", "Teruko Mitamura"], "abstract": "Recent advances in long-context reasoning abilities of language models led to interesting applications in large-scale multi-document summarization. However, prior work has shown that these long-context models are not effective at their claimed context windows. To this end, retrieval-augmented systems provide an efficient and effective alternative. However, their performance can be highly sensitive to the choice of retrieval context length. In this work, we present a hybrid method that combines retrieval-augmented systems with long-context windows supported by recent language models. Our method first estimates the optimal retrieval length as a function of the retriever, summarizer, and dataset. On a randomly sampled subset of the dataset, we use a panel of LLMs to generate a pool of silver references. We use these silver references to estimate the optimal context length for a given RAG system configuration. Our results on the multi-document summarization task showcase the effectiveness of our method across model classes and sizes. We compare against length estimates from strong long-context benchmarks such as RULER and HELMET. Our analysis also highlights the effectiveness of our estimation method for very long-context LMs and its generalization to new classes of LMs.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12972.pdf", "abstract_url": "https://arxiv.org/abs/2504.12972", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种结合检索增强系统和长上下文窗口的混合方法，用于多文档摘要任务，通过估计最佳检索长度来提高性能。", "motivation": "解决长上下文模型在声称的上下文窗口中效率不高的问题，以及检索增强系统对检索上下文长度选择的高度敏感性。", "method": "提出一种混合方法，结合检索增强系统和长上下文窗口，首先估计最佳检索长度，然后使用一组LLM生成银参考来估计给定RAG系统配置的最佳上下文长度。", "result": "在多文档摘要任务上展示了方法的有效性，与RULER和HELMET等强长上下文基准相比，表现出色，且对非常长上下文的LM和新类LM的估计方法有效。", "conclusion": "该方法不仅提高了多文档摘要的性能，而且为长上下文LM和新类LM的优化提供了有效的估计方法。"}}
{"id": "2504.13079", "title": "Retrieval-Augmented Generation with Conflicting Evidence", "authors": ["Han Wang", "Archiki Prasad", "Elias Stengel-Eskin", "Mohit Bansal"], "abstract": "Large language model (LLM) agents are increasingly employing retrieval-augmented generation (RAG) to improve the factuality of their responses. However, in practice, these systems often need to handle ambiguous user queries and potentially conflicting information from multiple sources while also suppressing inaccurate information from noisy or irrelevant documents. Prior work has generally studied and addressed these challenges in isolation, considering only one aspect at a time, such as handling ambiguity or robustness to noise and misinformation. We instead consider multiple factors simultaneously, proposing (i) RAMDocs (Retrieval with Ambiguity and Misinformation in Documents), a new dataset that simulates complex and realistic scenarios for conflicting evidence for a user query, including ambiguity, misinformation, and noise; and (ii) MADAM-RAG, a multi-agent approach in which LLM agents debate over the merits of an answer over multiple rounds, allowing an aggregator to collate responses corresponding to disambiguated entities while discarding misinformation and noise, thereby handling diverse sources of conflict jointly. We demonstrate the effectiveness of MADAM-RAG using both closed and open-source models on AmbigDocs -- which requires presenting all valid answers for ambiguous queries -- improving over strong RAG baselines by up to 11.40% and on FaithEval -- which requires suppressing misinformation -- where we improve by up to 15.80% (absolute) with Llama3.3-70B-Instruct. Furthermore, we find that RAMDocs poses a challenge for existing RAG baselines (Llama3.3-70B-Instruct only obtains 32.60 exact match score). While MADAM-RAG begins to address these conflicting factors, our analysis indicates that a substantial gap remains especially when increasing the level of imbalance in supporting evidence and misinformation.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2504.13079.pdf", "abstract_url": "https://arxiv.org/abs/2504.13079", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文提出了一种新的方法MADAM-RAG和一个数据集RAMDocs，用于处理大型语言模型（LLM）在检索增强生成（RAG）中遇到的模糊查询和冲突信息问题，通过多代理辩论机制提高回答的准确性和抑制错误信息。", "motivation": "解决大型语言模型在处理模糊用户查询和来自多个来源的潜在冲突信息时的挑战，同时抑制来自嘈杂或不相关文档的不准确信息。", "method": "提出了RAMDocs数据集模拟复杂和现实的冲突证据场景，以及MADAM-RAG方法，通过多代理辩论机制联合处理冲突信息的多样性。", "result": "MADAM-RAG在AmbigDocs和FaithEval上分别比强RAG基线提高了11.40%和15.80%，但RAMDocs对现有RAG基线仍构成挑战。", "conclusion": "MADAM-RAG开始解决这些冲突因素，但在支持证据和错误信息不平衡的情况下仍存在显著差距。"}}
{"id": "2504.13128", "title": "FreshStack: Building Realistic Benchmarks for Evaluating Retrieval on Technical Documents", "authors": ["Nandan Thakur", "Jimmy Lin", "Sam Havens", "Michael Carbin", "Omar Khattab", "Andrew Drozdov"], "abstract": "We introduce FreshStack, a reusable framework for automatically building information retrieval (IR) evaluation benchmarks from community-asked questions and answers. FreshStack conducts the following steps: (1) automatic corpus collection from code and technical documentation, (2) nugget generation from community-asked questions and answers, and (3) nugget-level support, retrieving documents using a fusion of retrieval techniques and hybrid architectures. We use FreshStack to build five datasets on fast-growing, recent, and niche topics to ensure the tasks are sufficiently challenging. On FreshStack, existing retrieval models, when applied out-of-the-box, significantly underperform oracle approaches on all five topics, denoting plenty of headroom to improve IR quality. In addition, we identify cases where rerankers do not clearly improve first-stage retrieval accuracy (two out of five topics). We hope that FreshStack will facilitate future work toward constructing realistic, scalable, and uncontaminated IR and RAG evaluation benchmarks. FreshStack datasets are available at:", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.13128.pdf", "abstract_url": "https://arxiv.org/abs/2504.13128", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "FreshStack是一个可重复使用的框架，用于从社区提问和答案中自动构建信息检索（IR）评估基准。它通过自动收集代码和技术文档、从社区问答中生成信息块，以及使用检索技术和混合架构的融合来检索文档，构建了五个关于快速发展的、近期和 niche 主题的数据集。现有检索模型在这些数据集上表现不佳，表明有改进IR质量的空间。FreshStack旨在促进构建现实、可扩展且无污染的IR和RAG评估基准。", "motivation": "解决在技术文档上评估信息检索（IR）时缺乏现实、可扩展和未受污染的基准的问题。", "method": "FreshStack框架通过自动收集代码和技术文档、从社区问答中生成信息块，以及使用检索技术和混合架构的融合来检索文档，构建评估基准。", "result": "在五个快速发展的、近期和 niche 主题上，现有检索模型表现不佳，表明有改进IR质量的空间。同时发现，在某些情况下，重新排名器并未明显提高第一阶段检索的准确性。", "conclusion": "FreshStack为构建现实、可扩展且无污染的IR和RAG评估基准提供了有效的框架，有助于未来工作的推进。"}}
{"id": "2504.12408", "title": "A Human-AI Comparative Analysis of Prompt Sensitivity in LLM-Based Relevance Judgment", "authors": ["Negar Arabzadeh", "Charles L. A . Clarke"], "abstract": "Large Language Models (LLMs) are increasingly used to automate relevance judgments for information retrieval (IR) tasks, often demonstrating agreement with human labels that approaches inter-human agreement. To assess the robustness and reliability of LLM-based relevance judgments, we systematically investigate impact of prompt sensitivity on the task. We collected prompts for relevance assessment from 15 human experts and 15 LLMs across three tasks~ -- ~binary, graded, and pairwise~ -- ~yielding 90 prompts in total. After filtering out unusable prompts from three humans and three LLMs, we employed the remaining 72 prompts with three different LLMs as judges to label document/query pairs from two TREC Deep Learning Datasets (2020 and 2021). We compare LLM-generated labels with TREC official human labels using Cohen's $\\kappa$ and pairwise agreement measures. In addition to investigating the impact of prompt variations on agreement with human labels, we compare human- and LLM-generated prompts and analyze differences among different LLMs as judges. We also compare human- and LLM-generated prompts with the standard UMBRELA prompt used for relevance assessment by Bing and TREC 2024 Retrieval Augmented Generation (RAG) Track. To support future research in LLM-based evaluation, we release all data and prompts at", "subjects": "Information Retrieval (cs.IR); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12408.pdf", "abstract_url": "https://arxiv.org/abs/2504.12408", "categories": ["Information Retrieval (cs.IR)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文通过系统研究提示敏感性对基于大型语言模型（LLM）的相关性判断任务的影响，评估了LLM在信息检索任务中的鲁棒性和可靠性。研究收集了人类专家和LLM生成的提示，比较了不同提示下LLM生成标签与人类标签的一致性，并分析了人类和LLM生成提示之间的差异。", "motivation": "评估基于LLM的相关性判断在信息检索任务中的鲁棒性和可靠性，特别是提示敏感性对任务的影响。", "method": "收集了15位人类专家和15个LLM生成的提示，使用三种不同的LLM作为评判者，对来自两个TREC深度学习数据集的文档/查询对进行标签。通过Cohen's κ和成对一致性测量比较LLM生成标签与人类标签的一致性。", "result": "研究发现提示变化对与人类标签的一致性有显著影响，并揭示了人类和LLM生成提示之间的差异。", "conclusion": "研究强调了在LLM基于评估中考虑提示敏感性的重要性，并为未来研究提供了数据和提示资源。"}}
