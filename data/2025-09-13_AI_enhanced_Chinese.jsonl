{"id": "2509.08903", "title": "Noise or Nuance: An Investigation Into Useful Information and Filtering For LLM Driven AKBC", "authors": ["Alex Clay", "Ernesto Jiménez-Ruiz", "Pranava Madhyastha"], "abstract": "RAG and fine-tuning are prevalent strategies for improving the quality of LLM outputs. However, in constrained situations, such as that of the 2025 LM-KBC challenge, such techniques are restricted. In this work we investigate three facets of the triple completion task: generation, quality assurance, and LLM response parsing. Our work finds that in this constrained setting: additional information improves generation quality, LLMs can be effective at filtering poor quality triples, and the tradeoff between flexibility and consistency with LLM response parsing is setting dependent.", "subjects": "Computation and Language (cs.CL)", "comments": "8 pages, 1 figure, accepted to the ISWC 2025 LM-KBC Workshop", "pdf_url": "https://arxiv.org/pdf/2509.08903.pdf", "abstract_url": "https://arxiv.org/abs/2509.08903", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "在受限环境下，研究LLM驱动AKBC中的有用信息与过滤，发现额外信息提升生成质量，LLM可有效过滤低质量三元组，解析灵活性-一致性权衡依赖设置。", "motivation": "解决在受限场景（如2025 LM-KBC挑战）中，RAG和微调受限时，如何提升LLM输出质量的问题。", "method": "调查三元组完成任务的三个层面：生成、质量保证和LLM响应解析。", "result": "额外信息改善生成质量，LLM能有效过滤低质量三元组，解析灵活性与一致性的权衡取决于具体设置。", "conclusion": "在受限设置中，信息过滤和解析策略对LLM性能至关重要，需根据情境调整。"}}
{"id": "2509.08907", "title": "Automated Evidence Extraction and Scoring for Corporate Climate Policy Engagement: A Multilingual RAG Approach", "authors": ["Imene Kolli", "Ario Saeid Vaghefi", "Chiara Colesanti Senni", "Shantam Raj", "Markus Leippold"], "abstract": "InfluenceMap's LobbyMap Platform monitors the climate policy engagement of over 500 companies and 250 industry associations, assessing each entity's support or opposition to science-based policy pathways for achieving the Paris Agreement's goal of limiting global warming to 1.5°C. Although InfluenceMap has made progress with automating key elements of the analytical workflow, a significant portion of the assessment remains manual, making it time- and labor-intensive and susceptible to human error. We propose an AI-assisted framework to accelerate the monitoring of corporate climate policy engagement by leveraging Retrieval-Augmented Generation to automate the most time-intensive extraction of relevant evidence from large-scale textual data. Our evaluation shows that a combination of layout-aware parsing, the Nomic embedding model, and few-shot prompting strategies yields the best performance in extracting and classifying evidence from multilingual corporate documents. We conclude that while the automated RAG system effectively accelerates evidence extraction, the nuanced nature of the analysis necessitates a human-in-the-loop approach where the technology augments, rather than replaces, expert judgment to ensure accuracy.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.08907.pdf", "abstract_url": "https://arxiv.org/abs/2509.08907", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种基于检索增强生成的多语言AI框架，用于自动从企业文档中提取和评分气候政策参与证据，加速监测过程，但仍需人工专家参与以确保准确性。", "motivation": "解决InfluenceMap平台在监测企业气候政策参与时，大量手动评估工作耗时、易错且效率低下的问题。", "method": "采用检索增强生成技术，结合布局感知解析、Nomic嵌入模型和少样本提示策略，从多语言文本数据中自动提取和分类证据。", "result": "评估显示，该方法在证据提取和分类方面性能最佳，有效加速了工作流程。", "conclusion": "自动化RAG系统能显著提升效率，但由于分析的复杂性，需要人机协作，技术应辅助而非替代专家判断。"}}
{"id": "2509.09307", "title": "Can Multimodal LLMs See Materials Clearly? A Multimodal Benchmark on Materials Characterization", "authors": ["Zhengzhao Lai", "Youbin Zheng", "Zhenyang Cai", "Haonan Lyu", "Jinpu Yang", "Hongqing Liang", "Yan Hu", "Benyou Wang"], "abstract": "Materials characterization is fundamental to acquiring materials information, revealing the processing-microstructure-property relationships that guide material design and optimization. While multimodal large language models (MLLMs) have recently shown promise in generative and predictive tasks within materials science, their capacity to understand real-world characterization imaging data remains underexplored. To bridge this gap, we present MatCha, the first benchmark for materials characterization image understanding, comprising 1,500 questions that demand expert-level domain expertise. MatCha encompasses four key stages of materials research comprising 21 distinct tasks, each designed to reflect authentic challenges faced by materials scientists. Our evaluation of state-of-the-art MLLMs on MatCha reveals a significant performance gap compared to human experts. These models exhibit degradation when addressing questions requiring higher-level expertise and sophisticated visual perception. Simple few-shot and chain-of-thought prompting struggle to alleviate these limitations. These findings highlight that existing MLLMs still exhibit limited adaptability to real-world materials characterization scenarios. We hope MatCha will facilitate future research in areas such as new material discovery and autonomous scientific agents. MatCha is available at", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Multimedia (cs.MM)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.09307.pdf", "abstract_url": "https://arxiv.org/abs/2509.09307", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Multimedia (cs.MM)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文介绍了MatCha基准，用于评估多模态大语言模型在材料表征图像理解方面的能力，发现现有模型性能远低于人类专家，并呼吁进一步研究。", "motivation": "解决多模态大语言模型在材料科学中理解真实世界表征成像数据能力不足的问题，以推动材料发现和自主科学代理的发展。", "method": "创建MatCha基准，包含1,500个需要专家级知识的问题，涵盖材料研究的四个阶段和21个任务，并评估现有MLLMs的性能。", "result": "评估显示MLLMs性能显著低于人类专家，在处理需要高级专业知识和视觉感知的问题时表现退化，且少样本和思维链提示无法有效改善。", "conclusion": "现有MLLMs对真实材料表征场景的适应性有限，MatCha基准将促进未来研究，如新材料发现和自主科学代理。"}}
{"id": "2509.08970", "title": "Global Constraint LLM Agents for Text-to-Model Translation", "authors": ["Junyang Cai", "Serdar Kadioglu", "Bistra Dilkina"], "abstract": "Natural language descriptions of optimization or satisfaction problems are challenging to translate into correct MiniZinc models, as this process demands both logical reasoning and constraint programming expertise. We introduce a framework that addresses this challenge with an agentic approach: multiple specialized large language model (LLM) agents decompose the modeling task by global constraint type. Each agent is dedicated to detecting and generating code for a specific class of global constraint, while a final assembler agent integrates these constraint snippets into a complete MiniZinc model. By dividing the problem into smaller, well-defined sub-tasks, each LLM handles a simpler reasoning challenge, potentially reducing overall complexity. We conduct initial experiments with several LLMs and show better performance against baselines such as one-shot prompting and chain-of-thought prompting. Finally, we outline a comprehensive roadmap for future work, highlighting potential enhancements and directions for improvement.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.08970.pdf", "abstract_url": "https://arxiv.org/abs/2509.08970", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种基于多智能体LLM的框架，用于将自然语言描述翻译为MiniZinc模型，通过分解任务提高性能。", "motivation": "解决自然语言描述优化或满足问题翻译为正确MiniZinc模型的挑战，该过程需要逻辑推理和约束编程专业知识。", "method": "使用多个专门LLM代理按全局约束类型分解建模任务，每个代理检测和生成特定约束代码，最后由组装代理集成完整模型。", "result": "初步实验显示，相比一次性提示和思维链提示等基线方法，性能更好。", "conclusion": "框架有效减少复杂性，并提出了未来改进路线图。"}}
{"id": "2509.09071", "title": "Understanding Economic Tradeoffs Between Human and AI Agents in Bargaining Games", "authors": ["Crystal Qian", "Kehang Zhu", "John Horton", "Benjamin S. Manning", "Vivian Tsai", "James Wexler", "Nithum Thain"], "abstract": "Coordination tasks traditionally performed by humans are increasingly being delegated to autonomous agents. As this pattern progresses, it becomes critical to evaluate not only these agents' performance but also the processes through which they negotiate in dynamic, multi-agent environments. Furthermore, different agents exhibit distinct advantages: traditional statistical agents, such as Bayesian models, may excel under well-specified conditions, whereas large language models (LLMs) can generalize across contexts. In this work, we compare humans (N = 216), LLMs (GPT-4o, Gemini 1.5 Pro), and Bayesian agents in a dynamic negotiation setting that enables direct, identical-condition comparisons across populations, capturing both outcomes and behavioral dynamics. Bayesian agents extract the highest surplus through aggressive optimization, at the cost of frequent trade rejections. Humans and LLMs can achieve similar overall surplus, but through distinct behaviors: LLMs favor conservative, concessionary trades with few rejections, while humans employ more strategic, risk-taking, and fairness-oriented behaviors. Thus, we find that performance parity -- a common benchmark in agent evaluation -- can conceal fundamental differences in process and alignment, which are critical for practical deployment in real-world coordination tasks.", "subjects": "Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT); Human-Computer Interaction (cs.HC)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.09071.pdf", "abstract_url": "https://arxiv.org/abs/2509.09071", "categories": ["Artificial Intelligence (cs.AI)", "Computer Science and Game Theory (cs.GT)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "比较人类、大语言模型和贝叶斯代理在动态谈判游戏中的经济权衡，发现性能相似但行为差异显著。", "motivation": "评估自主代理在协调任务中的谈判过程，超越仅关注性能的基准，以理解不同代理的优势和部署影响。", "method": "在相同条件下比较人类、LLMs（GPT-4o、Gemini 1.5 Pro）和贝叶斯代理的谈判行为和结果。", "result": "贝叶斯代理通过激进优化获得最高盈余但拒绝率高；LLMs保守、让步少拒绝；人类策略性、冒险且公平导向，总体盈余相似。", "conclusion": "性能对等可能掩盖过程和一致性差异，这对实际协调任务部署至关重要。"}}
{"id": "2509.09154", "title": "Mind Meets Space: Rethinking Agentic Spatial Intelligence from a Neuroscience-inspired Perspective", "authors": ["Bui Duc Manh", "Soumyaratna Debnath", "Zetong Zhang", "Shriram Damodaran", "Arvind Kumar", "Yueyi Zhang", "Lu Mi", "Erik Cambria", "Lin Wang"], "abstract": "Recent advances in agentic AI have led to systems capable of autonomous task execution and language-based reasoning, yet their spatial reasoning abilities remain limited and underexplored, largely constrained to symbolic and sequential processing. In contrast, human spatial intelligence, rooted in integrated multisensory perception, spatial memory, and cognitive maps, enables flexible, context-aware decision-making in unstructured environments. Therefore, bridging this gap is critical for advancing Agentic Spatial Intelligence toward better interaction with the physical 3D world. To this end, we first start from scrutinizing the spatial neural models as studied in computational neuroscience, and accordingly introduce a novel computational framework grounded in neuroscience principles. This framework maps core biological functions to six essential computation modules: bio-inspired multimodal sensing, multi-sensory integration, egocentric-allocentric conversion, an artificial cognitive map, spatial memory, and spatial reasoning. Together, these modules form a perspective landscape for agentic spatial reasoning capability across both virtual and physical environments. On top, we conduct a framework-guided analysis of recent methods, evaluating their relevance to each module and identifying critical gaps that hinder the development of more neuroscience-grounded spatial reasoning modules. We further examine emerging benchmarks and datasets and explore potential application domains ranging from virtual to embodied systems, such as robotics. Finally, we outline potential research directions, emphasizing the promising roadmap that can generalize spatial reasoning across dynamic or unstructured environments. We hope this work will benefit the research community with a neuroscience-grounded perspective and a structured pathway. Our project page can be found at Github.", "subjects": "Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "comments": "54 pages, journal", "pdf_url": "https://arxiv.org/pdf/2509.09154.pdf", "abstract_url": "https://arxiv.org/abs/2509.09154", "categories": ["Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "该论文从神经科学角度提出一个计算框架，以增强代理AI的空间推理能力，包括多模态感知和认知地图等模块，并分析现有方法、基准和应用。", "motivation": "解决代理AI在空间推理方面的局限性，使其能更好地与物理3D世界交互，借鉴人类空间智能的神经基础。", "method": "基于神经科学原理，开发一个包含六个计算模块的框架，包括多感官整合和人工认知地图，并用于分析现有方法和识别差距。", "result": "框架提供了结构化视角，识别了关键差距，并探讨了在虚拟和物理环境中的应用潜力，如机器人技术。", "conclusion": "该工作为研究社区提供了神经科学基础的观点和路线图，有望推广空间推理到动态或非结构化环境中。"}}
{"id": "2509.09210", "title": "ProgD: Progressive Multi-scale Decoding with Dynamic Graphs for Joint Multi-agent Motion Forecasting", "authors": ["Xing Gao", "Zherui Huang", "Weiyao Lin", "Xiao Sun"], "abstract": "Accurate motion prediction of surrounding agents is crucial for the safe planning of autonomous vehicles. Recent advancements have extended prediction techniques from individual agents to joint predictions of multiple interacting agents, with various strategies to address complex interactions within future motions of agents. However, these methods overlook the evolving nature of these interactions. To address this limitation, we propose a novel progressive multi-scale decoding strategy, termed ProgD, with the help of dynamic heterogeneous graph-based scenario modeling. In particular, to explicitly and comprehensively capture the evolving social interactions in future scenarios, given their inherent uncertainty, we design a progressive modeling of scenarios with dynamic heterogeneous graphs. With the unfolding of such dynamic heterogeneous graphs, a factorized architecture is designed to process the spatio-temporal dependencies within future scenarios and progressively eliminate uncertainty in future motions of multiple agents. Furthermore, a multi-scale decoding procedure is incorporated to improve on the future scenario modeling and consistent prediction of agents' future motion. The proposed ProgD achieves state-of-the-art performance on the INTERACTION multi-agent prediction benchmark, ranking $1^{st}$, and the Argoverse 2 multi-world forecasting benchmark.", "subjects": "Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.09210.pdf", "abstract_url": "https://arxiv.org/abs/2509.09210", "categories": ["Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出ProgD方法，通过动态异构图和渐进多尺度解码改进多智能体运动预测，在基准测试中达到最先进性能。", "motivation": "解决现有方法忽视交互演化的问题，以提升自动驾驶中多智能体运动预测的准确性。", "method": "使用动态异构图建模场景，结合渐进多尺度解码处理时空依赖和不确定性。", "result": "在INTERACTION和Argoverse 2基准测试中排名第一，实现最优性能。", "conclusion": "ProgD方法有效捕捉交互演化，提高预测一致性和准确性，对自动驾驶安全规划有重要意义。"}}
{"id": "2509.09215", "title": "Enabling Regulatory Multi-Agent Collaboration: Architecture, Challenges, and Solutions", "authors": ["Qinnan Hu", "Yuntao Wang", "Yuan Gao", "Zhou Su", "Linkang Du"], "abstract": "Large language models (LLMs)-empowered autonomous agents are transforming both digital and physical environments by enabling adaptive, multi-agent collaboration. While these agents offer significant opportunities across domains such as finance, healthcare, and smart manufacturing, their unpredictable behaviors and heterogeneous capabilities pose substantial governance and accountability challenges. In this paper, we propose a blockchain-enabled layered architecture for regulatory agent collaboration, comprising an agent layer, a blockchain data layer, and a regulatory application layer. Within this framework, we design three key modules: (i) an agent behavior tracing and arbitration module for automated accountability, (ii) a dynamic reputation evaluation module for trust assessment in collaborative scenarios, and (iii) a malicious behavior forecasting module for early detection of adversarial activities. Our approach establishes a systematic foundation for trustworthy, resilient, and scalable regulatory mechanisms in large-scale agent ecosystems. Finally, we discuss the future research directions for blockchain-enabled regulatory frameworks in multi-agent systems.", "subjects": "Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)", "comments": "7 pages, 6 figures", "pdf_url": "https://arxiv.org/pdf/2509.09215.pdf", "abstract_url": "https://arxiv.org/abs/2509.09215", "categories": ["Artificial Intelligence (cs.AI)", "Cryptography and Security (cs.CR)"], "matching_keywords": ["agent"], "AI": {"tldr": "提出基于区块链的分层架构，用于监管多智能体协作，包括行为追踪、声誉评估和恶意行为预测模块，以增强可信度和可扩展性。", "motivation": "解决大语言模型驱动的自主智能体在协作中行为不可预测和异构能力带来的治理与问责挑战。", "method": "设计区块链支持的分层架构，包含智能体层、区块链数据层和监管应用层，并集成行为追踪、声誉评估和恶意行为预测模块。", "result": "建立系统化基础，支持可信、弹性和可扩展的监管机制，适用于大规模智能体生态系统。", "conclusion": "区块链框架为多智能体系统提供有效监管，未来研究方向包括进一步优化和扩展监管机制。"}}
{"id": "2509.09245", "title": "Jupiter: Enhancing LLM Data Analysis Capabilities via Notebook and Inference-Time Value-Guided Search", "authors": ["Shuocheng Li", "Yihao Liu", "Silin Du", "Wenxuan Zeng", "Zhe Xu", "Mengyu Zhou", "Yeye He", "Haoyu Dong", "Shi Han", "Dongmei Zhang"], "abstract": "Large language models (LLMs) have shown great promise in automating data science workflows, but existing models still struggle with multi-step reasoning and tool use, which limits their effectiveness on complex data analysis tasks. To address this, we propose a scalable pipeline that extracts high-quality, tool-based data analysis tasks and their executable multi-step solutions from real-world Jupyter notebooks and associated data files. Using this pipeline, we introduce NbQA, a large-scale dataset of standardized task-solution pairs that reflect authentic tool-use patterns in practical data science scenarios. To further enhance multi-step reasoning, we present Jupiter, a framework that formulates data analysis as a search problem and applies Monte Carlo Tree Search (MCTS) to generate diverse solution trajectories for value model learning. During inference, Jupiter combines the value model and node visit counts to efficiently collect executable multi-step plans with minimal search steps. Experimental results show that Qwen2.5-7B and 14B-Instruct models on NbQA solve 77.82% and 86.38% of tasks on InfiAgent-DABench, respectively-matching or surpassing GPT-4o and advanced agent frameworks. Further evaluations demonstrate improved generalization and stronger tool-use reasoning across diverse multi-step reasoning tasks.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.09245.pdf", "abstract_url": "https://arxiv.org/abs/2509.09245", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文提出了Jupiter框架和NbQA数据集，通过从Jupyter笔记本提取高质量任务-解决方案对，并利用蒙特卡洛树搜索增强多步推理，显著提升了大型语言模型在复杂数据分析任务中的性能。", "motivation": "大型语言模型在自动化数据科学工作流中表现出潜力，但在多步推理和工具使用方面仍存在困难，限制了其在复杂数据分析任务中的有效性。", "method": "提出一个可扩展的管道，从真实Jupyter笔记本提取任务-解决方案对，构建NbQA数据集，并使用蒙特卡洛树搜索进行值模型学习和推理时搜索，以生成可执行的多步计划。", "result": "实验结果显示，Qwen2.5-7B和14B-Instruct模型在NbQA上分别解决了77.82%和86.38%的任务，性能匹配或超越了GPT-4o和先进代理框架，并展示了更好的泛化能力和工具使用推理。", "conclusion": "Jupiter框架有效提升了LLM的数据分析能力，通过结合数据集和搜索方法，为实际数据科学应用提供了更强大的自动化解决方案。"}}
{"id": "2509.09272", "title": "Fusing Knowledge and Language: A Comparative Study of Knowledge Graph-Based Question Answering with LLMs", "authors": ["Vaibhav Chaudhary", "Neha Soni", "Narotam Singh", "Amita Kapoor"], "abstract": "Knowledge graphs, a powerful tool for structuring information through relational triplets, have recently become the new front-runner in enhancing question-answering systems. While traditional Retrieval Augmented Generation (RAG) approaches are proficient in fact-based and local context-based extraction from concise texts, they encounter limitations when addressing the thematic and holistic understanding of complex, extensive texts, requiring a deeper analysis of both text and context. This paper presents a comprehensive technical comparative study of three different methodologies for constructing knowledge graph triplets and integrating them with Large Language Models (LLMs) for question answering: spaCy, Stanford CoreNLP-OpenIE, and GraphRAG, all leveraging open source technologies. We evaluate the effectiveness, feasibility, and adaptability of these methods by analyzing their capabilities, state of development, and their impact on the performance of LLM-based question answering. Experimental results indicate that while OpenIE provides the most comprehensive coverage of triplets, GraphRAG demonstrates superior reasoning abilities among the three. We conclude with a discussion on the strengths and limitations of each method and provide insights into future directions for improving knowledge graph-based question answering.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "46 pages, 4 figures, 17 tables", "pdf_url": "https://arxiv.org/pdf/2509.09272.pdf", "abstract_url": "https://arxiv.org/abs/2509.09272", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文比较了三种知识图谱构建方法（spaCy、Stanford CoreNLP-OpenIE、GraphRAG）与LLMs结合用于问答系统的效果，发现OpenIE覆盖最全，GraphRAG推理最佳。", "motivation": "解决传统RAG方法在处理复杂、长文本时对主题和整体理解的局限性，通过知识图谱增强问答系统。", "method": "使用spaCy、Stanford CoreNLP-OpenIE和GraphRAG构建知识图谱三元组，并与LLMs集成，评估其有效性、可行性和适应性。", "result": "实验结果显示OpenIE提供最全面的三元组覆盖，而GraphRAG在推理能力上表现最优。", "conclusion": "讨论了各方法的优缺点，并提出了改进知识图谱问答的未来方向。"}}
{"id": "2509.09292", "title": "LightAgent: Production-level Open-source Agentic AI Framework", "authors": ["Weige Cai", "Tong Zhu", "Jinyi Niu", "Ruiqi Hu", "Lingyao Li", "Tenglong Wang", "Xiaowu Dai", "Weining Shen", "Liwen Zhang"], "abstract": "With the rapid advancement of large language models (LLMs), Multi-agent Systems (MAS) have achieved significant progress in various application scenarios. However, substantial challenges remain in designing versatile, robust, and efficient platforms for agent deployment. To address these limitations, we propose \\textbf{LightAgent}, a lightweight yet powerful agentic framework, effectively resolving the trade-off between flexibility and simplicity found in existing frameworks. LightAgent integrates core functionalities such as Memory (mem0), Tools, and Tree of Thought (ToT), while maintaining an extremely lightweight structure. As a fully open-source solution, it seamlessly integrates with mainstream chat platforms, enabling developers to easily build self-learning agents. We have released LightAgent at \\href{", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.09292.pdf", "abstract_url": "https://arxiv.org/abs/2509.09292", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "LightAgent是一个轻量级开源多智能体框架，解决现有框架在灵活性与简洁性之间的权衡问题，集成核心功能如记忆、工具和思维树，支持与主流聊天平台无缝集成。", "motivation": "设计多功能、稳健且高效的智能体部署平台，以应对多智能体系统在应用中的挑战。", "method": "提出LightAgent框架，集成Memory (mem0)、Tools和Tree of Thought (ToT)等核心功能，保持轻量级结构，并开源实现。", "result": "框架有效解决了灵活性与简洁性的权衡，便于开发者构建自学习智能体。", "conclusion": "LightAgent作为开源解决方案，促进了智能体技术的易用性和集成性，具有广泛的应用潜力。"}}
{"id": "2509.09234", "title": "Agentic LLMs for Question Answering over Tabular Data", "authors": ["Rishit Tyagi", "Mohit Gupta", "Rahul Bouri"], "abstract": "Question Answering over Tabular Data (Table QA) presents unique challenges due to the diverse structure, size, and data types of real-world tables. The SemEval 2025 Task 8 (DataBench) introduced a benchmark composed of large-scale, domain-diverse datasets to evaluate the ability of models to accurately answer structured queries. We propose a Natural Language to SQL (NL-to-SQL) approach leveraging large language models (LLMs) such as GPT-4o, GPT-4o-mini, and DeepSeek v2:16b to generate SQL queries dynamically. Our system follows a multi-stage pipeline involving example selection, SQL query generation, answer extraction, verification, and iterative refinement. Experiments demonstrate the effectiveness of our approach, achieving 70.5\\% accuracy on DataBench QA and 71.6\\% on DataBench Lite QA, significantly surpassing baseline scores of 26\\% and 27\\% respectively. This paper details our methodology, experimental results, and alternative approaches, providing insights into the strengths and limitations of LLM-driven Table QA.", "subjects": "Computation and Language (cs.CL)", "comments": "Accepted at ACL workshop SemEval 2025", "pdf_url": "https://arxiv.org/pdf/2509.09234.pdf", "abstract_url": "https://arxiv.org/abs/2509.09234", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种基于大型语言模型（如GPT-4o、GPT-4o-mini和DeepSeek v2:16b）的自然语言到SQL方法，用于表格数据问答，通过多阶段管道实现动态SQL查询生成，并在DataBench基准测试中显著提升准确率。", "motivation": "解决表格数据问答中因表格结构、大小和数据类型多样性带来的挑战，利用SemEval 2025 Task 8基准评估模型能力。", "method": "采用多阶段管道，包括示例选择、SQL查询生成、答案提取、验证和迭代优化，利用LLMs生成SQL查询。", "result": "在DataBench QA和DataBench Lite QA上分别达到70.5%和71.6%的准确率，显著超越基线（26%和27%）。", "conclusion": "LLM驱动的表格问答方法有效，但存在局限性，论文提供了方法论和实验结果以指导未来研究。"}}
{"id": "2509.09360", "title": "MetaRAG: Metamorphic Testing for Hallucination Detection in RAG Systems", "authors": ["Channdeth Sok", "David Luz", "Yacine Haddam"], "abstract": "Large Language Models (LLMs) are increasingly deployed in enterprise applications, yet their reliability remains limited by hallucinations, i.e., confident but factually incorrect information. Existing detection approaches, such as SelfCheckGPT and MetaQA, primarily target standalone LLMs and do not address the unique challenges of Retrieval-Augmented Generation (RAG) systems, where responses must be consistent with retrieved evidence. We therefore present MetaRAG, a metamorphic testing framework for hallucination detection in Retrieval-Augmented Generation (RAG) systems. MetaRAG operates in a real-time, unsupervised, black-box setting, requiring neither ground-truth references nor access to model internals, making it suitable for proprietary and high-stakes domains. The framework proceeds in four stages: (1) decompose answers into atomic factoids, (2) generate controlled mutations of each factoid using synonym and antonym substitutions, (3) verify each variant against the retrieved context (synonyms are expected to be entailed and antonyms contradicted), and (4) aggregate penalties for inconsistencies into a response-level hallucination score. Crucially for identity-aware AI, MetaRAG localizes unsupported claims at the factoid span where they occur (e.g., pregnancy-specific precautions, LGBTQ+ refugee rights, or labor eligibility), allowing users to see flagged spans and enabling system designers to configure thresholds and guardrails for identity-sensitive queries. Experiments on a proprietary enterprise dataset illustrate the effectiveness of MetaRAG for detecting hallucinations and enabling trustworthy deployment of RAG-based conversational agents. We also outline a topic-based deployment design that translates MetaRAG's span-level scores into identity-aware safeguards; this design is discussed but not evaluated in our experiments.", "subjects": "Computation and Language (cs.CL)", "comments": "under review", "pdf_url": "https://arxiv.org/pdf/2509.09360.pdf", "abstract_url": "https://arxiv.org/abs/2509.09360", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "MetaRAG是一个用于检测RAG系统中幻觉的无监督黑盒测试框架，通过分解答案、生成变异、验证一致性和聚合分数来识别事实错误。", "motivation": "解决RAG系统中幻觉检测的挑战，现有方法如SelfCheckGPT和MetaQA主要针对独立LLMs，不适用于RAG的检索证据一致性要求。", "method": "使用蜕变测试框架，包括分解答案为事实、生成同义词和反义词变异、验证变异与检索上下文的一致性，并聚合不一致性分数。", "result": "在专有企业数据集上实验显示，MetaRAG能有效检测幻觉，支持可信部署，并定位身份敏感查询中的未支持声明。", "conclusion": "MetaRAG提供了一种实时、无监督的方法，适用于高风险领域，能增强RAG系统的可靠性和身份感知安全措施。"}}
{"id": "2509.09321", "title": "Towards Adaptive ML Benchmarks: Web-Agent-Driven Construction, Domain Expansion, and Metric Optimization", "authors": ["Hangyi Jia", "Yuxi Qian", "Hanwen Tong", "Xinhui Wu", "Lin Chen", "Feng Wei"], "abstract": "Recent advances in large language models (LLMs) have enabled the emergence of general-purpose agents for automating end-to-end machine learning (ML) workflows, including data analysis, feature engineering, model training, and competition solving. However, existing benchmarks remain limited in task coverage, domain diversity, difficulty modeling, and evaluation rigor, failing to capture the full capabilities of such agents in realistic settings. We present TAM Bench, a diverse, realistic, and structured benchmark for evaluating LLM-based agents on end-to-end ML tasks. TAM Bench features three key innovations: (1) A browser automation and LLM-based task acquisition system that automatically collects and structures ML challenges from platforms such as Kaggle, AIcrowd, and Biendata, spanning multiple task types and data modalities (e.g., tabular, text, image, graph, audio); (2) A leaderboard-driven difficulty modeling mechanism that estimates task complexity using participant counts and score dispersion, enabling scalable and objective task calibration; (3) A multi-dimensional evaluation framework incorporating performance, format compliance, constraint adherence, and task generalization. Based on 150 curated AutoML tasks, we construct three benchmark subsets of different sizes -- Lite, Medium, and Full -- designed for varying evaluation scenarios. The Lite version, with 18 tasks and balanced coverage across modalities and difficulty levels, serves as a practical testbed for daily benchmarking and comparative studies.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.09321.pdf", "abstract_url": "https://arxiv.org/abs/2509.09321", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "介绍TAM Bench，一个用于评估基于LLM的代理在端到端机器学习任务上的多样化、现实和结构化基准，通过自动任务收集、难度建模和多维评估来改进现有基准的不足。", "motivation": "现有基准在任务覆盖、领域多样性、难度建模和评估严谨性方面有限，无法充分捕捉LLM代理在真实环境中的能力。", "method": "使用浏览器自动化和LLM的任务获取系统自动收集ML挑战，基于排行榜的难度建模机制，以及多维评估框架。", "result": "基于150个AutoML任务构建了三个不同大小的基准子集（Lite、Medium、Full），Lite版本包含18个任务，覆盖多种模态和难度级别。", "conclusion": "TAM Bench提供了一个可扩展和客观的基准，用于评估LLM代理，支持日常基准测试和比较研究。"}}
{"id": "2509.09356", "title": "Curriculum-Based Multi-Tier Semantic Exploration via Deep Reinforcement Learning", "authors": ["Abdel Hakim Drid", "Vincenzo Suriani", "Daniele Nardi", "Abderrezzak Debilou"], "abstract": "Navigating and understanding complex and unknown environments autonomously demands more than just basic perception and movement from embodied agents. Truly effective exploration requires agents to possess higher-level cognitive abilities, the ability to reason about their surroundings, and make more informed decisions regarding exploration strategies. However, traditional RL approaches struggle to balance efficient exploration and semantic understanding due to limited cognitive capabilities embedded in the small policies for the agents, leading often to human drivers when dealing with semantic exploration. In this paper, we address this challenge by presenting a novel Deep Reinforcement Learning (DRL) architecture that is specifically designed for resource efficient semantic exploration. A key methodological contribution is the integration of a Vision-Language Model (VLM) common-sense through a layered reward function. The VLM query is modeled as a dedicated action, allowing the agent to strategically query the VLM only when deemed necessary for gaining external guidance, thereby conserving resources. This mechanism is combined with a curriculum learning strategy designed to guide learning at different levels of complexity to ensure robust and stable learning. Our experimental evaluation results convincingly demonstrate that our agent achieves significantly enhanced object discovery rates and develops a learned capability to effectively navigate towards semantically rich regions. Furthermore, it also shows a strategic mastery of when to prompt for external environmental information. By demonstrating a practical and scalable method for embedding common-sense semantic reasoning with autonomous agents, this research provides a novel approach to pursuing a fully intelligent and self-guided exploration in robotics.", "subjects": "Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": "The 19th International Conference on Intelligent Autonomous Systems (IAS 19), 2025, Genoa", "pdf_url": "https://arxiv.org/pdf/2509.09356.pdf", "abstract_url": "https://arxiv.org/abs/2509.09356", "categories": ["Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于课程学习的多层级深度强化学习架构，结合视觉语言模型和分层奖励函数，用于资源高效的语义探索，提高对象发现率和导航能力。", "motivation": "解决传统强化学习方法在平衡高效探索和语义理解方面的不足，由于智能体认知能力有限，常导致在语义探索中表现不佳。", "method": "集成视觉语言模型的常识推理作为分层奖励函数，将VLM查询建模为策略性动作，并结合课程学习策略在不同复杂度层级指导学习。", "result": "实验结果显示，智能体显著提高了对象发现率，学会了导航到语义丰富区域，并掌握了何时请求外部环境信息的策略。", "conclusion": "本研究提供了一种实用且可扩展的方法，将常识语义推理嵌入自主智能体，为实现完全智能和自引导的机器人探索提供了新途径。"}}
{"id": "2509.09467", "title": "Inteligencia Artificial jurídica y el desafío de la veracidad: análisis de alucinaciones, optimización de RAG y principios para una integración responsable", "authors": ["Alex Dantart"], "abstract": "This technical report analyzes the challenge of \"hallucinations\" (false information) in LLMs applied to law. It examines their causes, manifestations, and the effectiveness of the RAG mitigation strategy, highlighting its limitations and proposing holistic optimizations. The paper explores the ethical and regulatory implications, emphasizing human oversight as an irreplaceable role. It concludes that the solution lies not in incrementally improving generative models, but in adopting a \"consultative\" AI paradigm that prioritizes veracity and traceability, acting as a tool to amplify, not replace, professional judgment.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "in Spanish and English languages", "pdf_url": "https://arxiv.org/pdf/2509.09467.pdf", "abstract_url": "https://arxiv.org/abs/2509.09467", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "该技术报告分析了法律领域大语言模型中的'幻觉'问题，探讨其成因、表现及RAG缓解策略的有效性和局限性，提出整体优化方案，并强调人类监督的重要性，主张采用咨询式AI范式以优先考虑真实性和可追溯性。", "motivation": "解决法律应用中大语言模型产生虚假信息（幻觉）的问题，以确保信息的准确性和可靠性。", "method": "分析幻觉的成因和表现，评估RAG策略的有效性，并提出优化方法和伦理监管框架。", "result": "RAG策略有局限性，需要结合人类监督和咨询式AI范式来提升真实性和可追溯性。", "conclusion": "解决方案在于采用咨询式AI范式，强调真实性和可追溯性，将AI作为工具增强而非取代专业判断。"}}
{"id": "2509.09498", "title": "SEDM: Scalable Self-Evolving Distributed Memory for Agents", "authors": ["Haoran Xu", "Jiacong Hu", "Ke Zhang", "Lei Yu", "Yuxin Tang", "Xinyuan Song", "Yiqun Duan", "Lynn Ai", "Bill Shi"], "abstract": "Long-term multi-agent systems inevitably generate vast amounts of trajectories and historical interactions, which makes efficient memory management essential for both performance and scalability. Existing methods typically depend on vector retrieval and hierarchical storage, yet they are prone to noise accumulation, uncontrolled memory expansion, and limited generalization across domains. To address these challenges, we present SEDM, Self-Evolving Distributed Memory, a verifiable and adaptive framework that transforms memory from a passive repository into an active, self-optimizing component. SEDM integrates verifiable write admission based on reproducible replay, a self-scheduling memory controller that dynamically ranks and consolidates entries according to empirical utility, and cross-domain knowledge diffusion that abstracts reusable insights to support transfer across heterogeneous tasks. Evaluations on benchmark datasets demonstrate that SEDM improves reasoning accuracy while reducing token overhead compared with strong memory baselines, and further enables knowledge distilled from fact verification to enhance multi-hop reasoning. The results highlight SEDM as a scalable and sustainable memory mechanism for open-ended multi-agent collaboration. The code will be released in the later stage of this project.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.09498.pdf", "abstract_url": "https://arxiv.org/abs/2509.09498", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "SEDM是一种可扩展的自进化分布式内存框架，通过可验证写入、动态调度和跨域知识扩散，提升多智能体系统的记忆管理和泛化能力。", "motivation": "解决多智能体系统中轨迹和历史交互大量积累导致的噪声累积、内存无限扩展和跨域泛化受限问题。", "method": "集成可验证写入准入、自调度内存控制器和跨域知识扩散，将内存从被动存储转变为主动自优化组件。", "result": "在基准数据集上，SEDM提高了推理准确性并减少了令牌开销，支持从事实验证中提取知识增强多跳推理。", "conclusion": "SEDM是开放多智能体协作的可扩展和可持续内存机制，代码将后续发布。"}}
{"id": "2509.09560", "title": "Boosting Embodied AI Agents through Perception-Generation Disaggregation and Asynchronous Pipeline Execution", "authors": ["Shulai Zhang", "Ao Xu", "Quan Chen", "Han Zhao", "Weihao Cui", "Ningxin Zheng", "Haibin Lin", "Xin Liu", "Minyi Guo"], "abstract": "Embodied AI systems operate in dynamic environments, requiring seamless integration of perception and generation modules to process high-frequency input and output demands. Traditional sequential computation patterns, while effective in ensuring accuracy, face significant limitations in achieving the necessary \"thinking\" frequency for real-world applications. In this work, we present Auras, an algorithm-system co-designed inference framework to optimize the inference frequency of embodied AI agents. Auras disaggregates the perception and generation and provides controlled pipeline parallelism for them to achieve high and stable throughput. Faced with the data staleness problem that appears when the parallelism is increased, Auras establishes a public context for perception and generation to share, thereby promising the accuracy of embodied agents. Experimental results show that Auras improves throughput by 2.54x on average while achieving 102.7% of the original accuracy, demonstrating its efficacy in overcoming the constraints of sequential computation and providing high throughput.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.09560.pdf", "abstract_url": "https://arxiv.org/abs/2509.09560", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "Auras框架通过感知-生成解耦和异步流水线执行，提升具身AI代理的推理频率，平均吞吐量提高2.54倍，同时保持102.7%的原始准确率。", "motivation": "解决传统顺序计算模式在动态环境中无法满足高频率输入输出需求的问题，以提高具身AI系统的实时性能。", "method": "采用算法-系统协同设计，解耦感知和生成模块，提供受控的流水线并行执行，并建立共享公共上下文以应对数据过时问题。", "result": "实验显示，Auras平均吞吐量提升2.54倍，准确率达到原始水平的102.7%，证明其有效性和稳定性。", "conclusion": "Auras框架成功克服顺序计算限制，提供高吞吐量，适用于实时具身AI应用，具有实际部署潜力。"}}
{"id": "2509.09677", "title": "The Illusion of Diminishing Returns: Measuring Long Horizon Execution in LLMs", "authors": ["Akshit Sinha", "Arvindh Arun", "Shashwat Goel", "Steffen Staab", "Jonas Geiping"], "abstract": "Does continued scaling of large language models (LLMs) yield diminishing returns? Real-world value often stems from the length of task an agent can complete. We start this work by observing the simple but counterintuitive fact that marginal gains in single-step accuracy can compound into exponential improvements in the length of a task a model can successfully complete. Then, we argue that failures of LLMs when simple tasks are made longer arise from mistakes in execution, rather than an inability to reason. We propose isolating execution capability, by explicitly providing the knowledge and plan needed to solve a long-horizon task. We find that larger models can correctly execute significantly more turns even when small models have 100\\% single-turn accuracy. We observe that the per-step accuracy of models degrades as the number of steps increases. This is not just due to long-context limitations -- curiously, we observe a self-conditioning effect -- models become more likely to make mistakes when the context contains their errors from prior turns. Self-conditioning does not reduce by just scaling the model size. In contrast, recent thinking models do not self-condition, and can also execute much longer tasks in a single turn. We conclude by benchmarking frontier thinking models on the length of task they can execute in a single turn. Overall, by focusing on the ability to execute, we hope to reconcile debates on how LLMs can solve complex reasoning problems yet fail at simple tasks when made longer, and highlight the massive benefits of scaling model size and sequential test-time compute for long-horizon tasks.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.09677.pdf", "abstract_url": "https://arxiv.org/abs/2509.09677", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文探讨了大型语言模型（LLMs）在长视野任务中的执行能力，发现单步准确性的边际提升可导致任务完成长度的指数级改善，并识别了执行错误和自我条件效应作为主要限制因素。", "motivation": "解决LLMs在简单任务延长时失败的问题，挑战规模扩展是否带来收益递减的假设，并强调执行能力而非推理能力是关键。", "method": "通过隔离执行能力，提供知识和计划来评估模型在长视野任务中的表现，并比较不同规模和类型的模型（如思考模型）在单步和多步执行中的准确性。", "result": "大型模型在更多步骤中正确执行，但每步准确性随步骤增加而下降，自我条件效应（错误累积）未被规模扩展缓解；思考模型无此效应，能执行更长任务。", "conclusion": "聚焦执行能力可解释LLMs在复杂推理和简单长任务中的表现差异，强调扩展模型规模和序列测试时间计算对长视野任务的巨大益处。"}}
{"id": "2509.08835", "title": "Deep opacity and AI: A threat to XAI and to privacy protection mechanisms", "authors": ["Vincent C. Müller"], "abstract": "It is known that big data analytics and AI pose a threat to privacy, and that some of this is due to some kind of \"black box problem\" in AI. I explain how this becomes a problem in the context of justification for judgments and actions. Furthermore, I suggest distinguishing three kinds of opacity: 1) the subjects do not know what the system does (\"shallow opacity\"), 2) the analysts do not know what the system does (\"standard black box opacity\"), or 3) the analysts cannot possibly know what the system might do (\"deep opacity\"). If the agents, data subjects as well as analytics experts, operate under opacity, then these agents cannot provide justifications for judgments that are necessary to protect privacy, e.g., they cannot give \"informed consent\", or guarantee \"anonymity\". It follows from these points that agents in big data analytics and AI often cannot make the judgments needed to protect privacy. So I conclude that big data analytics makes the privacy problems worse and the remedies less effective. As a positive note, I provide a brief outlook on technical ways to handle this situation.", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.08835.pdf", "abstract_url": "https://arxiv.org/abs/2509.08835", "categories": ["Computers and Society (cs.CY)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了大数据分析和AI对隐私的威胁，特别是由于AI的'黑箱问题'导致的不透明性，分为浅层、标准和深层不透明，并指出这削弱了隐私保护机制的有效性。", "motivation": "解决AI和大数据分析中不透明性如何加剧隐私问题，并影响判断和行动的正当性。", "method": "区分三种不透明类型（浅层、标准黑箱、深层），并分析其对隐私保护机制（如知情同意和匿名性）的影响。", "result": "发现不透明性使代理无法提供必要的隐私保护判断，导致隐私问题恶化，补救措施效果降低。", "conclusion": "大数据分析加剧了隐私问题，但提供了技术处理方法的简要展望。"}}
{"id": "2509.08859", "title": "Multi Robot Coordination in Highly Dynamic Environments: Tackling Asymmetric Obstacles and Limited Communication", "authors": ["Vincenzo Suriani", "Daniele Affinita", "Domenico D. Bloisi", "Daniele Nardi"], "abstract": "Coordinating a fully distributed multi-agent system (MAS) can be challenging when the communication channel has very limited capabilities in terms of sending rate and packet payload. When the MAS has to deal with active obstacles in a highly partially observable environment, the communication channel acquires considerable relevance. In this paper, we present an approach to deal with task assignments in extremely active scenarios, where tasks need to be frequently reallocated among the agents participating in the coordination process. Inspired by market-based task assignments, we introduce a novel distributed coordination method to orchestrate autonomous agents' actions efficiently in low communication scenarios. In particular, our algorithm takes into account asymmetric obstacles. While in the real world, the majority of obstacles are asymmetric, they are usually treated as symmetric ones, thus limiting the applicability of existing methods. To summarize, the presented architecture is designed to tackle scenarios where the obstacles are active and asymmetric, the communication channel is poor and the environment is partially observable. Our approach has been validated in simulation and in the real world, using a team of NAO robots during official RoboCup competitions. Experimental results show a notable reduction in task overlaps in limited communication settings, with a decrease of 52% in the most frequent reallocated task.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": "The 19th International Conference on Intelligent Autonomous Systems (IAS 19), 2025, Genoa", "pdf_url": "https://arxiv.org/pdf/2509.08859.pdf", "abstract_url": "https://arxiv.org/abs/2509.08859", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种分布式多机器人协调方法，用于高动态环境中处理非对称障碍和有限通信，通过市场启发算法减少任务重叠。", "motivation": "解决多智能体系统在通信受限、环境部分可观测且障碍物非对称的动态场景中的任务分配挑战。", "method": "基于市场机制的新颖分布式协调算法，考虑非对称障碍物和低通信条件。", "result": "在仿真和真实NAO机器人实验中，任务重叠减少52%，验证了方法的有效性。", "conclusion": "该方法提高了多机器人系统在复杂环境中的协调效率，适用于实际应用如RoboCup竞赛。"}}
{"id": "2509.09629", "title": "Bridging the Capability Gap: Joint Alignment Tuning for Harmonizing LLM-based Multi-Agent Systems", "authors": ["Minghang Zhu", "Zhengliang Shi", "Zhiwei Xu", "Shiguang Wu", "Lingjie Wang", "Pengjie Ren", "Zhaochun Ren", "Zhumin Chen"], "abstract": "The advancement of large language models (LLMs) has enabled the construction of multi-agent systems to solve complex tasks by dividing responsibilities among specialized agents, such as a planning agent for subgoal generation and a grounding agent for executing tool-use actions. Most existing methods typically fine-tune these agents independently, leading to capability gaps among them with poor coordination. To address this, we propose MOAT, a Multi-Agent Joint Alignment Tuning framework that improves agents collaboration through iterative alignment. MOAT alternates between two key stages: (1) Planning Agent Alignment, which optimizes the planning agent to generate subgoal sequences that better guide the grounding agent; and (2) Grounding Agent Improving, which fine-tunes the grounding agent using diverse subgoal-action pairs generated by the agent itself to enhance its generalization capablity. Theoretical analysis proves that MOAT ensures a non-decreasing and progressively convergent training process. Experiments across six benchmarks demonstrate that MOAT outperforms state-of-the-art baselines, achieving average improvements of 3.1% on held-in tasks and 4.4% on held-out tasks.", "subjects": "Computation and Language (cs.CL)", "comments": "EMNLP 2025 Findings", "pdf_url": "https://arxiv.org/pdf/2509.09629.pdf", "abstract_url": "https://arxiv.org/abs/2509.09629", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出MOAT框架，通过联合对齐调优解决多智能体系统中的能力差距问题，提升协作性能，在多个基准测试中优于现有方法。", "motivation": "解决独立微调智能体导致的能力差距和协调不佳问题。", "method": "使用MOAT框架，交替进行规划智能体对齐和接地智能体改进的迭代对齐调优。", "result": "在六个基准测试中，MOAT平均提升3.1%（held-in任务）和4.4%（held-out任务），优于最先进基线。", "conclusion": "MOAT确保训练过程非递减且收敛，有效提升多智能体系统的协作和泛化能力。"}}
{"id": "2509.09265", "title": "Harnessing Uncertainty: Entropy-Modulated Policy Gradients for Long-Horizon LLM Agents", "authors": ["Jiawei Wang", "Jiacai Liu", "Yuqian Fu", "Yingru Li", "Xintao Wang", "Yuan Lin", "Yu Yue", "Lin Zhang", "Yang Wang", "Ke Wang"], "abstract": "In long-horizon tasks, recent agents based on Large Language Models (LLMs) face a significant challenge that sparse, outcome-based rewards make it difficult to assign credit to intermediate steps. Previous methods mainly focus on creating dense reward signals to guide learning, either through traditional reinforcement learning techniques like inverse reinforcement learning or by using Process Reward Models for step-by-step feedback. In this paper, we identify a fundamental problem in the learning dynamics of LLMs: the magnitude of policy gradients is inherently coupled with the entropy, which leads to inefficient small updates for confident correct actions and potentially destabilizes large updates for uncertain ones. To resolve this, we propose Entropy-Modulated Policy Gradients (EMPG), a framework that re-calibrates the learning signal based on step-wise uncertainty and the final task outcome. EMPG amplifies updates for confident correct actions, penalizes confident errors, and attenuates updates from uncertain steps to stabilize exploration. We further introduce a bonus term for future clarity that encourages agents to find more predictable solution paths. Through comprehensive experiments on three challenging agent tasks, WebShop, ALFWorld, and Deep Search, we demonstrate that EMPG achieves substantial performance gains and significantly outperforms strong policy gradient baselines. Project page is at", "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL)", "comments": "ICLR 2026 Under review", "pdf_url": "https://arxiv.org/pdf/2509.09265.pdf", "abstract_url": "https://arxiv.org/abs/2509.09265", "categories": ["Machine Learning (cs.LG)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出熵调制策略梯度（EMPG）框架，通过基于不确定性和任务结果重新校准学习信号，解决长视野任务中稀疏奖励导致的信用分配问题，在多个任务上显著提升性能。", "motivation": "解决基于大型语言模型（LLM）的智能体在长视野任务中，由于稀疏奖励导致中间步骤信用分配困难的问题，以及策略梯度幅度与熵耦合导致的学习效率低下和不稳定性。", "method": "使用熵调制策略梯度（EMPG）框架，基于步骤不确定性和最终任务结果重新校准学习信号，包括放大自信正确动作的更新、惩罚自信错误、减弱不确定步骤的更新，并引入未来清晰度奖励项。", "result": "在WebShop、ALFWorld和DeepSearch等挑战性任务上，EMPG实现了显著的性能提升，并大幅优于强基线策略梯度方法。", "conclusion": "EMPG通过调制不确定性有效稳定和加速学习，为长视野LLM智能体提供了更高效和稳定的训练方法，具有广泛的应用潜力。"}}
{"id": "2509.09594", "title": "ObjectReact: Learning Object-Relative Control for Visual Navigation", "authors": ["Sourav Garg", "Dustin Craggs", "Vineeth Bhat", "Lachlan Mares", "Stefan Podgorski", "Madhava Krishna", "Feras Dayoub", "Ian Reid"], "abstract": "Visual navigation using only a single camera and a topological map has recently become an appealing alternative to methods that require additional sensors and 3D maps. This is typically achieved through an \"image-relative\" approach to estimating control from a given pair of current observation and subgoal image. However, image-level representations of the world have limitations because images are strictly tied to the agent's pose and embodiment. In contrast, objects, being a property of the map, offer an embodiment- and trajectory-invariant world representation. In this work, we present a new paradigm of learning \"object-relative\" control that exhibits several desirable characteristics: a) new routes can be traversed without strictly requiring to imitate prior experience, b) the control prediction problem can be decoupled from solving the image matching problem, and c) high invariance can be achieved in cross-embodiment deployment for variations across both training-testing and mapping-execution settings. We propose a topometric map representation in the form of a \"relative\" 3D scene graph, which is used to obtain more informative object-level global path planning costs. We train a local controller, dubbed \"ObjectReact\", conditioned directly on a high-level \"WayObject Costmap\" representation that eliminates the need for an explicit RGB input. We demonstrate the advantages of learning object-relative control over its image-relative counterpart across sensor height variations and multiple navigation tasks that challenge the underlying spatial understanding capability, e.g., navigating a map trajectory in the reverse direction. We further show that our sim-only policy is able to generalize well to real-world indoor environments. Code and supplementary material are accessible via project page:", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Systems and Control (eess.SY)", "comments": "CoRL 2025; 23 pages including appendix", "pdf_url": "https://arxiv.org/pdf/2509.09594.pdf", "abstract_url": "https://arxiv.org/abs/2509.09594", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)", "Machine Learning (cs.LG)", "Systems and Control (eess.SY)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出ObjectReact方法，通过对象相对控制改进视觉导航，使用相对3D场景图进行路径规划，实现高不变性和跨部署泛化。", "motivation": "解决图像相对方法在视觉导航中的局限性，如图像与代理姿态绑定，导致泛化能力差和依赖先验经验的问题。", "method": "采用对象相对控制范式，构建相对3D场景图作为拓扑地图，训练基于WayObject Costmap的局部控制器ObjectReact，无需显式RGB输入。", "result": "在传感器高度变化和多种导航任务中优于图像相对方法，例如反向导航，且仅用模拟策略即可泛化到真实室内环境。", "conclusion": "对象相对控制提供更稳健和泛化的视觉导航方案，减少对图像匹配和先验模仿的依赖，适用于跨部署场景。"}}
{"id": "2509.09651", "title": "Retrieval-Augmented Generation for Reliable Interpretation of Radio Regulations", "authors": ["Zakaria El Kassimi", "Fares Fourati", "Mohamed-Slim Alouini"], "abstract": "We study question answering in the domain of radio regulations, a legally sensitive and high-stakes area. We propose a telecom-specific Retrieval-Augmented Generation (RAG) pipeline and introduce, to our knowledge, the first multiple-choice evaluation set for this domain, constructed from authoritative sources using automated filtering and human validation. To assess retrieval quality, we define a domain-specific retrieval metric, under which our retriever achieves approximately 97% accuracy. Beyond retrieval, our approach consistently improves generation accuracy across all tested models. In particular, while naively inserting documents without structured retrieval yields only marginal gains for GPT-4o (less than 1%), applying our pipeline results in nearly a 12% relative improvement. These findings demonstrate that carefully targeted grounding provides a simple yet strong baseline and an effective domain-specific solution for regulatory question answering. All code and evaluation scripts, along with our derived question-answer dataset, are available at", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Signal Processing (eess.SP)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.09651.pdf", "abstract_url": "https://arxiv.org/abs/2509.09651", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)", "Signal Processing (eess.SP)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种针对无线电法规领域的检索增强生成（RAG）管道，通过特定领域的检索指标和评估集，显著提高了生成准确性，提供了可靠的法规问答解决方案。", "motivation": "解决无线电法规这一法律敏感和高风险领域中的问答问题，确保回答的可靠性和准确性。", "method": "使用电信特定的RAG管道，包括自动化过滤和人工验证构建评估集，并定义领域特定的检索指标来评估检索质量。", "result": "检索器准确率约97%，RAG管道使GPT-4o的生成准确性相对提高近12%，而简单插入文档仅带来不足1%的增益。", "conclusion": "针对性的检索增强生成提供了一个简单而强大的基线，是法规问答的有效领域特定解决方案，所有代码和数据集已公开。"}}
{"id": "2509.09208", "title": "Incentivizing Safer Actions in Policy Optimization for Constrained Reinforcement Learning", "authors": ["Somnath Hazra", "Pallab Dasgupta", "Soumyajit Dey"], "abstract": "Constrained Reinforcement Learning (RL) aims to maximize the return while adhering to predefined constraint limits, which represent domain-specific safety requirements. In continuous control settings, where learning agents govern system actions, balancing the trade-off between reward maximization and constraint satisfaction remains a significant challenge. Policy optimization methods often exhibit instability near constraint boundaries, resulting in suboptimal training performance. To address this issue, we introduce a novel approach that integrates an adaptive incentive mechanism in addition to the reward structure to stay within the constraint bound before approaching the constraint boundary. Building on this insight, we propose Incrementally Penalized Proximal Policy Optimization (IP3O), a practical algorithm that enforces a progressively increasing penalty to stabilize training dynamics. Through empirical evaluation on benchmark environments, we demonstrate the efficacy of IP3O compared to the performance of state-of-the-art Safe RL algorithms. Furthermore, we provide theoretical guarantees by deriving a bound on the worst-case error of the optimality achieved by our algorithm.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "11 pages, Accepted to the 34th International Joint Conference on Artificial Intelligence (IJCAI) 2025, Main Track", "pdf_url": "https://arxiv.org/pdf/2509.09208.pdf", "abstract_url": "https://arxiv.org/abs/2509.09208", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文提出了一种名为IP3O的新方法，通过自适应激励机制和渐进惩罚来稳定约束强化学习中的策略优化，提高安全性和性能。", "motivation": "解决约束强化学习中奖励最大化和约束满足之间的平衡问题，特别是在连续控制设置中策略优化在约束边界附近的不稳定性。", "method": "引入自适应激励机制和渐进惩罚，基于Proximal Policy Optimization提出IP3O算法。", "result": "在基准环境上的实证评估显示，IP3O优于现有安全强化学习算法，并提供理论保证。", "conclusion": "IP3O方法有效稳定训练动态，确保约束满足，具有实际应用潜力。"}}
{"id": "2509.09219", "title": "Vejde: A Framework for Inductive Deep Reinforcement Learning Based on Factor Graph Color Refinement", "authors": ["Jakob Nyberg", "Pontus Johnson"], "abstract": "We present and evaluate Vejde; a framework which combines data abstraction, graph neural networks and reinforcement learning to produce inductive policy functions for decision problems with richly structured states, such as object classes and relations. MDP states are represented as data bases of facts about entities, and Vejde converts each state to a bipartite graph, which is mapped to latent states through neural message passing. The factored representation of both states and actions allows Vejde agents to handle problems of varying size and structure. We tested Vejde agents on eight problem domains defined in RDDL, with ten problem instances each, where policies were trained using both supervised and reinforcement learning. To test policy generalization, we separate problem instances in two sets, one for training and the other solely for testing. Test results on unseen instances for the Vejde agents were compared to MLP agents trained on each problem instance, as well as the online planning algorithm Prost. Our results show that Vejde policies in average generalize to the test instances without a significant loss in score. Additionally, the inductive agents received scores on unseen test instances that on average were close to the instance-specific MLP agents.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.09219.pdf", "abstract_url": "https://arxiv.org/abs/2509.09219", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "Vejde是一个结合数据抽象、图神经网络和强化学习的框架，用于生成具有丰富结构状态的决策问题的归纳策略函数。", "motivation": "解决在具有对象类和关系等结构化状态的决策问题中，如何实现策略的归纳和泛化，以处理不同大小和结构的问题。", "method": "将MDP状态表示为事实数据库，转换为二分图，通过神经消息传递映射到潜在状态，并使用监督和强化学习训练策略。", "result": "在八个RDDL问题域上测试，Vejde策略在未见实例上平均泛化良好，得分接近实例特定的MLP代理。", "conclusion": "Vejde框架能有效实现归纳强化学习，提升策略的泛化能力，适用于结构化状态问题。"}}
