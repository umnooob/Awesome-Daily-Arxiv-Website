{"id": "2506.11140", "title": "Autonomous Computer Vision Development with Agentic AI", "authors": ["Jin Kim", "Muhammad Wahi-Anwa", "Sangyun Park", "Shawn Shin", "John M. Hoffman", "Matthew S. Brown"], "abstract": "Agentic Artificial Intelligence (AI) systems leveraging Large Language Models (LLMs) exhibit significant potential for complex reasoning, planning, and tool utilization. We demonstrate that a specialized computer vision system can be built autonomously from a natural language prompt using Agentic AI methods. This involved extending SimpleMind (SM), an open-source Cognitive AI environment with configurable tools for medical image analysis, with an LLM-based agent, implemented using OpenManus, to automate the planning (tool configuration) for a particular computer vision task. We provide a proof-of-concept demonstration that an agentic system can interpret a computer vision task prompt, plan a corresponding SimpleMind workflow by decomposing the task and configuring appropriate tools. From the user input prompt, \"provide sm (SimpleMind) config for lungs, heart, and ribs segmentation for cxr (chest x-ray)\"), the agent LLM was able to generate the plan (tool configuration file in YAML format), and execute SM-Learn (training) and SM-Think (inference) scripts autonomously. The computer vision agent automatically configured, trained, and tested itself on 50 chest x-ray images, achieving mean dice scores of 0.96, 0.82, 0.83, for lungs, heart, and ribs, respectively. This work shows the potential for autonomous planning and tool configuration that has traditionally been performed by a data scientist in the development of computer vision applications.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "The paper is 13 pages long and contains 4 figures", "pdf_url": "https://arxiv.org/pdf/2506.11140.pdf", "abstract_url": "https://arxiv.org/abs/2506.11140", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"]}
{"id": "2506.11302", "title": "TARDIS STRIDE: A Spatio-Temporal Road Image Dataset for Exploration and Autonomy", "authors": ["Héctor Carrión", "Yutong Bai", "Víctor A. Hernández Castro", "Kishan Panaganti", "Ayush Zenith", "Matthew Trang", "Tony Zhang", "Pietro Perona", "Jitendra Malik"], "abstract": "World models aim to simulate environments and enable effective agent behavior. However, modeling real-world environments presents unique challenges as they dynamically change across both space and, crucially, time. To capture these composed dynamics, we introduce a Spatio-Temporal Road Image Dataset for Exploration (STRIDE) permuting 360-degree panoramic imagery into rich interconnected observation, state and action nodes. Leveraging this structure, we can simultaneously model the relationship between egocentric views, positional coordinates, and movement commands across both space and time. We benchmark this dataset via TARDIS, a transformer-based generative world model that integrates spatial and temporal dynamics through a unified autoregressive framework trained on STRIDE. We demonstrate robust performance across a range of agentic tasks such as controllable photorealistic image synthesis, instruction following, autonomous self-control, and state-of-the-art georeferencing. These results suggest a promising direction towards sophisticated generalist agents--capable of understanding and manipulating the spatial and temporal aspects of their material environments--with enhanced embodied reasoning capabilities. Training code, datasets, and model checkpoints are made available at", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": "Computer Vision, Pattern Recognition, LLMs, Dataset, Data Augmentation", "pdf_url": "https://arxiv.org/pdf/2506.11302.pdf", "abstract_url": "https://arxiv.org/abs/2506.11302", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"]}
{"id": "2506.11063", "title": "Who is in the Spotlight: The Hidden Bias Undermining Multimodal Retrieval-Augmented Generation", "authors": ["Jiayu Yao", "Shenghua Liu", "Yiwei Wang", "Lingrui Mei", "Baolong Bi", "Yuyao Ge", "Zhecheng Li", "Xueqi Cheng"], "abstract": "Multimodal Retrieval-Augmented Generation (RAG) systems have become essential in knowledge-intensive and open-domain tasks. As retrieval complexity increases, ensuring the robustness of these systems is critical. However, current RAG models are highly sensitive to the order in which evidence is presented, often resulting in unstable performance and biased reasoning, particularly as the number of retrieved items or modality diversity grows. This raises a central question: How does the position of retrieved evidence affect multimodal RAG performance? To answer this, we present the first comprehensive study of position bias in multimodal RAG systems. Through controlled experiments across text-only, image-only, and mixed-modality tasks, we observe a consistent U-shaped accuracy curve with respect to evidence position. To quantify this bias, we introduce the Position Sensitivity Index ($PSI_p$) and develop a visualization framework to trace attention allocation patterns across decoder layers. Our results reveal that multimodal interactions intensify position bias compared to unimodal settings, and that this bias increases logarithmically with retrieval range. These findings offer both theoretical and empirical foundations for position-aware analysis in RAG, highlighting the need for evidence reordering or debiasing strategies to build more reliable and equitable generation systems.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.11063.pdf", "abstract_url": "https://arxiv.org/abs/2506.11063", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"]}
{"id": "2506.11065", "title": "Smotrom tvoja pa ander drogoj verden! Resurrecting Dead Pidgin with Generative Models: Russenorsk Case Study", "authors": ["Alexey Tikhonov", "Sergei Shteiner", "Anna Bykova", "Ivan P. Yamshchikov"], "abstract": "Russenorsk, a pidgin language historically used in trade interactions between Russian and Norwegian speakers, represents a unique linguistic phenomenon. In this paper, we attempt to analyze its lexicon using modern large language models (LLMs), based on surviving literary sources. We construct a structured dictionary of the language, grouped by synonyms and word origins. Subsequently, we use this dictionary to formulate hypotheses about the core principles of word formation and grammatical structure in Russenorsk and show which hypotheses generated by large language models correspond to the hypotheses previously proposed ones in the academic literature. We also develop a \"reconstruction\" translation agent that generates hypothetical Russenorsk renderings of contemporary Russian and Norwegian texts.", "subjects": "Computation and Language (cs.CL)", "comments": "ACL Findings 2025", "pdf_url": "https://arxiv.org/pdf/2506.11065.pdf", "abstract_url": "https://arxiv.org/abs/2506.11065", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2506.11083", "title": "RedDebate: Safer Responses through Multi-Agent Red Teaming Debates", "authors": ["Ali Asad", "Stephen Obadinma", "Radin Shayanfar", "Xiaodan Zhu"], "abstract": "We propose RedDebate, a novel multi-agent debate framework that leverages adversarial argumentation among Large Language Models (LLMs) to proactively identify and mitigate their own unsafe behaviours. Existing AI safety methods often depend heavily on costly human evaluations or isolated single-model assessment, both subject to scalability constraints and oversight risks. RedDebate instead embraces collaborative disagreement, enabling multiple LLMs to critically examine one another's reasoning, and systematically uncovering unsafe blind spots through automated red-teaming, and iteratively improve their responses. We further integrate distinct types of long-term memory that retain learned safety insights from debate interactions. Evaluating on established safety benchmarks such as HarmBench, we demonstrate the proposed method's effectiveness. Debate alone can reduce unsafe behaviours by 17.7%, and when combined with long-term memory modules, achieves reductions exceeding 23.5%. To our knowledge, RedDebate constitutes the first fully automated framework that combines multi-agent debates with red-teaming to progressively enhance AI safety without direct human intervention.(Github Repository:", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.11083.pdf", "abstract_url": "https://arxiv.org/abs/2506.11083", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2506.11375", "title": "Benchmarking Multimodal LLMs on Recognition and Understanding over Chemical Tables", "authors": ["Yitong Zhou", "Mingyue Cheng", "Qingyang Mao", "Yucong Luo", "Qi Liu", "Yupeng Li", "Xiaohan Zhang", "Deguang Liu", "Xin Li", "Enhong Chen"], "abstract": "Chemical tables encode complex experimental knowledge through symbolic expressions, structured variables, and embedded molecular graphics. Existing benchmarks largely overlook this multimodal and domain-specific complexity, limiting the ability of multimodal large language models to support scientific understanding in chemistry. In this work, we introduce ChemTable, a large-scale benchmark of real-world chemical tables curated from the experimental sections of literature. ChemTable includes expert-annotated cell polygons, logical layouts, and domain-specific labels, including reagents, catalysts, yields, and graphical components and supports two core tasks: (1) Table Recognition, covering structure parsing and content extraction; and (2) Table Understanding, encompassing both descriptive and reasoning-oriented question answering grounded in table structure and domain semantics. We evaluated a range of representative multimodal models, including both open-source and closed-source models, on ChemTable and reported a series of findings with practical and conceptual insights. Although models show reasonable performance on basic layout parsing, they exhibit substantial limitations on both descriptive and inferential QA tasks compared to human performance, and we observe significant performance gaps between open-source and closed-source models across multiple dimensions. These results underscore the challenges of chemistry-aware table understanding and position ChemTable as a rigorous and realistic benchmark for advancing scientific reasoning.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.11375.pdf", "abstract_url": "https://arxiv.org/abs/2506.11375", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2506.11376", "title": "Large Language Model-Powered Conversational Agent Delivering Problem-Solving Therapy (PST) for Family Caregivers: Enhancing Empathy and Therapeutic Alliance Using In-Context Learning", "authors": ["Liying Wang", "Ph.D.", "Daffodil Carrington", "M.S.", "Daniil Filienko", "M.S.", "Caroline El Jazmi", "M.S.", "Serena Jinchen Xie", "M.S.", "Martine De Cock", "Ph.D.", "Sarah Iribarren", "Ph.D.", "Weichao Yuwen", "Ph.D"], "abstract": "Family caregivers often face substantial mental health challenges due to their multifaceted roles and limited resources. This study explored the potential of a large language model (LLM)-powered conversational agent to deliver evidence-based mental health support for caregivers, specifically Problem-Solving Therapy (PST) integrated with Motivational Interviewing (MI) and Behavioral Chain Analysis (BCA). A within-subject experiment was conducted with 28 caregivers interacting with four LLM configurations to evaluate empathy and therapeutic alliance. The best-performing models incorporated Few-Shot and Retrieval-Augmented Generation (RAG) prompting techniques, alongside clinician-curated examples. The models showed improved contextual understanding and personalized support, as reflected by qualitative responses and quantitative ratings on perceived empathy and therapeutic alliances. Participants valued the model's ability to validate emotions, explore unexpressed feelings, and provide actionable strategies. However, balancing thorough assessment with efficient advice delivery remains a challenge. This work highlights the potential of LLMs in delivering empathetic and tailored support for family caregivers.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.11376.pdf", "abstract_url": "https://arxiv.org/abs/2506.11376", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent", "@RAG"]}
{"id": "2506.11419", "title": "FocalAD: Local Motion Planning for End-to-End Autonomous Driving", "authors": ["Bin Sun", "Boao Zhang", "Jiayi Lu", "Xinjie Feng", "Jiachen Shang", "Rui Cao", "Mengchao Zheng", "Chuanye Wang", "Shichun Yang", "Yaoguang Cao", "Ziying Song"], "abstract": "In end-to-end autonomous driving,the motion prediction plays a pivotal role in ego-vehicle planning. However, existing methods often rely on globally aggregated motion features, ignoring the fact that planning decisions are primarily influenced by a small number of locally interacting agents. Failing to attend to these critical local interactions can obscure potential risks and undermine planning reliability. In this work, we propose FocalAD, a novel end-to-end autonomous driving framework that focuses on critical local neighbors and refines planning by enhancing local motion representations. Specifically, FocalAD comprises two core modules: the Ego-Local-Agents Interactor (ELAI) and the Focal-Local-Agents Loss (FLA Loss). ELAI conducts a graph-based ego-centric interaction representation that captures motion dynamics with local neighbors to enhance both ego planning and agent motion queries. FLA Loss increases the weights of decision-critical neighboring agents, guiding the model to prioritize those more relevant to planning. Extensive experiments show that FocalAD outperforms existing state-of-the-art methods on the open-loop nuScenes datasets and closed-loop Bench2Drive benchmark. Notably, on the robustness-focused Adv-nuScenes dataset, FocalAD achieves even greater improvements, reducing the average colilision rate by 41.9% compared to DiffusionDrive and by 15.6% compared to SparseDrive.", "subjects": "Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.11419.pdf", "abstract_url": "https://arxiv.org/abs/2506.11419", "categories": ["Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"]}
{"id": "2506.11445", "title": "Resolve Highway Conflict in Multi-Autonomous Vehicle Controls with Local State Attention", "authors": ["Xuan Duy Ta", "Bang Giang Le", "Thanh Ha Le", "Viet Cuong Ta"], "abstract": "In mixed-traffic environments, autonomous vehicles must adapt to human-controlled vehicles and other unusual driving situations. This setting can be framed as a multi-agent reinforcement learning (MARL) environment with full cooperative reward among the autonomous vehicles. While methods such as Multi-agent Proximal Policy Optimization can be effective in training MARL tasks, they often fail to resolve local conflict between agents and are unable to generalize to stochastic events. In this paper, we propose a Local State Attention module to assist the input state representation. By relying on the self-attention operator, the module is expected to compress the essential information of nearby agents to resolve the conflict in traffic situations. Utilizing a simulated highway merging scenario with the priority vehicle as the unexpected event, our approach is able to prioritize other vehicles' information to manage the merging process. The results demonstrate significant improvements in merging efficiency compared to popular baselines, especially in high-density traffic settings.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.11445.pdf", "abstract_url": "https://arxiv.org/abs/2506.11445", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2506.11555", "title": "RAG+: Enhancing Retrieval-Augmented Generation with Application-Aware Reasoning", "authors": ["Yu Wang", "Shiwan Zhao", "Ming Fan", "Zhihu Wang", "Yubo Zhang", "Xicheng Zhang", "Zhengfan Wang", "Heyuan Huang", "Ting Liu"], "abstract": "The integration of external knowledge through Retrieval-Augmented Generation (RAG) has become foundational in enhancing large language models (LLMs) for knowledge-intensive tasks. However, existing RAG paradigms often overlook the cognitive step of applying knowledge, leaving a gap between retrieved facts and task-specific reasoning. In this work, we introduce RAG+, a principled and modular extension that explicitly incorporates application-aware reasoning into the RAG pipeline. RAG+ constructs a dual corpus consisting of knowledge and aligned application examples, created either manually or automatically, and retrieves both jointly during inference. This design enables LLMs not only to access relevant information but also to apply it within structured, goal-oriented reasoning processes. Experiments across mathematical, legal, and medical domains, conducted on multiple models, demonstrate that RAG+ consistently outperforms standard RAG variants, achieving average improvements of 3-5%, and peak gains up to 7.5% in complex scenarios. By bridging retrieval with actionable application, RAG+ advances a more cognitively grounded framework for knowledge integration, representing a step toward more interpretable and capable LLMs.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.11555.pdf", "abstract_url": "https://arxiv.org/abs/2506.11555", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"]}
{"id": "2506.11092", "title": "Dynamic Context Tuning for Retrieval-Augmented Generation: Enhancing Multi-Turn Planning and Tool Adaptation", "authors": ["Jubin Abhishek Soni", "Amit Anand", "Rajesh Kumar Pandey", "Aniket Abhishek Soni"], "abstract": "Retrieval-Augmented Generation (RAG) has significantly advanced large language models (LLMs) by grounding their outputs in external tools and knowledge sources. However, existing RAG systems are typically constrained to static, single-turn interactions with fixed toolsets, making them ill-suited for dynamic domains such as healthcare and smart homes, where user intent, available tools, and contextual factors evolve over time. We present Dynamic Context Tuning (DCT), a lightweight framework that extends RAG to support multi-turn dialogue and evolving tool environments without requiring retraining. DCT integrates an attention-based context cache to track relevant past information, LoRA-based retrieval to dynamically select domain-specific tools, and efficient context compression to maintain inputs within LLM context limits. Experiments on both synthetic and real-world benchmarks show that DCT improves plan accuracy by 14% and reduces hallucinations by 37%, while matching GPT-4 performance at significantly lower cost. Furthermore, DCT generalizes to previously unseen tools, enabling scalable and adaptable AI assistants across a wide range of dynamic environments.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)", "comments": "6 pages, 5 figures, 3 tables. This manuscript has been submitted to IEEE conference. Researchers are welcome to read and build upon this work; please cite it appropriately. For questions or clarifications, feel free to contact me", "pdf_url": "https://arxiv.org/pdf/2506.11092.pdf", "abstract_url": "https://arxiv.org/abs/2506.11092", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["@RAG"]}
{"id": "2506.11102", "title": "Evolutionary Perspectives on the Evaluation of LLM-Based AI Agents: A Comprehensive Survey", "authors": ["Jiachen Zhu", "Menghui Zhu", "Renting Rui", "Rong Shan", "Congmin Zheng", "Bo Chen", "Yunjia Xi", "Jianghao Lin", "Weiwen Liu", "Ruiming Tang", "Yong Yu", "Weinan Zhang"], "abstract": "The advent of large language models (LLMs), such as GPT, Gemini, and DeepSeek, has significantly advanced natural language processing, giving rise to sophisticated chatbots capable of diverse language-related tasks. The transition from these traditional LLM chatbots to more advanced AI agents represents a pivotal evolutionary step. However, existing evaluation frameworks often blur the distinctions between LLM chatbots and AI agents, leading to confusion among researchers selecting appropriate benchmarks. To bridge this gap, this paper introduces a systematic analysis of current evaluation approaches, grounded in an evolutionary perspective. We provide a detailed analytical framework that clearly differentiates AI agents from LLM chatbots along five key aspects: complex environment, multi-source instructor, dynamic feedback, multi-modal perception, and advanced capability. Further, we categorize existing evaluation benchmarks based on external environments driving forces, and resulting advanced internal capabilities. For each category, we delineate relevant evaluation attributes, presented comprehensively in practical reference tables. Finally, we synthesize current trends and outline future evaluation methodologies through four critical lenses: environment, agent, evaluator, and metrics. Our findings offer actionable guidance for researchers, facilitating the informed selection and application of benchmarks in AI agent evaluation, thus fostering continued advancement in this rapidly evolving research domain.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.11102.pdf", "abstract_url": "https://arxiv.org/abs/2506.11102", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2506.11106", "title": "Graph-based RAG Enhancement via Global Query Disambiguation and Dependency-Aware Reranking", "authors": ["Ningyuan Li", "Junrui Liu", "Yi Shan", "Minghui Huang", "Tong Li"], "abstract": "Contemporary graph-based retrieval-augmented generation (RAG) methods typically begin by extracting entities from user queries and then leverage pre-constructed knowledge graphs to retrieve related relationships and metadata. However, this pipeline's exclusive reliance on entity-level extraction can lead to the misinterpretation or omission of latent yet critical information and relations. As a result, retrieved content may be irrelevant or contradictory, and essential knowledge may be excluded, exacerbating hallucination risks and degrading the fidelity of generated responses. To address these limitations, we introduce PankRAG, a framework that combines a globally aware, hierarchical query-resolution strategy with a novel dependency-aware reranking mechanism. PankRAG first constructs a multi-level resolution path that captures both parallel and sequential interdependencies within a query, guiding large language models (LLMs) through structured reasoning. It then applies its dependency-aware reranker to exploit the dependency structure among resolved sub-questions, enriching and validating retrieval results for subsequent sub-questions. Empirical evaluations demonstrate that PankRAG consistently outperforms state-of-the-art approaches across multiple benchmarks, underscoring its robustness and generalizability.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.11106.pdf", "abstract_url": "https://arxiv.org/abs/2506.11106", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"]}
{"id": "2506.11111", "title": "Evaluating and Improving Robustness in Large Language Models: A Survey and Future Directions", "authors": ["Kun Zhang", "Le Wu", "Kui Yu", "Guangyi Lv", "Dacao Zhang"], "abstract": "Large Language Models (LLMs) have gained enormous attention in recent years due to their capability of understanding and generating natural languages. With the rapid development and wild-range applications (e.g., Agents, Embodied Intelligence), the robustness of LLMs has received increased attention. As the core brain of many AI applications, the robustness of LLMs requires that models should not only generate consistent contents, but also ensure the correctness and stability of generated content when dealing with unexpeted application scenarios (e.g., toxic prompts, limited noise domain data, outof-distribution (OOD) applications, etc). In this survey paper, we conduct a thorough review of the robustness of LLMs, aiming to provide a comprehensive terminology of concepts and methods around this field and facilitate the community. Specifically, we first give a formal definition of LLM robustness and present the collection protocol of this survey paper. Then, based on the types of perturbated inputs, we organize this survey from the following perspectives: 1) Adversarial Robustness: tackling the problem that prompts are manipulated intentionally, such as noise prompts, long context, data attack, etc; 2) OOD Robustness: dealing with the unexpected real-world application scenarios, such as OOD detection, zero-shot transferring, hallucinations, etc; 3) Evaluation of Robustness: summarizing the new evaluation datasets, metrics, and tools for verifying the robustness of LLMs. After reviewing the representative work from each perspective, we discuss and highlight future opportunities and research directions in this field. Meanwhile, we also organize related works and provide an easy-to-search project (", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "33 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2506.11111.pdf", "abstract_url": "https://arxiv.org/abs/2506.11111", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2506.11112", "title": "Manifesto from Dagstuhl Perspectives Workshop 24352 -- Conversational Agents: A Framework for Evaluation (CAFE)", "authors": ["Christine Bauer", "Li Chen", "Nicola Ferro", "Norbert Fuhr", "Avishek Anand", "Timo Breuer", "Guglielmo Faggioli", "Ophir Frieder", "Hideo Joho", "Jussi Karlgren", "Johannes Kiesel", "Bart P. Knijnenburg", "Aldo Lipani", "Lien Michiels", "Andrea Papenmeier", "Maria Soledad Pera", "Mark Sanderson", "Scott Sanner", "Benno Stein", "Johanne R. Trippas", "Karin Verspoor", "Martijn C Willemsen"], "abstract": "During the workshop, we deeply discussed what CONversational Information ACcess (CONIAC) is and its unique features, proposing a world model abstracting it, and defined the Conversational Agents Framework for Evaluation (CAFE) for the evaluation of CONIAC systems, consisting of six major components: 1) goals of the system's stakeholders, 2) user tasks to be studied in the evaluation, 3) aspects of the users carrying out the tasks, 4) evaluation criteria to be considered, 5) evaluation methodology to be applied, and 6) measures for the quantitative criteria chosen.", "subjects": "Computation and Language (cs.CL); Human-Computer Interaction (cs.HC); Information Retrieval (cs.IR)", "comments": "43 pages; 10 figures; Dagstuhl manifesto", "pdf_url": "https://arxiv.org/pdf/2506.11112.pdf", "abstract_url": "https://arxiv.org/abs/2506.11112", "categories": ["Computation and Language (cs.CL)", "Human-Computer Interaction (cs.HC)", "Information Retrieval (cs.IR)"], "matching_keywords": ["agent"]}
{"id": "2506.11825", "title": "Revealing Political Bias in LLMs through Structured Multi-Agent Debate", "authors": ["Aishwarya Bandaru", "Fabian Bindley", "Trevor Bluth", "Nandini Chavda", "Baixu Chen", "Ethan Law"], "abstract": "Large language models (LLMs) are increasingly used to simulate social behaviour, yet their political biases and interaction dynamics in debates remain underexplored. We investigate how LLM type and agent gender attributes influence political bias using a structured multi-agent debate framework, by engaging Neutral, Republican, and Democrat American LLM agents in debates on politically sensitive topics. We systematically vary the underlying LLMs, agent genders, and debate formats to examine how model provenance and agent personas influence political bias and attitudes throughout debates. We find that Neutral agents consistently align with Democrats, while Republicans shift closer to the Neutral; gender influences agent attitudes, with agents adapting their opinions when aware of other agents' genders; and contrary to prior research, agents with shared political affiliations can form echo chambers, exhibiting the expected intensification of attitudes as debates progress.", "subjects": "Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Social and Information Networks (cs.SI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.11825.pdf", "abstract_url": "https://arxiv.org/abs/2506.11825", "categories": ["Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)", "Social and Information Networks (cs.SI)"], "matching_keywords": ["agent"]}
{"id": "2506.11003", "title": "EmbedAgent: Benchmarking Large Language Models in Embedded System Development", "authors": ["Ruiyang Xu", "Jialun Cao", "Mingyuan Wu", "Wenliang Zhong", "Yaojie Lu", "Ben He", "Xianpei Han", "Shing-Chi Cheung", "Le Sun"], "abstract": "Large Language Models (LLMs) have shown promise in various tasks, yet few benchmarks assess their capabilities in embedded system", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": "21 pages", "pdf_url": "https://arxiv.org/pdf/2506.11003.pdf", "abstract_url": "https://arxiv.org/abs/2506.11003", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2506.11773", "title": "AgentSense: Virtual Sensor Data Generation Using LLM Agent in Simulated Home Environments", "authors": ["Zikang Leng", "Megha Thukral", "Yaqi Liu", "Hrudhai Rajasekhar", "Shruthi K. Hiremath", "Thomas Plötz"], "abstract": "A major obstacle in developing robust and generalizable smart home-based Human Activity Recognition (HAR) systems is the lack of large-scale, diverse labeled datasets. Variability in home layouts, sensor configurations, and user behavior adds further complexity, as individuals follow varied routines and perform activities in distinct ways. Building HAR systems that generalize well requires training data that captures the diversity across users and environments. To address these challenges, we introduce AgentSense, a virtual data generation pipeline where diverse personas are generated by leveraging Large Language Models. These personas are used to create daily routines, which are then decomposed into low-level action sequences. Subsequently, the actions are executed in a simulated home environment called VirtualHome that we extended with virtual ambient sensors capable of recording the agents activities as they unfold. Overall, AgentSense enables the generation of rich, virtual sensor datasets that represent a wide range of users and home settings. Across five benchmark HAR datasets, we show that leveraging our virtual sensor data substantially improves performance, particularly when real data are limited. Notably, models trained on a combination of virtual data and just a few days of real data achieve performance comparable to those trained on the entire real datasets. These results demonstrate and prove the potential of virtual data to address one of the most pressing challenges in ambient sensing, which is the distinct lack of large-scale, annotated datasets without requiring any manual data collection efforts.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.11773.pdf", "abstract_url": "https://arxiv.org/abs/2506.11773", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"]}
{"id": "2506.11117", "title": "ScIRGen: Synthesize Realistic and Large-Scale RAG Dataset for Scientific Research", "authors": ["Junyong Lin", "Lu Dai", "Ruiqian Han", "Yijie Sui", "Ruilin Wang", "Xingliang Sun", "Qinglin Wu", "Min Feng", "Hao Liu", "Hui Xiong"], "abstract": "Scientific researchers need intensive information about datasets to effectively evaluate and develop theories and methodologies. The information needs regarding datasets are implicitly embedded in particular research tasks, rather than explicitly expressed in search queries. However, existing scientific retrieval and question-answering (QA) datasets typically address straightforward questions, which do not align with the distribution of real-world research inquiries. To bridge this gap, we developed ScIRGen, a dataset generation framework for scientific QA \\& retrieval that more accurately reflects the information needs of professional science researchers, and uses it to create a large-scale scientific retrieval-augmented generation (RAG) dataset with realistic queries, datasets and papers. Technically, we designed a dataset-oriented information extraction method that leverages academic papers to augment the dataset representation. We then proposed a question generation framework by employing cognitive taxonomy to ensure the quality of synthesized questions. We also design a method to automatically filter synthetic answers based on the perplexity shift of LLMs, which is highly aligned with human judgment of answers' validity. Collectively, these methodologies culminated in the creation of the 61k QA dataset, ScIRGen-Geo. We benchmarked representative methods on the ScIRGen-Geo dataset for their question-answering and retrieval capabilities, finding out that current methods still suffer from reasoning from complex questions. This work advances the development of more sophisticated tools to support the intricate information needs of the scientific community.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": "KDD 2025 Accepted", "pdf_url": "https://arxiv.org/pdf/2506.11117.pdf", "abstract_url": "https://arxiv.org/abs/2506.11117", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"]}
{"id": "2506.11127", "title": "GUIRoboTron-Speech: Towards Automated GUI Agents Based on Speech Instructions", "authors": ["Wenkang Han", "Zhixiong Zeng", "Jing Huang", "Shu Jiang", "Liming Zheng", "Longrong Yang", "Haibo Qiu", "Chang Yao", "Jingyuan Chen", "Lin Ma"], "abstract": "Autonomous agents for Graphical User Interfaces (GUIs) are revolutionizing human-computer interaction, yet their reliance on text-based instructions imposes limitations on accessibility and convenience, particularly in hands-free scenarios. To address this gap, we propose GUIRoboTron-Speech, the first end-to-end autonomous GUI agent that directly accepts speech instructions and on-device screenshots to predict actions. Confronted with the scarcity of speech-based GUI agent datasets, we initially generated high-quality speech instructions for training by leveraging a random timbre text-to-speech (TTS) model to convert existing text instructions. We then develop GUIRoboTron-Speech's capabilities through progressive grounding and planning training stages. A key contribution is a heuristic mixed-instruction training strategy designed to mitigate the modality imbalance inherent in pre-trained foundation models. Comprehensive experiments on several benchmark datasets validate the robust and superior performance of GUIRoboTron-Speech, demonstrating the significant potential and widespread applicability of speech as an effective instruction modality for driving GUI agents. Our code and datasets are available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.11127.pdf", "abstract_url": "https://arxiv.org/abs/2506.11127", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2506.11010", "title": "Data Science: a Natural Ecosystem", "authors": ["Emilio Porcu", "Roy El Moukari", "Laurent Najman", "Francisco Herrera", "Horst Simon"], "abstract": "This manuscript provides a holistic (data-centric) view of what we term essential data science, as a natural ecosystem with challenges and missions stemming from the data universe with its multiple combinations of the 5D complexities (data structure, domain, cardinality, causality, and ethics) with the phases of the data life cycle. Data agents perform tasks driven by specific goals. The data scientist is an abstract entity that comes from the logical organization of data agents with their actions. Data scientists face challenges that are defined according to the missions. We define specific discipline-induced data science, which in turn allows for the definition of pan-data science, a natural ecosystem that integrates specific disciplines with the essential data science. We semantically split the essential data science into computational, and foundational. We claim that there is a serious threat of divergence between computational and foundational data science. Especially, if no approach is taken to rate whether a data universe discovery should be useful or not. We suggest that rigorous approaches to measure the usefulness of data universe discoveries might mitigate such a divergence.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Databases (cs.DB); Machine Learning (stat.ML)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.11010.pdf", "abstract_url": "https://arxiv.org/abs/2506.11010", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Databases (cs.DB)", "Machine Learning (stat.ML)"], "matching_keywords": ["agent"]}
{"id": "2506.12009", "title": "Affogato: Learning Open-Vocabulary Affordance Grounding with Automated Data Generation at Scale", "authors": ["Junha Lee", "Eunha Park", "Chunghyun Park", "Dahyun Kang", "Minsu Cho"], "abstract": "Affordance grounding-localizing object regions based on natural language descriptions of interactions-is a critical challenge for enabling intelligent agents to understand and interact with their environments. However, this task remains challenging due to the need for fine-grained part-level localization, the ambiguity arising from multiple valid interaction regions, and the scarcity of large-scale datasets. In this work, we introduce Affogato, a large-scale benchmark comprising 150K instances, annotated with open-vocabulary text descriptions and corresponding 3D affordance heatmaps across a diverse set of objects and interactions. Building on this benchmark, we develop simple yet effective vision-language models that leverage pretrained part-aware vision backbones and a text-conditional heatmap decoder. Our models trained with the Affogato dataset achieve promising performance on the existing 2D and 3D benchmarks, and notably, exhibit effectiveness in open-vocabulary cross-domain generalization. The Affogato dataset is shared in public:", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.12009.pdf", "abstract_url": "https://arxiv.org/abs/2506.12009", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"]}
{"id": "2506.11150", "title": "ADAgent: LLM Agent for Alzheimer's Disease Analysis with Collaborative Coordinator", "authors": ["Wenlong Hou", "Gangqian Yang", "Ye Du", "Yeung Lau", "Lihao Liu", "Junjun He", "Ling Long", "Shujun Wang"], "abstract": "Alzheimer's disease (AD) is a progressive and irreversible neurodegenerative disease. Early and precise diagnosis of AD is crucial for timely intervention and treatment planning to alleviate the progressive neurodegeneration. However, most existing methods rely on single-modality data, which contrasts with the multifaceted approach used by medical experts. While some deep learning approaches process multi-modal data, they are limited to specific tasks with a small set of input modalities and cannot handle arbitrary combinations. This highlights the need for a system that can address diverse AD-related tasks, process multi-modal or missing input, and integrate multiple advanced methods for improved performance. In this paper, we propose ADAgent, the first specialized AI agent for AD analysis, built on a large language model (LLM) to address user queries and support decision-making. ADAgent integrates a reasoning engine, specialized medical tools, and a collaborative outcome coordinator to facilitate multi-modal diagnosis and prognosis tasks in AD. Extensive experiments demonstrate that ADAgent outperforms SOTA methods, achieving significant improvements in accuracy, including a 2.7% increase in multi-modal diagnosis, a 0.7% improvement in multi-modal prognosis, and enhancements in MRI and PET diagnosis tasks.", "subjects": "Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.11150.pdf", "abstract_url": "https://arxiv.org/abs/2506.11150", "categories": ["Image and Video Processing (eess.IV)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"]}
{"id": "2506.11343", "title": "From Replication to Redesign: Exploring Pairwise Comparisons for LLM-Based Peer Review", "authors": ["Yaohui Zhang", "Haijing Zhang", "Wenlong Ji", "Tianyu Hua", "Nick Haber", "Hancheng Cao", "Weixin Liang"], "abstract": "The advent of large language models (LLMs) offers unprecedented opportunities to reimagine peer review beyond the constraints of traditional workflows. Despite these opportunities, prior efforts have largely focused on replicating traditional review workflows with LLMs serving as direct substitutes for human reviewers, while limited attention has been given to exploring new paradigms that fundamentally rethink how LLMs can participate in the academic review process. In this paper, we introduce and explore a novel mechanism that employs LLM agents to perform pairwise comparisons among manuscripts instead of individual scoring. By aggregating outcomes from substantial pairwise evaluations, this approach enables a more accurate and robust measure of relative manuscript quality. Our experiments demonstrate that this comparative approach significantly outperforms traditional rating-based methods in identifying high-impact papers. However, our analysis also reveals emergent biases in the selection process, notably a reduced novelty in research topics and an increased institutional imbalance. These findings highlight both the transformative potential of rethinking peer review with LLMs and critical challenges that future systems must address to ensure equity and diversity.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.11343.pdf", "abstract_url": "https://arxiv.org/abs/2506.11343", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2506.11425", "title": "Agent-RLVR: Training Software Engineering Agents via Guidance and Environment Rewards", "authors": ["Jeff Da", "Clinton Wang", "Xiang Deng", "Yuntao Ma", "Nikhil Barhate", "Sean Hendryx"], "abstract": "Reinforcement Learning from Verifiable Rewards (RLVR) has been widely adopted as the de facto method for enhancing the reasoning capabilities of large language models and has demonstrated notable success in verifiable domains like math and competitive programming tasks. However, the efficacy of RLVR diminishes significantly when applied to agentic environments. These settings, characterized by multi-step, complex problem solving, lead to high failure rates even for frontier LLMs, as the reward landscape is too sparse for effective model training via conventional RLVR. In this work, we introduce Agent-RLVR, a framework that makes RLVR effective in challenging agentic settings, with an initial focus on software engineering tasks. Inspired by human pedagogy, Agent-RLVR introduces agent guidance, a mechanism that actively steers the agent towards successful trajectories by leveraging diverse informational cues. These cues, ranging from high-level strategic plans to dynamic feedback on the agent's errors and environmental interactions, emulate a teacher's guidance, enabling the agent to navigate difficult solution spaces and promotes active self-improvement via additional environment exploration. In the Agent-RLVR training loop, agents first attempt to solve tasks to produce initial trajectories, which are then validated by unit tests and supplemented with agent guidance. Agents then reattempt with guidance, and the agent policy is updated with RLVR based on the rewards of these guided trajectories. Agent-RLVR elevates the pass@1 performance of Qwen-2.5-72B-Instruct from 9.4% to 22.4% on SWE-Bench Verified. We find that our guidance-augmented RLVR data is additionally useful for test-time reward model training, shown by further boosting pass@1 to 27.8%. Agent-RLVR lays the groundwork for training agents with RLVR in complex, real-world environments where conventional RL methods struggle.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.11425.pdf", "abstract_url": "https://arxiv.org/abs/2506.11425", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"]}
{"id": "2506.11058", "title": "Refactoring Codebases through Library Design", "authors": ["Ziga Kovacic", "Celine Lee", "Justin Chiu", "Wenting Zhao", "Kevin Ellis"], "abstract": "Maintainable and general software allows developers to build robust applications efficiently, yet achieving these qualities often requires refactoring specialized solutions into reusable components. This challenge becomes particularly relevant as code agents become increasingly accurate at solving isolated programming problems. We investigate code agents' capacity to refactor code in ways supporting growth and reusability. We present both a method and a benchmark for refactoring: Librarian, a sample-and-rerank method for generating reusable libraries, and Minicode, a benchmark where code agents must minimize and refactor multiple independent solutions into a joint library. Compared to state-of-the-art code agents, Librarian achieves strong results on both compression and correctness on Minicode, obtaining compression rates 1.6-2x better than coding agents while also improving correctness. We open-source our code and benchmark at", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": "26 pages", "pdf_url": "https://arxiv.org/pdf/2506.11058.pdf", "abstract_url": "https://arxiv.org/abs/2506.11058", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2506.11060", "title": "Code Researcher: Deep Research Agent for Large Systems Code and Commit History", "authors": ["Ramneet Singh", "Sathvik Joel", "Abhav Mehrotra", "Nalin Wadhwa", "Ramakrishna B Bairi", "Aditya Kanade", "Nagarajan Natarajan"], "abstract": "Large Language Model (LLM)-based coding agents have shown promising results on coding benchmarks, but their effectiveness on systems code remains underexplored. Due to the size and complexities of systems code, making changes to a systems codebase is a daunting task, even for humans. It requires researching about many pieces of context, derived from the large codebase and its massive commit history, before making changes. Inspired by the recent progress on deep research agents, we design the first deep research agent for code, called Code Researcher, and apply it to the problem of generating patches for mitigating crashes reported in systems code. Code Researcher performs multi-step reasoning about semantics, patterns, and commit history of code to gather sufficient context. The context is stored in a structured memory which is used for synthesizing a patch. We evaluate Code Researcher on kBenchSyz, a benchmark of Linux kernel crashes, and show that it significantly outperforms strong baselines, achieving a crash-resolution rate of 58%, compared to 37.5% by SWE-agent. On an average, Code Researcher explores 10 files in each trajectory whereas SWE-agent explores only 1.33 files, highlighting Code Researcher's ability to deeply explore the codebase. Through another experiment on an open-source multimedia software, we show the generalizability of Code Researcher. Our experiments highlight the importance of global context gathering and multi-faceted reasoning for large codebases.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.11060.pdf", "abstract_url": "https://arxiv.org/abs/2506.11060", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2506.11475", "title": "AutoGen Driven Multi Agent Framework for Iterative Crime Data Analysis and Prediction", "authors": ["Syeda Kisaa Fatima", "Tehreem Zubair", "Noman Ahmed", "Asifullah Khan"], "abstract": "This paper introduces LUCID-MA (Learning and Understanding Crime through Dialogue of Multiple Agents), an innovative AI powered framework where multiple AI agents collaboratively analyze and understand crime data. Our system that consists of three core components: an analysis assistant that highlights spatiotemporal crime patterns, a feedback component that reviews and refines analytical results and a prediction component that forecasts future crime trends. With a well-designed prompt and the LLaMA-2-13B-Chat-GPTQ model, it runs completely offline and allows the agents undergo self-improvement through 100 rounds of communication with less human interaction. A scoring function is incorporated to evaluate agent's performance, providing visual plots to track learning progress. This work demonstrates the potential of AutoGen-style agents for autonomous, scalable, and iterative analysis in social science domains maintaining data privacy through offline execution.", "subjects": "Multiagent Systems (cs.MA); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.11475.pdf", "abstract_url": "https://arxiv.org/abs/2506.11475", "categories": ["Multiagent Systems (cs.MA)", "Computation and Language (cs.CL)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"]}
{"id": "2506.11638", "title": "LoRA-Gen: Specializing Large Language Model via Online LoRA Generation", "authors": ["Yicheng Xiao", "Lin Song", "Rui Yang", "Cheng Cheng", "Yixiao Ge", "Xiu Li", "Ying Shan"], "abstract": "Recent advances have highlighted the benefits of scaling language models to enhance performance across a wide range of NLP tasks. However, these approaches still face limitations in effectiveness and efficiency when applied to domain-specific tasks, particularly for small edge-side models. We propose the LoRA-Gen framework, which utilizes a large cloud-side model to generate LoRA parameters for edge-side models based on task descriptions. By employing the reparameterization technique, we merge the LoRA parameters into the edge-side model to achieve flexible specialization. Our method facilitates knowledge transfer between models while significantly improving the inference efficiency of the specialized model by reducing the input context length. Without specialized training, LoRA-Gen outperforms conventional LoRA fine-tuning, which achieves competitive accuracy and a 2.1x speedup with TinyLLaMA-1.1B in reasoning tasks. Besides, our method delivers a compression ratio of 10.1x with Gemma-2B on intelligent agent tasks.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.11638.pdf", "abstract_url": "https://arxiv.org/abs/2506.11638", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2506.11681", "title": "LLMs for Sentence Simplification: A Hybrid Multi-Agent prompting Approach", "authors": ["Pratibha Zunjare", "Michael Hsiao"], "abstract": "This paper addresses the challenge of transforming complex sentences into sequences of logical, simplified sentences while preserving semantic and logical integrity with the help of Large Language Models. We propose a hybrid approach that combines advanced prompting with multi-agent architectures to enhance the sentence simplification process. Experimental results show that our approach was able to successfully simplify 70% of the complex sentences written for video game design application. In comparison, a single-agent approach attained a 48% success rate on the same task.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.11681.pdf", "abstract_url": "https://arxiv.org/abs/2506.11681", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2506.11796", "title": "Solving Inverse Problems in Stochastic Self-Organising Systems through Invariant Representations", "authors": ["Elias Najarro", "Nicolas Bessone", "Sebastian Risi"], "abstract": "Self-organising systems demonstrate how simple local rules can generate complex stochastic patterns. Many natural systems rely on such dynamics, making self-organisation central to understanding natural complexity. A fundamental challenge in modelling such systems is solving the inverse problem: finding the unknown causal parameters from macroscopic observations. This task becomes particularly difficult when observations have a strong stochastic component, yielding diverse yet equivalent patterns. Traditional inverse methods fail in this setting, as pixel-wise metrics cannot capture feature similarities between variable outcomes. In this work, we introduce a novel inverse modelling method specifically designed to handle stochasticity in the observable space, leveraging the capacity of visual embeddings to produce robust representations that capture perceptual invariances. By mapping the pattern representations onto an invariant embedding space, we can effectively recover unknown causal parameters without the need for handcrafted objective functions or heuristics. We evaluate the method on two canonical models--a reaction-diffusion system and an agent-based model of social segregation--and show that it reliably recovers parameters despite stochasticity in the outcomes. We further apply the method to real biological patterns, highlighting its potential as a tool for both theorists and experimentalists to investigate the dynamics underlying complex stochastic pattern formation.", "subjects": "Adaptation and Self-Organizing Systems (nlin.AO); Disordered Systems and Neural Networks (cond-mat.dis-nn); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "comments": "Preprint. Under review", "pdf_url": "https://arxiv.org/pdf/2506.11796.pdf", "abstract_url": "https://arxiv.org/abs/2506.11796", "categories": ["Adaptation and Self-Organizing Systems (nlin.AO)", "Disordered Systems and Neural Networks (cond-mat.dis-nn)", "Computer Vision and Pattern Recognition (cs.CV)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"]}
{"id": "2506.11967", "title": "Visual Pre-Training on Unlabeled Images using Reinforcement Learning", "authors": ["Dibya Ghosh", "Sergey Levine"], "abstract": "In reinforcement learning (RL), value-based algorithms learn to associate each observation with the states and rewards that are likely to be reached from it. We observe that many self-supervised image pre-training methods bear similarity to this formulation: learning features that associate crops of images with those of nearby views, e.g., by taking a different crop or color augmentation. In this paper, we complete this analogy and explore a method that directly casts pre-training on unlabeled image data like web crawls and video frames as an RL problem. We train a general value function in a dynamical system where an agent transforms an image by changing the view or adding image augmentations. Learning in this way resembles crop-consistency self-supervision, but through the reward function, offers a simple lever to shape feature learning using curated images or weakly labeled captions when they exist. Our experiments demonstrate improved representations when training on unlabeled images in the wild, including video data like EpicKitchens, scene data like COCO, and web-crawl data like CC12M.", "subjects": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.11967.pdf", "abstract_url": "https://arxiv.org/abs/2506.11967", "categories": ["Machine Learning (cs.LG)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"]}
{"id": "2506.11763", "title": "DeepResearch Bench: A Comprehensive Benchmark for Deep Research Agents", "authors": ["Mingxuan Du", "Benfeng Xu", "Chiwei Zhu", "Xiaorui Wang", "Zhendong Mao"], "abstract": "Deep Research Agents are a prominent category of LLM-based agents. By autonomously orchestrating multistep web exploration, targeted retrieval, and higher-order synthesis, they transform vast amounts of online information into analyst-grade, citation-rich reports--compressing hours of manual desk research into minutes. However, a comprehensive benchmark for systematically evaluating the capabilities of these agents remains absent. To bridge this gap, we present DeepResearch Bench, a benchmark consisting of 100 PhD-level research tasks, each meticulously crafted by domain experts across 22 distinct fields. Evaluating DRAs is inherently complex and labor-intensive. We therefore propose two novel methodologies that achieve strong alignment with human judgment. The first is a reference-based method with adaptive criteria to assess the quality of generated research reports. The other framework is introduced to evaluate DRA's information retrieval and collection capabilities by assessing its effective citation count and overall citation accuracy. We have open-sourced DeepResearch Bench and key components of these frameworks at", "subjects": "Computation and Language (cs.CL); Information Retrieval (cs.IR)", "comments": "31 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2506.11763.pdf", "abstract_url": "https://arxiv.org/abs/2506.11763", "categories": ["Computation and Language (cs.CL)", "Information Retrieval (cs.IR)"], "matching_keywords": ["agent"]}
{"id": "2506.11237", "title": "LLM-as-a-Judge for Reference-less Automatic Code Validation and Refinement for Natural Language to Bash in IT Automation", "authors": ["Ngoc Phuoc An Vo", "Brent Paulovicks", "Vadim Sheinin"], "abstract": "In an effort to automatically evaluate and select the best model and improve code quality for automatic incident remediation in IT Automation, it is crucial to verify if the generated code for remediation action is syntactically and semantically correct and whether it can be executed correctly as intended. There are three approaches: 1) conventional methods use surface form similarity metrics (token match, exact match, etc.) which have numerous limitations, 2) execution-based evaluation focuses more on code functionality based on pass/fail judgments for given test-cases, and 3) LLM-as-a-Judge employs LLMs for automated evaluation to judge if it is a correct answer for a given problem based on pre-defined metrics. In this work, we focused on enhancing LLM-as-a-Judge using bidirectional functionality matching and logic representation for reference-less automatic validation and refinement for Bash code generation to select the best model for automatic incident remediation in IT Automation. We used execution-based evaluation as ground-truth to evaluate our LLM-as-a-Judge metrics. Results show high accuracy and agreement with execution-based evaluation (and up to 8% over baseline). Finally, we built Reflection code agents to utilize judgments and feedback from our evaluation metrics which achieved significant improvement (up to 24% increase in accuracy) for automatic code refinement.", "subjects": "Software Engineering (cs.SE); Computation and Language (cs.CL)", "comments": "10 pages", "pdf_url": "https://arxiv.org/pdf/2506.11237.pdf", "abstract_url": "https://arxiv.org/abs/2506.11237", "categories": ["Software Engineering (cs.SE)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2506.11172", "title": "Collapsing Sequence-Level Data-Policy Coverage via Poisoning Attack in Offline Reinforcement Learning", "authors": ["Xue Zhou", "Dapeng Man", "Chen Xu", "Fanyi Zeng", "Tao Liu", "Huan Wang", "Shucheng He", "Chaoyang Gao", "Wu Yang"], "abstract": "Offline reinforcement learning (RL) heavily relies on the coverage of pre-collected data over the target policy's distribution. Existing studies aim to improve data-policy coverage to mitigate distributional shifts, but overlook security risks from insufficient coverage, and the single-step analysis is not consistent with the multi-step decision-making nature of offline RL. To address this, we introduce the sequence-level concentrability coefficient to quantify coverage, and reveal its exponential amplification on the upper bound of estimation errors through theoretical analysis. Building on this, we propose the Collapsing Sequence-Level Data-Policy Coverage (CSDPC) poisoning attack. Considering the continuous nature of offline RL data, we convert state-action pairs into decision units, and extract representative decision patterns that capture multi-step behavior. We identify rare patterns likely to cause insufficient coverage, and poison them to reduce coverage and exacerbate distributional shifts. Experiments show that poisoning just 1% of the dataset can degrade agent performance by 90%. This finding provides new perspectives for analyzing and safeguarding the security of offline RL.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.11172.pdf", "abstract_url": "https://arxiv.org/abs/2506.11172", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2506.11415", "title": "Bias Amplification in RAG: Poisoning Knowledge Retrieval to Steer LLMs", "authors": ["Linlin Wang", "Tianqing Zhu", "Laiqiao Qin", "Longxiang Gao", "Wanlei Zhou"], "abstract": "In Large Language Models, Retrieval-Augmented Generation (RAG) systems can significantly enhance the performance of large language models by integrating external knowledge. However, RAG also introduces new security risks. Existing research focuses mainly on how poisoning attacks in RAG systems affect model output quality, overlooking their potential to amplify model biases. For example, when querying about domestic violence victims, a compromised RAG system might preferentially retrieve documents depicting women as victims, causing the model to generate outputs that perpetuate gender stereotypes even when the original query is gender neutral. To show the impact of the bias, this paper proposes a Bias Retrieval and Reward Attack (BRRA) framework, which systematically investigates attack pathways that amplify language model biases through a RAG system manipulation. We design an adversarial document generation method based on multi-objective reward functions, employ subspace projection techniques to manipulate retrieval results, and construct a cyclic feedback mechanism for continuous bias amplification. Experiments on multiple mainstream large language models demonstrate that BRRA attacks can significantly enhance model biases in dimensions. In addition, we explore a dual stage defense mechanism to effectively mitigate the impacts of the attack. This study reveals that poisoning attacks in RAG systems directly amplify model output biases and clarifies the relationship between RAG system security and model fairness. This novel potential attack indicates that we need to keep an eye on the fairness issues of the RAG system.", "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL); Cryptography and Security (cs.CR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.11415.pdf", "abstract_url": "https://arxiv.org/abs/2506.11415", "categories": ["Machine Learning (cs.LG)", "Computation and Language (cs.CL)", "Cryptography and Security (cs.CR)"], "matching_keywords": ["@RAG"]}
{"id": "2506.11180", "title": "Beyond Formal Semantics for Capabilities and Skills: Model Context Protocol in Manufacturing", "authors": ["Luis Miguel Vieira da Silva", "Aljosha Köcher", "Felix Gehlhoff"], "abstract": "Explicit modeling of capabilities and skills -- whether based on ontologies, Asset Administration Shells, or other technologies -- requires considerable manual effort and often results in representations that are not easily accessible to Large Language Models (LLMs). In this work-in-progress paper, we present an alternative approach based on the recently introduced Model Context Protocol (MCP). MCP allows systems to expose functionality through a standardized interface that is directly consumable by LLM-based agents. We conduct a prototypical evaluation on a laboratory-scale manufacturing system, where resource functions are made available via MCP. A general-purpose LLM is then tasked with planning and executing a multi-step process, including constraint handling and the invocation of resource functions via MCP. The results indicate that such an approach can enable flexible industrial automation without relying on explicit semantic models. This work lays the basis for further exploration of external tool integration in LLM-driven production systems.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET); Systems and Control (eess.SY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.11180.pdf", "abstract_url": "https://arxiv.org/abs/2506.11180", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)", "Emerging Technologies (cs.ET)", "Systems and Control (eess.SY)"], "matching_keywords": ["agent"]}
{"id": "2506.11266", "title": "Invocable APIs derived from NL2SQL datasets for LLM Tool-Calling Evaluation", "authors": ["Benjamin Elder", "Anupama Murthi", "Jungkoo Kang", "Ankita Rajaram Naik", "Kiran Kate", "Kinjal Basu", "Danish Contractor"], "abstract": "Large language models (LLMs) are routinely deployed as agentic systems, with access to tools that interact with live environments to accomplish tasks. In enterprise deployments these systems need to interact with API collections that can be extremely large and complex, often backed by databases. In order to create datasets with such characteristics, we explore how existing NL2SQL (Natural Language to SQL query) datasets can be used to automatically create NL2API datasets. Specifically, this work describes a novel data generation pipeline that exploits the syntax of SQL queries to construct a functionally equivalent sequence of API calls. We apply this pipeline to one of the largest NL2SQL datasets, BIRD-SQL to create a collection of over 2500 APIs that can be served as invocable tools or REST-endpoints. We pair natural language queries from BIRD-SQL to ground-truth API sequences based on this API pool. We use this collection to study the performance of 10 public LLMs and find that all models struggle to determine the right set of tools (consisting of tasks of intent detection, sequencing with nested function calls, and slot-filling). We find that models have extremely low task completion rates (7-47 percent - depending on the dataset) which marginally improves to 50 percent when models are employed as ReACT agents that interact with the live API environment. The best task completion rates are far below what may be required for effective general-use tool-calling agents, suggesting substantial scope for improvement in current state-of-the-art tool-calling LLMs. We also conduct detailed ablation studies, such as assessing the impact of the number of tools available as well as the impact of tool and slot-name obfuscation. We compare the performance of models on the original SQL generation tasks and find that current models are sometimes able to exploit SQL better than APIs.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": "10+32 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2506.11266.pdf", "abstract_url": "https://arxiv.org/abs/2506.11266", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"]}
{"id": "2506.11563", "title": "Learn to Preserve Personality: Federated Foundation Models in Recommendations", "authors": ["Zhiwei Li", "Guodong Long", "Chunxu Zhang", "Honglei Zhang", "Jing Jiang", "Chengqi Zhang"], "abstract": "A core learning challenge for existed Foundation Models (FM) is striking the tradeoff between generalization with personalization, which is a dilemma that has been highlighted by various parameter-efficient adaptation techniques. Federated foundation models (FFM) provide a structural means to decouple shared knowledge from individual specific adaptations via decentralized processes. Recommendation systems offer a perfect testbed for FFMs, given their reliance on rich implicit feedback reflecting unique user characteristics. This position paper discusses a novel learning paradigm where FFMs not only harness their generalization capabilities but are specifically designed to preserve the integrity of user personality, illustrated thoroughly within the recommendation contexts. We envision future personal agents, powered by personalized adaptive FMs, guiding user decisions on content. Such an architecture promises a user centric, decentralized system where individuals maintain control over their personalized agents.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "14 pages, 3 figures, conference, position paper", "pdf_url": "https://arxiv.org/pdf/2506.11563.pdf", "abstract_url": "https://arxiv.org/abs/2506.11563", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2506.11600", "title": "GraphRAG-Causal: A novel graph-augmented framework for causal reasoning and annotation in news", "authors": ["Abdul Haque", "Umm e Hani", "Ahmad Din", "Muhammad Babar", "Ali Abbas", "Insaf Ullah"], "abstract": "GraphRAG-Causal introduces an innovative framework that combines graph-based retrieval with large language models to enhance causal reasoning in news analysis. Traditional NLP approaches often struggle with identifying complex, implicit causal links, especially in low-data scenarios. Our approach addresses these challenges by transforming annotated news headlines into structured causal knowledge graphs. It then employs a hybrid retrieval system that merges semantic embeddings with graph-based structural cues leveraging Neo4j to accurately match and retrieve relevant events. The framework is built on a three-stage pipeline: First, during Data Preparation, news sentences are meticulously annotated and converted into causal graphs capturing cause, effect, and trigger relationships. Next, the Graph Retrieval stage stores these graphs along with their embeddings in a Neo4j database and utilizes hybrid Cypher queries to efficiently identify events that share both semantic and structural similarities with a given query. Finally, the LLM Inference stage utilizes these retrieved causal graphs in a few-shot learning setup with XML-based prompting, enabling robust classification and tagging of causal relationships. Experimental evaluations demonstrate that GraphRAG-Causal achieves an impressive F1-score of 82.1% on causal classification using just 20 few-shot examples. This approach significantly boosts accuracy and consistency, making it highly suitable for real-time applications in news reliability assessment, misinformation detection, and policy analysis.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "comments": "18 pages, 8 figures", "pdf_url": "https://arxiv.org/pdf/2506.11600.pdf", "abstract_url": "https://arxiv.org/abs/2506.11600", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"]}
{"id": "2506.11650", "title": "Robot Context Protocol (RCP): A Runtime-Agnostic Interface for Agent-Aware Robot Control", "authors": ["Lambert Lee", "Joshua Lau"], "abstract": "The Robot Context Protocol (RCP) is a lightweight, middleware-agnostic communication protocol designed to simplify the complexity of robotic systems and enable seamless interaction between robots, users, and autonomous agents. RCP provides a unified and semantically meaningful interface that decouples client-facing operations from backend implementations, supporting a wide range of deployment environments including physical robots, cloud-based orchestrators, and simulated platforms. Built on HTTP and WebSocket transport layers, the protocol defines a schema-driven message format with structured operations such as read, write, execute, and subscribe. It integrates features such as runtime introspection, asynchronous feedback, multi-tenant namespace isolation, and strict type validation to ensure robustness, scalability, and security. The architecture, message structure, interface model, and adapter-based backend integration strategy of RCP are described, along with deployment practices and applicability across industries including manufacturing, logistics, and healthcare. RCP enables intelligent, resilient, and safe robotic operations in complex, multi-agent ecosystems.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.11650.pdf", "abstract_url": "https://arxiv.org/abs/2506.11650", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2506.11718", "title": "Interaction, Process, Infrastructure: A Unified Architecture for Human-Agent Collaboration", "authors": ["Yun Wang", "Yan Lu"], "abstract": "As AI tools proliferate across domains, from chatbots and copilots to emerging agents, they increasingly support professional knowledge work. Yet despite their growing capabilities, these systems remain fragmented: they assist with isolated tasks but lack the architectural scaffolding for sustained, adaptive collaboration. We propose a layered framework for human-agent systems that integrates three interdependent dimensions: interaction, process, and infrastructure. Crucially, our architecture elevates process to a primary focus by making it explicit, inspectable, and adaptable, enabling humans and agents to align with evolving goals and coordinate over time. This model clarifies limitations of current tools, unifies emerging system design approaches, and reveals new opportunities for researchers and AI system builders. By grounding intelligent behavior in structured collaboration, we reimagine human-agent collaboration not as task-specific augmentation, but as a form of coherent and aligned system for real-world work.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.11718.pdf", "abstract_url": "https://arxiv.org/abs/2506.11718", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2506.11882", "title": "An Explainable AI Framework for Dynamic Resource Management in Vehicular Network Slicing", "authors": ["Haochen Sun", "Yifan Liu", "Ahmed Al-Tahmeesschi", "Swarna Chetty", "Syed Ali Raza Zaidi", "Avishek Nag", "Hamed Ahmadi"], "abstract": "Effective resource management and network slicing are essential to meet the diverse service demands of vehicular networks, including Enhanced Mobile Broadband (eMBB) and Ultra-Reliable and Low-Latency Communications (URLLC). This paper introduces an Explainable Deep Reinforcement Learning (XRL) framework for dynamic network slicing and resource allocation in vehicular networks, built upon a near-real-time RAN intelligent controller. By integrating a feature-based approach that leverages Shapley values and an attention mechanism, we interpret and refine the decisions of our reinforcementlearning agents, addressing key reliability challenges in vehicular communication systems. Simulation results demonstrate that our approach provides clear, real-time insights into the resource allocation process and achieves higher interpretability precision than a pure attention mechanism. Furthermore, the Quality of Service (QoS) satisfaction for URLLC services increased from 78.0% to 80.13%, while that for eMBB services improved from 71.44% to 73.21%.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "To appear in Proceedings of IEEE PIMRC 2025. 6 pages, 4 figures", "pdf_url": "https://arxiv.org/pdf/2506.11882.pdf", "abstract_url": "https://arxiv.org/abs/2506.11882", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2506.11912", "title": "Breaking Habits: On the Role of the Advantage Function in Learning Causal State Representations", "authors": ["Miguel Suau"], "abstract": "Recent work has shown that reinforcement learning agents can develop policies that exploit spurious correlations between rewards and observations. This phenomenon, known as policy confounding, arises because the agent's policy influences both past and future observation variables, creating a feedback loop that can hinder the agent's ability to generalize beyond its usual trajectories. In this paper, we show that the advantage function, commonly used in policy gradient methods, not only reduces the variance of gradient estimates but also mitigates the effects of policy confounding. By adjusting action values relative to the state representation, the advantage function downweights state-action pairs that are more likely under the current policy, breaking spurious correlations and encouraging the agent to focus on causal factors. We provide both analytical and empirical evidence demonstrating that training with the advantage function leads to improved out-of-trajectory performance.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.11912.pdf", "abstract_url": "https://arxiv.org/abs/2506.11912", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2506.12003", "title": "Upgrade or Switch: Do We Need a New Registry Architecture for the Internet of AI Agents?", "authors": ["Ramesh Raskar", "Pradyumna Chari", "Jared James Grogan", "Mahesh Lambe", "Robert Lincourt", "Raghu Bala", "Abhishek Singh", "Ayush Chopra", "Rajesh Ranjan", "Shailja Gupta", "Dimitris Stripelis", "Maria Gorskikh", "Sichao Wang"], "abstract": "The emerging Internet of AI Agents challenges existing web infrastructure designed for human-scale, reactive interactions. Unlike traditional web resources, autonomous AI agents initiate actions, maintain persistent state, spawn sub-agents, and negotiate directly with peers: demanding millisecond-level discovery, instant credential revocation, and cryptographic behavioral proofs that exceed current DNS/PKI capabilities. This paper analyzes whether to upgrade existing infrastructure or implement purpose-built registry architectures for autonomous agents. We identify critical failure points: DNS propagation (24-48 hours vs. required milliseconds), certificate revocation unable to scale to trillions of entities, and IPv4/IPv6 addressing inadequate for agent-scale routing. We evaluate three approaches: (1) Upgrade paths, (2) Switch options, (3) Hybrid registries. Drawing parallels to dialup-to-broadband transitions, we find that agent requirements constitute qualitative, and not incremental, changes. While upgrades offer compatibility and faster deployment, clean-slate solutions provide better performance but require longer for adoption. Our analysis suggests hybrid approaches will emerge, with centralized registries for critical agents and federated meshes for specialized use cases.", "subjects": "Networking and Internet Architecture (cs.NI); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.12003.pdf", "abstract_url": "https://arxiv.org/abs/2506.12003", "categories": ["Networking and Internet Architecture (cs.NI)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"]}
