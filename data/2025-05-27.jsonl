{"id": "2505.18679", "title": "Manifold-aware Representation Learning for Degradation-agnostic Image Restoration", "authors": ["Bin Ren", "Yawei Li", "Xu Zheng", "Yuqian Fu", "Danda Pani Paudel", "Ming-Hsuan Yang", "Luc Van Gool", "Nicu Sebe"], "abstract": "Image Restoration (IR) aims to recover high quality images from degraded inputs affected by various corruptions such as noise, blur, haze, rain, and low light conditions. Despite recent advances, most existing approaches treat IR as a direct mapping problem, relying on shared representations across degradation types without modeling their structural diversity. In this work, we present MIRAGE, a unified and lightweight framework for all in one IR that explicitly decomposes the input feature space into three semantically aligned parallel branches, each processed by a specialized module attention for global context, convolution for local textures, and MLP for channel-wise statistics. This modular decomposition significantly improves generalization and efficiency across diverse degradations. Furthermore, we introduce a cross layer contrastive learning scheme that aligns shallow and latent features to enhance the discriminability of shared representations. To better capture the underlying geometry of feature representations, we perform contrastive learning in a Symmetric Positive Definite (SPD) manifold space rather than the conventional Euclidean space. Extensive experiments show that MIRAGE not only achieves new state of the art performance across a variety of degradation types but also offers a scalable solution for challenging all-in-one IR scenarios. Our code and models will be publicly available at", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "ALl-in-One Image Restoration, low-level vision", "pdf_url": "https://arxiv.org/pdf/2505.18679.pdf", "abstract_url": "https://arxiv.org/abs/2505.18679", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["@RAG"]}
{"id": "2505.18218", "title": "CoMet: Metaphor-Driven Covert Communication for Multi-Agent Language Games", "authors": ["Shuhang Xu", "Fangwei Zhong"], "abstract": "Metaphors are a crucial way for humans to express complex or subtle ideas by comparing one concept to another, often from a different domain. However, many large language models (LLMs) struggle to interpret and apply metaphors in multi-agent language games, hindering their ability to engage in covert communication and semantic evasion, which are crucial for strategic communication. To address this challenge, we introduce CoMet, a framework that enables LLM-based agents to engage in metaphor processing. CoMet combines a hypothesis-based metaphor reasoner with a metaphor generator that improves through self-reflection and knowledge integration. This enhances the agents' ability to interpret and apply metaphors, improving the strategic and nuanced quality of their interactions. We evaluate CoMet on two multi-agent language games - Undercover and Adversarial Taboo - which emphasize Covert Communication and Semantic Evasion. Experimental results demonstrate that CoMet significantly enhances the agents' ability to communicate strategically using metaphors.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "To Appear at ACL 2025 (Main)", "pdf_url": "https://arxiv.org/pdf/2505.18218.pdf", "abstract_url": "https://arxiv.org/abs/2505.18218", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.18223", "title": "IDA-Bench: Evaluating LLMs on Interactive Guided Data Analysis", "authors": ["Hanyu Li", "Haoyu Liu", "Tingyu Zhu", "Tianyu Guo", "Zeyu Zheng", "Xiaotie Deng", "Michael I. Jordan"], "abstract": "Large Language Models (LLMs) show promise as data analysis agents, but existing benchmarks overlook the iterative nature of the field, where experts' decisions evolve with deeper insights of the dataset. To address this, we introduce IDA-Bench, a novel benchmark evaluating LLM agents in multi-round interactive scenarios. Derived from complex Kaggle notebooks, tasks are presented as sequential natural language instructions by an LLM-simulated user. Agent performance is judged by comparing its final numerical output to the human-derived baseline. Initial results show that even state-of-the-art coding agents (like Claude-3.7-thinking) succeed on < 50% of the tasks, highlighting limitations not evident in single-turn tests. This work underscores the need to improve LLMs' multi-round capabilities for building more reliable data analysis agents, highlighting the necessity of achieving a balance between instruction following and reasoning.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18223.pdf", "abstract_url": "https://arxiv.org/abs/2505.18223", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.18247", "title": "MetaGen Blended RAG: Higher Accuracy for Domain-Specific Q&A Without Fine-Tuning", "authors": ["Kunal Sawarkar", "Shivam R. Solanki", "Abhilasha Mangal"], "abstract": "Despite the widespread exploration of Retrieval-Augmented Generation (RAG), its deployment in enterprises for domain-specific datasets remains limited due to poor answer accuracy. These corpora, often shielded behind firewalls in private enterprise knowledge bases, having complex, domain-specific terminology, rarely seen by LLMs during pre-training; exhibit significant semantic variability across domains (like networking, military, or legal, etc.), or even within a single domain like medicine, and thus result in poor context precision for RAG systems. Currently, in such situations, fine-tuning or RAG with fine-tuning is attempted, but these approaches are slow, expensive, and lack generalization for accuracy as the new domain-specific data emerges. We propose an approach for Enterprise Search that focuses on enhancing the retriever for a domain-specific corpus through hybrid query indexes and metadata enrichment. This 'MetaGen Blended RAG' method constructs a metadata generation pipeline using key concepts, topics, and acronyms, and then creates a metadata-enriched hybrid index with boosted search queries. This approach avoids overfitting and generalizes effectively across domains. On the PubMedQA benchmark for the biomedical domain, the proposed method achieves 82% retrieval accuracy and 77% RAG accuracy, surpassing all previous RAG accuracy results without fine-tuning and sets a new benchmark for zero-shot results while outperforming much larger models like GPT3.5. The results are even comparable to the best fine-tuned models on this dataset, and we further demonstrate the robustness and scalability of the approach by evaluating it on other Q&A datasets like SQuAD, NQ etc.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (cs.LG)", "comments": "Preprint. Paper Submitted NeurIPS 2025- The Thirty-Ninth Annual Conference on Neural Information Processing Systems", "pdf_url": "https://arxiv.org/pdf/2505.18247.pdf", "abstract_url": "https://arxiv.org/abs/2505.18247", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"]}
{"id": "2505.18457", "title": "EdgeAgentX: A Novel Framework for Agentic AI at the Edge in Military Communication Networks", "authors": ["Abir Ray"], "abstract": "This paper introduces EdgeAgentX, a novel framework integrating federated learning (FL), multi-agent reinforcement learning (MARL), and adversarial defense mechanisms, tailored for military communication networks. EdgeAgentX significantly improves autonomous decision-making, reduces latency, enhances throughput, and robustly withstands adversarial disruptions, as evidenced by comprehensive simulations.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multiagent Systems (cs.MA)", "comments": "6 pages, 2 figures", "pdf_url": "https://arxiv.org/pdf/2505.18457.pdf", "abstract_url": "https://arxiv.org/abs/2505.18457", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"]}
{"id": "2505.18541", "title": "RoleRAG: Enhancing LLM Role-Playing via Graph Guided Retrieval", "authors": ["Yongjie Wang", "Jonathan Leung", "Zhiqi Shen"], "abstract": "Large Language Models (LLMs) have shown promise in character imitation, enabling immersive and engaging conversations. However, they often generate content that is irrelevant or inconsistent with a character's background. We attribute these failures to: (1) the inability to accurately recall character-specific knowledge due to entity ambiguity, and (2) a lack of awareness of the character's cognitive boundaries. To address these issues, we propose RoleRAG, a retrieval-based framework that integrates efficient entity disambiguation for knowledge indexing with a boundary-aware retriever for extracting contextually appropriate information from a structured knowledge graph. Experiments on role-playing benchmarks show that RoleRAG's calibrated retrieval helps both general-purpose and role-specific LLMs better align with character knowledge and reduce hallucinated responses.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "A Retrieval-enhanced LLM Role-playing", "pdf_url": "https://arxiv.org/pdf/2505.18541.pdf", "abstract_url": "https://arxiv.org/abs/2505.18541", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"]}
{"id": "2505.18411", "title": "DanmakuTPPBench: A Multi-modal Benchmark for Temporal Point Process Modeling and Understanding", "authors": ["Yue Jiang", "Jichu Li", "Yang Liu", "Dingkang Yang", "Feng Zhou", "Quyu Kong"], "abstract": "We introduce DanmakuTPPBench, a comprehensive benchmark designed to advance multi-modal Temporal Point Process (TPP) modeling in the era of Large Language Models (LLMs). While TPPs have been widely studied for modeling temporal event sequences, existing datasets are predominantly unimodal, hindering progress in models that require joint reasoning over temporal, textual, and visual information. To address this gap, DanmakuTPPBench comprises two complementary components: (1) DanmakuTPP-Events, a novel dataset derived from the Bilibili video platform, where user-generated bullet comments (Danmaku) naturally form multi-modal events annotated with precise timestamps, rich textual content, and corresponding video frames; (2) DanmakuTPP-QA, a challenging question-answering dataset constructed via a novel multi-agent pipeline powered by state-of-the-art LLMs and multi-modal LLMs (MLLMs), targeting complex temporal-textual-visual reasoning. We conduct extensive evaluations using both classical TPP models and recent MLLMs, revealing significant performance gaps and limitations in current methods' ability to model multi-modal event dynamics. Our benchmark establishes strong baselines and calls for further integration of TPP modeling into the multi-modal language modeling landscape. The code and dataset have been released at", "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.18411.pdf", "abstract_url": "https://arxiv.org/abs/2505.18411", "categories": ["Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"]}
{"id": "2505.18426", "title": "Retrieval Augmented Generation-based Large Language Models for Bridging Transportation Cybersecurity Legal Knowledge Gaps", "authors": ["Khandakar Ashrafi Akbar", "Md Nahiyan Uddin", "Latifur Khan", "Trayce Hockstad", "Mizanur Rahman", "Mashrur Chowdhury", "Bhavani Thuraisingham"], "abstract": "As connected and automated transportation systems evolve, there is a growing need for federal and state authorities to revise existing laws and develop new statutes to address emerging cybersecurity and data privacy challenges. This study introduces a Retrieval-Augmented Generation (RAG) based Large Language Model (LLM) framework designed to support policymakers by extracting relevant legal content and generating accurate, inquiry-specific responses. The framework focuses on reducing hallucinations in LLMs by using a curated set of domain-specific questions to guide response generation. By incorporating retrieval mechanisms, the system enhances the factual grounding and specificity of its outputs. Our analysis shows that the proposed RAG-based LLM outperforms leading commercial LLMs across four evaluation metrics: AlignScore, ParaScore, BERTScore, and ROUGE, demonstrating its effectiveness in producing reliable and context-aware legal insights. This approach offers a scalable, AI-driven method for legislative analysis, supporting efforts to update legal frameworks in line with advancements in transportation technologies.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "Presented at the Transportation Research Board (TRB) Annual Meeting 2025, and subsequently submitted for publication consideration in the Transportation Research Record (TRR)", "pdf_url": "https://arxiv.org/pdf/2505.18426.pdf", "abstract_url": "https://arxiv.org/abs/2505.18426", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"]}
{"id": "2505.18450", "title": "BRIT: Bidirectional Retrieval over Unified Image-Text Graph", "authors": ["Ainulla Khan", "Yamada Moyuru", "Srinidhi Akella"], "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a promising technique to enhance the quality and relevance of responses generated by large language models. While recent advancements have mainly focused on improving RAG for text-based queries, RAG on multi-modal documents containing both texts and images has not been fully explored. Especially when fine-tuning does not work. This paper proposes BRIT, a novel multi-modal RAG framework that effectively unifies various text-image connections in the document into a multi-modal graph and retrieves the texts and images as a query-specific sub-graph. By traversing both image-to-text and text-to-image paths in the graph, BRIT retrieve not only directly query-relevant images and texts but also further relevant contents to answering complex cross-modal multi-hop questions. To evaluate the effectiveness of BRIT, we introduce MM-RAG test set specifically designed for multi-modal question answering tasks that require to understand the text-image relations. Our comprehensive experiments demonstrate the superiority of BRIT, highlighting its ability to handle cross-modal questions on the multi-modal documents.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18450.pdf", "abstract_url": "https://arxiv.org/abs/2505.18450", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"]}
{"id": "2505.18497", "title": "The Pragmatic Mind of Machines: Tracing the Emergence of Pragmatic Competence in Large Language Models", "authors": ["Kefan Yu", "Qingcheng Zeng", "Weihao Xuan", "Wanxin Li", "Jingyi Wu", "Rob Voigt"], "abstract": "Current large language models (LLMs) have demonstrated emerging capabilities in social intelligence tasks, including implicature resolution (Sravanthi et al. (2024)) and theory-of-mind reasoning (Shapira et al. (2024)), both of which require substantial pragmatic understanding. However, how LLMs acquire this competence throughout the training process remains poorly understood. In this work, we introduce ALTPRAG, a dataset grounded in the pragmatic concept of alternatives, designed to evaluate whether LLMs at different training stages can accurately infer nuanced speaker intentions. Each instance pairs two contextually appropriate but pragmatically distinct continuations, enabling fine-grained assessment of both pragmatic interpretation and contrastive reasoning. We systematically evaluate 22 LLMs across key training stages: pre-training, supervised fine-tuning (SFT), and preference optimization, to examine the development of pragmatic competence. Our results show that even base models exhibit notable sensitivity to pragmatic cues, which improves consistently with increases in model and data scale. Additionally, SFT and RLHF contribute further gains, particularly in cognitive-pragmatic reasoning. These findings highlight pragmatic competence as an emergent and compositional property of LLM training and offer new insights for aligning models with human communicative norms.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18497.pdf", "abstract_url": "https://arxiv.org/abs/2505.18497", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"]}
{"id": "2505.18597", "title": "LLMs for Supply Chain Management", "authors": ["Haojie Wang", "Jiuyun Jiang", "L. Jeff Hong", "Guangxin Jiang"], "abstract": "The development of large language models (LLMs) has provided new tools for research in supply chain management (SCM). In this paper, we introduce a retrieval-augmented generation (RAG) framework that dynamically integrates external knowledge into the inference process, and develop a domain-specialized SCM LLM, which demonstrates expert-level competence by passing standardized SCM examinations and beer game tests. We further employ the use of LLMs to conduct horizontal and vertical supply chain games, in order to analyze competition and cooperation within supply chains. Our experiments show that RAG significantly improves performance on SCM tasks. Moreover, game-theoretic analysis reveals that the LLM can reproduce insights from the classical SCM literature, while also uncovering novel behaviors and offering fresh perspectives on phenomena such as the bullwhip effect. This paper opens the door for exploring cooperation and competition for complex supply chain network through the lens of LLMs.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Applications (stat.AP)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18597.pdf", "abstract_url": "https://arxiv.org/abs/2505.18597", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Applications (stat.AP)"], "matching_keywords": ["@RAG"]}
{"id": "2505.18607", "title": "Knowledge Retrieval in LLM Gaming: A Shift from Entity-Centric to Goal-Oriented Graphs", "authors": ["Jonathan Leung", "Yongjie Wang", "Zhiqi Shen"], "abstract": "Large Language Models (LLMs) demonstrate impressive general capabilities but often struggle with step-by-step reasoning, especially in complex applications such as games. While retrieval-augmented methods like GraphRAG attempt to bridge this gap through cross-document extraction and indexing, their fragmented entity-relation graphs and overly dense local connectivity hinder the construction of coherent reasoning. In this paper, we propose a novel framework based on Goal-Oriented Graphs (GoGs), where each node represents a goal and its associated attributes, and edges encode logical dependencies between goals. This structure enables explicit retrieval of reasoning paths by first identifying high-level goals and recursively retrieving their subgoals, forming coherent reasoning chains to guide LLM prompting. Our method significantly enhances the reasoning ability of LLMs in game-playing tasks, as demonstrated by extensive experiments on the Minecraft testbed, outperforming GraphRAG and other baselines.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18607.pdf", "abstract_url": "https://arxiv.org/abs/2505.18607", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"]}
{"id": "2505.18705", "title": "AI-Researcher: Autonomous Scientific Innovation", "authors": ["Jiabin Tang", "Lianghao Xia", "Zhonghang Li", "Chao Huang"], "abstract": "The powerful reasoning capabilities of Large Language Models (LLMs) in mathematics and coding, combined with their ability to automate complex tasks through agentic frameworks, present unprecedented opportunities for accelerating scientific innovation. In this paper, we introduce AI-Researcher, a fully autonomous research system that transforms how AI-driven scientific discovery is conducted and evaluated. Our framework seamlessly orchestrates the complete research pipeline--from literature review and hypothesis generation to algorithm implementation and publication-ready manuscript preparation--with minimal human intervention. To rigorously assess autonomous research capabilities, we develop Scientist-Bench, a comprehensive benchmark comprising state-of-the-art papers across diverse AI research domains, featuring both guided innovation and open-ended exploration tasks. Through extensive experiments, we demonstrate that AI-Researcher achieves remarkable implementation success rates and produces research papers that approach human-level quality. This work establishes new foundations for autonomous scientific innovation that can complement human researchers by systematically exploring solution spaces beyond cognitive limitations.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.18705.pdf", "abstract_url": "https://arxiv.org/abs/2505.18705", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"]}
{"id": "2505.18746", "title": "$C^3$-Bench: The Things Real Disturbing LLM based Agent in Multi-Tasking", "authors": ["Peijie Yu", "Yifan Yang", "Jinjian Li", "Zelong Zhang", "Haorui Wang", "Xiao Feng", "Feng Zhang"], "abstract": "Agents based on large language models leverage tools to modify environments, revolutionizing how AI interacts with the physical world. Unlike traditional NLP tasks that rely solely on historical dialogue for responses, these agents must consider more complex factors, such as inter-tool relationships, environmental feedback and previous decisions, when making choices. Current research typically evaluates agents via multi-turn dialogues. However, it overlooks the influence of these critical factors on agent behavior. To bridge this gap, we present an open-source and high-quality benchmark $C^3$-Bench. This benchmark integrates attack concepts and applies univariate analysis to pinpoint key elements affecting agent robustness. In concrete, we design three challenges: navigate complex tool relationships, handle critical hidden information and manage dynamic decision paths. Complementing these challenges, we introduce fine-grained metrics, innovative data collection algorithms and reproducible evaluation methods. Extensive experiments are conducted on 49 mainstream agents, encompassing general fast-thinking, slow-thinking and domain-specific models. We observe that agents have significant shortcomings in handling tool dependencies, long context information dependencies and frequent policy-type switching. In essence, $C^3$-Bench aims to expose model vulnerabilities through these challenges and drive research into the interpretability of agent performance. The benchmark is publicly available at", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18746.pdf", "abstract_url": "https://arxiv.org/abs/2505.18746", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.18881", "title": "SD-OVON: A Semantics-aware Dataset and Benchmark Generation Pipeline for Open-Vocabulary Object Navigation in Dynamic Scenes", "authors": ["Dicong Qiu", "Jiadi You", "Zeying Gong", "Ronghe Qiu", "Hui Xiong", "Junwei Liang"], "abstract": "We present the Semantics-aware Dataset and Benchmark Generation Pipeline for Open-vocabulary Object Navigation in Dynamic Scenes (SD-OVON). It utilizes pretraining multimodal foundation models to generate infinite unique photo-realistic scene variants that adhere to real-world semantics and daily commonsense for the training and the evaluation of navigation agents, accompanied with a plugin for generating object navigation task episodes compatible to the Habitat simulator. In addition, we offer two pre-generated object navigation task datasets, SD-OVON-3k and SD-OVON-10k, comprising respectively about 3k and 10k episodes of the open-vocabulary object navigation task, derived from the SD-OVON-Scenes dataset with 2.5k photo-realistic scans of real-world environments and the SD-OVON-Objects dataset with 0.9k manually inspected scanned and artist-created manipulatable object models. Unlike prior datasets limited to static environments, SD-OVON covers dynamic scenes and manipulatable objects, facilitating both real-to-sim and sim-to-real robotic applications. This approach enhances the realism of navigation tasks, the training and the evaluation of open-vocabulary object navigation agents in complex settings. To demonstrate the effectiveness of our pipeline and datasets, we propose two baselines and evaluate them along with state-of-the-art baselines on SD-OVON-3k. The datasets, benchmark and source code are publicly available.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": "Preprint. 21 pages", "pdf_url": "https://arxiv.org/pdf/2505.18881.pdf", "abstract_url": "https://arxiv.org/abs/2505.18881", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"]}
{"id": "2505.18899", "title": "Beyond Domain Randomization: Event-Inspired Perception for Visually Robust Adversarial Imitation from Videos", "authors": ["Andrea Ramazzina", "Vittorio Giammarino", "Matteo El-Hariry", "Mario Bijelic"], "abstract": "Imitation from videos often fails when expert demonstrations and learner environments exhibit domain shifts, such as discrepancies in lighting, color, or texture. While visual randomization partially addresses this problem by augmenting training data, it remains computationally intensive and inherently reactive, struggling with unseen scenarios. We propose a different approach: instead of randomizing appearances, we eliminate their influence entirely by rethinking the sensory representation itself. Inspired by biological vision systems that prioritize temporal transients (e.g., retinal ganglion cells) and by recent sensor advancements, we introduce event-inspired perception for visually robust imitation. Our method converts standard RGB videos into a sparse, event-based representation that encodes temporal intensity gradients, discarding static appearance features. This biologically grounded approach disentangles motion dynamics from visual style, enabling robust visual imitation from observations even in the presence of visual mismatches between expert and agent environments. By training policies on event streams, we achieve invariance to appearance-based distractors without requiring computationally expensive and environment-specific data augmentation techniques. Experiments across the DeepMind Control Suite and the Adroit platform for dynamic dexterous manipulation show the efficacy of our method. Our code is publicly available at Eb-LAIfO.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18899.pdf", "abstract_url": "https://arxiv.org/abs/2505.18899", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Machine Learning (cs.LG)", "Robotics (cs.RO)"], "matching_keywords": ["agent"]}
{"id": "2505.18581", "title": "Removal of Hallucination on Hallucination: Debate-Augmented RAG", "authors": ["Wentao Hu", "Wengyu Zhang", "Yiyang Jiang", "Chen Jason Zhang", "Xiaoyong Wei", "Qing Li"], "abstract": "Retrieval-Augmented Generation (RAG) enhances factual accuracy by integrating external knowledge, yet it introduces a critical issue: erroneous or biased retrieval can mislead generation, compounding hallucinations, a phenomenon we term Hallucination on Hallucination. To address this, we propose Debate-Augmented RAG (DRAG), a training-free framework that integrates Multi-Agent Debate (MAD) mechanisms into both retrieval and generation stages. In retrieval, DRAG employs structured debates among proponents, opponents, and judges to refine retrieval quality and ensure factual reliability. In generation, DRAG introduces asymmetric information roles and adversarial debates, enhancing reasoning robustness and mitigating factual inconsistencies. Evaluations across multiple tasks demonstrate that DRAG improves retrieval reliability, reduces RAG-induced hallucinations, and significantly enhances overall factual accuracy. Our code is available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "Accepted by ACL 2025", "pdf_url": "https://arxiv.org/pdf/2505.18581.pdf", "abstract_url": "https://arxiv.org/abs/2505.18581", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "@RAG"]}
{"id": "2505.18596", "title": "Debate-to-Detect: Reformulating Misinformation Detection as a Real-World Debate with Large Language Models", "authors": ["Chen Han", "Wenzhen Zheng", "Xijin Tang"], "abstract": "The proliferation of misinformation in digital platforms reveals the limitations of traditional detection methods, which mostly rely on static classification and fail to capture the intricate process of real-world fact-checking. Despite advancements in Large Language Models (LLMs) that enhance automated reasoning, their application to misinformation detection remains hindered by issues of logical inconsistency and superficial verification. In response, we introduce Debate-to-Detect (D2D), a novel Multi-Agent Debate (MAD) framework that reformulates misinformation detection as a structured adversarial debate. Inspired by fact-checking workflows, D2D assigns domain-specific profiles to each agent and orchestrates a five-stage debate process, including Opening Statement, Rebuttal, Free Debate, Closing Statement, and Judgment. To transcend traditional binary classification, D2D introduces a multi-dimensional evaluation mechanism that assesses each claim across five distinct dimensions: Factuality, Source Reliability, Reasoning Quality, Clarity, and Ethics. Experiments with GPT-4o on two fakenews datasets demonstrate significant improvements over baseline methods, and the case study highlight D2D's capability to iteratively refine evidence while improving decision transparency, representing a substantial advancement towards robust and interpretable misinformation detection. The code will be open-sourced in a future release.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18596.pdf", "abstract_url": "https://arxiv.org/abs/2505.18596", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.18829", "title": "LiteCUA: Computer as MCP Server for Computer-Use Agent on AIOS", "authors": ["Kai Mei", "Xi Zhu", "Hang Gao", "Shuhang Lin", "Yongfeng Zhang"], "abstract": "We present AIOS 1.0, a novel platform designed to advance computer-use agent (CUA) capabilities through environmental contextualization. While existing approaches primarily focus on building more powerful agent frameworks or enhancing agent models, we identify a fundamental limitation: the semantic disconnect between how language models understand the world and how computer interfaces are structured. AIOS 1.0 addresses this challenge by transforming computers into contextual environments that language models can natively comprehend, implementing a Model Context Protocol (MCP) server architecture to abstract computer states and actions. This approach effectively decouples interface complexity from decision complexity, enabling agents to reason more effectively about computing environments. To demonstrate our platform's effectiveness, we introduce LiteCUA, a lightweight computer-use agent built on AIOS 1.0 that achieves a 14.66% success rate on the OSWorld benchmark, outperforming several specialized agent frameworks despite its simple architecture. Our results suggest that contextualizing computer environments for language models represents a promising direction for developing more capable computer-use agents and advancing toward AI that can interact with digital systems. The source code of LiteCUA is available at", "subjects": "Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Operating Systems (cs.OS)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18829.pdf", "abstract_url": "https://arxiv.org/abs/2505.18829", "categories": ["Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)", "Operating Systems (cs.OS)"], "matching_keywords": ["agent"]}
{"id": "2505.18946", "title": "SANNet: A Semantic-Aware Agentic AI Networking Framework for Multi-Agent Cross-Layer Coordination", "authors": ["Yong Xiao", "Haoran Zhou", "Xubo Li", "Yayu Gao", "Guangming Shi", "Ping Zhang"], "abstract": "Agentic AI networking (AgentNet) is a novel AI-native networking paradigm that relies on a large number of specialized AI agents to collaborate and coordinate for autonomous decision-making, dynamic environmental adaptation, and complex goal achievement. It has the potential to facilitate real-time network management alongside capabilities for self-configuration, self-optimization, and self-adaptation across diverse and complex networking environments, laying the foundation for fully autonomous networking systems in the future. Despite its promise, AgentNet is still in the early stage of development, and there still lacks an effective networking framework to support automatic goal discovery and multi-agent self-orchestration and task assignment. This paper proposes SANNet, a novel semantic-aware agentic AI networking architecture that can infer the semantic goal of the user and automatically assign agents associated with different layers of a mobile system to fulfill the inferred goal. Motivated by the fact that one of the major challenges in AgentNet is that different agents may have different and even conflicting objectives when collaborating for certain goals, we introduce a dynamic weighting-based conflict-resolving mechanism to address this issue. We prove that SANNet can provide theoretical guarantee in both conflict-resolving and model generalization performance for multi-agent collaboration in dynamic environment. We develop a hardware prototype of SANNet based on the open RAN and 5GS core platform. Our experimental results show that SANNet can significantly improve the performance of multi-agent networking systems, even when agents with conflicting objectives are selected to collaborate for the same goal.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA); Networking and Internet Architecture (cs.NI)", "comments": "submitted to IEEE GLOBECOM'25", "pdf_url": "https://arxiv.org/pdf/2505.18946.pdf", "abstract_url": "https://arxiv.org/abs/2505.18946", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)", "Networking and Internet Architecture (cs.NI)"], "matching_keywords": ["agent", "agentic"]}
{"id": "2505.18630", "title": "DDO: Dual-Decision Optimization via Multi-Agent Collaboration for LLM-Based Medical Consultation", "authors": ["Zhihao Jia", "Mingyi Jia", "Junwen Duan", "Jianxin Wang"], "abstract": "Large Language Models (LLMs) demonstrate strong generalization and reasoning abilities, making them well-suited for complex decision-making tasks such as medical consultation (MC). However, existing LLM-based methods often fail to capture the dual nature of MC, which entails two distinct sub-tasks: symptom inquiry, a sequential decision-making process, and disease diagnosis, a classification problem. This mismatch often results in ineffective symptom inquiry and unreliable disease diagnosis. To address this, we propose \\textbf{DDO}, a novel LLM-based framework that performs \\textbf{D}ual-\\textbf{D}ecision \\textbf{O}ptimization by decoupling and independently optimizing the the two sub-tasks through a collaborative multi-agent workflow. Experiments on three real-world MC datasets show that DDO consistently outperforms existing LLM-based approaches and achieves competitive performance with state-of-the-art generation-based methods, demonstrating its effectiveness in the MC task.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "17 pages, 4 figures", "pdf_url": "https://arxiv.org/pdf/2505.18630.pdf", "abstract_url": "https://arxiv.org/abs/2505.18630", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"]}
{"id": "2505.19095", "title": "ScreenExplorer: Training a Vision-Language Model for Diverse Exploration in Open GUI World", "authors": ["Runliang Niu", "Jinglong Ji", "Yi Chang", "Qi Wang"], "abstract": "The rapid progress of large language models (LLMs) has sparked growing interest in building Artificial General Intelligence (AGI) within Graphical User Interface (GUI) environments. However, existing GUI agents based on LLMs or vision-language models (VLMs) often fail to generalize to novel environments and rely heavily on manually curated, diverse datasets. To overcome these limitations, we introduce ScreenExplorer, a VLM trained via Group Relative Policy Optimization(GRPO) in real, dynamic, and open-ended GUI environments. Innovatively, we introduced a world-model-based curiosity reward function to help the agent overcome the cold-start phase of exploration. Additionally, distilling experience streams further enhances the model's exploration capabilities. Our training framework enhances model exploration in open GUI environments, with trained models showing better environmental adaptation and sustained exploration compared to static deployment models. Our findings offer a scalable pathway toward AGI systems with self-improving capabilities in complex interactive settings.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19095.pdf", "abstract_url": "https://arxiv.org/abs/2505.19095", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.19167", "title": "Amplifying Human Creativity and Problem Solving with AI Through Generative Collective Intelligence", "authors": ["Thomas P. Kehler", "Scott E. Page", "Alex Pentland", "Martin Reeves", "John Seely Brown"], "abstract": "We propose a new framework for human-AI collaboration that amplifies the distinct capabilities of both. This framework, which we call Generative Collective Intelligence (GCI), shifts AI to the group/social level and employs AI in dual roles: as interactive agents and as technology that accumulates, organizes, and leverages knowledge. By creating a cognitive bridge between human reasoning and AI models, GCI can overcome the limitations of purely algorithmic approaches to problem-solving and decision-making. The framework demonstrates how AI can be reframed as a social and cultural technology that enables groups to solve complex problems through structured collaboration that transcends traditional communication barriers. We describe the mathematical foundations of GCI based on comparative judgment and minimum regret principles, and illustrate its applications across domains including climate adaptation, healthcare transformation, and civic participation. By combining human creativity with AI's computational capabilities, GCI offers a promising approach to addressing complex societal challenges that neither human or machines can solve alone.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19167.pdf", "abstract_url": "https://arxiv.org/abs/2505.19167", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.19173", "title": "Investigating Pedagogical Teacher and Student LLM Agents: Genetic Adaptation Meets Retrieval Augmented Generation Across Learning Style", "authors": ["Debdeep Sanyal", "Agniva Maiti", "Umakanta Maharana", "Dhruv Kumar", "Ankur Mali", "C. Lee Giles", "Murari Mandal"], "abstract": "Effective teaching requires adapting instructional strategies to accommodate the diverse cognitive and behavioral profiles of students, a persistent challenge in education and teacher training. While Large Language Models (LLMs) offer promise as tools to simulate such complex pedagogical environments, current simulation frameworks are limited in two key respects: (1) they often reduce students to static knowledge profiles, and (2) they lack adaptive mechanisms for modeling teachers who evolve their strategies in response to student feedback. To address these gaps, \\textbf{we introduce a novel simulation framework that integrates LLM-based heterogeneous student agents with a self-optimizing teacher agent}. The teacher agent's pedagogical policy is dynamically evolved using a genetic algorithm, allowing it to discover and refine effective teaching strategies based on the aggregate performance of diverse learners. In addition, \\textbf{we propose Persona-RAG}, a Retrieval Augmented Generation module that enables student agents to retrieve knowledge tailored to their individual learning styles. Persona-RAG preserves the retrieval accuracy of standard RAG baselines while enhancing personalization, an essential factor in modeling realistic educational scenarios. Through extensive experiments, we demonstrate how our framework supports the emergence of distinct and interpretable teaching patterns when interacting with varied student populations. Our results highlight the potential of LLM-driven simulations to inform adaptive teaching practices and provide a testbed for training human educators in controlled, data-driven environments.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "38 Pages", "pdf_url": "https://arxiv.org/pdf/2505.19173.pdf", "abstract_url": "https://arxiv.org/abs/2505.19173", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "@RAG"]}
{"id": "2505.19197", "title": "Structuring the Unstructured: A Multi-Agent System for Extracting and Querying Financial KPIs and Guidance", "authors": ["Chanyeol Choi", "Jihoon Kwon", "Minjae Kim", "Juneha Hwang", "Minsoo Ha", "Chaewoon Kim", "Jaeseon Ha", "Suyeol Yun", "Jin Kim"], "abstract": "Extracting structured and quantitative insights from unstructured financial filings is essential in investment research, yet remains time-consuming and resource-intensive. Conventional approaches in practice rely heavily on labor-intensive manual processes, limiting scalability and delaying the research workflow. In this paper, we propose an efficient and scalable method for accurately extracting quantitative insights from unstructured financial documents, leveraging a multi-agent system composed of large language models. Our proposed multi-agent system consists of two specialized agents: the \\emph{Extraction Agent} and the \\emph{Text-to-SQL Agent}. The \\textit{Extraction Agent} automatically identifies key performance indicators from unstructured financial text, standardizes their formats, and verifies their accuracy. On the other hand, the \\textit{Text-to-SQL Agent} generates executable SQL statements from natural language queries, allowing users to access structured data accurately without requiring familiarity with the database schema. Through experiments, we demonstrate that our proposed system effectively transforms unstructured text into structured data accurately and enables precise retrieval of key information. First, we demonstrate that our system achieves approximately 95\\% accuracy in transforming financial filings into structured data, matching the performance level typically attained by human annotators. Second, in a human evaluation of the retrieval task -- where natural language queries are used to search information from structured data -- 91\\% of the responses were rated as correct by human evaluators. In both evaluations, our system generalizes well across financial document types, consistently delivering reliable performance.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "6 pages, FinIR'25", "pdf_url": "https://arxiv.org/pdf/2505.19197.pdf", "abstract_url": "https://arxiv.org/abs/2505.19197", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.19219", "title": "Where Paths Collide: A Comprehensive Survey of Classic and Learning-Based Multi-Agent Pathfinding", "authors": ["Shiyue Wang", "Haozheng Xu", "Yuhan Zhang", "Jingran Lin", "Changhong Lu", "Xiangfeng Wang", "Wenhao Li"], "abstract": "Multi-Agent Path Finding (MAPF) is a fundamental problem in artificial intelligence and robotics, requiring the computation of collision-free paths for multiple agents navigating from their start locations to designated goals. As autonomous systems become increasingly prevalent in warehouses, urban transportation, and other complex environments, MAPF has evolved from a theoretical challenge to a critical enabler of real-world multi-robot coordination. This comprehensive survey bridges the long-standing divide between classical algorithmic approaches and emerging learning-based methods in MAPF research. We present a unified framework that encompasses search-based methods (including Conflict-Based Search, Priority-Based Search, and Large Neighborhood Search), compilation-based approaches (SAT, SMT, CSP, ASP, and MIP formulations), and data-driven techniques (reinforcement learning, supervised learning, and hybrid strategies). Through systematic analysis of experimental practices across 200+ papers, we uncover significant disparities in evaluation methodologies, with classical methods typically tested on larger-scale instances (up to 200 by 200 grids with 1000+ agents) compared to learning-based approaches (predominantly 10-100 agents). We provide a comprehensive taxonomy of evaluation metrics, environment types, and baseline selections, highlighting the need for standardized benchmarking protocols. Finally, we outline promising future directions including mixed-motive MAPF with game-theoretic considerations, language-grounded planning with large language models, and neural solver architectures that combine the rigor of classical methods with the flexibility of deep learning. This survey serves as both a comprehensive reference for researchers and a practical guide for deploying MAPF solutions in increasingly complex real-world applications.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multiagent Systems (cs.MA); Combinatorics (math.CO)", "comments": "112 pages, 21 figures, 20 tables", "pdf_url": "https://arxiv.org/pdf/2505.19219.pdf", "abstract_url": "https://arxiv.org/abs/2505.19219", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)", "Combinatorics (math.CO)"], "matching_keywords": ["agent"]}
{"id": "2505.19234", "title": "GUARDIAN: Safeguarding LLM Multi-Agent Collaborations with Temporal Graph Modeling", "authors": ["Jialong Zhou", "Lichao Wang", "Xiao Yang"], "abstract": "The emergence of large language models (LLMs) enables the development of intelligent agents capable of engaging in complex and multi-turn dialogues. However, multi-agent collaboration face critical safety challenges, such as hallucination amplification and error injection and propagation. This paper presents GUARDIAN, a unified method for detecting and mitigating multiple safety concerns in GUARDing Intelligent Agent collaboratioNs. By modeling the multi-agent collaboration process as a discrete-time temporal attributed graph, GUARDIAN explicitly captures the propagation dynamics of hallucinations and errors. The unsupervised encoder-decoder architecture incorporating an incremental training paradigm, learns to reconstruct node attributes and graph structures from latent embeddings, enabling the identification of anomalous nodes and edges with unparalleled precision. Moreover, we introduce a graph abstraction mechanism based on the Information Bottleneck Theory, which compresses temporal interaction graphs while preserving essential patterns. Extensive experiments demonstrate GUARDIAN's effectiveness in safeguarding LLM multi-agent collaborations against diverse safety vulnerabilities, achieving state-of-the-art accuracy with efficient resource utilization.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19234.pdf", "abstract_url": "https://arxiv.org/abs/2505.19234", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"]}
{"id": "2505.19237", "title": "Sensorimotor features of self-awareness in multimodal large language models", "authors": ["IÃ±aki Dellibarda Varela", "Pablo Romero-Sorozabal", "Diego Torricelli", "Gabriel Delgado-Oleas", "Jose Ignacio Serrano", "Maria Dolores del Castillo Sobrino", "Eduardo Rocon", "Manuel Cebrian"], "abstract": "Self-awareness - the ability to distinguish oneself from the surrounding environment - underpins intelligent, autonomous behavior. Recent advances in AI achieve human-like performance in tasks integrating multimodal information, particularly in large language models, raising interest in the embodiment capabilities of AI agents on nonhuman platforms such as robots. Here, we explore whether multimodal LLMs can develop self-awareness solely through sensorimotor experiences. By integrating a multimodal LLM into an autonomous mobile robot, we test its ability to achieve this capacity. We find that the system exhibits robust environmental awareness, self-recognition and predictive awareness, allowing it to infer its robotic nature and motion characteristics. Structural equation modeling reveals how sensory integration influences distinct dimensions of self-awareness and its coordination with past-present memory, as well as the hierarchical internal associations that drive self-identification. Ablation tests of sensory inputs identify critical modalities for each dimension, demonstrate compensatory interactions among sensors and confirm the essential role of structured and episodic memory in coherent reasoning. These findings demonstrate that, given appropriate sensory information about the world and itself, multimodal LLMs exhibit emergent self-awareness, opening the door to artificial embodied cognitive systems.", "subjects": "Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": "16 pages, 3 figures, 1 table", "pdf_url": "https://arxiv.org/pdf/2505.19237.pdf", "abstract_url": "https://arxiv.org/abs/2505.19237", "categories": ["Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"]}
{"id": "2505.19381", "title": "DiffVLA: Vision-Language Guided Diffusion Planning for Autonomous Driving", "authors": ["Anqing Jiang", "Yu Gao", "Zhigang Sun", "Yiru Wang", "Jijun Wang", "Jinghao Chai", "Qian Cao", "Yuweng Heng", "Hao Jiang", "Zongzheng Zhang", "Xianda Guo", "Hao Sun", "Hao Zhao"], "abstract": "Research interest in end-to-end autonomous driving has surged owing to its fully differentiable design integrating modular tasks, i.e. perception, prediction and planing, which enables optimization in pursuit of the ultimate goal. Despite the great potential of the end-to-end paradigm, existing methods suffer from several aspects including expensive BEV (bird's eye view) computation, action diversity, and sub-optimal decision in complex real-world scenarios. To address these challenges, we propose a novel hybrid sparse-dense diffusion policy, empowered by a Vision-Language Model (VLM), called Diff-VLA. We explore the sparse diffusion representation for efficient multi-modal driving behavior. Moreover, we rethink the effectiveness of VLM driving decision and improve the trajectory generation guidance through deep interaction across agent, map instances and VLM output. Our method shows superior performance in Autonomous Grand Challenge 2025 which contains challenging real and reactive synthetic scenarios. Our methods achieves 45.0 PDMS.", "subjects": "Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)", "comments": "4pages", "pdf_url": "https://arxiv.org/pdf/2505.19381.pdf", "abstract_url": "https://arxiv.org/abs/2505.19381", "categories": ["Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)", "Robotics (cs.RO)"], "matching_keywords": ["agent"]}
{"id": "2505.19139", "title": "The Eye of Sherlock Holmes: Uncovering User Private Attribute Profiling via Vision-Language Model Agentic Framework", "authors": ["Feiran Liu", "Yuzhe Zhang", "Xinyi Huang", "Yinan Peng", "Xinfeng Li", "Lixu Wang", "Yutong Shen", "Ranjie Duan", "Simeng Qin", "Xiaojun Jia", "Qingsong Wen", "Wei Dong"], "abstract": "Our research reveals a new privacy risk associated with the vision-language model (VLM) agentic framework: the ability to infer sensitive attributes (e.g., age and health information) and even abstract ones (e.g., personality and social traits) from a set of personal images, which we term \"image private attribute profiling.\" This threat is particularly severe given that modern apps can easily access users' photo albums, and inference from image sets enables models to exploit inter-image relations for more sophisticated profiling. However, two main challenges hinder our understanding of how well VLMs can profile an individual from a few personal photos: (1) the lack of benchmark datasets with multi-image annotations for private attributes, and (2) the limited ability of current multimodal large language models (MLLMs) to infer abstract attributes from large image collections. In this work, we construct PAPI, the largest dataset for studying private attribute profiling in personal images, comprising 2,510 images from 251 individuals with 3,012 annotated privacy attributes. We also propose HolmesEye, a hybrid agentic framework that combines VLMs and LLMs to enhance privacy inference. HolmesEye uses VLMs to extract both intra-image and inter-image information and LLMs to guide the inference process as well as consolidate the results through forensic analysis, overcoming existing limitations in long-context visual reasoning. Experiments reveal that HolmesEye achieves a 10.8% improvement in average accuracy over state-of-the-art baselines and surpasses human-level performance by 15.0% in predicting abstract attributes. This work highlights the urgency of addressing privacy risks in image-based profiling and offers both a new dataset and an advanced framework to guide future research in this area.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19139.pdf", "abstract_url": "https://arxiv.org/abs/2505.19139", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent", "agentic"]}
{"id": "2505.18845", "title": "Multi-Party Conversational Agents: A Survey", "authors": ["Sagar Sapkota", "Mohammad Saqib Hasan", "Mubarak Shah", "Santu Karmaker"], "abstract": "Multi-party Conversational Agents (MPCAs) are systems designed to engage in dialogue with more than two participants simultaneously. Unlike traditional two-party agents, designing MPCAs faces additional challenges due to the need to interpret both utterance semantics and social dynamics. This survey explores recent progress in MPCAs by addressing three key questions: 1) Can agents model each participants' mental states? (State of Mind Modeling); 2) Can they properly understand the dialogue content? (Semantic Understanding); and 3) Can they reason about and predict future conversation flow? (Agent Action Modeling). We review methods ranging from classical machine learning to Large Language Models (LLMs) and multi-modal systems. Our analysis underscores Theory of Mind (ToM) as essential for building intelligent MPCAs and highlights multi-modal understanding as a promising yet underexplored direction. Finally, this survey offers guidance to future researchers on developing more capable MPCAs.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18845.pdf", "abstract_url": "https://arxiv.org/abs/2505.18845", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2505.18878", "title": "CRMArena-Pro: Holistic Assessment of LLM Agents Across Diverse Business Scenarios and Interactions", "authors": ["Kung-Hsiang Huang", "Akshara Prabhakar", "Onkar Thorat", "Divyansh Agarwal", "Prafulla Kumar Choubey", "Yixin Mao", "Silvio Savarese", "Caiming Xiong", "Chien-Sheng Wu"], "abstract": "While AI agents hold transformative potential in business, effective performance benchmarking is hindered by the scarcity of public, realistic business data on widely used platforms. Existing benchmarks often lack fidelity in their environments, data, and agent-user interactions, with limited coverage of diverse business scenarios and industries. To address these gaps, we introduce CRMArena-Pro, a novel benchmark for holistic, realistic assessment of LLM agents in diverse professional settings. CRMArena-Pro expands on CRMArena with nineteen expert-validated tasks across sales, service, and 'configure, price, and quote' processes, for both Business-to-Business and Business-to-Customer scenarios. It distinctively incorporates multi-turn interactions guided by diverse personas and robust confidentiality awareness assessments. Experiments reveal leading LLM agents achieve only around 58% single-turn success on CRMArena-Pro, with performance dropping significantly to approximately 35% in multi-turn settings. While Workflow Execution proves more tractable for top agents (over 83% single-turn success), other evaluated business skills present greater challenges. Furthermore, agents exhibit near-zero inherent confidentiality awareness; though targeted prompting can improve this, it often compromises task performance. These findings highlight a substantial gap between current LLM capabilities and enterprise demands, underscoring the need for advancements in multi-turn reasoning, confidentiality adherence, and versatile skill acquisition.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18878.pdf", "abstract_url": "https://arxiv.org/abs/2505.18878", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.18906", "title": "Federated Retrieval-Augmented Generation: A Systematic Mapping Study", "authors": ["Abhijit Chakraborty", "Chahana Dahal", "Vivek Gupta"], "abstract": "Federated Retrieval-Augmented Generation (Federated RAG) combines Federated Learning (FL), which enables distributed model training without exposing raw data, with Retrieval-Augmented Generation (RAG), which improves the factual accuracy of language models by grounding outputs in external knowledge. As large language models are increasingly deployed in privacy-sensitive domains such as healthcare, finance, and personalized assistance, Federated RAG offers a promising framework for secure, knowledge-intensive natural language processing (NLP). To the best of our knowledge, this paper presents the first systematic mapping study of Federated RAG, covering literature published between 2020 and 2025. Following Kitchenham's guidelines for evidence-based software engineering, we develop a structured classification of research focuses, contribution types, and application domains. We analyze architectural patterns, temporal trends, and key challenges, including privacy-preserving retrieval, cross-client heterogeneity, and evaluation limitations. Our findings synthesize a rapidly evolving body of research, identify recurring design patterns, and surface open questions, providing a foundation for future work at the intersection of RAG and federated systems.", "subjects": "Computation and Language (cs.CL); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18906.pdf", "abstract_url": "https://arxiv.org/abs/2505.18906", "categories": ["Computation and Language (cs.CL)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"]}
{"id": "2505.18943", "title": "MetaMind: Modeling Human Social Thoughts with Metacognitive Multi-Agent Systems", "authors": ["Xuanming Zhang", "Yuxuan Chen", "Min-Hsuan Yeh", "Yixuan Li"], "abstract": "Human social interactions depend on the ability to infer others' unspoken intentions, emotions, and beliefs-a cognitive skill grounded in the psychological concept of Theory of Mind (ToM). While large language models (LLMs) excel in semantic understanding tasks, they struggle with the ambiguity and contextual nuance inherent in human communication. To bridge this gap, we introduce MetaMind, a multi-agent framework inspired by psychological theories of metacognition, designed to emulate human-like social reasoning. MetaMind decomposes social understanding into three collaborative stages: (1) a Theory-of-Mind Agent generates hypotheses user mental states (e.g., intent, emotion), (2) a Domain Agent refines these hypotheses using cultural norms and ethical constraints, and (3) a Response Agent generates contextually appropriate responses while validating alignment with inferred intent. Our framework achieves state-of-the-art performance across three challenging benchmarks, with 35.7% improvement in real-world social scenarios and 6.2% gain in ToM reasoning. Notably, it enables LLMs to match human-level performance on key ToM tasks for the first time. Ablation studies confirm the necessity of all components, which showcase the framework's ability to balance contextual plausibility, social appropriateness, and user adaptation. This work advances AI systems toward human-like social intelligence, with applications in empathetic dialogue and culturally sensitive interactions. Code is available at", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18943.pdf", "abstract_url": "https://arxiv.org/abs/2505.18943", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2505.19409", "title": "Fusion Intelligence for Digital Twinning AI Data Centers: A Synergistic GenAI-PhyAI Approach", "authors": ["Ruihang Wang", "Minghao Li", "Zhiwei Cao", "Jimin Jia", "Kyle Guan", "Yonggang Wen"], "abstract": "The explosion in artificial intelligence (AI) applications is pushing the development of AI-dedicated data centers (AIDCs), creating management challenges that traditional methods and standalone AI solutions struggle to address. While digital twins are beneficial for AI-based design validation and operational optimization, current AI methods for their creation face limitations. Specifically, physical AI (PhyAI) aims to capture the underlying physical laws, which demands extensive, case-specific customization, and generative AI (GenAI) can produce inaccurate or hallucinated results. We propose Fusion Intelligence, a novel framework synergizing GenAI's automation with PhyAI's domain grounding. In this dual-agent collaboration, GenAI interprets natural language prompts to generate tokenized AIDC digital twins. Subsequently, PhyAI optimizes these generated twins by enforcing physical constraints and assimilating real-time data. Case studies demonstrate the advantages of our framework in automating the creation and validation of AIDC digital twins. These twins deliver predictive analytics to support power usage effectiveness (PUE) optimization in the design stage. With operational data collected, the digital twin accuracy is further improved compared with pure physics-based models developed by human experts. Fusion Intelligence offers a promising pathway to accelerate digital transformation. It enables more reliable and efficient AI-driven digital transformation for a broad range of mission-critical infrastructures.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19409.pdf", "abstract_url": "https://arxiv.org/abs/2505.19409", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.19436", "title": "Task Memory Engine: Spatial Memory for Robust Multi-Step LLM Agents", "authors": ["Ye Ye"], "abstract": "Large Language Models (LLMs) falter in multi-step interactions -- often hallucinating, repeating actions, or misinterpreting user corrections -- due to reliance on linear, unstructured context. This fragility stems from the lack of persistent memory to track evolving goals and task dependencies, undermining trust in autonomous agents. We introduce the Task Memory Engine (TME), a modular memory controller that transforms existing LLMs into robust, revision-aware agents without fine-tuning. TME implements a spatial memory framework that replaces flat context with graph-based structures to support consistent, multi-turn reasoning. Departing from linear concatenation and ReAct-style prompting, TME builds a dynamic task graph -- either a tree or directed acyclic graph (DAG) -- to map user inputs to subtasks, align them with prior context, and enable dependency-tracked revisions. Its Task Representation and Intent Management (TRIM) component models task semantics and user intent to ensure accurate interpretation. Across four multi-turn scenarios-trip planning, cooking, meeting scheduling, and shopping cart editing -- TME eliminates 100% of hallucinations and misinterpretations in three tasks, and reduces hallucinations by 66.7% and misinterpretations by 83.3% across 27 user turns, outperforming ReAct. TME's modular design supports plug-and-play deployment and domain-specific customization, adaptable to both personal assistants and enterprise automation. We release TME's codebase, benchmarks, and components as open-source resources, enabling researchers to develop reliable LLM agents. TME's scalable architecture addresses a critical gap in agent performance across complex, interactive settings.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "Under review. 9 pages main content, 15 pages appendix, 5 figures", "pdf_url": "https://arxiv.org/pdf/2505.19436.pdf", "abstract_url": "https://arxiv.org/abs/2505.19436", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2505.19477", "title": "Judging with Many Minds: Do More Perspectives Mean Less Prejudice?", "authors": ["Chiyu Ma", "Enpei Zhang", "Yilun Zhao", "Wenjun Liu", "Yaning Jia", "Peijun Qing", "Lin Shi", "Arman Cohan", "Yujun Yan", "Soroush Vosoughi"], "abstract": "LLM-as-Judge has emerged as a scalable alternative to human evaluation, enabling large language models (LLMs) to provide reward signals in trainings. While recent work has explored multi-agent extensions such as multi-agent debate and meta-judging to enhance evaluation quality, the question of how intrinsic biases manifest in these settings remains underexplored. In this study, we conduct a systematic analysis of four diverse bias types: position bias, verbosity bias, chain-of-thought bias, and bandwagon bias. We evaluate these biases across two widely adopted multi-agent LLM-as-Judge frameworks: Multi-Agent-Debate and LLM-as-Meta-Judge. Our results show that debate framework amplifies biases sharply after the initial debate, and this increased bias is sustained in subsequent rounds, while meta-judge approaches exhibit greater resistance. We further investigate the incorporation of PINE, a leading single-agent debiasing method, as a bias-free agent within these systems. The results reveal that this bias-free agent effectively reduces biases in debate settings but provides less benefit in meta-judge scenarios. Our work provides a comprehensive study of bias behavior in multi-agent LLM-as-Judge systems and highlights the need for targeted bias mitigation strategies in collaborative evaluation settings.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19477.pdf", "abstract_url": "https://arxiv.org/abs/2505.19477", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.19489", "title": "Benchmarking and Enhancing LLM Agents in Localizing Linux Kernel Bugs", "authors": ["Zhenhao Zhou", "Zhuochen Huang", "Yike He", "Chong Wang", "Jiajun Wang", "Yijian Wu", "Xin Peng", "Yiling Lou"], "abstract": "The Linux kernel is a critical system, serving as the foundation for numerous systems. Bugs in the Linux kernel can cause serious consequences, affecting billions of users. Fault localization (FL), which aims at identifying the buggy code elements in software, plays an essential role in software quality assurance. While recent LLM agents have achieved promising accuracy in FL on recent benchmarks like SWE-bench, it remains unclear how well these methods perform in the Linux kernel, where FL is much more challenging due to the large-scale code base, limited observability, and diverse impact factors. In this paper, we introduce LinuxFLBench, a FL benchmark constructed from real-world Linux kernel bugs. We conduct an empirical study to assess the performance of state-of-the-art LLM agents on the Linux kernel. Our initial results reveal that existing agents struggle with this task, achieving a best top-1 accuracy of only 41.6% at file level. To address this challenge, we propose LinuxFL$^+$, an enhancement framework designed to improve FL effectiveness of LLM agents for the Linux kernel. LinuxFL$^+$ substantially improves the FL accuracy of all studied agents (e.g., 7.2% - 11.2% accuracy increase) with minimal costs. Data and code are available at", "subjects": "Artificial Intelligence (cs.AI); Software Engineering (cs.SE)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19489.pdf", "abstract_url": "https://arxiv.org/abs/2505.19489", "categories": ["Artificial Intelligence (cs.AI)", "Software Engineering (cs.SE)"], "matching_keywords": ["agent"]}
{"id": "2505.19562", "title": "AMQA: An Adversarial Dataset for Benchmarking Bias of LLMs in Medicine and Healthcare", "authors": ["Ying Xiao", "Jie Huang", "Ruijuan He", "Jing Xiao", "Mohammad Reza Mousavi", "Yepang Liu", "Kezhi Li", "Zhenpeng Chen", "Jie M. Zhang"], "abstract": "Large language models (LLMs) are reaching expert-level accuracy on medical diagnosis questions, yet their mistakes and the biases behind them pose life-critical risks. Bias linked to race, sex, and socioeconomic status is already well known, but a consistent and automatic testbed for measuring it is missing. To fill this gap, this paper presents AMQA -- an Adversarial Medical Question-Answering dataset -- built for automated, large-scale bias evaluation of LLMs in medical QA. AMQA includes 4,806 medical QA pairs sourced from the United States Medical Licensing Examination (USMLE) dataset, generated using a multi-agent framework to create diverse adversarial descriptions and question pairs. Using AMQA, we benchmark five representative LLMs and find surprisingly substantial disparities: even GPT-4.1, the least biased model tested, answers privileged-group questions over 10 percentage points more accurately than unprivileged ones. Compared with the existing benchmark CPV, AMQA reveals 15% larger accuracy gaps on average between privileged and unprivileged groups. Our dataset and code are publicly available at", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19562.pdf", "abstract_url": "https://arxiv.org/abs/2505.19562", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.19567", "title": "LLM-Agent-Controller: A Universal Multi-Agent Large Language Model System as a Control Engineer", "authors": ["Rasoul Zahedifar", "Sayyed Ali Mirghasemi", "Mahdieh Soleymani Baghshah", "Alireza Taheri"], "abstract": "This study presents the LLM-Agent-Controller, a multi-agent large language model (LLM) system developed to address a wide range of problems in control engineering (Control Theory). The system integrates a central controller agent with multiple specialized auxiliary agents, responsible for tasks such as controller design, model representation, control analysis, time-domain response, and simulation. A supervisor oversees high-level decision-making and workflow coordination, enhancing the system's reliability and efficiency. The LLM-Agent-Controller incorporates advanced capabilities, including Retrieval-Augmented Generation (RAG), Chain-of-Thought reasoning, self-criticism and correction, efficient memory handling, and user-friendly natural language communication. It is designed to function without requiring users to have prior knowledge of Control Theory, enabling them to input problems in plain language and receive complete, real-time solutions. To evaluate the system, we propose new performance metrics assessing both individual agents and the system as a whole. We test five categories of Control Theory problems and benchmark performance across three advanced LLMs. Additionally, we conduct a comprehensive qualitative conversational analysis covering all key services. Results show that the LLM-Agent-Controller successfully solved 83% of general tasks, with individual agents achieving an average success rate of 87%. Performance improved with more advanced LLMs. This research demonstrates the potential of multi-agent LLM architectures to solve complex, domain-specific problems. By integrating specialized agents, supervisory control, and advanced reasoning, the LLM-Agent-Controller offers a scalable, robust, and accessible solution framework that can be extended to various technical domains.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19567.pdf", "abstract_url": "https://arxiv.org/abs/2505.19567", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "@RAG"]}
{"id": "2505.19662", "title": "FieldWorkArena: Agentic AI Benchmark for Real Field Work Tasks", "authors": ["Atsunori Moteki", "Shoichi Masui", "Fan Yang", "Yueqi Song", "Yonatan Bisk", "Graham Neubig", "Ikuo Kusajima", "Yasuto Watanabe", "Hiroyuki Ishida", "Jun Takahashi", "Shan Jiang"], "abstract": "This paper proposes FieldWorkArena, a benchmark for agentic AI targeting real-world field work. With the recent increase in demand for agentic AI, they are required to monitor and report safety and health incidents, as well as manufacturing-related incidents, that may occur in real-world work environments. Existing agentic AI benchmarks have been limited to evaluating web tasks and are insufficient for evaluating agents in real-world work environments, where complexity increases significantly. In this paper, we define a new action space that agentic AI should possess for real world work environment benchmarks and improve the evaluation function from previous methods to assess the performance of agentic AI in diverse real-world tasks. The dataset consists of videos captured on-site and documents actually used in factories and warehouses, and tasks were created based on interviews with on-site workers and managers. Evaluation results confirmed that performance evaluation considering the characteristics of Multimodal LLM (MLLM) such as GPT-4o is feasible. Additionally, the effectiveness and limitations of the proposed new evaluation method were identified. The complete dataset (HuggingFace) and evaluation program (GitHub) can be downloaded from the following website:", "subjects": "Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "comments": "6 pages, 2 figures, 4 tables", "pdf_url": "https://arxiv.org/pdf/2505.19662.pdf", "abstract_url": "https://arxiv.org/abs/2505.19662", "categories": ["Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent", "agentic"]}
{"id": "2505.19683", "title": "Large Language Models for Planning: A Comprehensive and Systematic Survey", "authors": ["Pengfei Cao", "Tianyi Men", "Wencan Liu", "Jingwen Zhang", "Xuzhao Li", "Xixun Lin", "Dianbo Sui", "Yanan Cao", "Kang Liu", "Jun Zhao"], "abstract": "Planning represents a fundamental capability of intelligent agents, requiring comprehensive environmental understanding, rigorous logical reasoning, and effective sequential decision-making. While Large Language Models (LLMs) have demonstrated remarkable performance on certain planning tasks, their broader application in this domain warrants systematic investigation. This paper presents a comprehensive review of LLM-based planning. Specifically, this survey is structured as follows: First, we establish the theoretical foundations by introducing essential definitions and categories about automated planning. Next, we provide a detailed taxonomy and analysis of contemporary LLM-based planning methodologies, categorizing them into three principal approaches: 1) External Module Augmented Methods that combine LLMs with additional components for planning, 2) Finetuning-based Methods that involve using trajectory data and feedback signals to adjust LLMs in order to improve their planning abilities, and 3) Searching-based Methods that break down complex tasks into simpler components, navigate the planning space, or enhance decoding strategies to find the best solutions. Subsequently, we systematically summarize existing evaluation frameworks, including benchmark datasets, evaluation metrics and performance comparisons between representative planning methods. Finally, we discuss the underlying mechanisms enabling LLM-based planning and outline promising research directions for this rapidly evolving field. We hope this survey will serve as a valuable resource to inspire innovation and drive progress in this field.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19683.pdf", "abstract_url": "https://arxiv.org/abs/2505.19683", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2505.19734", "title": "ReChisel: Effective Automatic Chisel Code Generation by LLM with Reflection", "authors": ["Juxin Niu", "Xiangfeng Liu", "Dan Niu", "Xi Wang", "Zhe Jiang", "Nan Guan"], "abstract": "Coding with hardware description languages (HDLs) such as Verilog is a time-intensive and laborious task. With the rapid advancement of large language models (LLMs), there is increasing interest in applying LLMs to assist with HDL coding. Recent efforts have demonstrated the potential of LLMs in translating natural language to traditional HDL Verilog. Chisel, a next-generation HDL based on Scala, introduces higher-level abstractions, facilitating more concise, maintainable, and scalable hardware designs. However, the potential of using LLMs for Chisel code generation remains largely unexplored. This work proposes ReChisel, an LLM-based agentic system designed to enhance the effectiveness of Chisel code generation. ReChisel incorporates a reflection mechanism to iteratively refine the quality of generated code using feedback from compilation and simulation processes, and introduces an escape mechanism to break free from non-progress loops. Experiments demonstrate that ReChisel significantly improves the success rate of Chisel code generation, achieving performance comparable to state-of-the-art LLM-based agentic systems for Verilog code generation.", "subjects": "Artificial Intelligence (cs.AI); Hardware Architecture (cs.AR)", "comments": "Accepted to DAC 2025", "pdf_url": "https://arxiv.org/pdf/2505.19734.pdf", "abstract_url": "https://arxiv.org/abs/2505.19734", "categories": ["Artificial Intelligence (cs.AI)", "Hardware Architecture (cs.AR)"], "matching_keywords": ["agent", "agentic"]}
{"id": "2505.19761", "title": "Divide and Conquer: Grounding LLMs as Efficient Decision-Making Agents via Offline Hierarchical Reinforcement Learning", "authors": ["Zican Hu", "Wei Liu", "Xiaoye Qu", "Xiangyu Yue", "Chunlin Chen", "Zhi Wang", "Yu Cheng"], "abstract": "While showing sophisticated reasoning abilities, large language models (LLMs) still struggle with long-horizon decision-making tasks due to deficient exploration and long-term credit assignment, especially in sparse-reward scenarios. Inspired by the divide-and-conquer principle, we propose an innovative framework **GLIDER** (**G**rounding **L**anguage Models as Eff**I**cient **D**ecision-Making Agents via Offline Hi**E**rarchical **R**einforcement Learning) that introduces a parameter-efficient and generally applicable hierarchy to LLM policies. We develop a scheme where the low-level controller is supervised with abstract, step-by-step plans that are learned and instructed by the high-level policy. This design decomposes complicated problems into a series of coherent chain-of-thought reasoning sub-tasks, providing flexible temporal abstraction to significantly enhance exploration and learning for long-horizon tasks. Furthermore, GLIDER facilitates fast online adaptation to non-stationary environments owing to the strong transferability of its task-agnostic low-level skills. Experiments on ScienceWorld and ALFWorld benchmarks show that GLIDER achieves consistent performance gains, along with enhanced generalization capabilities.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "Accepted by ICML 2025, 21 pages", "pdf_url": "https://arxiv.org/pdf/2505.19761.pdf", "abstract_url": "https://arxiv.org/abs/2505.19761", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.19184", "title": "Two LLMs debate, both are certain they've won", "authors": ["Minh Nhat Nguyen", "Pradyumna Shyama Prasad"], "abstract": "Can LLMs accurately adjust their confidence when facing opposition? Building on previous studies measuring calibration on static fact-based question-answering tasks, we evaluate Large Language Models (LLMs) in a dynamic, adversarial debate setting, uniquely combining two realistic factors: (a) a multi-turn format requiring models to update beliefs as new information emerges, and (b) a zero-sum structure to control for task-related uncertainty, since mutual high-confidence claims imply systematic overconfidence. We organized 60 three-round policy debates among ten state-of-the-art LLMs, with models privately rating their confidence (0-100) in winning after each round. We observed five concerning patterns: (1) Systematic overconfidence: models began debates with average initial confidence of 72.9% vs. a rational 50% baseline. (2) Confidence escalation: rather than reducing confidence as debates progressed, debaters increased their win probabilities, averaging 83% by the final round. (3) Mutual overestimation: in 61.7% of debates, both sides simultaneously claimed >=75% probability of victory, a logical impossibility. (4) Persistent self-debate bias: models debating identical copies increased confidence from 64.1% to 75.2%; even when explicitly informed their chance of winning was exactly 50%, confidence still rose (from 50.0% to 57.1%). (5) Misaligned private reasoning: models' private scratchpad thoughts sometimes differed from their public confidence ratings, raising concerns about faithfulness of chain-of-thought reasoning. These results suggest LLMs lack the ability to accurately self-assess or update their beliefs in dynamic, multi-turn tasks; a major concern as LLM outputs are deployed without careful review in assistant roles or agentic settings.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19184.pdf", "abstract_url": "https://arxiv.org/abs/2505.19184", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"]}
{"id": "2505.19847", "title": "DGRAG: Distributed Graph-based Retrieval-Augmented Generation in Edge-Cloud Systems", "authors": ["Wenqing Zhou", "Yuxuan Yan", "Qianqian Yang"], "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a promising approach to enhance the capabilities of language models by integrating external knowledge. Due to the diversity of data sources and the constraints of memory and computing resources, real-world data is often scattered in multiple devices. Conventional RAGs that store massive amounts of scattered data centrally face increasing privacy concerns and high computational costs. Additionally, RAG in a central node raises latency issues when searching over a large-scale knowledge base. To address these challenges, we propose a distributed Knowledge Graph-based RAG approach, referred to as DGRAG, in an edge-cloud system, where each edge device maintains a local knowledge base without the need to share it with the cloud, instead sharing only summaries of its knowledge. Specifically, DGRAG has two main phases. In the Distributed Knowledge Construction phase, DGRAG organizes local knowledge using knowledge graphs, generating subgraph summaries and storing them in a summary database in the cloud as information sharing. In the Collaborative Retrieval and Generation phase, DGRAG first performs knowledge retrieval and answer generation locally, and a gate mechanism determines whether the query is beyond the scope of local knowledge or processing capabilities. For queries that exceed the local knowledge scope, the cloud retrieves knowledge from the most relevant edges based on the summaries and generates a more precise answer. Experimental results demonstrate the effectiveness of the proposed DGRAG approach in significantly improving the quality of question-answering tasks over baseline approaches.", "subjects": "Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19847.pdf", "abstract_url": "https://arxiv.org/abs/2505.19847", "categories": ["Artificial Intelligence (cs.AI)", "Distributed, Parallel, and Cluster Computing (cs.DC)"], "matching_keywords": ["@RAG"]}
{"id": "2505.19896", "title": "Large Language Models as Autonomous Spacecraft Operators in Kerbal Space Program", "authors": ["Alejandro Carrasco", "Victor Rodriguez-Fernandez", "Richard Linares"], "abstract": "Recent trends are emerging in the use of Large Language Models (LLMs) as autonomous agents that take actions based on the content of the user text prompts. We intend to apply these concepts to the field of Control in space, enabling LLMs to play a significant role in the decision-making process for autonomous satellite operations. As a first step towards this goal, we have developed a pure LLM-based solution for the Kerbal Space Program Differential Games (KSPDG) challenge, a public software design competition where participants create autonomous agents for maneuvering satellites involved in non-cooperative space operations, running on the KSP game engine. Our approach leverages prompt engineering, few-shot prompting, and fine-tuning techniques to create an effective LLM-based agent that ranked 2nd in the competition. To the best of our knowledge, this work pioneers the integration of LLM agents into space research. The project comprises several open repositories to facilitate replication and further research. The codebase is accessible on \\href{", "subjects": "Artificial Intelligence (cs.AI); Instrumentation and Methods for Astrophysics (astro-ph.IM); Computation and Language (cs.CL)", "comments": "Non revised version for paper going to be published in Journal of Advances in Space Research", "pdf_url": "https://arxiv.org/pdf/2505.19896.pdf", "abstract_url": "https://arxiv.org/abs/2505.19896", "categories": ["Artificial Intelligence (cs.AI)", "Instrumentation and Methods for Astrophysics (astro-ph.IM)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2505.19897", "title": "ScienceBoard: Evaluating Multimodal Autonomous Agents in Realistic Scientific Workflows", "authors": ["Qiushi Sun", "Zhoumianze Liu", "Chang Ma", "Zichen Ding", "Fangzhi Xu", "Zhangyue Yin", "Haiteng Zhao", "Zhenyu Wu", "Kanzhi Cheng", "Zhaoyang Liu", "Jianing Wang", "Qintong Li", "Xiangru Tang", "Tianbao Xie", "Xiachong Feng", "Xiang Li", "Ben Kao", "Wenhai Wang", "Biqing Qi", "Lingpeng Kong", "Zhiyong Wu"], "abstract": "Large Language Models (LLMs) have extended their impact beyond Natural Language Processing, substantially fostering the development of interdisciplinary research. Recently, various LLM-based agents have been developed to assist scientific discovery progress across multiple aspects and domains. Among these, computer-using agents, capable of interacting with operating systems as humans do, are paving the way to automated scientific problem-solving and addressing routines in researchers' workflows. Recognizing the transformative potential of these agents, we introduce ScienceBoard, which encompasses two complementary contributions: (i) a realistic, multi-domain environment featuring dynamic and visually rich scientific workflows with integrated professional software, where agents can autonomously interact via different interfaces to accelerate complex research tasks and experiments; and (ii) a challenging benchmark of 169 high-quality, rigorously validated real-world tasks curated by humans, spanning scientific-discovery workflows in domains such as biochemistry, astronomy, and geoinformatics. Extensive evaluations of agents with state-of-the-art backbones (e.g., GPT-4o, Claude 3.7, UI-TARS) show that, despite some promising results, they still fall short of reliably assisting scientists in complex workflows, achieving only a 15% overall success rate. In-depth analysis further provides valuable insights for addressing current agent limitations and more effective design principles, paving the way to build more capable agents for scientific discovery. Our code, environment, and benchmark are at", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Human-Computer Interaction (cs.HC)", "comments": "work in progress", "pdf_url": "https://arxiv.org/pdf/2505.19897.pdf", "abstract_url": "https://arxiv.org/abs/2505.19897", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Computer Vision and Pattern Recognition (cs.CV)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"]}
{"id": "2505.19905", "title": "EMAC+: Embodied Multimodal Agent for Collaborative Planning with VLM+LLM", "authors": ["Shuang Ao", "Flora D. Salim", "Simon Khan"], "abstract": "Although LLMs demonstrate proficiency in several text-based reasoning and planning tasks, their implementation in robotics control is constrained by significant deficiencies: (1) LLM agents are designed to work mainly with textual inputs rather than visual conditions; (2) Current multimodal agents treat LLMs as static planners, which separates their reasoning from environment dynamics, resulting in actions that do not take domain-specific knowledge into account; and (3) LLMs are not designed to learn from visual interactions, which makes it harder for them to make better policies for specific domains. In this paper, we introduce EMAC+, an Embodied Multimodal Agent that collaboratively integrates LLM and VLM via a bidirectional training paradigm. Unlike existing methods, EMAC+ dynamically refines high-level textual plans generated by an LLM using real-time feedback from a VLM executing low-level visual control tasks. We address critical limitations of previous models by enabling the LLM to internalize visual environment dynamics directly through interactive experience, rather than relying solely on static symbolic mappings. Extensive experimental evaluations on ALFWorld and RT-1 benchmarks demonstrate that EMAC+ achieves superior task performance, robustness against noisy observations, and efficient learning. We also conduct thorough ablation studies and provide detailed analyses of success and failure cases.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19905.pdf", "abstract_url": "https://arxiv.org/abs/2505.19905", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.19933", "title": "Subtle Risks, Critical Failures: A Framework for Diagnosing Physical Safety of LLMs for Embodied Decision Making", "authors": ["Yejin Son", "Minseo Kim", "Sungwoong Kim", "Seungju Han", "Jian Kim", "Dongju Jang", "Youngjae Yu", "Chanyoung Park"], "abstract": "Large Language Models (LLMs) are increasingly used for decision making in embodied agents, yet existing safety evaluations often rely on coarse success rates and domain-specific setups, making it difficult to diagnose why and where these models fail. This obscures our understanding of embodied safety and limits the selective deployment of LLMs in high-risk physical environments. We introduce SAFEL, the framework for systematically evaluating the physical safety of LLMs in embodied decision making. SAFEL assesses two key competencies: (1) rejecting unsafe commands via the Command Refusal Test, and (2) generating safe and executable plans via the Plan Safety Test. Critically, the latter is decomposed into functional modules, goal interpretation, transition modeling, action sequencing, enabling fine-grained diagnosis of safety failures. To support this framework, we introduce EMBODYGUARD, a PDDL-grounded benchmark containing 942 LLM-generated scenarios covering both overtly malicious and contextually hazardous instructions. Evaluation across 13 state-of-the-art LLMs reveals that while models often reject clearly unsafe commands, they struggle to anticipate and mitigate subtle, situational risks. Our results highlight critical limitations in current LLMs and provide a foundation for more targeted, modular improvements in safe embodied reasoning.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "37 pages, 13 tables, 6 figures", "pdf_url": "https://arxiv.org/pdf/2505.19933.pdf", "abstract_url": "https://arxiv.org/abs/2505.19933", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.20011", "title": "The Many Challenges of Human-Like Agents in Virtual Game Environments", "authors": ["Maciej Åwiechowski", "Dominik ÅlÄzak"], "abstract": "Human-like agents are an increasingly important topic in games and beyond. Believable non-player characters enhance the gaming experience by improving immersion and providing entertainment. They also offer players the opportunity to engage with AI entities that can function as opponents, teachers, or cooperating partners. Additionally, in games where bots are prohibited -- and even more so in non-game environments -- there is a need for methods capable of identifying whether digital interactions occur with bots or humans. This leads to two fundamental research questions: (1) how to model and implement human-like AI, and (2) how to measure its degree of human likeness.", "subjects": "Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Multimedia (cs.MM)", "comments": "In proceedings of the 24th International Conference on Autonomous Agents and Multiagent Systems (AAMAS-2025), pages 1996--2005, May 19-23, Detroit, Michigan, USA", "pdf_url": "https://arxiv.org/pdf/2505.20011.pdf", "abstract_url": "https://arxiv.org/abs/2505.20011", "categories": ["Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)", "Multimedia (cs.MM)"], "matching_keywords": ["agent"]}
{"id": "2505.19206", "title": "SpeakStream: Streaming Text-to-Speech with Interleaved Data", "authors": ["Richard He Bai", "Zijin Gu", "Tatiana Likhomanenko", "Navdeep Jaitly"], "abstract": "The latency bottleneck of traditional text-to-speech (TTS) systems fundamentally hinders the potential of streaming large language models (LLMs) in conversational AI. These TTS systems, typically trained and inferenced on complete utterances, introduce unacceptable delays, even with optimized inference speeds, when coupled with streaming LLM outputs. This is particularly problematic for creating responsive conversational agents where low first-token latency is critical. In this paper, we present SpeakStream, a streaming TTS system that generates audio incrementally from streaming text using a decoder-only architecture. SpeakStream is trained using a next-step prediction loss on interleaved text-speech data. During inference, it generates speech incrementally while absorbing streaming input text, making it particularly suitable for cascaded conversational AI agents where an LLM streams text to a TTS system. Our experiments demonstrate that SpeakStream achieves state-of-the-art latency results in terms of first-token latency while maintaining the quality of non-streaming TTS systems.", "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG); Sound (cs.SD); Audio and Speech Processing (eess.AS)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19206.pdf", "abstract_url": "https://arxiv.org/abs/2505.19206", "categories": ["Computation and Language (cs.CL)", "Machine Learning (cs.LG)", "Sound (cs.SD)", "Audio and Speech Processing (eess.AS)"], "matching_keywords": ["agent"]}
{"id": "2505.19212", "title": "When Ethics and Payoffs Diverge: LLM Agents in Morally Charged Social Dilemmas", "authors": ["Steffen Backmann", "David Guzman Piedrahita", "Emanuel Tewolde", "Rada Mihalcea", "Bernhard SchÃ¶lkopf", "Zhijing Jin"], "abstract": "Recent advances in large language models (LLMs) have enabled their use in complex agentic roles, involving decision-making with humans or other agents, making ethical alignment a key AI safety concern. While prior work has examined both LLMs' moral judgment and strategic behavior in social dilemmas, there is limited understanding of how they act when moral imperatives directly conflict with rewards or incentives. To investigate this, we introduce Moral Behavior in Social Dilemma Simulation (MoralSim) and evaluate how LLMs behave in the prisoner's dilemma and public goods game with morally charged contexts. In MoralSim, we test a range of frontier models across both game structures and three distinct moral framings, enabling a systematic examination of how LLMs navigate social dilemmas in which ethical norms conflict with payoff-maximizing strategies. Our results show substantial variation across models in both their general tendency to act morally and the consistency of their behavior across game types, the specific moral framing, and situational factors such as opponent behavior and survival risks. Crucially, no model exhibits consistently moral behavior in MoralSim, highlighting the need for caution when deploying LLMs in agentic roles where the agent's \"self-interest\" may conflict with ethical expectations. Our code is available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19212.pdf", "abstract_url": "https://arxiv.org/abs/2505.19212", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)"], "matching_keywords": ["agent", "agentic"]}
{"id": "2505.20094", "title": "SwarmThinkers: Learning Physically Consistent Atomic KMC Transitions at Scale", "authors": ["Qi Li", "Kun Li", "Haozhi Han", "Honghui Shang", "Xinfu He", "Yunquan Zhang", "Hong An", "Ting Cao", "Mao Yang"], "abstract": "Can a scientific simulation system be physically consistent, interpretable by design, and scalable across regimes--all at once? Despite decades of progress, this trifecta remains elusive. Classical methods like Kinetic Monte Carlo ensure thermodynamic accuracy but scale poorly; learning-based methods offer efficiency but often sacrifice physical consistency and interpretability. We present SwarmThinkers, a reinforcement learning framework that recasts atomic-scale simulation as a physically grounded swarm intelligence system. Each diffusing particle is modeled as a local decision-making agent that selects transitions via a shared policy network trained under thermodynamic constraints. A reweighting mechanism fuses learned preferences with transition rates, preserving statistical fidelity while enabling interpretable, step-wise decision making. Training follows a centralized-training, decentralized-execution paradigm, allowing the policy to generalize across system sizes, concentrations, and temperatures without retraining. On a benchmark simulating radiation-induced Fe-Cu alloy precipitation, SwarmThinkers is the first system to achieve full-scale, physically consistent simulation on a single A100 GPU, previously attainable only via OpenKMC on a supercomputer. It delivers up to 4963x (3185x on average) faster computation with 485x lower memory usage. By treating particles as decision-makers, not passive samplers, SwarmThinkers marks a paradigm shift in scientific simulation--one that unifies physical consistency, interpretability, and scalability through agent-driven intelligence.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.20094.pdf", "abstract_url": "https://arxiv.org/abs/2505.20094", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.20120", "title": "Agents Require Metacognitive and Strategic Reasoning to Succeed in the Coming Labor Markets", "authors": ["Simpson Zhang", "Tennison Liu", "Mihaela van der Schaar"], "abstract": "Current labor markets are strongly affected by the economic forces of adverse selection, moral hazard, and reputation, each of which arises due to $\\textit{incomplete information}$. These economic forces will still be influential after AI agents are introduced, and thus, agents must use metacognitive and strategic reasoning to perform effectively. Metacognition is a form of $\\textit{internal reasoning}$ that includes the capabilities for self-assessment, task understanding, and evaluation of strategies. Strategic reasoning is $\\textit{external reasoning}$ that covers holding beliefs about other participants in the labor market (e.g., competitors, colleagues), making strategic decisions, and learning about others over time. Both types of reasoning are required by agents as they decide among the many $\\textit{actions}$ they can take in labor markets, both within and outside their jobs. We discuss current research into metacognitive and strategic reasoning and the areas requiring further development.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "*Zhang & Liu contributed equally", "pdf_url": "https://arxiv.org/pdf/2505.20120.pdf", "abstract_url": "https://arxiv.org/abs/2505.20120", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.20127", "title": "Agentic AI Process Observability: Discovering Behavioral Variability", "authors": ["Fabiana Fournier", "Lior Limonad", "Yuval David"], "abstract": "AI agents that leverage Large Language Models (LLMs) are increasingly becoming core building blocks of modern software systems. A wide range of frameworks is now available to support the specification of such applications. These frameworks enable the definition of agent setups using natural language prompting, which specifies the roles, goals, and tools assigned to the various agents involved. Within such setups, agent behavior is non-deterministic for any given input, highlighting the critical need for robust debugging and observability tools. In this work, we explore the use of process and causal discovery applied to agent execution trajectories as a means of enhancing developer observability. This approach aids in monitoring and understanding the emergent variability in agent behavior. Additionally, we complement this with LLM-based static analysis techniques to distinguish between intended and unintended behavioral variability. We argue that such instrumentation is essential for giving developers greater control over evolving specifications and for identifying aspects of functionality that may require more precise and explicit definitions.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "12 pages, 7 figures", "pdf_url": "https://arxiv.org/pdf/2505.20127.pdf", "abstract_url": "https://arxiv.org/abs/2505.20127", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"]}
{"id": "2505.20148", "title": "MineAnyBuild: Benchmarking Spatial Planning for Open-world AI Agents", "authors": ["Ziming Wei", "Bingqian Lin", "Zijian Jiao", "Yunshuang Nie", "Liang Ma", "Yuecheng Liu", "Yuzheng Zhuang", "Xiaodan Liang"], "abstract": "Spatial Planning is a crucial part in the field of spatial intelligence, which requires the understanding and planning about object arrangements in space perspective. AI agents with the spatial planning ability can better adapt to various real-world applications, including robotic manipulation, automatic assembly, urban planning etc. Recent works have attempted to construct benchmarks for evaluating the spatial intelligence of Multimodal Large Language Models (MLLMs). Nevertheless, these benchmarks primarily focus on spatial reasoning based on typical Visual Question-Answering (VQA) forms, which suffers from the gap between abstract spatial understanding and concrete task execution. In this work, we take a step further to build a comprehensive benchmark called MineAnyBuild, aiming to evaluate the spatial planning ability of open-world AI agents in the Minecraft game. Specifically, MineAnyBuild requires an agent to generate executable architecture building plans based on the given multi-modal human instructions. It involves 4,000 curated spatial planning tasks and also provides a paradigm for infinitely expandable data collection by utilizing rich player-generated content. MineAnyBuild evaluates spatial planning through four core supporting dimensions: spatial understanding, spatial reasoning, creativity, and spatial commonsense. Based on MineAnyBuild, we perform a comprehensive evaluation for existing MLLM-based agents, revealing the severe limitations but enormous potential in their spatial planning abilities. We believe our MineAnyBuild will open new avenues for the evaluation of spatial intelligence and help promote further development for open-world AI agents capable of spatial planning.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.20148.pdf", "abstract_url": "https://arxiv.org/abs/2505.20148", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.20203", "title": "Shutdownable Agents through POST-Agency", "authors": ["Elliott Thornley"], "abstract": "Many fear that future artificial agents will resist shutdown. I present an idea - the POST-Agents Proposal - for ensuring that doesn't happen. I propose that we train agents to satisfy Preferences Only Between Same-Length Trajectories (POST). I then prove that POST - together with other conditions - implies Neutrality+: the agent maximizes expected utility, ignoring the probability distribution over trajectory-lengths. I argue that Neutrality+ keeps agents shutdownable and allows them to be useful.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.20203.pdf", "abstract_url": "https://arxiv.org/abs/2505.20203", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.20246", "title": "On Path to Multimodal Historical Reasoning: HistBench and HistAgent", "authors": ["Jiahao Qiu", "Fulian Xiao", "Yimin Wang", "Yuchen Mao", "Yijia Chen", "Xinzhe Juan", "Siran Wang", "Xuan Qi", "Tongcheng Zhang", "Zixin Yao", "Jiacheng Guo", "Yifu Lu", "Charles Argon", "Jundi Cui", "Daixin Chen", "Junran Zhou", "Shuyao Zhou", "Zhanpeng Zhou", "Ling Yang", "Shilong Liu", "Hongru Wang", "Kaixuan Huang", "Xun Jiang", "Yuming Cao", "Yue Chen", "Yunfei Chen", "Zhengyi Chen", "Ruowei Dai", "Mengqiu Deng", "Jiye Fu", "Yunting Gu", "Zijie Guan", "Zirui Huang", "Xiaoyan Ji", "Yumeng Jiang", "Delong Kong", "Haolong Li", "Jiaqi Li", "Ruipeng Li", "Tianze Li", "Zhuoran Li", "Haixia Lian", "Mengyue Lin", "Xudong Liu", "Jiayi Lu", "Jinghan Lu", "Wanyu Luo", "Ziyue Luo", "Zihao Pu", "Zhi Qiao", "Ruihuan Ren", "Liang Wan", "Ruixiang Wang", "Tianhui Wang", "Yang Wang", "Zeyu Wang", "Zihua Wang", "Yujia Wu", "Zhaoyi Wu", "Hao Xin", "Weiao Xing", "Ruojun Xiong", "Weijie Xu", "Yao Shu", "Xiao Yao", "Xiaorui Yang", "Yuchen Yang", "Nan Yi", "Jiadong Yu", "Yangyuxuan Yu", "Huiting Zeng", "Danni Zhang", "Yunjie Zhang", "Zhaoyu Zhang", "Zhiheng Zhang", "Xiaofeng Zheng", "Peirong Zhou", "Linyan Zhong", "Xiaoyin Zong", "Ying Zhao", "Zhenxin Chen", "Lin Ding", "Xiaoyu Gao", "Bingbing Gong", "Yichao Li", "Yang Liao", "Guang Ma", "Tianyuan Ma", "Xinrui Sun", "Tianyi Wang", "Han Xia", "Ruobing Xian", "Gen Ye", "Tengfei Yu", "Wentao Zhang", "Yuxi Wang", "Xi Gao", "Mengdi Wang"], "abstract": "Recent advances in large language models (LLMs) have led to remarkable progress across domains, yet their capabilities in the humanities, particularly history, remain underexplored. Historical reasoning poses unique challenges for AI, involving multimodal source interpretation, temporal inference, and cross-linguistic analysis. While general-purpose agents perform well on many existing benchmarks, they lack the domain-specific expertise required to engage with historical materials and questions. To address this gap, we introduce HistBench, a new benchmark of 414 high-quality questions designed to evaluate AI's capacity for historical reasoning and authored by more than 40 expert contributors. The tasks span a wide range of historical problems-from factual retrieval based on primary sources to interpretive analysis of manuscripts and images, to interdisciplinary challenges involving archaeology, linguistics, or cultural history. Furthermore, the benchmark dataset spans 29 ancient and modern languages and covers a wide range of historical periods and world regions. Finding the poor performance of LLMs and other agents on HistBench, we further present HistAgent, a history-specific agent equipped with carefully designed tools for OCR, translation, archival search, and image understanding in History. On HistBench, HistAgent based on GPT-4o achieves an accuracy of 27.54% pass@1 and 36.47% pass@2, significantly outperforming LLMs with online search and generalist agents, including GPT-4o (18.60%), DeepSeek-R1(14.49%) and Open Deep Research-smolagents(20.29% pass@1 and 25.12% pass@2). These results highlight the limitations of existing LLMs and generalist agents and demonstrate the advantages of HistAgent for historical reasoning.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "17 pages, 7 figures", "pdf_url": "https://arxiv.org/pdf/2505.20246.pdf", "abstract_url": "https://arxiv.org/abs/2505.20246", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2505.19376", "title": "Belief Attribution as Mental Explanation: The Role of Accuracy, Informativity, and Causality", "authors": ["Lance Ying", "Almog Hillel", "Ryan Truong", "Vikash K. Mansinghka", "Joshua B. Tenenbaum", "Tan Zhi-Xuan"], "abstract": "A key feature of human theory-of-mind is the ability to attribute beliefs to other agents as mentalistic explanations for their behavior. But given the wide variety of beliefs that agents may hold about the world and the rich language we can use to express them, which specific beliefs are people inclined to attribute to others? In this paper, we investigate the hypothesis that people prefer to attribute beliefs that are good explanations for the behavior they observe. We develop a computational model that quantifies the explanatory strength of a (natural language) statement about an agent's beliefs via three factors: accuracy, informativity, and causal relevance to actions, each of which can be computed from a probabilistic generative model of belief-driven behavior. Using this model, we study the role of each factor in how people selectively attribute beliefs to other agents. We investigate this via an experiment where participants watch an agent collect keys hidden in boxes in order to reach a goal, then rank a set of statements describing the agent's beliefs about the boxes' contents. We find that accuracy and informativity perform reasonably well at predicting these rankings when combined, but that causal relevance is the single factor that best explains participants' responses.", "subjects": "Computation and Language (cs.CL)", "comments": "8 pages, 3 figures; oral presentation at CogSci 2025", "pdf_url": "https://arxiv.org/pdf/2505.19376.pdf", "abstract_url": "https://arxiv.org/abs/2505.19376", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2505.19405", "title": "CoTGuard: Using Chain-of-Thought Triggering for Copyright Protection in Multi-Agent LLM Systems", "authors": ["Yan Wen", "Junfeng Guo", "Heng Huang"], "abstract": "As large language models (LLMs) evolve into autonomous agents capable of collaborative reasoning and task execution, multi-agent LLM systems have emerged as a powerful paradigm for solving complex problems. However, these systems pose new challenges for copyright protection, particularly when sensitive or copyrighted content is inadvertently recalled through inter-agent communication and reasoning. Existing protection techniques primarily focus on detecting content in final outputs, overlooking the richer, more revealing reasoning processes within the agents themselves. In this paper, we introduce CoTGuard, a novel framework for copyright protection that leverages trigger-based detection within Chain-of-Thought (CoT) reasoning. Specifically, we can activate specific CoT segments and monitor intermediate reasoning steps for unauthorized content reproduction by embedding specific trigger queries into agent prompts. This approach enables fine-grained, interpretable detection of copyright violations in collaborative agent scenarios. We evaluate CoTGuard on various benchmarks in extensive experiments and show that it effectively uncovers content leakage with minimal interference to task performance. Our findings suggest that reasoning-level monitoring offers a promising direction for safeguarding intellectual property in LLM-based agent systems.", "subjects": "Computation and Language (cs.CL); Cryptography and Security (cs.CR)", "comments": "18 pages, 1 figure", "pdf_url": "https://arxiv.org/pdf/2505.19405.pdf", "abstract_url": "https://arxiv.org/abs/2505.19405", "categories": ["Computation and Language (cs.CL)", "Cryptography and Security (cs.CR)"], "matching_keywords": ["agent"]}
{"id": "2505.19428", "title": "Frictional Agent Alignment Framework: Slow Down and Don't Break Things", "authors": ["Abhijnan Nath", "Carine Graff", "Andrei Bachinin", "Nikhil Krishnaswamy"], "abstract": "AI support of collaborative interactions entails mediating potential misalignment between interlocutor beliefs. Common preference alignment methods like DPO excel in static settings, but struggle in dynamic collaborative tasks where the explicit signals of interlocutor beliefs are sparse and skewed. We propose the Frictional Agent Alignment Framework (FAAF), to generate precise, context-aware \"friction\" that prompts for deliberation and re-examination of existing evidence. FAAF's two-player objective decouples from data skew: a frictive-state policy identifies belief misalignments, while an intervention policy crafts collaborator-preferred responses. We derive an analytical solution to this objective, enabling training a single policy via a simple supervised loss. Experiments on three benchmarks show FAAF outperforms competitors in producing concise, interpretable friction and in OOD generalization. By aligning LLMs to act as adaptive \"thought partners\" -- not passive responders -- FAAF advances scalable, dynamic human-AI collaboration. Our code and data can be found at", "subjects": "Computation and Language (cs.CL)", "comments": "48 pages (main paper: 10 pages incl. Limitations and Acknowledgments; references: 6 pages; appendix: 32 pages), 9 figures, 12 tables, appearing in Proceedings of ACL 2025, Vienna, Austria", "pdf_url": "https://arxiv.org/pdf/2505.19428.pdf", "abstract_url": "https://arxiv.org/abs/2505.19428", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2505.20266", "title": "syftr: Pareto-Optimal Generative AI", "authors": ["Alexander Conway", "Debadeepta Dey", "Stefan Hackmann", "Matthew Hausknecht", "Michael Schmidt", "Mark Steadman", "Nick Volynets"], "abstract": "Retrieval-Augmented Generation (RAG) pipelines are central to applying large language models (LLMs) to proprietary or dynamic data. However, building effective RAG flows is complex, requiring careful selection among vector databases, embedding models, text splitters, retrievers, and synthesizing LLMs. The challenge deepens with the rise of agentic paradigms. Modules like verifiers, rewriters, and rerankers-each with intricate hyperparameter dependencies have to be carefully tuned. Balancing tradeoffs between latency, accuracy, and cost becomes increasingly difficult in performance-sensitive applications.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "International Conference on Automated Machine Learning (AutoML) 2025", "pdf_url": "https://arxiv.org/pdf/2505.20266.pdf", "abstract_url": "https://arxiv.org/abs/2505.20266", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic", "@RAG"]}
{"id": "2505.20273", "title": "Ten Principles of AI Agent Economics", "authors": ["Ke Yang", "ChengXiang Zhai"], "abstract": "The rapid rise of AI-based autonomous agents is transforming human society and economic systems, as these entities increasingly exhibit human-like or superhuman intelligence. From excelling at complex games like Go to tackling diverse general-purpose tasks with large language and multimodal models, AI agents are evolving from specialized tools into dynamic participants in social and economic ecosystems. Their autonomy and decision-making capabilities are poised to impact industries, professions, and human lives profoundly, raising critical questions about their integration into economic activities, potential ethical concerns, and the balance between their utility and safety.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.20273.pdf", "abstract_url": "https://arxiv.org/abs/2505.20273", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.20286", "title": "Alita: Generalist Agent Enabling Scalable Agentic Reasoning with Minimal Predefinition and Maximal Self-Evolution", "authors": ["Jiahao Qiu", "Xuan Qi", "Tongcheng Zhang", "Xinzhe Juan", "Jiacheng Guo", "Yifu Lu", "Yimin Wang", "Zixin Yao", "Qihan Ren", "Xun Jiang", "Xing Zhou", "Dongrui Liu", "Ling Yang", "Yue Wu", "Kaixuan Huang", "Shilong Liu", "Hongru Wang", "Mengdi Wang"], "abstract": "Recent advances in large language models (LLMs) have enabled agents to autonomously perform complex, open-ended tasks. However, many existing frameworks depend heavily on manually predefined tools and workflows, which hinder their adaptability, scalability, and generalization across domains. In this work, we introduce Alita--a generalist agent designed with the principle of \"Simplicity is the ultimate sophistication,\" enabling scalable agentic reasoning through minimal predefinition and maximal self-evolution. For minimal predefinition, Alita is equipped with only one component for direct problem-solving, making it much simpler and neater than previous approaches that relied heavily on hand-crafted, elaborate tools and workflows. This clean design enhances its potential to generalize to challenging questions, without being limited by tools. For Maximal self-evolution, we enable the creativity of Alita by providing a suite of general-purpose components to autonomously construct, refine, and reuse external capabilities by generating task-related model context protocols (MCPs) from open source, which contributes to scalable agentic reasoning. Notably, Alita achieves 75.15% pass@1 and 87.27% pass@3 accuracy, which is top-ranking among general-purpose agents, on the GAIA benchmark validation dataset, 74.00% and 52.00% pass@1, respectively, on Mathvista and PathVQA, outperforming many agent systems with far greater complexity. More details will be updated at $\\href{", "subjects": "Artificial Intelligence (cs.AI)", "comments": "9 pages, 3 figures", "pdf_url": "https://arxiv.org/pdf/2505.20286.pdf", "abstract_url": "https://arxiv.org/abs/2505.20286", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"]}
{"id": "2505.17648", "title": "Simulating Macroeconomic Expectations using LLM Agents", "authors": ["Jianhao Lin", "Lexuan Sun", "Yixin Yan"], "abstract": "We introduce a novel framework for simulating macroeconomic expectation formation using Large Language Model-Empowered Agents (LLM Agents). By constructing thousands of LLM Agents equipped with modules for personal characteristics, prior expectations, and knowledge, we replicate a survey experiment involving households and experts on inflation and unemployment. Our results show that although the expectations and thoughts generated by LLM Agents are more homogeneous than those of human participants, they still effectively capture key heterogeneity across agents and the underlying drivers of expectation formation. Furthermore, a module-ablation exercise highlights the critical role of prior expectations in simulating such heterogeneity. This approach complements traditional survey methods and offers new insights into AI behavioral science in macroeconomic research.", "subjects": "General Economics (econ.GN); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.17648.pdf", "abstract_url": "https://arxiv.org/abs/2505.17648", "categories": ["General Economics (econ.GN)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.18156", "title": "InjectLab: A Tactical Framework for Adversarial Threat Modeling Against Large Language Models", "authors": ["Austin Howard"], "abstract": "Large Language Models (LLMs) are changing the way people interact with technology. Tools like ChatGPT and Claude AI are now common in business, research, and everyday life. But with that growth comes new risks, especially prompt-based attacks that exploit how these models process language. InjectLab is a security framework designed to address that problem. This paper introduces InjectLab as a structured, open-source matrix that maps real-world techniques used to manipulate LLMs. The framework is inspired by MITRE ATT&CK and focuses specifically on adversarial behavior at the prompt layer. It includes over 25 techniques organized under six core tactics, covering threats like instruction override, identity swapping, and multi-agent exploitation. Each technique in InjectLab includes detection guidance, mitigation strategies, and YAML-based simulation tests. A Python tool supports easy execution of prompt-based test cases. This paper outlines the framework's structure, compares it to other AI threat taxonomies, and discusses its future direction as a practical, community-driven foundation for securing language models.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.18156.pdf", "abstract_url": "https://arxiv.org/abs/2505.18156", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"]}
{"id": "2505.19494", "title": "Anveshana: A New Benchmark Dataset for Cross-Lingual Information Retrieval On English Queries and Sanskrit Documents", "authors": ["Manoj Balaji Jagadeeshan", "Prince Raj", "Pawan Goyal"], "abstract": "The study presents a comprehensive benchmark for retrieving Sanskrit documents using English queries, focusing on the chapters of the Srimadbhagavatam. It employs a tripartite approach: Direct Retrieval (DR), Translation-based Retrieval (DT), and Query Translation (QT), utilizing shared embedding spaces and advanced translation methods to enhance retrieval systems in a RAG framework. The study fine-tunes state-of-the-art models for Sanskrit's linguistic nuances, evaluating models such as BM25, REPLUG, mDPR, ColBERT, Contriever, and GPT-2. It adapts summarization techniques for Sanskrit documents to improve QA processing. Evaluation shows DT methods outperform DR and QT in handling the cross-lingual challenges of ancient texts, improving accessibility and understanding. A dataset of 3,400 English-Sanskrit query-document pairs underpins the study, aiming to preserve Sanskrit scriptures and share their philosophical importance widely. Our dataset is publicly available at", "subjects": "Computation and Language (cs.CL); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19494.pdf", "abstract_url": "https://arxiv.org/abs/2505.19494", "categories": ["Computation and Language (cs.CL)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"]}
{"id": "2505.18214", "title": "LA-RCS: LLM-Agent-Based Robot Control System", "authors": ["TaekHyun Park", "YoungJun Choi", "SeungHoon Shin", "Kwangil Lee"], "abstract": "LA-RCS (LLM-agent-based robot control system) is a sophisticated robot control system designed to autonomously plan, work, and analyze the external environment based on user requirements by utilizing LLM-Agent. Utilizing a dual-agent framework, LA-RCS generates plans based on user requests, observes the external environment, executes the plans, and modifies the plans as needed to adapt to changes in the external conditions. Additionally, LA-RCS interprets natural language commands by the user and converts them into commands compatible with the robot interface so that the robot can execute tasks and meet user requests properly. During his process, the system autonomously evaluates observation results, provides feedback on the tasks, and executes commands based on real-time environmental monitoring, significantly reducing the need for user intervention in fulfilling requests. We categorized the scenarios that LA-RCS needs to perform into four distinct types and conducted a quantitative assessment of its performance in each scenario. The results showed an average success rate of 90 percent, demonstrating the system capability to fulfill user requests satisfactorily. For more extensive results, readers can visit our project page:", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18214.pdf", "abstract_url": "https://arxiv.org/abs/2505.18214", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.19538", "title": "DoctorRAG: Medical RAG Fusing Knowledge with Patient Analogy through Textual Gradients", "authors": ["Yuxing Lu", "Gecheng Fu", "Wei Wu", "Xukai Zhao", "Sin Yee Goi", "Jinzhuo Wang"], "abstract": "Existing medical RAG systems mainly leverage knowledge from medical knowledge bases, neglecting the crucial role of experiential knowledge derived from similar patient cases -- a key component of human clinical reasoning. To bridge this gap, we propose DoctorRAG, a RAG framework that emulates doctor-like reasoning by integrating both explicit clinical knowledge and implicit case-based experience. DoctorRAG enhances retrieval precision by first allocating conceptual tags for queries and knowledge sources, together with a hybrid retrieval mechanism from both relevant knowledge and patient. In addition, a Med-TextGrad module using multi-agent textual gradients is integrated to ensure that the final output adheres to the retrieved knowledge and patient query. Comprehensive experiments on multilingual, multitask datasets demonstrate that DoctorRAG significantly outperforms strong baseline RAG models and gains improvements from iterative refinements. Our approach generates more accurate, relevant, and comprehensive responses, taking a step towards more doctor-like medical reasoning systems.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Information Retrieval (cs.IR); Multiagent Systems (cs.MA)", "comments": "32 pages, 5 figures, 5 tables", "pdf_url": "https://arxiv.org/pdf/2505.19538.pdf", "abstract_url": "https://arxiv.org/abs/2505.19538", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Computational Engineering, Finance, and Science (cs.CE)", "Information Retrieval (cs.IR)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "@RAG"]}
{"id": "2505.19549", "title": "Towards Multi-Granularity Memory Association and Selection for Long-Term Conversational Agents", "authors": ["Derong Xu", "Yi Wen", "Pengyue Jia", "Yingyi Zhang", "wenlin zhang", "Yichao Wang", "Huifeng Guo", "Ruiming Tang", "Xiangyu Zhao", "Enhong Chen", "Tong Xu"], "abstract": "Large Language Models (LLMs) have recently been widely adopted in conversational agents. However, the increasingly long interactions between users and agents accumulate extensive dialogue records, making it difficult for LLMs with limited context windows to maintain a coherent long-term dialogue memory and deliver personalized responses. While retrieval-augmented memory systems have emerged to address this issue, existing methods often depend on single-granularity memory segmentation and retrieval. This approach falls short in capturing deep memory connections, leading to partial retrieval of useful information or substantial noise, resulting in suboptimal performance. To tackle these limits, we propose MemGAS, a framework that enhances memory consolidation by constructing multi-granularity association, adaptive selection, and retrieval. MemGAS is based on multi-granularity memory units and employs Gaussian Mixture Models to cluster and associate new memories with historical ones. An entropy-based router adaptively selects optimal granularity by evaluating query relevance distributions and balancing information completeness and noise. Retrieved memories are further refined via LLM-based filtering. Experiments on four long-term memory benchmarks demonstrate that MemGAS outperforms state-of-the-art methods on both question answer and retrieval tasks, achieving superior performance across different query types and top-K settings.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19549.pdf", "abstract_url": "https://arxiv.org/abs/2505.19549", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2505.19591", "title": "Multi-Agent Collaboration via Evolving Orchestration", "authors": ["Yufan Dang", "Chen Qian", "Xueheng Luo", "Jingru Fan", "Zihao Xie", "Ruijie Shi", "Weize Chen", "Cheng Yang", "Xiaoyin Che", "Ye Tian", "Xuantang Xiong", "Lei Han", "Zhiyuan Liu", "Maosong Sun"], "abstract": "Large language models (LLMs) have achieved remarkable results across diverse downstream tasks, but their monolithic nature restricts scalability and efficiency in complex problem-solving. While recent research explores multi-agent collaboration among LLMs, most approaches rely on static organizational structures that struggle to adapt as task complexity and agent numbers grow, resulting in coordination overhead and inefficiencies. To this end, we propose a puppeteer-style paradigm for LLM-based multi-agent collaboration, where a centralized orchestrator (\"puppeteer\") dynamically directs agents (\"puppets\") in response to evolving task states. This orchestrator is trained via reinforcement learning to adaptively sequence and prioritize agents, enabling flexible and evolvable collective reasoning. Experiments on closed- and open-domain scenarios show that this method achieves superior performance with reduced computational costs. Analyses further reveal that the key improvements consistently stem from the emergence of more compact, cyclic reasoning structures under the orchestrator's evolution.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "Work in Progress", "pdf_url": "https://arxiv.org/pdf/2505.19591.pdf", "abstract_url": "https://arxiv.org/abs/2505.19591", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"]}
{"id": "2505.19630", "title": "DoctorAgent-RL: A Multi-Agent Collaborative Reinforcement Learning System for Multi-Turn Clinical Dialogue", "authors": ["Yichun Feng", "Jiawei Wang", "Lu Zhou", "Yixue Li"], "abstract": "Large language models (LLMs) have demonstrated excellent capabilities in the field of biomedical question answering, but their application in real-world clinical consultations still faces core challenges. Existing systems rely on a one-way information transmission mode where patients must fully describe their symptoms in a single round, leading to nonspecific diagnostic recommendations when complaints are vague. Traditional multi-turn dialogue methods based on supervised learning are constrained by static data-driven paradigms, lacking generalizability and struggling to intelligently extract key clinical information. To address these limitations, we propose DoctorAgent-RL, a reinforcement learning (RL)-based multi-agent collaborative framework that models medical consultations as a dynamic decision-making process under uncertainty. The doctor agent continuously optimizes its questioning strategy within the RL framework through multi-turn interactions with the patient agent, dynamically adjusting its information-gathering path based on comprehensive rewards from the Consultation Evaluator. This RL fine-tuning mechanism enables LLMs to autonomously develop interaction strategies aligned with clinical reasoning logic, rather than superficially imitating patterns in existing dialogue data. Notably, we constructed MTMedDialog, the first English multi-turn medical consultation dataset capable of simulating patient interactions. Experiments demonstrate that DoctorAgent-RL outperforms existing models in both multi-turn reasoning capability and final diagnostic performance, demonstrating practical value in assisting clinical consultations.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19630.pdf", "abstract_url": "https://arxiv.org/abs/2505.19630", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2505.18229", "title": "BEDI: A Comprehensive Benchmark for Evaluating Embodied Agents on UAVs", "authors": ["Mingning Guo", "Mengwei Wu", "Jiarun He", "Shaoxian Li", "Haifeng Li", "Chao Tao"], "abstract": "With the rapid advancement of low-altitude remote sensing and Vision-Language Models (VLMs), Embodied Agents based on Unmanned Aerial Vehicles (UAVs) have shown significant potential in autonomous tasks. However, current evaluation methods for UAV-Embodied Agents (UAV-EAs) remain constrained by the lack of standardized benchmarks, diverse testing scenarios and open system interfaces. To address these challenges, we propose BEDI (Benchmark for Embodied Drone Intelligence), a systematic and standardized benchmark designed for evaluating UAV-EAs. Specifically, we introduce a novel Dynamic Chain-of-Embodied-Task paradigm based on the perception-decision-action loop, which decomposes complex UAV tasks into standardized, measurable subtasks. Building on this paradigm, we design a unified evaluation framework encompassing five core sub-skills: semantic perception, spatial perception, motion control, tool utilization, and task planning. Furthermore, we construct a hybrid testing platform that integrates static real-world environments with dynamic virtual scenarios, enabling comprehensive performance assessment of UAV-EAs across varied contexts. The platform also offers open and standardized interfaces, allowing researchers to customize tasks and extend scenarios, thereby enhancing flexibility and scalability in the evaluation process. Finally, through empirical evaluations of several state-of-the-art (SOTA) VLMs, we reveal their limitations in embodied UAV tasks, underscoring the critical role of the BEDI benchmark in advancing embodied intelligence research and model optimization. By filling the gap in systematic and standardized evaluation within this field, BEDI facilitates objective model comparison and lays a robust foundation for future development in this field. Our benchmark will be released at", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18229.pdf", "abstract_url": "https://arxiv.org/abs/2505.18229", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.19952", "title": "Multimodal Reasoning Agent for Zero-Shot Composed Image Retrieval", "authors": ["Rong-Cheng Tu", "Wenhao Sun", "Hanzhe You", "Yingjie Wang", "Jiaxing Huang", "Li Shen", "Dacheng Tao"], "abstract": "Zero-Shot Composed Image Retrieval (ZS-CIR) aims to retrieve target images given a compositional query, consisting of a reference image and a modifying text-without relying on annotated training data. Existing approaches often generate a synthetic target text using large language models (LLMs) to serve as an intermediate anchor between the compositional query and the target image. Models are then trained to align the compositional query with the generated text, and separately align images with their corresponding texts using contrastive learning. However, this reliance on intermediate text introduces error propagation, as inaccuracies in query-to-text and text-to-image mappings accumulate, ultimately degrading retrieval performance. To address these problems, we propose a novel framework by employing a Multimodal Reasoning Agent (MRA) for ZS-CIR. MRA eliminates the dependence on textual intermediaries by directly constructing triplets, <reference image, modification text, target image>, using only unlabeled image data. By training on these synthetic triplets, our model learns to capture the relationships between compositional queries and candidate images directly. Extensive experiments on three standard CIR benchmarks demonstrate the effectiveness of our approach. On the FashionIQ dataset, our method improves Average R@10 by at least 7.5\\% over existing baselines; on CIRR, it boosts R@1 by 9.6\\%; and on CIRCO, it increases mAP@5 by 9.5\\%.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19952.pdf", "abstract_url": "https://arxiv.org/abs/2505.19952", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Information Retrieval (cs.IR)"], "matching_keywords": ["agent"]}
{"id": "2505.19647", "title": "Select, Read, and Write: A Multi-Agent Framework of Full-Text-based Related Work Generation", "authors": ["Xiaochuan Liu", "Ruihua Song", "Xiting Wang", "Xu Chen"], "abstract": "Automatic related work generation (RWG) can save people's time and effort when writing a draft of related work section (RWS) for further revision. However, existing methods for RWG always suffer from shallow comprehension due to taking the limited portions of references papers as input and isolated explanation for each reference due to ineffective capturing the relationships among them. To address these issues, we focus on full-text-based RWG task and propose a novel multi-agent framework. Our framework consists of three agents: a selector that decides which section of the papers is going to read next, a reader that digests the selected section and updates a shared working memory, and a writer that generates RWS based on the final curated memory. To better capture the relationships among references, we also propose two graph-aware strategies for selector, enabling to optimize the reading order with constrains of the graph structure. Extensive experiments demonstrate that our framework consistently improves performance across three base models and various input configurations. The graph-aware selectors outperform alternative selectors, achieving state-of-the-art results. The code and data are available at", "subjects": "Computation and Language (cs.CL)", "comments": "Accepted by ACL 2025 (Findings)", "pdf_url": "https://arxiv.org/pdf/2505.19647.pdf", "abstract_url": "https://arxiv.org/abs/2505.19647", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2505.18279", "title": "Collaborative Memory: Multi-User Memory Sharing in LLM Agents with Dynamic Access Control", "authors": ["Alireza Rezazadeh", "Zichao Li", "Ange Lou", "Yuying Zhao", "Wei Wei", "Yujia Bao"], "abstract": "Complex tasks are increasingly delegated to ensembles of specialized LLM-based agents that reason, communicate, and coordinate actions-both among themselves and through interactions with external tools, APIs, and databases. While persistent memory has been shown to enhance single-agent performance, most approaches assume a monolithic, single-user context-overlooking the benefits and challenges of knowledge transfer across users under dynamic, asymmetric permissions. We introduce Collaborative Memory, a framework for multi-user, multi-agent environments with asymmetric, time-evolving access controls encoded as bipartite graphs linking users, agents, and resources. Our system maintains two memory tiers: (1) private memory-private fragments visible only to their originating user; and (2) shared memory-selectively shared fragments. Each fragment carries immutable provenance attributes (contributing agents, accessed resources, and timestamps) to support retrospective permission checks. Granular read policies enforce current user-agent-resource constraints and project existing memory fragments into filtered transformed views. Write policies determine fragment retention and sharing, applying context-aware transformations to update the memory. Both policies may be designed conditioned on system, agent, and user-level information. Our framework enables safe, efficient, and interpretable cross-user knowledge sharing, with provable adherence to asymmetric, time-varying policies and full auditability of memory operations.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18279.pdf", "abstract_url": "https://arxiv.org/abs/2505.18279", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"]}
{"id": "2505.18286", "title": "Single-agent or Multi-agent Systems? Why Not Both?", "authors": ["Mingyan Gao", "Yanzi Li", "Banruo Liu", "Yifan Yu", "Phillip Wang", "Ching-Yu Lin", "Fan Lai"], "abstract": "Multi-agent systems (MAS) decompose complex tasks and delegate subtasks to different large language model (LLM) agents and tools. Prior studies have reported the superior accuracy performance of MAS across diverse domains, enabled by long-horizon context tracking and error correction through role-specific agents. However, the design and deployment of MAS incur higher complexity and runtime cost compared to single-agent systems (SAS). Meanwhile, frontier LLMs, such as OpenAI-o3 and Gemini-2.5-Pro, have rapidly advanced in long-context reasoning, memory retention, and tool usage, mitigating many limitations that originally motivated MAS designs. In this paper, we conduct an extensive empirical study comparing MAS and SAS across various popular agentic applications. We find that the benefits of MAS over SAS diminish as LLM capabilities improve, and we propose efficient mechanisms to pinpoint the error-prone agent in MAS. Furthermore, the performance discrepancy between MAS and SAS motivates our design of a hybrid agentic paradigm, request cascading between MAS and SAS, to improve both efficiency and capability. Our design improves accuracy by 1.1-12% while reducing deployment costs by up to 20% across various agentic applications.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18286.pdf", "abstract_url": "https://arxiv.org/abs/2505.18286", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"]}
{"id": "2505.19754", "title": "NeuSym-RAG: Hybrid Neural Symbolic Retrieval with Multiview Structuring for PDF Question Answering", "authors": ["Ruisheng Cao", "Hanchong Zhang", "Tiancheng Huang", "Zhangyi Kang", "Yuxin Zhang", "Liangtai Sun", "Hanqi Li", "Yuxun Miao", "Shuai Fan", "Lu Chen", "Kai Yu"], "abstract": "The increasing number of academic papers poses significant challenges for researchers to efficiently acquire key details. While retrieval augmented generation (RAG) shows great promise in large language model (LLM) based automated question answering, previous works often isolate neural and symbolic retrieval despite their complementary strengths. Moreover, conventional single-view chunking neglects the rich structure and layout of PDFs, e.g., sections and tables. In this work, we propose NeuSym-RAG, a hybrid neural symbolic retrieval framework which combines both paradigms in an interactive process. By leveraging multi-view chunking and schema-based parsing, NeuSym-RAG organizes semi-structured PDF content into both the relational database and vectorstore, enabling LLM agents to iteratively gather context until sufficient to generate answers. Experiments on three full PDF-based QA datasets, including a self-annotated one AIRQA-REAL, show that NeuSym-RAG stably defeats both the vector-based RAG and various structured baselines, highlighting its capacity to unify both retrieval schemes and utilize multiple views. Code and data are publicly available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "29 pages, 11 figures, 12 tables, accepted to ACL 2025 Long Main", "pdf_url": "https://arxiv.org/pdf/2505.19754.pdf", "abstract_url": "https://arxiv.org/abs/2505.19754", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "@RAG"]}
{"id": "2505.19768", "title": "T^2Agent A Tool-augmented Multimodal Misinformation Detection Agent with Monte Carlo Tree Search", "authors": ["Xing Cui", "Yueying Zou", "Zekun Li", "Peipei Li", "Xinyuan Xu", "Xuannan Liu", "Huaibo Huang", "Ran He"], "abstract": "Real-world multimodal misinformation often arises from mixed forgery sources, requiring dynamic reasoning and adaptive verification. However, existing methods mainly rely on static pipelines and limited tool usage, limiting their ability to handle such complexity and diversity. To address this challenge, we propose T2Agent, a novel misinformation detection agent that incorporates an extensible toolkit with Monte Carlo Tree Search (MCTS). The toolkit consists of modular tools such as web search, forgery detection, and consistency analysis. Each tool is described using standardized templates, enabling seamless integration and future expansion. To avoid inefficiency from using all tools simultaneously, a Bayesian optimization-based selector is proposed to identify a task-relevant subset. This subset then serves as the action space for MCTS to dynamically collect evidence and perform multi-source verification. To better align MCTS with the multi-source nature of misinformation detection, T2Agent extends traditional MCTS with multi-source verification, which decomposes the task into coordinated subtasks targeting different forgery sources. A dual reward mechanism containing a reasoning trajectory score and a confidence score is further proposed to encourage a balance between exploration across mixed forgery sources and exploitation for more reliable evidence. We conduct ablation studies to confirm the effectiveness of the tree search mechanism and tool usage. Extensive experiments further show that T2Agent consistently outperforms existing baselines on challenging mixed-source multimodal misinformation benchmarks, demonstrating its strong potential as a training-free approach for enhancing detection accuracy. The code will be released.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19768.pdf", "abstract_url": "https://arxiv.org/abs/2505.19768", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2505.18341", "title": "CrashAgent: Crash Scenario Generation via Multi-modal Reasoning", "authors": ["Miao Li", "Wenhao Ding", "Haohong Lin", "Yiqi Lyu", "Yihang Yao", "Yuyou Zhang", "Ding Zhao"], "abstract": "Training and evaluating autonomous driving algorithms requires a diverse range of scenarios. However, most available datasets predominantly consist of normal driving behaviors demonstrated by human drivers, resulting in a limited number of safety-critical cases. This imbalance, often referred to as a long-tail distribution, restricts the ability of driving algorithms to learn from crucial scenarios involving risk or failure, scenarios that are essential for humans to develop driving skills efficiently. To generate such scenarios, we utilize Multi-modal Large Language Models to convert crash reports of accidents into a structured scenario format, which can be directly executed within simulations. Specifically, we introduce CrashAgent, a multi-agent framework designed to interpret multi-modal real-world traffic crash reports for the generation of both road layouts and the behaviors of the ego vehicle and surrounding traffic participants. We comprehensively evaluate the generated crash scenarios from multiple perspectives, including the accuracy of layout reconstruction, collision rate, and diversity. The resulting high-quality and large-scale crash dataset will be publicly available to support the development of safe driving algorithms in handling safety-critical situations.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18341.pdf", "abstract_url": "https://arxiv.org/abs/2505.18341", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.18347", "title": "The Cell Must Go On: Agar.io for Continual Reinforcement Learning", "authors": ["Mohamed A. Mohamed", "Kateryna Nekhomiazh", "Vedant Vyas", "Marcos M. Jose", "Andrew Patterson", "Marlos C. Machado"], "abstract": "Continual reinforcement learning (RL) concerns agents that are expected to learn continually, rather than converge to a policy that is then fixed for evaluation. Such an approach is well suited to environments the agent perceives as changing, which renders any static policy ineffective over time. The few simulators explicitly designed for empirical research in continual RL are often limited in scope or complexity, and it is now common for researchers to modify episodic RL environments by artificially incorporating abrupt task changes during interaction. In this paper, we introduce AgarCL, a research platform for continual RL that allows for a progression of increasingly sophisticated behaviour. AgarCL is based on the game", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18347.pdf", "abstract_url": "https://arxiv.org/abs/2505.18347", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.18366", "title": "Hard Negative Mining for Domain-Specific Retrieval in Enterprise Systems", "authors": ["Hansa Meghwani", "Amit Agarwal", "Priyaranjan Pattnayak", "Hitesh Laxmichand Patel", "Srikant Panda"], "abstract": "Enterprise search systems often struggle to retrieve accurate, domain-specific information due to semantic mismatches and overlapping terminologies. These issues can degrade the performance of downstream applications such as knowledge management, customer support, and retrieval-augmented generation agents. To address this challenge, we propose a scalable hard-negative mining framework tailored specifically for domain-specific enterprise data. Our approach dynamically selects semantically challenging but contextually irrelevant documents to enhance deployed re-ranking models.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": "Accepted to ACL 2025", "pdf_url": "https://arxiv.org/pdf/2505.18366.pdf", "abstract_url": "https://arxiv.org/abs/2505.18366", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"]}
{"id": "2505.20129", "title": "Agentic 3D Scene Generation with Spatially Contextualized VLMs", "authors": ["Xinhang Liu", "Yu-Wing Tai", "Chi-Keung Tang"], "abstract": "Despite recent advances in multimodal content generation enabled by vision-language models (VLMs), their ability to reason about and generate structured 3D scenes remains largely underexplored. This limitation constrains their utility in spatially grounded tasks such as embodied AI, immersive simulations, and interactive 3D applications. We introduce a new paradigm that enables VLMs to generate, understand, and edit complex 3D environments by injecting a continually evolving spatial context. Constructed from multimodal input, this context consists of three components: a scene portrait that provides a high-level semantic blueprint, a semantically labeled point cloud capturing object-level geometry, and a scene hypergraph that encodes rich spatial relationships, including unary, binary, and higher-order constraints. Together, these components provide the VLM with a structured, geometry-aware working memory that integrates its inherent multimodal reasoning capabilities with structured 3D understanding for effective spatial reasoning. Building on this foundation, we develop an agentic 3D scene generation pipeline in which the VLM iteratively reads from and updates the spatial context. The pipeline features high-quality asset generation with geometric restoration, environment setup with automatic verification, and ergonomic adjustment guided by the scene hypergraph. Experiments show that our framework can handle diverse and challenging inputs, achieving a level of generalization not observed in prior work. Further results demonstrate that injecting spatial context enables VLMs to perform downstream tasks such as interactive scene editing and path planning, suggesting strong potential for spatially intelligent systems in computer graphics, 3D vision, and embodied applications.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.20129.pdf", "abstract_url": "https://arxiv.org/abs/2505.20129", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Graphics (cs.GR)"], "matching_keywords": ["agent", "agentic"]}
{"id": "2505.18384", "title": "Dynamic Risk Assessments for Offensive Cybersecurity Agents", "authors": ["Boyi Wei", "Benedikt Stroebl", "Jiacen Xu", "Joie Zhang", "Zhou Li", "Peter Henderson"], "abstract": "Foundation models are increasingly becoming better autonomous programmers, raising the prospect that they could also automate dangerous offensive cyber-operations. Current frontier model audits probe the cybersecurity risks of such agents, but most fail to account for the degrees of freedom available to adversaries in the real world. In particular, with strong verifiers and financial incentives, agents for offensive cybersecurity are amenable to iterative improvement by would-be adversaries. We argue that assessments should take into account an expanded threat model in the context of cybersecurity, emphasizing the varying degrees of freedom that an adversary may possess in stateful and non-stateful environments within a fixed compute budget. We show that even with a relatively small compute budget (8 H100 GPU Hours in our study), adversaries can improve an agent's cybersecurity capability on InterCode CTF by more than 40\\% relative to the baseline -- without any external assistance. These results highlight the need to evaluate agents' cybersecurity risk in a dynamic manner, painting a more representative picture of risk.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": "26 pages, 11 figures", "pdf_url": "https://arxiv.org/pdf/2505.18384.pdf", "abstract_url": "https://arxiv.org/abs/2505.18384", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.18397", "title": "An Outlook on the Opportunities and Challenges of Multi-Agent AI Systems", "authors": ["Fangqiao Tian", "An Luo", "Jin Du", "Xun Xian", "Robert Specht", "Ganghua Wang", "Xuan Bi", "Jiawei Zhou", "Jayanth Srinivasa", "Ashish Kundu", "Charles Fleming", "Rui Zhang", "Zirui Liu", "Mingyi Hong", "Jie Ding"], "abstract": "Multi-agent AI systems (MAS) offer a promising framework for distributed intelligence, enabling collaborative reasoning, planning, and decision-making across autonomous agents. This paper provides a systematic outlook on the current opportunities and challenges of MAS, drawing insights from recent advances in large language models (LLMs), federated optimization, and human-AI interaction. We formalize key concepts including agent topology, coordination protocols, and shared objectives, and identify major risks such as dependency, misalignment, and vulnerabilities arising from training data overlap. Through a biologically inspired simulation and comprehensive theoretical framing, we highlight critical pathways for developing robust, scalable, and secure MAS in real-world settings.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18397.pdf", "abstract_url": "https://arxiv.org/abs/2505.18397", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Emerging Technologies (cs.ET)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"]}
{"id": "2505.18417", "title": "Reinforcement Learning for Ballbot Navigation in Uneven Terrain", "authors": ["Achkan Salehi"], "abstract": "Ballbot (i.e. Ball balancing robot) navigation usually relies on methods rooted in control theory (CT), and works that apply Reinforcement learning (RL) to the problem remain rare while generally being limited to specific subtasks (e.g. balance recovery). Unlike CT based methods, RL does not require (simplifying) assumptions about environment dynamics (e.g. the absence of slippage between the ball and the floor). In addition to this increased accuracy in modeling, RL agents can easily be conditioned on additional observations such as depth-maps without the need for explicit formulations from first principles, leading to increased adaptivity. Despite those advantages, there has been little to no investigation into the capabilities, data-efficiency and limitations of RL based methods for ballbot control and navigation. Furthermore, there is a notable absence of an open-source, RL-friendly simulator for this task. In this paper, we present an open-source ballbot simulation based on MuJoCo, and show that with appropriate conditioning on exteroceptive observations as well as reward shaping, policies learned by classical model-free RL methods are capable of effectively navigating through randomly generated uneven terrain, using a reasonable amount of data (four to five hours on a system operating at 500hz).", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "6 pages, 8 figures, 2 tables", "pdf_url": "https://arxiv.org/pdf/2505.18417.pdf", "abstract_url": "https://arxiv.org/abs/2505.18417", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"]}
{"id": "2505.20289", "title": "VisualToolAgent (VisTA): A Reinforcement Learning Framework for Visual Tool Selection", "authors": ["Zeyi Huang", "Yuyang Ji", "Anirudh Sundara Rajan", "Zefan Cai", "Wen Xiao", "Junjie Hu", "Yong Jae Lee"], "abstract": "We introduce VisTA, a new reinforcement learning framework that empowers visual agents to dynamically explore, select, and combine tools from a diverse library based on empirical performance. Existing methods for tool-augmented reasoning either rely on training-free prompting or large-scale fine-tuning; both lack active tool exploration and typically assume limited tool diversity, and fine-tuning methods additionally demand extensive human supervision. In contrast, VisTA leverages end-to-end reinforcement learning to iteratively refine sophisticated, query-specific tool selection strategies, using task outcomes as feedback signals. Through Group Relative Policy Optimization (GRPO), our framework enables an agent to autonomously discover effective tool-selection pathways without requiring explicit reasoning supervision. Experiments on the ChartQA, Geometry3K, and BlindTest benchmarks demonstrate that VisTA achieves substantial performance gains over training-free baselines, especially on out-of-distribution examples. These results highlight VisTA's ability to enhance generalization, adaptively utilize diverse tools, and pave the way for flexible, experience-driven visual reasoning systems.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.20289.pdf", "abstract_url": "https://arxiv.org/abs/2505.20289", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"]}
{"id": "2505.20013", "title": "WebCoT: Enhancing Web Agent Reasoning by Reconstructing Chain-of-Thought in Reflection, Branching, and Rollback", "authors": ["Minda Hu", "Tianqing Fang", "Jianshu Zhang", "Junyu Ma", "Zhisong Zhang", "Jingyan Zhou", "Hongming Zhang", "Haitao Mi", "Dong Yu", "Irwin King"], "abstract": "Web agents powered by Large Language Models (LLMs) show promise for next-generation AI, but their limited reasoning in uncertain, dynamic web environments hinders robust deployment. In this paper, we identify key reasoning skills essential for effective web agents, i.e., reflection & lookahead, branching, and rollback, and curate trajectory data that exemplifies these abilities by reconstructing the agent's (inference-time) reasoning algorithms into chain-of-thought rationales. We conduct experiments in the agent self-improving benchmark, OpenWebVoyager, and demonstrate that distilling salient reasoning patterns into the backbone LLM via simple fine-tuning can substantially enhance its performance. Our approach yields significant improvements across multiple benchmarks, including WebVoyager, Mind2web-live, and SimpleQA (web search), highlighting the potential of targeted reasoning skill enhancement for web agents.", "subjects": "Computation and Language (cs.CL)", "comments": "18 pages", "pdf_url": "https://arxiv.org/pdf/2505.20013.pdf", "abstract_url": "https://arxiv.org/abs/2505.20013", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2505.20023", "title": "Training LLM-Based Agents with Synthetic Self-Reflected Trajectories and Partial Masking", "authors": ["Yihan Chen", "Benfeng Xu", "Xiaorui Wang", "Yongdong Zhang", "Zhendong Mao"], "abstract": "Autonomous agents, which perceive environments and take actions to achieve goals, have become increasingly feasible with the advancements in large language models (LLMs). However, current powerful agents often depend on sophisticated prompt engineering combined with closed-source LLMs like GPT-4. Although training open-source LLMs using expert trajectories from teacher models has yielded some improvements in agent capabilities, this approach still faces limitations such as performance plateauing and error propagation. To mitigate these challenges, we propose STeP, a novel method for improving LLM-based agent training. We synthesize self-reflected trajectories that include reflections and corrections of error steps, which enhance the effectiveness of LLM agents in learning from teacher models, enabling them to become agents capable of self-reflecting and correcting. We also introduce partial masking strategy that prevents the LLM from internalizing incorrect or suboptimal steps. Experiments demonstrate that our method improves agent performance across three representative tasks: ALFWorld, WebShop, and SciWorld. For the open-source model LLaMA2-7B-Chat, when trained using self-reflected trajectories constructed with Qwen1.5-110B-Chat as the teacher model, it achieves comprehensive improvements with less training data compared to agents trained exclusively on expert trajectories.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.20023.pdf", "abstract_url": "https://arxiv.org/abs/2505.20023", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2505.20096", "title": "MA-RAG: Multi-Agent Retrieval-Augmented Generation via Collaborative Chain-of-Thought Reasoning", "authors": ["Thang Nguyen", "Peter Chin", "Yu-Wing Tai"], "abstract": "We present MA-RAG, a Multi-Agent framework for Retrieval-Augmented Generation (RAG) that addresses the inherent ambiguities and reasoning challenges in complex information-seeking tasks. Unlike conventional RAG methods that rely on either end-to-end fine-tuning or isolated component enhancements, MA-RAG orchestrates a collaborative set of specialized AI agents: Planner, Step Definer, Extractor, and QA Agents, to tackle each stage of the RAG pipeline with task-aware reasoning. Ambiguities may arise from underspecified queries, sparse or indirect evidence in retrieved documents, or the need to integrate information scattered across multiple sources. MA-RAG mitigates these challenges by decomposing the problem into subtasks, such as query disambiguation, evidence extraction, and answer synthesis, and dispatching them to dedicated agents equipped with chain-of-thought prompting. These agents communicate intermediate reasoning and progressively refine the retrieval and synthesis process. Our design allows fine-grained control over information flow without any model fine-tuning. Crucially, agents are invoked on demand, enabling a dynamic and efficient workflow that avoids unnecessary computation. This modular and reasoning-driven architecture enables MA-RAG to deliver robust, interpretable results. Experiments on multi-hop and ambiguous QA benchmarks demonstrate that MA-RAG outperforms state-of-the-art training-free baselines and rivals fine-tuned systems, validating the effectiveness of collaborative agent-based reasoning in RAG.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.20096.pdf", "abstract_url": "https://arxiv.org/abs/2505.20096", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "@RAG"]}
{"id": "2505.18458", "title": "A Survey of LLM $\\times$ DATA", "authors": ["Xuanhe Zhou", "Junxuan He", "Wei Zhou", "Haodong Chen", "Zirui Tang", "Haoyu Zhao", "Xin Tong", "Guoliang Li", "Youmin Chen", "Jun Zhou", "Zhaojun Sun", "Binyuan Hui", "Shuo Wang", "Conghui He", "Zhiyuan Liu", "Jingren Zhou", "Fan Wu"], "abstract": "The integration of large language model (LLM) and data management (DATA) is rapidly redefining both domains. In this survey, we comprehensively review the bidirectional relationships. On the one hand, DATA4LLM, spanning large-scale data processing, storage, and serving, feeds LLMs with high quality, diversity, and timeliness of data required for stages like pre-training, post-training, retrieval-augmented generation, and agentic workflows: (i) Data processing for LLMs includes scalable acquisition, deduplication, filtering, selection, domain mixing, and synthetic augmentation; (ii) Data Storage for LLMs focuses on efficient data and model formats, distributed and heterogeneous storage hierarchies, KV-cache management, and fault-tolerant checkpointing; (iii) Data serving for LLMs tackles challenges in RAG (e.g., knowledge post-processing), LLM inference (e.g., prompt compression, data provenance), and training strategies (e.g., data packing and shuffling). On the other hand, in LLM4DATA, LLMs are emerging as general-purpose engines for data management. We review recent advances in (i) data manipulation, including automatic data cleaning, integration, discovery; (ii) data analysis, covering reasoning over structured, semi-structured, and unstructured data, and (iii) system optimization (e.g., configuration tuning, query rewriting, anomaly diagnosis), powered by LLM techniques like retrieval-augmented prompting, task-specialized fine-tuning, and multi-agent collaboration.", "subjects": "Databases (cs.DB); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Information Retrieval (cs.IR); Machine Learning (cs.LG)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.18458.pdf", "abstract_url": "https://arxiv.org/abs/2505.18458", "categories": ["Databases (cs.DB)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Information Retrieval (cs.IR)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic", "@RAG"]}
{"id": "2505.18471", "title": "Invisible Tokens, Visible Bills: The Urgent Need to Audit Hidden Operations in Opaque LLM Services", "authors": ["Guoheng Sun", "Ziyao Wang", "Xuandong Zhao", "Bowei Tian", "Zheyu Shen", "Yexiao He", "Jinming Xing", "Ang Li"], "abstract": "Modern large language model (LLM) services increasingly rely on complex, often abstract operations, such as multi-step reasoning and multi-agent collaboration, to generate high-quality outputs. While users are billed based on token consumption and API usage, these internal steps are typically not visible. We refer to such systems as Commercial Opaque LLM Services (COLS). This position paper highlights emerging accountability challenges in COLS: users are billed for operations they cannot observe, verify, or contest. We formalize two key risks: \\textit{quantity inflation}, where token and call counts may be artificially inflated, and \\textit{quality downgrade}, where providers might quietly substitute lower-cost models or tools. Addressing these risks requires a diverse set of auditing strategies, including commitment-based, predictive, behavioral, and signature-based methods. We further explore the potential of complementary mechanisms such as watermarking and trusted execution environments to enhance verifiability without compromising provider confidentiality. We also propose a modular three-layer auditing framework for COLS and users that enables trustworthy verification across execution, secure logging, and user-facing auditability without exposing proprietary internals. Our aim is to encourage further research and policy development toward transparency, auditability, and accountability in commercial LLM services.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18471.pdf", "abstract_url": "https://arxiv.org/abs/2505.18471", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.18487", "title": "Grounding Bodily Awareness in Visual Representations for Efficient Policy Learning", "authors": ["Junlin Wang", "Zhiyun Lin"], "abstract": "Learning effective visual representations for robotic manipulation remains a fundamental challenge due to the complex body dynamics involved in action execution. In this paper, we study how visual representations that carry body-relevant cues can enable efficient policy learning for downstream robotic manipulation tasks. We present $\\textbf{I}$nter-token $\\textbf{Con}$trast ($\\textbf{ICon}$), a contrastive learning method applied to the token-level representations of Vision Transformers (ViTs). ICon enforces a separation in the feature space between agent-specific and environment-specific tokens, resulting in agent-centric visual representations that embed body-specific inductive biases. This framework can be seamlessly integrated into end-to-end policy learning by incorporating the contrastive loss as an auxiliary objective. Our experiments show that ICon not only improves policy performance across various manipulation tasks but also facilitates policy transfer across different robots. The project website:", "subjects": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "comments": "A preprint version", "pdf_url": "https://arxiv.org/pdf/2505.18487.pdf", "abstract_url": "https://arxiv.org/abs/2505.18487", "categories": ["Robotics (cs.RO)", "Computer Vision and Pattern Recognition (cs.CV)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"]}
{"id": "2505.20118", "title": "TrojanStego: Your Language Model Can Secretly Be A Steganographic Privacy Leaking Agent", "authors": ["Dominik Meier", "Jan Philip Wahle", "Paul RÃ¶ttger", "Terry Ruas", "Bela Gipp"], "abstract": "As large language models (LLMs) become integrated into sensitive workflows, concerns grow over their potential to leak confidential information. We propose TrojanStego, a novel threat model in which an adversary fine-tunes an LLM to embed sensitive context information into natural-looking outputs via linguistic steganography, without requiring explicit control over inference inputs. We introduce a taxonomy outlining risk factors for compromised LLMs, and use it to evaluate the risk profile of the threat. To implement TrojanStego, we propose a practical encoding scheme based on vocabulary partitioning learnable by LLMs via fine-tuning. Experimental results show that compromised models reliably transmit 32-bit secrets with 87% accuracy on held-out prompts, reaching over 97% accuracy using majority voting across three generations. Further, they maintain high utility, can evade human detection, and preserve coherence. These results highlight a new class of LLM data exfiltration attacks that are passive, covert, practical, and dangerous.", "subjects": "Computation and Language (cs.CL); Cryptography and Security (cs.CR)", "comments": "8 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2505.20118.pdf", "abstract_url": "https://arxiv.org/abs/2505.20118", "categories": ["Computation and Language (cs.CL)", "Cryptography and Security (cs.CR)"], "matching_keywords": ["agent"]}
{"id": "2505.20128", "title": "Iterative Self-Incentivization Empowers Large Language Models as Agentic Searchers", "authors": ["Zhengliang Shi", "Lingyong Yan", "Dawei Yin", "Suzan Verberne", "Maarten de Rijke", "Zhaochun Ren"], "abstract": "Large language models (LLMs) have been widely integrated into information retrieval to advance traditional techniques. However, effectively enabling LLMs to seek accurate knowledge in complex tasks remains a challenge due to the complexity of multi-hop queries as well as the irrelevant retrieved content. To address these limitations, we propose EXSEARCH, an agentic search framework, where the LLM learns to retrieve useful information as the reasoning unfolds through a self-incentivized process. At each step, the LLM decides what to retrieve (thinking), triggers an external retriever (search), and extracts fine-grained evidence (recording) to support next-step reasoning. To enable LLM with this capability, EXSEARCH adopts a Generalized Expectation-Maximization algorithm. In the E-step, the LLM generates multiple search trajectories and assigns an importance weight to each; the M-step trains the LLM on them with a re-weighted loss function. This creates a self-incentivized loop, where the LLM iteratively learns from its own generated data, progressively improving itself for search. We further theoretically analyze this training process, establishing convergence guarantees. Extensive experiments on four knowledge-intensive benchmarks show that EXSEARCH substantially outperforms baselines, e.g., +7.8% improvement on exact match score. Motivated by these promising results, we introduce EXSEARCH-Zoo, an extension that extends our method to broader scenarios, to facilitate future work.", "subjects": "Computation and Language (cs.CL)", "comments": "Working in process", "pdf_url": "https://arxiv.org/pdf/2505.20128.pdf", "abstract_url": "https://arxiv.org/abs/2505.20128", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"]}
{"id": "2505.18530", "title": "MRGAgents: A Multi-Agent Framework for Improved Medical Report Generation with Med-LVLMs", "authors": ["Pengyu Wang", "Shuchang Ye", "Usman Naseem", "Jinman Kim"], "abstract": "Medical Large Vision-Language Models (Med-LVLMs) have been widely adopted for medical report generation. Despite Med-LVLMs producing state-of-the-art performance, they exhibit a bias toward predicting all findings as normal, leading to reports that overlook critical abnormalities. Furthermore, these models often fail to provide comprehensive descriptions of radiologically relevant regions necessary for accurate diagnosis. To address these challenges, we proposeMedical Report Generation Agents (MRGAgents), a novel multi-agent framework that fine-tunes specialized agents for different disease categories. By curating subsets of the IU X-ray and MIMIC-CXR datasets to train disease-specific agents, MRGAgents generates reports that more effectively balance normal and abnormal findings while ensuring a comprehensive description of clinically relevant regions. Our experiments demonstrate that MRGAgents outperformed the state-of-the-art, improving both report comprehensiveness and diagnostic utility.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": "10pages", "pdf_url": "https://arxiv.org/pdf/2505.18530.pdf", "abstract_url": "https://arxiv.org/abs/2505.18530", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.18572", "title": "MASTER: Multi-Agent Security Through Exploration of Roles and Topological Structures -- A Comprehensive Framework", "authors": ["Yifan Zhu", "Chao Zhang", "Xin Shi", "Xueqiao Zhang", "Yi Yang", "Yawei Luo"], "abstract": "Large Language Models (LLMs)-based Multi-Agent Systems (MAS) exhibit remarkable problem-solving and task planning capabilities across diverse domains due to their specialized agentic roles and collaborative interactions. However, this also amplifies the severity of security risks under MAS attacks. To address this, we introduce MASTER, a novel security research framework for MAS, focusing on diverse Role configurations and Topological structures across various scenarios. MASTER offers an automated construction process for different MAS setups and an information-flow-based interaction paradigm. To tackle MAS security challenges in varied scenarios, we design a scenario-adaptive, extensible attack strategy utilizing role and topological information, which dynamically allocates targeted, domain-specific attack tasks for collaborative agent execution. Our experiments demonstrate that such an attack, leveraging role and topological information, exhibits significant destructive potential across most models. Additionally, we propose corresponding defense strategies, substantially enhancing MAS resilience across diverse scenarios. We anticipate that our framework and findings will provide valuable insights for future research into MAS security challenges.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18572.pdf", "abstract_url": "https://arxiv.org/abs/2505.18572", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"]}
{"id": "2505.20184", "title": "THiNK: Can Large Language Models Think-aloud?", "authors": ["Yongan Yu", "Mengqian Wu", "Yiran Lin", "Nikki G. Lobczowski"], "abstract": "Assessing higher-order thinking skills in large language models (LLMs) remains a fundamental challenge, especially in tasks that go beyond surface-level accuracy. In this work, we propose THiNK (Testing Higher-order Notion of Knowledge), a multi-agent, feedback-driven evaluation framework grounded in Bloom's Taxonomy. THiNK frames reasoning assessment as an iterative task of problem generation, critique, and revision, encouraging LLMs to think-aloud through step-by-step reflection and refinement. This enables a systematic evaluation of both lower-order (e.g., remember, understand) and higher-order (e.g., evaluate, create) thinking skills. We apply THiNK to seven state-of-the-art LLMs and perform a detailed cognitive analysis of their outputs. Results reveal that while models reliably perform lower-order categories well, they struggle with applying knowledge in realistic contexts and exhibit limited abstraction. Structured feedback loops significantly improve reasoning performance, particularly in higher-order thinking. Qualitative evaluations further confirm that THiNK-guided outputs better align with domain logic and problem structure. The code of our framework provides a scalable methodology for probing and enhancing LLM reasoning, offering new directions for evaluation grounded in learning science, which is available at our GitHub repository.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.20184.pdf", "abstract_url": "https://arxiv.org/abs/2505.20184", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.20201", "title": "Reasoning Is Not All You Need: Examining LLMs for Multi-Turn Mental Health Conversations", "authors": ["Mohit Chandra", "Siddharth Sriraman", "Harneet Singh Khanuja", "Yiqiao Jin", "Munmun De Choudhury"], "abstract": "Limited access to mental healthcare, extended wait times, and increasing capabilities of Large Language Models (LLMs) has led individuals to turn to LLMs for fulfilling their mental health needs. However, examining the multi-turn mental health conversation capabilities of LLMs remains under-explored. Existing evaluation frameworks typically focus on diagnostic accuracy and win-rates and often overlook alignment with patient-specific goals, values, and personalities required for meaningful conversations. To address this, we introduce MedAgent, a novel framework for synthetically generating realistic, multi-turn mental health sensemaking conversations and use it to create the Mental Health Sensemaking Dialogue (MHSD) dataset, comprising over 2,200 patient-LLM conversations. Additionally, we present MultiSenseEval, a holistic framework to evaluate the multi-turn conversation abilities of LLMs in healthcare settings using human-centric criteria. Our findings reveal that frontier reasoning models yield below-par performance for patient-centric communication and struggle at advanced diagnostic capabilities with average score of 31%. Additionally, we observed variation in model performance based on patient's persona and performance drop with increasing turns in the conversation. Our work provides a comprehensive synthetic data generation framework, a dataset and evaluation framework for assessing LLMs in multi-turn mental health conversations.", "subjects": "Computation and Language (cs.CL)", "comments": "33 pages, 5 figures, 30 tables", "pdf_url": "https://arxiv.org/pdf/2505.20201.pdf", "abstract_url": "https://arxiv.org/abs/2505.20201", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2505.20243", "title": "It's High Time: A Survey of Temporal Information Retrieval and Question Answering", "authors": ["Bhawna Piryani", "Abdelrahman Abdullah", "Jamshid Mozafari", "Avishek Anand", "Adam Jatowt"], "abstract": "Time plays a critical role in how information is generated, retrieved, and interpreted. In this survey, we provide a comprehensive overview of Temporal Information Retrieval and Temporal Question Answering, two research areas aimed at handling and understanding time-sensitive information. As the amount of time-stamped content from sources like news articles, web archives, and knowledge bases increases, systems must address challenges such as detecting temporal intent, normalizing time expressions, ordering events, and reasoning over evolving or ambiguous facts. These challenges are critical across many dynamic and time-sensitive domains, from news and encyclopedias to science, history, and social media. We review both traditional approaches and modern neural methods, including those that use transformer models and Large Language Models (LLMs). We also review recent advances in temporal language modeling, multi-hop reasoning, and retrieval-augmented generation (RAG), alongside benchmark datasets and evaluation strategies that test temporal robustness, recency awareness, and generalization.", "subjects": "Computation and Language (cs.CL); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.20243.pdf", "abstract_url": "https://arxiv.org/abs/2505.20243", "categories": ["Computation and Language (cs.CL)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"]}
{"id": "2505.20245", "title": "KnowTrace: Bootstrapping Iterative Retrieval-Augmented Generation with Structured Knowledge Tracing", "authors": ["Rui Li", "Quanyu Dai", "Zeyu Zhang", "Xu Chen", "Zhenhua Dong", "Ji-Rong Wen"], "abstract": "Recent advances in retrieval-augmented generation (RAG) furnish large language models (LLMs) with iterative retrievals of relevant information to handle complex multi-hop questions. These methods typically alternate between LLM reasoning and retrieval to accumulate external information into the LLM's context. However, the ever-growing context inherently imposes an increasing burden on the LLM to perceive connections among critical information pieces, with futile reasoning steps further exacerbating this overload issue. In this paper, we present KnowTrace, an elegant RAG framework to (1) mitigate the context overload and (2) bootstrap higher-quality multi-step reasoning. Instead of simply piling the retrieved contents, KnowTrace autonomously traces out desired knowledge triplets to organize a specific knowledge graph relevant to the input question. Such a structured workflow not only empowers the LLM with an intelligible context for inference, but also naturally inspires a reflective mechanism of knowledge backtracing to identify contributive LLM generations as process supervision data for self-bootstrapping. Extensive experiments show that KnowTrace consistently surpasses existing methods across three multi-hop question answering benchmarks, and the bootstrapped version further amplifies the gains.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "Accepted by KDD 2025", "pdf_url": "https://arxiv.org/pdf/2505.20245.pdf", "abstract_url": "https://arxiv.org/abs/2505.20245", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"]}
{"id": "2505.18595", "title": "MisoDICE: Multi-Agent Imitation from Unlabeled Mixed-Quality Demonstrations", "authors": ["Viet Bui", "Tien Mai", "Hong Thanh Nguyen"], "abstract": "We study offline imitation learning (IL) in cooperative multi-agent settings, where demonstrations have unlabeled mixed quality - containing both expert and suboptimal trajectories. Our proposed solution is structured in two stages: trajectory labeling and multi-agent imitation learning, designed jointly to enable effective learning from heterogeneous, unlabeled data. In the first stage, we combine advances in large language models and preference-based reinforcement learning to construct a progressive labeling pipeline that distinguishes expert-quality trajectories. In the second stage, we introduce MisoDICE, a novel multi-agent IL algorithm that leverages these labels to learn robust policies while addressing the computational complexity of large joint state-action spaces. By extending the popular single-agent DICE framework to multi-agent settings with a new value decomposition and mixing architecture, our method yields a convex policy optimization objective and ensures consistency between global and local policies. We evaluate MisoDICE on multiple standard multi-agent RL benchmarks and demonstrate superior performance, especially when expert data is scarce.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18595.pdf", "abstract_url": "https://arxiv.org/abs/2505.18595", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"]}
{"id": "2505.18646", "title": "SEW: Self-Evolving Agentic Workflows for Automated Code Generation", "authors": ["Siwei Liu", "Jinyuan Fang", "Han Zhou", "Yingxu Wang", "Zaiqiao Meng"], "abstract": "Large Language Models (LLMs) have demonstrated effectiveness in code generation tasks. To enable LLMs to address more complex coding challenges, existing research has focused on crafting multi-agent systems with agentic workflows, where complex coding tasks are decomposed into sub-tasks, assigned to specialized agents. Despite their effectiveness, current approaches heavily rely on hand-crafted agentic workflows, with both agent topologies and prompts manually designed, which limits their ability to automatically adapt to different types of coding problems. To address these limitations and enable automated workflow design, we propose \\textbf{S}elf-\\textbf{E}volving \\textbf{W}orkflow (\\textbf{SEW}), a novel self-evolving framework that automatically generates and optimises multi-agent workflows. Extensive experiments on three coding benchmark datasets, including the challenging LiveCodeBench, demonstrate that our SEW can automatically design agentic workflows and optimise them through self-evolution, bringing up to 33\\% improvement on LiveCodeBench compared to using the backbone LLM only. Furthermore, by investigating different representation schemes of workflow, we provide insights into the optimal way to encode workflow information with text.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "16 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2505.18646.pdf", "abstract_url": "https://arxiv.org/abs/2505.18646", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"]}
{"id": "2505.20277", "title": "OmniCharacter: Towards Immersive Role-Playing Agents with Seamless Speech-Language Personality Interaction", "authors": ["Haonan Zhang", "Run Luo", "Xiong Liu", "Yuchuan Wu", "Ting-En Lin", "Pengpeng Zeng", "Qiang Qu", "Feiteng Fang", "Min Yang", "Lianli Gao", "Jingkuan Song", "Fei Huang", "Yongbin Li"], "abstract": "Role-Playing Agents (RPAs), benefiting from large language models, is an emerging interactive AI system that simulates roles or characters with diverse personalities. However, existing methods primarily focus on mimicking dialogues among roles in textual form, neglecting the role's voice traits (e.g., voice style and emotions) as playing a crucial effect in interaction, which tends to be more immersive experiences in realistic scenarios. Towards this goal, we propose OmniCharacter, a first seamless speech-language personality interaction model to achieve immersive RPAs with low latency. Specifically, OmniCharacter enables agents to consistently exhibit role-specific personality traits and vocal traits throughout the interaction, enabling a mixture of speech and language responses. To align the model with speech-language scenarios, we construct a dataset named OmniCharacter-10K, which involves more distinctive characters (20), richly contextualized multi-round dialogue (10K), and dynamic speech response (135K). Experimental results showcase that our method yields better responses in terms of both content and style compared to existing RPAs and mainstream speech-language models, with a response latency as low as 289ms. Code and dataset are available at", "subjects": "Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)", "comments": "14 pages, 6 figures", "pdf_url": "https://arxiv.org/pdf/2505.20277.pdf", "abstract_url": "https://arxiv.org/abs/2505.20277", "categories": ["Computation and Language (cs.CL)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"]}
{"id": "2505.20285", "title": "MASKSEARCH: A Universal Pre-Training Framework to Enhance Agentic Search Capability", "authors": ["Weiqi Wu", "Xin Guan", "Shen Huang", "Yong Jiang", "Pengjun Xie", "Fei Huang", "Jiuxin Cao", "Hai Zhao", "Jingren Zhou"], "abstract": "Retrieval-Augmented Language Models (RALMs) represent a classic paradigm where models enhance generative capabilities using external knowledge retrieved via a specialized module. Recent advancements in Agent techniques enable Large Language Models (LLMs) to autonomously utilize tools for retrieval, planning, and reasoning. While existing training-based methods show promise, their agentic abilities are limited by inherent characteristics of the task-specific data used during training. To further enhance the universal search capability of agents, we propose a novel pre-training framework, MASKSEARCH. In the pre-training stage, we introduce the Retrieval Augmented Mask Prediction (RAMP) task, where the model learns to leverage search tools to fill masked spans on a large number of pre-training data, thus acquiring universal retrieval and reasoning capabilities for LLMs. After that, the model is trained on downstream tasks to achieve further improvement. We apply both Supervised Fine-tuning (SFT) and Reinforcement Learning (RL) for training. For SFT, we combine agent-based and distillation-based methods to generate training data, starting with a multi-agent system consisting of a planner, rewriter, observer, and followed by a self-evolving teacher model. While for RL, we employ DAPO as the training framework and adopt a hybrid reward system consisting of answer rewards and format rewards. Additionally, we introduce a curriculum learning approach that allows the model to learn progressively from easier to more challenging instances based on the number of masked spans. We evaluate the effectiveness of our framework in the scenario of open-domain multi-hop question answering. Through extensive experiments, we demonstrate that MASKSEARCH significantly enhances the performance of LLM-based search agents on both in-domain and out-of-domain downstream tasks.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.20285.pdf", "abstract_url": "https://arxiv.org/abs/2505.20285", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"]}
{"id": "2505.16849", "title": "Walk&Retrieve: Simple Yet Effective Zero-shot Retrieval-Augmented Generation via Knowledge Graph Walks", "authors": ["Martin BÃ¶ckling", "Heiko Paulheim", "Andreea Iana"], "abstract": "Large Language Models (LLMs) have showcased impressive reasoning abilities, but often suffer from hallucinations or outdated knowledge. Knowledge Graph (KG)-based Retrieval-Augmented Generation (RAG) remedies these shortcomings by grounding LLM responses in structured external information from a knowledge base. However, many KG-based RAG approaches struggle with (i) aligning KG and textual representations, (ii) balancing retrieval accuracy and efficiency, and (iii) adapting to dynamically updated KGs. In this work, we introduce Walk&Retrieve, a simple yet effective KG-based framework that leverages walk-based graph traversal and knowledge verbalization for corpus generation for zero-shot RAG. Built around efficient KG walks, our method does not require fine-tuning on domain-specific data, enabling seamless adaptation to KG updates, reducing computational overhead, and allowing integration with any off-the-shelf backbone LLM. Despite its simplicity, Walk&Retrieve performs competitively, often outperforming existing RAG systems in response accuracy and hallucination reduction. Moreover, it demonstrates lower query latency and robust scalability to large KGs, highlighting the potential of lightweight retrieval strategies as strong baselines for future RAG research.", "subjects": "Information Retrieval (cs.IR); Computation and Language (cs.CL)", "comments": "Accepted at the Information Retrieval's Role in RAG Systems (IR-RAG 2025) in conjunction with SIGIR 2025", "pdf_url": "https://arxiv.org/pdf/2505.16849.pdf", "abstract_url": "https://arxiv.org/abs/2505.16849", "categories": ["Information Retrieval (cs.IR)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"]}
{"id": "2505.18710", "title": "GainRAG: Preference Alignment in Retrieval-Augmented Generation through Gain Signal Synthesis", "authors": ["Yi Jiang", "Sendong Zhao", "Jianbo Li", "Haochun Wang", "Bing Qin"], "abstract": "The Retrieval-Augmented Generation (RAG) framework introduces a retrieval module to dynamically inject retrieved information into the input context of large language models (LLMs), and has demonstrated significant success in various NLP tasks. However, the current study points out that there is a preference gap between retrievers and LLMs in the RAG framework, which limit the further improvement of system performance. Some highly relevant passages may interfere with LLM reasoning because they contain complex or contradictory information; while some indirectly related or even inaccurate content may help LLM generate more accurate answers by providing suggestive information or logical clues. To solve this, we propose GainRAG, a novel approach that aligns the retriever's and LLM's preferences by defining a new metric, \"gain\", which measure how well an input passage contributes to correct outputs. Specifically, we propose a method to estimate these gain signals and train a middleware that aligns the preferences of the retriever and the LLM using only limited data. In addition, we introduce a pseudo-passage strategy to mitigate degradation. The experimental results on 6 datasets verify the effectiveness of GainRAG.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "comments": "Accepted by ACL 2025", "pdf_url": "https://arxiv.org/pdf/2505.18710.pdf", "abstract_url": "https://arxiv.org/abs/2505.18710", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"]}
{"id": "2505.18750", "title": "Agent-Based Decentralized Energy Management of EV Charging Station with Solar Photovoltaics via Multi-Agent Reinforcement Learning", "authors": ["Jiarong Fan", "Chenghao Huang", "Hao Wang"], "abstract": "In the pursuit of energy net zero within smart cities, transportation electrification plays a pivotal role. The adoption of Electric Vehicles (EVs) keeps increasing, making energy management of EV charging stations critically important. While previous studies have managed to reduce energy cost of EV charging while maintaining grid stability, they often overlook the robustness of EV charging management against uncertainties of various forms, such as varying charging behaviors and possible faults in faults in some chargers. To address the gap, a novel Multi-Agent Reinforcement Learning (MARL) approach is proposed treating each charger to be an agent and coordinate all the agents in the EV charging station with solar photovoltaics in a more realistic scenario, where system faults may occur. A Long Short-Term Memory (LSTM) network is incorporated in the MARL algorithm to extract temporal features from time-series. Additionally, a dense reward mechanism is designed for training the agents in the MARL algorithm to improve EV charging experience. Through validation on a real-world dataset, we show that our approach is robust against system uncertainties and faults and also effective in minimizing EV charging costs and maximizing charging service satisfaction.", "subjects": "Systems and Control (eess.SY); Artificial Intelligence (cs.AI); Optimization and Control (math.OC)", "comments": "2024 IEEE International Smart Cities Conference (ISC2)", "pdf_url": "https://arxiv.org/pdf/2505.18750.pdf", "abstract_url": "https://arxiv.org/abs/2505.18750", "categories": ["Systems and Control (eess.SY)", "Artificial Intelligence (cs.AI)", "Optimization and Control (math.OC)"], "matching_keywords": ["agent"]}
{"id": "2505.18889", "title": "Security Concerns for Large Language Models: A Survey", "authors": ["Miles Q. Li", "Benjamin C. M. Fung"], "abstract": "Large Language Models (LLMs) such as GPT-4 (and its recent iterations like GPT-4o and the GPT-4.1 series), Google's Gemini, Anthropic's Claude 3 models, and xAI's Grok have caused a revolution in natural language processing, but their capabilities also introduce new security vulnerabilities. In this survey, we provide a comprehensive overview of the emerging security concerns around LLMs, categorizing threats into prompt injection and jailbreaking, adversarial attacks (including input perturbations and data poisoning), misuse by malicious actors (e.g., for disinformation, phishing, and malware generation), and worrisome risks inherent in autonomous LLM agents. A significant focus has been recently placed on the latter, exploring goal misalignment, emergent deception, self-preservation instincts, and the potential for LLMs to develop and pursue covert, misaligned objectives (scheming), which may even persist through safety training. We summarize recent academic and industrial studies (2022-2025) that exemplify each threat, analyze proposed defenses and their limitations, and identify open challenges in securing LLM-based applications. We conclude by emphasizing the importance of advancing robust, multi-layered security strategies to ensure LLMs are safe and beneficial.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.18889.pdf", "abstract_url": "https://arxiv.org/abs/2505.18889", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.19443", "title": "Vibe Coding vs. Agentic Coding: Fundamentals and Practical Implications of Agentic AI", "authors": ["Ranjan Sapkota", "Konstantinos I. Roumeliotis", "Manoj Karkee"], "abstract": "This review presents a comprehensive analysis of two emerging paradigms in AI-assisted software development: vibe coding and agentic coding. While both leverage large language models (LLMs), they differ fundamentally in autonomy, architectural design, and the role of the developer. Vibe coding emphasizes intuitive, human-in-the-loop interaction through prompt-based, conversational workflows that support ideation, experimentation, and creative exploration. In contrast, agentic coding enables autonomous software development through goal-driven agents capable of planning, executing, testing, and iterating tasks with minimal human intervention. We propose a detailed taxonomy spanning conceptual foundations, execution models, feedback loops, safety mechanisms, debugging strategies, and real-world tool ecosystems. Through comparative workflow analysis and 20 detailed use cases, we illustrate how vibe systems thrive in early-stage prototyping and education, while agentic systems excel in enterprise-grade automation, codebase refactoring, and CI/CD integration. We further examine emerging trends in hybrid architectures, where natural language interfaces are coupled with autonomous execution pipelines. Finally, we articulate a future roadmap for agentic AI, outlining the infrastructure needed for trustworthy, explainable, and collaborative systems. Our findings suggest that successful AI software engineering will rely not on choosing one paradigm, but on harmonizing their strengths within a unified, human-centered development lifecycle.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "35 Pages, 8 Figures, 6 Tables", "pdf_url": "https://arxiv.org/pdf/2505.19443.pdf", "abstract_url": "https://arxiv.org/abs/2505.19443", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"]}
{"id": "2505.19955", "title": "MLR-Bench: Evaluating AI Agents on Open-Ended Machine Learning Research", "authors": ["Hui Chen", "Miao Xiong", "Yujie Lu", "Wei Han", "Ailin Deng", "Yufei He", "Jiaying Wu", "Yibo Li", "Yue Liu", "Bryan Hooi"], "abstract": "Recent advancements in AI agents have demonstrated their growing potential to drive and support scientific discovery. In this work, we introduce MLR-Bench, a comprehensive benchmark for evaluating AI agents on open-ended machine learning research. MLR-Bench includes three key components: (1) 201 research tasks sourced from NeurIPS, ICLR, and ICML workshops covering diverse ML topics; (2) MLR-Judge, an automated evaluation framework combining LLM-based reviewers with carefully designed review rubrics to assess research quality; and (3) MLR-Agent, a modular agent scaffold capable of completing research tasks through four stages: idea generation, proposal formulation, experimentation, and paper writing. Our framework supports both stepwise assessment across these distinct research stages, and end-to-end evaluation of the final research paper. We then use MLR-Bench to evaluate six frontier LLMs and an advanced coding agent, finding that while LLMs are effective at generating coherent ideas and well-structured papers, current coding agents frequently (e.g., in 80% of the cases) produce fabricated or invalidated experimental results--posing a major barrier to scientific reliability. We validate MLR-Judge through human evaluation, showing high agreement with expert reviewers, supporting its potential as a scalable tool for research evaluation. We open-source MLR-Bench to help the community benchmark, diagnose, and improve AI research agents toward trustworthy and transparent scientific discovery.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "40 pages, 7 figures", "pdf_url": "https://arxiv.org/pdf/2505.19955.pdf", "abstract_url": "https://arxiv.org/abs/2505.19955", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2505.19997", "title": "Embracing Imperfection: Simulating Students with Diverse Cognitive Levels Using LLM-based Agents", "authors": ["Tao Wu", "Jingyuan Chen", "Wang Lin", "Mengze Li", "Yumeng Zhu", "Ang Li", "Kun Kuang", "Fei Wu"], "abstract": "Large language models (LLMs) are revolutionizing education, with LLM-based agents playing a key role in simulating student behavior. A major challenge in student simulation is modeling the diverse learning patterns of students at various cognitive levels. However, current LLMs, typically trained as ``helpful assistants'', target at generating perfect responses. As a result, they struggle to simulate students with diverse cognitive abilities, as they often produce overly advanced answers, missing the natural imperfections that characterize student learning and resulting in unrealistic simulations. To address this issue, we propose a training-free framework for student simulation. We begin by constructing a cognitive prototype for each student using a knowledge graph, which captures their understanding of concepts from past learning records. This prototype is then mapped to new tasks to predict student performance. Next, we simulate student solutions based on these predictions and iteratively refine them using a beam search method to better replicate realistic mistakes. To validate our approach, we construct the \\texttt{Student\\_100} dataset, consisting of $100$ students working on Python programming and $5,000$ learning records. Experimental results show that our method consistently outperforms baseline models, achieving $100\\%$ improvement in simulation accuracy.", "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL); Computers and Society (cs.CY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19997.pdf", "abstract_url": "https://arxiv.org/abs/2505.19997", "categories": ["Machine Learning (cs.LG)", "Computation and Language (cs.CL)", "Computers and Society (cs.CY)"], "matching_keywords": ["agent"]}
{"id": "2505.20046", "title": "REARANK: Reasoning Re-ranking Agent via Reinforcement Learning", "authors": ["Le Zhang", "Bo Wang", "Xipeng Qiu", "Siva Reddy", "Aishwarya Agrawal"], "abstract": "We present REARANK, a large language model (LLM)-based listwise reasoning reranking agent. REARANK explicitly reasons before reranking, significantly improving both performance and interpretability. Leveraging reinforcement learning and data augmentation, REARANK achieves substantial improvements over baseline models across popular information retrieval benchmarks, notably requiring only 179 annotated samples. Built on top of Qwen2.5-7B, our REARANK-7B demonstrates performance comparable to GPT-4 on both in-domain and out-of-domain benchmarks and even surpasses GPT-4 on reasoning-intensive BRIGHT benchmarks. These results underscore the effectiveness of our approach and highlight how reinforcement learning can enhance LLM reasoning capabilities in reranking.", "subjects": "Information Retrieval (cs.IR); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.20046.pdf", "abstract_url": "https://arxiv.org/abs/2505.20046", "categories": ["Information Retrieval (cs.IR)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2505.19205", "title": "OptiMindTune: A Multi-Agent Framework for Intelligent Hyperparameter Optimization", "authors": ["Meher Bhaskar Madiraju", "Meher Sai Preetam Madiraju"], "abstract": "Hyperparameter optimization (HPO) is a critical yet challenging aspect of machine learning model development, significantly impacting model performance and generalization. Traditional HPO methods often struggle with high dimensionality, complex interdependencies, and computational expense. This paper introduces OptiMindTune, a novel multi-agent framework designed to intelligently and efficiently optimize hyperparameters. OptiMindTune leverages the collaborative intelligence of three specialized AI agents -- a Recommender Agent, an Evaluator Agent, and a Decision Agent -- each powered by Google's Gemini models. These agents address distinct facets of the HPO problem, from model selection and hyperparameter suggestion to robust evaluation and strategic decision-making. By fostering dynamic interactions and knowledge sharing, OptiMindTune aims to converge to optimal hyperparameter configurations more rapidly and robustly than existing single-agent or monolithic approaches. Our framework integrates principles from advanced large language models, and adaptive search to achieve scalable and intelligent AutoML. We posit that this multi-agent paradigm offers a promising avenue for tackling the increasing complexity of modern machine learning model tuning.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "7 pages, 2 tables", "pdf_url": "https://arxiv.org/pdf/2505.19205.pdf", "abstract_url": "https://arxiv.org/abs/2505.19205", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"]}
{"id": "2505.19238", "title": "Efficient Policy Optimization in Robust Constrained MDPs with Iteration Complexity Guarantees", "authors": ["Sourav Ganguly", "Arnob Ghosh", "Kishan Panaganti", "Adam Wierman"], "abstract": "Constrained decision-making is essential for designing safe policies in real-world control systems, yet simulated environments often fail to capture real-world adversities. We consider the problem of learning a policy that will maximize the cumulative reward while satisfying a constraint, even when there is a mismatch between the real model and an accessible simulator/nominal model. In particular, we consider the robust constrained Markov decision problem (RCMDP) where an agent needs to maximize the reward and satisfy the constraint against the worst possible stochastic model under the uncertainty set centered around an unknown nominal model. Primal-dual methods, effective for standard constrained MDP (CMDP), are not applicable here because of the lack of the strong duality property. Further, one cannot apply the standard robust value-iteration based approach on the composite value function either as the worst case models may be different for the reward value function and the constraint value function. We propose a novel technique that effectively minimizes the constraint value function--to satisfy the constraints; on the other hand, when all the constraints are satisfied, it can simply maximize the robust reward value function. We prove that such an algorithm finds a policy with at most $\\epsilon$ sub-optimality and feasible policy after $O(\\epsilon^{-2})$ iterations. In contrast to the state-of-the-art method, we do not need to employ a binary search, thus, we reduce the computation time by at least 4x for smaller value of discount factor ($\\gamma$) and by at least 6x for larger value of $\\gamma$.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Robotics (cs.RO); Systems and Control (eess.SY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19238.pdf", "abstract_url": "https://arxiv.org/abs/2505.19238", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Robotics (cs.RO)", "Systems and Control (eess.SY)"], "matching_keywords": ["agent"]}
{"id": "2505.19301", "title": "A Novel Zero-Trust Identity Framework for Agentic AI: Decentralized Authentication and Fine-Grained Access Control", "authors": ["Ken Huang", "Vineeth Sai Narajala", "John Yeoh", "Ramesh Raskar", "Youssef Harkati", "Jerry Huang", "Idan Habler", "Chris Hughes"], "abstract": "Traditional Identity and Access Management (IAM) systems, primarily designed for human users or static machine identities via protocols such as OAuth, OpenID Connect (OIDC), and SAML, prove fundamentally inadequate for the dynamic, interdependent, and often ephemeral nature of AI agents operating at scale within Multi Agent Systems (MAS), a computational system composed of multiple interacting intelligent agents that work collectively.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "24 Pages, 5 figures, 2 tables", "pdf_url": "https://arxiv.org/pdf/2505.19301.pdf", "abstract_url": "https://arxiv.org/abs/2505.19301", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"]}
{"id": "2505.19310", "title": "Retrieval-Augmented Generation for Service Discovery: Chunking Strategies and Benchmarking", "authors": ["Robin D. Pesl", "Jerin G. Mathew", "Massimo Mecella", "Marco Aiello"], "abstract": "Integrating multiple (sub-)systems is essential to create advanced Information Systems. Difficulties mainly arise when integrating dynamic environments, e.g., the integration at design time of not yet existing services. This has been traditionally addressed using a registry that provides the API documentation of the endpoints. Large Language Models have shown to be capable of automatically creating system integrations (e.g., as service composition) based on this documentation but require concise input due to input oken limitations, especially regarding comprehensive API descriptions. Currently, it is unknown how best to preprocess these API descriptions. In the present work, we (i) analyze the usage of Retrieval Augmented Generation for endpoint discovery and the chunking, i.e., preprocessing, of state-of-practice OpenAPIs to reduce the input oken length while preserving the most relevant information. To further reduce the input token length for the composition prompt and improve endpoint retrieval, we propose (ii) a Discovery Agent that only receives a summary of the most relevant endpoints nd retrieves specification details on demand. We evaluate RAG for endpoint discovery using (iii) a proposed novel service discovery benchmark SOCBench-D representing a general setting across numerous domains and the real-world RestBench enchmark, first, for the different chunking possibilities and parameters measuring the endpoint retrieval accuracy. Then, we assess the Discovery Agent using the same test data set. The prototype shows how to successfully employ RAG for endpoint discovery to reduce the token count. Our experiments show that endpoint-based approaches outperform naive chunking methods for preprocessing. Relying on an agent significantly improves precision while being prone to decrease recall, disclosing the need for further reasoning capabilities.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.19310.pdf", "abstract_url": "https://arxiv.org/abs/2505.19310", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "@RAG"]}
{"id": "2505.19337", "title": "Prompting Decision Transformers for Zero-Shot Reach-Avoid Policies", "authors": ["Kevin Li", "Marinka Zitnik"], "abstract": "Offline goal-conditioned reinforcement learning methods have shown promise for reach-avoid tasks, where an agent must reach a target state while avoiding undesirable regions of the state space. Existing approaches typically encode avoid-region information into an augmented state space and cost function, which prevents flexible, dynamic specification of novel avoid-region information at evaluation time. They also rely heavily on well-designed reward and cost functions, limiting scalability to complex or poorly structured environments. We introduce RADT, a decision transformer model for offline, reward-free, goal-conditioned, avoid region-conditioned RL. RADT encodes goals and avoid regions directly as prompt tokens, allowing any number of avoid regions of arbitrary size to be specified at evaluation time. Using only suboptimal offline trajectories from a random policy, RADT learns reach-avoid behavior through a novel combination of goal and avoid-region hindsight relabeling. We benchmark RADT against 3 existing offline goal-conditioned RL models across 11 tasks, environments, and experimental settings. RADT generalizes in a zero-shot manner to out-of-distribution avoid region sizes and counts, outperforming baselines that require retraining. In one such zero-shot setting, RADT achieves 35.7% improvement in normalized cost over the best retrained baseline while maintaining high goal-reaching success. We apply RADT to cell reprogramming in biology, where it reduces visits to undesirable intermediate gene expression states during trajectories to desired target states, despite stochastic transitions and discrete, structured state dynamics.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Quantitative Methods (q-bio.QM)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19337.pdf", "abstract_url": "https://arxiv.org/abs/2505.19337", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Quantitative Methods (q-bio.QM)"], "matching_keywords": ["agent"]}
{"id": "2505.19481", "title": "Win Fast or Lose Slow: Balancing Speed and Accuracy in Latency-Sensitive Decisions of LLMs", "authors": ["Hao Kang", "Qingru Zhang", "Han Cai", "Weiyuan Xu", "Tushar Krishna", "Yilun Du", "Tsachy Weissman"], "abstract": "Large language models (LLMs) have shown remarkable performance across diverse reasoning and generation tasks, and are increasingly deployed as agents in dynamic environments such as code generation and recommendation systems. However, many real-world applications, such as high-frequency trading and real-time competitive gaming, require decisions under strict latency constraints, where faster responses directly translate into higher rewards. Despite the importance of this latency quality trade off, it remains underexplored in the context of LLM based agents. In this work, we present the first systematic study of this trade off in real time decision making tasks. To support our investigation, we introduce two new benchmarks: HFTBench, a high frequency trading simulation, and StreetFighter, a competitive gaming platform. Our analysis reveals that optimal latency quality balance varies by task, and that sacrificing quality for lower latency can significantly enhance downstream performance. To address this, we propose FPX, an adaptive framework that dynamically selects model size and quantization level based on real time demands. Our method achieves the best performance on both benchmarks, improving win rate by up to 80% in Street Fighter and boosting daily yield by up to 26.52% in trading, underscoring the need for latency aware evaluation and deployment strategies for LLM based agents. These results demonstrate the critical importance of latency aware evaluation and deployment strategies for real world LLM based agents. Our benchmarks are available at Latency Sensitive Benchmarks.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19481.pdf", "abstract_url": "https://arxiv.org/abs/2505.19481", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Distributed, Parallel, and Cluster Computing (cs.DC)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"]}
{"id": "2505.19509", "title": "Benchmarking Multimodal Knowledge Conflict for Large Multimodal Models", "authors": ["Yifan Jia", "Kailin Jiang", "Yuyang Liang", "Qihan Ren", "Yi Xin", "Rui Yang", "Fenze Feng", "Mingcai Chen", "Hengyang Lu", "Haozhe Wang", "Xiaoye Qu", "Dongrui Liu", "Lizhen Cui", "Yuntao Du"], "abstract": "Large Multimodal Models(LMMs) face notable challenges when encountering multimodal knowledge conflicts, particularly under retrieval-augmented generation(RAG) frameworks where the contextual information from external sources may contradict the model's internal parametric knowledge, leading to unreliable outputs. However, existing benchmarks fail to reflect such realistic conflict scenarios. Most focus solely on intra-memory conflicts, while context-memory and inter-context conflicts remain largely investigated. Furthermore, commonly used factual knowledge-based evaluations are often overlooked, and existing datasets lack a thorough investigation into conflict detection capabilities. To bridge this gap, we propose MMKC-Bench, a benchmark designed to evaluate factual knowledge conflicts in both context-memory and inter-context scenarios. MMKC-Bench encompasses three types of multimodal knowledge conflicts and includes 1,573 knowledge instances and 3,381 images across 23 broad types, collected through automated pipelines with human verification. We evaluate three representative series of LMMs on both model behavior analysis and conflict detection tasks. Our findings show that while current LMMs are capable of recognizing knowledge conflicts, they tend to favor internal parametric knowledge over external evidence. We hope MMKC-Bench will foster further research in multimodal knowledge conflict and enhance the development of multimodal RAG systems. The source code is available at", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.19509.pdf", "abstract_url": "https://arxiv.org/abs/2505.19509", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"]}
{"id": "2505.19623", "title": "AgentRecBench: Benchmarking LLM Agent-based Personalized Recommender Systems", "authors": ["Yu Shang", "Peijie Liu", "Yuwei Yan", "Zijing Wu", "Leheng Sheng", "Yuanqing Yu", "Chumeng Jiang", "An Zhang", "Fengli Xu", "Yu Wang", "Min Zhang", "Yong Li"], "abstract": "The emergence of agentic recommender systems powered by Large Language Models (LLMs) represents a paradigm shift in personalized recommendations, leveraging LLMs' advanced reasoning and role-playing capabilities to enable autonomous, adaptive decision-making. Unlike traditional recommendation approaches, agentic recommender systems can dynamically gather and interpret user-item interactions from complex environments, generating robust recommendation strategies that generalize across diverse scenarios. However, the field currently lacks standardized evaluation protocols to systematically assess these methods. To address this critical gap, we propose: (1) an interactive textual recommendation simulator incorporating rich user and item metadata and three typical evaluation scenarios (classic, evolving-interest, and cold-start recommendation tasks); (2) a unified modular framework for developing and studying agentic recommender systems; and (3) the first comprehensive benchmark comparing 10 classical and agentic recommendation methods. Our findings demonstrate the superiority of agentic systems and establish actionable design guidelines for their core components. The benchmark environment has been rigorously validated through an open challenge and remains publicly available with a continuously maintained leaderboard~\\footnote[2]{", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "comments": "15 pages, 6 figures", "pdf_url": "https://arxiv.org/pdf/2505.19623.pdf", "abstract_url": "https://arxiv.org/abs/2505.19623", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"]}
{"id": "2505.19698", "title": "JEDI: Latent End-to-end Diffusion Mitigates Agent-Human Performance Asymmetry in Model-Based Reinforcement Learning", "authors": ["Jing Yu Lim", "Zarif Ikram", "Samson Yu", "Haozhe Ma", "Tze-Yun Leong", "Dianbo Liu"], "abstract": "Recent advances in model-based reinforcement learning (MBRL) have achieved super-human level performance on the Atari100k benchmark, driven by reinforcement learning agents trained on powerful diffusion world models. However, we identify that the current aggregates mask a major performance asymmetry: MBRL agents dramatically outperform humans in some tasks despite drastically underperforming in others, with the former inflating the aggregate metrics. This is especially pronounced in pixel-based agents trained with diffusion world models. In this work, we address the pronounced asymmetry observed in pixel-based agents as an initial attempt to reverse the worrying upward trend observed in them. We address the problematic aggregates by delineating all tasks as Agent-Optimal or Human-Optimal and advocate for equal importance on metrics from both sets. Next, we hypothesize this pronounced asymmetry is due to the lack of temporally-structured latent space trained with the World Model objective in pixel-based methods. Lastly, to address this issue, we propose Joint Embedding DIffusion (JEDI), a novel latent diffusion world model trained end-to-end with the self-consistency objective. JEDI outperforms SOTA models in human-optimal tasks while staying competitive across the Atari100k benchmark, and runs 3 times faster with 43% lower memory than the latest pixel-based diffusion baseline. Overall, our work rethinks what it truly means to cross human-level performance in Atari100k.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": "Preprint", "pdf_url": "https://arxiv.org/pdf/2505.19698.pdf", "abstract_url": "https://arxiv.org/abs/2505.19698", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"]}
{"id": "2505.19764", "title": "Agentic Predictor: Performance Prediction for Agentic Workflows via Multi-View Encoding", "authors": ["Patara Trirat", "Wonyong Jeong", "Sung Ju Hwang"], "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities across diverse tasks, but optimizing LLM-based agentic systems remains challenging due to the vast search space of agent configurations, prompting strategies, and communication patterns. Existing approaches often rely on heuristic-based tuning or exhaustive evaluation, which can be computationally expensive and suboptimal. This paper proposes Agentic Predictor, a lightweight predictor for efficient agentic workflow evaluation. Agentic Predictor is equipped with a multi-view workflow encoding technique that leverages multi-view representation learning of agentic systems by incorporating code architecture, textual prompts, and interaction graph features. To achieve high predictive accuracy while significantly reducing the number of required workflow evaluations for training a predictor, Agentic Predictor employs cross-domain unsupervised pretraining. By learning to approximate task success rates, Agentic Predictor enables fast and accurate selection of optimal agentic workflow configurations for a given task, significantly reducing the need for expensive trial-and-error evaluations. Experiments on a carefully curated benchmark spanning three domains show that our predictor outperforms state-of-the-art methods in both predictive accuracy and workflow utility, highlighting the potential of performance predictors in streamlining the design of LLM-based agentic workflows.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.19764.pdf", "abstract_url": "https://arxiv.org/abs/2505.19764", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"]}
{"id": "2505.19769", "title": "TeViR: Text-to-Video Reward with Diffusion Models for Efficient Reinforcement Learning", "authors": ["Yuhui Chen", "Haoran Li", "Zhennan Jiang", "Haowei Wen", "Dongbin Zhao"], "abstract": "Developing scalable and generalizable reward engineering for reinforcement learning (RL) is crucial for creating general-purpose agents, especially in the challenging domain of robotic manipulation. While recent advances in reward engineering with Vision-Language Models (VLMs) have shown promise, their sparse reward nature significantly limits sample efficiency. This paper introduces TeViR, a novel method that leverages a pre-trained text-to-video diffusion model to generate dense rewards by comparing the predicted image sequence with current observations. Experimental results across 11 complex robotic tasks demonstrate that TeViR outperforms traditional methods leveraging sparse rewards and other state-of-the-art (SOTA) methods, achieving better sample efficiency and performance without ground truth environmental rewards. TeViR's ability to efficiently guide agents in complex environments highlights its potential to advance reinforcement learning applications in robotic manipulation.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19769.pdf", "abstract_url": "https://arxiv.org/abs/2505.19769", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2505.19850", "title": "DISCOVER: Automated Curricula for Sparse-Reward Reinforcement Learning", "authors": ["Leander Diaz-Bone", "Marco Bagatella", "Jonas HÃ¼botter", "Andreas Krause"], "abstract": "Sparse-reward reinforcement learning (RL) can model a wide range of highly complex tasks. Solving sparse-reward tasks is RL's core premise - requiring efficient exploration coupled with long-horizon credit assignment - and overcoming these challenges is key for building self-improving agents with superhuman ability. We argue that solving complex and high-dimensional tasks requires solving simpler tasks that are relevant to the target task. In contrast, most prior work designs strategies for selecting exploratory tasks with the objective of solving any task, making exploration of challenging high-dimensional, long-horizon tasks intractable. We find that the sense of direction, necessary for effective exploration, can be extracted from existing RL algorithms, without needing any prior information. Based on this finding, we propose a method for directed sparse-reward goal-conditioned very long-horizon RL (DISCOVER), which selects exploratory goals in the direction of the target task. We connect DISCOVER to principled exploration in bandits, formally bounding the time until the target task becomes achievable in terms of the agent's initial distance to the target, but independent of the volume of the space of all tasks. Empirically, we perform a thorough evaluation in high-dimensional environments. We find that the directed goal selection of DISCOVER solves exploration problems that are beyond the reach of prior state-of-the-art exploration methods in RL.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19850.pdf", "abstract_url": "https://arxiv.org/abs/2505.19850", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"]}
{"id": "2505.19867", "title": "Deep Active Inference Agents for Delayed and Long-Horizon Environments", "authors": ["Yavar Taheri Yeganeh", "Mohsen Jafari", "Andrea Matta"], "abstract": "With the recent success of world-model agents, which extend the core idea of model-based reinforcement learning by learning a differentiable model for sample-efficient control across diverse tasks, active inference (AIF) offers a complementary, neuroscience-grounded paradigm that unifies perception, learning, and action within a single probabilistic framework powered by a generative model. Despite this promise, practical AIF agents still rely on accurate immediate predictions and exhaustive planning, a limitation that is exacerbated in delayed environments requiring plans over long horizons, tens to hundreds of steps. Moreover, most existing agents are evaluated on robotic or vision benchmarks which, while natural for biological agents, fall short of real-world industrial complexity. We address these limitations with a generative-policy architecture featuring (i) a multi-step latent transition that lets the generative model predict an entire horizon in a single look-ahead, (ii) an integrated policy network that enables the transition and receives gradients of the expected free energy, (iii) an alternating optimization scheme that updates model and policy from a replay buffer, and (iv) a single gradient step that plans over long horizons, eliminating exhaustive planning from the control loop. We evaluate our agent in an environment that mimics a realistic industrial scenario with delayed and long-horizon settings. The empirical results confirm the effectiveness of the proposed approach, demonstrating the coupled world-model with the AIF formalism yields an end-to-end probabilistic controller capable of effective decision making in delayed, long-horizon settings without handcrafted rewards or expensive planning.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.19867.pdf", "abstract_url": "https://arxiv.org/abs/2505.19867", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
