{"id": "2505.04769", "title": "Vision-Language-Action Models: Concepts, Progress, Applications and Challenges", "authors": ["Ranjan Sapkota", "Yang Cao", "Konstantinos I. Roumeliotis", "Manoj Karkee"], "abstract": "Vision-Language-Action (VLA) models mark a transformative advancement in artificial intelligence, aiming to unify perception, natural language understanding, and embodied action within a single computational framework. This foundational review presents a comprehensive synthesis of recent advancements in Vision-Language-Action models, systematically organized across five thematic pillars that structure the landscape of this rapidly evolving field. We begin by establishing the conceptual foundations of VLA systems, tracing their evolution from cross-modal learning architectures to generalist agents that tightly integrate vision-language models (VLMs), action planners, and hierarchical controllers. Our methodology adopts a rigorous literature review framework, covering over 80 VLA models published in the past three years. Key progress areas include architectural innovations, parameter-efficient training strategies, and real-time inference accelerations. We explore diverse application domains such as humanoid robotics, autonomous vehicles, medical and industrial robotics, precision agriculture, and augmented reality navigation. The review further addresses major challenges across real-time control, multimodal action representation, system scalability, generalization to unseen tasks, and ethical deployment risks. Drawing from the state-of-the-art, we propose targeted solutions including agentic AI adaptation, cross-embodiment generalization, and unified neuro-symbolic planning. In our forward-looking discussion, we outline a future roadmap where VLA models, VLMs, and agentic AI converge to power socially aligned, adaptive, and general-purpose embodied agents. This work serves as a foundational reference for advancing intelligent, real-world robotics and artificial general intelligence. >Vision-language-action, Agentic AI, AI Agents, Vision-language Models", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "36 pages, 18 Figures, 4 Tables", "pdf_url": "https://arxiv.org/pdf/2505.04769.pdf", "abstract_url": "https://arxiv.org/abs/2505.04769", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文综述了视觉-语言-动作（VLA）模型的最新进展，包括其概念基础、架构创新、应用领域及面临的挑战，并提出了未来发展方向。", "motivation": "解决如何将感知、自然语言理解和具体行动统一到单一计算框架中的问题，以推动人工智能的发展。", "method": "采用严格的文献综述框架，覆盖了过去三年发表的80多个VLA模型，系统性地分析了这一领域的进展。", "result": "识别了VLA模型在架构创新、参数高效训练策略和实时推理加速等关键领域的进展，以及在人形机器人、自动驾驶等多个应用领域的潜力。", "conclusion": "提出了包括代理AI适应、跨体现泛化和统一神经符号规划在内的解决方案，并展望了VLA模型与视觉语言模型（VLMs）及代理AI融合的未来发展方向。"}}
{"id": "2505.04921", "title": "Perception, Reason, Think, and Plan: A Survey on Large Multimodal Reasoning Models", "authors": ["Yunxin Li", "Zhenyu Liu", "Zitao Li", "Xuanyu Zhang", "Zhenran Xu", "Xinyu Chen", "Haoyuan Shi", "Shenyuan Jiang", "Xintong Wang", "Jifang Wang", "Shouzheng Huang", "Xinping Zhao", "Borui Jiang", "Lanqing Hong", "Longyue Wang", "Zhuotao Tian", "Baoxing Huai", "Wenhan Luo", "Weihua Luo", "Zheng Zhang", "Baotian Hu", "Min Zhang"], "abstract": "Reasoning lies at the heart of intelligence, shaping the ability to make decisions, draw conclusions, and generalize across domains. In artificial intelligence, as systems increasingly operate in open, uncertain, and multimodal environments, reasoning becomes essential for enabling robust and adaptive behavior. Large Multimodal Reasoning Models (LMRMs) have emerged as a promising paradigm, integrating modalities such as text, images, audio, and video to support complex reasoning capabilities and aiming to achieve comprehensive perception, precise understanding, and deep reasoning. As research advances, multimodal reasoning has rapidly evolved from modular, perception-driven pipelines to unified, language-centric frameworks that offer more coherent cross-modal understanding. While instruction tuning and reinforcement learning have improved model reasoning, significant challenges remain in omni-modal generalization, reasoning depth, and agentic behavior. To address these issues, we present a comprehensive and structured survey of multimodal reasoning research, organized around a four-stage developmental roadmap that reflects the field's shifting design philosophies and emerging capabilities. First, we review early efforts based on task-specific modules, where reasoning was implicitly embedded across stages of representation, alignment, and fusion. Next, we examine recent approaches that unify reasoning into multimodal LLMs, with advances such as Multimodal Chain-of-Thought (MCoT) and multimodal reinforcement learning enabling richer and more structured reasoning chains. Finally, drawing on empirical insights from challenging benchmarks and experimental cases of OpenAI O3 and O4-mini, we discuss the conceptual direction of native large multimodal reasoning models (N-LMRMs), which aim to support scalable, agentic, and adaptive reasoning and planning in complex, real-world environments.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.04921.pdf", "abstract_url": "https://arxiv.org/abs/2505.04921", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文综述了大型多模态推理模型（LMRMs）的发展，探讨了从模块化、感知驱动的管道到统一、以语言为中心的框架的演变，以及面临的挑战和未来方向。", "motivation": "解决在开放、不确定和多模态环境中，人工智能系统需要更强的推理能力以实现稳健和自适应行为的问题。", "method": "通过四阶段发展路线图，回顾了从特定任务模块到统一多模态LLMs的推理方法，包括多模态思维链（MCoT）和多模态强化学习等进展。", "result": "指出了在全面模态泛化、推理深度和代理行为方面的挑战，并提出了原生大型多模态推理模型（N-LMRMs）的概念方向。", "conclusion": "N-LMRMs旨在支持复杂现实环境中可扩展、代理和自适应的推理与规划，代表了多模态推理研究的未来发展方向。"}}
{"id": "2505.04965", "title": "DenseGrounding: Improving Dense Language-Vision Semantics for Ego-Centric 3D Visual Grounding", "authors": ["Henry Zheng", "Hao Shi", "Qihang Peng", "Yong Xien Chng", "Rui Huang", "Yepeng Weng", "Zhongchao Shi", "Gao Huang"], "abstract": "Enabling intelligent agents to comprehend and interact with 3D environments through natural language is crucial for advancing robotics and human-computer interaction. A fundamental task in this field is ego-centric 3D visual grounding, where agents locate target objects in real-world 3D spaces based on verbal descriptions. However, this task faces two significant challenges: (1) loss of fine-grained visual semantics due to sparse fusion of point clouds with ego-centric multi-view images, (2) limited textual semantic context due to arbitrary language descriptions. We propose DenseGrounding, a novel approach designed to address these issues by enhancing both visual and textual semantics. For visual features, we introduce the Hierarchical Scene Semantic Enhancer, which retains dense semantics by capturing fine-grained global scene features and facilitating cross-modal alignment. For text descriptions, we propose a Language Semantic Enhancer that leverages large language models to provide rich context and diverse language descriptions with additional context during model training. Extensive experiments show that DenseGrounding significantly outperforms existing methods in overall accuracy, with improvements of 5.81% and 7.56% when trained on the comprehensive full dataset and smaller mini subset, respectively, further advancing the SOTA in egocentric 3D visual grounding. Our method also achieves 1st place and receives the Innovation Award in the CVPR 2024 Autonomous Grand Challenge Multi-view 3D Visual Grounding Track, validating its effectiveness and robustness.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "Accepted by ICLR 2025", "pdf_url": "https://arxiv.org/pdf/2505.04965.pdf", "abstract_url": "https://arxiv.org/abs/2505.04965", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "DenseGrounding通过增强视觉和文本语义，提高了自我中心3D视觉定位的性能，解决了点云与多视图图像稀疏融合导致的细粒度视觉语义丢失和语言描述限制的问题。", "motivation": "解决自我中心3D视觉定位中的两个主要挑战：由于点云与多视图图像的稀疏融合导致的细粒度视觉语义丢失，以及由于任意语言描述导致的有限文本语义上下文。", "method": "提出了DenseGrounding方法，包括Hierarchical Scene Semantic Enhancer来保留密集的视觉语义，和Language Semantic Enhancer利用大型语言模型提供丰富的文本上下文。", "result": "在全面数据集和小型子集上分别提高了5.81%和7.56%的准确率，并在CVPR 2024 Autonomous Grand Challenge Multi-view 3D Visual Grounding Track中获得第一名和创新奖。", "conclusion": "DenseGrounding通过增强视觉和文本语义，显著提高了自我中心3D视觉定位的性能，验证了其有效性和鲁棒性。"}}
{"id": "2505.05318", "title": "Mapping User Trust in Vision Language Models: Research Landscape, Challenges, and Prospects", "authors": ["Agnese Chiatti", "Sara Bernardini", "Lara Shibelski Godoy Piccolo", "Viola Schiaffonati", "Matteo Matteucci"], "abstract": "The rapid adoption of Vision Language Models (VLMs), pre-trained on large image-text and video-text datasets, calls for protecting and informing users about when to trust these systems. This survey reviews studies on trust dynamics in user-VLM interactions, through a multi-disciplinary taxonomy encompassing different cognitive science capabilities, collaboration modes, and agent behaviours. Literature insights and findings from a workshop with prospective VLM users inform preliminary requirements for future VLM trust studies.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Human-Computer Interaction (cs.HC); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.05318.pdf", "abstract_url": "https://arxiv.org/abs/2505.05318", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)", "Human-Computer Interaction (cs.HC)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文综述了用户与视觉语言模型（VLMs）互动中的信任动态，通过多学科分类法探讨了认知科学能力、协作模式和代理行为，并基于文献和未来VLM用户的研讨会提出了未来VLM信任研究的初步要求。", "motivation": "随着视觉语言模型（VLMs）在大型图像-文本和视频-文本数据集上的预训练快速普及，需要保护并告知用户何时可以信任这些系统。", "method": "通过多学科分类法回顾了用户-VLM互动中的信任动态研究，包括认知科学能力、协作模式和代理行为，并结合文献和用户研讨会的发现。", "result": "提出了未来VLM信任研究的初步要求，旨在更好地理解和指导用户对VLMs的信任。", "conclusion": "本文为理解和改善用户对视觉语言模型的信任提供了多角度的研究视角和初步指导，对未来的VLM信任研究具有重要意义。"}}
{"id": "2505.04638", "title": "Towards Artificial Intelligence Research Assistant for Expert-Involved Learning", "authors": ["Tianyu Liu", "Simeng Han", "Xiao Luo", "Hanchen Wang", "Pan Lu", "Biqing Zhu", "Yuge Wang", "Keyi Li", "Jiapeng Chen", "Rihao Qu", "Yufeng Liu", "Xinyue Cui", "Aviv Yaish", "Yuhang Chen", "Minsheng Hao", "Chuhan Li", "Kexing Li", "Arman Cohan", "Hua Xu", "Mark Gerstein", "James Zou", "Hongyu Zhao"], "abstract": "Large Language Models (LLMs) and Large Multi-Modal Models (LMMs) have emerged as transformative tools in scientific research, yet their reliability and specific contributions to biomedical applications remain insufficiently characterized. In this study, we present \\textbf{AR}tificial \\textbf{I}ntelligence research assistant for \\textbf{E}xpert-involved \\textbf{L}earning (ARIEL), a multimodal dataset designed to benchmark and enhance two critical capabilities of LLMs and LMMs in biomedical research: summarizing extensive scientific texts and interpreting complex biomedical figures. To facilitate rigorous assessment, we create two open-source sets comprising biomedical articles and figures with designed questions. We systematically benchmark both open- and closed-source foundation models, incorporating expert-driven human evaluations conducted by doctoral-level experts. Furthermore, we improve model performance through targeted prompt engineering and fine-tuning strategies for summarizing research papers, and apply test-time computational scaling to enhance the reasoning capabilities of LMMs, achieving superior accuracy compared to human-expert corrections. We also explore the potential of using LMM Agents to generate scientific hypotheses from diverse multimodal inputs. Overall, our results delineate clear strengths and highlight significant limitations of current foundation models, providing actionable insights and guiding future advancements in deploying large-scale language and multi-modal models within biomedical research.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Information Retrieval (cs.IR)", "comments": "36 pages, 7 figures", "pdf_url": "https://arxiv.org/pdf/2505.04638.pdf", "abstract_url": "https://arxiv.org/abs/2505.04638", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Information Retrieval (cs.IR)"], "matching_keywords": ["agent"], "AI": {"tldr": "本研究介绍了ARIEL，一个多模态数据集，旨在评估和提升大型语言模型和多模态模型在生物医学研究中的两个关键能力：总结科学文本和解释复杂生物医学图表。通过专家驱动的人类评估和模型优化策略，研究展示了当前基础模型的优势和局限性。", "motivation": "大型语言模型和多模态模型在科学研究中的应用日益广泛，但它们在生物医学应用中的可靠性和具体贡献尚未充分表征。", "method": "研究创建了两个开源数据集，包含生物医学文章和图表，并设计了问题。通过专家驱动的人类评估、提示工程和微调策略，以及测试时计算扩展，评估和优化了模型的性能。", "result": "研究通过优化策略显著提高了模型在总结研究论文和增强多模态模型推理能力方面的准确性，超过了人类专家的修正。同时，探索了使用多模态模型代理从多样化输入生成科学假设的潜力。", "conclusion": "研究结果明确了当前基础模型的优势和显著局限性，为未来在生物医学研究中部署大规模语言和多模态模型提供了可行的见解和指导。"}}
{"id": "2505.04628", "title": "How Social is It? A Benchmark for LLMs' Capabilities in Multi-user Multi-turn Social Agent Tasks", "authors": ["Yusen Wu", "Junwu Xiong", "Xiaotie Deng"], "abstract": "Expanding the application of large language models (LLMs) to societal life, instead of primary function only as auxiliary assistants to communicate with only one person at a time, necessitates LLMs' capabilities to independently play roles in multi-user, multi-turn social agent tasks within complex social settings. However, currently the capability has not been systematically measured with available benchmarks. To address this gap, we first introduce an agent task leveling framework grounded in sociological principles. Concurrently, we propose a novel benchmark, How Social Is It (we call it HSII below), designed to assess LLM's social capabilities in comprehensive social agents tasks and benchmark representative models. HSII comprises four stages: format parsing, target selection, target switching conversation, and stable conversation, which collectively evaluate the communication and task completion capabilities of LLMs within realistic social interaction scenarios dataset, HSII-Dataset. The dataset is derived step by step from news dataset. We perform an ablation study by doing clustering to the dataset. Additionally, we investigate the impact of chain of thought (COT) method on enhancing LLMs' social performance. Since COT cost more computation, we further introduce a new statistical metric, COT-complexity, to quantify the efficiency of certain LLMs with COTs for specific social tasks and strike a better trade-off between measurement of correctness and efficiency. Various results of our experiments demonstrate that our benchmark is well-suited for evaluating social skills in LLMs.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.04628.pdf", "abstract_url": "https://arxiv.org/abs/2505.04628", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Social and Information Networks (cs.SI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一个名为HSII的新基准，用于评估大型语言模型(LLMs)在多用户多轮社交代理任务中的社交能力，包括格式解析、目标选择、目标切换对话和稳定对话四个阶段，并提出了COT-complexity这一新统计指标来衡量COT方法在提升LLMs社交性能时的效率。", "motivation": "目前缺乏系统地衡量LLMs在多用户多轮社交代理任务中能力的基准，这限制了LLMs在社会生活中的应用扩展。", "method": "提出了一个基于社会学原则的代理任务分级框架和HSII基准，包括四个评估阶段，并使用从新闻数据集逐步构建的HSII-Dataset进行实验，包括对数据集的聚类消融研究和COT方法的影响研究。", "result": "实验结果表明，HSII基准能有效评估LLMs的社交技能，COT方法虽能提升性能但计算成本较高，新提出的COT-complexity指标有助于在正确性和效率之间找到更好的平衡。", "conclusion": "HSII基准为评估LLMs在复杂社交环境中的能力提供了系统的方法，COT-complexity指标的引入为优化LLMs的社交性能提供了新的视角。"}}
{"id": "2505.04649", "title": "FRAME: Feedback-Refined Agent Methodology for Enhancing Medical Research Insights", "authors": ["Chengzhang Yu", "Yiming Zhang", "Zhixin Liu", "Zenghui Ding", "Yining Sun", "Zhanpeng Jin"], "abstract": "The automation of scientific research through large language models (LLMs) presents significant opportunities but faces critical challenges in knowledge synthesis and quality assurance. We introduce Feedback-Refined Agent Methodology (FRAME), a novel framework that enhances medical paper generation through iterative refinement and structured feedback. Our approach comprises three key innovations: (1) A structured dataset construction method that decomposes 4,287 medical papers into essential research components through iterative refinement; (2) A tripartite architecture integrating Generator, Evaluator, and Reflector agents that progressively improve content quality through metric-driven feedback; and (3) A comprehensive evaluation framework that combines statistical metrics with human-grounded benchmarks. Experimental results demonstrate FRAME's effectiveness, achieving significant improvements over conventional approaches across multiple models (9.91% average gain with DeepSeek V3, comparable improvements with GPT-4o Mini) and evaluation dimensions. Human evaluation confirms that FRAME-generated papers achieve quality comparable to human-authored works, with particular strength in synthesizing future research directions. The results demonstrated our work could efficiently assist medical research by building a robust foundation for automated medical research paper generation while maintaining rigorous academic standards.", "subjects": "Computation and Language (cs.CL)", "comments": "12 pages, 4 figures, 5 table", "pdf_url": "https://arxiv.org/pdf/2505.04649.pdf", "abstract_url": "https://arxiv.org/abs/2505.04649", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了FRAME（反馈精炼代理方法），一种通过迭代精炼和结构化反馈增强医学论文生成的新框架。", "motivation": "大型语言模型（LLMs）在自动化科学研究中面临知识合成和质量保证的关键挑战。", "method": "FRAME包括三个关键创新：结构化数据集构建方法、集成生成器、评估器和反射器的三方架构，以及结合统计指标和人类基准的全面评估框架。", "result": "实验结果显示FRAME在多个模型和评估维度上显著优于传统方法，人类评估确认FRAME生成的论文质量与人类作者相当。", "conclusion": "FRAME为自动化医学研究论文生成建立了坚实基础，同时保持了严格的学术标准，有效辅助医学研究。"}}
{"id": "2505.04651", "title": "Scientific Hypothesis Generation and Validation: Methods, Datasets, and Future Directions", "authors": ["Adithya Kulkarni", "Fatimah Alotaibi", "Xinyue Zeng", "Longfeng Wu", "Tong Zeng", "Barry Menglong Yao", "Minqian Liu", "Shuaicheng Zhang", "Lifu Huang", "Dawei Zhou"], "abstract": "Large Language Models (LLMs) are transforming scientific hypothesis generation and validation by enabling information synthesis, latent relationship discovery, and reasoning augmentation. This survey provides a structured overview of LLM-driven approaches, including symbolic frameworks, generative models, hybrid systems, and multi-agent architectures. We examine techniques such as retrieval-augmented generation, knowledge-graph completion, simulation, causal inference, and tool-assisted reasoning, highlighting trade-offs in interpretability, novelty, and domain alignment. We contrast early symbolic discovery systems (e.g., BACON, KEKADA) with modern LLM pipelines that leverage in-context learning and domain adaptation via fine-tuning, retrieval, and symbolic grounding. For validation, we review simulation, human-AI collaboration, causal modeling, and uncertainty quantification, emphasizing iterative assessment in open-world contexts. The survey maps datasets across biomedicine, materials science, environmental science, and social science, introducing new resources like AHTech and CSKG-600. Finally, we outline a roadmap emphasizing novelty-aware generation, multimodal-symbolic integration, human-in-the-loop systems, and ethical safeguards, positioning LLMs as agents for principled, scalable scientific discovery.", "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.04651.pdf", "abstract_url": "https://arxiv.org/abs/2505.04651", "categories": ["Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文综述了大型语言模型（LLMs）在科学假设生成和验证中的应用，包括符号框架、生成模型、混合系统和多智能体架构等方法，并探讨了相关数据集和未来发展方向。", "motivation": "探讨如何利用LLMs进行科学假设的生成和验证，以解决信息合成、潜在关系发现和推理增强等问题。", "method": "综述了包括检索增强生成、知识图谱补全、模拟、因果推理和工具辅助推理等多种技术，并对比了早期符号发现系统与现代LLM管道的差异。", "result": "总结了在生物医学、材料科学、环境科学和社会科学等领域的数据集，并介绍了新的资源如AHTech和CSKG-600。", "conclusion": "提出了一个路线图，强调新颖性感知生成、多模态符号整合、人在环系统和伦理保障，将LLMs定位为原则性、可扩展科学发现的代理。"}}
{"id": "2505.04666", "title": "Fine-Tuning Large Language Models and Evaluating Retrieval Methods for Improved Question Answering on Building Codes", "authors": ["Mohammad Aqib", "Mohd Hamza", "Qipei Mei", "Ying Hei Chui"], "abstract": "Building codes are regulations that establish standards for the design, construction, and safety of buildings to ensure structural integrity, fire protection, and accessibility. They are often extensive, complex, and subject to frequent updates, making manual querying challenging and time-consuming. Key difficulties include navigating large volumes of text, interpreting technical language, and identifying relevant clauses across different sections. A potential solution is to build a Question-Answering (QA) system that answers user queries based on building codes. Among the various methods for building a QA system, Retrieval-Augmented Generation (RAG) stands out in performance. RAG consists of two components: a retriever and a language model. This study focuses on identifying a suitable retriever method for building codes and optimizing the generational capability of the language model using fine-tuning techniques. We conducted a detailed evaluation of various retrieval methods by performing the retrieval on the National Building Code of Canada (NBCC) and explored the impact of domain-specific fine-tuning on several language models using the dataset derived from NBCC. Our analysis included a comparative assessment of different retrievers and the performance of both pre-trained and fine-tuned models to determine the efficacy and domain-specific adaptation of language models using fine-tuning on the NBCC dataset. Experimental results showed that Elasticsearch proved to be the most robust retriever among all. The findings also indicate that fine-tuning language models on an NBCC-specific dataset can enhance their ability to generate contextually relevant responses. When combined with context retrieved by a powerful retriever like Elasticsearch, this improvement in LLM performance can optimize the RAG system, enabling it to better navigate the complexities of the NBCC.", "subjects": "Computation and Language (cs.CL); Information Retrieval (cs.IR); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.04666.pdf", "abstract_url": "https://arxiv.org/abs/2505.04666", "categories": ["Computation and Language (cs.CL)", "Information Retrieval (cs.IR)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "该研究通过微调大型语言模型和评估检索方法，提高了基于建筑规范的问答系统性能，特别是在处理加拿大国家建筑规范（NBCC）时表现出色。", "motivation": "建筑规范内容庞大、复杂且频繁更新，手动查询既具挑战性又耗时。研究旨在通过构建一个基于问答（QA）的系统来解决这些问题。", "method": "研究采用了检索增强生成（RAG）方法，包括检索器和语言模型两部分。重点评估了不同检索方法在NBCC上的表现，并探索了领域特定微调对语言模型性能的影响。", "result": "实验结果表明，Elasticsearch是最强大的检索器。此外，对NBCC特定数据集进行微调的语言模型能生成更符合上下文的回答。", "conclusion": "结合强大的检索器如Elasticsearch和经过微调的语言模型，可以优化RAG系统，使其更好地应对NBCC的复杂性。"}}
{"id": "2505.04927", "title": "Belief Filtering for Epistemic Control in Linguistic State Space", "authors": ["Sebastian Dumbrava"], "abstract": "We examine belief filtering as a mechanism for the epistemic control of artificial agents, focusing on the regulation of internal cognitive states represented as linguistic expressions. This mechanism is developed within the Semantic Manifold framework, where belief states are dynamic, structured ensembles of natural language fragments. Belief filters act as content-aware operations on these fragments across various cognitive transitions. This paper illustrates how the inherent interpretability and modularity of such a linguistically-grounded cognitive architecture directly enable belief filtering, offering a principled approach to agent regulation. The study highlights the potential for enhancing AI safety and alignment through structured interventions in an agent's internal semantic space and points to new directions for architecturally embedded cognitive governance.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "18 pages", "pdf_url": "https://arxiv.org/pdf/2505.04927.pdf", "abstract_url": "https://arxiv.org/abs/2505.04927", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了信念过滤作为一种机制，用于人工代理的认知控制，特别是在调节以语言表达为内部认知状态的情况下。该机制在语义流形框架内发展，其中信念状态是动态的、结构化的自然语言片段集合。信念过滤器作为对这些片段在不同认知转换中的内容感知操作。", "motivation": "解决如何通过结构化干预增强AI的安全性和对齐性，以及在代理的内部语义空间中实现认知治理的问题。", "method": "在语义流形框架内开发信念过滤机制，作为对自然语言片段的内容感知操作。", "result": "展示了基于语言的认知架构的固有可解释性和模块化如何直接支持信念过滤，为代理调节提供了原则性方法。", "conclusion": "信念过滤为增强AI安全性和对齐性提供了新途径，并为架构上嵌入的认知治理指明了新方向。"}}
{"id": "2505.04843", "title": "Large Language Models are Autonomous Cyber Defenders", "authors": ["Sebastián R. Castro", "Roberto Campbell", "Nancy Lau", "Octavio Villalobos", "Jiaqi Duan", "Alvaro A. Cardenas"], "abstract": "Fast and effective incident response is essential to prevent adversarial cyberattacks. Autonomous Cyber Defense (ACD) aims to automate incident response through Artificial Intelligence (AI) agents that plan and execute actions. Most ACD approaches focus on single-agent scenarios and leverage Reinforcement Learning (RL). However, ACD RL-trained agents depend on costly training, and their reasoning is not always explainable or transferable. Large Language Models (LLMs) can address these concerns by providing explainable actions in general security contexts. Researchers have explored LLM agents for ACD but have not evaluated them on multi-agent scenarios or interacting with other ACD agents. In this paper, we show the first study on how LLMs perform in multi-agent ACD environments by proposing a new integration to the CybORG CAGE 4 environment. We examine how ACD teams of LLM and RL agents can interact by proposing a novel communication protocol. Our results highlight the strengths and weaknesses of LLMs and RL and help us identify promising research directions to create, train, and deploy future teams of ACD agents.", "subjects": "Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)", "comments": "Presented at IEEE CAI Workshop on Adaptive Cyber Defense 2025. Proceedings to appear", "pdf_url": "https://arxiv.org/pdf/2505.04843.pdf", "abstract_url": "https://arxiv.org/abs/2505.04843", "categories": ["Artificial Intelligence (cs.AI)", "Cryptography and Security (cs.CR)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究了大型语言模型（LLMs）在多智能体自主网络防御（ACD）环境中的表现，提出了与CybORG CAGE 4环境的新集成，并探讨了LLM和强化学习（RL）智能体团队的互动方式。", "motivation": "解决自主网络防御中单智能体场景的局限性，以及RL训练成本高、解释性和可转移性不足的问题。", "method": "提出了一种新的通信协议，用于LLM和RL智能体在多智能体ACD环境中的互动，并在CybORG CAGE 4环境中进行了评估。", "result": "研究结果突出了LLMs和RL在ACD中的优势和弱点，为未来ACD智能体团队的创建、训练和部署指明了研究方向。", "conclusion": "LLMs在多智能体ACD环境中展现出潜力，但仍需进一步研究以优化其性能和团队协作能力。"}}
{"id": "2505.04646", "title": "Computational Irreducibility as the Foundation of Agency: A Formal Model Connecting Undecidability to Autonomous Behavior in Complex Systems", "authors": ["Poria Azadi"], "abstract": "This article explores the emergence of autonomy and agency by connecting fundamental computational limits (decidability, completeness, computational irreducibility) with physical concepts. We introduce a formal model of a \"minimal agent\" operating within potentially Turing-complete environments. Using algorithmic information theory, we argue that the inherent undecidability and computational irreducibility of agent-environment interaction lead to unpredictability and novel information generation, enabling agency (effective goal-directed action). Computational irreducibility prevents full external prediction, creating necessary conditions for autonomous behavior. We relate this to computational sourcehood, where an agent is the irreducible origin of its behavior, though formalizing this concept remains challenging. Our central thesis, formally proven, is that genuine autonomy necessarily implies undecidability from an external perspective, distinguishing autonomous systems from predictable ones. We propose that agency arises when agent-environment coupling complexity allows mutual information between internal states and relevant environmental variables to increase, particularly where analytical solutions are absent and operational closure is needed for persistence. This framework links agency directly to the computational properties of interaction, offering implications for understanding consciousness, designing autonomous AI, and reconceptualizing free will in a deterministic yet computationally irreducible universe.", "subjects": "Artificial Intelligence (cs.AI); Computational Complexity (cs.CC); Information Theory (cs.IT)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.04646.pdf", "abstract_url": "https://arxiv.org/abs/2505.04646", "categories": ["Artificial Intelligence (cs.AI)", "Computational Complexity (cs.CC)", "Information Theory (cs.IT)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过将基本计算限制（可判定性、完备性、计算不可约性）与物理概念联系起来，探讨了自主性和代理性的出现。我们引入了一个在潜在图灵完备环境中操作的“最小代理”的形式模型。使用算法信息理论，我们认为代理-环境交互的固有不可判定性和计算不可约性导致不可预测性和新信息生成，从而实现了代理性（有效的目标导向行动）。计算不可约性阻止了完全的外部预测，为自主行为创造了必要条件。我们将这与计算源联系起来，其中代理是其行为的不可约起源，尽管形式化这一概念仍然具有挑战性。我们的中心论点，正式证明，是真正的自主性必然意味着从外部视角看是不可判定的，这将自主系统与可预测系统区分开来。我们提出，当代理-环境耦合复杂性允许内部状态与相关环境变量之间的互信息增加时，特别是在分析解决方案缺失且需要操作闭合以维持持久性的情况下，代理性就会出现。这一框架将代理性直接与交互的计算属性联系起来，为理解意识、设计自主AI以及在确定性但计算不可约的宇宙中重新构想自由意志提供了启示。", "motivation": "探讨自主性和代理性的出现，通过连接基本计算限制与物理概念，理解复杂系统中的自主行为。", "method": "引入一个“最小代理”的形式模型，使用算法信息理论分析代理-环境交互的不可判定性和计算不可约性。", "result": "证明了真正的自主性必然意味着从外部视角看是不可判定的，计算不可约性为自主行为创造了必要条件。", "conclusion": "代理性直接与交互的计算属性相关，这一框架对理解意识、设计自主AI和重新构想自由意志有重要意义。"}}
{"id": "2505.04997", "title": "Foam-Agent: Towards Automated Intelligent CFD Workflows", "authors": ["Ling Yue", "Nithin Somasekharan", "Yadi Cao", "Shaowu Pan"], "abstract": "Computational Fluid Dynamics (CFD) is an essential simulation tool in various engineering disciplines, but it often requires substantial domain expertise and manual configuration, creating barriers to entry. We present Foam-Agent, a multi-agent framework that automates complex OpenFOAM-based CFD simulation workflows from natural language inputs. Our innovation includes (1) a hierarchical multi-index retrieval system with specialized indices for different simulation aspects, (2) a dependency-aware file generation system that provides consistency management across configuration files, and (3) an iterative error correction mechanism that diagnoses and resolves simulation failures without human intervention. Through comprehensive evaluation on the dataset of 110 simulation tasks, Foam-Agent achieves an 83.6% success rate with Claude 3.5 Sonnet, significantly outperforming existing frameworks (55.5% for MetaOpenFOAM and 37.3% for OpenFOAM-GPT). Ablation studies demonstrate the critical contribution of each system component, with the specialized error correction mechanism providing a 36.4% performance improvement. Foam-Agent substantially lowers the CFD expertise threshold while maintaining modeling accuracy, demonstrating the potential of specialized multi-agent systems to democratize access to complex scientific simulation tools. The code is public at", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.04997.pdf", "abstract_url": "https://arxiv.org/abs/2505.04997", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了Foam-Agent，一个多智能体框架，旨在通过自然语言输入自动化复杂的基于OpenFOAM的CFD模拟工作流程，显著降低了CFD的专业门槛。", "motivation": "计算流体动力学(CFD)是工程学科中重要的模拟工具，但其需要大量领域专业知识和手动配置，形成了进入壁垒。", "method": "Foam-Agent采用了(1)分层多索引检索系统，(2)依赖感知的文件生成系统，以及(3)迭代错误纠正机制，来自动化和优化CFD模拟工作流程。", "result": "在110个模拟任务的数据集上，Foam-Agent实现了83.6%的成功率，显著优于现有框架（MetaOpenFOAM为55.5%，OpenFOAM-GPT为37.3%）。", "conclusion": "Foam-Agent在保持建模准确性的同时，显著降低了CFD的专业门槛，展示了专门的多智能体系统在普及复杂科学模拟工具方面的潜力。"}}
{"id": "2505.05029", "title": "A Reputation System for Large Language Model-based Multi-agent Systems to Avoid the Tragedy of the Commons", "authors": ["Siyue Ren", "Wanli Fu", "Xinkun Zou", "Chen Shen", "Yi Cai", "Chen Chu", "Zhen Wang", "Shuyue Hu"], "abstract": "The tragedy of the commons, where individual self-interest leads to collectively disastrous outcomes, is a pervasive challenge in human society. Recent studies have demonstrated that similar phenomena can arise in generative multi-agent systems (MASs). To address this challenge, this paper explores the use of reputation systems as a remedy. We propose RepuNet, a dynamic, dual-level reputation framework that models both agent-level reputation dynamics and system-level network evolution. Specifically, driven by direct interactions and indirect gossip, agents form reputations for both themselves and their peers, and decide whether to connect or disconnect other agents for future interactions. Through two distinct scenarios, we show that RepuNet effectively mitigates the 'tragedy of the commons', promoting and sustaining cooperation in generative MASs. Moreover, we find that reputation systems can give rise to rich emergent behaviors in generative MASs, such as the formation of cooperative clusters, the social isolation of exploitative agents, and the preference for sharing positive gossip rather than negative ones.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.05029.pdf", "abstract_url": "https://arxiv.org/abs/2505.05029", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出RepuNet，一个动态的双层声誉框架，用于解决生成多代理系统中的'公地悲剧'问题。通过直接互动和间接八卦，代理形成对自己和同行的声誉，并决定是否连接或断开其他代理以进行未来互动。研究表明，RepuNet有效促进了生成多代理系统中的合作，并产生了丰富的涌现行为。", "motivation": "解决生成多代理系统中因个体自利行为导致的'公地悲剧'问题。", "method": "提出RepuNet，一个动态的双层声誉框架，包括代理级声誉动态和系统级网络演化。", "result": "RepuNet有效缓解了'公地悲剧'，促进了生成多代理系统中的合作，并观察到了合作集群的形成、剥削代理的社会隔离以及分享正面八卦的偏好等涌现行为。", "conclusion": "声誉系统如RepuNet能够有效解决生成多代理系统中的合作问题，并促进系统内丰富的社交动态和行为模式。"}}
{"id": "2505.05059", "title": "Enhancing Reinforcement Learning for the Floorplanning of Analog ICs with Beam Search", "authors": ["Sandro Junior Della Rovere", "Davide Basso", "Luca Bortolussi", "Mirjana Videnovic-Misic", "Husni Habal"], "abstract": "The layout of analog ICs requires making complex trade-offs, while addressing device physics and variability of the circuits. This makes full automation with learning-based solutions hard to achieve. However, reinforcement learning (RL) has recently reached significant results, particularly in solving the floorplanning problem. This paper presents a hybrid method that combines RL with a beam (BS) strategy. The BS algorithm enhances the agent's inference process, allowing for the generation of flexible floorplans by accomodating various objective weightings, and addressing congestion without without the need for policy retraining or fine-tuning. Moreover, the RL agent's generalization ability stays intact, along with its efficient handling of circuit features and constraints. Experimental results show approx. 5-85% improvement in area, dead space and half-perimeter wire length compared to a standard RL application, along with higher rewards for the agent. Moreover, performance and efficiency align closely with those of existing state-of-the-art techniques.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "Published in Proceedings of the 21st International Conference on Synthesis, Modeling, Analysis and Simulation Methods, and Applications to Circuit Design (SMACD 2025). 4 pages, 3 figures", "pdf_url": "https://arxiv.org/pdf/2505.05059.pdf", "abstract_url": "https://arxiv.org/abs/2505.05059", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种结合强化学习（RL）与波束搜索（BS）的混合方法，用于模拟集成电路（IC）的布局规划，通过BS算法增强RL代理的推理过程，实现了在不需重新训练或微调策略的情况下，灵活生成满足多种目标权重和解决拥塞问题的布局方案。实验结果显示，与标准RL应用相比，该方法在面积、死区和半周长线长等方面实现了约5-85%的改进，同时保持了RL代理的泛化能力和对电路特性及约束的高效处理。", "motivation": "模拟IC的布局需要做出复杂的权衡，同时考虑器件物理和电路的变异性，这使得基于学习的全自动化解决方案难以实现。本文旨在通过结合RL和BS策略，提高布局规划的自动化水平和效率。", "method": "采用了一种混合方法，结合了强化学习（RL）和波束搜索（BS）策略。BS算法用于增强RL代理的推理过程，支持生成灵活的布局方案，适应不同的目标权重和解决拥塞问题，而无需重新训练或微调策略。", "result": "实验结果表明，与标准RL应用相比，该方法在面积、死区和半周长线长等方面实现了约5-85%的改进，同时RL代理的泛化能力和对电路特性及约束的高效处理得以保持。", "conclusion": "本文提出的RL与BS结合的混合方法，在模拟IC布局规划中显示出显著的性能改进和效率提升，与现有最先进技术相媲美，为自动化布局规划提供了新的解决方案。"}}
{"id": "2505.05108", "title": "Multi-agent Embodied AI: Advances and Future Directions", "authors": ["Zhaohan Feng", "Ruiqi Xue", "Lei Yuan", "Yang Yu", "Ning Ding", "Meiqin Liu", "Bingzhao Gao", "Jian Sun", "Gang Wang"], "abstract": "Embodied artificial intelligence (Embodied AI) plays a pivotal role in the application of advanced technologies in the intelligent era, where AI systems are integrated with physical bodies that enable them to perceive, reason, and interact with their environments. Through the use of sensors for input and actuators for action, these systems can learn and adapt based on real-world feedback, allowing them to perform tasks effectively in dynamic and unpredictable environments. As techniques such as deep learning (DL), reinforcement learning (RL), and large language models (LLMs) mature, embodied AI has become a leading field in both academia and industry, with applications spanning robotics, healthcare, transportation, and manufacturing. However, most research has focused on single-agent systems that often assume static, closed environments, whereas real-world embodied AI must navigate far more complex scenarios. In such settings, agents must not only interact with their surroundings but also collaborate with other agents, necessitating sophisticated mechanisms for adaptation, real-time learning, and collaborative problem-solving. Despite increasing interest in multi-agent systems, existing research remains narrow in scope, often relying on simplified models that fail to capture the full complexity of dynamic, open environments for multi-agent embodied AI. Moreover, no comprehensive survey has systematically reviewed the advancements in this area. As embodied AI rapidly evolves, it is crucial to deepen our understanding of multi-agent embodied AI to address the challenges presented by real-world applications. To fill this gap and foster further development in the field, this paper reviews the current state of research, analyzes key contributions, and identifies challenges and future directions, providing insights to guide innovation and progress in this field.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.05108.pdf", "abstract_url": "https://arxiv.org/abs/2505.05108", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了多智能体具身人工智能（Embodied AI）的进展与未来方向，强调了在复杂动态环境中多智能体协作的重要性，并指出了当前研究的局限性和未来发展的潜力。", "motivation": "解决现实世界中具身AI在多智能体系统中面临的复杂协作和适应性问题，填补该领域综合性研究的空白。", "method": "通过回顾当前研究状态，分析关键贡献，识别挑战和未来方向，提供系统性的综述。", "result": "指出了多智能体具身AI研究的局限性，如依赖简化模型和缺乏对动态开放环境的全面考虑，并提出了未来发展的方向。", "conclusion": "为了推动具身AI领域的创新和进步，需要深化对多智能体系统的理解，解决现实应用中的挑战。"}}
{"id": "2505.05115", "title": "Is there a half-life for the success rates of AI agents?", "authors": ["Toby Ord"], "abstract": "Building on the recent empirical work of Kwa et al. (2025), I show that within their suite of research-engineering tasks the performance of AI agents on longer-duration tasks can be explained by an extremely simple mathematical model -- a constant rate of failing during each minute a human would take to do the task. This implies an exponentially declining success rate with the length of the task and that each agent could be characterised by its own half-life. This empirical regularity allows us to estimate the success rate for an agent at different task lengths. And the fact that this model is a good fit for the data is suggestive of the underlying causes of failure on longer tasks -- that they involve increasingly large sets of subtasks where failing any one fails the task. Whether this model applies more generally on other suites of tasks is unknown and an important subject for further work.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "9 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2505.05115.pdf", "abstract_url": "https://arxiv.org/abs/2505.05115", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "基于Kwa等人（2025年）的实证研究，本文提出一个极简数学模型，用以解释AI代理在长时间任务中的表现，即每分钟失败率恒定，导致成功率随任务时长呈指数下降，每个代理可被其半衰期表征。", "motivation": "探讨AI代理在不同时长任务中成功率的变化规律，及其背后的失败机制。", "method": "采用极简数学模型，假设AI代理在每分钟有恒定的失败率，从而推导出成功率随任务时长的指数下降关系。", "result": "模型与数据高度吻合，表明长时间任务的失败可能由于子任务数量增加，任一子任务失败导致整体任务失败。", "conclusion": "该模型为理解AI代理在长时间任务中的表现提供了新视角，但其普适性需进一步研究验证。"}}
{"id": "2505.04844", "title": "Osiris: A Lightweight Open-Source Hallucination Detection System", "authors": ["Alex Shan", "John Bauer", "Christopher D. Manning"], "abstract": "Retrieval-Augmented Generation (RAG) systems have gained widespread adoption by application builders because they leverage sources of truth to enable Large Language Models (LLMs) to generate more factually sound responses. However, hallucinations, instances of LLM responses that are unfaithful to the provided context, often prevent these systems from being deployed in production environments. Current hallucination detection methods typically involve human evaluation or the use of closed-source models to review RAG system outputs for hallucinations. Both human evaluators and closed-source models suffer from scaling issues due to their high costs and slow inference speeds. In this work, we introduce a perturbed multi-hop QA dataset with induced hallucinations. Via supervised fine-tuning on our dataset, we achieve better recall with a 7B model than GPT-4o on the RAGTruth hallucination detection benchmark and offer competitive performance on precision and accuracy, all while using a fraction of the parameters. Code is released at our repository.", "subjects": "Computation and Language (cs.CL)", "comments": "Stanford 191W", "pdf_url": "https://arxiv.org/pdf/2505.04844.pdf", "abstract_url": "https://arxiv.org/abs/2505.04844", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了Osiris，一个轻量级的开源幻觉检测系统，旨在解决RAG系统中LLM生成不忠实于上下文响应的问题。通过监督微调在扰动多跳QA数据集上，Osiris在RAGTruth基准测试中表现优于GPT-4o，同时使用更少的参数。", "motivation": "解决RAG系统中由于幻觉（LLM生成不忠实于上下文的响应）导致的生产环境部署障碍，以及当前依赖人工评估或闭源模型的幻觉检测方法在扩展性上的高成本和慢推理速度问题。", "method": "通过监督微调在扰动多跳QA数据集上训练一个7B模型，用于幻觉检测。", "result": "在RAGTruth幻觉检测基准测试中，该7B模型在召回率上优于GPT-4o，同时在精确度和准确度上表现竞争性，且使用的参数更少。", "conclusion": "Osiris作为一个轻量级的开源系统，提供了一种高效、可扩展的幻觉检测解决方案，有助于RAG系统在生产环境中的部署。"}}
{"id": "2505.04847", "title": "Benchmarking LLM Faithfulness in RAG with Evolving Leaderboards", "authors": ["Manveer Singh Tamber", "Forrest Sheng Bao", "Chenyu Xu", "Ge Luo", "Suleman Kazi", "Minseok Bae", "Miaoran Li", "Ofer Mendelevitch", "Renyi Qu", "Jimmy Lin"], "abstract": "Hallucinations remain a persistent challenge for LLMs. RAG aims to reduce hallucinations by grounding responses in contexts. However, even when provided context, LLMs still frequently introduce unsupported information or contradictions. This paper presents our efforts to measure LLM hallucinations with a focus on summarization tasks, assessing how often various LLMs introduce hallucinations when summarizing documents. We discuss Vectara's existing LLM hallucination leaderboard, based on the Hughes Hallucination Evaluation Model (HHEM). While HHEM and Vectara's Hallucination Leaderboard have garnered great research interest, we examine challenges faced by HHEM and current hallucination detection methods by analyzing the effectiveness of these methods on existing hallucination datasets. To address these limitations, we propose FaithJudge, an LLM-as-a-judge approach guided by few-shot human hallucination annotations, which substantially improves automated LLM hallucination evaluation over current methods. We introduce an enhanced hallucination leaderboard centered on FaithJudge, alongside our current hallucination leaderboard, enabling more reliable benchmarking of LLMs for hallucinations in RAG.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.04847.pdf", "abstract_url": "https://arxiv.org/abs/2505.04847", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文探讨了大型语言模型（LLMs）在检索增强生成（RAG）中的幻觉问题，提出了FaithJudge方法以改进幻觉评估，并引入了基于FaithJudge的增强幻觉排行榜。", "motivation": "解决LLMs在提供上下文时仍频繁引入不支持信息或矛盾的幻觉问题。", "method": "提出FaithJudge，一种基于少量人工幻觉注释指导的LLM-as-a-judge方法。", "result": "FaithJudge显著提高了现有幻觉检测方法的自动化评估效果。", "conclusion": "通过引入基于FaithJudge的增强幻觉排行榜，能够更可靠地评估LLMs在RAG中的幻觉问题。"}}
{"id": "2505.05197", "title": "Societal and technological progress as sewing an ever-growing, ever-changing, patchy, and polychrome quilt", "authors": ["Joel Z. Leibo", "Alexander Sasha Vezhnevets", "William A. Cunningham", "Sébastien Krier", "Manfred Diaz", "Simon Osindero"], "abstract": "Artificial Intelligence (AI) systems are increasingly placed in positions where their decisions have real consequences, e.g., moderating online spaces, conducting research, and advising on policy. Ensuring they operate in a safe and ethically acceptable fashion is thus critical. However, most solutions have been a form of one-size-fits-all \"alignment\". We are worried that such systems, which overlook enduring moral diversity, will spark resistance, erode trust, and destabilize our institutions. This paper traces the underlying problem to an often-unstated Axiom of Rational Convergence: the idea that under ideal conditions, rational agents will converge in the limit of conversation on a single ethics. Treating that premise as both optional and doubtful, we propose what we call the appropriateness framework: an alternative approach grounded in conflict theory, cultural evolution, multi-agent systems, and institutional economics. The appropriateness framework treats persistent disagreement as the normal case and designs for it by applying four principles: (1) contextual grounding, (2) community customization, (3) continual adaptation, and (4) polycentric governance. We argue here that adopting these design principles is a good way to shift the main alignment metaphor from moral unification to a more productive metaphor of conflict management, and that taking this step is both desirable and urgent.", "subjects": "Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "comments": "16 pages", "pdf_url": "https://arxiv.org/pdf/2505.05197.pdf", "abstract_url": "https://arxiv.org/abs/2505.05197", "categories": ["Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为“适当性框架”的替代方法，以应对AI决策中的道德多样性问题，强调在设计中考虑持续分歧，并提出了四项原则。", "motivation": "解决AI系统决策中忽视道德多样性，可能导致抵抗、信任侵蚀和制度不稳定的问题。", "method": "基于冲突理论、文化进化、多代理系统和经济学的适当性框架，应用四项原则：上下文基础、社区定制、持续适应和多中心治理。", "result": "适当性框架为AI系统设计提供了一种从道德统一转向冲突管理的新视角。", "conclusion": "采用这些设计原则对于改变AI对齐的主要隐喻，从道德统一转向更有效的冲突管理，既是可取的也是紧迫的。"}}
{"id": "2505.04916", "title": "An Open-Source Dual-Loss Embedding Model for Semantic Retrieval in Higher Education", "authors": ["Ramteja Sajja", "Yusuf Sermet", "Ibrahim Demir"], "abstract": "Recent advances in AI have catalyzed the adoption of intelligent educational tools, yet many semantic retrieval systems remain ill-suited to the unique linguistic and structural characteristics of academic content. This study presents two open-source embedding models fine-tuned for educational question answering, particularly in the context of course syllabi. A synthetic dataset of 3,197 sentence pairs, spanning synonymous terminology, paraphrased questions, and implicit-explicit mappings, was constructed through a combination of manual curation and large language model (LLM)-assisted generation. Two training strategies were evaluated: (1) a baseline model fine-tuned using MultipleNegativesRankingLoss (MNRL), and (2) a dual-loss model that combines MNRL with CosineSimilarityLoss to improve both semantic ranking and similarity calibration. Evaluations were conducted on 28 university course syllabi using a fixed set of natural language questions categorized into course, faculty, and teaching assistant information. Results demonstrate that both fine-tuned models outperform strong open-source baselines, including all-MiniLM-L6-v2 and multi-qa-MiniLM-L6-cos-v1, and that the dual-loss model narrows the performance gap with high-performing proprietary embeddings such as OpenAI's text-embedding-3 series. This work contributes reusable, domain-aligned embedding models and provides a replicable framework for educational semantic retrieval, supporting downstream applications such as academic chatbots, retrieval-augmented generation (RAG) systems, and learning management system (LMS) integrations.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": "17 pages, 3 Tables", "pdf_url": "https://arxiv.org/pdf/2505.04916.pdf", "abstract_url": "https://arxiv.org/abs/2505.04916", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本研究提出了两种针对教育问答，特别是课程大纲的开放源代码嵌入模型，通过结合手动策划和大型语言模型辅助生成的方法构建了一个包含3,197个句子对的合成数据集。评估结果表明，这两种微调模型均优于强大的开放源代码基线模型，且双损失模型缩小了与高性能专有嵌入模型的性能差距。", "motivation": "解决当前语义检索系统不适应学术内容独特语言和结构特征的问题，特别是在高等教育领域。", "method": "构建了一个合成数据集，并评估了两种训练策略：一种是使用MultipleNegativesRankingLoss（MNRL）微调的基线模型，另一种是结合MNRL和CosineSimilarityLoss的双损失模型，以提高语义排名和相似性校准。", "result": "微调模型在28个大学课程大纲上使用固定自然语言问题集进行评估，结果显示它们优于所有开放源代码基线模型，双损失模型缩小了与高性能专有嵌入模型的性能差距。", "conclusion": "这项工作贡献了可重用的、与领域对齐的嵌入模型，并为教育语义检索提供了一个可复制的框架，支持学术聊天机器人、检索增强生成（RAG）系统和学习管理系统（LMS）集成等下游应用。"}}
{"id": "2505.05177", "title": "MARK: Memory Augmented Refinement of Knowledge", "authors": ["Anish Ganguli", "Prabal Deb", "Debleena Banerjee"], "abstract": "Large Language Models (LLMs) assist in specialized tasks but struggle to align with evolving domain knowledge without costly fine-tuning. Domain knowledge consists of: Knowledge: Immutable facts (e.g., 'A stone is solid') and generally accepted principles (e.g., ethical standards); Refined Memory: Evolving insights shaped by business needs and real-world changes. However, a significant gap often exists between a domain expert's deep, nuanced understanding and the system's domain knowledge, which can hinder accurate information retrieval and application. Our Memory-Augmented Refinement of Knowledge (MARK) framework enables LLMs to continuously learn without retraining by leveraging structured refined memory, inspired by the Society of Mind. MARK operates through specialized agents, each serving a distinct role: Residual Refined Memory Agent: Stores and retrieves domain-specific insights to maintain context over time; User Question Refined Memory Agent: Captures user-provided facts, abbreviations, and terminology for better comprehension; LLM Response Refined Memory Agent: Extracts key elements from responses for refinement and personalization. These agents analyse stored refined memory, detect patterns, resolve contradictions, and improve response accuracy. Temporal factors like recency and frequency prioritize relevant information while discarding outdated insights. MARK enhances LLMs in multiple ways: Ground Truth Strategy: Reduces hallucinations by establishing a structured reference; Domain-Specific Adaptation: Essential for fields like healthcare, law, and manufacturing, where proprietary insights are absent from public datasets; Personalized AI Assistants: Improves virtual assistants by remembering user preferences, ensuring coherent responses over time.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.05177.pdf", "abstract_url": "https://arxiv.org/abs/2505.05177", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了MARK框架，旨在通过结构化精炼记忆使大型语言模型（LLMs）无需重新训练即可持续学习，以解决LLMs在适应不断变化的领域知识时的挑战。", "motivation": "大型语言模型在专业任务中提供帮助，但在不进行昂贵微调的情况下难以与不断发展的领域知识对齐，这影响了信息检索和应用的准确性。", "method": "MARK框架通过三个专门代理（残余精炼记忆代理、用户问题精炼记忆代理和LLM响应精炼记忆代理）利用结构化精炼记忆，分析存储的记忆，检测模式，解决矛盾，并提高响应准确性。", "result": "MARK框架通过建立结构化参考减少幻觉，实现领域特定适应，并提升个性化AI助手的性能，使其能够记住用户偏好，确保响应的一致性和准确性。", "conclusion": "MARK框架为大型语言模型提供了一种无需重新训练即可持续学习和适应领域知识的方法，特别是在需要专有见解的领域如医疗、法律和制造业中，以及提升个性化AI助手的性能方面具有重要价值。"}}
{"id": "2505.05225", "title": "QualBench: Benchmarking Chinese LLMs with Localized Professional Qualifications for Vertical Domain Evaluation", "authors": ["Mengze Hong", "Wailing Ng", "Di Jiang", "Chen Jason Zhang"], "abstract": "The rapid advancement of Chinese large language models (LLMs) underscores the need for domain-specific evaluations to ensure reliable applications. However, existing benchmarks often lack coverage in vertical domains and offer limited insights into the Chinese working context. Leveraging qualification exams as a unified framework for human expertise evaluation, we introduce QualBench, the first multi-domain Chinese QA benchmark dedicated to localized assessment of Chinese LLMs. The dataset includes over 17,000 questions across six vertical domains, with data selections grounded in 24 Chinese qualifications to closely align with national policies and working standards. Through comprehensive evaluation, the Qwen2.5 model outperformed the more advanced GPT-4o, with Chinese LLMs consistently surpassing non-Chinese models, highlighting the importance of localized domain knowledge in meeting qualification requirements. The best performance of 75.26% reveals the current gaps in domain coverage within model capabilities. Furthermore, we present the failure of LLM collaboration with crowdsourcing mechanisms and suggest the opportunities for multi-domain RAG knowledge enhancement and vertical domain LLM training with Federated Learning.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.05225.pdf", "abstract_url": "https://arxiv.org/abs/2505.05225", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "QualBench是首个专注于中文大语言模型（LLMs）本地化评估的多领域中文QA基准，包含六个垂直领域的17,000多个问题，基于24项中国资格认证，旨在评估模型在特定领域的应用可靠性。", "motivation": "现有基准在垂直领域覆盖不足，且缺乏对中国工作环境的深入洞察，因此需要开发一个专门针对中文LLMs的评估框架。", "method": "利用资格考试作为人类专业知识评估的统一框架，构建了QualBench数据集，并通过全面评估比较了不同模型的表现。", "result": "Qwen2.5模型表现优于更先进的GPT-4o，中文LLMs普遍超越非中文模型，最佳表现达到75.26%，揭示了模型能力在领域覆盖上的差距。", "conclusion": "研究强调了本地化领域知识在满足资格要求中的重要性，并提出了通过多领域RAG知识增强和联邦学习进行垂直领域LLM训练的潜在机会。"}}
{"id": "2505.05440", "title": "EcoAgent: An Efficient Edge-Cloud Collaborative Multi-Agent Framework for Mobile Automation", "authors": ["Biao Yi", "Xavier Hu", "Yurun Chen", "Shengyu Zhang", "Hongxia Yang", "Fan Wu", "Fei Wu"], "abstract": "Cloud-based mobile agents powered by (multimodal) large language models ((M)LLMs) offer strong reasoning abilities but suffer from high latency and cost. While fine-tuned (M)SLMs enable edge deployment, they often lose general capabilities and struggle with complex tasks. To address this, we propose EcoAgent, an Edge-Cloud cOllaborative multi-agent framework for mobile automation. EcoAgent features a closed-loop collaboration among a cloud-based Planning Agent and two edge-based agents: the Execution Agent for action execution and the Observation Agent for verifying outcomes. The Observation Agent uses a Pre-Understanding Module to compress screen images into concise text, reducing token usage. In case of failure, the Planning Agent retrieves screen history and replans via a Reflection Module. Experiments on AndroidWorld show that EcoAgent maintains high task success rates while significantly reducing MLLM token consumption, enabling efficient and practical mobile automation.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.05440.pdf", "abstract_url": "https://arxiv.org/abs/2505.05440", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "EcoAgent是一个高效的边缘-云协作多代理框架，旨在解决移动自动化中云代理延迟高、成本大及边缘代理通用能力不足的问题。通过云规划代理与边缘执行、观察代理的闭环协作，优化任务执行效率与资源消耗。", "motivation": "解决基于云的大型语言模型代理在移动自动化中存在的高延迟、高成本问题，以及边缘部署的特定语言模型在通用能力和复杂任务处理上的不足。", "method": "提出EcoAgent框架，包括云端的规划代理和边缘的执行代理与观察代理，通过预理解模块压缩图像信息减少令牌使用，并通过反思模块在失败时重新规划。", "result": "在AndroidWorld上的实验表明，EcoAgent在保持高任务成功率的同时，显著减少了大型语言模型的令牌消耗，实现了高效的移动自动化。", "conclusion": "EcoAgent通过边缘-云协作和多代理闭环协作，有效平衡了任务执行效率与资源消耗，为移动自动化提供了一种实用且高效的解决方案。"}}
{"id": "2505.05445", "title": "clem:todd: A Framework for the Systematic Benchmarking of LLM-Based Task-Oriented Dialogue System Realisations", "authors": ["Chalamalasetti Kranti", "Sherzod Hakimov", "David Schlangen"], "abstract": "The emergence of instruction-tuned large language models (LLMs) has advanced the field of dialogue systems, enabling both realistic user simulations and robust multi-turn conversational agents. However, existing research often evaluates these components in isolation-either focusing on a single user simulator or a specific system design-limiting the generalisability of insights across architectures and configurations. In this work, we propose clem todd (chat-optimized LLMs for task-oriented dialogue systems development), a flexible framework for systematically evaluating dialogue systems under consistent conditions. clem todd enables detailed benchmarking across combinations of user simulators and dialogue systems, whether existing models from literature or newly developed ones. It supports plug-and-play integration and ensures uniform datasets, evaluation metrics, and computational constraints. We showcase clem todd's flexibility by re-evaluating existing task-oriented dialogue systems within this unified setup and integrating three newly proposed dialogue systems into the same evaluation pipeline. Our results provide actionable insights into how architecture, scale, and prompting strategies affect dialogue performance, offering practical guidance for building efficient and effective conversational AI systems.", "subjects": "Computation and Language (cs.CL)", "comments": "30 pages", "pdf_url": "https://arxiv.org/pdf/2505.05445.pdf", "abstract_url": "https://arxiv.org/abs/2505.05445", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了clem todd框架，用于系统地评估基于大型语言模型的任务导向对话系统，通过统一的评估条件，比较不同用户模拟器和对话系统的组合，为构建高效对话AI提供实用指导。", "motivation": "现有研究往往孤立评估对话系统的组件，限制了跨架构和配置的见解的普遍性。", "method": "提出clem todd框架，支持即插即用集成，确保统一的数据集、评估指标和计算约束。", "result": "通过统一评估现有和新提出的对话系统，提供了关于架构、规模和提示策略如何影响对话性能的可操作见解。", "conclusion": "clem todd框架为构建高效有效的对话AI系统提供了实用的评估方法和指导。"}}
{"id": "2505.05223", "title": "Multi-Objective Reinforcement Learning for Adaptive Personalized Autonomous Driving", "authors": ["Hendrik Surmann", "Jorge de Heuvel", "Maren Bennewitz"], "abstract": "Human drivers exhibit individual preferences regarding driving style. Adapting autonomous vehicles to these preferences is essential for user trust and satisfaction. However, existing end-to-end driving approaches often rely on predefined driving styles or require continuous user feedback for adaptation, limiting their ability to support dynamic, context-dependent preferences. We propose a novel approach using multi-objective reinforcement learning (MORL) with preference-driven optimization for end-to-end autonomous driving that enables runtime adaptation to driving style preferences. Preferences are encoded as continuous weight vectors to modulate behavior along interpretable style objectives$\\unicode{x2013}$including efficiency, comfort, speed, and aggressiveness$\\unicode{x2013}$without requiring policy retraining. Our single-policy agent integrates vision-based perception in complex mixed-traffic scenarios and is evaluated in diverse urban environments using the CARLA simulator. Experimental results demonstrate that the agent dynamically adapts its driving behavior according to changing preferences while maintaining performance in terms of collision avoidance and route completion.", "subjects": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.05223.pdf", "abstract_url": "https://arxiv.org/abs/2505.05223", "categories": ["Robotics (cs.RO)", "Computer Vision and Pattern Recognition (cs.CV)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种使用多目标强化学习（MORL）和偏好驱动优化的新型端到端自动驾驶方法，旨在实现运行时对驾驶风格偏好的适应。", "motivation": "人类驾驶员展现出个性化的驾驶风格偏好，而现有的端到端驾驶方法往往依赖于预定义的驾驶风格或需要用户的持续反馈来适应，这限制了它们支持动态、上下文相关偏好的能力。", "method": "采用多目标强化学习（MORL）与偏好驱动优化，将偏好编码为连续权重向量，以在不重新训练策略的情况下，沿着可解释的风格目标（包括效率、舒适度、速度和侵略性）调整行为。", "result": "实验结果表明，该代理能够根据变化的偏好动态调整其驾驶行为，同时在避免碰撞和完成路线方面保持性能。", "conclusion": "该方法为自动驾驶车辆提供了一种有效的方式来适应个性化的驾驶风格偏好，从而增强用户信任和满意度，而无需持续的反馈或策略重新训练。"}}
{"id": "2505.04784", "title": "A Proposal for Evaluating the Operational Risk for ChatBots based on Large Language Models", "authors": ["Pedro Pinacho-Davidson", "Fernando Gutierrez", "Pablo Zapata", "Rodolfo Vergara", "Pablo Aqueveque"], "abstract": "The emergence of Generative AI (Gen AI) and Large Language Models (LLMs) has enabled more advanced chatbots capable of human-like interactions. However, these conversational agents introduce a broader set of operational risks that extend beyond traditional cybersecurity considerations. In this work, we propose a novel, instrumented risk-assessment metric that simultaneously evaluates potential threats to three key stakeholders: the service-providing organization, end users, and third parties. Our approach incorporates the technical complexity required to induce erroneous behaviors in the chatbot--ranging from non-induced failures to advanced prompt-injection attacks--as well as contextual factors such as the target industry, user age range, and vulnerability severity. To validate our metric, we leverage Garak, an open-source framework for LLM vulnerability testing. We further enhance Garak to capture a variety of threat vectors (e.g., misinformation, code hallucinations, social engineering, and malicious code generation). Our methodology is demonstrated in a scenario involving chatbots that employ retrieval-augmented generation (RAG), showing how the aggregated risk scores guide both short-term mitigation and longer-term improvements in model design and deployment. The results underscore the importance of multi-dimensional risk assessments in operationalizing secure, reliable AI-driven conversational systems.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "comments": "21 pages", "pdf_url": "https://arxiv.org/pdf/2505.04784.pdf", "abstract_url": "https://arxiv.org/abs/2505.04784", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文提出了一种基于大型语言模型（LLMs）的聊天机器人操作风险评估新方法，旨在评估对服务提供商、终端用户和第三方潜在威胁的多维风险。", "motivation": "随着生成式AI（Gen AI）和大型语言模型（LLMs）的发展，聊天机器人能够进行更类似人类的交互，但这也引入了超出传统网络安全考虑的更广泛的操作风险。", "method": "提出了一种新颖的、工具化的风险评估指标，结合了诱导聊天机器人错误行为所需的技术复杂性及上下文因素，并使用Garak框架进行验证和增强。", "result": "通过在一个采用检索增强生成（RAG）的聊天机器人场景中演示，结果显示多维风险评估对于实现安全、可靠的AI驱动对话系统至关重要。", "conclusion": "本文的方法强调了在模型设计和部署中进行多维风险评估的重要性，以指导短期缓解和长期改进。"}}
{"id": "2505.04725", "title": "Geometric Fault-Tolerant Neural Network Tracking Control of Unknown Systems on Matrix Lie Groups", "authors": ["Robin Chhabra", "Farzaneh Abdollahi"], "abstract": "We present a geometric neural network-based tracking controller for systems evolving on matrix Lie groups under unknown dynamics, actuator faults, and bounded disturbances. Leveraging the left-invariance of the tangent bundle of matrix Lie groups, viewed as an embedded submanifold of the vector space $\\R^{N\\times N}$, we propose a set of learning rules for neural network weights that are intrinsically compatible with the Lie group structure and do not require explicit parameterization. Exploiting the geometric properties of Lie groups, this approach circumvents parameterization singularities and enables a global search for optimal weights. The ultimate boundedness of all error signals -- including the neural network weights, the coordinate-free configuration error function, and the tracking velocity error -- is established using Lyapunov's direct method. To validate the effectiveness of the proposed method, we provide illustrative simulation results for decentralized formation control of multi-agent systems on the Special Euclidean group.", "subjects": "Systems and Control (eess.SY); Artificial Intelligence (cs.AI); Robotics (cs.RO); Dynamical Systems (math.DS)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.04725.pdf", "abstract_url": "https://arxiv.org/abs/2505.04725", "categories": ["Systems and Control (eess.SY)", "Artificial Intelligence (cs.AI)", "Robotics (cs.RO)", "Dynamical Systems (math.DS)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于几何神经网络的跟踪控制器，用于处理在矩阵李群上演化、具有未知动力学、执行器故障和有界干扰的系统。通过利用矩阵李群切丛的左不变性，提出了一组与李群结构内在兼容的神经网络权重学习规则，无需显式参数化。该方法利用李群的几何特性，避免了参数化奇异性，并实现了对最优权重的全局搜索。通过李雅普诺夫直接方法，建立了所有误差信号的最终有界性，包括神经网络权重、无坐标配置误差函数和跟踪速度误差。通过在多智能体系统上的仿真结果验证了所提方法的有效性。", "motivation": "解决在矩阵李群上演化、具有未知动力学、执行器故障和有界干扰的系统的跟踪控制问题。", "method": "利用矩阵李群切丛的左不变性，提出了一组与李群结构内在兼容的神经网络权重学习规则，无需显式参数化。", "result": "通过李雅普诺夫直接方法，建立了所有误差信号的最终有界性，并通过仿真验证了方法的有效性。", "conclusion": "所提出的几何神经网络跟踪控制器能够有效处理在矩阵李群上演化、具有未知动力学、执行器故障和有界干扰的系统的跟踪控制问题，具有全局搜索最优权重的优势。"}}
{"id": "2505.05015", "title": "An Agent-Based Modeling Approach to Free-Text Keyboard Dynamics for Continuous Authentication", "authors": ["Roberto Dillon", "Arushi"], "abstract": "Continuous authentication systems leveraging free-text keyboard dynamics offer a promising additional layer of security in a multifactor authentication setup that can be used in a transparent way with no impact on user experience. This study investigates the efficacy of behavioral biometrics by employing an Agent-Based Model (ABM) to simulate diverse typing profiles across mechanical and membrane keyboards. Specifically, we generated synthetic keystroke data from five unique agents, capturing features related to dwell time, flight time, and error rates within sliding 5-second windows updated every second. Two machine learning approaches, One-Class Support Vector Machine (OC-SVM) and Random Forest (RF), were evaluated for user verification. Results revealed a stark contrast in performance: while One-Class SVM failed to differentiate individual users within each group, Random Forest achieved robust intra-keyboard user recognition (Accuracy > 0.7) but struggled to generalize across keyboards for the same user, highlighting the significant impact of keyboard hardware on typing behavior. These findings suggest that: (1) keyboard-specific user profiles may be necessary for reliable authentication, and (2) ensemble methods like RF outperform One-Class SVM in capturing fine-grained user-specific patterns.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)", "comments": "16 pages, 5 figures, 12 tables", "pdf_url": "https://arxiv.org/pdf/2505.05015.pdf", "abstract_url": "https://arxiv.org/abs/2505.05015", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Cryptography and Security (cs.CR)"], "matching_keywords": ["agent"], "AI": {"tldr": "本研究通过基于代理的模型（ABM）模拟不同键盘上的打字行为，评估了自由文本键盘动态在连续认证系统中的有效性。使用两种机器学习方法（OC-SVM和RF）进行用户验证，发现RF在键盘内用户识别上表现良好，但跨键盘识别效果不佳，表明键盘硬件对打字行为有显著影响。", "motivation": "解决在连续认证系统中，如何利用自由文本键盘动态作为额外的安全层，同时不影响用户体验的问题。", "method": "采用基于代理的模型（ABM）模拟机械和薄膜键盘上的多样化打字行为，生成合成击键数据，并使用OC-SVM和RF两种机器学习方法进行用户验证。", "result": "RF在键盘内用户识别上表现良好（准确率>0.7），但在跨键盘识别同一用户时表现不佳；OC-SVM则无法区分组内用户。", "conclusion": "研究结果表明：（1）可能需要针对特定键盘的用户配置文件以实现可靠认证；（2）集成方法如RF在捕捉用户特定细粒度模式上优于OC-SVM。"}}
{"id": "2505.05211", "title": "Incentive-Aware Machine Learning; Robustness, Fairness, Improvement & Causality", "authors": ["Chara Podimata"], "abstract": "The article explores the emerging domain of incentive-aware machine learning (ML), which focuses on algorithmic decision-making in contexts where individuals can strategically modify their inputs to influence outcomes. It categorizes the research into three perspectives: robustness, aiming to design models resilient to \"gaming\"; fairness, analyzing the societal impacts of such systems; and improvement/causality, recognizing situations where strategic actions lead to genuine personal or societal improvement. The paper introduces a unified framework encapsulating models for these perspectives, including offline, online, and causal settings, and highlights key challenges such as differentiating between gaming and improvement and addressing heterogeneity among agents. By synthesizing findings from diverse works, we outline theoretical advancements and practical solutions for robust, fair, and causally-informed incentive-aware ML systems.", "subjects": "Computer Science and Game Theory (cs.GT); Artificial Intelligence (cs.AI)", "comments": "This literature review was published in SIGEcom Exchanges in 2025", "pdf_url": "https://arxiv.org/pdf/2505.05211.pdf", "abstract_url": "https://arxiv.org/abs/2505.05211", "categories": ["Computer Science and Game Theory (cs.GT)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了激励感知机器学习（ML）的新兴领域，专注于在个体可以策略性修改输入以影响结果的背景下进行算法决策。研究分为三个视角：鲁棒性、公平性和改进/因果性，并提出了一个统一的框架来封装这些视角的模型。", "motivation": "解决在个体可能策略性行为影响机器学习系统决策时，如何设计鲁棒、公平且能促进真实改进的算法的问题。", "method": "通过分类研究视角（鲁棒性、公平性、改进/因果性）并引入一个统一的框架，包括离线、在线和因果设置，来探索激励感知ML。", "result": "提出了理论进展和实际解决方案，用于构建鲁棒、公平且因果 informed 的激励感知ML系统。", "conclusion": "激励感知ML领域需要进一步研究以区分策略性行为和真实改进，并处理代理之间的异质性，以实现更公正和有效的算法决策。"}}
{"id": "2505.04846", "title": "HiPerRAG: High-Performance Retrieval Augmented Generation for Scientific Insights", "authors": ["Ozan Gokdemir", "Carlo Siebenschuh", "Alexander Brace", "Azton Wells", "Brian Hsu", "Kyle Hippe", "Priyanka V. Setty", "Aswathy Ajith", "J. Gregory Pauloski", "Varuni Sastry", "Sam Foreman", "Huihuo Zheng", "Heng Ma", "Bharat Kale", "Nicholas Chia", "Thomas Gibbs", "Michael E. Papka", "Thomas Brettin", "Francis J. Alexander", "Anima Anandkumar", "Ian Foster", "Rick Stevens", "Venkatram Vishwanath", "Arvind Ramanathan"], "abstract": "The volume of scientific literature is growing exponentially, leading to underutilized discoveries, duplicated efforts, and limited cross-disciplinary collaboration. Retrieval Augmented Generation (RAG) offers a way to assist scientists by improving the factuality of Large Language Models (LLMs) in processing this influx of information. However, scaling RAG to handle millions of articles introduces significant challenges, including the high computational costs associated with parsing documents and embedding scientific knowledge, as well as the algorithmic complexity of aligning these representations with the nuanced semantics of scientific content. To address these issues, we introduce HiPerRAG, a RAG workflow powered by high performance computing (HPC) to index and retrieve knowledge from more than 3.6 million scientific articles. At its core are Oreo, a high-throughput model for multimodal document parsing, and ColTrast, a query-aware encoder fine-tuning algorithm that enhances retrieval accuracy by using contrastive learning and late-interaction techniques. HiPerRAG delivers robust performance on existing scientific question answering benchmarks and two new benchmarks introduced in this work, achieving 90% accuracy on SciQ and 76% on PubMedQA-outperforming both domain-specific models like PubMedGPT and commercial LLMs such as GPT-4. Scaling to thousands of GPUs on the Polaris, Sunspot, and Frontier supercomputers, HiPerRAG delivers million document-scale RAG workflows for unifying scientific knowledge and fostering interdisciplinary innovation.", "subjects": "Information Retrieval (cs.IR); Computational Engineering, Finance, and Science (cs.CE); Computation and Language (cs.CL); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)", "comments": "This paper has been accepted at the Platform for Advanced Scientific Computing Conference (PASC 25), June 16-18, 2025, Brugg-Windisch, Switzerland", "pdf_url": "https://arxiv.org/pdf/2505.04846.pdf", "abstract_url": "https://arxiv.org/abs/2505.04846", "categories": ["Information Retrieval (cs.IR)", "Computational Engineering, Finance, and Science (cs.CE)", "Computation and Language (cs.CL)", "Distributed, Parallel, and Cluster Computing (cs.DC)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "HiPerRAG是一种高性能的检索增强生成（RAG）工作流程，旨在通过高性能计算（HPC）处理超过360万篇科学文章，解决科学文献快速增长带来的挑战。它通过Oreo模型和ColTrast算法提高了检索准确性，在科学问答基准测试中表现出色。", "motivation": "科学文献的快速增长导致了许多发现未被充分利用、努力重复和跨学科合作有限的问题。HiPerRAG旨在通过改进大型语言模型（LLMs）在处理这些信息时的真实性来解决这些问题。", "method": "HiPerRAG采用高性能计算（HPC）来索引和检索科学知识，核心包括高吞吐量的多模态文档解析模型Oreo和通过对比学习及晚期交互技术提高检索准确性的查询感知编码器微调算法ColTrast。", "result": "HiPerRAG在现有的科学问答基准测试和两个新引入的基准测试中表现出色，分别在SciQ和PubMedQA上达到了90%和76%的准确率，超过了PubMedGPT等特定领域模型和GPT-4等商业LLMs。", "conclusion": "HiPerRAG通过扩展到数千个GPU，在Polaris、Sunspot和Frontier超级计算机上实现了百万文档规模的RAG工作流程，为统一科学知识和促进跨学科创新提供了强有力的工具。"}}
{"id": "2505.05283", "title": "Software Development Life Cycle Perspective: A Survey of Benchmarks for CodeLLMs and Agents", "authors": ["Kaixin Wang", "Tianlin Li", "Xiaoyu Zhang", "Chong Wang", "Weisong Sun", "Yang Liu", "Bin Shi"], "abstract": "Code large language models (CodeLLMs) and agents have shown great promise in tackling complex software engineering", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.05283.pdf", "abstract_url": "https://arxiv.org/abs/2505.05283", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文调查了代码大型语言模型（CodeLLMs）和代理在软件开发生命周期中的基准测试，探讨了它们在解决复杂软件工程问题中的潜力。", "motivation": "探讨CodeLLMs和代理在软件工程中的应用潜力，以及如何通过基准测试评估它们的性能。", "method": "通过调查现有的基准测试，分析CodeLLMs和代理在软件开发生命周期各个阶段的表现。", "result": "CodeLLMs和代理在解决复杂软件工程问题方面显示出巨大的潜力，但需要更多的基准测试来全面评估它们的性能。", "conclusion": "CodeLLMs和代理有望在软件工程领域发挥重要作用，但需要进一步的研究和基准测试来优化它们的应用。"}}
{"id": "2505.05262", "title": "Enhancing Cooperative Multi-Agent Reinforcement Learning with State Modelling and Adversarial Exploration", "authors": ["Andreas Kontogiannis", "Konstantinos Papathanasiou", "Yi Shen", "Giorgos Stamou", "Michael M. Zavlanos", "George Vouros"], "abstract": "Learning to cooperate in distributed partially observable environments with no communication abilities poses significant challenges for multi-agent deep reinforcement learning (MARL). This paper addresses key concerns in this domain, focusing on inferring state representations from individual agent observations and leveraging these representations to enhance agents' exploration and collaborative task execution policies. To this end, we propose a novel state modelling framework for cooperative MARL, where agents infer meaningful belief representations of the non-observable state, with respect to optimizing their own policies, while filtering redundant and less informative joint state information. Building upon this framework, we propose the MARL SMPE algorithm. In SMPE, agents enhance their own policy's discriminative abilities under partial observability, explicitly by incorporating their beliefs into the policy network, and implicitly by adopting an adversarial type of exploration policies which encourages agents to discover novel, high-value states while improving the discriminative abilities of others. Experimentally, we show that SMPE outperforms state-of-the-art MARL algorithms in complex fully cooperative tasks from the MPE, LBF, and RWARE benchmarks.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "Accepted (Poster) at ICML 2025", "pdf_url": "https://arxiv.org/pdf/2505.05262.pdf", "abstract_url": "https://arxiv.org/abs/2505.05262", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新颖的状态建模框架和MARL SMPE算法，用于在部分可观察的无通信分布式环境中增强多智能体深度强化学习的协作能力。通过推断非可观察状态的有意义信念表示，并结合对抗性探索策略，SMPE在MPE、LBF和RWARE基准测试中优于现有最先进的MARL算法。", "motivation": "解决在无通信能力的分布式部分可观察环境中，多智能体深度强化学习（MARL）协作学习面临的挑战，特别是从个体智能体观察中推断状态表示并利用这些表示增强探索和协作任务执行策略的问题。", "method": "提出了一种新颖的状态建模框架，智能体在其中推断非可观察状态的有意义信念表示，并基于此框架提出了MARL SMPE算法。SMPE通过将信念显式地纳入策略网络，并采用对抗性探索策略，增强策略在部分可观察性下的判别能力。", "result": "实验表明，SMPE在MPE、LBF和RWARE基准测试中的复杂完全协作任务上，性能优于现有最先进的MARL算法。", "conclusion": "通过状态建模和对抗性探索，SMPE算法有效提升了多智能体在部分可观察环境中的协作能力和任务执行效率，为MARL领域的研究和应用提供了新的思路和方法。"}}
