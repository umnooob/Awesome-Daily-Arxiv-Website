{"id": "2505.09630", "title": "Generative diffusion model surrogates for mechanistic agent-based biological models", "authors": ["Tien Comlekoglu", "J. Quetzalcóatl Toledo-Marín", "Douglas W. DeSimone", "Shayn M. Peirce", "Geoffrey Fox", "James A. Glazier"], "abstract": "Mechanistic, multicellular, agent-based models are commonly used to investigate tissue, organ, and organism-scale biology at single-cell resolution. The Cellular-Potts Model (CPM) is a powerful and popular framework for developing and interrogating these models. CPMs become computationally expensive at large space- and time- scales making application and investigation of developed models difficult. Surrogate models may allow for the accelerated evaluation of CPMs of complex biological systems. However, the stochastic nature of these models means each set of parameters may give rise to different model configurations, complicating surrogate model development. In this work, we leverage denoising diffusion probabilistic models to train a generative AI surrogate of a CPM used to investigate \\textit{in vitro} vasculogenesis. We describe the use of an image classifier to learn the characteristics that define unique areas of a 2-dimensional parameter space. We then apply this classifier to aid in surrogate model selection and verification. Our CPM model surrogate generates model configurations 20,000 timesteps ahead of a reference configuration and demonstrates approximately a 22x reduction in computational time as compared to native code execution. Our work represents a step towards the implementation of DDPMs to develop digital twins of stochastic biological systems.", "subjects": "Quantitative Methods (q-bio.QM); Computer Vision and Pattern Recognition (cs.CV); Emerging Technologies (cs.ET); Performance (cs.PF)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.09630.pdf", "abstract_url": "https://arxiv.org/abs/2505.09630", "categories": ["Quantitative Methods (q-bio.QM)", "Computer Vision and Pattern Recognition (cs.CV)", "Emerging Technologies (cs.ET)", "Performance (cs.PF)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出使用生成扩散模型作为基于代理的机械生物模型的替代模型，以加速对复杂生物系统的评估，特别是在血管生成的体外研究中。", "motivation": "基于代理的机械模型，如细胞-波茨模型（CPM），在研究组织、器官和生物体尺度上的单细胞分辨率生物学时计算成本高昂，难以在大空间和时间尺度上应用和调查。", "method": "利用去噪扩散概率模型（DDPM）训练生成AI替代模型，结合图像分类器学习二维参数空间中独特区域的特征，以辅助替代模型的选择和验证。", "result": "替代模型能够生成比参考配置提前20,000个时间步的模型配置，计算时间比原生代码执行减少约22倍。", "conclusion": "这项工作代表了向实现DDPMs开发随机生物系统数字孪生的一步。"}}
{"id": "2505.10533", "title": "Enhancing Multi-Image Question Answering via Submodular Subset Selection", "authors": ["Aaryan Sharma", "Shivansh Gupta", "Samar Agarwal", "Vishak Prasad C.", "Ganesh Ramakrishnan"], "abstract": "Large multimodal models (LMMs) have achieved high performance in vision-language tasks involving single image but they struggle when presented with a collection of multiple images (Multiple Image Question Answering scenario). These tasks, which involve reasoning over large number of images, present issues in scalability (with increasing number of images) and retrieval performance. In this work, we propose an enhancement for retriever framework introduced in MIRAGE model using submodular subset selection techniques. Our method leverages query-aware submodular functions, such as GraphCut, to pre-select a subset of semantically relevant images before main retrieval component. We demonstrate that using anchor-based queries and augmenting the data improves submodular-retriever pipeline effectiveness, particularly in large haystack sizes.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.10533.pdf", "abstract_url": "https://arxiv.org/abs/2505.10533", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "通过子模子集选择增强多图像问答能力", "motivation": "大型多模态模型（LMMs）在涉及单图像的视觉语言任务中表现优异，但在面对多图像集合（多图像问答场景）时表现不佳。这些任务涉及对大量图像进行推理，存在可扩展性（随着图像数量增加）和检索性能的问题。", "method": "我们提出了一种改进MIRAGE模型中引入的检索器框架的方法，使用子模子集选择技术。我们的方法利用查询感知的子模函数，如GraphCut，在主检索组件之前预选一个语义相关的图像子集。", "result": "我们证明了使用基于锚点的查询和增强数据可以提高子模检索器管道的有效性，特别是在大型干草堆大小的情况下。", "conclusion": "通过子模子集选择技术，我们能够有效地提升多图像问答任务的性能，尤其是在处理大量图像时的可扩展性和检索效率。"}}
{"id": "2505.10257", "title": "Sage Deer: A Super-Aligned Driving Generalist Is Your Copilot", "authors": ["Hao Lu", "Jiaqi Tang", "Jiyao Wang", "Yunfan LU", "Xu Cao", "Qingyong Hu", "Yin Wang", "Yuting Zhang", "Tianxin Xie", "Yunpeng Zhang", "Yong Chen", "Jiayu.Gao", "Bin Huang", "Dengbo He", "Shuiguang Deng", "Hao Chen", "Ying-Cong Chen"], "abstract": "The intelligent driving cockpit, an important part of intelligent driving, needs to match different users' comfort, interaction, and safety needs. This paper aims to build a  Super-Aligned and GEneralist DRiving agent, SAGE DeeR. Sage Deer achieves three highlights: (1) Super alignment: It achieves different reactions according to different people's preferences and biases. (2) Generalist: It can understand the multi-view and multi-mode inputs to reason the user's physiological indicators, facial emotions, hand movements, body movements, driving scenarios, and behavioral decisions. (3) Self-Eliciting: It can elicit implicit thought chains in the language space to further increase generalist and super-aligned abilities. Besides, we collected multiple data sets and built a large-scale benchmark. This benchmark measures the deer's perceptual decision-making ability and the super alignment's accuracy.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.10257.pdf", "abstract_url": "https://arxiv.org/abs/2505.10257", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了Sage Deer，一个超级对齐和通用的驾驶代理，旨在满足智能驾驶座舱中不同用户的舒适、互动和安全需求。Sage Deer通过超级对齐、通用能力和自我激发三大亮点，实现了根据个人偏好和偏见的反应、理解多视角多模式输入以推理用户生理指标、面部情绪、手部动作、身体动作、驾驶场景和行为决策，以及在语言空间中激发隐式思维链以进一步增强通用和超级对齐能力。此外，研究还收集了多个数据集并建立了一个大规模基准，用于测量Deer的感知决策能力和超级对齐的准确性。", "motivation": "解决智能驾驶座舱中匹配不同用户舒适、互动和安全需求的问题", "method": "构建超级对齐和通用驾驶代理Sage Deer，实现超级对齐、通用能力和自我激发", "result": "Sage Deer能够根据个人偏好和偏见做出反应，理解多视角多模式输入，并在语言空间中激发隐式思维链", "conclusion": "Sage Deer作为一个超级对齐和通用的驾驶代理，能够有效满足智能驾驶座舱中的多样化需求，其通过收集的数据集和建立的基准为未来的研究提供了重要的参考和评估标准。"}}
{"id": "2505.09852", "title": "Do Large Language Models Know Conflict? Investigating Parametric vs. Non-Parametric Knowledge of LLMs for Conflict Forecasting", "authors": ["Apollinaire Poli Nemkova", "Sarath Chandra Lingareddy", "Sagnik Ray Choudhury", "Mark V. Albert"], "abstract": "Large Language Models (LLMs) have shown impressive performance across natural language tasks, but their ability to forecast violent conflict remains underexplored. We investigate whether LLMs possess meaningful parametric knowledge-encoded in their pretrained weights-to predict conflict escalation and fatalities without external data. This is critical for early warning systems, humanitarian planning, and policy-making. We compare this parametric knowledge with non-parametric capabilities, where LLMs access structured and unstructured context from conflict datasets (e.g., ACLED, GDELT) and recent news reports via Retrieval-Augmented Generation (RAG). Incorporating external information could enhance model performance by providing up-to-date context otherwise missing from pretrained weights. Our two-part evaluation framework spans 2020-2024 across conflict-prone regions in the Horn of Africa and the Middle East. In the parametric setting, LLMs predict conflict trends and fatalities relying only on pretrained knowledge. In the non-parametric setting, models receive summaries of recent conflict events, indicators, and geopolitical developments. We compare predicted conflict trend labels (e.g., Escalate, Stable Conflict, De-escalate, Peace) and fatalities against historical data. Our findings highlight the strengths and limitations of LLMs for conflict forecasting and the benefits of augmenting them with structured external knowledge.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.09852.pdf", "abstract_url": "https://arxiv.org/abs/2505.09852", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文探讨了大型语言模型（LLMs）在预测暴力冲突方面的能力，比较了其参数化知识与非参数化知识的表现，并评估了结合外部信息对模型性能的影响。", "motivation": "解决LLMs在预测冲突升级和 fatalities 方面的能力未被充分探索的问题，这对于早期预警系统、人道主义规划和政策制定至关重要。", "method": "通过两部分评估框架，比较LLMs在仅依赖预训练知识（参数化设置）和结合外部冲突数据集及新闻报告（非参数化设置）下的表现。", "result": "研究结果突出了LLMs在冲突预测中的优势和局限性，以及结合结构化外部知识的好处。", "conclusion": "LLMs在冲突预测方面具有一定的潜力，但结合外部信息可以显著提升其性能，这对于实际应用具有重要意义。"}}
{"id": "2505.10063", "title": "CAFE: Retrieval Head-based Coarse-to-Fine Information Seeking to Enhance Multi-Document QA Capability", "authors": ["Han Peng", "Jinhao Jiang", "Zican Dong", "Wayne Xin Zhao", "Lei Fang"], "abstract": "Advancements in Large Language Models (LLMs) have extended their input context length, yet they still struggle with retrieval and reasoning in long-context inputs. Existing methods propose to utilize the prompt strategy and retrieval head to alleviate this limitation. However, they still face challenges in balancing retrieval precision and recall, impacting their efficacy in answering questions. To address this, we introduce $\\textbf{CAFE}$, a two-stage coarse-to-fine method to enhance multi-document question-answering capacities. By gradually eliminating the negative impacts of background and distracting documents, CAFE makes the responses more reliant on the evidence documents. Initially, a coarse-grained filtering method leverages retrieval heads to identify and rank relevant documents. Then, a fine-grained steering method guides attention to the most relevant content. Experiments across benchmarks show CAFE outperforms baselines, achieving up to 22.1% and 13.7% SubEM improvement over SFT and RAG methods on the Mistral model, respectively.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.10063.pdf", "abstract_url": "https://arxiv.org/abs/2505.10063", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "CAFE是一种基于检索头的粗到细信息寻求方法，旨在增强多文档问答能力，通过两阶段方法减少背景和干扰文档的负面影响，使回答更依赖证据文档。", "motivation": "大型语言模型在处理长上下文输入时的检索和推理能力仍有局限，现有方法在平衡检索精度和召回率方面存在挑战，影响了问答效果。", "method": "CAFE采用两阶段方法：粗粒度过滤利用检索头识别和排名相关文档；细粒度引导方法指导关注最相关内容。", "result": "在多个基准测试中，CAFE表现优于基线方法，在Mistral模型上分别比SFT和RAG方法提高了22.1%和13.7%的SubEM。", "conclusion": "CAFE通过粗到细的信息寻求策略，有效提升了多文档问答的能力，为处理长上下文输入提供了新的解决方案。"}}
{"id": "2505.09945", "title": "Personalizing Large Language Models using Retrieval Augmented Generation and Knowledge Graph", "authors": ["Deeksha Prahlad", "Chanhee Lee", "Dongha Kim", "Hokeun Kim"], "abstract": "The advent of large language models (LLMs) has allowed numerous applications, including the generation of queried responses, to be leveraged in chatbots and other conversational assistants. Being trained on a plethora of data, LLMs often undergo high levels of over-fitting, resulting in the generation of extra and incorrect data, thus causing hallucinations in output generation. One of the root causes of such problems is the lack of timely, factual, and personalized information fed to the LLM. In this paper, we propose an approach to address these problems by introducing retrieval augmented generation (RAG) using knowledge graphs (KGs) to assist the LLM in personalized response generation tailored to the users. KGs have the advantage of storing continuously updated factual information in a structured way. While our KGs can be used for a variety of frequently updated personal data, such as calendar, contact, and location data, we focus on calendar data in this paper. Our experimental results show that our approach works significantly better in understanding personal information and generating accurate responses compared to the baseline LLMs using personal data as text inputs, with a moderate reduction in response time.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "To appear in the Companion Proceedings of the ACM Web Conference 2025 (WWW Companion '25)", "pdf_url": "https://arxiv.org/pdf/2505.09945.pdf", "abstract_url": "https://arxiv.org/abs/2505.09945", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种使用检索增强生成（RAG）和知识图谱（KG）来个性化大型语言模型（LLM）的方法，旨在解决LLM在生成响应时因缺乏及时、事实和个性化信息而产生的幻觉问题。通过将KG中的结构化数据与LLM结合，特别是在日历数据上的应用，实验结果表明该方法在理解个人信息和生成准确响应方面显著优于基线LLM，同时响应时间略有减少。", "motivation": "大型语言模型（LLM）在生成查询响应时，由于缺乏及时、事实和个性化的信息，常常产生过度拟合和错误数据，导致输出中的幻觉问题。", "method": "提出了一种结合检索增强生成（RAG）和知识图谱（KG）的方法，利用KG存储的结构化和持续更新的个人信息（如日历数据）来辅助LLM生成个性化响应。", "result": "实验结果显示，与直接将个人数据作为文本输入的基线LLM相比，该方法在理解个人信息和生成准确响应方面表现显著更好，响应时间略有减少。", "conclusion": "通过结合RAG和KG，可以有效地提升LLM在生成个性化响应时的准确性和效率，为解决LLM的幻觉问题提供了新的思路。"}}
{"id": "2505.10089", "title": "XRAG: Cross-lingual Retrieval-Augmented Generation", "authors": ["Wei Liu", "Sony Trenous", "Leonardo F. R. Ribeiro", "Bill Byrne", "Felix Hieber"], "abstract": "We propose XRAG, a novel benchmark designed to evaluate the generation abilities of LLMs in cross-lingual Retrieval-Augmented Generation (RAG) settings where the user language does not match the retrieval results. XRAG is constructed from recent news articles to ensure that its questions require external knowledge to be answered. It covers the real-world scenarios of monolingual and multilingual retrieval, and provides relevancy annotations for each retrieved document. Our novel dataset construction pipeline results in questions that require complex reasoning, as evidenced by the significant gap between human and LLM performance. Consequently, XRAG serves as a valuable benchmark for studying LLM reasoning abilities, even before considering the additional cross-lingual complexity. Experimental results on five LLMs uncover two previously unreported challenges in cross-lingual RAG: 1) in the monolingual retrieval setting, all evaluated models struggle with response language correctness; 2) in the multilingual retrieval setting, the main challenge lies in reasoning over retrieved information across languages rather than generation of non-English text.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.10089.pdf", "abstract_url": "https://arxiv.org/abs/2505.10089", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "XRAG是一个新颖的基准测试，旨在评估LLMs在跨语言检索增强生成（RAG）设置中的生成能力，其中用户语言与检索结果不匹配。XRAG基于最近的新闻文章构建，确保其问题需要外部知识来回答。它涵盖了单语和多语检索的现实场景，并为每个检索到的文档提供相关性注释。", "motivation": "解决在跨语言检索增强生成（RAG）设置中，当用户语言与检索结果不匹配时，LLMs的生成能力评估问题。", "method": "构建XRAG基准测试，基于最近的新闻文章，设计需要外部知识回答的问题，涵盖单语和多语检索场景，并提供文档相关性注释。", "result": "在五种LLMs上的实验结果显示了两项之前未报告的跨语言RAG挑战：1）在单语检索设置中，所有评估模型在响应语言正确性上表现不佳；2）在多语检索设置中，主要挑战在于跨语言信息的推理而非非英语文本的生成。", "conclusion": "XRAG作为一个有价值的基准测试，不仅用于研究LLMs的推理能力，还揭示了跨语言RAG中的新挑战，为未来的研究提供了方向。"}}
{"id": "2505.10143", "title": "GE-Chat: A Graph Enhanced RAG Framework for Evidential Response Generation of LLMs", "authors": ["Longchao Da", "Parth Mitesh Shah", "Kuan-Ru Liou", "Jiaxing Zhang", "Hua Wei"], "abstract": "Large Language Models are now key assistants in human decision-making processes. However, a common note always seems to follow: \"LLMs can make mistakes. Be careful with important info.\" This points to the reality that not all outputs from LLMs are dependable, and users must evaluate them manually. The challenge deepens as hallucinated responses, often presented with seemingly plausible explanations, create complications and raise trust issues among users. To tackle such issue, this paper proposes GE-Chat, a knowledge Graph enhanced retrieval-augmented generation framework to provide Evidence-based response generation. Specifically, when the user uploads a material document, a knowledge graph will be created, which helps construct a retrieval-augmented agent, enhancing the agent's responses with additional knowledge beyond its training corpus. Then we leverage Chain-of-Thought (CoT) logic generation, n-hop sub-graph searching, and entailment-based sentence generation to realize accurate evidence retrieval. We demonstrate that our method improves the existing models' performance in terms of identifying the exact evidence in a free-form context, providing a reliable way to examine the resources of LLM's conclusion and help with the judgment of the trustworthiness.", "subjects": "Computation and Language (cs.CL)", "comments": "5 pages, 4 figures, accepted to IJCAI2025 demo track", "pdf_url": "https://arxiv.org/pdf/2505.10143.pdf", "abstract_url": "https://arxiv.org/abs/2505.10143", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文提出GE-Chat，一个基于知识图谱增强的检索增强生成框架，旨在为大型语言模型提供基于证据的响应生成，以提高其输出的可靠性和可信度。", "motivation": "大型语言模型在人类决策过程中扮演重要角色，但其输出可能存在错误或幻觉，导致用户需要手动评估，这引发了信任问题。", "method": "通过构建知识图谱和检索增强代理，结合Chain-of-Thought逻辑生成、n跳子图搜索和基于蕴涵的句子生成，实现精确的证据检索。", "result": "该方法在自由形式上下文中准确识别证据方面提高了现有模型的性能，为检查大型语言模型结论的来源和判断其可信度提供了可靠途径。", "conclusion": "GE-Chat框架通过知识图谱和检索增强技术，显著提升了大型语言模型生成响应的证据支持，增强了用户对模型输出的信任。"}}
{"id": "2505.10218", "title": "RAIDEN-R1: Improving Role-awareness of LLMs via GRPO with Verifiable Reward", "authors": ["Zongsheng Wang", "Kaili Sun", "Bowen Wu", "Qun Yu", "Ying Li", "Baoxun Wang"], "abstract": "Role-playing conversational agents (RPCAs) face persistent challenges in maintaining role consistency. To address this, we propose RAIDEN-R1, a novel reinforcement learning framework that integrates Verifiable Role-Awareness Reward (VRAR). The method introduces both singular and multi-term mining strategies to generate quantifiable rewards by assessing role-specific keys. Additionally, we construct a high-quality, role-aware Chain-of-Thought dataset through multi-LLM collaboration, and implement experiments to enhance reasoning coherence. Experiments on the RAIDEN benchmark demonstrate RAIDEN-R1's superiority: our 14B-GRPO model achieves 88.04% and 88.65% accuracy on Script-Based Knowledge and Conversation Memory metrics, respectively, outperforming baseline models while maintaining robustness. Case analyses further reveal the model's enhanced ability to resolve conflicting contextual cues and sustain first-person narrative consistency. This work bridges the non-quantifiability gap in RPCA training and provides insights into role-aware reasoning patterns, advancing the development of RPCAs.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.10218.pdf", "abstract_url": "https://arxiv.org/abs/2505.10218", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "RAIDEN-R1是一种新型强化学习框架，通过整合可验证的角色意识奖励（VRAR）来提高角色扮演对话代理（RPCAs）的角色一致性。该方法引入了单术语和多术语挖掘策略，通过评估角色特定键生成可量化的奖励。此外，通过多LLM协作构建了一个高质量的角色意识思维链数据集，并实施了实验以增强推理连贯性。在RAIDEN基准测试中，RAIDEN-R1表现出色，14B-GRPO模型在基于脚本的知识和对话记忆指标上分别达到了88.04%和88.65%的准确率，优于基线模型，同时保持了鲁棒性。案例分析进一步揭示了模型在解决冲突上下文线索和维持第一人称叙事一致性方面的增强能力。", "motivation": "角色扮演对话代理（RPCAs）在保持角色一致性方面面临持续挑战。为了解决这一问题，提出了RAIDEN-R1框架，旨在通过可验证的角色意识奖励（VRAR）来提高RPCAs的角色意识。", "method": "RAIDEN-R1采用了一种新颖的强化学习框架，整合了VRAR，并引入了单术语和多术语挖掘策略来生成可量化的奖励。此外，通过多LLM协作构建了一个高质量的角色意识思维链数据集，以增强推理连贯性。", "result": "在RAIDEN基准测试中，14B-GRPO模型在基于脚本的知识和对话记忆指标上分别达到了88.04%和88.65%的准确率，优于基线模型。案例分析显示，模型在解决冲突上下文线索和维持第一人称叙事一致性方面表现出色。", "conclusion": "RAIDEN-R1工作填补了RPCA训练中的不可量化性空白，为角色意识推理模式提供了见解，推动了RPCAs的发展。"}}
{"id": "2505.10413", "title": "Hierarchical Document Refinement for Long-context Retrieval-augmented Generation", "authors": ["Jiajie Jin", "Xiaoxi Li", "Guanting Dong", "Yuyao Zhang", "Yutao Zhu", "Yongkang Wu", "Zhonghua Li", "Qi Ye", "Zhicheng Dou"], "abstract": "Real-world RAG applications often encounter long-context input scenarios, where redundant information and noise results in higher inference costs and reduced performance. To address these challenges, we propose LongRefiner, an efficient plug-and-play refiner that leverages the inherent structural characteristics of long documents. LongRefiner employs dual-level query analysis, hierarchical document structuring, and adaptive refinement through multi-task learning on a single foundation model. Experiments on seven QA datasets demonstrate that LongRefiner achieves competitive performance in various scenarios while using 10x fewer computational costs and latency compared to the best baseline. Further analysis validates that LongRefiner is scalable, efficient, and effective, providing practical insights for real-world long-text RAG applications. Our code is available at", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.10413.pdf", "abstract_url": "https://arxiv.org/abs/2505.10413", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出LongRefiner，一种高效的即插即用优化器，用于解决长上下文检索增强生成（RAG）应用中的冗余信息和噪声问题，通过双级查询分析、层次化文档结构和自适应优化，显著降低计算成本和延迟。", "motivation": "解决长上下文输入场景中冗余信息和噪声导致的高推理成本和性能下降问题。", "method": "采用双级查询分析、层次化文档结构和基于多任务学习的自适应优化，利用单一基础模型实现。", "result": "在七个QA数据集上的实验表明，LongRefiner在多种场景下达到竞争性性能，同时计算成本和延迟比最佳基线减少10倍。", "conclusion": "LongRefiner具有可扩展性、高效性和有效性，为实际长文本RAG应用提供了实用见解。"}}
{"id": "2505.10493", "title": "CL-RAG: Bridging the Gap in Retrieval-Augmented Generation with Curriculum Learning", "authors": ["Shaohan Wang", "Licheng Zhang", "Zheren Fu", "Zhendong Mao"], "abstract": "Retrieval-Augmented Generation (RAG) is an effective method to enhance the capabilities of large language models (LLMs). Existing methods focus on optimizing the retriever or generator in the RAG system by directly utilizing the top-k retrieved documents. However, the documents effectiveness are various significantly across user queries, i.e. some documents provide valuable knowledge while others totally lack critical information. It hinders the retriever and generator's adaptation during training. Inspired by human cognitive learning, curriculum learning trains models using samples progressing from easy to difficult, thus enhancing their generalization ability, and we integrate this effective paradigm to the training of the RAG system. In this paper, we propose a multi-stage Curriculum Learning based RAG system training framework, named CL-RAG. We first construct training data with multiple difficulty levels for the retriever and generator separately through sample evolution. Then, we train the model in stages based on the curriculum learning approach, thereby optimizing the overall performance and generalization of the RAG system more effectively. Our CL-RAG framework demonstrates consistent effectiveness across four open-domain QA datasets, achieving performance gains of 2% to 4% over multiple advanced methods.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.10493.pdf", "abstract_url": "https://arxiv.org/abs/2505.10493", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "CL-RAG是一种基于课程学习的检索增强生成系统训练框架，旨在通过从易到难的样本训练提升RAG系统的整体性能和泛化能力。", "motivation": "现有的RAG方法直接利用检索到的前k个文档，但这些文档的有效性因查询而异，影响了检索器和生成器的训练适应。", "method": "通过样本进化构建多难度级别的训练数据，并采用课程学习方法分阶段训练模型。", "result": "在四个开放域QA数据集上，CL-RAG框架相比多种先进方法实现了2%到4%的性能提升。", "conclusion": "CL-RAG框架通过课程学习有效提升了RAG系统的性能和泛化能力，展示了在不同数据集上的一致有效性。"}}
{"id": "2505.09901", "title": "Comparing Exploration-Exploitation Strategies of LLMs and Humans: Insights from Standard Multi-armed Bandit Tasks", "authors": ["Ziyuan Zhang", "Darcy Wang", "Ningyuan Chen", "Rodrigo Mansur", "Vahid Sarhangian"], "abstract": "Large language models (LLMs) are increasingly used to simulate or automate human behavior in complex sequential decision-making tasks. A natural question is then whether LLMs exhibit similar decision-making behavior to humans, and can achieve comparable (or superior) performance. In this work, we focus on the exploration-exploitation (E&E) tradeoff, a fundamental aspect of dynamic decision-making under uncertainty. We employ canonical multi-armed bandit (MAB) tasks introduced in the cognitive science and psychiatry literature to conduct a comparative study of the E&E strategies of LLMs, humans, and MAB algorithms. We use interpretable choice models to capture the E&E strategies of the agents and investigate how explicit reasoning, through both prompting strategies and reasoning-enhanced models, shapes LLM decision-making. We find that reasoning shifts LLMs toward more human-like behavior, characterized by a mix of random and directed exploration. In simple stationary tasks, reasoning-enabled LLMs exhibit similar levels of random and directed exploration compared to humans. However, in more complex, non-stationary environments, LLMs struggle to match human adaptability, particularly in effective directed exploration, despite achieving similar regret in certain scenarios. Our findings highlight both the promise and limits of LLMs as simulators of human behavior and tools for automated decision-making and point to potential areas of improvements.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.09901.pdf", "abstract_url": "https://arxiv.org/abs/2505.09901", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过标准多臂老虎机任务比较了大型语言模型（LLMs）与人类在探索-利用（E&E）策略上的差异，发现推理能力使LLMs更接近人类行为，但在复杂非静态环境中LLMs的适应性仍有限。", "motivation": "探讨LLMs在复杂序列决策任务中是否能模拟或自动化人类行为，特别是探索-利用（E&E）权衡这一动态决策中的基本方面。", "method": "使用认知科学和精神病学文献中引入的标准多臂老虎机（MAB）任务，通过可解释的选择模型比较LLMs、人类和MAB算法的E&E策略。", "result": "推理能力使LLMs更接近人类行为，表现为随机和定向探索的混合；在简单静态任务中，LLMs与人类的探索水平相似，但在复杂非静态环境中LLMs的适应性较差。", "conclusion": "LLMs作为人类行为模拟器和自动化决策工具既有前景也有局限，指出了潜在的改进方向。"}}
{"id": "2505.10117", "title": "Learning Virtual Machine Scheduling in Cloud Computing through Language Agents", "authors": ["JieHao Wu", "Ziwei Wang", "Junjie Sheng", "Wenhao Li", "Xiangfei Wang", "Jun Luo"], "abstract": "In cloud services, virtual machine (VM) scheduling is a typical Online Dynamic Multidimensional Bin Packing (ODMBP) problem, characterized by large-scale complexity and fluctuating demands. Traditional optimization methods struggle to adapt to real-time changes, domain-expert-designed heuristic approaches suffer from rigid strategies, and existing learning-based methods often lack generalizability and interpretability. To address these limitations, this paper proposes a hierarchical language agent framework named MiCo, which provides a large language model (LLM)-driven heuristic design paradigm for solving ODMBP. Specifically, ODMBP is formulated as a Semi-Markov Decision Process with Options (SMDP-Option), enabling dynamic scheduling through a two-stage architecture, i.e., Option Miner and Option Composer. Option Miner utilizes LLMs to discover diverse and useful non-context-aware strategies by interacting with constructed environments. Option Composer employs LLMs to discover a composing strategy that integrates the non-context-aware strategies with the contextual ones. Extensive experiments on real-world enterprise datasets demonstrate that MiCo achieves a 96.9\\% competitive ratio in large-scale scenarios involving more than 10,000 virtual machines. It maintains high performance even under nonstationary request flows and diverse configurations, thus validating its effectiveness in complex and large-scale cloud environments.", "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.10117.pdf", "abstract_url": "https://arxiv.org/abs/2505.10117", "categories": ["Machine Learning (cs.LG)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为MiCo的分层语言代理框架，利用大型语言模型（LLM）驱动的启发式设计范式来解决云服务中的虚拟机（VM）调度问题，即在线动态多维装箱问题（ODMBP）。通过两阶段架构（选项挖掘器和选项组合器），MiCo在大型复杂场景中实现了96.9%的竞争比，验证了其在复杂和大规模云环境中的有效性。", "motivation": "云服务中的虚拟机调度是一个典型的在线动态多维装箱问题（ODMBP），具有大规模复杂性和需求波动的特点。传统的优化方法难以适应实时变化，领域专家设计的启发式方法策略僵化，现有的基于学习的方法往往缺乏通用性和可解释性。", "method": "本文提出了一个名为MiCo的分层语言代理框架，将ODMBP表述为带有选项的半马尔可夫决策过程（SMDP-Option），通过两阶段架构（选项挖掘器和选项组合器）实现动态调度。选项挖掘器利用LLM通过与构建的环境交互来发现多样且有用的非上下文感知策略；选项组合器则利用LLM发现一种组合策略，将非上下文感知策略与上下文感知策略结合起来。", "result": "在涉及超过10,000个虚拟机的真实世界企业数据集上的大量实验表明，MiCo在大型场景中实现了96.9%的竞争比。即使在非平稳请求流和多样化配置下，MiCo仍保持高性能。", "conclusion": "MiCo框架在复杂和大规模的云环境中表现出了高效性，不仅解决了传统方法和现有学习方法的局限性，还通过LLM驱动的启发式设计范式为ODMBP问题提供了新的解决方案。"}}
{"id": "2505.10543", "title": "Towards a Deeper Understanding of Reasoning Capabilities in Large Language Models", "authors": ["Annie Wong", "Thomas Bäck", "Aske Plaat", "Niki van Stein", "Anna V. Kononova"], "abstract": "While large language models demonstrate impressive performance on static benchmarks, the true potential of large language models as self-learning and reasoning agents in dynamic environments remains unclear. This study systematically evaluates the efficacy of self-reflection, heuristic mutation, and planning as prompting techniques to test the adaptive capabilities of agents. We conduct experiments with various open-source language models in dynamic environments and find that larger models generally outperform smaller ones, but that strategic prompting can close this performance gap. Second, a too-long prompt can negatively impact smaller models on basic reactive tasks, while larger models show more robust behaviour. Third, advanced prompting techniques primarily benefit smaller models on complex games, but offer less improvement for already high-performing large language models. Yet, we find that advanced reasoning methods yield highly variable outcomes: while capable of significantly improving performance when reasoning and decision-making align, they also introduce instability and can lead to big performance drops. Compared to human performance, our findings reveal little evidence of true emergent reasoning. Instead, large language model performance exhibits persistent limitations in crucial areas such as planning, reasoning, and spatial coordination, suggesting that current-generation large language models still suffer fundamental shortcomings that may not be fully overcome through self-reflective prompting alone. Reasoning is a multi-faceted task, and while reasoning methods like Chain of thought improves multi-step reasoning on math word problems, our findings using dynamic benchmarks highlight important shortcomings in general reasoning capabilities, indicating a need to move beyond static benchmarks to capture the complexity of reasoning.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.10543.pdf", "abstract_url": "https://arxiv.org/abs/2505.10543", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过系统评估自我反思、启发式变异和规划等提示技术，探讨了大型语言模型在动态环境中的自适应能力。研究发现，尽管较大模型通常表现更优，但策略性提示可以缩小性能差距。然而，高级提示技术对较小模型在复杂任务中更有益，而对高性能大型模型改善有限。研究还揭示了大型语言模型在规划、推理和空间协调等关键领域存在持续限制，表明当前一代模型仍存在基本缺陷，仅通过自我反思提示可能无法完全克服。", "motivation": "探讨大型语言模型作为自学习和推理代理在动态环境中的真实潜力，以及当前模型在推理能力方面的局限性。", "method": "使用自我反思、启发式变异和规划等提示技术，在动态环境中对各种开源语言模型进行实验评估。", "result": "较大模型通常表现更优，但策略性提示可以缩小性能差距；高级提示技术对较小模型在复杂任务中更有益；大型语言模型在关键推理领域存在持续限制。", "conclusion": "当前一代大型语言模型在推理能力方面仍存在基本缺陷，需要超越静态基准以捕捉推理的复杂性。"}}
{"id": "2505.09737", "title": "General Dynamic Goal Recognition", "authors": ["Osher Elhadad", "Reuth Mirsky"], "abstract": "Understanding an agent's intent through its behavior is essential in human-robot interaction, interactive AI systems, and multi-agent collaborations. This task, known as Goal Recognition (GR), poses significant challenges in dynamic environments where goals are numerous and constantly evolving. Traditional GR methods, designed for a predefined set of goals, often struggle to adapt to these dynamic scenarios. To address this limitation, we introduce the General Dynamic GR problem - a broader definition of GR - aimed at enabling real-time GR systems and fostering further research in this area. Expanding on this foundation, this paper employs a model-free goal-conditioned RL approach to enable fast adaptation for GR across various changing tasks.", "subjects": "Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": "Accepted for publication at Generalization in Planning (GenPlan) as part of AAAI 2025 workshops", "pdf_url": "https://arxiv.org/pdf/2505.09737.pdf", "abstract_url": "https://arxiv.org/abs/2505.09737", "categories": ["Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了通用动态目标识别（General Dynamic GR）问题，旨在解决动态环境中目标识别（GR）的挑战，提出了一种无模型的目标条件强化学习方法，以实现快速适应各种变化的任务。", "motivation": "在动态环境中，目标众多且不断变化，传统的目标识别方法难以适应。本文旨在解决这一问题，推动实时GR系统的发展和相关研究的深入。", "method": "采用无模型的目标条件强化学习（RL）方法，以实现对不同变化任务的快速适应。", "result": "提出了一种更广泛的目标识别定义，即通用动态GR问题，并通过实验验证了所提方法的有效性。", "conclusion": "本文的工作为动态环境中的目标识别提供了新的视角和方法，有望促进人机交互、交互式AI系统和多智能体协作等领域的发展。"}}
{"id": "2505.09787", "title": "A Multimodal Multi-Agent Framework for Radiology Report Generation", "authors": ["Ziruo Yi", "Ting Xiao", "Mark V. Albert"], "abstract": "Radiology report generation (RRG) aims to automatically produce diagnostic reports from medical images, with the potential to enhance clinical workflows and reduce radiologists' workload. While recent approaches leveraging multimodal large language models (MLLMs) and retrieval-augmented generation (RAG) have achieved strong results, they continue to face challenges such as factual inconsistency, hallucination, and cross-modal misalignment. We propose a multimodal multi-agent framework for RRG that aligns with the stepwise clinical reasoning workflow, where task-specific agents handle retrieval, draft generation, visual analysis, refinement, and synthesis. Experimental results demonstrate that our approach outperforms a strong baseline in both automatic metrics and LLM-based evaluations, producing more accurate, structured, and interpretable reports. This work highlights the potential of clinically aligned multi-agent frameworks to support explainable and trustworthy clinical AI applications.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.09787.pdf", "abstract_url": "https://arxiv.org/abs/2505.09787", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文提出了一种多模态多代理框架，用于放射学报告生成，旨在通过模拟临床推理流程来提高报告的准确性和可解释性。", "motivation": "解决放射学报告生成中的事实不一致、幻觉和跨模态不对齐等问题，以增强临床工作流程并减少放射科医生的工作量。", "method": "采用多模态多代理框架，包括检索、草稿生成、视觉分析、精炼和合成等任务特定代理，模拟临床推理流程。", "result": "实验结果表明，该方法在自动指标和基于LLM的评估中均优于强基线，生成更准确、结构化和可解释的报告。", "conclusion": "这项工作展示了临床对齐的多代理框架在支持可解释和可信赖的临床AI应用方面的潜力。"}}
{"id": "2505.09932", "title": "Demystifying AI Agents: The Final Generation of Intelligence", "authors": ["Kevin J McNamara", "Rhea Pritham Marpu"], "abstract": "The trajectory of artificial intelligence (AI) has been one of relentless acceleration, evolving from rudimentary rule-based systems to sophisticated, autonomous agents capable of complex reasoning and interaction. This whitepaper chronicles this remarkable journey, charting the key technological milestones--advancements in prompting, training methodologies, hardware capabilities, and architectural innovations--that have converged to create the AI agents of today. We argue that these agents, exemplified by systems like OpenAI's ChatGPT with plugins and xAI's Grok, represent a culminating phase in AI development, potentially constituting the \"final generation\" of intelligence as we currently conceive it. We explore the capabilities and underlying technologies of these agents, grounded in practical examples, while also examining the profound societal implications and the unprecedented pace of progress that suggests intelligence is now doubling approximately every six months. The paper concludes by underscoring the critical need for wisdom and foresight in navigating the opportunities and challenges presented by this powerful new era of intelligence.", "subjects": "Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET); Machine Learning (cs.LG); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.09932.pdf", "abstract_url": "https://arxiv.org/abs/2505.09932", "categories": ["Artificial Intelligence (cs.AI)", "Emerging Technologies (cs.ET)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了人工智能（AI）从基础规则系统到复杂自主代理的演变历程，强调了如OpenAI的ChatGPT等系统代表的AI发展巅峰，及其对社会的影响和快速进步。", "motivation": "旨在记录AI技术的发展历程，展示当前AI代理的能力和潜在影响，强调在智能快速发展的时代需要智慧和远见。", "method": "通过回顾AI技术的关键里程碑和现有系统（如ChatGPT）的能力，结合实例分析AI代理的技术基础和社会影响。", "result": "指出当前AI代理可能代表AI发展的“最终一代”，智能每六个月翻一番，对社会产生深远影响。", "conclusion": "强调在智能快速发展的新时代，需要智慧和远见来应对AI带来的机遇和挑战。"}}
{"id": "2505.09970", "title": "Pre-Act: Multi-Step Planning and Reasoning Improves Acting in LLM Agents", "authors": ["Mrinal Rawat", "Ambuje Gupta", "Rushil Goomer", "Alessandro Di Bari", "Neha Gupta", "Roberto Pieraccini"], "abstract": "The ReAct (Reasoning + Action) capability in large language models (LLMs) has become the foundation of modern agentic systems. Recent LLMs, such as DeepSeek-R1 and OpenAI o1/o3, exemplify this by emphasizing reasoning through the generation of ample intermediate tokens, which help build a strong premise before producing the final output tokens. In this paper, we introduce Pre-Act, a novel approach that enhances the agent's performance by creating a multi-step execution plan along with the detailed reasoning for the given user input. This plan incrementally incorporates previous steps and tool outputs, refining itself after each step execution until the final response is obtained. Our approach is applicable to both conversational and non-conversational agents. To measure the performance of task-oriented agents comprehensively, we propose a two-level evaluation framework: (1) turn level and (2) end-to-end. Our turn-level evaluation, averaged across five models, shows that our approach, Pre-Act, outperforms ReAct by 70% in Action Recall on the Almita dataset. While this approach is effective for larger models, smaller models crucial for practical applications, where latency and cost are key constraints, often struggle with complex reasoning tasks required for agentic systems. To address this limitation, we fine-tune relatively small models such as Llama 3.1 (8B & 70B) using the proposed Pre-Act approach. Our experiments show that the fine-tuned 70B model outperforms GPT-4, achieving a 69.5% improvement in action accuracy (turn-level) and a 28% improvement in goal completion rate (end-to-end) on the Almita (out-of-domain) dataset.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.09970.pdf", "abstract_url": "https://arxiv.org/abs/2505.09970", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了Pre-Act方法，通过多步执行计划和详细推理增强大型语言模型（LLM）代理的性能，适用于对话和非对话代理。", "motivation": "解决现有LLM代理在复杂推理任务中的性能不足，特别是在较小模型中，这些模型在实际应用中因延迟和成本限制而至关重要。", "method": "提出Pre-Act方法，创建多步执行计划和详细推理，逐步整合先前步骤和工具输出，直至获得最终响应。并对较小模型进行微调。", "result": "Pre-Act在Almita数据集上的行动召回率比ReAct高70%。微调的70B模型在行动准确率和目标完成率上分别比GPT-4提高了69.5%和28%。", "conclusion": "Pre-Act方法显著提高了LLM代理的性能，特别是在较小模型中，为实际应用中的代理系统提供了有效的解决方案。"}}
{"id": "2505.10074", "title": "Leveraging Graph Retrieval-Augmented Generation to Support Learners' Understanding of Knowledge Concepts in MOOCs", "authors": ["Mohamed Abdelmagied", "Mohamed Amine Chatti", "Shoeb Joarder", "Qurat Ul Ain", "Rawaa Alatrash"], "abstract": "Massive Open Online Courses (MOOCs) lack direct interaction between learners and instructors, making it challenging for learners to understand new knowledge concepts. Recently, learners have increasingly used Large Language Models (LLMs) to support them in acquiring new knowledge. However, LLMs are prone to hallucinations which limits their reliability. Retrieval-Augmented Generation (RAG) addresses this issue by retrieving relevant documents before generating a response. However, the application of RAG across different MOOCs is limited by unstructured learning material. Furthermore, current RAG systems do not actively guide learners toward their learning needs. To address these challenges, we propose a Graph RAG pipeline that leverages Educational Knowledge Graphs (EduKGs) and Personal Knowledge Graphs (PKGs) to guide learners to understand knowledge concepts in the MOOC platform CourseMapper. Specifically, we implement (1) a PKG-based Question Generation method to recommend personalized questions for learners in context, and (2) an EduKG-based Question Answering method that leverages the relationships between knowledge concepts in the EduKG to answer learner selected questions. To evaluate both methods, we conducted a study with 3 expert instructors on 3 different MOOCs in the MOOC platform CourseMapper. The results of the evaluation show the potential of Graph RAG to empower learners to understand new knowledge concepts in a personalized learning experience.", "subjects": "Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "comments": "Accepted at EMOOCs 2025", "pdf_url": "https://arxiv.org/pdf/2505.10074.pdf", "abstract_url": "https://arxiv.org/abs/2505.10074", "categories": ["Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "该论文提出了一种基于图检索增强生成（Graph RAG）的管道，利用教育知识图（EduKGs）和个人知识图（PKGs）来帮助MOOCs学习者理解知识概念。", "motivation": "解决MOOCs中学习者与教师缺乏直接互动，以及大型语言模型（LLMs）在支持学习者获取新知识时存在的幻觉问题。", "method": "实施了一个基于PKG的问题生成方法，为学习者推荐个性化问题，以及一个基于EduKG的问题回答方法，利用EduKG中知识概念之间的关系来回答学习者选择的问题。", "result": "通过在MOOCs平台CourseMapper上对3个不同MOOCs的3位专家教师进行的研究评估，结果显示Graph RAG在个性化学习体验中帮助学习者理解新知识概念方面具有潜力。", "conclusion": "Graph RAG通过结合EduKGs和PKGs，为MOOCs学习者提供了一个有效的工具，以支持他们在缺乏直接教师互动的情况下理解新知识概念。"}}
{"id": "2505.10278", "title": "MASS: Multi-Agent Simulation Scaling for Portfolio Construction", "authors": ["Taian Guo", "Haiyang Shen", "Jinsheng Huang", "Zhengyang Mao", "Junyu Luo", "Zhuoru Chen", "Xuhui Liu", "Bingyu Xia", "Luchen Liu", "Yun Ma", "Ming Zhang"], "abstract": "LLM-based multi-agent has gained significant attention for their potential in simulation and enhancing performance. However, existing works are limited to pure simulations or are constrained by predefined workflows, restricting their applicability and effectiveness. In this paper, we introduce the Multi-Agent Scaling Simulation (MASS) for portfolio construction. MASS achieves stable and continuous excess returns by progressively increasing the number of agents for large-scale simulations to gain a superior understanding of the market and optimizing agent distribution end-to-end through a reverse optimization process, rather than relying on a fixed workflow. We demonstrate its superiority through performance experiments, ablation studies, backtesting experiments, experiments on updated data and stock pools, scaling experiments, parameter sensitivity experiments, and visualization experiments, conducted in comparison with 6 state-of-the-art baselines on 3 challenging A-share stock pools. We expect the paradigm established by MASS to expand to other tasks with similar characteristics. The implementation of MASS has been open-sourced at", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.10278.pdf", "abstract_url": "https://arxiv.org/abs/2505.10278", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了多代理缩放模拟（MASS）用于投资组合构建，通过逐步增加代理数量进行大规模模拟，以更好地理解市场，并通过反向优化过程优化代理分布，实现了稳定且持续的超额回报。", "motivation": "现有的基于LLM的多代理工作仅限于纯模拟或受限于预定义的工作流程，限制了其适用性和有效性。本文旨在解决这一问题，提出MASS方法以提升投资组合构建的性能。", "method": "MASS通过逐步增加代理数量进行大规模模拟，采用反向优化过程端到端优化代理分布，而非依赖固定工作流程。", "result": "通过在3个具有挑战性的A股股票池上与6个最先进的基线进行比较的性能实验、消融研究、回测实验等，证明了MASS的优越性。", "conclusion": "MASS建立的范式有望扩展到具有类似特征的其他任务。MASS的实现已开源。"}}
{"id": "2505.10468", "title": "AI Agents vs. Agentic AI: A Conceptual Taxonomy, Applications and Challenge", "authors": ["Ranjan Sapkota", "Konstantinos I. Roumeliotis", "Manoj Karkee"], "abstract": "This study critically distinguishes between AI Agents and Agentic AI, offering a structured conceptual taxonomy, application mapping, and challenge analysis to clarify their divergent design philosophies and capabilities. We begin by outlining the search strategy and foundational definitions, characterizing AI Agents as modular systems driven by Large Language Models (LLMs) and Large Image Models (LIMs) for narrow, task-specific automation. Generative AI is positioned as a precursor, with AI Agents advancing through tool integration, prompt engineering, and reasoning enhancements. In contrast, Agentic AI systems represent a paradigmatic shift marked by multi-agent collaboration, dynamic task decomposition, persistent memory, and orchestrated autonomy. Through a sequential evaluation of architectural evolution, operational mechanisms, interaction styles, and autonomy levels, we present a comparative analysis across both paradigms. Application domains such as customer support, scheduling, and data summarization are contrasted with Agentic AI deployments in research automation, robotic coordination, and medical decision support. We further examine unique challenges in each paradigm including hallucination, brittleness, emergent behavior, and coordination failure and propose targeted solutions such as ReAct loops, RAG, orchestration layers, and causal modeling. This work aims to provide a definitive roadmap for developing robust, scalable, and explainable AI agent and Agentic AI-driven systems. >AI Agents, Agent-driven, Vision-Language-Models, Agentic AI Decision Support System, Agentic-AI Applications", "subjects": "Artificial Intelligence (cs.AI)", "comments": "32 pages, 14 figures, 11 tables", "pdf_url": "https://arxiv.org/pdf/2505.10468.pdf", "abstract_url": "https://arxiv.org/abs/2505.10468", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic", "@RAG"], "AI": {"tldr": "本文通过构建概念分类法、应用映射和挑战分析，区分了AI代理与代理性AI，探讨了它们的设计哲学和能力差异。", "motivation": "解决AI代理与代理性AI在设计理念和能力上的混淆问题，为开发健壮、可扩展和可解释的AI系统提供明确路线图。", "method": "通过顺序评估架构演变、操作机制、交互风格和自主水平，对两种范式进行比较分析。", "result": "提出了针对AI代理和代理性AI独特挑战的解决方案，如ReAct循环、RAG、编排层和因果建模。", "conclusion": "本研究为开发健壮、可扩展和可解释的AI代理和代理性AI驱动系统提供了明确的指导方针和解决方案。"}}
{"id": "2505.10361", "title": "Plasticity as the Mirror of Empowerment", "authors": ["David Abel", "Michael Bowling", "André Barreto", "Will Dabney", "Shi Dong", "Steven Hansen", "Anna Harutyunyan", "Khimya Khetarpal", "Clare Lyle", "Razvan Pascanu", "Georgios Piliouras", "Doina Precup", "Jonathan Richens", "Mark Rowland", "Tom Schaul", "Satinder Singh"], "abstract": "Agents are minimally entities that are influenced by their past observations and act to influence future observations. This latter capacity is captured by empowerment, which has served as a vital framing concept across artificial intelligence and cognitive science. This former capacity, however, is equally foundational: In what ways, and to what extent, can an agent be influenced by what it observes? In this paper, we ground this concept in a universal agent-centric measure that we refer to as plasticity, and reveal a fundamental connection to empowerment. Following a set of desiderata on a suitable definition, we define plasticity using a new information-theoretic quantity we call the generalized directed information. We show that this new quantity strictly generalizes the directed information introduced by Massey (1990) while preserving all of its desirable properties. Our first finding is that plasticity is the mirror of empowerment: The agent's plasticity is identical to the empowerment of the environment, and vice versa. Our second finding establishes a tension between the plasticity and empowerment of an agent, suggesting that agent design needs to be mindful of both characteristics. We explore the implications of these findings, and suggest that plasticity, empowerment, and their relationship are essential to understanding agency.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.10361.pdf", "abstract_url": "https://arxiv.org/abs/2505.10361", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了‘可塑性’作为衡量代理受观察影响程度的新概念，并揭示了其与‘赋权’之间的基本联系。通过定义一种新的信息理论量——广义定向信息，作者展示了可塑性是赋权的镜像，并探讨了两者之间的张力及其对代理设计的影响。", "motivation": "解决代理如何以及多大程度上能受其观察影响的问题，并探索这一概念与赋权之间的关系。", "method": "使用新定义的信息理论量——广义定向信息来定义可塑性，并分析其与赋权的关系。", "result": "发现可塑性是赋权的镜像，且代理的可塑性与赋权之间存在张力。", "conclusion": "可塑性、赋权及其关系对于理解代理性质至关重要，代理设计需同时考虑这两者。"}}
{"id": "2505.09757", "title": "Trustless Autonomy: Understanding Motivations, Benefits and Governance Dilemma in Self-Sovereign Decentralized AI Agents", "authors": ["Botao Amber Hu", "Yuhan Liu", "Helena Rong"], "abstract": "The recent trend of self-sovereign Decentralized AI Agents (DeAgents) combines Large Language Model (LLM)-based AI agents with decentralization technologies such as blockchain smart contracts and trusted execution environments (TEEs). These tamper-resistant trustless substrates allow agents to achieve self-sovereignty through ownership of cryptowallet private keys and control of digital assets and social media accounts. DeAgent eliminates centralized control and reduces human intervention, addressing key trust concerns inherent in centralized AI systems. However, given ongoing challenges in LLM reliability such as hallucinations, this creates paradoxical tension between trustlessness and unreliable autonomy. This study addresses this empirical research gap through interviews with DeAgents stakeholders-experts, founders, and developers-to examine their motivations, benefits, and governance dilemmas. The findings will guide future DeAgents system and protocol design and inform discussions about governance in sociotechnical AI systems in the future agentic web.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "comments": "Submitted to CSCW 2026", "pdf_url": "https://arxiv.org/pdf/2505.09757.pdf", "abstract_url": "https://arxiv.org/abs/2505.09757", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文探讨了自我主权去中心化AI代理（DeAgents）的动机、益处及治理困境，结合了大型语言模型（LLM）与区块链智能合约等去中心化技术，旨在消除中心化控制并减少人为干预，但同时也面临信任缺失与不可靠自治之间的矛盾。", "motivation": "解决中心化AI系统中的关键信任问题，同时探索去中心化AI代理在实现自我主权过程中的动机、益处及治理挑战。", "method": "通过对DeAgents的利益相关者（专家、创始人、开发者）进行访谈，收集数据以填补实证研究的空白。", "result": "研究发现将指导未来DeAgents系统及协议的设计，并为未来代理网络中的社会技术AI系统治理讨论提供信息。", "conclusion": "尽管DeAgents在消除中心化控制和减少人为干预方面具有潜力，但LLM的可靠性问题如幻觉现象，导致了信任缺失与不可靠自治之间的紧张关系，这需要未来的研究和治理策略来解决。"}}
{"id": "2505.10012", "title": "Quantum Computing and AI: Perspectives on Advanced Automation in Science and Engineering", "authors": ["Tadashi Kadowaki"], "abstract": "Recent advances in artificial intelligence (AI) and quantum computing are accelerating automation in scientific and engineering processes, fundamentally reshaping research methodologies. This perspective highlights parallels between scientific automation and established Computer-Aided Engineering (CAE) practices, introducing Quantum CAE as a framework that leverages quantum algorithms for simulation, optimization, and machine learning within engineering design. Practical implementations of Quantum CAE are illustrated through case studies for combinatorial optimization problems. Further discussions include advancements toward higher automation levels, highlighting the critical role of specialized AI agents proficient in quantum algorithm design. The integration of quantum computing with AI raises significant questions about the collaborative dynamics among human scientists and engineers, AI systems, and quantum computational resources, underscoring a transformative future for automated discovery and innovation.", "subjects": "Quantum Physics (quant-ph); Artificial Intelligence (cs.AI)", "comments": "8 pages, 4 figures", "pdf_url": "https://arxiv.org/pdf/2505.10012.pdf", "abstract_url": "https://arxiv.org/abs/2505.10012", "categories": ["Quantum Physics (quant-ph)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了人工智能（AI）和量子计算在科学和工程自动化中的最新进展，提出了量子计算机辅助工程（Quantum CAE）框架，通过案例研究展示了其在组合优化问题中的应用，并讨论了AI与量子计算整合对未来自动化发现和创新的影响。", "motivation": "探讨AI和量子计算如何加速科学和工程领域的自动化进程，以及这种整合如何改变研究方法和工程设计。", "method": "引入Quantum CAE框架，利用量子算法进行工程设计中的模拟、优化和机器学习，并通过组合优化问题的案例研究来展示其实际应用。", "result": "展示了Quantum CAE在解决组合优化问题中的有效性，并强调了精通量子算法设计的专业AI代理在推动更高水平自动化中的关键作用。", "conclusion": "AI与量子计算的整合预示着自动化发现和创新的变革性未来，同时也提出了关于人类科学家和工程师、AI系统及量子计算资源之间协作动态的重要问题。"}}
{"id": "2505.10321", "title": "AutoPentest: Enhancing Vulnerability Management With Autonomous LLM Agents", "authors": ["Julius Henke"], "abstract": "A recent area of increasing research is the use of Large Language Models (LLMs) in penetration testing, which promises to reduce costs and thus allow for higher frequency. We conduct a review of related work, identifying best practices and common evaluation issues. We then present AutoPentest, an application for performing black-box penetration tests with a high degree of autonomy. AutoPentest is based on the LLM GPT-4o from OpenAI and the LLM agent framework LangChain. It can perform complex multi-step tasks, augmented by external tools and knowledge bases. We conduct a study on three capture-the-flag style Hack The Box (HTB) machines, comparing our implementation AutoPentest with the baseline approach of manually using the ChatGPT-4o user interface. Both approaches are able to complete 15-25 % of the subtasks on the HTB machines, with AutoPentest slightly outperforming ChatGPT. We measure a total cost of \\$96.20 US when using AutoPentest across all experiments, while a one-month subscription to ChatGPT Plus costs \\$20. The results show that further implementation efforts and the use of more powerful LLMs released in the future are likely to make this a viable part of vulnerability management.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.10321.pdf", "abstract_url": "https://arxiv.org/abs/2505.10321", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了AutoPentest，一个基于GPT-4o和LangChain框架的自主LLM代理应用，用于执行黑盒渗透测试，旨在降低成本并提高测试频率。", "motivation": "解决渗透测试成本高、频率低的问题，利用大型语言模型（LLMs）提高自动化水平。", "method": "基于GPT-4o和LangChain框架开发的AutoPentest应用，结合外部工具和知识库执行复杂的多步骤任务。", "result": "在Hack The Box（HTB）机器上的实验中，AutoPentest和ChatGPT-4o用户界面均能完成15-25%的子任务，AutoPentest略优于ChatGPT，总成本为96.20美元。", "conclusion": "未来的实现努力和更强大的LLMs的使用可能会使AutoPentest成为漏洞管理的可行部分。"}}
{"id": "2505.10387", "title": "Multi-Agent Path Finding For Large Agents Is Intractable", "authors": ["Artem Agafonov", "Konstantin Yakovlev"], "abstract": "The multi-agent path finding (MAPF) problem asks to find a set of paths on a graph such that when synchronously following these paths the agents never encounter a conflict. In the most widespread MAPF formulation, the so-called Classical MAPF, the agents sizes are neglected and two types of conflicts are considered: occupying the same vertex or using the same edge at the same time step. Meanwhile in numerous practical applications, e.g. in robotics, taking into account the agents' sizes is vital to ensure that the MAPF solutions can be safely executed. Introducing large agents yields an additional type of conflict arising when one agent follows an edge and its body overlaps with the body of another agent that is actually not using this same edge (e.g. staying still at some distinct vertex of the graph). Until now it was not clear how harder the problem gets when such conflicts are to be considered while planning. Specifically, it was known that Classical MAPF problem on an undirected graph can be solved in polynomial time, however no complete polynomial-time algorithm was presented to solve MAPF with large agents. In this paper we, for the first time, establish that the latter problem is NP-hard and, thus, if P!=NP no polynomial algorithm for it can, unfortunately, be presented. Our proof is based on the prevalent in the field technique of reducing the seminal 3SAT problem (which is known to be an NP-complete problem) to the problem at hand. In particular, for an arbitrary 3SAT formula we procedurally construct a dedicated graph with specific start and goal vertices and show that the given 3SAT formula is satisfiable iff the corresponding path finding instance has a solution.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Computational Complexity (cs.CC)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.10387.pdf", "abstract_url": "https://arxiv.org/abs/2505.10387", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Computational Complexity (cs.CC)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文首次证明了考虑大型代理的多代理路径查找（MAPF）问题是NP难的，这意味着如果P≠NP，则无法提出多项式时间算法来解决该问题。", "motivation": "解决在多代理路径查找问题中考虑代理大小的重要性，以确保解决方案可以安全执行，特别是在机器人等实际应用中。", "method": "通过将已知的NP完全问题3SAT归约到考虑大型代理的MAPF问题，证明了后者的NP难性。", "result": "证明了考虑大型代理的MAPF问题是NP难的，这意味着在P≠NP的假设下，不存在多项式时间算法来解决该问题。", "conclusion": "考虑大型代理的MAPF问题比传统MAPF问题更复杂，这为未来研究提供了重要的理论基础，并指出了在实际应用中寻找高效近似算法的必要性。"}}
{"id": "2505.10330", "title": "Efficient Adaptation of Reinforcement Learning Agents to Sudden Environmental Change", "authors": ["Jonathan Clifford Balloch"], "abstract": "Real-world autonomous decision-making systems, from robots to recommendation engines, must operate in environments that change over time. While deep reinforcement learning (RL) has shown an impressive ability to learn optimal policies in stationary environments, most methods are data intensive and assume a world that does not change between training and test time. As a result, conventional RL methods struggle to adapt when conditions change. This poses a fundamental challenge: how can RL agents efficiently adapt their behavior when encountering novel environmental changes during deployment without catastrophically forgetting useful prior knowledge? This dissertation demonstrates that efficient online adaptation requires two key capabilities: (1) prioritized exploration and sampling strategies that help identify and learn from relevant experiences, and (2) selective preservation of prior knowledge through structured representations that can be updated without disruption to reusable components.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "PhD Dissertation, 131 pages", "pdf_url": "https://arxiv.org/pdf/2505.10330.pdf", "abstract_url": "https://arxiv.org/abs/2505.10330", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了强化学习（RL）代理在环境突然变化时的有效适应问题，提出了两种关键能力以实现高效在线适应。", "motivation": "解决RL代理在训练和测试环境变化时难以适应的问题，避免灾难性遗忘有用先验知识。", "method": "采用优先探索和采样策略以及选择性保留先验知识的结构化表示。", "result": "展示了高效在线适应所需的两种关键能力。", "conclusion": "通过优先探索和选择性保留先验知识，RL代理可以在环境变化时有效适应，而不遗忘有用信息。"}}
{"id": "2505.10482", "title": "Fine-tuning Diffusion Policies with Backpropagation Through Diffusion Timesteps", "authors": ["Ningyuan Yang", "Jiaxuan Gao", "Feng Gao", "Yi Wu", "Chao Yu"], "abstract": "Diffusion policies, widely adopted in decision-making scenarios such as robotics, gaming and autonomous driving, are capable of learning diverse skills from demonstration data due to their high representation power. However, the sub-optimal and limited coverage of demonstration data could lead to diffusion policies that generate sub-optimal trajectories and even catastrophic failures. While reinforcement learning (RL)-based fine-tuning has emerged as a promising solution to address these limitations, existing approaches struggle to effectively adapt Proximal Policy Optimization (PPO) to diffusion models. This challenge stems from the computational intractability of action likelihood estimation during the denoising process, which leads to complicated optimization objectives. In our experiments starting from randomly initialized policies, we find that online tuning of Diffusion Policies demonstrates much lower sample efficiency compared to directly applying PPO on MLP policies (MLP+PPO). To address these challenges, we introduce NCDPO, a novel framework that reformulates Diffusion Policy as a noise-conditioned deterministic policy. By treating each denoising step as a differentiable transformation conditioned on pre-sampled noise, NCDPO enables tractable likelihood evaluation and gradient backpropagation through all diffusion timesteps. Our experiments demonstrate that NCDPO achieves sample efficiency comparable to MLP+PPO when training from scratch, outperforming existing methods in both sample efficiency and final performance across diverse benchmarks, including continuous robot control and multi-agent game scenarios. Furthermore, our experimental results show that our method is robust to the number denoising timesteps in the Diffusion Policy.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "9 pages for main text, 23 pages in total, submitted to Neurips, 13 figures", "pdf_url": "https://arxiv.org/pdf/2505.10482.pdf", "abstract_url": "https://arxiv.org/abs/2505.10482", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为NCDPO的新框架，通过将扩散策略重新表述为噪声条件确定性策略，解决了在扩散模型中应用PPO时遇到的计算难题，显著提高了样本效率和最终性能。", "motivation": "扩散策略在从演示数据学习多样化技能方面表现出色，但演示数据的次优和有限覆盖可能导致生成的轨迹次优甚至灾难性失败。现有的基于强化学习的微调方法难以有效适应扩散模型。", "method": "引入NCDPO框架，将扩散策略重新表述为噪声条件确定性策略，通过将每个去噪步骤视为对预采样噪声的可微分变换，实现了对所有扩散时间步的似然评估和梯度反向传播。", "result": "实验表明，NCDPO在从零开始训练时的样本效率与MLP+PPO相当，在多样化的基准测试中，包括连续机器人控制和多智能体游戏场景，样本效率和最终性能均优于现有方法。", "conclusion": "NCDPO不仅提高了扩散策略的样本效率和性能，而且对扩散策略中的去噪时间步数具有鲁棒性，为扩散策略的优化提供了新的方向。"}}
{"id": "2505.10522", "title": "Knowledge capture, adaptation and composition (KCAC): A framework for cross-task curriculum learning in robotic manipulation", "authors": ["Xinrui Wang", "Yan Jin"], "abstract": "Reinforcement learning (RL) has demonstrated remarkable potential in robotic manipulation but faces challenges in sample inefficiency and lack of interpretability, limiting its applicability in real world scenarios. Enabling the agent to gain a deeper understanding and adapt more efficiently to diverse working scenarios is crucial, and strategic knowledge utilization is a key factor in this process. This paper proposes a Knowledge Capture, Adaptation, and Composition (KCAC) framework to systematically integrate knowledge transfer into RL through cross-task curriculum learning. KCAC is evaluated using a two block stacking task in the CausalWorld benchmark, a complex robotic manipulation environment. To our knowledge, existing RL approaches fail to solve this task effectively, reflecting deficiencies in knowledge capture. In this work, we redesign the benchmark reward function by removing rigid constraints and strict ordering, allowing the agent to maximize total rewards concurrently and enabling flexible task completion. Furthermore, we define two self-designed sub-tasks and implement a structured cross-task curriculum to facilitate efficient learning. As a result, our KCAC approach achieves a 40 percent reduction in training time while improving task success rates by 10 percent compared to traditional RL methods. Through extensive evaluation, we identify key curriculum design parameters subtask selection, transition timing, and learning rate that optimize learning efficiency and provide conceptual guidance for curriculum based RL frameworks. This work offers valuable insights into curriculum design in RL and robotic learning.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.10522.pdf", "abstract_url": "https://arxiv.org/abs/2505.10522", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一个知识捕获、适应和组合（KCAC）框架，通过跨任务课程学习将知识转移系统地整合到强化学习中，以提高机器人操作的效率和可解释性。", "motivation": "强化学习在机器人操作中显示出巨大潜力，但面临样本效率低和缺乏可解释性的挑战，限制了其在实际场景中的应用。", "method": "KCAC框架通过重新设计奖励函数、定义自设计子任务和实施结构化跨任务课程，系统地整合知识转移。", "result": "KCAC方法在CausalWorld基准测试中实现了训练时间减少40%，任务成功率提高10%。", "conclusion": "本研究为基于课程的强化学习框架提供了优化学习效率的关键课程设计参数，并为机器人学习中的课程设计提供了有价值的见解。"}}
