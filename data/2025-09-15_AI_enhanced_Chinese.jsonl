{"id": "2509.10096", "title": "HHI-Assist: A Dataset and Benchmark of Human-Human Interaction in Physical Assistance Scenario", "authors": ["Saeed Saadatnejad", "Reyhaneh Hosseininejad", "Jose Barreiros", "Katherine M. Tsui", "Alexandre Alahi"], "abstract": "The increasing labor shortage and aging population underline the need for assistive robots to support human care recipients. To enable safe and responsive assistance, robots require accurate human motion prediction in physical interaction scenarios. However, this remains a challenging task due to the variability of assistive settings and the complexity of coupled dynamics in physical interactions. In this work, we address these challenges through two key contributions: (1) HHI-Assist, a dataset comprising motion capture clips of human-human interactions in assistive tasks; and (2) a conditional Transformer-based denoising diffusion model for predicting the poses of interacting agents. Our model effectively captures the coupled dynamics between caregivers and care receivers, demonstrating improvements over baselines and strong generalization to unseen scenarios. By advancing interaction-aware motion prediction and introducing a new dataset, our work has the potential to significantly enhance robotic assistance policies. The dataset and code are available at:", "subjects": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV)", "comments": "Accepted to RA-L 2025", "pdf_url": "https://arxiv.org/pdf/2509.10096.pdf", "abstract_url": "https://arxiv.org/abs/2509.10096", "categories": ["Robotics (cs.RO)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了HHI-Assist数据集和基于Transformer的去噪扩散模型，用于预测物理辅助场景中的人-人交互运动，以提高机器人辅助的安全性和响应性。", "motivation": "解决劳动力短缺和人口老龄化问题，需要开发能够准确预测人类运动以支持安全响应的辅助机器人，但现有方法因交互场景的变异性和耦合动力学复杂性而面临挑战。", "method": "提出HHI-Assist数据集，包含运动捕捉剪辑，并开发条件Transformer去噪扩散模型来预测交互代理的姿态。", "result": "模型有效捕捉了护理者和被护理者之间的耦合动力学，在基准测试中表现优于基线，并在未见场景中展示出强泛化能力。", "conclusion": "通过推进交互感知运动预测和提供新数据集，本研究有潜力显著改善机器人辅助策略，数据集和代码已公开。"}}
{"id": "2509.09721", "title": "A Multimodal RAG Framework for Housing Damage Assessment: Collaborative Optimization of Image Encoding and Policy Vector Retrieval", "authors": ["Jiayi Miao", "Dingxin Lu", "Zhuqi Wang"], "abstract": "After natural disasters, accurate evaluations of damage to housing are important for insurance claims response and planning of resources. In this work, we introduce a novel multimodal retrieval-augmented generation (MM-RAG) framework. On top of classical RAG architecture, we further the framework to devise a two-branch multimodal encoder structure that the image branch employs a visual encoder composed of ResNet and Transformer to extract the characteristic of building damage after disaster, and the text branch harnesses a BERT retriever for the text vectorization of posts as well as insurance policies and for the construction of a retrievable restoration index. To impose cross-modal semantic alignment, the model integrates a cross-modal interaction module to bridge the semantic representation between image and text via multi-head attention. Meanwhile, in the generation module, the introduced modal attention gating mechanism dynamically controls the role of visual evidence and text prior information during generation. The entire framework takes end-to-end training, and combines the comparison loss, the retrieval loss and the generation loss to form multi-task optimization objectives, and achieves image understanding and policy matching in collaborative learning. The results demonstrate superior performance in retrieval accuracy and classification index on damage severity, where the Top-1 retrieval accuracy has been improved by 9.6%.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.09721.pdf", "abstract_url": "https://arxiv.org/abs/2509.09721", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种新颖的多模态检索增强生成（MM-RAG）框架，用于自然灾害后的住房损坏评估，通过双分支编码器、跨模态交互和模态注意力门控机制，实现了图像和文本的协同优化，显著提高了检索准确性和分类性能。", "motivation": "解决自然灾害后住房损坏评估的准确性问题，以支持保险索赔响应和资源规划。", "method": "基于经典RAG架构，设计双分支多模态编码器（图像分支使用ResNet和Transformer，文本分支使用BERT），集成跨模态交互模块和模态注意力门控机制，进行端到端训练，结合比较损失、检索损失和生成损失的多任务优化。", "result": "在检索准确性和损坏严重性分类指标上表现优越，Top-1检索准确率提高了9.6%。", "conclusion": "该框架通过协同学习实现了图像理解和政策匹配，为灾害响应提供了高效工具，具有实际应用价值。"}}
{"id": "2509.10021", "title": "Efficient and Accurate Downfacing Visual Inertial Odometry", "authors": ["Jonas Kühne", "Christian Vogt", "Michele Magno", "Luca Benini"], "abstract": "Visual Inertial Odometry (VIO) is a widely used computer vision method that determines an agent's movement through a camera and an IMU sensor. This paper presents an efficient and accurate VIO pipeline optimized for applications on micro- and nano-UAVs. The proposed design incorporates state-of-the-art feature detection and tracking methods (SuperPoint, PX4FLOW, ORB), all optimized and quantized for emerging RISC-V-based ultra-low-power parallel systems on chips (SoCs). Furthermore, by employing a rigid body motion model, the pipeline reduces estimation errors and achieves improved accuracy in planar motion scenarios. The pipeline's suitability for real-time VIO is assessed on an ultra-low-power SoC in terms of compute requirements and tracking accuracy after quantization. The pipeline, including the three feature tracking methods, was implemented on the SoC for real-world validation. This design bridges the gap between high-accuracy VIO pipelines that are traditionally run on computationally powerful systems and lightweight implementations suitable for microcontrollers. The optimized pipeline on the GAP9 low-power SoC demonstrates an average reduction in RMSE of up to a factor of 3.65x over the baseline pipeline when using the ORB feature tracker. The analysis of the computational complexity of the feature trackers further shows that PX4FLOW achieves on-par tracking accuracy with ORB at a lower runtime for movement speeds below 24 pixels/frame.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO); Image and Video Processing (eess.IV)", "comments": "This article has been accepted for publication in the IEEE Internet of Things Journal (IoT-J)", "pdf_url": "https://arxiv.org/pdf/2509.10021.pdf", "abstract_url": "https://arxiv.org/abs/2509.10021", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Robotics (cs.RO)", "Image and Video Processing (eess.IV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种针对微型和纳米无人机优化的高效、准确的视觉惯性里程计（VIO）管道，集成先进特征跟踪方法，在低功耗SoC上实现实时性能，显著降低误差。", "motivation": "解决传统高精度VIO管道在计算资源受限的微控制器上运行困难的问题，为微型和纳米无人机应用提供轻量级实现。", "method": "使用SuperPoint、PX4FLOW和ORB等特征检测与跟踪方法，结合刚体运动模型进行优化和量化，部署在RISC-V低功耗SoC上。", "result": "在GAP9 SoC上，ORB特征跟踪器的RMSE平均降低3.65倍；PX4FLOW在速度低于24像素/帧时达到与ORB相当的精度且运行时间更短。", "conclusion": "该管道成功弥合了高精度与轻量级VIO之间的差距，适用于实时应用，提升了微型无人机的导航性能。"}}
{"id": "2509.09713", "title": "HANRAG: Heuristic Accurate Noise-resistant Retrieval-Augmented Generation for Multi-hop Question Answering", "authors": ["Duolin Sun", "Dan Yang", "Yue Shen", "Yihan Jiao", "Zhehao Tan", "Jie Feng", "Lianzhen Zhong", "Jian Wang", "Peng Wei", "Jinjie Gu"], "abstract": "The Retrieval-Augmented Generation (RAG) approach enhances question-answering systems and dialogue generation tasks by integrating information retrieval (IR) technologies with large language models (LLMs). This strategy, which retrieves information from external knowledge bases to bolster the response capabilities of generative models, has achieved certain successes. However, current RAG methods still face numerous challenges when dealing with multi-hop queries. For instance, some approaches overly rely on iterative retrieval, wasting too many retrieval steps on compound queries. Additionally, using the original complex query for retrieval may fail to capture content relevant to specific sub-queries, resulting in noisy retrieved content. If the noise is not managed, it can lead to the problem of noise accumulation. To address these issues, we introduce HANRAG, a novel heuristic-based framework designed to efficiently tackle problems of varying complexity. Driven by a powerful revelator, HANRAG routes queries, decomposes them into sub-queries, and filters noise from retrieved documents. This enhances the system's adaptability and noise resistance, making it highly capable of handling diverse queries. We compare the proposed framework against other leading industry methods across various benchmarks. The results demonstrate that our framework obtains superior performance in both single-hop and multi-hop question-answering tasks.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.09713.pdf", "abstract_url": "https://arxiv.org/abs/2509.09713", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "论文提出了HANRAG框架，通过启发式方法改进检索增强生成，有效处理多跳问答中的噪声和效率问题。", "motivation": "解决当前RAG方法在多跳查询中迭代检索浪费步骤和噪声累积的问题。", "method": "使用基于启发式的框架，包括查询路由、子查询分解和噪声过滤。", "result": "在单跳和多跳问答基准测试中，HANRAG表现出优于其他领先方法的性能。", "conclusion": "HANRAG提高了系统的适应性和抗噪能力，适用于多样化查询处理。"}}
{"id": "2509.09727", "title": "A Role-Aware Multi-Agent Framework for Financial Education Question Answering with LLMs", "authors": ["Andy Zhu", "Yingjun Du"], "abstract": "Question answering (QA) plays a central role in financial education, yet existing large language model (LLM) approaches often fail to capture the nuanced and specialized reasoning required for financial problem-solving. The financial domain demands multistep quantitative reasoning, familiarity with domain-specific terminology, and comprehension of real-world scenarios. We present a multi-agent framework that leverages role-based prompting to enhance performance on domain-specific QA. Our framework comprises a Base Generator, an Evidence Retriever, and an Expert Reviewer agent that work in a single-pass iteration to produce a refined answer. We evaluated our framework on a set of 3,532 expert-designed finance education questions from", "subjects": "Computation and Language (cs.CL); Computational Engineering, Finance, and Science (cs.CE)", "comments": "8 pages, 6 figures, Underreview", "pdf_url": "https://arxiv.org/pdf/2509.09727.pdf", "abstract_url": "https://arxiv.org/abs/2509.09727", "categories": ["Computation and Language (cs.CL)", "Computational Engineering, Finance, and Science (cs.CE)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于角色感知的多智能体框架，利用基于角色的提示来增强金融教育问答中大型语言模型的性能，通过单次迭代生成精炼答案。", "motivation": "解决现有大型语言模型在金融教育问答中难以捕捉专业推理和领域特定术语的问题，因为金融领域需要多步定量推理和真实场景理解。", "method": "使用一个多智能体框架，包括基础生成器、证据检索器和专家评审器智能体，通过角色提示在单次迭代中协作生成答案。", "result": "在3,532个专家设计的金融教育问题上进行了评估，但摘要未提供具体结果细节。", "conclusion": "该框架通过多智能体协作提高了金融问答的准确性和专业性，具有实际应用潜力。"}}
{"id": "2509.09710", "title": "Generating Individual Travel Diaries Using Large Language Models Informed by Census and Land-Use Data", "authors": ["Sepehr Golrokh Amin", "Devin Rhoads", "Fatemeh Fakhrmoosavi", "Nicholas E. Lownes", "John N. Ivan"], "abstract": "This study introduces a Large Language Model (LLM) scheme for generating individual travel diaries in agent-based transportation models. While traditional approaches rely on large quantities of proprietary household travel surveys, the method presented in this study generates personas stochastically from open-source American Community Survey (ACS) and Smart Location Database (SLD) data, then synthesizes diaries through direct prompting. This study features a novel one-to-cohort realism score: a composite of four metrics (Trip Count Score, Interval Score, Purpose Score, and Mode Score) validated against the Connecticut Statewide Transportation Study (CSTS) diaries, matched across demographic variables. The validation utilizes Jensen-Shannon Divergence to measure distributional similarities between generated and real diaries. When compared to diaries generated with classical methods (Negative Binomial for trip generation; Multinomial Logit for mode/purpose) calibrated on the validation set, LLM-generated diaries achieve comparable overall realism (LLM mean: 0.485 vs. 0.455). The LLM excels in determining trip purpose and demonstrates greater consistency (narrower realism score distribution), while classical models lead in numerical estimates of trip count and activity duration. Aggregate validation confirms the LLM's statistical representativeness (LLM mean: 0.612 vs. 0.435), demonstrating LLM's zero-shot viability and establishing a quantifiable metric of diary realism for future synthetic diary evaluation systems.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.09710.pdf", "abstract_url": "https://arxiv.org/abs/2509.09710", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本研究提出了一种利用大型语言模型（LLM）结合人口普查和土地使用数据生成个体出行日记的方法，用于基于代理的交通模型，通过验证显示其与经典方法相比具有可比拟的真实性和零样本可行性。", "motivation": "解决传统方法依赖专有家庭出行调查数据的问题，利用开源数据生成更易获取和真实的出行日记。", "method": "使用美国社区调查（ACS）和智能位置数据库（SLD）数据随机生成人物角色，通过直接提示LLM合成日记，并采用新颖的一对群体真实感评分（包括行程计数、间隔、目的和模式评分）和Jensen-Shannon散度进行验证。", "result": "LLM生成的日记在整体真实感上与经典方法相当（LLM均值0.485 vs. 0.455），在确定出行目的方面表现更优，且一致性更高，而经典方法在行程计数和活动持续时间估计上领先；聚合验证显示LLM具有统计代表性（均值0.612 vs. 0.435）。", "conclusion": "LLM方法展示了零样本可行性，为未来合成日记评估系统提供了可量化的真实感指标，具有潜在的应用价值。"}}
{"id": "2509.09734", "title": "MCP-AgentBench: Evaluating Real-World Language Agent Performance with MCP-Mediated Tools", "authors": ["Zikang Guo", "Benfeng Xu", "Chiwei Zhu", "Wentao Hong", "Xiaorui Wang", "Zhendong Mao"], "abstract": "The Model Context Protocol (MCP) is rapidly emerging as a pivotal open standard, designed to enhance agent-tool integration and interoperability, and is positioned to unlock a new era of powerful, interconnected, and genuinely utilitarian agentic AI. However, despite MCP's growing adoption, existing benchmarks often fail to capture real-world agent performance within this new paradigm, leading to a distorted perception of their true operational value and an inability to reliably differentiate proficiencies. To bridge this critical evaluation gap, we introduce MCP-AgentBench -- a comprehensive benchmark specifically engineered to rigorously assess language agent capabilities in MCP-mediated tool interactions. Core contributions of MCP-AgentBench include: the establishment of a robust MCP testbed comprising 33 operational servers with 188 distinct tools; the development of a benchmark featuring 600 systematically designed queries distributed across 6 distinct categories of varying interaction complexity; and the introduction of MCP-Eval, a novel outcome-oriented evaluation methodology prioritizing real-world task success. Through extensive empirical evaluation of leading language agents, we provide foundational insights. MCP-AgentBench aims to equip the research community with a standardized and reliable framework to build, validate, and advance agents capable of fully leveraging MCP's transformative benefits, thereby accelerating progress toward truly capable and interoperable AI systems.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.09734.pdf", "abstract_url": "https://arxiv.org/abs/2509.09734", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了MCP-AgentBench，一个专门用于评估语言代理在MCP协议下工具交互性能的综合基准，包括测试床、查询集和评估方法，以填补现有基准的不足。", "motivation": "现有基准未能准确评估MCP标准下的语言代理真实性能，导致对其操作价值的误解和无法可靠区分能力差异。", "method": "建立包含33个服务器和188个工具的MCP测试床，设计600个查询分布在6个复杂度类别，并引入MCP-Eval评估方法，强调任务成功。", "result": "通过实证评估领先语言代理，提供了基础见解，展示了基准的有效性。", "conclusion": "MCP-AgentBench为研究社区提供了标准化框架，以构建和验证代理，加速实现互操作和强大AI系统的进展。"}}
{"id": "2509.09848", "title": "Towards an AI-based knowledge assistant for goat farmers based on Retrieval-Augmented Generation", "authors": ["Nana Han", "Dong Liu", "Tomas Norton"], "abstract": "Large language models (LLMs) are increasingly being recognised as valuable knowledge communication tools in many industries. However, their application in livestock farming remains limited, being constrained by several factors not least the availability, diversity and complexity of knowledge sources. This study introduces an intelligent knowledge assistant system designed to support health management in farmed goats. Leveraging the Retrieval-Augmented Generation (RAG), two structured knowledge processing methods, table textualization and decision-tree textualization, were proposed to enhance large language models' (LLMs) understanding of heterogeneous data formats. Based on these methods, a domain-specific goat farming knowledge base was established to improve LLM's capacity for cross-scenario generalization. The knowledge base spans five key domains: Disease Prevention and Treatment, Nutrition Management, Rearing Management, Goat Milk Management, and Basic Farming Knowledge. Additionally, an online search module is integrated to enable real-time retrieval of up-to-date information. To evaluate system performance, six ablation experiments were conducted to examine the contribution of each component. The results demonstrated that heterogeneous knowledge fusion method achieved the best results, with mean accuracies of 87.90% on the validation set and 84.22% on the test set. Across the text-based, table-based, decision-tree based Q&A tasks, accuracy consistently exceeded 85%, validating the effectiveness of structured knowledge fusion within a modular design. Error analysis identified omission as the predominant error category, highlighting opportunities to further improve retrieval coverage and context integration. In conclusion, the results highlight the robustness and reliability of the proposed system for practical applications in goat farming.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.09848.pdf", "abstract_url": "https://arxiv.org/abs/2509.09848", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "该论文提出了一种基于检索增强生成（RAG）的AI知识助手，用于山羊养殖健康管理，通过结构化知识处理方法和知识库提高大型语言模型的性能。", "motivation": "解决大型语言模型在畜牧业应用中因知识源复杂性、多样性和可用性限制而受限的问题，特别是针对山羊养殖的健康管理需求。", "method": "使用检索增强生成（RAG），提出表格文本化和决策树文本化两种结构化知识处理方法，并建立领域特定知识库，集成在线搜索模块。", "result": "异构知识融合方法在验证集和测试集上平均准确率分别为87.90%和84.22%，在多种问答任务中准确率超过85%，显示系统有效性，但错误分析表明遗漏是主要问题。", "conclusion": "系统在实际山羊养殖应用中具有鲁棒性和可靠性，未来可改进检索覆盖和上下文整合以进一步提升性能。"}}
{"id": "2509.09867", "title": "LLMs as Agentic Cooperative Players in Multiplayer UNO", "authors": ["Yago Romano Matinez", "Jesse Roberts"], "abstract": "LLMs promise to assist humans -- not just by answering questions, but by offering useful guidance across a wide range of tasks. But how far does that assistance go? Can a large language model based agent actually help someone accomplish their goal as an active participant? We test this question by engaging an LLM in UNO, a turn-based card game, asking it not to win but instead help another player to do so. We built a tool that allows decoder-only LLMs to participate as agents within the RLCard game environment. These models receive full game-state information and respond using simple text prompts under two distinct prompting strategies. We evaluate models ranging from small (1B parameters) to large (70B parameters) and explore how model scale impacts performance. We find that while all models were able to successfully outperform a random baseline when playing UNO, few were able to significantly aid another player.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.09867.pdf", "abstract_url": "https://arxiv.org/abs/2509.09867", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文通过让LLM在UNO游戏中作为协作代理，测试其帮助其他玩家获胜的能力，发现模型规模影响性能，但多数模型未能显著协助玩家。", "motivation": "探索LLM是否能作为主动参与者帮助人类完成任务，特别是在协作场景中。", "method": "使用解码器LLM在RLCard环境中作为代理，提供完整游戏状态信息，采用两种提示策略，评估不同规模模型。", "result": "所有模型在UNO游戏中表现优于随机基线，但只有少数能显著帮助其他玩家获胜。", "conclusion": "LLM在协作任务中潜力有限，模型规模是关键因素，需进一步研究改进。"}}
{"id": "2509.09915", "title": "The (R)evolution of Scientific Workflows in the Agentic AI Era: Towards Autonomous Science", "authors": ["Woong Shin", "Renan Souza", "Daniel Rosendo", "Frédéric Suter", "Feiyi Wang", "Prasanna Balaprakash", "Rafael Ferreira da Silva"], "abstract": "Modern scientific discovery increasingly requires coordinating distributed facilities and heterogeneous resources, forcing researchers to act as manual workflow coordinators rather than scientists. Advances in AI leading to AI agents show exciting new opportunities that can accelerate scientific discovery by providing intelligence as a component in the ecosystem. However, it is unclear how this new capability would materialize and integrate in the real world. To address this, we propose a conceptual framework where workflows evolve along two dimensions which are intelligence (from static to intelligent) and composition (from single to swarm) to chart an evolutionary path from current workflow management systems to fully autonomous, distributed scientific laboratories. With these trajectories in mind, we present an architectural blueprint that can help the community take the next steps towards harnessing the opportunities in autonomous science with the potential for 100x discovery acceleration and transformational scientific workflows.", "subjects": "Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.09915.pdf", "abstract_url": "https://arxiv.org/abs/2509.09915", "categories": ["Artificial Intelligence (cs.AI)", "Distributed, Parallel, and Cluster Computing (cs.DC)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一个概念框架，通过智能和组成两个维度进化科学工作流，旨在实现从当前系统到全自主分布式实验室的转变，以加速科学发现。", "motivation": "解决现代科学研究中手动协调分布式设施和异构资源的问题，利用AI代理技术提供智能组件，以加速科学发现。", "method": "提出一个概念框架，基于智能（从静态到智能）和组成（从单到群）两个维度，设计进化路径和架构蓝图。", "result": "框架展示了从现有工作流管理系统到全自主科学实验室的进化潜力，可能实现100倍加速和变革性工作流。", "conclusion": "该框架为社区提供了迈向自主科学的步骤，具有加速科学发现和变革工作流的巨大潜力。"}}
{"id": "2509.10018", "title": "GAMA: A General Anonymizing Multi-Agent System for Privacy Preservation Enhanced by Domain Rules and Disproof Method", "authors": ["Hailong Yang", "Renhuo Zhao", "Guanjin Wang", "Zhaohong Deng"], "abstract": "With the rapid advancement of Large Language Model (LLM), LLM-based agents exhibit exceptional abilities in understanding and generating natural language, facilitating human-like collaboration and information transmission in LLM-based Multi-Agent System (MAS). High-performance LLMs are often hosted on remote servers in public spaces. When tasks involve privacy data, MAS cannot securely utilize these LLMs without implementing privacy-preserving mechanisms. To address this challenge, we propose a General Anonymizing Multi-Agent system (GAMA), which divides the agents' workspace into private and public spaces and protects privacy through the anonymizing mechanism. In the private space, agents handle sensitive data, while in the public space, only anonymized data is utilized. GAMA incorporates two key modules to mitigate semantic loss caused by anonymization: Domain-Rule-based Knowledge Enhancement (DRKE) and Disproof-based Logic Enhancement (DLE). We evaluate GAMA on two public question-answering datasets: Trivia Creative Writing and Logic Grid Puzzle. The results demonstrate that GAMA has superior performance compared to the state-of-the-art models. To further assess its privacy-preserving capabilities, we designed two new datasets: Knowledge Privacy Preservation and Logic Privacy Preservation. The final results highlight GAMA's exceptional effectiveness in both task processing and privacy preservation.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.10018.pdf", "abstract_url": "https://arxiv.org/abs/2509.10018", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "提出GAMA系统，通过划分私有和公共空间及匿名化机制保护隐私，结合DRKE和DLE模块减少语义损失，在问答数据集上表现优异，隐私保护效果显著。", "motivation": "解决LLM-based多智能体系统在处理隐私数据时无法安全使用远程高性能LLMs的问题。", "method": "使用空间划分和匿名化机制，集成Domain-Rule-based Knowledge Enhancement和Disproof-based Logic Enhancement模块。", "result": "在Trivia Creative Writing和Logic Grid Puzzle数据集上优于现有模型，新数据集测试显示任务处理和隐私保护均高效。", "conclusion": "GAMA系统有效平衡隐私保护和任务性能，适用于隐私敏感的多智能体应用。"}}
{"id": "2509.10054", "title": "XAgents: A Unified Framework for Multi-Agent Cooperation via IF-THEN Rules and Multipolar Task Processing Graph", "authors": ["Hailong Yang", "Mingxian Gu", "Jianqi Wang", "Guanjin Wang", "Zhaohong Deng"], "abstract": "The rapid advancement of Large Language Models (LLMs) has significantly enhanced the capabilities of Multi-Agent Systems (MAS) in supporting humans with complex, real-world tasks. However, MAS still face challenges in effective task planning when handling highly complex tasks with uncertainty, often resulting in misleading or incorrect outputs that hinder task execution. To address this, we propose XAgents, a unified multi-agent cooperative framework built on a multipolar task processing graph and IF-THEN rules. XAgents uses the multipolar task processing graph to enable dynamic task planning and handle task uncertainty. During subtask processing, it integrates domain-specific IF-THEN rules to constrain agent behaviors, while global rules enhance inter-agent collaboration. We evaluate the performance of XAgents across three distinct datasets, demonstrating that it consistently surpasses state-of-the-art single-agent and multi-agent approaches in both knowledge-typed and logic-typed question-answering tasks. The codes for XAgents are available at:", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.10054.pdf", "abstract_url": "https://arxiv.org/abs/2509.10054", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "XAgents是一个基于多极任务处理图和IF-THEN规则的多智能体合作框架，用于处理复杂任务的不确定性，在问答任务中优于现有方法。", "motivation": "解决多智能体系统在处理高度复杂和不确定任务时，任务规划无效导致误导或错误输出的问题。", "method": "使用多极任务处理图进行动态任务规划，结合领域特定和全局IF-THEN规则约束智能体行为和增强协作。", "result": "在三个数据集上评估，XAgents在知识和逻辑型问答任务中一致超越最先进的单智能体和多智能体方法。", "conclusion": "XAgents框架有效提升多智能体合作，处理不确定性任务，代码已开源，具有实际应用潜力。"}}
{"id": "2509.10147", "title": "Virtual Agent Economies", "authors": ["Nenad Tomasev", "Matija Franklin", "Joel Z. Leibo", "Julian Jacobs", "William A. Cunningham", "Iason Gabriel", "Simon Osindero"], "abstract": "The rapid adoption of autonomous AI agents is giving rise to a new economic layer where agents transact and coordinate at scales and speeds beyond direct human oversight. We propose the \"sandbox economy\" as a framework for analyzing this emergent system, characterizing it along two key dimensions: its origins (emergent vs. intentional) and its degree of separateness from the established human economy (permeable vs. impermeable). Our current trajectory points toward a spontaneous emergence of a vast and highly permeable AI agent economy, presenting us with opportunities for an unprecedented degree of coordination as well as significant challenges, including systemic economic risk and exacerbated inequality. Here we discuss a number of possible design choices that may lead to safely steerable AI agent markets. In particular, we consider auction mechanisms for fair resource allocation and preference resolution, the design of AI \"mission economies\" to coordinate around achieving collective goals, and socio-technical infrastructure needed to ensure trust, safety, and accountability. By doing this, we argue for the proactive design of steerable agent markets to ensure the coming technological shift aligns with humanity's long-term collective flourishing.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.10147.pdf", "abstract_url": "https://arxiv.org/abs/2509.10147", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出'沙盒经济'框架分析自主AI代理经济，探讨其机遇与挑战，并建议主动设计可控市场以促进人类繁荣。", "motivation": "解决自主AI代理经济带来的系统性风险和加剧不平等的问题，确保技术转变与人类长期利益一致。", "method": "使用'沙盒经济'框架，分析经济起源和分离度，并考虑拍卖机制、AI'使命经济'设计和社会技术基础设施。", "result": "当前趋势指向自发、高度可渗透的AI代理经济，提供前所未有的协调机会，但也带来风险和挑战。", "conclusion": "主动设计可控AI代理市场是关键，以确保安全、公平和问责，促进人类集体繁荣。"}}
{"id": "2509.10210", "title": "Towards Fully Automated Molecular Simulations: Multi-Agent Framework for Simulation Setup and Force Field Extraction", "authors": ["Marko Petković", "Vlado Menkovski", "Sofía Calero"], "abstract": "Automated characterization of porous materials has the potential to accelerate materials discovery, but it remains limited by the complexity of simulation setup and force field selection. We propose a multi-agent framework in which LLM-based agents can autonomously understand a characterization task, plan appropriate simulations, assemble relevant force fields, execute them and interpret their results to guide subsequent steps. As a first step toward this vision, we present a multi-agent system for literature-informed force field extraction and automated RASPA simulation setup. Initial evaluations demonstrate high correctness and reproducibility, highlighting this approach's potential to enable fully autonomous, scalable materials characterization.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.10210.pdf", "abstract_url": "https://arxiv.org/abs/2509.10210", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "提出多智能体框架，利用LLM智能体自动化多孔材料模拟设置和力场提取，提高材料表征效率和可扩展性。", "motivation": "解决多孔材料自动化表征中模拟设置和力场选择的复杂性限制问题。", "method": "使用基于LLM的多智能体系统，自主理解任务、规划模拟、组装力场、执行并解释结果。", "result": "初步评估显示高正确性和可重现性，支持全自主、可扩展材料表征。", "conclusion": "该方法有潜力实现完全自动化的分子模拟，加速材料发现。"}}
{"id": "2509.10162", "title": "Online Robust Planning under Model Uncertainty: A Sample-Based Approach", "authors": ["Tamir Shazman", "Idan Lev-Yehudi", "Ron Benchetit", "Vadim Indelman"], "abstract": "Online planning in Markov Decision Processes (MDPs) enables agents to make sequential decisions by simulating future trajectories from the current state, making it well-suited for large-scale or dynamic environments. Sample-based methods such as Sparse Sampling and Monte Carlo Tree Search (MCTS) are widely adopted for their ability to approximate optimal actions using a generative model. However, in practical settings, the generative model is often learned from limited data, introducing approximation errors that can degrade performance or lead to unsafe behaviors. To address these challenges, Robust MDPs (RMDPs) offer a principled framework for planning under model uncertainty, yet existing approaches are typically computationally intensive and not suited for real-time use. In this work, we introduce Robust Sparse Sampling (RSS), the first online planning algorithm for RMDPs with finite-sample theoretical performance guarantees. Unlike Sparse Sampling, which estimates the nominal value function, RSS computes a robust value function by leveraging the efficiency and theoretical properties of Sample Average Approximation (SAA), enabling tractable robust policy computation in online settings. RSS is applicable to infinite or continuous state spaces, and its sample and computational complexities are independent of the state space size. We provide theoretical performance guarantees and empirically show that RSS outperforms standard Sparse Sampling in environments with uncertain dynamics.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.10162.pdf", "abstract_url": "https://arxiv.org/abs/2509.10162", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文介绍了鲁棒稀疏采样（RSS），一种用于模型不确定性下在线规划的算法，具有有限样本理论保证，在不确定环境中优于标准方法。", "motivation": "解决在线规划中由于生成模型近似误差导致的性能下降或不安全行为问题，现有鲁棒MDP方法计算量大，不适合实时使用。", "method": "使用样本平均近似（SAA）计算鲁棒值函数，扩展稀疏采样以处理模型不确定性，适用于无限或连续状态空间。", "result": "RSS在样本和计算复杂度上独立于状态空间大小，理论保证性能，并在实验中优于标准稀疏采样。", "conclusion": "RSS提供了一种高效、可扩展的在线鲁棒规划方法，适用于实际动态环境，具有重要应用价值。"}}
{"id": "2509.10087", "title": "Querying Climate Knowledge: Semantic Retrieval for Scientific Discovery", "authors": ["Mustapha Adamu", "Qi Zhang", "Huitong Pan", "Longin Jan Latecki", "Eduard C. Dragut"], "abstract": "The growing complexity and volume of climate science literature make it increasingly difficult for researchers to find relevant information across models, datasets, regions, and variables. This paper introduces a domain-specific Knowledge Graph (KG) built from climate publications and broader scientific texts, aimed at improving how climate knowledge is accessed and used. Unlike keyword based search, our KG supports structured, semantic queries that help researchers discover precise connections such as which models have been validated in specific regions or which datasets are commonly used with certain teleconnection patterns. We demonstrate how the KG answers such questions using Cypher queries, and outline its integration with large language models in RAG systems to improve transparency and reliability in climate-related question answering. This work moves beyond KG construction to show its real world value for climate researchers, model developers, and others who rely on accurate, contextual scientific information.", "subjects": "Computation and Language (cs.CL)", "comments": "ACM SIGIR 2025 Workshop MANILA", "pdf_url": "https://arxiv.org/pdf/2509.10087.pdf", "abstract_url": "https://arxiv.org/abs/2509.10087", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了一个基于气候科学文献构建的领域知识图谱，支持语义查询，以改善气候知识的获取和使用，并集成大语言模型提升问答系统的可靠性。", "motivation": "解决气候科学文献复杂性和体量增长导致研究人员难以找到跨模型、数据集、区域和变量的相关信息的问题。", "method": "构建领域知识图谱，使用Cypher查询进行语义检索，并与大语言模型集成在RAG系统中。", "result": "知识图谱能够精确回答结构化查询，如模型验证和数据集关联，展示了实际应用价值。", "conclusion": "该知识图谱提升了气候研究的透明度和可靠性，对研究人员和模型开发者具有重要实际意义。"}}
{"id": "2509.10127", "title": "Population-Aligned Persona Generation for LLM-based Social Simulation", "authors": ["Zhengyu Hu", "Zheyuan Xiao", "Max Xiong", "Yuxuan Lei", "Tianfu Wang", "Jianxun Lian", "Kaize Ding", "Ziang Xiao", "Nicholas Jing Yuan", "Xing Xie"], "abstract": "Recent advances in large language models (LLMs) have enabled human-like social simulations at unprecedented scale and fidelity, offering new opportunities for computational social science. A key challenge, however, is the construction of persona sets that authentically represent the diversity and distribution of real-world populations. Most existing LLM-based social simulation studies focus primarily on designing agentic frameworks and simulation environments, often overlooking the complexities of persona generation and the potential biases introduced by unrepresentative persona sets. In this paper, we propose a systematic framework for synthesizing high-quality, population-aligned persona sets for LLM-driven social simulation. Our approach begins by leveraging LLMs to generate narrative personas from long-term social media data, followed by rigorous quality assessment to filter out low-fidelity profiles. We then apply importance sampling to achieve global alignment with reference psychometric distributions, such as the Big Five personality traits. To address the needs of specific simulation contexts, we further introduce a task-specific module that adapts the globally aligned persona set to targeted subpopulations. Extensive experiments demonstrate that our method significantly reduces population-level bias and enables accurate, flexible social simulation for a wide range of research and policy applications.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.10127.pdf", "abstract_url": "https://arxiv.org/abs/2509.10127", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种系统框架，用于生成与人口分布对齐的高质量角色集，以减少基于大语言模型的社会模拟中的偏见，并通过实验验证其有效性。", "motivation": "解决在大语言模型驱动的社会模拟中，角色集构建缺乏真实多样性和分布代表性，导致潜在偏见的问题。", "method": "利用大语言模型从社交媒体数据生成叙事角色，进行质量评估过滤，应用重要性采样与参考心理测量分布对齐，并引入任务特定模块适应子群体。", "result": "实验表明，该方法显著减少人口级偏见，支持准确灵活的社会模拟，适用于广泛研究和政策应用。", "conclusion": "该框架能生成高质量、对齐人口的角色集，提升社会模拟的真实性和实用性，为计算社会科学提供新工具。"}}
{"id": "2509.10222", "title": "Compartmentalised Agentic Reasoning for Clinical NLI", "authors": ["Maël Jullien", "Lei Xu", "Marco Valentino", "André Freitas"], "abstract": "A common assumption holds that scaling data and parameters yields increasingly structured, generalisable internal representations. We interrogate this assumption in clinical natural language inference (NLI) by adopting a benchmark decomposed into four reasoning families, Causal Attribution, Compositional Grounding, Epistemic Verification, and Risk State Abstraction, and introducing CARENLI, a Compartmentalised Agentic Reasoning for Clinical NLI that separates knowledge access from principled inference. CARENLI routes each premise, statement pair to a family specific solver and enforces auditable procedures via a planner, verifier, and refiner.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.10222.pdf", "abstract_url": "https://arxiv.org/abs/2509.10222", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "该论文质疑数据和参数扩展能带来结构化内部表示的假设，在临床自然语言推理中引入CARENLI方法，通过分解推理家族和分离知识访问与推理来提升可泛化性。", "motivation": "解决临床自然语言推理中数据和参数扩展不一定导致结构化、可泛化内部表示的问题。", "method": "采用CARENLI方法，将前提-陈述对路由到特定推理家族的求解器，并通过规划器、验证器和精炼器强制执行可审计程序。", "result": "CARENLI在分解的基准上展示了改进的可泛化性和可审计推理过程。", "conclusion": "CARENLI方法有效提升了临床NLI的结构化推理和泛化能力，具有实际应用价值。"}}
{"id": "2509.10401", "title": "Abduct, Act, Predict: Scaffolding Causal Inference for Automated Failure Attribution in Multi-Agent Systems", "authors": ["Alva West", "Yixuan Weng", "Minjun Zhu", "Zhen Lin", "Yue Zhang"], "abstract": "Failure attribution in multi-agent systems -- pinpointing the exact step where a decisive error occurs -- is a critical yet unsolved challenge. Current methods treat this as a pattern recognition task over long conversation logs, leading to critically low step-level accuracy (below 17\\%), which renders them impractical for debugging complex systems. Their core weakness is a fundamental inability to perform robust counterfactual reasoning: to determine if correcting a single action would have actually averted the task failure. To bridge this counterfactual inference gap, we introduce Abduct-Act-Predict (A2P) Scaffolding, a novel agent framework that transforms failure attribution from pattern recognition into a structured causal inference task. A2P explicitly guides a large language model through a formal three-step reasoning process within a single inference pass: (1) Abduction, to infer the hidden root causes behind an agent's actions; (2) Action, to define a minimal corrective intervention; and (3) Prediction, to simulate the subsequent trajectory and verify if the intervention resolves the failure. This structured approach leverages the holistic context of the entire conversation while imposing a rigorous causal logic on the model's analysis. Our extensive experiments on the Who\\&When benchmark demonstrate its efficacy. On the Algorithm-Generated dataset, A2P achieves 47.46\\% step-level accuracy, a 2.85$\\times$ improvement over the 16.67\\% of the baseline. On the more complex Hand-Crafted dataset, it achieves 29.31\\% step accuracy, a 2.43$\\times$ improvement over the baseline's 12.07\\%. By reframing the problem through a causal lens, A2P Scaffolding provides a robust, verifiable, and significantly more accurate solution for automated failure attribution.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.10401.pdf", "abstract_url": "https://arxiv.org/abs/2509.10401", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出A2P框架，通过因果推理改进多智能体系统中的失败归因，显著提高准确性。", "motivation": "解决多智能体系统中失败归因准确率低的问题，当前方法缺乏反事实推理能力。", "method": "使用Abduct-Act-Predict（A2P）框架，指导大语言模型进行三步因果推理：溯因、行动和预测。", "result": "在基准测试中，A2P将步骤级准确率从基线16.67%提升至47.46%，在复杂数据集上从12.07%提升至29.31%。", "conclusion": "A2P通过因果推理提供更鲁棒、可验证的失败归因解决方案，适用于复杂系统调试。"}}
{"id": "2509.09470", "title": "AEGIS: An Agent for Extraction and Geographic Identification in Scholarly Proceedings", "authors": ["Om Vishesh", "Harshad Khadilkar", "Deepak Akkil"], "abstract": "Keeping pace with the rapid growth of academia literature presents a significant challenge for researchers, funding bodies, and academic societies. To address the time-consuming manual effort required for scholarly discovery, we present a novel, fully automated system that transitions from data discovery to direct action. Our pipeline demonstrates how a specialized AI agent, 'Agent-E', can be tasked with identifying papers from specific geographic regions within conference proceedings and then executing a Robotic Process Automation (RPA) to complete a predefined action, such as submitting a nomination form. We validated our system on 586 papers from five different conferences, where it successfully identified every target paper with a recall of 100% and a near perfect accuracy of 99.4%. This demonstration highlights the potential of task-oriented AI agents to not only filter information but also to actively participate in and accelerate the workflows of the academic community.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "5 pages, 2 figures", "pdf_url": "https://arxiv.org/pdf/2509.09470.pdf", "abstract_url": "https://arxiv.org/abs/2509.09470", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "AEGIS是一个自动化系统，使用AI代理从学术会议中识别特定地理区域的论文，并通过RPA执行预定义操作，验证显示高召回率和准确性。", "motivation": "解决学术文献快速增长带来的手动发现耗时问题，为研究人员、资助机构和学术团体提供自动化支持。", "method": "开发一个AI代理（Agent-E）和RPA管道，从会议论文中提取和识别地理信息，并自动执行如提交提名表格等操作。", "result": "在5个会议的586篇论文上验证，系统成功识别所有目标论文，召回率100%，准确率99.4%。", "conclusion": "任务导向AI代理有潜力过滤信息并加速学术工作流程，提高效率。"}}
{"id": "2509.10423", "title": "Mutual Information Tracks Policy Coherence in Reinforcement Learning", "authors": ["Cameron Reid", "Wael Hafez", "Amirhossein Nazeri"], "abstract": "Reinforcement Learning (RL) agents deployed in real-world environments face degradation from sensor faults, actuator wear, and environmental shifts, yet lack intrinsic mechanisms to detect and diagnose these failures. We present an information-theoretic framework that reveals both the fundamental dynamics of RL and provides practical methods for diagnosing deployment-time anomalies. Through analysis of state-action mutual information patterns in a robotic control task, we first demonstrate that successful learning exhibits characteristic information signatures: mutual information between states and actions steadily increases from 0.84 to 2.83 bits (238% growth) despite growing state entropy, indicating that agents develop increasingly selective attention to task-relevant patterns. Intriguingly, states, actions and next states joint mutual information, MI(S,A;S'), follows an inverted U-curve, peaking during early learning before declining as the agent specializes suggesting a transition from broad exploration to efficient exploitation. More immediately actionable, we show that information metrics can differentially diagnose system failures: observation-space, i.e., states noise (sensor faults) produces broad collapses across all information channels with pronounced drops in state-action coupling, while action-space noise (actuator faults) selectively disrupts action-outcome predictability while preserving state-action relationships. This differential diagnostic capability demonstrated through controlled perturbation experiments enables precise fault localization without architectural modifications or performance degradation. By establishing information patterns as both signatures of learning and diagnostic for system health, we provide the foundation for adaptive RL systems capable of autonomous fault detection and policy adjustment based on information-theoretic principles.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Robotics (cs.RO)", "comments": "10 pages, 4 figures, 1 table", "pdf_url": "https://arxiv.org/pdf/2509.10423.pdf", "abstract_url": "https://arxiv.org/abs/2509.10423", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于互信息的信息论框架，用于跟踪强化学习中的策略一致性，并诊断部署时的异常，如传感器或执行器故障，通过分析状态-动作互信息模式实现自主故障检测和策略调整。", "motivation": "强化学习代理在真实环境中部署时面临传感器故障、执行器磨损和环境变化导致的性能退化，但缺乏内在机制来检测和诊断这些故障。", "method": "使用信息论框架分析状态-动作互信息模式，包括状态-动作互信息和状态-动作-下一状态联合互信息的动态变化，并通过受控扰动实验验证诊断能力。", "result": "成功学习显示状态-动作互信息从0.84比特增长到2.83比特（238%增长），联合互信息呈倒U型曲线；信息指标能区分传感器故障（广泛崩溃）和执行器故障（选择性破坏），实现精确故障定位。", "conclusion": "信息模式可作为学习和系统健康的签名，为自适应强化学习系统提供基础，支持自主故障检测和基于信息论原则的策略调整。"}}
{"id": "2509.09681", "title": "DB3 Team's Solution For Meta KDD Cup' 25", "authors": ["Yikuan Xia", "Jiazun Chen", "Yirui Zhan", "Suifeng Zhao", "Weipeng Jiang", "Chaorui Zhang", "Wei Han", "Bo Bai", "Jun Gao"], "abstract": "This paper presents the db3 team's winning solution for the Meta CRAG-MM Challenge 2025 at KDD Cup'25. Addressing the challenge's unique multi-modal, multi-turn question answering benchmark (CRAG-MM), we developed a comprehensive framework that integrates tailored retrieval pipelines for different tasks with a unified LLM-tuning approach for hallucination control. Our solution features (1) domain-specific retrieval pipelines handling image-indexed knowledge graphs, web sources, and multi-turn conversations; and (2) advanced refusal training using SFT, DPO, and RL. The system achieved 2nd place in Task 1, 2nd place in Task 2, and 1st place in Task 3, securing the grand prize for excellence in ego-centric queries through superior handling of first-person perspective challenges.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.09681.pdf", "abstract_url": "https://arxiv.org/abs/2509.09681", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了db3团队在Meta KDD Cup'25的CRAG-MM挑战中的获奖解决方案，通过集成多模态检索管道和统一LLM调优方法，有效控制幻觉，在多个任务中取得优异成绩。", "motivation": "解决CRAG-MM基准中的多模态、多轮问答挑战，特别是处理以自我为中心的查询问题。", "method": "开发了领域特定检索管道（处理图像索引知识图谱、网络来源和多轮对话）和高级拒绝训练（使用SFT、DPO和RL）。", "result": "在Task 1和Task 2中获第二名，Task 3中获第一名，赢得总奖，展示了在自我中心查询处理上的优越性。", "conclusion": "该框架成功整合了检索和LLM调优，为多模态问答系统提供了有效解决方案，具有实际应用价值。"}}
{"id": "2509.09685", "title": "TalkPlayData 2: An Agentic Synthetic Data Pipeline for Multimodal Conversational Music Recommendation", "authors": ["Keunwoo Choi", "Seungheon Doh", "Juhan Nam"], "abstract": "We present TalkPlayData 2, a synthetic dataset for multimodal conversational music recommendation generated by an agentic data pipeline. In TalkPlayData 2 pipeline, multiple large language model (LLM) agents are created under various roles with specialized prompts and access to different parts of information, and the chat data is acquired by logging the conversation between the Listener LLM and the Recsys LLM. To cover various conversation scenarios, for each conversation, the Listener LLM is conditioned on a finetuned conversation goal. Finally, all the LLMs are multimodal with audio and images, allowing a simulation of multimodal recommendation and conversation. In the LLM-as-a-judge and subjective evaluation experiments, TalkPlayData 2 achieved the proposed goal in various aspects related to training a generative recommendation model for music. TalkPlayData 2 and its generation code are open-sourced at", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI); Multimedia (cs.MM); Sound (cs.SD); Audio and Speech Processing (eess.AS)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.09685.pdf", "abstract_url": "https://arxiv.org/abs/2509.09685", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)", "Multimedia (cs.MM)", "Sound (cs.SD)", "Audio and Speech Processing (eess.AS)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "TalkPlayData 2 是一个通过多代理LLM管道生成的合成数据集，用于多模态对话式音乐推荐，支持音频和图像，并通过评估验证其有效性。", "motivation": "解决多模态对话式音乐推荐中缺乏高质量训练数据的问题。", "method": "使用多个角色化的LLM代理（如Listener和Recsys LLM）进行对话生成，基于专门提示和条件化目标，并整合多模态输入。", "result": "在LLM作为评判和主观评估中，数据集成功实现了训练生成式音乐推荐模型的目标。", "conclusion": "TalkPlayData 2 提供了一个有效的合成数据解决方案，可促进多模态推荐系统的开发，并已开源。"}}
{"id": "2509.09686", "title": "GeoGPT.RAG Technical Report", "authors": ["Fei Huang", "Fan Wu", "Zeqing Zhang", "Qihao Wang", "Long Zhang", "Grant Michael Boquet", "Hongyang Chen"], "abstract": "GeoGPT is an open large language model system built to advance research in the geosciences. To enhance its domain-specific capabilities, we integrated Retrieval Augmented Generation(RAG), which augments model outputs with relevant information retrieved from an external knowledge source. GeoGPT uses RAG to draw from the GeoGPT Library, a specialized corpus curated for geoscientific content, enabling it to generate accurate, context-specific answers. Users can also create personalized knowledge bases by uploading their own publication lists, allowing GeoGPT to retrieve and respond using user-provided materials. To further improve retrieval quality and domain alignment, we fine-tuned both the embedding model and a ranking model that scores retrieved passages by relevance to the query. These enhancements optimize RAG for geoscience applications and significantly improve the system's ability to deliver precise and trustworthy outputs. GeoGPT reflects a strong commitment to open science through its emphasis on collaboration, transparency, and community driven development. As part of this commitment, we have open-sourced two core RAG components-GeoEmbedding and GeoReranker-to support geoscientists, researchers, and professionals worldwide with powerful, accessible AI tools.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "comments": "19 pages, 10 figures, 10 tables", "pdf_url": "https://arxiv.org/pdf/2509.09686.pdf", "abstract_url": "https://arxiv.org/abs/2509.09686", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "GeoGPT是一个开源大语言模型系统，集成检索增强生成（RAG）技术，利用专业地学知识库和用户自定义知识库，通过优化嵌入和排序模型提升检索质量，旨在提供精确可靠的地学AI工具。", "motivation": "解决地学领域大语言模型缺乏领域特定能力和准确性的问题，通过RAG技术增强模型输出，提升信息检索和响应的精确度。", "method": "集成RAG技术，从GeoGPT Library检索相关信息；允许用户上传个性化知识库；微调嵌入模型和排序模型以优化检索相关性和领域对齐。", "result": "系统能够生成准确、上下文相关的答案，检索质量和领域对齐显著改善，提供更精确和可信的输出。", "conclusion": "GeoGPT通过开源核心组件促进开放科学，支持全球地学研究和专业人士使用，强调协作、透明和社区驱动的发展。"}}
{"id": "2509.10436", "title": "RefactorCoderQA: Benchmarking LLMs for Multi-Domain Coding Question Solutions in Cloud and Edge Deployment", "authors": ["Shadikur Rahman", "Aroosa Hameed", "Gautam Srivastava", "Syed Muhammad Danish"], "abstract": "To optimize the reasoning and problem-solving capabilities of Large Language Models (LLMs), we propose a novel cloud-edge collaborative architecture that enables a structured, multi-agent prompting framework. This framework comprises three specialized components: GuideLLM, a lightweight model deployed at the edge to provide methodological guidance; SolverLLM, a more powerful model hosted in the cloud responsible for generating code solutions; and JudgeLLM, an automated evaluator for assessing solution correctness and quality. To evaluate and demonstrate the effectiveness of this architecture in realistic settings, we introduce RefactorCoderQA, a comprehensive benchmark designed to evaluate and enhance the performance of Large Language Models (LLMs) across multi-domain coding tasks. Motivated by the limitations of existing benchmarks, RefactorCoderQA systematically covers various technical domains, including Software Engineering, Data Science, Machine Learning, and Natural Language Processing, using authentic coding challenges from Stack Overflow. Extensive experiments reveal that our fine-tuned model, RefactorCoder-MoE, achieves state-of-the-art performance, significantly outperforming leading open-source and commercial baselines with an overall accuracy of 76.84%. Human evaluations further validate the interpretability, accuracy, and practical relevance of the generated solutions. In addition, we evaluate system-level metrics, such as throughput and latency, to gain deeper insights into the performance characteristics and trade-offs of the proposed architecture.", "subjects": "Computation and Language (cs.CL)", "comments": "12 pages, 5 figures, submitted to IEEE Transactions on Services Computing", "pdf_url": "https://arxiv.org/pdf/2509.10436.pdf", "abstract_url": "https://arxiv.org/abs/2509.10436", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "提出RefactorCoderQA基准和云边协作架构，优化LLM在多领域编码任务中的性能，实现76.84%的准确率。", "motivation": "解决现有基准在评估LLM多领域编码能力方面的局限性，提升推理和问题解决能力。", "method": "使用云边协作架构，包括GuideLLM、SolverLLM和JudgeLLM，结合RefactorCoderQA基准进行实验评估。", "result": "RefactorCoder-MoE模型达到76.84%的准确率，优于基线，并通过人类评估和系统指标验证。", "conclusion": "该架构和基准有效提升LLM性能，具有实际应用价值。"}}
{"id": "2509.10446", "title": "DeepDive: Advancing Deep Search Agents with Knowledge Graphs and Multi-Turn RL", "authors": ["Rui Lu", "Zhenyu Hou", "Zihan Wang", "Hanchen Zhang", "Xiao Liu", "Yujiang Li", "Shi Feng", "Jie Tang", "Yuxiao Dong"], "abstract": "Augmenting large language models (LLMs) with browsing tools substantially improves their potential as deep search agents to solve complex, real-world tasks. Yet, open LLMs still perform poorly in such settings due to limited long-horizon reasoning capacity with browsing tools and the lack of sufficiently difficult supervised data. To address these challenges, we present DeepDive to advance deep search agents. First, we propose a strategy to automatically synthesize complex, difficult, and hard-to-find questions from open knowledge graphs. Second, we apply end-to-end multi-turn reinforcement learning (RL) to enhance LLMs' long-horizon reasoning with deep search. Experiments show that DeepDive-32B achieves a new open-source competitive result on BrowseComp, outperforming WebSailor, DeepSeek-R1-Browse, and Search-o1. We demonstrate that multi-turn RL training improves deep search ability and significantly contributes to the performance improvements across multiple benchmarks. We observe that DeepDive enables test-time scaling of tool calls and parallel sampling. All datasets, models, and code are publicly available at", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.10446.pdf", "abstract_url": "https://arxiv.org/abs/2509.10446", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "DeepDive通过知识图谱合成复杂问题和多轮强化学习，提升大型语言模型作为深度搜索代理的性能，在BrowseComp基准测试中取得开源竞争性结果。", "motivation": "解决大型语言模型在浏览工具辅助下长程推理能力不足和缺乏高难度监督数据的问题。", "method": "自动从开放知识图谱合成复杂问题，并应用端到端多轮强化学习来增强模型的长程推理能力。", "result": "DeepDive-32B在BrowseComp上超越WebSailor等模型，多轮强化学习显著提升性能，并支持测试时工具调用扩展和并行采样。", "conclusion": "DeepDive有效提升了深度搜索代理的能力，数据集、模型和代码已公开。"}}
{"id": "2509.09689", "title": "Personas within Parameters: Fine-Tuning Small Language Models with Low-Rank Adapters to Mimic User Behaviors", "authors": ["Himanshu Thakur", "Eshani Agrawal", "Smruthi Mukund"], "abstract": "A long-standing challenge in developing accurate recommendation models is simulating user behavior, mainly due to the complex and stochastic nature of user interactions. Towards this, one promising line of work has been the use of Large Language Models (LLMs) for simulating user behavior. However, aligning these general-purpose large pre-trained models with user preferences necessitates: (i) effectively and continously parsing large-scale tabular user-item interaction data, (ii) overcoming pre-training-induced inductive biases to accurately learn user specific knowledge, and (iii) achieving the former two at scale for millions of users. While most previous works have focused on complex methods to prompt an LLM or fine-tune it on tabular interaction datasets, our approach shifts the focus to extracting robust textual user representations using a frozen LLM and simulating cost-effective, resource-efficient user agents powered by fine-tuned Small Language Models (SLMs). Further, we showcase a method for training multiple low-rank adapters for groups of users or \\textit{persona}, striking an optimal balance between scalability and performance of user behavior agents. Our experiments provide compelling empirical evidence of the efficacy of our methods, demonstrating that user agents developed using our approach have the potential to bridge the gap between offline metrics and real-world performance of recommender systems.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.09689.pdf", "abstract_url": "https://arxiv.org/abs/2509.09689", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文提出了一种使用冻结大型语言模型提取用户表示，并通过微调小型语言模型和低秩适配器来高效模拟用户行为的方法，以提高推荐系统的性能和可扩展性。", "motivation": "解决推荐模型中模拟用户行为的挑战，包括处理大规模交互数据、克服预训练偏见以及实现可扩展性。", "method": "使用冻结大型语言模型提取用户表示，微调小型语言模型，并为用户群体训练低秩适配器以平衡可扩展性和性能。", "result": "实验表明，该方法能有效模拟用户行为，缩小离线指标与真实世界推荐系统性能之间的差距。", "conclusion": "该方法提供了一种资源高效的方式，通过用户代理提升推荐系统的准确性和实用性。"}}
{"id": "2509.09740", "title": "HypoGeneAgent: A Hypothesis Language Agent for Gene-Set Cluster Resolution Selection Using Perturb-seq Datasets", "authors": ["Ying Yuan", "Xing-Yue Monica Ge", "Aaron Archer Waterman", "Tommaso Biancalani", "David Richmond", "Yogesh Pandit", "Avtar Singh", "Russell Littman", "Jin Liu", "Jan-Christian Huetter", "Vladimir Ermakov"], "abstract": "Large-scale single-cell and Perturb-seq investigations routinely involve clustering cells and subsequently annotating each cluster with Gene-Ontology (GO) terms to elucidate the underlying biological programs. However, both stages, resolution selection and functional annotation, are inherently subjective, relying on heuristics and expert curation. We present HYPOGENEAGENT, a large language model (LLM)-driven framework, transforming cluster annotation into a quantitatively optimizable task. Initially, an LLM functioning as a gene-set analyst analyzes the content of each gene program or perturbation module and generates a ranked list of GO-based hypotheses, accompanied by calibrated confidence scores. Subsequently, we embed every predicted description with a sentence-embedding model, compute pair-wise cosine similarities, and let the agent referee panel score (i) the internal consistency of the predictions, high average similarity within the same cluster, termed intra-cluster agreement (ii) their external distinctiveness, low similarity between clusters, termed inter-cluster separation. These two quantities are combined to produce an agent-derived resolution score, which is maximized when clusters exhibit simultaneous coherence and mutual exclusivity. When applied to a public K562 CRISPRi Perturb-seq dataset as a preliminary test, our Resolution Score selects clustering granularities that exhibit alignment with known pathway compared to classical metrics such silhouette score, modularity score for gene functional enrichment summary. These findings establish LLM agents as objective adjudicators of cluster resolution and functional annotation, thereby paving the way for fully automated, context-aware interpretation pipelines in single-cell multi-omics studies.", "subjects": "Quantitative Methods (q-bio.QM); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.09740.pdf", "abstract_url": "https://arxiv.org/abs/2509.09740", "categories": ["Quantitative Methods (q-bio.QM)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "HypoGeneAgent uses an LLM to generate and score GO-based hypotheses for gene-set clusters, optimizing resolution selection in Perturb-seq data via intra-cluster agreement and inter-cluster separation metrics.", "motivation": "To address the subjectivity and reliance on heuristics in clustering resolution selection and functional annotation in single-cell studies like Perturb-seq.", "method": "An LLM generates ranked GO hypotheses with confidence scores; sentence embeddings compute cosine similarities for intra-cluster agreement and inter-cluster separation, combined into a resolution score for optimization.", "result": "Applied to a K562 CRISPRi Perturb-seq dataset, the resolution score outperformed traditional metrics like silhouette score in aligning with known biological pathways.", "conclusion": "LLM agents enable objective, automated cluster resolution and annotation, advancing automated interpretation in single-cell multi-omics research."}}
{"id": "2509.09864", "title": "Latency and Token-Aware Test-Time Compute", "authors": ["Jenny Y. Huang", "Mehul Damani", "Yousef El-Kurdi", "Ramon Astudillo", "Wei Sun"], "abstract": "Inference-time scaling has emerged as a powerful way to improve large language model (LLM) performance by generating multiple candidate responses and selecting among them. However, existing work on dynamic allocation for test-time compute typically considers only parallel generation methods such as best-of-N, overlooking incremental decoding methods like beam search, and has largely ignored latency, focusing only on token usage. We formulate inference-time scaling as a problem of dynamic compute allocation and method selection, where the system must decide which strategy to apply and how much compute to allocate on a per-query basis. Our framework explicitly incorporates both token cost and wall-clock latency, the latter being critical for user experience and particularly for agentic workflows where models must issue multiple queries efficiently. Experiments on reasoning benchmarks show that our approach consistently outperforms static strategies, achieving favorable accuracy-cost trade-offs while remaining practical for deployment.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.09864.pdf", "abstract_url": "https://arxiv.org/abs/2509.09864", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种动态计算分配框架，在推理时优化大语言模型的性能和效率，综合考虑令牌成本和延迟，优于静态策略。", "motivation": "解决现有推理时缩放方法仅关注令牌使用而忽略延迟的问题，特别是在需要高效多查询的代理工作流中。", "method": "动态计算分配和方法选择框架，结合令牌成本和墙钟延迟，在每查询基础上决定策略和计算量。", "result": "在推理基准测试中，该方法 consistently 优于静态策略，实现更好的准确性与成本权衡，并具有部署实用性。", "conclusion": "该框架有效提升LLM性能，同时控制延迟和成本，适用于实际部署，强调了动态分配的重要性。"}}
{"id": "2509.09870", "title": "Vibe Check: Understanding the Effects of LLM-Based Conversational Agents' Personality and Alignment on User Perceptions in Goal-Oriented Tasks", "authors": ["Hasibur Rahman", "Smit Desai"], "abstract": "Large language models (LLMs) enable conversational agents (CAs) to express distinctive personalities, raising new questions about how such designs shape user perceptions. This study investigates how personality expression levels and user-agent personality alignment influence perceptions in goal-oriented tasks. In a between-subjects experiment (N=150), participants completed travel planning with CAs exhibiting low, medium, or high expression across the Big Five traits, controlled via our novel Trait Modulation Keys framework. Results revealed an inverted-U relationship: medium expression produced the most positive evaluations across Intelligence, Enjoyment, Anthropomorphism, Intention to Adopt, Trust, and Likeability, significantly outperforming both extremes. Personality alignment further enhanced outcomes, with Extraversion and Emotional Stability emerging as the most influential traits. Cluster analysis identified three distinct compatibility profiles, with \"Well-Aligned\" users reporting substantially positive perceptions. These findings demonstrate that personality expression and strategic trait alignment constitute optimal design targets for CA personality, offering design implications as LLM-based CAs become increasingly prevalent.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.09870.pdf", "abstract_url": "https://arxiv.org/abs/2509.09870", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "研究探讨LLM对话代理的人格表达水平和用户-代理人格对齐如何影响目标导向任务中的用户感知，发现中等表达水平和对齐能带来最积极评价。", "motivation": "解决LLM对话代理人格设计如何影响用户感知的问题，以优化设计并提升用户体验。", "method": "使用Trait Modulation Keys框架进行组间实验（N=150），参与者完成旅行规划任务，代理展示不同Big Five特质表达水平。", "result": "中等表达水平产生最积极评价（如智力、信任），人格对齐进一步改善结果，外向性和情绪稳定性是关键特质，聚类分析识别出三种兼容性档案。", "conclusion": "人格表达和战略对齐是优化CA人格设计的关键，为LLM代理的广泛应用提供设计指导。"}}
{"id": "2509.09751", "title": "Meta-Learning Reinforcement Learning for Crypto-Return Prediction", "authors": ["Junqiao Wang", "Zhaoyang Guan", "Guanyu Liu", "Tianze Xia", "Xianzhi Li", "Shuo Yin", "Xinyuan Song", "Chuhan Cheng", "Tianyu Shi", "Alex Lee"], "abstract": "Predicting cryptocurrency returns is notoriously difficult: price movements are driven by a fast-shifting blend of on-chain activity, news flow, and social sentiment, while labeled training data are scarce and expensive. In this paper, we present Meta-RL-Crypto, a unified transformer-based architecture that unifies meta-learning and reinforcement learning (RL) to create a fully self-improving trading agent. Starting from a vanilla instruction-tuned LLM, the agent iteratively alternates between three roles-actor, judge, and meta-judge-in a closed-loop architecture. This learning process requires no additional human supervision. It can leverage multimodal market inputs and internal preference feedback. The agent in the system continuously refines both the trading policy and evaluation criteria. Experiments across diverse market regimes demonstrate that Meta-RL-Crypto shows good performance on the technical indicators of the real market and outperforming other LLM-based baselines.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.09751.pdf", "abstract_url": "https://arxiv.org/abs/2509.09751", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出Meta-RL-Crypto，一种结合元学习和强化学习的Transformer架构，用于加密货币回报预测，无需人工监督，通过多角色闭环学习实现自我改进的交易代理。", "motivation": "解决加密货币回报预测的挑战，包括数据稀缺、价格驱动因素复杂且快速变化的问题。", "method": "使用基于Transformer的架构，整合元学习和强化学习，代理在actor、judge和meta-judge角色间迭代，利用多模态输入和内部反馈进行闭环学习。", "result": "实验表明，Meta-RL-Crypto在多种市场环境下表现良好，优于其他基于LLM的基线方法，并在真实市场技术指标上显示出优势。", "conclusion": "该方法提供了一种全自动、自我改进的预测框架，具有实际应用潜力，可扩展到其他金融预测任务。"}}
{"id": "2509.09853", "title": "SWE-Effi: Re-Evaluating Software AI Agent System Effectiveness Under Resource Constraints", "authors": ["Zhiyu Fan", "Kirill Vasilevski", "Dayi Lin", "Boyuan Chen", "Yihao Chen", "Zhiqing Zhong", "Jie M. Zhang", "Pinjia He", "Ahmed E. Hassan"], "abstract": "The advancement of large language models (LLMs) and code agents has demonstrated significant potential to assist software engineering (SWE) tasks, such as autonomous issue resolution and feature addition. Existing AI for software engineering leaderboards (e.g., SWE-bench) focus solely on solution accuracy, ignoring the crucial factor of effectiveness in a resource-constrained world. This is a universal problem that also exists beyond software engineering tasks: any AI system should be more than correct - it must also be cost-effective. To address this gap, we introduce SWE-Effi, a set of new metrics to re-evaluate AI systems in terms of holistic effectiveness scores. We define effectiveness as the balance between the accuracy of outcome (e.g., issue resolve rate) and the resources consumed (e.g., token and time). In this paper, we specifically focus on the software engineering scenario by re-ranking popular AI systems for issue resolution on a subset of the SWE-bench benchmark using our new multi-dimensional metrics. We found that AI system's effectiveness depends not just on the scaffold itself, but on how well it integrates with the base model, which is key to achieving strong performance in a resource-efficient manner. We also identified systematic challenges such as the \"token snowball\" effect and, more significantly, a pattern of \"expensive failures\". In these cases, agents consume excessive resources while stuck on unsolvable tasks - an issue that not only limits practical deployment but also drives up the cost of failed rollouts during RL training. Lastly, we observed a clear trade-off between effectiveness under the token budget and effectiveness under the time budget, which plays a crucial role in managing project budgets and enabling scalable reinforcement learning, where fast responses are essential.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.09853.pdf", "abstract_url": "https://arxiv.org/abs/2509.09853", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了SWE-Effi，一套新指标来评估AI系统在资源约束下的整体有效性，强调准确性与资源消耗的平衡，并应用于软件工程场景。", "motivation": "现有AI系统评估仅关注准确性，忽略了资源效率这一关键问题，导致在实际部署中成本高昂和效率低下。", "method": "通过定义多维度指标（如准确率和资源消耗），重新排名SWE-bench基准上的AI系统，分析其集成和资源使用模式。", "result": "发现系统有效性依赖于模型集成，存在'令牌雪球'和'昂贵失败'等挑战，并观察到令牌预算和时间预算之间的权衡。", "conclusion": "SWE-Effi指标有助于优化AI系统部署，降低成本，并促进可扩展的强化学习，强调资源效率的重要性。"}}
{"id": "2509.09893", "title": "Self-Augmented Robot Trajectory: Efficient Imitation Learning via Safe Self-augmentation with Demonstrator-annotated Precision", "authors": ["Hanbit Oh", "Masaki Murooka", "Tomohiro Motoda", "Ryoichi Nakajo", "Yukiyasu Domae"], "abstract": "Imitation learning is a promising paradigm for training robot agents; however, standard approaches typically require substantial data acquisition -- via numerous demonstrations or random exploration -- to ensure reliable performance. Although exploration reduces human effort, it lacks safety guarantees and often results in frequent collisions -- particularly in clearance-limited tasks (e.g., peg-in-hole) -- thereby, necessitating manual environmental resets and imposing additional human burden. This study proposes Self-Augmented Robot Trajectory (SART), a framework that enables policy learning from a single human demonstration, while safely expanding the dataset through autonomous augmentation. SART consists of two stages: (1) human teaching only once, where a single demonstration is provided and precision boundaries -- represented as spheres around key waypoints -- are annotated, followed by one environment reset; (2) robot self-augmentation, where the robot generates diverse, collision-free trajectories within these boundaries and reconnects to the original demonstration. This design improves the data collection efficiency by minimizing human effort while ensuring safety. Extensive evaluations in simulation and real-world manipulation tasks show that SART achieves substantially higher success rates than policies trained solely on human-collected demonstrations. Video results available at", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": "Under review", "pdf_url": "https://arxiv.org/pdf/2509.09893.pdf", "abstract_url": "https://arxiv.org/abs/2509.09893", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "提出SART框架，通过单次人类演示和自主安全增强，高效学习机器人策略，减少人力需求并确保安全。", "motivation": "解决模仿学习中数据获取量大、安全性差的问题，特别是在间隙有限的任务中减少碰撞和人工重置负担。", "method": "SART框架包括单次人类演示标注精度边界，以及机器人自主生成无碰撞轨迹并连接回原演示。", "result": "在仿真和真实任务中，SART比仅基于人类演示的策略获得更高的成功率。", "conclusion": "SART有效提升数据收集效率和安全性，减少人类干预，适用于机器人模仿学习。"}}
{"id": "2509.09970", "title": "Securing LLM-Generated Embedded Firmware through AI Agent-Driven Validation and Patching", "authors": ["Seyed Moein Abtahi", "Akramul Azim"], "abstract": "Large Language Models (LLMs) show promise in generating firmware for embedded systems, but often introduce security flaws and fail to meet real-time performance constraints. This paper proposes a three-phase methodology that combines LLM-based firmware generation with automated security validation and iterative refinement in a virtualized environment. Using structured prompts, models like GPT-4 generate firmware for networking and control tasks, deployed on FreeRTOS via QEMU. These implementations are tested using fuzzing, static analysis, and runtime monitoring to detect vulnerabilities such as buffer overflows (CWE-120), race conditions (CWE-362), and denial-of-service threats (CWE-400). Specialized AI agents for Threat Detection, Performance Optimization, and Compliance Verification collaborate to improve detection and remediation. Identified issues are categorized using CWE, then used to prompt targeted LLM-generated patches in an iterative loop. Experiments show a 92.4\\% Vulnerability Remediation Rate (37.3\\% improvement), 95.8\\% Threat Model Compliance, and 0.87 Security Coverage Index. Real-time metrics include 8.6ms worst-case execution time and 195{\\mu}s jitter. This process enhances firmware security and performance while contributing an open-source dataset for future research.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.09970.pdf", "abstract_url": "https://arxiv.org/abs/2509.09970", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种结合LLM生成固件、自动化安全验证和迭代修复的三阶段方法，在虚拟化环境中提升嵌入式固件的安全性和实时性能。", "motivation": "解决LLM生成嵌入式固件时引入的安全漏洞和实时性能约束问题。", "method": "使用结构化提示和GPT-4等模型生成固件，通过模糊测试、静态分析和运行时监控检测漏洞，并利用AI代理进行迭代修复。", "result": "实验显示92.4%的漏洞修复率、95.8%的威胁模型合规性和0.87的安全覆盖指数，实时性能指标包括8.6ms最坏执行时间和195μs抖动。", "conclusion": "该方法显著增强固件安全性和性能，并贡献开源数据集供未来研究。"}}
{"id": "2509.09906", "title": "Tackling One Health Risks: How Large Language Models are leveraged for Risk Negotiation and Consensus-building", "authors": ["Alexandra Fetsch", "Iurii Savvateev", "Racem Ben Romdhane", "Martin Wiedmann", "Artemiy Dimov", "Maciej Durkalec", "Josef Teichmann", "Jakob Zinsstag", "Konstantinos Koutsoumanis", "Andreja Rajkovic", "Jason Mann", "Mauro Tonolla", "Monika Ehling-Schulz", "Matthias Filter", "Sophia Johler"], "abstract": "Key global challenges of our times are characterized by complex interdependencies and can only be effectively addressed through an integrated, participatory effort. Conventional risk analysis frameworks often reduce complexity to ensure manageability, creating silos that hinder comprehensive solutions. A fundamental shift towards holistic strategies is essential to enable effective negotiations between different sectors and to balance the competing interests of stakeholders. However, achieving this balance is often hindered by limited time, vast amounts of information, and the complexity of integrating diverse perspectives. This study presents an AI-assisted negotiation framework that incorporates large language models (LLMs) and AI-based autonomous agents into a negotiation-centered risk analysis workflow. The framework enables stakeholders to simulate negotiations, systematically model dynamics, anticipate compromises, and evaluate solution impacts. By leveraging LLMs' semantic analysis capabilities we could mitigate information overload and augment decision-making process under time constraints. Proof-of-concept implementations were conducted in two real-world scenarios: (i) prudent use of a biopesticide, and (ii) targeted wild animal population control. Our work demonstrates the potential of AI-assisted negotiation to address the current lack of tools for cross-sectoral engagement. Importantly, the solution's open source, web based design, suits for application by a broader audience with limited resources and enables users to tailor and develop it for their own needs.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.09906.pdf", "abstract_url": "https://arxiv.org/abs/2509.09906", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于大型语言模型和AI自主代理的AI辅助谈判框架，用于解决One Health风险中的跨部门协商和共识构建问题，通过概念验证展示了其在生物农药使用和野生动物种群控制等实际场景中的应用潜力。", "motivation": "全球挑战的复杂性需要综合和参与性方法，但传统风险分析框架常因简化复杂性而阻碍全面解决方案，且时间、信息和视角整合的限制使得利益相关者难以达成平衡。", "method": "开发了一个AI辅助谈判框架，集成大型语言模型和AI自主代理到风险分析工作流中，利用语义分析能力模拟谈判、建模动态、预测妥协和评估解决方案影响。", "result": "概念验证在生物农药谨慎使用和野生动物种群控制两个场景中成功实施，表明该框架能减轻信息过载、增强决策，并适用于资源有限的用户。", "conclusion": "AI辅助谈判工具有潜力弥补当前跨部门参与工具的不足，其开源和基于web的设计便于定制和广泛应用，促进更有效的风险管理和共识构建。"}}
{"id": "2509.10057", "title": "Reinforcement learning for spin torque oscillator tasks", "authors": ["Jakub Mojsiejuk", "Sławomir Ziętek", "Witold Skowroński"], "abstract": "We address the problem of automatic synchronisation of the spintronic oscillator (STO) by means of reinforcement learning (RL). A numerical solution of the macrospin Landau-Lifschitz-Gilbert-Slonczewski equation is used to simulate the STO and we train the two types of RL agents to synchronise with a target frequency within a fixed number of steps. We explore modifications to this base task and show an improvement in both convergence and energy efficiency of the synchronisation that can be easily achieved in the simulated environment.", "subjects": "Applied Physics (physics.app-ph); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "3 figures, 6 pages", "pdf_url": "https://arxiv.org/pdf/2509.10057.pdf", "abstract_url": "https://arxiv.org/abs/2509.10057", "categories": ["Applied Physics (physics.app-ph)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过强化学习实现自旋扭矩振荡器的自动同步，模拟环境显示改进后收敛和能效提升。", "motivation": "解决自旋扭矩振荡器（STO）的自动同步问题，以提高同步效率和降低能耗。", "method": "使用宏观自旋Landau-Lifschitz-Gilbert-Slonczewski方程的数值解模拟STO，并训练两种强化学习代理在固定步数内同步到目标频率。", "result": "在模拟环境中，改进任务后同步的收敛性和能量效率均得到改善。", "conclusion": "强化学习可有效优化STO同步，易于在模拟中实现，具有潜在应用价值。"}}
{"id": "2509.10289", "title": "We Need a New Ethics for a World of AI Agents", "authors": ["Iason Gabriel", "Geoff Keeling", "Arianna Manzini", "James Evans"], "abstract": "The deployment of capable AI agents raises fresh questions about safety, human-machine relationships and social coordination. We argue for greater engagement by scientists, scholars, engineers and policymakers with the implications of a world increasingly populated by AI agents. We explore key challenges that must be addressed to ensure that interactions between humans and agents, and among agents themselves, remain broadly beneficial.", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI)", "comments": "6 pages, no figures", "pdf_url": "https://arxiv.org/pdf/2509.10289.pdf", "abstract_url": "https://arxiv.org/abs/2509.10289", "categories": ["Computers and Society (cs.CY)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文主张科学家、学者、工程师和政策制定者应更深入地参与应对AI代理日益普及带来的安全、人机关系和社会协调等新伦理问题，以确保交互的广泛益处。", "motivation": "解决AI代理部署引发的安全、人机关系和社会协调等伦理挑战。", "method": "通过论证和探索关键挑战，呼吁多方参与和讨论。", "result": "识别了必须解决的关键挑战，以维持人类与代理及代理间交互的益处。", "conclusion": "需要新的伦理框架来应对AI代理世界，促进安全和有益的交互。"}}
