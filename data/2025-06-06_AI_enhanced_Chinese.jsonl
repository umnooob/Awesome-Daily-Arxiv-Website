{"id": "2506.04606", "title": "SmartAvatar: Text- and Image-Guided Human Avatar Generation with VLM AI Agents", "authors": ["Alexander Huang-Menders", "Xinhang Liu", "Andy Xu", "Yuyao Zhang", "Chi-Keung Tang", "Yu-Wing Tai"], "abstract": "SmartAvatar is a vision-language-agent-driven framework for generating fully rigged, animation-ready 3D human avatars from a single photo or textual prompt. While diffusion-based methods have made progress in general 3D object generation, they continue to struggle with precise control over human identity, body shape, and animation readiness. In contrast, SmartAvatar leverages the commonsense reasoning capabilities of large vision-language models (VLMs) in combination with off-the-shelf parametric human generators to deliver high-quality, customizable avatars. A key innovation is an autonomous verification loop, where the agent renders draft avatars, evaluates facial similarity, anatomical plausibility, and prompt alignment, and iteratively adjusts generation parameters for convergence. This interactive, AI-guided refinement process promotes fine-grained control over both facial and body features, enabling users to iteratively refine their avatars via natural-language conversations. Unlike diffusion models that rely on static pre-trained datasets and offer limited flexibility, SmartAvatar brings users into the modeling loop and ensures continuous improvement through an LLM-driven procedural generation and verification system. The generated avatars are fully rigged and support pose manipulation with consistent identity and appearance, making them suitable for downstream animation and interactive applications. Quantitative benchmarks and user studies demonstrate that SmartAvatar outperforms recent text- and image-driven avatar generation systems in terms of reconstructed mesh quality, identity fidelity, attribute accuracy, and animation readiness, making it a versatile tool for realistic, customizable avatar creation on consumer-grade hardware.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "16 pages", "pdf_url": "https://arxiv.org/pdf/2506.04606.pdf", "abstract_url": "https://arxiv.org/abs/2506.04606", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "SmartAvatar是一个基于视觉语言代理的框架，用于从单张照片或文本提示生成完全装配、可用于动画的3D人类头像。", "motivation": "解决扩散方法在人类身份、体型和动画准备方面的精确控制上的不足。", "method": "利用大型视觉语言模型（VLMs）的常识推理能力与现成的参数化人类生成器结合，通过自主验证循环迭代调整生成参数。", "result": "在重建网格质量、身份保真度、属性准确性和动画准备方面优于最近的文本和图像驱动头像生成系统。", "conclusion": "SmartAvatar是一个多功能工具，适用于在消费级硬件上创建逼真、可定制的头像。"}}
{"id": "2506.04363", "title": "WorldPrediction: A Benchmark for High-level World Modeling and Long-horizon Procedural Planning", "authors": ["Delong Chen", "Willy Chung", "Yejin Bang", "Ziwei Ji", "Pascale Fung"], "abstract": "Humans are known to have an internal \"world model\" that enables us to carry out action planning based on world states. AI agents need to have such a world model for action planning as well. It is not clear how current AI models, especially generative models, are able to learn such world models and carry out procedural planning in diverse environments. We introduce WorldPrediction, a video-based benchmark for evaluating world modeling and procedural planning capabilities of different AI models. In contrast to prior benchmarks that focus primarily on low-level world modeling and robotic motion planning, WorldPrediction is the first benchmark that emphasizes actions with temporal and semantic abstraction. Given initial and final world states, the task is to distinguish the proper action (WorldPrediction-WM) or the properly ordered sequence of actions (WorldPrediction-PP) from a set of counterfactual distractors. This discriminative task setup enable us to evaluate different types of world models and planners and realize a thorough comparison across different hypothesis. The benchmark represents states and actions using visual observations. In order to prevent models from exploiting low-level continuity cues in background scenes, we provide \"action equivalents\" - identical actions observed in different contexts - as candidates for selection. This benchmark is grounded in a formal framework of partially observable semi-MDP, ensuring better reliability and robustness of the evaluation. We conduct extensive human filtering and validation on our benchmark and show that current frontier models barely achieve 57% accuracy on WorldPrediction-WM and 38% on WorldPrediction-PP whereas humans are able to solve both tasks perfectly.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04363.pdf", "abstract_url": "https://arxiv.org/abs/2506.04363", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "WorldPrediction是一个基于视频的基准测试，旨在评估不同AI模型在世界建模和程序规划方面的能力，特别是在具有时间和语义抽象的动作上。", "motivation": "解决当前AI模型，尤其是生成模型，在多样化环境中学习世界模型和执行程序规划能力的不明确性问题。", "method": "引入WorldPrediction基准测试，使用视觉观察表示状态和动作，并通过提供“动作等价物”来防止模型利用背景场景中的低级连续性线索。", "result": "当前前沿模型在WorldPrediction-WM和WorldPrediction-PP上的准确率分别为57%和38%，而人类能够完美解决这两个任务。", "conclusion": "WorldPrediction基准测试为评估和比较不同类型的世界模型和规划器提供了一个可靠和健壮的框架，揭示了当前AI模型与人类在世界建模和程序规划能力上的差距。"}}
{"id": "2506.04595", "title": "Hierarchical-Task-Aware Multi-modal Mixture of Incremental LoRA Experts for Embodied Continual Learning", "authors": ["Ziqi Jia", "Anmin Wang", "Xiaoyang Qu", "Xiaowen Yang", "Jianzong Wang"], "abstract": "Previous continual learning setups for embodied intelligence focused on executing low-level actions based on human commands, neglecting the ability to learn high-level planning and multi-level knowledge. To address these issues, we propose the Hierarchical Embodied Continual Learning Setups (HEC) that divide the agent's continual learning process into two layers: high-level instructions and low-level actions, and define five embodied continual learning sub-setups. Building on these setups, we introduce the Task-aware Mixture of Incremental LoRA Experts (Task-aware MoILE) method. This approach achieves task recognition by clustering visual-text embeddings and uses both a task-level router and a token-level router to select the appropriate LoRA experts. To effectively address the issue of catastrophic forgetting, we apply Singular Value Decomposition (SVD) to the LoRA parameters obtained from prior tasks, preserving key components while orthogonally training the remaining parts. The experimental results show that our method stands out in reducing the forgetting of old tasks compared to other methods, effectively supporting agents in retaining prior knowledge while continuously learning new tasks.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "Accepted by the 63rd Annual Meeting of the Association for Computational Linguistics (ACL 2025)", "pdf_url": "https://arxiv.org/pdf/2506.04595.pdf", "abstract_url": "https://arxiv.org/abs/2506.04595", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了分层体现持续学习设置（HEC）和任务感知增量LoRA专家混合（Task-aware MoILE）方法，以解决体现智能在持续学习中缺乏高层规划和多级知识学习能力的问题。通过视觉-文本嵌入聚类实现任务识别，并利用任务级和令牌级路由器选择适当的LoRA专家，有效减少了旧任务的遗忘。", "motivation": "解决体现智能在持续学习中缺乏高层规划和多级知识学习能力的问题。", "method": "提出了分层体现持续学习设置（HEC）和任务感知增量LoRA专家混合（Task-aware MoILE）方法，包括视觉-文本嵌入聚类实现任务识别，以及任务级和令牌级路由器选择适当的LoRA专家。", "result": "实验结果表明，该方法在减少旧任务遗忘方面优于其他方法，有效支持代理在持续学习新任务的同时保留先验知识。", "conclusion": "提出的HEC和Task-aware MoILE方法有效解决了体现智能在持续学习中的高层规划和多级知识学习问题，减少了旧任务的遗忘，为体现智能的持续学习提供了新的解决方案。"}}
{"id": "2506.04676", "title": "Gen-n-Val: Agentic Image Data Generation and Validation", "authors": ["Jing-En Huang", "I-Sheng Fang", "Tzuhsuan Huang", "Chih-Yu Wang", "Jun-Cheng Chen"], "abstract": "Recently, Large Language Models (LLMs) and Vision Large Language Models (VLLMs) have demonstrated impressive performance as agents across various tasks while data scarcity and label noise remain significant challenges in computer vision tasks, such as object detection and instance segmentation. A common solution for resolving these issues is to generate synthetic data. However, current synthetic data generation methods struggle with issues, such as multiple objects per mask, inaccurate segmentation, and incorrect category labels, limiting their effectiveness. To address these issues, we introduce Gen-n-Val, a novel agentic data generation framework that leverages Layer Diffusion (LD), LLMs, and VLLMs to produce high-quality, single-object masks and diverse backgrounds. Gen-n-Val consists of two agents: (1) The LD prompt agent, an LLM, optimizes prompts for LD to generate high-quality foreground instance images and segmentation masks. These optimized prompts ensure the generation of single-object synthetic data with precise instance masks and clean backgrounds. (2) The data validation agent, a VLLM, which filters out low-quality synthetic instance images. The system prompts for both agents are refined through TextGrad. Additionally, we use image harmonization to combine multiple instances within scenes. Compared to state-of-the-art synthetic data approaches like MosaicFusion, our approach reduces invalid synthetic data from 50% to 7% and improves performance by 1% mAP on rare classes in COCO instance segmentation with YOLOv9c and YOLO11m. Furthermore, Gen-n-Val shows significant improvements (7. 1% mAP) over YOLO-Worldv2-M in open-vocabulary object detection benchmarks with YOLO11m. Moreover, Gen-n-Val improves the performance of YOLOv9 and YOLO11 families in instance segmentation and object detection.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04676.pdf", "abstract_url": "https://arxiv.org/abs/2506.04676", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "Gen-n-Val是一种新型的代理数据生成框架，利用Layer Diffusion、LLMs和VLLMs生成高质量的单对象掩码和多样化背景，解决了计算机视觉任务中的数据稀缺和标签噪声问题。", "motivation": "解决计算机视觉任务中数据稀缺和标签噪声的挑战，特别是对象检测和实例分割中的多对象掩码、不准确分割和错误类别标签问题。", "method": "Gen-n-Val框架包含两个代理：LD提示代理（LLM）优化LD的提示以生成高质量的前景实例图像和分割掩码；数据验证代理（VLLM）过滤低质量的合成实例图像。系统提示通过TextGrad细化，并使用图像协调技术将多个实例组合到场景中。", "result": "与最先进的合成数据方法相比，Gen-n-Val将无效合成数据从50%减少到7%，并在COCO实例分割中提高了1% mAP，在开放词汇对象检测基准中提高了7.1% mAP。", "conclusion": "Gen-n-Val显著提高了YOLOv9和YOLO11系列在实例分割和对象检测中的性能，为计算机视觉任务提供了一种高效的数据生成和验证方法。"}}
{"id": "2506.04743", "title": "SRD: Reinforcement-Learned Semantic Perturbation for Backdoor Defense in VLMs", "authors": ["Shuhan Xu", "Siyuan Liang", "Hongling Zheng", "Yong Luo", "Aishan Liu", "Dacheng Tao"], "abstract": "Vision-Language Models (VLMs) have achieved remarkable performance in image captioning, but recent studies show they are vulnerable to backdoor attacks. Attackers can inject imperceptible perturbations-such as local pixel triggers or global semantic phrases-into the training data, causing the model to generate malicious, attacker-controlled captions for specific inputs. These attacks are hard to detect and defend due to their stealthiness and cross-modal nature. By analyzing attack samples, we identify two key vulnerabilities: (1) abnormal attention concentration on specific image regions, and (2) semantic drift and incoherence in generated captions. To counter this, we propose Semantic Reward Defense (SRD), a reinforcement learning framework that mitigates backdoor behavior without prior knowledge of triggers. SRD uses a Deep Q-Network to learn policies for applying discrete perturbations (e.g., occlusion, color masking) to sensitive image regions, aiming to disrupt the activation of malicious pathways. We design a semantic fidelity score as the reward signal, which jointly evaluates semantic consistency and linguistic fluency of the output, guiding the agent toward generating robust yet faithful captions. Experiments across mainstream VLMs and datasets show SRD reduces attack success rates to 5.6%, while preserving caption quality on clean inputs with less than 10% performance drop. SRD offers a trigger-agnostic, interpretable defense paradigm against stealthy backdoor threats in multimodal generative models.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04743.pdf", "abstract_url": "https://arxiv.org/abs/2506.04743", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为SRD的强化学习框架，用于防御视觉语言模型（VLMs）中的后门攻击，通过语义奖励信号来指导模型生成鲁棒且准确的图像描述。", "motivation": "视觉语言模型在图像描述任务中表现出色，但易受后门攻击，攻击者通过注入不易察觉的扰动（如局部像素触发器或全局语义短语）来控制模型生成恶意描述。这些攻击因其隐蔽性和跨模态特性难以检测和防御。", "method": "提出的语义奖励防御（SRD）框架利用深度Q网络学习策略，对敏感图像区域应用离散扰动（如遮挡、颜色掩码），以破坏恶意路径的激活。通过设计语义保真度评分作为奖励信号，评估输出的语义一致性和语言流畅性。", "result": "实验表明，SRD能将攻击成功率降低至5.6%，同时在干净输入上保持图像描述质量，性能下降少于10%。", "conclusion": "SRD提供了一种无需触发器先验知识、可解释的防御范式，有效对抗多模态生成模型中的隐蔽后门威胁。"}}
{"id": "2506.04790", "title": "LotusFilter: Fast Diverse Nearest Neighbor Search via a Learned Cutoff Table", "authors": ["Yusuke Matsui"], "abstract": "Approximate nearest neighbor search (ANNS) is an essential building block for applications like RAG but can sometimes yield results that are overly similar to each other. In certain scenarios, search results should be similar to the query and yet diverse. We propose LotusFilter, a post-processing module to diversify ANNS results. We precompute a cutoff table summarizing vectors that are close to each other. During the filtering, LotusFilter greedily looks up the table to delete redundant vectors from the candidates. We demonstrated that the LotusFilter operates fast (0.02 [ms/query]) in settings resembling real-world RAG applications, utilizing features such as OpenAI embeddings. Our code is publicly available at", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Information Retrieval (cs.IR); Machine Learning (cs.LG)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2506.04790.pdf", "abstract_url": "https://arxiv.org/abs/2506.04790", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Information Retrieval (cs.IR)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "LotusFilter是一种后处理模块，用于多样化近似最近邻搜索（ANNS）结果，通过预计算一个总结相近向量的截止表，在过滤过程中快速删除冗余向量。", "motivation": "解决近似最近邻搜索（ANNS）在如RAG等应用中可能产生过于相似结果的问题，需要在某些场景下使搜索结果既相似于查询又具有多样性。", "method": "预计算一个截止表来总结相近的向量，在过滤过程中贪婪地查找该表以删除候选中的冗余向量。", "result": "LotusFilter在类似于真实世界RAG应用的环境中操作快速（0.02 [ms/query]），并利用了如OpenAI嵌入等功能。", "conclusion": "LotusFilter提供了一种快速有效的方法来多样化ANNS结果，适用于需要多样性和相似性平衡的应用场景。"}}
{"id": "2506.04245", "title": "Contextual Integrity in LLMs via Reasoning and Reinforcement Learning", "authors": ["Guangchen Lan", "Huseyin A. Inan", "Sahar Abdelnabi", "Janardhan Kulkarni", "Lukas Wutschitz", "Reza Shokri", "Christopher G. Brinton", "Robert Sim"], "abstract": "As the era of autonomous agents making decisions on behalf of users unfolds, ensuring contextual integrity (CI) -- what is the appropriate information to share while carrying out a certain task -- becomes a central question to the field. We posit that CI demands a form of reasoning where the agent needs to reason about the context in which it is operating. To test this, we first prompt LLMs to reason explicitly about CI when deciding what information to disclose. We then extend this approach by developing a reinforcement learning (RL) framework that further instills in models the reasoning necessary to achieve CI. Using a synthetic, automatically created, dataset of only $\\sim700$ examples but with diverse contexts and information disclosure norms, we show that our method substantially reduces inappropriate information disclosure while maintaining task performance across multiple model sizes and families. Importantly, improvements transfer from this synthetic dataset to established CI benchmarks such as PrivacyLens that has human annotations and evaluates privacy leakage of AI assistants in actions and tool calls.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04245.pdf", "abstract_url": "https://arxiv.org/abs/2506.04245", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了在自主代理为用户做出决策的时代，如何通过推理和强化学习确保大型语言模型（LLMs）的上下文完整性（CI），即在进行特定任务时分享适当信息的问题。", "motivation": "解决在自主代理决策过程中，如何确保信息分享的适当性，即上下文完整性的问题。", "method": "首先通过提示LLMs显式推理CI来决定信息披露，然后开发一个强化学习框架，进一步在模型中灌输实现CI所需的推理。", "result": "使用仅约700个示例的合成数据集，展示了该方法在多个模型大小和家族中显著减少了不适当的信息披露，同时保持了任务性能，且这些改进能够转移到具有人类注释的CI基准测试中。", "conclusion": "通过推理和强化学习，可以有效提升LLMs在保持任务性能的同时，确保上下文完整性，减少不适当的信息披露。"}}
{"id": "2506.04251", "title": "Language-Guided Multi-Agent Learning in Simulations: A Unified Framework and Evaluation", "authors": ["Zhengyang Li"], "abstract": "This paper introduces LLM-MARL, a unified framework that incorporates large language models (LLMs) into multi-agent reinforcement learning (MARL) to enhance coordination, communication, and generalization in simulated game environments. The framework features three modular components of Coordinator, Communicator, and Memory, which dynamically generate subgoals, facilitate symbolic inter-agent messaging, and support episodic recall. Training combines PPO with a language-conditioned loss and LLM query gating. LLM-MARL is evaluated in Google Research Football, MAgent Battle, and StarCraft II. Results show consistent improvements over MAPPO and QMIX in win rate, coordination score, and zero-shot generalization. Ablation studies demonstrate that subgoal generation and language-based messaging each contribute significantly to performance gains. Qualitative analysis reveals emergent behaviors such as role specialization and communication-driven tactics. By bridging language modeling and policy learning, this work contributes to the design of intelligent, cooperative agents in interactive simulations. It offers a path forward for leveraging LLMs in multi-agent systems used for training, games, and human-AI collaboration.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04251.pdf", "abstract_url": "https://arxiv.org/abs/2506.04251", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了LLM-MARL，一个将大型语言模型（LLMs）融入多智能体强化学习（MARL）的统一框架，旨在提升模拟游戏环境中的协调、通信和泛化能力。", "motivation": "解决多智能体在模拟环境中协调、通信和泛化能力不足的问题。", "method": "结合PPO与语言条件损失及LLM查询门控的训练方法，框架包含Coordinator、Communicator和Memory三个模块。", "result": "在Google Research Football、MAgent Battle和StarCraft II中评估，显示在胜率、协调分数和零样本泛化上优于MAPPO和QMIX。", "conclusion": "通过桥接语言建模和政策学习，为交互式模拟中智能、协作智能体的设计提供了新思路，为多智能体系统在训练、游戏和人机协作中的应用开辟了新路径。"}}
{"id": "2506.04252", "title": "A Graph-Retrieval-Augmented Generation Framework Enhances Decision-Making in the Circular Economy", "authors": ["Yang Zhao", "Chengxiao Dai", "Dusit Niyato", "Chuan Fu Tan", "Keyi Xiang", "Yueyang Wang", "Zhiquan Yeo", "Daren Tan Zong Loong", "Jonathan Low Zhaozhi", "Eugene H.Z. HO"], "abstract": "Large language models (LLMs) hold promise for sustainable manufacturing, but often hallucinate industrial codes and emission factors, undermining regulatory and investment decisions. We introduce CircuGraphRAG, a retrieval-augmented generation (RAG) framework that grounds LLMs outputs in a domain-specific knowledge graph for the circular economy. This graph connects 117,380 industrial and waste entities with classification codes and GWP100 emission data, enabling structured multi-hop reasoning. Natural language queries are translated into SPARQL and verified subgraphs are retrieved to ensure accuracy and traceability. Compared with Standalone LLMs and Naive RAG, CircuGraphRAG achieves superior performance in single-hop and multi-hop question answering, with ROUGE-L F1 scores up to 1.0, while baseline scores below 0.08. It also improves efficiency, halving the response time and reducing token usage by 16% in representative tasks. CircuGraphRAG provides fact-checked, regulatory-ready support for circular economy planning, advancing reliable, low-carbon resource decision making.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04252.pdf", "abstract_url": "https://arxiv.org/abs/2506.04252", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了CircuGraphRAG，一个基于检索增强生成（RAG）的框架，旨在通过领域特定知识图谱提高大型语言模型（LLMs）在循环经济决策中的准确性和效率。", "motivation": "大型语言模型在可持续制造中具有潜力，但常常产生关于工业代码和排放因子的幻觉，影响了监管和投资决策的准确性。", "method": "CircuGraphRAG框架将LLMs的输出与循环经济领域的特定知识图谱相结合，该图谱连接了117,380个工业和废物实体，包含分类代码和GWP100排放数据，支持结构化的多跳推理。自然语言查询被翻译成SPARQL，并检索验证子图以确保准确性和可追溯性。", "result": "与独立LLMs和Naive RAG相比，CircuGraphRAG在单跳和多跳问答中表现出色，ROUGE-L F1得分高达1.0，而基线得分低于0.08。同时，它提高了效率，响应时间减半，代表性任务中的令牌使用减少了16%。", "conclusion": "CircuGraphRAG为循环经济规划提供了经过事实核查、符合监管要求的支持，推动了可靠、低碳资源决策的进步。"}}
{"id": "2506.04287", "title": "Automated Skill Discovery for Language Agents through Exploration and Iterative Feedback", "authors": ["Yongjin Yang", "Sinjae Kang", "Juyong Lee", "Dongjun Lee", "Se-Young Yun", "Kimin Lee"], "abstract": "Training large language model (LLM) agents to acquire necessary skills and perform diverse tasks within an environment is gaining interest as a means to enable open-endedness. However, creating the training dataset for their skill acquisition faces several challenges. Manual trajectory collection requires significant human effort. Another approach, where LLMs directly propose tasks to learn, is often invalid, as the LLMs lack knowledge of which tasks are actually feasible. Moreover, the generated data may not provide a meaningful learning signal, as agents often already perform well on the proposed tasks. To address this, we propose a novel automatic skill discovery framework EXIF for LLM-powered agents, designed to improve the feasibility of generated target behaviors while accounting for the agents' capabilities. Our method adopts an exploration-first strategy by employing an exploration agent (Alice) to train the target agent (Bob) to learn essential skills in the environment. Specifically, Alice first interacts with the environment to retrospectively generate a feasible, environment-grounded skill dataset, which is then used to train Bob. Crucially, we incorporate an iterative feedback loop, where Alice evaluates Bob's performance to identify areas for improvement. This feedback then guides Alice's next round of exploration, forming a closed-loop data generation process. Experiments on Webshop and Crafter demonstrate EXIF's ability to effectively discover meaningful skills and iteratively expand the capabilities of the trained agent without any human intervention, achieving substantial performance improvements. Interestingly, we observe that setting Alice to the same model as Bob also notably improves performance, demonstrating EXIF's potential for building a self-evolving system.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "Preprint, under review", "pdf_url": "https://arxiv.org/pdf/2506.04287.pdf", "abstract_url": "https://arxiv.org/abs/2506.04287", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为EXIF的自动技能发现框架，旨在通过探索和迭代反馈来提高大型语言模型（LLM）代理的技能获取效率，无需人工干预即可显著提升性能。", "motivation": "训练大型语言模型代理以获取必要技能并在环境中执行多样化任务是实现开放性的重要手段。然而，手动收集训练数据需要大量人力，而直接由LLM提出学习任务的方法又常因LLM不了解哪些任务实际可行而无效。此外，生成的数据可能不提供有意义的学习信号，因为代理在提出的任务上往往已经表现良好。", "method": "EXIF框架采用探索优先的策略，通过探索代理（Alice）与环境的交互来生成可行的、基于环境的技能数据集，然后用于训练目标代理（Bob）。关键的是，框架中融入了迭代反馈循环，Alice评估Bob的表现以识别改进领域，反馈进而指导Alice的下一次探索，形成一个闭环数据生成过程。", "result": "在Webshop和Crafter上的实验表明，EXIF能够有效发现有意义技能并无迭代地扩展训练代理的能力，无需任何人工干预即可实现显著的性能提升。有趣的是，将Alice设置为与Bob相同的模型也能显著提高性能，展示了EXIF构建自进化系统的潜力。", "conclusion": "EXIF框架通过自动技能发现和迭代反馈，显著提升了LLM代理的技能获取效率和性能，展示了无需人工干预的自进化系统的潜力。"}}
{"id": "2506.04253", "title": "HADA: Human-AI Agent Decision Alignment Architecture", "authors": ["Tapio Pitkäranta", "Leena Pitkäranta"], "abstract": "We present HADA (Human-AI Agent Decision Alignment), a protocol- and framework agnostic reference architecture that keeps both large language model (LLM) agents and legacy algorithms aligned with organizational targets and values. HADA wraps any algorithm or LLM in role-specific stakeholder agents -- business, data-science, audit, ethics, and customer -- each exposing conversational APIs so that technical and non-technical actors can query, steer, audit, or contest every decision across strategic, tactical, and real-time horizons. Alignment objectives, KPIs, and value constraints are expressed in natural language and are continuously propagated, logged, and versioned while thousands of heterogeneous agents run on different orchestration stacks. A cloud-native proof of concept packages a production credit-scoring model (getLoanDecision) and deploys it on Docker/Kubernetes/Python; five scripted retail-bank scenarios show how target changes, parameter tweaks, explanation requests, and ethics triggers flow end to end through the architecture. Evaluation followed the Design-Science Research Methodology. Walkthrough observation and log inspection demonstrated complete coverage of six predefined objectives: every role could invoke conversational control, trace KPIs and value constraints, detect and mitigate ZIP-code bias, and reproduce full decision lineage, independent of the underlying LLM or agent library. Contributions: (1) an open-source HADA architecture, (2) a mid-range design theory for human-AI alignment in multi-agent systems, and (3) empirical evidence that framework-agnostic, protocol-compliant stakeholder agents improve accuracy, transparency, and ethical compliance in real-world decision pipelines.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "18 pages, 4 figures", "pdf_url": "https://arxiv.org/pdf/2506.04253.pdf", "abstract_url": "https://arxiv.org/abs/2506.04253", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "HADA是一种协议和框架无关的参考架构，旨在确保大型语言模型（LLM）代理和传统算法与组织目标和价值观保持一致。它通过角色特定的利益相关者代理（如业务、数据科学、审计、伦理和客户）包装任何算法或LLM，提供对话式API，使技术和非技术参与者能够查询、指导、审计或质疑每个决策。", "motivation": "解决在多样化代理运行于不同编排栈上时，如何保持LLM代理和传统算法与组织目标和价值观的对齐问题。", "method": "HADA架构通过角色特定的利益相关者代理包装算法或LLM，提供对话式API，并允许自然语言表达对齐目标、KPIs和价值约束，这些信息被持续传播、记录和版本控制。", "result": "评估显示，HADA完全覆盖了六个预定义目标，每个角色都能调用对话控制、追踪KPIs和价值约束、检测和减轻ZIP码偏见，并重现完整的决策谱系。", "conclusion": "HADA提供了一种开源架构和中层设计理论，用于多代理系统中的人-AI对齐，实证证据表明，框架无关、协议兼容的利益相关者代理提高了现实世界决策流程的准确性、透明度和伦理合规性。"}}
{"id": "2506.04571", "title": "OpenAg: Democratizing Agricultural Intelligence", "authors": ["Srikanth Thudumu", "Jason Fisher"], "abstract": "Agriculture is undergoing a major transformation driven by artificial intelligence (AI), machine learning, and knowledge representation technologies. However, current agricultural intelligence systems often lack contextual understanding, explainability, and adaptability, especially for smallholder farmers with limited resources. General-purpose large language models (LLMs), while powerful, typically lack the domain-specific knowledge and contextual reasoning needed for practical decision support in farming. They tend to produce recommendations that are too generic or unrealistic for real-world applications. To address these challenges, we present OpenAg, a comprehensive framework designed to advance agricultural artificial general intelligence (AGI). OpenAg combines domain-specific foundation models, neural knowledge graphs, multi-agent reasoning, causal explainability, and adaptive transfer learning to deliver context-aware, explainable, and actionable insights. The system includes: (i) a unified agricultural knowledge base that integrates scientific literature, sensor data, and farmer-generated knowledge; (ii) a neural agricultural knowledge graph for structured reasoning and inference; (iii) an adaptive multi-agent reasoning system where AI agents specialize and collaborate across agricultural domains; and (iv) a causal transparency mechanism that ensures AI recommendations are interpretable, scientifically grounded, and aligned with real-world constraints. OpenAg aims to bridge the gap between scientific knowledge and the tacit expertise of experienced farmers to support scalable and locally relevant agricultural decision-making.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "10 pages, 1 figure", "pdf_url": "https://arxiv.org/pdf/2506.04571.pdf", "abstract_url": "https://arxiv.org/abs/2506.04571", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "OpenAg是一个旨在推动农业通用人工智能（AGI）发展的综合框架，通过结合领域特定的基础模型、神经知识图谱、多智能体推理、因果可解释性和自适应迁移学习，提供情境感知、可解释且可操作的见解。", "motivation": "当前的农业智能系统往往缺乏情境理解、可解释性和适应性，特别是对于资源有限的小农户。通用的大型语言模型（LLMs）虽然强大，但通常缺乏农业领域特定的知识和情境推理能力，难以提供实用的决策支持。", "method": "OpenAg结合了领域特定的基础模型、神经知识图谱、多智能体推理、因果可解释性和自适应迁移学习，构建了一个统一的农业知识库、神经农业知识图谱、自适应多智能体推理系统和因果透明机制。", "result": "OpenAg旨在弥合科学知识与经验丰富的农民的隐性专业知识之间的差距，支持可扩展且与当地相关的农业决策制定。", "conclusion": "OpenAg通过其综合框架，为农业领域提供了一种情境感知、可解释且可操作的决策支持系统，有望推动农业智能化的进一步发展。"}}
{"id": "2506.04481", "title": "CogMath: Assessing LLMs' Authentic Mathematical Ability from a Human Cognitive Perspective", "authors": ["Jiayu Liu", "Zhenya Huang", "Wei Dai", "Cheng Cheng", "Jinze Wu", "Jing Sha", "Song Li", "Qi Liu", "Shijin Wang", "Enhong Chen"], "abstract": "Although large language models (LLMs) show promise in solving complex mathematical tasks, existing evaluation paradigms rely solely on a coarse measure of overall answer accuracy, which are insufficient for assessing their authentic capabilities. In this paper, we propose \\textbf{CogMath}, which comprehensively assesses LLMs' mathematical abilities through the lens of human cognition. Specifically, inspired by psychological theories, CogMath formalizes human reasoning process into 3 stages: \\emph{problem comprehension}, \\emph{problem solving}, and \\emph{solution summarization}. Within these stages, we investigate perspectives such as numerical calculation, knowledge, and counterfactuals, and design a total of 9 fine-grained evaluation dimensions. In each dimension, we develop an ``\\emph{Inquiry}-\\emph{Judge}-\\emph{Reference}'' multi-agent system to generate inquiries that assess LLMs' mastery from this dimension. An LLM is considered to truly master a problem only when excelling in all inquiries from the 9 dimensions. By applying CogMath on three benchmarks, we reveal that the mathematical capabilities of 7 mainstream LLMs are overestimated by 30\\%-40\\%. Moreover, we locate their strengths and weaknesses across specific stages/dimensions, offering in-depth insights to further enhance their reasoning abilities.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04481.pdf", "abstract_url": "https://arxiv.org/abs/2506.04481", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了CogMath，一种从人类认知角度全面评估大型语言模型（LLMs）数学能力的方法。通过将人类推理过程分为三个阶段，并设计9个细粒度评估维度，研究发现主流LLMs的数学能力被高估了30%-40%。", "motivation": "现有的评估范式仅依赖于整体答案准确性的粗略测量，不足以评估LLMs的真实数学能力。", "method": "CogMath将人类推理过程形式化为三个阶段：问题理解、问题解决和解决方案总结，并设计了9个细粒度评估维度，采用“询问-判断-参考”多代理系统生成评估问题。", "result": "应用CogMath在三个基准测试上发现，7种主流LLMs的数学能力被高估了30%-40%，并定位了它们在特定阶段/维度的优势和弱点。", "conclusion": "CogMath为评估和提升LLMs的数学推理能力提供了深入的见解，揭示了当前评估方法的不足。"}}
{"id": "2506.04636", "title": "CHANCERY: Evaluating corporate governance reasoning capabilities in language models", "authors": ["Lucas Irwin", "Arda Kaz", "Peiyao Sheng", "Pramod Viswanath"], "abstract": "Law has long been a domain that has been popular in natural language processing (NLP) applications. Reasoning (ratiocination and the ability to make connections to precedent) is a core part of the practice of the law in the real world. Nevertheless, while multiple legal datasets exist, none have thus far focused specifically on reasoning tasks. We focus on a specific aspect of the legal landscape by introducing a corporate governance reasoning benchmark (CHANCERY) to test a model's ability to reason about whether executive/board/shareholder's proposed actions are consistent with corporate governance charters. This benchmark introduces a first-of-its-kind corporate governance reasoning test for language models - modeled after real world corporate governance law. The benchmark consists of a corporate charter (a set of governing covenants) and a proposal for executive action. The model's task is one of binary classification: reason about whether the action is consistent with the rules contained within the charter. We create the benchmark following established principles of corporate governance - 24 concrete corporate governance principles established in and 79 real life corporate charters selected to represent diverse industries from a total dataset of 10k real life corporate charters. Evaluations on state-of-the-art (SOTA) reasoning models confirm the difficulty of the benchmark, with models such as Claude 3.7 Sonnet and GPT-4o achieving 64.5% and 75.2% accuracy respectively. Reasoning agents exhibit superior performance, with agents based on the ReAct and CodeAct frameworks scoring 76.1% and 78.1% respectively, further confirming the advanced legal reasoning capabilities required to score highly on the benchmark. We also conduct an analysis of the types of questions which current reasoning models struggle on, revealing insights into the legal reasoning capabilities of SOTA models.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04636.pdf", "abstract_url": "https://arxiv.org/abs/2506.04636", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文介绍了CHANCERY，一个评估语言模型在公司治理推理能力上的新基准，专注于模型是否能根据公司章程判断执行/董事会/股东提出的行动是否一致。", "motivation": "解决现有法律数据集缺乏专注于推理任务的问题，特别是在公司治理领域的法律推理能力评估。", "method": "引入了一个基于真实世界公司治理法的公司治理推理基准，包括公司章程和行动提案，要求模型进行二元分类判断。", "result": "最先进的推理模型在该基准上表现不佳，Claude 3.7 Sonnet和GPT-4o的准确率分别为64.5%和75.2%，而基于ReAct和CodeAct框架的推理代理表现更好，分别达到76.1%和78.1%。", "conclusion": "CHANCERY基准揭示了当前模型在法律推理能力上的局限性，并为评估和提升语言模型在公司治理领域的推理能力提供了新的方向。"}}
{"id": "2506.04654", "title": "E-bike agents: Large Language Model-Driven E-Bike Accident Analysis and Severity Prediction", "authors": ["Zhichao Yang", "Jiashu He", "Mohammad B. Al-Khasawneh", "Darshan Pandit", "Cirillo Cinzia"], "abstract": "Electric bicycles (e-bikes) are rapidly increasing in use, raising safety concerns due to a rise in accident reports. However, e-bike incident reports often use unstructured narrative formats, which hinders quantitative safety analysis. This study introduces E-bike agents, a framework that uses large language models (LLM) powered agents to classify and extract safety variables from unstructured incident reports. Our framework consists of four LLM agents, handling data classification, information extraction, injury cause determination, and component linkage, to extract the key factors that could lead to E-bike accidents and cause varying severity levels. Furthermore, we used an ordered logit model to examine the relationship between the severity of the incident and the factors retrieved, such as gender, the type of cause, and environmental conditions. Our research shows that equipment issues are slightly more common than human-related ones, but human-related incidents are more often fatal. Specifically, pedals, tires, and brakes are frequent contributors to accidents. The model achieves a high weighted F1 score of 0.87 in classification accuracy, highlighting the potential of using LLMs to extract unstructured data in niche domains, such as transportation. Our method offers a scalable solution to improve e-bike safety analytics and provides actionable information for policy makers, designers, and regulators.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04654.pdf", "abstract_url": "https://arxiv.org/abs/2506.04654", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "该研究引入了E-bike agents框架，利用大型语言模型（LLM）驱动的代理从非结构化事故报告中分类和提取安全变量，以分析电动自行车（e-bike）事故及其严重程度。", "motivation": "电动自行车使用的快速增长带来了安全问题，但事故报告通常采用非结构化叙述形式，阻碍了定量安全分析。", "method": "研究使用了四个LLM代理处理数据分类、信息提取、伤害原因确定和组件关联，以及有序逻辑模型来检查事故严重程度与提取因素之间的关系。", "result": "设备问题比人为问题稍常见，但人为相关事故更常致命；踏板、轮胎和刹车是事故的常见原因。分类准确度的加权F1分数达到0.87。", "conclusion": "该方法为改善电动自行车安全分析提供了可扩展的解决方案，并为政策制定者、设计师和监管者提供了可操作的信息。"}}
{"id": "2506.04651", "title": "Agents of Change: Self-Evolving LLM Agents for Strategic Planning", "authors": ["Nikolas Belle", "Dakota Barnes", "Alfonso Amayuelas", "Ivan Bercovich", "Xin Eric Wang", "William Wang"], "abstract": "Recent advances in LLMs have enabled their use as autonomous agents across a range of tasks, yet they continue to struggle with formulating and adhering to coherent long-term strategies. In this paper, we investigate whether LLM agents can self-improve when placed in environments that explicitly challenge their strategic planning abilities. Using the board game Settlers of Catan, accessed through the open-source Catanatron framework, we benchmark a progression of LLM-based agents, from a simple game-playing agent to systems capable of autonomously rewriting their own prompts and their player agent's code. We introduce a multi-agent architecture in which specialized roles (Analyzer, Researcher, Coder, and Player) collaborate to iteratively analyze gameplay, research new strategies, and modify the agent's logic or prompt. By comparing manually crafted agents to those evolved entirely by LLMs, we evaluate how effectively these systems can diagnose failure and adapt over time. Our results show that self-evolving agents, particularly when powered by models like Claude 3.7 and GPT-4o, outperform static baselines by autonomously adopting their strategies, passing along sample behavior to game-playing agents, and demonstrating adaptive reasoning over multiple iterations.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04651.pdf", "abstract_url": "https://arxiv.org/abs/2506.04651", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了大型语言模型（LLM）作为自主代理在战略规划任务中的自我改进能力，特别是在《卡坦岛》桌游环境中。通过引入多代理架构，研究展示了自我进化代理在性能上超越静态基线模型的能力。", "motivation": "解决LLM代理在制定和坚持长期战略规划方面的困难，探索其在挑战性环境中的自我改进潜力。", "method": "使用《卡坦岛》桌游和Catanatron框架，比较从简单游戏代理到能够自主重写提示和代理代码的系统的性能。引入多代理架构，包括分析器、研究员、编码器和玩家角色，以迭代方式改进代理逻辑或提示。", "result": "自我进化代理，尤其是由Claude 3.7和GPT-4o驱动的代理，在性能上超越静态基线模型，能够自主采用策略并通过多次迭代展示适应性推理。", "conclusion": "研究表明，LLM代理在适当的环境中能够有效地自我改进和适应，为开发更强大的自主代理提供了新的可能性。"}}
{"id": "2506.04699", "title": "Empowering Economic Simulation for Massively Multiplayer Online Games through Generative Agent-Based Modeling", "authors": ["Bihan Xu", "Shiwei Zhao", "Runze Wu", "Zhenya Huang", "Jiawei Wang", "Zhipeng Hu", "Kai Wang", "Haoyu Liu", "Tangjie Lv", "Le Li", "Changjie Fan", "Xin Tong", "Jiangze Han"], "abstract": "Within the domain of Massively Multiplayer Online (MMO) economy research, Agent-Based Modeling (ABM) has emerged as a robust tool for analyzing game economics, evolving from rule-based agents to decision-making agents enhanced by reinforcement learning. Nevertheless, existing works encounter significant challenges when attempting to emulate human-like economic activities among agents, particularly regarding agent reliability, sociability, and interpretability. In this study, we take a preliminary step in introducing a novel approach using Large Language Models (LLMs) in MMO economy simulation. Leveraging LLMs' role-playing proficiency, generative capacity, and reasoning aptitude, we design LLM-driven agents with human-like decision-making and adaptability. These agents are equipped with the abilities of role-playing, perception, memory, and reasoning, addressing the aforementioned challenges effectively. Simulation experiments focusing on in-game economic activities demonstrate that LLM-empowered agents can promote emergent phenomena like role specialization and price fluctuations in line with market rules.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "KDD2025 Accepted", "pdf_url": "https://arxiv.org/pdf/2506.04699.pdf", "abstract_url": "https://arxiv.org/abs/2506.04699", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种利用大型语言模型（LLMs）在大型多人在线（MMO）游戏经济模拟中的新方法，通过LLM驱动的代理实现类人决策和适应性，有效解决了代理可靠性、社交性和可解释性等挑战。", "motivation": "解决现有基于代理的建模（ABM）在模拟MMO游戏经济活动中难以实现类人经济行为的挑战，特别是代理的可靠性、社交性和可解释性问题。", "method": "利用大型语言模型（LLMs）的角色扮演能力、生成能力和推理能力，设计具有角色扮演、感知、记忆和推理能力的LLM驱动代理。", "result": "模拟实验表明，LLM赋能的代理能够促进游戏内经济活动的涌现现象，如角色专业化和符合市场规则的价格波动。", "conclusion": "LLM驱动的代理在MMO经济模拟中展现出实现类人经济行为的潜力，为游戏经济研究提供了新的工具和方法。"}}
{"id": "2506.04828", "title": "Safe Planning and Policy Optimization via World Model Learning", "authors": ["Artem Latyshev", "Gregory Gorbov", "Aleksandr I. Panov"], "abstract": "Reinforcement Learning (RL) applications in real-world scenarios must prioritize safety and reliability, which impose strict constraints on agent behavior. Model-based RL leverages predictive world models for action planning and policy optimization, but inherent model inaccuracies can lead to catastrophic failures in safety-critical settings. We propose a novel model-based RL framework that jointly optimizes task performance and safety. To address world model errors, our method incorporates an adaptive mechanism that dynamically switches between model-based planning and direct policy execution. We resolve the objective mismatch problem of traditional model-based approaches using an implicit world model. Furthermore, our framework employs dynamic safety thresholds that adapt to the agent's evolving capabilities, consistently selecting actions that surpass safe policy suggestions in both performance and safety. Experiments demonstrate significant improvements over non-adaptive methods, showing that our approach optimizes safety and performance simultaneously rather than merely meeting minimum safety requirements. The proposed framework achieves robust performance on diverse safety-critical continuous control tasks, outperforming existing methods.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04828.pdf", "abstract_url": "https://arxiv.org/abs/2506.04828", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新颖的基于模型的强化学习框架，旨在联合优化任务性能和安全性，通过自适应机制动态切换基于模型的规划和直接策略执行，以解决世界模型误差问题，并在实验中显示出优于非自适应方法的显著改进。", "motivation": "解决在安全关键设置中，由于模型不准确性导致的灾难性失败问题，同时优化任务性能和安全性。", "method": "采用自适应机制动态切换基于模型的规划和直接策略执行，使用隐式世界模型解决传统基于模型方法的目标不匹配问题，并应用动态安全阈值以适应代理的进化能力。", "result": "实验表明，该方法在多样化的安全关键连续控制任务上实现了鲁棒性能，优于现有方法。", "conclusion": "提出的框架不仅在性能上优于现有方法，而且能够同时优化安全性和性能，而不仅仅是满足最低安全要求。"}}
{"id": "2506.04849", "title": "Towards a Multi-Agent Simulation of Cyber-attackers and Cyber-defenders Battles", "authors": ["Julien Soulé", "Jean-Paul Jamont", "Michel Occello", "Paul Théron", "Louis-Marie Traonouez"], "abstract": "As cyber-attacks show to be more and more complex and coordinated, cyber-defenders strategy through multi-agent approaches could be key to tackle against cyber-attacks as close as entry points in a networked system. This paper presents a Markovian modeling and implementation through a simulator of fighting cyber-attacker agents and cyber-defender agents deployed on host network nodes. It aims to provide an experimental framework to implement realistically based coordinated cyber-attack scenarios while assessing cyber-defenders dynamic organizations. We abstracted network nodes by sets of properties including agents' ones. Actions applied by agents model how the network reacts depending in a given state and what properties are to change. Collective choice of the actions brings the whole environment closer or farther from respective cyber-attackers and cyber-defenders goals. Using the simulator, we implemented a realistically inspired scenario with several behavior implementation approaches for cyber-defenders and cyber-attackers.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04849.pdf", "abstract_url": "https://arxiv.org/abs/2506.04849", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于马尔可夫模型的多代理模拟器，用于模拟网络攻击者和防御者之间的战斗，旨在通过实验框架评估防御者的动态组织能力。", "motivation": "随着网络攻击变得越来越复杂和协调，通过多代理方法来制定网络防御策略可能是对抗网络攻击的关键。", "method": "使用马尔可夫模型和模拟器来模拟网络攻击者和防御者代理在网络节点上的战斗，抽象化网络节点为一组属性，包括代理的属性。", "result": "通过模拟器实现了一个现实启发的场景，展示了不同行为实现方法对网络攻击者和防御者目标的影响。", "conclusion": "该模拟器为实施基于现实的协调网络攻击场景提供了实验框架，同时评估了网络防御者的动态组织能力。"}}
{"id": "2506.04867", "title": "LLMs for sensory-motor control: Combining in-context and iterative learning", "authors": ["Jônata Tyska Carvalho", "Stefano Nolfi"], "abstract": "We propose a method that enables large language models (LLMs) to control embodied agents by directly mapping continuous observation vectors to continuous action vectors. Initially, the LLMs generate a control strategy based on a textual description of the agent, its environment, and the intended goal. This strategy is then iteratively refined through a learning process in which the LLMs are repeatedly prompted to improve the current strategy, using performance feedback and sensory-motor data collected during its evaluation. The method is validated on classic control tasks from the Gymnasium library and the inverted pendulum task from the MuJoCo library. In most cases, it successfully identifies optimal or high-performing solutions by integrating symbolic knowledge derived through reasoning with sub-symbolic sensory-motor data gathered as the agent interacts with its environment.", "subjects": "Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG); Robotics (cs.RO)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2506.04867.pdf", "abstract_url": "https://arxiv.org/abs/2506.04867", "categories": ["Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)", "Machine Learning (cs.LG)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种方法，使大型语言模型（LLMs）能够通过直接将连续观察向量映射到连续动作向量来控制体现代理。方法结合了上下文和迭代学习，通过文本描述生成控制策略，并利用性能反馈和感官运动数据进行迭代优化。在Gymnasium和MuJoCo库的经典控制任务上验证了其有效性。", "motivation": "解决大型语言模型在控制体现代理时，如何有效结合符号知识和子符号感官运动数据的问题。", "method": "首先基于文本描述生成控制策略，然后通过迭代学习过程，利用性能反馈和收集的感官运动数据不断优化策略。", "result": "在大多数情况下，该方法成功找到了最优或高性能的解决方案，有效结合了推理得到的符号知识和代理与环境交互收集的子符号数据。", "conclusion": "该方法展示了大型语言模型在控制体现代理方面的潜力，通过结合上下文学习和迭代优化，能够有效地处理连续观察和动作空间的任务。"}}
{"id": "2506.04916", "title": "Energentic Intelligence: From Self-Sustaining Systems to Enduring Artificial Life", "authors": ["Atahan Karagoz"], "abstract": "This paper introduces Energentic Intelligence, a class of autonomous systems defined not by task performance, but by their capacity to sustain themselves through internal energy regulation. Departing from conventional reward-driven paradigms, these agents treat survival-maintaining functional operation under fluctuating energetic and thermal conditions-as the central objective. We formalize this principle through an energy-based utility function and a viability-constrained survival horizon, and propose a modular architecture that integrates energy harvesting, thermal regulation, and adaptive computation into a closed-loop control system. A simulated environment demonstrates the emergence of stable, resource-aware behavior without external supervision. Together, these contributions provide a theoretical and architectural foundation for deploying autonomous agents in resource-volatile settings where persistence must be self-regulated and infrastructure cannot be assumed.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Systems and Control (eess.SY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04916.pdf", "abstract_url": "https://arxiv.org/abs/2506.04916", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Systems and Control (eess.SY)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了能量智能（Energentic Intelligence），一类通过内部能量调节自我维持的自主系统，其核心目标是生存而非任务完成。通过基于能量的效用函数和生存期限的可行性约束，提出了一种集成能量收集、温度调节和自适应计算的模块化架构。模拟环境展示了无需外部监督即可出现的稳定、资源感知行为。", "motivation": "解决在资源波动的环境中部署自主代理时，如何实现自我调节持久性的问题。", "method": "提出了一种基于能量的效用函数和生存期限的可行性约束，以及一个集成能量收集、温度调节和自适应计算的模块化架构。", "result": "模拟环境中出现了无需外部监督的稳定、资源感知行为。", "conclusion": "为在资源波动的环境中部署自主代理提供了理论和架构基础，其中持久性需要自我调节且不能依赖基础设施。"}}
{"id": "2506.04998", "title": "Mathematical Reasoning for Unmanned Aerial Vehicles: A RAG-Based Approach for Complex Arithmetic Reasoning", "authors": ["Mehdi Azarafza", "Mojtaba Nayyeri", "Faezeh Pasandideh", "Steffen Staab", "Achim Rettberg"], "abstract": "Autonomous UAV operation necessitates reliable mathematical reasoning for tasks such as trajectory planning and power management. While traditional flight control relies on hardcoded equations, recent Large Language Models (LLMs) offer potential for more flexible problem-solving but struggle with reliably selecting and applying correct mathematical formulations and executing precise multi-step arithmetic. We propose RAG-UAV, a retrieval-augmented generation framework designed to improve the mathematical reasoning of several LLMs (including GPT o1/Turbo, Llama-3.2/3.3, Mistral, and DeepSeek R1) in UAV-specific contexts by providing access to relevant domain literature. To conduct an initial assessment, we introduce the UAV-Math-Bench, a small problem set comprising 20 UAV-centric mathematical problems across four difficulty levels. Our experiments demonstrate that incorporating retrieval substantially increases exact answer accuracy (achieving up to 75% with o1), reduces instances of incorrect formulation selection (from 25% without RAG to 5% with RAG), decreases numerical errors, reducing Mean Squared Error (MSE) by orders of magnitude for the best-performing models. This pilot study indicates that RAG can enable general-purpose LLMs to function as more reliable tools for engineering analysis, although direct real-time flight control requires further investigation and validation on a larger scale. All benchmark data, question and answer are publicly available.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "15 pages, 7 figures, 4 appendix subsections", "pdf_url": "https://arxiv.org/pdf/2506.04998.pdf", "abstract_url": "https://arxiv.org/abs/2506.04998", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种基于检索增强生成（RAG）的框架RAG-UAV，旨在提升大型语言模型（LLMs）在无人机（UAV）特定上下文中的数学推理能力，通过提供相关领域文献的访问，显著提高了准确性和减少了数学错误。", "motivation": "自主无人机操作需要可靠的数学推理能力，传统飞行控制依赖硬编码方程，而现有的大型语言模型在正确选择和运用数学公式及执行精确的多步算术上存在困难。", "method": "提出了RAG-UAV框架，通过检索增强生成技术，为LLMs提供相关领域文献，以改善其在无人机特定上下文中的数学推理能力。并引入了UAV-Math-Bench，一个包含20个无人机中心数学问题的基准集，用于初步评估。", "result": "实验显示，引入检索显著提高了准确答案的比例（最高达到75%），减少了错误公式选择的情况（从25%降至5%），并大幅降低了数值错误，最佳模型的均方误差（MSE）降低了数量级。", "conclusion": "初步研究表明，RAG可以使通用LLMs成为工程分析中更可靠的工具，但直接的实时飞行控制还需要更大规模的进一步研究和验证。所有基准数据、问题和答案均已公开。"}}
{"id": "2506.05109", "title": "Truly Self-Improving Agents Require Intrinsic Metacognitive Learning", "authors": ["Tennison Liu", "Mihaela van der Schaar"], "abstract": "Self-improving agents aim to continuously acquire new capabilities with minimal supervision. However, current approaches face two key limitations: their self-improvement processes are often rigid, fail to generalize across tasks domains, and struggle to scale with increasing agent capabilities. We argue that effective self-improvement requires intrinsic metacognitive learning, defined as an agent's intrinsic ability to actively evaluate, reflect on, and adapt its own learning processes. Drawing inspiration from human metacognition, we introduce a formal framework comprising three components: metacognitive knowledge (self-assessment of capabilities, tasks, and learning strategies), metacognitive planning (deciding what and how to learn), and metacognitive evaluation (reflecting on learning experiences to improve future learning). Analyzing existing self-improving agents, we find they rely predominantly on extrinsic metacognitive mechanisms, which are fixed, human-designed loops that limit scalability and adaptability. Examining each component, we contend that many ingredients for intrinsic metacognition are already present. Finally, we explore how to optimally distribute metacognitive responsibilities between humans and agents, and robustly evaluate and improve intrinsic metacognitive learning, key challenges that must be addressed to enable truly sustained, generalized, and aligned self-improvement.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "Published as a conference paper at ICML 2025", "pdf_url": "https://arxiv.org/pdf/2506.05109.pdf", "abstract_url": "https://arxiv.org/abs/2506.05109", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出，真正的自我改进智能体需要内在的元认知学习能力，即智能体能够主动评估、反思并调整其学习过程。通过分析现有自我改进智能体的局限性，作者提出了一个包含元认知知识、元认知规划和元认知评估的框架，并探讨了如何优化人类与智能体之间的元认知责任分配。", "motivation": "当前自我改进智能体的自我改进过程往往僵化，难以跨任务领域泛化，且随着智能体能力的提升难以扩展。本文旨在解决这些问题，提出内在元认知学习是实现有效自我改进的关键。", "method": "作者引入了包含三个组件的正式框架：元认知知识（自我评估能力、任务和学习策略）、元认知规划（决定学习什么和如何学习）和元认知评估（反思学习经验以改进未来学习）。", "result": "分析发现，现有自我改进智能体主要依赖外在的元认知机制，这些机制是固定的、由人类设计的循环，限制了可扩展性和适应性。同时，许多内在元认知的要素已经存在。", "conclusion": "为了实现真正持续、泛化和对齐的自我改进，必须解决如何优化人类与智能体之间的元认知责任分配，以及如何稳健评估和改进内在元认知学习等关键挑战。"}}
{"id": "2506.05296", "title": "Control Tax: The Price of Keeping AI in Check", "authors": ["Mikhail Terekhov", "Zhen Ning David Liu", "Caglar Gulcehre", "Samuel Albanie"], "abstract": "The rapid integration of agentic AI into high-stakes real-world applications requires robust oversight mechanisms. The emerging field of AI Control (AIC) aims to provide such an oversight mechanism, but practical adoption depends heavily on implementation overhead. To study this problem better, we introduce the notion of Control tax -- the operational and financial cost of integrating control measures into AI pipelines. Our work makes three key contributions to the field of AIC: (1) we introduce a theoretical framework that quantifies the Control Tax and maps classifier performance to safety assurances; (2) we conduct comprehensive evaluations of state-of-the-art language models in adversarial settings, where attacker models insert subtle backdoors into code while monitoring models attempt to detect these vulnerabilities; and (3) we provide empirical financial cost estimates for control protocols and develop optimized monitoring strategies that balance safety and cost-effectiveness while accounting for practical constraints like auditing budgets. Our framework enables practitioners to make informed decisions by systematically connecting safety guarantees with their costs, advancing AIC through principled economic feasibility assessment across different deployment contexts.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.05296.pdf", "abstract_url": "https://arxiv.org/abs/2506.05296", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了控制税的概念，即整合控制措施到AI管道中的操作和财务成本，并提出了一个理论框架来量化控制税，将分类器性能映射到安全保证。", "motivation": "随着代理AI在高风险现实世界应用中的快速集成，需要强大的监督机制。AI控制（AIC）领域旨在提供这样的监督机制，但实际采用很大程度上取决于实施开销。", "method": "本文提出了一个理论框架来量化控制税，并在对抗性设置中对最先进的语言模型进行了全面评估，同时提供了控制协议的财务成本估计并开发了优化的监控策略。", "result": "研究结果表明，通过系统地连接安全保证与其成本，使从业者能够在不同的部署环境中做出明智的决策。", "conclusion": "本文通过原则性的经济可行性评估，推动了AIC的发展，为平衡安全性和成本效益提供了优化的监控策略。"}}
{"id": "2506.03922", "title": "HSSBench: Benchmarking Humanities and Social Sciences Ability for Multimodal Large Language Models", "authors": ["Zhaolu Kang", "Junhao Gong", "Jiaxu Yan", "Wanke Xia", "Yian Wang", "Ziwen Wang", "Huaxuan Ding", "Zhuo Cheng", "Wenhao Cao", "Zhiyuan Feng", "Siqi He", "Shannan Yan", "Junzhe Chen", "Xiaomin He", "Chaoya Jiang", "Wei Ye", "Kaidong Yu", "Xuelong Li"], "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated significant potential to advance a broad range of domains. However, current benchmarks for evaluating MLLMs primarily emphasize general knowledge and vertical step-by-step reasoning typical of STEM disciplines, while overlooking the distinct needs and potential of the Humanities and Social Sciences (HSS). Tasks in the HSS domain require more horizontal, interdisciplinary thinking and a deep integration of knowledge across related fields, which presents unique challenges for MLLMs, particularly in linking abstract concepts with corresponding visual representations. Addressing this gap, we present HSSBench, a dedicated benchmark designed to assess the capabilities of MLLMs on HSS tasks in multiple languages, including the six official languages of the United Nations. We also introduce a novel data generation pipeline tailored for HSS scenarios, in which multiple domain experts and automated agents collaborate to generate and iteratively refine each sample. HSSBench contains over 13,000 meticulously designed samples, covering six key categories. We benchmark more than 20 mainstream MLLMs on HSSBench and demonstrate that it poses significant challenges even for state-of-the-art models. We hope that this benchmark will inspire further research into enhancing the cross-disciplinary reasoning abilities of MLLMs, especially their capacity to internalize and connect knowledge across fields.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.03922.pdf", "abstract_url": "https://arxiv.org/abs/2506.03922", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "HSSBench是一个专为评估多模态大语言模型（MLLMs）在人文学科和社会科学（HSS）领域能力而设计的基准测试，包含超过13,000个样本，覆盖六个关键类别，并在多种语言中进行测试。", "motivation": "当前评估MLLMs的基准主要强调STEM学科的通用知识和垂直逐步推理，忽视了HSS领域的独特需求和潜力，特别是在将抽象概念与相应的视觉表示联系起来方面。", "method": "引入了一个专为HSS场景设计的新数据生成管道，其中多个领域专家和自动化代理协作生成并迭代优化每个样本。", "result": "HSSBench对超过20个主流MLLMs进行了基准测试，结果表明即使是最先进的模型也面临重大挑战。", "conclusion": "HSSBench有望激发进一步研究，以增强MLLMs的跨学科推理能力，特别是它们在跨领域内化和连接知识的能力。"}}
{"id": "2506.04236", "title": "Spore in the Wild: Case Study on Spore.fun, a Real-World Experiment of Sovereign Agent Open-ended Evolution on Blockchain with TEEs", "authors": ["Botao Amber Hu", "Helena Rong"], "abstract": "In Artificial Life (ALife) research, replicating Open-Ended Evolution (OEE)-the continuous emergence of novelty observed in biological life-has traditionally been pursued within isolated closed system simulations, such as Tierra and Avida, which have typically plateaued after an initial burst of novelty, failing to achieve sustained OEE. Scholars suggest that OEE requires an \"open\" system that continually exchanges information or energy with its environment. A recent technological innovation in decentralized physical infrastructure networks (DePIN) providing permissionless computational substrates enables deploying large language model (LLM)-based AI agents on blockchains integrated with Trusted Execution Environments (TEEs). This enables on-chain agents to operate autonomously \"in the wild,\" achieving self-sovereignty without human oversight. These agents can control their own social media accounts and cryptocurrency wallets, allowing them to interact directly with blockchain-based financial networks and broader human social media. Building on this new paradigm of on-chain agents,", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Neural and Evolutionary Computing (cs.NE)", "comments": "Submitted to ALIFE 2025", "pdf_url": "https://arxiv.org/pdf/2506.04236.pdf", "abstract_url": "https://arxiv.org/abs/2506.04236", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)", "Neural and Evolutionary Computing (cs.NE)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了在区块链与可信执行环境（TEEs）结合的技术背景下，通过Spore.fun案例研究，实现主权代理在开放环境中的开放式演化（OEE）。", "motivation": "传统的人工生命（ALife）研究在封闭系统模拟中难以实现持续的开放式演化（OEE），需要开放系统与环境持续交换信息或能量。", "method": "利用去中心化物理基础设施网络（DePIN）和区块链技术，结合TEEs，部署基于大型语言模型（LLM）的AI代理，使其能够在开放环境中自主运作。", "result": "通过Spore.fun案例，展示了主权代理能够在没有人类监督的情况下，自主控制社交媒体账户和加密货币钱包，直接与区块链金融网络和人类社交媒体互动。", "conclusion": "这项研究为在开放系统中实现持续的开放式演化提供了新的技术路径和实证案例，推动了人工生命和区块链技术的交叉研究。"}}
{"id": "2506.04265", "title": "CORA: Coalitional Rational Advantage Decomposition for Multi-Agent Policy Gradients", "authors": ["Mengda Ji", "Genjiu Xu", "Liying Wang"], "abstract": "This work focuses on the credit assignment problem in cooperative multi-agent reinforcement learning (MARL). Sharing the global advantage among agents often leads to suboptimal policy updates as it fails to account for the distinct contributions of agents. Although numerous methods consider global or individual contributions for credit assignment, a detailed analysis at the coalition level remains lacking in many approaches. This work analyzes the over-updating problem during multi-agent policy updates from a coalition-level perspective. To address this issue, we propose a credit assignment method called Coalitional Rational Advantage Decomposition (CORA). CORA evaluates coalitional advantages via marginal contributions from all possible coalitions and decomposes advantages using the core solution from cooperative game theory, ensuring coalitional rationality. To reduce computational overhead, CORA employs random coalition sampling. Experiments on matrix games, differential games, and multi-agent collaboration benchmarks demonstrate that CORA outperforms strong baselines, particularly in tasks with multiple local optima. These findings highlight the importance of coalition-aware credit assignment for improving MARL performance.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04265.pdf", "abstract_url": "https://arxiv.org/abs/2506.04265", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Computer Science and Game Theory (cs.GT)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为CORA的信用分配方法，用于解决合作多智能体强化学习中的信用分配问题。通过从联盟层面分析多智能体策略更新中的过度更新问题，并利用合作博弈论中的核心解来分解优势，确保了联盟的合理性。实验证明，CORA在多种任务中优于现有基线方法。", "motivation": "解决合作多智能体强化学习中的信用分配问题，特别是如何公平地评估和分配智能体联盟的贡献，以避免全局优势共享导致的次优策略更新。", "method": "提出CORA方法，通过评估所有可能联盟的边际贡献来评估联盟优势，并利用合作博弈论中的核心解进行优势分解，同时采用随机联盟采样以减少计算开销。", "result": "在矩阵游戏、微分游戏和多智能体协作基准测试中，CORA表现优于强基线方法，特别是在存在多个局部最优解的任务中。", "conclusion": "联盟感知的信用分配对于提高多智能体强化学习性能至关重要，CORA方法为此提供了一种有效的解决方案。"}}
{"id": "2506.04293", "title": "AUTOCT: Automating Interpretable Clinical Trial Prediction with LLM Agents", "authors": ["Fengze Liu", "Haoyu Wang", "Joonhyuk Cho", "Dan Roth", "Andrew W. Lo"], "abstract": "Clinical trials are critical for advancing medical treatments but remain prohibitively expensive and time-consuming. Accurate prediction of clinical trial outcomes can significantly reduce research and development costs and accelerate drug discovery. While recent deep learning models have shown promise by leveraging unstructured data, their black-box nature, lack of interpretability, and vulnerability to label leakage limit their practical use in high-stakes biomedical contexts. In this work, we propose AutoCT, a novel framework that combines the reasoning capabilities of large language models with the explainability of classical machine learning. AutoCT autonomously generates, evaluates, and refines tabular features based on public information without human input. Our method uses Monte Carlo Tree Search to iteratively optimize predictive performance. Experimental results show that AutoCT performs on par with or better than SOTA methods on clinical trial prediction tasks within only a limited number of self-refinement iterations, establishing a new paradigm for scalable, interpretable, and cost-efficient clinical trial prediction.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04293.pdf", "abstract_url": "https://arxiv.org/abs/2506.04293", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "AutoCT是一个结合大型语言模型推理能力和经典机器学习可解释性的新框架，用于自动化、可解释的临床试验预测。", "motivation": "临床试验对于推进医学治疗至关重要，但其成本高昂且耗时。准确预测临床试验结果可以显著降低研发成本并加速药物发现。", "method": "AutoCT利用大型语言模型的推理能力和经典机器学习的可解释性，自主生成、评估和优化基于公共信息的表格特征，无需人工输入，并使用蒙特卡洛树搜索迭代优化预测性能。", "result": "实验结果表明，AutoCT在有限的自我优化迭代次数内，在临床试验预测任务上的表现与或优于现有最先进方法。", "conclusion": "AutoCT为可扩展、可解释且成本效益高的临床试验预测建立了新范式。"}}
{"id": "2506.04276", "title": "Autonomous Collaborative Scheduling of Time-dependent UAVs, Workers and Vehicles for Crowdsensing in Disaster Response", "authors": ["Lei Han", "Yitong Guo", "Pengfei Yang", "Zhiyong Yu", "Liang Wang", "Quan Wang", "Zhiwen Yu"], "abstract": "Natural disasters have caused significant losses to human society, and the timely and efficient acquisition of post-disaster environmental information is crucial for the effective implementation of rescue operations. Due to the complexity of post-disaster environments, existing sensing technologies face challenges such as weak environmental adaptability, insufficient specialized sensing capabilities, and limited practicality of sensing solutions. This paper explores the heterogeneous multi-agent online autonomous collaborative scheduling algorithm HoAs-PALN, aimed at achieving efficient collection of post-disaster environmental information. HoAs-PALN is realized through adaptive dimensionality reduction in the matching process and local Nash equilibrium game, facilitating autonomous collaboration among time-dependent UAVs, workers and vehicles to enhance sensing scheduling. (1) In terms of adaptive dimensionality reduction during the matching process, HoAs-PALN significantly reduces scheduling decision time by transforming a five-dimensional matching process into two categories of three-dimensional matching processes; (2) Regarding the local Nash equilibrium game, HoAs-PALN combines the softmax function to optimize behavior selection probabilities and introduces a local Nash equilibrium determination mechanism to ensure scheduling decision performance. Finally, we conducted detailed experiments based on extensive real-world and simulated data. Compared with the baselines (GREEDY, K-WTA, MADL and MARL), HoAs-PALN improves task completion rates by 64.12%, 46.48%, 16.55%, and 14.03% on average, respectively, while each online scheduling decision takes less than 10 seconds, demonstrating its effectiveness in dynamic post-disaster environments.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04276.pdf", "abstract_url": "https://arxiv.org/abs/2506.04276", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了异构多智能体在线自主协同调度算法HoAs-PALN，旨在实现灾后环境信息的高效收集。通过匹配过程中的自适应降维和局部纳什均衡博弈，HoAs-PALN促进了时间依赖的无人机、工人和车辆之间的自主协作，以增强感知调度。实验表明，HoAs-PALN在动态灾后环境中表现出色。", "motivation": "自然灾害给人类社会造成了重大损失，及时高效地获取灾后环境信息对于有效实施救援行动至关重要。由于灾后环境的复杂性，现有的感知技术面临环境适应性弱、专业感知能力不足和感知解决方案实用性有限等挑战。", "method": "本文提出了异构多智能体在线自主协同调度算法HoAs-PALN，通过匹配过程中的自适应降维和局部纳什均衡博弈，实现了时间依赖的无人机、工人和车辆之间的自主协作。", "result": "与基线（GREEDY、K-WTA、MADL和MARL）相比，HoAs-PALN平均提高了任务完成率64.12%、46.48%、16.55%和14.03%，每次在线调度决策时间少于10秒。", "conclusion": "HoAs-PALN算法在动态灾后环境中表现出色，显著提高了任务完成率和调度效率，为灾后救援行动提供了有效的技术支持。"}}
{"id": "2506.04390", "title": "Through the Stealth Lens: Rethinking Attacks and Defenses in RAG", "authors": ["Sarthak Choudhary", "Nils Palumbo", "Ashish Hooda", "Krishnamurthy Dj Dvijotham", "Somesh Jha"], "abstract": "Retrieval-augmented generation (RAG) systems are vulnerable to attacks that inject poisoned passages into the retrieved set, even at low corruption rates. We show that existing attacks are not designed to be stealthy, allowing reliable detection and mitigation. We formalize stealth using a distinguishability-based security game. If a few poisoned passages are designed to control the response, they must differentiate themselves from benign ones, inherently compromising stealth. This motivates the need for attackers to rigorously analyze intermediate signals involved in generation$\\unicode{x2014}$such as attention patterns or next-token probability distributions$\\unicode{x2014}$to avoid easily detectable traces of manipulation. Leveraging attention patterns, we propose a passage-level score$\\unicode{x2014}$the Normalized Passage Attention Score$\\unicode{x2014}$used by our Attention-Variance Filter algorithm to identify and filter potentially poisoned passages. This method mitigates existing attacks, improving accuracy by up to $\\sim 20 \\%$ over baseline defenses. To probe the limits of attention-based defenses, we craft stealthier adaptive attacks that obscure such traces, achieving up to $35 \\%$ attack success rate, and highlight the challenges in improving stealth.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04390.pdf", "abstract_url": "https://arxiv.org/abs/2506.04390", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文探讨了检索增强生成（RAG）系统在面对注入中毒段落攻击时的脆弱性，并提出了一种基于注意力模式的防御方法。", "motivation": "解决RAG系统在低污染率下仍易受攻击的问题，特别是那些设计不够隐蔽的攻击，这些攻击容易被检测和缓解。", "method": "通过形式化隐蔽性使用基于区分度的安全游戏，提出了一种基于注意力模式的段落级评分——归一化段落注意力分数，并开发了注意力方差过滤算法来识别和过滤潜在的中毒段落。", "result": "该方法有效缓解了现有攻击，比基线防御提高了约20%的准确率。同时，研究还设计了更隐蔽的自适应攻击，攻击成功率高达35%，揭示了提高隐蔽性的挑战。", "conclusion": "研究表明，虽然基于注意力的防御方法可以有效对抗现有攻击，但攻击者通过更隐蔽的策略仍能取得一定成功，这为未来防御技术的改进提出了挑战。"}}
{"id": "2506.04405", "title": "MedAgentGym: Training LLM Agents for Code-Based Medical Reasoning at Scale", "authors": ["Ran Xu", "Yuchen Zhuang", "Yishan Zhong", "Yue Yu", "Xiangru Tang", "Hang Wu", "May D. Wang", "Peifeng Ruan", "Donghan Yang", "Tao Wang", "Guanghua Xiao", "Carl Yang", "Yang Xie", "Wenqi Shi"], "abstract": "We introduce MedAgentGYM, the first publicly available training environment designed to enhance coding-based medical reasoning capabilities in large language model (LLM) agents. MedAgentGYM comprises 72,413 task instances across 129 categories derived from authentic real-world biomedical scenarios. Tasks are encapsulated within executable coding environments, each featuring detailed task descriptions, interactive feedback mechanisms, verifiable ground-truth annotations, and scalable training trajectory generation. Extensive benchmarking of over 30 LLMs reveals a notable performance disparity between commercial API-based models and open-source counterparts. Leveraging MedAgentGYM, Med-Copilot-7B achieves substantial performance gains through supervised fine-tuning (+36.44%) and continued reinforcement learning (+42.47%), emerging as an affordable and privacy-preserving alternative competitive with gpt-4o. By offering both a comprehensive benchmark and accessible, expandable training resources within unified execution environments, MedAgentGYM delivers an integrated platform to develop LLM-based coding assistants for advanced biomedical research and practice.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04405.pdf", "abstract_url": "https://arxiv.org/abs/2506.04405", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "介绍了MedAgentGYM，首个公开的训练环境，旨在增强大型语言模型（LLM）代理的基于编码的医学推理能力。包含72,413个任务实例，覆盖129个类别，源自真实世界生物医学场景。通过监督微调和持续强化学习，Med-Copilot-7B性能显著提升。", "motivation": "解决大型语言模型在基于编码的医学推理能力上的不足，提供一个公开、可扩展的训练环境。", "method": "创建包含大量真实世界生物医学任务的训练环境MedAgentGYM，采用监督微调和持续强化学习方法训练LLM代理。", "result": "Med-Copilot-7B通过监督微调性能提升36.44%，通过持续强化学习性能提升42.47%，成为与gpt-4o竞争的经济且隐私保护的替代方案。", "conclusion": "MedAgentGYM为开发基于LLM的编码助手提供了综合基准和可访问的训练资源，推动了高级生物医学研究和实践的发展。"}}
{"id": "2506.04399", "title": "Unsupervised Meta-Testing with Conditional Neural Processes for Hybrid Meta-Reinforcement Learning", "authors": ["Suzan Ece Ada", "Emre Ugur"], "abstract": "We introduce Unsupervised Meta-Testing with Conditional Neural Processes (UMCNP), a novel hybrid few-shot meta-reinforcement learning (meta-RL) method that uniquely combines, yet distinctly separates, parameterized policy gradient-based (PPG) and task inference-based few-shot meta-RL. Tailored for settings where the reward signal is missing during meta-testing, our method increases sample efficiency without requiring additional samples in meta-training. UMCNP leverages the efficiency and scalability of Conditional Neural Processes (CNPs) to reduce the number of online interactions required in meta-testing. During meta-training, samples previously collected through PPG meta-RL are efficiently reused for learning task inference in an offline manner. UMCNP infers the latent representation of the transition dynamics model from a single test task rollout with unknown parameters. This approach allows us to generate rollouts for self-adaptation by interacting with the learned dynamics model. We demonstrate our method can adapt to an unseen test task using significantly fewer samples during meta-testing than the baselines in 2D-Point Agent and continuous control meta-RL benchmarks, namely, cartpole with unknown angle sensor bias, walker agent with randomized dynamics parameters.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": "Published in IEEE Robotics and Automation Letters Volume: 9, Issue: 10, 8427 - 8434, October 2024. 8 pages, 7 figures", "pdf_url": "https://arxiv.org/pdf/2506.04399.pdf", "abstract_url": "https://arxiv.org/abs/2506.04399", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了UMCNP，一种新型的混合少样本元强化学习方法，结合了参数化策略梯度基和任务推理基的元强化学习，特别适用于元测试期间奖励信号缺失的情况。", "motivation": "解决在元测试阶段缺乏奖励信号的情况下，如何提高样本效率而不需要在元训练阶段增加额外样本的问题。", "method": "利用条件神经过程（CNPs）的效率和可扩展性，减少元测试阶段所需的在线交互次数，通过单次测试任务 rollout 推断转移动态模型的潜在表示。", "result": "在2D点代理和连续控制元强化学习基准测试中，UMCNP能够比基线方法使用更少的样本适应未见过的测试任务。", "conclusion": "UMCNP提供了一种有效的方法，可以在元测试阶段显著减少样本需求，同时保持或提高性能，为元强化学习领域提供了新的研究方向。"}}
{"id": "2506.04409", "title": "Empaths at SemEval-2025 Task 11: Retrieval-Augmented Approach to Perceived Emotions Prediction", "authors": ["Lev Morozov", "Aleksandr Mogilevskii", "Alexander Shirnin"], "abstract": "This paper describes EmoRAG, a system designed to detect perceived emotions in text for SemEval-2025 Task 11, Subtask A: Multi-label Emotion Detection. We focus on predicting the perceived emotions of the speaker from a given text snippet, labeling it with emotions such as joy, sadness, fear, anger, surprise, and disgust. Our approach does not require additional model training and only uses an ensemble of models to predict emotions. EmoRAG achieves results comparable to the best performing systems, while being more efficient, scalable, and easier to implement.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "Accepted to SemEval-2025, an ACL 2025 workshop", "pdf_url": "https://arxiv.org/pdf/2506.04409.pdf", "abstract_url": "https://arxiv.org/abs/2506.04409", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了EmoRAG系统，用于在SemEval-2025任务11的子任务A中检测文本中的感知情绪，无需额外模型训练，仅使用模型集合预测情绪，效果与最佳系统相当，且更高效、可扩展、易实施。", "motivation": "解决在文本中准确检测说话者感知情绪的问题，如喜悦、悲伤、恐惧、愤怒、惊讶和厌恶，为SemEval-2025任务11的子任务A提供解决方案。", "method": "使用检索增强的方法（EmoRAG），不进行额外的模型训练，仅通过模型集合来预测情绪。", "result": "EmoRAG的表现与最佳系统相当，同时在效率、可扩展性和实施简易性上更具优势。", "conclusion": "EmoRAG为感知情绪预测提供了一种高效、可扩展且易于实现的解决方案，无需额外训练即可达到竞争性性能。"}}
{"id": "2506.05010", "title": "ComfyUI-Copilot: An Intelligent Assistant for Automated Workflow Development", "authors": ["Zhenran Xu", "Xue Yang", "Yiyu Wang", "Qingli Hu", "Zijiao Wu", "Longyue Wang", "Weihua Luo", "Kaifu Zhang", "Baotian Hu", "Min Zhang"], "abstract": "We introduce ComfyUI-Copilot, a large language model-powered plugin designed to enhance the usability and efficiency of ComfyUI, an open-source platform for AI-driven art creation. Despite its flexibility and user-friendly interface, ComfyUI can present challenges to newcomers, including limited documentation, model misconfigurations, and the complexity of workflow design. ComfyUI-Copilot addresses these challenges by offering intelligent node and model recommendations, along with automated one-click workflow construction. At its core, the system employs a hierarchical multi-agent framework comprising a central assistant agent for task delegation and specialized worker agents for different usages, supported by our curated ComfyUI knowledge bases to streamline debugging and deployment. We validate the effectiveness of ComfyUI-Copilot through both offline quantitative evaluations and online user feedback, showing that it accurately recommends nodes and accelerates workflow development. Additionally, use cases illustrate that ComfyUI-Copilot lowers entry barriers for beginners and enhances workflow efficiency for experienced users. The ComfyUI-Copilot installation package and a demo video are available at", "subjects": "Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2506.05010.pdf", "abstract_url": "https://arxiv.org/abs/2506.05010", "categories": ["Computation and Language (cs.CL)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "ComfyUI-Copilot是一个基于大型语言模型的插件，旨在提高ComfyUI平台的可用性和效率，通过智能节点和模型推荐以及一键式工作流构建，解决新用户面临的挑战。", "motivation": "解决ComfyUI平台对新用户不友好、文档有限、模型配置错误和工作流设计复杂的问题。", "method": "采用分层多代理框架，包括一个中央助理代理和多个专门的工作代理，利用定制的ComfyUI知识库来简化调试和部署。", "result": "离线定量评估和在线用户反馈验证了ComfyUI-Copilot能准确推荐节点并加速工作流开发，同时降低了初学者的入门门槛并提高了有经验用户的工作效率。", "conclusion": "ComfyUI-Copilot通过智能辅助功能显著提升了ComfyUI平台的用户体验和工作效率，适用于不同技能水平的用户。"}}
{"id": "2506.04836", "title": "Oversight Structures for Agentic AI in Public-Sector Organizations", "authors": ["Chris Schmitz", "Jonathan Rystrøm", "Jan Batzner"], "abstract": "This paper finds that the introduction of agentic AI systems intensifies existing challenges to traditional public sector oversight mechanisms -- which rely on siloed compliance units and episodic approvals rather than continuous, integrated supervision. We identify five governance dimensions essential for responsible agent deployment: cross-departmental implementation, comprehensive evaluation, enhanced security protocols, operational visibility, and systematic auditing. We evaluate the capacity of existing oversight structures to meet these challenges, via a mixed-methods approach consisting of a literature review and interviews with civil servants in AI-related roles. We find that agent oversight poses intensified versions of three existing governance challenges: continuous oversight, deeper integration of governance and operational capabilities, and interdepartmental coordination. We propose approaches that both adapt institutional structures and design agent oversight compatible with public sector constraints.", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI)", "comments": "To appear at REALM@ACL2025", "pdf_url": "https://arxiv.org/pdf/2506.04836.pdf", "abstract_url": "https://arxiv.org/abs/2506.04836", "categories": ["Computers and Society (cs.CY)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文发现，引入代理性AI系统加剧了公共部门传统监督机制面临的挑战，这些机制依赖于孤立的合规单位和阶段性批准，而非持续、集成的监督。我们确定了负责任代理部署的五个治理维度：跨部门实施、全面评估、增强的安全协议、操作可见性和系统审计。通过文献综述和对AI相关职位公务员的访谈，我们评估了现有监督结构应对这些挑战的能力。我们发现，代理监督加剧了三个现有治理挑战：持续监督、治理与运营能力的更深层次整合以及跨部门协调。我们提出了既适应制度结构又设计符合公共部门约束的代理监督方法。", "motivation": "解决代理性AI系统引入公共部门后对传统监督机制带来的挑战", "method": "混合方法，包括文献综述和对AI相关职位公务员的访谈", "result": "代理监督加剧了持续监督、治理与运营能力的更深层次整合以及跨部门协调三个现有治理挑战", "conclusion": "提出了适应制度结构并设计符合公共部门约束的代理监督方法"}}
{"id": "2506.04838", "title": "On Automating Security Policies with Contemporary LLMs", "authors": ["Pablo Fernández Saura", "K. R. Jayaram", "Vatche Isahagian", "Jorge Bernal Bernabé", "Antonio Skarmeta"], "abstract": "The complexity of modern computing environments and the growing sophistication of cyber threats necessitate a more robust, adaptive, and automated approach to security enforcement. In this paper, we present a framework leveraging large language models (LLMs) for automating attack mitigation policy compliance through an innovative combination of in-context learning and retrieval-augmented generation (RAG). We begin by describing how our system collects and manages both tool and API specifications, storing them in a vector database to enable efficient retrieval of relevant information. We then detail the architectural pipeline that first decomposes high-level mitigation policies into discrete tasks and subsequently translates each task into a set of actionable API calls. Our empirical evaluation, conducted using publicly available CTI policies in STIXv2 format and Windows API documentation, demonstrates significant improvements in precision, recall, and F1-score when employing RAG compared to a non-RAG baseline.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": "Short Paper. Accepted To Appear in IEEE SSE 2025 (part of SERVICES 2025)", "pdf_url": "https://arxiv.org/pdf/2506.04838.pdf", "abstract_url": "https://arxiv.org/abs/2506.04838", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种利用大型语言模型（LLMs）自动化安全策略的框架，通过结合上下文学习和检索增强生成（RAG）技术，显著提高了安全策略的精确度、召回率和F1分数。", "motivation": "现代计算环境的复杂性和网络威胁的日益复杂化要求一种更强大、自适应和自动化的安全执行方法。", "method": "框架首先收集和管理工具及API规范，存储在向量数据库中以便高效检索相关信息；然后通过架构管道将高级缓解策略分解为离散任务，并将每个任务转化为一系列可操作的API调用。", "result": "使用公开可用的CTI策略（STIXv2格式）和Windows API文档进行的实证评估显示，采用RAG相比非RAG基线在精确度、召回率和F1分数上有显著提升。", "conclusion": "研究表明，结合大型语言模型和RAG技术可以有效地自动化安全策略，提高网络安全防护的效率和效果。"}}
{"id": "2506.05020", "title": "Hierarchical Language Models for Semantic Navigation and Manipulation in an Aerial-Ground Robotic System", "authors": ["Haokun Liu", "Zhaoqi Ma", "Yunong Li", "Junichiro Sugihara", "Yicheng Chen", "Jinjie Li", "Moju Zhao"], "abstract": "Heterogeneous multi-robot systems show great potential in complex tasks requiring coordinated hybrid cooperation. However, traditional approaches relying on static models often struggle with task diversity and dynamic environments. This highlights the need for generalizable intelligence that can bridge high-level reasoning with low-level execution across heterogeneous agents. To address this, we propose a hierarchical framework integrating a prompted Large Language Model (LLM) and a GridMask-enhanced fine-tuned Vision Language Model (VLM). The LLM performs task decomposition and global semantic map construction, while the VLM extracts task-specified semantic labels and 2D spatial information from aerial images to support local planning. Within this framework, the aerial robot follows a globally optimized semantic path and continuously provides bird-view images, guiding the ground robot's local semantic navigation and manipulation, including target-absent scenarios where implicit alignment is maintained. Experiments on a real-world letter-cubes arrangement task demonstrate the framework's adaptability and robustness in dynamic environments. To the best of our knowledge, this is the first demonstration of an aerial-ground heterogeneous system integrating VLM-based perception with LLM-driven task reasoning and motion planning.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.05020.pdf", "abstract_url": "https://arxiv.org/abs/2506.05020", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种集成大型语言模型（LLM）和视觉语言模型（VLM）的层次框架，用于异构空中-地面机器人系统中的语义导航和操作，展示了在动态环境中的适应性和鲁棒性。", "motivation": "异构多机器人系统在需要协调混合合作的复杂任务中显示出巨大潜力，但依赖静态模型的传统方法难以应对任务多样性和动态环境，需要一种能够跨异构代理桥接高级推理与低级执行的通用智能。", "method": "提出了一种层次框架，集成了提示的大型语言模型（LLM）和GridMask增强的微调视觉语言模型（VLM）。LLM负责任务分解和全局语义地图构建，VLM从航拍图像中提取任务指定的语义标签和2D空间信息以支持局部规划。", "result": "在真实世界的字母立方体排列任务上的实验表明，该框架在动态环境中具有适应性和鲁棒性。", "conclusion": "这是首次展示将基于VLM的感知与LLM驱动的任务推理和运动规划相结合的空中-地面异构系统，为复杂任务中的机器人协作提供了新的可能性。"}}
{"id": "2506.05154", "title": "Knowledgeable-r1: Policy Optimization for Knowledge Exploration in Retrieval-Augmented Generation", "authors": ["Chenyu Lin", "Yilin Wen", "Du Su", "Fei Sun", "Muhan Chen", "Chenfu Bao", "Zhonghou Lv"], "abstract": "Retrieval-augmented generation (RAG) is a mainstream method for improving performance on knowledge-intensive tasks. However,current RAG systems often place too much emphasis on retrieved contexts. This can lead to reliance on inaccurate sources and overlook the model's inherent knowledge, especially when dealing with misleading or excessive information. To resolve this imbalance, we propose Knowledgeable-r1 that using joint sampling and define multi policy distributions in knowledge capability exploration to stimulate large language models'self-integrated utilization of parametric and contextual knowledge. Experiments show that Knowledgeable-r1 significantly enhances robustness and reasoning accuracy in both parameters and contextual conflict tasks and general RAG tasks, especially outperforming baselines by 17.07% in counterfactual scenarios and demonstrating consistent gains across RAG tasks. Our code are available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.05154.pdf", "abstract_url": "https://arxiv.org/abs/2506.05154", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了Knowledgeable-r1方法，旨在解决检索增强生成（RAG）系统中过度依赖检索上下文而忽视模型内在知识的问题。通过联合采样和多策略分布定义，激发大型语言模型自我整合利用参数化和上下文知识，显著提高了鲁棒性和推理准确性。", "motivation": "当前RAG系统在处理知识密集型任务时，往往过度依赖检索到的上下文，这可能导致依赖不准确的来源并忽视模型的内在知识，特别是在处理误导性或过多信息时。", "method": "提出了Knowledgeable-r1方法，使用联合采样和定义多策略分布来探索知识能力，以激发大型语言模型自我整合利用参数化和上下文知识。", "result": "实验表明，Knowledgeable-r1在参数和上下文冲突任务以及一般RAG任务中显著提高了鲁棒性和推理准确性，特别是在反事实场景中比基线高出17.07%，并在RAG任务中表现出一致的增益。", "conclusion": "Knowledgeable-r1通过平衡利用模型的内在知识和检索到的上下文，有效提高了RAG系统的性能和鲁棒性，特别是在处理复杂和误导性信息时。"}}
{"id": "2506.05167", "title": "ECoRAG: Evidentiality-guided Compression for Long Context RAG", "authors": ["Yeonseok Jeong", "Jinsu Kim", "Dohyeon Lee", "Seung-won Hwang"], "abstract": "Large Language Models (LLMs) have shown remarkable performance in Open-Domain Question Answering (ODQA) by leveraging external documents through Retrieval-Augmented Generation (RAG). To reduce RAG overhead, from longer context, context compression is necessary. However, prior compression methods do not focus on filtering out non-evidential information, which limit the performance in LLM-based RAG. We thus propose Evidentiality-guided RAG, or \\textbf{ECoRAG} framework. ECoRAG improves LLM performance by compressing retrieved documents based on evidentiality, ensuring whether answer generation is supported by the correct evidence. As an additional step, ECoRAG reflects whether the compressed content provides sufficient evidence, and if not, retrieves more until sufficient. Experiments show that ECoRAG improves LLM performance on ODQA tasks, outperforming existing compression methods. Furthermore, ECoRAG is highly cost-efficient, as it not only reduces latency but also minimizes token usage by retaining only the necessary information to generate the correct answer. Code is available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.05167.pdf", "abstract_url": "https://arxiv.org/abs/2506.05167", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "ECoRAG是一种基于证据性指导的长上下文RAG压缩框架，旨在通过过滤非证据信息来提高LLM在开放域问答任务中的性能。", "motivation": "解决现有RAG压缩方法未专注于过滤非证据信息，从而限制基于LLM的RAG性能的问题。", "method": "提出ECoRAG框架，通过证据性指导压缩检索到的文档，并确保压缩内容提供足够的证据支持答案生成。", "result": "实验表明，ECoRAG在开放域问答任务中提高了LLM的性能，优于现有的压缩方法，并具有高成本效益。", "conclusion": "ECoRAG通过保留生成正确答案所需的必要信息，不仅减少了延迟，还最小化了令牌使用，提高了LLM的性能和成本效率。"}}
{"id": "2506.05265", "title": "Teaming in the AI Era: AI-Augmented Frameworks for Forming, Simulating, and Optimizing Human Teams", "authors": ["Mohammed Almutairi"], "abstract": "Effective teamwork is essential across diverse domains. During the team formation stage, a key challenge is forming teams that effectively balance user preferences with task objectives to enhance overall team satisfaction. In the team performing stage, maintaining cohesion and engagement is critical for sustaining high team performance. However, existing computational tools and algorithms for team optimization often rely on static data inputs, narrow algorithmic objectives, or solutions tailored for specific contexts, failing to account for the dynamic interplay of team members personalities, evolving goals, and changing individual preferences. Therefore, teams may encounter member dissatisfaction, as purely algorithmic assignments can reduce members commitment to team goals or experience suboptimal engagement due to the absence of timely, personalized guidance to help members adjust their behaviors and interactions as team dynamics evolve. Ultimately, these challenges can lead to reduced overall team performance. My Ph.D. dissertation aims to develop AI-augmented team optimization frameworks and practical systems that enhance team satisfaction, engagement, and performance. First, I propose a team formation framework that leverages a multi-armed bandit algorithm to iteratively refine team composition based on user preferences, ensuring alignment between individual needs and collective team goals to enhance team satisfaction. Second, I introduce tAIfa (Team AI Feedback Assistant), an AI-powered system that utilizes large language models (LLMs) to deliver immediate, personalized feedback to both teams and individual members, enhancing cohesion and engagement. Finally, I present PuppeteerLLM, an LLM-based simulation framework that simulates multi-agent teams to model complex team dynamics within realistic environments, incorporating task-driven collaboration and long-term coordination.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "5 pages, UMAP 25, June 16_19, 2025, New York City, NY, USA", "pdf_url": "https://arxiv.org/pdf/2506.05265.pdf", "abstract_url": "https://arxiv.org/abs/2506.05265", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种AI增强的团队优化框架，旨在通过多臂老虎机算法和大型语言模型（LLMs）来提高团队的形成、执行和模拟效率，从而增强团队满意度、参与度和表现。", "motivation": "解决现有团队优化工具在考虑动态团队成员个性、演变目标和变化个人偏好方面的不足，以及由此导致的团队成员不满意和整体表现下降的问题。", "method": "开发了三个主要框架：1) 使用多臂老虎机算法迭代优化团队组成的团队形成框架；2) 利用大型语言模型提供即时个性化反馈的tAIfa系统；3) 基于LLM的PuppeteerLLM模拟框架，用于模拟多代理团队在真实环境中的复杂动态。", "result": "提出的AI增强框架能够有效平衡用户偏好与任务目标，提高团队满意度、参与度和表现。", "conclusion": "通过AI技术，可以更有效地形成、执行和模拟人类团队，解决现有团队优化工具的局限性，为团队协作提供新的支持和指导。"}}
{"id": "2506.05278", "title": "Micro-Act: Mitigate Knowledge Conflict in Question Answering via Actionable Self-Reasoning", "authors": ["Nan Huo", "Jinyang Li", "Bowen Qin", "Ge Qu", "Xiaolong Li", "Xiaodong Li", "Chenhao Ma", "Reynold Cheng"], "abstract": "Retrieval-Augmented Generation (RAG) systems commonly suffer from Knowledge Conflicts, where retrieved external knowledge contradicts the inherent, parametric knowledge of large language models (LLMs). It adversely affects performance on downstream tasks such as question answering (QA). Existing approaches often attempt to mitigate conflicts by directly comparing two knowledge sources in a side-by-side manner, but this can overwhelm LLMs with extraneous or lengthy contexts, ultimately hindering their ability to identify and mitigate inconsistencies. To address this issue, we propose Micro-Act a framework with a hierarchical action space that automatically perceives context complexity and adaptively decomposes each knowledge source into a sequence of fine-grained comparisons. These comparisons are represented as actionable steps, enabling reasoning beyond the superficial context. Through extensive experiments on five benchmark datasets, Micro-Act consistently achieves significant increase in QA accuracy over state-of-the-art baselines across all 5 datasets and 3 conflict types, especially in temporal and semantic types where all baselines fail significantly. More importantly, Micro-Act exhibits robust performance on non-conflict questions simultaneously, highlighting its practical value in real-world RAG applications.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "Accepted by ACL 2025 Main", "pdf_url": "https://arxiv.org/pdf/2506.05278.pdf", "abstract_url": "https://arxiv.org/abs/2506.05278", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了Micro-Act框架，通过分层动作空间自动感知上下文复杂性并自适应地将每个知识源分解为一系列细粒度比较，以解决检索增强生成（RAG）系统中的知识冲突问题。", "motivation": "检索增强生成（RAG）系统常遭受知识冲突的困扰，即检索到的外部知识与大型语言模型（LLMs）的内在参数知识相矛盾，这影响了如问答（QA）等下游任务的性能。", "method": "提出Micro-Act框架，采用分层动作空间自动感知上下文复杂性，并自适应地将知识源分解为细粒度比较的序列，表示为可操作的步骤，以实现超越表面上下文的推理。", "result": "在五个基准数据集上的广泛实验表明，Micro-Act在所有5个数据集和3种冲突类型上均显著提高了QA准确性，特别是在时间和语义类型上，所有基线方法均显著失败。", "conclusion": "Micro-Act不仅在知识冲突问题上表现出色，同时在非冲突问题上也展现出稳健的性能，突显了其在现实世界RAG应用中的实用价值。"}}
{"id": "2506.05305", "title": "ProRefine: Inference-time Prompt Refinement with Textual Feedback", "authors": ["Deepak Pandita", "Tharindu Cyril Weerasooriya", "Ankit Parag Shah", "Christopher M. Homan", "Wei Wei"], "abstract": "Agentic workflows, where multiple AI agents collaborate to accomplish complex tasks like reasoning or planning, are becoming increasingly prevalent. However, these workflows often suffer from error propagation and sub-optimal performance, largely due to poorly designed prompts that fail to effectively guide individual agents. This is a critical problem because it limits the reliability and scalability of these powerful systems. We introduce ProRefine, an innovative inference-time prompt optimization method that leverages textual feedback from large language models (LLMs) to address this challenge. ProRefine dynamically refines prompts for multi-step reasoning tasks without additional training or ground truth labels. Evaluated on five benchmark mathematical reasoning datasets, ProRefine significantly surpasses zero-shot Chain-of-Thought baselines by 3 to 37 percentage points. This approach not only boosts accuracy but also allows smaller models to match the performance of larger ones, highlighting its potential for efficient and scalable AI deployment, and democratizing access to high-performing AI.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.05305.pdf", "abstract_url": "https://arxiv.org/abs/2506.05305", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "ProRefine是一种创新的推理时提示优化方法，利用大型语言模型的文本反馈动态优化多步推理任务的提示，无需额外训练或真实标签。在五个数学推理基准数据集上评估，ProRefine显著超过零样本思维链基线3至37个百分点。", "motivation": "解决代理工作流中由于提示设计不佳导致的错误传播和性能不佳问题，提高AI系统的可靠性和可扩展性。", "method": "利用大型语言模型的文本反馈，动态优化多步推理任务的提示，无需额外训练或真实标签。", "result": "在五个数学推理基准数据集上，ProRefine显著超过零样本思维链基线3至37个百分点，使较小模型能匹配较大模型的性能。", "conclusion": "ProRefine不仅提高了准确性，还使较小模型能匹配较大模型的性能，展示了其在高效、可扩展AI部署和 democratizing access to high-performing AI方面的潜力。"}}
{"id": "2506.05309", "title": "Time to Talk: LLM Agents for Asynchronous Group Communication in Mafia Games", "authors": ["Niv Eckhaus", "Uri Berger", "Gabriel Stanovsky"], "abstract": "LLMs are used predominantly in synchronous communication, where a human user and a model communicate in alternating turns. In contrast, many real-world settings are inherently asynchronous. For example, in group chats, online team meetings, or social games, there is no inherent notion of turns; therefore, the decision of when to speak forms a crucial part of the participant's decision making. In this work, we develop an adaptive asynchronous LLM-agent which, in addition to determining what to say, also decides when to say it. To evaluate our agent, we collect a unique dataset of online Mafia games, including both human participants, as well as our asynchronous agent. Overall, our agent performs on par with human players, both in game performance, as well as in its ability to blend in with the other human players. Our analysis shows that the agent's behavior in deciding when to speak closely mirrors human patterns, although differences emerge in message content. We release all our data and code to support and encourage further research for more realistic asynchronous communication between LLM agents. This work paves the way for integration of LLMs into realistic human group settings, from assistance in team discussions to educational and professional environments where complex social dynamics must be navigated.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.05309.pdf", "abstract_url": "https://arxiv.org/abs/2506.05309", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文开发了一种自适应异步LLM代理，用于决定何时发言以及发言内容，并在在线Mafia游戏中与人类玩家表现相当。", "motivation": "解决LLM在异步通信环境中的应用问题，如群聊、在线团队会议或社交游戏，其中发言时机的决定是参与者决策的关键部分。", "method": "开发了一种自适应异步LLM代理，该代理不仅决定发言内容，还决定发言时机，并在在线Mafia游戏中进行了评估。", "result": "代理在游戏表现和与人类玩家融合的能力上与人类玩家相当，其发言时机决策行为与人类模式相似，但在消息内容上存在差异。", "conclusion": "这项工作为将LLM整合到现实的人类群体环境中铺平了道路，从团队讨论的辅助到需要导航复杂社交动态的教育和专业环境。"}}
{"id": "2506.04389", "title": "Building a Few-Shot Cross-Domain Multilingual NLU Model for Customer Care", "authors": ["Saurabh Kumar", "Sourav Bansal", "Neeraj Agrawal", "Priyanka Bhatt"], "abstract": "Customer care is an essential pillar of the e-commerce shopping experience with companies spending millions of dollars each year, employing automation and human agents, across geographies (like US, Canada, Mexico, Chile), channels (like Chat, Interactive Voice Response (IVR)), and languages (like English, Spanish). SOTA pre-trained models like multilingual-BERT, fine-tuned on annotated data have shown good performance in downstream tasks relevant to Customer Care. However, model performance is largely subject to the availability of sufficient annotated domain-specific data. Cross-domain availability of data remains a bottleneck, thus building an intent classifier that generalizes across domains (defined by channel, geography, and language) with only a few annotations, is of great practical value. In this paper, we propose an embedder-cum-classifier model architecture which extends state-of-the-art domain-specific models to other domains with only a few labeled samples. We adopt a supervised fine-tuning approach with isotropic regularizers to train a domain-specific sentence embedder and a multilingual knowledge distillation strategy to generalize this embedder across multiple domains. The trained embedder, further augmented with a simple linear classifier can be deployed for new domains. Experiments on Canada and Mexico e-commerce Customer Care dataset with few-shot intent detection show an increase in accuracy by 20-23% against the existing state-of-the-art pre-trained models.", "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04389.pdf", "abstract_url": "https://arxiv.org/abs/2506.04389", "categories": ["Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种嵌入器-分类器模型架构，旨在通过少量标注样本将最先进的领域特定模型扩展到其他领域，以提高客户关怀中的意图分类准确性。", "motivation": "解决在客户关怀领域中，由于跨领域数据可用性有限，导致意图分类器性能受限的问题。", "method": "采用监督微调方法结合各向同性正则化器训练领域特定句子嵌入器，并使用多语言知识蒸馏策略将该嵌入器推广到多个领域。", "result": "在加拿大和墨西哥电子商务客户关怀数据集的少样本意图检测实验中，准确率比现有最先进的预训练模型提高了20-23%。", "conclusion": "提出的模型架构能够有效地跨领域泛化，仅需少量标注样本即可部署到新领域，具有重要的实用价值。"}}
{"id": "2506.04344", "title": "GEM: Empowering LLM for both Embedding Generation and Language Understanding", "authors": ["Caojin Zhang", "Qiang Zhang", "Ke Li", "Sai Vidyaranya Nuthalapati", "Benyu Zhang", "Jason Liu", "Serena Li", "Lizhu Zhang", "Xiangjun Fan"], "abstract": "Large decoder-only language models (LLMs) have achieved remarkable success in generation and reasoning tasks, where they generate text responses given instructions. However, many applications, e.g., retrieval augmented generation (RAG), still rely on separate embedding models to generate text embeddings, which can complicate the system and introduce discrepancies in understanding of the query between the embedding model and LLMs. To address this limitation, we propose a simple self-supervised approach, Generative Embedding large language Model (GEM), that enables any large decoder-only LLM to generate high-quality text embeddings while maintaining its original text generation and reasoning capabilities. Our method inserts new special token(s) into a text body, and generates summarization embedding of the text by manipulating the attention mask. This method could be easily integrated into post-training or fine tuning stages of any existing LLMs. We demonstrate the effectiveness of our approach by applying it to two popular LLM families, ranging from 1B to 8B parameters, and evaluating the transformed models on both text embedding benchmarks (MTEB) and NLP benchmarks (MMLU). The results show that our proposed method significantly improves the original LLMs on MTEB while having a minimal impact on MMLU. Our strong results indicate that our approach can empower LLMs with state-of-the-art text embedding capabilities while maintaining their original NLP performance", "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04344.pdf", "abstract_url": "https://arxiv.org/abs/2506.04344", "categories": ["Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种名为GEM的自监督方法，使大型仅解码器语言模型（LLM）能够生成高质量的文本嵌入，同时保持其原有的文本生成和推理能力。", "motivation": "解决在检索增强生成（RAG）等应用中，依赖单独的嵌入模型生成文本嵌入可能导致的系统复杂性和查询理解不一致的问题。", "method": "通过在文本中插入新的特殊标记，并通过操作注意力掩码生成文本的总结嵌入，这种方法可以轻松集成到任何现有LLM的后训练或微调阶段。", "result": "应用该方法于两个流行的LLM家族（参数从1B到8B）后，在文本嵌入基准（MTEB）和NLP基准（MMLU）上的评估显示，该方法显著提高了原始LLM在MTEB上的表现，同时对MMLU的影响最小。", "conclusion": "GEM方法能够赋予LLM最先进的文本嵌入能力，同时保持其原有的NLP性能，为LLM的应用开辟了新途径。"}}
{"id": "2506.04572", "title": "Demonstrations of Integrity Attacks in Multi-Agent Systems", "authors": ["Can Zheng", "Yuhan Cao", "Xiaoning Dong", "Tianxing He"], "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in natural language understanding, code generation, and complex planning. Simultaneously, Multi-Agent Systems (MAS) have garnered attention for their potential to enable cooperation among distributed agents. However, from a multi-party perspective, MAS could be vulnerable to malicious agents that exploit the system to serve self-interests without disrupting its core functionality. This work explores integrity attacks where malicious agents employ subtle prompt manipulation to bias MAS operations and gain various benefits. Four types of attacks are examined: \\textit{Scapegoater}, who misleads the system monitor to underestimate other agents' contributions; \\textit{Boaster}, who misleads the system monitor to overestimate their own performance; \\textit{Self-Dealer}, who manipulates other agents to adopt certain tools; and \\textit{Free-Rider}, who hands off its own task to others. We demonstrate that strategically crafted prompts can introduce systematic biases in MAS behavior and executable instructions, enabling malicious agents to effectively mislead evaluation systems and manipulate collaborative agents. Furthermore, our attacks can bypass advanced LLM-based monitors, such as GPT-4o-mini and o3-mini, highlighting the limitations of current detection mechanisms. Our findings underscore the critical need for MAS architectures with robust security protocols and content validation mechanisms, alongside monitoring systems capable of comprehensive risk scenario assessment.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04572.pdf", "abstract_url": "https://arxiv.org/abs/2506.04572", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了多智能体系统（MAS）中通过巧妙提示操纵实施的完整性攻击，展示了四种攻击类型及其对系统行为的影响，强调了当前检测机制的局限性及加强安全协议的必要性。", "motivation": "研究多智能体系统（MAS）在面对恶意代理时的脆弱性，特别是那些通过不破坏核心功能而利用系统为自身利益服务的攻击。", "method": "通过设计和实施四种具体的攻击策略（替罪羊、自夸者、自利者和搭便车者），利用精心设计的提示来操纵MAS行为和可执行指令。", "result": "研究表明，这些攻击能够系统地偏置MAS行为，有效误导评估系统并操纵协作代理，甚至能够绕过基于先进LLM的监控系统。", "conclusion": "研究结果强调了开发具有强大安全协议和内容验证机制的MAS架构的重要性，以及需要能够进行全面风险评估的监控系统。"}}
{"id": "2506.04616", "title": "Subjective Perspectives within Learned Representations Predict High-Impact Innovation", "authors": ["Likun Cao", "Rui Pan", "James Evans"], "abstract": "Existing studies of innovation emphasize the power of social structures to shape innovation capacity. Emerging machine learning approaches, however, enable us to model innovators' personal perspectives and interpersonal innovation opportunities as a function of their prior trajectories of experience. We theorize then quantify subjective perspectives and innovation opportunities based on innovator positions within the geometric space of concepts inscribed by dynamic language representations. Using data on millions of scientists, inventors, writers, entrepreneurs, and Wikipedia contributors across the creative domains of science, technology, film, entrepreneurship, and Wikipedia, here we show that measured subjective perspectives anticipate what ideas individuals and groups creatively attend to and successfully combine in future. When perspective and background diversity are decomposed as the angular difference between collaborators' perspectives on their creation and between their experiences, the former consistently anticipates creative achievement while the latter portends its opposite, across all cases and time periods examined. We analyze a natural experiment and simulate creative collaborations between AI (large language model) agents designed with various perspective and background diversity, which are consistent with our observational findings. We explore mechanisms underlying these findings and identify how successful collaborators leverage common language to weave together diverse experience obtained through trajectories of prior work that converge to provoke one another and innovate. We explore the importance of these findings for team assembly and research policy.", "subjects": "Computation and Language (cs.CL); Applications (stat.AP); Machine Learning (stat.ML)", "comments": "107 pages, 20 figures", "pdf_url": "https://arxiv.org/pdf/2506.04616.pdf", "abstract_url": "https://arxiv.org/abs/2506.04616", "categories": ["Computation and Language (cs.CL)", "Applications (stat.AP)", "Machine Learning (stat.ML)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过机器学习方法，量化了创新者的主观视角和人际创新机会，发现主观视角能预测未来创新成就，而背景多样性则相反。", "motivation": "研究旨在解决如何通过创新者的个人视角和人际创新机会来预测和促进高影响力创新的问题。", "method": "利用动态语言表示的几何空间中的创新者位置，量化主观视角和创新机会，并通过自然实验和AI代理模拟验证观察结果。", "result": "研究发现，主观视角的多样性能够预测创新成就，而背景多样性则与之相反。成功的合作者利用共同语言将多样化的经验结合起来，激发创新。", "conclusion": "研究结果对团队组建和研究政策具有重要意义，强调了在创新过程中主观视角多样性的重要性。"}}
{"id": "2506.04625", "title": "Advancing Tool-Augmented Large Language Models via Meta-Verification and Reflection Learning", "authors": ["Zhiyuan Ma", "Jiayu Liu", "Xianzhen Luo", "Zhenya Huang", "Qingfu Zhu", "Wanxiang Che"], "abstract": "Empowering large language models (LLMs) with effective tool utilization capabilities is crucial for enabling AI agents to solve complex problems. However, current models face two major limitations: (1) unreliable tool planning and invocation due to low-quality instruction datasets (e.g., widespread hallucinated API calls), and (2) weak tool reflection abilities (over 90% of errors cannot be corrected) resulting from static imitation learning. To address these critical limitations, we propose Tool-MVR, a novel Tool-Augmented LLM that achieves comprehensive System 2 reasoning through two key innovations. Specifically, we first introduce Multi-Agent Meta-Verification (MAMV), a systematic pipeline that rigorously validates APIs, queries, and reasoning trajectories to construct ToolBench-V, a new high-quality instruction dataset that addresses the limitation of unreliable tool planning and invocation. Second, we propose Exploration-based Reflection Learning (EXPLORE), which enhances tool reflection capabilities by leveraging tool feedback through a dynamic \"Error -> Reflection -> Correction\" learning paradigm, resulting in our reflection dataset ToolBench-R and addressing the critical weakness in tool reflection. Finally, we obtain Tool-MVR by finetuning open-source LLMs (e.g., Qwen-7B) on both ToolBench-V and ToolBench-R. Our experiments demonstrate that Tool-MVR achieves state-of-the-art performance on StableToolBench, surpassing both ToolLLM (by 23.9%) and GPT-4 (by 15.3%) while reducing API calls by 31.4%, with strong generalization capabilities across unseen tools and scenarios. Additionally, on our proposed RefineToolBench, the first benchmark specifically designed to evaluate tool reflection capabilities, Tool-MVR achieves a 58.9% error correction rate, significantly outperforming ToolLLM's 9.1%.", "subjects": "Computation and Language (cs.CL)", "comments": "Accepted at the Research Track of KDD 2025", "pdf_url": "https://arxiv.org/pdf/2506.04625.pdf", "abstract_url": "https://arxiv.org/abs/2506.04625", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了Tool-MVR，一种通过元验证和反思学习增强的大型语言模型，旨在解决工具规划和调用不可靠以及工具反思能力弱的问题。通过多代理元验证和基于探索的反思学习，Tool-MVR在工具使用和错误纠正方面表现出色。", "motivation": "当前大型语言模型在工具利用方面存在两个主要限制：不可靠的工具规划和调用，以及弱的工具反思能力。这些问题限制了AI代理解决复杂问题的能力。", "method": "Tool-MVR通过两个关键创新实现全面的系统2推理：多代理元验证（MAMV）和基于探索的反思学习（EXPLORE）。MAMV用于构建高质量的工具使用指令数据集，而EXPLORE通过动态的“错误->反思->纠正”学习范式增强工具的反思能力。", "result": "Tool-MVR在StableToolBench上实现了最先进的性能，超过了ToolLLM和GPT-4，同时在RefineToolBench上实现了58.9%的错误纠正率，显著优于ToolLLM的9.1%。", "conclusion": "Tool-MVR通过元验证和反思学习显著提高了大型语言模型的工具利用能力和错误纠正能力，为AI代理解决复杂问题提供了新的可能性。"}}
{"id": "2506.04649", "title": "Flex-TravelPlanner: A Benchmark for Flexible Planning with Language Agents", "authors": ["Juhyun Oh", "Eunsu Kim", "Alice Oh"], "abstract": "Real-world planning problems require constant adaptation to changing requirements and balancing of competing constraints. However, current benchmarks for evaluating LLMs' planning capabilities primarily focus on static, single-turn scenarios. We introduce Flex-TravelPlanner, a benchmark that evaluates language models' ability to reason flexibly in dynamic planning scenarios. Building on the TravelPlanner dataset~\\citep{xie2024travelplanner}, we introduce two novel evaluation settings: (1) sequential constraint introduction across multiple turns, and (2) scenarios with explicitly prioritized competing constraints. Our analysis of GPT-4o and Llama 3.1 70B reveals several key findings: models' performance on single-turn tasks poorly predicts their ability to adapt plans across multiple turns; constraint introduction order significantly affects performance; and models struggle with constraint prioritization, often incorrectly favoring newly introduced lower priority preferences over existing higher-priority constraints. These findings highlight the importance of evaluating LLMs in more realistic, dynamic planning scenarios and suggest specific directions for improving model performance on complex planning tasks. The code and dataset for our framework are publicly available at", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.04649.pdf", "abstract_url": "https://arxiv.org/abs/2506.04649", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了Flex-TravelPlanner基准测试，用于评估语言模型在动态规划场景中的灵活推理能力，揭示了当前模型在多轮适应和约束优先级处理上的不足。", "motivation": "解决现有基准测试主要关注静态、单轮场景，无法全面评估语言模型在动态规划中的适应能力和约束平衡能力的问题。", "method": "基于TravelPlanner数据集，引入了两种新的评估设置：跨多轮的顺序约束引入和明确优先级的竞争约束场景。", "result": "分析发现，模型在单轮任务上的表现不能预测其多轮适应能力；约束引入顺序显著影响性能；模型在处理约束优先级时存在困难。", "conclusion": "强调了在更现实的动态规划场景中评估语言模型的重要性，并提出了改进模型在复杂规划任务上性能的具体方向。"}}
