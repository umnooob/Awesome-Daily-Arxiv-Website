{"id": "2507.12795", "title": "City-VLM: Towards Multidomain Perception Scene Understanding via Multimodal Incomplete Learning", "authors": ["Penglei Sun", "Yaoxian Song", "Xiangru Zhu", "Xiang Liu", "Qiang Wang", "Yue Liu", "Changqun Xia", "Tiefeng Li", "Yang Yang", "Xiaowen Chu"], "abstract": "Scene understanding enables intelligent agents to interpret and comprehend their environment. While existing large vision-language models (LVLMs) for scene understanding have primarily focused on indoor household tasks, they face two significant limitations when applied to outdoor large-scale scene understanding. First, outdoor scenarios typically encompass larger-scale environments observed through various sensors from multiple viewpoints (e.g., bird view and terrestrial view), while existing indoor LVLMs mainly analyze single visual modalities within building-scale contexts from humanoid viewpoints. Second, existing LVLMs suffer from missing multidomain perception outdoor data and struggle to effectively integrate 2D and 3D visual information. To address the aforementioned limitations, we build the first multidomain perception outdoor scene understanding dataset, named \\textbf{\\underline{SVM-City}}, deriving from multi\\textbf{\\underline{S}}cale scenarios with multi\\textbf{\\underline{V}}iew and multi\\textbf{\\underline{M}}odal instruction tuning data. It contains $420$k images and $4, 811$M point clouds with $567$k question-answering pairs from vehicles, low-altitude drones, high-altitude aerial planes, and satellite. To effectively fuse the multimodal data in the absence of one modality, we introduce incomplete multimodal learning to model outdoor scene understanding and design the LVLM named \\textbf{\\underline{City-VLM}}. Multimodal fusion is realized by constructing a joint probabilistic distribution space rather than implementing directly explicit fusion operations (e.g., concatenation). Experimental results on three typical outdoor scene understanding tasks show City-VLM achieves $18.14 \\%$ performance surpassing existing LVLMs in question-answering tasks averagely. Our method demonstrates pragmatic and generalization performance across multiple outdoor scenes.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.12795.pdf", "abstract_url": "https://arxiv.org/abs/2507.12795", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2507.12484", "title": "AI-Powered Math Tutoring: Platform for Personalized and Adaptive Education", "authors": ["Jarosław A. Chudziak", "Adam Kostka"], "abstract": "The growing ubiquity of artificial intelligence (AI), in particular large language models (LLMs), has profoundly altered the way in which learners gain knowledge and interact with learning material, with many claiming that AI positively influences their learning achievements. Despite this advancement, current AI tutoring systems face limitations associated with their reactive nature, often providing direct answers without encouraging deep reflection or incorporating structured pedagogical tools and strategies. This limitation is most apparent in the field of mathematics, in which AI tutoring systems remain underdeveloped. This research addresses the question: How can AI tutoring systems move beyond providing reactive assistance to enable structured, individualized, and tool-assisted learning experiences? We introduce a novel multi-agent AI tutoring platform that combines adaptive and personalized feedback, structured course generation, and textbook knowledge retrieval to enable modular, tool-assisted learning processes. This system allows students to learn new topics while identifying and targeting their weaknesses, revise for exams effectively, and practice on an unlimited number of personalized exercises. This article contributes to the field of artificial intelligence in education by introducing a novel platform that brings together pedagogical agents and AI-driven components, augmenting the field with modular and effective systems for teaching mathematics.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "8 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2507.12484.pdf", "abstract_url": "https://arxiv.org/abs/2507.12484", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"]}
{"id": "2507.12732", "title": "Strategy Adaptation in Large Language Model Werewolf Agents", "authors": ["Fuya Nakamori", "Yin Jou Huang", "Fei Cheng"], "abstract": "This study proposes a method to improve the performance of Werewolf agents by switching between predefined strategies based on the attitudes of other players and the context of conversations. While prior works of Werewolf agents using prompt engineering have employed methods where effective strategies are implicitly defined, they cannot adapt to changing situations. In this research, we propose a method that explicitly selects an appropriate strategy based on the game context and the estimated roles of other players. We compare the strategy adaptation Werewolf agents with baseline agents using implicit or fixed strategies and verify the effectiveness of our proposed method.", "subjects": "Computation and Language (cs.CL)", "comments": "7 pages, 2 figures", "pdf_url": "https://arxiv.org/pdf/2507.12732.pdf", "abstract_url": "https://arxiv.org/abs/2507.12732", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2507.12494", "title": "MR-LDM -- The Merge-Reactive Longitudinal Decision Model: Game Theoretic Human Decision Modeling for Interactive Sim Agents", "authors": ["Dustin Holley", "Jovin D'sa", "Hossein Nourkhiz Mahjoub", "Gibran Ali"], "abstract": "Enhancing simulation environments to replicate real-world driver behavior, i.e., more humanlike sim agents, is essential for developing autonomous vehicle technology. In the context of highway merging, previous works have studied the operational-level yielding dynamics of lag vehicles in response to a merging car at highway on-ramps. Other works focusing on tactical decision modeling generally consider limited action sets or utilize payoff functions with large parameter sets and limited payoff bounds. In this work, we aim to improve the simulation of the highway merge scenario by targeting a game theoretic model for tactical decision-making with improved payoff functions and lag actions. We couple this with an underlying dynamics model to have a unified decision and dynamics model that can capture merging interactions and simulate more realistic interactions in an explainable and interpretable fashion. The proposed model demonstrated good reproducibility of complex interactions when validated on a real-world dataset. The model was finally integrated into a high fidelity simulation environment and confirmed to have adequate computation time efficiency for use in large-scale simulations to support autonomous vehicle development.", "subjects": "Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT); Multiagent Systems (cs.MA); Robotics (cs.RO)", "comments": "8 pages", "pdf_url": "https://arxiv.org/pdf/2507.12494.pdf", "abstract_url": "https://arxiv.org/abs/2507.12494", "categories": ["Artificial Intelligence (cs.AI)", "Computer Science and Game Theory (cs.GT)", "Multiagent Systems (cs.MA)", "Robotics (cs.RO)"], "matching_keywords": ["agent"]}
{"id": "2507.12599", "title": "A Survey of Explainable Reinforcement Learning: Targets, Methods and Needs", "authors": ["Léo Saulières"], "abstract": "The success of recent Artificial Intelligence (AI) models has been accompanied by the opacity of their internal mechanisms, due notably to the use of deep neural networks. In order to understand these internal mechanisms and explain the output of these AI models, a set of methods have been proposed, grouped under the domain of eXplainable AI (XAI). This paper focuses on a sub-domain of XAI, called eXplainable Reinforcement Learning (XRL), which aims to explain the actions of an agent that has learned by reinforcement learning. We propose an intuitive taxonomy based on two questions \"What\" and \"How\". The first question focuses on the target that the method explains, while the second relates to the way the explanation is provided. We use this taxonomy to provide a state-of-the-art review of over 250 papers. In addition, we present a set of domains close to XRL, which we believe should get attention from the community. Finally, we identify some needs for the field of XRL.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "69 pages, 19 figures", "pdf_url": "https://arxiv.org/pdf/2507.12599.pdf", "abstract_url": "https://arxiv.org/abs/2507.12599", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"]}
{"id": "2507.12666", "title": "Fly, Fail, Fix: Iterative Game Repair with Reinforcement Learning and Large Multimodal Models", "authors": ["Alex Zook", "Josef Spjut", "Jonathan Tremblay"], "abstract": "Game design hinges on understanding how static rules and content translate into dynamic player behavior - something modern generative systems that inspect only a game's code or assets struggle to capture. We present an automated design iteration framework that closes this gap by pairing a reinforcement learning (RL) agent, which playtests the game, with a large multimodal model (LMM), which revises the game based on what the agent does. In each loop the RL player completes several episodes, producing (i) numerical play metrics and/or (ii) a compact image strip summarising recent video frames. The LMM designer receives a gameplay goal and the current game configuration, analyses the play traces, and edits the configuration to steer future behaviour toward the goal. We demonstrate results that LMMs can reason over behavioral traces supplied by RL agents to iteratively refine game mechanics, pointing toward practical, scalable tools for AI-assisted game design.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2507.12666.pdf", "abstract_url": "https://arxiv.org/abs/2507.12666", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"]}
{"id": "2507.12801", "title": "Imitating Mistakes in a Learning Companion AI Agent for Online Peer Learning", "authors": ["Sosui Moribe", "Taketoshi Ushiama"], "abstract": "In recent years, peer learning has gained attention as a method that promotes spontaneous thinking among learners, and its effectiveness has been confirmed by numerous studies. This study aims to develop an AI Agent as a learning companion that enables peer learning anytime and anywhere. However, peer learning between humans has various limitations, and it is not always effective. Effective peer learning requires companions at the same proficiency levels. In this study, we assume that a learner's peers with the same proficiency level as the learner make the same mistakes as the learner does and focus on English composition as a specific example to validate this approach.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": ")", "pdf_url": "https://arxiv.org/pdf/2507.12801.pdf", "abstract_url": "https://arxiv.org/abs/2507.12801", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"]}
{"id": "2507.12806", "title": "MCPEval: Automatic MCP-based Deep Evaluation for AI Agent Models", "authors": ["Zhiwei Liu", "Jielin Qiu", "Shiyu Wang", "Jianguo Zhang", "Zuxin Liu", "Roshan Ram", "Haolin Chen", "Weiran Yao", "Huan Wang", "Shelby Heinecke", "Silvio Savarese", "Caiming Xiong"], "abstract": "The rapid rise of Large Language Models (LLMs)-based intelligent agents underscores the need for robust, scalable evaluation frameworks. Existing methods rely on static benchmarks and labor-intensive data collection, limiting practical assessment. We introduce \\oursystemname, an open-source Model Context Protocol (MCP)-based framework that automates end-to-end task generation and deep evaluation of LLM agents across diverse domains. MCPEval standardizes metrics, seamlessly integrates with native agent tools, and eliminates manual effort in building evaluation pipelines. Empirical results across five real-world domains show its effectiveness in revealing nuanced, domain-specific performance. We publicly release MCPEval", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2507.12806.pdf", "abstract_url": "https://arxiv.org/abs/2507.12806", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2507.12821", "title": "Assessing adaptive world models in machines with novel games", "authors": ["Lance Ying", "Katherine M. Collins", "Prafull Sharma", "Cedric Colas", "Kaiya Ivy Zhao", "Adrian Weller", "Zenna Tavares", "Phillip Isola", "Samuel J. Gershman", "Jacob D. Andreas", "Thomas L. Griffiths", "Francois Chollet", "Kelsey R. Allen", "Joshua B. Tenenbaum"], "abstract": "Human intelligence exhibits a remarkable capacity for rapid adaptation and effective problem-solving in novel and unfamiliar contexts. We argue that this profound adaptability is fundamentally linked to the efficient construction and refinement of internal representations of the environment, commonly referred to as world models, and we refer to this adaptation mechanism as world model induction. However, current understanding and evaluation of world models in artificial intelligence (AI) remains narrow, often focusing on static representations learned from training on a massive corpora of data, instead of the efficiency and efficacy of models in learning these representations through interaction and exploration within a novel environment. In this Perspective, we provide a view of world model induction drawing on decades of research in cognitive science on how humans learn and adapt so efficiently; we then call for a new evaluation framework for assessing adaptive world models in AI. Concretely, we propose a new benchmarking paradigm based on suites of carefully designed games with genuine, deep and continually refreshing novelty in the underlying game structures -- we refer to this kind of games as novel games. We detail key desiderata for constructing these games and propose appropriate metrics to explicitly challenge and evaluate the agent's ability for rapid world model induction. We hope that this new evaluation framework will inspire future evaluation efforts on world models in AI and provide a crucial step towards developing AI systems capable of the human-like rapid adaptation and robust generalization -- a critical component of artificial general intelligence.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "17 pages, 4 figures", "pdf_url": "https://arxiv.org/pdf/2507.12821.pdf", "abstract_url": "https://arxiv.org/abs/2507.12821", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"]}
{"id": "2507.12862", "title": "Information-Theoretic Aggregation of Ethical Attributes in Simulated-Command", "authors": ["Hussein Abbass", "Taylan Akay", "Harrison Tolley"], "abstract": "In the age of AI, human commanders need to use the computational powers available in today's environment to simulate a very large number of scenarios. Within each scenario, situations occur where different decision design options could have ethical consequences. Making these decisions reliant on human judgement is both counter-productive to the aim of exploring very large number of scenarios in a timely manner and infeasible when considering the workload needed to involve humans in each of these choices. In this paper, we move human judgement outside the simulation decision cycle. Basically, the human will design the ethical metric space, leaving it to the simulated environment to explore the space. When the simulation completes its testing cycles, the testing environment will come back to the human commander with a few options to select from. The human commander will then exercise human-judgement to select the most appropriate course of action, which will then get executed accordingly. We assume that the problem of designing metrics that are sufficiently granular to assess the ethical implications of decisions is solved. Subsequently, the fundamental problem we look at in this paper is how to weight ethical decisions during the running of these simulations; that is, how to dynamically weight the ethical attributes when agents are faced with decision options with ethical implications during generative simulations. The multi-criteria decision making literature has started to look at nearby problems, where the concept of entropy has been used to determine the weights during aggregation. We draw from that literature different approaches to automatically calculate the weights for ethical attributes during simulation-based testing and evaluation.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.12862.pdf", "abstract_url": "https://arxiv.org/abs/2507.12862", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2507.13190", "title": "GEMMAS: Graph-based Evaluation Metrics for Multi Agent Systems", "authors": ["Jisoo Lee", "Raeyoung Chang", "Dongwook Kwon", "Harmanpreet Singh", "Nikhil Verma"], "abstract": "Multi-agent systems built on language models have shown strong performance on collaborative reasoning tasks. However, existing evaluations focus only on the correctness of the final output, overlooking how inefficient communication and poor coordination contribute to redundant reasoning and higher computational costs. We introduce GEMMAS, a graph-based evaluation framework that analyzes the internal collaboration process by modeling agent interactions as a directed acyclic graph. To capture collaboration quality, we propose two process-level metrics: Information Diversity Score (IDS) to measure semantic variation in inter-agent messages, and Unnecessary Path Ratio (UPR) to quantify redundant reasoning paths. We evaluate GEMMAS across five benchmarks and highlight results on GSM8K, where systems with only a 2.1% difference in accuracy differ by 12.8% in IDS and 80% in UPR, revealing substantial variation in internal collaboration. These findings demonstrate that outcome-only metrics are insufficient for evaluating multi-agent performance and highlight the importance of process-level diagnostics in designing more interpretable and resource-efficient collaborative AI systems.", "subjects": "Computation and Language (cs.CL)", "comments": "4 figures, 1 algorithm, 2 tables, 6 pages, under review at EMNLP Industry track 2025", "pdf_url": "https://arxiv.org/pdf/2507.13190.pdf", "abstract_url": "https://arxiv.org/abs/2507.13190", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2507.13285", "title": "Multi-Agent Synergy-Driven Iterative Visual Narrative Synthesis", "authors": ["Wang Xi", "Quan Shi", "Tian Yu", "Yujie Peng", "Jiayi Sun", "Mengxing Ren", "Zenghui Ding", "Ningguang Yao"], "abstract": "Automated generation of high-quality media presentations is challenging, requiring robust content extraction, narrative planning, visual design, and overall quality optimization. Existing methods often produce presentations with logical inconsistencies and suboptimal layouts, thereby struggling to meet professional standards. To address these challenges, we introduce RCPS (Reflective Coherent Presentation Synthesis), a novel framework integrating three key components: (1) Deep Structured Narrative Planning; (2) Adaptive Layout Generation; (3) an Iterative Optimization Loop. Additionally, we propose PREVAL, a preference-based evaluation framework employing rationale-enhanced multi-dimensional models to assess presentation quality across Content, Coherence, and Design. Experimental results demonstrate that RCPS significantly outperforms baseline methods across all quality dimensions, producing presentations that closely approximate human expert standards. PREVAL shows strong correlation with human judgments, validating it as a reliable automated tool for assessing presentation quality.", "subjects": "Computation and Language (cs.CL)", "comments": "22 pages, 7 figures, 3 tables. Submitted to an ACL-style conference", "pdf_url": "https://arxiv.org/pdf/2507.13285.pdf", "abstract_url": "https://arxiv.org/abs/2507.13285", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2507.13175", "title": "Black Box Deployed -- Functional Criteria for Artificial Moral Agents in the LLM Era", "authors": ["Matthew E. Brophy"], "abstract": "The advancement of powerful yet opaque large language models (LLMs) necessitates a fundamental revision of the philosophical criteria used to evaluate artificial moral agents (AMAs). Pre-LLM frameworks often relied on the assumption of transparent architectures, which LLMs defy due to their stochastic outputs and opaque internal states. This paper argues that traditional ethical criteria are pragmatically obsolete for LLMs due to this mismatch. Engaging with core themes in the philosophy of technology, this paper proffers a revised set of ten functional criteria to evaluate LLM-based artificial moral agents: moral concordance, context sensitivity, normative integrity, metaethical awareness, system resilience, trustworthiness, corrigibility, partial transparency, functional autonomy, and moral imagination. These guideposts, applied to what we term \"SMA-LLS\" (Simulating Moral Agency through Large Language Systems), aim to steer AMAs toward greater alignment and beneficial societal integration in the coming years. We illustrate these criteria using hypothetical scenarios involving an autonomous public bus (APB) to demonstrate their practical applicability in morally salient contexts.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "42 pages. Supplementary material included at end of article", "pdf_url": "https://arxiv.org/pdf/2507.13175.pdf", "abstract_url": "https://arxiv.org/abs/2507.13175", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2507.12475", "title": "Coarse Addition and the St. Petersburg Paradox: A Heuristic Perspective", "authors": ["Takashi Izumo"], "abstract": "The St. Petersburg paradox presents a longstanding challenge in decision theory. It describes a game whose expected value is infinite, yet for which no rational finite stake can be determined. Traditional solutions introduce auxiliary assumptions, such as diminishing marginal utility, temporal discounting, or extended number systems. These methods often involve mathematical refinements that may not correspond to how people actually perceive or process numerical information. This paper explores an alternative approach based on a modified operation of addition defined over coarse partitions of the outcome space. In this model, exact numerical values are grouped into perceptual categories, and each value is replaced by a representative element of its group before being added. This method allows for a phenomenon where repeated additions eventually cease to affect the outcome, a behavior described as inertial stabilization. Although this is not intended as a definitive resolution of the paradox, the proposed framework offers a plausible way to represent how agents with limited cognitive precision might handle divergent reward structures. We demonstrate that the St. Petersburg series can become inert under this coarse addition for a suitably constructed partition. The approach may also have broader applications in behavioral modeling and the study of machine reasoning under perceptual limitations.", "subjects": "Theoretical Economics (econ.TH); Artificial Intelligence (cs.AI); Optimization and Control (math.OC)", "comments": "16 pages, no figure", "pdf_url": "https://arxiv.org/pdf/2507.12475.pdf", "abstract_url": "https://arxiv.org/abs/2507.12475", "categories": ["Theoretical Economics (econ.TH)", "Artificial Intelligence (cs.AI)", "Optimization and Control (math.OC)"], "matching_keywords": ["agent"]}
{"id": "2507.12486", "title": "On multiagent online problems with predictions", "authors": ["Gabriel Istrate", "Cosmin Bonchis", "Victor Bogdan"], "abstract": "We study the power of (competitive) algorithms with predictions in a multiagent setting. We introduce a two predictor framework, that assumes that agents use one predictor for their future (self) behavior, and one for the behavior of the other players. The main problem we are concerned with is understanding what are the best competitive ratios that can be achieved by employing such predictors, under various assumptions on predictor quality.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2507.12486.pdf", "abstract_url": "https://arxiv.org/abs/2507.12486", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Computer Science and Game Theory (cs.GT)"], "matching_keywords": ["agent"]}
{"id": "2507.12496", "title": "FOUNDER: Grounding Foundation Models in World Models for Open-Ended Embodied Decision Making", "authors": ["Yucen Wang", "Rui Yu", "Shenghua Wan", "Le Gan", "De-Chuan Zhan"], "abstract": "Foundation Models (FMs) and World Models (WMs) offer complementary strengths in task generalization at different levels. In this work, we propose FOUNDER, a framework that integrates the generalizable knowledge embedded in FMs with the dynamic modeling capabilities of WMs to enable open-ended task solving in embodied environments in a reward-free manner. We learn a mapping function that grounds FM representations in the WM state space, effectively inferring the agent's physical states in the world simulator from external observations. This mapping enables the learning of a goal-conditioned policy through imagination during behavior learning, with the mapped task serving as the goal state. Our method leverages the predicted temporal distance to the goal state as an informative reward signal. FOUNDER demonstrates superior performance on various multi-task offline visual control benchmarks, excelling in capturing the deep-level semantics of tasks specified by text or videos, particularly in scenarios involving complex observations or domain gaps where prior methods struggle. The consistency of our learned reward function with the ground-truth reward is also empirically validated. Our project website is", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "Accepted by Forty-Second International Conference on Machine Learning (ICML 2025)", "pdf_url": "https://arxiv.org/pdf/2507.12496.pdf", "abstract_url": "https://arxiv.org/abs/2507.12496", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"]}
{"id": "2507.13152", "title": "SE-VLN: A Self-Evolving Vision-Language Navigation Framework Based on Multimodal Large Language Models", "authors": ["Xiangyu Dong", "Haoran Zhao", "Jiang Gao", "Haozhou Li", "Xiaoguang Ma", "Yaoming Zhou", "Fuhai Chen", "Juan Liu"], "abstract": "Recent advances in vision-language navigation (VLN) were mainly attributed to emerging large language models (LLMs). These methods exhibited excellent generalization capabilities in instruction understanding and task reasoning. However, they were constrained by the fixed knowledge bases and reasoning abilities of LLMs, preventing fully incorporating experiential knowledge and thus resulting in a lack of efficient evolutionary capacity. To address this, we drew inspiration from the evolution capabilities of natural agents, and proposed a self-evolving VLN framework (SE-VLN) to endow VLN agents with the ability to continuously evolve during testing. To the best of our knowledge, it was the first time that an multimodal LLM-powered self-evolving VLN framework was proposed. Specifically, SE-VLN comprised three core modules, i.e., a hierarchical memory module to transfer successful and failure cases into reusable knowledge, a retrieval-augmented thought-based reasoning module to retrieve experience and enable multi-step decision-making, and a reflection module to realize continual evolution. Comprehensive tests illustrated that the SE-VLN achieved navigation success rates of 57% and 35.2% in unseen environments, representing absolute performance improvements of 23.9% and 15.0% over current state-of-the-art methods on R2R and REVERSE datasets, respectively. Moreover, the SE-VLN showed performance improvement with increasing experience repository, elucidating its great potential as a self-evolving agent framework for VLN.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.13152.pdf", "abstract_url": "https://arxiv.org/abs/2507.13152", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"]}
{"id": "2507.13334", "title": "A Survey of Context Engineering for Large Language Models", "authors": ["Lingrui Mei", "Jiayu Yao", "Yuyao Ge", "Yiwei Wang", "Baolong Bi", "Yujun Cai", "Jiazhi Liu", "Mingyu Li", "Zhong-Zhi Li", "Duzhen Zhang", "Chenlin Zhou", "Jiayi Mao", "Tianze Xia", "Jiafeng Guo", "Shenghua Liu"], "abstract": "The performance of Large Language Models (LLMs) is fundamentally determined by the contextual information provided during inference. This survey introduces Context Engineering, a formal discipline that transcends simple prompt design to encompass the systematic optimization of information payloads for LLMs. We present a comprehensive taxonomy decomposing Context Engineering into its foundational components and the sophisticated implementations that integrate them into intelligent systems. We first examine the foundational components: context retrieval and generation, context processing and context management. We then explore how these components are architecturally integrated to create sophisticated system implementations: retrieval-augmented generation (RAG), memory systems and tool-integrated reasoning, and multi-agent systems. Through this systematic analysis of over 1300 research papers, our survey not only establishes a technical roadmap for the field but also reveals a critical research gap: a fundamental asymmetry exists between model capabilities. While current models, augmented by advanced context engineering, demonstrate remarkable proficiency in understanding complex contexts, they exhibit pronounced limitations in generating equally sophisticated, long-form outputs. Addressing this gap is a defining priority for future research. Ultimately, this survey provides a unified framework for both researchers and engineers advancing context-aware AI.", "subjects": "Computation and Language (cs.CL)", "comments": "ongoing work; 165 pages, 1401 citations", "pdf_url": "https://arxiv.org/pdf/2507.13334.pdf", "abstract_url": "https://arxiv.org/abs/2507.13334", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "@RAG"]}
{"id": "2507.12774", "title": "A Comprehensive Survey of Electronic Health Record Modeling: From Deep Learning Approaches to Large Language Models", "authors": ["Weijieying Ren", "Jingxi Zhu", "Zehao Liu", "Tianxiang Zhao", "Vasant Honavar"], "abstract": "Artificial intelligence (AI) has demonstrated significant potential in transforming healthcare through the analysis and modeling of electronic health records (EHRs). However, the inherent heterogeneity, temporal irregularity, and domain-specific nature of EHR data present unique challenges that differ fundamentally from those in vision and natural language tasks. This survey offers a comprehensive overview of recent advancements at the intersection of deep learning, large language models (LLMs), and EHR modeling. We introduce a unified taxonomy that spans five key design dimensions: data-centric approaches, neural architecture design, learning-focused strategies, multimodal learning, and LLM-based modeling systems. Within each dimension, we review representative methods addressing data quality enhancement, structural and temporal representation, self-supervised learning, and integration with clinical knowledge. We further highlight emerging trends such as foundation models, LLM-driven clinical agents, and EHR-to-text translation for downstream reasoning. Finally, we discuss open challenges in benchmarking, explainability, clinical alignment, and generalization across diverse clinical settings. This survey aims to provide a structured roadmap for advancing AI-driven EHR modeling and clinical decision support. For a comprehensive list of EHR-related methods, kindly refer to", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.12774.pdf", "abstract_url": "https://arxiv.org/abs/2507.12774", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2507.12624", "title": "Pathology-Guided Virtual Staining Metric for Evaluation and Training", "authors": ["Qiankai Wang", "James E.D. Tweel", "Parsin Haji Reza", "Anita Layton"], "abstract": "Virtual staining has emerged as a powerful alternative to traditional histopathological staining techniques, enabling rapid, reagent-free image transformations. However, existing evaluation methods predominantly rely on full-reference image quality assessment (FR-IQA) metrics such as structural similarity, which are originally designed for natural images and often fail to capture pathology-relevant features. Expert pathology reviews have also been used, but they are inherently subjective and time-consuming.", "subjects": "Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV); Systems and Control (eess.SY)", "comments": "19 pages, 10 figures. Intended for submission to the Journal of Imaging Informatics in Medicine (JIIM)", "pdf_url": "https://arxiv.org/pdf/2507.12624.pdf", "abstract_url": "https://arxiv.org/abs/2507.12624", "categories": ["Image and Video Processing (eess.IV)", "Computer Vision and Pattern Recognition (cs.CV)", "Systems and Control (eess.SY)"], "matching_keywords": ["agent"]}
{"id": "2507.12767", "title": "Autonomy for Older Adult-Agent Interaction", "authors": ["Jiaxin An"], "abstract": "As the global population ages, artificial intelligence (AI)-powered agents have emerged as potential tools to support older adults' caregiving. Prior research has explored agent autonomy by identifying key interaction stages in task processes and defining the agent's role at each stage. However, ensuring that agents align with older adults' autonomy preferences remains a critical challenge. Drawing on interdisciplinary conceptualizations of autonomy, this paper examines four key dimensions of autonomy for older adults: decision-making autonomy, goal-oriented autonomy, control autonomy, and social responsibility autonomy. This paper then proposes the following research directions: (1) Addressing social responsibility autonomy, which concerns the ethical and social implications of agent use in communal settings; (2) Operationalizing agent autonomy from the task perspective; and (3) Developing autonomy measures.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": "7 pages", "pdf_url": "https://arxiv.org/pdf/2507.12767.pdf", "abstract_url": "https://arxiv.org/abs/2507.12767", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2507.12846", "title": "Enter the Mind Palace: Reasoning and Planning for Long-term Active Embodied Question Answering", "authors": ["Muhammad Fadhil Ginting", "Dong-Ki Kim", "Xiangyun Meng", "Andrzej Reinke", "Bandi Jai Krishna", "Navid Kayhani", "Oriana Peltzer", "David D. Fan", "Amirreza Shaban", "Sung-Kyun Kim", "Mykel J. Kochenderfer", "Ali-akbar Agha-mohammadi", "Shayegan Omidshafiei"], "abstract": "As robots become increasingly capable of operating over extended periods -- spanning days, weeks, and even months -- they are expected to accumulate knowledge of their environments and leverage this experience to assist humans more effectively. This paper studies the problem of Long-term Active Embodied Question Answering (LA-EQA), a new task in which a robot must both recall past experiences and actively explore its environment to answer complex, temporally-grounded questions. Unlike traditional EQA settings, which typically focus either on understanding the present environment alone or on recalling a single past observation, LA-EQA challenges an agent to reason over past, present, and possible future states, deciding when to explore, when to consult its memory, and when to stop gathering observations and provide a final answer. Standard EQA approaches based on large models struggle in this setting due to limited context windows, absence of persistent memory, and an inability to combine memory recall with active exploration. To address this, we propose a structured memory system for robots, inspired by the mind palace method from cognitive science. Our method encodes episodic experiences as scene-graph-based world instances, forming a reasoning and planning algorithm that enables targeted memory retrieval and guided navigation. To balance the exploration-recall trade-off, we introduce value-of-information-based stopping criteria that determines when the agent has gathered sufficient information. We evaluate our method on real-world experiments and introduce a new benchmark that spans popular simulation environments and actual industrial sites. Our approach significantly outperforms state-of-the-art baselines, yielding substantial gains in both answer accuracy and exploration efficiency.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.12846.pdf", "abstract_url": "https://arxiv.org/abs/2507.12846", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2507.13169", "title": "Prompt Injection 2.0: Hybrid AI Threats", "authors": ["Jeremy McHugh", "Kristina Šekrst", "Jon Cefalu"], "abstract": "Prompt injection attacks, where malicious input is designed to manipulate AI systems into ignoring their original instructions and following unauthorized commands instead, were first discovered by Preamble, Inc. in May 2022 and responsibly disclosed to OpenAI. Over the last three years, these attacks have continued to pose a critical security threat to LLM-integrated systems. The emergence of agentic AI systems, where LLMs autonomously perform multistep tasks through tools and coordination with other agents, has fundamentally transformed the threat landscape. Modern prompt injection attacks can now combine with traditional cybersecurity exploits to create hybrid threats that systematically evade traditional security controls. This paper presents a comprehensive analysis of Prompt Injection 2.0, examining how prompt injections integrate with Cross-Site Scripting (XSS), Cross-Site Request Forgery (CSRF), and other web security vulnerabilities to bypass traditional security measures. We build upon Preamble's foundational research and mitigation technologies, evaluating them against contemporary threats, including AI worms, multi-agent infections, and hybrid cyber-AI attacks. Our analysis incorporates recent benchmarks that demonstrate how traditional web application firewalls, XSS filters, and CSRF tokens fail against AI-enhanced attacks. We also present architectural solutions that combine prompt isolation, runtime security, and privilege separation with novel threat detection capabilities.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.13169.pdf", "abstract_url": "https://arxiv.org/abs/2507.13169", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"]}
{"id": "2507.13171", "title": "Aligning Humans and Robots via Reinforcement Learning from Implicit Human Feedback", "authors": ["Suzie Kim", "Hye-Bin Shin", "Seong-Whan Lee"], "abstract": "Conventional reinforcement learning (RL) ap proaches often struggle to learn effective policies under sparse reward conditions, necessitating the manual design of complex, task-specific reward functions. To address this limitation, rein forcement learning from human feedback (RLHF) has emerged as a promising strategy that complements hand-crafted rewards with human-derived evaluation signals. However, most existing RLHF methods depend on explicit feedback mechanisms such as button presses or preference labels, which disrupt the natural interaction process and impose a substantial cognitive load on the user. We propose a novel reinforcement learning from implicit human feedback (RLIHF) framework that utilizes non-invasive electroencephalography (EEG) signals, specifically error-related potentials (ErrPs), to provide continuous, implicit feedback without requiring explicit user intervention. The proposed method adopts a pre-trained decoder to transform raw EEG signals into probabilistic reward components, en abling effective policy learning even in the presence of sparse external rewards. We evaluate our approach in a simulation environment built on the MuJoCo physics engine, using a Kinova Gen2 robotic arm to perform a complex pick-and-place task that requires avoiding obstacles while manipulating target objects. The results show that agents trained with decoded EEG feedback achieve performance comparable to those trained with dense, manually designed rewards. These findings validate the potential of using implicit neural feedback for scalable and human-aligned reinforcement learning in interactive robotics.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.13171.pdf", "abstract_url": "https://arxiv.org/abs/2507.13171", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
