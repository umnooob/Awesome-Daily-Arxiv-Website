{"id": "2506.10055", "title": "TaskCraft: Automated Generation of Agentic Tasks", "authors": ["Dingfeng Shi", "Jingyi Cao", "Qianben Chen", "Weichen Sun", "Weizhen Li", "Hongxuan Lu", "Fangchen Dong", "Tianrui Qin", "King Zhu", "Minghao Yang", "Jian Yang", "Ge Zhang", "Jiaheng Liu", "Changwang Zhang", "Jun Wang", "Yuchen Eleanor Jiang", "Wangchunshu Zhou"], "abstract": "Agentic tasks, which require multi-step problem solving with autonomy, tool use, and adaptive reasoning, are becoming increasingly central to the advancement of NLP and AI. However, existing instruction data lacks tool interaction, and current agentic benchmarks rely on costly human annotation, limiting their scalability. We introduce \\textsc{TaskCraft}, an automated workflow for generating difficulty-scalable, multi-tool, and verifiable agentic tasks with execution trajectories. TaskCraft expands atomic tasks using depth-based and width-based extensions to create structurally and hierarchically complex challenges. Empirical results show that these tasks improve prompt optimization in the generation workflow and enhance supervised fine-tuning of agentic foundation models. We present a large-scale synthetic dataset of approximately 36,000 tasks with varying difficulty to support future research on agent tuning and evaluation.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.10055.pdf", "abstract_url": "https://arxiv.org/abs/2506.10055", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "TaskCraft是一个自动化工作流，用于生成难度可扩展、多工具且可验证的代理任务及其执行轨迹，旨在解决现有指令数据缺乏工具交互和代理基准依赖昂贵人工标注的问题。", "motivation": "解决现有指令数据缺乏工具交互和代理基准依赖昂贵人工标注的问题，以支持NLP和AI领域的发展。", "method": "通过深度和广度扩展原子任务，创建结构和层次复杂的挑战，自动化生成代理任务。", "result": "生成了约36,000个不同难度的任务的大规模合成数据集，这些任务改善了生成工作流中的提示优化，并增强了代理基础模型的监督微调。", "conclusion": "TaskCraft为代理调优和评估的未来研究提供了支持，展示了自动化生成代理任务在提升模型性能方面的潜力。"}}
{"id": "2506.10077", "title": "A quantum semantic framework for natural language processing", "authors": ["Christopher J. Agostino", "Quan Le Thien", "Molly Apsel", "Denizhan Pak", "Elina Lesyk", "Ashabari Majumdar"], "abstract": "Semantic degeneracy represents a fundamental property of natural language that extends beyond simple polysemy to encompass the combinatorial explosion of potential interpretations that emerges as semantic expressions increase in complexity. Large Language Models (LLMs) and other modern NLP systems face inherent limitations precisely because they operate within natural language itself, making them subject to the same interpretive constraints imposed by semantic degeneracy. In this work, we argue using Kolmogorov complexity that as an expression's complexity grows, the likelihood of any interpreting agent (human or LLM-powered AI) recovering the single intended meaning vanishes. This computational intractability suggests the classical view that linguistic forms possess meaning in and of themselves is flawed. We alternatively posit that meaning is instead actualized through an observer-dependent interpretive act. To test this, we conducted a semantic Bell inequality test using diverse LLM agents as ``computational cognitive systems'' to interpret ambiguous word pairs under varied contextual settings. Across several independent experiments, we found average CHSH expectation values ranging from 1.2 to 2.8, with several runs yielding values (e.g., 2.3-2.4) that significantly violate the classical boundary ($|S|\\leq2$). This demonstrates that linguistic interpretation under ambiguity can exhibit non-classical contextuality, consistent with results from human cognition experiments. These results inherently imply that classical frequentist-based analytical approaches for natural language are necessarily lossy. Instead, we propose that Bayesian-style repeated sampling approaches can provide more practically useful and appropriate characterizations of linguistic meaning in context.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Information Theory (cs.IT)", "comments": "12 pages, 2 figures, accepted submission to Quantum AI and NLP 2025", "pdf_url": "https://arxiv.org/pdf/2506.10077.pdf", "abstract_url": "https://arxiv.org/abs/2506.10077", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)", "Information Theory (cs.IT)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种量子语义框架，用于解决自然语言处理中的语义退化问题，通过Kolmogorov复杂性论证了随着表达复杂性的增加，恢复单一预期意义的可能性消失，并通过语义贝尔不等式测试展示了语言解释在模糊性下可以表现出非经典上下文性。", "motivation": "解决自然语言处理中由于语义退化导致的解释限制问题，特别是大型语言模型（LLMs）和其他现代NLP系统面临的固有局限性。", "method": "使用Kolmogorov复杂性理论论证语义解释的局限性，并通过语义贝尔不等式测试，利用不同的LLM代理作为“计算认知系统”来解释在不同上下文设置下的模糊词对。", "result": "实验结果显示，平均CHSH期望值在1.2到2.8之间，多个运行结果（如2.3-2.4）显著违反了经典边界（|S|≤2），表明在模糊性下的语言解释可以表现出非经典上下文性。", "conclusion": "经典基于频率的分析方法对自然语言的处理必然是有损的，而贝叶斯风格的重复采样方法可以提供更实用和适当的语境中语言意义的表征。"}}
{"id": "2506.10086", "title": "Chat-of-Thought: Collaborative Multi-Agent System for Generating Domain Specific Information", "authors": ["Christodoulos Constantinides", "Shuxin Lin", "Nianjun Zhou", "Dhaval Patel"], "abstract": "This paper presents a novel multi-agent system called Chat-of-Thought, designed to facilitate the generation of Failure Modes and Effects Analysis (FMEA) documents for industrial assets. Chat-of-Thought employs multiple collaborative Large Language Model (LLM)-based agents with specific roles, leveraging advanced AI techniques and dynamic task routing to optimize the generation and validation of FMEA tables. A key innovation in this system is the introduction of a Chat of Thought, where dynamic, multi-persona-driven discussions enable iterative refinement of content. This research explores the application domain of industrial equipment monitoring, highlights key challenges, and demonstrates the potential of Chat-of-Thought in addressing these challenges through interactive, template-driven workflows and context-aware agent collaboration.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.10086.pdf", "abstract_url": "https://arxiv.org/abs/2506.10086", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一种名为Chat-of-Thought的新型多代理系统，旨在促进工业资产的故障模式与影响分析（FMEA）文档的生成。该系统利用具有特定角色的多个协作大型语言模型（LLM）代理，通过先进的AI技术和动态任务路由优化FMEA表的生成和验证。", "motivation": "解决工业设备监控领域中FMEA文档生成的挑战，通过多代理协作和动态讨论提高文档质量和效率。", "method": "采用多代理系统，每个代理具有特定角色，利用大型语言模型和动态任务路由技术，通过动态、多角色驱动的讨论迭代优化内容。", "result": "研究表明，Chat-of-Thought系统能够有效应对工业设备监控领域的挑战，通过交互式和模板驱动的工作流程以及上下文感知的代理协作，优化FMEA文档的生成。", "conclusion": "Chat-of-Thought系统展示了在多代理协作和动态讨论支持下，生成高质量FMEA文档的潜力，为工业设备监控领域提供了创新的解决方案。"}}
{"id": "2506.10380", "title": "TableRAG: A Retrieval Augmented Generation Framework for Heterogeneous Document Reasoning", "authors": ["Xiaohan Yu", "Pu Jian", "Chong Chen"], "abstract": "Retrieval-Augmented Generation (RAG) has demonstrated considerable effectiveness in open-domain question answering. However, when applied to heterogeneous documents, comprising both textual and tabular components, existing RAG approaches exhibit critical limitations. The prevailing practice of flattening tables and chunking strategies disrupts the intrinsic tabular structure, leads to information loss, and undermines the reasoning capabilities of LLMs in multi-hop, global queries. To address these challenges, we propose TableRAG, an hybrid framework that unifies textual understanding and complex manipulations over tabular data. TableRAG iteratively operates in four steps: context-sensitive query decomposition, text retrieval, SQL programming and execution, and compositional intermediate answer generation. We also develop HeteQA, a novel benchmark designed to evaluate the multi-hop heterogeneous reasoning capabilities. Experimental results demonstrate that TableRAG consistently outperforms existing baselines on both public datasets and our HeteQA, establishing a new state-of-the-art for heterogeneous document question answering. We release TableRAG at", "subjects": "Computation and Language (cs.CL); Information Retrieval (cs.IR)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2506.10380.pdf", "abstract_url": "https://arxiv.org/abs/2506.10380", "categories": ["Computation and Language (cs.CL)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "TableRAG是一个针对异构文档（包含文本和表格）的检索增强生成框架，通过结合文本理解和表格操作，解决了现有RAG方法在处理表格数据时的局限性。", "motivation": "现有RAG方法在处理包含文本和表格的异构文档时，由于扁平化表格和分块策略破坏了表格结构，导致信息丢失和多跳全局查询推理能力下降。", "method": "TableRAG采用混合框架，通过上下文敏感的查询分解、文本检索、SQL编程和执行以及组合中间答案生成四个步骤，统一了文本理解和表格数据的复杂操作。", "result": "实验结果表明，TableRAG在公共数据集和新开发的HeteQA基准上均优于现有基线，为异构文档问答设立了新的技术标准。", "conclusion": "TableRAG通过其创新的四步操作框架，有效提升了异构文档的推理能力，为未来的研究和应用提供了新的方向。"}}
{"id": "2506.10264", "title": "WGSR-Bench: Wargame-based Game-theoretic Strategic Reasoning Benchmark for Large Language Models", "authors": ["Qiyue Yin", "Pei Xu", "Qiaozhe Li", "Shengda Liu", "Shengqi Shen", "Tong Wang", "Yihong Han", "Xiaonan Zhao", "Likun Yang", "Shiyue Cao", "Shiyu Qiu", "Yuxuan Liu", "Shizhao Yu", "Lei Cui", "Chengxin Yan", "Jie Sun", "Xiangquan Tang", "Kaiqi Huang"], "abstract": "Recent breakthroughs in Large Language Models (LLMs) have led to a qualitative leap in artificial intelligence' s performance on reasoning tasks, particularly demonstrating remarkable capabilities in mathematical, symbolic, and commonsense reasoning. However, as a critical component of advanced human cognition, strategic reasoning, i.e., the ability to assess multi-agent behaviors in dynamic environments, formulate action plans, and adapt strategies, has yet to be systematically evaluated or modeled. To address this gap, this paper introduces WGSR-Bench, the first strategy reasoning benchmark for LLMs using wargame as its evaluation environment. Wargame, a quintessential high-complexity strategic scenario, integrates environmental uncertainty, adversarial dynamics, and non-unique strategic choices, making it an effective testbed for assessing LLMs' capabilities in multi-agent decision-making, intent inference, and counterfactual reasoning. WGSR-Bench designs test samples around three core tasks, i.e., Environmental situation awareness, Opponent risk modeling and Policy generation, which serve as the core S-POE architecture, to systematically assess main abilities of strategic reasoning. Finally, an LLM-based wargame agent is designed to integrate these parts for a comprehensive strategy reasoning assessment. With WGSR-Bench, we hope to assess the strengths and limitations of state-of-the-art LLMs in game-theoretic strategic reasoning and to advance research in large model-driven strategic intelligence.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "15 pages, 17 figures", "pdf_url": "https://arxiv.org/pdf/2506.10264.pdf", "abstract_url": "https://arxiv.org/abs/2506.10264", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了WGSR-Bench，这是一个基于战争游戏的战略推理基准测试，旨在评估大型语言模型（LLMs）在多智能体决策、意图推理和反事实推理等方面的能力。", "motivation": "尽管大型语言模型在数学、符号和常识推理方面表现出色，但作为高级人类认知的关键组成部分，战略推理能力尚未得到系统评估或建模。", "method": "通过设计围绕三个核心任务（环境态势感知、对手风险建模和政策生成）的测试样本，构建了S-POE架构，并设计了一个基于LLM的战争游戏代理，以全面评估战略推理能力。", "result": "WGSR-Bench为评估最先进LLMs在博弈论战略推理中的优势和局限性提供了有效工具。", "conclusion": "通过WGSR-Bench，希望能够评估大型语言模型在战略推理方面的能力，并推动大型模型驱动的战略智能研究。"}}
{"id": "2506.10192", "title": "Towards Responsible AI: Advances in Safety, Fairness, and Accountability of Autonomous Systems", "authors": ["Filip Cano"], "abstract": "Ensuring responsible use of artificial intelligence (AI) has become imperative as autonomous systems increasingly influence critical societal domains. However, the concept of trustworthy AI remains broad and multi-faceted. This thesis advances knowledge in the safety, fairness, transparency, and accountability of AI systems. In safety, we extend classical deterministic shielding techniques to become resilient against delayed observations, enabling practical deployment in real-world conditions. We also implement both deterministic and probabilistic safety shields into simulated autonomous vehicles to prevent collisions with road users, validating the use of these techniques in realistic driving simulators. We introduce fairness shields, a novel post-processing approach to enforce group fairness in sequential decision-making settings over finite and periodic time horizons. By optimizing intervention costs while strictly ensuring fairness constraints, this method efficiently balances fairness with minimal interference. For transparency and accountability, we propose a formal framework for assessing intentional behaviour in probabilistic decision-making agents, introducing quantitative metrics of agency and intention quotient. We use these metrics to propose a retrospective analysis of intention, useful for determining responsibility when autonomous systems cause unintended harm. Finally, we unify these contributions through the ``reactive decision-making'' framework, providing a general formalization that consolidates previous approaches. Collectively, the advancements presented contribute practically to the realization of safer, fairer, and more accountable AI systems, laying the foundations for future research in trustworthy AI.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "202 pages, 38 figures, PhD Thesis", "pdf_url": "https://arxiv.org/pdf/2506.10192.pdf", "abstract_url": "https://arxiv.org/abs/2506.10192", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了如何实现负责任的人工智能（AI），特别是在自主系统的安全性、公平性、透明度和问责制方面。通过扩展确定性屏蔽技术、引入公平屏蔽方法、提出形式化框架来评估意图行为，以及统一这些贡献的“反应性决策”框架，论文为构建更安全、更公平、更负责任的AI系统提供了实用进展。", "motivation": "随着自主系统在关键社会领域的影响力日益增强，确保人工智能（AI）的负责任使用变得至关重要。然而，可信赖AI的概念仍然广泛且多面。", "method": "论文采用了多种方法，包括扩展确定性屏蔽技术以应对延迟观察、在模拟自动驾驶车辆中实施安全和公平屏蔽、提出形式化框架来评估意图行为，以及通过“反应性决策”框架统一这些方法。", "result": "研究结果表明，通过所提出的技术和方法，可以有效地提高AI系统的安全性、公平性和问责制。特别是在模拟环境中验证了安全和公平屏蔽的有效性，以及通过量化指标评估了决策代理的意图和行为。", "conclusion": "论文的贡献为构建更安全、更公平、更负责任的AI系统提供了实用基础，并为未来可信赖AI的研究奠定了基础。"}}
{"id": "2506.10357", "title": "Optimus-3: Towards Generalist Multimodal Minecraft Agents with Scalable Task Experts", "authors": ["Zaijing Li", "Yuquan Xie", "Rui Shao", "Gongwei Chen", "Weili Guan", "Dongmei Jiang", "Liqiang Nie"], "abstract": "Recently, agents based on multimodal large language models (MLLMs) have achieved remarkable progress across various domains. However, building a generalist agent with capabilities such as perception, planning, action, grounding, and reflection in open-world environments like Minecraft remains challenges: insufficient domain-specific data, interference among heterogeneous tasks, and visual diversity in open-world settings. In this paper, we address these challenges through three key contributions. 1) We propose a knowledge-enhanced data generation pipeline to provide scalable and high-quality training data for agent development. 2) To mitigate interference among heterogeneous tasks, we introduce a Mixture-of-Experts (MoE) architecture with task-level routing. 3) We develop a Multimodal Reasoning-Augmented Reinforcement Learning approach to enhance the agent's reasoning ability for visual diversity in Minecraft. Built upon these innovations, we present Optimus-3, a general-purpose agent for Minecraft. Extensive experimental results demonstrate that Optimus-3 surpasses both generalist multimodal large language models and existing state-of-the-art agents across a wide range of tasks in the Minecraft environment. Project page:", "subjects": "Artificial Intelligence (cs.AI)", "comments": "24 pages, 10 figures", "pdf_url": "https://arxiv.org/pdf/2506.10357.pdf", "abstract_url": "https://arxiv.org/abs/2506.10357", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了Optimus-3，一个针对Minecraft环境的多模态通用代理，通过知识增强的数据生成管道、任务级路由的混合专家架构和多模态推理增强的强化学习方法，解决了领域特定数据不足、异构任务干扰和开放世界视觉多样性等挑战。", "motivation": "解决在开放世界环境（如Minecraft）中构建具有感知、规划、行动、基础和反思能力的通用代理所面临的挑战，包括领域特定数据不足、异构任务间的干扰以及开放世界设置的视觉多样性。", "method": "1) 提出知识增强的数据生成管道；2) 引入任务级路由的混合专家架构；3) 开发多模态推理增强的强化学习方法。", "result": "Optimus-3在Minecraft环境中的广泛实验结果表明，它超越了通用的多模态大型语言模型和现有的最先进代理。", "conclusion": "通过创新的数据生成、架构设计和强化学习方法，Optimus-3展示了在复杂开放世界环境中构建高效通用代理的潜力。"}}
{"id": "2506.10384", "title": "NeuroPAL: Punctuated Anytime Learning with Neuroevolution for Macromanagement in Starcraft: Brood War", "authors": ["Jim O'Connor", "Yeonghun Lee", "Gary B Parker"], "abstract": "StarCraft: Brood War remains a challenging benchmark for artificial intelligence research, particularly in the domain of macromanagement, where long-term strategic planning is required. Traditional approaches to StarCraft AI rely on rule-based systems or supervised deep learning, both of which face limitations in adaptability and computational efficiency. In this work, we introduce NeuroPAL, a neuroevolutionary framework that integrates Neuroevolution of Augmenting Topologies (NEAT) with Punctuated Anytime Learning (PAL) to improve the efficiency of evolutionary training. By alternating between frequent, low-fidelity training and periodic, high-fidelity evaluations, PAL enhances the sample efficiency of NEAT, enabling agents to discover effective strategies in fewer training iterations. We evaluate NeuroPAL in a fixed-map, single-race scenario in StarCraft: Brood War and compare its performance to standard NEAT-based training. Our results show that PAL significantly accelerates the learning process, allowing the agent to reach competitive levels of play in approximately half the training time required by NEAT alone. Additionally, the evolved agents exhibit emergent behaviors such as proxy barracks placement and defensive building optimization, strategies commonly used by expert human players. These findings suggest that structured evaluation mechanisms like PAL can enhance the scalability and effectiveness of neuroevolution in complex real-time strategy environments.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "IEEE Conference on Games 2025", "pdf_url": "https://arxiv.org/pdf/2506.10384.pdf", "abstract_url": "https://arxiv.org/abs/2506.10384", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了NeuroPAL，一种结合神经进化增强拓扑（NEAT）和间断随时学习（PAL）的框架，用于提高《星际争霸：母巢之战》中宏观管理的进化训练效率。", "motivation": "解决《星际争霸：母巢之战》中宏观管理长期战略规划的人工智能研究挑战，传统方法在适应性和计算效率上存在限制。", "method": "采用NeuroPAL框架，结合NEAT和PAL，通过交替进行低精度训练和高精度评估，提高样本效率。", "result": "PAL显著加速学习过程，使代理在约一半的训练时间内达到竞争水平，并展现出专家玩家常用的策略。", "conclusion": "结构化评估机制如PAL可以增强神经进化在复杂实时战略环境中的可扩展性和有效性。"}}
{"id": "2506.10326", "title": "A Benchmark for Generalizing Across Diverse Team Strategies in Competitive Pokémon", "authors": ["Cameron Angliss", "Jiaxun Cui", "Jiaheng Hu", "Arrasy Rahman", "Peter Stone"], "abstract": "Developing AI agents that can robustly adapt to dramatically different strategic landscapes without retraining is a central challenge for multi-agent learning. Pokémon Video Game Championships (VGC) is a domain with an extraordinarily large space of possible team configurations of approximately $10^{139}$ - far larger than those of Dota or Starcraft. The highly discrete, combinatorial nature of team building in Pokémon VGC causes optimal strategies to shift dramatically depending on both the team being piloted and the opponent's team, making generalization uniquely challenging. To advance research on this problem, we introduce VGC-Bench: a benchmark that provides critical infrastructure, standardizes evaluation protocols, and supplies human-play datasets and a range of baselines - from large-language-model agents and behavior cloning to reinforcement learning and empirical game-theoretic methods such as self-play, fictitious play, and double oracle. In the restricted setting where an agent is trained and evaluated on a single-team configuration, our methods are able to win against a professional VGC competitor. We extensively evaluated all baseline methods over progressively larger team sets and find that even the best-performing algorithm in the single-team setting struggles at scaling up as team size grows. Thus, policy generalization across diverse team strategies remains an open challenge for the community. Our code is open sourced at", "subjects": "Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT); Machine Learning (cs.LG); Multiagent Systems (cs.MA)", "comments": "15 pages, 3 figures, 10 tables, submitted to NeurIPS 2025 Datasets & Benchmarks Track", "pdf_url": "https://arxiv.org/pdf/2506.10326.pdf", "abstract_url": "https://arxiv.org/abs/2506.10326", "categories": ["Artificial Intelligence (cs.AI)", "Computer Science and Game Theory (cs.GT)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了VGC-Bench，一个用于评估AI代理在Pokémon视频游戏锦标赛（VGC）中跨多样化团队策略泛化能力的基准测试。VGC的团队配置空间极大，策略变化剧烈，使得泛化成为独特挑战。", "motivation": "解决AI代理在多智能体学习中无需重新训练即可适应不同战略环境的挑战，特别是在Pokémon VGC这种团队配置空间极大、策略变化剧烈的领域中。", "method": "引入了VGC-Bench基准测试，提供了基础设施、标准化评估协议、人类游戏数据集和多种基线方法，包括大型语言模型代理、行为克隆、强化学习以及自我对弈、虚构对弈和双重预言等经验博弈论方法。", "result": "在单一团队配置下训练的代理能够击败专业VGC选手，但随着团队规模增大，即使表现最佳的算法也难以扩展，策略泛化仍是一个开放挑战。", "conclusion": "VGC-Bench为研究AI在多智能体环境中的泛化能力提供了重要工具和基准，但跨多样化团队策略的泛化仍是一个未解决的挑战，需要社区进一步研究。"}}
{"id": "2506.10387", "title": "Mirage-1: Augmenting and Updating GUI Agent with Hierarchical Multimodal Skills", "authors": ["Yuquan Xie", "Zaijing Li", "Rui Shao", "Gongwei Chen", "Kaiwen Zhou", "Yinchuan Li", "Dongmei Jiang", "Liqiang Nie"], "abstract": "Recent efforts to leverage the Multi-modal Large Language Model (MLLM) as GUI agents have yielded promising outcomes. However, these agents still struggle with long-horizon tasks in online environments, primarily due to insufficient knowledge and the inherent gap between offline and online domains. In this paper, inspired by how humans generalize knowledge in open-ended environments, we propose a Hierarchical Multimodal Skills (HMS) module to tackle the issue of insufficient knowledge. It progressively abstracts trajectories into execution skills, core skills, and ultimately meta-skills, providing a hierarchical knowledge structure for long-horizon task planning. To bridge the domain gap, we propose the Skill-Augmented Monte Carlo Tree Search (SA-MCTS) algorithm, which efficiently leverages skills acquired in offline environments to reduce the action search space during online tree exploration. Building on HMS, we propose Mirage-1, a multimodal, cross-platform, plug-and-play GUI agent. To validate the performance of Mirage-1 in real-world long-horizon scenarios, we constructed a new benchmark, AndroidLH. Experimental results show that Mirage-1 outperforms previous agents by 32\\%, 19\\%, 15\\%, and 79\\% on AndroidWorld, MobileMiniWob++, Mind2Web-Live, and AndroidLH, respectively. Project page:", "subjects": "Artificial Intelligence (cs.AI)", "comments": "20 pages, 5 figures, 5 tables", "pdf_url": "https://arxiv.org/pdf/2506.10387.pdf", "abstract_url": "https://arxiv.org/abs/2506.10387", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了Mirage-1，一个多模态、跨平台、即插即用的GUI代理，通过分层多模态技能（HMS）模块和技能增强蒙特卡洛树搜索（SA-MCTS）算法，解决了多模态大型语言模型（MLLM）作为GUI代理在在线环境中执行长视野任务时的知识不足和领域差距问题。", "motivation": "解决多模态大型语言模型（MLLM）作为GUI代理在在线环境中执行长视野任务时的知识不足和领域差距问题。", "method": "提出了分层多模态技能（HMS）模块来构建层次化知识结构，以及技能增强蒙特卡洛树搜索（SA-MCTS）算法来利用离线环境中获得的技能减少在线树探索时的动作搜索空间。", "result": "Mirage-1在AndroidWorld、MobileMiniWob++、Mind2Web-Live和AndroidLH等基准测试中，分别比之前的代理表现提高了32%、19%、15%和79%。", "conclusion": "Mirage-1通过HMS和SA-MCTS的有效结合，显著提高了在真实世界长视野场景中的性能，为GUI代理的发展提供了新的方向。"}}
{"id": "2506.10420", "title": "Multi-dimensional Autoscaling of Processing Services: A Comparison of Agent-based Methods", "authors": ["Boris Sedlak", "Alireza Furutanpey", "Zihang Wang", "Víctor Casamayor Pujol", "Schahram Dustdar"], "abstract": "Edge computing breaks with traditional autoscaling due to strict resource constraints, thus, motivating more flexible scaling behaviors using multiple elasticity dimensions. This work introduces an agent-based autoscaling framework that dynamically adjusts both hardware resources and internal service configurations to maximize requirements fulfillment in constrained environments. We compare four types of scaling agents: Active Inference, Deep Q Network, Analysis of Structural Knowledge, and Deep Active Inference, using two real-world processing services running in parallel: YOLOv8 for visual recognition and OpenCV for QR code detection. Results show all agents achieve acceptable SLO performance with varying convergence patterns. While the Deep Q Network benefits from pre-training, the structural analysis converges quickly, and the deep active inference agent combines theoretical foundations with practical scalability advantages. Our findings provide evidence for the viability of multi-dimensional agent-based autoscaling for edge environments and encourage future work in this research direction.", "subjects": "Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Emerging Technologies (cs.ET); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.10420.pdf", "abstract_url": "https://arxiv.org/abs/2506.10420", "categories": ["Artificial Intelligence (cs.AI)", "Distributed, Parallel, and Cluster Computing (cs.DC)", "Emerging Technologies (cs.ET)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一种基于代理的自动扩展框架，用于在边缘计算环境中动态调整硬件资源和内部服务配置，以满足严格资源约束下的需求。通过比较四种扩展代理的性能，证明了多维代理自动扩展在边缘环境中的可行性。", "motivation": "边缘计算由于严格的资源约束，需要更灵活的扩展行为，利用多种弹性维度来最大化需求满足。", "method": "引入了一个基于代理的自动扩展框架，比较了四种类型的扩展代理：主动推理、深度Q网络、结构知识分析和深度主动推理。", "result": "结果显示所有代理都能达到可接受的SLO性能，但收敛模式各异。深度Q网络受益于预训练，结构分析快速收敛，深度主动推理代理结合了理论基础和实际可扩展性优势。", "conclusion": "研究结果为边缘环境中基于代理的多维自动扩展的可行性提供了证据，并鼓励未来在这一研究方向上的工作。"}}
{"id": "2506.10408", "title": "Reasoning RAG via System 1 or System 2: A Survey on Reasoning Agentic Retrieval-Augmented Generation for Industry Challenges", "authors": ["Jintao Liang", "Gang Su", "Huifeng Lin", "You Wu", "Rui Zhao", "Ziyue Li"], "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a powerful framework to overcome the knowledge limitations of Large Language Models (LLMs) by integrating external retrieval with language generation. While early RAG systems based on static pipelines have shown effectiveness in well-structured tasks, they struggle in real-world scenarios requiring complex reasoning, dynamic retrieval, and multi-modal integration. To address these challenges, the field has shifted toward Reasoning Agentic RAG, a paradigm that embeds decision-making and adaptive tool use directly into the retrieval process. In this paper, we present a comprehensive review of Reasoning Agentic RAG methods, categorizing them into two primary systems: predefined reasoning, which follows fixed modular pipelines to boost reasoning, and agentic reasoning, where the model autonomously orchestrates tool interaction during inference. We analyze representative techniques under both paradigms, covering architectural design, reasoning strategies, and tool coordination. Finally, we discuss key research challenges and propose future directions to advance the flexibility, robustness, and applicability of reasoning agentic RAG systems. Our collection of the relevant research has been organized into a", "subjects": "Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.10408.pdf", "abstract_url": "https://arxiv.org/abs/2506.10408", "categories": ["Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["agent", "agentic", "@RAG"], "AI": {"tldr": "本文综述了推理代理检索增强生成（RAG）方法，将其分为预定义推理和代理推理两大类，分析了代表性技术，并探讨了未来研究方向。", "motivation": "解决大型语言模型（LLMs）在知识限制、复杂推理、动态检索和多模态集成方面的挑战。", "method": "通过系统1（预定义推理）和系统2（代理推理）两种主要系统，分类和分析了推理代理RAG方法。", "result": "提出了提高推理代理RAG系统灵活性、鲁棒性和适用性的关键研究挑战和未来方向。", "conclusion": "推理代理RAG系统通过嵌入决策制定和自适应工具使用，为克服LLMs的局限性提供了有效途径，未来研究需进一步探索其灵活性和应用范围。"}}
{"id": "2506.10504", "title": "Beyond Single-User Dialogue: Assessing Multi-User Dialogue State Tracking Capabilities of Large Language Models", "authors": ["Sangmin Song", "Juhwan Choi", "JungMin Yun", "YoungBin Kim"], "abstract": "Large language models (LLMs) have demonstrated remarkable performance in zero-shot dialogue state tracking (DST), reducing the need for task-specific training. However, conventional DST benchmarks primarily focus on structured user-agent conversations, failing to capture the complexities of real-world multi-user interactions. In this study, we assess the robustness of LLMs in multi-user DST while minimizing dataset construction costs. Inspired by recent advances in LLM-based data annotation, we extend an existing DST dataset by generating utterances of a second user based on speech act theory. Our methodology systematically incorporates a second user's utterances into conversations, enabling a controlled evaluation of LLMs in multi-user settings. Experimental results reveal a significant performance drop compared to single-user DST, highlighting the limitations of current LLMs in extracting and tracking dialogue states amidst multiple speakers. Our findings emphasize the need for future research to enhance LLMs for multi-user DST scenarios, paving the way for more realistic and robust DST models.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.10504.pdf", "abstract_url": "https://arxiv.org/abs/2506.10504", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "大型语言模型（LLMs）在零样本对话状态跟踪（DST）中表现出色，但现有DST基准主要关注结构化用户-代理对话，未能捕捉多用户互动的复杂性。本研究评估了LLMs在多用户DST中的鲁棒性，并通过基于言语行为理论的第二用户话语生成扩展了现有DST数据集。实验结果显示，与单用户DST相比，性能显著下降，突显了当前LLMs在多说话者环境中提取和跟踪对话状态的局限性。", "motivation": "解决现有对话状态跟踪（DST）基准主要关注结构化用户-代理对话，未能捕捉多用户互动复杂性的问题。", "method": "基于言语行为理论，生成第二用户的话语，扩展现有DST数据集，系统地将第二用户的话语纳入对话中，以评估LLMs在多用户环境中的表现。", "result": "实验结果显示，与单用户DST相比，LLMs在多用户DST中的性能显著下降。", "conclusion": "当前LLMs在多说话者环境中提取和跟踪对话状态的能力有限，未来研究需要增强LLMs在多用户DST场景中的表现，以开发更现实和鲁棒的DST模型。"}}
{"id": "2506.10821", "title": "VideoDeepResearch: Long Video Understanding With Agentic Tool Using", "authors": ["Huaying Yuan", "Zheng Liu", "Junjie Zhou", "Ji-Rong Wen", "Zhicheng Dou"], "abstract": "Long video understanding (LVU) presents a significant challenge for current multi-modal large language models (MLLMs) due to the task's inherent complexity and context window constraint. It is widely assumed that addressing LVU tasks requires foundation MLLMs with extended context windows, strong visual perception capabilities, and proficient domain expertise. In this work, we challenge this common belief by introducing VideoDeepResearch, a novel agentic framework for long video understanding. Our approach relies solely on a text-only large reasoning model (LRM) combined with a modular multi-modal toolkit, including multimodal retrievers and visual perceivers, all of which are readily available in practice. For each LVU task, the system formulates a problem-solving strategy through reasoning, while selectively accessing and utilizing essential video content via tool using. We conduct extensive experiments on popular LVU benchmarks, including MLVU, Video-MME, and LVBench. Our results demonstrate that VideoDeepResearch achieves substantial improvements over existing MLLM baselines, surpassing the previous state-of-the-art by 9.6%, 6.6%, and 3.9% on MLVU (test), LVBench, and LongVideoBench, respectively. These findings highlight the promise of agentic systems in overcoming key challenges in LVU problems.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.10821.pdf", "abstract_url": "https://arxiv.org/abs/2506.10821", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "VideoDeepResearch提出了一种新颖的代理框架，仅通过文本大型推理模型（LRM）和模块化多模态工具包，有效解决了长视频理解（LVU）的挑战，无需依赖扩展上下文窗口的多模态大型语言模型（MLLMs）。", "motivation": "当前多模态大型语言模型（MLLMs）在处理长视频理解（LVU）任务时，由于任务的复杂性和上下文窗口的限制，面临重大挑战。本文挑战了解决LVU任务需要具有扩展上下文窗口、强大视觉感知能力和专业领域知识的MLLMs的普遍假设。", "method": "VideoDeepResearch框架结合了一个仅文本的大型推理模型（LRM）和一个模块化多模态工具包，包括多模态检索器和视觉感知器。对于每个LVU任务，系统通过推理制定问题解决策略，并通过工具使用选择性访问和利用关键视频内容。", "result": "在流行的LVU基准测试（包括MLVU、Video-MME和LVBench）上的广泛实验表明，VideoDeepResearch显著优于现有的MLLM基线，分别在MLVU（测试）、LVBench和LongVideoBench上超过了之前的最先进技术9.6%、6.6%和3.9%。", "conclusion": "这些发现突出了代理系统在克服LVU问题中的关键挑战方面的潜力，表明无需依赖扩展上下文窗口的MLLMs，仅通过文本大型推理模型和模块化多模态工具包即可有效解决长视频理解任务。"}}
{"id": "2506.10622", "title": "SDialog: A Python Toolkit for Synthetic Dialogue Generation and Analysis", "authors": ["Sergio Burdisso", "Esaú Villatoro-Tello", "Petr Motlicek"], "abstract": "The advancement of conversational AI systems relies on the availability of high-quality, flexible, and reproducible synthetic dialogues for training, evaluation, and benchmarking. SDialog is a modular, extensible Python toolkit designed to address the challenges of synthetic dialogue generation and analysis. By leveraging instruction-tuned Large Language Models (LLMs), SDialog provides abstractions for personas, orchestration, and scenario management, enabling the creation of realistic, diverse, and controllable conversational data for research and development. SDialog supports workflows such as multi-agent simulation and scenario-driven generation, and represents a step forward in the standardization of tools and frameworks for synthetic data generation, a crucial advancement for ensuring reproducibility in today's fast-evolving research landscape.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2506.10622.pdf", "abstract_url": "https://arxiv.org/abs/2506.10622", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "SDialog是一个模块化、可扩展的Python工具包，旨在解决合成对话生成和分析的挑战，利用指令调整的大型语言模型（LLMs）为研究和开发创建现实、多样且可控的对话数据。", "motivation": "为了解决对话AI系统发展中高质量、灵活且可复现的合成对话数据的可用性问题。", "method": "通过利用指令调整的大型语言模型（LLMs），SDialog提供了人物角色、编排和场景管理的抽象，支持多代理模拟和场景驱动生成等工作流程。", "result": "SDialog能够生成现实、多样且可控的对话数据，为合成数据生成工具和框架的标准化迈出了一步。", "conclusion": "SDialog代表了在快速发展的研究景观中确保可复现性的关键进步，为对话AI系统的训练、评估和基准测试提供了重要工具。"}}
{"id": "2506.10844", "title": "CIIR@LiveRAG 2025: Optimizing Multi-Agent Retrieval Augmented Generation through Self-Training", "authors": ["Alireza Salemi", "Mukta Maddipatla", "Hamed Zamani"], "abstract": "This paper presents mRAG, a multi-agent retrieval-augmented generation (RAG) framework composed of specialized agents for subtasks such as planning, searching, reasoning, and coordination. Our system uses a self-training paradigm with reward-guided trajectory sampling to optimize inter-agent collaboration and enhance response generation. Evaluated on DataMorgana-derived datasets during the SIGIR 2025 LiveRAG competition, mRAG outperforms conventional RAG baselines. We further analyze competition outcomes and showcase the framework's strengths with case studies, demonstrating its efficacy for complex, real-world RAG tasks.", "subjects": "Computation and Language (cs.CL); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.10844.pdf", "abstract_url": "https://arxiv.org/abs/2506.10844", "categories": ["Computation and Language (cs.CL)", "Information Retrieval (cs.IR)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文介绍了mRAG，一个多代理检索增强生成（RAG）框架，通过自训练范式优化代理间协作，提升响应生成质量。", "motivation": "解决传统RAG在处理复杂、现实世界任务时的局限性，通过多代理协作提高性能。", "method": "采用自训练范式与奖励引导的轨迹采样，优化多代理（规划、搜索、推理、协调）的协作。", "result": "在SIGIR 2025 LiveRAG竞赛中，mRAG优于传统RAG基线，展示了其在复杂任务中的高效性。", "conclusion": "mRAG框架通过多代理协作和自训练优化，显著提升了RAG任务的性能，适用于复杂现实世界应用。"}}
{"id": "2506.10764", "title": "OPT-BENCH: Evaluating LLM Agent on Large-Scale Search Spaces Optimization Problems", "authors": ["Xiaozhe Li", "Jixuan Chen", "Xinyu Fang", "Shengyuan Ding", "Haodong Duan", "Qingwen Liu", "Kai Chen"], "abstract": "Large Language Models (LLMs) have shown remarkable capabilities in solving diverse tasks. However, their proficiency in iteratively optimizing complex solutions through learning from previous feedback remains insufficiently explored. To bridge this gap, we present OPT-BENCH, a comprehensive benchmark designed to evaluate LLM agents on large-scale search space optimization problems. OPT-BENCH includes 20 real-world machine learning tasks sourced from Kaggle and 10 classical NP problems, offering a diverse and challenging environment for assessing LLM agents on iterative reasoning and solution refinement. To enable rigorous evaluation, we introduce OPT-Agent, an end-to-end optimization framework that emulates human reasoning when tackling complex problems by generating, validating, and iteratively improving solutions through leveraging historical feedback. Through extensive experiments on 9 state-of-the-art LLMs from 6 model families, we analyze the effects of optimization iterations, temperature settings, and model architectures on solution quality and convergence. Our results demonstrate that incorporating historical context significantly enhances optimization performance across both ML and NP tasks. All datasets, code, and evaluation tools are open-sourced to promote further research in advancing LLM-driven optimization and iterative reasoning. Project page: \\href{", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.10764.pdf", "abstract_url": "https://arxiv.org/abs/2506.10764", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了OPT-BENCH，一个用于评估大型语言模型（LLM）代理在大规模搜索空间优化问题上表现的全面基准。它包括20个来自Kaggle的真实世界机器学习任务和10个经典NP问题，旨在评估LLM代理在迭代推理和解决方案优化方面的能力。", "motivation": "尽管大型语言模型在解决多样化任务方面表现出色，但它们在通过从先前反馈中学习来迭代优化复杂解决方案方面的能力尚未得到充分探索。本文旨在填补这一研究空白。", "method": "为了进行严格评估，作者引入了OPT-Agent，这是一个端到端的优化框架，模拟人类在解决复杂问题时的推理过程，通过利用历史反馈生成、验证和迭代改进解决方案。", "result": "通过对6个模型家族的9个最先进LLM进行广泛实验，作者分析了优化迭代、温度设置和模型架构对解决方案质量和收敛性的影响。结果表明，融入历史背景显著提高了在ML和NP任务上的优化性能。", "conclusion": "所有数据集、代码和评估工具均已开源，以促进在推进LLM驱动的优化和迭代推理方面的进一步研究。"}}
{"id": "2506.10142", "title": "Rethinking Brain Tumor Segmentation from the Frequency Domain Perspective", "authors": ["Minye Shao", "Zeyu Wang", "Haoran Duan", "Yawen Huang", "Bing Zhai", "Shizheng Wang", "Yang Long", "Yefeng Zheng"], "abstract": "Precise segmentation of brain tumors, particularly contrast-enhancing regions visible in post-contrast MRI (areas highlighted by contrast agent injection), is crucial for accurate clinical diagnosis and treatment planning but remains challenging. However, current methods exhibit notable performance degradation in segmenting these enhancing brain tumor areas, largely due to insufficient consideration of MRI-specific tumor features such as complex textures and directional variations. To address this, we propose the Harmonized Frequency Fusion Network (HFF-Net), which rethinks brain tumor segmentation from a frequency-domain perspective. To comprehensively characterize tumor regions, we develop a Frequency Domain Decomposition (FDD) module that separates MRI images into low-frequency components, capturing smooth tumor contours and high-frequency components, highlighting detailed textures and directional edges. To further enhance sensitivity to tumor boundaries, we introduce an Adaptive Laplacian Convolution (ALC) module that adaptively emphasizes critical high-frequency details using dynamically updated convolution kernels. To effectively fuse tumor features across multiple scales, we design a Frequency Domain Cross-Attention (FDCA) integrating semantic, positional, and slice-specific information. We further validate and interpret frequency-domain improvements through visualization, theoretical reasoning, and experimental analyses. Extensive experiments on four public datasets demonstrate that HFF-Net achieves an average relative improvement of 4.48\\% (ranging from 2.39\\% to 7.72\\%) in the mean Dice scores across the three major subregions, and an average relative improvement of 7.33% (ranging from 5.96% to 8.64%) in the segmentation of contrast-enhancing tumor regions, while maintaining favorable computational efficiency and clinical applicability. Code:", "subjects": "Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (cs.CV)", "comments": "Accepted by IEEE Transactions on Medical Imaging", "pdf_url": "https://arxiv.org/pdf/2506.10142.pdf", "abstract_url": "https://arxiv.org/abs/2506.10142", "categories": ["Image and Video Processing (eess.IV)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为HFF-Net的频率域视角下的脑肿瘤分割方法，通过频率域分解、自适应拉普拉斯卷积和频率域交叉注意力模块，显著提高了对比增强脑肿瘤区域的分割精度。", "motivation": "当前方法在分割MRI中对比增强的脑肿瘤区域时性能下降，主要由于对MRI特定肿瘤特征（如复杂纹理和方向变化）考虑不足。", "method": "提出了HFF-Net，包括频率域分解模块（FDD）、自适应拉普拉斯卷积模块（ALC）和频率域交叉注意力模块（FDCA），以从频率域角度全面表征肿瘤区域。", "result": "在四个公共数据集上的实验表明，HFF-Net在三个主要子区域的平均Dice分数上实现了4.48%的相对改进，在对比增强肿瘤区域的分割上实现了7.33%的相对改进。", "conclusion": "HFF-Net不仅在分割精度上取得了显著提升，还保持了良好的计算效率和临床适用性，为脑肿瘤分割提供了新的视角和方法。"}}
{"id": "2506.10172", "title": "A Navigation Framework Utilizing Vision-Language Models", "authors": ["Yicheng Duan", "Kaiyu tang"], "abstract": "Vision-and-Language Navigation (VLN) presents a complex challenge in embodied AI, requiring agents to interpret natural language instructions and navigate through visually rich, unfamiliar environments. Recent advances in large vision-language models (LVLMs), such as CLIP and Flamingo, have significantly improved multimodal understanding but introduced new challenges related to computational cost and real-time deployment. In this project, we propose a modular, plug-and-play navigation framework that decouples vision-language understanding from action planning. By integrating a frozen vision-language model, Qwen2.5-VL-7B-Instruct, with lightweight planning logic, we aim to achieve flexible, fast, and adaptable navigation without extensive model fine-tuning. Our framework leverages prompt engineering, structured history management, and a two-frame visual input strategy to enhance decision-making continuity across navigation steps. We evaluate our system on the Room-to-Room benchmark within the VLN-CE setting using the Matterport3D dataset and Habitat-Lab simulation environment. Although our initial results reveal challenges in generalizing to unseen environments under strict evaluation settings, our modular approach lays a foundation for scalable and efficient navigation systems, highlighting promising directions for future improvement through enhanced environmental priors and expanded multimodal input integration.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.10172.pdf", "abstract_url": "https://arxiv.org/abs/2506.10172", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一个利用视觉语言模型（VLMs）的模块化导航框架，旨在解决视觉与语言导航（VLN）中的计算成本和实时部署挑战。通过将冻结的视觉语言模型与轻量级规划逻辑结合，实现了无需大量微调的灵活、快速导航。", "motivation": "解决视觉与语言导航（VLN）中因大型视觉语言模型（LVLMs）带来的计算成本高和实时部署难的问题。", "method": "提出一个模块化的即插即用导航框架，将视觉语言理解与动作规划解耦，结合冻结的视觉语言模型Qwen2.5-VL-7B-Instruct和轻量级规划逻辑，利用提示工程、结构化历史管理和双帧视觉输入策略。", "result": "在Room-to-Room基准测试中，尽管在严格评估设置下对未见环境的泛化能力存在挑战，但模块化方法为可扩展和高效的导航系统奠定了基础。", "conclusion": "模块化方法为未来的改进提供了方向，包括增强环境先验和扩展多模态输入集成，以实现更高效的导航系统。"}}
{"id": "2506.10934", "title": "Dynamic Epistemic Friction in Dialogue", "authors": ["Timothy Obiso", "Kenneth Lai", "Abhijnan Nath", "Nikhil Krishnaswamy", "James Pustejovsky"], "abstract": "Recent developments in aligning Large Language Models (LLMs) with human preferences have significantly enhanced their utility in human-AI collaborative scenarios. However, such approaches often neglect the critical role of \"epistemic friction,\" or the inherent resistance encountered when updating beliefs in response to new, conflicting, or ambiguous information. In this paper, we define dynamic epistemic friction as the resistance to epistemic integration, characterized by the misalignment between an agent's current belief state and new propositions supported by external evidence. We position this within the framework of Dynamic Epistemic Logic (Van Benthem and Pacuit, 2011), where friction emerges as nontrivial belief-revision during the interaction. We then present analyses from a situated collaborative task that demonstrate how this model of epistemic friction can effectively predict belief updates in dialogues, and we subsequently discuss how the model of belief alignment as a measure of epistemic resistance or friction can naturally be made more sophisticated to accommodate the complexities of real-world dialogue scenarios.", "subjects": "Computation and Language (cs.CL)", "comments": "11 pages, 2 figures, 2 tables, CoNLL 2025", "pdf_url": "https://arxiv.org/pdf/2506.10934.pdf", "abstract_url": "https://arxiv.org/abs/2506.10934", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了大型语言模型（LLMs）与人类偏好对齐的最新进展，但指出这些方法常忽视“认知摩擦”的关键作用。认知摩擦是指在面对新、冲突或模糊信息时更新信念所遇到的固有阻力。作者将动态认知摩擦定义为对新命题支持的认知整合的阻力，并在动态认知逻辑框架下进行定位。通过分析一个协作任务，展示了如何有效预测对话中的信念更新，并讨论了如何使信念对齐模型更加复杂以适应现实对话场景的复杂性。", "motivation": "解决大型语言模型在与人类协作场景中忽视认知摩擦的问题，即更新信念时对新、冲突或模糊信息的固有阻力。", "method": "在动态认知逻辑框架下定义动态认知摩擦，并通过协作任务分析预测对话中的信念更新。", "result": "展示了动态认知摩擦模型能有效预测对话中的信念更新，并提出了使信念对齐模型更加复杂以适应现实对话场景的方法。", "conclusion": "动态认知摩擦模型为理解和预测对话中的信念更新提供了有效工具，未来可进一步复杂化以适应更广泛的现实对话场景。"}}
{"id": "2506.10974", "title": "AutoMind: Adaptive Knowledgeable Agent for Automated Data Science", "authors": ["Yixin Ou", "Yujie Luo", "Jingsheng Zheng", "Lanning Wei", "Shuofei Qiao", "Jintian Zhang", "Da Zheng", "Huajun Chen", "Ningyu Zhang"], "abstract": "Large Language Model (LLM) agents have shown great potential in addressing real-world data science problems. LLM-driven data science agents promise to automate the entire machine learning pipeline, yet their real-world effectiveness remains limited. Existing frameworks depend on rigid, pre-defined workflows and inflexible coding strategies; consequently, they excel only on relatively simple, classical problems and fail to capture the empirical expertise that human practitioners bring to complex, innovative tasks. In this work, we introduce AutoMind, an adaptive, knowledgeable LLM-agent framework that overcomes these deficiencies through three key advances: (1) a curated expert knowledge base that grounds the agent in domain expert knowledge, (2) an agentic knowledgeable tree search algorithm that strategically explores possible solutions, and (3) a self-adaptive coding strategy that dynamically tailors code generation to task complexity. Evaluations on two automated data science benchmarks demonstrate that AutoMind delivers superior performance versus state-of-the-art baselines. Additional analyses confirm favorable effectiveness, efficiency, and qualitative solution quality, highlighting AutoMind as an efficient and robust step toward fully automated data science.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG); Multiagent Systems (cs.MA)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2506.10974.pdf", "abstract_url": "https://arxiv.org/abs/2506.10974", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "AutoMind是一个自适应的、知识丰富的LLM代理框架，旨在通过专家知识库、代理知识树搜索算法和自适应性编码策略，提高自动化数据科学的效率和效果。", "motivation": "解决现有LLM驱动数据科学代理在复杂、创新任务中因依赖刚性、预定义工作流程和不灵活编码策略而表现不佳的问题。", "method": "引入三个关键进步：1) 精选的专家知识库；2) 代理知识树搜索算法；3) 自适应性编码策略。", "result": "在两个自动化数据科学基准测试中，AutoMind表现出优于现有最先进基线的性能。", "conclusion": "AutoMind在效率、效果和解决方案质量方面表现出色，是实现完全自动化数据科学的高效且稳健的一步。"}}
{"id": "2506.10171", "title": "Disclosure Audits for LLM Agents", "authors": ["Saswat Das", "Jameson Sandler", "Ferdinando Fioretto"], "abstract": "Large Language Model agents have begun to appear as personal assistants, customer service bots, and clinical aides. While these applications deliver substantial operational benefits, they also require continuous access to sensitive data, which increases the likelihood of unauthorized disclosures. This study proposes an auditing framework for conversational privacy that quantifies and audits these risks. The proposed Conversational Manipulation for Privacy Leakage (CMPL) framework, is an iterative probing strategy designed to stress-test agents that enforce strict privacy directives. Rather than focusing solely on a single disclosure event, CMPL simulates realistic multi-turn interactions to systematically uncover latent vulnerabilities. Our evaluation on diverse domains, data modalities, and safety configurations demonstrate the auditing framework's ability to reveal privacy risks that are not deterred by existing single-turn defenses. In addition to introducing CMPL as a diagnostic tool, the paper delivers (1) an auditing procedure grounded in quantifiable risk metrics and (2) an open benchmark for evaluation of conversational privacy across agent implementations.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.10171.pdf", "abstract_url": "https://arxiv.org/abs/2506.10171", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种用于大型语言模型代理的对话隐私审计框架CMPL，旨在通过多轮交互测试揭示潜在的隐私泄露风险。", "motivation": "大型语言模型代理在提供操作便利的同时，持续访问敏感数据增加了未经授权披露的风险。", "method": "提出了CMPL框架，这是一种迭代探测策略，用于对执行严格隐私指令的代理进行压力测试。", "result": "评估表明，CMPL能够揭示现有单轮防御无法阻止的隐私风险。", "conclusion": "CMPL不仅是一种诊断工具，还提供了基于可量化风险指标的审计程序和开放的基准测试，以评估不同代理实现的对话隐私。"}}
{"id": "2506.10540", "title": "AniMaker: Automated Multi-Agent Animated Storytelling with MCTS-Driven Clip Generation", "authors": ["Haoyuan Shi", "Yunxin Li", "Xinyu Chen", "Longyue Wang", "Baotian Hu", "Min Zhang"], "abstract": "Despite rapid advancements in video generation models, generating coherent storytelling videos that span multiple scenes and characters remains challenging. Current methods often rigidly convert pre-generated keyframes into fixed-length clips, resulting in disjointed narratives and pacing issues. Furthermore, the inherent instability of video generation models means that even a single low-quality clip can significantly degrade the entire output animation's logical coherence and visual continuity. To overcome these obstacles, we introduce AniMaker, a multi-agent framework enabling efficient multi-candidate clip generation and storytelling-aware clip selection, thus creating globally consistent and story-coherent animation solely from text input. The framework is structured around specialized agents, including the Director Agent for storyboard generation, the Photography Agent for video clip generation, the Reviewer Agent for evaluation, and the Post-Production Agent for editing and voiceover. Central to AniMaker's approach are two key technical components: MCTS-Gen in Photography Agent, an efficient Monte Carlo Tree Search (MCTS)-inspired strategy that intelligently navigates the candidate space to generate high-potential clips while optimizing resource usage; and AniEval in Reviewer Agent, the first framework specifically designed for multi-shot animation evaluation, which assesses critical aspects such as story-level consistency, action completion, and animation-specific features by considering each clip in the context of its preceding and succeeding clips. Experiments demonstrate that AniMaker achieves superior quality as measured by popular metrics including VBench and our proposed AniEval framework, while significantly improving the efficiency of multi-candidate generation, pushing AI-generated storytelling animation closer to production standards.", "subjects": "Multiagent Systems (cs.MA); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.10540.pdf", "abstract_url": "https://arxiv.org/abs/2506.10540", "categories": ["Multiagent Systems (cs.MA)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "AniMaker是一个多代理框架，旨在通过MCTS驱动的剪辑生成和故事感知的剪辑选择，从文本输入创建全局一致且故事连贯的动画。", "motivation": "解决当前视频生成模型在生成跨多个场景和角色的连贯故事视频时面临的挑战，如叙事不连贯、节奏问题以及视频生成模型的不稳定性。", "method": "采用多代理框架，包括导演代理、摄影代理、评审代理和后期制作代理，以及MCTS-Gen和AniEval两个关键技术组件。", "result": "实验表明，AniMaker在VBench和提出的AniEval框架等流行指标上实现了更高质量，同时显著提高了多候选生成的效率。", "conclusion": "AniMaker通过其创新的多代理框架和关键技术组件，推动了AI生成的故事动画向生产标准迈进。"}}
{"id": "2506.10030", "title": "Safeguarding Multimodal Knowledge Copyright in the RAG-as-a-Service Environment", "authors": ["Tianyu Chen", "Jian Lou", "Wenjie Wang"], "abstract": "As Retrieval-Augmented Generation (RAG) evolves into service-oriented platforms (Rag-as-a-Service) with shared knowledge bases, protecting the copyright of contributed data becomes essential. Existing watermarking methods in RAG focus solely on textual knowledge, leaving image knowledge unprotected. In this work, we propose AQUA, the first watermark framework for image knowledge protection in Multimodal RAG systems. AQUA embeds semantic signals into synthetic images using two complementary methods: acronym-based triggers and spatial relationship cues. These techniques ensure watermark signals survive indirect watermark propagation from image retriever to textual generator, being efficient, effective and imperceptible. Experiments across diverse models and datasets show that AQUA enables robust, stealthy, and reliable copyright tracing, filling a key gap in multimodal RAG protection.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.10030.pdf", "abstract_url": "https://arxiv.org/abs/2506.10030", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出AQUA，首个用于多模态RAG系统中图像知识保护的水印框架，填补了现有RAG水印方法仅保护文本知识的空白。", "motivation": "随着RAG发展为服务导向平台（Rag-as-a-Service）并共享知识库，保护贡献数据的版权变得至关重要。现有RAG水印方法仅关注文本知识，图像知识未受保护。", "method": "AQUA通过两种互补方法将语义信号嵌入合成图像：基于缩写的触发器和空间关系线索，确保水印信号在从图像检索器到文本生成器的间接传播中存活，且高效、有效且不易察觉。", "result": "跨多种模型和数据集的实验表明，AQUA能够实现强大、隐蔽且可靠的版权追踪。", "conclusion": "AQUA填补了多模态RAG保护中的关键空白，为图像知识提供了有效的水印保护方案。"}}
{"id": "2506.10341", "title": "Provably Learning from Language Feedback", "authors": ["Wanqiao Xu", "Allen Nie", "Ruijie Zheng", "Aditya Modi", "Adith Swaminathan", "Ching-An Cheng"], "abstract": "Interactively learning from observation and language feedback is an increasingly studied area driven by the emergence of large language model (LLM) agents. While impressive empirical demonstrations have been shown, so far a principled framing of these decision problems remains lacking. In this paper, we formalize the Learning from Language Feedback (LLF) problem, assert sufficient assumptions to enable learning despite latent rewards, and introduce $\\textit{transfer eluder dimension}$ as a complexity measure to characterize the hardness of LLF problems. We show that transfer eluder dimension captures the intuition that information in the feedback changes the learning complexity of the LLF problem. We demonstrate cases where learning from rich language feedback can be exponentially faster than learning from reward. We develop a no-regret algorithm, called $\\texttt{HELiX}$, that provably solves LLF problems through sequential interactions, with performance guarantees that scale with the transfer eluder dimension of the problem. Across several empirical domains, we show that $\\texttt{HELiX}$ performs well even when repeatedly prompting LLMs does not work reliably. Our contributions mark a first step towards designing principled interactive learning algorithms from generic language feedback.", "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.10341.pdf", "abstract_url": "https://arxiv.org/abs/2506.10341", "categories": ["Machine Learning (cs.LG)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了从语言反馈中学习（LLF）问题的正式定义，引入了转移迷惑维度作为衡量LLF问题复杂性的指标，并开发了一种名为HELiX的无悔算法，该算法通过顺序交互解决LLF问题，其性能保证与问题的转移迷惑维度成比例。", "motivation": "尽管大型语言模型（LLM）代理的出现推动了从观察和语言反馈中交互式学习的研究，但这一决策问题的原则性框架仍然缺乏。本文旨在填补这一空白，提供一个正式的学习框架。", "method": "本文提出了LLF问题的正式定义，并引入了转移迷惑维度作为复杂性度量。开发了一种名为HELiX的无悔算法，该算法通过顺序交互解决LLF问题。", "result": "研究表明，转移迷惑维度能够捕捉反馈信息改变LLF问题学习复杂性的直觉。在某些情况下，从丰富的语言反馈中学习可以比从奖励中学习快指数级。HELiX算法在多个实证领域中表现良好，即使在重复提示LLMs不可靠的情况下也是如此。", "conclusion": "本文的贡献标志着设计从通用语言反馈中进行交互式学习的原理性算法的第一步。通过正式定义LLF问题和引入转移迷惑维度，为未来的研究提供了理论基础和实用工具。"}}
{"id": "2506.10825", "title": "Generalist Models in Medical Image Segmentation: A Survey and Performance Comparison with Task-Specific Approaches", "authors": ["Andrea Moglia", "Matteo Leccardi", "Matteo Cavicchioli", "Alice Maccarini", "Marco Marcon", "Luca Mainardi", "Pietro Cerveri"], "abstract": "Following the successful paradigm shift of large language models, leveraging pre-training on a massive corpus of data and fine-tuning on different downstream tasks, generalist models have made their foray into computer vision. The introduction of Segment Anything Model (SAM) set a milestone on segmentation of natural images, inspiring the design of a multitude of architectures for medical image segmentation. In this survey we offer a comprehensive and in-depth investigation on generalist models for medical image segmentation. We start with an introduction on the fundamentals concepts underpinning their development. Then, we provide a taxonomy on the different declinations of SAM in terms of zero-shot, few-shot, fine-tuning, adapters, on the recent SAM 2, on other innovative models trained on images alone, and others trained on both text and images. We thoroughly analyze their performances at the level of both primary research and best-in-literature, followed by a rigorous comparison with the state-of-the-art task-specific models. We emphasize the need to address challenges in terms of compliance with regulatory frameworks, privacy and security laws, budget, and trustworthy artificial intelligence (AI). Finally, we share our perspective on future directions concerning synthetic data, early fusion, lessons learnt from generalist models in natural language processing, agentic AI and physical AI, and clinical translation.", "subjects": "Image and Video Processing (eess.IV); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "comments": "132 pages, 26 figures, 23 tables. Andrea Moglia and Matteo Leccardi are equally contributing authors", "pdf_url": "https://arxiv.org/pdf/2506.10825.pdf", "abstract_url": "https://arxiv.org/abs/2506.10825", "categories": ["Image and Video Processing (eess.IV)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文综述了医学图像分割中的通用模型，包括其基础概念、分类、性能分析及与任务特定模型的比较，并探讨了未来发展方向。", "motivation": "探讨通用模型在医学图像分割领域的应用及其性能，解决如何有效利用这些模型以提高分割准确性和效率的问题。", "method": "通过分类和性能分析，比较了不同通用模型（如SAM及其变体）与任务特定模型在医学图像分割中的表现。", "result": "通用模型在医学图像分割中展现出潜力，但在遵守法规、隐私保护、预算和可信AI方面面临挑战。", "conclusion": "通用模型为医学图像分割提供了新的可能性，但需解决多方面的挑战，并探索合成数据、早期融合等未来方向。"}}
{"id": "2506.10751", "title": "Neural at ArchEHR-QA 2025: Agentic Prompt Optimization for Evidence-Grounded Clinical Question Answering", "authors": ["Sai Prasanna Teja Reddy Bogireddy", "Abrar Majeedi", "Viswanatha Reddy Gajjala", "Zhuoyan Xu", "Siddhant Rai", "Vaishnav Potlapalli"], "abstract": "Automated question answering (QA) over electronic health records (EHRs) can bridge critical information gaps for clinicians and patients, yet it demands both precise evidence retrieval and faithful answer generation under limited supervision. In this work, we present Neural, the runner-up in the BioNLP 2025 ArchEHR-QA shared task on evidence-grounded clinical QA. Our proposed method decouples the task into (1) sentence-level evidence identification and (2) answer synthesis with explicit citations. For each stage, we automatically explore the prompt space with DSPy's MIPROv2 optimizer, jointly tuning instructions and few-shot demonstrations on the development set. A self-consistency voting scheme further improves evidence recall without sacrificing precision. On the hidden test set, our method attains an overall score of 51.5, placing second stage while outperforming standard zero-shot and few-shot prompting by over 20 and 10 points, respectively. These results indicate that data-driven prompt optimization is a cost-effective alternative to model fine-tuning for high-stakes clinical QA, advancing the reliability of AI assistants in healthcare.", "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.10751.pdf", "abstract_url": "https://arxiv.org/abs/2506.10751", "categories": ["Machine Learning (cs.LG)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了Neural在BioNLP 2025 ArchEHR-QA共享任务中的方法，通过解耦任务为证据识别和答案合成，并利用DSPy的MIPROv2优化器自动探索提示空间，提高了临床问答的准确性和可靠性。", "motivation": "解决电子健康记录(EHRs)自动问答(QA)中的精确证据检索和有限监督下的忠实答案生成问题。", "method": "将任务解耦为句子级证据识别和带明确引用的答案合成，使用DSPy的MIPROv2优化器自动探索提示空间，并通过自一致性投票方案提高证据召回率。", "result": "在隐藏测试集上获得51.5的总分，比标准的零样本和少样本提示分别高出20和10分。", "conclusion": "数据驱动的提示优化是高风险临床QA中模型微调的成本效益替代方案，提高了医疗保健中AI助手的可靠性。"}}
{"id": "2506.10968", "title": "Eye, Robot: Learning to Look to Act with a BC-RL Perception-Action Loop", "authors": ["Justin Kerr", "Kush Hari", "Ethan Weber", "Chung Min Kim", "Brent Yi", "Tyler Bonnen", "Ken Goldberg", "Angjoo Kanazawa"], "abstract": "Humans do not passively observe the visual world -- we actively look in order to act. Motivated by this principle, we introduce EyeRobot, a robotic system with gaze behavior that emerges from the need to complete real-world tasks. We develop a mechanical eyeball that can freely rotate to observe its surroundings and train a gaze policy to control it using reinforcement learning. We accomplish this by first collecting teleoperated demonstrations paired with a 360 camera. This data is imported into a simulation environment that supports rendering arbitrary eyeball viewpoints, allowing episode rollouts of eye gaze on top of robot demonstrations. We then introduce a BC-RL loop to train the hand and eye jointly: the hand (BC) agent is trained from rendered eye observations, and the eye (RL) agent is rewarded when the hand produces correct action predictions. In this way, hand-eye coordination emerges as the eye looks towards regions which allow the hand to complete the task. EyeRobot implements a foveal-inspired policy architecture allowing high resolution with a small compute budget, which we find also leads to the emergence of more stable fixation as well as improved ability to track objects and ignore distractors. We evaluate EyeRobot on five panoramic workspace manipulation tasks requiring manipulation in an arc surrounding the robot arm. Our experiments suggest EyeRobot exhibits hand-eye coordination behaviors which effectively facilitate manipulation over large workspaces with a single camera. See project site for videos:", "subjects": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2506.10968.pdf", "abstract_url": "https://arxiv.org/abs/2506.10968", "categories": ["Robotics (cs.RO)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了EyeRobot，一个通过强化学习训练凝视行为以完成现实世界任务的机器人系统。该系统结合了机械眼球和BC-RL循环训练方法，实现了手眼协调，有效支持了大工作空间内的操作任务。", "motivation": "人类通过主动观察来行动，而非被动观察。受此启发，本文旨在开发一个能够通过主动凝视来辅助完成任务的机器人系统。", "method": "开发了一个可以自由旋转观察周围环境的机械眼球，并通过强化学习训练凝视策略。采用BC-RL循环联合训练手和眼：手（BC）代理从渲染的眼球观察中学习，眼（RL）代理在手产生正确动作预测时获得奖励。", "result": "EyeRobot在五个需要在大工作空间内操作的全景任务中表现出有效的手眼协调行为，能够稳定注视并跟踪目标，忽略干扰物。", "conclusion": "EyeRobot系统通过模仿人类的主动观察行为，实现了有效的手眼协调，为大工作空间内的机器人操作任务提供了一种新的解决方案。"}}
{"id": "2506.10953", "title": "Build the web for agents, not agents for the web", "authors": ["Xing Han Lù", "Gaurav Kamath", "Marius Mosbach", "Siva Reddy"], "abstract": "Recent advancements in Large Language Models (LLMs) and multimodal counterparts have spurred significant interest in developing web agents -- AI systems capable of autonomously navigating and completing tasks within web environments. While holding tremendous promise for automating complex web interactions, current approaches face substantial challenges due to the fundamental mismatch between human-designed interfaces and LLM capabilities. Current methods struggle with the inherent complexity of web inputs, whether processing massive DOM trees, relying on screenshots augmented with additional information, or bypassing the user interface entirely through API interactions. This position paper advocates for a paradigm shift in web agent research: rather than forcing web agents to adapt to interfaces designed for humans, we should develop a new interaction paradigm specifically optimized for agentic capabilities. To this end, we introduce the concept of an Agentic Web Interface (AWI), an interface specifically designed for agents to navigate a website. We establish six guiding principles for AWI design, emphasizing safety, efficiency, and standardization, to account for the interests of all primary stakeholders. This reframing aims to overcome fundamental limitations of existing interfaces, paving the way for more efficient, reliable, and transparent web agent design, which will be a collaborative effort involving the broader ML community.", "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.10953.pdf", "abstract_url": "https://arxiv.org/abs/2506.10953", "categories": ["Machine Learning (cs.LG)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种新的网络代理研究范式，主张开发专为代理能力优化的交互范式，而非让代理适应人类设计的界面。", "motivation": "当前的大型语言模型（LLMs）和多模态模型在开发网络代理方面面临挑战，主要因为人类设计的界面与LLM能力之间存在根本性不匹配。", "method": "引入了代理性网络界面（AWI）的概念，这是一个专为代理设计的网站导航界面，并建立了六个AWI设计指导原则，强调安全性、效率和标准化。", "result": "通过这种重构，旨在克服现有界面的基本限制，为更高效、可靠和透明的网络代理设计铺平道路。", "conclusion": "这一变革需要更广泛的ML社区的协作努力，以实现网络代理设计的根本性进步。"}}
{"id": "2506.10460", "title": "Equitable Mechanism Design for Facility Location", "authors": ["Toby Walsh"], "abstract": "We consider strategy proof mechanisms for facility location which maximize equitability between agents. As is common in the literature, we measure equitability with the Gini index. We first prove a simple but fundamental impossibility result that no strategy proof mechanism can bound the approximation ratio of the optimal Gini index of utilities for one or more facilities. We propose instead computing approximation ratios of the complemented Gini index of utilities, and consider how well both deterministic and randomized mechanisms approximate this. In addition, as Nash welfare is often put forwards as an equitable compromise between egalitarian and utilitarian outcomes, we consider how well mechanisms approximate the Nash welfare.", "subjects": "Computer Science and Game Theory (cs.GT); Artificial Intelligence (cs.AI)", "comments": "To appear in Proceedings of IJCAI 2025", "pdf_url": "https://arxiv.org/pdf/2506.10460.pdf", "abstract_url": "https://arxiv.org/abs/2506.10460", "categories": ["Computer Science and Game Theory (cs.GT)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了设施位置选择的策略证明机制，旨在最大化代理之间的公平性。通过Gini指数衡量公平性，证明了策略证明机制无法限制最优Gini指数的近似比率，并提出了计算补充Gini指数近似比率的方法。同时，研究了机制如何近似Nash福利，作为平等主义和功利主义结果的公平折衷。", "motivation": "解决在设施位置选择中如何设计策略证明机制以最大化代理之间的公平性问题。", "method": "使用Gini指数衡量公平性，提出计算补充Gini指数的近似比率，并探讨确定性和随机性机制对此的近似效果。同时，研究机制对Nash福利的近似。", "result": "证明了策略证明机制无法限制最优Gini指数的近似比率，提出了计算补充Gini指数近似比率的方法，并展示了机制在近似Nash福利方面的表现。", "conclusion": "研究表明，通过补充Gini指数和Nash福利的近似，可以在设施位置选择中实现更公平的策略证明机制设计。"}}
{"id": "2506.10467", "title": "Specification and Evaluation of Multi-Agent LLM Systems -- Prototype and Cybersecurity Applications", "authors": ["Felix Härer"], "abstract": "Recent advancements in LLMs indicate potential for novel applications, e.g., through reasoning capabilities in the latest OpenAI and DeepSeek models. For applying these models in specific domains beyond text generation, LLM-based multi-agent approaches can be utilized that solve complex tasks by combining reasoning techniques, code generation, and software execution. Applications might utilize these capabilities and the knowledge of specialized LLM agents. However, while many evaluations are performed on LLMs, reasoning techniques, and applications individually, their joint specification and combined application is not explored well. Defined specifications for multi-agent LLM systems are required to explore their potential and their suitability for specific applications, allowing for systematic evaluations of LLMs, reasoning techniques, and related aspects. This paper reports the results of exploratory research to specify and evaluate these aspects through a multi-agent system. The system architecture and prototype are extended from previous research and a specification is introduced for multi-agent systems. Test cases involving cybersecurity tasks indicate feasibility of the architecture and evaluation approach. In particular, the results show the evaluation of question answering, server security, and network security tasks that were completed correctly by agents with LLMs from OpenAI and DeepSeek.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.10467.pdf", "abstract_url": "https://arxiv.org/abs/2506.10467", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了基于LLM的多智能体系统在特定领域（如网络安全）中的应用潜力，提出了一个系统架构和原型，并通过测试案例验证了其可行性。", "motivation": "解决LLM在多智能体系统中联合规范和综合应用的不足，特别是在特定领域如网络安全中的应用潜力。", "method": "扩展了先前研究的系统架构和原型，引入了多智能体系统的规范，并通过涉及网络安全任务的测试案例进行评估。", "result": "测试结果表明，使用OpenAI和DeepSeek的LLM智能体能够正确完成问答、服务器安全和网络安全任务。", "conclusion": "研究表明，基于LLM的多智能体系统在特定应用中具有潜力，特别是在网络安全领域，为系统评估和应用开发提供了基础。"}}
{"id": "2506.10330", "title": "Augmenting Large Language Models with Static Code Analysis for Automated Code Quality Improvements", "authors": ["Seyed Moein Abtahi", "Akramul Azim"], "abstract": "This study examined code issue detection and revision automation by integrating Large Language Models (LLMs) such as OpenAI's GPT-3.5 Turbo and GPT-4o into software development workflows. A static code analysis framework detects issues such as bugs, vulnerabilities, and code smells within a large-scale software project. Detailed information on each issue was extracted and organized to facilitate automated code revision using LLMs. An iterative prompt engineering process is applied to ensure that prompts are structured to produce accurate and organized outputs aligned with the project requirements. Retrieval-augmented generation (RAG) is implemented to enhance the relevance and precision of the revisions, enabling LLM to access and integrate real-time external knowledge. The issue of LLM hallucinations - where the model generates plausible but incorrect outputs - is addressed by a custom-built \"Code Comparison App,\" which identifies and corrects erroneous changes before applying them to the codebase. Subsequent scans using the static code analysis framework revealed a significant reduction in code issues, demonstrating the effectiveness of combining LLMs, static analysis, and RAG to improve code quality, streamline the software development process, and reduce time and resource expenditure.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": "Accepted at FORGE 2025", "pdf_url": "https://arxiv.org/pdf/2506.10330.pdf", "abstract_url": "https://arxiv.org/abs/2506.10330", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本研究探讨了通过将大型语言模型（LLMs）如OpenAI的GPT-3.5 Turbo和GPT-4o集成到软件开发工作流中，实现代码问题检测和修订自动化的方法。结合静态代码分析框架和检索增强生成（RAG）技术，有效提升了代码质量并减少了开发时间和资源消耗。", "motivation": "解决软件开发中代码质量问题，如漏洞、错误和代码异味，以及如何自动化地检测和修订这些问题，以提高开发效率和代码质量。", "method": "集成大型语言模型（LLMs）和静态代码分析框架，应用迭代提示工程过程和检索增强生成（RAG）技术，以及开发“代码比较应用”来纠正模型生成的错误输出。", "result": "通过后续的静态代码分析扫描显示，代码问题显著减少，证明了结合LLMs、静态分析和RAG技术在提升代码质量、优化软件开发流程方面的有效性。", "conclusion": "结合大型语言模型、静态代码分析和检索增强生成技术，可以有效自动化代码质量改进，减少开发过程中的时间和资源消耗，为软件开发流程带来显著优化。"}}
{"id": "2506.10949", "title": "Monitoring Decomposition Attacks in LLMs with Lightweight Sequential Monitors", "authors": ["Chen Yueh-Han", "Nitish Joshi", "Yulin Chen", "Maksym Andriushchenko", "Rico Angell", "He He"], "abstract": "Current LLM safety defenses fail under decomposition attacks, where a malicious goal is decomposed into benign subtasks that circumvent refusals. The challenge lies in the existing shallow safety alignment techniques: they only detect harm in the immediate prompt and do not reason about long-range intent, leaving them blind to malicious intent that emerges over a sequence of seemingly benign instructions. We therefore propose adding an external monitor that observes the conversation at a higher granularity. To facilitate our study of monitoring decomposition attacks, we curate the largest and most diverse dataset to date, including question-answering, text-to-image, and agentic tasks. We verify our datasets by testing them on frontier LLMs and show an 87% attack success rate on average on GPT-4o. This confirms that decomposition attack is broadly effective. Additionally, we find that random tasks can be injected into the decomposed subtasks to further obfuscate malicious intents. To defend in real time, we propose a lightweight sequential monitoring framework that cumulatively evaluates each subtask. We show that a carefully prompt engineered lightweight monitor achieves a 93% defense success rate, beating reasoning models like o3 mini as a monitor. Moreover, it remains robust against random task injection and cuts cost by 90% and latency by 50%. Our findings suggest that lightweight sequential monitors are highly effective in mitigating decomposition attacks and are viable in deployment.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.10949.pdf", "abstract_url": "https://arxiv.org/abs/2506.10949", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "当前的大型语言模型（LLM）安全防御在分解攻击下失效，本文提出了一种轻量级序列监控框架来有效防御此类攻击。", "motivation": "解决现有LLM安全对齐技术无法检测长范围恶意意图的问题，特别是在分解攻击中，恶意目标被分解为规避拒绝的良性子任务。", "method": "提出并实施了一个外部监控器，以更高粒度观察对话，并使用精心策划的数据集验证分解攻击的广泛有效性。", "result": "轻量级序列监控框架在防御分解攻击中表现出93%的成功率，显著优于其他监控方法，同时降低了90%的成本和50%的延迟。", "conclusion": "轻量级序列监控器在缓解分解攻击方面极为有效，且在实际部署中具有可行性。"}}
{"id": "2506.10925", "title": "Agentic Semantic Control for Autonomous Wireless Space Networks: Extending Space-O-RAN with MCP-Driven Distributed Intelligence", "authors": ["Eduardo Baena", "Paolo Testolina", "Michele Polese", "Sergi Aliaga", "Andrew Benincasa", "Dimitrios Koutsonikolas", "Josep Jornet", "Tommaso Melodia"], "abstract": "Lunar surface operations impose stringent requirements on wireless communication systems, including autonomy, robustness to disruption, and the ability to adapt to environmental and mission-driven context. While Space-O-RAN provides a distributed orchestration model aligned with 3GPP standards, its decision logic is limited to static policies and lacks semantic integration. We propose a novel extension incorporating a semantic agentic layer enabled by the Model Context Protocol (MCP) and Agent-to-Agent (A2A) communication protocols, allowing context-aware decision making across real-time, near-real-time, and non-real-time control layers. Distributed cognitive agents deployed in rovers, landers, and lunar base stations implement wireless-aware coordination strategies, including delay-adaptive reasoning and bandwidth-aware semantic compression, while interacting with multiple MCP servers to reason over telemetry, locomotion planning, and mission constraints.", "subjects": "Networking and Internet Architecture (cs.NI); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Systems and Control (eess.SY)", "comments": "Lunar Surface Innovation Consortium 2025 Spring Meeting, May 20-22", "pdf_url": "https://arxiv.org/pdf/2506.10925.pdf", "abstract_url": "https://arxiv.org/abs/2506.10925", "categories": ["Networking and Internet Architecture (cs.NI)", "Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)", "Systems and Control (eess.SY)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种新颖的扩展方法，通过模型上下文协议（MCP）和代理到代理（A2A）通信协议，为Space-O-RAN增加了语义代理层，实现了跨实时、近实时和非实时控制层的上下文感知决策。", "motivation": "月球表面操作对无线通信系统提出了严格的要求，包括自主性、对中断的鲁棒性以及适应环境和任务驱动上下文的能力。Space-O-RAN的决策逻辑仅限于静态策略，缺乏语义集成。", "method": "通过引入MCP和A2A通信协议，部署在漫游车、着陆器和月球基站中的分布式认知代理实现了无线感知协调策略，包括延迟自适应推理和带宽感知语义压缩。", "result": "该方法允许代理与多个MCP服务器交互，以推理遥测、运动规划和任务约束，从而提高了系统的适应性和鲁棒性。", "conclusion": "通过扩展Space-O-RAN的语义代理层，本文提出的方法显著提升了无线通信系统在月球表面操作中的自主性和适应性，为未来的太空通信网络提供了新的研究方向。"}}
{"id": "2506.10756", "title": "Grounded Vision-Language Navigation for UAVs with Open-Vocabulary Goal Understanding", "authors": ["Yuhang Zhang", "Haosheng Yu", "Jiaping Xiao", "Mir Feroskhan"], "abstract": "Vision-and-language navigation (VLN) is a long-standing challenge in autonomous robotics, aiming to empower agents with the ability to follow human instructions while navigating complex environments. Two key bottlenecks remain in this field: generalization to out-of-distribution environments and reliance on fixed discrete action spaces. To address these challenges, we propose Vision-Language Fly (VLFly), a framework tailored for Unmanned Aerial Vehicles (UAVs) to execute language-guided flight. Without the requirement for localization or active ranging sensors, VLFly outputs continuous velocity commands purely from egocentric observations captured by an onboard monocular camera. The VLFly integrates three modules: an instruction encoder based on a large language model (LLM) that reformulates high-level language into structured prompts, a goal retriever powered by a vision-language model (VLM) that matches these prompts to goal images via vision-language similarity, and a waypoint planner that generates executable trajectories for real-time UAV control. VLFly is evaluated across diverse simulation environments without additional fine-tuning and consistently outperforms all baselines. Moreover, real-world VLN tasks in indoor and outdoor environments under direct and indirect instructions demonstrate that VLFly achieves robust open-vocabulary goal understanding and generalized navigation capabilities, even in the presence of abstract language input.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.10756.pdf", "abstract_url": "https://arxiv.org/abs/2506.10756", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了Vision-Language Fly (VLFly)框架，专为无人机(UAVs)设计，通过语言指导执行飞行任务，解决了视觉语言导航(VLN)领域中的分布外环境泛化和固定离散动作空间依赖两大瓶颈问题。", "motivation": "解决视觉语言导航(VLN)中的两大关键挑战：对分布外环境的泛化能力和对固定离散动作空间的依赖。", "method": "提出了VLFly框架，集成了基于大型语言模型(LLM)的指令编码器、基于视觉语言模型(VLM)的目标检索器和航点规划器，通过单目摄像头捕获的自我中心观察输出连续速度命令。", "result": "VLFly在多样化的模拟环境中无需额外微调即 consistently outperforms all baselines，并在真实世界的室内外VLN任务中展示了强大的开放词汇目标理解和泛化导航能力。", "conclusion": "VLFly框架通过集成LLM和VLM，实现了无需定位或主动测距传感器的语言引导无人机导航，展示了在抽象语言输入下的鲁棒性和泛化能力。"}}
{"id": "2506.10954", "title": "SWE-Factory: Your Automated Factory for Issue Resolution Training Data and Evaluation Benchmarks", "authors": ["Lianghong Guo", "Yanlin Wang", "Caihua Li", "Pengyu Yang", "Jiachi Chen", "Wei Tao", "Yingtian Zou", "Duyu Tang", "Zibin Zheng"], "abstract": "Constructing large-scale datasets for the GitHub issue resolution task is crucial for both training and evaluating the software engineering capabilities of Large Language Models (LLMs). However, the traditional process for creating such benchmarks is notoriously challenging and labor-intensive, particularly in the stages of setting up evaluation environments, grading test outcomes, and validating task instances. In this paper, we propose SWE-Factory, an automated pipeline designed to address these challenges. To tackle these issues, our pipeline integrates three core automated components. First, we introduce SWE-Builder, a multi-agent system that automates evaluation environment construction, which employs four specialized agents that work in a collaborative, iterative loop and leverages an environment memory pool to enhance efficiency. Second, we introduce a standardized, exit-code-based grading method that eliminates the need for manually writing custom parsers. Finally, we automate the fail2pass validation process using these reliable exit code signals. Experiments on 671 issues across four programming languages show that our pipeline can effectively construct valid task instances; for example, with GPT-4.1-mini, our SWE-Builder constructs 269 valid instances at $0.045 per instance, while with Gemini-2.5-flash, it achieves comparable performance at the lowest cost of $0.024 per instance. We also demonstrate that our exit-code-based grading achieves 100% accuracy compared to manual inspection, and our automated fail2pass validation reaches a precision of 0.92 and a recall of 1.00. We hope our automated pipeline will accelerate the collection of large-scale, high-quality GitHub issue resolution datasets for both training and evaluation. Our code and datasets are released at", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.10954.pdf", "abstract_url": "https://arxiv.org/abs/2506.10954", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "SWE-Factory是一个自动化管道，旨在解决构建GitHub问题解决任务大规模数据集的挑战，通过集成三个核心自动化组件：SWE-Builder、标准化退出码评分方法和自动化的fail2pass验证过程，有效构建有效任务实例。", "motivation": "传统构建GitHub问题解决任务基准的过程既具有挑战性又劳动密集型，特别是在设置评估环境、评分测试结果和验证任务实例阶段。", "method": "提出SWE-Factory自动化管道，包括SWE-Builder（一个多代理系统，自动化评估环境构建）、标准化退出码评分方法（无需手动编写自定义解析器）和自动化的fail2pass验证过程。", "result": "在四种编程语言的671个问题上进行的实验表明，该管道能有效构建有效任务实例，退出码评分达到100%准确率，自动fail2pass验证达到0.92的精确度和1.00的召回率。", "conclusion": "SWE-Factory自动化管道有望加速大规模、高质量GitHub问题解决数据集的收集，为训练和评估提供支持。"}}
