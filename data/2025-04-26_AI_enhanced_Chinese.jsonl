{"id": "2504.17207", "title": "Perspective-Aware Reasoning in Vision-Language Models via Mental Imagery Simulation", "authors": ["Phillip Y. Lee", "Jihyeon Je", "Chanho Park", "Mikaela Angelina Uy", "Leonidas Guibas", "Minhyuk Sung"], "abstract": "We present a framework for perspective-aware reasoning in vision-language models (VLMs) through mental imagery simulation. Perspective-taking, the ability to perceive an environment or situation from an alternative viewpoint, is a key benchmark for human-level visual understanding, essential for environmental interaction and collaboration with autonomous agents. Despite advancements in spatial reasoning within VLMs, recent research has shown that modern VLMs significantly lack perspective-aware reasoning capabilities and exhibit a strong bias toward egocentric interpretations. To bridge the gap between VLMs and human perception, we focus on the role of mental imagery, where humans perceive the world through abstracted representations that facilitate perspective shifts. Motivated by this, we propose a framework for perspective-aware reasoning, named Abstract Perspective Change (APC), that effectively leverages vision foundation models, such as object detection, segmentation, and orientation estimation, to construct scene abstractions and enable perspective transformations. Our experiments on synthetic and real-image benchmarks, compared with various VLMs, demonstrate significant improvements in perspective-aware reasoning with our framework, further outperforming fine-tuned spatial reasoning models and novel-view-synthesis-based approaches.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2504.17207.pdf", "abstract_url": "https://arxiv.org/abs/2504.17207", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种通过心理意象模拟在视觉语言模型（VLMs）中进行视角感知推理的框架，旨在缩小VLMs与人类感知之间的差距。", "motivation": "解决现代视觉语言模型在视角感知推理能力上的显著不足和以自我为中心解释的强烈偏见问题。", "method": "提出了名为抽象视角变化（APC）的框架，利用视觉基础模型（如物体检测、分割和方向估计）构建场景抽象并实现视角转换。", "result": "在合成和真实图像基准测试中，与各种VLMs相比，该框架在视角感知推理方面显示出显著改进，进一步优于微调的空间推理模型和基于新视角合成的方法。", "conclusion": "通过心理意象模拟的视角感知推理框架显著提升了VLMs的视角感知能力，为与自主代理的协作和环境交互提供了更接近人类水平的视觉理解。"}}
{"id": "2504.17371", "title": "Highly Accurate and Diverse Traffic Data: The DeepScenario Open 3D Dataset", "authors": ["Oussema Dhaouadi", "Johannes Meier", "Luca Wahl", "Jacques Kaiser", "Luca Scalerandi", "Nick Wandelburg", "Zhuolun Zhou", "Nijanthan Berinpanathan", "Holger Banzhaf", "Daniel Cremers"], "abstract": "Accurate 3D trajectory data is crucial for advancing autonomous driving. Yet, traditional datasets are usually captured by fixed sensors mounted on a car and are susceptible to occlusion. Additionally, such an approach can precisely reconstruct the dynamic environment in the close vicinity of the measurement vehicle only, while neglecting objects that are further away. In this paper, we introduce the DeepScenario Open 3D Dataset (DSC3D), a high-quality, occlusion-free dataset of 6 degrees of freedom bounding box trajectories acquired through a novel monocular camera drone tracking pipeline. Our dataset includes more than 175,000 trajectories of 14 types of traffic participants and significantly exceeds existing datasets in terms of diversity and scale, containing many unprecedented scenarios such as complex vehicle-pedestrian interaction on highly populated urban streets and comprehensive parking maneuvers from entry to exit. DSC3D dataset was captured in five various locations in Europe and the United States and include: a parking lot, a crowded inner-city, a steep urban intersection, a federal highway, and a suburban intersection. Our 3D trajectory dataset aims to enhance autonomous driving systems by providing detailed environmental 3D representations, which could lead to improved obstacle interactions and safety. We demonstrate its utility across multiple applications including motion prediction, motion planning, scenario mining, and generative reactive traffic agents. Our interactive online visualization platform and the complete dataset are publicly available at", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.17371.pdf", "abstract_url": "https://arxiv.org/abs/2504.17371", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了DeepScenario Open 3D数据集（DSC3D），这是一个高质量、无遮挡的6自由度边界框轨迹数据集，通过新型单目相机无人机跟踪流程获取，旨在提升自动驾驶系统的环境3D表示能力。", "motivation": "传统的数据集通常由固定在车上的传感器捕获，容易受到遮挡，且只能精确重建测量车辆附近的动态环境，忽略了较远的物体。为了解决这些问题，本文提出了DSC3D数据集。", "method": "使用新型单目相机无人机跟踪流程，捕获了超过175,000条14种交通参与者的轨迹，数据集在多样性和规模上显著超过现有数据集。", "result": "DSC3D数据集包含了前所未有的场景，如高度城市化的街道上复杂的车辆-行人互动以及从进入到退出的全面停车操作，覆盖了欧洲和美国的五个不同地点。", "conclusion": "DSC3D数据集通过提供详细的环境3D表示，有望改善自动驾驶系统中的障碍物交互和安全性，适用于运动预测、运动规划、场景挖掘和生成反应性交通代理等多种应用。"}}
{"id": "2504.17213", "title": "MCAF: Efficient Agent-based Video Understanding Framework through Multimodal Coarse-to-Fine Attention Focusing", "authors": ["Shiwen Cao", "Zhaoxing Zhang", "Junming Jiao", "Juyi Qiao", "Guowen Song", "Rong Shen"], "abstract": "Even in the era of rapid advances in large models, video understanding, particularly long videos, remains highly challenging. Compared with textual or image-based information, videos commonly contain more information with redundancy, requiring large models to strategically allocate attention at a global level for accurate comprehension. To address this, we propose MCAF, an agent-based, training-free framework perform video understanding through Multimodal Coarse-to-fine Attention Focusing. The key innovation lies in its ability to sense and prioritize segments of the video that are highly relevant to the understanding task. First, MCAF hierarchically concentrates on highly relevant frames through multimodal information, enhancing the correlation between the acquired contextual information and the query. Second, it employs a dilated temporal expansion mechanism to mitigate the risk of missing crucial details when extracting information from these concentrated frames. In addition, our framework incorporates a self-reflection mechanism utilizing the confidence level of the model's responses as feedback. By iteratively applying these two creative focusing strategies, it adaptively adjusts attention to capture highly query-connected context and thus improves response accuracy. MCAF outperforms comparable state-of-the-art methods on average. On the EgoSchema dataset, it achieves a remarkable 5% performance gain over the leading approach. Meanwhile, on Next-QA and IntentQA datasets, it outperforms the current state-of-the-art standard by 0.2% and 0.3% respectively. On the Video-MME dataset, which features videos averaging nearly an hour in length, MCAF also outperforms other agent-based methods.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.17213.pdf", "abstract_url": "https://arxiv.org/abs/2504.17213", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "MCAF是一种基于代理的无训练视频理解框架，通过多模态粗到细的注意力聚焦策略，有效提升长视频理解的准确性和效率。", "motivation": "解决长视频理解中的信息冗余和注意力分配问题，提高模型对视频内容的理解准确率。", "method": "采用多模态粗到细的注意力聚焦策略，包括层次化聚焦相关帧和使用扩张时间扩展机制，以及通过自我反思机制调整注意力。", "result": "在EgoSchema数据集上性能提升5%，在Next-QA和IntentQA数据集上分别优于当前最佳方法0.2%和0.3%，在Video-MME数据集上也表现优异。", "conclusion": "MCAF框架通过创新的注意力聚焦策略，显著提高了视频理解的准确性和效率，尤其在处理长视频时表现出色。"}}
{"id": "2504.17447", "title": "FRAG: Frame Selection Augmented Generation for Long Video and Long Document Understanding", "authors": ["De-An Huang", "Subhashree Radhakrishnan", "Zhiding Yu", "Jan Kautz"], "abstract": "There has been impressive progress in Large Multimodal Models (LMMs). Recent works extend these models to long inputs, including multi-page documents and long videos. However, the model size and performance of these long context models are still limited due to the computational cost in both training and inference. In this work, we explore an orthogonal direction and process long inputs without long context LMMs. We propose Frame Selection Augmented Generation (FRAG), where the model first selects relevant frames within the input, and then only generates the final outputs based on the selected frames. The core of the selection process is done by scoring each frame independently, which does not require long context processing. The frames with the highest scores are then selected by a simple Top-K selection. We show that this frustratingly simple framework is applicable to both long videos and multi-page documents using existing LMMs without any fine-tuning. We consider two models, LLaVA-OneVision and InternVL2, in our experiments and show that FRAG consistently improves the performance and achieves state-of-the-art performances for both long video and long document understanding. For videos, FRAG substantially improves InternVL2-76B by 5.8% on MLVU and 3.7% on Video-MME. For documents, FRAG achieves over 20% improvements on MP-DocVQA compared with recent LMMs specialized in long document understanding. Code is available at:", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.17447.pdf", "abstract_url": "https://arxiv.org/abs/2504.17447", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种名为FRAG（Frame Selection Augmented Generation）的框架，用于处理长视频和多页文档的理解问题，无需长上下文大型多模态模型（LMMs）。通过独立评分和Top-K选择相关帧，FRAG显著提高了现有LMMs在长视频和文档理解任务上的性能。", "motivation": "尽管大型多模态模型在多页文档和长视频理解方面取得了进展，但由于训练和推理的计算成本，这些长上下文模型的规模和性能仍然受限。本研究探索了一种无需长上下文LMMs的处理长输入的方法。", "method": "FRAG框架首先独立评分输入中的每一帧，然后通过简单的Top-K选择最高分的帧，仅基于这些选定的帧生成最终输出。这种方法避免了长上下文处理的需求。", "result": "实验表明，FRAG在长视频和多页文档理解任务上均显著提高了性能。特别是在视频理解任务中，FRAG将InternVL2-76B在MLVU和Video-MME上的性能分别提高了5.8%和3.7%；在文档理解任务中，FRAG在MP-DocVQA上相比专门的长文档理解LMMs实现了超过20%的性能提升。", "conclusion": "FRAG框架通过简单的帧选择和评分机制，有效提升了现有LMMs在长视频和文档理解任务上的性能，无需任何微调，实现了最先进的性能。"}}
{"id": "2504.17137", "title": "MIRAGE: A Metric-Intensive Benchmark for Retrieval-Augmented Generation Evaluation", "authors": ["Chanhee Park", "Hyeonseok Moon", "Chanjun Park", "Heuiseok Lim"], "abstract": "Retrieval-Augmented Generation (RAG) has gained prominence as an effective method for enhancing the generative capabilities of Large Language Models (LLMs) through the incorporation of external knowledge. However, the evaluation of RAG systems remains a challenge, due to the intricate interplay between retrieval and generation components. This limitation has resulted in a scarcity of benchmarks that facilitate a detailed, component-specific assessment. In this work, we present MIRAGE, a Question Answering dataset specifically designed for RAG evaluation. MIRAGE consists of 7,560 curated instances mapped to a retrieval pool of 37,800 entries, enabling an efficient and precise evaluation of both retrieval and generation tasks. We also introduce novel evaluation metrics aimed at measuring RAG adaptability, encompassing dimensions such as noise vulnerability, context acceptability, context insensitivity, and context misinterpretation. Through comprehensive experiments across various retriever-LLM configurations, we provide new insights into the optimal alignment of model pairs and the nuanced dynamics within RAG systems. The dataset and evaluation code are publicly available, allowing for seamless integration and customization in diverse research settings\\footnote{The MIRAGE code and data are available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "Accepted to NAACL2025 Findings", "pdf_url": "https://arxiv.org/pdf/2504.17137.pdf", "abstract_url": "https://arxiv.org/abs/2504.17137", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了MIRAGE，一个专为检索增强生成（RAG）评估设计的问答数据集，包含7,560个实例和37,800个检索条目，旨在解决RAG系统评估中的挑战。", "motivation": "检索增强生成（RAG）系统评估的复杂性导致了缺乏能够进行详细、组件特定评估的基准，这限制了RAG系统的进一步发展和优化。", "method": "提出了MIRAGE数据集和新的评估指标，包括噪声脆弱性、上下文可接受性、上下文不敏感性和上下文误解等维度，以全面评估RAG系统的性能。", "result": "通过在不同检索器-LLM配置上的综合实验，提供了关于模型对最佳对齐和RAG系统内部细微动态的新见解。", "conclusion": "MIRAGE数据集和评估代码的公开可用性为研究社区提供了一个强大的工具，以促进RAG系统的评估和优化，从而推动该领域的发展。"}}
{"id": "2504.17192", "title": "Paper2Code: Automating Code Generation from Scientific Papers in Machine Learning", "authors": ["Minju Seo", "Jinheon Baek", "Seongyun Lee", "Sung Ju Hwang"], "abstract": "Despite the rapid growth of machine learning research, corresponding code implementations are often unavailable, making it slow and labor-intensive for researchers to reproduce results and build upon prior work. In the meantime, recent Large Language Models (LLMs) excel at understanding scientific documents and generating high-quality code. Inspired by this, we introduce PaperCoder, a multi-agent LLM framework that transforms machine learning papers into functional code repositories. PaperCoder operates in three stages: planning, where it constructs a high-level roadmap, designs the system architecture with diagrams, identifies file dependencies, and generates configuration files; analysis, which focuses on interpreting implementation-specific details; and generation, where modular, dependency-aware code is produced. Moreover, each phase is instantiated through a set of specialized agents designed to collaborate effectively across the pipeline. We then evaluate PaperCoder on generating code implementations from machine learning papers based on both model-based and human evaluations, specifically from the original paper authors, with author-released repositories as ground truth if available. Our results demonstrate the effectiveness of PaperCoder in creating high-quality, faithful implementations. Furthermore, it consistently shows strengths in the recently released PaperBench benchmark, surpassing strong baselines by substantial margins.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.17192.pdf", "abstract_url": "https://arxiv.org/abs/2504.17192", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "PaperCoder是一个多代理大型语言模型框架，旨在将机器学习论文转化为功能性代码库，通过规划、分析和生成三个阶段自动化代码生成过程。", "motivation": "解决机器学习研究中代码实现不可用或难以复现的问题，加速研究进程。", "method": "采用多代理LLM框架，分三个阶段：规划（构建路线图、设计系统架构）、分析（解释实现细节）和生成（生成模块化、依赖感知的代码）。", "result": "PaperCoder在生成高质量、忠实于原论文的代码实现方面表现出色，在PaperBench基准测试中显著超越基线。", "conclusion": "PaperCoder有效自动化了从科学论文到代码的转换过程，为机器学习研究提供了强有力的工具。"}}
{"id": "2504.17200", "title": "A RAG-Based Multi-Agent LLM System for Natural Hazard Resilience and Adaptation", "authors": ["Yangxinyu Xie", "Bowen Jiang", "Tanwi Mallick", "Joshua David Bergerson", "John K. Hutchison", "Duane R. Verner", "Jordan Branham", "M. Ross Alexander", "Robert B. Ross", "Yan Feng", "Leslie-Anne Levy", "Weijie Su", "Camillo J. Taylor"], "abstract": "Large language models (LLMs) are a transformational capability at the frontier of artificial intelligence and machine learning that can support decision-makers in addressing pressing societal challenges such as extreme natural hazard events. As generalized models, LLMs often struggle to provide context-specific information, particularly in areas requiring specialized knowledge. In this work we propose a retrieval-augmented generation (RAG)-based multi-agent LLM system to support analysis and decision-making in the context of natural hazards and extreme weather events. As a proof of concept, we present WildfireGPT, a specialized system focused on wildfire hazards. The architecture employs a user-centered, multi-agent design to deliver tailored risk insights across diverse stakeholder groups. By integrating natural hazard and extreme weather projection data, observational datasets, and scientific literature through an RAG framework, the system ensures both the accuracy and contextual relevance of the information it provides. Evaluation across ten expert-led case studies demonstrates that WildfireGPT significantly outperforms existing LLM-based solutions for decision support.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.17200.pdf", "abstract_url": "https://arxiv.org/abs/2504.17200", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文提出了一种基于检索增强生成（RAG）的多代理大型语言模型（LLM）系统，旨在通过整合自然灾害和极端天气预测数据、观测数据集及科学文献，为自然灾害韧性和适应提供决策支持。作为概念验证，WildfireGPT专注于野火灾害，通过用户中心的多代理设计，为不同利益相关者提供定制化的风险洞察。", "motivation": "大型语言模型（LLMs）虽然在人工智能和机器学习领域具有变革性能力，但在提供需要专业知识的特定上下文信息方面存在局限。本文旨在解决这一问题，特别是在自然灾害和极端天气事件的背景下，为决策者提供更准确和相关的信息支持。", "method": "采用基于检索增强生成（RAG）的多代理LLM系统架构，整合自然灾害和极端天气的预测数据、观测数据集及科学文献，确保信息的准确性和上下文相关性。", "result": "通过十个专家主导的案例研究评估，WildfireGPT在决策支持方面显著优于现有的基于LLM的解决方案。", "conclusion": "本文提出的RAG-based多代理LLM系统为自然灾害韧性和适应提供了有效的决策支持工具，特别是在野火灾害领域，展示了其在提供定制化风险洞察方面的潜力。"}}
{"id": "2504.16939", "title": "A Desideratum for Conversational Agents: Capabilities, Challenges, and Future Directions", "authors": ["Emre Can Acikgoz", "Cheng Qian", "Hongru Wang", "Vardhan Dongre", "Xiusi Chen", "Heng Ji", "Dilek Hakkani-Tür", "Gokhan Tur"], "abstract": "Recent advances in Large Language Models (LLMs) have propelled conversational AI from traditional dialogue systems into sophisticated agents capable of autonomous actions, contextual awareness, and multi-turn interactions with users. Yet, fundamental questions about their capabilities, limitations, and paths forward remain open. This survey paper presents a desideratum for next-generation Conversational Agents - what has been achieved, what challenges persist, and what must be done for more scalable systems that approach human-level intelligence. To that end, we systematically analyze LLM-driven Conversational Agents by organizing their capabilities into three primary dimensions: (i) Reasoning - logical, systematic thinking inspired by human intelligence for decision making, (ii) Monitor - encompassing self-awareness and user interaction monitoring, and (iii) Control - focusing on tool utilization and policy following. Building upon this, we introduce a novel taxonomy by classifying recent work on Conversational Agents around our proposed desideratum. We identify critical research gaps and outline key directions, including realistic evaluations, long-term multi-turn reasoning skills, self-evolution capabilities, collaborative and multi-agent task completion, personalization, and proactivity. This work aims to provide a structured foundation, highlight existing limitations, and offer insights into potential future research directions for Conversational Agents, ultimately advancing progress toward Artificial General Intelligence (AGI). We maintain a curated repository of papers at:", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.16939.pdf", "abstract_url": "https://arxiv.org/abs/2504.16939", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文综述了大型语言模型（LLMs）驱动的对话代理的最新进展，提出了一个期望清单，包括已实现的成就、存在的挑战及未来发展方向，旨在推动对话代理向人工通用智能（AGI）迈进。", "motivation": "探讨对话代理的能力、限制及未来发展路径，以解决现有系统在可扩展性和接近人类水平智能方面的不足。", "method": "通过将对话代理的能力组织为三个主要维度（推理、监控、控制），并围绕这一期望清单对近期工作进行分类，提出新的分类法。", "result": "识别了关键研究空白，并提出了未来研究方向，包括现实评估、长期多轮推理技能、自我进化能力、协作和多代理任务完成、个性化及主动性。", "conclusion": "本文旨在为对话代理提供一个结构化基础，突出现有限制，并为未来研究方向提供见解，最终推动向AGI的进步。"}}
{"id": "2504.17282", "title": "Cracking the Code of Action: a Generative Approach to Affordances for Reinforcement Learning", "authors": ["Lynn Cherif", "Flemming Kondrup", "David Venuto", "Ankit Anand", "Doina Precup", "Khimya Khetarpal"], "abstract": "Agents that can autonomously navigate the web through a graphical user interface (GUI) using a unified action space (e.g., mouse and keyboard actions) can require very large amounts of domain-specific expert demonstrations to achieve good performance. Low sample efficiency is often exacerbated in sparse-reward and large-action-space environments, such as a web GUI, where only a few actions are relevant in any given situation. In this work, we consider the low-data regime, with limited or no access to expert behavior. To enable sample-efficient learning, we explore the effect of constraining the action space through $\\textit{intent-based affordances}$ -- i.e., considering in any situation only the subset of actions that achieve a desired outcome. We propose $\\textbf{Code as Generative Affordances}$ $(\\textbf{$\\texttt{CoGA}$})$, a method that leverages pre-trained vision-language models (VLMs) to generate code that determines affordable actions through implicit intent-completion functions and using a fully-automated program generation and verification pipeline. These programs are then used in-the-loop of a reinforcement learning agent to return a set of affordances given a pixel observation. By greatly reducing the number of actions that an agent must consider, we demonstrate on a wide range of tasks in the MiniWob++ benchmark that: $\\textbf{1)}$ $\\texttt{CoGA}$ is orders of magnitude more sample efficient than its RL agent, $\\textbf{2)}$ $\\texttt{CoGA}$'s programs can generalize within a family of tasks, and $\\textbf{3)}$ $\\texttt{CoGA}$ performs better or on par compared with behavior cloning when a small number of expert demonstrations is available.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.17282.pdf", "abstract_url": "https://arxiv.org/abs/2504.17282", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为CoGA的方法，通过利用预训练的视觉语言模型生成代码来限制动作空间，从而提高在低数据环境下强化学习代理的样本效率。", "motivation": "解决在图形用户界面（GUI）中，由于动作空间大和奖励稀疏导致的样本效率低下的问题，特别是在专家演示有限或不可用的情况下。", "method": "使用预训练的视觉语言模型（VLMs）生成代码，通过隐式意图完成函数和全自动程序生成与验证流程，确定可负担的动作，从而在强化学习代理中限制动作空间。", "result": "在MiniWob++基准测试中，CoGA显示出比其RL代理更高的样本效率，其程序能够在任务家族内泛化，并且在少量专家演示可用时，性能与行为克隆相当或更好。", "conclusion": "CoGA通过限制动作空间，显著提高了强化学习代理在低数据环境下的样本效率和性能，为自动化网页导航提供了一种有效的方法。"}}
{"id": "2504.17087", "title": "Leveraging LLMs as Meta-Judges: A Multi-Agent Framework for Evaluating LLM Judgments", "authors": ["Yuran Li", "Jama Hussein Mohamud", "Chongren Sun", "Di Wu", "Benoit Boulet"], "abstract": "Large language models (LLMs) are being widely applied across various fields, but as tasks become more complex, evaluating their responses is increasingly challenging. Compared to human evaluators, the use of LLMs to support performance evaluation offers a more efficient alternative. However, most studies focus mainly on aligning LLMs' judgments with human preferences, overlooking the existence of biases and mistakes in human judgment. Furthermore, how to select suitable LLM judgments given multiple potential LLM responses remains underexplored. To address these two aforementioned issues, we propose a three-stage meta-judge selection pipeline: 1) developing a comprehensive rubric with GPT-4 and human experts, 2) using three advanced LLM agents to score judgments, and 3) applying a threshold to filter out low-scoring judgments. Compared to methods using a single LLM as both judge and meta-judge, our pipeline introduces multi-agent collaboration and a more comprehensive rubric. Experimental results on the JudgeBench dataset show about 15.55\\% improvement compared to raw judgments and about 8.37\\% improvement over the single-agent baseline. Our work demonstrates the potential of LLMs as meta-judges and lays the foundation for future research on constructing preference datasets for LLM-as-a-judge reinforcement learning.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "12 pages, 5 figures, 6 tables", "pdf_url": "https://arxiv.org/pdf/2504.17087.pdf", "abstract_url": "https://arxiv.org/abs/2504.17087", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种利用大型语言模型（LLMs）作为元评判者的多代理框架，以解决在复杂任务中评估LLM响应的挑战。通过三阶段的选择流程，包括制定评分标准、多代理评分和应用阈值过滤，该方法在JudgeBench数据集上显示出比单一代理基线更优的性能。", "motivation": "随着大型语言模型（LLMs）在各领域的广泛应用，评估其响应变得越来越复杂。虽然使用LLMs支持性能评估比人类评估者更高效，但现有研究主要关注LLMs判断与人类偏好的对齐，忽视了人类判断中的偏见和错误，以及如何从多个潜在LLM响应中选择合适的判断。", "method": "提出了一个三阶段的元评判选择流程：1) 与GPT-4和人类专家共同制定全面的评分标准；2) 使用三个先进的LLM代理对判断进行评分；3) 应用阈值过滤低分判断。该方法引入了多代理协作和更全面的评分标准。", "result": "在JudgeBench数据集上的实验结果显示，与原始判断相比，该方法提高了约15.55%，与单一代理基线相比提高了约8.37%。", "conclusion": "本研究展示了LLMs作为元评判者的潜力，并为未来构建用于LLM-as-a-judge强化学习的偏好数据集奠定了基础。"}}
{"id": "2504.17356", "title": "Comprehend, Divide, and Conquer: Feature Subspace Exploration via Multi-Agent Hierarchical Reinforcement Learning", "authors": ["Weiliang Zhang", "Xiaohan Huang", "Yi Du", "Ziyue Qiao", "Qingqing Long", "Zhen Meng", "Yuanchun Zhou", "Meng Xiao"], "abstract": "Feature selection aims to preprocess the target dataset, find an optimal and most streamlined feature subset, and enhance the downstream machine learning task. Among filter, wrapper, and embedded-based approaches, the reinforcement learning (RL)-based subspace exploration strategy provides a novel objective optimization-directed perspective and promising performance. Nevertheless, even with improved performance, current reinforcement learning approaches face challenges similar to conventional methods when dealing with complex datasets. These challenges stem from the inefficient paradigm of using one agent per feature and the inherent complexities present in the datasets. This observation motivates us to investigate and address the above issue and propose a novel approach, namely HRLFS. Our methodology initially employs a Large Language Model (LLM)-based hybrid state extractor to capture each feature's mathematical and semantic characteristics. Based on this information, features are clustered, facilitating the construction of hierarchical agents for each cluster and sub-cluster. Extensive experiments demonstrate the efficiency, scalability, and robustness of our approach. Compared to contemporary or the one-feature-one-agent RL-based approaches, HRLFS improves the downstream ML performance with iterative feature subspace exploration while accelerating total run time by reducing the number of agents involved.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "20 pages, keywords: Automated Feature Engineering, Tabular Dataset, Multi-Agent Reinforcement Learning, Feature Selection", "pdf_url": "https://arxiv.org/pdf/2504.17356.pdf", "abstract_url": "https://arxiv.org/abs/2504.17356", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为HRLFS的新方法，通过多智能体分层强化学习进行特征子空间探索，旨在优化特征选择过程并提升下游机器学习任务的性能。", "motivation": "当前基于强化学习的特征选择方法在处理复杂数据集时面临效率低下和挑战，这主要是由于每个特征使用一个代理的范式以及数据集本身的复杂性。", "method": "HRLFS方法首先使用基于大型语言模型（LLM）的混合状态提取器来捕获每个特征的数学和语义特性，然后根据这些信息对特征进行聚类，从而为每个集群和子集群构建分层代理。", "result": "广泛的实验表明，HRLFS方法在效率、可扩展性和鲁棒性方面表现出色，与当代或一特征一代理的基于RL的方法相比，HRLFS通过减少涉及的代理数量加速了总运行时间，同时通过迭代特征子空间探索提高了下游ML性能。", "conclusion": "HRLFS提供了一种有效的特征选择方法，不仅提高了机器学习任务的性能，还通过优化代理使用加速了处理速度，为处理复杂数据集提供了一种新的解决方案。"}}
{"id": "2504.17574", "title": "RAGAT-Mind: A Multi-Granular Modeling Approach for Rumor Detection Based on MindSpore", "authors": ["Zhenkai Qin", "Guifang Yang", "Dongze Wu"], "abstract": "As false information continues to proliferate across social media platforms, effective rumor detection has emerged as a pressing challenge in natural language processing. This paper proposes RAGAT-Mind, a multi-granular modeling approach for Chinese rumor detection, built upon the MindSpore deep learning framework. The model integrates TextCNN for local semantic extraction, bidirectional GRU for sequential context learning, Multi-Head Self-Attention for global dependency focusing, and Bidirectional Graph Convolutional Networks (BiGCN) for structural representation of word co-occurrence graphs. Experiments on the Weibo1-Rumor dataset demonstrate that RAGAT-Mind achieves superior classification performance, attaining 99.2% accuracy and a macro-F1 score of 0.9919. The results validate the effectiveness of combining hierarchical linguistic features with graph-based semantic structures. Furthermore, the model exhibits strong generalization and interpretability, highlighting its practical value for real-world rumor detection applications.", "subjects": "Computation and Language (cs.CL); Computers and Society (cs.CY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.17574.pdf", "abstract_url": "https://arxiv.org/abs/2504.17574", "categories": ["Computation and Language (cs.CL)", "Computers and Society (cs.CY)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种基于MindSpore深度学习框架的多粒度建模方法RAGAT-Mind，用于中文谣言检测。该方法结合了TextCNN、双向GRU、多头自注意力和双向图卷积网络，有效整合了层次化语言特征和基于图的语义结构。在微博谣言数据集上的实验表明，RAGAT-Mind达到了99.2%的准确率和0.9919的宏观F1分数，展现了优异的分类性能和实际应用价值。", "motivation": "随着虚假信息在社交媒体平台上的不断扩散，有效的谣言检测成为自然语言处理领域的一个紧迫挑战。", "method": "RAGAT-Mind模型整合了TextCNN用于局部语义提取，双向GRU用于序列上下文学习，多头自注意力用于全局依赖关注，以及双向图卷积网络(BiGCN)用于词共现图的结构表示。", "result": "在Weibo1-Rumor数据集上的实验显示，RAGAT-Mind达到了99.2%的准确率和0.9919的宏观F1分数。", "conclusion": "结果验证了将层次化语言特征与基于图的语义结构结合的有效性。此外，该模型表现出强大的泛化能力和可解释性，突出了其在现实世界谣言检测应用中的实用价值。"}}
{"id": "2504.16946", "title": "MobileCity: An Efficient Framework for Large-Scale Urban Behavior Simulation", "authors": ["Xiaotong Ye", "Nicolas Bougie", "Toshihiko Yamasaki", "Narimasa Watanabe"], "abstract": "Generative agents offer promising capabilities for simulating realistic urban behaviors. However, existing methods oversimplify transportation choices in modern cities, and require prohibitive computational resources for large-scale population simulation. To address these limitations, we first present a virtual city that features multiple functional buildings and transportation modes. Then, we conduct extensive surveys to model behavioral choices and mobility preferences among population groups. Building on these insights, we introduce a simulation framework that captures the complexity of urban mobility while remaining scalable, enabling the simulation of over 4,000 agents. To assess the realism of the generated behaviors, we perform a series of micro and macro-level analyses. Beyond mere performance comparison, we explore insightful experiments, such as predicting crowd density from movement patterns and identifying trends in vehicle preferences across agent demographics.", "subjects": "Social and Information Networks (cs.SI); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.16946.pdf", "abstract_url": "https://arxiv.org/abs/2504.16946", "categories": ["Social and Information Networks (cs.SI)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "MobileCity是一个高效的大规模城市行为模拟框架，解决了现有方法在模拟现代城市交通选择时的过度简化问题，并减少了大规模人口模拟所需的计算资源。", "motivation": "现有生成代理在模拟现实城市行为时，对现代城市交通选择的模拟过于简化，且大规模人口模拟需要极高的计算资源。", "method": "首先构建一个具有多功能建筑和多种交通模式的虚拟城市，然后通过广泛调查建模人口群体的行为选择和移动偏好，最后引入一个既捕捉城市移动复杂性又保持可扩展性的模拟框架。", "result": "该框架能够模拟超过4,000个代理，通过微观和宏观层面的分析评估生成行为的真实性，并进行了如从移动模式预测人群密度和识别不同人口群体车辆偏好趋势等有洞察力的实验。", "conclusion": "MobileCity框架在保持可扩展性的同时，有效模拟了大规模城市行为的复杂性，为城市规划和行为研究提供了有价值的工具。"}}
{"id": "2504.16947", "title": "SCRAG: Social Computing-Based Retrieval Augmented Generation for Community Response Forecasting in Social Media Environments", "authors": ["Dachun Sun", "You Lyu", "Jinning Li", "Yizhuo Chen", "Tianshi Wang", "Tomoyoshi Kimura", "Tarek Abdelzaher"], "abstract": "This paper introduces SCRAG, a prediction framework inspired by social computing, designed to forecast community responses to real or hypothetical social media posts. SCRAG can be used by public relations specialists (e.g., to craft messaging in ways that avoid unintended misinterpretations) or public figures and influencers (e.g., to anticipate social responses), among other applications related to public sentiment prediction, crisis management, and social what-if analysis. While large language models (LLMs) have achieved remarkable success in generating coherent and contextually rich text, their reliance on static training data and susceptibility to hallucinations limit their effectiveness at response forecasting in dynamic social media environments. SCRAG overcomes these challenges by integrating LLMs with a Retrieval-Augmented Generation (RAG) technique rooted in social computing. Specifically, our framework retrieves (i) historical responses from the target community to capture their ideological, semantic, and emotional makeup, and (ii) external knowledge from sources such as news articles to inject time-sensitive context. This information is then jointly used to forecast the responses of the target community to new posts or narratives. Extensive experiments across six scenarios on the X platform (formerly Twitter), tested with various embedding models and LLMs, demonstrate over 10% improvements on average in key evaluation metrics. A concrete example further shows its effectiveness in capturing diverse ideologies and nuances. Our work provides a social computing tool for applications where accurate and concrete insights into community responses are crucial.", "subjects": "Social and Information Networks (cs.SI); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.16947.pdf", "abstract_url": "https://arxiv.org/abs/2504.16947", "categories": ["Social and Information Networks (cs.SI)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了SCRAG，一个受社会计算启发的预测框架，旨在预测社交媒体环境中社区对真实或假设帖子的反应。SCRAG通过整合大型语言模型（LLMs）与基于社会计算的检索增强生成（RAG）技术，克服了LLMs在动态社交媒体环境中预测反应的局限性。", "motivation": "解决大型语言模型（LLMs）在动态社交媒体环境中预测社区反应时的局限性，如依赖静态训练数据和易产生幻觉的问题。", "method": "SCRAG框架通过检索（i）目标社区的历史反应以捕捉其意识形态、语义和情感构成，以及（ii）来自新闻文章等来源的外部知识以注入时间敏感的背景，联合使用这些信息来预测社区对新帖子或叙述的反应。", "result": "在X平台（前Twitter）上的六个场景中进行的大量实验显示，关键评估指标平均提高了10%以上。一个具体例子进一步展示了其在捕捉多样意识形态和细微差别方面的有效性。", "conclusion": "SCRAG为需要准确和具体洞察社区反应的应用提供了一个社会计算工具，适用于公共情感预测、危机管理和社会假设分析等领域。"}}
{"id": "2504.17129", "title": "Peer-Aware Cost Estimation in Nonlinear General-Sum Dynamic Games for Mutual Learning and Intent Inference", "authors": ["Seyed Yousef Soltanian", "Wenlong Zhang"], "abstract": "Human-robot interactions can be modeled as incomplete-information general-sum dynamic games since the objective functions of both agents are not explicitly known to each other. However, solving for equilibrium policies for such games presents a major challenge, especially if the games involve nonlinear underlying dynamics. To simplify the problem, existing work often assumes that one agent is an expert with complete information about its peer, which can lead to biased estimates and failures in coordination. To address this challenge, we propose a nonlinear peer-aware cost estimation (N-PACE) algorithm for general-sum dynamic games. In N-PACE, using iterative linear quadratic (LQ) approximation of the nonlinear general-sum game, each agent explicitly models the learning dynamics of its peer agent while inferring their objective functions, leading to unbiased fast learning in inferring the unknown objective function of the peer agent, which is critical for task completion and safety assurance. Additionally, we demonstrate how N-PACE enables \\textbf{intent communication} in such multi-agent systems by explicitly modeling the peer's learning dynamics.", "subjects": "Systems and Control (eess.SY); Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.17129.pdf", "abstract_url": "https://arxiv.org/abs/2504.17129", "categories": ["Systems and Control (eess.SY)", "Artificial Intelligence (cs.AI)", "Computer Science and Game Theory (cs.GT)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种非线性同行感知成本估计算法（N-PACE），用于解决不完全信息一般和动态游戏中的人类-机器人交互问题。通过迭代线性二次近似，N-PACE使每个代理能够明确建模其同行代理的学习动态，同时推断其目标函数，从而实现快速无偏学习，并支持多代理系统中的意图通信。", "motivation": "解决在不完全信息一般和动态游戏中，由于代理间目标函数不明确而导致的协调失败和估计偏差问题。", "method": "提出N-PACE算法，利用迭代线性二次（LQ）近似非线性一般和游戏，使每个代理能够建模同行代理的学习动态并推断其目标函数。", "result": "N-PACE实现了对同行代理未知目标函数的快速无偏学习，支持任务完成和安全保证，并促进了多代理系统中的意图通信。", "conclusion": "N-PACE算法通过明确建模同行代理的学习动态和意图推断，有效解决了非线性一般和动态游戏中的协调和通信问题，为人类-机器人交互提供了新的解决方案。"}}
{"id": "2504.17355", "title": "Collaborative Multi-Agent Reinforcement Learning for Automated Feature Transformation with Graph-Driven Path Optimization", "authors": ["Xiaohan Huang", "Dongjie Wang", "Zhiyuan Ning", "Ziyue Qiao", "Qingqing Long", "Haowei Zhu", "Yi Du", "Min Wu", "Yuanchun Zhou", "Meng Xiao"], "abstract": "Feature transformation methods aim to find an optimal mathematical feature-feature crossing process that generates high-value features and improves the performance of downstream machine learning tasks. Existing frameworks, though designed to mitigate manual costs, often treat feature transformations as isolated operations, ignoring dynamic dependencies between transformation steps. To address the limitations, we propose TCTO, a collaborative multi-agent reinforcement learning framework that automates feature engineering through graph-driven path optimization. The framework's core innovation lies in an evolving interaction graph that models features as nodes and transformations as edges. Through graph pruning and backtracking, it dynamically eliminates low-impact edges, reduces redundant operations, and enhances exploration stability. This graph also provides full traceability to empower TCTO to reuse high-utility subgraphs from historical transformations. To demonstrate the efficacy and adaptability of our approach, we conduct comprehensive experiments and case studies, which show superior performance across a range of datasets.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "13 pages, Keywords: Automated Feature Transformation, Tabular Dataset, Reinforcement Learning", "pdf_url": "https://arxiv.org/pdf/2504.17355.pdf", "abstract_url": "https://arxiv.org/abs/2504.17355", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出TCTO，一个基于协作多智能体强化学习的框架，通过图驱动的路径优化自动化特征工程，解决了现有方法忽视特征转换步骤间动态依赖的问题。", "motivation": "现有特征转换框架常将特征转换视为孤立操作，忽略了转换步骤间的动态依赖，导致效率低下和性能不佳。", "method": "采用协作多智能体强化学习框架，构建一个演化交互图，将特征表示为节点，转换表示为边，通过图剪枝和回溯动态优化路径。", "result": "实验和案例研究表明，TCTO在多种数据集上表现出卓越的性能和适应性。", "conclusion": "TCTO框架通过图驱动的路径优化和动态剪枝，有效提升了特征工程的自动化水平和下游任务的性能。"}}
{"id": "2504.17490", "title": "Plasticine: Accelerating Research in Plasticity-Motivated Deep Reinforcement Learning", "authors": ["Mingqi Yuan", "Qi Wang", "Guozheng Ma", "Bo Li", "Xin Jin", "Yunbo Wang", "Xiaokang Yang", "Wenjun Zeng", "Dacheng Tao"], "abstract": "Developing lifelong learning agents is crucial for artificial general intelligence. However, deep reinforcement learning (RL) systems often suffer from plasticity loss, where neural networks gradually lose their ability to adapt during training. Despite its significance, this field lacks unified benchmarks and evaluation protocols. We introduce Plasticine, the first open-source framework for benchmarking plasticity optimization in deep RL. Plasticine provides single-file implementations of over 13 mitigation methods, 10 evaluation metrics, and learning scenarios with increasing non-stationarity levels from standard to open-ended environments. This framework enables researchers to systematically quantify plasticity loss, evaluate mitigation strategies, and analyze plasticity dynamics across different contexts. Our documentation, examples, and source code are available at", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "23 pages", "pdf_url": "https://arxiv.org/pdf/2504.17490.pdf", "abstract_url": "https://arxiv.org/abs/2504.17490", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "Plasticine是一个开源框架，旨在通过提供统一的基准和评估协议，加速针对深度强化学习中可塑性损失问题的研究。", "motivation": "深度强化学习系统在训练过程中经常遭受可塑性损失，即神经网络逐渐失去适应能力。这一领域缺乏统一的基准和评估协议，阻碍了研究的进展。", "method": "引入了Plasticine，这是一个开源框架，提供了超过13种缓解方法的单文件实现、10种评估指标以及从标准到开放环境的不同非平稳性水平的学习场景。", "result": "Plasticine使研究人员能够系统地量化可塑性损失，评估缓解策略，并分析不同背景下的可塑性动态。", "conclusion": "Plasticine框架的引入为深度强化学习中的可塑性研究提供了重要的工具和资源，有望推动这一领域的发展。"}}
{"id": "2504.17669", "title": "Towards a HIPAA Compliant Agentic AI System in Healthcare", "authors": ["Subash Neupane", "Shaswata Mitra", "Sudip Mittal", "Shahram Rahimi"], "abstract": "Agentic AI systems powered by Large Language Models (LLMs) as their foundational reasoning engine, are transforming clinical workflows such as medical report generation and clinical summarization by autonomously analyzing sensitive healthcare data and executing decisions with minimal human oversight. However, their adoption demands strict compliance with regulatory frameworks such as Health Insurance Portability and Accountability Act (HIPAA), particularly when handling Protected Health Information (PHI). This work-in-progress paper introduces a HIPAA-compliant Agentic AI framework that enforces regulatory compliance through dynamic, context-aware policy enforcement. Our framework integrates three core mechanisms: (1) Attribute-Based Access Control (ABAC) for granular PHI governance, (2) a hybrid PHI sanitization pipeline combining regex patterns and BERT-based model to minimize leakage, and (3) immutable audit trails for compliance verification.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.17669.pdf", "abstract_url": "https://arxiv.org/abs/2504.17669", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Emerging Technologies (cs.ET)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了一个符合HIPAA标准的Agentic AI框架，旨在通过动态、上下文感知的策略执行来确保在处理敏感医疗信息时的合规性。", "motivation": "解决在医疗保健领域中使用基于大型语言模型（LLMs）的Agentic AI系统时，如何确保遵守健康保险可携性和责任法案（HIPAA）等法规框架，特别是在处理受保护的健康信息（PHI）时的合规性问题。", "method": "提出了一个框架，该框架整合了三种核心机制：(1) 基于属性的访问控制（ABAC）用于细粒度的PHI治理，(2) 结合正则表达式模式和基于BERT的模型的混合PHI清理管道以减少信息泄露，(3) 不可变的审计跟踪用于合规性验证。", "result": "提出了一个工作进展中的框架，旨在通过上述机制确保Agentic AI系统在医疗保健领域的合规性。", "conclusion": "该框架为开发符合HIPAA标准的Agentic AI系统提供了一种可行的方法，有助于在医疗保健领域安全、合规地应用AI技术。"}}
