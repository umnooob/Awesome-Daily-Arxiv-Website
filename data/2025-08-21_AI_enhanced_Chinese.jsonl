{"id": "2508.14349", "title": "Deep Learning for Taxol Exposure Analysis: A New Cell Image Dataset and Attention-Based Baseline Model", "authors": ["Sean Fletcher", "Gabby Scott", "Douglas Currie", "Xin Zhang", "Yuqi Song", "Bruce MacLeod"], "abstract": "Monitoring the effects of the chemotherapeutic agent Taxol at the cellular level is critical for both clinical evaluation and biomedical research. However, existing detection methods require specialized equipment, skilled personnel, and extensive sample preparation, making them expensive, labor-intensive, and unsuitable for high-throughput or real-time analysis. Deep learning approaches have shown great promise in medical and biological image analysis, enabling automated, high-throughput assessment of cellular morphology. Yet, no publicly available dataset currently exists for automated morphological analysis of cellular responses to Taxol exposure. To address this gap, we introduce a new microscopy image dataset capturing C6 glioma cells treated with varying concentrations of Taxol. To provide an effective solution for Taxol concentration classification and establish a benchmark for future studies on this dataset, we propose a baseline model named ResAttention-KNN, which combines a ResNet-50 with Convolutional Block Attention Modules and uses a k-Nearest Neighbors classifier in the learned embedding space. This model integrates attention-based refinement and non-parametric classification to enhance robustness and interpretability. Both the dataset and implementation are publicly released to support reproducibility and facilitate future research in vision-based biomedical analysis.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "Accepted to the 2025 IEEE International Workshop on Foundations of Machine Learning for Drug Safety (FMLDS), to appear in November 2025", "pdf_url": "https://arxiv.org/pdf/2508.14349.pdf", "abstract_url": "https://arxiv.org/abs/2508.14349", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一个用于紫杉醇暴露分析的新细胞图像数据集和基于注意力的基线模型ResAttention-KNN，以自动化分类紫杉醇浓度，支持生物医学研究。", "motivation": "现有检测方法需要专业设备、人员和大样本准备，成本高、劳动密集，不适合高通量或实时分析，缺乏公开数据集。", "method": "使用ResNet-50结合卷积块注意力模块和k-最近邻分类器，在嵌入空间中进行分类，增强鲁棒性和可解释性。", "result": "提出了新数据集和基线模型，公开释放以支持可重复性和未来研究。", "conclusion": "该方法为基于视觉的生物医学分析提供了基准，促进自动化、高通量评估。"}}
{"id": "2508.14295", "title": "Pixels to Play: A Foundation Model for 3D Gameplay", "authors": ["Yuguang Yue", "Chris Green", "Samuel Hunt", "Irakli Salia", "Wenzhe Shi", "Jonathan J Hunt"], "abstract": "We introduce Pixels2Play-0.1 (P2P0.1), a foundation model that learns to play a wide range of 3D video games with recognizable human-like behavior. Motivated by emerging consumer and developer use cases - AI teammates, controllable NPCs, personalized live-streamers, assistive testers - we argue that an agent must rely on the same pixel stream available to players and generalize to new titles with minimal game-specific engineering. P2P0.1 is trained end-to-end with behavior cloning: labeled demonstrations collected from instrumented human game-play are complemented by unlabeled public videos, to which we impute actions via an inverse-dynamics model. A decoder-only transformer with auto-regressive action output handles the large action space while remaining latency-friendly on a single consumer GPU. We report qualitative results showing competent play across simple Roblox and classic MS-DOS titles, ablations on unlabeled data, and outline the scaling and evaluation steps required to reach expert-level, text-conditioned control.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.14295.pdf", "abstract_url": "https://arxiv.org/abs/2508.14295", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "介绍Pixels2Play-0.1，一个基础模型，通过像素流学习玩多种3D游戏，展现类人行为，使用行为克隆和变换器架构。", "motivation": "解决AI在游戏中作为队友、NPC等应用的需求，要求模型基于像素输入泛化到新游戏，减少工程定制。", "method": "端到端行为克隆训练，结合人类演示和未标记视频，通过逆动力学模型推断动作，使用解码器变换器输出动作。", "result": "定性结果显示在Roblox和MS-DOS游戏中表现良好，进行了未标记数据消融实验，并规划了扩展到专家级控制的步骤。", "conclusion": "模型有潜力实现广泛游戏应用，但需进一步扩展和评估以达到专家级和文本条件控制。"}}
{"id": "2508.14160", "title": "RynnEC: Bringing MLLMs into Embodied World", "authors": ["Ronghao Dang", "Yuqian Yuan", "Yunxuan Mao", "Kehan Li", "Jiangpin Liu", "Zhikai Wang", "Xin Li", "Fan Wang", "Deli Zhao"], "abstract": "We introduce RynnEC, a video multimodal large language model designed for embodied cognition. Built upon a general-purpose vision-language foundation model, RynnEC incorporates a region encoder and a mask decoder, enabling flexible region-level video interaction. Despite its compact architecture, RynnEC achieves state-of-the-art performance in object property understanding, object segmentation, and spatial reasoning. Conceptually, it offers a region-centric video paradigm for the brain of embodied agents, providing fine-grained perception of the physical world and enabling more precise interactions. To mitigate the scarcity of annotated 3D datasets, we propose an egocentric video based pipeline for generating embodied cognition data. Furthermore, we introduce RynnEC-Bench, a region-centered benchmark for evaluating embodied cognitive capabilities. We anticipate that RynnEC will advance the development of general-purpose cognitive cores for embodied agents and facilitate generalization across diverse embodied tasks. The code, model checkpoints, and benchmark are available at:", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": "The technical report of RynnEC, an embodied cognition MLLM", "pdf_url": "https://arxiv.org/pdf/2508.14160.pdf", "abstract_url": "https://arxiv.org/abs/2508.14160", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "RynnEC是一种用于具身认知的视频多模态大语言模型，通过区域编码器和掩码解码器实现灵活的区域级视频交互，在对象属性理解、分割和空间推理方面达到最先进性能，并引入了数据生成管道和基准测试。", "motivation": "解决具身代理在物理世界中需要细粒度感知和精确交互的问题，以及标注3D数据集稀缺的挑战。", "method": "基于通用视觉语言基础模型，集成区域编码器和掩码解码器，并使用以自我为中心的视频管道生成具身认知数据。", "result": "在对象属性理解、对象分割和空间推理任务中实现最先进性能，并开发了RynnEC-Bench基准。", "conclusion": "RynnEC有望推动具身代理通用认知核心的发展，并促进跨多样具身任务的泛化。"}}
{"id": "2508.14527", "title": "Adversarial Generation and Collaborative Evolution of Safety-Critical Scenarios for Autonomous Vehicles", "authors": ["Jiangfan Liu", "Yongkang Guo", "Fangzhi Zhong", "Tianyuan Zhang", "Zonglei Jing", "Siyuan Liang", "Jiakai Wang", "Mingchuan Zhang", "Aishan Liu", "Xianglong Liu"], "abstract": "The generation of safety-critical scenarios in simulation has become increasingly crucial for safety evaluation in autonomous vehicles prior to road deployment in society. However, current approaches largely rely on predefined threat patterns or rule-based strategies, which limit their ability to expose diverse and unforeseen failure modes. To overcome these, we propose ScenGE, a framework that can generate plentiful safety-critical scenarios by reasoning novel adversarial cases and then amplifying them with complex traffic flows. Given a simple prompt of a benign scene, it first performs Meta-Scenario Generation, where a large language model, grounded in structured driving knowledge, infers an adversarial agent whose behavior poses a threat that is both plausible and deliberately challenging. This meta-scenario is then specified in executable code for precise in-simulator control. Subsequently, Complex Scenario Evolution uses background vehicles to amplify the core threat introduced by Meta-Scenario. It builds an adversarial collaborator graph to identify key agent trajectories for optimization. These perturbations are designed to simultaneously reduce the ego vehicle's maneuvering space and create critical occlusions. Extensive experiments conducted on multiple reinforcement learning based AV models show that ScenGE uncovers more severe collision cases (+31.96%) on average than SoTA baselines. Additionally, our ScenGE can be applied to large model based AV systems and deployed on different simulators; we further observe that adversarial training on our scenarios improves the model robustness. Finally, we validate our framework through real-world vehicle tests and human evaluation, confirming that the generated scenarios are both plausible and critical. We hope our paper can build up a critical step towards building public trust and ensuring their safe deployment.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.14527.pdf", "abstract_url": "https://arxiv.org/abs/2508.14527", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "提出ScenGE框架，通过大语言模型推理和复杂交通流放大，生成多样且严重的自动驾驶安全关键场景，提高测试覆盖率和模型鲁棒性。", "motivation": "解决当前自动驾驶安全评估中，基于预定义规则的方法无法暴露多样和意外故障模式的问题。", "method": "使用大语言模型进行元场景生成，推理对抗性代理行为，并通过复杂场景演化优化轨迹，减少自车机动空间并创建关键遮挡。", "result": "实验显示ScenGE比现有方法平均多发现31.96%的严重碰撞案例，并可应用于不同模拟器，提升模型鲁棒性。", "conclusion": "框架有效生成可信且关键的安全场景，有助于建立公众信任和确保自动驾驶安全部署。"}}
{"id": "2508.14214", "title": "Large Language Models are Highly Aligned with Human Ratings of Emotional Stimuli", "authors": ["Mattson Ogg", "Chace Ashcraft", "Ritwik Bose", "Raphael Norman-Tenazas", "Michael Wolmetz"], "abstract": "Emotions exert an immense influence over human behavior and cognition in both commonplace and high-stress tasks. Discussions of whether or how to integrate large language models (LLMs) into everyday life (e.g., acting as proxies for, or interacting with, human agents), should be informed by an understanding of how these tools evaluate emotionally loaded stimuli or situations. A model's alignment with human behavior in these cases can inform the effectiveness of LLMs for certain roles or interactions. To help build this understanding, we elicited ratings from multiple popular LLMs for datasets of words and images that were previously rated for their emotional content by humans. We found that when performing the same rating tasks, GPT-4o responded very similarly to human participants across modalities, stimuli and most rating scales (r = 0.9 or higher in many cases). However, arousal ratings were less well aligned between human and LLM raters, while happiness ratings were most highly aligned. Overall LLMs aligned better within a five-category (happiness, anger, sadness, fear, disgust) emotion framework than within a two-dimensional (arousal and valence) organization. Finally, LLM ratings were substantially more homogenous than human ratings. Together these results begin to describe how LLM agents interpret emotional stimuli and highlight similarities and differences among biological and artificial intelligence in key behavioral domains.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.14214.pdf", "abstract_url": "https://arxiv.org/abs/2508.14214", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "大型语言模型（LLM）在情感刺激评估中与人类高度一致，GPT-4o在多数情况下与人类评分相似度高，但唤醒度评分一致性较低，快乐评分一致性最高。", "motivation": "探讨LLM在情感评估中与人类行为的对齐程度，以评估其在日常生活中的应用潜力。", "method": "使用人类先前评分的单词和图像数据集，让多个流行LLM（如GPT-4o）执行相同评分任务，比较其与人类评分的一致性。", "result": "GPT-4o在多数评分尺度上与人类高度一致（r ≥ 0.9），但唤醒度评分一致性较差；LLM在五类情感框架中比二维组织更一致，且评分更同质化。", "conclusion": "LLM在情感解释上与人类有显著相似性和差异，这有助于理解其在行为领域的应用和局限性。"}}
{"id": "2508.14893", "title": "Virtual Community: An Open World for Humans, Robots, and Society", "authors": ["Qinhong Zhou", "Hongxin Zhang", "Xiangye Lin", "Zheyuan Zhang", "Yutian Chen", "Wenjun Liu", "Zunzhe Zhang", "Sunli Chen", "Lixing Fang", "Qiushi Lyu", "Xinyu Sun", "Jincheng Yang", "Zeyuan Wang", "Bao Chi Dang", "Zhehuan Chen", "Daksha Ladia", "Jiageng Liu", "Chuang Gan"], "abstract": "The rapid progress in AI and Robotics may lead to a profound societal transformation, as humans and robots begin to coexist within shared communities, introducing both opportunities and challenges. To explore this future, we present Virtual Community-an open-world platform for humans, robots, and society-built on a universal physics engine and grounded in real-world 3D scenes. With Virtual Community, we aim to study embodied social intelligence at scale: 1) How robots can intelligently cooperate or compete; 2) How humans develop social relations and build community; 3) More importantly, how intelligent robots and humans can co-exist in an open world. To support these, Virtual Community features: 1) An open-source multi-agent physics simulator that supports robots, humans, and their interactions within a society; 2) A large-scale, real-world aligned community generation pipeline, including vast outdoor space, diverse indoor scenes, and a community of grounded agents with rich characters and appearances. Leveraging Virtual Community, we propose two novel challenges. The Community Planning Challenge evaluates multi-agent reasoning and planning ability in open-world settings, such as cooperating to help agents with daily activities and efficiently connecting other agents. The Community Robot Challenge requires multiple heterogeneous robots to collaborate in solving complex open-world tasks. We evaluate various baselines on these tasks and demonstrate the challenges in both high-level open-world task planning and low-level cooperation controls. We hope that Virtual Community will unlock further study of human-robot coexistence within open-world environments.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL); Robotics (cs.RO)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2508.14893.pdf", "abstract_url": "https://arxiv.org/abs/2508.14893", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Computation and Language (cs.CL)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了Virtual Community，一个基于物理引擎和真实3D场景的开放世界平台，用于研究人类、机器人和社会在共存中的社会智能，包括合作、竞争和社区建设，并提出了两个新挑战来评估多代理推理和规划能力。", "motivation": "解决AI和机器人技术快速发展带来的社会转型问题，探索人类与机器人在开放世界中如何智能共存，应对机会和挑战。", "method": "开发了一个开源的多代理物理模拟器，支持人类、机器人及其互动，并构建大规模真实世界对齐的社区生成管道，包括户外空间、室内场景和具身代理。", "result": "评估了多个基线模型，展示了在高层任务规划和低层合作控制方面的挑战，证明了平台的有效性和复杂性。", "conclusion": "Virtual Community有望推动开放世界中人类-机器人共存的研究，为未来社会智能的发展提供基础。"}}
{"id": "2508.14344", "title": "ISCA: A Framework for Interview-Style Conversational Agents", "authors": ["Charles Welch", "Allison Lahnala", "Vasudha Varadarajan", "Lucie Flek", "Rada Mihalcea", "J. Lomax Boyd", "João Sedoc"], "abstract": "We present a low-compute non-generative system for implementing interview-style conversational agents which can be used to facilitate qualitative data collection through controlled interactions and quantitative analysis. Use cases include applications to tracking attitude formation or behavior change, where control or standardization over the conversational flow is desired. We show how our system can be easily adjusted through an online administrative panel to create new interviews, making the tool accessible without coding. Two case studies are presented as example applications, one regarding the Expressive Interviewing system for COVID-19 and the other a semi-structured interview to survey public opinion on emerging neurotechnology. Our code is open-source, allowing others to build off of our work and develop extensions for additional functionality.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.14344.pdf", "abstract_url": "https://arxiv.org/abs/2508.14344", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "介绍ISCA框架，一种低计算非生成式系统，用于实现访谈式对话代理，便于通过受控交互和定量分析收集定性数据，支持在线调整和开源代码。", "motivation": "解决在态度形成或行为变化跟踪等应用中，需要标准化和控制对话流程的问题，以促进高效的数据收集。", "method": "使用非生成式系统，通过在线管理面板轻松调整和创建新访谈，无需编码，并基于开源代码实现。", "result": "通过两个案例研究（COVID-19表达性访谈和神经技术公众意见调查）展示了系统的可行性和应用效果。", "conclusion": "ISCA框架提供了一个可访问且可扩展的工具，有助于标准化对话和数据收集，未来可扩展更多功能。"}}
{"id": "2508.14410", "title": "Automated Optimization Modeling through Expert-Guided Large Language Model Reasoning", "authors": ["Beinuo Yang", "Qishen Zhou", "Junyi Li", "Xingchen Su", "Simon Hu"], "abstract": "Optimization Modeling (OM) is essential for solving complex decision-making problems. However, the process remains time-consuming and error-prone, heavily relying on domain experts. While Large Language Models (LLMs) show promise in addressing these challenges through their natural language understanding and reasoning capabilities, current approaches face three critical limitations: high benchmark labeling error rates reaching up to 42\\%, narrow evaluation scope that only considers optimal values, and computational inefficiency due to heavy reliance on multi-agent systems or model fine-tuning. In this work, we first enhance existing datasets through systematic error correction and more comprehensive annotation. Additionally, we introduce LogiOR, a new optimization modeling benchmark from the logistics domain, containing more complex problems with standardized annotations. Furthermore, we present ORThought, a novel framework that leverages expert-level optimization modeling principles through chain-of-thought reasoning to automate the OM process. Through extensive empirical evaluation, we demonstrate that ORThought outperforms existing approaches, including multi-agent frameworks, with particularly significant advantages on complex optimization problems. Finally, we provide a systematic analysis of our method, identifying critical success factors and failure modes, providing valuable insights for future research on LLM-based optimization modeling.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.14410.pdf", "abstract_url": "https://arxiv.org/abs/2508.14410", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过专家引导的大语言模型推理自动化优化建模，解决了现有方法的高错误率、评估范围窄和计算效率低的问题，提出了LogiOR基准和ORThought框架，在复杂问题上表现优异。", "motivation": "优化建模过程耗时、易错且依赖专家，现有大语言模型方法存在高错误率、评估局限和效率低下等问题，需要改进。", "method": "增强数据集、引入LogiOR基准，并开发ORThought框架，利用专家级原则和链式推理自动化优化建模。", "result": "ORThought在实证评估中优于现有方法，尤其在复杂优化问题上优势显著，并分析了成功因素和失败模式。", "conclusion": "该方法为基于大语言模型的优化建模提供了有效框架和见解，推动未来研究。"}}
{"id": "2508.14415", "title": "The Agent Behavior: Model, Governance and Challenges in the AI Digital Age", "authors": ["Qiang Zhang", "Pei Yan", "Yijia Xu", "Chuanpo Fu", "Yong Fang", "Yang Liu"], "abstract": "Advancements in AI have led to agents in networked environments increasingly mirroring human behavior, thereby blurring the boundary between artificial and human actors in specific contexts. This shift brings about significant challenges in trust, responsibility, ethics, security and etc. The difficulty in supervising of agent behaviors may lead to issues such as data contamination and unclear accountability. To address these challenges, this paper proposes the \"Network Behavior Lifecycle\" model, which divides network behavior into 6 stages and systematically analyzes the behavioral differences between humans and agents at each stage. Based on these insights, the paper further introduces the \"Agent for Agent (A4A)\" paradigm and the \"Human-Agent Behavioral Disparity (HABD)\" model, which examine the fundamental distinctions between human and agent behaviors across 5 dimensions: decision mechanism, execution efficiency, intention-behavior consistency, behavioral inertia, and irrational patterns. The effectiveness of the model is verified through real-world cases such as red team penetration and blue team defense. Finally, the paper discusses future research directions in dynamic cognitive governance architecture, behavioral disparity quantification, and meta-governance protocol stacks, aiming to provide a theoretical foundation and technical roadmap for secure and trustworthy human-agent collaboration.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.14415.pdf", "abstract_url": "https://arxiv.org/abs/2508.14415", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出'网络行为生命周期'模型和'A4A'范式及'HABD'模型，分析人类与AI代理行为差异，并通过案例验证，旨在为安全可信的人机协作提供理论基础和技术路线。", "motivation": "解决AI代理在联网环境中行为模仿人类带来的信任、责任、伦理和安全挑战，如数据污染和责任不清问题。", "method": "使用'网络行为生命周期'模型分6阶段分析行为差异，引入'A4A'范式和'HABD'模型从5个维度（决策机制、执行效率等）比较人类与代理行为，并通过红蓝队案例验证。", "result": "模型有效揭示了行为差异，验证了在渗透和防御场景中的实用性。", "conclusion": "未来研究方向包括动态认知治理架构、行为差异量化和元治理协议栈，以促进安全可信的人机协作。"}}
{"id": "2508.14564", "title": "Who Sees What? Structured Thought-Action Sequences for Epistemic Reasoning in LLMs", "authors": ["Luca Annese", "Sabrina Patania", "Silvia Serino", "Tom Foulsham", "Silvia Rossi", "Azzurra Ruggeri", "Dimitri Ognibene"], "abstract": "Recent advances in large language models (LLMs) and reasoning frameworks have opened new possibilities for improving the perspective -taking capabilities of autonomous agents. However, tasks that involve active perception, collaborative reasoning, and perspective taking (understanding what another agent can see or knows) pose persistent challenges for current LLM-based systems. This study investigates the potential of structured examples derived from transformed solution graphs generated by the Fast Downward planner to improve the performance of LLM-based agents within a ReAct framework. We propose a structured solution-processing pipeline that generates three distinct categories of examples: optimal goal paths (G-type), informative node paths (E-type), and step-by-step optimal decision sequences contrasting alternative actions (L-type). These solutions are further converted into ``thought-action'' examples by prompting an LLM to explicitly articulate the reasoning behind each decision. While L-type examples slightly reduce clarification requests and overall action steps, they do not yield consistent improvements. Agents are successful in tasks requiring basic attentional filtering but struggle in scenarios that required mentalising about occluded spaces or weighing the costs of epistemic actions. These findings suggest that structured examples alone are insufficient for robust perspective-taking, underscoring the need for explicit belief tracking, cost modelling, and richer environments to enable socially grounded collaboration in LLM-based agents.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)", "comments": "Accepted at ICSR25", "pdf_url": "https://arxiv.org/pdf/2508.14564.pdf", "abstract_url": "https://arxiv.org/abs/2508.14564", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了使用结构化示例（如G型、E型和L型）来提升基于LLM的智能体在视角推理任务中的性能，但发现仅靠结构化示例不足以实现稳健的视角推理，需要显式信念跟踪和成本建模。", "motivation": "解决当前LLM系统在主动感知、协作推理和视角推理任务中的挑战，如理解其他智能体能看到或知道什么。", "method": "提出结构化解决方案处理管道，生成三类示例（G型、E型、L型），并通过LLM转换为'思想-行动'示例，在ReAct框架中评估性能。", "result": "L型示例略微减少澄清请求和行动步骤，但未带来一致改进；智能体在基本注意过滤任务中成功，但在处理遮挡空间或权衡认知行动成本时表现不佳。", "conclusion": "结构化示例本身不足，需结合显式信念跟踪、成本建模和更丰富的环境，以实现基于LLM智能体的社会性协作。"}}
{"id": "2508.14654", "title": "Entropy-Constrained Strategy Optimization in Urban Floods: A Multi-Agent Framework with LLM and Knowledge Graph Integration", "authors": ["Peilin Ji", "Xiao Xue", "Simeng Wang", "Wenhao Yan"], "abstract": "In recent years, the increasing frequency of extreme urban rainfall events has posed significant challenges to emergency scheduling systems. Urban flooding often leads to severe traffic congestion and service disruptions, threatening public safety and mobility. However, effective decision making remains hindered by three key challenges: (1) managing trade-offs among competing goals (e.g., traffic flow, task completion, and risk mitigation) requires dynamic, context-aware strategies; (2) rapidly evolving environmental conditions render static rules inadequate; and (3) LLM-generated strategies frequently suffer from semantic instability and execution inconsistency. Existing methods fail to align perception, global optimization, and multi-agent coordination within a unified framework. To tackle these challenges, we introduce H-J, a hierarchical multi-agent framework that integrates knowledge-guided prompting, entropy-constrained generation, and feedback-driven optimization. The framework establishes a closed-loop pipeline spanning from multi-source perception to strategic execution and continuous refinement. We evaluate H-J on real-world urban topology and rainfall data under three representative conditions: extreme rainfall, intermittent bursts, and daily light rain. Experiments show that H-J outperforms rule-based and reinforcement-learning baselines in traffic smoothness, task success rate, and system robustness. These findings highlight the promise of uncertainty-aware, knowledge-constrained LLM-based approaches for enhancing resilience in urban flood response.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "17 pages including appendix, 6 figures", "pdf_url": "https://arxiv.org/pdf/2508.14654.pdf", "abstract_url": "https://arxiv.org/abs/2508.14654", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出H-J框架，结合LLM和知识图谱，通过熵约束优化和多智能体协调，提升城市洪水应急调度性能，在真实数据上验证其优于基线方法。", "motivation": "解决城市洪水应急调度中动态决策、环境变化和LLM策略不稳定的挑战，以提高交通流畅度、任务成功率和系统鲁棒性。", "method": "采用分层多智能体框架，集成知识引导提示、熵约束生成和反馈驱动优化，构建从感知到执行的闭环管道。", "result": "在极端降雨等条件下，H-J在交通平滑度、任务成功率和鲁棒性上优于基于规则和强化学习的基线方法。", "conclusion": "不确定性感知和知识约束的LLM方法有望增强城市洪水响应的韧性，为应急管理提供有效解决方案。"}}
{"id": "2508.14704", "title": "MCP-Universe: Benchmarking Large Language Models with Real-World Model Context Protocol Servers", "authors": ["Ziyang Luo", "Zhiqi Shen", "Wenzhuo Yang", "Zirui Zhao", "Prathyusha Jwalapuram", "Amrita Saha", "Doyen Sahoo", "Silvio Savarese", "Caiming Xiong", "Junnan Li"], "abstract": "The Model Context Protocol has emerged as a transformative standard for connecting large language models to external data sources and tools, rapidly gaining adoption across major AI providers and development platforms. However, existing benchmarks are overly simplistic and fail to capture real application challenges such as long-horizon reasoning and large, unfamiliar tool spaces. To address this critical gap, we introduce MCP-Universe, the first comprehensive benchmark specifically designed to evaluate LLMs in realistic and hard tasks through interaction with real-world MCP servers. Our benchmark encompasses 6 core domains spanning 11 different MCP servers: Location Navigation, Repository Management, Financial Analysis, 3D Design, Browser Automation, and Web Searching. To ensure rigorous evaluation, we implement execution-based evaluators, including format evaluators for agent format compliance, static evaluators for time-invariant content matching, and dynamic evaluators that automatically retrieve real-time ground truth for temporally sensitive tasks. Through extensive evaluation of leading LLMs, we find that even SOTA models such as GPT-5 (43.72%), Grok-4 (33.33%) and Claude-4.0-Sonnet (29.44%) exhibit significant performance limitations. In addition, our benchmark poses a significant long-context challenge for LLM agents, as the number of input tokens increases rapidly with the number of interaction steps. Moreover, it introduces an unknown-tools challenge, as LLM agents often lack familiarity with the precise usage of the MCP servers. Notably, enterprise-level agents like Cursor cannot achieve better performance than standard ReAct frameworks. Beyond evaluation, we open-source our extensible evaluation framework with UI support, enabling researchers and practitioners to seamlessly integrate new agents and MCP servers while fostering innovation in the rapidly evolving MCP ecosystem.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2508.14704.pdf", "abstract_url": "https://arxiv.org/abs/2508.14704", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "MCP-Universe是首个针对大型语言模型与真实MCP服务器交互的综合性基准测试，覆盖多个领域，揭示SOTA模型性能局限并开源评估框架。", "motivation": "解决现有基准测试过于简单，无法捕捉真实应用挑战如长时推理和大规模未知工具空间的问题。", "method": "通过执行型评估器（格式、静态和动态评估器）与真实MCP服务器交互，评估LLMs在6个核心领域的表现。", "result": "SOTA模型如GPT-5、Grok-4和Claude-4.0-Sonnet表现不佳，准确率低，面临长上下文和未知工具挑战，企业级代理不优于标准ReAct框架。", "conclusion": "MCP-Universe填补了基准测试空白，促进MCP生态系统创新，开源框架支持进一步研究和集成。"}}
{"id": "2508.14052", "title": "FinAgentBench: A Benchmark Dataset for Agentic Retrieval in Financial Question Answering", "authors": ["Chanyeol Choi", "Jihoon Kwon", "Alejandro Lopez-Lira", "Chaewoon Kim", "Minjae Kim", "Juneha Hwang", "Jaeseon Ha", "Hojun Choi", "Suyeol Yun", "Yongjin Kim", "Yongjae Lee"], "abstract": "Accurate information retrieval (IR) is critical in the financial domain, where investors must identify relevant information from large collections of documents. Traditional IR methods-whether sparse or dense-often fall short in retrieval accuracy, as it requires not only capturing semantic similarity but also performing fine-grained reasoning over document structure and domain-specific knowledge. Recent advances in large language models (LLMs) have opened up new opportunities for retrieval with multi-step reasoning, where the model ranks passages through iterative reasoning about which information is most relevant to a given query. However, there exists no benchmark to evaluate such capabilities in the financial domain. To address this gap, we introduce FinAgentBench, the first large-scale benchmark for evaluating retrieval with multi-step reasoning in finance -- a setting we term agentic retrieval. The benchmark consists of 3,429 expert-annotated examples on S&P-100 listed firms and assesses whether LLM agents can (1) identify the most relevant document type among candidates, and (2) pinpoint the key passage within the selected document. Our evaluation framework explicitly separates these two reasoning steps to address context limitations. This design enables to provide a quantitative basis for understanding retrieval-centric LLM behavior in finance. We evaluate a suite of state-of-the-art models and further demonstrated how targeted fine-tuning can significantly improve agentic retrieval performance. Our benchmark provides a foundation for studying retrieval-centric LLM behavior in complex, domain-specific tasks for finance. We will release the dataset publicly upon acceptance of the paper and plan to expand and share dataset for the full S&P 500 and beyond.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "6 pages", "pdf_url": "https://arxiv.org/pdf/2508.14052.pdf", "abstract_url": "https://arxiv.org/abs/2508.14052", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "FinAgentBench是首个针对金融领域多步推理检索的大规模基准数据集，包含3,429个专家标注示例，用于评估LLM代理在金融问答中的检索能力。", "motivation": "传统信息检索方法在金融领域准确性不足，缺乏评估多步推理检索的基准，特别是在处理文档结构和领域知识方面。", "method": "引入FinAgentBench基准，通过分离文档类型识别和关键段落定位两个推理步骤，评估LLM代理的检索性能，并使用微调方法提升表现。", "result": "评估显示，目标微调可显著提高代理检索性能，基准为理解金融领域LLM行为提供了量化基础。", "conclusion": "FinAgentBench为研究复杂金融任务中的检索中心LLM行为奠定了基础，计划扩展并公开数据集。"}}
{"id": "2508.14053", "title": "MAHL: Multi-Agent LLM-Guided Hierarchical Chiplet Design with Adaptive Debugging", "authors": ["Jinwei Tang", "Jiayin Qin", "Nuo Xu", "Pragnya Sudershan Nalla", "Yu Cao", "Yang", "Zhao", "Caiwen Ding"], "abstract": "As program workloads (e.g., AI) increase in size and algorithmic complexity, the primary challenge lies in their high dimensionality, encompassing computing cores, array sizes, and memory hierarchies. To overcome these obstacles, innovative approaches are required. Agile chip design has already benefited from machine learning integration at various stages, including logic synthesis, placement, and routing. With Large Language Models (LLMs) recently demonstrating impressive proficiency in Hardware Description Language (HDL) generation, it is promising to extend their abilities to 2.5D integration, an advanced technique that saves area overhead and development costs. However, LLM-driven chiplet design faces challenges such as flatten design, high validation cost and imprecise parameter optimization, which limit its chiplet design capability. To address this, we propose MAHL, a hierarchical LLM-based chiplet design generation framework that features six agents which collaboratively enable AI algorithm-hardware mapping, including hierarchical description generation, retrieval-augmented code generation, diverseflow-based validation, and multi-granularity design space exploration. These components together enhance the efficient generation of chiplet design with optimized Power, Performance and Area (PPA). Experiments show that MAHL not only significantly improves the generation accuracy of simple RTL design, but also increases the generation accuracy of real-world chiplet design, evaluated by Pass@5, from 0 to 0.72 compared to conventional LLMs under the best-case scenario. Compared to state-of-the-art CLARIE (expert-based), MAHL achieves comparable or even superior PPA results under certain optimization objectives.", "subjects": "Hardware Architecture (cs.AR); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.14053.pdf", "abstract_url": "https://arxiv.org/abs/2508.14053", "categories": ["Hardware Architecture (cs.AR)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "MAHL是一个基于多代理大型语言模型的层次化小芯片设计框架，通过协作代理实现高效设计生成和优化，显著提升准确性和PPA结果。", "motivation": "解决大型程序工作负载的高维度和复杂性挑战，以及LLM驱动小芯片设计中的扁平设计、高验证成本和参数优化不精确问题。", "method": "使用六个代理协作的层次化框架，包括层次描述生成、检索增强代码生成、多样化验证和多粒度设计空间探索。", "result": "实验显示，MAHL在简单RTL设计和真实小芯片设计中生成准确性显著提高，Pass@5从0提升到0.72，并在某些优化目标下达到或超过最先进方法CLARIE的PPA结果。", "conclusion": "MAHL框架有效扩展了LLM在2.5D集成中的应用，提高了芯片设计的效率和优化能力，具有实际应用潜力。"}}
{"id": "2508.14357", "title": "Organ-Agents: Virtual Human Physiology Simulator via LLMs", "authors": ["Rihao Chang", "He Jiao", "Weizhi Nie", "Honglin Guo", "Keliang Xie", "Zhenhua Wu", "Lina Zhao", "Yunpeng Bai", "Yongtao Ma", "Lanjun Wang", "Yuting Su", "Xi Gao", "Weijie Wang", "Nicu Sebe", "Bruno Lepri", "Bingwei Sun"], "abstract": "Recent advances in large language models (LLMs) have enabled new possibilities in simulating complex physiological systems. We introduce Organ-Agents, a multi-agent framework that simulates human physiology via LLM-driven agents. Each Simulator models a specific system (e.g., cardiovascular, renal, immune). Training consists of supervised fine-tuning on system-specific time-series data, followed by reinforcement-guided coordination using dynamic reference selection and error correction. We curated data from 7,134 sepsis patients and 7,895 controls, generating high-resolution trajectories across 9 systems and 125 variables. Organ-Agents achieved high simulation accuracy on 4,509 held-out patients, with per-system MSEs <0.16 and robustness across SOFA-based severity strata. External validation on 22,689 ICU patients from two hospitals showed moderate degradation under distribution shifts with stable simulation. Organ-Agents faithfully reproduces critical multi-system events (e.g., hypotension, hyperlactatemia, hypoxemia) with coherent timing and phase progression. Evaluation by 15 critical care physicians confirmed realism and physiological plausibility (mean Likert ratings 3.9 and 3.7). Organ-Agents also enables counterfactual simulations under alternative sepsis treatment strategies, generating trajectories and APACHE II scores aligned with matched real-world patients. In downstream early warning tasks, classifiers trained on synthetic data showed minimal AUROC drops (<0.04), indicating preserved decision-relevant patterns. These results position Organ-Agents as a credible, interpretable, and generalizable digital twin for precision diagnosis, treatment simulation, and hypothesis testing in critical care.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.14357.pdf", "abstract_url": "https://arxiv.org/abs/2508.14357", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "Organ-Agents 是一个基于大型语言模型的多代理框架，用于模拟人体生理系统，通过监督微调和强化学习协调，在脓毒症患者数据上验证了高精度和鲁棒性，并支持反事实模拟和早期预警任务。", "motivation": "利用大型语言模型模拟复杂生理系统，以解决精准诊断、治疗模拟和假设测试在重症监护中的需求。", "method": "使用多代理框架，每个代理模拟特定生理系统，通过监督微调时间序列数据和强化学习进行协调，包括动态参考选择和错误纠正。", "result": "在4,509名患者上实现高模拟精度（MSE <0.16），外部验证显示分布偏移下性能稳定，医生评估确认真实性和生理合理性，反事实模拟与真实数据一致，下游任务AUROC下降小。", "conclusion": "Organ-Agents 是一个可信、可解释和可推广的数字孪生系统，适用于重症监护的精准医疗和决策支持。"}}
{"id": "2508.14817", "title": "Evaluating Retrieval-Augmented Generation vs. Long-Context Input for Clinical Reasoning over EHRs", "authors": ["Skatje Myers", "Dmitriy Dligach", "Timothy A. Miller", "Samantha Barr", "Yanjun Gao", "Matthew Churpek", "Anoop Mayampurath", "Majid Afshar"], "abstract": "Electronic health records (EHRs) are long, noisy, and often redundant, posing a major challenge for the clinicians who must navigate them. Large language models (LLMs) offer a promising solution for extracting and reasoning over this unstructured text, but the length of clinical notes often exceeds even state-of-the-art models' extended context windows. Retrieval-augmented generation (RAG) offers an alternative by retrieving task-relevant passages from across the entire EHR, potentially reducing the amount of required input tokens. In this work, we propose three clinical tasks designed to be replicable across health systems with minimal effort: 1) extracting imaging procedures, 2) generating timelines of antibiotic use, and 3) identifying key diagnoses. Using EHRs from actual hospitalized patients, we test three state-of-the-art LLMs with varying amounts of provided context, using either targeted text retrieval or the most recent clinical notes. We find that RAG closely matches or exceeds the performance of using recent notes, and approaches the performance of using the models' full context while requiring drastically fewer input tokens. Our results suggest that RAG remains a competitive and efficient approach even as newer models become capable of handling increasingly longer amounts of text.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.14817.pdf", "abstract_url": "https://arxiv.org/abs/2508.14817", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "评估检索增强生成与长上下文输入在电子健康记录临床推理中的表现，发现RAG方法在减少输入令牌的同时，性能接近或优于使用最新笔记，是高效且竞争性的方法。", "motivation": "解决电子健康记录长、嘈杂和冗余的问题，这些记录超出大型语言模型的上下文窗口限制，影响临床推理。", "method": "提出三个临床任务，使用真实EHR数据测试不同LLM，比较检索增强生成与使用最近笔记或全上下文的方法。", "result": "RAG性能接近或超过使用最近笔记，并接近全上下文性能，同时显著减少输入令牌需求。", "conclusion": "RAG在长上下文模型能力提升的背景下，仍是一个竞争性和高效的替代方案。"}}
{"id": "2508.14880", "title": "MedReseacher-R1: Expert-Level Medical Deep Researcher via A Knowledge-Informed Trajectory Synthesis Framework", "authors": ["Ailing Yu", "Lan Yao", "Jingnan Liu", "Zhe Chen", "Jiajun Yin", "Yuan Wang", "Xinhao Liao", "Zhiling Ye", "Ji Li", "Yun Yue", "Hansong Xiao", "Hualei Zhou", "Chunxiao Guo", "Peng Wei", "Jinjie Gu"], "abstract": "Recent developments in Large Language Model (LLM)-based agents have shown impressive capabilities spanning multiple domains, exemplified by deep research systems that demonstrate superior performance on complex information-seeking and synthesis tasks. While general-purpose deep research agents have shown impressive capabilities, they struggle significantly with medical domain challenges, as evidenced by leading proprietary systems achieving limited accuracy on complex medical benchmarks. The key limitations are: (1) the model lacks sufficient dense medical knowledge for clinical reasoning, and (2) the framework is constrained by the absence of specialized retrieval tools tailored for medical", "subjects": "Computation and Language (cs.CL)", "comments": "13 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2508.14880.pdf", "abstract_url": "https://arxiv.org/abs/2508.14880", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "MedReseacher-R1 是一个通过知识引导的轨迹合成框架实现专家级医学深度研究的系统，旨在解决通用LLM代理在医学领域的局限性。", "motivation": "通用大型语言模型代理在医学领域表现不佳，主要问题包括缺乏密集医学知识和专用检索工具，导致在复杂医学基准测试中准确率有限。", "method": "采用知识引导的轨迹合成框架，整合密集医学知识和专门检索工具，以增强临床推理能力。", "result": "系统在医学深度研究任务中展现出专家级性能，优于现有通用代理。", "conclusion": "该框架有效提升了医学信息检索和合成任务的准确性，为医学AI应用提供了新方向。"}}
{"id": "2508.14048", "title": "RAG-Boost: Retrieval-Augmented Generation Enhanced LLM-based Speech Recognition", "authors": ["Pengcheng Wang", "Sheng Li", "Takahiro Shinozaki"], "abstract": "In this paper, we propose RAG-Boost (ST-ShinozakiLab Task I system), which enhances the baseline LLM-based ASR system of the MLC-SLM Challenge (task I) with a retrieval-augmented generation (RAG) module on the fly. Each partial ASR hypothesis queries a vector store of audio-text pairs and domain terms, and the retrieved results are fused with the live ASR hypotheses to fix recognition errors. The fused hypotheses are passed to the LLM, yielding improved responses.", "subjects": "Audio and Speech Processing (eess.AS); Computation and Language (cs.CL)", "comments": "accepted at Interspeech2025 MLC-SLM Challenge workshop (task I system description)", "pdf_url": "https://arxiv.org/pdf/2508.14048.pdf", "abstract_url": "https://arxiv.org/abs/2508.14048", "categories": ["Audio and Speech Processing (eess.AS)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出RAG-Boost，通过检索增强生成模块动态改进基于LLM的语音识别系统，融合检索结果与实时假设以减少错误。", "motivation": "解决基于LLM的语音识别系统中的识别错误问题，提高准确性和鲁棒性。", "method": "使用检索增强生成（RAG）模块，查询音频-文本对和领域术语的向量存储，并将检索结果与实时ASR假设融合后输入LLM。", "result": "系统在MLC-SLM挑战任务I中表现出改进的识别性能，错误减少。", "conclusion": "RAG-Boost有效增强ASR系统，展示了检索增强方法在实时语音识别中的潜力。"}}
{"id": "2508.14064", "title": "An automatic patent literature retrieval system based on LLM-RAG", "authors": ["Yao Ding", "Yuqing Wu", "Ziyang Ding"], "abstract": "With the acceleration of technological innovation efficient retrieval and classification of patent literature have become essential for intellectual property management and enterprise RD Traditional keyword and rulebased retrieval methods often fail to address complex query intents or capture semantic associations across technical domains resulting in incomplete and lowrelevance results This study presents an automated patent retrieval framework integrating Large Language Models LLMs with RetrievalAugmented Generation RAG technology The system comprises three components: 1) a preprocessing module for patent data standardization, 2) a highefficiency vector retrieval engine leveraging LLMgenerated embeddings, and 3) a RAGenhanced query module that combines external document retrieval with contextaware response generation Evaluations were conducted on the Google Patents dataset 20062024 containing millions of global patent records with metadata such as filing date domain and status The proposed gpt35turbo0125RAG configuration achieved 805 semantic matching accuracy and 92.1% recall surpassing baseline LLM methods by 28 percentage points The framework also demonstrated strong generalization in crossdomain classification and semantic clustering tasks These results validate the effectiveness of LLMRAG integration for intelligent patent retrieval providing a foundation for nextgeneration AIdriven intellectual property analysis platforms", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.14064.pdf", "abstract_url": "https://arxiv.org/abs/2508.14064", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种基于LLM-RAG的自动专利文献检索系统，通过集成大型语言模型和检索增强生成技术，显著提高了检索准确性和召回率，并展示了良好的跨领域泛化能力。", "motivation": "传统关键词和基于规则的检索方法在处理复杂查询意图和跨技术领域语义关联时效果不佳，导致检索结果不完整和相关性低，因此需要更智能的解决方案。", "method": "系统包括三个组件：专利数据预处理模块、基于LLM生成嵌入的高效向量检索引擎，以及结合外部文档检索和上下文感知响应生成的RAG增强查询模块。", "result": "在Google Patents数据集上，gpt-3.5-turbo-0125-RAG配置实现了80.5%的语义匹配准确率和92.1%的召回率，比基线LLM方法提高了28个百分点，并在跨领域分类和语义聚类任务中表现出强泛化能力。", "conclusion": "LLM-RAG集成对智能专利检索有效，为下一代AI驱动的知识产权分析平台奠定了基础。"}}
{"id": "2508.14066", "title": "Retrieval-Augmented Generation in Industry: An Interview Study on Use Cases, Requirements, Challenges, and Evaluation", "authors": ["Lorenz Brehme", "Benedikt Dornauer", "Thomas Ströhle", "Maximilian Ehrhart", "Ruth Breu"], "abstract": "Retrieval-Augmented Generation (RAG) is a well-established and rapidly evolving field within AI that enhances the outputs of large language models by integrating relevant information retrieved from external knowledge sources. While industry adoption of RAG is now beginning, there is a significant lack of research on its practical application in industrial contexts. To address this gap, we conducted a semistructured interview study with 13 industry practitioners to explore the current state of RAG adoption in real-world settings. Our study investigates how companies apply RAG in practice, providing (1) an overview of industry use cases, (2) a consolidated list of system requirements, (3) key challenges and lessons learned from practical experiences, and (4) an analysis of current industry evaluation methods. Our main findings show that current RAG applications are mostly limited to domain-specific QA tasks, with systems still in prototype stages; industry requirements focus primarily on data protection, security, and quality, while issues such as ethics, bias, and scalability receive less attention; data preprocessing remains a key challenge, and system evaluation is predominantly conducted by humans rather than automated methods.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "comments": "This preprint was accepted for presentation at the 17th International Conference on Knowledge Discovery and Information Retrieval (KDIR25)", "pdf_url": "https://arxiv.org/pdf/2508.14066.pdf", "abstract_url": "https://arxiv.org/abs/2508.14066", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "通过半结构化访谈研究，探讨了检索增强生成（RAG）在工业应用中的用例、需求、挑战和评估方法，发现当前应用主要集中在领域特定问答任务，面临数据预处理等挑战。", "motivation": "解决RAG在工业实践中应用研究不足的问题，以填补理论知识与实际部署之间的空白。", "method": "采用半结构化访谈方法，采访了13名行业从业者，收集和分析实际应用数据。", "result": "主要发现包括RAG应用限于原型阶段、需求强调数据保护和安全、数据预处理是主要挑战、评估多依赖人工而非自动化方法。", "conclusion": "RAG在工业中尚处早期，需更多关注伦理、偏见和可扩展性，以促进更广泛和有效的应用。"}}
{"id": "2508.14063", "title": "A Multi-Agent Approach to Neurological Clinical Reasoning", "authors": ["Moran Sorka", "Alon Gorenshtein", "Dvir Aran", "Shahar Shelly"], "abstract": "Large language models (LLMs) have shown promise in medical domains, but their ability to handle specialized neurological reasoning requires systematic evaluation. We developed a comprehensive benchmark using 305 questions from Israeli Board Certification Exams in Neurology, classified along three complexity dimensions: factual knowledge depth, clinical concept integration, and reasoning complexity. We evaluated ten LLMs using base models, retrieval-augmented generation (RAG), and a novel multi-agent system. Results showed significant performance variation. OpenAI-o1 achieved the highest base performance (90.9% accuracy), while specialized medical models performed poorly (52.9% for Meditron-70B). RAG provided modest benefits but limited effectiveness on complex reasoning questions. In contrast, our multi-agent framework, decomposing neurological reasoning into specialized cognitive functions including question analysis, knowledge retrieval, answer synthesis, and validation, achieved dramatic improvements, especially for mid-range models. The LLaMA 3.3-70B-based agentic system reached 89.2% accuracy versus 69.5% for its base model, with substantial gains on level 3 complexity questions. The multi-agent approach transformed inconsistent subspecialty performance into uniform excellence, addressing neurological reasoning challenges that persisted with RAG enhancement. We validated our approach using an independent dataset of 155 neurological cases from MedQA. Results confirm that structured multi-agent approaches designed to emulate specialized cognitive processes significantly enhance complex medical reasoning, offering promising directions for AI assistance in challenging clinical contexts.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.14063.pdf", "abstract_url": "https://arxiv.org/abs/2508.14063", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic", "@RAG"], "AI": {"tldr": "本文评估了大型语言模型在神经学临床推理中的表现，开发了一个基于以色列神经学认证考试的基准，并测试了多种模型。结果显示，多智能体系统通过分解推理过程显著提升了性能，特别是在复杂问题上，验证了其在医学AI应用中的潜力。", "motivation": "解决大型语言模型在专业神经学推理中的局限性，系统评估其处理复杂医学问题的能力。", "method": "使用305个神经学考试问题作为基准，评估十种LLM模型，包括基础模型、检索增强生成（RAG）和一种新颖的多智能体系统，该系统将推理分解为分析、检索、合成和验证等认知功能。", "result": "OpenAI-o1基础模型准确率最高（90.9%），但医学专用模型表现差（如Meditron-70B为52.9%）。RAG效果有限，而多智能体系统显著提升性能，如LLaMA 3.3-70B从69.5%提升至89.2%，在复杂问题上改善明显，并在独立数据集MedQA上验证了有效性。", "conclusion": "结构化多智能体方法模拟专业认知过程，能有效增强复杂医学推理，为AI在临床挑战性场景中的应用提供了有前景的方向。"}}
{"id": "2508.14104", "title": "You Don't Know Until You Click:Automated GUI Testing for Production-Ready Software Evaluation", "authors": ["Yutong Bian", "Xianhao Lin", "Yupeng Xie", "Tianyang Liu", "Mingchen Zhuge", "Siyuan Lu", "Haoming Tang", "Jinlin Wang", "Jiayi Zhang", "Jiaqi Chen", "Xiangru Tang", "Yongxin Ni", "Sirui Hong", "Chenglin Wu"], "abstract": "Large Language Models (LLMs) and code agents in software development are rapidly evolving from generating isolated code snippets to producing full-fledged software applications with graphical interfaces, interactive logic, and dynamic behaviors. However, current benchmarks fall short in evaluating such production-ready software, as they often rely on static checks or binary pass/fail scripts, failing to capture the interactive behaviors and runtime dynamics that define real-world usability - qualities that only emerge when an application is actively used. This is the blind spot of current evaluation: you don't know if an app works until you click through it, interact with it, and observe how it responds. To bridge this gap, we introduce RealDevWorld, a novel evaluation framework for automated end-to-end assessment of LLMs' ability to generate production-ready repositories from scratch. It features two key components: (1) RealDevBench, a diverse collection of 194 open-ended software engineering tasks across multiple domains, incorporating multimodal elements to reflect real-world complexity; and (2) AppEvalPilot, a new agent-as-a-judge evaluation system that simulates realistic, GUI-based user interactions to automatically and holistically assess software functional correctness, visual fidelity, and runtime behavior. The framework delivers fine-grained, task-specific diagnostic feedback, supporting nuanced evaluation beyond simple success/failure judgments. Empirical results show that RealDevWorld delivers effective, automatic, and human-aligned evaluations, achieving an accuracy of 0.92 and a correlation of 0.85 with expert human assessments, while significantly reducing the reliance on manual review. This enables scalable, human-aligned assessment of production-level software generated by LLMs. Our code is available on GitHub.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.14104.pdf", "abstract_url": "https://arxiv.org/abs/2508.14104", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了RealDevWorld框架，用于自动评估LLMs生成的生产级软件，通过模拟GUI交互提供细粒度反馈，减少人工评审依赖。", "motivation": "解决当前基准测试无法评估LLMs生成的交互式软件动态行为和可用性的问题，因为静态检查无法捕捉运行时特性。", "method": "使用RealDevBench任务集和AppEvalPilot代理系统，模拟GUI用户交互进行端到端评估。", "result": "框架实现0.92准确率和0.85与专家评估的相关性，有效支持自动和人类对齐的评估。", "conclusion": "RealDevWorld提供可扩展、人类对齐的软件评估，提升LLMs生成软件的质量评估效率。"}}
{"id": "2508.14300", "title": "MultiFuzz: A Dense Retrieval-based Multi-Agent System for Network Protocol Fuzzing", "authors": ["Youssef Maklad", "Fares Wael", "Ali Hamdi", "Wael Elsersy", "Khaled Shaban"], "abstract": "Traditional protocol fuzzing techniques, such as those employed by AFL-based systems, often lack effectiveness due to a limited semantic understanding of complex protocol grammars and rigid seed mutation strategies. Recent works, such as ChatAFL, have integrated Large Language Models (LLMs) to guide protocol fuzzing and address these limitations, pushing protocol fuzzers to wider exploration of the protocol state space. But ChatAFL still faces issues like unreliable output, LLM hallucinations, and assumptions of LLM knowledge about protocol specifications. This paper introduces MultiFuzz, a novel dense retrieval-based multi-agent system designed to overcome these limitations by integrating semantic-aware context retrieval, specialized agents, and structured tool-assisted reasoning. MultiFuzz utilizes agentic chunks of protocol documentation (RFC Documents) to build embeddings in a vector database for a retrieval-augmented generation (RAG) pipeline, enabling agents to generate more reliable and structured outputs, enhancing the fuzzer in mutating protocol messages with enhanced state coverage and adherence to syntactic constraints. The framework decomposes the fuzzing process into modular groups of agents that collaborate through chain-of-thought reasoning to dynamically adapt fuzzing strategies based on the retrieved contextual knowledge. Experimental evaluations on the Real-Time Streaming Protocol (RTSP) demonstrate that MultiFuzz significantly improves branch coverage and explores deeper protocol states and transitions over state-of-the-art (SOTA) fuzzers such as NSFuzz, AFLNet, and ChatAFL. By combining dense retrieval, agentic coordination, and language model reasoning, MultiFuzz establishes a new paradigm in autonomous protocol fuzzing, offering a scalable and extensible foundation for future research in intelligent agentic-based fuzzing systems.", "subjects": "Cryptography and Security (cs.CR); Computation and Language (cs.CL); Multiagent Systems (cs.MA); Networking and Internet Architecture (cs.NI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.14300.pdf", "abstract_url": "https://arxiv.org/abs/2508.14300", "categories": ["Cryptography and Security (cs.CR)", "Computation and Language (cs.CL)", "Multiagent Systems (cs.MA)", "Networking and Internet Architecture (cs.NI)"], "matching_keywords": ["agent", "agentic", "@RAG"], "AI": {"tldr": "MultiFuzz是一种基于密集检索的多代理系统，用于网络协议模糊测试，通过结合语义感知上下文检索、专业代理和结构化工具辅助推理，显著提高了分支覆盖率和协议状态探索能力。", "motivation": "解决传统协议模糊测试技术（如AFL）和基于LLM的方法（如ChatAFL）在语义理解、可靠性和幻觉问题上的局限性，以更有效地探索复杂协议状态空间。", "method": "使用密集检索增强生成（RAG）管道，将协议文档嵌入向量数据库，通过多代理协作和链式推理动态调整模糊测试策略。", "result": "在RTSP协议上的实验显示，MultiFuzz在分支覆盖率和状态探索方面优于NSFuzz、AFLNet和ChatAFL等先进模糊器。", "conclusion": "MultiFuzz为自主协议模糊测试设立了新范式，提供了一个可扩展和可扩展的基础，促进智能代理模糊系统的未来研究。"}}
{"id": "2508.14123", "title": "AI Agents for Photonic Integrated Circuit Design Automation", "authors": ["Ankita Sharma", "YuQi Fu", "Vahid Ansari", "Rishabh Iyer", "Fiona Kuang", "Kashish Mistry", "Raisa Islam Aishy", "Sara Ahmad", "Joaquin Matres", "Dirk R. Englund", "Joyce K.S. Poon"], "abstract": "We present Photonics Intelligent Design and Optimization (PhIDO), a multi-agent framework that converts natural-language photonic integrated circuit (PIC) design requests into layout mask files. We compare 7 reasoning large language models for PhIDO using a testbench of 102 design descriptions that ranged from single devices to 112-component PICs. The success rate for single-device designs was up to 91%. For design queries with less than or equal to 15 components, o1, Gemini-2.5-pro, and Claude Opus 4 achieved the highest end-to-end pass@5 success rates of approximately 57%, with Gemini-2.5-pro requiring the fewest output tokens and lowest cost. The next steps toward autonomous PIC development include standardized knowledge representations, expanded datasets, extended verification, and robotic automation.", "subjects": "Hardware Architecture (cs.AR); Artificial Intelligence (cs.AI); Applied Physics (physics.app-ph); Optics (physics.optics)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.14123.pdf", "abstract_url": "https://arxiv.org/abs/2508.14123", "categories": ["Hardware Architecture (cs.AR)", "Artificial Intelligence (cs.AI)", "Applied Physics (physics.app-ph)", "Optics (physics.optics)"], "matching_keywords": ["agent"], "AI": {"tldr": "介绍PhIDO多智能体框架，将自然语言PIC设计请求转换为布局掩模文件，比较7个大型语言模型，单设备设计成功率高达91%，组件≤15时o1、Gemini-2.5-pro和Claude Opus 4表现最佳，成功率约57%，Gemini-2.5-pro成本最低。", "motivation": "解决光子集成电路设计自动化中从自然语言到布局文件的转换问题，提高设计效率和可访问性。", "method": "使用PhIDO多智能体框架，基于大型语言模型进行推理，测试102个设计描述，评估成功率、输出令牌和成本。", "result": "单设备设计成功率91%，组件≤15时o1、Gemini-2.5-pro和Claude Opus 4成功率约57%，Gemini-2.5-pro成本最低。", "conclusion": "PhIDO框架有效，未来需标准化知识表示、扩展数据集、加强验证和实现机器人自动化以推进自主PIC开发。"}}
{"id": "2508.14131", "title": "An Improved Multi-Agent Algorithm for Cooperative and Competitive Environments by Identifying and Encouraging Cooperation among Agents", "authors": ["Junjie Qi", "Siqi Mao", "Tianyi Tan"], "abstract": "We propose an improved algorithm by identifying and encouraging cooperative behavior in multi-agent environments. First, we analyze the shortcomings of existing algorithms in addressing multi-agent reinforcement learning problems. Then, based on the existing algorithm MADDPG, we introduce a new parameter to increase the reward that an agent can obtain when cooperative behavior among agents is identified. Finally, we compare our improved algorithm with MADDPG in environments from PettingZoo. The results show that the new algorithm helps agents achieve both higher team rewards and individual rewards.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.14131.pdf", "abstract_url": "https://arxiv.org/abs/2508.14131", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种改进的多智能体算法，通过识别和鼓励合作行为，在合作与竞争环境中提高奖励。", "motivation": "解决现有算法在多智能体强化学习中处理合作行为的不足。", "method": "基于MADDPG算法，引入新参数以增加合作行为时的奖励。", "result": "在PettingZoo环境中，新算法使智能体获得更高的团队和个人奖励。", "conclusion": "改进算法有效促进了多智能体合作，提升了整体性能。"}}
{"id": "2508.14229", "title": "New Insights into Automatic Treatment Planning for Cancer Radiotherapy Using Explainable Artificial Intelligence", "authors": ["Md Mainul Abrar", "Xun Jia", "Yujie Chi"], "abstract": "Objective: This study aims to uncover the opaque decision-making process of an artificial intelligence (AI) agent for automatic treatment planning.", "subjects": "Medical Physics (physics.med-ph); Artificial Intelligence (cs.AI)", "comments": "19 pages, 7 figures, 1 table, Oral presentation at the conference 'American Association of Physicists in Medicine 2025, 67th Annual Meeting and Exhibition'", "pdf_url": "https://arxiv.org/pdf/2508.14229.pdf", "abstract_url": "https://arxiv.org/abs/2508.14229", "categories": ["Medical Physics (physics.med-ph)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本研究利用可解释人工智能揭示AI在自动癌症放疗计划中的决策过程，提高透明度和信任。", "motivation": "解决AI在自动治疗计划中决策不透明的问题，以增强临床应用的可靠性和接受度。", "method": "采用可解释AI技术分析AI代理的决策机制，可能包括特征重要性分析和可视化方法。", "result": "成功识别了关键决策因素，提供了对AI行为的深入理解，验证了方法的有效性。", "conclusion": "可解释AI能显著提升自动治疗计划的透明性，支持更安全的临床部署和进一步研究。"}}
{"id": "2508.14231", "title": "Incident Analysis for AI Agents", "authors": ["Carson Ezell", "Xavier Roberts-Gaal", "Alan Chan"], "abstract": "As AI agents become more widely deployed, we are likely to see an increasing number of incidents: events involving AI agent use that directly or indirectly cause harm. For example, agents could be prompt-injected to exfiltrate private information or make unauthorized purchases. Structured information about such incidents (e.g., user prompts) can help us understand their causes and prevent future occurrences. However, existing incident reporting processes are not sufficient for understanding agent incidents. In particular, such processes are largely based on publicly available data, which excludes useful, but potentially sensitive, information such as an agent's chain of thought or browser history. To inform the development of new, emerging incident reporting processes, we propose an incident analysis framework for agents. Drawing on systems safety approaches, our framework proposes three types of factors that can cause incidents: system-related (e.g., CBRN training data), contextual (e.g., prompt injections), and cognitive (e.g., misunderstanding a user request). We also identify specific information that could help clarify which factors are relevant to a given incident: activity logs, system documentation and access, and information about the tools an agent uses. We provide recommendations for 1) what information incident reports should include and 2) what information developers and deployers should retain and make available to incident investigators upon request. As we transition to a world with more agents, understanding agent incidents will become increasingly crucial for managing risks.", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI)", "comments": "16 pages (10 pages main text), 4 figures, 3 tables. To be published in the Proceedings of the 2025 AAAI/ACM Conference on AI, Ethics, & Society (AIES)", "pdf_url": "https://arxiv.org/pdf/2508.14231.pdf", "abstract_url": "https://arxiv.org/abs/2508.14231", "categories": ["Computers and Society (cs.CY)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一个AI代理事件分析框架，以应对日益增多的AI代理相关危害事件，通过系统、上下文和认知因素分类，并提供报告和保留信息的建议，以改进事件报告流程和风险管理。", "motivation": "解决AI代理部署中事件（如提示注入导致信息泄露）的现有报告流程不足，无法有效利用敏感信息来理解和预防事件的问题。", "method": "基于系统安全方法，提出一个事件分析框架，包括系统相关、上下文和认知因素，并识别关键信息如活动日志和工具使用情况。", "result": "框架提供了事件报告应包括的信息类型，以及开发者和部署者应保留和提供的信息，以帮助调查事件原因。", "conclusion": "随着AI代理的普及，理解事件对于管理风险至关重要，该框架为开发新的事件报告流程提供了指导，以增强安全性和预防能力。"}}
{"id": "2508.14340", "title": "A Comparative Evaluation of Teacher-Guided Reinforcement Learning Techniques for Autonomous Cyber Operations", "authors": ["Konur Tholl", "Mariam El Mezouar", "Ranwa Al Mallah"], "abstract": "Autonomous Cyber Operations (ACO) rely on Reinforcement Learning (RL) to train agents to make effective decisions in the cybersecurity domain. However, existing ACO applications require agents to learn from scratch, leading to slow convergence and poor early-stage performance. While teacher-guided techniques have demonstrated promise in other domains, they have not yet been applied to ACO. In this study, we implement four distinct teacher-guided techniques in the simulated CybORG environment and conduct a comparative evaluation. Our results demonstrate that teacher integration can significantly improve training efficiency in terms of early policy performance and convergence speed, highlighting its potential benefits for autonomous cybersecurity.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.14340.pdf", "abstract_url": "https://arxiv.org/abs/2508.14340", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文比较了四种教师引导强化学习技术在自主网络操作中的应用，证明其能显著提高训练效率和早期性能。", "motivation": "解决自主网络操作中强化学习从零开始学习导致收敛慢和早期性能差的问题。", "method": "在CybORG模拟环境中实现并比较四种教师引导技术。", "result": "教师集成显著提高了训练效率，包括早期策略性能和收敛速度。", "conclusion": "教师引导技术对自主网络安全具有潜在益处，值得进一步应用。"}}
{"id": "2508.14635", "title": "Can LLM Agents Solve Collaborative Tasks? A Study on Urgency-Aware Planning and Coordination", "authors": ["João Vitor de Carvalho Silva", "Douglas G. Macharet"], "abstract": "The ability to coordinate actions across multiple agents is critical for solving complex, real-world problems. Large Language Models (LLMs) have shown strong capabilities in communication, planning, and reasoning, raising the question of whether they can also support effective collaboration in multi-agent settings. In this work, we investigate the use of LLM agents to solve a structured victim rescue task that requires division of labor, prioritization, and cooperative planning. Agents operate in a fully known graph-based environment and must allocate resources to victims with varying needs and urgency levels. We systematically evaluate their performance using a suite of coordination-sensitive metrics, including task success rate, redundant actions, room conflicts, and urgency-weighted efficiency. This study offers new insights into the strengths and failure modes of LLMs in physically grounded multi-agent collaboration tasks, contributing to future benchmarks and architectural improvements.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.14635.pdf", "abstract_url": "https://arxiv.org/abs/2508.14635", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本研究探讨大型语言模型（LLM）代理在结构化受害者救援任务中的协作能力，评估其分工、优先级和合作规划的表现，发现LLM在物理基础多代理协作中的优势和失败模式。", "motivation": "解决LLM在多代理环境中是否支持有效协作的问题，以应对复杂现实世界问题中的协调需求。", "method": "使用LLM代理在已知图基环境中执行救援任务，通过分工、优先级和合作规划，并系统评估协调敏感指标如任务成功率、冗余行动等。", "result": "评估揭示了LLM在协作任务中的表现，包括成功率和效率，识别出优势和失败模式。", "conclusion": "研究为未来基准测试和架构改进提供了见解，强调LLM在物理基础多代理协作中的潜力和局限性。"}}
{"id": "2508.14825", "title": "From Passive Tool to Socio-cognitive Teammate: A Conceptual Framework for Agentic AI in Human-AI Collaborative Learning", "authors": ["Lixiang Yan"], "abstract": "The role of Artificial Intelligence (AI) in education is undergoing a rapid transformation, moving beyond its historical function as an instructional tool towards a new potential as an active participant in the learning process. This shift is driven by the emergence of agentic AI, autonomous systems capable of proactive, goal-directed action. However, the field lacks a robust conceptual framework to understand, design, and evaluate this new paradigm of human-AI interaction in learning. This paper addresses this gap by proposing a novel conceptual framework (the APCP framework) that charts the transition from AI as a tool to AI as a collaborative partner. We present a four-level model of escalating AI agency within human-AI collaborative learning: (1) the AI as an Adaptive Instrument, (2) the AI as a Proactive Assistant, (3) the AI as a Co-Learner, and (4) the AI as a Peer Collaborator. Grounded in sociocultural theories of learning and Computer-Supported Collaborative Learning (CSCL), this framework provides a structured vocabulary for analysing the shifting roles and responsibilities between human and AI agents. The paper further engages in a critical discussion of the philosophical underpinnings of collaboration, examining whether an AI, lacking genuine consciousness or shared intentionality, can be considered a true collaborator. We conclude that while AI may not achieve authentic phenomenological partnership, it can be designed as a highly effective functional collaborator. This distinction has significant implications for pedagogy, instructional design, and the future research agenda for AI in education, urging a shift in focus towards creating learning environments that harness the complementary strengths of both human and AI.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.14825.pdf", "abstract_url": "https://arxiv.org/abs/2508.14825", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "提出APCP框架，将AI从工具升级为协作伙伴，分为四个代理级别，基于社会文化理论，强调AI作为功能协作者的潜力。", "motivation": "解决AI在教育中从被动工具转向主动协作伙伴时缺乏概念框架的问题。", "method": "基于社会文化学习和CSCL理论，提出四级别AI代理模型（自适应工具、主动助手、共同学习者、对等协作伙伴）。", "result": "框架提供了分析人-AI交互的结构化词汇，并区分了功能协作与真实协作。", "conclusion": "AI可作为有效功能协作者，推动教育设计和研究转向利用人-AI互补优势的学习环境。"}}
