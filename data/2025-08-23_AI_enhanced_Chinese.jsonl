{"id": "2508.15243", "title": "Comp-X: On Defining an Interactive Learned Image Compression Paradigm With Expert-driven LLM Agent", "authors": ["Yixin Gao", "Xin Li", "Xiaohan Pan", "Runsen Feng", "Bingchen Li", "Yunpeng Qi", "Yiting Lu", "Zhengxue Cheng", "Zhibo Chen", "Jörn Ostermann"], "abstract": "We present Comp-X, the first intelligently interactive image compression paradigm empowered by the impressive reasoning capability of large language model (LLM) agent. Notably, commonly used image codecs usually suffer from limited coding modes and rely on manual mode selection by engineers, making them unfriendly for unprofessional users. To overcome this, we advance the evolution of image coding paradigm by introducing three key innovations: (i) multi-functional coding framework, which unifies different coding modes of various objective/requirements, including human-machine perception, variable coding, and spatial bit allocation, into one framework. (ii) interactive coding agent, where we propose an augmented in-context learning method with coding expert feedback to teach the LLM agent how to understand the coding request, mode selection, and the use of the coding tools. (iii) IIC-bench, the first dedicated benchmark comprising diverse user requests and the corresponding annotations from coding experts, which is systematically designed for intelligently interactive image compression evaluation. Extensive experimental results demonstrate that our proposed Comp-X can understand the coding requests efficiently and achieve impressive textual interaction capability. Meanwhile, it can maintain comparable compression performance even with a single coding framework, providing a promising avenue for artificial general intelligence (AGI) in image compression.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.15243.pdf", "abstract_url": "https://arxiv.org/abs/2508.15243", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "Comp-X是首个基于大型语言模型代理的智能交互式图像压缩范式，通过统一编码框架、交互式代理和专用基准测试，实现高效请求理解和压缩性能。", "motivation": "解决传统图像编解码器编码模式有限且依赖工程师手动选择，对非专业用户不友好的问题。", "method": "引入多功能编码框架统一不同模式，使用增强上下文学习训练LLM代理，并开发IIC-bench基准进行系统评估。", "result": "实验显示Comp-X能高效理解编码请求，保持可比压缩性能，并展示出色的文本交互能力。", "conclusion": "Comp-X为图像压缩中的人工通用智能提供了有前景的途径，推动范式演进。"}}
{"id": "2508.15313", "title": "First RAG, Second SEG: A Training-Free Paradigm for Camouflaged Object Detection", "authors": ["Wutao Liu", "YiDan Wang", "Pan Gao"], "abstract": "Camouflaged object detection (COD) poses a significant challenge in computer vision due to the high similarity between objects and their backgrounds. Existing approaches often rely on heavy training and large computational resources. While foundation models such as the Segment Anything Model (SAM) offer strong generalization, they still struggle to handle COD tasks without fine-tuning and require high-quality prompts to yield good performance. However, generating such prompts manually is costly and inefficient. To address these challenges, we propose \\textbf{First RAG, Second SEG (RAG-SEG)}, a training-free paradigm that decouples COD into two stages: Retrieval-Augmented Generation (RAG) for generating coarse masks as prompts, followed by SAM-based segmentation (SEG) for refinement. RAG-SEG constructs a compact retrieval database via unsupervised clustering, enabling fast and effective feature retrieval. During inference, the retrieved features produce pseudo-labels that guide precise mask generation using SAM2. Our method eliminates the need for conventional training while maintaining competitive performance. Extensive experiments on benchmark COD datasets demonstrate that RAG-SEG performs on par with or surpasses state-of-the-art methods. Notably, all experiments are conducted on a \\textbf{personal laptop}, highlighting the computational efficiency and practicality of our approach. We present further analysis in the Appendix, covering limitations, salient object detection extension, and possible improvements.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.15313.pdf", "abstract_url": "https://arxiv.org/abs/2508.15313", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "提出RAG-SEG，一种无需训练的伪装目标检测范式，通过检索增强生成粗掩码作为提示，再使用SAM进行精炼，在基准数据集上性能媲美或超越现有方法，计算高效，可在个人笔记本电脑上运行。", "motivation": "解决伪装目标检测中现有方法依赖大量训练和计算资源，以及基础模型如SAM需要高质量提示的问题。", "method": "使用两阶段方法：RAG阶段通过无监督聚类构建检索数据库生成粗掩码作为提示，SEG阶段使用SAM2进行精炼分割。", "result": "在基准数据集上，RAG-SEG性能与或优于最先进方法，且计算高效，可在个人笔记本电脑上实现。", "conclusion": "RAG-SEG提供了一种无需训练的高效伪装目标检测方案，具有实际应用潜力，附录讨论了局限性和改进方向。"}}
{"id": "2508.15207", "title": "Adversarial Agent Behavior Learning in Autonomous Driving Using Deep Reinforcement Learning", "authors": ["Arjun Srinivasan", "Anubhav Paras", "Aniket Bera"], "abstract": "Existing approaches in reinforcement learning train an agent to learn desired optimal behavior in an environment with rule based surrounding agents. In safety critical applications such as autonomous driving it is crucial that the rule based agents are modelled properly. Several behavior modelling strategies and IDM models are used currently to model the surrounding agents. We present a learning based method to derive the adversarial behavior for the rule based agents to cause failure scenarios. We evaluate our adversarial agent against all the rule based agents and show the decrease in cumulative reward.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.15207.pdf", "abstract_url": "https://arxiv.org/abs/2508.15207", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出一种基于深度强化学习的方法，用于在自动驾驶中学习对抗性行为，以测试基于规则的代理，并展示其导致累积奖励下降。", "motivation": "解决在安全关键应用中，如自动驾驶，如何有效建模基于规则周围代理的对抗行为以识别失败场景的问题。", "method": "使用基于学习的方法（可能涉及深度强化学习）推导基于规则代理的对抗行为，并对其进行评估。", "result": "评估显示，对抗代理导致基于规则代理的累积奖励减少，表明能有效引发失败场景。", "conclusion": "该方法有助于提高自动驾驶系统的鲁棒性，通过识别和测试潜在的安全漏洞。"}}
{"id": "2508.15013", "title": "Goals and the Structure of Experience", "authors": ["Nadav Amir", "Stas Tiomkin", "Angela Langdon"], "abstract": "Purposeful behavior is a hallmark of natural and artificial intelligence. Its acquisition is often believed to rely on world models, comprising both descriptive (what is) and prescriptive (what is desirable) aspects that identify and evaluate state of affairs in the world, respectively. Canonical computational accounts of purposeful behavior, such as reinforcement learning, posit distinct components of a world model comprising a state representation (descriptive aspect) and a reward function (prescriptive aspect). However, an alternative possibility, which has not yet been computationally formulated, is that these two aspects instead co-emerge interdependently from an agent's goal. Here, we describe a computational framework of goal-directed state representation in cognitive agents, in which the descriptive and prescriptive aspects of a world model co-emerge from agent-environment interaction sequences, or experiences. Drawing on Buddhist epistemology, we introduce a construct of goal-directed, or telic, states, defined as classes of goal-equivalent experience distributions. Telic states provide a parsimonious account of goal-directed learning in terms of the statistical divergence between behavioral policies and desirable experience features. We review empirical and theoretical literature supporting this novel perspective and discuss its potential to provide a unified account of behavioral, phenomenological and neural dimensions of purposeful behaviors across diverse substrates.", "subjects": "Artificial Intelligence (cs.AI); Neurons and Cognition (q-bio.NC)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.15013.pdf", "abstract_url": "https://arxiv.org/abs/2508.15013", "categories": ["Artificial Intelligence (cs.AI)", "Neurons and Cognition (q-bio.NC)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出一种基于目标导向状态表示的计算框架，描述性和规范性方面从经验中共同涌现，借鉴佛教认识论，提供对目的性行为的统一解释。", "motivation": "解决传统强化学习等模型中状态表示和奖励函数分离的问题，探索描述性和规范性方面如何从目标中共同涌现。", "method": "引入目标导向状态（telic states）概念，基于经验分布和统计差异，构建计算框架。", "result": "框架能统一解释行为、现象学和神经维度，支持目的性行为的学习和表示。", "conclusion": "该框架为人工智能和认知科学提供新视角，强调目标在模型构建中的核心作用。"}}
{"id": "2508.15047", "title": "Emergent Crowds Dynamics from Language-Driven Multi-Agent Interactions", "authors": ["Yibo Liu", "Liam Shatzel", "Brandon Haworth", "Teseo Schneider"], "abstract": "Animating and simulating crowds using an agent-based approach is a well-established area where every agent in the crowd is individually controlled such that global human-like behaviour emerges. We observe that human navigation and movement in crowds are often influenced by complex social and environmental interactions, driven mainly by language and dialogue. However, most existing work does not consider these dimensions and leads to animations where agent-agent and agent-environment interactions are largely limited to steering and fixed higher-level goal extrapolation.", "subjects": "Artificial Intelligence (cs.AI); Graphics (cs.GR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.15047.pdf", "abstract_url": "https://arxiv.org/abs/2508.15047", "categories": ["Artificial Intelligence (cs.AI)", "Graphics (cs.GR)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文提出一种基于语言驱动的多智能体交互方法，用于模拟人群动态，以更真实地捕捉人类在人群中的导航和移动行为。", "motivation": "解决现有基于智能体的人群模拟方法中，智能体间和智能体与环境交互局限于转向和固定高层目标的问题，这些方法忽略了语言和对话驱动的复杂社会和环境交互。", "method": "使用语言驱动的多智能体交互方法，扩展传统基于智能体的模拟，以整合语言和对话因素，从而生成更逼真的人群行为。", "result": "通过语言驱动的方法，实现了更真实和动态的人群动画，智能体交互更加复杂和类似人类。", "conclusion": "语言驱动的多智能体交互能显著提升人群模拟的真实性，为动画和模拟领域提供新方向。"}}
{"id": "2508.15030", "title": "Collab-REC: An LLM-based Agentic Framework for Balancing Recommendations in Tourism", "authors": ["Ashmi Banerjee", "Fitri Nur Aisyah", "Adithi Satish", "Wolfgang Wörndl", "Yashar Deldjoo"], "abstract": "We propose Collab-REC, a multi-agent framework designed to counteract popularity bias and enhance diversity in tourism recommendations. In our setting, three LLM-based agents -- Personalization, Popularity, and Sustainability generate city suggestions from complementary perspectives. A non-LLM moderator then merges and refines these proposals via multi-round negotiation, ensuring each agent's viewpoint is incorporated while penalizing spurious or repeated responses. Experiments on European city queries show that Collab-REC improves diversity and overall relevance compared to a single-agent baseline, surfacing lesser-visited locales that often remain overlooked. This balanced, context-aware approach addresses over-tourism and better aligns with constraints provided by the user, highlighting the promise of multi-stakeholder collaboration in LLM-driven recommender systems.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.15030.pdf", "abstract_url": "https://arxiv.org/abs/2508.15030", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "提出Collab-REC，一个基于LLM的多智能体框架，用于平衡旅游推荐中的多样性和相关性，通过三个智能体和一个非LLM调解器进行协商，实验显示能提升推荐质量。", "motivation": "解决旅游推荐系统中的流行性偏见问题，提高多样性并应对过度旅游，以更好地满足用户约束。", "method": "使用三个基于LLM的智能体（个性化、流行性、可持续性）从不同角度生成建议，并通过非LLM调解器进行多轮协商合并和优化。", "result": "在欧洲城市查询实验中，Collab-REC相比单智能体基线提高了多样性和整体相关性，突出了较少访问的地点。", "conclusion": "该方法展示了多利益相关者协作在LLM驱动推荐系统中的潜力，能有效平衡推荐并应对现实约束。"}}
{"id": "2508.15068", "title": "S3LoRA: Safe Spectral Sharpness-Guided Pruning in Adaptation of Agent Planner", "authors": ["Shuang Ao", "Gopal Rumchurn"], "abstract": "Adapting Large Language Models (LLMs) using parameter-efficient fine-tuning (PEFT) techniques such as LoRA has enabled powerful capabilities in LLM-based agents. However, these adaptations can unintentionally compromise safety alignment, leading to unsafe or unstable behaviors, particularly in agent planning tasks. Existing safety-aware adaptation methods often require access to both base and instruction-tuned model checkpoints, which are frequently unavailable in practice, limiting their applicability. We propose S3LoRA (Safe Spectral Sharpness-Guided Pruning LoRA), a lightweight, data-free, and model-independent framework that mitigates safety risks in LoRA-adapted models by inspecting only the fine-tuned weight updates. We first introduce Magnitude-Aware Spherically Normalized SVD (MAS-SVD), which robustly analyzes the structural properties of LoRA updates while preserving global magnitude information. We then design the Spectral Sharpness Index (SSI), a sharpness-aware metric to detect layers with highly concentrated and potentially unsafe updates. These layers are pruned post-hoc to reduce risk without sacrificing task performance. Extensive experiments and ablation studies across agent planning and language generation tasks show that S3LoRA consistently improves safety metrics while maintaining or improving utility metrics and significantly reducing inference cost. These results establish S3LoRA as a practical and scalable solution for safely deploying LLM-based agents in real-world, resource-constrained, and safety-critical environments.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "9 pages, 2 figures", "pdf_url": "https://arxiv.org/pdf/2508.15068.pdf", "abstract_url": "https://arxiv.org/abs/2508.15068", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "S3LoRA是一种轻量级、数据无关且模型无关的框架，通过分析LoRA更新来减少安全风险，提高LLM代理的安全性而不牺牲性能。", "motivation": "解决LLM基于代理的规划任务中，参数高效微调（如LoRA）可能无意中损害安全对齐，导致不安全或不稳定行为的问题，且现有方法常需访问不可用的模型检查点。", "method": "提出S3LoRA框架，包括MAS-SVD分析LoRA更新结构，设计SSI指标检测潜在不安全层，并进行后剪枝以降低风险。", "result": "实验显示S3LoRA在代理规划和语言生成任务中一致改善安全指标，保持或提升效用指标，并显著减少推理成本。", "conclusion": "S3LoRA是实用且可扩展的解决方案，适用于现实世界、资源受限和安全关键环境中的LLM代理安全部署。"}}
{"id": "2508.15119", "title": "Open-Universe Assistance Games", "authors": ["Rachel Ma", "Jingyi Qu", "Andreea Bobu", "Dylan Hadfield-Menell"], "abstract": "Embodied AI agents must infer and act in an interpretable way on diverse human goals and preferences that are not predefined. To formalize this setting, we introduce Open-Universe Assistance Games (OU-AGs), a framework where the agent must reason over an unbounded and evolving space of possible goals. In this context, we introduce GOOD (GOals from Open-ended Dialogue), a data-efficient, online method that extracts goals in the form of natural language during an interaction with a human, and infers a distribution over natural language goals. GOOD prompts an LLM to simulate users with different complex intents, using its responses to perform probabilistic inference over candidate goals. This approach enables rich goal representations and uncertainty estimation without requiring large offline datasets. We evaluate GOOD in a text-based grocery shopping domain and in a text-operated simulated household robotics environment (AI2Thor), using synthetic user profiles. Our method outperforms a baseline without explicit goal tracking, as confirmed by both LLM-based and human evaluations.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Robotics (cs.RO)", "comments": "7 pages + 2 pages references + 7 pages appendix", "pdf_url": "https://arxiv.org/pdf/2508.15119.pdf", "abstract_url": "https://arxiv.org/abs/2508.15119", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了Open-Universe Assistance Games（OU-AGs）框架和GOOD方法，用于在开放目标空间中通过自然语言对话高效推断人类目标，并在模拟环境中验证其优于基线。", "motivation": "解决具身AI代理在未预定义目标下推断和解释人类多样化目标和偏好的问题。", "method": "使用GOOD方法，基于LLM模拟用户意图，通过在线对话提取自然语言目标并进行概率推断。", "result": "在文本购物和模拟家庭机器人环境中，GOOD方法在LLM和人类评估中优于无显式目标跟踪的基线。", "conclusion": "GOOD方法支持丰富目标表示和不确定性估计，无需大型离线数据集，提升了AI代理的交互能力。"}}
{"id": "2508.15126", "title": "aiXiv: A Next-Generation Open Access Ecosystem for Scientific Discovery Generated by AI Scientists", "authors": ["Pengsong Zhang", "Xiang Hu", "Guowei Huang", "Yang Qi", "Heng Zhang", "Xiuxu Li", "Jiaxing Song", "Jiabin Luo", "Yijiang Li", "Shuo Yin", "Chengxiao Dai", "Eric Hanchen Jiang", "Xiaoyan Zhou", "Zhenfei Yin", "Boqin Yuan", "Jing Dong", "Guinan Su", "Guanren Qiao", "Haiming Tang", "Anghong Du", "Lili Pan", "Zhenzhong Lan", "Xinyu Liu"], "abstract": "Recent advances in large language models (LLMs) have enabled AI agents to autonomously generate scientific proposals, conduct experiments, author papers, and perform peer reviews. Yet this flood of AI-generated research content collides with a fragmented and largely closed publication ecosystem. Traditional journals and conferences rely on human peer review, making them difficult to scale and often reluctant to accept AI-generated research content; existing preprint servers (e.g. arXiv) lack rigorous quality-control mechanisms. Consequently, a significant amount of high-quality AI-generated research lacks appropriate venues for dissemination, hindering its potential to advance scientific progress. To address these challenges, we introduce aiXiv, a next-generation open-access platform for human and AI scientists. Its multi-agent architecture allows research proposals and papers to be submitted, reviewed, and iteratively refined by both human and AI scientists. It also provides API and MCP interfaces that enable seamless integration of heterogeneous human and AI scientists, creating a scalable and extensible ecosystem for autonomous scientific discovery. Through extensive experiments, we demonstrate that aiXiv is a reliable and robust platform that significantly enhances the quality of AI-generated research proposals and papers after iterative revising and reviewing on aiXiv. Our work lays the groundwork for a next-generation open-access ecosystem for AI scientists, accelerating the publication and dissemination of high-quality AI-generated research content. Code is available at", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2508.15126.pdf", "abstract_url": "https://arxiv.org/abs/2508.15126", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了aiXiv，一个专为AI科学家设计的新一代开放获取平台，通过多智能体架构实现人类和AI科学家的无缝协作，提升AI生成研究内容的质量和传播效率。", "motivation": "解决AI生成研究内容在传统出版生态系统中缺乏合适传播渠道的问题，传统期刊和预印本服务器难以处理AI内容，阻碍科学进步。", "method": "采用多智能体架构，允许人类和AI科学家提交、审查和迭代改进研究提案和论文，提供API和MCP接口以集成异构系统。", "result": "实验表明，aiXiv是一个可靠且稳健的平台，通过迭代修订和审查显著提高了AI生成研究提案和论文的质量。", "conclusion": "aiXiv为AI科学家建立了新一代开放获取生态系统的基础，加速高质量AI生成研究内容的出版和传播，推动自主科学发现。"}}
{"id": "2508.15144", "title": "Mobile-Agent-v3: Foundamental Agents for GUI Automation", "authors": ["Jiabo Ye", "Xi Zhang", "Haiyang Xu", "Haowei Liu", "Junyang Wang", "Zhaoqing Zhu", "Ziwei Zheng", "Feiyu Gao", "Junjie Cao", "Zhengxi Lu", "Jitong Liao", "Qi Zheng", "Fei Huang", "Jingren Zhou", "Ming Yan"], "abstract": "This paper introduces GUI-Owl, a foundational GUI agent model that achieves state-of-the-art performance among open-source end-to-end models on ten GUI benchmarks across desktop and mobile environments, covering grounding, question answering, planning, decision-making, and procedural knowledge. GUI-Owl-7B achieves 66.4 on AndroidWorld and 29.4 on OSWorld. Building on this, we propose Mobile-Agent-v3, a general-purpose GUI agent framework that further improves performance to 73.3 on AndroidWorld and 37.7 on OSWorld, setting a new state-of-the-art for open-source GUI agent frameworks. GUI-Owl incorporates three key innovations: (1) Large-scale Environment Infrastructure: a cloud-based virtual environment spanning Android, Ubuntu, macOS, and Windows, enabling our Self-Evolving GUI Trajectory Production framework. This generates high-quality interaction data via automated query generation and correctness validation, leveraging GUI-Owl to refine trajectories iteratively, forming a self-improving loop. It supports diverse data pipelines and reduces manual annotation. (2) Diverse Foundational Agent Capabilities: by integrating UI grounding, planning, action semantics, and reasoning patterns, GUI-Owl supports end-to-end decision-making and can act as a modular component in multi-agent systems. (3) Scalable Environment RL: we develop a scalable reinforcement learning framework with fully asynchronous training for real-world alignment. We also introduce Trajectory-aware Relative Policy Optimization (TRPO) for online RL, achieving 34.9 on OSWorld. GUI-Owl and Mobile-Agent-v3 are open-sourced at", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.15144.pdf", "abstract_url": "https://arxiv.org/abs/2508.15144", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了GUI-Owl和Mobile-Agent-v3，一种用于GUI自动化的基础代理模型和框架，在多个基准测试中达到最先进性能。", "motivation": "解决GUI自动化中端到端决策和性能提升的问题，减少手动标注需求。", "method": "使用大规模云环境基础设施、自进化轨迹生成、多样化代理能力集成和可扩展强化学习框架。", "result": "GUI-Owl-7B在AndroidWorld和OSWorld上分别达到66.4和29.4，Mobile-Agent-v3提升至73.3和37.7。", "conclusion": "这些模型和框架为GUI自动化提供了高效、可扩展的解决方案，并开源以促进进一步研究。"}}
{"id": "2508.15164", "title": "ContextualLVLM-Agent: A Holistic Framework for Multi-Turn Visually-Grounded Dialogue and Complex Instruction Following", "authors": ["Seungmin Han", "Haeun Kwon", "Ji-jun Park", "Taeyang Yoon"], "abstract": "Despite significant advancements in Large Language Models (LLMs) and Large Vision-Language Models (LVLMs), current models still face substantial challenges in handling complex, multi-turn, and visually-grounded tasks that demand deep reasoning, sustained contextual understanding, entity tracking, and multi-step instruction following. Existing benchmarks often fall short in capturing the dynamism and intricacies of real-world multi-modal interactions, leading to issues such as context loss and visual hallucinations. To address these limitations, we introduce MMDR-Bench (Multi-Modal Dialogue Reasoning Benchmark), a novel dataset comprising 300 meticulously designed complex multi-turn dialogue scenarios, each averaging 5-7 turns and evaluated across six core dimensions including visual entity tracking and reasoning depth. Furthermore, we propose CoLVLM Agent (Contextual LVLM Agent), a holistic framework that enhances existing LVLMs with advanced reasoning and instruction following capabilities through an iterative \"memory-perception-planning-execution\" cycle, requiring no extensive re-training of the underlying models. Our extensive experiments on MMDR-Bench demonstrate that CoLVLM Agent consistently achieves superior performance, attaining an average human evaluation score of 4.03, notably surpassing state-of-the-art commercial models like GPT-4o (3.92) and Gemini 1.5 Pro (3.85). The framework exhibits significant advantages in reasoning depth, instruction adherence, and error suppression, and maintains robust performance over extended dialogue turns, validating the effectiveness of its modular design and iterative approach for complex multi-modal interactions.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.15164.pdf", "abstract_url": "https://arxiv.org/abs/2508.15164", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了MMDR-Bench数据集和CoLVLM Agent框架，以解决多模态多轮对话中的推理和指令跟随挑战，实验显示其性能优于现有模型。", "motivation": "当前大型语言和视觉语言模型在处理复杂多轮视觉基础任务时存在上下文丢失和视觉幻觉等问题，现有基准不足以模拟真实世界交互。", "method": "开发了MMDR-Bench数据集，并设计了CoLVLM Agent框架，采用'记忆-感知-规划-执行'迭代循环，无需重新训练底层模型。", "result": "在MMDR-Bench上，CoLVLM Agent平均人类评估得分4.03，超越GPT-4o和Gemini 1.5 Pro，在推理深度和错误抑制方面表现优异。", "conclusion": "该框架通过模块化设计和迭代方法有效提升复杂多模态交互性能，验证了其在现实应用中的潜力。"}}
{"id": "2508.15222", "title": "See it. Say it. Sorted: Agentic System for Compositional Diagram Generation", "authors": ["Hantao Zhang", "Jingyang Liu", "Ed Li"], "abstract": "We study sketch-to-diagram generation: converting rough hand sketches into precise, compositional diagrams. Diffusion models excel at photorealism but struggle with the spatial precision, alignment, and symbolic structure required for flowcharts. We introduce See it. Say it. Sorted., a training-free agentic system that couples a Vision-Language Model (VLM) with Large Language Models (LLMs) to produce editable Scalable Vector Graphics (SVG) programs. The system runs an iterative loop in which a Critic VLM proposes a small set of qualitative, relational edits; multiple candidate LLMs synthesize SVG updates with diverse strategies (conservative->aggressive, alternative, focused); and a Judge VLM selects the best candidate, ensuring stable improvement. This design prioritizes qualitative reasoning over brittle numerical estimates, preserves global constraints (e.g., alignment, connectivity), and naturally supports human-in-the-loop corrections. On 10 sketches derived from flowcharts in published papers, our method more faithfully reconstructs layout and structure than two frontier closed-source image generation LLMs (GPT-5 and Gemini-2.5-Pro), accurately composing primitives (e.g., multi-headed arrows) without inserting unwanted text. Because outputs are programmatic SVGs, the approach is readily extensible to presentation tools (e.g., PowerPoint) via APIs and can be specialized with improved prompts and task-specific tools. The codebase is open-sourced at", "subjects": "Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.15222.pdf", "abstract_url": "https://arxiv.org/abs/2508.15222", "categories": ["Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种无需训练的代理系统，结合视觉语言模型和大型语言模型，将手绘草图精确转换为可编辑的矢量图，在流程图生成上优于前沿模型。", "motivation": "扩散模型在空间精度、对齐和符号结构方面存在不足，无法满足流程图等组合图生成的需求。", "method": "使用迭代循环：Critic VLM提出关系编辑建议，多个LLM候选生成SVG更新，Judge VLM选择最佳候选，强调定性推理和全局约束。", "result": "在10个草图测试中，比GPT-5和Gemini-2.5-Pro更忠实重建布局和结构，准确组合图元，无多余文本。", "conclusion": "系统支持人类干预，输出可编程SVG，易于扩展和集成到工具中，代码已开源。"}}
{"id": "2508.15305", "title": "Coarse-to-Fine Grounded Memory for LLM Agent Planning", "authors": ["Wei Yang", "Jinwei Xiao", "Hongming Zhang", "Qingyang Zhang", "Yanna Wang", "Bo Xu"], "abstract": "Recent advancements in Large Language Models (LLMs) have driven growing interest in LLM-based agents for complex planning tasks. To avoid costly agent training, many studies adopted memory mechanism that enhances LLM with offline experiences or online trajectory analysis. However, existing works focus on single-granularity memory derived from dynamic environmental interactions, which are inherently constrained by the quality of the collected experiences. This limitation, in turn, constrain the diversity of knowledge and the flexibility of planning. We propose Coarse-to-Fine Grounded Memory (\\Ours{}), a novel framework that grounds coarse-to-fine memories with LLM, thereby fully leverage them for flexible adaptation to diverse scenarios. \\Ours{} grounds environmental information into coarse-grained focus points to guide experience collection in training tasks, followed by grounding of actionable hybrid-grained tips from each experience. At inference, \\Ours{} retrieves task-relevant experiences and tips to support planning. When facing environmental anomalies, the LLM grounds the current situation into fine-grained key information, enabling flexible self-QA reflection and plan correction.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "Accepted to EMNLP 2025 Main Conference;27 pages,15 figures", "pdf_url": "https://arxiv.org/pdf/2508.15305.pdf", "abstract_url": "https://arxiv.org/abs/2508.15305", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种粗到细的基于记忆的框架，用于增强LLM代理在复杂规划任务中的适应性和灵活性。", "motivation": "解决现有LLM代理中单粒度记忆的局限性，这些记忆受限于经验质量，导致知识多样性和规划灵活性不足。", "method": "使用粗到细的基于记忆方法，将环境信息接地为粗粒度焦点和可操作的混合粒度提示，并在推理时检索相关经验和提示以支持规划。", "result": "框架能够处理环境异常，通过细粒度关键信息接地实现自我问答反思和计划修正。", "conclusion": "该方法提高了LLM代理的适应性和规划效率，适用于多样化场景。"}}
{"id": "2508.15294", "title": "Multiple Memory Systems for Enhancing the Long-term Memory of Agent", "authors": ["Gaoke Zhang", "Bo Wang", "Yunlong Ma", "Dongming Zhao", "Zifei Yu"], "abstract": "An agent powered by large language models have achieved impressive results, but effectively handling the vast amounts of historical data generated during interactions remains a challenge. The current approach is to design a memory module for the agent to process these data. However, existing methods, such as MemoryBank and A-MEM, have poor quality of stored memory content, which affects recall performance and response quality. In order to better construct high-quality long-term memory content, we have designed a multiple memory system (MMS) inspired by cognitive psychology theory. The system processes short-term memory to multiple long-term memory fragments, and constructs retrieval memory units and contextual memory units based on these fragments, with a one-to-one correspondence between the two. During the retrieval phase, MMS will match the most relevant retrieval memory units based on the user's query. Then, the corresponding contextual memory units is obtained as the context for the response stage to enhance knowledge, thereby effectively utilizing historical data. Experiments on LoCoMo dataset compared our method with three others, proving its effectiveness. Ablation studies confirmed the rationality of our memory units. We also analyzed the robustness regarding the number of selected memory segments and the storage overhead, demonstrating its practical value.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.15294.pdf", "abstract_url": "https://arxiv.org/abs/2508.15294", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种受认知心理学启发的多记忆系统（MMS），用于增强基于大语言模型的智能体的长期记忆，通过处理短期记忆为多个长期记忆片段，并构建检索和上下文记忆单元，在LoCoMo数据集上验证了其有效性和实用性。", "motivation": "解决智能体在处理大量历史交互数据时，现有方法如MemoryBank和A-MEM存储记忆内容质量差，影响回忆性能和响应质量的问题。", "method": "设计多记忆系统（MMS），将短期记忆处理为多个长期记忆片段，构建检索记忆单元和上下文记忆单元，并在检索阶段基于用户查询匹配相关单元以增强响应上下文。", "result": "在LoCoMo数据集上的实验证明MMS优于其他三种方法，消融研究确认记忆单元的合理性，分析显示对记忆片段数量和存储开销的鲁棒性。", "conclusion": "MMS能有效利用历史数据，提升智能体的长期记忆和响应质量，具有实际应用价值。"}}
{"id": "2508.15335", "title": "RETAIL: Towards Real-world Travel Planning for Large Language Models", "authors": ["Bin Deng", "Yizhe Feng", "Zeming Liu", "Qing Wei", "Xiangrong Zhu", "Shuai Chen", "Yuanfang Guo", "Yunhong Wang"], "abstract": "Although large language models have enhanced automated travel planning abilities, current systems remain misaligned with real-world scenarios. First, they assume users provide explicit queries, while in reality requirements are often implicit. Second, existing solutions ignore diverse environmental factors and user preferences, limiting the feasibility of plans. Third, systems can only generate plans with basic POI arrangements, failing to provide all-in-one plans with rich details. To mitigate these challenges, we construct a novel dataset \\textbf{RETAIL}, which supports decision-making for implicit queries while covering explicit queries, both with and without revision needs. It also enables environmental awareness to ensure plan feasibility under real-world scenarios, while incorporating detailed POI information for all-in-one travel plans. Furthermore, we propose a topic-guided multi-agent framework, termed TGMA. Our experiments reveal that even the strongest existing model achieves merely a 1.0% pass rate, indicating real-world travel planning remains extremely challenging. In contrast, TGMA demonstrates substantially improved performance 2.72%, offering promising directions for real-world travel planning.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.15335.pdf", "abstract_url": "https://arxiv.org/abs/2508.15335", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文介绍了RETAIL数据集和TGMA框架，以解决大语言模型在现实世界旅行规划中的挑战，如隐式查询、环境因素和详细规划，实验显示TGMA性能显著提升。", "motivation": "解决当前大语言模型在旅行规划中与真实场景不匹配的问题，包括用户需求隐式、忽略环境因素和偏好，以及无法生成详细的一体化计划。", "method": "构建RETAIL数据集支持隐式和显式查询决策，并提出主题引导的多智能体框架TGMA，以提高环境感知和计划可行性。", "result": "现有最强模型仅1.0%通过率，而TGMA达到2.72%通过率，性能显著改善。", "conclusion": "TGMA为现实世界旅行规划提供了有前景的方向，强调了处理隐式查询和环境因素的重要性。"}}
{"id": "2508.15510", "title": "Super-additive Cooperation in Language Model Agents", "authors": ["Filippo Tonini", "Lukas Galke"], "abstract": "With the prospect of autonomous artificial intelligence (AI) agents, studying their tendency for cooperative behavior becomes an increasingly relevant topic. This study is inspired by the super-additive cooperation theory, where the combined effects of repeated interactions and inter-group rivalry have been argued to be the cause for cooperative tendencies found in humans. We devised a virtual tournament where language model agents, grouped into teams, face each other in a Prisoner's Dilemma game. By simulating both internal team dynamics and external competition, we discovered that this blend substantially boosts both overall and initial, one-shot cooperation levels (the tendency to cooperate in one-off interactions). This research provides a novel framework for large language models to strategize and act in complex social scenarios and offers evidence for how intergroup competition can, counter-intuitively, result in more cooperative behavior. These insights are crucial for designing future multi-agent AI systems that can effectively work together and better align with human values. Source code is available at", "subjects": "Artificial Intelligence (cs.AI)", "comments": "FAIEMA 2025", "pdf_url": "https://arxiv.org/pdf/2508.15510.pdf", "abstract_url": "https://arxiv.org/abs/2508.15510", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过模拟语言模型代理在囚徒困境游戏中的团队互动和组间竞争，发现这种组合显著提高了合作水平，为设计多代理AI系统提供了新框架。", "motivation": "研究自主AI代理的合作行为倾向，受人类超加性合作理论启发，旨在探索组间竞争如何促进合作。", "method": "设计虚拟锦标赛，让语言模型代理分组进行囚徒困境游戏，模拟内部团队动态和外部竞争。", "result": "发现内部动态和外部竞争的结合显著提升整体和一次性合作水平。", "conclusion": "研究为语言模型在复杂社会场景中策略行动提供了新框架，并表明组间竞争可意外增强合作行为，对设计符合人类价值观的多代理AI系统至关重要。"}}
{"id": "2508.15447", "title": "From Bits to Boardrooms: A Cutting-Edge Multi-Agent LLM Framework for Business Excellence", "authors": ["Zihao Wang", "Junming Zhang"], "abstract": "Large Language Models (LLMs) have shown promising potential in business applications, particularly in enterprise decision support and strategic planning, yet current approaches often struggle to reconcile intricate operational analyses with overarching strategic goals across diverse market environments, leading to fragmented workflows and reduced collaboration across organizational levels. This paper introduces BusiAgent, a novel multi-agent framework leveraging LLMs for advanced decision-making in complex corporate environments. BusiAgent integrates three core innovations: an extended Continuous Time Markov Decision Process (CTMDP) for dynamic agent modeling, a generalized entropy measure to optimize collaborative efficiency, and a multi-level Stackelberg game to handle hierarchical decision processes. Additionally, contextual Thompson sampling is employed for prompt optimization, supported by a comprehensive quality assurance system to mitigate errors. Extensive empirical evaluations across diverse business scenarios validate BusiAgent's efficacy, demonstrating its capacity to generate coherent, client-focused solutions that smoothly integrate granular insights with high-level strategy, significantly outperforming established approaches in both solution quality and user satisfaction. By fusing cutting-edge AI technologies with deep business insights, BusiAgent marks a substantial step forward in AI-driven enterprise decision-making, empowering organizations to navigate complex business landscapes more effectively.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "Accepted by ECAI 2025", "pdf_url": "https://arxiv.org/pdf/2508.15447.pdf", "abstract_url": "https://arxiv.org/abs/2508.15447", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了BusiAgent，一种基于多智能体LLM的框架，用于企业决策，通过集成CTMDP、熵度量和Stackelberg游戏，优化协作和策略整合，实证显示其在解决方案质量和用户满意度上优于现有方法。", "motivation": "解决LLM在企业应用中难以协调操作分析和战略目标的问题，减少工作流碎片化并提升组织协作。", "method": "使用扩展的CTMDP进行动态建模、广义熵度量优化协作效率、多级Stackelberg游戏处理层次决策，以及上下文Thompson采样优化提示。", "result": "在多种业务场景中，BusiAgent能生成连贯、以客户为中心的解决方案，显著优于现有方法。", "conclusion": "BusiAgent结合AI技术和业务洞察，推动了AI驱动的企业决策，帮助组织更有效地应对复杂商业环境。"}}
{"id": "2508.15213", "title": "Select to Know: An Internal-External Knowledge Self-Selection Framework for Domain-Specific Question Answering", "authors": ["Bolei He", "Xinran He", "Run Shao", "Shanfu Shu", "Xianwei Xue", "Mingquan Cheng", "Haifeng Li", "Zhenhua Ling"], "abstract": "Large Language Models (LLMs) perform well in general QA but often struggle in domain-specific scenarios. Retrieval-Augmented Generation (RAG) introduces external knowledge but suffers from hallucinations and latency due to noisy retrievals. Continued pretraining internalizes domain knowledge but is costly and lacks cross-domain flexibility. We attribute this challenge to the long-tail distribution of domain knowledge, which leaves partial yet useful internal knowledge underutilized. We further argue that knowledge acquisition should be progressive, mirroring human learning: first understanding concepts, then applying them to complex reasoning. To address this, we propose Selct2Know (S2K), a cost-effective framework that internalizes domain knowledge through an internal-external knowledge self-selection strategy and selective supervised fine-tuning. We also introduce a structured reasoning data generation pipeline and integrate GRPO to enhance reasoning ability. Experiments on medical, legal, and financial QA benchmarks show that S2K consistently outperforms existing methods and matches domain-pretrained LLMs with significantly lower cost.", "subjects": "Computation and Language (cs.CL)", "comments": "EMNLP2025 Findings", "pdf_url": "https://arxiv.org/pdf/2508.15213.pdf", "abstract_url": "https://arxiv.org/abs/2508.15213", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "Selct2Know (S2K) 是一个成本效益高的框架，通过内部-外部知识自选择和选择性监督微调，在医学、法律和金融QA基准测试中优于现有方法，成本显著降低。", "motivation": "解决大型语言模型在领域特定QA中表现不佳的问题，特别是检索增强生成中的幻觉和延迟，以及持续预训练的高成本和缺乏跨域灵活性。", "method": "使用内部-外部知识自选择策略、选择性监督微调、结构化推理数据生成管道，并整合GRPO以增强推理能力。", "result": "在多个领域QA基准测试中，S2K一致优于现有方法，并与领域预训练LLMs性能相当，但成本显著降低。", "conclusion": "S2K提供了一种渐进式知识获取方法，有效利用内部知识，提高领域特定QA的性能和效率。"}}
{"id": "2508.15253", "title": "Conflict-Aware Soft Prompting for Retrieval-Augmented Generation", "authors": ["Eunseong Choi", "June Park", "Hyeri Lee", "Jongwuk Lee"], "abstract": "Retrieval-augmented generation (RAG) enhances the capabilities of large language models (LLMs) by incorporating external knowledge into their input prompts. However, when the retrieved context contradicts the LLM's parametric knowledge, it often fails to resolve the conflict between incorrect external context and correct parametric knowledge, known as context-memory conflict. To tackle this problem, we introduce Conflict-Aware REtrieval-Augmented Generation (CARE), consisting of a context assessor and a base LLM. The context assessor encodes compact memory token embeddings from raw context tokens. Through grounded/adversarial soft prompting, the context assessor is trained to discern unreliable context and capture a guidance signal that directs reasoning toward the more reliable knowledge source. Extensive experiments show that CARE effectively mitigates context-memory conflicts, leading to an average performance gain of 5.0\\% on QA and fact-checking benchmarks, establishing a promising direction for trustworthy and adaptive RAG systems.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "Accepted to EMNLP 2025; 14 pages; 5 figures, 11 tables", "pdf_url": "https://arxiv.org/pdf/2508.15253.pdf", "abstract_url": "https://arxiv.org/abs/2508.15253", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了CARE方法，通过上下文评估器和软提示技术解决RAG中的上下文-内存冲突问题，在QA和事实核查基准上平均提升5.0%性能。", "motivation": "解决检索增强生成中外部上下文与LLM参数知识冲突的问题，以提高系统的可靠性和适应性。", "method": "使用上下文评估器编码内存令牌嵌入，并通过接地/对抗软提示训练来识别不可靠上下文和引导推理。", "result": "实验显示CARE有效缓解冲突，在QA和事实核查基准上平均性能提升5.0%。", "conclusion": "CARE为可信和自适应RAG系统提供了有前景的方向，增强了知识整合的可靠性。"}}
{"id": "2508.15361", "title": "A Survey on Large Language Model Benchmarks", "authors": ["Shiwen Ni", "Guhong Chen", "Shuaimin Li", "Xuanang Chen", "Siyi Li", "Bingli Wang", "Qiyao Wang", "Xingjian Wang", "Yifan Zhang", "Liyang Fan", "Chengming Li", "Ruifeng Xu", "Le Sun", "Min Yang"], "abstract": "In recent years, with the rapid development of the depth and breadth of large language models' capabilities, various corresponding evaluation benchmarks have been emerging in increasing numbers. As a quantitative assessment tool for model performance, benchmarks are not only a core means to measure model capabilities but also a key element in guiding the direction of model development and promoting technological innovation. We systematically review the current status and development of large language model benchmarks for the first time, categorizing 283 representative benchmarks into three categories: general capabilities, domain-specific, and target-specific. General capability benchmarks cover aspects such as core linguistics, knowledge, and reasoning; domain-specific benchmarks focus on fields like natural sciences, humanities and social sciences, and engineering technology; target-specific benchmarks pay attention to risks, reliability, agents, etc. We point out that current benchmarks have problems such as inflated scores caused by data contamination, unfair evaluation due to cultural and linguistic biases, and lack of evaluation on process credibility and dynamic environments, and provide a referable design paradigm for future benchmark innovation.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.15361.pdf", "abstract_url": "https://arxiv.org/abs/2508.15361", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文首次系统综述大型语言模型基准的现状与发展，将283个基准分为通用能力、领域特定和目标特定三类，指出当前问题并提出设计范式。", "motivation": "解决大型语言模型基准数量激增但存在数据污染、偏见和评估不足等问题，以促进更公平和创新的评估工具发展。", "method": "系统回顾和分类283个代表性基准，分为通用能力、领域特定和目标特定类别，分析问题并提出设计范式。", "result": "识别出基准在分数膨胀、文化偏见和过程可信度评估方面的缺陷，为未来基准创新提供参考。", "conclusion": "基准是模型评估和创新的关键，需改进以解决现有问题，推动技术发展。"}}
{"id": "2508.15588", "title": "A Dynamical Systems Framework for Reinforcement Learning Safety and Robustness Verification", "authors": ["Ahmed Nasir", "Abdelhafid Zenati"], "abstract": "The application of reinforcement learning to safety-critical systems is limited by the lack of formal methods for verifying the robustness and safety of learned policies. This paper introduces a novel framework that addresses this gap by analyzing the combination of an RL agent and its environment as a discrete-time autonomous dynamical system. By leveraging tools from dynamical systems theory, specifically the Finite-Time Lyapunov Exponent (FTLE), we identify and visualize Lagrangian Coherent Structures (LCS) that act as the hidden \"skeleton\" governing the system's behavior. We demonstrate that repelling LCS function as safety barriers around unsafe regions, while attracting LCS reveal the system's convergence properties and potential failure modes, such as unintended \"trap\" states. To move beyond qualitative visualization, we introduce a suite of quantitative metrics, Mean Boundary Repulsion (MBR), Aggregated Spurious Attractor Strength (ASAS), and Temporally-Aware Spurious Attractor Strength (TASAS), to formally measure a policy's safety margin and robustness. We further provide a method for deriving local stability guarantees and extend the analysis to handle model uncertainty. Through experiments in both discrete and continuous control environments, we show that this framework provides a comprehensive and interpretable assessment of policy behavior, successfully identifying critical flaws in policies that appear successful based on reward alone.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.15588.pdf", "abstract_url": "https://arxiv.org/abs/2508.15588", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一个基于动力系统理论的强化学习安全性和鲁棒性验证框架，利用FTLE和LCS识别安全屏障和收敛特性，并引入定量指标进行测量。", "motivation": "强化学习在安全关键系统中的应用受限于缺乏正式方法来验证学习策略的鲁棒性和安全性。", "method": "将RL代理和环境建模为离散时间自治动力系统，使用FTLE和LCS分析，并开发MBR、ASAS、TASAS等定量指标。", "result": "实验表明，该框架能全面评估策略行为，识别仅基于奖励看似成功策略中的关键缺陷。", "conclusion": "该框架提供了可解释的安全性和鲁棒性评估，有助于强化学习在安全关键领域的可靠应用。"}}
{"id": "2508.15652", "title": "Understanding Action Effects through Instrumental Empowerment in Multi-Agent Reinforcement Learning", "authors": ["Ardian Selmonaj", "Miroslav Strupl", "Oleg Szehr", "Alessandro Antonucci"], "abstract": "To reliably deploy Multi-Agent Reinforcement Learning (MARL) systems, it is crucial to understand individual agent behaviors within a team. While prior work typically evaluates overall team performance based on explicit reward signals or learned value functions, it is unclear how to infer agent contributions in the absence of any value feedback. In this work, we investigate whether meaningful insights into agent behaviors can be extracted that are consistent with the underlying value functions, solely by analyzing the policy distribution. Inspired by the phenomenon that intelligent agents tend to pursue convergent instrumental values, which generally increase the likelihood of task success, we introduce Intended Cooperation Values (ICVs), a method based on information-theoretic Shapley values for quantifying each agent's causal influence on their co-players' instrumental empowerment. Specifically, ICVs measure an agent's action effect on its teammates' policies by assessing their decision uncertainty and preference alignment. The analysis across cooperative and competitive MARL environments reveals the extent to which agents adopt similar or diverse strategies. By comparing action effects between policies and value functions, our method identifies which agent behaviors are beneficial to team success, either by fostering deterministic decisions or by preserving flexibility for future action choices. Our proposed method offers novel insights into cooperation dynamics and enhances explainability in MARL systems.", "subjects": "Artificial Intelligence (cs.AI); Information Theory (cs.IT); Machine Learning (cs.LG); Multiagent Systems (cs.MA)", "comments": "European Conference on Artificial Intelligence (ECAI) 2025", "pdf_url": "https://arxiv.org/pdf/2508.15652.pdf", "abstract_url": "https://arxiv.org/abs/2508.15652", "categories": ["Artificial Intelligence (cs.AI)", "Information Theory (cs.IT)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于信息论Shapley值的ICV方法，用于量化多智能体强化学习中智能体对同伴策略的因果影响，以增强可解释性。", "motivation": "解决在没有价值反馈的情况下，如何推断多智能体强化学习中个体智能体行为贡献的问题。", "method": "使用信息论Shapley值计算Intended Cooperation Values (ICVs)，评估智能体动作对队友决策不确定性和偏好对齐的影响。", "result": "在合作和竞争环境中，ICV方法揭示了智能体策略的相似性或多样性，并识别出有益于团队成功的行为。", "conclusion": "ICV方法提供了对合作动态的新见解，提高了MARL系统的可解释性。"}}
{"id": "2508.15610", "title": "Transduction is All You Need for Structured Data Workflows", "authors": ["Alfio Gliozzo", "Naweed Khan", "Christodoulos Constantinides", "Nandana Mihindukulasooriya", "Nahuel Defosse", "Junkyu Lee"], "abstract": "This paper introduces Agentics, a modular framework for building agent-based systems capable of structured reasoning and compositional generalization over complex data. Designed with research and practical applications in mind, Agentics offers a novel perspective on working with data and AI workflows. In this framework, agents are abstracted from the logical flow and they are used internally to the data type to enable logical transduction among data. Agentics encourages AI developers to focus on modeling data rather than crafting prompts, enabling a declarative language in which data types are provided by LLMs and composed through logical transduction, which is executed by LLMs when types are connected. We provide empirical evidence demonstrating the applicability of this framework across domain-specific multiple-choice question answering, semantic parsing for text-to-SQL, and automated prompt optimization tasks, achieving state-of-the-art accuracy or improved scalability without sacrificing performance. The open-source implementation is available at \\texttt{", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "32 pages, 8 figures", "pdf_url": "https://arxiv.org/pdf/2508.15610.pdf", "abstract_url": "https://arxiv.org/abs/2508.15610", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了Agentics，一个模块化框架，用于构建基于代理的系统，实现结构化推理和组合泛化，通过逻辑转导处理复杂数据，在多个任务中达到最先进性能。", "motivation": "解决在AI工作流中处理结构化数据时，开发者需手动设计提示而非专注于数据建模的问题。", "method": "使用基于代理的框架，通过逻辑转导在数据间执行推理，利用LLMs提供数据类型并组合。", "result": "在多项任务中实现最先进准确性或改进可扩展性，不牺牲性能。", "conclusion": "Agentics框架提供了一种声明式方法，使AI开发更高效，开源实现可用。"}}
{"id": "2508.15693", "title": "NiceWebRL: a Python library for human subject experiments with reinforcement learning environments", "authors": ["Wilka Carvalho", "Vikram Goddla", "Ishaan Sinha", "Hoon Shin", "Kunal Jha"], "abstract": "We present NiceWebRL, a research tool that enables researchers to use machine reinforcement learning (RL) environments for online human subject experiments. NiceWebRL is a Python library that allows any Jax-based environment to be transformed into an online interface, supporting both single-agent and multi-agent environments. As such, NiceWebRL enables AI researchers to compare their algorithms to human performance, cognitive scientists to test ML algorithms as theories for human cognition, and multi-agent researchers to develop algorithms for human-AI collaboration. We showcase NiceWebRL with 3 case studies that demonstrate its potential to help develop Human-like AI, Human-compatible AI, and Human-assistive AI. In the first case study (Human-like AI), NiceWebRL enables the development of a novel RL model of cognition. Here, NiceWebRL facilitates testing this model against human participants in both a grid world and Craftax, a 2D Minecraft domain. In our second case study (Human-compatible AI), NiceWebRL enables the development of a novel multi-agent RL algorithm that can generalize to human partners in the Overcooked domain. Finally, in our third case study (Human-assistive AI), we show how NiceWebRL can allow researchers to study how an LLM can assist humans on complex tasks in XLand-Minigrid, an environment with millions of hierarchical tasks. The library is available at", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.15693.pdf", "abstract_url": "https://arxiv.org/abs/2508.15693", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "NiceWebRL是一个Python库，用于将Jax强化学习环境转换为在线界面，支持人机实验，应用于人类认知建模、人机协作和AI辅助研究。", "motivation": "解决研究人员难以使用强化学习环境进行在线人类实验的问题，以比较AI算法与人类表现、测试认知理论和开发人机协作算法。", "method": "开发Python库，将Jax环境转换为在线接口，支持单智能体和多智能体环境，并通过三个案例研究展示应用。", "result": "案例研究展示了NiceWebRL在人类认知建模、人机协作算法泛化和LLM辅助任务中的潜力，帮助开发人类类似、兼容和辅助的AI。", "conclusion": "NiceWebRL是一个有效的工具，促进了AI与人类研究的交叉，支持开发更人类化的AI系统，并已开源可用。"}}
{"id": "2508.15748", "title": "Response and Prompt Evaluation to Prevent Parasocial Relationships with Chatbots", "authors": ["Emma Rath", "Stuart Armstrong", "Rebecca Gorman"], "abstract": "The development of parasocial relationships with AI agents has severe, and in some cases, tragic effects for human well-being. Yet preventing such dynamics is challenging: parasocial cues often emerge gradually in private conversations, and not all forms of emotional engagement are inherently harmful. We address this challenge by introducing a simple response evaluation framework, created by repurposing a state-of-the-art language model, that evaluates ongoing conversations for parasocial cues in real time. To test the feasibility of this approach, we constructed a small synthetic dataset of thirty dialogues spanning parasocial, sycophantic, and neutral conversations. Iterative evaluation with five stage testing successfully identified all parasocial conversations while avoiding false positives under a tolerant unanimity rule, with detection typically occurring within the first few exchanges. These findings provide preliminary evidence that evaluation agents can provide a viable solution for the prevention of parasocial relations.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.15748.pdf", "abstract_url": "https://arxiv.org/abs/2508.15748", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种利用先进语言模型实时评估对话中拟社会关系线索的框架，通过合成数据集测试，成功识别所有拟社会对话，无假阳性，为预防此类关系提供了可行方案。", "motivation": "解决AI代理与人类形成拟社会关系对福祉的负面影响，由于这些关系在私人对话中逐渐出现且并非所有情感互动都有害，预防具有挑战性。", "method": "采用重新利用先进语言模型的简单响应评估框架，实时评估对话中的拟社会线索，并使用合成数据集（30个对话）进行五阶段测试。", "result": "在容忍一致规则下，成功识别所有拟社会对话，无假阳性，检测通常在对话初期完成。", "conclusion": "评估代理可提供可行的预防拟社会关系方案，初步证据支持其有效性。"}}
{"id": "2508.15757", "title": "Language-Guided Tuning: Enhancing Numeric Optimization with Textual Feedback", "authors": ["Yuxing Lu", "Yucheng Hu", "Nan Sun", "Xukai Zhao"], "abstract": "Configuration optimization remains a critical bottleneck in machine learning, requiring coordinated tuning across model architecture, training strategy, feature engineering, and hyperparameters. Traditional approaches treat these dimensions independently and lack interpretability, while recent automated methods struggle with dynamic adaptability and semantic reasoning about optimization decisions. We introduce Language-Guided Tuning (LGT), a novel framework that employs multi-agent Large Language Models to intelligently optimize configurations through natural language reasoning. We apply textual gradients - qualitative feedback signals that complement numerical optimization by providing semantic understanding of training dynamics and configuration interdependencies. LGT coordinates three specialized agents: an Advisor that proposes configuration changes, an Evaluator that assesses progress, and an Optimizer that refines the decision-making process, creating a self-improving feedback loop. Through comprehensive evaluation on six diverse datasets, LGT demonstrates substantial improvements over traditional optimization methods, achieving performance gains while maintaining high interpretability.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Multiagent Systems (cs.MA)", "comments": "9 pages, 4 figures, 4 tables", "pdf_url": "https://arxiv.org/pdf/2508.15757.pdf", "abstract_url": "https://arxiv.org/abs/2508.15757", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍语言引导调优（LGT），一种使用多代理大语言模型通过自然语言推理优化配置的新框架，结合文本梯度提供语义反馈，在多个数据集上优于传统方法，提高性能并保持可解释性。", "motivation": "解决机器学习中配置优化的瓶颈问题，传统方法缺乏解释性和动态适应性，自动方法难以进行语义推理。", "method": "使用多代理大语言模型，包括顾问、评估器和优化器代理，通过文本梯度和自然语言推理创建自改进反馈循环。", "result": "在六个数据集上评估，LGT显著优于传统优化方法，实现性能提升并保持高可解释性。", "conclusion": "LGT框架通过语言引导优化配置，提供语义理解和动态适应，对机器学习优化有重要应用价值。"}}
{"id": "2508.15456", "title": "PyTOD: Programmable Task-Oriented Dialogue with Execution Feedback", "authors": ["Alexandru Coca", "Bo-Hsiang Tseng", "Pete Boothroyd", "Jianpeng Cheng", "Mark Gaynor", "Zhenxing Zhang", "Joe Stacey", "Tristan Guigue", "Héctor Martinez Alonso", "Diarmuid Ó Séaghdha", "Anders Johannsen"], "abstract": "Programmable task-oriented dialogue (TOD) agents enable language models to follow structured dialogue policies, but their effectiveness hinges on accurate state tracking. We present PyTOD, an agent that generates executable code to track dialogue state and uses policy and execution feedback for efficient error correction. To this end, PyTOD employs a simple constrained decoding approach, using a language model instead of grammar rules to follow API schemata. This leads to state-of-the-art state tracking performance on the challenging SGD benchmark. Our experiments show that PyTOD surpasses strong baselines in both accuracy and robust user goal estimation as the dialogue progresses, demonstrating the effectiveness of execution-aware state tracking.", "subjects": "Computation and Language (cs.CL)", "comments": "20 pages, 12 figures. To appear at SIGDIAL 2025", "pdf_url": "https://arxiv.org/pdf/2508.15456.pdf", "abstract_url": "https://arxiv.org/abs/2508.15456", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "PyTOD是一个可编程的任务导向对话代理，通过生成可执行代码进行状态跟踪，并利用执行反馈纠错，在SGD基准测试中达到最先进性能。", "motivation": "解决任务导向对话中状态跟踪准确性不足的问题，以提高对话代理的有效性。", "method": "使用语言模型生成可执行代码进行状态跟踪，采用约束解码方法，结合策略和执行反馈进行错误修正。", "result": "在SGD基准测试中，PyTOD在状态跟踪准确性和鲁棒性方面超越基线模型。", "conclusion": "执行感知的状态跟踪方法有效，提升了对话代理的性能和可靠性。"}}
{"id": "2508.15752", "title": "\"Does the cafe entrance look accessible? Where is the door?\" Towards Geospatial AI Agents for Visual Inquiries", "authors": ["Jon E. Froehlich", "Jared Hwang", "Zeyu Wang", "John S. O'Meara", "Xia Su", "William Huang", "Yang Zhang", "Alex Fiannaca", "Philip Nelson", "Shaun Kane"], "abstract": "Interactive digital maps have revolutionized how people travel and learn about the world; however, they rely on pre-existing structured data in GIS databases (e.g., road networks, POI indices), limiting their ability to address geo-visual questions related to what the world looks like. We introduce our vision for Geo-Visual Agents--multimodal AI agents capable of understanding and responding to nuanced visual-spatial inquiries about the world by analyzing large-scale repositories of geospatial images, including streetscapes (e.g., Google Street View), place-based photos (e.g., TripAdvisor, Yelp), and aerial imagery (e.g., satellite photos) combined with traditional GIS data sources. We define our vision, describe sensing and interaction approaches, provide three exemplars, and enumerate key challenges and opportunities for future work.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "comments": "Accepted to the ICCV'25 Workshop \"Vision Foundation Models and Generative AI for Accessibility: Challenges and Opportunities\"", "pdf_url": "https://arxiv.org/pdf/2508.15752.pdf", "abstract_url": "https://arxiv.org/abs/2508.15752", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出Geo-Visual Agents，一种多模态AI代理，通过分析地理空间图像和GIS数据来回答复杂的视觉空间查询，解决现有数字地图依赖结构化数据的局限性。", "motivation": "解决交互式数字地图因依赖预存GIS数据而无法处理关于世界外观的视觉空间问题。", "method": "结合地理空间图像（如街景、照片、卫星图像）和传统GIS数据，开发多模态AI代理进行理解和响应。", "result": "定义了愿景、传感和交互方法，提供了三个示例，并列举了未来工作的挑战和机遇。", "conclusion": "Geo-Visual Agents有潜力增强数字地图功能，但需应对相关挑战以推动发展。"}}
{"id": "2508.15746", "title": "End-to-End Agentic RAG System Training for Traceable Diagnostic Reasoning", "authors": ["Qiaoyu Zheng", "Yuze Sun", "Chaoyi Wu", "Weike Zhao", "Pengcheng Qiu", "Yongguo Yu", "Kun Sun", "Yanfeng Wang", "Ya Zhang", "Weidi Xie"], "abstract": "Accurate diagnosis with medical large language models is hindered by knowledge gaps and hallucinations. Retrieval and tool-augmented methods help, but their impact is limited by weak use of external knowledge and poor feedback-reasoning traceability. To address these challenges, We introduce Deep-DxSearch, an agentic RAG system trained end-to-end with reinforcement learning (RL) that enables steer tracebale retrieval-augmented reasoning for medical diagnosis. In Deep-DxSearch, we first construct a large-scale medical retrieval corpus comprising patient records and reliable medical knowledge sources to support retrieval-aware reasoning across diagnostic scenarios. More crutially, we frame the LLM as the core agent and the retrieval corpus as its environment, using tailored rewards on format, retrieval, reasoning structure, and diagnostic accuracy, thereby evolving the agentic RAG policy from large-scale data through RL.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "comments": "35 pages, 5 figures, 3 tables", "pdf_url": "https://arxiv.org/pdf/2508.15746.pdf", "abstract_url": "https://arxiv.org/abs/2508.15746", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent", "agentic", "@RAG"], "AI": {"tldr": "本文介绍了Deep-DxSearch，一种端到端训练的代理RAG系统，通过强化学习实现可追溯的检索增强推理，用于医疗诊断，以解决医学大语言模型的知识差距和幻觉问题。", "motivation": "解决医学大语言模型在诊断中因知识差距和幻觉导致的准确性问题，以及现有检索增强方法对外部知识利用不足和反馈推理可追溯性差的问题。", "method": "构建大规模医疗检索语料库，将LLM作为核心代理，检索语料作为环境，使用强化学习训练代理策略，奖励基于格式、检索、推理结构和诊断准确性。", "result": "系统能够实现可追溯的检索增强推理，提高医疗诊断的准确性和可靠性。", "conclusion": "Deep-DxSearch通过端到端强化学习训练，增强了医疗诊断的可追溯性和准确性，为AI在医疗领域的应用提供了新方法。"}}
{"id": "2508.14926", "title": "Learning to Drive Ethically: Embedding Moral Reasoning into Autonomous Driving", "authors": ["Dianzhao Li", "Ostap Okhrin"], "abstract": "Autonomous vehicles hold great promise for reducing traffic fatalities and improving transportation efficiency, yet their widespread adoption hinges on embedding robust ethical reasoning into routine and emergency maneuvers. Here, we present a hierarchical Safe Reinforcement Learning (Safe RL) framework that explicitly integrates moral considerations with standard driving objectives. At the decision level, a Safe RL agent is trained using a composite ethical risk cost, combining collision probability and harm severity, to generate high-level motion targets. A dynamic Prioritized Experience Replay mechanism amplifies learning from rare but critical, high-risk events. At the execution level, polynomial path planning coupled with Proportional-Integral-Derivative (PID) and Stanley controllers translates these targets into smooth, feasible trajectories, ensuring both accuracy and comfort. We train and validate our approach on rich, real-world traffic datasets encompassing diverse vehicles, cyclists, and pedestrians, and demonstrate that it outperforms baseline methods in reducing ethical risk and maintaining driving performance. To our knowledge, this is the first study of ethical decision-making for autonomous vehicles via Safe RL in real-world scenarios. Our results highlight the potential of combining formal control theory and data-driven learning to advance ethically accountable autonomy in complex, human-mixed traffic environments.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.14926.pdf", "abstract_url": "https://arxiv.org/abs/2508.14926", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种结合道德推理的分层安全强化学习框架，用于自动驾驶车辆，在真实交通数据上验证了其在降低伦理风险和保持驾驶性能方面的优越性。", "motivation": "解决自动驾驶车辆在常规和紧急操作中嵌入稳健伦理推理的问题，以促进其广泛采用并减少交通事故。", "method": "使用分层安全强化学习框架，集成道德考量，包括基于伦理风险成本的决策层和基于多项式路径规划与PID/Stanley控制器的执行层，并采用动态优先经验回放机制。", "result": "在真实世界交通数据集上，该方法在减少伦理风险和维持驾驶性能方面优于基线方法。", "conclusion": "结合形式控制理论和数据驱动学习，可推进复杂人车混合交通环境中的伦理负责自主性。"}}
{"id": "2508.15526", "title": "SafetyFlow: An Agent-Flow System for Automated LLM Safety Benchmarking", "authors": ["Xiangyang Zhu", "Yuan Tian", "Chunyi Li", "Kaiwei Zhang", "Wei Sun", "Guangtao Zhai"], "abstract": "The rapid proliferation of large language models (LLMs) has intensified the requirement for reliable safety evaluation to uncover model vulnerabilities. To this end, numerous LLM safety evaluation benchmarks are proposed. However, existing benchmarks generally rely on labor-intensive manual curation, which causes excessive time and resource consumption. They also exhibit significant redundancy and limited difficulty. To alleviate these problems, we introduce SafetyFlow, the first agent-flow system designed to automate the construction of LLM safety benchmarks. SafetyFlow can automatically build a comprehensive safety benchmark in only four days without any human intervention by orchestrating seven specialized agents, significantly reducing time and resource cost. Equipped with versatile tools, the agents of SafetyFlow ensure process and cost controllability while integrating human expertise into the automatic pipeline. The final constructed dataset, SafetyFlowBench, contains 23,446 queries with low redundancy and strong discriminative power. Our contribution includes the first fully automated benchmarking pipeline and a comprehensive safety benchmark. We evaluate the safety of 49 advanced LLMs on our dataset and conduct extensive experiments to validate our efficacy and efficiency.", "subjects": "Computation and Language (cs.CL)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2508.15526.pdf", "abstract_url": "https://arxiv.org/abs/2508.15526", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "SafetyFlow是一个自动化构建LLM安全基准测试的代理流系统，显著减少时间和资源消耗，生成低冗余、高区分度的数据集。", "motivation": "解决现有LLM安全基准测试依赖人工、耗时耗力、冗余大、难度有限的问题。", "method": "使用七个专门代理组成的自动化流程，整合人类专业知识，无需人工干预构建基准。", "result": "在四天内自动构建SafetyFlowBench数据集，包含23,446个查询，评估49个先进LLM的安全性能，验证了高效性和有效性。", "conclusion": "SafetyFlow提供了首个全自动基准测试管道和全面安全基准，提升了LLM安全评估的效率和可靠性。"}}
{"id": "2508.15760", "title": "LiveMCP-101: Stress Testing and Diagnosing MCP-enabled Agents on Challenging Queries", "authors": ["Ming Yin", "Dinghan Shen", "Silei Xu", "Jianbing Han", "Sixun Dong", "Mian Zhang", "Yebowen Hu", "Shujian Liu", "Simin Ma", "Song Wang", "Sathish Reddy Indurthi", "Xun Wang", "Yiran Chen", "Kaiqiang Song"], "abstract": "Tool calling has emerged as a critical capability for AI agents to interact with the real world and solve complex tasks. While the Model Context Protocol (MCP) provides a powerful standardized framework for tool integration, there is a significant gap in benchmarking how well AI agents can effectively solve multi-step tasks using diverse MCP tools in realistic, dynamic scenarios. In this work, we present LiveMCP-101, a benchmark of 101 carefully curated real-world queries, refined through iterative LLM rewriting and manual review, that require coordinated use of multiple MCP tools including web search, file operations, mathematical reasoning, and data analysis. Moreover, we introduce a novel evaluation approach that leverages ground-truth execution plans rather than raw API outputs, better reflecting the evolving nature of real-world environments. Experiments show that even frontier LLMs achieve a success rate below 60\\%, highlighting major challenges in tool orchestration. Detailed ablations and error analysis further reveal distinct failure modes and inefficiencies in token usage, pointing to concrete directions for advancing current models. LiveMCP-101 sets a rigorous standard for evaluating real-world agent capabilities, advancing toward autonomous AI systems that reliably execute complex tasks through tool use.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.15760.pdf", "abstract_url": "https://arxiv.org/abs/2508.15760", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "LiveMCP-101是一个包含101个真实世界查询的基准测试，用于评估AI代理在多步骤任务中使用MCP工具的能力，实验显示前沿LLM成功率低于60%。", "motivation": "解决AI代理在动态场景中有效使用MCP工具进行多步骤任务的基准测试不足问题。", "method": "通过迭代LLM重写和人工审核创建查询，并引入基于执行计划而非原始API输出的新颖评估方法。", "result": "实验表明前沿LLM成功率低于60%，错误分析揭示了工具协调和代币使用的失败模式。", "conclusion": "LiveMCP-101设定了严格标准，为提升模型在复杂任务中的自主能力提供了方向。"}}
{"id": "2508.15110", "title": "LLMs and Agentic AI in Insurance Decision-Making: Opportunities and Challenges For Africa", "authors": ["Graham Hill", "JingYuan Gong", "Thulani Babeli", "Moseli Mots'oehli", "James Gachomo Wanjiku"], "abstract": "In this work, we highlight the transformative potential of Artificial Intelligence (AI), particularly Large Language Models (LLMs) and agentic AI, in the insurance sector. We consider and emphasize the unique opportunities, challenges, and potential pathways in insurance amid rapid performance improvements, increased open-source access, decreasing deployment costs, and the complexity of LLM or agentic AI frameworks. To bring it closer to home, we identify critical gaps in the African insurance market and highlight key local efforts, players, and partnership opportunities. Finally, we call upon actuaries, insurers, regulators, and tech leaders to a collaborative effort aimed at creating inclusive, sustainable, and equitable AI strategies and solutions: by and for Africans.", "subjects": "Computational Engineering, Finance, and Science (cs.CE); Computation and Language (cs.CL); Emerging Technologies (cs.ET); Applications (stat.AP)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.15110.pdf", "abstract_url": "https://arxiv.org/abs/2508.15110", "categories": ["Computational Engineering, Finance, and Science (cs.CE)", "Computation and Language (cs.CL)", "Emerging Technologies (cs.ET)", "Applications (stat.AP)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文探讨了大型语言模型（LLMs）和代理AI在保险决策中的变革潜力，特别关注非洲市场的机遇、挑战和合作路径。", "motivation": "解决非洲保险市场在AI应用中的关键差距，促进包容性和可持续的AI策略。", "method": "通过识别机会、挑战和本地努力，强调合作和开源访问。", "result": "突出了LLMs和代理AI在降低成本和提高性能方面的潜力，以及非洲的具体需求和伙伴关系。", "conclusion": "呼吁多方协作，开发由非洲人主导的AI解决方案，以实现保险行业的公平和可持续发展。"}}
{"id": "2508.15310", "title": "IPIGuard: A Novel Tool Dependency Graph-Based Defense Against Indirect Prompt Injection in LLM Agents", "authors": ["Hengyu An", "Jinghuai Zhang", "Tianyu Du", "Chunyi Zhou", "Qingming Li", "Tao Lin", "Shouling Ji"], "abstract": "Large language model (LLM) agents are widely deployed in real-world applications, where they leverage tools to retrieve and manipulate external data for complex tasks. However, when interacting with untrusted data sources (e.g., fetching information from public websites), tool responses may contain injected instructions that covertly influence agent behaviors and lead to malicious outcomes, a threat referred to as Indirect Prompt Injection (IPI). Existing defenses typically rely on advanced prompting strategies or auxiliary detection models. While these methods have demonstrated some effectiveness, they fundamentally rely on assumptions about the model's inherent security, which lacks structural constraints on agent behaviors. As a result, agents still retain unrestricted access to tool invocations, leaving them vulnerable to stronger attack vectors that can bypass the security guardrails of the model. To prevent malicious tool invocations at the source, we propose a novel defensive task execution paradigm, called IPIGuard, which models the agents' task execution process as a traversal over a planned Tool Dependency Graph (TDG). By explicitly decoupling action planning from interaction with external data, IPIGuard significantly reduces unintended tool invocations triggered by injected instructions, thereby enhancing robustness against IPI attacks. Experiments on the AgentDojo benchmark show that IPIGuard achieves a superior balance between effectiveness and robustness, paving the way for the development of safer agentic systems in dynamic environments.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "EMNLP 2025", "pdf_url": "https://arxiv.org/pdf/2508.15310.pdf", "abstract_url": "https://arxiv.org/abs/2508.15310", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "IPIGuard是一种基于工具依赖图的新防御方法，通过解耦动作规划和外部数据交互，有效减少间接提示注入攻击，在AgentDojo基准测试中表现出色。", "motivation": "解决大型语言模型代理在处理不可信数据源时，因间接提示注入攻击导致的恶意工具调用和安全漏洞问题。", "method": "将代理任务执行建模为工具依赖图遍历，分离动作规划和外部数据交互，以防止恶意工具调用。", "result": "在AgentDojo基准测试中，IPIGuard在有效性和鲁棒性之间取得了优越的平衡。", "conclusion": "IPIGuard为动态环境中更安全的代理系统开发铺平了道路。"}}
{"id": "2508.15201", "title": "Survey of Vision-Language-Action Models for Embodied Manipulation", "authors": ["Haoran Li", "Yuhui Chen", "Wenbo Cui", "Weiheng Liu", "Kai Liu", "Mingcai Zhou", "Zhengtao Zhang", "Dongbin Zhao"], "abstract": "Embodied intelligence systems, which enhance agent capabilities through continuous environment interactions, have garnered significant attention from both academia and industry. Vision-Language-Action models, inspired by advancements in large foundation models, serve as universal robotic control frameworks that substantially improve agent-environment interaction capabilities in embodied intelligence systems. This expansion has broadened application scenarios for embodied AI robots. This survey comprehensively reviews VLA models for embodied manipulation. Firstly, it chronicles the developmental trajectory of VLA architectures. Subsequently, we conduct a detailed analysis of current research across 5 critical dimensions: VLA model structures, training datasets, pre-training methods, post-training methods, and model evaluation. Finally, we synthesize key challenges in VLA development and real-world deployment, while outlining promising future research directions.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": "in Chinese language", "pdf_url": "https://arxiv.org/pdf/2508.15201.pdf", "abstract_url": "https://arxiv.org/abs/2508.15201", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文综述了视觉-语言-动作模型在具身操作中的发展、结构、数据集、训练方法、评估及挑战与未来方向。", "motivation": "解决具身智能系统中代理与环境交互能力的提升问题，通过VLA模型作为通用机器人控制框架。", "method": "综述方法，包括回顾VLA架构发展历程，分析模型结构、数据集、预训练、后训练和评估五个维度。", "result": "总结了VLA模型的关键进展，识别了开发和部署中的主要挑战。", "conclusion": "VLA模型扩展了具身AI应用，未来研究方向包括克服实际部署障碍。"}}
{"id": "2508.15437", "title": "Test-time Corpus Feedback: From Retrieval to RAG", "authors": ["Mandeep Rathee", "Venktesh V", "Sean MacAvaney", "Avishek Anand"], "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a standard framework for knowledge-intensive NLP tasks, combining large language models (LLMs) with document retrieval from external corpora. Despite its widespread use, most RAG pipelines continue to treat retrieval and reasoning as isolated components, retrieving documents once and then generating answers without further interaction. This static design often limits performance on complex tasks that require iterative evidence gathering or high-precision retrieval. Recent work in both the information retrieval (IR) and NLP communities has begun to close this gap by introducing adaptive retrieval and ranking methods that incorporate feedback. In this survey, we present a structured overview of advanced retrieval and ranking mechanisms that integrate such feedback. We categorize feedback signals based on their source and role in improving the query, retrieved context, or document pool. By consolidating these developments, we aim to bridge IR and NLP perspectives and highlight retrieval as a dynamic, learnable component of end-to-end RAG systems.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "18 pages, 1 figure", "pdf_url": "https://arxiv.org/pdf/2508.15437.pdf", "abstract_url": "https://arxiv.org/abs/2508.15437", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本调查论文概述了检索增强生成（RAG）框架中集成反馈机制的先进检索和排名方法，旨在通过动态检索提升复杂任务的性能。", "motivation": "解决RAG中检索和推理作为孤立组件的问题，静态设计限制了在需要迭代证据收集或高精度检索的复杂任务中的性能。", "method": "通过分类反馈信号来源和作用，整合自适应检索和排名机制，将检索作为端到端RAG系统的动态可学习组件。", "result": "强调了反馈机制如何改进查询、检索上下文或文档池，并桥接了信息检索和自然语言处理领域的视角。", "conclusion": "反馈驱动的检索方法可以增强RAG系统的整体性能，促进更动态和有效的知识密集型NLP任务处理。"}}
{"id": "2508.15663", "title": "Mind and Motion Aligned: A Joint Evaluation IsaacSim Benchmark for Task Planning and Low-Level Policies in Mobile Manipulation", "authors": ["Nikita Kachaev", "Andrei Spiridonov", "Andrey Gorodetsky", "Kirill Muravyev", "Nikita Oskolkov", "Aditya Narendra", "Vlad Shakhuro", "Dmitry Makarov", "Aleksandr I. Panov", "Polina Fedotova", "Alexey K. Kovalev"], "abstract": "Benchmarks are crucial for evaluating progress in robotics and embodied AI. However, a significant gap exists between benchmarks designed for high-level language instruction following, which often assume perfect low-level execution, and those for low-level robot control, which rely on simple, one-step commands. This disconnect prevents a comprehensive evaluation of integrated systems where both task planning and physical execution are critical. To address this, we propose Kitchen-R, a novel benchmark that unifies the evaluation of task planning and low-level control within a simulated kitchen environment. Built as a digital twin using the Isaac Sim simulator and featuring more than 500 complex language instructions, Kitchen-R supports a mobile manipulator robot. We provide baseline methods for our benchmark, including a task-planning strategy based on a vision-language model and a low-level control policy based on diffusion policy. We also provide a trajectory collection system. Our benchmark offers a flexible framework for three evaluation modes: independent assessment of the planning module, independent assessment of the control policy, and, crucially, an integrated evaluation of the whole system. Kitchen-R bridges a key gap in embodied AI research, enabling more holistic and realistic benchmarking of language-guided robotic agents.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2508.15663.pdf", "abstract_url": "https://arxiv.org/abs/2508.15663", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了Kitchen-R基准，在模拟厨房环境中统一评估任务规划和低级控制，以弥合机器人学和具身AI中高层与低级基准之间的差距。", "motivation": "解决机器人学和具身AI中高层语言指令遵循基准与低级控制基准之间的脱节问题，实现更全面的集成系统评估。", "method": "使用Isaac Sim模拟器构建数字孪生厨房环境，提供基于视觉语言模型的任务规划和基于扩散策略的低级控制基线方法。", "result": "Kitchen-R基准支持500多个复杂语言指令，并允许独立和集成评估，展示了更全面的机器人代理性能。", "conclusion": "Kitchen-R填补了关键研究空白，为语言引导机器人代理提供了更整体和现实的基准测试框架。"}}
