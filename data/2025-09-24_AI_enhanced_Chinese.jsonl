{"id": "2509.18167", "title": "SIRAG: Towards Stable and Interpretable RAG with A Process-Supervised Multi-Agent Framework", "authors": ["Junlin Wang", "Zehao Wu", "Shaowei Lu", "Yanlan Li", "Xinghao Huang"], "abstract": "Retrieval-Augmented Generation (RAG) enables large language models (LLMs) to access external knowledge sources, but the effectiveness of RAG relies on the coordination between the retriever and the generator. Since these components are developed independently, their interaction is often suboptimal: the retriever may return irrelevant or redundant documents, while the generator may fail to fully leverage retrieved evidence. In this work, we propose a process-supervised multi-agent framework to bridge the gap between retriever and generator. The framework introduces two lightweight agents: a Decision Maker, which determines when to continue retrieval or stop for answer generation, and a Knowledge Selector, which filters retrieved documents to retain only the most useful evidence. To provide fine-grained supervision, we employ an LLM-as-a-Judge that evaluates each intermediate action with process-level rewards, ensuring more accurate credit assignment than relying solely on final answer correctness. We further adopt a tree-structured rollout strategy to explore diverse reasoning paths, and train both agents with Proximal Policy Optimization (PPO) in an end-to-end manner. Experiments on single-hop and multi-hop question answering benchmarks show that our approach achieves higher accuracy, more stable convergence, and produces more interpretable reasoning trajectories compared with standard RAG baselines. Importantly, the proposed framework is modular and plug-and-play, requiring no modification to the retriever or generator, making it practical for real-world RAG applications.", "subjects": "Computation and Language (cs.CL)", "comments": "5 pages,2 figures, IRAC under review", "pdf_url": "https://arxiv.org/pdf/2509.18167.pdf", "abstract_url": "https://arxiv.org/abs/2509.18167", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文提出SIRAG框架，通过过程监督的多智能体系统改进RAG的稳定性和可解释性。", "motivation": "解决RAG中检索器和生成器交互不优化的问题，如检索不相关文档和生成器未充分利用证据。", "method": "使用决策制定者和知识选择器智能体，结合LLM评估和PPO训练，采用树结构探索推理路径。", "result": "在问答基准测试中实现更高准确性、更稳定收敛和更可解释的推理轨迹。", "conclusion": "该框架模块化、即插即用，无需修改现有组件，适用于实际RAG应用。"}}
{"id": "2509.18158", "title": "ZERA: Zero-init Instruction Evolving Refinement Agent - From Zero Instructions to Structured Prompts via Principle-based Optimization", "authors": ["Seungyoun Yi", "Minsoo Khang", "Sungrae Park"], "abstract": "Automatic Prompt Optimization (APO) improves large language model (LLM) performance by refining prompts for specific tasks. However, prior APO methods typically focus only on user prompts, rely on unstructured feedback, and require large sample sizes and long iteration cycles-making them costly and brittle. We propose ZERA (Zero-init Instruction Evolving Refinement Agent), a novel framework that jointly optimizes both system and user prompts through principled, low-overhead refinement. ZERA scores prompts using eight generalizable criteria with automatically inferred weights, and revises prompts based on these structured critiques. This enables fast convergence to high-quality prompts using minimal examples and short iteration cycles. We evaluate ZERA across five LLMs and nine diverse datasets spanning reasoning, summarization, and code generation tasks. Experimental results demonstrate consistent improvements over strong baselines. Further ablation studies highlight the contribution of each component to more effective prompt construction. Our implementation including all prompts is publicly available at", "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": "9 pages, 4 figures. To appear in EMNLP 2025 Main Conference (Oral Presentation)", "pdf_url": "https://arxiv.org/pdf/2509.18158.pdf", "abstract_url": "https://arxiv.org/abs/2509.18158", "categories": ["Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "ZERA是一种新颖的自动提示优化框架，通过基于原则的优化从零指令生成结构化提示，在多个LLM和数据集上实现快速收敛和性能提升。", "motivation": "解决现有自动提示优化方法仅关注用户提示、依赖非结构化反馈、需要大量样本和长迭代周期导致成本高和脆弱的问题。", "method": "联合优化系统和用户提示，使用八个可泛化标准评分并基于结构化批评修订提示，实现低开销精炼。", "result": "在五个LLM和九个多样化数据集上实验显示，相比强基线有持续改进，消融研究验证各组件贡献。", "conclusion": "ZERA通过结构化优化实现高效提示构建，具有实际应用价值，代码已公开。"}}
{"id": "2509.18405", "title": "Check Field Detection Agent (CFD-Agent) using Multimodal Large Language and Vision Language Models", "authors": ["Sourav Halder", "Jinjun Tong", "Xinyu Wu"], "abstract": "Checks remain a foundational instrument in the financial ecosystem, facilitating substantial transaction volumes across institutions. However, their continued use also renders them a persistent target for fraud, underscoring the importance of robust check fraud detection mechanisms. At the core of such systems lies the accurate identification and localization of critical fields, such as the signature, magnetic ink character recognition (MICR) line, courtesy amount, legal amount, payee, and payer, which are essential for subsequent verification against reference checks belonging to the same customer. This field-level detection is traditionally dependent on object detection models trained on large, diverse, and meticulously labeled datasets, a resource that is scarce due to proprietary and privacy concerns. In this paper, we introduce a novel, training-free framework for automated check field detection, leveraging the power of a vision language model (VLM) in conjunction with a multimodal large language model (MLLM). Our approach enables zero-shot detection of check components, significantly lowering the barrier to deployment in real-world financial settings. Quantitative evaluation of our model on a hand-curated dataset of 110 checks spanning multiple formats and layouts demonstrates strong performance and generalization capability. Furthermore, this framework can serve as a bootstrap mechanism for generating high-quality labeled datasets, enabling the development of specialized real-time object detection models tailored to institutional needs.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": "12 pages, 5 figures, 2 tables", "pdf_url": "https://arxiv.org/pdf/2509.18405.pdf", "abstract_url": "https://arxiv.org/abs/2509.18405", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于视觉语言模型和多模态大语言模型的免训练框架，用于支票关键字段的零样本检测，以降低金融欺诈检测的部署门槛。", "motivation": "支票在金融交易中广泛使用，但易受欺诈，传统检测方法依赖大量标注数据，而此类数据稀缺，因此需要开发无需训练的检测方案。", "method": "利用视觉语言模型和多模态大语言模型，实现支票字段的零样本检测，无需模型训练。", "result": "在包含110张支票的手工数据集上评估，模型表现出强性能和良好泛化能力。", "conclusion": "该框架不仅提升检测效率，还可作为生成高质量标注数据的引导机制，支持开发定制化实时检测模型。"}}
{"id": "2509.18175", "title": "ERFC: Happy Customers with Emotion Recognition and Forecasting in Conversation in Call Centers", "authors": ["Aditi Debsharma", "Bhushan Jagyasi", "Surajit Sen", "Priyanka Pandey", "Devicharith Dovari", "Yuvaraj V.C", "Rosalin Parida", "Gopali Contractor"], "abstract": "Emotion Recognition in Conversation has been seen to be widely applicable in call center analytics, opinion mining, finance, retail, healthcare, and other industries. In a call center scenario, the role of the call center agent is not just confined to receiving calls but to also provide good customer experience by pacifying the frustration or anger of the customers. This can be achieved by maintaining neutral and positive emotion from the agent. As in any conversation, the emotion of one speaker is usually dependent on the emotion of other speaker. Hence the positive emotion of an agent, accompanied with the right resolution will help in enhancing customer experience. This can change an unhappy customer to a happy one. Imparting the right resolution at right time becomes easier if the agent has the insight of the emotion of future utterances. To predict the emotions of the future utterances we propose a novel architecture, Emotion Recognition and Forecasting in Conversation. Our proposed ERFC architecture considers multi modalities, different attributes of emotion, context and the interdependencies of the utterances of the speakers in the conversation. Our intensive experiments on the IEMOCAP dataset have shown the feasibility of the proposed ERFC. This approach can provide a tremendous business value for the applications like call center, where the happiness of customer is utmost important.", "subjects": "Computation and Language (cs.CL)", "comments": "7 pages, 6 Figures, 4 Tables, 18 References", "pdf_url": "https://arxiv.org/pdf/2509.18175.pdf", "abstract_url": "https://arxiv.org/abs/2509.18175", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出ERFC架构，通过多模态和上下文分析预测对话中未来情感，应用于呼叫中心以提升客户体验。", "motivation": "解决呼叫中心中客户情感管理问题，通过预测未来情感帮助客服及时安抚客户，改善满意度。", "method": "使用多模态、情感属性、上下文和话语依赖性的ERFC架构，在IEMOCAP数据集上进行实验。", "result": "实验验证了ERFC的可行性，显示出在情感预测方面的有效性。", "conclusion": "ERFC能带来巨大商业价值，尤其在呼叫中心应用中，可显著提高客户幸福感。"}}
{"id": "2509.18226", "title": "From \"What to Eat?\" to Perfect Recipe: ChefMind's Chain-of-Exploration for Ambiguous User Intent in Recipe Recommendation", "authors": ["Yu Fu", "Linyue Cai", "Ruoyu Wu", "Yong Zhao"], "abstract": "Personalized recipe recommendation faces challenges in handling fuzzy user intent, ensuring semantic accuracy, and providing sufficient detail coverage. We propose ChefMind, a hybrid architecture combining Chain of Exploration (CoE), Knowledge Graph (KG), Retrieval-Augmented Generation (RAG), and a Large Language Model (LLM). CoE refines ambiguous queries into structured conditions, KG offers semantic reasoning and interpretability, RAG supplements contextual culinary details, and LLM integrates outputs into coherent recommendations. We evaluate ChefMind on the Xiachufang dataset and manually annotated queries, comparing it with LLM-only, KG-only, and RAG-only baselines. Results show that ChefMind achieves superior performance in accuracy, relevance, completeness, and clarity, with an average score of 8.7 versus 6.4-6.7 for ablation models. Moreover, it reduces unprocessed queries to 1.6%, demonstrating robustness in handling fuzzy demands.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "5 pages, 3 figures, submitted to icassp 2026", "pdf_url": "https://arxiv.org/pdf/2509.18226.pdf", "abstract_url": "https://arxiv.org/abs/2509.18226", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出ChefMind混合架构，结合CoE、KG、RAG和LLM，用于处理模糊用户意图的食谱推荐，在准确性和鲁棒性上优于基线模型。", "motivation": "解决个性化食谱推荐中用户意图模糊、语义准确性不足和细节覆盖不充分的问题。", "method": "使用链式探索（CoE）精炼查询，知识图谱（KG）进行语义推理，检索增强生成（RAG）补充上下文，大语言模型（LLM）整合输出。", "result": "在Xiachufang数据集上，ChefMind平均得分8.7，优于基线（6.4-6.7），未处理查询降至1.6%。", "conclusion": "ChefMind能有效处理模糊意图，提升推荐质量，具有实际应用潜力。"}}
{"id": "2509.18178", "title": "Foam-Agent: An End-to-End Composable Multi-Agent Framework for Automating CFD Simulation in OpenFOAM", "authors": ["Ling Yue", "Nithin Somasekharan", "Tingwen Zhang", "Yadi Cao", "Shaowu Pan"], "abstract": "Computational Fluid Dynamics (CFD) is an essential simulation tool in engineering, yet its steep learning curve and complex manual setup create significant barriers. To address these challenges, we introduce Foam-Agent, a multi-agent framework that automates the entire end-to-end OpenFOAM workflow from a single natural language prompt. Our key innovations address critical gaps in existing systems: 1. An Comprehensive End-to-End Simulation Automation: Foam-Agent is the first system to manage the full simulation pipeline, including advanced pre-processing with a versatile Meshing Agent capable of handling external mesh files and generating new geometries via Gmsh, automatic generation of HPC submission scripts, and post-simulation visualization via ParaView. 2. Composable Service Architecture: Going beyond a monolithic agent, the framework uses Model Context Protocol (MCP) to expose its core functions as discrete, callable tools. This allows for flexible integration and use by other agentic systems, such as Claude-code, for more exploratory workflows. 3. High-Fidelity Configuration Generation: We achieve superior accuracy through a Hierarchical Multi-Index RAG for precise context retrieval and a dependency-aware generation process that ensures configuration consistency. Evaluated on a benchmark of 110 simulation tasks, Foam-Agent achieves an 88.2% success rate with Claude 3.5 Sonnet, significantly outperforming existing frameworks (55.5% for MetaOpenFOAM). Foam-Agent dramatically lowers the expertise barrier for CFD, demonstrating how specialized multi-agent systems can democratize complex scientific computing. The code is public at", "subjects": "Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.18178.pdf", "abstract_url": "https://arxiv.org/abs/2509.18178", "categories": ["Artificial Intelligence (cs.AI)", "Computational Engineering, Finance, and Science (cs.CE)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic", "@RAG"], "AI": {"tldr": "本文介绍了Foam-Agent，一个端到端可组合的多智能体框架，通过自然语言提示自动化OpenFOAM的CFD模拟工作流，显著降低了使用门槛。", "motivation": "解决CFD模拟在OpenFOAM中学习曲线陡峭和手动设置复杂的问题，降低工程领域的专业壁垒。", "method": "采用多智能体框架，包括端到端自动化、基于MCP的可组合服务架构、以及分层多索引RAG和依赖感知生成的高保真配置方法。", "result": "在110个模拟任务基准测试中，使用Claude 3.5 Sonnet达到88.2%的成功率，远超现有框架的55.5%。", "conclusion": "Foam-Agent有效民主化了复杂科学计算，展示了专用多智能体系统的潜力，代码已公开。"}}
{"id": "2509.18229", "title": "An N-Plus-1 GPT Agency for Critical Solution of Mechanical Engineering Analysis Problems", "authors": ["Anthony Patera", "Rohan Abeyaratne"], "abstract": "Generative AI, and specifically GPT, can produce a remarkable solution to a mechanical engineering analysis problem - but also, on occasion, a flawed solution. For example, an elementary mechanics problem is solved flawlessly in one GPT instance and incorrectly in a subsequent GPT instance, with a success probability of only 85%. This unreliability renders \"out-of-the-box\" GPT unsuitable for deployment in education or engineering practice. We introduce an \"N-Plus-1\" GPT Agency for Initial (Low-Cost) Analysis of mechanical engineering Problem Statements. Agency first launches N instantiations of Agent Solve to yield N independent Proposed Problem Solution Realizations; Agency then invokes Agent Compare to summarize and compare the N Proposed Problem Solution Realizations and to provide a Recommended Problem Solution. We argue from Condorcet's Jury Theorem that, for a Problem Statement characterized by per-Solve success probability greater than 1/2 (and N sufficiently large), the Predominant (Agent Compare) Proposed Problem Solution will, with high probability, correspond to a Correct Proposed Problem Solution. Furthermore, Agent Compare can also incorporate aspects of Secondary (Agent Compare) Proposed Problem Solutions, in particular when the latter represent alternative Problem Statement interpretations - different Mathematical Models - or alternative Mathematical Solution Procedures. Comparisons to Grok Heavy, a commercial multi-agent model, show similarities in design and performance, but also important differences in emphasis: our Agency focuses on transparency and pedagogical value.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.18229.pdf", "abstract_url": "https://arxiv.org/abs/2509.18229", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种N+1 GPT代理方法，通过多个GPT实例并行求解机械工程问题，并利用比较代理提高解决方案的可靠性，适用于教育和工程实践。", "motivation": "解决GPT在机械工程问题分析中可靠性不足（如成功率仅85%）的问题，使其不适合直接用于教育或工程部署。", "method": "使用N+1代理框架：N个代理并行生成独立解决方案，另一个代理比较和汇总这些方案，推荐最优解，基于Condorcet陪审团定理提高正确概率。", "result": "方法在问题求解成功率大于1/2时，能高概率获得正确解；与Grok Heavy比较显示相似性能，但更注重透明度和教学价值。", "conclusion": "该代理方法提升了GPT的可靠性，强调了透明性和教育应用，为AI在工程领域的实用化提供了改进方向。"}}
{"id": "2509.18847", "title": "Failure Makes the Agent Stronger: Enhancing Accuracy through Structured Reflection for Reliable Tool Interactions", "authors": ["Junhao Su", "Yuanliang Wan", "Junwei Yang", "Hengyu Shi", "Tianyang Han", "Junfeng Luo", "Yurui Qiu"], "abstract": "Tool-augmented large language models (LLMs) are usually trained with supervised imitation or coarse-grained reinforcement learning that optimizes single tool calls. Current self-reflection practices rely on heuristic prompts or one-way reasoning: the model is urged to 'think more' instead of learning error diagnosis and repair. This is fragile in multi-turn interactions; after a failure the model often repeats the same mistake. We propose structured reflection, which turns the path from error to repair into an explicit, controllable, and trainable action. The agent produces a short yet precise reflection: it diagnoses the failure using evidence from the previous step and then proposes a correct, executable follow-up call. For training we combine DAPO and GSPO objectives with a reward scheme tailored to tool use, optimizing the stepwise strategy Reflect, then Call, then Final. To evaluate, we introduce Tool-Reflection-Bench, a lightweight benchmark that programmatically checks structural validity, executability, parameter correctness, and result consistency. Tasks are built as mini trajectories of erroneous call, reflection, and corrected call, with disjoint train and test splits. Experiments on BFCL v3 and Tool-Reflection-Bench show large gains in multi-turn tool-call success and error recovery, and a reduction of redundant calls. These results indicate that making reflection explicit and optimizing it directly improves the reliability of tool interaction and offers a reproducible path for agents to learn from failure.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "9pages", "pdf_url": "https://arxiv.org/pdf/2509.18847.pdf", "abstract_url": "https://arxiv.org/abs/2509.18847", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出结构化反思方法，通过将错误诊断和修复转化为可训练动作，提升工具增强大语言模型在多轮交互中的可靠性和准确性。", "motivation": "解决当前工具增强LLMs在失败后重复错误的问题，现有自我反思方法脆弱且不可控。", "method": "结合DAPO和GSPO目标与定制奖励方案，训练代理执行结构化反思（诊断错误并提出正确调用）。", "result": "在BFCL v3和Tool-Reflection-Bench基准测试中，多轮工具调用成功率和错误恢复显著提升，冗余调用减少。", "conclusion": "明确优化反思过程能提高工具交互可靠性，为代理从失败中学习提供可复现路径。"}}
{"id": "2509.18230", "title": "Towards General Computer Control with Hierarchical Agents and Multi-Level Action Spaces", "authors": ["Zihan Dong", "Xinyu Fan", "Zixiang Tang", "Yunqing Li"], "abstract": "Controlling desktop applications via software remains a fundamental yet under-served problem. Existing multi-modal large language models (MLLMs) ingest screenshots and task instructions to generate keystrokes and mouse events, but they suffer from prohibitive inference latency, poor sample efficiency on long-horizon sparse-reward tasks, and infeasible on-device deployment. We introduce a lightweight hierarchical reinforcement learning framework, ComputerAgent, that formulates OS control as a two-level option process (manager and subpolicy), employs a triple-modal state encoder (screenshot, task ID, numeric state) to handle visual and contextual diversity, integrates meta-actions with an early-stop mechanism to reduce wasted interactions, and uses a compact vision backbone plus small policy networks for on-device inference (15M parameters). On a suite of 135 real-world desktop tasks, ComputerAgent attains 92.1% success on simple tasks (<8 steps) and 58.8% on hard tasks (>=8 steps), matching or exceeding 200B-parameter MLLM baselines on simple scenarios while reducing model size by over four orders of magnitude and halving inference time. These results demonstrate that hierarchical RL offers a practical, scalable alternative to monolithic MLLM-based automation for computer control.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.18230.pdf", "abstract_url": "https://arxiv.org/abs/2509.18230", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种轻量级分层强化学习框架ComputerAgent，用于桌面应用控制，通过分层代理和多级动作空间，在保持高性能的同时大幅减小模型规模和推理时间。", "motivation": "解决现有多模态大语言模型在桌面控制中推理延迟高、样本效率低和无法在设备上部署的问题。", "method": "使用分层强化学习框架，包括管理器和子策略，结合三模态状态编码器、元动作和提前停止机制，采用紧凑视觉骨干和小型策略网络。", "result": "在135个真实桌面任务中，简单任务成功率92.1%，困难任务58.8%，模型规模减少四个数量级，推理时间减半，性能匹配或超过大型模型基线。", "conclusion": "分层强化学习为计算机控制提供了实用、可扩展的替代方案，优于单体大模型方法。"}}
{"id": "2509.18891", "title": "Attack for Defense: Adversarial Agents for Point Prompt Optimization Empowering Segment Anything Model", "authors": ["Xueyu Liu", "Xiaoyi Zhang", "Guangze Shi", "Meilin Liu", "Yexin Lai", "Yongfei Wu", "Mingqiang Wei"], "abstract": "Prompt quality plays a critical role in the performance of the Segment Anything Model (SAM), yet existing approaches often rely on heuristic or manually crafted prompts, limiting scalability and generalization. In this paper, we propose Point Prompt Defender, an adversarial reinforcement learning framework that adopts an attack-for-defense paradigm to automatically optimize point prompts. We construct a task-agnostic point prompt environment by representing image patches as nodes in a dual-space graph, where edges encode both physical and semantic distances. Within this environment, an attacker agent learns to activate a subset of prompts that maximally degrade SAM's segmentation performance, while a defender agent learns to suppress these disruptive prompts and restore accuracy. Both agents are trained using Deep Q-Networks with a reward signal based on segmentation quality variation. During inference, only the defender is deployed to refine arbitrary coarse prompt sets, enabling enhanced SAM segmentation performance across diverse tasks without retraining. Extensive experiments show that Point Prompt Defender effectively improves SAM's robustness and generalization, establishing a flexible, interpretable, and plug-and-play framework for prompt-based segmentation.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.18891.pdf", "abstract_url": "https://arxiv.org/abs/2509.18891", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出Point Prompt Defender，一种基于对抗强化学习的框架，通过攻击-防御范式自动优化点提示，提升Segment Anything Model的分割性能和泛化能力。", "motivation": "解决现有方法依赖启发式或手动设计提示的问题，以提高SAM的可扩展性和泛化性。", "method": "使用对抗强化学习，构建双空间图环境，攻击和防御代理通过Deep Q-Networks学习优化提示。", "result": "实验表明，该方法有效提升SAM的鲁棒性和泛化性，无需重新训练。", "conclusion": "建立了一个灵活、可解释的即插即用框架，适用于多种分割任务。"}}
{"id": "2509.18632", "title": "A Good Plan is Hard to Find: Aligning Models with Preferences is Misaligned with What Helps Users", "authors": ["Nishant Balepur", "Matthew Shu", "Yoo Yeon Sung", "Seraphina Goldfarb-Tarrant", "Shi Feng", "Fumeng Yang", "Rachel Rudinger", "Jordan Lee Boyd-Graber"], "abstract": "To assist users in complex tasks, LLMs generate plans: step-by-step instructions towards a goal. While alignment methods aim to ensure LLM plans are helpful, they train (RLHF) or evaluate (ChatbotArena) on what users prefer, assuming this reflects what helps them. We test this with Planorama: an interface where 126 users answer 300 multi-step questions with LLM plans. We get 4388 plan executions and 5584 comparisons to measure plan helpfulness (QA success) and user preferences on plans, and recreate the setup in agents and reward models to see if they simulate or prefer what helps users. We expose: 1) user/model preferences and agent success do not accurately predict which plans help users, so common alignment feedback can misalign with helpfulness; 2) this gap is not due to user-specific preferences, as users are similarly successful when using plans they prefer/disprefer; 3) surface-level cues like brevity and question similarity strongly link to preferences, but such biases fail to predict helpfulness. In all, we argue aligning helpful LLMs needs feedback from real user interactions, not just preferences of what looks helpful, so we discuss the plan NLP researchers can execute to solve this problem.", "subjects": "Computation and Language (cs.CL)", "comments": "EMNLP 2025", "pdf_url": "https://arxiv.org/pdf/2509.18632.pdf", "abstract_url": "https://arxiv.org/abs/2509.18632", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过Planorama实验发现，用户偏好与LLM计划的实际帮助性不一致，强调需要基于真实用户交互而非偏好的反馈来对齐模型。", "motivation": "解决LLM生成计划时，基于用户偏好的对齐方法（如RLHF）可能无法准确反映计划对用户的实际帮助性问题。", "method": "使用Planorama接口，收集126名用户执行300个多步骤问题的数据，通过计划执行和比较评估帮助性和偏好，并模拟代理和奖励模型。", "result": "用户偏好和模型偏好不能准确预测计划帮助性，偏好与帮助性差距非用户特定，表面线索（如简洁性）与偏好相关但无助于预测帮助性。", "conclusion": "对齐有帮助的LLM需要依赖真实用户交互反馈，而非仅偏好，并讨论了NLP研究者如何解决此问题。"}}
{"id": "2509.18713", "title": "MemOrb: A Plug-and-Play Verbal-Reinforcement Memory Layer for E-Commerce Customer Service", "authors": ["Yizhe Huang", "Yang Liu", "Ruiyu Zhao", "Xiaolong Zhong", "Xingming Yue", "Ling Jiang"], "abstract": "Large Language Model-based agents(LLM-based agents) are increasingly deployed in customer service, yet they often forget across sessions, repeat errors, and lack mechanisms for continual self-improvement. This makes them unreliable in dynamic settings where stability and consistency are critical. To better evaluate these properties, we emphasize two indicators: task success rate as a measure of overall effectiveness, and consistency metrics such as Pass$^k$ to capture reliability across multiple trials. To address the limitations of existing approaches, we propose MemOrb, a lightweight and plug-and-play verbal reinforcement memory layer that distills multi-turn interactions into compact strategy reflections. These reflections are stored in a shared memory bank and retrieved to guide decision-making, without requiring any fine-tuning. Experiments show that MemOrb significantly improves both success rate and stability, achieving up to a 63 percentage-point gain in multi-turn success rate and delivering more consistent performance across repeated trials. Our results demonstrate that structured reflection is a powerful mechanism for enhancing long-term reliability of frozen LLM agents in customer service scenarios.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.18713.pdf", "abstract_url": "https://arxiv.org/abs/2509.18713", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出MemOrb，一种即插即用的语言强化记忆层，用于提升电商客服中基于大语言模型的代理的长期可靠性和一致性，无需微调即可显著提高任务成功率和稳定性。", "motivation": "解决基于大语言模型的客服代理在跨会话中遗忘、重复错误和缺乏持续自我改进机制的问题，以提高其在动态环境中的可靠性和一致性。", "method": "采用MemOrb，一个轻量级的即插即用记忆层，通过将多轮交互提炼为紧凑的策略反思，存储在共享记忆库中，并在决策时检索使用，无需模型微调。", "result": "实验表明，MemOrb显著提高了任务成功率和稳定性，多轮成功率最高提升63个百分点，并在重复试验中表现更一致。", "conclusion": "结构化反思是增强冻结大语言模型代理在客服场景中长期可靠性的有效机制，MemOrb为实际部署提供了实用解决方案。"}}
{"id": "2509.18420", "title": "Instruction-Following Evaluation in Function Calling for Large Language Models", "authors": ["Nikolai Skripko"], "abstract": "Function calling is a core capability of large language models, essential for AI agents. Existing benchmarks such as the Berkeley Function Calling Leaderboard (BFCL), tau^2-Bench (", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.18420.pdf", "abstract_url": "https://arxiv.org/abs/2509.18420", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文评估了大型语言模型在函数调用中的指令遵循能力，指出现有基准的局限性，并提出了一种新的评估方法。", "motivation": "解决现有函数调用基准在评估指令遵循能力方面的不足，以提升AI代理的性能。", "method": "提出了一种新的评估方法，可能包括改进的基准或指标，用于更准确地测试指令遵循。", "result": "关键发现可能包括新方法在识别模型弱点方面的有效性，但具体结果未在摘要中提供。", "conclusion": "结论强调了改进评估方法的重要性，以推动大型语言模型在函数调用中的发展。"}}
{"id": "2509.18557", "title": "LLMZ+: Contextual Prompt Whitelist Principles for Agentic LLMs", "authors": ["Tom Pawelek", "Raj Patel", "Charlotte Crowell", "Noorbakhsh Amiri", "Sudip Mittal", "Shahram Rahimi", "Andy Perkins"], "abstract": "Compared to traditional models, agentic AI represents a highly valuable target for potential attackers as they possess privileged access to data sources and API tools, which are traditionally not incorporated into classical agents. Unlike a typical software application residing in a Demilitarized Zone (DMZ), agentic LLMs consciously rely on nondeterministic behavior of the AI (only defining a final goal, leaving the path selection to LLM). This characteristic introduces substantial security risk to both operational security and information security. Most common existing defense mechanism rely on detection of malicious intent and preventing it from reaching the LLM agent, thus protecting against jailbreak attacks such as prompt injection. In this paper, we present an alternative approach, LLMZ+, which moves beyond traditional detection-based approaches by implementing prompt whitelisting. Through this method, only contextually appropriate and safe messages are permitted to interact with the agentic LLM. By leveraging the specificity of context, LLMZ+ guarantees that all exchanges between external users and the LLM conform to predefined use cases and operational boundaries. Our approach streamlines the security framework, enhances its long-term resilience, and reduces the resources required for sustaining LLM information security. Our empirical evaluation demonstrates that LLMZ+ provides strong resilience against the most common jailbreak prompts. At the same time, legitimate business communications are not disrupted, and authorized traffic flows seamlessly between users and the agentic LLM. We measure the effectiveness of approach using false positive and false negative rates, both of which can be reduced to 0 in our experimental setting.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "7 pages, 5 figures, to be published and presented at ICMLA 2025", "pdf_url": "https://arxiv.org/pdf/2509.18557.pdf", "abstract_url": "https://arxiv.org/abs/2509.18557", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出LLMZ+方法，通过上下文提示白名单保护代理型LLM安全，防止越狱攻击，确保合法通信畅通。", "motivation": "代理型AI因访问数据和API工具而成为攻击目标，其非确定性行为带来安全风险，现有基于检测的防御机制不足。", "method": "采用提示白名单方法，仅允许上下文适当的安全消息与LLM交互，基于预定义用例和边界。", "result": "实证评估显示LLMZ+对常见越狱提示具有强韧性，假阳性和假阴性率可降至0，不干扰合法通信。", "conclusion": "LLMZ+简化安全框架，增强长期韧性，减少资源需求，为代理型LLM提供有效安全保障。"}}
{"id": "2509.18633", "title": "Adaptive Learning in Spatial Agent-Based Models for Climate Risk Assessment: A Geospatial Framework with Evolutionary Economic Agents", "authors": ["Yara Mohajerani"], "abstract": "Climate risk assessment requires modelling complex interactions between spatially heterogeneous hazards and adaptive economic systems. We present a novel geospatial agent-based model that integrates climate hazard data with evolutionary learning for economic agents. Our framework combines Mesa-based spatial modelling with CLIMADA climate impact assessment, introducing adaptive learning behaviours that allow firms to evolve strategies for budget allocation, pricing, wages, and risk adaptation through fitness-based selection and mutation. We demonstrate the framework using riverine flood projections under RCP8.5 until 2100, showing that evolutionary adaptation enables firms to converge with baseline (no hazard) production levels after decades of disruption due to climate stress. Our results reveal systemic risks where even agents that are not directly exposed to floods face impacts through supply chain disruptions, with the end-of-century average price of goods 5.6% higher under RCP8.5 compared to the baseline. This open-source framework provides financial institutions and companies with tools to quantify both direct and cascading climate risks while evaluating cost-effective adaptation strategies.", "subjects": "Artificial Intelligence (cs.AI); Risk Management (q-fin.RM)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2509.18633.pdf", "abstract_url": "https://arxiv.org/abs/2509.18633", "categories": ["Artificial Intelligence (cs.AI)", "Risk Management (q-fin.RM)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种结合地理空间建模和进化学习的新型基于代理模型，用于气候风险评估，通过模拟洪水情景展示适应性学习如何减轻生产损失和系统性风险。", "motivation": "解决气候风险评估中复杂空间异质性危害与自适应经济系统交互的建模问题。", "method": "集成Mesa空间建模和CLIMADA气候影响评估，引入基于适应度的进化学习算法，使经济代理能够演化预算分配、定价等策略。", "result": "在RCP8.5情景下，进化适应使企业生产水平在数十年后恢复基准水平，但未直接暴露的代理也面临供应链中断影响，商品价格平均上涨5.6%。", "conclusion": "该开源框架为金融机构和公司提供了量化直接和级联气候风险的工具，有助于评估成本效益高的适应策略。"}}
{"id": "2509.18667", "title": "TERAG: Token-Efficient Graph-Based Retrieval-Augmented Generation", "authors": ["Qiao Xiao", "Hong Ting Tsang", "Jiaxin Bai"], "abstract": "Graph-based Retrieval-augmented generation (RAG) has become a widely studied approach for improving the reasoning, accuracy, and factuality of Large Language Models. However, many existing graph-based RAG systems overlook the high cost associated with LLM token usage during graph construction, hindering large-scale adoption. To address this, we propose TERAG, a simple yet effective framework designed to build informative graphs at a significantly lower cost. Inspired by HippoRAG, we incorporate Personalized PageRank (PPR) during the retrieval phase, and we achieve at least 80% of the accuracy of widely used graph-based RAG methods while consuming only 3%-11% of the output tokens.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "16 pages, 2 figures, 4 tables. Submitted to the 2026 18th International Conference on Machine Learning and Computing (ICMLC 2026), under review", "pdf_url": "https://arxiv.org/pdf/2509.18667.pdf", "abstract_url": "https://arxiv.org/abs/2509.18667", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "TERAG是一种高效的图基检索增强生成框架，通过个性化PageRank减少LLM令牌使用，在保持高精度的同时显著降低成本。", "motivation": "解决现有图基RAG系统在构建图时LLM令牌使用成本高的问题，以促进大规模应用。", "method": "结合HippoRAG思想，在检索阶段使用个性化PageRank，优化图构建过程以减少令牌消耗。", "result": "TERAG仅消耗3%-11%的输出令牌，却能达到广泛使用图基RAG方法至少80%的准确率。", "conclusion": "TERAG框架简单有效，能以低成本构建信息丰富的图，提升RAG的可行性和可扩展性。"}}
{"id": "2509.18710", "title": "Autonomous Data Agents: A New Opportunity for Smart Data", "authors": ["Yanjie Fu", "Dongjie Wang", "Wangyang Ying", "Xiangliang Zhang", "Huan Liu", "Jian Pei"], "abstract": "As data continues to grow in scale and complexity, preparing, transforming, and analyzing it remains labor-intensive, repetitive, and difficult to scale. Since data contains knowledge and AI learns knowledge from it, the alignment between AI and data is essential. However, data is often not structured in ways that are optimal for AI utilization. Moreover, an important question arises: how much knowledge can we pack into data through intensive data operations? Autonomous data agents (DataAgents), which integrate LLM reasoning with task decomposition, action reasoning and grounding, and tool calling, can autonomously interpret data task descriptions, decompose tasks into subtasks, reason over actions, ground actions into python code or tool calling, and execute operations. Unlike traditional data management and engineering tools, DataAgents dynamically plan workflows, call powerful tools, and adapt to diverse data tasks at scale. This report argues that DataAgents represent a paradigm shift toward autonomous data-to-knowledge systems. DataAgents are capable of handling collection, integration, preprocessing, selection, transformation, reweighing, augmentation, reprogramming, repairs, and retrieval. Through these capabilities, DataAgents transform complex and unstructured data into coherent and actionable knowledge. We first examine why the convergence of agentic AI and data-to-knowledge systems has emerged as a critical trend. We then define the concept of DataAgents and discuss their architectural design, training strategies, as well as the new skills and capabilities they enable. Finally, we call for concerted efforts to advance action workflow optimization, establish open datasets and benchmark ecosystems, safeguard privacy, balance efficiency with scalability, and develop trustworthy DataAgent guardrails to prevent malicious actions.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.18710.pdf", "abstract_url": "https://arxiv.org/abs/2509.18710", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出自主数据代理（DataAgents），通过集成LLM推理、任务分解和工具调用，自动化处理复杂数据任务，实现数据到知识的转换。", "motivation": "数据规模扩大和复杂性增加导致数据准备和分析工作繁重、难以扩展，且数据未优化用于AI利用，限制了知识提取效率。", "method": "采用自主数据代理，结合LLM推理进行任务分解、动作推理、代码生成和工具调用，动态规划工作流以适应多样数据任务。", "result": "DataAgents能够处理数据收集、集成、预处理等多种操作，将复杂数据转化为可操作知识，推动自主数据知识系统的发展。", "conclusion": "DataAgents代表数据管理的范式转变，呼吁优化工作流、建立基准、保障隐私和开发可信防护措施。"}}
{"id": "2509.18787", "title": "The AGNTCY Agent Directory Service: Architecture and Implementation", "authors": ["Luca Muscariello", "Vijoy Pandey", "Ramiz Polic"], "abstract": "The Agent Directory Service (ADS) is a distributed directory for the discovery of AI agent capabilities, metadata, and provenance. It leverages content-addressed storage, hierarchical taxonomies, and cryptographic signing to enable efficient, verifiable, and multi-dimensional discovery across heterogeneous Multi-Agent Systems (MAS). Built on the Open Agentic Schema Framework (OASF), ADS decouples capability indexing from content location through a two-level mapping realized over a Kademlia-based Distributed Hash Table (DHT). It reuses mature OCI / ORAS infrastructure for artifact distribution, integrates Sigstore for provenance, and supports schema-driven extensibility for emerging agent modalities (LLM prompt agents, MCP servers, A2A-enabled components). This paper formalizes the architectural model, describes storage and discovery layers, explains security and performance properties, and positions ADS within the broader landscape of emerging agent registry and interoperability initiatives.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.18787.pdf", "abstract_url": "https://arxiv.org/abs/2509.18787", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了AGNTCY代理目录服务的架构与实现，这是一个用于AI代理能力发现的分布式目录系统。", "motivation": "解决异构多代理系统中代理能力、元数据和来源的发现难题，确保高效、可验证的多维发现。", "method": "基于Open Agentic Schema Framework，使用内容寻址存储、层次分类法、加密签名和Kademlia DHT实现两层映射。", "result": "系统支持可扩展性，集成OCI/ORAS和Sigstore，提高了安全性和性能。", "conclusion": "ADS为新兴代理注册和互操作性提供了有效解决方案，具有广泛的应用前景。"}}
{"id": "2509.18917", "title": "LiDAR Point Cloud Image-based Generation Using Denoising Diffusion Probabilistic Models", "authors": ["Amirhesam Aghanouri", "Cristina Olaverri-Monreal"], "abstract": "Autonomous vehicles (AVs) are expected to revolutionize transportation by improving efficiency and safety. Their success relies on 3D vision systems that effectively sense the environment and detect traffic agents. Among sensors AVs use to create a comprehensive view of surroundings, LiDAR provides high-resolution depth data enabling accurate object detection, safe navigation, and collision avoidance. However, collecting real-world LiDAR data is time-consuming and often affected by noise and sparsity due to adverse weather or sensor limitations. This work applies a denoising diffusion probabilistic model (DDPM), enhanced with novel noise scheduling and time-step embedding techniques to generate high-quality synthetic data for augmentation, thereby improving performance across a range of computer vision tasks, particularly in AV perception. These modifications impact the denoising process and the model's temporal awareness, allowing it to produce more realistic point clouds based on the projection. The proposed method was extensively evaluated under various configurations using the IAMCV and KITTI-360 datasets, with four performance metrics compared against state-of-the-art (SOTA) methods. The results demonstrate the model's superior performance over most existing baselines and its effectiveness in mitigating the effects of noisy and sparse LiDAR data, producing diverse point clouds with rich spatial relationships and structural detail.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.18917.pdf", "abstract_url": "https://arxiv.org/abs/2509.18917", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文应用改进的去噪扩散概率模型生成高质量合成LiDAR点云数据，以增强自动驾驶视觉系统性能。", "motivation": "解决真实LiDAR数据收集耗时、易受噪声和稀疏性影响的问题，以改善自动驾驶感知任务。", "method": "使用去噪扩散概率模型，结合新颖的噪声调度和时间步嵌入技术，生成合成点云数据。", "result": "在IAMCV和KITTI-360数据集上评估，模型在多种性能指标上优于现有方法，能有效减轻噪声和稀疏性影响。", "conclusion": "该方法能生成多样且结构丰富的点云，提升自动驾驶感知系统的鲁棒性和性能。"}}
{"id": "2509.18813", "title": "MAPEX: A Multi-Agent Pipeline for Keyphrase Extraction", "authors": ["Liting Zhang", "Shiwan Zhao", "Aobo Kong", "Qicheng Li"], "abstract": "Keyphrase extraction is a fundamental task in natural language processing. However, existing unsupervised prompt-based methods for Large Language Models (LLMs) often rely on single-stage inference pipelines with uniform prompting, regardless of document length or LLM backbone. Such one-size-fits-all designs hinder the full exploitation of LLMs' reasoning and generation capabilities, especially given the complexity of keyphrase extraction across diverse scenarios. To address these challenges, we propose MAPEX, the first framework that introduces multi-agent collaboration into keyphrase extraction. MAPEX coordinates LLM-based agents through modules for expert recruitment, candidate extraction, topic guidance, knowledge augmentation, and post-processing. A dual-path strategy dynamically adapts to document length: knowledge-driven extraction for short texts and topic-guided extraction for long texts. Extensive experiments on six benchmark datasets across three different LLMs demonstrate its strong generalization and universality, outperforming the state-of-the-art unsupervised method by 2.44\\% and standard LLM baselines by 4.01\\% in F1@5 on average. Code is available at", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.18813.pdf", "abstract_url": "https://arxiv.org/abs/2509.18813", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出MAPEX，首个将多智能体协作引入关键词提取的框架，通过动态双路径策略适应文档长度，在多个基准数据集上超越现有方法。", "motivation": "解决现有无监督提示方法在关键词提取中因统一提示设计而无法充分利用大型语言模型能力的问题，特别是在处理不同长度文档时。", "method": "MAPEX框架采用多智能体协作，包括专家招募、候选提取、主题引导、知识增强和后处理模块，使用双路径策略动态适应文档长度。", "result": "在六个基准数据集和三种大型语言模型上的实验显示，MAPEX平均F1@5分数比最先进无监督方法高2.44%，比标准基线高4.01%。", "conclusion": "MAPEX展示了强大的泛化性和普适性，为关键词提取任务提供了更有效的解决方案。"}}
{"id": "2509.19002", "title": "VIR-Bench: Evaluating Geospatial and Temporal Understanding of MLLMs via Travel Video Itinerary Reconstruction", "authors": ["Hao Wang", "Eiki Murata", "Lingfang Zhang", "Ayako Sato", "So Fukuda", "Ziqi Yin", "Wentao Hu", "Keisuke Nakao", "Yusuke Nakamura", "Sebastian Zwirner", "Yi-Chia Chen", "Hiroyuki Otomo", "Hiroki Ouchi", "Daisuke Kawahara"], "abstract": "Recent advances in multimodal large language models (MLLMs) have significantly enhanced video understanding capabilities, opening new possibilities for practical applications. Yet current video benchmarks focus largely on indoor scenes or short-range outdoor activities, leaving the challenges associated with long-distance travel largely unexplored. Mastering extended geospatial-temporal trajectories is critical for next-generation MLLMs, underpinning real-world tasks such as embodied-AI planning and navigation. To bridge this gap, we present VIR-Bench, a novel benchmark consisting of 200 travel videos that frames itinerary reconstruction as a challenging task designed to evaluate and push forward MLLMs' geospatial-temporal intelligence. Experimental results reveal that state-of-the-art MLLMs, including proprietary ones, struggle to achieve high scores, underscoring the difficulty of handling videos that span extended spatial and temporal scales. Moreover, we conduct an in-depth case study in which we develop a prototype travel-planning agent that leverages the insights gained from VIR-Bench. The agent's markedly improved itinerary recommendations verify that our evaluation protocol not only benchmarks models effectively but also translates into concrete performance gains in user-facing applications.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.19002.pdf", "abstract_url": "https://arxiv.org/abs/2509.19002", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了VIR-Bench，一个评估多模态大语言模型在长距离旅行视频中地理空间和时间理解能力的新基准，通过实验和案例研究验证其有效性。", "motivation": "当前视频基准主要关注室内或短距离户外场景，缺乏对长距离旅行相关挑战的评估，而掌握扩展的地理空间-时间轨迹对下一代MLLMs至关重要。", "method": "提出VIR-Bench基准，包含200个旅行视频，将行程重建作为任务来评估MLLMs，并通过案例研究开发旅行规划代理。", "result": "实验显示，现有先进MLLMs在VIR-Bench上得分较低，表明处理长时空视频的困难；案例研究中代理的行程推荐性能显著提升。", "conclusion": "VIR-Bench不仅能有效评估模型，还能转化为实际应用中的性能改进，推动MLLMs在现实世界任务中的发展。"}}
{"id": "2509.18868", "title": "Memory in Large Language Models: Mechanisms, Evaluation and Evolution", "authors": ["Dianxing Zhang", "Wendong Li", "Kani Song", "Jiaye Lu", "Gang Li", "Liuchun Yang", "Sheng Li"], "abstract": "Under a unified operational definition, we define LLM memory as a persistent state written during pretraining, finetuning, or inference that can later be addressed and that stably influences outputs. We propose a four-part taxonomy (parametric, contextual, external, procedural/episodic) and a memory quadruple (location, persistence, write/access path, controllability). We link mechanism, evaluation, and governance via the chain write -> read -> inhibit/update. To avoid distorted comparisons across heterogeneous setups, we adopt a three-setting protocol (parametric only, offline retrieval, online retrieval) that decouples capability from information availability on the same data and timeline. On this basis we build a layered evaluation: parametric (closed-book recall, edit differential, memorization/privacy), contextual (position curves and the mid-sequence drop), external (answer correctness vs snippet attribution/faithfulness), and procedural/episodic (cross-session consistency and timeline replay, E MARS+). The framework integrates temporal governance and leakage auditing (freshness hits, outdated answers, refusal slices) and uncertainty reporting via inter-rater agreement plus paired tests with multiple-comparison correction. For updating and forgetting, we present DMM Gov: coordinating DAPT/TAPT, PEFT, model editing (ROME, MEND, MEMIT, SERAC), and RAG to form an auditable loop covering admission thresholds, rollout, monitoring, rollback, and change audits, with specs for timeliness, conflict handling, and long-horizon consistency. Finally, we give four testable propositions: minimum identifiability; a minimal evaluation card; causally constrained editing with verifiable forgetting; and when retrieval with small-window replay outperforms ultra-long-context reading. This yields a reproducible, comparable, and governable coordinate system for research and deployment.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "50 pages, 1 figure, 8 tables This is a survey/framework paper on LLM memory mechanisms and evaluation", "pdf_url": "https://arxiv.org/pdf/2509.18868.pdf", "abstract_url": "https://arxiv.org/abs/2509.18868", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一个统一的大语言模型（LLM）内存定义、分类和评估框架，包括四部分分类法、内存四元组、三层评估协议以及更新治理机制，旨在实现内存研究的可重复性和可治理性。", "motivation": "解决LLM内存机制、评估和治理缺乏统一标准和可比性的问题，以避免异构设置下的扭曲比较。", "method": "采用操作定义、分类法（参数、上下文、外部、过程/情节内存）、内存四元组、三层评估协议（参数、离线检索、在线检索）和DMM Gov治理框架。", "result": "构建了分层评估体系，包括参数内存的回忆和隐私测试、上下文内存的位置曲线、外部内存的归因忠实性等，并提出了四个可测试命题。", "conclusion": "该框架为LLM内存研究提供了可重复、可比和可治理的坐标系统，促进部署中的一致性和审计能力。"}}
{"id": "2509.18970", "title": "LLM-based Agents Suffer from Hallucinations: A Survey of Taxonomy, Methods, and Directions", "authors": ["Xixun Lin", "Yucheng Ning", "Jingwen Zhang", "Yan Dong", "Yilong Liu", "Yongxuan Wu", "Xiaohua Qi", "Nan Sun", "Yanmin Shang", "Pengfei Cao", "Lixin Zou", "Xu Chen", "Chuan Zhou", "Jia Wu", "Shirui Pan", "Bin Wang", "Yanan Cao", "Kai Chen", "Songlin Hu", "Li Guo"], "abstract": "Driven by the rapid advancements of Large Language Models (LLMs), LLM-based agents have emerged as powerful intelligent systems capable of human-like cognition, reasoning, and interaction. These agents are increasingly being deployed across diverse real-world applications, including student education, scientific research, and financial analysis. However, despite their remarkable potential, LLM-based agents remain vulnerable to hallucination issues, which can result in erroneous task execution and undermine the reliability of the overall system design. Addressing this critical challenge requires a deep understanding and a systematic consolidation of recent advances on LLM-based agents. To this end, we present the first comprehensive survey of hallucinations in LLM-based agents. By carefully analyzing the complete workflow of agents, we propose a new taxonomy that identifies different types of agent hallucinations occurring at different stages. Furthermore, we conduct an in-depth examination of eighteen triggering causes underlying the emergence of agent hallucinations. Through a detailed review of a large number of existing studies, we summarize approaches for hallucination mitigation and detection, and highlight promising directions for future research. We hope this survey will inspire further efforts toward addressing hallucinations in LLM-based agents, ultimately contributing to the development of more robust and reliable agent systems.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.18970.pdf", "abstract_url": "https://arxiv.org/abs/2509.18970", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文是关于LLM智能体幻觉问题的首次全面综述，提出了幻觉分类、触发原因、缓解方法，并展望未来研究方向。", "motivation": "解决LLM智能体因幻觉问题导致的错误任务执行和系统可靠性不足，需要系统化理解近期进展。", "method": "通过分析智能体工作流程提出新分类法，深入探讨18种触发原因，并总结现有研究的缓解和检测方法。", "result": "识别了不同阶段的幻觉类型和原因，总结了缓解策略，为未来研究提供基础。", "conclusion": "本综述旨在激发更多努力，开发更鲁棒可靠的智能体系统。"}}
{"id": "2509.18883", "title": "LongCat-Flash-Thinking Technical Report", "authors": ["Meituan LongCat Team", "Anchun Gui", "Bei Li", "Bingyang Tao", "Bole Zhou", "Borun Chen", "Chao Zhang", "Chao Zhang", "Chengcheng Han", "Chenhui Yang", "Chi Zhang", "Chong Peng", "Chuyu Zhang", "Cong Chen", "Fengcun Li", "Gang Xu", "Guoyuan Lin", "Hao Jiang", "Hao Liang", "Haomin Fu", "Haoxiang Ma", "Hong Liu", "Hongyan Hao", "Hongyin Tang", "Hongyu Zang", "Hongzhi Ni", "Hui Su", "Jiahao Liu", "Jiahuan Li", "Jialin Liu", "Jianfei Zhang", "Jianhao Xu", "Jianing Wang", "Jiaqi Sun", "Jiaqi Zhang", "Jiarong Shi", "Jiawei Yang", "Jingang Wang", "Jinrui Ding", "Jun Kuang", "Jun Xu", "Ke He", "Kefeng Zhang", "Keheng Wang", "Keqing He", "Li Wei", "Liang Shi", "Lin Qiu", "Lingbin Kong", "Lingchuan Liu", "Linsen Guo", "Longfei An", "Mai Xia", "Meng Zhou", "Mengshen Zhu", "Peng Pei", "Pengcheng Jia", "Qi Gu", "Qi Guo", "Qiong Huang", "Quan Chen", "Quanchi Weng", "Rongxiang Weng", "Ruichen Shao", "Rumei Li", "Shanglin Lei", "Shuai Du", "Shuaikang Liu", "Shuang Zhou", "Shuhao Hu", "Siyu Xu", "Songshan Gong", "Tao Liang", "Tianhao Hu", "Wei He", "Wei Shi", "Wei Wang", "Wei Wu", "Wei Zhuo", "Weifeng Tang", "Wenjie Shi", "Wenlong Zhu", "Xi Su", "Xiangcheng Liu", "Xiangyu Xi", "Xiangzhou Huang", "Xiao Liu", "Xiaochen Jiang", "Xiaowei Shi", "Xiaowen Shi", "Xiaoyu Li", "Xin Chen", "Xinyue Zhao", "Xuan Huang", "Xuemiao Zhang", "Xuezhi Cao", "Xunliang Cai", "Yajie Zhang", "Yang Chen", "Yang Liu"], "abstract": "We present LongCat-Flash-Thinking, an efficient 560-billion-parameter open-source Mixture-of-Experts (MoE) reasoning model. Its advanced capabilities are cultivated through a meticulously crafted training process, beginning with long Chain-of-Thought (CoT) data cold-start and culminating in large-scale Reinforcement Learning (RL). We first employ a well-designed cold-start training strategy, which significantly enhances the reasoning potential and equips the model with specialized skills in both formal and agentic reasoning. Then, a core innovation is our domain-parallel training scheme, which decouples optimization across distinct domains (e.g., STEM, Code, Agentic) and subsequently fuses the resulting expert models into a single, nearly Pareto-optimal model. This entire process is powered by our Dynamic ORchestration for Asynchronous rollout (DORA) system, a large-scale RL framework that delivers a greater than threefold training speedup over synchronous methods on tens of thousands of accelerators. As a result, LongCat-Flash-Thinking achieves state-of-the-art performance among open-source models on a suite of complex reasoning tasks. The model exhibits exceptional efficiency in agentic reasoning, reducing average token consumption by 64.5% (from 19, 653 to 6, 965) on AIME-25, without degrading task accuracy. We release LongCat-Flash-Thinking to promote further advances in reasoning systems and agentic AI research.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.18883.pdf", "abstract_url": "https://arxiv.org/abs/2509.18883", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "LongCat-Flash-Thinking是一个高效的5600亿参数开源MoE推理模型，通过冷启动训练和大规模RL实现，在复杂推理任务中达到最先进性能，并显著提升效率。", "motivation": "解决复杂推理任务中模型效率和性能不足的问题，特别是在开源模型中提升推理能力和减少资源消耗。", "method": "使用长链思维数据冷启动训练，结合领域并行训练方案和DORA系统进行大规模RL优化，融合专家模型。", "result": "在AIME-25上平均token消耗减少64.5%，任务准确率未下降，实现状态最优性能。", "conclusion": "该模型推动了推理系统和代理AI研究，通过高效训练方法为开源社区提供先进工具。"}}
{"id": "2509.19077", "title": "Code Driven Planning with Domain-Adaptive Critic", "authors": ["Zikang Tian", "Shaohui Peng", "Du Huang", "Jiaming Guo", "Ruizhi Chen", "Rui Zhang", "Xishan Zhang", "Yuxuan Guo", "Zidong Du", "Qi Guo", "Ling Li", "Yewen Pu", "Xing Hu", "Yunji Chen"], "abstract": "Large Language Models (LLMs) have been widely adopted as task planners for AI agents in sequential decision-making problems, leveraging their extensive world knowledge. However, the gap between their general knowledge and environment-specific requirements often leads to inaccurate plans. To address this, existing approaches rely on frequent LLM queries to iteratively refine plans based on immediate environmental feedback, which incurs substantial query costs. However, this refinement is typically guided by short-term environmental feedback, limiting LLMs from developing plans aligned with long-term rewards. We propose Code Driven Planning with Domain-Adaptive Critic (CoPiC). Instead of relying on frequent queries, CoPiC employs LLMs to generate a diverse set of high-level planning programs, which iteratively produce and refine candidate plans. A trained domain-adaptive critic then evaluates these candidates and selects the one most aligned with long-term rewards for execution. Using high-level planning programs as planner and domain-adaptive critic as estimator, CoPiC improves planning while significantly reducing query costs. Results in ALFWorld, NetHack, and StarCraft II Unit Building show that CoPiC outperforms advanced LLM-based baselines, AdaPlanner and Reflexion, achieving an average (1) 23.33% improvement in success rate and (2) 91.27% reduction in query costs.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.19077.pdf", "abstract_url": "https://arxiv.org/abs/2509.19077", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出CoPiC方法，通过生成多样化高级规划程序并使用领域自适应评论家评估，减少LLM查询成本并提高长期奖励对齐的计划成功率。", "motivation": "解决LLM在任务规划中因通用知识与环境特定需求不匹配导致的计划不准确问题，以及现有方法依赖频繁查询和短期反馈的高成本和长期规划不足。", "method": "使用LLM生成多样化高级规划程序迭代生成候选计划，训练领域自适应评论家评估候选以选择长期奖励最优计划。", "result": "在ALFWorld、NetHack和StarCraft II实验中，CoPiC相比基线平均提高成功率23.33%，减少查询成本91.27%。", "conclusion": "CoPiC通过程序驱动规划和自适应评论家，有效提升规划性能并显著降低成本，适用于复杂决策问题。"}}
{"id": "2509.19199", "title": "Online Process Reward Leanring for Agentic Reinforcement Learning", "authors": ["Xiaoqian Liu", "Ke Wang", "Yuchuan Wu", "Fei Huang", "Yongbin Li", "Junge Zhang", "Jianbin Jiao"], "abstract": "Large language models (LLMs) are increasingly trained with reinforcement learning (RL) as autonomous agents that reason and act over long horizons in interactive environments.", "subjects": "Computation and Language (cs.CL)", "comments": "preprint", "pdf_url": "https://arxiv.org/pdf/2509.19199.pdf", "abstract_url": "https://arxiv.org/abs/2509.19199", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "该论文探讨了在大型语言模型作为自主代理进行长期推理和行动时，如何通过在线过程奖励学习来改进强化学习。", "motivation": "解决在交互环境中，大型语言模型作为自主代理进行强化学习时，奖励信号难以定义和优化的问题。", "method": "采用在线过程奖励学习方法，可能涉及动态调整奖励函数以改进代理行为。", "result": "关键发现未在摘要中明确，但暗示该方法可能提升代理在长期任务中的性能。", "conclusion": "结论是这种方法有望增强自主代理的强化学习效果，具有实际应用潜力。"}}
{"id": "2509.19236", "title": "AgentInit: Initializing LLM-based Multi-Agent Systems via Diversity and Expertise Orchestration for Effective and Efficient Collaboration", "authors": ["Chunhao Tian", "Yutong Wang", "Xuebo Liu", "Zhexuan Wang", "Liang Ding", "Miao Zhang", "Min Zhang"], "abstract": "Proper initialization is crucial for any system, particularly in multi-agent systems (MAS), where it plays a pivotal role in determining both the system's efficiency and effectiveness. However, existing MAS initialization methods do not fully account for the collaborative needs of the generated agents in subsequent stages. Inspired by the principles of effective team composition, we propose AgentInit, which aims to optimize the structure of agent teams. Specifically, in addition to multi-round interactions and reflections between agents during agent generation, AgentInit incorporates a Natural Language to Format mechanism to ensure consistency and standardization. Balanced team selection strategies using Pareto principles are subsequently applied to jointly consider agent team diversity and task relevance to promote effective and efficient collaboration and enhance overall system performance. Experiments show that AgentInit consistently outperforms state-of-the-art initialization methods and pre-defined strategies across various frameworks and tasks, achieving an overall performance improvement of up to 1.2 and 1.6, respectively, while also significantly reducing token consumption. Further analysis confirms its strong transferability to similar tasks and verifies the effectiveness of its key components, demonstrating its capability and adaptability as a reliable MAS initialization method. Source code and models are available at", "subjects": "Artificial Intelligence (cs.AI)", "comments": "EMNLP 2025 Findings", "pdf_url": "https://arxiv.org/pdf/2509.19236.pdf", "abstract_url": "https://arxiv.org/abs/2509.19236", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出AgentInit方法，通过多样性和专业性的编排来初始化基于LLM的多智能体系统，以提高协作效率和效果。", "motivation": "现有多智能体系统初始化方法未充分考虑后续协作需求，本文旨在解决此问题以优化系统性能。", "method": "采用多轮交互、反思、自然语言到格式机制，以及基于帕累托原则的平衡团队选择策略。", "result": "实验显示AgentInit在多种框架和任务中优于现有方法，性能提升达1.2和1.6倍，并显著减少令牌消耗。", "conclusion": "AgentInit具有强可转移性和适应性，是一种可靠的多智能体系统初始化方法。"}}
{"id": "2509.18119", "title": "MobileRL: Online Agentic Reinforcement Learning for Mobile GUI Agents", "authors": ["Yifan Xu", "Xiao Liu", "Xinghan Liu", "Jiaqi Fu", "Hanchen Zhang", "Bohao Jing", "Shudan Zhang", "Yuting Wang", "Wenyi Zhao", "Yuxiao Dong"], "abstract": "Building general-purpose graphical user interface (GUI) agents has become increasingly promising with the progress in vision language models. However, developing effective mobile GUI agents with reinforcement learning (RL) remains challenging due to the heavy-tailed distribution of task difficulty and the inefficiency of large-scale environment sampling. We present an online agentic reinforcement learning framework MOBILERL to enhance GUI agents in mobile environments. Its core component is the Difficulty-Adaptive GRPO (ADAGRPO) algorithm. In ADAGRPO, we design difficulty-adaptive positive replay and failure curriculum filtering to adapt the model to different task difficulties. We introduce the shortest path reward adjustment strategy to reshape rewards concerning the task length in multi-turn agentic tasks. Those strategies jointly stabilize RL training, improve sample efficiency, and generate strong performance across diverse mobile apps and tasks. We apply MOBILERL to two open models (Qwen2.5-VL-7B-Instruct and GLM-4.1V-9B-Base). The resultant MOBILERL-9B model achieves state-of-the-art results in terms of success rates on both AndroidWorld (75.8%) and AndroidLab (46.8%). The MOBILERL framework is adopted in the AutoGLM products, and also open-sourced at", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.18119.pdf", "abstract_url": "https://arxiv.org/abs/2509.18119", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了MobileRL框架，通过ADAGRPO算法增强移动GUI代理，在AndroidWorld和AndroidLab上实现SOTA成功率。", "motivation": "解决移动GUI代理在强化学习中任务难度分布重尾和大规模环境采样效率低的问题。", "method": "使用在线强化学习框架，核心为ADAGRPO算法，包括难度自适应重放、失败课程过滤和最短路径奖励调整。", "result": "MobileRL-9B模型在AndroidWorld和AndroidLab上的成功率分别达到75.8%和46.8%。", "conclusion": "MobileRL框架稳定训练、提高样本效率，性能优越，已应用于AutoGLM产品并开源。"}}
{"id": "2509.18169", "title": "PiMoE: Token-Level Routing for Integrating High-Precision Computation and Reasoning", "authors": ["Hengbo Xiao", "Jingyuan Fan", "Xin Tong", "Jingzhao Zhang", "Chao Lu", "Guannan He"], "abstract": "Complex systems typically rely on high-precision numerical computation to support decisions, but current large language models (LLMs) cannot yet incorporate such computations as an intrinsic and interpretable capability with existing architectures. Mainstream multi-agent approaches can leverage external experts, but inevitably introduce communication overhead and suffer from inefficient multimodal emergent capability and limited scalability. To this end, we propose PiMoE (Physically-isolated Mixture of Experts), a training and inference architecture for integrating computation and reasoning. Instead of the workflow paradigm of tool invocation, PiMoE endogenously integrates computational capabilities into neural networks after separately training experts, a text-to-computation module, and a router. At inference, the router directs computation and reasoning at the token level, thereby enabling iterative alternation within a single chain of thought. We evaluate PiMoE on two reasoning-computation tasks against LLM finetuning and the multi-agent system approaches. Results show that the PiMoE architecture achieves not only higher accuracy than directly finetuning LLMs but also significant improvements in response latency, token usage, and GPU energy consumption compared with mainstream multi-agent approaches. PiMoE offers an efficient, interpretable, and scalable paradigm for next-generation scientific or industrial intelligent systems.", "subjects": "Machine Learning (cs.LG); Computational Engineering, Finance, and Science (cs.CE); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.18169.pdf", "abstract_url": "https://arxiv.org/abs/2509.18169", "categories": ["Machine Learning (cs.LG)", "Computational Engineering, Finance, and Science (cs.CE)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "PiMoE提出了一种新的训练和推理架构，通过令牌级路由在神经网络中内源性地集成计算和推理能力，提高效率、准确性和可扩展性。", "motivation": "解决当前大语言模型无法内源且可解释地集成高精度计算的问题，避免多智能体方法的通信开销和效率限制。", "method": "使用物理隔离的专家混合模型，包括单独训练的专家、文本到计算模块和路由器，在推理时通过令牌级路由实现计算与推理的迭代交替。", "result": "在推理-计算任务中，PiMoE比直接微调LLM精度更高，比多智能体方法在延迟、令牌使用和GPU能耗上有显著改进。", "conclusion": "PiMoE为下一代科学或工业智能系统提供了高效、可解释和可扩展的范式。"}}
{"id": "2509.18200", "title": "Conversational Orientation Reasoning: Egocentric-to-Allocentric Navigation with Multimodal Chain-of-Thought", "authors": ["Yu Ti Huang"], "abstract": "Conversational agents must translate egocentric utterances (e.g., \"on my right\") into allocentric orientations (N/E/S/W). This challenge is particularly critical in indoor or complex facilities where GPS signals are weak and detailed maps are unavailable. While chain-of-thought (CoT) prompting has advanced reasoning in language and vision tasks, its application to multimodal spatial orientation remains underexplored. We introduce Conversational Orientation Reasoning (COR), a new benchmark designed for Traditional Chinese conversational navigation projected from real-world environments, addressing egocentric-to-allocentric reasoning in non-English and ASR-transcribed scenarios. We propose a multimodal chain-of-thought (MCoT) framework, which integrates ASR-transcribed speech with landmark coordinates through a structured three-step reasoning process: (1) extracting spatial relations, (2) mapping coordinates to absolute directions, and (3) inferring user orientation. A curriculum learning strategy progressively builds these capabilities on Taiwan-LLM-13B-v2.0-Chat, a mid-sized model representative of resource-constrained settings. Experiments show that MCoT achieves 100% orientation accuracy on clean transcripts and 98.1% with ASR transcripts, substantially outperforming unimodal and non-structured baselines. Moreover, MCoT demonstrates robustness under noisy conversational conditions, including ASR recognition errors and multilingual code-switching. The model also maintains high accuracy in cross-domain evaluation and resilience to linguistic variation, domain shift, and referential ambiguity. These findings highlight the potential of structured MCoT spatial reasoning as a path toward interpretable and resource-efficient embodied navigation.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.18200.pdf", "abstract_url": "https://arxiv.org/abs/2509.18200", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了对话式方向推理（COR）基准和多模态思维链（MCoT）框架，用于在中文对话导航中将自我中心方向转换为绝对方向，通过结构化推理在资源受限环境中实现高精度和鲁棒性。", "motivation": "解决在GPS信号弱或无详细地图的室内环境中，对话代理如何准确理解自我中心话语（如'在我的右边'）并将其转换为绝对方向（如北/东/南/西）的问题，特别是在非英语和ASR转录场景下。", "method": "使用多模态思维链（MCoT）框架，整合ASR转录语音和地标坐标，通过三步推理过程（提取空间关系、映射坐标到绝对方向、推断用户方向），并采用课程学习策略在Taiwan-LLM-13B-v2.0-Chat模型上训练。", "result": "MCoT在干净转录上达到100%方向准确率，在ASR转录上达到98.1%，优于单模态和非结构化基线，且在噪声对话条件、跨域评估和语言变异下表现出鲁棒性。", "conclusion": "结构化MCoT空间推理具有潜力，可实现可解释和资源高效的具身导航，适用于复杂环境。"}}
{"id": "2509.18407", "title": "Assistive Decision-Making for Right of Way Navigation at Uncontrolled Intersections", "authors": ["Navya Tiwari", "Joseph Vazhaeparampil", "Victoria Preston"], "abstract": "Uncontrolled intersections account for a significant fraction of roadway crashes due to ambiguous right-of-way rules, occlusions, and unpredictable driver behavior. While autonomous vehicle research has explored uncertainty-aware decision making, few systems exist to retrofit human-operated vehicles with assistive navigation support. We present a driver-assist framework for right-of-way reasoning at uncontrolled intersections, formulated as a Partially Observable Markov Decision Process (POMDP). Using a custom simulation testbed with stochastic traffic agents, pedestrians, occlusions, and adversarial scenarios, we evaluate four decision-making approaches: a deterministic finite state machine (FSM), and three probabilistic planners: QMDP, POMCP, and DESPOT. Results show that probabilistic planners outperform the rule-based baseline, achieving up to 97.5 percent collision-free navigation under partial observability, with POMCP prioritizing safety and DESPOT balancing efficiency and runtime feasibility. Our findings highlight the importance of uncertainty-aware planning for driver assistance and motivate future integration of sensor fusion and environment perception modules for real-time deployment in realistic traffic environments.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)", "comments": "6 pages, 5 figures. Accepted as a poster at Northeast Robotics Colloquium (NERC 2025). Extended abstract", "pdf_url": "https://arxiv.org/pdf/2509.18407.pdf", "abstract_url": "https://arxiv.org/abs/2509.18407", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于POMDP的驾驶员辅助框架，用于无信号交叉口的优先通行决策，通过仿真评估显示概率规划器优于规则基准，实现高安全导航。", "motivation": "解决无信号交叉口因规则模糊、遮挡和不可预测行为导致的高事故率问题，现有系统缺乏对人工驾驶车辆的辅助支持。", "method": "采用部分可观察马尔可夫决策过程（POMDP）建模，在自定义仿真环境中比较确定性有限状态机（FSM）和三种概率规划器（QMDP、POMCP、DESPOT）。", "result": "概率规划器优于基准，碰撞避免率高达97.5%，POMCP注重安全，DESPOT平衡效率和实时性。", "conclusion": "不确定性感知规划对驾驶辅助至关重要，未来需集成传感器融合和环境感知模块以实现实时部署。"}}
{"id": "2509.18661", "title": "Agentic AutoSurvey: Let LLMs Survey LLMs", "authors": ["Yixin Liu", "Yonghui Wu", "Denghui Zhang", "Lichao Sun"], "abstract": "The exponential growth of scientific literature poses unprecedented challenges for researchers attempting to synthesize knowledge across rapidly evolving fields. We present \\textbf{Agentic AutoSurvey}, a multi-agent framework for automated survey generation that addresses fundamental limitations in existing approaches. Our system employs four specialized agents (Paper Search Specialist, Topic Mining \\& Clustering, Academic Survey Writer, and Quality Evaluator) working in concert to generate comprehensive literature surveys with superior synthesis quality. Through experiments on six representative LLM research topics from COLM 2024 categories, we demonstrate that our multi-agent approach achieves significant improvements over existing baselines, scoring 8.18/10 compared to AutoSurvey's 4.77/10. The multi-agent architecture processes 75--443 papers per topic (847 total across six topics) while targeting high citation coverage (often $\\geq$80\\% on 75--100-paper sets; lower on very large sets such as RLHF) through specialized agent orchestration. Our 12-dimension evaluation captures organization, synthesis integration, and critical analysis beyond basic metrics. These findings demonstrate that multi-agent architectures represent a meaningful advancement for automated literature survey generation in rapidly evolving scientific domains.", "subjects": "Information Retrieval (cs.IR); Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)", "comments": "29 pages, 7 figures", "pdf_url": "https://arxiv.org/pdf/2509.18661.pdf", "abstract_url": "https://arxiv.org/abs/2509.18661", "categories": ["Information Retrieval (cs.IR)", "Computation and Language (cs.CL)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了Agentic AutoSurvey，一种多智能体框架，用于自动生成文献综述，通过四个专业智能体协作，在六个LLM研究主题上显著优于现有基线，评分从4.77提升至8.18/10。", "motivation": "解决科学文献爆炸式增长带来的知识综合挑战，现有方法在综述生成质量上存在局限。", "method": "采用多智能体框架，包括论文搜索专家、主题挖掘与聚类、学术综述撰写和质量评估四个智能体协同工作。", "result": "在COLM 2024的六个主题上，处理847篇论文，多智能体方法评分达8.18/10，显著高于AutoSurvey的4.77/10，并在组织和综合质量上表现优越。", "conclusion": "多智能体架构是自动文献综述生成的有意义进展，适用于快速演变的科学领域。"}}
{"id": "2509.18415", "title": "Context Lineage Assurance for Non-Human Identities in Critical Multi-Agent Systems", "authors": ["Sumana Malkapuram", "Sameera Gangavarapu", "Kailashnath Reddy Kavalakuntla", "Ananya Gangavarapu"], "abstract": "The proliferation of autonomous software agents necessitates rigorous frameworks for establishing secure and verifiable agent-to-agent (A2A) interactions, particularly when such agents are instantiated as non-human identities(NHIs). We extend the A2A paradigm [1 , 2] by introducing a cryptographically grounded mechanism for lineage verification, wherein the provenance and evolution of NHIs are anchored in append-only Merkle tree structures modeled after Certificate Transparency (CT) logs. Unlike traditional A2A models that primarily secure point-to-point interactions, our approach enables both agents and external verifiers to cryptographically validate multi-hop provenance, thereby ensuring the integrity of the entire call chain.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.18415.pdf", "abstract_url": "https://arxiv.org/abs/2509.18415", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于密码学的方法，用于在多代理系统中验证非人类身份的血统，确保交互链的完整性。", "motivation": "解决自主软件代理激增带来的安全挑战，特别是在非人类身份之间建立可验证的交互框架。", "method": "扩展A2A范式，引入基于Merkle树和证书透明度日志的密码学血统验证机制。", "result": "该方法使代理和外部验证者能够加密验证多跳来源，增强了整个调用链的完整性。", "conclusion": "结论是该方法为关键多代理系统提供了更安全的血统保证，具有实际应用潜力。"}}
{"id": "2509.18576", "title": "LCMF: Lightweight Cross-Modality Mambaformer for Embodied Robotics VQA", "authors": ["Zeyi Kang", "Liang He", "Yanxin Zhang", "Zuheng Ming", "Kaixing Zhao"], "abstract": "Multimodal semantic learning plays a critical role in embodied intelligence, especially when robots perceive their surroundings, understand human instructions, and make intelligent decisions. However, the field faces technical challenges such as effective fusion of heterogeneous data and computational efficiency in resource-constrained environments. To address these challenges, this study proposes the lightweight LCMF cascaded attention framework, introducing a multi-level cross-modal parameter sharing mechanism into the Mamba module. By integrating the advantages of Cross-Attention and Selective parameter-sharing State Space Models (SSMs), the framework achieves efficient fusion of heterogeneous modalities and semantic complementary alignment. Experimental results show that LCMF surpasses existing multimodal baselines with an accuracy of 74.29% in VQA tasks and achieves competitive mid-tier performance within the distribution cluster of Large Language Model Agents (LLM Agents) in EQA video tasks. Its lightweight design achieves a 4.35-fold reduction in FLOPs relative to the average of comparable baselines while using only 166.51M parameters (image-text) and 219M parameters (video-text), providing an efficient solution for Human-Robot Interaction (HRI) applications in resource-constrained scenarios with strong multimodal decision generalization capabilities.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.18576.pdf", "abstract_url": "https://arxiv.org/abs/2509.18576", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出轻量级LCMF框架，通过多级跨模态参数共享机制，在资源受限环境下实现高效多模态融合，在VQA和EQA任务中表现优异。", "motivation": "解决多模态语义学习中异构数据融合困难和计算效率低的问题，适用于资源受限的具身机器人环境。", "method": "采用级联注意力框架，结合交叉注意力和选择性参数共享状态空间模型，实现轻量级跨模态融合。", "result": "在VQA任务中准确率达74.29%，FLOPs减少4.35倍，参数仅166.51M（图像-文本）和219M（视频-文本）。", "conclusion": "LCMF为资源受限场景下的人机交互提供了高效解决方案，具有强大多模态决策泛化能力。"}}
{"id": "2509.18626", "title": "The Case for Negative Data: From Crash Reports to Counterfactuals for Reasonable Driving", "authors": ["Jay Patrikar", "Apoorva Sharma", "Sushant Veer", "Boyi Li", "Sebastian Scherer", "Marco Pavone"], "abstract": "Learning-based autonomous driving systems are trained mostly on incident-free data, offering little guidance near safety-performance boundaries. Real crash reports contain precisely the contrastive evidence needed, but they are hard to use: narratives are unstructured, third-person, and poorly grounded to sensor views. We address these challenges by normalizing crash narratives to ego-centric language and converting both logs and crashes into a unified scene-action representation suitable for retrieval. At decision time, our system adjudicates proposed actions by retrieving relevant precedents from this unified index; an agentic counterfactual extension proposes plausible alternatives, retrieves for each, and reasons across outcomes before deciding. On a nuScenes benchmark, precedent retrieval substantially improves calibration, with recall on contextually preferred actions rising from 24% to 53%. The counterfactual variant preserves these gains while sharpening decisions near risk.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": "8 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2509.18626.pdf", "abstract_url": "https://arxiv.org/abs/2509.18626", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出一种利用真实碰撞报告改进自动驾驶决策的方法，通过将碰撞叙述归一化为自我中心语言并构建统一场景-动作表示，结合检索和反事实推理，在nuScenes基准上显著提升动作选择和风险决策。", "motivation": "基于学习的自动驾驶系统主要依赖无事故数据训练，缺乏安全边界指导；真实碰撞报告提供对比证据但难以利用，因其非结构化、第三人称且与传感器视图脱节。", "method": "将碰撞叙述归一化为自我中心语言，并将日志和碰撞转换为统一场景-动作表示；决策时检索相关先例，并通过反事实扩展提出替代方案并推理结果。", "result": "在nuScenes基准上，先例检索将上下文偏好动作的召回率从24%提升至53%，改善校准；反事实变体保持增益并增强风险附近决策。", "conclusion": "利用碰撞数据和反事实推理可有效提升自动驾驶系统的安全性和决策质量，为处理边界情况提供新途径。"}}
{"id": "2509.19012", "title": "Pure Vision Language Action (VLA) Models: A Comprehensive Survey", "authors": ["Dapeng Zhang", "Jin Sun", "Chenghui Hu", "Xiaoyan Wu", "Zhenlong Yuan", "Rui Zhou", "Fei Shen", "Qingguo Zhou"], "abstract": "The emergence of Vision Language Action (VLA) models marks a paradigm shift from traditional policy-based control to generalized robotics, reframing Vision Language Models (VLMs) from passive sequence generators into active agents for manipulation and decision-making in complex, dynamic environments. This survey delves into advanced VLA methods, aiming to provide a clear taxonomy and a systematic, comprehensive review of existing research. It presents a comprehensive analysis of VLA applications across different scenarios and classifies VLA approaches into several paradigms: autoregression-based, diffusion-based, reinforcement-based, hybrid, and specialized methods; while examining their motivations, core strategies, and implementations in detail. In addition, foundational datasets, benchmarks, and simulation platforms are introduced. Building on the current VLA landscape, the review further proposes perspectives on key challenges and future directions to advance research in VLA models and generalizable robotics. By synthesizing insights from over three hundred recent studies, this survey maps the contours of this rapidly evolving field and highlights the opportunities and challenges that will shape the development of scalable, general-purpose VLA methods.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.19012.pdf", "abstract_url": "https://arxiv.org/abs/2509.19012", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文对视觉语言动作（VLA）模型进行了全面调查，分类了方法、应用和挑战，并展望了未来方向。", "motivation": "解决从传统策略控制向通用机器人转变的问题，将视觉语言模型转化为主动智能体以应对复杂动态环境。", "method": "采用系统综述方法，分析超过300项研究，分类VLA方法为自回归、扩散、强化、混合和专门方法。", "result": "提供了VLA领域的清晰分类、数据集和基准，识别了关键挑战和机遇。", "conclusion": "VLA模型有望推动可扩展通用方法的发展，但需解决当前挑战以实现通用机器人。"}}
{"id": "2509.19017", "title": "Fully Learnable Neural Reward Machines", "authors": ["Hazem Dewidar", "Elena Umili"], "abstract": "Non-Markovian Reinforcement Learning (RL) tasks present significant challenges, as agents must reason over entire trajectories of state-action pairs to make optimal decisions. A common strategy to address this is through symbolic formalisms, such as Linear Temporal Logic (LTL) or automata, which provide a structured way to express temporally extended objectives. However, these approaches often rely on restrictive assumptions -- such as the availability of a predefined Symbol Grounding (SG) function mapping raw observations to high-level symbolic representations, or prior knowledge of the temporal task. In this work, we propose a fully learnable version of Neural Reward Machines (NRM), which can learn both the SG function and the automaton end-to-end, removing any reliance on prior knowledge. Our approach is therefore as easily applicable as classic deep RL (DRL) approaches, while being far more explainable, because of the finite and compact nature of automata. Furthermore, we show that by integrating Fully Learnable Reward Machines (FLNRM) with DRL, our method outperforms previous approaches based on Recurrent Neural Networks (RNNs).", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.19017.pdf", "abstract_url": "https://arxiv.org/abs/2509.19017", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种完全可学习的神经奖励机（FLNRM），能够端到端学习符号接地函数和自动机，无需先验知识，在非马尔可夫强化学习任务中优于基于RNN的方法，并提高可解释性。", "motivation": "解决非马尔可夫强化学习任务中现有方法依赖预定义符号接地函数或任务先验知识的问题。", "method": "使用完全可学习的神经奖励机，结合深度强化学习，端到端学习符号接地和自动机。", "result": "FLNRM方法在性能上优于基于循环神经网络的方法。", "conclusion": "该方法易于应用，提高了可解释性，并有效处理非马尔可夫任务。"}}
{"id": "2509.19100", "title": "Algorithms for Adversarially Robust Deep Learning", "authors": ["Alexander Robey"], "abstract": "Given the widespread use of deep learning models in safety-critical applications, ensuring that the decisions of such models are robust against adversarial exploitation is of fundamental importance. In this thesis, we discuss recent progress toward designing algorithms that exhibit desirable robustness properties. First, we discuss the problem of adversarial examples in computer vision, for which we introduce new technical results, training paradigms, and certification algorithms. Next, we consider the problem of domain generalization, wherein the task is to train neural networks to generalize from a family of training distributions to unseen test distributions. We present new algorithms that achieve state-of-the-art generalization in medical imaging, molecular identification, and image classification. Finally, we study the setting of jailbreaking large language models (LLMs), wherein an adversarial user attempts to design prompts that elicit objectionable content from an LLM. We propose new attacks and defenses, which represent the frontier of progress toward designing robust language-based agents.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "PhD thesis", "pdf_url": "https://arxiv.org/pdf/2509.19100.pdf", "abstract_url": "https://arxiv.org/abs/2509.19100", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文综述了针对深度学习模型在安全关键应用中对抗性鲁棒性的算法进展，包括对抗性示例、领域泛化和大型语言模型越狱的攻防方法。", "motivation": "解决深度学习模型在安全关键应用中易受对抗性攻击的问题，确保其决策的鲁棒性。", "method": "引入新的技术结果、训练范式、认证算法，以及针对领域泛化和语言模型越狱的新算法。", "result": "在计算机视觉、医学影像、分子识别和图像分类等领域实现了最先进的泛化性能，并提出了前沿的攻防方法。", "conclusion": "论文推动了鲁棒深度学习算法的发展，对安全关键应用具有重要意义。"}}
{"id": "2509.19136", "title": "On the Soundness and Consistency of LLM Agents for Executing Test Cases Written in Natural Language", "authors": ["Sébastien Salva", "Redha Taguelmimt"], "abstract": "The use of natural language (NL) test cases for validating graphical user interface (GUI) applications is emerging as a promising direction to manually written executable test scripts, which are costly to develop and difficult to maintain. Recent advances in large language models (LLMs) have opened the possibility of the direct execution of NL test cases by LLM agents. This paper investigates this direction, focusing on the impact on NL test case unsoundness and on test case execution consistency. NL test cases are inherently unsound, as they may yield false failures due to ambiguous instructions or unpredictable agent behaviour. Furthermore, repeated executions of the same NL test case may lead to inconsistent outcomes, undermining test reliability. To address these challenges, we propose an algorithm for executing NL test cases with guardrail mechanisms and specialised agents that dynamically verify the correct execution of each test step. We introduce measures to evaluate the capabilities of LLMs in test execution and one measure to quantify execution consistency. We propose a definition of weak unsoundness to characterise contexts in which NL test case execution remains acceptable, with respect to the industrial quality levels Six Sigma. Our experimental evaluation with eight publicly available LLMs, ranging from 3B to 70B parameters, demonstrates both the potential and current limitations of current LLM agents for GUI testing. Our experiments show that Meta Llama 3.1 70B demonstrates acceptable capabilities in NL test case execution with high execution consistency (above the level 3-sigma). We provide prototype tools, test suites, and results.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.19136.pdf", "abstract_url": "https://arxiv.org/abs/2509.19136", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究使用大型语言模型（LLM）代理直接执行自然语言（NL）测试用例的可行性和挑战，重点关注NL测试用例的不健全性和执行不一致性。通过提出带有防护机制的算法和专门代理，实验评估显示某些LLM（如Meta Llama 3.1 70B）在GUI测试中具有高一致性，但仍有局限性。", "motivation": "解决手动编写可执行测试脚本成本高、维护难的问题，探索利用LLM代理直接执行NL测试用例的潜力，但NL测试用例存在不健全性和执行不一致性，影响测试可靠性。", "method": "提出一种算法，结合防护机制和专门代理，动态验证每个测试步骤的正确执行；引入评估LLM执行能力的指标和一致性量化方法；定义弱不健全性概念，并基于工业六西格玛标准进行实验，使用八个公开LLM（参数从3B到70B）进行GUI测试评估。", "result": "实验表明，Meta Llama 3.1 70B在NL测试用例执行中表现可接受，执行一致性高于3-sigma水平，但当前LLM代理在GUI测试中仍有局限性。", "conclusion": "LLM代理在NL测试用例执行中具有潜力，但需改进以应对不健全性和不一致性；提供原型工具和测试套件，为未来研究奠定基础。"}}
{"id": "2509.19292", "title": "SOE: Sample-Efficient Robot Policy Self-Improvement via On-Manifold Exploration", "authors": ["Yang Jin", "Jun Lv", "Han Xue", "Wendi Chen", "Chuan Wen", "Cewu Lu"], "abstract": "Intelligent agents progress by continually refining their capabilities through actively exploring environments. Yet robot policies often lack sufficient exploration capability due to action mode collapse. Existing methods that encourage exploration typically rely on random perturbations, which are unsafe and induce unstable, erratic behaviors, thereby limiting their effectiveness. We propose Self-Improvement via On-Manifold Exploration (SOE), a framework that enhances policy exploration and improvement in robotic manipulation. SOE learns a compact latent representation of task-relevant factors and constrains exploration to the manifold of valid actions, ensuring safety, diversity, and effectiveness. It can be seamlessly integrated with arbitrary policy models as a plug-in module, augmenting exploration without degrading the base policy performance. Moreover, the structured latent space enables human-guided exploration, further improving efficiency and controllability. Extensive experiments in both simulation and real-world tasks demonstrate that SOE consistently outperforms prior methods, achieving higher task success rates, smoother and safer exploration, and superior sample efficiency. These results establish on-manifold exploration as a principled approach to sample-efficient policy self-improvement. Project website:", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.19292.pdf", "abstract_url": "https://arxiv.org/abs/2509.19292", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出SOE框架，通过流形上探索提升机器人策略的样本效率，确保安全性和多样性。", "motivation": "解决机器人策略因动作模式崩溃而缺乏有效探索的问题，现有随机扰动方法不安全且不稳定。", "method": "学习任务相关因素的紧凑潜在表示，将探索约束在有效动作流形上，作为插件模块集成任意策略模型。", "result": "在仿真和真实任务中，SOE优于现有方法，实现更高成功率、更平滑探索和更好样本效率。", "conclusion": "流形上探索是样本高效策略自改进的原则性方法，支持人类引导提升可控性。"}}
{"id": "2509.19182", "title": "YAC: Bridging Natural Language and Interactive Visual Exploration with Generative AI for Biomedical Data Discovery", "authors": ["Devin Lange", "Shanghua Gao", "Pengwei Sui", "Austen Money", "Priya Misner", "Marinka Zitnik", "Nils Gehlenborg"], "abstract": "Incorporating natural language input has the potential to improve the capabilities of biomedical data discovery interfaces. However, user interface elements and visualizations are still powerful tools for interacting with data, even in the new world of generative AI. In our prototype system, YAC, Yet Another Chatbot, we bridge the gap between natural language and interactive visualizations by generating structured declarative output with a multi-agent system and interpreting that output to render linked interactive visualizations and apply data filters. Furthermore, we include widgets, which allow users to adjust the values of that structured output through user interface elements. We reflect on the capabilities and design of this system with an analysis of its technical dimensions and illustrate the capabilities through four usage scenarios.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.19182.pdf", "abstract_url": "https://arxiv.org/abs/2509.19182", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "YAC is a prototype system that uses generative AI to bridge natural language input with interactive visualizations for biomedical data discovery, enabling users to explore data through a multi-agent approach and adjustable widgets.", "motivation": "To enhance biomedical data discovery interfaces by integrating natural language input with the power of interactive visualizations, addressing the gap between conversational AI and traditional UI elements.", "method": "Uses a multi-agent system to generate structured declarative output from natural language, which is interpreted to render linked interactive visualizations and apply data filters, including widgets for user adjustments.", "result": "The system's capabilities are demonstrated through four usage scenarios, showing effective integration of natural language and visual exploration, with analysis of technical dimensions.", "conclusion": "YAC successfully bridges natural language and interactive visualizations, offering a promising approach for improving data discovery in biomedicine, with implications for future AI-driven interfaces."}}
