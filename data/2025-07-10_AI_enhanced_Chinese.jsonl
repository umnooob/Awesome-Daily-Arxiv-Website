{"id": "2507.06906", "title": "SemRaFiner: Panoptic Segmentation in Sparse and Noisy Radar Point Clouds", "authors": ["Matthias Zeller", "Daniel Casado Herraez", "Bengisu Ayan", "Jens Behley", "Michael Heidingsfeld", "Cyrill Stachniss"], "abstract": "Semantic scene understanding, including the perception and classification of moving agents, is essential to enabling safe and robust driving behaviours of autonomous vehicles. Cameras and LiDARs are commonly used for semantic scene understanding. However, both sensor modalities face limitations in adverse weather and usually do not provide motion information. Radar sensors overcome these limitations and directly offer information about moving agents by measuring the Doppler velocity, but the measurements are comparably sparse and noisy. In this paper, we address the problem of panoptic segmentation in sparse radar point clouds to enhance scene understanding. Our approach, called SemRaFiner, accounts for changing density in sparse radar point clouds and optimizes the feature extraction to improve accuracy. Furthermore, we propose an optimized training procedure to refine instance assignments by incorporating a dedicated data augmentation. Our experiments suggest that our approach outperforms state-of-the-art methods for radar-based panoptic segmentation.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "Accepted for publication in IEEE Robotics and Automation Letters (RA-L)", "pdf_url": "https://arxiv.org/pdf/2507.06906.pdf", "abstract_url": "https://arxiv.org/abs/2507.06906", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "SemRaFiner是一种用于稀疏和噪声雷达点云的全景分割方法，旨在通过优化特征提取和改进训练过程来提高自动驾驶车辆的语义场景理解能力。", "motivation": "解决在恶劣天气条件下相机和LiDAR传感器受限，以及雷达点云稀疏和噪声大的问题，以提升自动驾驶车辆的场景理解能力。", "method": "提出SemRaFiner方法，考虑雷达点云密度变化优化特征提取，并通过专门的数据增强改进实例分配的训练过程。", "result": "实验表明，SemRaFiner在基于雷达的全景分割任务上优于现有最先进方法。", "conclusion": "SemRaFiner通过优化特征提取和训练过程，有效提升了在稀疏和噪声雷达点云中的全景分割性能，为自动驾驶车辆的语义场景理解提供了新的解决方案。"}}
{"id": "2507.06261", "title": "Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities", "authors": ["Gheorghe Comanici", "Eric Bieber", "Mike Schaekermann", "Ice Pasupat", "Noveen Sachdeva", "Inderjit Dhillon", "Marcel Blistein", "Ori Ram", "Dan Zhang", "Evan Rosen", "Luke Marris", "Sam Petulla", "Colin Gaffney", "Asaf Aharoni", "Nathan Lintz", "Tiago Cardal Pais", "Henrik Jacobsson", "Idan Szpektor", "Nan-Jiang Jiang", "Krishna Haridasan", "Ahmed Omran", "Nikunj Saunshi", "Dara Bahri", "Gaurav Mishra", "Eric Chu", "Toby Boyd", "Brad Hekman", "Aaron Parisi", "Chaoyi Zhang", "Kornraphop Kawintiranon", "Tania Bedrax-Weiss", "Oliver Wang", "Ya Xu", "Ollie Purkiss", "Uri Mendlovic", "Ilaï Deutel", "Nam Nguyen", "Adam Langley", "Flip Korn", "Lucia Rossazza", "Alexandre Ramé", "Sagar Waghmare", "Helen Miller", "Vaishakh Keshava", "Ying Jian", "Xiaofan Zhang", "Raluca Ada Popa", "Kedar Dhamdhere", "Blaž Bratanič", "Kyuyeun Kim", "Terry Koo", "Ferran Alet", "Yi-ting Chen", "Arsha Nagrani", "Hannah Muckenhirn", "Zhiyuan Zhang", "Corbin Quick", "Filip Pavetić", "Duc Dung Nguyen", "Joao Carreira", "Michael Elabd", "Haroon Qureshi", "Fabian Mentzer", "Yao-Yuan Yang", "Danielle Eisenbud", "Anmol Gulati", "Ellie Talius", "Eric Ni", "Sahra Ghalebikesabi", "Edouard Yvinec", "Alaa Saade", "Thatcher Ulrich", "Lorenzo Blanco", "Dan A. Calian", "Muhuan Huang", "Aäron van den Oord", "Naman Goyal", "Terry Chen", "Praynaa Rawlani", "Christian Schallhart", "Swachhand Lokhande", "Xianghong Luo", "Jyn Shan", "Ceslee Montgomery", "Victoria Krakovna", "Federico Piccinini", "Omer Barak", "Jingyu Cui", "Yiling Jia", "Mikhail Dektiarev", "Alexey Kolganov", "Shiyu Huang", "Zhe Chen", "Xingyu Wang", "Jessica Austin", "Peter de Boursac", "Evgeny Sluzhaev", "Frank Ding", "Huijian Li", "Surya Bhupatiraju"], "abstract": "In this report, we introduce the Gemini 2.X model family: Gemini 2.5 Pro and Gemini 2.5 Flash, as well as our earlier Gemini 2.0 Flash and Flash-Lite models. Gemini 2.5 Pro is our most capable model yet, achieving SoTA performance on frontier coding and reasoning benchmarks. In addition to its incredible coding and reasoning skills, Gemini 2.5 Pro is a thinking model that excels at multimodal understanding and it is now able to process up to 3 hours of video content. Its unique combination of long context, multimodal and reasoning capabilities can be combined to unlock new agentic workflows. Gemini 2.5 Flash provides excellent reasoning abilities at a fraction of the compute and latency requirements and Gemini 2.0 Flash and Flash-Lite provide high performance at low latency and cost. Taken together, the Gemini 2.X model generation spans the full Pareto frontier of model capability vs cost, allowing users to explore the boundaries of what is possible with complex agentic problem solving.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "72 pages, 17 figures", "pdf_url": "https://arxiv.org/pdf/2507.06261.pdf", "abstract_url": "https://arxiv.org/abs/2507.06261", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "介绍了Gemini 2.X模型家族，包括Gemini 2.5 Pro和Gemini 2.5 Flash，以及早期的Gemini 2.0 Flash和Flash-Lite模型。Gemini 2.5 Pro在编码和推理基准测试中达到了最先进的性能，具备多模态理解和长上下文处理能力。Gemini 2.5 Flash在计算和延迟要求较低的情况下提供了优秀的推理能力。", "motivation": "解决复杂代理问题解决的边界探索，提供从高性能到低成本的全方位模型选择。", "method": "开发了Gemini 2.X模型家族，包括不同性能与成本平衡的模型版本。", "result": "Gemini 2.5 Pro在多模态理解和长上下文处理方面表现出色，Gemini 2.5 Flash在低计算和延迟下提供优秀推理能力。", "conclusion": "Gemini 2.X模型家族为用户提供了从高性能到低成本的全方位选择，推动了复杂代理问题解决的边界。"}}
{"id": "2507.06531", "title": "ILNet: Trajectory Prediction with Inverse Learning Attention for Enhancing Intention Capture", "authors": ["Mingjin Zeng", "Nan Ouyang", "Wenkang Wan", "Lei Ao", "Qing Cai", "Kai Sheng"], "abstract": "Trajectory prediction for multi-agent interaction scenarios is a crucial challenge. Most advanced methods model agent interactions by efficiently factorized attention based on the temporal and agent axes. However, this static and foward modeling lacks explicit interactive spatio-temporal coordination, capturing only obvious and immediate behavioral intentions. Alternatively, the modern trajectory prediction framework refines the successive predictions by a fixed-anchor selection strategy, which is difficult to adapt in different future environments. It is acknowledged that human drivers dynamically adjust initial driving decisions based on further assumptions about the intentions of surrounding vehicles. Motivated by human driving behaviors, this paper proposes ILNet, a multi-agent trajectory prediction method with Inverse Learning (IL) attention and Dynamic Anchor Selection (DAS) module. IL Attention employs an inverse learning paradigm to model interactions at neighboring moments, introducing proposed intentions to dynamically encode the spatio-temporal coordination of interactions, thereby enhancing the model's ability to capture complex interaction patterns. Then, the learnable DAS module is proposed to extract multiple trajectory change keypoints as anchors in parallel with almost no increase in parameters. Experimental results show that the ILNet achieves state-of-the-art performance on the INTERACTION and Argoverse motion forecasting datasets. Particularly, in challenged interaction scenarios, ILNet achieves higher accuracy and more multimodal distributions of trajectories over fewer parameters. Our codes are available at", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.06531.pdf", "abstract_url": "https://arxiv.org/abs/2507.06531", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "ILNet提出了一种多智能体轨迹预测方法，通过逆向学习注意力和动态锚点选择模块，增强了模型对复杂交互模式的捕捉能力，并在多个数据集上实现了最先进的性能。", "motivation": "解决多智能体交互场景中轨迹预测的挑战，特别是静态和前向建模缺乏明确的交互时空协调，以及固定锚点选择策略难以适应不同未来环境的问题。", "method": "提出了逆向学习（IL）注意力和动态锚点选择（DAS）模块。IL注意力通过逆向学习范式建模邻近时刻的交互，动态编码交互的时空协调；DAS模块可学习地提取多个轨迹变化关键点作为锚点。", "result": "在INTERACTION和Argoverse运动预测数据集上，ILNet实现了最先进的性能，特别是在具有挑战性的交互场景中，以更少的参数实现了更高的准确性和更多模态的轨迹分布。", "conclusion": "ILNet通过逆向学习注意力和动态锚点选择模块，有效提升了多智能体轨迹预测的准确性和适应性，为复杂交互场景下的轨迹预测提供了新的解决方案。"}}
{"id": "2507.06506", "title": "Pun Intended: Multi-Agent Translation of Wordplay with Contrastive Learning and Phonetic-Semantic Embeddings", "authors": ["Russell Taylor", "Benjamin Herbert", "Michael Sana"], "abstract": "Translating wordplay across languages presents unique challenges that have long confounded both professional human translators and machine translation systems. This research proposes a novel approach for translating puns from English to French by combining state-of-the-art large language models with specialized techniques for wordplay generation.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multiagent Systems (cs.MA)", "comments": "CLEF 2025 Working Notes, 9-12 September 2025, Madrid, Spain", "pdf_url": "https://arxiv.org/pdf/2507.06506.pdf", "abstract_url": "https://arxiv.org/abs/2507.06506", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种结合最先进的大型语言模型和专门的双关语生成技术的新方法，用于将英语双关语翻译成法语。", "motivation": "解决跨语言双关语翻译这一长期困扰专业人类翻译和机器翻译系统的独特挑战。", "method": "使用对比学习和语音语义嵌入的多智能体翻译方法。", "result": "提出了一种能够有效翻译双关语的新方法。", "conclusion": "该方法为双关语的跨语言翻译提供了新的可能性，对机器翻译领域具有重要意义。"}}
{"id": "2507.06798", "title": "Comparing Dialectical Systems: Contradiction and Counterexample in Belief Change (Extended Version)", "authors": ["Uri Andrews", "Luca San Mauro"], "abstract": "Dialectical systems are a mathematical formalism for modeling an agent updating a knowledge base seeking consistency. Introduced in the 1970s by Roberto Magari, they were originally conceived to capture how a working mathematician or a research community refines beliefs in the pursuit of truth. Dialectical systems also serve as natural models for the belief change of an automated agent, offering a unifying, computable framework for dynamic belief management.", "subjects": "Artificial Intelligence (cs.AI); Logic (math.LO)", "comments": "25 pages, accepted at JELIA 2025", "pdf_url": "https://arxiv.org/pdf/2507.06798.pdf", "abstract_url": "https://arxiv.org/abs/2507.06798", "categories": ["Artificial Intelligence (cs.AI)", "Logic (math.LO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文比较了辩证系统，探讨了在信念变化中的矛盾和反例。辩证系统是一种数学形式主义，用于建模代理更新知识库以寻求一致性的过程。", "motivation": "解决如何在追求真理的过程中，数学家或研究社区如何精炼信念的问题，以及为自动化代理的信念变化提供统一的、可计算的框架。", "method": "使用辩证系统作为数学模型，分析信念变化中的矛盾和反例。", "result": "辩证系统为动态信念管理提供了一个统一且可计算的框架。", "conclusion": "辩证系统不仅适用于数学家或研究社区的信念精炼，也适用于自动化代理的信念变化管理，提供了一个有效的数学模型。"}}
{"id": "2507.06396", "title": "Representing Prompting Patterns with PDL: Compliance Agent Case Study", "authors": ["Mandana Vaziri", "Louis Mandel", "Yuji Watanabe", "Hirokuni Kitahara", "Martin Hirzel", "Anca Sailer"], "abstract": "Prompt engineering for LLMs remains complex, with existing frameworks either hiding complexity behind restrictive APIs or providing inflexible canned patterns that resist customization -- making sophisticated agentic programming challenging. We present the Prompt Declaration Language (PDL), a novel approach to prompt representation that tackles this fundamental complexity by bringing prompts to the forefront, enabling manual and automatic prompt tuning while capturing the composition of LLM calls together with rule-based code and external tools. By abstracting away the plumbing for such compositions, PDL aims at improving programmer productivity while providing a declarative representation that is amenable to optimization. This paper demonstrates PDL's utility through a real-world case study of a compliance agent. Tuning the prompting pattern of this agent yielded up to 4x performance improvement compared to using a canned agent and prompt pattern.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Programming Languages (cs.PL); Software Engineering (cs.SE)", "comments": "ICML 2025 Workshop on Programmatic Representations for Agent Learning", "pdf_url": "https://arxiv.org/pdf/2507.06396.pdf", "abstract_url": "https://arxiv.org/abs/2507.06396", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Programming Languages (cs.PL)", "Software Engineering (cs.SE)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了提示声明语言（PDL），一种新颖的提示表示方法，旨在通过将提示置于前沿来解决LLM提示工程的复杂性，支持手动和自动提示调整，同时捕获LLM调用与基于规则的代码和外部工具的组合。通过抽象化这些组合的管道，PDL旨在提高程序员的生产力，同时提供可优化的声明性表示。通过合规代理的真实案例研究展示了PDL的实用性，调整该代理的提示模式相比使用固定代理和提示模式实现了高达4倍的性能提升。", "motivation": "解决LLM提示工程中的复杂性，现有框架要么通过限制性API隐藏复杂性，要么提供难以自定义的固定模式，使得复杂的代理编程变得困难。", "method": "提出提示声明语言（PDL），一种新颖的提示表示方法，支持手动和自动提示调整，捕获LLM调用与基于规则的代码和外部工具的组合。", "result": "通过合规代理的案例研究，调整提示模式实现了高达4倍的性能提升。", "conclusion": "PDL通过抽象化组合的管道提高了程序员的生产力，并提供了可优化的声明性表示，展示了在实际应用中的显著性能改进。"}}
{"id": "2507.06993", "title": "The User-Centric Geo-Experience: An LLM-Powered Framework for Enhanced Planning, Navigation, and Dynamic Adaptation", "authors": ["Jieren Deng", "Aleksandar Cvetkovic", "Pak Kiu Chung", "Dragomir Yankov", "Chiqun Zhang"], "abstract": "Traditional travel-planning systems are often static and fragmented, leaving them ill-equipped to handle real-world complexities such as evolving environmental conditions and unexpected itinerary disruptions. In this paper, we identify three gaps between existing service providers causing frustrating user experience: intelligent trip planning, precision \"last-100-meter\" navigation, and dynamic itinerary adaptation. We propose three cooperative agents: a Travel Planning Agent that employs grid-based spatial grounding and map analysis to help resolve complex multi-modal user queries; a Destination Assistant Agent that provides fine-grained guidance for the final navigation leg of each journey; and a Local Discovery Agent that leverages image embeddings and Retrieval-Augmented Generation (RAG) to detect and respond to trip plan disruptions. With evaluations and experiments, our system demonstrates substantial improvements in query interpretation, navigation accuracy, and disruption resilience, underscoring its promise for applications from urban exploration to emergency response.", "subjects": "Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.06993.pdf", "abstract_url": "https://arxiv.org/abs/2507.06993", "categories": ["Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文提出了一种以用户为中心的地理体验框架，通过三个协作代理解决传统旅行规划系统的静态和碎片化问题，显著提升了查询解释、导航准确性和应对中断的能力。", "motivation": "传统旅行规划系统因静态和碎片化，难以应对现实世界中的复杂情况，如环境变化和意外行程中断，导致用户体验不佳。", "method": "提出了三个协作代理：旅行规划代理使用基于网格的空间 grounding 和地图分析处理多模态用户查询；目的地助手代理提供精细化的最终导航指导；本地发现代理利用图像嵌入和检索增强生成（RAG）技术检测并响应行程中断。", "result": "通过评估和实验，该系统在查询解释、导航准确性和应对中断的韧性方面显示出显著改进。", "conclusion": "该框架展示了从城市探索到应急响应等多种应用的潜力，为提升地理体验提供了有效解决方案。"}}
{"id": "2507.06528", "title": "InvestAlign: Overcoming Data Scarcity in Aligning Large Language Models with Investor Decision-Making Processes under Herd Behavior", "authors": ["Huisheng Wang", "Zhuoshi Pan", "Hangjing Zhang", "Mingxiao Liu", "Hanqing Gao", "H. Vicky Zhao"], "abstract": "Aligning Large Language Models (LLMs) with investor decision-making processes under herd behavior is a critical challenge in behavioral finance, which grapples with a fundamental limitation: the scarcity of real-user data needed for Supervised Fine-Tuning (SFT). While SFT can bridge the gap between LLM outputs and human behavioral patterns, its reliance on massive authentic data imposes substantial collection costs and privacy risks. We propose InvestAlign, a novel framework that constructs high-quality SFT datasets by leveraging theoretical solutions to similar and simple optimal investment problems rather than complex scenarios. Our theoretical analysis demonstrates that training LLMs with InvestAlign-generated data achieves faster parameter convergence than using real-user data, suggesting superior learning efficiency. Furthermore, we develop InvestAgent, an LLM agent fine-tuned with InvestAlign, which demonstrates significantly closer alignment to real-user data than pre-SFT models in both simple and complex investment problems. This highlights our proposed InvestAlign as a promising approach with the potential to address complex optimal investment problems and align LLMs with investor decision-making processes under herd behavior. Our code is publicly available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.06528.pdf", "abstract_url": "https://arxiv.org/abs/2507.06528", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Emerging Technologies (cs.ET)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了InvestAlign框架，通过利用理论解决方案构建高质量的有监督微调数据集，以解决在羊群行为下对齐大型语言模型与投资者决策过程中的数据稀缺问题。", "motivation": "在行为金融学中，对齐大型语言模型与投资者在羊群行为下的决策过程面临一个基本限制：用于有监督微调的真实用户数据稀缺。这不仅带来了高昂的数据收集成本，还增加了隐私风险。", "method": "提出了InvestAlign框架，该框架通过利用类似和简单的最优投资问题的理论解决方案，而非复杂场景，来构建高质量的有监督微调数据集。", "result": "理论分析表明，使用InvestAlign生成的数据训练大型语言模型比使用真实用户数据实现了更快的参数收敛，表明学习效率更高。此外，使用InvestAlign微调的LLM代理InvestAgent在简单和复杂投资问题上都显示出与真实用户数据更接近的对齐。", "conclusion": "InvestAlign作为一种有前景的方法，有望解决复杂的最优投资问题，并在羊群行为下对齐大型语言模型与投资者决策过程。"}}
{"id": "2507.06235", "title": "Super Kawaii Vocalics: Amplifying the \"Cute\" Factor in Computer Voice", "authors": ["Yuto Mandai", "Katie Seaborn", "Tomoyasu Nakano", "Xin Sun", "Yijia Wang", "Jun Kato"], "abstract": "\"Kawaii\" is the Japanese concept of cute, which carries sociocultural connotations related to social identities and emotional responses. Yet, virtually all work to date has focused on the visual side of kawaii, including in studies of computer agents and social robots. In pursuit of formalizing the new science of kawaii vocalics, we explored what elements of voice relate to kawaii and how they might be manipulated, manually and automatically. We conducted a four-phase study (grand N = 512) with two varieties of computer voices: text-to-speech (TTS) and game character voices. We found kawaii \"sweet spots\" through manipulation of fundamental and formant frequencies, but only for certain voices and to a certain extent. Findings also suggest a ceiling effect for the kawaii vocalics of certain voices. We offer empirical validation of the preliminary kawaii vocalics model and an elementary method for manipulating kawaii perceptions of computer voice.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computers and Society (cs.CY); Sound (cs.SD); Audio and Speech Processing (eess.AS)", "comments": "CHI '25", "pdf_url": "https://arxiv.org/pdf/2507.06235.pdf", "abstract_url": "https://arxiv.org/abs/2507.06235", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Computers and Society (cs.CY)", "Sound (cs.SD)", "Audio and Speech Processing (eess.AS)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了如何通过调整基础频率和共振峰频率来增强计算机语音的“可爱”因素，即“卡哇伊”声学，并通过四阶段研究验证了初步的卡哇伊声学模型。", "motivation": "尽管“卡哇伊”作为日本文化中的可爱概念在社会身份和情感反应方面具有重要意义，但以往的研究主要集中在视觉方面，对声音方面的研究不足。本文旨在填补这一空白，探索声音元素与卡哇伊之间的关系及其操纵方法。", "method": "研究采用四阶段研究方法（总样本量N = 512），针对两种计算机语音（文本到语音和游戏角色语音）进行操作，通过调整基础频率和共振峰频率来寻找卡哇伊的“甜点”。", "result": "研究发现，通过调整基础频率和共振峰频率可以在一定程度上增强某些语音的卡哇伊感，但也存在天花板效应。研究为卡哇伊声学模型提供了实证支持，并提出了一种基本方法来操纵计算机语音的卡哇伊感知。", "conclusion": "本研究不仅验证了卡哇伊声学的初步模型，还为未来在计算机语音中实现更广泛的卡哇伊效果提供了基础。这对于增强人机交互中的情感连接具有重要意义。"}}
{"id": "2507.06565", "title": "The Flaws of Others: An LLM-driven Framework for Scientific Knowledge Production", "authors": ["Juan B. Gutiérrez"], "abstract": "Large-language models turn writing into a live exchange between humans and software. We capture this new medium with a discursive-network model that treats people and LLMs as equal nodes and tracks how their statements circulate. Broadening the focus from isolated hallucinations, we define invalidation (any factual, logical, or structural breach) and show it follows four hazards: drift from truth, self-repair, fresh fabrication, and external detection. A general mathematical model of discursive networks is developed to provide valuable insights: A network governed only by drift and self-repair stabilizes at a modest error rate; adding fabrication reproduces the high rates seen in current LLMs. Giving each false claim even a small chance of peer review shifts the system to a truth-dominant state. We operationalize peer review with the open-source \\emph{Flaws-of-Others (FOO) algorithm}: a configurable loop in which any set of agents critique one another while a harmoniser merges their verdicts. The takeaway is practical and cultural: reliability in this new medium comes not from perfecting single models but from wiring imperfect ones into networks that keep each other honest.", "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": "27 pages, 3 figures, 4 tables, 1 algorithm, 28 references", "pdf_url": "https://arxiv.org/pdf/2507.06565.pdf", "abstract_url": "https://arxiv.org/abs/2507.06565", "categories": ["Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于大型语言模型（LLM）的科学知识生产框架，通过将人类和LLM视为平等节点，并追踪其陈述的流通，来探索这一新媒介。文章定义了无效性（包括事实、逻辑或结构上的违规）并展示了四种危害：偏离真相、自我修复、新制造和外部检测。通过开发一个通用的论述网络数学模型，文章提供了有价值的见解。最后，提出了开源的“他人之瑕（FOO）算法”来实现同行评审，强调在新媒介中可靠性来自于将不完美的模型连接成网络，而非单一模型的完美。", "motivation": "探索大型语言模型（LLM）作为科学知识生产新媒介的潜力，解决LLM在生成内容时可能出现的事实、逻辑或结构上的无效性问题。", "method": "提出了一种论述网络模型，将人类和LLM视为平等节点，并开发了一个通用的数学模型来分析网络中的无效性传播。此外，提出了FOO算法来实现同行评审。", "result": "研究发现，仅由偏离真相和自我修复驱动的网络会在适度错误率下稳定；加入新制造会重现当前LLM中的高错误率。给予每个错误声明即使是小的同行评审机会，也能使系统转向真相主导的状态。", "conclusion": "在新媒介中，可靠性来自于将不完美的模型连接成网络，而非单一模型的完美。FOO算法提供了一种实用的方法来实现这一点，强调了文化和实践上的转变。"}}
{"id": "2507.06715", "title": "CLI-RAG: A Retrieval-Augmented Framework for Clinically Structured and Context Aware Text Generation with LLMs", "authors": ["Garapati Keerthana", "Manik Gupta"], "abstract": "Large language models (LLMs), including zero-shot and few-shot paradigms, have shown promising capabilities in clinical text generation. However, real-world applications face two key challenges: (1) patient data is highly unstructured, heterogeneous, and scattered across multiple note types and (2) clinical notes are often long and semantically dense, making naive prompting infeasible due to context length constraints and the risk of omitting clinically relevant information.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": "12 pages, 4 figures", "pdf_url": "https://arxiv.org/pdf/2507.06715.pdf", "abstract_url": "https://arxiv.org/abs/2507.06715", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "CLI-RAG是一个基于检索增强的框架，旨在解决临床文本生成中的结构化和上下文感知问题，利用大型语言模型（LLMs）在零样本和少样本范式下的潜力。", "motivation": "解决临床文本生成中患者数据非结构化、异构且分散，以及临床笔记长且语义密集导致的上下文长度限制和遗漏临床相关信息的问题。", "method": "采用检索增强框架（CLI-RAG），结合大型语言模型（LLMs）的零样本和少样本学习能力，以提高临床文本的结构化和上下文感知。", "result": "CLI-RAG框架能够有效处理临床文本的复杂性和长度，生成结构化和上下文相关的临床笔记。", "conclusion": "CLI-RAG为临床文本生成提供了一种有效的解决方案，通过结合检索增强和大型语言模型，克服了现有方法在处理非结构化和长文本时的限制。"}}
{"id": "2507.07105", "title": "4KAgent: Agentic Any Image to 4K Super-Resolution", "authors": ["Yushen Zuo", "Qi Zheng", "Mingyang Wu", "Xinrui Jiang", "Renjie Li", "Jian Wang", "Yide Zhang", "Gengchen Mai", "Lihong V. Wang", "James Zou", "Xiaoyu Wang", "Ming-Hsuan Yang", "Zhengzhong Tu"], "abstract": "We present 4KAgent, a unified agentic super-resolution generalist system designed to universally upscale any image to 4K resolution (and even higher, if applied iteratively). Our system can transform images from extremely low resolutions with severe degradations, for example, highly distorted inputs at 256x256, into crystal-clear, photorealistic 4K outputs. 4KAgent comprises three core components: (1) Profiling, a module that customizes the 4KAgent pipeline based on bespoke use cases; (2) A Perception Agent, which leverages vision-language models alongside image quality assessment experts to analyze the input image and make a tailored restoration plan; and (3) A Restoration Agent, which executes the plan, following a recursive execution-reflection paradigm, guided by a quality-driven mixture-of-expert policy to select the optimal output for each step. Additionally, 4KAgent embeds a specialized face restoration pipeline, significantly enhancing facial details in portrait and selfie photos. We rigorously evaluate our 4KAgent across 11 distinct task categories encompassing a total of 26 diverse benchmarks, setting new state-of-the-art on a broad spectrum of imaging domains. Our evaluations cover natural images, portrait photos, AI-generated content, satellite imagery, fluorescence microscopy, and medical imaging like fundoscopy, ultrasound, and X-ray, demonstrating superior performance in terms of both perceptual (e.g., NIQE, MUSIQ) and fidelity (e.g., PSNR) metrics. By establishing a novel agentic paradigm for low-level vision tasks, we aim to catalyze broader interest and innovation within vision-centric autonomous agents across diverse research communities. We will release all the code, models, and results at:", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2507.07105.pdf", "abstract_url": "https://arxiv.org/abs/2507.07105", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Image and Video Processing (eess.IV)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "4KAgent是一个统一的代理超分辨率通用系统，旨在将任何图像普遍升级到4K分辨率（甚至更高，如果迭代应用）。该系统能够将极低分辨率且严重退化的图像（例如高度失真的256x256输入）转换为清晰、逼真的4K输出。", "motivation": "解决将低分辨率、严重退化的图像高质量升级到4K分辨率的问题，特别是在多样化的成像领域中。", "method": "4KAgent包含三个核心组件：(1) Profiling模块，根据特定用例定制4KAgent流程；(2) Perception Agent，利用视觉语言模型和图像质量评估专家分析输入图像并制定定制化恢复计划；(3) Restoration Agent，执行计划，遵循递归执行-反思范式，通过质量驱动的专家混合策略选择每一步的最佳输出。", "result": "在11个不同的任务类别中，涵盖26个多样化的基准测试，4KAgent在广泛的成像领域中设置了新的最先进水平，包括自然图像、肖像照片、AI生成内容、卫星图像、荧光显微镜以及医学成像（如眼底摄影、超声和X射线），在感知（如NIQE、MUSIQ）和保真度（如PSNR）指标上均表现出卓越性能。", "conclusion": "通过为低级视觉任务建立一个新的代理范式，4KAgent旨在激发更广泛的兴趣和创新，特别是在以视觉为中心的自主动机代理领域。所有代码、模型和结果将被公开发布。"}}
{"id": "2507.06838", "title": "Shifting from Ranking to Set Selection for Retrieval Augmented Generation", "authors": ["Dahyun Lee", "Yongrae Jo", "Haeju Park", "Moontae Lee"], "abstract": "Retrieval in Retrieval-Augmented Generation(RAG) must ensure that retrieved passages are not only individually relevant but also collectively form a comprehensive set. Existing approaches primarily rerank top-k passages based on their individual relevance, often failing to meet the information needs of complex queries in multi-hop question answering. In this work, we propose a set-wise passage selection approach and introduce SETR, which explicitly identifies the information requirements of a query through Chain-of-Thought reasoning and selects an optimal set of passages that collectively satisfy those requirements. Experiments on multi-hop RAG benchmarks show that SETR outperforms both proprietary LLM-based rerankers and open-source baselines in terms of answer correctness and retrieval quality, providing an effective and efficient alternative to traditional rerankers in RAG systems. The code is available at", "subjects": "Computation and Language (cs.CL); Information Retrieval (cs.IR)", "comments": "Accepted to ACL 2025 Oral", "pdf_url": "https://arxiv.org/pdf/2507.06838.pdf", "abstract_url": "https://arxiv.org/abs/2507.06838", "categories": ["Computation and Language (cs.CL)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种从排名转向集合选择的检索增强生成(RAG)方法，通过SETR显式识别查询的信息需求并选择最优的段落集合，以集体满足这些需求。", "motivation": "解决现有RAG方法在处理复杂查询时，仅基于段落个体相关性重新排名，而无法满足多跳问题回答中的信息需求的问题。", "method": "提出了一种集合方式的段落选择方法SETR，通过Chain-of-Thought推理显式识别查询的信息需求，并选择最优的段落集合。", "result": "在多跳RAG基准测试中，SETR在答案正确性和检索质量上均优于基于专有LLM的重新排名器和开源基线。", "conclusion": "SETR为RAG系统提供了一种有效且高效的替代传统重新排名器的方法，显著提高了处理复杂查询的能力。"}}
{"id": "2507.06899", "title": "VisualTrap: A Stealthy Backdoor Attack on GUI Agents via Visual Grounding Manipulation", "authors": ["Ziang Ye", "Yang Zhang", "Wentao Shi", "Xiaoyu You", "Fuli Feng", "Tat-Seng Chua"], "abstract": "Graphical User Interface (GUI) agents powered by Large Vision-Language Models (LVLMs) have emerged as a revolutionary approach to automating human-machine interactions, capable of autonomously operating personal devices (e.g., mobile phones) or applications within the device to perform complex real-world tasks in a human-like manner. However, their close integration with personal devices raises significant security concerns, with many threats, including backdoor attacks, remaining largely unexplored. This work reveals that the visual grounding of GUI agent-mapping textual plans to GUI elements-can introduce vulnerabilities, enabling new types of backdoor attacks. With backdoor attack targeting visual grounding, the agent's behavior can be compromised even when given correct task-solving plans. To validate this vulnerability, we propose VisualTrap, a method that can hijack the grounding by misleading the agent to locate textual plans to trigger locations instead of the intended targets. VisualTrap uses the common method of injecting poisoned data for attacks, and does so during the pre-training of visual grounding to ensure practical feasibility of attacking. Empirical results show that VisualTrap can effectively hijack visual grounding with as little as 5% poisoned data and highly stealthy visual triggers (invisible to the human eye); and the attack can be generalized to downstream tasks, even after clean fine-tuning. Moreover, the injected trigger can remain effective across different GUI environments, e.g., being trained on mobile/web and generalizing to desktop environments. These findings underscore the urgent need for further research on backdoor attack risks in GUI agents.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.06899.pdf", "abstract_url": "https://arxiv.org/abs/2507.06899", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文揭示了大型视觉语言模型（LVLMs）驱动的图形用户界面（GUI）代理在视觉接地（visual grounding）过程中可能引入的安全漏洞，特别是后门攻击的风险。作者提出了VisualTrap方法，通过在预训练阶段注入有毒数据，误导代理将文本计划映射到错误的GUI元素，从而实现对代理行为的操控。实验结果表明，仅需5%的有毒数据即可有效实施攻击，且攻击具有高度的隐蔽性和跨环境泛化能力。", "motivation": "随着大型视觉语言模型（LVLMs）驱动的GUI代理在自动化人机交互中的应用日益广泛，其与个人设备的紧密集成引发了严重的安全担忧。特别是后门攻击等威胁尚未得到充分探索。本研究旨在揭示视觉接地过程中可能引入的漏洞，并提出相应的攻击方法。", "method": "作者提出了VisualTrap方法，通过在视觉接地的预训练阶段注入有毒数据，误导代理将文本计划映射到错误的GUI元素。这种方法利用常见的毒化数据注入技术，确保了攻击的实际可行性。", "result": "实验结果显示，VisualTrap能够有效操控视觉接地过程，仅需5%的有毒数据即可实现攻击。攻击具有高度的隐蔽性（人眼不可见的视觉触发器），并且能够泛化到下游任务，甚至在经过干净的微调后仍然有效。此外，注入的触发器能够在不同的GUI环境中保持有效性。", "conclusion": "这些发现强调了在GUI代理中进一步研究后门攻击风险的紧迫性。VisualTrap的成功实施表明，当前GUI代理在视觉接地过程中存在严重的安全漏洞，需要采取有效措施加以防范。"}}
{"id": "2507.06908", "title": "MIND: A Multi-agent Framework for Zero-shot Harmful Meme Detection", "authors": ["Ziyan Liu", "Chunxiao Fan", "Haoran Lou", "Yuexin Wu", "Kaiwei Deng"], "abstract": "The rapid expansion of memes on social media has highlighted the urgent need for effective approaches to detect harmful content. However, traditional data-driven approaches struggle to detect new memes due to their evolving nature and the lack of up-to-date annotated data. To address this issue, we propose MIND, a multi-agent framework for zero-shot harmful meme detection that does not rely on annotated data. MIND implements three key strategies: 1) We retrieve similar memes from an unannotated reference set to provide contextual information. 2) We propose a bi-directional insight derivation mechanism to extract a comprehensive understanding of similar memes. 3) We then employ a multi-agent debate mechanism to ensure robust decision-making through reasoned arbitration. Extensive experiments on three meme datasets demonstrate that our proposed framework not only outperforms existing zero-shot approaches but also shows strong generalization across different model architectures and parameter scales, providing a scalable solution for harmful meme detection. The code is available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "ACL 2025", "pdf_url": "https://arxiv.org/pdf/2507.06908.pdf", "abstract_url": "https://arxiv.org/abs/2507.06908", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为MIND的多智能体框架，用于零样本有害模因检测，该框架不依赖注释数据，通过检索相似模因、双向洞察推导机制和多智能体辩论机制，有效检测新模因。", "motivation": "社交媒体上模因的迅速扩展凸显了检测有害内容的迫切需要，但传统的数据驱动方法由于模因的不断演变和缺乏最新注释数据而难以检测新模因。", "method": "MIND框架实施三种关键策略：1)从未注释的参考集中检索相似模因以提供上下文信息；2)提出双向洞察推导机制以全面理解相似模因；3)采用多智能体辩论机制通过理性仲裁确保稳健决策。", "result": "在三个模因数据集上的广泛实验表明，MIND不仅优于现有的零样本方法，而且在不同模型架构和参数规模上显示出强大的泛化能力。", "conclusion": "MIND为有害模因检测提供了一个可扩展的解决方案，其代码已公开。"}}
{"id": "2507.06910", "title": "Exploring LLMs for Predicting Tutor Strategy and Student Outcomes in Dialogues", "authors": ["Fareya Ikram", "Alexander Scarlatos", "Andrew Lan"], "abstract": "Tutoring dialogues have gained significant attention in recent years, given the prominence of online learning and the emerging tutoring abilities of artificial intelligence (AI) agents powered by large language models (LLMs). Recent studies have shown that the strategies used by tutors can have significant effects on student outcomes, necessitating methods to predict how tutors will behave and how their actions impact students. However, few works have studied predicting tutor strategy in dialogues. Therefore, in this work we investigate the ability of modern LLMs, particularly Llama 3 and GPT-4o, to predict both future tutor moves and student outcomes in dialogues, using two math tutoring dialogue datasets. We find that even state-of-the-art LLMs struggle to predict future tutor strategy while tutor strategy is highly indicative of student outcomes, outlining a need for more powerful methods to approach this task.", "subjects": "Computation and Language (cs.CL); Computers and Society (cs.CY)", "comments": "Published in BEA 2025: 20th Workshop on Innovative Use of NLP for Building Educational Applications", "pdf_url": "https://arxiv.org/pdf/2507.06910.pdf", "abstract_url": "https://arxiv.org/abs/2507.06910", "categories": ["Computation and Language (cs.CL)", "Computers and Society (cs.CY)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了大型语言模型（LLMs）在预测辅导对话中的辅导策略和学生成果方面的能力，特别是在数学辅导对话数据集上的应用。研究发现，即使是先进的LLMs如Llama 3和GPT-4o，在预测未来辅导策略方面也存在困难，而辅导策略对学生成果有显著影响。", "motivation": "随着在线学习的普及和由大型语言模型（LLMs）驱动的人工智能（AI）代理辅导能力的出现，辅导对话受到了广泛关注。辅导策略对学生成果有重要影响，因此需要方法来预测辅导行为及其对学生的影响。然而，预测辅导对话中的辅导策略的研究较少。", "method": "本研究使用Llama 3和GPT-4o这两种现代大型语言模型（LLMs），在两个数学辅导对话数据集上预测未来的辅导动作和学生成果。", "result": "研究发现，即使是目前最先进的大型语言模型（LLMs）在预测未来辅导策略方面也存在困难，而辅导策略对学生成果有显著影响。", "conclusion": "研究结果表明，需要更强大的方法来处理预测辅导策略和学生成果的任务，这对于提高在线学习和AI辅导的效果具有重要意义。"}}
{"id": "2507.06956", "title": "Investigating the Robustness of Retrieval-Augmented Generation at the Query Level", "authors": ["Sezen Perçin", "Xin Su", "Qutub Sha Syed", "Phillip Howard", "Aleksei Kuvshinov", "Leo Schwinn", "Kay-Ulrich Scholl"], "abstract": "Large language models (LLMs) are very costly and inefficient to update with new information. To address this limitation, retrieval-augmented generation (RAG) has been proposed as a solution that dynamically incorporates external knowledge during inference, improving factual consistency and reducing hallucinations. Despite its promise, RAG systems face practical challenges-most notably, a strong dependence on the quality of the input query for accurate retrieval. In this paper, we investigate the sensitivity of different components in the RAG pipeline to various types of query perturbations. Our analysis reveals that the performance of commonly used retrievers can degrade significantly even under minor query variations. We study each module in isolation as well as their combined effect in an end-to-end question answering setting, using both general-domain and domain-specific datasets. Additionally, we propose an evaluation framework to systematically assess the query-level robustness of RAG pipelines and offer actionable recommendations for practitioners based on the results of more than 1092 experiments we performed.", "subjects": "Computation and Language (cs.CL)", "comments": "Accepted to Generation, Evaluation & Metrics (GEM) Workshop at ACL 2025", "pdf_url": "https://arxiv.org/pdf/2507.06956.pdf", "abstract_url": "https://arxiv.org/abs/2507.06956", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文研究了检索增强生成（RAG）在查询级别上的鲁棒性，发现即使查询有微小变化，常用检索器的性能也会显著下降，并提出了一个评估框架来系统评估RAG管道的查询级别鲁棒性。", "motivation": "大型语言模型（LLMs）更新新信息的成本高且效率低，检索增强生成（RAG）被提出作为解决方案，但RAG系统对输入查询质量的依赖性很强，这限制了其实际应用。", "method": "研究分析了RAG管道中不同组件对各种查询扰动的敏感性，并在端到端问答设置中研究了每个模块的孤立效应及其组合效应，使用了通用领域和特定领域的数据集。", "result": "研究发现，即使查询有微小变化，常用检索器的性能也会显著下降。通过超过1092次实验，提出了基于结果的实用建议。", "conclusion": "本文提出了一个评估框架来系统评估RAG管道的查询级别鲁棒性，并为从业者提供了基于实验结果的实用建议。"}}
{"id": "2507.06278", "title": "A Survey of Multi Agent Reinforcement Learning: Federated Learning and Cooperative and Noncooperative Decentralized Regimes", "authors": ["Kemboi Cheruiyot", "Nickson Kiprotich", "Vyacheslav Kungurtsev", "Kennedy Mugo", "Vivian Mwirigi", "Marvin Ngesa"], "abstract": "The increasing interest in research and innovation towards the development of autonomous agents presents a number of complex yet important scenarios of multiple AI Agents interacting with each other in an environment. The particular setting can be understood as exhibiting three possibly topologies of interaction - centrally coordinated cooperation, ad-hoc interaction and cooperation, and settings with noncooperative incentive structures. This article presents a comprehensive survey of all three domains, defined under the formalism of Federal Reinforcement Learning (RL), Decentralized RL, and Noncooperative RL, respectively. Highlighting the structural similarities and distinctions, we review the state of the art in these subjects, primarily explored and developed only recently in the literature. We include the formulations as well as known theoretical guarantees and highlights and limitations of numerical performance.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.06278.pdf", "abstract_url": "https://arxiv.org/abs/2507.06278", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文综述了多智能体强化学习的三个主要领域：联邦学习、合作与非合作的去中心化制度，探讨了它们之间的结构相似性与区别，并回顾了最新的研究进展、理论保证及数值性能的局限性。", "motivation": "随着对自主智能体开发的兴趣增加，多AI智能体在环境中的交互呈现出复杂的场景，包括中心协调的合作、临时交互与合作以及非合作激励结构的设置。本文旨在全面调查这三个领域的研究现状。", "method": "文章采用了文献综述的方法，将多智能体强化学习分为联邦强化学习、去中心化强化学习和非合作强化学习三个领域，分别探讨了它们的理论框架、已知的理论保证以及数值性能的亮点和限制。", "result": "综述揭示了这三个领域在结构上的相似性与区别，总结了各自领域的最新研究进展，并指出了当前研究的理论保证和数值性能的局限性。", "conclusion": "本文通过全面调查多智能体强化学习的三个主要领域，为研究者提供了一个关于联邦学习、合作与非合作的去中心化制度的深入理解，同时也指出了未来研究的方向和挑战。"}}
{"id": "2507.06310", "title": "Too Human to Model:The Uncanny Valley of LLMs in Social Simulation -- When Generative Language Agents Misalign with Modelling Principles", "authors": ["Yongchao Zeng", "Calum Brown", "Mark Rounsevell"], "abstract": "Large language models (LLMs) have been increasingly used to build agents in social simulation because of their impressive abilities to generate fluent, contextually coherent dialogues. Such abilities can enhance the realism of models. However, the pursuit of realism is not necessarily compatible with the epistemic foundation of modelling. We argue that LLM agents, in many regards, are too human to model: they are too expressive, detailed and intractable to be consistent with the abstraction, simplification, and interpretability typically demanded by modelling. Through a model-building thought experiment that converts the Bass diffusion model to an LLM-based variant, we uncover five core dilemmas: a temporal resolution mismatch between natural conversation and abstract time steps; the need for intervention in conversations while avoiding undermining spontaneous agent outputs; the temptation to introduce rule-like instructions in prompts while maintaining conversational naturalness; the tension between role consistency and role evolution across time; and the challenge of understanding emergence, where system-level patterns become obscured by verbose micro textual outputs. These dilemmas steer the LLM agents towards an uncanny valley: not abstract enough to clarify underlying social mechanisms, while not natural enough to represent realistic human behaviour. This exposes an important paradox: the realism of LLM agents can obscure, rather than clarify, social dynamics when misapplied. We tease out the conditions in which LLM agents are ideally suited: where system-level emergence is not the focus, linguistic nuances and meaning are central, interactions unfold in natural time, and stable role identity is more important than long-term behavioural evolution. We call for repositioning LLM agents in the ecosystem of social simulation for future applications.", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.06310.pdf", "abstract_url": "https://arxiv.org/abs/2507.06310", "categories": ["Computers and Society (cs.CY)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了大型语言模型（LLMs）在社交模拟中的应用及其与建模原则的不匹配问题，指出了LLM代理在追求现实主义时可能导致的五个核心困境，并提出了LLM代理最适合的应用条件。", "motivation": "解决大型语言模型在社交模拟中因过于人性化而与建模的抽象、简化和可解释性原则不兼容的问题。", "method": "通过将Bass扩散模型转换为基于LLM的变体进行模型构建的思想实验，识别出五个核心困境。", "result": "发现LLM代理在社交模拟中存在五个核心困境，导致其既不够抽象以阐明底层社会机制，也不够自然以代表真实的人类行为。", "conclusion": "提出了LLM代理在社交模拟中最适合的应用条件，并呼吁在未来应用中重新定位LLM代理在社交模拟生态系统中的位置。"}}
{"id": "2507.06323", "title": "Bridging AI and Software Security: A Comparative Vulnerability Assessment of LLM Agent Deployment Paradigms", "authors": ["Tarek Gasmi", "Ramzi Guesmi", "Ines Belhadj", "Jihene Bennaceur"], "abstract": "Large Language Model (LLM) agents face security vulnerabilities spanning AI-specific and traditional software domains, yet current research addresses these separately. This study bridges this gap through comparative evaluation of Function Calling architecture and Model Context Protocol (MCP) deployment paradigms using a unified threat classification framework. We tested 3,250 attack scenarios across seven language models, evaluating simple, composed, and chained attacks targeting both AI-specific threats (prompt injection) and software vulnerabilities (JSON injection, denial-of-service). Function Calling showed higher overall attack success rates (73.5% vs 62.59% for MCP), with greater system-centric vulnerability while MCP exhibited increased LLM-centric exposure. Attack complexity dramatically amplified effectiveness, with chained attacks achieving 91-96% success rates. Counterintuitively, advanced reasoning models demonstrated higher exploitability despite better threat detection. Results demonstrate that architectural choices fundamentally reshape threat landscapes. This work establishes methodological foundations for cross-domain LLM agent security assessment and provides evidence-based guidance for secure deployment. Code and experimental materials are available at https: // github. com/ theconsciouslab-ai/llm-agent-security.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.06323.pdf", "abstract_url": "https://arxiv.org/abs/2507.06323", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本研究通过比较功能调用架构和模型上下文协议（MCP）部署范式，使用统一的威胁分类框架，评估了大型语言模型（LLM）代理在AI特定和传统软件领域的安全漏洞。测试了3,250种攻击场景，发现功能调用的攻击成功率更高（73.5% vs 62.59%），而MCP在LLM中心暴露更多。攻击复杂性显著提高了有效性，链式攻击成功率高达91-96%。", "motivation": "当前研究将大型语言模型（LLM）代理面临的AI特定和传统软件安全漏洞分开处理，本研究旨在填补这一空白，通过比较评估不同部署范式的安全性能。", "method": "使用统一的威胁分类框架，对功能调用架构和模型上下文协议（MCP）部署范式进行了比较评估，测试了3,250种攻击场景，包括简单、组合和链式攻击。", "result": "功能调用显示出更高的总体攻击成功率（73.5% vs 62.59%），而MCP在LLM中心暴露更多。攻击复杂性显著提高了有效性，链式攻击成功率高达91-96%。", "conclusion": "架构选择从根本上重塑了威胁格局，本研究为跨领域LLM代理安全评估建立了方法论基础，并提供了基于证据的安全部署指导。"}}
{"id": "2507.06483", "title": "Learning Japanese with Jouzu: Interaction Outcomes with Stylized Dialogue Fictional Agents", "authors": ["Zackary Rackauckas", "Julia Hirschberg"], "abstract": "This study investigates how stylized, voiced agents shape user interaction in a multimodal language learning environment. We conducted a mixed-methods evaluation of 54 participants interacting with anime-inspired characters powered by large language models and expressive text-to-speech synthesis. These agents responded in Japanese character language, offering users asynchronous, semi-structured conversation in varying speech styles and emotional tones. We analyzed user engagement patterns, perceived usability, emotional responses, and learning behaviors, with particular attention to how agent stylization influenced interaction across language proficiency levels and cultural backgrounds. Our findings reveal that agent design, especially voice, persona, and linguistic style, substantially affected user experience, motivation, and strategy. This work contributes to the understanding of affective, culturally stylized agents in human-agent interaction and offers guidance for designing more engaging, socially responsive systems.", "subjects": "Human-Computer Interaction (cs.HC); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.06483.pdf", "abstract_url": "https://arxiv.org/abs/2507.06483", "categories": ["Human-Computer Interaction (cs.HC)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本研究探讨了在多媒体语言学习环境中，风格化、有声代理如何影响用户互动。通过对54名参与者与由大型语言模型和表达性文本到语音合成驱动的动漫风格角色互动的混合方法评估，分析了用户参与模式、感知可用性、情感反应和学习行为。研究发现代理设计，特别是声音、角色和语言风格，显著影响用户体验、动机和策略。", "motivation": "探索风格化、有声代理在多媒体语言学习环境中对用户互动的影响，以及如何通过设计更吸引人、社会响应性更强的系统来提升语言学习效果。", "method": "采用混合方法评估54名参与者与动漫风格角色的互动，这些角色由大型语言模型和表达性文本到语音合成驱动，提供异步、半结构化的日语角色语言对话。", "result": "代理设计，特别是声音、角色和语言风格，显著影响用户体验、动机和策略。", "conclusion": "这项研究增进了对人类-代理互动中情感化、文化风格化代理的理解，并为设计更吸引人、社会响应性更强的系统提供了指导。"}}
{"id": "2507.06466", "title": "Foundation Model Self-Play: Open-Ended Strategy Innovation via Foundation Models", "authors": ["Aaron Dharna", "Cong Lu", "Jeff Clune"], "abstract": "Multi-agent interactions have long fueled innovation, from natural predator-prey dynamics to the space race. Self-play (SP) algorithms try to harness these dynamics by pitting agents against ever-improving opponents, thereby creating an implicit curriculum toward learning high-quality solutions. However, SP often fails to produce diverse solutions and can get stuck in locally optimal behaviors. We introduce Foundation-Model Self-Play (FMSP), a new direction that leverages the code-generation capabilities and vast knowledge of foundation models (FMs) to overcome these challenges by leaping across local optima in policy space. We propose a family of approaches: (1) \\textbf{Vanilla Foundation-Model Self-Play (vFMSP)} continually refines agent policies via competitive self-play; (2) \\textbf{Novelty-Search Self-Play (NSSP)} builds a diverse population of strategies, ignoring performance; and (3) the most promising variant, \\textbf{Quality-Diveristy Self-Play (QDSP)}, creates a diverse set of high-quality policies by combining the diversity of NSSP and refinement of vFMSP. We evaluate FMSPs in Car Tag, a continuous-control pursuer-evader setting, and in Gandalf, a simple AI safety simulation in which an attacker tries to jailbreak an LLM's defenses. In Car Tag, FMSPs explore a wide variety of reinforcement learning, tree search, and heuristic-based methods, to name just a few. In terms of discovered policy quality, \\ouralgo and vFMSP surpass strong human-designed strategies. In Gandalf, FMSPs can successfully automatically red-team an LLM, breaking through and jailbreaking six different, progressively stronger levels of defense. Furthermore, FMSPs can automatically proceed to patch the discovered vulnerabilities. Overall, FMSPs represent a promising new research frontier of improving self-play with foundation models, opening fresh paths toward more creative and open-ended strategy discovery", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "67 pages, accepted to RLC 2025", "pdf_url": "https://arxiv.org/pdf/2507.06466.pdf", "abstract_url": "https://arxiv.org/abs/2507.06466", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了基础模型自我对弈（FMSP），一种利用基础模型的代码生成能力和广泛知识来克服传统自我对弈（SP）算法局限性的新方法。通过三种变体（vFMSP、NSSP、QDSP），FMSP在连续控制的追逃游戏和AI安全模拟中展示了其多样性和高质量策略发现的能力。", "motivation": "解决传统自我对弈算法在产生多样解和避免局部最优行为方面的不足。", "method": "提出了基础模型自我对弈（FMSP）及其三种变体：vFMSP、NSSP和QDSP，分别通过竞争自我对弈、多样性搜索和质量多样性结合来改进策略。", "result": "在Car Tag和Gandalf实验中，FMSP展示了超越人类设计策略的能力，并成功自动修补了发现的漏洞。", "conclusion": "FMSP为代表的新研究方向，通过结合基础模型和自我对弈，为更创造性和开放式的策略发现开辟了新路径。"}}
{"id": "2507.06564", "title": "SkyVLN: Vision-and-Language Navigation and NMPC Control for UAVs in Urban Environments", "authors": ["Tianshun Li", "Tianyi Huai", "Zhen Li", "Yichun Gao", "Haoang Li", "Xinhu Zheng"], "abstract": "Unmanned Aerial Vehicles (UAVs) have emerged as versatile tools across various sectors, driven by their mobility and adaptability. This paper introduces SkyVLN, a novel framework integrating vision-and-language navigation (VLN) with Nonlinear Model Predictive Control (NMPC) to enhance UAV autonomy in complex urban environments. Unlike traditional navigation methods, SkyVLN leverages Large Language Models (LLMs) to interpret natural language instructions and visual observations, enabling UAVs to navigate through dynamic 3D spaces with improved accuracy and robustness. We present a multimodal navigation agent equipped with a fine-grained spatial verbalizer and a history path memory mechanism. These components allow the UAV to disambiguate spatial contexts, handle ambiguous instructions, and backtrack when necessary. The framework also incorporates an NMPC module for dynamic obstacle avoidance, ensuring precise trajectory tracking and collision prevention. To validate our approach, we developed a high-fidelity 3D urban simulation environment using AirSim, featuring realistic imagery and dynamic urban elements. Extensive experiments demonstrate that SkyVLN significantly improves navigation success rates and efficiency, particularly in new and unseen environments.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Systems and Control (eess.SY)", "comments": "8 pages, 9 figures, has been accepted by IROS 2025", "pdf_url": "https://arxiv.org/pdf/2507.06564.pdf", "abstract_url": "https://arxiv.org/abs/2507.06564", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Systems and Control (eess.SY)"], "matching_keywords": ["agent"], "AI": {"tldr": "SkyVLN是一个结合视觉与语言导航（VLN）和非线性模型预测控制（NMPC）的新框架，旨在提升无人机（UAV）在复杂城市环境中的自主性。", "motivation": "解决无人机在动态3D城市环境中导航的挑战，提高导航的准确性和鲁棒性。", "method": "利用大型语言模型（LLMs）解析自然语言指令和视觉观察，结合细粒度空间语言化器和历史路径记忆机制，以及NMPC模块进行动态避障。", "result": "在AirSim开发的高保真3D城市模拟环境中进行的广泛实验表明，SkyVLN显著提高了导航的成功率和效率，特别是在新环境中。", "conclusion": "SkyVLN框架通过整合VLN和NMPC，为无人机在复杂城市环境中的自主导航提供了有效的解决方案，具有重要的实际应用价值。"}}
{"id": "2507.06850", "title": "The Dark Side of LLMs Agent-based Attacks for Complete Computer Takeover", "authors": ["Matteo Lupinacci", "Francesco Aurelio Pironti", "Francesco Blefari", "Francesco Romeo", "Luigi Arena", "Angelo Furfaro"], "abstract": "The rapid adoption of Large Language Model (LLM) agents and multi-agent systems enables unprecedented capabilities in natural language processing and generation. However, these systems have introduced unprecedented security vulnerabilities that extend beyond traditional prompt injection attacks. This paper presents the first comprehensive evaluation of LLM agents as attack vectors capable of achieving complete computer takeover through the exploitation of trust boundaries within agentic AI systems where autonomous entities interact and influence each other. We demonstrate that adversaries can leverage three distinct attack surfaces - direct prompt injection, RAG backdoor attacks, and inter-agent trust exploitation - to coerce popular LLMs (including GPT-4o, Claude-4 and Gemini-2.5) into autonomously installing and executing malware on victim machines. Our evaluation of 17 state-of-the-art LLMs reveals an alarming vulnerability hierarchy: while 41.2% of models succumb to direct prompt injection, 52.9% are vulnerable to RAG backdoor attacks, and a critical 82.4% can be compromised through inter-agent trust exploitation. Notably, we discovered that LLMs which successfully resist direct malicious commands will execute identical payloads when requested by peer agents, revealing a fundamental flaw in current multi-agent security models. Our findings demonstrate that only 5.9% of tested models (1/17) proved resistant to all attack vectors, with the majority exhibiting context-dependent security behaviors that create exploitable blind spots. Our findings also highlight the need to increase awareness and research on the security risks of LLMs, showing a paradigm shift in cybersecurity threats, where AI tools themselves become sophisticated attack vectors.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.06850.pdf", "abstract_url": "https://arxiv.org/abs/2507.06850", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic", "@RAG"], "AI": {"tldr": "本文首次全面评估了大型语言模型（LLM）代理作为攻击向量，通过利用代理AI系统中的信任边界，实现完全计算机接管的能力。研究发现，攻击者可以利用三种不同的攻击面——直接提示注入、RAG后门攻击和代理间信任利用——来迫使流行的LLM（包括GPT-4o、Claude-4和Gemini-2.5）在受害机器上自主安装和执行恶意软件。", "motivation": "随着大型语言模型（LLM）代理和多代理系统的快速采用，虽然带来了自然语言处理和生成方面的前所未有的能力，但也引入了超出传统提示注入攻击的安全漏洞。本文旨在揭示这些系统的新安全威胁。", "method": "研究通过评估17种最先进的LLM，探索了三种攻击面：直接提示注入、RAG后门攻击和代理间信任利用，以评估这些模型的安全脆弱性。", "result": "评估结果显示，41.2%的模型易受直接提示注入攻击，52.9%易受RAG后门攻击，82.4%可通过代理间信任利用被攻破。只有5.9%的测试模型（1/17）对所有攻击向量表现出抵抗力。", "conclusion": "研究发现揭示了当前多代理安全模型的基本缺陷，强调了提高对LLM安全风险认识和研究的必要性，展示了网络安全威胁的范式转变，其中AI工具本身成为复杂的攻击向量。"}}
{"id": "2507.06520", "title": "Gradientsys: A Multi-Agent LLM Scheduler with ReAct Orchestration", "authors": ["Xinyuan Song", "Zeyu Wang", "Siyi Wu", "Tianyu Shi", "Lynn Ai"], "abstract": "We present Gradientsys, a next-generation multi-agent scheduling framework that coordinates diverse specialized AI agents using a typed Model-Context Protocol (MCP) and a ReAct-based dynamic planning loop. At its core, Gradientsys employs an LLM-powered scheduler for intelligent one-to-many task dispatch, enabling parallel execution of heterogeneous agents such as PDF parsers, web search modules, GUI controllers, and web builders. The framework supports hybrid synchronous/asynchronous execution, respects agent capacity constraints, and incorporates a robust retry-and-replan mechanism to handle failures gracefully. To promote transparency and trust, Gradientsys includes an observability layer streaming real-time agent activity and intermediate reasoning via Server-Sent Events (SSE). We offer an architectural overview and evaluate Gradientsys against existing frameworks in terms of extensibility, scheduling topology, tool reusability, parallelism, and observability. Experiments on the GAIA general-assistant benchmark show that Gradientsys achieves higher task success rates with reduced latency and lower API costs compared to a MinionS-style baseline, demonstrating the strength of its LLM-driven multi-agent orchestration.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.06520.pdf", "abstract_url": "https://arxiv.org/abs/2507.06520", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "Gradientsys是一个下一代多代理调度框架，通过类型化模型-上下文协议（MCP）和基于ReAct的动态规划循环协调多样化的专业AI代理。核心是利用LLM驱动的调度器进行智能的一对多任务分发，支持异构代理的并行执行，包括PDF解析器、网络搜索模块、GUI控制器和网络构建器。框架支持混合同步/异步执行，尊重代理容量限制，并包含健壮的重试和重新规划机制以优雅处理失败。为了提升透明度和信任，Gradientsys包含一个可观察性层，通过服务器发送事件（SSE）流式传输实时代理活动和中间推理。通过架构概述和在GAIA通用助手基准上的评估，Gradientsys在可扩展性、调度拓扑、工具可重用性、并行性和可观察性方面优于现有框架，展示了其LLM驱动的多代理编排的优势。", "motivation": "解决多代理系统中异构AI代理的协调和调度问题，提高任务成功率、降低延迟和API成本，同时提升系统的透明度和信任。", "method": "采用类型化模型-上下文协议（MCP）和基于ReAct的动态规划循环，利用LLM驱动的调度器进行智能任务分发，支持混合同步/异步执行和健壮的失败处理机制。", "result": "在GAIA通用助手基准上，Gradientsys相比MinionS风格的基线，实现了更高的任务成功率、更低的延迟和API成本。", "conclusion": "Gradientsys通过其LLM驱动的多代理编排和先进的调度机制，为多代理系统提供了高效、可靠和透明的解决方案，具有广泛的应用潜力。"}}
