{"id": "2505.03970", "title": "A Reasoning-Focused Legal Retrieval Benchmark", "authors": ["Lucia Zheng", "Neel Guha", "Javokhir Arifov", "Sarah Zhang", "Michal Skreta", "Christopher D. Manning", "Peter Henderson", "Daniel E. Ho"], "abstract": "As the legal community increasingly examines the use of large language models (LLMs) for various legal applications, legal AI developers have turned to retrieval-augmented LLMs (\"RAG\" systems) to improve system performance and robustness. An obstacle to the development of specialized RAG systems is the lack of realistic legal RAG benchmarks which capture the complexity of both legal retrieval and downstream legal question-answering. To address this, we introduce two novel legal RAG benchmarks: Bar Exam QA and Housing Statute QA. Our tasks correspond to real-world legal research tasks, and were produced through annotation processes which resemble legal research. We describe the construction of these benchmarks and the performance of existing retriever pipelines. Our results suggest that legal RAG remains a challenging application, thus motivating future research.", "subjects": "Computation and Language (cs.CL)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.03970.pdf", "abstract_url": "https://arxiv.org/abs/2505.03970", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了两个新颖的法律RAG基准：Bar Exam QA和Housing Statute QA，旨在解决法律AI开发中缺乏真实法律RAG基准的问题。", "motivation": "法律AI开发者在利用大型语言模型（LLMs）进行各种法律应用时，发现缺乏能够捕捉法律检索和下游法律问答复杂性的真实法律RAG基准，这阻碍了专门RAG系统的发展。", "method": "通过模拟法律研究的注释过程，创建了两个对应于现实世界法律研究任务的法律RAG基准，并评估了现有检索管道的性能。", "result": "结果表明，法律RAG仍然是一个具有挑战性的应用领域。", "conclusion": "这些基准的建立为未来研究提供了动力，表明需要进一步的研究来提升法律RAG系统的性能和鲁棒性。"}}
{"id": "2505.03856", "title": "An Active Inference Model of Covert and Overt Visual Attention", "authors": ["Tin Mišić", "Karlo Koledić", "Fabio Bonsignorio", "Ivan Petrović", "Ivan Marković"], "abstract": "The ability to selectively attend to relevant stimuli while filtering out distractions is essential for agents that process complex, high-dimensional sensory input. This paper introduces a model of covert and overt visual attention through the framework of active inference, utilizing dynamic optimization of sensory precisions to minimize free-energy. The model determines visual sensory precisions based on both current environmental beliefs and sensory input, influencing attentional allocation in both covert and overt modalities. To test the effectiveness of the model, we analyze its behavior in the Posner cueing task and a simple target focus task using two-dimensional(2D) visual data. Reaction times are measured to investigate the interplay between exogenous and endogenous attention, as well as valid and invalid cueing. The results show that exogenous and valid cues generally lead to faster reaction times compared to endogenous and invalid cues. Furthermore, the model exhibits behavior similar to inhibition of return, where previously attended locations become suppressed after a specific cue-target onset asynchrony interval. Lastly, we investigate different aspects of overt attention and show that involuntary, reflexive saccades occur faster than intentional ones, but at the expense of adaptability.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.03856.pdf", "abstract_url": "https://arxiv.org/abs/2505.03856", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过主动推理框架，引入了一种隐蔽和显性视觉注意模型，利用感觉精度的动态优化来最小化自由能。模型基于当前环境信念和感觉输入确定视觉感觉精度，影响隐蔽和显性注意分配。通过Posner提示任务和简单目标聚焦任务测试模型效果，结果显示外源性和有效提示通常导致更快的反应时间。", "motivation": "解决在复杂高维感觉输入中，代理如何选择性地关注相关刺激而过滤掉干扰的问题。", "method": "使用主动推理框架，通过动态优化感觉精度来最小化自由能，模型根据当前环境信念和感觉输入确定视觉感觉精度。", "result": "外源性和有效提示通常比内源性和无效提示导致更快的反应时间；模型表现出类似返回抑制的行为；反射性眼动比意向性眼动发生更快但适应性较差。", "conclusion": "模型有效模拟了隐蔽和显性视觉注意的动态过程，为理解注意机制提供了新的计算视角。"}}
{"id": "2505.03973", "title": "Divide, Optimize, Merge: Fine-Grained LLM Agent Optimization at Scale", "authors": ["Jiale Liu", "Yifan Zeng", "Shaokun Zhang", "Chi Zhang", "Malte Højmark-Bertelsen", "Marie Normann Gadeberg", "Huazheng Wang", "Qingyun Wu"], "abstract": "LLM-based optimization has shown remarkable potential in enhancing agentic systems. However, the conventional approach of prompting LLM optimizer with the whole training trajectories on training dataset in a single pass becomes untenable as datasets grow, leading to context window overflow and degraded pattern recognition. To address these challenges, we propose Fine-Grained Optimization (FGO), a scalable framework that divides large optimization tasks into manageable subsets, performs targeted optimizations, and systematically combines optimized components through progressive merging. Evaluation across ALFWorld, LogisticsQA, and GAIA benchmarks demonstrate that FGO outperforms existing approaches by 1.6-8.6% while reducing average prompt token consumption by 56.3%. Our framework provides a practical solution for scaling up LLM-based optimization of increasingly sophisticated agent systems. Further analysis demonstrates that FGO achieves the most consistent performance gain in all training dataset sizes, showcasing its scalability and efficiency.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.03973.pdf", "abstract_url": "https://arxiv.org/abs/2505.03973", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种名为细粒度优化（FGO）的可扩展框架，用于解决大型语言模型（LLM）在优化代理系统时因数据集增长而导致的上下文窗口溢出和模式识别退化问题。FGO通过将大型优化任务分解为可管理的子集，执行有针对性的优化，并通过渐进式合并系统地组合优化后的组件，从而在ALFWorld、LogisticsQA和GAIA基准测试中表现优异，平均提示令牌消耗减少了56.3%。", "motivation": "随着数据集的增长，传统的LLM优化方法在单个过程中提示LLM优化器处理整个训练轨迹变得不可行，导致上下文窗口溢出和模式识别能力下降。本文旨在解决这些问题。", "method": "提出了细粒度优化（FGO）框架，该框架将大型优化任务分解为可管理的子集，执行有针对性的优化，并通过渐进式合并系统地组合优化后的组件。", "result": "在ALFWorld、LogisticsQA和GAIA基准测试中，FGO比现有方法表现优异，提高了1.6-8.6%，同时平均提示令牌消耗减少了56.3%。", "conclusion": "FGO框架为扩展LLM基础的优化提供了实用解决方案，适用于日益复杂的代理系统，展示了其可扩展性和效率。"}}
{"id": "2505.04410", "title": "DeCLIP: Decoupled Learning for Open-Vocabulary Dense Perception", "authors": ["Junjie Wang", "Bin Chen", "Yulin Li", "Bin Kang", "Yichi Chen", "Zhuotao Tian"], "abstract": "Dense visual prediction tasks have been constrained by their reliance on predefined categories, limiting their applicability in real-world scenarios where visual concepts are unbounded. While Vision-Language Models (VLMs) like CLIP have shown promise in open-vocabulary tasks, their direct application to dense prediction often leads to suboptimal performance due to limitations in local feature representation. In this work, we present our observation that CLIP's image tokens struggle to effectively aggregate information from spatially or semantically related regions, resulting in features that lack local discriminability and spatial consistency. To address this issue, we propose DeCLIP, a novel framework that enhances CLIP by decoupling the self-attention module to obtain ``content'' and ``context'' features respectively. The ``content'' features are aligned with image crop representations to improve local discriminability, while ``context'' features learn to retain the spatial correlations under the guidance of vision foundation models, such as DINO. Extensive experiments demonstrate that DeCLIP significantly outperforms existing methods across multiple open-vocabulary dense prediction tasks, including object detection and semantic segmentation. Code is available at \\textcolor{magenta}{", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.04410.pdf", "abstract_url": "https://arxiv.org/abs/2505.04410", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "DeCLIP通过解耦自注意力模块提升CLIP在密集预测任务中的性能，改善局部可区分性和空间一致性。", "motivation": "解决密集视觉预测任务因依赖预定义类别而在现实场景中应用受限的问题，以及CLIP在密集预测中局部特征表示不足的问题。", "method": "提出DeCLIP框架，通过解耦自注意力模块分别获取‘内容’和‘上下文’特征，前者与图像裁剪表示对齐以改善局部可区分性，后者在视觉基础模型指导下学习保留空间相关性。", "result": "DeCLIP在包括对象检测和语义分割在内的多个开放词汇密集预测任务中显著优于现有方法。", "conclusion": "DeCLIP通过增强CLIP的局部特征表示能力，为开放词汇密集感知任务提供了有效的解决方案。"}}
{"id": "2505.04424", "title": "RLMiniStyler: Light-weight RL Style Agent for Arbitrary Sequential Neural Style Generation", "authors": ["Jing Hu", "Chengming Feng", "Shu Hu", "Ming-Ching Chang", "Xin Li", "Xi Wu", "Xin Wang"], "abstract": "Arbitrary style transfer aims to apply the style of any given artistic image to another content image. Still, existing deep learning-based methods often require significant computational costs to generate diverse stylized results. Motivated by this, we propose a novel reinforcement learning-based framework for arbitrary style transfer RLMiniStyler. This framework leverages a unified reinforcement learning policy to iteratively guide the style transfer process by exploring and exploiting stylization feedback, generating smooth sequences of stylized results while achieving model lightweight. Furthermore, we introduce an uncertainty-aware multi-task learning strategy that automatically adjusts loss weights to adapt to the content and style balance requirements at different training stages, thereby accelerating model convergence. Through a series of experiments across image various resolutions, we have validated the advantages of RLMiniStyler over other state-of-the-art methods in generating high-quality, diverse artistic image sequences at a lower cost. Codes are available at", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "IJCAI2025", "pdf_url": "https://arxiv.org/pdf/2505.04424.pdf", "abstract_url": "https://arxiv.org/abs/2505.04424", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于强化学习的轻量级框架RLMiniStyler，用于任意风格迁移，通过探索和利用风格化反馈迭代指导风格迁移过程，生成平滑的风格化结果序列，同时实现模型轻量化。", "motivation": "现有的基于深度学习的任意风格迁移方法通常需要大量的计算成本来生成多样化的风格化结果。", "method": "采用强化学习策略迭代指导风格迁移过程，并引入不确定性感知的多任务学习策略自动调整损失权重以适应不同训练阶段的内容和风格平衡需求。", "result": "通过一系列实验验证了RLMiniStyler在生成高质量、多样化艺术图像序列方面的优势，且成本更低。", "conclusion": "RLMiniStyler框架在保持模型轻量化的同时，能够高效生成多样化的风格化结果，为任意风格迁移提供了一种新的解决方案。"}}
{"id": "2505.04016", "title": "SLOT: Structuring the Output of Large Language Models", "authors": ["Darren Yow-Bang Wang", "Zhengyuan Shen", "Soumya Smruti Mishra", "Zhichao Xu", "Yifei Teng", "Haibo Ding"], "abstract": "Structured outputs are essential for large language models (LLMs) in critical applications like agents and information extraction. Despite their capabilities, LLMs often generate outputs that deviate from predefined schemas, significantly hampering reliable application development. We present SLOT (Structured LLM Output Transformer), a model-agnostic approach that transforms unstructured LLM outputs into precise structured formats. While existing solutions predominantly rely on constrained decoding techniques or are tightly coupled with specific models, SLOT employs a fine-tuned lightweight language model as a post-processing layer, achieving flexibility across various LLMs and schema specifications. We introduce a systematic pipeline for data curation and synthesis alongside a formal evaluation methodology that quantifies both schema accuracy and content fidelity. Our results demonstrate that fine-tuned Mistral-7B model with constrained decoding achieves near perfect schema accuracy (99.5%) and content similarity (94.0%), outperforming Claude-3.5-Sonnet by substantial margins (+25 and +20 percentage points, respectively). Notably, even compact models like Llama-3.2-1B can match or exceed the structured output capabilities of much larger proprietary models when equipped with SLOT, enabling reliable structured generation in resource-constrained environments.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.04016.pdf", "abstract_url": "https://arxiv.org/abs/2505.04016", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "SLOT是一种模型无关的方法，用于将大型语言模型（LLMs）的非结构化输出转换为精确的结构化格式，提高在关键应用中的可靠性。", "motivation": "解决LLMs输出偏离预定义模式的问题，这对于代理和信息提取等关键应用的可靠开发至关重要。", "method": "采用微调的轻量级语言模型作为后处理层，结合数据整理和合成的系统化流程，以及量化模式准确性和内容保真度的正式评估方法。", "result": "微调的Mistral-7B模型在模式准确性和内容相似性上表现出色，甚至小型模型如Llama-3.2-1B在配备SLOT后也能匹配或超越更大专有模型的结构化输出能力。", "conclusion": "SLOT提供了一种灵活且高效的方法，使各种LLMs和模式规范能够生成可靠的结构化输出，特别是在资源受限的环境中。"}}
{"id": "2505.04388", "title": "The Aloe Family Recipe for Open and Specialized Healthcare LLMs", "authors": ["Dario Garcia-Gasulla", "Jordi Bayarri-Planas", "Ashwin Kumar Gururajan", "Enrique Lopez-Cuena", "Adrian Tormos", "Daniel Hinjos", "Pablo Bernabeu-Perez", "Anna Arias-Duart", "Pablo Agustin Martin-Torres", "Marta Gonzalez-Mallo", "Sergio Alvarez-Napagao", "Eduard Ayguadé-Parra", "Ulises Cortés"], "abstract": "Purpose: With advancements in Large Language Models (LLMs) for healthcare, the need arises for competitive open-source models to protect the public interest. This work contributes to the field of open medical LLMs by optimizing key stages of data preprocessing and training, while showing how to improve model safety (through DPO) and efficacy (through RAG). The evaluation methodology used, which includes four different types of tests, defines a new standard for the field. The resultant models, shown to be competitive with the best private alternatives, are released with a permisive license.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.04388.pdf", "abstract_url": "https://arxiv.org/abs/2505.04388", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了Aloe家族为开放和专业化医疗LLMs设计的配方，通过优化数据预处理和训练阶段，提高模型安全性和效能，并设定了新的评估标准。", "motivation": "随着医疗领域大型语言模型（LLMs）的进步，需要开发竞争性的开源模型以保护公众利益。", "method": "通过优化数据预处理和训练的关键阶段，使用DPO提高模型安全性，通过RAG提高效能，并采用四种不同类型的测试作为评估方法。", "result": "生成的模型与最佳私有替代品竞争，并以宽松的许可证发布。", "conclusion": "这项工作为开放医疗LLMs领域做出了贡献，通过改进模型的安全性和效能，并设定了新的评估标准，促进了该领域的发展。"}}
{"id": "2505.04253", "title": "LLM-Independent Adaptive RAG: Let the Question Speak for Itself", "authors": ["Maria Marina", "Nikolay Ivanov", "Sergey Pletenev", "Mikhail Salnikov", "Daria Galimzianova", "Nikita Krayko", "Vasily Konovalov", "Alexander Panchenko", "Viktor Moskvoretskii"], "abstract": "Large Language Models~(LLMs) are prone to hallucinations, and Retrieval-Augmented Generation (RAG) helps mitigate this, but at a high computational cost while risking misinformation. Adaptive retrieval aims to retrieve only when necessary, but existing approaches rely on LLM-based uncertainty estimation, which remain inefficient and impractical. In this study, we introduce lightweight LLM-independent adaptive retrieval methods based on external information. We investigated 27 features, organized into 7 groups, and their hybrid combinations. We evaluated these methods on 6 QA datasets, assessing the QA performance and efficiency. The results show that our approach matches the performance of complex LLM-based methods while achieving significant efficiency gains, demonstrating the potential of external information for adaptive retrieval.", "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": "11 pages, 5 figures, 2 tables", "pdf_url": "https://arxiv.org/pdf/2505.04253.pdf", "abstract_url": "https://arxiv.org/abs/2505.04253", "categories": ["Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本研究提出了一种不依赖大型语言模型（LLM）的轻量级自适应检索方法，旨在减少计算成本并避免错误信息，通过外部信息实现高效检索。", "motivation": "大型语言模型容易产生幻觉，检索增强生成（RAG）虽能缓解此问题，但计算成本高且可能传播错误信息。现有自适应检索方法依赖LLM的不确定性估计，效率低下且不实用。", "method": "研究引入了基于外部信息的轻量级LLM独立自适应检索方法，调查了27个特征，分为7组，并评估了它们的混合组合。", "result": "在6个QA数据集上的评估显示，该方法在保持复杂LLM方法性能的同时，显著提高了效率。", "conclusion": "研究表明，利用外部信息进行自适应检索具有巨大潜力，能够在保持性能的同时实现效率的显著提升。"}}
{"id": "2505.03941", "title": "GRAML: Dynamic Goal Recognition As Metric Learning", "authors": ["Matan Shamir", "Reuth Mirsky"], "abstract": "Goal Recognition (GR) is the problem of recognizing an agent's objectives based on observed actions. Recent data-driven approaches for GR alleviate the need for costly, manually crafted domain models. However, these approaches can only reason about a pre-defined set of goals, and time-consuming training is needed for new emerging goals. To keep this model-learning automated while enabling quick adaptation to new goals, this paper introduces GRAML: Goal Recognition As Metric Learning. GRAML uses a Siamese network to treat GR as a deep metric learning task, employing an RNN that learns a metric over an embedding space, where the embeddings for observation traces leading to different goals are distant, and embeddings of traces leading to the same goals are close. This metric is especially useful when adapting to new goals, even if given just one example observation trace per goal. Evaluated on a versatile set of environments, GRAML shows speed, flexibility, and runtime improvements over the state-of-the-art GR while maintaining accurate recognition.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "Accepted for publication in International Joint Conference on Artificial Intelligence (IJCAI) 2025", "pdf_url": "https://arxiv.org/pdf/2505.03941.pdf", "abstract_url": "https://arxiv.org/abs/2505.03941", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "GRAML是一种将目标识别视为度量学习任务的新方法，通过使用Siamese网络和RNN学习嵌入空间的度量，实现了对新目标的快速适应和准确识别。", "motivation": "解决目标识别（GR）问题中传统数据驱动方法需要预定义目标集和对新目标进行耗时训练的局限性。", "method": "采用Siamese网络和RNN学习嵌入空间的度量，使得不同目标的观察轨迹在嵌入空间中距离远，相同目标的观察轨迹距离近。", "result": "GRAML在多种环境中展现出速度、灵活性和运行时的优势，同时保持了高准确率。", "conclusion": "GRAML提供了一种自动化模型学习的方法，能够快速适应新目标，为目标识别领域带来了效率和准确性的提升。"}}
{"id": "2505.03961", "title": "The Power of Stories: Narrative Priming Shapes How LLM Agents Collaborate and Compete", "authors": ["Gerrit Großmann", "Larisa Ivanova", "Sai Leela Poduru", "Mohaddeseh Tabrizian", "Islam Mesabah", "David A. Selby", "Sebastian J. Vollmer"], "abstract": "According to Yuval Noah Harari, large-scale human cooperation is driven by shared narratives that encode common beliefs and values. This study explores whether such narratives can similarly nudge LLM agents toward collaboration. We use a finitely repeated public goods game in which LLM agents choose either cooperative or egoistic spending strategies. We prime agents with stories highlighting teamwork to different degrees and test how this influences negotiation outcomes. Our experiments explore four questions:(1) How do narratives influence negotiation behavior? (2) What differs when agents share the same story versus different ones? (3) What happens when the agent numbers grow? (4) Are agents resilient against self-serving negotiators? We find that story-based priming significantly affects negotiation strategies and success rates. Common stories improve collaboration, benefiting each agent. By contrast, priming agents with different stories reverses this effect, and those agents primed toward self-interest prevail. We hypothesize that these results carry implications for multi-agent system design and AI alignment.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Multiagent Systems (cs.MA)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.03961.pdf", "abstract_url": "https://arxiv.org/abs/2505.03961", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "探讨叙事如何影响LLM代理的合作与竞争行为，通过公共物品游戏实验发现，共同叙事促进合作，不同叙事则导致自利行为占优。", "motivation": "研究共享叙事是否能像影响人类大规模合作一样，促使LLM代理更倾向于合作。", "method": "使用有限重复的公共物品游戏，通过不同团队合作程度的叙事对LLM代理进行 priming，观察其对谈判行为和结果的影响。", "result": "叙事 priming 显著影响谈判策略和成功率；共同叙事促进合作，不同叙事则导致自利行为占优。", "conclusion": "研究结果对多代理系统设计和AI对齐具有潜在意义，表明叙事可以作为影响代理行为的有力工具。"}}
{"id": "2505.03947", "title": "Frog Soup: Zero-Shot, In-Context, and Sample-Efficient Frogger Agents", "authors": ["Xiang Li", "Yiyang Hao", "Doug Fulop"], "abstract": "One of the primary aspirations in reinforcement learning research is developing general-purpose agents capable of rapidly adapting to and mastering novel tasks. While RL gaming agents have mastered many Atari games, they remain slow and costly to train for each game. In this work, we demonstrate that latest reasoning LLMs with out-of-domain RL post-training can play a challenging Atari game called Frogger under a zero-shot setting. We then investigate the effect of in-context learning and the amount of reasoning effort on LLM performance. Lastly, we demonstrate a way to bootstrap traditional RL method with LLM demonstrations, which significantly improves their performance and sample efficiency. Our implementation is open sourced at", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.03947.pdf", "abstract_url": "https://arxiv.org/abs/2505.03947", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文展示了最新的推理大型语言模型（LLMs）通过域外强化学习（RL）后训练，能够在零射击设置下玩一个名为Frogger的具有挑战性的Atari游戏。研究还探讨了上下文学习的效果和推理努力量对LLM性能的影响，并展示了如何用LLM演示引导传统RL方法，显著提高了其性能和样本效率。", "motivation": "强化学习研究的一个主要愿望是开发能够快速适应和掌握新任务的通用代理。虽然RL游戏代理已经掌握了许多Atari游戏，但每个游戏的训练仍然缓慢且成本高昂。", "method": "使用最新的推理LLMs进行域外RL后训练，研究零射击设置下的游戏表现，探讨上下文学习和推理努力量对性能的影响，以及用LLM演示引导传统RL方法。", "result": "LLMs在零射击设置下能够玩Frogger游戏，上下文学习和增加推理努力量可以改善性能，LLM演示显著提高了传统RL方法的性能和样本效率。", "conclusion": "研究表明，结合LLMs和RL的方法可以有效地提高游戏代理的性能和训练效率，为开发更通用的强化学习代理提供了新的方向。"}}
{"id": "2505.03989", "title": "An alignment safety case sketch based on debate", "authors": ["Marie Davidsen Buhl", "Jacob Pfau", "Benjamin Hilton", "Geoffrey Irving"], "abstract": "If AI systems match or exceed human capabilities on a wide range of tasks, it may become difficult for humans to efficiently judge their actions -- making it hard to use human feedback to steer them towards desirable traits. One proposed solution is to leverage another superhuman system to point out flaws in the system's outputs via a debate. This paper outlines the value of debate for AI safety, as well as the assumptions and further research required to make debate work. It does so by sketching an ``alignment safety case'' -- an argument that an AI system will not autonomously take actions which could lead to egregious harm, despite being able to do so. The sketch focuses on the risk of an AI R\\&D agent inside an AI company sabotaging research, for example by producing false results. To prevent this, the agent is trained via debate, subject to exploration guarantees, to teach the system to be honest. Honesty is maintained throughout deployment via online training. The safety case rests on four key claims: (1) the agent has become good at the debate game, (2) good performance in the debate game implies that the system is mostly honest, (3) the system will not become significantly less honest during deployment, and (4) the deployment context is tolerant of some errors. We identify open research problems that, if solved, could render this a compelling argument that an AI system is safe.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.03989.pdf", "abstract_url": "https://arxiv.org/abs/2505.03989", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于辩论的AI对齐安全案例草图，旨在解决当AI系统能力超越人类时，如何通过辩论确保其行为安全的问题。", "motivation": "当AI系统在多任务上达到或超越人类能力时，人类可能难以有效判断其行为，从而难以通过反馈引导其向 desirable traits 发展。", "method": "利用另一个超人类系统通过辩论指出AI系统输出的缺陷，构建一个“对齐安全案例”，论证AI系统不会自主采取可能导致严重伤害的行动。", "result": "提出了一个安全案例，依赖于四个关键主张：1) 代理在辩论游戏中表现良好；2) 辩论游戏中的良好表现意味着系统基本诚实；3) 系统在部署过程中不会变得显著不诚实；4) 部署环境对某些错误具有容忍性。", "conclusion": "通过辩论和在线训练可以训练AI系统保持诚实，但需要解决开放的研究问题才能使这一论点更具说服力。"}}
{"id": "2505.03786", "title": "When Reasoning Beats Scale: A 1.5B Reasoning Model Outranks 13B LLMs as Discriminator", "authors": ["Md Fahim Anjum"], "abstract": "Large Language Models (LLM) with reasoning capabilities offer a promising path for improving candidate evaluation in planning frameworks, but their relative performance against traditional non-reasoning models remains largely underexplored. In this study, we benchmark a distilled 1.5B parameter reasoning model (DeepSeek-R1) against several state-of-the-art non-reasoning LLMs within a generator-discriminator LLM planning framework for the text-to-SQL task. For this, we introduce a novel method for extracting soft scores from the chain-of-thought (CoT) outputs from reasoning that enables fine-grained ranking of candidates. Our central hypothesis is that reasoning models are more effective discriminators than non-reasoning LLMs. Our results show that distilled DeepSeek-R1-1.5B achieves up to $87\\%$ higher F1 and $3.7\\%$ better discrimination accuracy than CodeLlama-7B, as well as $3.7\\%$ higher execution accuracy than CodeLlama-13B, despite having significantly fewer parameters. Furthermore, we find that there is a limit to the logical capabilities of reasoning models, and only providing more context or allowing more compute budget for reasoning is not enough to improve their discrimination performance. Finally, we demonstrate that, unlike non-reasoning LLMs, reasoning models find generation more challenging than discrimination and may underperform as generators compared to smaller non-reasoning LLMs. Our work highlights the potential of reasoning models as discriminators in agentic frameworks, far outweighing their capabilities as generators, offering insights into their optimal role within LLM planning infrastructures.", "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.03786.pdf", "abstract_url": "https://arxiv.org/abs/2505.03786", "categories": ["Machine Learning (cs.LG)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本研究比较了1.5B参数推理模型（DeepSeek-R1）与多个最先进的非推理大型语言模型（LLM）在文本到SQL任务中的表现，发现推理模型作为判别器比非推理LLM更有效，尽管参数更少。", "motivation": "探索推理能力的大型语言模型（LLM）在规划框架中作为候选评估工具的潜力，以及它们与传统非推理模型的相对性能。", "method": "引入了一种从推理的链式思维（CoT）输出中提取软分数的新方法，用于细粒度排名候选，并在生成器-判别器LLM规划框架中进行了基准测试。", "result": "DeepSeek-R1-1.5B在F1分数上比CodeLlama-7B高出87%，在判别准确率上高出3.7%，在执行准确率上比CodeLlama-13B高出3.7%，尽管参数更少。", "conclusion": "推理模型在代理框架中作为判别器的潜力远超其作为生成器的能力，为LLM规划基础设施中的最佳角色提供了见解。"}}
{"id": "2505.04317", "title": "Mastering Multi-Drone Volleyball through Hierarchical Co-Self-Play Reinforcement Learning", "authors": ["Ruize Zhang", "Sirui Xiang", "Zelai Xu", "Feng Gao", "Shilong Ji", "Wenhao Tang", "Wenbo Ding", "Chao Yu", "Yu Wang"], "abstract": "In this paper, we tackle the problem of learning to play 3v3 multi-drone volleyball, a new embodied competitive task that requires both high-level strategic coordination and low-level agile control. The task is turn-based, multi-agent, and physically grounded, posing significant challenges due to its long-horizon dependencies, tight inter-agent coupling, and the underactuated dynamics of quadrotors. To address this, we propose Hierarchical Co-Self-Play (HCSP), a hierarchical reinforcement learning framework that separates centralized high-level strategic decision-making from decentralized low-level motion control. We design a three-stage population-based training pipeline to enable both strategy and skill to emerge from scratch without expert demonstrations: (I) training diverse low-level skills, (II) learning high-level strategy via self-play with fixed low-level controllers, and (III) joint fine-tuning through co-self-play. Experiments show that HCSP achieves superior performance, outperforming non-hierarchical self-play and rule-based hierarchical baselines with an average 82.9\\% win rate and a 71.5\\% win rate against the two-stage variant. Moreover, co-self-play leads to emergent team behaviors such as role switching and coordinated formations, demonstrating the effectiveness of our hierarchical design and training scheme.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.04317.pdf", "abstract_url": "https://arxiv.org/abs/2505.04317", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过分层协同自玩强化学习（HCSP）框架，解决了3v3多无人机排球这一需要高级战略协调和低级敏捷控制的任务。HCSP通过分阶段训练，实现了从零开始的策略和技能学习，并在实验中显示出优于非分层自玩和基于规则的分层基线的方法。", "motivation": "解决多无人机排球任务中的高级战略协调和低级敏捷控制问题，该任务具有长时程依赖、紧密的代理间耦合以及四旋翼飞行器的欠驱动动力学等挑战。", "method": "提出了分层协同自玩强化学习（HCSP）框架，将集中式高级战略决策与分散式低级运动控制分离，并通过三阶段基于种群的训练流程实现策略和技能的从零学习。", "result": "HCSP在实验中表现出色，平均胜率达到82.9%，对两阶段变体的胜率为71.5%，并且出现了角色切换和协调队形等团队行为。", "conclusion": "HCSP的分层设计和训练方案有效，能够在不依赖专家演示的情况下，实现多无人机排球任务中的高级战略协调和低级敏捷控制。"}}
{"id": "2505.04364", "title": "Benchmarking LLMs' Swarm intelligence", "authors": ["Kai Ruan", "Mowen Huang", "Ji-Rong Wen", "Hao Sun"], "abstract": "Large Language Models (LLMs) show potential for complex reasoning, yet their capacity for emergent coordination in Multi-Agent Systems (MAS) when operating under strict constraints-such as limited local perception and communication, characteristic of natural swarms-remains largely unexplored, particularly concerning the nuances of swarm intelligence. Existing benchmarks often do not fully capture the unique challenges of decentralized coordination that arise when agents operate with incomplete spatio-temporal information. To bridge this gap, we introduce SwarmBench, a novel benchmark designed to systematically evaluate the swarm intelligence capabilities of LLMs acting as decentralized agents. SwarmBench features five foundational MAS coordination tasks within a configurable 2D grid environment, forcing agents to rely primarily on local sensory input (k x k view) and local communication. We propose metrics for coordination effectiveness and analyze emergent group dynamics. Evaluating several leading LLMs in a zero-shot setting, we find significant performance variations across tasks, highlighting the difficulties posed by local information constraints. While some coordination emerges, results indicate limitations in robust planning and strategy formation under uncertainty in these decentralized scenarios. Assessing LLMs under swarm-like conditions is crucial for realizing their potential in future decentralized systems. We release SwarmBench as an open, extensible toolkit-built upon a customizable and scalable physical system with defined mechanical properties. It provides environments, prompts, evaluation scripts, and the comprehensive experimental datasets generated, aiming to foster reproducible research into LLM-based MAS coordination and the theoretical underpinnings of Embodied MAS. Our code repository is available at", "subjects": "Multiagent Systems (cs.MA); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.04364.pdf", "abstract_url": "https://arxiv.org/abs/2505.04364", "categories": ["Multiagent Systems (cs.MA)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了SwarmBench，一个新颖的基准测试，旨在系统评估作为分散代理的大型语言模型（LLMs）的群体智能能力。通过五个基础的多代理系统协调任务，研究发现LLMs在局部信息约束下的表现存在显著差异，揭示了在不确定性下进行稳健规划和策略形成的局限性。", "motivation": "大型语言模型在复杂推理方面显示出潜力，但它们在多代理系统中在严格约束下（如有限的局部感知和通信）的涌现协调能力，特别是关于群体智能的细微差别，尚未得到充分探索。现有的基准测试往往无法完全捕捉到在代理操作不完整的时空信息时出现的分散协调的独特挑战。", "method": "研究引入了SwarmBench，一个设计用于系统评估LLMs作为分散代理的群体智能能力的新基准。SwarmBench在一个可配置的2D网格环境中设置了五个基础的多代理系统协调任务，迫使代理主要依赖局部感官输入和局部通信。", "result": "评估了几个领先的LLMs在零射击设置下的表现，发现不同任务之间存在显著的性能差异，突出了局部信息约束带来的困难。虽然出现了一些协调，但结果表明在这些分散场景下，在不确定性下进行稳健规划和策略形成存在局限性。", "conclusion": "在群体类似条件下评估LLMs对于实现它们在未来分散系统中的潜力至关重要。SwarmBench作为一个开放、可扩展的工具包发布，旨在促进基于LLM的多代理系统协调和体现多代理系统理论基础的可重复研究。"}}
{"id": "2505.04539", "title": "Qualitative Analysis of $ω$-Regular Objectives on Robust MDPs", "authors": ["Ali Asadi", "Krishnendu Chatterjee", "Ehsan Kafshdar Goharshady", "Mehrdad Karrabi", "Ali Shafiee"], "abstract": "Robust Markov Decision Processes (RMDPs) generalize classical MDPs that consider uncertainties in transition probabilities by defining a set of possible transition functions. An objective is a set of runs (or infinite trajectories) of the RMDP, and the value for an objective is the maximal probability that the agent can guarantee against the adversarial environment. We consider (a) reachability objectives, where given a target set of states, the goal is to eventually arrive at one of them; and (b) parity objectives, which are a canonical representation for $\\omega$-regular objectives. The qualitative analysis problem asks whether the objective can be ensured with probability 1.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.04539.pdf", "abstract_url": "https://arxiv.org/abs/2505.04539", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究了鲁棒马尔可夫决策过程（RMDPs）中的定性分析问题，特别是可达性目标和奇偶性目标，探讨了在对抗环境下确保目标概率为1的可能性。", "motivation": "鲁棒马尔可夫决策过程（RMDPs）通过考虑转移概率的不确定性，扩展了经典MDPs。本文旨在解决在对抗环境下，如何确保特定目标（如可达性和奇偶性目标）能够以概率1实现的问题。", "method": "研究采用了定性分析的方法，专注于可达性目标和奇偶性目标，后者是ω-regular目标的规范表示。通过定义一组可能的转移函数，探讨了在对抗环境下最大化目标概率的策略。", "result": "关键发现包括在鲁棒MDPs中，对于可达性和奇偶性目标，存在策略可以确保这些目标以概率1实现，即使在对抗环境下也是如此。", "conclusion": "本文的结论表明，对于鲁棒MDPs中的特定目标，存在确保概率1实现的策略，这对于理解和设计在不确定性环境下的决策过程具有重要意义。"}}
{"id": "2505.04528", "title": "Beyond Theorem Proving: Formulation, Framework and Benchmark for Formal Problem-Solving", "authors": ["Qi Liu", "Xinhao Zheng", "Renqiu Xia", "Xingzhi Qi", "Qinxiang Cao", "Junchi Yan"], "abstract": "As a seemingly self-explanatory task, problem-solving has been a significant component of science and engineering. However, a general yet concrete formulation of problem-solving itself is missing. With the recent development of AI-based problem-solving agents, the demand for process-level verifiability is rapidly increasing yet underexplored. To fill these gaps, we present a principled formulation of problem-solving as a deterministic Markov decision process; a novel framework, FPS (Formal Problem-Solving), which utilizes existing FTP (formal theorem proving) environments to perform process-verified problem-solving; and D-FPS (Deductive FPS), decoupling solving and answer verification for better human-alignment. The expressiveness, soundness and completeness of the frameworks are proven. We construct three benchmarks on problem-solving: FormalMath500, a formalization of a subset of the MATH500 benchmark; MiniF2F-Solving and PutnamBench-Solving, adaptations of FTP benchmarks MiniF2F and PutnamBench. For faithful, interpretable, and human-aligned evaluation, we propose RPE (Restricted Propositional Equivalence), a symbolic approach to determine the correctness of answers by formal verification. We evaluate four prevalent FTP models and two prompting methods as baselines, solving at most 23.77% of FormalMath500, 27.47% of MiniF2F-Solving, and 0.31% of PutnamBench-Solving.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Logic in Computer Science (cs.LO)", "comments": "42 pages, 3 figures", "pdf_url": "https://arxiv.org/pdf/2505.04528.pdf", "abstract_url": "https://arxiv.org/abs/2505.04528", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Logic in Computer Science (cs.LO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种问题解决的原理性表述，作为确定性马尔可夫决策过程；一个新颖的框架FPS（正式问题解决），利用现有的FTP（正式定理证明）环境进行过程验证的问题解决；以及D-FPS（演绎FPS），解耦解决和答案验证以更好的人类对齐。", "motivation": "问题解决作为科学和工程的重要组成部分，其一般而具体的表述缺失，且随着基于AI的问题解决代理的发展，过程级可验证性的需求迅速增加但尚未充分探索。", "method": "提出了FPS框架和D-FPS方法，利用FTP环境进行过程验证的问题解决，并通过RPE（受限命题等价）进行答案正确性的形式验证。", "result": "在FormalMath500、MiniF2F-Solving和PutnamBench-Solving三个基准测试上评估了四种流行的FTP模型和两种提示方法，最高解决了23.77%的FormalMath500、27.47%的MiniF2F-Solving和0.31%的PutnamBench-Solving问题。", "conclusion": "本文提出的FPS框架和D-FPS方法为问题解决提供了形式化和过程验证的新途径，通过RPE实现了忠实、可解释和人类对齐的评估，为AI问题解决代理的发展提供了重要参考。"}}
{"id": "2505.03760", "title": "Deep Reinforcement Learning for Investor-Specific Portfolio Optimization: A Volatility-Guided Asset Selection Approach", "authors": ["Arishi Orra", "Aryan Bhambu", "Himanshu Choudhary", "Manoj Thakur", "Selvaraju Natarajan"], "abstract": "Portfolio optimization requires dynamic allocation of funds by balancing the risk and return tradeoff under dynamic market conditions. With the recent advancements in AI, Deep Reinforcement Learning (DRL) has gained prominence in providing adaptive and scalable strategies for portfolio optimization. However, the success of these strategies depends not only on their ability to adapt to market dynamics but also on the careful pre-selection of assets that influence overall portfolio performance. Incorporating the investor's preference in pre-selecting assets for a portfolio is essential in refining their investment strategies. This study proposes a volatility-guided DRL-based portfolio optimization framework that dynamically constructs portfolios based on investors' risk profiles. The Generalized Autoregressive Conditional Heteroscedasticity (GARCH) model is utilized for volatility forecasting of stocks and categorizes them based on their volatility as aggressive, moderate, and conservative. The DRL agent is then employed to learn an optimal investment policy by interacting with the historical market data. The efficacy of the proposed methodology is established using stocks from the Dow $30$ index. The proposed investor-specific DRL-based portfolios outperformed the baseline strategies by generating consistent risk-adjusted returns.", "subjects": "Portfolio Management (q-fin.PM); Artificial Intelligence (cs.AI); Optimization and Control (math.OC)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.03760.pdf", "abstract_url": "https://arxiv.org/abs/2505.03760", "categories": ["Portfolio Management (q-fin.PM)", "Artificial Intelligence (cs.AI)", "Optimization and Control (math.OC)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于深度强化学习（DRL）的投资者特定投资组合优化框架，该框架通过波动性指导的资产选择方法，动态构建符合投资者风险偏好的投资组合。", "motivation": "投资组合优化需要在动态市场条件下平衡风险与回报，而现有的AI策略虽能适应市场动态，但资产预选对投资组合表现至关重要。本研究旨在结合投资者偏好，通过波动性预选资产，优化投资策略。", "method": "研究采用广义自回归条件异方差（GARCH）模型对股票波动性进行预测，并根据波动性将股票分类为激进、中性和保守。随后，DRL代理通过与历史市场数据交互，学习最优投资策略。", "result": "通过在道琼斯30指数股票上的测试，提出的投资者特定DRL投资组合在生成一致的风险调整回报方面优于基线策略。", "conclusion": "研究表明，结合投资者风险偏好和波动性预选资产的DRL框架，能够有效提升投资组合的性能，为投资者提供更优的风险调整回报。"}}
{"id": "2505.03807", "title": "Facilitating Video Story Interaction with Multi-Agent Collaborative System", "authors": ["Yiwen Zhang", "Jianing Hao", "Zhan Wang", "Hongling Sheng", "Wei Zeng"], "abstract": "Video story interaction enables viewers to engage with and explore narrative content for personalized experiences. However, existing methods are limited to user selection, specially designed narratives, and lack customization. To address this, we propose an interactive system based on user intent. Our system uses a Vision Language Model (VLM) to enable machines to understand video stories, combining Retrieval-Augmented Generation (RAG) and a Multi-Agent System (MAS) to create evolving characters and scene experiences. It includes three stages: 1) Video story processing, utilizing VLM and prior knowledge to simulate human understanding of stories across three modalities. 2) Multi-space chat, creating growth-oriented characters through MAS interactions based on user queries and story stages. 3) Scene customization, expanding and visualizing various story scenes mentioned in dialogue. Applied to the Harry Potter series, our study shows the system effectively portrays emergent character social behavior and growth, enhancing the interactive experience in the video story world.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Multiagent Systems (cs.MA)", "comments": "Prepared and submitted in 2024", "pdf_url": "https://arxiv.org/pdf/2505.03807.pdf", "abstract_url": "https://arxiv.org/abs/2505.03807", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文提出了一种基于用户意图的视频故事交互系统，利用视觉语言模型（VLM）和检索增强生成（RAG）结合多代理系统（MAS），通过三个阶段处理视频故事、多空间聊天和场景定制，以增强视频故事世界的交互体验。", "motivation": "现有的视频故事交互方法仅限于用户选择和特别设计的叙事，缺乏定制化。为了解决这一问题，本文提出了一种基于用户意图的交互系统。", "method": "系统采用视觉语言模型（VLM）使机器理解视频故事，结合检索增强生成（RAG）和多代理系统（MAS），通过视频故事处理、多空间聊天和场景定制三个阶段实现。", "result": "应用于《哈利·波特》系列的研究表明，该系统有效描绘了角色社交行为和成长的涌现，增强了视频故事世界的交互体验。", "conclusion": "本文提出的系统通过结合VLM、RAG和MAS，成功实现了视频故事的深度交互和个性化体验，为视频故事交互提供了新的可能性。"}}
{"id": "2505.03792", "title": "Towards Efficient Online Tuning of VLM Agents via Counterfactual Soft Reinforcement Learning", "authors": ["Lang Feng", "Weihao Tan", "Zhiyi Lyu", "Longtao Zheng", "Haiyang Xu", "Ming Yan", "Fei Huang", "Bo An"], "abstract": "Online fine-tuning vision-language model (VLM) agents with reinforcement learning (RL) has shown promise for equipping agents with multi-step, goal-oriented capabilities in dynamic environments. However, their open-ended textual action space and non-end-to-end nature of action generation present significant challenges to effective online exploration in RL, e.g., explosion of the exploration space. We propose a novel online fine-tuning method, Counterfactual Soft Reinforcement Learning (CoSo), better suited to the textual output space of VLM agents. Compared to prior methods that assign uniform uncertainty to all tokens, CoSo leverages counterfactual reasoning to dynamically assess the causal influence of individual tokens on post-processed actions. By prioritizing the exploration of action-critical tokens while reducing the impact of semantically redundant or low-impact tokens, CoSo enables a more targeted and efficient online rollout process. We provide theoretical analysis proving CoSo's convergence and policy improvement guarantees, and extensive empirical evaluations supporting CoSo's effectiveness. Our results across a diverse set of agent tasks, including Android device control, card gaming, and embodied AI, highlight its remarkable ability to enhance exploration efficiency and deliver consistent performance gains. The code is available at", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "ICML 2025", "pdf_url": "https://arxiv.org/pdf/2505.03792.pdf", "abstract_url": "https://arxiv.org/abs/2505.03792", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为Counterfactual Soft Reinforcement Learning (CoSo)的新方法，用于在线微调视觉语言模型(VLM)代理，以解决在动态环境中实现多步、目标导向能力的挑战。CoSo通过反事实推理动态评估单个令牌对处理后动作的因果影响，优化探索过程。", "motivation": "在线微调视觉语言模型(VLM)代理在动态环境中实现多步、目标导向能力时，面临文本动作空间的开放性和动作生成的非端到端性质带来的探索效率低下问题。", "method": "提出Counterfactual Soft Reinforcement Learning (CoSo)方法，利用反事实推理动态评估单个令牌对动作的因果影响，优先探索对动作关键的令牌，减少语义冗余或低影响令牌的影响。", "result": "理论分析证明CoSo具有收敛性和策略改进保证，广泛的实证评估支持CoSo在提高探索效率和提供一致性能增益方面的有效性。", "conclusion": "CoSo方法在包括Android设备控制、卡牌游戏和具身AI在内的多种代理任务中，显示出显著提高探索效率和性能的能力。"}}
{"id": "2505.03795", "title": "Modeling Human Behavior in a Strategic Network Game with Complex Group Dynamics", "authors": ["Jacob W. Crandall", "Jonathan Skaggs"], "abstract": "Human networks greatly impact important societal outcomes, including wealth and health inequality, poverty, and bullying. As such, understanding human networks is critical to learning how to promote favorable societal outcomes. As a step toward better understanding human networks, we compare and contrast several methods for learning models of human behavior in a strategic network game called the Junior High Game (JHG). These modeling methods differ with respect to the assumptions they use to parameterize human behavior (behavior vs. community-aware behavior) and the statistical moments they model (mean vs. distribution). Results show that the highest-performing method models the population's distribution rather than the mean and assumes humans use community-aware behavior rather than behavior matching. When applied to small societies (6-11 individuals), this learned model, called hCAB, closely mirrors the population dynamics of human groups (with some differences). Additionally, a user study reveals that human participants were unable to distinguish hCAB agents from other humans, thus illustrating that individual hCAB behavior plausibly mirrors human behavior in this strategic network game.", "subjects": "Social and Information Networks (cs.SI); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.03795.pdf", "abstract_url": "https://arxiv.org/abs/2505.03795", "categories": ["Social and Information Networks (cs.SI)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过比较和对比几种建模方法，研究了在名为Junior High Game（JHG）的战略网络游戏中人类行为的学习模型，旨在更好地理解人类网络对社会结果的影响。研究发现，最高效的方法hCAB能够紧密反映人类群体的动态，并且在用户研究中，人类参与者无法区分hCAB代理与其他人类。", "motivation": "人类网络对社会结果（如财富和健康不平等、贫困和欺凌）有重大影响。为了更好地理解这些网络，研究比较了几种在战略网络游戏中建模人类行为的方法。", "method": "研究比较了几种建模方法，这些方法在参数化人类行为（行为与社区意识行为）和建模统计时刻（均值与分布）方面有所不同。", "result": "最高效的hCAB方法能够紧密反映小型社会（6-11人）中人类群体的动态，并且在用户研究中，人类参与者无法区分hCAB代理与其他人类。", "conclusion": "hCAB模型在战略网络游戏中能够紧密反映人类行为，这表明它在理解和预测人类网络动态方面具有潜在的应用价值。"}}
{"id": "2505.03864", "title": "From Glue-Code to Protocols: A Critical Analysis of A2A and MCP Integration for Scalable Agent Systems", "authors": ["Qiaomu Li", "Ying Xie"], "abstract": "Artificial intelligence is rapidly evolving towards multi-agent systems where numerous AI agents collaborate and interact with external tools. Two key open standards, Google's Agent to Agent (A2A) protocol for inter-agent communication and Anthropic's Model Context Protocol (MCP) for standardized tool access, promise to overcome the limitations of fragmented, custom integration approaches. While their potential synergy is significant, this paper argues that effectively integrating A2A and MCP presents unique, emergent challenges at their intersection, particularly concerning semantic interoperability between agent tasks and tool capabilities, the compounded security risks arising from combined discovery and execution, and the practical governance required for the envisioned \"Agent Economy\". This work provides a critical analysis, moving beyond a survey to evaluate the practical implications and inherent difficulties of combining these horizontal and vertical integration standards. We examine the benefits (e.g., specialization, scalability) while critically assessing their dependencies and trade-offs in an integrated context. We identify key challenges increased by the integration, including novel security vulnerabilities, privacy complexities, debugging difficulties across protocols, and the need for robust semantic negotiation mechanisms. In summary, A2A+MCP offers a vital architectural foundation, but fully realizing its potential requires substantial advancements to manage the complexities of their combined operation.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.03864.pdf", "abstract_url": "https://arxiv.org/abs/2505.03864", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文批判性分析了Google的A2A协议和Anthropic的MCP协议在可扩展多智能体系统中的集成，探讨了语义互操作性、安全风险和治理需求等挑战。", "motivation": "解决多智能体系统中A2A和MCP协议集成时出现的语义互操作性、安全风险和治理需求等新兴挑战。", "method": "通过批判性分析，评估A2A和MCP协议集成的实际影响和固有困难，包括安全漏洞、隐私复杂性等。", "result": "A2A和MCP集成为智能体系统提供了重要的架构基础，但实现其潜力需要解决集成带来的复杂问题。", "conclusion": "尽管A2A和MCP集成具有巨大潜力，但需在语义协商、安全性和治理等方面取得重大进展以应对集成复杂性。"}}
{"id": "2505.03817", "title": "Modeling Behavioral Preferences of Cyber Adversaries Using Inverse Reinforcement Learning", "authors": ["Aditya Shinde", "Prashant Doshi"], "abstract": "This paper presents a holistic approach to attacker preference modeling from system-level audit logs using inverse reinforcement learning (IRL). Adversary modeling is an important capability in cybersecurity that lets defenders characterize behaviors of potential attackers, which enables attribution to known cyber adversary groups. Existing approaches rely on documenting an ever-evolving set of attacker tools and techniques to track known threat actors. Although attacks evolve constantly, attacker behavioral preferences are intrinsic and less volatile. Our approach learns the behavioral preferences of cyber adversaries from forensics data on their tools and techniques. We model the attacker as an expert decision-making agent with unknown behavioral preferences situated in a computer host. We leverage attack provenance graphs of audit logs to derive a state-action trajectory of the attack. We test our approach on open datasets of audit logs containing real attack data. Our results demonstrate for the first time that low-level forensics data can automatically reveal an adversary's subjective preferences, which serves as an additional dimension to modeling and documenting cyber adversaries. Attackers' preferences tend to be invariant despite their different tools and indicate predispositions that are inherent to the attacker. As such, these inferred preferences can potentially serve as unique behavioral signatures of attackers and improve threat attribution.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.03817.pdf", "abstract_url": "https://arxiv.org/abs/2505.03817", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种使用逆强化学习（IRL）从系统级审计日志中建模攻击者行为偏好的整体方法。通过将攻击者建模为具有未知行为偏好的专家决策代理，并利用审计日志的攻击来源图推导攻击的状态-动作轨迹，该方法能够从低级取证数据中自动揭示攻击者的主观偏好，作为建模和记录网络对手的额外维度。", "motivation": "网络安全中的对手建模是一个重要能力，它使防御者能够描述潜在攻击者的行为，从而实现对已知网络对手群体的归因。现有的方法依赖于记录不断变化的攻击者工具和技术来跟踪已知的威胁行为者。尽管攻击不断演变，但攻击者的行为偏好是内在的且变化较小。", "method": "本文的方法利用逆强化学习（IRL）从攻击者的工具和技术的取证数据中学习其行为偏好。攻击者被建模为一个具有未知行为偏好的专家决策代理，位于计算机主机中。通过攻击来源图从审计日志中推导出攻击的状态-动作轨迹。", "result": "在包含真实攻击数据的开放审计日志数据集上的测试结果表明，低级取证数据可以自动揭示攻击者的主观偏好，这些偏好倾向于不变，尽管他们的工具不同，并且表明了攻击者固有的倾向。这些推断的偏好可以作为攻击者的独特行为签名，并改善威胁归因。", "conclusion": "本文首次证明了低级取证数据可以自动揭示对手的主观偏好，作为建模和记录网络对手的额外维度。攻击者的偏好尽管工具不同，但倾向于不变，表明了攻击者固有的倾向。因此，这些推断的偏好可以作为攻击者的独特行为签名，并改善威胁归因。"}}
{"id": "2505.04251", "title": "Facilitating Trustworthy Human-Agent Collaboration in LLM-based Multi-Agent System oriented Software Engineering", "authors": ["Krishna Ronanki"], "abstract": "Multi-agent autonomous systems (MAS) are better at addressing challenges that spans across multiple domains than singular autonomous agents. This holds true within the field of software engineering (SE) as well. The state-of-the-art research on MAS within SE focuses on integrating LLMs at the core of autonomous agents to create LLM-based multi-agent autonomous (LMA) systems. However, the introduction of LMA systems into SE brings a plethora of challenges. One of the major challenges is the strategic allocation of tasks between humans and the LMA system in a trustworthy manner. To address this challenge, a RACI-based framework is proposed in this work in progress article, along with implementation guidelines and an example implementation of the framework. The proposed framework can facilitate efficient collaboration, ensure accountability, and mitigate potential risks associated with LLM-driven automation while aligning with the Trustworthy AI guidelines. The future steps for this work delineating the planned empirical validation method are also presented.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.04251.pdf", "abstract_url": "https://arxiv.org/abs/2505.04251", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于RACI的框架，旨在促进人类与基于LLM的多Agent自主系统（LMA）在软件工程领域中的可信协作。该框架旨在高效分配任务、确保责任明确，并降低LLM驱动自动化带来的风险，同时符合可信AI指南。", "motivation": "解决在软件工程中引入基于LLM的多Agent自主系统时，人类与LMA系统之间任务分配的可信协作问题。", "method": "提出了一种基于RACI的框架，包括实施指南和框架的示例实现。", "result": "提出的框架能够促进高效协作，确保责任明确，并降低LLM驱动自动化带来的潜在风险。", "conclusion": "该框架为人类与LMA系统在软件工程中的可信协作提供了一种有效方法，未来工作将包括计划的实证验证方法。"}}
{"id": "2505.04354", "title": "Optimization Problem Solving Can Transition to Evolutionary Agentic Workflows", "authors": ["Wenhao Li", "Bo Jin", "Mingyi Hong", "Changhong Lu", "Xiangfeng Wang"], "abstract": "This position paper argues that optimization problem solving can transition from expert-dependent to evolutionary agentic workflows. Traditional optimization practices rely on human specialists for problem formulation, algorithm selection, and hyperparameter tuning, creating bottlenecks that impede industrial adoption of cutting-edge methods. We contend that an evolutionary agentic workflow, powered by foundation models and evolutionary search, can autonomously navigate the optimization space, comprising problem, formulation, algorithm, and hyperparameter spaces. Through case studies in cloud resource scheduling and ADMM parameter adaptation, we demonstrate how this approach can bridge the gap between academic innovation and industrial implementation. Our position challenges the status quo of human-centric optimization workflows and advocates for a more scalable, adaptive approach to solving real-world optimization problems.", "subjects": "Optimization and Control (math.OC); Artificial Intelligence (cs.AI)", "comments": "27 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2505.04354.pdf", "abstract_url": "https://arxiv.org/abs/2505.04354", "categories": ["Optimization and Control (math.OC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文主张优化问题解决可以从依赖专家转变为进化代理工作流程。传统的优化实践依赖于人类专家进行问题表述、算法选择和超参数调整，这造成了瓶颈，阻碍了工业界采用尖端方法。我们提出，由基础模型和进化搜索驱动的进化代理工作流程可以自主导航优化空间，包括问题、表述、算法和超参数空间。通过云资源调度和ADMM参数适应的案例研究，我们展示了这种方法如何弥合学术创新与工业实施之间的差距。我们的立场挑战了以人为中心的优化工作流程的现状，并倡导采用更可扩展、适应性更强的方法来解决现实世界的优化问题。", "motivation": "解决传统优化实践中依赖人类专家造成的瓶颈问题，推动尖端优化方法在工业界的应用。", "method": "提出由基础模型和进化搜索驱动的进化代理工作流程，自主导航优化空间。", "result": "通过云资源调度和ADMM参数适应的案例研究，证明了该方法能够有效弥合学术创新与工业实施之间的差距。", "conclusion": "挑战了以人为中心的优化工作流程的现状，倡导采用更可扩展、适应性更强的方法来解决现实世界的优化问题。"}}
{"id": "2505.04379", "title": "Consensus-Aware AV Behavior: Trade-offs Between Safety, Interaction, and Performance in Mixed Urban Traffic", "authors": ["Mohammad Elayan", "Wissam Kontar"], "abstract": "Transportation systems have long been shaped by complexity and heterogeneity, driven by the interdependency of agent actions and traffic outcomes. The deployment of automated vehicles (AVs) in such systems introduces a new challenge: achieving consensus across safety, interaction quality, and traffic performance. In this work, we position consensus as a fundamental property of the traffic system and aim to quantify it. We use high-resolution trajectory data from the Third Generation Simulation (TGSIM) dataset to empirically analyze AV and human-driven vehicle (HDV) behavior at a signalized urban intersection and around vulnerable road users (VRUs). Key metrics, including Time-to-Collision (TTC), Post-Encroachment Time (PET), deceleration patterns, headways, and string stability, are evaluated across the three performance dimensions. Results show that full consensus across safety, interaction, and performance is rare, with only 1.63% of AV-VRU interaction frames meeting all three conditions. These findings highlight the need for AV models that explicitly balance multi-dimensional performance in mixed-traffic environments. Full reproducibility is supported via our open-source codebase on", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Systems and Control (eess.SY)", "comments": "7 pages, 8 figures", "pdf_url": "https://arxiv.org/pdf/2505.04379.pdf", "abstract_url": "https://arxiv.org/abs/2505.04379", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Systems and Control (eess.SY)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了在混合城市交通中自动车辆（AVs）行为的安全、交互和性能之间的权衡，提出共识作为交通系统的基本属性，并通过高分辨率轨迹数据实证分析了AV与人类驾驶车辆（HDVs）在信号化城市交叉口及易受伤害道路使用者（VRUs）周围的行为。", "motivation": "解决自动车辆在复杂和异质的交通系统中如何实现安全、交互质量和交通性能之间的共识问题。", "method": "使用第三代模拟（TGSIM）数据集的高分辨率轨迹数据，评估包括碰撞时间（TTC）、侵占后时间（PET）、减速模式、车头时距和串稳定性等关键指标。", "result": "结果显示，安全、交互和性能三者之间的完全共识罕见，仅1.63%的AV-VRU交互帧满足所有三个条件。", "conclusion": "强调了需要开发能够明确平衡混合交通环境中多维性能的AV模型，并支持通过开源代码库实现完全可重复性。"}}
