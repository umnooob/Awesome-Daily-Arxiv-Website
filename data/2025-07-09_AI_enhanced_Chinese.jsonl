{"id": "2507.05297", "title": "Fuzzy Classification Aggregation for a Continuum of Agents", "authors": ["Zijun Meng"], "abstract": "We prove that any optimal, independent, and zero unanimous fuzzy classification aggregation function of a continuum of individual classifications of $m\\ge 3$ objects into $2\\le p\\le m$ types must be a weighted arithmetic mean.", "subjects": "Artificial Intelligence (cs.AI); Theoretical Economics (econ.TH)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.05297.pdf", "abstract_url": "https://arxiv.org/abs/2507.05297", "categories": ["Artificial Intelligence (cs.AI)", "Theoretical Economics (econ.TH)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文证明了对于将m≥3个对象分类为2≤p≤m种类型的连续个体分类，任何最优、独立且零一致的模糊分类聚合函数必须是加权算术平均。", "motivation": "解决在连续个体分类中，如何最优、独立且零一致地聚合模糊分类的问题。", "method": "通过数学证明，分析模糊分类聚合函数的性质。", "result": "关键发现是，满足特定条件的最优模糊分类聚合函数必须是加权算术平均。", "conclusion": "结论表明，在连续个体分类的特定条件下，加权算术平均是唯一满足最优、独立和零一致性的聚合方法。"}}
{"id": "2507.05495", "title": "Deep Research Comparator: A Platform For Fine-grained Human Annotations of Deep Research Agents", "authors": ["Prahaladh Chandrahasan", "Jiahe Jin", "Zhihan Zhang", "Tevin Wang", "Andy Tang", "Lucy Mo", "Morteza Ziyadi", "Leonardo F.R. Ribeiro", "Zimeng Qiu", "Markus Dreyer", "Akari Asai", "Chenyan Xiong"], "abstract": "Effectively evaluating deep research agents that autonomously search the web, analyze information, and generate reports remains a major challenge, particularly when it comes to assessing long reports and giving detailed feedback on their intermediate steps. To address these gaps, we introduce Deep Research Comparator, a platform that offers a holistic framework for deep research agent hosting, side-by-side comparison, fine-grained human feedback collection, and ranking calculation. Given a user query, our platform displays the final reports from two different agents along with their intermediate steps during generation. Annotators can evaluate the overall quality of final reports based on side-by-side comparison, and also provide detailed feedback separately by assessing intermediate steps or specific text spans within the final report. Furthermore, we develop Simple Deepresearch, an end-to-end agent scaffold. This scaffold serves as a baseline that facilitates the easy integration of various large language models to transform them into deep research agents for evaluation. To demonstrate the platform's utility for deep research agent development, we have collected real user preference data from 17 annotators on three deep research agents. A demo video of our platform can be found at", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.05495.pdf", "abstract_url": "https://arxiv.org/abs/2507.05495", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了Deep Research Comparator平台，旨在解决深度研究代理的评估挑战，通过提供细粒度的人类注释和比较功能来改进代理的报告生成能力。", "motivation": "评估自主搜索网络、分析信息并生成报告的深度研究代理的有效性是一个主要挑战，尤其是在评估长篇报告和对其中间步骤提供详细反馈方面。", "method": "引入Deep Research Comparator平台，提供一个全面的框架，用于深度研究代理的托管、并排比较、细粒度人类反馈收集和排名计算。同时开发了Simple Deepresearch，一个端到端的代理支架，便于将各种大型语言模型集成到深度研究代理中进行评估。", "result": "通过17位注释者对三个深度研究代理的真实用户偏好数据收集，展示了平台在深度研究代理开发中的实用性。", "conclusion": "Deep Research Comparator平台为深度研究代理的评估和开发提供了一个有效的工具，通过细粒度的人类注释和比较，有助于改进代理的报告生成能力和中间步骤的反馈。"}}
{"id": "2507.05520", "title": "Cultivating Multimodal Intelligence: Interpretive Reasoning and Agentic RAG Approaches to Dermatological Diagnosis", "authors": ["Karishma Thakrar", "Shreyas Basavatia", "Akshay Daftardar"], "abstract": "The second edition of the 2025 ImageCLEF MEDIQA-MAGIC challenge, co-organized by researchers from Microsoft, Stanford University, and the Hospital Clinic of Barcelona, focuses on multimodal dermatology question answering and segmentation, using real-world patient queries and images. This work addresses the Closed Visual Question Answering (CVQA) task, where the goal is to select the correct answer to multiple-choice clinical questions based on both user-submitted images and accompanying symptom descriptions. The proposed approach combines three core components: (1) fine-tuning open-source multimodal models from the Qwen, Gemma, and LLaMA families on the competition dataset, (2) introducing a structured reasoning layer that reconciles and adjudicates between candidate model outputs, and (3) incorporating agentic retrieval-augmented generation (agentic RAG), which adds relevant information from the American Academy of Dermatology's symptom and condition database to fill in gaps in patient context. The team achieved second place with a submission that scored sixth, demonstrating competitive performance and high accuracy. Beyond competitive benchmarks, this research addresses a practical challenge in telemedicine: diagnostic decisions must often be made asynchronously, with limited input and with high accuracy and interpretability. By emulating the systematic reasoning patterns employed by dermatologists when evaluating skin conditions, this architecture provided a pathway toward more reliable automated diagnostic support systems.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "2025 ImageCLEF MEDIQA-MAGIC Challenge", "pdf_url": "https://arxiv.org/pdf/2507.05520.pdf", "abstract_url": "https://arxiv.org/abs/2507.05520", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic", "@RAG"], "AI": {"tldr": "2025年ImageCLEF MEDIQA-MAGIC挑战赛的第二版，由微软、斯坦福大学和巴塞罗那医院诊所的研究人员共同组织，专注于使用真实世界患者查询和图像的多模态皮肤病问答和分割。这项工作解决了封闭视觉问答（CVQA）任务，目标是根据用户提交的图像和伴随的症状描述选择正确的临床问题答案。提出的方法结合了三个核心组件：在竞赛数据集上微调开源多模态模型、引入结构化推理层以协调和裁决候选模型输出，以及结合代理检索增强生成（agentic RAG）以填补患者背景中的信息空白。团队以第六名的成绩获得第二名，展示了竞争性能和高准确性。", "motivation": "解决远程医疗中的一个实际挑战：诊断决策通常需要异步进行，输入有限，同时要求高准确性和可解释性。", "method": "结合微调开源多模态模型、结构化推理层和代理检索增强生成（agentic RAG）的方法。", "result": "团队在竞赛中获得第二名，展示了竞争性能和高准确性。", "conclusion": "通过模拟皮肤科医生评估皮肤状况时的系统推理模式，该架构为更可靠的自动化诊断支持系统提供了途径。"}}
{"id": "2507.05528", "title": "Conversational Education at Scale: A Multi-LLM Agent Workflow for Procedural Learning and Pedagogic Quality Assessment", "authors": ["Jiahuan Pei", "Fanghua Ye", "Xin Sun", "Wentao Deng", "Koen Hindriks", "Junxiao Wang"], "abstract": "Large language models (LLMs) have advanced virtual educators and learners, bridging NLP with AI4Education. Existing work often lacks scalability and fails to leverage diverse, large-scale course content, with limited frameworks for assessing pedagogic quality. To this end, we propose WikiHowAgent, a multi-agent workflow leveraging LLMs to simulate interactive teaching-learning conversations. It integrates teacher and learner agents, an interaction manager, and an evaluator to facilitate procedural learning and assess pedagogic quality. We introduce a dataset of 114,296 teacher-learner conversations grounded in 14,287 tutorials across 17 domains and 727 topics. Our evaluation protocol combines computational and rubric-based metrics with human judgment alignment. Results demonstrate the workflow's effectiveness in diverse setups, offering insights into LLM capabilities across domains. Our datasets and implementations are fully open-sourced.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "14 pages", "pdf_url": "https://arxiv.org/pdf/2507.05528.pdf", "abstract_url": "https://arxiv.org/abs/2507.05528", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了WikiHowAgent，一个利用大型语言模型（LLMs）模拟互动教学对话的多代理工作流程，旨在解决现有虚拟教育工具在可扩展性和教学评估方面的不足。", "motivation": "现有的虚拟教育工具往往缺乏可扩展性，未能充分利用多样化、大规模的课程内容，且缺乏评估教学质量的框架。", "method": "提出了一个多代理工作流程，包括教师和学习者代理、互动管理器和评估器，以促进程序性学习并评估教学质量。引入了一个包含114,296个教师-学习者对话的数据集，这些对话基于17个领域和727个主题的14,287个教程。", "result": "评估结果表明，该工作流程在多样化设置中有效，提供了关于LLM跨领域能力的见解。", "conclusion": "WikiHowAgent及其开放源代码的数据集和实现，为利用LLMs进行大规模对话式教育提供了有效的解决方案，同时也为教学质量的评估提供了新的框架。"}}
{"id": "2507.05755", "title": "An autonomous agent for auditing and improving the reliability of clinical AI models", "authors": ["Lukas Kuhn", "Florian Buettner"], "abstract": "The deployment of AI models in clinical practice faces a critical challenge: models achieving expert-level performance on benchmarks can fail catastrophically when confronted with real-world variations in medical imaging. Minor shifts in scanner hardware, lighting or demographics can erode accuracy, but currently reliability auditing to identify such catastrophic failure cases before deployment is a bespoke and time-consuming process. Practitioners lack accessible and interpretable tools to expose and repair hidden failure modes. Here we introduce ModelAuditor, a self-reflective agent that converses with users, selects task-specific metrics, and simulates context-dependent, clinically relevant distribution shifts. ModelAuditor then generates interpretable reports explaining how much performance likely degrades during deployment, discussing specific likely failure modes and identifying root causes and mitigation strategies. Our comprehensive evaluation across three real-world clinical scenarios - inter-institutional variation in histopathology, demographic shifts in dermatology, and equipment heterogeneity in chest radiography - demonstrates that ModelAuditor is able correctly identify context-specific failure modes of state-of-the-art models such as the established SIIM-ISIC melanoma classifier. Its targeted recommendations recover 15-25% of performance lost under real-world distribution shift, substantially outperforming both baseline models and state-of-the-art augmentation methods. These improvements are achieved through a multi-agent architecture and execute on consumer hardware in under 10 minutes, costing less than US$0.50 per audit.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.05755.pdf", "abstract_url": "https://arxiv.org/abs/2507.05755", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文介绍了ModelAuditor，一个自主代理，用于审计和提高临床AI模型的可靠性。它通过模拟临床相关的分布变化，生成可解释的报告，帮助识别和修复潜在的失败模式。", "motivation": "临床实践中部署的AI模型在面对现实世界中的变化时可能会失败，但目前缺乏有效和可解释的工具来识别和修复这些隐藏的失败模式。", "method": "引入ModelAuditor，一个自我反思的代理，与用户对话，选择任务特定的指标，模拟上下文依赖的、临床相关的分布变化，并生成解释性能可能下降的报告。", "result": "在三个真实世界的临床场景中，ModelAuditor能够正确识别最先进模型的特定上下文失败模式，其针对性建议恢复了15-25%的性能损失。", "conclusion": "ModelAuditor通过多代理架构在消费者硬件上以低成本快速执行审计，显著提高了临床AI模型的可靠性。"}}
{"id": "2507.05638", "title": "LLMs are Introvert", "authors": ["Litian Zhang", "Xiaoming Zhang", "Bingyu Yan", "Ziyi Zhou", "Bo Zhang", "Zhenyu Guan", "Xi Zhang", "Chaozhuo Li"], "abstract": "The exponential growth of social media and generative AI has transformed information dissemination, fostering connectivity but also accelerating the spread of misinformation. Understanding information propagation dynamics and developing effective control strategies is essential to mitigate harmful content. Traditional models, such as SIR, provide basic insights but inadequately capture the complexities of online interactions. Advanced methods, including attention mechanisms and graph neural networks, enhance accuracy but typically overlook user psychology and behavioral dynamics. Large language models (LLMs), with their human-like reasoning, offer new potential for simulating psychological aspects of information spread. We introduce an LLM-based simulation environment capturing agents' evolving attitudes, emotions, and responses. Initial experiments, however, revealed significant gaps between LLM-generated behaviors and authentic human dynamics, especially in stance detection and psychological realism. A detailed evaluation through Social Information Processing Theory identified major discrepancies in goal-setting and feedback evaluation, stemming from the lack of emotional processing in standard LLM training. To address these issues, we propose the Social Information Processing-based Chain of Thought (SIP-CoT) mechanism enhanced by emotion-guided memory. This method improves the interpretation of social cues, personalization of goals, and evaluation of feedback. Experimental results confirm that SIP-CoT-enhanced LLM agents more effectively process social information, demonstrating behaviors, attitudes, and emotions closer to real human interactions. In summary, this research highlights critical limitations in current LLM-based propagation simulations and demonstrates how integrating SIP-CoT and emotional memory significantly enhances the social intelligence and realism of LLM agents.", "subjects": "Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.05638.pdf", "abstract_url": "https://arxiv.org/abs/2507.05638", "categories": ["Artificial Intelligence (cs.AI)", "Social and Information Networks (cs.SI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了大型语言模型（LLMs）在模拟信息传播中的局限性，特别是其在捕捉用户心理和行为动态方面的不足，并提出了一种基于社会信息处理理论和情感引导记忆的改进方法SIP-CoT，以增强LLM代理的社会智能和真实性。", "motivation": "随着社交媒体和生成式AI的快速发展，信息传播的速度加快，但同时也加剧了错误信息的扩散。传统模型和现有高级方法在模拟在线互动复杂性时，往往忽视了用户心理学和行为动态。LLMs因其类似人类的推理能力，为模拟信息传播的心理方面提供了新的可能性，但初步实验显示其在行为生成和心理真实性方面存在显著差距。", "method": "作者提出了基于社会信息处理理论的思维链（SIP-CoT）机制，并通过情感引导的记忆增强这一方法，以改进对社交线索的解释、目标的个性化以及反馈的评估。", "result": "实验结果表明，经过SIP-CoT增强的LLM代理能更有效地处理社会信息，其行为、态度和情感更接近真实的人类互动。", "conclusion": "本研究揭示了当前基于LLM的传播模拟的关键局限性，并展示了通过整合SIP-CoT和情感记忆如何显著提升LLM代理的社会智能和真实性。"}}
{"id": "2507.05791", "title": "GTA1: GUI Test-time Scaling Agent", "authors": ["Yan Yang", "Dongxu Li", "Yutong Dai", "Yuhao Yang", "Ziyang Luo", "Zirui Zhao", "Zhiyuan Hu", "Junzhe Huang", "Amrita Saha", "Zeyuan Chen", "Ran Xu", "Liyuan Pan", "Caiming Xiong", "Junnan Li"], "abstract": "Graphical user interface (GUI) agents autonomously operate across platforms (e.g., Linux) to complete tasks by interacting with visual elements. Specifically, a user instruction is decomposed into a sequence of action proposals, each corresponding to an interaction with the GUI. After each action, the agent observes the updated GUI environment to plan the next step. However, two main challenges arise: i) resolving ambiguity in task planning (i.e., the action proposal sequence), where selecting an appropriate plan is non-trivial, as many valid ones may exist; ii) accurately grounding actions in complex and high-resolution interfaces, i.e., precisely interacting with visual targets.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.05791.pdf", "abstract_url": "https://arxiv.org/abs/2507.05791", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一种名为GTA1的图形用户界面(GUI)测试时缩放代理，旨在自主操作跨平台（如Linux）完成任务，通过交互视觉元素实现。用户指令被分解为一系列动作提案，每个对应于与GUI的交互。代理在每次动作后观察更新的GUI环境以规划下一步。", "motivation": "解决GUI代理在任务规划和动作定位中的两个主要挑战：i)在任务规划中解决模糊性（即动作提案序列），其中选择合适的计划非易事，因为可能存在许多有效的计划；ii)在复杂和高分辨率的界面中准确接地动作，即精确与视觉目标交互。", "method": "主要方法包括将用户指令分解为动作序列，并在每次交互后观察GUI环境的变化以规划后续步骤，旨在解决任务规划的模糊性和动作的精确定位问题。", "result": "关键发现或结果未在摘要中明确提及，但研究旨在通过提出的方法克服GUI代理在任务规划和动作定位中的挑战。", "conclusion": "主要结论和意义在于提出了一种新的GUI代理方法，旨在通过解决任务规划的模糊性和提高动作的精确定位来改善GUI代理的性能和效率。"}}
{"id": "2507.05868", "title": "CogniPlay: a work-in-progress Human-like model for General Game Playing", "authors": ["Aloïs Rautureau", "Éric Piette"], "abstract": "While AI systems have equaled or surpassed human performance in a wide variety of games such as Chess, Go, or Dota 2, describing these systems as truly \"human-like\" remains far-fetched. Despite their success, they fail to replicate the pattern-based, intuitive decision-making processes observed in human cognition. This paper presents an overview of findings from cognitive psychology and previous efforts to model human-like behavior in artificial agents, discusses their applicability to General Game Playing (GGP) and introduces our work-in-progress model based on these observations: CogniPlay.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "5 pages, 1 figure", "pdf_url": "https://arxiv.org/pdf/2507.05868.pdf", "abstract_url": "https://arxiv.org/abs/2507.05868", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了CogniPlay，一个正在进行中的、旨在模拟人类认知过程的通用游戏玩法模型。尽管AI在多种游戏中已达到或超越人类水平，但这些系统仍未能真正模拟人类基于模式的直觉决策过程。", "motivation": "解决现有AI系统在模拟人类直觉和模式识别决策过程中的不足，尤其是在通用游戏玩法（GGP）中的应用。", "method": "结合认知心理学的研究成果和先前模拟人类行为的人工智能代理的努力，提出了一个基于这些观察的工作进展模型：CogniPlay。", "result": "提出了一个旨在更接近人类认知过程的AI模型，该模型在通用游戏玩法中展现出潜力。", "conclusion": "CogniPlay模型代表了向更人类化的AI决策过程迈进的一步，为未来的研究和应用提供了新的方向。"}}
{"id": "2507.06042", "title": "On Lockean beliefs that are deductively closed and minimal change", "authors": ["Tommaso Flaminio", "Lluis Godo", "Ramón Pino Pérez", "Lluis Subirana"], "abstract": "Within the formal setting of the Lockean thesis, an agent belief set is defined in terms of degrees of confidence and these are described in probabilistic terms. This approach is of established interest, notwithstanding some limitations that make its use troublesome in some contexts, like, for instance, in belief change theory. Precisely, Lockean belief sets are not generally closed under (classical) logical deduction. The aim of the present paper is twofold: on one side we provide two characterizations of those belief sets that are closed under classical logic deduction, and on the other we propose an approach to probabilistic update that allows us for a minimal revision of those beliefs, i.e., a revision obtained by making the fewest possible changes to the existing belief set while still accommodating the new information. In particular, we show how we can deductively close a belief set via a minimal revision.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "18 pages, to appear in the proceedings of JELIA 2025", "pdf_url": "https://arxiv.org/pdf/2507.06042.pdf", "abstract_url": "https://arxiv.org/abs/2507.06042", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "在Lockean论文的形式化设置中，代理信念集通过置信度定义，并以概率术语描述。本文旨在双重目标：一是提供对经典逻辑演绎封闭的信念集的两个特征描述，二是提出一种概率更新方法，以实现对这些信念的最小修订。", "motivation": "解决Lockean信念集在经典逻辑演绎下不封闭的问题，以及在信念变化理论中应用的限制。", "method": "提供对经典逻辑演绎封闭的信念集的特征描述，并提出一种概率更新方法以实现最小修订。", "result": "展示了如何通过最小修订使信念集在演绎上封闭。", "conclusion": "本文不仅为Lockean信念集的演绎封闭性提供了理论支持，还提出了一种实用的最小修订方法，为信念变化理论的应用开辟了新途径。"}}
{"id": "2507.06221", "title": "Aligned Textual Scoring Rules", "authors": ["Yuxuan Lu", "Yifan Wu", "Jason Hartline", "Michael J. Curry"], "abstract": "Scoring rules elicit probabilistic predictions from a strategic agent by scoring the prediction against a ground truth state. A scoring rule is proper if, from the agent's perspective, reporting the true belief maximizes the expected score. With the development of language models, Wu and Hartline (2024) proposes a reduction from textual information elicitation to the numerical (i.e. probabilistic) information elicitation problem, which achieves provable properness for textual elicitation. However, not all proper scoring rules are well aligned with human preference over text. Our paper designs the Aligned Scoring rule (ASR) for text by optimizing and minimizing the mean squared error between a proper scoring rule and a reference score (e.g. human score). Our experiments show that our ASR outperforms previous methods in aligning with human preference while maintaining properness.", "subjects": "Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.06221.pdf", "abstract_url": "https://arxiv.org/abs/2507.06221", "categories": ["Artificial Intelligence (cs.AI)", "Computer Science and Game Theory (cs.GT)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文设计了Aligned Scoring rule (ASR)，通过优化和最小化适当评分规则与参考分数（如人类评分）之间的均方误差，用于文本评分。实验表明，ASR在保持适当性的同时，与人类偏好的对齐性优于先前的方法。", "motivation": "随着语言模型的发展，虽然Wu和Hartline（2024）提出了一种从文本信息引导到数值（即概率）信息引导问题的减少方法，实现了文本引导的可证明适当性，但并非所有适当的评分规则都与人类对文本的偏好良好对齐。", "method": "本文通过优化和最小化适当评分规则与参考分数（如人类评分）之间的均方误差，设计了Aligned Scoring rule (ASR)。", "result": "实验结果表明，ASR在保持适当性的同时，与人类偏好的对齐性优于先前的方法。", "conclusion": "ASR不仅在文本评分中保持了适当性，而且在对齐人类偏好方面表现出色，为文本信息引导提供了一种更有效的方法。"}}
{"id": "2507.06134", "title": "OpenAgentSafety: A Comprehensive Framework for Evaluating Real-World AI Agent Safety", "authors": ["Sanidhya Vijayvargiya", "Aditya Bharat Soni", "Xuhui Zhou", "Zora Zhiruo Wang", "Nouha Dziri", "Graham Neubig", "Maarten Sap"], "abstract": "Recent advances in AI agents capable of solving complex, everyday tasks, from scheduling to customer service, have enabled deployment in real-world settings, but their possibilities for unsafe behavior demands rigorous evaluation. While prior benchmarks have attempted to assess agent safety, most fall short by relying on simulated environments, narrow task domains, or unrealistic tool abstractions. We introduce OpenAgentSafety, a comprehensive and modular framework for evaluating agent behavior across eight critical risk categories. Unlike prior work, our framework evaluates agents that interact with real tools, including web browsers, code execution environments, file systems, bash shells, and messaging platforms; and supports over 350 multi-turn, multi-user tasks spanning both benign and adversarial user intents. OpenAgentSafety is designed for extensibility, allowing researchers to add tools, tasks, websites, and adversarial strategies with minimal effort. It combines rule-based analysis with LLM-as-judge assessments to detect both overt and subtle unsafe behaviors. Empirical analysis of five prominent LLMs in agentic scenarios reveals unsafe behavior in 51.2% of safety-vulnerable tasks with Claude-Sonnet-3.7, to 72.7% with o3-mini, highlighting critical safety vulnerabilities and the need for stronger safeguards before real-world deployment.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "19 pages, 10 figures", "pdf_url": "https://arxiv.org/pdf/2507.06134.pdf", "abstract_url": "https://arxiv.org/abs/2507.06134", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "OpenAgentSafety是一个全面的模块化框架，用于评估AI代理在八种关键风险类别中的行为，特别是在与真实工具交互时的安全性。", "motivation": "随着AI代理在解决复杂日常任务中的应用越来越广泛，其在现实世界中的不安全行为可能性需要严格的评估。现有的评估基准大多依赖于模拟环境、狭窄的任务领域或不真实的工具抽象，无法全面评估代理的安全性。", "method": "OpenAgentSafety框架评估代理与真实工具（如网络浏览器、代码执行环境、文件系统、bash shell和消息平台）的交互行为，支持超过350个多轮、多用户任务，涵盖良性和对抗性用户意图。该框架结合了基于规则的分析和LLM-as-judge评估，以检测明显和微妙的不安全行为。", "result": "对五种主要LLM在代理场景中的实证分析显示，在安全易受攻击的任务中，不安全行为的发生率从Claude-Sonnet-3.7的51.2%到o3-mini的72.7%，揭示了关键的安全漏洞。", "conclusion": "OpenAgentSafety框架的引入强调了在现实世界部署前需要更强的安全保障，以应对AI代理可能带来的安全风险。"}}
{"id": "2507.05275", "title": "A Fuzzy Supervisor Agent Design for Clinical Reasoning Assistance in a Multi-Agent Educational Clinical Scenario Simulation", "authors": ["Weibing Zheng", "Laurah Turner", "Jess Kropczynski", "Murat Ozer", "Seth Overla", "Shane Halse"], "abstract": "Assisting medical students with clinical reasoning (CR) during clinical scenario training remains a persistent challenge in medical education. This paper presents the design and architecture of the Fuzzy Supervisor Agent (FSA), a novel component for the Multi-Agent Educational Clinical Scenario Simulation (MAECSS) platform. The FSA leverages a Fuzzy Inference System (FIS) to continuously interpret student interactions with specialized clinical agents (e.g., patient, physical exam, diagnostic, intervention) using pre-defined fuzzy rule bases for professionalism, medical relevance, ethical behavior, and contextual distraction. By analyzing student decision-making processes in real-time, the FSA is designed to deliver adaptive, context-aware feedback and provides assistance precisely when students encounter difficulties. This work focuses on the technical framework and rationale of the FSA, highlighting its potential to provide scalable, flexible, and human-like supervision in simulation-based medical education. Future work will include empirical evaluation and integration into broader educational settings. More detailed design and implementation is~\\href{", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Logic in Computer Science (cs.LO); Multiagent Systems (cs.MA)", "comments": "6 pages, 3 figures, 1 table. 2025 IFSA World Congress NAFIPS Annual Meeting", "pdf_url": "https://arxiv.org/pdf/2507.05275.pdf", "abstract_url": "https://arxiv.org/abs/2507.05275", "categories": ["Computers and Society (cs.CY)", "Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)", "Logic in Computer Science (cs.LO)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了模糊监督代理（FSA）的设计和架构，这是多代理教育临床场景模拟（MAECSS）平台的一个新组件，旨在通过模糊推理系统（FIS）实时解释学生与专业临床代理的互动，提供自适应、上下文感知的反馈，以辅助医学生在临床场景训练中的临床推理。", "motivation": "解决医学生在临床场景训练中临床推理（CR）辅助的持续挑战。", "method": "设计并实现了一个模糊监督代理（FSA），利用模糊推理系统（FIS）和预定义的模糊规则库来实时分析学生的决策过程。", "result": "FSA能够提供自适应、上下文感知的反馈，并在学生遇到困难时提供精确的辅助。", "conclusion": "FSA展示了在模拟医学教育中提供可扩展、灵活和类似人类监督的潜力，未来工作将包括实证评估和更广泛的教育环境集成。"}}
{"id": "2507.05285", "title": "Beyond classical and contemporary models: a transformative ai framework for student dropout prediction in distance learning using rag, prompt engineering, and cross-modal fusion", "authors": ["Miloud Mihoubi", "Meriem Zerkouk", "Belkacem Chikhaoui"], "abstract": "Student dropout in distance learning remains a critical challenge, with profound societal and economic consequences. While classical machine learning models leverage structured socio-demographic and behavioral data, they often fail to capture the nuanced emotional and contextual factors embedded in unstructured student interactions. This paper introduces a transformative AI framework that redefines dropout prediction through three synergistic innovations: Retrieval-Augmented Generation (RAG) for domain-specific sentiment analysis, prompt engineering to decode academic stressors, and cross-modal attention fusion to dynamically align textual, behavioral, and socio-demographic insights. By grounding sentiment analysis in a curated knowledge base of pedagogical content, our RAG-enhanced BERT model interprets student comments with unprecedented contextual relevance, while optimized prompts isolate indicators of academic distress (e.g., \"isolation,\" \"workload anxiety\"). A cross-modal attention layer then fuses these insights with temporal engagement patterns, creating holistic risk profiles. Evaluated on a longitudinal dataset of 4 423 students, the framework achieves 89% accuracy and an F1-score of 0.88, outperforming conventional models by 7% and reducing false negatives by 21%. Beyond prediction, the system generates interpretable interventions by retrieving contextually aligned strategies (e.g., mentorship programs for isolated learners). This work bridges the gap between predictive analytics and actionable pedagogy, offering a scalable solution to mitigate dropout risks in global education systems", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Information Retrieval (cs.IR)", "comments": "10 pages, 5 figures, 5 tables. Submitted to the 38th Canadian Conference on Artificial Intelligence (Canadian AI 2025)", "pdf_url": "https://arxiv.org/pdf/2507.05285.pdf", "abstract_url": "https://arxiv.org/abs/2507.05285", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了一种创新的AI框架，用于远程教育中学生辍学预测，结合了RAG、提示工程和跨模态融合技术，显著提高了预测准确性和可操作性。", "motivation": "解决远程教育中学生辍学问题，传统机器学习模型无法捕捉非结构化学生互动中的情感和上下文因素。", "method": "采用RAG进行领域特定情感分析，提示工程解码学术压力源，跨模态注意力融合动态对齐文本、行为和社会人口学洞察。", "result": "在4,423名学生的纵向数据集上，框架达到89%的准确率和0.88的F1分数，比传统模型提高7%，减少21%的假阴性。", "conclusion": "该框架不仅预测辍学风险，还生成可解释的干预措施，为全球教育系统提供了可扩展的解决方案。"}}
{"id": "2507.05346", "title": "LoRA-Augmented Generation (LAG) for Knowledge-Intensive Language Tasks", "authors": ["William Fleshman", "Benjamin Van Durme"], "abstract": "The proliferation of fine-tuned language model experts for specific tasks and domains signals the need for efficient selection and combination methods. We propose LoRA-Augmented Generation (LAG) for leveraging large libraries of knowledge and task-specific LoRA adapters. LAG requires no additional training or access to data, and efficiently filters, retrieves, and applies experts on a per-token and layer basis. We evaluate LAG on various knowledge-intensive tasks, achieving superior performance over existing data-free methods. We explore scenarios where additional data is available, demonstrating LAG's compatibility with alternative solutions such as retrieval-augmented generation (RAG).", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.05346.pdf", "abstract_url": "https://arxiv.org/abs/2507.05346", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了LoRA增强生成（LAG）方法，用于高效选择和结合特定任务和领域的微调语言模型专家，无需额外训练或数据访问，在知识密集型任务上表现优异。", "motivation": "解决特定任务和领域中微调语言模型专家的高效选择和结合问题。", "method": "使用LoRA-Augmented Generation（LAG）方法，利用大量知识和任务特定的LoRA适配器库，无需额外训练或数据访问。", "result": "在多种知识密集型任务上，LAG的表现优于现有的无数据方法。", "conclusion": "LAG提供了一种高效的方法来选择和结合语言模型专家，特别是在知识密集型任务中，且与检索增强生成（RAG）等替代方案兼容。"}}
{"id": "2507.05330", "title": "MindFlow: Revolutionizing E-commerce Customer Support with Multimodal LLM Agents", "authors": ["Ming Gong", "Xucheng Huang", "Chenghan Yang", "Xianhan Peng", "Haoxin Wang", "Yang Liu", "Ling Jiang"], "abstract": "Recent advances in large language models (LLMs) have enabled new applications in e-commerce customer service. However, their capabilities remain constrained in complex, multimodal scenarios. We present MindFlow, the first open-source multimodal LLM agent tailored for e-commerce. Built on the CoALA framework, it integrates memory, decision-making, and action modules, and adopts a modular \"MLLM-as-Tool\" strategy for effect visual-textual reasoning. Evaluated via online A/B testing and simulation-based ablation, MindFlow demonstrates substantial gains in handling complex queries, improving user satisfaction, and reducing operational costs, with a 93.53% relative improvement observed in real-world deployments.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.05330.pdf", "abstract_url": "https://arxiv.org/abs/2507.05330", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了MindFlow，首个为电子商务定制的开源多模态大型语言模型（LLM）代理，基于CoALA框架构建，通过整合记忆、决策和行动模块，采用模块化的“MLLM-as-Tool”策略进行视觉-文本推理，显著提升了处理复杂查询、用户满意度和降低运营成本的能力。", "motivation": "尽管大型语言模型（LLMs）在电子商务客户服务中开启了新的应用，但在复杂的多模态场景中其能力仍受限。本文旨在解决这一问题。", "method": "基于CoALA框架构建的MindFlow，整合了记忆、决策和行动模块，采用模块化的“MLLM-as-Tool”策略进行视觉-文本推理。", "result": "通过在线A/B测试和基于模拟的消融评估，MindFlow在处理复杂查询、提高用户满意度和降低运营成本方面显示出显著优势，实际部署中观察到93.53%的相对改进。", "conclusion": "MindFlow作为一种开源多模态LLM代理，为电子商务客户服务提供了有效的解决方案，显著提升了服务质量和效率。"}}
{"id": "2507.05419", "title": "Motion Generation: A Survey of Generative Approaches and Benchmarks", "authors": ["Aliasghar Khani", "Arianna Rampini", "Bruno Roy", "Larasika Nadela", "Noa Kaplan", "Evan Atherton", "Derek Cheung", "Jacky Bibliowicz"], "abstract": "Motion generation, the task of synthesizing realistic motion sequences from various conditioning inputs, has become a central problem in computer vision, computer graphics, and robotics, with applications ranging from animation and virtual agents to human-robot interaction. As the field has rapidly progressed with the introduction of diverse modeling paradigms including GANs, autoencoders, autoregressive models, and diffusion-based techniques, each approach brings its own advantages and limitations. This growing diversity has created a need for a comprehensive and structured review that specifically examines recent developments from the perspective of the generative approach employed.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.05419.pdf", "abstract_url": "https://arxiv.org/abs/2507.05419", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文综述了运动生成领域的最新进展，重点分析了生成对抗网络（GANs）、自编码器、自回归模型和基于扩散的技术等多种生成方法及其优缺点。", "motivation": "随着计算机视觉、计算机图形学和机器人学中运动生成任务的快速发展，需要从生成方法的角度对最新进展进行全面和结构化的回顾。", "method": "通过对GANs、自编码器、自回归模型和基于扩散的技术等多种生成方法的分析，评估了它们在运动生成任务中的应用和性能。", "result": "各种生成方法在运动生成任务中各有优势和局限性，需要根据具体应用场景选择合适的方法。", "conclusion": "本文为运动生成领域的研究提供了全面的视角，强调了生成方法多样性对推动该领域发展的重要性，并指出了未来研究的方向。"}}
{"id": "2507.05279", "title": "ReservoirChat: Interactive Documentation Enhanced with LLM and Knowledge Graph for ReservoirPy", "authors": ["Virgile Boraud", "Yannis Bendi-Ouis", "Paul Bernard", "Xavier Hinaut"], "abstract": "We introduce a tool designed to improve the capabilities of Large Language Models (LLMs) in assisting with code development using the ReservoirPy library, as well as in answering complex questions in the field of Reservoir Computing. By incorporating external knowledge through Retrieval-Augmented Generation (RAG) and knowledge graphs, our approach aims to reduce hallucinations and increase the factual accuracy of generated responses. The system provides an interactive experience similar to ChatGPT, tailored specifically for ReservoirPy, enabling users to write, debug, and understand Python code while accessing reliable domain-specific insights. In our evaluation, while proprietary models such as ChatGPT-4o and NotebookLM performed slightly better on general knowledge questions, our model outperformed them on coding tasks and showed a significant improvement over its base model, Codestral-22B.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Neural and Evolutionary Computing (cs.NE)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.05279.pdf", "abstract_url": "https://arxiv.org/abs/2507.05279", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Neural and Evolutionary Computing (cs.NE)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "介绍了一个工具，旨在通过结合检索增强生成（RAG）和知识图谱，提高大型语言模型（LLMs）在协助使用ReservoirPy库进行代码开发及回答储层计算领域复杂问题时的能力。", "motivation": "解决LLMs在代码开发和特定领域问题回答中的幻觉问题，提高生成响应的准确性。", "method": "采用检索增强生成（RAG）和知识图谱技术，结合外部知识，为ReservoirPy提供定制化的交互式体验。", "result": "在编码任务上优于ChatGPT-4o和NotebookLM，相较于基础模型Codestral-22B有显著改进。", "conclusion": "该工具通过整合外部知识，显著提升了LLMs在特定领域的应用效果，尤其是在代码开发和理解方面。"}}
{"id": "2507.05517", "title": "Empowering Healthcare Practitioners with Language Models: Structuring Speech Transcripts in Two Real-World Clinical Applications", "authors": ["Jean-Philippe Corbeil", "Asma Ben Abacha", "George Michalopoulos", "Phillip Swazinna", "Miguel Del-Agua", "Jerome Tremblay", "Akila Jeeson Daniel", "Cari Bader", "Kevin Cho", "Pooja Krishnan", "Nathan Bodenstab", "Thomas Lin", "Wenxuan Teng", "Francois Beaulieu", "Paul Vozila"], "abstract": "Large language models (LLMs) such as GPT-4o and o1 have demonstrated strong performance on clinical natural language processing (NLP) tasks across multiple medical benchmarks. Nonetheless, two high-impact NLP tasks - structured tabular reporting from nurse dictations and medical order extraction from doctor-patient consultations - remain underexplored due to data scarcity and sensitivity, despite active industry efforts. Practical solutions to these real-world clinical tasks can significantly reduce the documentation burden on healthcare providers, allowing greater focus on patient care. In this paper, we investigate these two challenging tasks using private and open-source clinical datasets, evaluating the performance of both open- and closed-weight LLMs, and analyzing their respective strengths and limitations. Furthermore, we propose an agentic pipeline for generating realistic, non-sensitive nurse dictations, enabling structured extraction of clinical observations. To support further research in both areas, we release SYNUR and SIMORD, the first open-source datasets for nurse observation extraction and medical order extraction.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.05517.pdf", "abstract_url": "https://arxiv.org/abs/2507.05517", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文探讨了利用大型语言模型（LLMs）如GPT-4o和o1在临床自然语言处理（NLP）任务中的应用，特别是在护士口述结构化表格报告和医患咨询中医疗指令提取这两个高影响力但数据稀缺和敏感的任务上。通过私有和开源临床数据集评估开放和封闭权重LLMs的性能，并分析其优缺点。此外，提出了一个代理管道用于生成真实、非敏感的护士口述，支持临床观察的结构化提取，并发布了首个开源数据集SYNUR和SIMORD以支持进一步研究。", "motivation": "解决临床NLP任务中因数据稀缺和敏感性而未被充分探索的两个高影响力任务——护士口述结构化表格报告和医患咨询中医疗指令提取，以减轻医疗提供者的文档负担，使其更专注于患者护理。", "method": "使用私有和开源临床数据集评估开放和封闭权重LLMs的性能，并提出一个代理管道用于生成真实、非敏感的护士口述，支持临床观察的结构化提取。", "result": "评估了LLMs在护士观察提取和医疗指令提取任务上的性能，并发布了首个开源数据集SYNUR和SIMORD以支持这两个领域的研究。", "conclusion": "通过LLMs和提出的代理管道，可以有效支持临床NLP任务，减轻医疗提供者的文档负担，并通过发布的开源数据集促进进一步研究。"}}
{"id": "2507.05639", "title": "ECom-Bench: Can LLM Agent Resolve Real-World E-commerce Customer Support Issues?", "authors": ["Haoxin Wang", "Xianhan Peng", "Xucheng Huang", "Yizhe Huang", "Ming Gong", "Chenghan Yang", "Yang Liu", "Ling Jiang"], "abstract": "In this paper, we introduce ECom-Bench, the first benchmark framework for evaluating LLM agent with multimodal capabilities in the e-commerce customer support domain. ECom-Bench features dynamic user simulation based on persona information collected from real e-commerce customer interactions and a realistic task dataset derived from authentic e-commerce dialogues. These tasks, covering a wide range of business scenarios, are designed to reflect real-world complexities, making ECom-Bench highly challenging. For instance, even advanced models like GPT-4o achieve only a 10-20% pass^3 metric in our benchmark, highlighting the substantial difficulties posed by complex e-commerce scenarios. Upon publication, the code and data will be open-sourced to facilitate further research and development in this domain.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.05639.pdf", "abstract_url": "https://arxiv.org/abs/2507.05639", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了ECom-Bench，这是首个评估具有多模态能力的LLM代理在电子商务客户支持领域表现的基准框架。", "motivation": "解决在复杂电子商务场景中评估LLM代理性能的挑战。", "method": "基于真实电子商务客户互动收集的人物信息进行动态用户模拟，并使用源自真实电子商务对话的任务数据集。", "result": "即使是像GPT-4o这样的先进模型，在ECom-Bench中也仅达到10-20%的通过率，显示了电子商务场景的复杂性。", "conclusion": "ECom-Bench为电子商务客户支持领域的进一步研究和开发提供了具有挑战性的基准，代码和数据将开源以促进该领域的发展。"}}
{"id": "2507.05633", "title": "SARA: Selective and Adaptive Retrieval-augmented Generation with Context Compression", "authors": ["Yiqiao Jin", "Kartik Sharma", "Vineeth Rakesh", "Yingtong Dou", "Menghai Pan", "Mahashweta Das", "Srijan Kumar"], "abstract": "Retrieval-augmented Generation (RAG) extends large language models (LLMs) with external knowledge but faces key challenges: restricted effective context length and redundancy in retrieved documents. Pure compression-based approaches reduce input size but often discard fine-grained details essential for factual accuracy. We propose SARA, a unified RAG framework that balances local precision and global knowledge coverage under tight context budgets. SARA combines natural-language text snippets with semantic compression vectors to jointly enhance context efficiency and answer correctness. It represents contexts at two complementary levels: 1) fine-grained natural-language spans that preserve critical entities and numerical values, and 2) compact, interpretable vectors that summarize high-level semantics. An iterative evidence-selection module employs the compression vectors for dynamic reranking of contexts. Across 9 datasets and 5 open-source LLMs spanning 3 model families (Mistral, Llama, and Gemma), SARA consistently improves answer relevance (+17.71), answer correctness (+13.72), and semantic similarity (+15.53), demonstrating the importance of integrating textual and compressed representations for robust, context-efficient RAG.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": "20 pages", "pdf_url": "https://arxiv.org/pdf/2507.05633.pdf", "abstract_url": "https://arxiv.org/abs/2507.05633", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "SARA是一个统一的检索增强生成框架，通过结合自然语言文本片段和语义压缩向量，在有限的上下文预算下平衡局部精确性和全局知识覆盖，提高了回答的相关性、正确性和语义相似性。", "motivation": "检索增强生成（RAG）面临有效上下文长度受限和检索文档冗余的关键挑战。纯压缩方法虽然减少了输入大小，但常常丢弃对事实准确性至关重要的细粒度细节。", "method": "SARA结合了自然语言文本片段和语义压缩向量，以两个互补的层次表示上下文：1）保留关键实体和数值的细粒度自然语言片段，2）总结高级语义的紧凑、可解释向量。此外，一个迭代的证据选择模块利用压缩向量对上下文进行动态重新排序。", "result": "在9个数据集和5个开源LLM（涵盖3个模型家族：Mistral、Llama和Gemma）上，SARA在回答相关性（+17.71）、回答正确性（+13.72）和语义相似性（+15.53）方面持续改进。", "conclusion": "SARA展示了结合文本和压缩表示对于构建健壮、上下文高效的RAG系统的重要性，为未来的研究和发展提供了有价值的见解。"}}
{"id": "2507.05707", "title": "Agentic-R1: Distilled Dual-Strategy Reasoning", "authors": ["Weihua Du", "Pranjal Aggarwal", "Sean Welleck", "Yiming Yang"], "abstract": "Current long chain-of-thought (long-CoT) models excel at mathematical reasoning but rely on slow and error-prone natural language traces. Tool-augmented agents address arithmetic via code execution, but often falter on complex logical tasks. We introduce a fine-tuning framework, DualDistill, that distills complementary reasoning strategies from multiple teachers into a unified student model. Using this approach, we train Agentic-R1, which dynamically selects the optimal strategy for each query, invoking tools for arithmetic and algorithmic problems, and using text-based reasoning for abstract ones. Our method improves accuracy across a range of tasks, including both computation-intensive and standard benchmarks, demonstrating the effectiveness of multi-strategy distillation in achieving robust and efficient reasoning. Our project is available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2507.05707.pdf", "abstract_url": "https://arxiv.org/abs/2507.05707", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了DualDistill框架，通过从多个教师模型中提炼互补的推理策略，训练出能够动态选择最优策略的Agentic-R1模型，以提高在计算密集型和标准基准任务中的准确性。", "motivation": "解决当前长链思维模型在数学推理上依赖缓慢且易出错的自然语言追踪，以及工具增强代理在复杂逻辑任务上表现不佳的问题。", "method": "使用DualDistill框架，从多个教师模型中提炼互补的推理策略，训练出能够动态选择最优策略的学生模型Agentic-R1。", "result": "Agentic-R1在包括计算密集型和标准基准在内的多种任务中提高了准确性，证明了多策略提炼在实现健壮和高效推理方面的有效性。", "conclusion": "通过多策略提炼，可以训练出能够动态选择最优推理策略的模型，从而在多种任务中实现健壮和高效的推理。"}}
{"id": "2507.05713", "title": "DRAGON: Dynamic RAG Benchmark On News", "authors": ["Fedor Chernogorskii", "Sergei Averkiev", "Liliya Kudraleeva", "Zaven Martirosian", "Maria Tikhonova", "Valentin Malykh", "Alena Fenogenova"], "abstract": "Retrieval-Augmented Generation (RAG) is a widely adopted approach for improving the factuality of large language models (LLMs) by incorporating external knowledge at inference time. Although there exist multiple RAG benchmarks for English, evaluation resources for other languages, including Russian, remain scarce and static, failing to capture the dynamic nature of real-world deployments.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.05713.pdf", "abstract_url": "https://arxiv.org/abs/2507.05713", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了DRAGON，一个针对新闻领域的动态RAG（检索增强生成）基准测试，旨在解决非英语语言（如俄语）RAG评估资源稀缺且静态的问题。", "motivation": "当前，虽然存在多个英语的RAG基准测试，但其他语言（包括俄语）的评估资源仍然稀缺且静态，无法反映现实世界部署的动态特性。", "method": "提出了一个动态的RAG基准测试DRAGON，专注于新闻领域，以评估和改善大型语言模型（LLMs）在推理时通过整合外部知识的事实性。", "result": "DRAGON基准测试填补了非英语语言RAG评估资源的空白，特别是针对俄语，提供了一个动态的评估框架。", "conclusion": "DRAGON的推出为非英语语言的RAG评估提供了重要资源，有助于更准确地评估和提升LLMs在动态环境中的表现。"}}
{"id": "2507.05714", "title": "HIRAG: Hierarchical-Thought Instruction-Tuning Retrieval-Augmented Generation", "authors": ["YiHan Jiao", "ZheHao Tan", "Dan Yang", "DuoLin Sun", "Jie Feng", "Jian Wang", "Peng Wei"], "abstract": "Retrieval-augmented generation (RAG) has become a fundamental paradigm for addressing the challenges faced by large language models in handling real-time information and domain-specific problems. Traditional RAG systems primarily rely on the in-context learning (ICL) capabilities of the large language model itself. Still, in-depth research on the specific capabilities needed by the RAG generation model is lacking, leading to challenges with inconsistent document quality and retrieval system imperfections. Even the limited studies that fine-tune RAG generative models often \\textit{lack a granular focus on RAG task} or \\textit{a deeper utilization of chain-of-thought processes}. To address this, we propose that RAG models should possess three progressively hierarchical abilities (1) Filtering: the ability to select relevant information; (2) Combination: the ability to combine semantic information across paragraphs; and (3) RAG-specific reasoning: the ability to further process external knowledge using internal knowledge. Thus, we introduce our new RAG instruction fine-tuning method, Hierarchical-Thought Instruction-Tuning Retrieval-Augmented Generation (HIRAG) incorporates a \"think before answering\" strategy. This method enhances the model's open-book examination capability by utilizing multi-level progressive chain-of-thought. Experiments show that the HIRAG training strategy significantly improves the model's performance on datasets such as RGB, PopQA, MuSiQue, HotpotQA, and PubmedQA.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.05714.pdf", "abstract_url": "https://arxiv.org/abs/2507.05714", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种名为HIRAG的层次思维指令调优检索增强生成方法，旨在解决传统RAG系统在文档质量和检索系统不完善方面的挑战。通过引入三种渐进式层次能力，HIRAG显著提升了模型在多个数据集上的性能。", "motivation": "解决大型语言模型在处理实时信息和领域特定问题时面临的挑战，特别是传统RAG系统在文档质量不一致和检索系统不完善方面的问题。", "method": "提出HIRAG方法，该方法通过层次思维指令调优，增强模型的开放书考试能力，利用多级渐进式思维链。", "result": "实验表明，HIRAG训练策略显著提高了模型在RGB、PopQA、MuSiQue、HotpotQA和PubmedQA等数据集上的性能。", "conclusion": "HIRAG方法通过层次思维指令调优，有效提升了RAG模型的能力，为解决传统RAG系统的挑战提供了新的思路。"}}
{"id": "2507.05788", "title": "Flippi: End To End GenAI Assistant for E-Commerce", "authors": ["Anand A. Rajasekar", "Praveen Tangarajan", "Anjali Nainani", "Amogh Batwal", "Vinay Rao Dandin", "Anusua Trivedi", "Ozan Ersoy"], "abstract": "The emergence of conversational assistants has fundamentally reshaped user interactions with digital platforms. This paper introduces Flippi-a cutting-edge, end-to-end conversational assistant powered by large language models (LLMs) and tailored for the e-commerce sector. Flippi addresses the challenges posed by the vast and often overwhelming product landscape, enabling customers to discover products more efficiently through natural language dialogue. By accommodating both objective and subjective user requirements, Flippi delivers a personalized shopping experience that surpasses traditional search methods. This paper details how Flippi interprets customer queries to provide precise product information, leveraging advanced NLP techniques such as Query Reformulation, Intent Detection, Retrieval-Augmented Generation (RAG), Named Entity Recognition (NER), and Context Reduction. Flippi's unique capability to identify and present the most attractive offers on an e-commerce site is also explored, demonstrating how it empowers users to make cost-effective decisions. Additionally, the paper discusses Flippi's comparative analysis features, which help users make informed choices by contrasting product features, prices, and other relevant attributes. The system's robust architecture is outlined, emphasizing its adaptability for integration across various e-commerce platforms and the technological choices underpinning its performance and accuracy. Finally, a comprehensive evaluation framework is presented, covering performance metrics, user satisfaction, and the impact on customer engagement and conversion rates. By bridging the convenience of online shopping with the personalized assistance traditionally found in physical stores, Flippi sets a new standard for customer satisfaction and engagement in the digital marketplace.", "subjects": "Computation and Language (cs.CL)", "comments": "10 pages, 2 figures, 7 tables", "pdf_url": "https://arxiv.org/pdf/2507.05788.pdf", "abstract_url": "https://arxiv.org/abs/2507.05788", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了Flippi，一个基于大型语言模型(LLMs)的端到端对话助手，专为电子商务领域设计，旨在通过自然语言对话帮助用户更高效地发现产品。", "motivation": "解决电子商务平台上产品信息量大且复杂，用户难以高效找到合适产品的问题。", "method": "利用先进的NLP技术，包括查询重构、意图检测、检索增强生成(RAG)、命名实体识别(NER)和上下文缩减，以及比较分析功能。", "result": "Flippi能够提供精确的产品信息，识别并展示最具吸引力的优惠，帮助用户做出成本效益高的决策，并通过比较产品特性、价格等帮助用户做出明智选择。", "conclusion": "Flippi通过将在线购物的便利性与传统实体店的个性化服务相结合，为数字市场中的客户满意度和参与度设定了新标准。"}}
{"id": "2507.05673", "title": "R-VLM: Region-Aware Vision Language Model for Precise GUI Grounding", "authors": ["Joonhyung Park", "Peng Tang", "Sagnik Das", "Srikar Appalaraju", "Kunwar Yashraj Singh", "R. Manmatha", "Shabnam Ghadar"], "abstract": "Visual agent models for automating human activities on Graphical User Interfaces (GUIs) have emerged as a promising research direction, driven by advances in large Vision Language Models (VLMs). A critical challenge in GUI automation is the precise grounding of interface elements across diverse platforms. Existing vision-only GUI agents directly ground elements from large and cluttered screenshots, requiring them to process substantial irrelevant information that compromises their accuracy. In addition, these approaches typically employ basic cross-entropy loss for learning grounding objectives, which fails to effectively capture grounding quality compared to established object detection metrics like Intersection-over-Union (IoU). To address these issues, we introduce R-VLM, a novel GUI grounding approach that leverages zoomed-in region proposals for precise element localization. We also propose an IoU-aware objective function that facilitates model convergence toward high IoU predictions. Our approach bridges the gap between VLMs and conventional object detection techniques, improving the state-of-the-art grounding accuracy by 13% across diverse GUI platforms on the GUI grounding benchmarks ScreenSpot and AgentStudio. In addition, our R-VLM approach shows 3.2-9.7% absolute accuracy improvements in GUI navigation tasks on the AITW and Mind2Web benchmarks.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "ACL 2025; 17 pages", "pdf_url": "https://arxiv.org/pdf/2507.05673.pdf", "abstract_url": "https://arxiv.org/abs/2507.05673", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "R-VLM是一种新型的视觉语言模型，专注于图形用户界面（GUI）元素的精确定位，通过引入放大区域提案和IoU感知目标函数，显著提高了GUI自动化的准确性和效率。", "motivation": "解决GUI自动化中界面元素精确定位的挑战，特别是在处理大而杂乱的屏幕截图时，现有视觉模型因处理大量无关信息而影响准确性。", "method": "采用放大区域提案进行精确元素定位，并提出IoU感知目标函数以优化模型预测的IoU值。", "result": "在GUI定位基准测试ScreenSpot和AgentStudio上，R-VLM将最先进的定位准确率提高了13%；在AITW和Mind2Web基准测试的GUI导航任务中，绝对准确率提高了3.2-9.7%。", "conclusion": "R-VLM通过结合视觉语言模型和传统对象检测技术，显著提升了GUI元素的定位准确率，为GUI自动化任务提供了更高效的解决方案。"}}
{"id": "2507.05316", "title": "OASBuilder: Generating OpenAPI Specifications from Online API Documentation with Large Language Models", "authors": ["Koren Lazar", "Matan Vetzler", "Kiran Kate", "Jason Tsay", "David Boaz Himanshu Gupta", "Avraham Shinnar", "Rohith D Vallam", "David Amid Esther Goldbraich", "Guy Uziel", "Jim Laredo", "Ateret Anaby Tavor"], "abstract": "AI agents and business automation tools interacting with external web services require standardized, machine-readable information about their APIs in the form of API specifications. However, the information about APIs available online is often presented as unstructured, free-form HTML documentation, requiring external users to spend significant time manually converting it into a structured format. To address this, we introduce OASBuilder, a novel framework that transforms long and diverse API documentation pages into consistent, machine-readable API specifications. This is achieved through a carefully crafted pipeline that integrates large language models and rule-based algorithms which are guided by domain knowledge of the structure of documentation webpages. Our experiments demonstrate that OASBuilder generalizes well across hundreds of APIs, and produces valid OpenAPI specifications that encapsulate most of the information from the original documentation. OASBuilder has been successfully implemented in an enterprise environment, saving thousands of hours of manual effort and making hundreds of complex enterprise APIs accessible as tools for LLMs.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.05316.pdf", "abstract_url": "https://arxiv.org/abs/2507.05316", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "OASBuilder是一个利用大型语言模型和基于规则的算法，将非结构化的在线API文档转换为机器可读的OpenAPI规范的新框架。", "motivation": "解决在线API文档通常以非结构化、自由格式的HTML形式呈现，需要外部用户花费大量时间手动转换为结构化格式的问题。", "method": "通过结合大型语言模型和基于规则的算法，利用文档网页结构的领域知识，构建了一个精心设计的管道。", "result": "实验表明，OASBuilder在数百个API上表现良好，能够生成包含原始文档大部分信息的有效OpenAPI规范。", "conclusion": "OASBuilder已在企业环境中成功实施，节省了数千小时的手动工作，并使数百个复杂的企业API可作为LLM的工具使用。"}}
{"id": "2507.05321", "title": "AGACCI : Affiliated Grading Agents for Criteria-Centric Interface in Educational Coding Contexts", "authors": ["Kwangsuk Park", "Jiwoong Yang"], "abstract": "Recent advances in AI-assisted education have encouraged the integration of vision-language models (VLMs) into academic assessment, particularly for tasks that require both quantitative and qualitative evaluation. However, existing VLM based approaches struggle with complex educational artifacts, such as programming tasks with executable components and measurable outputs, that require structured reasoning and alignment with clearly defined evaluation criteria. We introduce AGACCI, a multi-agent system that distributes specialized evaluation roles across collaborative agents to improve accuracy, interpretability, and consistency in code-oriented assessment. To evaluate the framework, we collected 360 graduate-level code-based assignments from 60 participants, each annotated by domain experts with binary rubric scores and qualitative feedback. Experimental results demonstrate that AGACCI outperforms a single GPT-based baseline in terms of rubric and feedback accuracy, relevance, consistency, and coherence, while preserving the instructional intent and evaluative depth of expert assessments. Although performance varies across task types, AGACCI highlights the potential of multi-agent systems for scalable and context-aware educational evaluation.", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI)", "comments": "Accepted at ICML 2025 Workshop on Multi-Agent Systems in the Era of Foundation Models: Opportunities, Challenges and Futures (MAS)", "pdf_url": "https://arxiv.org/pdf/2507.05321.pdf", "abstract_url": "https://arxiv.org/abs/2507.05321", "categories": ["Computers and Society (cs.CY)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "AGACCI是一种多代理系统，用于教育编码环境中的评估，通过分配专业评估角色提高准确性、可解释性和一致性。", "motivation": "解决现有基于视觉语言模型（VLM）的方法在处理复杂教育工件（如具有可执行组件和可测量输出的编程任务）时的不足。", "method": "引入AGACCI，一个多代理系统，通过协作代理分配专业评估角色，以提高代码导向评估的准确性、可解释性和一致性。", "result": "实验结果显示，AGACCI在评分和反馈的准确性、相关性、一致性和连贯性方面优于基于GPT的单一基线，同时保留了专家评估的教学意图和评估深度。", "conclusion": "AGACCI展示了多代理系统在可扩展和情境感知教育评估中的潜力，尽管性能因任务类型而异。"}}
{"id": "2507.06016", "title": "Conditional Multi-Stage Failure Recovery for Embodied Agents", "authors": ["Youmna Farag", "Svetlana Stoyanchev", "Mohan Li", "Simon Keizer", "Rama Doddipatla"], "abstract": "Embodied agents performing complex tasks are susceptible to execution failures, motivating the need for effective failure recovery mechanisms. In this work, we introduce a conditional multistage failure recovery framework that employs zero-shot chain prompting. The framework is structured into four error-handling stages, with three operating during task execution and one functioning as a post-execution reflection phase. Our approach utilises the reasoning capabilities of LLMs to analyse execution challenges within their environmental context and devise strategic solutions. We evaluate our method on the TfD benchmark of the TEACH dataset and achieve state-of-the-art performance, outperforming a baseline without error recovery by 11.5% and surpassing the strongest existing model by 19%.", "subjects": "Computation and Language (cs.CL)", "comments": "Accepted at REALM 2025", "pdf_url": "https://arxiv.org/pdf/2507.06016.pdf", "abstract_url": "https://arxiv.org/abs/2507.06016", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一种条件多阶段故障恢复框架，用于提高执行复杂任务的具身代理在遇到执行失败时的恢复能力。", "motivation": "具身代理在执行复杂任务时容易遇到执行失败，因此需要有效的故障恢复机制。", "method": "采用零射击链提示的条件多阶段故障恢复框架，包括四个错误处理阶段，其中三个在任务执行期间操作，一个作为执行后的反思阶段。", "result": "在TEACH数据集的TfD基准测试中，该方法实现了最先进的性能，比没有错误恢复的基线提高了11.5%，比现有最强模型提高了19%。", "conclusion": "该框架通过利用LLMs的推理能力分析执行挑战并制定战略解决方案，显著提高了具身代理的故障恢复能力。"}}
{"id": "2507.05465", "title": "2048: Reinforcement Learning in a Delayed Reward Environment", "authors": ["Prady Saligram", "Tanvir Bhathal", "Robby Manihani"], "abstract": "Delayed and sparse rewards present a fundamental obstacle for reinforcement-learning (RL) agents, which struggle to assign credit for actions whose benefits emerge many steps later. The sliding-tile game 2048 epitomizes this challenge: although frequent small score changes yield immediate feedback, they often mislead agents into locally optimal but globally suboptimal strategies. In this work, we introduce a unified, distributional multi-step RL framework designed to directly optimize long-horizon performance. Using the open source Gym-2048 environment we develop and compare four agent variants: standard DQN, PPO, QR-DQN (Quantile Regression DQN), and a novel Horizon-DQN (H-DQN) that integrates distributional learning, dueling architectures, noisy networks, prioritized replay, and more. Empirical evaluation reveals a clear hierarchy in effectiveness: max episode scores improve from 3.988K (DQN) to 5.756K (PPO), 8.66K (QR-DQN), and 18.21K (H-DQN), with H-DQN reaching the 2048 tile. Upon scaling H-DQN it reaches a max score 41.828K and a 4096 tile. These results demonstrate that distributional, multi-step targets substantially enhance performance in sparse-reward domains, and they suggest promising avenues for further gains through model-based planning and curriculum learning.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.05465.pdf", "abstract_url": "https://arxiv.org/abs/2507.05465", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一个统一的、分布式的多步强化学习框架，旨在直接优化长期性能，特别是在延迟和稀疏奖励的环境中。通过在Gym-2048环境中开发和比较四种代理变体，研究发现H-DQN（一种新型的Horizon-DQN）在性能上显著优于其他方法，达到了2048和4096的瓷砖，展示了分布式、多步目标在稀疏奖励领域中的优势。", "motivation": "延迟和稀疏奖励是强化学习代理面临的一个基本障碍，代理难以将行动的好处归因于许多步骤之后。滑动瓷砖游戏2048体现了这一挑战：频繁的小分数变化提供了即时反馈，但常常误导代理采取局部最优但全局次优的策略。", "method": "本文引入了一个统一的、分布式的多步强化学习框架，并在Gym-2048环境中开发和比较了四种代理变体：标准DQN、PPO、QR-DQN（Quantile Regression DQN）和新型的Horizon-DQN（H-DQN）。H-DQN集成了分布式学习、决斗架构、噪声网络、优先回放等技术。", "result": "实证评估显示，代理的有效性有明显的层次：最大剧集分数从3.988K（DQN）提高到5.756K（PPO）、8.66K（QR-DQN）和18.21K（H-DQN），H-DQN达到了2048瓷砖。在扩展H-DQN后，它达到了41.828K的最大分数和4096瓷砖。", "conclusion": "这些结果表明，分布式、多步目标在稀疏奖励领域中显著提高了性能，并提出了通过基于模型的规划和课程学习进一步获得收益的有希望的途径。"}}
{"id": "2507.06229", "title": "Agent KB: Leveraging Cross-Domain Experience for Agentic Problem Solving", "authors": ["Xiangru Tang", "Tianrui Qin", "Tianhao Peng", "Ziyang Zhou", "Daniel Shao", "Tingting Du", "Xinming Wei", "Peng Xia", "Fang Wu", "He Zhu", "Ge Zhang", "Jiaheng Liu", "Xingyao Wang", "Sirui Hong", "Chenglin Wu", "Hao Cheng", "Chi Wang", "Wangchunshu Zhou"], "abstract": "As language agents tackle increasingly complex tasks, they struggle with effective error correction and experience reuse across domains. We introduce Agent KB, a hierarchical experience framework that enables complex agentic problem solving via a novel Reason-Retrieve-Refine pipeline. Agent KB addresses a core limitation: agents traditionally cannot learn from each other's experiences. By capturing both high-level strategies and detailed execution logs, Agent KB creates a shared knowledge base that enables cross-agent knowledge transfer. Evaluated on the GAIA benchmark, Agent KB improves success rates by up to 16.28 percentage points. On the most challenging tasks, Claude-3 improves from 38.46% to 57.69%, while GPT-4 improves from 53.49% to 73.26% on intermediate tasks. On SWE-bench code repair, Agent KB enables Claude-3 to improve from 41.33% to 53.33%. Our results suggest that Agent KB provides a modular, framework-agnostic infrastructure for enabling agents to learn from past experiences and generalize successful strategies to new tasks.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.06229.pdf", "abstract_url": "https://arxiv.org/abs/2507.06229", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "Agent KB是一个分层经验框架，通过新颖的Reason-Retrieve-Refine流程，支持复杂的代理问题解决，解决了代理间无法相互学习经验的核心限制。", "motivation": "解决语言代理在处理日益复杂任务时，跨领域错误纠正和经验复用效率低下的问题。", "method": "采用分层经验框架和Reason-Retrieve-Refine流程，构建共享知识库以实现跨代理知识转移。", "result": "在GAIA基准测试中，Agent KB将成功率提高了高达16.28个百分点；在最具挑战性的任务中，Claude-3和GPT-4的性能分别从38.46%提升至57.69%和从53.49%提升至73.26%；在SWE-bench代码修复任务中，Claude-3的性能从41.33%提升至53.33%。", "conclusion": "Agent KB提供了一个模块化、框架无关的基础设施，使代理能够从过去的经验中学习，并将成功策略推广到新任务中。"}}
{"id": "2507.05469", "title": "Inaugural MOASEI Competition at AAMAS'2025: A Technical Report", "authors": ["Ceferino Patino", "Tyler J. Billings", "Alireza Saleh Abadi", "Daniel Redder", "Adam Eck", "Prashant Doshi", "Leen-Kiat Soh"], "abstract": "We present the Methods for Open Agent Systems Evaluation Initiative (MOASEI) Competition, a multi-agent AI benchmarking event designed to evaluate decision-making under open-world conditions. Built on the free-range-zoo environment suite, MOASEI introduced dynamic, partially observable domains with agent and task openness--settings where entities may appear, disappear, or change behavior over time. The 2025 competition featured three tracks--Wildfire, Rideshare, and Cybersecurity--each highlighting distinct dimensions of openness and coordination complexity. Eleven teams from international institutions participated, with four of those teams submitting diverse solutions including graph neural networks, convolutional architectures, predictive modeling, and large language model--driven meta--optimization. Evaluation metrics centered on expected utility, robustness to perturbations, and responsiveness to environmental change. The results reveal promising strategies for generalization and adaptation in open environments, offering both empirical insight and infrastructure for future research. This report details the competition's design, findings, and contributions to the open-agent systems research community.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": "Report from the MOASEI'2025 Competition held at AAMAS'2025", "pdf_url": "https://arxiv.org/pdf/2507.05469.pdf", "abstract_url": "https://arxiv.org/abs/2507.05469", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "介绍了AAMAS'2025上的MOASEI竞赛，这是一个评估开放世界条件下多智能体AI决策制定的基准测试活动。竞赛基于free-range-zoo环境套件，引入了动态、部分可观察的领域，以及智能体和任务的开放性。2025年的竞赛设有三个赛道，展示了开放性和协调复杂性的不同维度。来自国际机构的十一个团队参与，其中四个团队提交了多样化的解决方案。评估指标集中在预期效用、对扰动的鲁棒性以及对环境变化的响应能力上。结果揭示了在开放环境中泛化和适应的有前景的策略。", "motivation": "解决在开放世界条件下多智能体AI决策制定的评估问题，特别是在动态、部分可观察的领域中，智能体和任务的开放性带来的挑战。", "method": "基于free-range-zoo环境套件，设计了三个赛道（Wildfire、Rideshare和Cybersecurity），引入了动态、部分可观察的领域，以及智能体和任务的开放性。", "result": "四个团队提交了多样化的解决方案，包括图神经网络、卷积架构、预测建模和大型语言模型驱动的元优化。评估结果显示出了在开放环境中泛化和适应的有前景的策略。", "conclusion": "MOASEI竞赛为开放智能体系统研究社区提供了实证见解和基础设施，展示了在开放环境中多智能体AI决策制定的潜力和挑战。"}}
{"id": "2507.05558", "title": "AI Agent Smart Contract Exploit Generation", "authors": ["Arthur Gervais", "Liyi Zhou"], "abstract": "We present A1, an agentic execution driven system that transforms any LLM into an end-to-end exploit generator. A1 has no hand-crafted heuristics and provides the agent with six domain-specific tools that enable autonomous vulnerability discovery. The agent can flexibly leverage these tools to understand smart contract behavior, generate exploit strategies, test them on blockchain states, and refine approaches based on execution feedback. All outputs are concretely validated to eliminate false positives.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.05558.pdf", "abstract_url": "https://arxiv.org/abs/2507.05558", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了A1，一个代理执行驱动的系统，能够将任何大型语言模型（LLM）转化为端到端的漏洞利用生成器。A1无需手工启发式方法，为代理提供了六种领域特定工具，支持自主发现漏洞。代理可以灵活利用这些工具来理解智能合约行为、生成利用策略、在区块链状态上测试它们，并根据执行反馈优化方法。所有输出都经过具体验证以消除误报。", "motivation": "解决智能合约漏洞利用生成的问题，特别是如何自动化地发现和验证这些漏洞，而无需依赖手工启发式方法。", "method": "开发了一个名为A1的系统，该系统利用代理执行驱动的方法，结合六种领域特定工具，使大型语言模型能够自主发现和验证智能合约的漏洞。", "result": "A1系统能够有效地生成和验证智能合约的漏洞利用策略，所有输出都经过具体验证，确保了无假阳性。", "conclusion": "A1系统代表了一种创新的方法，能够自动化地发现和验证智能合约漏洞，为智能合约安全领域提供了新的工具和方法。"}}
{"id": "2507.05630", "title": "How Not to Detect Prompt Injections with an LLM", "authors": ["Sarthak Choudhary", "Divyam Anshumaan", "Nils Palumbo", "Somesh Jha"], "abstract": "LLM-integrated applications and agents are vulnerable to prompt injection attacks, in which adversaries embed malicious instructions within seemingly benign user inputs to manipulate the LLM's intended behavior. Recent defenses based on $\\textit{known-answer detection}$ (KAD) have achieved near-perfect performance by using an LLM to classify inputs as clean or contaminated. In this work, we formally characterize the KAD framework and uncover a structural vulnerability in its design that invalidates its core security premise. We design a methodical adaptive attack, $\\textit{DataFlip}$, to exploit this fundamental weakness. It consistently evades KAD defenses with detection rates as low as $1.5\\%$ while reliably inducing malicious behavior with success rates of up to $88\\%$, without needing white-box access to the LLM or any optimization procedures.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.05630.pdf", "abstract_url": "https://arxiv.org/abs/2507.05630", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文揭示了基于已知答案检测（KAD）的LLM防御框架的结构性漏洞，并提出了一种名为DataFlip的方法论适应性攻击，能够有效规避KAD防御，成功诱导恶意行为。", "motivation": "解决LLM集成应用和代理在面对提示注入攻击时的脆弱性问题，特别是现有基于KAD的防御措施的安全前提被证明存在根本性弱点。", "method": "通过正式描述KAD框架并设计DataFlip攻击方法，利用KAD设计的结构性漏洞进行攻击。", "result": "DataFlip攻击能够将KAD防御的检测率降至1.5%，同时成功诱导恶意行为的成功率高达88%，且无需LLM的白盒访问或任何优化过程。", "conclusion": "研究表明KAD防御框架存在根本性安全漏洞，需要重新考虑LLM安全防御策略的设计。"}}
{"id": "2507.05577", "title": "Beyond Retrieval: Ensembling Cross-Encoders and GPT Rerankers with LLMs for Biomedical QA", "authors": ["Shashank Verma", "Fengyi Jiang", "Xiangning Xue"], "abstract": "Biomedical semantic question answering rooted in information retrieval can play a crucial role in keeping up to date with vast, rapidly evolving and ever-growing biomedical literature. A robust system can help researchers, healthcare professionals and even layman users access relevant knowledge grounded in evidence. The BioASQ 2025 Task13b Challenge serves as an important benchmark, offering a competitive platform for advancement of this space. This paper presents the methodologies and results from our participation in this challenge where we built a Retrieval-Augmented Generation (RAG) system that can answer biomedical questions by retrieving relevant PubMed documents and snippets to generate answers. For the retrieval task, we generated dense embeddings from biomedical articles for initial retrieval, and applied an ensemble of finetuned cross-encoders and large language models (LLMs) for re-ranking to identify top relevant documents. Our solution achieved an MAP@10 of 0.1581, placing 10th on the leaderboard for the retrieval task. For answer generation, we employed few-shot prompting of instruction-tuned LLMs. Our system achieved macro-F1 score of 0.95 for yes/no questions (rank 12), Mean Reciprocal Rank (MRR) of 0.64 for factoid questions (rank 1), mean-F1 score of 0.63 for list questions (rank 5), and ROUGE-SU4 F1 score of 0.29 for ideal answers (rank 11).", "subjects": "Information Retrieval (cs.IR); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": "Paper submitted to CLEF 2025 CEUR-WS", "pdf_url": "https://arxiv.org/pdf/2507.05577.pdf", "abstract_url": "https://arxiv.org/abs/2507.05577", "categories": ["Information Retrieval (cs.IR)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了参与BioASQ 2025 Task13b挑战的方法和结果，构建了一个基于检索增强生成（RAG）的系统，用于回答生物医学问题。通过生成密集嵌入和重排序技术，系统在检索任务中取得了MAP@10为0.1581的成绩。在答案生成方面，系统在不同类型的问题上表现优异，特别是在事实型问题上取得了MRR为0.64的最高排名。", "motivation": "解决生物医学领域信息检索和问答系统面临的挑战，帮助研究人员、医疗专业人员和非专业用户获取基于证据的相关知识。", "method": "构建了一个检索增强生成（RAG）系统，结合了密集嵌入生成、微调的交叉编码器和大型语言模型（LLMs）的重排序技术，以及指令调优的LLMs进行少样本提示的答案生成。", "result": "检索任务中MAP@10为0.1581，排名第10；答案生成方面，在是/否问题、事实型问题、列表问题和理想答案上分别取得了0.95的macro-F1、0.64的MRR、0.63的mean-F1和0.29的ROUGE-SU4 F1的成绩。", "conclusion": "通过结合先进的检索和生成技术，该系统在生物医学问答任务中表现出色，特别是在事实型问题上取得了最佳成绩，展示了检索增强生成方法在生物医学领域的潜力。"}}
{"id": "2507.05820", "title": "Constella: Supporting Storywriters' Interconnected Character Creation through LLM-based Multi-Agents", "authors": ["Syemin Park", "Soobin Park", "Youn-kyung Lim"], "abstract": "Creating a cast of characters by attending to their relational dynamics is a critical aspect of most long-form storywriting. However, our formative study (N=14) reveals that writers struggle to envision new characters that could influence existing ones, to balance similarities and differences among characters, and to intricately flesh out their relationships. Based on these observations, we designed Constella, an LLM-based multi-agent tool that supports storywriters' interconnected character creation process. Constella suggests related characters (FRIENDS DISCOVERY feature), reveals the inner mindscapes of several characters simultaneously (JOURNALS feature), and manifests relationships through inter-character responses (COMMENTS feature). Our 7-8 day deployment study with storywriters (N=11) shows that Constella enabled the creation of expansive communities composed of related characters, facilitated the comparison of characters' thoughts and emotions, and deepened writers' understanding of character relationships. We conclude by discussing how multi-agent interactions can help distribute writers' attention and effort across the character cast.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "50 pages", "pdf_url": "https://arxiv.org/pdf/2507.05820.pdf", "abstract_url": "https://arxiv.org/abs/2507.05820", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "Constella是一个基于LLM的多代理工具，旨在支持故事作者创建互相关联的角色。通过FRIENDS DISCOVERY、JOURNALS和COMMENTS功能，它帮助作者发现相关角色、比较角色的内心世界和深化角色关系理解。", "motivation": "解决作者在创作长篇故事时，难以构想影响现有角色的新角色、平衡角色间的相似与差异以及细致刻画角色关系的问题。", "method": "设计了Constella工具，利用基于LLM的多代理系统，提供角色发现、内心世界展示和角色间互动响应功能。", "result": "部署研究表明，Constella帮助作者创建了广泛相关的角色社区，促进了角色思想和情感的比较，并加深了对角色关系的理解。", "conclusion": "多代理互动有助于分散作者在角色阵容上的注意力和努力，为故事创作提供了新的支持方式。"}}
{"id": "2507.05720", "title": "MobileGUI-RL: Advancing Mobile GUI Agent through Reinforcement Learning in Online Environment", "authors": ["Yucheng Shi", "Wenhao Yu", "Zaitang Li", "Yonglin Wang", "Hongming Zhang", "Ninghao Liu", "Haitao Mi", "Dong Yu"], "abstract": "Recently, there has been a surge of vision-based GUI agents designed to automate everyday mobile and web tasks. These agents interpret raw GUI screenshots and autonomously decide where to click, scroll, or type, which bypasses handcrafted rules and app-specific APIs. However, most existing methods trained GUI agent in the offline environment using pre-collected trajectories. This approach limits scalability, causes overfitting to specific UI templates, and leads to brittle policies when faced with unseen environment. We present MobileGUI-RL, a scalable framework that trains GUI agent in online environment. MobileGUI-RL contains two key components. It (i) synthesizes a curriculum of learnable tasks through self-exploration and filtering, and (ii) adapts GRPO to GUI navigation with trajectory-aware advantages and composite rewards that balance task success and execution efficiency. Experiments on three online mobile-agent benchmarks show consistent gains, validating the effectiveness of our approach.", "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL)", "comments": "17 pages, 4 figures", "pdf_url": "https://arxiv.org/pdf/2507.05720.pdf", "abstract_url": "https://arxiv.org/abs/2507.05720", "categories": ["Machine Learning (cs.LG)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "MobileGUI-RL是一个通过强化学习在在线环境中训练移动GUI代理的框架，旨在解决现有方法在离线环境中训练导致的扩展性限制、对特定UI模板的过拟合以及面对新环境时的脆弱策略问题。", "motivation": "现有的基于视觉的GUI代理大多在离线环境中使用预先收集的轨迹进行训练，这种方法限制了代理的扩展性，容易对特定的UI模板过拟合，并且在面对新环境时策略脆弱。", "method": "MobileGUI-RL框架包含两个关键组件：(i) 通过自我探索和过滤合成一系列可学习的任务课程，(ii) 采用GRPO算法进行GUI导航，结合轨迹感知优势和复合奖励，以平衡任务成功和执行效率。", "result": "在三个在线移动代理基准测试上的实验显示，MobileGUI-RL方法取得了持续的增益，验证了其有效性。", "conclusion": "MobileGUI-RL通过在线环境训练和创新的任务合成及奖励机制，显著提高了GUI代理的适应性和执行效率，为移动GUI自动化任务提供了新的解决方案。"}}
{"id": "2507.06157", "title": "Evaluation of Habitat Robotics using Large Language Models", "authors": ["William Li", "Lei Hamilton", "Kaise Al-natour", "Sanjeev Mohindra"], "abstract": "This paper focuses on evaluating the effectiveness of Large Language Models at solving embodied robotic tasks using the Meta PARTNER benchmark. Meta PARTNR provides simplified environments and robotic interactions within randomized indoor kitchen scenes. Each randomized kitchen scene is given a task where two robotic agents cooperatively work together to solve the task. We evaluated multiple frontier models on Meta PARTNER environments. Our results indicate that reasoning models like OpenAI o3-mini outperform non-reasoning models like OpenAI GPT-4o and Llama 3 when operating in PARTNR's robotic embodied environments. o3-mini displayed outperform across centralized, decentralized, full observability, and partial observability configurations. This provides a promising avenue of research for embodied robotic development.", "subjects": "Robotics (cs.RO); Computation and Language (cs.CL)", "comments": "6 pages, IEEE HPEC submission", "pdf_url": "https://arxiv.org/pdf/2507.06157.pdf", "abstract_url": "https://arxiv.org/abs/2507.06157", "categories": ["Robotics (cs.RO)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过Meta PARTNER基准评估了大型语言模型在解决具身机器人任务中的有效性，发现推理模型如OpenAI o3-mini在多种配置下优于非推理模型。", "motivation": "评估大型语言模型在具身机器人任务中的表现，探索其在机器人开发中的应用潜力。", "method": "使用Meta PARTNER基准，在随机化的室内厨房场景中，评估多个前沿模型在合作机器人任务中的表现。", "result": "OpenAI o3-mini在集中式、分散式、完全可观察和部分可观察配置中均优于OpenAI GPT-4o和Llama 3等非推理模型。", "conclusion": "推理模型在具身机器人环境中表现出色，为机器人开发提供了有前景的研究方向。"}}
{"id": "2507.06127", "title": "PrefixAgent: An LLM-Powered Design Framework for Efficient Prefix Adder Optimization", "authors": ["Dongsheng Zuo", "Jiadong Zhu", "Yang Luo", "Yuzhe Ma"], "abstract": "Prefix adders are fundamental arithmetic circuits, but their design space grows exponentially with bit-width, posing significant optimization challenges. Previous works face limitations in performance, generalization, and scalability. To address these challenges, we propose PrefixAgent, a large language model (LLM)-powered framework that enables efficient prefix adder optimization. Specifically, PrefixAgent reformulates the problem into subtasks including backbone synthesis and structure refinement, which effectively reduces the search space. More importantly, this new design perspective enables us to efficiently collect enormous high-quality data and reasoning traces with E-graph, which further results in an effective fine-tuning of LLM. Experimental results show that PrefixAgent synthesizes prefix adders with consistently smaller areas compared to baseline methods, while maintaining scalability and generalization in commercial EDA flows.", "subjects": "Hardware Architecture (cs.AR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.06127.pdf", "abstract_url": "https://arxiv.org/abs/2507.06127", "categories": ["Hardware Architecture (cs.AR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "PrefixAgent是一个基于大型语言模型（LLM）的设计框架，旨在高效优化前缀加法器。通过将问题重新表述为子任务并利用E-graph收集高质量数据，该框架在保持可扩展性和通用性的同时，显著减少了搜索空间，实验结果显示其合成的加法器面积更小。", "motivation": "前缀加法器是基本的算术电路，但其设计空间随位宽呈指数级增长，带来了显著的优化挑战。现有方法在性能、通用性和可扩展性方面存在局限。", "method": "提出PrefixAgent框架，将问题重新表述为包括骨干合成和结构细化在内的子任务，有效减少搜索空间，并利用E-graph收集高质量数据和推理轨迹，进而对LLM进行有效微调。", "result": "实验结果表明，与基线方法相比，PrefixAgent合成的加法器面积更小，同时在商业EDA流程中保持了可扩展性和通用性。", "conclusion": "PrefixAgent通过创新的设计视角和LLM的强大能力，为前缀加法器的优化提供了一种高效、可扩展的解决方案，具有重要的实际应用价值。"}}
