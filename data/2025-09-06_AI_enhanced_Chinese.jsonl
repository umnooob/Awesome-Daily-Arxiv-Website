{"id": "2509.03527", "title": "Multilevel Analysis of Cryptocurrency News using RAG Approach with Fine-Tuned Mistral Large Language Model", "authors": ["Bohdan M. Pavlyshenko"], "abstract": "In the paper, we consider multilevel multitask analysis of cryptocurrency news using a fine-tuned Mistral 7B large language model with retrieval-augmented generation (RAG).", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03527.pdf", "abstract_url": "https://arxiv.org/abs/2509.03527", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "使用微调的Mistral 7B大语言模型和检索增强生成（RAG）方法进行加密货币新闻的多层次多任务分析。", "motivation": "解决加密货币新闻的复杂分析问题，可能包括情感分析、事件检测等多任务需求。", "method": "采用检索增强生成（RAG）方法，结合微调的Mistral 7B大语言模型进行多层次分析。", "result": "未提供具体结果，但方法可能提高分析的准确性和效率。", "conclusion": "该方法为加密货币新闻分析提供了有效工具，具有潜在应用价值。"}}
{"id": "2509.03540", "title": "Improving Factuality in LLMs via Inference-Time Knowledge Graph Construction", "authors": ["Shanglin Wu", "Lihui Liu", "Jinho D. Choi", "Kai Shu"], "abstract": "Large Language Models (LLMs) often struggle with producing factually consistent answers due to limitations in their parametric memory. Retrieval-Augmented Generation (RAG) methods address this issue by incorporating external knowledge from trusted sources at inference time. However, such methods typically treat knowledge as unstructured text, which limits their ability to support compositional reasoning and identify factual inconsistencies. To overcome these limitations, we propose a novel framework that dynamically constructs and expands knowledge graphs (KGs) during inference, integrating both internal knowledge extracted from LLMs and external information retrieved from external sources. Our method begins by extracting a seed KG from the question via prompting, followed by iterative expansion using the LLM's latent knowledge. The graph is then selectively refined through external retrieval, enhancing factual coverage and correcting inaccuracies. We evaluate our approach on three diverse factual QA benchmarks, demonstrating consistent improvements in factual accuracy, answer precision, and interpretability over baseline prompting and static KG-augmented methods. Our findings suggest that inference-time KG construction is a promising direction for enhancing LLM factuality in a structured, interpretable, and scalable manner.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03540.pdf", "abstract_url": "https://arxiv.org/abs/2509.03540", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种通过推理时动态构建知识图谱来增强大型语言模型事实性的新框架，结合内部和外部知识，在多个事实问答基准上显示出准确性、精确性和可解释性的改进。", "motivation": "解决大型语言模型在生成事实一致答案时因参数记忆限制而存在的问题，特别是现有检索增强生成方法处理非结构化知识的局限性，无法支持组合推理和识别事实不一致。", "method": "在推理时动态构建和扩展知识图谱，从问题中提取种子图谱，利用LLM的潜在知识迭代扩展，并通过外部检索选择性精炼，以整合内部和外部知识。", "result": "在三个事实问答基准上评估，该方法在事实准确性、答案精确性和可解释性方面一致优于基线提示和静态知识图谱增强方法。", "conclusion": "推理时知识图谱构建是增强LLM事实性的有前景方向，具有结构化、可解释和可扩展的优点。"}}
{"id": "2509.03565", "title": "ResearchPulse: Building Method-Experiment Chains through Multi-Document Scientific Inference", "authors": ["Qi Chen", "Jingxuan Wei", "Zhuoya Yao", "Haiguang Wang", "Gaowei Wu", "Bihui Yu", "Siyuan Li", "Cheng Tan"], "abstract": "Understanding how scientific ideas evolve requires more than summarizing individual papers-it demands structured, cross-document reasoning over thematically related research. In this work, we formalize multi-document scientific inference, a new task that extracts and aligns motivation, methodology, and experimental results across related papers to reconstruct research development chains. This task introduces key challenges, including temporally aligning loosely structured methods and standardizing heterogeneous experimental tables. We present ResearchPulse, an agent-based framework that integrates instruction planning, scientific content extraction, and structured visualization. It consists of three coordinated agents: a Plan Agent for task decomposition, a Mmap-Agent that constructs motivation-method mind maps, and a Lchart-Agent that synthesizes experimental line charts. To support this task, we introduce ResearchPulse-Bench, a citation-aware benchmark of annotated paper clusters. Experiments show that our system, despite using 7B-scale agents, consistently outperforms strong baselines like GPT-4o in semantic alignment, structural consistency, and visual fidelity. The dataset are available in", "subjects": "Computation and Language (cs.CL); Multimedia (cs.MM)", "comments": "Accepted to ACM MM 2025", "pdf_url": "https://arxiv.org/pdf/2509.03565.pdf", "abstract_url": "https://arxiv.org/abs/2509.03565", "categories": ["Computation and Language (cs.CL)", "Multimedia (cs.MM)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出ResearchPulse框架，通过多文档科学推理构建方法-实验链，以提取和对齐相关论文中的动机、方法和结果，并引入基准数据集ResearchPulse-Bench，实验显示其性能优于GPT-4o等基线。", "motivation": "解决科学思想演化需要跨文档结构化推理的问题，而非仅总结单篇论文。", "method": "使用基于代理的框架，包括计划代理、思维映射代理和线图代理，进行任务分解、内容提取和可视化。", "result": "系统在语义对齐、结构一致性和视觉保真度上优于GPT-4o等基线，尽管使用7B规模代理。", "conclusion": "ResearchPulse有效支持多文档科学推理任务，基准数据集可用，促进研究发展链的重建。"}}
{"id": "2509.03891", "title": "MobileRAG: Enhancing Mobile Agent with Retrieval-Augmented Generation", "authors": ["Gowen Loo", "Chang Liu", "Qinghong Yin", "Xiang Chen", "Jiawei Chen", "Jingyuan Zhang", "Yu Tian"], "abstract": "Smartphones have become indispensable in people's daily lives, permeating nearly every aspect of modern society. With the continuous advancement of large language models (LLMs), numerous LLM-based mobile agents have emerged. These agents are capable of accurately parsing diverse user queries and automatically assisting users in completing complex or repetitive operations. However, current agents 1) heavily rely on the comprehension ability of LLMs, which can lead to errors caused by misoperations or omitted steps during tasks, 2) lack interaction with the external environment, often terminating tasks when an app cannot fulfill user queries, and 3) lack memory capabilities, requiring each instruction to reconstruct the interface and being unable to learn from and correct previous mistakes. To alleviate the above issues, we propose MobileRAG, a mobile agents framework enhanced by Retrieval-Augmented Generation (RAG), which includes InterRAG, LocalRAG, and MemRAG. It leverages RAG to more quickly and accurately identify user queries and accomplish complex and long-sequence mobile tasks. Additionally, to more comprehensively assess the performance of MobileRAG, we introduce MobileRAG-Eval, a more challenging benchmark characterized by numerous complex, real-world mobile tasks that require external knowledge assistance. Extensive experimental results on MobileRAG-Eval demonstrate that MobileRAG can easily handle real-world mobile tasks, achieving 10.3\\% improvement over state-of-the-art methods with fewer operational steps. Our code is publicly available at:", "subjects": "Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03891.pdf", "abstract_url": "https://arxiv.org/abs/2509.03891", "categories": ["Computation and Language (cs.CL)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "MobileRAG是一个通过检索增强生成（RAG）技术增强的移动代理框架，包括InterRAG、LocalRAG和MemRAG组件，旨在更快速准确地处理用户查询并完成复杂移动任务，在MobileRAG-Eval基准测试中表现优于现有方法。", "motivation": "解决当前基于大语言模型的移动代理在任务执行中易出错、缺乏外部环境交互和记忆能力的问题，如误操作、任务终止和无法学习纠正错误。", "method": "提出MobileRAG框架，集成RAG技术（InterRAG、LocalRAG、MemRAG）来提升查询识别和任务完成能力，并引入MobileRAG-Eval基准进行评估。", "result": "在MobileRAG-Eval基准上，MobileRAG实现了10.3%的性能提升，且操作步骤更少，能有效处理现实世界中的复杂移动任务。", "conclusion": "MobileRAG通过RAG增强显著改善了移动代理的准确性和效率，为未来移动应用开发提供了有价值的框架和评估标准。"}}
{"id": "2509.03918", "title": "MTQA:Matrix of Thought for Enhanced Reasoning in Complex Question Answering", "authors": ["Fengxiao Tang", "Yufeng Li", "Zongzong Wu", "Ming Zhao"], "abstract": "Complex Question Answering (QA) is a fundamental and challenging task in NLP. While large language models (LLMs) exhibit impressive performance in QA, they suffer from significant performance degradation when facing complex and abstract QA tasks due to insufficient reasoning capabilities. Works such as Chain-of-Thought (CoT) and Tree-of-Thought (ToT) aim to enhance LLMs' reasoning abilities, but they face issues such as in-layer redundancy in tree structures and single paths in chain structures. Although some studies utilize Retrieval-Augmented Generation (RAG) methods to assist LLMs in reasoning, the challenge of effectively utilizing large amounts of information involving multiple entities and hops remains critical. To address this, we propose the Matrix of Thought (MoT), a novel and efficient LLM thought structure. MoT explores the problem in both horizontal and vertical dimensions through the \"column-cell communication\" mechanism, enabling LLMs to actively engage in multi-strategy and deep-level thinking, reducing redundancy within the column cells and enhancing reasoning capabilities. Furthermore, we develop a fact-correction mechanism by constructing knowledge units from retrieved knowledge graph triples and raw text to enhance the initial knowledge for LLM reasoning and correct erroneous answers. This leads to the development of an efficient and accurate QA framework (MTQA). Experimental results show that our framework outperforms state-of-the-art methods on four widely-used datasets in terms of F1 and EM scores, with reasoning time only 14.4\\% of the baseline methods, demonstrating both its efficiency and accuracy. The code for this framework is available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03918.pdf", "abstract_url": "https://arxiv.org/abs/2509.03918", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "提出矩阵思维（MoT）和事实校正机制，增强大语言模型在复杂问答中的推理能力，提高准确性和效率。", "motivation": "解决大语言模型在复杂抽象问答任务中推理能力不足、现有方法如CoT和ToT存在冗余和单一路径问题，以及RAG方法难以有效利用多实体和多跳信息的问题。", "method": "使用矩阵思维结构（MoT），通过列-单元通信机制在水平和垂直维度探索问题，结合知识图谱三元组和原始文本构建知识单元进行事实校正。", "result": "在四个数据集上F1和EM分数优于最先进方法，推理时间仅为基线方法的14.4%，证明高效且准确。", "conclusion": "MoT框架显著提升复杂问答的推理能力，代码可用，具有实际应用价值。"}}
{"id": "2509.03934", "title": "SelfAug: Mitigating Catastrophic Forgetting in Retrieval-Augmented Generation via Distribution Self-Alignment", "authors": ["Yuqing Huang", "Rongyang Zhang", "Qimeng Wang", "Chengqiang Lu", "Yan Gao", "Yi Wu", "Yao Hu", "Xuyang Zhi", "Guiquan Liu", "Xin Li", "Hao Wang", "Enhong Chen"], "abstract": "Recent advancements in large language models (LLMs) have revolutionized natural language processing through their remarkable capabilities in understanding and executing diverse tasks. While supervised fine-tuning, particularly in Retrieval-Augmented Generation (RAG) scenarios, effectively enhances task-specific performance, it often leads to catastrophic forgetting, where models lose their previously acquired knowledge and general capabilities. Existing solutions either require access to general instruction data or face limitations in preserving the model's original distribution. To overcome these limitations, we propose SelfAug, a self-distribution alignment method that aligns input sequence logits to preserve the model's semantic distribution, thereby mitigating catastrophic forgetting and improving downstream performance. Extensive experiments demonstrate that SelfAug achieves a superior balance between downstream learning and general capability retention. Our comprehensive empirical analysis reveals a direct correlation between distribution shifts and the severity of catastrophic forgetting in RAG scenarios, highlighting how the absence of RAG capabilities in general instruction tuning leads to significant distribution shifts during fine-tuning. Our findings not only advance the understanding of catastrophic forgetting in RAG contexts but also provide a practical solution applicable across diverse fine-tuning scenarios. Our code is publicly available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03934.pdf", "abstract_url": "https://arxiv.org/abs/2509.03934", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "SelfAug是一种自分布对齐方法，通过在RAG微调中对齐输入序列的logits来减轻灾难性遗忘，提升下游性能并保持模型的一般能力。", "motivation": "解决在检索增强生成（RAG）微调中，大型语言模型（LLMs）因灾难性遗忘而失去先前知识和一般能力的问题。", "method": "使用自分布对齐方法SelfAug，对齐输入序列的logits以保持模型的语义分布。", "result": "实验显示SelfAug在下游学习和一般能力保持之间取得更好平衡，并揭示分布偏移与灾难性遗忘严重性直接相关。", "conclusion": "SelfAug不仅推进了对RAG中灾难性遗忘的理解，还提供了一个适用于多种微调场景的实用解决方案。"}}
{"id": "2509.03940", "title": "VoxRole: A Comprehensive Benchmark for Evaluating Speech-Based Role-Playing Agents", "authors": ["Weihao Wu", "Liang Cao", "Xinyu Wu", "Zhiwei Lin", "Rui Niu", "Jingbei Li", "Zhiyong Wu"], "abstract": "Recent significant advancements in Large Language Models (LLMs) have greatly propelled the development of Role-Playing Conversational Agents (RPCAs). These systems aim to create immersive user experiences through consistent persona adoption. However, current RPCA research faces dual limitations. First, existing work predominantly focuses on the textual modality, entirely overlooking critical paralinguistic features including intonation, prosody, and rhythm in speech, which are essential for conveying character emotions and shaping vivid identities. Second, the speech-based role-playing domain suffers from a long-standing lack of standardized evaluation benchmarks. Most current spoken dialogue datasets target only fundamental capability assessments, featuring thinly sketched or ill-defined character profiles. Consequently, they fail to effectively quantify model performance on core competencies like long-term persona consistency. To address this critical gap, we introduce VoxRole, the first comprehensive benchmark specifically designed for the evaluation of speech-based RPCAs. The benchmark comprises 13335 multi-turn dialogues, totaling 65.6 hours of speech from 1228 unique characters across 261 movies. To construct this resource, we propose a novel two-stage automated pipeline that first aligns movie audio with scripts and subsequently employs an LLM to systematically build multi-dimensional profiles for each character. Leveraging VoxRole, we conduct a multi-dimensional evaluation of contemporary spoken dialogue models, revealing crucial insights into their respective strengths and limitations in maintaining persona consistency.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Sound (cs.SD)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03940.pdf", "abstract_url": "https://arxiv.org/abs/2509.03940", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Sound (cs.SD)"], "matching_keywords": ["agent"], "AI": {"tldr": "VoxRole是首个针对语音角色扮演代理的全面基准，包含13335个多轮对话和65.6小时语音，用于评估模型在保持角色一致性方面的能力。", "motivation": "解决当前角色扮演对话代理研究中忽视语音副语言特征和缺乏标准化评估基准的问题。", "method": "提出两阶段自动化流程：对齐电影音频与剧本，并使用大语言模型构建多维度角色档案。", "result": "评估显示当代语音对话模型在角色一致性方面存在优势和局限。", "conclusion": "VoxRole填补了关键空白，为语音角色扮演代理的发展提供了标准化评估工具。"}}
{"id": "2509.03536", "title": "PG-Agent: An Agent Powered by Page Graph", "authors": ["Weizhi Chen", "Ziwei Wang", "Leyang Yang", "Sheng Zhou", "Xiaoxuan Tang", "Jiajun Bu", "Yong Li", "Wei Jiang"], "abstract": "Graphical User Interface (GUI) agents possess significant commercial and social value, and GUI agents powered by advanced multimodal large language models (MLLMs) have demonstrated remarkable potential. Currently, existing GUI agents usually utilize sequential episodes of multi-step operations across pages as the prior GUI knowledge, which fails to capture the complex transition relationship between pages, making it challenging for the agents to deeply perceive the GUI environment and generalize to new scenarios. Therefore, we design an automated pipeline to transform the sequential episodes into page graphs, which explicitly model the graph structure of the pages that are naturally connected by actions. To fully utilize the page graphs, we further introduce Retrieval-Augmented Generation (RAG) technology to effectively retrieve reliable perception guidelines of GUI from them, and a tailored multi-agent framework PG-Agent with task decomposition strategy is proposed to be injected with the guidelines so that it can generalize to unseen scenarios. Extensive experiments on various benchmarks demonstrate the effectiveness of PG-Agent, even with limited episodes for page graph construction.", "subjects": "Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)", "comments": "Paper accepted to ACM MM 2025", "pdf_url": "https://arxiv.org/pdf/2509.03536.pdf", "abstract_url": "https://arxiv.org/abs/2509.03536", "categories": ["Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文提出PG-Agent，一种基于页面图的GUI代理，通过将序列化操作转换为图结构，并利用RAG技术和多代理框架，提升代理在未见场景中的泛化能力。", "motivation": "解决现有GUI代理无法捕捉页面间复杂转换关系，导致难以深度感知环境和泛化到新场景的问题。", "method": "设计自动化管道将序列化操作转换为页面图，引入RAG技术检索可靠感知指南，并开发多代理框架PG-Agent进行任务分解和指南注入。", "result": "在多个基准测试中，PG-Agent表现出有效性，即使使用有限序列构建页面图。", "conclusion": "页面图和RAG技术能显著增强GUI代理的感知和泛化能力，具有实际应用价值。"}}
{"id": "2509.03704", "title": "QuantV2X: A Fully Quantized Multi-Agent System for Cooperative Perception", "authors": ["Seth Z. Zhao", "Huizhi Zhang", "Zhaowei Li", "Juntong Peng", "Anthony Chui", "Zewei Zhou", "Zonglin Meng", "Hao Xiang", "Zhiyu Huang", "Fujia Wang", "Ran Tian", "Chenfeng Xu", "Bolei Zhou", "Jiaqi Ma"], "abstract": "Cooperative perception through Vehicle-to-Everything (V2X) communication offers significant potential for enhancing vehicle perception by mitigating occlusions and expanding the field of view. However, past research has predominantly focused on improving accuracy metrics without addressing the crucial system-level considerations of efficiency, latency, and real-world deployability. Noticeably, most existing systems rely on full-precision models, which incur high computational and transmission costs, making them impractical for real-time operation in resource-constrained environments. In this paper, we introduce \\textbf{QuantV2X}, the first fully quantized multi-agent system designed specifically for efficient and scalable deployment of multi-modal, multi-agent V2X cooperative perception. QuantV2X introduces a unified end-to-end quantization strategy across both neural network models and transmitted message representations that simultaneously reduces computational load and transmission bandwidth. Remarkably, despite operating under low-bit constraints, QuantV2X achieves accuracy comparable to full-precision systems. More importantly, when evaluated under deployment-oriented metrics, QuantV2X reduces system-level latency by 3.2$\\times$ and achieves a +9.5 improvement in mAP30 over full-precision baselines. Furthermore, QuantV2X scales more effectively, enabling larger and more capable models to fit within strict memory budgets. These results highlight the viability of a fully quantized multi-agent intermediate fusion system for real-world deployment. The system will be publicly released to promote research in this field:", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03704.pdf", "abstract_url": "https://arxiv.org/abs/2509.03704", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "QuantV2X是首个全量化多智能体系统，用于高效可扩展的多模态V2X协同感知部署，通过统一量化策略降低计算和传输成本，在保持精度的同时显著提升延迟和性能。", "motivation": "解决现有V2X协同感知系统因使用全精度模型导致的高计算和传输成本问题，使其在资源受限环境中不实用。", "method": "采用端到端统一量化策略，对神经网络模型和传输消息表示进行量化，以减少计算负载和传输带宽。", "result": "在低比特约束下，精度与全精度系统相当，系统级延迟降低3.2倍，mAP30提高9.5，并更有效地扩展模型以适应内存限制。", "conclusion": "全量化多智能体中间融合系统在现实世界部署中可行，将公开发布以促进研究。"}}
{"id": "2509.04104", "title": "Towards Stable and Personalised Profiles for Lexical Alignment in Spoken Human-Agent Dialogue", "authors": ["Keara Schaaij", "Roel Boumans", "Tibor Bosse", "Iris Hendrickx"], "abstract": "Lexical alignment, where speakers start to use similar words across conversation, is known to contribute to successful communication. However, its implementation in conversational agents remains underexplored, particularly considering the recent advancements in large language models (LLMs). As a first step towards enabling lexical alignment in human-agent dialogue, this study draws on strategies for personalising conversational agents and investigates the construction of stable, personalised lexical profiles as a basis for lexical alignment. Specifically, we varied the amounts of transcribed spoken data used for construction as well as the number of items included in the profiles per part-of-speech (POS) category and evaluated profile performance across time using recall, coverage, and cosine similarity metrics. It was shown that smaller and more compact profiles, created after 10 min of transcribed speech containing 5 items for adjectives, 5 items for conjunctions, and 10 items for adverbs, nouns, pronouns, and verbs each, offered the best balance in both performance and data efficiency. In conclusion, this study offers practical insights into constructing stable, personalised lexical profiles, taking into account minimal data requirements, serving as a foundational step toward lexical alignment strategies in conversational agents.", "subjects": "Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)", "comments": "Accepted for TSD 2025", "pdf_url": "https://arxiv.org/pdf/2509.04104.pdf", "abstract_url": "https://arxiv.org/abs/2509.04104", "categories": ["Computation and Language (cs.CL)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "该研究探讨了在口语人机对话中构建稳定且个性化的词汇配置文件，以实现词汇对齐，发现使用少量数据（如10分钟转录语音）创建紧凑配置文件效果最佳。", "motivation": "解决在对话代理中实现词汇对齐的问题，特别是在大型语言模型背景下，该领域尚未充分探索。", "method": "通过变化转录口语数据量和词性类别中的项目数，使用召回率、覆盖率和余弦相似度指标评估配置文件性能。", "result": "较小且紧凑的配置文件（如形容词和连词各5项，副词、名词、代词和动词各10项）在性能和数据处理效率上表现最佳。", "conclusion": "研究提供了构建稳定个性化词汇配置文件的实用见解，作为对话代理词汇对齐策略的基础步骤，考虑了最小数据需求。"}}
{"id": "2509.04183", "title": "MAGneT: Coordinated Multi-Agent Generation of Synthetic Multi-Turn Mental Health Counseling Sessions", "authors": ["Aishik Mandal", "Tanmoy Chakraborty", "Iryna Gurevych"], "abstract": "The growing demand for scalable psychological counseling highlights the need for fine-tuning open-source Large Language Models (LLMs) with high-quality, privacy-compliant data, yet such data remains scarce. Here we introduce MAGneT, a novel multi-agent framework for synthetic psychological counseling session generation that decomposes counselor response generation into coordinated sub-tasks handled by specialized LLM agents, each modeling a key psychological technique. Unlike prior single-agent approaches, MAGneT better captures the structure and nuance of real counseling. In addition, we address inconsistencies in prior evaluation protocols by proposing a unified evaluation framework integrating diverse automatic and expert metrics. Furthermore, we expand the expert evaluations from four aspects of counseling in previous works to nine aspects, enabling a more thorough and robust assessment of data quality. Empirical results show that MAGneT significantly outperforms existing methods in quality, diversity, and therapeutic alignment of the generated counseling sessions, improving general counseling skills by 3.2% and CBT-specific skills by 4.3% on average on cognitive therapy rating scale (CTRS). Crucially, experts prefer MAGneT-generated sessions in 77.2% of cases on average across all aspects. Moreover, fine-tuning an open-source model on MAGneT-generated sessions shows better performance, with improvements of 6.3% on general counseling skills and 7.3% on CBT-specific skills on average on CTRS over those fine-tuned with sessions generated by baseline methods. We also make our code and data public.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "25 pages, 29 figures", "pdf_url": "https://arxiv.org/pdf/2509.04183.pdf", "abstract_url": "https://arxiv.org/abs/2509.04183", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "MAGneT是一种多代理框架，用于生成合成心理咨询会话，通过分解任务并使用专门代理模拟心理技术，显著提高会话质量、多样性和治疗一致性，优于现有方法。", "motivation": "解决高质量、隐私合规的心理咨询数据稀缺问题，以微调开源大语言模型。", "method": "使用多代理框架，将咨询师响应生成分解为子任务，由专门LLM代理处理，并引入统一评估框架。", "result": "MAGneT在质量、多样性和治疗对齐方面显著优于基线，专家偏好率77.2%，微调模型性能提升6.3-7.3%。", "conclusion": "MAGneT有效生成高质量合成数据，提升心理咨询模型性能，代码和数据公开。"}}
{"id": "2509.03581", "title": "Learning When to Plan: Efficiently Allocating Test-Time Compute for LLM Agents", "authors": ["Davide Paglieri", "Bartłomiej Cupiał", "Jonathan Cook", "Ulyana Piterbarg", "Jens Tuyls", "Edward Grefenstette", "Jakob Nicolaus Foerster", "Jack Parker-Holder", "Tim Rocktäschel"], "abstract": "Training large language models (LLMs) to reason via reinforcement learning (RL) significantly improves their problem-solving capabilities. In agentic settings, existing methods like ReAct prompt LLMs to explicitly plan before every action; however, we demonstrate that always planning is computationally expensive and degrades performance on long-horizon tasks, while never planning further limits performance. To address this, we introduce a conceptual framework formalizing dynamic planning for LLM agents, enabling them to flexibly decide when to allocate test-time compute for planning. We propose a simple two-stage training pipeline: (1) supervised fine-tuning on diverse synthetic data to prime models for dynamic planning, and (2) RL to refine this capability in long-horizon environments. Experiments on the Crafter environment show that dynamic planning agents trained with this approach are more sample-efficient and consistently achieve more complex objectives. Additionally, we demonstrate that these agents can be effectively steered by human-written plans, surpassing their independent capabilities. To our knowledge, this work is the first to explore training LLM agents for dynamic test-time compute allocation in sequential decision-making tasks, paving the way for more efficient, adaptive, and controllable agentic systems.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03581.pdf", "abstract_url": "https://arxiv.org/abs/2509.03581", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种动态规划框架，让LLM代理在测试时灵活决定何时进行规划，通过两阶段训练提高效率和性能。", "motivation": "解决现有方法如ReAct中总是规划导致计算成本高和性能下降的问题，以及从不规划限制性能的挑战。", "method": "使用两阶段训练管道：先监督微调合成数据，再强化学习在长视野环境中优化动态规划能力。", "result": "在Crafter环境中，动态规划代理更样本高效，能实现更复杂目标，并可被人类计划引导超越独立能力。", "conclusion": "这是首个探索动态测试时计算分配的LLM代理训练工作，为更高效、自适应和可控的代理系统铺平道路。"}}
{"id": "2509.03550", "title": "Diffusion-RL Based Air Traffic Conflict Detection and Resolution Method", "authors": ["Tonghe Li", "Jixin Liu", "Weili Zeng", "Hao Jiang"], "abstract": "In the context of continuously rising global air traffic, efficient and safe Conflict Detection and Resolution (CD&R) is paramount for air traffic management. Although Deep Reinforcement Learning (DRL) offers a promising pathway for CD&R automation, existing approaches commonly suffer from a \"unimodal bias\" in their policies. This leads to a critical lack of decision-making flexibility when confronted with complex and dynamic constraints, often resulting in \"decision deadlocks.\" To overcome this limitation, this paper pioneers the integration of diffusion probabilistic models into the safety-critical task of CD&R, proposing a novel autonomous conflict resolution framework named Diffusion-AC. Diverging from conventional methods that converge to a single optimal solution, our framework models its policy as a reverse denoising process guided by a value function, enabling it to generate a rich, high-quality, and multimodal action distribution. This core architecture is complemented by a Density-Progressive Safety Curriculum (DPSC), a training mechanism that ensures stable and efficient learning as the agent progresses from sparse to high-density traffic environments. Extensive simulation experiments demonstrate that the proposed method significantly outperforms a suite of state-of-the-art DRL benchmarks. Most critically, in the most challenging high-density scenarios, Diffusion-AC not only maintains a high success rate of 94.1% but also reduces the incidence of Near Mid-Air Collisions (NMACs) by approximately 59% compared to the next-best-performing baseline, significantly enhancing the system's safety margin. This performance leap stems from its unique multimodal decision-making capability, which allows the agent to flexibly switch to effective alternative maneuvers.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "59 pages,13 figures, 3 tables", "pdf_url": "https://arxiv.org/pdf/2509.03550.pdf", "abstract_url": "https://arxiv.org/abs/2509.03550", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于扩散概率模型和深度强化学习的冲突检测与解决框架Diffusion-AC，通过多模态决策和密度渐进安全课程，在高密度空管场景中显著提升成功率和安全性。", "motivation": "解决现有深度强化学习方法在冲突检测与解决中的单模态偏差问题，导致决策僵局和灵活性不足，以应对日益增长的全球空中交通需求。", "method": "集成扩散概率模型，将策略建模为基于价值函数的反向去噪过程，生成多模态动作分布，并结合密度渐进安全课程进行训练。", "result": "在模拟实验中，Diffusion-AC在高密度场景下实现94.1%的成功率，并将近空中碰撞发生率降低约59%，优于现有基准方法。", "conclusion": "该方法通过多模态决策能力增强了系统的灵活性和安全性，为空管自动化提供了更有效的解决方案。"}}
{"id": "2509.03626", "title": "Explainable Knowledge Graph Retrieval-Augmented Generation (KG-RAG) with KG-SMILE", "authors": ["Zahra Zehtabi Sabeti Moghaddam", "Zeinab Dehghani", "Maneeha Rani", "Koorosh Aslansefat", "Bhupesh Kumar Mishra", "Rameez Raja Kureshi", "Dhavalkumar Thakker"], "abstract": "Generative AI, such as Large Language Models (LLMs), has achieved impressive progress but still produces hallucinations and unverifiable claims, limiting reliability in sensitive domains. Retrieval-Augmented Generation (RAG) improves accuracy by grounding outputs in external knowledge, especially in domains like healthcare, where precision is vital. However, RAG remains opaque and essentially a black box, heavily dependent on data quality. We developed a method-agnostic, perturbation-based framework that provides token and component-level interoperability for Graph RAG using SMILE and named it as Knowledge-Graph (KG)-SMILE. By applying controlled perturbations, computing similarities, and training weighted linear surrogates, KG-SMILE identifies the graph entities and relations most influential to generated outputs, thereby making RAG more transparent. We evaluate KG-SMILE using comprehensive attribution metrics, including fidelity, faithfulness, consistency, stability, and accuracy. Our findings show that KG-SMILE produces stable, human-aligned explanations, demonstrating its capacity to balance model effectiveness with interpretability and thereby fostering greater transparency and trust in machine learning technologies.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03626.pdf", "abstract_url": "https://arxiv.org/abs/2509.03626", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种名为KG-SMILE的基于扰动的框架，用于增强知识图谱检索增强生成（KG-RAG）的可解释性，通过识别关键图实体和关系来提高透明度和信任。", "motivation": "解决生成式AI（如LLMs）在敏感领域（如医疗）中产生幻觉和不可验证声明的问题，以及RAG方法的不透明性和对数据质量的依赖。", "method": "使用SMILE框架，通过受控扰动、相似性计算和加权线性代理模型，提供标记和组件级互操作性，以识别影响输出的图实体和关系。", "result": "评估显示KG-SMILE在保真度、忠实度、一致性、稳定性和准确性方面表现良好，产生稳定且与人类对齐的解释，平衡了模型有效性和可解释性。", "conclusion": "KG-SMILE增强了RAG的透明度，促进了机器学习技术的信任，适用于需要高可靠性的领域。"}}
{"id": "2509.03736", "title": "Are LLM Agents Behaviorally Coherent? Latent Profiles for Social Simulation", "authors": ["James Mooney", "Josef Woldense", "Zheng Robert Jia", "Shirley Anugrah Hayati", "My Ha Nguyen", "Vipul Raheja", "Dongyeop Kang"], "abstract": "The impressive capabilities of Large Language Models (LLMs) have fueled the notion that synthetic agents can serve as substitutes for real participants in human-subject research. In an effort to evaluate the merits of this claim, social science researchers have largely focused on whether LLM-generated survey data corresponds to that of a human counterpart whom the LLM is prompted to represent. In contrast, we address a more fundamental question: Do agents maintain internal consistency, retaining similar behaviors when examined under different experimental settings? To this end, we develop a study designed to (a) reveal the agent's internal state and (b) examine agent behavior in a basic dialogue setting. This design enables us to explore a set of behavioral hypotheses to assess whether an agent's conversation behavior is consistent with what we would expect from their revealed internal state. Our findings on these hypotheses show significant internal inconsistencies in LLMs across model families and at differing model sizes. Most importantly, we find that, although agents may generate responses matching those of their human counterparts, they fail to be internally consistent, representing a critical gap in their capabilities to accurately substitute for real participants in human-subject research. Our simulation code and data are publicly accessible.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "25 pages, 9 figures, 7 tables", "pdf_url": "https://arxiv.org/pdf/2509.03736.pdf", "abstract_url": "https://arxiv.org/abs/2509.03736", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本研究评估大型语言模型（LLM）代理在行为一致性方面的表现，发现尽管能生成类似人类的响应，但内部不一致，限制了其在人类主体研究中的替代能力。", "motivation": "解决LLM代理是否能在不同实验设置中保持内部行为一致性的问题，以评估其作为真实参与者替代品的可行性。", "method": "开发研究设计，揭示代理内部状态并分析基本对话设置中的行为，通过行为假设检验一致性。", "result": "发现LLM代理在模型家族和大小上存在显著内部不一致，无法保持行为一致性。", "conclusion": "LLM代理在行为上不连贯，存在关键能力差距，不能准确替代真实人类参与者，影响其在社会科学研究中的应用。"}}
{"id": "2509.03768", "title": "RAGuard: A Novel Approach for in-context Safe Retrieval Augmented Generation for LLMs", "authors": ["Connor Walker", "Koorosh Aslansefat", "Mohammad Naveed Akram", "Yiannis Papadopoulos"], "abstract": "Accuracy and safety are paramount in Offshore Wind (OSW) maintenance, yet conventional Large Language Models (LLMs) often fail when confronted with highly specialised or unexpected scenarios. We introduce RAGuard, an enhanced Retrieval-Augmented Generation (RAG) framework that explicitly integrates safety-critical documents alongside technical", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (stat.ML)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03768.pdf", "abstract_url": "https://arxiv.org/abs/2509.03768", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (stat.ML)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "RAGuard是一种新颖的检索增强生成框架，通过整合安全关键文档来提高大型语言模型在海上风电维护中的准确性和安全性。", "motivation": "解决大型语言模型在高度专业化或意外场景中准确性和安全性不足的问题，特别是在海上风电维护领域。", "method": "使用增强的检索增强生成（RAG）方法，明确集成安全关键文档与技术信息。", "result": "关键发现包括改进的模型性能和增强的安全处理能力（基于摘要推断）。", "conclusion": "RAGuard框架能有效提升LLMs在关键应用中的可靠性和安全性，具有实际应用价值。"}}
{"id": "2509.03811", "title": "Leveraging LLM-Based Agents for Intelligent Supply Chain Planning", "authors": ["Yongzhi Qi", "Jiaheng Yin", "Jianshen Zhang", "Dongyang Geng", "Zhengyu Chen", "Hao Hu", "Wei Qi", "Zuo-Jun Max Shen"], "abstract": "In supply chain management, planning is a critical concept. The movement of physical products across different categories, from suppliers to warehouse management, to sales, and logistics transporting them to customers, entails the involvement of many entities. It covers various aspects such as demand forecasting, inventory management, sales operations, and replenishment. How to collect relevant data from an e-commerce platform's perspective, formulate long-term plans, and dynamically adjust them based on environmental changes, while ensuring interpretability, efficiency, and reliability, is a practical and challenging problem. In recent years, the development of AI technologies, especially the rapid progress of large language models, has provided new tools to address real-world issues. In this work, we construct a Supply Chain Planning Agent (SCPA) framework that can understand domain knowledge, comprehend the operator's needs, decompose tasks, leverage or create new tools, and return evidence-based planning reports. We deploy this framework in", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03811.pdf", "abstract_url": "https://arxiv.org/abs/2509.03811", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于大型语言模型的智能供应链规划代理框架，用于解决供应链管理中的规划问题。", "motivation": "解决供应链管理中数据收集、长期规划制定、动态调整以及确保可解释性、效率和可靠性的挑战性问题。", "method": "构建一个供应链规划代理（SCPA）框架，利用大型语言模型理解领域知识、分解任务、创建工具并生成基于证据的规划报告。", "result": "框架能够部署并处理供应链规划任务，但具体结果未在摘要中详细说明。", "conclusion": "该框架为供应链规划提供了新的AI驱动方法，具有实际应用潜力。"}}
{"id": "2509.03827", "title": "What Would an LLM Do? Evaluating Policymaking Capabilities of Large Language Models", "authors": ["Pierre Le Coz", "Jia An Liu", "Debarun Bhattacharjya", "Georgina Curto", "Serge Stinckwich"], "abstract": "Large language models (LLMs) are increasingly being adopted in high-stakes domains. Their capacity to process vast amounts of unstructured data, explore flexible scenarios, and handle a diversity of contextual factors can make them uniquely suited to provide new insights for the complexity of social policymaking. This article evaluates whether LLMs' are aligned with domain experts (and among themselves) to inform social policymaking on the subject of homelessness alleviation - a challenge affecting over 150 million people worldwide. We develop a novel benchmark comprised of decision scenarios with policy choices across four geographies (South Bend, USA; Barcelona, Spain; Johannesburg, South Africa; Macau SAR, China). The policies in scope are grounded in the conceptual framework of the Capability Approach for human development. We also present an automated pipeline that connects the benchmarked policies to an agent-based model, and we explore the social impact of the recommended policies through simulated social scenarios. The paper results reveal promising potential to leverage LLMs for social policy making. If responsible guardrails and contextual calibrations are introduced in collaboration with local domain experts, LLMs can provide humans with valuable insights, in the form of alternative policies at scale.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03827.pdf", "abstract_url": "https://arxiv.org/abs/2509.03827", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文评估大型语言模型在无家可归政策制定中的能力，开发基于能力方法的基准测试和自动化管道，显示LLMs在负责任使用时能提供有价值的政策见解。", "motivation": "解决LLMs在高风险领域（如社会政策制定）的应用问题，评估其是否与领域专家一致，以应对全球无家可归挑战。", "method": "开发包含决策场景的基准测试，覆盖四个地区，使用能力方法框架，并连接基于代理的模型进行模拟。", "result": "LLMs显示出在政策制定中的潜力，能提供规模化替代政策，但需负责任护栏和本地专家合作。", "conclusion": "LLMs可在社会政策中提供宝贵见解，强调负责任使用和专家协作的重要性。"}}
{"id": "2509.03817", "title": "Learning to Deliberate: Meta-policy Collaboration for Agentic LLMs with Multi-agent Reinforcement Learning", "authors": ["Wei Yang", "Jesse Thomason"], "abstract": "Multi-agent systems of large language models (LLMs) show promise for complex reasoning, but their effectiveness is often limited by fixed collaboration protocols. These frameworks typically focus on macro-level orchestration while overlooking agents' internal deliberative capabilities. This critical meta-cognitive blindspot treats agents as passive executors unable to adapt their strategy based on internal cognitive states like uncertainty or confidence. We introduce the Meta-Policy Deliberation Framework (MPDF), where agents learn a decentralized policy over a set of high-level meta-cognitive actions: Persist, Refine, and Concede. To overcome the instability of traditional policy gradients in this setting, we develop SoftRankPO, a novel reinforcement learning algorithm. SoftRankPO stabilizes training by shaping advantages based on the rank of rewards mapped through smooth normal quantiles, making the learning process robust to reward variance. Experiments show that MPDF with SoftRankPO achieves a a 4-5% absolute gain in average accuracy across five mathematical and general reasoning benchmarks compared to six state-of-the-art heuristic and learning-based multi-agent reasoning algorithms. Our work presents a paradigm for learning adaptive, meta-cognitive policies for multi-agent LLM systems, shifting the focus from designing fixed protocols to learning dynamic, deliberative strategies.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03817.pdf", "abstract_url": "https://arxiv.org/abs/2509.03817", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种元策略审议框架（MPDF）和SoftRankPO算法，通过多智能体强化学习使LLM智能体学习自适应元认知策略，在多个推理基准上实现4-5%的绝对准确率提升。", "motivation": "解决多智能体LLM系统中固定协作协议限制智能体内部审议能力的问题，智能体无法基于不确定性或置信度等内部认知状态调整策略。", "method": "使用MPDF框架，智能体学习去中心化策略，包括Persist、Refine和Concede等元认知动作，并开发SoftRankPO算法通过平滑正态分位数映射奖励排名来稳定强化学习训练。", "result": "在五个数学和通用推理基准上，MPDF与SoftRankPO相比六种最先进的多智能体推理算法，平均准确率绝对提升4-5%。", "conclusion": "工作展示了学习自适应、元认知策略的范式，将焦点从设计固定协议转向学习动态审议策略，提升多智能体LLM系统的推理能力。"}}
{"id": "2509.03787", "title": "Evaluating the Robustness of Retrieval-Augmented Generation to Adversarial Evidence in the Health Domain", "authors": ["Shakiba Amirshahi", "Amin Bigdeli", "Charles L. A. Clarke", "Amira Ghenai"], "abstract": "Retrieval augmented generation (RAG) systems provide a method for factually grounding the responses of a Large Language Model (LLM) by providing retrieved evidence, or context, as support. Guided by this context, RAG systems can reduce hallucinations and expand the ability of LLMs to accurately answer questions outside the scope of their training data. Unfortunately, this design introduces a critical vulnerability: LLMs may absorb and reproduce misinformation present in retrieved evidence. This problem is magnified if retrieved evidence contains adversarial material explicitly intended to promulgate misinformation. This paper presents a systematic evaluation of RAG robustness in the health domain and examines alignment between model outputs and ground-truth answers. We focus on the health domain due to the potential for harm caused by incorrect responses, as well as the availability of evidence-based ground truth for many common health-related questions. We conduct controlled experiments using common health questions, varying both the type and composition of the retrieved documents (helpful, harmful, and adversarial) as well as the framing of the question by the user (consistent, neutral, and inconsistent). Our findings reveal that adversarial documents substantially degrade alignment, but robustness can be preserved when helpful evidence is also present in the retrieval pool. These findings offer actionable insights for designing safer RAG systems in high-stakes domains by highlighting the need for retrieval safeguards. To enable reproducibility and facilitate future research, all experimental results are publicly available in our github repository.", "subjects": "Information Retrieval (cs.IR); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03787.pdf", "abstract_url": "https://arxiv.org/abs/2509.03787", "categories": ["Information Retrieval (cs.IR)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "评估检索增强生成在健康领域对抗性证据的鲁棒性，发现对抗性文档降低对齐，但存在有益证据时可保持鲁棒性。", "motivation": "解决RAG系统因检索证据中的错误信息而可能传播错误的问题，特别是在高风险的健康领域。", "method": "使用控制实验，变化检索文档类型（有益、有害、对抗性）和问题框架（一致、中性、不一致），评估模型输出与真实答案的对齐。", "result": "对抗性文档显著降低对齐，但如果有益证据存在，鲁棒性得以保持。", "conclusion": "强调需要检索保障措施，以设计更安全的RAG系统，特别是在高风险领域，所有结果公开以促进研究。"}}
{"id": "2509.04027", "title": "CoT-Space: A Theoretical Framework for Internal Slow-Thinking via Reinforcement Learning", "authors": ["Zeyu Gan", "Hao Yi", "Yong Liu"], "abstract": "Reinforcement Learning (RL) has become a pivotal approach for enhancing the reasoning capabilities of Large Language Models (LLMs). However, a significant theoretical gap persists, as traditional token-level RL frameworks fail to align with the reasoning-level nature of complex, multi-step thought processes like Chain-of-Thought (CoT). To address this challenge, we introduce CoT-Space, a novel theoretical framework that recasts LLM reasoning from a discrete token-prediction task to an optimization process within a continuous, reasoning-level semantic space. By analyzing this process from both a noise perspective and a risk perspective, we demonstrate that the convergence to an optimal CoT length is a natural consequence of the fundamental trade-off between underfitting and overfitting. Furthermore, extensive experiments provide strong empirical validation for our theoretical findings. Our framework not only provides a coherent explanation for empirical phenomena such as overthinking but also offers a solid theoretical foundation to guide the future development of more effective and generalizable reasoning agents.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "Preprint Edition", "pdf_url": "https://arxiv.org/pdf/2509.04027.pdf", "abstract_url": "https://arxiv.org/abs/2509.04027", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "CoT-Space是一个理论框架，通过强化学习将LLM推理从离散标记预测重新定义为连续语义空间中的优化过程，解释并验证了最优CoT长度的收敛性。", "motivation": "解决传统强化学习框架在复杂多步推理（如Chain-of-Thought）中与推理级别不匹配的理论空白。", "method": "引入CoT-Space框架，从噪声和风险角度分析推理过程，将推理视为连续语义空间中的优化。", "result": "实验验证了理论发现，表明最优CoT长度是欠拟合和过拟合权衡的自然结果，并解释了如过度思考等经验现象。", "conclusion": "该框架为未来开发更有效和可泛化的推理代理提供了坚实的理论基础。"}}
{"id": "2509.04343", "title": "Psychologically Enhanced AI Agents", "authors": ["Maciej Besta", "Shriram Chandran", "Robert Gerstenberger", "Mathis Lindner", "Marcin Chrapek", "Sebastian Hermann Martschat", "Taraneh Ghandi", "Patrick Iff", "Hubert Niewiadomski", "Piotr Nyczyk", "Jürgen Müller", "Torsten Hoefler"], "abstract": "We introduce MBTI-in-Thoughts, a framework for enhancing the effectiveness of Large Language Model (LLM) agents through psychologically grounded personality conditioning. Drawing on the Myers-Briggs Type Indicator (MBTI), our method primes agents with distinct personality archetypes via prompt engineering, enabling control over behavior along two foundational axes of human psychology, cognition and affect. We show that such personality priming yields consistent, interpretable behavioral biases across diverse tasks: emotionally expressive agents excel in narrative generation, while analytically primed agents adopt more stable strategies in game-theoretic settings. Our framework supports experimenting with structured multi-agent communication protocols and reveals that self-reflection prior to interaction improves cooperation and reasoning quality. To ensure trait persistence, we integrate the official 16Personalities test for automated verification. While our focus is on MBTI, we show that our approach generalizes seamlessly to other psychological frameworks such as Big Five, HEXACO, or Enneagram. By bridging psychological theory and LLM behavior design, we establish a foundation for psychologically enhanced AI agents without any fine-tuning.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computers and Society (cs.CY); Human-Computer Interaction (cs.HC); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.04343.pdf", "abstract_url": "https://arxiv.org/abs/2509.04343", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Computers and Society (cs.CY)", "Human-Computer Interaction (cs.HC)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "MBTI-in-Thoughts框架通过基于MBTI的人格条件化提示工程，增强LLM代理的有效性，实现无微调的心理增强AI代理。", "motivation": "解决如何通过心理学理论增强大型语言模型代理的行为一致性和可解释性，以控制其在认知和情感轴上的行为。", "method": "使用Myers-Briggs Type Indicator（MBTI）进行提示工程，通过人格原型条件化代理，并集成16Personalities测试进行自动化验证。", "result": "人格条件化在多样任务中产生一致的行为偏差，如情感表达代理在叙事生成中表现优异，分析型代理在博弈论设置中采用更稳定策略，且自我反思提升合作和推理质量。", "conclusion": "该框架为心理增强AI代理奠定了基础，可推广到其他心理学框架如Big Five，无需微调即可实现行为控制。"}}
{"id": "2509.03828", "title": "An Agentic Model Context Protocol Framework for Medical Concept Standardization", "authors": ["Jaerong Ahn", "Andrew Wen", "Nan Wang", "Heling Jia", "Zhiyi Yue", "Sunyang Fu", "Hongfang Liu"], "abstract": "The Observational Medical Outcomes Partnership (OMOP) common data model (CDM) provides a standardized representation of heterogeneous health data to support large-scale, multi-institutional research. One critical step in data standardization using OMOP CDM is the mapping of source medical terms to OMOP standard concepts, a procedure that is resource-intensive and error-prone. While large language models (LLMs) have the potential to facilitate this process, their tendency toward hallucination makes them unsuitable for clinical deployment without training and expert validation. Here, we developed a zero-training, hallucination-preventive mapping system based on the Model Context Protocol (MCP), a standardized and secure framework allowing LLMs to interact with external resources and tools. The system enables explainable mapping and significantly improves efficiency and accuracy with minimal effort. It provides real-time vocabulary lookups and structured reasoning outputs suitable for immediate use in both exploratory and production environments.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03828.pdf", "abstract_url": "https://arxiv.org/abs/2509.03828", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "开发了一种基于模型上下文协议（MCP）的零训练、防幻觉映射系统，用于OMOP CDM中的医学术语标准化，提高效率和准确性。", "motivation": "解决OMOP CDM中源医学术语映射到标准概念时资源密集和易出错的问题，同时应对大语言模型（LLMs）的幻觉倾向，使其适合临床部署。", "method": "使用模型上下文协议（MCP）框架，允许LLMs与外部资源和工具交互，实现零训练、防幻觉的映射，包括实时词汇查找和结构化推理输出。", "result": "系统显著提高了映射效率和准确性，提供可解释的映射结果，适用于探索和生产环境，无需专家验证。", "conclusion": "该系统为医疗数据标准化提供了一种高效、可靠的解决方案，支持大规模多机构研究，并可直接部署于临床环境。"}}
{"id": "2509.03890", "title": "FaMA: LLM-Empowered Agentic Assistant for Consumer-to-Consumer Marketplace", "authors": ["Yineng Yan", "Xidong Wang", "Jin Seng Cheng", "Ran Hu", "Wentao Guan", "Nahid Farahmand", "Hengte Lin", "Yue Li"], "abstract": "The emergence of agentic AI, powered by Large Language Models (LLMs), marks a paradigm shift from reactive generative systems to proactive, goal-oriented autonomous agents capable of sophisticated planning, memory, and tool use. This evolution presents a novel opportunity to address long-standing challenges in complex digital environments. Core tasks on Consumer-to-Consumer (C2C) e-commerce platforms often require users to navigate complex Graphical User Interfaces (GUIs), making the experience time-consuming for both buyers and sellers. This paper introduces a novel approach to simplify these interactions through an LLM-powered agentic assistant. This agent functions as a new, conversational entry point to the marketplace, shifting the primary interaction model from a complex GUI to an intuitive AI agent. By interpreting natural language commands, the agent automates key high-friction workflows. For sellers, this includes simplified updating and renewal of listings, and the ability to send bulk messages. For buyers, the agent facilitates a more efficient product discovery process through conversational search. We present the architecture for Facebook Marketplace Assistant (FaMA), arguing that this agentic, conversational paradigm provides a lightweight and more accessible alternative to traditional app interfaces, allowing users to manage their marketplace activities with greater efficiency. Experiments show FaMA achieves a 98% task success rate on solving complex tasks on the marketplace and enables up to a 2x speedup on interaction time.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03890.pdf", "abstract_url": "https://arxiv.org/abs/2509.03890", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "FaMA是一个基于LLM的智能助手，旨在简化C2C电子商务平台的用户交互，通过自然语言命令自动化高摩擦工作流，实验显示任务成功率达98%，交互时间缩短一半。", "motivation": "解决C2C平台用户因复杂GUI导致的交互耗时问题，提升买家和卖家的效率。", "method": "开发LLM驱动的智能助手，通过自然语言解释和自动化关键工作流，如卖家更新列表和买家对话搜索。", "result": "FaMA在复杂任务上达到98%的成功率，交互时间最多减少2倍。", "conclusion": "FaMA提供了一种轻量级、易访问的替代方案，能显著提升市场平台的管理效率。"}}
{"id": "2509.03956", "title": "World Model Implanting for Test-time Adaptation of Embodied Agents", "authors": ["Minjong Yoo", "Jinwoo Jang", "Sihyung Yoon", "Honguk Woo"], "abstract": "In embodied AI, a persistent challenge is enabling agents to robustly adapt to novel domains without requiring extensive data collection or retraining. To address this, we present a world model implanting framework (WorMI) that combines the reasoning capabilities of large language models (LLMs) with independently learned, domain-specific world models through test-time composition. By allowing seamless implantation and removal of the world models, the embodied agent's policy achieves and maintains cross-domain adaptability. In the WorMI framework, we employ a prototype-based world model retrieval approach, utilizing efficient trajectory-based abstract representation matching, to incorporate relevant models into test-time composition. We also develop a world-wise compound attention method that not only integrates the knowledge from the retrieved world models but also aligns their intermediate representations with the reasoning model's representation within the agent's policy. This framework design effectively fuses domain-specific knowledge from multiple world models, ensuring robust adaptation to unseen domains. We evaluate our WorMI on the VirtualHome and ALFWorld benchmarks, demonstrating superior zero-shot and few-shot performance compared to several LLM-based approaches across a range of unseen domains. These results highlight the frameworks potential for scalable, real-world deployment in embodied agent scenarios where adaptability and data efficiency are essential.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03956.pdf", "abstract_url": "https://arxiv.org/abs/2509.03956", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了世界模型植入框架（WorMI），结合大语言模型和领域特定世界模型，通过测试时组合实现具身代理在未见领域的鲁棒自适应。", "motivation": "解决具身AI中代理在无需大量数据收集或重新训练的情况下，适应新领域的鲁棒性问题。", "method": "使用原型世界模型检索和轨迹抽象表示匹配，结合世界级复合注意力方法，集成多个世界模型知识。", "result": "在VirtualHome和ALFWorld基准测试中，WorMI在零样本和少样本场景下优于其他基于LLM的方法。", "conclusion": "该框架具有可扩展性和数据效率，适用于现实世界具身代理部署。"}}
{"id": "2509.03906", "title": "A Foundation Model for Chest X-ray Interpretation with Grounded Reasoning via Online Reinforcement Learning", "authors": ["Qika Lin", "Yifan Zhu", "Bin Pu", "Ling Huang", "Haoran Luo", "Jingying Ma", "Zhen Peng", "Tianzhe Zhao", "Fangzhi Xu", "Jian Zhang", "Kai He", "Zhonghong Ou", "Swapnil Mishra", "Mengling Feng"], "abstract": "Medical foundation models (FMs) have shown tremendous promise amid the rapid advancements in artificial intelligence (AI) technologies. However, current medical FMs typically generate answers in a black-box manner, lacking transparent reasoning processes and locally grounded interpretability, which hinders their practical clinical deployments. To this end, we introduce DeepMedix-R1, a holistic medical FM for chest X-ray (CXR) interpretation. It leverages a sequential training pipeline: initially fine-tuned on curated CXR instruction data to equip with fundamental CXR interpretation capabilities, then exposed to high-quality synthetic reasoning samples to enable cold-start reasoning, and finally refined via online reinforcement learning to enhance both grounded reasoning quality and generation performance. Thus, the model produces both an answer and reasoning steps tied to the image's local regions for each query. Quantitative evaluation demonstrates substantial improvements in report generation (e.g., 14.54% and 31.32% over LLaVA-Rad and MedGemma) and visual question answering (e.g., 57.75% and 23.06% over MedGemma and CheXagent) tasks. To facilitate robust assessment, we propose Report Arena, a benchmarking framework using advanced language models to evaluate answer quality, further highlighting the superiority of DeepMedix-R1. Expert review of generated reasoning steps reveals greater interpretability and clinical plausibility compared to the established Qwen2.5-VL-7B model (0.7416 vs. 0.2584 overall preference). Collectively, our work advances medical FM development toward holistic, transparent, and clinically actionable modeling for CXR interpretation.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "15 pages", "pdf_url": "https://arxiv.org/pdf/2509.03906.pdf", "abstract_url": "https://arxiv.org/abs/2509.03906", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出DeepMedix-R1，一种基于在线强化学习的胸部X光解释基础模型，通过分步训练提升报告生成和视觉问答性能，并增强可解释性。", "motivation": "解决当前医学基础模型在胸部X光解释中缺乏透明推理过程和局部可解释性的问题，以促进临床实际部署。", "method": "采用序列训练管道：先在CXR指令数据上微调，再使用合成推理样本进行冷启动推理，最后通过在线强化学习优化推理质量和生成性能。", "result": "在报告生成和视觉问答任务上显著优于现有模型（如LLaVA-Rad和MedGemma），并通过专家评审显示更高的可解释性和临床合理性。", "conclusion": "DeepMedix-R1推动了医学基础模型向全面、透明和临床可操作的方向发展，为CXR解释提供了更可靠的AI工具。"}}
{"id": "2509.04100", "title": "Hybrid Reinforcement Learning and Search for Flight Trajectory Planning", "authors": ["Alberto Luise", "Michele Lombardi", "Florent Teichteil Koenigsbuch"], "abstract": "This paper explores the combination of Reinforcement Learning (RL) and search-based path planners to speed up the optimization of flight paths for airliners, where in case of emergency a fast route re-calculation can be crucial. The fundamental idea is to train an RL Agent to pre-compute near-optimal paths based on location and atmospheric data and use those at runtime to constrain the underlying path planning solver and find a solution within a certain distance from the initial guess. The approach effectively reduces the size of the solver's search space, significantly speeding up route optimization. Although global optimality is not guaranteed, empirical results conducted with Airbus aircraft's performance models show that fuel consumption remains nearly identical to that of an unconstrained solver, with deviations typically within 1%. At the same time, computation speed can be improved by up to 50% as compared to using a conventional solver alone.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.04100.pdf", "abstract_url": "https://arxiv.org/abs/2509.04100", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了结合强化学习和搜索的路径规划方法，用于加速航班轨迹优化，在紧急情况下快速重新计算路径。", "motivation": "解决在紧急情况下需要快速优化飞行路径的问题，传统方法计算速度慢。", "method": "训练强化学习代理预计算近最优路径，并用于约束路径规划求解器，缩小搜索空间。", "result": "实验显示燃料消耗与无约束求解器几乎相同（偏差在1%内），计算速度提高高达50%。", "conclusion": "该方法在保持性能的同时显著加速路径优化，适用于实际航空应用。"}}
{"id": "2509.03990", "title": "Meta-Policy Reflexion: Reusable Reflective Memory and Rule Admissibility for Resource-Efficient LLM Agent", "authors": ["Chunlong Wu", "Zhibo Qu"], "abstract": "Large language model (LLM) agents achieve impressive single-task performance but commonly exhibit repeated failures, inefficient exploration, and limited cross-task adaptability. Existing reflective strategies (e.g., Reflexion, ReAct) improve per-episode behavior but typically produce ephemeral, task-specific traces that are not reused across tasks. Reinforcement-learning based alternatives can produce transferable policies but require substantial parameter updates and compute. In this work we introduce Meta-Policy Reflexion (MPR): a hybrid framework that consolidates LLM-generated reflections into a structured, predicate-like Meta-Policy Memory (MPM) and applies that memory at inference time through two complementary mechanisms soft memory-guided decoding and hard rule admissibility checks(HAC). MPR (i) externalizes reusable corrective knowledge without model weight updates, (ii) enforces domain constraints to reduce unsafe or invalid actions, and (iii) retains the adaptability of language-based reflection. We formalize the MPM representation, present algorithms for update and decoding, and validate the approach in a text-based agent environment following the experimental protocol described in the provided implementation (AlfWorld-based). Empirical results reported in the supplied material indicate consistent gains in execution accuracy and robustness when compared to Reflexion baselines; rule admissibility further improves stability. We analyze mechanisms that explain these gains, discuss scalability and failure modes, and outline future directions for multimodal and multi?agent extensions.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03990.pdf", "abstract_url": "https://arxiv.org/abs/2509.03990", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "Meta-Policy Reflexion (MPR) 是一个混合框架，通过结构化元策略内存和规则可接受性检查，提高LLM代理的效率和跨任务适应性，无需权重更新。", "motivation": "解决LLM代理在单任务中重复失败、探索效率低和跨任务适应性差的问题，现有方法如Reflexion和ReAct产生短暂的任务特定痕迹，而强化学习需要大量计算。", "method": "使用Meta-Policy Memory (MPM) 存储LLM生成的反思，通过软内存引导解码和硬规则可接受性检查在推理时应用，无需模型权重更新。", "result": "在文本代理环境中，与Reflexion基线相比，执行准确性和鲁棒性有显著提升，规则可接受性进一步增强了稳定性。", "conclusion": "MPR提供可重用知识、强制领域约束并保持适应性，未来可扩展到多模态和多代理场景。"}}
{"id": "2509.04125", "title": "Analysis of Bluffing by DQN and CFR in Leduc Hold'em Poker", "authors": ["Tarik Zaciragic", "Aske Plaat", "K. Joost Batenburg"], "abstract": "In the game of poker, being unpredictable, or bluffing, is an essential skill. When humans play poker, they bluff. However, most works on computer-poker focus on performance metrics such as win rates, while bluffing is overlooked. In this paper we study whether two popular algorithms, DQN (based on reinforcement learning) and CFR (based on game theory), exhibit bluffing behavior in Leduc Hold'em, a simplified version of poker. We designed an experiment where we let the DQN and CFR agent play against each other while we log their actions. We find that both DQN and CFR exhibit bluffing behavior, but they do so in different ways. Although both attempt to perform bluffs at different rates, the percentage of successful bluffs (where the opponent folds) is roughly the same. This suggests that bluffing is an essential aspect of the game, not of the algorithm. Future work should look at different bluffing styles and at the full game of poker. Code at", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.04125.pdf", "abstract_url": "https://arxiv.org/abs/2509.04125", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文分析了DQN和CFR算法在Leduc Hold'em扑克中的诈唬行为，发现两者均表现出诈唬，但方式不同，成功诈唬率相似，表明诈唬是游戏而非算法的本质。", "motivation": "解决扑克游戏中诈唬行为在计算机算法中被忽视的问题，研究DQN和CFR是否在简化扑克中展现诈唬。", "method": "设计实验让DQN和CFR代理互相对战，记录并分析其行动，比较诈唬行为和成功率。", "result": "DQN和CFR均表现出诈唬行为，但方式各异；成功诈唬率大致相同。", "conclusion": "诈唬是扑克游戏的关键元素，未来工作应探索不同诈唬风格和完整扑克游戏。"}}
{"id": "2509.04317", "title": "Improving Robustness of AlphaZero Algorithms to Test-Time Environment Changes", "authors": ["Isidoro Tamassia", "Wendelin Böhmer"], "abstract": "The AlphaZero framework provides a standard way of combining Monte Carlo planning with prior knowledge provided by a previously trained policy-value neural network. AlphaZero usually assumes that the environment on which the neural network was trained will not change at test time, which constrains its applicability. In this paper, we analyze the problem of deploying AlphaZero agents in potentially changed test environments and demonstrate how the combination of simple modifications to the standard framework can significantly boost performance, even in settings with a low planning budget available. The code is publicly available on GitHub.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.04317.pdf", "abstract_url": "https://arxiv.org/abs/2509.04317", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过简单修改AlphaZero框架，提高其在测试环境变化时的鲁棒性，并在低规划预算下显著提升性能。", "motivation": "解决AlphaZero在测试环境变化时性能下降的问题，扩展其应用范围。", "method": "结合蒙特卡洛规划和策略价值神经网络，对标准框架进行简单修改。", "result": "修改后的方法显著提高了在变化测试环境中的性能，即使规划预算较低。", "conclusion": "这些修改增强了AlphaZero的适应性和实用性，代码已公开。"}}
{"id": "2509.04310", "title": "EvoEmo: Towards Evolved Emotional Policies for LLM Agents in Multi-Turn Negotiation", "authors": ["Yunbo Long", "Liming Xu", "Lukas Beckenbauer", "Yuhan Liu", "Alexandra Brintrup"], "abstract": "Recent research on Chain-of-Thought (CoT) reasoning in Large Language Models (LLMs) has demonstrated that agents can engage in \\textit{complex}, \\textit{multi-turn} negotiations, opening new avenues for agentic AI. However, existing LLM agents largely overlook the functional role of emotions in such negotiations, instead generating passive, preference-driven emotional responses that make them vulnerable to manipulation and strategic exploitation by adversarial counterparts. To address this gap, we present EvoEmo, an evolutionary reinforcement learning framework that optimizes dynamic emotional expression in negotiations. EvoEmo models emotional state transitions as a Markov Decision Process and employs population-based genetic optimization to evolve high-reward emotion policies across diverse negotiation scenarios. We further propose an evaluation framework with two baselines -- vanilla strategies and fixed-emotion strategies -- for benchmarking emotion-aware negotiation. Extensive experiments and ablation studies show that EvoEmo consistently outperforms both baselines, achieving higher success rates, higher efficiency, and increased buyer savings. This findings highlight the importance of adaptive emotional expression in enabling more effective LLM agents for multi-turn negotiation.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.04310.pdf", "abstract_url": "https://arxiv.org/abs/2509.04310", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "EvoEmo 是一个进化强化学习框架，通过优化动态情感表达，提升大型语言模型代理在多轮谈判中的性能，超越基线方法。", "motivation": "现有大型语言模型代理在谈判中忽视情感功能，产生被动情感响应，易受对手操纵和利用。", "method": "使用马尔可夫决策过程建模情感状态转换，并采用基于种群的遗传优化来演化高奖励情感策略。", "result": "实验显示 EvoEmo 在成功率、效率和买家节省方面均优于基线方法。", "conclusion": "自适应情感表达对提升大型语言模型代理在多轮谈判中的有效性至关重要。"}}
{"id": "2509.03741", "title": "Designing Gaze Analytics for ELA Instruction: A User-Centered Dashboard with Conversational AI Support", "authors": ["Eduardo Davalos", "Yike Zhang", "Shruti Jain", "Namrata Srivastava", "Trieu Truong", "Nafees-ul Haque", "Tristan Van", "Jorge Salas", "Sara McFadden", "Sun-Joo Cho", "Gautam Biswas", "Amanda Goodwin"], "abstract": "Eye-tracking offers rich insights into student cognition and engagement, but remains underutilized in classroom-facing educational technology due to challenges in data interpretation and accessibility. In this paper, we present the iterative design and evaluation of a gaze-based learning analytics dashboard for English Language Arts (ELA), developed through five studies involving teachers and students. Guided by user-centered design and data storytelling principles, we explored how gaze data can support reflection, formative assessment, and instructional decision-making. Our findings demonstrate that gaze analytics can be approachable and pedagogically valuable when supported by familiar visualizations, layered explanations, and narrative scaffolds. We further show how a conversational agent, powered by a large language model (LLM), can lower cognitive barriers to interpreting gaze data by enabling natural language interactions with multimodal learning analytics. We conclude with design implications for future EdTech systems that aim to integrate novel data modalities in classroom contexts.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": "22 pages, 9 figures, 3 tables, submitted to IUI2026", "pdf_url": "https://arxiv.org/pdf/2509.03741.pdf", "abstract_url": "https://arxiv.org/abs/2509.03741", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过用户中心设计和数据叙事原则，迭代开发并评估了用于英语语言艺术教学的注视分析仪表板，结合对话AI降低数据解读障碍。", "motivation": "解决眼动追踪数据在课堂教育技术中因解读困难和可访问性低而未被充分利用的问题。", "method": "采用用户中心设计和数据叙事原则，通过五项涉及教师和学生的研究进行迭代设计和评估，并集成大型语言模型驱动的对话代理。", "result": "发现注视分析在熟悉可视化、分层解释和叙事支架支持下具有可接近性和教学价值，对话代理通过自然语言交互降低认知障碍。", "conclusion": "为未来教育技术系统整合新颖数据模态提供了设计启示，强调用户友好和AI辅助的重要性。"}}
{"id": "2509.03771", "title": "Learning an Adversarial World Model for Automated Curriculum Generation in MARL", "authors": ["Brennen Hill"], "abstract": "World models that infer and predict environmental dynamics are foundational to embodied intelligence. However, their potential is often limited by the finite complexity and implicit biases of hand-crafted training environments. To develop truly generalizable and robust agents, we need environments that scale in complexity alongside the agents learning within them. In this work, we reframe the challenge of environment generation as the problem of learning a goal-conditioned, generative world model. We propose a system where a generative **Attacker** agent learns an implicit world model to synthesize increasingly difficult challenges for a team of cooperative **Defender** agents. The Attacker's objective is not passive prediction, but active, goal-driven interaction: it models and generates world states (i.e., configurations of enemy units) specifically to exploit the Defenders' weaknesses. Concurrently, the embodied Defender team learns a cooperative policy to overcome these generated worlds. This co-evolutionary dynamic creates a self-scaling curriculum where the world model continuously adapts to challenge the decision-making policy of the agents, providing an effectively infinite stream of novel and relevant training scenarios. We demonstrate that this framework leads to the emergence of complex behaviors, such as the world model learning to generate flanking and shielding formations, and the defenders learning coordinated focus-fire and spreading tactics. Our findings position adversarial co-evolution as a powerful method for learning instrumental world models that drive agents toward greater strategic depth and robustness.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03771.pdf", "abstract_url": "https://arxiv.org/abs/2509.03771", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种通过对抗性共同进化学习目标条件生成世界模型的方法，用于多智能体强化学习中的自动课程生成，以创建无限复杂和相关的训练场景。", "motivation": "解决手工艺训练环境有限复杂性和隐含偏见的问题，以开发更通用和鲁棒的智能体。", "method": "使用生成性攻击者智能体学习隐式世界模型，生成逐渐困难的挑战，同时防御者智能体学习协作策略，形成共同进化动态。", "result": "框架导致复杂行为的出现，如世界模型生成侧翼和屏蔽阵型，防御者学习协调集火和分散战术。", "conclusion": "对抗性共同进化是学习工具性世界模型的有效方法，推动智能体实现更大的战略深度和鲁棒性。"}}
{"id": "2509.03780", "title": "Natural Latents: Latent Variables Stable Across Ontologies", "authors": ["John Wentworth", "David Lorell"], "abstract": "Suppose two Bayesian agents each learn a generative model of the same environment. We will assume the two have converged on the predictive distribution, i.e. distribution over some observables in the environment, but may have different generative models containing different latent variables. Under what conditions can one agent guarantee that their latents are a function of the other agents latents?", "subjects": "Probability (math.PR); Artificial Intelligence (cs.AI); Information Theory (cs.IT); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03780.pdf", "abstract_url": "https://arxiv.org/abs/2509.03780", "categories": ["Probability (math.PR)", "Artificial Intelligence (cs.AI)", "Information Theory (cs.IT)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了在不同生成模型中，当两个贝叶斯代理学习同一环境的预测分布时，一个代理的潜在变量在何种条件下能保证是另一个代理潜在变量的函数。", "motivation": "解决在不同本体论下，潜在变量是否稳定和可比较的问题，以确保代理间潜在变量的一致性。", "method": "使用贝叶斯方法和生成模型分析，假设代理收敛于相同的预测分布，但可能有不同的潜在变量结构。", "result": "识别了条件，使得一个代理的潜在变量可以表示为另一个代理潜在变量的函数。", "conclusion": "结论是，在特定条件下，潜在变量可以跨本体论稳定，这有助于代理间知识共享和模型对齐。"}}
{"id": "2509.03793", "title": "SAMVAD: A Multi-Agent System for Simulating Judicial Deliberation Dynamics in India", "authors": ["Prathamesh Devadiga", "Omkaar Jayadev Shetty", "Pooja Agarwal"], "abstract": "Understanding the complexities of judicial deliberation is crucial for assessing the efficacy and fairness of a justice system. However, empirical studies of judicial panels are constrained by significant ethical and practical barriers. This paper introduces SAMVAD, an innovative Multi-Agent System (MAS) designed to simulate the deliberation process within the framework of the Indian justice system.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.03793.pdf", "abstract_url": "https://arxiv.org/abs/2509.03793", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "SAMVAD是一个多代理系统，用于模拟印度司法系统中的审议过程，以克服伦理和实践障碍。", "motivation": "解决司法审议研究中的伦理和实践限制问题。", "method": "使用多代理系统（MAS）来模拟审议过程。", "result": "开发了SAMVAD系统，用于模拟印度司法审议动态。", "conclusion": "SAMVAD有助于评估司法系统的效能和公平性。"}}
{"id": "2509.03834", "title": "From Leiden to Pleasure Island: The Constant Potts Model for Community Detection as a Hedonic Game", "authors": ["Lucas Lopes Felipe", "Konstantin Avrachenkov", "Daniel Sadoc Menasche"], "abstract": "Community detection is one of the fundamental problems in data science which consists of partitioning nodes into disjoint communities. We present a game-theoretic perspective on the Constant Potts Model (CPM) for partitioning networks into disjoint communities, emphasizing its efficiency, robustness, and accuracy. Efficiency: We reinterpret CPM as a potential hedonic game by decomposing its global Hamiltonian into local utility functions, where the local utility gain of each agent matches the corresponding increase in global utility. Leveraging this equivalence, we prove that local optimization of the CPM objective via better-response dynamics converges in pseudo-polynomial time to an equilibrium partition. Robustness: We introduce and relate two stability criteria: a strict criterion based on a novel notion of robustness, requiring nodes to simultaneously maximize neighbors and minimize non-neighbors within communities, and a relaxed utility function based on a weighted sum of these objectives, controlled by a resolution parameter. Accuracy: In community tracking scenarios, where initial partitions are used to bootstrap the Leiden algorithm with partial ground-truth information, our experiments reveal that robust partitions yield higher accuracy in recovering ground-truth communities.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT)", "comments": "Manuscript submitted to Physica A: Statistical Mechanics and its Applications", "pdf_url": "https://arxiv.org/pdf/2509.03834.pdf", "abstract_url": "https://arxiv.org/abs/2509.03834", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computer Science and Game Theory (cs.GT)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文从博弈论角度分析恒定Potts模型（CPM）用于社区检测，将其重新解释为潜在享乐博弈，证明局部优化在伪多项式时间内收敛，并引入稳定性标准以提高在社区追踪中的准确性。", "motivation": "解决社区检测问题，特别是如何高效、鲁棒和准确地划分网络节点到不相交社区，通过博弈论视角改进现有方法。", "method": "将CPM的全局Hamiltonian分解为局部效用函数，使用更好响应动态进行局部优化，并引入基于邻居和非邻居计数的稳定性标准。", "result": "实验显示，鲁棒分区在社区追踪场景中能更准确地恢复真实社区，且优化过程在伪多项式时间内收敛到均衡分区。", "conclusion": "CPM的博弈论重释提供了高效、鲁棒的社区检测方法，适用于实际数据科学应用，提升了准确性和稳定性。"}}
{"id": "2509.04139", "title": "Enhancing Technical Documents Retrieval for RAG", "authors": ["Songjiang Lai", "Tsun-Hin Cheung", "Ka-Chun Fung", "Kaiwen Xue", "Kwan-Ho Lin", "Yan-Ming Choi", "Vincent Ng", "Kin-Man Lam"], "abstract": "In this paper, we introduce Technical-Embeddings, a novel framework designed to optimize semantic retrieval in technical documentation, with applications in both hardware and software development. Our approach addresses the challenges of understanding and retrieving complex technical content by leveraging the capabilities of Large Language Models (LLMs). First, we enhance user queries by generating expanded representations that better capture user intent and improve dataset diversity, thereby enriching the fine-tuning process for embedding models. Second, we apply summary extraction techniques to encode essential contextual information, refining the representation of technical documents. To further enhance retrieval performance, we fine-tune a bi-encoder BERT model using soft prompting, incorporating separate learning parameters for queries and document context to capture fine-grained semantic nuances. We evaluate our approach on two public datasets, RAG-EDA and Rust-Docs-QA, demonstrating that Technical-Embeddings significantly outperforms baseline models in both precision and recall. Our findings highlight the effectiveness of integrating query expansion and contextual summarization to enhance information access and comprehension in technical domains. This work advances the state of Retrieval-Augmented Generation (RAG) systems, offering new avenues for efficient and accurate technical document retrieval in engineering and product development workflows.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.04139.pdf", "abstract_url": "https://arxiv.org/abs/2509.04139", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "介绍Technical-Embeddings框架，通过查询扩展和上下文摘要优化技术文档语义检索，在RAG-EDA和Rust-Docs-QA数据集上显著提升精确率和召回率。", "motivation": "解决技术文档中复杂内容的检索和理解挑战，以改进RAG系统在硬件和软件开发中的应用。", "method": "利用LLM增强查询表示、应用摘要提取编码上下文，并微调BERT双编码器模型，使用软提示和分离学习参数捕获语义细节。", "result": "在公开数据集上显著优于基线模型，提高了检索性能的精确率和召回率。", "conclusion": "集成查询扩展和上下文摘要有效提升技术领域信息访问，推动RAG系统发展，为工程和产品开发提供高效准确检索方案。"}}
{"id": "2509.03845", "title": "Meta-Inverse Reinforcement Learning for Mean Field Games via Probabilistic Context Variables", "authors": ["Yang Chen", "Xiao Lin", "Bo Yan", "Libo Zhang", "Jiamou Liu", "Neset Özkan Tan", "Michael Witbrock"], "abstract": "Designing suitable reward functions for numerous interacting intelligent agents is challenging in real-world applications. Inverse reinforcement learning (IRL) in mean field games (MFGs) offers a practical framework to infer reward functions from expert demonstrations. While promising, the assumption of agent homogeneity limits the capability of existing methods to handle demonstrations with heterogeneous and unknown objectives, which are common in practice. To this end, we propose a deep latent variable MFG model and an associated IRL method. Critically, our method can infer rewards from different yet structurally similar tasks without prior knowledge about underlying contexts or modifying the MFG model itself. Our experiments, conducted on simulated scenarios and a real-world spatial taxi-ride pricing problem, demonstrate the superiority of our approach over state-of-the-art IRL methods in MFGs.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT)", "comments": "Accepted to AAAI 2024", "pdf_url": "https://arxiv.org/pdf/2509.03845.pdf", "abstract_url": "https://arxiv.org/abs/2509.03845", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computer Science and Game Theory (cs.GT)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于概率上下文变量的元逆强化学习方法，用于平均场博弈，能够从专家演示中推断奖励函数，处理异构和未知目标，无需先验知识或修改模型，在模拟和真实场景中优于现有方法。", "motivation": "解决在平均场博弈中设计奖励函数的挑战，特别是处理具有异构和未知目标的专家演示，这在实践中常见但现有方法因假设代理同质性而受限。", "method": "提出了一种深度潜在变量平均场博弈模型和相关的逆强化学习方法，利用概率上下文变量从结构相似但不同的任务中推断奖励，无需先验上下文知识。", "result": "在模拟场景和真实世界出租车定价问题上的实验表明，该方法优于最先进的平均场博弈逆强化学习方法。", "conclusion": "该方法扩展了逆强化学习在平均场博弈中的应用，能够有效处理异构目标，具有实际应用潜力。"}}
{"id": "2509.04303", "title": "HumAIne-Chatbot: Real-Time Personalized Conversational AI via Reinforcement Learning", "authors": ["Georgios Makridis", "Georgios Fragiadakis", "Jorge Oliveira", "Tomaz Saraiva", "Philip Mavrepis", "Georgios Fatouros", "Dimosthenis Kyriazis"], "abstract": "Current conversational AI systems often provide generic, one-size-fits-all interactions that overlook individual user characteristics and lack adaptive dialogue management. To address this gap, we introduce \\textbf{HumAIne-chatbot}, an AI-driven conversational agent that personalizes responses through a novel user profiling framework. The system is pre-trained on a diverse set of GPT-generated virtual personas to establish a broad prior over user types. During live interactions, an online reinforcement learning agent refines per-user models by combining implicit signals (e.g. typing speed, sentiment, engagement duration) with explicit feedback (e.g., likes and dislikes). This profile dynamically informs the chatbot dialogue policy, enabling real-time adaptation of both content and style. To evaluate the system, we performed controlled experiments with 50 synthetic personas in multiple conversation domains. The results showed consistent improvements in user satisfaction, personalization accuracy, and task achievement when personalization features were enabled. Statistical analysis confirmed significant differences between personalized and nonpersonalized conditions, with large effect sizes across key metrics. These findings highlight the effectiveness of AI-driven user profiling and provide a strong foundation for future real-world validation.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": "11 pages, 4 figures, IEEE conference format", "pdf_url": "https://arxiv.org/pdf/2509.04303.pdf", "abstract_url": "https://arxiv.org/abs/2509.04303", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "HumAIne-chatbot 是一种通过强化学习实现实时个性化对话的AI系统，利用用户画像和在线学习提升交互质量。", "motivation": "解决当前对话AI系统通用性强、缺乏个性化适应的问题。", "method": "使用预训练虚拟角色和在线强化学习，结合隐式和显式反馈动态调整对话策略。", "result": "实验显示个性化功能显著提高用户满意度、个性化准确性和任务完成率。", "conclusion": "AI驱动用户画像有效，为实际应用奠定基础。"}}
{"id": "2509.04152", "title": "TAGAL: Tabular Data Generation using Agentic LLM Methods", "authors": ["Benoît Ronval", "Pierre Dupont", "Siegfried Nijssen"], "abstract": "The generation of data is a common approach to improve the performance of machine learning tasks, among which is the training of models for classification. In this paper, we present TAGAL, a collection of methods able to generate synthetic tabular data using an agentic workflow. The methods leverage Large Language Models (LLMs) for an automatic and iterative process that uses feedback to improve the generated data without any further LLM training. The use of LLMs also allows for the addition of external knowledge in the generation process. We evaluate TAGAL across diverse datasets and different aspects of quality for the generated data. We look at the utility of downstream ML models, both by training classifiers on synthetic data only and by combining real and synthetic data. Moreover, we compare the similarities between the real and the generated data. We show that TAGAL is able to perform on par with state-of-the-art approaches that require LLM training and generally outperforms other training-free approaches. These findings highlight the potential of agentic workflow and open new directions for LLM-based data generation methods.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.04152.pdf", "abstract_url": "https://arxiv.org/abs/2509.04152", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "TAGAL 是一种使用代理工作流和大型语言模型生成合成表格数据的方法，无需额外训练，在数据质量和下游机器学习任务中表现优异。", "motivation": "解决机器学习分类任务中数据生成的需求，特别是如何高效、自动地生成高质量表格数据，而无需训练大型语言模型。", "method": "利用大型语言模型（LLMs）的代理工作流，通过自动迭代和反馈机制生成数据，并融入外部知识。", "result": "TAGAL 在多个数据集上评估，生成的数据质量高，下游分类器性能与需要训练的方法相当，优于其他免训练方法，且真实与生成数据相似度高。", "conclusion": "代理工作流在LLM数据生成中潜力巨大，为未来方法开辟新方向，强调免训练方法的有效性。"}}
