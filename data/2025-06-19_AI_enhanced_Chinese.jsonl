{"id": "2506.14831", "title": "Recent Advances in Multi-Agent Human Trajectory Prediction: A Comprehensive Review", "authors": ["Céline Finet", "Stephane Da Silva Martins", "Jean-Bernard Hayet", "Ioannis Karamouzas", "Javad Amirian", "Sylvie Le Hégarat-Mascle", "Julien Pettré", "Emanuel Aldea"], "abstract": "With the emergence of powerful data-driven methods in human trajectory prediction (HTP), gaining a finer understanding of multi-agent interactions lies within hand's reach, with important implications in areas such as autonomous navigation and crowd modeling. This survey reviews some of the most recent advancements in deep learning-based multi-agent trajectory prediction, focusing on studies published between 2020 and 2024. We categorize the existing methods based on their architectural design, their input representations, and their overall prediction strategies, placing a particular emphasis on models evaluated using the ETH/UCY benchmark. Furthermore, we highlight key challenges and future research directions in the field of multi-agent HTP.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Robotics (cs.RO)", "comments": "30 pages", "pdf_url": "https://arxiv.org/pdf/2506.14831.pdf", "abstract_url": "https://arxiv.org/abs/2506.14831", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Machine Learning (cs.LG)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文综述了2020年至2024年间基于深度学习的多智能体人类轨迹预测的最新进展，重点分析了ETH/UCY基准测试中的模型，并探讨了该领域的关键挑战和未来研究方向。", "motivation": "随着数据驱动方法在人类轨迹预测中的兴起，深入理解多智能体互动变得触手可及，这对自主导航和人群建模等领域具有重要意义。", "method": "本文根据架构设计、输入表示和整体预测策略对现有方法进行了分类，特别关注了使用ETH/UCY基准测试评估的模型。", "result": "综述了多智能体人类轨迹预测领域的最新进展，并识别了该领域的关键挑战。", "conclusion": "本文不仅总结了多智能体人类轨迹预测的当前状态，还指出了未来的研究方向，为该领域的进一步发展提供了指导。"}}
{"id": "2506.14990", "title": "MEAL: A Benchmark for Continual Multi-Agent Reinforcement Learning", "authors": ["Tristan Tomilin", "Luka van den Boogaard", "Samuel Garcin", "Bram Grooten", "Meng Fang", "Mykola Pechenizkiy"], "abstract": "Benchmarks play a crucial role in the development and analysis of reinforcement learning (RL) algorithms, with environment availability strongly impacting research. One particularly underexplored intersection is continual learning (CL) in cooperative multi-agent settings. To remedy this, we introduce MEAL (Multi-agent Environments for Adaptive Learning), the first benchmark tailored for continual multi-agent reinforcement learning (CMARL). Existing CL benchmarks run environments on the CPU, leading to computational bottlenecks and limiting the length of task sequences. MEAL leverages JAX for GPU acceleration, enabling continual learning across sequences of 100 tasks on a standard desktop PC in a few hours. We show that naively combining popular CL and MARL methods yields strong performance on simple environments, but fails to scale to more complex settings requiring sustained coordination and adaptation. Our ablation study identifies architectural and algorithmic features critical for CMARL on MEAL.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.14990.pdf", "abstract_url": "https://arxiv.org/abs/2506.14990", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "MEAL是一个专为持续多智能体强化学习（CMARL）设计的基准测试，旨在解决该领域研究不足的问题。通过利用JAX进行GPU加速，MEAL能够在标准桌面PC上几小时内完成100个任务的持续学习序列。研究表明，简单结合现有的持续学习和多智能体强化学习方法在复杂环境中表现不佳，MEAL的消融研究揭示了CMARL关键的结构和算法特征。", "motivation": "解决持续学习（CL）在合作多智能体设置中研究不足的问题，提供一个高效的基准测试以促进相关算法的发展和分析。", "method": "引入MEAL基准测试，利用JAX实现GPU加速，支持在标准桌面PC上快速完成长序列任务的持续学习。", "result": "研究发现，简单结合现有的CL和MARL方法在简单环境中表现良好，但在需要持续协调和适应的复杂环境中表现不佳。消融研究揭示了CMARL成功的关键因素。", "conclusion": "MEAL为持续多智能体强化学习提供了一个高效的基准测试，揭示了在该领域取得成功所需的关键结构和算法特征，为未来的研究指明了方向。"}}
{"id": "2506.15131", "title": "Modeling the One-to-Many Property in Open-Domain Dialogue with LLMs", "authors": ["Jing Yang Lee", "Kong-Aik Lee", "Woon-Seng Gan"], "abstract": "Open-domain Dialogue (OD) exhibits a one-to-many (o2m) property, whereby multiple appropriate responses exist for a single dialogue context. Despite prior research showing that modeling this property boosts response diversity, most modern LLM-based dialogue agents do not explicitly do so. In this work, we model the o2m property of OD in LLMs by decomposing OD generation into two key tasks: Multi-Response Generation (MRG) and Preference-based Selection (PS), which entail generating a set of n semantically and lexically diverse high-quality responses for a given dialogue context, followed by selecting a single response based on human preference, respectively. To facilitate MRG and PS, we introduce o2mDial, a dialogue corpus explicitly designed to capture the o2m property by featuring multiple plausible responses for each context. Leveraging o2mDial, we propose new in-context learning and instruction-tuning strategies, as well as novel evaluation metrics for MRG, alongside a model-based approach for PS. Empirical results demonstrate that applying the proposed two-stage framework to smaller LLMs for OD generation enhances overall response diversity while maintaining contextual coherence, improving response quality by up to 90%, bringing them closer to the performance of larger models.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.15131.pdf", "abstract_url": "https://arxiv.org/abs/2506.15131", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种通过分解开放域对话生成任务为多响应生成和基于偏好的选择两阶段框架，以显式建模开放域对话的一对多属性，并引入o2mDial语料库和新颖的学习策略及评估指标，实证表明该方法能提升较小语言模型的响应多样性和质量。", "motivation": "开放域对话(OD)具有一对多(o2m)属性，即单一对话上下文可对应多个合适的响应。尽管先前研究表明建模此属性可提升响应多样性，但大多数基于大型语言模型(LLM)的对话代理并未显式进行此建模。", "method": "通过将OD生成分解为多响应生成(MRG)和基于偏好的选择(PS)两阶段任务，引入o2mDial语料库，并提出新的上下文学习、指令调整策略及MRG评估指标，以及PS的模型基方法。", "result": "实证结果表明，将提出的两阶段框架应用于较小LLM进行OD生成，能在保持上下文连贯性的同时，显著提升响应多样性，响应质量提升高达90%，使其性能接近更大模型。", "conclusion": "通过显式建模OD的一对多属性，并采用两阶段生成和选择框架，可以有效提升较小LLM在开放域对话中的表现，为开发更高效、多样的对话系统提供了新思路。"}}
{"id": "2506.15207", "title": "Multi-Agent Reinforcement Learning for Autonomous Multi-Satellite Earth Observation: A Realistic Case Study", "authors": ["Mohamad A. Hady", "Siyi Hu", "Mahardhika Pratama", "Jimmy Cao", "Ryszard Kowalczyk"], "abstract": "The exponential growth of Low Earth Orbit (LEO) satellites has revolutionised Earth Observation (EO) missions, addressing challenges in climate monitoring, disaster management, and more. However, autonomous coordination in multi-satellite systems remains a fundamental challenge. Traditional optimisation approaches struggle to handle the real-time decision-making demands of dynamic EO missions, necessitating the use of Reinforcement Learning (RL) and Multi-Agent Reinforcement Learning (MARL). In this paper, we investigate RL-based autonomous EO mission planning by modelling single-satellite operations and extending to multi-satellite constellations using MARL frameworks. We address key challenges, including energy and data storage limitations, uncertainties in satellite observations, and the complexities of decentralised coordination under partial observability. By leveraging a near-realistic satellite simulation environment, we evaluate the training stability and performance of state-of-the-art MARL algorithms, including PPO, IPPO, MAPPO, and HAPPO. Our results demonstrate that MARL can effectively balance imaging and resource management while addressing non-stationarity and reward interdependency in multi-satellite coordination. The insights gained from this study provide a foundation for autonomous satellite operations, offering practical guidelines for improving policy learning in decentralised EO missions.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.15207.pdf", "abstract_url": "https://arxiv.org/abs/2506.15207", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了使用强化学习（RL）和多智能体强化学习（MARL）在低地球轨道（LEO）卫星群中进行自主地球观测（EO）任务规划的可行性，特别是在处理能源和数据存储限制、观测不确定性及分散协调复杂性方面的挑战。", "motivation": "随着低地球轨道卫星数量的指数级增长，地球观测任务在气候监测、灾害管理等领域面临自主协调的挑战。传统优化方法难以满足动态EO任务的实时决策需求。", "method": "研究通过模拟单卫星操作并扩展到多卫星星座，利用MARL框架（包括PPO、IPPO、MAPPO和HAPPO算法）来评估训练稳定性和性能。", "result": "结果表明，MARL能有效平衡成像和资源管理，同时解决多卫星协调中的非平稳性和奖励相互依赖问题。", "conclusion": "本研究为自主卫星操作奠定了基础，为改进分散EO任务中的策略学习提供了实用指南。"}}
{"id": "2506.15225", "title": "Joint Computation Offloading and Resource Allocation for Uncertain Maritime MEC via Cooperation of UAVs and Vessels", "authors": ["Jiahao You", "Ziye Jia", "Chao Dong", "Qihui Wu", "Zhu Han"], "abstract": "The computation demands from the maritime Internet of Things (MIoT) increase rapidly in recent years, and the unmanned aerial vehicles (UAVs) and vessels based multi-access edge computing (MEC) can fulfill these MIoT requirements. However, the uncertain maritime tasks present significant challenges of inefficient computation offloading and resource allocation. In this paper, we focus on the maritime computation offloading and resource allocation through the cooperation of UAVs and vessels, with consideration of uncertain tasks. Specifically, we propose a cooperative MEC framework for computation offloading and resource allocation, including MIoT devices, UAVs and vessels. Then, we formulate the optimization problem to minimize the total execution time. As for the uncertain MIoT tasks, we leverage Lyapunov optimization to tackle the unpredictable task arrivals and varying computational resource availability. \nBy converting the long-term constraints into short-term constraints, we obtain a set of small-scale optimization problems. Further, considering the heterogeneity of actions and resources of UAVs and vessels, we reformulate the small-scale optimization problem into a Markov game (MG). Moreover, a heterogeneous-agent soft actor-critic is proposed to sequentially update various neural networks and effectively solve the MG problem. \nFinally, simulations are conducted to verify the effectiveness in addressing computational offloading and resource allocation.", "subjects": "Artificial Intelligence (cs.AI); Signal Processing (eess.SP)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.15225.pdf", "abstract_url": "https://arxiv.org/abs/2506.15225", "categories": ["Artificial Intelligence (cs.AI)", "Signal Processing (eess.SP)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种通过无人机和船舶合作的海上多接入边缘计算（MEC）框架，用于处理不确定的海上任务的计算卸载和资源分配问题，旨在最小化总执行时间。", "motivation": "海上物联网（MIoT）的计算需求快速增长，但不确定的海上任务给计算卸载和资源分配带来了效率低下的挑战。", "method": "提出了一种合作MEC框架，利用Lyapunov优化处理不确定任务，将长期约束转化为短期约束，并将问题重新表述为马尔可夫游戏（MG），采用异构代理软演员-评论家方法解决。", "result": "仿真验证了所提方法在解决计算卸载和资源分配问题上的有效性。", "conclusion": "通过无人机和船舶的合作，可以有效处理海上MEC中的不确定任务，优化计算卸载和资源分配，提高执行效率。"}}
{"id": "2506.15377", "title": "Efficient and Generalizable Environmental Understanding for Visual Navigation", "authors": ["Ruoyu Wang", "Xinshu Li", "Chen Wang", "Lina Yao"], "abstract": "Visual Navigation is a core task in Embodied AI, enabling agents to navigate complex environments toward given objectives. Across diverse settings within Navigation tasks, many necessitate the modelling of sequential data accumulated from preceding time steps. While existing methods perform well, they typically process all historical observations simultaneously, overlooking the internal association structure within the data, which may limit the potential for further improvements in task performance. We address this by examining the unique characteristics of Navigation tasks through the lens of causality, introducing a causal framework to highlight the limitations of conventional sequential methods. Leveraging this insight, we propose Causality-Aware Navigation (CAN), which incorporates a Causal Understanding Module to enhance the agent's environmental understanding capability. Empirical evaluations show that our approach consistently outperforms baselines across various tasks and simulation environments. Extensive ablations studies attribute these gains to the Causal Understanding Module, which generalizes effectively in both Reinforcement and Supervised Learning settings without computational overhead.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.15377.pdf", "abstract_url": "https://arxiv.org/abs/2506.15377", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种因果感知导航（CAN）方法，通过引入因果理解模块来增强代理的环境理解能力，从而在视觉导航任务中超越现有方法。", "motivation": "解决现有视觉导航方法在处理历史观察数据时忽视内部关联结构，限制任务性能进一步提升的问题。", "method": "通过因果视角分析导航任务的独特特性，提出因果感知导航（CAN）方法，并引入因果理解模块。", "result": "实证评估显示，CAN方法在各种任务和模拟环境中均优于基线方法，且因果理解模块在强化学习和监督学习设置中均能有效泛化，无需额外计算开销。", "conclusion": "CAN方法通过增强环境理解能力，显著提升了视觉导航任务的性能，且具有广泛的适用性和高效性。"}}
{"id": "2506.15567", "title": "Managing Complex Failure Analysis Workflows with LLM-based Reasoning and Acting Agents", "authors": ["Aline Dobrovsky", "Konstantin Schekotihin", "Christian Burmer"], "abstract": "Failure Analysis (FA) is a highly intricate and knowledge-intensive process. The integration of AI components within the computational infrastructure of FA labs has the potential to automate a variety of tasks, including the detection of non-conformities in images, the retrieval of analogous cases from diverse data sources, and the generation of reports from annotated images. However, as the number of deployed AI models increases, the challenge lies in orchestrating these components into cohesive and efficient workflows that seamlessly integrate with the FA process.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.15567.pdf", "abstract_url": "https://arxiv.org/abs/2506.15567", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了在复杂的故障分析(FA)工作流程中，如何利用基于大型语言模型(LLM)的推理和行动代理来管理和协调日益增多的AI组件，以实现自动化任务和提高效率。", "motivation": "故障分析是一个高度复杂和知识密集的过程，随着AI模型数量的增加，如何将这些组件协调成高效且与FA过程无缝集成的工作流程成为一个挑战。", "method": "采用基于大型语言模型(LLM)的推理和行动代理来管理和协调FA工作流程中的AI组件。", "result": "通过LLM-based代理，可以有效地自动化FA过程中的多种任务，包括图像中的非一致性检测、从多样数据源中检索类似案例以及从注释图像生成报告。", "conclusion": "基于LLM的推理和行动代理为解决FA工作流程中AI组件的协调问题提供了有效的解决方案，有望显著提高FA过程的效率和自动化水平。"}}
{"id": "2506.15624", "title": "The Effect of State Representation on LLM Agent Behavior in Dynamic Routing Games", "authors": ["Lyle Goodyear", "Rachel Guo", "Ramesh Johari"], "abstract": "Large Language Models (LLMs) have shown promise as decision-makers in dynamic settings, but their stateless nature necessitates creating a natural language representation of history. We present a unifying framework for systematically constructing natural language \"state\" representations for prompting LLM agents in repeated multi-agent games. Previous work on games with LLM agents has taken an ad hoc approach to encoding game history, which not only obscures the impact of state representation on agents' behavior, but also limits comparability between studies. Our framework addresses these gaps by characterizing methods of state representation along three axes: action informativeness (i.e., the extent to which the state representation captures actions played); reward informativeness (i.e., the extent to which the state representation describes rewards obtained); and prompting style (or natural language compression, i.e., the extent to which the full text history is summarized).", "subjects": "Artificial Intelligence (cs.AI)", "comments": "27 pages, 20 figures", "pdf_url": "https://arxiv.org/pdf/2506.15624.pdf", "abstract_url": "https://arxiv.org/abs/2506.15624", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一个统一的框架，用于在重复多代理游戏中系统地构建自然语言“状态”表示，以提示LLM代理。该框架通过三个维度来表征状态表示的方法：动作信息性、奖励信息性和提示风格。", "motivation": "解决LLM代理在动态设置中作为决策者的无状态性质，以及先前工作中对游戏历史编码的临时方法，这些方法不仅模糊了状态表示对代理行为的影响，还限制了研究之间的可比性。", "method": "通过三个维度（动作信息性、奖励信息性和提示风格）系统地构建自然语言状态表示的统一框架。", "result": "提出了一个框架，能够更系统地构建和比较LLM代理在重复多代理游戏中的状态表示，从而更好地理解和控制代理行为。", "conclusion": "该框架不仅提高了LLM代理在动态路由游戏中的决策质量，还为未来研究提供了可比较的基础，有助于更深入地理解状态表示对代理行为的影响。"}}
{"id": "2506.15672", "title": "SwarmAgentic: Towards Fully Automated Agentic System Generation via Swarm Intelligence", "authors": ["Yao Zhang", "Chenyang Lin", "Shijie Tang", "Haokun Chen", "Shijie Zhou", "Yunpu Ma", "Volker Tresp"], "abstract": "The rapid progress of Large Language Models has advanced agentic systems in decision-making, coordination, and task execution. Yet, existing agentic system generation frameworks lack full autonomy, missing from-scratch agent generation, self-optimizing agent functionality, and collaboration, limiting adaptability and scalability. We propose SwarmAgentic, a framework for fully automated agentic system generation that constructs agentic systems from scratch and jointly optimizes agent functionality and collaboration as interdependent components through language-driven exploration. To enable efficient search over system-level structures, SwarmAgentic maintains a population of candidate systems and evolves them via feedback-guided updates, drawing inspiration from Particle Swarm Optimization (PSO). We evaluate our method on six real-world, open-ended, and exploratory tasks involving high-level planning, system-level coordination, and creative reasoning. Given only a task description and an objective function, SwarmAgentic outperforms all baselines, achieving a +261.8% relative improvement over ADAS on the TravelPlanner benchmark, highlighting the effectiveness of full automation in structurally unconstrained tasks. This framework marks a significant step toward scalable and autonomous agentic system design, bridging swarm intelligence with fully automated system multi-agent generation. Our code is publicly released at", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "41 pages", "pdf_url": "https://arxiv.org/pdf/2506.15672.pdf", "abstract_url": "https://arxiv.org/abs/2506.15672", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了SwarmAgentic框架，旨在通过群体智能实现完全自动化的代理系统生成，解决了现有框架在自主性、自我优化和协作方面的不足。", "motivation": "现有代理系统生成框架缺乏完全自主性，无法实现从零开始的代理生成、自我优化代理功能以及协作，这限制了系统的适应性和可扩展性。", "method": "SwarmAgentic框架通过语言驱动的探索，从零开始构建代理系统，并将代理功能和协作作为相互依赖的组件进行联合优化。受粒子群优化（PSO）启发，该框架通过反馈引导的更新来维护和进化候选系统群体。", "result": "在六个涉及高级规划、系统级协调和创造性推理的真实世界、开放性和探索性任务中，SwarmAgentic仅给定任务描述和目标函数，就超越了所有基线，在TravelPlanner基准测试中实现了相对于ADAS的+261.8%相对改进。", "conclusion": "SwarmAgentic框架标志着向可扩展和自主代理系统设计迈出了重要一步，将群体智能与完全自动化的系统多代理生成相结合。"}}
{"id": "2506.15677", "title": "Embodied Web Agents: Bridging Physical-Digital Realms for Integrated Agent Intelligence", "authors": ["Yining Hong", "Rui Sun", "Bingxuan Li", "Xingcheng Yao", "Maxine Wu", "Alexander Chien", "Da Yin", "Ying Nian Wu", "Zhecan James Wang", "Kai-Wei Chang"], "abstract": "AI agents today are mostly siloed - they either retrieve and reason over vast amount of digital information and knowledge obtained online; or interact with the physical world through embodied perception, planning and action - but rarely both. This separation limits their ability to solve tasks that require integrated physical and digital intelligence, such as cooking from online recipes, navigating with dynamic map data, or interpreting real-world landmarks using web knowledge. We introduce Embodied Web Agents, a novel paradigm for AI agents that fluidly bridge embodiment and web-scale reasoning. To operationalize this concept, we first develop the Embodied Web Agents task environments, a unified simulation platform that tightly integrates realistic 3D indoor and outdoor environments with functional web interfaces. Building upon this platform, we construct and release the Embodied Web Agents Benchmark, which encompasses a diverse suite of tasks including cooking, navigation, shopping, tourism, and geolocation - all requiring coordinated reasoning across physical and digital realms for systematic assessment of cross-domain intelligence. Experimental results reveal significant performance gaps between state-of-the-art AI systems and human capabilities, establishing both challenges and opportunities at the intersection of embodied cognition and web-scale knowledge access. All datasets, codes and websites are publicly available at our project page", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.15677.pdf", "abstract_url": "https://arxiv.org/abs/2506.15677", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Computer Vision and Pattern Recognition (cs.CV)", "Multimedia (cs.MM)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了‘具身网络智能体’的新范式，旨在通过结合物理世界的感知与行动和数字世界的知识检索与推理，解决现有AI智能体在物理与数字领域分离的问题。", "motivation": "当前AI智能体大多局限于单一领域，要么处理数字信息，要么与物理世界互动，这限制了它们在需要结合物理和数字智能的任务中的表现。", "method": "开发了一个统一的模拟平台，集成了真实的3D室内外环境和功能性网络接口，并在此基础上构建了一个包含多样化任务的基准测试。", "result": "实验结果显示，当前最先进的AI系统与人类能力之间存在显著差距，揭示了在具身认知和网络规模知识访问交叉领域的挑战与机遇。", "conclusion": "通过‘具身网络智能体’的提出和相关平台的开发，为AI智能体在物理与数字领域的整合提供了新的研究方向和实践工具。"}}
{"id": "2506.15635", "title": "FindingDory: A Benchmark to Evaluate Memory in Embodied Agents", "authors": ["Karmesh Yadav", "Yusuf Ali", "Gunshi Gupta", "Yarin Gal", "Zsolt Kira"], "abstract": "Large vision-language models have recently demonstrated impressive performance in planning and control tasks, driving interest in their application to real-world robotics. However, deploying these models for reasoning in embodied contexts is limited by their ability to incorporate long-term experience collected across multiple days and represented by vast collections of images. Current VLMs typically struggle to process more than a few hundred images concurrently, highlighting the need for more efficient mechanisms to handle long-term memory in embodied settings. To effectively evaluate these models for long-horizon control, a benchmark must specifically target scenarios where memory is crucial for success. Existing long-video QA benchmarks overlook embodied challenges like object manipulation and navigation, which demand low-level skills and fine-grained reasoning over past interactions. Moreover, effective memory integration in embodied agents involves both recalling relevant historical information and executing actions based on that information, making it essential to study these aspects together rather than in isolation. In this work, we introduce a new benchmark for long-range embodied tasks in the Habitat simulator. This benchmark evaluates memory-based capabilities across 60 tasks requiring sustained engagement and contextual awareness in an environment. The tasks can also be procedurally extended to longer and more challenging versions, enabling scalable evaluation of memory and reasoning. We also present baselines that integrate state-of-the-art VLMs with low level navigation policies, assessing their performance on these memory-intensive tasks and highlight areas for improvement.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2506.15635.pdf", "abstract_url": "https://arxiv.org/abs/2506.15635", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了FindingDory基准测试，用于评估具身代理中的记忆能力，特别是在需要长期记忆和情境意识的60个任务中。", "motivation": "大型视觉语言模型在规划和控制任务中表现出色，但在具身环境中处理长期经验（如多日收集的大量图像）的能力有限，需要更高效的长期记忆机制。", "method": "在Habitat模拟器中引入一个新的基准测试，评估60个需要持续参与和环境意识的任务，这些任务可以程序化扩展到更长和更具挑战性的版本。", "result": "提出了将最先进的视觉语言模型与低级导航策略结合的基线，评估了它们在记忆密集型任务上的表现，并指出了需要改进的领域。", "conclusion": "该基准测试为评估具身代理的长期记忆和推理能力提供了可扩展的方法，并为未来研究指明了方向。"}}
{"id": "2506.15241", "title": "Research on Graph-Retrieval Augmented Generation Based on Historical Text Knowledge Graphs", "authors": ["Yang Fan", "Zhang Qi", "Xing Wenqian", "Liu Chang", "Liu Liu"], "abstract": "This article addresses domain knowledge gaps in general large language models for historical text analysis in the context of computational humanities and AIGC technology. We propose the Graph RAG framework, combining chain-of-thought prompting, self-instruction generation, and process supervision to create a The First Four Histories character relationship dataset with minimal manual annotation. This dataset supports automated historical knowledge extraction, reducing labor costs. In the graph-augmented generation phase, we introduce a collaborative mechanism between knowledge graphs and retrieval-augmented generation, improving the alignment of general models with historical knowledge. Experiments show that the domain-specific model Xunzi-Qwen1.5-14B, with Simplified Chinese input and chain-of-thought prompting, achieves optimal performance in relation extraction (F1 = 0.68). The DeepSeek model integrated with GraphRAG improves F1 by 11% (0.08-0.19) on the open-domain C-CLUE relation extraction dataset, surpassing the F1 value of Xunzi-Qwen1.5-14B (0.12), effectively alleviating hallucinations phenomenon, and improving interpretability. This framework offers a low-resource solution for classical text knowledge extraction, advancing historical knowledge services and humanities research.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.15241.pdf", "abstract_url": "https://arxiv.org/abs/2506.15241", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了Graph RAG框架，结合思维链提示、自指令生成和过程监督，以最小化人工标注创建《前四史》人物关系数据集，支持自动化历史知识提取，降低劳动成本。通过知识图谱与检索增强生成的协作机制，提升通用模型与历史知识的对齐。实验显示，特定领域模型Xunzi-Qwen1.5-14B在关系提取上达到最佳性能（F1 = 0.68），而集成GraphRAG的DeepSeek模型在开放领域C-CLUE关系提取数据集上F1提升11%，有效缓解幻觉现象并提高可解释性。", "motivation": "解决通用大语言模型在历史文本分析中的领域知识缺口问题，特别是在计算人文和AIGC技术背景下。", "method": "提出Graph RAG框架，结合思维链提示、自指令生成和过程监督，创建《前四史》人物关系数据集，并引入知识图谱与检索增强生成的协作机制。", "result": "Xunzi-Qwen1.5-14B在关系提取上达到F1 = 0.68；集成GraphRAG的DeepSeek模型在C-CLUE数据集上F1提升11%，有效缓解幻觉现象并提高可解释性。", "conclusion": "该框架为古典文本知识提取提供了低资源解决方案，推动了历史知识服务和人文研究的进步。"}}
{"id": "2506.15246", "title": "TopClustRAG at SIGIR 2025 LiveRAG Challenge", "authors": ["Juli Bakagianni", "John Pavlopoulos", "Aristidis Likas"], "abstract": "We present TopClustRAG, a retrieval-augmented generation (RAG) system developed for the LiveRAG Challenge, which evaluates end-to-end question answering over large-scale web corpora. Our system employs a hybrid retrieval strategy combining sparse and dense indices, followed by K-Means clustering to group semantically similar passages. Representative passages from each cluster are used to construct cluster-specific prompts for a large language model (LLM), generating intermediate answers that are filtered, reranked, and finally synthesized into a single, comprehensive response. This multi-stage pipeline enhances answer diversity, relevance, and faithfulness to retrieved evidence. Evaluated on the FineWeb Sample-10BT dataset, TopClustRAG ranked 2nd in faithfulness and 7th in correctness on the official leaderboard, demonstrating the effectiveness of clustering-based context filtering and prompt aggregation in large-scale RAG systems.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.15246.pdf", "abstract_url": "https://arxiv.org/abs/2506.15246", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "TopClustRAG是一个为LiveRAG挑战开发的检索增强生成系统，结合稀疏和密集索引的混合检索策略，通过K-Means聚类分组语义相似的段落，生成多样化和相关性强的回答。", "motivation": "解决在大规模网络语料库上进行端到端问答时，如何提高答案的多样性、相关性和对检索证据的忠实度的问题。", "method": "采用混合检索策略结合K-Means聚类，从每个聚类中选择代表性段落构建特定于聚类的提示，生成中间答案后过滤、重新排名并合成为最终回答。", "result": "在FineWeb Sample-10BT数据集上评估，TopClustRAG在忠实度上排名第2，在正确性上排名第7，证明了聚类基于上下文过滤和提示聚合的有效性。", "conclusion": "TopClustRAG通过聚类和提示聚合的策略，在大规模RAG系统中有效提高了答案的质量，展示了在提高答案多样性和相关性方面的潜力。"}}
{"id": "2506.15425", "title": "Understanding GUI Agent Localization Biases through Logit Sharpness", "authors": ["Xingjian Tao", "Yiwei Wang", "Yujun Cai", "Zhicheng Yang", "Jing Tang"], "abstract": "Multimodal large language models (MLLMs) have enabled GUI agents to interact with operating systems by grounding language into spatial actions. Despite their promising performance, these models frequently exhibit hallucinations-systematic localization errors that compromise reliability. We propose a fine-grained evaluation framework that categorizes model predictions into four distinct types, revealing nuanced failure modes beyond traditional accuracy metrics. To better quantify model uncertainty, we introduce the Peak Sharpness Score (PSS), a metric that evaluates the alignment between semantic continuity and logits distribution in coordinate prediction. Building on this insight, we further propose Context-Aware Cropping, a training-free technique that improves model performance by adaptively refining input context. Extensive experiments demonstrate that our framework and methods provide actionable insights and enhance the interpretability and robustness of GUI agent behavior.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.15425.pdf", "abstract_url": "https://arxiv.org/abs/2506.15425", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种细粒度的评估框架和Peak Sharpness Score (PSS)指标，以量化多模态大语言模型在GUI代理中的定位偏差，并通过Context-Aware Cropping技术提升模型性能。", "motivation": "解决多模态大语言模型在GUI代理中因系统性定位错误（幻觉）而影响可靠性的问题。", "method": "引入Peak Sharpness Score (PSS)指标评估语义连续性与坐标预测logits分布的一致性，并提出训练无关的技术Context-Aware Cropping自适应优化输入上下文。", "result": "实验表明，所提出的框架和方法能够提供可操作的见解，增强GUI代理行为的可解释性和鲁棒性。", "conclusion": "通过细粒度评估和创新技术，本研究提高了GUI代理的定位准确性和模型的不确定性量化能力，为未来研究提供了新的方向。"}}
{"id": "2506.15451", "title": "AgentGroupChat-V2: Divide-and-Conquer Is What LLM-Based Multi-Agent System Need", "authors": ["Zhouhong Gu", "Xiaoxuan Zhu", "Yin Cai", "Hao Shen", "Xingzhou Chen", "Qingyi Wang", "Jialin Li", "Xiaoran Shi", "Haoran Guo", "Wenxuan Huang", "Hongwei Feng", "Yanghua Xiao", "Zheyu Ye", "Yao Hu", "Shaosheng Cao"], "abstract": "Large language model based multi-agent systems have demonstrated significant potential in social simulation and complex task resolution domains. However, current frameworks face critical challenges in system architecture design, cross-domain generalizability, and performance guarantees, particularly as task complexity and number of agents increases. We introduces AgentGroupChat-V2, a novel framework addressing these challenges through three core innovations: (1) a divide-and-conquer fully parallel architecture that decomposes user queries into hierarchical task forest structures enabling dependency management and distributed concurrent processing. (2) an adaptive collaboration engine that dynamically selects heterogeneous LLM combinations and interaction modes based on task characteristics. (3) agent organization optimization strategies combining divide-and-conquer approaches for efficient problem decomposition. Extensive experiments demonstrate AgentGroupChat-V2's superior performance across diverse domains, achieving 91.50% accuracy on GSM8K (exceeding the best baseline by 5.6 percentage points), 30.4% accuracy on competition-level AIME (nearly doubling other methods), and 79.20% pass@1 on HumanEval. Performance advantages become increasingly pronounced with higher task difficulty, particularly on Level 5 MATH problems where improvements exceed 11 percentage points compared to state-of-the-art baselines. These results confirm that AgentGroupChat-V2 provides a comprehensive solution for building efficient, general-purpose LLM multi-agent systems with significant advantages in complex reasoning scenarios. Code is available at", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.15451.pdf", "abstract_url": "https://arxiv.org/abs/2506.15451", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了AgentGroupChat-V2，一个基于大型语言模型的多智能体系统框架，通过分而治之的全并行架构、自适应协作引擎和智能体组织优化策略，有效解决了当前框架在系统架构设计、跨领域通用性和性能保证方面的挑战。", "motivation": "当前基于大型语言模型的多智能体系统在系统架构设计、跨领域通用性和性能保证方面面临挑战，特别是在任务复杂性和智能体数量增加时。", "method": "AgentGroupChat-V2通过三个核心创新解决这些挑战：(1) 分而治之的全并行架构，(2) 自适应协作引擎，(3) 智能体组织优化策略。", "result": "在多个领域的广泛实验中，AgentGroupChat-V2表现出卓越的性能，如在GSM8K上达到91.50%的准确率，在AIME上达到30.4%的准确率，在HumanEval上达到79.20%的pass@1。", "conclusion": "AgentGroupChat-V2为构建高效、通用的LLM多智能体系统提供了全面的解决方案，在复杂推理场景中具有显著优势。"}}
{"id": "2506.15569", "title": "SciVer: Evaluating Foundation Models for Multimodal Scientific Claim Verification", "authors": ["Chengye Wang", "Yifei Shen", "Zexi Kuang", "Arman Cohan", "Yilun Zhao"], "abstract": "We introduce SciVer, the first benchmark specifically designed to evaluate the ability of foundation models to verify claims within a multimodal scientific context. SciVer consists of 3,000 expert-annotated examples over 1,113 scientific papers, covering four subsets, each representing a common reasoning type in multimodal scientific claim verification. To enable fine-grained evaluation, each example includes expert-annotated supporting evidence. We assess the performance of 21 state-of-the-art multimodal foundation models, including o4-mini, Gemini-2.5-Flash, Llama-3.2-Vision, and Qwen2.5-VL. Our experiment reveals a substantial performance gap between these models and human experts on SciVer. Through an in-depth analysis of retrieval-augmented generation (RAG), and human-conducted error evaluations, we identify critical limitations in current open-source models, offering key insights to advance models' comprehension and reasoning in multimodal scientific literature tasks.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.15569.pdf", "abstract_url": "https://arxiv.org/abs/2506.15569", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "SciVer是首个专门设计用于评估基础模型在多模态科学背景下验证声明能力的基准。它包含3,000个专家注释的例子，覆盖1,113篇科学论文，涵盖四种常见的多模态科学声明验证推理类型。通过评估21种最先进的多模态基础模型，研究发现这些模型与人类专家之间存在显著性能差距，并指出了当前开源模型的关键限制。", "motivation": "解决在多模态科学文献中验证声明的挑战，评估基础模型在此任务上的能力。", "method": "构建SciVer基准，包含专家注释的例子和支撑证据，评估21种多模态基础模型的性能，包括o4-mini、Gemini-2.5-Flash、Llama-3.2-Vision和Qwen2.5-VL。", "result": "发现当前最先进的多模态基础模型与人类专家在SciVer上存在显著性能差距，识别了开源模型的关键限制。", "conclusion": "研究为提升模型在多模态科学文献任务中的理解和推理能力提供了关键见解，指出了未来改进的方向。"}}
{"id": "2506.15522", "title": "Lessons from Training Grounded LLMs with Verifiable Rewards", "authors": ["Shang Hong Sim", "Tej Deep Pala", "Vernon Toh", "Hai Leong Chieu", "Amir Zadeh", "Chuan Li", "Navonil Majumder", "Soujanya Poria"], "abstract": "Generating grounded and trustworthy responses remains a key challenge for large language models (LLMs). While retrieval-augmented generation (RAG) with citation-based grounding holds promise, instruction-tuned models frequently fail even in straightforward scenarios: missing explicitly stated answers, citing incorrectly, or refusing when evidence is available. In this work, we explore how reinforcement learning (RL) and internal reasoning can enhance grounding in LLMs. We use the GRPO (Group Relative Policy Optimization) method to train models using verifiable outcome-based rewards targeting answer correctness, citation sufficiency, and refusal quality, without requiring gold reasoning traces or expensive annotations. Through comprehensive experiments across ASQA, QAMPARI, ELI5, and ExpertQA we show that reasoning-augmented models significantly outperform instruction-only variants, especially in handling unanswerable queries and generating well-cited responses. A two-stage training setup, first optimizing answer and citation behavior and then refusal, further improves grounding by stabilizing the learning signal. Additionally, we revisit instruction tuning via GPT-4 distillation and find that combining it with GRPO enhances performance on long-form, generative QA tasks. Overall, our findings highlight the value of reasoning, stage-wise optimization, and outcome-driven RL for building more verifiable and reliable LLMs.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.15522.pdf", "abstract_url": "https://arxiv.org/abs/2506.15522", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文探讨了如何通过强化学习(RL)和内部推理来增强大型语言模型(LLMs)的接地性和可信赖性。使用GRPO方法训练模型，针对答案正确性、引用充分性和拒绝质量进行优化，无需昂贵的注释。实验表明，结合推理的模型在多个数据集上表现优于仅指令调优的模型，特别是在处理不可回答的查询和生成良好引用的响应方面。", "motivation": "解决大型语言模型在生成接地和可信赖响应方面的挑战，特别是在检索增强生成(RAG)和基于引用的接地中存在的失败情况。", "method": "使用GRPO(Group Relative Policy Optimization)方法，通过可验证的结果基于奖励训练模型，优化答案正确性、引用充分性和拒绝质量。采用两阶段训练设置，先优化答案和引用行为，再优化拒绝行为。", "result": "在ASQA、QAMPARI、ELI5和ExpertQA等多个数据集上的实验表明，结合推理的模型显著优于仅指令调优的变体，特别是在处理不可回答的查询和生成良好引用的响应方面。结合GPT-4蒸馏的指令调优和GRPO进一步提高了长形式生成QA任务的性能。", "conclusion": "研究结果强调了推理、分阶段优化和结果驱动的强化学习在构建更可验证和可靠的大型语言模型中的价值。"}}
{"id": "2506.15674", "title": "Leaky Thoughts: Large Reasoning Models Are Not Private Thinkers", "authors": ["Tommaso Green", "Martin Gubri", "Haritz Puerto", "Sangdoo Yun", "Seong Joon Oh"], "abstract": "We study privacy leakage in the reasoning traces of large reasoning models used as personal agents. Unlike final outputs, reasoning traces are often assumed to be internal and safe. We challenge this assumption by showing that reasoning traces frequently contain sensitive user data, which can be extracted via prompt injections or accidentally leak into outputs. Through probing and agentic evaluations, we demonstrate that test-time compute approaches, particularly increased reasoning steps, amplify such leakage. While increasing the budget of those test-time compute approaches makes models more cautious in their final answers, it also leads them to reason more verbosely and leak more in their own thinking. This reveals a core tension: reasoning improves utility but enlarges the privacy attack surface. We argue that safety efforts must extend to the model's internal thinking, not just its outputs.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.15674.pdf", "abstract_url": "https://arxiv.org/abs/2506.15674", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Cryptography and Security (cs.CR)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "研究大型推理模型在作为个人代理时的隐私泄露问题，特别是推理痕迹中的敏感用户数据泄露。", "motivation": "解决大型推理模型在推理过程中可能泄露敏感用户数据的问题，挑战了推理痕迹内部安全的假设。", "method": "通过探测和代理评估，展示了测试时计算方法（尤其是增加的推理步骤）如何放大这种泄露。", "result": "研究发现，增加推理步骤虽然使模型在最终答案上更加谨慎，但也导致其推理更加冗长，从而在思考过程中泄露更多信息。", "conclusion": "研究揭示了推理提升效用与扩大隐私攻击面之间的核心张力，主张安全努力必须扩展到模型的内部思考，而不仅仅是其输出。"}}
{"id": "2506.14852", "title": "Cost-Efficient Serving of LLM Agents via Test-Time Plan Caching", "authors": ["Qizheng Zhang", "Michael Wornow", "Kunle Olukotun"], "abstract": "LLM-based agentic applications have shown increasingly remarkable capabilities in complex workflows but incur substantial costs due to extensive planning and reasoning requirements. Existing LLM caching techniques (like context caching and semantic caching), primarily designed for serving chatbots, are insufficient for agentic applications where outputs depend on external data or environmental contexts. We propose agentic plan caching, a novel approach that extracts, stores, adapts, and reuses structured plan templates from planning stages of agentic applications across semantically similar tasks to reduce the cost of serving. Unlike traditional semantic caching, our system extracts plan templates from completed agent executions at test-time, employs keyword extraction to match new requests against cached plans, and utilizes lightweight models to adapt these templates to task-specific plans with contexts. Evaluation across multiple real-world agentic applications shows that our system can reduce costs by 46.62% on average while maintaining performance, offering a more efficient solution for serving LLM-based agents that complements existing LLM serving infrastructures.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Performance (cs.PF)", "comments": "23 pages", "pdf_url": "https://arxiv.org/pdf/2506.14852.pdf", "abstract_url": "https://arxiv.org/abs/2506.14852", "categories": ["Distributed, Parallel, and Cluster Computing (cs.DC)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)", "Performance (cs.PF)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种名为代理计划缓存的新方法，旨在通过提取、存储、调整和重用代理应用程序规划阶段的结构化计划模板，来降低基于LLM的代理应用的服务成本。", "motivation": "现有的LLM缓存技术（如上下文缓存和语义缓存）主要设计用于服务聊天机器人，对于依赖外部数据或环境上下文的代理应用来说不够有效，导致高昂的服务成本。", "method": "代理计划缓存方法从完成的代理执行中提取计划模板，使用关键词提取将新请求与缓存计划匹配，并利用轻量级模型将这些模板调整为具有上下文的任务特定计划。", "result": "在多个实际代理应用中的评估显示，该系统平均可降低成本46.62%，同时保持性能，为基于LLM的代理服务提供了更高效的解决方案。", "conclusion": "代理计划缓存是一种有效的成本降低方法，能够补充现有的LLM服务基础设施，为复杂的代理工作流提供经济高效的解决方案。"}}
{"id": "2506.14988", "title": "Fair Algorithms with Probing for Multi-Agent Multi-Armed Bandits", "authors": ["Tianyi Xu", "Jiaxin Liu", "Zizhan Zheng"], "abstract": "We propose a multi-agent multi-armed bandit (MA-MAB) framework aimed at ensuring fair outcomes across agents while maximizing overall system performance. A key challenge in this setting is decision-making under limited information about arm rewards. To address this, we introduce a novel probing framework that strategically gathers information about selected arms before allocation. In the offline setting, where reward distributions are known, we leverage submodular properties to design a greedy probing algorithm with a provable performance bound. For the more complex online setting, we develop an algorithm that achieves sublinear regret while maintaining fairness. Extensive experiments on synthetic and real-world datasets show that our approach outperforms baseline methods, achieving better fairness and efficiency.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.14988.pdf", "abstract_url": "https://arxiv.org/abs/2506.14988", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种多智能体多臂老虎机（MA-MAB）框架，旨在确保智能体间的公平结果同时最大化系统整体性能。通过引入新颖的探测框架，在分配前策略性地收集有关选定臂的信息。在离线设置中，利用子模性质设计了一种具有可证明性能界的贪婪探测算法；在更复杂的在线设置中，开发了一种在保持公平性的同时实现次线性遗憾的算法。", "motivation": "解决在多智能体多臂老虎机设置中，如何在有限的臂奖励信息下做出决策，以确保公平性和最大化系统性能的问题。", "method": "在离线设置中，利用子模性质设计贪婪探测算法；在在线设置中，开发实现次线性遗憾的算法。", "result": "在合成和真实世界数据集上的广泛实验表明，该方法在公平性和效率上优于基线方法。", "conclusion": "提出的框架和算法在多智能体多臂老虎机问题中有效平衡了公平性和性能，为相关领域提供了新的解决方案。"}}
{"id": "2506.15167", "title": "LLM Agent for Hyper-Parameter Optimization", "authors": ["Wanzhe Wang", "Jianqiu Peng", "Menghao Hu", "Weihuang Zhong", "Tong Zhang", "Shuai Wang", "Yixin Zhang", "Mingjie Shao", "Wanli Ni"], "abstract": "Hyper-parameters are essential and critical for the performance of communication algorithms. However, current hyper-parameters tuning methods for warm-start particles swarm optimization with cross and mutation (WS-PSO-CM) algortihm for radio map-enabled unmanned aerial vehicle (UAV) trajectory and communication are primarily heuristic-based, exhibiting low levels of automation and unsatisfactory performance. In this paper, we design an large language model (LLM) agent for automatic hyper-parameters-tuning, where an iterative framework and model context protocol (MCP) are applied. In particular, the LLM agent is first setup via a profile, which specifies the mission, background, and output format. Then, the LLM agent is driven by the prompt requirement, and iteratively invokes WS-PSO-CM algorithm for exploration. Finally, the LLM agent autonomously terminates the loop and returns a set of hyper-parameters. Our experiment results show that the minimal sum-rate achieved by hyper-parameters generated via our LLM agent is significantly higher than those by both human heuristics and random generation methods. This indicates that an LLM agent with PSO knowledge and WS-PSO-CM algorithm background is useful in finding high-performance hyper-parameters.", "subjects": "Information Theory (cs.IT); Artificial Intelligence (cs.AI)", "comments": "6 pages, 6 figures", "pdf_url": "https://arxiv.org/pdf/2506.15167.pdf", "abstract_url": "https://arxiv.org/abs/2506.15167", "categories": ["Information Theory (cs.IT)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文设计了一个基于大型语言模型（LLM）的代理，用于自动调整WS-PSO-CM算法的超参数，以提高无人机轨迹和通信的性能。通过迭代框架和模型上下文协议（MCP），LLM代理能够自主探索并终止循环，返回一组超参数。实验结果表明，LLM代理生成的超参数在最小和速率上显著优于人类启发式和随机生成方法。", "motivation": "当前用于WS-PSO-CM算法的超参数调整方法主要是启发式的，自动化水平低且性能不理想。本文旨在解决这一问题，通过LLM代理实现超参数的自动优化。", "method": "设计了一个LLM代理，通过配置文件设置任务、背景和输出格式，然后根据提示要求驱动代理，并迭代调用WS-PSO-CM算法进行探索，最后自主终止循环并返回超参数。", "result": "实验结果显示，LLM代理生成的超参数在最小和速率上显著优于人类启发式和随机生成方法。", "conclusion": "具有PSO知识和WS-PSO-CM算法背景的LLM代理在寻找高性能超参数方面非常有用，这为提高通信算法的性能提供了新的自动化解决方案。"}}
{"id": "2506.15421", "title": "Reward Models in Deep Reinforcement Learning: A Survey", "authors": ["Rui Yu", "Shenghua Wan", "Yucen Wang", "Chen-Xiao Gao", "Le Gan", "Zongzhang Zhang", "De-Chuan Zhan"], "abstract": "In reinforcement learning (RL), agents continually interact with the environment and use the feedback to refine their behavior. To guide policy optimization, reward models are introduced as proxies of the desired objectives, such that when the agent maximizes the accumulated reward, it also fulfills the task designer's intentions. Recently, significant attention from both academic and industrial researchers has focused on developing reward models that not only align closely with the true objectives but also facilitate policy optimization. In this survey, we provide a comprehensive review of reward modeling techniques within the deep RL literature. We begin by outlining the background and preliminaries in reward modeling. Next, we present an overview of recent reward modeling approaches, categorizing them based on the source, the mechanism, and the learning paradigm. Building on this understanding, we discuss various applications of these reward modeling techniques and review methods for evaluating reward models. Finally, we conclude by highlighting promising research directions in reward modeling. Altogether, this survey includes both established and emerging methods, filling the vacancy of a systematic review of reward models in current literature.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "IJCAI 2025 Survey Track (To Appear)", "pdf_url": "https://arxiv.org/pdf/2506.15421.pdf", "abstract_url": "https://arxiv.org/abs/2506.15421", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文综述了深度强化学习中奖励模型的研究进展，包括背景、分类、应用及评估方法，并指出了未来研究方向。", "motivation": "解决深度强化学习中奖励模型如何更准确地反映任务设计者意图并促进策略优化的问题。", "method": "通过文献综述，对奖励模型技术进行分类，基于来源、机制和学习范式，并讨论其应用和评估方法。", "result": "综述了深度强化学习中奖励模型的现有和新兴方法，填补了该领域系统综述的空白。", "conclusion": "奖励模型在深度强化学习中至关重要，未来研究应关注更高效的模型设计和评估方法。"}}
{"id": "2506.15253", "title": "RAS-Eval: A Comprehensive Benchmark for Security Evaluation of LLM Agents in Real-World Environments", "authors": ["Yuchuan Fu", "Xiaohan Yuan", "Dongxia Wang"], "abstract": "The rapid deployment of Large language model (LLM) agents in critical domains like healthcare and finance necessitates robust security frameworks. To address the absence of standardized evaluation benchmarks for these agents in dynamic environments, we introduce RAS-Eval, a comprehensive security benchmark supporting both simulated and real-world tool execution. RAS-Eval comprises 80 test cases and 3,802 attack tasks mapped to 11 Common Weakness Enumeration (CWE) categories, with tools implemented in JSON, LangGraph, and Model Context Protocol (MCP) formats. We evaluate 6 state-of-the-art LLMs across diverse scenarios, revealing significant vulnerabilities: attacks reduced agent task completion rates (TCR) by 36.78% on average and achieved an 85.65% success rate in academic settings. Notably, scaling laws held for security capabilities, with larger models outperforming smaller counterparts. Our findings expose critical risks in real-world agent deployments and provide a foundational framework for future security research. Code and data are available at", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": "12 pages, 8 figures", "pdf_url": "https://arxiv.org/pdf/2506.15253.pdf", "abstract_url": "https://arxiv.org/abs/2506.15253", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了RAS-Eval，一个全面的安全基准测试，用于评估在动态环境中部署的大型语言模型（LLM）代理的安全性。它包括80个测试案例和3,802个攻击任务，覆盖11个CWE类别，并在6种最先进的LLM上进行了评估，揭示了显著的安全漏洞。", "motivation": "随着大型语言模型（LLM）代理在医疗和金融等关键领域的快速部署，缺乏在动态环境中对这些代理进行标准化安全评估的基准测试成为了一个问题。", "method": "研究团队开发了RAS-Eval基准测试，支持模拟和真实世界的工具执行，包括80个测试案例和3,802个攻击任务，映射到11个CWE类别，并使用JSON、LangGraph和MCP格式实现工具。", "result": "评估显示，攻击平均降低了代理任务完成率（TCR）36.78%，在学术环境中达到了85.65%的成功率。较大的模型在安全能力上表现优于较小的模型。", "conclusion": "研究结果揭示了在真实世界部署LLM代理时的关键风险，并为未来的安全研究提供了一个基础框架。代码和数据已公开。"}}
{"id": "2506.15468", "title": "Co-Creative Learning via Metropolis-Hastings Interaction between Humans and AI", "authors": ["Ryota Okumura", "Tadahiro Taniguchi", "Akira Taniguchi", "Yoshinobu Hagiwara"], "abstract": "We propose co-creative learning as a novel paradigm where humans and AI, i.e., biological and artificial agents, mutually integrate their partial perceptual information and knowledge to construct shared external representations, a process we interpret as symbol emergence. Unlike traditional AI teaching based on unilateral knowledge transfer, this addresses the challenge of integrating information from inherently different modalities. We empirically test this framework using a human-AI interaction model based on the Metropolis-Hastings naming game (MHNG), a decentralized Bayesian inference mechanism. In an online experiment, 69 participants played a joint attention naming game (JA-NG) with one of three computer agent types (MH-based, always-accept, or always-reject) under partial observability. Results show that human-AI pairs with an MH-based agent significantly improved categorization accuracy through interaction and achieved stronger convergence toward a shared sign system. Furthermore, human acceptance behavior aligned closely with the MH-derived acceptance probability. These findings provide the first empirical evidence for co-creative learning emerging in human-AI dyads via MHNG-based interaction. This suggests a promising path toward symbiotic AI systems that learn with humans, rather than from them, by dynamically aligning perceptual experiences, opening a new venue for symbiotic AI alignment.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.15468.pdf", "abstract_url": "https://arxiv.org/abs/2506.15468", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为‘共同创造性学习’的新范式，通过人类与AI之间的Metropolis-Hastings命名游戏互动，实现生物与人工代理之间部分感知信息和知识的相互整合，构建共享的外部表示。", "motivation": "解决传统AI教学中单向知识转移无法整合来自不同模态信息的挑战。", "method": "使用基于Metropolis-Hastings命名游戏（MHNG）的人机交互模型进行实证测试。", "result": "实验结果显示，与基于MH的代理配对的人机组合通过互动显著提高了分类准确性，并实现了向共享符号系统的更强收敛。", "conclusion": "这为通过MHNG基础的互动在人类-AI二元组中出现的共同创造性学习提供了首个实证证据，为开发能够与人类共同学习而非仅从人类学习的共生AI系统开辟了新途径。"}}
{"id": "2506.15513", "title": "RePCS: Diagnosing Data Memorization in LLM-Powered Retrieval-Augmented Generation", "authors": ["Le Vu Anh", "Nguyen Viet Anh", "Mehmet Dik", "Luong Van Nghia"], "abstract": "Retrieval-augmented generation (RAG) has become a common strategy for updating large language model (LLM) responses with current, external information. However, models may still rely on memorized training data, bypass the retrieved evidence, and produce contaminated outputs. We introduce Retrieval-Path Contamination Scoring (RePCS), a diagnostic method that detects such behavior without requiring model access or retraining. RePCS compares two inference paths: (i) a parametric path using only the query, and (ii) a retrieval-augmented path using both the query and retrieved context by computing the Kullback-Leibler (KL) divergence between their output distributions. A low divergence suggests that the retrieved context had minimal impact, indicating potential memorization. This procedure is model-agnostic, requires no gradient or internal state access, and adds only a single additional forward pass. We further derive PAC-style guarantees that link the KL threshold to user-defined false positive and false negative rates. On the Prompt-WNQA benchmark, RePCS achieves a ROC-AUC of 0.918. This result outperforms the strongest prior method by 6.5 percentage points while keeping latency overhead below 4.7% on an NVIDIA T4 GPU. RePCS offers a lightweight, black-box safeguard to verify whether a RAG system meaningfully leverages retrieval, making it especially valuable in safety-critical applications.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "11 pages, 7 figures, 5 tables", "pdf_url": "https://arxiv.org/pdf/2506.15513.pdf", "abstract_url": "https://arxiv.org/abs/2506.15513", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了RePCS，一种诊断大型语言模型（LLM）驱动的检索增强生成（RAG）中数据记忆化的方法。RePCS通过比较两种推理路径的KL散度来检测模型是否依赖记忆数据而非检索证据，无需模型访问或重新训练。", "motivation": "解决在检索增强生成（RAG）中，模型可能依赖记忆的训练数据而非检索到的外部信息，导致输出污染的问题。", "method": "提出Retrieval-Path Contamination Scoring (RePCS)，通过计算仅使用查询的参数路径和使用查询及检索上下文的检索增强路径之间的KL散度，来诊断数据记忆化。", "result": "在Prompt-WNQA基准测试中，RePCS的ROC-AUC达到0.918，比之前最强方法高出6.5个百分点，延迟开销低于4.7%。", "conclusion": "RePCS提供了一种轻量级的黑盒保护措施，用于验证RAG系统是否有效利用检索，特别适用于安全关键应用。"}}
{"id": "2506.15543", "title": "Learning Algorithms in the Limit", "authors": ["Hristo Papazov", "Nicolas Flammarion"], "abstract": "This paper studies the problem of learning computable functions in the limit by extending Gold's inductive inference framework to incorporate \\textit{computational observations} and \\textit{restricted input sources}. Complimentary to the traditional Input-Output Observations, we introduce Time-Bound Observations, and Policy-Trajectory Observations to study the learnability of general recursive functions under more realistic constraints. While input-output observations do not suffice for learning the class of general recursive functions in the limit, we overcome this learning barrier by imposing computational complexity constraints or supplementing with approximate time-bound observations. Further, we build a formal framework around observations of \\textit{computational agents} and show that learning computable functions from policy trajectories reduces to learning rational functions from input and output, thereby revealing interesting connections to finite-state transducer inference. On the negative side, we show that computable or polynomial-mass characteristic sets cannot exist for the class of linear-time computable functions even for policy-trajectory observations.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Data Structures and Algorithms (cs.DS); Formal Languages and Automata Theory (cs.FL)", "comments": "Accepted at COLT 2025. This version matches the proceedings version", "pdf_url": "https://arxiv.org/pdf/2506.15543.pdf", "abstract_url": "https://arxiv.org/abs/2506.15543", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Data Structures and Algorithms (cs.DS)", "Formal Languages and Automata Theory (cs.FL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过扩展Gold的归纳推理框架，引入计算观察和受限输入源，研究了在极限下学习可计算函数的问题。通过引入时间限制观察和策略轨迹观察，克服了传统输入输出观察在学习一般递归函数时的限制，并建立了围绕计算代理观察的正式框架。", "motivation": "解决在更现实的约束下学习一般递归函数的问题，克服传统输入输出观察在学习这类函数时的不足。", "method": "扩展Gold的归纳推理框架，引入时间限制观察和策略轨迹观察，建立计算代理观察的正式框架。", "result": "在施加计算复杂性约束或补充近似时间限制观察的情况下，可以克服学习障碍；从策略轨迹学习可计算函数简化为从输入和输出学习有理函数。", "conclusion": "通过引入新的观察方法和建立正式框架，本研究为在极限下学习可计算函数提供了新的途径，揭示了与有限状态转换器推断的有趣联系。"}}
