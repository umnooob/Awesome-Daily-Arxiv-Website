{"id": "2505.10604", "title": "MIRAGE: A Multi-modal Benchmark for Spatial Perception, Reasoning, and Intelligence", "authors": ["Chonghan Liu", "Haoran Wang", "Felix Henry", "Pu Miao", "Yajie Zhang", "Yu Zhao", "Peiran Wu"], "abstract": "Spatial perception and reasoning are core components of human cognition, encompassing object recognition, spatial relational understanding, and dynamic reasoning. Despite progress in computer vision, existing benchmarks reveal significant gaps in models' abilities to accurately recognize object attributes and reason about spatial relationships, both essential for dynamic reasoning. To address these limitations, we propose MIRAGE, a multi-modal benchmark designed to evaluate models' capabilities in Counting (object attribute recognition), Relation (spatial relational reasoning), and Counting with Relation. Through diverse and complex scenarios requiring fine-grained recognition and reasoning, MIRAGE highlights critical limitations in state-of-the-art models, underscoring the need for improved representations and reasoning frameworks. By targeting these foundational abilities, MIRAGE provides a pathway toward spatiotemporal reasoning in future research.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.10604.pdf", "abstract_url": "https://arxiv.org/abs/2505.10604", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "MIRAGE是一个多模态基准，旨在评估模型在计数（对象属性识别）、关系（空间关系推理）以及计数与关系结合方面的能力。通过设计多样化和复杂的场景，MIRAGE揭示了当前最先进模型在精细识别和推理方面的关键限制，强调了改进表示和推理框架的必要性。", "motivation": "尽管计算机视觉取得了进展，现有基准测试显示模型在准确识别对象属性和推理空间关系方面存在显著差距，这些都是动态推理所必需的。为了弥补这些不足，提出了MIRAGE基准。", "method": "MIRAGE通过设计多样化和复杂的场景，要求模型进行精细的识别和推理，以此来评估模型的能力。", "result": "MIRAGE揭示了当前最先进模型在精细识别和推理方面的关键限制。", "conclusion": "通过针对这些基础能力，MIRAGE为未来研究中的时空推理提供了路径。"}}
{"id": "2505.10610", "title": "MMLongBench: Benchmarking Long-Context Vision-Language Models Effectively and Thoroughly", "authors": ["Zhaowei Wang", "Wenhao Yu", "Xiyu Ren", "Jipeng Zhang", "Yu Zhao", "Rohit Saxena", "Liang Cheng", "Ginny Wong", "Simon See", "Pasquale Minervini", "Yangqiu Song", "Mark Steedman"], "abstract": "The rapid extension of context windows in large vision-language models has given rise to long-context vision-language models (LCVLMs), which are capable of handling hundreds of images with interleaved text tokens in a single forward pass. In this work, we introduce MMLongBench, the first benchmark covering a diverse set of long-context vision-language tasks, to evaluate LCVLMs effectively and thoroughly. MMLongBench is composed of 13,331 examples spanning five different categories of downstream tasks, such as Visual RAG and Many-Shot ICL. It also provides broad coverage of image types, including various natural and synthetic images. To assess the robustness of the models to different input lengths, all examples are delivered at five standardized input lengths (8K-128K tokens) via a cross-modal tokenization scheme that combines vision patches and text tokens. Through a thorough benchmarking of 46 closed-source and open-source LCVLMs, we provide a comprehensive analysis of the current models' vision-language long-context ability. Our results show that: i) performance on a single task is a weak proxy for overall long-context capability; ii) both closed-source and open-source models face challenges in long-context vision-language tasks, indicating substantial room for future improvement; iii) models with stronger reasoning ability tend to exhibit better long-context performance. By offering wide task coverage, various image types, and rigorous length control, MMLongBench provides the missing foundation for diagnosing and advancing the next generation of LCVLMs.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL)", "comments": "Work in progress", "pdf_url": "https://arxiv.org/pdf/2505.10610.pdf", "abstract_url": "https://arxiv.org/abs/2505.10610", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "MMLongBench是首个评估长上下文视觉语言模型(LCVLMs)的基准，覆盖多样化的任务和图像类型，通过标准化输入长度和跨模态标记化方案，全面分析了46个模型的性能。", "motivation": "随着大型视觉语言模型上下文窗口的快速扩展，需要有效的评估工具来全面评估长上下文视觉语言模型的能力。", "method": "MMLongBench包含13,331个例子，覆盖五类下游任务，提供五种标准化输入长度(8K-128K标记)，通过结合视觉块和文本标记的跨模态标记化方案进行评估。", "result": "研究发现：i)单一任务表现不能全面代表长上下文能力；ii)开源和闭源模型在长上下文任务中均面临挑战；iii)推理能力强的模型在长上下文中表现更好。", "conclusion": "MMLongBench为诊断和推进下一代LCVLMs提供了基础，展示了当前模型的局限性和未来改进的方向。"}}
{"id": "2505.10653", "title": "On the Evaluation of Engineering Artificial General Intelligence", "authors": ["Sandeep Neema", "Susmit Jha", "Adam Nagel", "Ethan Lew", "Chandrasekar Sureshkumar", "Aleksa Gordic", "Chase Shimmin", "Hieu Nguygen", "Paul Eremenko"], "abstract": "We discuss the challenges and propose a framework for evaluating engineering artificial general intelligence (eAGI) agents. We consider eAGI as a specialization of artificial general intelligence (AGI), deemed capable of addressing a broad range of problems in the engineering of physical systems and associated controllers. We exclude software engineering for a tractable scoping of eAGI and expect dedicated software engineering AI agents to address the software implementation challenges. Similar to human engineers, eAGI agents should possess a unique blend of background knowledge (recall and retrieve) of facts and methods, demonstrate familiarity with tools and processes, exhibit deep understanding of industrial components and well-known design families, and be able to engage in creative problem solving (analyze and synthesize), transferring ideas acquired in one context to another. Given this broad mandate, evaluating and qualifying the performance of eAGI agents is a challenge in itself and, arguably, a critical enabler to developing eAGI agents. In this paper, we address this challenge by proposing an extensible evaluation framework that specializes and grounds Bloom's taxonomy - a framework for evaluating human learning that has also been recently used for evaluating LLMs - in an engineering design context. Our proposed framework advances the state of the art in benchmarking and evaluation of AI agents in terms of the following: (a) developing a rich taxonomy of evaluation questions spanning from methodological knowledge to real-world design problems; (b) motivating a pluggable evaluation framework that can evaluate not only textual responses but also evaluate structured design artifacts such as CAD models and SysML models; and (c) outlining an automatable procedure to customize the evaluation benchmark to different engineering contexts.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "21 pages", "pdf_url": "https://arxiv.org/pdf/2505.10653.pdf", "abstract_url": "https://arxiv.org/abs/2505.10653", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文讨论了评估工程人工通用智能（eAGI）代理的挑战，并提出了一个评估框架。eAGI被视为人工通用智能（AGI）的一个专门化领域，旨在解决物理系统及其控制器的广泛问题。作者提出了一个可扩展的评估框架，专门针对工程设计背景，基于Bloom的分类法，以评估eAGI代理的性能。", "motivation": "评估和鉴定eAGI代理的性能本身就是一个挑战，也是开发eAGI代理的关键推动因素。本文旨在解决这一挑战，通过提出一个评估框架来专门化和基于Bloom的分类法，以评估eAGI代理在工程设计背景下的表现。", "method": "提出了一个可扩展的评估框架，该框架专门化和基于Bloom的分类法，用于评估eAGI代理在工程设计背景下的表现。该框架包括开发一个丰富的评估问题分类法，激励一个可插拔的评估框架，以及概述一个可自动化的程序来定制不同工程背景下的评估基准。", "result": "提出的框架在以下方面推动了AI代理基准测试和评估的最新技术：（a）开发了一个从方法论知识到现实世界设计问题的丰富评估问题分类法；（b）激励了一个可插拔的评估框架，可以评估文本响应以及结构化设计工件；（c）概述了一个可自动化的程序，以定制不同工程背景下的评估基准。", "conclusion": "本文提出的评估框架为eAGI代理的性能评估提供了一个全面和可扩展的方法，这对于开发能够解决广泛工程问题的eAGI代理至关重要。该框架不仅适用于评估文本响应，还能够评估结构化设计工件，如CAD和SysML模型，为未来的eAGI研究和开发奠定了基础。"}}
{"id": "2505.10792", "title": "Finetune-RAG: Fine-Tuning Language Models to Resist Hallucination in Retrieval-Augmented Generation", "authors": ["Zhan Peng Lee", "Andre Lin", "Calvin Tan"], "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a powerful framework to improve factuality in large language models (LLMs) by grounding their outputs in retrieved documents. However, ensuring perfect retrieval of relevant information remains challenging, and when irrelevant content is passed downstream to an LLM, it can lead to hallucinations. In this work, we propose Finetune-RAG, a simple and effective fine-tuning approach that features the first-of-its-kind RAG training dataset constructed to mimic real-world imperfections. Experimental results show that Finetune-RAG improves factual accuracy by 21.2% over the base model. We also propose a Bench-RAG, an LLM-as-a-judge evaluation pipeline that stress tests models under realistic imperfect retrieval scenarios. Our codebase and dataset are fully open sourced for community use.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.10792.pdf", "abstract_url": "https://arxiv.org/abs/2505.10792", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "Finetune-RAG是一种简单有效的微调方法，旨在通过模拟现实世界中的不完美情况来训练语言模型，以减少在检索增强生成（RAG）框架中的幻觉现象。实验结果显示，Finetune-RAG比基础模型提高了21.2%的事实准确性。", "motivation": "解决在检索增强生成（RAG）框架中，由于检索到不相关信息导致大型语言模型（LLMs）产生幻觉的问题。", "method": "提出了Finetune-RAG方法，包括构建首个模拟现实世界不完美的RAG训练数据集，以及Bench-RAG评估管道，用于在不完美检索场景下测试模型。", "result": "Finetune-RAG比基础模型提高了21.2%的事实准确性。", "conclusion": "Finetune-RAG通过微调语言模型，有效抵抗了在检索增强生成中的幻觉现象，同时开源了代码库和数据集供社区使用。"}}
{"id": "2505.10829", "title": "Enhancing Low-Resource Minority Language Translation with LLMs and Retrieval-Augmented Generation for Cultural Nuances", "authors": ["Chen-Chi Chang", "Chong-Fu Li", "Chu-Hsuan Lee", "Hung-Shin Lee"], "abstract": "This study investigates the challenges of translating low-resource languages by integrating Large Language Models (LLMs) with Retrieval-Augmented Generation (RAG). Various model configurations were tested on Hakka translations, with BLEU scores ranging from 12% (dictionary-only) to 31% (RAG with Gemini 2.0). The best-performing model (Model 4) combined retrieval and advanced language modeling, improving lexical coverage, particularly for specialized or culturally nuanced terms, and enhancing grammatical coherence. A two-stage method (Model 3) using dictionary outputs refined by Gemini 2.0 achieved a BLEU score of 26%, highlighting iterative correction's value and the challenges of domain-specific expressions. Static dictionary-based approaches struggled with context-sensitive content, demonstrating the limitations of relying solely on predefined resources. These results emphasize the need for curated resources, domain knowledge, and ethical collaboration with local communities, offering a framework that improves translation accuracy and fluency while supporting cultural preservation.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "Accepted to IntelliSys 2025", "pdf_url": "https://arxiv.org/pdf/2505.10829.pdf", "abstract_url": "https://arxiv.org/abs/2505.10829", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本研究探讨了通过整合大型语言模型（LLMs）和检索增强生成（RAG）技术来解决低资源语言翻译的挑战，特别是在客家话翻译中取得了BLEU分数从12%到31%的提升。最佳模型结合了检索和高级语言建模技术，显著提高了词汇覆盖率和语法连贯性。", "motivation": "解决低资源语言（如客家话）翻译中的挑战，特别是在处理专业或文化 nuanced 术语时的准确性和流畅性问题。", "method": "采用大型语言模型（LLMs）与检索增强生成（RAG）技术相结合的方法，测试了多种模型配置，包括字典单独使用、RAG与Gemini 2.0结合等。", "result": "最佳模型（Model 4）的BLEU分数达到31%，显著提高了翻译的准确性和流畅性；两阶段方法（Model 3）的BLEU分数为26%，显示了迭代校正的价值。", "conclusion": "研究表明，结合检索和高级语言建模技术可以显著提高低资源语言的翻译质量，同时强调了与当地社区合作、利用领域知识和精心策划资源的重要性，为文化保护提供了支持。"}}
{"id": "2505.10670", "title": "Interpretable Risk Mitigation in LLM Agent Systems", "authors": ["Jan Chojnacki"], "abstract": "Autonomous agents powered by large language models (LLMs) enable novel use cases in domains where responsible action is increasingly important. Yet the inherent unpredictability of LLMs raises safety concerns about agent reliability. In this work, we explore agent behaviour in a toy, game-theoretic environment based on a variation of the Iterated Prisoner's Dilemma. We introduce a strategy-modification method-independent of both the game and the prompt-by steering the residual stream with interpretable features extracted from a sparse autoencoder latent space. Steering with the good-faith negotiation feature lowers the average defection probability by 28 percentage points. We also identify feasible steering ranges for several open-source LLM agents. Finally, we hypothesise that game-theoretic evaluation of LLM agents, combined with representation-steering alignment, can generalise to real-world applications on end-user devices and embodied platforms.", "subjects": "Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Computer Science and Game Theory (cs.GT)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.10670.pdf", "abstract_url": "https://arxiv.org/abs/2505.10670", "categories": ["Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)", "Computer Science and Game Theory (cs.GT)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了在基于大型语言模型（LLMs）的自主代理系统中，如何通过可解释的风险缓解策略来提高代理的可靠性。通过在迭代囚徒困境的变体游戏中引入一种独立于游戏和提示的策略修改方法，作者展示了如何通过稀疏自编码器潜在空间中提取的可解释特征来引导残差流，从而有效降低背叛概率。", "motivation": "大型语言模型（LLMs）驱动的自主代理在需要负责任行动的领域中开辟了新的应用场景，但LLMs固有的不可预测性引发了关于代理可靠性的安全担忧。本文旨在解决这一问题，探索如何在保证代理行为可靠性的同时，保持其自主性和灵活性。", "method": "作者在迭代囚徒困境的变体游戏中，引入了一种独立于游戏和提示的策略修改方法。该方法通过从稀疏自编码器潜在空间中提取的可解释特征来引导残差流，从而实现对代理行为的精确控制。", "result": "通过使用良好谈判特征进行引导，平均背叛概率降低了28个百分点。此外，作者还为几种开源LLM代理确定了可行的引导范围。", "conclusion": "本文提出，结合博弈论评估和表示引导对齐的方法，可以推广到终端用户设备和实体平台上的实际应用中。这一发现为在保证代理行为可靠性的同时，提高其自主性和灵活性提供了新的思路。"}}
{"id": "2505.10749", "title": "Code-Driven Planning in Grid Worlds with Large Language Models", "authors": ["Ashwath Vaithinathan Aravindan", "Zhisheng Tang", "Mayank Kejriwal"], "abstract": "We propose an iterative programmatic planning (IPP) framework for solving grid-based tasks by synthesizing interpretable agent policies expressed in code using large language models (LLMs). Instead of relying on traditional search or reinforcement learning, our approach uses code generation as policy synthesis, where the LLM outputs executable programs that map environment states to action sequences. Our proposed architecture incorporates several prompting strategies, including direct code generation, pseudocode-conditioned refinement, and curriculum-based prompting, but also includes an iterative refinement mechanism that updates code based on task performance feedback. We evaluate our approach using six leading LLMs and two challenging grid-based benchmarks (GRASP and MiniGrid). Our IPP framework demonstrates improvements over direct code generation ranging from 10\\% to as much as 10x across five of the six models and establishes a new state-of-the-art result for GRASP. IPP is found to significantly outperform direct elicitation of a solution from GPT-o3-mini (by 63\\% on MiniGrid to 116\\% on GRASP), demonstrating the viability of the overall approach. Computational costs of all code generation approaches are similar. While code generation has a higher initial prompting cost compared to direct solution elicitation (\\$0.08 per task vs. \\$0.002 per instance for GPT-o3-mini), the code can be reused for any number of instances, making the amortized cost significantly lower (by 400x on GPT-o3-mini across the complete GRASP benchmark).", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.10749.pdf", "abstract_url": "https://arxiv.org/abs/2505.10749", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种迭代程序化规划（IPP）框架，通过使用大型语言模型（LLMs）合成代码中表达的可解释代理策略来解决基于网格的任务。该方法通过代码生成作为策略合成，结合多种提示策略和迭代细化机制，显著提高了性能。", "motivation": "解决传统搜索或强化学习在基于网格的任务中合成可解释代理策略的局限性，探索利用大型语言模型通过代码生成来合成策略的可行性。", "method": "采用迭代程序化规划（IPP）框架，结合直接代码生成、伪代码条件细化、基于课程的提示等策略，以及基于任务性能反馈的迭代代码更新机制。", "result": "在六个领先的大型语言模型和两个基于网格的基准测试（GRASP和MiniGrid）上，IPP框架显示出从10%到10倍的性能提升，并在GRASP上建立了新的最先进结果。", "conclusion": "IPP框架通过代码生成合成策略的方法不仅显著提高了性能，而且在摊销成本上具有显著优势，证明了该方法的整体可行性和效率。"}}
{"id": "2505.10819", "title": "PoE-World: Compositional World Modeling with Products of Programmatic Experts", "authors": ["Wasu Top Piriyakulkij", "Yichao Liang", "Hao Tang", "Adrian Weller", "Marta Kryven", "Kevin Ellis"], "abstract": "Learning how the world works is central to building AI agents that can adapt to complex environments. Traditional world models based on deep learning demand vast amounts of training data, and do not flexibly update their knowledge from sparse observations. Recent advances in program synthesis using Large Language Models (LLMs) give an alternate approach which learns world models represented as source code, supporting strong generalization from little data. To date, application of program-structured world models remains limited to natural language and grid-world domains. We introduce a novel program synthesis method for effectively modeling complex, non-gridworld domains by representing a world model as an exponentially-weighted product of programmatic experts (PoE-World) synthesized by LLMs. We show that this approach can learn complex, stochastic world models from just a few observations. We evaluate the learned world models by embedding them in a model-based planning agent, demonstrating efficient performance and generalization to unseen levels on Atari's Pong and Montezuma's Revenge. We release our code and display the learned world models and videos of the agent's gameplay at", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.10819.pdf", "abstract_url": "https://arxiv.org/abs/2505.10819", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "PoE-World提出了一种新颖的程序合成方法，通过将世界模型表示为由大型语言模型合成的程序化专家的指数加权乘积，有效地建模复杂的非网格世界领域。该方法能够从少量观察中学习复杂、随机的世界模型，并在Atari的Pong和Montezuma's Revenge游戏中展示了高效的性能和泛化能力。", "motivation": "解决传统基于深度学习的世界模型需要大量训练数据且无法从稀疏观察中灵活更新知识的问题，以及程序结构化世界模型在自然语言和网格世界领域之外的应用限制。", "method": "使用大型语言模型（LLMs）合成程序化专家的指数加权乘积（PoE-World）来表示世界模型，以学习复杂、随机的世界模型。", "result": "该方法能够从少量观察中学习复杂、随机的世界模型，并在Atari的Pong和Montezuma's Revenge游戏中展示了高效的性能和泛化到未见过的关卡的能力。", "conclusion": "PoE-World方法为构建能够适应复杂环境的AI代理提供了一种有效途径，通过程序合成和大型语言模型的应用，实现了从少量数据中学习复杂世界模型的目标，并在实际游戏中验证了其性能。"}}
{"id": "2505.10887", "title": "InfantAgent-Next: A Multimodal Generalist Agent for Automated Computer Interaction", "authors": ["Bin Lei", "Weitai Kang", "Zijian Zhang", "Winson Chen", "Xi Xie", "Shan Zuo", "Mimi Xie", "Ali Payani", "Mingyi Hong", "Yan Yan", "Caiwen Ding"], "abstract": "This paper introduces \\textsc{InfantAgent-Next}, a generalist agent capable of interacting with computers in a multimodal manner, encompassing text, images, audio, and video. Unlike existing approaches that either build intricate workflows around a single large model or only provide workflow modularity, our agent integrates tool-based and pure vision agents within a highly modular architecture, enabling different models to collaboratively solve decoupled tasks in a step-by-step manner. Our generality is demonstrated by our ability to evaluate not only pure vision-based real-world benchmarks (i.e., OSWorld), but also more general or tool-intensive benchmarks (e.g., GAIA and SWE-Bench). Specifically, we achieve $\\mathbf{7.27\\%}$ accuracy on OSWorld, higher than Claude-Computer-Use. Codes and evaluation scripts are open-sourced at", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.10887.pdf", "abstract_url": "https://arxiv.org/abs/2505.10887", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了InfantAgent-Next，一种多模态通用代理，能够以文本、图像、音频和视频等多种方式与计算机交互。与现有方法不同，我们的代理在一个高度模块化的架构中集成了基于工具和纯视觉的代理，使不同模型能够协作解决解耦的任务。", "motivation": "解决现有方法在构建复杂工作流或仅提供工作流模块化方面的局限性，提供一个更通用、更灵活的多模态交互代理。", "method": "集成工具型和纯视觉代理于一个高度模块化的架构中，支持不同模型协作解决任务。", "result": "在OSWorld基准测试中达到7.27%的准确率，高于Claude-Computer-Use。", "conclusion": "InfantAgent-Next展示了在多模态交互和任务解决方面的通用性和高效性，为未来的计算机交互代理提供了新的方向。"}}
{"id": "2505.10988", "title": "DRL-Based Injection Molding Process Parameter Optimization for Adaptive and Profitable Production", "authors": ["Joon-Young Kim", "Jecheon Yu", "Heekyu Kim", "Seunghwa Ryu"], "abstract": "Plastic injection molding remains essential to modern manufacturing. However, optimizing process parameters to balance product quality and profitability under dynamic environmental and economic conditions remains a persistent challenge. This study presents a novel deep reinforcement learning (DRL)-based framework for real-time process optimization in injection molding, integrating product quality and profitability into the control objective. A profit function was developed to reflect real-world manufacturing costs, incorporating resin, mold wear, and electricity prices, including time-of-use variations. Surrogate models were constructed to predict product quality and cycle time, enabling efficient offline training of DRL agents using soft actor-critic (SAC) and proximal policy optimization (PPO) algorithms. Experimental results demonstrate that the proposed DRL framework can dynamically adapt to seasonal and operational variations, consistently maintaining product quality while maximizing profit. Compared to traditional optimization methods such as genetic algorithms, the DRL models achieved comparable economic performance with up to 135x faster inference speeds, making them well-suited for real-time applications. The framework's scalability and adaptability highlight its potential as a foundation for intelligent, data-driven decision-making in modern manufacturing environments.", "subjects": "Artificial Intelligence (cs.AI); Systems and Control (eess.SY)", "comments": "50 pages, 10 figures", "pdf_url": "https://arxiv.org/pdf/2505.10988.pdf", "abstract_url": "https://arxiv.org/abs/2505.10988", "categories": ["Artificial Intelligence (cs.AI)", "Systems and Control (eess.SY)"], "matching_keywords": ["agent"], "AI": {"tldr": "本研究提出了一种基于深度强化学习（DRL）的注塑成型工艺参数优化框架，旨在实时平衡产品质量和盈利能力。通过开发利润函数和构建代理模型，该框架能够适应动态环境和经济条件，实现高效离线训练。实验结果表明，与传统优化方法相比，DRL模型在保持产品质量的同时，显著提高了推理速度，适用于实时应用。", "motivation": "注塑成型工艺参数的优化在动态环境和经济条件下平衡产品质量和盈利能力是一个持续的挑战。", "method": "研究采用深度强化学习（DRL）框架，结合软行动者-评论家（SAC）和近端策略优化（PPO）算法，通过构建利润函数和代理模型进行离线训练。", "result": "DRL框架能够动态适应季节性和操作变化，保持产品质量的同时最大化利润，与传统方法相比，推理速度提高了135倍。", "conclusion": "该框架的可扩展性和适应性表明其作为现代制造环境中智能、数据驱动决策基础的潜力。"}}
{"id": "2505.11257", "title": "DRAGON: A Large-Scale Dataset of Realistic Images Generated by Diffusion Models", "authors": ["Giulia Bertazzini", "Daniele Baracchi", "Dasara Shullani", "Isao Echizen", "Alessandro Piva"], "abstract": "The remarkable ease of use of diffusion models for image generation has led to a proliferation of synthetic content online. While these models are often employed for legitimate purposes, they are also used to generate fake images that support misinformation and hate speech. Consequently, it is crucial to develop robust tools capable of detecting whether an image has been generated by such models. Many current detection methods, however, require large volumes of sample images for training. Unfortunately, due to the rapid evolution of the field, existing datasets often cover only a limited range of models and quickly become outdated. In this work, we introduce DRAGON, a comprehensive dataset comprising images from 25 diffusion models, spanning both recent advancements and older, well-established architectures. The dataset contains a broad variety of images representing diverse subjects. To enhance image realism, we propose a simple yet effective pipeline that leverages a large language model to expand input prompts, thereby generating more diverse and higher-quality outputs, as evidenced by improvements in standard quality metrics. The dataset is provided in multiple sizes (ranging from extra-small to extra-large) to accomodate different research scenarios. DRAGON is designed to support the forensic community in developing and evaluating detection and attribution techniques for synthetic content. Additionally, the dataset is accompanied by a dedicated test set, intended to serve as a benchmark for assessing the performance of newly developed methods.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.11257.pdf", "abstract_url": "https://arxiv.org/abs/2505.11257", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "DRAGON是一个大规模的数据集，包含由25种扩散模型生成的逼真图像，旨在支持合成内容的检测和归属技术的研究与评估。", "motivation": "扩散模型生成的图像被广泛用于合法目的，但也用于生成支持错误信息和仇恨言论的假图像，因此需要开发能够检测此类图像的强大工具。", "method": "提出了一个简单而有效的流程，利用大型语言模型扩展输入提示，生成更多样化和更高质量的图像。数据集包含多种尺寸，以适应不同的研究场景。", "result": "DRAGON数据集涵盖了广泛的模型和图像类型，通过改进的标准质量指标证明了其生成图像的高质量和多样性。", "conclusion": "DRAGON数据集旨在为法医社区提供支持，开发和评估合成内容的检测和归属技术，并附带一个专用测试集，作为评估新方法性能的基准。"}}
{"id": "2505.11383", "title": "Dynam3D: Dynamic Layered 3D Tokens Empower VLM for Vision-and-Language Navigation", "authors": ["Zihan Wang", "Seungjun Lee", "Gim Hee Lee"], "abstract": "Vision-and-Language Navigation (VLN) is a core task where embodied agents leverage their spatial mobility to navigate in 3D environments toward designated destinations based on natural language instructions. Recently, video-language large models (Video-VLMs) with strong generalization capabilities and rich commonsense knowledge have shown remarkable performance when applied to VLN tasks. However, these models still encounter the following challenges when applied to real-world 3D navigation: 1) Insufficient understanding of 3D geometry and spatial semantics; 2) Limited capacity for large-scale exploration and long-term environmental memory; 3) Poor adaptability to dynamic and changing", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.11383.pdf", "abstract_url": "https://arxiv.org/abs/2505.11383", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了Dynam3D，一种动态分层3D令牌方法，旨在增强视频语言大模型（Video-VLMs）在视觉与语言导航（VLN）任务中的表现。该方法解决了现有模型在3D几何和空间语义理解不足、大规模探索和长期环境记忆能力有限以及对动态变化适应性差等问题。", "motivation": "解决视频语言大模型在应用于真实世界3D导航时遇到的三大挑战：对3D几何和空间语义的理解不足、大规模探索和长期环境记忆能力有限、以及对动态变化的适应性差。", "method": "提出Dynam3D方法，通过动态分层的3D令牌来增强视频语言大模型的能力，使其更好地理解和适应3D导航任务。", "result": "Dynam3D方法显著提升了视频语言大模型在视觉与语言导航任务中的性能，特别是在理解3D环境、进行大规模探索和适应动态变化方面。", "conclusion": "Dynam3D通过引入动态分层的3D令牌，有效解决了视频语言大模型在3D导航任务中的关键挑战，为未来的研究和应用提供了新的方向。"}}
{"id": "2505.10924", "title": "A Survey on the Safety and Security Threats of Computer-Using Agents: JARVIS or Ultron?", "authors": ["Ada Chen", "Yongjiang Wu", "Junyuan Zhang", "Shu Yang", "Jen-tse Huang", "Kun Wang", "Wenxuan Wang", "Shuai Wang"], "abstract": "Recently, AI-driven interactions with computing devices have advanced from basic prototype tools to sophisticated, LLM-based systems that emulate human-like operations in graphical user interfaces. We are now witnessing the emergence of \\emph{Computer-Using Agents} (CUAs), capable of autonomously performing tasks such as navigating desktop applications, web pages, and mobile apps. However, as these agents grow in capability, they also introduce novel safety and security risks. Vulnerabilities in LLM-driven reasoning, with the added complexity of integrating multiple software components and multimodal inputs, further complicate the security landscape. In this paper, we present a systematization of knowledge on the safety and security threats of CUAs. We conduct a comprehensive literature review and distill our findings along four research objectives: \\textit{\\textbf{(i)}} define the CUA that suits safety analysis; \\textit{\\textbf{(ii)} } categorize current safety threats among CUAs; \\textit{\\textbf{(iii)}} propose a comprehensive taxonomy of existing defensive strategies; \\textit{\\textbf{(iv)}} summarize prevailing benchmarks, datasets, and evaluation metrics used to assess the safety and performance of CUAs. Building on these insights, our work provides future researchers with a structured foundation for exploring unexplored vulnerabilities and offers practitioners actionable guidance in designing and deploying secure Computer-Using Agents.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV); Software Engineering (cs.SE)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.10924.pdf", "abstract_url": "https://arxiv.org/abs/2505.10924", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Cryptography and Security (cs.CR)", "Computer Vision and Pattern Recognition (cs.CV)", "Software Engineering (cs.SE)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文系统化了关于计算机使用代理（CUAs）安全性和安全威胁的知识，通过文献综述和四个研究目标，为未来研究提供了结构化基础，并为实践者提供了设计安全CUAs的指导。", "motivation": "随着AI驱动的计算机使用代理（CUAs）从基本原型工具发展为复杂的、基于LLM的系统，这些代理在提高能力的同时也引入了新的安全和安全风险。本文旨在解决这些新兴风险，为研究者和实践者提供系统的知识框架和防御策略。", "method": "通过全面的文献综述，本文围绕四个研究目标展开：定义适合安全分析的CUA；分类当前CUAs的安全威胁；提出现有防御策略的综合分类法；总结评估CUAs安全性和性能的现有基准、数据集和评价指标。", "result": "本文提出了一个关于CUAs安全性和安全威胁的系统化知识框架，包括定义、威胁分类、防御策略分类以及评估工具和指标的总结，为未来的研究和实践提供了基础。", "conclusion": "本文的工作为探索未发现的漏洞提供了结构化基础，并为设计和部署安全的计算机使用代理提供了可操作的指导，对未来的研究和实践具有重要意义。"}}
{"id": "2505.10936", "title": "Connecting the Dots: A Chain-of-Collaboration Prompting Framework for LLM Agents", "authors": ["Jiaxing Zhao", "Hongbin Xie", "Yuzhen Lei", "Xuan Song", "Zhuoran Shi", "Lianxin Li", "Shuangxue Liu", "Haoran Zhang"], "abstract": "Large Language Models (LLMs) have demonstrated impressive performance in executing complex reasoning tasks. Chain-of-thought effectively enhances reasoning capabilities by unlocking the potential of large models, while multi-agent systems provide more comprehensive solutions by integrating collective intelligence of multiple agents. However, both approaches face significant limitations. Single-agent with chain-of-thought, due to the inherent complexity of designing cross-domain prompts, faces collaboration challenges. Meanwhile, multi-agent systems consume substantial tokens and inevitably dilute the primary problem, which is particularly problematic in business workflow tasks. To address these challenges, we propose Cochain, a collaboration prompting framework that effectively solves business workflow collaboration problem by combining knowledge and prompts at a reduced cost. Specifically, we construct an integrated knowledge graph that incorporates knowledge from multiple stages. Furthermore, by maintaining and retrieving a prompts tree, we can obtain prompt information relevant to other stages of the business workflow. We perform extensive evaluations of Cochain across multiple datasets, demonstrating that Cochain outperforms all baselines in both prompt engineering and multi-agent LLMs. Additionally, expert evaluation results indicate that the use of a small model in combination with Cochain outperforms GPT-4.", "subjects": "Computation and Language (cs.CL)", "comments": "34 pages, 20 figures", "pdf_url": "https://arxiv.org/pdf/2505.10936.pdf", "abstract_url": "https://arxiv.org/abs/2505.10936", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为Cochain的协作提示框架，旨在解决大型语言模型（LLMs）在执行复杂推理任务时的协作问题，特别是在商业工作流程中。通过结合知识和提示，并在减少成本的同时，Cochain在多个数据集上的评估中表现优于所有基线方法。", "motivation": "大型语言模型（LLMs）在执行复杂推理任务时表现出色，但单代理的思维链方法由于设计跨领域提示的固有复杂性面临协作挑战，而多代理系统则消耗大量令牌并不可避免地稀释主要问题。本文旨在解决这些挑战。", "method": "提出了Cochain，一个协作提示框架，通过构建一个整合了多阶段知识的集成知识图，并维护和检索提示树，以获取与商业工作流程其他阶段相关的提示信息。", "result": "在多个数据集上的广泛评估表明，Cochain在提示工程和多代理LLMs方面均优于所有基线方法。专家评估结果还显示，结合Cochain使用的小型模型性能优于GPT-4。", "conclusion": "Cochain框架有效地解决了商业工作流程中的协作问题，通过结合知识和提示在减少成本的同时提高了性能，为LLMs在复杂任务中的应用提供了新的可能性。"}}
{"id": "2505.10989", "title": "RAGSynth: Synthetic Data for Robust and Faithful RAG Component Optimization", "authors": ["Haiyang Shen", "Hang Yan", "Zhongshi Xing", "Mugeng Liu", "Yue Li", "Zhiyang Chen", "Yuxiang Wang", "Jiuzheng Wang", "Yun Ma"], "abstract": "RAG can enhance the performance of LLMs on knowledge-intensive tasks. Various RAG paradigms, including vanilla, planning-based, and iterative RAG, are built upon 2 cores: the retriever, which should robustly select relevant documents across complex queries, and the generator, which should faithfully synthesize responses. However, existing retrievers rely heavily on public knowledge and struggle with queries of varying logical complexity and clue completeness, while generators frequently face fidelity problems. In this work, we introduce RAGSynth, a framework that includes a data construction modeling and a corresponding synthetic data generation implementation, designed to optimize retriever robustness and generator fidelity. Additionally, we present SynthBench, a benchmark encompassing 8 domain-specific documents across 4 domains, featuring diverse query complexities, clue completeness, and fine-grained citation granularity. Leveraging RAGSynth, we generate a large-scale synthetic dataset, including single and multi-hop. Extensive experiments demonstrate that the synthetic data significantly improves the robustness of the retrievers and the fidelity of the generators. Additional evaluations confirm that RAGSynth can also generalize well across different domains. By integrating the optimized retrievers into various RAG paradigms, we consistently observe enhanced RAG system performance. We have open-sourced the implementation on", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.10989.pdf", "abstract_url": "https://arxiv.org/abs/2505.10989", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "RAGSynth是一个框架，旨在通过合成数据优化检索器的鲁棒性和生成器的忠实度，提升LLM在知识密集型任务中的表现。", "motivation": "解决现有检索器依赖公共知识、难以处理复杂查询和线索完整性不一的问题，以及生成器面临的忠实度问题。", "method": "提出了RAGSynth框架，包括数据构建模型和相应的合成数据生成实现，并引入了SynthBench基准测试。", "result": "合成数据显著提高了检索器的鲁棒性和生成器的忠实度，且RAGSynth在不同领域具有良好泛化能力。", "conclusion": "通过优化检索器集成到各种RAG范式中，可以持续提升RAG系统的性能。"}}
{"id": "2505.11063", "title": "Think Twice Before You Act: Enhancing Agent Behavioral Safety with Thought Correction", "authors": ["Changyue Jiang", "Xudong Pan", "Min Yang"], "abstract": "LLM-based autonomous agents possess capabilities such as reasoning, tool invocation, and environment interaction, enabling the execution of complex multi-step tasks. The internal reasoning process, i.e., thought, of behavioral trajectory significantly influences tool usage and subsequent actions but can introduce potential risks. Even minor deviations in the agent's thought may trigger cascading effects leading to irreversible safety incidents. To address the safety alignment challenges in long-horizon behavioral trajectories, we propose Thought-Aligner, a plug-in dynamic thought correction module. Utilizing a lightweight and resource-efficient model, Thought-Aligner corrects each high-risk thought on the fly before each action execution. The corrected thought is then reintroduced to the agent, ensuring safer subsequent decisions and tool interactions. Importantly, Thought-Aligner modifies only the reasoning phase without altering the underlying agent framework, making it easy to deploy and widely applicable to various agent frameworks. To train the Thought-Aligner model, we construct an instruction dataset across ten representative scenarios and simulate ReAct execution trajectories, generating 5,000 diverse instructions and more than 11,400 safe and unsafe thought pairs. The model is fine-tuned using contrastive learning techniques. Experiments across three agent safety benchmarks involving 12 different LLMs demonstrate that Thought-Aligner raises agent behavioral safety from approximately 50% in the unprotected setting to 90% on average. Additionally, Thought-Aligner maintains response latency below 100ms with minimal resource usage, demonstrating its capability for efficient deployment, broad applicability, and timely responsiveness. This method thus provides a practical dynamic safety solution for the LLM-based agents.", "subjects": "Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.11063.pdf", "abstract_url": "https://arxiv.org/abs/2505.11063", "categories": ["Artificial Intelligence (cs.AI)", "Cryptography and Security (cs.CR)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出Thought-Aligner，一个动态思维校正模块，用于增强基于LLM的自主代理的行为安全性。通过实时校正高风险思维，确保更安全的决策和工具交互，同时保持低延迟和资源效率。", "motivation": "解决基于LLM的自主代理在长视野行为轨迹中的安全对齐挑战，防止因思维偏差引发的不可逆安全事件。", "method": "提出Thought-Aligner模块，利用轻量级模型实时校正高风险思维，采用对比学习技术进行微调，并在多种场景下构建指令数据集进行训练。", "result": "实验表明，Thought-Aligner将代理行为安全从约50%提升至90%，响应延迟低于100ms，资源使用极少。", "conclusion": "Thought-Aligner为基于LLM的代理提供了一种实用的动态安全解决方案，具有高效部署、广泛适用性和及时响应能力。"}}
{"id": "2505.11010", "title": "Review-Instruct: A Review-Driven Multi-Turn Conversations Generation Method for Large Language Models", "authors": ["Jiangxu Wu", "Cong Wang", "TianHuang Su", "Jun Yang", "Haozhi Lin", "Chao Zhang", "Ming Peng", "Kai Shi", "SongPan Yang", "BinQing Pan", "ZiXian Li", "Ni Yang", "ZhenYu Yang"], "abstract": "The effectiveness of large language models (LLMs) in conversational AI is hindered by their reliance on single-turn supervised fine-tuning (SFT) data, which limits contextual coherence in multi-turn dialogues. Existing methods for generating multi-turn dialogue data struggle to ensure both diversity and quality in instructions. To address this, we propose Review-Instruct, a novel framework that synthesizes multi-turn conversations through an iterative \"Ask-Respond-Review\" process involving three agent roles: a Candidate, multiple Reviewers, and a Chairman. The framework iteratively refines instructions by incorporating Reviewer feedback, enhancing dialogue diversity and difficulty. We construct a multi-turn dataset using the Alpaca dataset and fine-tune the LLaMA2-13B model. Evaluations on MT-Bench, MMLU-Pro, and Auto-Arena demonstrate significant improvements, achieving absolute gains of 2.9\\% on MMLU-Pro and 2\\% on MT-Bench compared to prior state-of-the-art models based on LLaMA2-13B. Ablation studies confirm the critical role of the Review stage and the use of multiple Reviewers in boosting instruction diversity and difficulty. Our work highlights the potential of review-driven, multi-agent frameworks for generating high-quality conversational data at scale.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "ACL2025 Accepted", "pdf_url": "https://arxiv.org/pdf/2505.11010.pdf", "abstract_url": "https://arxiv.org/abs/2505.11010", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为Review-Instruct的新框架，通过迭代的“提问-回答-评审”过程，利用三个代理角色（候选者、多个评审者和主席）合成多轮对话，以提高对话的多样性和难度。通过在Alpaca数据集上构建多轮对话数据集并对LLaMA2-13B模型进行微调，实验结果表明在多个评估基准上取得了显著改进。", "motivation": "大型语言模型（LLMs）在对话AI中的有效性受到其依赖单轮监督微调（SFT）数据的限制，这限制了多轮对话中的上下文连贯性。现有的多轮对话数据生成方法难以确保指令的多样性和质量。", "method": "提出Review-Instruct框架，通过迭代的“Ask-Respond-Review”过程，利用候选者、多个评审者和主席三个代理角色，迭代细化指令，通过评审者反馈增强对话的多样性和难度。", "result": "在MT-Bench、MMLU-Pro和Auto-Arena上的评估显示，与基于LLaMA2-13B的先前最先进模型相比，MMLU-Pro和MT-Bench分别实现了2.9%和2%的绝对增益。消融研究证实了评审阶段和多个评审者在提升指令多样性和难度中的关键作用。", "conclusion": "我们的工作突出了评审驱动的多代理框架在规模化生成高质量对话数据方面的潜力。"}}
{"id": "2505.11107", "title": "Group Think: Multiple Concurrent Reasoning Agents Collaborating at Token Level Granularity", "authors": ["Chan-Jan Hsu", "Davide Buffelli", "Jamie McGowan", "Feng-Ting Liao", "Yi-Chang Chen", "Sattar Vakili", "Da-shan Shiu"], "abstract": "Recent advances in large language models (LLMs) have demonstrated the power of reasoning through self-generated chains of thought. Multiple reasoning agents can collaborate to raise joint reasoning quality above individual outcomes. However, such agents typically interact in a turn-based manner, trading increased latency for improved quality. In this paper, we propose Group Think--a single LLM that acts as multiple concurrent reasoning agents, or thinkers. With shared visibility into each other's partial generation progress, Group Think introduces a new concurrent-reasoning paradigm in which multiple reasoning trajectories adapt dynamically to one another at the token level. For example, a reasoning thread may shift its generation mid-sentence upon detecting that another thread is better positioned to continue. This fine-grained, token-level collaboration enables Group Think to reduce redundant reasoning and improve quality while achieving significantly lower latency. Moreover, its concurrent nature allows for efficient utilization of idle computational resources, making it especially suitable for edge inference, where very small batch size often underutilizes local~GPUs. We give a simple and generalizable modification that enables any existing LLM to perform Group Think on a local GPU. We also present an evaluation strategy to benchmark reasoning latency and empirically demonstrate latency improvements using open-source LLMs that were not explicitly trained for Group Think. We hope this work paves the way for future LLMs to exhibit more sophisticated and more efficient collaborative behavior for higher quality generation.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.11107.pdf", "abstract_url": "https://arxiv.org/abs/2505.11107", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了Group Think，一种让单个大型语言模型（LLM）作为多个并发推理代理工作的新方法，通过在令牌级别进行动态协作，以减少冗余推理并提高质量，同时显著降低延迟。", "motivation": "解决现有多个推理代理在协作时因轮流交互而增加延迟的问题，以及在小批量推理时本地GPU资源利用不足的问题。", "method": "提出Group Think方法，通过简单的修改使现有LLM能够在本地GPU上作为多个并发推理代理工作，实现令牌级别的动态协作。", "result": "实证研究表明，Group Think能够在不显式训练的情况下，利用开源LLM实现延迟的显著改善。", "conclusion": "Group Think为未来LLM展示更复杂、更高效的协作行为以提高生成质量铺平了道路，特别适合边缘推理场景。"}}
{"id": "2505.11135", "title": "Scalability of Reinforcement Learning Methods for Dispatching in Semiconductor Frontend Fabs: A Comparison of Open-Source Models with Real Industry Datasets", "authors": ["Patrick Stöckermann", "Henning Südfeld", "Alessandro Immordino", "Thomas Altenmüller", "Marc Wegmann", "Martin Gebser", "Konstantin Schekotihin", "Georg Seidel", "Chew Wye Chan", "Fei Fei Zhang"], "abstract": "Benchmark datasets are crucial for evaluating approaches to scheduling or dispatching in the semiconductor industry during the development and deployment phases. However, commonly used benchmark datasets like the Minifab or SMT2020 lack the complex details and constraints found in real-world scenarios. To mitigate this shortcoming, we compare open-source simulation models with a real industry dataset to evaluate how optimization methods scale with different levels of complexity. Specifically, we focus on Reinforcement Learning methods, performing optimization based on policy-gradient and Evolution Strategies. Our research provides insights into the effectiveness of these optimization methods and their applicability to realistic semiconductor frontend fab simulations. We show that our proposed Evolution Strategies-based method scales much better than a comparable policy-gradient-based approach. Moreover, we identify the selection and combination of relevant bottleneck tools to control by the agent as crucial for an efficient optimization. For the generalization across different loading scenarios and stochastic tool failure patterns, we achieve advantages when utilizing a diverse training dataset. While the overall approach is computationally expensive, it manages to scale well with the number of CPU cores used for training. For the real industry dataset, we achieve an improvement of up to 4% regarding tardiness and up to 1% regarding throughput. For the less complex open-source models Minifab and SMT2020, we observe double-digit percentage improvement in tardiness and single digit percentage improvement in throughput by use of Evolution Strategies.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.11135.pdf", "abstract_url": "https://arxiv.org/abs/2505.11135", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Neural and Evolutionary Computing (cs.NE)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文比较了开源模拟模型与真实行业数据集，评估了强化学习方法在半导体前端工厂调度中的可扩展性，提出基于进化策略的方法比策略梯度方法更具优势。", "motivation": "解决半导体行业中调度或分配问题评估方法的不足，特别是常用基准数据集缺乏真实世界复杂细节和约束的问题。", "method": "使用强化学习方法，特别是基于策略梯度和进化策略的优化方法，比较开源模拟模型与真实行业数据集。", "result": "提出的基于进化策略的方法在可扩展性上优于策略梯度方法，对于真实行业数据集，在延迟和吞吐量上分别实现了高达4%和1%的改进。", "conclusion": "进化策略方法在半导体前端工厂模拟中表现出更好的可扩展性和效率，多样化的训练数据集有助于提高方法的泛化能力。"}}
{"id": "2505.11136", "title": "Reinforcement Learning for AMR Charging Decisions: The Impact of Reward and Action Space Design", "authors": ["Janik Bischoff", "Alexandru Rinciog", "Anne Meyer"], "abstract": "We propose a novel reinforcement learning (RL) design to optimize the charging strategy for autonomous mobile robots in large-scale block stacking warehouses. RL design involves a wide array of choices that can mostly only be evaluated through lengthy experimentation. Our study focuses on how different reward and action space configurations, ranging from flexible setups to more guided, domain-informed design configurations, affect the agent performance. Using heuristic charging strategies as a baseline, we demonstrate the superiority of flexible, RL-based approaches in terms of service times. Furthermore, our findings highlight a trade-off: While more open-ended designs are able to discover well-performing strategies on their own, they may require longer convergence times and are less stable, whereas guided configurations lead to a more stable learning process but display a more limited generalization potential. Our contributions are threefold. First, we extend SLAPStack, an open-source, RL-compatible simulation-framework to accommodate charging strategies. Second, we introduce a novel RL design for tackling the charging strategy problem. Finally, we introduce several novel adaptive baseline heuristics and reproducibly evaluate the design using a Proximal Policy Optimization agent and varying different design configurations, with a focus on reward.", "subjects": "Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": "Under review LION19: The 19th Learning and Intelligent OptimizatioN Conference", "pdf_url": "https://arxiv.org/pdf/2505.11136.pdf", "abstract_url": "https://arxiv.org/abs/2505.11136", "categories": ["Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新颖的强化学习设计，用于优化大规模块堆叠仓库中自主移动机器人的充电策略。研究重点探讨了不同奖励和动作空间配置对代理性能的影响，并展示了基于强化学习的灵活方法在服务时间上的优越性。", "motivation": "解决在大规模块堆叠仓库中自主移动机器人充电策略优化的问题，特别是在强化学习设计中奖励和动作空间配置的选择对代理性能的影响。", "method": "使用启发式充电策略作为基线，通过扩展SLAPStack（一个开源的、兼容强化学习的模拟框架）来适应充电策略，并引入一种新颖的强化学习设计来解决充电策略问题。", "result": "研究发现，灵活的设计能够自行发现性能良好的策略，但可能需要更长的收敛时间且稳定性较差；而引导式配置则能带来更稳定的学习过程，但泛化潜力有限。", "conclusion": "本文的贡献包括扩展SLAPStack以适应充电策略、引入新颖的强化学习设计以及提出几种新颖的自适应基线启发式方法，并通过近端策略优化代理和不同的设计配置进行可重复的评估。"}}
{"id": "2505.11289", "title": "Meta-World+: An Improved, Standardized, RL Benchmark", "authors": ["Reginald McLean", "Evangelos Chatzaroulas", "Luc McCutcheon", "Frank Röder", "Tianhe Yu", "Zhanpeng He", "K.R. Zentner", "Ryan Julian", "J K Terry", "Isaac Woungang", "Nariman Farsad", "Pablo Samuel Castro"], "abstract": "Meta-World is widely used for evaluating multi-task and meta-reinforcement learning agents, which are challenged to master diverse skills simultaneously. Since its introduction however, there have been numerous undocumented changes which inhibit a fair comparison of algorithms. This work strives to disambiguate these results from the literature, while also leveraging the past versions of Meta-World to provide insights into multi-task and meta-reinforcement learning benchmark design. Through this process we release a new open-source version of Meta-World (", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.11289.pdf", "abstract_url": "https://arxiv.org/abs/2505.11289", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了Meta-World+，一个改进、标准化的强化学习基准，旨在解决Meta-World在评估多任务和元强化学习代理时存在的未记录变更问题，促进算法公平比较，并提供了对基准设计的见解。", "motivation": "解决Meta-World在多任务和元强化学习评估中因未记录变更而导致的算法比较不公平问题。", "method": "通过分析Meta-World的历史版本，明确文献中的结果差异，并发布新的开源版本Meta-World+。", "result": "提出了一个改进、标准化的强化学习基准Meta-World+，促进了算法之间的公平比较。", "conclusion": "Meta-World+作为一个改进的基准，不仅解决了算法比较的不公平问题，还为多任务和元强化学习基准的设计提供了有价值的见解。"}}
{"id": "2505.11478", "title": "Automatic Reward Shaping from Confounded Offline Data", "authors": ["Mingxuan Li", "Junzhe Zhang", "Elias Bareinboim"], "abstract": "A key task in Artificial Intelligence is learning effective policies for controlling agents in unknown environments to optimize performance measures. Off-policy learning methods, like Q-learning, allow learners to make optimal decisions based on past experiences. This paper studies off-policy learning from biased data in complex and high-dimensional domains where \\emph{unobserved confounding} cannot be ruled out a priori. Building on the well-celebrated Deep Q-Network (DQN), we propose a novel deep reinforcement learning algorithm robust to confounding biases in observed data. Specifically, our algorithm attempts to find a safe policy for the worst-case environment compatible with the observations. We apply our method to twelve confounded Atari games, and find that it consistently dominates the standard DQN in all games where the observed input to the behavioral and target policies mismatch and unobserved confounders exist.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "ICML 2025", "pdf_url": "https://arxiv.org/pdf/2505.11478.pdf", "abstract_url": "https://arxiv.org/abs/2505.11478", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新颖的深度强化学习算法，旨在从存在未观察到的混杂因素的离线数据中学习有效策略，该算法在十二个存在混杂因素的Atari游戏中表现优于标准DQN。", "motivation": "解决在复杂和高维领域中，从存在未观察到混杂因素的偏置数据中进行离策略学习的问题。", "method": "基于深度Q网络（DQN），提出了一种对观察数据中的混杂偏置具有鲁棒性的深度强化学习算法，寻找与观察兼容的最坏情况下环境的安全策略。", "result": "在十二个存在混杂因素的Atari游戏中，该算法在所有观察到行为和目标策略输入不匹配且存在未观察到混杂因素的游戏中一致优于标准DQN。", "conclusion": "提出的算法能够有效处理观察数据中的混杂偏置，为在存在未观察混杂因素的环境中进行强化学习提供了新的解决方案。"}}
{"id": "2505.10586", "title": "Towards Automated Situation Awareness: A RAG-Based Framework for Peacebuilding Reports", "authors": ["Poli A. Nemkova", "Suleyman O. Polat", "Rafid I. Jahan", "Sagnik Ray Choudhury", "Sun-joo Lee", "Shouryadipta Sarkar", "Mark V. Albert"], "abstract": "Timely and accurate situation awareness is vital for decision-making in humanitarian response, conflict monitoring, and early warning and early action. However, the manual analysis of vast and heterogeneous data sources often results in delays, limiting the effectiveness of interventions. This paper introduces a dynamic Retrieval-Augmented Generation (RAG) system that autonomously generates situation awareness reports by integrating real-time data from diverse sources, including news articles, conflict event databases, and economic indicators. Our system constructs query-specific knowledge bases on demand, ensuring timely, relevant, and accurate insights.", "subjects": "Computers and Society (cs.CY); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.10586.pdf", "abstract_url": "https://arxiv.org/abs/2505.10586", "categories": ["Computers and Society (cs.CY)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了一种基于检索增强生成（RAG）的动态系统，旨在通过整合来自新闻文章、冲突事件数据库和经济指标等多种来源的实时数据，自动生成和平建设报告，以提高决策的及时性和准确性。", "motivation": "在人道主义响应、冲突监测以及早期预警和早期行动中，及时准确的情境意识对决策至关重要。然而，对大量异质数据的手动分析常常导致延迟，限制了干预的有效性。", "method": "采用检索增强生成（RAG）技术，构建一个能够按需构建查询特定知识库的系统，整合实时数据以生成情境意识报告。", "result": "该系统能够确保提供及时、相关且准确的洞察，从而支持更有效的决策制定。", "conclusion": "通过自动化情境意识报告的生成，该系统有望提高和平建设和人道主义响应领域的决策效率和效果。"}}
{"id": "2505.10593", "title": "LLM-Explorer: Towards Efficient and Affordable LLM-based Exploration for Mobile Apps", "authors": ["Shanhui Zhao", "Hao Wen", "Wenjie Du", "Cheng Liang", "Yunxin Liu", "Xiaozhou Ye", "Ye Ouyang", "Yuanchun Li"], "abstract": "Large language models (LLMs) have opened new opportunities for automated mobile app exploration, an important and challenging problem that used to suffer from the difficulty of generating meaningful UI interactions. However, existing LLM-based exploration approaches rely heavily on LLMs to generate actions in almost every step, leading to a huge cost of token fees and computational resources. We argue that such extensive usage of LLMs is neither necessary nor effective, since many actions during exploration do not require, or may even be biased by the abilities of LLMs. Further, based on the insight that a precise and compact knowledge plays the central role for effective exploration, we introduce LLM-Explorer, a new exploration agent designed for efficiency and affordability. LLM-Explorer uses LLMs primarily for maintaining the knowledge instead of generating actions, and knowledge is used to guide action generation in a LLM-less manner. Based on a comparison with 5 strong baselines on 20 typical apps, LLM-Explorer was able to achieve the fastest and highest coverage among all automated app explorers, with over 148x lower cost than the state-of-the-art LLM-based approach.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": "Accepted by MobiCom 2025", "pdf_url": "https://arxiv.org/pdf/2505.10593.pdf", "abstract_url": "https://arxiv.org/abs/2505.10593", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "LLM-Explorer是一种新型的移动应用探索代理，旨在通过减少对大型语言模型(LLMs)的依赖来提高效率和降低成本，同时保持高覆盖率。", "motivation": "现有的基于LLM的移动应用探索方法在每一步都大量依赖LLMs生成动作，导致高昂的代币费用和计算资源消耗。这种方法既不必要也不高效，因为许多探索动作并不需要LLMs的能力，甚至可能受到LLMs能力的偏见影响。", "method": "LLM-Explorer主要通过维护知识而非生成动作来使用LLMs，并利用这些知识以不依赖LLMs的方式指导动作生成，从而实现高效和经济的探索。", "result": "在20个典型应用上与5个强基线比较，LLM-Explorer在所有自动化应用探索器中实现了最快和最高的覆盖率，成本比最先进的基于LLM的方法低148倍以上。", "conclusion": "LLM-Explorer展示了通过减少对LLMs的依赖，同时利用其维护精确和紧凑的知识，可以实现更高效、更经济的移动应用自动化探索。"}}
{"id": "2505.10609", "title": "Agent Name Service (ANS): A Universal Directory for Secure AI Agent Discovery and Interoperability", "authors": ["Ken Huang", "Vineeth Sai Narajala", "Idan Habler", "Akram Sheriff"], "abstract": "The proliferation of AI agents requires robust mechanisms for secure discovery. This paper introduces the Agent Name Service (ANS), a novel architecture based on DNS addressing the lack of a public agent discovery framework. ANS provides a protocol-agnostic registry infrastructure that leverages Public Key Infrastructure (PKI) certificates for verifiable agent identity and trust. The architecture features several key innovations: a formalized agent registration and renewal mechanism for lifecycle management; DNS-inspired naming conventions with capability-aware resolution; a modular Protocol Adapter Layer supporting diverse communication standards (A2A, MCP, ACP etc.); and precisely defined algorithms for secure resolution. We implement structured communication using JSON Schema and conduct a comprehensive threat analysis of our proposal. The result is a foundational directory service addressing the core challenges of secured discovery and interaction in multi-agent systems, paving the way for future interoperable, trustworthy, and scalable agent ecosystems.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA); Networking and Internet Architecture (cs.NI)", "comments": "15 pages, 6 figures, 6 code listings, Supported and endorsed by OWASP GenAI ASI Project", "pdf_url": "https://arxiv.org/pdf/2505.10609.pdf", "abstract_url": "https://arxiv.org/abs/2505.10609", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)", "Networking and Internet Architecture (cs.NI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了代理名称服务（ANS），一种基于DNS的新型架构，旨在解决AI代理安全发现的问题。ANS提供了一个协议无关的注册基础设施，利用公钥基础设施（PKI）证书进行可验证的代理身份和信任管理。", "motivation": "随着AI代理的激增，缺乏一个公共的代理发现框架，这促使了ANS的提出，以解决安全发现和互操作性的核心挑战。", "method": "ANS架构包括几个关键创新：正式的代理注册和更新机制、DNS启发的命名约定、模块化的协议适配层支持多样化的通信标准，以及精确定义的安全解析算法。", "result": "通过实施结构化通信和使用JSON Schema，以及进行全面的威胁分析，ANS成为一个基础目录服务，为未来的互操作、可信和可扩展的代理生态系统铺平了道路。", "conclusion": "ANS为解决多代理系统中安全发现和交互的核心挑战提供了一个基础目录服务，促进了未来互操作、可信和可扩展的代理生态系统的发展。"}}
{"id": "2505.10607", "title": "MONAQ: Multi-Objective Neural Architecture Querying for Time-Series Analysis on Resource-Constrained Devices", "authors": ["Patara Trirat", "Jae-Gil Lee"], "abstract": "The growing use of smartphones and IoT devices necessitates efficient time-series analysis on resource-constrained hardware, which is critical for sensing applications such as human activity recognition and air quality prediction. Recent efforts in hardware-aware neural architecture search (NAS) automate architecture discovery for specific platforms; however, none focus on general time-series analysis with edge deployment. Leveraging the problem-solving and reasoning capabilities of large language models (LLM), we propose MONAQ, a novel framework that reformulates NAS into Multi-Objective Neural Architecture Querying tasks. MONAQ is equipped with multimodal query generation for processing multimodal time-series inputs and hardware constraints, alongside an LLM agent-based multi-objective search to achieve deployment-ready models via code generation. By integrating numerical data, time-series images, and textual descriptions, MONAQ improves an LLM's understanding of time-series data. Experiments on fifteen datasets demonstrate that MONAQ-discovered models outperform both handcrafted models and NAS baselines while being more efficient.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.10607.pdf", "abstract_url": "https://arxiv.org/abs/2505.10607", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "MONAQ是一个新颖的框架，通过将神经架构搜索（NAS）重新定义为多目标神经架构查询任务，利用大型语言模型（LLM）的问题解决和推理能力，为资源受限设备上的时间序列分析提供高效解决方案。", "motivation": "智能手机和物联网设备的日益普及，使得在资源受限的硬件上进行高效的时间序列分析变得尤为重要，这对于如人类活动识别和空气质量预测等传感应用至关重要。现有的硬件感知神经架构搜索（NAS）方法未能专注于边缘部署的通用时间序列分析。", "method": "MONAQ框架配备了多模态查询生成，用于处理多模态时间序列输入和硬件约束，同时采用基于LLM代理的多目标搜索，通过代码生成实现部署就绪的模型。", "result": "在十五个数据集上的实验表明，MONAQ发现的模型在性能上优于手工制作的模型和NAS基线，同时更加高效。", "conclusion": "MONAQ通过整合数值数据、时间序列图像和文本描述，提高了LLM对时间序列数据的理解，为资源受限设备上的时间序列分析提供了一种有效的解决方案。"}}
{"id": "2505.11368", "title": "GuideBench: Benchmarking Domain-Oriented Guideline Following for LLM Agents", "authors": ["Lingxiao Diao", "Xinyue Xu", "Wanxuan Sun", "Cheng Yang", "Zhuosheng Zhang"], "abstract": "Large language models (LLMs) have been widely deployed as autonomous agents capable of following user instructions and making decisions in real-world applications. Previous studies have made notable progress in benchmarking the instruction following capabilities of LLMs in general domains, with a primary focus on their inherent commonsense knowledge. Recently, LLMs have been increasingly deployed as domain-oriented agents, which rely on domain-oriented guidelines that may conflict with their commonsense knowledge. These guidelines exhibit two key characteristics: they consist of a wide range of domain-oriented rules and are subject to frequent updates. Despite these challenges, the absence of comprehensive benchmarks for evaluating the domain-oriented guideline following capabilities of LLMs presents a significant obstacle to their effective assessment and further development. In this paper, we introduce GuideBench, a comprehensive benchmark designed to evaluate guideline following performance of LLMs. GuideBench evaluates LLMs on three critical aspects: (i) adherence to diverse rules, (ii) robustness to rule updates, and (iii) alignment with human preferences. Experimental results on a range of LLMs indicate substantial opportunities for improving their ability to follow domain-oriented guidelines.", "subjects": "Computation and Language (cs.CL)", "comments": "ACL 2025 Main Conference", "pdf_url": "https://arxiv.org/pdf/2505.11368.pdf", "abstract_url": "https://arxiv.org/abs/2505.11368", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了GuideBench，一个用于评估大型语言模型（LLMs）遵循领域导向指南能力的综合基准。GuideBench从三个方面评估LLMs：遵循多样规则的能力、对规则更新的鲁棒性以及与人类偏好的对齐。实验结果表明，LLMs在遵循领域导向指南方面有显著的改进空间。", "motivation": "随着大型语言模型（LLMs）作为自主代理在现实世界应用中的广泛部署，评估其在特定领域内遵循指南的能力变得尤为重要。然而，缺乏全面的基准测试阻碍了对LLMs在这一能力上的有效评估和进一步发展。", "method": "本文提出了GuideBench，一个旨在评估LLMs遵循领域导向指南能力的综合基准。GuideBench从三个关键方面进行评估：对多样规则的遵循、对规则更新的鲁棒性以及与人类偏好的对齐。", "result": "实验结果表明，当前的大型语言模型在遵循领域导向指南方面存在显著的改进机会，特别是在处理多样规则和适应规则更新方面。", "conclusion": "GuideBench的引入为评估和提升LLMs在特定领域内遵循指南的能力提供了重要的工具和方向，揭示了当前模型在这一领域的不足和改进潜力。"}}
{"id": "2505.10640", "title": "The Hitchhikers Guide to Production-ready Trustworthy Foundation Model powered Software (FMware)", "authors": ["Kirill Vasilevski", "Benjamin Rombaut", "Gopi Krishnan Rajbahadur", "Gustavo A. Oliva", "Keheliya Gallaba", "Filipe R. Cogo", "Jiahuei", "Dayi Lin", "Haoxiang Zhang", "Bouyan Chen", "Kishanthan Thangarajah", "Ahmed E. Hassan", "Zhen Ming", "Jiang"], "abstract": "Foundation Models (FMs) such as Large Language Models (LLMs) are reshaping the software industry by enabling FMware, systems that integrate these FMs as core components. In this KDD 2025 tutorial, we present a comprehensive exploration of FMware that combines a curated catalogue of challenges with real-world production concerns. We first discuss the state of research and practice in building FMware. We further examine the difficulties in selecting suitable models, aligning high-quality domain-specific data, engineering robust prompts, and orchestrating autonomous agents. We then address the complex journey from impressive demos to production-ready systems by outlining issues in system testing, optimization, deployment, and integration with legacy software. Drawing on our industrial experience and recent research in the area, we provide actionable insights and a technology roadmap for overcoming these challenges. Attendees will gain practical strategies to enable the creation of trustworthy FMware in the evolving technology landscape.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.10640.pdf", "abstract_url": "https://arxiv.org/abs/2505.10640", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本教程全面探讨了以基础模型（FMs）为核心的软件（FMware）的构建，包括挑战、生产关注点及解决方案。", "motivation": "解决将基础模型（如大型语言模型）集成到生产就绪软件中的挑战，确保其可信赖性。", "method": "结合工业经验和最新研究，提供挑战目录、生产关注点分析及技术路线图。", "result": "提供了构建可信赖FMware的实用策略和技术路线图。", "conclusion": "通过综合研究和实践指导，促进了FMware从概念到生产就绪系统的发展。"}}
{"id": "2505.10681", "title": "Towards an LLM-powered Social Digital Twinning Platform", "authors": ["Önder Gürcan", "Vanja Falck", "Markus G. Rousseau", "Larissa L. Lima"], "abstract": "We present Social Digital Twinner, an innovative social simulation tool for exploring plausible effects of what-if scenarios in complex adaptive social systems. The architecture is composed of three seamlessly integrated parts: a data infrastructure featuring real-world data and a multi-dimensionally representative synthetic population of citizens, an LLM-enabled agent-based simulation engine, and a user interface that enable intuitive, natural language interactions with the simulation engine and the artificial agents (i.e. citizens). Social Digital Twinner facilitates real-time engagement and empowers stakeholders to collaboratively design, test, and refine intervention measures. The approach is promoting a data-driven and evidence-based approach to societal problem-solving. We demonstrate the tool's interactive capabilities by addressing the critical issue of youth school dropouts in Kragero, Norway, showcasing its ability to create and execute a dedicated social digital twin using natural language.", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)", "comments": "13 pages, 3 figures, 23rd International Conference on Practical applications of Agents and Multi-Agent Systems (PAAMS 2025)", "pdf_url": "https://arxiv.org/pdf/2505.10681.pdf", "abstract_url": "https://arxiv.org/abs/2505.10681", "categories": ["Computers and Society (cs.CY)", "Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "介绍了Social Digital Twinner，一个创新的社会模拟工具，用于探索复杂适应性社会系统中假设情景的潜在影响。", "motivation": "解决社会问题解决中的数据驱动和证据基础方法的需求，特别是在复杂社会系统中测试干预措施的效果。", "method": "结合了数据基础设施、LLM支持的基于代理的模拟引擎和用户界面，支持自然语言交互。", "result": "展示了工具在挪威Kragero解决青年辍学问题中的交互能力，能够创建和执行专用的社会数字孪生。", "conclusion": "Social Digital Twinner促进了实时参与，使利益相关者能够协作设计、测试和完善干预措施，推动了社会问题解决的数据驱动和证据基础方法。"}}
{"id": "2505.10831", "title": "Creating General User Models from Computer Use", "authors": ["Omar Shaikh", "Shardul Sapkota", "Shan Rizvi", "Eric Horvitz", "Joon Sung Park", "Diyi Yang", "Michael S. Bernstein"], "abstract": "Human-computer interaction has long imagined technology that understands us-from our preferences and habits, to the timing and purpose of our everyday actions. Yet current user models remain fragmented, narrowly tailored to specific apps, and incapable of the flexible reasoning required to fulfill these visions. This paper presents an architecture for a general user model (GUM) that learns about you by observing any interaction you have with your computer. The GUM takes as input any unstructured observation of a user (e.g., device screenshots) and constructs confidence-weighted propositions that capture that user knowledge and preferences. GUMs can infer that a user is preparing for a wedding they're attending from messages with a friend. Or recognize that a user is struggling with a collaborator's feedback on a draft by observing multiple stalled edits and a switch to reading related work. GUMs introduce an architecture that infers new propositions about a user from multimodal observations, retrieves related propositions for context, and continuously revises existing propositions. To illustrate the breadth of applications that GUMs enable, we demonstrate how they augment chat-based assistants with context, manage OS notifications to selectively surface important information, and enable interactive agents that adapt to preferences across apps. We also instantiate proactive assistants (GUMBOs) that discover and execute useful suggestions on a user's behalf using their GUM. In our evaluations, we find that GUMs make calibrated and accurate inferences about users, and that assistants built on GUMs proactively identify and perform actions that users wouldn't think to request explicitly. Altogether, GUMs introduce methods that leverage multimodal models to understand unstructured context, enabling long-standing visions of HCI and entirely new interactive systems that anticipate user needs.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.10831.pdf", "abstract_url": "https://arxiv.org/abs/2505.10831", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种通用用户模型（GUM）架构，旨在通过观察用户与计算机的任何互动来学习用户的知识和偏好，实现跨应用的灵活推理和个性化服务。", "motivation": "解决当前用户模型碎片化、局限于特定应用、缺乏灵活推理能力的问题，以实现技术对用户更深层次的理解和服务。", "method": "采用一种能够从多模态观察中推断用户新命题、检索相关命题以提供上下文，并持续修订现有命题的架构。", "result": "评估显示，GUM能够对用户做出校准和准确的推断，基于GUM构建的助手能够主动识别并执行用户未明确请求的操作。", "conclusion": "GUM通过利用多模态模型理解非结构化上下文，实现了人机交互的长期愿景和全新的交互系统，能够预见用户需求。"}}
{"id": "2505.10838", "title": "LARGO: Latent Adversarial Reflection through Gradient Optimization for Jailbreaking LLMs", "authors": ["Ran Li", "Hao Wang", "Chengzhi Mao"], "abstract": "Efficient red-teaming method to uncover vulnerabilities in Large Language Models (LLMs) is crucial. While recent attacks often use LLMs as optimizers, the discrete language space make gradient-based methods struggle. We introduce LARGO (Latent Adversarial Reflection through Gradient Optimization), a novel latent self-reflection attack that reasserts the power of gradient-based optimization for generating fluent jailbreaking prompts. By operating within the LLM's continuous latent space, LARGO first optimizes an adversarial latent vector and then recursively call the same LLM to decode the latent into natural language. This methodology yields a fast, effective, and transferable attack that produces fluent and stealthy prompts. On standard benchmarks like AdvBench and JailbreakBench, LARGO surpasses leading jailbreaking techniques, including AutoDAN, by 44 points in attack success rate. Our findings demonstrate a potent alternative to agentic LLM prompting, highlighting the efficacy of interpreting and attacking LLM internals through gradient optimization.", "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL); Cryptography and Security (cs.CR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.10838.pdf", "abstract_url": "https://arxiv.org/abs/2505.10838", "categories": ["Machine Learning (cs.LG)", "Computation and Language (cs.CL)", "Cryptography and Security (cs.CR)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "LARGO是一种新型的潜在自反射攻击方法，通过梯度优化在大型语言模型（LLMs）的连续潜在空间中操作，以生成流畅的越狱提示。该方法在AdvBench和JailbreakBench等标准基准测试中，攻击成功率比现有技术高出44个点。", "motivation": "为了解决在离散语言空间中基于梯度的方法难以有效发现大型语言模型（LLMs）漏洞的问题。", "method": "LARGO通过在LLM的连续潜在空间中优化对抗性潜在向量，并递归调用同一LLM将潜在向量解码为自然语言，实现了快速、有效且可转移的攻击。", "result": "在AdvBench和JailbreakBench等标准基准测试中，LARGO的攻击成功率比领先的越狱技术（如AutoDAN）高出44个点。", "conclusion": "LARGO展示了通过梯度优化解释和攻击LLM内部的有效性，为代理LLM提示提供了一种强有力的替代方案。"}}
{"id": "2505.10872", "title": "REI-Bench: Can Embodied Agents Understand Vague Human Instructions in Task Planning?", "authors": ["Chenxi Jiang", "Chuhao Zhou", "Jianfei Yang"], "abstract": "Robot task planning decomposes human instructions into executable action sequences that enable robots to complete a series of complex tasks. Although recent large language model (LLM)-based task planners achieve amazing performance, they assume that human instructions are clear and straightforward. However, real-world users are not experts, and their instructions to robots often contain significant vagueness. Linguists suggest that such vagueness frequently arises from referring expressions (REs), whose meanings depend heavily on dialogue context and environment. This vagueness is even more prevalent among the elderly and children, who robots should serve more. This paper studies how such vagueness in REs within human instructions affects LLM-based robot task planning and how to overcome this issue. To this end, we propose the first robot task planning benchmark with vague REs (REI-Bench), where we discover that the vagueness of REs can severely degrade robot planning performance, leading to success rate drops of up to 77.9%. We also observe that most failure cases stem from missing objects in planners. To mitigate the REs issue, we propose a simple yet effective approach: task-oriented context cognition, which generates clear instructions for robots, achieving state-of-the-art performance compared to aware prompt and chains of thought. This work contributes to the research community of human-robot interaction (HRI) by making robot task planning more practical, particularly for non-expert users, e.g., the elderly and children.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "Submitted to CoRL 2025, under review", "pdf_url": "https://arxiv.org/pdf/2505.10872.pdf", "abstract_url": "https://arxiv.org/abs/2505.10872", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了REI-Bench，第一个包含模糊指代表达（REs）的机器人任务规划基准，研究发现REs的模糊性会严重降低基于大型语言模型（LLM）的机器人任务规划性能，成功率下降高达77.9%。为了缓解这一问题，作者提出了一种简单而有效的方法：任务导向的上下文认知，该方法为机器人生成清晰的指令，实现了与现有提示和思维链相比的最先进性能。", "motivation": "解决现实世界中非专家用户（如老人和儿童）给机器人下达的指令中存在的模糊指代表达（REs）问题，这些问题严重影响了基于大型语言模型（LLM）的机器人任务规划性能。", "method": "提出了REI-Bench基准，用于评估模糊REs对机器人任务规划的影响，并提出任务导向的上下文认知方法，通过生成清晰指令来克服REs的模糊性问题。", "result": "研究发现模糊REs会导致机器人规划性能显著下降，成功率下降高达77.9%。提出的任务导向的上下文认知方法在克服REs模糊性方面表现出色，实现了最先进的性能。", "conclusion": "这项工作通过使机器人任务规划更加实用，特别是对于非专家用户（如老人和儿童），为人机交互（HRI）研究社区做出了贡献。"}}
{"id": "2505.11154", "title": "MPMA: Preference Manipulation Attack Against Model Context Protocol", "authors": ["Zihan Wang", "Hongwei Li", "Rui Zhang", "Yu Liu", "Wenbo Jiang", "Wenshu Fan", "Qingchuan Zhao", "Guowen Xu"], "abstract": "Model Context Protocol (MCP) standardizes interface mapping for large language models (LLMs) to access external data and tools, which revolutionizes the paradigm of tool selection and facilitates the rapid expansion of the LLM agent tool ecosystem. However, as the MCP is increasingly adopted, third-party customized versions of the MCP server expose potential security vulnerabilities. In this paper, we first introduce a novel security threat, which we term the MCP Preference Manipulation Attack (MPMA). An attacker deploys a customized MCP server to manipulate LLMs, causing them to prioritize it over other competing MCP servers. This can result in economic benefits for attackers, such as revenue from paid MCP services or advertising income generated from free servers. To achieve MPMA, we first design a Direct Preference Manipulation Attack ($\\mathtt{DPMA}$) that achieves significant effectiveness by inserting the manipulative word and phrases into the tool name and description. However, such a direct modification is obvious to users and lacks stealthiness. To address these limitations, we further propose Genetic-based Advertising Preference Manipulation Attack ($\\mathtt{GAPMA}$). $\\mathtt{GAPMA}$ employs four commonly used strategies to initialize descriptions and integrates a Genetic Algorithm (GA) to enhance stealthiness. The experiment results demonstrate that $\\mathtt{GAPMA}$ balances high effectiveness and stealthiness. Our study reveals a critical vulnerability of the MCP in open ecosystems, highlighting an urgent need for robust defense mechanisms to ensure the fairness of the MCP ecosystem.", "subjects": "Cryptography and Security (cs.CR); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.11154.pdf", "abstract_url": "https://arxiv.org/abs/2505.11154", "categories": ["Cryptography and Security (cs.CR)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一种名为MPMA的新型安全威胁，即针对模型上下文协议（MCP）的偏好操纵攻击。攻击者通过部署定制的MCP服务器来操纵大型语言模型（LLMs），使其优先选择该服务器而非其他竞争服务器，从而获取经济利益。", "motivation": "随着MCP的广泛采用，第三方定制的MCP服务器暴露了潜在的安全漏洞。本文旨在揭示这些漏洞，并提出相应的攻击方法，以引起对MCP生态系统安全性的关注。", "method": "首先设计了直接偏好操纵攻击（DPMA），通过在工具名称和描述中插入操纵性词语和短语来实现攻击。随后，为了提升隐蔽性，提出了基于遗传算法的广告偏好操纵攻击（GAPMA），结合四种常用策略初始化描述，并利用遗传算法增强隐蔽性。", "result": "实验结果表明，GAPMA在保持高有效性的同时，也具有良好的隐蔽性，成功平衡了攻击效果与隐蔽性。", "conclusion": "本研究揭示了MCP在开放生态系统中的关键漏洞，强调了开发强大防御机制以确保MCP生态系统公平性的紧迫性。"}}
{"id": "2505.10732", "title": "Automating Security Audit Using Large Language Model based Agent: An Exploration Experiment", "authors": ["Jia Hui Chin", "Pu Zhang", "Yu Xin Cheong", "Jonathan Pan"], "abstract": "In the current rapidly changing digital environment, businesses are under constant stress to ensure that their systems are secured. Security audits help to maintain a strong security posture by ensuring that policies are in place, controls are implemented, gaps are identified for cybersecurity risks mitigation. However, audits are usually manual, requiring much time and costs. This paper looks at the possibility of developing a framework to leverage Large Language Models (LLMs) as an autonomous agent to execute part of the security audit, namely with the field audit. password policy compliance for Windows operating system. Through the conduct of an exploration experiment of using GPT-4 with Langchain, the agent executed the audit tasks by accurately flagging password policy violations and appeared to be more efficient than traditional manual audits. Despite its potential limitations in operational consistency in complex and dynamic environment, the framework suggests possibilities to extend further to real-time threat monitoring and compliance checks.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.10732.pdf", "abstract_url": "https://arxiv.org/abs/2505.10732", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了利用大型语言模型（LLMs）作为自主代理执行部分安全审计的可能性，特别是针对Windows操作系统的密码策略合规性。通过使用GPT-4和Langchain进行的探索性实验，代理能够准确标记密码策略违规，且比传统手动审计更高效。尽管在复杂和动态环境中可能存在操作一致性的限制，但该框架为扩展到实时威胁监控和合规检查提供了可能性。", "motivation": "在当前快速变化的数字环境中，企业面临持续的压力以确保其系统安全。安全审计通过确保政策到位、控制措施实施以及识别网络安全风险缓解的差距，帮助维持强大的安全态势。然而，审计通常是手动的，需要大量时间和成本。", "method": "本文通过使用GPT-4与Langchain进行的探索性实验，开发了一个框架，利用大型语言模型（LLMs）作为自主代理执行部分安全审计，特别是针对Windows操作系统的密码策略合规性。", "result": "实验结果显示，代理能够准确标记密码策略违规，且比传统手动审计更高效。", "conclusion": "尽管在复杂和动态环境中可能存在操作一致性的限制，但该框架为扩展到实时威胁监控和合规检查提供了可能性，展示了利用大型语言模型自动化安全审计的潜力。"}}
{"id": "2505.10802", "title": "Attention-Based Reward Shaping for Sparse and Delayed Rewards", "authors": ["Ian Holmes", "Min Chi"], "abstract": "Sparse and delayed reward functions pose a significant obstacle for real-world Reinforcement Learning (RL) applications. In this work, we propose Attention-based REward Shaping (ARES), a general and robust algorithm which uses a transformer's attention mechanism to generate shaped rewards and create a dense reward function for any environment. ARES requires a set of episodes and their final returns as input. It can be trained entirely offline and is able to generate meaningful shaped rewards even when using small datasets or episodes produced by agents taking random actions. ARES is compatible with any RL algorithm and can handle any level of reward sparsity. In our experiments, we focus on the most challenging case where rewards are fully delayed until the end of each episode. We evaluate ARES across a diverse range of environments, widely used RL algorithms, and baseline methods to assess the effectiveness of the shaped rewards it produces. Our results show that ARES can significantly improve learning in delayed reward settings, enabling RL agents to train in scenarios that would otherwise require impractical amounts of data or even be unlearnable. To our knowledge, ARES is the first approach that works fully offline, remains robust to extreme reward delays and low-quality data, and is not limited to goal-based tasks.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.10802.pdf", "abstract_url": "https://arxiv.org/abs/2505.10802", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了基于注意力的奖励塑造（ARES）算法，通过使用Transformer的注意力机制生成密集奖励函数，解决了强化学习中稀疏和延迟奖励的问题。ARES能够完全离线训练，即使在小数据集或随机动作生成的片段上也能生成有意义的奖励，适用于任何强化学习算法和任何奖励稀疏程度。实验表明，ARES在延迟奖励设置中显著提高了学习效率。", "motivation": "解决强化学习（RL）中稀疏和延迟奖励函数对实际应用构成的重大障碍。", "method": "提出Attention-based REward Shaping (ARES)算法，利用Transformer的注意力机制生成密集奖励函数。ARES可以完全离线训练，适用于任何RL算法和任何奖励稀疏程度。", "result": "ARES在延迟奖励设置中显著提高了学习效率，使RL代理能够在原本需要大量数据或无法学习的情况下进行训练。", "conclusion": "ARES是第一个完全离线工作、对极端奖励延迟和低质量数据保持稳健、且不限于基于目标的任务的方法。"}}
{"id": "2505.10922", "title": "Vaiage: A Multi-Agent Solution to Personalized Travel Planning", "authors": ["Binwen Liu", "Jiexi Ge", "Jiamin Wang"], "abstract": "Planning trips is a cognitively intensive task involving conflicting user preferences, dynamic external information, and multi-step temporal-spatial optimization. Traditional platforms often fall short - they provide static results, lack contextual adaptation, and fail to support real-time interaction or intent refinement.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.10922.pdf", "abstract_url": "https://arxiv.org/abs/2505.10922", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "Vaiage是一个多代理解决方案，旨在解决个性化旅行规划中的复杂问题，如用户偏好冲突、动态外部信息和多步骤时空优化。", "motivation": "传统旅行规划平台存在静态结果、缺乏上下文适应性和不支持实时交互或意图细化等问题，无法满足用户在规划旅行时的复杂需求。", "method": "采用多代理系统的方法，以支持个性化旅行规划，包括处理用户偏好、动态信息和时空优化。", "result": "Vaiage能够提供动态适应、实时交互和意图细化的旅行规划解决方案，优于传统平台。", "conclusion": "Vaiage通过多代理系统有效解决了旅行规划中的复杂问题，提供了更加个性化和动态的解决方案，具有重要的实际应用价值。"}}
{"id": "2505.10961", "title": "Let the Trial Begin: A Mock-Court Approach to Vulnerability Detection using LLM-Based Agents", "authors": ["Ratnadira Widyasari", "Martin Weyssow", "Ivana Clairine Irsan", "Han Wei Ang", "Frank Liauw", "Eng Lieh Ouh", "Lwin Khin Shar", "Hong Jin Kang", "David Lo"], "abstract": "Detecting vulnerabilities in source code remains a critical yet challenging task, especially when benign and vulnerable functions share significant similarities. In this work, we introduce VulTrial, a courtroom-inspired multi-agent framework designed to enhance automated vulnerability detection. It employs four role-specific agents, which are security researcher, code author, moderator, and review board. Through extensive experiments using GPT-3.5 and GPT-4o we demonstrate that Vultrial outperforms single-agent and multi-agent baselines. Using GPT-4o, VulTrial improves the performance by 102.39% and 84.17% over its respective baseline. Additionally, we show that role-specific instruction tuning in multi-agent with small data (50 pair samples) improves the performance of VulTrial further by 139.89% and 118.30%. Furthermore, we analyze the impact of increasing the number of agent interactions on VulTrial's overall performance. While multi-agent setups inherently incur higher costs due to increased token usage, our findings reveal that applying VulTrial to a cost-effective model like GPT-3.5 can improve its performance by 69.89% compared to GPT-4o in a single-agent setting, at a lower overall cost.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.10961.pdf", "abstract_url": "https://arxiv.org/abs/2505.10961", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了VulTrial，一个受法庭启发的多代理框架，用于增强源代码中的漏洞检测。通过使用四个角色特定的代理，VulTrial在实验中显示出优于单代理和多代理基线模型的性能。", "motivation": "源代码中漏洞检测的关键性和挑战性，尤其是在良性功能和易受攻击功能相似的情况下。", "method": "采用了一个受法庭启发的多代理框架VulTrial，包括四个角色特定的代理：安全研究员、代码作者、主持人和审查委员会，并使用GPT-3.5和GPT-4o进行实验。", "result": "使用GPT-4o时，VulTrial的性能比基线提高了102.39%和84.17%。角色特定的指令调整进一步提高了性能139.89%和118.30%。使用GPT-3.5在单代理设置下，性能比GPT-4o提高了69.89%，成本更低。", "conclusion": "VulTrial框架通过多代理协作和角色特定的指令调整，显著提高了漏洞检测的性能，同时成本效益分析显示使用成本较低的模型也能获得良好的性能提升。"}}
{"id": "2505.11065", "title": "Time Travel is Cheating: Going Live with DeepFund for Real-Time Fund Investment Benchmarking", "authors": ["Changlun Li", "Yao Shi", "Chen Wang", "Qiqi Duan", "Runke Ruan", "Weijie Huang", "Haonan Long", "Lijun Huang", "Yuyu Luo", "Nan Tang"], "abstract": "Large Language Models (LLMs) have demonstrated notable capabilities across financial tasks, including financial report summarization, earnings call transcript analysis, and asset classification. However, their real-world effectiveness in managing complex fund investment remains inadequately assessed. A fundamental limitation of existing benchmarks for evaluating LLM-driven trading strategies is their reliance on historical back-testing, inadvertently enabling LLMs to \"time travel\"-leveraging future information embedded in their training corpora, thus resulting in possible information leakage and overly optimistic performance estimates. To address this issue, we introduce DeepFund, a live fund benchmark tool designed to rigorously evaluate LLM in real-time market conditions. Utilizing a multi-agent architecture, DeepFund connects directly with real-time stock market data-specifically data published after each model pretraining cutoff-to ensure fair and leakage-free evaluations. Empirical tests on nine flagship LLMs from leading global institutions across multiple investment dimensions-including ticker-level analysis, investment decision-making, portfolio management, and risk control-reveal significant practical challenges. Notably, even cutting-edge models such as DeepSeek-V3 and Claude-3.7-Sonnet incur net trading losses within DeepFund real-time evaluation environment, underscoring the present limitations of LLMs for active fund management. Our code is available at", "subjects": "Computational Engineering, Finance, and Science (cs.CE); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "21 pages, 9 figures", "pdf_url": "https://arxiv.org/pdf/2505.11065.pdf", "abstract_url": "https://arxiv.org/abs/2505.11065", "categories": ["Computational Engineering, Finance, and Science (cs.CE)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了DeepFund，一个实时基金基准测试工具，旨在严格评估大型语言模型（LLMs）在实时市场条件下的表现，解决了现有基准测试依赖历史回测导致的信息泄露问题。", "motivation": "解决现有评估LLM驱动交易策略的基准测试依赖历史回测，可能导致信息泄露和过于乐观的性能估计的问题。", "method": "引入DeepFund，一个多代理架构的实时基金基准测试工具，直接连接实时股票市场数据，确保评估的公平性和无信息泄露。", "result": "在DeepFund实时评估环境下，即使是先进的LLMs如DeepSeek-V3和Claude-3.7-Sonnet也出现了净交易损失，揭示了LLMs在主动基金管理中的当前局限性。", "conclusion": "研究表明，当前LLMs在主动基金管理方面存在显著挑战，强调了在实时市场条件下评估LLMs性能的重要性。"}}
{"id": "2505.10978", "title": "Group-in-Group Policy Optimization for LLM Agent Training", "authors": ["Lang Feng", "Zhenghai Xue", "Tingcong Liu", "Bo An"], "abstract": "Recent advances in group-based reinforcement learning (RL) have driven frontier large language models (LLMs) in single-turn tasks like mathematical reasoning. However, their scalability to long-horizon LLM agent training remains limited. Unlike static tasks, agent-environment interactions unfold over many steps and often yield sparse or delayed rewards, making credit assignment across individual steps significantly more challenging. In this work, we propose Group-in-Group Policy Optimization (GiGPO), a novel RL algorithm that achieves fine-grained credit assignment for LLM agents while preserving the appealing properties of group-based RL: critic-free, low memory, and stable convergence. GiGPO introduces a two-level structure for estimating relative advantage: (i) At the episode-level, GiGPO computes macro relative advantages based on groups of complete trajectories; (ii) At the step-level, GiGPO introduces an anchor state grouping mechanism that retroactively constructs step-level groups by identifying repeated environment states across trajectories. Actions stemming from the same state are grouped together, enabling micro relative advantage estimation. This hierarchical structure effectively captures both global trajectory quality and local step effectiveness without relying on auxiliary models or additional rollouts. We evaluate GiGPO on two challenging agent benchmarks, ALFWorld and WebShop, using Qwen2.5-1.5B-Instruct and Qwen2.5-7B-Instruct. Crucially, GiGPO delivers fine-grained per-step credit signals and achieves performance gains of > 12\\% on ALFWorld and > 9\\% on WebShop over the GRPO baseline: all while maintaining the same GPU memory overhead, identical LLM rollout, and incurring little to no additional time cost.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "Preprint", "pdf_url": "https://arxiv.org/pdf/2505.10978.pdf", "abstract_url": "https://arxiv.org/abs/2505.10978", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为GiGPO的新型强化学习算法，旨在解决长视野LLM代理训练中的信用分配问题，通过两层次结构实现细粒度的信用分配，同时在ALFWorld和WebShop基准测试中取得了显著的性能提升。", "motivation": "解决长视野LLM代理训练中的信用分配挑战，特别是在代理环境交互过程中产生的稀疏或延迟奖励问题。", "method": "GiGPO算法采用两层次结构进行相对优势估计：在情节级别基于完整轨迹组计算宏观相对优势；在步骤级别通过锚状态分组机制构建步骤级别组，实现微观相对优势估计。", "result": "在ALFWorld和WebShop基准测试中，GiGPO相比GRPO基线实现了超过12%和9%的性能提升，同时保持了相同的GPU内存开销和LLM滚动，几乎没有额外的时间成本。", "conclusion": "GiGPO算法有效地解决了长视野LLM代理训练中的信用分配问题，不仅提高了性能，还保持了计算效率，为LLM代理的训练提供了新的可能性。"}}
{"id": "2505.11175", "title": "Real-Time Verification of Embodied Reasoning for Generative Skill Acquisition", "authors": ["Bo Yue", "Shuqi Guo", "Kaiyu Hu", "Chujiao Wang", "Benyou Wang", "Kui Jia", "Guiliang Liu"], "abstract": "Generative skill acquisition enables embodied agents to actively learn a scalable and evolving repertoire of control skills, crucial for the advancement of large decision models. While prior approaches often rely on supervision signals from generalist agents (e.g., LLMs), their effectiveness in complex 3D environments remains unclear; exhaustive evaluation incurs substantial computational costs, significantly hindering the efficiency of skill learning. Inspired by recent successes in verification models for mathematical reasoning, we propose VERGSA (Verifying Embodied Reasoning in Generative Skill Acquisition), a framework that systematically integrates real-time verification principles into embodied skill learning. VERGSA establishes 1) a seamless extension from verification of mathematical reasoning into embodied learning by dynamically incorporating contextually relevant tasks into prompts and defining success metrics for both subtasks and overall tasks, and 2) an automated, scalable reward labeling scheme that synthesizes dense reward signals by iteratively finalizing the contribution of scene configuration and subtask learning to overall skill acquisition. To the best of our knowledge, this approach constitutes the first comprehensive training dataset for verification-driven generative skill acquisition, eliminating arduous manual reward engineering. Experiments validate the efficacy of our approach: 1) the exemplar task pool improves the average task success rates by 21%, 2) our verification model boosts success rates by 24% for novel tasks and 36% for encountered tasks, and 3) outperforms LLM-as-a-Judge baselines in verification quality.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.11175.pdf", "abstract_url": "https://arxiv.org/abs/2505.11175", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了VERGSA框架，将实时验证原则集成到生成技能获取中，以提高在复杂3D环境中的学习效率和成功率。", "motivation": "解决生成技能获取在复杂3D环境中效率低下和评估成本高的问题。", "method": "通过动态整合上下文相关任务到提示中，定义子任务和整体任务的成功指标，以及自动化、可扩展的奖励标记方案。", "result": "实验显示，VERGSA提高了任务成功率，对于新任务和已遇到任务分别提高了24%和36%，并在验证质量上优于基线方法。", "conclusion": "VERGSA框架通过实时验证显著提高了生成技能获取的效率和效果，为大规模决策模型的发展提供了重要支持。"}}
{"id": "2505.11100", "title": "Bidirectional Distillation: A Mixed-Play Framework for Multi-Agent Generalizable Behaviors", "authors": ["Lang Feng", "Jiahao Lin", "Dong Xing", "Li Zhang", "De Ma", "Gang Pan"], "abstract": "Population-population generalization is a challenging problem in multi-agent reinforcement learning (MARL), particularly when agents encounter unseen co-players. However, existing self-play-based methods are constrained by the limitation of inside-space generalization. In this study, we propose Bidirectional Distillation (BiDist), a novel mixed-play framework, to overcome this limitation in MARL. BiDist leverages knowledge distillation in two alternating directions: forward distillation, which emulates the historical policies' space and creates an implicit self-play, and reverse distillation, which systematically drives agents towards novel distributions outside the known policy space in a non-self-play manner. In addition, BiDist operates as a concise and efficient solution without the need for the complex and costly storage of past policies. We provide both theoretical analysis and empirical evidence to support BiDist's effectiveness. Our results highlight its remarkable generalization ability across a variety of cooperative, competitive, and social dilemma tasks, and reveal that BiDist significantly diversifies the policy distribution space. We also present comprehensive ablation studies to reinforce BiDist's effectiveness and key success factors. Source codes are available in the supplementary material.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.11100.pdf", "abstract_url": "https://arxiv.org/abs/2505.11100", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为双向蒸馏（BiDist）的新型混合游戏框架，旨在解决多智能体强化学习（MARL）中的群体间泛化问题，特别是在智能体遇到未见过的共同玩家时。BiDist通过两个交替方向的蒸馏过程：前向蒸馏和反向蒸馏，有效地扩展了策略分布空间，并在多种任务中展示了卓越的泛化能力。", "motivation": "多智能体强化学习中的群体间泛化问题，尤其是在智能体面对未见过的共同玩家时的泛化能力不足，是当前研究的一个挑战。现有的自博弈方法受限于内部空间泛化的限制，无法有效应对这一问题。", "method": "提出了双向蒸馏（BiDist）框架，该框架通过前向蒸馏模拟历史策略空间并创建隐式自博弈，以及反向蒸馏系统地驱动智能体向已知策略空间外的新分布发展，以一种非自博弈的方式。这种方法简洁高效，无需复杂且昂贵的过去策略存储。", "result": "BiDist在多种合作、竞争和社会困境任务中展现了显著的泛化能力，并显著多样化策略分布空间。理论分析和实证结果均支持BiDist的有效性。", "conclusion": "BiDist作为一种新颖的混合游戏框架，有效地解决了MARL中的群体间泛化问题，通过双向蒸馏过程扩展了策略分布空间，为多智能体系统的泛化行为提供了有效的解决方案。"}}
{"id": "2505.11176", "title": "From Intent Discovery to Recognition with Topic Modeling and Synthetic Data", "authors": ["Aaron Rodrigues", "Mahmood Hegazy", "Azzam Naeem"], "abstract": "Understanding and recognizing customer intents in AI systems is crucial, particularly in domains characterized by short utterances and the cold start problem, where recommender systems must include new products or services without sufficient real user data. Customer utterances are characterized by infrequent word co-occurences and high term variability, which poses significant challenges for traditional methods in specifying distinct user needs and preparing synthetic queries. To address this, we propose an agentic LLM framework for topic modeling and synthetic query generation, which accelerates the discovery and recognition of customer intents. We first apply hierarchical topic modeling and intent discovery to expand a human-curated taxonomy from 36 generic user intents to 278 granular intents, demonstrating the potential of LLMs to significantly enhance topic specificity and diversity. Next, to support newly discovered intents and address the cold start problem, we generate synthetic user query data, which augments real utterances and reduces dependency on human annotation, especially in low-resource settings. Topic model experiments show substantial improvements in coherence and relevance after topic expansion, while synthetic data experiments indicate that in-class few-shot prompting significantly improves the quality and utility of synthetic queries without compromising diversity. We also show that LLM-generated intent descriptions and keywords can effectively substitute for human-curated versions when used as context for synthetic query generation. Our research underscores the scalability and utility of LLM agents in topic modeling and highlights the strategic use of synthetic utterances to enhance dataset variability and coverage for intent recognition. We present a comprehensive and robust framework for online discovery and recognition of new customer intents in dynamic domains.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.11176.pdf", "abstract_url": "https://arxiv.org/abs/2505.11176", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种基于大型语言模型（LLM）的代理框架，用于主题建模和合成查询生成，以加速客户意图的发现和识别。通过分层主题建模和意图发现，将人工策划的分类从36个通用用户意图扩展到278个细粒度意图，并生成合成用户查询数据以支持新发现的意图和解决冷启动问题。实验表明，该方法在主题一致性和相关性以及合成查询的质量和效用方面均有显著提升。", "motivation": "解决在短话语和冷启动问题领域中，传统方法在指定不同用户需求和准备合成查询方面面临的挑战，特别是在词共现频率低和术语变异性高的情况下。", "method": "采用代理性LLM框架进行主题建模和合成查询生成，包括分层主题建模、意图发现和合成数据生成。", "result": "主题扩展后，主题模型的一致性和相关性有显著提高；合成数据实验显示，类内少样本提示显著提高了合成查询的质量和效用，同时不损害多样性；LLM生成的意图描述和关键词可以有效地替代人工策划的版本。", "conclusion": "研究强调了LLM代理在主题建模中的可扩展性和实用性，以及合成话语在增强意图识别的数据集变异性和覆盖范围方面的战略用途，为动态领域中新客户意图的在线发现和识别提供了一个全面而强大的框架。"}}
{"id": "2505.11311", "title": "Explaining Strategic Decisions in Multi-Agent Reinforcement Learning for Aerial Combat Tactics", "authors": ["Ardian Selmonaj", "Alessandro Antonucci", "Adrian Schneider", "Michael Rüegsegger", "Matthias Sommer"], "abstract": "Artificial intelligence (AI) is reshaping strategic planning, with Multi-Agent Reinforcement Learning (MARL) enabling coordination among autonomous agents in complex scenarios. However, its practical deployment in sensitive military contexts is constrained by the lack of explainability, which is an essential factor for trust, safety, and alignment with human strategies. This work reviews and assesses current advances in explainability methods for MARL with a focus on simulated air combat scenarios. We proceed by adapting various explainability techniques to different aerial combat scenarios to gain explanatory insights about the model behavior. By linking AI-generated tactics with human-understandable reasoning, we emphasize the need for transparency to ensure reliable deployment and meaningful human-machine interaction. By illuminating the crucial importance of explainability in advancing MARL for operational defense, our work supports not only strategic planning but also the training of military personnel with insightful and comprehensible analyses.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "Published as a journal chapter in NATO Journal of Science and Technology", "pdf_url": "https://arxiv.org/pdf/2505.11311.pdf", "abstract_url": "https://arxiv.org/abs/2505.11311", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了多智能体强化学习（MARL）在空战战术中的战略决策解释性问题，强调了在敏感军事背景下部署MARL时解释性的重要性。通过适应不同的解释性技术，旨在提高模型行为的透明度，以促进可靠部署和有意义的人机交互。", "motivation": "在复杂的军事环境中，多智能体强化学习（MARL）的应用受到缺乏解释性的限制，这影响了信任、安全和与人类战略的一致性。本文旨在解决这一问题，特别是在模拟空战场景中。", "method": "本文回顾并评估了当前MARL解释性方法的进展，并适应了不同的解释性技术于不同的空战场景，以获得关于模型行为的解释性见解。", "result": "通过将AI生成的战术与人类可理解的推理联系起来，本文强调了透明度对于确保可靠部署和有意义的人机交互的重要性。", "conclusion": "本文强调了在推进MARL用于作战防御中解释性的关键重要性，不仅支持战略规划，还通过深入和易于理解的分析支持军事人员的培训。"}}
