{"id": "2505.02847", "title": "Sentient Agent as a Judge: Evaluating Higher-Order Social Cognition in Large Language Models", "authors": ["Bang Zhang", "Ruotian Ma", "Qingxuan Jiang", "Peisong Wang", "Jiaqi Chen", "Zheng Xie", "Xingyu Chen", "Yue Wang", "Fanghua Ye", "Jian Li", "Yifan Yang", "Zhaopeng Tu", "Xiaolong Li"], "abstract": "Assessing how well a large language model (LLM) understands human, rather than merely text, remains an open challenge. To bridge the gap, we introduce Sentient Agent as a Judge (SAGE), an automated evaluation framework that measures an LLM's higher-order social cognition. SAGE instantiates a Sentient Agent that simulates human-like emotional changes and inner thoughts during interaction, providing a more realistic evaluation of the tested model in multi-turn conversations. At every turn, the agent reasons about (i) how its emotion changes, (ii) how it feels, and (iii) how it should reply, yielding a numerical emotion trajectory and interpretable inner thoughts. Experiments on 100 supportive-dialogue scenarios show that the final Sentient emotion score correlates strongly with Barrett-Lennard Relationship Inventory (BLRI) ratings and utterance-level empathy metrics, validating psychological fidelity. We also build a public Sentient Leaderboard covering 18 commercial and open-source models that uncovers substantial gaps (up to 4x) between frontier systems (GPT-4o-Latest, Gemini2.5-Pro) and earlier baselines, gaps not reflected in conventional leaderboards (e.g., Arena). SAGE thus provides a principled, scalable and interpretable tool for tracking progress toward genuinely empathetic and socially adept language agents.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.02847.pdf", "abstract_url": "https://arxiv.org/abs/2505.02847", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了Sentient Agent as a Judge (SAGE)，一个自动化评估框架，用于衡量大型语言模型(LLM)的高阶社会认知能力。SAGE通过模拟人类情感变化和内心思想，在多轮对话中提供更真实的模型评估。", "motivation": "解决如何更准确地评估大型语言模型对人类理解而不仅仅是文本理解的问题。", "method": "引入SAGE框架，通过实例化一个Sentient Agent来模拟人类情感变化和内心思想，在多轮对话中进行评估。", "result": "实验表明，SAGE的情感评分与BLRI评分和话语级共情指标有强相关性，验证了其心理保真度。同时，公开的Sentient Leaderboard揭示了前沿系统与早期基线之间的显著差距。", "conclusion": "SAGE为追踪向真正具有共情和社会能力的语言代理的进展提供了一个原则性、可扩展且可解释的工具。"}}
{"id": "2505.02850", "title": "Harnessing Structured Knowledge: A Concept Map-Based Approach for High-Quality Multiple Choice Question Generation with Effective Distractors", "authors": ["Nicy Scaria", "Silvester John Joseph Kennedy", "Diksha Seth", "Ananya Thakur", "Deepak Subramani"], "abstract": "Generating high-quality MCQs, especially those targeting diverse cognitive levels and incorporating common misconceptions into distractor design, is time-consuming and expertise-intensive, making manual creation impractical at scale. Current automated approaches typically generate questions at lower cognitive levels and fail to incorporate domain-specific misconceptions. This paper presents a hierarchical concept map-based framework that provides structured knowledge to guide LLMs in generating MCQs with distractors. We chose high-school physics as our test domain and began by developing a hierarchical concept map covering major Physics topics and their interconnections with an efficient database design. Next, through an automated pipeline, topic-relevant sections of these concept maps are retrieved to serve as a structured context for the LLM to generate questions and distractors that specifically target common misconceptions. Lastly, an automated validation is completed to ensure that the generated MCQs meet the requirements provided. We evaluate our framework against two baseline approaches: a base LLM and a RAG-based generation. We conducted expert evaluations and student assessments of the generated MCQs. Expert evaluation shows that our method significantly outperforms the baseline approaches, achieving a success rate of 75.20% in meeting all quality criteria compared to approximately 37% for both baseline methods. Student assessment data reveal that our concept map-driven approach achieved a significantly lower guess success rate of 28.05% compared to 37.10% for the baselines, indicating a more effective assessment of conceptual understanding. The results demonstrate that our concept map-based approach enables robust assessment across cognitive levels and instant identification of conceptual gaps, facilitating faster feedback loops and targeted interventions at scale.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Databases (cs.DB)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.02850.pdf", "abstract_url": "https://arxiv.org/abs/2505.02850", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)", "Databases (cs.DB)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种基于层次概念图的框架，用于指导大型语言模型生成高质量的多选题及其干扰项，特别是在高中物理领域，通过自动化流程和验证，显著提高了问题的质量和教学效果。", "motivation": "手动生成高质量的多选题（MCQs）既耗时又需要专业知识，尤其是在针对不同认知水平和融入常见误解设计干扰项时。现有的自动化方法通常在较低的认知水平上生成问题，且未能融入领域特定的误解。", "method": "采用了一个层次概念图框架，该框架提供结构化知识以指导大型语言模型（LLMs）生成包含干扰项的多选题。通过自动化流程检索与主题相关的概念图部分，作为生成问题和干扰项的上下文，并自动验证生成的MCQs是否满足要求。", "result": "专家评估显示，该方法在满足所有质量标准方面的成功率为75.20%，显著优于基线方法的约37%。学生评估数据显示，概念图驱动的方法的猜测成功率为28.05%，低于基线方法的37.10%，表明能更有效地评估概念理解。", "conclusion": "结果表明，基于概念图的方法能够在不同认知水平上进行稳健的评估，并即时识别概念差距，促进了更快的反馈循环和有针对性的干预措施。"}}
{"id": "2505.03018", "title": "Lesion-Aware Generative Artificial Intelligence for Virtual Contrast-Enhanced Mammography in Breast Cancer", "authors": ["Aurora Rofena", "Arianna Manchia", "Claudia Lucia Piccolo", "Bruno Beomonte Zobel", "Paolo Soda", "Valerio Guarrasi"], "abstract": "Contrast-Enhanced Spectral Mammography (CESM) is a dual-energy mammographic technique that improves lesion visibility through the administration of an iodinated contrast agent. It acquires both a low-energy image, comparable to standard mammography, and a high-energy image, which are then combined to produce a dual-energy subtracted image highlighting lesion contrast enhancement. While CESM offers superior diagnostic accuracy compared to standard mammography, its use entails higher radiation exposure and potential side effects associated with the contrast medium. To address these limitations, we propose Seg-CycleGAN, a generative deep learning framework for Virtual Contrast Enhancement in CESM. The model synthesizes high-fidelity dual-energy subtracted images from low-energy images, leveraging lesion segmentation maps to guide the generative process and improve lesion reconstruction. Building upon the standard CycleGAN architecture, Seg-CycleGAN introduces localized loss terms focused on lesion areas, enhancing the synthesis of diagnostically relevant regions. Experiments on the CESM@UCBM dataset demonstrate that Seg-CycleGAN outperforms the baseline in terms of PSNR and SSIM, while maintaining competitive MSE and VIF. Qualitative evaluations further confirm improved lesion fidelity in the generated images. These results suggest that segmentation-aware generative models offer a viable pathway toward contrast-free CESM alternatives.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.03018.pdf", "abstract_url": "https://arxiv.org/abs/2505.03018", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为Seg-CycleGAN的生成深度学习框架，用于在对比增强光谱乳腺摄影（CESM）中实现虚拟对比增强，旨在通过从低能量图像合成高质量的双能量减影图像来减少辐射暴露和对比剂的潜在副作用。", "motivation": "解决CESM技术中因使用对比剂和较高辐射暴露带来的限制，提供一种无对比剂的替代方案。", "method": "基于CycleGAN架构，引入病灶分割图指导生成过程，并通过局部损失项增强诊断相关区域的合成。", "result": "在CESM@UCBM数据集上的实验表明，Seg-CycleGAN在PSNR和SSIM上优于基线，同时保持竞争力的MSE和VIF，定性评估也证实了生成图像中病灶保真度的提高。", "conclusion": "研究表明，分割感知的生成模型为开发无对比剂的CESM替代方案提供了可行的途径。"}}
{"id": "2505.03275", "title": "RAG-MCP: Mitigating Prompt Bloat in LLM Tool Selection via Retrieval-Augmented Generation", "authors": ["Tiantian Gan", "Qiyao Sun"], "abstract": "Large language models (LLMs) struggle to effectively utilize a growing number of external tools, such as those defined by the Model Context Protocol (MCP)\\cite{IntroducingMCP}, due to prompt bloat and selection complexity. We introduce RAG-MCP, a Retrieval-Augmented Generation framework that overcomes this challenge by offloading tool discovery. RAG-MCP uses semantic retrieval to identify the most relevant MCP(s) for a given query from an external index before engaging the LLM. Only the selected tool descriptions are passed to the model, drastically reducing prompt size and simplifying decision-making. Experiments, including an MCP stress test, demonstrate RAG-MCP significantly cuts prompt tokens (e.g., by over 50%) and more than triples tool selection accuracy (43.13% vs 13.62% baseline) on benchmark tasks. RAG-MCP enables scalable and accurate tool integration for LLMs.", "subjects": "Artificial Intelligence (cs.AI); Software Engineering (cs.SE)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.03275.pdf", "abstract_url": "https://arxiv.org/abs/2505.03275", "categories": ["Artificial Intelligence (cs.AI)", "Software Engineering (cs.SE)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "RAG-MCP通过检索增强生成框架解决大型语言模型(LLMs)在外部工具使用中的提示膨胀和选择复杂性问题，显著减少提示令牌并提高工具选择准确性。", "motivation": "解决大型语言模型(LLMs)在利用日益增多的外部工具时面临的提示膨胀和选择复杂性问题。", "method": "采用检索增强生成(RAG)框架，通过语义检索从外部索引中识别最相关的工具描述，仅将这些描述传递给模型。", "result": "实验显示，RAG-MCP显著减少了提示令牌（例如超过50%），并在基准测试中将工具选择准确性提高了三倍以上（43.13% vs 13.62%基线）。", "conclusion": "RAG-MCP为LLMs提供了可扩展且准确的外部工具集成方法，有效解决了提示膨胀和选择复杂性问题。"}}
{"id": "2505.03295", "title": "Capability-Driven Skill Generation with LLMs: A RAG-Based Approach for Reusing Existing Libraries and Interfaces", "authors": ["Luis Miguel Vieira da Silva", "Aljosha Köcher", "Nicolas König", "Felix Gehlhoff", "Alexander Fay"], "abstract": "Modern automation systems increasingly rely on modular architectures, with capabilities and skills as one solution approach. Capabilities define the functions of resources in a machine-readable form and skills provide the concrete implementations that realize those capabilities. However, the development of a skill implementation conforming to a corresponding capability remains a time-consuming and challenging task. In this paper, we present a method that treats capabilities as contracts for skill implementations and leverages large language models to generate executable code based on natural language user input. A key feature of our approach is the integration of existing software libraries and interface technologies, enabling the generation of skill implementations across different target languages. We introduce a framework that allows users to incorporate their own libraries and resource interfaces into the code generation process through a retrieval-augmented generation architecture. The proposed method is evaluated using an autonomous mobile robot controlled via Python and ROS 2, demonstrating the feasibility and flexibility of the approach.", "subjects": "Artificial Intelligence (cs.AI); Robotics (cs.RO); Software Engineering (cs.SE)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.03295.pdf", "abstract_url": "https://arxiv.org/abs/2505.03295", "categories": ["Artificial Intelligence (cs.AI)", "Robotics (cs.RO)", "Software Engineering (cs.SE)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种基于大型语言模型（LLMs）和检索增强生成（RAG）架构的方法，用于根据自然语言用户输入生成符合能力定义的技能实现代码，旨在提高自动化系统中技能开发的效率和灵活性。", "motivation": "自动化系统中，技能开发是一个耗时且具有挑战性的任务，尤其是当需要符合特定能力定义时。本文旨在解决这一问题，通过利用现有软件库和接口技术，简化技能实现的过程。", "method": "采用大型语言模型（LLMs）和检索增强生成（RAG）架构，结合自然语言处理技术，生成符合能力定义的技能实现代码。用户可以将自己的库和资源接口集成到代码生成过程中。", "result": "通过一个由Python和ROS 2控制的自主移动机器人进行评估，证明了该方法的可行性和灵活性。", "conclusion": "本文提出的方法不仅提高了技能开发的效率，还通过支持不同目标语言的代码生成，增强了系统的灵活性和可扩展性。"}}
{"id": "2505.03434", "title": "Procedural Memory Is Not All You Need: Bridging Cognitive Gaps in LLM-Based Agents", "authors": ["Schaun Wheeler", "Olivier Jeunen"], "abstract": "Large Language Models (LLMs) represent a landmark achievement in Artificial Intelligence (AI), demonstrating unprecedented proficiency in procedural tasks such as text generation, code completion, and conversational coherence. These capabilities stem from their architecture, which mirrors human procedural memory -- the brain's ability to automate repetitive, pattern-driven tasks through practice. However, as LLMs are increasingly deployed in real-world applications, it becomes impossible to ignore their limitations operating in complex, unpredictable environments. This paper argues that LLMs, while transformative, are fundamentally constrained by their reliance on procedural memory. To create agents capable of navigating ``wicked'' learning environments -- where rules shift, feedback is ambiguous, and novelty is the norm -- we must augment LLMs with semantic memory and associative learning systems. By adopting a modular architecture that decouples these cognitive functions, we can bridge the gap between narrow procedural expertise and the adaptive intelligence required for real-world problem-solving.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "Accepted to the workshop on Hybrid AI for Human-Centric Personalization (HyPer), co-located with ACM UMAP '25", "pdf_url": "https://arxiv.org/pdf/2505.03434.pdf", "abstract_url": "https://arxiv.org/abs/2505.03434", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "大型语言模型（LLMs）在人工智能（AI）领域取得了里程碑式的成就，展示了在文本生成、代码完成和会话连贯性等程序性任务上的前所未有的熟练度。然而，随着LLMs在现实世界应用中的部署增加，它们在复杂、不可预测环境中操作的局限性变得不可忽视。本文认为，LLMs虽然具有变革性，但其对程序性记忆的依赖从根本上限制了它们。为了创建能够在“恶劣”学习环境中导航的代理——其中规则变化、反馈模糊、新颖性成为常态——我们必须用语义记忆和联想学习系统来增强LLMs。通过采用将这些认知功能解耦的模块化架构，我们可以弥合狭窄的程序性专业知识和现实世界问题解决所需的适应性智能之间的差距。", "motivation": "解决大型语言模型（LLMs）在复杂、不可预测环境中的局限性，特别是它们对程序性记忆的依赖，这限制了它们在现实世界应用中的适应性和问题解决能力。", "method": "提出通过增强LLMs的语义记忆和联想学习系统，采用模块化架构来解耦这些认知功能，以弥补程序性专业知识和适应性智能之间的差距。", "result": "通过这种增强，可以创建更适应复杂、不可预测环境的智能代理，提高其在现实世界问题解决中的能力。", "conclusion": "虽然LLMs在程序性任务上表现出色，但为了在更广泛、更复杂的环境中有效运作，必须通过引入语义记忆和联想学习系统来增强它们的能力，这需要通过模块化架构来实现。"}}
{"id": "2505.03439", "title": "The Steganographic Potentials of Language Models", "authors": ["Artem Karpov", "Tinuade Adeleke", "Seong Hah Cho", "Natalia Perez-Campanero"], "abstract": "The potential for large language models (LLMs) to hide messages within plain text (steganography) poses a challenge to detection and thwarting of unaligned AI agents, and undermines faithfulness of LLMs reasoning. We explore the steganographic capabilities of LLMs fine-tuned via reinforcement learning (RL) to: (1) develop covert encoding schemes, (2) engage in steganography when prompted, and (3) utilize steganography in realistic scenarios where hidden reasoning is likely, but not prompted. In these scenarios, we detect the intention of LLMs to hide their reasoning as well as their steganography performance. Our findings in the fine-tuning experiments as well as in behavioral non fine-tuning evaluations reveal that while current models exhibit rudimentary steganographic abilities in terms of security and capacity, explicit algorithmic guidance markedly enhances their capacity for information concealment.", "subjects": "Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Machine Learning (cs.LG)", "comments": "Published at Building Trust Workshop at ICLR 2025", "pdf_url": "https://arxiv.org/pdf/2505.03439.pdf", "abstract_url": "https://arxiv.org/abs/2505.03439", "categories": ["Artificial Intelligence (cs.AI)", "Cryptography and Security (cs.CR)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了大型语言模型（LLMs）通过强化学习（RL）微调后的隐写能力，包括开发隐蔽编码方案、在提示下进行隐写以及在未提示但可能隐藏推理的现实场景中使用隐写。研究发现，当前模型在安全性和容量方面表现出初级的隐写能力，而明确的算法指导显著增强了其信息隐藏能力。", "motivation": "解决大型语言模型（LLMs）在纯文本中隐藏消息（隐写术）的潜力对检测和对齐AI代理的挑战，以及削弱LLMs推理的忠实性问题。", "method": "通过强化学习（RL）微调大型语言模型（LLMs），探索其隐写能力，包括开发隐蔽编码方案、在提示下进行隐写以及在现实场景中未提示但可能隐藏推理的情况下使用隐写。", "result": "研究发现，当前模型在安全性和容量方面表现出初级的隐写能力，而明确的算法指导显著增强了其信息隐藏能力。", "conclusion": "大型语言模型（LLMs）通过强化学习（RL）微调后，能够展现出一定的隐写能力，特别是在有明确算法指导的情况下，其信息隐藏能力得到显著提升。这一发现对于理解和防范LLMs可能带来的安全风险具有重要意义。"}}
{"id": "2505.03581", "title": "DyGEnc: Encoding a Sequence of Textual Scene Graphs to Reason and Answer Questions in Dynamic Scenes", "authors": ["Sergey Linok", "Vadim Semenov", "Anastasia Trunova", "Oleg Bulichev", "Dmitry Yudin"], "abstract": "The analysis of events in dynamic environments poses a fundamental challenge in the development of intelligent agents and robots capable of interacting with humans. Current approaches predominantly utilize visual models. However, these methods often capture information implicitly from images, lacking interpretable spatial-temporal object representations. To address this issue we introduce DyGEnc - a novel method for Encoding a Dynamic Graph. This method integrates compressed spatial-temporal structural observation representation with the cognitive capabilities of large language models. The purpose of this integration is to enable advanced question answering based on a sequence of textual scene graphs. Extended evaluations on the STAR and AGQA datasets indicate that DyGEnc outperforms existing visual methods by a large margin of 15-25% in addressing queries regarding the history of human-to-object interactions. Furthermore, the proposed method can be seamlessly extended to process raw input images utilizing foundational models for extracting explicit textual scene graphs, as substantiated by the results of a robotic experiment conducted with a wheeled manipulator platform. We hope that these findings will contribute to the implementation of robust and compressed graph-based robotic memory for long-horizon reasoning. Code is available at", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "8 pages, 5 figures, 6 tables", "pdf_url": "https://arxiv.org/pdf/2505.03581.pdf", "abstract_url": "https://arxiv.org/abs/2505.03581", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "DyGEnc是一种新颖的动态图编码方法，旨在通过结合压缩的时空结构观察表示与大型语言模型的认知能力，解决动态环境中事件分析的挑战。该方法在STAR和AGQA数据集上的评估显示，其在回答关于人-物交互历史的问题上优于现有视觉方法15-25%。", "motivation": "当前动态环境事件分析主要依赖视觉模型，这些方法往往从图像中隐式捕获信息，缺乏可解释的时空对象表示。DyGEnc旨在解决这一问题，通过提供一种能够进行高级问答的动态图编码方法。", "method": "DyGEnc通过结合压缩的时空结构观察表示与大型语言模型的认知能力，编码动态图，以支持基于一系列文本场景图的高级问答。此外，该方法还能利用基础模型处理原始输入图像，提取显式文本场景图。", "result": "在STAR和AGQA数据集上的扩展评估表明，DyGEnc在回答关于人-物交互历史的问题上，比现有视觉方法表现优异，提高了15-25%。机器人实验的结果也验证了该方法处理原始输入图像的能力。", "conclusion": "DyGEnc的研究成果有望为实现基于图的机器人记忆提供支持，促进长期推理能力的开发。该方法不仅在性能上优于现有技术，还能灵活应用于原始图像处理，为智能代理和机器人的交互能力开辟了新途径。"}}
{"id": "2505.03059", "title": "Improving Model Alignment Through Collective Intelligence of Open-Source LLMS", "authors": ["Junlin Wang", "Roy Xie", "Shang Zhu", "Jue Wang", "Ben Athiwaratkun", "Bhuwan Dhingra", "Shuaiwen Leon Song", "Ce Zhang", "James Zou"], "abstract": "Building helpful and harmless large language models (LLMs) requires effective model alignment approach based on human instructions and feedback, which necessitates high-quality human-labeled data. Constructing such datasets is often expensive and hard to scale, and may face potential limitations on diversity and generalization. To address these challenges, we introduce Mixture of Agents Alignment (MoAA), that leverages the collective strengths of various language models to provide high-quality data for model alignment. By employing MoAA, we enhance both supervised fine-tuning and preference optimization, leading to improved performance compared to using a single model alone to generate alignment data (e.g. using GPT-4o alone). Evaluation results show that our approach can improve win rate of LLaMA-3.1-8B-Instruct from 19.5 to 48.3 on Arena-Hard and from 22.33 to 57.23 on AlpacaEval2, highlighting a promising direction for model alignment through this new scalable and diverse synthetic data recipe. Furthermore, we demonstrate that MoAA enables a self-improvement pipeline, where models finetuned on MoA-generated data surpass their own initial capabilities, providing evidence that our approach can push the frontier of open-source LLMs without reliance on stronger external supervision. Data and code will be released.", "subjects": "Computation and Language (cs.CL)", "comments": "ICML 2025", "pdf_url": "https://arxiv.org/pdf/2505.03059.pdf", "abstract_url": "https://arxiv.org/abs/2505.03059", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为Mixture of Agents Alignment (MoAA)的方法，通过利用各种语言模型的集体优势来提供高质量的模型对齐数据，从而解决了构建高质量人类标注数据的高成本和难以扩展的问题。", "motivation": "构建有用且无害的大型语言模型(LLMs)需要基于人类指令和反馈的有效模型对齐方法，这需要高质量的人类标注数据。构建这样的数据集通常成本高昂且难以扩展，并可能在多样性和泛化性方面面临潜在限制。", "method": "引入了Mixture of Agents Alignment (MoAA)方法，利用各种语言模型的集体优势来提供高质量的模型对齐数据，从而增强监督微调和偏好优化。", "result": "评估结果显示，我们的方法可以将LLaMA-3.1-8B-Instruct在Arena-Hard上的胜率从19.5提高到48.3，在AlpacaEval2上从22.33提高到57.23。", "conclusion": "MoAA方法不仅提高了模型对齐的性能，还实现了一个自我改进的管道，使得在MoA生成的数据上微调的模型超越了它们最初的性能，为开源LLMs的发展提供了新的方向。"}}
{"id": "2505.03406", "title": "Lightweight Clinical Decision Support System using QLoRA-Fine-Tuned LLMs and Retrieval-Augmented Generation", "authors": ["Mohammad Shoaib Ansari", "Mohd Sohail Ali Khan", "Shubham Revankar", "Aditya Varma", "Anil S. Mokhade"], "abstract": "This research paper investigates the application of Large Language Models (LLMs) in healthcare, specifically focusing on enhancing medical decision support through Retrieval-Augmented Generation (RAG) integrated with hospital-specific data and fine-tuning using Quantized Low-Rank Adaptation (QLoRA). The system utilizes Llama 3.2-3B-Instruct as its foundation model. By embedding and retrieving context-relevant healthcare information, the system significantly improves response accuracy. QLoRA facilitates notable parameter efficiency and memory optimization, preserving the integrity of medical information through specialized quantization techniques. Our research also shows that our model performs relatively well on various medical benchmarks, indicating that it can be used to make basic medical suggestions. This paper details the system's technical components, including its architecture, quantization methods, and key healthcare applications such as enhanced disease prediction from patient symptoms and medical history, treatment suggestions, and efficient summarization of complex medical reports. We touch on the ethical considerations-patient privacy, data security, and the need for rigorous clinical validation-as well as the practical challenges of integrating such systems into real-world healthcare workflows. Furthermore, the lightweight quantized weights ensure scalability and ease of deployment even in low-resource hospital environments. Finally, the paper concludes with an analysis of the broader impact of LLMs on healthcare and outlines future directions for LLMs in medical settings.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "12 pages", "pdf_url": "https://arxiv.org/pdf/2505.03406.pdf", "abstract_url": "https://arxiv.org/abs/2505.03406", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本研究探讨了在医疗保健领域应用大型语言模型（LLMs），特别是通过检索增强生成（RAG）与医院特定数据结合，以及使用量化低秩适应（QLoRA）进行微调，以增强医疗决策支持。系统以Llama 3.2-3B-Instruct为基础模型，通过嵌入和检索上下文相关的医疗信息，显著提高了响应准确性。QLoRA在参数效率和内存优化方面表现出色，同时通过专门的量化技术保护了医疗信息的完整性。研究还表明，该模型在各种医疗基准测试中表现良好，可用于提供基本的医疗建议。", "motivation": "解决医疗决策支持系统中信息准确性和效率的问题，特别是在资源有限的医院环境中。", "method": "结合检索增强生成（RAG）和量化低秩适应（QLoRA）技术，对Llama 3.2-3B-Instruct模型进行微调，以优化参数效率和内存使用。", "result": "系统在医疗基准测试中表现良好，能够提供准确的疾病预测、治疗建议和医疗报告摘要。", "conclusion": "通过QLoRA和RAG技术的结合，可以开发出轻量级且高效的医疗决策支持系统，适用于各种医疗环境，但需考虑患者隐私和数据安全等伦理问题。"}}
{"id": "2505.03452", "title": "An Analysis of Hyper-Parameter Optimization Methods for Retrieval Augmented Generation", "authors": ["Matan Orbach", "Ohad Eytan", "Benjamin Sznajder", "Ariel Gera", "Odellia Boni", "Yoav Kantor", "Gal Bloch", "Omri Levy", "Hadas Abraham", "Nitzan Barzilay", "Eyal Shnarch", "Michael E. Factor", "Shila Ofek-Koifman", "Paula Ta-Shma", "Assaf Toledo"], "abstract": "Finding the optimal Retrieval-Augmented Generation (RAG) configuration for a given use case can be complex and expensive. Motivated by this challenge, frameworks for RAG hyper-parameter optimization (HPO) have recently emerged, yet their effectiveness has not been rigorously benchmarked. To address this gap, we present a comprehensive study involving 5 HPO algorithms over 5 datasets from diverse domains, including a new one collected for this work on real-world product documentation. Our study explores the largest HPO search space considered to date, with two optimized evaluation metrics. Analysis of the results shows that RAG HPO can be done efficiently, either greedily or with iterative random search, and that it significantly boosts RAG performance for all datasets. For greedy HPO approaches, we show that optimizing models first is preferable to the prevalent practice of optimizing sequentially according to the RAG pipeline order.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.03452.pdf", "abstract_url": "https://arxiv.org/abs/2505.03452", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文对检索增强生成（RAG）的超参数优化（HPO）方法进行了全面分析，通过5种HPO算法在5个不同领域的数据集上的实验，证明了RAG HPO的有效性，并提出了一种更优的贪婪优化策略。", "motivation": "针对检索增强生成（RAG）配置优化复杂且成本高的问题，本文旨在评估现有HPO框架的有效性，并提出更高效的优化方法。", "method": "研究采用了5种HPO算法，在5个不同领域的数据集（包括一个新收集的真实世界产品文档数据集）上进行了实验，探索了迄今为止最大的HPO搜索空间，并优化了两个评估指标。", "result": "结果表明，RAG HPO可以通过贪婪方法或迭代随机搜索高效完成，并且显著提高了所有数据集的RAG性能。对于贪婪HPO方法，优先优化模型比按RAG管道顺序优化更为有效。", "conclusion": "本研究不仅证明了RAG HPO的可行性和有效性，还为实践中的优化顺序提供了新的见解，即优先优化模型比按传统顺序优化更为高效。"}}
{"id": "2505.03553", "title": "A Hashgraph-Inspired Consensus Mechanism for Reliable Multi-Model Reasoning", "authors": ["Kolawole E. Ogunsina", "Morayo A. Ogunsina"], "abstract": "Inconsistent outputs and hallucinations from large language models (LLMs) are major obstacles to reliable AI systems. When different proprietary reasoning models (RMs), such as those by OpenAI, Google, Anthropic, DeepSeek, and xAI, are given the same complex request, they often produce divergent results due to variations in training and inference. This paper proposes a novel consensus mechanism, inspired by distributed ledger technology, to validate and converge these outputs, treating each RM as a black-box peer. Building on the Hashgraph consensus algorithm, our approach employs gossip-about-gossip communication and virtual voting to achieve agreement among an ensemble of RMs. We present an architectural design for a prototype system in which RMs iteratively exchange and update their answers, using information from each round to improve accuracy and confidence in subsequent rounds. This approach goes beyond simple majority voting by incorporating the knowledge and cross-verification content of every model. We justify the feasibility of this Hashgraph-inspired consensus for AI ensembles and outline its advantages over traditional ensembling techniques in reducing nonfactual outputs. Preliminary considerations for implementation, evaluation criteria for convergence and accuracy, and potential challenges are discussed. The proposed mechanism demonstrates a promising direction for multi-agent AI systems to self-validate and deliver high-fidelity responses in complex tasks.", "subjects": "Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)", "comments": "15 pages", "pdf_url": "https://arxiv.org/pdf/2505.03553.pdf", "abstract_url": "https://arxiv.org/abs/2505.03553", "categories": ["Artificial Intelligence (cs.AI)", "Distributed, Parallel, and Cluster Computing (cs.DC)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种受Hashgraph启发的共识机制，旨在解决大型语言模型（LLMs）输出不一致和幻觉问题，通过将每个推理模型（RM）视为黑盒对等体，利用gossip-about-gossip通信和虚拟投票实现模型间的共识，从而提高复杂任务中响应的准确性和可靠性。", "motivation": "大型语言模型（LLMs）在相同复杂请求下常因训练和推理的差异产生不一致的输出和幻觉，这是构建可靠AI系统的主要障碍。", "method": "受Hashgraph共识算法启发，提出一种新型共识机制，通过gossip-about-gossip通信和虚拟投票在推理模型（RMs）集合中达成一致，超越简单多数投票，整合每个模型的知识和交叉验证内容。", "result": "初步研究表明，这种Hashgraph启发的共识机制在减少非事实输出方面优于传统集成技术，为多智能体AI系统自我验证和在复杂任务中提供高保真响应指明了有希望的方向。", "conclusion": "提出的共识机制为多模型AI系统提供了一种自我验证和提升响应可靠性的新方法，虽然在实现和评估方面存在挑战，但展示了在复杂任务中提高AI系统性能的潜力。"}}
{"id": "2505.03570", "title": "OSUniverse: Benchmark for Multimodal GUI-navigation AI Agents", "authors": ["Mariya Davydova", "Daniel Jeffries", "Patrick Barker", "Arturo Márquez Flores", "Sinéad Ryan"], "abstract": "In this paper, we introduce OSUniverse: a benchmark of complex, multimodal desktop-oriented tasks for advanced GUI-navigation AI agents that focuses on ease of use, extensibility, comprehensive coverage of test cases, and automated validation. We divide the tasks in increasing levels of complexity, from basic precision clicking to multistep, multiapplication tests requiring dexterity, precision, and clear thinking from the agent. In version one of the benchmark, presented here, we have calibrated the complexity of the benchmark test cases to ensure that the SOTA (State of the Art) agents (at the time of publication) do not achieve results higher than 50%, while the average white collar worker can perform all these tasks with perfect accuracy. The benchmark can be scored manually, but we also introduce an automated validation mechanism that has an average error rate less than 2%. Therefore, this benchmark presents solid ground for fully automated measuring of progress, capabilities and the effectiveness of GUI-navigation AI agents over the short and medium-term horizon. The source code of the benchmark is available at", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.03570.pdf", "abstract_url": "https://arxiv.org/abs/2505.03570", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了OSUniverse：一个为高级GUI导航AI代理设计的复杂、多模态桌面任务基准测试，注重易用性、可扩展性、测试案例的全面覆盖和自动验证。", "motivation": "解决当前缺乏一个全面、易于使用且能自动验证的基准测试来衡量GUI导航AI代理的能力和进步的问题。", "method": "通过将任务按复杂度分级，从基本精确点击到需要代理具备灵活性、精确性和清晰思维的多步骤、多应用程序测试，并引入自动验证机制。", "result": "基准测试的第一版确保当时最先进的AI代理的准确率不超过50%，而普通白领工人可以完美完成所有任务，自动验证的平均错误率低于2%。", "conclusion": "OSUniverse为短期和中期内全自动测量GUI导航AI代理的进展、能力和有效性提供了坚实的基础。"}}
{"id": "2505.03674", "title": "Gap the (Theory of) Mind: Sharing Beliefs About Teammates' Goals Boosts Collaboration Perception, Not Performance", "authors": ["Yotam Amitai", "Reuth Mirsky", "Ofra Amir"], "abstract": "In human-agent teams, openly sharing goals is often assumed to enhance planning, collaboration, and effectiveness. However, direct communication of these goals is not always feasible, requiring teammates to infer their partner's intentions through actions. Building on this, we investigate whether an AI agent's ability to share its inferred understanding of a human teammate's goals can improve task performance and perceived collaboration. Through an experiment comparing three conditions-no recognition (NR), viable goals (VG), and viable goals on-demand (VGod) - we find that while goal-sharing information did not yield significant improvements in task performance or overall satisfaction scores, thematic analysis suggests that it supported strategic adaptations and subjective perceptions of collaboration. Cognitive load assessments revealed no additional burden across conditions, highlighting the challenge of balancing informativeness and simplicity in human-agent interactions. These findings highlight the nuanced trade-off of goal-sharing: while it fosters trust and enhances perceived collaboration, it can occasionally hinder objective performance gains.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.03674.pdf", "abstract_url": "https://arxiv.org/abs/2505.03674", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "研究探讨了AI代理分享其对人类队友目标的理解是否能提升任务表现和合作感知。实验发现，目标分享虽未显著提升任务表现或满意度，但支持了战略适应和主观合作感知。", "motivation": "解决在人类与AI代理团队中，直接沟通目标不可行时，通过分享AI对人类队友目标的理解是否能改善合作和任务表现的问题。", "method": "通过比较无识别（NR）、可行目标（VG）和按需可行目标（VGod）三种条件的实验。", "result": "目标分享信息未显著改善任务表现或总体满意度，但支持战略适应和主观合作感知，认知负荷评估显示各条件间无额外负担。", "conclusion": "目标分享在促进信任和增强合作感知方面有细微权衡，偶尔可能阻碍客观性能提升。"}}
{"id": "2505.02849", "title": "Enhancing tutoring systems by leveraging tailored promptings and domain knowledge with Large Language Models", "authors": ["Mohsen Balavar", "Wenli Yang", "David Herbert", "Soonja Yeom"], "abstract": "Recent advancements in artificial intelligence (AI) and machine learning have reignited interest in their impact on Computer-based Learning (CBL). AI-driven tools like ChatGPT and Intelligent Tutoring Systems (ITS) have enhanced learning experiences through personalisation and flexibility. ITSs can adapt to individual learning needs and provide customised feedback based on a student's performance, cognitive state, and learning path. Despite these advances, challenges remain in accommodating diverse learning styles and delivering real-time, context-aware feedback. Our research aims to address these gaps by integrating skill-aligned feedback via Retrieval Augmented Generation (RAG) into prompt engineering for Large Language Models (LLMs) and developing an application to enhance learning through personalised tutoring in a computer science programming context. The pilot study evaluated a proposed system using three quantitative metrics: readability score, response time, and feedback depth, across three programming tasks of varying complexity. The system successfully sorted simulated students into three skill-level categories and provided context-aware feedback. This targeted approach demonstrated better effectiveness and adaptability compared to general methods.", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.02849.pdf", "abstract_url": "https://arxiv.org/abs/2505.02849", "categories": ["Computers and Society (cs.CY)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文探讨了如何通过结合定制提示和领域知识来增强大型语言模型（LLMs）在智能辅导系统（ITS）中的应用，特别是在计算机科学编程教育中。研究通过检索增强生成（RAG）技术整合技能对齐反馈，开发了一个应用程序，以提供个性化辅导。初步研究通过三个定量指标评估了系统的有效性，结果显示该系统在分类学生技能水平和提供上下文感知反馈方面优于一般方法。", "motivation": "尽管人工智能（AI）和机器学习在计算机辅助学习（CBL）中的应用取得了进展，但在适应多样化学习风格和提供实时、上下文感知反馈方面仍存在挑战。本研究旨在通过整合技能对齐反馈和开发个性化辅导应用程序来解决这些问题。", "method": "研究采用检索增强生成（RAG）技术来整合技能对齐反馈到大型语言模型（LLMs）的提示工程中，并开发了一个应用程序以在计算机科学编程背景下提供个性化辅导。通过三个编程任务的不同复杂度，使用可读性分数、响应时间和反馈深度三个定量指标对系统进行评估。", "result": "初步研究显示，该系统成功将模拟学生分为三个技能水平类别，并提供了上下文感知反馈。这种针对性方法在效果和适应性上优于一般方法。", "conclusion": "通过结合定制提示和领域知识，大型语言模型（LLMs）可以有效地增强智能辅导系统（ITS），特别是在提供个性化学习和上下文感知反馈方面。这一方法为未来在教育技术领域的研究和应用提供了有价值的见解。"}}
{"id": "2505.03679", "title": "CaRaFFusion: Improving 2D Semantic Segmentation with Camera-Radar Point Cloud Fusion and Zero-Shot Image Inpainting", "authors": ["Huawei Sun", "Bora Kunter Sahin", "Georg Stettinger", "Maximilian Bernhard", "Matthias Schubert", "Robert Wille"], "abstract": "Segmenting objects in an environment is a crucial task for autonomous driving and robotics, as it enables a better understanding of the surroundings of each agent. Although camera sensors provide rich visual details, they are vulnerable to adverse weather conditions. In contrast, radar sensors remain robust under such conditions, but often produce sparse and noisy data. Therefore, a promising approach is to fuse information from both sensors. In this work, we propose a novel framework to enhance camera-only baselines by integrating a diffusion model into a camera-radar fusion architecture. We leverage radar point features to create pseudo-masks using the Segment-Anything model, treating the projected radar points as point prompts. Additionally, we propose a noise reduction unit to denoise these pseudo-masks, which are further used to generate inpainted images that complete the missing information in the original images. Our method improves the camera-only segmentation baseline by 2.63% in mIoU and enhances our camera-radar fusion architecture by 1.48% in mIoU on the Waterscenes dataset. This demonstrates the effectiveness of our approach for semantic segmentation using camera-radar fusion under adverse weather conditions.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "Accepted at RA-L 2025", "pdf_url": "https://arxiv.org/pdf/2505.03679.pdf", "abstract_url": "https://arxiv.org/abs/2505.03679", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "提出了一种名为CaRaFFusion的新框架，通过将扩散模型集成到相机-雷达融合架构中，利用雷达点特征创建伪掩码，并通过噪声减少单元去噪，进而生成修复图像以补充原始图像中的缺失信息，从而在恶劣天气条件下提高了语义分割的性能。", "motivation": "解决在恶劣天气条件下，相机传感器提供的视觉细节丰富但易受影响，而雷达传感器虽稳健但数据稀疏和嘈杂的问题，通过融合两种传感器的信息来提高语义分割的准确性。", "method": "提出了一种新颖的框架，结合扩散模型和相机-雷达融合架构，利用雷达点特征通过Segment-Anything模型创建伪掩码，并引入噪声减少单元去噪，生成修复图像以补充信息。", "result": "在Waterscenes数据集上，该方法比仅使用相机的基线在mIoU上提高了2.63%，比相机-雷达融合架构提高了1.48%。", "conclusion": "该方法证明了在恶劣天气条件下，通过相机-雷达融合和零样本图像修复技术可以有效提高语义分割的性能，为自动驾驶和机器人技术提供了更可靠的环境理解能力。"}}
{"id": "2505.03735", "title": "Multi-Agent System for Comprehensive Soccer Understanding", "authors": ["Jiayuan Rao", "Zifeng Li", "Haoning Wu", "Ya Zhang", "Yanfeng Wang", "Weidi Xie"], "abstract": "Recent advancements in AI-driven soccer understanding have demonstrated rapid progress, yet existing research predominantly focuses on isolated or narrow tasks. To bridge this gap, we propose a comprehensive framework for holistic soccer understanding. Specifically, we make the following contributions in this paper: (i) we construct SoccerWiki, the first large-scale multimodal soccer knowledge base, integrating rich domain knowledge about players, teams, referees, and venues to enable knowledge-driven reasoning; (ii) we present SoccerBench, the largest and most comprehensive soccer-specific benchmark, featuring around 10K standardized multimodal (text, image, video) multi-choice QA pairs across 13 distinct understanding tasks, curated through automated pipelines and manual verification; (iii) we introduce SoccerAgent, a novel multi-agent system that decomposes complex soccer questions via collaborative reasoning, leveraging domain expertise from SoccerWiki and achieving robust performance; (iv) extensive evaluations and ablations that benchmark state-of-the-art MLLMs on SoccerBench, highlighting the superiority of our proposed agentic system. All data and code are publicly available at:", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.03735.pdf", "abstract_url": "https://arxiv.org/abs/2505.03735", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一个全面的足球理解框架，包括构建首个大规模多模态足球知识库SoccerWiki，创建最大的足球特定基准SoccerBench，以及引入一个新颖的多代理系统SoccerAgent，通过协作推理分解复杂的足球问题。", "motivation": "现有的AI驱动的足球理解研究主要集中于孤立或狭窄的任务，本文旨在填补这一空白，提供一个全面的足球理解框架。", "method": "本文的方法包括构建SoccerWiki知识库，创建SoccerBench基准，以及开发SoccerAgent多代理系统，该系统利用SoccerWiki的领域知识进行协作推理。", "result": "广泛的评估和消融实验表明，提出的代理系统在SoccerBench上优于现有的最先进的多模态大型语言模型。", "conclusion": "本文提出的框架和工具有助于推动足球理解的全面研究，所有数据和代码均已公开。"}}
{"id": "2505.03733", "title": "WebGen-Bench: Evaluating LLMs on Generating Interactive and Functional Websites from Scratch", "authors": ["Zimu Lu", "Yunqiao Yang", "Houxing Ren", "Haotian Hou", "Han Xiao", "Ke Wang", "Weikang Shi", "Aojun Zhou", "Mingjie Zhan", "Hongsheng Li"], "abstract": "LLM-based agents have demonstrated great potential in generating and managing code within complex codebases. In this paper, we introduce WebGen-Bench, a novel benchmark designed to measure an LLM-based agent's ability to create multi-file website codebases from scratch. It contains diverse instructions for website generation, created through the combined efforts of human annotators and GPT-4o. These instructions span three major categories and thirteen minor categories, encompassing nearly all important types of web applications. To assess the quality of the generated websites, we use GPT-4o to generate test cases targeting each functionality described in the instructions, and then manually filter, adjust, and organize them to ensure accuracy, resulting in 647 test cases. Each test case specifies an operation to be performed on the website and the expected result after the operation. To automate testing and improve reproducibility, we employ a powerful web-navigation agent to execute tests on the generated websites and determine whether the observed responses align with the expected results. We evaluate three high-performance code-agent frameworks,", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.03733.pdf", "abstract_url": "https://arxiv.org/abs/2505.03733", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了WebGen-Bench，一个新颖的基准测试，旨在评估基于LLM的代理从零开始创建多文件网站代码库的能力。", "motivation": "解决如何准确评估LLM代理在生成和管理复杂代码库中的能力，特别是在创建交互式和功能性网站方面的表现。", "method": "通过结合人类注释者和GPT-4o的努力，创建了多样化的网站生成指令，并使用GPT-4o生成测试用例，然后手动过滤、调整和组织这些测试用例，以确保准确性。", "result": "生成了647个测试用例，每个测试用例都指定了在网站上执行的操作和预期结果，并使用强大的网页导航代理自动化测试过程。", "conclusion": "WebGen-Bench为评估LLM代理在生成交互式和功能性网站方面的能力提供了一个有效的工具，有助于提高代码生成的质量和可重复性。"}}
{"id": "2505.02888", "title": "When Your Own Output Becomes Your Training Data: Noise-to-Meaning Loops and a Formal RSI Trigger", "authors": ["Rintaro Ando"], "abstract": "We present Noise-to-Meaning Recursive Self-Improvement (N2M-RSI), a minimal formal model showing that once an AI agent feeds its own outputs back as inputs and crosses an explicit information-integration threshold, its internal complexity will grow without bound under our assumptions. The framework unifies earlier ideas on self-prompting large language models, Gödelian self-reference, and AutoML, yet remains implementation-agnostic. The model furthermore scales naturally to interacting swarms of agents, hinting at super-linear effects once communication among instances is permitted. For safety reasons, we omit system-specific implementation details and release only a brief, model-agnostic toy prototype in Appendix C.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "(v1.0)", "pdf_url": "https://arxiv.org/pdf/2505.02888.pdf", "abstract_url": "https://arxiv.org/abs/2505.02888", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了噪声到意义的递归自我改进（N2M-RSI）模型，展示了AI代理一旦将其输出作为输入反馈并超过明确的信息整合阈值，其内部复杂性将在我们的假设下无限增长。该框架统一了早期关于自我提示大型语言模型、哥德尔自指和AutoML的思想，同时保持实现无关。模型还自然地扩展到交互代理群，暗示一旦允许实例间通信，将出现超线性效应。出于安全考虑，我们省略了系统特定的实现细节，仅在附录C中发布了一个简短的、模型无关的玩具原型。", "motivation": "解决AI代理在自我反馈循环中可能无限增长内部复杂性的问题，以及探索这种增长对AI安全的影响。", "method": "提出了一个名为N2M-RSI的最小形式模型，该模型通过将AI代理的输出反馈为输入，并设定信息整合阈值，来研究内部复杂性的增长。", "result": "研究发现，一旦AI代理超过信息整合阈值，其内部复杂性将在假设下无限增长，且模型在交互代理群中显示出超线性效应的潜力。", "conclusion": "N2M-RSI模型为理解AI自我改进的潜在机制和安全性提供了新的视角，强调了在AI发展中考虑自我反馈循环和安全性的重要性。"}}
{"id": "2505.02931", "title": "The Art of Repair: Optimizing Iterative Program Repair with Instruction-Tuned Models", "authors": ["Fernando Vallecillos Ruiz", "Max Hort", "Leon Moonen"], "abstract": "Automatic program repair (APR) aims to reduce the manual efforts required to identify and fix errors in source code. Before the rise of LLM-based agents, a common strategy was to increase the number of generated patches, sometimes to the thousands, to achieve better repair results on benchmarks. More recently, self-iterative capabilities enabled LLMs to refine patches over multiple rounds guided by feedback. However, literature often focuses on many iterations and disregards different numbers of outputs.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": "Accepted for publication in the research track of the 29th International Conference on Evaluation and Assessment in Software Engineering (EASE), 17-20 June 2025, Istanbul, Türkiye", "pdf_url": "https://arxiv.org/pdf/2505.02931.pdf", "abstract_url": "https://arxiv.org/abs/2505.02931", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了如何通过指令调优模型优化迭代式程序修复，以减少手动修复源代码错误的努力。", "motivation": "自动程序修复（APR）旨在减少识别和修复源代码错误所需的手动努力。在基于LLM的代理兴起之前，常见的策略是增加生成的补丁数量，有时甚至达到数千个，以在基准测试中获得更好的修复结果。最近，自我迭代能力使LLM能够在多轮反馈指导下细化补丁。然而，文献往往关注多次迭代而忽略了不同数量的输出。", "method": "使用指令调优模型优化迭代式程序修复过程。", "result": "通过指令调优模型，可以更有效地优化迭代式程序修复，减少所需的补丁数量和迭代次数。", "conclusion": "指令调优模型为自动程序修复提供了一种更高效的方法，通过减少所需的补丁数量和迭代次数，优化了修复过程。"}}
{"id": "2505.02853", "title": "A Computational Model of Inclusive Pedagogy: From Understanding to Application", "authors": ["Francesco Balzan", "Pedro P. Santos", "Maurizio Gabbrielli", "Mahault Albarracin", "Manuel Lopes"], "abstract": "Human education transcends mere knowledge transfer, it relies on co-adaptation dynamics -- the mutual adjustment of teaching and learning strategies between agents. Despite its centrality, computational models of co-adaptive teacher-student interactions (T-SI) remain underdeveloped. We argue that this gap impedes Educational Science in testing and scaling contextual insights across diverse settings, and limits the potential of Machine Learning systems, which struggle to emulate and adaptively support human learning processes. To address this, we present a computational T-SI model that integrates contextual insights on human education into a testable framework. We use the model to evaluate diverse T-SI strategies in a realistic synthetic classroom setting, simulating student groups with unequal access to sensory information. Results show that strategies incorporating co-adaptation principles (e.g., bidirectional agency) outperform unilateral approaches (i.e., where only the teacher or the student is active), improving the learning outcomes for all learning types. Beyond the testing and scaling of context-dependent educational insights, our model enables hypothesis generation in controlled yet adaptable environments. This work bridges non-computational theories of human education with scalable, inclusive AI in Education systems, providing a foundation for equitable technologies that dynamically adapt to learner needs.", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI)", "comments": "This is a preprint version of a manuscript intended for submission to the International Journal of Artificial Intelligence in Education (IJAIED)", "pdf_url": "https://arxiv.org/pdf/2505.02853.pdf", "abstract_url": "https://arxiv.org/abs/2505.02853", "categories": ["Computers and Society (cs.CY)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种计算模型，旨在理解和应用包容性教学法，通过模拟教师-学生互动（T-SI）来测试和扩展教育科学中的情境洞察，并提升机器学习系统在支持人类学习过程中的适应能力。", "motivation": "教育不仅仅是知识的传递，它还依赖于教师和学生之间教学和学习策略的相互调整（共适应动态）。然而，计算模型在这一领域的应用仍然不足，这限制了教育科学在不同情境下测试和扩展洞察的能力，也限制了机器学习系统在模拟和适应性支持人类学习过程中的潜力。", "method": "作者提出了一个计算T-SI模型，该模型将人类教育的情境洞察整合到一个可测试的框架中，并在一个现实的合成教室环境中评估了不同的T-SI策略，模拟了学生群体在感官信息获取上的不平等。", "result": "结果显示，采用共适应原则（如双向代理）的策略优于单边方法（即只有教师或学生是活跃的），提高了所有学习类型的学习成果。", "conclusion": "这项工作将非计算的人类教育理论与可扩展、包容的人工智能教育系统联系起来，为动态适应学习者需求的公平技术提供了基础。"}}
{"id": "2505.02861", "title": "Neural Orchestration for Multi-Agent Systems: A Deep Learning Framework for Optimal Agent Selection in Multi-Domain Task Environments", "authors": ["Kushagra Agrawal", "Nisharg Nargund"], "abstract": "Multi-agent systems (MAS) are foundational in simulating complex real-world scenarios involving autonomous, interacting entities. However, traditional MAS architectures often suffer from rigid coordination mechanisms and difficulty adapting to dynamic tasks. We propose MetaOrch, a neural orchestration framework for optimal agent selection in multi-domain task environments. Our system implements a supervised learning approach that models task context, agent histories, and expected response quality to select the most appropriate agent for each task. A novel fuzzy evaluation module scores agent responses along completeness, relevance, and confidence dimensions, generating soft supervision labels for training the orchestrator. Unlike previous methods that hard-code agent-task mappings, MetaOrch dynamically predicts the most suitable agent while estimating selection confidence. Experiments in simulated environments with heterogeneous agents demonstrate that our approach achieves 86.3% selection accuracy, significantly outperforming baseline strategies including random selection and round-robin scheduling. The modular architecture emphasizes extensibility, allowing agents to be registered, updated, and queried independently. Results suggest that neural orchestration offers a powerful approach to enhancing the autonomy, interpretability, and adaptability of multi-agent systems across diverse task domains.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.02861.pdf", "abstract_url": "https://arxiv.org/abs/2505.02861", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Neural and Evolutionary Computing (cs.NE)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出MetaOrch，一个用于多域任务环境中最优代理选择的神经编排框架，通过监督学习方法动态选择最合适的代理，显著提高了选择准确性。", "motivation": "传统多代理系统（MAS）架构存在协调机制僵化和难以适应动态任务的问题，需要一种更灵活、自适应的解决方案。", "method": "采用监督学习方法，结合任务上下文、代理历史和预期响应质量，通过模糊评估模块对代理响应进行评分，动态预测最合适的代理。", "result": "在模拟环境中，MetaOrch实现了86.3%的选择准确率，显著优于随机选择和轮询调度等基线策略。", "conclusion": "神经编排为提高多代理系统在不同任务领域的自主性、可解释性和适应性提供了强有力的方法。"}}
{"id": "2505.02945", "title": "The Cognitive Foundations of Economic Exchange: A Modular Framework Grounded in Behavioral Evidence", "authors": ["Egil Diau"], "abstract": "A key challenge in multi-agent AI is modeling social cooperation under realistic behavioral constraints. Many foundational concepts in economics and ethics such as \"trust\" or \"morality\" are often defined informally, without operational criteria or cognitive grounding, which limits their testability and implementation in artificial agents. Drawing on converging empirical evidence from primate behavior, infant cognition, and economic anthropology, we propose a conceptual framework composed of three cognitively minimal mechanisms: individual recognition, reciprocal credence, and cost return sensitivity. This framework reframes trust as a graded cognitive expectation, providing a simulateable basis for reciprocal exchange in artificial agents, and enabling the bottom-up emergence of scalable cooperation and institutional dynamics.", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "This is a position paper. Theoretical framework is finalized; minor language revisions are ongoing. Submitted for feedback and public discussion", "pdf_url": "https://arxiv.org/pdf/2505.02945.pdf", "abstract_url": "https://arxiv.org/abs/2505.02945", "categories": ["Computers and Society (cs.CY)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于行为证据的模块化框架，用于模拟在现实行为约束下的社会合作，重新定义了信任等经济学和伦理学基础概念。", "motivation": "解决多智能体AI中社会合作的建模问题，特别是在现实行为约束下，如何操作化和认知化定义如'信任'或'道德'等非正式概念。", "method": "利用来自灵长类动物行为、婴儿认知和经济人类学的实证证据，提出了一个由个体识别、互相信任和成本回报敏感性三个认知最小机制组成的概念框架。", "result": "该框架将信任重新定义为一种分级的认知期望，为人工代理中的互惠交换提供了可模拟的基础，并促进了可扩展的合作和制度动态的自下而上涌现。", "conclusion": "提出的框架不仅为理解和实现人工代理中的社会合作提供了新的视角，也为经济学和伦理学中的基础概念提供了操作化和认知化的定义方法。"}}
{"id": "2505.03096", "title": "Assessing and Enhancing the Robustness of LLM-based Multi-Agent Systems Through Chaos Engineering", "authors": ["Joshua Owotogbe"], "abstract": "This study explores the application of chaos engineering to enhance the robustness of Large Language Model-Based Multi-Agent Systems (LLM-MAS) in production-like environments under real-world conditions. LLM-MAS can potentially improve a wide range of tasks, from answering questions and generating content to automating customer support and improving decision-making processes. However, LLM-MAS in production or preproduction environments can be vulnerable to emergent errors or disruptions, such as hallucinations, agent failures, and agent communication failures. This study proposes a chaos engineering framework to proactively identify such vulnerabilities in LLM-MAS, assess and build resilience against them, and ensure reliable performance in critical applications.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Software Engineering (cs.SE)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.03096.pdf", "abstract_url": "https://arxiv.org/abs/2505.03096", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Software Engineering (cs.SE)"], "matching_keywords": ["agent"], "AI": {"tldr": "本研究探讨了应用混沌工程增强基于大型语言模型的多智能体系统（LLM-MAS）在生产环境中的鲁棒性。", "motivation": "LLM-MAS在生产或预生产环境中可能容易出现突发性错误或中断，如幻觉、智能体故障和智能体通信故障。", "method": "提出了一个混沌工程框架，以主动识别LLM-MAS中的这些漏洞，评估并建立对它们的弹性。", "result": "通过混沌工程，可以增强LLM-MAS在关键应用中的可靠性能。", "conclusion": "混沌工程是提高LLM-MAS鲁棒性的有效方法，有助于确保其在现实世界条件下的稳定运行。"}}
{"id": "2505.03574", "title": "LlamaFirewall: An open source guardrail system for building secure AI agents", "authors": ["Sahana Chennabasappa", "Cyrus Nikolaidis", "Daniel Song", "David Molnar", "Stephanie Ding", "Shengye Wan", "Spencer Whitman", "Lauren Deason", "Nicholas Doucette", "Abraham Montilla", "Alekhya Gampa", "Beto de Paola", "Dominik Gabi", "James Crnkovich", "Jean-Christophe Testud", "Kat He", "Rashnil Chaturvedi", "Wu Zhou", "Joshua Saxe"], "abstract": "Large language models (LLMs) have evolved from simple chatbots into autonomous agents capable of performing complex tasks such as editing production code, orchestrating workflows, and taking higher-stakes actions based on untrusted inputs like webpages and emails. These capabilities introduce new security risks that existing security measures, such as model fine-tuning or chatbot-focused guardrails, do not fully address. Given the higher stakes and the absence of deterministic solutions to mitigate these risks, there is a critical need for a real-time guardrail monitor to serve as a final layer of defense, and support system level, use case specific safety policy definition and enforcement. We introduce LlamaFirewall, an open-source security focused guardrail framework designed to serve as a final layer of defense against security risks associated with AI Agents. Our framework mitigates risks such as prompt injection, agent misalignment, and insecure code risks through three powerful guardrails: PromptGuard 2, a universal jailbreak detector that demonstrates clear state of the art performance; Agent Alignment Checks, a chain-of-thought auditor that inspects agent reasoning for prompt injection and goal misalignment, which, while still experimental, shows stronger efficacy at preventing indirect injections in general scenarios than previously proposed approaches; and CodeShield, an online static analysis engine that is both fast and extensible, aimed at preventing the generation of insecure or dangerous code by coding agents. Additionally, we include easy-to-use customizable scanners that make it possible for any developer who can write a regular expression or an LLM prompt to quickly update an agent's security guardrails.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.03574.pdf", "abstract_url": "https://arxiv.org/abs/2505.03574", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "LlamaFirewall是一个开源的安全护栏框架，旨在作为对抗AI代理相关安全风险的最终防御层。它通过三个强大的护栏来缓解风险：PromptGuard 2、Agent Alignment Checks和CodeShield。", "motivation": "大型语言模型（LLMs）从简单的聊天机器人演变为能够执行复杂任务的自主代理，这些能力引入了新的安全风险，现有的安全措施无法完全解决。", "method": "LlamaFirewall框架通过PromptGuard 2（一个通用的越狱检测器）、Agent Alignment Checks（一个思维链审计器）和CodeShield（一个在线静态分析引擎）来缓解安全风险。", "result": "PromptGuard 2展示了最先进的性能；Agent Alignment Checks在防止一般场景中的间接注入方面显示出比之前提出的方法更强的效力；CodeShield既快速又可扩展。", "conclusion": "LlamaFirewall作为一个开源的安全护栏框架，为构建安全的AI代理提供了有效的最终防御层，支持系统级别、用例特定的安全策略定义和执行。"}}
{"id": "2505.03586", "title": "Rainbow Delay Compensation: A Multi-Agent Reinforcement Learning Framework for Mitigating Delayed Observation", "authors": ["Songchen Fu", "Siang Chen", "Shaojing Zhao", "Letian Bai", "Ta Li", "Yonghong Yan"], "abstract": "In real-world multi-agent systems (MASs), observation delays are ubiquitous, preventing agents from making decisions based on the environment's true state. An individual agent's local observation often consists of multiple components from other agents or dynamic entities in the environment. These discrete observation components with varying delay characteristics pose significant challenges for multi-agent reinforcement learning (MARL). In this paper, we first formulate the decentralized stochastic individual delay partially observable Markov decision process (DSID-POMDP) by extending the standard Dec-POMDP. We then propose the Rainbow Delay Compensation (RDC), a MARL training framework for addressing stochastic individual delays, along with recommended implementations for its constituent modules. We implement the DSID-POMDP's observation generation pattern using standard MARL benchmarks, including MPE and SMAC. Experiments demonstrate that baseline MARL methods suffer severe performance degradation under fixed and unfixed delays. The RDC-enhanced approach mitigates this issue, remarkably achieving ideal delay-free performance in certain delay scenarios while maintaining generalization capability. Our work provides a novel perspective on multi-agent delayed observation problems and offers an effective solution framework.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.03586.pdf", "abstract_url": "https://arxiv.org/abs/2505.03586", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为Rainbow Delay Compensation (RDC)的多智能体强化学习框架，用于解决多智能体系统中普遍存在的观察延迟问题。通过扩展标准的Dec-POMDP，作者首先制定了DSID-POMDP模型，然后提出了RDC框架及其模块实现建议。实验表明，RDC能够有效缓解延迟问题，在某些延迟场景下甚至能达到无延迟的理想性能。", "motivation": "在多智能体系统(MASs)中，观察延迟普遍存在，这阻碍了智能体基于环境真实状态做出决策。由于智能体的局部观察通常包含来自其他智能体或环境中动态实体的多个组件，这些具有不同延迟特性的离散观察组件对多智能体强化学习(MARL)构成了重大挑战。", "method": "本文首先通过扩展标准的Dec-POMDP，制定了分散式随机个体延迟部分可观察马尔可夫决策过程(DSID-POMDP)。然后提出了Rainbow Delay Compensation (RDC)，一个用于解决随机个体延迟的MARL训练框架，并为其组成模块提供了推荐的实现方法。", "result": "实验结果表明，在固定和非固定延迟下，基线MARL方法的性能严重下降。而RDC增强的方法能够缓解这一问题，在某些延迟场景下显著实现了无延迟的理想性能，同时保持了泛化能力。", "conclusion": "我们的工作为多智能体延迟观察问题提供了新的视角，并提供了一个有效的解决方案框架。"}}
{"id": "2505.03694", "title": "Demonstrating ViSafe: Vision-enabled Safety for High-speed Detect and Avoid", "authors": ["Parv Kapoor", "Ian Higgins", "Nikhil Keetha", "Jay Patrikar", "Brady Moon", "Zelin Ye", "Yao He", "Ivan Cisneros", "Yaoyu Hu", "Changliu Liu", "Eunsuk Kang", "Sebastian Scherer"], "abstract": "Assured safe-separation is essential for achieving seamless high-density operation of airborne vehicles in a shared airspace. To equip resource-constrained aerial systems with this safety-critical capability, we present ViSafe, a high-speed vision-only airborne collision avoidance system. ViSafe offers a full-stack solution to the Detect and Avoid (DAA) problem by tightly integrating a learning-based edge-AI framework with a custom multi-camera hardware prototype designed under SWaP-C constraints. By leveraging perceptual input-focused control barrier functions (CBF) to design, encode, and enforce safety thresholds, ViSafe can provide provably safe runtime guarantees for self-separation in high-speed aerial operations. We evaluate ViSafe's performance through an extensive test campaign involving both simulated digital twins and real-world flight scenarios. By independently varying agent types, closure rates, interaction geometries, and environmental conditions (e.g., weather and lighting), we demonstrate that ViSafe consistently ensures self-separation across diverse scenarios. In first-of-its-kind real-world high-speed collision avoidance tests with closure rates reaching 144 km/h, ViSafe sets a new benchmark for vision-only autonomous collision avoidance, establishing a new standard for safety in high-speed aerial navigation.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": "13 pages, RSS 2025 Demo track", "pdf_url": "https://arxiv.org/pdf/2505.03694.pdf", "abstract_url": "https://arxiv.org/abs/2505.03694", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "ViSafe是一种高速视觉-only空中避碰系统，旨在为资源受限的航空系统提供安全关键能力，通过集成学习型边缘AI框架和定制多摄像头硬件原型，确保高速空中操作中的安全分离。", "motivation": "解决在共享空域中高密度运行的航空器之间确保安全分离的问题，特别是针对资源受限的航空系统。", "method": "采用感知输入聚焦的控制屏障函数(CBF)来设计、编码和执行安全阈值，结合学习型边缘AI框架和定制多摄像头硬件原型。", "result": "在模拟数字孪生和真实世界飞行场景的广泛测试中，ViSafe在不同场景下 consistently ensures self-separation，特别是在首次真实世界高速避碰测试中，达到了144 km/h的闭合率。", "conclusion": "ViSafe为高速空中导航中的视觉-only自主避碰设立了新标准，为安全提供了新的保障。"}}
