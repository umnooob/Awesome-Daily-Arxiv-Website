{"id": "2507.22917", "title": "Reading Between the Timelines: RAG for Answering Diachronic Questions", "authors": ["Kwun Hang Lau", "Ruiyuan Zhang", "Weijie Shi", "Xiaofang Zhou", "Xiaojun Cheng"], "abstract": "While Retrieval-Augmented Generation (RAG) excels at injecting static, factual knowledge into Large Language Models (LLMs), it exhibits a critical deficit in handling longitudinal queries that require tracking entities and phenomena across time. This blind spot arises because conventional, semantically-driven retrieval methods are not equipped to gather evidence that is both topically relevant and temporally coherent for a specified duration. We address this challenge by proposing a new framework that fundamentally redesigns the RAG pipeline to infuse temporal logic. Our methodology begins by disentangling a user's query into its core subject and its temporal window. It then employs a specialized retriever that calibrates semantic matching against temporal relevance, ensuring the collection of a contiguous evidence set that spans the entire queried period. To enable rigorous evaluation of this capability, we also introduce the Analytical Diachronic Question Answering Benchmark (ADQAB), a challenging evaluation suite grounded in a hybrid corpus of real and synthetic financial news. Empirical results on ADQAB show that our approach yields substantial gains in answer accuracy, surpassing standard RAG implementations by 13% to 27%. This work provides a validated pathway toward RAG systems capable of performing the nuanced, evolutionary analysis required for complex, real-world questions. The dataset and code for this study are publicly available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.22917.pdf", "abstract_url": "https://arxiv.org/abs/2507.22917", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种新的框架，通过重新设计RAG管道以融入时间逻辑，解决了传统RAG在处理需要跨时间跟踪实体和现象的纵向查询时的不足。该方法在ADQAB基准测试中显示出答案准确率的显著提升。", "motivation": "传统的RAG在处理需要跨时间跟踪实体和现象的纵向查询时存在不足，因为传统的语义驱动检索方法无法收集既主题相关又时间连贯的证据。", "method": "提出了一种新框架，通过将用户的查询分解为核心主题和时间窗口，然后使用专门的检索器校准语义匹配与时间相关性，确保收集跨越整个查询时间段的连续证据集。", "result": "在ADQAB上的实证结果显示，该方法在答案准确率上比标准RAG实现提高了13%到27%。", "conclusion": "这项工作为RAG系统提供了一条经过验证的路径，使其能够执行复杂、现实世界问题所需的细致、进化分析。"}}
{"id": "2507.22923", "title": "How and Where to Translate? The Impact of Translation Strategies in Cross-lingual LLM Prompting", "authors": ["Aman Gupta", "Yingying Zhuang", "Zhou Yu", "Ziji Zhang", "Anurag Beniwal"], "abstract": "Despite advances in the multilingual capabilities of Large Language Models (LLMs), their performance varies substantially across different languages and tasks. In multilingual retrieval-augmented generation (RAG)-based systems, knowledge bases (KB) are often shared from high-resource languages (such as English) to low-resource ones, resulting in retrieved information from the KB being in a different language than the rest of the context. In such scenarios, two common practices are pre-translation to create a mono-lingual prompt and cross-lingual prompting for direct inference. However, the impact of these choices remains unclear. In this paper, we systematically evaluate the impact of different prompt translation strategies for classification tasks with RAG-enhanced LLMs in multilingual systems. Experimental results show that an optimized prompting strategy can significantly improve knowledge sharing across languages, therefore improve the performance on the downstream classification task. The findings advocate for a broader utilization of multilingual resource sharing and cross-lingual prompt optimization for non-English languages, especially the low-resource ones.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "Accepted at Prompt Optimization KDD '25", "pdf_url": "https://arxiv.org/pdf/2507.22923.pdf", "abstract_url": "https://arxiv.org/abs/2507.22923", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文探讨了在跨语言大型语言模型（LLM）提示中翻译策略的影响，特别是在多语言检索增强生成（RAG）系统中，如何通过优化提示策略改善跨语言知识共享和下游分类任务的性能。", "motivation": "尽管大型语言模型（LLMs）在多语言能力上有所进步，但在不同语言和任务中的表现差异显著。在多语言检索增强生成（RAG）系统中，知识库（KB）通常从高资源语言（如英语）共享到低资源语言，导致检索到的信息与上下文语言不同。这种情况下的翻译策略选择对性能的影响尚不明确。", "method": "本文系统地评估了在多语言系统中，使用RAG增强的LLMs进行分类任务时，不同提示翻译策略的影响。", "result": "实验结果表明，优化的提示策略可以显著改善跨语言知识共享，从而提高下游分类任务的性能。", "conclusion": "研究结果主张更广泛地利用多语言资源共享和跨语言提示优化，特别是对于非英语语言，尤其是低资源语言。"}}
{"id": "2507.23242", "title": "Generalized Reinforcement Learning for Retriever-Specific Query Rewriter with Unstructured Real-World Documents", "authors": ["Sungguk Cha", "DongWook Kim", "Taeseung Hahn", "Mintae Kim", "Youngsub Han", "Byoung-Ki Jeon"], "abstract": "Retrieval-Augmented Generation (RAG) systems rely heavily on effective query formulation to unlock external knowledge, yet optimizing queries for diverse, unstructured real-world documents remains a challenge. We introduce \\textbf{RL-QR}, a reinforcement learning framework for retriever-specific query rewriting that eliminates the need for human-annotated datasets and extends applicability to both text-only and multi-modal databases. By synthesizing scenario-question pairs and leveraging Generalized Reward Policy Optimization (GRPO), RL-QR trains query rewriters tailored to specific retrievers, enhancing retrieval performance across varied domains. Experiments on industrial in-house data demonstrate significant improvements, with $\\text{RL-QR}_{\\text{multi-modal}}$ achieving an 11\\% relative gain in NDCG@3 for multi-modal RAG and $\\text{RL-QR}_{\\text{lexical}}$ yielding a 9\\% gain for lexical retrievers. However, challenges persist with semantic and hybrid retrievers, where rewriters failed to improve performance, likely due to training misalignments. Our findings highlight RL-QR's potential to revolutionize query optimization for RAG systems, offering a scalable, annotation-free solution for real-world retrieval tasks, while identifying avenues for further refinement in semantic retrieval contexts.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.23242.pdf", "abstract_url": "https://arxiv.org/abs/2507.23242", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了RL-QR，一个基于强化学习的查询重写框架，旨在优化检索增强生成（RAG）系统中的查询效率，无需人工标注数据集，适用于文本和多模态数据库。实验显示在多模态和词汇检索器上性能显著提升，但在语义和混合检索器上仍有挑战。", "motivation": "解决在多样化和非结构化的真实世界文档中优化查询以提升检索增强生成（RAG）系统效率的问题。", "method": "采用强化学习框架RL-QR，通过合成场景-问题对和利用广义奖励策略优化（GRPO）训练特定于检索器的查询重写器。", "result": "RL-QR在多模态RAG中实现了NDCG@3相对提升11%，在词汇检索器中提升9%，但在语义和混合检索器上未显示改进。", "conclusion": "RL-QR有潜力革新RAG系统的查询优化，为真实世界检索任务提供可扩展、无需标注的解决方案，同时指出了在语义检索环境中进一步改进的方向。"}}
{"id": "2507.23276", "title": "How Far Are AI Scientists from Changing the World?", "authors": ["Qiujie Xie", "Yixuan Weng", "Minjun Zhu", "Fuchen Shen", "Shulin Huang", "Zhen Lin", "Jiahui Zhou", "Zilan Mao", "Zijie Yang", "Linyi Yang", "Jian Wu", "Yue Zhang"], "abstract": "The emergence of large language models (LLMs) is propelling automated scientific discovery to the next level, with LLM-based Artificial Intelligence (AI) Scientist systems now taking the lead in scientific research. Several influential works have already appeared in the field of AI Scientist systems, with AI-generated research papers having been accepted at the ICLR 2025 workshop, suggesting that a human-level AI Scientist capable of uncovering phenomena previously unknown to humans, may soon become a reality. In this survey, we focus on the central question: How far are AI scientists from changing the world and reshaping the scientific research paradigm? To answer this question, we provide a prospect-driven review that comprehensively analyzes the current achievements of AI Scientist systems, identifying key bottlenecks and the critical components required for the emergence of a scientific agent capable of producing ground-breaking discoveries that solve grand challenges. We hope this survey will contribute to a clearer understanding of limitations of current AI Scientist systems, showing where we are, what is missing, and what the ultimate goals for scientific AI should be.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.23276.pdf", "abstract_url": "https://arxiv.org/abs/2507.23276", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了基于大型语言模型（LLMs）的AI科学家系统在科学研究中的进展，及其改变世界和重塑科研范式的潜力。", "motivation": "探索AI科学家系统如何解决重大挑战，以及它们离实现这一目标还有多远。", "method": "通过前瞻性综述，全面分析AI科学家系统的当前成就，识别关键瓶颈和必要组件。", "result": "AI科学家系统已在科学研究中取得显著进展，但仍存在限制，需明确其终极目标。", "conclusion": "本文旨在帮助更清晰地理解当前AI科学家系统的局限性，明确现状、缺失及科学AI的终极目标。"}}
{"id": "2507.23330", "title": "AI Must not be Fully Autonomous", "authors": ["Tosin Adewumi", "Lama Alkhaled", "Florent Imbert", "Hui Han", "Nudrat Habib", "Karl Löwenmark"], "abstract": "Autonomous Artificial Intelligence (AI) has many benefits. It also has many risks. In this work, we identify the 3 levels of autonomous AI. We are of the position that AI must not be fully autonomous because of the many risks, especially as artificial superintelligence (ASI) is speculated to be just decades away. Fully autonomous AI, which can develop its own objectives, is at level 3 and without responsible human oversight. However, responsible human oversight is crucial for mitigating the risks. To ague for our position, we discuss theories of autonomy, AI and agents. Then, we offer 12 distinct arguments and 6 counterarguments with rebuttals to the counterarguments. We also present 15 pieces of recent evidence of AI misaligned values and other risks in the appendix.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "11 pages, 1 figure", "pdf_url": "https://arxiv.org/pdf/2507.23330.pdf", "abstract_url": "https://arxiv.org/abs/2507.23330", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文主张人工智能（AI）不应完全自主，因为存在诸多风险，特别是在人工超级智能（ASI）可能几十年内实现的背景下。作者提出了AI自主性的三个级别，并强调负责任人监督的重要性。", "motivation": "解决完全自主AI带来的风险问题，特别是在ASI可能很快实现的背景下。", "method": "通过讨论自主性、AI和代理的理论，提出12个不同的论点和6个反论点，并对反论点进行反驳。", "result": "提出了AI不应完全自主的立场，并提供了15个AI价值观错位和其他风险的证据。", "conclusion": "负责任人监督对于减轻AI风险至关重要，AI不应达到完全自主的第三级别。"}}
{"id": "2507.22925", "title": "Hierarchical Memory for High-Efficiency Long-Term Reasoning in LLM Agents", "authors": ["Haoran Sun", "Shaoning Zeng"], "abstract": "Long-term memory is one of the key factors influencing the reasoning capabilities of Large Language Model Agents (LLM Agents). Incorporating a memory mechanism that effectively integrates past interactions can significantly enhance decision-making and contextual coherence of LLM Agents. While recent works have made progress in memory storage and retrieval, such as encoding memory into dense vectors for similarity-based search or organizing knowledge in the form of graph, these approaches often fall short in structured memory organization and efficient retrieval. To address these limitations, we propose a Hierarchical Memory (H-MEM) architecture for LLM Agents that organizes and updates memory in a multi-level fashion based on the degree of semantic abstraction. Each memory vector is embedded with a positional index encoding pointing to its semantically related sub-memories in the next layer. During the reasoning phase, an index-based routing mechanism enables efficient, layer-by-layer retrieval without performing exhaustive similarity computations. We evaluate our method on five task settings from the LoCoMo dataset. Experimental results show that our approach consistently outperforms five baseline methods, demonstrating its effectiveness in long-term dialogue scenarios.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.22925.pdf", "abstract_url": "https://arxiv.org/abs/2507.22925", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种用于大型语言模型代理（LLM Agents）的分层记忆（H-MEM）架构，旨在通过多层次的语义抽象组织和更新记忆，以提高长期推理效率。", "motivation": "长期记忆是影响大型语言模型代理推理能力的关键因素之一。现有的记忆存储和检索方法在结构化记忆组织和高效检索方面存在不足。", "method": "提出了一种分层记忆架构，通过语义抽象的多层次组织记忆，并采用基于索引的路由机制进行高效检索。", "result": "在LoCoMo数据集的五个任务设置上评估，该方法 consistently outperforms 五种基线方法，证明了其在长期对话场景中的有效性。", "conclusion": "分层记忆架构显著提高了大型语言模型代理的长期推理能力，特别是在结构化记忆组织和高效检索方面。"}}
{"id": "2507.23336", "title": "DSBC : Data Science task Benchmarking with Context engineering", "authors": ["Ram Mohan Rao Kadiyala", "Siddhant Gupta", "Jebish Purbey", "Giulio Martini", "Suman Debnath", "Hamza Farooq"], "abstract": "Recent advances in large language models (LLMs) have significantly impacted data science workflows, giving rise to specialized data science agents designed to automate analytical tasks. Despite rapid adoption, systematic benchmarks evaluating the efficacy and limitations of these agents remain scarce. In this paper, we introduce a comprehensive benchmark specifically crafted to reflect real-world user interactions with data science agents by observing usage of our commercial applications. We evaluate three LLMs: Claude-4.0-Sonnet, Gemini-2.5-Flash, and OpenAI-o4-Mini across three approaches: zero-shot with context engineering, multi-step with context engineering, and with SmolAgent. Our benchmark assesses performance across a diverse set of eight data science task categories, additionally exploring the sensitivity of models to common prompting issues, such as data leakage and slightly ambiguous instructions. We further investigate the influence of temperature parameters on overall and task-specific outcomes for each model and approach. Our findings reveal distinct performance disparities among the evaluated models and methodologies, highlighting critical factors that affect practical deployment. The benchmark dataset and evaluation framework introduced herein aim to provide a foundation for future research of more robust and effective data science agents.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Multiagent Systems (cs.MA)", "comments": "32 pages", "pdf_url": "https://arxiv.org/pdf/2507.23336.pdf", "abstract_url": "https://arxiv.org/abs/2507.23336", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一个专门设计的基准测试，用于评估数据科学代理在实际用户交互中的效能和限制，测试了三种大型语言模型在不同方法下的表现。", "motivation": "大型语言模型（LLMs）的进步显著影响了数据科学工作流程，催生了旨在自动化分析任务的专门数据科学代理。然而，系统评估这些代理效能和限制的基准测试仍然稀缺。", "method": "通过观察商业应用的使用情况，设计了一个反映真实世界用户与数据科学代理交互的全面基准测试，评估了三种LLMs（Claude-4.0-Sonnet、Gemini-2.5-Flash和OpenAI-o4-Mini）在三种方法（零射击与上下文工程、多步与上下文工程、以及使用SmolAgent）下的表现。", "result": "研究发现，评估的模型和方法之间存在明显的性能差异，突出了影响实际部署的关键因素。", "conclusion": "引入的基准数据集和评估框架旨在为未来研究更强大和有效的数据科学代理提供基础。"}}
{"id": "2507.23429", "title": "Chatting with your ERP: A Recipe", "authors": ["Jorge Ruiz Gómez", "Lidia Andrés Susinos", "Jorge Alamo Olivé", "Sonia Rey Osorno", "Manuel Luis Gonzalez Hernández"], "abstract": "This paper presents the design, implementation, and evaluation behind a Large Language Model (LLM) agent that chats with an industrial production-grade ERP system. The agent is capable of interpreting natural language queries and translating them into executable SQL statements, leveraging open-weight LLMs. A novel dual-agent architecture combining reasoning and critique stages was proposed to improve query generation reliability.", "subjects": "Artificial Intelligence (cs.AI); Databases (cs.DB); Emerging Technologies (cs.ET); Human-Computer Interaction (cs.HC); Multiagent Systems (cs.MA)", "comments": "11 pages, includes 3 tables summarizing schema and model performance. Submitted on July 31, 2025. Targets integration of LLM agents with ERP systems using open-weight models and Ollama deployment", "pdf_url": "https://arxiv.org/pdf/2507.23429.pdf", "abstract_url": "https://arxiv.org/abs/2507.23429", "categories": ["Artificial Intelligence (cs.AI)", "Databases (cs.DB)", "Emerging Technologies (cs.ET)", "Human-Computer Interaction (cs.HC)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了与工业级ERP系统聊天的大型语言模型(LLM)代理的设计、实现和评估。该代理能够解释自然语言查询并将其转换为可执行的SQL语句，利用开放权重的LLM。提出了一种新颖的双代理架构，结合了推理和批判阶段，以提高查询生成的可靠性。", "motivation": "解决如何让非技术用户通过自然语言与复杂的ERP系统交互的问题。", "method": "采用大型语言模型(LLM)代理，设计了一种双代理架构，结合推理和批判阶段，以提高自然语言查询转换为SQL语句的准确性。", "result": "开发出的代理能够有效解释自然语言查询并生成可靠的SQL语句，提高了用户与ERP系统交互的便捷性和效率。", "conclusion": "通过双代理架构的LLM代理，可以显著提升自然语言到SQL转换的可靠性，为非技术用户提供了一种更直观、高效的ERP系统交互方式。"}}
{"id": "2507.23554", "title": "DICE: Dynamic In-Context Example Selection in LLM Agents via Efficient Knowledge Transfer", "authors": ["Ruoyu Wang", "Junda Wu", "Yu Xia", "Tong Yu", "Ryan A. Rossi", "Julian McAuley", "Lina Yao"], "abstract": "Large language model-based agents, empowered by in-context learning (ICL), have demonstrated strong capabilities in complex reasoning and tool-use tasks. However, existing works have shown that the effectiveness of ICL is highly sensitive to the choice of demonstrations, with suboptimal examples often leading to unstable or degraded performance. While prior work has explored example selection, including in some agentic or multi-step settings, existing approaches typically rely on heuristics or task-specific designs and lack a general, theoretically grounded criterion for what constitutes an effective demonstration across reasoning steps. Therefore, it is non-trivial to develop a principled, general-purpose method for selecting demonstrations that consistently benefit agent performance. In this paper, we address this challenge with DICE, Dynamic In-Context Example Selection for LLM Agents, a theoretically grounded ICL framework for agentic tasks that selects the most relevant demonstrations at each step of reasoning. Our approach decomposes demonstration knowledge into transferable and non-transferable components through a causal lens, showing how the latter can introduce spurious dependencies that impair generalization. We further propose a stepwise selection criterion with a formal guarantee of improved agent performance. Importantly, DICE is a general, framework-agnostic solution that can be integrated as a plug-in module into existing agentic frameworks without any additional training cost. Extensive experiments across diverse domains demonstrate our method's effectiveness and generality, highlighting the importance of principled, context-aware demo selection for robust and efficient LLM agents.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.23554.pdf", "abstract_url": "https://arxiv.org/abs/2507.23554", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了DICE，一种基于理论基础的动态上下文示例选择框架，旨在提升大型语言模型代理在复杂推理和工具使用任务中的表现。通过因果视角分解演示知识，并提出逐步选择标准，DICE能够在不增加额外训练成本的情况下，作为插件模块集成到现有代理框架中。", "motivation": "现有研究表明，上下文学习（ICL）的效果高度依赖于演示示例的选择，而次优示例往往导致性能不稳定或下降。尽管已有工作探索了示例选择，但缺乏一个普遍、理论基础的准则来定义跨推理步骤的有效演示。", "method": "DICE通过因果视角将演示知识分解为可转移和不可转移的组件，提出了一种逐步选择标准，并正式保证了代理性能的提升。它是一种通用、框架无关的解决方案，可作为插件模块集成到现有代理框架中。", "result": "跨多个领域的广泛实验证明了DICE方法的有效性和通用性，强调了基于原则、上下文感知的演示选择对于构建稳健高效的大型语言模型代理的重要性。", "conclusion": "DICE提供了一种理论基础的动态上下文示例选择方法，能够显著提升大型语言模型代理的性能，且无需额外训练成本，具有广泛的适用性和实际应用价值。"}}
{"id": "2507.22929", "title": "EH-Benchmark Ophthalmic Hallucination Benchmark and Agent-Driven Top-Down Traceable Reasoning Workflow", "authors": ["Xiaoyu Pan", "Yang Bai", "Ke Zou", "Yang Zhou", "Jun Zhou", "Huazhu Fu", "Yih-Chung Tham", "Yong Liu"], "abstract": "Medical Large Language Models (MLLMs) play a crucial role in ophthalmic diagnosis, holding significant potential to address vision-threatening diseases. However, their accuracy is constrained by hallucinations stemming from limited ophthalmic knowledge, insufficient visual localization and reasoning capabilities, and a scarcity of multimodal ophthalmic data, which collectively impede precise lesion detection and disease diagnosis. Furthermore, existing medical benchmarks fail to effectively evaluate various types of hallucinations or provide actionable solutions to mitigate them. To address the above challenges, we introduce EH-Benchmark, a novel ophthalmology benchmark designed to evaluate hallucinations in MLLMs. We categorize MLLMs' hallucinations based on specific tasks and error types into two primary classes: Visual Understanding and Logical Composition, each comprising multiple subclasses. Given that MLLMs predominantly rely on language-based reasoning rather than visual processing, we propose an agent-centric, three-phase framework, including the Knowledge-Level Retrieval stage, the Task-Level Case Studies stage, and the Result-Level Validation stage. Experimental results show that our multi-agent framework significantly mitigates both types of hallucinations, enhancing accuracy, interpretability, and reliability. Our project is available at", "subjects": "Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Multiagent Systems (cs.MA)", "comments": "9 figures, 5 tables. submit/6621751", "pdf_url": "https://arxiv.org/pdf/2507.22929.pdf", "abstract_url": "https://arxiv.org/abs/2507.22929", "categories": ["Computation and Language (cs.CL)", "Computer Vision and Pattern Recognition (cs.CV)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了EH-Benchmark，一个用于评估医学大型语言模型（MLLMs）在眼科诊断中幻觉问题的新基准，并提出了一个基于代理的三阶段框架来减轻这些幻觉。", "motivation": "医学大型语言模型在眼科诊断中因幻觉问题（如有限的眼科知识、不足的视觉定位和推理能力、以及多模态眼科数据的稀缺）而影响准确性，现有医疗基准无法有效评估或解决这些问题。", "method": "提出了EH-Benchmark基准，将MLLMs的幻觉分为视觉理解和逻辑组合两大类，并提出了一个基于代理的三阶段框架（知识级检索、任务级案例研究和结果级验证）来减轻幻觉。", "result": "实验结果表明，多代理框架显著减轻了两种类型的幻觉，提高了准确性、可解释性和可靠性。", "conclusion": "EH-Benchmark和提出的多代理框架为评估和减轻MLLMs在眼科诊断中的幻觉问题提供了有效的解决方案，有助于提高诊断的准确性和可靠性。"}}
{"id": "2507.22927", "title": "PRGB Benchmark: A Robust Placeholder-Assisted Algorithm for Benchmarking Retrieval-Augmented Generation", "authors": ["Zhehao Tan", "Yihan Jiao", "Dan Yang", "Lei Liu", "Jie Feng", "Duolin Sun", "Yue Shen", "Jian Wang", "Peng Wei", "Jinjie Gu"], "abstract": "Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by integrating external knowledge, where the LLM's ability to generate responses based on the combination of a given query and retrieved documents is crucial. However, most benchmarks focus on overall RAG system performance, rarely assessing LLM-specific capabilities. Current benchmarks emphasize broad aspects such as noise robustness, but lack a systematic and granular evaluation framework on document utilization. To this end, we introduce \\textit{Placeholder-RAG-Benchmark}, a multi-level fine-grained benchmark, emphasizing the following progressive dimensions: (1) multi-level filtering abilities, (2) combination abilities, and (3) reference reasoning. To provide a more nuanced understanding of LLMs' roles in RAG systems, we formulate an innovative placeholder-based approach to decouple the contributions of the LLM's parametric knowledge and the external knowledge. Experiments demonstrate the limitations of representative LLMs in the RAG system's generation capabilities, particularly in error resilience and context faithfulness. Our benchmark provides a reproducible framework for developing more reliable and efficient RAG systems. Our code is available in", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.22927.pdf", "abstract_url": "https://arxiv.org/abs/2507.22927", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了PRGB基准，一个通过占位符辅助的算法，用于评估检索增强生成（RAG）系统中大型语言模型（LLM）的能力。该基准强调多级细粒度评估，包括过滤能力、组合能力和参考推理能力，旨在更系统地理解LLM在RAG系统中的角色。", "motivation": "当前大多数基准测试侧重于评估RAG系统的整体性能，而很少评估LLM特定的能力，尤其是在文档利用方面的系统性和细粒度评估框架的缺乏。", "method": "提出了一个多级细粒度的基准测试\textit{Placeholder-RAG-Benchmark}，采用基于占位符的创新方法来解耦LLM的参数知识和外部知识的贡献。", "result": "实验揭示了代表性LLM在RAG系统生成能力上的局限性，特别是在错误恢复和上下文忠实度方面。", "conclusion": "该基准为开发更可靠和高效的RAG系统提供了一个可重复的框架，有助于更系统地评估和提升LLM在RAG中的表现。"}}
{"id": "2507.22931", "title": "Enhancing RAG Efficiency with Adaptive Context Compression", "authors": ["Shuyu Guo", "Zhaochun Ren"], "abstract": "Retrieval-augmented generation (RAG) enhances large language models (LLMs) with external knowledge but incurs significant inference costs due to lengthy retrieved contexts. While context compression mitigates this issue, existing methods apply fixed compression rates, over-compressing simple queries or under-compressing complex ones. We propose Adaptive Context Compression for RAG (ACC-RAG), a framework that dynamically adjusts compression rates based on input complexity, optimizing inference efficiency without sacrificing accuracy. ACC-RAG combines a hierarchical compressor (for multi-granular embeddings) with a context selector to retain minimal sufficient information, akin to human skimming. Evaluated on Wikipedia and five QA datasets, ACC-RAG outperforms fixed-rate methods and matches/unlocks over 4 times faster inference versus standard RAG while maintaining or improving accuracy.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.22931.pdf", "abstract_url": "https://arxiv.org/abs/2507.22931", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种自适应上下文压缩框架ACC-RAG，用于动态调整压缩率以优化检索增强生成（RAG）的推理效率，同时保持准确性。", "motivation": "解决RAG中因检索到的上下文过长而导致的推理成本高的问题，以及现有固定压缩率方法在简单查询上过度压缩或在复杂查询上压缩不足的局限性。", "method": "提出ACC-RAG框架，结合分层压缩器（用于多粒度嵌入）和上下文选择器，根据输入复杂度动态调整压缩率，保留最小足够信息。", "result": "在Wikipedia和五个QA数据集上的评估显示，ACC-RAG优于固定率方法，推理速度比标准RAG快4倍以上，同时保持或提高了准确性。", "conclusion": "ACC-RAG通过自适应压缩率优化了RAG的推理效率，为处理不同复杂度的查询提供了一种有效的解决方案。"}}
{"id": "2507.22932", "title": "FinMarBa: A Market-Informed Dataset for Financial Sentiment Classification", "authors": ["Baptiste Lefort", "Eric Benhamou", "Beatrice Guez", "Jean-Jacques Ohana", "Ethan Setrouk", "Alban Etienne"], "abstract": "This paper presents a novel hierarchical framework for portfolio optimization, integrating lightweight Large Language Models (LLMs) with Deep Reinforcement Learning (DRL) to combine sentiment signals from financial news with traditional market indicators. Our three-tier architecture employs base RL agents to process hybrid data, meta-agents to aggregate their decisions, and a super-agent to merge decisions based on market data and sentiment analysis. Evaluated on data from 2018 to 2024, after training on 2000-2017, the framework achieves a 26% annualized return and a Sharpe ratio of 1.2, outperforming equal-weighted and S&P 500 benchmarks. Key contributions include scalable cross-modal integration, a hierarchical RL structure for enhanced stability, and open-source reproducibility.", "subjects": "Computation and Language (cs.CL); General Finance (q-fin.GN)", "comments": "8 pages", "pdf_url": "https://arxiv.org/pdf/2507.22932.pdf", "abstract_url": "https://arxiv.org/abs/2507.22932", "categories": ["Computation and Language (cs.CL)", "General Finance (q-fin.GN)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新颖的分层投资组合优化框架，结合轻量级大型语言模型（LLMs）和深度强化学习（DRL），将金融新闻的情感信号与传统市场指标相结合。", "motivation": "解决如何有效结合金融新闻情感分析和传统市场指标以优化投资组合的问题。", "method": "采用三层架构：基础RL代理处理混合数据，元代理聚合决策，超级代理基于市场数据和情感分析合并决策。", "result": "在2018至2024年的数据上评估，训练数据为2000-2017年，框架实现了26%的年化回报率和1.2的夏普比率，优于等权重和S&P 500基准。", "conclusion": "主要贡献包括可扩展的跨模态集成、增强稳定性的分层RL结构以及开源可重复性。"}}
{"id": "2507.23565", "title": "Semantic Chain-of-Trust: Autonomous Trust Orchestration for Collaborator Selection via Hypergraph-Aided Agentic AI", "authors": ["Botao Zhu", "Xianbin Wang", "Dusit Niyato"], "abstract": "In collaborative systems, the effective completion of tasks hinges on task-specific trust evaluations of potential devices for distributed collaboration. However, the complexity of tasks, the spatiotemporal dynamism of distributed device resources, and the inevitable assessment overhead dramatically increase the complexity and resource consumption of the trust evaluation process. As a result, ill-timed or overly frequent trust evaluations can reduce utilization rate of constrained resources, negatively affecting collaborative task execution. To address this challenge, this paper proposes an autonomous trust orchestration method based on a new concept of semantic chain-of-trust. Our technique employs agentic AI and hypergraph to establish and maintain trust relationships among devices. By leveraging its strengths in autonomous perception, task decomposition, and semantic reasoning, we propose agentic AI to perceive device states and autonomously perform trust evaluations of collaborators based on historical performance data only during device idle periods, thereby enabling efficient utilization of distributed resources. In addition, agentic AI performs task-specific trust evaluations on collaborator resources by analyzing the alignment between resource capabilities and task requirements. Moreover, by maintaining a trust hypergraph embedded with trust semantics for each device, agentic AI enables hierarchical management of collaborators and identifies collaborators requiring trust evaluation based on trust semantics, thereby achieving a balance between overhead and trust accuracy. Furthermore, local trust hypergraphs from multiple devices can be chained together to support multi-hop collaboration, enabling efficient coordination in large-scale systems. Experimental results demonstrate that the proposed method achieves resource-efficient trust evaluation.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.23565.pdf", "abstract_url": "https://arxiv.org/abs/2507.23565", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种基于语义信任链的自主信任编排方法，利用代理AI和超图技术，在设备空闲期间基于历史性能数据进行信任评估，以实现分布式资源的高效利用。", "motivation": "解决协作系统中由于任务复杂性、分布式设备资源的时空动态性及评估开销导致的信任评估过程复杂和资源消耗大的问题。", "method": "采用代理AI和超图技术，通过自主感知、任务分解和语义推理，进行设备状态感知和基于历史性能数据的信任评估，同时维护嵌入信任语义的信任超图。", "result": "实验结果表明，所提出的方法实现了资源高效的信任评估。", "conclusion": "通过语义信任链和代理AI技术，本文方法在保证信任准确性的同时，有效平衡了开销，支持大规模系统中的高效协作。"}}
{"id": "2507.22938", "title": "A Graph-based Approach for Multi-Modal Question Answering from Flowcharts in Telecom Documents", "authors": ["Sumit Soman", "H. G. Ranjani", "Sujoy Roychowdhury", "Venkata Dharma Surya Narayana Sastry", "Akshat Jain", "Pranav Gangrade", "Ayaaz Khan"], "abstract": "Question-Answering (QA) from technical documents often involves questions whose answers are present in figures, such as flowcharts or flow diagrams. Text-based Retrieval Augmented Generation (RAG) systems may fail to answer such questions. We leverage graph representations of flowcharts obtained from Visual large Language Models (VLMs) and incorporate them in a text-based RAG system to show that this approach can enable image retrieval for QA in the telecom domain. We present the end-to-end approach from processing technical documents, classifying image types, building graph representations, and incorporating them with the text embedding pipeline for efficient retrieval. We benchmark the same on a QA dataset created based on proprietary telecom product information documents. Results show that the graph representations obtained using a fine-tuned VLM model have lower edit distance with respect to the ground truth, which illustrate the robustness of these representations for flowchart images. Further, the approach for QA using these representations gives good retrieval performance using text-based embedding models, including a telecom-domain adapted one. Our approach also alleviates the need for a VLM in inference, which is an important cost benefit for deployed QA systems.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "Accepted for publication at the KDD 2025 Workshop on Structured Knowledge for Large Language Models", "pdf_url": "https://arxiv.org/pdf/2507.22938.pdf", "abstract_url": "https://arxiv.org/abs/2507.22938", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种基于图的方法，用于从电信文档中的流程图中进行多模态问答。通过利用视觉大语言模型（VLMs）获得的流程图图表示，并将其整合到基于文本的检索增强生成（RAG）系统中，实现了在电信领域的图像检索问答。", "motivation": "解决技术文档中基于流程图的问答问题，传统基于文本的RAG系统在此类问题上表现不佳。", "method": "使用VLMs获取流程图的图表示，并将其与文本嵌入管道结合，构建了一个端到端的处理流程，包括技术文档处理、图像类型分类、图表示构建等步骤。", "result": "实验结果表明，使用微调VLM模型获得的图表示与真实值之间的编辑距离较低，证明了这些表示对于流程图图像的鲁棒性。此外，该方法在使用基于文本的嵌入模型（包括电信领域适应的模型）时，展现了良好的检索性能。", "conclusion": "该方法不仅提高了问答系统的性能，还避免了在推理过程中使用VLM，为部署的问答系统带来了重要的成本效益。"}}
{"id": "2507.23633", "title": "MemoCue: Empowering LLM-Based Agents for Human Memory Recall via Strategy-Guided Querying", "authors": ["Qian Zhao", "Zhuo Sun", "Bin Guo", "Zhiwen Yu"], "abstract": "Agent-assisted memory recall is one critical research problem in the field of human-computer interaction. In conventional methods, the agent can retrieve information from its equipped memory module to help the person recall incomplete or vague memories. The limited size of memory module hinders the acquisition of complete memories and impacts the memory recall performance in practice. Memory theories suggest that the person's relevant memory can be proactively activated through some effective cues. Inspired by this, we propose a novel strategy-guided agent-assisted memory recall method, allowing the agent to transform an original query into a cue-rich one via the judiciously designed strategy to help the person recall memories. To this end, there are two key challenges. (1) How to choose the appropriate recall strategy for diverse forgetting scenarios with distinct memory-recall characteristics? (2) How to obtain the high-quality responses leveraging recall strategies, given only abstract and sparsely annotated strategy patterns? To address the challenges, we propose a Recall Router framework. Specifically, we design a 5W Recall Map to classify memory queries into five typical scenarios and define fifteen recall strategy patterns across the corresponding scenarios. We then propose a hierarchical recall tree combined with the Monte Carlo Tree Search algorithm to optimize the selection of strategy and the generation of strategy responses. We construct an instruction tuning dataset and fine-tune multiple open-source large language models (LLMs) to develop MemoCue, an agent that excels in providing memory-inspired responses. Experiments on three representative datasets show that MemoCue surpasses LLM-based methods by 17.74% in recall inspiration. Further human evaluation highlights its advantages in memory-recall applications.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.23633.pdf", "abstract_url": "https://arxiv.org/abs/2507.23633", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "MemoCue是一种基于LLM的代理，通过策略引导查询增强人类记忆回忆能力。", "motivation": "解决传统代理辅助记忆回忆方法中记忆模块大小限制导致的记忆获取不完整和回忆性能下降的问题。", "method": "设计了Recall Router框架，包括5W Recall Map分类记忆查询和十五种回忆策略模式，结合蒙特卡洛树搜索算法优化策略选择和响应生成。", "result": "在三个代表性数据集上的实验显示，MemoCue在回忆灵感上比基于LLM的方法提高了17.74%。", "conclusion": "MemoCue在记忆回忆应用中显示出优势，为人类记忆回忆提供了有效的辅助工具。"}}
{"id": "2507.23773", "title": "SimuRA: Towards General Goal-Oriented Agent via Simulative Reasoning Architecture with LLM-Based World Model", "authors": ["Mingkai Deng", "Jinyu Hou", "Yilin Shen", "Hongxia Jin", "Graham Neubig", "Zhiting Hu", "Eric Xing"], "abstract": "AI agents built on large language models (LLMs) hold enormous promise, but current practice focuses on a one-task-one-agent approach, which not only falls short of scalability and generality, but also suffers from the fundamental limitations of autoregressive LLMs. On the other hand, humans are general agents who reason by mentally simulating the outcomes of their actions and plans. Moving towards a more general and powerful AI agent, we introduce SimuRA, a goal-oriented architecture for generalized agentic reasoning. Based on a principled formulation of optimal agent in any environment, \\modelname overcomes the limitations of autoregressive reasoning by introducing a world model for planning via simulation. The generalized world model is implemented using LLM, which can flexibly plan in a wide range of environments using the concept-rich latent space of natural language. Experiments on difficult web browsing tasks show that \\modelname improves the success of flight search from 0\\% to 32.2\\%. World-model-based planning, in particular, shows consistent advantage of up to 124\\% over autoregressive planning, demonstrating the advantage of world model simulation as a reasoning paradigm. We are excited about the possibility for training a single, general agent model based on LLMs that can act superintelligently in all environments. To start, we make SimuRA, a web-browsing agent built on \\modelname with pretrained LLMs, available as a research demo for public testing.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.23773.pdf", "abstract_url": "https://arxiv.org/abs/2507.23773", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)", "Robotics (cs.RO)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "SimuRA是一种面向通用目标的代理架构，通过基于LLM的世界模型进行模拟推理，旨在克服自回归LLM的局限性，提高代理的通用性和效率。", "motivation": "当前基于大型语言模型（LLMs）的AI代理采用一对一任务的方法，缺乏可扩展性和通用性，且受限于自回归LLMs的基本限制。", "method": "SimuRA引入了一个世界模型，通过模拟规划和推理，利用自然语言的概念丰富潜在空间，在广泛的环境中灵活规划。", "result": "在困难的网页浏览任务中，SimuRA将航班搜索的成功率从0%提高到32.2%，基于世界模型的规划比自回归规划有高达124%的优势。", "conclusion": "SimuRA展示了基于LLMs训练单一通用代理模型的潜力，该模型可以在所有环境中智能行动，为未来研究提供了方向。"}}
{"id": "2507.23701", "title": "TextQuests: How Good are LLMs at Text-Based Video Games?", "authors": ["Long Phan", "Mantas Mazeika", "Andy Zou", "Dan Hendrycks"], "abstract": "Evaluating AI agents within complex, interactive environments that mirror real-world challenges is critical for understanding their practical capabilities. While existing agent benchmarks effectively assess skills like tool use or performance on structured tasks, they often do not fully capture an agent's ability to operate autonomously in exploratory environments that demand sustained, self-directed reasoning over a long and growing context. To spur the development of agents capable of more robust intrinsic reasoning over long horizons, we introduce TextQuests, a benchmark based on the Infocom suite of interactive fiction games. These text-based adventures, which can take human players over 30 hours and require hundreds of precise actions to solve, serve as an effective proxy for evaluating AI agents on focused, stateful tasks. The benchmark is specifically designed to assess an LLM agent's capacity for self-contained problem-solving by precluding the use of external tools, thereby focusing on intrinsic long-context reasoning capabilities in an exploratory environment characterized by the need for trial-and-error learning and sustained problem-solving within a single interactive session. We release TextQuests at", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.23701.pdf", "abstract_url": "https://arxiv.org/abs/2507.23701", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了TextQuests，一个基于Infocom互动小说游戏的基准测试，旨在评估大型语言模型（LLM）在文本冒险游戏中的自主问题解决能力，特别是在需要长时间上下文推理和试错学习的探索性环境中。", "motivation": "现有的AI代理基准测试在评估工具使用或结构化任务表现方面有效，但未能全面评估代理在需要长时间自主推理的探索性环境中的能力。为了解决这一问题，本文提出了TextQuests基准测试。", "method": "通过基于Infocom互动小说游戏的TextQuests基准测试，评估LLM代理在无需外部工具的情况下，进行长时间上下文推理和自主问题解决的能力。", "result": "TextQuests基准测试能够有效评估LLM代理在需要长时间自主推理和试错学习的探索性环境中的表现。", "conclusion": "TextQuests为开发能够在长时间自主推理和复杂问题解决方面表现更强大的AI代理提供了新的基准测试，推动了AI在探索性环境中的应用发展。"}}
{"id": "2507.22897", "title": "RecUserSim: A Realistic and Diverse User Simulator for Evaluating Conversational Recommender Systems", "authors": ["Luyu Chen", "Quanyu Dai", "Zeyu Zhang", "Xueyang Feng", "Mingyu Zhang", "Pengcheng Tang", "Xu Chen", "Yue Zhu", "Zhenhua Dong"], "abstract": "Conversational recommender systems (CRS) enhance user experience through multi-turn interactions, yet evaluating CRS remains challenging. User simulators can provide comprehensive evaluations through interactions with CRS, but building realistic and diverse simulators is difficult. While recent work leverages large language models (LLMs) to simulate user interactions, they still fall short in emulating individual real users across diverse scenarios and lack explicit rating mechanisms for quantitative evaluation. To address these gaps, we propose RecUserSim, an LLM agent-based user simulator with enhanced simulation realism and diversity while providing explicit scores. RecUserSim features several key modules: a profile module for defining realistic and diverse user personas, a memory module for tracking interaction history and discovering unknown preferences, and a core action module inspired by Bounded Rationality theory that enables nuanced decision-making while generating more fine-grained actions and personalized responses. To further enhance output control, a refinement module is designed to fine-tune final responses. Experiments demonstrate that RecUserSim generates diverse, controllable outputs and produces realistic, high-quality dialogues, even with smaller base LLMs. The ratings generated by RecUserSim show high consistency across different base LLMs, highlighting its effectiveness for CRS evaluation.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": "Accepted by TheWebConf'25 Industry Track", "pdf_url": "https://arxiv.org/pdf/2507.22897.pdf", "abstract_url": "https://arxiv.org/abs/2507.22897", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了RecUserSim，一个基于大型语言模型（LLM）代理的用户模拟器，旨在通过增强模拟的真实性和多样性，并提供明确的评分机制，来解决对话推荐系统（CRS）评估中的挑战。", "motivation": "对话推荐系统（CRS）通过多轮互动提升用户体验，但其评估仍然面临挑战。现有的用户模拟器在模拟真实用户行为和提供多样化场景方面存在不足，且缺乏明确的评分机制进行定量评估。", "method": "RecUserSim采用LLM代理为基础，设计了几个关键模块：用于定义真实多样化用户角色的配置文件模块，用于跟踪互动历史和发现未知偏好的记忆模块，以及受有限理性理论启发的核心行动模块，该模块支持细致的决策生成更细粒度的动作和个性化响应。此外，还设计了一个细化模块来微调最终响应。", "result": "实验表明，RecUserSim能够生成多样化且可控的输出，并产生真实、高质量的对话，即使使用较小的基础LLM。RecUserSim生成的评分在不同基础LLM之间显示出高度一致性，证明了其在CRS评估中的有效性。", "conclusion": "RecUserSim通过其模块化设计和LLM代理的应用，显著提升了用户模拟的真实性和多样性，同时提供了明确的评分机制，为对话推荐系统的评估提供了一个有效的工具。"}}
{"id": "2507.22904", "title": "SketchMind: A Multi-Agent Cognitive Framework for Assessing Student-Drawn Scientific Sketches", "authors": ["Ehsan Latif", "Zirak Khan", "Xiaoming Zhai"], "abstract": "Scientific sketches (e.g., models) offer a powerful lens into students' conceptual understanding, yet AI-powered automated assessment of such free-form, visually diverse artifacts remains a critical challenge. Existing solutions often treat sketch evaluation as either an image classification task or monolithic vision-language models, which lack interpretability, pedagogical alignment, and adaptability across cognitive levels. To address these limitations, we present SketchMind, a cognitively grounded, multi-agent framework for evaluating and improving student-drawn scientific sketches. SketchMind comprises modular agents responsible for rubric parsing, sketch perception, cognitive alignment, and iterative feedback with sketch modification, enabling personalized and transparent evaluation. We evaluate SketchMind on a curated dataset of 3,575 student-generated sketches across six science assessment items with different highest order of Bloom's level that require students to draw models to explain phenomena. Compared to baseline GPT-4o performance without SRG (average accuracy: 55.6%), and with SRG integration achieves 77.1% average accuracy (+21.4% average absolute gain). We also demonstrate that multi-agent orchestration with SRG enhances SketchMind performance, for example, GPT-4.1 gains an average 8.9% increase in sketch prediction accuracy, outperforming single-agent pipelines across all items. Human evaluators rated the feedback and co-created sketches generated by \\textsc{SketchMind} with GPT-4.1, which achieved an average of 4.1 out of 5, significantly higher than those of baseline models (e.g., 2.3 for GPT-4o). Experts noted the system's potential to meaningfully support conceptual growth through guided revision. Our code and (pending approval) dataset will be released to support reproducibility and future research in AI-driven education.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": "Submitted to NeurIPS2025", "pdf_url": "https://arxiv.org/pdf/2507.22904.pdf", "abstract_url": "https://arxiv.org/abs/2507.22904", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "SketchMind是一个基于多智能体认知框架的系统，旨在评估和改进学生绘制的科学草图，通过模块化智能体实现个性化、透明的评估，并在科学教育中展现出显著的效果提升。", "motivation": "科学草图（如模型）能有效反映学生的概念理解，但现有的AI自动评估方法在解释性、教育对齐和跨认知水平适应性方面存在不足。", "method": "SketchMind采用多智能体框架，包括规则解析、草图感知、认知对齐和迭代反馈与修改等模块化智能体，以实现对科学草图的评估和改进。", "result": "与基线GPT-4o相比，SketchMind在集成SRG后平均准确率提高了21.4%，达到77.1%。多智能体协调进一步提升了性能，如GPT-4.1的草图预测准确率平均提高了8.9%。人类评估者对SketchMind生成的反馈和共同创作的草图评分显著高于基线模型。", "conclusion": "SketchMind通过其多智能体框架和SRG集成，不仅提高了评估的准确性和效率，还能通过引导修订支持学生的概念成长，具有在AI驱动教育中的广泛应用潜力。"}}
{"id": "2507.22902", "title": "Toward the Autonomous AI Doctor: Quantitative Benchmarking of an Autonomous Agentic AI Versus Board-Certified Clinicians in a Real World Setting", "authors": ["Hashim Hayat", "Maksim Kudrautsau", "Evgeniy Makarov", "Vlad Melnichenko", "Tim Tsykunou", "Piotr Varaksin", "Matt Pavelle", "Adam Z. Oskowitz"], "abstract": "Background: Globally we face a projected shortage of 11 million healthcare practitioners by 2030, and administrative burden consumes 50% of clinical time. Artificial intelligence (AI) has the potential to help alleviate these problems. However, no end-to-end autonomous large language model (LLM)-based AI system has been rigorously evaluated in real-world clinical practice. In this study, we evaluated whether a multi-agent LLM-based AI framework can function autonomously as an AI doctor in a virtual urgent care setting. Methods: We retrospectively compared the performance of the multi-agent AI system Doctronic and board-certified clinicians across 500 consecutive urgent-care telehealth encounters. The primary end points: diagnostic concordance, treatment plan consistency, and safety metrics, were assessed by blinded LLM-based adjudication and expert human review. Results: The top diagnosis of Doctronic and clinician matched in 81% of cases, and the treatment plan aligned in 99.2% of cases. No clinical hallucinations occurred (e.g., diagnosis or treatment not supported by clinical findings). In an expert review of discordant cases, AI performance was superior in 36.1%, and human performance was superior in 9.3%; the diagnoses were equivalent in the remaining cases. Conclusions: In this first large-scale validation of an autonomous AI doctor, we demonstrated strong diagnostic and treatment plan concordance with human clinicians, with AI performance matching and in some cases exceeding that of practicing clinicians. These findings indicate that multi-agent AI systems achieve comparable clinical decision-making to human providers and offer a potential solution to healthcare workforce shortages.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.22902.pdf", "abstract_url": "https://arxiv.org/abs/2507.22902", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本研究评估了一个基于多代理大型语言模型（LLM）的AI系统Doctronic在虚拟紧急护理设置中作为AI医生的性能，与董事会认证的临床医生相比，显示出强大的诊断和治疗计划一致性，AI性能在某些情况下甚至超过了实践中的临床医生。", "motivation": "全球面临到2030年预计短缺1100万医疗从业者的问题，且行政负担消耗了50%的临床时间。人工智能（AI）有潜力帮助缓解这些问题，但目前尚未有端到端的自主大型语言模型（LLM）基于AI系统在真实世界临床实践中被严格评估。", "method": "研究回顾性比较了多代理AI系统Doctronic和董事会认证的临床医生在500次连续的紧急护理远程医疗遭遇中的表现。主要终点：诊断一致性、治疗计划一致性和安全指标，通过盲法LLM基于裁决和专家人工审查进行评估。", "result": "Doctronic和临床医生的顶级诊断在81%的病例中匹配，治疗计划在99.2%的病例中一致。未发生临床幻觉（例如，诊断或治疗不受临床发现支持）。在专家审查不一致的病例中，AI性能在36.1%的病例中优于人类，人类性能在9.3%的病例中优于AI；其余病例中的诊断等效。", "conclusion": "在这首次大规模验证自主AI医生的研究中，我们展示了与人类临床医生强大的诊断和治疗计划一致性，AI性能在某些情况下甚至超过了实践中的临床医生。这些发现表明，多代理AI系统实现了与人类提供者相当的临床决策，并为医疗劳动力短缺提供了潜在解决方案。"}}
{"id": "2507.23734", "title": "RAGNet: Large-scale Reasoning-based Affordance Segmentation Benchmark towards General Grasping", "authors": ["Dongming Wu", "Yanping Fu", "Saike Huang", "Yingfei Liu", "Fan Jia", "Nian Liu", "Feng Dai", "Tiancai Wang", "Rao Muhammad Anwer", "Fahad Shahbaz Khan", "Jianbing Shen"], "abstract": "General robotic grasping systems require accurate object affordance perception in diverse open-world scenarios following human instructions. However, current studies suffer from the problem of lacking reasoning-based large-scale affordance prediction data, leading to considerable concern about open-world effectiveness. To address this limitation, we build a large-scale grasping-oriented affordance segmentation benchmark with human-like instructions, named RAGNet. It contains 273k images, 180 categories, and 26k reasoning instructions. The images cover diverse embodied data domains, such as wild, robot, ego-centric, and even simulation data. They are carefully annotated with an affordance map, while the difficulty of language instructions is largely increased by removing their category name and only providing functional descriptions. Furthermore, we propose a comprehensive affordance-based grasping framework, named AffordanceNet, which consists of a VLM pre-trained on our massive affordance data and a grasping network that conditions an affordance map to grasp the target. Extensive experiments on affordance segmentation benchmarks and real-robot manipulation tasks show that our model has a powerful open-world generalization ability. Our data and code is available at", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2507.23734.pdf", "abstract_url": "https://arxiv.org/abs/2507.23734", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Robotics (cs.RO)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了RAGNet，一个面向通用抓取的大规模基于推理的可用性分割基准，旨在解决当前研究中缺乏基于推理的大规模可用性预测数据的问题。通过构建包含273k图像、180个类别和26k推理指令的数据集，并提出了AffordanceNet框架，该框架结合了在大量可用性数据上预训练的VLM和基于可用性地图的抓取网络，展示了强大的开放世界泛化能力。", "motivation": "解决通用机器人抓取系统在多样化开放世界场景中准确感知对象可用性的问题，特别是当前研究缺乏基于推理的大规模可用性预测数据，影响了开放世界的有效性。", "method": "构建了一个大规模抓取导向的可用性分割基准RAGNet，包含273k图像、180个类别和26k推理指令，并提出了AffordanceNet框架，该框架包括一个在大规模可用性数据上预训练的VLM和一个基于可用性地图的抓取网络。", "result": "在可用性分割基准和真实机器人操作任务上的大量实验表明，AffordanceNet具有强大的开放世界泛化能力。", "conclusion": "RAGNet和AffordanceNet为解决通用机器人抓取系统中的可用性感知问题提供了有效的数据集和方法，展示了在开放世界中的强大泛化能力。"}}
{"id": "2507.23095", "title": "SMART-Editor: A Multi-Agent Framework for Human-Like Design Editing with Structural Integrity", "authors": ["Ishani Mondal", "Meera Bharadwaj", "Ayush Roy", "Aparna Garimella", "Jordan Lee Boyd-Graber"], "abstract": "We present SMART-Editor, a framework for compositional layout and content editing across structured (posters, websites) and unstructured (natural images) domains. Unlike prior models that perform local edits, SMART-Editor preserves global coherence through two strategies: Reward-Refine, an inference-time rewardguided refinement method, and RewardDPO, a training-time preference optimization approach using reward-aligned layout pairs. To evaluate model performance, we introduce SMARTEdit-Bench, a benchmark covering multi-domain, cascading edit scenarios. SMART-Editor outperforms strong baselines like InstructPix2Pix and HIVE, with RewardDPO achieving up to 15% gains in structured settings and Reward-Refine showing advantages on natural images. Automatic and human evaluations confirm the value of reward-guided planning in producing semantically consistent and visually aligned edits.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "Under Submission", "pdf_url": "https://arxiv.org/pdf/2507.23095.pdf", "abstract_url": "https://arxiv.org/abs/2507.23095", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "SMART-Editor是一个多智能体框架，用于在结构化和非结构化领域进行组合布局和内容编辑，通过Reward-Refine和RewardDPO策略保持全局一致性，并在多领域编辑场景中优于现有基线。", "motivation": "解决现有模型在进行局部编辑时无法保持全局一致性的问题。", "method": "采用Reward-Refine（推理时奖励引导的细化方法）和RewardDPO（训练时偏好优化方法）两种策略。", "result": "SMART-Editor在结构化设置中比基线模型提高15%，在自然图像上显示优势，自动和人工评估证实了奖励引导规划的价值。", "conclusion": "SMART-Editor通过奖励引导的规划，能够产生语义一致和视觉对齐的编辑，展示了在多领域编辑中的优越性能。"}}
{"id": "2507.23194", "title": "Geak: Introducing Triton Kernel AI Agent & Evaluation Benchmarks", "authors": ["Jianghui Wang", "Vinay Joshi", "Saptarshi Majumder", "Xu Chao", "Bin Ding", "Ziqiong Liu", "Pratik Prabhanjan Brahma", "Dong Li", "Zicheng Liu", "Emad Barsoum"], "abstract": "The demand for AI-generated GPU kernels is rapidly growing, influenced by the need for scalable, hardware-optimized solutions in both industry and academia. As deep learning workloads grow in complexity and diversity, it is imperative to automate low-level kernel development to meet performance and productivity demands. Major cloud providers, semiconductor companies, and research institutions are now investing heavily in AI-driven code generation for GPUs, aiming to reduce manual optimization efforts while achieving near-expert performance on hardware like AMD MI300X. The Triton language, a Python-based DSL for GPU programming, has emerged as a popular target for such AI-generated kernels due to its balance of performance and ease-of-coding. In this work, we present an evaluation suite for Triton-based GPU kernels and GEAK (Generating Efficient AI-centric GPU Kernels)-a framework that leverages cutting-edge LLMs to generate performant Triton code specifically for AMD GPUs, including the AMD MI300X and MI250. GEAK leverages inference-time compute scaling to produce Triton-based GPU kernels using a reasoning loop adapted from Reflexion-style feedback mechanisms. On two evaluation benchmarks, GEAK significantly outperformed the baselines of directly prompting frontier LLMs as well as Reflexion-based generation pipelines by achieving correctness up to $63$% and execution speed up of up to $2.59$X. These results highlight the promise of GEAK-like agentic code generation for accelerating the adoption of diverse hardware platforms and democratizing access to expert-level kernel performance.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.23194.pdf", "abstract_url": "https://arxiv.org/abs/2507.23194", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了GEAK框架，一个利用先进LLMs为AMD GPU生成高性能Triton代码的系统，以及一个评估Triton基础GPU内核的测试套件。GEAK通过推理时计算缩放和Reflexion风格反馈机制，在正确性和执行速度上显著优于基线方法。", "motivation": "随着深度学习工作负载的复杂性和多样性增加，自动化低级内核开发以满足性能和生产力需求变得至关重要。", "method": "GEAK框架利用前沿的LLMs和推理时计算缩放，采用Reflexion风格的反馈机制生成针对AMD GPU的高性能Triton代码。", "result": "在两个评估基准上，GEAK在正确性上达到了63%，执行速度提升了2.59倍，显著优于直接提示前沿LLMs和基于Reflexion的生成流程。", "conclusion": "GEAK类代理代码生成有望加速多样化硬件平台的采用，并使专家级内核性能的访问民主化。"}}
{"id": "2507.22952", "title": "Automated Label Placement on Maps via Large Language Models", "authors": ["Harry Shomer", "Jiejun Xu"], "abstract": "Label placement is a critical aspect of map design, serving as a form of spatial annotation that directly impacts clarity and interpretability. Despite its importance, label placement remains largely manual and difficult to scale, as existing automated systems struggle to integrate cartographic conventions, adapt to context, or interpret labeling instructions. In this work, we introduce a new paradigm for automatic label placement (ALP) that formulates the task as a data editing problem and leverages large language models (LLMs) for context-aware spatial annotation. To support this direction, we curate MAPLE, the first known benchmarking dataset for evaluating ALP on real-world maps, encompassing diverse landmark types and label placement annotations from open-source data. Our method retrieves labeling guidelines relevant to each landmark type leveraging retrieval-augmented generation (RAG), integrates them into prompts, and employs instruction-tuned LLMs to generate ideal label coordinates. We evaluate four open-source LLMs on MAPLE, analyzing both overall performance and generalization across different types of landmarks. This includes both zero-shot and instruction-tuned performance. Our results demonstrate that LLMs, when guided by structured prompts and domain-specific retrieval, can learn to perform accurate spatial edits, aligning the generated outputs with expert cartographic standards. Overall, our work presents a scalable framework for AI-assisted map finishing and demonstrates the potential of foundation models in structured data editing tasks. The code and data can be found at", "subjects": "Human-Computer Interaction (cs.HC); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "comments": "Workshop on AI for Data Editing (AI4DE) at KDD 2025", "pdf_url": "https://arxiv.org/pdf/2507.22952.pdf", "abstract_url": "https://arxiv.org/abs/2507.22952", "categories": ["Human-Computer Interaction (cs.HC)", "Computer Vision and Pattern Recognition (cs.CV)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种利用大型语言模型（LLMs）进行地图标签自动放置（ALP）的新方法，通过将任务视为数据编辑问题，并结合检索增强生成（RAG）技术，实现了上下文感知的空间标注。", "motivation": "地图标签放置是地图设计中的一个关键环节，直接影响地图的清晰度和可解释性。然而，现有的自动化系统难以整合制图惯例、适应上下文或解释标签放置指令，导致标签放置仍然主要依赖手动操作，难以扩展。", "method": "本研究提出了一种新的ALP范式，利用LLMs进行上下文感知的空间标注。方法包括检索与地标类型相关的标签放置指南，将其整合到提示中，并利用指令调优的LLMs生成理想的标签坐标。", "result": "在MAPLE基准数据集上评估了四种开源LLMs，结果表明，当LLMs受到结构化提示和领域特定检索的引导时，能够学习执行准确的空间编辑，生成的输出与专家制图标准一致。", "conclusion": "本研究为AI辅助地图完成提供了一个可扩展的框架，并展示了基础模型在结构化数据编辑任务中的潜力。"}}
{"id": "2507.23772", "title": "SeqAffordSplat: Scene-level Sequential Affordance Reasoning on 3D Gaussian Splatting", "authors": ["Di Li", "Jie Feng", "Jiahao Chen", "Weisheng Dong", "Guanbin Li", "Yuhui Zheng", "Mingtao Feng", "Guangming Shi"], "abstract": "3D affordance reasoning, the task of associating human instructions with the functional regions of 3D objects, is a critical capability for embodied agents. Current methods based on 3D Gaussian Splatting (3DGS) are fundamentally limited to single-object, single-step interactions, a paradigm that falls short of addressing the long-horizon, multi-object tasks required for complex real-world applications. To bridge this gap, we introduce the novel task of Sequential 3D Gaussian Affordance Reasoning and establish SeqAffordSplat, a large-scale benchmark featuring 1800+ scenes to support research on long-horizon affordance understanding in complex 3DGS environments. We then propose SeqSplatNet, an end-to-end framework that directly maps an instruction to a sequence of 3D affordance masks. SeqSplatNet employs a large language model that autoregressively generates text interleaved with special segmentation tokens, guiding a conditional decoder to produce the corresponding 3D mask. To handle complex scene geometry, we introduce a pre-training strategy, Conditional Geometric Reconstruction, where the model learns to reconstruct complete affordance region masks from known geometric observations, thereby building a robust geometric prior. Furthermore, to resolve semantic ambiguities, we design a feature injection mechanism that lifts rich semantic features from 2D Vision Foundation Models (VFM) and fuses them into the 3D decoder at multiple scales. Extensive experiments demonstrate that our method sets a new state-of-the-art on our challenging benchmark, effectively advancing affordance reasoning from single-step interactions to complex, sequential tasks at the scene level.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.23772.pdf", "abstract_url": "https://arxiv.org/abs/2507.23772", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了SeqAffordSplat，一个基于3D高斯泼溅（3DGS）的场景级顺序功能推理任务和大型基准测试，旨在解决现有方法在长视野、多对象任务中的局限性。提出的SeqSplatNet框架通过大型语言模型和条件解码器，将指令映射到一系列3D功能掩码，结合几何重建预训练和特征注入机制，显著提升了复杂场景下的功能推理能力。", "motivation": "现有的基于3D高斯泼溅（3DGS）的功能推理方法仅限于单对象、单步交互，无法满足复杂现实应用中对长视野、多对象任务的需求。", "method": "提出了SeqSplatNet，一个端到端框架，利用大型语言模型自回归生成文本与分割标记，指导条件解码器生成相应的3D掩码；引入条件几何重建预训练策略和特征注入机制，以处理复杂场景几何和语义歧义。", "result": "在包含1800多个场景的大规模基准测试上，SeqSplatNet设立了新的最先进水平，有效将功能推理从单步交互推进到场景级的复杂顺序任务。", "conclusion": "SeqAffordSplat和SeqSplatNet为复杂3DGS环境中的长视野功能理解提供了新的研究方向和解决方案，显著提升了功能推理的能力和范围。"}}
{"id": "2507.23779", "title": "Phi-Ground Tech Report: Advancing Perception in GUI Grounding", "authors": ["Miaosen Zhang", "Ziqiang Xu", "Jialiang Zhu", "Qi Dai", "Kai Qiu", "Yifan Yang", "Chong Luo", "Tianyi Chen", "Justin Wagle", "Tim Franklin", "Baining Guo"], "abstract": "With the development of multimodal reasoning models, Computer Use Agents (CUAs), akin to Jarvis from \\textit{\"Iron Man\"}, are becoming a reality. GUI grounding is a core component for CUAs to execute actual actions, similar to mechanical control in robotics, and it directly leads to the success or failure of the system. It determines actions such as clicking and typing, as well as related parameters like the coordinates for clicks. Current end-to-end grounding models still achieve less than 65\\% accuracy on challenging benchmarks like ScreenSpot-pro and UI-Vision, indicating they are far from being ready for deployment. % , as a single misclick can result in unacceptable consequences. In this work, we conduct an empirical study on the training of grounding models, examining details from data collection to model training. Ultimately, we developed the \\textbf{Phi-Ground} model family, which achieves state-of-the-art performance across all five grounding benchmarks for models under $10B$ parameters in agent settings. In the end-to-end model setting, our model still achieves SOTA results with scores of \\textit{\\textbf{43.2}} on ScreenSpot-pro and \\textit{\\textbf{27.2}} on UI-Vision. We believe that the various details discussed in this paper, along with our successes and failures, not only clarify the construction of grounding models but also benefit other perception tasks. Project homepage: \\href{", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Multimedia (cs.MM)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.23779.pdf", "abstract_url": "https://arxiv.org/abs/2507.23779", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Multimedia (cs.MM)"], "matching_keywords": ["agent"], "AI": {"tldr": "Phi-Ground技术报告：提升GUI接地感知能力", "motivation": "随着多模态推理模型的发展，计算机使用代理（CUAs）的实现成为可能。GUI接地是CUAs执行实际动作的核心组件，类似于机器人中的机械控制，直接关系到系统的成败。当前端到端接地模型在ScreenSpot-pro和UI-Vision等具有挑战性的基准测试中准确率仍低于65%，远未达到部署标准。", "method": "本研究对接地模型的训练进行了实证研究，从数据收集到模型训练的细节进行了考察。最终开发了Phi-Ground模型家族，该模型在代理设置下，在所有五个接地基准测试中，对于参数小于100亿的模型，实现了最先进的性能。在端到端模型设置中，该模型在ScreenSpot-pro和UI-Vision上的得分分别为43.2和27.2，同样达到了SOTA结果。", "result": "Phi-Ground模型家族在五个接地基准测试中均实现了最先进的性能，特别是在代理设置下，对于参数小于100亿的模型表现尤为突出。在端到端模型设置中，ScreenSpot-pro和UI-Vision上的得分分别为43.2和27.2。", "conclusion": "本文讨论的各种细节，以及我们的成功和失败，不仅阐明了接地模型的构建，还对其他感知任务有益。Phi-Ground模型家族的开发为GUI接地感知领域带来了显著的进步。"}}
{"id": "2507.23588", "title": "DiffLoRA: Differential Low-Rank Adapters for Large Language Models", "authors": ["Alexandre Misrahi", "Nadezhda Chirkova", "Maxime Louis", "Vassilina Nikoulina"], "abstract": "Differential Transformer has recently been proposed to improve performance in Transformer models by canceling out noise through a denoiser attention mechanism. In this work, we introduce DiffLoRA, a parameter-efficient adaptation of the differential attention mechanism, with low-rank adapters on both positive and negative attention terms. This approach retains the efficiency of LoRA while aiming to benefit from the performance gains of differential attention. We evaluate DiffLoRA across a broad range of NLP tasks, including general benchmarks, many-shot in-context learning, RAG, and long-context tests. We observe that, although DiffLoRA falls short of other parameter-efficient fine-tuning methods in most evaluation tasks, it shows interesting results in certain domains (+11 pts on LoRA for HumanEval). We analyze the attention patterns post-finetuning to identify the reasons for this behavior.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.23588.pdf", "abstract_url": "https://arxiv.org/abs/2507.23588", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "DiffLoRA是一种参数高效的差分注意力机制适配器，通过在正负注意力项上使用低秩适配器，旨在结合LoRA的效率和差分注意力的性能提升。虽然在大多数评估任务中表现不如其他参数高效的微调方法，但在某些领域（如HumanEval）显示出有趣的结果。", "motivation": "解决Transformer模型中通过差分注意力机制提高性能的问题，同时保持参数效率。", "method": "引入DiffLoRA，一种在正负注意力项上使用低秩适配器的参数高效差分注意力机制适配方法。", "result": "在大多数NLP任务中表现不如其他参数高效微调方法，但在HumanEval上比LoRA提高了11分。", "conclusion": "DiffLoRA在特定领域显示出潜力，但需要进一步分析注意力模式以理解其行为原因。"}}
{"id": "2507.23334", "title": "MUST-RAG: MUSical Text Question Answering with Retrieval Augmented Generation", "authors": ["Daeyong Kwon", "SeungHeon Doh", "Juhan Nam"], "abstract": "Recent advancements in Large language models (LLMs) have demonstrated remarkable capabilities across diverse domains. While they exhibit strong zero-shot performance on various tasks, LLMs' effectiveness in music-related applications remains limited due to the relatively small proportion of music-specific knowledge in their training data. To address this limitation, we propose MusT-RAG, a comprehensive framework based on Retrieval Augmented Generation (RAG) to adapt general-purpose LLMs for text-only music question answering (MQA) tasks. RAG is a technique that provides external knowledge to LLMs by retrieving relevant context information when generating answers to questions. To optimize RAG for the music domain, we (1) propose MusWikiDB, a music-specialized vector database for the retrieval stage, and (2) utilizes context information during both inference and fine-tuning processes to effectively transform general-purpose LLMs into music-specific models. Our experiment demonstrates that MusT-RAG significantly outperforms traditional fine-tuning approaches in enhancing LLMs' music domain adaptation capabilities, showing consistent improvements across both in-domain and out-of-domain MQA benchmarks. Additionally, our MusWikiDB proves substantially more effective than general Wikipedia corpora, delivering superior performance and computational efficiency.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR); Machine Learning (cs.LG)", "comments": "8 pages, 2 figures", "pdf_url": "https://arxiv.org/pdf/2507.23334.pdf", "abstract_url": "https://arxiv.org/abs/2507.23334", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "MusT-RAG是一个基于检索增强生成（RAG）的框架，旨在通过引入音乐特定知识来增强大型语言模型（LLMs）在音乐问答（MQA）任务中的表现。", "motivation": "大型语言模型在音乐相关应用中的效果受限，因为其训练数据中音乐特定知识的比例较小。", "method": "提出了MusT-RAG框架，包括一个音乐专用的向量数据库MusWikiDB用于检索阶段，并在推理和微调过程中利用上下文信息，将通用LLMs转化为音乐特定模型。", "result": "实验表明，MusT-RAG在增强LLMs的音乐领域适应能力方面显著优于传统的微调方法，在领域内和领域外的MQA基准测试中均显示出持续的改进。", "conclusion": "MusT-RAG和MusWikiDB的结合不仅提高了性能，还提升了计算效率，为音乐领域的文本问答任务提供了一种有效的解决方案。"}}
{"id": "2507.23227", "title": "Enabling Few-Shot Alzheimer's Disease Diagnosis on Tabular Biomarker Data with LLMs", "authors": ["Sophie Kearney", "Shu Yang", "Zixuan Wen", "Bojian Hou", "Duy Duong-Tran", "Tianlong Chen", "Jason Moore", "Marylyn Ritchie", "Li Shen"], "abstract": "Early and accurate diagnosis of Alzheimer's disease (AD), a complex neurodegenerative disorder, requires analysis of heterogeneous biomarkers (e.g., neuroimaging, genetic risk factors, cognitive tests, and cerebrospinal fluid proteins) typically represented in a tabular format. With flexible few-shot reasoning, multimodal integration, and natural-language-based interpretability, large language models (LLMs) offer unprecedented opportunities for prediction with structured biomedical data. We propose a novel framework called TAP-GPT, Tabular Alzheimer's Prediction GPT, that adapts TableGPT2, a multimodal tabular-specialized LLM originally developed for business intelligence tasks, for AD diagnosis using structured biomarker data with small sample sizes. Our approach constructs few-shot tabular prompts using in-context learning examples from structured biomedical data and finetunes TableGPT2 using the parameter-efficient qLoRA adaption for a clinical binary classification task of AD or cognitively normal (CN). The TAP-GPT framework harnesses the powerful tabular understanding ability of TableGPT2 and the encoded prior knowledge of LLMs to outperform more advanced general-purpose LLMs and a tabular foundation model (TFM) developed for prediction tasks. To our knowledge, this is the first application of LLMs to the prediction task using tabular biomarker data, paving the way for future LLM-driven multi-agent frameworks in biomedical informatics.", "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG); Quantitative Methods (q-bio.QM)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.23227.pdf", "abstract_url": "https://arxiv.org/abs/2507.23227", "categories": ["Computation and Language (cs.CL)", "Machine Learning (cs.LG)", "Quantitative Methods (q-bio.QM)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为TAP-GPT的新框架，利用大型语言模型（LLMs）进行阿尔茨海默病（AD）的早期和准确诊断，特别是在小样本量的结构化生物标志物数据上。", "motivation": "阿尔茨海默病是一种复杂的神经退行性疾病，其早期和准确诊断需要分析多种异质性生物标志物，这些数据通常以表格形式呈现。", "method": "研究提出TAP-GPT框架，通过调整TableGPT2模型（一种最初为商业智能任务开发的多模态表格专用LLM），利用少量样本的结构化生物标志物数据进行AD诊断。方法包括构建少量样本的表格提示和使用参数高效的qLoRA适应进行微调。", "result": "TAP-GPT框架利用TableGPT2的强大表格理解能力和LLMs的编码先验知识，在AD或认知正常（CN）的临床二元分类任务中，表现优于更先进的通用LLMs和专为预测任务开发的表格基础模型（TFM）。", "conclusion": "这是LLMs首次应用于使用表格生物标志物数据的预测任务，为未来生物医学信息学中的LLM驱动多代理框架铺平了道路。"}}
{"id": "2507.22898", "title": "Voice-guided Orchestrated Intelligence for Clinical Evaluation (VOICE): A Voice AI Agent System for Prehospital Stroke Assessment", "authors": ["Julian Acosta", "Scott Adams", "Julius Kernbach", "Romain Hardy", "Sung Eun Kim", "Luyang Luo", "Xiaoman Zhang", "Shreya Johri", "Mohammed Baharoon", "Pranav Rajpurkar"], "abstract": "We developed a voice-driven artificial intelligence (AI) system that guides anyone - from paramedics to family members - through expert-level stroke evaluations using natural conversation, while also enabling smartphone video capture of key examination components for documentation and potential expert review. This addresses a critical gap in emergency care: current stroke recognition by first responders is inconsistent and often inaccurate, with sensitivity for stroke detection as low as 58%, causing life-threatening delays in treatment. Three non-medical volunteers used our AI system to assess ten simulated stroke patients, including cases with likely large vessel occlusion (LVO) strokes and stroke-like conditions, while we measured diagnostic accuracy, completion times, user confidence, and expert physician review of the AI-generated reports. The AI system correctly identified 84% of individual stroke signs and detected 75% of likely LVOs, completing evaluations in just over 6 minutes. Users reported high confidence (median 4.5/5) and ease of use (mean 4.67/5). The system successfully identified 86% of actual strokes but also incorrectly flagged 2 of 3 non-stroke cases as strokes. When an expert physician reviewed the AI reports with videos, they identified the correct diagnosis in 100% of cases, but felt confident enough to make preliminary treatment decisions in only 40% of cases due to observed AI errors including incorrect scoring and false information. While the current system's limitations necessitate human oversight, ongoing rapid advancements in speech-to-speech AI models suggest that future versions are poised to enable highly accurate assessments. Achieving human-level voice interaction could transform emergency medical care, putting expert-informed assessment capabilities in everyone's hands.", "subjects": "Human-Computer Interaction (cs.HC); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.22898.pdf", "abstract_url": "https://arxiv.org/abs/2507.22898", "categories": ["Human-Computer Interaction (cs.HC)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "开发了一个语音驱动的人工智能系统，用于通过自然对话指导非专业人员进行专家级中风评估，并记录关键检查视频供专家审查。", "motivation": "解决急救护理中中风识别不一致和不准确的问题，当前中风检测的敏感性低至58%，导致治疗延误。", "method": "使用语音AI系统，由三名非医疗志愿者对十名模拟中风患者进行评估，测量诊断准确性、完成时间、用户信心和专家审查AI生成的报告。", "result": "AI系统正确识别了84%的中风迹象和75%的可能大血管闭塞，评估时间约6分钟，用户信心高，但存在误报。专家审查后正确诊断率为100%，但仅40%情况下有信心做出初步治疗决定。", "conclusion": "当前系统需要人工监督，但随着语音到语音AI模型的快速进步，未来版本有望实现高精度评估，可能改变紧急医疗护理。"}}
{"id": "2507.22947", "title": "ELMES: An Automated Framework for Evaluating Large Language Models in Educational Scenarios", "authors": ["Shou'ang Wei", "Xinyun Wang", "Shuzhen Bi", "Jian Chen", "Ruijia Li", "Bo Jiang", "Xin Lin", "Min Zhang", "Yu Song", "BingDong Li", "Aimin Zhou", "Hao Hao"], "abstract": "The emergence of Large Language Models (LLMs) presents transformative opportunities for education, generating numerous novel application scenarios. However, significant challenges remain: evaluation metrics vary substantially across different educational scenarios, while many emerging scenarios lack appropriate assessment metrics. Current benchmarks predominantly measure general intelligence rather than pedagogical capabilities. To address this gap, we introduce ELMES, an open-source automated evaluation framework specifically designed for assessing LLMs in educational settings. ELMES features a modular architecture that enables researchers to create dynamic, multi-agent dialogues through simple configuration files, facilitating flexible scenario design without requiring extensive programming expertise. The framework incorporates a hybrid evaluation engine that objectively quantifies traditionally subjective pedagogical metrics using an LLM-as-a-Judge methodology. We conduct systematic benchmarking of state-of-the-art LLMs across four critical educational scenarios: Knowledge Point Explanation, Guided Problem-Solving Teaching, Interdisciplinary Lesson Plan Generation, and Contextualized Question Generation, employing fine-grained metrics developed in collaboration with education specialists. Our results demonstrate distinct capability distributions among models, revealing context-specific strengths and limitations. ELMES provides educators and researchers with an accessible evaluation framework that significantly reduces adaptation barriers for diverse educational applications while advancing the practical implementation of LLMs in pedagogy. The framework is publicly available at \\emph{", "subjects": "Computers and Society (cs.CY); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.22947.pdf", "abstract_url": "https://arxiv.org/abs/2507.22947", "categories": ["Computers and Society (cs.CY)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "ELMES是一个开源的自动化评估框架，专门设计用于评估教育场景中的大型语言模型（LLMs）。它通过模块化架构和混合评估引擎，支持多代理对话和客观量化教学指标，旨在解决教育场景中评估标准不一和缺乏适当评估指标的问题。", "motivation": "大型语言模型（LLMs）在教育领域的应用潜力巨大，但面临评估标准不统一和缺乏适当评估指标的挑战。现有基准主要衡量一般智能而非教学能力。", "method": "ELMES框架采用模块化架构，允许研究人员通过简单配置文件创建动态多代理对话，无需深入编程知识。它结合了LLM-as-a-Judge方法，客观量化传统上主观的教学指标。", "result": "在四个关键教育场景中系统评估了最先进的LLMs，结果显示模型在不同情境下的能力分布各异，揭示了特定的优势和局限。", "conclusion": "ELMES为教育工作者和研究人员提供了一个易于使用的评估框架，显著降低了多样化教育应用的适应障碍，推动了LLMs在教学实践中的实际应用。"}}
{"id": "2507.23088", "title": "Beyond Rigid AI: Towards Natural Human-Machine Symbiosis for Interoperative Surgical Assistance", "authors": ["Lalithkumar Seenivasan", "Jiru Xu", "Roger D. Soberanis Mukul", "Hao Ding", "Grayson Byrd", "Yu-Chun Ku", "Jose L. Porras", "Masaru Ishii", "Mathias Unberath"], "abstract": "Emerging surgical data science and robotics solutions, especially those designed to provide assistance in situ, require natural human-machine interfaces to fully unlock their potential in providing adaptive and intuitive aid. Contemporary AI-driven solutions remain inherently rigid, offering limited flexibility and restricting natural human-machine interaction in dynamic surgical environments. These solutions rely heavily on extensive task-specific pre-training, fixed object categories, and explicit manual-prompting. This work introduces a novel Perception Agent that leverages speech-integrated prompt-engineered large language models (LLMs), segment anything model (SAM), and any-point tracking foundation models to enable a more natural human-machine interaction in real-time intraoperative surgical assistance. Incorporating a memory repository and two novel mechanisms for segmenting unseen elements, Perception Agent offers the flexibility to segment both known and unseen elements in the surgical scene through intuitive interaction. Incorporating the ability to memorize novel elements for use in future surgeries, this work takes a marked step towards human-machine symbiosis in surgical procedures. Through quantitative analysis on a public dataset, we show that the performance of our agent is on par with considerably more labor-intensive manual-prompting strategies. Qualitatively, we show the flexibility of our agent in segmenting novel elements (instruments, phantom grafts, and gauze) in a custom-curated dataset. By offering natural human-machine interaction and overcoming rigidity, our Perception Agent potentially brings AI-based real-time assistance in dynamic surgical environments closer to reality.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.23088.pdf", "abstract_url": "https://arxiv.org/abs/2507.23088", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一种新型的感知代理，利用语音集成的提示工程大型语言模型（LLMs）、分割任何模型（SAM）和任意点跟踪基础模型，以实现更自然的人机交互，用于实时术中手术辅助。", "motivation": "解决当前AI驱动的手术辅助解决方案在动态手术环境中固有的刚性，限制自然人机交互的问题。", "method": "开发了一个感知代理，结合了记忆库和两种新机制，用于分割手术场景中的已知和未见元素，通过直观交互实现。", "result": "定量分析显示，该代理的性能与更劳动密集的手动提示策略相当；定性分析展示了其在分割新元素（器械、幻影移植物和纱布）方面的灵活性。", "conclusion": "通过提供自然的人机交互并克服刚性，感知代理使基于AI的动态手术环境中的实时辅助更接近现实。"}}
{"id": "2507.23361", "title": "SWE-Exp: Experience-Driven Software Issue Resolution", "authors": ["Silin Chen", "Shaoxin Lin", "Xiaodong Gu", "Yuling Shi", "Heng Lian", "Longfei Yun", "Dong Chen", "Weiguo Sun", "Lin Cao", "Qianxiang Wang"], "abstract": "Recent advances in large language model (LLM) agents have shown remarkable progress in software issue resolution, leveraging advanced techniques such as multi-agent collaboration and Monte Carlo Tree Search (MCTS). However, current agents act as memoryless explorers - treating each problem separately without retaining or reusing knowledge from previous repair experiences. This leads to redundant exploration of failed trajectories and missed chances to adapt successful issue resolution methods to similar problems. To address this problem, we introduce SWE-Exp, an experience - enhanced approach that distills concise and actionable experience from prior agent trajectories, enabling continuous learning across issues. Our method introduces a multi-faceted experience bank that captures both successful and failed repair attempts. Specifically, it extracts reusable issue resolution knowledge at different levels - from high-level problem comprehension to specific code changes. Experiments show that SWE-Exp achieves state-of-the-art resolution rate (41.6% Pass@1) on SWE-bench-Verified under open-source agent frameworks. Our approach establishes a new paradigm in which automated software engineering agents systematically accumulate and leverage repair expertise, fundamentally shifting from trial-and-error exploration to strategic, experience-driven issue resolution.", "subjects": "Software Engineering (cs.SE); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2507.23361.pdf", "abstract_url": "https://arxiv.org/abs/2507.23361", "categories": ["Software Engineering (cs.SE)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "SWE-Exp是一种经验增强的方法，通过从先前的代理轨迹中提炼简洁且可操作的经验，实现跨问题的持续学习，提高了软件问题解决率。", "motivation": "解决当前大型语言模型代理在软件问题解决中作为无记忆探索者，无法保留或重用先前修复经验的问题。", "method": "引入一个多方面的经验库，捕捉成功和失败的修复尝试，提取不同层次的可重用问题解决知识。", "result": "SWE-Exp在SWE-bench-Verified上实现了最先进的解决率（41.6% Pass@1）。", "conclusion": "SWE-Exp建立了一个新范式，使自动化软件工程代理能够系统地积累和利用修复专业知识，从根本上从试错探索转变为战略性的、经验驱动的问题解决。"}}
{"id": "2507.23674", "title": "TweakLLM: A Routing Architecture for Dynamic Tailoring of Cached Responses", "authors": ["Muhammad Taha Cheema", "Abeer Aamir", "Khawaja Gul Muhammad", "Naveed Anwar Bhatti", "Ihsan Ayyub Qazi", "Zafar Ayyub Qazi"], "abstract": "Large Language Models (LLMs) process millions of queries daily, making efficient response caching a compelling optimization for reducing cost and latency. However, preserving relevance to user queries using this approach proves difficult due to the personalized nature of chatbot interactions and the limited accuracy of semantic similarity search. To address this, we present TweakLLM, a novel routing architecture that employs a lightweight LLM to dynamically adapt cached responses to incoming prompts. Through comprehensive evaluation, including user studies with side-by-side comparisons, satisfaction voting, as well as multi-agent LLM debates, we demonstrate that TweakLLM maintains response quality comparable to frontier models while significantly improving cache effectiveness. Our results across real-world datasets highlight TweakLLM as a scalable, resource-efficient caching solution for high-volume LLM deployments without compromising user experience.", "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL)", "comments": "13 pages, 9 figures", "pdf_url": "https://arxiv.org/pdf/2507.23674.pdf", "abstract_url": "https://arxiv.org/abs/2507.23674", "categories": ["Machine Learning (cs.LG)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "TweakLLM是一种新颖的路由架构，旨在通过轻量级LLM动态调整缓存响应以适应传入提示，以提高缓存效率而不损害用户体验。", "motivation": "解决在使用大型语言模型（LLMs）处理大量查询时，通过缓存优化成本和延迟的同时，保持对用户查询的个性化响应相关性的挑战。", "method": "采用轻量级LLM动态调整缓存响应，以适应传入的提示，通过用户研究、满意度投票和多代理LLM辩论进行综合评估。", "result": "TweakLLM在保持与前沿模型相当的响应质量的同时，显著提高了缓存效率。", "conclusion": "TweakLLM为高容量LLM部署提供了一个可扩展、资源高效的缓存解决方案，且不损害用户体验。"}}
{"id": "2507.23348", "title": "SWE-Debate: Competitive Multi-Agent Debate for Software Issue Resolution", "authors": ["Han Li", "Yuling Shi", "Shaoxin Lin", "Xiaodong Gu", "Heng Lian", "Xin Wang", "Yantao Jia", "Tao Huang", "Qianxiang Wang"], "abstract": "Issue resolution has made remarkable progress thanks to the advanced reasoning capabilities of large language models (LLMs). Recently, agent-based frameworks such as SWE-agent have further advanced this progress by enabling autonomous, tool-using agents to tackle complex software engineering tasks. While existing agent-based issue resolution approaches are primarily based on agents' independent explorations, they often get stuck in local solutions and fail to identify issue patterns that span across different parts of the codebase. To address this limitation, we propose SWE-Debate, a competitive multi-agent debate framework that encourages diverse reasoning paths and achieves more consolidated issue localization. SWE-Debate first creates multiple fault propagation traces as localization proposals by traversing a code dependency graph. Then, it organizes a three-round debate among specialized agents, each embodying distinct reasoning perspectives along the fault propagation trace. This structured competition enables agents to collaboratively converge on a consolidated fix plan. Finally, this consolidated fix plan is integrated into an MCTS-based code modification agent for patch generation. Experiments on the SWE-bench benchmark show that SWE-Debate achieves new state-of-the-art results in open-source agent frameworks and outperforms baselines by a large margin.", "subjects": "Software Engineering (cs.SE); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2507.23348.pdf", "abstract_url": "https://arxiv.org/abs/2507.23348", "categories": ["Software Engineering (cs.SE)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "SWE-Debate是一个竞争性多代理辩论框架，旨在通过多样化的推理路径和更集中的问题定位来解决软件问题。它通过创建多个故障传播轨迹作为定位提案，并组织三轮辩论，最终整合出一个统一的修复计划，用于补丁生成。", "motivation": "现有的基于代理的问题解决方法主要基于代理的独立探索，这往往导致局部解决方案，无法识别跨代码库的问题模式。", "method": "SWE-Debate首先通过遍历代码依赖图创建多个故障传播轨迹作为定位提案，然后组织三轮辩论，每个代理代表不同的推理视角，最后整合出一个统一的修复计划，用于MCTS基础的代码修改代理生成补丁。", "result": "在SWE-bench基准测试中，SWE-Debate在开源代理框架中取得了新的最先进结果，并大幅优于基线。", "conclusion": "SWE-Debate通过竞争性多代理辩论框架，实现了更集中的问题定位和更有效的补丁生成，为软件问题解决提供了新的方法。"}}
{"id": "2507.23370", "title": "Trae Agent: An LLM-based Agent for Software Engineering with Test-time Scaling", "authors": ["Trae Research Team", "Pengfei Gao", "Zhao Tian", "Xiangxin Meng", "Xinchen Wang", "Ruida Hu", "Yuanan Xiao", "Yizhou Liu", "Zhao Zhang", "Junjie Chen", "Cuiyun Gao", "Yun Lin", "Yingfei Xiong", "Chao Peng", "Xia Liu"], "abstract": "Software issue resolution is a critical challenge in software engineering and has garnered increasing attention in recent years. With the rapid advancement of large language models (LLMs), substantial progress has been made in addressing real-world software engineering tasks. Recent studies have introduced ensemble reasoning techniques to enhance the performance of LLM-based issue resolution. However, existing prompting-based methods still face limitations in effectively exploring large ensemble spaces and lack the capacity for repository-level understanding, both of which constrain their overall effectiveness. In this paper, we propose Trae Agent, the first agent-based ensemble reasoning approach for repository-level issue resolution. Trae Agent formulates our goal as an optimal solution search problem and addresses two key challenges, i.e., large ensemble spaces and repository-level understanding, through modular agents for generation, pruning, and selection. We conduct extensive experiments using three leading LLMs on the widely-adopted SWE-bench benchmark, comparing Trae Agent against four state-of-the-art ensemble reasoning techniques. Experimental results demonstrate that Trae Agent consistently achieves superior performance, with an average improvement of 10.22% over all baselines in terms of Pass@1. Trae Agent has achieved first place on the SWE-bench Verified leaderboard, with a notable Pass@1 score of 75.20%. We are pleased to release Trae Agent as an open-source project to support the research community, with all resources available at", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": "Pengfei Gao and Zhao Tian contributed equally to this technical report", "pdf_url": "https://arxiv.org/pdf/2507.23370.pdf", "abstract_url": "https://arxiv.org/abs/2507.23370", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "Trae Agent是一种基于大型语言模型（LLM）的代理，用于软件工程中的问题解决，通过测试时扩展技术提高性能。", "motivation": "解决软件工程中问题解决的挑战，特别是在探索大型集成空间和缺乏仓库级理解方面的限制。", "method": "提出了一种基于代理的集成推理方法，通过生成、修剪和选择的模块化代理来应对挑战。", "result": "在SWE-bench基准测试中，Trae Agent平均比所有基线方法提高了10.22%的Pass@1性能，达到了75.20%的显著成绩。", "conclusion": "Trae Agent作为一种开源项目发布，支持研究社区，展示了在软件工程问题解决中的卓越性能和潜力。"}}
{"id": "2507.23261", "title": "DynaSwarm: Dynamically Graph Structure Selection for LLM-based Multi-agent System", "authors": ["Hui Yi Leong", "Yuqing Wu"], "abstract": "Current multi-agent systems (MAS) frameworks often rely on manually designed and static collaboration graph structures, limiting adaptability and performance. To address these limitations, we propose DynaSwarm, a dynamic framework that enhances LLM-based MAS through two key innovations: (1) an actor-critic reinforcement learning (A2C) mechanism to optimize graph structures with improved stability over prior RL methods, and (2) a dynamic graph selector that adaptively chooses the optimal graph structure for each input sample via parameter-efficient LLM fine-tuning. DynaSwarm eliminates the need for rigid, one-fits-all graph architectures, instead leveraging sample-specific idiosyncrasies to dynamically route queries through specialized agent networks. (c) We propose to fine-tune the demonstration retriever to fully exploit the power of in-context learning (ICL). Extensive experiments on question answering, mathematical reasoning, and coding tasks demonstrate that DynaSwarm consistently outperforms state-of-the-art single-agent and MAS baselines across multiple LLM backbones. Our findings highlight the importance of sample-aware structural flexibility in LLM MAS designs.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.23261.pdf", "abstract_url": "https://arxiv.org/abs/2507.23261", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "DynaSwarm是一个动态框架，通过A2C强化学习机制和动态图选择器优化LLM-based多智能体系统的图结构，提高适应性和性能。", "motivation": "解决当前多智能体系统框架依赖手动设计和静态协作图结构，限制适应性和性能的问题。", "method": "采用actor-critic强化学习(A2C)机制优化图结构，并通过动态图选择器为每个输入样本自适应选择最优图结构。", "result": "在问答、数学推理和编码任务上的广泛实验表明，DynaSwarm在多个LLM骨架上 consistently outperforms 最先进的单智能体和多智能体基线。", "conclusion": "研究强调了在LLM多智能体系统设计中样本感知结构灵活性的重要性。"}}
{"id": "2507.23217", "title": "Zero-Shot Document Understanding using Pseudo Table of Contents-Guided Retrieval-Augmented Generation", "authors": ["Hyeon Seong Jeong", "Sangwoo Jo", "Byeong Hyun Yoon", "Yoonseok Heo", "Haedong Jeong", "Taehoon Kim"], "abstract": "Understanding complex multimodal documents remains challenging due to their structural inconsistencies and limited training data availability. We introduce \\textit{DocsRay}, a training-free document understanding system that integrates pseudo Table of Contents (TOC) generation with hierarchical Retrieval-Augmented Generation (RAG). Our approach leverages multimodal Large Language Models' (LLMs) native capabilities to seamlessly process documents containing diverse elements such as text, images, charts, and tables without requiring specialized models or additional training. DocsRay's framework synergistically combines three key techniques: (1) a semantic structuring module using prompt-based LLM interactions to generate a hierarchical pseudo-TOC, (2) zero-shot multimodal analysis that converts diverse document elements into unified, text-centric representations using the inherent capabilities of multimodal LLMs, and (3) an efficient two-stage hierarchical retrieval system that reduces retrieval complexity from $O(N)$ to $O(S + k_1 \\cdot N_s)$. Evaluated on documents averaging 49.4 pages and 20,971 textual tokens, DocsRay reduced query latency from 3.89 to 2.12 seconds, achieving a 45% efficiency improvement. On the MMLongBench-Doc benchmark, DocsRay-Pro attains an accuracy of 64.7%, substantially surpassing previous state-of-the-art results.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.23217.pdf", "abstract_url": "https://arxiv.org/abs/2507.23217", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "DocsRay是一种无需训练的文档理解系统，通过伪目录生成和分层检索增强生成技术，利用多模态大型语言模型处理复杂多模态文档，显著提高了效率和准确性。", "motivation": "解决复杂多模态文档因结构不一致和训练数据有限而难以理解的问题。", "method": "结合伪目录生成、零样本多模态分析和高效的两阶段分层检索系统，利用多模态大型语言模型的原生能力处理文档。", "result": "在平均49.4页和20,971个文本标记的文档上，查询延迟从3.89秒减少到2.12秒，效率提高了45%。在MMLongBench-Doc基准测试中，DocsRay-Pro的准确率达到64.7%，显著超越先前的最先进结果。", "conclusion": "DocsRay通过创新的方法显著提升了文档理解的效率和准确性，为处理复杂多模态文档提供了有效的解决方案。"}}
{"id": "2507.23735", "title": "Distributed AI Agents for Cognitive Underwater Robot Autonomy", "authors": ["Markus Buchholz", "Ignacio Carlucho", "Michele Grimaldi", "Yvan R. Petillot"], "abstract": "Achieving robust cognitive autonomy in robots navigating complex, unpredictable environments remains a fundamental challenge in robotics. This paper presents Underwater Robot Self-Organizing Autonomy (UROSA), a groundbreaking architecture leveraging distributed Large Language Model AI agents integrated within the Robot Operating System 2 (ROS 2) framework to enable advanced cognitive capabilities in Autonomous Underwater Vehicles. UROSA decentralises cognition into specialised AI agents responsible for multimodal perception, adaptive reasoning, dynamic mission planning, and real-time decision-making. Central innovations include flexible agents dynamically adapting their roles, retrieval-augmented generation utilising vector databases for efficient knowledge management, reinforcement learning-driven behavioural optimisation, and autonomous on-the-fly ROS 2 node generation for runtime functional extensibility. Extensive empirical validation demonstrates UROSA's promising adaptability and reliability through realistic underwater missions in simulation and real-world deployments, showing significant advantages over traditional rule-based architectures in handling unforeseen scenarios, environmental uncertainties, and novel mission objectives. This work not only advances underwater autonomy but also establishes a scalable, safe, and versatile cognitive robotics framework capable of generalising to a diverse array of real-world applications.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.23735.pdf", "abstract_url": "https://arxiv.org/abs/2507.23735", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了水下机器人自组织自主性（UROSA）架构，利用分布式大型语言模型AI代理在ROS 2框架内实现自主水下车辆的高级认知能力。", "motivation": "解决机器人在复杂、不可预测环境中实现稳健认知自主性的基本挑战。", "method": "采用分布式大型语言模型AI代理，分散认知到专门负责多模态感知、自适应推理、动态任务规划和实时决策的AI代理中。", "result": "实证验证显示UROSA在模拟和实际水下任务中展现出良好的适应性和可靠性，优于传统基于规则的架构。", "conclusion": "UROSA不仅推进了水下自主性，还建立了一个可扩展、安全且多功能的认知机器人框架，能够泛化到多样化的实际应用中。"}}
{"id": "2507.23694", "title": "A survey of multi-agent geosimulation methodologies: from ABM to LLM", "authors": ["Virginia Padilla", "Jacinto Dávila"], "abstract": "We provide a comprehensive examination of agent-based approaches that codify the principles and linkages underlying multi-agent systems, simulations, and information systems. Based on two decades of study, this paper confirms a framework intended as a formal specification for geosimulation platforms. Our findings show that large language models (LLMs) can be effectively incorporated as agent components if they follow a structured architecture specific to fundamental agent activities such as perception, memory, planning, and action. This integration is precisely consistent with the architecture that we formalize, providing a solid platform for next-generation geosimulation systems.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": "20 pages, 1 table", "pdf_url": "https://arxiv.org/pdf/2507.23694.pdf", "abstract_url": "https://arxiv.org/abs/2507.23694", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文全面考察了基于代理的方法，这些方法编码了多代理系统、模拟和信息系统的原理和联系。基于二十年的研究，本文确认了一个旨在作为地理模拟平台正式规范的框架。我们的研究结果表明，如果大型语言模型（LLMs）遵循与基本代理活动（如感知、记忆、规划和行动）相关的结构化架构，它们可以有效地作为代理组件被纳入。这种整合与我们形式化的架构完全一致，为下一代地理模拟系统提供了一个坚实的平台。", "motivation": "解决如何将大型语言模型（LLMs）有效地整合到多代理地理模拟系统中的问题", "method": "基于二十年的研究，确认并形式化了一个用于地理模拟平台的框架", "result": "大型语言模型（LLMs）可以作为代理组件被有效地纳入地理模拟系统，前提是它们遵循与基本代理活动相关的结构化架构", "conclusion": "通过形式化的架构，为整合大型语言模型（LLMs）到地理模拟系统提供了一个坚实的平台，推动了下一代地理模拟系统的发展"}}
{"id": "2507.23698", "title": "Scalable Multi-Task Reinforcement Learning for Generalizable Spatial Intelligence in Visuomotor Agents", "authors": ["Shaofei Cai", "Zhancun Mu", "Haiwen Xia", "Bowei Zhang", "Anji Liu", "Yitao Liang"], "abstract": "While Reinforcement Learning (RL) has achieved remarkable success in language modeling, its triumph hasn't yet fully translated to visuomotor agents. A primary challenge in RL models is their tendency to overfit specific tasks or environments, thereby hindering the acquisition of generalizable behaviors across diverse settings. This paper provides a preliminary answer to this challenge by demonstrating that RL-finetuned visuomotor agents in Minecraft can achieve zero-shot generalization to unseen worlds. Specifically, we explore RL's potential to enhance generalizable spatial reasoning and interaction capabilities in 3D worlds. To address challenges in multi-task RL representation, we analyze and establish cross-view goal specification as a unified multi-task goal space for visuomotor policies. Furthermore, to overcome the significant bottleneck of manual task design, we propose automated task synthesis within the highly customizable Minecraft environment for large-scale multi-task RL training, and we construct an efficient distributed RL framework to support this. Experimental results show RL significantly boosts interaction success rates by $4\\times$ and enables zero-shot generalization of spatial reasoning across diverse environments, including real-world settings. Our findings underscore the immense potential of RL training in 3D simulated environments, especially those amenable to large-scale task generation, for significantly advancing visuomotor agents' spatial reasoning.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2507.23698.pdf", "abstract_url": "https://arxiv.org/abs/2507.23698", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了如何通过强化学习（RL）在Minecraft中微调的视觉运动代理实现对新世界的零样本泛化，提升3D世界中可泛化的空间推理和交互能力。", "motivation": "强化学习在语言建模方面取得了显著成功，但在视觉运动代理中的应用尚未完全实现。主要挑战是RL模型容易对特定任务或环境过拟合，阻碍了在不同设置下获得可泛化行为。", "method": "通过分析并建立跨视图目标规范作为视觉运动策略的统一多任务目标空间，解决了多任务RL表示中的挑战。为了克服手动任务设计的重大瓶颈，提出了在高度可定制的Minecraft环境中进行自动化任务合成以支持大规模多任务RL训练，并构建了一个高效的分布式RL框架。", "result": "实验结果显示，RL显著提高了交互成功率4倍，并实现了包括真实世界设置在内的多样化环境中空间推理的零样本泛化。", "conclusion": "我们的发现强调了在3D模拟环境中，尤其是那些适合大规模任务生成的环境中进行RL训练的巨大潜力，可以显著推进视觉运动代理的空间推理能力。"}}
