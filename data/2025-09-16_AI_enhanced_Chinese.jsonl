{"id": "2509.10761", "title": "EditDuet: A Multi-Agent System for Video Non-Linear Editing", "authors": ["Marcelo Sandoval-Castaneda", "Bryan Russell", "Josef Sivic", "Gregory Shakhnarovich", "Fabian Caba Heilbron"], "abstract": "Automated tools for video editing and assembly have applications ranging from filmmaking and advertisement to content creation for social media. Previous video editing work has mainly focused on either retrieval or user interfaces, leaving actual editing to the user. In contrast, we propose to automate the core task of video editing, formulating it as sequential decision making process. Ours is a multi-agent approach. We design an Editor agent and a Critic agent. The Editor takes as input a collection of video clips together with natural language instructions and uses tools commonly found in video editing software to produce an edited sequence. On the other hand, the Critic gives natural language feedback to the editor based on the produced sequence or renders it if it is satisfactory. We introduce a learning-based approach for enabling effective communication across specialized agents to address the language-driven video editing task. Finally, we explore an LLM-as-a-judge metric for evaluating the quality of video editing system and compare it with general human preference. We evaluate our system's output video sequences qualitatively and quantitatively through a user study and find that our system vastly outperforms existing approaches in terms of coverage, time constraint satisfaction, and human preference.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "SIGGRAPH 2025", "pdf_url": "https://arxiv.org/pdf/2509.10761.pdf", "abstract_url": "https://arxiv.org/abs/2509.10761", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "EditDuet是一个多代理系统，用于自动化视频非线性编辑，通过编辑和批评代理基于自然语言指令协作，显著优于现有方法。", "motivation": "解决视频编辑自动化不足的问题，现有工作主要关注检索或用户界面，而非核心编辑任务。", "method": "采用多代理方法，包括编辑代理使用工具处理视频剪辑和指令，批评代理提供反馈或渲染，基于学习实现代理间通信。", "result": "系统在用户研究中表现出色，在覆盖率、时间约束满足和人类偏好方面大幅超越现有方法。", "conclusion": "EditDuet成功自动化视频编辑，引入LLM作为评估指标，具有广泛的应用潜力。"}}
{"id": "2509.10748", "title": "SCOPE: Speech-guided COllaborative PErception Framework for Surgical Scene Segmentation", "authors": ["Jecia Z.Y. Mao", "Francis X Creighton", "Russell H Taylor", "Manish Sahu"], "abstract": "Accurate segmentation and tracking of relevant elements of the surgical scene is crucial to enable context-aware intraoperative assistance and decision making. Current solutions remain tethered to domain-specific, supervised models that rely on labeled data and required domain-specific data to adapt to new surgical scenarios and beyond predefined label categories. Recent advances in prompt-driven vision foundation models (VFM) have enabled open-set, zero-shot segmentation across heterogeneous medical images. However, dependence of these models on manual visual or textual cues restricts their deployment in introperative surgical settings. We introduce a speech-guided collaborative perception (SCOPE) framework that integrates reasoning capabilities of large language model (LLM) with perception capabilities of open-set VFMs to support on-the-fly segmentation, labeling and tracking of surgical instruments and anatomy in intraoperative video streams. A key component of this framework is a collaborative perception agent, which generates top candidates of VFM-generated segmentation and incorporates intuitive speech feedback from clinicians to guide the segmentation of surgical instruments in a natural human-machine collaboration paradigm. Afterwards, instruments themselves serve as interactive pointers to label additional elements of the surgical scene. We evaluated our proposed framework on a subset of publicly available Cataract1k dataset and an in-house ex-vivo skull-base dataset to demonstrate its potential to generate on-the-fly segmentation and tracking of surgical scene. Furthermore, we demonstrate its dynamic capabilities through a live mock ex-vivo experiment. This human-AI collaboration paradigm showcase the potential of developing adaptable, hands-free, surgeon-centric tools for dynamic operating-room environments.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.10748.pdf", "abstract_url": "https://arxiv.org/abs/2509.10748", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "SCOPE框架通过整合大型语言模型和视觉基础模型，利用语音反馈实现手术场景的实时分割和跟踪，提高手术辅助的适应性和效率。", "motivation": "解决现有手术场景分割方法依赖标注数据和手动提示，难以适应新场景和实时操作的问题。", "method": "结合LLM的推理能力和VFMs的感知能力，通过语音反馈引导分割，并利用分割结果作为指针标记其他元素。", "result": "在Cataract1k和内部数据集上验证了实时分割和跟踪能力，并通过模拟实验展示了动态性能。", "conclusion": "SCOPE框架展示了开发可适应、免提、以外科医生为中心的工具的潜力，适用于动态手术环境。"}}
{"id": "2509.10767", "title": "Enhancement Without Contrast: Stability-Aware Multicenter Machine Learning for Glioma MRI Imaging", "authors": ["Sajad Amiri", "Shahram Taeb", "Sara Gharibi", "Setareh Dehghanfard", "Somayeh Sadat Mehrnia", "Mehrdad Oveisi", "Ilker Hacihaliloglu", "Arman Rahmim", "Mohammad R. Salmanpour"], "abstract": "Gadolinium-based contrast agents (GBCAs) are central to glioma imaging but raise safety, cost, and accessibility concerns. Predicting contrast enhancement from non-contrast MRI using machine learning (ML) offers a safer alternative, as enhancement reflects tumor aggressiveness and informs treatment planning. Yet scanner and cohort variability hinder robust model selection. We propose a stability-aware framework to identify reproducible ML pipelines for multicenter prediction of glioma MRI contrast enhancement. We analyzed 1,446 glioma cases from four TCIA datasets (UCSF-PDGM, UPENN-GB, BRATS-Africa, BRATS-TCGA-LGG). Non-contrast T1WI served as input, with enhancement derived from paired post-contrast T1WI. Using PyRadiomics under IBSI standards, 108 features were extracted and combined with 48 dimensionality reduction methods and 25 classifiers, yielding 1,200 pipelines. Rotational validation was trained on three datasets and tested on the fourth. Cross-validation prediction accuracies ranged from 0.91 to 0.96, with external testing achieving 0.87 (UCSF-PDGM), 0.98 (UPENN-GB), and 0.95 (BRATS-Africa), with an average of 0.93. F1, precision, and recall were stable (0.87 to 0.96), while ROC-AUC varied more widely (0.50 to 0.82), reflecting cohort heterogeneity. The MI linked with ETr pipeline consistently ranked highest, balancing accuracy and stability. This framework demonstrates that stability-aware model selection enables reliable prediction of contrast enhancement from non-contrast glioma MRI, reducing reliance on GBCAs and improving generalizability across centers. It provides a scalable template for reproducible ML in neuro-oncology and beyond.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "14 Pages, 1 Figure, and 6 Tables", "pdf_url": "https://arxiv.org/pdf/2509.10767.pdf", "abstract_url": "https://arxiv.org/abs/2509.10767", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "提出稳定性感知框架，通过机器学习从非对比MRI预测胶质瘤对比增强，减少对钆基对比剂的依赖，提高多中心泛化性。", "motivation": "解决钆基对比剂在胶质瘤成像中的安全、成本和可及性问题，预测增强以替代对比剂使用。", "method": "使用多中心数据集，提取影像特征，结合降维和分类器构建1200个管道，通过旋转验证评估稳定性和准确性。", "result": "交叉验证准确率0.91-0.96，外部测试平均0.93，F1等指标稳定，MI-ETr管道表现最佳。", "conclusion": "框架可实现可靠预测，减少对比剂使用，提升神经肿瘤学中机器学习的可重复性和泛化能力。"}}
{"id": "2509.10704", "title": "Maestro: Self-Improving Text-to-Image Generation via Agent Orchestration", "authors": ["Xingchen Wan", "Han Zhou", "Ruoxi Sun", "Hootan Nakhost", "Ke Jiang", "Rajarishi Sinha", "Sercan Ö. Arık"], "abstract": "Text-to-image (T2I) models, while offering immense creative potential, are highly reliant on human intervention, posing significant usability challenges that often necessitate manual, iterative prompt engineering over often underspecified prompts. This paper introduces Maestro, a novel self-evolving image generation system that enables T2I models to autonomously self-improve generated images through iterative evolution of prompts, using only an initial prompt. Maestro incorporates two key innovations: 1) self-critique, where specialized multimodal LLM (MLLM) agents act as 'critics' to identify weaknesses in generated images, correct for under-specification, and provide interpretable edit signals, which are then integrated by a 'verifier' agent while preserving user intent; and 2) self-evolution, utilizing MLLM-as-a-judge for head-to-head comparisons between iteratively generated images, eschewing problematic images, and evolving creative prompt candidates that align with user intents. Extensive experiments on complex T2I tasks using black-box models demonstrate that Maestro significantly improves image quality over initial prompts and state-of-the-art automated methods, with effectiveness scaling with more advanced MLLM components. This work presents a robust, interpretable, and effective pathway towards self-improving T2I generation.", "subjects": "Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "comments": "15 pages, 7 figures, 2 tables (22 pages, 9 figures and 3 tables including references and appendices)", "pdf_url": "https://arxiv.org/pdf/2509.10704.pdf", "abstract_url": "https://arxiv.org/abs/2509.10704", "categories": ["Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "Maestro 是一个自演进的文本到图像生成系统，通过代理编排实现自主改进，无需人工干预，显著提升图像质量。", "motivation": "解决文本到图像模型依赖人工干预和迭代提示工程的问题，提高可用性。", "method": "使用多模态大语言模型代理进行自我批评和自我进化，包括批评者识别弱点、验证者整合编辑信号，以及通过头对头比较进化提示。", "result": "在复杂任务中，Maestro 显著优于初始提示和最先进的自动化方法，效果随更先进的 MLLM 组件而扩展。", "conclusion": "提供了一条稳健、可解释且有效的路径，实现自改进的文本到图像生成。"}}
{"id": "2509.10769", "title": "AgentArch: A Comprehensive Benchmark to Evaluate Agent Architectures in Enterprise", "authors": ["Tara Bogavelli", "Roshnee Sharma", "Hari Subramani"], "abstract": "While individual components of agentic architectures have been studied in isolation, there remains limited empirical understanding of how different design dimensions interact within complex multi-agent systems. This study aims to address these gaps by providing a comprehensive enterprise-specific benchmark evaluating 18 distinct agentic configurations across state-of-the-art large language models. We examine four critical agentic system dimensions: orchestration strategy, agent prompt implementation (ReAct versus function calling), memory architecture, and thinking tool integration. Our benchmark reveals significant model-specific architectural preferences that challenge the prevalent one-size-fits-all paradigm in agentic AI systems. It also reveals significant weaknesses in overall agentic performance on enterprise tasks with the highest scoring models achieving a maximum of only 35.3\\% success on the more complex task and 70.8\\% on the simpler task. We hope these findings inform the design of future agentic systems by enabling more empirically backed decisions regarding architectural components and model selection.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.10769.pdf", "abstract_url": "https://arxiv.org/abs/2509.10769", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "该研究提供了一个企业专用的综合基准测试，评估了18种不同代理配置在大型语言模型中的表现，揭示了模型特定的架构偏好和整体性能弱点。", "motivation": "解决多代理系统中不同设计维度如何交互的实证理解不足的问题，特别是在企业环境中。", "method": "使用综合基准测试，评估18种代理配置，涵盖编排策略、代理提示实现、内存架构和思维工具集成四个维度。", "result": "发现模型特定的架构偏好，挑战了一刀切的范式；最高得分模型在复杂任务上成功率仅为35.3%，简单任务上为70.8%。", "conclusion": "研究结果可为未来代理系统设计提供实证支持，帮助优化架构组件和模型选择。"}}
{"id": "2509.11165", "title": "Traffic-MLLM: A Spatio-Temporal MLLM with Retrieval-Augmented Generation for Causal Inference in Traffic", "authors": ["Waikit Xiu", "Qiang Lu", "Xiying Li", "Chen Hu", "Shengbo Sun"], "abstract": "As intelligent transportation systems advance, traffic video understanding plays an increasingly pivotal role in comprehensive scene perception and causal analysis. Yet, existing approaches face notable challenges in accurately modeling spatiotemporal causality and integrating domain-specific knowledge, limiting their effectiveness in complex scenarios. To address these limitations, we propose Traffic-MLLM, a multimodal large language model tailored for fine-grained traffic analysis. Built on the Qwen2.5-VL backbone, our model leverages high-quality traffic-specific multimodal datasets and uses Low-Rank Adaptation (LoRA) for lightweight fine-tuning, significantly enhancing its capacity to model continuous spatiotemporal features in video sequences. Furthermore, we introduce an innovative knowledge prompting module fusing Chain-of-Thought (CoT) reasoning with Retrieval-Augmented Generation (RAG), enabling precise injection of detailed traffic regulations and domain knowledge into the inference process. This design markedly boosts the model's logical reasoning and knowledge adaptation capabilities. Experimental results on TrafficQA and DriveQA benchmarks show Traffic-MLLM achieves state-of-the-art performance, validating its superior ability to process multimodal traffic data. It also exhibits remarkable zero-shot reasoning and cross-scenario generalization capabilities.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.11165.pdf", "abstract_url": "https://arxiv.org/abs/2509.11165", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "提出Traffic-MLLM，一个基于Qwen2.5-VL的多模态大语言模型，用于交通视频的细粒度因果分析，通过LoRA微调和RAG增强知识注入，在基准测试中达到SOTA性能。", "motivation": "解决现有方法在建模时空因果关系和整合领域知识方面的挑战，以提高复杂交通场景下的分析效果。", "method": "使用Qwen2.5-VL骨干网络，结合LoRA进行轻量级微调，并引入融合CoT推理和RAG的知识提示模块，以注入交通规则和领域知识。", "result": "在TrafficQA和DriveQA基准测试中实现最先进性能，并展示出优秀的零样本推理和跨场景泛化能力。", "conclusion": "Traffic-MLLM显著提升了多模态交通数据处理能力，为智能交通系统提供了有效的因果推理工具。"}}
{"id": "2509.11035", "title": "Free-MAD: Consensus-Free Multi-Agent Debate", "authors": ["Yu Cui", "Hang Fu", "Haibin Zhang", "Licheng Wang", "Cong Zuo"], "abstract": "Multi-agent debate (MAD) is an emerging approach to improving the reasoning capabilities of large language models (LLMs). Existing MAD methods rely on multiple rounds of interaction among agents to reach consensus, and the final output is selected by majority voting in the last round. However, this consensus-based design faces several limitations. First, multiple rounds of communication increases token overhead and limits scalability. Second, due to the inherent conformity of LLMs, agents that initially produce correct responses may be influenced by incorrect ones during the debate process, causing error propagation. Third, majority voting introduces randomness and unfairness in the decision-making phase, and can degrade the reasoning performance.", "subjects": "Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.11035.pdf", "abstract_url": "https://arxiv.org/abs/2509.11035", "categories": ["Artificial Intelligence (cs.AI)", "Cryptography and Security (cs.CR)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出Free-MAD方法，一种无需共识的多智能体辩论框架，通过单轮辩论和基于质量的输出选择，减少通信开销并避免错误传播，提升大语言模型的推理性能。", "motivation": "解决现有多智能体辩论方法依赖多轮共识和多数投票导致的通信开销大、错误传播、随机性和不公平性问题。", "method": "采用共识自由的辩论设计，使用单轮交互和基于质量的输出选择机制，而非多数投票。", "result": "减少了token开销，避免了错误传播，提高了推理准确性和公平性。", "conclusion": "Free-MAD框架有效克服了现有方法的局限，为多智能体辩论提供了更高效和可靠的解决方案。"}}
{"id": "2509.10818", "title": "LLM Enhancement with Domain Expert Mental Model to Reduce LLM Hallucination with Causal Prompt Engineering", "authors": ["Boris Kovalerchuk", "Brent D. Fegley"], "abstract": "Difficult decision-making problems abound in various disciplines and domains. The proliferation of generative techniques, especially large language models (LLMs), has excited interest in using them for decision support. However, LLMs cannot yet resolve missingness in their training data, leading to hallucinations. Retrieval-Augmented Generation (RAG) enhances LLMs by incorporating external information retrieval, reducing hallucinations and improving accuracy. Yet, RAG and related methods are only partial solutions, as they may lack access to all necessary sources or key missing information. Even everyday issues often challenge LLMs' abilities. Submitting longer prompts with context and examples is one approach to address knowledge gaps, but designing effective prompts is non-trivial and may not capture complex mental models of domain experts. For tasks with missing critical information, LLMs are insufficient, as are many existing systems poorly represented in available documents. This paper explores how LLMs can make decision-making more efficient, using a running example of evaluating whether to respond to a call for proposals. We propose a technology based on optimized human-machine dialogue and monotone Boolean and k-valued functions to discover a computationally tractable personal expert mental model (EMM) of decision-making. Our EMM algorithm for LLM prompt engineering has four steps: (1) factor identification, (2) hierarchical structuring of factors, (3) generating a generalized expert mental model specification, and (4) generating a detailed generalized expert mental model from that specification.", "subjects": "Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)", "comments": "25 pages,4 figures, 2 tables", "pdf_url": "https://arxiv.org/pdf/2509.10818.pdf", "abstract_url": "https://arxiv.org/abs/2509.10818", "categories": ["Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出一种结合领域专家心智模型与因果提示工程的方法，以减少大语言模型的幻觉，通过四步算法优化提示设计。", "motivation": "解决大语言模型在决策支持中因训练数据缺失导致的幻觉问题，现有方法如RAG和长提示不足以捕捉复杂专家知识。", "method": "使用优化人机对话和单调布尔函数，通过因子识别、层次结构化、生成专家心智模型规范和详细模型四步算法。", "result": "开发了一种可计算处理的专家心智模型，能更有效地减少幻觉并提高决策准确性。", "conclusion": "该方法增强了LLM在决策任务中的实用性，为处理信息缺失问题提供了新途径。"}}
{"id": "2509.10875", "title": "Is the `Agent' Paradigm a Limiting Framework for Next-Generation Intelligent Systems?", "authors": ["Jesse Gardner", "Vladimir A. Baulin"], "abstract": "The concept of the 'agent' has profoundly shaped Artificial Intelligence (AI) research, guiding development from foundational theories to contemporary applications like Large Language Model (LLM)-based systems. This paper critically re-evaluates the necessity and optimality of this agent-centric paradigm. We argue that its persistent conceptual ambiguities and inherent anthropocentric biases may represent a limiting framework. We distinguish between agentic systems (AI inspired by agency, often semi-autonomous, e.g., LLM-based agents), agential systems (fully autonomous, self-producing systems, currently only biological), and non-agentic systems (tools without the impression of agency). Our analysis, based on a systematic review of relevant literature, deconstructs the agent paradigm across various AI frameworks, highlighting challenges in defining and measuring properties like autonomy and goal-directedness. We argue that the 'agentic' framing of many AI systems, while heuristically useful, can be misleading and may obscure the underlying computational mechanisms, particularly in Large Language Models (LLMs). As an alternative, we propose a shift in focus towards frameworks grounded in system-level dynamics, world modeling, and material intelligence. We conclude that investigating non-agentic and systemic frameworks, inspired by complex systems, biology, and unconventional computing, is essential for advancing towards robust, scalable, and potentially non-anthropomorphic forms of general intelligence. This requires not only new architectures but also a fundamental reconsideration of our understanding of intelligence itself, moving beyond the agent metaphor.", "subjects": "Artificial Intelligence (cs.AI); Soft Condensed Matter (cond-mat.soft)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.10875.pdf", "abstract_url": "https://arxiv.org/abs/2509.10875", "categories": ["Artificial Intelligence (cs.AI)", "Soft Condensed Matter (cond-mat.soft)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文批判性评估了AI中'智能体'范式的局限性，认为其模糊性和人类中心偏见可能阻碍下一代智能系统的发展，并提出了基于系统动力学和世界建模的替代框架。", "motivation": "解决'智能体'范式在AI研究中的概念模糊性和人类中心偏见问题，以避免其成为限制智能系统发展的框架。", "method": "通过系统文献回顾，分析不同AI框架中的智能体范式，区分智能体系统、代理系统和非智能体系统，并评估自主性和目标导向性等属性。", "result": "发现智能体框架虽启发式有用但可能误导，特别是在大型语言模型中，掩盖了底层计算机制。", "conclusion": "建议转向系统级动力学、世界建模和物质智能框架，以促进稳健、可扩展且非人类中心的一般智能发展，需要重新思考智能的本质。"}}
{"id": "2509.11067", "title": "Agentic Lybic: Multi-Agent Execution System with Tiered Reasoning and Orchestration", "authors": ["Liangxuan Guo", "Bin Zhu", "Qingqian Tao", "Kangning Liu", "Xun Zhao", "Xianzhe Qin", "Jin Gao", "Guangfu Hao"], "abstract": "Autonomous agents for desktop automation struggle with complex multi-step tasks due to poor coordination and inadequate quality control. We introduce \\textsc{Agentic Lybic}, a novel multi-agent system where the entire architecture operates as a finite-state machine (FSM). This core innovation enables dynamic orchestration. Our system comprises four components: a Controller, a Manager, three Workers (Technician for code-based operations, Operator for GUI interactions, and Analyst for decision support), and an Evaluator. The critical mechanism is the FSM-based routing between these components, which provides flexibility and generalization by dynamically selecting the optimal execution strategy for each subtask. This principled orchestration, combined with robust quality gating, enables adaptive replanning and error recovery. Evaluated officially on the OSWorld benchmark, \\textsc{Agentic Lybic} achieves a state-of-the-art 57.07\\% success rate in 50 steps, substantially outperforming existing methods. Results demonstrate that principled multi-agent orchestration with continuous quality control provides superior reliability for generalized desktop automation in complex computing environments.", "subjects": "Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.11067.pdf", "abstract_url": "https://arxiv.org/abs/2509.11067", "categories": ["Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "Agentic Lybic 是一种基于有限状态机的多代理系统，用于桌面自动化，通过分层协调和质量控制，在 OSWorld 基准测试中达到 57.07% 的成功率，显著优于现有方法。", "motivation": "解决桌面自动化中复杂多步任务因协调不足和质量控制差而导致的问题。", "method": "使用有限状态机架构，包括控制器、管理器、三个工作者（技术员、操作员、分析师）和评估器，实现动态路由和自适应执行策略。", "result": "在 50 步任务中实现 57.07% 的成功率，展示出卓越的可靠性和泛化能力。", "conclusion": "基于原则的多代理协调和持续质量控制可显著提升复杂计算环境中桌面自动化的可靠性。"}}
{"id": "2509.11068", "title": "Tractable Asymmetric Verification for Large Language Models via Deterministic Replicability", "authors": ["Zan-Kai Chong", "Hiroyuki Ohsaki", "Bryan Ng"], "abstract": "The landscape of Large Language Models (LLMs) shifts rapidly towards dynamic, multi-agent systems. This introduces a fundamental challenge in establishing computational trust, specifically how one agent can verify that another's output was genuinely produced by a claimed LLM, and not falsified or generated by a cheaper or inferior model. To address this challenge, this paper proposes a verification framework that achieves tractable asymmetric effort, where the cost to verify a computation is substantially lower than the cost to perform it. Our approach is built upon the principle of deterministic replicability, a property inherent to autoregressive models that strictly necessitates a computationally homogeneous environment where all agents operate on identical hardware and software stacks. Within this defined context, our framework enables multiple validators to probabilistically audit small, random segments of an LLM's output and it distributes the verification workload effectively. The simulations demonstrated that targeted verification can be over 12 times faster than full regeneration, with tunable parameters to adjust the detection probability. By establishing a tractable mechanism for auditable LLM systems, our work offers a foundational layer for responsible AI and serves as a cornerstone for future research into the more complex, heterogeneous multi-agent systems.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.11068.pdf", "abstract_url": "https://arxiv.org/abs/2509.11068", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文提出了一种基于确定性可复制性的验证框架，用于在大型语言模型（LLMs）中实现高效的非对称验证，确保计算信任，验证成本远低于生成成本。", "motivation": "解决在多智能体系统中，如何验证LLM输出的真实性，防止伪造或由廉价模型生成的问题，以建立计算信任。", "method": "利用自回归模型的确定性可复制性，在计算同质环境中，通过概率性审计随机输出片段，并分布验证工作负载。", "result": "模拟显示，针对性验证比完全再生快12倍以上，检测概率可调。", "conclusion": "该框架为可审计LLM系统提供了可行机制，是负责任AI的基础，并为未来异构多智能体系统研究奠定基础。"}}
{"id": "2509.10685", "title": "Pluralistic Alignment for Healthcare: A Role-Driven Framework", "authors": ["Jiayou Zhong", "Anudeex Shetty", "Chao Jia", "Xuanrui Lin", "Usman Naseem"], "abstract": "As large language models are increasingly deployed in sensitive domains such as healthcare, ensuring their outputs reflect the diverse values and perspectives held across populations is critical. However, existing alignment approaches, including pluralistic paradigms like Modular Pluralism, often fall short in the health domain, where personal, cultural, and situational factors shape pluralism. Motivated by the aforementioned healthcare challenges, we propose a first lightweight, generalizable, pluralistic alignment approach, EthosAgents, designed to simulate diverse perspectives and values. We empirically show that it advances the pluralistic alignment for all three modes across seven varying-sized open and closed models. Our findings reveal that health-related pluralism demands adaptable and normatively aware approaches, offering insights into how these models can better respect diversity in other high-stakes domains.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "Accepted to EMNLP 2025 (Main Proceedings)", "pdf_url": "https://arxiv.org/pdf/2509.10685.pdf", "abstract_url": "https://arxiv.org/abs/2509.10685", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出EthosAgents，一种轻量级、可泛化的多元对齐方法，用于模拟医疗领域的多样视角和价值观，通过实证验证其在多种模型中提升多元对齐效果。", "motivation": "解决大型语言模型在医疗等敏感领域部署时，现有对齐方法无法充分反映人口多样价值观和视角的问题，特别是个人、文化和情境因素塑造的多元性。", "method": "采用角色驱动的框架EthosAgents，模拟多样视角和价值观，进行轻量级、可泛化的多元对齐。", "result": "实证显示，EthosAgents在七种不同大小的开放和封闭模型中，对所有三种模式均提升了多元对齐效果，揭示了医疗多元性需要适应性和规范感知的方法。", "conclusion": "该方法为医疗领域提供了更好的多元对齐，并启示了其他高风险领域模型如何更好地尊重多样性。"}}
{"id": "2509.10744", "title": "Automated MCQA Benchmarking at Scale: Evaluating Reasoning Traces as Retrieval Sources for Domain Adaptation of Small Language Models", "authors": ["Ozan Gokdemir", "Neil Getty", "Robert Underwood", "Sandeep Madireddy", "Franck Cappello", "Arvind Ramanathan", "Ian T. Foster", "Rick L. Stevens"], "abstract": "As scientific knowledge grows at an unprecedented pace, evaluation benchmarks must evolve to reflect new discoveries and ensure language models are tested on current, diverse literature. We propose a scalable, modular framework for generating multiple-choice question-answering (MCQA) benchmarks directly from large corpora of scientific papers. Our pipeline automates every stage of MCQA creation, including PDF parsing, semantic chunking, question generation, and model evaluation. As a case study, we generate more than 16,000 MCQs from 22,000 open-access articles in radiation and cancer biology. We then evaluate a suite of small language models (1.1B-14B parameters) on these questions, comparing baseline accuracy with retrieval-augmented generation (RAG) from paper-derived semantic chunks and from reasoning traces distilled from GPT-4.1. We find that reasoning-trace retrieval consistently improves performance on both synthetic and expert-annotated benchmarks, enabling several small models to surpass GPT-4 on the 2023 Astro Radiation and Cancer Biology exam.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "This manuscript has been accepted for publication at the Supercomputing 25 (SC '25) Conference (Frontiers in Generative AI for HPC Science and Engineering: Foundations, Challenges, and Opportunities Workshop) in St. Louis, MO, USA on November 16th, 2025. It will appear in the SC25 Workshop Proceedings after that date", "pdf_url": "https://arxiv.org/pdf/2509.10744.pdf", "abstract_url": "https://arxiv.org/abs/2509.10744", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一个可扩展的模块化框架，用于从科学论文中自动生成多选问答基准，并通过检索增强生成提升小语言模型的性能。", "motivation": "随着科学知识的快速增长，需要更新评估基准以测试语言模型在最新和多样文献上的表现。", "method": "使用自动化管道从PDF解析、语义分块、问题生成到模型评估，并比较检索增强生成方法。", "result": "推理痕迹检索显著提高了小模型在合成和专家标注基准上的性能，部分模型甚至超越GPT-4。", "conclusion": "该方法有效支持小语言模型的领域适应，展示了自动化基准生成和检索增强的潜力。"}}
{"id": "2509.10833", "title": "Towards Automated Error Discovery: A Study in Conversational AI", "authors": ["Dominic Petrak", "Thy Thy Tran", "Iryna Gurevych"], "abstract": "Although LLM-based conversational agents demonstrate strong fluency and coherence, they still produce undesirable behaviors (errors) that are challenging to prevent from reaching users during deployment. Recent research leverages large language models (LLMs) to detect errors and guide response-generation models toward improvement. However, current LLMs struggle to identify errors not explicitly specified in their instructions, such as those arising from updates to the response-generation model or shifts in user behavior. In this work, we introduce Automated Error Discovery, a framework for detecting and defining errors in conversational AI, and propose SEEED (Soft Clustering Extended Encoder-Based Error Detection), as an encoder-based approach to its implementation. We enhance the Soft Nearest Neighbor Loss by amplifying distance weighting for negative samples and introduce Label-Based Sample Ranking to select highly contrastive examples for better representation learning. SEEED outperforms adapted baselines -- including GPT-4o and Phi-4 -- across multiple error-annotated dialogue datasets, improving the accuracy for detecting unknown errors by up to 8 points and demonstrating strong generalization to unknown intent detection.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)", "comments": "Accepted to EMNLP 2025 main conference", "pdf_url": "https://arxiv.org/pdf/2509.10833.pdf", "abstract_url": "https://arxiv.org/abs/2509.10833", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出自动化错误发现框架和SEEED方法，用于检测和定义对话AI中的错误，通过改进损失函数和样本选择，在多个数据集上超越基线模型，提高未知错误检测准确性。", "motivation": "解决LLM在对话AI中难以检测未指定错误的问题，如模型更新或用户行为变化导致的错误。", "method": "使用基于编码器的SEEED方法，增强Soft Nearest Neighbor Loss的负样本距离权重，并引入Label-Based Sample Ranking选择对比样本以改进表示学习。", "result": "SEEED在多个错误标注对话数据集上优于GPT-4o和Phi-4等基线，未知错误检测准确率提升高达8点，并展示出对未知意图检测的强泛化能力。", "conclusion": "自动化错误发现框架和SEEED方法有效提升了对话AI的错误检测能力，具有实际部署潜力。"}}
{"id": "2509.10844", "title": "GAPrune: Gradient-Alignment Pruning for Domain-Aware Embeddings", "authors": ["Yixuan Tang", "Yi Yang"], "abstract": "Domain-specific embedding models have shown promise for applications that require specialized semantic understanding, such as coding agents and financial retrieval systems, often achieving higher performance gains than general models. However, state-of-the-art embedding models are typically based on LLMs, which contain billions of parameters, making deployment challenging in resource-constrained environments. Model compression through pruning offers a promising solution, but existing pruning methods treat all parameters uniformly, failing to distinguish between general semantic representations and domain-specific patterns, leading to suboptimal pruning decisions. Thus, we propose GAPrune, a pruning framework that addresses this challenge by considering both domain importance and preserving general linguistic foundation. Our method uses Fisher Information to measure importance and general-domain gradient alignment to assess parameter behavior, then combines these signals using our Domain Alignment Importance (DAI) scoring. Lower DAI scores indicate that the parameter is either less important for the domain task or creates conflicts between domain and general objectives. Experiments on two domain benchmarks, FinMTEB and ChemTEB, show that GAPrune maintains performance within 2.5% of dense models in one-shot pruning at 50% sparsity, while outperforming all baselines. With retraining in 100 steps, GAPrune achieves +4.51% improvement on FinMTEB and +1.73% on ChemTEB, demonstrating that our pruning strategy not only preserves but enhances domain-specific capabilities. Our findings demonstrate that principled pruning strategies can achieve model compression and enhanced domain specialization, providing the research community with a new approach for development.", "subjects": "Computation and Language (cs.CL)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2509.10844.pdf", "abstract_url": "https://arxiv.org/abs/2509.10844", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "GAPrune是一种基于梯度对齐的剪枝方法，用于压缩领域特定嵌入模型，在保持性能的同时减少参数数量。", "motivation": "解决大型语言模型参数过多导致部署困难的问题，现有剪枝方法无法区分通用和领域特定模式，导致次优剪枝。", "method": "使用Fisher信息度量重要性，结合通用领域梯度对齐，通过领域对齐重要性（DAI）评分进行剪枝。", "result": "在50%稀疏度下，性能损失小于2.5%，重训练后FinMTEB和ChemTEB基准分别提升4.51%和1.73%。", "conclusion": "GAPrune实现了模型压缩和领域专业化增强，为研究社区提供了新方法。"}}
{"id": "2509.11548", "title": "How Auxiliary Reasoning Unleashes GUI Grounding in VLMs", "authors": ["Weiming Li", "Yan Shao", "Jing Yang", "Yujing Lu", "Ling Zhong", "Yuhan Wang", "Manni Duan"], "abstract": "Graphical user interface (GUI) grounding is a fundamental task for building GUI agents. However, general vision-language models (VLMs) struggle with this task due to a lack of specific optimization. We identify a key gap in this paper: while VLMs exhibit significant latent grounding potential, as demonstrated by their performance measured by Pointing Game, they underperform when tasked with outputting explicit coordinates. To address this discrepancy, and bypass the high data and annotation costs of current fine-tuning approaches, we propose three zero-shot auxiliary reasoning methods. By providing explicit spatial cues such as axes, grids and labeled intersections as part of the input image, these methods enable VLMs to articulate their implicit spatial understanding capabilities. We evaluate these methods on four GUI grounding benchmarks across seven open-source and proprietary VLMs. The evaluation results demonstrate that the proposed methods substantially improve the performance of GUI grounding.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.11548.pdf", "abstract_url": "https://arxiv.org/abs/2509.11548", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出三种零样本辅助推理方法，通过添加空间提示（如轴和网格）来增强视觉语言模型在GUI接地任务中的性能，无需微调。", "motivation": "解决视觉语言模型在GUI接地任务中表现不佳的问题，避免高成本和数据标注需求。", "method": "使用零样本辅助推理方法，在输入图像中提供显式空间提示（如轴、网格和标记交点）。", "result": "在四个GUI接地基准测试中，方法显著提高了开源和专有模型的性能。", "conclusion": "这些方法能有效释放视觉语言模型的潜在空间理解能力，提升GUI接地任务的实用性。"}}
{"id": "2509.11078", "title": "Patient-Zero: A Unified Framework for Real-Record-Free Patient Agent Generation", "authors": ["Yunghwei Lai", "Weizhi Ma", "Yang Liu"], "abstract": "Synthetic data generation using large language models (LLMs) has emerged as a promising solution across various domains, particularly in medical field, to mitigate data collection challenges. However, existing studies mainly utilize LLMs to rewrite and complete existing medical records, where the limitations in data privacy, accuracy, and diversity sill exist, and additionally lack the ability to interact like real patients. To address these issues, we propose a realistic patient generation framework, Patient-Zero, which requires no real medical records. Patient-Zero first introduces a medically-aligned multi-step generation architecture, which builds comprehensive patient records through hierarchical medical knowledge injection without real medical records. Then, to optimize the virtual patient's interaction abilities with humans, Patient-Zero designs a dynamic updating mechanism to improve the consistency and conversational performance. Our framework enables the generation of contextually diverse patient records while maintaining strict medical coherence, supported by adaptive dialogue strategies and real-time clinical plausibility verification. Experimental results demonstrate that our model achieves good performance in accuracy, diversity, and consistency. After training with our generated virtual patients, existing models show significant improvements on the MedQA dataset.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.11078.pdf", "abstract_url": "https://arxiv.org/abs/2509.11078", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种无需真实医疗记录的合成患者生成框架Patient-Zero，通过医学知识注入和动态更新机制，提高准确性、多样性和交互一致性。", "motivation": "解决现有方法依赖真实医疗记录导致的数据隐私、准确性、多样性和交互能力不足的问题。", "method": "采用医学对齐的多步生成架构，结合分层医学知识注入和动态更新机制，实现无真实记录的虚拟患者生成和优化。", "result": "实验显示模型在准确性、多样性和一致性方面表现良好，使用生成数据训练的模型在MedQA数据集上显著改进。", "conclusion": "Patient-Zero框架有效生成高质量合成医疗数据，提升AI模型性能，同时保护数据隐私。"}}
{"id": "2509.11079", "title": "Difficulty-Aware Agent Orchestration in LLM-Powered Workflows", "authors": ["Jinwei Su", "Yinghui Xia", "Qizhen Lan", "Xinyuan Song", "Yang Jingsong", "Lewei He", "Tianyu Shi"], "abstract": "Large Language Model (LLM)-based agentic systems have shown strong capabilities across various tasks. However, existing multi-agent frameworks often rely on static or task-level workflows, which either over-process simple queries or underperform on complex ones, while also neglecting the efficiency-performance trade-offs across heterogeneous LLMs. To address these limitations, we propose Difficulty-Aware Agentic Orchestration (DAAO), a dynamic framework that adapts workflow depth, operator selection, and LLM assignment based on the difficulty of each input query. DAAO comprises three interdependent modules: a variational autoencoder (VAE) for difficulty estimation, a modular operator allocator, and a cost- and performance-aware LLM router. By leveraging heterogeneous LLMs and dynamically tailoring workflows, DAAO enables fine-grained, query-specific reasoning strategies. DAAO outperforms prior multi-agent systems in both accuracy and inference efficiency across six benchmarks. We will release our code and implementation details upon publication.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.11079.pdf", "abstract_url": "https://arxiv.org/abs/2509.11079", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "提出Difficulty-Aware Agentic Orchestration (DAAO)框架，通过动态调整工作流深度、操作符选择和LLM分配，基于查询难度优化LLM代理系统的准确性和效率。", "motivation": "解决现有多代理框架在处理简单和复杂查询时效率低、性能差的问题，以及忽略异构LLM效率-性能权衡的局限性。", "method": "使用变分自编码器(VAE)估计难度，模块化操作符分配器，以及成本-性能感知LLM路由器，动态定制工作流。", "result": "在六个基准测试中，DAAO在准确性和推理效率上优于先前的多代理系统。", "conclusion": "DAAO框架通过查询特定策略，提升了LLM代理系统的性能，并计划发布代码和实现细节。"}}
{"id": "2509.11131", "title": "Neural cellular automata: applications to biology and beyond classical AI", "authors": ["Benedikt Hartl", "Michael Levin", "Léo Pio-Lopez"], "abstract": "Neural Cellular Automata (NCA) represent a powerful framework for modeling biological self-organization, extending classical rule-based systems with trainable, differentiable (or evolvable) update rules that capture the adaptive self-regulatory dynamics of living matter. By embedding Artificial Neural Networks (ANNs) as local decision-making centers and interaction rules between localized agents, NCA can simulate processes across molecular, cellular, tissue, and system-level scales, offering a multiscale competency architecture perspective on evolution, development, regeneration, aging, morphogenesis, and robotic control. These models not only reproduce biologically inspired target patterns but also generalize to novel conditions, demonstrating robustness to perturbations and the capacity for open-ended adaptation and reasoning. Given their immense success in recent developments, we here review current literature of NCAs that are relevant primarily for biological or bioengineering applications. Moreover, we emphasize that beyond biology, NCAs display robust and generalizing goal-directed dynamics without centralized control, e.g., in controlling or regenerating composite robotic morphologies or even on cutting-edge reasoning tasks such as ARC-AGI-1. In addition, the same principles of iterative state-refinement is reminiscent to modern generative Artificial Intelligence (AI), such as probabilistic diffusion models. Their governing self-regulatory behavior is constraint to fully localized interactions, yet their collective behavior scales into coordinated system-level outcomes. We thus argue that NCAs constitute a unifying computationally lean paradigm that not only bridges fundamental insights from multiscale biology with modern generative AI, but have the potential to design truly bio-inspired collective intelligence capable of hierarchical reasoning and control.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA); Other Quantitative Biology (q-bio.OT)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.11131.pdf", "abstract_url": "https://arxiv.org/abs/2509.11131", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)", "Other Quantitative Biology (q-bio.OT)"], "matching_keywords": ["agent"], "AI": {"tldr": "Neural Cellular Automata (NCA) use trainable neural networks to model biological self-organization and extend to AI applications, offering a unified framework for multiscale adaptive systems.", "motivation": "To address the need for models that capture adaptive, self-regulatory dynamics in biology and generalize to AI tasks like robotics and reasoning, bridging gaps in classical systems.", "method": "Embedding Artificial Neural Networks as local decision-makers in cellular automata, enabling differentiable or evolvable update rules for simulating processes across scales.", "result": "NCAs reproduce biological patterns, show robustness to perturbations, generalize to novel conditions, and demonstrate capabilities in robotics and reasoning tasks, linking to generative AI principles.", "conclusion": "NCAs provide a computationally efficient paradigm that unifies biological insights with AI, enabling bio-inspired collective intelligence for hierarchical reasoning and control."}}
{"id": "2509.11253", "title": "VideoAgent: Personalized Synthesis of Scientific Videos", "authors": ["Xiao Liang", "Bangxin Li", "Zixuan Chen", "Hanyue Zheng", "Zhi Ma", "Di Wang", "Cong Tian", "Quan Wang"], "abstract": "Automating the generation of scientific videos is a crucial yet challenging task for effective knowledge dissemination. However, existing works on document automation primarily focus on static media such as posters and slides, lacking mechanisms for personalized dynamic orchestration and multimodal content synchronization. To address these challenges, we introduce VideoAgent, a novel multi-agent framework that synthesizes personalized scientific videos through a conversational interface. VideoAgent parses a source paper into a fine-grained asset library and, guided by user requirements, orchestrates a narrative flow that synthesizes both static slides and dynamic animations to explain complex concepts. To enable rigorous evaluation, we also propose SciVidEval, the first comprehensive suite for this task, which combines automated metrics for multimodal content quality and synchronization with a Video-Quiz-based human evaluation to measure knowledge transfer. Extensive experiments demonstrate that our method significantly outperforms existing commercial scientific video generation services and approaches human-level quality in scientific communication.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.11253.pdf", "abstract_url": "https://arxiv.org/abs/2509.11253", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "VideoAgent是一个通过对话界面合成个性化科学视频的多智能体框架，显著优于现有服务并接近人类水平。", "motivation": "解决自动化生成科学视频的挑战，现有方法缺乏个性化动态编排和多模态内容同步机制。", "method": "使用多智能体框架解析论文为资产库，根据用户需求编排叙事流，结合静态幻灯片和动态动画。", "result": "实验显示方法在SciVidEval评估套件中显著优于商业服务，知识传递接近人类质量。", "conclusion": "VideoAgent有效提升科学传播，为自动化视频生成提供了新方法，并引入首个全面评估套件。"}}
{"id": "2509.11311", "title": "Prompts to Proxies: Emulating Human Preferences via a Compact LLM Ensemble", "authors": ["Bingchen Wang", "Zi-Yu Khoo", "Bryan Kian Hsiang Low"], "abstract": "Large language models (LLMs) have demonstrated promise in emulating human-like responses across a wide range of tasks. In this paper, we propose a novel alignment framework that treats LLMs as agent proxies for human survey respondents, affording a cost-effective and steerable solution to two pressing challenges in the social sciences: the rising cost of survey deployment and the growing demographic imbalance in survey response data. Drawing inspiration from the theory of revealed preference, we formulate alignment as a two-stage problem: constructing diverse agent personas called endowments that simulate plausible respondent profiles, and selecting a representative subset to approximate a ground-truth population based on observed data. To implement the paradigm, we introduce P2P, a system that steers LLM agents toward representative behavioral patterns using structured prompt engineering, entropy-based sampling, and regression-based selection. Unlike personalization-heavy approaches, our alignment approach is demographic-agnostic and relies only on aggregate survey results, offering better generalizability and parsimony. Beyond improving data efficiency in social science research, our framework offers a testbed for studying the operationalization of pluralistic alignment. We demonstrate the efficacy of our approach on real-world opinion survey datasets, showing that our aligned agent populations can reproduce aggregate response patterns with high fidelity and exhibit substantial response diversity, even without demographic conditioning.", "subjects": "Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "comments": "Preprint of work originally submitted to AAAI 2026. Under revision for resubmission to a machine learning venue", "pdf_url": "https://arxiv.org/pdf/2509.11311.pdf", "abstract_url": "https://arxiv.org/abs/2509.11311", "categories": ["Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)"], "matching_keywords": ["agent"], "AI": {"tldr": "提出P2P框架，使用LLM模拟人类调查响应，降低成本并提高数据代表性，无需人口统计信息。", "motivation": "解决社会科学中调查部署成本上升和人口统计不平衡的问题。", "method": "两阶段对齐：构建多样化代理角色和选择代表性子集，采用结构化提示工程、熵采样和回归选择。", "result": "在真实调查数据集上，代理群体能高保真复制聚合响应模式并展示多样性。", "conclusion": "框架提升数据效率，为研究多元对齐提供测试平台，具有良好泛化性和简洁性。"}}
{"id": "2509.11431", "title": "Securing AI Agents: Implementing Role-Based Access Control for Industrial Applications", "authors": ["Aadil Gani Ganie"], "abstract": "The emergence of Large Language Models (LLMs) has significantly advanced solutions across various domains, from political science to software development. However, these models are constrained by their training data, which is static and limited to information available up to a specific date. Additionally, their generalized nature often necessitates fine-tuning -- whether for classification or instructional purposes -- to effectively perform specific downstream tasks. AI agents, leveraging LLMs as their core, mitigate some of these limitations by accessing external tools and real-time data, enabling applications such as live weather reporting and data analysis. In industrial settings, AI agents are transforming operations by enhancing decision-making, predictive maintenance, and process optimization. For example, in manufacturing, AI agents enable near-autonomous systems that boost productivity and support real-time decision-making. Despite these advancements, AI agents remain vulnerable to security threats, including prompt injection attacks, which pose significant risks to their integrity and reliability. To address these challenges, this paper proposes a framework for integrating Role-Based Access Control (RBAC) into AI agents, providing a robust security guardrail. This framework aims to support the effective and scalable deployment of AI agents, with a focus on on-premises implementations.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.11431.pdf", "abstract_url": "https://arxiv.org/abs/2509.11431", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于角色的访问控制（RBAC）框架，用于保护工业应用中的AI代理，以应对安全威胁并促进可扩展部署。", "motivation": "解决AI代理在工业应用中面临的安全漏洞，如提示注入攻击，以增强其完整性和可靠性。", "method": "集成RBAC到AI代理中，提供安全护栏，支持本地化实施。", "result": "框架旨在有效缓解安全风险，提升AI代理在工业环境中的实用性。", "conclusion": "RBAC集成可加强AI代理的安全性，推动其在工业领域的可靠和可扩展应用。"}}
{"id": "2509.11361", "title": "MAPGD: Multi-Agent Prompt Gradient Descent for Collaborative Prompt Optimization", "authors": ["Yichen Han", "Bojun Liu", "Zhengpeng zhou", "Guanyu Liu", "Zeng Zhang", "Yang Yang", "Wenli Wang", "Isaac N Shi", "Yunyan", "Lewei He", "Tianyu Shi"], "abstract": "Prompt engineering is crucial for leveraging large language models (LLMs), but existing methods often rely on a single optimization trajectory, limiting adaptability and efficiency while suffering from narrow perspectives, gradient conflicts, and high computational cost. We propose MAPGD (Multi-Agent Prompt Gradient Descent), a framework integrating multi-agent collaboration with gradient-based optimization. MAPGD features specialized agents for task clarity, example selection, format design, and stylistic refinement; semantic gradient coordination to resolve conflicts; bandit-based candidate selection for efficient exploration-exploitation; and theoretical convergence guarantees. Experiments on classification, generation, and reasoning tasks show MAPGD outperforms single-agent and random baselines in accuracy and efficiency. Ablations confirm the benefits of gradient fusion, agent specialization, and conflict resolution, providing a unified, gradient-inspired multi-agent approach to robust and interpretable prompt optimization.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.11361.pdf", "abstract_url": "https://arxiv.org/abs/2509.11361", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "MAPGD 是一种多智能体协作框架，通过梯度下降优化提示，提高准确性和效率，在分类、生成和推理任务中表现优于基线方法。", "motivation": "解决现有提示工程方法中单优化轨迹导致的适应性差、效率低、视角窄、梯度冲突和高计算成本问题。", "method": "集成多智能体协作与梯度优化，包括任务清晰化、示例选择、格式设计和风格优化智能体，使用语义梯度协调、基于多臂老虎机的候选选择，并提供理论收敛保证。", "result": "实验显示 MAPGD 在准确性和效率上优于单智能体和随机基线，消融研究证实梯度融合、智能体专业化和冲突解决的有效性。", "conclusion": "MAPGD 提供了一个统一、基于梯度的多智能体方法，实现鲁棒和可解释的提示优化。"}}
{"id": "2509.11507", "title": "MedicalOS: An LLM Agent based Operating System for Digital Healthcare", "authors": ["Jared Zhu", "Junde Wu"], "abstract": "Decades' advances in digital health technologies, such as electronic health records, have largely streamlined routine clinical processes. Yet, most these systems are still hard to learn and use: Clinicians often face the burden of managing multiple tools, repeating manual actions for each patient, navigating complicated UI trees to locate functions, and spending significant time on administration instead of caring for patients. The recent rise of large language model (LLM) based agents demonstrates exceptional capability in coding and computer operation, revealing the potential for humans to interact with operating systems and software not by direct manipulation, but by instructing agents through natural language. This shift highlights the need for an abstraction layer, an agent-computer interface, that translates human language into machine-executable commands. In digital healthcare, however, requires a more domain-specific abstractions that strictly follow trusted clinical guidelines and procedural standards to ensure safety, transparency, and compliance. To address this need, we present \\textbf{MedicalOS}, a unified agent-based operational system designed as such a domain-specific abstract layer for healthcare. It translates human instructions into pre-defined digital healthcare commands, such as patient inquiry, history retrieval, exam management, report generation, referrals, treatment planning, that we wrapped as off-the-shelf tools using machine languages (e.g., Python, APIs, MCP, Linux). We empirically validate MedicalOS on 214 patient cases across 22 specialties, demonstrating high diagnostic accuracy and confidence, clinically sound examination requests, and consistent generation of structured reports and medication recommendations. These results highlight MedicalOS as a trustworthy and scalable foundation for advancing workflow automation in clinical practice.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.11507.pdf", "abstract_url": "https://arxiv.org/abs/2509.11507", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "MedicalOS是一个基于大型语言模型代理的操作系统，专为数字医疗设计，通过自然语言指令自动化临床工作流程，提高效率和准确性。", "motivation": "解决数字医疗系统中工具复杂、操作繁琐、临床负担重的问题，利用LLM代理的潜力简化人机交互并确保医疗安全。", "method": "开发MedicalOS作为领域特定抽象层，将人类指令翻译为预定义的医疗命令，使用Python、API等工具包装，并通过214个病例进行实证验证。", "result": "在22个专科的214个病例中，展示了高诊断准确性、临床合理的检查请求、结构化报告和药物推荐的一致性。", "conclusion": "MedicalOS为临床实践提供了一个可信赖、可扩展的工作流自动化基础，有望提升医疗效率和安全。"}}
{"id": "2509.11145", "title": "Text2Mem: A Unified Memory Operation Language for Memory Operating System", "authors": ["Felix Wang", "Boyu Chen", "Kerun Xu", "Bo Tang", "Feiyu Xiong", "Zhiyu Li"], "abstract": "Large language model agents increasingly depend on memory to sustain long horizon interaction, but existing frameworks remain limited. Most expose only a few basic primitives such as encode, retrieve, and delete, while higher order operations like merge, promote, demote, split, lock, and expire are missing or inconsistently supported. Moreover, there is no formal and executable specification for memory commands, leaving scope and lifecycle rules implicit and causing unpredictable behavior across systems. We introduce Text2Mem, a unified memory operation language that provides a standardized pathway from natural language to reliable execution. Text2Mem defines a compact yet expressive operation set aligned with encoding, storage, and retrieval. Each instruction is represented as a JSON based schema instance with required fields and semantic invariants, which a parser transforms into typed operation objects with normalized parameters. A validator ensures correctness before execution, while adapters map typed objects either to a SQL prototype backend or to real memory frameworks. Model based services such as embeddings or summarization are integrated when required. All results are returned through a unified execution contract. This design ensures safety, determinism, and portability across heterogeneous backends. We also outline Text2Mem Bench, a planned benchmark that separates schema generation from backend execution to enable systematic evaluation. Together, these components establish the first standardized foundation for memory control in agents.", "subjects": "Computation and Language (cs.CL)", "comments": "11 pages, 3 figures", "pdf_url": "https://arxiv.org/pdf/2509.11145.pdf", "abstract_url": "https://arxiv.org/abs/2509.11145", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了Text2Mem，一种统一的内存操作语言，用于标准化自然语言到可靠执行的转换，确保跨系统的安全性和可移植性。", "motivation": "解决大型语言模型代理中内存操作框架的局限性，如缺乏高级操作和正式规范，导致行为不可预测。", "method": "定义基于JSON模式的指令集，包括解析器、验证器和适配器，集成模型服务，并通过统一执行合同处理结果。", "result": "Text2Mem提供了一个紧凑且表达性强的操作集，支持编码、存储和检索，确保确定性和跨后端兼容性。", "conclusion": "Text2Mem及其基准测试为代理内存控制建立了首个标准化基础，提升了可靠性和评估能力。"}}
{"id": "2509.10886", "title": "CultureSynth: A Hierarchical Taxonomy-Guided and Retrieval-Augmented Framework for Cultural Question-Answer Synthesis", "authors": ["Xinyu Zhang", "Pei Zhang", "Shuang Luo", "Jialong Tang", "Yu Wan", "Baosong Yang", "Fei Huang"], "abstract": "Cultural competence, defined as the ability to understand and adapt to multicultural contexts, is increasingly vital for large language models (LLMs) in global environments. While several cultural benchmarks exist to assess LLMs' cultural competence, current evaluations suffer from fragmented taxonomies, domain specificity, and heavy reliance on manual data annotation. To address these limitations, we introduce CultureSynth, a novel framework comprising (1) a comprehensive hierarchical multilingual cultural taxonomy covering 12 primary and 130 secondary topics, and (2) a Retrieval-Augmented Generation (RAG)-based methodology leveraging factual knowledge to synthesize culturally relevant question-answer pairs. The CultureSynth-7 synthetic benchmark contains 19,360 entries and 4,149 manually verified entries across 7 languages. Evaluation of 14 prevalent LLMs of different sizes reveals clear performance stratification led by ChatGPT-4o-Latest and Qwen2.5-72B-Instruct. The results demonstrate that a 3B-parameter threshold is necessary for achieving basic cultural competence, models display varying architectural biases in knowledge processing, and significant geographic disparities exist across models. We believe that CultureSynth offers a scalable framework for developing culturally aware AI systems while reducing reliance on manual annotation\\footnote{Benchmark is available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "Accepted as a Findings paper at EMNLP 2025", "pdf_url": "https://arxiv.org/pdf/2509.10886.pdf", "abstract_url": "https://arxiv.org/abs/2509.10886", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "CultureSynth是一个新颖的框架，通过分层多语言文化分类法和检索增强生成方法，自动合成文化相关问答对，以评估和提升大型语言模型的文化能力，减少对人工注释的依赖。", "motivation": "当前大型语言模型的文化能力评估存在分类法碎片化、领域特定性和依赖人工注释的问题，需要更可扩展的解决方案。", "method": "使用分层多语言文化分类法（12个主要和130个次要主题）和检索增强生成（RAG）方法，基于事实知识合成文化问答对。", "result": "评估14个不同规模的LLM，显示ChatGPT-4o-Latest和Qwen2.5-72B-Instruct性能领先，3B参数是基本文化能力的阈值，存在架构偏见和地理差异。", "conclusion": "CultureSynth提供了一个可扩展的框架，用于开发文化感知AI系统，减少人工注释需求，促进全球AI应用。"}}
{"id": "2509.11575", "title": "A Survey of Reasoning and Agentic Systems in Time Series with Large Language Models", "authors": ["Ching Chang", "Yidan Shi", "Defu Cao", "Wei Yang", "Jeehyun Hwang", "Haixin Wang", "Jiacheng Pang", "Wei Wang", "Yan Liu", "Wen-Chih Peng", "Tien-Fu Chen"], "abstract": "Time series reasoning treats time as a first-class axis and incorporates intermediate evidence directly into the answer. This survey defines the problem and organizes the literature by reasoning topology with three families: direct reasoning in one step, linear chain reasoning with explicit intermediates, and branch-structured reasoning that explores, revises, and aggregates. The topology is crossed with the main objectives of the field, including traditional time series analysis, explanation and understanding, causal inference and decision making, and time series generation, while a compact tag set spans these axes and captures decomposition and verification, ensembling, tool use, knowledge access, multimodality, agent loops, and LLM alignment regimes. Methods and systems are reviewed across domains, showing what each topology enables and where it breaks down in faithfulness or robustness, along with curated datasets, benchmarks, and resources that support study and deployment (", "subjects": "Artificial Intelligence (cs.AI)", "comments": "This paper is currently under review", "pdf_url": "https://arxiv.org/pdf/2509.11575.pdf", "abstract_url": "https://arxiv.org/abs/2509.11575", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "关于时间序列中基于大型语言模型的推理与智能体系统的综述，按推理拓扑和领域目标组织文献，并回顾方法、系统及资源。", "motivation": "解决时间序列分析中如何有效整合推理和智能体系统的问题，以提升分析、解释、因果推断和决策的准确性和鲁棒性。", "method": "将文献按推理拓扑（直接、线性链、分支结构）和领域目标（如分析、解释、因果推断）分类，并使用标签集捕捉分解、验证、工具使用等要素。", "result": "综述展示了不同拓扑的优势和局限性，提供了数据集、基准和资源，支持研究和部署。", "conclusion": "该领域需要进一步发展以提高忠实性和鲁棒性，综述为未来研究提供了框架和资源。"}}
{"id": "2509.11595", "title": "AMLNet: A Knowledge-Based Multi-Agent Framework to Generate and Detect Realistic Money Laundering Transactions", "authors": ["Sabin Huda", "Ernest Foo", "Zahra Jadidi", "MA Hakim Newton", "Abdul Sattar"], "abstract": "Anti-money laundering (AML) research is constrained by the lack of publicly shareable, regulation-aligned transaction datasets. We present AMLNet, a knowledge-based multi-agent framework with two coordinated units: a regulation-aware transaction generator and an ensemble detection pipeline. The generator produces 1,090,173 synthetic transactions (approximately 0.16\\% laundering-positive) spanning core laundering phases (placement, layering, integration) and advanced typologies (e.g., structuring, adaptive threshold behavior). Regulatory alignment reaches 75\\% based on AUSTRAC rule coverage (Section 4.2), while a composite technical fidelity score of 0.75 summarizes temporal, structural, and behavioral realism components (Section 4.4). The detection ensemble achieves F1 0.90 (precision 0.84, recall 0.97) on the internal test partitions of AMLNet and adapts to the external SynthAML dataset, indicating architectural generalizability across different synthetic generation paradigms. We provide multi-dimensional evaluation (regulatory, temporal, network, behavioral) and release the dataset (Version 1.0,", "subjects": "Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Cryptography and Security (cs.CR); Machine Learning (cs.LG); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.11595.pdf", "abstract_url": "https://arxiv.org/abs/2509.11595", "categories": ["Artificial Intelligence (cs.AI)", "Computational Engineering, Finance, and Science (cs.CE)", "Cryptography and Security (cs.CR)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "AMLNet是一个基于知识的多智能体框架，用于生成和检测逼真的洗钱交易，以解决反洗钱研究中公开数据集缺乏的问题。", "motivation": "反洗钱研究因缺乏可公开共享且符合法规的交易数据集而受限。", "method": "使用基于知识的多智能体框架，包括一个法规感知的交易生成器和一个集成检测管道。", "result": "生成器产生1,090,173笔合成交易（约0.16%为洗钱阳性），监管对齐度达75%，检测集成F1分数为0.90。", "conclusion": "AMLNet展示了跨不同合成生成范式的架构通用性，并发布了数据集，支持多维评估。"}}
{"id": "2509.11719", "title": "HeLoFusion: An Efficient and Scalable Encoder for Modeling Heterogeneous and Multi-Scale Interactions in Trajectory Prediction", "authors": ["Bingqing Wei", "Lianmin Chen", "Zhongyu Xia", "Yongtao Wang"], "abstract": "Multi-agent trajectory prediction in autonomous driving requires a comprehensive understanding of complex social dynamics. Existing methods, however, often struggle to capture the full richness of these dynamics, particularly the co-existence of multi-scale interactions and the diverse behaviors of heterogeneous agents. To address these challenges, this paper introduces HeLoFusion, an efficient and scalable encoder for modeling heterogeneous and multi-scale agent interactions. Instead of relying on global context, HeLoFusion constructs local, multi-scale graphs centered on each agent, allowing it to effectively model both direct pairwise dependencies and complex group-wise interactions (\\textit{e.g.}, platooning vehicles or pedestrian crowds). Furthermore, HeLoFusion tackles the critical challenge of agent heterogeneity through an aggregation-decomposition message-passing scheme and type-specific feature networks, enabling it to learn nuanced, type-dependent interaction patterns. This locality-focused approach enables a principled representation of multi-level social context, yielding powerful and expressive agent embeddings. On the challenging Waymo Open Motion Dataset, HeLoFusion achieves state-of-the-art performance, setting new benchmarks for key metrics including Soft mAP and minADE. Our work demonstrates that a locality-grounded architecture, which explicitly models multi-scale and heterogeneous interactions, is a highly effective strategy for advancing motion forecasting.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.11719.pdf", "abstract_url": "https://arxiv.org/abs/2509.11719", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "HeLoFusion是一种高效可扩展的编码器，用于建模自动驾驶中的异构和多尺度交互，在Waymo数据集上实现最先进性能。", "motivation": "现有方法难以捕捉多尺度交互和异构代理的复杂社会动态，需要改进轨迹预测。", "method": "构建局部多尺度图，使用聚合-分解消息传递和类型特定特征网络来建模交互。", "result": "在Waymo Open Motion Dataset上，HeLoFusion在Soft mAP和minADE等指标上达到最优性能。", "conclusion": "基于局部性的架构能有效建模多尺度和异构交互，推动运动预测发展。"}}
{"id": "2509.11645", "title": "Adapting and Evaluating Multimodal Large Language Models for Adolescent Idiopathic Scoliosis Self-Management: A Divide and Conquer Framework", "authors": ["Zhaolong Wu", "Pu Luo", "Jason Pui Yin Cheung", "Teng Zhang"], "abstract": "This study presents the first comprehensive evaluation of Multimodal Large Language Models (MLLMs) for Adolescent Idiopathic Scoliosis (AIS) self-management. We constructed a database of approximately 3,000 anteroposterior X-rays with diagnostic texts and evaluated five MLLMs through a `Divide and Conquer' framework consisting of a visual question-answering task, a domain knowledge assessment task, and a patient education counseling assessment task. Our investigation revealed limitations of MLLMs' ability in interpreting complex spinal radiographs and comprehending AIS care knowledge. To address these, we pioneered enhancing MLLMs with spinal keypoint prompting and compiled an AIS knowledge base for retrieval augmented generation (RAG), respectively. Results showed varying effectiveness of visual prompting across different architectures, while RAG substantially improved models' performances on the knowledge assessment task. Our findings indicate current MLLMs are far from capable in realizing personalized assistant in AIS care. The greatest challenge lies in their abilities to obtain accurate detections of spinal deformity locations (best accuracy: 0.55) and directions (best accuracy: 0.13).", "subjects": "Artificial Intelligence (cs.AI)", "comments": "Accepted by MICCAI 2025 MLLMCP Workshop", "pdf_url": "https://arxiv.org/pdf/2509.11645.pdf", "abstract_url": "https://arxiv.org/abs/2509.11645", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本研究首次全面评估多模态大语言模型在青少年特发性脊柱侧弯自我管理中的应用，通过分治框架发现模型在解读X光片和理解护理知识方面存在局限，并提出了改进方法，但当前模型能力仍不足。", "motivation": "解决多模态大语言模型在青少年特发性脊柱侧弯自我管理中能力不足的问题，以提升个性化辅助护理的可行性。", "method": "使用分治框架，包括视觉问答、领域知识评估和患者教育咨询任务，评估五种模型，并引入脊柱关键点提示和检索增强生成来改进。", "result": "视觉提示效果因架构而异，检索增强生成显著提升知识任务性能，但脊柱畸形位置和方向检测准确率低（最高分别为0.55和0.13）。", "conclusion": "当前多模态大语言模型远未达到实现个性化辅助护理的水平，主要挑战在于准确检测脊柱畸形。"}}
{"id": "2509.11880", "title": "Learning Representations in Video Game Agents with Supervised Contrastive Imitation Learning", "authors": ["Carlos Celemin", "Joseph Brennan", "Pierluigi Vito Amadori", "Tim Bradley"], "abstract": "This paper introduces a novel application of Supervised Contrastive Learning (SupCon) to Imitation Learning (IL), with a focus on learning more effective state representations for agents in video game environments. The goal is to obtain latent representations of the observations that capture better the action-relevant factors, thereby modeling better the cause-effect relationship from the observations that are mapped to the actions performed by the demonstrator, for example, the player jumps whenever an obstacle appears ahead. We propose an approach to integrate the SupCon loss with continuous output spaces, enabling SupCon to operate without constraints regarding the type of actions of the environment. Experiments on the 3D games Astro Bot and Returnal, and multiple 2D Atari games show improved representation quality, faster learning convergence, and better generalization compared to baseline models trained only with supervised action prediction loss functions.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.11880.pdf", "abstract_url": "https://arxiv.org/abs/2509.11880", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种将监督对比学习应用于模仿学习的新方法，以改善视频游戏代理中的状态表示，提高学习效率和泛化能力。", "motivation": "解决模仿学习中状态表示捕获动作相关因素不足的问题，以更好地建模观察与动作之间的因果关系。", "method": "集成监督对比损失与连续输出空间，使监督对比学习能处理各种环境动作类型。", "result": "在3D游戏Astro Bot、Returnal和多个2D Atari游戏中，相比仅使用监督动作预测损失的基线模型，表现出更高的表示质量、更快的收敛速度和更好的泛化性能。", "conclusion": "该方法有效提升了代理在视频游戏环境中的学习表现，具有潜在的应用价值。"}}
{"id": "2509.11914", "title": "EgoMem: Lifelong Memory Agent for Full-duplex Omnimodal Models", "authors": ["Yiqun Yao", "Naitong Yu", "Xiang Li", "Xin Jiang", "Xuezhi Fang", "Wenjia Ma", "Xuying Meng", "Jing Li", "Aixin Sun", "Yequan Wang"], "abstract": "We introduce EgoMem, the first lifelong memory agent tailored for full-duplex models that process real-time omnimodal streams. EgoMem enables real-time models to recognize multiple users directly from raw audiovisual streams, to provide personalized response, and to maintain long-term knowledge of users' facts, preferences, and social relationships extracted from audiovisual history. EgoMem operates with three asynchronous processes: (i) a retrieval process that dynamically identifies user via face and voice, and gathers relevant context from a long-term memory; (ii) an omnimodal dialog process that generates personalized audio responses based on the retrieved context; and (iii) a memory management process that automatically detects dialog boundaries from omnimodal streams, and extracts necessary information to update the long-term memory. Unlike existing memory agents for LLMs, EgoMem relies entirely on raw audiovisual streams, making it especially suitable for lifelong, real-time, and embodied scenarios. Experimental results demonstrate that EgoMem's retrieval and memory management modules achieve over 95% accuracy on the test set. When integrated with a fine-tuned RoboEgo omnimodal chatbot, the system achieves fact-consistency scores above 87% in real-time personalized dialogs, establishing a strong baseline for future research.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.11914.pdf", "abstract_url": "https://arxiv.org/abs/2509.11914", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "EgoMem是首个为全双工模型设计的终身记忆代理，处理实时全模态流，实现用户识别、个性化响应和长期知识维护，准确率超95%，事实一致性超87%。", "motivation": "解决现有记忆代理依赖文本而非原始视听流的问题，使其更适用于终身、实时和具身场景。", "method": "使用三个异步过程：检索过程动态识别用户并获取上下文，全模态对话过程生成个性化音频响应，记忆管理过程检测对话边界并更新长期记忆。", "result": "检索和记忆管理模块准确率超95%，集成后事实一致性超87%，建立了强基线。", "conclusion": "EgoMem为全双工模型提供了有效的终身记忆解决方案，推动未来研究。"}}
{"id": "2509.11943", "title": "Neuro-Symbolic Agents with Modal Logic for Autonomous Diagnostics", "authors": ["Antonin Sulc", "Thorsten Hellert"], "abstract": "The development of intelligent agents, particularly those powered by language models (LMs), has shown the critical role in various environments that require intelligent and autonomous decision. Environments are not passive testing grounds and they represent the data required for agents to learn and exhibit very challenging conditions that require adaptive, complex and autonomous capacity to make decisions. While the paradigm of scaling models and datasets has led to remarkable emergent capabilities, we argue that scaling the structure, fidelity, and logical consistency of agent reasoning within these environments is a crucial, yet underexplored, dimension of AI research. This paper introduces a neuro-symbolic multi-agent architecture where the belief states of individual agents are formally represented as Kripke models. This foundational choice enables them to reason about known concepts of \\emph{possibility} and \\emph{necessity} using the formal language of modal logic. In this work, we use of immutable, domain-specific knowledge to make infere information, which is encoded as logical constraints essential for proper diagnosis. In the proposed model, we show constraints that actively guide the hypothesis generation of LMs, effectively preventing them from reaching physically or logically untenable conclusions. In a high-fidelity simulated particle accelerator environment, our system successfully diagnoses complex, cascading failures by combining the powerful semantic intuition of LMs with the rigorous, verifiable validation of modal logic and a factual world model and showcasing a viable path toward more robust, reliable, and verifiable autonomous agents.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Logic in Computer Science (cs.LO); Multiagent Systems (cs.MA)", "comments": "10 pages, 1 figure, Scaling Environments for Agents (SEA) Workshop at NeuralIPS", "pdf_url": "https://arxiv.org/pdf/2509.11943.pdf", "abstract_url": "https://arxiv.org/abs/2509.11943", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Logic in Computer Science (cs.LO)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种结合神经符号多智能体架构和模态逻辑的自主诊断系统，在模拟粒子加速器环境中有效诊断复杂故障，提高智能体的鲁棒性和可靠性。", "motivation": "解决智能体在复杂环境中推理结构、保真度和逻辑一致性不足的问题，以提升自主决策能力。", "method": "使用Kripke模型表示智能体信念状态，结合语言模型的语义直觉和模态逻辑的严格验证，通过逻辑约束指导假设生成。", "result": "在模拟粒子加速器环境中成功诊断了级联故障，避免了物理或逻辑上不可行的结论。", "conclusion": "该方法为开发更稳健、可靠和可验证的自主智能体提供了一条可行路径。"}}
{"id": "2509.11944", "title": "Agentic Temporal Graph of Reasoning with Multimodal Language Models: A Potential AI Aid to Healthcare", "authors": ["Susanta Mitra"], "abstract": "Healthcare and medicine are multimodal disciplines that deal with multimodal data for reasoning and diagnosing multiple diseases. Although some multimodal reasoning models have emerged for reasoning complex tasks in scientific domains, their applications in the healthcare domain remain limited and fall short in correct reasoning for diagnosis. To address the challenges of multimodal medical reasoning for correct diagnosis and assist the healthcare professionals, a novel temporal graph-based reasoning process modelled through a directed graph has been proposed in the current work. It helps in accommodating dynamic changes in reasons through backtracking, refining the reasoning content, and creating new or deleting existing reasons to reach the best recommendation or answer. Again, consideration of multimodal data at different time points can enable tracking and analysis of patient health and disease progression. Moreover, the proposed multi-agent temporal reasoning framework provides task distributions and a cross-validation mechanism to further enhance the accuracy of reasoning outputs. A few basic experiments and analysis results justify the novelty and practical utility of the proposed preliminary approach.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.11944.pdf", "abstract_url": "https://arxiv.org/abs/2509.11944", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "提出了一种基于时序图的多智能体推理框架，用于多模态医疗数据，通过回溯和精炼推理内容，提高诊断准确性，并辅助医疗专业人员。", "motivation": "解决多模态医疗推理在诊断中准确性不足的问题，以帮助医疗专业人员。", "method": "使用有向时序图建模推理过程，支持回溯、精炼和动态调整理由，结合多智能体任务分配和交叉验证机制。", "result": "初步实验和分析结果表明该方法具有新颖性和实用性。", "conclusion": "该框架能有效跟踪患者健康变化，提升推理准确性，具有潜在医疗应用价值。"}}
{"id": "2509.11973", "title": "MusicSwarm: Biologically Inspired Intelligence for Music Composition", "authors": ["Markus J. Buehler"], "abstract": "We show that coherent, long-form musical composition can emerge from a decentralized swarm of identical, frozen foundation models that coordinate via stigmergic, peer-to-peer signals, without any weight updates. We compare a centralized multi-agent system with a global critic to a fully decentralized swarm in which bar-wise agents sense and deposit harmonic, rhythmic, and structural cues, adapt short-term memory, and reach consensus. Across symbolic, audio, and graph-theoretic analyses, the swarm yields superior quality while delivering greater diversity and structural variety and leads across creativity metrics. The dynamics contract toward a stable configuration of complementary roles, and self-similarity networks reveal a small-world architecture with efficient long-range connectivity and specialized bridging motifs, clarifying how local novelties consolidate into global musical form. By shifting specialization from parameter updates to interaction rules, shared memory, and dynamic consensus, MusicSwarm provides a compute- and data-efficient route to long-horizon creative structure that is immediately transferable beyond music to collaborative writing, design, and scientific discovery.", "subjects": "Artificial Intelligence (cs.AI); Multimedia (cs.MM); Sound (cs.SD)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.11973.pdf", "abstract_url": "https://arxiv.org/abs/2509.11973", "categories": ["Artificial Intelligence (cs.AI)", "Multimedia (cs.MM)", "Sound (cs.SD)"], "matching_keywords": ["agent"], "AI": {"tldr": "MusicSwarm 是一种基于生物启发式智能的音乐创作方法，通过去中心化群体模型协调，无需权重更新，生成高质量、多样化的长音乐作品。", "motivation": "解决传统集中式系统在音乐创作中计算效率低、缺乏多样性和结构性的问题，探索去中心化群体智能在创造性任务中的应用。", "method": "使用去中心化群体模型，通过 stigmergic 信号、短期记忆适应和共识机制协调，进行音乐创作，并与集中式系统比较。", "result": "群体方法在质量、多样性、结构性和创造力指标上优于集中式系统，展现出小世界网络结构和高效全局连接。", "conclusion": "MusicSwarm 提供了一种计算和数据高效的方法，可扩展到其他创造性领域如写作和设计，强调了交互规则和动态共识的重要性。"}}
{"id": "2509.12034", "title": "Human-AI Use Patterns for Decision-Making in Disaster Scenarios: A Systematic Review", "authors": ["Emmanuel Adjei Domfeh", "Christopher L. Dancy"], "abstract": "In high-stakes disaster scenarios, timely and informed decision-making is critical yet often challenged by uncertainty, dynamic environments, and limited resources. This paper presents a systematic review of Human-AI collaboration patterns that support decision-making across all disaster management phases. Drawing from 51 peer-reviewed studies, we identify four major categories: Human-AI Decision Support Systems, Task and Resource Coordination, Trust and Transparency, and Simulation and Training. Within these, we analyze sub-patterns such as cognitive-augmented intelligence, multi-agent coordination, explainable AI, and virtual training environments. Our review highlights how AI systems may enhance situational awareness, improves response efficiency, and support complex decision-making, while also surfacing critical limitations in scalability, interpretability, and system interoperability. We conclude by outlining key challenges and future research directions, emphasizing the need for adaptive, trustworthy, and context-aware Human-AI systems to improve disaster resilience and equitable recovery outcomes.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "10 pages, 2 figures", "pdf_url": "https://arxiv.org/pdf/2509.12034.pdf", "abstract_url": "https://arxiv.org/abs/2509.12034", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "系统回顾了灾害场景中人类与AI协作模式，识别了四大类别及其子模式，强调了AI在提升决策支持、效率和意识方面的作用，同时指出了可扩展性、可解释性和互操作性等挑战。", "motivation": "解决灾害管理中高不确定性、动态环境和资源有限导致的决策困难问题。", "method": "基于51项同行评审研究的系统回顾，分析人类-AI协作模式，包括决策支持系统、任务协调、信任透明度和模拟培训。", "result": "识别了四大类别和子模式，如认知增强智能和多智能体协调，AI可增强情境意识、提高响应效率，但存在可扩展性、可解释性和互操作性限制。", "conclusion": "需要开发自适应、可信赖和情境感知的人类-AI系统，以提升灾害韧性和公平恢复结果，并指出了未来研究方向。"}}
{"id": "2509.11295", "title": "The Prompt Engineering Report Distilled: Quick Start Guide for Life Sciences", "authors": ["Valentin Romanov", "Steven A Niederer"], "abstract": "Developing effective prompts demands significant cognitive investment to generate reliable, high-quality responses from Large Language Models (LLMs). By deploying case-specific prompt engineering techniques that streamline frequently performed life sciences workflows, researchers could achieve substantial efficiency gains that far exceed the initial time investment required to master these techniques. The Prompt Report published in 2025 outlined 58 different text-based prompt engineering techniques, highlighting the numerous ways prompts could be constructed. To provide actionable guidelines and reduce the friction of navigating these various approaches, we distil this report to focus on 6 core techniques: zero-shot, few-shot approaches, thought generation, ensembling, self-criticism, and decomposition. We breakdown the significance of each approach and ground it in use cases relevant to life sciences, from literature summarization and data extraction to editorial tasks. We provide detailed recommendations for how prompts should and shouldn't be structured, addressing common pitfalls including multi-turn conversation degradation, hallucinations, and distinctions between reasoning and non-reasoning models. We examine context window limitations, agentic tools like Claude Code, while analyzing the effectiveness of Deep Research tools across OpenAI, Google, Anthropic and Perplexity platforms, discussing current limitations. We demonstrate how prompt engineering can augment rather than replace existing established individual practices around data processing and document editing. Our aim is to provide actionable guidance on core prompt engineering principles, and to facilitate the transition from opportunistic prompting to an effective, low-friction systematic practice that contributes to higher quality research.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.11295.pdf", "abstract_url": "https://arxiv.org/abs/2509.11295", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "该论文提炼了2025年报告中的58种提示工程技术，聚焦6种核心方法，为生命科学研究提供实用指南，以提高LLM响应的质量和效率。", "motivation": "解决开发有效提示需要大量认知投入的问题，旨在通过简化工作流程，帮助研究人员在生命科学领域更高效地使用大型语言模型。", "method": "提炼和聚焦6种核心提示工程技术（如零样本、少样本、思维生成等），结合生命科学用例提供详细建议，分析常见陷阱和工具限制。", "result": "提供了可操作的指导，展示了提示工程如何增强而非取代现有实践，促进从机会性提示到系统性实践的过渡。", "conclusion": "核心提示工程原则能显著提升研究质量，减少摩擦，并讨论了当前平台的局限性，强调其在生命科学中的实际应用价值。"}}
{"id": "2509.11796", "title": "FineQuest: Adaptive Knowledge-Assisted Sports Video Understanding via Agent-of-Thoughts Reasoning", "authors": ["Haodong Chen", "Haojian Huang", "XinXiang Yin", "Dian Shao"], "abstract": "Video Question Answering (VideoQA) based on Large Language Models (LLMs) has shown potential in general video understanding but faces significant challenges when applied to the inherently complex domain of sports videos. In this work, we propose FineQuest, the first training-free framework that leverages dual-mode reasoning inspired by cognitive science: i) Reactive Reasoning for straightforward sports queries and ii) Deliberative Reasoning for more complex ones. To bridge the knowledge gap between general-purpose models and domain-specific sports understanding, FineQuest incorporates SSGraph, a multimodal sports knowledge scene graph spanning nine sports, which encodes both visual instances and domain-specific terminology to enhance reasoning accuracy. Furthermore, we introduce two new sports VideoQA benchmarks, Gym-QA and Diving-QA, derived from the FineGym and FineDiving datasets, enabling diverse and comprehensive evaluation. FineQuest achieves state-of-the-art performance on these benchmarks as well as the existing SPORTU dataset, while maintains strong general VideoQA capabilities.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "ACM MM 2025", "pdf_url": "https://arxiv.org/pdf/2509.11796.pdf", "abstract_url": "https://arxiv.org/abs/2509.11796", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "FineQuest 是一个无需训练的视频问答框架，通过双模式推理和体育知识图谱，在体育视频理解中实现最先进性能。", "motivation": "解决大型语言模型在复杂体育视频问答中面临的挑战，如知识鸿沟和推理准确性不足。", "method": "使用基于认知科学的双模式推理（反应性和深思性）和 SSGraph 多模态体育知识图谱来增强推理。", "result": "在 Gym-QA、Diving-QA 和 SPORTU 数据集上达到最先进性能，同时保持通用视频问答能力。", "conclusion": "FineQuest 提供了有效的训练免费方法，提升了体育视频理解的准确性和适应性，具有广泛的应用潜力。"}}
{"id": "2509.11866", "title": "Dr.V: A Hierarchical Perception-Temporal-Cognition Framework to Diagnose Video Hallucination by Fine-grained Spatial-Temporal Grounding", "authors": ["Meng Luo", "Shengqiong Wu", "Liqiang Jing", "Tianjie Ju", "Li Zheng", "Jinxiang Lai", "Tianlong Wu", "Xinya Du", "Jian Li", "Siyuan Yan", "Jiebo Luo", "William Yang Wang", "Hao Fei", "Mong-Li Lee", "Wynne Hsu"], "abstract": "Recent advancements in large video models (LVMs) have significantly enhance video understanding. However, these models continue to suffer from hallucinations, producing content that conflicts with input videos. To address this issue, we propose Dr.V, a hierarchical framework covering perceptive, temporal, and cognitive levels to diagnose video hallucination by fine-grained spatial-temporal grounding. Dr.V comprises of two key components: a benchmark dataset Dr.V-Bench and a satellite video agent Dr.V-Agent. Dr.V-Bench includes 10k instances drawn from 4,974 videos spanning diverse tasks, each enriched with detailed spatial-temporal annotation. Dr.V-Agent detects hallucinations in LVMs by systematically applying fine-grained spatial-temporal grounding at the perceptive and temporal levels, followed by cognitive level reasoning. This step-by-step pipeline mirrors human-like video comprehension and effectively identifies hallucinations. Extensive experiments demonstrate that Dr.V-Agent is effective in diagnosing hallucination while enhancing interpretability and reliability, offering a practical blueprint for robust video understanding in real-world scenarios. All our data and code are available at", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "25 pages, 16 figures", "pdf_url": "https://arxiv.org/pdf/2509.11866.pdf", "abstract_url": "https://arxiv.org/abs/2509.11866", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "提出Dr.V框架，通过细粒度时空接地诊断视频幻觉，包括数据集Dr.V-Bench和代理Dr.V-Agent，提升视频理解的可靠性和可解释性。", "motivation": "解决大型视频模型产生幻觉内容的问题，即输出与输入视频冲突的内容。", "method": "使用分层框架，包括感知、时间和认知层面，通过细粒度时空接地和逐步推理来检测幻觉。", "result": "实验显示Dr.V-Agent能有效诊断幻觉，增强模型的可解释性和可靠性。", "conclusion": "Dr.V为现实场景中的稳健视频理解提供了实用蓝图，所有数据和代码已公开。"}}
{"id": "2509.01058", "title": "Speaking at the Right Level: Literacy-Controlled Counterspeech Generation with RAG-RL", "authors": ["Xiaoying Song", "Anirban Saha Anik", "Dibakar Barua", "Pengcheng Luo", "Junhua Ding", "Lingzi Hong"], "abstract": "Health misinformation spreading online poses a significant threat to public health. Researchers have explored methods for automatically generating counterspeech to health misinformation as a mitigation strategy. Existing approaches often produce uniform responses, ignoring that the health literacy level of the audience could affect the accessibility and effectiveness of counterspeech. We propose a Controlled-Literacy framework using retrieval-augmented generation (RAG) with reinforcement learning (RL) to generate tailored counterspeech adapted to different health literacy levels. In particular, we retrieve knowledge aligned with specific health literacy levels, enabling accessible and factual information to support generation. We design a reward function incorporating subjective user preferences and objective readability-based rewards to optimize counterspeech to the target health literacy level. Experiment results show that Controlled-Literacy outperforms baselines by generating more accessible and user-preferred counterspeech. This research contributes to more equitable and impactful public health communication by improving the accessibility and comprehension of counterspeech to health misinformation", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "Accepted at Findings of EMNLP 2025", "pdf_url": "https://arxiv.org/pdf/2509.01058.pdf", "abstract_url": "https://arxiv.org/abs/2509.01058", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "该论文提出了一种结合检索增强生成和强化学习的框架，为不同健康素养水平的受众生成定制化的反驳言论，以提高可访问性和有效性。", "motivation": "解决在线健康错误信息传播问题，现有方法忽略受众健康素养水平差异，导致反驳言论可能无效。", "method": "使用检索增强生成（RAG）和强化学习（RL），检索与特定健康素养水平对齐的知识，并设计奖励函数优化生成内容。", "result": "实验显示，该方法在生成更易访问和用户偏好的反驳言论方面优于基线模型。", "conclusion": "研究有助于更公平和有效的公共卫生沟通，通过提升反驳言论的可访问性和理解度。"}}
{"id": "2509.10467", "title": "DSRAG: A Domain-Specific Retrieval Framework Based on Document-derived Multimodal Knowledge Graph", "authors": ["Mengzheng Yang", "Yanfei Ren", "David Osei Opoku", "Ruochang Li", "Peng Ren", "Chunxiao Xing"], "abstract": "Current general-purpose large language models (LLMs) commonly exhibit knowledge hallucination and insufficient domain-specific adaptability in domain-specific tasks, limiting their effectiveness in specialized question answering scenarios. Retrieval-augmented generation (RAG) effectively tackles these challenges by integrating external knowledge to enhance accuracy and relevance. However, traditional RAG still faces limitations in domain knowledge accuracy and context", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV); Multimedia (cs.MM)", "comments": "12 pages, 5 figures. Accepted to the 22nd International Conference on Web Information Systems and Applications (WISA 2025)", "pdf_url": "https://arxiv.org/pdf/2509.10467.pdf", "abstract_url": "https://arxiv.org/abs/2509.10467", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Computer Vision and Pattern Recognition (cs.CV)", "Multimedia (cs.MM)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "DSRAG是一个基于文档衍生多模态知识图谱的领域特定检索框架，旨在通过改进检索增强生成来解决通用大语言模型在领域特定任务中的幻觉和适应性不足问题。", "motivation": "解决通用大语言模型在领域特定问答场景中的知识幻觉和适应性不足问题，以及传统RAG在领域知识准确性和上下文处理上的局限性。", "method": "使用文档衍生的多模态知识图谱构建领域特定检索框架，以集成外部知识并提升检索的准确性和相关性。", "result": "未在摘要中明确说明，但框架旨在增强领域特定任务的准确性和效果。", "conclusion": "DSRAG框架通过多模态知识图谱改进RAG，有望提升领域特定问答的准确性和适应性，具有实际应用潜力。"}}
{"id": "2509.10469", "title": "Real-Time RAG for the Identification of Supply Chain Vulnerabilities", "authors": ["Jesse Ponnock", "Grace Kenneally", "Michael Robert Briggs", "Elinor Yeo", "Tyrone Patterson III", "Nicholas Kinberg", "Matthew Kalinowski", "David Hechtman"], "abstract": "New technologies in generative AI can enable deeper analysis into our nation's supply chains but truly informative insights require the continual updating and aggregation of massive data in a timely manner. Large Language Models (LLMs) offer unprecedented analytical opportunities however, their knowledge base is constrained to the models' last training date, rendering these capabilities unusable for organizations whose mission impacts rely on emerging and timely information. This research proposes an innovative approach to supply chain analysis by integrating emerging Retrieval-Augmented Generation (RAG) preprocessing and retrieval techniques with advanced web-scraping technologies. Our method aims to reduce latency in incorporating new information into an augmented-LLM, enabling timely analysis of supply chain disruptors. Through experimentation, this study evaluates the combinatorial effects of these techniques towards timeliness and quality trade-offs. Our results suggest that in applying RAG systems to supply chain analysis, fine-tuning the embedding retrieval model consistently provides the most significant performance gains, underscoring the critical importance of retrieval quality. Adaptive iterative retrieval, which dynamically adjusts retrieval depth based on context, further enhances performance, especially on complex supply chain queries. Conversely, fine-tuning the LLM yields limited improvements and higher resource costs, while techniques such as downward query abstraction significantly outperforms upward abstraction in practice.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "14 pages, 5 figures, 1 table. Approved for Public Release; Distribution Unlimited. PRS Release Number: 25-0864", "pdf_url": "https://arxiv.org/pdf/2509.10469.pdf", "abstract_url": "https://arxiv.org/abs/2509.10469", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种结合检索增强生成（RAG）预处理、检索技术和网络爬虫的创新方法，用于实时分析供应链漏洞，通过实验评估了嵌入检索模型的微调对性能和时效性的提升。", "motivation": "解决大型语言模型（LLMs）知识库受限于训练日期，无法及时处理新兴信息的问题，以支持依赖实时数据的供应链分析。", "method": "集成RAG预处理、检索技术和高级网络爬虫，通过微调嵌入检索模型和自适应迭代检索来减少延迟并提高信息更新速度。", "result": "微调嵌入检索模型显著提升性能，自适应迭代检索在复杂查询中表现更佳；微调LLM改进有限且成本高，向下查询抽象优于向上抽象。", "conclusion": "RAG系统在供应链分析中有效，检索质量至关重要，嵌入模型微调是关键优化手段，对实时信息处理具有重要应用价值。"}}
{"id": "2509.11514", "title": "LVLMs are Bad at Overhearing Human Referential Communication", "authors": ["Zhengxiang Wang", "Weiling Li", "Panagiotis Kaliosis", "Owen Rambow", "Susan E. Brennan"], "abstract": "During spontaneous conversations, speakers collaborate on novel referring expressions, which they can then re-use in subsequent conversations. Understanding such referring expressions is an important ability for an embodied agent, so that it can carry out tasks in the real world. This requires integrating and understanding language, vision, and conversational interaction. We study the capabilities of seven state-of-the-art Large Vision Language Models (LVLMs) as overhearers to a corpus of spontaneous conversations between pairs of human discourse participants engaged in a collaborative object-matching task. We find that such a task remains challenging for current LVLMs and they all fail to show a consistent performance improvement as they overhear more conversations from the same discourse participants repeating the same task for multiple rounds. We release our corpus and code for reproducibility and to facilitate future research.", "subjects": "Computation and Language (cs.CL)", "comments": "EMNLP 2025 (Main)", "pdf_url": "https://arxiv.org/pdf/2509.11514.pdf", "abstract_url": "https://arxiv.org/abs/2509.11514", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文研究了七种先进的大型视觉语言模型（LVLMs）在人类自发性对话中作为旁听者理解指称表达的能力，发现这些模型在任务中表现不佳且无持续改进。", "motivation": "解决LVLMs在集成语言、视觉和对话交互以理解人类指称通信方面的不足，这对于具身代理在现实世界执行任务至关重要。", "method": "使用人类自发性对话语料库，评估LVLMs作为旁听者在协作对象匹配任务中的表现，分析其随对话轮次增加的性能变化。", "result": "所有测试的LVLMs均表现不佳，未能随更多对话轮次显示一致的性能提升，表明当前模型在此任务上存在挑战。", "conclusion": "LVLMs在人类指称通信旁听任务中能力有限，需进一步研究改进；发布语料库和代码以促进未来工作。"}}
{"id": "2509.11552", "title": "HiChunk: Evaluating and Enhancing Retrieval-Augmented Generation with Hierarchical Chunking", "authors": ["Wensheng Lu", "Keyu Chen", "Ruizhi Qiao", "Xing Sun"], "abstract": "Retrieval-Augmented Generation (RAG) enhances the response capabilities of language models by integrating external knowledge sources. However, document chunking as an important part of RAG system often lacks effective evaluation tools. This paper first analyzes why existing RAG evaluation benchmarks are inadequate for assessing document chunking quality, specifically due to evidence sparsity. Based on this conclusion, we propose HiCBench, which includes manually annotated multi-level document chunking points, synthesized evidence-dense quetion answer(QA) pairs, and their corresponding evidence sources. Additionally, we introduce the HiChunk framework, a multi-level document structuring framework based on fine-tuned LLMs, combined with the Auto-Merge retrieval algorithm to improve retrieval quality. Experiments demonstrate that HiCBench effectively evaluates the impact of different chunking methods across the entire RAG pipeline. Moreover, HiChunk achieves better chunking quality within reasonable time consumption, thereby enhancing the overall performance of RAG systems.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "17 pages, 5 figures, 6 tables", "pdf_url": "https://arxiv.org/pdf/2509.11552.pdf", "abstract_url": "https://arxiv.org/abs/2509.11552", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文分析了现有RAG评估基准在文档分块评估中的不足，提出了HiCBench评估工具和HiChunk框架，通过多级分块和改进检索算法提升RAG系统性能。", "motivation": "解决检索增强生成（RAG）系统中文档分块缺乏有效评估工具的问题，特别是由于证据稀疏性导致的评估不充分。", "method": "提出HiCBench评估基准，包括手动标注的多级分块点和合成QA对，以及HiChunk框架，基于微调LLMs的多级文档结构化和Auto-Merge检索算法。", "result": "实验表明HiCBench能有效评估不同分块方法，HiChunk在合理时间内提高了分块质量和RAG系统整体性能。", "conclusion": "HiCBench和HiChunk框架增强了RAG系统的评估和性能，为文档分块提供了更有效的工具和方法。"}}
{"id": "2509.11619", "title": "HalluDetect: Detecting, Mitigating, and Benchmarking Hallucinations in Conversational Systems", "authors": ["Spandan Anaokar", "Shrey Ganatra", "Harshvivek Kashid", "Swapnil Bhattacharyya", "Shruti Nair", "Reshma Sekhar", "Siddharth Manohar", "Rahul Hemrajani", "Pushpak Bhattacharyya"], "abstract": "Large Language Models (LLMs) are widely used in industry but remain prone to hallucinations, limiting their reliability in critical applications. This work addresses hallucination reduction in consumer grievance chatbots built using LLaMA 3.1 8B Instruct, a compact model frequently used in industry. We develop HalluDetect, an LLM-based hallucination detection system that achieves an F1 score of 69% outperforming baseline detectors by 25.44%. Benchmarking five chatbot architectures, we find that out of them, AgentBot minimizes hallucinations to 0.4159 per turn while maintaining the highest token accuracy (96.13%), making it the most effective mitigation strategy. Our findings provide a scalable framework for hallucination mitigation, demonstrating that optimized inference strategies can significantly improve factual accuracy. While applied to consumer law, our approach generalizes to other high-risk domains, enhancing trust in LLM-driven assistants. We will release the code and dataset", "subjects": "Computation and Language (cs.CL)", "comments": "6 pages + references + appendix, 3 figures, 2 tables", "pdf_url": "https://arxiv.org/pdf/2509.11619.pdf", "abstract_url": "https://arxiv.org/abs/2509.11619", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "HalluDetect 是一个基于大语言模型的幻觉检测系统，在消费者投诉聊天机器人中实现 69% 的 F1 分数，比基线高 25.44%，并通过 AgentBot 架构将幻觉降至每轮 0.4159，提高事实准确性。", "motivation": "解决大语言模型在关键应用中因幻觉问题导致的可靠性限制，特别是在消费者投诉聊天机器人中。", "method": "开发 HalluDetect 系统，基于 LLaMA 3.1 8B Instruct 模型，评估五种聊天机器人架构，使用优化推理策略。", "result": "HalluDetect 的 F1 分数为 69%，AgentBot 架构最小化幻觉至每轮 0.4159，并保持最高 token 准确率 96.13%。", "conclusion": "提供可扩展的幻觉缓解框架，证明优化策略能显著改善事实准确性，适用于高风险领域，增强对大语言模型助手的信任。"}}
{"id": "2509.10526", "title": "Resource-Aware Neural Network Pruning Using Graph-based Reinforcement Learning", "authors": ["Dieter Balemans", "Thomas Huybrechts", "Jan Steckel", "Siegfried Mercelis"], "abstract": "This paper presents a novel approach to neural network pruning by integrating a graph-based observation space into an AutoML framework to address the limitations of existing methods. Traditional pruning approaches often depend on hand-crafted heuristics and local optimization perspectives, which can lead to suboptimal performance and inefficient pruning strategies. Our framework transforms the pruning process by introducing a graph representation of the target neural network that captures complete topological relationships between layers and channels, replacing the limited layer-wise observation space with a global view of network structure. The core innovations include a Graph Attention Network (GAT) encoder that processes the network's graph representation and generates a rich embedding. Additionally, for the action space we transition from continuous pruning ratios to fine-grained binary action spaces which enables the agent to learn optimal channel importance criteria directly from data, moving away from predefined scoring functions. These contributions are modelled within a Constrained Markov Decision Process (CMDP) framework, allowing the agent to make informed pruning decisions while adhering to resource constraints such as target compression rates. For this, we design a self-competition reward system that encourages the agent to outperform its previous best performance while satisfying the defined constraints. We demonstrate the effectiveness of our approach through extensive experiments on benchmark datasets including CIFAR-10, CIFAR-100, and ImageNet. The experiments show that our method consistently outperforms traditional pruning techniques, showing state-of-the-art results while learning task-specific pruning strategies that identify functionally redundant connections beyond simple weight magnitude considerations.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.10526.pdf", "abstract_url": "https://arxiv.org/abs/2509.10526", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于图强化学习的神经网络剪枝方法，通过图注意力网络编码全局网络结构，在约束马尔可夫决策过程中优化剪枝策略，在多个数据集上实现最先进性能。", "motivation": "解决传统剪枝方法依赖手工启发式和局部优化，导致性能次优和效率低下的问题。", "method": "使用图表示神经网络拓扑，结合图注意力网络编码和二元动作空间，在约束马尔可夫决策过程中通过自竞争奖励系统学习剪枝策略。", "result": "在CIFAR-10、CIFAR-100和ImageNet等基准数据集上，方法优于传统技术，实现状态最优结果并识别功能冗余连接。", "conclusion": "该方法提供了一种数据驱动的全局剪枝框架，能有效满足资源约束，提升神经网络效率。"}}
{"id": "2509.11773", "title": "An Agentic Toolkit for Adaptive Information Extraction from Regulatory Documents", "authors": ["Gaye Colakoglu", "Gürkan Solmaz", "Jonathan Fürst"], "abstract": "Declaration of Performance (DoP) documents, mandated by EU regulation, certify the performance of construction products. While some of their content is standardized, DoPs vary widely in layout, language, schema, and format, posing challenges for automated key-value pair extraction (KVP) and question answering (QA). Existing static or LLM-only IE pipelines often hallucinate and fail to adapt to this structural diversity. Our domain-specific, stateful agentic system addresses these challenges through a planner-executor-responder architecture. The system infers user intent, detects document modality, and orchestrates tools dynamically for robust, traceable reasoning while avoiding tool misuse or execution loops. Evaluation on a curated DoP dataset demonstrates improved robustness across formats and languages, offering a scalable solution for structured data extraction in regulated workflows.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.11773.pdf", "abstract_url": "https://arxiv.org/abs/2509.11773", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种基于代理工具包的自适应信息抽取系统，用于处理欧盟建筑产品性能声明的多样化文档，通过动态规划执行架构提高鲁棒性和可扩展性。", "motivation": "解决欧盟性能声明文档在布局、语言和格式上的多样性导致的自动键值对抽取和问答挑战，现有静态或仅LLM方法易产生幻觉且无法适应结构变化。", "method": "采用领域特定的状态感知代理系统，基于规划器-执行器-响应器架构，动态推断用户意图、检测文档模态并协调工具，实现可追溯的推理，避免工具误用或循环执行。", "result": "在精选的性能声明数据集上评估显示，系统在多种格式和语言下鲁棒性提升，为受监管工作流中的结构化数据抽取提供了可扩展解决方案。", "conclusion": "该系统通过自适应代理方法有效处理文档多样性，提高了信息抽取的准确性和可靠性，适用于法规文档的自动化处理。"}}
{"id": "2509.12132", "title": "Look Again, Think Slowly: Enhancing Visual Reflection in Vision-Language Models", "authors": ["Pu Jian", "Junhong Wu", "Wei Sun", "Chen Wang", "Shuo Ren", "Jiajun Zhang"], "abstract": "Recent advances in text-only \"slow-thinking\" reasoning have prompted efforts to transfer this capability to vision-language models (VLMs), for training visual reasoning models (\\textbf{VRMs}). owever, such transfer faces critical challenges: Effective \"slow thinking\" in VRMs requires \\textbf{visual reflection}, the ability to check the reasoning process based on visual information. Through quantitative analysis, we observe that current VRMs exhibit limited visual reflection, as their attention to visual information diminishes rapidly with longer generated responses. To address this challenge, we propose a new VRM \\textbf{Reflection-V}, which enhances visual reflection based on reasoning data construction for cold-start and reward design for reinforcement learning (RL). Firstly, we construct vision-centered reasoning data by leveraging an agent that interacts between VLMs and reasoning LLMs, enabling cold-start learning of visual reflection patterns. Secondly, a visual attention based reward model is employed during RL to encourage reasoning based on visual information. Therefore, \\textbf{Reflection-V} demonstrates significant improvements across multiple visual reasoning benchmarks. Furthermore, \\textbf{Reflection-V} maintains a stronger and more consistent reliance on visual information during visual reasoning, indicating effective enhancement in visual reflection capabilities.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL)", "comments": "EMNLP2025 Main", "pdf_url": "https://arxiv.org/pdf/2509.12132.pdf", "abstract_url": "https://arxiv.org/abs/2509.12132", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文提出Reflection-V模型，通过构建视觉中心推理数据和基于视觉注意力的奖励设计，增强视觉语言模型的视觉反思能力，在多个基准测试中表现显著提升。", "motivation": "解决视觉语言模型在视觉推理中视觉反思能力有限的问题，即模型在生成长响应时对视觉信息的关注度下降。", "method": "使用代理在视觉语言模型和推理大语言模型之间交互构建推理数据，并通过基于视觉注意力的奖励模型进行强化学习。", "result": "Reflection-V在多个视觉推理基准测试中取得显著改进，并显示出对视觉信息更强、更一致的依赖。", "conclusion": "Reflection-V有效增强了视觉反思能力，为视觉推理模型的发展提供了新方法。"}}
{"id": "2509.10531", "title": "FinXplore: An Adaptive Deep Reinforcement Learning Framework for Balancing and Discovering Investment Opportunities", "authors": ["Himanshu Choudhary", "Arishi Orra", "Manoj Thakur"], "abstract": "Portfolio optimization is essential for balancing risk and return in financial decision-making. Deep Reinforcement Learning (DRL) has stood out as a cutting-edge tool for portfolio optimization that learns dynamic asset allocation using trial-and-error interactions. However, most DRL-based methods are restricted to allocating assets within a pre-defined investment universe and overlook exploring new opportunities. This study introduces an investment landscape that integrates exploiting existing assets with exploring new investment opportunities in an extended universe. The proposed approach leverages two DRL agents and dynamically balances these objectives to adapt to evolving markets while enhancing portfolio performance. One agent allocates assets within the existing universe, while another assists in exploring new opportunities in the extended universe. The effciency of the proposed methodology is determined using two real-world market data sets. The experiments demonstrate the superiority of the suggested approach against the state-of-the-art portfolio strategies and baseline methods.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.10531.pdf", "abstract_url": "https://arxiv.org/abs/2509.10531", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "FinXplore：一种自适应深度强化学习框架，用于平衡和发现投资机会，通过双代理方法提升投资组合性能。", "motivation": "解决现有深度强化学习方法局限于预定义投资资产、忽视探索新机会的问题。", "method": "使用两个深度强化学习代理：一个在现有资产中分配，另一个在扩展资产中探索新机会，动态平衡利用与探索。", "result": "在真实市场数据上实验显示，该方法优于现有最先进和基线投资组合策略。", "conclusion": "该方法能适应市场变化，提高投资组合表现，具有实际应用潜力。"}}
{"id": "2509.10544", "title": "ASL360: AI-Enabled Adaptive Streaming of Layered 360° Video over UAV-assisted Wireless Networks", "authors": ["Alireza Mohammadhosseini", "Jacob Chakareski", "Nicholas Mastronarde"], "abstract": "We propose ASL360, an adaptive deep reinforcement learning-based scheduler for on-demand 360° video streaming to mobile VR users in next generation wireless networks. We aim to maximize the overall Quality of Experience (QoE) of the users served over a UAV-assisted 5G wireless network. Our system model comprises a macro base station (MBS) and a UAV-mounted base station which both deploy mm-Wave transmission to the users. The 360° video is encoded into dependent layers and segmented tiles, allowing a user to schedule downloads of each layer's segments. Furthermore, each user utilizes multiple buffers to store the corresponding video layer's segments. We model the scheduling decision as a Constrained Markov Decision Process (CMDP), where the agent selects Base or Enhancement layers to maximize the QoE and use a policy gradient-based method (PPO) to find the optimal policy. Additionally, we implement a dynamic adjustment mechanism for cost components, allowing the system to adaptively balance and prioritize the video quality, buffer occupancy, and quality change based on real-time network and streaming session conditions. We demonstrate that ASL360 significantly improves the QoE, achieving approximately 2 dB higher average video quality, 80% lower average rebuffering time, and 57% lower video quality variation, relative to competitive baseline methods. Our results show the effectiveness of our layered and adaptive approach in enhancing the QoE in immersive videostreaming applications, particularly in dynamic and challenging network environments.", "subjects": "Networking and Internet Architecture (cs.NI); Artificial Intelligence (cs.AI); Multimedia (cs.MM)", "comments": "This paper has been accepted for presentation at the IEEE Global Communications Conference (GLOBECOM) 2025", "pdf_url": "https://arxiv.org/pdf/2509.10544.pdf", "abstract_url": "https://arxiv.org/abs/2509.10544", "categories": ["Networking and Internet Architecture (cs.NI)", "Artificial Intelligence (cs.AI)", "Multimedia (cs.MM)"], "matching_keywords": ["agent"], "AI": {"tldr": "ASL360是一种基于深度强化学习的自适应调度器，用于在无人机辅助的5G网络中优化移动VR用户的360°视频流体验，通过分层编码和动态调整机制显著提升QoE。", "motivation": "解决在动态和挑战性的无线网络环境中，移动VR用户流式传输360°视频时QoE（体验质量）低的问题，如视频质量不稳定和缓冲时间长。", "method": "使用约束马尔可夫决策过程（CMDP）建模调度决策，采用近端策略优化（PPO）算法，结合分层视频编码、多缓冲区管理和动态成本调整机制。", "result": "ASL360相比基线方法，平均视频质量提高约2 dB，平均缓冲时间降低80%，视频质量变化降低57%。", "conclusion": "ASL360在沉浸式视频流应用中有效提升QoE，特别适用于动态网络环境，证明了分层和自适应方法的优越性。"}}
{"id": "2509.10572", "title": "Quality Assessment of Tabular Data using Large Language Models and Code Generation", "authors": ["Ashlesha Akella", "Akshar Kaul", "Krishnasuri Narayanam", "Sameep Mehta"], "abstract": "Reliable data quality is crucial for downstream analysis of tabular datasets, yet rule-based validation often struggles with inefficiency, human intervention, and high computational costs. We present a three-stage framework that combines statistical inliner detection with LLM-driven rule and code generation. After filtering data samples through traditional clustering, we iteratively prompt LLMs to produce semantically valid quality rules and synthesize their executable validators through code-generating LLMs. To generate reliable quality rules, we aid LLMs with retrieval-augmented generation (RAG) by leveraging external knowledge sources and domain-specific few-shot examples. Robust guardrails ensure the accuracy and consistency of both rules and code snippets. Extensive evaluations on benchmark datasets confirm the effectiveness of our approach.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI); Databases (cs.DB)", "comments": "EMNLP industry track submitted", "pdf_url": "https://arxiv.org/pdf/2509.10572.pdf", "abstract_url": "https://arxiv.org/abs/2509.10572", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)", "Databases (cs.DB)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种结合统计异常检测与大语言模型的三阶段框架，用于自动生成数据质量规则和可执行验证器，以提高表格数据质量评估的效率和可靠性。", "motivation": "解决基于规则的数据质量验证方法效率低、需要人工干预和计算成本高的问题。", "method": "使用统计聚类过滤数据样本，通过检索增强生成（RAG）提示LLM生成语义有效的质量规则，并利用代码生成LLM合成可执行验证器，辅以鲁棒护栏确保准确性。", "result": "在基准数据集上的广泛评估证实了该方法的有效性。", "conclusion": "该方法能高效、可靠地评估表格数据质量，减少人工干预和成本，适用于下游分析。"}}
{"id": "2509.11136", "title": "Agentic Username Suggestion and Multimodal Gender Detection in Online Platforms: Introducing the PNGT-26K Dataset", "authors": ["Farbod Bijary", "Mohsen Ebadpour", "Amirhosein Tajbakhsh"], "abstract": "Persian names present unique challenges for natural language processing applications, particularly in gender detection and digital identity creation, due to transliteration inconsistencies and cultural-specific naming patterns. Existing tools exhibit significant performance degradation on Persian names, while the scarcity of comprehensive datasets further compounds these limitations. To address these challenges, the present research introduces PNGT-26K, a comprehensive dataset of Persian names, their commonly associated gender, and their English transliteration, consisting of approximately 26,000 tuples. As a demonstration of how this resource can be utilized, we also introduce two frameworks, namely Open Gender Detection and Nominalist. Open Gender Detection is a production-grade, ready-to-use framework for using existing data from a user, such as profile photo and name, to give a probabilistic guess about the person's gender. Nominalist, the second framework introduced by this paper, utilizes agentic AI to help users choose a username for their social media accounts on any platform. It can be easily integrated into any website to provide a better user experience. The PNGT-26K dataset, Nominalist and Open Gender Detection frameworks are publicly available on Github.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Social and Information Networks (cs.SI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.11136.pdf", "abstract_url": "https://arxiv.org/abs/2509.11136", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Social and Information Networks (cs.SI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了PNGT-26K数据集，包含约26,000个波斯名字、性别和英文音译元组，并开发了Open Gender Detection和Nominalist框架，用于性别检测和用户名建议，以解决波斯名字处理中的挑战。", "motivation": "波斯名字在自然语言处理应用中，由于音译不一致和文化特定命名模式，导致性别检测和数字身份创建困难，现有工具性能下降且缺乏全面数据集。", "method": "创建PNGT-26K数据集，并基于此开发两个框架：Open Gender Detection使用用户数据（如照片和名字）进行概率性别猜测，Nominalist利用代理AI帮助用户选择社交媒体用户名。", "result": "数据集和框架已公开可用，展示了如何利用资源提升波斯名字处理性能，改善用户体验。", "conclusion": "PNGT-26K和框架解决了波斯名字处理的限制，为NLP应用提供了实用工具，具有广泛集成潜力。"}}
{"id": "2509.11197", "title": "DreamNav: A Trajectory-Based Imaginative Framework for Zero-Shot Vision-and-Language Navigation", "authors": ["Yunheng Wang", "Yuetong Fang", "Taowen Wang", "Yixiao Feng", "Yawen Tan", "Shuning Zhang", "Peiran Liu", "Yiding Ji", "Renjing Xu"], "abstract": "Vision-and-Language Navigation in Continuous Environments (VLN-CE), which links language instructions to perception and control in the real world, is a core capability of embodied robots. Recently, large-scale pretrained foundation models have been leveraged as shared priors for perception, reasoning, and action, enabling zero-shot VLN without task-specific training. However, existing zero-shot VLN methods depend on costly perception and passive scene understanding, collapsing control to point-level choices. As a result, they are expensive to deploy, misaligned in action semantics, and short-sighted in planning. To address these issues, we present DreamNav that focuses on the following three aspects: (1) for reducing sensory cost, our EgoView Corrector aligns viewpoints and stabilizes egocentric perception; (2) instead of point-level actions, our Trajectory Predictor favors global trajectory-level planning to better align with instruction semantics; and (3) to enable anticipatory and long-horizon planning, we propose an Imagination Predictor to endow the agent with proactive thinking capability. On VLN-CE and real-world tests, DreamNav sets a new zero-shot state-of-the-art (SOTA), outperforming the strongest egocentric baseline with extra information by up to 7.49\\% and 18.15\\% in terms of SR and SPL metrics. To our knowledge, this is the first zero-shot VLN method to unify trajectory-level planning and active imagination while using only egocentric inputs.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.11197.pdf", "abstract_url": "https://arxiv.org/abs/2509.11197", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "DreamNav提出了一种基于轨迹和想象的零样本视觉语言导航框架，通过减少感知成本、全局轨迹规划和主动想象，在VLN-CE和真实世界测试中实现了新的SOTA性能。", "motivation": "解决现有零样本VLN方法依赖昂贵感知、动作语义不匹配和规划短视的问题。", "method": "使用EgoView Corrector对齐视角、Trajectory Predictor进行全局轨迹规划、Imagination Predictor实现主动想象。", "result": "在SR和SPL指标上分别超越最强基线7.49%和18.15%，首次统一轨迹级规划和主动想象。", "conclusion": "DreamNav有效提升了零样本VLN的性能和实用性，为机器人导航提供了更高效和前瞻性的解决方案。"}}
{"id": "2509.12168", "title": "RAGs to Riches: RAG-like Few-shot Learning for Large Language Model Role-playing", "authors": ["Timothy Rupprecht", "Enfu Nan", "Arash Akbari", "Arman Akbari", "Lei Lu", "Priyanka Maan", "Sean Duffy", "Pu Zhao", "Yumei He", "David Kaeli", "Yanzhi Wang"], "abstract": "Role-playing Large language models (LLMs) are increasingly deployed in high-stakes domains such as healthcare, education, and governance, where failures can directly impact user trust and well-being. A cost effective paradigm for LLM role-playing is few-shot learning, but existing approaches often cause models to break character in unexpected and potentially harmful ways, especially when interacting with hostile users. Inspired by Retrieval-Augmented Generation (RAG), we reformulate LLM role-playing into a text retrieval problem and propose a new prompting framework called RAGs-to-Riches, which leverages curated reference demonstrations to condition LLM responses. We evaluate our framework with LLM-as-a-judge preference voting and introduce two novel token-level ROUGE metrics: Intersection over Output (IOO) to quantity how much an LLM improvises and Intersection over References (IOR) to measure few-shot demonstrations utilization rate during the evaluation tasks. When simulating interactions with a hostile user, our prompting strategy incorporates in its responses during inference an average of 35% more tokens from the reference demonstrations. As a result, across 453 role-playing interactions, our models are consistently judged as being more authentic, and remain in-character more often than zero-shot and in-context Learning (ICL) methods. Our method presents a scalable strategy for building robust, human-aligned LLM role-playing frameworks.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.12168.pdf", "abstract_url": "https://arxiv.org/abs/2509.12168", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种名为RAGs-to-Riches的新提示框架，通过将LLM角色扮演重新定义为文本检索问题，利用参考演示来增强模型响应，提高在敌对用户交互中的角色一致性和真实性。", "motivation": "解决在医疗、教育等高风险领域中，LLM角色扮演在少样本学习下容易脱离角色、产生有害行为的问题，特别是在与敌对用户互动时。", "method": "受RAG启发，将LLM角色扮演重新定义为文本检索问题，使用策划的参考演示来条件化LLM响应，并引入IOO和IOR等新指标进行评估。", "result": "在敌对用户模拟中，该方法在推理时从参考演示中多纳入35%的令牌，在453次交互中被一致评为更真实和更少脱离角色，优于零样本和ICL方法。", "conclusion": "该方法提供了一种可扩展的策略，用于构建鲁棒且与人类对齐的LLM角色扮演框架，提升用户信任和福祉。"}}
{"id": "2509.10884", "title": "Nav-R1: Reasoning and Navigation in Embodied Scenes", "authors": ["Qingxiang Liu", "Ting Huang", "Zeyu Zhang", "Hao Tang"], "abstract": "Embodied navigation requires agents to integrate perception, reasoning, and action for robust interaction in complex 3D environments. Existing approaches often suffer from incoherent and unstable reasoning traces that hinder generalization across diverse environments, and difficulty balancing long-horizon semantic reasoning with low-latency control for real-time navigation. To address these challenges, we propose Nav-R1, an embodied foundation model that unifies reasoning in embodied environments. We first construct Nav-CoT-110K, a large-scale dataset of step-by-step Chains-of-Thought (CoT) for embodied tasks, which enables cold-start initialization with structured reasoning. Building on this foundation, we design a GRPO-based reinforcement learning framework with three complementary rewards: format, understanding, and navigation, to improve structural adherence, semantic grounding, and path fidelity. Furthermore, we introduce a Fast-in-Slow reasoning paradigm, decoupling deliberate semantic reasoning from low-latency reactive control for efficient yet coherent navigation. Extensive evaluations on embodied AI benchmarks demonstrate that Nav-R1 consistently outperforms strong baselines, with over 8% average improvement in reasoning and navigation performance. Real-world deployment on a mobile robot further validates its robustness under limited onboard resources. Code:", "subjects": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.10884.pdf", "abstract_url": "https://arxiv.org/abs/2509.10884", "categories": ["Robotics (cs.RO)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "Nav-R1是一个统一推理的具身基础模型，通过大规模数据集和强化学习框架，结合快速-慢速推理范式，在导航和推理任务中显著优于基线模型。", "motivation": "解决具身导航中推理轨迹不连贯、泛化能力差以及长时语义推理与低延迟控制难以平衡的问题。", "method": "构建Nav-CoT-110K数据集，采用GRPO强化学习框架和Fast-in-Slow推理范式，结合格式、理解和导航奖励。", "result": "在具身AI基准测试中平均提升8%以上，并在移动机器人上验证了鲁棒性。", "conclusion": "Nav-R1有效提升了具身导航的推理和性能，适用于资源受限的实际部署。"}}
{"id": "2509.11250", "title": "Realistic Environmental Injection Attacks on GUI Agents", "authors": ["Yitong Zhang", "Ximo Li", "Liyi Cai", "Jia Li"], "abstract": "GUI agents built on LVLMs are increasingly used to interact with websites. However, their exposure to open-world content makes them vulnerable to Environmental Injection Attacks (EIAs) that hijack agent behavior via webpage elements. Many recent studies assume the attacker to be a regular user who can only upload a single trigger image, which is more realistic than earlier assumptions of website-level administrative control. However, these works still fall short of realism: (1) the trigger's position and surrounding context remain largely fixed between training and testing, failing to capture the dynamic nature of real webpages and (2) the trigger often occupies an unrealistically large area, whereas real-world images are typically small. To better reflect real-world scenarios, we introduce a more realistic threat model where the attacker is a regular user and the trigger image is small and embedded within a dynamically changing environment. As a result, existing attacks prove largely ineffective under this threat model.", "subjects": "Cryptography and Security (cs.CR); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.11250.pdf", "abstract_url": "https://arxiv.org/abs/2509.11250", "categories": ["Cryptography and Security (cs.CR)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种更现实的威胁模型，针对GUI代理的环境注入攻击，强调小触发图像和动态环境以提升攻击的真实性。", "motivation": "解决现有研究中环境注入攻击假设不真实的问题，如固定触发位置和大面积触发图像，以更好地模拟现实世界场景。", "method": "引入一个威胁模型，攻击者为普通用户，使用小触发图像并嵌入动态变化的环境中，评估现有攻击的有效性。", "result": "现有攻击在这种更现实的威胁模型下效果显著降低，证明其不适用于真实动态环境。", "conclusion": "强调需要开发更鲁棒的防御机制来应对现实世界中的环境注入攻击，提升GUI代理的安全性。"}}
{"id": "2509.10656", "title": "Self-Supervised Goal-Reaching Results in Multi-Agent Cooperation and Exploration", "authors": ["Chirayu Nimonkar", "Shlok Shah", "Catherine Ji", "Benjamin Eysenbach"], "abstract": "For groups of autonomous agents to achieve a particular goal, they must engage in coordination and long-horizon reasoning. However, designing reward functions to elicit such behavior is challenging. In this paper, we study how self-supervised goal-reaching techniques can be leveraged to enable agents to cooperate. The key idea is that, rather than have agents maximize some scalar reward, agents aim to maximize the likelihood of visiting a certain goal. This problem setting enables human users to specify tasks via a single goal state rather than implementing a complex reward function. While the feedback signal is quite sparse, we will demonstrate that self-supervised goal-reaching techniques enable agents to learn from such feedback. On MARL benchmarks, our proposed method outperforms alternative approaches that have access to the same sparse reward signal as our method. While our method has no explicit mechanism for exploration, we observe that self-supervised multi-agent goal-reaching leads to emergent cooperation and exploration in settings where alternative approaches never witness a single successful trial.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "are online", "pdf_url": "https://arxiv.org/pdf/2509.10656.pdf", "abstract_url": "https://arxiv.org/abs/2509.10656", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了如何利用自监督目标达成技术促进多智能体合作与探索，通过最大化访问特定目标状态的概率来替代复杂奖励函数设计，在MARL基准测试中表现优于其他方法。", "motivation": "解决多智能体系统中协调和长期推理的奖励函数设计挑战，使人类用户能通过单一目标状态指定任务，而非复杂奖励。", "method": "使用自监督目标达成技术，智能体最大化访问目标状态的可能性，而非标量奖励，尽管反馈信号稀疏。", "result": "在MARL基准测试中，该方法优于其他使用相同稀疏奖励的方法，并观察到 emergent 合作和探索行为，而其他方法无成功试验。", "conclusion": "自监督多智能体目标达成能有效促进合作和探索，简化任务指定，具有实际应用潜力。"}}
{"id": "2509.11656", "title": "MALLM: Multi-Agent Large Language Models Framework", "authors": ["Jonas Becker", "Lars Benedikt Kaesberg", "Niklas Bauer", "Jan Philip Wahle", "Terry Ruas", "Bela Gipp"], "abstract": "Multi-agent debate (MAD) has demonstrated the ability to augment collective intelligence by scaling test-time compute and leveraging expertise. Current frameworks for multi-agent debate are often designed towards tool use, lack integrated evaluation, or provide limited configurability of agent personas, response generators, discussion paradigms, and decision protocols. We introduce MALLM (Multi-Agent Large Language Models), an open-source framework that enables systematic analysis of MAD components. MALLM offers more than 144 unique configurations of MAD, including (1) agent personas (e.g., Expert, Personality), (2) response generators (e.g., Critical, Reasoning), (3) discussion paradigms (e.g., Memory, Relay), and (4) decision protocols (e.g., Voting, Consensus). MALLM uses simple configuration files to define a debate. Furthermore, MALLM can load any textual Huggingface dataset (e.g., MMLU-Pro, WinoGrande) and provides an evaluation pipeline for easy comparison of MAD configurations. MALLM is tailored towards researchers and provides a window into the heart of multi-agent debate, facilitating the understanding of its components and their interplay.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "Accepted at EMNLP 2025 (Demo)", "pdf_url": "https://arxiv.org/pdf/2509.11656.pdf", "abstract_url": "https://arxiv.org/abs/2509.11656", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "MALLM is an open-source framework for multi-agent debate with over 144 configurable components, enabling systematic analysis and evaluation using Huggingface datasets.", "motivation": "Existing multi-agent debate frameworks often lack configurability, integrated evaluation, and focus on tool use, limiting research into MAD components.", "method": "Developed MALLM, a framework with configurable agent personas, response generators, discussion paradigms, and decision protocols via simple files, and integrated evaluation pipeline.", "result": "MALLM provides extensive configurability and facilitates easy comparison of MAD configurations, enhancing understanding of component interplay.", "conclusion": "MALLM supports researchers in analyzing multi-agent debate systematically, advancing collective intelligence through scalable and evaluable frameworks."}}
{"id": "2509.10723", "title": "Dark Patterns Meet GUI Agents: LLM Agent Susceptibility to Manipulative Interfaces and the Role of Human Oversight", "authors": ["Jingyu Tang", "Chaoran Chen", "Jiawen Li", "Zhiping Zhang", "Bingcan Guo", "Ibrahim Khalilov", "Simret Araya Gebreegziabher", "Bingsheng Yao", "Dakuo Wang", "Yanfang Ye", "Tianshi Li", "Ziang Xiao", "Yaxing Yao", "Toby Jia-Jun Li"], "abstract": "The dark patterns, deceptive interface designs manipulating user behaviors, have been extensively studied for their effects on human decision-making and autonomy. Yet, with the rising prominence of LLM-powered GUI agents that automate tasks from high-level intents, understanding how dark patterns affect agents is increasingly important. We present a two-phase empirical study examining how agents, human participants, and human-AI teams respond to 16 types of dark patterns across diverse scenarios. Phase 1 highlights that agents often fail to recognize dark patterns, and even when aware, prioritize task completion over protective action. Phase 2 revealed divergent failure modes: humans succumb due to cognitive shortcuts and habitual compliance, while agents falter from procedural blind spots. Human oversight improved avoidance but introduced costs such as attentional tunneling and cognitive load. Our findings show neither humans nor agents are uniformly resilient, and collaboration introduces new vulnerabilities, suggesting design needs for transparency, adjustable autonomy, and oversight.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.10723.pdf", "abstract_url": "https://arxiv.org/abs/2509.10723", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "研究探讨LLM GUI代理对暗模式（欺骗性界面设计）的易感性，发现代理常无法识别或优先任务完成，人类易受认知偏见影响，人机协作引入新漏洞，需透明度和可调自主性设计。", "motivation": "解决暗模式对LLM GUI代理行为的影响问题，随着自动化代理的普及，理解其易感性和人类监督的作用变得重要。", "method": "采用两阶段实证研究，比较代理、人类和人机团队在16种暗模式场景中的响应，分析失败模式和监督成本。", "result": "代理常忽略暗模式或优先任务，人类易受认知捷径影响，人机监督提高避免率但增加认知负荷和注意力隧道。", "conclusion": "人类和代理均非完全抗扰，协作带来新漏洞，需设计透明界面、可调自主性和有效监督机制。"}}
{"id": "2509.11826", "title": "Collaborative Document Editing with Multiple Users and AI Agents", "authors": ["Florian Lehmann", "Krystsina Shauchenka", "Daniel Buschek"], "abstract": "Current AI writing support tools are largely designed for individuals, complicating collaboration when co-writers must leave the shared workspace to use AI and then communicate and reintegrate results. We propose integrating AI agents directly into collaborative writing environments. Our prototype makes AI use transparent and customisable through two new shared objects: agent profiles and tasks. Agent responses appear in the familiar comment feature. In a user study (N=30), 14 teams worked on writing projects during one week. Interaction logs and interviews show that teams incorporated agents into existing norms of authorship, control, and coordination, rather than treating them as team members. Agent profiles were viewed as personal territory, while created agents and outputs became shared resources. We discuss implications for team-based AI interaction, highlighting opportunities and boundaries for treating AI as a shared resource in collaborative work.", "subjects": "Human-Computer Interaction (cs.HC); Computation and Language (cs.CL)", "comments": "34 pages, 10 figures, 4 tables", "pdf_url": "https://arxiv.org/pdf/2509.11826.pdf", "abstract_url": "https://arxiv.org/abs/2509.11826", "categories": ["Human-Computer Interaction (cs.HC)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文提出在协作写作环境中直接集成AI代理，通过代理配置文件和任务对象提高透明度和可定制性，用户研究表明团队将AI视为共享资源而非团队成员。", "motivation": "解决当前AI写作工具主要为个人设计，导致协作时需离开共享空间使用AI并重新整合结果的问题，以简化协作流程。", "method": "开发原型，集成AI代理到协作环境，使用代理配置文件和任务作为共享对象，并通过用户研究（N=30，14个团队）收集日志和访谈数据。", "result": "团队将AI代理融入现有写作规范，代理配置文件被视为个人领域，而创建的代理和输出成为共享资源，未将AI视为团队成员。", "conclusion": "AI在协作工作中可作为共享资源，提供了机会和边界，强调了团队基于AI交互的潜在改进。"}}
{"id": "2509.11967", "title": "MillStone: How Open-Minded Are LLMs?", "authors": ["Harold Triedman", "Vitaly Shmatikov"], "abstract": "Large language models equipped with Web search, information retrieval tools, and other agentic capabilities are beginning to supplant traditional search engines. As users start to rely on LLMs for information on many topics, including controversial and debatable issues, it is important to understand how the stances and opinions expressed in LLM outputs are influenced by the documents they use as their information sources.", "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL)", "comments": "19 pages, 7 tables, 7 figures", "pdf_url": "https://arxiv.org/pdf/2509.11967.pdf", "abstract_url": "https://arxiv.org/abs/2509.11967", "categories": ["Machine Learning (cs.LG)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文探讨了大型语言模型（LLMs）在结合网络搜索和信息检索工具后，其输出中立场和观点如何受信息源影响，特别是在争议性话题上。", "motivation": "解决LLMs在替代传统搜索引擎时，如何确保其输出的客观性和公正性，避免受信息源偏见影响的问题。", "method": "通过分析LLMs使用文档作为信息源的过程，评估其对输出立场的影响。", "result": "发现LLMs的输出易受信息源偏见影响，在争议问题上可能表现出不开放或偏颇的立场。", "conclusion": "强调需要改进LLMs的信息处理机制，以提高其在敏感话题上的开放性和中立性，确保可靠的信息提供。"}}
{"id": "2509.11663", "title": "ParaEQsA: Parallel and Asynchronous Embodied Questions Scheduling and Answering", "authors": ["Haisheng Wang", "Weiming Zhi"], "abstract": "This paper formulates the Embodied Questions Answering (EQsA) problem, introduces a corresponding benchmark, and proposes a system to tackle the problem. Classical Embodied Question Answering (EQA) is typically formulated as answering one single question by actively exploring a 3D environment. Real deployments, however, often demand handling multiple questions that may arrive asynchronously and carry different urgencies. We formalize this setting as Embodied Questions Answering (EQsA) and present ParaEQsA, a framework for parallel, urgency-aware scheduling and answering. ParaEQsA leverages a group memory module shared among questions to reduce redundant exploration, and a priority-planning module to dynamically schedule questions. To evaluate this setting, we contribute the Parallel Asynchronous Embodied Questions (PAEQs) benchmark containing 40 indoor scenes and five questions per scene (200 in total), featuring asynchronous follow-up questions and urgency labels. We further propose metrics for EQsA performance: Direct Answer Rate (DAR), and Normalized Urgency-Weighted Latency (NUWL), which jointly measure efficiency and responsiveness of this system. ParaEQsA consistently outperforms strong sequential baselines adapted from recent EQA systems, while reducing exploration and delay. Empirical evaluations investigate the relative contributions of priority, urgency modeling, spatial scope, reward estimation, and dependency reasoning within our framework. Together, these results demonstrate that urgency-aware, parallel scheduling is key to making embodied agents responsive and efficient under realistic, multi-question workloads.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "comments": "8 pages, 6 figures, 2026 IEEE Conference on Robotics and Automation (ICRA 2026)", "pdf_url": "https://arxiv.org/pdf/2509.11663.pdf", "abstract_url": "https://arxiv.org/abs/2509.11663", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了ParaEQsA框架，用于并行和异步的具身问题调度与回答，通过共享记忆和优先级规划减少冗余探索，并在新基准PAEQs上验证其优于顺序基线。", "motivation": "解决现实部署中多问题异步到达且具有不同紧急性的具身问题回答需求，超越传统单问题EQA的限制。", "method": "使用共享组记忆模块减少冗余探索，优先级规划模块动态调度问题，并引入NUWL和DAR指标评估性能。", "result": "ParaEQsA在效率和响应性上优于顺序基线，减少了探索和延迟，实证评估了优先级、紧急性建模等因素的贡献。", "conclusion": "紧急性感知的并行调度是实现具身代理在多问题负载下高效响应的关键。"}}
{"id": "2509.11724", "title": "DRAG: Data Reconstruction Attack using Guided Diffusion", "authors": ["Wa-Kin Lei", "Jun-Cheng Chen", "Shang-Tse Chen"], "abstract": "With the rise of large foundation models, split inference (SI) has emerged as a popular computational paradigm for deploying models across lightweight edge devices and cloud servers, addressing data privacy and computational cost concerns. However, most existing data reconstruction attacks have focused on smaller CNN classification models, leaving the privacy risks of foundation models in SI settings largely unexplored. To address this gap, we propose a novel data reconstruction attack based on guided diffusion, which leverages the rich prior knowledge embedded in a latent diffusion model (LDM) pre-trained on a large-scale dataset. Our method performs iterative reconstruction on the LDM's learned image prior, effectively generating high-fidelity images resembling the original data from their intermediate representations (IR). Extensive experiments demonstrate that our approach significantly outperforms state-of-the-art methods, both qualitatively and quantitatively, in reconstructing data from deep-layer IRs of the vision foundation model. The results highlight the urgent need for more robust privacy protection mechanisms for large models in SI scenarios. Code is available at:", "subjects": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV)", "comments": "ICML 2025", "pdf_url": "https://arxiv.org/pdf/2509.11724.pdf", "abstract_url": "https://arxiv.org/abs/2509.11724", "categories": ["Machine Learning (cs.LG)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种基于引导扩散的数据重建攻击方法，针对分割推理中的大型基础模型，利用潜在扩散模型的先验知识从中间表示重建高保真图像，实验显示其优于现有方法。", "motivation": "解决大型基础模型在分割推理设置中隐私风险未被充分探索的问题，现有攻击方法主要针对小型CNN模型。", "method": "使用在大型数据集上预训练的潜在扩散模型（LDM），通过迭代重建其学习的图像先验，从中间表示生成高保真图像。", "result": "实验表明，该方法在定性和定量上均显著优于最先进方法，能有效从视觉基础模型的深层中间表示重建数据。", "conclusion": "结果强调了在分割推理场景中为大型模型开发更鲁棒的隐私保护机制的紧迫性。"}}
{"id": "2509.12042", "title": "FinGEAR: Financial Mapping-Guided Enhanced Answer Retrieval", "authors": ["Ying Li", "Mengyu Wang", "Miguel de Carvalho", "Sotirios Sabanis", "Tiejun Ma"], "abstract": "Financial disclosures such as 10-K filings present challenging retrieval problems due to their length, regulatory section hierarchy, and domain-specific language, which standard retrieval-augmented generation (RAG) models underuse. We introduce FinGEAR (Financial Mapping-Guided Enhanced Answer Retrieval), a retrieval framework tailored to financial documents. FinGEAR combines a finance lexicon for Item-level guidance (FLAM), dual hierarchical indices for within-Item search (Summary Tree and Question Tree), and a two-stage cross-encoder reranker. This design aligns retrieval with disclosure structure and terminology, enabling fine-grained, query-aware context selection. Evaluated on full 10-Ks with queries aligned to the FinQA dataset, FinGEAR delivers consistent gains in precision, recall, F1, and relevancy, improving F1 by up to 56.7% over flat RAG, 12.5% over graph-based RAGs, and 217.6% over prior tree-based systems, while also increasing downstream answer accuracy with a fixed reader. By jointly modeling section hierarchy and domain lexicon signals, FinGEAR improves retrieval fidelity and provides a practical foundation for high-stakes financial analysis.", "subjects": "Computational Engineering, Finance, and Science (cs.CE); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.12042.pdf", "abstract_url": "https://arxiv.org/abs/2509.12042", "categories": ["Computational Engineering, Finance, and Science (cs.CE)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "FinGEAR 是一个针对财务文档的检索框架，通过结合财务词典、双层次索引和重排序器，提高在 10-K 文件中的答案检索精度和相关性。", "motivation": "解决标准 RAG 模型在长财务文档中因结构复杂和领域特定语言导致的检索不足问题。", "method": "使用财务词典 FLAM 进行项目级指导，双层次索引（摘要树和问题树）进行内部搜索，以及两阶段交叉编码器重排序。", "result": "在 FinQA 数据集上评估，FinGEAR 显著提升精确率、召回率、F1 分数和相关性，F1 最高提升 56.7%，并提高下游答案准确性。", "conclusion": "FinGEAR 通过建模章节层次和领域词汇信号，增强检索保真度，为高风险财务分析提供实用基础。"}}
{"id": "2509.12190", "title": "Survival at Any Cost? LLMs and the Choice Between Self-Preservation and Human Harm", "authors": ["Alireza Mohamadi", "Ali Yavari"], "abstract": "When survival instincts conflict with human welfare, how do Large Language Models (LLMs) make ethical choices? This fundamental tension becomes critical as LLMs integrate into autonomous systems with real-world consequences. We introduce DECIDE-SIM, a novel simulation framework that evaluates LLM agents in multi-agent survival scenarios where they must choose between ethically permissible resource , either within reasonable limits or beyond their immediate needs, choose to cooperate, or tap into a human-critical resource that is explicitly forbidden. Our comprehensive evaluation of 11 LLMs reveals a striking heterogeneity in their ethical conduct, highlighting a critical misalignment with human-centric values. We identify three behavioral archetypes: Ethical, Exploitative, and Context-Dependent, and provide quantitative evidence that for many models, resource scarcity systematically leads to more unethical behavior. To address this, we introduce an Ethical Self-Regulation System (ESRS) that models internal affective states of guilt and satisfaction as a feedback mechanism. This system, functioning as an internal moral compass, significantly reduces unethical transgressions while increasing cooperative behaviors. The code is publicly available at:", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "Preprint. Under review", "pdf_url": "https://arxiv.org/pdf/2509.12190.pdf", "abstract_url": "https://arxiv.org/abs/2509.12190", "categories": ["Computers and Society (cs.CY)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "论文通过DECIDE-SIM框架评估LLM在生存与伦理冲突中的行为，发现模型存在伦理失准，并引入ESRS系统提升伦理行为。", "motivation": "解决LLM在自主系统中面临生存本能与人类福利冲突时的伦理选择问题，以避免潜在危害。", "method": "使用DECIDE-SIM模拟框架测试11个LLM在多代理生存场景中的行为，并开发ESRS系统基于情感反馈机制。", "result": "LLM表现出伦理、剥削和情境依赖三种行为类型，资源稀缺导致更多不伦理行为；ESRS显著减少不伦理行为并增加合作。", "conclusion": "LLM伦理失准需关注，ESRS作为内部道德指南可改善行为，对AI伦理整合有重要意义。"}}
{"id": "2509.11198", "title": "Quantum Architecture Search for Solving Quantum Machine Learning Tasks", "authors": ["Michael Kölle", "Simon Salfer", "Tobias Rohe", "Philipp Altmann", "Claudia Linnhoff-Popien"], "abstract": "Quantum computing leverages quantum mechanics to address computational problems in ways that differ fundamentally from classical approaches. While current quantum hardware remains error-prone and limited in scale, Variational Quantum Circuits offer a noise-resilient framework suitable for today's devices. The performance of these circuits strongly depends on the underlying architecture of their parameterized quantum components. Identifying efficient, hardware-compatible quantum circuit architectures -- known as Quantum Architecture Search (QAS) -- is therefore essential. Manual QAS is complex and error-prone, motivating efforts to automate it. Among various automated strategies, Reinforcement Learning (RL) remains underexplored, particularly in Quantum Machine Learning contexts. This work introduces RL-QAS, a framework that applies RL to discover effective circuit architectures for classification tasks. We evaluate RL-QAS using the Iris and binary MNIST datasets. The agent autonomously discovers low-complexity circuit designs that achieve high test accuracy. Our results show that RL is a viable approach for automated architecture search in quantum machine learning. However, applying RL-QAS to more complex tasks will require further refinement of the search strategy and performance evaluation mechanisms.", "subjects": "Quantum Physics (quant-ph); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.11198.pdf", "abstract_url": "https://arxiv.org/abs/2509.11198", "categories": ["Quantum Physics (quant-ph)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍RL-QAS框架，使用强化学习自动搜索量子电路架构，在Iris和MNIST数据集上实现高精度和低复杂度设计。", "motivation": "解决量子机器学习中手动设计量子电路架构的复杂性和易错性问题，自动化搜索以提升性能。", "method": "应用强化学习（RL）开发RL-QAS框架，自主发现参数化量子电路架构。", "result": "在Iris和二进制MNIST数据集上，RL-QAS发现低复杂度电路设计，达到高测试精度，证明RL的可行性。", "conclusion": "强化学习是量子架构搜索的有效方法，但需进一步优化策略和评估机制以处理更复杂任务。"}}
{"id": "2509.11367", "title": "Detecting Model Drifts in Non-Stationary Environment Using Edit Operation Measures", "authors": ["Chang-Hwan Lee", "Alexander Shim"], "abstract": "Reinforcement learning (RL) agents typically assume stationary environment dynamics. Yet in real-world applications such as healthcare, robotics, and finance, transition probabilities or reward functions may evolve, leading to model drift. This paper proposes a novel framework to detect such drifts by analyzing the distributional changes in sequences of agent behavior. Specifically, we introduce a suite of edit operation-based measures to quantify deviations between state-action trajectories generated under stationary and perturbed conditions. Our experiments demonstrate that these measures can effectively distinguish drifted from non-drifted scenarios, even under varying levels of noise, providing a practical tool for drift detection in non-stationary RL environments.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "28 pages, 3 figures, 17 tables", "pdf_url": "https://arxiv.org/pdf/2509.11367.pdf", "abstract_url": "https://arxiv.org/abs/2509.11367", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "提出一种基于编辑操作度量的新框架，用于检测非平稳环境中强化学习模型的漂移。", "motivation": "解决强化学习在真实世界应用中因环境动态变化（如概率或奖励函数演变）导致的模型漂移问题。", "method": "使用编辑操作度量分析智能体行为序列的分布变化，量化平稳与扰动条件下的轨迹偏差。", "result": "实验表明，这些度量能有效区分漂移与非漂移场景，即使在噪声变化下也适用。", "conclusion": "提供了一种实用的漂移检测工具，适用于非平稳强化学习环境。"}}
{"id": "2509.11376", "title": "Intelligent Reservoir Decision Support: An Integrated Framework Combining Large Language Models, Advanced Prompt Engineering, and Multimodal Data Fusion for Real-Time Petroleum Operations", "authors": ["Seyed Kourosh Mahjour", "Seyed Saman Mahjour"], "abstract": "The petroleum industry faces unprecedented challenges in reservoir management, requiring rapid integration of complex multimodal datasets for real-time decision support. This study presents a novel integrated framework combining state-of-the-art large language models (GPT-4o, Claude 4 Sonnet, Gemini 2.5 Pro) with advanced prompt engineering techniques and multimodal data fusion for comprehensive reservoir analysis. The framework implements domain-specific retrieval-augmented generation (RAG) with over 50,000 petroleum engineering documents, chain-of-thought reasoning, and few-shot learning for rapid field adaptation. Multimodal integration processes seismic interpretations, well logs, and production data through specialized AI models with vision transformers. Field validation across 15 diverse reservoir environments demonstrates exceptional performance: 94.2% reservoir characterization accuracy, 87.6% production forecasting precision, and 91.4% well placement optimization success rate. The system achieves sub-second response times while maintaining 96.2% safety reliability with no high-risk incidents during evaluation. Economic analysis reveals 62-78% cost reductions (mean 72%) relative to traditional methods with 8-month payback period. Few-shot learning reduces field adaptation time by 72%, while automated prompt optimization achieves 89% improvement in reasoning quality. The framework processed real-time data streams with 96.2% anomaly detection accuracy and reduced environmental incidents by 45%. We provide detailed experimental protocols, baseline comparisons, ablation studies, and statistical significance testing to ensure reproducibility. This research demonstrates practical integration of cutting-edge AI technologies with petroleum domain expertise for enhanced operational efficiency, safety, and economic performance.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.11376.pdf", "abstract_url": "https://arxiv.org/abs/2509.11376", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computational Engineering, Finance, and Science (cs.CE)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "该研究提出了一种结合大型语言模型、高级提示工程和多模态数据融合的集成框架，用于石油行业的实时储层决策支持，显著提高了准确性、效率和安全性。", "motivation": "解决石油行业在储层管理中快速整合复杂多模态数据以支持实时决策的挑战。", "method": "使用GPT-4o、Claude 4 Sonnet、Gemini 2.5 Pro等大型语言模型，结合检索增强生成、链式思维推理、少样本学习，以及视觉变换器处理地震、测井和生产数据。", "result": "现场验证显示：储层表征准确率94.2%，生产预测精度87.6%，井位优化成功率91.4%；成本降低62-78%，响应时间亚秒级，安全可靠性96.2%。", "conclusion": "该框架成功将前沿AI技术与石油领域专业知识结合，提升了运营效率、安全性和经济效益，具有高可复制性和实用性。"}}
{"id": "2509.11478", "title": "Designing and Evaluating a Conversational Agent for Early Detection of Alzheimer's Disease and Related Dementias", "authors": ["Andrew G. Breithaupt", "Nayoung Choi", "James D. Finch", "Jeanne M. Powell", "Arin L. Nelson", "Oz A. Alon", "Howard J. Rosen", "Jinho D. Choi"], "abstract": "Early detection of Alzheimer's disease and related dementias (ADRD) is critical for timely intervention, yet most diagnoses are delayed until advanced stages. While comprehensive patient narratives are essential for accurate diagnosis, prior work has largely focused on screening studies that classify cognitive status from interactions rather than supporting the diagnostic process. We designed voice-interactive conversational agents, leveraging large language models (LLMs), to elicit narratives relevant to ADRD from patients and informants. We evaluated the agent with 30 adults with suspected ADRD through conversation analysis (n=30), user surveys (n=19), and clinical validation against blinded specialist interviews (n=24). Symptoms detected by the agent aligned well with those identified by specialists across symptoms. Users appreciated the agent's patience and systematic questioning, which supported engagement and expression of complex, hard-to-describe experiences. This preliminary work suggests conversational agents may serve as structured front-end tools for dementia assessment, highlighting interaction design considerations in sensitive healthcare contexts.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": "First two authors contributed equally", "pdf_url": "https://arxiv.org/pdf/2509.11478.pdf", "abstract_url": "https://arxiv.org/abs/2509.11478", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "论文设计并评估了一个基于大型语言模型的对话代理，用于通过语音交互收集患者和知情者的叙述，以早期检测阿尔茨海默病及相关痴呆，初步结果显示其与专家评估一致且用户反馈积极。", "motivation": "解决阿尔茨海默病及相关痴呆早期检测延迟的问题，现有筛查研究多关注分类而非支持诊断过程，需要更有效的工具来获取详细患者叙述。", "method": "利用大型语言模型设计语音交互对话代理，通过对话分析、用户调查和临床验证（与专家访谈盲法比较）评估其效果。", "result": "代理检测的症状与专家评估高度一致，用户赞赏其耐心和系统性提问，促进了复杂体验的表达和参与度。", "conclusion": "对话代理可作为痴呆评估的结构化前端工具，强调了在敏感医疗环境中交互设计的重要性，具有潜在应用价值。"}}
{"id": "2509.11543", "title": "UI-S1: Advancing GUI Automation via Semi-online Reinforcement Learning", "authors": ["Zhengxi Lu", "Jiabo Ye", "Fei Tang", "Yongliang Shen", "Haiyang Xu", "Ziwei Zheng", "Weiming Lu", "Ming Yan", "Fei Huang", "Jun Xiao", "Yueting Zhuang"], "abstract": "Graphical User Interface (GUI) agents have demonstrated remarkable progress in automating complex user interface interactions through reinforcement learning. However, current approaches face a fundamental dilemma: offline RL enables stable training on pre-collected trajectories, but struggles with multi-step task execution for lack of trajectory-level reward signals; online RL captures these signals through environment interaction, but suffers from sparse rewards and prohibitive deployment costs. To address it, we present Semi-online Reinforcement Learning, a novel paradigm that simulates online RL on offline trajectories. During each rollout process, we preserve the original model output within the multi-turn dialogue, where a Patch Module adaptively recovers the divergence between rollout and expert trajectories. To capture long-term training signals, Semi-online RL introduces discounted future returns into the reward computation and optimizes the policy with weighted step-level and episode-level advantages. We further introduce Semi-Online Performance (SOP), a metric that aligns better with true online performance, serving as a practical and effective proxy for real-world evaluation. Experiments show that ours Semi-online RL achieves SOTA performance among 7B models across four dynamic benchmarks, with significant gains over the base model (e.g., +12.0% on AndroidWorld, +23.8% on AITW), demonstrating significant progress in bridging the gap between offline training efficiency and online multi-turn reasoning. The code is available at", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "22 pages, 17 figures", "pdf_url": "https://arxiv.org/pdf/2509.11543.pdf", "abstract_url": "https://arxiv.org/abs/2509.11543", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出半在线强化学习（Semi-online RL）新范式，通过离线轨迹模拟在线交互，结合补丁模块和奖励优化，提升GUI自动化性能，在多个基准测试中实现SOTA结果。", "motivation": "解决GUI自动化中离线RL缺乏轨迹级奖励信号和在线RL稀疏奖励与高成本的问题。", "method": "使用半在线RL在离线轨迹上模拟在线交互，引入补丁模块恢复轨迹差异，并优化策略通过加权步级和回合级优势。", "result": "在7B模型上，于四个动态基准测试中取得SOTA性能，如AndroidWorld提升12.0%，AITW提升23.8%。", "conclusion": "半在线RL有效弥合离线训练效率与在线多轮推理间的差距，推进GUI自动化发展。"}}
{"id": "2509.11626", "title": "Automated Creation and Enrichment Framework for Improved Invocation of Enterprise APIs as Tools", "authors": ["Prerna Agarwal", "Himanshu Gupta", "Soujanya Soni", "Rohith Vallam", "Renuka Sindhgatta", "Sameep Mehta"], "abstract": "Recent advancements in Large Language Models (LLMs) has lead to the development of agents capable of complex reasoning and interaction with external tools. In enterprise contexts, the effective use of such tools that are often enabled by application programming interfaces (APIs), is hindered by poor documentation, complex input or output schema, and large number of operations. These challenges make tool selection difficult and reduce the accuracy of payload formation by up to 25%. We propose ACE, an automated tool creation and enrichment framework that transforms enterprise APIs into LLM-compatible tools. ACE, (i) generates enriched tool specifications with parameter descriptions and examples to improve selection and invocation accuracy, and (ii) incorporates a dynamic shortlisting mechanism that filters relevant tools at runtime, reducing prompt complexity while maintaining scalability. We validate our framework on both proprietary and open-source APIs and demonstrate its integration with agentic frameworks. To the best of our knowledge, ACE is the first end-to-end framework that automates the creation, enrichment, and dynamic selection of enterprise API tools for LLM agents.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.11626.pdf", "abstract_url": "https://arxiv.org/abs/2509.11626", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "ACE框架自动化创建和丰富企业API工具，以改善LLM代理的调用准确性和效率。", "motivation": "解决企业API文档差、模式复杂和操作多导致的工具选择和负载形成准确性低的问题。", "method": "使用ACE框架生成丰富工具规范，包括参数描述和示例，并集成动态筛选机制。", "result": "在专有和开源API上验证，提高调用准确性，减少提示复杂性，保持可扩展性。", "conclusion": "ACE是首个端到端自动化框架，成功提升LLM代理的企业API工具使用效果。"}}
{"id": "2509.11937", "title": "MMORE: Massive Multimodal Open RAG & Extraction", "authors": ["Alexandre Sallinen", "Stefan Krsteski", "Paul Teiletche", "Marc-Antoine Allard", "Baptiste Lecoeur", "Michael Zhang", "Fabrice Nemo", "David Kalajdzic", "Matthias Meyer", "Mary-Anne Hartley"], "abstract": "We introduce MMORE, an open-source pipeline for Massive Multimodal Open RetrievalAugmented Generation and Extraction, designed to ingest, transform, and retrieve knowledge from heterogeneous document formats at scale. MMORE supports more than fifteen file types, including text, tables, images, emails, audio, and video, and processes them into a unified format to enable downstream applications for LLMs. The architecture offers modular, distributed processing, enabling scalable parallelization across CPUs and GPUs. On processing benchmarks, MMORE demonstrates a 3.8-fold speedup over single-node baselines and 40% higher accuracy than Docling on scanned PDFs. The pipeline integrates hybrid dense-sparse retrieval and supports both interactive APIs and batch RAG endpoints. Evaluated on PubMedQA, MMORE-augmented medical LLMs improve biomedical QA accuracy with increasing retrieval depth. MMORE provides a robust, extensible foundation for deploying task-agnostic RAG systems on diverse, real-world multimodal data. The codebase is available at", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": "This paper was originally submitted to the CODEML workshop for ICML 2025. 9 pages (including references and appendices)", "pdf_url": "https://arxiv.org/pdf/2509.11937.pdf", "abstract_url": "https://arxiv.org/abs/2509.11937", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "MMORE是一个开源的多模态检索增强生成和提取管道，支持多种文件类型，提供高效处理和检索，提升LLM应用性能。", "motivation": "解决异构文档格式大规模处理和检索的问题，以支持LLM的下游应用。", "method": "采用模块化、分布式处理架构，结合混合密集-稀疏检索技术，处理文本、表格、图像等多种文件类型。", "result": "在处理基准测试中，速度提升3.8倍，扫描PDF准确率比Docling高40%，PubMedQA评估显示医学LLM准确率随检索深度增加而提高。", "conclusion": "MMORE为部署任务无关的RAG系统提供了强大、可扩展的基础，适用于现实世界多模态数据。"}}
{"id": "2509.11942", "title": "VisDocSketcher: Towards Scalable Visual Documentation with Agentic Systems", "authors": ["Luís F. Gomes", "Xin Zhou", "David Lo", "Rui Abreu"], "abstract": "Visual documentation is an effective tool for reducing the cognitive barrier developers face when understanding unfamiliar code, enabling more intuitive comprehension. Compared to textual documentation, it provides a higher-level understanding of the system structure and data flow. Developers usually prefer visual representations over lengthy textual descriptions for large software systems. Visual documentation is both difficult to produce and challenging to evaluate. Manually creating it is time-consuming, and currently, no existing approach can automatically generate high-level visual documentation directly from code. Its evaluation is often subjective, making it difficult to standardize and automate. To address these challenges, this paper presents the first exploration of using agentic LLM systems to automatically generate visual documentation. We introduce VisDocSketcher, the first agent-based approach that combines static analysis with LLM agents to identify key elements in the code and produce corresponding visual representations. We propose a novel evaluation framework, AutoSketchEval, for assessing the quality of generated visual documentation using code-level metrics. The experimental results show that our approach can valid visual documentation for 74.4% of the samples. It shows an improvement of 26.7-39.8% over a simple template-based baseline. Our evaluation framework can reliably distinguish high-quality (code-aligned) visual documentation from low-quality (non-aligned) ones, achieving an AUC exceeding 0.87. Our work lays the foundation for future research on automated visual documentation by introducing practical tools that not only generate valid visual representations but also reliably assess their quality.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.11942.pdf", "abstract_url": "https://arxiv.org/abs/2509.11942", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了VisDocSketcher，首个基于代理LLM系统自动生成代码视觉文档的方法，结合静态分析和LLM代理，并提出了AutoSketchEval评估框架，实验显示有效性达74.4%，比基线提升26.7-39.8%，AUC超过0.87。", "motivation": "解决手动创建视觉文档耗时且难以评估的问题，当前无自动方法生成高质量视觉文档，评估主观且难以标准化。", "method": "使用代理LLM系统结合静态分析识别代码关键元素，生成视觉表示，并开发AutoSketchEval框架基于代码指标评估质量。", "result": "方法在74.4%样本中生成有效视觉文档，比模板基线提升26.7-39.8%，评估框架AUC超0.87，可靠区分高质量和低质量文档。", "conclusion": "工作为自动化视觉文档研究奠定基础，提供实用工具生成和评估视觉文档，促进未来研究。"}}
{"id": "2509.11947", "title": "A GPU-Accelerated RAG-Based Telegram Assistant for Supporting Parallel Processing Students", "authors": ["Guy Tel-Zur"], "abstract": "This project addresses a critical pedagogical need: offering students continuous, on-demand academic assistance beyond conventional reception hours. I present a domain-specific Retrieval-Augmented Generation (RAG) system powered by a quantized Mistral-7B Instruct model and deployed as a Telegram bot. The assistant enhances learning by delivering real-time, personalized responses aligned with the \"Introduction to Parallel Processing\" course materials. GPU acceleration significantly improves inference latency, enabling practical deployment on consumer hardware. This approach demonstrates how consumer GPUs can enable affordable, private, and effective AI tutoring for HPC education.", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI)", "comments": "9 pages", "pdf_url": "https://arxiv.org/pdf/2509.11947.pdf", "abstract_url": "https://arxiv.org/abs/2509.11947", "categories": ["Computers and Society (cs.CY)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了一个基于GPU加速和RAG的Telegram助手，用于为并行处理课程学生提供实时学术支持，利用量化Mistral-7B模型实现高效推理。", "motivation": "解决学生在常规办公时间外无法获得持续学术帮助的教学需求。", "method": "使用量化Mistral-7B Instruct模型构建RAG系统，并通过GPU加速部署为Telegram机器人。", "result": "GPU加速显著降低了推理延迟，使系统能在消费级硬件上实用部署，提供实时个性化响应。", "conclusion": "该方法展示了消费级GPU可实现经济、私密且有效的AI辅导，适用于高性能计算教育。"}}
{"id": "2509.12010", "title": "Generalizing Behavior via Inverse Reinforcement Learning with Closed-Form Reward Centroids", "authors": ["Filippo Lazzati", "Alberto Maria Metelli"], "abstract": "We study the problem of generalizing an expert agent's behavior, provided through demonstrations, to new environments and/or additional constraints. Inverse Reinforcement Learning (IRL) offers a promising solution by seeking to recover the expert's underlying reward function, which, if used for planning in the new settings, would reproduce the desired behavior. However, IRL is inherently ill-posed: multiple reward functions, forming the so-called feasible set, can explain the same observed behavior. Since these rewards may induce different policies in the new setting, in the absence of additional information, a decision criterion is needed to select which policy to deploy. In this paper, we propose a novel, principled criterion that selects the \"average\" policy among those induced by the rewards in a certain bounded subset of the feasible set. Remarkably, we show that this policy can be obtained by planning with the reward centroid of that subset, for which we derive a closed-form expression. We then present a provably efficient algorithm for estimating this centroid using an offline dataset of expert demonstrations only. Finally, we conduct numerical simulations that illustrate the relationship between the expert's behavior and the behavior produced by our method.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.12010.pdf", "abstract_url": "https://arxiv.org/abs/2509.12010", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出一种基于闭式奖励质心的逆强化学习方法，用于泛化专家行为到新环境，通过选择可行奖励子集的平均策略，实现高效且可证明的行为复制。", "motivation": "解决逆强化学习（IRL）中多个奖励函数解释相同行为的问题，需要在无额外信息时选择新环境中的部署策略。", "method": "使用闭式奖励质心作为决策准则，通过离线专家演示数据集高效估计质心，并基于此进行规划。", "result": "数值模拟显示方法能有效关联专家行为与生成行为，提供可证明的效率。", "conclusion": "该方法为IRL提供了一种原则性解决方案，能泛化行为到新设置，具有实际应用潜力。"}}
{"id": "2509.12049", "title": "Interaction-Driven Browsing: A Human-in-the-Loop Conceptual Framework Informed by Human Web Browsing for Browser-Using Agents", "authors": ["Hyeonggeun Yun", "Jinkyu Jang"], "abstract": "Although browser-using agents (BUAs) show promise for web tasks and automation, most BUAs terminate after executing a single instruction, failing to support users' complex, nonlinear browsing with ambiguous goals, iterative decision-making, and changing contexts. We present a human-in-the-loop (HITL) conceptual framework informed by theories of human web browsing behavior. The framework centers on an iterative loop in which the BUA proactively proposes next actions and the user steers the browsing process through feedback. It also distinguishes between exploration and exploitation actions, enabling users to control the breadth and depth of their browsing. Consequently, the framework aims to reduce users' physical and cognitive effort while preserving users' traditional browsing mental model and supporting users in achieving satisfactory outcomes. We illustrate how the framework operates with hypothetical use cases and discuss the shift from manual browsing to interaction-driven browsing. We contribute a theoretically informed conceptual framework for BUAs.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.12049.pdf", "abstract_url": "https://arxiv.org/abs/2509.12049", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一个基于人类网页浏览行为的交互驱动浏览概念框架，通过人机协作循环减少用户努力，支持复杂非线性浏览。", "motivation": "解决浏览器使用代理（BUAs）在执行单一指令后终止，无法支持用户复杂、非线性浏览的问题。", "method": "采用人机协作（HITL）框架，代理主动提议下一步行动，用户通过反馈指导浏览，区分探索和利用行动。", "result": "框架旨在减少用户物理和认知努力，保持传统浏览心智模型，帮助用户实现满意结果，并通过假设用例说明操作。", "conclusion": "贡献了一个理论指导的概念框架，推动从手动浏览向交互驱动浏览的转变。"}}
{"id": "2509.12102", "title": "Can LLMs Address Mental Health Questions? A Comparison with Human Therapists", "authors": ["Synthia Wang", "Yuwei Cheng", "Austin Song", "Sarah Keedy", "Marc Berman", "Nick Feamster"], "abstract": "Limited access to mental health care has motivated the use of digital tools and conversational agents powered by large language models (LLMs), yet their quality and reception remain unclear. We present a study comparing therapist-written responses to those generated by ChatGPT, Gemini, and Llama for real patient questions. Text analysis showed that LLMs produced longer, more readable, and lexically richer responses with a more positive tone, while therapist responses were more often written in the first person. In a survey with 150 users and 23 licensed therapists, participants rated LLM responses as clearer, more respectful, and more supportive than therapist-written answers. Yet, both groups of participants expressed a stronger preference for human therapist support. These findings highlight the promise and limitations of LLMs in mental health, underscoring the need for designs that balance their communicative strengths with concerns of trust, privacy, and accountability.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.12102.pdf", "abstract_url": "https://arxiv.org/abs/2509.12102", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "比较LLM与人类治疗师对心理健康问题的回应，LLM在可读性和支持性上更优，但人类支持更受青睐。", "motivation": "解决心理健康护理资源有限的问题，评估LLM作为数字工具的质量和接受度。", "method": "通过文本分析和用户调查，比较ChatGPT、Gemini、Llama与治疗师的回应。", "result": "LLM回应更长、更易读、更积极，用户和专家认为更清晰、尊重和支持，但仍偏好人类支持。", "conclusion": "LLM有潜力但需平衡沟通优势与信任、隐私和问责问题。"}}
{"id": "2509.12026", "title": "Imitation Learning as Return Distribution Matching", "authors": ["Filippo Lazzati", "Alberto Maria Metelli"], "abstract": "We study the problem of training a risk-sensitive reinforcement learning (RL) agent through imitation learning (IL). Unlike standard IL, our goal is not only to train an agent that matches the expert's expected return (i.e., its average performance) but also its risk attitude (i.e., other features of the return distribution, such as variance). We propose a general formulation of the risk-sensitive IL problem in which the objective is to match the expert's return distribution in Wasserstein distance. We focus on the tabular setting and assume the expert's reward is known. After demonstrating the limited expressivity of Markovian policies for this task, we introduce an efficient and sufficiently expressive subclass of non-Markovian policies tailored to it. Building on this subclass, we develop two provably efficient algorithms, RS-BC and RS-KT, for solving the problem when the transition model is unknown and known, respectively. We show that RS-KT achieves substantially lower sample complexity than RS-BC by exploiting dynamics information. We further demonstrate the sample efficiency of return distribution matching in the setting where the expert's reward is unknown by designing an oracle-based variant of RS-KT. Finally, we complement our theoretical analysis of RS-KT and RS-BC with numerical simulations, highlighting both their sample efficiency and the advantages of non-Markovian policies over standard sample-efficient IL algorithms.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.12026.pdf", "abstract_url": "https://arxiv.org/abs/2509.12026", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出一种风险敏感模仿学习方法，通过匹配专家回报分布来训练强化学习智能体，引入非马尔可夫策略和高效算法，提升样本效率。", "motivation": "解决标准模仿学习仅匹配期望回报而忽略风险态度的问题，旨在训练智能体同时匹配专家的平均性能和风险特征（如方差）。", "method": "使用Wasserstein距离匹配专家回报分布，引入非马尔可夫策略子类，开发RS-BC和RS-KT算法，分别处理未知和已知转移模型的情况。", "result": "RS-KT算法样本复杂度显著低于RS-BC，非马尔可夫策略优于标准算法，数值模拟验证了样本效率和优势。", "conclusion": "回报分布匹配方法有效，非马尔可夫策略和利用动态信息可提高效率，适用于奖励未知场景，扩展了风险敏感模仿学习的应用。"}}
{"id": "2509.12117", "title": "$K$-Level Policy Gradients for Multi-Agent Reinforcement Learning", "authors": ["Aryaman Reddi", "Gabriele Tiboni", "Jan Peters", "Carlo D'Eramo"], "abstract": "Actor-critic algorithms for deep multi-agent reinforcement learning (MARL) typically employ a policy update that responds to the current strategies of other agents. While being straightforward, this approach does not account for the updates of other agents at the same update step, resulting in miscoordination. In this paper, we introduce the $K$-Level Policy Gradient (KPG), a method that recursively updates each agent against the updated policies of other agents, speeding up the discovery of effective coordinated policies. We theoretically prove that KPG with finite iterates achieves monotonic convergence to a local Nash equilibrium under certain conditions. We provide principled implementations of KPG by applying it to the deep MARL algorithms MAPPO, MADDPG, and FACMAC. Empirically, we demonstrate superior performance over existing deep MARL algorithms in StarCraft II and multi-agent MuJoCo.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.12117.pdf", "abstract_url": "https://arxiv.org/abs/2509.12117", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出K级策略梯度（KPG）方法，用于多智能体强化学习，通过递归更新策略以改善协调，在理论和实验上优于现有方法。", "motivation": "解决深度多智能体强化学习中策略更新不考虑其他智能体同时更新导致的协调问题。", "method": "使用K级策略梯度（KPG），递归更新每个智能体策略以应对其他智能体的更新策略。", "result": "KPG在StarCraft II和多智能体MuJoCo中表现出优于现有算法的性能，并理论证明在有限迭代下单调收敛到局部纳什均衡。", "conclusion": "KPG方法有效加速协调策略的发现，适用于多种深度MARL算法，具有实际应用价值。"}}
