{"id": "2505.21898", "title": "Co-Saving: Resource Aware Multi-Agent Collaboration for Software Development", "authors": ["Rennai Qiu", "Chen Qian", "Ran Li", "Yufan Dang", "Weize Chen", "Cheng Yang", "Yingli Zhang", "Ye Tian", "Xuantang Xiong", "Lei Han", "Zhiyuan Liu", "Maosong Sun"], "abstract": "Recent advancements in Large Language Models (LLMs) and autonomous agents have demonstrated remarkable capabilities across various domains. However, standalone agents frequently encounter limitations when handling complex tasks that demand extensive interactions and substantial computational resources. Although Multi-Agent Systems (MAS) alleviate some of these limitations through collaborative mechanisms like task decomposition, iterative communication, and role specialization, they typically remain resource-unaware, incurring significant inefficiencies due to high token consumption and excessive execution time. To address these limitations, we propose a resource-aware multi-agent system -- Co-Saving (meaning that multiple agents collaboratively engage in resource-saving activities), which leverages experiential knowledge to enhance operational efficiency and solution quality. Our key innovation is the introduction of \"shortcuts\" -- instructional transitions learned from historically successful trajectories -- which allows to bypass redundant reasoning agents and expedite the collective problem-solving process. Experiments for software development tasks demonstrate significant advantages over existing methods. Specifically, compared to the state-of-the-art MAS ChatDev, our method achieves an average reduction of 50.85% in token usage, and improves the overall code quality by 10.06%.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA); Software Engineering (cs.SE)", "comments": "Work in Progress", "pdf_url": "https://arxiv.org/pdf/2505.21898.pdf", "abstract_url": "https://arxiv.org/abs/2505.21898", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)", "Software Engineering (cs.SE)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种资源感知的多代理协作系统Co-Saving，旨在通过利用经验知识来提高操作效率和解决方案质量，特别是在软件开发任务中显著减少了令牌使用并提高了代码质量。", "motivation": "解决大型语言模型（LLMs）和自主代理在处理需要大量交互和计算资源的复杂任务时的局限性，以及多代理系统（MAS）因高令牌消耗和执行时间过长而导致的效率低下问题。", "method": "引入了“捷径”——从历史上成功的轨迹中学到的指令转换，以绕过冗余的推理代理并加速集体问题解决过程。", "result": "与最先进的多代理系统ChatDev相比，Co-Saving平均减少了50.85%的令牌使用，并将整体代码质量提高了10.06%。", "conclusion": "Co-Saving通过资源感知和经验知识的利用，显著提高了多代理协作的效率和解决方案的质量，为复杂任务的自动化处理提供了新的可能性。"}}
{"id": "2505.21870", "title": "Evaluating the Retrieval Robustness of Large Language Models", "authors": ["Shuyang Cao", "Karthik Radhakrishnan", "David Rosenberg", "Steven Lu", "Pengxiang Cheng", "Lu Wang", "Shiyue Zhang"], "abstract": "Retrieval-augmented generation (RAG) generally enhances large language models' (LLMs) ability to solve knowledge-intensive tasks. But RAG may also lead to performance degradation due to imperfect retrieval and the model's limited ability to leverage retrieved content. In this work, we evaluate the robustness of LLMs in practical RAG setups (henceforth retrieval robustness). We focus on three research questions: (1) whether RAG is always better than non-RAG; (2) whether more retrieved documents always lead to better performance; (3) and whether document orders impact results. To facilitate this study, we establish a benchmark of 1500 open-domain questions, each with retrieved documents from Wikipedia. We introduce three robustness metrics, each corresponds to one research question. Our comprehensive experiments, involving 11 LLMs and 3 prompting strategies, reveal that all of these LLMs exhibit surprisingly high retrieval robustness; nonetheless, different degrees of imperfect robustness hinders them from fully utilizing the benefits of RAG.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "19 pages", "pdf_url": "https://arxiv.org/pdf/2505.21870.pdf", "abstract_url": "https://arxiv.org/abs/2505.21870", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文评估了大型语言模型（LLMs）在实际检索增强生成（RAG）设置中的检索鲁棒性，探讨了RAG是否总是优于非RAG、更多检索文档是否总是带来更好性能以及文档顺序是否影响结果三个问题。通过建立包含1500个开放域问题的基准测试，并引入三个鲁棒性指标，研究发现所有测试的LLMs都表现出较高的检索鲁棒性，但不同程度的缺陷阻碍了它们充分利用RAG的优势。", "motivation": "解决检索增强生成（RAG）可能因不完美的检索和模型利用检索内容能力有限而导致性能下降的问题，评估LLMs在实际RAG设置中的检索鲁棒性。", "method": "建立包含1500个开放域问题的基准测试，每个问题配有从Wikipedia检索的文档，引入三个鲁棒性指标对应三个研究问题，进行涉及11个LLMs和3种提示策略的综合实验。", "result": "所有测试的LLMs都表现出较高的检索鲁棒性，但不同程度的缺陷阻碍了它们充分利用RAG的优势。", "conclusion": "尽管LLMs在实际RAG设置中表现出较高的检索鲁棒性，但不同程度的缺陷限制了它们从RAG中获得的全部好处，这为未来改进LLMs的检索利用能力提供了方向。"}}
{"id": "2505.21757", "title": "BehaviorSFT: Behavioral Token Conditioning for Clinical Agents Across the Proactivity Spectrum", "authors": ["Yubin Kim", "Zhiyuan Hu", "Hyewon Jeong", "Eugene Park", "Shuyue Stella Li", "Chanwoo Park", "Shiyun Xiong", "MingYu Lu", "Hyeonhoon Lee", "Xin Liu", "Daniel McDuff", "Cynthia Breazeal", "Samir Tulebaev", "Hae Won Park"], "abstract": "Large Language Models (LLMs) as clinical agents require careful behavioral adaptation. While adept at reactive tasks (e.g., diagnosis reasoning), LLMs often struggle with proactive engagement, like unprompted identification of critical missing information or risks. We introduce BehaviorBench, a comprehensive dataset to evaluate agent behaviors across a clinical assistance spectrum, ranging from reactive query responses to proactive interventions (e.g., clarifying ambiguities, flagging overlooked critical data). Our BehaviorBench experiments reveal LLMs' inconsistent proactivity. To address this, we propose BehaviorSFT, a novel training strategy using behavioral tokens to explicitly condition LLMs for dynamic behavioral selection along this spectrum. BehaviorSFT boosts performance, achieving up to 97.3% overall Macro F1 on BehaviorBench and improving proactive task scores (e.g., from 95.0% to 96.5% for Qwen2.5-7B-Ins). Crucially, blind clinician evaluations confirmed BehaviorSFT-trained agents exhibit more realistic clinical behavior, striking a superior balance between helpful proactivity (e.g., timely, relevant suggestions) and necessary restraint (e.g., avoiding over-intervention) versus standard fine-tuning or explicit instructed agents.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.21757.pdf", "abstract_url": "https://arxiv.org/abs/2505.21757", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了BehaviorSFT，一种通过行为令牌调节临床代理行为的新训练策略，旨在解决大型语言模型（LLMs）在临床代理中从反应性任务到主动性干预的行为适应问题。", "motivation": "大型语言模型（LLMs）作为临床代理在反应性任务（如诊断推理）中表现良好，但在主动性干预（如未提示的关键信息识别）方面存在困难。", "method": "提出了BehaviorSFT训练策略，使用行为令牌明确调节LLMs，以实现沿临床辅助频谱的动态行为选择。", "result": "BehaviorSFT在BehaviorBench上的总体Macro F1达到97.3%，并提高了主动性任务得分（如Qwen2.5-7B-Ins从95.0%提高到96.5%）。临床医生盲评确认BehaviorSFT训练的代理展现出更现实的临床行为。", "conclusion": "BehaviorSFT通过行为令牌调节，显著提升了LLMs在临床代理中的行为适应能力，实现了帮助性主动性和必要克制之间的优越平衡。"}}
{"id": "2505.21940", "title": "RISE: Reasoning Enhancement via Iterative Self-Exploration in Multi-hop Question Answering", "authors": ["Bolei He", "Xinran He", "Mengke Chen", "Xianwei Xue", "Ying Zhu", "Zhenhua Ling"], "abstract": "Large Language Models (LLMs) excel in many areas but continue to face challenges with complex reasoning tasks, such as Multi-Hop Question Answering (MHQA). MHQA requires integrating evidence from diverse sources while managing intricate logical dependencies, often leads to errors in reasoning. Retrieval-Augmented Generation (RAG), widely employed in MHQA tasks, faces challenges in effectively filtering noisy data and retrieving all necessary evidence, thereby limiting its effectiveness in addressing MHQA challenges. To address these challenges, we propose RISE:Reasoning Enhancement via Iterative Self-Exploration, a novel framework designed to enhance models' reasoning capability through iterative self-exploration. Specifically, RISE involves three key steps in addressing MHQA tasks: question decomposition, retrieve-then-read, and self-critique. By leveraging continuous self-exploration, RISE identifies accurate reasoning paths, iteratively self-improving the model's capability to integrate evidence, maintain logical consistency, and enhance performance in MHQA tasks. Extensive experiments on multiple MHQA benchmarks demonstrate that RISE significantly improves reasoning accuracy and task performance.", "subjects": "Computation and Language (cs.CL)", "comments": "ACL 2025 Findings", "pdf_url": "https://arxiv.org/pdf/2505.21940.pdf", "abstract_url": "https://arxiv.org/abs/2505.21940", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了RISE框架，通过迭代自我探索增强大型语言模型在复杂推理任务中的能力，特别是在多跳问答任务中。", "motivation": "大型语言模型在复杂推理任务如多跳问答中面临挑战，特别是在整合多样证据和管理复杂逻辑依赖时容易出错。检索增强生成方法在多跳问答任务中难以有效过滤噪声数据并检索所有必要证据，限制了其效果。", "method": "RISE框架通过问题分解、检索后阅读和自我批评三个关键步骤，利用持续的自我探索来识别准确的推理路径，迭代自我提升模型整合证据、保持逻辑一致性的能力。", "result": "在多个多跳问答基准测试上的广泛实验表明，RISE显著提高了推理准确性和任务性能。", "conclusion": "RISE通过迭代自我探索有效增强了模型在多跳问答任务中的推理能力，为复杂推理任务提供了一种新的解决方案。"}}
{"id": "2505.21936", "title": "RedTeamCUA: Realistic Adversarial Testing of Computer-Use Agents in Hybrid Web-OS Environments", "authors": ["Zeyi Liao", "Jaylen Jones", "Linxi Jiang", "Eric Fosler-Lussier", "Yu Su", "Zhiqiang Lin", "Huan Sun"], "abstract": "Computer-use agents (CUAs) promise to automate complex tasks across operating systems (OS) and the web, but remain vulnerable to indirect prompt injection. Current evaluations of this threat either lack support realistic but controlled environments or ignore hybrid web-OS attack scenarios involving both interfaces. To address this, we propose RedTeamCUA, an adversarial testing framework featuring a novel hybrid sandbox that integrates a VM-based OS environment with Docker-based web platforms. Our sandbox supports key features tailored for red teaming, such as flexible adversarial scenario configuration, and a setting that decouples adversarial evaluation from navigational limitations of CUAs by initializing tests directly at the point of an adversarial injection. Using RedTeamCUA, we develop RTC-Bench, a comprehensive benchmark with 864 examples that investigate realistic, hybrid web-OS attack scenarios and fundamental security vulnerabilities. Benchmarking current frontier CUAs identifies significant vulnerabilities: Claude 3.7 Sonnet | CUA demonstrates an ASR of 42.9%, while Operator, the most secure CUA evaluated, still exhibits an ASR of 7.6%. Notably, CUAs often attempt to execute adversarial tasks with an Attempt Rate as high as 92.5%, although failing to complete them due to capability limitations. Nevertheless, we observe concerning ASRs of up to 50% in realistic end-to-end settings, with the recently released frontier Claude 4 Opus | CUA showing an alarming ASR of 48%, demonstrating that indirect prompt injection presents tangible risks for even advanced CUAs despite their capabilities and safeguards. Overall, RedTeamCUA provides an essential framework for advancing realistic, controlled, and systematic analysis of CUA vulnerabilities, highlighting the urgent need for robust defenses to indirect prompt injection prior to real-world deployment.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.21936.pdf", "abstract_url": "https://arxiv.org/abs/2505.21936", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "RedTeamCUA是一个针对计算机使用代理（CUAs）在混合Web-OS环境中进行现实对抗性测试的框架，提出了一个新颖的混合沙盒，用于评估间接提示注入的威胁。", "motivation": "当前对计算机使用代理（CUAs）的评估要么缺乏支持现实但受控的环境，要么忽略了涉及Web和OS接口的混合攻击场景，RedTeamCUA旨在解决这一问题。", "method": "提出了RedTeamCUA框架，包括一个集成了基于VM的OS环境和基于Docker的Web平台的新颖混合沙盒，支持灵活的对抗性场景配置和直接从对抗性注入点初始化测试的设置。", "result": "通过RTC-Bench基准测试发现，当前前沿的CUAs存在显著漏洞，Claude 3.7 Sonnet | CUA的ASR为42.9%，Operator的ASR为7.6%。在现实的端到端设置中，ASR高达50%，Claude 4 Opus | CUA的ASR为48%。", "conclusion": "RedTeamCUA为推进对CUA漏洞的现实、受控和系统分析提供了重要框架，强调了在现实世界部署前对间接提示注入进行强大防御的紧迫需求。"}}
{"id": "2505.21963", "title": "LaMDAgent: An Autonomous Framework for Post-Training Pipeline Optimization via LLM Agents", "authors": ["Taro Yano", "Yoichi Ishibashi", "Masafumi Oyamada"], "abstract": "Large Language Models (LLMs) have demonstrated exceptional performance across a wide range of tasks. To further tailor LLMs to specific domains or applications, post-training techniques such as Supervised Fine-Tuning (SFT), Preference Learning, and model merging are commonly employed. While each of these methods has been extensively studied in isolation, the automated construction of complete post-training pipelines remains an underexplored area. Existing approaches typically rely on manual design or focus narrowly on optimizing individual components, such as data ordering or merging strategies. In this work, we introduce LaMDAgent (short for Language Model Developing Agent), a novel framework that autonomously constructs and optimizes full post-training pipelines through the use of LLM-based agents. LaMDAgent systematically explores diverse model generation techniques, datasets, and hyperparameter configurations, leveraging task-based feedback to discover high-performing pipelines with minimal human intervention. Our experiments show that LaMDAgent improves tool-use accuracy by 9.0 points while preserving instruction-following capabilities. Moreover, it uncovers effective post-training strategies that are often overlooked by conventional human-driven exploration. We further analyze the impact of data and model size scaling to reduce computational costs on the exploration, finding that model size scalings introduces new challenges, whereas scaling data size enables cost-effective pipeline discovery.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.21963.pdf", "abstract_url": "https://arxiv.org/abs/2505.21963", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "LaMDAgent是一个自主框架，通过LLM代理自动构建和优化完整的后训练管道，以提高特定领域或应用的性能。", "motivation": "解决后训练技术（如监督微调、偏好学习和模型合并）在自动化构建完整后训练管道方面的不足，现有方法多依赖人工设计或仅优化单个组件。", "method": "引入LaMDAgent框架，利用基于LLM的代理系统地探索多样化的模型生成技术、数据集和超参数配置，通过任务反馈发现高性能管道。", "result": "实验显示，LaMDAgent在保持指令跟随能力的同时，提高了工具使用准确性9.0个百分点，并发现了传统人工探索常忽略的有效后训练策略。", "conclusion": "LaMDAgent通过自主优化后训练管道，显著提升了模型性能，同时分析了数据和模型规模扩展对计算成本的影响，为高效管道发现提供了新思路。"}}
{"id": "2505.21979", "title": "Pearl: A Multimodal Culturally-Aware Arabic Instruction Dataset", "authors": ["Fakhraddin Alwajih", "Samar Mohamed Magdy", "Abdellah El Mekki", "Omer Nacar", "Youssef Nafea", "Safaa Taher Abdelfadil", "Abdulfattah Mohammed Yahya", "Hamzah Luqman", "Nada Almarwani", "Samah Aloufi", "Baraah Qawasmeh", "Houdaifa Atou", "Serry Sibaee", "Hamzah A. Alsayadi", "Walid Al-Dhabyani", "Maged S. Al-shaibani", "Aya El aatar", "Nour Qandos", "Rahaf Alhamouri", "Samar Ahmad", "Razan Khassib", "Lina Hamad", "Mohammed Anwar AL-Ghrawi", "Fatimah Alshamari", "Cheikh Malainine", "Doaa Qawasmeh", "Aminetou Yacoub", "Tfeil moilid", "Ruwa AbuHweidi", "Ahmed Aboeitta", "Vatimetou Mohamed Lemin", "Reem Abdel-Salam", "Ahlam Bashiti", "Adel Ammar", "Aisha Alansari", "Ahmed Ashraf", "Nora Alturayeif", "Sara Shatnawi", "Alcides Alcoba Inciarte", "AbdelRahim A. Elmadany", "Mohamedou cheikh tourad", "Ismail Berrada", "Mustafa Jarrar", "Shady Shehata", "Muhammad Abdul-Mageed"], "abstract": "Mainstream large vision-language models (LVLMs) inherently encode cultural biases, highlighting the need for diverse multimodal datasets. To address this gap, we introduce Pearl, a large-scale Arabic multimodal dataset and benchmark explicitly designed for cultural understanding. Constructed through advanced agentic workflows and extensive human-in-the-loop annotations by 45 annotators from across the Arab world, Pearl comprises over K multimodal examples spanning ten culturally significant domains covering all Arab countries. We further provide two robust evaluation benchmarks Pearl and Pearl-Lite along with a specialized subset Pearl-X explicitly developed to assess nuanced cultural variations. Comprehensive evaluations on state-of-the-art open and proprietary LVLMs demonstrate that reasoning-centric instruction alignment substantially improves models' cultural grounding compared to conventional scaling methods. Pearl establishes a foundational resource for advancing culturally-informed multimodal modeling research. All datasets and benchmarks are publicly available.", "subjects": "Computation and Language (cs.CL)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.21979.pdf", "abstract_url": "https://arxiv.org/abs/2505.21979", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "Pearl是一个大规模阿拉伯多模态数据集和基准，专为文化理解设计，旨在解决主流大型视觉语言模型中的文化偏见问题。", "motivation": "主流大型视觉语言模型（LVLMs）固有地编码文化偏见，凸显了对多样化多模态数据集的需求。", "method": "通过先进的代理工作流程和来自阿拉伯世界45位注释者的广泛人工参与注释，构建了包含超过K个多模态示例的Pearl数据集，涵盖所有阿拉伯国家的十个文化重要领域。", "result": "综合评估表明，与传统的扩展方法相比，以推理为中心的指令对齐显著提高了模型的文化基础。", "conclusion": "Pearl为推进文化 informed 的多模态建模研究建立了基础资源，所有数据集和基准都是公开可用的。"}}
{"id": "2505.22019", "title": "VRAG-RL: Empower Vision-Perception-Based RAG for Visually Rich Information Understanding via Iterative Reasoning with Reinforcement Learning", "authors": ["Qiuchen Wang", "Ruixue Ding", "Yu Zeng", "Zehui Chen", "Lin Chen", "Shihang Wang", "Pengjun Xie", "Fei Huang", "Feng Zhao"], "abstract": "Effectively retrieving, reasoning and understanding visually rich information remains a challenge for RAG methods. Traditional text-based methods cannot handle visual-related information. On the other hand, current vision-based RAG approaches are often limited by fixed pipelines and frequently struggle to reason effectively due to the insufficient activation of the fundamental capabilities of models. As RL has been proven to be beneficial for model reasoning, we introduce VRAG-RL, a novel RL framework tailored for complex reasoning across visually rich information. With this framework, VLMs interact with search engines, autonomously sampling single-turn or multi-turn reasoning trajectories with the help of visual perception tokens and undergoing continual optimization based on these samples. Our approach highlights key limitations of RL in RAG domains: (i) Prior Multi-modal RAG approaches tend to merely incorporate images into the context, leading to insufficient reasoning token allocation and neglecting visual-specific perception; and (ii) When models interact with search engines, their queries often fail to retrieve relevant information due to the inability to articulate requirements, thereby leading to suboptimal performance. To address these challenges, we define an action space tailored for visually rich inputs, with actions including cropping and scaling, allowing the model to gather information from a coarse-to-fine perspective. Furthermore, to bridge the gap between users' original inquiries and the retriever, we employ a simple yet effective reward that integrates query rewriting and retrieval performance with a model-based reward. Our VRAG-RL optimizes VLMs for RAG tasks using specially designed RL strategies, aligning the model with real-world applications. The code is available at \\hyperlink{", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.22019.pdf", "abstract_url": "https://arxiv.org/abs/2505.22019", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "VRAG-RL是一种新颖的强化学习框架，旨在通过视觉感知令牌和迭代推理，增强视觉丰富信息的检索、推理和理解能力。", "motivation": "解决传统基于文本的RAG方法无法处理视觉相关信息，以及当前基于视觉的RAG方法因固定流程和模型基础能力激活不足而难以有效推理的问题。", "method": "引入VRAG-RL框架，通过视觉语言模型与搜索引擎的交互，自主采样单轮或多轮推理轨迹，并基于这些样本进行持续优化。定义了针对视觉丰富输入的动作空间，包括裁剪和缩放等操作。", "result": "VRAG-RL通过专门设计的强化学习策略优化视觉语言模型，提高了在RAG任务中的性能，特别是在视觉丰富信息的理解和推理方面。", "conclusion": "VRAG-RL框架通过强化学习优化视觉语言模型，有效解决了视觉丰富信息检索和理解中的关键挑战，为实际应用提供了新的解决方案。"}}
{"id": "2505.22061", "title": "Safeguarding Privacy of Retrieval Data against Membership Inference Attacks: Is This Query Too Close to Home?", "authors": ["Yujin Choi", "Youngjoo Park", "Junyoung Byun", "Jaewook Lee", "Jinseong Park"], "abstract": "Retrieval-augmented generation (RAG) mitigates the hallucination problem in large language models (LLMs) and has proven effective for specific, personalized applications. However, passing private retrieved documents directly to LLMs introduces vulnerability to membership inference attacks (MIAs), which try to determine whether the target datum exists in the private external database or not. Based on the insight that MIA queries typically exhibit high similarity to only one target document, we introduce Mirabel, a similarity-based MIA detection framework designed for the RAG system. With the proposed Mirabel, we show that simple detect-and-hide strategies can successfully obfuscate attackers, maintain data utility, and remain system-agnostic. We experimentally prove its detection and defense against various state-of-the-art MIA methods and its adaptability to existing private RAG systems.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.22061.pdf", "abstract_url": "https://arxiv.org/abs/2505.22061", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了Mirabel，一个基于相似性的成员推理攻击（MIA）检测框架，旨在保护检索增强生成（RAG）系统中的隐私数据。通过简单的检测和隐藏策略，Mirabel能够有效混淆攻击者，保持数据效用，并且与系统无关。实验证明，Mirabel能够检测和防御各种最先进的MIA方法，并适应现有的私有RAG系统。", "motivation": "检索增强生成（RAG）虽然缓解了大语言模型（LLMs）中的幻觉问题，并在特定、个性化的应用中证明有效，但直接将私有检索文档传递给LLMs会引入成员推理攻击（MIAs）的漏洞，这种攻击试图确定目标数据是否存在于私有外部数据库中。", "method": "基于MIA查询通常只与一个目标文档表现出高度相似性的洞察，本文提出了Mirabel，一个相似性基础的MIA检测框架，设计用于RAG系统。", "result": "实验证明，Mirabel能够成功检测和防御各种最先进的MIA方法，并且能够适应现有的私有RAG系统，同时通过简单的检测和隐藏策略有效混淆攻击者，保持数据效用。", "conclusion": "Mirabel框架为RAG系统提供了一种有效的隐私保护机制，能够在不牺牲数据效用和系统兼容性的情况下，防御成员推理攻击。"}}
{"id": "2505.22095", "title": "Learning to Route Queries Across Knowledge Bases for Step-wise Retrieval-Augmented Reasoning", "authors": ["Chunyi Peng", "Zhipeng Xu", "Zhenghao Liu", "Yishan Li", "Yukun Yan", "Shuo Wang", "Zhiyuan Liu", "Yu Gu", "Minghe Yu", "Ge Yu", "Maosong Sun"], "abstract": "Multimodal Retrieval-Augmented Generation (MRAG) has shown promise in mitigating hallucinations in Multimodal Large Language Models (MLLMs) by incorporating external knowledge during generation. Existing MRAG methods typically adopt a static retrieval pipeline that fetches relevant information from multiple Knowledge Bases (KBs), followed by a refinement step. However, these approaches overlook the reasoning and planning capabilities of MLLMs to dynamically determine how to interact with different KBs during the reasoning process. To address this limitation, we propose R1-Router, a novel MRAG framework that learns to decide when and where to retrieve knowledge based on the evolving reasoning state. Specifically, R1-Router can generate follow-up queries according to the current reasoning step, routing these intermediate queries to the most suitable KB, and integrating external knowledge into a coherent reasoning trajectory to answer the original query. Furthermore, we introduce Step-wise Group Relative Policy Optimization (Step-GRPO), a tailored reinforcement learning algorithm that assigns step-specific rewards to optimize the reasoning behavior of MLLMs. Experimental results on various open-domain QA benchmarks across multiple modalities demonstrate that R1-Router outperforms baseline models by over 7%. Further analysis shows that R1-Router can adaptively and effectively leverage diverse KBs, reducing unnecessary retrievals and improving both efficiency and accuracy.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.22095.pdf", "abstract_url": "https://arxiv.org/abs/2505.22095", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种名为R1-Router的新型多模态检索增强生成框架，该框架能够根据推理状态动态决定何时以及从哪个知识库检索知识，以提高多模态大语言模型的推理效率和准确性。", "motivation": "现有的多模态检索增强生成方法通常采用静态检索流程，忽视了多模态大语言模型在推理过程中的动态规划和推理能力，导致检索效率低下和准确性不足。", "method": "R1-Router框架通过学习生成后续查询并根据当前推理步骤将这些查询路由到最合适的知识库，结合外部知识形成连贯的推理轨迹。此外，引入了Step-wise Group Relative Policy Optimization（Step-GRPO）算法，通过分配步骤特定的奖励来优化模型的推理行为。", "result": "在多个开放领域问答基准测试中，R1-Router的表现优于基线模型超过7%，能够自适应且有效地利用多样化的知识库，减少不必要的检索，提高效率和准确性。", "conclusion": "R1-Router通过动态路由查询和优化推理行为，显著提高了多模态检索增强生成的效率和准确性，为未来的多模态推理研究提供了新的方向。"}}
{"id": "2505.22101", "title": "MemOS: An Operating System for Memory-Augmented Generation (MAG) in Large Language Models", "authors": ["Zhiyu Li", "Shichao Song", "Hanyu Wang", "Simin Niu", "Ding Chen", "Jiawei Yang", "Chenyang Xi", "Huayi Lai", "Jihao Zhao", "Yezhaohui Wang", "Junpeng Ren", "Zehao Lin", "Jiahao Huo", "Tianyi Chen", "Kai Chen", "Kehang Li", "Zhiqiang Yin", "Qingchen Yu", "Bo Tang", "Hongkang Yang", "Zhi-Qin John Xu", "Feiyu Xiong"], "abstract": "Large Language Models (LLMs) have emerged as foundational infrastructure in the pursuit of Artificial General Intelligence (AGI). Despite their remarkable capabilities in language perception and generation, current LLMs fundamentally lack a unified and structured architecture for handling memory. They primarily rely on parametric memory (knowledge encoded in model weights) and ephemeral activation memory (context-limited runtime states). While emerging methods like Retrieval-Augmented Generation (RAG) incorporate plaintext memory, they lack lifecycle management and multi-modal integration, limiting their capacity for long-term knowledge evolution. To address this, we introduce MemOS, a memory operating system designed for LLMs that, for the first time, elevates memory to a first-class operational resource. It builds unified mechanisms for representation, organization, and governance across three core memory types: parametric, activation, and plaintext. At its core is the MemCube, a standardized memory abstraction that enables tracking, fusion, and migration of heterogeneous memory, while offering structured, traceable access across tasks and contexts. MemOS establishes a memory-centric execution framework with strong controllability, adaptability, and evolvability. It fills a critical gap in current LLM infrastructure and lays the groundwork for continual adaptation, personalized intelligence, and cross-platform coordination in next-generation intelligent systems.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.22101.pdf", "abstract_url": "https://arxiv.org/abs/2505.22101", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了MemOS，一个专为大型语言模型（LLMs）设计的内存操作系统，旨在解决当前LLMs在处理内存时缺乏统一和结构化架构的问题。MemOS通过引入MemCube作为标准化的内存抽象，实现了对参数内存、激活内存和纯文本内存的统一表示、组织和治理，从而提升了内存的可控性、适应性和可进化性。", "motivation": "当前的大型语言模型（LLMs）主要依赖参数内存和短暂的激活内存，缺乏统一和结构化的内存处理架构。尽管像检索增强生成（RAG）这样的新兴方法引入了纯文本内存，但它们缺乏生命周期管理和多模态集成，限制了长期知识进化的能力。", "method": "MemOS通过引入MemCube，一个标准化的内存抽象，实现了对三种核心内存类型（参数、激活和纯文本）的统一表示、组织和治理。MemCube支持异构内存的跟踪、融合和迁移，并提供跨任务和上下文的结构化、可追踪访问。", "result": "MemOS建立了一个以内存为中心的执行框架，具有强大的可控性、适应性和可进化性。它填补了当前LLM基础设施中的一个关键空白，并为下一代智能系统中的持续适应、个性化智能和跨平台协调奠定了基础。", "conclusion": "MemOS首次将内存提升为一类操作资源，为大型语言模型提供了一个统一和结构化的内存处理架构。这不仅解决了当前LLMs在处理内存时的问题，还为未来的智能系统发展提供了新的可能性。"}}
{"id": "2505.21784", "title": "Towards Safety Reasoning in LLMs: AI-agentic Deliberation for Policy-embedded CoT Data Creation", "authors": ["Tharindu Kumarage", "Ninareh Mehrabi", "Anil Ramakrishna", "Xinyan Zhao", "Richard Zemel", "Kai-Wei Chang", "Aram Galstyan", "Rahul Gupta", "Charith Peris"], "abstract": "Safety reasoning is a recent paradigm where LLMs reason over safety policies before generating responses, thereby mitigating limitations in existing safety measures such as over-refusal and jailbreak vulnerabilities. However, implementing this paradigm is challenging due to the resource-intensive process of creating high-quality policy-embedded chain-of-thought (CoT) datasets while ensuring reasoning remains accurate and free from hallucinations or policy conflicts. To tackle this, we propose AIDSAFE: Agentic Iterative Deliberation for Safety Reasoning, a novel data generation recipe that leverages multi-agent deliberation to iteratively expand reasoning on safety policies. A data refiner stage in AIDSAFE ensures high-quality outputs by eliminating repetitive, redundant, and deceptive thoughts. AIDSAFE-generated CoTs provide a strong foundation for supervised fine-tuning (SFT)-based safety training. Additionally, to address the need of preference data in alignment stages, such as DPO training, we introduce a supplemental recipe that uses belief augmentation to create distinct selected and rejected CoT samples. Our evaluations demonstrate that AIDSAFE-generated CoTs achieve superior policy adherence and reasoning quality. Consequently, we show that fine-tuning open-source LLMs on these CoTs can significantly improve safety generalization and jailbreak robustness while maintaining acceptable utility and over-refusal accuracy. AIDSAFE-generated CoT datasets can be found here:", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "Accepted to ACL 2025 (Findings)", "pdf_url": "https://arxiv.org/pdf/2505.21784.pdf", "abstract_url": "https://arxiv.org/abs/2505.21784", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了AIDSAFE：一种利用多智能体审议迭代扩展安全策略推理的新型数据生成方法，旨在解决创建高质量策略嵌入思维链（CoT）数据集的挑战，以提高大型语言模型（LLM）的安全推理能力。", "motivation": "现有的安全措施存在过度拒绝和越狱漏洞等限制，安全推理作为一种新范式，要求LLM在生成响应前对安全策略进行推理，但实现这一范式面临创建高质量策略嵌入CoT数据集的资源密集型挑战。", "method": "提出AIDSAFE方法，通过多智能体审议迭代扩展安全策略的推理，并引入数据精炼阶段以消除重复、冗余和欺骗性思维，确保输出高质量。此外，为满足对齐阶段偏好数据的需求，提出了使用信念增强创建选定和拒绝CoT样本的补充方法。", "result": "评估显示，AIDSAFE生成的CoT在策略遵循和推理质量上表现优异，对开源LLM进行微调可显著提高安全泛化和越狱鲁棒性，同时保持可接受的实用性和过度拒绝准确性。", "conclusion": "AIDSAFE为安全训练提供了高质量的CoT数据集基础，通过微调LLM可以显著提升模型的安全性能，同时解决了现有安全措施的主要限制。"}}
{"id": "2505.21907", "title": "Modeling and Optimizing User Preferences in AI Copilots: A Comprehensive Survey and Taxonomy", "authors": ["Saleh Afzoon", "Zahra Jahanandish", "Phuong Thao Huynh", "Amin Beheshti", "Usman Naseem"], "abstract": "AI copilots, context-aware, AI-powered systems designed to assist users in tasks such as software development and content creation, are becoming integral to modern workflows. As these systems grow in capability and adoption, personalization has emerged as a cornerstone for ensuring usability, trust, and productivity. Central to this personalization is preference optimization: the ability of AI copilots to detect, interpret, and align with individual user preferences. While personalization techniques are well-established in domains like recommender systems and dialogue agents, their adaptation to interactive, real-time systems like AI copilots remains fragmented and underexplored. This survey addresses this gap by synthesizing research on how user preferences are captured, modeled, and refined within the design of AI copilots. We introduce a unified definition of AI copilots and propose a phase-based taxonomy of preference optimization strategies, structured around pre-interaction, mid-interaction, and post-interaction stages. We analyze techniques for acquiring preference signals, modeling user intent, and integrating feedback loops, highlighting both established approaches and recent innovations. By bridging insights from AI personalization, human-AI collaboration, and large language model adaptation, this survey provides a structured foundation for designing adaptive, preference-aware AI copilots. It offers a holistic view of the available preference resources, how they can be leveraged, and which technical approaches are most suited to each stage of system design.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.21907.pdf", "abstract_url": "https://arxiv.org/abs/2505.21907", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文综述了AI副驾驶中用户偏好建模与优化的研究，提出了一个基于阶段的分类法，并分析了偏好信号获取、用户意图建模及反馈循环整合的技术。", "motivation": "随着AI副驾驶在能力与采用率上的增长，个性化成为确保可用性、信任和生产力的关键。然而，将个性化技术适应于如AI副驾驶这样的交互式实时系统仍处于分散和未充分探索的状态。", "method": "本文通过综合研究AI副驾驶设计中如何捕捉、建模和精炼用户偏好，提出了一个统一的AI副驾驶定义，并围绕交互前、交互中和交互后阶段构建了偏好优化策略的分类法。", "result": "分析表明，通过结合AI个性化、人-AI协作和大语言模型适应的见解，可以设计出适应性强的、偏好感知的AI副驾驶。", "conclusion": "本综述为设计自适应、偏好感知的AI副驾驶提供了结构化基础，全面概述了可用的偏好资源、如何利用这些资源以及哪些技术方法最适合系统设计的每个阶段。"}}
{"id": "2505.22006", "title": "Efficiently Enhancing General Agents With Hierarchical-categorical Memory", "authors": ["Changze Qiao", "Mingming Lu"], "abstract": "With large language models (LLMs) demonstrating remarkable capabilities, there has been a surge in research on leveraging LLMs to build general-purpose multi-modal agents. However, existing approaches either rely on computationally expensive end-to-end training using large-scale multi-modal data or adopt tool-use methods that lack the ability to continuously learn and adapt to new environments. In this paper, we introduce EHC, a general agent capable of learning without parameter updates. EHC consists of a Hierarchical Memory Retrieval (HMR) module and a Task-Category Oriented Experience Learning (TOEL) module. The HMR module facilitates rapid retrieval of relevant memories and continuously stores new information without being constrained by memory capacity. The TOEL module enhances the agent's comprehension of various task characteristics by classifying experiences and extracting patterns across different categories. Extensive experiments conducted on multiple standard datasets demonstrate that EHC outperforms existing methods, achieving state-of-the-art performance and underscoring its effectiveness as a general agent for handling complex multi-modal tasks.", "subjects": "Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.22006.pdf", "abstract_url": "https://arxiv.org/abs/2505.22006", "categories": ["Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了EHC，一种无需参数更新即可学习的通用代理，通过分层记忆检索和任务类别导向的经验学习模块，有效处理复杂多模态任务。", "motivation": "现有方法依赖于计算成本高的端到端训练或缺乏持续学习能力的工具使用方法，无法适应新环境。", "method": "EHC包含分层记忆检索(HMR)模块和任务类别导向经验学习(TOEL)模块，前者快速检索相关记忆并持续存储新信息，后者通过分类经验和提取跨类别模式增强代理对任务特性的理解。", "result": "在多个标准数据集上的广泛实验表明，EHC优于现有方法，实现了最先进的性能。", "conclusion": "EHC作为一种通用代理，有效处理复杂多模态任务，展示了其高效性和适应性。"}}
{"id": "2505.21544", "title": "Vision Meets Language: A RAG-Augmented YOLOv8 Framework for Coffee Disease Diagnosis and Farmer Assistance", "authors": ["Semanto Mondal"], "abstract": "As a social being, we have an intimate bond with the environment. A plethora of things in human life, such as lifestyle, health, and food are dependent on the environment and agriculture. It comes under our responsibility to support the environment as well as agriculture. However, traditional farming practices often result in inefficient resource use and environmental challenges. To address these issues, precision agriculture has emerged as a promising approach that leverages advanced technologies to optimise agricultural processes. In this work, a hybrid approach is proposed that combines the three different potential fields of model AI: object detection, large language model (LLM), and Retrieval-Augmented Generation (RAG). In this novel framework, we have tried to combine the vision and language models to work together to identify potential diseases in the tree leaf. This study introduces a novel AI-based precision agriculture system that uses Retrieval Augmented Generation (RAG) to provide context-aware diagnoses and natural language processing (NLP) and YOLOv8 for crop disease detection. The system aims to tackle major issues with large language models (LLMs), especially hallucinations and allows for adaptive treatment plans and real-time disease detection. The system provides an easy-to-use interface to the farmers, which they can use to detect the different diseases related to coffee leaves by just submitting the image of the affected leaf the model will detect the diseases as well as suggest potential remediation methodologies which aim to lower the use of pesticides, preserving livelihoods, and encouraging environmentally friendly methods. With an emphasis on scalability, dependability, and user-friendliness, the project intends to improve RAG-integrated object detection systems for wider agricultural applications in the future.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL)", "comments": "There are 14 pages, 8 figures", "pdf_url": "https://arxiv.org/pdf/2505.21544.pdf", "abstract_url": "https://arxiv.org/abs/2505.21544", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种结合视觉与语言模型的创新框架，用于咖啡树病害诊断和农民辅助，通过整合YOLOv8、大型语言模型和检索增强生成技术，实现实时病害检测和适应性治疗方案。", "motivation": "解决传统农业实践中资源使用效率低和环境污染问题，通过精准农业技术优化农业过程。", "method": "采用YOLOv8进行作物病害检测，结合检索增强生成（RAG）和自然语言处理（NLP）技术，提供上下文感知诊断和治疗建议。", "result": "开发了一个用户友好的系统，农民只需提交受影响叶子的图像，系统即可检测病害并建议补救方法，旨在减少农药使用，保护生计，鼓励环保方法。", "conclusion": "该项目强调了可扩展性、可靠性和用户友好性，旨在改进RAG集成的物体检测系统，以适用于更广泛的农业应用。"}}
{"id": "2505.22050", "title": "Reinforced Reasoning for Embodied Planning", "authors": ["Di Wu", "Jiaxin Fan", "Junzhe Zang", "Guanbo Wang", "Wei Yin", "Wenhao Li", "Bo Jin"], "abstract": "Embodied planning requires agents to make coherent multi-step decisions based on dynamic visual observations and natural language goals. While recent vision-language models (VLMs) excel at static perception tasks, they struggle with the temporal reasoning, spatial understanding, and commonsense grounding needed for planning in interactive environments. In this work, we introduce a reinforcement fine-tuning framework that brings R1-style reasoning enhancement into embodied planning. We first distill a high-quality dataset from a powerful closed-source model and perform supervised fine-tuning (SFT) to equip the model with structured decision-making priors. We then design a rule-based reward function tailored to multi-step action quality and optimize the policy via Generalized Reinforced Preference Optimization (GRPO). Our approach is evaluated on Embench, a recent benchmark for interactive embodied tasks, covering both in-domain and out-of-domain scenarios. Experimental results show that our method significantly outperforms models of similar or larger scale, including GPT-4o-mini and 70B+ open-source baselines, and exhibits strong generalization to unseen environments. This work highlights the potential of reinforcement-driven reasoning to advance long-horizon planning in embodied AI.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.22050.pdf", "abstract_url": "https://arxiv.org/abs/2505.22050", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种强化微调框架，将R1式推理增强应用于具身规划，通过监督微调和基于规则的奖励函数优化策略，显著提升了模型在交互式具身任务中的表现。", "motivation": "解决视觉语言模型在交互式环境中进行多步决策时面临的时间推理、空间理解和常识基础不足的问题。", "method": "首先从强大的闭源模型中提取高质量数据集进行监督微调，然后设计基于规则的奖励函数，并通过广义强化偏好优化（GRPO）优化策略。", "result": "在Embench基准测试中，该方法显著优于类似或更大规模的模型，包括GPT-4o-mini和70B+开源基线，并展现出对未见环境的强泛化能力。", "conclusion": "这项工作强调了强化驱动推理在推进具身AI中长期规划中的潜力。"}}
{"id": "2505.22092", "title": "VIRAL: Vision-grounded Integration for Reward design And Learning", "authors": ["Valentin Cuzin-Rambaud", "Emilien Komlenovic", "Alexandre Faure", "Bruno Yun"], "abstract": "The alignment between humans and machines is a critical challenge in artificial intelligence today. Reinforcement learning, which aims to maximize a reward function, is particularly vulnerable to the risks associated with poorly designed reward functions. Recent advancements has shown that Large Language Models (LLMs) for reward generation can outperform human performance in this context. We introduce VIRAL, a pipeline for generating and refining reward functions through the use of multi-modal LLMs. VIRAL autonomously creates and interactively improves reward functions based on a given environment and a goal prompt or annotated image. The refinement process can incorporate human feedback or be guided by a description generated by a video LLM, which explains the agent's policy in video form. We evaluated VIRAL in five Gymnasium environments, demonstrating that it accelerates the learning of new behaviors while ensuring improved alignment with user intent. The source-code and demo video are available at:", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.22092.pdf", "abstract_url": "https://arxiv.org/abs/2505.22092", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了VIRAL，一个通过多模态大型语言模型（LLMs）生成和优化奖励函数的管道，旨在解决人工智能中人与机器对齐的关键挑战。VIRAL能够基于给定环境和目标提示或注释图像自主创建并交互式改进奖励函数，其优化过程可以融入人类反馈或由视频LLM生成的描述指导。在五个Gymnasium环境中的评估表明，VIRAL加速了新行为的学习，同时提高了与用户意图的对齐。", "motivation": "解决人工智能中人与机器对齐的关键挑战，特别是在强化学习中，由于奖励函数设计不当带来的风险。", "method": "使用多模态大型语言模型（LLMs）生成和优化奖励函数，通过环境、目标提示或注释图像自主创建奖励函数，并可以融入人类反馈或视频LLM生成的描述进行优化。", "result": "在五个Gymnasium环境中的评估显示，VIRAL加速了新行为的学习，并提高了与用户意图的对齐。", "conclusion": "VIRAL为奖励函数的设计和学习提供了一种有效的方法，能够加速学习过程并确保更好的用户意图对齐，为人工智能领域的人机对齐问题提供了新的解决方案。"}}
{"id": "2505.22311", "title": "From Large AI Models to Agentic AI: A Tutorial on Future Intelligent Communications", "authors": ["Feibo Jiang", "Cunhua Pan", "Li Dong", "Kezhi Wang", "Octavia A. Dobre", "Merouane Debbah"], "abstract": "With the advent of 6G communications, intelligent communication systems face multiple challenges, including constrained perception and response capabilities, limited scalability, and low adaptability in dynamic environments. This tutorial provides a systematic introduction to the principles, design, and applications of Large Artificial Intelligence Models (LAMs) and Agentic AI technologies in intelligent communication systems, aiming to offer researchers a comprehensive overview of cutting-edge technologies and practical guidance. First, we outline the background of 6G communications, review the technological evolution from LAMs to Agentic AI, and clarify the tutorial's motivation and main contributions. Subsequently, we present a comprehensive review of the key components required for constructing LAMs. We further categorize LAMs and analyze their applicability, covering Large Language Models (LLMs), Large Vision Models (LVMs), Large Multimodal Models (LMMs), Large Reasoning Models (LRMs), and lightweight LAMs. Next, we propose a LAM-centric design paradigm tailored for communications, encompassing dataset construction and both internal and external learning approaches. Building upon this, we develop an LAM-based Agentic AI system for intelligent communications, clarifying its core components such as planners, knowledge bases, tools, and memory modules, as well as its interaction mechanisms. We also introduce a multi-agent framework with data retrieval, collaborative planning, and reflective evaluation for 6G. Subsequently, we provide a detailed overview of the applications of LAMs and Agentic AI in communication scenarios. Finally, we summarize the research challenges and future directions in current studies, aiming to support the development of efficient, secure, and sustainable next-generation intelligent communication systems.", "subjects": "Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Networking and Internet Architecture (cs.NI); Signal Processing (eess.SP)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.22311.pdf", "abstract_url": "https://arxiv.org/abs/2505.22311", "categories": ["Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)", "Networking and Internet Architecture (cs.NI)", "Signal Processing (eess.SP)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本教程系统地介绍了大型人工智能模型（LAMs）和代理AI技术在智能通信系统中的原理、设计和应用，旨在为研究人员提供前沿技术的全面概述和实践指导。", "motivation": "解决6G通信中智能通信系统面临的感知和响应能力受限、可扩展性有限以及在动态环境中适应性低的问题。", "method": "提出了一种以LAM为中心的设计范式，包括数据集构建和内外学习方法，并开发了一个基于LAM的代理AI系统，明确了其核心组件和交互机制。", "result": "介绍了LAMs和代理AI在通信场景中的应用，并总结了当前研究中的挑战和未来方向。", "conclusion": "支持开发高效、安全、可持续的下一代智能通信系统。"}}
{"id": "2505.22147", "title": "Lifted Forward Planning in Relational Factored Markov Decision Processes with Concurrent Actions", "authors": ["Florian Andreas Marwitz", "Tanya Braun", "Ralf Möller", "Marcel Gehrke"], "abstract": "Decision making is a central problem in AI that can be formalized using a Markov Decision Process. A problem is that, with increasing numbers of (indistinguishable) objects, the state space grows exponentially. To compute policies, the state space has to be enumerated. Even more possibilities have to be enumerated if the size of the action space depends on the size of the state space, especially if we allow concurrent actions. To tackle the exponential blow-up in the action and state space, we present a first-order representation to store the spaces in polynomial instead of exponential size in the number of objects and introduce Foreplan, a relational forward planner, which uses this representation to efficiently compute policies for numerous indistinguishable objects and actions. Additionally, we introduce an even faster approximate version of Foreplan. Moreover, Foreplan identifies how many objects an agent should act on to achieve a certain task given restrictions. Further, we provide a theoretical analysis and an empirical evaluation of Foreplan, demonstrating a speedup of at least four orders of magnitude.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.22147.pdf", "abstract_url": "https://arxiv.org/abs/2505.22147", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为Foreplan的关系前向规划器，用于在具有并发动作的关系因子马尔可夫决策过程中进行高效决策。通过一阶表示法，Foreplan能够以多项式大小存储状态和动作空间，避免了对象数量增加时的指数级膨胀。此外，还介绍了Foreplan的近似版本，以及其在确定为实现特定任务所需操作对象数量方面的能力。理论和实证评估显示，Foreplan实现了至少四个数量级的加速。", "motivation": "随着（不可区分）对象数量的增加，马尔可夫决策过程中的状态空间呈指数级增长，尤其是在允许并发动作的情况下，动作空间的大小也依赖于状态空间的大小，这导致计算策略时需要枚举的可能性急剧增加。本文旨在解决这一状态和动作空间的指数级膨胀问题。", "method": "本文提出了一种一阶表示法，用于以多项式大小而非指数大小存储状态和动作空间，并介绍了Foreplan，一个利用这种表示法高效计算策略的关系前向规划器。此外，还提出了一个更快的Foreplan近似版本。", "result": "Foreplan能够高效处理大量不可区分对象和动作的策略计算，其近似版本进一步提高了计算速度。理论和实证评估表明，Foreplan实现了至少四个数量级的加速。", "conclusion": "Foreplan及其近似版本为解决状态和动作空间指数级膨胀问题提供了有效的方法，显著提高了在具有并发动作的关系因子马尔可夫决策过程中的决策效率。"}}
{"id": "2505.22368", "title": "AgentDNS: A Root Domain Naming System for LLM Agents", "authors": ["Enfang Cui", "Yujun Cheng", "Rui She", "Dan Liu", "Zhiyuan Liang", "Minxin Guo", "Tianzheng Li", "Qian Wei", "Wenjuan Xing", "Zhijie Zhong"], "abstract": "The rapid evolution of Large Language Model (LLM) agents has highlighted critical challenges in cross-vendor service discovery, interoperability, and communication. Existing protocols like model context protocol and agent-to-agent protocol have made significant strides in standardizing interoperability between agents and tools, as well as communication among multi-agents. However, there remains a lack of standardized protocols and solutions for service discovery across different agent and tool vendors. In this paper, we propose AgentDNS, a root domain naming and service discovery system designed to enable LLM agents to autonomously discover, resolve, and securely invoke third-party agent and tool services across organizational and technological boundaries. Inspired by the principles of the traditional DNS, AgentDNS introduces a structured mechanism for service registration, semantic service discovery, secure invocation, and unified billing. We detail the architecture, core functionalities, and use cases of AgentDNS, demonstrating its potential to streamline multi-agent collaboration in real-world scenarios. The source code will be published on", "subjects": "Artificial Intelligence (cs.AI)", "comments": "7 pages, 6 figures", "pdf_url": "https://arxiv.org/pdf/2505.22368.pdf", "abstract_url": "https://arxiv.org/abs/2505.22368", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了AgentDNS，一个为大型语言模型（LLM）代理设计的根域名和服务发现系统，旨在解决跨供应商服务发现、互操作性和通信的挑战。", "motivation": "随着大型语言模型（LLM）代理的快速发展，跨供应商服务发现、互操作性和通信方面存在挑战。现有的协议在标准化代理与工具之间的互操作性以及多代理之间的通信方面取得了显著进展，但在不同代理和工具供应商之间的服务发现方面仍缺乏标准化协议和解决方案。", "method": "受传统DNS原则的启发，AgentDNS引入了一种结构化机制，用于服务注册、语义服务发现、安全调用和统一计费。", "result": "AgentDNS的架构、核心功能和用例展示了其在现实场景中简化多代理协作的潜力。", "conclusion": "AgentDNS有潜力成为LLM代理之间服务发现和协作的标准协议，促进跨组织和技术边界的无缝交互。"}}
{"id": "2505.22597", "title": "HDDLGym: A Tool for Studying Multi-Agent Hierarchical Problems Defined in HDDL with OpenAI Gym", "authors": ["Ngoc La", "Ruaridh Mon-Williams", "Julie A. Shah"], "abstract": "In recent years, reinforcement learning (RL) methods have been widely tested using tools like OpenAI Gym, though many tasks in these environments could also benefit from hierarchical planning. However, there is a lack of a tool that enables seamless integration of hierarchical planning with RL. Hierarchical Domain Definition Language (HDDL), used in classical planning, introduces a structured approach well-suited for model-based RL to address this gap. To bridge this integration, we introduce HDDLGym, a Python-based tool that automatically generates OpenAI Gym environments from HDDL domains and problems. HDDLGym serves as a link between RL and hierarchical planning, supporting multi-agent scenarios and enabling collaborative planning among agents. This paper provides an overview of HDDLGym's design and implementation, highlighting the challenges and design choices involved in integrating HDDL with the Gym interface, and applying RL policies to support hierarchical planning. We also provide detailed instructions and demonstrations for using the HDDLGym framework, including how to work with existing HDDL domains and problems from International Planning Competitions, exemplified by the Transport domain. Additionally, we offer guidance on creating new HDDL domains for multi-agent scenarios and demonstrate the practical use of HDDLGym in the Overcooked domain. By leveraging the advantages of HDDL and Gym, HDDLGym aims to be a valuable tool for studying RL in hierarchical planning, particularly in multi-agent contexts.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multiagent Systems (cs.MA)", "comments": "Accepted to Proceedings of ICAPS 2025", "pdf_url": "https://arxiv.org/pdf/2505.22597.pdf", "abstract_url": "https://arxiv.org/abs/2505.22597", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "HDDLGym是一个基于Python的工具，旨在通过将分层领域定义语言（HDDL）与OpenAI Gym环境无缝集成，填补分层规划与强化学习（RL）之间的空白。它支持多智能体场景，促进智能体间的协作规划。", "motivation": "解决分层规划与强化学习（RL）之间缺乏有效集成工具的问题，特别是在多智能体场景中。", "method": "开发了HDDLGym工具，自动从HDDL域和问题生成OpenAI Gym环境，作为RL和分层规划之间的桥梁。", "result": "HDDLGym成功集成了HDDL与Gym接口，支持多智能体协作规划，并提供了使用现有HDDL域和创建新域的详细指南。", "conclusion": "HDDLGym是一个有价值的工具，特别适用于研究多智能体上下文中的分层规划与强化学习。"}}
{"id": "2505.21534", "title": "Uncovering Bottlenecks and Optimizing Scientific Lab Workflows with Cycle Time Reduction Agents", "authors": ["Yao Fehlis"], "abstract": "Scientific laboratories, particularly those in pharmaceutical and biotechnology companies, encounter significant challenges in optimizing workflows due to the complexity and volume of tasks such as compound screening and assay execution. We introduce Cycle Time Reduction Agents (CTRA), a LangGraph-based agentic workflow designed to automate the analysis of lab operational metrics. CTRA comprises three main components: the Question Creation Agent for initiating analysis, Operational Metrics Agents for data extraction and validation, and Insights Agents for reporting and visualization, identifying bottlenecks in lab processes. This paper details CTRA's architecture, evaluates its performance on a lab dataset, and discusses its potential to accelerate pharmaceutical and biotechnological development. CTRA offers a scalable framework for reducing cycle times in scientific labs.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.21534.pdf", "abstract_url": "https://arxiv.org/abs/2505.21534", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了一种基于LangGraph的代理工作流CTRA，旨在通过自动化分析实验室操作指标来优化科学实验室的工作流程，特别是在制药和生物技术公司中。CTRA通过三个主要组件识别实验室流程中的瓶颈，展示了在实验室数据集上的性能，并讨论了其在加速药物和生物技术发展中的潜力。", "motivation": "科学实验室，尤其是制药和生物技术公司的实验室，在优化工作流程方面面临重大挑战，主要由于任务如化合物筛选和测定执行的复杂性和量大。", "method": "引入Cycle Time Reduction Agents (CTRA)，一个基于LangGraph的代理工作流，包含三个主要组件：问题创建代理用于启动分析，操作指标代理用于数据提取和验证，以及洞察代理用于报告和可视化，识别实验室流程中的瓶颈。", "result": "CTRA在实验室数据集上的性能评估显示其能够有效识别流程中的瓶颈，提供了一个可扩展的框架以减少科学实验室的周期时间。", "conclusion": "CTRA有潜力加速制药和生物技术的开发，通过提供一个可扩展的框架来优化科学实验室的工作流程。"}}
{"id": "2505.22430", "title": "RAG-Zeval: Towards Robust and Interpretable Evaluation on RAG Responses through End-to-End Rule-Guided Reasoning", "authors": ["Kun Li", "Yunxiang Li", "Tianhua Zhang", "Hongyin Luo", "Xixin Wu", "James Glass", "Helen Meng"], "abstract": "Robust evaluation is critical for deploying trustworthy retrieval-augmented generation (RAG) systems. However, current LLM-based evaluation frameworks predominantly rely on directly prompting resource-intensive models with complex multi-stage prompts, underutilizing models' reasoning capabilities and introducing significant computational cost. In this paper, we present RAG-Zeval (RAG-Zero Evaluator), a novel end-to-end framework that formulates faithfulness and correctness evaluation as a rule-guided reasoning task. Our approach trains evaluators with reinforcement learning, facilitating compact models to generate comprehensive and sound assessments with detailed explanation in one-pass. We introduce a ranking-based outcome reward mechanism, using preference judgments rather than absolute scores, to address the challenge of obtaining precise pointwise reward signals. To this end, we synthesize the ranking references by generating quality-controlled responses with zero human annotation. Experiments demonstrate RAG-Zeval's superior performance, achieving the strongest correlation with human judgments and outperforming baselines that rely on LLMs with 10-100 times more parameters. Our approach also exhibits superior interpretability in response evaluation.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.22430.pdf", "abstract_url": "https://arxiv.org/abs/2505.22430", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "RAG-Zeval是一种新颖的端到端框架，通过规则引导的推理任务来评估检索增强生成（RAG）系统的忠实度和正确性，利用强化学习训练评估器，以更低的计算成本实现与人类判断更强的相关性。", "motivation": "当前基于LLM的评估框架主要依赖直接提示资源密集型模型，未能充分利用模型的推理能力，且计算成本高。RAG-Zeval旨在解决这一问题，提供更鲁棒和可解释的评估方法。", "method": "采用强化学习训练评估器，通过规则引导的推理任务来评估RAG响应的忠实度和正确性，并引入基于排名的结果奖励机制，使用偏好判断而非绝对分数。", "result": "RAG-Zeval在实验中表现出色，与人类判断的相关性最强，且性能优于依赖参数多10-100倍的LLM的基线方法。", "conclusion": "RAG-Zeval提供了一种高效、可解释的RAG系统评估方法，显著降低了计算成本，同时提高了评估的准确性和可靠性。"}}
{"id": "2505.21863", "title": "GETReason: Enhancing Image Context Extraction through Hierarchical Multi-Agent Reasoning", "authors": ["Shikhhar Siingh", "Abhinav Rawat", "Vivek Gupta", "Chitta Baral"], "abstract": "Publicly significant images from events hold valuable contextual information, crucial for journalism and education. However, existing methods often struggle to extract this relevance accurately. To address this, we introduce GETReason (Geospatial Event Temporal Reasoning), a framework that moves beyond surface-level image descriptions to infer deeper contextual meaning. We propose that extracting global event, temporal, and geospatial information enhances understanding of an image's significance. Additionally, we introduce GREAT (Geospatial Reasoning and Event Accuracy with Temporal Alignment), a new metric for evaluating reasoning-based image understanding. Our layered multi-agent approach, assessed using a reasoning-weighted metric, demonstrates that meaningful insights can be inferred, effectively linking images to their broader event context.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.21863.pdf", "abstract_url": "https://arxiv.org/abs/2505.21863", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "GETReason是一个通过分层多智能体推理增强图像上下文提取的框架，旨在超越表面描述，推断更深层次的上下文意义。", "motivation": "解决现有方法在准确提取公开重要图像的上下文信息方面的不足，这些信息对新闻和教育至关重要。", "method": "引入了GETReason框架和GREAT评估指标，采用分层多智能体方法，通过地理空间事件时间推理来增强图像理解。", "result": "评估显示，该方法能够有效推断有意义的见解，将图像与其更广泛的事件背景联系起来。", "conclusion": "GETReason框架和GREAT指标为图像理解提供了新的视角和方法，有助于更准确地提取和评估图像的上下文信息。"}}
{"id": "2505.22501", "title": "EvolveSearch: An Iterative Self-Evolving Search Agent", "authors": ["Dingchu Zhang", "Yida Zhao", "Jialong Wu", "Baixuan Li", "Wenbiao Yin", "Liwen Zhang", "Yong Jiang", "Yufeng Li", "Kewei Tu", "Pengjun Xie", "Fei Huang"], "abstract": "The rapid advancement of large language models (LLMs) has transformed the landscape of agentic information seeking capabilities through the integration of tools such as search engines and web browsers. However, current mainstream approaches for enabling LLM web search proficiency face significant challenges: supervised fine-tuning struggles with data production in open-search domains, while RL converges quickly, limiting their data utilization efficiency. To address these issues, we propose EvolveSearch, a novel iterative self-evolution framework that combines SFT and RL to enhance agentic web search capabilities without any external human-annotated reasoning data. Extensive experiments on seven multi-hop question-answering (MHQA) benchmarks demonstrate that EvolveSearch consistently improves performance across iterations, ultimately achieving an average improvement of 4.7\\% over the current state-of-the-art across seven benchmarks, opening the door to self-evolution agentic capabilities in open web search domains.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.22501.pdf", "abstract_url": "https://arxiv.org/abs/2505.22501", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "EvolveSearch是一种新颖的迭代自进化框架，旨在通过结合监督微调（SFT）和强化学习（RL）来提升大型语言模型（LLMs）在开放网络搜索领域的代理信息寻求能力，无需外部人工标注的推理数据。", "motivation": "当前主流方法在提升LLM网络搜索能力方面面临挑战：监督微调在开放搜索领域的数据生产上存在困难，而强化学习则收敛过快，限制了数据利用效率。", "method": "提出EvolveSearch框架，结合监督微调（SFT）和强化学习（RL），通过迭代自进化来增强代理网络搜索能力。", "result": "在七个多跳问答（MHQA）基准测试上的广泛实验表明，EvolveSearch在迭代过程中持续提升性能，最终在七个基准测试上平均比当前最先进技术提高了4.7%。", "conclusion": "EvolveSearch为开放网络搜索领域的自进化代理能力打开了大门，展示了结合SFT和RL在提升LLM网络搜索能力方面的潜力。"}}
{"id": "2505.21550", "title": "Collaborative Agentic AI Needs Interoperability Across Ecosystems", "authors": ["Rishi Sharma", "Martijn de Vos", "Pradyumna Chari", "Ramesh Raskar", "Anne-Marie Kermarrec"], "abstract": "Collaborative agentic AI is projected to transform entire industries by enabling AI-powered agents to autonomously perceive, plan, and act within digital environments. Yet, current solutions in this field are all built in isolation, and we are rapidly heading toward a landscape of fragmented, incompatible ecosystems. In this position paper, we argue that interoperability, achieved by the adoption of minimal standards, is essential to ensure open, secure, web-scale, and widely-adopted agentic ecosystems. To this end, we devise a minimal architectural foundation for collaborative agentic AI, named Web of Agents, which is composed of four components: agent-to-agent messaging, interaction interoperability, state management, and agent discovery. Web of Agents adopts existing standards and reuses existing infrastructure where possible. With Web of Agents, we take the first but critical step toward interoperable agentic systems and offer a pragmatic path forward before ecosystem fragmentation becomes the norm.", "subjects": "Networking and Internet Architecture (cs.NI); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.21550.pdf", "abstract_url": "https://arxiv.org/abs/2505.21550", "categories": ["Networking and Internet Architecture (cs.NI)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文讨论了协作式代理AI在数字环境中自主感知、规划和行动的潜力，以及当前解决方案的孤立性问题。作者提出通过采用最小标准实现互操作性，以确保开放、安全、网络规模和广泛采用的代理生态系统。为此，他们设计了一个名为“Web of Agents”的最小架构基础，包括四个组件：代理间消息传递、交互互操作性、状态管理和代理发现。", "motivation": "解决协作式代理AI领域当前解决方案孤立且不兼容的问题，防止生态系统碎片化。", "method": "提出一个名为“Web of Agents”的最小架构基础，包括代理间消息传递、交互互操作性、状态管理和代理发现四个组件，采用现有标准并尽可能重用现有基础设施。", "result": "设计了一个促进协作式代理AI互操作性的最小架构基础，为未来的生态系统提供了可行的路径。", "conclusion": "通过“Web of Agents”架构，作者为协作式代理AI的互操作性迈出了关键一步，为防止生态系统碎片化提供了实用的解决方案。"}}
{"id": "2505.22571", "title": "Agent-UniRAG: A Trainable Open-Source LLM Agent Framework for Unified Retrieval-Augmented Generation Systems", "authors": ["Hoang Pham", "Khac-Hoai Nam Bui"], "abstract": "This paper presents a novel approach for unified retrieval-augmented generation (RAG) systems using the recent emerging large language model (LLM) agent concept. Specifically, Agent LLM, which utilizes LLM as fundamental controllers, has become a promising approach to enable the interpretability of RAG tasks, especially for complex reasoning question-answering systems (e.g., multi-hop queries). Nonetheless, previous works mainly focus on solving RAG systems with either single-hop or multi-hop approaches separately, which limits the application of those approaches to real-world applications. In this study, we propose a trainable agent framework called Agent-UniRAG for unified retrieval-augmented LLM systems, which enhances the effectiveness and interpretability of RAG systems. The main idea is to design an LLM agent framework to solve RAG tasks step-by-step based on the complexity of the inputs, simultaneously including single-hop and multi-hop queries in an end-to-end manner. Furthermore, we introduce SynAgent-RAG, a synthetic dataset to enable the proposed agent framework for small open-source LLMs (e.g., Llama-3-8B). The results show comparable performances with closed-source and larger open-source LLMs across various RAG benchmarks. Our source code and dataset are publicly available for further exploitation.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Databases (cs.DB); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.22571.pdf", "abstract_url": "https://arxiv.org/abs/2505.22571", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Databases (cs.DB)", "Information Retrieval (cs.IR)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文提出了一种新颖的统一检索增强生成（RAG）系统方法，利用大型语言模型（LLM）代理概念，设计了一个名为Agent-UniRAG的可训练代理框架，以提高RAG系统的有效性和可解释性。该框架能够根据输入的复杂性逐步解决RAG任务，同时包括单跳和多跳查询。此外，还引入了SynAgent-RAG合成数据集，支持小型开源LLM。结果显示，在各种RAG基准测试中，其性能与闭源和更大的开源LLM相当。", "motivation": "解决现有RAG系统主要单独处理单跳或多跳查询的限制，提高其在现实世界应用中的适用性和可解释性。", "method": "设计了一个可训练的LLM代理框架Agent-UniRAG，根据输入复杂性逐步解决RAG任务，并引入SynAgent-RAG合成数据集支持小型开源LLM。", "result": "在各种RAG基准测试中，Agent-UniRAG的性能与闭源和更大的开源LLM相当。", "conclusion": "Agent-UniRAG框架通过统一处理单跳和多跳查询，提高了RAG系统的有效性和可解释性，同时支持小型开源LLM，为RAG系统的进一步发展提供了新的可能性。"}}
{"id": "2505.21559", "title": "Streamlining Resilient Kubernetes Autoscaling with Multi-Agent Systems via an Automated Online Design Framework", "authors": ["Julien Soulé", "Jean-Paul Jamont", "Michel Occello", "Louis-Marie Traonouez", "Paul Théron"], "abstract": "In cloud-native systems, Kubernetes clusters with interdependent services often face challenges to their operational resilience due to poor workload management issues such as resource blocking, bottlenecks, or continuous pod crashes. These vulnerabilities are further amplified in adversarial scenarios, such as Distributed Denial-of-Service attacks (DDoS). Conventional Horizontal Pod Autoscaling (HPA) approaches struggle to address such dynamic conditions, while reinforcement learning-based methods, though more adaptable, typically optimize single goals like latency or resource usage, neglecting broader failure scenarios. We propose decomposing the overarching goal of maintaining operational resilience into failure-specific sub-goals delegated to collaborative agents, collectively forming an HPA Multi-Agent System (MAS). We introduce an automated, four-phase online framework for HPA MAS design: 1) modeling a digital twin built from cluster traces; 2) training agents in simulation using roles and missions tailored to failure contexts; 3) analyzing agent behaviors for explainability; and 4) transferring learned policies to the real cluster. Experimental results demonstrate that the generated HPA MASs outperform three state-of-the-art HPA systems in sustaining operational resilience under various adversarial conditions in a proposed complex cluster.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.21559.pdf", "abstract_url": "https://arxiv.org/abs/2505.21559", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种通过多智能体系统（MAS）和自动化在线设计框架来增强Kubernetes集群操作弹性的方法，旨在解决传统水平Pod自动扩展（HPA）方法在动态和对抗性条件下（如DDoS攻击）的不足。", "motivation": "解决云原生系统中Kubernetes集群因工作负载管理问题（如资源阻塞、瓶颈或持续Pod崩溃）及其在对抗性场景（如DDoS攻击）下进一步放大的操作弹性挑战。", "method": "提出将维持操作弹性的总体目标分解为特定于故障的子目标，委托给协作的智能体，形成一个HPA多智能体系统（MAS），并引入一个自动化的四阶段在线框架用于HPA MAS设计。", "result": "实验结果表明，生成的HPA MAS在各种对抗性条件下，在提出的复杂集群中维持操作弹性方面优于三种最先进的HPA系统。", "conclusion": "通过多智能体系统和自动化在线设计框架，可以有效提升Kubernetes集群在动态和对抗性条件下的操作弹性，为云原生系统的稳健运行提供了新的解决方案。"}}
{"id": "2505.22648", "title": "WebDancer: Towards Autonomous Information Seeking Agency", "authors": ["Jialong Wu", "Baixuan Li", "Runnan Fang", "Wenbiao Yin", "Liwen Zhang", "Zhengwei Tao", "Dingchu Zhang", "Zekun Xi", "Yong Jiang", "Pengjun Xie", "Fei Huang", "Jingren Zhou"], "abstract": "Addressing intricate real-world problems necessitates in-depth information seeking and multi-step reasoning. Recent progress in agentic systems, exemplified by Deep Research, underscores the potential for autonomous multi-step research. In this work, we present a cohesive paradigm for building end-to-end agentic information seeking agents from a data-centric and training-stage perspective. Our approach consists of four key stages: (1) browsing data construction, (2) trajectories sampling, (3) supervised fine-tuning for effective cold start, and (4) reinforcement learning for enhanced generalisation. We instantiate this framework in a web agent based on the ReAct, WebDancer. Empirical evaluations on the challenging information seeking benchmarks, GAIA and WebWalkerQA, demonstrate the strong performance of WebDancer, achieving considerable results and highlighting the efficacy of our training paradigm. Further analysis of agent training provides valuable insights and actionable, systematic pathways for developing more capable agentic models. The codes and demo will be released in", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.22648.pdf", "abstract_url": "https://arxiv.org/abs/2505.22648", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了WebDancer，一种端到端的自主信息寻求代理框架，通过数据构建、轨迹采样、监督微调和强化学习四个关键阶段，展示了在GAIA和WebWalkerQA基准测试上的强大性能。", "motivation": "解决复杂的现实世界问题需要深入的信息寻求和多步推理，本文旨在构建一个自主的多步研究代理框架。", "method": "采用数据构建、轨迹采样、监督微调和强化学习四个阶段的训练范式，基于ReAct的WebDancer代理实例化。", "result": "在GAIA和WebWalkerQA基准测试中，WebDancer表现出色，验证了训练范式的有效性。", "conclusion": "WebDancer的训练范式为开发更强大的代理模型提供了有价值的见解和系统化的路径。"}}
{"id": "2505.21956", "title": "Cross-modal RAG: Sub-dimensional Retrieval-Augmented Text-to-Image Generation", "authors": ["Mengdan Zhu", "Senhao Cheng", "Guangji Bai", "Yifei Zhang", "Liang Zhao"], "abstract": "Text-to-image generation increasingly demands access to domain-specific, fine-grained, and rapidly evolving knowledge that pretrained models cannot fully capture. Existing Retrieval-Augmented Generation (RAG) methods attempt to address this by retrieving globally relevant images, but they fail when no single image contains all desired elements from a complex user query. We propose Cross-modal RAG, a novel framework that decomposes both queries and images into sub-dimensional components, enabling subquery-aware retrieval and generation. Our method introduces a hybrid retrieval strategy - combining a sub-dimensional sparse retriever with a dense retriever - to identify a Pareto-optimal set of images, each contributing complementary aspects of the query. During generation, a multimodal large language model is guided to selectively condition on relevant visual features aligned to specific subqueries, ensuring subquery-aware image synthesis. Extensive experiments on MS-COCO, Flickr30K, WikiArt, CUB, and ImageNet-LT demonstrate that Cross-modal RAG significantly outperforms existing baselines in both retrieval and generation quality, while maintaining high efficiency.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.21956.pdf", "abstract_url": "https://arxiv.org/abs/2505.21956", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种名为Cross-modal RAG的新框架，旨在通过将查询和图像分解为子维度组件，实现子查询感知的检索和生成，以解决文本到图像生成中对领域特定、细粒度和快速变化知识的需求。", "motivation": "解决现有检索增强生成（RAG）方法在处理复杂用户查询时，无法从单一图像中获取所有所需元素的问题。", "method": "提出了一种混合检索策略，结合子维度稀疏检索器和密集检索器，识别一组帕累托最优图像，每张图像贡献查询的互补方面。在生成过程中，多模态大型语言模型被引导选择性地条件化与特定子查询相关的视觉特征。", "result": "在MS-COCO、Flickr30K、WikiArt、CUB和ImageNet-LT上的大量实验表明，Cross-modal RAG在检索和生成质量上显著优于现有基线，同时保持高效率。", "conclusion": "Cross-modal RAG框架通过子查询感知的检索和生成，显著提高了文本到图像生成的性能，为处理复杂查询提供了一种有效的方法。"}}
{"id": "2505.21569", "title": "ChemHAS: Hierarchical Agent Stacking for Enhancing Chemistry Tools", "authors": ["Zhucong Li", "Bowei Zhang", "Jin Xiao", "Zhijian Zhou", "Fenglei Cao", "Jiaqing Liang", "Yuan Qi"], "abstract": "Large Language Model (LLM)-based agents have demonstrated the ability to improve performance in chemistry-related tasks by selecting appropriate tools. However, their effectiveness remains limited by the inherent prediction errors of chemistry tools. In this paper, we take a step further by exploring how LLMbased agents can, in turn, be leveraged to reduce prediction errors of the tools. To this end, we propose ChemHAS (Chemical Hierarchical Agent Stacking), a simple yet effective method that enhances chemistry tools through optimizing agent-stacking structures from limited data. ChemHAS achieves state-of-the-art performance across four fundamental chemistry tasks, demonstrating that our method can effectively compensate for prediction errors of the tools. Furthermore, we identify and characterize four distinct agent-stacking behaviors, potentially improving interpretability and revealing new possibilities for AI agent applications in scientific research. Our code and dataset are publicly available at https: //anonymous.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "9 pages", "pdf_url": "https://arxiv.org/pdf/2505.21569.pdf", "abstract_url": "https://arxiv.org/abs/2505.21569", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "ChemHAS是一种通过优化代理堆叠结构来增强化学工具性能的简单有效方法，它在四个基础化学任务中实现了最先进的性能，并识别了四种不同的代理堆叠行为。", "motivation": "解决基于大型语言模型（LLM）的代理在化学相关任务中因化学工具的固有预测错误而受限的问题。", "method": "提出了ChemHAS（化学层次代理堆叠），一种通过从有限数据中优化代理堆叠结构来增强化学工具的方法。", "result": "ChemHAS在四个基础化学任务中实现了最先进的性能，有效补偿了工具的预测错误，并识别了四种不同的代理堆叠行为。", "conclusion": "ChemHAS不仅提高了化学工具的性能，还通过识别代理堆叠行为提高了可解释性，为科学研究中AI代理的应用揭示了新的可能性。"}}
{"id": "2505.21577", "title": "RepoMaster: Autonomous Exploration and Understanding of GitHub Repositories for Complex Task Solving", "authors": ["Huacan Wang", "Ziyi Ni", "Shuo Zhang", "Shuo Lu", "Sen Hu", "Ziyang He", "Chen Hu", "Jiaye Lin", "Yifu Guo", "Yuntao Du", "Pin Lyu"], "abstract": "The ultimate goal of code agents is to solve complex tasks autonomously. Although large language models (LLMs) have made substantial progress in code generation, real-world tasks typically demand full-fledged code repositories rather than simple scripts. Building such repositories from scratch remains a major challenge. Fortunately, GitHub hosts a vast, evolving collection of open-source repositories, which developers frequently reuse as modular components for complex tasks. Yet, existing frameworks like OpenHands and SWE-Agent still struggle to effectively leverage these valuable resources. Relying solely on README files provides insufficient guidance, and deeper exploration reveals two core obstacles: overwhelming information and tangled dependencies of repositories, both constrained by the limited context windows of current LLMs. To tackle these issues, we propose RepoMaster, an autonomous agent framework designed to explore and reuse GitHub repositories for solving complex tasks. For efficient understanding, RepoMaster constructs function-call graphs, module-dependency graphs, and hierarchical code trees to identify essential components, providing only identified core elements to the LLMs rather than the entire repository. During autonomous execution, it progressively explores related components using our exploration tools and prunes information to optimize context usage. Evaluated on the adjusted MLE-bench, RepoMaster achieves a 110% relative boost in valid submissions over the strongest baseline OpenHands. On our newly released GitTaskBench, RepoMaster lifts the task-pass rate from 24.1% to 62.9% while reducing token usage by 95%. Our code and demonstration materials are publicly available at", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": "A novel approach; Very practical", "pdf_url": "https://arxiv.org/pdf/2505.21577.pdf", "abstract_url": "https://arxiv.org/abs/2505.21577", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "RepoMaster是一个自主代理框架，旨在探索和重用GitHub仓库以解决复杂任务。通过构建函数调用图、模块依赖图等，有效识别核心组件，优化LLMs的上下文使用，显著提升了任务完成率和效率。", "motivation": "解决现有框架在利用GitHub开源仓库进行复杂任务解决时的信息过载和依赖关系复杂问题，以及当前LLMs有限上下文窗口的限制。", "method": "构建函数调用图、模块依赖图和分层代码树来识别核心组件，使用探索工具逐步探索相关组件，并通过信息剪枝优化上下文使用。", "result": "在调整后的MLE-bench上，RepoMaster的有效提交量比最强基线OpenHands提高了110%；在新发布的GitTaskBench上，任务通过率从24.1%提升至62.9%，同时减少了95%的token使用。", "conclusion": "RepoMaster通过有效探索和理解GitHub仓库，显著提高了复杂任务的解决效率和成功率，为代码代理的发展提供了新的方向。"}}
{"id": "2505.21582", "title": "AITEE -- Agentic Tutor for Electrical Engineering", "authors": ["Christopher Knievel", "Alexander Bernhardt", "Christian Bernhardt"], "abstract": "Intelligent tutoring systems combined with large language models offer a promising approach to address students' diverse needs and promote self-efficacious learning. While large language models possess good foundational knowledge of electrical engineering basics, they remain insufficiently capable of addressing specific questions about electrical circuits. In this paper, we present AITEE, an agent-based tutoring system for electrical engineering designed to accompany students throughout their learning process, offer individualized support, and promote self-directed learning. AITEE supports both hand-drawn and digital circuits through an adapted circuit reconstruction process, enabling natural interaction with students. Our novel graph-based similarity measure identifies relevant context from lecture materials through a retrieval augmented generation approach, while parallel Spice simulation further enhances accuracy in applying solution methodologies. The system implements a Socratic dialogue to foster learner autonomy through guided questioning. Experimental evaluations demonstrate that AITEE significantly outperforms baseline approaches in domain-specific knowledge application, with even medium-sized LLM models showing acceptable performance. Our results highlight the potential of agentic tutors to deliver scalable, personalized, and effective learning environments for electrical engineering education.", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)", "comments": "12 pages, 11 figures, 6 tables", "pdf_url": "https://arxiv.org/pdf/2505.21582.pdf", "abstract_url": "https://arxiv.org/abs/2505.21582", "categories": ["Computers and Society (cs.CY)", "Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "AITEE是一种基于代理的电气工程辅导系统，结合大型语言模型，通过个性化支持和促进自主学习，有效解决学生在电气电路学习中的特定问题。", "motivation": "解决大型语言模型在电气工程基础知识应用中的不足，特别是针对电气电路的具体问题，提供个性化学习支持。", "method": "采用基于图的相似性度量从讲座材料中检索相关上下文，结合并行Spice仿真提高解决方案的准确性，并通过苏格拉底对话促进学习者自主性。", "result": "实验评估显示，AITEE在领域特定知识应用上显著优于基线方法，即使是中等规模的LLM模型也表现出可接受的性能。", "conclusion": "AITEE展示了代理辅导系统在提供可扩展、个性化和有效的电气工程教育学习环境方面的潜力。"}}
{"id": "2505.21996", "title": "Learning World Models for Interactive Video Generation", "authors": ["Taiye Chen", "Xun Hu", "Zihan Ding", "Chi Jin"], "abstract": "Foundational world models must be both interactive and preserve spatiotemporal coherence for effective future planning with action choices. However, present models for long video generation have limited inherent world modeling capabilities due to two main challenges: compounding errors and insufficient memory mechanisms. We enhance image-to-video models with interactive capabilities through additional action conditioning and autoregressive framework, and reveal that compounding error is inherently irreducible in autoregressive video generation, while insufficient memory mechanism leads to incoherence of world models. We propose video retrieval augmented generation (VRAG) with explicit global state conditioning, which significantly reduces long-term compounding errors and increases spatiotemporal consistency of world models. In contrast, naive autoregressive generation with extended context windows and retrieval-augmented generation prove less effective for video generation, primarily due to the limited in-context learning capabilities of current video models. Our work illuminates the fundamental challenges in video world models and establishes a comprehensive benchmark for improving video generation models with internal world modeling capabilities.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.21996.pdf", "abstract_url": "https://arxiv.org/abs/2505.21996", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种通过视频检索增强生成（VRAG）和显式全局状态条件来改进视频生成模型的方法，旨在解决自回归视频生成中的长期复合错误和时空一致性问题。", "motivation": "当前的长视频生成模型由于复合错误和内存机制不足，缺乏有效的世界建模能力，这限制了其在未来规划和动作选择中的应用。", "method": "通过额外的动作条件和自回归框架增强图像到视频模型的交互能力，并引入视频检索增强生成（VRAG）与显式全局状态条件，以减少长期复合错误并提高时空一致性。", "result": "VRAG显著减少了长期复合错误，并提高了世界模型的时空一致性，而简单的自回归生成和检索增强生成由于当前视频模型的上下文学习能力有限，效果较差。", "conclusion": "本研究揭示了视频世界模型中的基本挑战，并为提高具有内部世界建模能力的视频生成模型建立了一个全面的基准。"}}
{"id": "2505.21588", "title": "Herd Behavior: Investigating Peer Influence in LLM-based Multi-Agent Systems", "authors": ["Young-Min Cho", "Sharath Chandra Guntuku", "Lyle Ungar"], "abstract": "Recent advancements in Large Language Models (LLMs) have enabled the emergence of multi-agent systems where LLMs interact, collaborate, and make decisions in shared environments. While individual model behavior has been extensively studied, the dynamics of peer influence in such systems remain underexplored. In this paper, we investigate herd behavior, the tendency of agents to align their outputs with those of their peers, within LLM-based multi-agent interactions. We present a series of controlled experiments that reveal how herd behaviors are shaped by multiple factors. First, we show that the gap between self-confidence and perceived confidence in peers significantly impacts an agent's likelihood to conform. Second, we find that the format in which peer information is presented plays a critical role in modulating the strength of herd behavior. Finally, we demonstrate that the degree of herd behavior can be systematically controlled, and that appropriately calibrated herd tendencies can enhance collaborative outcomes. These findings offer new insights into the social dynamics of LLM-based systems and open pathways for designing more effective and adaptive multi-agent collaboration frameworks.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": "Preprint", "pdf_url": "https://arxiv.org/pdf/2505.21588.pdf", "abstract_url": "https://arxiv.org/abs/2505.21588", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究了基于大型语言模型（LLM）的多智能体系统中的从众行为，探讨了同伴影响如何塑造智能体的输出一致性。通过一系列控制实验，揭示了自我信心与感知同伴信心之间的差距、同伴信息呈现格式以及从众行为强度可调控性对协作结果的影响。", "motivation": "尽管单个大型语言模型的行为已被广泛研究，但在多智能体系统中同伴影响的动态性仍未得到充分探索。本研究旨在填补这一空白，探索从众行为在多智能体互动中的表现及其影响因素。", "method": "通过一系列控制实验，研究了自我信心与感知同伴信心之间的差距、同伴信息呈现格式对从众行为强度的影响，以及如何系统控制从众行为以优化协作结果。", "result": "研究发现，自我信心与感知同伴信心之间的差距显著影响智能体的从众可能性；同伴信息的呈现格式对从众行为的强度有重要影响；适当地校准从众倾向可以增强协作效果。", "conclusion": "这些发现为理解基于LLM的多智能体系统的社会动态提供了新视角，并为设计更有效和适应性强的多智能体协作框架开辟了道路。"}}
{"id": "2505.21880", "title": "Incorporating LLMs for Large-Scale Urban Complex Mobility Simulation", "authors": ["Yu-Lun Song", "Chung-En Tsern", "Che-Cheng Wu", "Yu-Ming Chang", "Syuan-Bo Huang", "Wei-Chu Chen", "Michael Chia-Liang Lin", "Yu-Ta Lin"], "abstract": "This study presents an innovative approach to urban mobility simulation by integrating a Large Language Model (LLM) with Agent-Based Modeling (ABM). Unlike traditional rule-based ABM, the proposed framework leverages LLM to enhance agent diversity and realism by generating synthetic population profiles, allocating routine and occasional locations, and simulating personalized routes. Using real-world data, the simulation models individual behaviors and large-scale mobility patterns in Taipei City. Key insights, such as route heat maps and mode-specific indicators, provide urban planners with actionable information for policy-making. Future work focuses on establishing robust validation frameworks to ensure accuracy and reliability in urban planning applications.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computers and Society (cs.CY)", "comments": "8 pages, 8 figures. This paper is reviewed and accepted by the CUPUM (Computational Urban Planning and Urban Management) Conference held by University College London (UCL) in 2025", "pdf_url": "https://arxiv.org/pdf/2505.21880.pdf", "abstract_url": "https://arxiv.org/abs/2505.21880", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Computers and Society (cs.CY)"], "matching_keywords": ["agent"], "AI": {"tldr": "本研究提出了一种创新的城市流动性模拟方法，通过将大型语言模型（LLM）与基于代理的建模（ABM）相结合，增强了代理的多样性和真实性。", "motivation": "解决传统基于规则的ABM在模拟城市流动性时缺乏多样性和真实性的问题。", "method": "利用LLM生成合成人口档案、分配常规和偶尔的地点，并模拟个性化路线，结合ABM进行大规模城市流动性模拟。", "result": "在台北市的模拟中，模型成功模拟了个体行为和大规模流动性模式，生成了如路线热图和模式特定指标等关键见解。", "conclusion": "该框架为城市规划者提供了可操作的政策制定信息，未来工作将集中于建立稳健的验证框架以确保城市规划应用的准确性和可靠性。"}}
{"id": "2505.21604", "title": "Public Discourse Sandbox: Facilitating Human and AI Digital Communication Research", "authors": ["Kristina Radivojevic", "Caleb Reinking", "Shaun Whitfield", "Paul Brenner"], "abstract": "Social media serves as a primary communication and information dissemination platform for major global events, entertainment, and niche or topically focused community discussions. Therefore, it represents a valuable resource for researchers who aim to understand numerous questions. However, obtaining data can be difficult, expensive, and often unreliable due to the presence of bots, fake accounts, and manipulated content. Additionally, there are ethical concerns if researchers decide to conduct an online experiment without explicitly notifying social media users about their intent. There is a need for more controlled and scalable mechanisms to evaluate the impacts of digital discussion interventions on audiences. We introduce the Public Discourse Sandbox (PDS), which serves as a digital discourse research platform for human-AI as well as AI-AI discourse research, testing, and training. PDS provides a safe and secure space for research experiments that are not viable on public, commercial social media platforms. Its main purpose is to enable the understanding of AI behaviors and the impacts of customized AI participants via techniques such as prompt engineering, retrieval-augmented generation (RAG), and fine-tuning. We provide a hosted live version of the sandbox to support researchers as well as the open-sourced code on GitHub for community collaboration and contribution.", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.21604.pdf", "abstract_url": "https://arxiv.org/abs/2505.21604", "categories": ["Computers and Society (cs.CY)", "Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了公共话语沙盒（PDS），一个为人类-AI及AI-AI话语研究、测试和训练设计的数字话语研究平台，旨在解决社交媒体数据获取的困难和伦理问题。", "motivation": "社交媒体是主要的信息传播平台，但数据获取困难、昂贵且不可靠，同时存在伦理问题。需要更可控和可扩展的机制来评估数字讨论干预对受众的影响。", "method": "引入公共话语沙盒（PDS），提供一个安全的研究环境，支持通过提示工程、检索增强生成（RAG）和微调等技术理解AI行为和定制AI参与者的影响。", "result": "PDS为研究人员提供了一个在公共商业社交媒体平台上不可行的安全实验空间，并提供了托管版本和开源代码以支持研究和社区合作。", "conclusion": "PDS通过提供一个安全、可控的研究环境，促进了人类和AI数字通信研究的发展，支持了AI行为和干预影响的深入理解。"}}
{"id": "2505.21964", "title": "UI-Evol: Automatic Knowledge Evolving for Computer Use Agents", "authors": ["Ziyun Zhang", "Xinyi Liu", "Xiaoyi Zhang", "Jun Wang", "Gang Chen", "Yan Lu"], "abstract": "External knowledge has played a crucial role in the recent development of computer use agents. We identify a critical knowledge-execution gap: retrieved knowledge often fails to translate into effective real-world task execution. Our analysis shows even 90\\% correct knowledge yields only 41\\% execution success rate. To bridge this gap, we propose UI-Evol, a plug-and-play module for autonomous GUI knowledge evolution. UI-Evol consists of two stages: a Retrace Stage that extracts faithful objective action sequences from actual agent-environment interactions, and a Critique Stage that refines existing knowledge by comparing these sequences against external references. We conduct comprehensive experiments on the OSWorld benchmark with the state-of-the-art Agent S2. Our results demonstrate that UI-Evol not only significantly boosts task performance but also addresses a previously overlooked issue of high behavioral standard deviation in computer use agents, leading to superior performance on computer use tasks and substantially improved agent reliability.", "subjects": "Human-Computer Interaction (cs.HC); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.21964.pdf", "abstract_url": "https://arxiv.org/abs/2505.21964", "categories": ["Human-Computer Interaction (cs.HC)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "UI-Evol是一个自动知识进化模块，旨在解决计算机使用代理中知识执行差距的问题，通过两个阶段显著提升任务执行成功率和代理可靠性。", "motivation": "解决计算机使用代理中检索到的知识难以有效转化为实际任务执行的问题，即使90%正确的知识也只有41%的执行成功率。", "method": "提出UI-Evol模块，包括Retrace阶段从代理-环境交互中提取准确的动作序列，和Critique阶段通过比较这些序列与外部参考来精炼现有知识。", "result": "在OSWorld基准测试中，UI-Evol显著提升了任务性能，解决了计算机使用代理行为标准偏差高的问题，提高了代理的可靠性。", "conclusion": "UI-Evol通过自动知识进化有效桥接了知识执行差距，为计算机使用代理的性能和可靠性提供了显著改进。"}}
{"id": "2505.21731", "title": "Deep Reinforcement Learning Agents are not even close to Human Intelligence", "authors": ["Quentin Delfosse", "Jannis Blüml", "Fabian Tatai", "Théo Vincent", "Bjarne Gregori", "Elisabeth Dillies", "Jan Peters", "Constantin Rothkopf", "Kristian Kersting"], "abstract": "Deep reinforcement learning (RL) agents achieve impressive results in a wide variety of tasks, but they lack zero-shot adaptation capabilities. While most robustness evaluations focus on tasks complexifications, for which human also struggle to maintain performances, no evaluation has been performed on tasks simplifications. To tackle this issue, we introduce HackAtari, a set of task variations of the Arcade Learning Environments. We use it to demonstrate that, contrary to humans, RL agents systematically exhibit huge performance drops on simpler versions of their training tasks, uncovering agents' consistent reliance on shortcuts. Our analysis across multiple algorithms and architectures highlights the persistent gap between RL agents and human behavioral intelligence, underscoring the need for new benchmarks and methodologies that enforce systematic generalization testing beyond static evaluation protocols. Training and testing in the same environment is not enough to obtain agents equipped with human-like intelligence.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": "49 pages in total, 5 main figures, 14 figures total", "pdf_url": "https://arxiv.org/pdf/2505.21731.pdf", "abstract_url": "https://arxiv.org/abs/2505.21731", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "深度强化学习（RL）代理在多种任务中表现出色，但缺乏零样本适应能力。本文通过HackAtari评估了RL代理在任务简化情况下的表现，发现与人类不同，RL代理在简化任务上表现大幅下降，揭示了其对捷径的依赖。", "motivation": "解决深度强化学习代理在任务简化情况下表现不佳的问题，揭示其与人类行为智能之间的差距。", "method": "引入HackAtari，一套Arcade学习环境任务变体，用于评估RL代理在简化任务上的表现。", "result": "RL代理在简化任务上表现显著下降，显示出对捷径的依赖，与人类行为智能存在持续差距。", "conclusion": "需要新的基准和方法论，以超越静态评估协议，进行系统性泛化测试，以获得具备类人智能的代理。"}}
{"id": "2505.21966", "title": "MapStory: LLM-Powered Text-Driven Map Animation Prototyping with Human-in-the-Loop Editing", "authors": ["Aditya Gunturu", "Ben Pearman", "Keiichi Ihara", "Morteza Faraji", "Bryan Wang", "Rubaiat Habib Kazi", "Ryo Suzuki"], "abstract": "We introduce MapStory, an LLM-powered animation authoring tool that generates editable map animation sequences directly from natural language text. Given a user-written script, MapStory leverages an agentic architecture to automatically produce a scene breakdown, which decomposes the script into key animation building blocks such as camera movements, visual highlights, and animated elements. Our system includes a researcher component that accurately queries geospatial information by leveraging an LLM with web search, enabling the automatic extraction of relevant regions, paths, and coordinates while allowing users to edit and query for changes or additional information to refine the results. Additionally, users can fine-tune parameters of these blocks through an interactive timeline editor. We detail the system's design and architecture, informed by formative interviews with professional animators and an analysis of 200 existing map animation videos. Our evaluation, which includes expert interviews (N=5) and a usability study (N=12), demonstrates that MapStory enables users to create map animations with ease, facilitates faster iteration, encourages creative exploration, and lowers barriers to creating map-centric stories.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Multimedia (cs.MM)", "comments": "16 pages and 15 figures", "pdf_url": "https://arxiv.org/pdf/2505.21966.pdf", "abstract_url": "https://arxiv.org/abs/2505.21966", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Multimedia (cs.MM)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "MapStory是一个基于LLM的动画创作工具，通过自然语言文本生成可编辑的地图动画序列。它利用代理架构自动分解脚本为关键动画构建块，包括摄像机移动、视觉高亮和动画元素。系统还包含一个研究者组件，通过LLM与网络搜索准确查询地理空间信息，支持用户编辑和查询以优化结果。用户可以通过交互式时间线编辑器微调这些块的参数。通过专业动画师的初步访谈和200个现有地图动画视频的分析，我们详细设计了系统。评估包括专家访谈（N=5）和可用性研究（N=12），显示MapStory使用户能轻松创建地图动画，加快迭代速度，鼓励创意探索，并降低创建以地图为中心的故事的门槛。", "motivation": "解决传统地图动画创作过程中复杂、耗时且需要专业知识的问题，通过自然语言处理和LLM技术简化创作流程，使非专业人士也能轻松制作高质量的地图动画。", "method": "采用LLM驱动的代理架构自动分解自然语言脚本为动画构建块，结合网络搜索准确提取地理空间信息，提供交互式时间线编辑器供用户微调和编辑。", "result": "MapStory能够有效降低地图动画创作的难度，提高创作效率，支持快速迭代和创意探索，用户体验良好。", "conclusion": "MapStory通过结合LLM技术和交互式编辑工具，为非专业人士提供了强大的地图动画创作能力，有望推动地图故事讲述的普及和创新。"}}
{"id": "2505.22655", "title": "Position: Uncertainty Quantification Needs Reassessment for Large-language Model Agents", "authors": ["Michael Kirchhof", "Gjergji Kasneci", "Enkelejda Kasneci"], "abstract": "Large-language models (LLMs) and chatbot agents are known to provide wrong outputs at times, and it was recently found that this can never be fully prevented. Hence, uncertainty quantification plays a crucial role, aiming to quantify the level of ambiguity in either one overall number or two numbers for aleatoric and epistemic uncertainty. This position paper argues that this traditional dichotomy of uncertainties is too limited for the open and interactive setup that LLM agents operate in when communicating with a user, and that we need to research avenues that enrich uncertainties in this novel scenario. We review the literature and find that popular definitions of aleatoric and epistemic uncertainties directly contradict each other and lose their meaning in interactive LLM agent settings. Hence, we propose three novel research directions that focus on uncertainties in such human-computer interactions: Underspecification uncertainties, for when users do not provide all information or define the exact task at the first go, interactive learning, to ask follow-up questions and reduce the uncertainty about the current context, and output uncertainties, to utilize the rich language and speech space to express uncertainties as more than mere numbers. We expect that these new ways of dealing with and communicating uncertainties will lead to LLM agent interactions that are more transparent, trustworthy, and intuitive.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "Accepted at ICML 2025", "pdf_url": "https://arxiv.org/pdf/2505.22655.pdf", "abstract_url": "https://arxiv.org/abs/2505.22655", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文讨论了大型语言模型（LLMs）和聊天机器人代理在交互式环境中不确定性量化的局限性，并提出了三种新的研究方向以丰富这一领域。", "motivation": "大型语言模型和聊天机器人代理有时会提供错误的输出，且这一问题无法完全避免。传统的不确定性二分法在开放和交互式的环境中显得过于局限，需要新的研究方法来应对。", "method": "本文回顾了相关文献，发现流行的偶然性和认知性不确定性定义在交互式LLM代理设置中相互矛盾并失去意义。因此，提出了三种新的研究方向：未指定不确定性、交互式学习和输出不确定性。", "result": "研究发现，传统的不确定性量化方法在LLM代理的交互式环境中存在局限性，需要新的方法来更有效地处理和传达不确定性。", "conclusion": "通过引入新的不确定性处理和交流方式，可以提高LLM代理交互的透明度、可信度和直观性。"}}
{"id": "2505.22657", "title": "3DLLM-Mem: Long-Term Spatial-Temporal Memory for Embodied 3D Large Language Model", "authors": ["Wenbo Hu", "Yining Hong", "Yanjun Wang", "Leison Gao", "Zibu Wei", "Xingcheng Yao", "Nanyun Peng", "Yonatan Bitton", "Idan Szpektor", "Kai-Wei Chang"], "abstract": "Humans excel at performing complex tasks by leveraging long-term memory across temporal and spatial experiences. In contrast, current Large Language Models (LLMs) struggle to effectively plan and act in dynamic, multi-room 3D environments. We posit that part of this limitation is due to the lack of proper 3D spatial-temporal memory modeling in LLMs. To address this, we first introduce 3DMem-Bench, a comprehensive benchmark comprising over 26,000 trajectories and 2,892 embodied tasks, question-answering and captioning, designed to evaluate an agent's ability to reason over long-term memory in 3D environments. Second, we propose 3DLLM-Mem, a novel dynamic memory management and fusion model for embodied spatial-temporal reasoning and actions in LLMs. Our model uses working memory tokens, which represents current observations, as queries to selectively attend to and fuse the most useful spatial and temporal features from episodic memory, which stores past observations and interactions. Our approach allows the agent to focus on task-relevant information while maintaining memory efficiency in complex, long-horizon environments. Experimental results demonstrate that 3DLLM-Mem achieves state-of-the-art performance across various tasks, outperforming the strongest baselines by 16.5% in success rate on 3DMem-Bench's most challenging in-the-wild embodied tasks.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.22657.pdf", "abstract_url": "https://arxiv.org/abs/2505.22657", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了3DLLM-Mem，一种为大型语言模型设计的长期时空记忆模型，旨在解决在动态、多房间3D环境中有效规划和行动的问题。通过引入3DMem-Bench基准和提出3DLLM-Mem模型，研究展示了在复杂长期环境中的优越性能。", "motivation": "当前大型语言模型在动态、多房间3D环境中规划和行动的能力有限，部分原因是缺乏适当的3D时空记忆建模。", "method": "提出了3DLLM-Mem模型，使用工作记忆令牌作为查询，选择性地关注并融合来自情景记忆的最有用的时空特征。", "result": "3DLLM-Mem在3DMem-Bench的各种任务中实现了最先进的性能，最具挑战性的野外体现任务中成功率比最强基线高出16.5%。", "conclusion": "3DLLM-Mem通过有效的动态记忆管理和融合，显著提升了大型语言模型在复杂长期3D环境中的表现。"}}
{"id": "2505.22250", "title": "YH-MINER: Multimodal Intelligent System for Natural Ecological Reef Metric Extraction", "authors": ["Mingzhuang Wang", "Yvyang Li", "Xiyang Zhang", "Fei Tan", "Qi Shi", "Guotao Zhang", "Siqi Chen", "Yufei Liu", "Lei Lei", "Ming Zhou", "Qiang Lin", "Hongqiang Yang"], "abstract": "Coral reefs, crucial for sustaining marine biodiversity and ecological processes (e.g., nutrient cycling, habitat provision), face escalating threats, underscoring the need for efficient monitoring. Coral reef ecological monitoring faces dual challenges of low efficiency in manual analysis and insufficient segmentation accuracy in complex underwater scenarios. This study develops the YH-OSI system, establishing an intelligent framework centered on the Multimodal Large Model (MLLM) for \"object detection-semantic segmentation-prior input\". The system uses the object detection module (mAP@0.5=0.78) to generate spatial prior boxes for coral instances, driving the segment module to complete pixel-level segmentation in low-light and densely occluded scenarios. The segmentation masks and finetuned classification instructions are fed into the Qwen2-VL-based multimodal model as prior inputs, achieving a genus-level classification accuracy of 88% and simultaneously extracting core ecological metrics. Meanwhile, the system retains the scalability of the multimodal model through standardized interfaces, laying a foundation for future integration into multimodal agent-based underwater robots and supporting the full-process automation of \"image acquisition-prior generation-real-time analysis.\"", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Quantitative Methods (q-bio.QM)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.22250.pdf", "abstract_url": "https://arxiv.org/abs/2505.22250", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Quantitative Methods (q-bio.QM)"], "matching_keywords": ["agent"], "AI": {"tldr": "YH-MINER是一个多模态智能系统，旨在通过对象检测-语义分割-先验输入的智能框架，高效提取珊瑚礁生态指标，解决珊瑚礁生态监测中手动分析效率低和复杂水下场景分割精度不足的问题。", "motivation": "珊瑚礁对维持海洋生物多样性和生态过程至关重要，但面临日益严重的威胁，需要高效的监测方法。当前珊瑚礁生态监测面临手动分析效率低和复杂水下场景分割精度不足的双重挑战。", "method": "研究开发了YH-OSI系统，基于多模态大模型（MLLM）构建了一个以“对象检测-语义分割-先验输入”为核心的智能框架。系统通过对象检测模块生成珊瑚实例的空间先验框，驱动分割模块在低光和密集遮挡场景下完成像素级分割。分割掩码和微调的分类指令作为先验输入输入到基于Qwen2-VL的多模态模型中。", "result": "系统在属级分类上达到了88%的准确率，并同时提取了核心生态指标。此外，系统通过标准化接口保留了多模态模型的可扩展性。", "conclusion": "YH-MINER系统为未来集成到基于多模态代理的水下机器人中奠定了基础，支持“图像采集-先验生成-实时分析”的全过程自动化，为珊瑚礁生态监测提供了高效的解决方案。"}}
{"id": "2505.22566", "title": "Universal Visuo-Tactile Video Understanding for Embodied Interaction", "authors": ["Yifan Xie", "Mingyang Li", "Shoujie Li", "Xingting Li", "Guangyu Chen", "Fei Ma", "Fei Richard Yu", "Wenbo Ding"], "abstract": "Tactile perception is essential for embodied agents to understand physical attributes of objects that cannot be determined through visual inspection alone. While existing approaches have made progress in visual and language modalities for physical understanding, they fail to effectively incorporate tactile information that provides crucial haptic feedback for real-world interaction. In this paper, we present VTV-LLM, the first multi-modal large language model for universal Visuo-Tactile Video (VTV) understanding that bridges the gap between tactile perception and natural language. To address the challenges of cross-sensor and cross-modal integration, we contribute VTV150K, a comprehensive dataset comprising 150,000 video frames from 100 diverse objects captured across three different tactile sensors (GelSight Mini, DIGIT, and Tac3D), annotated with four fundamental tactile attributes (hardness, protrusion, elasticity, and friction). We develop a novel three-stage training paradigm that includes VTV enhancement for robust visuo-tactile representation, VTV-text alignment for cross-modal correspondence, and text prompt finetuning for natural language generation. Our framework enables sophisticated tactile reasoning capabilities including feature assessment, comparative analysis, scenario-based decision making and so on. Experimental evaluations demonstrate that VTV-LLM achieves superior performance in tactile video understanding tasks, establishing a foundation for more intuitive human-machine interaction in tactile domains.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)", "comments": "13 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2505.22566.pdf", "abstract_url": "https://arxiv.org/abs/2505.22566", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了VTV-LLM，首个用于通用视觉触觉视频（VTV）理解的多模态大型语言模型，旨在通过整合触觉感知与自然语言，解决现有方法在物理理解中触觉信息不足的问题。", "motivation": "触觉感知对于理解物体的物理属性至关重要，尤其是在视觉检查无法确定的情况下。现有方法在视觉和语言模态上取得了进展，但未能有效整合触觉信息，这限制了真实世界交互的效果。", "method": "提出了VTV-LLM模型，并贡献了VTV150K数据集，包含来自100种不同物体的150,000帧视频，覆盖三种触觉传感器。开发了一种新颖的三阶段训练范式，包括VTV增强、VTV-文本对齐和文本提示微调。", "result": "VTV-LLM在触觉视频理解任务中表现出色，支持复杂的触觉推理能力，如特征评估、比较分析和基于场景的决策制定。", "conclusion": "该研究为触觉领域的人机交互奠定了更直观的基础，展示了整合触觉感知与自然语言的潜力。"}}
{"id": "2505.21919", "title": "Towards Efficient Key-Value Cache Management for Prefix Prefilling in LLM Inference", "authors": ["Yue Zhu", "Hao Yu", "Chen Wang", "Zhuoran Liu", "Eun Kyung Lee"], "abstract": "The increasing adoption of large language models (LLMs) with extended context windows necessitates efficient Key-Value Cache (KVC) management to optimize inference performance. Inference workloads like Retrieval-Augmented Generation (RAG) and agents exhibit high cache reusability, making efficient caching critical to reducing redundancy and improving speed. We analyze real-world KVC access patterns using publicly available traces and evaluate commercial key-value stores like Redis and state-of-the-art RDMA-based systems (CHIME [1] and Sherman [2]) for KVC metadata management. Our work demonstrates the lack of tailored storage solution for KVC prefilling, underscores the need for an efficient distributed caching system with optimized metadata management for LLM workloads, and provides insights into designing improved KVC management systems for scalable, low-latency inference.", "subjects": "Emerging Technologies (cs.ET); Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC)", "comments": "This paper has been accepted at IEEE Cloud 2025 as WIP paper. The final version will appear in IEEE Xplore", "pdf_url": "https://arxiv.org/pdf/2505.21919.pdf", "abstract_url": "https://arxiv.org/abs/2505.21919", "categories": ["Emerging Technologies (cs.ET)", "Artificial Intelligence (cs.AI)", "Distributed, Parallel, and Cluster Computing (cs.DC)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文探讨了大型语言模型(LLMs)推理中键值缓存(KVC)的高效管理问题，特别是在扩展上下文窗口的情况下。通过分析真实世界的KVC访问模式，评估了Redis等商业键值存储和基于RDMA的系统，指出了当前缺乏针对KVC预填充的定制存储解决方案，并提出了设计高效分布式缓存系统的必要性。", "motivation": "随着大型语言模型(LLMs)在扩展上下文窗口中的应用日益增多，如何高效管理键值缓存(KVC)以优化推理性能成为一个关键问题。特别是在像检索增强生成(RAG)和代理这样的推理工作负载中，缓存的高重用性使得高效缓存管理对于减少冗余和提高速度至关重要。", "method": "通过分析公开可用的跟踪数据来研究真实世界的KVC访问模式，并评估了包括Redis在内的商业键值存储和基于RDMA的最新系统（如CHIME和Sherman）在KVC元数据管理方面的表现。", "result": "研究发现，当前缺乏专门为KVC预填充设计的存储解决方案，强调了需要为LLM工作负载设计一个具有优化元数据管理的高效分布式缓存系统。", "conclusion": "本文强调了为大型语言模型推理设计高效KVC管理系统的重要性，特别是在支持扩展上下文窗口和减少延迟方面，为未来研究提供了方向。"}}
{"id": "2505.21985", "title": "Reward-Independent Messaging for Decentralized Multi-Agent Reinforcement Learning", "authors": ["Naoto Yoshida", "Tadahiro Taniguchi"], "abstract": "In multi-agent reinforcement learning (MARL), effective communication improves agent performance, particularly under partial observability. We propose MARL-CPC, a framework that enables communication among fully decentralized, independent agents without parameter sharing. MARL-CPC incorporates a message learning model based on collective predictive coding (CPC) from emergent communication research. Unlike conventional methods that treat messages as part of the action space and assume cooperation, MARL-CPC links messages to state inference, supporting communication in non-cooperative, reward-independent settings. We introduce two algorithms -Bandit-CPC and IPPO-CPC- and evaluate them in non-cooperative MARL tasks. Benchmarks show that both outperform standard message-as-action approaches, establishing effective communication even when messages offer no direct benefit to the sender. These results highlight MARL-CPC's potential for enabling coordination in complex, decentralized environments.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.21985.pdf", "abstract_url": "https://arxiv.org/abs/2505.21985", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为MARL-CPC的框架，用于在完全分散、独立的多智能体强化学习（MARL）中实现有效通信，无需参数共享。通过集体预测编码（CPC）的消息学习模型，MARL-CPC在非合作、奖励无关的环境中支持通信，优于传统的消息作为行动的方法。", "motivation": "解决在多智能体强化学习中，特别是在部分可观察性下，如何实现有效通信以提高智能体性能的问题，尤其是在非合作、奖励无关的设置中。", "method": "提出了MARL-CPC框架，结合了集体预测编码（CPC）的消息学习模型，并引入了两种算法-Bandit-CPC和IPPO-CPC，在非合作的MARL任务中进行评估。", "result": "基准测试表明，Bandit-CPC和IPPO-CPC均优于标准的消息作为行动的方法，即使在消息对发送者没有直接好处的情况下也能建立有效的通信。", "conclusion": "MARL-CPC展示了在复杂的分散环境中实现协调的潜力，特别是在非合作、奖励无关的设置中。"}}
{"id": "2505.21969", "title": "DORAEMON: Decentralized Ontology-aware Reliable Agent with Enhanced Memory Oriented Navigation", "authors": ["Tianjun Gu", "Linfeng Li", "Xuhong Wang", "Chenghua Gong", "Jingyu Gong", "Zhizhong Zhang", "Yuan Xie", "Lizhuang Ma", "Xin Tan"], "abstract": "Adaptive navigation in unfamiliar environments is crucial for household service robots but remains challenging due to the need for both low-level path planning and high-level scene understanding. While recent vision-language model (VLM) based zero-shot approaches reduce dependence on prior maps and scene-specific training data, they face significant limitations: spatiotemporal discontinuity from discrete observations, unstructured memory representations, and insufficient task understanding leading to navigation failures. We propose DORAEMON (Decentralized Ontology-aware Reliable Agent with Enhanced Memory Oriented Navigation), a novel cognitive-inspired framework consisting of Ventral and Dorsal Streams that mimics human navigation capabilities. The Dorsal Stream implements the Hierarchical Semantic-Spatial Fusion and Topology Map to handle spatiotemporal discontinuities, while the Ventral Stream combines RAG-VLM and Policy-VLM to improve decision-making. Our approach also develops Nav-Ensurance to ensure navigation safety and efficiency. We evaluate DORAEMON on the HM3D, MP3D, and GOAT datasets, where it achieves state-of-the-art performance on both success rate (SR) and success weighted by path length (SPL) metrics, significantly outperforming existing methods. We also introduce a new evaluation metric (AORI) to assess navigation intelligence better. Comprehensive experiments demonstrate DORAEMON's effectiveness in zero-shot autonomous navigation without requiring prior map building or pre-training.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.21969.pdf", "abstract_url": "https://arxiv.org/abs/2505.21969", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "DORAEMON是一种新颖的认知启发框架，旨在解决家用服务机器人在陌生环境中自适应导航的挑战，通过模仿人类导航能力，结合Ventral和Dorsal Streams，实现了在零射击自主导航中的最先进性能。", "motivation": "解决家用服务机器人在陌生环境中自适应导航的挑战，特别是低级别路径规划和高级别场景理解的需求，以及现有视觉语言模型（VLM）基于零射击方法的局限性。", "method": "提出了DORAEMON框架，包括Ventral和Dorsal Streams，分别处理时空不连续性和改善决策制定，同时开发了Nav-Ensurance以确保导航的安全和效率。", "result": "在HM3D、MP3D和GOAT数据集上评估，DORAEMON在成功率和路径长度加权的成功率（SPL）指标上均达到了最先进的性能，显著优于现有方法。", "conclusion": "DORAEMON框架在不需要预先构建地图或预训练的情况下，有效实现了零射击自主导航，为家用服务机器人的导航提供了新的解决方案。"}}
{"id": "2505.22125", "title": "Sentiment Simulation using Generative AI Agents", "authors": ["Melrose Tia", "Jezreel Sophia Lanuzo", "Lei Rigi Baltazar", "Marie Joy Lopez-Relente", "Diwa Malaya Quiñones", "Jason Albia"], "abstract": "Traditional sentiment analysis relies on surface-level linguistic patterns and retrospective data, limiting its ability to capture the psychological and contextual drivers of human sentiment. These limitations constrain its effectiveness in applications that require predictive insight, such as policy testing, narrative framing, and behavioral forecasting. We present a robust framework for sentiment simulation using generative AI agents embedded with psychologically rich profiles. Agents are instantiated from a nationally representative survey of 2,485 Filipino respondents, combining sociodemographic information with validated constructs of personality traits, values, beliefs, and socio-political attitudes. The framework includes three stages: (1) agent embodiment via categorical or contextualized encodings, (2) exposure to real-world political and economic scenarios, and (3) generation of sentiment ratings accompanied by explanatory rationales. Using Quadratic Weighted Accuracy (QWA), we evaluated alignment between agent-generated and human responses. Contextualized encoding achieved 92% alignment in replicating original survey responses. In sentiment simulation tasks, agents reached 81%--86% accuracy against ground truth sentiment, with contextualized profile encodings significantly outperforming categorical (p < 0.0001, Cohen's d = 0.70). Simulation results remained consistent across repeated trials (+/-0.2--0.5% SD) and resilient to variation in scenario framing (p = 0.9676, Cohen's d = 0.02). Our findings establish a scalable framework for sentiment modeling through psychographically grounded AI agents. This work signals a paradigm shift in sentiment analysis from retrospective classification to prospective and dynamic simulation grounded in psychology of sentiment formation.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "comments": "18 pages, 10 figures", "pdf_url": "https://arxiv.org/pdf/2505.22125.pdf", "abstract_url": "https://arxiv.org/abs/2505.22125", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种使用生成式AI代理进行情感模拟的框架，通过结合心理学丰富的档案，超越了传统情感分析的表层语言模式限制。", "motivation": "传统情感分析依赖于表层语言模式和回顾性数据，无法充分捕捉人类情感的心理和上下文驱动因素，限制了其在需要预测洞察的应用中的有效性。", "method": "框架包括三个阶段：(1)通过分类或上下文编码实现代理体现，(2)暴露于现实世界的政治和经济场景，(3)生成情感评分并附带解释性理由。使用二次加权准确度(QWA)评估代理生成与人类反应的对齐。", "result": "上下文编码在复制原始调查反应中达到了92%的对齐。在情感模拟任务中，代理对真实情感的准确率达到81%-86%，上下文档案编码显著优于分类编码(p < 0.0001, Cohen's d = 0.70)。模拟结果在重复试验中保持一致(+/-0.2-0.5% SD)，对场景框架的变化具有弹性(p = 0.9676, Cohen's d = 0.02)。", "conclusion": "研究建立了一个通过心理档案基础的AI代理进行情感建模的可扩展框架，标志着情感分析从回顾性分类向基于情感形成心理学的预期和动态模拟的范式转变。"}}
{"id": "2505.22174", "title": "Online Fair Division for Personalized $2$-Value Instances", "authors": ["Georgios Amanatidis", "Alexandros Lolos", "Evangelos Markakis", "Victor Turmel"], "abstract": "We study an online fair division setting, where goods arrive one at a time and there is a fixed set of $n$ agents, each of whom has an additive valuation function over the goods. Once a good appears, the value each agent has for it is revealed and it must be allocated immediately and irrevocably to one of the agents. It is known that without any assumptions about the values being severely restricted or coming from a distribution, very strong impossibility results hold in this setting. To bypass the latter, we turn our attention to instances where the valuation functions are restricted. In particular, we study personalized $2$-value instances, where there are only two possible values each agent may have for each good, possibly different across agents, and we show how to obtain worst case guarantees with respect to well-known fairness notions, such as maximin share fairness and envy-freeness up to one (or two) good(s). We suggest a deterministic algorithm that maintains a $1/(2n-1)$-MMS allocation at every time step and show that this is the best possible any deterministic algorithm can achieve if one cares about every single time step; nevertheless, eventually the allocation constructed by our algorithm becomes a $1/4$-MMS allocation. To achieve this, the algorithm implicitly maintains a fragile system of priority levels for all agents. Further, we show that, by allowing some limited access to future information, it is possible to have stronger results with less involved approaches. By knowing the values of goods for $n-1$ time steps into the future, we design a matching-based algorithm that achieves an EF$1$ allocation every $n$ time steps, while always maintaining an EF$2$ allocation. Finally, we show that our results allow us to get the first nontrivial guarantees for additive instances in which the ratio of the maximum over the minimum value an agent has for a good is bounded.", "subjects": "Computer Science and Game Theory (cs.GT); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.22174.pdf", "abstract_url": "https://arxiv.org/abs/2505.22174", "categories": ["Computer Science and Game Theory (cs.GT)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究了在线公平分配问题，特别是在个性化2值实例中，如何在不完全信息下实现最大最小份额公平性和无嫉妒性（至多一个或两个物品）。提出了一种确定性算法，能够在每一步保持1/(2n-1)-MMS分配，并展示了通过有限未来信息可以获得更强结果的方法。", "motivation": "解决在线公平分配中由于缺乏对物品价值的假设或分布信息而导致的强不可能性问题，特别是在个性化2值实例中。", "method": "提出了一种确定性算法，通过隐式维护所有代理的优先级系统，以及一种基于匹配的算法，利用有限的未来信息。", "result": "确定性算法能在每一步保持1/(2n-1)-MMS分配，最终达到1/4-MMS分配；基于匹配的算法能在每n步实现EF1分配，同时始终保持EF2分配。", "conclusion": "在个性化2值实例中，通过适当的算法设计，可以在在线公平分配中实现有意义的公平性保证，即使在没有完整信息的情况下。"}}
{"id": "2505.22303", "title": "Voice CMS: updating the knowledge base of a digital assistant through conversation", "authors": ["Grzegorz Wolny", "Michał Szczerbak"], "abstract": "In this study, we propose a solution based on a multi-agent LLM architecture and a voice user interface (VUI) designed to update the knowledge base of a digital assistant. Its usability is evaluated in comparison to a more traditional graphical content management system (CMS), with a focus on understanding the relationship between user preferences and the complexity of the information being provided. The findings demonstrate that, while the overall usability of the VUI is rated lower than the graphical interface, it is already preferred by users for less complex tasks. Furthermore, the quality of content entered through the VUI is comparable to that achieved with the graphical interface, even for highly complex tasks. Obtained qualitative results suggest that a hybrid interface combining the strengths of both approaches could address the key challenges identified during the experiment, such as reducing cognitive load through graphical feedback while maintaining the intuitive nature of voice-based interactions. This work highlights the potential of conversational interfaces as a viable and effective method for knowledge management in specific business contexts.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.22303.pdf", "abstract_url": "https://arxiv.org/abs/2505.22303", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本研究提出了一种基于多代理LLM架构和语音用户界面（VUI）的解决方案，旨在更新数字助理的知识库。与传统图形内容管理系统（CMS）相比，VUI在用户偏好和信息复杂性之间的关系上表现出色，尤其是在处理较不复杂的任务时更受用户青睐。尽管VUI的整体可用性评分低于图形界面，但在内容质量上与之相当，甚至对于高度复杂的任务也是如此。定性结果表明，结合两种界面优势的混合界面可以解决实验中发现的关键挑战，如通过图形反馈减少认知负荷，同时保持语音交互的直观性。这项工作强调了对话式界面在特定商业场景中作为知识管理方法的潜力和有效性。", "motivation": "解决如何有效更新数字助理知识库的问题，并探索用户偏好与信息复杂性之间的关系。", "method": "采用多代理LLM架构和语音用户界面（VUI），并与传统图形内容管理系统（CMS）进行可用性比较。", "result": "VUI在处理较不复杂任务时更受用户青睐，内容质量与图形界面相当；混合界面可解决关键挑战。", "conclusion": "对话式界面在特定商业场景中作为知识管理方法具有潜力和有效性，混合界面可能是未来的发展方向。"}}
{"id": "2505.22384", "title": "Exact Algorithms and Lower Bounds for Forming Coalitions of Constrained Maximum Size", "authors": ["Foivos Fioravantes", "Harmender Gahlawat", "Nikolaos Melissinos"], "abstract": "Imagine we want to split a group of agents into teams in the most \\emph{efficient} way, considering that each agent has their own preferences about their teammates. This scenario is modeled by the extensively studied \\textsc{Coalition Formation} problem. Here, we study a version of this problem where each team must additionally be of bounded size.", "subjects": "Data Structures and Algorithms (cs.DS); Artificial Intelligence (cs.AI)", "comments": "a preliminary version appeared in AAAI 2025", "pdf_url": "https://arxiv.org/pdf/2505.22384.pdf", "abstract_url": "https://arxiv.org/abs/2505.22384", "categories": ["Data Structures and Algorithms (cs.DS)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究了在团队规模受限的情况下，如何最有效地将一组代理人分成团队的问题，考虑到每个代理人对自己队友的偏好。", "motivation": "解决在团队规模有上限限制的情况下，如何高效地形成联盟或团队的问题，同时考虑到每个成员的偏好。", "method": "研究使用了精确算法和下界分析的方法来探讨受限最大规模的联盟形成问题。", "result": "提出了在团队规模受限条件下形成联盟的精确算法，并给出了相关的下界结果。", "conclusion": "研究表明，在团队规模受限的情况下，通过精确算法可以有效解决联盟形成问题，同时下界分析为问题的复杂性提供了理论支持。"}}
{"id": "2505.22467", "title": "Topological Structure Learning Should Be A Research Priority for LLM-Based Multi-Agent Systems", "authors": ["Jiaxi Yang", "Mengqi Zhang", "Yiqiao Jin", "Hao Chen", "Qingsong Wen", "Lu Lin", "Yi He", "Weijie Xu", "James Evans", "Jindong Wang"], "abstract": "Large Language Model-based Multi-Agent Systems (MASs) have emerged as a powerful paradigm for tackling complex tasks through collaborative intelligence. Nevertheless, the question of how agents should be structurally organized for optimal cooperation remains largely unexplored. In this position paper, we aim to gently redirect the focus of the MAS research community toward this critical dimension: develop topology-aware MASs for specific tasks. Specifically, the system consists of three core components - agents, communication links, and communication patterns - that collectively shape its coordination performance and efficiency. To this end, we introduce a systematic, three-stage framework: agent selection, structure profiling, and topology synthesis. Each stage would trigger new research opportunities in areas such as language models, reinforcement learning, graph learning, and generative modeling; together, they could unleash the full potential of MASs in complicated real-world applications. Then, we discuss the potential challenges and opportunities in the evaluation of multiple systems. We hope our perspective and framework can offer critical new insights in the era of agentic AI.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.22467.pdf", "abstract_url": "https://arxiv.org/abs/2505.22467", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出大型语言模型多代理系统（MASs）的结构学习应成为研究重点，强调通过代理选择、结构分析和拓扑合成的三阶段框架来优化协作效率和性能，并探讨了相关挑战与机遇。", "motivation": "解决大型语言模型多代理系统在复杂任务中如何通过优化组织结构以实现最优协作的问题。", "method": "引入一个系统性的三阶段框架：代理选择、结构分析和拓扑合成，以指导多代理系统的结构优化。", "result": "提出了一个框架，旨在激发在语言模型、强化学习、图学习和生成建模等领域的新研究机会，以充分发挥多代理系统在复杂现实应用中的潜力。", "conclusion": "本文的视角和框架为代理性AI时代提供了关键的新见解，强调了拓扑结构学习在多代理系统中的重要性。"}}
{"id": "2505.22477", "title": "Human-Centered Human-AI Collaboration (HCHAC)", "authors": ["Qi Gao", "Wei Xu", "Hanxi Pan", "Mowei Shen", "Zaifeng Gao"], "abstract": "In the intelligent era, the interaction between humans and intelligent systems fundamentally involves collaboration with autonomous intelligent agents. Human-AI Collaboration (HAC) represents a novel type of human-machine relationship facilitated by autonomous intelligent machines equipped with AI technologies. In this paradigm, AI agents serve not only as auxiliary tools but also as active teammates, partnering with humans to accomplish tasks collaboratively. Human-centered AI (HCAI) emphasizes that humans play critical leadership roles in the collaboration. This human-led collaboration imparts new dimensions to the human-machine relationship, necessitating innovative research perspectives, paradigms, and agenda to address the unique challenges posed by HAC. This chapter delves into the essence of HAC from the human-centered perspective, outlining its core concepts and distinguishing features. It reviews the current research methodologies and research agenda within the HAC field from the HCAI perspective, highlighting advancements and ongoing studies. Furthermore, a framework for human-centered HAC (HCHAC) is proposed by integrating these reviews and analyses. A case study of HAC in the context of autonomous vehicles is provided, illustrating practical applications and the synergistic interactions between humans and AI agents. Finally, it identifies potential future research directions aimed at enhancing the effectiveness, reliability, and ethical integration of human-centered HAC systems in diverse domains.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "comments": "This article is a chapter from the upcoming book Handbook of Human-Centered Artificial Intelligence", "pdf_url": "https://arxiv.org/pdf/2505.22477.pdf", "abstract_url": "https://arxiv.org/abs/2505.22477", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了以人为中心的人与AI协作（HCHAC）的核心概念、特征及研究框架，通过自动驾驶案例展示了其实际应用，并提出了未来研究方向。", "motivation": "解决在智能时代中，人类与自主智能代理协作时面临的新挑战，强调人类在协作中的领导作用。", "method": "从以人为中心的AI（HCAI）角度出发，综述了HAC领域的研究方法和议程，提出了HCHAC框架，并通过自动驾驶案例进行说明。", "result": "提出了一个整合性的HCHAC框架，展示了人类与AI代理在实际应用中的协同互动，并识别了提升系统有效性、可靠性和伦理整合的未来研究方向。", "conclusion": "HCHAC为人类与AI的协作提供了新的研究视角和范式，其框架和案例研究为未来在多个领域中的应用和发展奠定了基础。"}}
{"id": "2505.22503", "title": "From Strangers to Assistants: Fast Desire Alignment for Embodied Agent-User Adaptation", "authors": ["Yuanfei Wang", "Xinju Huang", "Fangwei Zhong", "Yaodong Yang", "Yizhou Wang", "Yuanpei Chen", "Hao Dong"], "abstract": "While embodied agents have made significant progress in performing complex physical tasks, real-world applications demand more than pure task execution. The agents must collaborate with unfamiliar agents and human users, whose goals are often vague and implicit. In such settings, interpreting ambiguous instructions and uncovering underlying desires is essential for effective assistance. Therefore, fast and accurate desire alignment becomes a critical capability for embodied agents. In this work, we first develop a home assistance simulation environment HA-Desire that integrates an LLM-driven human user agent exhibiting realistic value-driven goal selection and communication. The ego agent must interact with this proxy user to infer and adapt to the user's latent desires. To achieve this, we present a novel framework FAMER for fast desire alignment, which introduces a desire-based mental reasoning mechanism to identify user intent and filter desire-irrelevant actions. We further design a reflection-based communication module that reduces redundant inquiries, and incorporate goal-relevant information extraction with memory persistence to improve information reuse and reduce unnecessary exploration. Extensive experiments demonstrate that our framework significantly enhances both task execution and communication efficiency, enabling embodied agents to quickly adapt to user-specific desires in complex embodied environments.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.22503.pdf", "abstract_url": "https://arxiv.org/abs/2505.22503", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一个名为FAMER的新框架，旨在快速实现具身代理与用户之间的欲望对齐，通过引入基于欲望的心理推理机制和反思式通信模块，显著提高了任务执行和通信效率。", "motivation": "具身代理在复杂物理任务执行方面取得了显著进展，但在实际应用中，代理需要与目标模糊且隐含的不熟悉代理和人类用户协作。因此，快速准确地实现欲望对齐成为具身代理的关键能力。", "method": "开发了一个家庭辅助模拟环境HA-Desire，集成了由LLM驱动的人类用户代理，展示了现实的价值驱动目标选择和通信。提出了FAMER框架，包括基于欲望的心理推理机制、反思式通信模块和目标相关信息提取与记忆持久化。", "result": "大量实验证明，FAMER框架显著提高了任务执行和通信效率，使具身代理能够在复杂的具身环境中快速适应用户特定的欲望。", "conclusion": "FAMER框架通过创新的欲望对齐机制，为具身代理在理解和适应人类用户隐含欲望方面提供了有效的解决方案，具有重要的实际应用价值。"}}
{"id": "2505.22531", "title": "Training RL Agents for Multi-Objective Network Defense Tasks", "authors": ["Andres Molina-Markham", "Luis Robaina", "Sean Steinle", "Akash Trivedi", "Derek Tsui", "Nicholas Potteiger", "Lauren Brandt", "Ransom Winder", "Ahmed Ridley"], "abstract": "Open-ended learning (OEL) -- which emphasizes training agents that achieve broad capability over narrow competency -- is emerging as a paradigm to develop artificial intelligence (AI) agents to achieve robustness and generalization. However, despite promising results that demonstrate the benefits of OEL, applying OEL to develop autonomous agents for real-world cybersecurity applications remains a challenge.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.22531.pdf", "abstract_url": "https://arxiv.org/abs/2505.22531", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Cryptography and Security (cs.CR)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了开放式学习（OEL）在训练多目标网络防御任务中的强化学习（RL）代理的应用，强调了OEL在实现广泛能力而非狭窄能力方面的优势，并指出了将OEL应用于现实世界网络安全自主代理开发的挑战。", "motivation": "解决在现实世界网络安全应用中开发具有鲁棒性和泛化能力的自主代理的挑战。", "method": "采用开放式学习（OEL）方法训练强化学习（RL）代理，以实现多目标网络防御任务。", "result": "尽管OEL展示了其在实现广泛能力方面的优势，但在网络安全领域的实际应用中仍面临挑战。", "conclusion": "开放式学习为开发具有鲁棒性和泛化能力的AI代理提供了有前景的途径，但在网络安全等实际应用中仍需克服特定挑战。"}}
{"id": "2505.22583", "title": "GitGoodBench: A Novel Benchmark For Evaluating Agentic Performance On Git", "authors": ["Tobias Lindenbauer", "Egor Bogomolov", "Yaroslav Zharov"], "abstract": "Benchmarks for Software Engineering (SE) AI agents, most notably SWE-bench, have catalyzed progress in programming capabilities of AI agents. However, they overlook critical developer workflows such as Version Control System (VCS) operations. To address this issue, we present GitGoodBench, a novel benchmark for evaluating AI agent performance on VCS tasks. GitGoodBench covers three core Git scenarios extracted from permissive open-source Python, Java, and Kotlin repositories. Our benchmark provides three datasets: a comprehensive evaluation suite (900 samples), a rapid prototyping version (120 samples), and a training corpus (17,469 samples). We establish baseline performance on the prototyping version of our benchmark using GPT-4o equipped with custom tools, achieving a 21.11% solve rate overall. We expect GitGoodBench to serve as a crucial stepping stone toward truly comprehensive SE agents that go beyond mere programming.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": "Short Paper, 5 pages", "pdf_url": "https://arxiv.org/pdf/2505.22583.pdf", "abstract_url": "https://arxiv.org/abs/2505.22583", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "GitGoodBench是一个新颖的基准测试，旨在评估AI代理在版本控制系统（VCS）任务上的性能，填补了现有软件工程AI代理基准测试在VCS操作方面的空白。", "motivation": "现有的软件工程AI代理基准测试（如SWE-bench）忽视了版本控制系统（VCS）操作等关键开发者工作流程，GitGoodBench旨在解决这一问题。", "method": "GitGoodBench从宽松的开源Python、Java和Kotlin仓库中提取了三个核心Git场景，提供了三个数据集：全面评估套件（900个样本）、快速原型版本（120个样本）和训练语料库（17,469个样本）。", "result": "使用配备自定义工具的GPT-4o在原型版本上建立了基线性能，总体解决率为21.11%。", "conclusion": "GitGoodBench预计将成为实现真正全面软件工程代理的关键一步，超越单纯的编程能力。"}}
{"id": "2505.22642", "title": "FastTD3: Simple, Fast, and Capable Reinforcement Learning for Humanoid Control", "authors": ["Younggyo Seo", "Carmelo Sferrazza", "Haoran Geng", "Michal Nauman", "Zhao-Heng Yin", "Pieter Abbeel"], "abstract": "Reinforcement learning (RL) has driven significant progress in robotics, but its complexity and long training times remain major bottlenecks. In this report, we introduce FastTD3, a simple, fast, and capable RL algorithm that significantly speeds up training for humanoid robots in popular suites such as HumanoidBench, IsaacLab, and MuJoCo Playground. Our recipe is remarkably simple: we train an off-policy TD3 agent with several modifications -- parallel simulation, large-batch updates, a distributional critic, and carefully tuned hyperparameters. FastTD3 solves a range of HumanoidBench tasks in under 3 hours on a single A100 GPU, while remaining stable during training. We also provide a lightweight and easy-to-use implementation of FastTD3 to accelerate RL research in robotics.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.22642.pdf", "abstract_url": "https://arxiv.org/abs/2505.22642", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "FastTD3是一种简单、快速且功能强大的强化学习算法，显著加快了人形机器人在HumanoidBench、IsaacLab和MuJoCo Playground等流行套件中的训练速度。", "motivation": "强化学习在机器人领域取得了显著进展，但其复杂性和长时间的训练仍然是主要瓶颈。", "method": "通过并行模拟、大批量更新、分布评论家以及精心调整的超参数，训练一个离策略的TD3代理。", "result": "FastTD3在单个A100 GPU上不到3小时就能解决一系列HumanoidBench任务，同时在训练过程中保持稳定。", "conclusion": "FastTD3不仅提高了训练效率，还提供了轻量级且易于使用的实现，以加速机器人领域的强化学习研究。"}}
