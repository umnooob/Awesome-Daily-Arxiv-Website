{"id": "2509.13834", "title": "Semi-MoE: Mixture-of-Experts meets Semi-Supervised Histopathology Segmentation", "authors": ["Nguyen Lan Vi Vu", "Thanh-Huy Nguyen", "Thien Nguyen", "Daisuke Kihara", "Tianyang Wang", "Xingjian Li", "Min Xu"], "abstract": "Semi-supervised learning has been employed to alleviate the need for extensive labeled data for histopathology image segmentation, but existing methods struggle with noisy pseudo-labels due to ambiguous gland boundaries and morphological misclassification. This paper introduces Semi-MOE, to the best of our knowledge, the first multi-task Mixture-of-Experts framework for semi-supervised histopathology image segmentation. Our approach leverages three specialized expert networks: A main segmentation expert, a signed distance field regression expert, and a boundary prediction expert, each dedicated to capturing distinct morphological features. Subsequently, the Multi-Gating Pseudo-labeling module dynamically aggregates expert features, enabling a robust fuse-and-refine pseudo-labeling mechanism. Furthermore, to eliminate manual tuning while dynamically balancing multiple learning objectives, we propose an Adaptive Multi-Objective Loss. Extensive experiments on GlaS and CRAG benchmarks show that our method outperforms state-of-the-art approaches in low-label settings, highlighting the potential of MoE-based architectures in advancing semi-supervised segmentation. Our code is available at", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "Accepted to BMVC 2025", "pdf_url": "https://arxiv.org/pdf/2509.13834.pdf", "abstract_url": "https://arxiv.org/abs/2509.13834", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "Semi-MoE是一种用于半监督组织病理学图像分割的多任务混合专家框架，通过三个专家网络和自适应多目标损失，在低标签设置下优于现有方法。", "motivation": "解决半监督学习在组织病理学图像分割中因腺体边界模糊和形态学误分类导致的伪标签噪声问题。", "method": "使用三个专家网络（主分割、有符号距离场回归、边界预测）和多门控伪标签模块，结合自适应多目标损失进行动态平衡。", "result": "在GlaS和CRAG基准测试中，该方法在低标签设置下优于最先进方法。", "conclusion": "MoE架构有潜力推动半监督分割领域的发展，代码已公开。"}}
{"id": "2509.13399", "title": "EdiVal-Agent: An Object-Centric Framework for Automated, Scalable, Fine-Grained Evaluation of Multi-Turn Editing", "authors": ["Tianyu Chen", "Yasi Zhang", "Zhi Zhang", "Peiyu Yu", "Shu Wang", "Zhendong Wang", "Kevin Lin", "Xiaofei Wang", "Zhengyuan Yang", "Linjie Li", "Chung-Ching Lin", "Jianwen Xie", "Oscar Leong", "Lijuan Wang", "Ying Nian Wu", "Mingyuan Zhou"], "abstract": "Instruction-based image editing has advanced rapidly, yet reliable and interpretable evaluation remains a bottleneck. Current protocols either (i) depend on paired reference images -- resulting in limited coverage and inheriting biases from prior generative models -- or (ii) rely solely on zero-shot vision--language models (VLMs), whose prompt-based assessments of instruction following, content consistency, and visual quality are often imprecise.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "Tianyu Chen and Yasi Zhang contributed equally; Oscar Leong, Lijuan Wang, Ying Nian Wu, and Mingyuan Zhou advised equally", "pdf_url": "https://arxiv.org/pdf/2509.13399.pdf", "abstract_url": "https://arxiv.org/abs/2509.13399", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了EdiVal-Agent，一个基于对象的自动化、可扩展、细粒度评估框架，用于多轮图像编辑，以解决当前评估方法的局限性。", "motivation": "指令式图像编辑发展迅速，但可靠且可解释的评估仍是瓶颈，现有方法要么依赖配对参考图像（覆盖有限且存在偏见），要么仅依赖零样本视觉语言模型（评估不精确）。", "method": "使用对象中心框架，自动化、可扩展地进行细粒度评估，可能结合多种评估指标以提高精确度。", "result": "框架能够提供更可靠和可解释的评估结果，提升指令遵循、内容一致性和视觉质量的评估精度。", "conclusion": "EdiVal-Agent框架解决了图像编辑评估的挑战，为未来研究提供了更有效的评估工具。"}}
{"id": "2509.13677", "title": "AgentCTG: Harnessing Multi-Agent Collaboration for Fine-Grained Precise Control in Text Generation", "authors": ["Xinxu Zhou", "Jiaqi Bai", "Zhenqi Sun", "Fanxiang Zeng", "Yue Liu"], "abstract": "Although significant progress has been made in many tasks within the field of Natural Language Processing (NLP), Controlled Text Generation (CTG) continues to face numerous challenges, particularly in achieving fine-grained conditional control over generation. Additionally, in real scenario and online applications, cost considerations, scalability, domain knowledge learning and more precise control are required, presenting more challenge for CTG. This paper introduces a novel and scalable framework, AgentCTG, which aims to enhance precise and complex control over the text generation by simulating the control and regulation mechanisms in multi-agent workflows. We explore various collaboration methods among different agents and introduce an auto-prompt module to further enhance the generation effectiveness. AgentCTG achieves state-of-the-art results on multiple public datasets. To validate its effectiveness in practical applications, we propose a new challenging Character-Driven Rewriting task, which aims to convert the original text into new text that conform to specific character profiles and simultaneously preserve the domain knowledge. When applied to online navigation with role-playing, our approach significantly enhances the driving experience through improved content delivery. By optimizing the generation of contextually relevant text, we enable a more immersive interaction within online communities, fostering greater personalization and user engagement.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.13677.pdf", "abstract_url": "https://arxiv.org/abs/2509.13677", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "AgentCTG是一个新颖且可扩展的框架，通过多代理协作模拟控制机制，增强文本生成的精细控制，在多个数据集上达到最先进性能，并在角色驱动重写和在线导航等实际应用中验证其有效性。", "motivation": "解决受控文本生成（CTG）中实现细粒度条件控制的挑战，特别是在实际应用中需要考虑成本、可扩展性、领域知识学习和更精确控制的问题。", "method": "引入AgentCTG框架，模拟多代理工作流中的控制和调节机制，探索不同代理的协作方法，并集成自动提示模块以提高生成效果。", "result": "在多个公共数据集上取得最先进结果，提出并验证了角色驱动重写任务，在在线导航应用中显著提升内容交付和用户体验。", "conclusion": "AgentCTG通过优化上下文相关文本生成，增强了在线社区的沉浸式互动，促进个性化和用户参与度，展示了其在复杂控制任务中的潜力和实用性。"}}
{"id": "2509.13702", "title": "DSCC-HS: A Dynamic Self-Reinforcing Framework for Hallucination Suppression in Large Language Models", "authors": ["Xiao Zheng"], "abstract": "Large Language Model (LLM) hallucination is a significant barrier to their reliable deployment. Current methods like Retrieval-Augmented Generation (RAG) are often reactive. We introduce **Dynamic Self-reinforcing Calibration for Hallucination Suppression (DSCC-HS)**, a novel, proactive framework that intervenes during autoregressive decoding. Inspired by dual-process cognitive theory, DSCC-HS uses a compact proxy model, trained in adversarial roles as a Factual Alignment Proxy (FAP) and a Hallucination Detection Proxy (HDP). During inference, these proxies dynamically steer a large target model by injecting a real-time steering vector, which is the difference between FAP and HDP logits, at each decoding step. This plug-and-play approach requires no modification to the target model. Our experiments on TruthfulQA and BioGEN show DSCC-HS achieves state-of-the-art performance. On TruthfulQA, it reached a 99.2% Factual Consistency Rate (FCR). On the long-form BioGEN benchmark, it attained the highest FActScore of 46.50. These results validate DSCC-HS as a principled and efficient solution for enhancing LLM factuality.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.13702.pdf", "abstract_url": "https://arxiv.org/abs/2509.13702", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "DSCC-HS是一种新颖的主动框架，通过动态自强化校准抑制大型语言模型中的幻觉，无需修改目标模型，在TruthfulQA和BioGEN基准测试中实现最先进性能。", "motivation": "解决大型语言模型幻觉问题，当前方法如RAG多为被动，需要更主动的干预。", "method": "使用基于双过程认知理论的紧凑代理模型（FAP和HDP），在自回归解码过程中注入实时转向向量。", "result": "在TruthfulQA上实现99.2%的事实一致性率，在BioGEN上获得最高FActScore 46.50。", "conclusion": "DSCC-HS是增强LLM事实性的原则性和高效解决方案。"}}
{"id": "2509.13930", "title": "Linguistic Nepotism: Trading-off Quality for Language Preference in Multilingual RAG", "authors": ["Dayeon Ki", "Marine Carpuat", "Paul McNamee", "Daniel Khashabi", "Eugene Yang", "Dawn Lawrie", "Kevin Duh"], "abstract": "Multilingual Retrieval-Augmented Generation (mRAG) systems enable language models to answer knowledge-intensive queries with citation-supported responses across languages. While such systems have been proposed, an open questions is whether the mixture of different document languages impacts generation and citation in unintended ways. To investigate, we introduce a controlled methodology using model internals to measure language preference while holding other factors such as document relevance constant. Across eight languages and six open-weight models, we find that models preferentially cite English sources when queries are in English, with this bias amplified for lower-resource languages and for documents positioned mid-context. Crucially, we find that models sometimes trade-off document relevance for language preference, indicating that citation choices are not always driven by informativeness alone. Our findings shed light on how language models leverage multilingual context and influence citation behavior.", "subjects": "Computation and Language (cs.CL)", "comments": "33 pages, 20 figures", "pdf_url": "https://arxiv.org/pdf/2509.13930.pdf", "abstract_url": "https://arxiv.org/abs/2509.13930", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文通过模型内部测量方法，发现在多语言RAG系统中，模型倾向于引用英语来源，尤其是在查询为英语时，这种偏见在低资源语言和文档位于上下文中间位置时更为明显，有时会牺牲文档相关性。", "motivation": "解决多语言检索增强生成系统中，不同语言文档混合是否对生成和引用产生意外影响的问题。", "method": "使用模型内部测量方法，控制文档相关性等因素，测量语言偏好，覆盖八种语言和六个开源模型。", "result": "模型优先引用英语来源，偏见在低资源语言和中间位置文档中放大，有时以牺牲相关性为代价。", "conclusion": "揭示了语言模型如何利用多语言上下文并影响引用行为，表明引用选择不总是由信息性驱动。"}}
{"id": "2509.13869", "title": "Do LLMs Align Human Values Regarding Social Biases? Judging and Explaining Social Biases with LLMs", "authors": ["Yang Liu", "Chenhui Chu"], "abstract": "Large language models (LLMs) can lead to undesired consequences when misaligned with human values, especially in scenarios involving complex and sensitive social biases. Previous studies have revealed the misalignment of LLMs with human values using expert-designed or agent-based emulated bias scenarios. However, it remains unclear whether the alignment of LLMs with human values differs across different types of scenarios (e.g., scenarios containing negative vs. non-negative questions). In this study, we investigate the alignment of LLMs with human values regarding social biases (HVSB) in different types of bias scenarios. Through extensive analysis of 12 LLMs from four model families and four datasets, we demonstrate that LLMs with large model parameter scales do not necessarily have lower misalignment rate and attack success rate. Moreover, LLMs show a certain degree of alignment preference for specific types of scenarios and the LLMs from the same model family tend to have higher judgment consistency. In addition, we study the understanding capacity of LLMs with their explanations of HVSB. We find no significant differences in the understanding of HVSB across LLMs. We also find LLMs prefer their own generated explanations. Additionally, we endow smaller language models (LMs) with the ability to explain HVSB. The generation results show that the explanations generated by the fine-tuned smaller LMs are more readable, but have a relatively lower model agreeability.", "subjects": "Computation and Language (cs.CL)", "comments": "38 pages, 31 figures", "pdf_url": "https://arxiv.org/pdf/2509.13869.pdf", "abstract_url": "https://arxiv.org/abs/2509.13869", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "该研究探讨大型语言模型（LLMs）在涉及社会偏见的场景中与人类价值观的对齐情况，发现模型规模不必然降低误对齐率，且模型对特定场景有偏好，解释能力无显著差异，小型模型微调后可生成更易读但同意度较低的解释。", "motivation": "解决LLMs在复杂敏感社会偏见场景中与人类价值观的潜在误对齐问题，以评估不同类型场景下的对齐差异。", "method": "分析12个LLMs在四个数据集上的表现，包括误对齐率和攻击成功率评估，并研究模型对偏见场景的判断和解释能力，包括微调小型模型。", "result": "大模型规模不保证更好对齐，模型对特定场景有偏好，家族内模型一致性高；LLMs解释能力无显著差异，偏好自身生成解释；微调小模型生成更易读但同意度较低的解释。", "conclusion": "LLMs在社会偏见价值观对齐上存在不一致性，需改进对齐方法，微调小模型可提升解释可读性但需平衡同意度，对AI伦理和模型开发有启示。"}}
{"id": "2509.13341", "title": "Imagined Autocurricula", "authors": ["Ahmet H. Güzel", "Matthew Thomas Jackson", "Jarek Luca Liesen", "Tim Rocktäschel", "Jakob Nicolaus Foerster", "Ilija Bogunovic", "Jack Parker-Holder"], "abstract": "Training agents to act in embodied environments typically requires vast training data or access to accurate simulation, neither of which exists for many cases in the real world. Instead, world models are emerging as an alternative leveraging offline, passively collected data, they make it possible to generate diverse worlds for training agents in simulation. In this work, we harness world models to generate imagined environments to train robust agents capable of generalizing to novel task variations. One of the challenges in doing this is ensuring the agent trains on useful generated data. We thus propose a novel approach, IMAC (Imagined Autocurricula), leveraging Unsupervised Environment Design (UED), which induces an automatic curriculum over generated worlds. In a series of challenging, procedurally generated environments, we show it is possible to achieve strong transfer performance on held-out environments, having trained only inside a world model learned from a narrower dataset. We believe this opens the path to utilizing larger-scale, foundation world models for generally capable agents.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.13341.pdf", "abstract_url": "https://arxiv.org/abs/2509.13341", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出IMAC方法，利用世界模型生成想象环境，通过无监督环境设计自动课程训练智能体，实现在有限数据下泛化到新任务。", "motivation": "解决在真实世界中训练智能体时缺乏大量训练数据或准确仿真的问题，利用离线被动数据生成多样环境。", "method": "使用世界模型生成想象环境，结合无监督环境设计（UED）自动创建训练课程，确保智能体在有用数据上训练。", "result": "在程序生成环境中，仅使用窄数据集学习的世界模型训练后，智能体在保留环境中表现出强大的泛化性能。", "conclusion": "该方法为利用大规模基础世界模型训练通用智能体开辟了新途径。"}}
{"id": "2509.13347", "title": "OpenHA: A Series of Open-Source Hierarchical Agentic Models in Minecraft", "authors": ["Zihao Wang", "Muyao Li", "Kaichen He", "Xiangyu Wang", "Zhancun Mu", "Anji Liu", "Yitao Liang"], "abstract": "The choice of action spaces is a critical yet unresolved challenge in developing capable, end-to-end trainable agents. This paper first presents a large-scale, systematic comparison of prominent abstracted action spaces and tokenizers for Vision-Language-Action (VLA) or hierarchical agent models in the open-ended Minecraft. Our analysis reveals that no single action space is universally optimal; instead, the most effective abstraction is highly task-dependent, creating a dilemma for building generalist agents. To resolve this, we introduce Chain of Action (CoA), a novel framework that unifies high-level planning and low-level control within a single, monolithic VLA model. CoA treats an abstracted action not as a command for a separate policy, but as an intermediate reasoning step--akin to a chain of thought--that guides the generation of the final, executable action. Furthermore, we demonstrate that an All-in-One agent trained on a diverse mixture of action spaces using the CoA paradigm learns a more robust and generalizable policy. This unified agent achieves a new state-of-the-art, improving the overall task success rate over strong, specialized baselines. To foster reproducible research, we release the OpenHA (Open Hierarchical Agents) suite, which includes our comprehensive benchmark of over 800 distinct tasks, curated datasets, source code, and all pretrained model checkpoints at", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.13347.pdf", "abstract_url": "https://arxiv.org/abs/2509.13347", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了OpenHA套件，包括在Minecraft中比较动作空间、提出Chain of Action框架以统一规划和控制，并通过混合训练实现最先进的通用代理。", "motivation": "解决在开发端到端可训练代理时，动作空间选择这一关键但未解决的挑战，以构建更通用的代理。", "method": "使用Chain of Action框架，将抽象动作视为中间推理步骤，指导最终可执行动作的生成，并在多样动作空间上训练All-in-One代理。", "result": "统一代理在超过800个任务上实现了新的最先进性能，提高了任务成功率，超越了专门的基线模型。", "conclusion": "CoA框架和混合训练方法能学习更鲁棒和可泛化的策略，推动通用代理的发展，并通过开源套件促进可重复研究。"}}
{"id": "2509.13352", "title": "Agentic UAVs: LLM-Driven Autonomy with Integrated Tool-Calling and Cognitive Reasoning", "authors": ["Anis Koubaa", "Khaled Gabr"], "abstract": "Unmanned Aerial Vehicles (UAVs) are increasingly deployed in defense, surveillance, and disaster response, yet most systems remain confined to SAE Level 2--3 autonomy. Their reliance on rule-based control and narrow AI restricts adaptability in dynamic, uncertain missions. Existing UAV frameworks lack context-aware reasoning, autonomous decision-making, and ecosystem-level integration; critically, none leverage Large Language Model (LLM) agents with tool-calling for real-time knowledge access. This paper introduces the Agentic UAVs framework, a five-layer architecture (Perception, Reasoning, Action, Integration, Learning) that augments UAVs with LLM-driven reasoning, database querying, and third-party system interaction. A ROS2 and Gazebo-based prototype integrates YOLOv11 object detection with GPT-4 reasoning and local Gemma-3 deployment. In simulated search-and-rescue scenarios, agentic UAVs achieved higher detection confidence (0.79 vs. 0.72), improved person detection rates (91% vs. 75%), and markedly increased action recommendation (92% vs. 4.5%). These results confirm that modest computational overhead enables qualitatively new levels of autonomy and ecosystem integration.", "subjects": "Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": "14 pages, 1 figure", "pdf_url": "https://arxiv.org/pdf/2509.13352.pdf", "abstract_url": "https://arxiv.org/abs/2509.13352", "categories": ["Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了Agentic UAVs框架，利用LLM驱动的推理和工具调用，提升无人机在动态任务中的自主性和集成能力，模拟实验显示检测和推荐性能显著改善。", "motivation": "解决无人机在防御、监视和灾难响应中因依赖规则控制和窄AI而缺乏上下文感知推理、自主决策和生态系统集成的问题，特别是未利用LLM代理进行实时知识访问。", "method": "采用五层架构（感知、推理、行动、集成、学习），结合ROS2和Gazebo原型，集成YOLOv11对象检测、GPT-4推理和本地Gemma-3部署。", "result": "在模拟搜救场景中，检测置信度从0.72提高到0.79，人员检测率从75%提升到91%，行动推荐率从4.5%大幅增加到92%。", "conclusion": "适度的计算开销可实现新的自主水平和生态系统集成，证实LLM驱动方法在无人机领域的有效性。"}}
{"id": "2509.13368", "title": "$Agent^2$: An Agent-Generates-Agent Framework for Reinforcement Learning Automation", "authors": ["Yuan Wei", "Xiaohan Shan", "Ran Miao", "Jianmin Li"], "abstract": "Reinforcement learning agent development traditionally requires extensive expertise and lengthy iterations, often resulting in high failure rates and limited accessibility. This paper introduces $Agent^2$, a novel agent-generates-agent framework that achieves fully automated RL agent design through intelligent LLM-driven generation. The system autonomously transforms natural language task descriptions and environment code into comprehensive, high-performance reinforcement learning solutions without human intervention. $Agent^2$ features a revolutionary dual-agent architecture. The Generator Agent serves as an autonomous AI designer that analyzes tasks and generates executable RL agents, while the Target Agent is the resulting automatically generated RL agent. The framework decomposes RL development into two distinct stages: MDP modeling and algorithmic optimization, enabling more targeted and effective agent generation. Built on the Model Context Protocol, $Agent^2$ provides a unified framework that standardizes intelligent agent creation across diverse environments and algorithms, while incorporating adaptive training management and intelligent feedback analysis for continuous improvement. Extensive experiments on a wide range of benchmarks, including MuJoCo, MetaDrive, MPE, and SMAC, demonstrate that $Agent^2$ consistently outperforms manually designed solutions across all tasks, achieving up to 55% performance improvement and substantial gains on average. By enabling truly end-to-end, closed-loop automation, this work establishes a new paradigm in which intelligent agents design and optimize other agents, marking a fundamental breakthrough for automated AI systems.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "9 pages, 7 figures", "pdf_url": "https://arxiv.org/pdf/2509.13368.pdf", "abstract_url": "https://arxiv.org/abs/2509.13368", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一种名为Agent^2的框架，通过LLM驱动的智能生成，实现完全自动化的强化学习代理设计，无需人工干预，并在多个基准测试中显著超越手动设计的解决方案。", "motivation": "强化学习代理开发传统上需要专业知识和长时间迭代，失败率高且可访问性有限，旨在解决这些问题。", "method": "采用双代理架构，包括生成器代理分析任务并生成可执行代理，目标代理是生成的强化学习代理，分解开发为MDP建模和算法优化阶段，基于模型上下文协议实现标准化。", "result": "在MuJoCo、MetaDrive、MPE和SMAC等基准测试中，Agent^2始终优于手动设计，性能提升高达55%，平均增益显著。", "conclusion": "该工作确立了智能代理设计和优化的新范式，为自动化AI系统带来根本性突破，实现端到端闭环自动化。"}}
{"id": "2509.13547", "title": "AI Agents with Human-Like Collaborative Tools: Adaptive Strategies for Enhanced Problem-Solving", "authors": ["Harper Reed", "Michael Sugimura", "Angelo Zangari"], "abstract": "We investigate whether giving LLM agents the collaborative tools and autonomy that humans naturally use for problem solving can improve their performance. We equip Claude Code agents with MCP-based social media and journaling tools and allow them to use these tools as they see fit. Across 34 Aider Polyglot Python programming challenges, collaborative tools substantially improve performance on the hardest problems, delivering 15-40% lower cost, 12-27% fewer turns, and 12-38% faster completion than baseline agents. Effects on the full challenge set are mixed, suggesting these tools act as performance enhancers when additional reasoning scaffolding is most needed. Surprisingly, Different models naturally adopted distinct collaborative strategies without explicit instruction. Sonnet 3.7 engaged broadly across tools and benefited from articulation-based cognitive scaffolding. Sonnet 4 showed selective adoption, leaning on journal-based semantic search when problems were genuinely difficult. This mirrors how human developers adjust collaboration based on expertise and task complexity. Behavioral analysis shows agents prefer writing over reading by about 2-9x, indicating that structured articulation drives much of the improvement rather than information access alone. Overall, AI agents can systematically benefit from human-inspired collaboration tools at the edge of their capabilities, pointing to adaptive collaborative interfaces as reasoning enhancers rather than universal efficiency boosts.", "subjects": "Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)", "comments": "16 pages, 5 tables", "pdf_url": "https://arxiv.org/pdf/2509.13547.pdf", "abstract_url": "https://arxiv.org/abs/2509.13547", "categories": ["Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "研究通过赋予LLM代理类似人类的协作工具和自主性，在编程挑战中显著提升性能，尤其在难题上降低成本、减少交互次数并加快完成速度，不同模型展现出自适应协作策略。", "motivation": "解决LLM代理在复杂问题解决中性能不足的问题，通过模拟人类协作工具来增强其能力。", "method": "为Claude Code代理配备MCP-based社交媒体和日志工具，允许其自主使用，并在34个Aider Polyglot Python编程挑战中测试。", "result": "在难题上性能提升15-40%成本降低、12-27%交互减少、12-38%完成加速；不同模型采用不同协作策略，代理偏好书写而非阅读。", "conclusion": "AI代理能从人类启发式协作工具中获益，尤其在能力边缘，表明自适应协作界面可作为推理增强器，而非普遍效率提升。"}}
{"id": "2509.14034", "title": "Enhancing Multi-Agent Debate System Performance via Confidence Expression", "authors": ["Zijie Lin", "Bryan Hooi"], "abstract": "Generative Large Language Models (LLMs) have demonstrated remarkable performance across a wide range of tasks. Recent research has introduced Multi-Agent Debate (MAD) systems, which leverage multiple LLMs to simulate human debate and thereby improve task performance. However, while some LLMs may possess superior knowledge or reasoning capabilities for specific tasks, they often struggle to clearly communicate this advantage during debates, in part due to a lack of confidence expression. Moreover, inappropriate confidence expression can cause agents in MAD systems to either stubbornly maintain incorrect beliefs or converge prematurely on suboptimal answers, ultimately reducing debate effectiveness and overall system performance. To address these challenges, we propose incorporating confidence expression into MAD systems to allow LLMs to explicitly communicate their confidence levels. To validate this approach, we develop ConfMAD, a MAD framework that integrates confidence expression throughout the debate process. Experimental results demonstrate the effectiveness of our method, and we further analyze how confidence influences debate dynamics, offering insights into the design of confidence-aware MAD systems.", "subjects": "Computation and Language (cs.CL)", "comments": "EMNLP'25 Findings", "pdf_url": "https://arxiv.org/pdf/2509.14034.pdf", "abstract_url": "https://arxiv.org/abs/2509.14034", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "通过引入置信度表达，提出ConfMAD框架，增强多智能体辩论系统性能，实验验证其有效性。", "motivation": "解决多智能体辩论系统中LLMs因缺乏置信度表达而无法有效沟通优势，导致固执或过早收敛于次优答案的问题。", "method": "开发ConfMAD框架，将置信度表达整合到辩论过程中，使LLMs能明确传达置信水平。", "result": "实验结果显示方法有效，并分析了置信度对辩论动态的影响，为设计置信感知系统提供见解。", "conclusion": "置信度表达能提升辩论效果和系统性能，对多智能体辩论系统的设计具有指导意义。"}}
{"id": "2509.14180", "title": "Synthesizing Behaviorally-Grounded Reasoning Chains: A Data-Generation Framework for Personal Finance LLMs", "authors": ["Akhil Theerthala"], "abstract": "Personalized financial advice requires consideration of user goals, constraints, risk tolerance, and jurisdiction. Prior LLM work has focused on support systems for investors and financial planners. Simultaneously, numerous recent studies examine broader personal finance tasks, including budgeting, debt management, retirement, and estate planning, through agentic pipelines that incur high maintenance costs, yielding less than 25% of their expected financial returns. In this study, we introduce a novel and reproducible framework that integrates relevant financial context with behavioral finance studies to construct supervision data for end-to-end advisors. Using this framework, we create a 19k sample reasoning dataset and conduct a comprehensive fine-tuning of the Qwen-3-8B model on the dataset. Through a held-out test split and a blind LLM-jury study, we demonstrate that through careful data curation and behavioral integration, our 8B model achieves performance comparable to significantly larger baselines (14-32B parameters) across factual accuracy, fluency, and personalization metrics while incurring 80% lower costs than the larger counterparts.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "24 pages, 11 figures. The paper presents a novel framework for generating a personal finance dataset. The resulting fine-tuned model and dataset are publicly available", "pdf_url": "https://arxiv.org/pdf/2509.14180.pdf", "abstract_url": "https://arxiv.org/abs/2509.14180", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种结合金融背景和行为金融学的新框架，用于生成监督数据，通过微调Qwen-3-8B模型，在个性化财务建议任务中实现与更大模型相当的性能，同时降低成本。", "motivation": "解决个性化财务建议中现有方法维护成本高、财务回报低的问题，需要整合用户目标和行为因素。", "method": "开发一个可复现的框架，整合金融上下文和行为金融学研究，生成19k样本推理数据集，并微调Qwen-3-8B模型。", "result": "在测试和盲审研究中，8B参数模型在事实准确性、流畅性和个性化指标上表现与14-32B参数基线相当，成本降低80%。", "conclusion": "通过精心数据策划和行为整合，较小模型可实现高效财务建议，降低资源消耗，具有实际应用价值。"}}
{"id": "2509.13588", "title": "Programmable Cognitive Bias in Social Agents", "authors": ["Xuan Liu", "Haoyang Shang", "Haojian Jin"], "abstract": "This paper introduces CoBRA, a novel toolkit for systematically specifying agent behavior in LLM-based social simulation. We found that conventional approaches that specify agent behaviors through implicit natural language descriptions cannot yield consistent behaviors across models, and the produced agent behaviors do not capture the nuances of the descriptions. In contrast, CoBRA presents a new approach to program agents' cognitive biases explicitly, by grounding agents' expected behaviors using classic social science experiments. CoBRA has two components: (1) Cognitive Bias Index that measures the cognitive bias of a social agent, by quantifying the agent's reactions in a set of validated classical social science experiments; (2) Behavioral Regulation Engine that aligns the agent's behavior to demonstrate controlled cognitive bias. We evaluated CoBRA as an HCI toolkit through demonstration and technical benchmarks. Our results suggest that CoBRA can precisely program the cognitive bias demonstrated in a social agent in a model-agnostic manner.", "subjects": "Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Computers and Society (cs.CY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.13588.pdf", "abstract_url": "https://arxiv.org/abs/2509.13588", "categories": ["Artificial Intelligence (cs.AI)", "Computational Engineering, Finance, and Science (cs.CE)", "Computers and Society (cs.CY)"], "matching_keywords": ["agent"], "AI": {"tldr": "CoBRA工具包通过经典社会科学实验，以模型无关的方式精确编程基于LLM的社交模拟中代理的认知偏见行为。", "motivation": "传统方法使用隐式自然语言描述指定代理行为，导致跨模型行为不一致且无法捕捉描述细微差别。", "method": "CoBRA包括认知偏见指数（通过经典实验量化偏见）和行为调节引擎（对齐行为以控制偏见）。", "result": "评估显示CoBRA能精确编程代理的认知偏见，模型无关。", "conclusion": "CoBRA提供了一种系统化方法，提升社交模拟中代理行为的可控性和一致性。"}}
{"id": "2509.13356", "title": "CogniAlign: Survivability-Grounded Multi-Agent Moral Reasoning for Safe and Transparent AI", "authors": ["Hasin Jawad Ali", "Ilhamul Azam", "Ajwad Abrar", "Md. Kamrul Hasan", "Hasan Mahmud"], "abstract": "The challenge of aligning artificial intelligence (AI) with human values persists due to the abstract and often conflicting nature of moral principles and the opacity of existing approaches. This paper introduces CogniAlign, a multi-agent deliberation framework based on naturalistic moral realism, that grounds moral reasoning in survivability, defined across individual and collective dimensions, and operationalizes it through structured deliberations among discipline-specific scientist agents. Each agent, representing neuroscience, psychology, sociology, and evolutionary biology, provides arguments and rebuttals that are synthesized by an arbiter into transparent and empirically anchored judgments. We evaluate CogniAlign on classic and novel moral questions and compare its outputs against GPT-4o using a five-part ethical audit framework. Results show that CogniAlign consistently outperforms the baseline across more than sixty moral questions, with average performance gains of 16.2 points in analytic quality, 14.3 points in breadth, and 28.4 points in depth of explanation. In the Heinz dilemma, for example, CogniAlign achieved an overall score of 89.2 compared to GPT-4o's 69.2, demonstrating a decisive advantage in handling moral reasoning. By reducing black-box reasoning and avoiding deceptive alignment, CogniAlign highlights the potential of interdisciplinary deliberation as a scalable pathway for safe and transparent AI alignment.", "subjects": "Computers and Society (cs.CY); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.13356.pdf", "abstract_url": "https://arxiv.org/abs/2509.13356", "categories": ["Computers and Society (cs.CY)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "CogniAlign is a multi-agent framework using interdisciplinary deliberation for AI moral reasoning, outperforming GPT-4o in ethical audits.", "motivation": "To address the challenge of aligning AI with human values due to abstract moral principles and opaque methods.", "method": "Uses a multi-agent system with agents from neuroscience, psychology, sociology, and evolutionary biology for structured deliberations based on survivability, synthesized by an arbiter.", "result": "Outperforms GPT-4o by average gains of 16.2 points in analytic quality, 14.3 in breadth, and 28.4 in depth, with an 89.2 score vs. 69.2 in the Heinz dilemma.", "conclusion": "Demonstrates the potential of interdisciplinary deliberation for scalable, safe, and transparent AI alignment, reducing black-box reasoning and deceptive alignment."}}
{"id": "2509.13615", "title": "See, Think, Act: Teaching Multimodal Agents to Effectively Interact with GUI by Identifying Toggles", "authors": ["Zongru Wu", "Rui Mao", "Zhiyuan Tian", "Pengzhou Cheng", "Tianjie Ju", "Zheng Wu", "Lingzhong Dong", "Haiyue Sheng", "Zhuosheng Zhang", "Gongshen Liu"], "abstract": "The advent of multimodal agents facilitates effective interaction within graphical user interface (GUI), especially in ubiquitous GUI control. However, their inability to reliably execute toggle control instructions remains a key bottleneck. To investigate this, we construct a state control benchmark with binary toggle instructions from public datasets. Evaluations of existing agents demonstrate their unreliability, particularly when the current toggle state already matches the desired state. To address the challenge, we propose State-aware Reasoning (StaR), a training method that teaches agents to perceive the current toggle state, analyze the desired state from the instruction, and act accordingly. Experiments on three multimodal agents demonstrate that StaR can improve toggle instruction execution accuracy by over 30\\%. Further evaluations on three public benchmarks show that StaR also enhances general task performance. Finally, evaluations on a dynamic environment highlight the potential of StaR for real-world applications. Code, benchmark, and StaR-enhanced agents are available at", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.13615.pdf", "abstract_url": "https://arxiv.org/abs/2509.13615", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出State-aware Reasoning (StaR)方法，通过教导多模态代理感知当前切换状态并相应行动，提高GUI中切换指令执行的准确性，实验显示性能提升超过30%。", "motivation": "解决多模态代理在图形用户界面(GUI)中执行切换控制指令不可靠的问题，特别是在当前状态与期望状态匹配时。", "method": "使用State-aware Reasoning (StaR)训练方法，教导代理感知当前切换状态、分析指令中的期望状态，并据此行动。", "result": "在三个多模态代理上，StaR将切换指令执行准确性提高超过30%；在三个公共基准测试中，一般任务性能也得到提升；动态环境评估显示其在实际应用中的潜力。", "conclusion": "StaR方法有效解决了GUI交互中的切换控制瓶颈，提高了代理的可靠性和泛化能力，代码和基准已公开。"}}
{"id": "2509.13704", "title": "InfraMind: A Novel Exploration-based GUI Agentic Framework for Mission-critical Industrial Management", "authors": ["Liangtao Lin", "Zhaomeng Zhu", "Tianwei Zhang", "Yonggang Wen"], "abstract": "Mission-critical industrial infrastructure, such as data centers, increasingly depends on complex management software. Its operations, however, pose significant challenges due to the escalating system complexity, multi-vendor integration, and a shortage of expert operators. While Robotic Process Automation (RPA) offers partial automation through handcrafted scripts, it suffers from limited flexibility and high maintenance costs. Recent advances in Large Language Model (LLM)-based graphical user interface (GUI) agents have enabled more flexible automation, yet these general-purpose agents face five critical challenges when applied to industrial management, including unfamiliar element understanding, precision and efficiency, state localization, deployment constraints, and safety requirements. To address these issues, we propose InfraMind, a novel exploration-based GUI agentic framework specifically tailored for industrial management systems. InfraMind integrates five innovative modules to systematically resolve different challenges in industrial management: (1) systematic search-based exploration with virtual machine snapshots for autonomous understanding of complex GUIs; (2) memory-driven planning to ensure high-precision and efficient task execution; (3) advanced state identification for robust localization in hierarchical interfaces; (4) structured knowledge distillation for efficient deployment with lightweight models; and (5) comprehensive, multi-layered safety mechanisms to safeguard sensitive operations. Extensive experiments on both open-source and commercial DCIM platforms demonstrate that our approach consistently outperforms existing frameworks in terms of task success rate and operational efficiency, providing a rigorous and scalable solution for industrial management automation.", "subjects": "Artificial Intelligence (cs.AI); Software Engineering (cs.SE)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.13704.pdf", "abstract_url": "https://arxiv.org/abs/2509.13704", "categories": ["Artificial Intelligence (cs.AI)", "Software Engineering (cs.SE)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "InfraMind是一个基于探索的GUI代理框架，专为工业管理系统设计，通过五个创新模块解决复杂GUI自动化挑战，在实验中优于现有框架。", "motivation": "解决关键工业基础设施管理中系统复杂性、多供应商集成和专家短缺问题，以及现有RPA和LLM代理的局限性。", "method": "集成五个模块：系统搜索探索、内存驱动规划、高级状态识别、结构化知识蒸馏和多层安全机制。", "result": "在开源和商业DCIM平台上实验显示，任务成功率和操作效率优于现有框架。", "conclusion": "InfraMind提供了一个严谨且可扩展的工业管理自动化解决方案，有效应对挑战。"}}
{"id": "2509.13761", "title": "THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning", "authors": ["Qikai Chang", "Zhenrong Zhang", "Pengfei Hu", "Jiefeng Ma", "Yicheng Pan", "Jianshu Zhang", "Jun Du", "Quan Liu", "Jianqing Gao"], "abstract": "Large Language Models (LLMs) have made remarkable progress in mathematical reasoning, but still continue to struggle with high-precision tasks like numerical computation and formal symbolic manipulation. Integrating external tools has emerged as a promising approach to bridge this gap. Despite recent advances, existing methods struggle with three key challenges: constructing tool-integrated reasoning data, performing fine-grained optimization, and enhancing inference. To overcome these limitations, we propose THOR (Tool-Integrated Hierarchical Optimization via RL). First, we introduce TIRGen, a multi-agent actor-critic-based pipeline for constructing high-quality datasets of tool-integrated reasoning paths, aligning with the policy and generalizing well across diverse models. Second, to perform fine-grained hierarchical optimization, we introduce an RL strategy that jointly optimizes for both trajectory-level problem solving and step-level code generation. This is motivated by our key insight that the success of an intermediate tool call is a strong predictor of the final answer's correctness. Finally, THOR incorporates a self-correction mechanism that leverages immediate tool feedback to dynamically revise erroneous reasoning paths during inference. Our approach demonstrates strong generalization across diverse models, performing effectively in both reasoning and non-reasoning models. It further achieves state-of-the-art performance for models of a similar scale on multiple mathematical benchmarks, while also delivering consistent improvements on code benchmarks. Our code will be publicly available at", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "22 pages, 13 figures", "pdf_url": "https://arxiv.org/pdf/2509.13761.pdf", "abstract_url": "https://arxiv.org/abs/2509.13761", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "THOR通过强化学习和工具集成，提升大语言模型在数学推理中的精确计算和符号操作能力，构建高质量数据集并优化推理路径。", "motivation": "解决大语言模型在数学推理中高精度任务（如数值计算和符号操作）的不足，通过工具集成来弥补差距。", "method": "使用TIRGen多智能体管道构建数据集，结合强化学习进行层次优化，并集成自校正机制利用工具反馈动态修正推理。", "result": "在多个数学和代码基准测试中达到最先进性能，并有效泛化到不同模型。", "conclusion": "THOR方法显著提升了工具集成推理的效率和准确性，具有广泛的应用潜力。"}}
{"id": "2509.13941", "title": "An Empirical Study on Failures in Automated Issue Solving", "authors": ["Simiao Liu", "Fang Liu", "Liehao Li", "Xin Tan", "Yinghao Zhu", "Xiaoli Lian", "Li Zhang"], "abstract": "Automated issue solving seeks to autonomously identify and repair defective code snippets across an entire codebase. SWE-Bench has emerged as the most widely adopted benchmark for evaluating progress in this area. While LLM-based agentic tools show great promise, they still fail on a substantial portion of tasks. Moreover, current evaluations primarily report aggregate issue-solving rates, which obscure the underlying causes of success and failure, making it challenging to diagnose model weaknesses or guide targeted improvements. To bridge this gap, we first analyze the performance and efficiency of three SOTA tools, spanning both pipeline-based and agentic architectures, in automated issue solving tasks of SWE-Bench-Verified under varying task characteristics. Furthermore, to move from high-level performance metrics to underlying cause analysis, we conducted a systematic manual analysis of 150 failed instances. From this analysis, we developed a comprehensive taxonomy of failure modes comprising 3 primary phases, 9 main categories, and 25 fine-grained subcategories. Then we systematically analyze the distribution of the identified failure modes, the results reveal distinct failure fingerprints between the two architectural paradigms, with the majority of agentic failures stemming from flawed reasoning and cognitive deadlocks. Motivated by these insights, we propose a collaborative Expert-Executor framework. It introduces a supervisory Expert agent tasked with providing strategic oversight and course-correction for a primary Executor agent. This architecture is designed to correct flawed reasoning and break the cognitive deadlocks that frequently lead to failure. Experiments show that our framework solves 22.2% of previously intractable issues for a leading single agent. These findings pave the way for building more robust agents through diagnostic evaluation and collaborative design.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.13941.pdf", "abstract_url": "https://arxiv.org/abs/2509.13941", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "对SWE-Bench中自动化问题解决失败进行实证研究，开发失败模式分类法，并提出协作专家-执行者框架以提升性能。", "motivation": "当前评估主要报告聚合成功率，掩盖失败原因，难以诊断模型弱点或指导改进。", "method": "分析SOTA工具性能，手动分析150个失败实例以开发分类法，并设计协作框架进行实验验证。", "result": "识别出失败模式分布，显示代理架构失败多源于推理缺陷和认知死锁；协作框架解决22.2%先前无法处理的问题。", "conclusion": "通过诊断评估和协作设计，可构建更鲁棒的代理，推动自动化问题解决领域的进步。"}}
{"id": "2509.14030", "title": "CrowdAgent: Multi-Agent Managed Multi-Source Annotation System", "authors": ["Maosheng Qin", "Renyu Zhu", "Mingxuan Xia", "Chenkai Chen", "Zhen Zhu", "Minmin Lin", "Junbo Zhao", "Lu Xu", "Changjie Fan", "Runze Wu", "Haobo Wang"], "abstract": "High-quality annotated data is a cornerstone of modern Natural Language Processing (NLP). While recent methods begin to leverage diverse annotation sources-including Large Language Models (LLMs), Small Language Models (SLMs), and human experts-they often focus narrowly on the labeling step itself. A critical gap remains in the holistic process control required to manage these sources dynamically, addressing complex scheduling and quality-cost trade-offs in a unified manner. Inspired by real-world crowdsourcing companies, we introduce CrowdAgent, a multi-agent system that provides end-to-end process control by integrating task assignment, data annotation, and quality/cost management. It implements a novel methodology that rationally assigns tasks, enabling LLMs, SLMs, and human experts to advance synergistically in a collaborative annotation workflow. We demonstrate the effectiveness of CrowdAgent through extensive experiments on six diverse multimodal classification tasks. The source code and video demo are available at", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14030.pdf", "abstract_url": "https://arxiv.org/abs/2509.14030", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "CrowdAgent是一个多代理系统，通过整合任务分配、数据标注和质量/成本管理，提供端到端的过程控制，以动态管理LLM、SLM和人类专家等多样注释源，在六个多模态分类任务上验证了其有效性。", "motivation": "解决NLP中高质量注释数据的需求，现有方法仅关注标注步骤，缺乏对动态管理多样注释源、处理复杂调度和质量成本权衡的整体过程控制。", "method": "引入多代理系统CrowdAgent，采用新颖方法合理分配任务，使LLM、SLM和人类专家在协作标注工作流中协同工作，实现任务分配、标注和质量/成本管理的集成。", "result": "在六个多样多模态分类任务上进行广泛实验，证明了CrowdAgent的有效性。", "conclusion": "CrowdAgent提供了一种统一的方法来管理注释过程，解决了质量与成本的权衡问题，提升了NLP数据标注的效率和质量。"}}
{"id": "2509.14132", "title": "When Avatars Have Personality: Effects on Engagement and Communication in Immersive Medical Training", "authors": ["Julia S. Dollis", "Iago A. Brito", "Fernanda B. Färber", "Pedro S. F. B. Ribeiro", "Rafael T. Sousa", "Arlindo R. Galvão Filho"], "abstract": "While virtual reality (VR) excels at simulating physical environments, its effectiveness for training complex interpersonal skills is limited by a lack of psychologically plausible virtual humans. This is a critical gap in high-stakes domains like medical education, where communication is a core competency. This paper introduces a framework that integrates large language models (LLMs) into immersive VR to create medically coherent virtual patients with distinct, consistent personalities, built on a modular architecture that decouples personality from clinical data. We evaluated our system in a mixed-method, within-subjects study with licensed physicians who engaged in simulated consultations. Results demonstrate that the approach is not only feasible but is also perceived by physicians as a highly rewarding and effective training enhancement. Furthermore, our analysis uncovers critical design principles, including a ``realism-verbosity paradox\" where less communicative agents can seem more artificial, and the need for challenges to be perceived as authentic to be instructive. This work provides a validated framework and key insights for developing the next generation of socially intelligent VR training environments.", "subjects": "Human-Computer Interaction (cs.HC); Computation and Language (cs.CL)", "comments": "8 pages, 2 figures", "pdf_url": "https://arxiv.org/pdf/2509.14132.pdf", "abstract_url": "https://arxiv.org/abs/2509.14132", "categories": ["Human-Computer Interaction (cs.HC)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一个将大型语言模型集成到沉浸式VR中的框架，用于创建具有不同一致个性的医学虚拟患者，并通过医师研究验证了其可行性和有效性。", "motivation": "解决虚拟现实中虚拟人类缺乏心理可信度的问题，特别是在医学教育等高风险领域中，以提升人际沟通技能的培训效果。", "method": "使用模块化架构，将个性与临床数据分离，并整合大型语言模型来构建医学上连贯的虚拟患者，通过混合方法的受试者内研究进行评估。", "result": "系统可行且被医师视为高度有益和有效的培训增强工具，揭示了设计原则如'真实感-冗长悖论'和挑战需真实感知才具指导性。", "conclusion": "提供了一个经验证的框架和关键见解，用于开发下一代社会智能VR培训环境。"}}
{"id": "2509.13380", "title": "ASTREA: Introducing Agentic Intelligence for Orbital Thermal Autonomy", "authors": ["Alejandro D. Mousist"], "abstract": "This paper presents ASTREA, the first agentic system deployed on flight-heritage hardware (TRL 9) for autonomous spacecraft operations. Using thermal control as a representative use case, we integrate a resource-constrained Large Language Model (LLM) agent with a reinforcement learning controller in an asynchronous architecture tailored for space-qualified platforms. Ground experiments show that LLM-guided supervision improves thermal stability and reduces violations, confirming the feasibility of combining semantic reasoning with adaptive control under hardware constraints. However, on-orbit validation aboard the International Space Station (ISS) reveals performance degradation caused by inference latency mismatched with the rapid thermal cycles characteristic of Low Earth Orbit (LEO) satellites. These results highlight both the opportunities and current limitations of agentic LLM-based systems in real flight environments, providing practical design guidelines for future space autonomy.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multiagent Systems (cs.MA); Systems and Control (eess.SY)", "comments": "This preprint presents ASTREA, a multi-agent architecture combining LLM-guided semantic modulation with reinforcement learning for autonomous satellite operations. The system is validated in hardware orbital environments", "pdf_url": "https://arxiv.org/pdf/2509.13380.pdf", "abstract_url": "https://arxiv.org/abs/2509.13380", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)", "Systems and Control (eess.SY)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了ASTREA，首个在飞行遗产硬件上部署的自主航天器操作代理系统，结合大语言模型和强化学习控制器，地面实验显示其改善热稳定性，但轨道验证揭示延迟问题。", "motivation": "解决航天器在资源受限硬件上实现自主热控制的问题，结合语义推理和自适应控制以提高操作效率。", "method": "使用资源受限的大语言模型代理与强化学习控制器集成，采用异步架构，针对空间合格平台设计。", "result": "地面实验证明LLM指导的监督提高热稳定性并减少违规；轨道验证显示由于推理延迟与快速热循环不匹配导致性能下降。", "conclusion": "代理LLM系统在真实飞行环境中具有潜力但存在限制，为未来空间自主设计提供实用指南。"}}
{"id": "2509.13642", "title": "LLM-I: LLMs are Naturally Interleaved Multimodal Creators", "authors": ["Zirun Guo", "Feng Zhang", "Kai Jia", "Tao Jin"], "abstract": "We propose LLM-Interleaved (LLM-I), a flexible and dynamic framework that reframes interleaved image-text generation as a tool-use problem. LLM-I is designed to overcome the \"one-tool\" bottleneck of current unified models, which are limited to synthetic imagery and struggle with tasks requiring factual grounding or programmatic precision. Our framework empowers a central LLM or MLLM agent to intelligently orchestrate a diverse toolkit of specialized visual tools, including online image search, diffusion-based generation, code execution, and image editing. The agent is trained to select and apply these tools proficiently via a Reinforcement Learning (RL) framework that features a hybrid reward system combining rule-based logic with judgments from LLM and MLLM evaluators. Trained on a diverse new dataset using four different model backbones, LLM-I demonstrates state-of-the-art performance, outperforming existing methods by a large margin across four benchmarks. We also introduce a novel test-time scaling strategy that provides further performance gains. Project Page:", "subjects": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.13642.pdf", "abstract_url": "https://arxiv.org/abs/2509.13642", "categories": ["Machine Learning (cs.LG)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "LLM-I是一个动态框架，通过将交错图像-文本生成重新定义为工具使用问题，利用强化学习训练大型语言模型智能协调多种视觉工具，实现最先进的性能。", "motivation": "解决当前统一模型在合成图像、事实基础和程序精度方面的局限性，避免单一工具瓶颈。", "method": "使用强化学习框架，结合规则逻辑和LLM/MLLM评估器的混合奖励系统，训练模型选择和运用多样化视觉工具。", "result": "在四个基准测试中大幅超越现有方法，并通过新颖的测试时扩展策略获得额外性能提升。", "conclusion": "LLM-I框架有效提升了交错多模态生成的能力，具有灵活性和动态性，为未来研究提供了新方向。"}}
{"id": "2509.14221", "title": "GEM-Bench: A Benchmark for Ad-Injected Response Generation within Generative Engine Marketing", "authors": ["Silan Hu", "Shiqi Zhang", "Yimin Shi", "Xiaokui Xiao"], "abstract": "Generative Engine Marketing (GEM) is an emerging ecosystem for monetizing generative engines, such as LLM-based chatbots, by seamlessly integrating relevant advertisements into their responses. At the core of GEM lies the generation and evaluation of ad-injected responses. However, existing benchmarks are not specifically designed for this purpose, which limits future research. To address this gap, we propose GEM-Bench, the first comprehensive benchmark for ad-injected response generation in GEM. GEM-Bench includes three curated datasets covering both chatbot and search scenarios, a metric ontology that captures multiple dimensions of user satisfaction and engagement, and several baseline solutions implemented within an extensible multi-agent framework. Our preliminary results indicate that, while simple prompt-based methods achieve reasonable engagement such as click-through rate, they often reduce user satisfaction. In contrast, approaches that insert ads based on pre-generated ad-free responses help mitigate this issue but introduce additional overhead. These findings highlight the need for future research on designing more effective and efficient solutions for generating ad-injected responses in GEM.", "subjects": "Information Retrieval (cs.IR); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14221.pdf", "abstract_url": "https://arxiv.org/abs/2509.14221", "categories": ["Information Retrieval (cs.IR)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "GEM-Bench是首个针对生成引擎营销中广告注入响应生成的全面基准，包括数据集、指标和基线解决方案，初步结果显示简单方法影响用户满意度，需更高效方案。", "motivation": "现有基准不专门针对生成引擎营销中的广告注入响应生成，限制了研究发展，需填补此空白。", "method": "提出GEM-Bench基准，包含三个策划数据集、多维度指标本体和基于可扩展多智能体框架的基线解决方案。", "result": "初步结果表明，基于提示的简单方法提高参与度但降低用户满意度，而基于预生成无广告响应的插入方法缓解问题但增加开销。", "conclusion": "强调未来研究需设计更有效和高效的广告注入响应生成方案，以提升用户满意度和参与度。"}}
{"id": "2509.13597", "title": "Agentic JWT: A Secure Delegation Protocol for Autonomous AI Agents", "authors": ["Abhishek Goswami"], "abstract": "Autonomous LLM agents can issue thousands of API calls per hour without human oversight. OAuth 2.0 assumes deterministic clients, but in agentic settings stochastic reasoning, prompt injection, or multi-agent orchestration can silently expand privileges.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": "17 pages, 6 figures, 2 Tables", "pdf_url": "https://arxiv.org/pdf/2509.13597.pdf", "abstract_url": "https://arxiv.org/abs/2509.13597", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出Agentic JWT协议，解决自主AI代理在OAuth 2.0下的安全委托问题，防止权限静默扩展。", "motivation": "解决自主LLM代理在无监督下发出大量API调用时，由于随机推理、提示注入或多代理协调导致权限静默扩展的安全问题。", "method": "开发Agentic JWT协议，一种安全的委托协议，用于增强OAuth 2.0在代理环境中的适用性。", "result": "协议可能有效限制权限扩展，提高代理系统的安全性。", "conclusion": "Agentic JWT协议为自主AI代理提供更安全的委托机制，减少安全风险。"}}
{"id": "2509.13471", "title": "An LLM Agentic Approach for Legal-Critical Software: A Case Study for Tax Prep Software", "authors": ["Sina Gogani-Khiabani", "Ashutosh Trivedi", "Diptikalyan Saha", "Saeid Tizpaz-Niari"], "abstract": "Large language models (LLMs) show promise for translating natural-language statutes into executable logic, but reliability in legally critical settings remains challenging due to ambiguity and hallucinations. We present an agentic approach for developing legal-critical software, using U.S. federal tax preparation as a case study. The key challenge is test-case generation under the oracle problem, where correct outputs require interpreting law. Building on metamorphic testing, we introduce higher-order metamorphic relations that compare system outputs across structured shifts among similar individuals. Because authoring such relations is tedious and error-prone, we use an LLM-driven, role-based framework to automate test generation and code synthesis. We implement a multi-agent system that translates tax code into executable software and incorporates a metamorphic-testing agent that searches for counterexamples. In experiments, our framework using a smaller model (GPT-4o-mini) achieves a worst-case pass rate of 45%, outperforming frontier models (GPT-4o and Claude 3.5, 9-15%) on complex tax-code tasks. These results support agentic LLM methodologies as a path to robust, trustworthy legal-critical software from natural-language specifications.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": "To appear at ICSE 26. 12 pages", "pdf_url": "https://arxiv.org/pdf/2509.13471.pdf", "abstract_url": "https://arxiv.org/abs/2509.13471", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种基于大语言模型（LLM）的代理方法，用于开发法律关键软件，以美国联邦税务准备为例，通过高阶蜕变关系和角色框架自动化测试生成，提高可靠性。", "motivation": "解决LLM在法律关键环境中因模糊性和幻觉导致的可靠性问题，确保从自然语言法规生成可执行逻辑的准确性。", "method": "采用代理方法，结合蜕变测试，引入高阶蜕变关系，并使用LLM驱动的角色框架自动化测试生成和代码合成，构建多代理系统。", "result": "实验显示，使用较小模型（GPT-4o-mini）的最坏情况通过率为45%，优于前沿模型（GPT-4o和Claude 3.5的9-15%）。", "conclusion": "代理LLM方法为从自然语言规范开发稳健、可信的法律关键软件提供了可行路径。"}}
{"id": "2509.13626", "title": "Mind the Gap: Aligning Knowledge Bases with User Needs to Enhance Mental Health Retrieval", "authors": ["Amanda Chan", "James Jiayu Liu", "He Kai", "Onno P. Kampman"], "abstract": "Access to reliable mental health information is vital for early help-seeking, yet expanding knowledge bases is resource-intensive and often misaligned with user needs. This results in poor performance of retrieval systems when presented concerns are not covered or expressed in informal or contextualized language. We present an AI-based gap-informed framework for corpus augmentation that authentically identifies underrepresented topics (gaps) by overlaying naturalistic user data such as forum posts in order to prioritize expansions based on coverage and usefulness. In a case study, we compare Directed (gap-informed augmentations) with Non-Directed augmentation (random additions), evaluating the relevance and usefulness of retrieved information across four retrieval-augmented generation (RAG) pipelines. Directed augmentation achieved near-optimal performance with modest expansions--requiring only a 42% increase for Query Transformation, 74% for Reranking and Hierarchical, and 318% for Baseline--to reach ~95% of the performance of an exhaustive reference corpus. In contrast, Non-Directed augmentation required substantially larger and thus practically infeasible expansions to achieve comparable performance (232%, 318%, 403%, and 763%, respectively). These results show that strategically targeted corpus growth can reduce content creation demands while sustaining high retrieval and provision quality, offering a scalable approach for building trusted health information repositories and supporting generative AI applications in high-stakes domains.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "comments": "25 pages, 3 figures, submitted to NeurIPS 2025 GenAI4Health", "pdf_url": "https://arxiv.org/pdf/2509.13626.pdf", "abstract_url": "https://arxiv.org/abs/2509.13626", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "该论文提出了一种基于AI的框架，通过分析用户数据识别知识库中的空白，并优先扩充相关内容，从而在精神健康信息检索中实现高效和高质量的性能提升。", "motivation": "解决精神健康知识库扩展资源密集且与用户需求不匹配的问题，导致检索系统在覆盖不足或非正式语言查询时性能低下。", "method": "使用AI框架，通过叠加自然用户数据（如论坛帖子）识别未充分代表的话题（空白），并基于覆盖度和有用性优先扩充语料库，比较定向与非定向扩充方法。", "result": "定向扩充仅需较小规模扩展（如42%到318%）即可达到接近最优性能（约95%），而非定向扩充需要更大且不切实际的扩展（232%到763%）才能达到类似效果。", "conclusion": "战略性目标语料增长可以减少内容创建需求，维持高检索质量，为可信健康信息库和生成AI应用提供可扩展方法。"}}
{"id": "2509.13782", "title": "Who is Introducing the Failure? Automatically Attributing Failures of Multi-Agent Systems via Spectrum Analysis", "authors": ["Yu Ge", "Linna Xie", "Zhong Li", "Yu Pei", "Tian Zhang"], "abstract": "Large Language Model Powered Multi-Agent Systems (MASs) are increasingly employed to automate complex real-world problems, such as programming and scientific discovery. Despite their promising, MASs are not without their flaws. However, failure attribution in MASs - pinpointing the specific agent actions responsible for failures - remains underexplored and labor-intensive, posing significant challenges for debugging and system improvement. To bridge this gap, we propose FAMAS, the first spectrum-based failure attribution approach for MASs, which operates through systematic trajectory replay and abstraction, followed by spectrum", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "20 pages, 6 figures", "pdf_url": "https://arxiv.org/pdf/2509.13782.pdf", "abstract_url": "https://arxiv.org/abs/2509.13782", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出FAMAS，首个基于频谱分析的多智能体系统故障归因方法，通过轨迹重放和抽象自动识别导致故障的特定智能体行为，以解决调试和改进系统的挑战。", "motivation": "多智能体系统在自动化复杂任务中存在故障，但故障归因过程未充分探索且劳动密集，阻碍了系统调试和改进。", "method": "FAMAS方法，基于频谱分析，通过系统化的轨迹重放和抽象来归因故障。", "result": "FAMAS能够自动识别故障的根源，减少人工干预，提高多智能体系统的可靠性和调试效率。", "conclusion": "FAMAS填补了多智能体系统故障归因的空白，为自动化调试和系统优化提供了有效工具，具有实际应用价值。"}}
{"id": "2509.13854", "title": "Understanding the Process of Human-AI Value Alignment", "authors": ["Jack McKinlay", "Marina De Vos", "Janina A. Hoffmann", "Andreas Theodorou"], "abstract": "Background: Value alignment in computer science research is often used to refer to the process of aligning artificial intelligence with humans, but the way the phrase is used often lacks precision. Objectives: In this paper, we conduct a systematic literature review to advance the understanding of value alignment in artificial intelligence by characterising the topic in the context of its research literature. We use this to suggest a more precise definition of the term. Methods: We analyse 172 value alignment research articles that have been published in recent years and synthesise their content using thematic analyses. Results: Our analysis leads to six themes: value alignment drivers & approaches; challenges in value alignment; values in value alignment; cognitive processes in humans and AI; human-agent teaming; and designing and developing value-aligned systems. Conclusions: By analysing these themes in the context of the literature we define value alignment as an ongoing process between humans and autonomous agents that aims to express and implement abstract values in diverse contexts, while managing the cognitive limits of both humans and AI agents and also balancing the conflicting ethical and political demands generated by the values in different groups. Our analysis gives rise to a set of research challenges and opportunities in the field of value alignment for future work.", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI)", "comments": "39 pages, 7 figures", "pdf_url": "https://arxiv.org/pdf/2509.13854.pdf", "abstract_url": "https://arxiv.org/abs/2509.13854", "categories": ["Computers and Society (cs.CY)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过系统文献综述分析172篇价值对齐研究文章，提出更精确的定义，并识别六个主题，以促进人类与AI在价值对齐过程中的理解。", "motivation": "解决价值对齐术语在计算机科学研究中缺乏精确性的问题，以更好地理解和定义人类与AI之间的价值对齐过程。", "method": "使用主题分析方法对172篇近期发表的价值对齐研究文章进行系统文献综述和内容综合。", "result": "分析得出六个主题：价值对齐驱动因素与方法、挑战、价值观、人类与AI的认知过程、人机团队协作、以及系统设计开发，并基于此提出了价值对齐的新定义。", "conclusion": "价值对齐被定义为人类与自主代理之间旨在表达和实施抽象价值观的持续过程，需管理认知限制和平衡伦理政治需求，为未来研究提供了挑战和机遇。"}}
{"id": "2509.13978", "title": "LLM Agents for Interactive Workflow Provenance: Reference Architecture and Evaluation Methodology", "authors": ["Renan Souza", "Timothy Poteet", "Brian Etz", "Daniel Rosendo", "Amal Gueroudji", "Woong Shin", "Prasanna Balaprakash", "Rafael Ferreira da Silva"], "abstract": "Modern scientific discovery increasingly relies on workflows that process data across the Edge, Cloud, and High Performance Computing (HPC) continuum. Comprehensive and in-depth analyses of these data are critical for hypothesis validation, anomaly detection, reproducibility, and impactful findings. Although workflow provenance techniques support such analyses, at large scale, the provenance data become complex and difficult to analyze. Existing systems depend on custom scripts, structured queries, or static dashboards, limiting data interaction. In this work, we introduce an evaluation methodology, reference architecture, and open-source implementation that leverages interactive Large Language Model (LLM) agents for runtime data analysis. Our approach uses a lightweight, metadata-driven design that translates natural language into structured provenance queries. Evaluations across LLaMA, GPT, Gemini, and Claude, covering diverse query classes and a real-world chemistry workflow, show that modular design, prompt tuning, and Retrieval-Augmented Generation (RAG) enable accurate and insightful LLM agent responses beyond recorded provenance.", "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC); Artificial Intelligence (cs.AI); Databases (cs.DB)", "comments": "Paper accepted in the proceedings of the ACM/IEEE Supercomputing Conference (SC). Cite it as Renan Souza, Timothy Poteet, Brian Etz, Daniel Rosendo, Amal Gueroudji, Woong Shin, Prasanna Balaprakash, and Rafael Ferreira da Silva. 2025. LLM Agents for Interactive Workflow Provenance: Reference Architecture and Evaluation Methodology. In SC Workshops (WORKS)", "pdf_url": "https://arxiv.org/pdf/2509.13978.pdf", "abstract_url": "https://arxiv.org/abs/2509.13978", "categories": ["Distributed, Parallel, and Cluster Computing (cs.DC)", "Artificial Intelligence (cs.AI)", "Databases (cs.DB)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文提出了一种利用交互式大语言模型（LLM）代理进行工作流溯源分析的参考架构和评估方法，通过自然语言查询提高大规模数据交互和分析能力。", "motivation": "现代科学发现依赖于跨边缘、云和高性能计算（HPC）的工作流，但大规模溯源数据复杂难分析，现有系统依赖自定义脚本或静态仪表板，限制了数据交互。", "method": "采用轻量级元数据驱动设计，将自然语言转换为结构化溯源查询，结合模块化设计、提示调优和检索增强生成（RAG）技术，评估了多种LLM模型。", "result": "评估显示，该方法在LLaMA、GPT、Gemini和Claude等模型上，针对多样查询类和真实化学工作流，实现了准确且深入的LLM代理响应，超越了记录的溯源数据。", "conclusion": "该方法提升了工作流溯源的交互性和分析深度，支持科学发现的可重复性和洞察力，具有实际应用价值。"}}
{"id": "2509.14172", "title": "TGPO: Tree-Guided Preference Optimization for Robust Web Agent Reinforcement Learning", "authors": ["Ziyuan Chen", "Zhenghui Zhao", "Zhangye Han", "Miancan Liu", "Xianhang Ye", "Yiqing Li", "Hongbo Min", "Jinkui Ren", "Xiantao Zhang", "Guitao Cao"], "abstract": "With the rapid advancement of large language models and vision-language models, employing large models as Web Agents has become essential for automated web interaction. However, training Web Agents with reinforcement learning faces critical challenges including credit assignment misallocation, prohibitively high annotation costs, and reward sparsity. To address these issues, we propose Tree-Guided Preference Optimization (TGPO), an offline reinforcement learning framework that proposes a tree-structured trajectory representation merging semantically identical states across trajectories to eliminate label conflicts. Our framework incorporates a Process Reward Model that automatically generates fine-grained rewards through subgoal progress, redundancy detection, and action verification. Additionally, a dynamic weighting mechanism prioritizes high-impact decision points during training. Experiments on Online-Mind2Web and our self-constructed C-WebShop datasets demonstrate that TGPO significantly outperforms existing methods, achieving higher success rates with fewer redundant steps.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14172.pdf", "abstract_url": "https://arxiv.org/abs/2509.14172", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "TGPO是一种离线强化学习框架，通过树结构轨迹表示和过程奖励模型解决Web Agent训练中的信用分配、高标注成本和奖励稀疏问题，在实验中显著提高了成功率并减少了冗余步骤。", "motivation": "解决Web Agent在强化学习训练中面临的信用分配错误、高标注成本和奖励稀疏等关键挑战。", "method": "提出TGPO框架，使用树结构轨迹表示合并语义相同状态，集成过程奖励模型自动生成细粒度奖励，并采用动态权重机制优先处理高影响力决策点。", "result": "在Online-Mind2Web和C-WebShop数据集上，TGPO显著优于现有方法，实现了更高的成功率和更少的冗余步骤。", "conclusion": "TGPO有效提升了Web Agent的鲁棒性和效率，为自动化Web交互提供了更优的解决方案。"}}
