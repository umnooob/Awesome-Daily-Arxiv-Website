{"id": "2505.04921", "title": "Perception, Reason, Think, and Plan: A Survey on Large Multimodal Reasoning Models", "authors": ["Yunxin Li", "Zhenyu Liu", "Zitao Li", "Xuanyu Zhang", "Zhenran Xu", "Xinyu Chen", "Haoyuan Shi", "Shenyuan Jiang", "Xintong Wang", "Jifang Wang", "Shouzheng Huang", "Xinping Zhao", "Borui Jiang", "Lanqing Hong", "Longyue Wang", "Zhuotao Tian", "Baoxing Huai", "Wenhan Luo", "Weihua Luo", "Zheng Zhang", "Baotian Hu", "Min Zhang"], "abstract": "Reasoning lies at the heart of intelligence, shaping the ability to make decisions, draw conclusions, and generalize across domains. In artificial intelligence, as systems increasingly operate in open, uncertain, and multimodal environments, reasoning becomes essential for enabling robust and adaptive behavior. Large Multimodal Reasoning Models (LMRMs) have emerged as a promising paradigm, integrating modalities such as text, images, audio, and video to support complex reasoning capabilities and aiming to achieve comprehensive perception, precise understanding, and deep reasoning. As research advances, multimodal reasoning has rapidly evolved from modular, perception-driven pipelines to unified, language-centric frameworks that offer more coherent cross-modal understanding. While instruction tuning and reinforcement learning have improved model reasoning, significant challenges remain in omni-modal generalization, reasoning depth, and agentic behavior. To address these issues, we present a comprehensive and structured survey of multimodal reasoning research, organized around a four-stage developmental roadmap that reflects the field's shifting design philosophies and emerging capabilities. First, we review early efforts based on task-specific modules, where reasoning was implicitly embedded across stages of representation, alignment, and fusion. Next, we examine recent approaches that unify reasoning into multimodal LLMs, with advances such as Multimodal Chain-of-Thought (MCoT) and multimodal reinforcement learning enabling richer and more structured reasoning chains. Finally, drawing on empirical insights from challenging benchmarks and experimental cases of OpenAI O3 and O4-mini, we discuss the conceptual direction of native large multimodal reasoning models (N-LMRMs), which aim to support scalable, agentic, and adaptive reasoning and planning in complex, real-world environments.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.04921.pdf", "abstract_url": "https://arxiv.org/abs/2505.04921", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文综述了大型多模态推理模型（LMRMs）的发展，探讨了从模块化、感知驱动的管道到统一的、以语言为中心的框架的演变，以及面临的挑战和未来的发展方向。", "motivation": "解决在开放、不确定和多模态环境中，人工智能系统需要更强的推理能力以实现稳健和自适应行为的问题。", "method": "通过四阶段发展路线图，回顾了从任务特定模块到统一的多模态大型语言模型（LLMs）的演变，包括多模态思维链（MCoT）和多模态强化学习等进展。", "result": "提出了原生大型多模态推理模型（N-LMRMs）的概念方向，旨在支持复杂现实环境中可扩展、能动和自适应的推理与规划。", "conclusion": "多模态推理研究正朝着支持更深入、更结构化推理链和更强大代理行为的方向发展，N-LMRMs代表了未来的重要发展方向。"}}
{"id": "2505.04769", "title": "Vision-Language-Action Models: Concepts, Progress, Applications and Challenges", "authors": ["Ranjan Sapkota", "Yang Cao", "Konstantinos I. Roumeliotis", "Manoj Karkee"], "abstract": "Vision-Language-Action (VLA) models mark a transformative advancement in artificial intelligence, aiming to unify perception, natural language understanding, and embodied action within a single computational framework. This foundational review presents a comprehensive synthesis of recent advancements in Vision-Language-Action models, systematically organized across five thematic pillars that structure the landscape of this rapidly evolving field. We begin by establishing the conceptual foundations of VLA systems, tracing their evolution from cross-modal learning architectures to generalist agents that tightly integrate vision-language models (VLMs), action planners, and hierarchical controllers. Our methodology adopts a rigorous literature review framework, covering over 80 VLA models published in the past three years. Key progress areas include architectural innovations, parameter-efficient training strategies, and real-time inference accelerations. We explore diverse application domains such as humanoid robotics, autonomous vehicles, medical and industrial robotics, precision agriculture, and augmented reality navigation. The review further addresses major challenges across real-time control, multimodal action representation, system scalability, generalization to unseen tasks, and ethical deployment risks. Drawing from the state-of-the-art, we propose targeted solutions including agentic AI adaptation, cross-embodiment generalization, and unified neuro-symbolic planning. In our forward-looking discussion, we outline a future roadmap where VLA models, VLMs, and agentic AI converge to power socially aligned, adaptive, and general-purpose embodied agents. This work serves as a foundational reference for advancing intelligent, real-world robotics and artificial general intelligence. >Vision-language-action, Agentic AI, AI Agents, Vision-language Models", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "36 pages, 18 Figures, 4 Tables", "pdf_url": "https://arxiv.org/pdf/2505.04769.pdf", "abstract_url": "https://arxiv.org/abs/2505.04769", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文综述了视觉-语言-动作（VLA）模型的最新进展，包括其概念基础、架构创新、应用领域及面临的挑战，并提出了未来发展方向。", "motivation": "解决如何将感知、自然语言理解和具体行动统一到单一计算框架中的问题，以推动人工智能的发展。", "method": "采用严格的文献综述框架，覆盖了过去三年发表的80多个VLA模型，系统性地分析了这一领域的进展。", "result": "识别了VLA模型在架构创新、参数高效训练策略和实时推理加速等关键领域的进展，以及在人形机器人、自动驾驶等多个应用领域的应用。", "conclusion": "VLA模型、视觉语言模型（VLMs）和代理AI的融合将推动社会对齐、自适应和通用目的的具身代理的发展，为智能机器人和人工通用智能的进步奠定了基础。"}}
{"id": "2505.04965", "title": "DenseGrounding: Improving Dense Language-Vision Semantics for Ego-Centric 3D Visual Grounding", "authors": ["Henry Zheng", "Hao Shi", "Qihang Peng", "Yong Xien Chng", "Rui Huang", "Yepeng Weng", "Zhongchao Shi", "Gao Huang"], "abstract": "Enabling intelligent agents to comprehend and interact with 3D environments through natural language is crucial for advancing robotics and human-computer interaction. A fundamental task in this field is ego-centric 3D visual grounding, where agents locate target objects in real-world 3D spaces based on verbal descriptions. However, this task faces two significant challenges: (1) loss of fine-grained visual semantics due to sparse fusion of point clouds with ego-centric multi-view images, (2) limited textual semantic context due to arbitrary language descriptions. We propose DenseGrounding, a novel approach designed to address these issues by enhancing both visual and textual semantics. For visual features, we introduce the Hierarchical Scene Semantic Enhancer, which retains dense semantics by capturing fine-grained global scene features and facilitating cross-modal alignment. For text descriptions, we propose a Language Semantic Enhancer that leverages large language models to provide rich context and diverse language descriptions with additional context during model training. Extensive experiments show that DenseGrounding significantly outperforms existing methods in overall accuracy, with improvements of 5.81% and 7.56% when trained on the comprehensive full dataset and smaller mini subset, respectively, further advancing the SOTA in egocentric 3D visual grounding. Our method also achieves 1st place and receives the Innovation Award in the CVPR 2024 Autonomous Grand Challenge Multi-view 3D Visual Grounding Track, validating its effectiveness and robustness.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "Accepted by ICLR 2025", "pdf_url": "https://arxiv.org/pdf/2505.04965.pdf", "abstract_url": "https://arxiv.org/abs/2505.04965", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "DenseGrounding是一种新方法，旨在通过增强视觉和文本语义来改进以自我为中心的3D视觉接地任务，解决了点云与多视图图像稀疏融合导致的细粒度视觉语义丢失和任意语言描述导致的有限文本语义上下文的问题。", "motivation": "解决在3D环境中基于自然语言描述定位目标物体时，因视觉和文本语义不足而面临的挑战。", "method": "提出了Hierarchical Scene Semantic Enhancer来保留密集的视觉语义，以及Language Semantic Enhancer利用大型语言模型提供丰富的文本上下文。", "result": "DenseGrounding在整体准确率上显著优于现有方法，在完整数据集和小型子集上分别提高了5.81%和7.56%，并在CVPR 2024挑战赛中获得了第一名和创新奖。", "conclusion": "DenseGrounding通过增强视觉和文本语义，有效提高了以自我为中心的3D视觉接地的准确性和鲁棒性，推动了该领域的技术进步。"}}
{"id": "2505.04628", "title": "How Social is It? A Benchmark for LLMs' Capabilities in Multi-user Multi-turn Social Agent Tasks", "authors": ["Yusen Wu", "Junwu Xiong", "Xiaotie Deng"], "abstract": "Expanding the application of large language models (LLMs) to societal life, instead of primary function only as auxiliary assistants to communicate with only one person at a time, necessitates LLMs' capabilities to independently play roles in multi-user, multi-turn social agent tasks within complex social settings. However, currently the capability has not been systematically measured with available benchmarks. To address this gap, we first introduce an agent task leveling framework grounded in sociological principles. Concurrently, we propose a novel benchmark, How Social Is It (we call it HSII below), designed to assess LLM's social capabilities in comprehensive social agents tasks and benchmark representative models. HSII comprises four stages: format parsing, target selection, target switching conversation, and stable conversation, which collectively evaluate the communication and task completion capabilities of LLMs within realistic social interaction scenarios dataset, HSII-Dataset. The dataset is derived step by step from news dataset. We perform an ablation study by doing clustering to the dataset. Additionally, we investigate the impact of chain of thought (COT) method on enhancing LLMs' social performance. Since COT cost more computation, we further introduce a new statistical metric, COT-complexity, to quantify the efficiency of certain LLMs with COTs for specific social tasks and strike a better trade-off between measurement of correctness and efficiency. Various results of our experiments demonstrate that our benchmark is well-suited for evaluating social skills in LLMs.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Social and Information Networks (cs.SI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.04628.pdf", "abstract_url": "https://arxiv.org/abs/2505.04628", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Social and Information Networks (cs.SI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了HSII基准测试，旨在评估大型语言模型（LLMs）在多用户多轮社交代理任务中的社交能力，包括格式解析、目标选择、目标切换对话和稳定对话四个阶段，并提出了COT-complexity这一新统计指标来衡量效率。", "motivation": "当前缺乏系统测量LLMs在复杂社交环境中作为多用户多轮社交代理的能力的基准测试，本文旨在填补这一空白。", "method": "提出了基于社会学原则的代理任务分级框架和HSII基准测试，包括四个评估阶段，并使用从新闻数据集逐步构建的HSII-Dataset进行实验。", "result": "实验结果表明，HSII基准测试能有效评估LLMs的社交技能，且COT方法能提升LLMs的社交表现，但需在正确性和效率之间找到平衡。", "conclusion": "HSII基准测试为评估LLMs在复杂社交任务中的能力提供了有效工具，同时COT-complexity指标为优化LLMs的社交性能提供了新的视角。"}}
{"id": "2505.04638", "title": "Towards Artificial Intelligence Research Assistant for Expert-Involved Learning", "authors": ["Tianyu Liu", "Simeng Han", "Xiao Luo", "Hanchen Wang", "Pan Lu", "Biqing Zhu", "Yuge Wang", "Keyi Li", "Jiapeng Chen", "Rihao Qu", "Yufeng Liu", "Xinyue Cui", "Aviv Yaish", "Yuhang Chen", "Minsheng Hao", "Chuhan Li", "Kexing Li", "Arman Cohan", "Hua Xu", "Mark Gerstein", "James Zou", "Hongyu Zhao"], "abstract": "Large Language Models (LLMs) and Large Multi-Modal Models (LMMs) have emerged as transformative tools in scientific research, yet their reliability and specific contributions to biomedical applications remain insufficiently characterized. In this study, we present \\textbf{AR}tificial \\textbf{I}ntelligence research assistant for \\textbf{E}xpert-involved \\textbf{L}earning (ARIEL), a multimodal dataset designed to benchmark and enhance two critical capabilities of LLMs and LMMs in biomedical research: summarizing extensive scientific texts and interpreting complex biomedical figures. To facilitate rigorous assessment, we create two open-source sets comprising biomedical articles and figures with designed questions. We systematically benchmark both open- and closed-source foundation models, incorporating expert-driven human evaluations conducted by doctoral-level experts. Furthermore, we improve model performance through targeted prompt engineering and fine-tuning strategies for summarizing research papers, and apply test-time computational scaling to enhance the reasoning capabilities of LMMs, achieving superior accuracy compared to human-expert corrections. We also explore the potential of using LMM Agents to generate scientific hypotheses from diverse multimodal inputs. Overall, our results delineate clear strengths and highlight significant limitations of current foundation models, providing actionable insights and guiding future advancements in deploying large-scale language and multi-modal models within biomedical research.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Information Retrieval (cs.IR)", "comments": "36 pages, 7 figures", "pdf_url": "https://arxiv.org/pdf/2505.04638.pdf", "abstract_url": "https://arxiv.org/abs/2505.04638", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Information Retrieval (cs.IR)"], "matching_keywords": ["agent"], "AI": {"tldr": "本研究介绍了ARIEL，一个多模态数据集，旨在评估和提升LLMs和LMMs在生物医学研究中的两项关键能力：总结科学文本和解释复杂生物医学图表。通过专家驱动的人类评估和模型优化策略，研究展示了当前基础模型的优势和局限性。", "motivation": "尽管LLMs和LMMs已成为科学研究中的变革性工具，但它们在生物医学应用中的可靠性和具体贡献尚未充分表征。", "method": "创建了两个开源数据集，包含生物医学文章和图表及设计的问题，系统地评估了开源和闭源基础模型，并采用专家驱动的人类评估。通过针对性的提示工程和微调策略优化模型性能，并应用测试时计算扩展提升LMMs的推理能力。", "result": "研究结果表明，通过优化策略，模型在总结研究论文方面的性能得到提升，LMMs的推理能力也优于人类专家修正。同时，探索了使用LMM代理从多模态输入生成科学假设的潜力。", "conclusion": "研究结果明确了当前基础模型的优势和显著局限性，为未来在生物医学研究中部署大规模语言和多模态模型提供了可行的见解和指导。"}}
{"id": "2505.04649", "title": "FRAME: Feedback-Refined Agent Methodology for Enhancing Medical Research Insights", "authors": ["Chengzhang Yu", "Yiming Zhang", "Zhixin Liu", "Zenghui Ding", "Yining Sun", "Zhanpeng Jin"], "abstract": "The automation of scientific research through large language models (LLMs) presents significant opportunities but faces critical challenges in knowledge synthesis and quality assurance. We introduce Feedback-Refined Agent Methodology (FRAME), a novel framework that enhances medical paper generation through iterative refinement and structured feedback. Our approach comprises three key innovations: (1) A structured dataset construction method that decomposes 4,287 medical papers into essential research components through iterative refinement; (2) A tripartite architecture integrating Generator, Evaluator, and Reflector agents that progressively improve content quality through metric-driven feedback; and (3) A comprehensive evaluation framework that combines statistical metrics with human-grounded benchmarks. Experimental results demonstrate FRAME's effectiveness, achieving significant improvements over conventional approaches across multiple models (9.91% average gain with DeepSeek V3, comparable improvements with GPT-4o Mini) and evaluation dimensions. Human evaluation confirms that FRAME-generated papers achieve quality comparable to human-authored works, with particular strength in synthesizing future research directions. The results demonstrated our work could efficiently assist medical research by building a robust foundation for automated medical research paper generation while maintaining rigorous academic standards.", "subjects": "Computation and Language (cs.CL)", "comments": "12 pages, 4 figures, 5 table", "pdf_url": "https://arxiv.org/pdf/2505.04649.pdf", "abstract_url": "https://arxiv.org/abs/2505.04649", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了FRAME（反馈精炼代理方法），一种通过迭代精炼和结构化反馈来增强医学论文生成的新框架。该方法通过分解医学论文、集成生成器、评估器和反射器代理，以及结合统计指标和人类基准的评估框架，显著提高了论文生成的质量。实验结果显示，FRAME在多模型和多评估维度上优于传统方法，且生成的论文质量接近人类作者水平。", "motivation": "自动化科学研究通过大型语言模型（LLMs）提供了重要机会，但在知识合成和质量保证方面面临关键挑战。本文旨在解决这些问题，通过FRAME框架提高医学论文生成的效率和质量。", "method": "FRAME框架包括三个关键创新：1) 通过迭代精炼将4,287篇医学论文分解为基本研究组件的结构化数据集构建方法；2) 集成生成器、评估器和反射器代理的三方架构，通过指标驱动的反馈逐步提高内容质量；3) 结合统计指标和人类基准的综合评估框架。", "result": "实验结果显示，FRAME在多模型（如DeepSeek V3和GPT-4o Mini）和多评估维度上显著优于传统方法，生成的论文质量接近人类作者水平，特别是在合成未来研究方向方面表现出色。", "conclusion": "FRAME能够有效地辅助医学研究，为自动化医学研究论文生成建立坚实基础，同时保持严格的学术标准。"}}
{"id": "2505.04651", "title": "Scientific Hypothesis Generation and Validation: Methods, Datasets, and Future Directions", "authors": ["Adithya Kulkarni", "Fatimah Alotaibi", "Xinyue Zeng", "Longfeng Wu", "Tong Zeng", "Barry Menglong Yao", "Minqian Liu", "Shuaicheng Zhang", "Lifu Huang", "Dawei Zhou"], "abstract": "Large Language Models (LLMs) are transforming scientific hypothesis generation and validation by enabling information synthesis, latent relationship discovery, and reasoning augmentation. This survey provides a structured overview of LLM-driven approaches, including symbolic frameworks, generative models, hybrid systems, and multi-agent architectures. We examine techniques such as retrieval-augmented generation, knowledge-graph completion, simulation, causal inference, and tool-assisted reasoning, highlighting trade-offs in interpretability, novelty, and domain alignment. We contrast early symbolic discovery systems (e.g., BACON, KEKADA) with modern LLM pipelines that leverage in-context learning and domain adaptation via fine-tuning, retrieval, and symbolic grounding. For validation, we review simulation, human-AI collaboration, causal modeling, and uncertainty quantification, emphasizing iterative assessment in open-world contexts. The survey maps datasets across biomedicine, materials science, environmental science, and social science, introducing new resources like AHTech and CSKG-600. Finally, we outline a roadmap emphasizing novelty-aware generation, multimodal-symbolic integration, human-in-the-loop systems, and ethical safeguards, positioning LLMs as agents for principled, scalable scientific discovery.", "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.04651.pdf", "abstract_url": "https://arxiv.org/abs/2505.04651", "categories": ["Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文综述了大型语言模型（LLMs）在科学假设生成和验证中的应用，包括符号框架、生成模型、混合系统和多智能体架构等方法，并探讨了检索增强生成、知识图谱补全等技术。文章还对比了早期符号发现系统与现代LLM流程，并提出了未来研究方向。", "motivation": "探讨大型语言模型如何通过信息合成、潜在关系发现和推理增强来改变科学假设的生成和验证过程。", "method": "综述了LLM驱动的方法，包括符号框架、生成模型、混合系统和多智能体架构，以及检索增强生成、知识图谱补全等技术。", "result": "文章回顾了模拟、人机协作、因果建模和不确定性量化等验证技术，并介绍了跨生物医学、材料科学等领域的数据集。", "conclusion": "提出了一个路线图，强调新颖性感知生成、多模态符号整合、人在环系统和伦理保障，将LLMs定位为原则性、可扩展科学发现的代理。"}}
{"id": "2505.04666", "title": "Fine-Tuning Large Language Models and Evaluating Retrieval Methods for Improved Question Answering on Building Codes", "authors": ["Mohammad Aqib", "Mohd Hamza", "Qipei Mei", "Ying Hei Chui"], "abstract": "Building codes are regulations that establish standards for the design, construction, and safety of buildings to ensure structural integrity, fire protection, and accessibility. They are often extensive, complex, and subject to frequent updates, making manual querying challenging and time-consuming. Key difficulties include navigating large volumes of text, interpreting technical language, and identifying relevant clauses across different sections. A potential solution is to build a Question-Answering (QA) system that answers user queries based on building codes. Among the various methods for building a QA system, Retrieval-Augmented Generation (RAG) stands out in performance. RAG consists of two components: a retriever and a language model. This study focuses on identifying a suitable retriever method for building codes and optimizing the generational capability of the language model using fine-tuning techniques. We conducted a detailed evaluation of various retrieval methods by performing the retrieval on the National Building Code of Canada (NBCC) and explored the impact of domain-specific fine-tuning on several language models using the dataset derived from NBCC. Our analysis included a comparative assessment of different retrievers and the performance of both pre-trained and fine-tuned models to determine the efficacy and domain-specific adaptation of language models using fine-tuning on the NBCC dataset. Experimental results showed that Elasticsearch proved to be the most robust retriever among all. The findings also indicate that fine-tuning language models on an NBCC-specific dataset can enhance their ability to generate contextually relevant responses. When combined with context retrieved by a powerful retriever like Elasticsearch, this improvement in LLM performance can optimize the RAG system, enabling it to better navigate the complexities of the NBCC.", "subjects": "Computation and Language (cs.CL); Information Retrieval (cs.IR); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.04666.pdf", "abstract_url": "https://arxiv.org/abs/2505.04666", "categories": ["Computation and Language (cs.CL)", "Information Retrieval (cs.IR)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "该研究通过微调大型语言模型和评估检索方法，旨在提高基于建筑规范的问答系统性能。研究发现Elasticsearch是最强大的检索方法，且针对加拿大国家建筑规范的特定领域微调能增强语言模型生成相关回答的能力。", "motivation": "建筑规范内容庞大、复杂且频繁更新，手动查询既困难又耗时。研究旨在通过构建问答系统来解决这些问题，特别是利用检索增强生成（RAG）技术来提高查询效率和准确性。", "method": "研究评估了多种检索方法在加拿大国家建筑规范（NBCC）上的表现，并探索了领域特定微调对几种语言模型的影响。通过比较不同检索器和预训练与微调模型的性能，确定了语言模型在NBCC数据集上的适应性和效能。", "result": "实验结果表明，Elasticsearch在所有检索器中表现最为鲁棒。此外，针对NBCC特定数据集的微调能显著提升语言模型生成上下文相关回答的能力。", "conclusion": "结合强大的检索器如Elasticsearch和针对特定领域微调的语言模型，可以优化RAG系统，使其更好地应对建筑规范的复杂性，从而提高问答系统的性能和用户体验。"}}
{"id": "2505.04646", "title": "Computational Irreducibility as the Foundation of Agency: A Formal Model Connecting Undecidability to Autonomous Behavior in Complex Systems", "authors": ["Poria Azadi"], "abstract": "This article explores the emergence of autonomy and agency by connecting fundamental computational limits (decidability, completeness, computational irreducibility) with physical concepts. We introduce a formal model of a \"minimal agent\" operating within potentially Turing-complete environments. Using algorithmic information theory, we argue that the inherent undecidability and computational irreducibility of agent-environment interaction lead to unpredictability and novel information generation, enabling agency (effective goal-directed action). Computational irreducibility prevents full external prediction, creating necessary conditions for autonomous behavior. We relate this to computational sourcehood, where an agent is the irreducible origin of its behavior, though formalizing this concept remains challenging. Our central thesis, formally proven, is that genuine autonomy necessarily implies undecidability from an external perspective, distinguishing autonomous systems from predictable ones. We propose that agency arises when agent-environment coupling complexity allows mutual information between internal states and relevant environmental variables to increase, particularly where analytical solutions are absent and operational closure is needed for persistence. This framework links agency directly to the computational properties of interaction, offering implications for understanding consciousness, designing autonomous AI, and reconceptualizing free will in a deterministic yet computationally irreducible universe.", "subjects": "Artificial Intelligence (cs.AI); Computational Complexity (cs.CC); Information Theory (cs.IT)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.04646.pdf", "abstract_url": "https://arxiv.org/abs/2505.04646", "categories": ["Artificial Intelligence (cs.AI)", "Computational Complexity (cs.CC)", "Information Theory (cs.IT)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过将基本计算限制（可判定性、完备性、计算不可约性）与物理概念联系起来，探讨了自主性和能动性的出现。我们引入了一个在潜在图灵完备环境中操作的“最小代理”的形式模型。使用算法信息理论，我们认为代理-环境交互的固有不可判定性和计算不可约性导致了不可预测性和新信息的生成，从而实现了能动性（有效的目标导向行动）。计算不可约性阻止了完全的外部预测，为自主行为创造了必要条件。我们将这与计算源联系起来，其中代理是其行为的不可约起源，尽管形式化这一概念仍然具有挑战性。我们的中心论点，正式证明，是真正的自主性必然意味着从外部视角看是不可判定的，将自主系统与可预测的系统区分开来。我们提出，当代理-环境耦合复杂性允许内部状态与相关环境变量之间的互信息增加时，特别是在分析解决方案缺失和需要操作闭合以维持持久性的情况下，能动性就会出现。这一框架将能动性直接与交互的计算属性联系起来，为理解意识、设计自主AI以及在确定性但计算不可约的宇宙中重新构想自由意志提供了启示。", "motivation": "探讨自主性和能动性的出现，通过连接基本计算限制与物理概念，理解自主系统与可预测系统的区别。", "method": "引入一个在潜在图灵完备环境中操作的“最小代理”的形式模型，并使用算法信息理论分析代理-环境交互的不可判定性和计算不可约性。", "result": "证明了真正的自主性必然意味着从外部视角看是不可判定的，计算不可约性为自主行为创造了必要条件，能动性在特定条件下出现。", "conclusion": "这一框架将能动性直接与交互的计算属性联系起来，为理解意识、设计自主AI以及在确定性但计算不可约的宇宙中重新构想自由意志提供了启示。"}}
{"id": "2505.04843", "title": "Large Language Models are Autonomous Cyber Defenders", "authors": ["Sebastián R. Castro", "Roberto Campbell", "Nancy Lau", "Octavio Villalobos", "Jiaqi Duan", "Alvaro A. Cardenas"], "abstract": "Fast and effective incident response is essential to prevent adversarial cyberattacks. Autonomous Cyber Defense (ACD) aims to automate incident response through Artificial Intelligence (AI) agents that plan and execute actions. Most ACD approaches focus on single-agent scenarios and leverage Reinforcement Learning (RL). However, ACD RL-trained agents depend on costly training, and their reasoning is not always explainable or transferable. Large Language Models (LLMs) can address these concerns by providing explainable actions in general security contexts. Researchers have explored LLM agents for ACD but have not evaluated them on multi-agent scenarios or interacting with other ACD agents. In this paper, we show the first study on how LLMs perform in multi-agent ACD environments by proposing a new integration to the CybORG CAGE 4 environment. We examine how ACD teams of LLM and RL agents can interact by proposing a novel communication protocol. Our results highlight the strengths and weaknesses of LLMs and RL and help us identify promising research directions to create, train, and deploy future teams of ACD agents.", "subjects": "Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)", "comments": "Presented at IEEE CAI Workshop on Adaptive Cyber Defense 2025. Proceedings to appear", "pdf_url": "https://arxiv.org/pdf/2505.04843.pdf", "abstract_url": "https://arxiv.org/abs/2505.04843", "categories": ["Artificial Intelligence (cs.AI)", "Cryptography and Security (cs.CR)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究了大型语言模型（LLMs）在多代理自主网络防御（ACD）环境中的表现，提出了与CybORG CAGE 4环境的新集成，并探讨了LLM和强化学习（RL）代理团队如何通过新型通信协议互动。", "motivation": "解决自主网络防御中单代理场景的局限性，以及RL训练代理的高成本和不可解释性问题。", "method": "提出了一种新的集成方法到CybORG CAGE 4环境，并设计了一个新型通信协议来研究LLM和RL代理在多代理ACD环境中的互动。", "result": "研究结果突出了LLMs和RL在ACD中的优势和弱点，为未来ACD代理团队的创建、训练和部署指明了研究方向。", "conclusion": "LLMs在多代理ACD环境中展现出潜力，但需进一步研究以优化其与RL代理的协作和通信效率。"}}
{"id": "2505.04927", "title": "Belief Filtering for Epistemic Control in Linguistic State Space", "authors": ["Sebastian Dumbrava"], "abstract": "We examine belief filtering as a mechanism for the epistemic control of artificial agents, focusing on the regulation of internal cognitive states represented as linguistic expressions. This mechanism is developed within the Semantic Manifold framework, where belief states are dynamic, structured ensembles of natural language fragments. Belief filters act as content-aware operations on these fragments across various cognitive transitions. This paper illustrates how the inherent interpretability and modularity of such a linguistically-grounded cognitive architecture directly enable belief filtering, offering a principled approach to agent regulation. The study highlights the potential for enhancing AI safety and alignment through structured interventions in an agent's internal semantic space and points to new directions for architecturally embedded cognitive governance.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "18 pages", "pdf_url": "https://arxiv.org/pdf/2505.04927.pdf", "abstract_url": "https://arxiv.org/abs/2505.04927", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了信念过滤作为一种机制，用于人工代理的认知控制，特别是在调节以语言表达的内部认知状态方面。该机制在语义流形框架内开发，其中信念状态是动态的、结构化的自然语言片段集合。信念过滤器作为对这些片段在各种认知转换中的内容感知操作。", "motivation": "解决如何通过结构化干预增强AI的安全性和对齐性，以及如何在代理的内部语义空间中实现认知治理的问题。", "method": "在语义流形框架内开发信念过滤机制，作为对自然语言片段的内容感知操作，用于调节人工代理的认知状态。", "result": "研究表明，基于语言的认知架构的固有可解释性和模块化直接支持信念过滤，为代理调节提供了原则性方法。", "conclusion": "通过结构化干预代理的内部语义空间，可以增强AI的安全性和对齐性，为认知治理的架构嵌入指明了新方向。"}}
{"id": "2505.04997", "title": "Foam-Agent: Towards Automated Intelligent CFD Workflows", "authors": ["Ling Yue", "Nithin Somasekharan", "Yadi Cao", "Shaowu Pan"], "abstract": "Computational Fluid Dynamics (CFD) is an essential simulation tool in various engineering disciplines, but it often requires substantial domain expertise and manual configuration, creating barriers to entry. We present Foam-Agent, a multi-agent framework that automates complex OpenFOAM-based CFD simulation workflows from natural language inputs. Our innovation includes (1) a hierarchical multi-index retrieval system with specialized indices for different simulation aspects, (2) a dependency-aware file generation system that provides consistency management across configuration files, and (3) an iterative error correction mechanism that diagnoses and resolves simulation failures without human intervention. Through comprehensive evaluation on the dataset of 110 simulation tasks, Foam-Agent achieves an 83.6% success rate with Claude 3.5 Sonnet, significantly outperforming existing frameworks (55.5% for MetaOpenFOAM and 37.3% for OpenFOAM-GPT). Ablation studies demonstrate the critical contribution of each system component, with the specialized error correction mechanism providing a 36.4% performance improvement. Foam-Agent substantially lowers the CFD expertise threshold while maintaining modeling accuracy, demonstrating the potential of specialized multi-agent systems to democratize access to complex scientific simulation tools. The code is public at", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.04997.pdf", "abstract_url": "https://arxiv.org/abs/2505.04997", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "Foam-Agent是一个多智能体框架，旨在通过自然语言输入自动化复杂的基于OpenFOAM的CFD模拟工作流程，显著降低了CFD的专业门槛。", "motivation": "解决CFD模拟需要大量领域专业知识和手动配置的问题，降低使用门槛。", "method": "采用分层多索引检索系统、依赖感知的文件生成系统和迭代错误纠正机制。", "result": "在110个模拟任务的数据集上，Foam-Agent的成功率达到83.6%，显著优于现有框架。", "conclusion": "Foam-Agent通过自动化复杂科学模拟工具的使用，展示了多智能体系统在降低专业门槛方面的潜力。"}}
{"id": "2505.05029", "title": "A Reputation System for Large Language Model-based Multi-agent Systems to Avoid the Tragedy of the Commons", "authors": ["Siyue Ren", "Wanli Fu", "Xinkun Zou", "Chen Shen", "Yi Cai", "Chen Chu", "Zhen Wang", "Shuyue Hu"], "abstract": "The tragedy of the commons, where individual self-interest leads to collectively disastrous outcomes, is a pervasive challenge in human society. Recent studies have demonstrated that similar phenomena can arise in generative multi-agent systems (MASs). To address this challenge, this paper explores the use of reputation systems as a remedy. We propose RepuNet, a dynamic, dual-level reputation framework that models both agent-level reputation dynamics and system-level network evolution. Specifically, driven by direct interactions and indirect gossip, agents form reputations for both themselves and their peers, and decide whether to connect or disconnect other agents for future interactions. Through two distinct scenarios, we show that RepuNet effectively mitigates the 'tragedy of the commons', promoting and sustaining cooperation in generative MASs. Moreover, we find that reputation systems can give rise to rich emergent behaviors in generative MASs, such as the formation of cooperative clusters, the social isolation of exploitative agents, and the preference for sharing positive gossip rather than negative ones.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.05029.pdf", "abstract_url": "https://arxiv.org/abs/2505.05029", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出RepuNet，一个动态的双层声誉框架，用于解决生成多代理系统中的'公地悲剧'问题，通过直接互动和间接流言形成代理声誉，有效促进合作。", "motivation": "解决生成多代理系统中因个体自利行为导致的集体灾难性后果，即'公地悲剧'问题。", "method": "提出RepuNet，一个动态的双层声誉框架，模拟代理级声誉动态和系统级网络演化，通过直接互动和间接流言形成声誉。", "result": "RepuNet有效缓解了'公地悲剧'，促进了生成多代理系统中的合作，并观察到了丰富的涌现行为，如合作集群的形成、剥削代理的社会隔离以及分享积极流言的偏好。", "conclusion": "声誉系统如RepuNet能够有效解决生成多代理系统中的合作问题，防止'公地悲剧'，并促进积极的社交行为。"}}
{"id": "2505.05108", "title": "Multi-agent Embodied AI: Advances and Future Directions", "authors": ["Zhaohan Feng", "Ruiqi Xue", "Lei Yuan", "Yang Yu", "Ning Ding", "Meiqin Liu", "Bingzhao Gao", "Jian Sun", "Gang Wang"], "abstract": "Embodied artificial intelligence (Embodied AI) plays a pivotal role in the application of advanced technologies in the intelligent era, where AI systems are integrated with physical bodies that enable them to perceive, reason, and interact with their environments. Through the use of sensors for input and actuators for action, these systems can learn and adapt based on real-world feedback, allowing them to perform tasks effectively in dynamic and unpredictable environments. As techniques such as deep learning (DL), reinforcement learning (RL), and large language models (LLMs) mature, embodied AI has become a leading field in both academia and industry, with applications spanning robotics, healthcare, transportation, and manufacturing. However, most research has focused on single-agent systems that often assume static, closed environments, whereas real-world embodied AI must navigate far more complex scenarios. In such settings, agents must not only interact with their surroundings but also collaborate with other agents, necessitating sophisticated mechanisms for adaptation, real-time learning, and collaborative problem-solving. Despite increasing interest in multi-agent systems, existing research remains narrow in scope, often relying on simplified models that fail to capture the full complexity of dynamic, open environments for multi-agent embodied AI. Moreover, no comprehensive survey has systematically reviewed the advancements in this area. As embodied AI rapidly evolves, it is crucial to deepen our understanding of multi-agent embodied AI to address the challenges presented by real-world applications. To fill this gap and foster further development in the field, this paper reviews the current state of research, analyzes key contributions, and identifies challenges and future directions, providing insights to guide innovation and progress in this field.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.05108.pdf", "abstract_url": "https://arxiv.org/abs/2505.05108", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文综述了多智能体具身人工智能（Embodied AI）的研究现状、关键贡献、挑战及未来方向，强调了在动态开放环境中多智能体协作的重要性。", "motivation": "解决现实世界中多智能体具身AI在动态、开放环境中的协作与适应问题，填补该领域综合性研究的空白。", "method": "通过系统回顾当前研究，分析关键技术和挑战，提出未来发展方向。", "result": "识别了多智能体具身AI研究中的局限性，如过度简化模型，缺乏对动态开放环境的全面考虑。", "conclusion": "为了推动多智能体具身AI的发展，需要更深入地理解其在复杂环境中的应用，促进技术创新和进步。"}}
{"id": "2505.05318", "title": "Mapping User Trust in Vision Language Models: Research Landscape, Challenges, and Prospects", "authors": ["Agnese Chiatti", "Sara Bernardini", "Lara Shibelski Godoy Piccolo", "Viola Schiaffonati", "Matteo Matteucci"], "abstract": "The rapid adoption of Vision Language Models (VLMs), pre-trained on large image-text and video-text datasets, calls for protecting and informing users about when to trust these systems. This survey reviews studies on trust dynamics in user-VLM interactions, through a multi-disciplinary taxonomy encompassing different cognitive science capabilities, collaboration modes, and agent behaviours. Literature insights and findings from a workshop with prospective VLM users inform preliminary requirements for future VLM trust studies.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Computers and Society (cs.CY); Human-Computer Interaction (cs.HC); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.05318.pdf", "abstract_url": "https://arxiv.org/abs/2505.05318", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)", "Human-Computer Interaction (cs.HC)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文综述了视觉语言模型（VLMs）中用户信任的研究，通过多学科分类法探讨了信任动态，并基于文献和用户研讨提出了未来研究的初步要求。", "motivation": "随着视觉语言模型（VLMs）的快速应用，需要保护并告知用户何时可以信任这些系统。", "method": "通过多学科分类法回顾了用户-VLM互动中的信任动态研究，并结合文献见解和潜在用户的研讨会结果。", "result": "提出了未来VLM信任研究的初步要求。", "conclusion": "本文为理解和管理用户对VLMs的信任提供了研究框架和方向，强调了多学科方法的重要性。"}}
{"id": "2505.05059", "title": "Enhancing Reinforcement Learning for the Floorplanning of Analog ICs with Beam Search", "authors": ["Sandro Junior Della Rovere", "Davide Basso", "Luca Bortolussi", "Mirjana Videnovic-Misic", "Husni Habal"], "abstract": "The layout of analog ICs requires making complex trade-offs, while addressing device physics and variability of the circuits. This makes full automation with learning-based solutions hard to achieve. However, reinforcement learning (RL) has recently reached significant results, particularly in solving the floorplanning problem. This paper presents a hybrid method that combines RL with a beam (BS) strategy. The BS algorithm enhances the agent's inference process, allowing for the generation of flexible floorplans by accomodating various objective weightings, and addressing congestion without without the need for policy retraining or fine-tuning. Moreover, the RL agent's generalization ability stays intact, along with its efficient handling of circuit features and constraints. Experimental results show approx. 5-85% improvement in area, dead space and half-perimeter wire length compared to a standard RL application, along with higher rewards for the agent. Moreover, performance and efficiency align closely with those of existing state-of-the-art techniques.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "Published in Proceedings of the 21st International Conference on Synthesis, Modeling, Analysis and Simulation Methods, and Applications to Circuit Design (SMACD 2025). 4 pages, 3 figures", "pdf_url": "https://arxiv.org/pdf/2505.05059.pdf", "abstract_url": "https://arxiv.org/abs/2505.05059", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种结合强化学习（RL）和波束搜索（BS）的混合方法，用于模拟集成电路的布局规划。该方法通过BS算法增强RL代理的推理过程，无需重新训练或微调策略，即可生成灵活的布局方案，有效处理拥塞问题。实验结果显示，在面积、死区和半周长线长等方面比标准RL应用有约5-85%的改善，且代理获得更高的奖励。", "motivation": "模拟集成电路的布局需要做出复杂的权衡，同时解决器件物理和电路变异性的问题，这使得基于学习的全自动化解决方案难以实现。本文旨在通过结合RL和BS策略，提高布局规划的自动化水平和效率。", "method": "本文采用了一种混合方法，结合了强化学习（RL）和波束搜索（BS）策略。BS算法用于增强RL代理的推理过程，支持多种目标权重的灵活调整，并有效处理拥塞问题。", "result": "实验结果表明，与标准RL应用相比，该方法在面积、死区和半周长线长等方面实现了约5-85%的改善，同时代理获得了更高的奖励。其性能和效率与现有最先进技术相当。", "conclusion": "本文提出的RL与BS结合的混合方法，不仅保持了RL代理的泛化能力和对电路特征及约束的高效处理，而且在布局规划的性能和效率上实现了显著提升，为模拟集成电路的自动化布局提供了新的解决方案。"}}
{"id": "2505.04844", "title": "Osiris: A Lightweight Open-Source Hallucination Detection System", "authors": ["Alex Shan", "John Bauer", "Christopher D. Manning"], "abstract": "Retrieval-Augmented Generation (RAG) systems have gained widespread adoption by application builders because they leverage sources of truth to enable Large Language Models (LLMs) to generate more factually sound responses. However, hallucinations, instances of LLM responses that are unfaithful to the provided context, often prevent these systems from being deployed in production environments. Current hallucination detection methods typically involve human evaluation or the use of closed-source models to review RAG system outputs for hallucinations. Both human evaluators and closed-source models suffer from scaling issues due to their high costs and slow inference speeds. In this work, we introduce a perturbed multi-hop QA dataset with induced hallucinations. Via supervised fine-tuning on our dataset, we achieve better recall with a 7B model than GPT-4o on the RAGTruth hallucination detection benchmark and offer competitive performance on precision and accuracy, all while using a fraction of the parameters. Code is released at our repository.", "subjects": "Computation and Language (cs.CL)", "comments": "Stanford 191W", "pdf_url": "https://arxiv.org/pdf/2505.04844.pdf", "abstract_url": "https://arxiv.org/abs/2505.04844", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了Osiris，一个轻量级的开源幻觉检测系统，旨在解决检索增强生成（RAG）系统中因幻觉问题而难以部署到生产环境的问题。通过在一个扰动多跳QA数据集上进行监督微调，Osiris在RAGTruth幻觉检测基准上以7B模型的规模实现了比GPT-4o更好的召回率，并在精度和准确度上表现出竞争力。", "motivation": "解决RAG系统中因LLM生成的响应与提供上下文不忠实（即幻觉）而难以部署到生产环境的问题，以及当前依赖人工评估或闭源模型的幻觉检测方法在扩展性上的高成本和慢推理速度问题。", "method": "通过在一个扰动多跳QA数据集上进行监督微调，开发了一个轻量级的开源幻觉检测系统Osiris。", "result": "Osiris在RAGTruth幻觉检测基准上以7B模型的规模实现了比GPT-4o更好的召回率，并在精度和准确度上表现出竞争力。", "conclusion": "Osiris作为一个轻量级的开源幻觉检测系统，不仅解决了RAG系统中的幻觉问题，还通过高效的方法在性能上超越了更大规模的闭源模型，为RAG系统的生产部署提供了可行的解决方案。"}}
{"id": "2505.04847", "title": "Benchmarking LLM Faithfulness in RAG with Evolving Leaderboards", "authors": ["Manveer Singh Tamber", "Forrest Sheng Bao", "Chenyu Xu", "Ge Luo", "Suleman Kazi", "Minseok Bae", "Miaoran Li", "Ofer Mendelevitch", "Renyi Qu", "Jimmy Lin"], "abstract": "Hallucinations remain a persistent challenge for LLMs. RAG aims to reduce hallucinations by grounding responses in contexts. However, even when provided context, LLMs still frequently introduce unsupported information or contradictions. This paper presents our efforts to measure LLM hallucinations with a focus on summarization tasks, assessing how often various LLMs introduce hallucinations when summarizing documents. We discuss Vectara's existing LLM hallucination leaderboard, based on the Hughes Hallucination Evaluation Model (HHEM). While HHEM and Vectara's Hallucination Leaderboard have garnered great research interest, we examine challenges faced by HHEM and current hallucination detection methods by analyzing the effectiveness of these methods on existing hallucination datasets. To address these limitations, we propose FaithJudge, an LLM-as-a-judge approach guided by few-shot human hallucination annotations, which substantially improves automated LLM hallucination evaluation over current methods. We introduce an enhanced hallucination leaderboard centered on FaithJudge, alongside our current hallucination leaderboard, enabling more reliable benchmarking of LLMs for hallucinations in RAG.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.04847.pdf", "abstract_url": "https://arxiv.org/abs/2505.04847", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文探讨了如何测量大型语言模型(LLMs)在摘要任务中的幻觉问题，介绍了Vectara现有的LLM幻觉排行榜及其基于的Hughes Hallucination Evaluation Model (HHEM)。文章分析了HHEM和当前幻觉检测方法面临的挑战，并提出了FaithJudge方法，这是一种基于少量人类幻觉注释指导的LLM-as-a-judge方法，显著提高了自动化LLM幻觉评估的准确性。最后，文章介绍了一个以FaithJudge为中心的增强版幻觉排行榜，旨在为RAG中的LLM幻觉提供更可靠的基准测试。", "motivation": "解决LLMs在提供上下文的情况下仍然频繁引入不支持信息或矛盾的幻觉问题，特别是在摘要任务中。", "method": "提出了FaithJudge方法，这是一种基于少量人类幻觉注释指导的LLM-as-a-judge方法，用于自动化评估LLM的幻觉。", "result": "FaithJudge方法显著提高了自动化LLM幻觉评估的准确性，超越了当前的方法。", "conclusion": "通过引入以FaithJudge为中心的增强版幻觉排行榜，能够更可靠地评估RAG中LLMs的幻觉问题，为未来的研究和应用提供了新的方向。"}}
{"id": "2505.04916", "title": "An Open-Source Dual-Loss Embedding Model for Semantic Retrieval in Higher Education", "authors": ["Ramteja Sajja", "Yusuf Sermet", "Ibrahim Demir"], "abstract": "Recent advances in AI have catalyzed the adoption of intelligent educational tools, yet many semantic retrieval systems remain ill-suited to the unique linguistic and structural characteristics of academic content. This study presents two open-source embedding models fine-tuned for educational question answering, particularly in the context of course syllabi. A synthetic dataset of 3,197 sentence pairs, spanning synonymous terminology, paraphrased questions, and implicit-explicit mappings, was constructed through a combination of manual curation and large language model (LLM)-assisted generation. Two training strategies were evaluated: (1) a baseline model fine-tuned using MultipleNegativesRankingLoss (MNRL), and (2) a dual-loss model that combines MNRL with CosineSimilarityLoss to improve both semantic ranking and similarity calibration. Evaluations were conducted on 28 university course syllabi using a fixed set of natural language questions categorized into course, faculty, and teaching assistant information. Results demonstrate that both fine-tuned models outperform strong open-source baselines, including all-MiniLM-L6-v2 and multi-qa-MiniLM-L6-cos-v1, and that the dual-loss model narrows the performance gap with high-performing proprietary embeddings such as OpenAI's text-embedding-3 series. This work contributes reusable, domain-aligned embedding models and provides a replicable framework for educational semantic retrieval, supporting downstream applications such as academic chatbots, retrieval-augmented generation (RAG) systems, and learning management system (LMS) integrations.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": "17 pages, 3 Tables", "pdf_url": "https://arxiv.org/pdf/2505.04916.pdf", "abstract_url": "https://arxiv.org/abs/2505.04916", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本研究提出了两种针对教育问答（特别是课程大纲）进行微调的开源嵌入模型，通过结合手动策划和大型语言模型辅助生成的方法构建了一个包含3,197个句子对的合成数据集。评估结果表明，这两种微调模型均优于强大的开源基线模型，且双损失模型缩小了与高性能专有嵌入模型的性能差距。", "motivation": "当前许多语义检索系统不适合学术内容的独特语言和结构特征，本研究旨在解决这一问题，特别是在教育问答领域。", "method": "研究评估了两种训练策略：一种是使用MultipleNegativesRankingLoss（MNRL）进行微调的基线模型，另一种是结合MNRL和CosineSimilarityLoss的双损失模型，以改进语义排名和相似性校准。", "result": "结果表明，这两种微调模型均优于包括all-MiniLM-L6-v2和multi-qa-MiniLM-L6-cos-v1在内的强大开源基线模型，且双损失模型缩小了与OpenAI的text-embedding-3系列等高性能专有嵌入模型的性能差距。", "conclusion": "这项工作贡献了可重复使用的、与领域对齐的嵌入模型，并为教育语义检索提供了一个可复制的框架，支持学术聊天机器人、检索增强生成（RAG）系统和学习管理系统（LMS）集成等下游应用。"}}
{"id": "2505.05115", "title": "Is there a half-life for the success rates of AI agents?", "authors": ["Toby Ord"], "abstract": "Building on the recent empirical work of Kwa et al. (2025), I show that within their suite of research-engineering tasks the performance of AI agents on longer-duration tasks can be explained by an extremely simple mathematical model -- a constant rate of failing during each minute a human would take to do the task. This implies an exponentially declining success rate with the length of the task and that each agent could be characterised by its own half-life. This empirical regularity allows us to estimate the success rate for an agent at different task lengths. And the fact that this model is a good fit for the data is suggestive of the underlying causes of failure on longer tasks -- that they involve increasingly large sets of subtasks where failing any one fails the task. Whether this model applies more generally on other suites of tasks is unknown and an important subject for further work.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "9 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2505.05115.pdf", "abstract_url": "https://arxiv.org/abs/2505.05115", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文基于Kwa等人（2025年）的实证研究，展示了AI代理在长时间任务中的表现可以通过一个极其简单的数学模型来解释，即每分钟失败率恒定。这意味着成功率随任务长度呈指数下降，每个代理可以用其半衰期来表征。", "motivation": "解决AI代理在长时间任务中成功率下降的问题，并探索其背后的原因。", "method": "使用一个简单的数学模型，即每分钟失败率恒定，来分析AI代理在长时间任务中的表现。", "result": "发现AI代理的成功率随任务长度呈指数下降，每个代理可以用其半衰期来表征。这一模型很好地拟合了数据，暗示了长时间任务失败的原因是涉及越来越多的子任务，其中任何一个子任务的失败都会导致整个任务的失败。", "conclusion": "这一模型为理解AI代理在长时间任务中的表现提供了新的视角，但其在其他任务套件中的适用性尚不清楚，需要进一步研究。"}}
{"id": "2505.05177", "title": "MARK: Memory Augmented Refinement of Knowledge", "authors": ["Anish Ganguli", "Prabal Deb", "Debleena Banerjee"], "abstract": "Large Language Models (LLMs) assist in specialized tasks but struggle to align with evolving domain knowledge without costly fine-tuning. Domain knowledge consists of: Knowledge: Immutable facts (e.g., 'A stone is solid') and generally accepted principles (e.g., ethical standards); Refined Memory: Evolving insights shaped by business needs and real-world changes. However, a significant gap often exists between a domain expert's deep, nuanced understanding and the system's domain knowledge, which can hinder accurate information retrieval and application. Our Memory-Augmented Refinement of Knowledge (MARK) framework enables LLMs to continuously learn without retraining by leveraging structured refined memory, inspired by the Society of Mind. MARK operates through specialized agents, each serving a distinct role: Residual Refined Memory Agent: Stores and retrieves domain-specific insights to maintain context over time; User Question Refined Memory Agent: Captures user-provided facts, abbreviations, and terminology for better comprehension; LLM Response Refined Memory Agent: Extracts key elements from responses for refinement and personalization. These agents analyse stored refined memory, detect patterns, resolve contradictions, and improve response accuracy. Temporal factors like recency and frequency prioritize relevant information while discarding outdated insights. MARK enhances LLMs in multiple ways: Ground Truth Strategy: Reduces hallucinations by establishing a structured reference; Domain-Specific Adaptation: Essential for fields like healthcare, law, and manufacturing, where proprietary insights are absent from public datasets; Personalized AI Assistants: Improves virtual assistants by remembering user preferences, ensuring coherent responses over time.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.05177.pdf", "abstract_url": "https://arxiv.org/abs/2505.05177", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "MARK框架通过结构化精炼记忆使大型语言模型（LLMs）无需重新训练即可持续学习，解决了LLMs难以适应不断演变的领域知识的问题。", "motivation": "解决大型语言模型（LLMs）在适应不断演变的领域知识时需要进行昂贵微调的问题，以及领域专家深厚、细致的理解与系统领域知识之间存在显著差距的问题。", "method": "采用MARK框架，通过专门的代理（如残余精炼记忆代理、用户问题精炼记忆代理和LLM响应精炼记忆代理）来存储、检索和精炼领域特定洞察，利用时间因素（如新近性和频率）优先考虑相关信息。", "result": "MARK框架通过减少幻觉、领域特定适应和个性化AI助手，提高了LLMs的准确性和应用范围。", "conclusion": "MARK框架为LLMs提供了一种无需重新训练即可持续学习和适应领域知识的方法，特别是在医疗、法律和制造等领域，以及个性化AI助手的开发中具有重要应用价值。"}}
{"id": "2505.05197", "title": "Societal and technological progress as sewing an ever-growing, ever-changing, patchy, and polychrome quilt", "authors": ["Joel Z. Leibo", "Alexander Sasha Vezhnevets", "William A. Cunningham", "Sébastien Krier", "Manfred Diaz", "Simon Osindero"], "abstract": "Artificial Intelligence (AI) systems are increasingly placed in positions where their decisions have real consequences, e.g., moderating online spaces, conducting research, and advising on policy. Ensuring they operate in a safe and ethically acceptable fashion is thus critical. However, most solutions have been a form of one-size-fits-all \"alignment\". We are worried that such systems, which overlook enduring moral diversity, will spark resistance, erode trust, and destabilize our institutions. This paper traces the underlying problem to an often-unstated Axiom of Rational Convergence: the idea that under ideal conditions, rational agents will converge in the limit of conversation on a single ethics. Treating that premise as both optional and doubtful, we propose what we call the appropriateness framework: an alternative approach grounded in conflict theory, cultural evolution, multi-agent systems, and institutional economics. The appropriateness framework treats persistent disagreement as the normal case and designs for it by applying four principles: (1) contextual grounding, (2) community customization, (3) continual adaptation, and (4) polycentric governance. We argue here that adopting these design principles is a good way to shift the main alignment metaphor from moral unification to a more productive metaphor of conflict management, and that taking this step is both desirable and urgent.", "subjects": "Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "comments": "16 pages", "pdf_url": "https://arxiv.org/pdf/2505.05197.pdf", "abstract_url": "https://arxiv.org/abs/2505.05197", "categories": ["Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了人工智能系统在决策时面临的伦理多样性问题，提出了一种名为‘适当性框架’的替代方法，以应对持续的道德分歧。", "motivation": "解决AI系统在决策时忽视道德多样性，可能导致信任侵蚀和制度不稳定的问题。", "method": "提出了基于冲突理论、文化进化、多智能体系统和制度经济学的‘适当性框架’，包含四个设计原则：上下文基础、社区定制、持续适应和多中心治理。", "result": "通过‘适当性框架’，可以将道德统一的隐喻转变为更有效的冲突管理隐喻。", "conclusion": "采用这些设计原则对于管理持续的道德分歧是可行且紧迫的，有助于AI系统更安全、更符合伦理地运作。"}}
{"id": "2505.05440", "title": "EcoAgent: An Efficient Edge-Cloud Collaborative Multi-Agent Framework for Mobile Automation", "authors": ["Biao Yi", "Xavier Hu", "Yurun Chen", "Shengyu Zhang", "Hongxia Yang", "Fan Wu", "Fei Wu"], "abstract": "Cloud-based mobile agents powered by (multimodal) large language models ((M)LLMs) offer strong reasoning abilities but suffer from high latency and cost. While fine-tuned (M)SLMs enable edge deployment, they often lose general capabilities and struggle with complex tasks. To address this, we propose EcoAgent, an Edge-Cloud cOllaborative multi-agent framework for mobile automation. EcoAgent features a closed-loop collaboration among a cloud-based Planning Agent and two edge-based agents: the Execution Agent for action execution and the Observation Agent for verifying outcomes. The Observation Agent uses a Pre-Understanding Module to compress screen images into concise text, reducing token usage. In case of failure, the Planning Agent retrieves screen history and replans via a Reflection Module. Experiments on AndroidWorld show that EcoAgent maintains high task success rates while significantly reducing MLLM token consumption, enabling efficient and practical mobile automation.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.05440.pdf", "abstract_url": "https://arxiv.org/abs/2505.05440", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "EcoAgent是一个高效的边缘-云协作多代理框架，旨在解决基于云的大型语言模型在移动自动化中高延迟和高成本的问题，同时保持强大的推理能力。", "motivation": "解决基于云的大型语言模型在移动自动化应用中的高延迟、高成本问题，以及边缘部署的细调模型在通用能力和复杂任务处理上的不足。", "method": "提出了EcoAgent框架，通过云端的规划代理和边缘的执行代理、观察代理之间的闭环协作，优化任务执行和验证过程，减少令牌使用。", "result": "在AndroidWorld上的实验表明，EcoAgent在保持高任务成功率的同时，显著减少了大型语言模型的令牌消耗，实现了高效且实用的移动自动化。", "conclusion": "EcoAgent通过边缘-云协作和多代理框架，有效平衡了移动自动化的效率和能力，为未来的移动自动化应用提供了可行的解决方案。"}}
{"id": "2505.05445", "title": "clem:todd: A Framework for the Systematic Benchmarking of LLM-Based Task-Oriented Dialogue System Realisations", "authors": ["Chalamalasetti Kranti", "Sherzod Hakimov", "David Schlangen"], "abstract": "The emergence of instruction-tuned large language models (LLMs) has advanced the field of dialogue systems, enabling both realistic user simulations and robust multi-turn conversational agents. However, existing research often evaluates these components in isolation-either focusing on a single user simulator or a specific system design-limiting the generalisability of insights across architectures and configurations. In this work, we propose clem todd (chat-optimized LLMs for task-oriented dialogue systems development), a flexible framework for systematically evaluating dialogue systems under consistent conditions. clem todd enables detailed benchmarking across combinations of user simulators and dialogue systems, whether existing models from literature or newly developed ones. It supports plug-and-play integration and ensures uniform datasets, evaluation metrics, and computational constraints. We showcase clem todd's flexibility by re-evaluating existing task-oriented dialogue systems within this unified setup and integrating three newly proposed dialogue systems into the same evaluation pipeline. Our results provide actionable insights into how architecture, scale, and prompting strategies affect dialogue performance, offering practical guidance for building efficient and effective conversational AI systems.", "subjects": "Computation and Language (cs.CL)", "comments": "30 pages", "pdf_url": "https://arxiv.org/pdf/2505.05445.pdf", "abstract_url": "https://arxiv.org/abs/2505.05445", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了clem todd框架，用于系统评估基于大型语言模型的任务导向对话系统，支持在不同用户模拟器和对话系统组合下进行统一评测。", "motivation": "现有研究往往孤立评估对话系统的组件，限制了跨架构和配置的通用性见解。", "method": "提出clem todd框架，支持插件式集成，确保统一的数据集、评估指标和计算约束。", "result": "通过统一设置重新评估现有系统并集成新系统，提供了关于架构、规模和提示策略如何影响对话性能的可操作见解。", "conclusion": "clem todd框架为构建高效有效的对话AI系统提供了实用指导。"}}
{"id": "2505.05225", "title": "QualBench: Benchmarking Chinese LLMs with Localized Professional Qualifications for Vertical Domain Evaluation", "authors": ["Mengze Hong", "Wailing Ng", "Di Jiang", "Chen Jason Zhang"], "abstract": "The rapid advancement of Chinese large language models (LLMs) underscores the need for domain-specific evaluations to ensure reliable applications. However, existing benchmarks often lack coverage in vertical domains and offer limited insights into the Chinese working context. Leveraging qualification exams as a unified framework for human expertise evaluation, we introduce QualBench, the first multi-domain Chinese QA benchmark dedicated to localized assessment of Chinese LLMs. The dataset includes over 17,000 questions across six vertical domains, with data selections grounded in 24 Chinese qualifications to closely align with national policies and working standards. Through comprehensive evaluation, the Qwen2.5 model outperformed the more advanced GPT-4o, with Chinese LLMs consistently surpassing non-Chinese models, highlighting the importance of localized domain knowledge in meeting qualification requirements. The best performance of 75.26% reveals the current gaps in domain coverage within model capabilities. Furthermore, we present the failure of LLM collaboration with crowdsourcing mechanisms and suggest the opportunities for multi-domain RAG knowledge enhancement and vertical domain LLM training with Federated Learning.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.05225.pdf", "abstract_url": "https://arxiv.org/abs/2505.05225", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "QualBench是首个专注于中文大语言模型（LLMs）垂直领域评估的多领域中文QA基准测试，包含超过17,000个问题，覆盖六个垂直领域，基于24项中国资格认证，旨在评估模型在中国工作环境中的表现。", "motivation": "现有基准测试在垂直领域的覆盖不足，且对中国工作环境的洞察有限，这促使了QualBench的创建，以提供更贴近中国政策和行业标准的评估框架。", "method": "利用资格认证考试作为人类专业知识评估的统一框架，构建了一个包含多领域问题的数据集，并对中文LLMs进行了全面评估。", "result": "Qwen2.5模型表现优于更先进的GPT-4o，中文LLMs普遍超越非中文模型，最佳表现达到75.26%，揭示了模型能力在领域覆盖上的当前差距。", "conclusion": "研究强调了本地化领域知识在满足资格要求中的重要性，并指出了LLM与众包机制合作的失败，以及多领域RAG知识增强和垂直领域LLM训练与联邦学习的潜在机会。"}}
{"id": "2505.04784", "title": "A Proposal for Evaluating the Operational Risk for ChatBots based on Large Language Models", "authors": ["Pedro Pinacho-Davidson", "Fernando Gutierrez", "Pablo Zapata", "Rodolfo Vergara", "Pablo Aqueveque"], "abstract": "The emergence of Generative AI (Gen AI) and Large Language Models (LLMs) has enabled more advanced chatbots capable of human-like interactions. However, these conversational agents introduce a broader set of operational risks that extend beyond traditional cybersecurity considerations. In this work, we propose a novel, instrumented risk-assessment metric that simultaneously evaluates potential threats to three key stakeholders: the service-providing organization, end users, and third parties. Our approach incorporates the technical complexity required to induce erroneous behaviors in the chatbot--ranging from non-induced failures to advanced prompt-injection attacks--as well as contextual factors such as the target industry, user age range, and vulnerability severity. To validate our metric, we leverage Garak, an open-source framework for LLM vulnerability testing. We further enhance Garak to capture a variety of threat vectors (e.g., misinformation, code hallucinations, social engineering, and malicious code generation). Our methodology is demonstrated in a scenario involving chatbots that employ retrieval-augmented generation (RAG), showing how the aggregated risk scores guide both short-term mitigation and longer-term improvements in model design and deployment. The results underscore the importance of multi-dimensional risk assessments in operationalizing secure, reliable AI-driven conversational systems.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "comments": "21 pages", "pdf_url": "https://arxiv.org/pdf/2505.04784.pdf", "abstract_url": "https://arxiv.org/abs/2505.04784", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文提出了一种基于大型语言模型的聊天机器人操作风险评估新方法，考虑了服务提供商、终端用户和第三方三个关键利益相关者，结合技术复杂性和上下文因素，使用增强的Garak框架验证，并通过RAG聊天机器人场景展示了其有效性。", "motivation": "随着生成式AI和大型语言模型的发展，聊天机器人能够进行更人性化的交互，但也带来了超出传统网络安全考虑的操作风险。本文旨在解决如何全面评估这些风险的问题。", "method": "提出了一种新颖的、仪器化的风险评估指标，结合了诱导聊天机器人错误行为的技术复杂性和上下文因素，使用增强的Garak框架进行验证。", "result": "通过RAG聊天机器人场景的演示，展示了聚合风险评分如何指导短期缓解和长期模型设计与部署的改进，强调了多维风险评估在操作化安全、可靠的AI驱动对话系统中的重要性。", "conclusion": "本文的方法强调了在操作化安全、可靠的AI驱动对话系统中进行多维风险评估的重要性，为聊天机器人的设计和部署提供了实用的风险评估工具。"}}
{"id": "2505.04725", "title": "Geometric Fault-Tolerant Neural Network Tracking Control of Unknown Systems on Matrix Lie Groups", "authors": ["Robin Chhabra", "Farzaneh Abdollahi"], "abstract": "We present a geometric neural network-based tracking controller for systems evolving on matrix Lie groups under unknown dynamics, actuator faults, and bounded disturbances. Leveraging the left-invariance of the tangent bundle of matrix Lie groups, viewed as an embedded submanifold of the vector space $\\R^{N\\times N}$, we propose a set of learning rules for neural network weights that are intrinsically compatible with the Lie group structure and do not require explicit parameterization. Exploiting the geometric properties of Lie groups, this approach circumvents parameterization singularities and enables a global search for optimal weights. The ultimate boundedness of all error signals -- including the neural network weights, the coordinate-free configuration error function, and the tracking velocity error -- is established using Lyapunov's direct method. To validate the effectiveness of the proposed method, we provide illustrative simulation results for decentralized formation control of multi-agent systems on the Special Euclidean group.", "subjects": "Systems and Control (eess.SY); Artificial Intelligence (cs.AI); Robotics (cs.RO); Dynamical Systems (math.DS)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.04725.pdf", "abstract_url": "https://arxiv.org/abs/2505.04725", "categories": ["Systems and Control (eess.SY)", "Artificial Intelligence (cs.AI)", "Robotics (cs.RO)", "Dynamical Systems (math.DS)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于几何神经网络的跟踪控制器，用于处理在矩阵李群上演化、具有未知动力学、执行器故障和有界干扰的系统。该方法利用矩阵李群切丛的左不变性，提出了一组与李群结构内在兼容的神经网络权重学习规则，无需显式参数化。通过利用李群的几何特性，此方法避免了参数化奇异性，并实现了对最优权重的全局搜索。使用Lyapunov直接方法，建立了所有误差信号的最终有界性。通过在多智能体系统的特殊欧几里得群上的分散形成控制仿真结果，验证了所提方法的有效性。", "motivation": "解决在矩阵李群上演化、具有未知动力学、执行器故障和有界干扰的系统的跟踪控制问题。", "method": "利用矩阵李群切丛的左不变性，提出了一组与李群结构内在兼容的神经网络权重学习规则，无需显式参数化。", "result": "建立了所有误差信号的最终有界性，并通过仿真验证了方法的有效性。", "conclusion": "所提出的几何神经网络跟踪控制器能够有效处理在矩阵李群上演化、具有未知动力学、执行器故障和有界干扰的系统的跟踪控制问题，避免了参数化奇异性，并实现了对最优权重的全局搜索。"}}
{"id": "2505.04846", "title": "HiPerRAG: High-Performance Retrieval Augmented Generation for Scientific Insights", "authors": ["Ozan Gokdemir", "Carlo Siebenschuh", "Alexander Brace", "Azton Wells", "Brian Hsu", "Kyle Hippe", "Priyanka V. Setty", "Aswathy Ajith", "J. Gregory Pauloski", "Varuni Sastry", "Sam Foreman", "Huihuo Zheng", "Heng Ma", "Bharat Kale", "Nicholas Chia", "Thomas Gibbs", "Michael E. Papka", "Thomas Brettin", "Francis J. Alexander", "Anima Anandkumar", "Ian Foster", "Rick Stevens", "Venkatram Vishwanath", "Arvind Ramanathan"], "abstract": "The volume of scientific literature is growing exponentially, leading to underutilized discoveries, duplicated efforts, and limited cross-disciplinary collaboration. Retrieval Augmented Generation (RAG) offers a way to assist scientists by improving the factuality of Large Language Models (LLMs) in processing this influx of information. However, scaling RAG to handle millions of articles introduces significant challenges, including the high computational costs associated with parsing documents and embedding scientific knowledge, as well as the algorithmic complexity of aligning these representations with the nuanced semantics of scientific content. To address these issues, we introduce HiPerRAG, a RAG workflow powered by high performance computing (HPC) to index and retrieve knowledge from more than 3.6 million scientific articles. At its core are Oreo, a high-throughput model for multimodal document parsing, and ColTrast, a query-aware encoder fine-tuning algorithm that enhances retrieval accuracy by using contrastive learning and late-interaction techniques. HiPerRAG delivers robust performance on existing scientific question answering benchmarks and two new benchmarks introduced in this work, achieving 90% accuracy on SciQ and 76% on PubMedQA-outperforming both domain-specific models like PubMedGPT and commercial LLMs such as GPT-4. Scaling to thousands of GPUs on the Polaris, Sunspot, and Frontier supercomputers, HiPerRAG delivers million document-scale RAG workflows for unifying scientific knowledge and fostering interdisciplinary innovation.", "subjects": "Information Retrieval (cs.IR); Computational Engineering, Finance, and Science (cs.CE); Computation and Language (cs.CL); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)", "comments": "This paper has been accepted at the Platform for Advanced Scientific Computing Conference (PASC 25), June 16-18, 2025, Brugg-Windisch, Switzerland", "pdf_url": "https://arxiv.org/pdf/2505.04846.pdf", "abstract_url": "https://arxiv.org/abs/2505.04846", "categories": ["Information Retrieval (cs.IR)", "Computational Engineering, Finance, and Science (cs.CE)", "Computation and Language (cs.CL)", "Distributed, Parallel, and Cluster Computing (cs.DC)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "HiPerRAG是一种高性能的检索增强生成（RAG）工作流程，旨在通过高性能计算（HPC）处理超过360万篇科学文章，解决科学文献快速增长带来的挑战。它结合了Oreo多模态文档解析模型和ColTrast查询感知编码器微调算法，显著提高了检索准确性。", "motivation": "科学文献的指数级增长导致了发现的未充分利用、努力重复和跨学科合作有限。HiPerRAG旨在通过改进大型语言模型（LLMs）在处理这些信息时的真实性来解决这些问题。", "method": "HiPerRAG利用高性能计算（HPC）来索引和检索知识，核心包括Oreo（一种高吞吐量的多模态文档解析模型）和ColTrast（一种使用对比学习和晚期交互技术增强检索准确性的查询感知编码器微调算法）。", "result": "HiPerRAG在现有的科学问答基准和本工作中引入的两个新基准上表现出色，在SciQ上达到90%的准确率，在PubMedQA上达到76%的准确率，超过了PubMedGPT等特定领域模型和GPT-4等商业LLMs。", "conclusion": "HiPerRAG通过扩展到数千个GPU，在Polaris、Sunspot和Frontier超级计算机上实现了百万文档规模的RAG工作流程，为统一科学知识和促进跨学科创新提供了强有力的工具。"}}
{"id": "2505.05223", "title": "Multi-Objective Reinforcement Learning for Adaptive Personalized Autonomous Driving", "authors": ["Hendrik Surmann", "Jorge de Heuvel", "Maren Bennewitz"], "abstract": "Human drivers exhibit individual preferences regarding driving style. Adapting autonomous vehicles to these preferences is essential for user trust and satisfaction. However, existing end-to-end driving approaches often rely on predefined driving styles or require continuous user feedback for adaptation, limiting their ability to support dynamic, context-dependent preferences. We propose a novel approach using multi-objective reinforcement learning (MORL) with preference-driven optimization for end-to-end autonomous driving that enables runtime adaptation to driving style preferences. Preferences are encoded as continuous weight vectors to modulate behavior along interpretable style objectives$\\unicode{x2013}$including efficiency, comfort, speed, and aggressiveness$\\unicode{x2013}$without requiring policy retraining. Our single-policy agent integrates vision-based perception in complex mixed-traffic scenarios and is evaluated in diverse urban environments using the CARLA simulator. Experimental results demonstrate that the agent dynamically adapts its driving behavior according to changing preferences while maintaining performance in terms of collision avoidance and route completion.", "subjects": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.05223.pdf", "abstract_url": "https://arxiv.org/abs/2505.05223", "categories": ["Robotics (cs.RO)", "Computer Vision and Pattern Recognition (cs.CV)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于多目标强化学习（MORL）的自适应个性化自动驾驶方法，通过偏好驱动优化实现运行时对驾驶风格偏好的适应，无需策略重新训练。", "motivation": "人类驾驶员展现出个性化的驾驶风格偏好，现有端到端驾驶方法通常依赖于预定义的驾驶风格或需要持续的用户反馈进行适应，限制了其支持动态、上下文相关偏好的能力。", "method": "使用多目标强化学习（MORL）与偏好驱动优化，将偏好编码为连续权重向量，以在可解释的风格目标（包括效率、舒适度、速度和攻击性）上调节行为。", "result": "实验结果表明，该代理能够根据变化的偏好动态调整其驾驶行为，同时在避免碰撞和路线完成方面保持性能。", "conclusion": "该方法能够有效适应驾驶风格偏好，提高用户信任和满意度，为自动驾驶领域提供了一种新的解决方案。"}}
{"id": "2505.05015", "title": "An Agent-Based Modeling Approach to Free-Text Keyboard Dynamics for Continuous Authentication", "authors": ["Roberto Dillon", "Arushi"], "abstract": "Continuous authentication systems leveraging free-text keyboard dynamics offer a promising additional layer of security in a multifactor authentication setup that can be used in a transparent way with no impact on user experience. This study investigates the efficacy of behavioral biometrics by employing an Agent-Based Model (ABM) to simulate diverse typing profiles across mechanical and membrane keyboards. Specifically, we generated synthetic keystroke data from five unique agents, capturing features related to dwell time, flight time, and error rates within sliding 5-second windows updated every second. Two machine learning approaches, One-Class Support Vector Machine (OC-SVM) and Random Forest (RF), were evaluated for user verification. Results revealed a stark contrast in performance: while One-Class SVM failed to differentiate individual users within each group, Random Forest achieved robust intra-keyboard user recognition (Accuracy > 0.7) but struggled to generalize across keyboards for the same user, highlighting the significant impact of keyboard hardware on typing behavior. These findings suggest that: (1) keyboard-specific user profiles may be necessary for reliable authentication, and (2) ensemble methods like RF outperform One-Class SVM in capturing fine-grained user-specific patterns.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)", "comments": "16 pages, 5 figures, 12 tables", "pdf_url": "https://arxiv.org/pdf/2505.05015.pdf", "abstract_url": "https://arxiv.org/abs/2505.05015", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Cryptography and Security (cs.CR)"], "matching_keywords": ["agent"], "AI": {"tldr": "本研究探讨了利用自由文本键盘动态进行连续认证的代理基于模型方法，通过模拟不同键盘上的打字行为，评估了两种机器学习方法在用户验证中的效果。", "motivation": "解决在多重认证设置中，如何利用自由文本键盘动态作为一种透明且不影响用户体验的额外安全层的问题。", "method": "采用代理基于模型（ABM）模拟机械和薄膜键盘上的多样化打字行为，生成合成击键数据，并使用一类支持向量机（OC-SVM）和随机森林（RF）两种机器学习方法进行用户验证。", "result": "一类支持向量机无法区分组内用户，而随机森林在键盘内用户识别上表现良好（准确率>0.7），但在跨键盘同一用户识别上表现不佳，表明键盘硬件对打字行为有显著影响。", "conclusion": "研究结果表明：（1）可能需要键盘特定的用户配置文件以实现可靠的认证；（2）在捕捉细粒度用户特定模式方面，集成方法如随机森林优于一类支持向量机。"}}
{"id": "2505.05211", "title": "Incentive-Aware Machine Learning; Robustness, Fairness, Improvement & Causality", "authors": ["Chara Podimata"], "abstract": "The article explores the emerging domain of incentive-aware machine learning (ML), which focuses on algorithmic decision-making in contexts where individuals can strategically modify their inputs to influence outcomes. It categorizes the research into three perspectives: robustness, aiming to design models resilient to \"gaming\"; fairness, analyzing the societal impacts of such systems; and improvement/causality, recognizing situations where strategic actions lead to genuine personal or societal improvement. The paper introduces a unified framework encapsulating models for these perspectives, including offline, online, and causal settings, and highlights key challenges such as differentiating between gaming and improvement and addressing heterogeneity among agents. By synthesizing findings from diverse works, we outline theoretical advancements and practical solutions for robust, fair, and causally-informed incentive-aware ML systems.", "subjects": "Computer Science and Game Theory (cs.GT); Artificial Intelligence (cs.AI)", "comments": "This literature review was published in SIGEcom Exchanges in 2025", "pdf_url": "https://arxiv.org/pdf/2505.05211.pdf", "abstract_url": "https://arxiv.org/abs/2505.05211", "categories": ["Computer Science and Game Theory (cs.GT)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了激励感知机器学习（ML）的新兴领域，专注于在个体可以策略性修改输入以影响结果的背景下进行算法决策。", "motivation": "解决在个体可能策略性行为影响ML系统决策时，如何保持模型的鲁棒性、公平性，并识别策略性行为带来的真正个人或社会改进的问题。", "method": "提出了一个统一的框架，包括离线、在线和因果设置下的模型，用于研究鲁棒性、公平性和改进/因果关系。", "result": "概述了理论进展和实际解决方案，以构建鲁棒、公平和因果感知的激励感知ML系统。", "conclusion": "激励感知ML系统需要在设计时考虑到个体策略性行为的影响，以实现更公平、更鲁棒且能促进真正改进的算法决策。"}}
{"id": "2505.05262", "title": "Enhancing Cooperative Multi-Agent Reinforcement Learning with State Modelling and Adversarial Exploration", "authors": ["Andreas Kontogiannis", "Konstantinos Papathanasiou", "Yi Shen", "Giorgos Stamou", "Michael M. Zavlanos", "George Vouros"], "abstract": "Learning to cooperate in distributed partially observable environments with no communication abilities poses significant challenges for multi-agent deep reinforcement learning (MARL). This paper addresses key concerns in this domain, focusing on inferring state representations from individual agent observations and leveraging these representations to enhance agents' exploration and collaborative task execution policies. To this end, we propose a novel state modelling framework for cooperative MARL, where agents infer meaningful belief representations of the non-observable state, with respect to optimizing their own policies, while filtering redundant and less informative joint state information. Building upon this framework, we propose the MARL SMPE algorithm. In SMPE, agents enhance their own policy's discriminative abilities under partial observability, explicitly by incorporating their beliefs into the policy network, and implicitly by adopting an adversarial type of exploration policies which encourages agents to discover novel, high-value states while improving the discriminative abilities of others. Experimentally, we show that SMPE outperforms state-of-the-art MARL algorithms in complex fully cooperative tasks from the MPE, LBF, and RWARE benchmarks.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "Accepted (Poster) at ICML 2025", "pdf_url": "https://arxiv.org/pdf/2505.05262.pdf", "abstract_url": "https://arxiv.org/abs/2505.05262", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新颖的状态建模框架和MARL SMPE算法，用于在分布式部分可观察环境中增强多智能体深度强化学习的合作能力。通过推断非可观察状态的有意义信念表示，并结合对抗性探索策略，SMPE在复杂全合作任务中表现出色。", "motivation": "解决在无通信能力的分布式部分可观察环境中，多智能体深度强化学习（MARL）面临的合作学习挑战。", "method": "提出状态建模框架和MARL SMPE算法，包括推断非可观察状态的信念表示和采用对抗性探索策略。", "result": "SMPE在MPE、LBF和RWARE基准测试中的复杂全合作任务上优于现有最先进的MARL算法。", "conclusion": "通过状态建模和对抗性探索，SMPE有效提升了多智能体在部分可观察环境中的合作能力和任务执行效率。"}}
{"id": "2505.05283", "title": "Software Development Life Cycle Perspective: A Survey of Benchmarks for CodeLLMs and Agents", "authors": ["Kaixin Wang", "Tianlin Li", "Xiaoyu Zhang", "Chong Wang", "Weisong Sun", "Yang Liu", "Bin Shi"], "abstract": "Code large language models (CodeLLMs) and agents have shown great promise in tackling complex software engineering", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.05283.pdf", "abstract_url": "https://arxiv.org/abs/2505.05283", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文调查了代码大型语言模型（CodeLLMs）和代理在软件开发生命周期视角下的基准测试，展示了它们在解决复杂软件工程问题上的巨大潜力。", "motivation": "探讨CodeLLMs和代理在软件工程领域的应用潜力，以及如何通过基准测试评估它们的性能。", "method": "采用调查方法，收集和分析现有的CodeLLMs和代理在软件开发生命周期各阶段的基准测试。", "result": "CodeLLMs和代理在解决复杂软件工程问题方面显示出巨大的潜力，但需要更多的基准测试来全面评估它们的性能。", "conclusion": "CodeLLMs和代理在软件工程领域具有重要应用前景，未来的研究应关注开发更全面的基准测试以促进这一领域的发展。"}}
