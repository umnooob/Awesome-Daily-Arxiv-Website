{"id": "2506.08403", "title": "TACTIC: Translation Agents with Cognitive-Theoretic Interactive Collaboration", "authors": ["Weiya Li", "Junjie Chen", "Bei Li", "Boyang Liu", "Zichen Wen", "Nuanqiao Shan", "Xiaoqian Liu", "Anping Liu", "Huajie Liu", "Youyan Wang", "Wujiuge Yin", "Hu Song", "Bing Huang", "Zhiyuan Xia", "Jialiang Chen", "Linfeng Zhang"], "abstract": "Machine translation has long been a central task in natural language processing. With the rapid advancement of large language models (LLMs), there has been remarkable progress in translation quality. However, fully realizing the translation potential of LLMs remains an open challenge. Recent studies have explored multi-agent systems to decompose complex translation tasks into collaborative subtasks, showing initial promise in enhancing translation quality through agent cooperation and specialization. Nevertheless, existing multi-agent translation frameworks largely neglect foundational insights from cognitive translation studies. These insights emphasize how human translators employ different cognitive strategies, such as balancing literal and free translation, refining expressions based on context, and iteratively evaluating outputs. To address this limitation, we propose a cognitively informed multi-agent framework called TACTIC, which stands for T ranslation A gents with Cognitive- T heoretic Interactive Collaboration. The framework comprises six functionally distinct agents that mirror key cognitive processes observed in human translation behavior. These include agents for drafting, refinement, evaluation, scoring, context reasoning, and external knowledge gathering. By simulating an interactive and theory-grounded translation workflow, TACTIC effectively leverages the full capacity of LLMs for high-quality translation. Experimental results on diverse language pairs from the FLORES-200 and WMT24 benchmarks show that our method consistently achieves state-of-the-art performance. Using DeepSeek-V3 as the base model, TACTIC surpasses GPT-4.1 by an average of +0.6 XCOMET and +1.18 COMETKIWI-23. Compared to DeepSeek-R1, it further improves by +0.84 XCOMET and +2.99 COMETKIWI-23. Code is available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2506.08403.pdf", "abstract_url": "https://arxiv.org/abs/2506.08403", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "TACTIC是一个认知理论指导的多智能体翻译框架，通过模拟人类翻译的认知过程，提升大型语言模型在翻译任务中的表现。", "motivation": "解决现有多智能体翻译框架忽视认知翻译研究基础洞察的问题，以更接近人类翻译的方式提升翻译质量。", "method": "提出TACTIC框架，包含六个功能不同的智能体，分别负责起草、精炼、评估、评分、上下文推理和外部知识收集，模拟人类翻译的认知过程。", "result": "在FLORES-200和WMT24基准测试的多种语言对上，TACTIC consistently achieves state-of-the-art performance, surpassing GPT-4.1 and DeepSeek-R1 in XCOMET and COMETKIWI-23 scores.", "conclusion": "TACTIC通过认知理论指导的多智能体协作，有效释放了大型语言模型在翻译任务中的潜力，实现了高质量的翻译输出。"}}
{"id": "2506.08364", "title": "CC-RAG: Structured Multi-Hop Reasoning via Theme-Based Causal Graphs", "authors": ["Jash Rajesh Parekh", "Pengcheng Jiang", "Jiawei Han"], "abstract": "Understanding cause and effect relationships remains a formidable challenge for Large Language Models (LLMs), particularly in specialized domains where reasoning requires more than surface-level correlations. Retrieval-Augmented Generation (RAG) improves factual accuracy, but standard RAG pipelines treat evidence as flat context, lacking the structure required to model true causal dependencies. We introduce Causal-Chain RAG (CC-RAG), a novel approach that integrates zero-shot triple extraction and theme-aware graph chaining into the RAG pipeline, enabling structured multi-hop inference. Given a domain specific corpus, CC-RAG constructs a Directed Acyclic Graph (DAG) of <cause, relation, effect> triples and uses forward/backward chaining to guide structured answer generation. Experiments on two real-world domains: Bitcoin price fluctuations and Gaucher disease, show that CC-RAG outperforms standard RAG and zero-shot LLMs in chain similarity, information density, and lexical diversity. Both LLM-as-a-Judge and human evaluations consistently favor CC-RAG. Our results demonstrate that explicitly modeling causal structure enables LLMs to generate more accurate and interpretable responses, especially in specialized domains where flat retrieval fails.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.08364.pdf", "abstract_url": "https://arxiv.org/abs/2506.08364", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "CC-RAG是一种新颖的方法，通过零样本三元组提取和主题感知图链技术增强RAG管道，支持结构化多跳推理，专门解决大型语言模型在专业领域中因果推理的挑战。", "motivation": "解决大型语言模型（LLMs）在专业领域中理解和推理因果关系时面临的挑战，特别是在需要超越表面相关性的深度推理场景中。", "method": "结合零样本三元组提取和主题感知图链技术到RAG管道中，构建<原因, 关系, 结果>的有向无环图（DAG），并通过前向/后向链引导结构化答案生成。", "result": "在比特币价格波动和高雪氏病两个真实世界领域的实验中，CC-RAG在链相似性、信息密度和词汇多样性方面优于标准RAG和零样本LLMs。LLM-as-a-Judge和人类评估一致倾向于CC-RAG。", "conclusion": "明确建模因果结构使LLMs能够生成更准确和可解释的响应，特别是在平面检索失败的专业领域中。"}}
{"id": "2506.08136", "title": "EconWebArena: Benchmarking Autonomous Agents on Economic Tasks in Realistic Web Environments", "authors": ["Zefang Liu", "Yinzhu Quan"], "abstract": "We introduce EconWebArena, a benchmark for evaluating autonomous agents on complex, multimodal economic tasks in realistic web environments. The benchmark comprises 360 curated tasks from 82 authoritative websites spanning domains such as macroeconomics, labor, finance, trade, and public policy. Each task challenges agents to navigate live websites, interpret structured and visual content, interact with real interfaces, and extract precise, time-sensitive data through multi-step workflows. We construct the benchmark by prompting multiple large language models (LLMs) to generate candidate tasks, followed by rigorous human curation to ensure clarity, feasibility, and source reliability. Unlike prior work, EconWebArena emphasizes fidelity to authoritative data sources and the need for grounded web-based economic reasoning. We evaluate a diverse set of state-of-the-art multimodal LLMs as web agents, analyze failure cases, and conduct ablation studies to assess the impact of visual grounding, plan-based reasoning, and interaction design. Our results reveal substantial performance gaps and highlight persistent challenges in grounding, navigation, and multimodal understanding, positioning EconWebArena as a rigorous testbed for economic web intelligence.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.08136.pdf", "abstract_url": "https://arxiv.org/abs/2506.08136", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "EconWebArena是一个评估自主代理在真实网络环境中执行复杂、多模态经济任务能力的基准测试。它包含360个精选任务，覆盖宏观经济、劳动力、金融等多个领域，要求代理导航实时网站、解释内容并与界面互动。通过LLMs生成任务并经过人工筛选确保质量，该基准强调权威数据源和基于网络的经济推理。评估显示，现有技术在接地、导航和多模态理解方面存在显著挑战。", "motivation": "解决现有基准在评估自主代理处理复杂经济任务时缺乏真实网络环境和权威数据源的问题。", "method": "通过大型语言模型(LLMs)生成候选任务，并经过严格的人工筛选，构建包含360个任务的基准。评估多模态LLMs作为网络代理的性能，分析失败案例，并进行消融研究。", "result": "评估揭示了在多模态理解、导航和接地方面的显著性能差距和持续挑战。", "conclusion": "EconWebArena为经济网络智能提供了一个严格的测试平台，突出了当前技术在处理复杂经济任务时的局限性。"}}
{"id": "2506.08430", "title": "CAF-I: A Collaborative Multi-Agent Framework for Enhanced Irony Detection with Large Language Models", "authors": ["Ziqi.Liu", "Ziyang.Zhou", "Mingxuan.Hu"], "abstract": "Large language model (LLM) have become mainstream methods in the field of sarcasm detection. However, existing LLM methods face challenges in irony detection, including: 1. single-perspective limitations, 2. insufficient comprehensive understanding, and 3. lack of interpretability. This paper introduces the Collaborative Agent Framework for Irony (CAF-I), an LLM-driven multi-agent system designed to overcome these issues. CAF-I employs specialized agents for Context, Semantics, and Rhetoric, which perform multidimensional analysis and engage in interactive collaborative optimization. A Decision Agent then consolidates these perspectives, with a Refinement Evaluator Agent providing conditional feedback for optimization. Experiments on benchmark datasets establish CAF-I's state-of-the-art zero-shot performance. Achieving SOTA on the vast majority of metrics, CAF-I reaches an average Macro-F1 of 76.31, a 4.98 absolute improvement over the strongest prior baseline. This success is attained by its effective simulation of human-like multi-perspective analysis, enhancing detection accuracy and interpretability.", "subjects": "Computation and Language (cs.CL); Multiagent Systems (cs.MA)", "comments": "ICML 2025 Workshop on Collaborative and Federated Agentic Workflows", "pdf_url": "https://arxiv.org/pdf/2506.08430.pdf", "abstract_url": "https://arxiv.org/abs/2506.08430", "categories": ["Computation and Language (cs.CL)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了CAF-I，一个基于大型语言模型的多代理系统，旨在通过多维分析和交互协作优化来提高反语检测的准确性和可解释性。", "motivation": "解决现有大型语言模型在反语检测中面临的单视角限制、理解不全面和缺乏可解释性等问题。", "method": "采用专门化的代理（Context、Semantics、Rhetoric）进行多维分析，并通过决策代理和细化评估代理进行协作优化。", "result": "在基准数据集上，CAF-I实现了零射击的最先进性能，平均Macro-F1达到76.31，比之前最强的基线提高了4.98。", "conclusion": "CAF-I通过模拟人类多视角分析，有效提高了反语检测的准确性和可解释性，为相关领域的研究提供了新的方向。"}}
{"id": "2506.08479", "title": "Efficient Context Selection for Long-Context QA: No Tuning, No Iteration, Just Adaptive-$k$", "authors": ["Chihiro Taguchi", "Seiji Maekawa", "Nikita Bhutani"], "abstract": "Retrieval-augmented generation (RAG) and long-context language models (LCLMs) both address context limitations of LLMs in open-domain question answering (QA). However, optimal external context to retrieve remains an open problem: fixing the retrieval size risks either wasting tokens or omitting key evidence. Existing adaptive methods like Self-RAG and Self-Route rely on iterative LLM prompting and perform well on factoid QA, but struggle with aggregation QA, where the optimal context size is both unknown and variable. We present Adaptive-$k$ retrieval, a simple and effective single-pass method that adaptively selects the number of passages based on the distribution of the similarity scores between the query and the candidate passages. It does not require model fine-tuning, extra LLM inferences or changes to existing retriever-reader pipelines. On both factoid and aggregation QA benchmarks, Adaptive-$k$ matches or outperforms fixed-$k$ baselines while using up to 10x fewer tokens than full-context input, yet still retrieves 70% of relevant passages. It improves accuracy across five LCLMs and two embedding models, highlighting that dynamically adjusting context size leads to more efficient and accurate QA.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": "26 pages, 16 tables, 5 figures", "pdf_url": "https://arxiv.org/pdf/2506.08479.pdf", "abstract_url": "https://arxiv.org/abs/2506.08479", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种名为Adaptive-$k$检索的简单有效方法，用于在长上下文问答中自适应选择外部上下文的数量，无需模型微调或额外LLM推理，显著提高了问答的效率和准确性。", "motivation": "解决在开放领域问答中，如何最优地选择外部上下文的问题，避免固定检索大小导致的令牌浪费或关键证据遗漏。", "method": "提出Adaptive-$k$检索方法，基于查询与候选段落相似性分数的分布，自适应选择段落数量，无需模型微调或额外LLM推理。", "result": "在事实性和聚合性问答基准测试中，Adaptive-$k$匹配或优于固定-$k$基线，同时使用的令牌数量比全上下文输入少10倍，且仍检索到70%的相关段落。", "conclusion": "动态调整上下文大小可以带来更高效和准确的问答，Adaptive-$k$方法在多种LCLMs和嵌入模型中均提高了准确性。"}}
{"id": "2506.08500", "title": "DRAGged into Conflicts: Detecting and Addressing Conflicting Sources in Search-Augmented LLMs", "authors": ["Arie Cattan", "Alon Jacovi", "Ori Ram", "Jonathan Herzig", "Roee Aharoni", "Sasha Goldshtein", "Eran Ofek", "Idan Szpektor", "Avi Caciularu"], "abstract": "Retrieval Augmented Generation (RAG) is a commonly used approach for enhancing large language models (LLMs) with relevant and up-to-date information. However, the retrieved sources can often contain conflicting information and it remains unclear how models should address such discrepancies. In this work, we first propose a novel taxonomy of knowledge conflict types in RAG, along with the desired model behavior for each type. We then introduce CONFLICTS, a high-quality benchmark with expert annotations of conflict types in a realistic RAG setting. CONFLICTS is the first benchmark that enables tracking progress on how models address a wide range of knowledge conflicts. We conduct extensive experiments on this benchmark, showing that LLMs often struggle to appropriately resolve conflicts between sources. While prompting LLMs to explicitly reason about the potential conflict in the retrieved documents significantly improves the quality and appropriateness of their responses, substantial room for improvement in future research remains.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.08500.pdf", "abstract_url": "https://arxiv.org/abs/2506.08500", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种新颖的检索增强生成（RAG）中知识冲突类型的分类法，并介绍了CONFLICTS基准测试，用于评估模型如何处理这些冲突。实验表明，大型语言模型（LLMs）在解决源间冲突时常遇到困难，但通过提示模型明确推理潜在冲突可显著改善其响应质量。", "motivation": "检索增强生成（RAG）是增强大型语言模型（LLMs）相关性和时效性信息的常用方法，但检索到的源常包含冲突信息，模型应如何处理这些冲突尚不明确。", "method": "提出了一种新颖的知识冲突类型分类法及每种类型的理想模型行为，并引入了CONFLICTS基准测试，该测试包含专家在现实RAG设置中对冲突类型的注释。", "result": "实验显示，LLMs在解决源间冲突时常遇到困难，但通过提示模型明确推理潜在冲突可显著改善其响应质量。", "conclusion": "尽管通过明确推理冲突可以改善LLMs的响应，但在未来研究中仍有很大的改进空间。"}}
{"id": "2506.08726", "title": "Improved LLM Agents for Financial Document Question Answering", "authors": ["Nelvin Tan", "Zian Seng", "Liang Zhang", "Yu-Ching Shih", "Dong Yang", "Amol Salunkhe"], "abstract": "Large language models (LLMs) have shown impressive capabilities on numerous natural language processing tasks. However, LLMs still struggle with numerical question answering for financial documents that include tabular and textual data. Recent works have showed the effectiveness of critic agents (i.e., self-correction) for this task given oracle labels. Building upon this framework, this paper examines the effectiveness of the traditional critic agent when oracle labels are not available, and show, through experiments, that this critic agent's performance deteriorates in this scenario. With this in mind, we present an improved critic agent, along with the calculator agent which outperforms the previous state-of-the-art approach (program-of-thought) and is safer. Furthermore, we investigate how our agents interact with each other, and how this interaction affects their performance.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "12 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2506.08726.pdf", "abstract_url": "https://arxiv.org/abs/2506.08726", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了大型语言模型（LLMs）在金融文档问答任务中的表现，特别是在没有Oracle标签的情况下传统批评代理的性能下降问题，并提出了一种改进的批评代理和计算器代理，这些新方法在性能上超越了现有技术（程序思维）且更为安全。", "motivation": "解决LLMs在处理包含表格和文本数据的金融文档数值问答任务时的困难，特别是在缺乏Oracle标签的情况下传统批评代理性能下降的问题。", "method": "提出了一种改进的批评代理和计算器代理，通过实验评估这些新方法在没有Oracle标签的情况下的性能，并研究代理间互动对性能的影响。", "result": "改进的批评代理和计算器代理在没有Oracle标签的情况下，性能优于现有的程序思维方法，并且更为安全。", "conclusion": "研究表明，改进的代理方法在金融文档问答任务中有效，特别是在缺乏Oracle支持的情况下，为未来的研究提供了新的方向。"}}
{"id": "2506.08938", "title": "FaithfulRAG: Fact-Level Conflict Modeling for Context-Faithful Retrieval-Augmented Generation", "authors": ["Qinggang Zhang", "Zhishang Xiang", "Yilin Xiao", "Le Wang", "Junhui Li", "Xinrun Wang", "Jinsong Su"], "abstract": "Large language models (LLMs) augmented with retrieval systems have demonstrated significant potential in handling knowledge-intensive tasks. However, these models often struggle with unfaithfulness issues, generating outputs that either ignore the retrieved context or inconsistently blend it with the LLM`s parametric knowledge. This issue is particularly severe in cases of knowledge conflict, where the retrieved context conflicts with the model`s parametric knowledge. While existing faithful RAG approaches enforce strict context adherence through well-designed prompts or modified decoding strategies, our analysis reveals a critical limitation: they achieve faithfulness by forcibly suppressing the model`s parametric knowledge, which undermines the model`s internal knowledge structure and increases the risk of misinterpreting the context. To this end, this paper proposes FaithfulRAG, a novel framework that resolves knowledge conflicts by explicitly modeling discrepancies between the model`s parametric knowledge and retrieved context. Specifically, FaithfulRAG identifies conflicting knowledge at the fact level and designs a self-thinking process, allowing LLMs to reason about and integrate conflicting facts before generating responses. Extensive experiments demonstrate that our method outperforms state-of-the-art methods. The code is available at https://", "subjects": "Computation and Language (cs.CL)", "comments": "Qinggang Zhang and Zhishang Xiang contributed equally to this work. Corresponding author: Jinsong Su", "pdf_url": "https://arxiv.org/pdf/2506.08938.pdf", "abstract_url": "https://arxiv.org/abs/2506.08938", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "FaithfulRAG是一个新颖的框架，旨在解决检索增强生成（RAG）中的不忠实问题，特别是在知识冲突的情况下。它通过在事实级别上明确建模模型参数知识与检索上下文之间的差异，并通过自我思考过程来整合冲突事实，从而生成更忠实的响应。", "motivation": "大型语言模型（LLMs）与检索系统结合在处理知识密集型任务时显示出巨大潜力，但在知识冲突情况下，模型往往会产生忽略检索上下文或不一致地混合其参数知识的输出，导致不忠实问题。", "method": "FaithfulRAG通过在事实级别上识别冲突知识，并设计一个自我思考过程，允许LLMs在生成响应之前对冲突事实进行推理和整合。", "result": "大量实验证明，FaithfulRAG在解决知识冲突和生成忠实响应方面优于现有最先进的方法。", "conclusion": "FaithfulRAG通过明确建模和整合冲突知识，不仅提高了生成的忠实性，还保持了模型内部知识结构的完整性，为检索增强生成领域提供了新的解决方案。"}}
{"id": "2506.08972", "title": "Atomic-to-Compositional Generalization for Mobile Agents with A New Benchmark and Scheduling System", "authors": ["Yuan Guo", "Tingjia Miao", "Zheng Wu", "Pengzhou Cheng", "Ming Zhou", "Zhuosheng Zhang"], "abstract": "Autonomous agents powered by multimodal large language models have been developed to facilitate task execution on mobile devices. However, prior work has predominantly focused on atomic tasks -- such as shot-chain execution tasks and single-screen grounding tasks -- while overlooking the generalization to compositional tasks, which are indispensable for real-world applications. This work introduces UI-NEXUS, a comprehensive benchmark designed to evaluate mobile agents on three categories of compositional operations: Simple Concatenation, Context Transition, and Deep Dive. UI-NEXUS supports interactive evaluation in 20 fully controllable local utility app environments, as well as 30 online Chinese and English service apps. It comprises 100 interactive task templates with an average optimal step count of 14.05. Experimental results across a range of mobile agents with agentic workflow or agent-as-a-model show that UI-NEXUS presents significant challenges. Specifically, existing agents generally struggle to balance performance and efficiency, exhibiting representative failure modes such as under-execution, over-execution, and attention drift, causing visible atomic-to-compositional generalization gap. Inspired by these findings, we propose AGENT-NEXUS, a lightweight and efficient scheduling system to tackle compositional mobile tasks. AGENT-NEXUS extrapolates the abilities of existing mobile agents by dynamically decomposing long-horizon tasks to a series of self-contained atomic subtasks. AGENT-NEXUS achieves 24% to 40% task success rate improvement for existing mobile agents on compositional operation tasks within the UI-NEXUS benchmark without significantly sacrificing inference overhead. The demo video, dataset, and code are available on the project page at", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.08972.pdf", "abstract_url": "https://arxiv.org/abs/2506.08972", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了UI-NEXUS基准测试和AGENT-NEXUS调度系统，旨在评估和改进移动代理在组合任务上的表现，填补了现有研究在原子任务到组合任务泛化能力上的空白。", "motivation": "现有的移动代理主要关注原子任务，而忽视了组合任务的泛化能力，这在现实应用中是不可或缺的。", "method": "提出了UI-NEXUS基准测试来评估移动代理在三种组合操作上的表现，并开发了AGENT-NEXUS调度系统，通过动态分解长视野任务为自包含的原子子任务来提升性能。", "result": "实验显示，现有移动代理在组合任务上表现不佳，而AGENT-NEXUS在不显著增加推理开销的情况下，将任务成功率提高了24%至40%。", "conclusion": "UI-NEXUS和AGENT-NEXUS为移动代理在组合任务上的性能评估和改进提供了有效工具，显著提升了任务成功率。"}}
{"id": "2506.08140", "title": "AutoSDT: Scaling Data-Driven Discovery Tasks Toward Open Co-Scientists", "authors": ["Yifei Li", "Hanane Nour Moussa", "Ziru Chen", "Shijie Chen", "Botao Yu", "Mingyi Xue", "Benjamin Burns", "Tzu-Yao Chiu", "Vishal Dey", "Zitong Lu", "Chen Wei", "Qianheng Zhang", "Tianyu Zhang", "Song Gao", "Xuhui Huang", "Xia Ning", "Nesreen K. Ahmed", "Ali Payani", "Huan Sun"], "abstract": "Despite long-standing efforts in accelerating scientific discovery with AI, building AI co-scientists remains challenging due to limited high-quality data for training and evaluation. To tackle this data scarcity issue, we present AutoSDT, an automatic pipeline that collects high-quality coding tasks in real-world data-driven discovery workflows. AutoSDT leverages the coding capabilities and parametric knowledge of LLMs to search for diverse sources, select ecologically valid tasks, and synthesize accurate task instructions and code solutions. Using our pipeline, we construct AutoSDT-5K, a dataset of 5,404 coding tasks for data-driven discovery that covers four scientific disciplines and 756 unique Python packages. To the best of our knowledge, AutoSDT-5K is the only automatically collected and the largest open dataset for data-driven scientific discovery. Expert feedback on a subset of 256 tasks shows the effectiveness of AutoSDT: 93% of the collected tasks are ecologically valid, and 92.2% of the synthesized programs are functionally correct. Trained on AutoSDT-5K, the Qwen2.5-Coder-Instruct LLM series, dubbed AutoSDT-Coder, show substantial improvement on two challenging data-driven discovery benchmarks, ScienceAgentBench and DiscoveryBench. Most notably, AutoSDT-Coder-32B reaches the same level of performance as GPT-4o on ScienceAgentBench with a success rate of 7.8%, doubling the performance of its base model. On DiscoveryBench, it lifts the hypothesis matching score to 8.1, bringing a 17.4% relative improvement and closing the gap between open-weight models and GPT-4o.", "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.08140.pdf", "abstract_url": "https://arxiv.org/abs/2506.08140", "categories": ["Machine Learning (cs.LG)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "AutoSDT是一个自动化的流程，旨在解决AI辅助科学发现中的数据稀缺问题，通过构建AutoSDT-5K数据集，提高了数据驱动发现任务的性能。", "motivation": "解决AI辅助科学发现中高质量数据稀缺的问题，以促进AI共同科学家的发展。", "method": "利用大型语言模型（LLMs）的编码能力和参数知识，自动收集、选择生态有效的任务，并合成准确的任务指令和代码解决方案。", "result": "构建了AutoSDT-5K数据集，包含5,404个数据驱动发现任务，覆盖四个科学学科和756个独特的Python包。专家反馈显示，93%的任务生态有效，92.2%的合成程序功能正确。基于AutoSDT-5K训练的Qwen2.5-Coder-Instruct LLM系列在ScienceAgentBench和DiscoveryBench上表现显著提升。", "conclusion": "AutoSDT有效地解决了数据稀缺问题，通过自动收集高质量任务和代码解决方案，显著提升了数据驱动科学发现的性能，缩小了开源模型与GPT-4o之间的差距。"}}
{"id": "2506.08074", "title": "Hierarchical Lexical Graph for Enhanced Multi-Hop Retrieval", "authors": ["Abdellah Ghassel", "Ian Robinson", "Gabriel Tanase", "Hal Cooper", "Bryan Thompson", "Zhen Han", "Vassilis N. Ioannidis", "Soji Adeshina", "Huzefa Rangwala"], "abstract": "Retrieval-Augmented Generation (RAG) grounds large language models in external evidence, yet it still falters when answers must be pieced together across semantically distant documents. We close this gap with the Hierarchical Lexical Graph (HLG), a three-tier index that (i) traces every atomic proposition to its source, (ii) clusters propositions into latent topics, and (iii) links entities and relations to expose cross-document paths. On top of HLG we build two complementary, plug-and-play retrievers: StatementGraphRAG, which performs fine-grained entity-aware beam search over propositions for high-precision factoid questions, and TopicGraphRAG, which selects coarse topics before expanding along entity links to supply broad yet relevant context for exploratory queries. Additionally, existing benchmarks lack the complexity required to rigorously evaluate multi-hop summarization systems, often focusing on single-document queries or limited datasets. To address this, we introduce a synthetic dataset generation pipeline that curates realistic, multi-document question-answer pairs, enabling robust evaluation of multi-hop retrieval systems. Extensive experiments across five datasets demonstrate that our methods outperform naive chunk-based RAG achieving an average relative improvement of 23.1% in retrieval recall and correctness. Open-source Python library is available at", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "KDD '25", "pdf_url": "https://arxiv.org/pdf/2506.08074.pdf", "abstract_url": "https://arxiv.org/abs/2506.08074", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种名为层次化词汇图（HLG）的三层索引结构，旨在解决检索增强生成（RAG）在跨文档语义距离较远时答案拼接困难的问题。HLG通过追踪原子命题到其来源、将命题聚类成潜在主题、以及链接实体和关系来揭示跨文档路径。在此基础上，构建了两种互补的即插即用检索器：StatementGraphRAG和TopicGraphRAG，分别针对细粒度实体感知的高精度事实性问题和粗粒度主题的探索性查询。此外，为了严格评估多跳摘要系统，引入了一个合成数据集生成管道，用于策划现实的多文档问答对。在五个数据集上的广泛实验表明，该方法在检索召回率和正确性上平均相对提高了23.1%。", "motivation": "解决检索增强生成（RAG）在跨文档语义距离较远时答案拼接困难的问题。", "method": "提出层次化词汇图（HLG）的三层索引结构，并在此基础上构建了两种互补的即插即用检索器：StatementGraphRAG和TopicGraphRAG。", "result": "在五个数据集上的实验表明，该方法在检索召回率和正确性上平均相对提高了23.1%。", "conclusion": "HLG及其配套检索器有效提升了多跳检索的性能，为复杂问答和探索性查询提供了强有力的支持。"}}
{"id": "2506.08566", "title": "Generating Vision-Language Navigation Instructions Incorporated Fine-Grained Alignment Annotations", "authors": ["Yibo Cui", "Liang Xie", "Yu Zhao", "Jiawei Sun", "Erwei Yin"], "abstract": "Vision-Language Navigation (VLN) enables intelligent agents to navigate environments by integrating visual perception and natural language instructions, yet faces significant challenges due to the scarcity of fine-grained cross-modal alignment annotations. Existing datasets primarily focus on global instruction-trajectory matching, neglecting sub-instruction-level and entity-level alignments critical for accurate navigation action decision-making. To address this limitation, we propose FCA-NIG, a generative framework that automatically constructs navigation instructions with dual-level fine-grained cross-modal annotations. In this framework, an augmented trajectory is first divided into sub-trajectories, which are then processed through GLIP-based landmark detection, crafted instruction construction, OFA-Speaker based R2R-like instruction generation, and CLIP-powered entity selection, generating sub-instruction-trajectory pairs with entity-landmark annotations. Finally, these sub-pairs are aggregated to form a complete instruction-trajectory pair. The framework generates the FCA-R2R dataset, the first large-scale augmentation dataset featuring precise sub-instruction-sub-trajectory and entity-landmark alignments. Extensive experiments demonstrate that training with FCA-R2R significantly improves the performance of multiple state-of-the-art VLN agents, including SF, EnvDrop, RecBERT, and HAMT. Incorporating sub-instruction-trajectory alignment enhances agents' state awareness and decision accuracy, while entity-landmark alignment further boosts navigation performance and generalization. These results highlight the effectiveness of FCA-NIG in generating high-quality, scalable training data without manual annotation, advancing fine-grained cross-modal learning in complex navigation tasks.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.08566.pdf", "abstract_url": "https://arxiv.org/abs/2506.08566", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为FCA-NIG的生成框架，旨在自动构建包含细粒度跨模态注释的导航指令，以解决视觉语言导航（VLN）中细粒度跨模态对齐注释稀缺的问题。通过该框架生成的FCA-R2R数据集显著提升了多种先进VLN代理的性能。", "motivation": "视觉语言导航（VLN）面临的主要挑战是由于缺乏细粒度的跨模态对齐注释，这限制了导航动作决策的准确性。现有的数据集主要关注全局指令-轨迹匹配，忽视了子指令级别和实体级别的对齐。", "method": "提出的FCA-NIG框架通过增强轨迹分割、基于GLIP的地标检测、精心设计的指令构建、基于OFA-Speaker的R2R类指令生成和基于CLIP的实体选择，生成带有实体-地标注释的子指令-轨迹对，最终聚合形成完整的指令-轨迹对。", "result": "实验表明，使用FCA-R2R数据集训练显著提高了包括SF、EnvDrop、RecBERT和HAMT在内的多种最先进VLN代理的性能。子指令-轨迹对齐增强了代理的状态感知和决策准确性，而实体-地标对齐进一步提升了导航性能和泛化能力。", "conclusion": "FCA-NIG框架无需手动注释即可生成高质量、可扩展的训练数据，推动了复杂导航任务中细粒度跨模态学习的进展。"}}
{"id": "2506.08292", "title": "From Debate to Equilibrium: Belief-Driven Multi-Agent LLM Reasoning via Bayesian Nash Equilibrium", "authors": ["Xie Yi", "Zhanke Zhou", "Chentao Cao", "Qiyu Niu", "Tongliang Liu", "Bo Han"], "abstract": "Multi-agent frameworks can substantially boost the reasoning power of large language models (LLMs), but they typically incur heavy computational costs and lack convergence guarantees. To overcome these challenges, we recast multi-LLM coordination as an incomplete-information game and seek a Bayesian Nash equilibrium (BNE), in which each agent optimally responds to its probabilistic beliefs about the strategies of others. We introduce Efficient Coordination via Nash Equilibrium (ECON), a hierarchical reinforcement-learning paradigm that marries distributed reasoning with centralized final output. Under ECON, each LLM independently selects responses that maximize its expected reward, conditioned on its beliefs about co-agents, without requiring costly inter-agent exchanges. We mathematically prove that ECON attains a markedly tighter regret bound than non-equilibrium multi-agent schemes. Empirically, ECON outperforms existing multi-LLM approaches by 11.2% on average across six benchmarks spanning complex reasoning and planning tasks. Further experiments demonstrate ECON's ability to flexibly incorporate additional models, confirming its scalability and paving the way toward larger, more powerful multi-LLM ensembles. The code is publicly available at:", "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL)", "comments": "Accepted by ICML 2025", "pdf_url": "https://arxiv.org/pdf/2506.08292.pdf", "abstract_url": "https://arxiv.org/abs/2506.08292", "categories": ["Machine Learning (cs.LG)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为ECON的高效协调框架，通过贝叶斯纳什均衡（BNE）解决多智能体大型语言模型（LLM）协调中的高计算成本和缺乏收敛保证的问题。ECON结合了分布式推理和集中式最终输出，无需昂贵的智能体间交换，显著提高了性能。", "motivation": "多智能体框架虽能大幅提升大型语言模型的推理能力，但通常伴随高计算成本和缺乏收敛保证的问题。本文旨在克服这些挑战。", "method": "将多LLM协调重新定义为不完全信息博弈，寻求贝叶斯纳什均衡（BNE），并引入ECON框架，该框架结合了分布式推理和集中式最终输出，每个LLM根据对其他智能体策略的概率信念独立选择最优响应。", "result": "ECON在数学上证明了比非均衡多智能体方案具有更紧的遗憾界限。在六个涵盖复杂推理和规划任务的基准测试中，ECON平均 outperforms 现有方法11.2%。", "conclusion": "ECON不仅提高了多LLM协调的效率和性能，还展示了灵活整合额外模型的能力，为更大、更强大的多LLM集成铺平了道路。"}}
{"id": "2506.08295", "title": "From Passive to Active Reasoning: Can Large Language Models Ask the Right Questions under Incomplete Information?", "authors": ["Zhanke Zhou", "Xiao Feng", "Zhaocheng Zhu", "Jiangchao Yao", "Sanmi Koyejo", "Bo Han"], "abstract": "While existing benchmarks probe the reasoning abilities of large language models (LLMs) across diverse domains, they predominantly assess passive reasoning, providing models with all the information needed to reach a solution. By contrast, active reasoning-where an LLM must interact with external systems to acquire missing evidence or data-has received little systematic attention. To address this shortfall, we present AR-Bench, a novel benchmark designed explicitly to evaluate an LLM's active reasoning skills. AR-Bench comprises three task families-detective cases, situation puzzles, and guessing numbers-that together simulate real-world, agentic scenarios and measure performance across commonsense, logical, and symbolic reasoning challenges. Empirical evaluation on AR-Bench demonstrates that contemporary LLMs exhibit pronounced difficulties with active reasoning: they frequently fail to acquire or leverage the information needed to solve tasks. This gap highlights a stark divergence between their passive and active reasoning abilities. Moreover, ablation studies indicate that even advanced strategies, such as tree-based searching or post-training approaches, yield only modest gains and fall short of the levels required for real-world deployment. Collectively, these findings highlight the critical need to advance methodology for active reasoning, e.g., incorporating interactive learning, real-time feedback loops, and environment-aware objectives for training. The benchmark is publicly available at:", "subjects": "Machine Learning (cs.LG); Computation and Language (cs.CL)", "comments": "Accepted by ICML 2025", "pdf_url": "https://arxiv.org/pdf/2506.08295.pdf", "abstract_url": "https://arxiv.org/abs/2506.08295", "categories": ["Machine Learning (cs.LG)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了AR-Bench，一个专门设计用于评估大型语言模型（LLMs）主动推理能力的新基准。通过三个任务家族模拟现实世界中的代理场景，研究发现当代LLMs在主动推理方面存在显著困难，强调了推进主动推理方法学的必要性。", "motivation": "现有基准主要评估大型语言模型的被动推理能力，而主动推理——即模型需要与外部系统交互以获取缺失信息的能力——尚未得到系统性的关注。本文旨在填补这一空白。", "method": "提出了AR-Bench基准，包含侦探案件、情境谜题和猜数字三个任务家族，用于评估LLMs在常识、逻辑和符号推理挑战中的主动推理能力。", "result": "实证评估显示，当代LLMs在主动推理方面表现不佳，难以获取或利用必要信息解决问题。即使采用高级策略，如基于树的搜索或后训练方法，改进也有限。", "conclusion": "研究结果强调了推进主动推理方法学的紧迫性，建议融入交互式学习、实时反馈循环和环境感知目标等策略。AR-Bench基准已公开提供。"}}
{"id": "2506.08379", "title": "Reinforce LLM Reasoning through Multi-Agent Reflection", "authors": ["Yurun Yuan", "Tengyang Xie"], "abstract": "Leveraging more test-time computation has proven to be an effective way to boost the reasoning capabilities of large language models (LLMs). Among various methods, the verify-and-improve paradigm stands out for enabling dynamic solution exploration and feedback incorporation. However, existing approaches often suffer from restricted feedback spaces and lack of coordinated training of different parties, leading to suboptimal performance. To address this, we model this multi-turn refinement process as a Markov Decision Process and introduce DPSDP (Direct Policy Search by Dynamic Programming), a reinforcement learning algorithm that trains an actor-critic LLM system to iteratively refine answers via direct preference learning on self-generated data. Theoretically, DPSDP can match the performance of any policy within the training distribution. Empirically, we instantiate DPSDP with various base models and show improvements on both in- and out-of-distribution benchmarks. For example, on benchmark MATH 500, majority voting over five refinement steps increases first-turn accuracy from 58.2% to 63.2% with Ministral-based models. An ablation study further confirms the benefits of multi-agent collaboration and out-of-distribution generalization.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "International Conference on Machine Learning (ICML), 2025", "pdf_url": "https://arxiv.org/pdf/2506.08379.pdf", "abstract_url": "https://arxiv.org/abs/2506.08379", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为DPSDP的强化学习算法，通过多智能体反思来增强大型语言模型（LLMs）的推理能力。该方法将多轮精炼过程建模为马尔可夫决策过程，并通过直接偏好学习自我生成的数据来训练一个演员-评论家LLM系统，以迭代地改进答案。理论和实证结果表明，DPSDP能够提高模型在分布内和分布外基准上的性能。", "motivation": "现有的验证和改进方法在动态解决方案探索和反馈整合方面表现出色，但受限于反馈空间的限制和不同部分之间缺乏协调训练，导致性能不佳。本文旨在解决这些问题，通过多智能体协作和强化学习来优化LLMs的推理能力。", "method": "本文提出DPSDP（通过动态规划的直接策略搜索），这是一种强化学习算法，它将多轮精炼过程建模为马尔可夫决策过程，并训练一个演员-评论家LLM系统，通过直接偏好学习自我生成的数据来迭代地改进答案。", "result": "实证结果显示，DPSDP能够显著提高模型在分布内和分布外基准上的性能。例如，在MATH 500基准测试中，基于Ministral的模型通过五次精炼步骤的多数投票，将首轮准确率从58.2%提高到63.2%。消融研究进一步证实了多智能体协作和分布外泛化的好处。", "conclusion": "本文提出的DPSDP算法通过多智能体反思和强化学习，有效地提升了LLMs的推理能力。理论和实证结果均表明，该方法在提高模型性能方面具有显著优势，特别是在多智能体协作和分布外泛化方面。"}}
{"id": "2506.08633", "title": "Approaching Dialogue State Tracking via Aligning Speech Encoders and LLMs", "authors": ["Šimon Sedláček", "Bolaji Yusuf", "Ján Švec", "Pradyoth Hegde", "Santosh Kesiraju", "Oldřich Plchot", "Jan Černocký"], "abstract": "In this work, we approach spoken Dialogue State Tracking (DST) by bridging the representation spaces of speech encoders and LLMs via a small connector module, with a focus on fully open-sourced and open-data components (WavLM-large, OLMo). We focus on ablating different aspects of such systems including full/LoRA adapter fine-tuning, the effect of agent turns in the dialogue history, as well as fuzzy matching-based output post-processing, which greatly improves performance of our systems on named entities in the dialogue slot values. We conduct our experiments on the SpokenWOZ dataset, and additionally utilize the Speech-Aware MultiWOZ dataset to augment our training data. Ultimately, our best-performing WavLM + connector + OLMo-1B aligned models achieve state of the art on the SpokenWOZ test set (34.66% JGA), and our system with Gemma-2-9B-instruct further surpasses this result, reaching 42.17% JGA on SpokenWOZ test.", "subjects": "Audio and Speech Processing (eess.AS); Computation and Language (cs.CL)", "comments": "Accepted to Interspeech 2025", "pdf_url": "https://arxiv.org/pdf/2506.08633.pdf", "abstract_url": "https://arxiv.org/abs/2506.08633", "categories": ["Audio and Speech Processing (eess.AS)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过连接语音编码器和大型语言模型（LLMs）的表示空间，采用小型连接模块，专注于完全开源和开放数据的组件（WavLM-large, OLMo），来解决口语对话状态跟踪（DST）问题。", "motivation": "解决口语对话状态跟踪（DST）中的表示空间不匹配问题，通过桥接语音编码器和LLMs的表示空间，提高系统性能。", "method": "使用小型连接模块桥接语音编码器和LLMs的表示空间，研究包括全/LoRA适配器微调、对话历史中代理轮次的影响，以及基于模糊匹配的输出后处理。", "result": "在SpokenWOZ测试集上，最佳性能的WavLM + 连接器 + OLMo-1B对齐模型达到了34.66%的JGA，而使用Gemma-2-9B-instruct的系统进一步超越了这一结果，达到了42.17%的JGA。", "conclusion": "通过桥接语音编码器和LLMs的表示空间，可以有效提升口语对话状态跟踪的性能，特别是在命名实体的对话槽值中，模糊匹配后处理显著提高了系统性能。"}}
{"id": "2506.08098", "title": "Cognitive Weave: Synthesizing Abstracted Knowledge with a Spatio-Temporal Resonance Graph", "authors": ["Akash Vishwakarma", "Hojin Lee", "Mohith Suresh", "Priyam Shankar Sharma", "Rahul Vishwakarma", "Sparsh Gupta", "Yuvraj Anupam Chauhan"], "abstract": "The emergence of capable large language model (LLM) based agents necessitates memory architectures that transcend mere data storage, enabling continuous learning, nuanced reasoning, and dynamic adaptation. Current memory systems often grapple with fundamental limitations in structural flexibility, temporal awareness, and the ability to synthesize higher-level insights from raw interaction data. This paper introduces Cognitive Weave, a novel memory framework centered around a multi-layered spatio-temporal resonance graph (STRG). This graph manages information as semantically rich insight particles (IPs), which are dynamically enriched with resonance keys, signifiers, and situational imprints via a dedicated semantic oracle interface (SOI). These IPs are interconnected through typed relational strands, forming an evolving knowledge tapestry. A key component of Cognitive Weave is the cognitive refinement process, an autonomous mechanism that includes the synthesis of insight aggregates (IAs) condensed, higher-level knowledge structures derived from identified clusters of related IPs. We present comprehensive experimental results demonstrating Cognitive Weave's marked enhancement over existing approaches in long-horizon planning tasks, evolving question-answering scenarios, and multi-session dialogue coherence. The system achieves a notable 34% average improvement in task completion rates and a 42% reduction in mean query latency when compared to state-of-the-art baselines. Furthermore, this paper explores the ethical considerations inherent in such advanced memory systems, discusses the implications for long-term memory in LLMs, and outlines promising future research trajectories.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.08098.pdf", "abstract_url": "https://arxiv.org/abs/2506.08098", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了Cognitive Weave，一种新颖的记忆框架，通过多层时空共振图（STRG）管理信息，实现连续学习、细腻推理和动态适应，显著提升了任务完成率和查询效率。", "motivation": "解决当前记忆系统在结构灵活性、时间感知能力以及从原始交互数据中合成高级洞察方面的基本限制。", "method": "采用多层时空共振图（STRG）管理信息，通过语义预言接口（SOI）动态丰富洞察粒子（IPs），并通过认知精炼过程自主合成洞察聚合（IAs）。", "result": "在长期规划任务、演进问答场景和多会话对话连贯性方面，Cognitive Weave比现有方法平均提高了34%的任务完成率，并减少了42%的平均查询延迟。", "conclusion": "Cognitive Weave为大型语言模型（LLMs）的长期记忆提供了新的可能性，同时探讨了此类高级记忆系统的伦理考虑和未来研究方向。"}}
{"id": "2506.08119", "title": "SOP-Bench: Complex Industrial SOPs for Evaluating LLM Agents", "authors": ["Subhrangshu Nandi", "Arghya Datta", "Nikhil Vichare", "Indranil Bhattacharya", "Huzefa Raja", "Jing Xu", "Shayan Ray", "Giuseppe Carenini", "Abhi Srivastava", "Aaron Chan", "Man Ho Woo", "Amar Kandola", "Brandon Theresa", "Francesco Carbone"], "abstract": "Large Language Models (LLMs) demonstrate impressive general-purpose reasoning and problem-solving abilities. However, they struggle with executing complex, long-horizon workflows that demand strict adherence to Standard Operating Procedures (SOPs), a critical requirement for real-world industrial automation. Despite this need, there is a lack of public benchmarks that reflect the complexity, structure, and domain-specific nuances of SOPs. To address this, we present three main contributions. First, we introduce a synthetic data generation framework to create realistic, industry-grade SOPs that rigorously test the planning, reasoning, and tool-use capabilities of LLM-based agents. Second, using this framework, we develop SOP-Bench, a benchmark of over 1,800 tasks across 10 industrial domains, each with APIs, tool interfaces, and human-validated test cases. Third, we evaluate two prominent agent architectures: Function-Calling and ReAct Agents, on SOP-Bench, observing average success rates of only 27% and 48%, respectively. Remarkably, when the tool registry is much larger than necessary, agents invoke incorrect tools nearly 100% of the time. These findings underscore a substantial gap between current agentic capabilities of LLMs and the demands of automating real-world SOPs. Performance varies significantly by task and domain, highlighting the need for domain-specific benchmarking and architectural choices before deployment. SOP-Bench is publicly available at", "subjects": "Artificial Intelligence (cs.AI)", "comments": "Under review", "pdf_url": "https://arxiv.org/pdf/2506.08119.pdf", "abstract_url": "https://arxiv.org/abs/2506.08119", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了SOP-Bench，一个用于评估基于大型语言模型（LLM）的代理在复杂工业标准操作程序（SOPs）中表现的基准测试。通过合成数据生成框架创建了10个工业领域的1800多个任务，评估了两种代理架构的性能，发现当前LLM代理的能力与自动化真实世界SOPs的需求之间存在显著差距。", "motivation": "大型语言模型（LLMs）在通用推理和问题解决方面表现出色，但在执行需要严格遵守标准操作程序（SOPs）的复杂、长期工作流程时存在困难。目前缺乏反映SOPs复杂性、结构和领域特定细微差别的公开基准测试。", "method": "提出了一个合成数据生成框架来创建真实、工业级的SOPs，开发了SOP-Bench基准测试，包含10个工业领域的1800多个任务，每个任务都有API、工具接口和人工验证的测试用例。评估了两种代理架构：Function-Calling和ReAct Agents。", "result": "在SOP-Bench上，Function-Calling和ReAct Agents的平均成功率分别为27%和48%。当工具注册表远大于必要规模时，代理调用错误工具的概率接近100%。", "conclusion": "当前LLM代理的能力与自动化真实世界SOPs的需求之间存在显著差距。性能因任务和领域而异，强调了在部署前进行领域特定基准测试和架构选择的必要性。SOP-Bench已公开提供。"}}
{"id": "2506.08332", "title": "ORFS-agent: Tool-Using Agents for Chip Design Optimization", "authors": ["Amur Ghose", "Andrew B. Kahng", "Sayak Kundu", "Zhiang Wang"], "abstract": "Machine learning has been widely used to optimize complex engineering workflows across numerous domains. In the context of integrated circuit design, modern flows (e.g., going from a register-transfer level netlist to physical layouts) involve extensive configuration via thousands of parameters, and small changes to these parameters can have large downstream impacts on desired outcomes - namely design performance, power, and area. Recent advances in Large Language Models (LLMs) offer new opportunities for learning and reasoning within such high-dimensional optimization tasks. In this work, we introduce ORFS-agent, an LLM-based iterative optimization agent that automates parameter tuning in an open-source hardware design flow. ORFS-agent adaptively explores parameter configurations, demonstrating clear improvements over standard Bayesian optimization approaches in terms of resource efficiency and final design metrics. Our empirical evaluations on two different technology nodes and a range of circuit benchmarks indicate that ORFS-agent can improve both routed wirelength and effective clock period by over 13%, all while using 40% fewer optimization iterations. Moreover, by following natural language objectives to trade off certain metrics for others, ORFS-agent demonstrates a flexible and interpretable framework for multi-objective optimization. Crucially, RFS-agent is modular and model-agnostic, and can be plugged in to any frontier LLM without any further fine-tuning.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.08332.pdf", "abstract_url": "https://arxiv.org/abs/2506.08332", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "ORFS-agent是一种基于大型语言模型（LLM）的迭代优化代理，用于自动化开源硬件设计流程中的参数调优，相比标准贝叶斯优化方法在资源效率和最终设计指标上显示出明显改进。", "motivation": "解决集成电路设计中由于大量参数配置导致的复杂优化问题，以及如何高效地调整这些参数以优化设计性能、功耗和面积。", "method": "引入ORFS-agent，一个基于LLM的迭代优化代理，自适应地探索参数配置，无需进一步微调即可与任何前沿LLM插件配合使用。", "result": "在两个不同的技术节点和一系列电路基准测试中，ORFS-agent能够将布线长度和有效时钟周期改善超过13%，同时使用40%更少的优化迭代次数。", "conclusion": "ORFS-agent提供了一个灵活且可解释的多目标优化框架，能够根据自然语言目标在不同指标之间进行权衡，展示了在集成电路设计优化中的潜在应用价值。"}}
{"id": "2506.08800", "title": "Measuring Data Science Automation: A Survey of Evaluation Tools for AI Assistants and Agents", "authors": ["Irene Testini", "José Hernández-Orallo", "Lorenzo Pacchiardi"], "abstract": "Data science aims to extract insights from data to support decision-making processes. Recently, Large Language Models (LLMs) are increasingly used as assistants for data science, by suggesting ideas, techniques and small code snippets, or for the interpretation of results and reporting. Proper automation of some data-science activities is now promised by the rise of LLM agents, i.e., AI systems powered by an LLM equipped with additional affordances--such as code execution and knowledge bases--that can perform self-directed actions and interact with digital environments. In this paper, we survey the evaluation of LLM assistants and agents for data science. We find (1) a dominant focus on a small subset of goal-oriented activities, largely ignoring data management and exploratory activities; (2) a concentration on pure assistance or fully autonomous agents, without considering intermediate levels of human-AI collaboration; and (3) an emphasis on human substitution, therefore neglecting the possibility of higher levels of automation thanks to task transformation.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.08800.pdf", "abstract_url": "https://arxiv.org/abs/2506.08800", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文调查了用于评估AI助手和代理在数据科学中自动化程度的工具，指出了当前研究的局限性。", "motivation": "解决数据科学中AI助手和代理评估工具的不足，特别是在数据管理、探索性活动、人机协作水平以及任务转换方面的忽视。", "method": "通过文献调查，分析了当前评估LLM助手和代理在数据科学中应用的研究现状。", "result": "发现当前研究主要集中在目标导向活动上，忽视了数据管理和探索性活动；集中在纯辅助或完全自主代理上，未考虑人机协作的中间水平；强调人类替代，忽视了任务转换带来的更高级自动化可能性。", "conclusion": "指出了当前评估工具在数据科学自动化研究中的局限性，并提出了未来研究应关注的方向，包括更全面的活动覆盖、人机协作的中间水平以及任务转换的可能性。"}}
{"id": "2506.08900", "title": "MIRAGE: Multimodal foundation model and benchmark for comprehensive retinal OCT image analysis", "authors": ["José Morano", "Botond Fazekas", "Emese Sükei", "Ronald Fecso", "Taha Emre", "Markus Gumpinger", "Georg Faustmann", "Marzieh Oghbaie", "Ursula Schmidt-Erfurth", "Hrvoje Bogunović"], "abstract": "Artificial intelligence (AI) has become a fundamental tool for assisting clinicians in analyzing ophthalmic images, such as optical coherence tomography (OCT). However, developing AI models often requires extensive annotation, and existing models tend to underperform on independent, unseen data. Foundation models (FMs), large AI models trained on vast unlabeled datasets, have shown promise in overcoming these challenges. Nonetheless, available FMs for ophthalmology lack extensive validation, especially for segmentation tasks, and focus on a single imaging modality. In this context, we propose MIRAGE, a novel multimodal FM for the analysis of OCT and scanning laser ophthalmoscopy (SLO) images. Additionally, we propose a new evaluation benchmark with OCT/SLO classification and segmentation tasks. The comparison with general and specialized FMs and segmentation methods shows the superiority of MIRAGE in both types of tasks, highlighting its suitability as a basis for the development of robust AI systems for retinal OCT image analysis. Both MIRAGE and the evaluation benchmark are publicly available:", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.08900.pdf", "abstract_url": "https://arxiv.org/abs/2506.08900", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了MIRAGE，一种新型的多模态基础模型，用于分析OCT和SLO图像，并提出了一个新的评估基准。与通用和专业的基础模型及分割方法相比，MIRAGE在分类和分割任务中表现出优越性。", "motivation": "开发AI模型通常需要大量注释，现有模型在独立、未见数据上表现不佳。眼科领域的基础模型缺乏广泛验证，尤其是分割任务，且仅关注单一成像模态。", "method": "提出了MIRAGE，一种用于OCT和SLO图像分析的多模态基础模型，并建立了一个包含OCT/SLO分类和分割任务的新评估基准。", "result": "与通用和专业的基础模型及分割方法相比，MIRAGE在分类和分割任务中表现出优越性，适合作为视网膜OCT图像分析稳健AI系统的基础。", "conclusion": "MIRAGE及其评估基准的公开可用性，为开发用于视网膜OCT图像分析的稳健AI系统提供了有力工具。"}}
{"id": "2506.08580", "title": "HGFormer: A Hierarchical Graph Transformer Framework for Two-Stage Colonel Blotto Games via Reinforcement Learning", "authors": ["Yang Lv", "Jinlong Lei", "Peng Yi"], "abstract": "Two-stage Colonel Blotto game represents a typical adversarial resource allocation problem, in which two opposing agents sequentially allocate resources in a network topology across two phases: an initial resource deployment followed by multiple rounds of dynamic reallocation adjustments. The sequential dependency between game stages and the complex constraints imposed by the graph topology make it difficult for traditional approaches to attain a globally optimal strategy. To address these challenges, we propose a hierarchical graph Transformer framework called HGformer. By incorporating an enhanced graph Transformer encoder with structural biases and a two-agent hierarchical decision model, our approach enables efficient policy generation in large-scale adversarial environments. Moreover, we design a layer-by-layer feedback reinforcement learning algorithm that feeds the long-term returns from lower-level decisions back into the optimization of the higher-level strategy, thus bridging the coordination gap between the two decision-making stages. Experimental results demonstrate that, compared to existing hierarchical decision-making or graph neural network methods, HGformer significantly improves resource allocation efficiency and adversarial payoff, achieving superior overall performance in complex dynamic game scenarios.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.08580.pdf", "abstract_url": "https://arxiv.org/abs/2506.08580", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "HGFormer是一个用于两阶段Colonel Blotto游戏的分层图Transformer框架，通过强化学习解决对抗性资源分配问题。", "motivation": "解决两阶段Colonel Blotto游戏中由于游戏阶段的顺序依赖和图拓扑的复杂约束，传统方法难以获得全局最优策略的问题。", "method": "提出了一个分层图Transformer框架HGformer，结合了增强的图Transformer编码器与结构偏见和两代理分层决策模型，以及一个逐层反馈的强化学习算法。", "result": "实验结果表明，与现有的分层决策或图神经网络方法相比，HGformer显著提高了资源分配效率和对抗性收益，在复杂的动态游戏场景中实现了卓越的整体性能。", "conclusion": "HGformer框架通过其创新的分层决策和强化学习算法，有效地解决了复杂对抗性环境中的资源分配问题，为类似问题提供了新的解决方案。"}}
{"id": "2506.08630", "title": "Modular Recurrence in Contextual MDPs for Universal Morphology Control", "authors": ["Laurens Engwegen", "Daan Brinks", "Wendelin Böhmer"], "abstract": "A universal controller for any robot morphology would greatly improve computational and data efficiency. By utilizing contextual information about the properties of individual robots and exploiting their modular structure in the architecture of deep reinforcement learning agents, steps have been made towards multi-robot control. Generalization to new, unseen robots, however, remains a challenge. In this paper we hypothesize that the relevant contextual information is partially observable, but that it can be inferred through interactions for better generalization to contexts that are not seen during training. To this extent, we implement a modular recurrent architecture and evaluate its generalization performance on a large set of MuJoCo robots. The results show a substantial improved performance on robots with unseen dynamics, kinematics, and topologies, in four different environments.", "subjects": "Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.08630.pdf", "abstract_url": "https://arxiv.org/abs/2506.08630", "categories": ["Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种利用上下文信息和模块化结构的深度强化学习代理，以实现对任何机器人形态的通用控制。通过实施模块化循环架构，并在MuJoCo机器人上进行评估，结果显示在四种不同环境中，对未见过的动力学、运动学和拓扑结构的机器人性能有显著提升。", "motivation": "解决为任何机器人形态开发通用控制器的问题，以提高计算和数据效率，并解决对新、未见过的机器人泛化能力的挑战。", "method": "实施模块化循环架构，利用上下文信息并通过交互推断相关信息，以改善对训练期间未见过的上下文的泛化能力。", "result": "在MuJoCo机器人上的评估结果显示，对未见过的动力学、运动学和拓扑结构的机器人，在四种不同环境中的性能有显著提升。", "conclusion": "通过模块化循环架构和上下文信息的利用，可以显著提高对未见过的机器人形态的泛化能力，为实现通用机器人控制器的目标迈出了重要一步。"}}
{"id": "2506.09050", "title": "ALE-Bench: A Benchmark for Long-Horizon Objective-Driven Algorithm Engineering", "authors": ["Yuki Imajuku", "Kohki Horie", "Yoichi Iwata", "Kensho Aoki", "Naohiro Takahashi", "Takuya Akiba"], "abstract": "How well do AI systems perform in algorithm engineering for hard optimization problems in domains such as package-delivery routing, crew scheduling, factory production planning, and power-grid balancing? We introduce ALE-Bench, a new benchmark for evaluating AI systems on score-based algorithmic programming contests. Drawing on real tasks from the AtCoder Heuristic Contests, ALE-Bench presents optimization problems that are computationally hard and admit no known exact solution. Unlike short-duration, pass/fail coding benchmarks, ALE-Bench encourages iterative solution refinement over long time horizons. Our software framework supports interactive agent architectures that leverage test-run feedback and visualizations. Our evaluation of frontier LLMs revealed that while they demonstrate high performance on specific problems, a notable gap remains compared to humans in terms of consistency across problems and long-horizon problem-solving capabilities. This highlights the need for this benchmark to foster future AI advancements.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "36 pages", "pdf_url": "https://arxiv.org/pdf/2506.09050.pdf", "abstract_url": "https://arxiv.org/abs/2506.09050", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "ALE-Bench是一个新的基准测试，用于评估AI系统在基于分数的算法编程竞赛中的表现，专注于解决如包裹配送路由、机组调度等领域的硬优化问题。", "motivation": "解决AI系统在算法工程中对于硬优化问题的长期表现评估不足的问题。", "method": "利用AtCoder Heuristic Contests中的真实任务，设计了支持交互式代理架构的软件框架，鼓励长时间跨度的解决方案迭代优化。", "result": "前沿的大型语言模型在特定问题上表现出色，但在问题间的一致性和长期问题解决能力上与人类相比仍有显著差距。", "conclusion": "ALE-Bench的引入旨在促进未来AI在算法工程领域的进步，特别是在长期目标驱动的算法设计方面。"}}
{"id": "2506.09049", "title": "VIKI-R: Coordinating Embodied Multi-Agent Cooperation via Reinforcement Learning", "authors": ["Li Kang", "Xiufeng Song", "Heng Zhou", "Yiran Qin", "Jie Yang", "Xiaohong Liu", "Philip Torr", "Lei Bai", "Zhenfei Yin"], "abstract": "Coordinating multiple embodied agents in dynamic environments remains a core challenge in artificial intelligence, requiring both perception-driven reasoning and scalable cooperation strategies. While recent works have leveraged large language models (LLMs) for multi-agent planning, a few have begun to explore vision-language models (VLMs) for visual reasoning. However, these VLM-based approaches remain limited in their support for diverse embodiment types. In this work, we introduce VIKI-Bench, the first hierarchical benchmark tailored for embodied multi-agent cooperation, featuring three structured levels: agent activation, task planning, and trajectory perception. VIKI-Bench includes diverse robot embodiments, multi-view visual observations, and structured supervision signals to evaluate reasoning grounded in visual inputs. To demonstrate the utility of VIKI-Bench, we propose VIKI-R, a two-stage framework that fine-tunes a pretrained vision-language model (VLM) using Chain-of-Thought annotated demonstrations, followed by reinforcement learning under multi-level reward signals. Our extensive experiments show that VIKI-R significantly outperforms baselines method across all task levels. Furthermore, we show that reinforcement learning enables the emergence of compositional cooperation patterns among heterogeneous agents. Together, VIKI-Bench and VIKI-R offer a unified testbed and method for advancing multi-agent, visual-driven cooperation in embodied AI systems.", "subjects": "Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2506.09049.pdf", "abstract_url": "https://arxiv.org/abs/2506.09049", "categories": ["Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了VIKI-Bench，一个为具身多智能体合作设计的层次化基准测试，以及VIKI-R，一个两阶段框架，通过强化学习在视觉输入的基础上进行推理，显著优于基线方法。", "motivation": "解决在动态环境中协调多个具身智能体的核心挑战，需要感知驱动的推理和可扩展的合作策略。", "method": "提出VIKI-R，一个两阶段框架，首先使用思维链注释的演示对预训练的视觉语言模型进行微调，然后在多级奖励信号下进行强化学习。", "result": "VIKI-R在所有任务级别上显著优于基线方法，并且强化学习使得异构智能体之间出现了组合合作模式。", "conclusion": "VIKI-Bench和VIKI-R为推进具身AI系统中的多智能体、视觉驱动合作提供了统一的测试平台和方法。"}}
{"id": "2506.08933", "title": "What Limits Virtual Agent Application? OmniBench: A Scalable Multi-Dimensional Benchmark for Essential Virtual Agent Capabilities", "authors": ["Wendong Bu", "Yang Wu", "Qifan Yu", "Minghe Gao", "Bingchen Miao", "Zhenkui Zhang", "Kaihang Pan", "Yunfei Li", "Mengze Li", "Wei Ji", "Juncheng Li", "Siliang Tang", "Yueting Zhuang"], "abstract": "As multimodal large language models (MLLMs) advance, MLLM-based virtual agents have demonstrated remarkable performance. However, existing benchmarks face significant limitations, including uncontrollable task complexity, extensive manual annotation with limited scenarios, and a lack of multidimensional evaluation. In response to these challenges, we introduce OmniBench, a self-generating, cross-platform, graph-based benchmark with an automated pipeline for synthesizing tasks of controllable complexity through subtask composition. To evaluate the diverse capabilities of virtual agents on the graph, we further present OmniEval, a multidimensional evaluation framework that includes subtask-level evaluation, graph-based metrics, and comprehensive tests across 10 capabilities. Our synthesized dataset contains 36k graph-structured tasks across 20 scenarios, achieving a 91\\% human acceptance rate. Training on our graph-structured data shows that it can more efficiently guide agents compared to manually annotated data. We conduct multidimensional evaluations for various open-source and closed-source models, revealing their performance across various capabilities and paving the way for future advancements. Our project is available at", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "Accepted by ICML 2025 (Oral)", "pdf_url": "https://arxiv.org/pdf/2506.08933.pdf", "abstract_url": "https://arxiv.org/abs/2506.08933", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了OmniBench，一个自生成、跨平台、基于图的基准测试，用于评估多模态大语言模型（MLLM）虚拟代理的多维能力，解决了现有基准测试在任务复杂性控制、手动注释限制和多维评估缺乏方面的问题。", "motivation": "解决现有基准测试在评估多模态大语言模型虚拟代理时面临的任务复杂性不可控、手动注释场景有限和多维评估缺乏的问题。", "method": "引入OmniBench，一个自生成、跨平台、基于图的基准测试，通过子任务组合合成可控复杂度的任务，并开发OmniEval进行多维评估。", "result": "合成的数据集包含20个场景中的36k个图结构任务，人类接受率达到91%。图结构数据比手动注释数据更有效地指导代理。", "conclusion": "OmniBench和OmniEval为虚拟代理的多维能力评估提供了有效的工具，揭示了不同开源和闭源模型的性能差异，为未来进步铺平了道路。"}}
{"id": "2506.00160", "title": "Werewolf: A Straightforward Game Framework with TTS for Improved User Engagement", "authors": ["Qihui Fan", "Enfu Nan", "Wenbo Li", "Lei Lu", "Pu Zhao", "Yanzhi Wang"], "abstract": "The growing popularity of social deduction game systems for both business applications and AI research has greatly benefited from the rapid advancements in Large Language Models (LLMs), which now demonstrate stronger reasoning and persuasion capabilities. Especially with the raise of DeepSeek R1 and V3 models, LLMs should enable a more engaging experience for human players in LLM-agent-based social deduction games like Werewolf. Previous works either fine-tuning, advanced prompting engineering, or additional experience pool to achieve engaging text-format Werewolf game experience. We propose a novel yet straightforward LLM-based Werewolf game system with tuned Text-to-Speech(TTS) models designed for enhanced compatibility with various LLM models, and improved user engagement. We argue with ever enhancing LLM reasoning, extra components will be unnecessary in the case of Werewolf.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.00160.pdf", "abstract_url": "https://arxiv.org/abs/2506.00160", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于大型语言模型(LLMs)的简单狼人杀游戏系统，通过调整文本到语音(TTS)模型来提高与不同LLM模型的兼容性和用户参与度。", "motivation": "随着大型语言模型(LLMs)在推理和说服能力上的快速进步，特别是在DeepSeek R1和V3模型的推动下，LLMs能够在基于LLM代理的社交推理游戏（如狼人杀）中为人类玩家提供更吸引人的体验。本文旨在解决如何在不依赖额外组件的情况下，利用LLMs提升狼人杀游戏的用户参与度。", "method": "提出了一种新颖而简单的基于LLM的狼人杀游戏系统，该系统采用了调整过的文本到语音(TTS)模型，旨在增强与各种LLM模型的兼容性。", "result": "通过这种方法，系统能够在不需要额外组件的情况下，利用不断进步的LLM推理能力，提供更吸引人的狼人杀游戏体验。", "conclusion": "随着LLM推理能力的不断提升，对于狼人杀这类游戏，额外的组件将变得不必要。本文提出的系统展示了如何通过简单的设计和调整过的TTS模型，有效提升用户参与度和游戏体验。"}}
{"id": "2506.06363", "title": "ChemGraph: An Agentic Framework for Computational Chemistry Workflows", "authors": ["Thang D. Pham", "Aditya Tanikanti", "Murat Keçeli"], "abstract": "Atomistic simulations are essential tools in chemistry and materials science, accelerating the discovery of novel catalysts, energy storage materials, and pharmaceuticals. However, running these simulations remains challenging due to the wide range of computational methods, diverse software ecosystems, and the need for expert knowledge and manual effort for the setup, execution, and validation stages. In this work, we present ChemGraph, an agentic framework powered by artificial intelligence and state-of-the-art simulation tools to streamline and automate computational chemistry and materials science workflows. ChemGraph leverages graph neural network-based foundation models for accurate yet computationally efficient calculations and large language models (LLMs) for natural language understanding, task planning, and scientific reasoning to provide an intuitive and interactive interface. Users can perform tasks such as molecular structure generation, single-point energy, geometry optimization, vibrational analysis, and thermochemistry calculations with methods ranging from tight-binding and machine learning interatomic potentials to density functional theory or wave function theory-based methods. We evaluate ChemGraph across 13 benchmark tasks and demonstrate that smaller LLMs (GPT-4o-mini, Claude-3.5-haiku, Qwen2.5-14B) perform well on simple workflows, while more complex tasks benefit from using larger models like GPT-4o. Importantly, we show that decomposing complex tasks into smaller subtasks through a multi-agent framework enables smaller LLM models to match or exceed GPT-4o's performance in specific scenarios.", "subjects": "Chemical Physics (physics.chem-ph); Materials Science (cond-mat.mtrl-sci); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Computational Physics (physics.comp-ph)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.06363.pdf", "abstract_url": "https://arxiv.org/abs/2506.06363", "categories": ["Chemical Physics (physics.chem-ph)", "Materials Science (cond-mat.mtrl-sci)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)", "Computational Physics (physics.comp-ph)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "ChemGraph是一个基于人工智能的代理框架，旨在简化和自动化计算化学和材料科学的工作流程。它结合了图神经网络基础模型和大型语言模型，提供直观的交互界面，支持从简单到复杂的多种计算任务。", "motivation": "原子模拟在化学和材料科学中至关重要，但由于计算方法多样、软件生态系统复杂以及需要专家知识和手动操作，执行这些模拟仍然具有挑战性。ChemGraph旨在解决这些问题。", "method": "ChemGraph利用图神经网络基础模型进行高效准确的计算，并使用大型语言模型（LLMs）进行自然语言理解、任务规划和科学推理，以提供一个直观的交互界面。", "result": "在13个基准任务上的评估显示，较小的LLMs在简单工作流上表现良好，而更复杂的任务则受益于使用更大的模型。通过多代理框架将复杂任务分解为较小子任务，可以使较小的LLM模型在特定场景中匹配或超过GPT-4o的性能。", "conclusion": "ChemGraph通过结合先进的模拟工具和人工智能技术，有效地简化和自动化了计算化学和材料科学的工作流程，为复杂任务的执行提供了新的可能性。"}}
{"id": "2506.07675", "title": "QUITE: A Query Rewrite System Beyond Rules with LLM Agents", "authors": ["Yuyang Song", "Hanxu Yan", "Jiale Lao", "Yibo Wang", "Yufei Li", "Yuanchun Zhou", "Jianguo Wang", "Mingjie Tang"], "abstract": "Query rewrite transforms SQL queries into semantically equivalent forms that run more efficiently. Existing approaches mainly rely on predefined rewrite rules, but they handle a limited subset of queries and can cause performance regressions. This limitation stems from three challenges of rule-based query rewrite: (1) it is hard to discover and verify new rules, (2) fixed rewrite rules do not generalize to new query patterns, and (3) some rewrite techniques cannot be expressed as fixed rules. Motivated by the fact that human experts exhibit significantly better rewrite ability but suffer from scalability, and Large Language Models (LLMs) have demonstrated nearly human-level semantic and reasoning abilities, we propose a new approach of using LLMs to rewrite SQL queries beyond rules. Due to the hallucination problems in LLMs, directly applying LLMs often leads to nonequivalent and suboptimal queries. To address this issue, we propose QUITE (query rewrite), a training-free and feedback-aware system based on LLM agents that rewrites SQL queries into semantically equivalent forms with significantly better performance, covering a broader range of query patterns and rewrite strategies compared to rule-based methods. Firstly, we design a multi-agent framework controlled by a finite state machine (FSM) to equip LLMs with the ability to use external tools and enhance the rewrite process with real-time database feedback. Secondly, we develop a rewrite middleware to enhance the ability of LLMs to generate optimized query equivalents. Finally, we employ a novel hint injection technique to improve execution plans for rewritten queries. Extensive experiments show that QUITE reduces query execution time by up to 35.8% over state-of-the-art approaches and produces 24.1% more rewrites than prior methods, covering query cases that earlier systems did not handle.", "subjects": "Databases (cs.DB); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.07675.pdf", "abstract_url": "https://arxiv.org/abs/2506.07675", "categories": ["Databases (cs.DB)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "QUITE是一个基于LLM代理的查询重写系统，旨在超越传统基于规则的方法，通过利用LLM的语义和推理能力来重写SQL查询，以提高执行效率并覆盖更广泛的查询模式。", "motivation": "现有的查询重写方法主要依赖于预定义的重写规则，这些方法处理的查询范围有限，且可能导致性能下降。QUITE旨在解决规则基础查询重写的三个挑战：发现和验证新规则的困难、固定重写规则无法泛化到新查询模式、以及某些重写技术无法表达为固定规则。", "method": "QUITE采用了一个基于LLM代理的训练免费和反馈感知系统，设计了一个由有限状态机控制的多代理框架，以增强LLM使用外部工具的能力，并通过实时数据库反馈优化重写过程。此外，开发了一个重写中间件来增强LLM生成优化查询等价物的能力，并采用了一种新颖的提示注入技术来改进重写查询的执行计划。", "result": "大量实验表明，QUITE比最先进的方法减少了高达35.8%的查询执行时间，并产生了比先前方法多24.1%的重写，覆盖了早期系统未处理的查询案例。", "conclusion": "QUITE通过利用LLM代理和实时反馈，成功地超越了传统的基于规则的查询重写方法，提供了一种更高效、更广泛适用的查询优化解决方案。"}}
{"id": "2506.08045", "title": "UAVs Meet Agentic AI: A Multidomain Survey of Autonomous Aerial Intelligence and Agentic UAVs", "authors": ["Ranjan Sapkota", "Konstantinos I. Roumeliotis", "Manoj Karkee"], "abstract": "Agentic UAVs represent a new frontier in autonomous aerial intelligence, integrating perception, decision-making, memory, and collaborative planning to operate adaptively in complex, real-world environments. Driven by recent advances in Agentic AI, these systems surpass traditional UAVs by exhibiting goal-driven behavior, contextual reasoning, and interactive autonomy. We provide a comprehensive foundation for understanding the architectural components and enabling technologies that distinguish Agentic UAVs from traditional autonomous UAVs. Furthermore, a detailed comparative analysis highlights advancements in autonomy with AI agents, learning, and mission flexibility. This study explores seven high-impact application domains precision agriculture, construction & mining, disaster response, environmental monitoring, infrastructure inspection, logistics, security, and wildlife conservation, illustrating the broad societal value of agentic aerial intelligence. Furthermore, we identify key challenges in technical constraints, regulatory limitations, and data-model reliability, and we present emerging solutions across hardware innovation, learning architectures, and human-AI interaction. Finally, a future roadmap is proposed, outlining pathways toward self-evolving aerial ecosystems, system-level collaboration, and sustainable, equitable deployments. This survey establishes a foundational framework for the future development, deployment, and governance of agentic aerial systems (Agentic UAVs) across diverse societal and industrial domains.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": "40 pages, 6 Figures", "pdf_url": "https://arxiv.org/pdf/2506.08045.pdf", "abstract_url": "https://arxiv.org/abs/2506.08045", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文综述了代理无人机（Agentic UAVs）在自主空中智能领域的新进展，探讨了其架构组件、使能技术、应用领域及未来发展方向。", "motivation": "解决传统无人机在复杂现实环境中适应性不足的问题，通过集成感知、决策、记忆和协作规划等技术，提升无人机的自主性和智能水平。", "method": "通过比较分析和多领域应用案例研究，评估代理无人机与传统无人机的差异，以及AI代理、学习和任务灵活性方面的进步。", "result": "代理无人机在精准农业、灾害响应、环境监测等多个高影响力领域展现出广泛的社会价值，同时面临技术、法规和数据模型可靠性等挑战。", "conclusion": "提出了未来发展的路线图，包括自进化空中生态系统、系统级协作和可持续、公平部署的路径，为代理无人机的发展、部署和治理奠定了基础。"}}
{"id": "2506.08149", "title": "Ego-centric Learning of Communicative World Models for Autonomous Driving", "authors": ["Hang Wang", "Dechen Gao", "Junshan Zhang"], "abstract": "We study multi-agent reinforcement learning (MARL) for tasks in complex high-dimensional environments, such as autonomous driving. MARL is known to suffer from the \\textit{partial observability} and \\textit{non-stationarity} issues. To tackle these challenges, information sharing is often employed, which however faces major hurdles in practice, including overwhelming communication overhead and scalability concerns. By making use of generative AI embodied in world model together with its latent representation, we develop {\\it CALL}, \\underline{C}ommunic\\underline{a}tive Wor\\underline{l}d Mode\\underline{l}, for MARL, where 1) each agent first learns its world model that encodes its state and intention into low-dimensional latent representation with smaller memory footprint, which can be shared with other agents of interest via lightweight communication; and 2) each agent carries out ego-centric learning while exploiting lightweight information sharing to enrich her world model, and then exploits its generalization capacity to improve prediction for better planning. We characterize the gain on the prediction accuracy from the information sharing and its impact on performance gap. Extensive experiments are carried out on the challenging local trajectory planning tasks in the CARLA platform to demonstrate the performance gains of using \\textit{CALL}.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.08149.pdf", "abstract_url": "https://arxiv.org/abs/2506.08149", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究了多智能体强化学习（MARL）在复杂高维环境（如自动驾驶）中的应用，提出了CALL（Communicative World Model）方法，通过生成AI和潜在表示来优化信息共享，提高预测准确性和规划性能。", "motivation": "解决MARL在复杂环境中的部分可观察性和非平稳性问题，同时克服信息共享中的通信开销和可扩展性问题。", "method": "开发CALL方法，每个智能体首先学习其世界模型，将状态和意图编码为低维潜在表示，通过轻量级通信与其他智能体共享；然后进行自我中心学习，利用信息共享丰富世界模型，提高预测和规划能力。", "result": "实验在CARLA平台上进行，展示了CALL在局部轨迹规划任务中的性能提升。", "conclusion": "CALL通过优化信息共享和利用世界模型的泛化能力，有效提高了MARL在复杂环境中的预测准确性和规划性能。"}}
{"id": "2506.08173", "title": "Repeton: Structured Bug Repair with ReAct-Guided Patch-and-Test Cycles", "authors": ["Nguyen Phu Vinh", "Anh Chung Hoang", "Chris Ngo", "Truong-Son Hy"], "abstract": "Large Language Models (LLMs) have shown strong capabilities in code generation and comprehension, yet their application to complex software engineering tasks often suffers from low precision and limited interpretability. We present Repeton, a fully open-source framework that leverages LLMs for precise and automated code manipulation in real-world Git repositories. Rather than generating holistic fixes, Repeton operates through a structured patch-and-test pipeline: it iteratively diagnoses issues, proposes code changes, and validates each patch through automated testing. This stepwise process is guided by lightweight heuristics and development tools, avoiding reliance on embedding-based retrieval systems. Evaluated on the SWE-bench Lite benchmark, our method shows good performance compared to RAG-based methods in both patch validity and interpretability. By decomposing software engineering tasks into modular, verifiable stages, Repeton provides a practical path toward scalable and transparent autonomous debugging.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.08173.pdf", "abstract_url": "https://arxiv.org/abs/2506.08173", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "Repeton是一个完全开源的框架，利用大型语言模型（LLMs）在真实世界的Git仓库中进行精确和自动化的代码操作。通过结构化的补丁和测试流程，它迭代地诊断问题、提出代码更改，并通过自动化测试验证每个补丁。在SWE-bench Lite基准测试中，与基于RAG的方法相比，Repeton在补丁有效性和可解释性方面表现出色。", "motivation": "大型语言模型（LLMs）在代码生成和理解方面表现出强大的能力，但在复杂软件工程任务中的应用往往受到低精度和有限可解释性的限制。", "method": "Repeton通过结构化的补丁和测试流程操作：迭代地诊断问题、提出代码更改，并通过自动化测试验证每个补丁。这一逐步过程由轻量级启发式方法和开发工具指导，避免依赖基于嵌入的检索系统。", "result": "在SWE-bench Lite基准测试中，Repeton在补丁有效性和可解释性方面与基于RAG的方法相比表现出色。", "conclusion": "通过将软件工程任务分解为模块化、可验证的阶段，Repeton为可扩展和透明的自主调试提供了一条实用路径。"}}
{"id": "2506.08708", "title": "PhyBlock: A Progressive Benchmark for Physical Understanding and Planning via 3D Block Assembly", "authors": ["Liang Ma", "Jiajun Wen", "Min Lin", "Rongtao Xu", "Xiwen Liang", "Bingqian Lin", "Jun Ma", "Yongxin Wang", "Ziming Wei", "Haokun Lin", "Mingfei Han", "Meng Cao", "Bokui Chen", "Ivan Laptev", "Xiaodan Liang"], "abstract": "While vision-language models (VLMs) have demonstrated promising capabilities in reasoning and planning for embodied agents, their ability to comprehend physical phenomena, particularly within structured 3D environments, remains severely limited. To close this gap, we introduce PhyBlock, a progressive benchmark designed to assess VLMs on physical understanding and planning through robotic 3D block assembly tasks. PhyBlock integrates a novel four-level cognitive hierarchy assembly task alongside targeted Visual Question Answering (VQA) samples, collectively aimed at evaluating progressive spatial reasoning and fundamental physical comprehension, including object properties, spatial relationships, and holistic scene understanding. PhyBlock includes 2600 block tasks (400 assembly tasks, 2200 VQA tasks) and evaluates models across three key dimensions: partial completion, failure diagnosis, and planning robustness. We benchmark 21 state-of-the-art VLMs, highlighting their strengths and limitations in physically grounded, multi-step planning. Our empirical findings indicate that the performance of VLMs exhibits pronounced limitations in high-level planning and reasoning capabilities, leading to a notable decline in performance for the growing complexity of the tasks. Error analysis reveals persistent difficulties in spatial orientation and dependency reasoning. Surprisingly, chain-of-thought prompting offers minimal improvements, suggesting spatial tasks heavily rely on intuitive model comprehension. We position PhyBlock as a unified testbed to advance embodied reasoning, bridging vision-language understanding and real-world physical problem-solving.", "subjects": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.08708.pdf", "abstract_url": "https://arxiv.org/abs/2506.08708", "categories": ["Robotics (cs.RO)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了PhyBlock，一个用于评估视觉语言模型（VLMs）在物理理解和规划方面能力的渐进式基准，特别是在3D块组装任务中。", "motivation": "解决视觉语言模型在理解物理现象，尤其是在结构化3D环境中的能力有限的问题。", "method": "通过整合一个新颖的四级认知层次组装任务和针对性的视觉问答（VQA）样本，评估渐进式空间推理和基本物理理解能力。", "result": "评估了21种最先进的VLMs，发现它们在高级规划和推理能力上存在显著限制，特别是在任务复杂性增加时表现下降。", "conclusion": "PhyBlock作为一个统一的测试平台，旨在推动体现推理的发展，连接视觉语言理解和现实世界的物理问题解决。"}}
{"id": "2506.08228", "title": "Scaling Laws of Motion Forecasting and Planning -- A Technical Report", "authors": ["Mustafa Baniodeh", "Kratarth Goel", "Scott Ettinger", "Carlos Fuertes", "Ari Seff", "Tim Shen", "Cole Gulino", "Chenjie Yang", "Ghassen Jerfel", "Dokook Choe", "Rui Wang", "Vinutha Kallem", "Sergio Casas", "Rami Al-Rfou", "Benjamin Sapp", "Dragomir Anguelov"], "abstract": "We study the empirical scaling laws of a family of encoder-decoder autoregressive transformer models on the task of joint motion forecasting and planning in the autonomous driving domain. Using a 500 thousand hours driving dataset, we demonstrate that, similar to language modeling, model performance improves as a power-law function of the total compute budget, and we observe a strong correlation between model training loss and model evaluation metrics. Most interestingly, closed-loop metrics also improve with scaling, which has important implications for the suitability of open-loop metrics for model development and hill climbing. We also study the optimal scaling of the number of transformer parameters and the training data size for a training compute-optimal model. We find that as the training compute budget grows, optimal scaling requires increasing the model size 1.5x as fast as the dataset size. We also study inference-time compute scaling, where we observe that sampling and clustering the output of smaller models makes them competitive with larger models, up to a crossover point beyond which a larger models becomes more inference-compute efficient. Overall, our experimental results demonstrate that optimizing the training and inference-time scaling properties of motion forecasting and planning models is a key lever for improving their performance to address a wide variety of driving scenarios. Finally, we briefly study the utility of training on general logged driving data of other agents to improve the performance of the ego-agent, an important research area to address the scarcity of robotics data for large capacity models training.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.08228.pdf", "abstract_url": "https://arxiv.org/abs/2506.08228", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究了自动驾驶领域中联合运动预测和规划任务的编码器-解码器自回归变换器模型的实证缩放定律。使用50万小时的驾驶数据集，我们发现模型性能随着计算预算的增加而按幂律函数提升，且模型训练损失与评估指标之间存在强相关性。闭环指标也随缩放而提升，这对开环指标在模型开发和优化中的适用性有重要影响。我们还研究了模型参数数量和训练数据大小的最优缩放比例，发现随着计算预算的增加，模型大小的增长速度应比数据集大小快1.5倍。此外，我们还观察到，在推理时计算缩放中，对小模型的输出进行采样和聚类可以使它们与更大的模型竞争，直到达到一个交叉点。最后，我们简要研究了利用其他智能体的通用日志驾驶数据训练来提高自我智能体性能的效用。", "motivation": "解决自动驾驶领域中联合运动预测和规划任务的模型性能和效率问题，特别是在计算资源和数据稀缺的情况下。", "method": "使用编码器-解码器自回归变换器模型，并在50万小时的驾驶数据集上进行实验，研究模型性能、训练和推理时的计算缩放规律。", "result": "模型性能随着计算预算的增加而按幂律函数提升，闭环指标也随缩放而提升。模型大小的增长速度应比数据集大小快1.5倍。在推理时计算缩放中，小模型的输出采样和聚类可以与更大的模型竞争。", "conclusion": "优化运动预测和规划模型的训练和推理时缩放属性是提高其性能以应对各种驾驶场景的关键。利用其他智能体的通用日志驾驶数据训练可以缓解大型模型训练中机器人数据稀缺的问题。"}}
{"id": "2506.08311", "title": "Understanding Software Engineering Agents Through the Lens of Traceability: An Empirical Study", "authors": ["Ira Ceka", "Saurabh Pujar", "Shyam Ramji", "Luca Buratti", "Gail Kaiser", "Baishakhi Ray"], "abstract": "With the advent of large language models (LLMs), software engineering agents (SWE agents) have emerged as a powerful paradigm for automating a range of software tasks -- from code generation and repair to test case synthesis. These agents operate autonomously by interpreting user input and responding to environmental feedback. While various agent architectures have demonstrated strong empirical performance, the internal decision-making worfklows that drive their behavior remain poorly understood. Deeper insight into these workflows hold promise for improving both agent reliability and efficiency. In this work, we present the first systematic study of SWE agent behavior through the lens of execution traces. Our contributions are as follows: (1) we propose the first taxonomy of decision-making pathways across five representative agents; (2) using this taxonomy, we identify three core components essential to agent success -- bug localization, patch generation, and reproduction test generation -- and study each in depth; (3) we study the impact of test generation on successful patch production; and analyze strategies that can lead to successful test generation; (4) we further conduct the first large-scale code clone analysis comparing agent-generated and developer-written patches and provide a qualitative study revealing structural and stylistic differences in patch content. Together, these findings offer novel insights into agent design and open avenues for building agents that are both more effective and more aligned with human development practices.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.08311.pdf", "abstract_url": "https://arxiv.org/abs/2506.08311", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过执行跟踪的视角，首次系统研究了软件工程代理（SWE代理）的行为，提出了五种代表性代理的决策路径分类法，并深入分析了代理成功的三个核心组件。", "motivation": "随着大型语言模型（LLMs）的出现，软件工程代理（SWE代理）已成为自动化软件任务的强大范式，但其内部决策工作流程仍不为人所理解。", "method": "通过执行跟踪的视角，提出了五种代表性代理的决策路径分类法，并深入分析了代理成功的三个核心组件：错误定位、补丁生成和再现测试生成。", "result": "研究发现，测试生成对成功生成补丁有重要影响，并分析了导致成功测试生成的策略。此外，首次大规模代码克隆分析揭示了代理生成和开发者编写补丁之间的结构和风格差异。", "conclusion": "这些发现为代理设计提供了新的见解，并为构建更有效且更符合人类开发实践的代理开辟了途径。"}}
{"id": "2506.08336", "title": "Your Agent Can Defend Itself against Backdoor Attacks", "authors": ["Li Changjiang", "Liang Jiacheng", "Cao Bochuan", "Chen Jinghui", "Wang Ting"], "abstract": "Despite their growing adoption across domains, large language model (LLM)-powered agents face significant security risks from backdoor attacks during training and fine-tuning. These compromised agents can subsequently be manipulated to execute malicious operations when presented with specific triggers in their inputs or environments. To address this pressing risk, we present ReAgent, a novel defense against a range of backdoor attacks on LLM-based agents. Intuitively, backdoor attacks often result in inconsistencies among the user's instruction, the agent's planning, and its execution. Drawing on this insight, ReAgent employs a two-level approach to detect potential backdoors. At the execution level, ReAgent verifies consistency between the agent's thoughts and actions; at the planning level, ReAgent leverages the agent's capability to reconstruct the instruction based on its thought trajectory, checking for consistency between the reconstructed instruction and the user's instruction. Extensive evaluation demonstrates ReAgent's effectiveness against various backdoor attacks across tasks. For instance, ReAgent reduces the attack success rate by up to 90\\% in database operation tasks, outperforming existing defenses by large margins. This work reveals the potential of utilizing compromised agents themselves to mitigate backdoor risks.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.08336.pdf", "abstract_url": "https://arxiv.org/abs/2506.08336", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出ReAgent，一种针对大型语言模型（LLM）代理后门攻击的新型防御方法，通过检测用户指令、代理规划和执行间的不一致性来有效降低攻击成功率。", "motivation": "大型语言模型（LLM）代理在训练和微调过程中面临后门攻击的安全风险，这些被攻击的代理在特定触发条件下可能执行恶意操作。", "method": "ReAgent采用两级检测方法：在执行层面验证代理的思考与行动的一致性；在规划层面利用代理的能力基于其思考轨迹重构指令，检查重构指令与用户指令的一致性。", "result": "广泛评估显示，ReAgent能有效对抗多种后门攻击，如在数据库操作任务中将攻击成功率降低高达90%，远超现有防御方法。", "conclusion": "这项工作揭示了利用被攻击代理自身减轻后门风险的潜力，为LLM代理的安全提供了新的防御思路。"}}
{"id": "2506.08507", "title": "MasHost Builds It All: Autonomous Multi-Agent System Directed by Reinforcement Learning", "authors": ["Kuo Yang", "Xingjie Yang", "Linhui Yu", "Qing Xu", "Yan Fang", "Xu Wang", "Zhengyang Zhou", "Yang Wang"], "abstract": "Large Language Model (LLM)-driven Multi-agent systems (Mas) have recently emerged as a powerful paradigm for tackling complex real-world tasks. However, existing Mas construction methods typically rely on manually crafted interaction mechanisms or heuristic rules, introducing human biases and constraining the autonomous ability. Even with recent advances in adaptive Mas construction, existing systems largely remain within the paradigm of semi-autonomous patterns. In this work, we propose MasHost, a Reinforcement Learning (RL)-based framework for autonomous and query-adaptive Mas design. By formulating Mas construction as a graph search problem, our proposed MasHost jointly samples agent roles and their interactions through a unified probabilistic sampling mechanism. Beyond the accuracy and efficiency objectives pursued in prior works, we introduce component rationality as an additional and novel design principle in Mas. To achieve this multi-objective optimization, we propose Hierarchical Relative Policy Optimization (HRPO), a novel RL strategy that collaboratively integrates group-relative advantages and action-wise rewards. To our knowledge, our proposed MasHost is the first RL-driven framework for autonomous Mas graph construction. Extensive experiments on six benchmarks demonstrate that MasHost consistently outperforms most competitive baselines, validating its effectiveness, efficiency, and structure rationality.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.08507.pdf", "abstract_url": "https://arxiv.org/abs/2506.08507", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了MasHost，一个基于强化学习的自主多代理系统设计框架，旨在解决现有多代理系统构建方法中的人为偏见和自主能力受限问题。", "motivation": "解决现有多代理系统构建方法依赖手工制作的交互机制或启发式规则，引入人为偏见并限制自主能力的问题。", "method": "提出MasHost框架，将多代理系统构建视为图搜索问题，通过统一的概率采样机制联合采样代理角色及其交互，并引入组件合理性作为新的设计原则。", "result": "在六个基准测试上的广泛实验表明，MasHost在有效性、效率和结构合理性方面 consistently 优于大多数竞争基线。", "conclusion": "MasHost是第一个基于强化学习的自主多代理系统图构建框架，其提出的分层相对策略优化（HRPO）策略有效实现了多目标优化。"}}
{"id": "2506.08902", "title": "Intention-Conditioned Flow Occupancy Models", "authors": ["Chongyi Zheng", "Seohong Park", "Sergey Levine", "Benjamin Eysenbach"], "abstract": "Large-scale pre-training has fundamentally changed how machine learning research is done today: large foundation models are trained once, and then can be used by anyone in the community (including those without data or compute resources to train a model from scratch) to adapt and fine-tune to specific tasks. Applying this same framework to reinforcement learning (RL) is appealing because it offers compelling avenues for addressing core challenges in RL, including sample efficiency and robustness. However, there remains a fundamental challenge to pre-train large models in the context of RL: actions have long-term dependencies, so training a foundation model that reasons across time is important. Recent advances in generative AI have provided new tools for modeling highly complex distributions. In this paper, we build a probabilistic model to predict which states an agent will visit in the temporally distant future (i.e., an occupancy measure) using flow matching. As large datasets are often constructed by many distinct users performing distinct tasks, we include in our model a latent variable capturing the user intention. This intention increases the expressivity of our model, and enables adaptation with generalized policy improvement. We call our proposed method intention-conditioned flow occupancy models (InFOM). Comparing with alternative methods for pre-training, our experiments on $36$ state-based and $4$ image-based benchmark tasks demonstrate that the proposed method achieves $1.8 \\times$ median improvement in returns and increases success rates by $36\\%$. Website:", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.08902.pdf", "abstract_url": "https://arxiv.org/abs/2506.08902", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于意图条件流占用模型（InFOM）的方法，用于预测代理在时间上遥远的未来将访问哪些状态，利用流匹配和潜在变量捕获用户意图，以提高模型的表达能力和适应性。", "motivation": "解决在强化学习（RL）中预训练大型模型时的基本挑战，即动作具有长期依赖性，以及如何利用大型数据集构建的多样性用户意图来提高模型的适应性和性能。", "method": "使用流匹配构建概率模型预测代理的未来状态占用度量，并引入潜在变量捕获用户意图，通过广义策略改进实现适应。", "result": "在36个基于状态和4个基于图像的基准任务上的实验表明，该方法在回报中实现了1.8倍的中位数改进，成功率提高了36%。", "conclusion": "提出的InFOM方法在预训练中表现出色，通过捕获用户意图和流匹配技术，显著提高了强化学习的样本效率和鲁棒性。"}}
{"id": "2506.09046", "title": "Agentic Neural Networks: Self-Evolving Multi-Agent Systems via Textual Backpropagation", "authors": ["Xiaowen Ma", "Chenyang Lin", "Yao Zhang", "Volker Tresp", "Yunpu Ma"], "abstract": "Leveraging multiple Large Language Models(LLMs) has proven effective for addressing complex, high-dimensional tasks, but current approaches often rely on static, manually engineered multi-agent configurations. To overcome these constraints, we present the Agentic Neural Network(ANN), a framework that conceptualizes multi-agent collaboration as a layered neural network architecture. In this design, each agent operates as a node, and each layer forms a cooperative \"team\" focused on a specific subtask. Agentic Neural Network follows a two-phase optimization strategy: (1) Forward Phase-Drawing inspiration from neural network forward passes, tasks are dynamically decomposed into subtasks, and cooperative agent teams with suitable aggregation methods are constructed layer by layer. (2) Backward Phase-Mirroring backpropagation, we refine both global and local collaboration through iterative feedback, allowing agents to self-evolve their roles, prompts, and coordination. This neuro-symbolic approach enables ANN to create new or specialized agent teams post-training, delivering notable gains in accuracy and adaptability. Across four benchmark datasets, ANN surpasses leading multi-agent baselines under the same configurations, showing consistent performance improvements. Our findings indicate that ANN provides a scalable, data-driven framework for multi-agent systems, combining the collaborative capabilities of LLMs with the efficiency and flexibility of neural network principles. We plan to open-source the entire framework.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.09046.pdf", "abstract_url": "https://arxiv.org/abs/2506.09046", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了Agentic Neural Network（ANN）框架，通过将多智能体协作建模为分层的神经网络架构，实现了自我进化的多智能体系统。ANN采用两阶段优化策略，显著提高了任务的准确性和适应性。", "motivation": "当前的多智能体系统通常依赖于静态、手动设计的配置，这限制了处理复杂、高维任务的能力。为了解决这一问题，本文提出了ANN框架，旨在通过神经网络的原理提高多智能体系统的效率和灵活性。", "method": "ANN框架将多智能体协作视为分层的神经网络架构，每个智能体作为节点，每层形成一个专注于特定子任务的协作“团队”。采用两阶段优化策略：前向阶段动态分解任务并构建协作团队；后向阶段通过迭代反馈优化全局和局部协作。", "result": "在四个基准数据集上的实验表明，ANN在相同配置下超越了领先的多智能体基线方法，显示出持续的性能改进。", "conclusion": "ANN提供了一个可扩展、数据驱动的多智能体系统框架，结合了大型语言模型的协作能力和神经网络原理的效率与灵活性。计划开源整个框架。"}}
{"id": "2506.08961", "title": "Towards Robust Deep Reinforcement Learning against Environmental State Perturbation", "authors": ["Chenxu Wang", "Huaping Liu"], "abstract": "Adversarial attacks and robustness in Deep Reinforcement Learning (DRL) have been widely studied in various threat models; however, few consider environmental state perturbations, which are natural in embodied scenarios. To improve the robustness of DRL agents, we formulate the problem of environmental state perturbation, introducing a preliminary non-targeted attack method as a calibration adversary, and then propose a defense framework, named Boosted Adversarial Training (BAT), which first tunes the agents via supervised learning to avoid catastrophic failure and subsequently adversarially trains the agent with reinforcement learning. Extensive experimental results substantiate the vulnerability of mainstream agents under environmental state perturbations and the effectiveness of our proposed attack. The defense results demonstrate that while existing robust reinforcement learning algorithms may not be suitable, our BAT framework can significantly enhance the robustness of agents against environmental state perturbations across various situations.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2506.08961.pdf", "abstract_url": "https://arxiv.org/abs/2506.08961", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了深度强化学习（DRL）在环境状态扰动下的鲁棒性问题，提出了一种名为Boosted Adversarial Training（BAT）的防御框架，旨在通过监督学习和对抗训练增强DRL代理的鲁棒性。", "motivation": "尽管对抗攻击和深度强化学习的鲁棒性已在多种威胁模型中得到广泛研究，但环境状态扰动在具体场景中的自然性却鲜有考虑。本文旨在解决这一问题，提高DRL代理在环境状态扰动下的鲁棒性。", "method": "本文首先通过引入一种初步的非目标攻击方法作为校准对手来制定环境状态扰动问题，随后提出了BAT防御框架。该框架首先通过监督学习调整代理以避免灾难性失败，然后通过强化学习对代理进行对抗训练。", "result": "大量实验结果证实了主流代理在环境状态扰动下的脆弱性以及所提出攻击方法的有效性。防御结果表明，虽然现有的鲁棒强化学习算法可能不适用，但BAT框架能显著增强代理在各种情况下对环境状态扰动的鲁棒性。", "conclusion": "本文提出的BAT框架为增强DRL代理在环境状态扰动下的鲁棒性提供了一种有效方法，弥补了现有研究在这一领域的不足，为未来的研究和应用提供了新的方向。"}}
