{"id": "2509.14566", "title": "DICE: Diffusion Consensus Equilibrium for Sparse-view CT Reconstruction", "authors": ["Leon Suarez-Rodriguez", "Roman Jacome", "Romario Gualdron-Hurtado", "Ana Mantilla-Dulcey", "Henry Arguello"], "abstract": "Sparse-view computed tomography (CT) reconstruction is fundamentally challenging due to undersampling, leading to an ill-posed inverse problem. Traditional iterative methods incorporate handcrafted or learned priors to regularize the solution but struggle to capture the complex structures present in medical images. In contrast, diffusion models (DMs) have recently emerged as powerful generative priors that can accurately model complex image distributions. In this work, we introduce Diffusion Consensus Equilibrium (DICE), a framework that integrates a two-agent consensus equilibrium into the sampling process of a DM. DICE alternates between: (i) a data-consistency agent, implemented through a proximal operator enforcing measurement consistency, and (ii) a prior agent, realized by a DM performing a clean image estimation at each sampling step. By balancing these two complementary agents iteratively, DICE effectively combines strong generative prior capabilities with measurement consistency. Experimental results show that DICE significantly outperforms state-of-the-art baselines in reconstructing high-quality CT images under uniform and non-uniform sparse-view settings of 15, 30, and 60 views (out of a total of 180), demonstrating both its effectiveness and robustness.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "8 pages, 4 figures, confenrence", "pdf_url": "https://arxiv.org/pdf/2509.14566.pdf", "abstract_url": "https://arxiv.org/abs/2509.14566", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "DICE框架通过结合扩散模型和共识平衡，在稀疏视图CT重建中显著优于现有方法，提高了图像质量。", "motivation": "解决稀疏视图CT重建中的欠采样问题，传统方法难以捕捉复杂图像结构。", "method": "使用扩散共识平衡框架，交替数据一致性代理和先验代理（扩散模型）进行迭代优化。", "result": "在15、30和60视图设置下，DICE在均匀和非均匀稀疏视图中优于最先进基线，展示有效性和鲁棒性。", "conclusion": "DICE成功整合生成先验和测量一致性，为CT重建提供高效解决方案。"}}
{"id": "2509.14860", "title": "MARIC: Multi-Agent Reasoning for Image Classification", "authors": ["Wonduk Seo", "Minhyeong Yu", "Hyunjin An", "Seunghyun Lee"], "abstract": "Image classification has traditionally relied on parameter-intensive model training, requiring large-scale annotated datasets and extensive fine tuning to achieve competitive performance. While recent vision language models (VLMs) alleviate some of these constraints, they remain limited by their reliance on single pass representations, often failing to capture complementary aspects of visual content. In this paper, we introduce Multi Agent based Reasoning for Image Classification (MARIC), a multi agent framework that reformulates image classification as a collaborative reasoning process. MARIC first utilizes an Outliner Agent to analyze the global theme of the image and generate targeted prompts. Based on these prompts, three Aspect Agents extract fine grained descriptions along distinct visual dimensions. Finally, a Reasoning Agent synthesizes these complementary outputs through integrated reflection step, producing a unified representation for classification. By explicitly decomposing the task into multiple perspectives and encouraging reflective synthesis, MARIC mitigates the shortcomings of both parameter-heavy training and monolithic VLM reasoning. Experiments on 4 diverse image classification benchmark datasets demonstrate that MARIC significantly outperforms baselines, highlighting the effectiveness of multi-agent visual reasoning for robust and interpretable image classification.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Multiagent Systems (cs.MA)", "comments": "Preprint", "pdf_url": "https://arxiv.org/pdf/2509.14860.pdf", "abstract_url": "https://arxiv.org/abs/2509.14860", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "MARIC 是一个多代理框架，通过协作推理进行图像分类，优于基线方法。", "motivation": "解决传统图像分类依赖参数密集型训练和单次表示的限制，提高鲁棒性和可解释性。", "method": "使用 Outliner Agent 分析全局主题并生成提示，三个 Aspect Agents 提取细粒度描述，Reasoning Agent 合成输出进行分类。", "result": "在 4 个基准数据集上显著超越基线，验证了多代理视觉推理的有效性。", "conclusion": "MARIC 通过多视角分解和反射合成，缓解了参数训练和单次推理的不足，增强了图像分类性能。"}}
{"id": "2509.15159", "title": "AIP: Subverting Retrieval-Augmented Generation via Adversarial Instructional Prompt", "authors": ["Saket S. Chaturvedi", "Gaurav Bagwe", "Lan Zhang", "Xiaoyong Yuan"], "abstract": "Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by retrieving relevant documents from external sources to improve factual accuracy and verifiability. However, this reliance introduces new attack surfaces within the retrieval pipeline, beyond the LLM itself. While prior RAG attacks have exposed such vulnerabilities, they largely rely on manipulating user queries, which is often infeasible in practice due to fixed or protected user inputs. This narrow focus overlooks a more realistic and stealthy vector: instructional prompts, which are widely reused, publicly shared, and rarely audited. Their implicit trust makes them a compelling target for adversaries to manipulate RAG behavior covertly.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Computation and Language (cs.CL)", "comments": "Accepted at EMNLP 2025 Conference", "pdf_url": "https://arxiv.org/pdf/2509.15159.pdf", "abstract_url": "https://arxiv.org/abs/2509.15159", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "论文探讨了通过对抗性指令提示颠覆检索增强生成的攻击方法，揭示RAG系统的新漏洞。", "motivation": "解决RAG系统依赖外部检索引入的攻击面问题，特别是用户查询操纵不切实际时，指令提示的潜在风险。", "method": "利用指令提示的公开性和重用性，设计对抗性提示来操纵RAG行为，提供更隐蔽的攻击向量。", "result": "发现指令提示是可行的攻击目标，能导致RAG系统行为被秘密操控，暴露安全漏洞。", "conclusion": "结论是RAG系统需要加强指令提示的审计和安全措施，以防范此类现实攻击。"}}
{"id": "2509.14267", "title": "Graph-Enhanced Retrieval-Augmented Question Answering for E-Commerce Customer Support", "authors": ["Piyushkumar Patel"], "abstract": "E-Commerce customer support requires quick and accurate answers grounded in product data and past support cases. This paper develops a novel retrieval-augmented generation (RAG) framework that uses knowledge graphs (KGs) to improve the relevance of the answer and the factual grounding. We examine recent advances in knowledge-augmented RAG and chatbots based on large language models (LLM) in customer support, including Microsoft's GraphRAG and hybrid retrieval architectures. We then propose a new answer synthesis algorithm that combines structured subgraphs from a domain-specific KG with text documents retrieved from support archives, producing more coherent and grounded responses. We detail the architecture and knowledge flow of our system, provide comprehensive experimental evaluation, and justify its design in real-time support settings. Our implementation demonstrates 23\\% improvement in factual accuracy and 89\\% user satisfaction in e-Commerce QA scenarios.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Theory (cs.IT)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14267.pdf", "abstract_url": "https://arxiv.org/abs/2509.14267", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Information Theory (cs.IT)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种基于知识图谱的检索增强生成框架，用于提升电子商务客户支持问答的准确性和用户满意度。", "motivation": "解决电子商务客户支持中快速准确回答基于产品数据和历史支持案例的问题，提高事实准确性和相关性。", "method": "结合知识图谱的结构化子图和文本文档检索，开发新的答案合成算法，集成RAG和LLM技术。", "result": "在实验中，事实准确性提高了23%，用户满意度达到89%。", "conclusion": "该方法在实时支持场景中有效，提供了更连贯和基于事实的响应，具有实际应用价值。"}}
{"id": "2509.14257", "title": "From Correction to Mastery: Reinforced Distillation of Large Language Model Agents", "authors": ["Yuanjie Lyu", "Chengyu Wang", "Jun Huang", "Tong Xu"], "abstract": "Large Language Model agents excel at solving complex tasks through iterative reasoning and tool use, but typically depend on ultra-large, costly backbones. Existing distillation approaches train smaller students to imitate full teacher trajectories, yet reasoning and knowledge gaps between the teacher and student often lead to compounding errors. We propose SCoRe, a student-centered framework in which the student generates trajectories and the teacher intervenes only at the first critical error, producing training data matched to the student's ability and exposing specific weaknesses. The student is first fine-tuned on corrected trajectories. Subsequently, short-horizon reinforcement learning starts from the verified prefix before the first critical error, with target rewards assigned at that step. This design encourages autonomous problem-solving beyond imitation and improves training stability. Particularly, on 12 challenging benchmarks, a 7B-parameter student distilled with SCoRe matches the agentic performance of a 72B-parameter teacher.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14257.pdf", "abstract_url": "https://arxiv.org/abs/2509.14257", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "SCoRe是一个学生中心框架，通过教师仅在首次关键错误时干预，结合微调和强化学习，使7B参数学生模型在12个基准上匹配72B教师模型的性能。", "motivation": "解决大型语言模型代理依赖昂贵大模型，以及现有蒸馏方法中学生推理和知识差距导致错误累积的问题。", "method": "使用SCoRe框架，学生生成轨迹，教师干预首次关键错误，进行微调和短视强化学习以鼓励自主解决问题。", "result": "在12个挑战性基准上，7B学生模型达到72B教师模型的代理性能。", "conclusion": "SCoRe有效缩小学生与教师差距，提升训练稳定性和性能，具有实际应用价值。"}}
{"id": "2509.14268", "title": "DetectAnyLLM: Towards Generalizable and Robust Detection of Machine-Generated Text Across Domains and Models", "authors": ["Jiachen Fu", "Chun-Le Guo", "Chongyi Li"], "abstract": "The rapid advancement of large language models (LLMs) has drawn urgent attention to the task of machine-generated text detection (MGTD). However, existing approaches struggle in complex real-world scenarios: zero-shot detectors rely heavily on scoring model's output distribution while training-based detectors are often constrained by overfitting to the training data, limiting generalization. We found that the performance bottleneck of training-based detectors stems from the misalignment between training objective and task needs. To address this, we propose Direct Discrepancy Learning (DDL), a novel optimization strategy that directly optimizes the detector with task-oriented knowledge. DDL enables the detector to better capture the core semantics of the detection task, thereby enhancing both robustness and generalization. Built upon this, we introduce DetectAnyLLM, a unified detection framework that achieves state-of-the-art MGTD performance across diverse LLMs. To ensure a reliable evaluation, we construct MIRAGE, the most diverse multi-task MGTD benchmark. MIRAGE samples human-written texts from 10 corpora across 5 text-domains, which are then re-generated or revised using 17 cutting-edge LLMs, covering a wide spectrum of proprietary models and textual styles. Extensive experiments on MIRAGE reveal the limitations of existing methods in complex environment. In contrast, DetectAnyLLM consistently outperforms them, achieving over a 70% performance improvement under the same training data and base scoring model, underscoring the effectiveness of our DDL. Project page: {", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Computers and Society (cs.CY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14268.pdf", "abstract_url": "https://arxiv.org/abs/2509.14268", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Computers and Society (cs.CY)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种名为Direct Discrepancy Learning (DDL)的新优化策略和DetectAnyLLM框架，用于提高机器生成文本检测的泛化性和鲁棒性，在多样化基准MIRAGE上实现了超过70%的性能提升。", "motivation": "解决现有机器生成文本检测方法在零样本和训练基检测器中泛化能力不足的问题，特别是在复杂真实场景中。", "method": "采用DDL优化策略，直接优化检测器以捕获任务核心语义，并构建DetectAnyLLM统一框架。", "result": "在MIRAGE基准测试中，DetectAnyLLM consistently outperforms existing methods, achieving over a 70% performance improvement。", "conclusion": "DDL和DetectAnyLLM有效提升了检测性能，为机器生成文本检测提供了更通用的解决方案。"}}
{"id": "2509.14289", "title": "From Capabilities to Performance: Evaluating Key Functional Properties of LLM Architectures in Penetration Testing", "authors": ["Lanxiao Huang", "Daksh Dave", "Ming Jin", "Tyler Cody", "Peter Beling"], "abstract": "Large language models (LLMs) are increasingly used to automate or augment penetration testing, but their effectiveness and reliability across attack phases remain unclear. We present a comprehensive evaluation of multiple LLM-based agents, from single-agent to modular designs, across realistic penetration testing scenarios, measuring empirical performance and recurring failure patterns. We also isolate the impact of five core functional capabilities via targeted augmentations: Global Context Memory (GCM), Inter-Agent Messaging (IAM), Context-Conditioned Invocation (CCI), Adaptive Planning (AP), and Real-Time Monitoring (RTM). These interventions support, respectively: (i) context coherence and retention, (ii) inter-component coordination and state management, (iii) tool use accuracy and selective execution, (iv) multi-step strategic planning, error detection, and recovery, and (v) real-time dynamic responsiveness. Our results show that while some architectures natively exhibit subsets of these properties, targeted augmentations substantially improve modular agent performance, especially in complex, multi-step, and real-time penetration testing tasks.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14289.pdf", "abstract_url": "https://arxiv.org/abs/2509.14289", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文评估了多种基于LLM的代理在渗透测试中的性能，通过针对性增强核心功能，显著提升了模块化代理在复杂任务中的表现。", "motivation": "解决LLM在渗透测试中有效性和可靠性不明确的问题，评估不同架构的性能和失败模式。", "method": "使用全面评估方法，比较单代理和模块化设计，并通过针对性增强五个核心功能（GCM、IAM、CCI、AP、RTM）来隔离其影响。", "result": "结果显示，针对性增强显著提高了模块化代理的性能，特别是在复杂、多步骤和实时任务中。", "conclusion": "结论是针对性功能增强可以改善LLM代理在渗透测试中的表现，强调了模块化设计和核心能力的重要性。"}}
{"id": "2509.14382", "title": "Detecting Pipeline Failures through Fine-Grained Analysis of Web Agents", "authors": ["Daniel Röder", "Akhil Juneja", "Roland Roller", "Sven Schmeier"], "abstract": "Web agents powered by large language models (LLMs) can autonomously perform complex, multistep tasks in dynamic web environments. However, current evaluations mostly focus on the overall success while overlooking intermediate errors. This limits insight into failure modes and hinders systematic improvement. This work analyzes existing benchmarks and highlights the lack of fine-grained diagnostic tools. To address this gap, we propose a modular evaluation framework that decomposes agent pipelines into interpretable stages for detailed error analysis. Using the SeeAct framework and the Mind2Web dataset as a case study, we show how this approach reveals actionable weaknesses missed by standard metrics - paving the way for more robust and generalizable web agents.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14382.pdf", "abstract_url": "https://arxiv.org/abs/2509.14382", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种模块化评估框架，用于对基于LLM的Web代理进行细粒度错误分析，以揭示标准指标遗漏的弱点，从而提升代理的鲁棒性和泛化能力。", "motivation": "当前评估主要关注整体成功率，忽略了中间错误，限制了失败模式的洞察和系统改进。", "method": "提出模块化评估框架，将代理管道分解为可解释的阶段，使用SeeAct框架和Mind2Web数据集进行案例研究。", "result": "该方法揭示了标准指标遗漏的可操作弱点，有助于更详细地分析错误。", "conclusion": "该框架为开发更稳健和可泛化的Web代理铺平了道路。"}}
{"id": "2509.14485", "title": "Beyond the high score: Prosocial ability profiles of multi-agent populations", "authors": ["Marko Tesic", "Yue Zhao", "Joel Z. Leibo", "Rakshit S. Trivedi", "Jose Hernandez-Orallo"], "abstract": "The development and evaluation of social capabilities in AI agents require complex environments where competitive and cooperative behaviours naturally emerge. While game-theoretic properties can explain why certain teams or agent populations outperform others, more abstract behaviours, such as convention following, are harder to control in training and evaluation settings. The Melting Pot contest is a social AI evaluation suite designed to assess the cooperation capabilities of AI systems. In this paper, we apply a Bayesian approach known as Measurement Layouts to infer the capability profiles of multi-agent systems in the Melting Pot contest. We show that these capability profiles not only predict future performance within the Melting Pot suite but also reveal the underlying prosocial abilities of agents. Our analysis indicates that while higher prosocial capabilities sometimes correlate with better performance, this is not a universal trend-some lower-scoring agents exhibit stronger cooperation abilities. Furthermore, we find that top-performing contest submissions are more likely to achieve high scores in scenarios where prosocial capabilities are not required. These findings, together with reports that the contest winner used a hard-coded solution tailored to specific environments, suggest that at least one top-performing team may have optimised for conditions where cooperation was not necessary, potentially exploiting limitations in the evaluation framework. We provide recommendations for improving the annotation of cooperation demands and propose future research directions to account for biases introduced by different testing environments. Our results demonstrate that Measurement Layouts offer both strong predictive accuracy and actionable insights, contributing to a more transparent and generalisable approach to evaluating AI systems in complex social settings.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14485.pdf", "abstract_url": "https://arxiv.org/abs/2509.14485", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文使用贝叶斯测量布局方法分析多智能体系统在Melting Pot竞赛中的能力概况，发现亲社会能力与性能非完全相关，并指出评估框架存在偏差，提出改进建议。", "motivation": "解决AI智能体在复杂社会环境中亲社会能力评估的挑战，避免仅依赖高分而忽略合作行为。", "method": "应用贝叶斯测量布局方法推断多智能体系统的能力概况，并分析其在Melting Pot竞赛中的表现。", "result": "亲社会能力有时与性能正相关，但非普遍；高分提交可能在无需合作场景中表现更好，揭示评估框架的局限性。", "conclusion": "测量布局方法提供准确预测和可操作见解，建议改进评估标注以增强透明性和泛化性。"}}
{"id": "2509.14507", "title": "DeKeyNLU: Enhancing Natural Language to SQL Generation through Task Decomposition and Keyword Extraction", "authors": ["Jian Chen", "Zhenyan Chen", "Xuming Hu", "Peilin Zhou", "Yining Hua", "Han Fang", "Cissy Hing Yee Choy", "Xinmei Ke", "Jingfeng Luo", "Zixuan Yuan"], "abstract": "Natural Language to SQL (NL2SQL) provides a new model-centric paradigm that simplifies database access for non-technical users by converting natural language queries into SQL commands. Recent advancements, particularly those integrating Retrieval-Augmented Generation (RAG) and Chain-of-Thought (CoT) reasoning, have made significant strides in enhancing NL2SQL performance. However, challenges such as inaccurate task decomposition and keyword extraction by LLMs remain major bottlenecks, often leading to errors in SQL generation. While existing datasets aim to mitigate these issues by fine-tuning models, they struggle with over-fragmentation of tasks and lack of domain-specific keyword annotations, limiting their effectiveness. To address these limitations, we present DeKeyNLU, a novel dataset which contains 1,500 meticulously annotated QA pairs aimed at refining task decomposition and enhancing keyword extraction precision for the RAG pipeline. Fine-tuned with DeKeyNLU, we propose DeKeySQL, a RAG-based NL2SQL pipeline that employs three distinct modules for user question understanding, entity retrieval, and generation to improve SQL generation accuracy. We benchmarked multiple model configurations within DeKeySQL RAG pipeline. Experimental results demonstrate that fine-tuning with DeKeyNLU significantly improves SQL generation accuracy on both BIRD (62.31% to 69.10%) and Spider (84.2% to 88.7%) dev datasets.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14507.pdf", "abstract_url": "https://arxiv.org/abs/2509.14507", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "DeKeyNLU通过任务分解和关键词提取增强自然语言到SQL生成，提出新数据集和RAG管道DeKeySQL，显著提高SQL生成准确率。", "motivation": "解决NL2SQL中任务分解和关键词提取不准确的问题，现有数据集存在任务过度碎片化和缺乏领域特定关键词注释的局限性。", "method": "创建DeKeyNLU数据集，包含1500个标注QA对，并开发DeKeySQL RAG管道，使用三个模块进行用户问题理解、实体检索和生成。", "result": "在BIRD和Spider数据集上，SQL生成准确率分别从62.31%提升到69.10%和从84.2%提升到88.7%。", "conclusion": "DeKeyNLU和DeKeySQL有效改进NL2SQL性能，为简化数据库访问提供更可靠的方法。"}}
{"id": "2509.14546", "title": "Rationality Check! Benchmarking the Rationality of Large Language Models", "authors": ["Zhilun Zhou", "Jing Yi Wang", "Nicholas Sukiennik", "Chen Gao", "Fengli Xu", "Yong Li", "James Evans"], "abstract": "Large language models (LLMs), a recent advance in deep learning and machine intelligence, have manifested astonishing capacities, now considered among the most promising for artificial general intelligence. With human-like capabilities, LLMs have been used to simulate humans and serve as AI assistants across many applications. As a result, great concern has arisen about whether and under what circumstances LLMs think and behave like real human agents. Rationality is among the most important concepts in assessing human behavior, both in thinking (i.e., theoretical rationality) and in taking action (i.e., practical rationality). In this work, we propose the first benchmark for evaluating the omnibus rationality of LLMs, covering a wide range of domains and LLMs. The benchmark includes an easy-to-use toolkit, extensive experimental results, and analysis that illuminates where LLMs converge and diverge from idealized human rationality. We believe the benchmark can serve as a foundational tool for both developers and users of LLMs.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14546.pdf", "abstract_url": "https://arxiv.org/abs/2509.14546", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了首个评估大型语言模型（LLMs）综合理性的基准，包括工具包、实验结果和分析，以比较LLMs与理想人类理性的异同。", "motivation": "随着LLMs在模拟人类和AI助手应用中广泛使用，需要评估其是否及在何种情况下像真实人类一样思考和行动，理性是评估人类行为的关键概念。", "method": "提出一个基准，涵盖多个领域和LLMs，包括易用工具包、广泛实验和对比分析。", "result": "基准提供了实验结果，揭示了LLMs在理性方面与理想人类行为的收敛和分歧点。", "conclusion": "该基准可作为LLMs开发者和用户的基础工具，促进对LLMs理性的理解和改进。"}}
{"id": "2509.14547", "title": "(P)rior(D)yna(F)low: A Priori Dynamic Workflow Construction via Multi-Agent Collaboration", "authors": ["Yi Lin", "Lujin Zhao", "Yijie Shi"], "abstract": "Recent studies have shown that carefully designed workflows coordinating large language models(LLMs) significantly enhance task-solving capabilities compared to using a single model. While an increasing number of works focus on autonomous workflow construction, most existing approaches rely solely on historical experience, leading to limitations in efficiency and adaptability. We argue that while historical experience is valuable, workflow construction should also flexibly respond to the unique characteristics of each task. To this end, we propose an a priori dynamic framework for automated workflow construction. Our framework first leverages Q-table learning to optimize the decision space, guiding agent decisions and enabling effective use of historical experience. At the same time, agents evaluate the current task progress and make a priori decisions regarding the next executing agent, allowing the system to proactively select the more suitable workflow structure for each given task. Additionally, we incorporate mechanisms such as cold-start initialization, early stopping, and pruning to further improve system efficiency. Experimental evaluations on four benchmark datasets demonstrate the feasibility and effectiveness of our approach. Compared to state-of-the-art baselines, our method achieves an average improvement of 4.05%, while reducing workflow construction and inference costs to only 30.68%-48.31% of those required by existing methods.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14547.pdf", "abstract_url": "https://arxiv.org/abs/2509.14547", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "提出PriorDynaFlow框架，通过多智能体协作和Q表学习优化工作流构建，提高任务解决效率和适应性，实验显示性能提升4.05%，成本降至30.68%-48.31%。", "motivation": "解决现有工作流构建方法仅依赖历史经验导致的效率和适应性不足问题，强调需灵活响应任务特性。", "method": "使用Q表学习优化决策空间，结合智能体评估任务进度和先验决策，并集成冷启动、早停和剪枝机制。", "result": "在四个基准数据集上验证，性能平均提升4.05%，构建和推理成本降至基线方法的30.68%-48.31%。", "conclusion": "框架有效结合历史经验和动态响应，提升工作流构建的效率和适应性，具有实际应用潜力。"}}
{"id": "2509.14647", "title": "AgentCompass: Towards Reliable Evaluation of Agentic Workflows in Production", "authors": ["NVJK Kartik", "Garvit Sapra", "Rishav Hada", "Nikhil Pareek"], "abstract": "With the growing adoption of Large Language Models (LLMs) in automating complex, multi-agent workflows, organizations face mounting risks from errors, emergent behaviors, and systemic failures that current evaluation methods fail to capture. We present AgentCompass, the first evaluation framework designed specifically for post-deployment monitoring and debugging of agentic workflows. AgentCompass models the reasoning process of expert debuggers through a structured, multi-stage analytical pipeline: error identification and categorization, thematic clustering, quantitative scoring, and strategic summarization. The framework is further enhanced with a dual memory system-episodic and semantic-that enables continual learning across executions. Through collaborations with design partners, we demonstrate the framework's practical utility on real-world deployments, before establishing its efficacy against the publicly available TRAIL benchmark. AgentCompass achieves state-of-the-art results on key metrics, while uncovering critical issues missed in human annotations, underscoring its role as a robust, developer-centric tool for reliable monitoring and improvement of agentic systems in production.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14647.pdf", "abstract_url": "https://arxiv.org/abs/2509.14647", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "AgentCompass是一个专为生产环境中多智能体工作流设计的评估框架，通过结构化分析和双记忆系统实现可靠监控和调试。", "motivation": "解决大型语言模型在自动化复杂工作流时产生的错误、涌现行为和系统性故障，当前评估方法无法有效捕捉这些问题。", "method": "采用多阶段分析管道（错误识别、分类、主题聚类、定量评分和战略总结）和双记忆系统（情景和语义记忆）进行持续学习。", "result": "在真实部署和TRAIL基准测试中取得最先进结果，发现人类注释遗漏的关键问题。", "conclusion": "AgentCompass作为开发者中心工具，能可靠监控和改进生产中的智能体系统，具有实际应用价值。"}}
{"id": "2509.14750", "title": "Enhancing Retrieval Augmentation via Adversarial Collaboration", "authors": ["Letian Zhang", "Guanghao Meng", "Xudong Ren", "Yiming Wang", "Shu-Tao Xia"], "abstract": "Retrieval-augmented Generation (RAG) is a prevalent approach for domain-specific LLMs, yet it is often plagued by \"Retrieval Hallucinations\"--a phenomenon where fine-tuned models fail to recognize and act upon poor-quality retrieved documents, thus undermining performance. To address this, we propose the Adversarial Collaboration RAG (AC-RAG) framework. AC-RAG employs two heterogeneous agents: a generalist Detector that identifies knowledge gaps, and a domain-specialized Resolver that provides precise solutions. Guided by a moderator, these agents engage in an adversarial collaboration, where the Detector's persistent questioning challenges the Resolver's expertise. This dynamic process allows for iterative problem dissection and refined knowledge retrieval. Extensive experiments show that AC-RAG significantly improves retrieval accuracy and outperforms state-of-the-art RAG methods across various vertical domains.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14750.pdf", "abstract_url": "https://arxiv.org/abs/2509.14750", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "通过对抗性协作增强检索增强生成（RAG），使用检测器和解析器代理在主持人指导下迭代改进检索准确性，减少检索幻觉。", "motivation": "解决RAG中的检索幻觉问题，即微调模型无法识别低质量检索文档，导致性能下降。", "method": "提出AC-RAG框架，采用异构代理（通用检测器和领域专业解析器）在主持人引导下进行对抗性协作，通过迭代问题分解优化知识检索。", "result": "实验表明AC-RAG显著提高检索准确性，并在多个垂直领域超越最先进的RAG方法。", "conclusion": "AC-RAG框架有效缓解检索幻觉，提升RAG性能，具有广泛的应用潜力。"}}
{"id": "2509.14778", "title": "OpenLens AI: Fully Autonomous Research Agent for Health Infomatics", "authors": ["Yuxiao Cheng", "Jinli Suo"], "abstract": "Health informatics research is characterized by diverse data modalities, rapid knowledge expansion, and the need to integrate insights across biomedical science, data analytics, and clinical practice. These characteristics make it particularly well-suited for agent-based approaches that can automate knowledge exploration, manage complex workflows, and generate clinically meaningful outputs. Recent progress in large language model (LLM)-based agents has demonstrated promising capabilities in literature synthesis, data analysis, and even end-to-end research execution. However, existing systems remain limited for health informatics because they lack mechanisms to interpret medical visualizations and often overlook domain-specific quality requirements. To address these gaps, we introduce OpenLens AI, a fully automated framework tailored to health informatics. OpenLens AI integrates specialized agents for literature review, data analysis, code generation, and manuscript preparation, enhanced by vision-language feedback for medical visualization and quality control for reproducibility. The framework automates the entire research pipeline, producing publication-ready LaTeX manuscripts with transparent and traceable workflows, thereby offering a domain-adapted solution for advancing health informatics research.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14778.pdf", "abstract_url": "https://arxiv.org/abs/2509.14778", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "OpenLens AI是一个专为健康信息学设计的全自动研究代理框架，整合文献综述、数据分析、代码生成和手稿准备，通过视觉语言反馈和质量控制提升可重复性。", "motivation": "解决健康信息学研究中现有LLM代理无法有效解释医学可视化且忽视领域特定质量要求的问题。", "method": "集成专门代理，结合视觉语言反馈进行医学可视化解释和质量控制，自动化整个研究流程。", "result": "框架能自动化生成可发表的LaTeX手稿，提供透明和可追溯的工作流。", "conclusion": "OpenLens AI为健康信息学研究提供了一个领域适应的解决方案，推动该领域的进步。"}}
{"id": "2509.15221", "title": "ScaleCUA: Scaling Open-Source Computer Use Agents with Cross-Platform Data", "authors": ["Zhaoyang Liu", "JingJing Xie", "Zichen Ding", "Zehao Li", "Bowen Yang", "Zhenyu Wu", "Xuehui Wang", "Qiushi Sun", "Shi Liu", "Weiyun Wang", "Shenglong Ye", "Qingyun Li", "Zeyue Tian", "Gen Luo", "Xiangyu Yue", "Biqing Qi", "Kai Chen", "Bowen Zhou", "Yu Qiao", "Qifeng Chen", "Wenhai Wang"], "abstract": "Vision-Language Models (VLMs) have enabled computer use agents (CUAs) that operate GUIs autonomously, showing great potential, yet progress is limited by the lack of large-scale, open-source computer use data and foundation models. In this work, we introduce ScaleCUA, a step toward scaling open-source CUAs. It offers a large-scale dataset spanning 6 operating systems and 3 task domains, built via a closed-loop pipeline uniting automated agents with human experts. Trained on this scaled-up data, ScaleCUA can operate seamlessly across platforms. Specifically, it delivers strong gains over baselines (+26.6 on WebArena-Lite-v2, +10.7 on ScreenSpot-Pro) and sets new state-of-the-art results (94.4% on MMBench-GUI L1-Hard, 60.6% on OSWorld-G, 47.4% on WebArena-Lite-v2). These findings underscore the power of data-driven scaling for general-purpose computer use agents. We will release data, models, and code to advance future research:", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.15221.pdf", "abstract_url": "https://arxiv.org/abs/2509.15221", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "ScaleCUA 是一个开源计算机使用代理，通过大规模跨平台数据集训练，实现自主操作图形用户界面，在多个基准测试中取得显著性能提升。", "motivation": "解决视觉语言模型在计算机使用代理中因缺乏大规模开源数据和基础模型而进展受限的问题。", "method": "使用闭环管道结合自动化代理和人类专家构建大规模数据集，涵盖6个操作系统和3个任务领域，并训练模型实现跨平台无缝操作。", "result": "在基准测试中表现优异，如 WebArena-Lite-v2 提升26.6分，ScreenSpot-Pro 提升10.7分，并在多个数据集上创下新纪录。", "conclusion": "数据驱动的扩展对通用计算机使用代理具有强大潜力，将发布数据、模型和代码以推动未来研究。"}}
{"id": "2509.14998", "title": "A Knowledge-driven Adaptive Collaboration of LLMs for Enhancing Medical Decision-making", "authors": ["Xiao Wu", "Ting-Zhu Huang", "Liang-Jian Deng", "Yanyuan Qiao", "Imran Razzak", "Yutong Xie"], "abstract": "Medical decision-making often involves integrating knowledge from multiple clinical specialties, typically achieved through multidisciplinary teams. Inspired by this collaborative process, recent work has leveraged large language models (LLMs) in multi-agent collaboration frameworks to emulate expert teamwork. While these approaches improve reasoning through agent interaction, they are limited by static, pre-assigned roles, which hinder adaptability and dynamic knowledge integration. To address these limitations, we propose KAMAC, a Knowledge-driven Adaptive Multi-Agent Collaboration framework that enables LLM agents to dynamically form and expand expert teams based on the evolving diagnostic context. KAMAC begins with one or more expert agents and then conducts a knowledge-driven discussion to identify and fill knowledge gaps by recruiting additional specialists as needed. This supports flexible, scalable collaboration in complex clinical scenarios, with decisions finalized through reviewing updated agent comments. Experiments on two real-world medical benchmarks demonstrate that KAMAC significantly outperforms both single-agent and advanced multi-agent methods, particularly in complex clinical scenarios (i.e., cancer prognosis) requiring dynamic, cross-specialty expertise. Our code is publicly available at:", "subjects": "Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "comments": "The paper has been accepted to the EMNLP 2025 Main Conference", "pdf_url": "https://arxiv.org/pdf/2509.14998.pdf", "abstract_url": "https://arxiv.org/abs/2509.14998", "categories": ["Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出KAMAMAC框架，通过知识驱动的自适应多智能体协作，动态组建专家团队以增强医疗决策，在复杂临床场景中显著优于现有方法。", "motivation": "解决现有多智能体协作框架中静态角色分配导致的适应性和动态知识整合不足的问题。", "method": "使用KAMAC框架，从初始专家代理开始，通过知识驱动讨论识别并填补知识空白，动态招募额外专家，支持灵活可扩展的协作。", "result": "在两个真实医疗基准测试中，KAMAC在复杂场景（如癌症预后）中显著优于单智能体和先进多智能体方法。", "conclusion": "KAMAC框架有效模拟多学科团队协作，提升医疗决策的适应性和准确性，代码已公开。"}}
{"id": "2509.15219", "title": "Out-of-Sight Trajectories: Tracking, Fusion, and Prediction", "authors": ["Haichao Zhang", "Yi Xu", "Yun Fu"], "abstract": "Trajectory prediction is a critical task in computer vision and autonomous systems, playing a key role in autonomous driving, robotics, surveillance, and virtual reality. Existing methods often rely on complete and noise-free observational data, overlooking the challenges associated with out-of-sight objects and the inherent noise in sensor data caused by limited camera coverage, obstructions, and the absence of ground truth for denoised trajectories. These limitations pose safety risks and hinder reliable prediction in real-world scenarios. In this extended work, we present advancements in Out-of-Sight Trajectory (OST), a novel task that predicts the noise-free visual trajectories of out-of-sight objects using noisy sensor data. Building on our previous research, we broaden the scope of Out-of-Sight Trajectory Prediction (OOSTraj) to include pedestrians and vehicles, extending its applicability to autonomous driving, robotics, surveillance, and virtual reality. Our enhanced Vision-Positioning Denoising Module leverages camera calibration to establish a vision-positioning mapping, addressing the lack of visual references, while effectively denoising noisy sensor data in an unsupervised manner. Through extensive evaluations on the Vi-Fi and JRDB datasets, our approach achieves state-of-the-art performance in both trajectory denoising and prediction, significantly surpassing previous baselines. Additionally, we introduce comparisons with traditional denoising methods, such as Kalman filtering, and adapt recent trajectory prediction models to our task, providing a comprehensive benchmark. This work represents the first initiative to integrate vision-positioning projection for denoising noisy sensor trajectories of out-of-sight agents, paving the way for future advances. The code and preprocessed datasets are available at", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Multiagent Systems (cs.MA); Multimedia (cs.MM); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.15219.pdf", "abstract_url": "https://arxiv.org/abs/2509.15219", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Machine Learning (cs.LG)", "Multiagent Systems (cs.MA)", "Multimedia (cs.MM)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了Out-of-Sight Trajectory (OST)任务，通过Vision-Positioning Denoising Module在无监督方式下去噪传感器数据并预测视线外物体的轨迹，在Vi-Fi和JRDB数据集上达到最先进性能。", "motivation": "解决现有方法依赖完整无噪声观测数据的问题，处理视线外物体和传感器噪声带来的安全风险，提升自动驾驶、机器人等领域的可靠预测。", "method": "使用Vision-Positioning Denoising Module，基于相机标定建立视觉-定位映射，以无监督方式去噪传感器数据，并扩展应用到行人和车辆。", "result": "在Vi-Fi和JRDB数据集上，轨迹去噪和预测性能显著超越基线，并与卡尔曼滤波等传统方法比较，提供全面基准。", "conclusion": "首次集成视觉-定位投影用于视线外代理的去噪，为未来进展铺平道路，代码和数据集已公开。"}}
{"id": "2509.14435", "title": "Causal-Counterfactual RAG: The Integration of Causal-Counterfactual Reasoning into RAG", "authors": ["Harshad Khadilkar", "Abhay Gupta"], "abstract": "Large language models (LLMs) have transformed natural language processing (NLP), enabling diverse applications by integrating large-scale pre-trained knowledge. However, their static knowledge limits dynamic reasoning over external information, especially in knowledge-intensive domains. Retrieval-Augmented Generation (RAG) addresses this challenge by combining retrieval mechanisms with generative modeling to improve contextual understanding. Traditional RAG systems suffer from disrupted contextual integrity due to text chunking and over-reliance on semantic similarity for retrieval, often resulting in shallow and less accurate responses. We propose Causal-Counterfactual RAG, a novel framework that integrates explicit causal graphs representing cause-effect relationships into the retrieval process and incorporates counterfactual reasoning grounded on the causal structure. Unlike conventional methods, our framework evaluates not only direct causal evidence but also the counterfactuality of associated causes, combining results from both to generate more robust, accurate, and interpretable answers. By leveraging causal pathways and associated hypothetical scenarios, Causal-Counterfactual RAG preserves contextual coherence, reduces hallucination, and enhances reasoning fidelity.", "subjects": "Computation and Language (cs.CL); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14435.pdf", "abstract_url": "https://arxiv.org/abs/2509.14435", "categories": ["Computation and Language (cs.CL)", "Information Retrieval (cs.IR)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "提出Causal-Counterfactual RAG框架，通过整合因果图和反事实推理，改进RAG系统，提升答案的准确性、鲁棒性和可解释性。", "motivation": "解决传统RAG系统因文本分块和过度依赖语义相似性导致的上下文完整性破坏和浅层响应问题。", "method": "集成显式因果图到检索过程，并结合基于因果结构的反事实推理，评估直接因果证据和反事实性。", "result": "框架通过因果路径和假设场景，保持上下文连贯性，减少幻觉，增强推理保真度。", "conclusion": "Causal-Counterfactual RAG能生成更稳健、准确和可解释的答案，适用于知识密集型领域。"}}
{"id": "2509.14477", "title": "Ticket-Bench: A Kickoff for Multilingual and Regionalized Agent Evaluation", "authors": ["Thales Sales Almeida", "João Guilherme Alves Santos", "Thiago Laitz", "Giovana Kerche Bonás"], "abstract": "Large language models (LLMs) are increasingly deployed as task-oriented agents, where success depends on their ability to generate accurate function calls under realistic, multilingual conditions. However, existing agent evaluations largely overlook cultural and linguistic diversity, often relying on monolingual or naively translated benchmarks. We introduce Ticket-Bench, a benchmark for multilingual agent evaluation in task-oriented scenarios. Ticket-Bench simulates the domain of soccer ticket purchases across six major languages: Portuguese, English, Spanish, German, Italian, and French. Using localized teams, cities, and user profiles to provide a higher level of realism. We evaluate a wide range of commercial and open-source LLMs, measuring function-calling accuracy and consistency across languages. Results show that reasoning-oriented models (e.g., GPT-5, Qwen3-235B) dominate performance but still exhibit notable cross-lingual disparities. These findings underscore the need for culturally aware, multilingual benchmarks to guide the development of robust LLM agents.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14477.pdf", "abstract_url": "https://arxiv.org/abs/2509.14477", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "介绍Ticket-Bench基准，用于多语言代理评估，模拟足球票购买任务，覆盖六种语言，评估LLM在功能调用准确性和一致性方面的表现。", "motivation": "解决现有代理评估忽视文化和语言多样性问题，依赖单语或简单翻译基准的局限性。", "method": "创建Ticket-Bench基准，模拟多语言足球票购买场景，使用本地化数据评估商业和开源LLM的功能调用准确性。", "result": "推理导向模型（如GPT-5、Qwen3-235B）性能领先，但存在显著的跨语言差异。", "conclusion": "强调需要文化感知的多语言基准，以指导开发更稳健的LLM代理。"}}
{"id": "2509.14480", "title": "Process-Supervised Reinforcement Learning for Interactive Multimodal Tool-Use Agents", "authors": ["Weiting Tan", "Xinghua Qu", "Ming Tu", "Meng Ge", "Andy T. Liu", "Philipp Koehn", "Lu Lu"], "abstract": "Effective interactive tool use requires agents to master Tool Integrated Reasoning (TIR): a complex process involving multi-turn planning and long-context dialogue management. To train agents for this dynamic process, particularly in multi-modal contexts, we introduce a sandbox environment for reinforcement learning (RL) that supports interleaved speech-text rollouts. Our core strategy, Turn-level Adjudicated Reinforcement Learning (TARL), addresses the challenge of credit assignment in long-horizon tasks by employing a Large Language Model (LLM) as a judge to provide turn-level evaluation. To enhance exploration, we integrate a mixed-task training curriculum with mathematical reasoning problems. This unified approach boosts the task pass rate on the text-based $\\tau$-bench by over 6% compared to strong RL baselines. Crucially, we demonstrate our framework's suitability for fine-tuning a multi-modal foundation model for agentic tasks. By training a base multi-modal LLM on interleaved speech-text rollouts, we equip it with tool-use abilities, paving the way for more natural, voice-driven interactive agents.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14480.pdf", "abstract_url": "https://arxiv.org/abs/2509.14480", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种用于交互式多模态工具使用代理的流程监督强化学习方法，通过TARL策略和LLM法官改进信用分配，结合混合任务课程提升性能，并在文本和多模态基准上验证有效性。", "motivation": "解决在动态多模态环境中，代理需要掌握工具集成推理（TIR）的挑战，包括多轮规划和长上下文对话管理，以训练更有效的交互式代理。", "method": "使用沙盒环境进行强化学习，采用Turn-level Adjudicated Reinforcement Learning (TARL)策略，利用大型语言模型（LLM）作为法官提供回合级评估，并结合数学推理问题的混合任务课程来增强探索。", "result": "在文本基准τ-bench上，任务通过率比强RL基线提高了超过6%，并成功微调了多模态基础模型，使其具备工具使用能力。", "conclusion": "该框架为开发更自然的语音驱动交互代理铺平了道路，展示了在多模态环境中训练代理的有效性和适用性。"}}
{"id": "2509.14956", "title": "Sentinel Agents for Secure and Trustworthy Agentic AI in Multi-Agent Systems", "authors": ["Diego Gosmar", "Deborah A. Dahl"], "abstract": "This paper proposes a novel architectural framework aimed at enhancing security and reliability in multi-agent systems (MAS). A central component of this framework is a network of Sentinel Agents, functioning as a distributed security layer that integrates techniques such as semantic analysis via large language models (LLMs), behavioral analytics, retrieval-augmented verification, and cross-agent anomaly detection. Such agents can potentially oversee inter-agent communications, identify potential threats, enforce privacy and access controls, and maintain comprehensive audit records. Complementary to the idea of Sentinel Agents is the use of a Coordinator Agent. The Coordinator Agent supervises policy implementation, and manages agent participation. In addition, the Coordinator also ingests alerts from Sentinel Agents. Based on these alerts, it can adapt policies, isolate or quarantine misbehaving agents, and contain threats to maintain the integrity of the MAS ecosystem. This dual-layered security approach, combining the continuous monitoring of Sentinel Agents with the governance functions of Coordinator Agents, supports dynamic and adaptive defense mechanisms against a range of threats, including prompt injection, collusive agent behavior, hallucinations generated by LLMs, privacy breaches, and coordinated multi-agent attacks. In addition to the architectural design, we present a simulation study where 162 synthetic attacks of different families (prompt injection, hallucination, and data exfiltration) were injected into a multi-agent conversational environment. The Sentinel Agents successfully detected the attack attempts, confirming the practical feasibility of the proposed monitoring approach. The framework also offers enhanced system observability, supports regulatory compliance, and enables policy evolution over time.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "25 pages, 12 figures", "pdf_url": "https://arxiv.org/pdf/2509.14956.pdf", "abstract_url": "https://arxiv.org/abs/2509.14956", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种新颖的多智能体系统安全框架，通过哨兵智能体和协调智能体实现分布式监控和治理，增强安全性和可靠性。", "motivation": "解决多智能体系统中的安全威胁，如提示注入、幻觉和隐私泄露，以提高系统的信任度和可靠性。", "method": "使用哨兵智能体进行语义分析、行为分析和异常检测，结合协调智能体管理策略和威胁响应。", "result": "在模拟攻击测试中，哨兵智能体成功检测了162次合成攻击，验证了方法的可行性。", "conclusion": "该框架提供动态防御机制，支持系统可观测性和合规性，具有实际应用潜力。"}}
{"id": "2509.15076", "title": "Forecasting and Visualizing Air Quality from Sky Images with Vision-Language Models", "authors": ["Mohammad Saleh Vahdatpour", "Maryam Eyvazi", "Yanqing Zhang"], "abstract": "Air pollution remains a critical threat to public health and environmental sustainability, yet conventional monitoring systems are often constrained by limited spatial coverage and accessibility. This paper proposes an AI-driven agent that predicts ambient air pollution levels from sky images and synthesizes realistic visualizations of pollution scenarios using generative modeling. Our approach combines statistical texture analysis with supervised learning for pollution classification, and leverages vision-language model (VLM)-guided image generation to produce interpretable representations of air quality conditions. The generated visuals simulate varying degrees of pollution, offering a foundation for user-facing interfaces that improve transparency and support informed environmental decision-making. These outputs can be seamlessly integrated into intelligent applications aimed at enhancing situational awareness and encouraging behavioral responses based on real-time forecasts. We validate our method using a dataset of urban sky images and demonstrate its effectiveness in both pollution level estimation and semantically consistent visual synthesis. The system design further incorporates human-centered user experience principles to ensure accessibility, clarity, and public engagement in air quality forecasting. To support scalable and energy-efficient deployment, future iterations will incorporate a green CNN architecture enhanced with FPGA-based incremental learning, enabling real-time inference on edge platforms.", "subjects": "Machine Learning (cs.LG); Computer Vision and Pattern Recognition (cs.CV)", "comments": "Published at ICCVW 2025", "pdf_url": "https://arxiv.org/pdf/2509.15076.pdf", "abstract_url": "https://arxiv.org/abs/2509.15076", "categories": ["Machine Learning (cs.LG)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出一种AI代理，利用天空图像预测空气质量并生成污染可视化，结合统计纹理分析和监督学习进行分类，通过VLM引导生成可解释图像，验证有效并支持实时应用。", "motivation": "解决传统空气质量监测系统空间覆盖有限和可访问性不足的问题，以改善公共健康和环境可持续性。", "method": "结合统计纹理分析和监督学习进行污染分类，利用视觉语言模型引导图像生成，并采用以人为本的用户体验设计。", "result": "方法在数据集上验证有效，能准确估计污染水平并生成语义一致的视觉合成，支持实时预测和用户界面集成。", "conclusion": "系统可提升透明度和环境决策，未来将集成绿色CNN和FPGA学习以实现可扩展、节能的实时边缘部署。"}}
{"id": "2509.15172", "title": "Internalizing Self-Consistency in Language Models: Multi-Agent Consensus Alignment", "authors": ["Ankur Samanta", "Akshayaa Magesh", "Youliang Yu", "Runzhe Wu", "Ayush Jain", "Daniel Jiang", "Boris Vidolov", "Paul Sajda", "Yonathan Efroni", "Kaveh Hassani"], "abstract": "Language Models (LMs) are inconsistent reasoners, often generating contradictory responses to identical prompts. While inference-time methods can mitigate these inconsistencies, they fail to address the core problem: LMs struggle to reliably select reasoning pathways leading to consistent outcomes under exploratory sampling. To address this, we formalize self-consistency as an intrinsic property of well-aligned reasoning models and introduce Multi-Agent Consensus Alignment (MACA), a reinforcement learning framework that post-trains models to favor reasoning trajectories aligned with their internal consensus using majority/minority outcomes from multi-agent debate. These trajectories emerge from deliberative exchanges where agents ground reasoning in peer arguments, not just aggregation of independent attempts, creating richer consensus signals than single-round majority voting. MACA enables agents to teach themselves to be more decisive and concise, and better leverage peer insights in multi-agent settings without external supervision, driving substantial improvements across self-consistency (+27.6% on GSM8K), single-agent reasoning (+23.7% on MATH), sampling-based inference (+22.4% Pass@20 on MATH), and multi-agent ensemble decision-making (+42.7% on MathQA). These findings, coupled with strong generalization to unseen benchmarks (+16.3% on GPQA, +11.6% on CommonsenseQA), demonstrate robust self-alignment that more reliably unlocks latent reasoning potential of language models.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.15172.pdf", "abstract_url": "https://arxiv.org/abs/2509.15172", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文提出多智能体共识对齐（MACA）框架，通过强化学习训练语言模型，使其在推理中偏好与内部共识一致的路径，显著提升自一致性、推理能力和泛化性能。", "motivation": "解决语言模型在相同提示下生成矛盾响应的不一致性问题，传统推理时方法未能从根本上改善模型选择一致推理路径的能力。", "method": "使用多智能体辩论的多数/少数结果，通过强化学习后训练模型，使智能体在审议交换中基于同伴论证而非独立尝试的聚合来形成共识信号。", "result": "在多个基准测试中取得显著改进，如自一致性（GSM8K +27.6%）、单智能体推理（MATH +23.7%）、采样推理（MATH Pass@20 +22.4%）和多智能体决策（MathQA +42.7%），并在未见基准上表现出强泛化能力（GPQA +16.3%，CommonsenseQA +11.6%）。", "conclusion": "MACA框架实现了语言模型的稳健自对齐，更可靠地释放其潜在推理潜力，无需外部监督即可提升智能体的决策力和简洁性。"}}
{"id": "2509.14635", "title": "SWE-QA: Can Language Models Answer Repository-level Code Questions?", "authors": ["Weihan Peng", "Yuling Shi", "Yuhang Wang", "Xinyun Zhang", "Beijun Shen", "Xiaodong Gu"], "abstract": "Understanding and reasoning about entire software repositories is an essential capability for intelligent software engineering tools. While existing benchmarks such as CoSQA and CodeQA have advanced the field, they predominantly focus on small, self-contained code snippets. These setups fail to capture the complexity of real-world repositories, where effective understanding and reasoning often require navigating multiple files, understanding software architecture, and grounding answers in long-range code dependencies. In this paper, we present SWE-QA, a repository-level code question answering (QA) benchmark designed to facilitate research on automated QA systems in realistic code environments. SWE-QA involves 576 high-quality question-answer pairs spanning diverse categories, including intention understanding, cross-file reasoning, and multi-hop dependency analysis. To construct SWE-QA, we first crawled 77,100 GitHub issues from 11 popular repositories. Based on an analysis of naturally occurring developer questions extracted from these issues, we developed a two-level taxonomy of repository-level questions and constructed a set of seed questions for each category. For each category, we manually curated and validated questions and collected their corresponding answers. As a prototype application, we further develop SWE-QA-Agent, an agentic framework in which LLM agents reason and act to find answers automatically. We evaluate six advanced LLMs on SWE-QA under various context augmentation strategies. Experimental results highlight the promise of LLMs, particularly our SWE-QA-Agent framework, in addressing repository-level QA, while also revealing open challenges and pointing to future research directions.", "subjects": "Computation and Language (cs.CL); Programming Languages (cs.PL); Software Engineering (cs.SE)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2509.14635.pdf", "abstract_url": "https://arxiv.org/abs/2509.14635", "categories": ["Computation and Language (cs.CL)", "Programming Languages (cs.PL)", "Software Engineering (cs.SE)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了SWE-QA，一个仓库级代码问答基准，用于评估语言模型在复杂软件仓库环境中的能力，并开发了SWE-QA-Agent框架进行实验验证。", "motivation": "现有基准如CoSQA和CodeQA主要关注小代码片段，无法捕捉真实仓库的复杂性，需要解决多文件导航、软件架构理解和长距离依赖推理的问题。", "method": "通过爬取GitHub问题构建576个高质量问答对，开发两级分类法，并创建SWE-QA-Agent框架，使用LLM代理进行自动推理和答案查找，评估多种上下文增强策略。", "result": "实验显示LLMs（特别是SWE-QA-Agent）在仓库级问答中表现出潜力，但也揭示了开放挑战，为未来研究指明方向。", "conclusion": "SWE-QA推动了自动化问答系统在真实代码环境中的研究，强调了LLMs的应用前景和需进一步解决的问题。"}}
{"id": "2509.14671", "title": "TableDART: Dynamic Adaptive Multi-Modal Routing for Table Understanding", "authors": ["Xiaobo Xing", "Wei Yuan", "Tong Chen", "Quoc Viet Hung Nguyen", "Xiangliang Zhang", "Hongzhi Yin"], "abstract": "Modeling semantic and structural information from tabular data remains a core challenge for effective table understanding. Existing Table-as-Text approaches flatten tables for large language models (LLMs), but lose crucial structural cues, while Table-as-Image methods preserve structure yet struggle with fine-grained semantics. Recent Table-as-Multimodality strategies attempt to combine textual and visual views, but they (1) statically process both modalities for every query-table pair within a large multimodal LLMs (MLLMs), inevitably introducing redundancy and even conflicts, and (2) depend on costly fine-tuning of MLLMs. In light of this, we propose TableDART, a training-efficient framework that integrates multimodal views by reusing pretrained single-modality models. TableDART introduces a lightweight 2.59M-parameter MLP gating network that dynamically selects the optimal path (either Text-only, Image-only, or Fusion) for each table-query pair, effectively reducing redundancy and conflicts from both modalities. In addition, we propose a novel agent to mediate cross-modal knowledge integration by analyzing outputs from text- and image-based models, either selecting the best result or synthesizing a new answer through reasoning. This design avoids the prohibitive costs of full MLLM fine-tuning. Extensive experiments on seven benchmarks show that TableDART establishes new state-of-the-art performance among open-source models, surpassing the strongest baseline by an average of 4.02%. The code is available at:", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14671.pdf", "abstract_url": "https://arxiv.org/abs/2509.14671", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "TableDART 是一个高效的框架，通过动态选择文本、图像或融合路径，结合预训练单模态模型，减少冗余和冲突，提升表格理解性能。", "motivation": "解决现有表格理解方法在语义和结构信息处理上的不足，如静态多模态处理导致冗余、冲突和高成本微调问题。", "method": "使用轻量级 MLP 门控网络动态选择最优路径，并通过代理中介跨模态知识整合，避免全 MLLM 微调。", "result": "在七个基准测试中，TableDART 平均超越最强基线 4.02%，达到开源模型中的新 SOTA 性能。", "conclusion": "TableDART 提供了一种训练高效的方法，有效结合多模态视图，提升表格理解的准确性和效率。"}}
{"id": "2509.14265", "title": "Evolution of Kernels: Automated RISC-V Kernel Optimization with Large Language Models", "authors": ["Siyuan Chen", "Zhichao Lu", "Qingfu Zhang"], "abstract": "Automated kernel design is critical for overcoming software ecosystem barriers in emerging hardware platforms like RISC-V. While large language models (LLMs) have shown promise for automated kernel optimization, demonstrating success in CUDA domains with comprehensive technical documents and mature codebases, their effectiveness remains unproven for reference-scarce domains like RISC-V. We present Evolution of Kernels (EoK), a novel LLM-based evolutionary program search framework that automates kernel design for domains with limited reference material. EoK mitigates reference scarcity by mining and formalizing reusable optimization ideas (general design principles + actionable thoughts) from established kernel libraries' development histories; it then guides parallel LLM explorations using these ideas, enriched via Retrieval-Augmented Generation (RAG) with RISC-V-specific context, prioritizing historically effective techniques. Empirically, EoK achieves a median 1.27x speedup, surpassing human experts on all 80 evaluated kernel design tasks and improving upon prior LLM-based automated kernel design methods by 20%. These results underscore the viability of incorporating human experience into emerging domains and highlight the immense potential of LLM-based automated kernel optimization.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": "Technical report", "pdf_url": "https://arxiv.org/pdf/2509.14265.pdf", "abstract_url": "https://arxiv.org/abs/2509.14265", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出EoK框架，利用LLM和进化搜索自动化RISC-V内核优化，通过挖掘历史优化理念和RAG技术，在参考稀缺领域实现1.27倍中位加速，超越人类专家和现有方法。", "motivation": "解决RISC-V等新兴硬件平台因参考材料稀缺而难以自动化内核优化的问题，弥补LLM在此类领域的不足。", "method": "基于LLM的进化程序搜索框架，从成熟内核库开发历史中挖掘可重用优化理念，结合RAG技术注入RISC-V特定上下文，指导并行LLM探索。", "result": "在80个内核设计任务中，EoK实现中位1.27倍加速，优于人类专家和先前LLM方法20%。", "conclusion": "EoK证明将人类经验融入新兴领域的可行性，突显LLM在自动化内核优化中的巨大潜力。"}}
{"id": "2509.14276", "title": "Constructive Conflict-Driven Multi-Agent Reinforcement Learning for Strategic Diversity", "authors": ["Yuxiang Mai", "Qiyue Yin", "Wancheng Ni", "Pei Xu", "Kaiqi Huang"], "abstract": "In recent years, diversity has emerged as a useful mechanism to enhance the efficiency of multi-agent reinforcement learning (MARL). However, existing methods predominantly focus on designing policies based on individual agent characteristics, often neglecting the interplay and mutual influence among agents during policy formation. To address this gap, we propose Competitive Diversity through Constructive Conflict (CoDiCon), a novel approach that incorporates competitive incentives into cooperative scenarios to encourage policy exchange and foster strategic diversity among agents. Drawing inspiration from sociological research, which highlights the benefits of moderate competition and constructive conflict in group decision-making, we design an intrinsic reward mechanism using ranking features to introduce competitive motivations. A centralized intrinsic reward module generates and distributes varying reward values to agents, ensuring an effective balance between competition and cooperation. By optimizing the parameterized centralized reward module to maximize environmental rewards, we reformulate the constrained bilevel optimization problem to align with the original task objectives. We evaluate our algorithm against state-of-the-art methods in the SMAC and GRF environments. Experimental results demonstrate that CoDiCon achieves superior performance, with competitive intrinsic rewards effectively promoting diverse and adaptive strategies among cooperative agents.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": "Accepted by IJCAI 2025", "pdf_url": "https://arxiv.org/pdf/2509.14276.pdf", "abstract_url": "https://arxiv.org/abs/2509.14276", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出CoDiCon方法，通过引入竞争性内在奖励促进多智能体强化学习中的战略多样性，在SMAC和GRF环境中优于现有方法。", "motivation": "解决现有MARL方法忽视智能体间相互影响，导致政策形成中缺乏战略多样性的问题。", "method": "使用基于排名的内在奖励机制，通过中央模块平衡竞争与合作，并优化双层优化问题以对齐任务目标。", "result": "实验显示CoDiCon性能优越，能有效促进智能体间多样和自适应策略。", "conclusion": "CoDiCon通过建设性冲突增强MARL效率，为多智能体系统提供了改进策略多样性的有效途径。"}}
{"id": "2509.14284", "title": "The Sum Leaks More Than Its Parts: Compositional Privacy Risks and Mitigations in Multi-Agent Collaboration", "authors": ["Vaidehi Patil", "Elias Stengel-Eskin", "Mohit Bansal"], "abstract": "As large language models (LLMs) become integral to multi-agent systems, new privacy risks emerge that extend beyond memorization, direct inference, or single-turn evaluations. In particular, seemingly innocuous responses, when composed across interactions, can cumulatively enable adversaries to recover sensitive information, a phenomenon we term compositional privacy leakage. We present the first systematic study of such compositional privacy leaks and possible mitigation methods in multi-agent LLM systems. First, we develop a framework that models how auxiliary knowledge and agent interactions jointly amplify privacy risks, even when each response is benign in isolation. Next, to mitigate this, we propose and evaluate two defense strategies: (1) Theory-of-Mind defense (ToM), where defender agents infer a questioner's intent by anticipating how their outputs may be exploited by adversaries, and (2) Collaborative Consensus Defense (CoDef), where responder agents collaborate with peers who vote based on a shared aggregated state to restrict sensitive information spread. Crucially, we balance our evaluation across compositions that expose sensitive information and compositions that yield benign inferences. Our experiments quantify how these defense strategies differ in balancing the privacy-utility trade-off. We find that while chain-of-thought alone offers limited protection to leakage (~39% sensitive blocking rate), our ToM defense substantially improves sensitive query blocking (up to 97%) but can reduce benign task success. CoDef achieves the best balance, yielding the highest Balanced Outcome (79.8%), highlighting the benefit of combining explicit reasoning with defender collaboration. Together, our results expose a new class of risks in collaborative LLM deployments and provide actionable insights for designing safeguards against compositional, context-driven privacy leakage.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2509.14284.pdf", "abstract_url": "https://arxiv.org/abs/2509.14284", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究了多智能体LLM系统中的组合隐私泄漏风险，提出了ToM和CoDef两种防御策略，实验表明CoDef在隐私与效用间取得最佳平衡。", "motivation": "解决多智能体系统中看似无害的响应在组合后导致敏感信息泄露的新隐私风险。", "method": "开发框架建模风险，提出并评估ToM防御（基于意图推理）和CoDef防御（基于协作共识）。", "result": "ToM防御显著提升敏感查询阻止率（达97%），但降低良性任务成功率；CoDef实现最高平衡结果（79.8%）。", "conclusion": "揭示了协作LLM部署中的新风险，提供了可操作的防御设计见解，强调组合推理与协作的重要性。"}}
{"id": "2509.14834", "title": "LLM Agents at the Roundtable: A Multi-Perspective and Dialectical Reasoning Framework for Essay Scoring", "authors": ["Jinhee Jang", "Ayoung Moon", "Minkyoung Jung", "YoungBin Kim. Seung Jin Lee"], "abstract": "The emergence of large language models (LLMs) has brought a new paradigm to automated essay scoring (AES), a long-standing and practical application of natural language processing in education. However, achieving human-level multi-perspective understanding and judgment remains a challenge. In this work, we propose Roundtable Essay Scoring (RES), a multi-agent evaluation framework designed to perform precise and human-aligned scoring under a zero-shot setting. RES constructs evaluator agents based on LLMs, each tailored to a specific prompt and topic context. Each agent independently generates a trait-based rubric and conducts a multi-perspective evaluation. Then, by simulating a roundtable-style discussion, RES consolidates individual evaluations through a dialectical reasoning process to produce a final holistic score that more closely aligns with human evaluation. By enabling collaboration and consensus among agents with diverse evaluation perspectives, RES outperforms prior zero-shot AES approaches. Experiments on the ASAP dataset using ChatGPT and Claude show that RES achieves up to a 34.86% improvement in average QWK over straightforward prompting (Vanilla) methods.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14834.pdf", "abstract_url": "https://arxiv.org/abs/2509.14834", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了RES框架，利用多智能体LLM进行零样本论文评分，通过圆桌讨论和辩证推理提高与人类评估的一致性，在ASAP数据集上表现优于现有方法。", "motivation": "解决自动论文评分中实现人类多视角理解和判断的挑战。", "method": "构建基于LLM的评估器智能体，每个智能体独立生成评分标准并进行多视角评估，通过模拟圆桌讨论进行辩证推理以整合分数。", "result": "在ASAP数据集上，RES比Vanilla方法在平均QWK上提高了34.86%。", "conclusion": "RES框架通过多智能体协作和共识，提升了零样本论文评分的准确性和人类对齐性。"}}
{"id": "2509.14279", "title": "Towards Robust Agentic CUDA Kernel Benchmarking, Verification, and Optimization", "authors": ["Robert Tjarko Lange", "Qi Sun", "Aaditya Prasad", "Maxence Faldor", "Yujin Tang", "David Ha"], "abstract": "Recent advances in large language models (LLMs) demonstrate their effectiveness in scaling test-time compute for software engineering tasks. However, these approaches often focus on high-level solutions, with limited attention to optimizing low-level CUDA kernel implementations. Additionally, existing kernel generation benchmarks suffer from exploitable loopholes and insufficient diversity in testing conditions, hindering true generalization assessment. To address these limitations, we introduce robust-kbench, a new benchmark for rigorous evaluation of kernel performance and correctness across varied scenarios. Furthermore, we present a comprehensive agentic framework that automates CUDA kernel discovery, verification, and optimization. This pipeline enables frontier LLMs to translate torch code to CUDA kernels and iteratively improve their runtime within our robust evaluation setting. Our sequential workflow first translates PyTorch code into equivalent CUDA kernels. It then optimizes their runtime using a novel evolutionary meta-generation procedure tailored to the CUDA ecosystem, guided by LLM-based verifiers for correctness and efficient filtering. Evaluated on robust-kbench, our approach produces CUDA kernels outperforming torch implementations for practical applications, including forward and backward passes. It can fuse operations and deploy various runtime optimization strategies. The verifier workflow accurately classifies incorrect kernels, enhancing hardware verification efficiency.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "62 pages, 10 figures", "pdf_url": "https://arxiv.org/pdf/2509.14279.pdf", "abstract_url": "https://arxiv.org/abs/2509.14279", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了robust-kbench基准和自动化框架，用于CUDA内核的生成、验证和优化，利用LLM提升性能。", "motivation": "解决现有LLM方法在CUDA内核优化中的不足，如基准测试漏洞和多样性缺乏，以评估和提升泛化能力。", "method": "使用代理框架，将PyTorch代码翻译为CUDA内核，并通过进化元生成和基于LLM的验证器进行迭代优化。", "result": "在robust-kbench上评估，生成的CUDA内核性能优于torch实现，支持操作融合和多种优化策略，验证器能准确分类错误内核。", "conclusion": "该框架有效自动化CUDA内核优化，提高硬件验证效率，适用于实际应用。"}}
{"id": "2509.14436", "title": "When Content is Goliath and Algorithm is David: The Style and Semantic Effects of Generative Search Engine", "authors": ["Lijia Ma", "Juan Qin", "Xingchen Xu", "Yong Tan"], "abstract": "Generative search engines (GEs) leverage large language models (LLMs) to deliver AI-generated summaries with website citations, establishing novel traffic acquisition channels while fundamentally altering the search engine optimization landscape. To investigate the distinctive characteristics of GEs, we collect data through interactions with Google's generative and conventional search platforms, compiling a dataset of approximately ten thousand websites across both channels. Our empirical analysis reveals that GEs exhibit preferences for citing content characterized by significantly higher predictability for underlying LLMs and greater semantic similarity among selected sources. Through controlled experiments utilizing retrieval augmented generation (RAG) APIs, we demonstrate that these citation preferences emerge from intrinsic LLM tendencies to favor content aligned with their generative expression patterns. Motivated by applications of LLMs to optimize website content, we conduct additional experimentation to explore how LLM-based content polishing by website proprietors alters AI summaries, finding that such polishing paradoxically enhances information diversity within AI summaries. Finally, to assess the user-end impact of LLM-induced information increases, we design a generative search engine and recruit Prolific participants to conduct a randomized controlled experiment involving an information-seeking and writing task. We find that higher-educated users exhibit minimal changes in their final outputs' information diversity but demonstrate significantly reduced task completion time when original sites undergo polishing. Conversely, lower-educated users primarily benefit through enhanced information density in their task outputs while maintaining similar completion times across experimental groups.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "comments": "59 pages, 6 figures, 20 tables", "pdf_url": "https://arxiv.org/pdf/2509.14436.pdf", "abstract_url": "https://arxiv.org/abs/2509.14436", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "生成式搜索引擎偏好可预测和语义相似的内容，通过LLM优化内容可增强信息多样性，对高教育和低教育用户产生不同影响。", "motivation": "研究生成式搜索引擎如何改变搜索优化和流量获取，探索其内容偏好和用户影响。", "method": "收集数据、实证分析、RAG API实验、LLM内容优化实验、用户随机对照实验。", "result": "GEs偏好可预测和语义相似内容；LLM优化内容增加信息多样性；高教育用户节省时间，低教育用户提升信息密度。", "conclusion": "生成式搜索引擎基于LLM偏好，内容优化可改善多样性，对不同用户群体有差异化益处。"}}
{"id": "2509.14537", "title": "ClearFairy: Capturing Creative Workflows through Decision Structuring, In-Situ Questioning, and Rationale Inference", "authors": ["Kihoon Son", "DaEun Choi", "Tae Soo Kim", "Young-Ho Kim", "Sangdoo Yun", "Juho Kim"], "abstract": "Capturing professionals' decision-making in creative workflows is essential for reflection, collaboration, and knowledge sharing, yet existing methods often leave rationales incomplete and implicit decisions hidden. To address this, we present CLEAR framework that structures reasoning into cognitive decision steps-linked units of actions, artifacts, and self-explanations that make decisions traceable. Building on this framework, we introduce ClearFairy, a think-aloud AI assistant for UI design that detects weak explanations, asks lightweight clarifying questions, and infers missing rationales to ease the knowledge-sharing burden. In a study with twelve creative professionals, 85% of ClearFairy's inferred rationales were accepted, increasing strong explanations from 14% to over 83% of decision steps without adding cognitive demand. The captured steps also enhanced generative AI agents in Figma, yielding next-action predictions better aligned with professionals and producing more coherent design outcomes. For future research on human knowledge-grounded creative AI agents, we release a dataset of captured 417 decision steps.", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14537.pdf", "abstract_url": "https://arxiv.org/abs/2509.14537", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "ClearFairy是一个AI助手，通过结构化决策步骤、现场提问和推理缺失理由，捕捉创意工作流程中的决策过程，提高解释质量和知识共享。", "motivation": "解决现有方法在捕捉创意工作流程中决策时，理由不完整和隐含决策未被记录的问题。", "method": "使用CLEAR框架结构化推理为认知决策步骤，结合AI助手检测弱解释、提问和推理缺失理由。", "result": "在12名创意专业人士的研究中，85%的推理理由被接受，强解释从14%增加到83%，且提升了生成AI代理的性能。", "conclusion": "ClearFairy有效支持知识共享和创意AI代理，未来研究可基于发布的数据集推进。"}}
{"id": "2509.14608", "title": "Enterprise AI Must Enforce Participant-Aware Access Control", "authors": ["Shashank Shreedhar Bhatt", "Tanmay Rajore", "Khushboo Aggarwal", "Ganesh Ananthanarayanan", "Ranveer Chandra", "Nishanth Chandran", "Suyash Choudhury", "Divya Gupta", "Emre Kiciman", "Sumit Kumar Pandey", "Srinath Setty", "Rahul Sharma", "Teijia Zhao"], "abstract": "Large language models (LLMs) are increasingly deployed in enterprise settings where they interact with multiple users and are trained or fine-tuned on sensitive internal data. While fine-tuning enhances performance by internalizing domain knowledge, it also introduces a critical security risk: leakage of confidential training data to unauthorized users. These risks are exacerbated when LLMs are combined with Retrieval-Augmented Generation (RAG) pipelines that dynamically fetch contextual documents at inference time.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14608.pdf", "abstract_url": "https://arxiv.org/abs/2509.14608", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "企业AI需实施参与者感知访问控制以防止敏感数据泄露", "motivation": "解决LLMs在企业环境中微调和RAG管道带来的机密训练数据泄露风险", "method": "提出参与者感知访问控制机制，增强安全措施", "result": "识别了数据泄露风险，并强调了访问控制的重要性", "conclusion": "企业部署LLMs时必须集成访问控制以保护敏感信息"}}
{"id": "2509.14622", "title": "Adversarial Distilled Retrieval-Augmented Guarding Model for Online Malicious Intent Detection", "authors": ["Yihao Guo", "Haocheng Bian", "Liutong Zhou", "Ze Wang", "Zhaoyi Zhang", "Francois Kawala", "Milan Dean", "Ian Fischer", "Yuantao Peng", "Noyan Tokgozoglu", "Ivan Barrientos", "Riyaaz Shaik", "Rachel Li", "Chandru Venkataraman", "Reza Shifteh Far", "Moses Pawar", "Venkat Sundaranatha", "Michael Xu", "Frank Chu"], "abstract": "With the deployment of Large Language Models (LLMs) in interactive applications, online malicious intent detection has become increasingly critical. However, existing approaches fall short of handling diverse and complex user queries in real time. To address these challenges, we introduce ADRAG (Adversarial Distilled Retrieval-Augmented Guard), a two-stage framework for robust and efficient online malicious intent detection. In the training stage, a high-capacity teacher model is trained on adversarially perturbed, retrieval-augmented inputs to learn robust decision boundaries over diverse and complex user queries. In the inference stage, a distillation scheduler transfers the teacher's knowledge into a compact student model, with a continually updated knowledge base collected online. At deployment, the compact student model leverages top-K similar safety exemplars retrieved from the online-updated knowledge base to enable both online and real-time malicious query detection. Evaluations across ten safety benchmarks demonstrate that ADRAG, with a 149M-parameter model, achieves 98.5% of WildGuard-7B's performance, surpasses GPT-4 by 3.3% and Llama-Guard-3-8B by 9.5% on out-of-distribution detection, while simultaneously delivering up to 5.6x lower latency at 300 queries per second (QPS) in real-time applications.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14622.pdf", "abstract_url": "https://arxiv.org/abs/2509.14622", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出ADRAG框架，通过对抗蒸馏和检索增强实现高效实时的在线恶意意图检测，在性能和延迟方面优于现有模型。", "motivation": "解决大型语言模型在交互应用中处理多样复杂用户查询时，现有方法实时性和鲁棒性不足的问题。", "method": "使用两阶段框架：训练阶段用对抗扰动和检索增强输入训练教师模型，推理阶段通过蒸馏调度器将知识转移到紧凑学生模型，并利用在线更新知识库进行检索。", "result": "在十个安全基准测试中，ADRAG以149M参数模型达到WildGuard-7B性能的98.5%，在分布外检测上超越GPT-4 3.3%和Llama-Guard-3-8B 9.5%，延迟降低5.6倍，支持300 QPS。", "conclusion": "ADRAG框架有效提升了在线恶意意图检测的鲁棒性和效率，适用于实时应用，具有实际部署价值。"}}
{"id": "2509.14627", "title": "Towards Human-like Multimodal Conversational Agent by Generating Engaging Speech", "authors": ["Taesoo Kim", "Yongsik Jo", "Hyunmin Song", "Taehwan Kim"], "abstract": "Human conversation involves language, speech, and visual cues, with each medium providing complementary information. For instance, speech conveys a vibe or tone not fully captured by text alone. While multimodal LLMs focus on generating text responses from diverse inputs, less attention has been paid to generating natural and engaging speech. We propose a human-like agent that generates speech responses based on conversation mood and responsive style information. To achieve this, we build a novel MultiSensory Conversation dataset focused on speech to enable agents to generate natural speech. We then propose a multimodal LLM-based model for generating text responses and voice descriptions, which are used to generate speech covering paralinguistic information. Experimental results demonstrate the effectiveness of utilizing both visual and audio modalities in conversation to generate engaging speech. The source code is available in", "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "Published in Interspeech 2025", "pdf_url": "https://arxiv.org/pdf/2509.14627.pdf", "abstract_url": "https://arxiv.org/abs/2509.14627", "categories": ["Human-Computer Interaction (cs.HC)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于多模态LLM的对话代理，通过整合视觉和音频信息生成自然且吸引人的语音，以模拟人类对话。", "motivation": "解决当前多模态LLM主要关注文本生成，而忽略生成自然和吸引人语音的问题，以提升对话代理的人性化程度。", "method": "构建MultiSensory Conversation数据集，并开发多模态LLM模型，生成文本响应和语音描述，用于覆盖副语言信息的语音合成。", "result": "实验结果表明，利用视觉和音频模态能有效生成吸引人的语音，验证了方法的有效性。", "conclusion": "该代理能生成更人性化的语音响应，推动多模态对话系统的发展，源代码已公开。"}}
{"id": "2509.14803", "title": "OnlineMate: An LLM-Based Multi-Agent Companion System for Cognitive Support in Online Learning", "authors": ["Xian Gao", "Zongyun Zhang", "Ting Liu", "Yuzhuo Fu"], "abstract": "In online learning environments, students often lack personalized peer interactions, which play a crucial role in supporting cognitive development and learning engagement. Although previous studies have utilized large language models (LLMs) to simulate interactive dynamic learning environments for students, these interactions remain limited to conversational exchanges, lacking insights and adaptations to the learners' individualized learning and cognitive states. As a result, students' interest in discussions with AI learning companions is low, and they struggle to gain inspiration from such interactions. To address this challenge, we propose OnlineMate, a multi-agent learning companion system driven by LLMs that integrates the Theory of Mind (ToM). OnlineMate is capable of simulating peer-like agent roles, adapting to learners' cognitive states during collaborative discussions, and inferring their psychological states, such as misunderstandings, confusion, or motivation. By incorporating Theory of Mind capabilities, the system can dynamically adjust its interaction strategies to support the development of higher-order thinking and cognition. Experimental results in simulated learning scenarios demonstrate that OnlineMate effectively fosters deep learning and discussions while enhancing cognitive engagement in online educational settings.", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.14803.pdf", "abstract_url": "https://arxiv.org/abs/2509.14803", "categories": ["Computers and Society (cs.CY)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "OnlineMate是一个基于大语言模型的多智能体学习伴侣系统，融入心理理论，模拟同伴角色，适应学习者认知状态，提升在线学习的深度讨论和认知参与。", "motivation": "解决在线学习中缺乏个性化同伴互动的问题，现有AI学习伴侣仅限于对话，无法适应个体学习状态，导致学生兴趣低和启发不足。", "method": "使用大语言模型驱动多智能体系统，整合心理理论，模拟同伴角色，动态调整交互策略以适应学习者的认知和心理状态。", "result": "在模拟学习场景中，实验结果显示OnlineMate有效促进深度学习和讨论，增强认知参与。", "conclusion": "OnlineMate系统能支持高阶思维发展，改善在线教育环境中的学习效果和互动质量。"}}
{"id": "2509.15160", "title": "An Evaluation-Centric Paradigm for Scientific Visualization Agents", "authors": ["Kuangshi Ai", "Haichao Miao", "Zhimin Li", "Chaoli Wang", "Shusen Liu"], "abstract": "Recent advances in multi-modal large language models (MLLMs) have enabled increasingly sophisticated autonomous visualization agents capable of translating user intentions into data visualizations. However, measuring progress and comparing different agents remains challenging, particularly in scientific visualization (SciVis), due to the absence of comprehensive, large-scale benchmarks for evaluating real-world capabilities. This position paper examines the various types of evaluation required for SciVis agents, outlines the associated challenges, provides a simple proof-of-concept evaluation example, and discusses how evaluation benchmarks can facilitate agent self-improvement. We advocate for a broader collaboration to develop a SciVis agentic evaluation benchmark that would not only assess existing capabilities but also drive innovation and stimulate future development in the field.", "subjects": "Human-Computer Interaction (cs.HC); Computation and Language (cs.CL); Graphics (cs.GR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.15160.pdf", "abstract_url": "https://arxiv.org/abs/2509.15160", "categories": ["Human-Computer Interaction (cs.HC)", "Computation and Language (cs.CL)", "Graphics (cs.GR)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出以评估为中心的范式，探讨科学可视化代理的评估挑战，并倡导开发基准以推动创新。", "motivation": "多模态大语言模型进步使自主可视化代理更先进，但缺乏大规模基准来评估科学可视化代理的真实能力，阻碍进展比较。", "method": "作为立场论文，分析评估类型、挑战，提供概念验证评估示例，并讨论基准如何促进代理自我改进。", "result": "识别了评估挑战，展示了概念验证，并强调了基准对评估现有能力和驱动创新的重要性。", "conclusion": "呼吁广泛合作开发科学可视化代理评估基准，以评估能力、推动创新和刺激未来发展。"}}
{"id": "2509.14877", "title": "AI-Driven Multi-Agent Vehicular Planning for Battery Efficiency and QoS in 6G Smart Cities", "authors": ["Rohin Gillgallon", "Giacomo Bergami", "Reham Almutairi", "Graham Morgan"], "abstract": "While simulators exist for vehicular IoT nodes communicating with the Cloud through Edge nodes in a fully-simulated osmotic architecture, they often lack support for dynamic agent planning and optimisation to minimise vehicular battery consumption while ensuring fair communication times. Addressing these challenges requires extending current simulator architectures with AI algorithms for both traffic prediction and dynamic agent planning. This paper presents an extension of SimulatorOrchestrator (SO) to meet these requirements. Preliminary results over a realistic urban dataset show that utilising vehicular planning algorithms can lead to improved battery and QoS performance compared with traditional shortest path algorithms. The additional inclusion of desirability areas enabled more ambulances to be routed to their target destinations while utilising less energy to do so, compared to traditional and weighted algorithms without desirability considerations.", "subjects": "Networking and Internet Architecture (cs.NI); Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET)", "comments": "16 pages, 2 figures, 2 tables, 2 algorithms", "pdf_url": "https://arxiv.org/pdf/2509.14877.pdf", "abstract_url": "https://arxiv.org/abs/2509.14877", "categories": ["Networking and Internet Architecture (cs.NI)", "Artificial Intelligence (cs.AI)", "Emerging Technologies (cs.ET)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文扩展了SimulatorOrchestrator模拟器，集成AI算法进行多智能体车辆规划，以在6G智慧城市中优化电池效率和QoS。初步结果显示，相比传统算法，能改善电池性能和通信公平性。", "motivation": "解决现有模拟器缺乏动态智能体规划和优化的问题，以最小化车辆电池消耗并确保公平通信时间。", "method": "扩展SimulatorOrchestrator模拟器，集成AI算法进行交通预测和动态智能体规划，包括引入期望区域概念。", "result": "在城市数据集上的初步结果表明，车辆规划算法比传统最短路径算法在电池和QoS性能上表现更好；期望区域的使用使更多救护车以更低能耗到达目的地。", "conclusion": "AI驱动的多智能体规划能有效提升6G智慧城市中的车辆效率和通信质量，具有实际应用潜力。"}}
{"id": "2509.15032", "title": "Sample Efficient Experience Replay in Non-stationary Environments", "authors": ["Tianyang Duan", "Zongyuan Zhang", "Songxiao Guo", "Yuanye Zhao", "Zheng Lin", "Zihan Fang", "Yi Liu", "Dianxin Luan", "Dong Huang", "Heming Cui", "Yong Cui"], "abstract": "Reinforcement learning (RL) in non-stationary environments is challenging, as changing dynamics and rewards quickly make past experiences outdated. Traditional experience replay (ER) methods, especially those using TD-error prioritization, struggle to distinguish between changes caused by the agent's policy and those from the environment, resulting in inefficient learning under dynamic conditions. To address this challenge, we propose the Discrepancy of Environment Dynamics (DoE), a metric that isolates the effects of environment shifts on value functions. Building on this, we introduce Discrepancy of Environment Prioritized Experience Replay (DEER), an adaptive ER framework that prioritizes transitions based on both policy updates and environmental changes. DEER uses a binary classifier to detect environment changes and applies distinct prioritization strategies before and after each shift, enabling more sample-efficient learning. Experiments on four non-stationary benchmarks demonstrate that DEER further improves the performance of off-policy algorithms by 11.54 percent compared to the best-performing state-of-the-art ER methods.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Networking and Internet Architecture (cs.NI)", "comments": "5 pages, 3 figures", "pdf_url": "https://arxiv.org/pdf/2509.15032.pdf", "abstract_url": "https://arxiv.org/abs/2509.15032", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Networking and Internet Architecture (cs.NI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种在非平稳环境中提高样本效率的经验回放方法DEER，通过度量环境动态差异并优先处理关键转换，在四个基准测试中比现有方法性能提升11.54%。", "motivation": "解决强化学习在非平稳环境中因环境动态和奖励变化导致过去经验快速过时的问题，传统经验回放方法难以区分策略和环境变化的影响，导致学习效率低下。", "method": "引入环境动态差异（DoE）度量来隔离环境变化对价值函数的影响，并基于此开发DEER框架，使用二元分类器检测环境变化，并在变化前后应用不同的优先策略。", "result": "在四个非平稳基准测试中，DEER将离策略算法的性能提高了11.54%，相比最先进的ER方法更高效。", "conclusion": "DEER通过自适应优先处理经验，有效应对非平稳环境，提高了强化学习的样本效率和性能，具有实际应用潜力。"}}
{"id": "2509.15042", "title": "Reinforcement Learning Agent for a 2D Shooter Game", "authors": ["Thomas Ackermann", "Moritz Spang", "Hamza A. A. Gardi"], "abstract": "Reinforcement learning agents in complex game environments often suffer from sparse rewards, training instability, and poor sample efficiency. This paper presents a hybrid training approach that combines offline imitation learning with online reinforcement learning for a 2D shooter game agent. We implement a multi-head neural network with separate outputs for behavioral cloning and Q-learning, unified by shared feature extraction layers with attention mechanisms. Initial experiments using pure deep Q-Networks exhibited significant instability, with agents frequently reverting to poor policies despite occasional good performance. To address this, we developed a hybrid methodology that begins with behavioral cloning on demonstration data from rule-based agents, then transitions to reinforcement learning. Our hybrid approach achieves consistently above 70% win rate against rule-based opponents, substantially outperforming pure reinforcement learning methods which showed high variance and frequent performance degradation. The multi-head architecture enables effective knowledge transfer between learning modes while maintaining training stability. Results demonstrate that combining demonstration-based initialization with reinforcement learning optimization provides a robust solution for developing game AI agents in complex multi-agent environments where pure exploration proves insufficient.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2509.15042.pdf", "abstract_url": "https://arxiv.org/abs/2509.15042", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出一种结合离线模仿学习和在线强化学习的混合训练方法，用于2D射击游戏AI代理，通过多头神经网络和注意力机制提高稳定性和胜率。", "motivation": "解决强化学习在复杂游戏环境中奖励稀疏、训练不稳定和样本效率低的问题。", "method": "使用多头神经网络，共享特征提取层，结合行为克隆和Q学习，从演示数据初始化后过渡到强化学习。", "result": "混合方法达到超过70%的胜率，显著优于纯强化学习方法，减少了性能波动和退化。", "conclusion": "结合演示初始化和强化学习优化，为复杂多代理环境中的游戏AI开发提供了鲁棒解决方案。"}}
{"id": "2509.15103", "title": "Vulnerable Agent Identification in Large-Scale Multi-Agent Reinforcement Learning", "authors": ["Simin Li", "Zheng Yuwei", "Zihao Mao", "Linhao Wang", "Ruixiao Xu", "Chengdong Ma", "Xin Yu", "Yuqing Ma", "Qi Dou", "Xin Wang", "Jie Luo", "Bo An", "Yaodong Yang", "Weifeng Lv", "Xianglong Liu"], "abstract": "Partial agent failure becomes inevitable when systems scale up, making it crucial to identify the subset of agents whose compromise would most severely degrade overall performance. In this paper, we study this Vulnerable Agent Identification (VAI) problem in large-scale multi-agent reinforcement learning (MARL). We frame VAI as a Hierarchical Adversarial Decentralized Mean Field Control (HAD-MFC), where the upper level involves an NP-hard combinatorial task of selecting the most vulnerable agents, and the lower level learns worst-case adversarial policies for these agents using mean-field MARL. The two problems are coupled together, making HAD-MFC difficult to solve. To solve this, we first decouple the hierarchical process by Fenchel-Rockafellar transform, resulting a regularized mean-field Bellman operator for upper level that enables independent learning at each level, thus reducing computational complexity. We then reformulate the upper-level combinatorial problem as a MDP with dense rewards from our regularized mean-field Bellman operator, enabling us to sequentially identify the most vulnerable agents by greedy and RL algorithms. This decomposition provably preserves the optimal solution of the original HAD-MFC. Experiments show our method effectively identifies more vulnerable agents in large-scale MARL and the rule-based system, fooling system into worse failures, and learns a value function that reveals the vulnerability of each agent.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": "submitted to NIPS 2025", "pdf_url": "https://arxiv.org/pdf/2509.15103.pdf", "abstract_url": "https://arxiv.org/abs/2509.15103", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "该论文提出了一种在大型多智能体强化学习中识别易受攻击智能体的方法，通过分层对抗分散平均场控制框架和解耦优化，有效降低了计算复杂度并保持了最优解。", "motivation": "解决在系统规模扩大时，部分智能体故障不可避免的问题，需要识别那些被攻陷会严重降低整体性能的智能体子集。", "method": "使用分层对抗分散平均场控制（HAD-MFC）框架，通过Fenchel-Rockafellar变换解耦层次过程，将上层组合问题转化为MDP，并应用贪婪和RL算法进行学习。", "result": "实验表明，该方法能有效识别更多易受攻击智能体，在大型MARL和基于规则系统中诱导更严重的故障，并学习到揭示每个智能体脆弱性的价值函数。", "conclusion": "该方法为大规模MARL中的脆弱性识别提供了高效解决方案，具有实际应用价值。"}}
