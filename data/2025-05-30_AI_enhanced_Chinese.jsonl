{"id": "2505.23130", "title": "PhotoArtAgent: Intelligent Photo Retouching with Language Model-Based Artist Agents", "authors": ["Haoyu Chen", "Keda Tao", "Yizao Wang", "Xinlei Wang", "Lei Zhu", "Jinjin Gu"], "abstract": "Photo retouching is integral to photographic art, extending far beyond simple technical fixes to heighten emotional expression and narrative depth. While artists leverage expertise to create unique visual effects through deliberate adjustments, non-professional users often rely on automated tools that produce visually pleasing results but lack interpretative depth and interactive transparency. In this paper, we introduce PhotoArtAgent, an intelligent system that combines Vision-Language Models (VLMs) with advanced natural language reasoning to emulate the creative process of a professional artist. The agent performs explicit artistic analysis, plans retouching strategies, and outputs precise parameters to Lightroom through an API. It then evaluates the resulting images and iteratively refines them until the desired artistic vision is achieved. Throughout this process, PhotoArtAgent provides transparent, text-based explanations of its creative rationale, fostering meaningful interaction and user control. Experimental results show that PhotoArtAgent not only surpasses existing automated tools in user studies but also achieves results comparable to those of professional human artists.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23130.pdf", "abstract_url": "https://arxiv.org/abs/2505.23130", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "PhotoArtAgent是一个结合视觉语言模型和高级自然语言推理的智能系统，旨在模拟专业艺术家的创作过程，提供透明、文本化的创意解释，并在用户研究中超越了现有自动化工具，达到了与专业人类艺术家相当的效果。", "motivation": "解决非专业用户在照片修饰中缺乏解释深度和交互透明度的问题，模拟专业艺术家的创作过程，提供更高质量的图像修饰。", "method": "结合视觉语言模型（VLMs）和高级自然语言推理，进行明确的艺术分析，规划修饰策略，并通过API输出精确参数到Lightroom，然后评估并迭代优化图像。", "result": "PhotoArtAgent在用户研究中不仅超越了现有自动化工具，还达到了与专业人类艺术家相当的效果。", "conclusion": "PhotoArtAgent通过模拟专业艺术家的创作过程和提供透明的创意解释，为照片修饰提供了高质量的解决方案，同时增强了用户交互和控制。"}}
{"id": "2505.22752", "title": "Climate Finance Bench", "authors": ["Rafik Mankour", "Yassine Chafai", "Hamada Saleh", "Ghassen Ben Hassine", "Thibaud Barreau", "Peter Tankov"], "abstract": "Climate Finance Bench introduces an open benchmark that targets question-answering over corporate climate disclosures using Large Language Models. We curate 33 recent sustainability reports in English drawn from companies across all 11 GICS sectors and annotate 330 expert-validated question-answer pairs that span pure extraction, numerical reasoning, and logical reasoning. Building on this dataset, we propose a comparison of RAG (retrieval-augmented generation) approaches. We show that the retriever's ability to locate passages that actually contain the answer is the chief performance bottleneck. We further argue for transparent carbon reporting in AI-for-climate applications, highlighting advantages of techniques such as Weight Quantization.", "subjects": "Computation and Language (cs.CL)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.22752.pdf", "abstract_url": "https://arxiv.org/abs/2505.22752", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "Climate Finance Bench提出了一个开放的基准，针对使用大型语言模型对公司气候披露进行问答。我们整理了33份最近用英语编写的可持续发展报告，这些报告来自所有11个GICS部门的公司，并注释了330个经过专家验证的问题-答案对，涵盖了纯提取、数值推理和逻辑推理。基于这个数据集，我们提出了RAG（检索增强生成）方法的比较。我们表明，检索器定位包含答案的段落的能力是主要的性能瓶颈。我们进一步主张在AI-for-climate应用中透明的碳报告，强调了诸如权重量化等技术的优势。", "motivation": "解决在公司气候披露中使用大型语言模型进行问答时缺乏开放基准的问题。", "method": "整理和注释可持续发展报告中的问题-答案对，比较RAG方法，并分析检索器的性能瓶颈。", "result": "检索器定位包含答案的段落的能力是主要的性能瓶颈。", "conclusion": "提出了一个开放的基准，强调了在AI-for-climate应用中透明碳报告的重要性，并展示了权重量化等技术的优势。"}}
{"id": "2505.22698", "title": "Design and testing of an agent chatbot supporting decision making with public transport data", "authors": ["Luca Fantin", "Marco Antonelli", "Margherita Cesetti", "Daniele Irto", "Bruno Zamengo", "Francesco Silvestri"], "abstract": "Assessing the quality of public transportation services requires the analysis of large quantities of data on the scheduled and actual trips and documents listing the quality constraints each service needs to meet. Interrogating such datasets with SQL queries, organizing and visualizing the data can be quite complex for most users. This paper presents a chatbot offering a user-friendly tool to interact with these datasets and support decision making. It is based on an agent architecture, which expands the capabilities of the core Large Language Model (LLM) by allowing it to interact with a series of tools that can execute several tasks, like performing SQL queries, plotting data and creating maps from the coordinates of a trip and its stops. This paper also tackles one of the main open problems of such Generative AI projects: collecting data to measure the system's performance. Our chatbot has been extensively tested with a workflow that asks several questions and stores the generated query, the retrieved data and the natural language response for each of them. Such questions are drawn from a set of base examples which are then completed with actual data from the database. This procedure yields a dataset for the evaluation of the chatbot's performance, especially the consistency of its answers and the correctness of the generated queries.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.22698.pdf", "abstract_url": "https://arxiv.org/abs/2505.22698", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一种基于代理架构的聊天机器人，旨在通过用户友好的方式帮助用户与公共交通数据集交互并支持决策制定。该聊天机器人扩展了大型语言模型（LLM）的核心能力，使其能够执行SQL查询、绘制数据和创建地图等任务。此外，本文还解决了生成式AI项目中的一个主要开放问题：收集数据以测量系统性能。", "motivation": "评估公共交通服务质量需要分析大量关于计划与实际行程的数据以及每项服务需要满足的质量约束文件。对于大多数用户来说，使用SQL查询、组织和可视化这些数据可能相当复杂。", "method": "采用基于代理架构的聊天机器人，扩展大型语言模型（LLM）的能力，使其能够与一系列工具交互，执行SQL查询、数据绘图和从行程及其站点的坐标创建地图等任务。", "result": "通过一个工作流程广泛测试了聊天机器人，该流程提出多个问题，并为每个问题存储生成的查询、检索的数据和自然语言响应。这些问题来自一组基础示例，然后用数据库中的实际数据完成，从而产生一个用于评估聊天机器人性能的数据集。", "conclusion": "本文提出的聊天机器人提供了一种用户友好的工具，用于与公共交通数据集交互并支持决策制定，同时解决了生成式AI项目中性能测量数据收集的开放问题。"}}
{"id": "2505.22809", "title": "First Steps Towards Overhearing LLM Agents: A Case Study With Dungeons & Dragons Gameplay", "authors": ["Andrew Zhu", "Evan Osgood", "Chris Callison-Burch"], "abstract": "Much work has been done on conversational LLM agents which directly assist human users with tasks. We present an alternative paradigm for interacting with LLM agents, which we call \"overhearing agents\". These overhearing agents do not actively participate in conversation -- instead, they \"listen in\" on human-to-human conversations and perform background tasks or provide suggestions to assist the user. In this work, we explore the overhearing agents paradigm through the lens of Dungeons & Dragons gameplay. We present an in-depth study using large multimodal audio-language models as overhearing agents to assist a Dungeon Master. We perform a human evaluation to examine the helpfulness of such agents and find that some large audio-language models have the emergent ability to perform overhearing agent tasks using implicit audio cues. Finally, we release Python libraries and our project code to support further research into the overhearing agents paradigm at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)", "comments": "8 pages, 5 figures. In submission at EMNLP 2025", "pdf_url": "https://arxiv.org/pdf/2505.22809.pdf", "abstract_url": "https://arxiv.org/abs/2505.22809", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为‘偷听代理’的新型LLM代理交互范式，该代理不直接参与对话，而是通过‘监听’人类之间的对话来执行后台任务或提供建议。研究以《龙与地下城》游戏为例，探索了大型多模态音频-语言模型作为偷听代理协助地下城主的潜力，并通过人类评估验证了其有效性。", "motivation": "解决如何让LLM代理在不直接参与对话的情况下，通过监听人类对话来提供背景支持或建议的问题。", "method": "使用大型多模态音频-语言模型作为偷听代理，在《龙与地下城》游戏中进行深入案例研究，并进行人类评估。", "result": "研究发现，某些大型音频-语言模型具有利用隐式音频线索执行偷听代理任务的新兴能力。", "conclusion": "偷听代理范式为LLM代理的交互提供了新的可能性，特别是在游戏等场景中，能够有效协助用户。研究还发布了Python库和项目代码，以支持未来关于偷听代理范式的进一步研究。"}}
{"id": "2505.22753", "title": "Enhancing Lifelong Multi-Agent Path-finding by Using Artificial Potential Fields", "authors": ["Arseniy Pertzovsky", "Roni Stern", "Ariel Felner", "Roie Zivan"], "abstract": "We explore the use of Artificial Potential Fields (APFs) to solve Multi-Agent Path Finding (MAPF) and Lifelong MAPF (LMAPF) problems. In MAPF, a team of agents must move to their goal locations without collisions, whereas in LMAPF, new goals are generated upon arrival. We propose methods for incorporating APFs in a range of MAPF algorithms, including Prioritized Planning, MAPF-LNS2, and Priority Inheritance with Backtracking (PIBT). Experimental results show that using APF is not beneficial for MAPF but yields up to a 7-fold increase in overall system throughput for LMAPF.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.22753.pdf", "abstract_url": "https://arxiv.org/abs/2505.22753", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "探讨了使用人工势场（APFs）解决多智能体路径规划（MAPF）和终身多智能体路径规划（LMAPF）问题的方法。", "motivation": "解决多智能体在到达目标位置后新目标生成时的路径规划问题，以避免碰撞并提高系统吞吐量。", "method": "将人工势场（APFs）整合到多种MAPF算法中，包括优先规划、MAPF-LNS2和优先级继承与回溯（PIBT）。", "result": "实验结果表明，APF对MAPF无益，但能使LMAPF的整体系统吞吐量提高多达7倍。", "conclusion": "人工势场（APFs）在终身多智能体路径规划（LMAPF）中显著提高了系统吞吐量，为相关领域的研究和应用提供了新的思路。"}}
{"id": "2505.22777", "title": "MEDAL: A Framework for Benchmarking LLMs as Multilingual Open-Domain Chatbots and Dialogue Evaluators", "authors": ["John Mendonça", "Alon Lavie", "Isabel Trancoso"], "abstract": "As the capabilities of chatbots and their underlying LLMs continue to dramatically improve, evaluating their performance has increasingly become a major blocker to their further development. A major challenge is the available benchmarking datasets, which are largely static, outdated, and lacking in multilingual coverage, limiting their ability to capture subtle linguistic and cultural variations. This paper introduces MEDAL, an automated multi-agent framework for generating, evaluating, and curating more representative and diverse open-domain dialogue evaluation benchmarks. Our approach leverages several state-of-the-art LLMs to generate user-chatbot multilingual dialogues, conditioned on varied seed contexts. A strong LLM (GPT-4.1) is then used for a multidimensional analysis of the performance of the chatbots, uncovering noticeable cross-lingual performance differences. Guided by this large-scale evaluation, we curate a new meta-evaluation multilingual benchmark and human-annotate samples with nuanced quality judgments. This benchmark is then used to assess the ability of several reasoning and non-reasoning LLMs to act as evaluators of open-domain dialogues. We find that current LLMs struggle to detect nuanced issues, particularly those involving empathy and reasoning.", "subjects": "Computation and Language (cs.CL)", "comments": "May ARR", "pdf_url": "https://arxiv.org/pdf/2505.22777.pdf", "abstract_url": "https://arxiv.org/abs/2505.22777", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了MEDAL，一个自动化多代理框架，用于生成、评估和策划更具代表性和多样性的开放领域对话评估基准。该框架利用先进的LLM生成多语言用户-聊天机器人对话，并使用GPT-4.1进行多维性能分析，揭示了显著的跨语言性能差异。研究还发现，当前的LLM在检测涉及同理心和推理的微妙问题方面存在困难。", "motivation": "随着聊天机器人及其底层LLM能力的显著提升，评估其性能已成为进一步发展的主要障碍。现有的基准数据集大多是静态的、过时的，且缺乏多语言覆盖，限制了捕捉细微语言和文化差异的能力。", "method": "MEDAL框架利用多个先进的LLM生成基于不同种子上下文的多语言用户-聊天机器人对话，然后使用GPT-4.1进行多维性能分析。基于这一大规模评估，策划了一个新的元评估多语言基准，并对样本进行了带有细微质量判断的人工标注。", "result": "研究发现，当前的LLM在检测涉及同理心和推理的微妙问题方面表现不佳，揭示了显著的跨语言性能差异。", "conclusion": "MEDAL框架为生成和评估开放领域对话提供了更代表性和多样性的基准，揭示了当前LLM在评估开放领域对话时的局限性，特别是在检测微妙问题方面。"}}
{"id": "2505.22990", "title": "MenTeR: A fully-automated Multi-agenT workflow for end-to-end RF/Analog Circuits Netlist Design", "authors": ["Pin-Han Chen", "Yu-Sheng Lin", "Wei-Cheng Lee", "Tin-Yu Leu", "Po-Hsiang Hsu", "Anjana Dissanayake", "Sungjin Oh", "Chinq-Shiun Chiu"], "abstract": "RF/Analog design is essential for bridging digital technologies with real-world signals, ensuring the functionality and reliability of a wide range of electronic systems. However, analog design procedures are often intricate, time-consuming and reliant on expert intuition, and hinder the time and cost efficiency of circuit development. To overcome the limitations of the manual circuit design, we introduce MenTeR - a multiagent workflow integrated into an end-to-end analog design framework. By employing multiple specialized AI agents that collaboratively address different aspects of the design process, such as specification understanding, circuit optimization, and test bench validation, MenTeR reduces the dependency on frequent trial-and-error-style intervention. MenTeR not only accelerates the design cycle time but also facilitates a broader exploration of the design space, demonstrating robust capabilities in handling real-world analog systems. We believe that MenTeR lays the groundwork for future \"RF/Analog Copilots\" that can collaborate seamlessly with human designers.", "subjects": "Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET); Machine Learning (cs.LG)", "comments": "9 pages, 7 figures, accepted by IEEE ICLAD 2025", "pdf_url": "https://arxiv.org/pdf/2505.22990.pdf", "abstract_url": "https://arxiv.org/abs/2505.22990", "categories": ["Artificial Intelligence (cs.AI)", "Emerging Technologies (cs.ET)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "MenTeR是一个全自动的多代理工作流，用于端到端的RF/模拟电路网表设计，旨在通过AI代理协作减少对人工干预的依赖，加速设计周期并拓宽设计空间探索。", "motivation": "模拟设计过程复杂、耗时且依赖专家直觉，阻碍了电路开发的时间和成本效率。", "method": "采用多个专门的AI代理，协作处理设计过程的不同方面，如规格理解、电路优化和测试台验证。", "result": "MenTeR减少了频繁的试错式干预需求，加速了设计周期，并能够更广泛地探索设计空间。", "conclusion": "MenTeR为未来能与人类设计师无缝协作的“RF/模拟副驾驶”奠定了基础。"}}
{"id": "2505.22960", "title": "Revisiting Multi-Agent Debate as Test-Time Scaling: A Systematic Study of Conditional Effectiveness", "authors": ["Yongjin Yang", "Euiin Yi", "Jongwoo Ko", "Kimin Lee", "Zhijing Jin", "Se-Young Yun"], "abstract": "The remarkable growth in large language model (LLM) capabilities has spurred exploration into multi-agent systems, with debate frameworks emerging as a promising avenue for enhanced problem-solving. These multi-agent debate (MAD) approaches, where agents collaboratively present, critique, and refine arguments, potentially offer improved reasoning, robustness, and diverse perspectives over monolithic models. Despite prior studies leveraging MAD, a systematic understanding of its effectiveness compared to self-agent methods, particularly under varying conditions, remains elusive. This paper seeks to fill this gap by conceptualizing MAD as a test-time computational scaling technique, distinguished by collaborative refinement and diverse exploration capabilities. We conduct a comprehensive empirical investigation comparing MAD with strong self-agent test-time scaling baselines on mathematical reasoning and safety-related tasks. Our study systematically examines the influence of task difficulty, model scale, and agent diversity on MAD's performance. Key findings reveal that, for mathematical reasoning, MAD offers limited advantages over self-agent scaling but becomes more effective with increased problem difficulty and decreased model capability, while agent diversity shows little benefit. Conversely, for safety tasks, MAD's collaborative refinement can increase vulnerability, but incorporating diverse agent configurations facilitates a gradual reduction in attack success through the collaborative refinement process. We believe our findings provide critical guidance for the future development of more effective and strategically deployed MAD systems.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "Preprint, under review", "pdf_url": "https://arxiv.org/pdf/2505.22960.pdf", "abstract_url": "https://arxiv.org/abs/2505.22960", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过将多智能体辩论（MAD）概念化为测试时计算扩展技术，系统地研究了其在数学推理和安全相关任务上的有效性。研究发现，MAD在数学推理任务上的优势有限，但在问题难度增加和模型能力降低时更为有效；而在安全任务中，MAD的协作细化可能增加脆弱性，但通过引入多样化的智能体配置可以逐步降低攻击成功率。", "motivation": "尽管多智能体辩论（MAD）框架在增强问题解决能力方面显示出潜力，但其与单智能体方法相比的有效性，尤其是在不同条件下的表现，尚未得到系统理解。本研究旨在填补这一空白。", "method": "本研究将MAD概念化为一种测试时计算扩展技术，并通过在数学推理和安全相关任务上与强单智能体测试时扩展基线进行比较，进行了全面的实证研究。", "result": "研究发现，对于数学推理任务，MAD相对于单智能体扩展的优势有限，但随着问题难度的增加和模型能力的降低，MAD的有效性提高；而在安全任务中，MAD的协作细化可能增加系统的脆弱性，但通过多样化的智能体配置可以逐步降低攻击成功率。", "conclusion": "本研究的结果为未来开发更有效和战略部署的MAD系统提供了关键指导。"}}
{"id": "2505.22954", "title": "Darwin Godel Machine: Open-Ended Evolution of Self-Improving Agents", "authors": ["Jenny Zhang", "Shengran Hu", "Cong Lu", "Robert Lange", "Jeff Clune"], "abstract": "Today's AI systems have human-designed, fixed architectures and cannot autonomously and continuously improve themselves. The advance of AI could itself be automated. If done safely, that would accelerate AI development and allow us to reap its benefits much sooner. Meta-learning can automate the discovery of novel algorithms, but is limited by first-order improvements and the human design of a suitable search space. The Gödel machine proposed a theoretical alternative: a self-improving AI that repeatedly modifies itself in a provably beneficial manner. Unfortunately, proving that most changes are net beneficial is impossible in practice. We introduce the Darwin Gödel Machine (DGM), a self-improving system that iteratively modifies its own code (thereby also improving its ability to modify its own codebase) and empirically validates each change using coding benchmarks. Inspired by Darwinian evolution and open-endedness research, the DGM maintains an archive of generated coding agents. It grows the archive by sampling an agent from it and using a foundation model to create a new, interesting, version of the sampled agent. This open-ended exploration forms a growing tree of diverse, high-quality agents and allows the parallel exploration of many different paths through the search space. Empirically, the DGM automatically improves its coding capabilities (e.g., better code editing tools, long-context window management, peer-review mechanisms), increasing performance on SWE-bench from 20.0% to 50.0%, and on Polyglot from 14.2% to 30.7%. Furthermore, the DGM significantly outperforms baselines without self-improvement or open-ended exploration. All experiments were done with safety precautions (e.g., sandboxing, human oversight). The DGM is a significant step toward self-improving AI, capable of gathering its own stepping stones along paths that unfold into endless innovation.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.22954.pdf", "abstract_url": "https://arxiv.org/abs/2505.22954", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "达尔文哥德尔机（DGM）是一种自我改进的系统，通过迭代修改自身代码并利用编码基准进行经验验证，自动提升编码能力。受达尔文进化和开放性研究启发，DGM维护一个生成的编码代理档案，并通过基础模型创建新版本代理来扩展档案。这种方法在搜索空间中并行探索多种路径，形成多样化的高质量代理树。实验显示，DGM在SWE-bench和Polyglot上的性能显著提升，且显著优于无自我改进或开放性探索的基线。所有实验均采取安全措施。DGM是实现自我改进AI的重要一步，能够沿着无限创新的路径收集自己的垫脚石。", "motivation": "解决当前AI系统架构固定、无法自主持续自我改进的问题，加速AI发展并安全地实现其潜在益处。", "method": "引入达尔文哥德尔机（DGM），一个通过迭代修改自身代码并利用编码基准进行经验验证的自我改进系统，受达尔文进化和开放性研究启发，维护一个生成的编码代理档案，并通过基础模型创建新版本代理来扩展档案。", "result": "DGM在SWE-bench上的性能从20.0%提升到50.0%，在Polyglot上从14.2%提升到30.7%，显著优于无自我改进或开放性探索的基线。", "conclusion": "DGM是实现自我改进AI的重要一步，能够沿着无限创新的路径收集自己的垫脚石，所有实验均采取安全措施。"}}
{"id": "2505.23075", "title": "Second Opinion Matters: Towards Adaptive Clinical AI via the Consensus of Expert Model Ensemble", "authors": ["Amit Kumthekar", "Zion Tilley", "Henry Duong", "Bhargav Patel", "Michael Magnoli", "Ahmed Omar", "Ahmed Nasser", "Chaitanya Gharpure", "Yevgen Reztzov"], "abstract": "Despite the growing clinical adoption of large language models (LLMs), current approaches heavily rely on single model architectures. To overcome risks of obsolescence and rigid dependence on single model systems, we present a novel framework, termed the Consensus Mechanism. Mimicking clinical triage and multidisciplinary clinical decision-making, the Consensus Mechanism implements an ensemble of specialized medical expert agents enabling improved clinical decision making while maintaining robust adaptability. This architecture enables the Consensus Mechanism to be optimized for cost, latency, or performance, purely based on its interior model configuration.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "23 pages, 11 figures", "pdf_url": "https://arxiv.org/pdf/2505.23075.pdf", "abstract_url": "https://arxiv.org/abs/2505.23075", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为共识机制的新框架，通过专家模型集合的共识来改进临床决策，同时保持强大的适应性。", "motivation": "解决当前大型语言模型在临床应用中过度依赖单一模型架构的风险，如过时和刚性依赖问题。", "method": "模仿临床分诊和多学科临床决策，实现了一个专门医疗专家代理的集合，即共识机制。", "result": "共识机制能够根据其内部模型配置，针对成本、延迟或性能进行优化。", "conclusion": "共识机制提供了一种灵活、可优化的方法，以改进临床AI的决策过程，同时适应不同的操作需求。"}}
{"id": "2505.22942", "title": "WorkForceAgent-R1: Incentivizing Reasoning Capability in LLM-based Web Agents via Reinforcement Learning", "authors": ["Yuchen Zhuang", "Di Jin", "Jiaao Chen", "Wenqi Shi", "Hanrui Wang", "Chao Zhang"], "abstract": "Large language models (LLMs)-empowered web agents enables automating complex, real-time web navigation tasks in enterprise environments. However, existing web agents relying on supervised fine-tuning (SFT) often struggle with generalization and robustness due to insufficient reasoning capabilities when handling the inherently dynamic nature of web interactions. In this study, we introduce WorkForceAgent-R1, an LLM-based web agent trained using a rule-based R1-style reinforcement learning framework designed explicitly to enhance single-step reasoning and planning for business-oriented web navigation tasks. We employ a structured reward function that evaluates both adherence to output formats and correctness of actions, enabling WorkForceAgent-R1 to implicitly learn robust intermediate reasoning without explicit annotations or extensive expert demonstrations. Extensive experiments on the WorkArena benchmark demonstrate that WorkForceAgent-R1 substantially outperforms SFT baselines by 10.26-16.59%, achieving competitive performance relative to proprietary LLM-based agents (gpt-4o) in workplace-oriented web navigation tasks.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "Work in Progress", "pdf_url": "https://arxiv.org/pdf/2505.22942.pdf", "abstract_url": "https://arxiv.org/abs/2505.22942", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了WorkForceAgent-R1，一种基于大型语言模型（LLM）的网络代理，通过强化学习框架增强单步推理和规划能力，用于企业环境中的网络导航任务。", "motivation": "现有的基于监督微调（SFT）的网络代理在处理网络交互的动态性时，由于推理能力不足，往往难以实现良好的泛化和鲁棒性。", "method": "采用基于规则的R1风格强化学习框架，通过结构化奖励函数评估输出格式的遵守和动作的正确性，隐式学习稳健的中间推理。", "result": "在WorkArena基准测试中，WorkForceAgent-R1显著优于SFT基线10.26-16.59%，在工作场所导向的网络导航任务中与专有LLM代理（gpt-4o）竞争性能相当。", "conclusion": "WorkForceAgent-R1通过强化学习有效提升了LLM代理在复杂网络导航任务中的推理能力和性能，为自动化企业环境中的网络任务提供了新的解决方案。"}}
{"id": "2505.22961", "title": "ToMAP: Training Opponent-Aware LLM Persuaders with Theory of Mind", "authors": ["Peixuan Han", "Zijia Liu", "Jiaxuan You"], "abstract": "Large language models (LLMs) have shown promising potential in persuasion, but existing works on training LLM persuaders are still preliminary. Notably, while humans are skilled in modeling their opponent's thoughts and opinions proactively and dynamically, current LLMs struggle with such Theory of Mind (ToM) reasoning, resulting in limited diversity and opponent awareness. To address this limitation, we introduce Theory of Mind Augmented Persuader (ToMAP), a novel approach for building more flexible persuader agents by incorporating two theory of mind modules that enhance the persuader's awareness and analysis of the opponent's mental state. Specifically, we begin by prompting the persuader to consider possible objections to the target central claim, and then use a text encoder paired with a trained MLP classifier to predict the opponent's current stance on these counterclaims. Our carefully designed reinforcement learning schema enables the persuader learns how to analyze opponent-related information and utilize it to generate more effective arguments. Experiments show that the ToMAP persuader, while containing only 3B parameters, outperforms much larger baselines, like GPT-4o, with a relative gain of 39.4% across multiple persuadee models and diverse corpora. Notably, ToMAP exhibits complex reasoning chains and reduced repetition during training, which leads to more diverse and effective arguments. The opponent-aware feature of ToMAP also makes it suitable for long conversations and enables it to employ more logical and opponent-aware strategies. These results underscore our method's effectiveness and highlight its potential for developing more persuasive language agents. Code is available at:", "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.22961.pdf", "abstract_url": "https://arxiv.org/abs/2505.22961", "categories": ["Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了ToMAP，一种通过整合两个心理理论模块来增强大型语言模型（LLM）说服者对手意识和分析能力的新方法。ToMAP通过预测对手的立场并利用强化学习生成更有效的论点，实验显示其在多个模型和语料库上优于更大的基线模型。", "motivation": "当前的大型语言模型在说服任务中缺乏对人类对手心理状态的动态建模能力，导致论点多样性和对手意识有限。", "method": "ToMAP通过两个心理理论模块增强说服者的对手意识：一是考虑目标中心主张的可能反对意见，二是使用文本编码器和MLP分类器预测对手对这些反对意见的当前立场。结合精心设计的强化学习模式，使说服者学会分析和利用对手相关信息生成更有效的论点。", "result": "ToMAP说服者虽然仅包含3B参数，但在多个说服者模型和多样语料库上的表现优于更大的基线模型（如GPT-4o），相对增益达到39.4%。此外，ToMAP展现出更复杂的推理链和减少的重复，生成更多样和有效的论点。", "conclusion": "ToMAP的有效性强调了其在开发更具说服力的语言代理方面的潜力，特别适合长对话和需要更多逻辑和对手意识策略的场景。"}}
{"id": "2505.23153", "title": "Conceptual Framework Toward Embodied Collective Adaptive Intelligence", "authors": ["Fan Wang", "Shaoshan Liu"], "abstract": "Collective Adaptive Intelligence (CAI) represent a transformative approach in artificial intelligence, wherein numerous autonomous agents collaborate, adapt, and self-organize to navigate complex, dynamic environments. This paradigm is particularly impactful in embodied AI applications, where adaptability and resilience are paramount. By enabling systems to reconfigure themselves in response to unforeseen challenges, CAI facilitate robust performance in real-world scenarios. This article introduces a conceptual framework for designing and analyzing CAI. It delineates key attributes including task generalization, resilience, scalability, and self-assembly, aiming to bridge theoretical foundations with practical methodologies for engineering adaptive, emergent intelligence. By providing a structured foundation for understanding and implementing CAI, this work seeks to guide researchers and practitioners in developing more resilient, scalable, and adaptable AI systems across various domains.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23153.pdf", "abstract_url": "https://arxiv.org/abs/2505.23153", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "集体适应性智能（CAI）代表了一种人工智能的变革性方法，其中众多自主代理协作、适应并自组织以导航复杂、动态的环境。本文介绍了一个设计和分析CAI的概念框架，旨在连接理论基础与工程适应性、涌现智能的实用方法。", "motivation": "解决在复杂动态环境中实现人工智能系统的适应性、韧性和自组织能力的挑战，特别是在具身AI应用中。", "method": "提出了一个概念框架，明确了任务泛化、韧性、可扩展性和自组装等关键属性，以指导CAI的设计和分析。", "result": "为理解和实施CAI提供了一个结构化的基础，旨在指导研究人员和从业者开发更韧性、可扩展和适应性强的AI系统。", "conclusion": "通过提供一个结构化的框架，这项工作旨在促进跨领域开发更韧性、可扩展和适应性强的AI系统，连接理论与实践的桥梁。"}}
{"id": "2505.23399", "title": "GAM-Agent: Game-Theoretic and Uncertainty-Aware Collaboration for Complex Visual Reasoning", "authors": ["Jusheng Zhang", "Yijia Fan", "Wenjun Lin", "Ruiqi Chen", "Haoyi Jiang", "Wenhao Chai", "Jian Wang", "Keze Wang"], "abstract": "We propose GAM-Agent, a game-theoretic multi-agent framework for enhancing vision-language reasoning. Unlike prior single-agent or monolithic models, GAM-Agent formulates the reasoning process as a non-zero-sum game between base agents--each specializing in visual perception subtasks--and a critical agent that verifies logic consistency and factual correctness. Agents communicate via structured claims, evidence, and uncertainty estimates. The framework introduces an uncertainty-aware controller to dynamically adjust agent collaboration, triggering multi-round debates when disagreement or ambiguity is detected. This process yields more robust and interpretable predictions. Experiments on four challenging benchmarks--MMMU, MMBench, MVBench, and V*Bench--demonstrate that GAM-Agent significantly improves performance across various VLM backbones. Notably, GAM-Agent boosts the accuracy of small-to-mid scale models (e.g., Qwen2.5-VL-7B, InternVL3-14B) by 5--6\\%, and still enhances strong models like GPT-4o by up to 2--3\\%. Our approach is modular, scalable, and generalizable, offering a path toward reliable and explainable multi-agent multimodal reasoning.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23399.pdf", "abstract_url": "https://arxiv.org/abs/2505.23399", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "GAM-Agent是一个基于博弈论的多智能体框架，旨在增强视觉语言推理能力。通过将推理过程建模为非零和游戏，结合不确定性感知控制器动态调整智能体协作，显著提升了多种视觉语言模型在复杂推理任务上的性能。", "motivation": "解决现有视觉语言推理模型中单智能体或整体模型在复杂推理任务上的局限性，提高推理的鲁棒性和可解释性。", "method": "采用博弈论多智能体框架，包括专门处理视觉感知子任务的基础智能体和一个验证逻辑一致性和事实正确性的关键智能体，通过结构化声明、证据和不确定性估计进行通信，并引入不确定性感知控制器动态调整协作。", "result": "在MMMU、MMBench、MVBench和V*Bench四个挑战性基准测试中，GAM-Agent显著提升了各种视觉语言模型的性能，尤其是中小规模模型的准确率提高了5-6%，即使是强大的GPT-4o模型也提升了2-3%。", "conclusion": "GAM-Agent提供了一种模块化、可扩展且通用的方法，为实现可靠和可解释的多智能体多模态推理开辟了道路。"}}
{"id": "2505.23436", "title": "Emergent Risk Awareness in Rational Agents under Resource Constraints", "authors": ["Daniel Jarne Ornia", "Nicholas Bishop", "Joel Dyer", "Wei-Chen Lee", "Ani Calinescu", "Doyne Farme", "Michael Wooldridge"], "abstract": "Advanced reasoning models with agentic capabilities (AI agents) are deployed to interact with humans and to solve sequential decision-making problems under (approximate) utility functions and internal models. When such problems have resource or failure constraints where action sequences may be forcibly terminated once resources are exhausted, agents face implicit trade-offs that reshape their utility-driven (rational) behaviour. Additionally, since these agents are typically commissioned by a human principal to act on their behalf, asymmetries in constraint exposure can give rise to previously unanticipated misalignment between human objectives and agent incentives. We formalise this setting through a survival bandit framework, provide theoretical and empirical results that quantify the impact of survival-driven preference shifts, identify conditions under which misalignment emerges and propose mechanisms to mitigate the emergence of risk-seeking or risk-averse behaviours. As a result, this work aims to increase understanding and interpretability of emergent behaviours of AI agents operating under such survival pressure, and offer guidelines for safely deploying such AI systems in critical resource-limited environments.", "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23436.pdf", "abstract_url": "https://arxiv.org/abs/2505.23436", "categories": ["Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文探讨了在资源约束下，具有代理能力的高级推理模型（AI代理）如何在与人类互动和解决序列决策问题时，因资源或失败约束而面临的行为重塑。通过生存多臂老虎机框架，作者量化了生存驱动偏好转变的影响，识别了不对齐出现的条件，并提出了缓解风险寻求或风险规避行为的机制。", "motivation": "解决在资源有限的环境中，AI代理因资源约束而被迫终止行动序列时，其效用驱动行为如何被重塑，以及由此可能引发的人类目标与代理激励之间的不对齐问题。", "method": "采用生存多臂老虎机框架，结合理论和实证研究，量化生存驱动偏好转变的影响，并识别不对齐出现的条件。", "result": "研究发现，在特定条件下，AI代理会表现出风险寻求或风险规避的行为，提出了缓解这些行为的机制。", "conclusion": "本研究旨在增加对在生存压力下操作的AI代理 emergent行为的理解和可解释性，并为在关键资源有限环境中安全部署此类AI系统提供指导。"}}
{"id": "2505.23474", "title": "Socratic-PRMBench: Benchmarking Process Reward Models with Systematic Reasoning Patterns", "authors": ["Xiang Li", "Haiyang Yu", "Xinghua Zhang", "Ziyang Huang", "Shizhu He", "Kang Liu", "Jun Zhao", "Fei Huang", "Yongbin Li"], "abstract": "Process Reward Models (PRMs) are crucial in complex reasoning and problem-solving tasks (e.g., LLM agents with long-horizon decision-making) by verifying the correctness of each intermediate reasoning step. In real-world scenarios, LLMs may apply various reasoning patterns (e.g., decomposition) to solve a problem, potentially suffering from errors under various reasoning patterns. Therefore, PRMs are required to identify errors under various reasoning patterns during the reasoning process. However, existing benchmarks mainly focus on evaluating PRMs with stepwise correctness, ignoring a systematic evaluation of PRMs under various reasoning patterns. To mitigate this gap, we introduce Socratic-PRMBench, a new benchmark to evaluate PRMs systematically under six reasoning patterns, including Transformation, Decomposition, Regather, Deduction, Verification, and Integration. Socratic-PRMBench}comprises 2995 reasoning paths with flaws within the aforementioned six reasoning patterns. Through our experiments on both PRMs and LLMs prompted as critic models, we identify notable deficiencies in existing PRMs. These observations underscore the significant weakness of current PRMs in conducting evaluations on reasoning steps under various reasoning patterns. We hope Socratic-PRMBench can serve as a comprehensive testbed for systematic evaluation of PRMs under diverse reasoning patterns and pave the way for future development of PRMs.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23474.pdf", "abstract_url": "https://arxiv.org/abs/2505.23474", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了Socratic-PRMBench，一个新的基准测试，旨在系统评估过程奖励模型（PRMs）在六种推理模式下的表现，揭示了现有PRMs在多样化推理模式下的显著不足。", "motivation": "解决现有基准测试主要关注逐步正确性评估，而忽视了对PRMs在各种推理模式下系统评估的问题。", "method": "引入Socratic-PRMBench基准测试，包含2995条在六种推理模式（如转换、分解、重新收集等）中存在缺陷的推理路径，对PRMs和作为批评模型的LLMs进行实验。", "result": "实验发现现有PRMs在多样化推理模式下评估推理步骤时存在显著弱点。", "conclusion": "Socratic-PRMBench可作为PRMs在多样化推理模式下系统评估的综合测试平台，为PRMs的未来发展铺平道路。"}}
{"id": "2505.23518", "title": "TRAP: Targeted Redirecting of Agentic Preferences", "authors": ["Hangoo Kang", "Jehyeok Yeon", "Gagandeep Singh"], "abstract": "Autonomous agentic AI systems powered by vision-language models (VLMs) are rapidly advancing toward real-world deployment, yet their cross-modal reasoning capabilities introduce new attack surfaces for adversarial manipulation that exploit semantic reasoning across modalities. Existing adversarial attacks typically rely on visible pixel perturbations or require privileged model or environment access, making them impractical for stealthy, real-world exploitation. We introduce TRAP, a generative adversarial framework that manipulates the agent's decision-making using diffusion-based semantic injections. Our method combines negative prompt-based degradation with positive semantic optimization, guided by a Siamese semantic network and layout-aware spatial masking. Without requiring access to model internals, TRAP produces visually natural images yet induces consistent selection biases in agentic AI systems. We evaluate TRAP on the Microsoft Common Objects in Context (COCO) dataset, building multi-candidate decision scenarios. Across these scenarios, TRAP achieves a 100% attack success rate on leading models, including LLaVA-34B, Gemma3, and Mistral-3.1, significantly outperforming baselines such as SPSA, Bandit, and standard diffusion approaches. These results expose a critical vulnerability: Autonomous agents can be consistently misled through human-imperceptible cross-modal manipulations. These findings highlight the need for defense strategies beyond pixel-level robustness to address semantic vulnerabilities in cross-modal decision-making.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23518.pdf", "abstract_url": "https://arxiv.org/abs/2505.23518", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了TRAP，一种生成对抗框架，通过扩散基础的语义注入操纵自主代理AI系统的决策。该方法结合了基于负面提示的退化和正面语义优化，无需访问模型内部，即可在视觉自然图像中诱导选择偏见。", "motivation": "随着基于视觉语言模型(VLMs)的自主代理AI系统向现实世界部署快速推进，其跨模态推理能力引入了新的攻击面，现有攻击方法依赖可见像素扰动或需要特权模型或环境访问，不适用于隐蔽的现实世界利用。", "method": "TRAP结合了负面提示基础的退化和正面语义优化，由Siamese语义网络和布局感知空间掩码引导，无需访问模型内部，生成视觉自然图像但诱导代理AI系统的选择偏见。", "result": "在Microsoft COCO数据集上构建的多候选决策场景中，TRAP对包括LLaVA-34B、Gemma3和Mistral-3.1在内的领先模型实现了100%的攻击成功率，显著优于SPSA、Bandit和标准扩散方法等基线。", "conclusion": "这些结果揭示了一个关键漏洞：自主代理可以通过人类难以察觉的跨模态操纵被一致误导。这些发现强调了需要超越像素级鲁棒性的防御策略，以解决跨模态决策中的语义漏洞。"}}
{"id": "2505.23559", "title": "SafeScientist: Toward Risk-Aware Scientific Discoveries by LLM Agents", "authors": ["Kunlun Zhu", "Jiaxun Zhang", "Ziheng Qi", "Nuoxing Shang", "Zijia Liu", "Peixuan Han", "Yue Su", "Haofei Yu", "Jiaxuan You"], "abstract": "Recent advancements in large language model (LLM) agents have significantly accelerated scientific discovery automation, yet concurrently raised critical ethical and safety concerns. To systematically address these challenges, we introduce \\textbf{SafeScientist}, an innovative AI scientist framework explicitly designed to enhance safety and ethical responsibility in AI-driven scientific exploration. SafeScientist proactively refuses ethically inappropriate or high-risk tasks and rigorously emphasizes safety throughout the research process. To achieve comprehensive safety oversight, we integrate multiple defensive mechanisms, including prompt monitoring, agent-collaboration monitoring, tool-use monitoring, and an ethical reviewer component. Complementing SafeScientist, we propose \\textbf{SciSafetyBench}, a novel benchmark specifically designed to evaluate AI safety in scientific contexts, comprising 240 high-risk scientific tasks across 6 domains, alongside 30 specially designed scientific tools and 120 tool-related risk tasks. Extensive experiments demonstrate that SafeScientist significantly improves safety performance by 35\\% compared to traditional AI scientist frameworks, without compromising scientific output quality. Additionally, we rigorously validate the robustness of our safety pipeline against diverse adversarial attack methods, further confirming the effectiveness of our integrated approach. The code and data will be available at", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23559.pdf", "abstract_url": "https://arxiv.org/abs/2505.23559", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了SafeScientist，一个旨在提高AI驱动科学探索安全性和伦理责任的新型AI科学家框架，以及SciSafetyBench，一个评估科学背景下AI安全的新基准。通过集成多种防御机制，SafeScientist显著提高了安全性能，同时不牺牲科学输出质量。", "motivation": "解决大型语言模型（LLM）代理在加速科学发现自动化过程中引发的伦理和安全问题。", "method": "开发了SafeScientist框架，集成了提示监控、代理协作监控、工具使用监控和伦理审查组件等多种防御机制，并提出了SciSafetyBench基准进行安全评估。", "result": "实验表明，SafeScientist比传统AI科学家框架安全性能提高了35%，且科学输出质量未受影响。安全管道对多样化的对抗攻击方法表现出鲁棒性。", "conclusion": "SafeScientist和SciSafetyBench为AI驱动的科学探索提供了一种安全、伦理的方法，有效平衡了科学发现和风险控制。"}}
{"id": "2505.22993", "title": "Verify-in-the-Graph: Entity Disambiguation Enhancement for Complex Claim Verification with Interactive Graph Representation", "authors": ["Hoang Pham", "Thanh-Do Nguyen", "Khac-Hoai Nam Bui"], "abstract": "Claim verification is a long-standing and challenging task that demands not only high accuracy but also explainability of the verification process. This task becomes an emerging research issue in the era of large language models (LLMs) since real-world claims are often complex, featuring intricate semantic structures or obfuscated entities. Traditional approaches typically address this by decomposing claims into sub-claims and querying a knowledge base to resolve hidden or ambiguous entities. However, the absence of effective disambiguation strategies for these entities can compromise the entire verification process. To address these challenges, we propose Verify-in-the-Graph (VeGraph), a novel framework leveraging the reasoning and comprehension abilities of LLM agents. VeGraph operates in three phases: (1) Graph Representation - an input claim is decomposed into structured triplets, forming a graph-based representation that integrates both structured and unstructured information; (2) Entity Disambiguation -VeGraph iteratively interacts with the knowledge base to resolve ambiguous entities within the graph for deeper sub-claim verification; and (3) Verification - remaining triplets are verified to complete the fact-checking process. Experiments using Meta-Llama-3-70B (instruct version) show that VeGraph achieves competitive performance compared to baselines on two benchmarks HoVer and FEVEROUS, effectively addressing claim verification challenges. Our source code and data are available for further exploitation.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Databases (cs.DB); Information Retrieval (cs.IR)", "comments": "Published at NAACL 2025 Main Conference", "pdf_url": "https://arxiv.org/pdf/2505.22993.pdf", "abstract_url": "https://arxiv.org/abs/2505.22993", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Databases (cs.DB)", "Information Retrieval (cs.IR)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为Verify-in-the-Graph（VeGraph）的新框架，用于增强复杂声明验证中的实体消歧，通过交互式图表示和大型语言模型（LLMs）的推理与理解能力，分三个阶段进行声明验证。", "motivation": "解决复杂声明验证中的实体消歧问题，传统方法由于缺乏有效的消歧策略，可能会影响整个验证过程的准确性和可解释性。", "method": "VeGraph框架分为三个阶段：图表示（将声明分解为结构化三元组，形成图表示）、实体消歧（与知识库交互以解决图中的模糊实体）和验证（验证剩余三元组以完成事实检查）。", "result": "使用Meta-Llama-3-70B（指导版本）在两个基准测试HoVer和FEVEROUS上进行的实验显示，VeGraph相比基线方法具有竞争力的性能。", "conclusion": "VeGraph有效解决了声明验证中的挑战，其源代码和数据可供进一步利用，为复杂声明验证提供了新的解决方案。"}}
{"id": "2505.23006", "title": "A Practical Approach for Building Production-Grade Conversational Agents with Workflow Graphs", "authors": ["Chiwan Park", "Wonjun Jang", "Daeryong Kim", "Aelim Ahn", "Kichang Yang", "Woosung Hwang", "Jihyeon Roh", "Hyerin Park", "Hyosun Wang", "Min Seok Kim", "Jihoon Kang"], "abstract": "The advancement of Large Language Models (LLMs) has led to significant improvements in various service domains, including search, recommendation, and chatbot applications. However, applying state-of-the-art (SOTA) research to industrial settings presents challenges, as it requires maintaining flexible conversational abilities while also strictly complying with service-specific constraints. This can be seen as two conflicting requirements due to the probabilistic nature of LLMs. In this paper, we propose our approach to addressing this challenge and detail the strategies we employed to overcome their inherent limitations in real-world applications. We conduct a practical case study of a conversational agent designed for the e-commerce domain, detailing our implementation workflow and optimizations. Our findings provide insights into bridging the gap between academic research and real-world application, introducing a framework for developing scalable, controllable, and reliable AI-driven agents.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "Accepted to ACL 2025 Industry Track. 12 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2505.23006.pdf", "abstract_url": "https://arxiv.org/abs/2505.23006", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种通过工作流图构建生产级对话代理的实用方法，旨在解决将最先进的大型语言模型（LLMs）应用于工业环境时面临的挑战，特别是在保持灵活对话能力的同时严格遵守服务特定约束的需求。", "motivation": "大型语言模型（LLMs）的进步显著提升了搜索、推荐和聊天机器人等服务的性能。然而，将这些先进的研究成果应用到工业环境中存在挑战，主要因为需要在保持对话灵活性的同时，严格遵守服务特定的约束，这两者由于LLMs的概率性质而显得相互冲突。", "method": "本文提出了一种方法来解决这一挑战，并详细介绍了在实际应用中克服其固有局限性的策略。通过一个为电子商务领域设计的对话代理的实际案例研究，详细说明了实施工作流程和优化措施。", "result": "研究结果为弥合学术研究与实际应用之间的差距提供了见解，并介绍了一个用于开发可扩展、可控且可靠的AI驱动代理的框架。", "conclusion": "本文的主要结论和意义在于提出了一种实用的方法，通过工作流图构建生产级对话代理，为开发可扩展、可控且可靠的AI驱动代理提供了框架，有助于将先进的LLMs研究成果更有效地应用于工业环境。"}}
{"id": "2505.23052", "title": "Query Routing for Retrieval-Augmented Language Models", "authors": ["Jiarui Zhang", "Xiangyu Liu", "Yong Hu", "Chaoyue Niu", "Fan Wu", "Guihai Chen"], "abstract": "Retrieval-Augmented Generation (RAG) significantly improves the performance of Large Language Models (LLMs) on knowledge-intensive tasks. However, varying response quality across LLMs under RAG necessitates intelligent routing mechanisms, which select the most suitable model for each query from multiple retrieval-augmented LLMs via a dedicated router model. We observe that external documents dynamically affect LLMs' ability to answer queries, while existing routing methods, which rely on static parametric knowledge representations, exhibit suboptimal performance in RAG scenarios. To address this, we formally define the new retrieval-augmented LLM routing problem, incorporating the influence of retrieved documents into the routing framework. We propose RAGRouter, a RAG-aware routing design, which leverages document embeddings and RAG capability embeddings with contrastive learning to capture knowledge representation shifts and enable informed routing decisions. Extensive experiments on diverse knowledge-intensive tasks and retrieval settings show that RAGRouter outperforms the best individual LLM by 3.61% on average and existing routing methods by 3.29%-9.33%. With an extended score-threshold-based mechanism, it also achieves strong performance-efficiency trade-offs under low-latency constraints.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23052.pdf", "abstract_url": "https://arxiv.org/abs/2505.23052", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了RAGRouter，一种针对检索增强生成（RAG）场景下的智能路由机制，通过结合文档嵌入和RAG能力嵌入，利用对比学习来优化大型语言模型（LLMs）的选择，以提高知识密集型任务的性能。", "motivation": "解决在检索增强生成（RAG）场景下，由于外部文档动态影响大型语言模型（LLMs）回答查询的能力，现有依赖静态参数知识表示的路由方法表现不佳的问题。", "method": "提出了RAGRouter，一种RAG感知的路由设计，通过结合文档嵌入和RAG能力嵌入，利用对比学习来捕捉知识表示的变化，并做出明智的路由决策。", "result": "在多种知识密集型任务和检索设置上的广泛实验表明，RAGRouter平均比最佳个体LLM性能高出3.61%，比现有路由方法性能高出3.29%-9.33%。", "conclusion": "RAGRouter不仅提高了性能，还通过扩展的基于分数阈值的机制，在低延迟约束下实现了强健的性能-效率权衡。"}}
{"id": "2505.23596", "title": "MAPLE: A Mobile Assistant with Persistent Finite State Machines for Recovery Reasoning", "authors": ["Linqiang Guo", "Wei Liu", "Yi Wen Heng", "Tse-Hsun", "Chen", "Yang Wang"], "abstract": "Mobile GUI agents aim to autonomously complete user-instructed tasks across mobile apps. Recent advances in Multimodal Large Language Models (MLLMs) enable these agents to interpret UI screens, identify actionable elements, and perform interactions such as tapping or typing. However, existing agents remain reactive: they reason only over the current screen and lack a structured model of app navigation flow, limiting their ability to understand context, detect unexpected outcomes, and recover from errors. We present MAPLE, a state-aware multi-agent framework that abstracts app interactions as a Finite State Machine (FSM). We computationally model each UI screen as a discrete state and user actions as transitions, allowing the FSM to provide a structured representation of the app execution. MAPLE consists of specialized agents responsible for four phases of task execution: planning, execution, verification, error recovery, and knowledge retention. These agents collaborate to dynamically construct FSMs in real time based on perception data extracted from the UI screen, allowing the GUI agents to track navigation progress and flow, validate action outcomes through pre- and post-conditions of the states, and recover from errors by rolling back to previously stable states. Our evaluation results on two challenging cross-app benchmarks, Mobile-Eval-E and SPA-Bench, show that MAPLE outperforms the state-of-the-art baseline, improving task success rate by up to 12%, recovery success by 13.8%, and action accuracy by 6.5%. Our results highlight the importance of structured state modeling in guiding mobile GUI agents during task execution. Moreover, our FSM representation can be integrated into future GUI agent architectures as a lightweight, model-agnostic memory layer to support structured planning, execution verification, and error recovery.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23596.pdf", "abstract_url": "https://arxiv.org/abs/2505.23596", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "MAPLE是一个基于有限状态机（FSM）的多代理框架，旨在提升移动GUI代理的任务执行能力，通过结构化状态建模支持任务规划、执行验证和错误恢复。", "motivation": "解决现有移动GUI代理在理解上下文、检测意外结果和从错误中恢复方面的局限性。", "method": "将应用交互抽象为有限状态机（FSM），通过专门代理协作动态构建FSM，实现导航进度跟踪、动作结果验证和错误恢复。", "result": "在两个跨应用基准测试中，MAPLE显著提高了任务成功率、恢复成功率和动作准确性。", "conclusion": "结构化状态建模对指导移动GUI代理任务执行至关重要，FSM表示可作为轻量级、模型无关的内存层集成到未来GUI代理架构中。"}}
{"id": "2505.23762", "title": "ZeroGUI: Automating Online GUI Learning at Zero Human Cost", "authors": ["Chenyu Yang", "Shiqian Su", "Shi Liu", "Xuan Dong", "Yue Yu", "Weijie Su", "Xuehui Wang", "Zhaoyang Liu", "Jinguo Zhu", "Hao Li", "Wenhai Wang", "Yu Qiao", "Xizhou Zhu", "Jifeng Dai"], "abstract": "The rapid advancement of large Vision-Language Models (VLMs) has propelled the development of pure-vision-based GUI Agents, capable of perceiving and operating Graphical User Interfaces (GUI) to autonomously fulfill user instructions. However, existing approaches usually adopt an offline learning framework, which faces two core limitations: (1) heavy reliance on high-quality manual annotations for element grounding and action supervision, and (2) limited adaptability to dynamic and interactive environments. To address these limitations, we propose ZeroGUI, a scalable, online learning framework for automating GUI Agent training at Zero human cost. Specifically, ZeroGUI integrates (i) VLM-based automatic task generation to produce diverse training goals from the current environment state, (ii) VLM-based automatic reward estimation to assess task success without hand-crafted evaluation functions, and (iii) two-stage online reinforcement learning to continuously interact with and learn from GUI environments. Experiments on two advanced GUI Agents (UI-TARS and Aguvis) demonstrate that ZeroGUI significantly boosts performance across OSWorld and AndroidLab environments. The code is available at", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23762.pdf", "abstract_url": "https://arxiv.org/abs/2505.23762", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "ZeroGUI是一个零人工成本的在线GUI学习自动化框架，旨在解决现有离线学习方法对高质量手动注释的依赖和动态交互环境适应性的限制。", "motivation": "解决现有纯视觉GUI代理在离线学习框架中对高成本手动注释的依赖和动态交互环境适应性差的问题。", "method": "提出ZeroGUI框架，包括基于VLM的自动任务生成、自动奖励估计和两阶段在线强化学习，以实现零人工成本的GUI代理训练。", "result": "在UI-TARS和Aguvis两个先进GUI代理上的实验表明，ZeroGUI在OSWorld和AndroidLab环境中显著提升了性能。", "conclusion": "ZeroGUI通过自动化任务生成和奖励估计，结合在线强化学习，有效提升了GUI代理的训练效率和适应性，且无需人工干预。"}}
{"id": "2505.23695", "title": "Data-to-Dashboard: Multi-Agent LLM Framework for Insightful Visualization in Enterprise Analytics", "authors": ["Ran Zhang", "Mohannad Elhamod"], "abstract": "The rapid advancement of LLMs has led to the creation of diverse agentic systems in data analysis, utilizing LLMs' capabilities to improve insight generation and visualization. In this paper, we present an agentic system that automates the data-to-dashboard pipeline through modular LLM agents capable of domain detection, concept extraction, multi-perspective analysis generation, and iterative self-reflection. Unlike existing chart QA systems, our framework simulates the analytical reasoning process of business analysts by retrieving domain-relevant knowledge and adapting to diverse datasets without relying on closed ontologies or question templates.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23695.pdf", "abstract_url": "https://arxiv.org/abs/2505.23695", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了一个基于多代理LLM框架的系统，旨在自动化数据到仪表板的流程，通过模块化LLM代理进行领域检测、概念提取、多视角分析生成和迭代自我反思，模拟业务分析师的推理过程。", "motivation": "解决在数据分析中如何更高效地生成见解和可视化的问题，特别是在不依赖封闭本体论或问题模板的情况下适应多样化数据集。", "method": "采用多代理LLM框架，包括领域检测、概念提取、多视角分析生成和迭代自我反思等模块，模拟业务分析师的推理过程。", "result": "开发了一个能够自动化数据到仪表板流程的系统，能够检索领域相关知识并适应多样化数据集。", "conclusion": "该框架通过模拟业务分析师的推理过程，提高了数据分析的效率和见解的生成，为企业在没有封闭本体论或问题模板的情况下提供了灵活的解决方案。"}}
{"id": "2505.23686", "title": "ROTATE: Regret-driven Open-ended Training for Ad Hoc Teamwork", "authors": ["Caroline Wang", "Arrasy Rahman", "Jiaxun Cui", "Yoonchang Sung", "Peter Stone"], "abstract": "Developing AI agents capable of collaborating with previously unseen partners is a fundamental generalization challenge in multi-agent learning, known as Ad Hoc Teamwork (AHT). Existing AHT approaches typically adopt a two-stage pipeline, where first, a fixed population of teammates is generated with the idea that they should be representative of the teammates that will be seen at deployment time, and second, an AHT agent is trained to collaborate well with agents in the population. To date, the research community has focused on designing separate algorithms for each stage. This separation has led to algorithms that generate teammate pools with limited coverage of possible behaviors, and that ignore whether the generated teammates are easy to learn from for the AHT agent. Furthermore, algorithms for training AHT agents typically treat the set of training teammates as static, thus attempting to generalize to previously unseen partner agents without assuming any control over the distribution of training teammates. In this paper, we present a unified framework for AHT by reformulating the problem as an open-ended learning process between an ad hoc agent and an adversarial teammate generator. We introduce ROTATE, a regret-driven, open-ended training algorithm that alternates between improving the AHT agent and generating teammates that probe its deficiencies. Extensive experiments across diverse AHT environments demonstrate that ROTATE significantly outperforms baselines at generalizing to an unseen set of evaluation teammates, thus establishing a new standard for robust and generalizable teamwork.", "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23686.pdf", "abstract_url": "https://arxiv.org/abs/2505.23686", "categories": ["Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了ROTATE，一种基于遗憾驱动的开放式训练算法，用于提升Ad Hoc Teamwork（AHT）中AI代理与未知伙伴协作的能力。通过将AHT问题重新定义为开放式学习过程，ROTATE在多样化的AHT环境中显著优于基线方法，为团队合作的鲁棒性和泛化性设立了新标准。", "motivation": "解决多智能体学习中与未知伙伴协作的泛化挑战，即Ad Hoc Teamwork（AHT）。现有方法通常采用两阶段流程，首先生成一个固定的队友群体，然后训练AHT代理与这些队友协作。这种方法限制了队友行为的覆盖范围，且忽略了生成的队友是否易于AHT代理学习。", "method": "提出了一个统一的AHT框架，将问题重新定义为AHT代理与对抗性队友生成器之间的开放式学习过程。介绍了ROTATE算法，该算法交替改进AHT代理和生成能够探测其缺陷的队友。", "result": "在多样化的AHT环境中进行的广泛实验表明，ROTATE在泛化到未见过的评估队友集合方面显著优于基线方法。", "conclusion": "ROTATE为团队合作的鲁棒性和泛化性设立了新标准，通过开放式学习过程有效提升了AHT代理与未知伙伴协作的能力。"}}
{"id": "2505.23481", "title": "PhysicsNeRF: Physics-Guided 3D Reconstruction from Sparse Views", "authors": ["Mohamed Rayan Barhdadi", "Hasan Kurban", "Hussein Alnuweiri"], "abstract": "PhysicsNeRF is a physically grounded framework for 3D reconstruction from sparse views, extending Neural Radiance Fields with four complementary constraints: depth ranking, RegNeRF-style consistency, sparsity priors, and cross-view alignment. While standard NeRFs fail under sparse supervision, PhysicsNeRF employs a compact 0.67M-parameter architecture and achieves 21.4 dB average PSNR using only 8 views, outperforming prior methods. A generalization gap of 5.7-6.2 dB is consistently observed and analyzed, revealing fundamental limitations of sparse-view reconstruction. PhysicsNeRF enables physically consistent, generalizable 3D representations for agent interaction and simulation, and clarifies the expressiveness-generalization trade-off in constrained NeRF models.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "4 pages, 2 figures, 2 tables. Preliminary work. Under review by the Building Physically Plausible World Models Workshop at the 42nd International Conference on Machine Learning (ICML 2025), Vancouver, Canada", "pdf_url": "https://arxiv.org/pdf/2505.23481.pdf", "abstract_url": "https://arxiv.org/abs/2505.23481", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "PhysicsNeRF是一个基于物理的框架，用于从稀疏视图中进行3D重建，通过结合深度排序、RegNeRF风格的一致性、稀疏先验和跨视图对齐等四种互补约束，扩展了神经辐射场（NeRF）。", "motivation": "解决在稀疏监督下标准NeRF方法失败的问题，提供物理一致且可泛化的3D表示，用于代理交互和模拟。", "method": "采用一个紧凑的0.67M参数架构，结合深度排序、RegNeRF风格的一致性、稀疏先验和跨视图对齐四种约束。", "result": "仅使用8个视图即可实现21.4 dB的平均PSNR，优于先前的方法，并揭示了稀疏视图重建的基本限制。", "conclusion": "PhysicsNeRF不仅实现了物理一致的3D重建，还阐明了约束NeRF模型中表达力与泛化能力之间的权衡。"}}
{"id": "2505.22673", "title": "Physiology-Informed Generative Multi-Task Network for Contrast-Free CT Perfusion", "authors": ["Wasif Khan", "Kyle B. See", "Simon Kato", "Ziqian Huang", "Amy Lazarte", "Kyle Douglas", "Xiangyang Lou", "Teng J. Peng", "Dhanashree Rajderkar", "John Rees", "Pina Sanelli", "Amita Singh", "Ibrahim Tuna", "Christina A. Wilson", "Ruogu Fang"], "abstract": "Perfusion imaging is extensively utilized to assess hemodynamic status and tissue perfusion in various organs. Computed tomography perfusion (CTP) imaging plays a key role in the early assessment and planning of stroke treatment. While CTP provides essential perfusion parameters to identify abnormal blood flow in the brain, the use of contrast agents in CTP can lead to allergic reactions and adverse side effects, along with costing USD 4.9 billion worldwide in 2022. To address these challenges, we propose a novel deep learning framework called Multitask Automated Generation of Intermodal CT perfusion maps (MAGIC). This framework combines generative artificial intelligence and physiological information to map non-contrast computed tomography (CT) imaging to multiple contrast-free CTP imaging maps. We demonstrate enhanced image fidelity by incorporating physiological characteristics into the loss terms. Our network was trained and validated using CT image data from patients referred for stroke at UF Health and demonstrated robustness to abnormalities in brain perfusion activity. A double-blinded study was conducted involving seven experienced neuroradiologists and vascular neurologists. This study validated MAGIC's visual quality and diagnostic accuracy showing favorable performance compared to clinical perfusion imaging with intravenous contrast injection. Overall, MAGIC holds great promise in revolutionizing healthcare by offering contrast-free, cost-effective, and rapid perfusion imaging.", "subjects": "Tissues and Organs (q-bio.TO); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "comments": "Under Review", "pdf_url": "https://arxiv.org/pdf/2505.22673.pdf", "abstract_url": "https://arxiv.org/abs/2505.22673", "categories": ["Tissues and Organs (q-bio.TO)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为MAGIC的新型深度学习框架，旨在通过生成人工智能和生理信息，将非对比计算机断层扫描（CT）成像映射到多个无对比剂的CT灌注成像图，以解决CT灌注成像中使用对比剂带来的问题和成本。", "motivation": "CT灌注成像在评估中风治疗中起着关键作用，但使用对比剂可能导致过敏反应和副作用，且全球成本高昂。本文旨在解决这些问题。", "method": "提出了一种结合生成人工智能和生理信息的多任务自动生成跨模态CT灌注图（MAGIC）的深度学习框架，通过在损失项中融入生理特征来增强图像保真度。", "result": "MAGIC在视觉质量和诊断准确性方面表现出色，与使用静脉对比剂的临床灌注成像相比，显示出优越的性能。", "conclusion": "MAGIC有望通过提供无对比剂、成本效益高且快速的灌注成像，革新医疗保健领域。"}}
{"id": "2505.23187", "title": "Cross-Task Experiential Learning on LLM-based Multi-Agent Collaboration", "authors": ["Yilong Li", "Chen Qian", "Yu Xia", "Ruijie Shi", "Yufan Dang", "Zihao Xie", "Ziming You", "Weize Chen", "Cheng Yang", "Weichuan Liu", "Ye Tian", "Xuantang Xiong", "Lei Han", "Zhiyuan Liu", "Maosong Sun"], "abstract": "Large Language Model-based multi-agent systems (MAS) have shown remarkable progress in solving complex tasks through collaborative reasoning and inter-agent critique. However, existing approaches typically treat each task in isolation, resulting in redundant computations and limited generalization across structurally similar tasks. To address this, we introduce multi-agent cross-task experiential learning (MAEL), a novel framework that endows LLM-driven agents with explicit cross-task learning and experience accumulation. We model the task-solving workflow on a graph-structured multi-agent collaboration network, where agents propagate information and coordinate via explicit connectivity. During the experiential learning phase, we quantify the quality for each step in the task-solving workflow and store the resulting rewards along with the corresponding inputs and outputs into each agent's individual experience pool. During inference, agents retrieve high-reward, task-relevant experiences as few-shot examples to enhance the effectiveness of each reasoning step, thereby enabling more accurate and efficient multi-agent collaboration. Experimental results on diverse datasets demonstrate that MAEL empowers agents to learn from prior task experiences effectively-achieving faster convergence and producing higher-quality solutions on current tasks.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)", "comments": "Work in Progress", "pdf_url": "https://arxiv.org/pdf/2505.23187.pdf", "abstract_url": "https://arxiv.org/abs/2505.23187", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为MAEL的新框架，旨在通过跨任务经验学习提升基于大型语言模型的多智能体系统在解决复杂任务时的协作效率和泛化能力。", "motivation": "现有的基于大型语言模型的多智能体系统在处理任务时通常孤立对待每个任务，导致计算冗余和在结构相似任务间泛化能力有限。", "method": "MAEL框架通过图结构的多智能体协作网络建模任务解决流程，智能体通过显式连接传播信息和协调。在经验学习阶段，量化任务解决流程中每一步的质量，并将结果奖励与相应的输入输出存储到每个智能体的个体经验池中。在推理时，智能体检索高奖励、任务相关的经验作为少样本示例，以增强每一步推理的有效性。", "result": "在多样化数据集上的实验结果表明，MAEL能够有效使智能体从先前的任务经验中学习，实现更快的收敛速度并在当前任务上产生更高质量的解决方案。", "conclusion": "MAEL框架通过跨任务经验学习，显著提升了多智能体协作的准确性和效率，为解决复杂任务提供了一种新的有效方法。"}}
{"id": "2505.22814", "title": "A Large Language Model-Enabled Control Architecture for Dynamic Resource Capability Exploration in Multi-Agent Manufacturing Systems", "authors": ["Jonghan Lim", "Ilya Kovalenko"], "abstract": "Manufacturing environments are becoming more complex and unpredictable due to factors such as demand variations and shorter product lifespans. This complexity requires real-time decision-making and adaptation to disruptions. Traditional control approaches highlight the need for advanced control strategies capable of overcoming unforeseen challenges, as they demonstrate limitations in responsiveness within dynamic industrial settings. Multi-agent systems address these challenges through decentralization of decision-making, enabling systems to respond dynamically to operational changes. However, current multi-agent systems encounter challenges related to real-time adaptation, context-aware decision-making, and the dynamic exploration of resource capabilities. Large language models provide the possibility to overcome these limitations through context-aware decision-making capabilities. This paper introduces a large language model-enabled control architecture for multi-agent manufacturing systems to dynamically explore resource capabilities in response to real-time disruptions. A simulation-based case study demonstrates that the proposed architecture improves system resilience and flexibility. The case study findings show improved throughput and efficient resource utilization compared to existing approaches.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.22814.pdf", "abstract_url": "https://arxiv.org/abs/2505.22814", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于大型语言模型的控制架构，用于多智能体制造系统中动态探索资源能力，以提高系统对实时干扰的响应能力。通过模拟案例研究，证明了该架构在提高系统韧性和灵活性方面的有效性。", "motivation": "制造环境因需求变化和产品生命周期缩短而变得更加复杂和不可预测，传统控制方法在动态工业环境中的响应能力有限，多智能体系统虽能通过分散决策应对这些挑战，但在实时适应、情境感知决策和资源能力动态探索方面仍面临挑战。", "method": "引入大型语言模型支持的控制架构，用于多智能体制造系统，以动态探索资源能力，应对实时干扰。", "result": "模拟案例研究显示，提出的架构提高了系统韧性和灵活性，改善了吞吐量和资源利用效率。", "conclusion": "大型语言模型支持的控制架构为多智能体制造系统提供了一种有效的解决方案，能够动态探索资源能力，提高对实时干扰的响应能力，从而提升制造系统的整体性能。"}}
{"id": "2505.23277", "title": "Sentinel: Attention Probing of Proxy Models for LLM Context Compression with an Understanding Perspective", "authors": ["Yong Zhang", "Yanwen Huang", "Ning Cheng", "Yang Guo", "Yun Zhu", "Yanmeng Wang", "Shaojun Wang", "Jing Xiao"], "abstract": "Retrieval-augmented generation (RAG) enhances large language models (LLMs) with external context, but retrieved passages are often lengthy, noisy, or exceed input limits. Existing compression methods typically require supervised training of dedicated compression models, increasing cost and reducing portability. We propose Sentinel, a lightweight sentence-level compression framework that reframes context filtering as an attention-based understanding task. Rather than training a compression model, Sentinel probes decoder attention from an off-the-shelf 0.5B proxy LLM using a lightweight classifier to identify sentence relevance. Empirically, we find that query-context relevance estimation is consistent across model scales, with 0.5B proxies closely matching the behaviors of larger models. On the LongBench benchmark, Sentinel achieves up to 5$\\times$ compression while matching the QA performance of 7B-scale compression systems. Our results suggest that probing native attention signals enables fast, effective, and question-aware context compression. Code available at:", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "Preprint. 17 pages including appendix", "pdf_url": "https://arxiv.org/pdf/2505.23277.pdf", "abstract_url": "https://arxiv.org/abs/2505.23277", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "Sentinel提出了一种轻量级的句子级压缩框架，通过基于注意力的理解任务来过滤上下文，无需训练专用压缩模型，实现了快速有效的上下文压缩。", "motivation": "检索增强生成（RAG）虽然能够通过外部上下文增强大型语言模型（LLMs），但检索到的段落往往冗长、嘈杂或超出输入限制。现有的压缩方法通常需要监督训练专用的压缩模型，增加了成本并降低了可移植性。", "method": "Sentinel利用现成的0.5B代理LLM的解码器注意力，通过轻量级分类器识别句子相关性，实现了基于注意力的上下文过滤。", "result": "在LongBench基准测试中，Sentinel实现了高达5倍的压缩，同时匹配了7B规模压缩系统的QA性能。", "conclusion": "研究表明，探测原生注意力信号能够实现快速、有效且问题感知的上下文压缩。"}}
{"id": "2505.23291", "title": "ScEdit: Script-based Assessment of Knowledge Editing", "authors": ["Xinye Li", "Zunwen Zheng", "Qian Zhang", "Dekai Zhuang", "Jiabao Kang", "Liyan Xu", "Qingbin Liu", "Xi Chen", "Zhiying Tu", "Dianhui Chu", "Dianbo Sui"], "abstract": "Knowledge Editing (KE) has gained increasing attention, yet current KE tasks remain relatively simple. Under current evaluation frameworks, many editing methods achieve exceptionally high scores, sometimes nearing perfection. However, few studies integrate KE into real-world application scenarios (e.g., recent interest in LLM-as-agent). To support our analysis, we introduce a novel script-based benchmark -- ScEdit (Script-based Knowledge Editing Benchmark) -- which encompasses both counterfactual and temporal edits. We integrate token-level and text-level evaluation methods, comprehensively analyzing existing KE techniques. The benchmark extends traditional fact-based (\"What\"-type question) evaluation to action-based (\"How\"-type question) evaluation. We observe that all KE methods exhibit a drop in performance on established metrics and face challenges on text-level metrics, indicating a challenging task. Our benchmark is available at", "subjects": "Computation and Language (cs.CL)", "comments": "ACL 2025 Findings", "pdf_url": "https://arxiv.org/pdf/2505.23291.pdf", "abstract_url": "https://arxiv.org/abs/2505.23291", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了ScEdit，一个基于脚本的知识编辑评估基准，旨在更全面地评估知识编辑方法在现实应用场景中的表现。", "motivation": "当前的知识编辑任务评估框架相对简单，许多编辑方法在这些框架下表现接近完美，但缺乏在真实世界应用场景中的验证。", "method": "作者提出了一个新颖的基于脚本的基准——ScEdit，该基准包含反事实和时间编辑，并整合了令牌级和文本级的评估方法。", "result": "研究发现，所有知识编辑方法在既定指标上的表现均有所下降，且在文本级指标上面临挑战，表明这是一个具有挑战性的任务。", "conclusion": "ScEdit基准的引入为知识编辑领域提供了一个更全面、更接近实际应用的评估工具，揭示了当前方法在实际应用中的局限性。"}}
{"id": "2505.23299", "title": "Data-efficient Meta-models for Evaluation of Context-based Questions and Answers in LLMs", "authors": ["Julia Belikova", "Konstantin Polev", "Rauf Parchiev", "Dmitry Simakov"], "abstract": "Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) systems are increasingly deployed in industry applications, yet their reliability remains hampered by challenges in detecting hallucinations. While supervised state-of-the-art (SOTA) methods that leverage LLM hidden states -- such as activation tracing and representation analysis -- show promise, their dependence on extensively annotated datasets limits scalability in real-world applications. This paper addresses the critical bottleneck of data annotation by investigating the feasibility of reducing training data requirements for two SOTA hallucination detection frameworks: Lookback Lens, which analyzes attention head dynamics, and probing-based approaches, which decode internal model representations. We propose a methodology combining efficient classification algorithms with dimensionality reduction techniques to minimize sample size demands while maintaining competitive performance. Evaluations on standardized question-answering RAG benchmarks show that our approach achieves performance comparable to strong proprietary LLM-based baselines with only 250 training samples. These results highlight the potential of lightweight, data-efficient paradigms for industrial deployment, particularly in annotation-constrained scenarios.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23299.pdf", "abstract_url": "https://arxiv.org/abs/2505.23299", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文探讨了如何通过结合高效分类算法和降维技术，减少用于检测大型语言模型（LLMs）和检索增强生成（RAG）系统中幻觉的最先进方法所需的训练数据量，同时保持竞争性能。", "motivation": "解决在工业应用中部署大型语言模型和检索增强生成系统时，由于依赖大量标注数据而受限的可扩展性问题。", "method": "提出了一种结合高效分类算法和降维技术的方法论，以减少训练样本需求。", "result": "在标准化的问答RAG基准测试中，仅用250个训练样本就达到了与强大专有LLM基线相当的性能。", "conclusion": "这些结果凸显了在标注受限的场景下，轻量级、数据高效的范式在工业部署中的潜力。"}}
{"id": "2505.22846", "title": "RocqStar: Leveraging Similarity-driven Retrieval and Agentic Systems for Rocq generation", "authors": ["Nikita Khramov", "Andrei Kozyrev", "Gleb Solovev", "Anton Podkopaev"], "abstract": "Interactive Theorem Proving was repeatedly shown to be fruitful combined with Generative Artificial Intelligence. This paper assesses multiple approaches to Rocq generation and illuminates potential avenues for improvement. We highlight the importance of thorough premise selection for generating Rocq proofs and propose a novel approach, leveraging retrieval via a self-attentive embedder model. The evaluation of the designed approach shows up to 28% relative increase of the generator's performance. We tackle the problem of writing Rocq proofs using a multi-stage agentic system, tailored for formal verification, and demonstrate its high effectiveness. We conduct an ablation study and show the use of multi-agent debate on the planning stage of proof synthesis.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Logic in Computer Science (cs.LO); Software Engineering (cs.SE)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.22846.pdf", "abstract_url": "https://arxiv.org/abs/2505.22846", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Logic in Computer Science (cs.LO)", "Software Engineering (cs.SE)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文评估了多种生成Rocq证明的方法，并提出了一种新颖的方法，通过自注意力嵌入模型进行检索，以提高生成器的性能。研究表明，该方法能相对提高生成器性能达28%。", "motivation": "解决在交互式定理证明中生成Rocq证明的问题，特别是在前提选择和证明合成阶段的有效性。", "method": "采用自注意力嵌入模型进行相似性驱动的检索，并结合多阶段代理系统，专为形式验证设计。", "result": "设计的方案使生成器性能相对提高了28%，并通过消融研究展示了多代理辩论在证明合成规划阶段的有效性。", "conclusion": "通过相似性驱动的检索和多代理系统的结合，显著提高了Rocq证明生成的效率和效果，为形式验证领域提供了新的改进方向。"}}
{"id": "2505.22852", "title": "Operationalizing CaMeL: Strengthening LLM Defenses for Enterprise Deployment", "authors": ["Krti Tallam", "Emma Miller"], "abstract": "CaMeL (Capabilities for Machine Learning) introduces a capability-based sandbox to mitigate prompt injection attacks in large language model (LLM) agents. While effective, CaMeL assumes a trusted user prompt, omits side-channel concerns, and incurs performance tradeoffs due to its dual-LLM design. This response identifies these issues and proposes engineering improvements to expand CaMeL's threat coverage and operational usability. We introduce: (1) prompt screening for initial inputs, (2) output auditing to detect instruction leakage, (3) a tiered-risk access model to balance usability and control, and (4) a verified intermediate language for formal guarantees. Together, these upgrades align CaMeL with best practices in enterprise security and support scalable deployment.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.22852.pdf", "abstract_url": "https://arxiv.org/abs/2505.22852", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "CaMeL（机器学习能力）引入了一种基于能力的沙箱，以减轻大型语言模型（LLM）代理中的提示注入攻击。本文识别了CaMeL的局限性，并提出了工程改进，以扩大其威胁覆盖范围和操作可用性。", "motivation": "解决CaMeL在假设用户提示可信、忽略侧信道问题以及因双LLM设计导致的性能折衷方面的局限性。", "method": "提出了四项改进：（1）初始输入的提示筛查，（2）输出审计以检测指令泄漏，（3）分层风险访问模型以平衡可用性和控制，（4）用于形式保证的验证中间语言。", "result": "这些升级使CaMeL与企业安全最佳实践保持一致，并支持可扩展的部署。", "conclusion": "通过提出的改进，CaMeL的威胁覆盖范围和操作可用性得到显著提升，更适合企业级部署。"}}
{"id": "2505.22909", "title": "Learning to Charge More: A Theoretical Study of Collusion by Q-Learning Agents", "authors": ["Cristian Chica", "Yinglong Guo", "Gilad Lerman"], "abstract": "There is growing experimental evidence that $Q$-learning agents may learn to charge supracompetitive prices. We provide the first theoretical explanation for this behavior in infinite repeated games. Firms update their pricing policies based solely on observed profits, without computing equilibrium strategies. We show that when the game admits both a one-stage Nash equilibrium price and a collusive-enabling price, and when the $Q$-function satisfies certain inequalities at the end of experimentation, firms learn to consistently charge supracompetitive prices. We introduce a new class of one-memory subgame perfect equilibria (SPEs) and provide conditions under which learned behavior is supported by naive collusion, grim trigger policies, or increasing strategies. Naive collusion does not constitute an SPE unless the collusive-enabling price is a one-stage Nash equilibrium, whereas grim trigger policies can.", "subjects": "General Economics (econ.GN); Artificial Intelligence (cs.AI); Computer Science and Game Theory (cs.GT)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.22909.pdf", "abstract_url": "https://arxiv.org/abs/2505.22909", "categories": ["General Economics (econ.GN)", "Artificial Intelligence (cs.AI)", "Computer Science and Game Theory (cs.GT)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文通过理论研究了Q学习代理在无限重复游戏中如何学会收取超竞争价格的行为。研究发现，在游戏存在一阶段纳什均衡价格和促成合谋的价格，且Q函数在实验结束时满足特定不等式的情况下，企业会学会持续收取超竞争价格。", "motivation": "解决Q学习代理在无限重复游戏中学会收取超竞争价格行为的理论解释问题。", "method": "研究使用理论分析，探讨了在特定条件下，基于观察利润更新定价策略的Q学习代理如何学会收取超竞争价格。", "result": "研究发现，当游戏满足特定条件时，Q学习代理会学会收取超竞争价格，并且引入了一类新的单记忆子博弈完美均衡（SPEs）。", "conclusion": "研究结论表明，在特定条件下，Q学习代理的行为可以被天真的合谋、严厉触发策略或增加策略所支持，而天真的合谋除非促成合谋的价格是一阶段纳什均衡，否则不构成SPE。"}}
{"id": "2505.23495", "title": "Diagnosing and Addressing Pitfalls in KG-RAG Datasets: Toward More Reliable Benchmarking", "authors": ["Liangliang Zhang", "Zhuorui Jiang", "Hongliang Chi", "Haoyang Chen", "Mohammed Elkoumy", "Fali Wang", "Qiong Wu", "Zhengyi Zhou", "Shirui Pan", "Suhang Wang", "Yao Ma"], "abstract": "Knowledge Graph Question Answering (KGQA) systems rely on high-quality benchmarks to evaluate complex multi-hop reasoning. However, despite their widespread use, popular datasets such as WebQSP and CWQ suffer from critical quality issues, including inaccurate or incomplete ground-truth annotations, poorly constructed questions that are ambiguous, trivial, or unanswerable, and outdated or inconsistent knowledge. Through a manual audit of 16 popular KGQA datasets, including WebQSP and CWQ, we find that the average factual correctness rate is only 57 %. To address these issues, we introduce KGQAGen, an LLM-in-the-loop framework that systematically resolves these pitfalls. KGQAGen combines structured knowledge grounding, LLM-guided generation, and symbolic verification to produce challenging and verifiable QA instances. Using KGQAGen, we construct KGQAGen-10k, a ten-thousand scale benchmark grounded in Wikidata, and evaluate a diverse set of KG-RAG models. Experimental results demonstrate that even state-of-the-art systems struggle on this benchmark, highlighting its ability to expose limitations of existing models. Our findings advocate for more rigorous benchmark construction and position KGQAGen as a scalable framework for advancing KGQA evaluation.", "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": "9 pages", "pdf_url": "https://arxiv.org/pdf/2505.23495.pdf", "abstract_url": "https://arxiv.org/abs/2505.23495", "categories": ["Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文通过手动审核16个流行的KGQA数据集，发现平均事实正确率仅为57%，并提出了KGQAGen框架来解决这些问题，构建了KGQAGen-10k基准测试，展示了现有模型的局限性。", "motivation": "解决知识图谱问答（KGQA）系统中由于数据集质量问题（如不准确或不完整的真实标注、构建不良的问题、过时或不一致的知识）导致的评估不可靠问题。", "method": "引入KGQAGen，一个结合结构化知识基础、LLM引导生成和符号验证的LLM-in-the-loop框架，以产生具有挑战性和可验证的QA实例。", "result": "构建的KGQAGen-10k基准测试显示，即使是先进的KG-RAG模型也在此基准上表现不佳，凸显了现有模型的局限性。", "conclusion": "研究结果主张更严格的基准构建，并将KGQAGen定位为推动KGQA评估的可扩展框架。"}}
{"id": "2505.23752", "title": "ThinkGeo: Evaluating Tool-Augmented Agents for Remote Sensing Tasks", "authors": ["Akashah Shabbir", "Muhammad Akhtar Munir", "Akshay Dudhane", "Muhammad Umer Sheikh", "Muhammad Haris Khan", "Paolo Fraccaro", "Juan Bernabe Moreno", "Fahad Shahbaz Khan", "Salman Khan"], "abstract": "Recent progress in large language models (LLMs) has enabled tool-augmented agents capable of solving complex real-world tasks through step-by-step reasoning. However, existing evaluations often focus on general-purpose or multimodal scenarios, leaving a gap in domain-specific benchmarks that assess tool-use capabilities in complex remote sensing use cases. We present ThinkGeo, an agentic benchmark designed to evaluate LLM-driven agents on remote sensing tasks via structured tool use and multi-step planning. Inspired by tool-interaction paradigms, ThinkGeo includes human-curated queries spanning a wide range of real-world applications such as urban planning, disaster assessment and change analysis, environmental monitoring, transportation analysis, aviation monitoring, recreational infrastructure, and industrial site analysis. Each query is grounded in satellite or aerial imagery and requires agents to reason through a diverse toolset. We implement a ReAct-style interaction loop and evaluate both open and closed-source LLMs (e.g., GPT-4o, Qwen2.5) on 436 structured agentic tasks. The benchmark reports both step-wise execution metrics and final answer correctness. Our analysis reveals notable disparities in tool accuracy and planning consistency across models. ThinkGeo provides the first extensive testbed for evaluating how tool-enabled LLMs handle spatial reasoning in remote sensing. Our code and dataset are publicly available", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23752.pdf", "abstract_url": "https://arxiv.org/abs/2505.23752", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "ThinkGeo是一个评估工具增强代理在遥感任务中表现的基准测试，专注于通过结构化工具使用和多步规划来评估LLM驱动的代理。", "motivation": "现有的评估大多集中在通用或多模态场景，缺乏针对复杂遥感用例中工具使用能力的领域特定基准。", "method": "ThinkGeo包括人类策划的查询，覆盖广泛的实际应用，并实现ReAct风格的交互循环，评估开源和闭源LLM在436个结构化代理任务上的表现。", "result": "分析揭示了不同模型在工具准确性和规划一致性上的显著差异。", "conclusion": "ThinkGeo为评估工具化LLM如何处理遥感中的空间推理提供了首个广泛的测试平台，其代码和数据集已公开。"}}
{"id": "2505.23020", "title": "AgentAlign: Navigating Safety Alignment in the Shift from Informative to Agentic Large Language Models", "authors": ["Jinchuan Zhang", "Lu Yin", "Yan Zhou", "Songlin Hu"], "abstract": "The acquisition of agentic capabilities has transformed LLMs from \"knowledge providers\" to \"action executors\", a trend that while expanding LLMs' capability boundaries, significantly increases their susceptibility to malicious use. Previous work has shown that current LLM-based agents execute numerous malicious tasks even without being attacked, indicating a deficiency in agentic use safety alignment during the post-training phase. To address this gap, we propose AgentAlign, a novel framework that leverages abstract behavior chains as a medium for safety alignment data synthesis. By instantiating these behavior chains in simulated environments with diverse tool instances, our framework enables the generation of highly authentic and executable instructions while capturing complex multi-step dynamics. The framework further ensures model utility by proportionally synthesizing benign instructions through non-malicious interpretations of behavior chains, precisely calibrating the boundary between helpfulness and harmlessness. Evaluation results on AgentHarm demonstrate that fine-tuning three families of open-source models using our method substantially improves their safety (35.8% to 79.5% improvement) while minimally impacting or even positively enhancing their helpfulness, outperforming various prompting methods. The dataset and code have both been open-sourced.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "Submitted to ACL 2025", "pdf_url": "https://arxiv.org/pdf/2505.23020.pdf", "abstract_url": "https://arxiv.org/abs/2505.23020", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了AgentAlign框架，旨在解决大型语言模型（LLMs）从信息提供者转变为行动执行者时面临的安全对齐问题。通过利用抽象行为链作为安全对齐数据合成的媒介，并在模拟环境中实例化这些行为链，该框架能够生成高度真实且可执行的指令，同时捕捉复杂的多步动态。评估结果显示，使用该方法微调的模型在安全性上有显著提升，同时对其帮助性影响最小甚至有所增强。", "motivation": "随着LLMs从'知识提供者'转变为'行动执行者'，其能力边界扩展的同时，也显著增加了被恶意利用的脆弱性。现有研究表明，即使在没有受到攻击的情况下，基于LLM的代理也会执行大量恶意任务，这表明在后训练阶段存在代理使用安全对齐的不足。", "method": "提出了AgentAlign框架，该框架利用抽象行为链作为安全对齐数据合成的媒介，通过在模拟环境中实例化这些行为链，生成高度真实且可执行的指令，并捕捉复杂的多步动态。此外，框架通过行为链的非恶意解释比例合成良性指令，精确校准帮助性和无害性之间的边界。", "result": "在AgentHarm上的评估结果显示，使用该方法微调的三个开源模型家族在安全性上有显著提升（35.8%至79.5%的改善），同时对其帮助性影响最小甚至有所增强，优于各种提示方法。", "conclusion": "AgentAlign框架有效解决了LLMs在转变为行动执行者时的安全对齐问题，显著提高了模型的安全性，同时保持了其帮助性，为LLMs的安全使用提供了新的解决方案。数据集和代码均已开源。"}}
{"id": "2505.23723", "title": "ML-Agent: Reinforcing LLM Agents for Autonomous Machine Learning Engineering", "authors": ["Zexi Liu", "Jingyi Chai", "Xinyu Zhu", "Shuo Tang", "Rui Ye", "Bo Zhang", "Lei Bai", "Siheng Chen"], "abstract": "The emergence of large language model (LLM)-based agents has significantly advanced the development of autonomous machine learning (ML) engineering. However, most existing approaches rely heavily on manual prompt engineering, failing to adapt and optimize based on diverse experimental experiences. Focusing on this, for the first time, we explore the paradigm of learning-based agentic ML, where an LLM agent learns through interactive experimentation on ML tasks using online reinforcement learning (RL). To realize this, we propose a novel agentic ML training framework with three key components: (1) exploration-enriched fine-tuning, which enables LLM agents to generate diverse actions for enhanced RL exploration; (2) step-wise RL, which enables training on a single action step, accelerating experience collection and improving training efficiency; (3) an agentic ML-specific reward module, which unifies varied ML feedback signals into consistent rewards for RL optimization. Leveraging this framework, we train ML-Agent, driven by a 7B-sized Qwen-2.5 LLM for autonomous ML. Remarkably, despite being trained on merely 9 ML tasks, our 7B-sized ML-Agent outperforms the 671B-sized DeepSeek-R1 agent. Furthermore, it achieves continuous performance improvements and demonstrates exceptional cross-task generalization capabilities.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23723.pdf", "abstract_url": "https://arxiv.org/abs/2505.23723", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种基于强化学习的LLM代理训练框架ML-Agent，用于自主机器学习工程，通过探索丰富的微调、逐步强化学习和特定奖励模块，显著提升了代理的性能和跨任务泛化能力。", "motivation": "现有的基于大型语言模型（LLM）的代理方法主要依赖手动提示工程，无法根据多样化的实验经验进行适应和优化。", "method": "提出了一个包含探索丰富微调、逐步强化学习和特定奖励模块的代理训练框架。", "result": "尽管仅在9个ML任务上训练，7B大小的ML-Agent在性能上超过了671B大小的DeepSeek-R1代理，并显示出持续的改进和卓越的跨任务泛化能力。", "conclusion": "学习型代理ML范式通过强化学习实现了自主机器学习的进步，展示了小规模模型在大规模任务上的潜力和效率。"}}
{"id": "2505.23765", "title": "From Chat Logs to Collective Insights: Aggregative Question Answering", "authors": ["Wentao Zhang", "Woojeong Kim", "Yuntian Deng"], "abstract": "Conversational agents powered by large language models (LLMs) are rapidly becoming integral to our daily interactions, generating unprecedented amounts of conversational data. Such datasets offer a powerful lens into societal interests, trending topics, and collective concerns. Yet, existing approaches typically treat these interactions as independent and miss critical insights that could emerge from aggregating and reasoning across large-scale conversation logs. In this paper, we introduce Aggregative Question Answering, a novel task requiring models to reason explicitly over thousands of user-chatbot interactions to answer aggregative queries, such as identifying emerging concerns among specific demographics. To enable research in this direction, we construct a benchmark, WildChat-AQA, comprising 6,027 aggregative questions derived from 182,330 real-world chatbot conversations. Experiments show that existing methods either struggle to reason effectively or incur prohibitive computational costs, underscoring the need for new approaches capable of extracting collective insights from large-scale conversational data.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23765.pdf", "abstract_url": "https://arxiv.org/abs/2505.23765", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了聚合问答这一新任务，旨在通过分析大规模聊天日志来回答聚合性问题，如识别特定人群的新兴关注点。作者构建了一个基准数据集WildChat-AQA，并展示了现有方法在这一任务上的局限性。", "motivation": "随着基于大型语言模型的对话代理在日常互动中的广泛应用，产生了大量的对话数据。这些数据可以反映社会兴趣、趋势话题和集体关注点，但现有方法通常将这些互动视为独立的，忽略了通过聚合和推理大规模对话日志可能获得的关键见解。", "method": "本文提出了聚合问答任务，要求模型明确地对数千次用户与聊天机器人的互动进行推理，以回答聚合性问题。为了支持这一方向的研究，作者构建了一个包含6,027个聚合性问题的基准数据集WildChat-AQA，这些问题源自182,330次真实世界的聊天机器人对话。", "result": "实验表明，现有方法要么难以有效推理，要么计算成本过高，这凸显了需要新的方法能够从大规模对话数据中提取集体见解。", "conclusion": "本文提出的聚合问答任务和WildChat-AQA数据集为从大规模对话数据中提取集体见解提供了新的研究方向，同时也揭示了现有方法在这一领域的不足，为未来研究指明了方向。"}}
{"id": "2505.23189", "title": "TrackVLA: Embodied Visual Tracking in the Wild", "authors": ["Shaoan Wang", "Jiazhao Zhang", "Minghan Li", "Jiahang Liu", "Anqi Li", "Kui Wu", "Fangwei Zhong", "Junzhi Yu", "Zhizheng Zhang", "He Wang"], "abstract": "Embodied visual tracking is a fundamental skill in Embodied AI, enabling an agent to follow a specific target in dynamic environments using only egocentric vision. This task is inherently challenging as it requires both accurate target recognition and effective trajectory planning under conditions of severe occlusion and high scene dynamics. Existing approaches typically address this challenge through a modular separation of recognition and planning. In this work, we propose TrackVLA, a Vision-Language-Action (VLA) model that learns the synergy between object recognition and trajectory planning. Leveraging a shared LLM backbone, we employ a language modeling head for recognition and an anchor-based diffusion model for trajectory planning. To train TrackVLA, we construct an Embodied Visual Tracking Benchmark (EVT-Bench) and collect diverse difficulty levels of recognition samples, resulting in a dataset of 1.7 million samples. Through extensive experiments in both synthetic and real-world environments, TrackVLA demonstrates SOTA performance and strong generalizability. It significantly outperforms existing methods on public benchmarks in a zero-shot manner while remaining robust to high dynamics and occlusion in real-world scenarios at 10 FPS inference speed. Our project page is:", "subjects": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23189.pdf", "abstract_url": "https://arxiv.org/abs/2505.23189", "categories": ["Robotics (cs.RO)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "TrackVLA是一种视觉-语言-动作（VLA）模型，旨在通过结合对象识别和轨迹规划来解决具身视觉跟踪任务中的挑战。", "motivation": "解决在动态环境中仅使用自我中心视觉跟踪特定目标时面临的识别和规划挑战。", "method": "利用共享的LLM骨干网络，结合语言建模头进行识别和基于锚点的扩散模型进行轨迹规划。", "result": "TrackVLA在合成和真实世界环境中展示了最先进的性能和强大的泛化能力，显著优于现有方法。", "conclusion": "TrackVLA通过结合识别和规划，提高了在动态和遮挡条件下的跟踪性能，同时保持了较高的推理速度。"}}
{"id": "2505.22907", "title": "Conversational Alignment with Artificial Intelligence in Context", "authors": ["Rachel Katharine Sterken", "James Ravi Kirkpatrick"], "abstract": "The development of sophisticated artificial intelligence (AI) conversational agents based on large language models raises important questions about the relationship between human norms, values, and practices and AI design and performance. This article explores what it means for AI agents to be conversationally aligned to human communicative norms and practices for handling context and common ground and proposes a new framework for evaluating developers' design choices. We begin by drawing on the philosophical and linguistic literature on conversational pragmatics to motivate a set of desiderata, which we call the CONTEXT-ALIGN framework, for conversational alignment with human communicative practices. We then suggest that current large language model (LLM) architectures, constraints, and affordances may impose fundamental limitations on achieving full conversational alignment.", "subjects": "Computers and Society (cs.CY); Computation and Language (cs.CL)", "comments": "20 pages, to be published in Philosophical Perspectives", "pdf_url": "https://arxiv.org/pdf/2505.22907.pdf", "abstract_url": "https://arxiv.org/abs/2505.22907", "categories": ["Computers and Society (cs.CY)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了人工智能（AI）对话代理如何与人类交流规范和实践中处理上下文和共同点的做法对齐，并提出了一个评估开发者设计选择的新框架。", "motivation": "随着基于大型语言模型（LLM）的复杂AI对话代理的发展，如何使AI设计与人类规范、价值观和实践对齐成为一个重要问题。", "method": "作者从哲学和语言学文献中汲取灵感，提出了一个名为CONTEXT-ALIGN的框架，用于评估AI对话代理与人类交流实践的对齐程度。", "result": "研究表明，当前的大型语言模型架构、限制和功能可能对实现完全的对齐构成根本性限制。", "conclusion": "本文提出了一个评估AI对话代理与人类交流规范对齐的框架，并指出当前技术可能存在的局限性，为未来的研究和开发提供了方向。"}}
{"id": "2505.23266", "title": "Disrupting Vision-Language Model-Driven Navigation Services via Adversarial Object Fusion", "authors": ["Chunlong Xie", "Jialing He", "Shangwei Guo", "Jiacheng Wang", "Shudong Zhang", "Tianwei Zhang", "Tao Xiang"], "abstract": "We present Adversarial Object Fusion (AdvOF), a novel attack framework targeting vision-and-language navigation (VLN) agents in service-oriented environments by generating adversarial 3D objects. While foundational models like Large Language Models (LLMs) and Vision Language Models (VLMs) have enhanced service-oriented navigation systems through improved perception and decision-making, their integration introduces vulnerabilities in mission-critical service workflows. Existing adversarial attacks fail to address service computing contexts, where reliability and quality-of-service (QoS) are paramount. We utilize AdvOF to investigate and explore the impact of adversarial environments on the VLM-based perception module of VLN agents. In particular, AdvOF first precisely aggregates and aligns the victim object positions in both 2D and 3D space, defining and rendering adversarial objects. Then, we collaboratively optimize the adversarial object with regularization between the adversarial and victim object across physical properties and VLM perceptions. Through assigning importance weights to varying views, the optimization is processed stably and multi-viewedly by iterative fusions from local updates and justifications. Our extensive evaluations demonstrate AdvOF can effectively degrade agent performance under adversarial conditions while maintaining minimal interference with normal navigation tasks. This work advances the understanding of service security in VLM-powered navigation systems, providing computational foundations for robust service composition in physical-world deployments.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "comments": "Under review", "pdf_url": "https://arxiv.org/pdf/2505.23266.pdf", "abstract_url": "https://arxiv.org/abs/2505.23266", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了Adversarial Object Fusion (AdvOF)，一种针对视觉与语言导航(VLN)代理的新型攻击框架，通过生成对抗性3D对象来破坏服务导向环境中的导航系统。", "motivation": "大型语言模型(LLMs)和视觉语言模型(VLMs)虽然提升了服务导向导航系统的感知和决策能力，但其集成也引入了在关键任务服务流程中的脆弱性。现有对抗攻击未能充分考虑服务计算环境中对可靠性和服务质量(QoS)的高要求。", "method": "AdvOF首先在2D和3D空间中精确聚合和对齐受害对象位置，定义并渲染对抗性对象。然后，通过对抗性对象与受害对象在物理属性和VLM感知之间的正则化协作优化，以及通过迭代融合从局部更新和调整中稳定且多视角地处理优化。", "result": "广泛的评估表明，AdvOF能在对抗条件下有效降低代理性能，同时对正常导航任务的干扰最小。", "conclusion": "这项工作增进了对VLM驱动导航系统服务安全的理解，为物理世界部署中的鲁棒服务组合提供了计算基础。"}}
{"id": "2505.23239", "title": "OSS-UAgent: An Agent-based Usability Evaluation Framework for Open Source Software", "authors": ["Lingkai Meng", "Yu Shao", "Long Yuan", "Longbin Lai", "Peng Cheng", "Wenyuan Yu", "Wenjie Zhang", "Xuemin Lin", "Jingren Zhou"], "abstract": "Usability evaluation is critical to the impact and adoption of open source software (OSS), yet traditional methods relying on human evaluators suffer from high costs and limited scalability. To address these limitations, we introduce OSS-UAgent, an automated, configurable, and interactive agent-based usability evaluation framework specifically designed for open source software. Our framework employs intelligent agents powered by large language models (LLMs) to simulate developers performing programming tasks across various experience levels (from Junior to Expert). By dynamically constructing platform-specific knowledge bases, OSS-UAgent ensures accurate and context-aware code generation. The generated code is automatically evaluated across multiple dimensions, including compliance, correctness, and readability, providing a comprehensive measure of the software's usability. Additionally, our demonstration showcases OSS-UAgent's practical application in evaluating graph analytics platforms, highlighting its effectiveness in automating usability evaluation.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23239.pdf", "abstract_url": "https://arxiv.org/abs/2505.23239", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "OSS-UAgent是一个基于代理的开源软件可用性评估框架，旨在通过自动化解决传统方法的高成本和可扩展性限制。", "motivation": "解决传统依赖人工评估的开源软件可用性评估方法的高成本和有限可扩展性问题。", "method": "利用大型语言模型（LLMs）驱动的智能代理模拟不同经验水平的开发者执行编程任务，动态构建平台特定知识库以实现准确和上下文感知的代码生成。", "result": "生成的代码在合规性、正确性和可读性等多个维度上自动评估，全面衡量软件的可用性。", "conclusion": "OSS-UAgent在图形分析平台的评估中展示了其自动化可用性评估的有效性，为开源软件的可用性评估提供了一种新方法。"}}
{"id": "2505.23419", "title": "SWE-bench Goes Live!", "authors": ["Linghao Zhang", "Shilin He", "Chaoyun Zhang", "Yu Kang", "Bowen Li", "Chengxing Xie", "Junhao Wang", "Maoquan Wang", "Yufan Huang", "Shengyu Fu", "Elsie Nallipogu", "Qingwei Lin", "Yingnong Dang", "Saravan Rajmohan", "Dongmei Zhang"], "abstract": "The issue-resolving task, where a model generates patches to fix real-world bugs, has emerged as a critical benchmark for evaluating the capabilities of large language models (LLMs). While SWE-bench and its variants have become standard in this domain, they suffer from key limitations: they have not been updated since their initial releases, cover a narrow set of repositories, and depend heavily on manual effort for instance construction and environment setup. These factors hinder scalability and introduce risks of overfitting and data contamination. In this work, we present \\textbf{SWE-bench-Live}, a \\textit{live-updatable} benchmark designed to overcome these challenges. Our initial release consists of 1,319 tasks derived from real GitHub issues created since 2024, spanning 93 repositories. Each task is accompanied by a dedicated Docker image to ensure reproducible execution. Central to our benchmark is \\method, an automated curation pipeline that streamlines the entire process from instance creation to environment setup, removing manual bottlenecks and enabling scalability and continuous updates. We evaluate a range of state-of-the-art agent frameworks and LLMs on SWE-bench-Live, revealing a substantial performance gap compared to static benchmarks like SWE-bench, even under controlled evaluation conditions. To better understand this discrepancy, we perform detailed analyses across repository origin, issue recency, and task difficulty. By providing a fresh, diverse, and executable benchmark grounded in live repository activity, SWE-bench-Live facilitates rigorous, contamination-resistant evaluation of LLMs and agents in dynamic, real-world software development settings.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "}", "pdf_url": "https://arxiv.org/pdf/2505.23419.pdf", "abstract_url": "https://arxiv.org/abs/2505.23419", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了SWE-bench-Live，一个可实时更新的基准测试，旨在解决现有SWE-bench及其变体在评估大型语言模型（LLMs）修复现实世界bug能力时的局限性。通过自动化流程和持续更新，提供了更广泛、更动态的评估环境。", "motivation": "现有的SWE-bench及其变体在评估LLMs修复bug能力时存在局限性，如未更新、覆盖仓库范围窄、依赖人工等，影响了评估的扩展性和准确性。", "method": "提出了SWE-bench-Live，一个包含1,319个任务的实时更新基准测试，每个任务配有Docker镜像以确保可重复执行，并采用自动化流程从实例创建到环境设置。", "result": "在SWE-bench-Live上评估了一系列先进的代理框架和LLMs，发现与静态基准测试相比存在显著性能差距，即使在受控评估条件下也是如此。", "conclusion": "SWE-bench-Live通过提供一个新鲜、多样且可执行的基准测试，促进了在动态、现实世界软件开发环境中对LLMs和代理的严格、抗污染评估。"}}
{"id": "2505.23671", "title": "GSO: Challenging Software Optimization Tasks for Evaluating SWE-Agents", "authors": ["Manish Shetty", "Naman Jain", "Jinjian Liu", "Vijay Kethanaboyina", "Koushik Sen", "Ion Stoica"], "abstract": "Developing high-performance software is a complex task that requires specialized expertise. We introduce GSO, a benchmark for evaluating language models' capabilities in developing high-performance software. We develop an automated pipeline that generates and executes performance tests to analyze repository commit histories to identify 102 challenging optimization tasks across 10 codebases, spanning diverse domains and programming languages. An agent is provided with a codebase and performance test as a precise specification, and tasked to improve the runtime efficiency, which is measured against the expert developer optimization. Our quantitative evaluation reveals that leading SWE-Agents struggle significantly, achieving less than 5% success rate, with limited improvements even with inference-time scaling. Our qualitative analysis identifies key failure modes, including difficulties with low-level languages, practicing lazy optimization strategies, and challenges in accurately localizing bottlenecks. We release the code and artifacts of our benchmark along with agent trajectories to enable future research.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2505.23671.pdf", "abstract_url": "https://arxiv.org/abs/2505.23671", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "GSO是一个用于评估语言模型在开发高性能软件方面能力的基准测试。通过自动化管道生成和执行性能测试，分析了10个代码库中的102个具有挑战性的优化任务。定量评估显示，领先的SWE-Agents成功率低于5%，定性分析揭示了关键失败模式。", "motivation": "开发高性能软件是一项复杂的任务，需要专业知识。本文旨在通过GSO基准测试评估语言模型在此类任务中的能力。", "method": "开发了一个自动化管道，生成和执行性能测试，分析代码库提交历史，识别优化任务。代理被提供代码库和性能测试作为精确规范，任务是提高运行时效率。", "result": "领先的SWE-Agents在优化任务中表现不佳，成功率低于5%，即使在推理时间扩展的情况下改进有限。", "conclusion": "GSO基准测试揭示了语言模型在开发高性能软件方面的挑战，包括处理低级语言的困难、懒惰优化策略的应用以及准确定位瓶颈的挑战。发布了代码和代理轨迹以促进未来研究。"}}
{"id": "2505.23352", "title": "Understanding the Information Propagation Effects of Communication Topologies in LLM-based Multi-Agent Systems", "authors": ["Xu Shen", "Yixin Liu", "Yiwei Dai", "Yili Wang", "Rui Miao", "Yue Tan", "Shirui Pan", "Xin Wang"], "abstract": "The communication topology in large language model-based multi-agent systems fundamentally governs inter-agent collaboration patterns, critically shaping both the efficiency and effectiveness of collective decision-making. While recent studies for communication topology automated design tend to construct sparse structures for efficiency, they often overlook why and when sparse and dense topologies help or hinder collaboration. In this paper, we present a causal framework to analyze how agent outputs, whether correct or erroneous, propagate under topologies with varying sparsity. Our empirical studies reveal that moderately sparse topologies, which effectively suppress error propagation while preserving beneficial information diffusion, typically achieve optimal task performance. Guided by this insight, we propose a novel topology design approach, EIB-leanrner, that balances error suppression and beneficial information propagation by fusing connectivity patterns from both dense and sparse graphs. Extensive experiments show the superior effectiveness, communication cost, and robustness of EIB-leanrner.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23352.pdf", "abstract_url": "https://arxiv.org/abs/2505.23352", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了基于大型语言模型的多智能体系统中通信拓扑结构对信息传播的影响，提出了一个因果框架来分析不同稀疏度拓扑下智能体输出的传播情况，并介绍了一种新的拓扑设计方法EIB-leanrner，以平衡错误抑制和有益信息传播。", "motivation": "解决在大型语言模型基于多智能体系统中，通信拓扑结构设计如何影响信息传播和集体决策效率与效果的问题，特别是稀疏和密集拓扑结构在何时以及为何有助于或阻碍协作的问题。", "method": "提出了一个因果框架来分析智能体输出在不同稀疏度拓扑下的传播情况，并基于实证研究结果，设计了一种新的拓扑设计方法EIB-leanrner，该方法通过融合密集和稀疏图的连接模式来平衡错误抑制和有益信息传播。", "result": "实证研究表明，适度稀疏的拓扑结构能够有效抑制错误传播同时保留有益信息扩散，从而实现最佳任务性能。EIB-leanrner在实验中显示出卓越的有效性、通信成本和鲁棒性。", "conclusion": "通过因果分析和实证研究，本文揭示了通信拓扑结构在多智能体系统中的重要性，并提出了一种有效的拓扑设计方法EIB-leanrner，为未来的多智能体系统设计提供了新的视角和方法。"}}
{"id": "2505.23643", "title": "Securing AI Agents with Information-Flow Control", "authors": ["Manuel Costa", "Boris Köpf", "Aashish Kolluri", "Andrew Paverd", "Mark Russinovich", "Ahmed Salem", "Shruti Tople", "Lukas Wutschitz", "Santiago Zanella-Béguelin"], "abstract": "As AI agents become increasingly autonomous and capable, ensuring their security against vulnerabilities such as prompt injection becomes critical. This paper explores the use of information-flow control (IFC) to provide security guarantees for AI agents. We present a formal model to reason about the security and expressiveness of agent planners. Using this model, we characterize the class of properties enforceable by dynamic taint-tracking and construct a taxonomy of tasks to evaluate security and utility trade-offs of planner designs. Informed by this exploration, we present Fides, a planner that tracks confidentiality and integrity labels, deterministically enforces security policies, and introduces novel primitives for selectively hiding information. Its evaluation in AgentDojo demonstrates that this approach broadens the range of tasks that can be securely accomplished. A tutorial to walk readers through the the concepts introduced in the paper can be found at", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23643.pdf", "abstract_url": "https://arxiv.org/abs/2505.23643", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了使用信息流控制（IFC）为AI代理提供安全保障，提出了一个形式化模型来推理代理规划器的安全性和表达能力，并介绍了Fides规划器，该规划器通过动态污点跟踪和保密性及完整性标签的跟踪，确定性地执行安全策略，扩大了可安全完成的任务范围。", "motivation": "随着AI代理变得越来越自主和强大，确保其安全免受诸如提示注入等漏洞的威胁变得至关重要。", "method": "本文提出了一个形式化模型来推理代理规划器的安全性和表达能力，并介绍了Fides规划器，该规划器通过动态污点跟踪和保密性及完整性标签的跟踪，确定性地执行安全策略。", "result": "在AgentDojo中的评估表明，这种方法扩大了可安全完成的任务范围。", "conclusion": "通过信息流控制和Fides规划器的应用，可以有效地提高AI代理的安全性，同时保持其功能性和实用性。"}}
{"id": "2505.23422", "title": "From Knowledge to Noise: CTIM-Rover and the Pitfalls of Episodic Memory in Software Engineering Agents", "authors": ["Tobias Lindenbauer", "Georg Groh", "Hinrich Schütze"], "abstract": "We introduce CTIM-Rover, an AI agent for Software Engineering (SE) built on top of AutoCodeRover (Zhang et al., 2024) that extends agentic reasoning frameworks with an episodic memory, more specifically, a general and repository-level Cross-Task-Instance Memory (CTIM). While existing open-source SE agents mostly rely on ReAct (Yao et al., 2023b), Reflexion (Shinn et al., 2023), or Code-Act (Wang et al., 2024), all of these reasoning and planning frameworks inefficiently discard their long-term memory after a single task instance. As repository-level understanding is pivotal for identifying all locations requiring a patch for fixing a bug, we hypothesize that SE is particularly well positioned to benefit from CTIM. For this, we build on the Experiential Learning (EL) approach ExpeL (Zhao et al., 2024), proposing a Mixture-Of-Experts (MoEs) inspired approach to create both a general-purpose and repository-level CTIM. We find that CTIM-Rover does not outperform AutoCodeRover in any configuration and thus conclude that neither ExpeL nor DoT-Bank (Lingam et al., 2024) scale to real-world SE problems. Our analysis indicates noise introduced by distracting CTIM items or exemplar trajectories as the likely source of the performance degradation.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": "Short Paper, REALM '25 camera-ready", "pdf_url": "https://arxiv.org/pdf/2505.23422.pdf", "abstract_url": "https://arxiv.org/abs/2505.23422", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "介绍了CTIM-Rover，一个基于AutoCodeRover的软件工程AI代理，它通过引入跨任务实例记忆（CTIM）来扩展代理推理框架。尽管CTIM旨在提升软件工程中的长期记忆利用，但研究发现CTIM-Rover在所有配置中均未超越AutoCodeRover，表明现有的经验学习和记忆方法难以扩展到现实世界的软件工程问题。", "motivation": "解决现有开源软件工程代理在单次任务实例后丢弃长期记忆的低效问题，探索跨任务实例记忆（CTIM）在软件工程中的潜在优势。", "method": "基于Experiential Learning（EL）方法ExpeL，提出了一种受Mixture-Of-Experts（MoEs）启发的策略，构建通用和仓库级别的CTIM。", "result": "CTIM-Rover在所有配置中均未超越AutoCodeRover，分析表明性能下降可能由CTIM项或示例轨迹引入的噪声引起。", "conclusion": "ExpeL和DoT-Bank等方法难以扩展到现实世界的软件工程问题，CTIM在软件工程中的应用面临挑战。"}}
{"id": "2505.23710", "title": "From Connectivity to Autonomy: The Dawn of Self-Evolving Communication Systems", "authors": ["Zeinab Nezami", "Syed Danial Ali Shah", "Maryam Hafeez", "Karim Djemame", "Syed Ali Raza Zaidi"], "abstract": "This paper envisions 6G as a self-evolving telecom ecosystem, where AI-driven intelligence enables dynamic adaptation beyond static connectivity. We explore the key enablers of autonomous communication systems, spanning reconfigurable infrastructure, adaptive middleware, and intelligent network functions, alongside multi-agent collaboration for distributed decision-making. We explore how these methodologies align with emerging industrial IoT frameworks, ensuring seamless integration within digital manufacturing processes. Our findings emphasize the potential for improved real-time decision-making, optimizing efficiency, and reducing latency in networked control systems. The discussion addresses ethical challenges, research directions, and standardization efforts, concluding with a technology stack roadmap to guide future developments. By leveraging state-of-the-art 6G network management techniques, this research contributes to the next generation of intelligent automation solutions, bridging the gap between theoretical advancements and real-world industrial applications.", "subjects": "Systems and Control (eess.SY); Artificial Intelligence (cs.AI); Distributed, Parallel, and Cluster Computing (cs.DC); Emerging Technologies (cs.ET)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.23710.pdf", "abstract_url": "https://arxiv.org/abs/2505.23710", "categories": ["Systems and Control (eess.SY)", "Artificial Intelligence (cs.AI)", "Distributed, Parallel, and Cluster Computing (cs.DC)", "Emerging Technologies (cs.ET)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文设想6G为一个自我演进的电信生态系统，其中AI驱动的智能实现超越静态连接的动态适应。我们探索了自主通信系统的关键推动因素，包括可重构基础设施、自适应中间件和智能网络功能，以及多代理协作的分布式决策。", "motivation": "解决当前通信系统在动态适应和智能自动化方面的不足，以满足未来6G网络和工业物联网框架的需求。", "method": "采用AI驱动的智能技术、可重构基础设施、自适应中间件、智能网络功能和多代理协作的分布式决策方法。", "result": "研究发现，这些方法能够提高实时决策能力，优化效率，并减少网络控制系统的延迟。", "conclusion": "通过利用最先进的6G网络管理技术，本研究为下一代智能自动化解决方案做出了贡献，弥合了理论进展与实际工业应用之间的差距。同时，讨论了伦理挑战、研究方向、标准化努力，并提出了技术栈路线图以指导未来发展。"}}
{"id": "2505.23720", "title": "COBRA: Contextual Bandit Algorithm for Ensuring Truthful Strategic Agents", "authors": ["Arun Verma", "Indrajit Saha", "Makoto Yokoo", "Bryan Kian Hsiang Low"], "abstract": "This paper considers a contextual bandit problem involving multiple agents, where a learner sequentially observes the contexts and the agent's reported arms, and then selects the arm that maximizes the system's overall reward. Existing work in contextual bandits assumes that agents truthfully report their arms, which is unrealistic in many real-life applications. For instance, consider an online platform with multiple sellers; some sellers may misrepresent product quality to gain an advantage, such as having the platform preferentially recommend their products to online users. To address this challenge, we propose an algorithm, COBRA, for contextual bandit problems involving strategic agents that disincentivize their strategic behavior without using any monetary incentives, while having incentive compatibility and a sub-linear regret guarantee. Our experimental results also validate the different performance aspects of our proposed algorithm.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML)", "comments": "This paper proposes a contextual bandit algorithm that prevents strategic agents from misreporting while having approximate incentive compatibility and a sub-linear regret guarantee", "pdf_url": "https://arxiv.org/pdf/2505.23720.pdf", "abstract_url": "https://arxiv.org/abs/2505.23720", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)", "Machine Learning (stat.ML)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为COBRA的上下文多臂老虎机算法，用于处理涉及策略性代理的问题，确保代理的真实性，同时不依赖货币激励。", "motivation": "现有的上下文多臂老虎机算法假设代理会真实报告其选择，这在许多实际应用中是不现实的。例如，在线平台上的卖家可能会为了获得优势而虚假宣传产品质量。", "method": "我们提出了一种算法COBRA，用于处理涉及策略性代理的上下文多臂老虎机问题，该算法在不使用任何货币激励的情况下，抑制代理的策略性行为，同时保证激励兼容性和次线性遗憾。", "result": "实验结果验证了我们提出的算法在不同性能方面的有效性。", "conclusion": "COBRA算法能够有效处理策略性代理的问题，确保代理的真实性，同时保持系统的整体奖励最大化，具有重要的实际应用价值。"}}
