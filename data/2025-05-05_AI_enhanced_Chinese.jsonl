{"id": "2505.00743", "title": "DOPE: Dual Object Perception-Enhancement Network for Vision-and-Language Navigation", "authors": ["Yinfeng Yu", "Dongsheng Yang"], "abstract": "Vision-and-Language Navigation (VLN) is a challenging task where an agent must understand language instructions and navigate unfamiliar environments using visual cues. The agent must accurately locate the target based on visual information from the environment and complete tasks through interaction with the surroundings. Despite significant advancements in this field, two major limitations persist: (1) Many existing methods input complete language instructions directly into multi-layer Transformer networks without fully exploiting the detailed information within the instructions, thereby limiting the agent's language understanding capabilities during task execution; (2) Current approaches often overlook the modeling of object relationships across different modalities, failing to effectively utilize latent clues between objects, which affects the accuracy and robustness of navigation decisions. We propose a Dual Object Perception-Enhancement Network (DOPE) to address these issues to improve navigation performance. First, we design a Text Semantic Extraction (TSE) to extract relatively essential phrases from the text and input them into the Text Object Perception-Augmentation (TOPA) to fully leverage details such as objects and actions within the instructions. Second, we introduce an Image Object Perception-Augmentation (IOPA), which performs additional modeling of object information across different modalities, enabling the model to more effectively utilize latent clues between objects in images and text, enhancing decision-making accuracy. Extensive experiments on the R2R and REVERIE datasets validate the efficacy of the proposed approach.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)", "comments": "Main paper (10 pages). Accepted for publication by ICMR(International Conference on Multimedia Retrieval) 2025", "pdf_url": "https://arxiv.org/pdf/2505.00743.pdf", "abstract_url": "https://arxiv.org/abs/2505.00743", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为DOPE的双对象感知增强网络，旨在通过改进语言理解和跨模态对象关系建模来提升视觉与语言导航任务的性能。", "motivation": "解决视觉与语言导航（VLN）任务中语言指令细节利用不足和跨模态对象关系建模缺失的问题。", "method": "设计了文本语义提取（TSE）和文本对象感知增强（TOPA）来充分利用指令中的细节信息，以及图像对象感知增强（IOPA）来加强跨模态对象信息的建模。", "result": "在R2R和REVERIE数据集上的广泛实验验证了所提方法的有效性。", "conclusion": "DOPE网络通过增强语言理解和跨模态对象关系建模，显著提高了导航决策的准确性和鲁棒性。"}}
{"id": "2505.00740", "title": "Fast2comm:Collaborative perception combined with prior knowledge", "authors": ["Zhengbin Zhang", "Yan Wu", "Hongkun Zhang"], "abstract": "Collaborative perception has the potential to significantly enhance perceptual accuracy through the sharing of complementary information among agents. However, real-world collaborative perception faces persistent challenges, particularly in balancing perception performance and bandwidth limitations, as well as coping with localization errors. To address these challenges, we propose Fast2comm, a prior knowledge-based collaborative perception framework. Specifically, (1)we propose a prior-supervised confidence feature generation method, that effectively distinguishes foreground from background by producing highly discriminative confidence features; (2)we propose GT Bounding Box-based spatial prior feature selection strategy to ensure that only the most informative prior-knowledge features are selected and shared, thereby minimizing background noise and optimizing bandwidth efficiency while enhancing adaptability to localization inaccuracies; (3)we decouple the feature fusion strategies between model training and testing phases, enabling dynamic bandwidth adaptation. To comprehensively validate our framework, we conduct extensive experiments on both real-world and simulated datasets. The results demonstrate the superior performance of our model and highlight the necessity of the proposed methods. Our code is available at", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Multiagent Systems (cs.MA)", "comments": "8pages,8figures", "pdf_url": "https://arxiv.org/pdf/2505.00740.pdf", "abstract_url": "https://arxiv.org/abs/2505.00740", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "Fast2comm是一个基于先验知识的协作感知框架，旨在通过共享互补信息提高感知准确性，同时解决感知性能与带宽限制之间的平衡问题以及定位误差的挑战。", "motivation": "解决现实世界协作感知中感知性能与带宽限制之间的平衡问题，以及应对定位误差的挑战。", "method": "提出了一种先验监督的置信特征生成方法，GT边界框为基础的空间先验特征选择策略，以及在模型训练和测试阶段解耦特征融合策略。", "result": "在真实世界和模拟数据集上的广泛实验证明了模型的优越性能，并突出了所提出方法的必要性。", "conclusion": "Fast2comm框架通过有效区分前景与背景、优化带宽效率和增强对定位不准确性的适应性，显著提高了协作感知的准确性和效率。"}}
{"id": "2505.00759", "title": "Multi-Modal Language Models as Text-to-Image Model Evaluators", "authors": ["Jiahui Chen", "Candace Ross", "Reyhane Askari-Hemmat", "Koustuv Sinha", "Melissa Hall", "Michal Drozdzal", "Adriana Romero-Soriano"], "abstract": "The steady improvements of text-to-image (T2I) generative models lead to slow deprecation of automatic evaluation benchmarks that rely on static datasets, motivating researchers to seek alternative ways to evaluate the T2I progress. In this paper, we explore the potential of multi-modal large language models (MLLMs) as evaluator agents that interact with a T2I model, with the objective of assessing prompt-generation consistency and image aesthetics. We present Multimodal Text-to-Image Eval (MT2IE), an evaluation framework that iteratively generates prompts for evaluation, scores generated images and matches T2I evaluation of existing benchmarks with a fraction of the prompts used in existing static benchmarks. Moreover, we show that MT2IE's prompt-generation consistency scores have higher correlation with human judgment than scores previously introduced in the literature. MT2IE generates prompts that are efficient at probing T2I model performance, producing the same relative T2I model rankings as existing benchmarks while using only 1/80th the number of prompts for evaluation.", "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.00759.pdf", "abstract_url": "https://arxiv.org/abs/2505.00759", "categories": ["Computer Vision and Pattern Recognition (cs.CV)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了多模态大型语言模型（MLLMs）作为评估者代理的潜力，用于评估文本到图像（T2I）生成模型的提示生成一致性和图像美学。提出了多模态文本到图像评估（MT2IE）框架，该框架迭代生成评估提示，评分生成的图像，并以现有静态基准测试中使用的提示的一小部分匹配T2I评估。", "motivation": "随着文本到图像（T2I）生成模型的持续改进，依赖静态数据集的自动评估基准逐渐过时，促使研究者寻找评估T2I进展的替代方法。", "method": "提出了多模态文本到图像评估（MT2IE）框架，利用多模态大型语言模型（MLLMs）作为评估者代理，迭代生成评估提示，评分生成的图像，并与现有基准测试的T2I评估进行匹配。", "result": "MT2IE的提示生成一致性得分与人类判断的相关性高于文献中先前引入的得分。MT2IE生成的提示在探测T2I模型性能方面效率高，仅使用现有基准测试中1/80的提示数量即可产生相同的T2I模型相对排名。", "conclusion": "MT2IE框架展示了多模态大型语言模型在评估文本到图像生成模型方面的潜力，提供了一种高效且与人类判断更一致的评估方法。"}}
{"id": "2505.00747", "title": "Wireless Communication as an Information Sensor for Multi-agent Cooperative Perception: A Survey", "authors": ["Zhiying Song", "Tenghui Xie", "Fuxi Wen", "Jun Li"], "abstract": "Cooperative perception extends the perception capabilities of autonomous vehicles by enabling multi-agent information sharing via Vehicle-to-Everything (V2X) communication. Unlike traditional onboard sensors, V2X acts as a dynamic \"information sensor\" characterized by limited communication, heterogeneity, mobility, and scalability. This survey provides a comprehensive review of recent advancements from the perspective of information-centric cooperative perception, focusing on three key dimensions: information representation, information fusion, and large-scale deployment. We categorize information representation into data-level, feature-level, and object-level schemes, and highlight emerging methods for reducing data volume and compressing messages under communication constraints. In information fusion, we explore techniques under both ideal and non-ideal conditions, including those addressing heterogeneity, localization errors, latency, and packet loss. Finally, we summarize system-level approaches to support scalability in dense traffic scenarios. Compared with existing surveys, this paper introduces a new perspective by treating V2X communication as an information sensor and emphasizing the challenges of deploying cooperative perception in real-world intelligent transportation systems.", "subjects": "Other Computer Science (cs.OH); Computer Vision and Pattern Recognition (cs.CV); Multiagent Systems (cs.MA); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.00747.pdf", "abstract_url": "https://arxiv.org/abs/2505.00747", "categories": ["Other Computer Science (cs.OH)", "Computer Vision and Pattern Recognition (cs.CV)", "Multiagent Systems (cs.MA)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文综述了多智能体协同感知中无线通信作为信息传感器的作用，重点讨论了信息表示、信息融合和大规模部署三个关键维度。", "motivation": "解决自动驾驶车辆通过V2X通信实现多智能体信息共享时面临的通信限制、异构性、移动性和可扩展性等挑战。", "method": "从信息中心的角度，分类信息表示为数据级、特征级和对象级方案，并探索在理想和非理想条件下的信息融合技术。", "result": "提出了减少数据量和压缩消息的新方法，以及在密集交通场景中支持可扩展性的系统级方法。", "conclusion": "通过将V2X通信视为信息传感器，本文为实际智能交通系统中部署协同感知提供了新的视角和解决方案。"}}
{"id": "2505.00753", "title": "A Survey on Large Language Model based Human-Agent Systems", "authors": ["Henry Peng Zou", "Wei-Chieh Huang", "Yaozu Wu", "Yankai Chen", "Chunyu Miao", "Hoang Nguyen", "Yue Zhou", "Weizhi Zhang", "Liancheng Fang", "Langzhou He", "Yangning Li", "Yuwei Cao", "Dongyuan Li", "Renhe Jiang", "Philip S. Yu"], "abstract": "Recent advances in large language models (LLMs) have sparked growing interest in building fully autonomous agents. However, fully autonomous LLM-based agents still face significant challenges, including limited reliability due to hallucinations, difficulty in handling complex tasks, and substantial safety and ethical risks, all of which limit their feasibility and trustworthiness in real-world applications. To overcome these limitations, LLM-based human-agent systems (LLM-HAS) incorporate human-provided information, feedback, or control into the agent system to enhance system performance, reliability and safety. This paper provides the first comprehensive and structured survey of LLM-HAS. It clarifies fundamental concepts, systematically presents core components shaping these systems, including environment & profiling, human feedback, interaction types, orchestration and communication, explores emerging applications, and discusses unique challenges and opportunities. By consolidating current knowledge and offering a structured overview, we aim to foster further research and innovation in this rapidly evolving interdisciplinary field. Paper lists and resources are available at", "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": "}", "pdf_url": "https://arxiv.org/pdf/2505.00753.pdf", "abstract_url": "https://arxiv.org/abs/2505.00753", "categories": ["Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文综述了基于大型语言模型的人-代理系统（LLM-HAS），探讨了如何通过整合人类提供的信息、反馈或控制来克服完全自主代理的局限性，提高系统性能、可靠性和安全性。", "motivation": "解决完全自主的大型语言模型代理在可靠性、处理复杂任务能力以及安全和伦理风险方面的挑战，以增强其在现实世界应用中的可行性和可信度。", "method": "通过系统化的文献综述，明确了LLM-HAS的基本概念，并系统地介绍了构成这些系统的核心组件，包括环境与剖析、人类反馈、交互类型、编排与通信等。", "result": "提供了LLM-HAS的结构化概述，探索了新兴应用，并讨论了该领域的独特挑战和机遇。", "conclusion": "通过整合当前知识和提供结构化概述，旨在促进这一快速发展的跨学科领域的进一步研究和创新。"}}
{"id": "2505.00935", "title": "Autonomous Embodied Agents: When Robotics Meets Deep Learning Reasoning", "authors": ["Roberto Bigazzi"], "abstract": "The increase in available computing power and the Deep Learning revolution have allowed the exploration of new topics and frontiers in Artificial Intelligence research. A new field called Embodied Artificial Intelligence, which places at the intersection of Computer Vision, Robotics, and Decision Making, has been gaining importance during the last few years, as it aims to foster the development of smart autonomous robots and their deployment in society. The recent availability of large collections of 3D models for photorealistic robotic simulation has allowed faster and safe training of learning-based agents for millions of frames and a careful evaluation of their behavior before deploying the models on real robotic platforms. These intelligent agents are intended to perform a certain task in a possibly unknown environment. To this end, during the training in simulation, the agents learn to perform continuous interactions with the surroundings, such as gathering information from the environment, encoding and extracting useful cues for the task, and performing actions towards the final goal; where every action of the agent influences the interactions. This dissertation follows the complete creation process of embodied agents for indoor environments, from their concept to their implementation and deployment. We aim to contribute to research in Embodied AI and autonomous agents, in order to foster future work in this field. We present a detailed analysis of the procedure behind implementing an intelligent embodied agent, comprehending a thorough description of the current state-of-the-art in literature, technical explanations of the proposed methods, and accurate experimental studies on relevant robotic tasks.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)", "comments": "Ph.D. Dissertation", "pdf_url": "https://arxiv.org/pdf/2505.00935.pdf", "abstract_url": "https://arxiv.org/abs/2505.00935", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了自主体现代理（Embodied AI）的新兴领域，结合计算机视觉、机器人技术和决策制定，旨在开发智能自主机器人。通过利用3D模型进行仿真训练，研究展示了从概念到部署的全过程，并对当前技术状态、方法及实验研究进行了详细分析。", "motivation": "解决如何开发能够在未知环境中执行任务的智能自主机器人，以及如何安全有效地训练这些代理的问题。", "method": "利用大规模3D模型进行光真实感机器人仿真，训练学习型代理进行数百万帧的交互学习，包括环境信息收集、任务相关线索提取及目标导向行动执行。", "result": "提出了实现室内环境智能体现代理的完整流程，包括概念化、实施和部署，为Embodied AI领域的未来研究奠定了基础。", "conclusion": "本研究为自主体现代理的发展提供了重要见解和方法，促进了智能机器人在社会中的部署和应用，为未来研究指明了方向。"}}
{"id": "2505.00989", "title": "VTS-LLM: Domain-Adaptive LLM Agent for Enhancing Awareness in Vessel Traffic Services through Natural Language", "authors": ["Sijin Sun", "Liangbin Zhao", "Ming Deng", "Xiuju Fu"], "abstract": "Vessel Traffic Services (VTS) are essential for maritime safety and regulatory compliance through real-time traffic management. However, with increasing traffic complexity and the prevalence of heterogeneous, multimodal data, existing VTS systems face limitations in spatiotemporal reasoning and intuitive human interaction. In this work, we propose VTS-LLM Agent, the first domain-adaptive large LLM agent tailored for interactive decision support in VTS operations. We formalize risk-prone vessel identification as a knowledge-augmented Text-to-SQL task, combining structured vessel databases with external maritime knowledge. To support this, we construct a curated benchmark dataset consisting of a custom schema, domain-specific corpus, and a query-SQL test set in multiple linguistic styles. Our framework incorporates NER-based relational reasoning, agent-based domain knowledge injection, semantic algebra intermediate representation, and query rethink mechanisms to enhance domain grounding and context-aware understanding. Experimental results show that VTS-LLM outperforms both general-purpose and SQL-focused baselines under command-style, operational-style, and formal natural language queries, respectively. Moreover, our analysis provides the first empirical evidence that linguistic style variation introduces systematic performance challenges in Text-to-SQL modeling. This work lays the foundation for natural language interfaces in vessel traffic services and opens new opportunities for proactive, LLM-driven maritime real-time traffic management.", "subjects": "Computation and Language (cs.CL)", "comments": "8 pages, 5 figures, 7 tablels, submitted to ITSC2025", "pdf_url": "https://arxiv.org/pdf/2505.00989.pdf", "abstract_url": "https://arxiv.org/abs/2505.00989", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了VTS-LLM Agent，首个专为船舶交通服务（VTS）操作中的交互式决策支持设计的领域自适应大型语言模型代理，旨在通过自然语言增强VTS的意识和交互能力。", "motivation": "随着交通复杂性的增加和多模态数据的普及，现有的VTS系统在时空推理和直观人机交互方面存在局限，需要更高效的解决方案。", "method": "研究将风险船舶识别形式化为知识增强的Text-to-SQL任务，结合结构化船舶数据库和外部海事知识，并构建了一个定制基准数据集。框架包括基于NER的关系推理、基于代理的领域知识注入、语义代数中间表示和查询重新思考机制。", "result": "实验结果显示，VTS-LLM在命令式、操作式和正式自然语言查询下均优于通用和专注于SQL的基线模型，并首次实证表明语言风格变化对Text-to-SQL建模性能有系统性影响。", "conclusion": "这项工作为船舶交通服务中的自然语言界面奠定了基础，为LLM驱动的主动实时海事交通管理开辟了新机会。"}}
{"id": "2505.00875", "title": "Thoughts without Thinking: Reconsidering the Explanatory Value of Chain-of-Thought Reasoning in LLMs through Agentic Pipelines", "authors": ["Ramesh Manuvinakurike", "Emanuel Moss", "Elizabeth Anne Watkins", "Saurav Sahay", "Giuseppe Raffa", "Lama Nachman"], "abstract": "Agentic pipelines present novel challenges and opportunities for human-centered explainability. The HCXAI community is still grappling with how best to make the inner workings of LLMs transparent in actionable ways. Agentic pipelines consist of multiple LLMs working in cooperation with minimal human control. In this research paper, we present early findings from an agentic pipeline implementation of a perceptive task guidance system. Through quantitative and qualitative analysis, we analyze how Chain-of-Thought (CoT) reasoning, a common vehicle for explainability in LLMs, operates within agentic pipelines. We demonstrate that CoT reasoning alone does not lead to better outputs, nor does it offer explainability, as it tends to produce explanations without explainability, in that they do not improve the ability of end users to better understand systems or achieve their goals.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.00875.pdf", "abstract_url": "https://arxiv.org/abs/2505.00875", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文探讨了在代理管道中，链式思维（CoT）推理对大型语言模型（LLMs）解释性的价值，发现CoT推理本身并不能提高输出质量或提供有效的解释性。", "motivation": "解决代理管道中LLMs的透明度和解释性问题，特别是在缺乏人类控制的情况下，如何使LLMs的内部工作机制对最终用户更透明和可操作。", "method": "通过定量和定性分析，研究了一个感知任务指导系统的代理管道实现中CoT推理的作用。", "result": "研究发现，CoT推理单独使用时，既不能提高输出质量，也不能提供有效的解释性，其生成的解释往往无法帮助用户更好地理解系统或实现目标。", "conclusion": "在代理管道中，仅依赖CoT推理不足以提供有效的解释性或改善输出质量，需要探索其他方法以增强LLMs的透明度和用户理解。"}}
{"id": "2505.00972", "title": "Seeking to Collide: Online Safety-Critical Scenario Generation for Autonomous Driving with Retrieval Augmented Large Language Models", "authors": ["Yuewen Mei", "Tong Nie", "Jian Sun", "Ye Tian"], "abstract": "Simulation-based testing is crucial for validating autonomous vehicles (AVs), yet existing scenario generation methods either overfit to common driving patterns or operate in an offline, non-interactive manner that fails to expose rare, safety-critical corner cases. In this paper, we introduce an online, retrieval-augmented large language model (LLM) framework for generating safety-critical driving scenarios. Our method first employs an LLM-based behavior analyzer to infer the most dangerous intent of the background vehicle from the observed state, then queries additional LLM agents to synthesize feasible adversarial trajectories. To mitigate catastrophic forgetting and accelerate adaptation, we augment the framework with a dynamic memorization and retrieval bank of intent-planner pairs, automatically expanding its behavioral library when novel intents arise. Evaluations using the Waymo Open Motion Dataset demonstrate that our model reduces the mean minimum time-to-collision from 1.62 to 1.08 s and incurs a 75% collision rate, substantially outperforming baselines.", "subjects": "Artificial Intelligence (cs.AI); Robotics (cs.RO)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.00972.pdf", "abstract_url": "https://arxiv.org/abs/2505.00972", "categories": ["Artificial Intelligence (cs.AI)", "Robotics (cs.RO)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一种基于检索增强大型语言模型（LLM）的在线框架，用于生成自动驾驶的安全关键驾驶场景，通过LLM行为分析器和动态记忆检索库，有效暴露罕见的安全临界案例，显著提高了碰撞率和最小碰撞时间。", "motivation": "现有的场景生成方法要么过度拟合常见驾驶模式，要么以离线、非交互方式运行，无法暴露罕见的安全临界案例，这限制了自动驾驶车辆（AVs）的验证效果。", "method": "采用基于LLM的行为分析器推断背景车辆的最危险意图，然后查询额外的LLM代理合成可行的对抗轨迹，并通过动态记忆和检索库增强框架，以减轻灾难性遗忘并加速适应。", "result": "在Waymo Open Motion Dataset上的评估显示，该模型将平均最小碰撞时间从1.62秒减少到1.08秒，并实现了75%的碰撞率，显著优于基线方法。", "conclusion": "提出的在线、检索增强LLM框架有效生成安全关键驾驶场景，提高了自动驾驶车辆的测试效率和安全性，为未来的AV验证提供了新的方向。"}}
{"id": "2505.01073", "title": "Retrieval Augmented Learning: A Retrial-based Large Language Model Self-Supervised Learning and Autonomous Knowledge Generation", "authors": ["Zongyuan Li", "Pengfei Li", "Runnan Qi", "Yanan Ni", "Lumin Jiang", "Hui Wu", "Xuebo Zhang", "Kuihua Huang", "Xian Guo"], "abstract": "The lack of domain-specific data in the pre-training of Large Language Models (LLMs) severely limits LLM-based decision systems in specialized applications, while post-training a model in the scenarios requires significant computational resources. In this paper, we present Retrial-Augmented Learning (RAL), a reward-free self-supervised learning framework for LLMs that operates without model training. By developing Retrieval-Augmented Generation (RAG) into a module for organizing intermediate data, we realized a three-stage autonomous knowledge generation of proposing a hypothesis, validating the hypothesis, and generating the knowledge. The method is evaluated in the LLM-PySC2 environment, a representative decision-making platform that combines sufficient complexity with domain-specific knowledge requirements. Experiments demonstrate that the proposed method effectively reduces hallucination by generating and utilizing validated knowledge, and increases decision-making performance at an extremely low cost. Meanwhile, the approach exhibits potential in out-of-distribution(OOD) tasks, robustness, and transferability, making it a cost-friendly but effective solution for decision-making problems and autonomous knowledge generation.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.01073.pdf", "abstract_url": "https://arxiv.org/abs/2505.01073", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了Retrial-Augmented Learning (RAL)，一种无需模型训练的奖励自由自监督学习框架，通过将Retrieval-Augmented Generation (RAG)发展为组织中间数据的模块，实现了假设提出、验证假设和生成知识的三阶段自主知识生成。该方法在LLM-PySC2环境中评估，有效减少了幻觉，提高了决策性能，并在OOD任务、鲁棒性和可转移性方面展现出潜力。", "motivation": "大型语言模型(LLMs)在预训练中缺乏领域特定数据，严重限制了基于LLM的决策系统在专业应用中的表现，而场景中的后训练需要大量计算资源。", "method": "开发了Retrieval-Augmented Generation (RAG)作为一个模块，用于组织中间数据，实现了一个三阶段的自主知识生成过程：提出假设、验证假设和生成知识。", "result": "实验表明，所提出的方法通过生成和利用验证知识有效减少了幻觉，并在极低成本下提高了决策性能。同时，该方法在OOD任务、鲁棒性和可转移性方面展现出潜力。", "conclusion": "RAL是一种成本友好但有效的解决方案，适用于决策问题和自主知识生成，特别是在领域特定知识需求高且计算资源有限的情况下。"}}
{"id": "2505.01181", "title": "Explainable AI Based Diagnosis of Poisoning Attacks in Evolutionary Swarms", "authors": ["Mehrdad Asadi", "Roxana Rădulescu", "Ann Nowé"], "abstract": "Swarming systems, such as for example multi-drone networks, excel at cooperative tasks like monitoring, surveillance, or disaster assistance in critical environments, where autonomous agents make decentralized decisions in order to fulfill team-level objectives in a robust and efficient manner. Unfortunately, team-level coordinated strategies in the wild are vulnerable to data poisoning attacks, resulting in either inaccurate coordination or adversarial behavior among the agents. To address this challenge, we contribute a framework that investigates the effects of such data poisoning attacks, using explainable AI methods. We model the interaction among agents using evolutionary intelligence, where an optimal coalition strategically emerges to perform coordinated tasks. Then, through a rigorous evaluation, the swarm model is systematically poisoned using data manipulation attacks. We showcase the applicability of explainable AI methods to quantify the effects of poisoning on the team strategy and extract footprint characterizations that enable diagnosing. Our findings indicate that when the model is poisoned above 10%, non-optimal strategies resulting in inefficient cooperation can be identified.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "To appear in short form in Genetic and Evolutionary Computation Conference (GECCO '25 Companion), 2025", "pdf_url": "https://arxiv.org/pdf/2505.01181.pdf", "abstract_url": "https://arxiv.org/abs/2505.01181", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于可解释AI的框架，用于诊断进化群体中的数据中毒攻击，展示了如何通过可解释AI方法量化中毒对团队策略的影响，并提取特征以进行诊断。", "motivation": "群体系统（如多无人机网络）在关键环境中的协作任务中表现出色，但团队级别的协调策略容易受到数据中毒攻击，导致协调不准确或对抗行为。本文旨在解决这一挑战。", "method": "使用进化智能建模代理间的交互，通过数据操纵攻击系统地毒化群体模型，并应用可解释AI方法来量化和诊断中毒的影响。", "result": "研究发现，当模型中毒超过10%时，可以识别出导致低效协作的非最优策略。", "conclusion": "本文的框架和发现为诊断和减轻群体系统中的数据中毒攻击提供了新的视角和方法，有助于提高群体系统的安全性和效率。"}}
{"id": "2505.00749", "title": "The Coral Protocol: Open Infrastructure Connecting The Internet of Agents", "authors": ["Roman J. Georgio", "Caelum Forder", "Suman Deb", "Peter Carroll", "Önder Gürcan"], "abstract": "The Coral Protocol is an open and decentralized collaboration infrastructure that enables communication, coordination, trust and payments for The Internet of Agents. It addresses the growing need for interoperability in a world where organizations are deploying multiple specialized AI agents that must work together across domains and vendors. As a foundational platform for multi-agent AI ecosystems, Coral establishes a common language and coordination framework allowing any agent to participate in complex workflows with others. Its design emphasizes broad compatibility, security, and vendor neutrality, ensuring that agent interactions are efficient and trustworthy. In particular, Coral introduces standardized messaging formats for agent communication, a modular coordination mechanism for orchestrating multi-agent tasks, and secure team formation capabilities for dynamically assembling trusted groups of agents. Together, these innovations position Coral Protocol as a cornerstone of the emerging \"Internet of Agents,\" unlocking new levels of automation, collective intelligence, and business value through open agent collaboration.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": "31 pages, 3 figures, Whitepaper", "pdf_url": "https://arxiv.org/pdf/2505.00749.pdf", "abstract_url": "https://arxiv.org/abs/2505.00749", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "珊瑚协议是一个开放和去中心化的协作基础设施，旨在为‘代理互联网’提供通信、协调、信任和支付功能。", "motivation": "解决在一个组织中部署多个专业AI代理时，这些代理需要跨领域和跨供应商协作的互操作性问题。", "method": "作为一个多代理AI生态系统的基础平台，珊瑚协议建立了一个通用语言和协调框架，允许任何代理参与复杂的工作流程。其设计强调广泛的兼容性、安全性和供应商中立性。", "result": "珊瑚协议引入了标准化的代理通信消息格式、模块化的协调机制用于编排多代理任务，以及安全的团队形成能力，用于动态组建可信的代理群组。", "conclusion": "这些创新使珊瑚协议成为新兴‘代理互联网’的基石，通过开放的代理协作，解锁自动化、集体智能和商业价值的新水平。"}}
{"id": "2505.00841", "title": "From Texts to Shields: Convergence of Large Language Models and Cybersecurity", "authors": ["Tao Li", "Ya-Ting Yang", "Yunian Pan", "Quanyan Zhu"], "abstract": "This report explores the convergence of large language models (LLMs) and cybersecurity, synthesizing interdisciplinary insights from network security, artificial intelligence, formal methods, and human-centered design. It examines emerging applications of LLMs in software and network security, 5G vulnerability analysis, and generative security engineering. The report highlights the role of agentic LLMs in automating complex tasks, improving operational efficiency, and enabling reasoning-driven security analytics. Socio-technical challenges associated with the deployment of LLMs -- including trust, transparency, and ethical considerations -- can be addressed through strategies such as human-in-the-loop systems, role-specific training, and proactive robustness testing. The report further outlines critical research challenges in ensuring interpretability, safety, and fairness in LLM-based systems, particularly in high-stakes domains. By integrating technical advances with organizational and societal considerations, this report presents a forward-looking research agenda for the secure and effective adoption of LLMs in cybersecurity.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.00841.pdf", "abstract_url": "https://arxiv.org/abs/2505.00841", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本报告探讨了大型语言模型（LLMs）与网络安全的融合，综合了来自网络安全、人工智能、形式化方法和以人为中心设计的跨学科见解。", "motivation": "研究大型语言模型在网络安全领域的应用及其带来的挑战，旨在推动LLMs在网络安全中的安全和有效应用。", "method": "通过综合跨学科见解，分析LLMs在软件和网络安全、5G漏洞分析及生成安全工程中的新兴应用。", "result": "报告强调了代理性LLMs在自动化复杂任务、提高操作效率和实现推理驱动的安全分析中的作用，并提出了解决信任、透明度和伦理考虑等社会技术挑战的策略。", "conclusion": "通过整合技术进步与组织和社会考虑，报告提出了一个前瞻性的研究议程，以确保LLM-based系统在高风险领域中的可解释性、安全性和公平性。"}}
{"id": "2505.00913", "title": "Fine-Tuning without Performance Degradation", "authors": ["Han Wang", "Adam White", "Martha White"], "abstract": "Fine-tuning policies learned offline remains a major challenge in application domains. Monotonic performance improvement during \\emph{fine-tuning} is often challenging, as agents typically experience performance degradation at the early fine-tuning stage. The community has identified multiple difficulties in fine-tuning a learned network online, however, the majority of progress has focused on improving learning efficiency during fine-tuning. In practice, this comes at a serious cost during fine-tuning: initially, agent performance degrades as the agent explores and effectively overrides the policy learned offline. We show across a range of settings, many offline-to-online algorithms exhibit either (1) performance degradation or (2) slow learning (sometimes effectively no improvement) during fine-tuning. We introduce a new fine-tuning algorithm, based on an algorithm called Jump Start, that gradually allows more exploration based on online estimates of performance. Empirically, this approach achieves fast fine-tuning and significantly reduces performance degradations compared with existing algorithms designed to do the same.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.00913.pdf", "abstract_url": "https://arxiv.org/abs/2505.00913", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文介绍了一种新的微调算法，旨在解决离线学习策略在在线微调过程中性能下降的问题。通过逐步增加探索，该算法实现了快速微调并显著减少了性能下降。", "motivation": "离线学习的策略在在线微调过程中常常面临性能下降的挑战，尤其是在微调初期。社区虽然已经识别出在线微调学习网络的多个困难，但大多数进展集中在提高微调期间的学习效率上，这在实际应用中带来了严重的性能下降成本。", "method": "本文提出了一种基于Jump Start算法的新微调算法，该算法根据在线性能估计逐步允许更多的探索。", "result": "实验证明，与现有设计用于相同目的的算法相比，这种方法实现了快速微调，并显著减少了性能下降。", "conclusion": "新提出的微调算法有效地解决了离线到在线学习过程中的性能下降问题，为相关领域的研究和应用提供了有价值的参考。"}}
{"id": "2505.01085", "title": "Artificial Intelligence in Government: Why People Feel They Lose Control", "authors": ["Alexander Wuttke", "Adrian Rauchfleisch", "Andreas Jungherr"], "abstract": "The use of Artificial Intelligence (AI) in public administration is expanding rapidly, moving from automating routine tasks to deploying generative and agentic systems that autonomously act on goals. While AI promises greater efficiency and responsiveness, its integration into government functions raises concerns about fairness, transparency, and accountability. This article applies principal-agent theory (PAT) to conceptualize AI adoption as a special case of delegation, highlighting three core tensions: assessability (can decisions be understood?), dependency (can the delegation be reversed?), and contestability (can decisions be challenged?). These structural challenges may lead to a \"failure-by-success\" dynamic, where early functional gains obscure long-term risks to democratic legitimacy. To test this framework, we conducted a pre-registered factorial survey experiment across tax, welfare, and law enforcement domains. Our findings show that although efficiency gains initially bolster trust, they simultaneously reduce citizens' perceived control. When the structural risks come to the foreground, institutional trust and perceived control both drop sharply, suggesting that hidden costs of AI adoption significantly shape public attitudes. The study demonstrates that PAT offers a powerful lens for understanding the institutional and political implications of AI in government, emphasizing the need for policymakers to address delegation risks transparently to maintain public trust.", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.01085.pdf", "abstract_url": "https://arxiv.org/abs/2505.01085", "categories": ["Computers and Society (cs.CY)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文探讨了人工智能在政府中的应用如何影响公众的感知控制，使用委托-代理理论分析了AI采纳中的核心紧张关系，并通过实验展示了效率提升与公众信任和控制感之间的关系。", "motivation": "解决人工智能在公共行政中迅速扩展所带来的公平性、透明度和问责制问题，以及这些如何影响公众对政府的信任和控制感。", "method": "应用委托-代理理论（PAT）将AI采纳概念化为一种特殊的委托情况，并通过预注册的因子调查实验在税收、福利和执法领域测试这一框架。", "result": "研究发现，虽然效率提升最初增强了信任，但同时也减少了公民的感知控制；当结构性风险显现时，制度信任和感知控制都会急剧下降。", "conclusion": "研究强调，委托-代理理论为理解AI在政府中的制度和政治影响提供了强有力的视角，政策制定者需要透明地解决委托风险以维持公众信任。"}}
{"id": "2505.01307", "title": "Document Retrieval Augmented Fine-Tuning (DRAFT) for safety-critical software assessments", "authors": ["Regan Bolton", "Mohammadreza Sheikhfathollahi", "Simon Parkinson", "Vanessa Vulovic", "Gary Bamford", "Dan Basher", "Howard Parkinson"], "abstract": "Safety critical software assessment requires robust assessment against complex regulatory frameworks, a process traditionally limited by manual evaluation. This paper presents Document Retrieval-Augmented Fine-Tuning (DRAFT), a novel approach that enhances the capabilities of a large language model (LLM) for safety-critical compliance assessment. DRAFT builds upon existing Retrieval-Augmented Generation (RAG) techniques by introducing a novel fine-tuning framework that accommodates our dual-retrieval architecture, which simultaneously accesses both software documentation and applicable reference standards. To fine-tune DRAFT, we develop a semi-automated dataset generation methodology that incorporates variable numbers of relevant documents with meaningful distractors, closely mirroring real-world assessment scenarios. Experiments with GPT-4o-mini demonstrate a 7% improvement in correctness over the baseline model, with qualitative improvements in evidence handling, response structure, and domain-specific reasoning. DRAFT represents a practical approach to improving compliance assessment systems while maintaining the transparency and evidence-based reasoning essential in regulatory domains.", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2505.01307.pdf", "abstract_url": "https://arxiv.org/abs/2505.01307", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了文档检索增强微调（DRAFT），一种新颖的方法，用于增强大型语言模型（LLM）在安全关键合规评估中的能力。DRAFT通过引入一种新颖的微调框架和双检索架构，同时访问软件文档和适用的参考标准，提高了评估的准确性和效率。", "motivation": "安全关键软件评估需要针对复杂的监管框架进行 robust 的评估，这一过程传统上受限于手动评估。", "method": "DRAFT 基于现有的检索增强生成（RAG）技术，引入了一种新颖的微调框架，支持双检索架构，同时访问软件文档和适用的参考标准。此外，开发了一种半自动化的数据集生成方法，包含不同数量的相关文档和有意义的干扰项，以紧密模拟真实世界的评估场景。", "result": "使用 GPT-4o-mini 进行的实验显示，与基线模型相比，正确性提高了 7%，在证据处理、响应结构和领域特定推理方面有定性改进。", "conclusion": "DRAFT 提供了一种实用的方法来改进合规评估系统，同时保持了监管领域所必需的透明度和基于证据的推理。"}}
