{"id": "2504.21561", "title": "Iterative Trajectory Exploration for Multimodal Agents", "authors": ["Pengxiang Li", "Zhi Gao", "Bofei Zhang", "Yapeng Mi", "Xiaojian Ma", "Chenrui Shi", "Tao Yuan", "Yuwei Wu", "Yunde Jia", "Song-Chun Zhu", "Qing Li"], "abstract": "Multimodal agents, which integrate a controller (e.g., a large language model) with external tools, have demonstrated remarkable capabilities in tackling complex tasks. However, existing agents need to collect a large number of expert data for fine-tuning to adapt to new environments. In this paper, we propose an online self-exploration method for multimodal agents, namely SPORT, via step-wise preference optimization to refine the trajectories of agents, which automatically generates tasks and learns from solving the generated tasks, without any expert annotation. SPORT operates through four iterative components: task synthesis, step sampling, step verification, and preference tuning. First, we synthesize multi-modal tasks using language models. Then, we introduce a novel search scheme, where step sampling and step verification are executed alternately to solve each generated task. We employ a verifier to provide AI feedback to construct step-wise preference data. The data is subsequently used to update the controller's policy through preference tuning, producing a SPORT Agent. By interacting with real environments, the SPORT Agent evolves into a more refined and capable system. Evaluation in the GTA and GAIA benchmarks show that the SPORT Agent achieves 6.41\\% and 3.64\\% improvements, underscoring the generalization and effectiveness introduced by our method. The project page is", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "16 pages, 8 figures", "pdf_url": "https://arxiv.org/pdf/2504.21561.pdf", "abstract_url": "https://arxiv.org/abs/2504.21561", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"]}
{"id": "2504.21024", "title": "WebEvolver: Enhancing Web Agent Self-Improvement with Coevolving World Model", "authors": ["Tianqing Fang", "Hongming Zhang", "Zhisong Zhang", "Kaixin Ma", "Wenhao Yu", "Haitao Mi", "Dong Yu"], "abstract": "Agent self-improvement, where the backbone Large Language Model (LLM) of the agent are trained on trajectories sampled autonomously based on their own policies, has emerged as a promising approach for enhancing performance. Recent advancements, particularly in web environments, face a critical limitation: their performance will reach a stagnation point during autonomous learning cycles, hindering further improvement. We argue that this stems from limited exploration of the web environment and insufficient exploitation of pre-trained web knowledge in LLMs. To improve the performance of self-improvement, we propose a novel framework that introduces a co-evolving World Model LLM. This world model predicts the next observation based on the current observation and action within the web environment. Leveraging LLMs' pretrained knowledge of abundant web content, the World Model serves dual roles: (1) as a virtual web server generating self-instructed training data to continuously refine the agent's policy, and (2) as an imagination engine during inference, enabling look-ahead simulation to guide action selection for the agent LLM. Experiments in real-world web environments (Mind2Web-Live, WebVoyager, and GAIA-web) show a 10% performance gain over existing self-evolving agents, demonstrating the efficacy and generalizability of our approach, without using any distillation from more powerful close-sourced models. Our work establishes the necessity of integrating world models into autonomous agent frameworks to unlock sustained adaptability.", "subjects": "Computation and Language (cs.CL)", "comments": "19 pages", "pdf_url": "https://arxiv.org/pdf/2504.21024.pdf", "abstract_url": "https://arxiv.org/abs/2504.21024", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2504.21132", "title": "LLM Enhancer: Merged Approach using Vector Embedding for Reducing Large Language Model Hallucinations with External Knowledge", "authors": ["Naheed Rayhan", "Md. Ashrafuzzaman"], "abstract": "Large Language Models (LLMs), such as ChatGPT, have demonstrated the capability to generate human like, natural responses across a range of tasks, including task oriented dialogue and question answering. However, their application in real world, critical scenarios is often hindered by a tendency to produce inaccurate information and a limited ability to leverage external knowledge sources. This paper introduces the LLM ENHANCER system, designed to integrate multiple online sources such as Google, Wikipedia, and DuckDuckGo to enhance data accuracy. The LLMs employed within this system are open source. The data acquisition process for the LLM ENHANCER system operates in parallel, utilizing custom agent tools to manage the flow of information. Vector embeddings are used to identify the most pertinent information, which is subsequently supplied to the LLM for user interaction. The LLM ENHANCER system mitigates hallucinations in chat based LLMs while preserving response naturalness and accuracy.", "subjects": "Computation and Language (cs.CL); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.21132.pdf", "abstract_url": "https://arxiv.org/abs/2504.21132", "categories": ["Computation and Language (cs.CL)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"]}
{"id": "2504.21165", "title": "Detecting Manipulated Contents Using Knowledge-Grounded Inference", "authors": ["Mark Huasong Meng", "Ruizhe Wang", "Meng Xu", "Chuan Yan", "Guangdong Bai"], "abstract": "The detection of manipulated content, a prevalent form of fake news, has been widely studied in recent years. While existing solutions have been proven effective in fact-checking and analyzing fake news based on historical events, the reliance on either intrinsic knowledge obtained during training or manually curated context hinders them from tackling zero-day manipulated content, which can only be recognized with real-time contextual information. In this work, we propose Manicod, a tool designed for detecting zero-day manipulated content. Manicod first sources contextual information about the input claim from mainstream search engines, and subsequently vectorizes the context for the large language model (LLM) through retrieval-augmented generation (RAG). The LLM-based inference can produce a \"truthful\" or \"manipulated\" decision and offer a textual explanation for the decision. To validate the effectiveness of Manicod, we also propose a dataset comprising 4270 pieces of manipulated fake news derived from 2500 recent real-world news headlines. Manicod achieves an overall F1 score of 0.856 on this dataset and outperforms existing methods by up to 1.9x in F1 score on their benchmarks on fact-checking and claim verification.", "subjects": "Computation and Language (cs.CL); Social and Information Networks (cs.SI)", "comments": "16 pages", "pdf_url": "https://arxiv.org/pdf/2504.21165.pdf", "abstract_url": "https://arxiv.org/abs/2504.21165", "categories": ["Computation and Language (cs.CL)", "Social and Information Networks (cs.SI)"], "matching_keywords": ["@RAG"]}
{"id": "2504.21218", "title": "Theoretical Foundations for Semantic Cognition in Artificial Intelligence", "authors": ["Sebastian Dumbrava"], "abstract": "This monograph presents a modular cognitive architecture for artificial intelligence grounded in the formal modeling of belief as structured semantic state. Belief states are defined as dynamic ensembles of linguistic expressions embedded within a navigable manifold, where operators enable assimilation, abstraction, nullification, memory, and introspection. Drawing from philosophy, cognitive science, and neuroscience, we develop a layered framework that enables self-regulating epistemic agents capable of reflective, goal-directed thought. At the core of this framework is the epistemic vacuum: a class of semantically inert cognitive states that serves as the conceptual origin of belief space. From this foundation, the Null Tower arises as a generative structure recursively built through internal representational capacities. The theoretical constructs are designed to be implementable in both symbolic and neural systems, including large language models, hybrid agents, and adaptive memory architectures. This work offers a foundational substrate for constructing agents that reason, remember, and regulate their beliefs in structured, interpretable ways.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.21218.pdf", "abstract_url": "https://arxiv.org/abs/2504.21218", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2504.21347", "title": "IRL Dittos: Embodied Multimodal AI Agent Interactions in Open Spaces", "authors": ["Seonghee Lee", "Denae Ford", "John Tang", "Sasa Junuzovic", "Asta Roseway", "Ed Cutrell", "Kori Inkpen"], "abstract": "We introduce the In Real Life (IRL) Ditto, an AI-driven embodied agent designed to represent remote colleagues in shared office spaces, creating opportunities for real-time exchanges even in their absence. IRL Ditto offers a unique hybrid experience by allowing in-person colleagues to encounter a digital version of their remote teammates, initiating greetings, updates, or small talk as they might in person. Our research question examines: How can the IRL Ditto influence interactions and relationships among colleagues in a shared office space? Through a four-day study, we assessed IRL Ditto's ability to strengthen social ties by simulating presence and enabling meaningful interactions across different levels of social familiarity. We find that enhancing social relationships depended deeply on the foundation of the relationship participants had with the source of the IRL Ditto. This study provides insights into the role of embodied agents in enriching workplace dynamics for distributed teams.", "subjects": "Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)", "comments": "8 pages, 3 figures", "pdf_url": "https://arxiv.org/pdf/2504.21347.pdf", "abstract_url": "https://arxiv.org/abs/2504.21347", "categories": ["Artificial Intelligence (cs.AI)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"]}
{"id": "2504.21433", "title": "NGENT: Next-Generation AI Agents Must Integrate Multi-Domain Abilities to Achieve Artificial General Intelligence", "authors": ["Zhicong Li", "Hangyu Mao", "Jiangjin Yin", "Mingzhe Xing", "Zhiwei Xu", "Yuanxing Zhang", "Yang Xiao"], "abstract": "This paper argues that the next generation of AI agent (NGENT) should integrate across-domain abilities to advance toward Artificial General Intelligence (AGI). Although current AI agents are effective in specialized tasks such as robotics, role-playing, and tool-using, they remain confined to narrow domains. We propose that future AI agents should synthesize the strengths of these specialized systems into a unified framework capable of operating across text, vision, robotics, reinforcement learning, emotional intelligence, and beyond. This integration is not only feasible but also essential for achieving the versatility and adaptability that characterize human intelligence. The convergence of technologies across AI domains, coupled with increasing user demand for cross-domain capabilities, suggests that such integration is within reach. Ultimately, the development of these versatile agents is a critical step toward realizing AGI. This paper explores the rationale for this shift, potential pathways for achieving it.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.21433.pdf", "abstract_url": "https://arxiv.org/abs/2504.21433", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2504.21774", "title": "Is Intermediate Fusion All You Need for UAV-based Collaborative Perception?", "authors": ["Jiuwu Hao", "Liguo Sun", "Yuting Wan", "Yueyang Wu", "Ti Xiang", "Haolin Song", "Pin Lv"], "abstract": "Collaborative perception enhances environmental awareness through inter-agent communication and is regarded as a promising solution to intelligent transportation systems. However, existing collaborative methods for Unmanned Aerial Vehicles (UAVs) overlook the unique characteristics of the UAV perspective, resulting in substantial communication overhead. To address this issue, we propose a novel communication-efficient collaborative perception framework based on late-intermediate fusion, dubbed LIF. The core concept is to exchange informative and compact detection results and shift the fusion stage to the feature representation level. In particular, we leverage vision-guided positional embedding (VPE) and box-based virtual augmented feature (BoBEV) to effectively integrate complementary information from various agents. Additionally, we innovatively introduce an uncertainty-driven communication mechanism that uses uncertainty evaluation to select high-quality and reliable shared areas. Experimental results demonstrate that our LIF achieves superior performance with minimal communication bandwidth, proving its effectiveness and practicality. Code and models are available at", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.21774.pdf", "abstract_url": "https://arxiv.org/abs/2504.21774", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2504.21853", "title": "A Survey of Interactive Generative Video", "authors": ["Jiwen Yu", "Yiran Qin", "Haoxuan Che", "Quande Liu", "Xintao Wang", "Pengfei Wan", "Di Zhang", "Kun Gai", "Hao Chen", "Xihui Liu"], "abstract": "Interactive Generative Video (IGV) has emerged as a crucial technology in response to the growing demand for high-quality, interactive video content across various domains. In this paper, we define IGV as a technology that combines generative capabilities to produce diverse high-quality video content with interactive features that enable user engagement through control signals and responsive feedback. We survey the current landscape of IGV applications, focusing on three major domains: 1) gaming, where IGV enables infinite exploration in virtual worlds; 2) embodied AI, where IGV serves as a physics-aware environment synthesizer for training agents in multimodal interaction with dynamically evolving scenes; and 3) autonomous driving, where IGV provides closed-loop simulation capabilities for safety-critical testing and validation. To guide future development, we propose a comprehensive framework that decomposes an ideal IGV system into five essential modules: Generation, Control, Memory, Dynamics, and Intelligence. Furthermore, we systematically analyze the technical challenges and future directions in realizing each component for an ideal IGV system, such as achieving real-time generation, enabling open-domain control, maintaining long-term coherence, simulating accurate physics, and integrating causal reasoning. We believe that this systematic analysis will facilitate future research and development in the field of IGV, ultimately advancing the technology toward more sophisticated and practical applications.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.21853.pdf", "abstract_url": "https://arxiv.org/abs/2504.21853", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"]}
{"id": "2504.21432", "title": "UAV-VLN: End-to-End Vision Language guided Navigation for UAVs", "authors": ["Pranav Saxena", "Nishant Raghuvanshi", "Neena Goveas"], "abstract": "A core challenge in AI-guided autonomy is enabling agents to navigate realistically and effectively in previously unseen environments based on natural language commands. We propose UAV-VLN, a novel end-to-end Vision-Language Navigation (VLN) framework for Unmanned Aerial Vehicles (UAVs) that seamlessly integrates Large Language Models (LLMs) with visual perception to facilitate human-interactive navigation. Our system interprets free-form natural language instructions, grounds them into visual observations, and plans feasible aerial trajectories in diverse environments.", "subjects": "Robotics (cs.RO); Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.21432.pdf", "abstract_url": "https://arxiv.org/abs/2504.21432", "categories": ["Robotics (cs.RO)", "Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"]}
{"id": "2504.21252", "title": "Talk Before You Retrieve: Agent-Led Discussions for Better RAG in Medical QA", "authors": ["Xuanzhao Dong", "Wenhui Zhu", "Hao Wang", "Xiwen Chen", "Peijie Qiu", "Rui Yin", "Yi Su", "Yalin Wang"], "abstract": "Medical question answering (QA) is a reasoning-intensive task that remains challenging for large language models (LLMs) due to hallucinations and outdated domain knowledge. Retrieval-Augmented Generation (RAG) provides a promising post-training solution by leveraging external knowledge. However, existing medical RAG systems suffer from two key limitations: (1) a lack of modeling for human-like reasoning behaviors during information retrieval, and (2) reliance on suboptimal medical corpora, which often results in the retrieval of irrelevant or noisy snippets. To overcome these challenges, we propose Discuss-RAG, a plug-and-play module designed to enhance the medical QA RAG system through collaborative agent-based reasoning. Our method introduces a summarizer agent that orchestrates a team of medical experts to emulate multi-turn brainstorming, thereby improving the relevance of retrieved content. Additionally, a decision-making agent evaluates the retrieved snippets before their final integration. Experimental results on four benchmark medical QA datasets show that Discuss-RAG consistently outperforms MedRAG, especially significantly improving answer accuracy by up to 16.67% on BioASQ and 12.20% on PubMedQA. The code is available at:", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.21252.pdf", "abstract_url": "https://arxiv.org/abs/2504.21252", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent", "@RAG"]}
{"id": "2504.21474", "title": "Homa at SemEval-2025 Task 5: Aligning Librarian Records with OntoAligner for Subject Tagging", "authors": ["Hadi Bayrami Asl Tekanlou", "Jafar Razmara", "Mahsa Sanaei", "Mostafa Rahgouy", "Hamed Babaei Giglou"], "abstract": "This paper presents our system, Homa, for SemEval-2025 Task 5: Subject Tagging, which focuses on automatically assigning subject labels to technical records from TIBKAT using the Gemeinsame Normdatei (GND) taxonomy. We leverage OntoAligner, a modular ontology alignment toolkit, to address this task by integrating retrieval-augmented generation (RAG) techniques. Our approach formulates the subject tagging problem as an alignment task, where records are matched to GND categories based on semantic similarity. We evaluate OntoAligner's adaptability for subject indexing and analyze its effectiveness in handling multilingual records. Experimental results demonstrate the strengths and limitations of this method, highlighting the potential of alignment techniques for improving subject tagging in digital libraries.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "7 pages, 4 figures, accepted to the LLMs4Subjects shared task at SemEval2025", "pdf_url": "https://arxiv.org/pdf/2504.21474.pdf", "abstract_url": "https://arxiv.org/abs/2504.21474", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"]}
{"id": "2504.21029", "title": "PICO: Secure Transformers via Robust Prompt Isolation and Cybersecurity Oversight", "authors": ["Ben Goertzel", "Paulos Yibelo"], "abstract": "We propose a robust transformer architecture designed to prevent prompt injection attacks and ensure secure, reliable response generation. Our PICO (Prompt Isolation and Cybersecurity Oversight) framework structurally separates trusted system instructions from untrusted user inputs through dual channels that are processed independently and merged only by a controlled, gated fusion mechanism. In addition, we integrate a specialized Security Expert Agent within a Mixture-of-Experts (MoE) framework and incorporate a Cybersecurity Knowledge Graph (CKG) to supply domain-specific reasoning. Our training design further ensures that the system prompt branch remains immutable while the rest of the network learns to handle adversarial inputs safely. This PICO framework is presented via a general mathematical formulation, then elaborated in terms of the specifics of transformer architecture, and fleshed out via hypothetical case studies including Policy Puppetry attacks. While the most effective implementation may involve training transformers in a PICO-based way from scratch, we also present a cost-effective fine-tuning approach.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.21029.pdf", "abstract_url": "https://arxiv.org/abs/2504.21029", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2504.21030", "title": "Advancing Multi-Agent Systems Through Model Context Protocol: Architecture, Implementation, and Applications", "authors": ["Naveen Krishnan"], "abstract": "Multi-agent systems represent a significant advancement in artificial intelligence, enabling complex problem-solving through coordinated specialized agents. However, these systems face fundamental challenges in context management, coordination efficiency, and scalable operation. This paper introduces a comprehensive framework for advancing multi-agent systems through Model Context Protocol (MCP), addressing these challenges through standardized context sharing and coordination mechanisms. We extend previous work on AI agent architectures by developing a unified theoretical foundation, advanced context management techniques, and scalable coordination patterns. Through detailed implementation case studies across enterprise knowledge management, collaborative research, and distributed problem-solving domains, we demonstrate significant performance improvements compared to traditional approaches. Our evaluation methodology provides a systematic assessment framework with benchmark tasks and datasets specifically designed for multi-agent systems. We identify current limitations, emerging research opportunities, and potential transformative applications across industries. This work contributes to the evolution of more capable, collaborative, and context-aware artificial intelligence systems that can effectively address complex real-world challenges.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.21030.pdf", "abstract_url": "https://arxiv.org/abs/2504.21030", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2504.21034", "title": "SAGA: A Security Architecture for Governing AI Agentic Systems", "authors": ["Georgios Syros", "Anshuman Suri", "Cristina Nita-Rotaru", "Alina Oprea"], "abstract": "Large Language Model (LLM)-based agents increasingly interact, collaborate, and delegate tasks to one another autonomously with minimal human interaction. Industry guidelines for agentic system governance emphasize the need for users to maintain comprehensive control over their agents, mitigating potential damage from malicious agents. Several proposed agentic system designs address agent identity, authorization, and delegation, but remain purely theoretical, without concrete implementation and evaluation. Most importantly, they do not provide user-controlled agent management. To address this gap, we propose SAGA, a Security Architecture for Governing Agentic systems, that offers user oversight over their agents' lifecycle. In our design, users register their agents with a central entity, the Provider, that maintains agents contact information, user-defined access control policies, and helps agents enforce these policies on inter-agent communication. We introduce a cryptographic mechanism for deriving access control tokens, that offers fine-grained control over an agent's interaction with other agents, balancing security and performance consideration. We evaluate SAGA on several agentic tasks, using agents in different geolocations, and multiple on-device and cloud LLMs, demonstrating minimal performance overhead with no impact on underlying task utility in a wide range of conditions. Our architecture enables secure and trustworthy deployment of autonomous agents, accelerating the responsible adoption of this technology in sensitive environments.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.21034.pdf", "abstract_url": "https://arxiv.org/abs/2504.21034", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"]}
{"id": "2504.21625", "title": "Meeseeks: An Iterative Benchmark Evaluating LLMs Multi-Turn Instruction-Following Ability", "authors": ["Jiaming Wang"], "abstract": "The ability to follow instructions accurately is fundamental for Large Language Models (LLMs) to serve as reliable agents in real-world applications. While existing instruction-following benchmarks are either single-turn or introduce new requirements in each turn without allowing self-correction, Meeseeks simulates realistic human-LLM interactions through an iterative feedback process. This design enables models to self-correct based on specific requirement failures, better reflecting real-world user-end usage patterns. The benchmark implements a comprehensive evaluation system with 38 capability tags organized across three dimensions: Intent Recognition, Granular Content Validation, and Output Structure Validation. Through rigorous evaluation across LLMs, Meeseeks provides valuable insights into LLMs' instruction-following capabilities in practical applications.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.21625.pdf", "abstract_url": "https://arxiv.org/abs/2504.21625", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2504.21776", "title": "WebThinker: Empowering Large Reasoning Models with Deep Research Capability", "authors": ["Xiaoxi Li", "Jiajie Jin", "Guanting Dong", "Hongjin Qian", "Yutao Zhu", "Yongkang Wu", "Ji-Rong Wen", "Zhicheng Dou"], "abstract": "Large reasoning models (LRMs), such as OpenAI-o1 and DeepSeek-R1, demonstrate impressive long-horizon reasoning capabilities. However, their reliance on static internal knowledge limits their performance on complex, knowledge-intensive tasks and hinders their ability to produce comprehensive research reports requiring synthesis of diverse web information. To address this, we propose \\textbf{WebThinker}, a deep research agent that empowers LRMs to autonomously search the web, navigate web pages, and draft research reports during the reasoning process. WebThinker integrates a \\textbf{Deep Web Explorer} module, enabling LRMs to dynamically search, navigate, and extract information from the web when encountering knowledge gaps. It also employs an \\textbf{Autonomous Think-Search-and-Draft strategy}, allowing the model to seamlessly interleave reasoning, information gathering, and report writing in real time. To further enhance research tool utilization, we introduce an \\textbf{RL-based training strategy} via iterative online Direct Preference Optimization (DPO). Extensive experiments on complex reasoning benchmarks (GPQA, GAIA, WebWalkerQA, HLE) and scientific report generation tasks (Glaive) demonstrate that WebThinker significantly outperforms existing methods and strong proprietary systems. Our approach enhances LRM reliability and applicability in complex scenarios, paving the way for more capable and versatile deep research systems. The code is available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.21776.pdf", "abstract_url": "https://arxiv.org/abs/2504.21776", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["agent"]}
{"id": "2504.21851", "title": "TRUST: An LLM-Based Dialogue System for Trauma Understanding and Structured Assessments", "authors": ["Sichang Tu", "Abigail Powers", "Stephen Doogan", "Jinho D. Choi"], "abstract": "Objectives: While Large Language Models (LLMs) have been widely used to assist clinicians and support patients, no existing work has explored dialogue systems for standard diagnostic interviews and assessments. This study aims to bridge the gap in mental healthcare accessibility by developing an LLM-powered dialogue system that replicates clinician behavior. Materials and Methods: We introduce TRUST, a framework of cooperative LLM modules capable of conducting formal diagnostic interviews and assessments for Post-Traumatic Stress Disorder (PTSD). To guide the generation of appropriate clinical responses, we propose a Dialogue Acts schema specifically designed for clinical interviews. Additionally, we develop a patient simulation approach based on real-life interview transcripts to replace time-consuming and costly manual testing by clinicians. Results: A comprehensive set of evaluation metrics is designed to assess the dialogue system from both the agent and patient simulation perspectives. Expert evaluations by conversation and clinical specialists show that TRUST performs comparably to real-life clinical interviews. Discussion: Our system performs at the level of average clinicians, with room for future enhancements in communication styles and response appropriateness. Conclusions: Our TRUST framework shows its potential to facilitate mental healthcare availability.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "5 figures, 4 tables", "pdf_url": "https://arxiv.org/pdf/2504.21851.pdf", "abstract_url": "https://arxiv.org/abs/2504.21851", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2504.21048", "title": "Multi-Agent Reinforcement Learning for Resources Allocation Optimization: A Survey", "authors": ["Mohamad A. Hady", "Siyi Hu", "Mahardhika Pratama", "Jimmy Cao", "Ryszard Kowalczyk"], "abstract": "Multi-Agent Reinforcement Learning (MARL) has become a powerful framework for numerous real-world applications, modeling distributed decision-making and learning from interactions with complex environments. Resource Allocation Optimization (RAO) benefits significantly from MARL's ability to tackle dynamic and decentralized contexts. MARL-based approaches are increasingly applied to RAO challenges across sectors playing pivotal roles to Industry 4.0 developments. This survey provides a comprehensive review of recent MARL algorithms for RAO, encompassing core concepts, classifications, and a structured taxonomy. By outlining the current research landscape and identifying primary challenges and future directions, this survey aims to support researchers and practitioners in leveraging MARL's potential to advance resource allocation solutions.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.21048.pdf", "abstract_url": "https://arxiv.org/abs/2504.21048", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"]}
{"id": "2504.21716", "title": "LLM-Empowered Embodied Agent for Memory-Augmented Task Planning in Household Robotics", "authors": ["Marc Glocker", "Peter Hönig", "Matthias Hirschmanner", "Markus Vincze"], "abstract": "We present an embodied robotic system with an LLM-driven agent-orchestration architecture for autonomous household object management. The system integrates memory-augmented task planning, enabling robots to execute high-level user commands while tracking past actions. It employs three specialized agents: a routing agent, a task planning agent, and a knowledge base agent, each powered by task-specific LLMs. By leveraging in-context learning, our system avoids the need for explicit model training. RAG enables the system to retrieve context from past interactions, enhancing long-term object tracking. A combination of Grounded SAM and LLaMa3.2-Vision provides robust object detection, facilitating semantic scene understanding for task planning. Evaluation across three household scenarios demonstrates high task planning accuracy and an improvement in memory recall due to RAG. Specifically, Qwen2.5 yields best performance for specialized agents, while LLaMA3.1 excels in routing tasks. The source code is available at:", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "Accepted at Austrian Robotics Workshop 2025", "pdf_url": "https://arxiv.org/pdf/2504.21716.pdf", "abstract_url": "https://arxiv.org/abs/2504.21716", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "@RAG"]}
{"id": "2504.21798", "title": "SWE-smith: Scaling Data for Software Engineering Agents", "authors": ["John Yang", "Kilian Leret", "Carlos E. Jimenez", "Alexander Wettig", "Kabir Khandpur", "Yanzhe Zhang", "Binyuan Hui", "Ofir Press", "Ludwig Schmidt", "Diyi Yang"], "abstract": "Despite recent progress in Language Models (LMs) for software engineering, collecting training data remains a significant pain point. Existing datasets are small, with at most 1,000s of training instances from 11 or fewer GitHub repositories. The procedures to curate such datasets are often complex, necessitating hundreds of hours of human labor; companion execution environments also take up several terabytes of storage, severely limiting their scalability and usability. To address this pain point, we introduce SWE-smith, a novel pipeline for generating software engineering training data at scale. Given any Python codebase, SWE-smith constructs a corresponding execution environment, then automatically synthesizes 100s to 1,000s of task instances that break existing test(s) in the codebase. Using SWE-smith, we create a dataset of 50k instances sourced from 128 GitHub repositories, an order of magnitude larger than all previous works. We train SWE-agent-LM-32B, achieving 40.2% Pass@1 resolve rate on the SWE-bench Verified benchmark, state of the art among open source models. We open source SWE-smith (collection procedure, task instances, trajectories, models) to lower the barrier of entry for research in LM systems for automated software engineering. All assets available at", "subjects": "Software Engineering (cs.SE); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.21798.pdf", "abstract_url": "https://arxiv.org/abs/2504.21798", "categories": ["Software Engineering (cs.SE)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"]}
{"id": "2504.21205", "title": "SecRepoBench: Benchmarking LLMs for Secure Code Generation in Real-World Repositories", "authors": ["Connor Dilgren", "Purva Chiniya", "Luke Griffith", "Yu Ding", "Yizheng Chen"], "abstract": "This paper introduces SecRepoBench, a benchmark to evaluate LLMs on secure code generation in real-world repositories. SecRepoBench has 318 code generation tasks in 27 C/C++ repositories, covering 15 CWEs. We evaluate 19 state-of-the-art LLMs using our benchmark and find that the models struggle with generating correct and secure code. In addition, the performance of LLMs to generate self-contained programs as measured by prior benchmarks do not translate to comparative performance at generating secure and correct code at the repository level in SecRepoBench. We show that the state-of-the-art prompt engineering techniques become less effective when applied to the repository level secure code generation problem. We conduct extensive experiments, including an agentic technique to generate secure code, to demonstrate that our benchmark is currently the most difficult secure coding benchmark, compared to previous state-of-the-art benchmarks. Finally, our comprehensive analysis provides insights into potential directions for enhancing the ability of LLMs to generate correct and secure code in real-world repositories.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.21205.pdf", "abstract_url": "https://arxiv.org/abs/2504.21205", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"]}
{"id": "2504.21454", "title": "SimPRIVE: a Simulation framework for Physical Robot Interaction with Virtual Environments", "authors": ["Federico Nesti", "Gianluca D'Amico", "Mauro Marinoni", "Giorgio Buttazzo"], "abstract": "The use of machine learning in cyber-physical systems has attracted the interest of both industry and academia. However, no general solution has yet been found against the unpredictable behavior of neural networks and reinforcement learning agents. Nevertheless, the improvements of photo-realistic simulators have paved the way towards extensive testing of complex algorithms in different virtual scenarios, which would be expensive and dangerous to implement in the real world.", "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)", "comments": "Submitted to IEEE ITSC 2025", "pdf_url": "https://arxiv.org/pdf/2504.21454.pdf", "abstract_url": "https://arxiv.org/abs/2504.21454", "categories": ["Robotics (cs.RO)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"]}
{"id": "2504.21848", "title": "Characterizing AI Agents for Alignment and Governance", "authors": ["Atoosa Kasirzadeh", "Iason Gabriel"], "abstract": "The creation of effective governance mechanisms for AI agents requires a deeper understanding of their core properties and how these properties relate to questions surrounding the deployment and operation of agents in the world. This paper provides a characterization of AI agents that focuses on four dimensions: autonomy, efficacy, goal complexity, and generality. We propose different gradations for each dimension, and argue that each dimension raises unique questions about the design, operation, and governance of these systems. Moreover, we draw upon this framework to construct \"agentic profiles\" for different kinds of AI agents. These profiles help to illuminate cross-cutting technical and non-technical governance challenges posed by different classes of AI agents, ranging from narrow task-specific assistants to highly autonomous general-purpose systems. By mapping out key axes of variation and continuity, this framework provides developers, policymakers, and members of the public with the opportunity to develop governance approaches that better align with collective societal goals.", "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI); Systems and Control (eess.SY)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.21848.pdf", "abstract_url": "https://arxiv.org/abs/2504.21848", "categories": ["Computers and Society (cs.CY)", "Artificial Intelligence (cs.AI)", "Systems and Control (eess.SY)"], "matching_keywords": ["agent", "agentic"]}
