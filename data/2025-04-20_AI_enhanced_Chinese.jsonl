{"id": "2504.12696", "title": "Collaborative Perception Datasets for Autonomous Driving: A Review", "authors": ["Naibang Wang", "Deyong Shang", "Yan Gong", "Xiaoxi Hu", "Ziying Song", "Lei Yang", "Yuhan Huang", "Xiaoyu Wang", "Jianli Lu"], "abstract": "Collaborative perception has attracted growing interest from academia and industry due to its potential to enhance perception accuracy, safety, and robustness in autonomous driving through multi-agent information fusion. With the advancement of Vehicle-to-Everything (V2X) communication, numerous collaborative perception datasets have emerged, varying in cooperation paradigms, sensor configurations, data sources, and application scenarios. However, the absence of systematic summarization and comparative analysis hinders effective resource utilization and standardization of model evaluation. As the first comprehensive review focused on collaborative perception datasets, this work reviews and compares existing resources from a multi-dimensional perspective. We categorize datasets based on cooperation paradigms, examine their data sources and scenarios, and analyze sensor modalities and supported tasks. A detailed comparative analysis is conducted across multiple dimensions. We also outline key challenges and future directions, including dataset scalability, diversity, domain adaptation, standardization, privacy, and the integration of large language models. To support ongoing research, we provide a continuously updated online repository of collaborative perception datasets and related literature:", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": "18pages, 7figures, journal", "pdf_url": "https://arxiv.org/pdf/2504.12696.pdf", "abstract_url": "https://arxiv.org/abs/2504.12696", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文综述了自动驾驶领域的协作感知数据集，首次从多维度角度对现有资源进行了系统性的回顾与比较，并指出了关键挑战与未来方向。", "motivation": "解决由于缺乏系统性总结和比较分析而导致的资源利用效率低下和模型评估标准化问题。", "method": "从合作范式、数据来源与场景、传感器模态及支持任务等多个维度对现有数据集进行分类和比较分析。", "result": "提出了数据集可扩展性、多样性、领域适应、标准化、隐私保护及大语言模型整合等关键挑战和未来研究方向。", "conclusion": "通过提供持续更新的在线资源库，支持自动驾驶协作感知领域的持续研究，促进资源的有效利用和技术的标准化发展。"}}
{"id": "2504.12679", "title": "TongUI: Building Generalized GUI Agents by Learning from Multimodal Web Tutorials", "authors": ["Bofei Zhang", "Zirui Shang", "Zhi Gao", "Wang Zhang", "Rui Xie", "Xiaojian Ma", "Tao Yuan", "Xinxiao Wu", "Song-Chun Zhu", "Qing Li"], "abstract": "Building Graphical User Interface (GUI) agents is a promising research direction, which simulates human interaction with computers or mobile phones to perform diverse GUI tasks. However, a major challenge in developing generalized GUI agents is the lack of sufficient trajectory data across various operating systems and applications, mainly due to the high cost of manual annotations. In this paper, we propose the TongUI framework that builds generalized GUI agents by learning from rich multimodal web tutorials. Concretely, we crawl and process online GUI tutorials (such as videos and articles) into GUI agent trajectory data, through which we produce the GUI-Net dataset containing 143K trajectory data across five operating systems and more than 200 applications. We develop the TongUI agent by fine-tuning Qwen2.5-VL-3B/7B models on GUI-Net, which show remarkable performance improvements on commonly used grounding and navigation benchmarks, outperforming baseline agents about 10\\% on multiple benchmarks, showing the effectiveness of the GUI-Net dataset and underscoring the significance of our TongUI framework. We will fully open-source the code, the GUI-Net dataset, and the trained models soon.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12679.pdf", "abstract_url": "https://arxiv.org/abs/2504.12679", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "TongUI框架通过从多模态网络教程中学习，构建了通用的GUI代理，解决了因手动标注成本高而缺乏跨操作系统和应用程序轨迹数据的问题。", "motivation": "开发通用GUI代理的主要挑战是缺乏跨各种操作系统和应用程序的足够轨迹数据，这主要是由于手动标注的高成本。", "method": "提出TongUI框架，通过爬取和处理在线GUI教程（如视频和文章）为GUI代理轨迹数据，创建了包含143K轨迹数据的GUI-Net数据集，并在该数据集上微调Qwen2.5-VL-3B/7B模型。", "result": "TongUI代理在常用的基础和导航基准测试中表现出显著的性能提升，在多个基准测试中优于基线代理约10%。", "conclusion": "GUI-Net数据集的有效性和TongUI框架的重要性得到了验证，代码、GUI-Net数据集和训练模型将完全开源。"}}
{"id": "2504.12313", "title": "Exploring the Impact of Personality Traits on Conversational Recommender Systems: A Simulation with Large Language Models", "authors": ["Xiaoyan Zhao", "Yang Deng", "Wenjie Wang", "Hongzhan lin", "Hong Cheng", "Rui Zhang", "See-Kiong Ng", "Tat-Seng Chua"], "abstract": "Conversational Recommender Systems (CRSs) engage users in multi-turn interactions to deliver personalized recommendations. The emergence of large language models (LLMs) further enhances these systems by enabling more natural and dynamic user interactions. However, a key challenge remains in understanding how personality traits shape conversational recommendation outcomes. Psychological evidence highlights the influence of personality traits on user interaction behaviors. To address this, we introduce an LLM-based personality-aware user simulation for CRSs (PerCRS). The user agent induces customizable personality traits and preferences, while the system agent possesses the persuasion capability to simulate realistic interaction in CRSs. We incorporate multi-aspect evaluation to ensure robustness and conduct extensive analysis from both user and system perspectives. Experimental results demonstrate that state-of-the-art LLMs can effectively generate diverse user responses aligned with specified personality traits, thereby prompting CRSs to dynamically adjust their recommendation strategies. Our experimental analysis offers empirical insights into the impact of personality traits on the outcomes of conversational recommender systems.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12313.pdf", "abstract_url": "https://arxiv.org/abs/2504.12313", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了人格特质对会话推荐系统（CRSs）的影响，并提出了一个基于大型语言模型（LLMs）的人格感知用户模拟（PerCRS）。通过实验证明，先进的LLMs能够有效生成与指定人格特质一致的用户响应，从而促使CRSs动态调整其推荐策略。", "motivation": "理解人格特质如何影响会话推荐系统的结果是一个关键挑战。心理学证据表明，人格特质对用户交互行为有影响。", "method": "引入了一个基于LLM的人格感知用户模拟（PerCRS），用户代理诱导可定制的人格特质和偏好，系统代理具备说服能力以模拟CRSs中的现实交互。", "result": "实验结果表明，先进的LLMs能够有效生成与指定人格特质一致的用户响应，促使CRSs动态调整其推荐策略。", "conclusion": "本文的实验分析为理解人格特质对会话推荐系统结果的影响提供了实证见解，展示了LLMs在模拟多样化用户响应和动态调整推荐策略方面的潜力。"}}
{"id": "2504.12667", "title": "Two Tasks, One Goal: Uniting Motion and Planning for Excellent End To End Autonomous Driving Performance", "authors": ["Lin Liu", "Ziying Song", "Hongyu Pan", "Lei Yang", "Caiyan Jia"], "abstract": "End-to-end autonomous driving has made impressive progress in recent years. Former end-to-end autonomous driving approaches often decouple planning and motion tasks, treating them as separate modules. This separation overlooks the potential benefits that planning can gain from learning out-of-distribution data encountered in motion tasks. However, unifying these tasks poses significant challenges, such as constructing shared contextual representations and handling the unobservability of other vehicles' states. To address these challenges, we propose TTOG, a novel two-stage trajectory generation framework. In the first stage, a diverse set of trajectory candidates is generated, while the second stage focuses on refining these candidates through vehicle state information. To mitigate the issue of unavailable surrounding vehicle states, TTOG employs a self-vehicle data-trained state estimator, subsequently extended to other vehicles. Furthermore, we introduce ECSA (equivariant context-sharing scene adapter) to enhance the generalization of scene representations across different agents. Experimental results demonstrate that TTOG achieves state-of-the-art performance across both planning and motion tasks. Notably, on the challenging open-loop nuScenes dataset, TTOG reduces the L2 distance by 36.06\\%. Furthermore, on the closed-loop Bench2Drive dataset, our approach achieves a 22\\% improvement in the driving score (DS), significantly outperforming existing baselines.", "subjects": "Computer Vision and Pattern Recognition (cs.CV)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12667.pdf", "abstract_url": "https://arxiv.org/abs/2504.12667", "categories": ["Computer Vision and Pattern Recognition (cs.CV)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种新颖的两阶段轨迹生成框架TTOG，旨在统一自动驾驶中的规划和运动任务，通过共享上下文表示和处理其他车辆状态不可观测的挑战，显著提升了端到端自动驾驶的性能。", "motivation": "现有的端到端自动驾驶方法通常将规划和运动任务解耦，忽视了运动任务中学习到的分布外数据对规划的潜在益处。本文旨在解决统一这两项任务时面临的挑战，如构建共享的上下文表示和处理其他车辆状态的不可观测性。", "method": "提出了TTOG框架，包括生成多样化轨迹候选的第一阶段和通过车辆状态信息细化这些候选的第二阶段。为了解决周围车辆状态不可用的问题，TTOG采用了自车数据训练的状态估计器，并扩展到其他车辆。此外，引入了ECSA（等变上下文共享场景适配器）以增强不同代理间场景表示的泛化能力。", "result": "实验结果表明，TTOG在规划和运动任务上都达到了最先进的性能。在nuScenes数据集上，L2距离减少了36.06%；在Bench2Drive数据集上，驾驶分数（DS）提高了22%，显著优于现有基线。", "conclusion": "TTOG框架通过统一规划和运动任务，有效解决了端到端自动驾驶中的关键挑战，显著提升了性能，为未来的自动驾驶研究提供了新的方向。"}}
{"id": "2504.12323", "title": "The Other Side of the Coin: Exploring Fairness in Retrieval-Augmented Generation", "authors": ["Zheng Zhang", "Ning Li", "Qi Liu", "Rui Li", "Weibo Gao", "Qingyang Mao", "Zhenya Huang", "Baosheng Yu", "Dacheng Tao"], "abstract": "Retrieval-Augmented Generation (RAG) enhances Large Language Models (LLMs) by retrieving relevant document from external knowledge sources. By referencing this external knowledge, RAG effectively reduces the generation of factually incorrect content and addresses hallucination issues within LLMs. Recently, there has been growing attention to improving the performance and efficiency of RAG systems from various perspectives. While these advancements have yielded significant results, the application of RAG in domains with considerable societal implications raises a critical question about fairness: What impact does the introduction of the RAG paradigm have on the fairness of LLMs? To address this question, we conduct extensive experiments by varying the LLMs, retrievers, and retrieval sources. Our experimental analysis reveals that the scale of the LLMs plays a significant role in influencing fairness outcomes within the RAG framework. When the model scale is smaller than 8B, the integration of retrieval mechanisms often exacerbates unfairness in small-scale LLMs (e.g., LLaMA3.2-1B, Mistral-7B, and LLaMA3-8B). To mitigate the fairness issues introduced by RAG for small-scale LLMs, we propose two approaches, FairFT and FairFilter. Specifically, in FairFT, we align the retriever with the LLM in terms of fairness, enabling it to retrieve documents that facilitate fairer model outputs. In FairFilter, we propose a fairness filtering mechanism to filter out biased content after retrieval. Finally, we validate our proposed approaches on real-world datasets, demonstrating their effectiveness in improving fairness while maintaining performance.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "12 pages", "pdf_url": "https://arxiv.org/pdf/2504.12323.pdf", "abstract_url": "https://arxiv.org/abs/2504.12323", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文探讨了检索增强生成（RAG）在大型语言模型（LLMs）中应用的公平性问题，发现小规模LLMs（小于8B）在整合检索机制时往往会加剧不公平性，并提出了两种方法（FairFT和FairFilter）来缓解这一问题。", "motivation": "随着RAG系统在具有重大社会影响的领域中的应用增加，其对LLMs公平性的影响成为一个关键问题。", "method": "通过变化LLMs、检索器和检索源进行广泛实验，提出了FairFT和FairFilter两种方法来缓解RAG引入的公平性问题。", "result": "实验分析显示，模型规模对RAG框架内的公平性结果有显著影响，小规模LLMs在整合检索机制时往往会加剧不公平性。提出的FairFT和FairFilter方法在真实数据集上验证了其有效性。", "conclusion": "研究强调了在应用RAG时考虑公平性的重要性，并提出了有效的解决方案，以在保持性能的同时改善公平性。"}}
{"id": "2504.12322", "title": "A Strategic Coordination Framework of Small LLMs Matches Large LLMs in Data Synthesis", "authors": ["Xin Gao", "Qizhi Pei", "Zinan Tang", "Yu Li", "Honglin Lin", "Jiang Wu", "Conghui He", "Lijun Wu"], "abstract": "While data synthesis and distillation are promising strategies to enhance small language models, current approaches heavily rely on Large Language Models (LLMs), which suffer from high computational costs, environmental inefficiency, and potential biases inherited from monolithic architectures. In contrast, smaller LLMs are more accessible and sustainable, but their individual capabilities often fall short in generating high-quality, diverse, and reliable data. Inspired by collaborative human processes (e.g., peer review), we propose a multiple small LLMs involved framework, GRA, that aggregates specialized roles across small LLMs to iterative refinement and quality control typically achieved by a single large LLM. In this collaborative framework, multiple small LLMs assume distinct roles-Generator, Reviewer, and Adjudicator-to simulate a peer-review-inspired data synthesis pipeline. The Generator proposes initial data samples, the Reviewer critiques their quality and diversity, and the Adjudicator resolves conflicts to finalize the output. By decomposing the synthesis process into specialized sub-tasks, collaborative small LLMs can achieve data-level parity with large LLM-based distillation. Through experiments across multiple benchmarks, we demonstrate that GRA-produced data matches or exceeds the quality of single large LLM outputs, e.g., Qwen-2.5-72B-Instruct. Our results challenge the necessity of monolithic large models for high-quality data synthesis, advocating instead for strategic coordination of smaller agents. Our datasets, models, and code are publicly available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12322.pdf", "abstract_url": "https://arxiv.org/abs/2504.12322", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为GRA的战略协调框架，通过多个小型语言模型（LLMs）的协作，模拟同行评审过程，以合成高质量数据，挑战了大型语言模型在数据合成中的必要性。", "motivation": "解决大型语言模型（LLMs）在数据合成和蒸馏过程中存在的高计算成本、环境效率低下以及潜在偏见问题，同时提升小型LLMs在生成高质量、多样化和可靠数据方面的能力。", "method": "提出了一个多小型LLMs参与的框架GRA，通过分配Generator、Reviewer和Adjudicator三个角色，模拟同行评审过程，进行数据的迭代优化和质量控制。", "result": "实验证明，GRA框架生成的数据在多个基准测试中匹配或超过了单一大型LLM（如Qwen-2.5-72B-Instruct）的输出质量。", "conclusion": "研究表明，通过小型LLMs的战略协调，可以实现与大型LLMs相当的数据合成质量，挑战了大型模型在高质量数据合成中的必要性，并提倡使用更小、更可持续的代理。"}}
{"id": "2504.12477", "title": "Towards Conversational AI for Human-Machine Collaborative MLOps", "authors": ["George Fatouros", "Georgios Makridis", "George Kousiouris", "John Soldatos", "Anargyros Tsadimas", "Dimosthenis Kyriazis"], "abstract": "This paper presents a Large Language Model (LLM) based conversational agent system designed to enhance human-machine collaboration in Machine Learning Operations (MLOps). We introduce the Swarm Agent, an extensible architecture that integrates specialized agents to create and manage ML workflows through natural language interactions. The system leverages a hierarchical, modular design incorporating a KubeFlow Pipelines (KFP) Agent for ML pipeline orchestration, a MinIO Agent for data management, and a Retrieval-Augmented Generation (RAG) Agent for domain-specific knowledge integration. Through iterative reasoning loops and context-aware processing, the system enables users with varying technical backgrounds to discover, execute, and monitor ML pipelines; manage datasets and artifacts; and access relevant documentation, all via intuitive conversational interfaces. Our approach addresses the accessibility gap in complex MLOps platforms like Kubeflow, making advanced ML tools broadly accessible while maintaining the flexibility to extend to other platforms. The paper describes the architecture, implementation details, and demonstrates how this conversational MLOps assistant reduces complexity and lowers barriers to entry for users across diverse technical skill levels.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)", "comments": "8 pages, 5 figures", "pdf_url": "https://arxiv.org/pdf/2504.12477.pdf", "abstract_url": "https://arxiv.org/abs/2504.12477", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文介绍了一个基于大型语言模型（LLM）的对话代理系统，旨在增强人机协作在机器学习操作（MLOps）中的应用。通过引入Swarm Agent这一可扩展架构，系统整合了专门代理，通过自然语言交互创建和管理ML工作流。", "motivation": "解决复杂MLOps平台（如Kubeflow）的可访问性问题，使不同技术背景的用户都能轻松使用高级ML工具。", "method": "采用分层模块化设计，整合了KubeFlow Pipelines Agent、MinIO Agent和Retrieval-Augmented Generation Agent，通过迭代推理循环和上下文感知处理，实现自然语言交互。", "result": "展示了这一对话式MLOps助手如何降低复杂性，为不同技术水平的用户降低使用门槛。", "conclusion": "该系统的架构和实施细节表明，通过直观的对话界面，可以有效提升MLOps的可访问性和灵活性，同时支持扩展到其他平台。"}}
{"id": "2504.12482", "title": "Agentic AI Optimisation (AAIO): what it is, how it works, why it matters, and how to deal with it", "authors": ["Luciano Floridi", "Carlotta Buttaboni", "Emmie Hine", "Jessica Morley", "Claudio Novelli", "Tyler Schroder"], "abstract": "The emergence of Agentic Artificial Intelligence (AAI) systems capable of independently initiating digital interactions necessitates a new optimisation paradigm designed explicitly for seamless agent-platform interactions. This article introduces Agentic AI Optimisation (AAIO) as an essential methodology for ensuring effective integration between websites and agentic AI systems. Like how Search Engine Optimisation (SEO) has shaped digital content discoverability, AAIO can define interactions between autonomous AI agents and online platforms. By examining the mutual interdependency between website optimisation and agentic AI success, the article highlights the virtuous cycle that AAIO can create. It further explores the governance, ethical, legal, and social implications (GELSI) of AAIO, emphasising the necessity of proactive regulatory frameworks to mitigate potential negative impacts. The article concludes by affirming AAIO's essential role as part of a fundamental digital infrastructure in the era of autonomous digital agents, advocating for equitable and inclusive access to its benefits.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12482.pdf", "abstract_url": "https://arxiv.org/abs/2504.12482", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了代理性人工智能优化（AAIO）作为一种新方法，旨在确保网站与代理性AI系统之间的有效整合。类似于搜索引擎优化（SEO）如何塑造数字内容的可发现性，AAIO可以定义自主AI代理与在线平台之间的互动。文章探讨了AAIO的治理、伦理、法律和社会影响（GELSI），并强调了建立前瞻性监管框架的必要性。", "motivation": "随着能够独立发起数字交互的代理性人工智能（AAI）系统的出现，需要一种新的优化范式来确保代理与平台之间的无缝交互。", "method": "文章提出了代理性人工智能优化（AAIO）作为确保网站与代理性AI系统有效整合的方法论，并探讨了AAIO的治理、伦理、法律和社会影响（GELSI）。", "result": "AAIO可以创建一个良性循环，优化网站与代理性AI系统之间的互动，同时需要前瞻性的监管框架来减轻潜在的负面影响。", "conclusion": "AAIO在自主数字代理时代作为基本数字基础设施的重要组成部分，其角色至关重要，文章倡导公平和包容地获取其好处。"}}
{"id": "2504.12497", "title": "Heuristic Recognition and Rapid Response to Unfamiliar Events Outside of Agent Design Scope", "authors": ["Robert E. Wray", "Steven J. Jones", "John E. Laird"], "abstract": "Regardless of past learning, an agent in an open world will face unfamiliar situations and events outside of prior experience, existing models, or policies. Further, the agent will sometimes lack relevant knowledge and/or sufficient time to assess the situation, generate and evaluate options, and pursue a robustly considered course of action. How can an agent respond reasonably to situations that are outside of its original design scope? How can it recognize such situations sufficiently quickly and reliably to determine reasonable, adaptive courses of action? We identify key characteristics needed for solutions, evaluate the state-of-the-art by these requirements, and outline a proposed, novel approach that combines domain-general meta-knowledge (in the form of appraisals inspired by human cognition) and metareasoning. It has the potential to provide fast, adaptive responses to unfamiliar situations, more fully meeting the performance characteristics required for open-world, general agents.", "subjects": "Artificial Intelligence (cs.AI)", "comments": "12 pages, 3 figures. Submitted to AGI25 conference", "pdf_url": "https://arxiv.org/pdf/2504.12497.pdf", "abstract_url": "https://arxiv.org/abs/2504.12497", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了开放世界中代理面对超出其设计范围的不熟悉事件时的快速响应问题，提出了一种结合领域通用元知识和元推理的新方法。", "motivation": "解决代理在开放世界中遇到超出其经验、模型或政策范围的不熟悉情况时，如何快速识别并合理响应的问题。", "method": "提出了一种结合领域通用元知识（以人类认知启发的评估形式）和元推理的新方法。", "result": "该方法有潜力为不熟悉的情况提供快速、自适应的响应，更全面地满足开放世界通用代理的性能要求。", "conclusion": "通过结合领域通用元知识和元推理，可以更有效地解决代理在开放世界中面对不熟悉事件时的快速识别和响应问题。"}}
{"id": "2504.12612", "title": "The Chronicles of Foundation AI for Forensics of Multi-Agent Provenance", "authors": ["Ching-Chun Chang", "Isao Echizen"], "abstract": "Provenance is the chronology of things, resonating with the fundamental pursuit to uncover origins, trace connections, and situate entities within the flow of space and time. As artificial intelligence advances towards autonomous agents capable of interactive collaboration on complex tasks, the provenance of generated content becomes entangled in the interplay of collective creation, where contributions are continuously revised, extended or overwritten. In a multi-agent generative chain, content undergoes successive transformations, often leaving little, if any, trace of prior contributions. In this study, we investigates the problem of tracking multi-agent provenance across the temporal dimension of generation. We propose a chronological system for post hoc attribution of generative history from content alone, without reliance on internal memory states or external meta-information. At its core lies the notion of symbolic chronicles, representing signed and time-stamped records, in a form analogous to the chain of custody in forensic science. The system operates through a feedback loop, whereby each generative timestep updates the chronicle of prior interactions and synchronises it with the synthetic content in the very act of generation. This research seeks to develop an accountable form of collaborative artificial intelligence within evolving cyber ecosystems.", "subjects": "Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12612.pdf", "abstract_url": "https://arxiv.org/abs/2504.12612", "categories": ["Artificial Intelligence (cs.AI)", "Cryptography and Security (cs.CR)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究了在多智能体生成链中追踪内容来源的问题，提出了一种基于符号编年史的系统，用于事后从内容本身归因生成历史，不依赖内部记忆状态或外部元信息。", "motivation": "随着人工智能向能够交互协作完成复杂任务的自主智能体发展，生成内容的来源在多智能体集体创作中变得复杂，难以追踪。", "method": "研究提出了一种基于符号编年史的系统，通过反馈循环更新交互记录，并在生成过程中同步合成内容。", "result": "开发了一种可追溯的多智能体协作人工智能形式，为进化中的网络生态系统提供了一种负责任的协作方式。", "conclusion": "这项研究为在多智能体环境中追踪内容来源提供了一种新方法，有助于实现更可追溯和负责任的协作人工智能。"}}
{"id": "2504.12682", "title": "WebLists: Extracting Structured Information From Complex Interactive Websites Using Executable LLM Agents", "authors": ["Arth Bohra", "Manvel Saroyan", "Danil Melkozerov", "Vahe Karufanyan", "Gabriel Maher", "Pascal Weinberger", "Artem Harutyunyan", "Giovanni Campagna"], "abstract": "Most recent web agent research has focused on navigation and transaction tasks, with little emphasis on extracting structured data at scale. We present WebLists, a benchmark of 200 data-extraction tasks across four common business and enterprise use-cases. Each task requires an agent to navigate to a webpage, configure it appropriately, and extract complete datasets with well-defined schemas. We show that both LLMs with search capabilities and SOTA web agents struggle with these tasks, with a recall of 3% and 31%, respectively, despite higher performance on question-answering tasks.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12682.pdf", "abstract_url": "https://arxiv.org/abs/2504.12682", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "WebLists是一个包含200个数据提取任务的基准测试，覆盖四种常见的商业和企业用例，旨在评估从复杂交互式网站中提取结构化数据的能力。", "motivation": "解决当前网络代理研究在规模化提取结构化数据方面的不足，尤其是在导航和交易任务之外的领域。", "method": "提出了WebLists基准测试，要求代理导航到网页、适当配置并提取具有明确定义模式的数据集。", "result": "研究表明，具有搜索能力的LLMs和最先进的网络代理在这些任务上的表现不佳，召回率分别为3%和31%，尽管在问答任务上表现更好。", "conclusion": "WebLists基准测试揭示了当前技术在从复杂交互式网站中提取结构化数据方面的挑战，为未来的研究提供了方向。"}}
{"id": "2504.13032", "title": "InstructRAG: Leveraging Retrieval-Augmented Generation on Instruction Graphs for LLM-Based Task Planning", "authors": ["Zheng Wang", "Shu Xian Teo", "Jun Jie Chew", "Wei Shi"], "abstract": "Recent advancements in large language models (LLMs) have enabled their use as agents for planning complex tasks. Existing methods typically rely on a thought-action-observation (TAO) process to enhance LLM performance, but these approaches are often constrained by the LLMs' limited knowledge of complex tasks. Retrieval-augmented generation (RAG) offers new opportunities by leveraging external databases to ground generation in retrieved information. In this paper, we identify two key challenges (enlargability and transferability) in applying RAG to task planning. We propose InstructRAG, a novel solution within a multi-agent meta-reinforcement learning framework, to address these challenges. InstructRAG includes a graph to organize past instruction paths (sequences of correct actions), an RL-Agent with Reinforcement Learning to expand graph coverage for enlargability, and an ML-Agent with Meta-Learning to improve task generalization for transferability. The two agents are trained end-to-end to optimize overall planning performance. Our experiments on four widely used task planning datasets demonstrate that InstructRAG significantly enhances performance and adapts efficiently to new tasks, achieving up to a 19.2% improvement over the best existing approach.", "subjects": "Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)", "comments": "This paper has been accepted by SIGIR 2025", "pdf_url": "https://arxiv.org/pdf/2504.13032.pdf", "abstract_url": "https://arxiv.org/abs/2504.13032", "categories": ["Artificial Intelligence (cs.AI)", "Information Retrieval (cs.IR)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文提出了InstructRAG，一种在多智能体元强化学习框架下的新解决方案，旨在解决将检索增强生成（RAG）应用于任务规划时的可扩展性和可转移性挑战。通过结合强化学习和元学习，InstructRAG在四个广泛使用的任务规划数据集上显著提升了性能，并有效适应新任务。", "motivation": "大型语言模型（LLMs）作为规划复杂任务的代理使用时，其性能受限于对复杂任务知识的有限了解。检索增强生成（RAG）通过利用外部数据库来基于检索到的信息进行生成，为解决这一问题提供了新机会。然而，将RAG应用于任务规划时面临可扩展性和可转移性两大挑战。", "method": "InstructRAG采用多智能体元强化学习框架，包括一个组织过去指令路径的图、一个通过强化学习扩展图覆盖范围的RL-Agent，以及一个通过元学习提高任务泛化能力的ML-Agent。这两个智能体端到端训练以优化整体规划性能。", "result": "在四个广泛使用的任务规划数据集上的实验表明，InstructRAG显著提升了性能，并有效适应新任务，相比现有最佳方法实现了高达19.2%的性能提升。", "conclusion": "InstructRAG通过结合强化学习和元学习，有效解决了将RAG应用于任务规划时的可扩展性和可转移性挑战，为基于LLM的任务规划提供了新的解决方案。"}}
{"id": "2504.13145", "title": "Exploring Expert Failures Improves LLM Agent Tuning", "authors": ["Li-Cheng Lan", "Andrew Bai", "Minhao Cheng", "Ruochen Wang", "Cho-Jui Hsieh", "Tianyi Zhou"], "abstract": "Large Language Models (LLMs) have shown tremendous potential as agents, excelling at tasks that require multiple rounds of reasoning and interactions. Rejection Sampling Fine-Tuning (RFT) has emerged as an effective method for finetuning LLMs as agents: it first imitates expert-generated successful trajectories and further improves agentic skills through iterative fine-tuning on successful, self-generated trajectories. However, since the expert (e.g., GPT-4) succeeds primarily on simpler subtasks and RFT inherently favors simpler scenarios, many complex subtasks remain unsolved and persistently out-of-distribution (OOD). Upon investigating these challenging subtasks, we discovered that previously failed expert trajectories can often provide valuable guidance, e.g., plans and key actions, that can significantly improve agent exploration efficiency and acquisition of critical skills. Motivated by these observations, we propose Exploring Expert Failures (EEF), which identifies beneficial actions from failed expert trajectories and integrates them into the training dataset. Potentially harmful actions are meticulously excluded to prevent contamination of the model learning process. By leveraging the beneficial actions in expert failures, EEF successfully solves some previously unsolvable subtasks and improves agent tuning performance. Remarkably, our approach achieved a 62\\% win rate in WebShop, outperforming RFT (53. 6\\%) and GPT-4 (35. 6\\%), and to the best of our knowledge, setting a new state-of-the-art as the first method to surpass a score of 0.81 in WebShop and exceed 81 in SciWorld.", "subjects": "Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.13145.pdf", "abstract_url": "https://arxiv.org/abs/2504.13145", "categories": ["Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文提出了一种名为探索专家失败（EEF）的新方法，通过从专家失败的轨迹中提取有益动作来改进大型语言模型（LLM）代理的调优，显著提高了在复杂子任务上的表现。", "motivation": "解决在复杂子任务上大型语言模型代理因主要模仿专家成功轨迹而导致的性能不足问题。", "method": "提出EEF方法，从专家失败的轨迹中识别并整合有益动作到训练数据集中，同时排除有害动作以避免污染模型学习过程。", "result": "EEF在WebShop中实现了62%的胜率，优于RFT（53.6%）和GPT-4（35.6%），并在WebShop和SciWorld中创下了新的最先进成绩。", "conclusion": "通过利用专家失败中的有益信息，EEF不仅解决了之前无法解决的子任务，还显著提高了代理的调优性能，为LLM代理的发展提供了新的方向。"}}
{"id": "2504.13171", "title": "Sleep-time Compute: Beyond Inference Scaling at Test-time", "authors": ["Kevin Lin", "Charlie Snell", "Yu Wang", "Charles Packer", "Sarah Wooders", "Ion Stoica", "Joseph E. Gonzalez"], "abstract": "Scaling test-time compute has emerged as a key ingredient for enabling large language models (LLMs) to solve difficult problems, but comes with high latency and inference cost. We introduce sleep-time compute, which allows models to \"think\" offline about contexts before queries are presented: by anticipating what queries users might ask and pre-computing useful quantities, we can significantly reduce the compute requirements at test-time. To demonstrate the efficacy of our method, we create modified versions of two reasoning tasks - Stateful GSM-Symbolic and Stateful AIME. We find that sleep-time compute can reduce the amount of test-time compute needed to achieve the same accuracy by ~ 5x on Stateful GSM-Symbolic and Stateful AIME and that by scaling sleep-time compute we can further increase accuracy by up to 13% on Stateful GSM-Symbolic and 18% on Stateful AIME. Furthermore, we introduce Multi-Query GSM-Symbolic, which extends GSM-Symbolic by including multiple related queries per context. By amortizing sleep-time compute across related queries about the same context using Multi-Query GSM-Symbolic, we can decrease the average cost per query by 2.5x. We then conduct additional analysis to understand when sleep-time compute is most effective, finding the predictability of the user query to be well correlated with the efficacy of sleep-time compute. Finally, we conduct a case-study of applying sleep-time compute to a realistic agentic SWE task.", "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2504.13171.pdf", "abstract_url": "https://arxiv.org/abs/2504.13171", "categories": ["Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了‘睡眠时间计算’方法，通过预先计算用户可能提出的查询的有用量，显著减少了测试时的计算需求。在Stateful GSM-Symbolic和Stateful AIME两个推理任务上的实验表明，该方法能将测试时计算量减少约5倍，并通过扩展睡眠时间计算进一步提高准确性。此外，通过Multi-Query GSM-Symbolic分摊相关查询的计算成本，每个查询的平均成本降低了2.5倍。", "motivation": "解决大型语言模型在解决难题时测试时计算成本高和延迟高的问题。", "method": "引入‘睡眠时间计算’方法，预先计算用户可能提出的查询的有用量，减少测试时的计算需求。", "result": "在Stateful GSM-Symbolic和Stateful AIME任务上，测试时计算量减少约5倍，准确性提高13%和18%；通过Multi-Query GSM-Symbolic，每个查询的平均成本降低2.5倍。", "conclusion": "睡眠时间计算能有效减少测试时的计算需求和成本，特别是在用户查询可预测性高的情况下效果更佳。"}}
{"id": "2504.12330", "title": "HM-RAG: Hierarchical Multi-Agent Multimodal Retrieval Augmented Generation", "authors": ["Pei Liu", "Xin Liu", "Ruoyu Yao", "Junming Liu", "Siyuan Meng", "Ding Wang", "Jun Ma"], "abstract": "While Retrieval-Augmented Generation (RAG) augments Large Language Models (LLMs) with external knowledge, conventional single-agent RAG remains fundamentally limited in resolving complex queries demanding coordinated reasoning across heterogeneous data ecosystems. We present HM-RAG, a novel Hierarchical Multi-agent Multimodal RAG framework that pioneers collaborative intelligence for dynamic knowledge synthesis across structured, unstructured, and graph-based data. The framework is composed of three-tiered architecture with specialized agents: a Decomposition Agent that dissects complex queries into contextually coherent sub-tasks via semantic-aware query rewriting and schema-guided context augmentation; Multi-source Retrieval Agents that carry out parallel, modality-specific retrieval using plug-and-play modules designed for vector, graph, and web-based databases; and a Decision Agent that uses consistency voting to integrate multi-source answers and resolve discrepancies in retrieval results through Expert Model Refinement. This architecture attains comprehensive query understanding by combining textual, graph-relational, and web-derived evidence, resulting in a remarkable 12.95% improvement in answer accuracy and a 3.56% boost in question classification accuracy over baseline RAG systems on the ScienceQA and CrisisMMD benchmarks. Notably, HM-RAG establishes state-of-the-art results in zero-shot settings on both datasets. Its modular architecture ensures seamless integration of new data modalities while maintaining strict data governance, marking a significant advancement in addressing the critical challenges of multimodal reasoning and knowledge synthesis in RAG systems. Code is available at", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12330.pdf", "abstract_url": "https://arxiv.org/abs/2504.12330", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "HM-RAG是一种新颖的分层多代理多模态检索增强生成框架，旨在通过协作智能解决跨异构数据生态系统的复杂查询问题。", "motivation": "传统的单代理RAG在解决需要跨异构数据生态系统协调推理的复杂查询时存在根本限制。", "method": "HM-RAG采用三层架构，包括分解代理、多源检索代理和决策代理，通过语义感知查询重写、模式引导上下文增强、并行多模态检索和一致性投票等技术，实现动态知识合成。", "result": "在ScienceQA和CrisisMMD基准测试中，HM-RAG在答案准确率和问题分类准确率上分别比基线RAG系统提高了12.95%和3.56%，并在零样本设置下建立了最先进的结果。", "conclusion": "HM-RAG的模块化架构确保了新数据模态的无缝集成，同时保持严格的数据治理，标志着在解决RAG系统中多模态推理和知识合成的关键挑战方面取得了重大进展。"}}
{"id": "2504.12342", "title": "Benchmarking Biopharmaceuticals Retrieval-Augmented Generation Evaluation", "authors": ["Hanmeng Zhong", "Linqing Chen", "Weilei Wang", "Wentao Wu"], "abstract": "Recently, the application of the retrieval-augmented Large Language Models (LLMs) in specific domains has gained significant attention, especially in biopharmaceuticals. However, in this context, there is no benchmark specifically designed for biopharmaceuticals to evaluate LLMs. In this paper, we introduce the Biopharmaceuticals Retrieval-Augmented Generation Evaluation (BRAGE) , the first benchmark tailored for evaluating LLMs' Query and Reference Understanding Capability (QRUC) in the biopharmaceutical domain, available in English, French, German and Chinese. In addition, Traditional Question-Answering (QA) metrics like accuracy and exact match fall short in the open-ended retrieval-augmented QA scenarios. To address this, we propose a citation-based classification method to evaluate the QRUC of LLMs to understand the relationship between queries and references. We apply this method to evaluate the mainstream LLMs on BRAGE. Experimental results show that there is a significant gap in the biopharmaceutical QRUC of mainstream LLMs, and their QRUC needs to be improved.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12342.pdf", "abstract_url": "https://arxiv.org/abs/2504.12342", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文介绍了首个针对生物制药领域的检索增强大型语言模型（LLMs）评估基准——BRAGE，旨在评估LLMs在生物制药领域的查询和参考理解能力（QRUC），并提出了基于引用的分类方法以改进传统QA指标在开放检索增强QA场景中的不足。", "motivation": "当前缺乏专门针对生物制药领域评估LLMs的基准，且传统QA指标在开放检索增强QA场景中表现不佳。", "method": "提出了BRAGE基准和基于引用的分类方法，用于评估LLMs的QRUC。", "result": "实验结果显示，主流LLMs在生物制药QRUC方面存在显著差距，需进一步提升。", "conclusion": "BRAGE为生物制药领域的LLMs评估提供了首个专门基准，基于引用的分类方法有效补充了传统QA指标的不足，揭示了LLMs在该领域的改进空间。"}}
{"id": "2504.12345", "title": "Reimagining Urban Science: Scaling Causal Inference with Large Language Models", "authors": ["Yutong Xia", "Ao Qu", "Yunhan Zheng", "Yihong Tang", "Dingyi Zhuang", "Yuxuan Liang", "Cathy Wu", "Roger Zimmermann", "Jinhua Zhao"], "abstract": "Urban causal research is essential for understanding the complex dynamics of cities and informing evidence-based policies. However, it is challenged by the inefficiency and bias of hypothesis generation, barriers to multimodal data complexity, and the methodological fragility of causal experimentation. Recent advances in large language models (LLMs) present an opportunity to rethink how urban causal analysis is conducted. This Perspective examines current urban causal research by analyzing taxonomies that categorize research topics, data sources, and methodological approaches to identify structural gaps. We then introduce an LLM-driven conceptual framework, AutoUrbanCI, composed of four distinct modular agents responsible for hypothesis generation, data engineering, experiment design and execution, and results interpretation with policy recommendations. We propose evaluation criteria for rigor and transparency and reflect on implications for human-AI collaboration, equity, and accountability. We call for a new research agenda that embraces AI-augmented workflows not as replacements for human expertise but as tools to broaden participation, improve reproducibility, and unlock more inclusive forms of urban causal reasoning.", "subjects": "Computation and Language (cs.CL); Computers and Society (cs.CY); Multiagent Systems (cs.MA)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12345.pdf", "abstract_url": "https://arxiv.org/abs/2504.12345", "categories": ["Computation and Language (cs.CL)", "Computers and Society (cs.CY)", "Multiagent Systems (cs.MA)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种利用大型语言模型（LLMs）重新构想城市科学的方法，特别是通过AutoUrbanCI框架来提升城市因果研究的效率和广度。", "motivation": "城市因果研究在理解城市复杂动态和为基于证据的政策提供信息方面至关重要，但面临着假设生成的效率和偏见、多模态数据复杂性的障碍以及因果实验方法脆弱性的挑战。", "method": "引入了一个LLM驱动的概念框架AutoUrbanCI，该框架由四个独立的模块化代理组成，分别负责假设生成、数据工程、实验设计和执行以及结果解释与政策建议。", "result": "提出了评估严谨性和透明度的标准，并反思了人机协作、公平性和责任性的影响。", "conclusion": "呼吁一个新的研究议程，将AI增强的工作流程视为扩大参与、提高可重复性和解锁更包容的城市因果推理形式的工具，而非取代人类专业知识。"}}
{"id": "2504.12516", "title": "BrowseComp: A Simple Yet Challenging Benchmark for Browsing Agents", "authors": ["Jason Wei", "Zhiqing Sun", "Spencer Papay", "Scott McKinney", "Jeffrey Han", "Isa Fulford", "Hyung Won Chung", "Alex Tachard Passos", "William Fedus", "Amelia Glaese"], "abstract": "We present BrowseComp, a simple yet challenging benchmark for measuring the ability for agents to browse the web. BrowseComp comprises 1,266 questions that require persistently navigating the internet in search of hard-to-find, entangled information. Despite the difficulty of the questions, BrowseComp is simple and easy-to-use, as predicted answers are short and easily verifiable against reference answers. BrowseComp for browsing agents can be seen as analogous to how programming competitions are an incomplete but useful benchmark for coding agents. While BrowseComp sidesteps challenges of a true user query distribution, like generating long answers or resolving ambiguity, it measures the important core capability of exercising persistence and creativity in finding information. BrowseComp can be found at", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12516.pdf", "abstract_url": "https://arxiv.org/abs/2504.12516", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["agent"], "AI": {"tldr": "介绍了BrowseComp，一个简单但具有挑战性的基准测试，用于评估网络浏览代理的能力。", "motivation": "解决如何有效测量代理在网络上持久导航和寻找难以找到、纠缠信息的能力的问题。", "method": "创建包含1,266个问题的BrowseComp基准测试，这些问题需要代理在互联网上持续导航以寻找信息。", "result": "BrowseComp提供了一个简单易用但具有挑战性的测试环境，预测答案简短且易于与参考答案核对。", "conclusion": "BrowseComp虽然避开了真实用户查询分布的复杂性，但有效测量了代理在寻找信息时的持久性和创造力，类似于编程竞赛对编码代理的评估作用。"}}
{"id": "2504.12560", "title": "CDF-RAG: Causal Dynamic Feedback for Adaptive Retrieval-Augmented Generation", "authors": ["Elahe Khatibi", "Ziyu Wang", "Amir M. Rahmani"], "abstract": "Retrieval-Augmented Generation (RAG) has significantly enhanced large language models (LLMs) in knowledge-intensive tasks by incorporating external knowledge retrieval. However, existing RAG frameworks primarily rely on semantic similarity and correlation-driven retrieval, limiting their ability to distinguish true causal relationships from spurious associations. This results in responses that may be factually grounded but fail to establish cause-and-effect mechanisms, leading to incomplete or misleading insights. To address this issue, we introduce Causal Dynamic Feedback for Adaptive Retrieval-Augmented Generation (CDF-RAG), a framework designed to improve causal consistency, factual accuracy, and explainability in generative reasoning. CDF-RAG iteratively refines queries, retrieves structured causal graphs, and enables multi-hop causal reasoning across interconnected knowledge sources. Additionally, it validates responses against causal pathways, ensuring logically coherent and factually grounded outputs. We evaluate CDF-RAG on four diverse datasets, demonstrating its ability to improve response accuracy and causal correctness over existing RAG-based methods. Our code is publicly available at", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12560.pdf", "abstract_url": "https://arxiv.org/abs/2504.12560", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "CDF-RAG是一个旨在通过因果动态反馈增强检索增强生成（RAG）框架的适应性，以提高生成推理中的因果一致性、事实准确性和可解释性。", "motivation": "现有的RAG框架主要依赖语义相似性和相关性驱动的检索，难以区分真实的因果关系与虚假的关联，导致响应可能基于事实但缺乏因果机制，产生不完整或误导性的见解。", "method": "CDF-RAG通过迭代优化查询、检索结构化因果图，并实现跨互联知识源的多跳因果推理，同时根据因果路径验证响应，确保逻辑一致和事实基础。", "result": "在四个不同的数据集上评估CDF-RAG，证明其在提高响应准确性和因果正确性方面优于现有的基于RAG的方法。", "conclusion": "CDF-RAG通过引入因果动态反馈机制，显著提升了RAG框架在知识密集型任务中的表现，特别是在理解和应用因果关系方面。"}}
{"id": "2504.12563", "title": "MetaSynth: Meta-Prompting-Driven Agentic Scaffolds for Diverse Synthetic Data Generation", "authors": ["Haris Riaz", "Sourav Bhabesh", "Vinayak Arannil", "Miguel Ballesteros", "Graham Horwood"], "abstract": "Recent smaller language models such Phi-3.5 and Phi-4 rely on synthetic data generated using larger Language models. Questions remain about leveraging synthetic data for other use cases, such as adapting LLMs to specific domains. A key limitation of synthetic data is low diversity, which negatively impacts its downstream applicability for improving other models. To address this, we propose MetaSynth, a method for generating synthetic data that enhances diversity through meta-prompting, where a language model orchestrates multiple \"expert\" LLM agents to collaboratively generate data. Using only 25 million tokens of synthetic data generated with MetaSynth, we successfully adapt a well-trained LLM (Mistral-7B-v0.3) to two specialized domains-Finance and Biomedicine-without compromising the capabilities of the resulting model in general tasks. In addition, we evaluate the diversity of our synthetic data using seven automated metrics, and find that it approaches the diversity of LLM pre-training corpora.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "33 pages, 17 figures. Preprint", "pdf_url": "https://arxiv.org/pdf/2504.12563.pdf", "abstract_url": "https://arxiv.org/abs/2504.12563", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "MetaSynth提出了一种通过元提示增强合成数据多样性的方法，利用语言模型协调多个“专家”LLM代理协作生成数据，成功将Mistral-7B-v0.3适应到金融和生物医学领域，且不损害其在通用任务上的能力。", "motivation": "解决合成数据多样性低的问题，以提高其在改进其他模型时的下游适用性。", "method": "采用元提示方法，让一个语言模型协调多个“专家”LLM代理协作生成数据。", "result": "仅使用2500万标记的MetaSynth生成合成数据，成功将Mistral-7B-v0.3适应到金融和生物医学领域，且不损害其在通用任务上的能力；合成数据的多样性接近LLM预训练语料库的多样性。", "conclusion": "MetaSynth通过元提示驱动的代理支架生成多样化的合成数据，为特定领域适应LLM提供了一种有效方法，同时保持了模型在通用任务上的性能。"}}
{"id": "2504.12673", "title": "ACoRN: Noise-Robust Abstractive Compression in Retrieval-Augmented Language Models", "authors": ["Singon Kim", "Gunho Jung", "Seong-Whan Lee"], "abstract": "Abstractive compression utilizes smaller langauge models to condense query-relevant context, reducing computational costs in retrieval-augmented generation (RAG). However,retrieved documents often include information that is either irrelevant to answering the query or misleading due to factual incorrect content, despite having high relevance scores. This behavior indicates that abstractive compressors are more likely to omit important information essential for the correct answer, especially in long contexts where attention dispersion occurs. To address this issue, we categorize retrieved documents in a more fine-grained manner and propose Abstractive Compression Robust against Noise (ACoRN), which introduces two novel training steps. First, we use offline data augmentation on the training dataset to enhance compressor robustness against two distinct types of retrieval noise. Second, since the language modelbased compressor cannot fully utilize information from multiple retrieved documents and exhibits positional bias, we perform finetuning to generate summaries centered around key information that directly supports the correct answer. Our experiments demonstrate that T5-large, trained with ACoRN as a compressor, improves EM and F1 scores while preserving the answer string, which could serve as direct evidence. ACoRN excels on datasets with many accuracy-reducing documents, making it highly useful in real-world scenarios.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12673.pdf", "abstract_url": "https://arxiv.org/abs/2504.12673", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "ACoRN提出了一种针对检索增强语言模型中噪声鲁棒的抽象压缩方法，通过数据增强和微调训练步骤，提高了在存在噪声文档情况下的压缩质量和答案准确性。", "motivation": "解决检索增强生成（RAG）中，由于检索到的文档可能包含无关或误导信息，导致抽象压缩器忽略重要信息的问题。", "method": "提出ACoRN方法，包括两个新颖的训练步骤：离线数据增强以提高压缩器对检索噪声的鲁棒性，以及微调训练以减少位置偏差并围绕关键信息生成摘要。", "result": "实验表明，使用ACoRN训练的T5-large作为压缩器，提高了EM和F1分数，同时在包含大量降低准确性文档的数据集上表现优异。", "conclusion": "ACoRN在现实世界场景中非常有用，特别是在处理包含大量噪声文档的情况下，能够有效提高抽象压缩的质量和答案的准确性。"}}
{"id": "2504.12734", "title": "Pandora: A Code-Driven Large Language Model Agent for Unified Reasoning Across Diverse Structured Knowledge", "authors": ["Yongrui Chen", "Junhao He", "Linbo Fu", "Shenyu Zhang", "Rihui Jin", "Xinbang Dai", "Jiaqi Li", "Dehai Min", "Nan Hu", "Yuxin Zhang", "Guilin Qi", "Yi Huang", "Tongtong Wu"], "abstract": "Unified Structured Knowledge Reasoning (USKR) aims to answer natural language questions (NLQs) by using structured sources such as tables, databases, and knowledge graphs in a unified way. Existing USKR methods either rely on employing task-specific strategies or custom-defined representations, which struggle to leverage the knowledge transfer between different SKR tasks or align with the prior of LLMs, thereby limiting their performance. This paper proposes a novel USKR framework named \\textsc{Pandora}, which takes advantage of \\textsc{Python}'s \\textsc{Pandas} API to construct a unified knowledge representation for alignment with LLM pre-training. It employs an LLM to generate textual reasoning steps and executable Python code for each question. Demonstrations are drawn from a memory of training examples that cover various SKR tasks, facilitating knowledge transfer. Extensive experiments on four benchmarks involving three SKR tasks demonstrate that \\textsc{Pandora} outperforms existing unified frameworks and competes effectively with task-specific methods.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12734.pdf", "abstract_url": "https://arxiv.org/abs/2504.12734", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为Pandora的新型统一结构化知识推理（USKR）框架，利用Python的Pandas API构建统一的知识表示，与大型语言模型（LLM）预训练对齐，通过生成文本推理步骤和可执行Python代码来回答自然语言问题，并在多个基准测试中表现出色。", "motivation": "解决现有USKR方法因依赖任务特定策略或自定义表示而难以利用不同结构化知识推理（SKR）任务间的知识转移或与LLM先验对齐的问题。", "method": "采用Python的Pandas API构建统一知识表示，利用LLM生成文本推理步骤和可执行代码，并通过涵盖各种SKR任务的训练示例记忆促进知识转移。", "result": "在涉及三个SKR任务的四个基准测试中，Pandora的表现优于现有统一框架，并能有效与任务特定方法竞争。", "conclusion": "Pandora通过统一的知识表示和代码驱动的推理方法，为跨不同结构化知识源的统一推理提供了一种有效的解决方案，展示了在USKR任务中的优越性能。"}}
{"id": "2504.12891", "title": "Are AI agents the new machine translation frontier? Challenges and opportunities of single- and multi-agent systems for multilingual digital communication", "authors": ["Vicent Briva-Iglesias"], "abstract": "The rapid evolution of artificial intelligence (AI) has introduced AI agents as a disruptive paradigm across various industries, yet their application in machine translation (MT) remains underexplored. This paper describes and analyses the potential of single- and multi-agent systems for MT, reflecting on how they could enhance multilingual digital communication. While single-agent systems are well-suited for simpler translation tasks, multi-agent systems, which involve multiple specialized AI agents collaborating in a structured manner, may offer a promising solution for complex scenarios requiring high accuracy, domain-specific knowledge, and contextual awareness. To demonstrate the feasibility of multi-agent workflows in MT, we are conducting a pilot study in legal MT. The study employs a multi-agent system involving four specialized AI agents for (i) translation, (ii) adequacy review, (iii) fluency review, and (iv) final editing. Our findings suggest that multi-agent systems may have the potential to significantly improve domain-adaptability and contextual awareness, with superior translation quality to traditional MT or single-agent systems. This paper also sets the stage for future research into multi-agent applications in MT, integration into professional translation workflows, and shares a demo of the system analyzed in the paper.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET); Human-Computer Interaction (cs.HC)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12891.pdf", "abstract_url": "https://arxiv.org/abs/2504.12891", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Emerging Technologies (cs.ET)", "Human-Computer Interaction (cs.HC)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文探讨了AI代理在机器翻译（MT）中的应用潜力，特别是单代理和多代理系统在提升多语言数字通信中的作用。通过一个法律MT的试点研究，展示了多代理系统在提高翻译质量和领域适应性方面的优势。", "motivation": "探索AI代理在机器翻译领域的应用，以解决传统机器翻译或单代理系统在复杂场景下可能遇到的准确性、领域特定知识和上下文意识不足的问题。", "method": "采用多代理系统进行试点研究，该系统包括四个专门的AI代理，分别负责翻译、充分性审查、流畅性审查和最终编辑。", "result": "研究发现，多代理系统在领域适应性和上下文意识方面具有显著优势，能够提供比传统MT或单代理系统更高质量的翻译。", "conclusion": "多代理系统在机器翻译领域展现出巨大潜力，特别是在需要高准确性和领域特定知识的复杂场景中。这为未来的研究和专业翻译工作流程的整合奠定了基础。"}}
{"id": "2504.12951", "title": "Are Retrials All You Need? Enhancing Large Language Model Reasoning Without Verbalized Feedback", "authors": ["Nearchos Potamitis", "Akhil Arora"], "abstract": "Recent advancements in large language models (LLMs) have catalyzed the development of general-purpose autonomous agents, demonstrating remarkable performance in complex reasoning tasks across various domains. This surge has spurred the evolution of a plethora of prompt-based reasoning frameworks. A recent focus has been on iterative reasoning strategies that refine outputs through self-evaluation and verbalized feedback. However, these strategies require additional computational complexity to enable models to recognize and correct their mistakes, leading to a significant increase in their cost. In this work, we introduce the concept of ``retrials without feedback'', an embarrassingly simple yet powerful mechanism for enhancing reasoning frameworks by allowing LLMs to retry problem-solving attempts upon identifying incorrect answers. Unlike conventional iterative refinement methods, our method does not require explicit self-reflection or verbalized feedback, simplifying the refinement process. Our findings indicate that simpler retrial-based approaches often outperform more sophisticated reasoning frameworks, suggesting that the benefits of complex methods may not always justify their computational costs. By challenging the prevailing assumption that more intricate reasoning strategies inherently lead to better performance, our work offers new insights into how simpler, more efficient approaches can achieve optimal results. So, are retrials all you need?", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2504.12951.pdf", "abstract_url": "https://arxiv.org/abs/2504.12951", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为“无反馈重试”的简单而强大的机制，用于增强大型语言模型（LLMs）的推理框架，通过允许LLMs在识别错误答案后重试解决问题，而无需复杂的自我反思或口头反馈。研究发现，这种简单的方法往往能胜过更复杂的推理框架，挑战了更复杂策略必然带来更好性能的普遍假设。", "motivation": "当前基于迭代推理的策略通过自我评估和口头反馈来优化输出，但这种方法增加了计算复杂性和成本。本文旨在探索一种更简单、更高效的方法来提升LLMs的推理能力。", "method": "引入了“无反馈重试”机制，允许LLMs在发现错误答案时重试解决问题，而无需进行复杂的自我反思或生成口头反馈。", "result": "研究发现，简单的基于重试的方法往往能超越更复杂的推理框架，表明复杂方法的好处并不总是能证明其计算成本的合理性。", "conclusion": "本文挑战了更复杂推理策略必然带来更好性能的假设，展示了更简单、更高效的方法如何能够达到最佳结果，为LLMs的推理框架提供了新的见解。"}}
{"id": "2504.12972", "title": "Estimating Optimal Context Length for Hybrid Retrieval-augmented Multi-document Summarization", "authors": ["Adithya Pratapa", "Teruko Mitamura"], "abstract": "Recent advances in long-context reasoning abilities of language models led to interesting applications in large-scale multi-document summarization. However, prior work has shown that these long-context models are not effective at their claimed context windows. To this end, retrieval-augmented systems provide an efficient and effective alternative. However, their performance can be highly sensitive to the choice of retrieval context length. In this work, we present a hybrid method that combines retrieval-augmented systems with long-context windows supported by recent language models. Our method first estimates the optimal retrieval length as a function of the retriever, summarizer, and dataset. On a randomly sampled subset of the dataset, we use a panel of LLMs to generate a pool of silver references. We use these silver references to estimate the optimal context length for a given RAG system configuration. Our results on the multi-document summarization task showcase the effectiveness of our method across model classes and sizes. We compare against length estimates from strong long-context benchmarks such as RULER and HELMET. Our analysis also highlights the effectiveness of our estimation method for very long-context LMs and its generalization to new classes of LMs.", "subjects": "Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12972.pdf", "abstract_url": "https://arxiv.org/abs/2504.12972", "categories": ["Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文提出了一种结合检索增强系统和长上下文窗口的混合方法，用于多文档摘要任务，通过估计最优检索长度来提高性能。", "motivation": "解决长上下文模型在声称的上下文窗口中效率不高的问题，以及检索增强系统对检索上下文长度选择高度敏感的问题。", "method": "结合检索增强系统和长上下文窗口的混合方法，首先估计最优检索长度，然后使用LLM生成银参考来估计给定RAG系统配置的最优上下文长度。", "result": "在多文档摘要任务中，该方法在不同模型类别和大小上均显示出有效性，并与RULER和HELMET等强长上下文基准进行了比较。", "conclusion": "该方法对于非常长上下文的LM有效，并且能够推广到新类别的LM，为多文档摘要任务提供了一种有效的解决方案。"}}
{"id": "2504.12546", "title": "Anonymous Public Announcements", "authors": ["Thomas Ågotnes", "Rustam Galimullin", "Ken Satoh", "Satoshi Tojo"], "abstract": "We formalise the notion of an \\emph{anonymous public announcement} in the tradition of public announcement logic. Such announcements can be seen as in-between a public announcement from ``the outside\" (an announcement of $\\phi$) and a public announcement by one of the agents (an announcement of $K_a\\phi$): we get more information than just $\\phi$, but not (necessarily) about exactly who made it. Even if such an announcement is prima facie anonymous, depending on the background knowledge of the agents it might reveal the identity of the announcer: if I post something on a message board, the information might reveal who I am even if I don't sign my name. Furthermore, like in the Russian Cards puzzle, if we assume that the announcer's intention was to stay anonymous, that in fact might reveal more information. In this paper we first look at the case when no assumption about intentions are made, in which case the logic with an anonymous public announcement operator is reducible to epistemic logic. We then look at the case when we assume common knowledge of the intention to stay anonymous, which is both more complex and more interesting: in several ways it boils down to the notion of a ``safe\" announcement (again, similarly to Russian Cards). Main results include formal expressivity results and axiomatic completeness for key logical languages.", "subjects": "Logic in Computer Science (cs.LO); Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12546.pdf", "abstract_url": "https://arxiv.org/abs/2504.12546", "categories": ["Logic in Computer Science (cs.LO)", "Artificial Intelligence (cs.AI)", "Cryptography and Security (cs.CR)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文在公共公告逻辑的传统中形式化了匿名公共公告的概念，探讨了在不同背景下公告如何可能揭示公告者身份，并研究了在保持匿名意图的共同知识下的逻辑复杂性。", "motivation": "解决在公共公告中如何形式化和理解匿名性的问题，特别是在公告可能无意中揭示公告者身份的情况下。", "method": "采用公共公告逻辑的方法，研究匿名公共公告的逻辑性质，包括在没有假设意图和假设共同知识意图保持匿名两种情况下的逻辑表达和复杂性。", "result": "主要结果包括形式表达性结果和关键逻辑语言的公理完备性，特别是在假设共同知识意图保持匿名的情况下，逻辑复杂性增加，与“安全”公告概念相关。", "conclusion": "匿名公共公告在特定条件下可以简化为认知逻辑，但在假设共同知识意图保持匿名的情况下，逻辑更为复杂且有趣，与安全公告概念密切相关。"}}
{"id": "2504.12557", "title": "TraCeS: Trajectory Based Credit Assignment From Sparse Safety Feedback", "authors": ["Siow Meng Low", "Akshat Kumar"], "abstract": "In safe reinforcement learning (RL), auxiliary safety costs are used to align the agent to safe decision making. In practice, safety constraints, including cost functions and budgets, are unknown or hard to specify, as it requires anticipation of all possible unsafe behaviors. We therefore address a general setting where the true safety definition is unknown, and has to be learned from sparsely labeled data. Our key contributions are: first, we design a safety model that performs credit assignment to estimate each decision step's impact on the overall safety using a dataset of diverse trajectories and their corresponding binary safety labels (i.e., whether the corresponding trajectory is safe/unsafe). Second, we illustrate the architecture of our safety model to demonstrate its ability to learn a separate safety score for each timestep. Third, we reformulate the safe RL problem using the proposed safety model and derive an effective algorithm to optimize a safe yet rewarding policy. Finally, our empirical results corroborate our findings and show that this approach is effective in satisfying unknown safety definition, and scalable to various continuous control tasks.", "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12557.pdf", "abstract_url": "https://arxiv.org/abs/2504.12557", "categories": ["Machine Learning (cs.LG)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种基于轨迹的信用分配方法TraCeS，用于从稀疏的安全反馈中学习未知的安全定义，并通过安全模型为每个决策步骤分配信用，以优化安全且奖励的策略。", "motivation": "在安全强化学习中，安全约束（包括成本函数和预算）通常是未知或难以指定的，因为这需要预测所有可能的不安全行为。本文旨在解决在真实安全定义未知且需要从稀疏标记数据中学习的一般设置下的问题。", "method": "设计了一个安全模型，该模型通过信用分配来估计每个决策步骤对整体安全的影响，使用多样化的轨迹及其对应的二进制安全标签（即轨迹是否安全/不安全）的数据集。展示了安全模型的架构，以证明其能够为每个时间步骤学习单独的安全分数。重新制定了安全强化学习问题，并推导出一个有效的算法来优化安全且奖励的策略。", "result": "实证结果支持了我们的发现，表明这种方法在满足未知安全定义方面是有效的，并且可以扩展到各种连续控制任务。", "conclusion": "本文提出的TraCeS方法能够有效地从稀疏的安全反馈中学习未知的安全定义，并通过安全模型为每个决策步骤分配信用，从而优化出既安全又具有奖励的策略。这一方法在满足未知安全定义和扩展到各种连续控制任务方面表现出色。"}}
{"id": "2504.12982", "title": "Accommodate Knowledge Conflicts in Retrieval-augmented LLMs: Towards Reliable Response Generation in the Wild", "authors": ["Jiatai Wang", "Zhiwei Xu", "Di Jin", "Xuewen Yang", "Tao Li"], "abstract": "The proliferation of large language models (LLMs) has significantly advanced information retrieval systems, particularly in response generation (RG). Unfortunately, LLMs often face knowledge conflicts between internal memory and retrievaled external information, arising from misinformation, biases, or outdated knowledge. These conflicts undermine response reliability and introduce uncertainty in decision-making. In this work, we analyze how LLMs navigate knowledge conflicts from an information-theoretic perspective and reveal that when conflicting and supplementary information exhibit significant differences, LLMs confidently resolve their preferences. However, when the distinction is ambiguous, LLMs experience heightened uncertainty. Based on this insight, we propose Swin-VIB, a novel framework that integrates a pipeline of variational information bottleneck models into adaptive augmentation of retrieved information and guiding LLM preference in response generation. Extensive experiments on single-choice, open-ended question-answering (QA), and retrieval augmented generation (RAG) validate our theoretical findings and demonstrate the efficacy of Swin-VIB. Notably, our method improves single-choice task accuracy by at least 7.54\\% over competitive baselines.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12982.pdf", "abstract_url": "https://arxiv.org/abs/2504.12982", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文探讨了大型语言模型(LLMs)在处理内部记忆与检索外部信息之间的知识冲突时的挑战，提出了一种名为Swin-VIB的新框架，通过变分信息瓶颈模型来增强检索信息的适应性，并指导LLMs在响应生成中的偏好，显著提高了任务准确性。", "motivation": "解决大型语言模型(LLMs)在内部记忆与检索到的外部信息之间遇到的知识冲突问题，这些问题由于错误信息、偏见或过时知识而产生，影响了响应的可靠性和决策过程中的不确定性。", "method": "提出Swin-VIB框架，该框架集成了一系列变分信息瓶颈模型，用于自适应增强检索信息并指导LLMs在响应生成中的偏好。", "result": "在单选择、开放式问答和检索增强生成任务上的广泛实验验证了理论发现，并证明了Swin-VIB的有效性，特别是在单选择任务上，准确率至少提高了7.54%。", "conclusion": "Swin-VIB框架通过有效处理知识冲突，提高了大型语言模型在响应生成中的可靠性和准确性，为信息检索系统的进步提供了重要方向。"}}
{"id": "2504.13079", "title": "Retrieval-Augmented Generation with Conflicting Evidence", "authors": ["Han Wang", "Archiki Prasad", "Elias Stengel-Eskin", "Mohit Bansal"], "abstract": "Large language model (LLM) agents are increasingly employing retrieval-augmented generation (RAG) to improve the factuality of their responses. However, in practice, these systems often need to handle ambiguous user queries and potentially conflicting information from multiple sources while also suppressing inaccurate information from noisy or irrelevant documents. Prior work has generally studied and addressed these challenges in isolation, considering only one aspect at a time, such as handling ambiguity or robustness to noise and misinformation. We instead consider multiple factors simultaneously, proposing (i) RAMDocs (Retrieval with Ambiguity and Misinformation in Documents), a new dataset that simulates complex and realistic scenarios for conflicting evidence for a user query, including ambiguity, misinformation, and noise; and (ii) MADAM-RAG, a multi-agent approach in which LLM agents debate over the merits of an answer over multiple rounds, allowing an aggregator to collate responses corresponding to disambiguated entities while discarding misinformation and noise, thereby handling diverse sources of conflict jointly. We demonstrate the effectiveness of MADAM-RAG using both closed and open-source models on AmbigDocs -- which requires presenting all valid answers for ambiguous queries -- improving over strong RAG baselines by up to 11.40% and on FaithEval -- which requires suppressing misinformation -- where we improve by up to 15.80% (absolute) with Llama3.3-70B-Instruct. Furthermore, we find that RAMDocs poses a challenge for existing RAG baselines (Llama3.3-70B-Instruct only obtains 32.60 exact match score). While MADAM-RAG begins to address these conflicting factors, our analysis indicates that a substantial gap remains especially when increasing the level of imbalance in supporting evidence and misinformation.", "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "comments": "", "pdf_url": "https://arxiv.org/pdf/2504.13079.pdf", "abstract_url": "https://arxiv.org/abs/2504.13079", "categories": ["Computation and Language (cs.CL)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "@RAG"], "AI": {"tldr": "本文提出了一种新的检索增强生成（RAG）方法MADAM-RAG，以及一个模拟复杂和现实场景的数据集RAMDocs，旨在同时处理用户查询的模糊性、多源信息的冲突以及噪声和错误信息的抑制。通过多轮辩论的多代理方法，MADAM-RAG在AmbigDocs和FaithEval数据集上显著优于现有RAG基线，显示出在处理信息冲突方面的有效性。", "motivation": "大型语言模型（LLM）代理越来越多地使用检索增强生成（RAG）来提高回答的事实性。然而，这些系统在实际应用中需要处理模糊的用户查询和来自多个来源的潜在冲突信息，同时抑制来自噪声或无关文档的不准确信息。现有工作通常孤立地研究和解决这些挑战，每次只考虑一个方面。本文旨在同时考虑多个因素，提出一种更全面的解决方案。", "method": "本文提出了（i）RAMDocs数据集，模拟用户查询的复杂和现实场景，包括模糊性、错误信息和噪声；（ii）MADAM-RAG，一种多代理方法，其中LLM代理在多轮辩论中讨论答案的优点，允许聚合器整理对应于消除模糊性实体的响应，同时丢弃错误信息和噪声。", "result": "在AmbigDocs和FaithEval数据集上，MADAM-RAG使用封闭和开源模型显著优于强RAG基线，分别提高了11.40%和15.80%（绝对）。然而，RAMDocs对现有RAG基线构成了挑战（Llama3.3-70B-Instruct仅获得32.60的精确匹配分数）。分析表明，尤其是在增加支持证据和错误信息的不平衡水平时，仍存在显著差距。", "conclusion": "MADAM-RAG开始解决这些冲突因素，但分析表明，尤其是在支持证据和错误信息的不平衡水平增加时，仍存在显著差距。这项工作为未来研究提供了方向和数据集，以进一步改进RAG系统在处理复杂信息冲突方面的能力。"}}
{"id": "2504.12408", "title": "A Human-AI Comparative Analysis of Prompt Sensitivity in LLM-Based Relevance Judgment", "authors": ["Negar Arabzadeh", "Charles L. A . Clarke"], "abstract": "Large Language Models (LLMs) are increasingly used to automate relevance judgments for information retrieval (IR) tasks, often demonstrating agreement with human labels that approaches inter-human agreement. To assess the robustness and reliability of LLM-based relevance judgments, we systematically investigate impact of prompt sensitivity on the task. We collected prompts for relevance assessment from 15 human experts and 15 LLMs across three tasks~ -- ~binary, graded, and pairwise~ -- ~yielding 90 prompts in total. After filtering out unusable prompts from three humans and three LLMs, we employed the remaining 72 prompts with three different LLMs as judges to label document/query pairs from two TREC Deep Learning Datasets (2020 and 2021). We compare LLM-generated labels with TREC official human labels using Cohen's $\\kappa$ and pairwise agreement measures. In addition to investigating the impact of prompt variations on agreement with human labels, we compare human- and LLM-generated prompts and analyze differences among different LLMs as judges. We also compare human- and LLM-generated prompts with the standard UMBRELA prompt used for relevance assessment by Bing and TREC 2024 Retrieval Augmented Generation (RAG) Track. To support future research in LLM-based evaluation, we release all data and prompts at", "subjects": "Information Retrieval (cs.IR); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12408.pdf", "abstract_url": "https://arxiv.org/abs/2504.12408", "categories": ["Information Retrieval (cs.IR)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "本文通过系统研究提示敏感性对基于大型语言模型（LLM）的相关性判断任务的影响，评估了LLM在信息检索任务中的鲁棒性和可靠性。研究收集了人类专家和LLM生成的提示，比较了不同提示下LLM生成标签与人类标签的一致性，并分析了人类与LLM生成提示的差异。", "motivation": "评估基于LLM的相关性判断在信息检索任务中的鲁棒性和可靠性，特别是提示敏感性对任务的影响。", "method": "收集了15位人类专家和15个LLM生成的提示，使用三种不同的LLM作为评委对文档/查询对进行标签，比较LLM生成标签与TREC官方人类标签的一致性。", "result": "研究发现提示变化对LLM与人类标签的一致性有显著影响，并揭示了人类与LLM生成提示之间的差异。", "conclusion": "研究为基于LLM的评估提供了新的见解，并发布了所有数据和提示以支持未来研究。"}}
{"id": "2504.12714", "title": "Cross-environment Cooperation Enables Zero-shot Multi-agent Coordination", "authors": ["Kunal Jha", "Wilka Carvalho", "Yancheng Liang", "Simon S. Du", "Max Kleiman-Weiner", "Natasha Jaques"], "abstract": "Zero-shot coordination (ZSC), the ability to adapt to a new partner in a cooperative task, is a critical component of human-compatible AI. While prior work has focused on training agents to cooperate on a single task, these specialized models do not generalize to new tasks, even if they are highly similar. Here, we study how reinforcement learning on a distribution of environments with a single partner enables learning general cooperative skills that support ZSC with many new partners on many new problems. We introduce two Jax-based, procedural generators that create billions of solvable coordination challenges. We develop a new paradigm called Cross-Environment Cooperation (CEC), and show that it outperforms competitive baselines quantitatively and qualitatively when collaborating with real people. Our findings suggest that learning to collaborate across many unique scenarios encourages agents to develop general norms, which prove effective for collaboration with different partners. Together, our results suggest a new route toward designing generalist cooperative agents capable of interacting with humans without requiring human data.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)", "comments": "Accepted to CogSci 2025, In-review for ICML 2025", "pdf_url": "https://arxiv.org/pdf/2504.12714.pdf", "abstract_url": "https://arxiv.org/abs/2504.12714", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)", "Machine Learning (cs.LG)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文研究了通过跨环境合作（CEC）实现零样本多智能体协调的方法，提出了一种新范式，通过在多个环境中与单一伙伴进行强化学习，培养通用的合作技能，以支持与多个新伙伴在新问题上的零样本协调。", "motivation": "解决现有专门化模型无法泛化到新任务的问题，即使这些任务高度相似，旨在开发能够与人类互动而不需要人类数据的通用合作智能体。", "method": "引入了两个基于Jax的程序生成器，创建了数十亿个可解决的协调挑战，并开发了跨环境合作（CEC）新范式。", "result": "CEC在定量和定性上都优于竞争基线，特别是在与真人合作时，表明通过学习在多种独特场景中合作，智能体能够发展出有效的通用规范。", "conclusion": "研究结果为设计能够与人类互动而不需要人类数据的通用合作智能体提供了新途径。"}}
{"id": "2504.12722", "title": "SimUSER: Simulating User Behavior with Large Language Models for Recommender System Evaluation", "authors": ["Nicolas Bougie", "Narimasa Watanabe"], "abstract": "Recommender systems play a central role in numerous real-life applications, yet evaluating their performance remains a significant challenge due to the gap between offline metrics and online behaviors. Given the scarcity and limits (e.g., privacy issues) of real user data, we introduce SimUSER, an agent framework that serves as believable and cost-effective human proxies. SimUSER first identifies self-consistent personas from historical data, enriching user profiles with unique backgrounds and personalities. Then, central to this evaluation are users equipped with persona, memory, perception, and brain modules, engaging in interactions with the recommender system. SimUSER exhibits closer alignment with genuine humans than prior work, both at micro and macro levels. Additionally, we conduct insightful experiments to explore the effects of thumbnails on click rates, the exposure effect, and the impact of reviews on user engagement. Finally, we refine recommender system parameters based on offline A/B test results, resulting in improved user engagement in the real world.", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12722.pdf", "abstract_url": "https://arxiv.org/abs/2504.12722", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "SimUSER是一个模拟用户行为的代理框架，用于推荐系统评估，通过模拟具有个性和记忆的用户行为，缩小离线指标与在线行为之间的差距。", "motivation": "推荐系统在现实应用中扮演重要角色，但由于离线指标与在线行为之间的差距，评估其性能仍面临挑战。真实用户数据的稀缺和隐私问题限制了评估的有效性。", "method": "SimUSER首先从历史数据中识别自洽的人物角色，丰富用户档案，然后通过配备人物角色、记忆、感知和大脑模块的用户与推荐系统互动。", "result": "SimUSER在微观和宏观层面上都比之前的工作更接近真实人类行为。实验还探讨了缩略图对点击率的影响、曝光效应以及评论对用户参与度的影响。", "conclusion": "基于离线A/B测试结果优化推荐系统参数，SimUSER在现实世界中提高了用户参与度，为推荐系统评估提供了一种可信且成本效益高的人类代理方法。"}}
{"id": "2504.12735", "title": "The Athenian Academy: A Seven-Layer Architecture Model for Multi-Agent Systems", "authors": ["Lidong Zhai", "Zhijie Qiu", "Xizhong Guo", "Jiaqi Li"], "abstract": "This paper proposes the \"Academy of Athens\" multi-agent seven-layer framework, aimed at systematically addressing challenges in multi-agent systems (MAS) within artificial intelligence (AI) art creation, such as collaboration efficiency, role allocation, environmental adaptation, and task parallelism. The framework divides MAS into seven layers: multi-agent collaboration, single-agent multi-role playing, single-agent multi-scene traversal, single-agent multi-capability incarnation, different single agents using the same large model to achieve the same target agent, single-agent using different large models to achieve the same target agent, and multi-agent synthesis of the same target agent. Through experimental validation in art creation, the framework demonstrates its unique advantages in task collaboration, cross-scene adaptation, and model fusion. This paper further discusses current challenges such as collaboration mechanism optimization, model stability, and system security, proposing future exploration through technologies like meta-learning and federated learning. The framework provides a structured methodology for multi-agent collaboration in AI art creation and promotes innovative applications in the art field.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12735.pdf", "abstract_url": "https://arxiv.org/abs/2504.12735", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了'雅典学院'多智能体七层框架，旨在系统解决人工智能艺术创作中多智能体系统（MAS）面临的协作效率、角色分配、环境适应和任务并行等挑战。", "motivation": "解决人工智能艺术创作中多智能体系统在协作效率、角色分配、环境适应和任务并行等方面的问题。", "method": "提出一个七层框架，包括多智能体协作、单智能体多角色扮演、单智能体多场景穿越、单智能体多能力化身、不同单智能体使用同一大模型实现同一目标智能体、单智能体使用不同大模型实现同一目标智能体，以及多智能体合成同一目标智能体。", "result": "在艺术创作中的实验验证表明，该框架在任务协作、跨场景适应和模型融合方面具有独特优势。", "conclusion": "该框架为AI艺术创作中的多智能体协作提供了结构化方法，并促进了艺术领域的创新应用。未来可通过元学习和联邦学习等技术进一步探索协作机制优化、模型稳定性和系统安全性等挑战。"}}
{"id": "2504.12757", "title": "MCP Guardian: A Security-First Layer for Safeguarding MCP-Based AI System", "authors": ["Sonu Kumar", "Anubhav Girdhar", "Ritesh Patil", "Divyansh Tripathi"], "abstract": "As Agentic AI gain mainstream adoption, the industry invests heavily in model capabilities, achieving rapid leaps in reasoning and quality. However, these systems remain largely confined to data silos, and each new integration requires custom logic that is difficult to scale. The Model Context Protocol (MCP) addresses this challenge by defining a universal, open standard for securely connecting AI-based applications (MCP clients) to data sources (MCP servers). However, the flexibility of the MCP introduces new risks, including malicious tool servers and compromised data integrity. We present MCP Guardian, a framework that strengthens MCP-based communication with authentication, rate-limiting, logging, tracing, and Web Application Firewall (WAF) scanning. Through real-world scenarios and empirical testing, we demonstrate how MCP Guardian effectively mitigates attacks and ensures robust oversight with minimal overheads. Our approach fosters secure, scalable data access for AI assistants, underscoring the importance of a defense-in-depth approach that enables safer and more transparent innovation in AI-driven environments.", "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.12757.pdf", "abstract_url": "https://arxiv.org/abs/2504.12757", "categories": ["Cryptography and Security (cs.CR)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent", "agentic"], "AI": {"tldr": "本文介绍了MCP Guardian，一个为基于MCP的AI系统提供安全保护的框架，通过认证、限速、日志记录、追踪和WAF扫描等措施，有效减轻攻击并确保强健的监督，同时最小化开销。", "motivation": "随着Agentic AI的主流化，行业在模型能力上投入巨大，实现了推理和质量的快速飞跃。然而，这些系统仍然大多局限于数据孤岛，每个新的集成都需要难以扩展的自定义逻辑。MCP通过定义一个通用的、开放的标准来安全连接基于AI的应用程序（MCP客户端）和数据源（MCP服务器）来解决这一挑战。但MCP的灵活性也带来了新的风险，包括恶意工具服务器和数据完整性的破坏。", "method": "我们提出了MCP Guardian，一个框架，通过认证、限速、日志记录、追踪和Web应用防火墙（WAF）扫描来加强基于MCP的通信。", "result": "通过真实场景和实证测试，我们展示了MCP Guardian如何有效减轻攻击并确保强健的监督，同时最小化开销。", "conclusion": "我们的方法促进了AI助手的安全、可扩展数据访问，强调了深度防御方法的重要性，这种方法能够在AI驱动的环境中实现更安全、更透明的创新。"}}
{"id": "2504.13128", "title": "FreshStack: Building Realistic Benchmarks for Evaluating Retrieval on Technical Documents", "authors": ["Nandan Thakur", "Jimmy Lin", "Sam Havens", "Michael Carbin", "Omar Khattab", "Andrew Drozdov"], "abstract": "We introduce FreshStack, a reusable framework for automatically building information retrieval (IR) evaluation benchmarks from community-asked questions and answers. FreshStack conducts the following steps: (1) automatic corpus collection from code and technical documentation, (2) nugget generation from community-asked questions and answers, and (3) nugget-level support, retrieving documents using a fusion of retrieval techniques and hybrid architectures. We use FreshStack to build five datasets on fast-growing, recent, and niche topics to ensure the tasks are sufficiently challenging. On FreshStack, existing retrieval models, when applied out-of-the-box, significantly underperform oracle approaches on all five topics, denoting plenty of headroom to improve IR quality. In addition, we identify cases where rerankers do not clearly improve first-stage retrieval accuracy (two out of five topics). We hope that FreshStack will facilitate future work toward constructing realistic, scalable, and uncontaminated IR and RAG evaluation benchmarks. FreshStack datasets are available at:", "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)", "comments": null, "pdf_url": "https://arxiv.org/pdf/2504.13128.pdf", "abstract_url": "https://arxiv.org/abs/2504.13128", "categories": ["Information Retrieval (cs.IR)", "Artificial Intelligence (cs.AI)", "Computation and Language (cs.CL)"], "matching_keywords": ["@RAG"], "AI": {"tldr": "FreshStack是一个可重复使用的框架，用于从社区提问和答案中自动构建信息检索（IR）评估基准。它通过自动收集代码和技术文档、从社区问答中生成信息块，以及使用检索技术和混合架构的融合来检索文档，构建了五个数据集。现有检索模型在这些数据集上的表现显著低于理想方法，表明IR质量有提升空间。", "motivation": "解决构建现实、可扩展且未受污染的信息检索（IR）和检索增强生成（RAG）评估基准的挑战。", "method": "自动从代码和技术文档收集语料库，从社区问答生成信息块，使用检索技术和混合架构的融合进行文档检索。", "result": "现有检索模型在五个主题上的表现显著低于理想方法，且在某些情况下，重新排名器并未明显提高第一阶段的检索准确性。", "conclusion": "FreshStack为构建现实、可扩展且未受污染的IR和RAG评估基准提供了便利，现有检索模型的表现表明IR质量有显著提升空间。"}}
{"id": "2504.12777", "title": "Multi-Agent Reinforcement Learning Simulation for Environmental Policy Synthesis", "authors": ["James Rudd-Jones", "Mirco Musolesi", "María Pérez-Ortiz"], "abstract": "Climate policy development faces significant challenges due to deep uncertainty, complex system dynamics, and competing stakeholder interests. Climate simulation methods, such as Earth System Models, have become valuable tools for policy exploration. However, their typical use is for evaluating potential polices, rather than directly synthesizing them. The problem can be inverted to optimize for policy pathways, but the traditional optimization approaches often struggle with non-linear dynamics, heterogeneous agents, and comprehensive uncertainty quantification. We propose a framework for augmenting climate simulations with Multi-Agent Reinforcement Learning (MARL) to address these limitations. We identify key challenges at the interface between climate simulations and the application of MARL in the context of policy synthesis, including reward definition, scalability with increasing agents and state spaces, uncertainty propagation across linked systems, and solution validation. Additionally, we discuss challenges in making MARL-derived solutions interpretable and useful for policy-makers. Our framework provides a foundation for more sophisticated climate policy exploration while acknowledging important limitations and areas for future research.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": "Published in AAMAS'25 Blue Sky Ideas Track", "pdf_url": "https://arxiv.org/pdf/2504.12777.pdf", "abstract_url": "https://arxiv.org/abs/2504.12777", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种利用多智能体强化学习（MARL）增强气候模拟的框架，以解决气候政策制定中的非线性动态、异质代理和全面不确定性量化等挑战。", "motivation": "气候政策制定面临深度不确定性、复杂系统动态和竞争利益相关者利益等挑战，传统的气候模拟方法主要用于评估潜在政策，而非直接合成政策。", "method": "通过将多智能体强化学习（MARL）与气候模拟相结合，提出一个框架来优化政策路径，解决非线性动态、异质代理和不确定性量化等问题。", "result": "识别了气候模拟与MARL在政策合成应用中的关键挑战，包括奖励定义、可扩展性、不确定性传播和解决方案验证，并讨论了使MARL衍生解决方案对政策制定者可解释和有用的挑战。", "conclusion": "该框架为更复杂的气候政策探索提供了基础，同时承认了重要的局限性和未来研究领域。"}}
{"id": "2504.12961", "title": "QLLM: Do We Really Need a Mixing Network for Credit Assignment in Multi-Agent Reinforcement Learning?", "authors": ["Zhouyang Jiang", "Bin Zhang", "Airong Wei", "Zhiwei Xu"], "abstract": "Credit assignment has remained a fundamental challenge in multi-agent reinforcement learning (MARL). Previous studies have primarily addressed this issue through value decomposition methods under the centralized training with decentralized execution paradigm, where neural networks are utilized to approximate the nonlinear relationship between individual Q-values and the global Q-value. Although these approaches have achieved considerable success in various benchmark tasks, they still suffer from several limitations, including imprecise attribution of contributions, limited interpretability, and poor scalability in high-dimensional state spaces. To address these challenges, we propose a novel algorithm, \\textbf{QLLM}, which facilitates the automatic construction of credit assignment functions using large language models (LLMs). Specifically, the concept of \\textbf{TFCAF} is introduced, wherein the credit allocation process is represented as a direct and expressive nonlinear functional formulation. A custom-designed \\textit{coder-evaluator} framework is further employed to guide the generation, verification, and refinement of executable code by LLMs, significantly mitigating issues such as hallucination and shallow reasoning during inference. Extensive experiments conducted on several standard MARL benchmarks demonstrate that the proposed method consistently outperforms existing state-of-the-art baselines. Moreover, QLLM exhibits strong generalization capability and maintains compatibility with a wide range of MARL algorithms that utilize mixing networks, positioning it as a promising and versatile solution for complex multi-agent scenarios.", "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)", "comments": "9 pages, 7 figures", "pdf_url": "https://arxiv.org/pdf/2504.12961.pdf", "abstract_url": "https://arxiv.org/abs/2504.12961", "categories": ["Multiagent Systems (cs.MA)", "Artificial Intelligence (cs.AI)"], "matching_keywords": ["agent"], "AI": {"tldr": "本文提出了一种名为QLLM的新算法，利用大型语言模型（LLMs）自动构建信用分配函数，以解决多智能体强化学习（MARL）中的信用分配问题。通过引入TFCAF概念和定制设计的coder-evaluator框架，QLLM在多个标准MARL基准测试中表现优异，展现出强大的泛化能力和广泛的兼容性。", "motivation": "解决多智能体强化学习中的信用分配问题，特别是现有方法在贡献精确归属、可解释性和高维状态空间扩展性方面的局限性。", "method": "提出QLLM算法，利用大型语言模型自动构建信用分配函数，引入TFCAF概念表示信用分配过程，并采用coder-evaluator框架指导LLMs生成、验证和优化可执行代码。", "result": "在多个标准MARL基准测试中，QLLM算法 consistently outperforms existing state-of-the-art baselines，展现出强大的泛化能力和广泛的兼容性。", "conclusion": "QLLM作为一种新颖且通用的解决方案，适用于复杂的多智能体场景，能够有效解决MARL中的信用分配问题，并保持与多种利用混合网络的MARL算法的兼容性。"}}
